Corpus -Based  Learn ing  of  Compound Noun Index ing  * 
Byung-Kwan Kwak, 
Jee-Hyub Kim, 
and Geunbae Lee t 
NLP Lab., Dept. of CSE 
Pohang University of 
Science & Technology 
(POSTECH) 
{nerguri,gblee} @postech.ac.kr 
J ung  Yun  Seo 
NLP Lab., 
Dept. of Computer  Science 
Sogang University 
seojy@ccs.sogang.ac.kr 
Abst ract  
In this paper, we present a corpus- 
based learning method that can 
index diverse types of compound 
nouns using rules automatically ex- 
tracted from a large tagged corpus. 
We develop an efficient way of ex- 
tracting the compound noun index- 
ing rules automatically and perform 
extensive experiments to evaluate 
our indexing rules. The automatic 
learning method shows about the 
same performance compared with 
the manual inguistic approach but 
is more portable and requires no 
human efforts. We also evaluate 
the seven different filtering meth- 
ods based on both the effectiveness 
and the efficiency, and present a 
new method to solve the problems of 
compound noun over-generation a d 
data sparseness in statistical com- 
pound noun processing. 
1 In t roduct ion  
Compound nouns are more specific and ex- 
pressive than simple nouns, so they are more 
valuable as index terms and can increase 
the precision in search experiments. There 
are many definitions for the compound noun 
which cause ambiguities as to whether a given 
continuous noun sequence is a compound 
noun or not. We, therefore, need a clean 
" This research was supported by KOSEF special 
purpose basic research (1997.9 - 2000.8 #970-1020- 
301-3) 
t Corresponding author 
definition of compound nouns in terms of in- 
formation retrieval, so we define a compound 
noun as "any continuous noun sequence that 
appears frequently in documents." 1 
In Korean documents, compound nouns are 
represented in various forms (shown in Table 
1), so there is a difficulty in indexing all types 
of compound nouns. Until now, there have 
been much works on compound noun index- 
ing, but they still have limitations of cover- 
ing all types of compound nouns and require 
much linguistic knowledge to accomplish this 
goal. In this paper, we propose a corpus- 
based learning method for compound noun 
indexing which can extract he rules automat- 
ically with little linguistic knowledge. 
Table 1: Various types of Korean compound 
noun with regard to "jeong-bo geom-saeg (in- 
formation retrieval)" 
jeong-bo-geom-saeg (information-retrieval) 
jeong-bo-eui geom-saeg (retrieval of information) 
jeong-bo geom-saeg (information retrieval) 
jeong-bo-leul geom-saeg-ha-neun 
(retrieving information) 
jeong-bo-geom-saeg si-seu-tem 
(information-retrieval system) 
As the number of the documents i growing 
retrieval, efficiency also becomes as important 
as effectiveness. To increase the efficiency, we 
focus on reducing the number of indexed spu- 
rious compound nouns. We perform experi- 
ments on several filtering methods to find the 
algorithm that can reduce spurious compound 
nouns most efficiently. 
1 The frequency threshold can be adjusted accord- 
ing to application systems. 
57 
The remainder of this paper ? is organized 
as follows. Section 2 describes previous com- 
pound noun indexing methods for Korean and 
compound noun filtering methods. We show 
overall compound noun indexing system ar- 
chitecture in Section 3, and expl~.~n each mod- 
ule of the system in Section 4 and 5 in de- 
tail. We evaluate our method with standard 
Korean test collections in Section 6. Finally, 
concluding remarks are given in Section 7. 
2 P rev ious  Research  
2.1 Compound Noun Indexing 
There have been two different methods 
for compound noun indexing: statistical 
and linguistic. In one Statistical method, 
(Fagan, 1989) indexed phrases using six 
different parameters, including information 
on co-occurrence of phrase elements, rela- 
tive location of phrase elements, etc., and 
achieved reasonable performance. However, 
his method couldn't reveal consistent sub- 
stantial improvements on five experimental 
document collections in effectiveness. (Strza- 
lkowski et al, 1996; Evans and Zhai, 1996) 
indexed subcompounds from complex noun 
phrases using noun-phrase analysis. These 
methods need to find the head-modifier rela- 
tions from noun phrases and therefore require 
difficult syntactic parsing in Korean. 
For Korean, in one statistical method, (Lee 
and Ahn, 1996) indexed general Korean nouns 
using n-grams without linguistic knowledge 
and the experiment results showed that the 
proposed method might be Mmost as effec- 
tive as the linguistic noun indexing. How- 
ever, this method can generate many spuri- 
ous n-grarn~ which decrease the precision in 
search performance. In linguistic methods, 
(Kim, 1994) used five manually chosen com- 
pound noun indexing rule patterns based on 
linguistic knowledge. However, this method 
cannot index the diverse types of compound 
nouns. (Won et al, 2000) used a full parser 
and increased the precision in search experi- 
ments. However, this linguistic method can- 
not be applied to unrestricted texts robustly. 
In summary, the previous methods, 
whether they are statistical or linguistic, 
have their own shortcomings. Statistical 
methods require signiAcant amounts of 
co-occurrence information for reasonable 
performance and can not index the diverse 
types of compound nouns. Linguistic meth- 
ods need compound noun indexing rules 
described by human and sometimes result 
in meaningless compound nouns, which 
decreases the performance of information 
retrieval systems. They cannot also cover the 
various types of compound nouns because of 
the limitation of human linguistic knowledge. 
In this paper, we present a hybrid method 
that uses linguistic rules but these rules are 
automatically acquired from a large corpus 
through statistical learning. Our method gen- 
erates more diverse compound noun index- 
ing rule patterns than the previous tandard 
methods (Kim, 1994; Lee et ah, 1997), be- 
cause previous methods use only most gen- 
eral rule patterns (shown in Table 2) and are 
based solely on human linguistic knowledge. 
Table 2: Typical hand-written compound 
noun indexing rule patterns for Korean 
Noun without case makers / Noun 
Noun with a genitive case maker / Noun 
Noun with a nominal case maker or 
an accusative case maker \[ 
Verbal common oun or adjectival common noun 
Noun with an adnominal ending \] Noun 
Noun within predicate particle phrase / Noun 
(The two nouns before and after a slash 
in the pattern can form a single compound noun.) 
2.2 Compound Noun F i l ter ing 
Compound noun indexing methods, whether 
they are statistical or linguistic, tend to gen- 
erate spurious compound nouns when they 
are actually applied. Since an information re- 
trieval system can be evaluated by its effec- 
tiveness and also by its efficiency (van Rijs- 
bergen, 1979), the spurious compound nouns 
should be efficiently filtered. (Kando et al, 
1998) insisted that, for Japanese, the smaller 
the number of index terms is, the better the 
performance of the information retrieval sys- 
tem should be. 
58 
For Korean, (Won et al, 2000) showed 
that segmentation f compound nouns is more 
efficient than compound noun synthesis in 
search performance. There have been many 
works on compound noun filtering methods; 
(Kim, 1994) used mutual information only, 
and (Yun et al, 1997) used mutual informa- 
tion and relative frequency of POS (Part-Of- 
Speech) pairs together. (Lee et ai., 1997) used 
stop word dictionaries which were constructed 
manually. Most of the previous methods for 
compound noun filtering utilized only one 
consistent method for generated compound 
nouns irrespective of the different origin of 
compound noun indexing rules, and the meth- 
ods cause many problems due to data sparse- 
hess in dictionary and training data. Our 
approach solves the data sparseness problem 
by using co-occurrence information on auto- 
matically extracted compound noun elements 
together with a statistical precision measure 
which fits best to each rule. 
3 Overa l l  Sys tem Arch i tec ture  
The compound noun indexing system pro- 
posed in this paper Consists of two major 
modules: one for automatically extracting 
compound noun indexing rules (in Figure 1) 
and the other for indexing documents, fil- 
tering the automatically generated compound 
nouns, and weighting the indexed compound 
nouns (in Figure 2). 
Compound ~ Tagged Corpus 1 
Compound ~ R  
Noun Statistical 
Information 
~ Roles with 
Precision 
Extracted Rules I 
Filtered Rules 
Figure 1: Compound noun indexing-rule ex- 
traction module (control flow =~, data flow 
Compound Noun~-----~-~ Indexing I ~_Indexing~'~ / 
Rules wig f--.......?-.~ 
Compound 
//Compound Noun\[ s~i~ \[ Infonnadon \[ 
Find \[ Compound I Nouns , I 
Weighted 
. Compound 
Nouns 
Figure 2: Compound noun indexing, filtering, 
and weighting module (control flow =~, data 
flow ~) 
4 Automat ic  Ext rac t ion  of  
Compound Noun Index ing  Ru les  
There are three major steps in automatically 
extracting compound noun indexing rules. 
The first step is to collect compound noun 
statistical information, and the second step is 
to extract the rules from a large tagged cor- 
pus using the collected statistical information. 
The final step is to learn each rule's precision.. 
4.1 Col lect ing Compound Noun 
Statist ics 
We collect initial compound noun seeds which 
were gathered from various types of well- 
balanced ocuments uch as ETRI Kemong 
encyclopaedia 2 nd many dictionaries on the 
Internet, and we collected 10,368 seeds, as 
shown in Table 3. The small number of seeds 
are bootstrapped to extract the Compound 
noun indexing rules for various corpora. 
Table 3: Collected compound noun seeds 
No. of 2 3 Total 
component elements 
ETRI Kemong encyclomedia 5,100 2,088 7,188 
Internet dictionaries 2,071 1,109 3,180 
To collect more practical statistics on the 
compound nouns, we made a 1,000,000 eo- 
jeol(Korean spacing unit which corresponds 
2 Courteously provided by ETRI, Korea. 
59 
to an English word or phrase) tagged cor- 
pus for a compound noun indexing experi- 
ment from a large document set (Korean In- 
formation Base). We collected complete com- 
pound nouns (a continuous noun sequence 
composed of at least two nouns on the condi- 
tion that both the preceding and the following 
POS of the sequence axe not nouns (Yoon et 
al., 1998)) composed of 1 - 3 no, ms from the 
tagged training corpus (Table 4). 
Table 4: Statistics for complete compound 
nouns 
No. of 1 2 3 
component elements 
Vocabulary 264,359 200,455 63,790 
4.2  Ext rac t ing  Index ing  Ru les  
We define a template (in Table 5) to extract 
the compound noun indexing rules from a 
POS tagged corpus. 
The template means that if a front- 
condition-tag, a rear-condition-tag, and sub- 
string-tags are coincident with input sentence 
tags, the lexical item in the synthesis position 
of the sentence can be indexed as a compound 
noun as "x /  y (for 3-noun compounds, x / 
y / z)". The tags used in the template are 
POS (Part-Of-Speech) tags and we use the 
POSTAG set (Table 17). 
The following is an algorithm to extract 
compound noun indexing rules from a large 
tagged corpus using the two-noun compound 
seeds and the template defined above. The 
rule extraction scope is limited to the end 
of a sentence or, if there is a conjunctive 
ending (eCC) in the sentence, only to the 
conjunctive nding of the sentence. A rule 
extraction example is shown in Figure 3. 
Algorithm 1: Extracting compound noun 
indexing rules (for 2-noun compounds) 
Read Template 
Read Seed 
(Consist of Constituent 1 / Constituent 2) 
TokeD/ze Seed into Constituents 
Put Constituent 1 into Key1 and Constituent 2 
? into Key2 
While (Not(End of Documents)) 
{ 
Read Initial Tag of Sentence 
While (Not(End of Sentence or eCC)) 
{ 
Read NeIt Tag of Sentence 
If (Read Tag =ffi Key1) 
{ 
While (Not(End of Sentence or eCC)) 
( 
Read Next Tag of Sentence 
If (Current Tag == Key2) 
Write Rule according 
to the Template 
} 
} 
} 
The next step is to  refine the extracted 
rules to select he proper ones. We used a rule 
filtering algorithm (Algorithm 2) using the 
frequency together with the heuristics that 
the rules with negative lexical items (shown in 
Table 6) will make spurious compound nouns. 
Algorithm 2: Filtering extracted rules us- 
ing frequency and heuristics 
I. For each compound noun seed, select 
the rules whose frequency is greater than 2. 
2. Among rules selected by step 1, select 
only rules that are extracted 
at least by 2 seeds. 
3. Discard rules which contain 
negative lexical items. 
Table 5: The template to extract the com- 
pound noun indexing rules 
,o  
front-condition-tag I 
sub-string-tags (tag 1 tag 2 ... tag n-1 tag n) \[ 
rear-condition-tag I 
synthesis locations (x y) 
lexicon x / lexicon y 
(for 3-noun compounds, 
synthesis locations (x, y, z) 
lexicon x / lexicon y / lexicon z) 
Table 6: Negative 
negative items (tags) 
je-oe(MC) (exclude) 
eobs(E) (not exist) 
mos-ha(D) (can not) 
lexical item examples 
example phrases 
no-jo-leul je-oe-han hoe-eui 
(meeting excluding union) 
sa-gwa-ga eobs~neun na-mu 
(tree without apple) 
dog-lib-eul mos-han gug-ga 
(country that 
cannot be liberated) 
We automatically extracted and filtered out 
60 
Tagged ~t~ 
B,~baI-Ib, 
MC< .kong-bo > 
.iC<tmb. 
MC< geom-sacg > 
fron~com~illm1_~g I sub_s~ring_mgs (~ I lag2 ... tag n-I ~n)  
~rcar_cond~iol~. I~ syn~lcsls location (x y) ~> lexicon x I Icxlco~ y 
(i.formafioa~?uicvall 
Indcxlag Rule: 
B I MC.jC<leul> MC I y I l 3 
Figure 3: Rule Extraction Process Example 
2,036 rules from the large tagged corpus (Ko- 
rean Information Base, 1,000,000 eojeol) us- 
ing the above Algorithm 2. Among the ill- 
tered rules, there are 19 rules with negative 
lexical items and we finally selected 2,017 
rules. Table 7 shows a distribution of the final 
rules according to the number of elements in 
their sub-string-tags. 
Table 7: Distribution of extracted rules by 
number of elements in sub-string-tags 
No. Distribution Example 
2 tags 79.6 % MC MC 
3 tags 12.6 % MC jO(eui) MC 
4 tags 4.7 % MC y eCNMG MC 
5 tags 1.5 % MC MC jO(e) 
DI<sog-ha-neun) MC 
over 6 tags 1.6 % 
The automatically extracted rules have 
more rule patterns and lexical items than 
human-made rules so they can cover more 
diverse types of compound nouns (Table 8). 
When checking the overlap between the two 
rule collections, we found that the manual in- 
guistic rules are a subset of our automatically 
generated statistical rules. Table 9 shows 
some of the example rules newly generated 
from our extraction algorithm, which were 
originally missing in the manual rule patterns. 
4.3 Learning the Precision o f  
Ext racted  Rules 
In the proposed method, we use the precision 
of rules to solve the compound noun over- 
generation and the data sparseness problems. 
The precision of a rule can be defined by 
Table 8: Comparison between the automati- 
cally extracted rules and the manual rules 
Method 
Manual 
linguistic 
method 
Our method 
No. of No. of 
general lexical terms 
rule patterns used in rule patterns 
16 
23 78 
Table 9: Examples of newly added rule pat- 
terns 
Rule 
Noun + bound noun / Noun 
Noun + suffix / Noun 
Noun + suffix + assignment verb + 
adnominal ending / Noun 
counting how many indexed compound noun 
candidates generated by the rule are actual 
compound nouns: 
Yactuat 
Prec(rule) = Ncandidate 
where Prec(rule) is the precision of a rule, 
Ndctual is the number of actual compound 
nouns, and Ncandidat e is the number of com- 
pound noun candidates generated by the au- 
tomatic indexing rules. 
To  calculate the precision, we need a defin- 
ing measurement for compound noun identi- 
fication. (Su et al, 1994) showed that the 
average mutual information of a compound 
noun tends to be higher than that of a non- 
compound noun, so we try to use the mutual 
information as the measure for identifying the 
compound nouns. If the mutual information 
of the compound noun candidate is higher 
than the average mutual information of the 
compound noun seeds, we decide that it is 
a compound noun. For mutual information 
(MI), we use two different equations: one for 
two-element compound nouns (Church and 
Hanks, 1990) and the other for three-element 
compound nouns (Suet  al., 1994). The equa- 
tion for two-element compound nouns is as 
follow: 
P(x,y) 
I(x;y) = log 2 P(x) x P(y) 
61 
where x and y are two words in the corpus, 
and I(x; y) is the mutual information of these 
two words (in this order). Table 10 shows 
the average MI value of the two and three 
elements. 
Table 10: Average value of the mutual infor- 
mation (MI) of compound noun seeds 
.Number of elements \[ 2 I 3 
Average MI 3.56 3.62 
The MI was calculated from the statistics of 
the complete compound nouns collected from 
the tagged training corpus (see Section 4.1). 
However, complete compound nouns are 
continuous noun sequences and cause the 
data sparseness problem. Therefore, we need 
to expand the statistics. Figure 4 shows 
the architecture of the precision learning 
module by expanding the statistics of the 
complete compound nouns along with an 
algorithmic explanation (Algorithm 3) of the 
process. Table 11 shows the improvement in
the average precision during the repetitive 
execution of this learning process. 
Norm Statistical ) 
Compound Norm of Rules ~ '~ Rule incision (step 5) (s~ 2.7) l~v v\[ (step s) 
Figure 4: Learning the precision of the com- 
pound noun indexing rules (The steps are 
shown in Algorithm 3) 
Algorithm 3: 
i. Calculate all rules' initial precision 
using initial complete compound noun 
statistical information. 
2. Calculate the average precision 
of the rules. 
3. Multiply a rule's precision by 
the frequency of the compound noun made 
by the  ru le .  
We ca l l  th i s  va lue  the  mod i f ied  f requency  
(MF). 
4. Collect the same compound nouns, and 
sum all the modified frequencies 
for each compound noun. 
5. If the sunm~ed modified frequency is greater 
than a threshold, add this compound noun 
to the complete compound noun 
s ta t i s t i ca l  information. 
6. Calculate all rules' precision again 
using the changed complete compound noun 
s ta t i s t i ca l  in fo rmat ion .  
7. Calculate the average precision of the rules. 
8. If the average precision of the rules is 
equal to the previous average precision, 
stop. Othervise, go to step 2. 
Table 11: Improvement in the average preci- 
sion of rules 
Learning 1 2 3 4 5 6 
cycles 
Avg. prec. 0.19 0.23 0.39 0.44 0.45 0.45 
of rules 
5 Compound Noun Index ing ,  
F i l te r ing ,  and  Weight ing  
In this section, we explai n how to use the au- 
tomatically extracted rules to actually index 
the compound nouns, and describe how to fil- 
ter and weight the indexed compound nouns. 
5.1 Compound Noun I ndex ing  
To index compound nouns from documents, 
we use a natural anguage processing engine, 
SKOPE (Standard KOrean Processing En- 
gine) (Cha et al, 1998), which processes doc- 
uments by analysing words into morphemes 
and tagging part-of-speeches. The tagging 
results are compared with the automatically 
learned compound noun indexing rules and, if 
they are coincident with each other, we index 
them as compound nouns. Figure 5 shows a 
process of the compound noun indexing with 
an example. 
5.2 Compound Noun F i l ter ing 
Among the indexed compound nouns above, 
still there can be meaningless compound 
nouns, which increases the number of index 
terms and the search time. To solve com- 
pound noun over-generation problem, we ex- 
periment with seven different filtering meth- 
ods (shown in Table 12) by analyzing their 
62 
?. " Tagging Result: 
bbal-li jeong-bo-leul B<bbal-li> 
geom-saeg-ha-netm ~ Auaty~ ~.  ~ MC<jeong-bo >
(~evmg I \~'~?_"2:? ?"/ ~ jc<,e.,> 
information I \ tagging / /1..~ ? :-t.~..~ \] ~ --  - /  / I.MU< geom-saeg > 
/ I eCNMG<neun> 
"~d~"~g"l~ ~es-- \ ] 'X~mpoun"~ Indexed 
i 1,2 . 
Complete l /  ~ geom-saeg 
_ C?mp~No~ ~ - -  (mf , ,~o . /  
Statistical Information \] retrieval) 
Figure 5: Compound noun indexing process 
relative effectiveness and efficiency, as shown 
in Table 16. These methods can be divided 
into three categories: first one using MI, sec- 
ond one using the frequency of the compound 
nouns (FC), and the last one using the fre- 
quency of the compound noun elements (FE). 
MI (Mutual Information) is a measure of word 
association, and used under the assumption 
that a highly associated word n-gram is more 
likely to be a compound noun. FC is used 
under the assumption that a frequently en- 
countered word n-gram is more likely to be a 
compound than a rarely encountered n-gram. 
FE is ;used under the assumption that a word 
n-gram with a frequently encountered specific 
element is more likely to be a compound. In 
the method of C, D, E, and F, each threshold 
was decided by calculating the average num- 
ber of compound nouns of each method. 
Table 12: Seven different filtering methods 
(MI) A. Mutual information of compound 
noun elements (0) 
(MI) B. Mutual information of compound 
noun elements 
(average of MI of compound noun seeds) 
(FC) C. Frequency of compound nouns 
in the training corpus (4) 
(FC) D. Frequency of compound nouns 
in the test corpus (2) 
(FE) E. Frequency of compound noun heads 
in the training corpus (5) 
(FE) F. Frequency of compound noun modifiers 
in the training corpus (5) 
G. No filtering 
(The value in parantheses is a threshold.) 
Among these methods, method B gener- 
ated the smallest number of compound nouns 
best efficiency and showed the reasonable f- 
fectiveness (Table 16). On the basis of this 
filtering method, we develop a smoothing 
method by combining the precision of rules 
with the mutual information of the compound 
noun elements, and propose our final filtering 
method (H) as follows: 
P(x, y) + ~ ? Precision T(x, y) = log 2 P(x) x P(y) 
where a is a weighting coefficient and Preci- 
sion is the applied rules learned in Section 4.3. 
For the three-element compound nouns, the 
MI part is replaced with the three-element MI
equation 3 (Su et al, 1994). 
6 Exper iment  Resu l ts  
To calculate the similarity between a docu- 
ment and a query, we use the p-norm retrieval 
model (Fox, 1983) and use 2.0 as the p-value. 
We also use fhe  component nouns in a com- 
pound as the indexing terms. We follow the 
standard TREC evaluation schemes (Salton 
and Buckley, 1991). For single index terms, 
we use the weighting method atn.ntc (Lee, 
1995). 
6.1 Compound Noun Index ing  
Exper iments  
This experiment shows how well the proposed 
method can index diverse types of compound 
nouns than the previous popular methods 
which use human-generated compound noun 
indexing rules (Kim, 1994; Lee et al, 1997). 
For simplicity, we filtered the generated com- 
pound nouns using the mutual information of 
the compound noun elements with a thresh- 
old of zero (method A in Table 12). 
Table 13 shows that the terms indexed by 
previous linguistic approach are a subset of 
the ones made by our statistical approach. 
This means that the proposed method can 
cover more diverse compound nouns than the 
3 
PD (x, ~, z) 
I(x;y;z) = log 2 Px(x,y,z) 
63 
Table 13: Compound noun indexing coverage 
experiment (With a 200,000 eojeol Korean In- 
formation Base) 
Manual 
linguistic 
rule patterns 
Our 
automatic 
rule patterns 
No. of 
generated actual 22,276 30,168 
compound nouns. (+35.4 %) 
No. of 
generated actual 7,892 
compound nouns 
without overlap 
manual inguistic rule method. We perform a 
retrieval experiment to evaluate the automat- 
ically extracted rules. Table 144 and table 155 
show that our method has slightly better re- 
call and l l -point average precision than the 
manual inguistic rule method. 
Table 14: Compound noun indexing effective- 
ness experiment I 
Avg. recall 
Manual linguistic 
rule patterns 
82.66 
Our automatic 
rule patterns 
83.62 
(+1.16 %) 
ll-pt. 42.24 42.33 
avg. precision (+0.21%) 
No. of 504,040 515,801 
index terms (+2.33 %) 
Table 15: Compound noun indexing effective- 
ness experiment II
Avg. recall 
ll-pt, avg. 
precision 
No. of 
index terms 
Manual linguistic 
rule patterns 
86.32 
34.33 
1,242,458 
Our automatic 
rule patterns 
87.50 
(+1.35 %) 
34.54 
(+0.61%) 
1,282,818 
(+3.15 %) 
4 With KTSET2.0 test collections (Courteously 
provided by KT, Korea. (4,410 documents and 50 
queries)) 
s With KRIST2.0 test collection (Courteously pro- 
vided by KORDIC, Korea. (13,514 documents and 30 
queries)) 
6.2 Retrieval Experiments Using 
Various Filtering Methods 
In this experiment, we compare the seven fil- 
tering methods to find out which one is the 
best in terms of effectiveness and efficiency. 
For this experiment, we used our automatic 
rules for the compound noun indexing, and 
the test collection KTSET2.0. To check the 
effectiveness, we used recall and l l -point  av- 
erage precision. To check the efficiency, we 
used the number of index terms. Table 16 
shows the results of the various filtering ex- 
periments. 
From Table 16, the methods using mu- 
tual information reduce the number of in- 
dex terms, whereas they have lower precision. 
The reason of this lower precision is that MI 
has a bias, i.e., scoring in favor of rare terms 
over common terms, so MI seems to have a 
problem in its sensitivity to probabil ity es- 
t imation error (Yang and Pedersen, 1997). 
In this experiment 6, we see that method B 
generates the smallest number of compound 
nouns (best efficiency) and our final propos- 
ing method H has the best recall and precision 
? (effectiveness) with the  reasonable number ? of 
compound nouns (efficiency). We can con- 
clude that the filtering method H is the best, 
considering the effectiveness and the efficiency 
at the same time. 
7 Conc lus ion  
In this paper, we presented a method to ex- 
tract the compound noun indexing rules au- 
tomatically from a large tagged corpus, and 
showed that this method can index compound 
nouns appearing in diverse types of docu- 
ments. 
In the view of effectiveness, this method is 
slightly better than the previous linguistic ap- 
proaches but requires no human effort. 
The proposed method also uses no parser 
and no rules described by humans, there- 
fore, it can be applied to unrestricted texts 
very robustly and has high domain porta- 
6 Our Korean NLQ (Natural Lan- 
guage Querying) demo system (located in 
'http:/ /nlp.postech.ac.kz /Resarch/POSNLQ/') 
can be tested. 
64 
Table 16: Retrieval experiment 
A B C 
Average 83.62 83.62 83.62 
recall (+0.00) (+0.00) 
ll-pt, avg. 42.45 42.42 42.49 
precision (-0.07) (+0.09) 
Precision 52.11 52.44 52.07 
at 10 Docs. 
No. of 515,80 508,20 514,54 5~ 
index terms (-1.47) (-0.24) (-+ 
results 
D 
83.62 
(+0.00) 
42.55 
(+0.24) 
52.80 
47,27 
+6.10) 
of various filtering 
E F 
83.62 
(+0.00) 
42.72 
(+0.64) 
52.26 
572,36 
(+10.97) 
83.62 
(+0.00) 
42.48 
(+0.07) 
51.89 
574,04 
(+11.29) 
; methods 
G 
84.32 
(+0.84) 
42.48 
(+0.07) 
52.81 
705,98 
(+36.87) 
H 
84.32 
(.+0.84) 
42.75 
(+o.71) 
52.98 
509,90 
(-1.14) 
bility. We also presented a filtering method 
to solve the compound noun over-generation 
problem. Our proposed filtering method (H) 
shows good retrieval performance both in the 
view of the effectiveness and the efficiency. 
In the future, we need to perform some 
experiments on much larger commercial 
databases to test the practicality of our 
method. 
. Finally, our method doesn't  require lan- 
guage dependent knowledge, so it needs to be 
verified whether it can be easily applied to 
other languages. 
References 
Jeongwon Cha, Geunbae Lee, and Jong-Hyeok 
Lee. 1998. Generalized unknown morpheme 
guessing for hybrid pos tagging of korean. 
In Proceedings of SIXTH WORKSHOP ON 
VERY LARGE CORPORA in Coling-ACL 98. 
K. W. Church and P. Hanks. 1990. Word associ- 
ation norms, mutual information, and lexicog- 
raphy. Computational Linguistics, 16(1):22-29. 
David A. Evans and Chengxiang Zhai. 1996. 
Noun-phrase analysis in unrestricted text for 
information retrieval. In Proceedingof the 3~th 
Annual Meetinof the Association for Computa- 
tional Linguistics, Santa Cruz, CA, pages 17- 
24. 
Joel L. Fagan. 1989. The effectiveness of a non- 
syntactic approach to automatic phrase index- 
ing for document retrieval. JASIS, 40(2):115- 
132. 
E. A. Fox. 1983. Extending the Boolean and Vec- 
tor Space Models of Information Retrieval with 
P-norm Queries and Multiple Concept Types. 
Ph.D. thesis, Cornell Univ. 
Noriko Kando, Kyo Kageura, Masaharu Yoshoka, 
and Keizo Oyama. 1998. Phrase processing 
methods for japanase text retrieval. SIGIR fo- 
rum, 32(2):23-28. 
Pan Koo Kim. 1994. The automatic indexing 
of compound words from korean text based on 
mutual information. Journal of KISS (in Ko- 
rean), 21(7):1333-1340. 
Joon Ho Lee and Jeong Soo Ahn. 1996. Using 
n-grams for korean text retrieval. In SIGIR'96, 
pages 216-224. 
Hyun-A Lee, Jong-Hyeok Lee, and Geunbae Lee. 
1997. Noun phrase indexing using clausal 
segmentation. Journal of KISS (in Korean), 
24(3):302-311. 
Joon Ho Lee. 1995. Combining multiple vidence 
from different properties of weighting schemes. 
In SIGIR'95, pages 180-188. 
Gerard Salton and Chris Buckley. 1991. 
Text retrieval conferences evaluation pro- 
gram. In .ftp://)2p.cs.corneU.edu/pub/smart/, 
trec_eval.7.0beta.tar.gz. 
Tomek Strzalkowski, Louise Guthrie, Jussi Karl- 
gren, Jura Leistensnider, Fang Lin, Jose Perez- 
Carballo, Troy Straszheim, Jin Wang, and Jon 
Wilding. 1996. Natural anguage information 
retrieval: Trec-5 report. In The Fifth Text 
REtrieval conference (TREC-5), NIST Special 
publication, pages 500-238. 
Keh-Yih Su, Mind-Wen Wu, and Jing-Shin 
Chang. 1994. A corpus-based approach to au- 
tomatic ompound extraction. In Proceedings 
of ACL 94, pages 242-247. 
C. J. van Rijsbergen. 1979. Information Re- 
trieval. University of Computing Science, 
Lodon. 
Hyungsuk Won, Mihwa Park, and Geunbae Lee. 
2000. Integrated multi-level indexing method 
for compound noun processing. In Journal o.f 
KISS, 27(1) (in Korean), pages 84-95. 
65 
Tag 
MC 
T 
B 
DI 
I 
js 
eGS 
eCNMM 
eCC 
+ 
so  
s. 
sf 
Table 17: The POS (Part-Of-Speech) set of POSTAG 
common noun 
pronoun 
adverb 
irregular verb 
assignment verb 
auxiliary particle 
prefmal ending 
nominal ending 
conjunctive ending 
prefix 
other symbol 
sentence closer 
foreign word 
MP 
G 
K 
HI~ 
E 
jo 
eCNDI 
eCNMG 
Y 
S c 
s -  
sh 
Description 
proper noun 
adnoun 
interjection 
regular adjective 
existential predicate 
other particle 
attx conj ending 
adnomina l  end ing  
predicative particle 
suffix 
left parenthesis 
sentence connection 
Chinese character 
Tag 
MD 
S 
DR 
HI 
jc 
eGE 
eCNDC 
eCNB 
b 
su  
s '  
s ,  
Description 
bound noun 
numeral 
regular verb 
irregular adjective 
case particle 
final ending 
quote conj ending 
adverbial ending 
auxiliary verb 
unit symbol 
right parenthesis 
sentence comma 
Yiming Yang and Jan O. Pedersen. 1997. A com- 
parative study on feature selection in text cat- 
egorization. In Douglas H. Fisher, editor, Pro- 
ceedings of ICML-97, l~th International Con- 
ference on Machine Learning, pages 412--420, 
Nashville, US. Morgan Kaufmann Publishers, 
San Francisco, US. 
Jun-Tae Yoon, Eui-Seok Jong, and Mansuk Song. 
1998. Analysis of korean compound noun in- 
dexing using lexical information between ouns. 
Journal of KISS (in Korean), 25(11):1716- 
1725. 
Bo-Hyun Yun, Yong-Jae Kwak, and Hae-Chang 
Rim. 1997. A korean information retrieval 
model alleviating syntactic term mismatches. 
In Proceedings ofthe Natural Language Process- 
ing Pacific Rim Symposium, pages 107-112. 
66 
Proceedings of the 2012 Workshop on Biomedical Natural Language Processing (BioNLP 2012), pages 172?175,
Montre?al, Canada, June 8, 2012. c?2012 Association for Computational Linguistics
Finding small molecule and protein pairs in scientific literature using a
bootstrapping method
Ying Yan, Jee-Hyub Kim, Samuel Croset, Dietrich Rebholz-Schuhmann
European Bioinformatics Institute
Wellcome Trust Genome Campus
Hinxton
Cambridge
UK
{yan, jhkim, croset, rebholz}@ebi.ac.uk
Abstract
The relationship between small molecules
and proteins has attracted attention from the
biomedical research community. In this pa-
per a text mining method of extracting small-
molecule and protein pairs from natural text
is presented, based on a semi-supervised ma-
chine learning approach. The technique has
been applied to the complete collection of
MEDLINE abstracts and pairs were extracted
and evaluated. The results show the feasibility
of the bootstrapping system, which will subse-
quently be further investigated and improved.
1 Introduction
Information extraction has become a major task in
text-mining. A large number of studies have been
carried out with the objective of developing tech-
niques to overcome the highly ambiguous and vari-
able nature of natural language for the extraction of
information from scientific text (Song et al, 2006).
Natural language processing (NLP) of biomedical
text has been initiated and used for different knowl-
edge discovery tasks such as the extraction of rela-
tionships between different types of biological ob-
jects.
Relationships between proteins and small
molecules are of particular concern in the biomed-
ical research domain. The importance of target
specific small molecule research is vital in the
scientific community?s understanding of numerous
biological processes with potential discoveries
yielding various translational benefits and outcomes
to public health and industry. While there has been
a great number of traditional studies already com-
pleted in this field, the underlying difficulty with this
type of research has been trying to understand how
one molecule interacts with a target protein. Given
the biological background, many researchers in
Cheminformatics and Metabolomics are attempting
to find the connections between small molecules
and other biological entities in order to bridge the
chemical and biological domains.
Of the few reported text mining approaches to this
problem, Temkin and Gilder (2003) was concerned
with the extraction of protein and small molecule in-
teraction, and used a rule-based approach utilising
a lexical analyser and context free grammar. Jiao
and Wild (2009) presented a technique for detect-
ing protein and small molecule interaction using a
maximum entropy based learning method; this work
also uses corpus-based machine learning. The main
drawback of both of these studies is that they require
a fully annotated corpus which is difficult to gener-
ate.
1.1 The bootstrapping method
At present a gold standard annotated corpus is not
available, and constructing a reasonable annotated
corpus would require an infeasible amount of man-
ual work. Our proposed solution to this problem
is to develop a semi-supervised machine learning
method. In this paper a bootstrapping algorithm is
presented which requires only unannotated training
texts and a handful of protein small molecule pairs,
known as seeds. The basic work of a bootstrap-
ping system can be presented as an expansion en-
gine which uses the initial seed pairs fed into the
172
system to generate patterns that are used, in turn, to
find more pairs. The operation of the algorithm is
controlled by certain criteria that are delivered from
a measurement of the quality or selectivity of pat-
terns and discovered pairs.
Bootstrapping systems have been maturely used
for information extraction purposes in other research
domains, and it has been empirically shown to be
a powerful method in learning lexico-syntactic pat-
terns for extracting specific relations (Riloff and
Jones, 1999). Bootstrapping systems can operate
with a greatly reduced number of training examples.
A bootstrapping system seems promising for the
purpose of relation extraction, making it a suitable
candidate method for protein and small molecule
pair extraction.
2 Implementation
The typical bootstrapping method was tailored in
order to improve its suitability for our extraction
task, operating in the biomedical literature resource
MEDLINE. The bootstrapping architecture is pre-
sented in Figure 1. The whole collection of MED-
LINE was filtered using a co-occurrence approach
and a named entity recogniser. In this way the
sentences which contained both a protein and a
small molecule were selected. The structure of pat-
terns which are suitable to extract protein and small
molecule pairs from MEDLINE was defined. Each
sentence is tokenized and then normalised based on
the results of syntactic parsing in order to obtain a
more generalised view of the pattern. In the fol-
lowing sections, we describe in more detail these as-
pects.
2.1 Protein and small molecule recognition
Two dictionary-based named entity recognisers
were used to detect the names of proteins and small
molecules in the full collection of MEDLINE ab-
stracts, with the two source dictionaries constructed
using the resources UniProt (Apweiler et al, 2004)
and ChEBI (De Matos et al, 2006) respectively. The
following example shows the two recognisers iden-
tify a chemical object and a protein object in a sen-
tence from a MEDLINE extract:
<chebi>Paracetamol</chebi>, 100 mg/kg, in-
hibited <uniprot>COX-1</uniprot> in stomach
Figure 1: Extraction system architecture
mucosa ex vivo much less effectively than in other
tissues.
2.2 Sentence analysis for normalisation
It was anticipated that variations in tense and other
language characteristics would cause problems in
pattern generation. We therefore applied a list of
normalisation steps for pattern generation. The sur-
rounding context in the biomedical text is not nor-
mally useful and makes it difficult to identify the text
and observe a clear sentence structure. The parsing
result normalises patterns by eliminating non-useful
components in a sentence. The step of normalisation
hence increases the quality of the pattern.
The complete list of normalisation steps is as fol-
lows:
1. Replaced the representation of measurement
units, such as mg/L and ml/day.
2. Employed the part-of-speech (POS) tagger GE-
NIA (Tsuruoka et al, 2005) to analyse each to-
ken, and the tokens which are weakly related to
the sentence structure were removed. So that,
the only remaining tokens are the head noun of
a noun phrase (NP), the verb phrase, and prepo-
sitional phrase chunks.
3. Finally a simple rule to identify the head noun
was defined. In a general case, for a NP se-
quence, the last token is considered as the head
noun. When the last token is a single character,
the second last token is considered as the head
noun.
173
Table 1: An example of a generated pattern
Seed tuple: Paracetamol, COX-1
Found string: ?CHEBI, UNIT, inhibit UNIPROT
in mucosa than in tissue.?
Pattern: NP List1, UNIT, inhibit NP List2
Constraints: NP List1=?CHEBI*?
NP List2=?UNIPROT*?
Keywords: ?,UNIT,inhibit?
The above example after these normalisation
steps becomes:
CHEBI*, UNIT, inhibit UNIPROT* in mucosa
than in tissue.
where CHEBI* and UNIPROT* are the seeds in
context.
2.3 Bootstrapping
The bootstrapping system is applied to the nor-
malised sentences. The process starts with 100
high precision protein small molecule pairs col-
lected from the ChEBI ontology. These pairs were
retrieved by querying the ChEBI sub-ontology for
the relation ?has role?. From the resulting data we
extracted small molecules that are enzyme inhibitors
together with the name of the enzyme.
2.3.1 Pattern generation and pair extraction
The concept of a bootstrapping system is that us-
ing a high precision seed pair to start the extrac-
tion engine, the system can effectively learn the pat-
tern construction rule and the pattern constraints.
Searching for the seed pairs in the corpus returns
strings which are candidate extraction patterns for
other pairs. The candidate patterns are made up of
?slots? and ?context strings?, where the slots are ei-
ther of type small-molecule or protein, and context
is the text connecting the slots and the words imme-
diately before and after the pair. By analysing the
surrounding context of the slots new elements of the
pattern are discovered, which can subsequently be
used to search for new small-molecule protein pairs.
The process of deriving a pattern from the above ex-
ample is shown in Table 1.
The generated pattern can then be used to search
the corpus and find other matching contexts. New
pairs are retrieved from the matching context by
simply locating the protein and small molecule
names from the same positions as they are in the pat-
tern.
For instance, the pattern produced in Table 1 is
matched against a normalised sentence ?data sug-
gest CHEBI, UNIT, inhibit UNIPROT?, extracting
the new pair <trifluoperazine, CaMKII>.
2.3.2 Evaluating seeds and patterns
The quality of the pattern is critical since pat-
terns that generate a bad pair can introduce more
false positive seeds. Therefore, within a bootstrap-
ping system it is necessary to have a stage of pattern
evaluation. Estimations of the confidence score of
a pattern can be used as one of the stopping criteria.
We implemented an evaluation step for both patterns
and pairs based on an evaluation method developed
by Agichtein and Gravano (2000). Adapting the ap-
proach to this work, if patterni predicts tuple t =
<chemical, protein>, and there is already a tuple
t? = <chemical, protein?> with high confidence,
and chemical from t is same as chemical from t?,
then we could define this as a positive match of pat-
tern (Ppositive), otherwise the pattern is considered
as a negative match (Pnegative). So that the confi-
dence score of pattern (P ) is estimated as:
Conf(P ) =
Ppositive
Ppositive + Pnegative
(1)
To evaluate the pairs we again employ the method
described by Agichtein and Gravano (2000). The
confidence of a particular pair is a function of the
number of patterns that generate it. Equation 2
shows how to calculate a confidence score for tuple
T , where P is the set of patterns that derive T . Ci is
the context that also contains T , Match(Ci, Pi) is
the degree of match of Ci and Pi.
Conf(T ) = 1?
?|P |
I=0 (1? (Conf (Pi) ? Match (Ci, Pi)))
(2)
3 Results and discussion
Table 2 shows the top 10 generated patterns ranked
by the frequency that they appear in MEDLINE. As
can be seen the patterns all have very simple struc-
tures. Simple patterns are more likely to be produc-
tive, i.e the simpler the structure of the pattern, the
more pairs it generates. However, simple structures
are also likely to generate more false negative pairs.
174
The pairs produced by these top 10 patterns were
collected, and the confidence score then calculated
using equation 1. The result implies that the confi-
dence score of a pattern, and in turn the selectivity
and productivity of the pattern, are strongly associ-
ated with the pattern?s structure.
Table 2: The top 10 comment patterns
Frequency Pattern Confidence
68 UNIPROT* CHEBI* CHEBI 0.16
61 CHEBI* UNIPROT* UNIPROT 0.15
51 CHEBI* UNIPROT* be 0.10
49 CHEBI* UNIPROT* CHEBI 0.10
41 UNIPROT* CHEBI* be 0.21
40 CHEBI* UNIPROT* 0.08
38 UNIPROT* CHEBI* UNIPROT 0.16
37 UNIPROT* CHEBI* 0.30
26 be CHEBI* UNIPROT* 0.26
24 UNIPROT* CHEBI CHEBI* CHEBI 0.17
3.1 Quality of the extracted pairs
One hundred pairs extracted by first and second gen-
eration patterns were randomly selected for manual
inspection by a domain expert curator. It was found
that over 60% were valid pairs. From further exami-
nation of the cases together with their extraction pat-
terns, it can be seen that the patterns have a high con-
fidence score, ensuring the quality of the extracted
pair. For instance, from the original text Paraceta-
mol, 100 mg/kg, inhibited COX-1 in stomach mucosa
ex vivo much less effectively than in other tissues, the
pattern ?CHEBI*, UNIT, inhibit UNIPROT*? with
0.62 confidence score derives a correct pair <Parac-
etamol, COX-1>.
Generally speaking, simple patterns are more
likely to have lower confidence scores. However it
was also found that the pattern quality heavily de-
pends on the quality and reliability of the name en-
tity recognition (NE) system.
4 Conclusions and future work
We have presented a method of detecting small
molecule and protein pairs in MEDLINE abstracts.
It employs semi-supervised machine learning meth-
ods to enable patterns to be automatically generated,
rather than requiring human input. The approach can
be used for high throughput text mining applications
where manual curation is unrealistic.
The first and second iteration of results are
promising and show that the approach enables many
useful small molecule protein pairs to be extracted
from MEDLINE using just a small number of seed
pairs as input. The approach makes use of a rigor-
ous method of evaluating the quality of generated
patterns and extracted pairs. Manual inspection has
been used to validate these preliminary results and
has shown that approximately half of the discovered
pairs represent valid small molecule protein relation-
ships, and we expect to improve this significantly.
In future we will develop the method further
and analyse the results after further algorithm iter-
ations, enabling discovery of new patterns and con-
sequently new pairs of proteins and small molecules
that are currently undetected.
References
E. Agichtein and L. Gravano. 2000. Snowball: Ex-
tracting relations from large plain-text collections. In
Proceedings of the fifth ACM conference on Digital li-
braries, pages 85?94. ACM.
R. Apweiler, A. Bairoch, C.H. Wu, W.C. Barker,
B. Boeckmann, S. Ferro, E. Gasteiger, H. Huang,
R. Lopez, M. Magrane, et al 2004. UniProt: the uni-
versal protein knowledgebase. Nucleic acids research,
32(suppl 1):D115?D119.
P. De Matos, M. Ennis, M. Darsow, M. Guedj, K. Degt-
yarenko, and R. Apweiler. 2006. ChEBI-chemical en-
tities of biological interest. Nucleic Acids Research,
Database Summary: 646.
D. Jiao and D.J. Wild. 2009. Extraction of CYP chemi-
cal interactions from biomedical literature using natu-
ral language processing methods. Journal of chemical
information and modeling, 49(2):263?269.
E. Riloff and R. Jones. 1999. Learning dictionaries for
information extraction by multi-level bootstrapping.
In Proceedings of the National Conference on Artifi-
cial Intelligence, pages 474?479. John Wiley & Sons
Ltd.
M. Song, I.Y. Song, X. Hu, and H. Han. 2006. Infor-
mation extraction in biomedical literature. In J. Wang,
editor, Encyclopedia of Data Warehousing and Data
Mining, pages 615?620. Information Science Refer-
ence.
J.M. Temkin and M.R. Gilder. 2003. Extraction
of protein interaction information from unstructured
text using a context-free grammar. Bioinformatics,
19(16):2046?2053.
Y. Tsuruoka, Y. Tateishi, J.D. Kim, T. Ohta, J. McNaught,
S. Ananiadou, and J. Tsujii. 2005. Developing a ro-
bust part-of-speech tagger for biomedical text. Ad-
vances in informatics, pages 382?392.
175
