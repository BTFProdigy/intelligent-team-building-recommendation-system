Issues in Arabic Orthography and Morphology Analysis 
Tim BUCKWALTER 
Linguistic Data Consortium 
University of Pennsylvania 
Philadelphia, PA 19104 USA 
timbuck2@ldc.upenn.edu 
 
 
Abstract 
This paper discusses several issues in Arabic 
orthography that were encountered in the 
process of performing morphology analysis 
and POS tagging of 542,543 Arabic words in 
three newswire corpora at the LDC during 
2002-2004, by means of the Buckwalter 
Arabic Morphological Analyzer. The most 
important issues involved variation in the 
orthography of Modern Standard Arabic that 
called for specific changes to the Analyzer 
algorithm, and also a more rigorous definition 
of typographic errors. Some orthographic 
anomalies had a direct impact on word 
tokenization, which in turn affected the 
morphology analysis and assignment of POS 
tags. 
1 Introduction 
In 2002 the LDC began using output from the 
Buckwalter Arabic Morphological Analyzer 
(Buckwalter, 2002), in order to perform 
morphological annotation and POS tagging of 
Arabic newswire text. From 2002 to 2004 three 
corpora were analyzed and over half a million 
Arabic word tokens were annotated and tagged 
(see Table 1).1 
 
Corpus Arabic Word Tokens 
AFP 123,810 
Ummah 125,698 
Annahar 293,035 
Total 542,543 
Table 1: Arabic newswire corpora 
                                                     
1 The tagged AFP, Ummah, and Annahar corpora 
were published as ?Arabic Treebank: Part 1 v 2.0? 
(Maamouri 2003),  ?Arabic Treebank: Part 2 v 2.0? 
(Maamouri 2004), and ?Arabic Treebank: Part 3 v 1.0? 
(Maamouri 2004), respectively, and are available from 
the LDC website <http://www.ldc.upenn.edu >  
The author was responsible for developing and 
maintaining the Analyzer, which primarily 
involved filling in the gaps in the lexicon and 
modifying the POS tag set in order to meet the 
requirements of treebanking efforts that were 
performed subsequently at the LDC with the same 
annotated and POS-tagged newswire data. 
2 Lessons from the AFP corpus 
During the tagging of the AFP data, the first 
corpus in the series, the Buckwalter Analyzer was 
equipped to handle basic orthographic variation 
that often goes unnoticed because it is a common 
feature of written Arabic (Buckwalter, 1992). This 
orthographic variation involves the writing (or 
omission) of hamza above or below alif in stem-
initial position, and to a lesser extent, the writing 
(or omission) of madda on alif, also in stem-initial 
position. In both cases use of the bare alif without 
hamza or madda is quite common and goes by 
unnoticed by most readers. What took the LDC 
morphology annotation team by surprise was to 
find that in the AFP data the common omission of 
hamza in this environment had been extended to 
stem-medial and stem-final positions as well, as 
seen in the following words from that corpus: ????  
????  ??????   ???  ??????   ?????  ?????   ????? .  
This type of orthographic variation was not 
attested to the same extent in the two subsequent 
corpora, Ummah and Annahar, which leads us to 
conclude that some orthographic practices might 
be restricted to specific news agencies. It is 
important to note that most of the native Arabic 
speakers who annotated the AFP data using the 
output from the Analyzer did not regard these 
omissions of hamza on alif in stem-medial and 
stem-final positions as orthographic errors, and 
fully expected the Analyzer to provide a solution. 
3 Lessons from the Ummah corpus 
During the tagging of the Ummah data, a 
different set of orthographic issues arose. Although 
the Buckwalter Analyzer was equipped to handle 
so-called ?Egyptian? spelling (where word-final 
ya? is spelled without the two dots, making it 
identical to alif maqsura), the Ummah corpus 
presented the LDC annotation team with just the 
opposite phenomenon: dozens of word-final alif 
maqsura?s spelled with two dots.2  Whereas some 
of the affected words were automatically rejected 
as typographical errors (e.g., ???  ????  ??????  ?????  
???? ), others where gladly analyzed at face value 
(e.g., ???  ???  ??? ). Unfortunately, this led to 
numerous false positive analyses: for example ???  
was analyzed as ?ali and ?alayya, but not as ?ala. 
Initially, these words were tagged as typographical 
errors, but their pervasiveness led the LDC team to 
reconsider this position, upon which the author was 
asked to modify the Analyzer algorithm in order to 
accommodate this typographic anomaly. As a 
result, all words ending in ya? were now re-
interpreted as ending in either ya? or alif maqsura, 
and both forms were analyzed, as seen in the 
following (abridged) output:3 
 
<token_Arabic> ???
<variant>Ely
<solution>
<lemmaID>EalaY_1</lemmaID>
<pos>Ealay/PREP+ya/PRON_1S</pos>
<gloss>on/above + me</gloss>
</solution>
<solution>
<lemmaID>Ealiy~_1</lemmaID>
<voc>Ealiy~N</voc>
<pos>Ealiy~/ADJ+N/CASE_INDEF_NOM</pos>
<gloss>supreme/high + [indef.nom.]</gloss>
</solution>
<solution>
<lemmaID>Ealiy~_2</lemmaID>
<voc>Ealiy~N</voc>
<pos>Ealiy~/NOUN_PROP+N/CASE_INDEF_NOM</pos>
<gloss>Ali + [indef.nom.]</gloss>
</solution>
</variant>
<variant>ElY
<solution>
<lemmaID>EalaY_1</lemmaID>
<voc>EalaY</voc>
<pos>EalaY/PREP</pos>
<gloss>on/above</gloss>
</solution>
</variant>
</token_Arabic>
4 Lessons from all three corpora 
The Annahar corpus presented no orthographic 
surprises, or at least nothing that the LDC 
annotation team had not seen before. The Annahar 
data did contain some additional orthographic 
                                                     
2 It is not entirely clear whether these ?dotted? alif 
maqsura?s were produced by human typists or by an 
encoding conversion process gone awry. It is possible 
that the original keyboarding was done on a platform 
where word-final ya? and alif maqsura are displayed via 
visually identical ?un-dotted? glyphs, so it makes no 
difference which of the two keys the typist presses on 
the keyboard: both produce the same visual display, but 
are stored electronically as two different characters. 
3 A key to the transliteration scheme used by the 
Analyzer can be found at <http://www.ldc.upenn.edu/ 
myl/morph/buckwalter.html> 
features that we now identify as being common to 
all three corpora, as well as corpora outside the set 
we have annotated at the LDC.  
The first orthographic feature relates to the 
somewhat free interchange of stem-initial hamza 
above alif and hamza below alif. With some lexical 
items the orthographic variation simply reflects 
variation in pronunciation: for example, both 
?isbaniya (with hamza under alif) and ?asbaniya 
(with hamza above alif) are well attested. But in 
cases involving other orthographic pairs, more 
interpretations are possible. Take, for instance, 
what we called the ?qala ?anna? problem. This 
problem was identified after numerous encounters 
with constructions in which qala was followed by 
?anna rather than ?inna, and for no apparent 
linguistic reason. Initially this was treated as a 
typographical error, but again, its pervasiveness 
forced us to take a different approach.  
One solution we considered was to modify the 
Analyzer algorithm so that instances of stem-initial 
hamza on alif would also be treated as possible 
instances of hamza under alif, very much in the 
spirit of the approach we used for dealing with the 
alif maqsura / ya? free variation cited earlier. 
However, there is compelling evidence that the 
orthography of hamza in stem-initial position is a 
fairly reliable indication of the perceived value of 
subsequent short vowel: a or u for hamza above 
alif, and i for hamza below alif. In other words, 
there is no free variation. The decision was taken 
to regard ?qala ?anna? constructions as gram-
matically acceptable in MSA.4 
5 Concatenation in Arabic orthography 
The second, and more serious, orthographic 
anomaly we encountered in all three corpora is 
what we call the problem of Arabic ?run-on? 
words, or free concatenation of words when the 
word immediately preceding ends with a non-
connector letter, such as alif, dal, dhal, ra, za, 
waw, ta marbuta, etc.  
The most frequent ?run-on? words in Arabic are 
combinations of the high-frequency function words 
la and ma (which end in alif) with following 
perfect or imperfect verbs, such as la-yazal, ma-
yuram, and ma-zala ( ??????  ??????  ????? ). The la of 
?absolute negation? concatenates freely with 
nouns, as in la-budda, la-shakka ( ????  ???? ). It can 
be argued that these are lexicalized collocations, 
but their spelling with intervening space ( ????  ?? ? 
                                                     
4 Badawi, Carter and Gully regard ?qala ?anna? 
constructions as grammatical but restricted to contexts 
?where the exact words of the speaker are not used or 
reported? (Badawi, Carter and Gully 2004, p. 713). This 
assertion could be investigated in the LDC corpora. 
???  ??   ? ??  ??) is just as frequent as their spelling in 
concatenated form. 
Proper name phrases, especially those involving 
the word ?abd ( ????????  ????????? ) are also written 
either separately or in concatenated form. Part of 
the data annotation process at the LDC involves 
assigning case endings to tokenized words, but 
there is currently no mechanism in the Analyzer to 
assign two case endings (or several pairs of POS 
tags) to what is being processed as a single word 
token. As a result of this, the phrase ?abd allah is 
assigned a single POS tag and case ending when it 
is written in concatenated form, but two POS tags 
and two case endings when written with 
intervening space. 
The problem of assigning more than one case 
ending and POS tag to concatenations is more 
obvious in fully lexicalized concatenations such as 
khamsumi?atin, sittumi?atin, sab?umi?atin, etc 
( ???????  ? ??????  ? ??????? ). When these numbers are 
written with intervening space ( ????  ???  ? ????  ??  ? 
????  ??? ), two case endings and two POS tags are 
assigned by the Analyzer. But when they are 
written in concatenated form only one case ending 
and POS tag is assigned, and the ?infixed? case 
ending of the first token is left undefined: 
khamsmi?atin, sittmi?atin, sab?mi?atin, etc. 5 
So far we have discussed relatively controlled 
concatenation, involving mostly high-frequency 
function words and lexicalized phrases. But 
concatenation extends beyond that to random 
combinations of words?the only requirement 
being that the word immediately preceding end 
with a non-connector letter. These concatenations 
are fairly frequent, as attested by their Google 
scores (see Table 2).  
It is important to note that these concatenations 
are not immediately obvious to readers due to the 
characteristics of proportionally spaced Arabic 
fonts. Most of the native readers of Arabic at the 
LDC did not consider concatenations such as these 
to be typographical errors. Their logic was best 
expressed in the statement: ?I can read the text just 
fine. Why can?t the Morphological Analyzer?? 
 
                                                     
5 We regard these as ?fully lexicalized? 
concatenations because the first of the two constituent 
tokens ends in a connector letter. In other word, their 
concatenation is deliberate and not an accident of 
orthography. 
Concatenation Google 
Frequency 
???????  846 
????????????  719 
??????????  162 
???????????  158 
???????  138 
?????  130 
????????  99 
?????  77 
???????  54 
Table 2: Arabic Concatenations and their Google 
Frequencies (sample taken March 25,2004) 
6 Conclusion 
There are several levels of orthographic variation 
in Arabic, and each level calls for a specific 
response to resolve the orthographic anomaly. It is 
important that the output analysis record which 
method was used to resolve the anomaly. The 
methods used for resolving orthographic anomaly 
range from exact matching of the surface 
orthography to various strategies of orthography 
manipulation. Each manipulation strategy carries 
with it certain assumptions about the text, and 
these assumptions should be part of the output 
analysis. For example, an analysis of ???  obtained 
by exact matching in a text known to contain 
suspicious word-final ya?s (that may be alif 
maqsura?s) does not have the same value as an 
analysis of the same word, using the same exact 
matching, but in a text where word-final ya?s and 
alif maqsura?s display normal character 
distribution frequencies. 
The problem of run-on words in Arabic calls for 
a reassessment of current tokenization strategies, 
including the definition of ?word token? itself. 6 It 
should be assumed that each input string represents 
one or more potential word tokens, each of which 
needs to be submitted individually for morphology 
analysis. For example, the input string ?????  can be 
segmented as a single word token, yielding two 
morphological analyses (faqad-tum and fa-qud-
tum) or it can be segmented as two word tokens 
(fqd tm), yielding several possible analysis pairs 
(faqada / fuqida / faqd / fa-qad +  tamma). 
                                                     
6 By ?tokenization? we mean the identification of 
orthographically valid character string units that can be 
submitted to the Analyzer for analysis. The Analyzer 
itself performs a different kind of ?tokenization? by 
identifying prefixes and suffixes that are bound 
morphemes but which may be treated as ?word tokens? 
in syntactic analysis. 
Syntactic analysis would be needed for 
determining which morphology analysis is most 
likely the correct one for each tokenization (fqdtm 
and fqd tm). 
7 Acknowledgements 
Our thanks go to the Arabic annotation team at 
the LDC, especially the team of native speaker 
informants that provided the author with daily 
feedback on the performance of the Morphological 
Analyzer, especially in areas which led to a 
reassessment and better understanding of 
orthographic variation, as well as tokenization and 
functional definitions of typographical errors. 
References  
Elsaid Badawi, M.G. Carter, and Adrian Wallace. 
2004. Modern Written Arabic: A Comprehensive 
Grammar. Routledge, London. 
Tim Buckwalter. 1992. ?Orthographic Variation in 
Arabic and its Relevance to Automatic Spell-
Checking,? in Proceedings of the Third 
International Conference on Multilingual 
Computing (Arabic and Roman Script), 
University of Durham, U.K., December 10-12, 
1992. 
Tim Buckwalter. 2002. Buckwalter Arabic 
Morphological Analyzer Version 1.0. Linguistic 
Data Consortium, catalog number LDC2002L49 
and ISBN 1-58563-257-0. < http://www.ldc. 
upenn.edu/Catalog/CatalogEntry.jsp?catalogId=
LDC2002L49 > 
Mohamed Maamouri, et al 2003. Arabic 
Treebank: Part 1 v 2.0. Linguistic Data 
Consortium, catalog number LDC2003T06 and 
ISBN:  1-58563-261-9. < http://www.ldc.upenn.-
edu/Catalog/CatalogEntry.jsp?catalogId= 
LDC2003T06 > 
Mohamed Maamouri, et al 2004. Arabic 
Treebank: Part 2 v 2.0. Linguistic Data 
Consortium, catalog number LDC2004T02 and 
ISBN:  1-58563-282-1. < http://www.ldc.upenn.-
edu/Catalog/CatalogEntry.jsp?catalogId= 
LDC2004T02 > 
Mohamed Maamouri, et al 2004. Arabic 
Treebank: Part 3 v 1.0. Linguistic Data 
Consortium, catalog number LDC2004T11 and 
ISBN:  1-58563-298-8. < http://www.ldc.upenn.-
edu/Catalog/CatalogEntry.jsp?catalogId= 
LDC2004T11 > 
 
Proceedings of the Ninth Workshop on Innovative Use of NLP for Building Educational Applications , pages 109?115,
Baltimore, Maryland USA, June 26, 2014. c?2014 Association for Computational Linguistics
ArCADE: An Arabic Corpus of Auditory Dictation Errors
C. Anton Rytting
Paul Rodrigues
Tim Buckwalter
Valerie Novak
Aric Bills
University of Maryland
7005 52nd Avenue
College Park, MD 20742
{crytting,prr,tbuckwal,
vnovak,abills}@umd.edu
Noah H. Silbert
Communication
Sciences & Disorders
University of Cincinnati
2600 Clifton Avenue
Cincinnati, Ohio
silbernh
@ucmail.uc.edu
Mohini Madgavkar
Independent Researcher
6120 Dhaka Pl. 20189-6120
Dhaka, Bangladesh
mohini.madgavkar
@gmail.com
Abstract
We present a new corpus of word-level lis-
tening errors collected from 62 native En-
glish speakers learning Arabic designed to
inform models of spell checking for this
learner population. While we use the cor-
pus to assist in automated detection and
correction of auditory errors in electronic
dictionary lookup, the corpus can also be
used as a phonological error layer, to be
combined with a composition error layer
in a more complex spell-checking system
for non-native speakers. The corpus may
be useful to instructors of Arabic as a sec-
ond language, and researchers who study
second language phonology and listening
perception.
1 Introduction
Learner corpora have received attention as an im-
portant resource both for guiding teachers in cur-
riculum development (Nesselhauf, 2004) and for
providing training and evaluation material the de-
velopment of tools for computer-assisted language
learning (CALL). One of the most commonly used
technologies in CALL is spell correction. Spell
correction is used for providing automated feed-
back to language learners (cf. Warschauer and
Ware, 2006), automatic assessment (Bestgen and
Granger, 2011), and in providing cleaner input
to downstream natural language processing (NLP)
tools, thereby improving their performance (e.g.
Nagata et al., 2011). However, off-the-shelf spell
correctors developed for native speakers of the tar-
get language are of only limited use for repairing
language learners? spelling errors, since their error
patterns are different (e.g. Hovermale, 2011; Mit-
ton and Okada, 2007; Okada, 2005).
Most learner corpora (and spell correctors) are
understandably focused on learner-written texts.
Thus, they allow a greater understanding (and im-
provement) of learners? writing skills. However,
another important aspect of language learning is
listening comprehension (cf. Field, 2008; Prince,
2012). A better understanding of listening errors
can guide teachers and curriculum development
just as written production errors do. Listening er-
ror data may also be helpful for improving tech-
nologies for listening training tools, by helping
prioritize the most critical pairs of phonemes for
discrimination, and pointing out the most trouble-
some contexts for phoneme discrimination.
Finally, spell correction specifically designed
to correct listening errors may aid listening com-
prehension and vocabulary acquisition. If learn-
ers are unable to hear, recall and record accu-
rately what they heard, they will be less able to
search dictionaries or the Web for more informa-
tion on new vocabulary items they otherwise could
have learned from listening exercises. While data-
driven spelling correction on popular search en-
gines may catch some non-native errors, native er-
rors are likely to ?drown out? any non-native errors
they conflict with due to larger numbers of native
users of these search engines. On the other hand, if
themost common listening and transcription errors
are automatically corrected within a search tool,
learners will have greater success in finding the
new vocabulary items they may have misheard in
speech.
Learner corpora focused on written production
may not have enough samples of phonologically-
based errors to aid in developing such tools, and
109
even in a large corpus, word avoidance strategies
and other biases would make the source unreli-
able for estimating relative magnitudes of listening
problems accurately. It may be more effective to
target listening errors directly, through other tasks
such as listening dictation.
2 Related Work
Tools for language learning and maintenance, and
learner corpora fromwhich to build them, typically
focus on language pairs for which there is a large
market. Learner corpora for native English learn-
ers of low resource languages such as Arabic have
been until recently comparatively rare, and often
too small to be of practical use for the develop-
ment of educational technology. In the past few
years, however, a number of learner corpora for
Arabic have become available, including a corpus
of 19 non-native (mostlyMalaysian) students at Al
Al-Bayt University (Abu al-Rub, 2007); the Ara-
bic InterlanguageDatabase (ARIDA;Abuhakema
et al., 2008, 2009); the Arabic Learners Writ-
ten Corpus from the University of Arizona Center
for Educational Resources in Culture, Language,
and Literacy (CERCLL; Farwaneh and Tamimi,
2012);1 and the Arabic Learner Corpus v1 (Alfaifi
and Atwell, 2013).2
These corpora are all derived from learner writ-
ing samples, such as essays, and as such they con-
tainmany different types of errors, including errors
in morphology, syntax, and word choice. Spelling
errors are also observed, but relatively rarely, and
the relevance of these spelling errors to listening
competence is unclear. Hence, while they are
likely to be useful for many applications in teach-
ing Arabic writing, their usefulness for other pur-
poses, such as examining listening skills and the
effects of learner phonology on spelling, is limited.
Corpora or datasets focused on speaking and lis-
tening skills in Arabic are rarer. One such corpus,
the West Point Arabic Speech Corpus, available
from the LDC, contains one hour of non-native
(learner) speech (LaRocca and Chouairi, 2002)
Sethy et al. (2005) describe a corpus of elicited
Arabic speech, but because none of the partici-
pants had prior exposure to Arabic, its use for un-
1Available from http://l2arabiccorpus.cercll.
arizona.edu/?q=homepage.
2As of February 2014, a second version, with about 130K
words from non-native speakers, is available from http:
//www.arabiclearnercorpus.com/. It also has a small
(three hour) speech component.
derstanding learner Arabic is limited. While there
have been a few studies of Arabic listening skills
(e.g. Huthaily, 2008; Faircloth, 2013), their cov-
erage was not sufficiently broad to make reuse of
their data likely to inform such purposes as the de-
velopment of phoneme discrimination training or
other CALL technology.
3 Motivation
We present here the Arabic Corpus of Auditory
Dictation Errors (ArCADE) version 1, a corpus
of Arabic words as transcribed by 62 native En-
glish speakers learning Arabic. This corpus fills
the current gap in non-native spelling error cor-
pora, and particularly for spelling errors due to lis-
tening difficulties. Unlike error corpora collected
from non-native Arabic writing samples, it is de-
signed to elicit spelling errors arising from percep-
tual errors; it provides more naturalistic data than
is typical in phoneme identification or confusion
studies.
A principal purpose for creating the corpus was
to aid in the development and evaluation of tools
for detecting and correcting listening errors to aid
in dictionary lookup of words learners encountered
in spoken language (cf. Rytting et al., 2010). As
such, it serves as a complementary dataset for the
dictionary search engine?s query logs, since in this
case the intended target of each transcription is
known (rather than having to be inferred, in the
case of query logs). We list three other potential
uses for this corpus in Section 5.
4 Corpus Design and Creation
The ArCADE corpus was created through an
elicitation experiment, similar in structure to an
American-style spelling test. The principal differ-
ence (other than the language) is that in this case,
the participants are expected to be unfamiliar with
thewords, and thus forced to rely onwhat they hear
in the moment, rather than their lexical knowledge.
We selected words from a commonly-used dictio-
nary of Modern Standard Arabic such that the set
of words would contain a complete set of non-glide
consonants in various phonetic contexts.
4.1 Selection of Stimulus Words
Since the corpus was originally collected for a
study focused on the perception of consonants
within the context of real Arabic words, the stim-
ulus set was designed with three purposes in
110
mind: coverage of target sounds, exclusion of ba-
sic words, and brevity (so that participants could
complete the task in one sitting).
In order to differentiate consonants that are rela-
tively unpredictable (and thus test listening ability)
from consonants whose value could be predicted
from non-acoustic cues (such as prior knowledge
of morphological structure), the corpus is anno-
tated for target consonants vs. non-target conso-
nants. A target consonant is defined as a consonant
that should not be predictable (assuming the word
is unknown to the listener) except by the acoustic
cues alone. Glides /w/ and /j/ were not targeted
in the study because orthographic ambiguities be-
tween glides and vowels would complicate the er-
ror analysis.
Each Arabic consonant other than the glides oc-
curs as a target consonant in the stimulus set in six
consonant/vowel/word-boundary contexts: C_V,
V_C, V_V, #_V, V_#, and C_#.3 (The contexts
#_C and C_C are phonotactically illegal in Mod-
ern Standard Arabic.)
Consonants that were judged morphologically
predictable within a word were considered non-
target consonants. These included: (1) non-root
consonants, when Semitic roots were known to the
researchers; (2) consonants participating in a redu-
plicative pattern such as /tamtam/ and /zalzala/;
and (3) Consonants found in doubled (R2=R3)
roots if the two consonants surfaced separately
(e.g., in broken plurals such as /?asnan/).
We excluded words from our stimulus set if
we anticipated that an intermediate Arabic student
would already be familiar with them or would eas-
ily be able to guess their spellings. Items found
in vocabulary lists associated with two commonly-
used introductory textbooks (Al-Kitaab and Alif-
Baa) were excluded (Brustad et al., 2004a,b).
Loanwords from Western languages were also ex-
cluded, as were well-known place names (e.g.,
/?iskotlanda/ = ?Scotland?). Words found only in
colloquial dialects and terms that might be offen-
sive or otherwise distracting (as judged by native
speaker of Arabic) were removed, as well.
In order to keep the stimulus set as short as pos-
sible while maintaining coverage of the full set of
target stimuli consonants in each targeted context,
we chose words with multiple target consonants
whenever possible. The final set of 261words con-
3C = consonant, V = vowel, # = word boundary, and ?_?
(underscore) = location of target consonant.
tained 649 instances of target consonants: one in-
stance of each geminate consonant and between 17
and 50 instances of each singleton consonant (at
least two instances for each of the six contexts),
with a few exceptions.4 Although glides and vow-
els were not specifically targeted, 6 instances of
/w/, 10 instances of /j/, and at least 12 instances of
each of the monophthong vowels (/a/, /i/, /u/, /a:/,
/i:/, /u:/) occur in the stimulus set.
4.2 Recording of the Stimuli
The audio data used in the dictation was recorded
in a sound-proof boothwith a unidirectionalmicro-
phone (Earthworks SR30/HC) equippedwith a pop
filter, and saved as WAV files (stereo, 44.1kHz,
32-bit) with Adobe Audition. The stimuli were
spoken at a medium-fast rate. The audio files were
segmented and normalized with respect to peak
amplitude with Matlab.
The nativeArabic speaker in the audio recording
is of Egyptian and Levantine background, but was
instructed to speak with a neutral (?BBC Arabic?)
accent.
4.3 Participants and Methodology
Seventy-five participants were recruited from six
universities. To be eligible, participants had to be
18 years of age or older, native speakers of En-
glish, and have no known history of speech lan-
guage pathology or hearing loss. Participants were
required to have completed at least two semesters
of university level Arabic courses in order to en-
sure that they were able to correctly write the Ara-
bic characters and to transcribe Arabic speech.
Heritage speakers of Arabic and non-English dom-
inant bilinguals were excluded from the study. The
corpus contains responses from 62 participants.
The mean duration of Arabic study completed was
5.6 semesters (median 4).
Before beginning the experiment, participants
were asked to fill out a biographical questionnaire.
This included questions about language exposure
during childhood and languages studied in a class-
room setting. There were additional questions
about time spent outside of the United States to
ascertain possible exposure to languages not ad-
dressed in previous questions.
4These exceptions include only one instance of a phone
rather than two for the following contexts: (1) /h/ in the con-
text C_#, (2) /f/ in the context V_#, and (3) /z/ in the context
#_V. One geminate consonant, /x:/, was inadvertently omitted
from the stimulus set.
111
Participants wrote their responses to the 261
stimulus words on a response sheet that contained
numbered boxes. They were asked to use Arabic
orthography with full diacritics and short vowels
(fatha, damma, kasra, shadda and sukun). The
shadda (gemination) mark was required in order
to analyze the participants? perception of geminate
consonants; the other diacritics were included so as
to not single out shadda for special attention (since
participants were na?ve to the purpose of the study)
and also to increase the value of the resulting error
corpus for later analysis of short vowels.
4.4 Presentation of the Stumuli
The proctors who ran the experiment supplied an
iPod Touch tablet to each participant, pre-loaded
with a custom stimuli presentation application.
In this custom iPod application, 261 Arabic
words were randomized into 9 stimulus sets. Each
stimulus set was preceded by four practice items
which were not scored; thus each participant saw
265 items. Each touch screen tablet was initialized
by the testers to deliver a specific stimulus set. A
button on the touch screen allowed the participants
to begin the experiment. After a few seconds? de-
lay, the first word was played. A stimulus num-
ber identifying the word appeared in a large font
to aid the participants in recording the word on pa-
per. Participants were given 15 seconds to write
their response, before the tablet automatically ad-
vanced to the next word. Participants were not able
to replay a word.
The participants used noise-canceling head-
phones (Audio-Technica ATH-ANC7 or ATH-
ANC7B) for listening to the audio stimuli. The
experiment was performed in a quiet classroom.
4.5 Data Coding
The participants? handwritten responses were
typed in as they were written, using Arabic Uni-
code characters. Any diacritics (short vowels or
gemination) written by the participants were pre-
served. An automatic post-process was used to en-
sure that the gemination mark was ordered prop-
erly with respect to an adjacent short vowel mark.
The corpus consists of twomain sections: ortho-
graphic and phonemic. The orthographic section is
very simple: each stimulus word is given in its tar-
get orthography (with diacritics) and in each par-
ticipant?s corresponding orthographic transcrip-
tion (including diacritics if the participant provided
them as instructed). The phonemic section is more
elaborate, containing additional fields designed for
a phone level analysis of target consonants. Its
construction is described in further detail below.
Both the orthographic response and the canon-
ical (reference) spelling were automatically con-
verted to a phonemic representation. This conver-
sion normalizes certain orthographic distinctions,
such as various spellings for word-final vowels.
This phonemic representation of the response for
each stimulus item was then compared with the
phonemic representation of the item?s canonical
pronunciation, and each phoneme of the response
was aligned automatically with the most probable
phoneme (or set of equally plausible phonemes)
in the canonical phonemic representation of the
auditory stimulus. This alignment was done via
dynamic programming with a weighted Leven-
shtein edit distance metric. Specifically, weights
were used to favor the alignment of vowels and
glides with each other rather than with non-glide
consonants (since the scope of our original study
was non-glide consonants). Thus substitutions be-
tween short vowels, long vowels, and glides are
given preference over other confusions. This is in-
tended to reduce the ambiguity of the alignments
and to ensure that non-glide consonants are aligned
with non-glide consonants when possible, without
introducing any bias in the non-glide consonants
alignments. When one unique alignment had the
lowest cost, it was used as the alignment for that
item. In some cases, multiple alignments were tied
for minimal cost. In this case, all alignments were
used and assigned equal probability.
Once the least-cost alignment(s) were found be-
tween a response string and the reference string for
an item, the target consonants within the reference
string were then each paired with the correspond-
ing phonemes in the response, and an error cate-
gory (<substitution>, <deletion>, or <match> for
no error) was assigned. In the case of geminate
phonemes, two subtypes of <substitution>were in-
troduced: <gemination> and <degemination>.
Where an entire word had no response, ?NA?
was used to indicate that no edit operation can be
assigned. (A total of 112 items were missing).
Note that insertions were not marked, because
only the 649 instances of target consonants were
analyzed for the phonemic portion of the corpus,
and no other material in each stimulus word (in-
cluding any possible insertion points for additional
material) were annotated for errors. Insertions can
112
be recovered from the orthographic portion of the
corpus.
The coding method described above yielded a
set of 41,121 target consonant records of partici-
pants? responses to target consonants (not count-
ing the 112 non-response items), including 29,634
matches (72.1%) and 11,487 errors (27.9%). At
the word level, there are 16,217 words, of which
8321 (48.2%) contain at least one error in a tar-
geted consonant, and 5969 (37.1%) are spelled
perfectly (excluding diacritics).
5 Potential Uses of the Corpus
In addition to the uses described in Section  3, we
believe the data could be used for several other
uses, such as examining linguistic correlates of
proficiency, developing phonemic training, and in-
vestigating non-native Arabic handwriting.
One potential use of the corpus is to analyze the
errors by individual learners to determine which
sounds are confused only by relatively beginning
learners (after two semesters) and which are con-
fused by beginning and experienced learners alike.
While hard measures of proficiency are not avail-
able for the participants, the language question-
naire includes time of study and self-report mea-
sures of proficiency. To the extent to which these
proxies are reliable, the corpus may lead to the de-
velopment of hypotheses which can be tested in
more targeted studies.
Since the corpus allows quantitative evidence
for the relative difficulty of particular sound pairs
in particular contexts, it may guide the prioritiza-
tion of foci for phonemic discrimination training
and other listening exercises. At the most basic
level, a teacher can take our original audio stimuli
and use them as dictation exercises for beginning
students (who may not be ready for sentence or
paragraph level dictation). It may also form the ba-
sis for automated phonemic discrimination train-
ing, such as Michael et al. (2013). Cf. Bradlow
(2008) for a review.
Since the participants handwrote their re-
sponses, the corpus contains, as a byproduct, a
set of 16,329 words in non-native handwriting and
their digital transcriptions. As Alfaifi and Atwell
(2013) note, this could be used as a corpus of non-
native handwriting for training or evaluating OCR
on L2 Arabic script. If corresponding native tran-
scriptions of the same (or similar) strings were ob-
tained, the corpus could also be used to differenti-
ate native from non-native handwriting (cf. Farooq
et al., 2006; Ramaiah et al., 2013).
6 Limitations and future work
The corpus as it currently stands has some limita-
tions worth noting. First, there is no control set
of native Arabic listeners to provide a comparison
point for distinguishing non-native perceptual er-
rors from acoustic errors that even native speakers
are subject to. Second, the survey does not con-
tain proficiency ratings (except self-report) for the
participants, making direct correlation of particu-
lar confusion patterns with proficiency level more
difficult.
Statistical analysis of the participants? accuracy
at distinguishing Arabic consonants is currently
underway (Silbert et al., in preparation). An inves-
tigation of the utility of the corpus for training and
evaluating spelling correction for L1 English late
learners of Arabic, including the effects of training
corpus size on accuracy, is also in progress.
7 Conclusion
The Arabic Corpus of Auditory Dictation Errors
(ArCADE) version 1 provides a corpus of word-
level transcriptions of Arabic speech by native En-
glish speakers learning Arabic, ideal for the anal-
ysis of within-word listening errors, as well as the
development and evaluation of NLP tools that seek
to aid either in developing listening skill or in com-
pensating for typical non-native deficits in listen-
ing. Since most learner corpora only include writ-
ten composition or spoken production from stu-
dents, this corpus fills a gap in the resources avail-
able for the study of Arabic as a second language.
The corpus, along with the original audio
stimuli and participants? handwriting samples,
is available at http://www.casl.umd.edu/
datasets/cade/arcade/index.html.
Acknowledgments
This material is based on work supported, in whole
or in part, with funding from the United States
Government. Any opinions, findings, and conclu-
sions or recommendations expressed in this mate-
rial are those of the authors and do not necessarily
reflect the views of the University of Maryland,
College Park and/or any agency or entity of the
United States Government.
113
References
Muhammad Abu al-Rub. 2007. ???????? ??????? ?????
.?????? ???????? ??????? ????? ?????? ??? ??????? ?????? ???
Tahl??l al-akht??? al-kit?b?yah ?ala mustaw?
al-iml?? lad? muta?allim? al-lughah al-?arab?yah
al-n?ti?q?na bi-ghayrih? [Analysis of written
spelling errors among non-native speak-
ing learners of Arabic]. ????????? ?????? ???????
.??????????? Dir?s?t, al-?Ul?m al-Ins?n?yah wa-al-
Ijtim???yah [Humanities and Social Sciences],
34(2). http://journals.ju.edu.jo/
DirasatHum/article/view/1911/1898.
Ghazi Abuhakema, Anna Feldman, and Eileen
Fitzpatrick. 2008. Annotating an Arabic learner
corpus for error. In Proceedings of the Interna-
tional Conference on Language Resources and
Evaluation (LREC 2008). Marrakech, Morocco.
Ghazi Abuhakema, Anna Feldman, and Eileen
Fitzpatrick. 2009. ARIDA: An Arabic inter-
language database and its applications: A pilot
study. Journal of the National Council of Less
Commonly Taught Languages (NCOLCTL),
7:161?184.
Abdullah Alfaifi and Eric Atwell. 2013. Potential
uses of the Arabic Learner Corpus. In Leeds
Language, Linguistics, and Translation PGR
Conference 2013. University of Leeds, Leeds,
UK.
Yves Bestgen and Sylvaine Granger. 2011. Cat-
egorising spelling errors to assess L2 writ-
ing. International Journal of Continuing En-
gineering Education and Life-Long Learning,
21(2/3):235?252.
Ann Bradlow. 2008. Training non-native language
sound patterns. In Phonology and Second Lan-
guage Acquisition, Benjamins, Amsterdam and
Philadelphia, pages 287?308.
Kristin Brustad, Mahmoud Al-Batal, and Abbas
Al-Tonsi. 2004a. Al-Kitaab fii Ta?allum al-
?Arabiyya, volume 1. Georgetown University
Press, Washington, DC, 1st edition.
Kristin Brustad, Mahmoud Al-Batal, and Abbas
Al-Tonsi. 2004b. Alif Baa: Introduction to Ara-
bic Letters and Sounds. Georgetown University
Press, Washington, DC, 2nd edition.
Laura Rose Faircloth. 2013. The L2 Perception
of Phonemic Distinctions in Arabic by English
Speakers. BA Thesis, The College of William
and Mary. https://digitalarchive.wm.
edu/bitstream/handle/10288/18160/
FairclothLauraRose2013Thesis.pdf?
sequence=1.
Faisal Farooq, Liana Lorigo, and Venu Govin-
daraju. 2006. On the accent in handwrit-
ing of individuals. In Tenth Interna-
tional Workshop on Frontiers in Hand-
writing Recognition. La Baule, France.
http://hal.inria.fr/docs/00/11/26/
30/PDF/cr103741695994.pdf.
Samira Farwaneh and Mohammed Tamimi. 2012.
Arabic learners written corpus: A resource for
research and learning. Available from the
University of Arizona Center for Educational
Resources in Culture, Language, and Literacy
web site. http://l2arabiccorpus.cercll.
arizona.edu/?q=homepage.
John Field. 2008. Listening in the Language Class-
room. Cambridge University Press, Cambridge,
UK.
DJ Hovermale. 2011. Erron: A Phrase-Based
Machine Traslation Approach to Customized
Spelling Correction. Ph.D. thesis, The Ohio
State University.
Khaled Yahya Huthaily. 2008. Second Lan-
guage Instruction with Phonological Knowl-
edge: Teaching Arabic to Speakers of English.
Ph.D. thesis, The University of Montana.
Col. Stephen A. LaRocca and Rajaa Chouairi.
2002. West Point Arabic speech corpus. Tech-
nical report, LDC, Philadelphia.
Erica B. Michael, Greg Colflesh, Valerie Karuzis,
Michael Key, Svetlana Cook, Noah H. Silbert,
Christopher Green, Evelyn Browne, C. Anton
Rytting, Eric Pelzl, and Michael Bunting. 2013.
Perceptual training for second language speech
perception: Validation study to assess the ef-
ficacy of a new training regimen (TTO 2013).
Technical report, University of Maryland Cen-
ter for Advanced Study of Language, College
Park, MD.
RogerMitton and Takeshi Okada. 2007. The adap-
tation of an English spellchecker for Japanese
writers. Birbeck ePrints, London. http://
eprints.bbk.ac.uk/archive/00000592.
Ryo Nagata, Edward Whittaker, and Vera Shein-
man. 2011. Creating a manually error-tagged
and shallow-parsed learner corpus. In Proceed-
ings of the 49th Annual Meeting of the Asso-
114
ciation for Computational Linguistics. Associ-
ation for Computational Linguistics, Portland,
OR, pages 1210?1219.
Nadja Nesselhauf. 2004. Learner corpora and their
potential in language teaching. In How to Use
Corpora in Language Teaching, Benjamins,
Amsterdam and Philadelphia, pages 125?152.
Takeshi Okada. 2005. Spelling errors made by
Japanese EFL writers: with reference to errors
occurring at the word-initial and word-final po-
sitions. In Vivian Cook and Benedetta Bassetti,
editors, Second language writing systems, Mul-
tilingual Matters, Clevedon, UK, pages 164?
183.
Peter Prince. 2012. Writing it down: Issues re-
lating to the use of restitution tasks in listening
comprehension. TESOL Journal, 3(1):65?86.
Chetan Ramaiah, Arti Shivram, and Venu
Govindaraju. 2013. A Baysian framework
for modeling accents in handwriting. In
12th International Conference on Docu-
ment Analysis and Recognition (ICDAR).
http://ieeexplore.ieee.org/xpls/abs_
all.jsp?arnumber=6628752.
C. Anton Rytting, Paul Rodrigues, Tim Buckwal-
ter, DavidM. Zajic, Bridget Hirsch, Jeff Carnes,
Nathanael Lynn, Sarah Wayland, Chris Taylor,
Jason White, Charles Blake, Evelyn Browne,
Corey Miller, and Tristan Purvis. 2010. Error
correction for Arabic dictionary lookup. In Sev-
enth International Conference on Language Re-
sources and Evaluation (LREC 2010). Valletta,
Malta.
Abhinav Sethy, Shrikanth Narayanan, Nicolaus
Mote, and W. Lewis Johnson. 2005. Modeling
and automating detection of errors inArabic lan-
guage learner speech. In INTERSPEECH-2005.
pages 177?180.
Noah H. Silbert, C. Anton Rytting, Paul Ro-
drigues, Tim Buckwalter, Valerie Novak, Mo-
hiniMadgavkar, Katharine Burk, andAric Bills.
in preparation. Similarity and bias in non-native
Arabic consonant perception.
Mark Warschauer and Paige Ware. 2006. Auto-
mated writing evaluation: Defining the class-
room research agenda. Language Teaching Re-
search, 10(2):157?180.
115
