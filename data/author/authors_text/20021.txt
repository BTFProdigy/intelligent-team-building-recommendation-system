Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: System Demonstrations,
pages 67?70, Dublin, Ireland, August 23-29 2014.
 A Sentence Judgment System for Grammatical Error Detection 
 
Lung-Hao Lee 1,2, Liang-Chih Yu3,4, Kuei-Ching Lee1,2,  
Yuen-Hsien Tseng1, Li-Ping Chang5, Hsin-Hsi Chen2 
1Information Technology Center, National Taiwan Normal University 
2Dept. of Computer Science and Information Engineering, National Taiwan University 
3Dept. of Information Management, Yuen Ze University 
4Innovation Center for Big Data and Digital Convergence, Yuen Ze University 
5Mandarin Training Center, National Taiwan Normal University 
lcyu@saturn.yzu.edu.tw, {lhlee, johnlee, lchang, 
samtseng}@ntnu.edu.tw, hhchen@ntu.edu.tw 
  
 
Abstract 
This study develops a sentence judgment system using both rule-based and n-gram statistical 
methods to detect grammatical errors in Chinese sentences. The rule-based method provides 
142 rules developed by linguistic experts to identify potential rule violations in input sentences. 
The n-gram statistical method relies on the n-gram scores of both correct and incorrect training 
sentences to determine the correctness of the input sentences, providing learners with im-
proved understanding of linguistic rules and n-gram frequencies. 
1 Introduction 
China?s growing global influence has prompted a surge of interest in learning Chinese as a foreign 
language (CFL), and this trend is expected to continue. This has driven an increase in demand for au-
tomated IT-based tools designed to assist CFL learners in mastering the language, including so-called 
MOOCs (Massive Open Online Courses) which allows huge numbers of learners to simultaneously 
access instructional opportunities and resources. This, in turn, has driven demand for automatic proof-
reading techniques to help instructors review and respond to the large volume of assignments and tests 
submitted by enrolled learners. 
However, whereas many computer-assisted learning tools have been developed for use by students 
of English as a Foreign Language (EFL), support for CFL learners is relatively sparse, especially in 
terms of tools designed to automatically detect and correct Chinese grammatical errors. For example, 
while Microsoft Word has integrated robust English spelling and grammar checking functions for 
years, such tools for Chinese are still quite primitive. In contrast to the plethora of research related to 
EFL learning, relatively few studies have focused on grammar checking for CFL learners. Wu et al. 
(2010) proposed relative position and parse template language models to detect Chinese errors written 
by US learner. Yu and Chen (2012) proposed a classifier to detect word-ordering errors in Chinese 
sentences from the HSK dynamic composition corpus. Chang et al. (2012) proposed a penalized prob-
abilistic First-Order Inductive Learning (pFOIL) algorithm for error diagnosis. In summary, although 
there are many approaches and tools to help EFL learners, the research problem described above for 
CFL learning is still under-explored. In addition, no common platform is available to compare differ-
ent approaches and to promote the study of this important issue. 
This study develops a sentence judgment system using both rule-based and n-gram statistical meth-
ods to detect grammatical errors in sentences written by CFL learners. Learners can input Chinese sen-
tences into the proposed system to check for possible grammatical errors. The rule-based method uses 
a set of rules developed by linguistic experts to identify potential rule violations in input sentences. 
 
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer 
are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ 
67
The n-gr
tences to
proved u
can also 
assignme
2 A S
Figure 1
http://sjf
shown in
part-of-s
grammat
ods dete
informat
ence, as 
?
( I
The ru
(towards
frequenc
detail the
2.1 Pr
Chinese 
Languag
nese wo
usually s
corpus-b
Ma, 200
ed word
????
?POS:W
words, t
lexicon a
POS tag 
 
am statistica
 determine 
nderstandin
be incorpora
nts and test
entence Ju
 shows the
.itc.ntnu.edu
 the upper 
peech taggi
ical error de
ct grammatic
ion, the exp
shown in the
     ?     ??
      from   he
le-based me
)) cannot be
y of the big
 pre-process
e-processin
is written w
e Processing
rd segmente
uffers from 
ased learnin
2). This is fo
s with parts-
??? (Ob
ord? sequen
he translatio
nd therefore
?SHI? is a ta
l method re
the correctn
g of both lin
ted into onl
s. 
dgement S
 user interf
.tw/demo/. L
part of Fig. 
ng, and then
tection. Fina
al errors. O
lanation of t
 bottom par
    ?     ?
re    go   tow
thod shows
 used after a
ram ?? ?
ing, rule-ba
g 
ithout word 
 (NLP) task
rs are gener
the unknow
g method is 
llowed by a
of-speech (T
ama is the p
ce  shown 
n of a forei
 is extracted
g to represen
Figure 1.
lies on the n
ess of the in
guistic rules 
ine CFL MO
ystem 
ace of the 
earners can
1. Each inp
 passed to 
lly, an inpu
therwise, it w
he matched 
t of Fig. 1. F
         ? 
ads  north. )
a rule violat
 verb (e.g., ?
? (go toward
sed method, 
boundaries.
s, texts mus
ally trained 
n word (i.e.,
used to merg
 reliable and
sai and Che
resident of 
as follows: 
gn proper na
 by the unk
t the be-ver
Screenshot 
-gram scor
put sentence
and n-gram 
OC platform
sentence ju
 submit sing
ut sentence 
both the ru
t sentence w
ill be mark
rules and n-g
or instance, 
 
ion is detec
?? (go)). T
s) is relativ
and n-gram 
 As a result,
t undergo au
by an input 
 the out-of-v
e unknown
 cost-effecti
n, 2004). F
the USA). 
 Nb:???
me ????
nown word 
b ???. 
of the senten
es of both c
s. The syste
frequencies
s to help as
dgment sys
le or multip
is pre-proce
le-based an
ill be marke
ed as correc
ram frequen
the followin
ted and expl
he n-gram fr
e low. The f
statistical m
 prior to the
tomatic wo
lexicon and
ocabulary, o
 words to tac
ve POS-tagg
or example, 
It was segm
  SHI:?  N
? (Obama) 
detection me
ce judgemen
orrect and in
m helps lea
. In addition,
sess and/or 
tem, which 
le sentences
ssed for wo
d n-gram st
d as incorre
t ( ). In ad
cies are als
g sentence i
ains that a p
equencies al
ollowing su
ethod. 
 implementa
rd segmenta
 probability 
r OOV) pro
kle the OOV
ing method 
take the Ch
ented and ta
c:??  Na
is not likely
chanism. In
t system. 
correct train
rners develo
 the propose
score the nu
can be acc
 through th
rd segmenta
atistical met
ct ( ) if bo
dition to the
o presented 
s marked as 
reposition (e
so shows th
bsections de
tion of mos
tion. Autom
models. Ho
blem. In this
 problem (C
to label the 
inese senten
gged in the
:??. Amo
 to be inclu
 this case, th
ing sen-
p an im-
d system 
mbers of 
essed at 
e textbox 
tion and 
hods for 
th meth-
 decision 
for refer-
incorrect: 
.g., ??? 
at the the 
scribe in 
t Natural 
atic Chi-
wever, it 
 study, a 
hen and 
segment-
ce ???
 form of  
ng these 
ded in a 
e special 
 
68
2.2 Rule-based Linguistic Analysis 
Several symbols are used to represent the syntactic rules to facilitate the detection of errors embedded 
in Chinese sentences written by CFL learners: (1) ?*? is a wild card, with ?Nh*? denoting all subordi-
nate tags of ?Nh?, e.g., ?Nhaa,? ?Nhab,? ?Nhac,? ?Nhb,? and ?Nhc?. (2) ?-? means an exclusion from 
the previous representation, with ?N*-Nab-Nbc? indicating that the corresponding word should be any 
noun (N*) excluding countable entity nouns (Nab) and surnames (Nbc). (3) ?/? means an alternative 
(i.e., ?or?), where the expression ???/??/??? (some/these/those) indicates that one of these 
three words satisfies the rule. (4) The rule mx{W1 W2} denotes the mutual exclusivity of the two 
words W1 and W2. (5) ?<? denotes the follow-by condition, where the expression ?Nhb  <  Nep? 
means the POS-tag ?Nep? follows the tag ?Nhb? that can exist several words ahead of the ?Nep?. 
Using such rule symbols, we manually constructed syntactic rules to cover errors that frequently oc-
cur in sentences written by CFL learners. We adopted the ?Analysis of 900 Common Erroneous Sam-
ples of Chinese Sentences? (Cheng, 1997) as the development set to handcraft the linguistic rules with 
syntactic information. If an input sentence satisfies any syntactic rule, the system will report the input 
as suspected of containing grammatical errors, creating a useful tool for autonomous CFL learners.  
2.3 N-gram Statistical Analysis 
Language modeling approaches to grammatical error detection are usually based on a score (log prob-
ability) output by an n-gram model trained on a large corpus. A sentence with grammatical errors usu-
ally has a low n-gram score. However, choosing an appropriate threshold to determine whether a sen-
tence is correct is still a nontrivial task. Therefore, this study proposes the use of n-gram scores of cor-
rect and incorrect sentences to build the respective correct and incorrect statistical models for gram-
matical error detection. That is, a given sentence is denoted as incorrect (i.e., having grammatical er-
rors) if its probability score output by the statistical model of incorrect sentences (i.e., the incorrect 
model) is greater than that of correct sentences (i.e., the correct model).  
To build the incorrect and correct statistical models, a total of 19,080 sentences with grammatical 
errors were extracted from the HSK dynamic composition corpus. These sentences were then manual-
ly corrected. An n-gram (n= 2 and 3) language model was then built from the Sinica corpus released 
by the Association for Computational Linguistics and Chinese Language Processing (ACLCLP) using 
the SRILM toolkit (Stolcke, 2002). The trained language model was used to assign an n?gram score 
for each correct and incorrect sentence, which were then used to build the respective correct and incor-
rect models based on a normal probability density function (Manning and Sch?tze, 1999). Both mod-
els can then be used to evaluate each test sentence by transforming its n-gram score into a probability 
score to determine whether the sentence is correct or not. 
3 Performance Evaluation 
The test set included 880 sentences with grammatical errors generated by CSL learners in the NCKU 
Chinese Language Center, and the corresponding 880 manually corrected sentences. For the rule-
based approach, a total of 142 rules were developed to identify incorrect sentences. For the n-gram 
statistical approach, both bi-gram and tri-gram language models were used for the correct and incor-
rect statistical models. In addition to precision, recall, and F1, the false positive rate (FPR) was defined 
as the number of correct sentences incorrectly identified as incorrect sentences divided by the total 
number of correct sentences in the test set. 
Table 1 shows the comparative results of the rule-based and n-gram statistical approaches to gram-
matical error detection. The results show that the rule-based approach achieved high precision, low 
recall and low FPR. Conversely, the n-gram-based approach yielded low precision, high recall and 
high FPR. In addition, the tri-gram model outperformed the bi-gram model for all metrics. Given the 
different results yielded by the rule-based and n-gram statistical approaches, we present different com-
binations of these two methods for comparison. The ?OR? combination means that a given sentence is 
identified as incorrect by only one of the methods, while the ?AND? combination means that a given 
sentence is identified as incorrect by both methods. The results show that the ?OR? combination yield-
ed better recall than the individual methods, and the ?AND? combination yielded better precision and 
FPR than the individual methods. Thus, the choice of methods may depend on application require-
ments or preferences 
69
Method Precision Recall F1 False Positive Rate 
Rule 0.857 0.224 0.356 0.038 
2-gram 0.555 0.751 0.638 0.603 
3-gram 0.585 0.838 0.689 0.595 
Rule OR 2-gram 0.500 1.000 0.667 1.000 
Rule OR 3-gram 0.502 1.000 0.668 0.993 
Rule AND 2-gram 0.924 0.083 0.153 0.007 
Rule AND 3-gram 0.924 0.083 0.153 0.007 
Table 1. Comparative results of the rule-based and n-gram statistical approaches. 
 
Many learner corpora exist for EFL for use in machine learning, including the International Corpus 
of Learner English (ICLE) and Cambridge Learner Corpus (CLC). But collecting a representative 
sample of authentic errors from CFL learners poses a challenge. In addition, English and Chinese 
grammars are markedly different. In contrast to syntax-oriented English language, Chinese is dis-
course-oriented, with meaning often expressed in several clauses to make a complete sentence. These 
characteristics make syntactic parsing difficult, due to long dependency between words in a clause or 
across clauses in a sentence. These difficulties constrain system performance.  
4 Conclusions  
This study presents a sentence judgment system developed using both rule-based and n-gram statisti-
cal methods to detect grammatical errors in sentences written by CFL learners. The system not only 
alerts learners to potential grammatical errors in their input sentences, but also helps them learn about 
linguistic rules and n-gram frequencies. The major contributions of this work include: (a) demonstrat-
ingg the feasibility of detecting grammatical errors in sentences written by CFL learners, (b) develop-
ing a system to facilitate autonomous learning among CFL learners and (c) collecting real grammatical 
errors  from CFL learners for the construction of a Chinese learner corpus. 
Acknowledgments 
This research was partially supported by Ministry of Science and Technology, Taiwan under the grant 
NSC102-2221-E-155-029-MY3, NSC 102-2221-E-002-103-MY3, and the "Aim for the Top Universi-
ty Project" sponsored by the Ministry of Education, Taiwan.  
Reference 
Andreas Stolcke. 2002. SRILM ? An extensible language modeling toolkit. Proceedings of ICSLP?02, pages 
901-904. 
Chi-Hsin Yu and Hsin-Hsi Chen. 2012. Detecting word ordering errors in Chinese sentences for learning Chi-
nese as a foreign language. Proceedings of COLING?12, pages 3003-3018. 
Christopher D. Manning and Hinrich Sch?tze. 1999. Foundations of Statistical Natural Language Processing. 
MIT Press. Cambridge, MA.  
Chung-Hsien Wu, Chao-Hung Liu, Matthew Harris and Liang-Chih Yu. 2010. Sentence correction incorporating 
relative position and parse template language model. IEEE Transactions on Audio, Speech, and Language 
Processing, 18(6):1170-1181. 
Keh-Jiann Chen and Wei-Yun Ma. 2002. Unknown word extraction for Chinese documents. Proceedings of 
COLING?02, pages 169-175. 
M. Cheng. 1997. Analysis of 900 Common Erroneous Samples of Chinese Sentences - for Chinese Learners 
from English Speaking Countries (in Chinese). Beijing, CN: Sinolingua. 
Ru-Ying Chang, Chung-Hsien Wu, and Philips K. Prasetyo. 2012. Error diagnosis of Chinese sentences using 
inductive learning algorithm and decomposition-based testing mechanism. ACM Transactions on Asian Lan-
guage Information Processing, 11(1):Article 3. 
Yu-Fang Tsai and Keh-Jiann Chen. 2004. Reliable and cost-effective pos-tagging. International Journal of 
Computational Linguistics and Chinese Language Processing, 9(1):83-96. 
70
