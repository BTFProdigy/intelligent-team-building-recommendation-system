Proceedings of NAACL HLT 2007, Companion Volume, pages 145?148,
Rochester, NY, April 2007. c?2007 Association for Computational Linguistics
Joint Morphological-Lexical Language Modeling for Machine Translation
Ruhi Sarikaya Yonggang Deng
IBM T.J. Watson Research Center
Yorktown Heights, NY 10598
sarikaya@us.ibm.com ydeng@us.ibm.com
Abstract
We present a joint morphological-lexical language 
model (JMLLM) for use in statistical machine trans-
lation (SMT) of language pairs where one or both of 
the languages are morphologically rich. The pro-
posed JMLLM takes advantage of the rich morphol-
ogy to reduce the Out-Of-Vocabulary (OOV) rate, 
while keeping the predictive power of the whole 
words. It also allows incorporation of additional 
available semantic, syntactic and linguistic informa-
tion about the morphemes and words into the lan-
guage model. Preliminary experiments with an
English to Dialectal-Arabic SMT system demon-
strate improved translation performance over trigram 
based baseline language model.
1 Introduction
Statistical machine translation (SMT) methods have 
evolved from using the simple word based models 
(Brown et al, 1993) to phrase based models (Marcu and 
Wong, 2002; Koehn et al, 2004; Och and Ney, 2004). 
More recently, there is a significant effort focusing on 
integrating richer knowledge, such as syntactic parse trees 
(Huang and Knight, 2006) within the translation process 
to overcome the limitations of the phrase based models.  
The SMT has been formulated as a noisy channel model 
in which the target language sentence, e is seen as dis-
torted by the channel into the foreign language f :
)()|(argmax)|(argmax?
ee
ePefPfePe ??
where P(f | e) is the translation model and P(e) is lan-
guage model of the target language. The overwhelming 
proportion of the SMT research has been focusing on im-
proving the translation model. Despite several new studies 
(Kirchhoff and Yang, 2004; Schwenk et al, 2006), lan-
guage modeling for SMT has not been receiving much 
attention.  Currently, the state-of-the-art SMT systems 
have been using the standard word n-gram models.  Since 
n-gram models learn from given data, a severe drop in 
performance may be observed if the target domain is not 
adequately covered in  the training data. The   coverage 
problem is aggravated for morphologically rich lan-
guages. Arabic is such a language where affixes are 
appended to the beginning or end of a stem to generate 
new words that indicate case, gender, tense etc. associ-
ated with the stem. Hence, it is natural that this leads to 
rapid vocabulary growth, which is accompanied by 
worse language model probability estimation due to 
data sparsity and high Out-Of-Vocabulary (OOV) rate. 
Due to rich morphology, one would suspect that 
words may not be the best lexical units for Arabic, and 
perhaps morphological units would be a better choice. 
Recently, there have been a number of new methods 
using the morphological units to represent lexical items 
(Ghaoui et al, 2005; Xiang et al, 2006; Choueiter et al, 
2006). Factored Language Models (FLMs) (Kirchhoff 
and Yang, 2004) share the same idea to some extent but 
here words are decomposed into a number of features 
and the resulting representation is used in a generalized 
back-off scheme to improve the robustness of probabil-
ity estimates for rarely observed word n-grams.
In this study we propose a tree structure called Mor-
phological-Lexical Parse Tree (MLPT) to combine the 
information provided by a morphological analyzer with 
the lexical information within a single Joint Morpho-
logical-Lexical Language Model (JMLLM). The MLPT 
allows us to include available syntactic and semantic 
information about the morphological segments1 (i.e. 
prefix/stem/suffix), words or group of words. The 
JMLLM can also be used to guide the recognition for 
selecting high probability morphological sentence seg-
mentations. 
The rest of the paper is organized as follows. Section 
2 provides a description of the morphological segmenta-
tion method. A short overview of Maximum Entropy 
modeling is given in Section 3. The proposed JMLLM 
is presented in Section 4. Section 5 introduces the SMT 
system and Section 6 describes the experimental results 
followed by the conclusions in Section 7.
2 Morphological Segmentation
Applying the morphological segmentation to data 
improves  the  coverage  and  reduces the OOV rate.  In
                                                          
1 We use ?Morphological Segment? and ?Morpheme? inter-
changeably.
145
this study we use a rule-based morphological segmenta-
tion algorithm for Iraqi-Arabic (Afify et. al., 2006). This 
algorithm analyzes a given surface word, and generates 
one of the four possible segmentations: {stem, pre-
fix+stem, suffix+stem, prefix+stem+suffix}. Here, stem
includes those words that do not have any affixes. We use 
the longest prefixes (suffixes).  Using finer affixes re-
duces the n-gram language model span, and leads to poor 
performance for a fixed n-gram size. Therefore, we prede-
fine a set of prefixes and suffixes and perform blind word 
segmentation. In order to minimize the illegitimate seg-
mentations we employ the following algorithm. Using the 
given set of prefixes and suffixes, a word is first blindly 
chopped to one of the four segmentations mentioned 
above. This segmentation is accepted if the following 
three rules apply:
(1) The resulting stem has more than two characters.
(2) The resulting stem is accepted by the Buckwalter 
morphological analyzer (Buckwalter, 2002).
(3) The resulting stem exists in the original dictionary.
The first rule eliminates many of the illegitimate segmen-
tations. The second rule ensures that the word is a valid 
Arabic stem, given that the Buckwalter morphological 
analyzer covers all words in the Arabic language. Unfor-
tunately, the fact that the stem is a valid Arabic stem does 
not always imply that the segmentation is valid. The third 
rule, while still not offering such guarantee, simply pre-
fers keeping the word intact if its stem does not occur in 
the lexicon. In our implementation we used the following 
set of prefixes and suffixes for dialectal Iraqi:
? Prefix list: {chAl, bhAl, lhAl, whAl, wbAl, wAl, bAl, 
hAl, EAl, fAl, Al, cd, ll, b, f, c, d, w}.
? Suffix list: {thmA, tynA, hmA, thA, thm, tkm, tnA, 
tny,whA, whm, wkm, wnA, wny, An, hA, hm, hn, km, 
kn, nA, ny, tm, wA, wh, wk, wn, yn, tk, th, h, k, t, y}.
These affixes are selected based on our knowledge of 
their adequacy for dialectal Iraqi Arabic. In addition, we 
found in preliminary experiments that keeping the top-N 
frequent decomposable words intact led to better per-
formance. A value of N=5000 was experimentally found 
to work well in practice. Using this segmentation method 
will produce prefixes and suffixes on the SMT output that 
are glued to the following or previous word to form mean-
ingful words. 
3 Maximum Entropy Modeling
The Maximum Entropy (MaxEnt) method is an effec-
tive method to combine multiple information sources 
(features) in statistical modeling and has been used widely 
in many areas of natural language processing (Berger et 
al.,, 2000). The MaxEnt modeling produces a probability 
model that is as uniform as possible while matching em-
pirical feature expectations exactly:
?
?
?
?
'
),'(
),(
)|(     
o
j
hojfi
e
i
hoifi
ehoP ?
?
which describes the probability of a particular outcome 
(e.g. one of the morphemes) given the history (h) or 
context. Notice that the denominator includes a sum 
over all possible outcomes, o', which is essentially a 
normalization factor for probabilities to sum to 1. The 
indicator functions if  or features are ?activated? when 
certain outcomes are generated for certain context. The 
MaxEnt model is trained using the Improved Iterative 
Scaling algorithm.
4 Joint Morphological-Lexical Language 
Modeling
The purpose of morphological analysis is to split a 
word into its constituting segments.  Hence, a set of 
segments can form a meaningful lexical unit such as a 
word. There may be additional information for words or 
group of words, such as part-of-speech (POS) tags, syn-
tactic (from parse tree) and semantic information, or 
morpheme and word attributes. For example, in Arabic 
and to a certain extent in French, some words can be 
masculine/feminine or singular/plural. All of these in-
formation sources can be represented using a -what we 
call- Morphological-Lexical Parse Tree (MLPT).  
MLPT is a tree structured joint representation of lexical, 
morphological, attribute, syntactic and semantic content 
of the sentence.  An example of a MLPT for an Arabic 
sentence is shown in Fig. 1. The leaves of the tree are 
morphemes that are predicted by the language model. 
Each morphological segment has one of the three attrib-
utes: {prefix, stem, suffix} as generated by the morpho-
logical analysis mentioned in Sec. 2. Each word can 
take three sets of attributes: {type, gender, number}.
Word type can be considered as POS, but here we con-
sider only nouns (N), verbs (V) and the rest are labeled 
as ?other? (O). Gender can be masculine (M) or femi-
nine (F). Number can be singular (S), plural (P) or dou-
ble (D) (this is specific to Arabic).  For example, NMP 
label for the first2 word, ????, shows that this word is a 
noun (N), male (M), plural (P).  Using the information 
represented in MLPT for Arabic language modeling 
provides a back-off for smooth probability estimation 
even for those words that are not seen before. 
The JMLLM integrates the local morpheme and 
word n-grams, morphological dependencies and attrib-
ute information associated with morphological segments 
and words, which are all represented in the MLPT using 
the MaxEnt framework. We  trained JMLLM  for Iraqi-
                                                          
2 In Arabic text is written (read) from right-to-left. 
146
Arabic speech recognition task (Sarikaya et al, 2007),
and obtained significant improvements over word and 
morpheme based trigram language models.
We can construct a single probability model that mod-
els the joint probability of all of the available information 
sources in the MLPT. To compute the joint probability of 
the morpheme sequence and its MLPT, we use features 
extracted from MLPT. Even though the framework is 
generic to jointly represent the information sources in the 
MLPT, in this study we limit ourselves to using only lexi-
cal and morphological content of the sentence, along with 
the morphological attributes simply because the lexical 
attributes are not available yet and we are in the process 
of labeling them. Therefore, the information we used from 
MLPT in Fig. 1 uses everything but the second row that 
contains lexical attributes (NFS, VFP, NFS, and NMP).
Using the morphological segmentation improves the 
coverage, for example, splitting the word, ??????? as ???
(prefix) and ???? (stem) as in Fig. 1, allows us to decode 
other combinations of this stem with the prefix and suffix 
list provided in Sec.2.  These additional combinations 
certainly cover those words that are not seen in the un-
segmented training data. 
The first step in building the MaxEnt model is to rep-
resent a MLPT as a sequence of morphological segments, 
morphological attributes, words, and word attributes using 
a bracket notation. Converting the MLPT into a text se-
quence allows us to group the semantically related mor-
phological segments and their attributes. In this notation, 
each morphological segment is associated (this associa-
tion is denoted by ?=") with an attribute (i.e. pre-
fix/stem/suffix) and the lexical items are represented by 
opening and closing tokens, [WORD and WORD] respec-
tively. The parse tree given in Fig. 1 can be converted into 
a token sequence in text format as follows:
[!S! [NMP ????=stem NMP] [NFS [??????? ??=prefix ?????=stem 
???????] NFS] [VFP  [?  ??????=prefix ???=stem ??=suffix ??????] 
VFP]  [NFS [??????? ???=prefix ???????=stem  ???????] NFS] !S!]
This representation uniquely defines the MLPT given in 
Fig. 1. Given the bracket notation of the text, JMLLM can 
be trained in two ways with varying degrees of ?tightness 
of integration?. A relatively ?loose integration?  involves 
using only the leaves of the MLPT as the model output 
and estimating P(M|MLPT), where M is the morpheme 
sequence. In this case JMLLM predicts only morphemes.  
A tight integration method would require every token in 
the bracket representation to be an outcome of the joint 
model.  In our preliminary experiments we chose the 
loose integration method, simply because the model 
training time was significantly faster than that for the tight 
integration. segment. The JMLLM can employ any type 
of questions one can derive from MLPT for predicting the 
next morphological segment. In addition to regular tri-
gram questions about previous morphological segments, 
questions about the attributes of the  previous morpho-
Fig 1. Morphological-Lexical Parse Tree.
logical segments, parent lexical item and attributes of 
the parent lexical item can be used. Obviously joint 
questions combining these information sources are also 
used. Obviously joint questions combining these infor-
mation sources are also used. These questions include 
(1) previous morpheme 1?im and current active parent 
word ( iw ) (2) ii wm ,1? and previous morpheme attribute
( 1?ima ). (3) iii wmama ,, 21 ?? ,lexical attribute ( iwa ) and 
21 , ?? ii mm . 
The history given in )|( hoP consists of answers to 
these questions. In our experiments, we have not ex-
haustively searched for the best feature set but rather 
used a small subset of these features which we believed 
to be helpful in predicting the next morpheme. The lan-
guage model score for a given morpheme using JMLLM 
is conditioned not only on the previous morphemes but 
also on their attributes, and the lexical items and their 
attributes. As such, the language model scores are 
smoother compared to n-gram models especially for 
unseen lexical items. 
5 Statistical Machine Translation System
Starting from a collection of parallel sentences, we 
trained word alignment models in two translation direc-
tions, from English to Iraqi Arabic and from Iraqi Ara-
bic to English, and derived two sets of Viterbi
alignments. By combining word alignments in two di-
rections using heuristics (Och and Ney, 2003), a single 
set of static word alignments was then formed. All 
phrase pairs which respect to the word alignment 
boundary constraint were identified and pooled together 
to build phrase translation tables with the Maximum 
Likelihood criterion. The maximum number of words in 
Arabic phrases was set to 5.
Our decoder is the phrase-based multi-stack imple-
mentation of log-linear models similar to Pharaoh 
(Koehn et al 2004). Like most other MaxEnt-based 
decoders, active features in our decoder include transla-
tion models in two directions, lexicon weights in two
!S!
?????? ???????
?????????
NMPNFSVFP
stem prefix stem
???????
NFS
??????? ????? ???
suffix prefixstemstem prefix
147
directions, language model, distortion model, and sen-
tence length penalty. 
6 Experiments
The parallel corpus has 459K utterance pairs with 90K 
words (50K morphemes). The Iraqi-Arabic language 
model training data is slightly larger than the Iraqi-Arabic 
side of the parallel corpus and it has 2.8M words with 
98K unique lexical items. The morphologically analyzed 
training data has 2.6M words with 58K unique vocabulary 
items. A statistical trigram language model using Modi-
fied Knesser-Ney smoothing has been built for the mor-
phologically segmented data.  The test data consists of 
2242 utterances (3474 unique words). The OOV rate for 
the unsegmented test data is 8.7%, the corresponding 
number for the morphologically analyzed data is 7.4%. 
Hence, morphological segmentation reduces the OOV 
rate by 1.3% (15% relative), which is not as large reduc-
tion as compared to training data (about 40% relative re-
duction). We believe this would limit the potential 
improvement we could get from JMLLM, since JMLLM 
is expected to be more effective compared to word n-
gram models, when the OOV rate is significantly reduced 
after segmentation. 
We measure translation performance by the BLEU 
score (Papineni et al 2002) with one reference for each
hypothesis. In order to evaluate the performance of the 
JMLLM, a translation N-best list (N=10) is generated 
using the baseline Morpheme-trigram language model.
First, on a heldout development data all feature weights
including the language model weight are optimized to 
maximize the BLEU score using the downhill simplex 
method (Och and Hey, 2002). These weights are fixed 
when the language models are used on the test data.  The 
translation BLEU (%) scores are given in Table 1. The 
first entry (37.59) is the oracle BLEU score for the N-best 
list. The baseline morpheme-trigram achieved 29.63, 
word-trigram rescoring improved the BLEU score to 
29.91. The JMLLM achieved 30.20 and log-linear inter-
polation with the morpheme-trigram improved the BLEU 
score to 30.41.  
7 Conclusions
We presented a new language modeling technique called 
Joint Morphological-Lexical Language Modeling 
(JMLLM) for use in SMT. JMLLM allows joint modeling 
of lexical, morphological and additional information
sources about morphological  segments,  lexical  items  
and sentence. The translation results demonstrate that 
joint modeling provides encouraging improvement over 
morpheme  based language  model. Our future work 
will be directed towards tight integration of all available 
Table 1.  SMT N-best list rescoring.
LANGUAGE MODELS BLEU (%)
N-best Oracle 37.59
Morpheme-trigram 29.63
Word-trigram 29.91
JMLLM 30.20
JMLLM + Morpheme-Trigram 30.41
information by predicting the entire MLPT (besides 
leaves).
References 
P. Brown er al.,. 1993. The mathematics of statistical machine transla-
tion. Computational Linguistics, 19(2):263?311.
A. Berger, S. Della Pietra and V. Della Pietra, "A Maximum Entropy 
Approach to Natural Language Processing," Computational Lin-
guistics, vol. 22, no. 1, March 1996 
T. Buckwalter. 2002. Buckwalter Arabic morphological analyzer 
version 1.0, LDC2002L49 and ISBN 1-58563-257-0, 2002.
G. Choueiter, D. Povey, S.F. Chen, and G. Zweig, 2006. Morpheme-
based language modeling for Arabic LVCSR. ICASSP?06, Tou-
louse, France, 2006.
A. Ghaoui, F. Yvon, C. Mokbel, and G. Chollet, 2005. On the use of 
morphological constraints in N-gram statistical language model, 
Eurospeech?05, Lisbon, Portugal, 2005.
B. Huang and K. Knight. 2006. Relabeling Syntax Trees to Improve 
Syntax-Based Machine Translation Quality. In HLT/NAACL.
B. Xiang, K. Nguyen, L. Nguyen, R. Schwartz, J. Makhoul, 2006. 
Morphological decomposition for Arabic broadcast news tran-
scription?, ICASSP?06,  Toulouse, France, 2006.
K. Kirchhoff and M. Yang. 2005. Improved language modeling for 
statistical machine translation. In ACL?05 workshop on Building 
and Using Parallel Text, pages 125?128.
P. Koehn, F. J. Och, and D. Marcu. 2004. Pharaoh: A beam search 
decoder for phrase based statistical machine translation models. In 
Proc. of 6th Conf. of  AMTA.
F. J. Och and H. Ney. 2002. Discriminative training and maximum 
entropy models for statistical machine translation. In ACL, pages 
295?302, University of Pennsylvania.
F. J. Och and H. Ney. 2003. A Systematic Comparison of Various 
Statistical Alignment Models. Comp. Linguistics, 29(1):9--51. 
K.  Papineni, S. Roukos, T. Ward, and W.-J. Zhu. 2002. BLEU: a 
Method for Automatic Evaluation of machine translation. In ACL 
02, pages 311?318
H. Schwenk, D. D?echelotte  and J-L. Gauvain. 2006.  Continuous 
space language models for statistical machine translation. In 
ACL/COLING, pages 723?730.
M. Afify, R. Sarikaya, H-K. J. Kuo, L. Besacier and Y. Gao. 2006. On 
the Use of Morphological Analysis for Dialectal Arabic Speech 
Recognition, In Interspeech-2006, Pittsburgh PA.
R. Sarikaya, M .Afify and Y. Gao. 2007. Joint Morphological-Lexical 
Modeling (JMLLM) for Arabic. ICASSP 2007, Honolulu Hawaii.
148
Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 1?8,
Prague, Czech Republic, June 2007. c?2007 Association for Computational Linguistics
Guiding Statistical Word Alignment Models With Prior Knowledge
Yonggang Deng and Yuqing Gao
IBM T. J. Watson Research Center
Yorktown Heights, NY 10598
{ydeng,yuqing}@us.ibm.com
Abstract
We present a general framework to incor-
porate prior knowledge such as heuristics
or linguistic features in statistical generative
word alignment models. Prior knowledge
plays a role of probabilistic soft constraints
between bilingual word pairs that shall be
used to guide word alignment model train-
ing. We investigate knowledge that can be
derived automatically from entropy princi-
ple and bilingual latent semantic analysis
and show how they can be applied to im-
prove translation performance.
1 Introduction
Statistical word alignment models learn word as-
sociations between parallel sentences from statis-
tics. Most models are trained from corpora in an
unsupervised manner whose success is heavily de-
pendent on the quality and quantity of the training
data. It has been shown that human knowledge,
in the form of a small amount of manually anno-
tated parallel data to be used to seed or guide model
training, can significantly improve word alignment
F-measure and translation performance (Ittycheriah
and Roukos, 2005; Fraser and Marcu, 2006).
As formulated in the competitive linking algo-
rithm (Melamed, 2000), the problem of word align-
ment can be regarded as a process of word link-
age disambiguation, that is, choosing correct asso-
ciations among all competing hypothesis. The more
reasonable constraints are imposed on this process,
the easier the task would become. For instance, the
most relaxed IBM Model-1, which assumes that any
source word can be generated by any target word
equally regardless of distance, can be improved by
demanding a Markov process of alignments as in
HMM-based models (Vogel et al, 1996), or imple-
menting a distribution of number of target words
linked to a source word as in IBM fertility-based
models (Brown et al, 1993).
Following the path, we shall put more constraints
on word alignment models and investigate ways of
implementing them in a statistical framework. We
have seen examples showing that names tend to
align to names and function words are likely to be
linked to function words. These observations are
independent of language and can be understood by
common sense. Moreover, there are other linguis-
tically motivated constraints. For instance, words
aligned to each other presumably are semantically
consistent; and likely to be, they are syntactically
agreeable. In these paper, we shall exploit some of
these constraints in building better word alignments
in the application of statistical machine translation.
We propose a simple framework that can inte-
grate prior knowledge into statistical word align-
ment model training. In the framework, prior knowl-
edge serves as probabilistic soft constraints that will
guide word alignment model training. We present
two types of constraints that are derived in an un-
supervised way: one is based on the entropy prin-
ciple, the other comes from bilingual latent seman-
tic analysis. We investigate their impact on word
alignments and show their effectiveness in improv-
ing translation performance.
1
2 Constrained Word Alignment Models
The framework that we propose to incorporate sta-
tistical constraints into word alignment models is
generic. It can be applied to complicated models
such IBM Model-4 (Brown et al, 1993). We shall
take HMM-based word alignment model (Vogel et
al., 1996) as an example and follow the notation of
(Brown et al, 1993). Let e = el1 represent a source
string and f = fm1 a target string. The random vari-
able a = am1 specifies the indices of source words
that target words are aligned to.
In an HMM-based word alignment model, source
words are treated as Markov states while target
words are observations that are generated when
jumping to states:
P (a, f |e) =
m?
j=1
P (aj |aj?1, e)t(fj |eaj )
Notice that a target word f is generated from a
source state e by a simple lookup of the translation
table, a.k.a., t-table t(f |e), as depicted in (A) of Fig-
ure 1. To incorporate prior knowledge or impose
constraints, we introduce two nodes E and F repre-
senting the hidden tags of the source word e and the
target word f respectively, and organize the depen-
dency structure as in (B) of Figure 1. Given this gen-
erative procedure, f will also depend on its tag F ,
which is determined probabilistically by the source
tag E. The dependency from E to F functions as a
soft constraint showing how the two hidden tags are
agreeable to each other. Mathematically, the condi-
tional distribution follows:
P (f |e) =
?
E,F
P (f,E, F |e)
=
?
E,F
P (E|e)P (F |E)P (f |e, F )
= t(f |e) ? Con(f, e), (1)
where
Con(f, e) =
?
E,F
P (E|e)P (F |E)P (F |f)/P (F ) (2)
is the soft weight attached to the t-table entry. It con-
siders all possible hidden tags of e and f and serves
as constraint between the link.
 
 
 f 
e 
f 
e E
F
A B 
Figure 1: A simple table lookup (A) vs. a con-
strained procedure (B) of generating a target word
f from a source word e.
We do not change the value of Con(f, e) during
iterative model training but rather keep it constant as
an indicator of how strong the word pair should be
considered as a candidate. This information is de-
rived before word alignment model training and will
act as soft constraints that need to be respected dur-
ing training and alignments. For a given word pair,
the soft constraint can have different assignment in
different sentence pairs since the word tags can be
context dependent.
To understand why we take the ?detour? of gen-
erating a target word rather than directly from a t-
table, consider the hidden tag as binary value in-
dicating being a name or not. Without these con-
straints, t-table entries for names with low frequency
tend to be flat and word alignments can be chosen
randomly without sufficient statistics or strong lexi-
cal preference under maximum likelihood criterion.
If we assume that a name is produced by a name
with a high probability but by a non-name with a
low probability, i.e. P (F = E) >> P (F 6= E),
proper names with low counts then are encouraged
to link to proper names during training; and conse-
quently, conditional probability mass would be more
focused on correct name translations. On the other
hand, names are discouraged to produce non-names.
This will potentially avoid incorrect word associa-
tions. We are able to apply this type of constraint
since usually there are many monolingual resources
available to build a high performance probabilistic
name tagger. The example suggests that putting rea-
sonable constraints learned frommonolingual analy-
sis can alleviate data spareness problem in bilingual
applications.
The weights Con(f, e) are the prior knowledge
that shall be assigned with care but respected dur-
ing training. The baseline is to set al these weights
2
to 1, which is equivalent to placing no prior knowl-
edge on model training. The introduction of these
weights does not complicate parameter estimation
procedure. Whenever a source word e is hypoth-
esized to generate a target word f , the translation
probability t(f |e) should be weighted by Con(f, e).
We point out that the constraints between f and e
through their hidden tags are in probabilities. There
are no hard decisions made before training. A strong
preference between two words can be expressed by
assigning corresponding weights close to 1. This
will affect the final alignment model.
Depending on the hidden tags, there are many re-
alizations of reasonable constraints that can be put
beforehand. They can be semantic classes, syntactic
annotations, or as simple as whether being a function
word or content word. Moreover, the source side and
the target side do not have to share the same set of
tags. The framework is also flexible to support mul-
tiple types of constraints that can be implemented in
parallel or cascaded sequence. Moreover, the con-
straints between words can be dependent on context
within parallel sentences. Next, we will describe
two types of constraints that we proposed. Both of
them are derived from data in an unsupervised way.
2.1 Entropy Principle
It is assumed that generally speaking, a source func-
tion word generates a target function word with a
higher probability than generating a target content
word; similar assumption applies to a source con-
tent word as well. We capture this type of constraint
by defining the hidden tag E and F as binary labels
indicating being a content word or not. Based on
the assumption, we design probabilistic relationship
between the two hidden tags as:
P (E = F ) = 1? P (E 6= F ) = ?,
where ? is a scalar whose value is close to 1, say
0.9. The bigger ? is, the tighter constraint we put on
word pairs to be connected requiring the same type
of label.
To determine the probability of a word being
a function word, we apply the entropy principle.
A function word, say ?of?,?in? or ?have?, appears
more frequently than a content word, say ?journal?
or ?chemistry?, in a document or sentence. We will
approximate the probability of a word as a function
word with the relative uncertainty of its being ob-
served in a sentence.
More specifically, suppose we have N parallel
sentences in the training corpus. For each word wi1,
let cij be the number of word wi observed in the j-th
sentence pair, and let ci be the total number of oc-
currences of wi in the corpus. We define the relative
entropy of word wi as
wi = ?
1
logN
N?
j=1
cij
ci
log
cij
ci
.
With the entropy of a word, the likelihood of word
w being tagged as a function word is approximated
with w(1) = w and being tagged as a content word
with w(0) = 1? w.
We ignore the denominator in Equ. (2) and find
the constraint under the entropy principle:
Con(f, e) = ?(e(0)f (0) + e(1)f (1)) +
(1? ?)(e(1)f (0) + e(0)f (1)).
As can be seen, the connection between two
words is simulated with a binary symmetric chan-
nel. An example distribution of the constraint func-
tion is illustrated in Figure 2. A high value of ?
encourages connecting word pairs with compara-
ble entropy; When ? = 0.5, Con(f, e) is constant
which corresponds to applying no prior constraint;
When ? is close to 0, the function plays opposite
role on word alignment training where a high fre-
quency word is pushed to associate with a low fre-
quency word.
2.2 Bilingual Latent Semantic Analysis
Latent Semantic Analysis (LSA) is a theory and
method for extracting and representing the meaning
of words by statistically analyzing word contextual
usages in a collection of text. It provides a method
by which to calculate the similarity of meaning of
given words and documents. LSA has been success-
fully applied to information retrieval (Deerwester
et al, 1990), statistical langauge modeling (Belle-
garda, 2000) and etc.
1We prefix ?E ? to source words and ?F ? to target words
to distinguish words that have the same spelling but are from
different languages.
3
 
0  0
.2  0.
4  0.6
 
0.8
 
1 0 0.
2
 
0.4 0.6 0.8 1
 
0
 
0.1
 
0.2
 
0.3
 
0.4
 
0.5
 
0.6
 
0.7
 
0.8
 
0.9
Con(f,e)
alpha=
0.9
e(0)
f(0)
 
0  0
.2  0.
4  0.6
 
0.8
 
1 0 0.
2
 
0.4 0.6 0.8 1
 
0.1
 
0.2
 
0.3
 
0.4
 
0.5
 
0.6
 
0.7
 
0.8
 
0.9
Con(f,e)
alpha=
0.1
e(0)
f(0)
Figure 2: Distribution of the constraint function
based on entropy principle when ? = 0.9 on the
left and ? = 0.1 on the right.
We explore LSA techniques in bilingual environ-
ment to derive semantic constraints as prior knowl-
edge for guiding a word alignment model train-
ing. The idea is to find semantic representation of
source words and target words in the so-called low-
dimensional LSA-space, and then to use their sim-
ilarities to quantitatively establish semantic consis-
tencies. We propose two different approaches.
2.2.1 A Simple Bag-of-word Model
One method we investigate is a simple bag-of-
word model as in monolingual LSA. We treat each
sentence pair as a document and do not distin-
guish source words and target words as if they
are terms generated from the same vocabulary. A
sparse matrix W characterizing word-document co-
occurrence is constructed. Following the notation in
section 2.1, the ij-th entry of the matrix W is de-
fined as in (Bellegarda, 2000)
Wij = (1? wi)
cij
cj
,
where cj is the total number of words in the j-th
sentence pair. This construction considers the im-
portance of words globally (corpus wide) and locally
(within sentence pairs). Alternative constructions of
the matrix are possible using raw counts or TF-IDF
(Deerwester et al, 1990).
W is a M ? N sparse matrix, where M is the
size of vocabulary including both source and target
words. To obtain a compact representation, singular
value decomposition (SVD) is employed (cf. Berry
et al(1993)) to yield W ? W? = U ? S ? V T
as Figure 3 shows, where, for some order R 
min(M,N) of the decomposition, U is a M?R left
singular matrix with rows ui, i = 1, ? ? ? ,M , S is a
R?R diagonal matrix of singular values s1 ? s2 ?
. . . ? sR  0, and V is N?R a right singular ma-
trix with rows vj , j = 1, ? ? ? , N . For each i, the
scaled R-vector uiS may be viewed as representing
wi, the i-th word in the vocabulary, and similarly the
scaled R-vector vjS as representing dj , j-th docu-
ment in the corpus. Note that the uiS?s and vjS?s
both belong to IRR, the so-called LSA-space. All
target and source words are projected into the same
LSA-space too.
NM?
RM?
RR?
NR?
R orthonormalvectors
Documents
1wMw WordsW
U
S
TV
1d
Nd
R orthonormalvectors
Figure 3: SVD of the Sparse Matrix W .
As Equ. (2) suggested, to induce semantic con-
straints in a straightforward way, one would proceed
as follows: firstly, perform word semantic cluster-
ing with, say, their compact representations in the
LSA-space; secondly, construct cluster generating
dependencies by specifying the conditional distribu-
tion of P (F |E); and finally, for each word pair, in-
duce the semantic constraint by considering all pos-
sible semantic labeling schemes. We approximate
this long process with simply finding word similar-
ities defined by their cosine distance in the low di-
mension space:
Con(f, e) =
1
2
(cos(ufS, ueS) + 1) (3)
The linear mapping above is introduced to avoid
negative constraints and to set the maximum con-
straint value as 1.
In building word alignment models, a special
?NULL? word is usually introduced to address tar-
get words that align to no source words. Since this
physically non-existing word is not in the vocabu-
lary of the bilingual LSA, we use the centroid of all
source words as its vector representation in the LSA-
space. The semantic constraints between ?NULL?
and any target words can be derived in the same way.
However, this is chosen for mostly computational
4
convenience, and is not the only way to address the
empty word issue.
2.2.2 Utilizing Word Alignment Statistics
While the simple bag-of-word model puts all
source words and target words as rows in the ma-
trix, another method of deriving semantic constraint
constructs the sparse matrix by taking source words
as rows and target words as columns and uses statis-
tics from word alignment training to form word pair
co-occurrence association.
More specifically, we regard each target word f as
a ?document? and each source word e as a ?term?.
The number of occurrences of the source word e in
the document f is defined as the expected number
of times that f generates e in the parallel corpus
under the word alignment model. This method re-
quires training the baseline word alignment model
in another direction by taking fs as source words
and es as target words, which is often done for
symmetric alignments, and then dumping out the
soft counts when model converges. We threshold
the minimum word-to-word translation probability
to remove word pairs that have low co-occurrence
counts.
Following the similarity induced semantic con-
straints in section 2.2.1, we need to find the distance
between a term and a document. Let vf be the pro-
jection of the document representing the target word
f and ue the projection of the term representing the
source word e after performing SVD on the sparse
matrix, we calculate the similarity between (f, e)
and then find their semantic constraint to be
Con(f, e) =
1
2
(cos(vfS
1/2, ueS
1/2) + 1) (4)
Unlike the method in section 2.2.1, there is no
empty word issue here since we do have statistics
of the ?NULL? word as a source word generating e
words and therefore there is a ?document? assigned
to it.
3 Experimental Results
We test our framework on the task of large vocab-
ulary translation from dialectical (Iraqi) Arabic ut-
terances into English. The task covers multiple do-
mains including travel, emergency medical diagno-
sis, defense-oriented force protection, security and
etc. To avoid impacts of speech recognition errors,
we only report experiments from text to text transla-
tion.
The training corpus consists of 390K sentence
pairs, with total 2.43M Arabic words and 3.38M En-
glish words. These sentences are in typical spoken
transcription form, i.e., spelling errors, disfluencies,
such as word or phrase repetition, and ungrammat-
ical utterances are commonly observed. Arabic ut-
terance length ranges from 3 to 70 words with the
average of 6 words.
There are 25K entries in the English vocabulary
and 90K in Arabic side. Data sparseness severely
challenges word alignment model and consequently
automatic phrase translation induction. There are
42K singletons in Arabic vocabulary, and 14K Ara-
bic words with occurrence of twice each in the cor-
pus. Since Arabic is a morphologically rich lan-
guage where affixes are attached to stem words to
indicate gender, tense, case and etc, in order to re-
duce vocabulary size and address out-of-vocabulary
words, we split Arabic words into affix and root ac-
cording to a rule-based segmentation scheme (Xiang
et al, 2006) with the help from the Buckwalter ana-
lyzer (LDC, 2002) output. This reduces the size of
Arabic vocabulary to 52K.
Our test data consists of 1294 sentence pairs.
They are split into two parts: half of them is used as
the development set, on which training parameters
and decoding feature weights are tuned, the other
half is for test.
3.1 Training and Translation Setup
Starting from the collection of parallel training sen-
tences, we train word alignment models in two trans-
lation directions, from English to Iraqi Arabic and
from Iraqi Arabic to English, and derive two sets
of Viterbi alignments. By combining word align-
ments in two directions using heuristics (Och and
Ney, 2003), a single set of static word alignments
is then formed. All phrase pairs which respect to
the word alignment boundary constraint are iden-
tified and pooled to build phrase translation tables
with the Maximum Likelihood criterion. We prune
phrase translation entries by their probabilities. The
maximum number of tokens in Arabic phrases is set
to 5 for all conditions.
Our decoder is a phrase-based multi-stack imple-
5
mentation of the log-linear model similar to Pharaoh
(Koehn et al, 2003). Like other log-linear model
based decoders, active features in our translation en-
gine include translation models in two directions,
lexicon weights in two directions, language model,
distortion model, and sentence length penalty. These
feature weights are tuned on the dev set to achieve
optimal translation performance using downhill sim-
plex method (Och and Ney, 2002). The language
model is a statistical trigram model estimated with
Modified Kneser-Ney smoothing (Chen and Good-
man, 1996) using all English sentences in the paral-
lel training data.
We measure translation performance by the
BLEU score (Papineni et al, 2002) and Translation
Error Rate (TER) (Snover et al, 2006) with one ref-
erence for each hypothesis. Word alignment mod-
els trained with different constraints are compared
to show their effects on the resulting phrase transla-
tion tables and the final translation performance.
3.2 Translation Results
Our baseline word alignment model is the word-to-
word Hidden Markov Model (Vogel et al, 1996).
Basic models in two translation directions are
trained simultaneously where statistics of two direc-
tions are shared to learn symmetric translation lexi-
con and word alignments with high precision moti-
vated by (Zens et al, 2004) and (Liang et al, 2006).
The baseline translation results (BLEU and TER) on
the dev and test set are presented in the line ?HMM?
of Table 1. We also compare with results of IBM
Model-4 word alignments implemented in GIZA++
toolkit (Och and Ney, 2003).
We study and compare two types of constraint and
see how they affect word alignments and translation
output. One is based on the entropy principle as de-
scribed in Section 2.1, where ? is set to 0.9; The
other is based on bilingual latent semantic analysis.
For the simple bag-of-word bilingual LSA as de-
scribed in Section 2.2.1, after SVD on the sparse ma-
trix using the toolkit SVDPACK (Berry et al, 1993),
all source and target words are projected into a low-
dimensional (R = 88) LSA-space. Word pair se-
mantic constrains are calculated based on their sim-
ilarity as in Equ. 3 before word alignment training.
Like the baseline, we perform 6 iterations of IBM
Model-1 training and then 4 iteration of HMM train-
ing. The semantic constraints are used to guide word
alignment model training for each iteration. The
BLEU score and TER with this constraint are shown
in the line ?BiLSA-1? of Table 1.
To exploit word alignment statistics in bilingual
LSA as described in Section 2.2.2, we dump out the
statistics of the baseline word alignment model and
use them to construct the sparse matrix. We find
low-dimensional representation (R = 67) of English
words and Arabic words and use their similarity to
establish semantic constraints as in Equ. 4. The
training procedure is the same as the baseline and
?BiLSA-1?. The translation results with these word
alignments are shown as ?BiLSA-2? in Table 1.
As Table 1 shows, when the entropy based con-
straints are applied, BLEU score improves 0.5 point
on the test set. Clearly, when bilingual LSA con-
straints are applied, translation performance can be
improved up to 1.6 BLEU points. We also observe
that TER can drop 2.1 points with the ?BiLSA-1?
constraint.
While ?BiLSA-1? constraint performs better on
the test set, ?BiLSA-2? constraint achieves slightly
higher BLEU score on the dev set. We then
try a simple combination of these two types
of constraints, that is the geometric mean of
ConBiLSA?1(f, e) andConBiLSA?2(f, e), and find
out that BLEU score can be improved a little bit fur-
ther on both sets as the line ?Mix? shows.
We notice that the relatively simpler HMM model
can perform comparable or better than the sophis-
ticated Model-4 when proper constraints are active
in guiding word alignment model training. We also
try to put constraints in Model-4. As the Equation
1 implies, when a word-to-word generative proba-
bility is needed, one should multiply corresponding
lexicon entry in the t-table with the word pair con-
straint. We simply modify the GIZA++ toolkit (Och
and Ney, 2003) by always weighting lexicon proba-
bilities with soft constraints during iterative model
training, and obtain 0.7% TER reduction on both
sets and 0.4% BLEU improvement on the test set.
3.3 Analysis
To understand how prior knowledge encoded as soft
constraints plays a role in guiding word alignment
training, we compare statistics of different word
alignment models. We find that our baseline HMM
6
Table 1: Translation Results with different word
alignments.
BLEU TERAlignments
dev test dev test
Model-4 0.310 0.296 0.528 0.530
+Mix 0.306 0.300 0.521 0.523
HMM 0.289 0.288 0.543 0.542
+Entropy 0.289 0.293 0.534 0.536
+BiLSA-1 0.294 0.300 0.531 0.521
+BiLSA-2 0.298 0.292 0.530 0.528
+Mix 0.302 0.304 0.532 0.524
generates 2.6% less number of total word links than
that of Model-4. Part of the reason is that mod-
els of two directions in the baseline are trained si-
multaneously. The requirement of bi-directional ev-
idence places a certain constraint on word align-
ments. When ?BiLSA-1? constraints are applied in
the baseline model, 2.7% less number of total word
links are hypothesized, and consequently, less num-
ber of Arabic n-gram translations in the final phrase
translation table are induced. The observation sug-
gests that the constraints improve word alignment
precision and accuracy of phrase translation tables
as well.
 
bAl_ mrM mAl _tk 
in your esophagus 
HMM 
bAl_ mrM mAl _tk 
in your esophagus 
+BiLSA-1 
bAl_ mrM mAl _tk 
in your esophagus 
Model-4 
(in) (esophagus) gloss (ownership) (yours) 
Figure 4: An example of word alignments under dif-
ferent models
Figure 4 shows example word alignments of a par-
tial sentence pair. The complete English sentence is
?have you ever had like any reflux diseases in your
esophagus?. We notice that the Arabic word ?mrM?
(means esophagus) appears only once in the corpus.
Some of the word pair constraints are listed in Ta-
ble 2. The example demos that due to reasonable
constraints placed in word alignment training, the
link to ? tK? is corrected and consequently we have
accurate word translation for the Arabic singleton
Table 2: Word pair constraint values
English e Arabic f ConBiLSA?1(f, e)
esophagus mrM 0.6424
mAl 0.1819
tk 0.2897
your mrM 0.6319
mAl 0.4930
tk 0.9672
?mrM?.
4 Related Work
Heuristics based on co-occurrence analysis, such as
point-wise mutual information or Dice coefficients
, have been shown to be indicative for word align-
ments (Zhang and Vogel, 2005; Melamed, 2000).
The framework presented in this paper demonstrates
the possibility of taking heuristics as constraints
guiding statistical generative word alignment model
training. Their effectiveness can be expected espe-
cially when data sparseness is severe.
Discriminative word alignment models, such as
Ittycheriah and Roukos (2005); Moore (2005);
Blunsom and Cohn (2006), have received great
amount of study recently. They have proven that lin-
guistic knowledge is useful in modeling word align-
ments under log-linear distributions as morphologi-
cal, semantic or syntactic features. Our framework
proposes to exploit these features differently by tak-
ing them as soft constraints of translation lexicon un-
der a generative model.
While word alignments can help identifying se-
mantic relations (van der Plas and Tiedemann,
2006), we proceed in the reverse direction. We in-
vestigate the impact of semantic constraints on sta-
tistical word alignment models as prior knowledge.
In (Ma et al, 2004), bilingual semantic maps are
constructed to guide word alignment. The frame-
work we proposed seamlessly integrates derived se-
mantic similarities into a statistical word alignment
model. And we extended monolingual latent seman-
tic analysis in bilingual applications.
Toutanova et al (2002) augmented bilingual sen-
tence pairs with part-of-speech tags as linguistic
constraints for HMM-based word alignments. The
constraints between tags are automatically learned
in a parallel generative procedure along with lex-
7
icon. We have introduced hidden tags between a
word pair to specialize their soft constraints, which
serve as prior knowledge that will be used in guiding
word alignment model training. Constraint between
tags are embedded into the word to word generative
process.
5 Conclusions and Future Work
We have presented a simple and effective framework
to incorporate prior knowledge such as heuristics
or linguistic features into statistical generative word
alignment models. Prior knowledge serves as soft
constraints that shall be placed on translation lexi-
con to guide word alignment model training and dis-
ambiguation during Viterbi alignment process. We
studied two types of constraints that can be obtained
automatically from data and showed improved per-
formance (up to 1.6% absolute BLEU increase or
2.1% absolute TER reduction) in translating dialec-
tical Arabic into English. Future work includes im-
plementing the idea in alternative alignment mod-
els and also exploiting prior knowledge derived from
such as manually-aligned data and pre-existing lin-
guistic resources.
AcknowledgementWe thank Mohamed Afify for
discussions and the anonymous reviewers for sug-
gestions.
References
J. R. Bellegarda. 2000. Exploiting latent semantic informa-
tion in statistical language modeling. Proc. of the IEEE,
88(8):1279?1296, August.
M. Berry, T. Do, and S. Varadhan. 1993. Svdpackc (version
1.0) user?s guide. Tech. report cs-93-194, University of Ten-
nessee, Knoxville, TN.
P. Blunsom and T. Cohn. 2006. Discriminative word alignment
with conditional random fields. In Proc. of COLING/ACL,
pages 65?72.
P. Brown, S. Della Pietra, V. Della Pietra, and R. Mercer. 1993.
The mathematics of machine translation: Parameter estima-
tion. Computational Linguistics, 19:263?312.
S. F. Chen and J. Goodman. 1996. An empirical study of
smoothing techniques for language modeling. In Proc. of
ACL, pages 310?318.
S. C. Deerwester, S. T. Dumais, T. K. Landauer, G. W. Furnas,
and R. A. Harshman. 1990. Indexing by latent semantic
analysis. Journal of the American Society of Information
Science, 41(6):391?407.
A. Fraser and D. Marcu. 2006. Semi-supervised training for
statistical word alignment. In Proc. of COLING/ACL, pages
769?776.
A. Ittycheriah and S. Roukos. 2005. A maximum entropy word
aligner for arabic-english machine translation. In Proc. of
HLT/EMNLP, pages 89?96.
P. Koehn, F. Och, and D. Marcu. 2003. Statistical phrase-based
translation. In Proc. of HLT-NAACL.
LDC, 2002. Buckwalter Arabic Morphological Analyzer Ver-
sion 1.0. LDC Catalog Number LDC2002L49.
P. Liang, B. Taskar, and D. Klein. 2006. Alignment by agree-
ment. In Proc. of HLT/NAACL, pages 104?111.
Q. Ma, K. Kanzaki, Y. Zhang, M. Murata, and H. Isahara.
2004. Self-organizing semantic maps and its application to
word alignment in japanese-chinese parallel corpora. Neural
Netw., 17(8-9):1241?1253.
I. Dan. Melamed. 2000. Models of translational equivalence
among words. Computational Linguistics, 26(2):221?249.
R. C. Moore. 2005. A discriminative framework for bilingual
word alignment. In Proc. of HLT/EMNLP, pages 81?88.
F. J. Och and H. Ney. 2002. Discriminative training and max-
imum entropy models for statistical machine translation. In
Proc. of ACL, pages 295?302.
F. J. Och and H. Ney. 2003. A systematic comparison of vari-
ous statistical alignment models. Computational Linguistics,
29(1):19?51.
K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002. Bleu: a
method for automatic evaluation of machine translation. In
Proc. of ACL, pages 311?318.
M. Snover, B. Dorr, R. Schwartz, L. Micciulla, and J. Makhoul.
2006. A study of translation edit rate with targeted human
annotation. In Proc. of AMTA.
K. Toutanova, H. T. Ilhan, and C. Manning. 2002. Extentions
to HMM-based statistical word alignment models. In Proc.
of EMNLP.
Lonneke van der Plas and Jo?rg Tiedemann. 2006. Finding syn-
onyms using automatic word alignment and measures of dis-
tributional similarity. In Proc. of the COLING/ACL 2006
Main Conference Poster Sessions, pages 866?873.
S. Vogel, H. Ney, and C. Tillmann. 1996. HMM based word
alignment in statistical translation. In Proc. of COLING.
B. Xiang, K. Nguyen, L. Nguyen, R. Schwartz, and J. Makhoul.
2006. Morphological decomposition for arabic broadcast
news transcription. In Proc. of ICASSP, pages 1089?1092.
R. Zens, E. Matusov, and H. Ney. 2004. Improved word align-
ment using a symmetric lexicon model. In Proc. of COL-
ING, pages 36?42.
Y. Zhang and S. Vogel. 2005. Competitive grouping in inte-
grated phrase segmentation and alignment model. In Proc.
of the ACL Workshop on Building and Using Parallel Texts,
pages 159?162.
8
Proceedings of ACL-08: HLT, pages 81?88,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
Phrase Table Training For Precision and Recall:
What Makes a Good Phrase and a Good Phrase Pair?
Yonggang Deng? , Jia Xu+ and Yuqing Gao?
?IBM T.J. Watson Research Center, Yorktown Heights, NY 10598, USA
{ydeng,yuqing}@us.ibm.com
+Chair of Computer Science VI, RWTH Aachen University, D-52056 Aachen, Germany
xujia@cs.rwth-aachen.de
Abstract
In this work, the problem of extracting phrase
translation is formulated as an information re-
trieval process implemented with a log-linear
model aiming for a balanced precision and re-
call. We present a generic phrase training al-
gorithm which is parameterized with feature
functions and can be optimized jointly with
the translation engine to directly maximize
the end-to-end system performance. Multiple
data-driven feature functions are proposed to
capture the quality and confidence of phrases
and phrase pairs. Experimental results demon-
strate consistent and significant improvement
over the widely used method that is based on
word alignment matrix only.
1 Introduction
Phrase has become the standard basic translation
unit in Statistical Machine Translation (SMT) since
it naturally captures context dependency and models
internal word reordering. In a phrase-based SMT
system, the phrase translation table is the defining
component which specifies alternative translations
and their probabilities for a given source phrase. In
learning such a table from parallel corpus, two re-
lated issues need to be addressed (either separately
or jointly): which pairs are considered valid trans-
lations and how to assign weights, such as proba-
bilities, to them. The first problem is referred to as
phrase pair extraction, which identifies phrase pairs
that are supposed to be translations of each other.
Methods have been proposed, based on syntax, that
take advantage of linguistic constraints and align-
ment of grammatical structure, such as in Yamada
and Knight (2001) and Wu (1995). The most widely
used approach derives phrase pairs from word align-
ment matrix (Och and Ney, 2003; Koehn et al,
2003). Other methods do not depend on word align-
ments only, such as directly modeling phrase align-
ment in a joint generative way (Marcu and Wong,
2002), pursuing information extraction perspective
(Venugopal et al, 2003), or augmenting with model-
based phrase pair posterior (Deng and Byrne, 2005).
Using relative frequency as translation probabil-
ity is a common practice to measure goodness of
a phrase pair. Since most phrases appear only a
few times in training data, a phrase pair translation
is also evaluated by lexical weights (Koehn et al,
2003) or term weighting (Zhao et al, 2004) as addi-
tional features to avoid overestimation. The transla-
tion probability can also be discriminatively trained
such as in Tillmann and Zhang (2006).
The focus of this paper is the phrase pair extrac-
tion problem. As in information retrieval, precision
and recall issues need to be addressed with a right
balance for building a phrase translation table. High
precision requires that identified translation candi-
dates are accurate, while high recall wants as much
valid phrase pairs as possible to be extracted, which
is important and necessary for online translation that
requires coverage. In the word-alignment derived
phrase extraction approach, precision can be im-
proved by filtering out most of the entries by using
a statistical significance test (Johnson et al, 2007).
On the other hand, there are valid translation pairs
in the training corpus that are not learned due to
word alignment errors as shown in Deng and Byrne
(2005).
81
We would like to improve phrase translation ac-
curacy and at the same time extract as many as pos-
sible valid phrase pairs that are missed due to in-
correct word alignments. One approach is to lever-
age underlying word alignment quality such as in
Ayan and Dorr (2006). In this work, we present a
generic discriminative phrase pair extraction frame-
work that can integrate multiple features aiming to
identify correct phrase translation candidates. A sig-
nificant deviation from most other approaches is that
the framework is parameterized and can be opti-
mized jointly with the decoder to maximize transla-
tion performance on a development set. Within the
general framework, the main work is on investigat-
ing useful metrics. We employ features based on
word alignment models and alignment matrix. We
also propose information metrics that are derived
from both bilingual and monolingual perspectives.
All these features are data-driven and independent of
languages. The proposed phrase extraction frame-
work is general to apply linguistic features such as
semantic, POS tags and syntactic dependency.
2 A Generic Phrase Training Procedure
Let e = eI1 denote an English sentence and let
f = fJ1 denote its translation in a foreign lan-
guage, say Chinese. Phrase extraction begins with
sentence-aligned parallel corpora {(ei, fi)}. We use
E = eieib and F = f
je
jb
to denote an English and
foreign phrases respectively, where ib(jb) is the po-
sition in the sentence of the beginning word of the
English(foreign) phrase and ie(je) is the position of
the ending word of the phrase.
We first train word alignment models and will use
them to evaluate the goodness of a phrase and a
phrase pair. Let fk(E,F ), k = 1, 2, ? ? ? ,K be K
feature functions to be used to measure the quality
of a given phrase pair (E,F ). The generic phrase
extraction procedure is an evaluation, ranking, fil-
tering, estimation and tuning process, presented in
Algorithm 1.
Step 1 (line 1) is the preparation stage. Begin-
ning with a flat lexicon, we train IBM Model-1 word
alignment model with 10 iterations for each trans-
lation direction. We then train HMM word align-
ment models (Vogel et al, 1996) in two directions
simultaneously by merging statistics collected in the
Algorithm 1 A Generic Phrase Training Procedure
1: Train Model-1 and HMM word alignment models
2: for all sentence pair (e, f) do
3: Identify candidate phrases on each side
4: for all candidate phrase pair (E,F ) do
5: Calculate its feature function values fk
6: Obtain the score q(E,F ) =
?K
k=1 ?kfk(E,F )
7: end for
8: Sort candidate phrase pairs by their final scores q
9: Find the maximum score qm = max q(E,F )
10: for all candidate phrase pair (E,F ) do
11: If q(E,F ) ? qm? ? , dump the pair into the pool
12: end for
13: end for
14: Built a phrase translation table from the phrase pair pool
15: Discriminatively train feature weights ?k and threshold ?
E-step from two directions motivated by Zens et al
(2004) with 5 iterations. We use these models to de-
fine the feature functions of candidate phrase pairs
such as phrase pair posterior distribution. More de-
tails will be given in Section 3.
Step 2 (line 2) consists of phrase pair evalua-
tion, ranking and filtering. Usually all n-grams up
to a pre-defined length limit are considered as can-
didate phrases. This is also the place where lin-
guistic constraints can be applied, say to avoid non-
compositional phrases (Lin, 1999). Each normalized
feature score derived from word alignment models
or language models will be log-linearly combined
to generate the final score. Phrase pair filtering is
simply thresholding on the final score by comparing
to the maximum within the sentence pair. Note that
under the log-linear model, applying threshold for
filtering is equivalent to comparing the ?likelihood?
ratio.
Step 3 (line 14) pools all candidate phrase pairs
that pass the threshold testing and estimates the fi-
nal phrase translation table by maximum likelihood
criterion. For each candidate phrase pair which is
above the threshold, we assign HMM-based phrase
pair posterior as its soft count when dumping them
into the global phrase pair pool. Other possibilities
for the weighting include assigning constant one or
the exponential of the final score etc.
One of the advantages of the proposed phrase
training algorithm is that it is a parameterized pro-
cedure that can be optimized jointly with the trans-
82
lation engine to minimize the final translation errors
measured by automatic metrics such as BLEU (Pa-
pineni et al, 2002). In the final step 4 (line 15), pa-
rameters {?k, ?} are discriminatively trained on a
development set using the downhill simplex method
(Nelder and Mead, 1965).
This phrase training procedure is general in the
sense that it is configurable and trainable with dif-
ferent feature functions and their parameters. The
commonly used phrase extraction approach based
on word alignment heuristics (referred as ViterbiEx-
tract algorithm for comparison in this paper) as de-
scribed in (Och, 2002; Koehn et al, 2003) is a spe-
cial case of the algorithm, where candidate phrase
pairs are restricted to those that respect word align-
ment boundaries.
We rely on multiple feature functions that aim to
describe the quality of candidate phrase translations
and the generic procedure to figure out the best way
of combining these features. A good feature func-
tion pops up valid translation pairs and pushes down
incorrect ones.
3 Features
Now we present several feature functions that we in-
vestigated to help extracting correct phrase transla-
tions. All these features are data-driven and defined
based on models, such as statistical word alignment
model or language model.
3.1 Model-based Phrase Pair Posterior
In a statistical generative word alignment model
(Brown et al, 1993), it is assumed that (i) a random
variable a specifies how each target word fj is gen-
erated by (therefore aligned to) a source 1 word eaj ;
and (ii) the likelihood function f(f ,a|e) specifies a
generative procedure from the source sentence to the
target sentence. Given a phrase pair in a sentence
pair, there will be many generative paths that align
the source phrase to the target phrase. The likelihood
of those generative procedures can be accumulated
to get the likelihood of the phrase pair (Deng and
Byrne, 2005). This is implemented as the summa-
tion of the likelihood function over all valid hidden
word alignments.
1The word source and target are in the sense of word align-
ment direction, not as in the source-channel formulation.
More specifically, let A(j1,j2)(i1,i2) be the set of word
alignment a that aligns the source phrase ej1i1 to the
target phrase f j2j1 (links to NULL word are ignored
for simplicity):
A(j1,j2)(i1,i2) = {a : aj ? [i1, i2] iff j ? [j1, j2]}
The alignment set given a phrase pair ignores those
pairs with word links across the phrase boundary.
Consequently, the phrase-pair posterior distribution
is defined as
P?(e
i2
i1 ? f
j2
j1 |e, f) =
?
a?A
(j1,j2)
(i1,i2)
f(a, f |e; ?)
?
a f(a, f |e; ?)
.(1)
Switching the source and the target, we can obtain
the posterior distribution in another translation di-
rection. This distribution is applicable to all word
alignment models that follow assumptions (i) and
(ii). However, the complexity of the likelihood func-
tion could make it impractical to calculate the sum-
mations in Equation 1 unless an approximation is
applied.
Several feature functions will be defined on top of
the posterior distribution. One of them is based on
HMM word alignment model. We use the geometric
mean of posteriors in two translation directions as
a symmetric metric for phrase pair quality evalua-
tion function under HMM alignment models. Table
1 shows the phrase pair posterior matrix of the ex-
ample.
Replacing the word alignment model with IBM
Model-1 is another feature function that we added.
IBM Model-1 is simple yet has been shown to be
effective in many applications (Och et al, 2004).
There is a close form solution to calculate the phrase
pair posterior under Model-1. Moreover, word to
word translation table under HMM is more concen-
trated than that under Model-1. Therefore, the pos-
terior distribution evaluated by Model-1 is smoother
and potentially it can alleviate the overestimation
problem in HMM especially when training data size
is small.
3.2 Bilingual Information Metric
Trying to find phrase translations for any possible n-
gram is not a good idea for two reasons. First, due
to data sparsity and/or alignment model?s capabil-
ity, there would exist n-grams that cannot be aligned
83
    f1                  f2                 f3 
(that)   (is)   (what) 
 
 
what?s   that 
  e1                e2 
e11 e
2
1 e
2
2 HBL(f
j2
j1
)
f11 0.0006 0.012 0.89 0.08
f21 0.0017 0.035 0.343 0.34
f31 0.07 0.999 0.0004 0.24
f22 0.03 0.0001 0.029 0.7
f32 0.89 0.006 0.006 0.05
f33 0.343 0.002 0.002 0.06
HBL(e
i2
i1
) 0.869 0.26 0.70
Table 1: Phrase pair posterior distribution for the example
well, for instance, n-grams that are part of a para-
phrase translation or metaphorical expression. To
give an example, the unigram ?tomorrow? in ?the day
after tomorrow? whose Chinese translation is a sin-
gle word ???. Extracting candidate translations
for such kind of n-grams for the sake of improving
coverage (recall) might hurt translation quality (pre-
cision). We will define a confidence metric to esti-
mate how reliably the model can align an n-gram in
one side to a phrase on the other side given a par-
allel sentence. Second, some n-grams themselves
carry no linguistic meaning; their phrase translations
can be misleading, for example non-compositional
phrases (Lin, 1999). We will address this in section
3.3.
Given a sentence pair, the basic assumption is that
if the HMM word alignment model can align an En-
glish phrase well to a foreign phrase, the posterior
distribution of the English phrase generating all for-
eign phrases on the other side is significantly biased.
For instance, the posterior of one foreign phrase is
far larger than that of the others. We use the entropy
of the posterior distribution as the confidence metric:
HBL(e
i2
i1 |e, f) = H(P??HMM (e
i2
i1 ? ?)) (2)
where H(P ) = ?
?
x P (x) logP (x) is the entropy
of a distribution P (x), P??HMM (e
i2
i1 ? ?) is the
normalized probability (sum up to 1) of the pos-
terior P?HMM (e
i2
i1 ? ?) as defined in Equation 1.
Low entropy signals a high confidence that the En-
glish phrase can be aligned correctly. On the other
hand, high entropy implies ambiguity presented in
discriminating the correct foreign phrase from the
others from the viewpoint of the model.
Similarly we calculate the confidence metric of
aligning a foreign phrase correctly with the word
alignment model in foreign to English direction. Ta-
ble 1 shows the entropy of phrases. The unigram
of foreign side f22 is unlikely to survive with such
high ambiguity. Adding the entropy in two direc-
tions defines the bilingual information metric as an-
other feature function, which describes the reliabil-
ity of aligning each phrase correctly by the model.
Note that we used HMM word alignment model to
find the posterior distribution. Other models such as
Model-1 can be applied in the same way. This fea-
ture function quantitatively captures the goodness of
phrases. During phrase pair ranking, it can help
to move upward phrases that can be aligned well
and push downward phrases that are difficult for the
model to find correct translations.
3.3 Monolingual Information Metric
Now we turn to monolingual resources to evaluate
the quality of an n-gram being a good phrase. A
phrase in a sentence is specified by its boundaries.
We assume that the boundaries of a good phrase
should be the ?right? place to break. More generally,
we want to quantify how effective a word bound-
ary is as a phrase boundary. One would perform say
NP-chunking or parsing to avoid splitting a linguis-
tic constituent. We apply a language model (LM)
to describe the predictive uncertainty (PU ) between
words in two directions.
Given a history wn?11 , a language model specifies
a conditional distribution of the future word being
predicted to follow the history. We can find the en-
tropy of such pdf: HLM (w
n?1
1 ) = H(P (?|w
n?1
1 )).
So given a sentencewN1 , the PU of the boundary be-
tween word wi and wi+1 is established by two-way
entropy sum using a forward and backward language
model: PU(wN1 , i) = HLMF (w
i
1) + HLMB(w
i+1
N )
We assume that the higher the predictive uncer-
tainty is, the more likely the left or right part of the
word boundary can be ?cut-and-pasted? to form an-
other reasonable sentence. So a good phrase is char-
acterized with high PU values on the boundaries.
For example, in ?we want to have a table near the
window?, the PU value of the point after ?table? is
0.61, higher than that between ?near? and ?the? 0.3,
using trigram LMs.
With this, the feature function derived from
84
monolingual clue for a phrase pair can be defined
as the product of PUs of the four word boundaries.
3.4 Word Alignments Induced Metric
The widely used ViterbiExtract algorithm relies
on word alignment matrix and no-crossing-link as-
sumption to extract phrase translation candidates.
Practically it has been proved to work well. How-
ever, discarding correct phrase pairs due to incorrect
word links leaves room for improving recall. This
is especially true for not significantly large training
corpora. Provided with a word alignment matrix,
we define within phrase pair consistency ratio (WP-
PCR) as another feature function. WPPCR was used
as one of the scores in (Venugopal et al, 2003) for
phrase extraction. It is defined as the number of con-
sistent word links associated with any words within
the phrase pair divided by the number of all word
links associated with any words within the phrase
pair. An inconsistent link connects a word within
the phrase pair to a word outside the phrase pair. For
example, the WPPCR for (e21, f
2
1 ) in Table 1 is 2/3.
As a special case, the ViterbiExtract algorithm ex-
tracts only phrase pairs with WPPCR is 1.
To further discriminate the pairs with higher WP-
PCR from those with lower ratio, we apply a Bi-
Linear Transform (BLT) (Oppenheim and Schafer,
1989) mapping. BLT is commonly used in sig-
nal processing to attenuate the low frequency parts.
When used to map WPPCR, it exaggerates the dif-
ference between phrase pairs with high WPPCR and
those with low WPPCR, making the pairs with low
ratio more unlikely to be selected as translation can-
didates. One of the nice properties of BLT is that
there is a parameter that can be changed to adjust
the degree of attenuation, which provides another di-
mension for system optimization.
4 Experimental Results
We evaluate the effect of the proposed phrase extrac-
tion algorithm with translation performance. We do
experiments on IWSLT (Paul, 2006) 2006 Chinese-
English corpus. The task is to translate Chinese ut-
terances in travel domain into English. We report
only text (speech transcription) translation results.
The training corpus consists of 40K Chinese-
English parallel sentences in travel domain with to-
Eval Set 04dev 04test 05test 06dev 06test
# of sentences 506 500 506 489 500
# of words 2808 2906 3209 5214 5550
# of refs 16 16 16 7 7
Table 2: Dev/test set statistics
tal 306K English words and 295K Chinese words.
In the data processing step, Chinese characters are
segmented into words. English text are normalized
and lowercased. All punctuation is removed.
There are five sets of evaluation sentences in
tourism domain for development and test. Their
statistics are shown in Table 2. We will tune training
and decoding parameters on 06dev and report results
on other sets.
4.1 Training and Translation Setup
Our decoder is a phrase-based multi-stack imple-
mentation of the log-linear model similar to Pharaoh
(Koehn et al, 2003). Like other log-linear model
based decoders, active features in our transla-
tion engine include translation models in two di-
rections, lexicon weights in two directions, lan-
guage model, lexicalized distortion models, sen-
tence length penalty and other heuristics. These fea-
ture weights are tuned on the dev set to achieve op-
timal translation performance using downhill sim-
plex method. The language model is a statistical
trigram model estimated with Modified Kneser-Ney
smoothing (Chen and Goodman, 1996) using only
English sentences in the parallel training data.
Starting from the collection of parallel training
sentences, we build word alignment models in two
translation directions, from English to Chinese and
from Chinese to English, and derive two sets of
Viterbi alignments. By combining word alignments
in two directions using heuristics (Och and Ney,
2003), a single set of static word alignments is then
formed. Based on alignment models and word align-
ment matrices, we compare different approaches of
building a phrase translation table and show the fi-
nal translation results. We measure translation per-
formance by the BLEU (Papineni et al, 2002) and
METEOR (Banerjee and Lavie, 2005) scores with
multiple translation references.
85
BLEU Scores
Table 04dev 04test 05test 06dev 06test
HMM 0.367 0.407 0.473 0.200 0.190
Model-4 0.380 0.403 0.485 0.210 0.204
New 0.411 0.427 0.500 0.216 0.208
METEOR Scores
Table 04dev 04test 05test 06dev 06test
HMM 0.532 0.586 0.675 0.482 0.471
Model-4 0.540 0.593 0.682 0.492 0.480
New 0.568 0.614 0.691 0.505 0.487
Table 3: Translation Results
4.2 Translation Results
Our baseline phrase table training method is the
ViterbiExtract algorithm. All phrase pairs with re-
spect to the word alignment boundary constraint are
identified and pooled to build phrase translation ta-
bles with the Maximum Likelihood criterion. We
prune phrase translation entries by their probabili-
ties. The maximum number of words in Chinese and
English phrases is set to 8 and 25 respectively for all
conditions2. We perform online style phrase train-
ing, i.e., phrase extraction is not particular for any
evaluation set.
Two different word alignment models are trained
as the baseline, one is symmetric HMM word align-
ment model, the other is IBM Model-4 as imple-
mented in the GIZA++ toolkit (Och and Ney, 2003).
The translation results as measured by BLEU and
METEOR scores are presented in Table 3. We notice
that Model-4 based phrase table performs roughly
1% better in terms of both BLEU and METEOR
scores than that based on HMM.
We follow the generic phrase training procedure
as described in section 2. The most time consuming
part is calculating posteriors, which is carried out in
parallel with 30 jobs in less than 1.5 hours.
We use the Viterbi word alignments from HMM
to define within phrase pair consistency ratio as dis-
cussed in section 3.4. Although Table 3 implies that
Model-4 word alignment quality is better than that
of HMM, we did not get benefits by switching to
Model-4 to compute word alignments based feature
values.
In estimating phrase translation probability, we
use accumulated HMM-based phrase pair posteriors
2We chose large numbers for phrase length limit to build a
strong baseline and to avoid impact of longer phase length.
as their ?soft? frequencies and then the final trans-
lation probability is the relative frequency. HMM-
based posterior was shown to be better than treating
each occurrence as count one.
Once we have computed all feature values for all
phrase pairs in the training corpus, we discrimina-
tively train feature weights ?ks and the threshold
? using the downhill simplex method to maximize
the BLEU score on 06dev set. Since the translation
engine implements a log-linear model, the discrim-
inative training of feature weights in the decoder
should be embedded in the whole end-to-end system
jointly with the discriminative phrase table training
process. This is globally optimal but computation-
ally demanding. As a compromise, we fix the de-
coder feature weights and put all efforts on optimiz-
ing phrase training parameters to find out the best
phrase table.
The translation results with the discriminatively
trained phrase table are shown as the row of ?New?
in Table 3. We observe that the new approach is con-
sistently better than the baseline ViterbiExtract algo-
rithmwith either Model-4 or HMMword alignments
on all sets. Roughly, it has 0.5% higher BLEU score
on 2006 sets and 1.5% to 3% higher on other sets
than Model-4 based ViterbiExtract method. Similar
superior results are observed when measured with
METEOR score.
5 Discussions
The generic phrase training algorithm follows an in-
formation retrieval perspective as in (Venugopal et
al., 2003) but aims to improve both precision and
recall with the trainable log-linear model. A clear
advantage of the proposed approach over the widely
used ViterbiExtract method is trainability. Under the
general framework, one can put as many features as
possible together under the log-linear model to eval-
uate the quality of a phrase and a phase pair. The
phrase table extracting procedure is trainable and
can be optimized jointly with the translation engine.
Another advantage is flexibility, which is pro-
vided partially by the threshold ? . As the figure
1 shows, when we increase the threshold by al-
lowing more candidate phrase pair hypothesized as
valid translation, we observe the phrase table size in-
creases monotonically. On the other hand, we notice
86
1
2
3
4
5
6
7
8
91
01
11
21
31
41
5
0.170.180.190.
2
Thr
esh
old
Thr
esh
oldi
ng E
ffec
ts
Translation Performance
0
5
10
1555.
566.5
Log10 of the number of Entries in the PhraseTable
BLE
U
Phr
ase
tabl
e S
ize
Figure 1: Thresholding effects on translation perfor-
mance and phrase table size
that the translation performance improves gradually.
After reaching its peak, the BLEU score drops as the
threshold ? increases. When ? is large enough, the
translation performance is not changing much but
still worse than the peak value. It implies a balanc-
ing process between precision and recall. The final
optimal threshold ? is around 5.
The flexibility is also enabled by multiple con-
figurable features used to evaluate the quality of a
phrase and a phrase pair. Ideally, a perfect combina-
tion of feature functions divides the correct and in-
correct candidate phrase pairs within a parallel sen-
tence into two ordered separate sets. We use feature
functions to decide the order and the threshold ? to
locate the boundary guided with a development set.
So the main issue to investigate now is which
features are important and valuable in ranking can-
didate phrase pairs. We propose several informa-
tion metrics derived from posterior distribution, lan-
guage model and word alignments as feature func-
tions. The ViterbiExtract is a special case where
a single binary feature function defined from word
alignments is used. Its good performance (as shown
in Table 3) suggests that word alignments are very
indicative of phrase pair quality. So we design com-
parative experiments to capture word alignment im-
pact only. We start with basic features that in-
clude model-based posterior, bilingual and mono-
lingual information metrics. Its results on different
test sets are presented in the ?basic? row of Table 4.
We add word alignment feature (?+align? row), and
Features 04dev 04test 05test 06dev 06test
basic 0.393 0.406 0.496 0.205 0.199
+align 0.401 0.429 0.502 0.208 0.196
+align BLT 0.411 0.427 0.500 0.216 0.208
Table 4: Translation Results (BLEU) of discriminative
phrase training approach using different features
75K
250K 1
32K
PP1
PP3
PP2
Model?4
New
Features 04dev 04test 05test 06dev 06test
PP2 0.380 0.395 0.480 0.207 0.202
PP1+PP2 0.380 0.403 0.485 0.210 0.204
PP2+PP3 0.411 0.427 0.500 0.216 0.208
PP1+PP2+PP3 0.412 0.432 0.500 0.217 0.214
Table 5: Translation Results (BLEU) of Different Phrase
Pair Combination
then apply bilinear transform to the consistency ratio
WPPCR as described in section 3.4 (?+align BLT?
row). The parameter controlling the degree of atten-
uation in BLT is also optimized together with other
feature weights.
With the basic features, the new phrase extraction
approach performs better than the baseline method
with HMM word alignment models but similar to
the baseline method with Model-4. With the word
alignment based feature WPPCR, we obtain a 2%
improvement on 04test set but not much on other
sets except slight degradation on 06test. Finally, ap-
plying BLT transform to WPPCR leads to additional
0.8 BLEU point on 06dev set and 1.2 point on 06test
set. This confirms the effectiveness of word align-
ment based features.
Now we compare the phrase table using the pro-
posed method to that extracted using the baseline
ViterbiExtract method with Model-4 word align-
ments. The Venn diagram in Table 5 shows how the
two phrase tables overlap with each other and size
of each part. As expected, they have a large num-
ber of common phrase pairs (PP2). The new method
is able to extract more phrase pairs than the base-
line with Model-4. PP1 is the set of phrase pairs
found by Model-4 alignments. Removing PP1 from
the baseline phrase table (comparing the first group
of scores) or adding PP1 to the new phrase table
87
(the second group of scores) overall results in no or
marginal performance change. On the other hand,
adding phrase pairs extracted by the new method
only (PP3) can lead to significant BLEU score in-
creases (comparing row 1 vs. 3, and row 2 vs. 4).
6 Conclusions
In this paper, the problem of extracting phrase trans-
lation is formulated as an information retrieval pro-
cess implemented with a log-linear model aiming for
a balanced precision and recall. We have presented
a generic phrase translation extraction procedure
which is parameterized with feature functions. It
can be optimized jointly with the translation engine
to directly maximize the end-to-end translation per-
formance. Multiple feature functions were investi-
gated. Our experimental results on IWSLT Chinese-
English corpus have demonstrated consistent and
significant improvement over the widely used word
alignment matrix based extraction method. 3
Acknowledgement We would like to thank Xi-
aodong Cui, Radu Florian and other IBM colleagues
for useful discussions and the anonymous reviewers
for their constructive suggestions.
References
N. Ayan and B. Dorr. 2006. Going beyond AER: An
extensive analysis of word alignments and their impact
on MT. In Proc. of ACL, pages 9?16.
S. Banerjee and A. Lavie. 2005. METEOR: An auto-
matic metric for MT evaluation with improved cor-
relation with human judgments. In Proc. of the ACL
Workshop on Intrinsic and Extrinsic Evaluation Mea-
sures for Machine Translation and/or Summarization,
pages 65?72.
P. Brown, S. Della Pietra, V. Della Pietra, and R. Mer-
cer. 1993. The mathematics of machine transla-
tion: Parameter estimation. Computational Linguis-
tics, 19:263?312.
S. F. Chen and J. Goodman. 1996. An empirical study of
smoothing techniques for language modeling. In Proc.
of ACL, pages 310?318.
Y. Deng and W. Byrne. 2005. HMM word and phrase
alignment for statistical machine translation. In Proc.
of HLT-EMNLP, pages 169?176.
3By parallelism, we have shown the feasibility and effec-
tiveness (results not presented here) of the proposed method in
handling millions of sentence pairs.
H. Johnson, J. Martin, G. Foster, and R. Kuhn. 2007. Im-
proving translation quality by discarding most of the
phrasetable. In Proc. of EMNLP-CoNLL, pages 967?
975.
P. Koehn, F. Och, and D.Marcu. 2003. Statistical phrase-
based translation. In Proc. of HLT-NAACL, pages 48?
54.
D. Lin. 1999. Automatic identification of non-
compositional phrases. In Proc. of ACL, pages 317?
324.
D. Marcu and D. Wong. 2002. A phrase-based, joint
probability model for statistical machine translation.
In Proc. of EMNLP, pages 133?139.
J. A. Nelder and R. Mead. 1965. A simplex method
for function minimization. Computer Journal, 7:308?
313.
F. J. Och and H. Ney. 2003. A systematic comparison of
various statistical alignment models. Computational
Linguistics, 29(1):19?51.
F. J. Och, D. Gildea, and et al 2004. A smorgasbord of
features for statistical machine translation. In Proc. of
HLT-NAACL, pages 161?168.
F. Och. 2002. Statistical Machine Translation: From
Single Word Models to Alignment Templates. Ph.D.
thesis, RWTH Aachen, Germany.
A. V. Oppenheim and R. W. Schafer. 1989. Discrete-
Time Signal Processing. Prentice-Hall.
K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002.
Bleu: a method for automatic evaluation of machine
translation. In Proc. of ACL, pages 311?318.
M. Paul. 2006. Overview of the IWSLT 2006 evaluation
campaign. In Proc. of IWSLT, pages 1?15.
C. Tillmann and T. Zhang. 2006. A discriminative global
training algorithm for statistical MT. In Proc. of ACL,
pages 721?728.
A. Venugopal, S. Vogel, and A. Waibel. 2003. Effective
phrase translation extraction from alignment models.
In Proc. of ACL, pages 319?326.
S. Vogel, H. Ney, and C. Tillmann. 1996. HMM based
word alignment in statistical translation. In Proc. of
the COLING.
D. Wu. 1995. An algorithm for simultaneously bracket-
ing parallel texts by aligning words. In Proc. of ACL,
pages 244?251.
K. Yamada and K. Knight. 2001. A syntax-based statis-
tical translation model. In Proc. of ACL, pages 523?
530.
R. Zens, E. Matusov, and H. Ney. 2004. Improved word
alignment using a symmetric lexicon model. In Proc.
of COLING, pages 36?42.
B. Zhao, S. Vogel, M. Eck, and A. Waibel. 2004. Phrase
pair rescoring with term weighting for statistical ma-
chine translation. In Proc. of EMNLP, pages 206?213.
88
Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 229?232,
Suntec, Singapore, 4 August 2009.
c
?2009 ACL and AFNLP
Optimizing Word Alignment Combination For Phrase Table Training
Yonggang Deng and Bowen Zhou
IBM T.J. Watson Research Center
Yorktown Heights, NY 10598, USA
{ydeng,zhou}@us.ibm.com
Abstract
Combining word alignments trained in
two translation directions has mostly re-
lied on heuristics that are not directly
motivated by intended applications. We
propose a novel method that performs
combination as an optimization process.
Our algorithm explicitly maximizes the ef-
fectiveness function with greedy search
for phrase table training or synchronized
grammar extraction. Experimental results
show that the proposed method leads to
significantly better translation quality than
existing methods. Analysis suggests that
this simple approach is able to maintain
accuracy while maximizing coverage.
1 Introduction
Word alignment is the process of identifying
word-to-word links between parallel sentences. It
is a fundamental and often a necessary step before
linguistic knowledge acquisitions, such as train-
ing a phrase translation table in phrasal machine
translation (MT) system (Koehn et al, 2003), or
extracting hierarchial phrase rules or synchronized
grammars in syntax-based translation framework.
Most word alignment models distinguish trans-
lation direction in deriving word alignment matrix.
Given a parallel sentence, word alignments in two
directions are established first, and then they are
combined as knowledge source for phrase train-
ing or rule extraction. This process is also called
symmetrization. It is a common practice in most
state of the art MT systems. Widely used align-
ment models, such as IBM Model serial (Brown
et al, 1993) and HMM , all assume one-to-many
alignments. Since many-to-many links are com-
monly observed in natural language, symmetriza-
tion is able to make up for this modeling limita-
tion. On the other hand, combining two direc-
tional alignments practically can lead to improved
performance. Symmetrization can also be real-
ized during alignment model training (Liang et al,
2006; Zens et al, 2004).
Given two sets of word alignments trained in
two translation directions, two extreme combina-
tion are intersection and union. While intersec-
tion achieves high precision with low recall, union
is the opposite. A right balance of these two ex-
treme cases would offer a good coverage with rea-
sonable accuracy. So starting from intersection,
gradually adding elements in the union by heuris-
tics is typically used. Koehn et al (2003) grow
the set of word links by appending neighboring
points, while Och and Hey (2003) try to avoid both
horizontal and vertical neighbors. These heuristic-
based combination methods are not driven explic-
itly by the intended application of the resulting
output. Ayan (2005) exploits many advanced ma-
chine learning techniques for general word align-
ment combination problem. However, human
annotation is required for supervised training in
those techniques.
We propose a new combination method. Like
heuristics, we aim to find a balance between in-
tersection and union. But unlike heuristics, com-
bination is carried out as an optimization process
driven by an effectiveness function. We evaluate
the impact of each alignment pair w.r.t. the target
application, say phrase table training, and gradu-
ally add or remove the word link that currently
can maximize the predicted benefit measured by
the effectiveness function. More specifically, we
consider the goal of word alignment combination
is for phrase table training, and we directly moti-
vate word alignment combination as a process of
maximizing the number of phrase translations that
can be extracted within a sentence pair.
2 Combination As Optimization Process
Given a parallel sentence (e = e
I
1
, f = f
J
1
), a
word link is represented by a pair of indices (i, j),
229
which means that Foreign word f
j
is aligned with
English word e
i
. The direction of word alignments
is ignored. Since the goal of word alignment com-
bination is for phrase table training, we first for-
mally define a phrase translation. Provided with
a set of static word alignments A, a phrase pair
(e
i
2
i
1
, f
j
2
j
1
) is considered translation of each other if
and only if there exists at least one word link be-
tween them and no cross phrase boundary links ex-
ist in A, i.e., for all (i, j) ? A, i ? [i
1
, i
2
] iff j ?
[j
1
, j
2
]. Notice that by this definition, it does not
matter whether boundary words of the phrase pairs
should be aligned or not. Let PP
n
(A) denote the
set of phrase pairs that can be extracted with A
where up to n boundary words are allowed to be
not-aligned, i.e., aligned to empty word NULL. As
can be imagined, increasing n would improve re-
call of phrase table but likely to hurt precision. For
word alignment combination, we focus on the set
with high accuracy where n = 0.
Let A
1
, A
2
denote two sets of word alignments
to be combined for the given sentence pair. For
instance, A
1
could be word alignments from En-
glish to foreign while A
2
the other direction. On
different setup, A
1
could be Model-4 alignments,
while A
2
is from HMM. In the first combination
method we presented in Algorithm 1, we start with
intersection A
I
. A
c
is the candidate link set to be
evaluated and appended to the combined set A. Its
initial value is the difference between union and
intersection. We assume that there is an effective-
ness function g(?) which quantitatively measures
the ?goodness? of a alignment set for the intended
application. A higher number indicates a better
alignment set. We use the function g to drive the
process. Each time, we identify the best word link
(
?
i,
?
j) in the candidate set that can maximize the
function g and append it to the current set A. This
process is repeated until the candidate set is empty
or adding any link in the set would lead to degra-
dation. Finally (line 15 to 21), we pickup word
links in the candidate set to align those uncov-
ered words. This is applied to maximize cover-
age, which is similar as the ?final? in (Koehn et al,
2003). Again, we use the function g(?) to rank the
word links in A
c
and sequentially append them to
A depending on current word coverage.
The algorithm clearly is a greedy search pro-
cedure that maximizes the function g. Since we
plan to take the combined word alignments for
phrase translation training, a natural choice for
g is the number of phrase pairs that can be ex-
tracted with the given alignment set. We choose
g(A) = |PP
0
(A)|, where we only count phrase
pairs that all boundary words are aligned. The
reason of putting a tight constraint is to maintain
phrase table accuracy while improving the cover-
age. By keeping track of the span of currently
aligned words, we can have efficient implemen-
tation of the function g.
Algorithm 1 Combination ofA
1
andA
2
as an Optimized
Expanding Process
1: A
I
= A
1
?A
2
, A
U
= A
1
?A
2
2: A = A
I
, A
c
= A
U
?A
I
3: total = g(A)
4: while A
c
6= ? do
5: curMax = max
(i,j)?A
c
g(A ? {(i, j)})
6: if curMax ? total then
7: (
?
i,
?
j) = argmax
(i,j)?A
c
g(A ? {(i, j)})
8: A = A ? {(
?
i,
?
j)}
9: A
c
= A
c
? {(
?
i,
?
j)}
10: total = curMax
11: else {adding any link will make it worse}
12: break
13: end if
14: end while
15: while A
c
6= ? do
16: (
?
i,
?
j) = argmax
(i,j)?A
c
g(A ? {(i, j)})
17: if e
?
i
is not aligned or f
?
j
is not aligned then
18: A = A ? {(
?
i,
?
j)}
19: end if
20: A
c
= A
c
? {(
?
i,
?
j)}
21: end while
22: return A
Alternatively, the optimization can go in oppo-
site direction. We start with the union A = A
U
,
and gradually remove the worse word link (
?
i,
?
j) =
argmax
(i,j)?A
c
g(A ? {(i, j)}) that could max-
imize the effectiveness function. Similarly, this
shrinking process is repeated until either candidate
set is empty or removing any link in the candidate
set would reduce the value of function g.
Other choice of ?goodness? function g is pos-
sible. For instance, one could consider syntactic
constraints, or weight phrase pairs differently ac-
cording to their global co-occurrence. The basic
idea is to implement the combination as an itera-
tive customized optimization process that is driven
by the application.
3 Experimental Results
We test the proposed new idea on Persian Farsi to
English translation. The task is to translate spoken
Farsi into English. We decode reference transcrip-
tion so recognition is not an issue. The training
230
data was provided by the DARPA TransTac pro-
gram. It consists of around 110K sentence pairs
with 850K English words in the military force
protection domain. We train IBM Model-4 using
GIZA++ toolkit (Och and Ney, 2003) in two trans-
lation directions and perform different word align-
ment combination. The resulting alignment set is
used to train a phrase translation table, where Farsi
phrases are limited to up to 6 words.
The quality of resulting phrase translation table
is measured by translation results. Our decoder
is a phrase-based multi-stack implementation of
the log-linear model similar to Pharaoh (Koehn et
al., 2003). Like other log-linear model based de-
coders, active features in our translation engine in-
clude translation models in two directions, lexicon
weights in two directions, language model, lexi-
calized reordering models, sentence length penalty
and other heuristics. These feature weights are
tuned on the dev set to achieve optimal transla-
tion performance evaluated by automatic metric.
The language model is a statistical 4-gram model
estimated with Modified Kneser-Ney smoothing
(Chen and Goodman, 1996) using only English
sentences in the parallel training data.
3.1 Phrase Table Comparison
We first study the impact of different word align-
ment combination methods on phrase translation
table, and compare our approaches to heuristic
based methods. The same English to Farsi and
Farsi to English Model-4 word alignments are
used, but we try different combination methods
and analysis the final alignment set and the result-
ing phase translation table. Table 1 presents some
statistics. Each row corresponds to a particular
combination. The first two are intersection (I) and
union (U). The next two methods are heuristic (H)
in (Och and Ney, 2003) and grow-diagonal (GD)
proposed in (Koehn et al, 2003). Our proposed
methods are presented in the following two rows:
one is optimization as an expanding process (OE),
the other is optimization as an shrinking process
(OS). In the last four rows, we add ?final? opera-
tion (line 15 to 21 in Algorithm 1).
For each method, we calculate the output align-
ment set size as a percentage of the union (the
2nd column) and resulting phrase table (PP
n
(A))
size (in thousand) with different constrain on the
maximum number of unaligned boundary words
n = 0, 1, 2 (the next 3 columns). As we can
see, the intersection has less than half of all word
links in the pool. This implies the underlying word
alignment quality leaves much room for improve-
ments, mainly due to data sparseness. Not sur-
prisingly, when relaxing unaligned boundary word
number from 0 to 2, the phrase table size increases
more than 7 times. This is the result of very low
recall of word alignments, consequently the esti-
mated phrase table PP
2
(A) has very low accu-
racy. Union suffers from the opposite problem:
many incorrect word links prevent good phrase
pairs from being extracted.
The two heuristic methods and our proposed
optimization approaches achieve somewhat a bal-
ance between I and U. By comparing size of
PP
0
(A) (3rd column), optimization methods are
able to identify much more phrase pairs with sim-
ilar size of alignment set. This confirms that the
new method is indeed moving to the desired di-
rection of extracting as many accurate (all bound-
ary words should be aligned) phrase pairs as pos-
sible. We still notice that ratio of |PP
2
(A)| and
|PP
0
(A)| (the last column) is high. We suspect
that the ratio of this two phrase table size might
somewhat be indicative of the phrase table accu-
racy, which is hard to estimate without manual an-
notation though.
Method
|A|
|A
U
|
|PP
0
| |PP
1
| |PP
2
|
|PP
2
|
|PP
0
|
I 45% 424 2047 3658 8.63
U 100% 354 555 578 1.63
H 78% 538 1225 1519 2.82
GD 82% 499 1081 1484 2.97
OS 84% 592 1110 1210 2.04
OE 78% 659 1359 1615 2.45
HF 95% 427 670 697 1.63
GDF 97% 412 647 673 1.63
OSF 89% 484 752 781 1.61
OEF 89% 476 739 768 1.61
Table 1: Statistics of word alignment set and the
resulting phrase table size (number of entries in
thousand (K)) with different combination methods
3.2 Translation Results
The ultimate goal of word alignment combination
is for building translation system. The quality of
resulting phrase tables is measured by automatic
translation metric. We have one dev set (1430 sen-
tences with 11483 running words), test set 1 (1390
sentences with 10334 running words) and test set
2 (417 sentences with 4239 running words). The
dev set and test set 1 are part of all available Farsi-
231
English parallel corpus. They are holdout from
training data as tuning and testing. The test set 2
is the standard NIST offline evaluation set, where
4 references are available for each sentence. The
dev and test set 1 are much closer to the training
set than the standard test set 2. We tune all fea-
ture weights automatically (Och, 2003) to maxi-
mize the BLEU (Papineni et al, 2002) score on
the dev set.
Table 2 shows BLEU score of different com-
bination methods on all three sets. Union per-
forms much worse on the dev and test1 than inter-
section, while intersection achieved the same per-
formance on test2 as union but with more than 6
times of phrase table size. Grow-diagonal (GD)
has more than 1 bleu point on test2 than intersec-
tion but with less than half of phrase table size.
The proposed new method OE is consistently bet-
ter than both heuristic methods GD and H, with
more than 1 point on dev/teset1 and 0.7 point on
test2. Comparing the last group to the middle one,
we can see the effect of the ?final? operation on
all four methods. Tabel 1 shows that after apply-
ing the final operation, phrase table size is cut into
half. When evaluated with automatic translation
metric, all four methods generally perform much
worse on dev and test1 that are close to training
data, but better on NIST standard test2. We ob-
serve half BLEU point improvement for optimiza-
tion method but marginal gain for heuristic-based
approaches. This suggest that the phrase table ac-
curacy get improved with the final operation. Op-
timization method directly tries to maximize the
number of phrase pairs that can be extracted. We
observe that it (OEF) is able to find more than
14% more phrase pairs than heuristic methods and
achieve 1 BLEU point gain than the best heuristic
method (GDF).
Method dev test1 test2
I 0.396 0.308 0.348
U 0.341 0.294 0.348
H 0.400 0.314 0.341
GD 0.391 0.314 0.360
OS 0.383 0.316 0.356
OE 0.410 0.329 0.367
HF 0.361 0.297 0.343
GDF 0.361 0.301 0.362
OSF 0.372 0.305 0.361
OEF 0.370 0.306 0.372
Table 2: Translation results (BLEU score) with
phrase tables trained with different word align-
ment combination methods
4 Conclusions
We presented a simple yet effective method for
word alignment symmetrization and combination
in general. The problem is formulated as an opti-
mization with greedy search driven by an effec-
tiveness function, which can be customized di-
rectly to maximum benefit for intended applica-
tions such as phrase table training or synchronized
grammar extraction in machine translation. Ex-
perimental results demonstrated consistent better
BLEU scores than the best heuristic method. The
optimization process can better maintain accuracy
while improving coverage.
The algorithm is generic and leaves much space
for variations. For instance, designing a better ef-
fectiveness function g, or considering a soft link
with some probability rather than binary 0/1 con-
nection would potentially be opportunities for fur-
ther improvement. On the other hand, the search
space of current algorithm is limited by the pool
of candidate set, it is possible to suggest new links
while driven by the target function.
Acknowledgments We thank the DARPA
TransTac program for funding and the anonymous
reviewers for their constructive suggestions.
References
N. F. Ayan. 2005. Combining Linguistic andMachine Learn-
ing Techniques for Word Alignment Improvement. Ph.D.
thesis, University of Maryland, College Park, November.
P. Brown, S. Della Pietra, V. Della Pietra, and R. Mercer.
1993. The mathematics of machine translation: Parameter
estimation. Computational Linguistics, 19:263?312.
S. F. Chen and J. Goodman. 1996. An empirical study of
smoothing techniques for language modeling. In Proc. of
ACL, pages 310?318.
P. Koehn, F. Och, and D. Marcu. 2003. Statistical phrase-
based translation. In Proc. of HLT-NAACL, pages 48?54.
P. Liang, B. Taskar, and D. Klein. 2006. Alignment by agree-
ment. In Proc. of HLT-NAACL, pages 104?111.
F. J. Och and H. Ney. 2003. A systematic comparison of
various statistical alignment models. Computational Lin-
guistics, 29(1):19?51.
F. J. Och. 2003. Minimum error rate training in statistical
machine translation. In Proc. of ACL, pages 160?167.
K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002. Bleu:
a method for automatic evaluation of machine translation.
In Proc. of ACL, pages 311?318.
R. Zens, E. Matusov, and H. Ney. 2004. Improved word
alignment using a symmetric lexicon model. In Proc. of
COLING, pages 36?42.
232
IBM MASTOR SYSTEM: Multilingual Automatic Speech-to-speech Translator * 
 
Yuqing Gao, Liang Gu, Bowen Zhou, Ruhi Sarikaya, Mohamed Afify, Hong-Kwang Kuo, 
Wei-zhong Zhu, Yonggang Deng, Charles Prosser, Wei Zhang and Laurent Besacier 
IBM T. J. Watson Research Center, Yorktown Heights, NY 10598 
 
ABSTRACT 
In this paper, we describe the IBM MASTOR, a speech-to-speech 
translation system that can translate spontaneous free-form 
speech in real-time on both laptop and hand-held PDAs. Chal-
lenges include speech recognition and machine translation in 
adverse environments, lack of training data and linguistic re-
sources for under-studied languages, and the need to rapidly de-
velop capabilities for new languages. Another challenge is de-
signing algorithms and building models in a scalable manner to 
perform well even on memory and CPU deficient hand-held com-
puters. We describe our approaches, experience, and success in 
building working free-form S2S systems that can handle two 
language pairs (including a low-resource language). 
 
1. INTRODUCTION 
Automatic speech-to-speech (S2S) translation breaks down com-
munication barriers between people who do not share a common 
language and hence enable instant oral cross-lingual communica-
tion for many critical applications such as emergency medical 
care. The development of an accurate, efficient and robust S2S 
translation system poses a lot of challenges. This is especially 
true for colloquial speech and resource deficient languages. 
The IBM MASTOR speech-to-speech translation system has been 
developed for the DARPA CAST and Transtac programs whose 
mission is to develop technologies that enable rapid deployment 
of real-time S2S translation of low-resource languages on port-
able devices. It originated from the IBM MARS S2S system 
handling the air travel reservation domain described in [1], which 
was later significantly improved in all components, including 
ASR, MT and TTS, and later evolved into the MASTOR multi-
lingual S2S system that covers much broader domains such as 
medical treatment and force protection [2,3]. More recently, we 
have further broadened our experience and efforts to very rapidly 
develop systems for under-studied languages, such as regional 
dialects of Arabic. The intent of this program is to provide lan-
guage support to military, medical and humanitarian personnel 
during operations in foreign territories, by deciphering possibly 
critical language communications with a two-way real-time 
speech-to-speech translation system designed for specific tasks 
such as medical triage and force protection.  
The initial data collection effort for the project has shown that the 
domain of force protection and medical triage is, though limited, 
rather broad. In fact, the definition of domain coverage is tough 
when the speech from responding foreign language speakers are 
concerned, as their responses are less constrained and may in-
clude out-of-domain words and concepts. Moreover, flexible 
casual or colloquial speaking style inevitably appears in the hu-
man-to-human conversational communications. Therefore, the 
project is a great challenge that calls for major research efforts. 
Among all the challenges for speech recognition and translation 
for under-studied languages, there are two main issues: 1) Lack of 
appropriate amount of speech data that represent the domain of 
interest and the oral language spoken by the target speakers, re-
sulting in difficulties in accurate estimation of statistical models 
for speech recognition and translation. 2) Lack of linguistic 
knowledge realization in spelling standards, transcriptions, lexi-
cons and dictionaries, or annotated corpora. Therefore, various 
different approaches have to be explored.  
Another critical challenge is to embed complicated algorithms 
and programs into small devices for mobile users. A hand-held 
computing device may have a CPU of 256MHz and 64MB mem-
ory; to fit the programs, as well as the models and data files into 
this memory and operate the system in real-time are tremendous 
challenges [4]. 
In this paper, we will describe the overall framework of the 
MASTOR system and our approaches for each major component, 
i.e., speech recognition and translation. Various statistical ap-
proaches [5,6,7,8] are explored and used to solve different techni-
cal challenges. We will show how we addressed the challenges 
that arise when building automatic speech recognition (ASR) and 
machine translation (MT) for colloquial Arabic on both the laptop 
and handheld PDA platforms. 
 
2. SYSTEM OVERVIEW 
The general framework of our speech translation system is illus-
trated in Figure 1. The general framework of our MASTOR sys-
tem has components of ASR, MT and TTS. The cascaded ap-
proach allows us to deploy the power of the existing advanced 
speech and language processing techniques, while concentrating 
on the unique problems in speech-to-speech translation. Figure 2 
illustrates the MASTOR GUI (Graphic User Interface) on laptop 
and PDA, respectively. 
Acoustic models for English and Mandarin baseline are devel-
oped for large-vocabulary continuous speech and trained on over 
200 hours of speech collected from about 2000 speakers for each 
language. However, the Arabic dialect speech recognizer was 
only trained using about 50 hours of dialectal speech.  The train-
ing data for Arabic consists of about 200K short utterances. Large 
efforts were invested in initial cleaning and normalization of the 
training data because of large number of irregular dialectal words 
and variations in spellings. We experimented with three ap-
proaches for pronunciation and acoustic modeling: i.e. grapheme, 
phonetic, and context-sensitive grapheme as will be described in 
ASR TTS 
Statistical NLU/NLG 
based MT 
Figure 1 IBM MASTOR Speech-to-Speech Translation System 
Statistical MT using 
WFST/SIPL  
* Thanks to DARPA for funding 
section 3.A. We found that using context-sensitive pronunciation 
rules reduces the WER of the grapheme based acoustic model by 
about 3% (from 36.7% to 35.8%). Based on these results, we 
decided to use context-sensitive grapheme models in our system.  
The Arabic language model (LM) is an interpolated model con-
sisting of a trigram LM, a class-based LM and a morphologically 
processed LM, all trained from a corpus of a few hundred thou-
sand words. We also built a compact language model for the 
hand-held system, where singletons are eliminated and bigram 
and trigram counts are pruned with increased thresholds. The LM 
footprint size is 10MB. 
There are two approaches for translation. The concept based ap-
proach uses natural language understanding (NLU) and natural 
language generation models trained from an annotated corpus. 
Another approach is the phrase-based finite state transducer 
which is trained using an un-annotated parallel corpus. 
A trainable, phrase-splicing and variable substitution TTS system 
is adopted to synthesize speech from translated sentences, which 
has a special ability to generate speech of mixed languages seam-
lessly [9]. In addition, a small footprint TTS is developed for the 
handheld devices using embedded concatenative TTS technolo-
gies.[10] 
Next, we will describe our approaches in automatic speech recog-
nition and machine translation in greater detail. 
 
3. AUTOMATIC SPEECH RECOGNITION 
A. Acoustic Models 
Acoustic models and the pronunciation dictionary greatly influ-
ence the ASR performance. In particular, creating an accurate 
pronunciation dictionary poses a major challenge when changing 
the language. Deriving pronunciations for resource rich languages 
like English or Mandarin is relatively straight forward using ex-
isting dictionaries or letter to sound models. In certain languages 
such as Arabic and Hebrew, the written form does not typically 
contain short vowels which a native speaker can infer from con-
text. Deriving automatic phonetic transcription for speech corpora 
is thus difficult. This problem is even more apparent when con-
sidering colloquial Arabic, mainly due to the large number of 
irregular dialectal words. 
One approach to overcome the absence of short vowels is to use 
grapheme based acoustic models. This leads to straightforward 
construction of pronunciation lexicons and hence facilitates 
model training and decoding. However, the same grapheme may 
lead to different phonetic sounds depending on its context. This 
results in less accurate acoustic models. For this reason we ex-
perimented with two other different approaches. The first is a full 
phonetic approach which uses short vowels, and the second uses 
context-sensitive graphemes for the letter "A" (Alif) where two 
different phonemes are used for "A" depending on its position in 
the word. 
Using phoneme based pronunciations would require vowelization 
of every word. To perform vowelization, we used a mix of dic-
tionary search and a statistical approach. The word is first 
searched in an existing vowelized dictionary, and if not found it is 
passed to the statistical vowelizer [11].  Due to the difficulties in 
accurately vowelizing dialectal words, our experiments have not 
shown any improvements using phoneme based ASR compared 
to grapheme based.  
Speech recognition for both the laptop and hand-held systems is 
based on the IBM ViaVoice engine. This highly robust and effi-
cient framework uses rank based acoustic scores [12] which are 
derived from tree-clustered context dependent Gaussian models. 
These acoustic scores together with n-gram LM probabilities are 
incorporated into a stack based search algorithm to yield the most 
probable word sequence given the input speech. 
The English acoustic models use an alphabet of 52 phones. Each 
phone is modeled with a 3-state left-to-right hidden Markov 
model (HMM). The system has approximately 3,500 context-
dependent states modeled using 42K Gaussian distributions and 
trained using 40 dimensional features. The context-dependent 
states are generated using a decision-tree classifier. The collo-
quial Arabic acoustic models use about 30 phones that essentially 
correspond to graphemes in the Arabic alphabet. The colloquial 
Arabic HMM structure is the same as that of the English model. 
The Arabic acoustic models are also built using 40 dimensional 
features. The compact model for the PDA has about 2K leaves 
and 28K Gaussian distributions.  The laptop version has over 3K 
leaves and 60K Gaussians. All acoustic models are trained using 
discriminative training [13]. 
B. Language Modeling   
Language modeling (LM) of the probability of various word se-
quences is crucial for high-performance ASR of free-style open-
 
   
 
 
Figure 2  IBM MASTOR system in Windows XP and Win-
dows CE 
ended coversational systems. Our approaches to build statistical 
tri-gram LMs fall into three categories: 1) obtaining additional 
training material automatically; 2) interpolating domain-specific 
LMs with other LMs; 3) improving distribution estimation ro-
bustness and accuracy with limited in-domain resources. Auto-
matic data collection and expansion is the most straight-forward 
way to achieve efficient LM, especially when little in-domain 
data is available. For resource-rich languages such as English and 
Chinese, we retrieve additional data from the World Wide Web 
(WWW) to enhance our limited domain specific data, which 
shows significant improvement [6]. 
In Arabic, words can take prefixes and suffixes to generate new 
words which are semantically related to the root form of the word 
(stem). As a result, the vocabulary size in Arabic can become 
very large even for specific domains. To alleviate this problem, 
we built a language model on morphologically tokenized data by 
applying morphological analysis and hence splitting some of the 
words into prefix+stem+suffix, prefix+stem or stem+suffix forms. 
We refer the reader to [14] to learn more about the morphological 
tokenization algorithm. Morphological analysis reduced the vo-
cabulary size by about 30% without sacrificing the coverage. 
More specifically, in our MASTOR system, the English language 
model has two components that are linearly interpolated. The first 
one is built using in-domain data. The second component acts as a 
background model and is built using a very large generic text 
inventory that is domain independent. The language model counts 
are also pruned to control the size of this background model. The 
colloquial Arabic language model for our laptop system is com-
posed of three components that are linearly interpolated. The first 
one is the basic word tri-gram model. The second one is a class 
based language model with 13 classes that covers names for Eng-
lish and Arabic, numbers, months, days, etc. The third one is the 
morphological language model described above. 
4. SPEECH TRANSLATION 
A. NLU/NLG-based Speech Translation 
One of the translation algorithms we proposed and applied in 
MASTOR is the statistical translation method based on natural 
language understanding (NLU) and natural language generation 
(NLG). Statistical machine translation methods translate a sen-
tence W in the source language into a sentence A in the target 
language by using a statistical model that estimates the probabil-
ity of A given W, i.e. ( )WAp . Conventionally, ( )WAp  is opti-
mized on a set of pairs of sentences that are translations of one 
another. To alleviate this data sparseness problem and, hence, 
enhance both the accuracy and robustness of estimating ( )WAp , 
we proposed a statistical concept-based machine translation para-
digm that predicts A with not only W but also the underlying con-
cepts embedded in W and/or A. As a result, the optimal sentence 
A is picked by first understanding the meaning of the source sen-
tence W.  
Let C denote the concepts in the source language and S denote the 
concepts in the target language, our proposed statistical concept-
based algorithm should select a word sequence A? as 
( ) ( ) ( ) ( )
??
?
??
?
== ? WCpWCSpWCSApWApA
CSAA
,,,maxargmaxarg?
,
 , 
where the conditional probabilities ( )WCp , ( )WCSp ,  and 
( )WCSAp ,,  are estimated by the Natural Language Understand-
ing (NLU), Natural Concept Generation (NCG) and Natural 
Word Generation (NWG) procedures, respectively. The probabil-
ity distributions are estimated and optimized upon a pre-annotated 
bilingual corpus. In our MASTOR system, ( )WCp  is estimated 
by a decision-tree based statistical semantic parser, and 
( )WCSp ,  and ( )WCSAp ,,  are estimated by maximizing the 
conditional entropy as depicted in [2] and [7], respectively. 
We are currently developing a new translation method that unifies 
statistical phrase-based translation models and the above 
NLU/NLG based approach. We will discuss this work in future 
publications. 
 
B. Fast and Memory Efficient Machine Translation Using SIPL 
Another translation method we proposed in MASTOR is based on 
the Weighted Finite-State Transducer (WFST). In particular, we 
developed a novel phrase-based translation framework using 
WFSTs that achieves both memory efficiency and fast speed, 
which is suitable for real time speech-to-speech translation on 
scalable computational platforms. In the proposed framework [15] 
which we refer to as Statistical Integrated Phrase Lattices (SIPLs), 
we statically construct a single optimized WFST encoding the 
entire translation model. In addition, we introduce a Viterbi de-
coder that can combine the translation model and language model 
FSTs with the input lattice efficiently, resulting in translation 
speeds of up to thousands of words per second on a PC and hun-
dred words per second on a PDA device. This WFST-based ap-
proach is well-suited to devices with limited computation and 
memory. We achieve this efficiency by using methods that allow 
us to perform more composition and graph optimization offline 
(such as, the determinization of the phrase segmentation trans-
ducer P) than in previous work, and by utilizing a specialized 
decoder involving multilayer search.  
During the offline training, we separate the entire translation lat-
tice H into two pieces: the language model L and the translation 
model M: 
( )( )( )WTPDetMinMinM =  
where   is the composition operator, Min  denotes the 
minimization operation, and Det  denotes the determinization 
operation; T is the phrase translation transducer, and W is the 
phrase-to-word transducer. Due to the determinizability of P, M 
can be computed offline using a moderate amount of memory. 
The translation problem can be framed as finding the best path in 
the full search lattice given an input sentence/automaton I. To 
address the problem of efficiently computing LMI  , we have 
developed a multilayer search algorithm. 
Specifically, we have one layer for each of the input FSM's: I, L, 
and M. At each layer, the search process is performed via a state 
traversal procedure starting from the start state 0s

, and consum-
ing an input word in each step in a left-to-right manner.  
We represent each state s in the search space using the following 
7-tuple: Is , Ms , Ls , Mc , Lc , h
 
, prevs , where Is , Ms , and 
Ls record the current state in each input FSM; Mc and Lc  record 
the accumulated cost in L and M in the best path up to this point; 
h
 
 records the target word sequence labeling the best path up to 
this point; and prevs  records the best previous state. 
To reduce the search space, two active search states are merged 
whenever they have identical Is , Ms , and Ls values; the re-
maining state components are inherited from the state with lower 
cost.  In addition, two pruning methods, histogram pruning and 
threshold or beam pruning, are used to achieve the desired bal-
ance between translation accuracy and speed. 
To provide the decoder for the PDA devices as well that lacks a 
floating-point processor, the search algorithm is implemented 
using fixed-point arithmetic. 
 
 
5. CONCLUSION 
We described the framework of the IBM MASTOR system, the 
various technologies used in building major components for lan-
guages with different levels of data resources. The technologies 
have shown successes in building real-time S2S systems on both 
laptop and small computation resource platforms for two lan-
guage pairs, English-Mandarin Chinese, and English-Arabic dia-
lect. In the latter case, we also developed approaches which lead 
to very rapid (in the matter of 3-4 months) development of sys-
tems using very limited language and domain resources. We are 
working on improving spontaneous speech recognition accuracy 
and more naturally integrating two translation approaches.  
 
6. ACKNOWLEDGEMENT 
The authors sincerely thank Drs. Yoshinori Tahara, Fu-hua Liu, 
Yongxing Li, Etienne Marcheret, Raimo Bakis, Ellen Eide, Burn 
Lewis, Tony Lee, Ossama Emam, and Lubos Ures for their help 
and contributions to the MASTOR S2S system. 
 
7. REFERENCES 
[1] Y. Gao et al ?MARS: A Statistical Semantic Parsing and Generation 
Based Multilingual Automatic tRanslation System,? Machine Trans-
lation, vol. 17, pp.185-212, 2004. 
[2] L. Gu et al ?Improving Statistical Natural Concept Generation in 
Interlingua-based Speech-to-Speech Translation,? in Proc. Eu-
rospeech?2003, pp.2769-2772. 
[3] F.-H. Liu, ?Robustness in Speech-to-Speech Translation,? in Proc. 
Eurospeech?2003, pp.2797-2800. 
[4] B. Zhou et al ?Two-way speech-to-speech translation on handheld 
devices,? in Proc. ICSLP'04, South Korea, Oct, 2004. 
[5] H. Erdogan et al ?Using Semantic Analysis to Improve Speech 
Recognition Performance,? Computer Speech and Language, vol.19, 
pp.321-343, 2005. 
[6] R. Sarikaya, et al  ?Rapid Language Model Development Using 
External Resources for New Spoken Dialog Domains,? in Proc. 
ICASSP'05, Philadelphia, PA, Mar, 2005. 
[7] L. Gu et al ?Concept-based Speech-to-Speech Translation using 
Maximum Entropy Models for Statistical Natural Concept Genera-
tion,? IEEE Trans. Speech and Audio Processing, vol.14, no.2, 
pp.377-392, March, 2006. 
[8] B. Zhou et al ?Constrained phrase-based translation using weighted 
finite-state transducers,? in Proc. ICASSP'05, Philadelphia, Mar, 
2005. 
[9] E. Eide et al ?Recent Improvements to the IBM Trainable Speech 
Synthesis System,? in Proc.  ICASSP, Hong Kong, China, 2003. 
[10] Dan Chazan et al ?Reducing the Footprint of the IBM Trainable 
Speech Synthesis System,? in ICSLP-2002, pp.2381-2384  
[11] R. Sarikaya et al ?Maximum Entropy Based Vowelization of Ara-
bic,? Interspeech2006 (submitted for publication). 
[12] L.R. Bahl, et al ?Robust methods for using context-dependent fea-
tures and models in a continuous speech recognizer,? in Proc. 
ICASSP, 1994 
[13] D. Povey & P.C. Woodland, ?Minimum Phone Error and I-
Smoothing for Improved Discriminative Training,? In Proc. ICASSP, 
Orlando, 2002. 
[14] M. Afify et.al, ?On the Use of Morphological Analysis for Dialectal 
Arabic Speech Recognition,? Interspeech 2006 (submitted for publi-
cation). 
[15] B. Zhou, S. Chen, and Y. Gao, ?Fast Machine Translation Using 
Statistical Integrated Phrase Lattices,? submitted to COL-
ING/ACL'2006. 
 
 
Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language
Processing (HLT/EMNLP), pages 169?176, Vancouver, October 2005. c?2005 Association for Computational Linguistics
HMM Word and Phrase Alignment for Statistical Machine Translation
Yonggang Deng1 , William Byrne1,2
Center for Language and Speech Processing, Johns Hopkins University
Baltimore, MD 21210, USA 1
Machine Intelligence Lab, Cambridge University Engineering Department
Trumpington Street, Cambridge CB2 1PZ, UK 2
dengyg@jhu.edu , wjb31@cam.ac.uk
Abstract
HMM-based models are developed for the
alignment of words and phrases in bitext.
The models are formulated so that align-
ment and parameter estimation can be per-
formed efficiently. We find that Chinese-
English word alignment performance is
comparable to that of IBM Model-4 even
over large training bitexts. Phrase pairs
extracted from word alignments generated
under the model can also be used for
phrase-based translation, and in Chinese
to English and Arabic to English transla-
tion, performance is comparable to sys-
tems based on Model-4 alignments. Di-
rect phrase pair induction under the model
is described and shown to improve trans-
lation performance.
1 Introduction
Describing word alignment is one of the fundamen-
tal goals of Statistical Machine Translation (SMT).
Alignment specifies how word order changes when
a sentence is translated into another language, and
given a sentence and its translation, alignment spec-
ifies translation at the word level. It is straightfor-
ward to extend word alignment to phrase alignment:
two phrases align if their words align.
Deriving phrase pairs from word alignments is
now widely used in phrase-based SMT. Parameters
of a statistical word alignment model are estimated
from bitext, and the model is used to generate word
alignments over the same bitext. Phrase pairs are ex-
tracted from the aligned bitext and used in the SMT
system. With this approach the quality of the under-
lying word alignments can have a strong influence
on phrase-based SMT system performance. The
common practice therefore is to extract phrase pairs
from the best attainable word alignments. Currently,
Model-4 alignments (Brown and others, 1993) as
produced by GIZA++ (Och and Ney, 2000) are often
the best that can be obtained, especially with large
bitexts.
Despite its modeling power and widespread use,
Model-4 has shortcomings. Its formulation is such
that maximum likelihood parameter estimation and
bitext alignment are implemented by approximate,
hill-climbing, methods. Consequently parameter es-
timation can be slow, memory intensive, and diffi-
cult to parallelize. It is also difficult to compute
statistics under Model-4. This limits its usefulness
for modeling tasks other than the generation of word
alignments.
We describe an HMM alignment model devel-
oped as an alternative to Model-4. In the word align-
ment and phrase-based translation experiments to
be presented, its performance is comparable or im-
proved relative to Model-4. Practically, we can train
the model by the Forward-Backward algorithm, and
by parallelizing estimation, we can control memory
usage, reduce the time needed for training, and in-
crease the bitext used for training. We can also com-
pute statistics under the model in ways not practical
with Model-4, and we show the value of this in the
extraction of phrase pairs from bitext.
2 HMM Word and Phrase Alignment
Our goal is to develop a generative probabilistic
model of Word-to-Phrase (WtoP) alignment. We
start with an l-word source sentence e = el1, and an
169
m-word target sentence f = fm1 , which is realized
as a sequence of K phrases: f = vK1 .
Each phrase is generated as a translation of one
source word, which is determined by the alignment
sequence aK1 : eak ? vk . The length of each phrase
is specified by the process ?K1 , which is constrained
so that
?K
k=1 ?k = m.
We also allow target phrases to be inserted, i.e. to
be generated by a NULL source word. For this, we
define a binary hallucination sequence hK1 : if hk =
0, then NULL ? vk ; if hk = 1 then eak ? vk.
With all these quantities gathered into an align-
ment a = (?K1 , aK1 , hK1 ,K), the modeling objective
is to realize the conditional distribution P (f ,a|e).
With the assumption that P (f ,a|e) = 0 if f 6= vK1 ,
we write P (f ,a|e) = P (vK1 ,K, aK1 , hK1 , ?K1 |e) and
P (vK1 ,K, aK1 , hK1 , ?K1 |e)
= ?(m|l) ? P (K|m, e)
? P (aK1 , ?K1 , hK1 |K,m, e)
? P (vK1 |aK1 , hK1 , ?K1 ,K,m, e)
We now describe the component distributions.
Sentence Length ?(m|l) determines the target
sentence length. It is not needed during alignment,
where sentence lengths are known, and is ignored.
Phrase Count P (K|m, e) specifies the number of
target phrases. We use a simple, single parameter
distribution, with ? = 8.0 throughout
P (K|m, e) = P (K|m, l) ? ?K
Word-to-Phrase Alignment Alignment is a
Markov process that specifies the lengths of phrases
and their alignment with source words
P (aK1 , hK1 , ?K1 |K,m, e)
=
K
?
k=1
P (ak, hk, ?k|ak?1, ?k?1, e)
=
K
?
k=1
p(ak|ak?1, hk; l) d(hk)n(?k; eak )
The actual word-to-phrase alignment (ak) is a first-
order Markov process, as in HMM-based word-to-
word alignment (Vogel et al, 1996). It necessarily
depends on the hallucination variable
p(aj |aj?1, hj ; l)
=
?
?
?
1 aj = aj?1, hj = 0
0 aj 6= aj?1, hj = 0
a(aj |aj?1; l) hj = 1
This formulation allows target phrases to be in-
serted without disrupting the Markov dependencies
of phrases aligned to actual source words.
The phrase length model n(?; e) gives the proba-
bility that a word e produces a phrase with ? words
in the target language; n(?; e) is defined for ? =
1, ? ? ? , N . The hallucination process is a simple
i.i.d. process, where d(0) = p0, and d(1) = 1 ? p0.
Word-to-Phrase Translation The translation of
words to phrases is given as
P (vK1 |aK1 , hK1 , ?K1 ,K,m, e) =
K
?
k=1
p(vk|eak , hk, ?k)
We introduce the notation vk = vk[1], . . . , vk[?k]
and a dummy variable xk (for phrase insertion) :
xk =
{
eak hk = 1
NULL hk = 0
We define two models of word-to-phrase translation.
This simplest is based on context-independent word-
to-word translation
p(vk|eak , hk, ?k) =
?k
?
j=1
t(vk[j] |xk)
We also define a model that captures foreign word
context with bigram translation probabilities
p(vk|eak , hk, ?k)
= t(vk[1] |xk)
?k
?
j=2
t2(vk[j] | vk [j ? 1], xk)
Here, t(f |e) is the usual context independent word-
to-word translation probability. The bigram trans-
lation probability t2(f |f ?, e) specifies the likelihood
that target word f is to follow f ? in a phrase gener-
ated by source word e.
170
2.1 Properties of the Model and Prior Work
The formulation of the WtoP alignment model
was motivated by both the HMM word alignment
model (Vogel et al, 1996) and IBM Model-4 with
the goal of building on the strengths of each.
The relationship with the word-to-word HMM
alignment model is straightforward. For example,
constraining the phrase length component n(?; e)
to permit only phrases of one word would give a
word-to-word HMM alignment model. The exten-
sions introduced are the phrase count, and the phrase
length models, and the bigram translation distribu-
tion. The hallucination process is motivated by the
use of NULL alignments into Markov alignment
models as done by (Och and Ney, 2003).
The phrase length model is motivated by
Toutanova et al (2002) who introduced ?stay? prob-
abilities in HMM alignment as an alternative to word
fertility. By comparison, Word-to-Phrase HMM
alignment models contain detailed models of state
occupancy, motivated by the IBM fertility model,
which are more powerful than a single staying pa-
rameter. In fact, the WtoP model is a segmental
Hidden Markov Model (Ostendorf et al, 1996), in
which states emit observation sequences.
Comparison with Model-4 is less straightforward.
The main features of Model-4 are NULL source
words, source word fertility, and the distortion
model. The WtoP alignment model includes the
first two of these. However distortion, which al-
lows hypothesized words to be distributed through-
out the target sentence, is difficult to incorporate into
a model that supports efficient DP-based search. We
preserve efficiency in the WtoP model by insisting
that target words form connected phrases; this is not
as general as Model-4 distortion. This weakness
is somewhat offset by a more powerful (Markov)
alignment process as well as by the phrase count
distribution. Despite these differences, the WtoP
alignment model and Model-4 allow similar align-
ments. For example, in Fig. 1, Model-4 would allow
f
e
f
e
f f
1 2
1 2 3 4
Figure 1: Word-to-Word and Word-to-Phrase Links
f1, f3, and f4 to be generated by e1 with a fertility
of 3. Under the WtoP model, e1 could generate f1
and f3f4 with phrase lengths 1 and 2, respectively:
source words can generate more than one phrase.
This alignment could also be generated via four
single word foreign phrases. The balance between
word-to-word and word-to-phrase alignments is set
by the phrase count distribution parameter ?. As
? increases, alignments with shorter phrases are
favored, and for very large ? the model allows
only word-to-word alignments (see Fig. 2). Al-
though the WtoP alignment model is more com-
plex than the word-to-word HMM alignment model,
the Baum-Welch and Viterbi algorithms can still be
used. Word-to-word alignments are generated by
the Viterbi algorithm: a? = argmaxa P (f ,a|e); if
eak ? vk , eak is linked to all the words in vk.
The bigram translation probability relies on word
context, known to be helpful in translation (Berger
et al, 1996), to improve the identification of tar-
get phrases. As an example, f is the Chinese word
for ?world trade center?. Table 1 shows how the
likelihood of the correct English phrase is improved
with bigram translation probabilities; this example
is from the C?E, N=4 system of Table 2.
Model unigram bigram
P (world|f) 0.06 0.06
P (trade|world, f) 0.06 0.99
P (center|trade, f) 0.06 0.99
P (world trade center|f, 3) 0.0002 0.0588
Table 1: Context in Bigram Phrase Translation.
There are of course much prior work in translation
that incorporates phrases. Sumita et al (2004) de-
velop a model of phrase-to-phrase alignment, which
while based on HMM alignment process, appears
to be deficient. Marcu and Wong (2002) propose a
model to learn lexical correspondences at the phrase
level. To our knowledge, ours is the first non-
syntactic model of bitext alignment (as opposed to
translation) that links words and phrases.
3 Embedded Alignment Model Estimation
We now discuss estimation of the WtoP model pa-
rameters by the EM algorithm. Since the WtoP
model can be treated as an HMM with a very com-
plex state space, it is straightforward to apply Baum-
171
Welch parameter estimation. We show the forward
recursion as an example.
Given a sentence pair (el1, fm1 ), the forward prob-
ability ?j(i, ?) is defined as the probability of gen-
erating the first j target words with the added con-
dition that the target words f jj??+1 form a phrase
aligned to source word ei. It can be calculated recur-
sively (omitting the hallucination process, for sim-
plicity) as
?j(i, ?) =
{
?
i?,??
?j??(i?, ??)a(i|i?, l)
}
? ?
? n(?; ei) ? t(fj??+1|ei) ?
j
?
j?=j??+2
t2(fj? |ei)
This recursion is over a trellis of l(N + 1)m nodes.
Models are trained from a flat-start. We begin
with 10 iterations of EM to train Model-1, followed
by 5 EM iterations to train Model-2 (Brown and oth-
ers, 1993). We initialize the parameters of the word-
to-word HMM alignment model by collecting word
alignment counts from the Model-2 Viterbi align-
ments, and refine the word-to-word HMM alignment
model by 5 iterations of the Baum-Welch algorithm.
We increase the order of the WtoP model (N ) from
2 to the final value in increments of 1, by perform-
ing 5 Baum Welch iterations at each step. At the fi-
nal value of N , we introduce the bigram translation
probability; we use Witten-Bell smoothing (1991)
as a backoff strategy for t2, and other strategies are
possible.
4 Bitext Word Alignment
We now investigate bitext word alignment perfor-
mance. We start with the FBIS Chinese/English
parallel corpus which consists of approx. 10M En-
glish/7.5M Chinese words. The Chinese side of the
corpus is segmented into words by the LDC seg-
menter1. The alignment test set consists of 124 sen-
tences from the NIST 2001 dry-run MT-eval2 set that
are manually word aligned.
We first analyze the distribution of word links
within these manual alignments. Of the Chinese
words which are aligned to more than one English
words, 82% of these words align with consecutive
1http://www.ldc.upenn.edu/Projects/Chinese
2http://www.nist.gov/speech/tests/mt
Model AER1?1 AER1?N AER
C??E
Model-4 37.9 68.3 37.3
HMM, N=1 42.8 72.9 42.0
HMM, N=2 38.3 71.2 38.1
HMM, N=3 37.4 69.5 37.8
HMM, N=4 37.1 69.1 37.8
+ bigram t-table 37.5 65.8 37.1
E??C
Model-4 42.3 87.2 45.0
HMM, N=1 45.0 90.6 47.2
HMM, N=2 42.7 87.5 44.5
+ bigram t-table 44.2 85.5 45.1
Table 2: FBIS Bitext Alignment Error Rate.
2 4 6 8 10 121500
1850
2200
2550
2900
3250
3600
3950
?
# o
f hy
pot
hes
ize
d li
nks
0 1426
28
30
32
34
36
38
40
Ov
era
ll A
ER1?1 Links
1?N Links
Total Links
Overall AER
Figure 2: Balancing Word and Phrase Alignments
English words (phrases). In the other direction,
among all English words which are aligned to mul-
tiple Chinese words, 88% of these align to Chinese
phrases. In this collection, at least, word-to-phrase
alignments are plentiful.
Alignment performance is measured by the
Alignment Error Rate (AER) (Och and Ney, 2003)
AER(B;B?) = 1? 2 ? |B ?B?|/(|B?| + |B|)
where B is a set reference word links, and B? are the
word links generated automatically.
AER gives a general measure of word alignment
quality. We are also interested in how the model
performs over the word-to-word and word-to-phrase
alignments it supports. We split the reference align-
ments into two subsets: B1?1 contains word-to-
word reference links (e.g. 1?1 in Fig 1); and
B1?N contains word-to-phrase reference links (e.g.
1?3, 1?4 in Fig 1); The automatic alignment B?
is partitioned similarly. We define additional AERs:
AER1?1 = AER(B1?1, B?1?1), and AER1?N =
AER(B1?N , B?1?N ), which measure word-to-word
and word-to-phrase alignment, separately.
Table 2 presents the three AER measurements for
172
the WtoP alignment models trained as described in
Section 3. GIZA++ Model 4 alignment performance
is also presented for comparison. We note first that
the word-to-word HMM (N=1) alignment model is
worse than Model 4, as expected. For the WtoP
models in the C?E direction, we see reduced AER
for phrases lengths up to 4, although in the E?C di-
rection, AER is reduced only for phrases of length
2; performance for N > 2 is not reported.
In introducing the bigram phrase translation (the
bigram t-table), there is a tradeoff between word-
to-word and word-to-phrase alignment quality. As
mentioned, the bigram t-table increases the likeli-
hood of word-to-phrase alignments. In both transla-
tion directions, this reduces the AER1?N . However,
it also causes increases in AER1?1, primarily due to
a drop in recall: fewer word-to-word alignments are
produced. For C?E, this is not severe enough to
cause an overall AER increase; however, in E?C,
AER does increase.
Fig. 2 (C?E, N=4) shows how the 1-1 and 1-
N alignment behavior is balanced by the phrase
count parameter. As ? increases, the model favors
alignments with more word-to-word links and fewer
word-to-phrase links; the overall Alignment Error
Rate (AER) suggests a good balance at ? = 8.0.
After observing that the WtoP model performs as
well as Model-4 over the FBIS C-E bitext, we inves-
tigated performance over these large bitexts :
- ?NEWS? containing non-UN parallel Chi-
nese/English corpora from LDC (mainly FBIS, Xin-
hua, Hong Kong, Sinorama, and Chinese Treebank).
- ?NEWS+UN01-02? also including UN parallel
corpora from the years 2001 and 2002.
- ?ALL C-E? refers to all the C-E bitext available
from LDC as of his submission; this consists of the
NEWS corpora with the UN bitext from all years.
Over all these collections, WtoP alignment per-
formance (Table 3) is comparable to that of Model-
4. We do note a small degradation in the E?C WtoP
alignments. It is quite possible that this one-to-many
model suffers slightly with English as the source and
Chinese as the target, since English sentences tend to
be longer. Notably, simply increasing the amount of
bitext used in training need not improve AER. How-
ever, larger aligned bitexts can give improved phrase
pair coverage of the test set.
One of the desirable features of HMMs is that the
Bitext English Words Model C?E E?C
M-4 37.1 45.3NEWS 71M
WtoP 36.1 44.8
NEWS+ M-4 36.1 43.4
UN01-02 96M WtoP 36.4 44.2
ALL C-E 200M WtoP 36.8 44.7
Table 3: AER Over Large C-E Bitexts.
Forward-Backward steps can be run in parallel: bi-
text is partitioned; the Forward-Backward algorithm
is run over the subsets on different CPUs; statistics
are merged to reestimate model parameters. Parti-
tioning the bitext also reduces the memory usage,
since different cooccurrence tables can be kept for
each partition. With the ?ALL C-E? bitext collec-
tion, a single set of WtoP models (C?E, N=4, bi-
gram t-table) can be trained over 200M words of
Chinese-English bitext by splitting training over 40
CPUs; each Forward-Backward process takes less
than 2GB of memory and the training run finishes
in five days. By contrast, the 96M English word
NEWS+UN01-02 is about the largest C-E bitext
over which we can train Model-4 with our GIZA++
configuration and computing infrastructure.
Based on these and other experiments, in this pa-
per we set a maximum value of N = 4 for F?E; in
E?F, we set N=2 and omit the bigram phrase trans-
lation probability; ? is set to 8.0. We do not claim
that this is optimal, however.
5 Phrase Pair Induction
A common approach to phrase-based translation is
to extract an inventory of phrase pairs (PPI) from bi-
text (Koehn et al, 2003), For example, in the phrase-
extract algorithm (Och, 2002), a word alignment
a?m1 is generated over the bitext, and all word sub-
sequences ei2i1 and f
j2
j1 are found that satisfy :
a?m1 : a?j ? [i1, i2] iff j ? [j1, j2] . (1)
The PPI comprises all such phrase pairs (ei2i1 , f
j2
j1 ).
The process can be stated slightly differently.
First, we define a set of alignments :
A(i1, i2; j1, j2) = {am1 : aj ? [i1, i2] iff j ? [j1, j2]} .
If a?m1 ? A(i1, i2; j1, j2) then (ei2i1 , f
j2
j1 ) form a
phrase pair.
Viewed in this way, there are many possible align-
ments under which phrases might be paired, and
173
the selection of phrase pairs need not be based on
a single alignment. Rather than simply accepting a
phrase pair (ei2i1 , f
j2
j1 ) if the unique MAP alignment
satisfies Equation 1, we can assign a probability to
phrases occurring as translation pairs :
P (f , A(i1, i2; j1, j2 ) | e) =
?
a : am1 ?A(i1,i2;j1,j2 )
P (f ,a|e)
For a fixed set of indices i1, i2, j1, j2, the quan-
tity P (f , A(i1, i2; j1, j2 ) | e) can be computed effi-
ciently using a modified Forward algorithm. Since
P (f |e) can also be computed by the Forward al-
gorithm, the phrase-to-phrase posterior distribution
P (A(i1, i2; j1, j2 ) | f , e) is easily found.
PPI Induction Strategies In the phrase-extract
algorithm (Och, 2002), the alignment a? is gener-
ated as follows: Model-4 is trained in both directions
(e.g. F?E and E?F); two sets of word alignments
are generated by the Viterbi algorithm for each set
of models; and the two alignments are merged. This
forms a static aligned bitext. Next, all foreign word
sequences up to a given length (here, 5 words) are
extracted from the test set. For each of these, a
phrase pair is added to the PPI if the foreign phrase
can be found aligned to an English phrase under
Eq 1. We refer to the result as the Model-4 Viterbi
Phrase-Extract PPI.
Constructed in this way, the PPI is limited to
phrase pairs which can be found in the Viterbi align-
ments. Some foreign phrases which do appear in
the training bitext will not be included in the PPI
because suitable English phrases cannot be found.
To add these to the PPI we can use the phrase-to-
phrase posterior distribution to find English phrases
as candidate translations. This adds phrases to the
Viterbi Phrase-Extract PPI and increase the test set
coverage. A somewhat ad hoc PPI Augmentation
algorithm is given to the right.
Condition (A) extracts phrase pairs based on the
geometric mean of the E?F and F?E posteriors
(Tg = 0.01 throughout). The threshold Tp selects
additional phrase pairs under a more forgiving crite-
rion: as Tp decreases, more phrase pairs are added
and PPI coverage increases. Note that this algorithm
is constructed specifically to improve a Viterbi PPI;
it is certainly not the only way to extract phrase pairs
under the phrase-to-phrase posterior distribution.
Once the PPI phrase pairs are set, the phrase trans-
lation probabilities are set based on the number of
times each phrase pair is extracted from a sentence
pair, i.e. from relative frequencies.
For each foreign phrase v not in the Viterbi PPI :
For all pairs (fm1 , el1) and j1, j2 s.t. f
j2
j1 = v :
For 1 ? i1 ? i2 ? l, find
f(i1, i2) = PF?E(A(i1, i2; j1, j2) | el1, fm1 )
b(i1, i2) = PE?F (A(i1, i2; j1, j2) | el1, fm1 )
g(i1, i2) =
?
f(11, i2) b(i1, i2)
(?i1, i?2) = argmax
1?i1,i2?l
g(i1, i2) , and set u = ei?2i?1
Add (u, v) to the PPI if any of A, B, or C hold :
b(?i1, i?2) ? Tg and f (?i1, i?2) ? Tg (A)
b(?i1, i?2) < Tg and f (?i1, i?2) > Tp (B)
f (?i1, i?2) < Tg and b(?i1, i?2) > Tp (C)
PPI Augmentation via Phrase-Posterior Induction
HMM-based models are often used if posterior
distributions are needed. Model-1 can also be used
in this way (Venugopal et al, 2003), although it is
a relatively weak alignment model. By comparison,
finding posterior distributions under Model-4 is dif-
ficult. The Word-to-Phrase alignment model appears
not to suffer this tradeoff: it is a good model of word
alignment under which statistics such as the phrase-
to-phrase posterior can be calculated.
6 Translation Experiments
We evaluate the quality of phrase pairs extracted
from the bitext through the translation performance
of the Translation Template Model (TTM) (Kumar
et al, 2005), which is a phrase-based translation sys-
tem implemented using weighted finite state trans-
ducers. Performance is measured by BLEU (Pap-
ineni and others, 2001).
Chinese?English Translation We report perfor-
mance on the NIST Chinese/English 2002, 2003 and
2004 (News only) MT evaluation sets. These consist
of 878, 919, and 901 sentences, respectively. Each
Chinese sentence has 4 reference translations.
We evaluate two C?E translation systems. The
smaller system is built on the FBIS C-E bitext col-
lection. The language model used for this system is
a trigram word language model estimated with 21M
174
V-PE WtoP eval02 eval03 eval04 eval02 eval03 eval04
Model Tp cvg BLEU cvg BLEU cvg BLEU cvg BLEU cvg BLEU cvg BLEU
FBIS C?E System News A?E System
1 M-4 - 20.1 23.8 17.7 22.8 20.2 23.0 19.5 36.9 21.5 39.1 18.5 40.0
2 0.7 24.6 24.6 21.4 23.7 24.6 23.7 23.8 37.6 26.6 40.2 22.4 40.3
3 WtoP - 19.7 23.9 17.4 23.3 19.8 23.3 18.4 36.2 20.6 38.6 17.4 39.2
4 1.0 23.1 24.0 20.0 23.7 23.2 23.5 21.8 36.7 24.3 39.3 20.4 39.7
5 0.9 24.0 24.8 20.9 23.9 24.0 23.8 23.2 37.2 25.8 39.7 21.8 40.1
6 0.7 24.6 24.9 21.3 24.0 24.7 23.9 23.7 37.2 26.5 39.7 22.4 39.9
7 0.5 24.9 24.9 21.6 24.1 24.8 23.9 24.0 37.2 26.9 39.7 22.7 39.8
Large C?E System Large A?E System
8 M-4 - 32.5 27.7 29.3 27.1 32.5 26.6 26.4 38.1 28.1 40.1 28.2 39.9
9 WtoP - 30.6 27.9 27.5 27.0 30.6 26.4 24.8 38.1 26.6 40.1 26.7 40.6
10 0.7 38.2 28.2 32.3 27.3 37.1 26.8 30.7 39.3 32.9 41.6 32.5 41.9
Table 4: Translation Analysis and Performance of PPI Extraction Procedures
words taken from the English side of the bitext; all
language models are built with the SRILM toolkit
using Kneser-Ney smoothing (Stolcke, 2002).
The larger system is based on alignments gener-
ated over all available C-E bitext (the ?ALL C-E?
collection of Section 4). The language model is
an equal-weight interpolated trigram model trained
over 373M English words taken from the English
side of the bitext and the LDC Gigaword corpus.
Arabic?English Translation We also evaluate our
WtoP alignment models in Arabic-English transla-
tion. We report results on a small and a large system.
In each, Arabic text is tokenized by the Buckwalter
analyzer provided by LDC. We test our models on
NIST Arabic/English 2002, 2003 and 2004 (News
only) MT evaluation sets that consists of 1043, 663
and 707 Arabic sentences, respectively. Each Arabic
sentence has 4 reference translations.
In the small system, the training bitext is from
A-E News parallel text, with ?3.5M words on the
English side. We follow the same training proce-
dure and configurations as in Chinese/English sys-
tem in both translation directions. The language
model is an equal-weight interpolated trigram built
over ?400M words from the English side of the bi-
text, including UN text, and the LDC English Gi-
gaword collection. The large Arabic/English system
employs the same language model. Alignments are
generated over all A-E bitext available from LDC as
of this submission; this consists of approx. 130M
words on the English side.
WtoP Model and Model-4 Comparison We first
look at translation performance of the small A?E
and C?E systems, where alignment models are
trained over the smaller bitext collections. The base-
line systems (Table 4, line 1) are based on Model-4
Viterbi Phrase-Extract PPIs.
We compare WtoP alignments directly to Model-
4 alignments by extracting PPIs from the WtoP
alignments using the Viterbi Phrase-Extract proce-
dure (Table 4, line 3). In C?E translation, perfor-
mance is comparable to that of Model-4; in A?E
translation, performance lags slightly. As we add
phrase pairs to the WtoP Viterbi Phrase-Extract PPI
via the Phrase-Posterior Augmentation procedure
(Table 4, lines 4-7), we obtain a ?1% improvement
in BLEU; the value of Tp = 0.7 gives improvements
across all sets. In C?E translation, this yields good
gains relative to Model-4, while in A?E we match
or improve the Model-4 performance.
The performance gains through PPI augmentation
are consistent with increased PPI coverage of the test
set. We tabulate the percentage of test set phrases
that appear in each of the PPIs (the ?cvg? values
in Table 4). The augmentation scheme is designed
specifically to increase coverage, and we find that
BLEU score improvements track the phrase cover-
age of the test set. This is further confirmed by the
experiment of Table 4, line 2 in which we take the
PPI extracted from Model-4 Viterbi alignments, and
add phrase pairs to it using the Phrase-Posterior aug-
mentation scheme with Tp = 0.7. We find that the
augmentation scheme under the WtoP models can
be used to improve the Model-4 PPI itself.
We also investigate C?E and A?E translation
performance with PPIs extracted from large bitexts.
175
Performance of systems based on Model-4 Viterbi
Phrase-Extract PPIs is shown in Table 4, line 8.
To train Model-4 using GIZA++, we split the bi-
texts into two (A-E) or three (C-E) partitions, and
train models for each division separately; we find
that memory usage is otherwise too great. These
serve as a single set of alignments for the bitext,
as if they had been generated under a single align-
ment model. When we translate with Viterbi Phrase-
Extract PPIs taken from WtoP alignments created
over all available bitext, we find comparable perfor-
mance to the Model-4 baseline (Table 4, line 9). Us-
ing the Phrase-Posterior augmentation scheme with
Tp = 0.7 yields further improvement (Table 4, line
10). Pooling the sets to form two large C?E and
A?E test sets, the A?E system improvements are
significant at a 95% level (Och, 2003); the C?E sys-
tems are only equivalent.
7 Conclusion
We have described word-to-phrase alignment mod-
els capable of good quality bitext word alignment.
In Arabic-English and Chinese-English translation
and alignment they compare well to Model-4, even
with large bitexts. The model architecture was in-
spired by features of Model-4, such as fertility and
distortion, but care was taken to ensure that dy-
namic programming procedures, such as EM and
Viterbi alignment, could still be performed. There
is practical value in this: training and alignment
are easily parallelized. Working with HMMs also
makes it straightforward to explore new modeling
approaches. We show an augmentation scheme that
adds to phrases extracted from Viterbi alignments;
this improves translation with both the WtoP and the
Model-4 phrase pairs, even though it would be infea-
sible to implement the scheme under Model-4 itself.
We note that these models are still relatively simple,
and we anticipate further alignment and translation
improvement as the models are refined.
Acknowledgments The TTM translation system was provided
by Shankar Kumar. This work was funded by ONR MURI
Grant N00014-01-1-0685.
References
A. L. Berger, S. Della Pietra, and V. J. Della Pietra. 1996.
A maximum entropy approach to natural language pro-
cessing. Computational Linguistics, 22(1):39?71.
P. F. Brown et al 1993. The mathematics of machine
translation: Parameter estimation. Computational Lin-
guistics, 19:263?312.
P. Koehn, F. Och, and D. Marcu. 2003. Statistical phrase-
based translation. In Proc. of HLT-NAACL.
S. Kumar, Y. Deng, and W. Byrne. 2005. A weighted fi-
nite state transducer translation template model for sta-
tistical machine translation. Journal of Natural Lan-
guage Engineering, 11(3).
D. Marcu and W. Wong. 2002. A phrase-based, joint
probability model for statistical machine translation.
In Proc. of EMNLP.
F. Och and H. Ney. 2000. Improved statistical alignment
models. In Proc. of ACL, Hong Kong, China.
F. J. Och and H. Ney. 2003. A systematic comparison of
various statistical alignment models. Computational
Linguistics, 29(1):19?51.
F. Och. 2002. Statistical Machine Translation: From
Single Word Models to Alignment Templates. Ph.D.
thesis, RWTH Aachen, Germany.
F. Och. 2003. Minimum error rate training in statistical
machine translation. In Proc. of ACL.
M. Ostendorf, V. Digalakis, and O. Kimball. 1996. From
HMMs to segment models: a unified view of stochas-
tic modeling for speech recognition. IEEE Trans.
Acoustics, Speech and Signal Processing, 4:360?378.
K. Papineni et al 2001. BLEU: a method for automatic
evaluation of machine translation. Technical Report
RC22176 (W0109-022), IBM Research Division.
A. Stolcke. 2002. SRILM ? an extensible language mod-
eling toolkit. In Proc. ICSLP.
E. Sumita et al 2004. EBMT, SMT, Hybrid and More:
ATR spoken language translation system. In Proc.
of the International Workshop on Spoken Language
Translation, Kyoto, Japan.
K. Toutanova, H. T. Ilhan, and C. Manning. 2002. Exten-
tions to HMM-based statistical word alignment mod-
els. In Proc. of EMNLP.
A. Venugopal, S. Vogel, and A. Waibel. 2003. Effective
phrase translation extraction from alignment models.
In Proc. of ACL.
S. Vogel, H. Ney, and C. Tillmann. 1996. HMM based
word alignment in statistical translation. In Proc. of
the COLING.
I. H. Witten and T. C. Bell. 1991. The zero-frequency
problem: Estimating the probabilities of novel events
in adaptive text compression. In IEEE Trans. Inform
Theory, volume 37, pages 1085?1094, July.
176
 	
ffProceedings of the Human Language Technology Conference of the NAACL, Companion Volume, pages 265?268,
New York City, June 2006. c?2006 Association for Computational Linguistics
MTTK: An Alignment Toolkit for Statistical Machine Translation
Yonggang Deng 1
Center for Language and Speech Processing1
Johns Hopkins University
Baltimore, MD 21218
dengyg@jhu.edu
William Byrne1,2
Machine Intelligence Lab 2
Cambridge University Engineering Department
Trumpington Street, Cambridge CB2 1PZ, UK
wjb31@cam.ac.uk
Abstract
The MTTK alignment toolkit for statisti-
cal machine translation can be used for
word, phrase, and sentence alignment of
parallel documents. It is designed mainly
for building statistical machine translation
systems, but can be exploited in other
multi-lingual applications. It provides
computationally efficient alignment and
estimation procedures that can be used
for the unsupervised alignment of parallel
text collections in a language independent
fashion. MTTK Version 1.0 is available
under the Open Source Educational Com-
munity License.
1 Introduction
Parallel text alignment procedures attempt to iden-
tify translation equivalences within collections of
translated documents. This can be be done at various
levels. At the finest level, this involves the alignment
of words and phrases within two sentences that are
known to be translations (Brown et al, 1993; Och
and Ney, 2003; Vogel et al, 1996; Deng and Byrne,
2005). Another task is the identification and align-
ment of sentence-level segments within document
pairs that are known to be translations (Gale and
Church, 1991); this is referred to as sentence-level
alignment, although it may also involve the align-
ment of sub-sentential segments (Deng et al, ) as
well as the identification of long segments in either
document which are not translations. There is also
document level translation which involves the iden-
tification of translated document pairs in a collection
of documents in multiple languages. As an example,
Figure 1 shows parallel Chinese/English text that is
aligned at the sentence, word, and phrase levels.
Parallel text plays a crucial role in multi-lingual
natural language processing research. In particu-
lar, statistical machine translation systems require
collections of sentence pairs (or sentence fragment
pairs) as the basic ingredients for building statistical
word and phrase alignment models. However, with
the increasing availability of parallel text, human-
created alignments are expensive and often unaf-
fordable for practical systems, even at a small scale.
High quality automatic alignment of parallel text has
therefore become indispensable. In addition to good
alignment quality, several other properties are also
desirable in automatic alignment systems. Ideally,
these should be general-purpose and language in-
dependent, capable of aligning very different lan-
guages, such as English, French, Chinese, German
and Arabic, to give a few examples of current in-
terest. If the alignment system is based on statis-
tical models, the model parameters should be esti-
mated from scratch, in an unsupervised manner from
whatever parallel text is available. To process mil-
lions of sentence pairs, these models need to be ca-
pable of generalization and the alignment and esti-
mation algorithms should be computationally effi-
cient. Finally, since noisy mismatched text is often
found in real data, such as parallel text mined from
web pages, automatic alignment needs to be robust.
There are systems available for these purposes, no-
tably the GIZA++ (Och and Ney, 2003) toolkit and
265
! " # $ % & ' () , * +,
$ % '- , ./ 01 &2 .
It is necessary to resolutely remove obstacles in
rivers and lakes .
3 4 56 78 9: , ;< => .
4 . It is necessary to strengthen monitoring and
forecast work and scientifically dispatch people and
materials .
! ?@ AB CD , EFGH IJ 9
: K> .
It is necessary to take effective measures and try by
every possible means to provide precision forecast .
L M ! NO PQ RS 9: FT ,
A U*V W XY() .
Before the flood season comes , it is necessary to
seize the time to formulate plans for forecasting
floods and to carry out work with clear
 	
Figure 1: Chinese/English Parallel Corpus Aligned at the Sentence, Word, and Phrase Levels: horizontal
lines denote the segmentations of a sentence alignment and arrows denote a word-level mapping.
the Champollion Toolkit (Ma et al, 2004).
This demo introduces MTTK, the Machine Trans-
lation Toolkit. The toolkit can be used to train statis-
tical models and perform parallel text alignment at
different levels. Target applications include not only
machine translation, but also bilingual lexicon in-
duction, cross lingual information retrieval and other
multi-lingual applications.
2 MTTK Components
MTTK is a collection of C++ programs and Perl
and shell scripts that can be used to build statisti-
cal alignment models from parallel text. Respective
of the text to be aligned, MTTK?s functions are cat-
egorized into the following two main parts.
2.1 Chunk Alignment
Chunk alignment aims to extract sentence or sub-
sentence pairs from parallel corpora. A chunk
can be multiple sentences, a sentence or a sub-
sentence, as required by the application. Two align-
ment procedures are implemented: one is the widely
used dynamic programming procedure that derives
monotone alignment of sentence segments (Gale
and Church, 1991); the other is divisive clustering
procedure that begins by finding coarse alignments
that are then iteratively refined by successive binary
splitting (Deng et al, ). These two types of align-
ment procedures complement each other. They can
be used together to improve the overall sentence
alignment quality.
When translation lexicons are not available,
chunk alignment can be performed using length-
based statistics. This usually can serve as a start-
ing point of sentence alignment. Alignment qual-
ity can be further improved when the chunking pro-
cedure is based on translation lexicons from IBM
Model-1 alignment model (Brown et al, 1993). The
MTTK toolkit also generates alignment score for
each chunk pair, that can be utilized in post process-
ing, for example in filtering out aligned segments of
dubious quality.
2.2 Word and Phrase Alignment
After a collection of sentence or sub-sentence pairs
are extracted via chunk alignment procedures, sta-
tistical word and phrase alignment models can be
estimated with EM algorithms. MTTK provides im-
plementations of various alignment, models includ-
ing IBM Model-1, Model-2 (Brown et al, 1993),
HMM-based word-to-word alignment model (Vogel
et al, 1996; Och and Ney, 2003) and HMM-based
word-to-phrase alignment model (Deng and Byrne,
2005). After model parameters are estimated, the
Viterbi word alignments can be derived. A novel
computation performed by MTTK is the genera-
266
tion of model-based phrase pair posterior distribu-
tions (Deng and Byrne, 2005), which plays an im-
portant role in extracting a phrase-to-phrase transla-
tion probabilities.
3 MTTK Features
MTTK is designed to process huge amounts of par-
allel text. Model parameter estimation can be car-
ried out parallel during EM training using multiple
CPUs. The entire parallel text is split into parts.
During each E-step , statistics are collected paral-
lel over each part, while in the M-steps, these statis-
tics are merged together to update model parame-
ters for next iteration. This parallel implementation
not only reduces model training time significantly,
it also avoids memory usage issues that arise in pro-
cessing millions of sentence pairs, since each E-Step
need only save and process co-occurrence that ap-
pears in its part of the parallel text. This enables
building a single model from many millions of sen-
tence pairs.
Another feature of MTTK is language indepen-
dence. Linguistic knowledge is not required during
model training, although when it is available, per-
formance can be improved. Statistical parameters
are estimated and learned automatically from data
in an unsupervised way. To accommodate language
diversity, there are several parameters in MTTK that
can be tuned for individual applications to optimize
performance.
4 A Typical Application of MTTK in
Parallel Text Alignment
A typical example of using MTTK is give in Fig-
ure 2. It starts with a collection of document pairs.
During pre-processing, documents are normalized
and tokenized into token sequences. This prepro-
cessing is carried out before using the MTTK, and
is usually language dependent, requiring, for exam-
ple, segmenting Chinese characters into words or ap-
plying morphological analyzing to Arabic word se-
quences.
Statistical models are then built from scratch.
Chunk alignment begins with length statistics that
can be simply obtained by counting the number of
tokens on in each language. The chunk aligning
procedure then applies dynamic programming to de-
rive a sentence alignment. After sorting the gener-
ated sentence pairs by their probabilities, high qual-
ity sentence pairs are then selected and used to train
a translation lexicon. As an input for next round
chunk alignment, more and better sentence pairs can
be extracted and serve as training material for a bet-
ter translation lexicon. This bootstrapping procedure
identifies high quality sentence pairs in an iterative
fashion.
To maximize the number of training words for
building word and phrase alignment models, long
sentence pairs are then processed further using a di-
visive clustering chunk procedure that derives chunk
pairs at the sub-sentence level. This provides addi-
tional translation training pairs that would otherwise
be discarded as being overly long.
Once all usable chunk pairs are identified in the
chunk alignment procedure, word alignment model
training starts with IBM Model-1. Model com-
plexity increases gradually to Model-2, and then
HMM-based word-to-word alignment model, and
finally to HMM-based word-to-phrase alignment
model (Deng and Byrne, 2005). With these models,
word alignments can be obtained using the Viterbi
algorithm, and phrase pair posterior distributions
can be computed in building a phrase translation ta-
ble.
In published experiments we have found that
MTTK generates alignments of quality comparable
to those generated by GIZA++, where alignment
quality is measured both directly in terms of Align-
ment Error Rate relative to human word alignments
and indirectly through the translation performance
of systems constructed from the alignments (Deng
and Byrne, 2005). We have used MTTK as the basis
of translation systems entered into the recent NIST
Arabic-English and Chinese-English MT Evalua-
tions as well as the TC-STAR Chinese-English MT
evaluation (NIST, 2005; TC-STAR, 2005).
5 Availability
MTTK Version 1.0 is released under the Open
Source Educational Community License1.
The tools and documentation are available at
http://mi.eng.cam.ac.uk/?wjb31/distrib/mttkv1/ .
1http://www.opensource.org/licenses/ecl1.php
267
{ t(f|e), a(i|j;l,m) }
WtW HMM Training
{ t(f|e), P(i|i?;l) }
AlignSHmm
{ t(f|e), P(i|i?;l), n(phi;e), t2(f|f?,e) }
Model?1 Training
{ t(f|e) }
Model?2 Training
WtP HMM Training w/ Bigram t?table
{ t(f|e), P(i|i?;l), n(phi;e) }
WtP HMM Training N=2,3...
Length Statistics
AlignHmm
AlignM2
AlignM1
AlignSHmm
PPEM
PPEM
PPEHmm
PPEHmm
PPEHmm
High Quality Pairs
Model?1 Training{ t(f|e) }
FilterChunk Alignments
W
ord A
lignm
ents
Phrase A
lignm
ents
Document Alignments
Bitext Chunking
Figure 2: A Typical Unsupervised Translation Alignment Procedure with MTTK.
6 Acknowledgements
Funded by ONR MURI Grant N00014-01-1-0685.
References
P. Brown, S. Della Pietra, V. Della Pietra, and R. Mer-
cer. 1993. The mathematics of machine transla-
tion: Parameter estimation. Computational Linguis-
tics, 19:263?312.
Y. Deng and W. Byrne. 2005. Hmm word and phrase
alignment for statistical machine translation. In Proc.
of HLT-EMNLP.
Y. Deng, S. Kumar, and W. Byrne. Segmentation and
alignment of parallel text for statistical machine trans-
lation. Journal of Natural Language Engineering. to
appear.
W. A. Gale and K. W. Church. 1991. A program for
aligning sentences in bilingual corpora. In Meeting of
the Association for Computational Linguistics, pages
177?184.
X. Ma, C. Cieri, and D. Miller. 2004. Corpora & tools
for machine translation. In Machine Translation Eval-
uation Workshop, Alexandria, VA. NIST.
NIST, 2005. The NIST Machine Translation Eval-
uations Workshop. North Bethesda, MD, June.
http://www.nist.gov/speech/tests/summaries/2005/mt05.htm.
F. J. Och and H. Ney. 2003. A systematic comparison of
various statistical alignment models. Computational
Linguistics, 29(1):19?51.
TC-STAR, 2005. TC-STAR Speech-to-Speech Trans-
lation Evaluation Meeting. Trento, Italy, April.
http://www.tc-star.org/.
S. Vogel, H. Ney, and C. Tillmann. 1996. HMM based
word alignment in statistical translation. In Proc. of
the COLING.
268
Proceedings of the ACL 2010 Conference Short Papers, pages 22?26,
Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational Linguistics
Diversify and Combine: Improving Word Alignment for Machine
Translation on Low-Resource Languages
Bing Xiang, Yonggang Deng, and Bowen Zhou
IBM T. J. Watson Research Center
Yorktown Heights, NY 10598
{bxiang,ydeng,zhou}@us.ibm.com
Abstract
We present a novel method to improve
word alignment quality and eventually the
translation performance by producing and
combining complementary word align-
ments for low-resource languages. Instead
of focusing on the improvement of a single
set of word alignments, we generate mul-
tiple sets of diversified alignments based
on different motivations, such as linguis-
tic knowledge, morphology and heuris-
tics. We demonstrate this approach on an
English-to-Pashto translation task by com-
bining the alignments obtained from syn-
tactic reordering, stemming, and partial
words. The combined alignment outper-
forms the baseline alignment, with signif-
icantly higher F-scores and better transla-
tion performance.
1 Introduction
Word alignment usually serves as the starting
point and foundation for a statistical machine
translation (SMT) system. It has received a signif-
icant amount of research over the years, notably in
(Brown et al, 1993; Ittycheriah and Roukos, 2005;
Fraser and Marcu, 2007; Hermjakob, 2009). They
all focused on the improvement of word alignment
models. In this work, we leverage existing align-
ers and generate multiple sets of word alignments
based on complementary information, then com-
bine them to get the final alignment for phrase
training. The resource required for this approach
is little, compared to what is needed to build a rea-
sonable discriminative alignment model, for ex-
ample. This makes the approach especially ap-
pealing for SMT on low-resource languages.
Most of the research on alignment combination
in the past has focused on how to combine the
alignments from two different directions, source-
to-target and target-to-source. Usually people start
from the intersection of two sets of alignments,
and gradually add links in the union based on
certain heuristics, as in (Koehn et al, 2003), to
achieve a better balance compared to using either
intersection (high precision) or union (high recall).
In (Ayan and Dorr, 2006) a maximum entropy ap-
proach was proposed to combine multiple align-
ments based on a set of linguistic and alignment
features. A different approach was presented in
(Deng and Zhou, 2009), which again concentrated
on the combination of two sets of alignments, but
with a different criterion. It tries to maximize the
number of phrases that can be extracted in the
combined alignments. A greedy search method
was utilized and it achieved higher translation per-
formance than the baseline.
More recently, an alignment selection approach
was proposed in (Huang, 2009), which com-
putes confidence scores for each link and prunes
the links from multiple sets of alignments using
a hand-picked threshold. The alignments used
in that work were generated from different align-
ers (HMM, block model, and maximum entropy
model). In this work, we use soft voting with
weighted confidence scores, where the weights
can be tuned with a specific objective function.
There is no need for a pre-determined threshold
as used in (Huang, 2009). Also, we utilize var-
ious knowledge sources to enrich the alignments
instead of using different aligners. Our strategy is
to diversify and then combine in order to catch any
complementary information captured in the word
alignments for low-resource languages.
The rest of the paper is organized as follows.
22
We present three different sets of alignments in
Section 2 for an English-to-Pashto MT task. In
Section 3, we propose the alignment combination
algorithm. The experimental results are reported
in Section 4. We conclude the paper in Section 5.
2 Diversified Word Alignments
We take an English-to-Pashto MT task as an exam-
ple and create three sets of additional alignments
on top of the baseline alignment.
2.1 Syntactic Reordering
Pashto is a subject-object-verb (SOV) language,
which puts verbs after objects. People have pro-
posed different syntactic rules to pre-reorder SOV
languages, either based on a constituent parse tree
(Dra?bek and Yarowsky, 2004; Wang et al, 2007)
or dependency parse tree (Xu et al, 2009). In
this work, we apply syntactic reordering for verb
phrases (VP) based on the English constituent
parse. The VP-based reordering rule we apply in
the work is:
? V P (V B?, ?) ? V P (?, V B?)
where V B? represents V B, V BD, V BG, V BN ,
V BP and V BZ .
In Figure 1, we show the reference alignment
between an English sentence and the correspond-
ing Pashto translation, where E is the original En-
glish sentence, P is the Pashto sentence (in ro-
manized text), and E? is the English sentence after
reordering. As we can see, after the VP-based re-
ordering, the alignment between the two sentences
becomes monotone, which makes it easier for the
aligner to get the alignment correct. During the
reordering of English sentences, we store the in-
dex changes for the English words. After getting
the alignment trained on the reordered English and
original Pashto sentence pairs, we map the English
words back to the original order, along with the
learned alignment links. In this way, the align-
ment is ready to be combined with the baseline
alignment and any other alternatives.
2.2 Stemming
Pashto is one of the morphologically rich lan-
guages. In addition to the linguistic knowledge ap-
plied in the syntactic reordering described above,
we also utilize morphological analysis by applying
stemming on both the English and Pashto sides.
For English, we use Porter stemming (Porter,
                          
                                        S                                                                                                 
 
 
                          S           CC            S 
  
            NP              VP            NP              VP 
 
            PRP  VBP        NP                  VBP        NP        ADVP 
 
                      PRP$         NNS                     PRP       RB 
 
      E:    they  are   your employees and you   know    them      well 
 
 
      P:  hQvy  stAsO   kArvAl   dy    Av  tAsO   hQvy    smh      pOZnB  
 
 
      E?: they  your  employees  are   and  you   them    well      know 
Figure 1: Alignment before/after VP-based re-
ordering.
1980), a widely applied algorithm to remove the
common morphological and inflexional endings
from words in English. For Pashto, we utilize
a morphological decompostion algorithm that has
been shown to be effective for Arabic speech
recognition (Xiang et al, 2006). We start from a
fixed set of affixes with 8 prefixes and 21 suffixes.
The prefixes and suffixes are stripped off from
the Pashto words under the two constraints:(1)
Longest matched affixes first; (2) Remaining stem
must be at least two characters long.
2.3 Partial Word
For low-resource languages, we usually suffer
from the data sparsity issue. Recently, a simple
method was presented in (Chiang et al, 2009),
which keeps partial English and Urdu words in the
training data for alignment training. This is similar
to the stemming method, but is more heuristics-
based, and does not rely on a set of available af-
fixes. With the same motivation, we keep the first
4 characters of each English and Pashto word to
generate one more alternative for the word align-
ment.
3 Confidence-Based Alignment
Combination
Now we describe the algorithm to combine mul-
tiple sets of word alignments based on weighted
confidence scores. Suppose aijk is an alignment
link in the i-th set of alignments between the j-th
source word and k-th target word in sentence pair
(S,T ). Similar to (Huang, 2009), we define the
confidence of aijk as
c(aijk|S, T ) =
?
qs2t(aijk|S, T )qt2s(aijk|T, S),
(1)
23
where the source-to-target link posterior probabil-
ity
qs2t(aijk|S, T ) =
pi(tk|sj)
?K
k?=1 pi(tk? |sj)
, (2)
and the target-to-source link posterior probability
qt2s(aijk|T, S) is defined similarly. pi(tk|sj) is
the lexical translation probability between source
word sj and target word tk in the i-th set of align-
ments.
Our alignment combination algorithm is as fol-
lows.
1. Each candidate link ajk gets soft votes from
N sets of alignments via weighted confidence
scores:
v(ajk|S, T ) =
N
?
i=1
wi ? c(aijk|S, T ), (3)
where the weight wi for each set of alignment
can be optimized under various criteria. In
this work, we tune it on a hand-aligned de-
velopment set to maximize the alignment F-
score.
2. All candidates are sorted by soft votes in de-
scending order and evaluated sequentially. A
candidate link ajk is included if one of the
following is true:
? Neither sj nor tk is aligned so far;
? sj is not aligned and its left or right
neighboring word is aligned to tk so far;
? tk is not aligned and its left or right
neighboring word is aligned to sj so far.
3. Repeat scanning all candidate links until no
more links can be added.
In this way, those alignment links with higher
confidence scores have higher priority to be in-
cluded in the combined alignment.
4 Experiments
4.1 Baseline
Our training data contains around 70K English-
Pashto sentence pairs released under the DARPA
TRANSTAC project, with about 900K words on
the English side. The baseline is a phrase-based
MT system similar to (Koehn et al, 2003). We
use GIZA++ (Och and Ney, 2000) to generate
the baseline alignment for each direction and then
apply grow-diagonal-final (gdf). The decoding
weights are optimized with minimum error rate
training (MERT) (Och, 2003) to maximize BLEU
scores (Papineni et al, 2002). There are 2028 sen-
tences in the tuning set and 1019 sentences in the
test set, both with one reference. We use another
150 sentence pairs as a heldout hand-aligned set
to measure the word alignment quality. The three
sets of alignments described in Section 2 are gen-
erated on the same training data separately with
GIZA++ and enhanced by gdf as for the baseline
alignment. The English parse tree used for the
syntactic reordering was produced by a maximum
entropy based parser (Ratnaparkhi, 1997).
4.2 Improvement in Word Alignment
In Table 1 we show the precision, recall and F-
score of each set of word alignments for the 150-
sentence set. Using partial word provides the high-
est F-score among all individual alignments. The
F-score is 5% higher than for the baseline align-
ment. The VP-based reordering itself does not im-
prove the F-score, which could be due to the parse
errors on the conversational training data. We ex-
periment with three options (c0, c1, c2) when com-
bining the baseline and reordering-based align-
ments. In c0, the weights wi and confidence scores
c(aijk|S, T ) in Eq. (3) are all set to 1. In c1,
we set confidence scores to 1, while tuning the
weights with hill climbing to maximize the F-
score on a hand-aligned tuning set. In c2, we com-
pute the confidence scores as in Eq. (1) and tune
the weights as in c1. The numbers in Table 1 show
the effectiveness of having both weights and con-
fidence scores during the combination.
Similarly, we combine the baseline with each
of the other sets of alignments using c2. They
all result in significantly higher F-scores. We
also generate alignments on VP-reordered partial
words (X in Table 1) and compared B + X and
B + V + P . The better results with B + V + P
show the benefit of keeping the alignments as di-
versified as possible before the combination. Fi-
nally, we compare the proposed alignment combi-
nation c2 with the heuristics-based method (gdf),
where the latter starts from the intersection of all 4
sets of alignments and then applies grow-diagonal-
final (Koehn et al, 2003) based on the links in
the union. The proposed combination approach on
B + V + S + P results in close to 7% higher F-
scores than the baseline and also 2% higher than
24
gdf. We also notice that its higher F-score is
mainly due to the higher precision, which should
result from the consideration of confidence scores.
Alignment Comb P R F
Baseline 0.6923 0.6414 0.6659
V 0.6934 0.6388 0.6650
S 0.7376 0.6495 0.6907
P 0.7665 0.6643 0.7118
X 0.7615 0.6641 0.7095
B+V c0 0.7639 0.6312 0.6913
B+V c1 0.7645 0.6373 0.6951
B+V c2 0.7895 0.6505 0.7133
B+S c2 0.7942 0.6553 0.7181
B+P c2 0.8006 0.6612 0.7242
B+X c2 0.7827 0.6670 0.7202
B+V+P c2 0.7912 0.6755 0.7288
B+V+S+P gdf 0.7238 0.7042 0.7138
B+V+S+P c2 0.7906 0.6852 0.7342
Table 1: Alignment precision, recall and F-score
(B: baseline; V: VP-based reordering; S: stem-
ming; P: partial word; X: VP-reordered partial
word).
4.3 Improvement in MT Performance
In Table 2, we show the corresponding BLEU
scores on the test set for the systems built on each
set of word alignment in Table 1. Similar to the
observation from Table 1, c2 outperforms c0 and
c1, and B + V + S + P with c2 outperforms
B + V + S + P with gdf. We also ran one ex-
periment in which we concatenated all 4 sets of
alignments into one big set (shown as cat). Over-
all, the BLEU score with confidence-based com-
bination was increased by 1 point compared to the
baseline, 0.6 compared to gdf, and 0.7 compared
to cat. All results are statistically significant with
p < 0.05 using the sign-test described in (Collins
et al, 2005).
5 Conclusions
In this work, we have presented a word alignment
combination method that improves both the align-
ment quality and the translation performance. We
generated multiple sets of diversified alignments
based on linguistics, morphology, and heuris-
tics, and demonstrated the effectiveness of com-
bination on the English-to-Pashto translation task.
We showed that the combined alignment signif-
icantly outperforms the baseline alignment with
Alignment Comb Links Phrase BLEU
Baseline 963K 565K 12.67
V 965K 624K 12.82
S 915K 692K 13.04
P 906K 716K 13.30
X 911K 689K 13.00
B+V c0 870K 890K 13.20
B+V c1 865K 899K 13.32
B+V c2 874K 879K 13.60
B+S c2 864K 948K 13.41
B+P c2 863K 942K 13.40
B+X c2 871K 905K 13.37
B+V+P c2 880K 914K 13.60
B+V+S+P cat 3749K 1258K 13.01
B+V+S+P gdf 1021K 653K 13.14
B+V+S+P c2 907K 771K 13.73
Table 2: Improvement in BLEU scores (B: base-
line; V: VP-based reordering; S: stemming; P: par-
tial word; X: VP-reordered partial word).
both higher F-score and higher BLEU score. The
combination approach itself is not limited to any
specific alignment. It provides a general frame-
work that can take advantage of as many align-
ments as possible, which could differ in prepro-
cessing, alignment modeling, or any other aspect.
Acknowledgments
This work was supported by the DARPA
TRANSTAC program. We would like to thank
Upendra Chaudhari, Sameer Maskey and Xiao-
qiang Luo for providing useful resources and the
anonymous reviewers for their constructive com-
ments.
References
Necip Fazil Ayan and Bonnie J. Dorr. 2006. A max-
imum entropy approach to combining word align-
ments. In Proc. HLT/NAACL, June.
Peter Brown, Vincent Della Pietra, Stephen Della
Pietra, and Robert Mercer. 1993. The mathematics
of statistical machine translation: parameter estima-
tion. Computational Linguistics, 19(2):263?311.
David Chiang, Kevin Knight, Samad Echihabi, et al
2009. Isi/language weaver nist 2009 systems. In
Presentation at NIST MT 2009 Workshop, August.
Michael Collins, Philipp Koehn, and Ivona Kuc?erova?.
2005. Clause restructuring for statistical machine
translation. In Proc. of ACL, pages 531?540.
25
Yonggang Deng and Bowen Zhou. 2009. Optimizing
word alignment combination for phrase table train-
ing. In Proc. ACL, pages 229?232, August.
Elliott Franco Dra?bek and David Yarowsky. 2004. Im-
proving bitext word alignments via syntax-based re-
ordering of english. In Proc. ACL.
Alexander Fraser and Daniel Marcu. 2007. Getting the
structure right for word alignment: Leaf. In Proc. of
EMNLP, pages 51?60, June.
Ulf Hermjakob. 2009. Improved word alignment with
statistics and linguistic heuristics. In Proc. EMNLP,
pages 229?237, August.
Fei Huang. 2009. Confidence measure for word align-
ment. In Proc. ACL, pages 932?940, August.
Abraham Ittycheriah and Salim Roukos. 2005. A max-
imum entropy word aligner for arabic-english ma-
chine translation. In Proc. of HLT/EMNLP, pages
89?96, October.
Philipp Koehn, Franz Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In Proc.
NAACL/HLT.
Franz Josef Och and Hermann Ney. 2000. Improved
statistical alignment models. In Proc. of ACL, pages
440?447, Hong Kong, China, October.
Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In Proc. of ACL,
pages 160?167.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
jing Zhu. 2002. Bleu: a method for automatic evalu-
ation of machine translation. In Proc. of ACL, pages
311?318.
Martin Porter. 1980. An algorithm for suffix stripping.
In Program, volume 14, pages 130?137.
Adwait Ratnaparkhi. 1997. A linear observed time sta-
tistical parser based on maximum entropy models.
In Proc. of EMNLP, pages 1?10.
Chao Wang, Michael Collins, and Philipp Koehn.
2007. Chinese syntactic reordering for statistical
machine translation. In Proc. EMNLP, pages 737?
745.
Bing Xiang, Kham Nguyen, Long Nguyen, Richard
Schwartz, and John Makhoul. 2006. Morphological
decomposition for arabic broadcast news transcrip-
tion. In Proc. ICASSP.
Peng Xu, Jaeho Kang, Michael Ringgaard, and Franz
Och. 2009. Using a dependency parser to improve
smt for subject-object-verb languages. In Proc.
NAACL/HLT, pages 245?253, June.
26
