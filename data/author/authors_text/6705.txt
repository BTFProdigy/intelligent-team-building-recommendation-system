Proceedings of the ACL-ISMB Workshop on Linking Biological Literature, Ontologies and Databases: Mining
Biological Semantics, pages 46?53, Detroit, June 2005. c?2005 Association for Computational Linguistics
Using Biomedical Literature Mining to Consolidate the Set of Known
Human Protein?Protein Interactions
Arun Ramani, Edward Marcotte
Institute for Cellular and Molecular Biology
University of Texas at Austin
1 University Station A4800
Austin, TX 78712
arun@icmb.utexas.edu
marcotte@icmb.utexas.edu
Razvan Bunescu, Raymond Mooney
Department of Computer Sciences
University of Texas at Austin
1 University Station C0500
Austin, TX 78712
razvan@cs.utexas.edu
mooney@cs.utexas.edu
Abstract
This paper presents the results of a large-
scale effort to construct a comprehensive
database of known human protein inter-
actions by combining and linking known
interactions from existing databases and
then adding to them by automatically min-
ing additional interactions from 750,000
Medline abstracts. The end result is a
network of 31,609 interactions amongst
7,748 proteins. The text mining sys-
tem first identifies protein names in the
text using a trained Conditional Random
Field (CRF) and then identifies interac-
tions through a filtered co-citation anal-
ysis. We also report two new strategies
for mining interactions, either by finding
explicit statements of interactions in the
text using learned pattern-based rules or
a Support-Vector Machine using a string
kernel. Using information in existing on-
tologies, the automatically extracted data
is shown to be of equivalent accuracy to
manually curated data sets.
1 Introduction
Proteins are often considered in terms of their net-
works of interactions, a view that has spurred con-
siderable effort in mapping large-scale protein in-
teraction networks. Thus far, the most complete
protein networks are measured for yeast and de-
rive from the synthesis of varied large scale experi-
mental interaction data and in-silico interaction pre-
dictions (summarized in (von Mering et al, 2002;
Lee et al, 2004; Jansen et al, 2003)). Unlike the
case of yeast, only minimal progress has been made
with respect to the human proteome. While some
moderate-scale interaction maps have been created,
such as for the purified TNFa/NFKB protein com-
plex (Bouwmeester et al, 2004) and the proteins in-
volved in the human Smad signaling pathway (Col-
land et al, 2004), the bulk of known human pro-
tein interaction data derives from individual, small-
scale experiments reported in Medline. Many of
these interactions have been collected in the Reac-
tome (Joshi-Tope et al, 2005), BIND (Bader et al,
2003), DIP (Xenarios et al, 2002), and HPRD (Peri
et al, 2004) databases, with Reactome contributing
11,000 interactions that have been manually entered
from articles focusing on interactions in core cellular
pathways, and HPRD contributing a set of 12,000
interactions recovered by manual curation of Med-
line articles using teams of readers. Additional inter-
actions have been transferred from other organisms
based on orthology (Lehner and Fraser, 2004).
A comparison of these existing interaction data
sets is enlightening. Although the interactions from
these data sets are in principle derived from the same
source (Medline), the sets are quite disjoint (Fig-
ure 1) implying either that the sets are biased for
different classes of interactions, or that the actual
number of interactions in Medline is quite large.
We suspect both reasons. It is clear that each data
set has a different explicit focus (Reactome towards
core cellular machinery, HPRD towards disease-
linked genes, and DIP and BIND more randomly
46
distributed). Due to these biases, it is likely that
many interactions from Medline are still excluded
from these data sets. The maximal overlap between
interaction data sets is seen for BIND: 25% of these
interactions are also in HPRD or Reactome; only 1%
of Reactome interactions are in HPRD or BIND.
Figure 1: Overlap diagram for known datasets.
Medline now has records from more than 4,800
journals accounting for around 15 million articles.
These citations contain thousands of experimentally
recorded protein interactions, and even a cursory in-
vestigation of Medline reveals human protein inter-
actions not present in the current databases. How-
ever, retrieving these data manually is made diffi-
cult by the large number of articles, all lacking for-
mal structure. Automated extraction of informa-
tion would be preferable, and therefore, mining data
from Medline abstracts is a growing field (Jenssen
et al, 2001; Rzhetsky et al, 2004; Liu and Wong,
2003; Hirschman et al, 2002).
In this paper, we describe a framework for
automatic extraction of protein interactions from
biomedical literature. We focus in particular on the
difficult and important problem of identifying inter-
actions concerning human proteins. We describe a
system for first accurately identifying the names of
human proteins in the documents, then on identify-
ing pairs of interacting human proteins, and demon-
strate that the extracted protein interactions are com-
parable to those extracted manually. In the pro-
cess, we consolidate the existing set of publically-
available human protein interactions into a network
of 31,609 interactions between 7,748 proteins.
2 Assembling existing protein interaction
data
We previously gathered the existing human protein
interaction data sets ((Ramani et al, 2005); sum-
marized in Table 1), representing the current sta-
tus of the publically-available human interactome.
This required unification of the interactions under
a shared naming and annotation convention. For
this purpose, we mapped each interacting protein
to LocusLink (now EntrezGene) identification num-
bers and retained only unique interactions (i.e., for
two proteins A and B, we retain only A?B or B?A,
not both). We have chosen to omit self-interactions,
A?A or B?B, for technical reasons, as their qual-
ity cannot be assessed on the functional benchmark
that we describe in Section 3. In most cases, a small
loss of proteins occurred in the conversion between
the different gene identifiers (e.g., converting from
the NCBI ?gi? codes in BIND to LocusLink iden-
tifiers). In the case of Human Protein Reference
Database (HPRD), this processing resulted in a sig-
nificant reduction in the number of interactions from
12,013 total interactions to 6,054 unique, non-self
interactions, largely due to the fact that HPRD often
records both A-B and B-A interactions, as well as a
large number of self interactions, and indexes genes
by their common names rather than conventional
database entries, often resulting in multiple entries
for different synonyms. An additional 9,283 (or
60,000 at lower confidence) interactions are avail-
able from orthologous transfer of interactions from
large-scale screens in other organisms (orthology-
core and orthology-all) (Lehner and Fraser, 2004).
3 Two benchmark tests of accuracy for
interaction data
To measure the relative accuracy of each protein in-
teraction data set, we established two benchmarks
of interaction accuracy, one based on shared protein
function and the other based on previously known
interactions. First, we constructed a benchmark in
which we tested the extent to which interaction part-
ners in a data set shared annotation, a measure previ-
ously shown to correlate with the accuracy of func-
tional genomics data sets (von Mering et al, 2002;
Lee et al, 2004; Lehner and Fraser, 2004). We
used the functional annotations listed in the KEGG
47
Dataset Version Total Is (Ps) Self (A-A) Is (Ps) Unique (A-B) Is (Ps)
Reactome 08/03/04 12,497 (6,257) 160 (160) 12,336 (807)
BIND 08/03/04 6,212 (5,412) 549 (549) 5,663 (4,762)
HPRD* 04/12/04 12,013 (4,122) 3,028 (3,028) 6,054 (2,747)
Orthology (all) 03/31/04 71,497 (6,257) 373 (373) 71,124 (6,228)
Orthology (core) 03/31/04 11,488 (3,918) 206 (206) 11,282 (3,863)
Table 1: Is = Interactions, Ps = Proteins.
(Kanehisa et al, 2004) and Gene Ontology (Ash-
burner et al, 2000) annotation databases. These
databases provide specific pathway and biological
process annotations for approximately 7,500 human
genes, assigning human genes into 155 KEGG path-
ways (at the lowest level of KEGG) and 1,356 GO
pathways (at level 8 of the GO biological process
annotation). KEGG and GO annotations were com-
bined into a single composite functional annotation
set, which was then split into independent testing
and training sets by randomly assigning annotated
genes into the two categories (3,800 and 3,815 anno-
tated genes respectively). For the second benchmark
based on known physical interactions, we assembled
the human protein interactions from Reactome and
BIND, a set of 11,425 interactions between 1,710
proteins. Each benchmark therefore consists of a
set of binary relations between proteins, either based
on proteins sharing annotation or physically inter-
acting. Generally speaking, we expect more accu-
rate protein interaction data sets to be more enriched
in these protein pairs. More specifically, we expect
true physical interactions to score highly on both
tests, while non-physical or indirect associations,
such as genetic associations, should score highly on
the functional, but not physical interaction, test.
For both benchmarks, the scoring scheme for
measuring interaction set accuracy is in the form of
a log odds ratio of gene pairs either sharing anno-
tations or physically interacting. To evaluate a data
set, we calculate a log likelihood ratio (LLR) as:
LLR = ln
P (DjI)
P (Dj:I)
= ln
P (IjD)P (:I)
P (:IjD)P (I)
(1)
where P (DjI) and P (Dj:I) are the probability
of observing the data D conditioned on the genes
sharing benchmark associations (I) and not sharing
benchmark associations (:I). In its expanded form
(obtained by applying Bayes theorem), P (IjD) and
P (:IjD) are estimated using the frequencies of in-
teractions observed in the given data set D between
annotated genes sharing benchmark associations and
not sharing associations, respectively, while the pri-
ors P (I) and P (:I) are estimated based on the to-
tal frequencies of all benchmark genes sharing the
same associations and not sharing associations, re-
spectively. A score of zero indicates interaction part-
ners in the data set being tested are no more likely
than random to belong to the same pathway or to in-
teract; higher scores indicate a more accurate data
set.
Among the literature-derived interactions (Reac-
tome, BIND, HPRD), a total of 17,098 unique in-
teractions occur in the public data sets. Testing the
existing protein interaction data on the functional
benchmark reveals that Reactome has the highest
accuracy (LLR = 3.8), followed by BIND (LLR =
2.9), HPRD (LLR = 2.1), core orthology-inferred in-
teractions (LLR = 2.1) and the non-core orthology-
inferred interaction (LLR = 1.1). The two most
accurate data sets, Reactome and BIND, form the
basis of the protein interaction?based benchmark.
Testing the remaining data sets on this benchmark
(i.e., for their consistency with these accurate pro-
tein interaction data sets) reveals a similar ranking in
the remaining data. Core orthology-inferred interac-
tions are the most accurate (LLR = 5.0), followed by
HPRD (LLR = 3.7) and non-core orthology inferred
interactions (LLR = 3.7).
4 Framework for Mining Protein?Protein
Interactions
The extraction of interacting proteins from Medline
abstracts proceeds in two separate steps:
1. First, we automatically identify protein names
48
using a CRF system trained on a set of 750
abstracts manually annotated for proteins (see
Section 5 for details).
2. Based on the output of the CRF tagger, we fil-
ter out less confident extractions and then try to
detect which pairs of the remaining extracted
protein names are interaction pairs.
For the second step, we investigate two general
methods:
 Use co-citation analysis to score each pair of
proteins based on the assumption that proteins
co-occurring in a large number of abstracts tend
to be interacting proteins. Out of the resulting
protein pairs we keep only those that co-occur
in abstracts likely to discuss interactions, based
on a Naive Bayes classifier (see Section 6 for
details).
 Given that we already have a set of 230 Med-
line abstracts manually tagged for both proteins
and interactions, we can use it to train an inter-
action extractor. In Section 7 we discuss two
different methods for learning this interaction
extractor.
5 A CRF Tagger for Protein Names
The task of identifying protein names is made diffi-
cult by the fact that unlike other organisms, such as
yeast or E. coli, the human genes have no standard-
ized naming convention, and thus present one of the
hardest sets of gene/protein names to extract. For
example, human proteins may be named with typ-
ical English words, such as ?light?, ?map?, ?com-
plement?, and ?Sonic Hedgehog?. It is therefore
necessary that an information extraction algorithm
be specifically trained to extract gene and protein
names accurately.
We have previously described (Bunescu et al,
2005) effective protein and gene name tagging us-
ing a Maximum Entropy based algorithm. Condi-
tional Random Fields (CRF) (Lafferty et al, 2001)
are new types of probabilistic models that preserve
all the advantages of Maximum Entropy models and
at the same time avoid the label bias problem by al-
lowing a sequence of tagging decisions to compete
against each other in a global probabilistic model.
In both training and testing the CRF protein-name
tagger, the corresponding Medline abstracts were
processed as follows. Text was tokenized using
white-space as delimiters and treating all punctua-
tion marks as separate tokens. The text was seg-
mented into sentences, and part-of-speech tags were
assigned to each token using Brill?s tagger (Brill,
1995). For each token in each sentence, a vector of
binary features was generated using the feature tem-
plates employed by the Maximum Entropy approach
described in (Bunescu et al, 2005). Generally, these
features make use of the words occurring before and
after the current position in the text, their POS tags
and capitalization patterns. Each feature occurring
in the training data is associated with a parameter in
the CRF model. We used the CRF implementation
from (McCallum, 2002). To train the CRF?s parame-
ters, we used 750 Medline abstracts manually anno-
tated for protein names (Bunescu et al, 2005). We
then used the trained system to tag protein and gene
names in the entire set of 753,459 Medline abstracts
citing the word ?human?.
In Figure 2 we compare the performance of the
CRF tagger with that of the Maximum Entropy tag-
ger from (Bunescu et al, 2005), using the same
set of features, by doing 10-fold cross-validation on
Yapex ? a smaller dataset of 200 manually annotated
abstracts (Franzen et al, 2002). Each model assigns
to each extracted protein name a normalized confi-
dence value. The precision?recall curves from Fig-
ure 2 are obtained by varying a threshold on the min-
imum accepted confidence. We also plot the preci-
sion and recall obtained by simply matching textual
phrases against entries from a protein dictionary.
 50
 60
 70
 80
 90
 100
 0  20  40  60  80  100
Pr
ec
is
io
n 
(%
)
Recall (%)
CRF
MaxEnt
Dict
Figure 2: Protein Tagging Performance.
49
The dictionary of human protein names was
assembled from the LocusLink and Swissprot
databases by manually curating the gene names
and synonyms (87,723 synonyms between 18,879
unique gene names) to remove genes that were re-
ferred to as ?hypothetical? or ?probable? and also to
omit entries that referred to more than one protein
identifier.
6 Co-citation Analysis and Bayesian
Classification
In order to establish which interactions occurred
between the proteins identified in the Medline ab-
stracts, we used a 2-step strategy: measure co-
citation of protein names, then enrich these pairs for
physical interactions using a Bayesian filter. First,
we counted the number of abstracts citing a pair of
proteins, and then calculated the probability of co-
citation under a random model based on the hyper-
geometric distribution (Lee et al, 2004; Jenssen et
al., 2001) as:
P (kjN;m; n) =

n
k

N   n
m  k


N
m
 (2)
where N equals the total number of abstracts, n of
which cite the first protein, m cite the second pro-
tein, and k cite both.
Empirically, we find the co-citation probability
has a hyperbolic relationship with the accuracy on
the functional annotation benchmark from Section 3,
with protein pairs co?cited with low random proba-
bility scoring high on the benchmark.
With a threshold on the estimated extraction con-
fidence of 80% (as computed by the CRF model)
in the protein name identification, close to 15,000
interactions are extracted with the co-citation ap-
proach that score comparable or better on the func-
tional benchmark than the manually extracted inter-
actions from HPRD, which serves to establish a min-
imal threshold for our mined interactions.
However, it is clear that proteins are co-cited for
many reasons other than physical interactions. We
therefore tried to enrich specifically for physical in-
teractions by applying a secondary filter. We applied
a Bayesian classifier (Marcotte et al, 2001) to mea-
sure the likelihood of the abstracts citing the pro-
tein pairs to discuss physical protein?protein inter-
actions. The classifier scores each of the co-citing
abstracts according to the usage frequency of dis-
criminating words relevant to physical protein inter-
actions. For a co-cited protein pair, we calculated
the average score of co-citing Medline abstracts and
used this to re-rank the top-scoring 15,000 co-cited
protein pairs.
Interactions extracted by co-citation and filtered
using the Bayesian estimator compare favorably
with the other interaction data sets on the functional
annotation benchmark (Figure 3). Testing the accu-
racy of these extracted protein pairs on the physi-
cal interaction benchmark (Figure 4) reveals that the
co-cited proteins scored high by this classifier are
indeed strongly enriched for physical interactions.
 0.5
 1
 1.5
 2
 2.5
 3
 3.5
 4
 0  10000  20000  30000  40000  50000  60000  70000
LL
R
 s
co
re
, f
un
ct
io
na
l b
en
ch
m
ar
k
# of interactions recovered
Co-citation, Bayes filter
BIND
Reactome
HPRD
Orthology (core)
Orthology (core)
Figure 3: Accuracy, functional benchmark
 2
 2.5
 3
 3.5
 4
 4.5
 5
 5.5
 6
 0  10000  20000  30000  40000  50000  60000  70000
LL
R
 s
co
re
, p
hy
sic
al
 b
en
ch
m
ar
k
# of interactions recovered
Co-citation, Bayes filter
HPRD
Orthology (core)
Orthology (core)
Figure 4: Accuracy, physical benchmark
Keeping all the interactions that score better than
HPRD, our co-citation / Bayesian classifier analy-
sis yields 6,580 interactions between 3,737 proteins.
By combining these interactions with the 26,280 in-
teractions from the other sources, we obtained a fi-
50
nal set of 31,609 interactions between 7,748 human
proteins.
7 Learning Interaction Extractors
In (Bunescu et al, 2005) we described a dataset of
230 Medline abstracts manually annotated for pro-
teins and their interactions. This can be used as a
training dataset for a method that learns interaction
extractors. Such a method simply classifies a sen-
tence containing two protein names as positive or
negative, where positive means that the sentence as-
serts an interaction between the two proteins. How-
ever a sentence in the training data may contain more
than two proteins and more than one pair of inter-
acting proteins. In order to extract the interacting
pairs, we replicate the sentences having n proteins
(n  2) into Cn
2
sentences such that each one has
exactly two of the proteins tagged, with the rest of
the protein tags omitted. If the tagged proteins in-
teract, then the replicated sentence is added to the
set of positive sentences, otherwise it is added to the
set of negative sentences. During testing, a sentence
having n proteins (n  2) is again replicated into
C
n
2
sentences in a similar way.
7.1 Extraction using Longest Common
Subsequences (ELCS)
Blaschke et al (Blaschke and Valencia, 2001;
Blaschke and Valencia, 2002) manually developed
rules for extracting interacting proteins. Each of
their rules (or frames) is a sequence of words (or
POS tags) and two protein-name tokens. Between
every two adjacent words is a number indicating
the maximum number of intervening words allowed
when matching the rule to a sentence. In (Bunescu
et al, 2005) we described a new method ELCS (Ex-
traction using Longest Common Subsequences) that
automatically learns such rules. ELCS? rule repre-
sentation is similar to that in (Blaschke and Valen-
cia, 2001; Blaschke and Valencia, 2002), except that
it currently does not use POS tags, but allows dis-
junctions of words. Figure 5 shows an example of a
rule learned by ELCS. Words in square brackets sep-
arated by ?j? indicate disjunctive lexical constraints,
i.e. one of the given words must match the sen-
tence at that position. The numbers in parentheses
between adjacent constraints indicate the maximum
number of unconstrained words allowed between the
two (called a word gap). The protein names are de-
noted here with PROT. A sentence matches the rule
if and only if it satisfies the word constraints in the
given order and respects the respective word gaps.
- (7) interaction (0) [between j of] (5) PROT (9) PROT (17) .
Figure 5: Sample extraction rule learned by ELCS.
7.2 Extraction using a Relation Kernel (ERK)
Both Blaschke and ELCS do interaction extraction
based on a limited set of matching rules, where a rule
is simply a sparse (gappy) subsequence of words (or
POS tags) anchored on the two protein-name tokens.
Therefore, the two methods share a common limita-
tion: either through manual selection (Blaschke), or
as a result of the greedy learning procedure (ELCS),
they end up using only a subset of all possible an-
chored sparse subsequences. Ideally, we would want
to use all such anchored sparse subsequences as fea-
tures, with weights reflecting their relative accuracy.
However explicitly creating for each sentence a vec-
tor with a position for each such feature is infeasi-
ble, due to the high dimensionality of the feature
space. Here we can exploit an idea used before in
string kernels (Lodhi et al, 2002): computing the
dot-product between two such vectors amounts to
calculating the number of common anchored sub-
sequences between the two sentences. This can be
done very efficiently by modifying the dynamic pro-
gramming algorithm from (Lodhi et al, 2002) to ac-
count only for anchored subsequences i.e. sparse
subsequences which contain the two protein-name
tokens. Besides restricting the word subsequences
to be anchored on the two protein tokens, we can
further prune down the feature space by utilizing the
following property of natural language statements:
whenever a sentence asserts a relationship between
two entity mentions, it generally does this using one
of the following three patterns:
 [FI] Fore?Inter: words before and between the
two entity mentions are simultaneously used to
express the relationship. Examples: ?interac-
tion of hP
1
i with hP
2
i?, ?activation of hP
1
i by
hP
2
i?.
51
 [I] Inter: only words between the two entity
mentions are essential for asserting the rela-
tionship. Examples: ?hP
1
i interacts with hP
2
i?,
?hP
1
i is activated by hP
2
i?.
 [IA] Inter?After: words between and after the
two entity mentions are simultaneously used
to express the relationship. Examples: hP
1
i ?
hP
2
i complex?, ?hP
1
i and hP
2
i interact?.
Another useful observation is that all these pat-
terns use at most 4 words to express the relationship
(not counting the two entities). Consequently, when
computing the relation kernel, we restrict the count-
ing of common anchored subsequences only to those
having one of the three types described above, with a
maximum word-length of 4. This type of feature se-
lection leads not only to a faster kernel computation,
but also to less overfitting, which results in increased
accuracy (we omit showing here comparative results
supporting this claim, due to lack of space).
We used this kernel in conjunction with Support
Vector Machines (Vapnik, 1998) learning in or-
der to find a decision hyperplane that best separates
the positive examples from negative examples. We
modified the libsvm package for SVM learning by
plugging in the kernel described above.
7.3 Preliminary experimental results
We compare the following three systems on the task
of retrieving protein interactions from the dataset of
230 Medline abstracts (assuming gold standard pro-
teins):
 [Manual]: We report the performance of the
rule-based system of (Blaschke and Valencia,
2001; Blaschke and Valencia, 2002).
 [ELCS]: We report the 10-fold cross-validated
results from (Bunescu et al, 2005) as a
precision-recall graph.
 [ERK]: Based on the same splits as those
used by ELCS, we compute the corresponding
precision-recall graph.
The results, summarized in Figure 6, show that
the relation kernel outperforms both ELCS and the
manually written rules. In future work, we intend
to analyze the complete Medline with ERK and in-
tegrate the extracted interactions into a larger com-
posite set.
 0
 10
 20
 30
 40
 50
 60
 70
 80
 90
 100
 0  10  20  30  40  50  60  70  80  90  100
Pr
ec
is
io
n 
(%
)
Recall (%)
ERK
Manual
ELCS
Figure 6: PR curves for interaction extractors.
8 Conclusion
Through a combination of automatic text mining and
consolidation of existing databases, we have con-
structed a large database of known human protein
interactions containing 31,609 interactions amongst
7,748 proteins. By mining 753,459 human-related
abstracts from Medline with a combination of a
CRF-based protein tagger, co-citation analysis, and
automatic text classification, we extracted a set of
6,580 interactions between 3,737 proteins. By uti-
lizing information in existing knowledge bases, this
automatically extracted data was found to have an
accuracy comparable to manually developed data
sets. More details on our interaction database have
been published in the biological literature (Ramani
et al, 2005) and it is available on the web at
http://bioinformatics.icmb.utexas.edu/idserve. We
are currently exploring improvements to this
database by more accurately identifying assertions
of interactions in the text using an SVM that exploits
a relational string kernel.
9 Acknowledgements
This work was supported by grants from the N.S.F.
(IIS-0325116, EIA-0219061), N.I.H. (GM06779-
01), Welch (F1515), and a Packard Fellowship
(E.M.M.).
52
References
M. Ashburner, C. A. Ball, J. A. Blake, D. Botstein, H. Butler,
J. M. Cherry, A. P. Davis, K. Dolinski, S. S. Dwight, and J. T.
et al Eppig. 2000. Gene ontology: tool for the unification
of biology. the gene ontology consortium. Nature Genetics,
25(1):25?29.
G. D. Bader, D. Betel, and C. W. Hogue. 2003. Bind: the
biomolecular interaction network database. Nucleic Acids
Research, 31(1):248?250.
C. Blaschke and A. Valencia. 2001. Can bibliographic pointers
for known biological data be found automatically? protein
interactions as a case study. Comparative and Functional
Genomics, 2:196?206.
C. Blaschke and A. Valencia. 2002. The frame-based module
of the Suiseki information extraction system. IEEE Intelli-
gent Systems, 17:14?20.
T. Bouwmeester, A. Bauch, H. Ruffner, P. O. Angrand,
G. Bergamini, K. Croughton, C. Cruciat, D. Eberhard,
J. Gagneur, S. Ghidelli, and et al 2004. A physical and
functional map of the human tnf-alpha/nf-kappa b signal
transduction pathway. Nature Cell Biology, 6(2):97?105.
Eric Brill. 1995. Transformation-based error-driven learning
and natural language processing: A case study in part-of-
speech tagging. Computational Linguistics, 21(4):543?565.
Razvan Bunescu, Ruifang Ge, Rohit J. Kate, Edward M.
Marcotte, Raymond J. Mooney, Arun Kumar Ramani, and
Yuk Wah Wong. 2005. Comparative experiments on learn-
ing information extractors for proteins and their interactions.
Artificial Intelligence in Medicine (special issue on Sum-
marization and Information Extraction from Medical Doc-
uments), 33(2):139?155.
F. Colland, X. Jacq, V. Trouplin, C. Mougin, C. Groizeleau,
A. Hamburger, A. Meil, J. Wojcik, P. Legrain, and J. M.
Gauthier. 2004. Functional proteomics mapping of a human
signaling pathway. Genome Research, 14(7):1324?1332.
K. Franzen, G. Eriksson, F. Olsson, L. Asker, P. Liden, and
J. Coster. 2002. Protein names and how to find them. Inter-
national Journal of Medical Informatics, 67(1-3):49?61.
L. Hirschman, J. C. Park, J. Tsujii, L. Wong, and C. H. Wu.
2002. Accomplishments and challenges in literature data
mining for biology. Bioinformatics, 18(12):1553?1561.
R. Jansen, H. Yu, D. Greenbaum, Y. Kluger, N. J. Krogan,
S. Chung, A. Emili, M. Snyder, J. F. Greenblatt, and M. Ger-
stein. 2003. A bayesian networks approach for predict-
ing protein-protein interactions from genomic data. Science,
302(5644):449?453.
T. K. Jenssen, A. Laegreid, J. Komorowski, and E. Hovig. 2001.
A literature network of human genes for high-throughput
analysis of gene expression. Nature Genetics, 28(1):21?28.
G. Joshi-Tope, M. Gillespie, I. Vastrik, P. D?Eustachio,
E. Schmidt, B. de Bono, B. Jassal, G. R. Gopinath, G. R.
Wu, L. Matthews, and et al 2005. Reactome: a knowl-
edgebase of biological pathways. Nucleic Acids Research,
33 Database Issue:D428?432.
M. Kanehisa, S. Goto, S. Kawashima, Y. Okuno, and M. Hat-
tori. 2004. The kegg resource for deciphering the genome.
Nucleic Acids Research, 32 Database issue:D277?280.
John Lafferty, Andrew McCallum, and Fernando Pereira. 2001.
Conditional random fields: Probabilistic models for seg-
menting and labeling sequence data. In Proceedings of
18th International Conference on Machine Learning (ICML-
2001), pages 282?289, Williamstown, MA.
I. Lee, S. V. Date, A. T. Adai, and E. M. Marcotte. 2004. A
probabilistic functional network of yeast genes. Science,
306(5701):1555?1558.
B. Lehner and A. G. Fraser. 2004. A first-draft human protein-
interaction map. Genome Biology, 5(9):R63.
H. Liu and L. Wong. 2003. Data mining tools for biological se-
quences. Journal of Bioinformatics and Computational Bi-
ology, 1(1):139?167.
Huma Lodhi, Craig Saunders, John Shawe-Taylor, Nello Cris-
tianini, and Chris Watkins. 2002. Text classification us-
ing string kernels. Journal of Machine Learning Research,
2:419?444.
E. M. Marcotte, I. Xenarios, and D. Eisenberg. 2001. Min-
ing literature for protein-protein interactions. Bioinformat-
ics, 17(4):359?363.
Andrew Kachites McCallum. 2002. Mallet: A machine learn-
ing for language toolkit. http://mallet.cs.umass.edu.
S. Peri, J. D. Navarro, T. Z. Kristiansen, R. Amanchy, V. Suren-
dranath, B. Muthusamy, T. K. Gandhi, K. N. Chandrika,
N. Deshpande, S. Suresh, and et al 2004. Human protein
reference database as a discovery resource for proteomics.
Nucleic Acids Research, 32 Database issue:D497?501.
A. K. Ramani, R. C. Bunescu, R. J. Mooney, and E. M. Mar-
cotte. 2005. Consolidating the set of know human protein-
protein interactions in preparation for large-scale mapping of
the human interactome. Genome Biology, 6(5):r40.
A. Rzhetsky, I. Iossifov, T. Koike, M. Krauthammer, P. Kra,
M. Morris, H. Yu, P. A. Duboue, W. Weng, W. J. Wilbur,
V. Hatzivassiloglou, and C. Friedman. 2004. Geneways: a
system for extracting, analyzing, visualizing, and integrating
molecular pathway data. Journal of Biomedical Informatics,
37(1):43?53.
Vladimir N. Vapnik. 1998. Statistical Learning Theory. John
Wiley & Sons.
C. von Mering, R. Krause, B. Snel, M. Cornell, S. G. Oliver,
S. Fields, and P. Bork. 2002. Comparative assessment of
large-scale data sets of protein-protein interactions. Nature,
417(6887):399?403.
I. Xenarios, L. Salwinski, X. J. Duan, P. Higney, S. M. Kim, and
D. Eisenberg. 2002. Dip, the database of interacting pro-
teins: a research tool for studying cellular networks of pro-
tein interactions. Nucleic Acids Research, 30(1):303?305.
53
Proceedings of the BioNLP Workshop on Linking Natural Language Processing and Biology at HLT-NAACL 06, pages 49?56,
New York City, June 2006. c?2006 Association for Computational Linguistics
Integrating Co-occurrence Statistics with Information Extraction for
Robust Retrieval of Protein Interactions from Medline
Razvan Bunescu, Raymond Mooney
Department of Computer Sciences
University of Texas at Austin
1 University Station C0500
Austin, TX 78712
razvan@cs.utexas.edu
mooney@cs.utexas.edu
Arun Ramani, Edward Marcotte
Institute for Cellular and Molecular Biology
University of Texas at Austin
1 University Station A4800
Austin, TX 78712
arun@icmb.utexas.edu
marcotte@icmb.utexas.edu
Abstract
The task of mining relations from collec-
tions of documents is usually approached
in two different ways. One type of sys-
tems do relation extraction from individ-
ual sentences, followed by an aggrega-
tion of the results over the entire collec-
tion. Other systems follow an entirely dif-
ferent approach, in which co-occurrence
counts are used to determine whether the
mentioning together of two entities is due
to more than simple chance. We show
that increased extraction performance can
be obtained by combining the two ap-
proaches into an integrated relation ex-
traction model.
1 Introduction
Information Extraction (IE) is a natural language
processing task in which text documents are ana-
lyzed with the aim of finding mentions of relevant
entities and important relationships between them.
In many cases, the subtask of relation extraction re-
duces to deciding whether a sentence asserts a par-
ticular relationship between two entities, which is
still a difficult, unsolved problem. There are how-
ever cases where the decision whether the two enti-
ties are in a relationship is made relative to an en-
tire document, or a collection of documents. In the
biomedical domain, for example, one may be inter-
ested in finding the pairs of human proteins that are
said to be interacting in any of the Medline abstracts,
where the answer is not required to specify which
abstracts are actually describing the interaction. As-
sembling a ranked list of interacting proteins can be
very useful to biologists - based on this list, they can
make more informed decisions with respect to which
genes to focus on in their research.
In this paper, we investigate methods that use
multiple occurrences of the same pair of entities
across a collection of documents in order to boost
the performance of a relation extraction system.
The proposed methods are evaluated on the task
of finding pairs of human proteins whose interac-
tions are reported in Medline abstracts. The major-
ity of known human protein interactions are derived
from individual, small-scale experiments reported in
Medline. Some of these interactions have already
been collected in the Reactome (Joshi-Tope et al,
2005), BIND (Bader et al, 2003), DIP (Xenarios et
al., 2002), and HPRD (Peri et al, 2004) databases.
The amount of human effort involved in creating and
updating these databases is currently no match for
the continuous growth of Medline. It is therefore
very useful to have a method that automatically and
reliably extracts interaction pairs from Medline.
Systems that do relation extraction from a col-
lection of documents can be divided into two ma-
jor categories. In one category are IE systems
that first extract information from individual sen-
tences, and then combine the results into corpus-
level results (Craven, 1999; Skounakis and Craven,
2003). The second category corresponds to ap-
proaches that do not exploit much information from
the context of individual occurrences. Instead,
based on co-occurrence counts, various statistical
49
or information-theoretic tests are used to decide
whether the two entities in a pair appear together
more often than simple chance would predict (Lee
et al, 2004; Ramani et al, 2005). We believe that
a combination of the two approaches can inherit the
advantages of each method and lead to improved re-
lation extraction accuracy.
The following two sections describe the two or-
thogonal approaches to corpus-level relation extrac-
tion. A model that integrates the two approaches is
then introduced in Section 4. This is followed by a
description of the dataset used for evaluation in Sec-
tion 5, and experimental results in Section 6.
2 Sentence-level relation extraction
Most systems that identify relations between enti-
ties mentioned in text documents consider only pair
of entities that are mentioned in the same sentence
(Ray and Craven, 2001; Zhao and Grishman, 2005;
Bunescu and Mooney, 2005). To decide the exis-
tence and the type of a relationship, these systems
generally use lexico-semantic clues inferred from
the sentence context of the two entities. Much re-
search has been focused recently on automatically
identifying biologically relevant entities and their
relationships such as protein-protein interactions or
subcellular localizations. For example, the sentence
?TR6 specifically binds Fas ligand?, states an inter-
action between the two proteins TR6 and Fas ligand.
One of the first systems for extracting interactions
between proteins is described in (Blaschke and Va-
lencia, 2001). There, sentences are matched deter-
ministically against a set of manually developed pat-
terns, where a pattern is a sequence of words or Part-
of-Speech (POS) tags and two protein-name tokens.
Between every two adjacent words is a number in-
dicating the maximum number of words that can be
skipped at that position. An example is: ?interaction
of (3) <P> (3) with (3) <P>?. This approach is
generalized in (Bunescu and Mooney, 2005), where
subsequences of words (or POS tags) from the sen-
tence are used as implicit features. Their weights are
learned by training a customized subsequence ker-
nel on a dataset of Medline abstracts annotated with
proteins and their interactions.
A relation extraction system that works at the
sentence-level and which outputs normalized confi-
dence values for each extracted pair of entities can
also be used for corpus-level relation extraction. A
straightforward way to do this is to apply an aggre-
gation operator over the confidence values inferred
for all occurrences of a given pair of entities. More
exactly, if p
1
and p
2
are two entities that occur in a
total of n sentences s
1
, s
2
, ..., s
n
in the entire corpus
C , then the confidence P (R(p
1
; p
2
)jC) that they are
in a particular relationship R is defined as:
P (R(p
1
; p
2
)jC) =  (fP (R(p
1
; p
2
)js
i
)ji=1:ng)
Table 1 shows only four of the many possible
choices for the aggregation operator  .
max  
max
= max
i
P (R(p
1
; p
2
)js
i
)
noisy-or  
nor
= 1  
Y
i
(1   P (R(p
1
; p
2
)js
i
))
avg  
avg
=
X
i
P (R(p
1
; p
2
)js
i
)
n
and  
and
=
Y
i
P (R(p
1
; p
2
)js
i
)
1=n
Table 1: Aggregation Operators.
Out of the four operators in Table 1, we believe
that the max operator is the most appropriate for ag-
gregating confidence values at the corpus-level. The
question that needs to be answered is whether there
is a sentence somewhere in the corpus that asserts
the relationship R between entities p
1
and p
2
. Us-
ing avg instead would answer a different question -
whether R(p
1
; p
2
) is true in most of the sentences
containing p
1
and p
2
. Also, the and operator would
be most appropriate for finding whether R(p
1
; p
2
)
is true in all corresponding sentences in the corpus.
The value of the noisy-or operator (Pearl, 1986) is
too dependent on the number of occurrences, there-
fore it is less appropriate for a corpus where the oc-
currence counts vary from one entity pair to another
(as confirmed in our experiments from Section 6).
For examples, if the confidence threshold is set at
0:5, and the entity pair (p
1
; p
2
) occurs in 6 sentences
or less, each with confidence 0:1, then R(p
1
; p
2
) is
false, according to the noisy-or operator. However,
if (p
1
; p
2
) occur in more than 6 sentences, with the
same confidence value of 0:1, then the correspond-
ing noisy-or value exceeds 0:5, making R(p
1
; p
2
)
true.
50
3 Co-occurrence statistics
Given two entities with multiple mentions in a large
corpus, another approach to detect whether a re-
lationship holds between them is to use statistics
over their occurrences in textual patterns that are
indicative for that relation. Various measures such
as pointwise mutual information (PMI) , chi-square
(2) or log-likelihood ratio (LLR) (Manning and
Schu?tze, 1999) use the two entities? occurrence
statistics to detect whether their co-occurrence is due
to chance, or to an underlying relationship.
A recent example is the co-citation approach from
(Ramani et al, 2005), which does not try to find spe-
cific assertions of interactions in text, but rather ex-
ploits the idea that if many different abstracts refer-
ence both protein p
1
and protein p
2
, then p
1
and p
2
are likely to interact. Particularly, if the two proteins
are co-cited significantly more often than one would
expect if they were cited independently at random,
then it is likely that they interact. The model used
to compute the probability of random co-citation is
based on the hypergeometric distribution (Lee et al,
2004; Jenssen et al, 2001). Thus, if N is the total
number of abstracts, n of which cite the first protein,
m cite the second protein, and k cite both, then the
probability of co-citation under a random model is:
P (kjN;m; n) =

n
k

N   n
m  k


N
m
 (1)
The approach that we take in this paper is to con-
strain the two proteins to be mentioned in the same
sentence, based on the assumption that if there is
a reason for two protein names to co-occur in the
same sentence, then in most cases that is caused by
their interaction. To compute the ?degree of inter-
action? between two proteins p
1
and p
2
, we use the
information-theoretic measure of pointwise mutual
information (Church and Hanks, 1990; Manning
and Schu?tze, 1999), which is computed based on the
following quantities:
1. N : the total number of protein pairs co-
occurring in the same sentence in the corpus.
2. P (p
1
; p
2
) ' n
12
=N : the probability that p
1
and p
2
co-occur in the same sentence; n
12
= the
number of sentences mentioning both p
1
and
p
2
.
3. P (p
1
; p) ' n
1
=N : the probability that p
1
co-
occurs with any other protein in the same sen-
tence; n
1
= the number of sentences mention-
ing p
1
and p.
4. P (p
2
; p) ' n
2
=N : the probability that p
2
co-
occurs with any other protein in the same sen-
tence; n
2
= the number of sentences mention-
ing p
2
and p.
The PMI is then defined as in Equation 2 below:
PMI(p
1
; p
2
) = log
P (p
1
; p
2
)
P (p
1
; p)  P (p
2
; p)
' logN
n
12
n
1
 n
2
(2)
Given that the PMI will be used only for ranking
pairs of potentially interacting proteins, the constant
factor N and the log operator can be ignored. For
sake of simplicity, we use the simpler formula from
Equation 3.
sPMI(p
1
; p
2
) =
n
12
n
1
 n
2
(3)
4 Integrated model
The sPMI(p
1
; p
2
) formula can be rewritten as:
sPMI(p
1
; p
2
) =
1
n
1
 n
2

n
12
X
i=1
1 (4)
Let s
1
, s
2
, ..., s
n
12
be the sentence contexts corre-
sponding to the n
12
co-occurrences of p
1
and p
2
,
and assume that a sentence-level relation extractor
is available, with the capability of computing nor-
malized confidence values for all extractions. Then
one way of using the extraction confidence is to have
each co-occurrence weighted by its confidence, i.e.
replace the constant 1 with the normalized scores
P (R(p
1
; p
2
)js
i
), as illustrated in Equation 5. This
results in a new formula wPMI (weighted PMI),
which is equal with the product between sPMI and
the average aggregation operator  
avg
.
wPMI(p
1
; p
2
) =
1
n
1
 n
2

n
12
X
i=1
P (R(p
1
; p
2
)js
i
)
=
n
12
n
1
 n
2
  
avg
(5)
51
The operator  
avg
can be replaced with any other ag-
gregation operator from Table 1. As argued in Sec-
tion 2, we consider max to be the most appropriate
operator for our task, therefore the integrated model
is based on the weighted PMI product illustrated in
Equation 6.
wPMI(p
1
; p
2
) =
n
12
n
1
 n
2
  
max
(6)
=
n
12
n
1
 n
2
 max
i
P (R(p
1
; p
2
)js
i
)
If a pair of entities p
1
and p
2
is ranked by wPMI
among the top pairs, this means that it is unlikely
that p
1
and p
2
have co-occurred together in the en-
tire corpus by chance, and at the same time there is
at least one mention where the relation extractor de-
cides with high confidence that R(p
1
; p
2
) = 1.
5 Evaluation Corpus
Contrasting the performance of the integrated model
against the sentence-level extractor or the PMI-
based ranking requires an evaluation dataset that
provides two types of annotations:
1. The complete list of interactions reported in the
corpus (Section 5.1).
2. Annotation of mentions of genes and proteins,
together with their corresponding gene identi-
fiers (Section 5.2).
We do not differentiate between genes and their
protein products, mapping them to the same gene
identifiers. Also, even though proteins may partic-
ipate in different types of interactions, we are con-
cerned only with detecting whether they interact in
the general sense of the word.
5.1 Medline Abstracts and Interactions
In order to compile an evaluation corpus and an as-
sociated comprehensive list of interactions, we ex-
ploited information contained in the HPRD (Peri
et al, 2004) database. Every interaction listed in
HPRD is linked to a set of Medline articles where the
corresponding experiment is reported. More exactly,
each interaction is specified in the database as a tuple
that contains the LocusLink (now EntrezGene) iden-
tifiers of all genes involved and the PubMed identi-
fiers of the corresponding articles (as illustrated in
Table 2).
Interaction (XML) (HPRD)
<interaction>
<gene>2318</gene>
<gene>58529</gene>
<pubmed>10984498 11171996</pubmed>
</interaction>
Participant Genes (XML) (NCBI)
<gene id=?2318?>
<name>FLNC</name>
<description>filamin C, gamma</description>
<synonyms>
<synonym>ABPA</synonym>
<synonym>ABPL</synonym>
<synonym>FLN2</synonym>
<synonym>ABP-280</synonym>
<synonym>ABP280A</synonym>
</synonyms>
<proteins>
<protein>gamma filamin</protein>
<protein>filamin 2</protein>
<protein>gamma-filamin</protein>
<protein>ABP-L, gamma filamin</protein>
<protein>actin-binding protein 280</protein>
<protein>gamma actin-binding protein</protein>
<protein>filamin C, gamma</protein>
</proteins>
</gene>
<gene id=?58529?>
<name>MYOZ1</name>
<description>myozenin 1</description>
<synonyms> ... </synonyms>
<proteins> ... </proteins>
</gene>
Medline Abstract (XML) (NCBI)
<PMID>10984498</PMID>
<AbstractText>
We found that this protein binds to three other Z-disc pro-
teins; therefore, we have named it FATZ, gamma-filamin,
alpha-actinin and telethonin binding protein of the Z-disc.
</AbstractText>
Table 2: Interactions, Genes and Abstracts.
The evaluation corpus (henceforth referred to as
the HPRD corpus) is created by collecting the Med-
line abstracts corresponding to interactions between
human proteins, as specified in HPRD. In total,
5,617 abstracts are included in this corpus, with an
associated list of 7,785 interactions. This list is com-
prehensive - the HPRD database is based on an an-
notation process in which the human annotators re-
port all interactions described in a Medline article.
On the other hand, the fact that only abstracts are
included in the corpus (as opposed to including the
full article) means that the list may contain interac-
tions that are not actually reported in the HPRD cor-
pus. Nevertheless, if the abstracts were annotated
52
with gene mentions and corresponding GIDs, then
a ?quasi-exact? interaction list could be computed
based on the following heuristic:
[H] If two genes with identifiers gid
1
and gid
2
are
mentioned in the same sentence in an abstract with
PubMed identifier pmid, and if gid
1
and gid
2
are
participants in an interaction that is linked to pmid
in HPRD, then consider that the abstract (and con-
sequently the entire HPRD corpus) reports the inter-
action between gid
1
and gid
2
. 
An application of the above heuristic is shown at
the bottom of Table 2. The HPRD record at the
top of the table specifies that the Medline article
with ID 10984498 reports an interaction between the
proteins FATZ (with ID 58529) and gamma-filamin
(with ID 2318). The two protein names are men-
tioned in a sentence in the abstract for 10984498,
therefore, by [H], we consider that the HPRD cor-
pus reports this interaction.
This is very similar to the procedure used in
(Craven, 1999) for creating a ?weakly-labeled?
dataset of subcellular-localization relations. [H] is
a strong heuristic ? it is already known that the full
article reports an interaction between the two genes.
Finding the two genes collocated in the same sen-
tence in the abstract is very likely to be due to the
fact that the abstract discusses their interaction. The
heuristic can be made even more accurate if a pair
of genes is considered as interacting only if they co-
occur in a (predefined) minimum number of sen-
tences in the entire corpus ? with the evaluation
modified accordingly, as described later in Section 6.
5.2 Gene Name Annotation and Normalization
For the annotation of gene names and their normal-
ization, we use a dictionary-based approach similar
to (Cohen, 2005). NCBI1 provides a comprehen-
sive dictionary of human genes, where each gene is
specified by its unique identifier, and qualified with
an official name, a description, synonym names and
one or more protein names, as illustrated in Table 2.
All of these names, including the description, are
considered as potential referential expressions for
the gene entity. Each name string is reduced to a
normal form by: replacing dashes with spaces, intro-
ducing spaces between sequences of letters and se-
1URL: http://www.ncbi.nih.gov
quences of digits, replacing Greek letters with their
Latin counterparts (capitalized), substituting Roman
numerals with Arabic numerals, decapitalizing the
first word if capitalized. All names are further tok-
enized, and checked against a dictionary of close to
100K English nouns. Names that are found in this
dictionary are simply filtered out. We also ignore
all ambiguous names (i.e. names corresponding to
more than one gene identifier). The remaining non-
ambiguous names are added to the final gene dictio-
nary, which is implemented as a trie-like structure in
order to allow a fast lookup of gene IDs based on the
associated normalized sequences of tokens.
Each abstract from the HPRD corpus is tokenized
and segmented in sentences using the OpenNLP2
package. The resulting sentences are then annotated
by traversing them from left to right and finding the
longest token sequences whose normal forms match
entries from the gene dictionary.
6 Experimental Evaluation
The main purpose of the experiments in this section
is to compare the performance of the following four
methods on the task of corpus-level relation extrac-
tion:
1. Sentence-level relation extraction followed by
the application of an aggregation operator that
assembles corpus-level results (SSK.Max).
2. Pointwise Mutual Information (PMI).
3. The integrated model, a product of the two base
models (PMI.SSK.Max).
4. The hypergeometric co-citation method (HG).
7 Experimental Methodology
All abstracts, either from the HPRD corpus, or
from the entire Medline, are annotated using the
dictionary-based approach described in Section 5.2.
The sentence-level extraction is done with the sub-
sequence kernel (SSK) approach from (Bunescu and
Mooney, 2005), which was shown to give good re-
sults on extracting interactions from biomedical ab-
stracts. The subsequence kernel was trained on a
set of 225 Medline abstracts which were manually
2URL: http://opennlp.sourceforge.net
53
annotated with protein names and their interactions.
It is known that PMI gives undue importance to
low frequency events (Dunning, 1993), therefore the
evaluation considers only pairs of genes that occur at
least 5 times in the whole corpus.
When evaluating corpus-level extraction on
HPRD, because the ?quasi-exact? list of interactions
is known, we report the precision-recall (PR) graphs,
where the precision (P) and recall (R) are computed
as follows:
P =
#true interactions extracted
#total interaction extracted
R =
#true interactions extracted
#true interactions
All pairs of proteins are ranked based on each scor-
ing method, and precision recall points are com-
puted by considering the top N pairs, where N
varies from 1 to the total number of pairs.
When evaluating on the entire Medline, we used
the shared protein function benchmark described in
(Ramani et al, 2005). Given the set of interacting
pairs recovered at each recall level, this benchmark
calculates the extent to which interaction partners
in a data set share functional annotation, a measure
previously shown to correlate with the accuracy of
functional genomics data sets (Lee et al, 2004). The
KEGG (Kanehisa et al, 2004) and Gene Ontology
(Ashburner et al, 2000) databases provide specific
pathway and biological process annotations for ap-
proximately 7,500 human genes, assigning human
genes into 155 KEGG pathways (at the lowest level
of KEGG) and 1,356 GO pathways (at level 8 of the
GO biological process annotation).
The scoring scheme for measuring interaction set
accuracy is in the form of a log odds ratio of gene
pairs sharing functional annotations. To evaluate a
data set, a log likelihood ratio (LLR) is calculated as
follows:
LLR = ln
P (DjI)
P (Dj:I)
= ln
P (IjD)P (:I)
P (:IjD)P (I)
(7)
where P (DjI) and P (Dj:I) are the probability
of observing the data D conditioned on the genes
sharing benchmark associations (I) and not sharing
benchmark associations (:I). In its expanded form
(obtained by Bayes theorem), P (IjD) and P (:IjD)
are estimated using the frequencies of interactions
observed in the given data set D between annotated
genes sharing benchmark associations and not shar-
ing associations, respectively, while the priors P (I)
and P (:I) are estimated based on the total frequen-
cies of all benchmark genes sharing the same asso-
ciations and not sharing associations, respectively.
A score of zero indicates interaction partners in the
data set being tested are no more likely than random
to belong to the same pathway or to interact; higher
scores indicate a more accurate data set.
8 Experimental Results
The results for the HPRD corpus-level extraction are
shown in Figure 1. Overall, the integrated model has
a more consistent performance, with a gain in preci-
sion mostly at recall levels past 40%. The SSK.Max
and HG models both exhibit a sudden decrease in
precision at around 5% recall level. While SSK.Max
goes back to a higher precision level, the HG model
begins to recover only late at 70% recall.
 0
 0.1
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
 0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1
Pr
ec
isi
on
Recall
PMI.SSK.Max
PMI
SSK.Max
HG
Figure 1: PR curves for corpus-level extraction.
A surprising result in this experiment is the be-
havior of the HG model, which is significantly out-
performed by PMI, and which does only marginally
better than a simple baseline that considers all pairs
to be interacting.
We also compared the two methods on corpus-
level extraction from the entire Medline, using the
shared protein function benchmark. As before, we
considered only protein pairs occurring in the same
54
sentence, with a minimum frequency count of 5. The
resulting 47,436 protein pairs were ranked accord-
ing to their PMI and HG scores, with pairs that are
most likely to be interacting being placed at the top.
For each ranking, the LLR score was computed for
the top N proteins, where N varied in increments of
1,000.
The comparative results for PMI and HG are
shown in Figure 2, together with the scores for three
human curated databases: HPRD, BIND and Reac-
tome. On the top 18,000 protein pairs, PMI outper-
forms HG substantially, after which both converge
to the same value for all the remaining pairs.
 2
 2.25
 2.5
 2.75
 3
 3.25
 3.5
 3.75
 4
 4.25
 4.5
 4.75
 5
 2500  5000  7500  10000 12500 15000 17500 20000 22500 25000
LL
R
Top N pairs
PMI
HG
HPRD
BIND
Reactome
Figure 2: Functional annotation benchmark.
Figure 3 shows a comparison of the four aggre-
gation operators on the same HPRD corpus, which
confirms that, overall, max is most appropriate for
integrating corpus-level results.
9 Future Work
The piece of related work that is closest to the aim of
this paper is the Bayesian approach from (Skounakis
and Craven, 2003). In their probabilistic model, co-
occurrence statistics are taken into account by using
a prior probability that a pair of proteins are inter-
acting, given the number of co-occurrences in the
corpus. However, they do not use the confidences of
the sentence-level extractions. The GeneWays sys-
tem from (Rzhetsky et al, 2004) takes a different
approach, in which co-occurrence frequencies are
simply used to re-rank the ouput from the relation
extractor.
An interesting direction for future research is to
 0
 0.1
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
 0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1
Pr
ec
isi
on
Recall
Max
Noisy-Or
Avg
And
Figure 3: PR curves for aggregation operators.
design a model that takes into account both the ex-
traction confidences and the co-occurrence statis-
tics, without losing the probabilistic (or information-
theoretic) interpretation. One could investigate ways
of integrating the two orthogonal approaches to
corpus-level extraction based on other statistical
tests, such as chi-square and log-likelihood ratio.
The sentence-level extractor used in this paper
was trained to recognize relation mentions in iso-
lation. However, the trained model is later used,
through the max aggregation operator, to recognize
whether multiple mentions of the same pair of pro-
teins indicate a relationship between them. This
points to a fundamental mismatch between the train-
ing and testing phases of the model. We expect that
better accuracy can be obtained by designing an ap-
proach that is using information from multiple oc-
currences of the same pair in both training and test-
ing.
10 Conclusion
Extracting relations from a collection of documents
can be approached in two fundamentally different
ways. In one approach, an IE system extracts rela-
tion instances from corpus sentences, and then ag-
gregates the local extractions into corpus-level re-
sults. In the second approach, statistical tests based
on co-occurrence counts are used for deciding if a
given pair of entities are mentioned together more
often than chance would predict. We have described
55
a method to integrate the two approaches, and given
experimental results that confirmed our intuition that
an integrated model would have a better perfor-
mance.
11 Acknowledgements
This work was supported by grants from the N.S.F.
(IIS-0325116, EIA-0219061), N.I.H. (GM06779-
01), Welch (F1515), and a Packard Fellowship
(E.M.M.).
References
M. Ashburner, C. A. Ball, J. A. Blake, D. Botstein, H. Butler,
J. M. Cherry, A. P. Davis, K. Dolinski, S. S. Dwight, and J. T.
et al Eppig. 2000. Gene ontology: tool for the unification
of biology. the gene ontology consortium. Nature Genetics,
25(1):25?29.
G. D. Bader, D. Betel, and C. W. Hogue. 2003. Bind: the
biomolecular interaction network database. Nucleic Acids
Research, 31(1):248?250.
C. Blaschke and A. Valencia. 2001. Can bibliographic pointers
for known biological data be found automatically? protein
interactions as a case study. Comparative and Functional
Genomics, 2:196?206.
Razvan C. Bunescu and Raymond J. Mooney. 2005. Subse-
quence kernels for relation extraction. In Proceedings of the
Conference on Neural Information Processing Systems, Van-
couver, BC.
Kenneth W. Church and Patrick W. Hanks. 1990. Word associ-
ation norms, mutual information and lexicography. Compu-
tational Linguistics, 16(1):22?29.
Aaron M. Cohen. 2005. Unsupervised gene/protein named en-
tity normalization using automatically extracted dictionaries.
In Proceedings of the ACL-ISMB Workshop on Linking Bio-
logical Literature, Ontologies and Databases: Minining Bi-
ological Semantics, pages 17?24, Detroit, MI.
Mark Craven. 1999. Learning to extract relations from MED-
LINE. In Papers from the Sixteenth National Conference
on Artificial Intelligence (AAAI-99) Workshop on Machine
Learning for Information Extraction, pages 25?30, July.
Ted Dunning. 1993. Accurate methods for the statistics
of surprise and coincidence. Computational Linguistics,
19(1):61?74.
T. K. Jenssen, A. Laegreid, J. Komorowski, and E. Hovig. 2001.
A literature network of human genes for high-throughput
analysis of gene expression. Nature Genetics, 28(1):21?28.
G. Joshi-Tope, M. Gillespie, I. Vastrik, P. D?Eustachio,
E. Schmidt, B. de Bono, B. Jassal, G. R. Gopinath, G. R.
Wu, L. Matthews, and et al 2005. Reactome: a knowl-
edgebase of biological pathways. Nucleic Acids Research,
33 Database Issue:D428?432.
M. Kanehisa, S. Goto, S. Kawashima, Y. Okuno, and M. Hat-
tori. 2004. The KEGG resource for deciphering the genome.
Nucleic Acids Research, 32 Database issue:D277?280.
I. Lee, S. V. Date, A. T. Adai, and E. M. Marcotte. 2004. A
probabilistic functional network of yeast genes. Science,
306(5701):1555?1558.
Christopher D. Manning and Hinrich Schu?tze. 1999. Foun-
dations of Statistical Natural Language Processing. MIT
Press, Cambridge, MA.
Judea Pearl. 1986. Fusion, propagation, and structuring in be-
lief networks. Artificial Intelligence, 29(3):241?288.
S. Peri, J. D. Navarro, T. Z. Kristiansen, R. Amanchy, V. Suren-
dranath, B. Muthusamy, T. K. Gandhi, K. N. Chandrika,
N. Deshpande, S. Suresh, and et al 2004. Human protein
reference database as a discovery resource for proteomics.
Nucleic Acids Research, 32 Database issue:D497?501.
A. K. Ramani, R. C. Bunescu, R. J. Mooney, and E. M. Mar-
cotte. 2005. Consolidating the set of know human protein-
protein interactions in preparation for large-scale mapping of
the human interactome. Genome Biology, 6(5):r40.
Soumya Ray and Mark Craven. 2001. Representing sentence
structure in hidden Markov models for information extrac-
tion. In Proceedings of the Seventeenth International Joint
Conference on Artificial Intelligence (IJCAI-2001), pages
1273?1279, Seattle, WA.
A. Rzhetsky, T. Iossifov, I. Koike, M. Krauthammer, P. Kra,
M. Morris, H. Yu, P.A. Duboue, W. Weng, W.J. Wilbur,
V. Hatzivassiloglou, and C. Friedman. 2004. GeneWays: a
system for extracting, analyzing, visualizing, and integrating
molecular pathway data. Journal of Biomedical Informatics,
37:43?53.
Marios Skounakis and Mark Craven. 2003. Evidence combina-
tion in biomedical natural-language processing. In Proceed-
ings of the 3nd ACM SIGKDD Workshop on Data Mining in
Bioinformatics (BIOKDD 2003), pages 25?32, Washington,
DC.
I. Xenarios, L. Salwinski, X. J. Duan, P. Higney, S. M. Kim, and
D. Eisenberg. 2002. DIP, the database of interacting pro-
teins: a research tool for studying cellular networks of pro-
tein interactions. Nucleic Acids Research, 30(1):303?305.
Shubin Zhao and Ralph Grishman. 2005. Extracting relations
with integrated information using kernel methods. In Pro-
ceedings of the 43rd Annual Meeting of the Association for
Computational Linguistics (ACL?05), pages 419?426, Ann
Arbor, Michigan, June. Association for Computational Lin-
guistics.
56
