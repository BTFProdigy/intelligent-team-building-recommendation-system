Multilingual Sentence Generation
Takako Aikawa
Maite Melero
Lee Schwartz
Andi Wu
Microsoft Research
One Microsoft Way
Redmond, WA 98008, USA
takakoa@microsoft.com
maitem@microsoft.com
leesc@micorosft.com
andiwu@microsoft.com
Abstract
This paper presents an overview of a
robust, broad-coverage, and
application-independent natural
language generation system. It
demonstrates how the different
language generation components
function within a multilingual
Machine Translation (MT) system,
using the languages that we are
currently working on (English,
Spanish, Japanese, and Chinese).
Section 1 provides a system
description. Section 2 focuses on the
generation components and their core
set of rules. Section 3 describes an
additional layer of generation rules
included to address application-
specific issues. Section 4 provides a
brief description of the evaluation
method and results for the MT system
of which our generation components
are a part.
1 System Description
We present a natural language generation
method in the context of a multi-lingual MT
system. The system that we have been
developing is a hybrid system with rule-based,
example-based, and statistical components.
Analysis and generation are performed with
linguistic parsers and syntactic realization
modules, the rules of which are coded by hand.
Transfer is accomplished using transfer
rules/mappings automatically extracted from
aligned corpora.
The MT process starts with a source sentence
being analyzed by the source-language parser,
which produces as output a syntactic tree. This
tree is input to the Logical Form module, which
produces a deep syntactic representation of the
input sentence, called the LF (Heidorn, G. E.,
2000). The LF uses the same basic set of
relation types for all languages. Figure 1 gives
the syntactic tree and LF for the simple English
sentence, ?I gave the pencils to John?.
Tree
LF
Figure 1
The LF is the final output of the analysis phase
and the input to the transfer phase.
Transfer extracts a set of mappings from the
source-target language MindNet (Richardson,
2000), a translation knowledge database, and
applies these mappings to the LF of the source
sentence to produce a target LF. The translation
MindNet for a language pair is a repository of
aligned LFs and portions of LFs (produced by
analyzing sentence-aligned corpora). An
alignment of two LFs is a set of mappings
between a node or set of nodes (and the relations
between them) in the source LF and a node or
set of nodes (and the relations between them) in
the target LF (Menezes & Richardson, 2001).
In the translation process, the transfer
component searches the alignments in the
MindNet for those that match portions of the LF
of the sentence being translated. Mappings with
larger context are preferred to mappings with
smaller context and higher frequency mappings
are preferred to lower frequency mappings. The
lemmas in any portion of the LF of the input
sentence that do not participate in a mapping are
mapped to a target lemma using a bilingual
dictionary. The target LF fragments from the
transfer mappings and dictionary mappings are
stitched together to produce the target LF
(Menezes & Richardson, 2001). For our
example in Figure 1, the transfer component
produces the following target LFs for Spanish,
Japanese, and Chinese (Figure 2).1
Source sentence: I gave the pencils to John.
Transferred Spanish LF:
Transferred Japanese LF:
Transferred Chinese LF:
Figure 2
The transferred LF is the input to the generation
component, which we will discuss in detail
below.
2 Syntactic Generation Component
The different language generation modules in
our system are syntactic realization components
that take as input an LF characteristic of the
language to be generated and produce a
syntactic tree and surface string for that
language. In this sense, they are functionally
similar to the REALPRO system (Lavoie and
Rambow, 1997).
1 English gloss is provided in Figure 2 for readability
purposes only.
The generation modules are not designed
specifically for MT, but rather are application-
independent. They can take as input an LF
produced by a dialog application, a critiquing
application, a database query application, an MT
application, etc. They only require a
monolingual dictionary for the language being
generated and an input LF that is characteristic
of that language. For each language there is
only one generation component that is used for
all applications, and for MT, it is used for
translation from all languages to that language.
At the beginning of generation, the input LF
is converted into a basic syntactic tree that
conforms to the tree geometry of the NLP
system. The nodes in LF become subtrees of this
tree and the LF relations become
complement/adjunct relationships between the
subtrees. This basic tree can be set up in
different ways. For English, Spanish, and
Chinese, we set it up as strictly head-initial with
all the complements/adjuncts following the
head, resembling the tree of a VSO language.
For Japanese, we set it up as strictly head-final,
with all the complements/adjuncts preceding the
head. Figure 3 gives the basic Spanish
generation tree produced from the Spanish
transferred LF in Figure 2.
Figure 3
The generation rules apply to the basic tree,
transforming it into a target language tree. In the
application of the rules, we traverse the tree in a
top-down, left-to-right, depth-first fashion,
visiting each node and applying the relevant
rules. Each rule can perform one or more of the
following operations:
(1) Assign a syntactic label to the node. For
example, the ?DECL? label will be assigned
to the root node of a declarative sentence.
(2) Modify a node by changing some
information within the node. For example, a
pronoun might be marked as reflexive if it is
found to be co-referential with the subject of
the clause it is in.
(3) Expand a node by introducing new node(s)
into the tree. For example, the ?Definite?
(+Def) feature on a node may become a
determiner phrase attached to the syntactic
subtree for that node.
(4) Delete a node. For example, for a pro-drop
language, a pronominal subject may be
removed from the tree.
(5) Move a node by deleting it from Position A
and inserting it in Position B. For example,
for an SVO language, the subject NP of a
sentence may be moved from a post-verbal
position to a pre-verbal position.
(6) Ensure grammatical agreement between
nodes. For example, if the subject of a
sentence is first person singular, those
number and person features will be assigned
to the main verb.
(7) Insert punctuation and capitalization.
The nodes in the generated tree are linked to
each other by relations such as ?head?, ?parent?
and ?sibling?. The entire tree is thus visible
from any given node via these relations. When
a rule is applied to a node, the decisions made in
that rule can be based not just on features of that
node, but also on features of any other node in
the tree. This basically eliminates the need for
backtracking, which would be necessary only if
there were local ambiguities resulting from the
absence of global information. In this sense, our
approach is similar to that of other large-scale
generators (Tomita and Nyberg, 1988).
The generation rules operate on a single tree.
Rule application is deterministic and thus very
efficient. If necessary, the tree can be traversed
more than once, as is the case in the generation
modules for the languages we are currently
working on. There is a ?feeding? relationship
among the rules. The rules that assign
punctuation and capitalization, for example, do
not apply until all the movement rules have
applied, and movement rules do not apply until
nodetypes and functional roles are assigned.
To improve efficiency and to prevent a rule
from applying at the wrong time or to the wrong
structure, the rules are classified into different
groups according to the passes in which they are
applied. Each traversal of the tree activates a
given group of rules. The order in which the
different groups of rules are applied depends on
the feeding relations.
For the simple example in Figure 2 above,
the Spanish, Chinese, and Japanese generation
components all have an initial pass that assigns
nodetypes and functional roles and a final pass
that inserts punctuation marks.
In addition, the Spanish component, in a first
pass that identifies syntactic functions, deletes
the pronominal subject and inserts a dative clitic
pronoun. It also inserts the definite article and
the personal marker ?a?. In a second pass, it
checks agreement between indirect object and
doubled clitic as well as between subject and
verb, assigning the appropriate person, number,
and gender agreement information to the
terminal nodes.
Reordering operations, such as moving the
clitic in front of the verb, if the verb is finite, or
after, if it is non-finite, come later. The last pass
takes care of euphonic issues, such as
contractions or apocopated adjectives. Figure 4a
shows the resulting tree.
Figure 4a
The Chinese component has a node-
modification pass, which adds the FUNCW
node headed by (le) to indicate past tense. In
this pass the direct object is also turned into a
prepositional phrase introduced by (ba) to
show the definiteness of the NP. Following this
pass, a movement pass moves the subject in
front of the verb.
Figure 4b
The Japanese component has a pass in which
case-markers or modifiers are inserted. In
Figure 4c, the nominative, the accusative, and
the dative case markers are inserted in the
subject, direct object, and indirect object NPs,
respectively. Also, the demonstrative
corresponding to English "that" is inserted at the
beginning of the definite NP (pencil).
Figure 4c
After the grammatical rules apply, the
morphological rules apply to the leaf nodes of
the tree. Since each node in the tree is a feature
matrix and agreement information has already
been assigned by the generation rules,
morphological processing simply turns the
feature matrices into inflected forms. For
instance, in our Spanish example, the verb ?dar?
with the ?past?, ?singular? and ?1st person?
features is spelled out as ?di?. Once all the
words are inflected, the inflected form of each
leaf node is displayed to produce the surface
string. This completes the generation process,
as exemplified for Spanish in Figure 5.
Figure 5
3 Application-Driven Generation
The example used in the previous sections is
quite simple, and not representative of the actual
problems that arise in MT. Applications, such
as MT, that automatically create input for the
generation component for a language will not
always produce ideal LFs for that language, i.e.,
LFs that could have been produced by the
analysis modules for that language.
We have designed the generation
components, therefore, to add a degree of
robustness to our applications. To some extent,
and based only on information about the
language being generated, the generation
components will fix incomplete or inconsistent
LFs and will verify that the structures they
generate comply with the constraints imposed
by the target language.
The core generation rules are designed to be
application-independent and source-language-
independent. Expanding the rule base to cover
all the idiosyncrasies of the input would
contaminate the core rules and result in loss of
generality. In order to maintain the integrity of
the core rules while accommodating imperfect
input, we have opted to add a pre-generation
layer to our generation components.
Pre-generation rules apply before the basic
syntactic tree is built. They can modify the
input LF by adding or removing features,
changing lemmas, or even changing structural
relations. Below we give examples of problems
solved in the pre-generation layers of our
different language generation modules. These
illustrate not just the source-language
independence, but also the application-
independence of the generation modules.
We start with the English generation
component, which was used in experimental
question-answering applications before being
used in MT. Among the pre-generation rules in
this component is one that removes the marker
indicating non-restrictive modification (Nonrest)
from LF nodes that are not in a modification
relationship to another LF node. So, for
example, when the question-answering
application is presented with the query ?When
did Hitler come to power,? the NLP system
analyzes the question, produces an LF for it,
searches its Encarta Mindnet (which contains
the LFs for the sentences in the Encarta
encyclopedia), retrieves the LF fragment in
Figure 6, and sends it to the English generation
component.
Figure 6
The LF that is the input to generation in this
example is a portion of the LF representation of
a complete sentence that includes the phrase
?Hitler, who came to power in 1933.? The part
of that sentence that answers the question is the
nonrestrictive relative clause ?who came to
power in 1933.? Yet, we do not want to
generate the answer as a non-restrictive relative
clause (as indicated by Nonrest in the LF), but
as a declarative sentence. So, rather than pollute
the core generation rules by including checks for
implausible contexts in the rule for generating
nonrestrictive modifiers, a pre-generation rule
simply cleans up the input. The rule is
application-independent (though motivated by a
particular application) and can only serve to
clean up bad input, whatever its source.
An example of a rule motivated by MT, but
useful for other applications, is the pre-
generation rule that changes the quantifier ?less?
to ?fewer?, and vice versa, in the appropriate
situations. When the LF input to the English
generation component specifies ?less? as a
quantifier of a plural count noun such as ?car,?
this rule changes the quantifier to ?fewer?.
Conversely, when an input LF has ?fewer?
specified as a quantifier of a mass noun such as
?luck?, the rule changes it to ?less.? This rule
makes no reference to the source of the input to
generation. This has the advantage that it will
apply in a grammar-checking application as well
as in an MT application (or any other
application). If the input to English generation
were the LF produced for the ungrammatical
sentence ?He has less cars,? the generation
component would produce the correct ?He has
fewer cars,? thereby effectively grammar
checking the sentence. And, if the ultimate
source of the same input LF were the Spanish
sentence ?Juan tiene menos coches, ? the result
would be the same, even if ?menos? which
corresponds to both ?less? and ?fewer? in
English, were not transferred correctly. Another
type of problem that a generation component
might encounter is the absence of necessary
information. The Spanish generation
component, for instance, may receive as input
underspecified nominal relations, such as the
one exemplified in Figure 7, in which a noun
(registro) is modified by another noun
(programa). The relationship between the two
nouns needs to be made explicit, in Spanish, by
means of a preposition when the modifying
noun is not a proper noun. Absent the necessary
information in the incoming LF, a pre-
generation rule introduces the default
preposition ?de? to specify this relationship.
Figure 7
Another example of a pre-generation rule, this
time from Japanese, deals with the unspecified
1st/2nd person pronominal subject for particular
types of predicates. The 1st/2nd person pronoun
( ) is not used as the subject in
sentences that express the speaker?s/the
listener?s desire (unless there is some
focus/contrast on the subject). So, one of the
Japanese pre-generation rules deletes the subject
in the input LF that involves such a predicate.
For instance, below is the input LF, the modified
LF, and the string produced from the English
sentence ?I want to read the book.?
Figure 8
From Chinese, we give an example of a rule that
actually changes the structure of an LF. In our
system, it is possible for the source and target
languages to have different LF representations
for similar structures. In English and other
European languages, for example, the verb ?BE?
is required in sentences like ?He is smart?. In
Chinese, however, no copula is used. Instead,
an adjectival predicate is used. While we might
attempt at the LF level to unify these
representations, we have not yet done so.
Moreover, the LF in our system is not intended
to be an interlingua representation. Differences
between languages and their LFs are tolerated.
Therefore, Chinese uses a pre-generation rule to
transform the be-predicate adjective LF into its
Chinese equivalent as shown in Figure 9, though
we soon expect transfer to automatically do this.
Figure 9
4 Evaluation
The generation components described in the
previous sections are part of an MT system that
has been run on actual Microsoft technical
documentation. The system is frequently
evaluated to provide a measure of progress and
to yield feedback on its design and development.
In evaluating our progress over time and
comparing our system with others, we have
performed several periodic, blind human
evaluations. We focus here on the evaluation of
our Spanish-English and English-Spanish
systems.
For each evaluation, several human raters
judge the same set of 200-250 sentences
randomly extracted from our technical corpora
(150K sentences).2 The raters are not shown the
source language sentence; instead, they are
presented with a human translation, along with
two machine-generated translations. Their task
is to choose between the alternatives, using the
human translation as a reference.
Table 1 summarizes a comparison of the
output of our Spanish-English system with that
of Babelfish (http://world.altavista.com/).
Table 2 does the same for our English-Spanish
system and Lernout & Hauspie?s English-
Spanish system (http://officeupdate.lhsl.com/).
In these tables, a rating of 1 means that raters
uniformly preferred the translation produced by
our system; a rating of 0 means that they did not
uniformly prefer either translation; a rating of -1
means that they uniformly preferred the
translation produced by the alternative system.3
Beside each rating is a confidence measure for
the mean preference at the .99 level (Richardson,
S., et al(2001)).
Spanish-English
Systems
Mean preference
score (7 raters)
Sample
size
Our 4/01 (2001)
MT vs. Babelfish
0.32 ? 0.11
(at .99)
250
sentences
Table 1. Our Spanish-English MT vs. Babelfish
English-Spanish
Systems
Mean preference
score (5 raters)
Sample
size
Our 4/01 (2001)
MT vs. L&H
0.19 ? 0.14
(at 0.99)
250
sentences
Table 2. Our English-Spanish MT vs. Lernout &
Hauspie
2 The human raters used for these evaluations work for an
independent agency and played no development role
building the systems they test.
3 In interpreting our results, it is important to keep in mind
that our MT system has been customized to the test domain,
while the Babelfish and Lernout & Hauspie systems have
not.
5 Conclusion
In this paper we have presented an overview of
the natural language generation component
developed at Microsoft Research and have
demonstrated how this component functions
within a multilingual Machine Translation
system. We have provided motivation for the
generation architecture, which consists of a set
of core rules and a set of application-driven pre-
generation rules, within a wide-coverage, robust,
application-independent, multilingual natural
language processing system. In addition we
have presented evaluation figures for Spanish-
English and English-Spanish, two of the
language pairs of the MT system in which our
generation components are used.
6 References
Heidorn, G. E. (2000): Intelligence Writing
Assistance. In Dale R., Moisl H., and Somers
H. (eds.), A Handbook of Natural Language
Processing: Techniques and Applications for
the Processing of Language as Text. Marcel
Dekker, New York, 1998 (published in
August 2000), pages 181-207.
Jensen, K., Heidorn G., and Richardson S.
(eds.) (1993): Natural Language Processing:
The PLNLP Approach, Boston, Kluwer.
Lavoie, Benoit and Owen Rambow. (1997): A
fast and portable realizer for text generation.
In Proceedings of the Fifth Conference on
Applied Natural-Language Processing
(ANLP-1997), pages 265-268.
Melero, M. and Font-Llitjos, A. (2001):
Construction of a Spanish Generation module
in the framework of a General-Purpose,
Multilingual Natural Language Processing
System. In Proceedings of the VII
International Symposium on Social
Communication, Santiago de Cuba.
Reiter, E. and Dale, R. (2000): Building Natural
Language Generation Systems, Cambridge
University Press.
Richardson, S., et al(2001): Overcoming the
customization bottleneck using example-
based MT, Paper submitted for Data-driven
MT Workshop at ACL 2001, Toulouse,
France.
Richardson, S. (2000): The evolution of an NLP
System. NLP Group Microsoft Research,
Presentation at the LREC?2000 Athens,
Greece.
Tomita, M. and Nyberg E. (1988): The GenKit
and Transformation Kit User?s Guide.
Technical Report CMU-CMT-88-MEMO,
Centre for Machine Translation, Carnegie
Mellon University.
Proceedings of the 1st Workshop on South and Southeast Asian Natural Language Processing (WSSANLP), pages 8?16,
the 23rd International Conference on Computational Linguistics (COLING), Beijing, August 2010
Thai Sentence-Breaking for Large-Scale SMT 
 
 
Glenn Slayden 
thai-language.com  
glenn@thai-language.com 
Mei-Yuh Hwang 
Microsoft Research 
mehwang@microsoft.com 
Lee Schwartz 
Microsoft Research 
leesc@microsoft.com 
 
 
Abstract 
Thai language text presents challenges 
for integration into large-scale multi-
language statistical machine translation 
(SMT) systems, largely stemming from 
the nominal lack of punctuation and in-
ter-word space. For Thai sentence break-
ing, we describe a monolingual maxi-
mum entropy classifier with features that 
may be applicable to other languages 
such as Arabic, Khmer and Lao. We ap-
ply this sentence breaker to our large-
vocabulary, general-purpose, bidirec-
tional Thai-English SMT system, and 
achieve BLEU scores of around 0.20, 
reaching our threshold of releasing it as a 
free online service. 
1 Introduction 
NLP research has consolidated around the notion 
of the sentence as the fundamental unit of trans-
lation, a consensus which has fostered the devel-
opment powerful statistical and analytical ap-
proaches which incorporate an assumption of 
deterministic sentence delineation. As such sys-
tems become more sophisticated, languages for 
which this assumption is challenged receive in-
creased attention. Thai is one such language, 
since it uses space neither to distinguish syl-
lables from words or affixes, nor to unambi-
guously signal sentence boundaries. 
Written Thai has no sentence-end punctuation, 
but a space character is always present between 
sentences. There is generally no space between 
words, but a space character may appear within a 
sentence according to linguistic or prescriptive 
orthographic motivation (Wathabunditkul 2003), 
and these characteristics disqualify sentence-
breaking (SB) methods used for other languages, 
such as Palmer and Hearst (1997). Thai SB has 
therefore been regarded as the task of classifying 
each space that appears in a Thai source text as 
either sentence-breaking (sb) or non-sentence-
breaking (nsb). 
Several researchers have investigated Thai 
SB. Along with a discussion of Thai word break-
ing (WB), Aroonmanakun (2007) examines the 
issue. With a human study, he establishes that 
sentence breaks elicited from Thai informants 
exhibit varying degrees of consensus. Mittra-
piyanuruk and Sornlertlamvanich (2000) define 
part-of-speech (POS) tags for sb and nsb and 
train a trigram model over a POS-annotated cor-
pus. At runtime, they use the Viterbi algorithm 
to select the POS sequence with the highest 
probability, from which the corresponding space 
type is read back. Charoenpornsawat and Sornler-
tlamvanich (2001) apply Winnow, a multiplica-
tive trigger threshold classifier, to the problem. 
Their model has ten features: the number of 
words to the left and right, and the left-two and 
right-two POS tags and words. 
We present a monolingual Thai SB based on a 
maximum entropy (ME) classifier (Ratnaparkhi 
1996; Reynar and Ratnaparkhi, 1997) which is 
suitable for sentence-breaking SMT training data 
and runtime inputs. Our model uses a four token 
window of Thai lemmas, plus categorical fea-
tures, to describe the proximal environment of 
the space token under consideration, allowing 
runtime classification of space tokens with pos-
sibly unseen contexts. 
As our SB model relies on Thai WB, we re-
view our approach to this problem, plus related 
preprocessing, in the next section. Section 2 also 
discusses the complementary operation to WB, 
namely, the re-spacing of Thai text generated by 
SMT output. Section 3 details our SB model and 
evaluates its performance. We describe the inte-
gration of this work with our large-scale SMT 
system in Section 4. We draw conclusions in 
Section 5. 
8
2 Pre- and Post-processing 
As will be shown in Section 3, our sentence 
breaker relies on Thai WB. In turn, with the aim 
of minimizing WB errors, we perform Unicode 
character sequence normalization prior to WB. 
As output byproducts, our WB analysis readily 
identifies certain types of named entities which 
we propagate into our THA-ENG SMT; in this 
section, we briefly summarize these preliminary 
processing steps, and we conclude the section 
with a discussion of Thai text re-spacing.  
2.1 Character Sequence Normalization 
Thai orthography uses an alphabet of 44 conso-
nants and a number of vowel glyphs and tone 
marks. The four Thai tone marks and some Thai 
vowel characters are super- and/or sub-scripted 
with respect to a base character. For example, 
the ?? ? sequence consists of three code points: 
?  ? ? ? ?. When two or more of these combining 
marks are present on the same base character, the 
ordering of these code points in memory should 
be consistent so that orthographically identical 
entities are recognized as equivalent by comput-
er systems. However, some computer word pro-
cessors do not enforce the correct sequence or do 
not properly indicate incorrect sequences to the 
user visually. This often results in documents 
with invalid byte sequences. 
Correcting these errors is desirable for SMT 
inputs. In order to normalize Thai input character 
sequences to a canonical Unicode form, we de-
veloped a finite state transducer (FST) which 
detects and repairs a number of sequencing er-
rors which render Thai text either orthographi-
cally invalid, or not in a correct Unicode se-
quence. 
For example, a superscripted Thai tone mark 
should follow a super- or sub-scripted Thai vo-
wel when they both apply to the same consonant. 
When the input has the tone mark and the vowel 
glyph swapped, the input can be fully repaired: 
?  ?  ? ? ? ?  ?  ? ? ?  ?  ?  ???? 
?  ? ? ? ? ?  ?  ?  ? ? ? ? ?  ?  ???? 
Figure 1. Two unambiguous repairs 
Other cases are ambiguous. The occurrence of 
multiple adjacent vowel glyphs is an error where 
the intention may not be clear. We retain the 
first-appearing glyph, unless it is a pre-posed 
vowel, in which case we retain the last-appearing 
instance. These two treatments are contrasted in 
Figure 2. Miscoding (Figure 3) is another variety 
of input error that is readily repaired. 
????  ?  ?? 
???? ?  ?? 
Figure 2. Two ambiguous repairs 
Within the Infoquest Thai newswire corpus, a 
low-noise corpus, about 0.05% of the lines exhi-
bit at least one of the problems mentioned here. 
For some chunks of broad-range web scraped 
data, we observe rates as high as 4.1%. This 
measure is expected to under-represent the utility 
of the filter to WB, since Thai text streams, lack-
ing intra-word spacing and permitting two un-
written vowels, have few re-alignment check-
points, allowing tokenization state machines to 
linger in misaligned states. 
?   ? ? ?  ?  ?   ???   ?  ??? 
?   ?   ?  ?  ?  ?  ?  ?? 
Figure 3. Two common mis-codings 
2.2 Uniscribe Thai Tokenization 
Thai text does not normally use the space cha-
racter to separate words, except in certain specif-
ic contexts. Although Unicode offers the Zero-
Width Space (ZWSP) as one solution for indicat-
ing word breaks in Thai, it is infrequently used. 
Programmatic tokenization has become a staple 
of Thai computational linguistics. The problem 
has been well studied, with precision and recall 
near 95% (Haruechaiyasak et al 2008).  
In our SMT application, both the sentence 
breaker and the SMT system itself require Thai 
WB, and we use the same word breaker for these 
tasks (although the system design currently pro-
hibits directly passing tokens between these two 
components). Our method is to apply post-
processing heuristics to the output of Uniscribe 
(Bishop et al 2003), which is provided as part of 
the Microsoft? WindowsTM operating system 
interface. Our heuristics fall into two categories: 
?re-gluing? words that Uniscribe broke too ag-
gressively, and a smaller class of cases of further 
breaking of words that Uniscribe did not break. 
Re-gluing is achieved by comparing Uniscribe 
output against a Thai lexicon in which desired 
breaks within a word are tagged. Underbreaking 
by Uniscribe is less common and is restricted to 
a number of common patterns which are repaired 
explicitly. 
9
2.3 Person Name Entities 
In written Thai, certain types of entities employ 
prescriptive whitespace patterns. By removing 
these recognized patterns from consideration, SB 
precision can be improved. Furthermore, be-
cause our re-gluing procedure requires a lookup 
of every syllable proposed by Uniscribe, it is 
efficient to consider, during WB, additional 
processing that can be informed by the same 
lookup. Accordingly, we briefly mention some 
of the entity types that our WB identifies, focus-
ing on those that incorporate distinctive spacing 
patterns. 
Person names in Thai adhere to a convention 
for the use of space characters. This helps Thai 
readers to identify the boundaries of multi-
syllable surnames that they may not have seen 
before. The following grammar summarizes the 
prescriptive conventions for names appearing in 
Thai text:  
<name-entity> ::= <honorific>  <full-name> 
<full-name> ::= <first-name> [<last-name>] 
<first-name> ::= <name-text> space 
<last-name> ::= <name-text> space 
<name-text> ::= <thai-alphabetic-char>+ 
<thai-alphabetic-char> ::= ? | ? | ? | ? | ... 
Figure 4. Name entity recognition grammar 
The re-glue lookup also determines if a sylla-
ble matches one of the following predefined spe-
cial categories: name-introducing honorific (h), 
Thai or foreign given name (g), token which is 
likely to form part of a surname (s), or token 
which aborts the gathering of a name (i.e. is un-
likely to form part of a name).  
.../???/???/?/???/???/ /?/????/??/??/ /???/... 
??? ??? ? ? ?? ???  ? ? ??? ?? ? ?  ??? 
 h g0 g1 g2 sp0 s0 s1 s2 s3 sp1  
th
at
 
M
r. 
<o
ov
> 
hi
t 
be
lo
ve
d 
 <o
ov
> 
st
ab
le
 
<o
ov
> 
<o
ov
> 
 sa
i d
 
...that Mr. Chiranut Winichotkun said...
Figure 5. Thai person-name entity recognition 
Figure 5 shows a Thai name appearing within 
a text fragment, with Uniscribe detected token 
boundaries indicated by slashes. In the third row 
we have identified the special category, if any, 
for each token. The fourth line shows the Eng-
lish translation gloss, or <oov> if none. The bot-
tom row is the desired translation output. 
Our name identifier first notes the presence of 
an honorific {h} ??? followed by a pattern of 
tokens {g0-gn}, {s0-sn} and spaces {sp0, sp1} 
that is compatible with a person name and sur-
name of sensible length. 
Next, we determine which of those tokens in 
the ranges {g} and {s} following the honorific 
do not have a gloss translation (i.e., are not 
found in the lexicon). These tokens are indicated 
by <oov> in the gloss above. When the number 
of unknown tokens exceeds a threshold, we hy-
pothesize that these tokens form a name. The 
lack of lexical morphology in Thai facilitates 
this method because token (or syllable) lookup 
generally equates with the lookup of a stemmed 
lemma. 
2.4 Calendar Date Entities 
Our WB also identifies Thai calendar dates, as 
these also exhibit a pattern which incorporates 
spaces. As a prerequisite to identifying dates, we 
map Thai orthographic digits {? ? ? ? ? ? ? 
? ? ?} to Arabic digits 0 through 9, respec-
tively. For example, our system would interpret 
the input text ???? as equivalent to ?2540.? 
.../??/???/??/? /14/ ??????/ /????/ /???/...
?? ??? ??? sp 14 ?????? sp ???? sp ??? 
on day which  14 March  2540  and 
...on March 14th, 1997 and... 
Figure 6. Date entity recognition 
Figure 6 shows a fragment of Thai text which 
contains a calendar date for which our system 
will emit a single token. As shown in the exam-
ple, our system detects and adjusts for the use of 
Thai Buddhist year dates when necessary. Ga-
thering of disparate and optional parts of the 
Thai date is summarized by the grammar in Fig-
ure 7. 
<date-entity> ::= [<cardinal-words>] [space] <date> 
<cardinal-words> ::= ????? ?| ?? ?
<date> ::= month-date [space] year 
<year> ::= <tha-digit> <tha-digit> <tha-digit> <tha-digit> 
<year> ::= <ara-digit> <ara-digit> <ara-digit> <ara-digit> 
<month-date> ::= <day> [space] <month> 
<day> ::= <thai-digit>+ 
<day> ::= <ara-digit>+ 
<month> ::= <month-full> | <month-abbr> 
<month-full> ::= ?????? | ????????? ?| ?????? | ... 
<month-abbr> ::= ?.?. | ?.?. | ?.??. | ... 
<tha-digit> ::= ? | ? | ? | ? | ? | ? | ? | ? | ? | ? 
<ara-digit> ::= 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 
Figure 7. Date recognition grammar 
10
2.5 Thai Text Re-spacing 
To conclude this section, we mention an opera-
tion complementary to Thai WB, whereby Thai 
words output by an SMT system must be re-
spaced in accordance with Thai prescriptive 
convention. As will be mentioned in Section 4.2, 
for each input sentence, our English-Thai system 
has access to an English dependency parse tree, 
as well as links between this tree and a Thai 
transfer dependency tree. After using these links 
to transfer syntactic information to the Thai tree, 
we are able to apply prescriptive spacing rules 
(Wathabunditkul 2003) as closely as possible. 
Human evaluation showed satisfactory results 
for this process. 
3 Maximum Entropy Sentence-Breaking 
We now turn to a description of our statistical 
sentence-breaking model. We train an ME clas-
sifier on features which describe the proximal 
environment of the space token under considera-
tion and use this model at runtime to classify 
space tokens with possibly unseen contexts. 
3.1 Modeling 
Under the ME framework, let B={sb, nsb} 
represent the set of possible classes we are inter-
ested in predicting for each space token in the 
input stream. Let C={linguistic contexts} 
represent the set of possible contexts that we can 
observe, which must be encoded by binary fea-
tures, ??(?, ?), 1 ? ? ? ?, such as: 
??(?, ?) = ? 1 if the previous word is English ???  ? = ???.0 otherwise.  
This feature helps us learn that the space after an 
English word is usually not a sentence boundary. 
??(?, ?) = ?
 1 if the distance to the previous honorific 
is less than 15 tokens ??? ? = ???
0 otherwise.
 
This feature enables us to learn that spaces 
which follow an honorific are less likely to mark 
sentence boundaries. Assume the joint probabili-
ty p(b,c) is modeled by 
?(?, ?) = ?? ??
??(?,?)?
???
 
where we have k free parameters {??}  to esti-
mate and Z is a normalization factor to make 
? ?(?, ?) = 1.?,?  The ME learning algorithm 
finds a solution {??} representing the most un-
certain commitment 
max  ?(?) = ???(?, ?) log ?(?, ?)  
that satisfies the observed distribution ???(?, ?) of 
the training data 
   ??(?, ?)??(?, ?) = ? ???(?, ?)??(?, ?), 1 ? ? ? ? . 
This is solved via the Generalized Iterative Scal-
ing algorithm (Darroch and Ratcliff 1972). At 
run-time, a space token is considered an sb, if 
and only if p(sb|c) > 0.5, where 
?(??|?) = ?(??, ?)?(??, ?) + ?(???, ?) . 
3.2 Feature Selection 
The core context of our model, {w, x, y, z}, is a 
window spanning two tokens to the left (posi-
tions w and x) and two tokens to the right (posi-
tions y and z) of a classification candidate space 
token. 
c token characteristic 
yk Yamok (syllable reduplication) symbol ? 
sp space 
?? Thai numeric digits 
num Arabic numeric digits 
ABC Sequence of all capital ASCII characters 
cnn single character (derived from hex) 
ckkmmnn single character (derived from UTF8 hex) 
ascii any amount of non-Thai text 
(Thai text) Thai word (derived from lemma) 
Table 1. Categorical and derived feature names 
The possible values of each of the window 
positions {w, x, y, z} are shown in Table 1, 
where the first match to the token at the desig-
nated position is assigned as the feature value for 
that position. Foreign-text tokens plus any inter-
vening space are merged, so a single ?ascii? fea-
ture may represent an arbitrary amount of non-
Thai script with interior space. 
Figure 8 shows an example sentence that has 
been tokenized. Token boundaries are indicated 
by slashes. Although there are three space tokens 
in the original input, we extract four contexts. 
The shaded boxes in the source text?and the 
shaded line in the figure?indicate the single sb 
context that is synthesized by wrapping, to be 
described in Section 3.4. 
For each context, in addition to the {w, x, y, z} 
features, we extract two more features indicated 
by {l ,r} in Figure 8. They are the number of 
11
tokens between the previous space token (wrap-
ping as necessary) and the current one, and the 
number of tokens between the current space to-
ken and the next space token (wrapping as ne-
cessary). These features do not distinguish 
whether the bounding space token is sb or nsb. 
This is because, processing left-to-right, it is 
permissible to use a feature such as ?number of 
tokens since last sb,? but not ?number of tokens 
until next sb,? which would be available during 
training but not at runtime. 
??????????????????? R1C1  ??????????????????????
??????????  A1 
?R1C1 reference style was converted to A1 reference style.? 
__/??????/???/????/???/???/  /R1C1/   /???/????/??/
????/??????/???/????/???/???/  /A1/__ 
 b c=w c=x c=y c=z c=l c=r 
nsb ??? ??? ABC sp 5 1 
nsb sp ABC ??? ???? 1 9 
nsb ??? ??? ABC sp 9 1 
sb sp ABC ?????? ??? 1 5 
Figure 8. A Thai sentence and the training contexts extracted. Hig-
hlighting shows the context for sb.  
In addition to the above core features, our 
model emits certain extra features only if they 
appear: 
? An individual feature for each English punc-
tuation mark, since these are sometimes used 
in Thai. For example, there is one feature for 
the sentence end period (i.e. full-stop); 
? The current nest depth for paired glyphs with 
directional variation, such as brackets, braces, 
and parentheses; 
? The current parity value for paired glyphs 
without directional distinction such as 
?straight? quotation marks. 
The following example illustrates paired direc-
tional glyphs (in this case, parentheses): 
.../??????????/?  /(/??????/__/???/)/  /??????/  /???????/???/... 
...Unilever (Thailand) Ltd. disclosed that... 
 b c=w c=x c=y c=z c=pn 
nsb ( ?????? ??? ) 1 
Figure 9. Text fragment illustrating paired directional glyphs and 
the context for the highlighted space 
     In Figure 9, the space between ?????? 
?country? and ??? ?Thai,? generates an nsb 
context which includes the features shown, 
where ?pn? is an extra feature which indicates 
the parenthesis nesting level. This feature helps 
the model learn that spaces which occur within 
parentheses are likely to be nsb. 
Parity features for the non-directional paired 
glyphs, which do nest, are true binary features. 
Since these features have only two possible val-
ues (inside or outside), they are only emitted 
when their value is ?inside,? that is, when the 
space under consideration occurs between such a 
pair. 
3.3 Sentence Breaker Training Corpus 
Thai corpora which are marked with sentence 
breaks are required for training. We assembled a 
corpus of 361,802 probable sentences. This cor-
pus includes purchased, publicly available, and 
web-crawled content. In total it contains 911,075 
spaces, a figure which includes one inter-
sentence space per sentence, generated as de-
scribed below. 
3.4 Out-of-context Sentences 
For SB training, paragraphs are first tokenized 
into words as described in Section 2.2. This 
process does not introduce new spaces between 
tokens; only original spaces in the text are classi-
fied as sb/nsb and used for the context features 
described below. To keep this distinction clear, 
token boundaries are indicated by a slash rather 
than space in the examples shown in this paper. 
For 91% of our training sentences, the para-
graphs from which they originate are inaccessi-
ble. In feature extraction for each of these sen-
tences, we wrap the sentence?s head around to its 
tail to obtain its sb context. In other words, for a 
sentence of tokens t0-tn-1, the context of sb (the 
last space) is given by 
{ w=tn-2, x=tn-1, y=t0, z=t1 }. 
     This process was illustrated in Figure 8. Al-
though not an ideal substitute for sentences in 
context, this ensures that we extract at least one 
sb context per sentence. The number of nsb con-
texts extracted per sentence is equal to the num-
ber of interior space tokens in the original sen-
tence. Sentence wrapping is not needed when 
training with sentence-delimited paragraph 
sources. Contexts sb and nsb are extracted from 
the token stream of the entire paragraph and 
wrapping is used only to generate one additional 
sb for the entire paragraph. 
12
3.5 Sentence Breaker Evaluation 
Although evaluation against a single-domain 
corpus does not measure important design re-
quirements of our system, namely resilience to 
broad-domain input texts, we evaluated against 
the ORCHID corpus (Charoenporn et al 1997) 
for the purpose of comparison with the existing 
literature. Following the methodology of the stu-
dies cited below, we use 10-fold ?10% averaged 
testing against the ORCHID corpus. 
Our results are consistent with recent work us-
ing the Winnow algorithm, which itself com-
pares favorably with the probabilistic POS tri-
gram approach. Both of these studies use evalua-
tion metrics, attributed to Black and Taylor 
(1997), which aim to more usefully measure sen-
tence-breaker utility. Accordingly, the following 
definitions are used in Table 2: 
space-correct =  (#correct sb+#correct nsb)total # of space tokens  
false break= #sb false positivestotal # of space tokens 
     It was generally possible to reconstruct preci-
sion and recall figures from these published re-
sults1 and we present a comprehensive table of 
results. Reconstructed values are marked with a 
dagger and the optimal result in each category is 
marked in boldface. 
 Mittrapiyanuruk
et al 
Charoenpornsawat 
et al 
Our result
method POS Trigram Winnow MaxEnt 
#sb in reference 10528 1086? 2133 
#space tokens 33141 3801 7227 
nsb-precision 90.27? 91.48? 93.18 
nsb-recall 87.18? 97.56? 94.41 
sb-precision 74.35? 92.69? 86.21 
sb-recall 79.82 77.27 83.50 
?space-correct? 85.26 89.13 91.19 
?false-break? 8.75 1.74 3.94 
Table 2. Evaluation of Thai Sentence Breakers against 
ORCHID 
Finally, we would be remiss in not acknowl-
edging the general hazard of assigning sentence 
breaks in a language such as Thai, where source 
                                                 
1 Full results for Charoenpornsawat et al are reconstructed based 
on remarks in their text, including that ?the ratio of the number of 
[nsb to sb] is about 5:2.? 
text authors may intentionally include or omit 
spaces in order to create syntactic or semantic 
ambiguity. We defer to Mittrapiyanuruk and 
Sornlertlamvanich (2000) and Aroonmanakun 
(2007) for informed commentary on this topic. 
4 SMT System and Integration 
The primary application for which we developed 
the Thai sentence breaker described in this work 
is the Microsoft? BING? general-domain ma-
chine translation service. In this section, we pro-
vide a brief overview of this large-scale SMT 
system, focusing on Thai-specific integration 
issues. 
4.1 Overview 
Like many multilingual SMT systems, our sys-
tem is based on hybrid generative/discriminative 
models. Given a sequence of foreign words, f, its 
best translation is the sequence of target words, 
e, that maximizes  
?? = argmax? ?(?|?) =  argmax? ?(?|?)?(?) 
= argmaxe  { log ?(?|?) + log ?(?)} 
where the translation model ?(?|?) is computed 
on dozens to hundreds of features. The target 
language model (LM), ?(?), is represented by a 
smoothed n-grams (Chen 1996) and sometimes 
more than one LM is adopted in practice. To 
achieve the best performance, the log likelihoods 
evaluated by these features/models are linearly 
combined. After ?(?|?) and ?(?) are trained, the 
combination weights ??  are tuned on a held-out 
dataset to optimize an objective function, which 
we set to be the BLEU score (Papineni et al 
2002): 
{???} = max{??}  BLEU({??}, {?}) 
?? =  argmaxe  {???log
?
 ??(?|?) +???log
?
??(?)} 
where {r} is the set of gold translations for the 
given input source sentences. To learn ?? we use 
the algorithm described by Och (2003), where 
the decoder output at any point is approximated 
using n-best lists, allowing an optimal line 
search to be employed. 
4.2 Phrasal and Treelet Translation 
Since we have a high-quality real-time rule-
based English parser available, we base our Eng-
13
lish-to-Thai translation (ENG-THA) on the 
?treelet? concept suggested in Menezes and 
Quirk (2008). This approach parses the source 
language into a dependency tree which includes 
part-of-speech labels.  
   Lacking a Thai parser, we use a purely statis-
tical phrasal translator after Pharaoh (Koehn 
2004) for THA-ENG translation, where we 
adopt the name and date translation described in 
Sections 2.3 and 2.4.  
     We also experimented with phrasal ENG-
THA translation. Though we actually achieved a 
slightly better BLEU score than treelet for this 
translation direction, qualitative human evalua-
tion by native speaker informants was mixed. 
We adopted the treelet ENG-THA in the final 
system, for its better re-spacing (Section 2.5). 
4.3 Training, Development and Test Data 
Naturally, our system relies on parallel text cor-
pora to learn the mapping between two languag-
es. The parallel corpus contains sentence pairs, 
corresponding to translations of each other. For 
Thai, quality corpora are generally not available 
in sufficient quality for training a general-
domain SMT system. For the ENG-THA pair, 
we resort to Internet crawls as a source of text. 
We first identify paired documents, break each 
document into sentences, and align sentences in 
one document against those in its parallel docu-
ment. Bad alignments are discarded. Only sen-
tence pairs with high alignment confidence are 
kept in our parallel corpus. Our sentence align-
ment algorithm is based on Moore (2002). 
For our ENG-THA translation system, we as-
sembled three resources: a parallel training cor-
pus, a development bitext (also called the lamb-
da set) for training the feature combination 
weights {??}, and a test corpus for BLEU and 
human evaluation. Both the lambda and the test 
sets have single reference translations per sen-
tence. 
Data Set #Sentences 
(ENG||THA) training 725K 
(ENG,THA) lambda 2K 
(ENG,THA) test 5K 
THA LM text 10.3M 
ENG LM text 45.6M 
Table 3. Corpus size of parallel and monolingual data 
 
Although it is well known that language trans-
lation pairs are not symmetric, we use these 
same resources to build our THA-ENG transla-
tion system due to the lack of additional corpora.  
Our parallel MT corpus consists of approx-
imately 725,000 English-Thai sentence pairs 
from various sources. Additionally we have 9.6 
million Thai sentences, which are used to train a 
Thai 4-gram LM for ENG-THA translation, to-
gether with the Thai sentences in the parallel 
corpus. Trigrams and 4-grams that occur only 
once are pruned, and n-gram backoff weights are 
re-normalized after pruning, with the surviving 
KN smoothed probabilities intact (Kneser and 
Ney 1995). Similarly, a 4-gram ENG LM is 
trained for THA-ENG translation, on a total of 
45.6M English sentences. 
For both the lambda and test sets, THA LM 
incurs higher out-of-vocabulary (OOV) rates 
(1.6%) than ENG LM (0.7%), due to its smaller 
training set and thus smaller lexicon. Both trans-
lation directions define the maximum 
phrase/treelet length to be 4 and the maximum 
re-ordering jump to be 4 as well. 
4.4 BLEU Scores 
To evaluate our end-to-end performance, we 
compute case insensitive 4-gram BLEU scores. 
Translation outputs are WB first according to the 
Thai/English tokenizer, before BLEU scores are 
computed. The BLEU scores on the test sets are 
shown in Table 4. We are not aware of any pre-
viously published BLEU results for either direc-
tion of this language pair. 
  BLEU 
THA-ENG 0.233 
ENG-THA 0.194 
Table 4. Four-gram case-insensitive BLEU scores. 
Figures 10 and 11 illustrate sample outputs for 
the each translation direction, with reference 
translations. 
INPUT: ??????????????????????????? ??? ???? ???
??????????????????????? ??????????????????????????
OUTPUT: In Thailand a Orchid approximately 175 type if 
extinct from Thailand. It means extinct from the world. 
REF: In Thailand, there are about 175 species of Orchid. If 
they disappear from Thailand, they will be gone from the 
world. 
Figure 10.  THA-ENG Sample Translation Output 
14
INPUT: In our nation the problems and barriers we face are 
just problems and barriers of law not selection or develop-
ment. 
OUTPUT: ?????????????????? ?????????????????????
??????????????????????????????????????????????????
????? 
REF: ????????????????????????????? ???????????
???????????????????? ???????????????????????????
????????????????????? ?
Figure 11. ENG-THA Sample Translation Output 
Although the translation quality is far from being 
perfect, SMT is making good process on build-
ing useful applications. 
5 Conclusion and Future Work 
Our maximum entropy model for Thai sentence-
breaking achieves results which are consistent 
with contemporary work in this task, allowing us 
to overcome this obstacle to Thai SMT integra-
tion. This general approach can be applied to 
other South-East Asian languages in which space 
does not deterministically delimit sentence 
boundaries. 
In Arabic writing, commas are often used to 
separate sentences until the end of a paragraph 
when a period is finally used. In this case, the 
comma character is similar to the space token in 
Thai where its usage is ambiguous. We can use 
the same approach (perhaps with different lin-
guistic features) to identify which commas are 
sentence-breaking and which are not. 
Our overall system incorporates a range of in-
dependent solutions to problems in Thai text 
processing, including character sequence norma-
lization, tokenization, name and date identifica-
tion, sentence-breaking, and Thai text re-
spacing. We successfully integrated each solu-
tion into an existing large-scale SMT frame-
work, obtaining sufficient quality to release the 
Thai-English language pair in a high-volume, 
general-domain, free public online service. 
There remains much room for improvement. 
We need to find or create true Thai-English di-
rectional corpora to train the lambdas and to test 
our models. The size of our parallel corpus for 
Thai should increase by at least an order of mag-
nitude, without loss of bitext quality. With a 
larger corpus, we can consider longer phrase 
length, higher-order n-grams, and longer re-
ordering distance. 
References 
W. Aroonmanakun. 2007. Thoughts on Word 
and Sentence Segmentation in Thai. In Pro-
ceedings of the Seventh International Sympo-
sium on Natural Language Processing, Pat-
taya, Thailand, 85-90. 
F. Avery Bishop, David C. Brown and David M. 
Meltzer. 2003. Supporting Multilanguage 
Text Layout and Complex Scripts with Win-
dows 2000. http://www.microsoft.com/typo-
graphy/developers/uniscribe/intro.htm 
A. W. Black and P. Taylor. 1997. Assigning 
Phrase Breaks from Part-of-Speech Se-
quences. Computer Speech and Language, 
12:99-117. 
Thatsanee Charoenporn, Virach Sornlertlamva-
nich, and Hitoshi Isahara. 1997. Building A 
Thai Part-Of-Speech Tagged Corpus (ORC-
HID). 
Paisarn Charoenpornsawat and Virach Sornler-
tlamvanich. 2001. Automatic sentence break 
disambiguation for Thai. In International 
Conference on Computer Processing of 
Oriental Languages (ICCPOL), 231-235. 
S. F. Chen and J. Goodman. 1996. An empirical 
study of smoothing techniques for language 
modeling. In Proceedings of the 34th Annual 
Meeting on Association for Computational 
Linguistics, 310-318. Morristown, NJ: ACL. 
J. N. Darroch and D. Ratcliff. 1972. Generalized 
Iterative Scaling for Log-Linear Models. The 
Annals of Mathematical Statistics, 43(5): 
1470-1480. 
Choochart Haruechaiyasak, Sarawoot Kon-
gyoung, and Matthew N. Dailey. 2008. A 
Comparative Study on Thai Word Segmenta-
tion Approaches. In Proceedings of ECTI-
CON 2008. Pathumthani, Thailand: ECTI. 
Reinhard Kneser and Hermann Ney. 1995. Im-
proved Backing-Off for M-Gram Language 
Modeling. In Proceedings of International 
Conference on Acoustics, Speech and Signal 
Procesing (ICASSP), 1:181-184. 
Philipp Koehn. 2004. Pharaoh: a Beam Search 
Decoder for Phrase-Based Statistical Machine 
Translation Models. In Proceedings of the As-
15
sociation of Machine Translation in the Amer-
icas (AMTA-2004). 
Arul Menezes, and Chris Quirk. 2008. Syntactic 
Models for Structural Word Insertion and De-
letion during Translation. In Proceedings of 
the 2008 Conference on Empirical Methods in 
Natural Language Processing. 
P. Mittrapiyanuruk and V. Sornlertlamvanich. 
2000. The Automatic Thai Sentence Extrac-
tion. In Proceedings of the Fourth Symposium 
on Natural Language Processing, 23-28. 
Robert C. Moore. 2002. Fast and Accurate Sen-
tence Alignment of Bilingual Corpora. In Ma-
chine Translation: From Research to Real 
Users (Proceedings, 5th Conference of the As-
sociation for Machine Translation in the 
Americas, Tiburon, California), Springer-
Verlag, Heidelberg, Germany, 135-244 
Franz Josef Och. 2003. Minimum error rate 
training in statistical machine translation. In 
Proceedings of the 41th Annual Meeting of the 
Association for Computational Linguistics. 
Stroudsburg, PA: ACL. 
David D. Palmer and Marti A. Hearst. 1997. 
Adaptive Multilingual Sentence Boundary 
Disambiguation. Computational Linguistics, 
23:241-267. 
Kishore Papineni, Salim Roukos, Todd Ward, 
and Wei-jing Zhu. 2002. BLEU: a method for 
automatic evaluation of machine translation. 
In Proceedings of the 40th Annual meeting of 
the Association for Computational Linguistics, 
311?318. Stroudsburg, PA: ACL. 
Adwait Ratnaparkhi, 1996. A Maximum Entropy 
Model for Part-of-Speech Tagging. In Pro-
ceedings of the Conference on Empirical Me-
thods in Natural Language Processing, 133-
142. 
Jeffrey C. Reynar and Adwait Ratnaparkhi. 
1997. A Maximum Entropy Approach to Iden-
tifying Sentence Boundaries, In Proceedings 
of the Fifth Conference on Applied Natural 
Language Processing, 16-19. 
Suphawut Wathabunditkul. 2003. Spacing in the 
Thai Language. http://www.thailanguage.com/ 
ref/spacing 
16
