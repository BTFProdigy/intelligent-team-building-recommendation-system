Proceedings of the 3rd Workshop on Constraints and Language Processing (CSLP-06), pages 17?24,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Numbat: Abolishing Privileges when Licensing New Constituents in
Constraint-oriented Parsing
Jean-Philippe Prost
Centre for Language Technology
Macquarie University, Sydney, Australia
and Laboratoire Parole et Langage
Universite? de Provence, Aix-en-Provence, France
jpprost@ics.mq.edu.au
Abstract
The constraint-oriented approaches to lan-
guage processing step back from the gen-
erative theory and make it possible, in the-
ory, to deal with all types of linguistic re-
lationships (e.g. dependency, linear prece-
dence or immediate dominance) with the
same importance when parsing an input
utterance. Yet in practice, all implemented
constraint-oriented parsing strategies still
need to discriminate between ?important?
and ?not-so-important? types of relations
during the parsing process.
In this paper we introduce a new
constraint-oriented parsing strategy based
on Property Grammars, which overcomes
this drawback and grants the same impor-
tance to all types of relations.
1 Introduction
In linguistics, the term gradience is often used to
refer to the notion of acceptability as a gradient,
as opposed to a more classical all-or-none notion.
The research goal of this project is to build an ex-
perimental platform for computing gradience, i.e.
for quantifying the degree of acceptability of an
input utterance. We called this platform Numbat.
In order to be able to quantify such a gradi-
ent of acceptability with no a priori opinion on
the influence played by different types of linguis-
tic relationships, we want to adopt a framework
where no one type of (syntactic) relation (e.g. de-
pendency, immediate dominance, or linear prece-
dence) is preferred over the other ones. Although
a constraint-oriented (CO) paradigm such as Prop-
erty Grammars (Blache, 2001) theoretically does
not rely on any preferred relations, we observe that
the parsing strategies implemented so far (Moraw-
ietz and Blache, 2002; Balfourier et al, 2002;
Dahl and Blache, 2004; VanRullen, 2005) do not
account for such a feature of the formalism. The
strategy we have designed overcomes that prob-
lem and allows for constituents to be licensed by
any type of relation. Not only does our approach
maintain a close connection between implementa-
tion and underpinning theory, but it also allows for
the decisions made with respect to gradience to be
better informed. The purpose of the present pa-
per is to present this new parsing strategy, and to
emphasise how it ?abolishes the privilege? usually
only granted to a subset of syntactic relationships.
Section 2 presents some background informa-
tion about the CO approaches and briefly intro-
duces the Property Grammars formalism. Section
3 exposes and discusses the parsing strategy im-
plemented in Numbat. Section 4 then draws the
conclusion.
2 Constraint-oriented Approaches
The main feature common to all Constraint-
oriented approaches is that parsing is mod-
elled as a Constraint Satisfaction Problem (CSP).
Maruyama?s Constraint Dependency Grammar
(CDG) (Maruyama, 1990) is the first formalism
to introduce the parsing process as a CSP solver.
Several extensions of CDG have then been pro-
posed (Heinecke et al, 1998; Duchier, 1999; Foth
et al, 2004).
Menzel and colleagues (Heinecke et al, 1998;
Foth et al, 2004) developed a weighted (or
?graded?) version of CDG. Their parsing strate-
gies are explored in the context of robust parsing.
These strategies are based on an over-generation
of candidate solutions. In this approach the CSP is
turned into an optimisation problem, where sub-
optimal solutions are filtered out according to a
function of the weights associated to the violated
constraints, and the notion of well-formedness is
replaced by one of optimality. Indeed, the over-
generation introduces inconsistencies in the con-
straint system, which prevents the use of the con-
17
straint system as a set of well-formedness condi-
tions, since even a well-formed utterance violates
a subset of constraints. Consequently it is not pos-
sible to distinguish an optimal structure of an ill-
formed utterance from an optimal structure of a
well-formed utterance.
Duchier (1999) relies on set constraints and se-
lection constraints1 to axiomatise syntactic well-
formedness and provides a concurrent constraint
programming account of the parsing process. With
the eXtended Dependency Grammar (XDG) (De-
busmann et al, 2004) the notion of dependency
tree is further extended to ?multi-dimensional? de-
pendency graph, where each dimension (e.g. Im-
mediate Dominance and Linear Precedence) is as-
sociated with its own set of well-formedness con-
ditions (called principles). Duchier (2000) sees
dependency parsing as a configuration problem,
where given a finite set of components (nodes in
a graph) and a set of constraints specifying how
these components may be connected, the task con-
sists of finding a solution tree.
It seems, to the best of our knowledge, that nei-
ther of these works around XDG attempts to ac-
count for ill-formedness.
The Property Grammars (PG), introduced by
Blache (Blache, 2001; Blache, 2005)2, step back
from Dependency Grammar. Solving the con-
straint system no longer results in a dependency
structure but in a phrase structure, whose granular-
ity may be tailored from a shallow one (i.e. a col-
lection of disconnected components) to a deep one
(i.e. a single hierarchical structure of constituents)
according to application requirements3. This fea-
ture makes the formalism well suited for account-
ing for both ill-formedness and well-formedness,
which is a key requirement for our experimental
platform.
Introducing degrees of acceptability for an ut-
terance does not mean indeed that it should be
done at the expense of well-formedness: we want
our model to account for ill-formedness and yet
to also be able to recognise and acknowledge
when an utterance is well-formed. This require-
1Although they are referred to with the same name by
their respective authors, Duchier?s notion of selection con-
straint is not to be confused with Dahl?s selection constraints
(Dahl and Blache, 2004). The two notions are significantly
different.
2The Property Grammars were defined on the basis of the
5P formalism (Be`s and Blache, 1999).
3For a discussion regarding PG and parsing with variable
granularity see (VanRullen, 2005).
ment rules out Optimality-theoretic frameworks
as well as the ones based on Maruyama?s CDG.
Note that this is not to say that the task could
not be achieved in a CDG-based framework; sim-
ply at this stage there is no work based on CDG,
which would combine both an account of well-
formedness and of optimality. A CO framework
based on PG seems therefore best-suited for our
purpose. Meanwhile, though different parsing
strategies have been proposed for PG (Moraw-
ietz and Blache, 2002; Balfourier et al, 2002;
Dahl and Blache, 2004; VanRullen, 2005), none
of these strategies implements the possibility af-
forded by the theory to rely on any type of con-
straint in order to license a (possibly ill-formed)
constituent.
We will see in this paper how the parsing strat-
egy implemented in Numbat overcomes this prob-
lem.
2.1 The Property Grammars Formalism
2.1.1 Terminology
Construction. In PG a construction can be a
lexical item?s Part-of-Speech, a phrase, or top-
level constructions such as, for example, the
Caused-motion or the Subject-auxiliary Inversion
constructions. The notion of construction is sim-
ilar to the one in Construction Grammar (CxG)4,
as in (Goldberg, 1995), where:
Cx is a construction iff Cx is a form-
meaning pair ?Fi, Si? such that some as-
pect of Fi or some aspect of Si is not
strictly predictable from Cx?s compo-
nent parts or from other previously es-
tablished constructions.
In this paper we only focus on syntax. For us, at
the syntactic level, a construction is defined by a
form, where a form is specified as a list of proper-
ties. When building a traditional phrase structure
(i.e. a hierarchical structure of constituents) a con-
struction can be simply seen as a non-terminal.
Property. A property is a constraint, which
models a relationship among constructions. PG
pre-defines several types of properties, which are
specified according to their semantics. Moreover,
the framework allows for new types to be defined.
4Blache (2004) discussed how PG can be used as a formal
framework for CxG.
18
In Numbat, a property type is also called a rela-
tion. Section 2.1.2 briefly presents some of the
pre-defined property types and their semantics.
Assignment. In PG an assignment is a list of
constituents. Let?s consider, for example, the three
constituents DET, ADJ and N, the following lists
are possible assignments: [DET], [ADJ], [DET,
ADJ], [ADJ, N], [DET, N], [DET, ADJ, N], etc..
2.1.2 Some Pre-defined Property Types
Here are some property types pre-defined in PG.
See (Blache, 2005) for more types and more de-
tailed definitions.
Notation. We note:
? K a set of constructions, with {C, C1, C2} ?
K;
? C a set of constituents, with {c, c1, c2} ? C;
? A an assignment;
? ind a function such that ind(c,A) is the in-
dex of c in A;
? cx a function such that cx(c) is the construc-
tion of c;
? P(C1, C2)[c1, c2,A] or (C1 P C2)[c1, c2,A]
the constraint such that the relation P param-
etered with (C1, C2), applies to [c1, c2,A].
Linear Precedence (?).
By definition, (C1 ? C2)[c1, c2,A] holds iff
?
?
?
?
?
?
?
cx(c1) = C1, and
cx(c2) = C2, and
{c1, c2} ? A, and
ind(c1,A) < ind(c2,A)
Exclusion (<).
By definition, (C1 < C2)[c1, c2,A] holds iff
?
?
?
cx(c1) = C1, and
cx(c2) = C2, and
{c1, c2} ? A 6= {c1, c2}
Uniqueness (Uniq).
By definition, Uniq(C)[c,A] holds iff
?
?
?
cx(c) = C, and
c ? A, and
?c? ? A\{c}, cx(c?) 6= C
2.2 Related Problems
CO parsing with PG is an intersection of differ-
ent classes of constraint-related problems, each of
which is listed below.
Configuration problem. Given a set of com-
ponents and a set of constraints specifying how
these components can be connected, a configu-
ration problem consists of finding a solution tree
which connects the components together. Deep
parsing with PG is a configuration problem where
the components are constituents, and the resulting
structure is a phrase structure. By extension, a so-
lution to such a problem is called a configuration.
A configuration problem can be modelled with a
(static) CSP.
Dynamic CSP. In our case the problem is actu-
ally dynamic, in that the set of constraints to be
solved evolves by the addition of new constraints.
As we will see it later new constituents are inferred
during the parsing process, and subsequently new
constraints are dynamically added to the system.
When dealing with deep parsing, i.e. with well-
formedness only, the problem can be tackled as
a Dynamic CSP, and solving techniques such as
Local Search (Verfaillie and Schiex, 1994) can be
applied.
Optimisation problem. In order to account for
ill-formedness as well as well-formedness, we
need to allow constraint relaxation, which turns
the problem into an optimisation one. The ex-
pected outcome is thus an optimal configuration
with respect to some valuation function. Should
the input be well-formed, no constraints are re-
laxed and the expected outcome is a full parse.
Should the input be ill-formed, constraints are re-
laxed and the expected outcome is either an opti-
mal full parse or a set of (optimal) partial parses.
3 Numbat Architecture
3.1 The Parsing Strategy in Numbat
Relying on a design pattern used in various optimi-
sation techniques, such as dynamic programming,
the top-level strategy adopted in Numbat consists
in three main steps:
1. splitting the problem into overlapping sub-
problems;
2. solving the sub-problems?or building opti-
mal sub-solutions;
19
3. building an optimal global solution, using the
sub-solutions.
More specifically, the strategy adopted pro-
ceeds by successive generate-and-test: the possi-
ble models to local systems are generated, then
their satisfiability is tested against the grammar.
The partial solutions are re-injected in the pro-
cess dynamically, and the basic process is iterated
again. Note that the generate-and-test method is
not compulsory and is only chosen here because
it allows us to conveniently control and then filter
the assignments.
Given an input utterance, the parsing process is
made up of a re-iteration of the basic following
steps:
1. Building Site. Build a set of constituents;
2. Assignation. Build all the possible assign-
ments, i.e. all the possible combinations of
one or more constituents;
3. Checkpoint Alpha. Filter out illegal assign-
ments;
4. Appropriation. For every assignment, iden-
tify and build all the relevant properties
among its elements, which leaves us with a
property store, i.e. a constraint system;
5. Checkpoint Bravo. Filter out illegal assign-
ments and irrelevant properties;
6. Satisfaction. Solve the constraint system;
7. Formation. Identify forms of construction,
i.e. subsets of properties from the property
store and nominate the corresponding candi-
date constructions;
8. Polling booth. Decide which of the candi-
date constructions are licensed and carried
over to the next iteration;
The process stops when no new constituent can be
built.
Each of these steps is defined in the following
section.
3.1.1 Building Site
During the first iteration, this phase builds one
constituent for each Part-of-Speech (POS) associ-
ated with an input word. From the second itera-
tion onwards, new constituents are built provided
the candidate assignments output by the previous
round.
3.1.2 Assignation
From one iteration to the next new assignments
are built, involving at least one of the new con-
stituents. These constituents result from the pre-
vious iteration. Notice that the amount of new as-
signments created by each iteration grows expo-
nentially with the amount of constituents (the ?old?
ones and the new ones). Fortunately, the next step
will filter out a large proportion of them.
This phase of assignation is essential to the pro-
cess, and makes Numbat different from any other
parsing strategy for PG. The difference will be
made clear in the Satisfaction phase.
3.1.3 Checkpoint Alpha
In Numbat we use a filtering profile to specify
which combination of heuristics applies during the
parsing process. This feature proves to be very
useful when performing experiments, as it allows
an incremental approach, in order to determine the
relative importance of each of the criteria on gra-
dience by turning on and off one or other heuristic.
The heuristics play different roles. They are pri-
marily used to prune the search space as early as
possible in the process. Meanwhile, most of them
capture language specific aspects (e.g. Contigu-
ity, see below). These language specific heuris-
tics are already present in previous works on PG in
one form or another. We are working in the same
framework and accept these restrictions, which
might be relaxed by future work on the formal
side.
During Checkpoint Alpha the following heuris-
tics may apply.
Heuristic 1 (Distinct Constituents) An as-
signment may contain no pairwise intersecting
constituents.
That is, any two constituents may not have any
constituent in common. For example, the con-
stituents {DET1, ADJ2} and {ADJ2, NOUN3} may
not belong to the same assignment, since they have
one constituent in common.
Heuristic 2 (Contiguity) An assignment is a set
of contiguous elements.
This heuristic rules out crossing-over elements.
Although this heuristic has little consequence
when dealing with languages such as French or
English, it may have to be turned off for languages
with cross-serial dependencies such as Dutch. But
if turned off, an additional problem then occurs
20
that the semantics of pre-defined property types
must be re-defined. The linear precedence, for in-
stance, would need to account for the order be-
tween two crossing-over phrases, which is not the
case in the current definition. On the other hand,
notice that long distance dependencies are not
ruled out by heuristic 2, since nested constituents
are still legal.
3.1.4 Appropriation
This step has to do with the gathering of all the
properties relevant to every assignment from the
grammar. This operation is made easier by pre-
processing the grammar, which is done at an ini-
tialisation step. During this preliminary phase, a
lookup table is created for the grammar, where all
the properties are indexed by their operands. Ev-
ery property is also linked directly to the construc-
tions for which it participates in the definition?
i.e. the constructions for which the property is
a member of the form. This table is actually a
hash table, where the keys are the constructions
on which the properties hold. For example, the
property (Det ? Noun) is indexed by the couple
of constructions (Det, Noun). And the property
({Pronoun, Adv} < V) is indexed by the triplets
of constructions (Pronoun, Adv, V). Thus, given
an assignment, i.e. a set of constituents, all we
have to do here is to retrieve all the relevant prop-
erties from the lookup table, using all the (rele-
vant) combinations of constituents as keys.
3.1.5 Checkpoint Bravo
Filters apply here, which aim to prune again the
search space. The following heuristics may apply.
Heuristic 3 (Full Coverage) Every element of an
assignment must be involved in at least one con-
straint. That is, for each element in an assignment
there must be at least one constraint defined over
this element.
Example 1 Consider the assignment A =
?Det,N, V ?, and the grammar made up of the fol-
lowing properties:
VP ::= {V ? NP} (1)
NP ::= {Uniq(N), Det ? N, N ? Adj} (2)
S ::= {NP ? VP} (3)
According to heuristic 3 A is ruled out, since the V
element is not covered by any constraints, whether
we build an NP or a VP.
Notice that this heuristic is semantically equiv-
alent to the Constituency property present in early
versions of PG5. The Constituency property used
to specify which types of constituent (i.e. con-
structions) were legal ones (for a construction).
Such a constraint is unnecessary since the infor-
mation can be retrieved by simply listing all the
types of constituents used in the definitions of
properties. In example 1 for instance, the set
of legal constituents for the NP construction is
[Det,N,Adj].
A main reason for dealing with constituency as
a filter rather than as a constraint is to improve ef-
ficiency by reducing the amount of constraints in
the system. Indeed, a filter aims to rule out con-
straints, which are subsequently removed from the
constraint system. If dealt with as a constraint it-
self, Constituency would only make the constraint
system more complex.
Heuristic 3 raises the issue of ruling out assign-
ments with ?free? constituents, i.e. constituents
which are not connected to the rest of the assign-
ment. Such a situation may occur, for example,
in the case of an unknown word, either because
it is absent from the lexicon, or misspelled. We
choose to leave it up to the grammar writer to de-
sign their own ad hoc solutions regarding how to
handle such cases. It may be done, for instance,
through the definition of a ?wildcard construc-
tion?, and perhaps also a ?wildcard property type?,
which will be used appropriately in the grammar.
3.1.6 Satisfaction
At this stage, only legal assignments and rele-
vant properties are kept in the system. All the re-
quired information for evaluating the properties is
thus available and all we have to do now is to solve
the constraint system.
The solver we use is implemented in Constraint
Handling Rules (CHR) (Fru?hwirth, 1994). Un-
like other CHR implementations of PG (Moraw-
ietz and Blache, 2002; Dahl and Blache, 2004)
where the semantics of the property types are en-
coded in the handlers6?and therefore each type
of property requires a different handler?, the ap-
proach we have adopted allows us to externalise
the semantics and to generalise the properties eval-
uation with one single handler. The algorithm un-
5The Constituency property is discarded in the version of
PG underpinning Numbat.
6A CHR handler is a rule of the general form (A => B
| C), which can be read ?if A then (if B then C)?
21
derlying this handler can be expressed as follows:
for each (list of n constituents, assignment, property)
if (the list of n constituents and the assignment match the
property?s ones)
then
if (property is satisfied)
then (tick property as being SATISFIED)
else (tick property as being VIOLATED)
The CHR handler takes the following form:
listOfConstituents(Ccs) &&
assignment(Asg) &&
property(Pp) ==>
Pp.isConsistentWith(Asg,Ccs) |
(Pp.isSatisfied() ->
sat(Pp) ; unSat(Pp)).
3.1.7 Formation
This phase is concerned with identifying the
constructions in the grammar which can be trig-
gered (i.e. licensed) by the properties present in
the property store. A construction is triggered by
any of the properties which are used to define this
construction. This task can be performed easily
by accessing them directly in the lookup table (see
section 3.1.4), using a property?s operands as the
key. The constructions which are triggered are
called target constructions. We then build a con-
stituent for each of these target construction. Such
a constituent is called a candidate constituent.
This phase basically builds constituent struc-
tures. During the next iteration these candidates
may be used in turn as constituents. The process
thus accounts for recursive structures as well as
non-recursive ones. Meanwhile, it is interesting to
emphasise that building such a constituent struc-
ture is not necessary when parsing with PG. We
could, for instance, deal with the whole sentence
at once as a sequence of word order constraints.
This way no constituent structure would be needed
to license infinite sets of strings. In this case, the
efficiency of such a process is something that has
been worked on extensively within the CSP field.
What we are contributing is merely a representa-
tion and translation to CSP, which allows us to
take advantage of these efficiencies that decades
of other work have produced.
Monotonic and Non-monotonic Constraints.
The notions of Selection Constraint in (Dahl and
Blache, 2004) and of non-Lacunar Constraint
in (VanRullen, 2005) are equivalent and denote
a class of constraint types, whose semantics is
monotonic, in that their satisfiability does not
change when new elements are added to the as-
signment. Constraint types such as Linear Prece-
dence or Obligation, for example, are monotonic.
On the other hand the constraint Uniq(C)[c,A]
(see 2.1.2), for example, is non-monotonic: if the
contextual assignment A grows?i.e. if new con-
stituents are added to it?the constraint needs to
be re-evaluated. In parsing strategies where the as-
signments are built dynamically by successive ad-
ditions of new constituents, the evaluation of the
relevant constraints is performed on the fly, which
means that the non-monotonic constraints need to
be re-evaluated every time the assignment grows.
This problem is tackled in different ways, accord-
ing to implementation. But we observe that in all
cases, the decision to trigger new candidate con-
stituents relies only on the evaluation of the mono-
tonic constraints. The decision process usually
simply ignores the non-monotonic ones. Numbat,
by fixing the assignments prior to evaluating the
local constraint systems, includes both the mono-
tonic and the non-monotonic constraints in the li-
censing process (i.e. in the Formation phase).
3.1.8 Polling Booth
This phase is concerned with the election pro-
cess, which leads to choosing the candidates who
will make it to the next iteration.
The following heuristics may apply.
Heuristic 4 (Minimum Satisfaction) An assign-
ment is valid only if at least one constraint holds
on any of its constituents.
Notice that in all other implementations of PG this
heuristic is much more restrictive and requires that
a monotonic constraint must hold.
Heuristic 5 (Full Input Span) A valid (partial or
final) solution to the parsing problem is either a
single constituent which spans exactly the input
utterance, or a combination of constituents (i.e.
a combination of partial parses) which spans ex-
actly the input utterance.
In theory, we want the Polling Booth to build all
the candidate constituents we have identified, and
re-inject them in the system for new iterations. In
practice, different strategies may apply in order to
prune the search space, such as strategies based on
the use of a ranking function. In our case, every it-
eration of the parsing process only propagates one
22
valid combination of constituents to the next iter-
ation (e.g. the best one according to a valuation
function). Somehow such a strategy corresponds
to always providing the main process with a ?dis-
ambiguated? set of input constituents from one it-
eration to another. This heuristic may also be used
as a termination rule.
A question then arises regarding the relaxation
policy: Do all the constraint types carry same im-
portance with respect to relaxation? This ques-
tion addresses the relative importance of differ-
ent constraint types with respect to acceptability.
Does, for instance, the violation of a constraint
of Linear Precedence between a Determiner and
a Noun in a Noun Phrase have the same impact
on the overall acceptability of the Noun Phrase
than the violation of Uniqueness of the Noun (still
within a Noun Phrase)? From a linguistic point of
view, the answer to that question is not straight-
forward and requires number of empirical studies.
Some works have been carried out (Gibson, 2000;
Keller, 2000), which aim to provide elements of
answer in very targeted syntactic contexts.
The impact that the relaxation of different con-
straint types has on acceptability should not be bi-
ased by a particular parsing strategy. Thus, the
framework provides the linguist (and the grammar
writer) with maximum flexibility when it comes to
decide the cost of relaxing different types of con-
straint on acceptability, since any type may be re-
laxed. Intuitively, one can clearly relax (in French)
a constraint of Agreement in gender between de-
terminer and noun; on the other hand one could
not as easily relax constraints of type Obligation,
which are often used to specify heads. A com-
plete breakdown of constraints into relaxable and
non-relaxable is future work. But at the end, the
parser just produces sets of satisfied and violated
constraints, regardless of how important they are.
There will then be a separate process for predict-
ing gradience, where the relative importance of
particular constraints in determining acceptability
will be decided experimentally.
4 Conclusion
In this paper we have presented the constraint-
oriented parsing strategy based on Property Gram-
mars, that we have developed as part of the Num-
bat platform. We have also demonstrated that,
unlike other existing parsers for PG, this strategy
does not privilege any particular type of property
when licensing a new constituent. By doing so,
this parser contributes to maintain a close connec-
tion with the underpinning theory. In the context
of robust parsing, where decisions must be made
on the basis of a balance between satisfied and vi-
olated properties, it also allows the decision pro-
cess to be better informed by providing it with
more grounding linguistic material concerning the
input.
For the same reason, this contribution is also
fairly valuable in the context of our prime research
goal, which is concerned with quantifying accept-
ability.
In further works we plan to evaluate the perfor-
mance of the parser. We also plan to use Numbat
to run series of experiments on gradience, in order
to design and test a suitable valuation function to
be used to assess the degree of acceptability of an
input utterance.
References
Jean-Marie Balfourier, Philippe Blache, and Tris-
tan Van Rullen. 2002. From Shallow to Deep Pars-
ing Using Constraint Satisfaction. In Proc. of the
6th Int?l Conference on Computational Linguistics
(COLING 2002).
Gabriel Be`s and Philippe Blache. 1999. Proprie?te?s et
analyse d?un langage. In TALN.
Philippe Blache. 2001. Les Grammaires de Proprie?te?s
: des contraintes pour le traitement automatique des
langues naturelles. Herme`s Sciences.
Philippe Blache. 2004. Constraints: an operational
framework for constructions grammars. In ICCG-
04, pages 25?26.
Philippe Blache. 2005. Property Grammars: A fully
constraint-based theory. In Henning Christiansen,
Peter Rossen Skadhauge, and Jorgen Villadsen, ed-
itors, Constraint Solving and Language Processing,
volume 3438 of LNAI. Springer.
Veronica Dahl and Philippe Blache. 2004. Directly
executable constraint based grammars. In Journees
Francophones de Programmation en Logique avec
Contraintes, pages 149?166, Angers, France.
Ralph Debusmann, Denys Duchier, and Geert-Jan M.
Kruijff. 2004. Extensible Dependency Grammar: A
New Methodology. In Proceedings of the 7th Inter-
national Conference on Computational Linguistics
(COLING 2004).
Denys Duchier. 1999. Axiomatizing Dependency
Parsing Using Set Constraints. In Proceedings 6th
Meeting on the Mathematics of Language, Orlando,
FL.
23
Denys Duchier. 2000. Configuration Of Labeled Trees
Under Lexicalized Constraints And Principles. To
appear in the Journal of Language and Computation,
December.
Kilian Foth, Wolfgang Menzel, and Ingo Schr?der.
2004. Robust Parsing with Weighted Constraints.
Natural Language Engineerings.
Thom Fru?hwirth. 1994. Theory and Practice of Con-
straint Handling Rules. The Journal of Logic Pro-
gramming, 37((1-3)), October. Special Issue on
Constraint Logic Programming.
Edward Gibson. 2000. The Dependency Locality
Theory: A Distance-Based Theory of Linguistic
Complexity. In Alec Marantz, Yasushi Miyashita,
and Wayne ONeil, editors, Image, Language, Brain,
pages 95?126. Cambridge, Mass., MIT Press.
Adele Goldberg. 1995. Constructions: A Con-
struction Grammar Approach to Argument Struc-
ture. Chicago University Press.
Johannes Heinecke, Ju?rgen Kunze, Wolfgang Menzel,
and Ingo Shro?der. 1998. Eliminative Parsing with
Graded Constraints. In Proc. 7th CoLing conf., 36th
Annual Meeting of the ACL, volume Coling?ACL
?98, pages pp. 526?530, Montreal, Canada.
Frank Keller. 2000. Gradience in Grammar - Exper-
imental and Computational Aspects of Degrees of
Grammaticality. Ph.D. thesis, University of Edin-
burgh.
Hiroshi Maruyama. 1990. Structural Disambiguation
with Constraint Propagation. In Proceedings 28th
Annual Meeting of the ACL, pages pp. 31?38, Pit-
tburgh, PA.
Frank Morawietz and Philippe Blache. 2002. Pars-
ing natural languages with chr. Under consideration
for publication in Theory and Practice of Logic Pro-
gramming.
Tristan VanRullen. 2005. Vers une analyse syntaxique
a` granularite? variable. Ph.D. thesis, Universite? de
Provence, Informatique.
Ge?rard Verfaillie and Thomas Schiex. 1994. Solution
reuse in dynamic CSPs. In AAAI ?94: Proc. of the
twelfth national conf. on AI (vol. 1), pages 307?312,
Menlo Park, CA, USA. American Ass. for AI.
24
Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 172?175,
Paris, October 2009. c?2009 Association for Computational Linguistics
Grammar Error Detection with Best Approximated Parse
Jean-Philippe Prost
LIFO, Universite? d?Orle?ans
INRIA Lille - Nord Europe
Jean-Philippe.Prost@univ-orleans.fr
Abstract
In this paper, we propose that grammar er-
ror detection be disambiguated in generat-
ing the connected parse(s) of optimal merit
for the full input utterance, in overcom-
ing the cheapest error. The detected er-
ror(s) are described as violated grammat-
ical constraints in a framework for Model-
Theoretic Syntax (MTS). We present a
parsing algorithm for MTS, which only re-
lies on a grammar of well-formedness, in
that the process does not require any extra-
grammatical resources, additional rules
for constraint relaxation or error handling,
or any recovery process.
1 Introduction
Grammar error detection is a crucial part of
NLP applications such as Grammar Checking or
Computer-Assisted Language Learning (CALL).
The problem is made highly ambiguous depending
on which context is used for interpreting, and thus
pinpointing, the error. For example, a phrase may
look perfectly fine when isolated (e.g. brief inter-
view), but is erroneous in a specific context (e.g.
in *The judge grants brief interview to this plain-
tiff, or in *The judges brief interview this plain-
tiff ). Robust partial parsing is often not enough to
precisely desambiguate those cases. The solution
we prescribe is to point out the error(s) as a set
of violated (atomic) constraints of minimal cost,
along with the structural context used for measur-
ing that cost. Given an ungrammatical input string,
the aim is then to provide an approximated rooted
parse tree for it, along with a description of all the
grammatical constraints it violates. For example,
Figure 1 illustrates an approximated parse for an
ill-formed sentence in French, and the error be-
ing detected in that context. Property Grammar
(Blache, 2001) provides an elegant framework for
that purpose.
S15
NP3
D1
Le
The
N2
juge
judge
VP9
V8
octroie
grants
*NP7
AP6
A4
bref
brief
N5
entretien
interview
PP10
P11
a`
to
NP12
D13
ce
this
N14
plaignant
plaintiff
Figure 1: Approximated parse for an erroneous French sen-
tence (the Noun ?entretien? requires a Determiner).
Most of the relevant approaches to robust
knowledge-based parsing addresses the problem
as a recovery process. More specifically, we
observe three families of approaches in that re-
spect: those relying on grammar mal-rules in or-
der to specify how to correctly parse what ought
to be ungrammatical (Bender et al, 2004; Foster,
2007); those relying on constraint relaxation ac-
cording to specified relaxation rules (Douglas and
Dale, 1992); and those relying on constraint re-
laxation with no relaxation rules, along with a re-
covery process based on weighted parsing (Fou-
vry, 2003; Foth et al, 2005). The first two are
actually quite similar, in that, through their use
of extra-grammatical rules, they both extend the
grammar?s coverage with a set of ought-to-be-
ungrammatical utterances. The main drawback
of those approaches is that when faced with un-
expected input at best their outcome remains un-
known, at worst the parsing process fails. With
robust weighted parsing, on the other hand, that
problem does not occur. The recovery process
consists of filtering out structures with respect to
their weights or the weights of the constraints be-
ing relaxed. However, these strategies usually
can not discriminate between grammatical and un-
grammatical sentences. The reason for that comes
172
from the fact that grammaticality is disconnected
from grammar consistency: since the grammar
contains contradicting (universal) constraints, no
conclusion can be drawn with regard to the gram-
maticality of a syntactic structure, which violates
part of the constraint system. The same problem
occurs with Optimality Theory. In a different fash-
ion, Fouvry weighs unification constraints accord-
ing to ?how much information it contains?. How-
ever, relaxation only seems possible for those uni-
fication constraints: error patterns such as word
order, co-occurrence, uniqueness, mutual exclu-
sion, . . . can not be tackled. The same restriction is
observed in VanRullen (2005), though to a much
smaller extent in terms of unrelaxable constraints.
What we would like is (i) to detect any type
of errors, and present them as conditions of well-
formedness being violated in solely relying on the
knowledge of a grammar of well-formedness?as
opposed to an error grammar or mal-rules, and
(ii) to present, along-side the violated constraints,
an approximated parse for the full sentence, which
may explain which errors have been found and
overcome. We propose here a parsing algorithm
which meets these requirements.
2 Property Grammar
The framework we are using for knowledge rep-
resentation is Property Grammar (Blache, 2001)
(PG), whose model-theoretical semantics was for-
malised by Duchier et al (2009). Intuitively, a
PG grammar decomposes what would be rewriting
rules of a generative grammar into atomic syntac-
tic properties ? a property being represented as a
boolean constraint. Take, for instance, the rewrit-
ing rule NP ? D N. That rule implicitely informs
on different properties (for French): (1) NP has a
D child; (2) the D child is unique; (3) NP has an
N child; (4) the N child is unique; (5) the D child
precedes the N child; (6) the N child requires the
D child. PG defines a set of axioms, each axiom
corresponding to a constraint type. The proper-
ties above are then specified in the grammar as the
following constraints: (1) NP :M D; (2) NP : D!;
(3) NP :M N; (4) NP : N!; (5) NP : D ? N; (6)
NP : N ? D. These constraints can be indepen-
dently violated. A PG grammar is traditionally
presented as a collection of Categories (or Con-
structions), each of them being specified by a set
of constraints. Table 1 shows an example of a
category. The class of models we are working
NP (Noun Phrase)
Features Property Type : Properties
[AVM]
obligation : NP:M(N ? PRO)uniqueness : NP: D!: NP: N!: NP: PP!: NP: PRO!linearity : NP: D ? N: NP: D ? PRO: NP: D ? AP: NP: N ? PPrequirement : NP: N ? D: NP: AP ? Nexclusion : NP: N < PRO
dependency : NP: N?GEND 1NUM 2
? D?GEND 1NUM 2
?
Table 1: NP specification in Property Grammar
with is made up of trees labelled with categories,
whose surface realisations are the sentences ? of
language. A syntax tree of the realisation of the
well-formed sentence ? is a strong model of the
PG grammar G iff it satisfies every constraint in G.
The loose semantics also allows for constraints to
be relaxed. Informally, a syntax tree of the realisa-
tion of the ill-formed sentence ? is a loose model
of G iff it maximises the proportion of satisfied
constraints in G with respect to the total number
of evaluated ones for a given category. The set of
violated constraints provides a description of the
detected error(s).
3 Parsing Algorithm
The class of models is further restricted to con-
stituent tree structures with no pairwise intersect-
ing constituents, satisfying at least one constraint.
Since the solution parse must have a single root,
should a category not be found for a node a wild-
card (called Star) is used instead. The Star cate-
gory is not specified by any constraint in the gram-
mar.
We introduce an algorithm for Loose Satisfac-
tion Chart Parsing (LSCP), presented as Algo-
rithm 1. We have named our implementation of it
Numbat. LSCP is based on the probabilistic CKY,
augmented with a process of loose constraint sat-
isfaction. However, LSCP differs from CKY in
various respects. While CKY requires a grammar
in Chomsky Normal Form (CNF), LSCP takes an
ordinary PG grammar, since no equivalent of the
CNF exists for PG. Consequently, LSCP gener-
ates n-ary structures. LSCP also uses scores of
merit instead of probabilities for the constituents.
That score can be optimised, since it only factors
through the influence of the constituent?s immedi-
ate descendants.
Steps 1 and 2 enumerate all the possible and
173
Algorithm 1 Loose Satisfaction Chart Parsing
/? Initialisation ?/
Create and clear the chart pi: every score in pi is set to 0
/? Base case: populate pi with POS-tags for each word ?/
for i? 1 to num words
for (each POS-category T of wi)
if merit(T ) ? pi[i, 1, T ] then
Create constituent wTi , whose category is T
pi[i, 1, T ]? {wTi , merit(wTi )}
/? Recursive case ?/
/? Step 1: SELECTION of the current reference span ?/
for span? 1 to num words
for offset ? 1 to num words? span + 1
end ? offset + span? 1
K ? ?
/? Step 2: ENUMERATION of all the configurations ?/
for (every set partition P in [offset, . . . , end])
KP ? buildConfigurations(P)
K ? K ?KP
/? Step 3: CHARACTERISATION of the constraint system from the grammar ?/
for (every configurationA ? KP )
?A ? characterisation(A)/? Step 4: PROJECTION into categories ?/
/? CA is a set of candidate constituents ?/
CA ? projection(?A )checkpoint(CA)
/? Step 5: MEMOISATION of the optimal candidate constituent ?/
for (every candidate constituent x ? CA, of construction C)
if merit(x) ? pi[offset, span, C] then
pi[offset, span, C]? {x, merit(x)}
if pi[offset, span] = ? then
pi[offset, span]? preferred forest inK
legal configurations of optimal sub-structures al-
ready stored in the chart for a given span and off-
set. At this stage, a configuration is a tree with
an unlabelled root. Note that Step 2 actually does
not calculate all the set partitions, but only the le-
gal ones, i.e. those which are made up of sub-
sets of contiguous elements. Step 3 evaluates the
constraint system, using a configuration as an as-
signment. The characterisation process is imple-
mented with Algorithm 2. Step 4 consists of mak-
Algorithm 2 Characterisation Function
function characterisation(A = ?c1, . . . , cn? : assignment,
G: grammar)
returns the set of evaluated properties relevant toA,
and the set of projected categories forA.
/? For storing the result characterisation: ?/
create and clear ?A [property]: table of boolean, indexed by property/? For storing the result projected categories: ?/
create and clear CA: set of category
/? For temporarily storing the properties to be evaluated: ?/
create and clear S: set of property
for (mask ? [1 . . . 2n ? 1])
key? applyBinaryMask(A,mask)
if (key is in the set of indexes for G) then
/? Properties are retrieved from the grammar, then evaluated ?/
S ? G[key].getProperties()
?A ? evaluate(S)/? Projection Step: fetch the categories to be projected ?/
CA ? G[key].getDominantCategories()
return ?A , CA
The key is a hash-code of a combination of constructions, used for fetching the
constraints this combination is concerned with.
ing a category judgement for a configuration, on
the basis of which constraints are satisfied and vi-
olated, in order to label its root. The process is a
simple table lookup, the grammar being indexed
by properties. Step 5 then memoises the optimal
sub-structures for every possible category. Note
that the uniqueness of the solution is not guaran-
teed, and there may well be many different parses
with exact same merit for a given input utterance.
Should the current cell in the chart not being
populated with any constituents, a preferred for-
est of partial parses (= Star category) is used in-
stead. The preferred forest is constructed on the
fly (as part of buildConfigurations); a pointer
is maintained to the preferred configuration dur-
ing enumeration. The preference goes to: (i) the
constituents with the widest span; (ii) the least
overall number of constituents. This translates
heuristically into a preference score pF computed
as follows (where F is the forest, and Ci its con-
stituents): pF = span ? (merit(Ci) + span). In
that way, LSCP always delivers a parse for any
input. The technique is somehow similar to the
one of Riezler et al (2002), where fragment parses
are allowed for achieving increased robustness, al-
though their solution requires the standard gram-
mar to be augmented with a fragment grammar.
4 Evaluation
In order to measure Numbat?s ability to (i) detect
errors in an ungrammatical sentence, and (ii) build
the best approximated parse for it, Numbat should,
ideally, be evaluated on a corpus of both well-
formed and ill-formed utterances annotated with
spannnig phrase structures. Unfortunately, such
a Gold Standard is not available to us. The de-
velopment of adequate resources is central to fu-
ture works. In order to (partially) overcome that
problem we have carried out two distinct evalua-
tions: one aims to measure Numbat?s performance
on grammatical sentences, and the other one on
ungrammatical sentences. Evaluation 1, whose re-
sults are reported in Table 2, follows the proto-
col devised for the EASY evaluation campaign of
parsers of French (Paroubek et al, 2003), with a
subset of the campaign?s corpus. For comparison,
Table 3 reports the performance measured under
the same circumstances for two other parsers: a
shallow one (VanRullen, 2005) also based on PG,
and a stochastic one (VanRullen et al, 2006). The
grammar used for that evaluation was developed
by VanRullen (2005). Evaluation 2 was run on
174
Precision Recall F
Total 0.7835 0.7057 0.7416
general lemonde 0.8187 0.7515 0.7837
general mlcc 0.7175 0.6366 0.6746
general senat 0.8647 0.7069 0.7779
litteraire 0.8124 0.7651 0.788
mail 0.7193 0.6951 0.707
medical 0.8573 0.678 0.757
oral delic 0.6817 0.621 0.649
questions amaryllis 0.8081 0.7432 0.7743
questions trec 0.8208 0.7069 0.7596
Table 2: EASY scores of Numbat (Eval. 1)
Precision Recall F
shallow parser 0.7846 0.8376 0.8102
stochastic parser 0.9013 0.8978 0.8995
Table 3: Comparative EASY scores
a corpus of unannotated ungrammatical sentences
(Blache et al, 2006), where each of the ungram-
matical sentences (amounting to 94% of the cor-
pus) matches a controlled error pattern. Five ex-
pert annotators were asked whether the solution
trees were possible and acceptable syntactic parses
for their corresponding sentence. Specific instruc-
tions were given to make sure that the judgement
does not hold on the grammatical acceptability of
the surface sentence as such, but actually on the
parse associated with it. For that evaluation Van-
Rullen?s grammar was completed with nested cat-
egories (since the EASY annotation scheme only
has chunks). Given the nature of the material to
be assessed here, the Precision and Recall mea-
surements had to be modified. The total number
of input sentences is interpreted as the number of
predictions; the number of COMPLETE structures
is interpreted as the number of observations; and
the number of structures evaluated as CORRECT
by human judges is interpreted as the number of
correct solutions. Hence the following formula-
tions and scores: Precision=CORRECT/COMPLETE=0.74;
Recall=CORRECT/Total=0.68; F=0.71. 92% of the cor-
pus is analysed with a complete structure; 74% of
these complete parses were judged as syntactically
correct. The Recall score indicates that the correct
parses represent 68% of the corpus. In spite of a
lack of a real baseline, these scores compare with
those of grammatical parsers.
5 Conclusion
In this paper, we have proposed to address the
problem of grammar error detection in providing
a set of violated syntactic properties for an ill-
formed sentence, along with the best structural
context in the form of a connected syntax tree. We
have introduced an algorithm for Loose Satisfac-
tion Chart Parsing (LSCP) which meets those re-
quirements, and presented performance measures
for it. Future work includes optimisation of LSCP
and validation on more appropriate corpora.
Acknowledgement
Partly funded by ANR-07-MDCO-03 (CRoTAL).
References
E. M. Bender, D. Flickinger, S. Oepen, A. Walsh, and
T. Baldwin. 2004. Arboretum: Using a precision
grammar for grammar checking in CALL. In Proc.
of InSTIL/ICALL2004, volume 17, page 19.
P. Blache, B. Hemforth, and S. Rauzy. 2006. Ac-
ceptability Prediction by Means of Grammaticality
Quantification. In Proc. of CoLing/ACL, pages 57?
64. ACL.
P. Blache. 2001. Les Grammaires de Proprie?te?s :
des contraintes pour le traitement automatique des
langues naturelles. Herme`s Sciences.
S. Douglas and R. Dale. 1992. Towards Robust PATR.
In Proc. of CoLing, volume 2, pages 468?474. ACL.
D. Duchier, J-P. Prost, and T-B-H. Dao. 2009.
A Model-Theoretic Framework for Grammaticality
Judgements. In To appear in Proc. of FG?09, vol-
ume 5591 of LNCS. FOLLI, Springer.
J. Foster. 2007. Real bad grammar: Realistic grammat-
ical description with grammaticality. Corpus Lin-
guistics and Lingustic Theory, 3(1):73?86.
K. Foth, W. Menzel, and I. Schro?der. 2005. Robust
Parsing with Weighted Constraints. Natural Lan-
guage Engineering, 11(1):1?25.
F. Fouvry. 2003. Constraint relaxation with weighted
feature structures. pages 103?114.
P. Paroubek, I. Robba, and A. Vilnat. 2003. EASY:
An Evaluation Protocol for Syntactic Parsers.
www.limsi.fr/RS2005/chm/lir/lir11/ (08/2008).
S. Riezler, T. H. King, R. M. Kaplan, R. Crouch,
J. T. III Maxwell, and M. Johnson. 2002.
Parsing the Wall Street Journal using a Lexical-
Functional Grammar and Discriminative Estimation
Techniques. In Proc. of ACL, pages 271?278. ACL.
T. VanRullen, P. Blache, and J-M. Balfourier. 2006.
Constraint-Based Parsing as an Efficient Solution:
Results from the Parsing Evaluation Campaign
EASy. In Proc. of LREC, pages 165?170.
T. VanRullen. 2005. Vers une analyse syntaxique a`
granularite? variable. The`se de doctorat.
175
