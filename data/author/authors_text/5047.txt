Proceedings of the 7th SIGdial Workshop on Discourse and Dialogue, pages 76?79,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Semantic tagging for resolution of indirect anaphora
R. Vieira1, E. Bick2, J. Coelho1, V. Muller1, S. Collovini1, J. Souza1, L. Rino3
UNISINOS1, University of Denmark2, UFSCAR3
renatav@unisinos.br, eckhard.bick@mail.dk, lucia@dc.ufscar.br
Abstract
This paper presents an evaluation of indi-
rect anaphor resolution which considers as
lexical resource the semantic tagging pro-
vided by the PALAVRAS parser. We de-
scribe the semantic tagging process and a
corpus experiment.
1 Introduction
Bridging anaphora represents a special part of the
general problem of anaphor resolution. As a spe-
cial case of anaphora, it has been studied and dis-
cussed by different authors and for various lan-
guages. There are many problems in develop-
ing such studies. First, bridging is not a regu-
lar class, it seldom contains cases of associative
and indirect anaphora (defined in the sequence);
lexical resources such as Wordnet are not avail-
able for every language, and even when available
such resources have proven to be insufficient for
the problem. In fact, different sources of lexi-
cal knowledge have been evaluated for anaphora
resolution (Poesio et al, 2002; Markert and Nis-
sim, 2005; Bunescu, 2003). At last, corpus stud-
ies of bridging anaphora usually report results
on a reduced number of examples, because this
kind of data is scarce. Usually bridging anaphora
considers two types: Associative anaphors are
NPs that have an antecedent that is necessary
to their interpretation (the relation between the
anaphor and its antecedent is different from iden-
tity); and Indirect anaphor are those that have
an identity relation with their antecedents but the
anaphor and its antecedent have different head-
nouns. In both associative and indirect anaphora,
the semantic relation holding between the anaphor
and its antecedent play an essential role for res-
olution. However, here we present an evalu-
ation of the semantic tagging provided by the
Portuguese parser PALAVRAS (Bick, 2000)
(http://visl.sdu.dk/visl/pt/parsing/automatic) as a
lexical resource for indirect anaphora resolution.
We focus on indirect anaphors for two reasons,
they are greater in number and they present better
agreement features concerning human annotation.
2 Semantic Annotation with Prototype
Tags
As a Constraint Grammar system, PALAVRAS
encodes all annotational information as word
based tags. A distinction is made between mor-
phological, syntactic, valency and semantic tags,
and for a given rule module (or level of analysis),
one tag type will be regarded as primary (= flagged
for disambiguation), while tags from lower lev-
els provide unambiguous context, and tags from
higher levels ambiguous lexical potentialities.
Thus, semantic tags are regarded as secondary
help tags at the syntactic level, but will have un-
dergone some disambiguation at the anaphora res-
olution level. The semantic noun classes were
conceived as distinctors rather than semantic de-
finitions, the goal being on the one hand to cap-
ture semantically motivated regularities and rela-
tions in syntax, on the other hand to allow to dis-
tinguish between different senses, or to chose dif-
ferent translation equivalents in MT applications.
A limited set of semantic prototype classes was
deamed ideal for both purposes, since it allows at
the same time similarity-based lumping of words
(useful in structural analysis, IR, anaphora reso-
lution) and context based polysemy resolution for
an individual word (useful in MT, lexicography,
alignment). Though we define class hypernyms
as prototypes in the Roschian sense (Rosch, 1978)
76
as an (idealized) best instance of a given class of
entities, we avoided low level prototypes, using
<Azo> for four-legged land-animals rather than
<dog> and <cat> for dog and cat races etc.).
Where possible, systematic sub-classes were es-
tablished. Semiotic artifacts <sem>, for instance
are sub-divided into ?readables? <sem-r> (book-
prototype: book, paper, magazine), ?watchables?
<sem-w> (film, show, spectacle), ?listenables?
etc. The final category inventory, though devel-
oped independently, resembles the ontology used
in the multilingual European SIMPLE project
(http://www.ub.es/ gilcub/SIMPLE/simple.html).
For the sake of rule based inheritance reasoning,
semantic prototype classes were bundled using a
matrix of 16 atomic semantic features. Thus,
the atomic feature +MOVE is shared by the dif-
ferent human and animal prototypes as well as
the vehicle prototype, but the vehicle prototype
lacks the +ANIM feature, and only the bun-
dle on human prototypes (<Hprof>, <Hfam>,
<Hideo>,...) shares the +HUM feature (human
professional, human family, human follower of a
theory/belief/conviction/ideology). In the parser,
a rule selecting the +MOVE feature (e.g. for sub-
jects of movement verbs) will help discard com-
peting senses from lemmas with the above proto-
types, since they will all inherit choices based on
the shared atomic feature. Furthermore, atomic
features can themselves be subjected to inheri-
tance rules, e.g. +HUM ?> +ANIM ?> +CON-
CRETE, or +MOVE?> +MOVABLE. In Table 1,
which contains examples of polysemic institution
nouns, positive features are marked with capital
letters, negative features with small letters1. The
words in the Table 1 are ambiguous with regard
to the feature H, and since it is only the <inst>
prototype that contributes the +HUM feature po-
tential, it can be singled out by a rule selecting
?H? or by discarding ?h?. The parser?s about 140
prototypes have been manually implemented for a
lexicon of about 35.000 nouns. In addition, the
?HUM category was also introduced as a selec-
tion restriction for 2.000 verb senses (subject re-
striction) and 1.300 adjective senses (head restric-
tion).
While the semantic annotation of common
nouns is carried out by disambiguating a given
lemma?s lexicon-listed prototype potential, this
strategy is not sufficient for proper nouns, due
1furn=furniture, con=container, inst=institution
Ee = entities (?CONCRETE)
Jj = ?MOVABLE
Hh = ?HUMAN ENTITY
Mm = ?MAS
Ll = ?LOCATION
polysemy spectrum
Ee j Hh m Ll faculdade
E H L <inst> univ. faculty
e h l <f-c> property
Ee j Hh m Ll fundo
e h L <Labs> bottom
E H L <inst> foundation
e h l <ac> <smP> funds
Ee j Hh Mm Ll indu?stria
E H m L <inst> industry
e h M l <am> diligence
E Jj Hh m L rede
J h <con> net
j H <inst> <+n> network
J h <furn> hammock
Table 1: Feature bundles in prototype based poly-
semy
to the productive nature of this word class. In
two recent NER projects, the parser was aug-
mented with a pattern recognition module and a
rule-based module for identifying and classify-
ing names. In the first project (Bick, 2003),
6 main classes with about 15 subclasses were
used in a lexeme-based approach, while the
second adopted the 41 largely functional cate-
gories of Linguateca?s joint HAREM evaluation
in 2005 (http://www.linguateca.com). A lexicon-
registered name like Berlin would have a stable
tag (<civ> = civitas) in the first version, while
it would be tagged as either <hum>, <top> or
<org> in the second, dependent on context. At
the time of writing, we have not yet tagged our
anaphora corpus with name type tags, and it is
unclear which approach, lexematic or functional,
will work best for the resolution of indirect and
associative anaphora.
3 Indirect Anaphora Resolution
Our work was based on a corpus formed by 31
newspaper articles, from Folha de Sa?o Paulo, writ-
ten in Brazilian Portuguese. The corpus was au-
tomatically parsed using the parser PALAVRAS,
and manually annotated for anaphoricity using
the MMAX tool(http://mmax.eml-research.de/) .
Four subjects annotated the corpus. All annota-
tors agreed on the antecedent in 73% of the cases,
in other 22% of the cases there was agreement be-
tween three annotators and in 5% of the cases only
two annotators agreed. There were 133 cases of
77
definite Indirect anaphors (NPs starting with def-
inite articles) from the total of 1454 definite de-
scriptions (near to 10%) and 2267 NPs.
The parser gives to each noun of the text (or to
most of them) a semantic tag. For instance, the
noun japone?s [japanese] has the following seman-
tic tags ling and Hnat, representing the features:
human nationality and language respectively.
<word id="word_28">
<n can="japone?s" gender="M" number="S">
<secondary_n tag="Hnat"/>
<secondary_n tag="ling"/>
</n>
</word>
The approach consists in finding relationships
with previous nouns through the semantic tags.
The chosen antecedent will be the nearest expres-
sion with the largest number of equal semantic
tags. For instance, in the example below, the
anaphor is resolved by applying this resolution
principle, to japone?s - a l??ngua.
O Eurocenter oferece cursos de japone?s em Kanazawa.
Apo?s um me?s, o aluno falara? modestamente a l??ngua.
The Eurocenter offers Japanese courses in Kanazawa. Af-
ter one month, a student can modestly speak the language.
As both expressions (japanese and language)
hold the semantic tag ?ling? the anaphor is re-
solved. For the experiments, we considered as cor-
rect the cases where the antecedent found automat-
ically was the same as in the manual annotation
(same), and also the cases in which the antecedent
of the manual annotation was found further up in
the chain identified automatically (in-chain). We
also counted those cases in which the antecedent
of the manual annotation was among the group of
candidates sharing the same tags (in-candidates),
but was not the chosen one (the chosen being the
nearest with greater number of equal tags).
Indirect anaphora
Results # % of Total
Same 25 19%
In-chain 15 11%
Total Correct 40 30%
In-candidates 9 7%
Unsolved 40 30%
Error 44 33%
Total 133 100%
Table 2: Indirect anaphor resolution
Table 2 shows the results of the indirect anaphor
resolution. In 19% of the cases, the system found
the same antecedent as marked in the manual an-
notation. Considering the chain identified by the
system the correct cases go up to 30%. The great
number of unsolved cases were related to the fact
that proper names were not tagged. Considering
mainly the tagged nouns (about 93 cases), the cor-
rect cases amount to 43%). This gives us an idea
of the quality of the tags for the task. We further
tested if increasing the weight of more specific
features in opposition to the more general ones
would help in the antecedent decision process. A
semantic tag that is more specific receives a higher
weight The semantic tag set has three levels, level
1, which is more general receives weight 1, level 2
receives 5, and level 3 receives 10. See the exam-
ple below.
<A> 1 Animal, umbrella tag
<AA> 5 Group of animals
<Adom> 10 Domestic animal
In this experiment the chosen candidate is the
nearest one whose sum of equal tag values has
higher weight. Table 3 shows just a small im-
provement in the correct cases. If we do not
consider unsolved cases, mostly related to proper
names, indirect anaphors were correctly identified
in 46% of the cases (43/96).
Indirect anaphora
Results # % of Total
Same 24 18%
In-chain 19 14%
Total Correct 43 32%
In-candidates 6 5%
Unsolved 40 30%
Error 44 33%
Total 133 100%
Table 3: Indirect anaphor - weighting schema
Since there is no semantic tagging for proper
names as yet, the relationship between pairs such
as Sa?o Carlos - a cidade [Sa?o Carlos - the city]
could not be found. Regarding wrong antecedents,
we have seen that some semantic relationships are
weaker, having no semantic tags in common, for
instance: a proposta - o aumento [the proposal -
the rise]. In some cases the antecedent is not a
previous noun phrase but a whole sentence, para-
graph or disjoint parts of the text. As we con-
sider only relations holding between noun phrases,
these cases could not be resolved. Finally, there
are cases of plain heuristic failure. For instance,
establishing a relationship between os professores
78
[the teachers], with the semantic tags H and Hprof,
and os politicos [the politicians], with the seman-
tic tags H and Hprof, when the correct antecedent
was os docentes [the docents], with the semantic
tags HH (group of humans) and Hprof.
4 Final Remarks
Previous work on nominal anaphor resolution has
used lexical knowledge in different ways. (Poe-
sio et al, 1997) presented results concerning the
resolution of bridging definitions, using the Word-
Net (Fellbaum, 1998), where bridging DDs en-
close our Indirect and Associative anaphora. Poe-
sio et al reported 35% of recall for synonymy,
56% for hypernymy and 38% for meronymy.
(Schulte im Walde, 1997) evaluated the bridg-
ing cases presented in (Poesio et al, 1997), on
the basis of lexical acquisition from the British
National Corpus. She reported a recall of 33%
for synonymy, 15% for hypernymy and 18% for
meronymy. (Poesio et al, 2002) considering syn-
tactic patterns for lexical knowledge acquisition,
obtained better results for resolving meronymy
(66% of recall). (Gasperin and Vieira, 2004)
tested the use of word similarity lists on resolv-
ing indirect anaphora, reporting 33% of recall.
(Markert and Nissim, 2005) presented two ways
(WordNet and Web) of obtaining lexical knowl-
edge for antecedent selection in coreferent DDs
(Direct and Indirect anaphora). Markert and
Nissim achieved 71% of recall using Web-based
method and 65% of recall using WordNet-based
method. We can say that our results are very sat-
isfactory, considering the related work. Note that
usually evaluation of bridging anaphora is made
on the basis of a limited number of cases, because
the data is sparse. Our study was based on 133
examples, which is not much but surpasses some
of the previous related work. Mainly, our results
indicate that the semantic tagging provided by the
parser is a good resource for dealing with the prob-
lem, if compared to other lexical resources such as
WordNet and acquired similarity lists. We believe
that the results will improve significantly once se-
mantic tags for proper names are provided by the
parser. This evaluation is planned as future work.
Acknowledgments
This work was partially funded by CNPq.
References
Eckhard Bick. 2000. The Parsing System PALAVRAS:
Automatic Grammatical Analysis of Protuguese in
a Constraint Grammar Framework. Ph.D. thesis,
Arhus University, Arhus.
Eckhard Bick. 2003. Multi-level ner for portuguese in
a cg framework. In Nuno J. et al Mamede, editor,
Computational Processing of the Portuguese Lan-
guage (Procedings of the 6th International Work-
shop, PROPOR 2003), number 2721 in Lecture
Notes in Computer Science, pages 118?125, Faro,
Portugal. Springer.
Razvan Bunescu. 2003. Associative anaphora reso-
lution: A web-based approach. In Proceedings of
the Workshop on The Computational Treatment of
Anaphora - EACL 2003, Budapest.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press, Cambridge,
MA.
Caroline Gasperin and Renata Vieira. 2004. Us-
ing word similarity lists for resolving indirect
anaphora. In Proceedings of ACL Workshop on Ref-
erence Resolution and its Applications, pages 40?
46, Barcelona.
Katja Markert and Malvina Nissim. 2005. Comparing
knowledge sources for nominal anaphora resolution.
Computational Linguistics, 31(3):367?401.
Massimo Poesio, Renata Vieira, and Simone Teufel.
1997. Resolving bridging descriptions in un-
restricted texts. In Proceedings of the Work-
shop on Operational Factors In Practical, Robust,
Anaphora Resolution for Unrestricted Texts, pages
1?6, Madrid.
Masimo Poesio, Ishikawa Tomonori, Sabine Shulte im
Walde, and Renata Vieira. 2002. Acquiring lexical
knowledge for anaphora resolution. In Proceedings
of 3rd Language resources and evaluation confer-
ence LREC 2002, Las Palmas.
Eleanor Rosch. 1978. Principles of categorization.
In E. Rosch and B. Lloyd, editors, Cognition and
Categorization, pages 27?48. Hillsdale, New Jersey:
Lawrence Erlbaum Associate.
Sabine Schulte im Walde. 1997. Resolving Bridging
Descriptions in High-Dimensional Space Resolving
Bridging Descriptions in High-Dimensional Space.
Ph.D. thesis, Institut fu?r Maschinelle Sprachverar-
beitung, Universita?t Stuttgart, and Center for Cogni-
tive Science, University of Edinburgh, Edinburgh.
79
TextGraphs-2: Graph-Based Algorithms for Natural Language Processing, pages 17?24,
Rochester, April 2007 c?2007 Association for Computational Linguistics
Extractive Automatic Summarization: Does more linguistic knowledge 
make a difference? 
 
Daniel S. Leite1, Lucia H. M. Rino1, Thiago A. S. Pardo2, Maria das Gra?as V. Nunes2 
N?cleo Interinstitucional de Ling??stica Computacional (NILC) 
http://www.nilc.icmc.usp.br 
1Departamento de Computa??o, UFSCar  
CP 676, 13565-905 S?o Carlos - SP, Brazil 
2Instituto de Ci?ncias Matem?ticas e de Computa??o, Universidade de S?o Paulo 
CP 668, 13560-970 S?o Carlos - SP, Brazil 
{daniel_leite; lucia}@dc.ufscar.br , {taspardo,gracan}@icmc.usp.br 
 
 
Abstract 
In this article we address the usefulness of 
linguistic-independent methods in extrac-
tive Automatic Summarization, arguing 
that linguistic knowledge is not only useful, 
but may be necessary to improve the in-
formativeness of automatic extracts. An as-
sessment of four diverse AS methods on 
Brazilian Portuguese texts is presented to 
support our claim. One of them is Mihal-
cea?s TextRank; other two are modified 
versions of the former through the inclusion 
of varied linguistic features. Finally, the 
fourth method employs machine learning 
techniques, tackling more profound and 
language-dependent knowledge. 
1 Introduction 
Usually, automatic summarization involves produc-
ing a condensed version of a source text through 
selecting or generalizing its relevant content. As a 
result, either an extract or an abstract will be pro-
duced. An extract is produced by copying text seg-
ments and pasting them into the final text preserving 
the original order. An abstract instead is produced 
by selecting and restructuring information from the 
source text. The resulting structure is thus linguisti-
cally realized independently of the surface choices 
of the source text. This comprises, thus, a rewriting 
task. 
This article focuses solely on extracts of source 
texts written in Brazilian Portuguese. For extrac-
tive Automatic Summarization (AS), several meth-
ods have been suggested that are based upon 
statistics or data readily available in the source 
text. Word frequency (Luhn, 1958) and sentence 
position (Edmundson, 1969) methods are classic 
examples of that. Usually, extractive AS does not 
take into account linguistic and semantic knowl-
edge in order to be portable to distinct domains or 
languages (Mihalcea, 2005). Graph-based methods 
aim at the same and have been gaining a lot of in-
terest because they usually do not rely on any lin-
guistic resource and run pretty fast. Exemplars of 
those are LexRank (Erkan and Radev, 2004) and 
TextRank (Mihalcea and Tarau, 2004). In spite of 
their potentialities, we claim that there is a com-
promise in pursuing a language-free setting: how-
ever portable a system may be, it may also produce 
extracts that lack the degree of informativeness 
needed for use. Informativeness, in the current 
context, refers to the ability of an automatic sum-
marizer to produce summaries that convey most 
information of reference, or ideal, summaries. Our 
assessment thus aimed at verifying if parsimonious 
use of linguistic knowledge could improve extrac-
tive AS. 
We argue that the lack of linguistic knowledge 
in extractive AS can be the reason for weak per-
formance regarding informativeness. This argu-
ment follows from acknowledging that 
improvements on the scores usually obtained in 
that field have not been expressive lately. The most 
common metrics used to date, precision and recall, 
signal average results, suggesting that it is not 
enough to pursue completely language-free sys-
tems, no matter the current demands for portability 
in the global communication scenario. We focus 
here on TextRank, which can be used for summa-
17
rizing Brazilian Portuguese texts due to its lan-
guage independence. To show that linguistic 
knowledge does make a difference in extractive 
AS, we compared four automatic summarizers: 
TextRank itself, two other modified versions of 
that, and SuPor-2 (Leite and Rino, 2006). 
TextRank works in a completely unsupervised 
way. Our two variations, although still 
unsupervised, include diverse linguistic knowledge 
in the preprocessing phase. SuPor-2 is the only 
machine learning-based system amongst the four 
ones, and it was built to summarize texts in 
Brazilian Portuguese, although it may be 
customized to other languages. Unlike the others, it 
embeds more sophisticated decision features that 
rely on varied linguistic resources. Some of them 
correspond to full summarization methods by 
themselves: Lexical Chaining (Barzilay and 
Elhadad, 1997), Relationship Mapping (Salton et 
al., 1997), and Importance of Topics (Larocca Neto 
et al, 2000). This is its unique and distinguishing 
characteristic.   
In what follows we first review the different lev-
els of processing in extractive AS (Section 2), then 
we describe TextRank and its implementation to 
summarize Brazilian Portuguese texts (Section 3). 
Our suggested modifications of TextRank are pre-
sented in Section 4, whilst SuPor-2 is described in 
Section 5. Finally, we compare the results of the 
four automatic summarizers when running on Bra-
zilian Portuguese texts (Section 6), and make some 
remarks on linguistic independence for extractive 
AS in Section 7. 
2 A Review of Automatic Summarization 
Mani (2001) classifies AS methods based upon 
three levels of linguistic processing to summarize a 
text, namely: 
 
? Shallow level. At this level only features at the 
surface of the text are explored. For example, 
location (Edmunson, 1969), sentence length 
and presence of signaling phrases (e.g., Kupiec 
et al, 1995). Combined, such features may 
yield a salience function that drives selection 
of sentences of the source text to include in a 
summary. 
 ? Entity level. The aim here is to build an inter-
nal representation of the source text that con-
veys its entities and corresponding 
relationships. These amount to the information 
that allows identifying important text seg-
ments. Examples of such relations are word 
cooccurrence (e.g., Salton et al, 1997), syno-
nyms and antonyms (e.g., Barzilay and Elha-
dad, 1997), logical relations, such as 
concordance or contradiction, and syntactic 
relations. 
 ? Discourse level. At this level the whole struc-
ture of the source text is modeled, provided 
that its communicative goals can be grasped 
from the source text. The discourse structure is 
intended to help retrieving, e.g., the main top-
ics of the document (e.g, Barzilay and Elha-
dad, 1997; Larocca Neto et al, 2000) or its 
rhetorical structure (e.g., Marcu, 1999), in or-
der to provide the means for AS. 
 
In this work we mainly focus on the entity level. 
Special entities and their relations thus provide the 
means to identify important sentences for building 
an extract. In turn, there is a loss of independence 
from linguistic knowledge, when compared to shal-
lower approaches. Actually, apart from TextRank, 
the other systems described in this paper target en-
tity level methods, as we shall see shortly.  
3 The TextRank Method 
The unsupervised TextRank method (Mihalcea and 
Tarau, 2004) takes after Google?s PageRank (Brin 
and Page, 1998), a graph-based system that helps 
judge the relevance of a webpage through incoming 
and outgoing links. PageRank directed graphs repre-
sent webpages as nodes and their linking to other 
webpages as edges. A random walk model is thus 
applied to build a path between the nodes, in order 
to grade the importance of a webpage in the graph. 
Similarly to grading webpages through travers-
ing a graph, TextRank attempts to weight sentences 
of a text by building an undirected graph. Nodes are 
now sentences, and edges express their similarity 
degrees to other sentences in the text. Actually, the 
degree of similarity is based upon content overlap. 
As such, similarity degrees help assess the overall 
cohesive structure of a text. The more content over-
lap a sentence has with other sentences, the more 
important it is and more likely it is to be included in 
the extract.. Similarity is calculated through equa-
tion [1] (Mihalcea and Tarau, 2004), where Si and Sj 
are sentences and wk is a common token between 
18
them. The numerator is the sum of common words 
between Si and Sj. To reduce bias, normalization of 
the involved sentences length takes place, as shows 
the denominator. 
 
|)log(||)log(|
|}|{|),(
ji
jkikk
ji SS
SwSwwSSSim +
???=  [1] 
 
Once the graph and all similarity degrees are 
produced, sentence importance is calculated by the 
random walk algorithm shown in equation [2]. 
TR(Vi) signals sentence importance, d is an arbitrary 
parameter in the interval [0,1], and N is the number 
of sentences in the text. Parameter d integrates the 
probability of jumping from one vertex to another 
randomly chosen. Thus, it is responsible for random 
walking. This parameter is normally set to 0.85 (this 
value is also used in TextRank). 
 
? ?
-
= -
=
??
??
?
?
??
??
?
?
??+-=
1
0
1
0
),(
),()()1()(
N
j
N
k
kj
ji
ji
SSSim
SSSimVTRddVTR  [2] 
 
Initial TR similarity values are randomly set in 
the [0,1] interval. After successive calculations, 
those values converge to the targeted importance 
value. After calculating the importance of the verti-
ces, the sentences are sorted in reverse order and the 
top ones are selected to compose the extract. As 
usual, the number of sentences of the extract is de-
pendent upon a given compression rate. 
  Clearly, TextRank is not language dependent. 
For this reason Mihalcea (2005) could use it to 
evaluate AS on texts in Brazilian Portuguese, be-
sides reporting results on texts in English. She also 
explored distinct means of representing a text with-
out considering linguistic knowledge, emphasizing 
TextRank language and domain independence. She 
varies, e.g., the ways the graphs could be traversed 
using both directed and undirected graphs. Once a 
sentence is chosen to compose an extract, having 
undirected graphs makes possible, to look forward ? 
from the sentence to its outgoing edges (i.e., focus-
ing on the set of its following sentences in the text) 
? or to look backward, considering that sentence 
incoming edges and, thus, the set of its preceding 
sentences in the text. 
Another variation proposed by Mihalcea is to 
replace the PageRank algorithm (Equation [2]) by 
HITS (Kleinberg, 1999). This works quite simi-
larly to PageRank. However, instead of aggregat-
ing the scores for both incoming and outgoing 
links of a node in just one final score, it produces 
two independent scores. These are correspondingly 
named ?authority? and ?hub? scores. 
4 Improving TextRank through varia-
tions on linguistic information 
To improve the similarity scores between sen-
tences in TextRank we fed it with more linguistic 
knowledge, yielding its two modified versions. The 
first variation focused just upon basic preprocess-
ing; the second one, on the use of a thesaurus to 
calculate semantic similarity to promote AS deci-
sions. However, we did not modify the main ex-
tractive algorithm of TextRank: we kept the graph 
undirected and used PageRank as the score deter-
miner. Actually, we modified only the method of 
computing the edges weights. 
4.1 Using Basic Preprocessing Methods 
In applying Equation 1 for similarity scores, only 
exact matches between two words are allowed. 
Since in Brazilian Portuguese there are many mor-
phological and inflexional endings for most words, 
this process becomes troublesome: important 
matches may be ignored. To overcome that, we used 
a stemmer for Brazilian Portuguese (Caldas Jr. et 
al., 2001) based upon Porter?s algorithm (1980). We 
also removed stopwords from the source text, be-
cause they are not useful in determining similarity. 
The resulting version of TextRank is named hereaf-
ter ?TextRank+Stem+StopwordsRem?. 
4.2 Using a Thesaurus 
Our second TextRank variation involved plugging 
into the system a Brazilian Portuguese thesaurus 
(Dias-da-Silva et al, 2003). Our hypothesis here is 
that semantic similarity of the involved words is 
also important to improve the informativeness of 
the extracts under production. Thus, an extractive 
summarizer should consider not only word repeti-
tion in the source text, but also synonymy and an-
tonymy.  
Although plugging the thesaurus into the 
automatic summarizer did not imply changing its 
main method of calculating similarity, there were 
some obstacles to overcome concerning the follow-
ing:  
19
 
 
 
 
 
 Figure 1. SuPor-2 training phase 
 
  
Figure 2. SuPor-2 extraction phase 
 
a) Should we consider only synonyms or both 
synonyms and antonyms in addition to term 
repetition (reiteration)? 
 
b) How to acknowledge, and disentangle, se-
mantic similarity, when polissemy, for ex-
ample, is present? 
 
c) Once the proper relations have been 
determined, how should they be weighted? 
Just considering all thesaural relations to be 
equally important might not be the best ap-
proach. 
Concerning (a), synonyms, antonyms, and term 
repetition were all considered, as suggested by oth-
ers (e.g., Barzilay and Elhadad, 1997). We did not 
tackle (b) to choose the right sense of a word be-
cause of the lack of an effective disambiguation 
procedure for Brazilian Portuguese. Finally, in 
tackling (c) and, thus, grading the importance of 
the relations for sentence similarity, we adopted 
the same weights proposed by Barzilay and Elha-
dad (1997) in their lexical chaining method, which 
is discussed in more detail below. For both reitera-
tion and synonymy, they assume a score of 10 for 
the considered lexical chain; for antonymy, they 
suggest a score of 7. The resulting version of Tex-
tRank is named here ?TextRank+Thesaurus?. 
5 The SuPor-2 System 
SuPor-2 is an extractive summarizer built from 
scratch for Brazilian Portuguese. It embeds differ-
ent features in order to identify and extract relevant 
sentences of a source text. To configure SuPor-2 
for an adequate combination of such features we 
employ a machine learning approach. Figures 1 
and 2 depict the training and extraction phases, 
respectively. 
For training, machine learning is carried out by a 
Na?ve-Bayes classifier that employs Kernel meth-
ods for numeric feature handling, known as Flexi-
ble Bayes (John and Langley, 1995). This 
environment is provided by WEKA1 (Witten and 
Frank, 2005), which is used within SuPor-2 itself. 
The training corpus comprises both source texts 
and corresponding reference extracts. Every sen-
tence from a source text is represented in the train-
                                                        
1 Waikato Environment for Knowledge Analysis. Available at 
http://www.cs.waikato.ac.nz/ml/weka/ (December, 2006) 
20
ing dataset as a tuple of the considered features. 
Each tuple is labeled with its class, which signals if 
the sentence appears in a reference extract. The 
class label will be true if the sentence under focus 
matches a sentence of the reference extract and 
false otherwise. 
Once produced, the training dataset is used by 
the Bayesian classifier to depict the sentences that 
are candidates to compose the extract (Figure 2). In 
other words, the probability for the ?true? class is 
computed and the top-ranked sentences are se-
lected, until reaching the intended compression 
rate. 
When computing features, three full methods 
(M) and four corpus-based parameters (P) are con-
sidered. Both methods and parameters are mapped 
onto the feature space and are defined as follows: 
 
(M) Lexical Chaining (Barzilay and Elhadad, 
1997). This method computes the connectedness 
between words aiming at determining lexical 
chains in the source text. The stronger a lexical 
chain, the more important it is considered for ex-
traction. Both an ontological resource and Word-
Net (Miller et al, 1990) are used to identify 
different relations, such as synonymy or antonym, 
hypernymy or hyponymy, that intervene to com-
pute connectedness. The lexical chains are then 
used to produce three sets of sentences. To identify 
and extract sentences from those sets, three heuris-
tics are  made available, namely: (H1) selecting 
every sentence s of the source text based on each 
member m of every strong lexical chain of the text. 
In this case, s is the sentence that contains the first 
occurrence of m; (H2) this heuristics is similar to 
the former one, but instead of considering all the 
members of a strong lexical chain, it uses only the 
representative ones. A representative member is 
one whose frequency is greater than the average 
frequency of all words in the chain; (H3) a sen-
tence s is chosen by focusing only on representa-
tive lexical chains of every topic of the source text. 
In SuPor-2, the mapping of this method onto a 
nominal feature is accomplished by signaling 
which heuristics have recommended the sentence. 
Thus, features in the domain may range over the 
values {?None?, ?H1?, ?H2?, ?H3?, ?H1H2?, 
?H1H3?, ?H2H3?, ?H1H2H3?}. 
 
(M) Relationship Mapping (Salton et al, 
1997). This method performs similarly to the pre-
vious one and also to TextRank in that it builds up 
a graph interconnecting text segments. However, it 
considers paragraphs instead of sentences as verti-
ces. Hence, graph edges signal the connectiveness 
of the paragraphs of the source text. Similarity 
scores between two paragraphs are thus related to 
the degree of connectivity of the nodes. Similarly 
to Lexical Chaining, Salton et al also suggest three 
different ways of producing extracts. However, 
they now depend on the way the graph is traversed. 
The so-called dense or bushy path (P1), deep path 
(P2), and segmented path (P3) aim at tackling dis-
tinct textual problems that may damage the quality 
of the resulting extracts. The dense path considers 
that paragraphs are totally independent from each 
other, focusing on the top-ranked ones (i.e., the 
ones that are denser). As a result, it does not guar-
antee that an extract will be cohesive. The deep 
path is intended to overcome the former problem 
by choosing paragraphs that may be semantically 
inter-related. Its drawback is that only one topic, 
even one that is irrelevant, may be conveyed in the 
extract. Thus, it may lack proper coverage of the 
source text. Finally, the segmented path aims at 
overcoming the limitations of the former ones, ad-
dressing all the topics at once. Similarly to Lexical 
Chaining, features in the Relationship method 
range over the set {?None?,?P1?,?P2?,?P3?, ?P1P2?, 
?P1P3?, ?P2P3?, ?P1P2P3?}. 
 
(M) Importance of Topics (Larocca Neto et 
al., 2000). This method also aims at identifying the 
main topics of the source text, however through the 
TextTiling algorithm (Hearst, 1993). Once the top-
ics of the source text have been determined, the 
first step is to select sentences that better express 
the importance of each topic. The amount of sen-
tences, in this case, is proportional to the topic im-
portance. The second step is to determine the 
sentences that will actually be included in the ex-
tract. This is carried out by measuring their simi-
larity to their respective topic centroids (Larocca 
Neto et al, 2000). The method thus signals how 
relevant a sentence is to a given topic. In SuPor-2 
this method yields a numeric feature whose value 
conveys the harmonic mean between the sentence 
similarity to the centroid of the topic in which it 
appears and the importance of that topic.  
(P) Sentence Length (Kupiec et al, 1995). 
This parameter just signals the normalized count of 
words of a sentence. 
21
(P) Sentence Location (Edmundson, 1969). 
This parameter takes into account the position of a 
sentence in the text. It is valued, thus, in 
{?II?,?IM?,?IF?,?MI?,?MM?,?MF?,?FI?,?FM?,?FF?}. 
In this set the first letter of each label signals the 
position of the sentence within a paragraph (Initial, 
Medium, or Final). Similarly, the second letter sig-
nals the position of the paragraph within the text. 
(P) Occurrence of proper nouns (e.g., Kupiec 
et al, 1995). This parameter accounts for the num-
ber of proper nouns in a sentence.  
(P) Word Frequency (Luhn, 1958). This pa-
rameter mirrors the normalized sum of the word 
frequency in a sentence. 
SuPor-2 provides a flexible way of combining 
linguistic and non-linguistic features for extraction. 
There are profound differences from TextRank. 
First, it is clearly language-dependent. Also, its 
graph-based methods do not assign weights to their 
vertices in order to select sentences for extraction. 
Instead, they traverse a graph in very specific  and 
varied ways that mirror both linguistic interde-
pendencies and important connections between the 
nodes. 
6 Assessing the Four Systems 
To assess the degree of informativeness of the sys-
tems previously described, we adopt ROUGE2 (Lin 
and Hovy, 2003), whose recall rate mirrors the in-
formativeness degree of automatically generated 
extracts by correlating automatic summaries with 
ideal ones. 
The two modified versions of TextRank require 
linguistic knowledge but at a low cost. This is cer-
tainly due to varying only preprocessing, while the 
main decision procedure is kept unchanged and 
language-independent. Those three systems do not 
need training, one of the main arguments in favor 
of TextRank (Mihalcea and Tarau, 2004). In con-
trast, SuPor-2 relies on training and this is certainly 
one of its main bottlenecks. It also employs lin-
guistic knowledge for both preprocessing and ex-
traction, which TextRank purposefully avoids. 
However, using WEKA has made its adjustments 
less demanding and more consistent, indicating 
that scaling up the system is feasible.  
                                                        
2 Recall-Oriented Understudy for Gisting Evaluation. Avail-
able at http://haydn.isi.edu/ROUGE/ (January, 2007). 
In our assessment, the same single-document 
summarization scenario posed by Mihalcea (2005) 
was adopted, namely: (a) we considered the Brazil-
ian Portuguese TeM?rio corpus (Pardo and Rino, 
2003); (b) we used the same baseline, which se-
lects top-first sentences to include in the extract; 
(c) we adopted a 70-75% compression rate, making 
it compatible with the compression rate of the ref-
erence summaries; and (d) ROUGE was used for 
evaluation in its Ngram(1,1) 95% confidence rate 
setting, without stopwords removal. TeM?rio com-
prises 100 newspaper articles from online Brazilian 
newswire. A set of corresponding manual summa-
ries produced by an expert in Brazilian Portuguese 
is also included in TeM?rio. These are our refer-
ence summaries. 
For training and testing SuPor-2, we avoided 
building an additional training corpus by using a 
10-fold cross-validation procedure. Finally, we 
produced three sets of extracts using ?TextRank +  
Stem + StopwordsRem?, ?TextRank + Thesaurus?, 
and SuPor-2 on the TeM?rio source texts. Results 
for informativeness are shown in Table 1. Since 
Mihalcea?s setting was kept unchanged, we just 
included in that table the same results presented in 
(Mihalcea, 2005), i.e., we did not run her systems 
all over again. We also reproduced for comparison 
the TextRank variations reported by Mihalcea, es-
pecially regarding graph-based walks by PageRank 
and HITS. Shaded lines correspond to our sug-
gested methods presented in Sections 4 and 5, 
which involve differing degrees of dependence on 
linguistic knowledge. 
It can be seen that ?TextRank+Thesaurus? and 
?TextRank+Stem+StopwordsRem? considerably 
outperformed all other versions of TextRank. 
Compared with Mihalcea's best version, i.e., with 
'TextRank (PageRank - backward)', those two 
methods represented a 6% and 9% improvement, 
respectively. We can conclude that neither the way 
the graph is built nor the choice of the graph-based 
ranking algorithm affects the results as signifi-
cantly as do the linguistic-based methods. Clearly, 
both variations proposed in this paper signal that 
linguistic knowledge, even if only used at the pre-
processing stage, provides more informative ex-
tracts than those produced when no linguistic 
knowledge at all is considered. Moreover, at that 
stage little modeling and computational effort is 
demanded, since lexicons, stoplists, and thesauri 
22
are quite widely available nowadays for several 
Romance languages. 
Even the baseline outperformed most versions 
of TextRank, showing that linguistic independence 
in a random walk model for extractive AS should 
be reconsidered. Actually, this shows that linguis-
tic knowledge does make a difference, at least for 
summarizing newswire texts in Brazilian Portu-
guese. 
In addition, SuPor-2 performance exceeds the 
best version of TextRank that uses no linguistic 
knowledge ? ?TextRank (PageRank - backward)? ? 
by about 14%. 
 
 
System ROUGE NGram(1,1) 
SuPor-2 0,5839 
TextRank+Thesaurus 0,5603 
TextRank+Stem+StopwordsRem 0,5426 
TextRank (PageRank - backward) 0,5121 
TextRank (HIT hub - forward) 0,5002 
TextRank (HITS authority - backward) 0,5002 
Baseline 0,4963 
TextRank (PageRank - undirected) 0,4939 
TextRank (HITS authority - forward) 0,4834 
TextRank (HIT hub - backward) 0,4834 
TextRank (HITS authority - undirected) 0,4814 
TextRank (HIT hub - undirected) 0,4814 
TextRank (PageRank - forward) 0,4574 
 
Table 1. Informativeness comparison between ex-
tractive summarizers 
7 Final Remarks 
A critical issue in the comparison presented above 
is the contrast between having an unsupervised or 
supervised summarizer, which is related to the is-
sue on having linguistic-independent extractive 
summarizers. Perhaps the question that we should 
pose here is how interesting and useful an extrac-
tive automatic summarizer that is totally independ-
ent from linguistic knowledge can actually be. To 
our view, the more non-informative an extract, the 
less useful it may be. So, summarizers that do not 
reach a minimum threshold concerning informa-
tiveness are deemed to failure nowadays. Clearly, 
SuPor-2 requires language-dependent resources, 
but its main extraction procedure is still general 
enough to make it portable and adaptable to new 
domains and languages. Hence, SuPor-2 assess-
ment suggests that it may be interesting to scale up 
SuPor-2. 
Considering that SuPor-2 is one of the best ex-
tractive summarizers for Brazilian Portuguese texts 
(Leite and Rino, 2006) and ?TextRank+Thesaurus? 
performed only 4% below it, we can also argue  in 
favor of providing even simple linguistic proce-
dures for extractive AS. The latter system shows 
that TextRank can yield extracts nearly as informa-
tive as those produced by the former, when em-
bedding stemming and stopwords removal. It can 
also perform AS with little computational effort 
and no training, when compared to the supervised 
SuPor-2. As a conclusion, we see that some lin-
guistic knowledge may boost TextRank perform-
ance without too much effort, since language-
dependent resources for preprocessing texts in 
natural language are usually available and easy to 
handle, concerning our addressed approach. 
There are many experiments that may be derived 
from our discussion in this paper (1) Although the 
reported results suggest that linguistic knowledge 
does make a difference when embedded in lan-
guage-free extractive summarizers, the perform-
ance of the top systems assessed through ROUGE 
should be more comprehensively licensed through 
additional assessment tasks. (2) These could also 
incorporate other graph-based algorithms than 
TextRank, such as the LexRank one, aiming at re-
assuring our claim and scaling up graph-based ap-
proaches. (3) Since we addressed language-
independence (thus portability) versus language-
dependence for informativeness, it would also be 
interesting to explore other domains or languages 
to support our claim or, at least, to look for other 
findings to confirm if linguistic knowledge indeed 
makes a difference. (4) Other TextRank variations 
could also be explored, to see if adding more fea-
tures would make TextRank closer to SuPor-2. 
Acknowledgements 
This work has been supported by the Brazilian re-
search funding agencies CNPq, CAPES and 
FAPESP.
23
References 
B. C. Dias-da-Silva, M. F. Oliveira, H. R. Moraes, C. 
Paschoalino, R. Hasegawa, D. Amorin and A. C. 
Nascimento. 2000. Constru??o de um Thesaurus Ele-
tr?nico para o Portugu?s do Brasil. In Proceedings of 
the V Encontro para o Processamento Computacio-
nal da L?ngua Portuguesa Escrita e Falada 
(PROPOR 2000), S?o Carlos, Brasil , 1-11. 
C. Lin and E. H. Hovy. 2003. Automatic Evaluation of 
Summaries Using N-gram Co-occurrence Statistics. 
In Proceedings of Language Technology Conference 
(HLT-NAACL 2003), Edmonton, Canada.  
D. Marcu. 1999. Discourse Trees Are Good Indicators 
of Importance in Text. In Mani, I., Maybury, M. T. 
(Eds.). 1999. Advances in Automatic Text Summari-
zation. MIT Press. 
D. S. Leite and L. H. M. Rino. 2006. Selecting a Feature 
Set to Summarize Texts in Brazilian Portuguese. In J. 
S. Sichman et al (eds.): Proceedings of 18th. Brazil-
ian Symposium on Artificial Intelligence (SBIA'06) 
and 10th. Ibero-American Artificial Intelligence Con-
ference (IBERAMIA'06). Lecture Notes on Artificial 
Intelligence, No. 4140, Springer-Verlag, 462-471. 
G. Erkan and D R. Radev. 2004. LexRank: Graph-based 
Lexical Centrality as Salience in Text Summariza-
tion. Journal of Artificial Intelligence Research 
22:457-479 
G. A. Miller, R. Beckwith, C. Fellbaum, D. Gross and 
K. Miller. 1990. Introduction to WordNet: An On-
line Lexical Database. International Journal of Lexi-
cography 3(4):235-244 
G. Salton, and C. Buckley. 1988. Term-weighting ap-
proaches in automatic text retrieval. Information 
Processing & Management 24 : 513-523.. Reprinted 
in: K. Sparck-Jones and P. Willet (eds.). 1997. Read-
ings in Information Retrieval, Morgan Kaufmann, 
323-328.  
H. Luhn. 1958. The automatic creation of literature ab-
stracts. IBM Journal of Research and Development 
2:159-165 
H. P. Edmundson. 1969. New methods in automatic 
extracting. Journal of the Association for Computing 
Machinery 16:264-285. 
I. Witten and E. Frank. 2005. Data Mining: Practical 
machine learning tools and techniques, 2nd ed. Mor-
gan Kaufmann, San Francisco. 
I. Mani. 2001. Automatic Summarization. John Benja-
min?s Publishing Company.  
I. Mani and M. T. Maybury. 1999. Advances in Auto-
matic Text Summarization. MIT Press. 
J. Caldas Junior, C. Y. M. Imamura and S. O. Rezende. 
Avalia??o de um Algoritmo de Stemming para a 
L?ngua Portuguesa. In Proceedings of the 2nd Con-
gress of Logic Applied to Technology 
(LABTEC?2001), vol. II. Faculdade SENAC de Ci?n-
cias Exatas e Tecnologia, S?o Paulo, Brasil (2001), 
267-274. 
J. M. Kleinberg. 1999. Authoritative sources in hyper-
linked environment. Journal of the ACM, 46(5):604-
632. 
J. Kupiec, J. Pedersen and F. Chen. 1995. A trainable 
document summarizer. In Proceedings of the 18th 
ACM-SIGIR Conference on Research & Develop-
ment in Information Retrieval, 68-73. 
J. Larocca Neto, A. D. Santos, C. A. A. Kaestner and A. 
A. Freitas. 2000. Generating Text Summaries 
through the Relative Importance of Topics. Lecture 
Notes in Artificial Intelligence, No. 1952. Springer-
Verlag, 200-309 
M. A. Hearst. 1993. TextTiling: A Quantitative Ap-
proach to Discourse Segmentation. Technical Report 
93/24. University of California, Berkeley. 
M. F. Porter. 1980. An Algorithm for Suffix Stripping. 
Program, 14 (3) : 130-137 
R. Mihalcea and P. Tarau. 2004. TextRank: Bringing 
Order into Texts. In  Proceedings of the Conference 
on Empirical Methods in Natural Language Process-
ing (EMNLP 2004), Barcelona, Spain, July.  
R. Mihalcea. 2005. Language Independent Extractive 
Summarization. In Proceedings of the 43th Annual 
Meeting of the Association for Computational Lin-
guistics, Companion Volume (ACL2005), Ann Ar-
bor, MI, June. 
R. Barzilay and M. Elhadad. 1997. Using lexical chains 
for text summarization. In Proceedings of the Intelli-
gent Scalable Text Summarization Workshop 
(ISTS'97), ACL, Madrid, Spain.  
S. Brin and L. Page. 1998. The anatomy of a large-scale 
hypertextual Web search engine. Computer Networks 
and ISDN Systems 30:1-7. 
T. A. S. Pardo and L.H.M. Rino. 2003. TeM?rio: A cor-
pus for automatic text summarization (in Portu-
guese). NILC Tech. Report NILC-TR-03-09  
24
An interlingua aiming at communication on the Web: 
How language-independent can it be? 
Ronaldo Teixeira Martins 
ronaIdo @nilc.icmsc.sc.usp.br 
Lucia Helena Machado Rino 
Iucia @ dc. uf scar.br 
Maria das Graqas Volpe Nunes 
md gvnune @ icmc.sc, usp.br 
Gisele Montilha 
gisele @nilc. icmsc, sc. usp. br 
Osvaldo Novais de Oliveira Jr. 
chu@if.sc.usp.br 
Ndcleo Interinstitucional de Lingiiistica Computacional (NILC/Sio Carlos) 
http://nilc.icmsc.sc.usp.br 
CP 668 - ICMC-USP, 13560-970 Silo Carlos, SP, Brazil 
Abstract 
In this paper, we describe the Universal Networking Language, an interlingua 
to be plugged in a Web environment aiming at allowing for many-to-many 
information exchange, 'many' here referring to many natural anguages. The 
interlingua is embedded in a Knowledge-Base MT system whose language- 
dependent modules comprise an encoder, a decoder, and linguistic resources 
that have been developed by native speakers of each language involved in the 
project. Issues concerning both the interlingua formalism and its foundational 
issues are discussed. 
1. Introduction 
The widespread use of the Web and the 
growing Intemet facilities have sparked 
enormous interest in improving the ways 
people use to communicate. In this context 
multilingual Machine Translation systems 
become prominent, for they allow for a huge 
information flow. To date, MT systems have 
been built under limited conditions, of which 
we highlight two: i) in general, they mirror 
one-to-many(languages) or many(languages)- 
to-one approaches, often involving English at 
the "one" end; ii) communication is reduced 
to basic information exchange, ignoring 
richness and flexibility implied by human 
mind. The first limitation has been seldom 
overcome, since it requires a robust 
environment and research teams that can 
cope with knowledge of several anguages 1, 
to derive precise automatic language 
analyzers and synthesizers. The second 
limitation follows up the first: adding up 
communicative issues to linguistic 
processing/modeling makes still harder to 
overcome MT limitations. 
In this article, we elaborate on work using 
an interlingua conceived to overcome the first 
limitation, i.e., to allow for a many-to-many 
information exchange environment, which 
shall be plugged in a nontraditional Internet 
platform. The goal is to allow interlocutors to 
entangle communication even if they do not 
share the same mother tongue or the English 
Standing, most often, for natural language, or NL. 
24 
language, unlike MT systems that have just 
one language at one of their edges. As the 
main component of a Knowledge-Base MT 
system (hereafter, KBMT), the interlingua 
approach has been developed under the 
Universal Networking Language Project, or 
simply UNL Project. What makes the 
interlingua UNL special is its intended use: 
as an electronic language for networks, it has 
to allow for high quality 2 conversation 
systems involving many languages. As the 
main component of a KBMT system, it has to 
be sufficiently robust o ground research and 
development (R&D) of the language-specific 
modules to be attached to the system. It is 
this latter perspective that is undertaken here: 
from the viewpoint of R&D, we discuss how 
broad, or language-independent, he 
interlingua UNL is, especially focusing on its 
syntax and coverage. In addition to being 
consistent and complete to represent 
meaning, we also consider its sharing by 
researchers all around the world, which is an 
important bottleneck of the UNL Project, 
since information exchange by researchers 
during R&D brings about the problems 
introduced by the interlingua UNL itself, 
concerning both its formalism and 
foundational issues. Before discussing this 
topic in Section 5, we present an overview of 
the UNL Project (Section 2) and describe the 
main features of the interlingua UNL 
(Section 3). In Section 4, we describe the 
UNL system architecture. Hereafter, 
'interlingua UNL' will be simply referred to 
as UNL, the acronym for Universal 
Networking Language. Also, the viewpoint 
presented here is that of interlingua users 
who experience R&D for a given NL, and not 
of its authors. 
2. The UNL Project 
The UNL Project 3 has been launched by 
the United Nations University to foster and 
ease international web communication by 
means of NLP systems. Its main strength lies 
on the development of the UNL, as a unique 
semantic (or meaning) representation that can 
be interchanged with the various languages to 
be integrated in the KBMT system. In the 
UNL Project, plug-in software to encode NL 
texts onto UNL ones (NL-UNL encoders) 
and to decode UNL into NL texts (UNL-NL 
decoders) have been developed by R&D 
groups in their own native languages. The 
modules to process Brazilian Portuguese 4, for 
example, have been developed by a team of 
Portuguese native speakers that comprises 
linguists, computational linguists, and 
computer experts. Such packages will be 
made available in WWW servers and will be 
accessible by browsing through Internet, thus 
overcoming the need for people all around 
the world tO learn the language of their 
interlocutors. Several inguistic groups have 
signed to the. Project, namely: the Indo- 
European (Portuguese, Spanish, French, 
Italian, English, German, Russian, Latvian 
and Hindi), the Semitic (Arabic), the Sino- 
Tibetan (Chinese), the Ural-Altaic 
(Mongolian), the Malayan-Polynesian 
(Indonesian), and the Japanese. 
On the one hand, the main strength of 
the Project is that knowledgeable specialists 
address language-dependent issues of their 
mother tongue, most of which are related to 
R&D of the encoding and decoding modules 
and to the specification of the NL-UNL 
lexicon. On the other hand, this also 
represents a crucial problem faced by the 
project participants, for distinct groups may 
interpret the interlingua specification 
differently. There is thus the need for a 
consensus about the UNL formalism, 
2 By 'high quality' we mean 'at least allowing for 
readability and understandability by any user'. 
3 A description of both, the Project and the UNL itself, 
can be found in http://www.unl.ias.unu.edu/. 
4 Hereafter referred to as Portuguese or by its acronym, 
BP. 
25 
bringing about an assessment of its coverage, 
completeness, and consistency, all features 
that will be discussed shortly. 
3. The Universal Networking Language 
The UNL is a formal language designed 
for rendering automatic multilingual 
information exchange. It is intended to be a 
cross-linguistic semantic representation of 
NL sentence meaning, being the core of the 
UNL System, the KBMT system developed 
by H. Uchida (1996) at the Institute of 
Advanced- Studies, United Nations 
University, Tokyo; Japan. 
UNL subsumes a tridimensional theory of 
(sentence) meaning, whose components are 
defined according to one of the following sets 
(Martins et al, 1998a): concepts (e.g., "cat", 
"sit", "on", or "mat"), concept relations (e.g., 
"agent", "place", or "object"), and concept 
predicates (e.g., "past" or "definite"). Such 
components are formally and 
correspondingly represented by three 
different kinds of entities, namely: Universal 
Words (UWs), Relation Labels (RLs), and 
Attribute Labels (ALs). According to the 
UNL syntax, information conveyed by each 
sentence can be represented by a hypergraph 
whose nodes represent UWs and whose arcs 
represent RLs. To make symbol processing 
simpler, hypergraphs are often reduced to 
lists of ordered binary relations between 
concepts, as it is shown in Figure 1 for the 
sentence (1) The cat sat  on the mat. 5 
'sit', 'cat', 'on' and 'mat' are UWs; 'agt' (agent), 
'pie' (place) and 'obj' (object) are RLs; '@def, 
'@entry' and '@past' are ALs. 
Figure la: UNL hypergraph representation f the 
English sentence "The cat sat on the mat" 
agt(sit. @entry. @past,cat. @def) 
plc(sit. @entry. @past,on) 
obj(on,mat. @def) 
Figure lb :  UNL linear representation of the 
English sentence "The cat sat on the mat." 
UWs are labels for concept-like 
information, roughly corresponding to the 
lexical level in the sentence structure. They 
comprise an open large inventory, virtually 
capable of denoting every non-compositional 
meaning to be conveyed by any speaker of 
any language. For the sake of representation, 
these atomic semantic ontents are associated 
to English words and expressions, which play 
the role of semantic labels. However, there is 
no one-to-one mapping between the English 
vocabulary and the UNL lexicon, for UNL, 
as a multilingual representation code, is 
larger than the English vocabulary. To avoid 
unnecessary proliferation of the UNL 
vocabulary and to certify that standards be 
observed by UNL teams, control over the 
specification of the UW set is centered at the 
UNL Center, in Japan. 
Several semantic relationships hold 
between UWs, namely synonymy, antonymy, 
hyponymy, hypemymy and meronymy, 
which compose the UNL Ontology. Steady 
semantic valencies (such as agent and object 
features) can also be represented, forming the 
UNL Knowledge-Base. Both Ontology and 
Knowledge-Base aim at constraining the 
scope of UW labels, whenever ambiguity is 
to be avoided. The. UNL representation f 
sentence (1), for example, can be ambiguous 
26 
in Romance languages, for the translation of 
'cat' should make explicit the animal sex: if 
male, it would be "gato" (Portuguese and 
Spanish), "gatto" (Italian), "chat" (French), 
whereas different names would have to be 
used for the female cat. Instead of having a 
unique UW 'cat', it is thus quite feasible to 
have a whole structure in which 'cat' is only 
the hyper-ordinate option. 
For the English-UNL association ot to 
undermine the intended universality of the 
UW inventory, its semantic-orthograpical 
correspondence has to be considered rather 
incidental, or even. approximated. It is not 
always the case that extensions 6 of a UW 
label and of its corresponding English word 
coincide. The extension of the English word 
"mat", for example, does not exactly coincide 
with the extension of any Portuguese word, 
although we can find many overlaps between 
"mat" and, e.g., "capacho" (Portuguese). 
Portuguese speakers, however, would not say 
"capacho" for the ornamental dishmat, as 
would not English speakers use the word 
"mat" for a fawner (still "capacho" in 
Portuguese). Since each language categorizes 
the world in a very idiosyncratic way, it 
would be misleading to impose a 
straightforward correspondence between 
lexical items of two different languages. In 
UNL, this problem has been overcome by 
proposing a rather analogic lexicon, instead 
of a digital one. Although discrete, UWs 
convey continuous entities, in the sense that 
semantic gaps between concepts are fulfilled 
by the UNL Knowledge-Base, as it is shown 
for the UW 'mat' in Figure 2. Granularity 
thus plays an important role in UNL lexical 
organization and brings flexibility into cross- 
linguistic lexical matching. 
Cf. (Frege, 1892), extension here is used to establish 
the relationship between a word and the world, 
opposed to intension, referring to the relationship 
between aword and its meaning. 
icl 
Figure 2a: UNL hypergraph artial representation for 
the meaning denoted by the English word "mat" 
"mat" 
"mat(aoj>entity)" 
"mat(icl>event)" 
"mat(icl>frame)" 
"mat(icl>rug)" 
"mat(icl>state)" 
"mat(obi>entitv)" 
Figure 2b: UNL partial inear epresentation for 
the meaning denoted by the English word "mat" 
While lexical representation in UNL 
comprises a set of universal concepts 
signaled by UWs, the cross-lexical level 
involves a set of ordered binary relations 
between UWs, which are the Relation Labels 
(RLs). RLs specification are similar to 
Fillmore's semantic ases (1968), with RLs 
corresponding to semantic-value relations 
linking concept-like information. There are 
currently 44 RLs, but this set has been 
continuously modified by empirical evidence 
of lack, or redundancy, of relations. The 
inventory of RLs can be divided into three 
parts, according to the functional aspects of 
the related concepts: ontological, event-like 
and logical relations. Ontological relations 
are used as UW constraints in reducing 
lexical granularity or avoiding ambiguity as 
shown above, and they help positioning UWs 
in a UNL lexical structure. Five different 
labels are used to convey ontological 
relations: icl (hyponymy), equ (synonymy), 
ant (antonymy), pof (meronymy), and fld 
(semantic field). 
2"7 
UNL depicts sentence meaning as a fact 
composed by either a simple or a complex 
event, which is considered here the starting 
point of a UNL representation, i.e., its 
minimal complete semantic unit. Event-like 
relations are assigned by an event external or 
internal structure, or by both. An event 
external structure has to do nearly always 
with time and space boundaries. It can be 
referred to by a set of RLs signaling the event 
co-occurrent meanings, such as 7 its 
environment (scn); starting place (pl0, 
finishing p!ace (pit), or, simply, place (plc); 
range (fmt); starting time (tmf), finishing 
time (tmt), or, simply, time (tim); and 
duration (dur). Action modifiers, such as 
manner (man) and method (met) can also 
qualify this structure. An event internal 
structure is associated to one of the following 
simple frames: action, activity, movement, 
state, and process, each expressing different 
RLs in the event itself, including its actors 
and circumstances. 
Event actors are any animate or inanimate 
character playing any role in events, which 
can be the main or the coadjutant actors. 
There can be up to eight actors, signaled by 
the following RLs: agent (agt), co-agent 
(cag), object (obj), co-object (cob), object 
place (opl), beneficiary (ben), partner (ptn) 
and instrument (ins). They can also be 
coordinated through the RLs conjunction 
(and) and disjunction (or), or subordinated to 
each other by possession (pos), content (cnt), 
naming (nam), comparison (bas), proportion 
(per), and modification (mod). They can still 
be quantified (qua) or qualified by the RLs 
"property attribution" (aoj) and co-attribution 
(cao). It is possible to refer to an "initial 
actor" (src), a "final actor" (gol), or an 
"intermediary actor" (via). Finally, spatial 
relationships can also hold between actors: 
current place (plc), origin (firm), destination 
(to), and path (via). Besides single events, 
there can still be complex cross-event 
relationships which express either paralleled 
events - co-occurrence (coo), conjunction 
(and), and disjunction (or) - or hierarchically 
posed events - purpose (pur), reason (rsn), 
condition (con), and sequence (seq). They 
can all be referred to as logical relations, 
since they are often isomorphic to first-order 
logic predicates. 
According to the UNL authors, it is 
possible to codify any sentence written in any 
NL into a corresponding UNL text expressing 
the sentence meaning through the use of the 
above RLs. This is still a claim to be verified, 
since cases of superposition and competition 
between different RLs have been observed, 
as it is discussed in Section 5. 
In addition to UWs and RLs, UNL 
makes use of predicate-like information, or 
Attribute Labels (ALs), which are names for 
event and concept "transformations", in a 
sense very close to that intended by Chomsky 
(1957, 1965). They are not explicitly 
represented in a UNL hypergraph, although 
they are used to modify its nodes. ALs can 
convey information about concept intensions 
and extensions. In the former case, ALs name 
information about utterers' intensions over 
either specific parts of a sentence (focus, 
topic, emphasis, theme) or the whole 
structure (exclamation, interrogation, 
invitation, recommendation, obligation, etc.). 
In the latter case, ALs refer to spatial 
(definite, indefinite, generic, plural) or 
temporal (past, present, future)information, 
or still, temporal external (begin-soon, begin- 
just, end-soon, end-just) or intemal 
(perfecfive, progressive, imperfective, 
iterative) structures. To differentiate ALs 
from UWs, ALs are attached to UWs by the 
symbol ".@". The cOncept expressed by the 
UW 'sit' in "sit. @entry. @past", for example, 
is taken as the starting point (. @entry) of the 
corresponding hypergraph and it is to be 
modified by temporal information (.@past). 
7 RLs names are bracketed.  
28 
4. The UNL System 
The UNL system architecture consists of 
two main processes, the encoder and 
decoder, and several linguistic resources, 
each group of these corresponding to a NL 
embedded in the system, as depicted in 
Figure 3. 
~U~qL e language-to-~ dictionary 
UNL-t0-target-~ uage dictionary 
~source  I 
language I 
Encoder 
? r I 
1 
Decoder 
language I 
 s~t~CNL e language-to-~ grammar J 
Figure 3: The UNL System Architecture 
A source document (SLD) conveys 
written text on any subject, in any of the NLs 
considered. There is no constraint in the 
domain or structure of the SLD, but there is 
necessarily a loss of semantic expressiveness 
during NL-UNL encoding. The goal of the 
UNL is not, in principle, to fully preserve text 
meaning, but only its main components, i.e., 
those considered to be essential. However, 
there is no measurable account as to what is 
essential in the UNL Project. By convention, 
this is linked to what has been called the 
literal meaning, whi.ch is directly derived 
from interpreting the sentence surface 
structure. Therefore, there is no room to 
represent content hat is not directly mapped 
onto the NL syntactic-semantic licensed 
structures. 
The NL-UNL encoding tool, or UNL 
Encoder, is generic enough to handle all the 
29 
languages included in the Project. Apart from 
the (supposedly) universal knowledge-base, 
used to fill-in possible interlexical gaps when 
mapping is not precise, all other linguistic 
resources are language-dependent. The 
source grammar essentially guides the 
elicitation of the sentence semantic structure 
into its corresponding UNL structure, by 
determining RLs and ALs, always giving 
priority to information content. 
The UNL-NL decoding tool, or UNL 
Decoder, works in the opposite way to the 
Encoder. Besides the lexicon and the 
grammar, a cooccurrence dictionary is also 
used at this stage, to disentangle lexical 
choice. The target grammar is responsible for 
the semantic-syntactic mapping, now 
resolving semantic organization by making 
syntactic and dependence choices between 
UWs, taking RLs and ALs into account. 
5. Remarks on language-independence 
The main strength of the UNL Project 
rests on human expertise: language-specific 
aspects to be included in the multilingual 
KBMT system are handled by native 
speakers of that language, in an attempt o 
overcome the need of representing 
knowledge across several languages or 
cultures. It has been successful in developing 
NL-driven resources and processes by 
researchers all around the world. For 
example, the BP UNL lexicon has over 
65,000 entries that are categorized according 
to grammatical and some semantic features, 
and this will be extended considerably in the 
future to cover the Portuguese vocabulary to 
a greater extent. Up to the present ime, only 
decoding systems customized to each NL 
have been plugged into a general decoder 
skeleton (provided by the UNL Center) and 
have already been assessed, producing 
promising results. The BP decoder, for 
example, is able to produce outputs whose 
literal meaning is preserved in most cases 
(Martins et al, 1998b), using handcoded 
UNL expressions. Actually, to decode any 
UNL text, NL-UNL encoding has to be 
handmade, since customization of the UNL 
Encoder to each NL has not yet been 
undertaken in the project. In spite of the 
promising decoding results, a) output quality 
varies enormously with UNL sentences 
encoding, which can be different across 
distinct research groups; b) communicative 
aspects of information exchange on the web 
are not explored in depth, as it can be seen 
through the list of RLs or ALs. UNL is not 
knowledge intensive and there are no 
guidelines as to consistently recognize or 
extract such kind of information from the 
surface of the source texts. 
There are several reasons why 
interpretation and use of the UNL among the 
various teams are not uniform, including 
cultural aspects and syntax differences of the 
languages involved. Using English as the 
lingua franca for communication and 
cooperation among the research groups and 
as the knowledge representation language has 
also brought limitations into the Project, 
since it implies a non-desirable level of 
language-dependence. This is inevitable, 
however, for limitations definitely come 
along with the choice made. For example, 
attaching a NL word to a UW may be 
difficult, owing to the cross-references 
introduced by using English to convey UNL 
symbols. Resuming the example shown in 
Figure 1, this is the case of the UW "on" in 
(lb): the preposition 'on' fills in the position 
feature of the verb 'sit' and, thus, is 
represented in UNL correspondingly as the 
second term of the binary relation 'plc' and 
the first term of 'obj'. This, undoubtedly, is 
critical, for 'sit' can be juxtaposed to other 
prepositions leading to different meanings, 
which, in turn, may introduce different sets of 
binary relations, implying a high-level 
complexity in the UNL representation. As a 
result, languages whose syntactic structures 
deeply differ from the English ones may 
30 
present an additional level of complexity that 
makes mapping to/from UNL impossible or 
unrealistic. In this respect, we have not been 
facing many problems in fitting Portuguese 
structures with UNL ones, since Portuguese, 
like English, is an inflectional anguage that 
also employs prepositional constructions. 
However, prepositions in Portuguese may 
play considerably different roles compared to 
English. Various extensions of the English 
spatial prepositions "on", "over" and 
"above", for example, are subsumed in 
Portuguese by a single form "sobre" (which 
may also mean ..about). Therefore, in 
Portuguese, cats could be, at the same time, 
not only "on" but also "over" and "above" 
mats. Only world knowledge, associated to 
contextual indexes, both absent in the 
referred UNL hypergraph, could avoid the 
unsuited encodings The cat sat over the mat. 
or The cat sat above the mat. from the 
Portuguese sentence "O gato sentou sobre o 
tapete". 
Another problem related to the sentence 
The cat sat on the mat. refers to the existence 
of competing analyses: it is quite plausible 
that a UNL representation suggesting a noun 
phrase instead of a full sentence holds for this 
sentence. It so happens when the arc between 
'sitting' and 'cat' concepts are labeled by the 
RL 'obj', instead of the RL 'agt' in (1), as it 
is shown in Figure 1 a', yielding the UNL text 
shown in Figure lb'. 
o 
Figure la': UNL hypergraph representation f 
the English sentence "The cat sat on the mat." 
obj(sit. @entry. @past,cat. @def) 
plc(sit. @ entry. @ past,on) 
obj(on,mat. @def) 
Figure lb ' :  UNL linear representation f the 
English sentence "The cat sat on the mat." 
Both analyses are equally accurate and 
can lead to good NL surface expressions, 
although they refer to different semantic 
facts. Indeed, to define an object relationship 
between "sitting" and "cat" is to say that the 
cat was already sat before the beginning of 
the event (e,g., The cat sat on the mat ate the 
fish.). In this case, the animal does not 
actually perform the action, but is 
conditioned to it, the main performer position 
being empty, thus yielding the referred noun 
phrase. In Figure 1, instead, the cat on its 
own has taken the sitting position, therefore 
introducing an agent relationship. These two 
different semantic facts may correspond, in 
English, to a single surface structure. Indeed, 
(1) is orthographically identical to (1'). 
However, other languages (e.g., Portuguese) 
do behave differently. 
Although it is also possible to have, in 
Portuguese, the same surface structure 
corresponding to both UNL representations 
("sentado no tapete"), it is more feasible to 
have, for each case, completely different 
constructions. In the case depicted by Figure 
1, the UW "sit" would be associated to the 
verb "sentar" (corresponding to "to sit"). 
Thus, the generation result should be 
something like "O gato sentou no tapete" or 
"O gato sentado no tapete". On the other 
hand, for Figure 1', the same UW 'sit' would 
be generated in a completely different way, 
corresponding to the passive form of the 
Portuguese xpression "colocar sentado" (to 
be put in a sitted position), for which there is 
no adequate English surface xpression. 
Distinguishing such situations to cope 
with syntactic-semantic troublesome 
mappings, though interesting, is a highly 
31 
context-sensitive task, often surpassing 
sentence boundaries. UNL descriptions do 
not address such fine-grained level of 
meaning representation, being limited to 
meanings derived from context-free source 
sentences, even when context-freeness 
implies insufficient information. When this is 
not possible, UNL offers a default analysis 
for semantically ambiguous sentences, in 
which case we can say that the UNL 
representation is probabilistic, rather than 
deterministic. 
The _way we believe some of UNL 
limitations can-be  overcome and/or 
minimized is by designing a fully-fledged 
testing procedure to assess outputs of both 
decoder and encoder for the various 
languages. Since the same encoding and 
decoding procedures have been delivered to 
the UNL teams, it is possible that part of the 
set of rules or translation strategies of a given 
team may be interchangeable with another 
one from a different language. In this way, 
sharing procedures may become a warranty 
for common ground assessment of the varied 
models, in which case it may be possible to 
make eligible concurrent strategies equally 
available for the languages involved. 
Concerning the UNL means to 
disambiguate or proceed to reference 
resolution or other discourse figures, most of 
the troublesome occurrences are enclosed in 
the treatment issued by specialists and, thus, 
they are constrained to, and handled by, at the 
level of native speakers use. This measure 
can be somewhat fruitful, provided that each 
signatory of the Project finds a way to trace a 
UNL text back onto its own NL text or vice- 
versa, making a proper use of the UNL 
syntax or symbols. This, in fact, can be a 
good method to evaluate (de)coding: once a 
UNL code has been produced from any NL 
text, this code can be the source to decoding 
into the same NL, in order to compare the 
original NL text with the automatically 
generated one. Evaluation, in this case, can 
be carried out by the same research group 
responsible for both processes. 
Compared to other interlingua pproaches 
(e.g., Mikrokosmos, Gazelle, or Kant), the 
UNL Project is in a much earlier stage - most 
of those are over 10 years old, while the UNL 
one is about 3 years old - but it is much more 
ambitious than most of the current systems 
under construction. For UNL is actually a 
front-end to a many-to-many communication 
system, with no constraints that are normally 
inherent in MT systems. Since knowledge is 
specified by native speakers for each NL 
module, grammar, semantics and world 
knowledge can be well founded. Its 
limitations, from a conceptual viewpoint, are 
shared by most of its counterparts, as in 
treating text at the sentence level only. In 
addition, by no means is the UNL system 
committed to event replication as it is the 
case of human translation. Automatic 
strategies have no psychological motivation 
whatsoever and are solely based upon 
computer efficiency principles, namely time 
and space. 
Acknowledgments 
The development of resources for 
Brazilian Portuguese in the UNL Project has 
been sponsored by the Institute of Advanced 
Studies of the United Nations University. The 
authors are also grateful to CNPq and Finep 
(Brazil) for the financial support and to Mr. 
Tadao Takahashi, the coordinator of the 
Brazilian branch in the UNL Project. 
References 
Chomsky, N. (1957). Syntactic Structures. 
The Hague, Mouton. 
Chomsky, N. (1965). Aspects of the Theory of 
Syntax. MIT Press, Cambridge, MA. 
Fillmore, C. (1968). The case for case. In 
Bach, E. and Harms, R.T. (orgs.), 
Universals in linguistic theory, pp. 1-88. 
Rinehard and Winston, New York. 
32 
Frege, G. (1892). On Sinn and Bedeutung. In 
Beaney, M. (ed.), The Frege Reader. 
Blackwell Publishers, Malden, MA, 1997. 
Martins, R.T., Rino, L.H.M., Nunes, M.G.V. 
(1998a). As Regras Gramaticais para a 
Decodtfica~ao UNL-Portugu~s no Projeto 
UNL. Relat6rio T6cnico 67. Instituto de 
CiSncias Matem~iticas e da Computa~ao. 
Universidade de S~o Paulo, Sao Carlos. 
Martins, R.T.; Rino, L.H.M.; Nunes, 
M.G.V.; Oliveira Jr., O.N. (1998b). Can 
the syntactic realization be detached from 
the syntactic analysis during generation of 
natural ldnguage sentences? III Encontro 
para o processamento c mputacional da 
lingua portuguesa escrita e falada 
(PROPOR'98). Porto Alegre - RS. 
Novembro. 
Uchida, H. (1996). UNL: Universal 
Networking Language - An Electronic 
Language for Communication, 
Understanding, and Collaboration. 
UNU/IAS/UNL Center. Tokyo, Japan. 
33 
