Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1017?1026,
Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
Weighted Alignment Matrices for Statistical Machine Translation
Yang Liu , Tian Xia , Xinyan Xiao and Qun Liu
Key Laboratory of Intelligent Information Processing
Institute of Computing Technology
Chinese Academy of Sciences
P.O. Box 2704, Beijing 100190, China
{yliu,xiatian,xiaoxinyan,liuqun}@ict.ac.cn
Abstract
Current statistical machine translation sys-
tems usually extract rules from bilingual
corpora annotated with 1-best alignments.
They are prone to learn noisy rules due
to alignment mistakes. We propose a new
structure called weighted alignment matrix
to encode all possible alignments for a par-
allel text compactly. The key idea is to as-
sign a probability to each word pair to in-
dicate how well they are aligned. We de-
sign new algorithms for extracting phrase
pairs from weighted alignment matrices
and estimating their probabilities. Our ex-
periments on multiple language pairs show
that using weighted matrices achieves con-
sistent improvements over using n-best
lists in significant less extraction time.
1 Introduction
Statistical machine translation (SMT) relies heav-
ily on annotated bilingual corpora. Word align-
ment, which indicates the correspondence be-
tween the words in a parallel text, is one of the
most important annotations in SMT. Word-aligned
corpora have been found to be an excellent source
for translation-related knowledge, not only for
phrase-based models (Och and Ney, 2004; Koehn
et al, 2003), but also for syntax-based models
(e.g., (Chiang, 2007; Galley et al, 2006; Shen
et al, 2008; Liu et al, 2006)). Och and Ney
(2003) indicate that the quality of machine transla-
tion output depends directly on the quality of ini-
tial word alignment.
Modern alignment methods can be divided into
two major categories: generative methods and dis-
criminative methods. Generative methods (Brown
et al, 1993; Vogel and Ney, 1996) treat word
alignment as a hidden process and maximize the
likelihood of bilingual training corpus using the
expectation maximization (EM) algorithm. In
contrast, discriminative methods (e.g., (Moore et
al., 2006; Taskar et al, 2005; Liu et al, 2005;
Blunsom and Cohn, 2006)) have the freedom to
define arbitrary feature functions that describe var-
ious characteristics of an alignment. They usu-
ally optimize feature weights on manually-aligned
data. While discriminative methods show supe-
rior alignment accuracy in benchmarks, genera-
tive methods are still widely used to produce word
alignments for large sentence-aligned corpora.
However, neither generative nor discriminative
alignment methods are reliable enough to yield
high quality alignments for SMT, especially for
distantly-related language pairs such as Chinese-
English and Arabic-English. The F-measures for
Chinese-English and Arabic-English are usually
around 80% (Liu et al, 2005) and 70% (Fraser
and Marcu, 2007), respectively. As most current
SMT systems only use 1-best alignments for ex-
tracting rules, alignment errors might impair trans-
lation quality.
Recently, several studies have shown that offer-
ing more alternatives of annotations to SMT sys-
tems will result in significant improvements, such
as replacing 1-best trees with packed forests (Mi
et al, 2008) and replacing 1-best word segmenta-
tions with word lattices (Dyer et al, 2008). Sim-
ilarly, Venugopal et al (2008) use n-best align-
ments instead of 1-best alignments for translation
rule extraction. While they achieve significant im-
provements on the IWSLT data, extracting rules
from n-best alignments might be computationally
expensive.
In this paper, we propose a new structure named
weighted alignment matrix to represent the align-
ment distribution for a sentence pair compactly. In
a weighted matrix, each element that corresponds
to a word pair is assigned a probability to measure
the confidence of aligning the two words. There-
fore, a weighted matrix is capable of using a lin-
1017
the
development
of
China
?s
economy
z
h
o
n
g
g
u
o
d
e
j
i
n
g
j
i
f
a
z
h
a
n
Figure 1: An example of word alignment between
a pair of Chinese and English sentences.
ear space to encode the probabilities of exponen-
tially many alignments. We develop a new algo-
rithm for extracting phrase pairs from weighted
matrices and show how to estimate their relative
frequencies and lexical weights. Experimental re-
sults show that using weighted matrices achieves
consistent improvements in translation quality and
significant reduction in extraction time over using
n-best lists.
2 Background
Figure 1 shows an example of word alignment be-
tween a pair of Chinese and English sentences.
The Chinese and English words are listed horizon-
tally and vertically, respectively. The dark points
indicate the correspondence between the words in
two languages. For example, the first Chinese
word ?zhongguo? is aligned to the fourth English
word ?China?.
Formally, given a source sentence f = fJ
1
=
f
1
, . . . , f
j
, . . . , f
J
and a target sentence e = eI
1
=
e
1
, . . . , e
i
, . . . , e
I
, we define a link l = (j, i) to
exist if f
j
and e
i
are translation (or part of trans-
lation) of one another. Then, an alignment a is a
subset of the Cartesian product of word positions:
a ? {(j, i) : j = 1, . . . , J ; i = 1, . . . , I} (1)
Usually, SMT systems only use the 1-best align-
ments for extracting translation rules. For exam-
ple, given a source phrase ?f and a target phrase
e?, the phrase pair ( ?f , e?) is said to be consistent
(Och and Ney, 2004) with the alignment if and
only if: (1) there must be at least one word in-
side one phrase aligned to a word inside the other
phrase and (2) no words inside one phrase can be
aligned to a word outside the other phrase.
After all phrase pairs are extracted from the
training corpus, their translation probabilities can
be estimated as relative frequencies (Och and Ney,
2004):
?(e?|
?
f) =
count(
?
f, e?)
?
e?
?
count(
?
f , e?
?
)
(2)
where count( ?f , e?) indicates how often the phrase
pair ( ?f, e?) occurs in the training corpus.
Besides relative frequencies, lexical weights
(Koehn et al, 2003) are widely used to estimate
how well the words in ?f translate the words in
e?. To do this, one needs first to estimate a lexi-
cal translation probability distribution w(e|f) by
relative frequency from the same word alignments
in the training corpus:
w(e|f) =
count(f, e)
?
e
?
count(f, e
?
)
(3)
Note that a special source NULL token is added
to each source sentence and aligned to each un-
aligned target word.
As the alignment a? between a phrase pair ( ?f, e?)
is retained during extraction, the lexical weight
can be calculated as
p
w
(e?|
?
f, a?) =
|e?|
?
i=1
1
|{j|(j, i) ? a?}|
?
w(e
i
|f
j
) (4)
If there are multiple alignments a? for a phrase
pair ( ?f , e?), Koehn et al (2003) choose the one
with the highest lexical weight:
p
w
(e?|
?
f) = max
a?
{
p
w
(e?|
?
f, a?)
}
(5)
Simple and effective, relative frequencies and
lexical weights have become the standard features
in modern discriminative SMT systems.
3 Weighted Alignment Matrix
We believe that offering more candidate align-
ments to extracting translation rules might help
improve translation quality. Instead of using n-
best lists (Venugopal et al, 2008), we propose a
new structure called weighted alignment matrix.
We use an example to illustrate our idea. Fig-
ure 2(a) and Figure 2(b) show two alignments of
a Chinese-English sentence pair. We observe that
some links (e.g., (1,4) corresponding to the word
1018
the
development
of
China
?s
economy
z
h
o
n
g
g
u
o
d
e
j
i
n
g
j
i
f
a
z
h
a
n
the
development
of
China
?s
economy
z
h
o
n
g
g
u
o
d
e
j
i
n
g
j
i
f
a
z
h
a
n
the
development
of
China
?s
economy
z
h
o
n
g
g
u
o
d
e
j
i
n
g
j
i
f
a
z
h
a
n
1.0
0.6
0.40.4
1.0
1.0
0.4
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
(a) (b) (c)
Figure 2: (a) One alignment of a sentence pair; (b) another alignment of the same sentence pair; (c)
the resulting weighted alignment matrix that takes the two alignments as samples, of which the initial
probabilities are 0.6 and 0.4, respectively.
pair (?zhongguo?, ?China?)) occur in both align-
ments, some links (e.g., (2,3) corresponding to the
word pair (?de?,?of?)) occur only in one align-
ment, and some links (e.g., (1,1) corresponding
to the word pair (?zhongguo?, ?the?)) do not oc-
cur. Intuitively, we can estimate how well two
words are aligned by calculating its relative fre-
quency, which is the probability sum of align-
ments in which the link occurs divided by the
probability sum of all possible alignments. Sup-
pose that the probabilities of the two alignments in
Figures 2(a) and 2(b) are 0.6 and 0.4, respectively.
We can estimate the relative frequencies for every
word pair and obtain a weighted matrix shown in
Figure 2(c). Therefore, each word pair is associ-
ated with a probability to indicate how well they
are aligned. For example, in Figure 2(c), we say
that the word pair (?zhongguo?, ?China?) is def-
initely aligned, (?zhongguo?, ?the?) is definitely
unaligned, and (?de?, ?of?) has a 60% chance to
get algned.
Formally, a weighted alignment matrix m is a
J ? I matrix, in which each element stores a link
probability p
m
(j, i) to indicate how well f
j
and
e
i
are aligned. Currently, we estimate link proba-
bilities from an n-best list by calculating relative
frequencies:
p
m
(j, i) =
?
a?N
p(a)? ?(a, j, i)
?
a?N
p(a)
(6)
=
?
a?N
p(a)? ?(a, j, i) (7)
where
?(a, j, i) =
{
1 (j, i) ? a
0 otherwise (8)
Note that N is an n-best list, p(a) is the probabil-
ity of an alignment a in the n-best list, ?(a, j, i)
indicates whether a link (j, i) occurs in the align-
ment a or not. We assign 0 to any unseen
alignment. As p(a) is usually normalized (i.e.,
?
a?N
p(a) ? 1), we remove the denominator in
Eq. (6).
Accordingly, the probability that the two words
f
j
and e
i
are not aligned is
p?
m
(j, i) = 1.0? p
m
(j, i) (9)
For example, as shown in Figure 2(c), the prob-
ability for the two words ?de? and ?of? being
aligned is 0.6 and the probability that they are not
aligned is 0.4.
Intuitively, the probability of an alignment a is
the product of link probabilities. If a link (j, i)
occurs in a, we use p
m
(j, i); otherwise we use
p?
m
(j, i). Formally, given a weighted alignment
matrix m, the probability of an alignment a can
be calculated as
p
m
(a) =
J
?
j=1
I
?
i=1
(p
m
(j, i) ? ?(a, j, i) +
p?
m
(j, i) ? (1? ?(a, j, i))) (10)
It proves that the sum of all alignment proba-
bilities is always 1:
?
a?A
p
m
(a) ? 1, where A
1019
1: procedure PHRASEEXTRACT(fJ
1
, e
I
1
, m, l)
2: R ? ?
3: for j
1
? 1 . . . J do
4: j
2
? j
1
5: while j
2
< J ? j
2
? j
1
< l do
6: T ? {i|?j : j
1
? j ? j
2
? p
m
(j, i) > 0}
7: i
l
? MIN(T )
8: i
u
? MAX(T )
9: for n? 1 . . . l do
10: for i
1
? i
l
? n + 1 . . . i
u
do
11: i
2
? i
1
+ n? 1
12: R ? R? {(f j2
j
1
, e
i
2
i
1
)}
13: end for
14: end for
15: j
2
? j
2
+ 1
16: end while
17: end for
18: returnR
19: end procedure
Figure 3: Algorithm for extracting phrase pairs
from a sentence pair ?fJ
1
, e
I
1
? annotated with a
weighted alignment matrix m.
is the set of all possible alignments. Therefore, a
weighted alignment matrix is capable of encoding
the probabilities of 2J?I alignments using only a
J ? I space.
Note that p
m
(a) is not necessarily equal to p(a)
because the encoding of a weighted alignment ma-
trix changes the alignment probability distribu-
tion. For example, while the initial probability of
the alignment in Figure 2(a) (i.e., p(a)) is 0.6, the
probability of the same alignment encoded in the
matrix shown in Figure 2(c) (i.e., p
m
(a)) becomes
0.1296 according to Eq. (10). It should be em-
phasized that a weighted matrix encodes all pos-
sible alignments rather than the input n-best list,
although the link probabilities are estimated from
the n-best list.
4 Phrase Pair Extraction
In this section, we describe how to extract phrase
pairs from the training corpus annotated with
weighted alignment matrices (Section 4.1) and
how to estimate their relative frequencies (Section
4.2) and lexical weights (Section 4.3).
4.1 Extraction Algorithm
Och and Ney (2004) describe a ?phrase-extract?
algorithm for extracting phrase pairs from a sen-
tence pair annotated with a 1-best alignment.
Given a source phrase, they first identify the target
phrase that is consistent with the alignment. Then,
they expand the boundaries of the target phrase if
the boundary words are unaligned.
Unfortunately, this algorithm cannot be directly
used to manipulate a weighted alignment matrix,
which is a compact representation of all pos-
sible alignments. The major difference is that
the ?tight? phrase that has both boundary words
aligned is not necessarily the smallest candidate
in a weighted matrix. For example, in Figure
2(a), the ?tight? target phrase corresponding to
the source phrase ?zhongguo de? is ?of China?.
According to Och?s algorithm, the target phrase
?China? breaks the alignment consistency and
therefore is not valid candidate. However, this is
not true for using the weighted matrix shown in
Figure 2(c). The target phrase ?China? is treated
as a ?potential? candidate 1, although it might be
assigned only a small fractional count (see Table
1).
Therefore, we enumerate all potential phrase
pairs and calculate their fractional counts for
eliminating less promising candidates. Figure 3
shows the algorithm for extracting phrases from
a weighted matrix. The input of the algorithm
is a source sentence fJ
1
, a target sentence eI
1
, a
weighted alignment matrix m, and a phrase length
limit l (line 1). After initializing R that stores col-
lected phrase pairs (line 2), we identify the cor-
responding target phrases for all possible source
phrases (lines 3-5). Given a source phrase f j2
j
1
, we
find the lower and upper bounds of target positions
(i.e., i
l
and i
u
) that have positive link probabili-
ties (lines 6-8). For example, the lower bound is
3 and the upper bound is 5 for the source phrase
?zhongguo de? in Figure 2(c). Finally, we enu-
merate all target phrases that allow for unaligned
boundary words with varying phrase lengths (lines
9-14). Note that we need to ensure that 1 ? i
1
? I
and 1 ? i
2
? I in lines 10-11, which are omitted
for simplicity.
4.2 Calculating Relative Frequencies
To estimate the relative frequency of a phrase pair,
we need to estimate how often it occurs in the
training corpus. Given an n-best list, the fractional
count of a phrase pair is the probability sum of
the alignments with which the phrase pair is con-
sistent. Obviously, it is unrealistic for a weighted
alignment matrix to enumerate all possible align-
ments explicitly to calculate fractional counts. In-
stead, we resort to link probabilities to calculate
1By potential, we mean that the fractional count of a
phrase pair is positive. Section 4.2 describes how to calcu-
late fractional counts.
1020
the
development
of
China
?s
economy
z
h
o
n
g
g
u
o
d
e
j
i
n
g
j
i
f
a
z
h
a
n
1.0
0.6
0.40.4
1.0
1.0
0.4
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
Figure 4: An example of calculating fractional
count. Given the phrase pair (?zhongguo de?, ?of
China?), we divide the matrix into three areas: in-
side (heavy shading), outside (light shading), and
irrelevant (no shading).
counts efficiently. Equivalent to explicit enumera-
tion, we interpret the fractional count of a phrase
pair as the probability that it satisfies the two align-
ment consistency conditions (see Section 2).
Given a phrase pair, we divide the elements of
a weighted alignment matrix into three categories:
(1) inside elements that fall inside the phrase pair,
(2) outside elements that fall outside the phrase
pair while fall in the same row or the same col-
umn, and (3) irrelevant elements that fall outside
the phrase pair while fall in neither the same row
nor the same column. Figure 4 shows an exam-
ple. Given the phrase pair (?zhongguo de?, ?of
China?), we divide the matrix into three areas: in-
side (heavy shading), outside (light shading), and
irrelevant (no shading).
To what extent a phrase pair satisfies the align-
ment consistency is measured by calculating in-
side and outside probabilities. Although there are
the same terms in the parsing literature, they have
different meanings here. The inside probability in-
dicates the chance that there is at least one word
inside one phrase aligned to a word inside the
other phrase. The outside probability indicates the
chance that no words inside one phrase are aligned
to a word outside the other phrase.
Given a phrase pair (f j2
j
1
, e
i
2
i
1
), we denote the in-
side area as in(j
1
, j
2
, i
1
, i
2
) and the outside area
as out(j
1
, j
2
, i
1
, i
2
). Therefore, the inside proba-
bility of a phrase pair is calculated as
?(j
1
, j
2
, i
1
, i
2
) = 1?
?
(j,i)?in(j
1
,j
2
,i
1
,i
2
)
p?
m
(j, i) (11)
target phrase ? ? count
of China 1.0 0.36 0.36
of China ?s 1.0 0.36 0.36
China ?s 1.0 0.24 0.24
China 1.0 0.24 0.24
?s economy 0.4 0 0
Table 1: Some candidate target phrases of the
source phrase ?zhongguo de? in Figure 4, where ?
is inside probability, ? is outside probability, and
count is fractional count.
For example, the inside probability for (?zhong-
guo de?, ?of China?) in Figure 4 is 1.0, which
means that there always exists at least one aligned
word pair inside.
Accordingly, the outside probability of a phrase
pair is calculated as
?(j
1
, j
2
, i
1
, i
2
) =
?
(j,i)?out(j
1
,j
2
,i
1
,i
2
)
p?
m
(j, i) (12)
For example, the outside probability for
(?zhongguo de?, ?of China?) in Figure 4 is 0.36,
which means the probability that there are no
aligned word pairs outside is 0.36.
Finally, we use the product of inside and outside
probabilities as the fractional count of a phrase
pair:
count(f
j
2
j
1
, e
i
2
i
1
) = ?(j
1
, j
2
, i
1
, i
2
)?
?(j
1
, j
2
, i
1
, i
2
) (13)
Table 1 lists some candidate target phrases of
the source phrase ?zhongguo de? in Figure 4. We
also give their inside probabilities, outside proba-
bilities, and fractional counts.
After collecting the fractional counts from the
training corpus, we then use Eq. (2) to calculate
relative frequencies in two translation directions.
Often, our approach extracts a large amount of
phrase pairs from training corpus as we soften
the alignment consistency constraint. To main-
tain a reasonable phrase table size, we discard any
phrase pair that has a fractional count lower than
a threshold t. During extraction, we first obtain
a list of candidate target phrases for each source
phrase, as shown in Table 1. Then, we prune the
list according to the threshold t. For example, we
only retain the top two candidates in Table 1 if
t = 0.3. Note that we perform the pruning locally.
Although it is more reasonable to prune a phrase
table after accumulating all fractional counts from
1021
training corpus, such global pruning strategy usu-
ally leads to very large disk and memory require-
ments.
4.3 Calculating Lexical Weights
Recall that we need to obtain two translation prob-
ability tables w(e|f) and w(f |e) before calculat-
ing lexical weights (see Section 2). Following
Koehn et al (2003), we estimate the two distribu-
tions by relative frequencies from the training cor-
pus annotated with weighted alignment matrices.
In other words, we still use Eq. (3) but the way of
calculating fractional counts is different now.
Given a source word f
j
, a target word e
i
, and
a weighted alignment matrix, the fractional count
count(f
j
, e
i
) is p
m
(j, i). For NULL words, the
fractional counts can be calculated as
count(f
j
, e
0
) =
I
?
i=1
p?
m
(j, i) (14)
count(f
0
, e
i
) =
J
?
j=1
p?
m
(j, i) (15)
For example, in Figure 4, count(de, of) is 0.6,
count(de,NULL) is 0.24, and count(NULL,of) is
0.24.
Then, we adapt Eq. (4) to calculate lexical
weight:
p
w
(e?|
?
f ,m) =
|e?|
?
i=1
(
(
1
{j|p
m
(j, i) > 0}
?
?
?j:p
m
(j,i)>0
p(e
i
|f
j
)? p
m
(j, i)
)
+
p(e
i
|f
0
)?
|
?
f |
?
j=1
p?
m
(j, i)
)
(16)
For example, for the target word ?of? in Figure
4, the sum of aligned and unaligned probabilities
is
1
2
? (p(of|de)? 0.6 + p(of|fazhan)? 0.4) +
p(of|NULL)? 0.24
Note that we take link probabilities into account
and calculate the probability that a target word
translates a source NULL token explicitly.
5 Experiments
5.1 Data Preparation
We evaluated our approach on Chinese-to-English
translation. We used the FBIS corpus (6.9M
+ 8.9M words) as the training data. For lan-
guage model, we used the SRI Language Mod-
eling Toolkit (Stolcke, 2002) to train a 4-gram
model on the Xinhua portion of GIGAWORD cor-
pus. We used the NIST 2002 MT evaluation test
set as our development set, and used the NIST
2005 test set as our test set. We evaluated the trans-
lation quality using case-insensitive BLEU metric
(Papineni et al, 2002).
To obtain weighted alignment matrices, we fol-
lowed Venugopal et al (2008) to produce n-
best lists via GIZA++. We first ran GIZA++
to produce 50-best lists in two translation direc-
tions. Then, we used the refinement technique
?grow-diag-final-and? (Koehn et al, 2003) to all
50 ? 50 bidirectional alignment pairs. Suppose
that p
s2t
and p
t2s
are the probabilities of an align-
ment pair assigned by GIZA++, respectively. We
used p
s2t
? p
t2s
as the probability of the result-
ing symmetric alignment. As different alignment
pairs might produce the same symmetric align-
ments, we followed Venugopal et al (2008) to
remove duplicate alignments and retain only the
alignment with the highest probability. Therefore,
there were 550 candidate alignments on average
for each sentence pair in the training data. We
obtained n-best lists by selecting the top n align-
ments from the 550-best lists. The probability of
each alignment in the n-best list was re-estimated
by re-normalization (Venugopal et al, 2008). Fi-
nally, these n-best alignments served as samples
for constructing weighted alignment matrices.
After extracting phrase pairs from n-best lists
and weighted alignment matrices, we ran Moses
(Koehn et al, 2007) to translate the development
and test sets. We used the simple distance-based
reordering model to remove the dependency of
lexicalization on word alignments for Moses.
5.2 Effect of Pruning Threshold
Our first experiment investigated the effect of
pruning threshold on translation quality (BLEU
scores on the test set) and the phrase table size (fil-
tered for the test set), as shown in Figure 5. To
save time, we extracted phrase pairs just from the
first 10K sentence pairs of the FBIS corpus. We
used 12 different thresholds: 0.0001, 0.001, 0.01,
0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, and 0.9. Obvi-
ously, the lower the threshold is, the more phrase
pairs are extracted. When t = 0.0001, the number
of phrase pairs used on the test set was 460,284
1022
0.195
0.196
0.197
0.198
0.199
0.200
0.201
0.202
0.203
0.204
0.205
0.206
0.207
0.208
 150  200  250  300  350  400  450  500
BL
EU
 sc
or
e
phrase table size (103)
t=10-4
t=10-3
t=10-2
t=0.9...0.1
Figure 5: Effect of pruning threshold on transla-
tion quality and phrase table size.
and the BLEU score was 20.55. Generally, both
the number of phrase pairs and the BLEU score
went down with the increase of t. However, this
trend did not hold within the range [0.1, 0.9]. To
achieve a good tradeoff between translation qual-
ity and phrase table size, we set t = 0.01 for the
following experiments.
5.3 N -best lists Vs. Weighted Matrices
Figure 6 shows the BLEU scores and aver-
age extraction time using n-best alignments and
weighted matrices, respectively. We used the en-
tire training data for phrase extraction. When us-
ing 1-best alignments, Moses achieved a BLEU
score of 0.2826 and the average extraction time
was 4.19 milliseconds per sentence pair (see point
n = 1). The BLEU scores rose with the in-
crease of n for using n-best alignments. How-
ever, the score went down slightly when n = 50.
This suggests that including more noisy align-
ments might be harmful. These improvements
over 1-best alignments are not statistically signif-
icant. This finding failed to echo the promising
results reported by Venogopal et al (2008). We
think that there are two possible reasons. First,
they evaluated their approach on the IWSLT data
while we used the NIST data. It might be easier
to obtain significant improvements on the IWSLT
data in which the sentences are shorter. Sec-
ond, they used the hierarchical phrase-based sys-
tem while we used the phrase-based system, which
might be less sensitive to word alignments because
the alignments inside the phrase pairs hardly have
an effect.
When using weighted alignment matrices, we
0.280
0.281
0.282
0.283
0.284
0.285
0.286
0.287
0.288
0.289
0.290
0.291
0.292
0.293
 0  10  20  30  40  50  60  70  80  90
BL
EU
 sc
or
e
average extracting time (milliseconds/sentence pair)
n=1
n=5
n=10
n=50
n=5
n=10
n=50
n-best
m(n)
Figure 6: Comparison of n-best alignments and
weighted alignment matrices. We use m(n) to de-
note the matrices that take n-best lists as samples.
obtained higher BLEU scores than using n-best
lists with much less extraction time. We achieved
a BLEU score of 0.2901 when using the weighted
matrices estimated from 10-best lists. The abso-
lute improvement of 0.75 over using 1-best align-
ments (from 0.2826 to 0.2901) is statistically sig-
nificant at p < 0.05 by using sign-test (Collins
et al, 2005). Although the improvements over n-
best lists are not always statistically significant,
weighted alignment matrices maintain consistent
superiority in both translation quality and extrac-
tion speed.
5.4 Comparison of Parameter Estimation
In theory, the set of phrase pairs extracted from n-
best alignments is the subset of the set extracted
from the corresponding weighted matrices. In
practice, however, this is not true because we use
the pruning threshold t to maintain a reasonable
table size. Even so, the phrase tables produced by
n-best lists and weighted matrices still share many
phrase pairs.
Table 2 gives some statistics. We use m(10)
to represent the weighted matrices estimated from
10-best lists. ?all? denotes the full phrase table,
?shared? denotes the intersection of two tables,
and ?non-shared? denotes the complement. Note
that the probabilities of ?shared? phrase pairs are
different for the two approaches. We obtained
6.13M and 6.34M phrase pairs for the test set by
using 10-best lists and the corresponding matrices,
respectively. There were 4.58M phrase pairs in-
cluded by both tables. Note that the relative fre-
quencies and lexical weights for the same phrase
1023
shared non-shared all
method phrases BLEU phrases BLEU phrases BLEU
10-best 4.58M 28.35 1.55M 12.32 6.13M 28.47
m(10) 4.58M 28.90 1.76M 13.21 6.34M 29.01
Table 2: Comparison of phrase tables learned from n-best lists and weighted matrices. We use m(10)
to represent the weighted matrices estimated from 10-best lists. ?all? denotes the full phrase table,
?shared? denotes the intersection of two tables, and ?non-shared? denotes the complement. Note that the
probabilities of ?shared? phrase pairs are different for the two approaches.
0.200
0.210
0.220
0.230
0.240
0.250
0.260
0.270
0.280
0.290
 0  50  100  150  200  250
BL
EU
 sc
or
e
training corpus size (103)
1-best
10-best
m(10)
Figure 7: Comparison of n-best alignments and
weighted alignment matrices with varying training
corpus sizes.
pairs might be different in two tables. We found
that using matrices outperformed using n-best lists
even with the same phrase pairs. This suggests that
our methods for parameter estimation make better
use of noisy data. Another interesting finding was
that using the shared phrase pairs achieved almost
the same results with using full phrase tables.
5.5 Effect of Training Corpus Size
To investigate the effect of training corpus size on
our approach, we extracted phrase pairs from n-
best lists and weighted matrices trained on five
training corpora with varying sizes: 10K, 50K,
100K, 150K, and 239K sentence pairs. As shown
in Figure 7, our approach outperformed both 1-
best and n-best lists consistently. More impor-
tantly, the gains seem increase when more training
data are used.
5.6 Results on Other Language Pairs
To further examine the efficacy of the proposed ap-
proach, we scaled our experiments to large data
with multiple language pairs. We used the Eu-
roparl training corpus from the WMT07 shared
S?E F?E G?E
Sentences 1.26M 1.29M 1.26M
Foreign words 33.16M 33.18M 29.58M
English words 31.81M 32.62M 31.93M
Table 3: Statistics of the Europarl training data.
?S? denotes Spanish, ?E? denotes English, ?F? de-
notes French, ?G? denotes German.
1-best 10-best m(10)
S?E 30.90 30.97 31.03
E?S 31.16 31.25 31.34
F?E 30.69 30.76 30.82
E?F 26.42 26.65 26.54
G?E 24.46 24.58 24.66
E?G 18.03 18.30 18.20
Table 4: BLEU scores (case-insensitive) on the
Europarl data. ?S? denotes Spanish, ?E? denotes
English, ?F? denotes French, ?G? denotes Ger-
man.
task. 2 Table 3 shows the statistics of the train-
ing data. There are four languages (Spanish,
French, German, and English) and six transla-
tion directions (Foreign-to-English and English-
to-Foreign). We used the ?dev2006? data in the
?dev? directory as the development set and the
?test2006? data in the ?devtest? directory as the
test set. Both the development and test sets contain
2,000 sentences with single reference translations.
We tokenized and lowercased all the training,
development, and test data. We trained a 4-gram
language model using SRI Language Modeling
Toolkit on the target side of the training corpus for
each task. We ran GIZA++ on the entire train-
ing data to obtain n-best alignments and weighted
matrices. To save time, we just used the first 100K
sentences of each aligned training corpus to ex-
tract phrase pairs.
2http://www.statmt.org/wmt07/shared-task.html
1024
Table 4 lists the case-insensitive BLEU scores
of 1-best, 10-best, and m(10) on the Europarl
data. Using weighted packed matrices continued
to show advantage over using 1-best alignments on
multiple language pairs. However, these improve-
ments were very small and not significant. We at-
tribute this to the fact that GIZA++ usually pro-
duces high quality 1-best alignments for closely-
related European language pairs, especially when
trained on millions of sentences.
6 Related Work
Recent studies has shown that SMT systems
can benefit from making the annotation pipeline
wider: using packed forests instead of 1-best trees
(Mi et al, 2008), word lattices instead of 1-best
segmentations (Dyer et al, 2008), and n-best
alignments instead of 1-best alignments (Venu-
gopal et al, 2008). We propose a compact repre-
sentation of multiple word alignments that enables
SMT systems to make a better use of noisy align-
ments.
Matusov et al (2004) propose ?cost matrices?
for producing symmetric alignments. Kumar et al
(2007) describe how to use ?posterior probabil-
ity matrices? to improve alignment accuracy via
a bridge language. Although not using the term
?weighted matrices? directly, they both assign a
probability to each word pair.
We follow Och and Ney (2004) to develop
a new phrase extraction algorithm for weighted
alignment matrices. The methods for calculating
relative frequencies (Och and Ney, 2004) and lex-
ical weights (Koehn et al, 2003) are also adapted
for the weighted matrix case.
Many researchers (e.g., (Venugopal et al, 2003;
Deng et al, 2008)) observe that softening the
alignment consistency constraint help improve
translation quality. For example, Deng et al
(2008) define a feature named ?within phrase pair
consistency ratio? to measure the degree of consis-
tency. As each link is associated with a probability
in a weighted matrix, we use these probabilities to
evaluate the validity of a phrase pair.
We estimate the link probabilities by calculating
relative frequencies over n-best lists. Niehues and
Vogel (2008) propose a discriminative approach to
modeling the alignment matrix directly. The dif-
ference is that they assign a boolean value instead
of a probability to each word pair.
7 Conclusion and Future Work
We have presented a new structure called weighted
alignment matrix that encodes the alignment dis-
tribution for a sentence pair. Accordingly, we de-
velop new methods for extracting phrase pairs and
estimating their probabilities. Our experiments
show that the proposed approach achieves better
translation quality over using n-best lists in less
extraction time. An interesting finding is that our
approach performs better than the baseline even
they use the same phrase pairs.
Although our approach consistently outper-
forms using 1-best alignments for varying lan-
guage pairs, the improvements are comparatively
small. One possible reason is that taking n-best
lists as samples sometimes might change align-
ment probability distributions inappropriately. A
more principled solution is to directly model the
weighted alignment matrices, either in a genera-
tive or a discriminative way. We believe that better
estimation of alignment distributions will result in
more significant improvements.
Another interesting direction is applying our ap-
proach to extracting translation rules with hierar-
chical structures such as hierarchical phrases (Chi-
ang, 2007) and tree-to-string rules (Galley et al,
2006; Liu et al, 2006). We expect that these
syntax-based systems could benefit more from our
approach.
Acknowledgement
The authors were supported by Microsoft Re-
search Asia Natural Language Processing Theme
Program grant (2009-2010), High-Technology
R&D Program (863) Project No. 2006AA010108,
and National Natural Science Foundation of China
Contract 60736014. Part of this work was done
while Yang Liu was visiting the SMT group led by
Stephan Vogel at CMU. We thank the anonymous
reviewers for their insightful comments. We are
also grateful to Stephan Vogel, Alon Lavie, Fran-
cisco Guzman, Nguyen Bach, Andreas Zollmann,
Vamshi Ambati, and Kevin Gimpel for their help-
ful feedback.
References
Phil Blunsom and Trevor Cohn. 2006. Discrimina-
tive word alignment with conditional random fields.
In Proceedings of COLING/ACL 2006, pages 65?72,
Sydney, Australia, July.
1025
Peter F. Brown, Stephen A. Della Pietra, Vincent J.
Della Pietra, and Robert L. Mercer. 1993. The
mathematics of statistical machine translation: Pa-
rameter estimation. Computational Linguistics,
19(2):263?311.
David Chiang. 2007. Hierarchical phrase-based trans-
lation. Computational Linguistics, 33(2):201?228.
Michael Collins, Philipp Koehn, and Ivona Kuc?erova?.
2005. Clause restructuring for statistical machine
translation. In Proceedings of ACL 2005, pages
531?540, Ann Arbor, USA, June.
Yonggang Deng, Jia Xu, and Yuqing Gao. 2008.
Phrase table training for precision and recall: What
makes a good phrase and a good phrase pair?
In Proceedings of ACL/HLT 2008, pages 81?88,
Columbus, Ohio, USA, June.
Christopher Dyer, Smaranda Muresan, and Philip
Resnik. 2008. Generalizing word lattice trans-
lation. In Proceedings of ACL/HLT 2008, pages
1012?1020, Columbus, Ohio, June.
Alexander Fraser and Daniel Marcu. 2007. Measur-
ing word alignment quality for statistical machine
translation. Computational Linguistics, Squibs and
Discussions, 33(3):293?303.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable inference and training of
context-rich syntactic translation models. In Pro-
ceedings of COLING/ACL 2006, pages 961?968,
Sydney, Australia, July.
Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In Proceedings
of HLT/NAACL 2003, pages 127?133, Edmonton,
Canada, May.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexan-
dra Constantin, and Evan Herbst. 2007. Moses:
Open source toolkit for statistical machine transla-
tion. In Proceedings of ACL 2007 (poster), pages
77?80, Prague, Czech Republic, June.
Shankar Kumar, Franz J. Och, and Wolfgang
Macherey. 2007. Improving word alignment with
bridge languages. In Proceedings of EMNLP 2007,
pages 42?50, Prague, Czech Republic, June.
Yang Liu, Qun Liu, and Shouxun Lin. 2005. Log-
linear models for word alignment. In Proceedings
of ACL 2005, pages 459?466, Ann Arbor, Michigan,
June.
Yang Liu, Qun Liu, and Shouxun Lin. 2006. Tree-
to-string alignment template for statistical machine
translation. In Proceedings of COLING/ACL 2006,
pages 609?616, Sydney, Australia, July.
Evgeny Matusov, Richard Zens, and Hermann Ney.
2004. Symmetric word alignments for statistical
machine translation. In Proceedings of COLING
2004, pages 219?225, Geneva, Switzerland, August.
Haitao Mi, Liang Huang, and Qun Liu. 2008. Forest-
based translation. In Proceedings of ACL/HLT 2008,
pages 192?199, Columbus, Ohio, June.
Robert C. Moore, Wen-tau Yih, and Andreas Bode.
2006. Improved discriminative bilingual word
alignment. In Proceedings of COLING/ACL 2006,
pages 513?520, Sydney, Australia, July.
Jan Niehues and Stephan Vogel. 2008. Discrimina-
tive word alignment via alignment matrix modeling.
In Proceedings of WMT-3, pages 18?25, Columbus,
Ohio, USA, June.
Franz J. Och and Hermann Ney. 2003. A systematic
comparison of various statistical alignment models.
Computational Linguistics, 29(1):19?51.
Franz J. Och and Hermann Ney. 2004. The alignment
template approach to statistical machine translation.
Computational Linguistics, 30(4):417?449.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic
evaluation of machine translation. In Proceedings
of ACL 2002, pages 311?318, Philadelphia, Penn-
sylvania, USA, July.
Libin Shen, Jinxi Xu, and Ralph Weischedel. 2008.
A new string-to-dependency machine translation al-
gorithm with a target dependency language model.
In Proceedings of ACL/HLT 2008, pages 577?585,
Columbus, Ohio, June.
Andreas Stolcke. 2002. Srilm - an extension language
model modeling toolkit. In Proceedings of ICSLP
2002, pages 901?904, Denver, Colorado, Septem-
ber.
Ben Taskar, Simon Lacoste-Julien, and Dan Klein.
2005. A discriminative matching approach to word
alignment. In Proceedings of HLT/EMNLP 2005,
pages 73?80, Vancouver, British Columbia, Canada,
October.
Ashish Venugopal, Stephan Vogel, and Alex Waibel.
2003. Effective phrase translation extraction from
alignment models. In Proceedings of ACL 2003,
pages 319?326, Sapporo, Japan, July.
Ashish Venugopal, Andreas Zollmann, Noah A. Smith,
and Stephan Vogel. 2008. Wider pipelines: n-
best alignments and parses in mt training. In Pro-
ceedings of AMTA 2008, pages 192?201, Waikiki,
Hawaii, October.
Stephan Vogel and Hermann Ney. 1996. Hmm-based
word alignment in statistical translation. In Pro-
ceedings of COLING 1996, pages 836?841, Copen-
hagen, Danmark, August.
1026
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 535?544,
Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational Linguistics
Improving Alignment of System Combination by Using
Multi-objective Optimization
Tian Xia+, Zongcheng Ji?, Shaodan Zhai+, Yidong Chen++, Qun Liu?, Shaojun Wang+
++ Xiamen University, Xiamen 361005, P.R. China
+ Wright State University, 3640 Colonel Glenn Hwy, Dayton, OH 45435, USA
? Institute of Computing Technology, Chinese Academy of Sciences
P.O. Box 2704, Beijing 100190, China
{jizongcheng, liuqun}@ict.ac.cn and ydchen@xmu.edu.cn
{xia.7, zhai.6, shaojun.wang}@wright.edu
Abstract
This paper proposes a multi-objective opti-
mization framework which supports heteroge-
neous information sources to improve align-
ment in machine translation system combi-
nation techniques. In this area, most of
techniques usually utilize confusion networks
(CN) as their central data structure to com-
pact an exponential number of an potential hy-
potheses, and because better hypothesis align-
ment may benefit constructing better quality
confusion networks, it is natural to add more
useful information to improve alignment re-
sults. However, these information may be het-
erogeneous, so the widely-used Viterbi algo-
rithm for searching the best alignment may
not apply here. In the multi-objective opti-
mization framework, each information source
is viewed as an independent objective, and
a new goal of improving all objectives can
be searched by mature algorithms. The so-
lutions from this framework, termed Pareto
optimal solutions, are then combined to con-
struct confusion networks. Experiments on
two Chinese-to-English translation datasets
show significant improvements, 0.97 and 1.06
BLEU points over a strong Indirected Hidden
Markov Model-based (IHMM) system, and
4.75 and 3.53 points over the best single ma-
chine translation systems.
1 Introduction
System combination (SC) techniques have the
power of boosting translation quality in BLEU by
several percent over the best among all input ma-
chine translation systems (Bangalore et al, 2001;
Matusov et al, 2006; Sim et al, 2007; Rosti et al,
2007b; Rosti et al, 2007a; Huang and Papineni,
2007; He et al, 2008; Rosti et al, 2008; He and
Toutanova, 2009; Li et al, 2009; Feng et al, 2009;
Pauls et al, 2009). A central data structure in the
SC is the confusion network, and its quality greatly
affects the final performance. He et al (2008) pro-
posed a new hypothesis alignment algorithm for
constructing high-quality confusion networks called
Indirect Hidden Markov Model (IHMM), which
does better in synonym matching compared with
the classic translation edit rate (TER) based algo-
rithm (Rosti et al, 2007b; Rosti et al, 2008; Sim et
al., 2007). Now, current state-of-the-art SC systems
have been using IHMM or variants in their align-
ment algorithms more or less (Li et al, 2009; Feng
et al, 2009).
Our motivation derives from an observation that
in an ideal alignment of a pair of sentences, many-to-
many alignments often exist. For instance, ?be about
to? has the same meaning with ?be on the point
of?. Because Hidden Markov Model based align-
ment algorithms, e.g. IHMM for system combina-
tion, HMM in GIZA++ software for statistical ma-
chine translation (SMT) (Och and Ney, 2000; Koehn
et al, 2003), are designed for one-to-many align-
ment, and running GIZA++ from two directions to
gain better performance turns into a standard opera-
tion in SMT, therefore we are seeking a way to em-
power IHMM by introducing bi-directional informa-
tion.
However, it appears to be intractable in an IHMM
model to search the optimal solution by simply
defining a new goal as a product of probabilities
535
from two directions. To bypass this problem, Liang
et al (2006) adopts a simple and effective variational
inference algorithm.
Further, different alignment algorithms capture
different information and linguistic phenomena for
a pair of sentences, hence more information would
be expected to benefit the final alignment. Liang?s
method may not be suitable for this expected out-
come.
We propose to adopt multi-objective optimiza-
tion framework to support heterogeneous informa-
tion sources which may induce difficulties in a
conventional search algorithm. In this framework,
there exist a variety of matured multi-objective op-
timization algorithms, e.g. evolutionary algorithm
(Deb et al, 2000; Deb et al, 2002), Tabu search
(Hansen, 1997), ants colony (Engelbrecht, 2005),
and simulated annealing (Serafini, 1994). In this
work, we select the multi-objective evolutionary al-
gorithm because of its public open source software
(http://www.iitk.ac.in/kangal/codes.shtml). On the
other hand, this framework is also totally unsuper-
vised. It prevents weights of a linearly combined
goal from training even if all information is homoge-
neous and applicable in a Viterbi search (Forney Jr,
1973). This framework views any useful informa-
tion benefiting alignment as an independent objec-
tive, and researchers just need to write short codes
for objective definitions. The search algorithm seeks
for potentially better solutions which are no worse
than the current solution set. The output from multi-
objective optimization algorithms includes a set of
solutions, called Pareto optimal solutions, each one
being a many-to-many alignment. We then com-
bine and normalize them into a unique one-to-one
alignment to perform confusion network construc-
tion (Section 3.3).
Our work is conducted on the classic pipeline
which has three modules, pair-wise hypothesis
alignment, confusion network construction, and
training. Now many work integrates neighboring
modules to avoid propagated errors to gain improved
performance. For example, Rosti et al (2008), and
Li et al (2009) combine the first and the second
module, and He and Toutanova (2009) combine all
modules into one directly. Nevertheless, the classic
structure also owns its merits. Because of the in-
dependence between modules, a system is relatively
simple to maintain, and improvements on each mod-
ule might contribute to final performance additively.
Based on our work, lattice-based minimum error
rate training (lattice-MERT) and minimum bayes
risk training techniques (Kumar et al, 2009) could
be adopted on the third module. And Feng et al
(2009) in the second module adopts a different data
structure called lattice which could directly use our
better many-to-many alignment for construction.
Experiments on the Chinese-to-English task on
two datasets use four objectives, IHMM probabil-
ity (Section 3.2.1), and alignment probability from
GIZA++ (Section 3.2.2) from two directions. Re-
sults show multi-objective optimization framework
efficiently integrates different information to gain
approximately 1 BLEU point improvement over a
strong baseline.
2 Background
We briefly give an introduction to confusion net-
works, and because the IHMM based alignment is
an important objective in our multi-objective frame-
work, here we also provide detailed definition of for-
mulas for completeness of content.
2.1 Confusion Network
Table 1 shows hypotheses h1 and h2 are aligned to
selected backbone h0. When alignment algorithm
obtains good enough results, the expected output
?he prefers apples? is included in its corresponding
confusion network in Figure 1. This suggests de-
veloping better alignment algorithm may help creat-
ing high-quality confusion networks. This also mo-
tivates us to use the BLEU of oracle hypotheses to
approximately measure the quality of a set of CNs.
We hereafter call it an oracle BLEU of a CN. See
more in Section 5.1.
h0 :he feels like apples
h1 :he prefer ? apples
h2 :him prefers to apples
Table 1: A toy example of hypothesis alignment, where
h0 is the backbone hypothesis. h1and h2 are aligned to
the backbone separately. The resulting confusion net-
work is in Figure 1.
A confusion network G = (V,E) is a directed
acyclic graph with a unique source and sink vertex,
536
b b b b
him
he
prefers
prefer
feel
?
like
like
b
apples
Figure 1: A classic confusion network, and the bold path
the expected output.
formally a weighted finite state automation (FSA),
where V is the set of nodes andE is the set of edges.
Each edge is restricted to attach to a single word as
well as an associated probability. A special mark ?
is a place-holder denoting no word here.
2.2 IHMM-based Alignment
Indirected Hidden Markov Model (IHMM) was
firstly proposed by He et. al (2008). Compared with
TER-based alignment performing literal matching,
IHMM supports synonym comparison in redefining
emission probabilities in an IHMM model.
Let f I = (f1, . . . fI) be a backbone hypothesis,
and eJ = (e1, . . . eJ) be a hypothesis aligned to the
backbone, both being English sentences in our ex-
periments. Let aJ = {a1, . . . aj} be an alignment.
Suppose the aj th word in f I is aligned to jth word
in eJ , and the conditional probability that the hy-
pothesis is generated by the backbone, shown in the
upper graph of Figure 3, is given by
p(f I , eJ) =
?
aJ
J?
j=1
{pt(aj |aj?1, I)po(ej |faj )}
(1)
The distortion probability pt(aj |aj?1, I) from po-
sition aj?1 to aj , relies on jumped distance, which
is computed as follows:
pt(i? |i, I) = c(i
?
? i)
?I
t=1 c(t? i)
(2)
The distortion parameters c(d) are grouped into
11 buckets, c(? ?4),c(?3),c(?2). . .c(5),c(? 6).
Because all the hypotheses in system combina-
tion are in the same language, the IHMM model
would support more monotonic alignments, and
non-monotonic alignments will be penalized.
c(d) = (1 + |d? 1|)?K , d = ?4 . . . 6 (3)
where K is tuned on held-out data.
Let p0 be the probability of jumping to a null
word state, which is also tuned on held-out data, and
the accurate transition probability becomes:
pt(i? |i, I) =
{
p0 if i? = null
(1? p0)pt(i
?
|i, I) otherwise
(4)
The output probability po(e|f) from the state
word f to the observation word e, also called trans-
lation probability, is a linear interpolation of se-
mantic similarity psem(e|f) and surface similarity
psur(e|f), and ? is the interpolation factor:
po(e|f) = ?psem(e|f) + (1? ?)psur(e|f) (5)
When calculating semantic similarity psem(e|f),
source sentence src is needed, and a bilingual prob-
abilistic dictionary pdic(w1|w2) is necessary.
psem(e|f) ?
?
c?src
pdic(c|f) ? pdic(e|c) (6)
Note that psem(e|f) has been updated with differ-
ent source sentences.
The surface similarity psur(e|f) is measured by
the literal matching rate:
psur(e, f) = exp{?[ LMP(f, e)max(|f |, |e|) ? 1]} (7)
where LMP(f, e) is the length of the longest
matched prefix, and ? is a smoothing parameter.
3 Multi-objective Optimization
Many decision making problems in the real world
consider more than one objective. One natural way
is to scalarize multiple objectives into one by assign-
ing it with a weight vector. This method allows a
simple optimization algorithm in many cases, while
in system combination, it would cause problems.
In the first module, in order to train suitable
weights of objectives, extra labeled data is needed,
besides that, the efficient Viterbi algorithm for
searching the optimal alignment would not work for
537
the alignment objectives in this work. More, the pa-
rameter training in the third module relies on the
CNs constructed from the output of the first mod-
ule, which increases the instability of the whole sys-
tem. Therefore, an unsupervised multi-objective al-
gorithm may be a good choice allowing for more
alignment information.
There exist other alternative optimization algo-
rithms in the multi-objective optimization frame-
work, though the evolutionary algorithm is adopted
here, we only introduce some general concepts.
3.1 Pareto Optimal Solutions
A general multi-objective optimization problem
consists of a number of objectives and is associated
with a number of constraints. Mathematically, the
problem can be written as follows (Deb, 2001)
Maximize fi(x) i = 1 . . .M
s.t. gj(x) ? 0 j = 1 . . . N
hk(x) = 0 k = 1 . . .K
where x denotes a potential solution, its structure re-
lying on different problems, and the number of con-
straints M,N,K depend on different problems. All
the functions fi, gj , hk map a solution x into a scalar.
We will explain them in terms of system combina-
tion.
In this work, we refer to x = {xi,j |xi,j ? {0, 1}}
as a potential alignment of a pair of hypotheses,
where xi,j is a boolean value to denote whether the
ith word in the first hypothesis is aligned to the jth
word in the second hypothesis. Here the definition of
x seems different from that of a in Formula 1, and
they could convert to each other. Using a line-based
access style, a matrix can be unfolded as a vector.
We refer to f as IHMM alignment probability (He et
al., 2008) and GIZA++ alignment probability (Chen
et al, 2009), total four objectives from two direc-
tions, and the larger the objectives, the better. The
gjs and hks serve as the role of checking if x repre-
sents a legal alignment. For instance, the subscripts
of xi,j are not in bounds.
Definition 1. Let x, x? be two potential align-
ments. If fi(x) ? fi(x?) holds for all i, we call
the alignment x dominates the alignment x?. If there
0
1
2
3
4
5
0 1 2 3 4 5
b
p3
b
p5
b
p7
b
p1
?p2
? p6
?p4
X: Reversed IHMM Probability (1e-8)
Y:D
irec
tIH
MM
Pro
bab
ility
(1e
-8)
Figure 2: Sample solutions with only two objectives.
Pareto Optimal Solutions p1, p3, p5, p7. Other points
p2, p4, p6 are dominated by at least one point in the Pareto
optimal solutions.
does not exist any alignment x?? to dominate x, we
call the alignment x to be non-dominated.
Definition 2. A alignment x is said to be Pareto
optimal if there is no other alignment x? found to
dominate x.
In Figure 2, p1 dominates p2, and p2 dominates
p4. To summarize, a point is dominated by the ones
on its upper and right side with ties. In this example,
p1, p3, p5, p7 are Pareto optimal.
In some cases, Pareto optimal solutions can be
used for good candidate solutions. Considering
the IHMM model, maximizing Y axis, the top-4
best alignments are p1, p2, p3, p4. But from the
view of Pareto optimal, the top-4 alignments would
be p1, p3, p5, p7 without order, which considers a
greater range than a single optimization model. In
our method, we just combine these Pareto optimal
solutions equally into a unique alignment (Section
3.3).
Our adopted multi-objective optimization search-
ing algorithm is the non-dominated sorting ge-
netic algorithm II (NSGA-II) (Deb et al, 2000;
Deb et al, 2002) with an open source software
(http://www.iitk.ac.in/kangal/codes.shtml). NSGA-
II has a complexity of O(mn2), wherem is the num-
ber of objectives and n is the population size in an
evolutionary algorithm.
3.2 Objectives in Evolutionary Algorithm
The optimization objectives in our experiments can
be categorized as an IHMM alignment probability
(He et al, 2008) and GIZA++ alignment probability
538
b b b
b b bO:
S: f1 f2 f3
e1 e2 e3
b b b
b b b
S:
O:
e1 e2 e3
f1 f2 f3
Backbone
Backbone
Figure 3: The same alignment (f1, e1)(f1, e2)(f2, e3) in
two IHMM models. The upper one is a typical example
in IHMM, and in the bottom one, because any word in the
observation is required not to correspond to two statuses,
it has a minor trouble. S: status sequence, O: observation
sequence.
(Chen et al, 2009), total four from two directions.
3.2.1 IHMM Probability
A typical IHMM alignment is demonstrated
in the upper graph of Figure 3, where a
backbone is acting the role of a status se-
quence. The unnormalized conditional align-
ment probability is [pt(1|null)] ? [pt(1|1)pt(2|1)] ?
[po(e1|f1)po(e2|f1)po(e3|f2)]. However, the same
alignment (f1, e1)(f1, e2)(f2, e3), if we change the
alignment direction, the backbone being observa-
tions, would be a bit different. We offer a minor
modification to Formula 1.
Look at the bottom graph of Figure 3, the obser-
vation f1 has two statuses, e1 and e2 at the same
time, it becomes ambiguous to compute the tran-
sitional probability between pt(3|1) and pt(3|2).
This is because IHMM algorithm deals with one-
to-many alignments, and MOEA permits many-to-
many alignments.
We hence empirically modify the IHMM model
to support many-to-many alignments. A new status
is defined, rather than a single position pt(j|i), but
as a set of positions pt({j}|{i}). The positions in
one status need not to be adjacent to each other.
The redefined transitional probability
pt({j}|{i}) =
1
|{j}| ? |{i}|
?
i,j
pt(j|i)
The redefined emission probability
po(j|{i}) =
?
i
po(j|i)
We need to note that there is no guarantee on
the closed property of probabilities, though these
approximations prove to be effective in a practical
sense. Straightforwardly, when there is only one po-
sition in a new status, the expanded IHMM degener-
ates to the standard IHMM.
Let us return to the second IHMM ex-
ample. The new probability becomes
[pt(1|null)pt(2|null)] ? [12pt(3|1)pt(3|2) ?pt(null|3)] ?
[po(f1|e1)po(f1|e2)po(f2|e3)po(f3|null)].
3.2.2 Alignment Probability
GIZA++ considers very different and more in-
formation in alignment, we attempt to utilize them.
All probabilities appearing in below formulas can be
looked up in GIZA++.
Given a pair of hypotheses f I = (f1, . . . fI),
eJ = (e1, . . . eJ), and their alignment a, the align-
ment probability could be calculated as follows
pGiza(eJ |f I ,a) =
?
ei
T (ei|f
I ,a)
T (ei|f
I ,a) =
{
n(?i|ei)
?
(j,i)?a t(ei|fj)a(j|i)/?i if?i 6= 0
n(0|ei)t(ei|null)a(0|i) otherwise
?i = |{j|(i, j) ? a}|
where ?i is the fertility number, t(e|c) the transla-
tion probability for the word pair, z(j|i) alignment
probability to show how likely a target word at posi-
tion i could be translated into a source word at posi-
tion j, and n(?|e) is the fertility probability to show
how likely a given target word e is translated into ?
source words.
In order to increase the coverage of words, we col-
lect all the hypothesis pairs in both the tuning set
and the test set and feed them into GIZA++. This
is an off-line operation, which makes it not suitable
for an online translation system. In some circum-
stances, users submit a pile of documents in the hope
of high-quality translations, thus more useful knowl-
edge sources would be helpful. In our experiments,
a pure GIZA++ based system combination does not
perform as well as IHMM based, but does benefit
the final translation quality if combined in our multi-
objective optimization framework.
539
3.3 Configuration of Evolutionary Algorithm
3.3.1 Encoding
Given a sentence pair <f I , eJ>, we define a two-
dimensional matrix x = {zi,j |zij ? {0, 1}} to en-
code a set of possible alignments. Using a line-based
access style, the matrix could be unfolded as a vector
with |I| ? |J | bits of length.
3.3.2 Initialization
Because in NSGA-II software the initial popu-
lation are generated at random. In order to make
NSGA-II more consistent and flexible, better initial
seeds should be fed with, thus we combine an ex-
isting word alignment results as input. Here we use
together two N-best lists generated from directional
HMM and reversed HMM respectively for initializa-
tion.
3.3.3 Normalization of Pareto Optimal
Solutions
Multi-objective optimization algorithms do not
pose weights on objectives, thus they output a set
of so-called Pareto optimal solutions, each of which
is a many-to-many alignment. We can understand
them as an N-best alignment list without explicit
preferences. We also empirically compare it with the
idea that directly cuts an N-best list from the IHMM
based alignment.
We describe a two-stage strategy for normaliza-
tion. Firstly, we use a simple and effective voting
strategy to combine a set of many-to-many align-
ments into a single many-to-many alignment, and
Secondly we normalize it into a one-to-one align-
ment for confusion network construction. In the first
stage, we count the number of word-to-word align-
ments on each position pair (i, j). If there is more
than a half number of alignments, then we output 1,
otherwise 0. In the second stage, if any word relates
to more than one word alignment, the one with the
highest posterior probability is selected (He et al,
2008; Feng et al, 2009). The posterior probabili-
ties can be computed in a classic forward-backward
procedure in IHMM (He et al, 2008).
4 Training and Decoding
Our work does not change the classic pipeline, thus
the model and features are nearly identical to the
ones in (Rosti et al, 2007b; He et al, 2008), which
are modeled in a log-linear fashion in Eq. 8. Trans-
lation on a CN is just a concatenation of edges tra-
versed, on which 4 categories of features are defined.
1. word posterior probabilities. In Eq. 8,
p(w|sys, span) are word confidence scores. If
the word w comes from the kth hypothesis of
thesys-th system, the raw score should be 1k+1 ,and then it would be normalized by the same
sys and span. The same word coming from
different systems owns a different score, so
there are sys system weights ?sys.
2. logarithm of language model score, L(h).
3. number of null edge, Numnull.
4. number of words, Numw.
log(h) =
?
span log(
?
sys ?sysp(w|sys, span))
+ w0L(h) + w1Numnull + w2Numw
(8)
Decoding a confusion network is straightforward,
traversing each node from left to right, and the beam
search algorithm will retain for each node an N-
best list. The final N-best can be acquired following
(Huang and Chiang, 2005).
The training process follows minimum error rate
training (MERT) described in (Och, 2003; Koehn et
al., 2003). In each iteration, the Powell algorithm
would attempt to predict the optimal parameters on
the cumulative N-best list.
5 Experiments
We evaluate our method in two datasets in the
Chinese-to-English task. In the first one, NIST MT
2002 and 2005 are used for tuning and testing re-
spectively, and in the second, the newswire part of
MT 2006 and 2008 are for tuning and testing. A 5-
gram language model is trained on the Xinhua por-
tion of the Gigaword corpus. We report the case-
sensitive NIST-BLEU score.
Four single machine translation systems partici-
pating in the system combination consist of a BTG-
based system using a Max-Entropy based reordering
model, a hierarchical phrase-based system, a Moses
decoder and a syntax-based system. 10-best unique
hypotheses from a single system on the development
540
SYSTEM MT 2005 MT 2008(news)
best single 0.3207 0.3016
IHMM* 0.3585(+3.78%) 0.3263(+2.47%)
IncIHMM 0.3639(+4.32%) 0.3320(+3.04%)
GIZA++ 0.3438(+2.31%) 0.3166(+1.50%)
PPBD 0.3619(+4.10%) 0.3306(+2.90%)
N-best IHMM 0.3590(+3.83%) 0.3270(+2.54%)
dH+rH 0.3604 0.3284
dH+dT 0.3610 0.3290
dH+rH+dT 0.3609 0.3289
dH+rH+rT 0.3630?(+4.27%) 0.3320?(+3.04%)
dH+rH+dT+rT 0.3682??(+4.75%) 0.3369??(+3.53%)
Table 2: PPBD is a posterior probabilistic-based decod-
ing (section 5.3). N-best IHMM simulates the Pareto op-
timal solutions in our method (section 5.3). The last five
systems adopt different objective combinations. The im-
provement percents in parentheses are compared to the
best single. dH: directed IHMM, rH: reversed IHMM,
dT: directed translation probability, rT: reversed transla-
tion probability. ?? significance at 0.01 level, and ? sig-
nificance at 0.05 level over the IHMM model.
and test sets are collected as the input of the system
combination.
Our baseline systems are described as follows.
Two main baseline systems are IHMM based and in-
cremental IHMM (Li et al, 2009). The first system
differs from our method just in hypothesis alignment
algorithm, and the second combines the first and sec-
ond module of the system combination pipeline.
Because our method utilizes bidirectional infor-
mation, we also provide another two alternative
systems for comparison, which are GIZA++ based
alignment and the posterior probability based align-
ment (Liang et al, 2006). Finally, we also provide
an N-best alignment IHMM system, which com-
bines an N-best alignment list to simulate the Pareto
optimal solutions in our method.
The method that linearly combines all objectives
is not listed as our baseline like (Duh et al, 2012)
does, because their algorithm finds the best weighted
solution in a fixed and small solution set, while
in our problem, the solution space is a trellis-style
structure consisting of an exponential number of so-
lutions, and no efficient algorithms apply here.
The IHMM based alignment utilizes typical set-
tings (He et al, 2008; Feng et al, 2009). The
smoothing factor for the surface similarity model,
and ? = 3 the controlling factor for the distor-
tion model, K = 2. The bilingual probabilistic
dictionary is trained in the FBIS corpus which in-
cludes about 230k parallel sentence pairs. GIZA++
based system is to run GIZA++ from two directions
to align all the hypotheses, and make the intersec-
tion using grow-diag-final heuristics (Koehn et al,
2003). The many-to-many alignments are normal-
ized with the same method with ours. Our system
employs NSGA-II software to realize the MOEA al-
gorithm. The main parameters, generation number,
cross probability and mutation probability, and pop-
ulation size, are empirically set as 100, 0.9, 0.001
and 40, and we examine the influence of difference
populations sizes in the full system combination.
5.1 The Quality of Confusion Networks
This experiment shows the relationship between hy-
pothesis alignment and confusion network. Intu-
itively, we expect a better hypothesis alignment
would reduce the error in constructing confusion
networks, and then improve the final translation
quality.
We first use the alignment error rate (AER) (Och
and Ney, 2000), which is widely used to measure
the quality of hypothesis alignment. The smaller,
the better. For convenience, we only examine exact
literal matching. IHMM based alignment reaches
around 0.15 in AER, and our method 0.145.
As the AER may not vividly reflect the relations
between alignment and the final BLEU of systems,
and the quality of confusion network is hard to mea-
sure directly, we assume that the quality of confu-
sion networks could be measured by the oracle hy-
potheses that could be generated from them. We test
the BLEU of the oracle hypotheses.
From this angle, we demonstrate several oracle
BLEU of CNs generated from some conventional
alignment algorithms. The results are shown in Ta-
ble 3.
We find the confusion network from IHMM based
alignment (He et al, 2008) is better than that from
TER based alignment (Rosti et al, 2007b) by about
1 point in both two datasets. These quantities agree
with the final improvements in the BLEU score in
(He et al, 2008). As confusion networks from
MOEA based alignment also show superiority over
541
alignment MT02 MT05
GIZA++ 0.5690 0.5228
TER 0.5720 0.5270
IHMM 0.5883 0.5382
IncIHMM 0.5931 0.5453
MOEA 0.6017 0.5526
Table 3: Oracle BLEUs of CNs. GIZA++: invoking
GIZA++ software. TER: minimum translation edit rate.
IHMM: indirect hidden markov model. IncIHMM: in-
cremental indirect hidden markov model. MOEA: multi-
objective evolution algorithm.
that from IHMM based in the oracle BLEU, we ex-
pect our final translation quality would be improved.
In Table 3, GIZA++ and TER perform simi-
larly, because the former is more capable of tackling
many-to-many alignments over the latter, while lat-
ter based might obtain relatively more precise align-
ment information. Both of the two do not consider
synonym matching compared to IHMM.
Our method and IncIHMM overpass IHMM on
this metric due to different strategies. Obtaining bet-
ter hypothesis alignment or better construction of
confusion networks benefit the quality of CNs.
5.2 Different Objective Combinations
As our framework is convenient to support different
alignment information, we test the influence of dif-
ferent objective combinations to the final translation
quality. We adopt four objectives to depict the can-
didate alignment, directed IHMM probability (dH),
reversed IHMM probability (rH), directed alignment
probability (dT), and reversed alignment probability
(rT). Table 2 demonstrates all the results.
We can see that the IHMM based system out-
performs the GIZA++ based system by about 1-1.5
points in BLEU, which agrees with the difference of
oracle BLEU in Table 1. From (He et al, 2008), the
IHMM based system outperforms the TER based by
1 point, which also agrees with our results in Table
1. Our system, using dH + rH + dT + rT, improves
BLEU score by about 1 points over the IHMM based
system. This comparison verifies our assumption,
improving the quality of the confusion network does
improve system performance.
The different feature combinations exhibit inter-
esting results. The system with dH + rH + dT is
0.05 point better than the system with dH + rH, and
the system dH + rH + rT is 0.3 point better than sys-
tem with dH + rH, so the contributions of feature
dT and rT are 0.05 and 0.3 respectively. While the
two features are used together in the fourth system,
the contribution is about 0.8 point, rather than 0.35.
This phenomenon also proves the correlations be-
tween different features.
Our method explores a way to integrate GIZA++
and IHMM, and is supportive of useful features.
Compared to the classic and powerful IHMM based
system, we obtained an improvement of 0.97 points
on MT 05 and 1.06 points on news of MT 2008,
and equivalently over the best single system by 4.75
points and 3.53 points respectively. More, compared
with the incremental IHMM, our system also shows
moderate improvement, though not much. We hope
these two ideas could be effectively combined in the
future work.
5.3 Comparison with Other Bi-directional
Alignment Methods
Our method introduces multiple alignment infor-
mation into system combination to obtain improve-
ments, thus it would be interesting to explore other
alternative methods for utilizing this information.
We provide three alternative methods similar to our
motivations, and they fall into two categories.
The first category is from the angle of bi-
directional alignment. We use GiZA++ alignment
and the posterior probability decoding-based align-
ment for comparison. The basic idea for the lat-
ter is setting a word-to-word alignment xi,j as 1,
if its approximate posterior marginal probability
q(xi,j , x) = pd(xi,j |x, ?d) ? pr(xi,j |x, ?r) is greater
than a threshold ?, where pd and pr are posterior
marginal probabilities from directed and reversed
IHMM models, which could be conveniently com-
puted with a forward-backward algorithm, and the ?
is tuned on a validation-set optimized data. We just
list some ? values to examine its best performance
shown in Table 4.
The second class is because our method combines
the Pareto optimal solutions that consist of several
candidate alignments, thus for fairness we also use
a 100-best outputs from the directed IHMM model
and conduct the same normalization technique.
The general results are shown in Table 2. We can
542
? MT 2005 MT 2008
IHMM 0.3585 0.3263
0.15 0.3556 0.3391
0.2 0.3619 0.3306
0.25 0.3575 0.3278
0.3 0.3608 0.3259
Table 4: Posterior decoding. When threshold ? are set
to suitable values, simple bi-directional alignment could
overpass the baseline.
see that, GIZA++ leads to the worst performance,
which can be explained as GIZA++ does not support
synonym matching like IHMM. The N-best IHMM
has a minor improvement over the IHMM method.
We found differences in the N-best list are not obvi-
ous enough. In comparison, the posterior decoding
method brings relatively significant improvements
on both datasets. However, the threshold ? must
be selected suitably. Table 4 lists the ideal results,
which will be hampered when tuning on a validation
set.
All of the three candidate methods can not conve-
niently support extra alignment information, and a
linear model poses restrictions on features to get an
efficient decoding, the multi-objective optimization
may be a good selection as an inference algorithm in
many circumstances.
5.4 Population Size
We test the influence of final translation quality and
time consumed by different population size.
population BLEU
size MT 2005
20 0.3597
40 0.3682
60 0.3655
Table 5: Big population size consumes more CPU time.
In our experiments, we use a multi-thread technique to
speed up the alignment, and choose 40 as the parameter
to leverage the time and BLEU.
We expect enlarging the population size would
improve the translation quality, but the BLEU in
population size set as 60 does not overpass when set
as 40. We conjecture that, in our code, if the N-best
size from IHMM (we set as 50-best) does not reach
the population size, we would use randomly gener-
ated seeds, which may hamper the performance of
MOEA. We also tried a larger population in MOEA,
but did not receive obvious improvement on perfor-
mance.
We exerted a hard restriction on the genes in evo-
lutionary algorithm, that is many-to-many discon-
tiguous alignment is forbidden. This trick speeds up
running by about 20 times, and does not harm sys-
tem performance. Now our method runs about 0.9
seconds to align a pair of hypotheses. In practice,
we utilize multi-thread to speed up.
6 Conclusion
In this paper, we explore a multi-objective frame-
work to conveniently support more useful alignment
objectives to improve the hypothesis alignment. By
a minor modification of the first module in the
classic pipeline, we successfully combine GIZA++
and IHMM to obtain significant improvement over
a powerful and state-of-the-art IHMM based sys-
tem. In comparison with another genre of improving
system combination by combing adjacent modules
of the pipeline, more powerful incremental IHMM
here, our system also show moderate improvement.
Though, our best system may not overpass He and
Toutanova (2009) who combine all the modules into
a unified training procedure, we believe our method
could boost many work on the higher modules of the
pipeline to obtain a further improvement to match
their work.
7 Acknowledgement
This research is partially supported by Air Force
Office of Scientific Research under grant FA9550-
10-1-0335, the National Science Foundation under
grant IIS RI-small 1218863 and a Google research
award. We thank the anonymous reviewers for their
insightful comments.
References
B Bangalore, German Bordel, and Giuseppe Riccardi.
2001. Computing consensus translation from multi-
ple machine translation systems. In Automatic Speech
Recognition and Understanding.
Yidong Chen, Xiaodong Shi, Changle Zhou, and
Qingyang Hong. 2009. A word alignment
543
model based on multiobjective evolutionary algo-
rithms. Computers and Mathematics with Applica-
tions, 57.
Kalyanmoy Deb, Samir Agrawal, Amrit Pratap, and
Tanaka Meyarivan. 2000. A fast elitist non-dominated
sorting genetic algorithm for multi-objective optimiza-
tion: Nsga-ii. Lecture notes in computer science,
1917:849?858.
Kalyanmoy Deb, Amrit Pratap, Sameer Agarwal, and
TAMT Meyarivan. 2002. A fast and elitist multiob-
jective genetic algorithm: Nsga-ii. Evolutionary Com-
putation, IEEE Transactions on, 6(2):182?197.
Kalyanmoy Deb. 2001. Multi-objective optimization.
Multi-objective optimization using evolutionary algo-
rithms, pages 13?46.
John DeNero, Shankar Kumar, Ciprian Chelba, and Franz
Och. 2010. Model combination for machine transla-
tion. In Proc. of NAACL, pages 975?983.
Kevin Duh, Katsuhito Sudoh, Xianchao Wu, Hajime
Tsukada, and Masaaki Nagata. 2012. Learning to
translate with multiple objectives. In Proc. of ACL,
pages 1?10.
Andries P Engelbrecht. 2005. Fundamentals of compu-
tational swarm intelligence, volume 1. Wiley Chich-
ester.
Yang Feng, Yang Liu, Haitao Mi, Qun Liu, and Ya-
juan L?. 2009. Lattice-based system combination for
statistical machine translation. In Proc. of EMNLP,
EMNLP ?09.
G David Forney Jr. 1973. The viterbi algorithm. Proc.
of the IEEE, 61(3):268?278.
Michael Pilegaard Hansen. 1997. Tabu search for mul-
tiobjective optimization: Mots. In Proc. of Multiple
Criteria Decision Making, pages 574?586.
Xiaodong He and Kristina Toutanova. 2009. Joint opti-
mization for machine translation system combination.
In Proc. of EMNLP.
Xiaodong He, Mei Yang, Jianfeng Gao, Patrick Nguyen,
and Robert Moore. 2008. Indirect-hmm-based hy-
pothesis alignment for combining outputs from ma-
chine translation systems. In Proc. of EMNLP.
Liang Huang and David Chiang. 2005. Better k-best
parsing. In Proc. of IWPT.
Fei Huang and Kishore Papineni. 2007. Hierarchical
system combination for machine translation. In Proc.
of EMNLP-CoNLL.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Proc.
of NAACL.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, et al 2007. Moses: Open source toolkit for sta-
tistical machine translation. In Proc. of ACL: Poster,
pages 177?180.
Shankar Kumar, Wolfgang Macherey, Chris Dyer, and
Franz Och. 2009. Efficient minimum error rate train-
ing and minimum bayes-risk decoding for translation
hypergraphs and lattices. In Proc. of Joint ACL and
AFNLP.
Zhifei Li and Sanjeev Khudanpur. 2009. Forest rerank-
ing for machine translation with the perceptron algo-
rithm. GALE book chapter on MT From Text.
Chi-Ho Li, Xiaodong He, Yupeng Liu, and Ning Xi.
2009. Incremental hmm alignment for mt system com-
bination. In Proc. of Joint ACL and AFNLP.
Percy Liang, Ben Taskar, and Dan Klein. 2006. Align-
ment by agreement. In Proc. of NAACL.
Evgeny Matusov, Nicola Ueffing, and Hermann Ney.
2006. Computing consensus translation from multiple
machine translation systems using enhanced hypothe-
ses alignment. In Proc. of EACL.
Haitao Mi, Liang Huang, and Qun Liu. 2008. Forest-
based translation. Proc. of ACL-08: HLT, pages 192?
199.
F. J. Och and H. Ney. 2000. Improved statistical align-
ment models. pages 440?447, October.
Franz Josef Och. 2003. Minimum error rate training in
statistical machine translation. In Proc. of ACL, pages
160?167.
Adam Pauls, John DeNero, and Dan Klein. 2009. Con-
sensus training for consensus decoding in machine
translation. In Proc. of EMNLP.
Antti-Veikko I Rosti, Necip Fazil Ayan, Bing Xiang, Spy-
ros Matsoukas, Richard Schwartz, and Bonnie Dorr.
2007a. Combining outputs from multiple machine
translation systems. In Proc. of NAACL-HLT.
Antti-Veikko I Rosti, Spyros Matsoukas, and Richard
Schwartz. 2007b. Improved word-level system com-
bination for machine translation. In Proc. of ACL, vol-
ume 45.
Antti-Veikko I Rosti, Bing Zhang, Spyros Matsoukas,
and Richard Schwartz. 2008. Incremental hypothesis
alignment for building confusion networks with appli-
cation to machine translation system combination. In
Proc. of WSMT.
Paolo Serafini. 1994. Simulated annealing for multi ob-
jective optimization problems. In Proc. of Multiple
Criteria Decision Making, pages 283?292. Springer.
Khe Chai Sim, William J Byrne, Mark JF Gales, Hichem
Sahbi, and Phil C Woodland. 2007. Consensus net-
work decoding for statistical machine translation sys-
tem combination. In Proc. of ICASSP, volume 4.
Yong Zhao and Xiaodong He. 2009. Using n-gram based
features for machine translation system combination.
In Proc. of NAACL: Short Papers, pages 205?208.
544
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 851?856,
Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational Linguistics
A Corpus Level MIRA Tuning Strategy for Machine Translation
Ming Tan, Tian Xia, Shaojun Wang
Wright State University
3640 Colonel Glenn Hwy,
Dayton, OH 45435 USA
{tan.6, xia.7, shaojun.wang}
@wright.edu
Bowen Zhou
IBM T.J. Watson Research Center
1101 Kitchawan Rd,
Yorktown Heights, NY 10598 USA
zhou@us.ibm.com
Abstract
MIRA based tuning methods have been
widely used in statistical machine translation
(SMT) system with a large number of fea-
tures. Since the corpus-level BLEU is not de-
composable, these MIRA approaches usually
define a variety of heuristic-driven sentence-
level BLEUs in their model losses. Instead,
we present a new MIRA method, which em-
ploys an exact corpus-level BLEU to com-
pute the model loss. Our method is simpler in
implementation. Experiments on Chinese-to-
English translation show its effectiveness over
two state-of-the-art MIRA implementations.
1 Introduction
Margin infused relaxed algorithm (MIRA) has been
widely adopted for the parameter optimization in
SMT with a large feature size (Watanabe et al, 2007;
Chiang et al, 2008; Chiang et al, 2009; Chiang,
2012; Eidelman, 2012; Cherry and Foster, 2012).
Since BLEU is defined on the corpus, and not de-
composed into sentences, most MIRA approaches
consider a variety of sentence-level BLEUs for the
model losses, many of which are heuristic-driven
(Watanabe et al, 2007; Chiang et al, 2008; Chi-
ang et al, 2009; Chiang, 2012; Cherry and Foster,
2012). The sentence-level BLEU appearing in the
objective is generally based on a pseudo-document,
which may not precisely reflect the corpus-level
BLEU. We believe that this mismatch could poten-
tially harm the performance. To avoid the sentence
BLEU, the work in (Haddow et al, 2011) proposed
to process sentences in small batches. The authors
adopted a Gibbs sampling (Arun et al, 2009) tech-
nique to search the hope and fear hypotheses, and
they did not compare with MIRA. Watanabe (2012)
also tuned the parameters with small batches of sen-
tences and optimized a hinge loss not explicitly re-
lated to BLEU using stochastic gradient descent.
Both approaches introduced additional complexities
over baseline MIRA approaches.
In contrast, we propose a remarkably simple but
efficient batch MIRA approach which exploits the
exact corpus-level BLEU to compute model losses.
We search for a hope and a fear hypotheses for the
corpus with a straightforward approach and mini-
mize the structured hinge loss defined on them. The
experiments show that our method consistently out-
performs two state-of-the-art MIRAs in Chinese-to-
English translation tasks with a moderate margin.
2 Margin Infused Relaxed Algorithm
We optimize the model parameters based on N-best
lists. Our development (dev) set is a set of triples
{(fi, ei , ri)}Mi=1, where fi is a source-language sen-
tence, corresponded by a list of target-language hy-
potheses ei = {eij}
N(fi)
j=1 , with a number of refer-
ences ri. h(e ij ) is a feature vector. Generally, most
decoders return a top-1 candidate as the transla-
tion result, such that e?i(w) = arg maxj w ? h(eij ),
where w are the model parameters. In this paper, we
aim at optimizing the BLEU score (Papineni et al,
2002).
MIRA is an instance of online learning which as-
sumes an overlap of the decoding procedure and the
parameter optimization procedure. For example in
(Crammer et al, 2006; Chiang et al, 2008), MIRA
851
is performed after an input sentence are decoded,
and the next sentence is decoded with the updated
parameters. The objective for each sentence i is,
min
w
1
2
||w ?w?||2 + C ? li(w) (1)
li(w) = max
eij
{b(e?i )? b(eij)
?w ? [h(e?i )? h(eij )]} (2)
where e?i ? ei is a hope candidate, w
? is the pa-
rameter vector from the last sentence. Since MIRA
defines its objective only based on the current sen-
tence, b(?) is a sentence-level BLEU.
Most MIRA algorithms need a deliberate defini-
tion of b(?), since BLEU cannot be decomposed into
sentences. The types of the sentence BLEU calcula-
tion includes: (a) a smoothed version of BLEU for
eij (Liang et al, 2006), (b) fit eij into a pseudo-
document considering the history (Chiang et al,
2008; Chiang, 2012), (c) use eij to replace the corre-
sponding hypothesis in the oracles (Watanabe et al,
2007). The sentence-level BLEU sometimes per-
plexes the algorithms and results in a mismatch with
the corpus-level BLEU.
3 Corpus-level MIRA
3.1 Algorithm
We propose a batch tuning strategy, corpus-level
MIRA (c-MIRA), in which an objective is not built
upon a hinge loss of a single sentence, but upon that
of the entire corpus.
The online MIRAs are difficult to parallelize.
Therefore, similar to the batch MIRA in (Cherry and
Foster, 2012), we conduct the batch tuning by re-
peating the following steps: (a) Decode source sen-
tences (in parallel) and obtain {ei}Mi=1, (b) Merge
{ei}Mi=1 with the one from the previous iteration, (c)
Invoke Algorithm 1.
We define E = (eE,1 , eE,2 , ..., eE,M ) as a corpus
hypothesis, with H (E) =
1
M
M?
i=1
h(eE,i). eE,i is the
hypothesis of the source sentence fi covered by E .
E is corresponded to a corpus-level BLEU, which
we ultimately want to optimize. Following MIRA
formulated in (Crammer et al, 2006; Chiang et al,
2008), c-MIRA repeatedly optimizes,
min
w
1
2
||w ?w?||2 + C ? lcorpus(w) (3)
lcorpus(w) = max
E
{B(E?)? B(E)
?w ? [H(E?)?H(E)]} (4)
where B(?) is a corpus-level BLEU. E? is a hope
hypothesis. E ? L, where L is the hypothesis space
of the entire corpus, and |L| = |e1| ? ? ? |eM|.
Algorithm 1 Corpus-Level MIRA
Require: {(fi, ei , ri)}Mi=1, w0, C
1: for t = 1 ? ? ?T do
2: E? = {} ,E ? = {} . Initialize the hope and fear
3: for i = 1 ? ? ?M do
4: eE?,i = arg max
eij
[wt?1 ? h(eij) + b?(eij )]
5: eE?,i = arg max
eij
[wt?1 ? h(eij)? b?(eij )]
6: E? ? E? + {eE?,i} . Build the hope
7: E ? ? E ? + {eE?,i} . Build the fear
8: end for
9: 4B = B(E?)? B(E ?) . the BLEU difference
10: 4H = H(E ?)?H(E?) . the feature difference
11: ? = min
[
C, 4B+wt?1?4H||4H||2
]
12: wt = wt?1 ? ? ? 4H
13: w?t =
1
t+ 1
t?
t=0
wt
14: end for
15: return w?t with the optimal BLEU on the dev set.
c-MIRA can be regarded as a standard MIRA,
in which there is only one single triple (F ,L,R),
where F and R are the source and reference of
the corpus respectively. Eq. 3 is equivalent to a
quadratic programming with |L| constraints. Cram-
mer et al (2006) show that a single constraint with
one hope E? and one fear E ? admits a closed-form
update and performs well. We denote one execution
of the outer loop as an epoch. The hope and fear
are updated in each epoch. Similar to (Chiang et al,
2008), the hope and fear hypotheses are defined as
following,
E? = max
E
[w ?H(E) + B(E)] (5)
E ? = max
E
[w ?H(E)? B(E)] (6)
Eq. 5 and 6 find the hypotheses with the best and
worse BLEU that the decoder can easily achieve. It
is unnecessary to search the entire space of L for
precise solution E?and E ?, because MIRA only at-
852
tempts to separate the hope from the fear by a mar-
gin proportional to their BLEU differentials (Cherry
and Foster, 2012). We just construct E?and E ? re-
spectively by,
eE?,i = max
ei,j
[w ? h(ei,j) + b?(ei,j)]
eE ?,i = max
ei,j
[w ? h(ei,j)? b?(ei,j)]
where b? is simply a BLEU with add one smoothing
(Lin and Och, 2004). A smoothed BLEU is good
enough to pick up a ?satisfying? pair of hope and
fear. However, the updating step (Line 11) uses the
corpus-level BLEU.
3.2 Justification
c-MIRA treats a corpus as one sentence for decod-
ing, while conventional decoders process sentences
one by one. We show the optimal solutions from the
two methods are equivalent theoretically.
We follow the notations in (Och and Ney,
2002). We search a hypothesis on corpus E =
{e1 ,k1 , e2 ,k2 , ..., eM ,kM } with the highest probabil-
ity given the source corpus F = {f1, f2, ..., fM},
E = arg max
E
logP (E|F)
= arg max
E
(
w ?
M?
i=1
h(ei,ki )?
M?
i=1
log(Zi)
)
(7)
= {arg max
ei,ki
w ? h(ei,ki )}
M
i=1 (8)
where Zi =
?N(fi)
j=1 exp(w ? h(ei ,j )), which is a
constant with respective to E . Eq. 7 shows that
the feature vector of E is determined by the sum of
each candidate?s feature vectors. Also, the model
score can be decomposed into each sentence in Eq.
8, which shows that decoding all sentences together
equals to decoding one by one.
We also show that if the metric is decomposable,
the loss in c-MIRA is actually the sum of the hinge
loss li(w) in structural SVM (Tsochantaridis et al,
2004; Cherry and Foster, 2012). We assume B(eij)
to be the metric of a sentence hypothesis, then the
loss of c-MIRA in Eq. 4 is,
lcorpus(w) ? max
E?
M?
i=1
[B(ei,kE? )?B(ei,kE? )
?w?h(ei,kE? ) + w ? h(ei,kE? )]
=
M?
i=1
max
eij
[B(ei,kE? )?B(eij)
?w?h(ei,kE? ) + w ? h(eij)] =
M?
i=1
li(w)
Instead of adopting a cutting-plane algorithm
(Tsochantaridis et al, 2004), we optimize the same
loss with a MIRA pattern in a simpler way. How-
ever, since BLEU is not decomposable, the struc-
tural SVM (Cherry and Foster, 2012) uses an inter-
polated sentence BLEU (Liang et al, 2006). Al-
though Algorithm 1 has an outlook similar to the
batch-MIRA algorithm in (Cherry and Foster, 2012),
their loss definitions differ fundamentally. Batch
MIRA basically uses a sentence-level loss, and they
also follow the sentence-by-sentence tuning pattern.
In the future work, we will compare structural SVM
and c-MIRA under decomposable metrics like WER
or SSER (Och and Ney, 2002).
4 Experiments and Analysis
We first evaluate c-MIRA in a iterative batch tuning
procedure in a Chinese-to-English machine transla-
tion system with 228 features. Second, we show c-
MIRA is also effective in the re-ranking task with
more than 50,000 features.
In both experiments, we compare c-MIRA and
three baselines: (1) MERT (Och, 2003), (2) Chiang
et al?s MIRA (MIRA1) in (Chiang et al, 2008). (3)
batch-MIRA (MIRA2) in (Cherry and Foster, 2012).
Here, we roughly choose C with the best BLEU on
dev set, from {0.1, 0.01, 0.001, 0.0001, 0.00001}.
We convert Chiang et al?s MIRA to the batch mode
described in section 3.1. So the only difference be-
tween MIRA1 and MIRA2 is: MIRA1 obtains mul-
tiple constraints before optimization, while MIRA2
only uses one constraint. We implement MERT
and MIRA1, and directly use MIRA2 from Moses
(Koehn et al, 2007). We conduct experiments in a
server of 8-cores with 2.5GHz Opteron. We set the
maximum number of epochs as we generally do not
observe an obvious increase on the dev set BLEU.
853
MERT MIRA1 MIRA2 c-MIRA
C 0.0001 0.001 0.0001
8 dev 34.80 34.70 34.73 34.70
feat. 04 31.92 31.81 31.73 31.83
05 28.85 28.94 28.71 28.92
C 0.001 0.001 0.001
all dev 34.61 35.24 35.14 35.56
feat. 04 31.76 32.25 32.04 32.57+
05 28.85 29.43 29.37 29.41
06news 30.91 31.43 31.24 31.82+
06others 27.43 28.01 28.13 28.45
08news 25.62 26.11 26.03 26.40
08others 16.22 16.66 16.46 17.10+
Table 1: BLEUs (%) on the dev and test sets with 8 dense
features only and all features. The significant symbols (+
at 0.05 level) are compared with MIRA2
The epoch size for MIRA1 and MIRA2 is 40, while
the one for c-MIRA is 400. c-MIRA runs more
epochs, because we update the parameters by much
fewer times. However, we can implement Line 3?8
in Algorithm 1 in multi-thread (we use eight threads
in the following experiments), which makes our al-
gorithm much faster. Also, we increase the epoch
sizes of MIRA1 and MIRA2 to 400, and find there
is no improvement on their performance.
4.1 Iterative Batch Training
In this experiment, we conduct the batch tuning pro-
cedure shown in section 3. We align the FBIS data
including about 230K sentence pairs with GIZA++
for extracting grammar, and train a 4-gram language
model on the Xinhua portion of Gigaword corpus. A
hierarchical phrase-based model (Chiang, 2007) is
tuned on NIST MT 2002, which has 878 sentences,
and tested on MT 2004, 2005, 2006, and 2008. All
features used here, besides eight basic ones in (Chi-
ang, 2007), consists of an extra 220 group features.
We design such feature templates to group gram-
mar by the length of source side and target side,
(feat type, a ? src side ? b, c ? tgt side ? d) ,
where feat type denotes any of relative frequency,
reversed relative frequency, lexical probability and
reversed lexical probability, and [a, b], [c, d] enumer-
ate all possible subranges of [1, 10], as the maximum
MERT MIRA1 MIRA2 c-MIRA
R. T. 25.8min 16.0min 7.3min 7.8min
Table 2: Running time.
length on each side of a hierarchical grammar is lim-
ited to 10. There are 4? 55 extra group features. We
also set the size of N-best list per sentence before
merge as 200.
All methods use 30 decoding iterations. We se-
lect the iteration with the best BLEU of the dev set
for testing. We present the BLEU scores in Table 1
on two feature settings: (1) 8 basic features only, and
(2) all 228 features. In the first case, due to the small
feature size, MERT can get a better BLEU of the
dev set, and all MIRA algorithms fails to generally
beat MERT on the test set. However, as the feature
size increase to 228, MERT degrades on the dev-set
BLEU, and also become worse on test sets, while
MIRA algorithms improve on the dev set expect-
edly. MIRA1 performs better than MIRA2, proba-
bly because of more constraints. c-MIRA can mod-
erately improve BLEU by 0.2?0.4 from MIRA1
and 0.2?0.6 from MIRA2. This might indicate that
a loss defined on corpus is more accurate than the
one defined on sentence. Table 2 lists the running
time. Only MIRA2 is fairly faster than c-MIRA be-
cause of more epochs in c-MIRA.
4.2 Re-ranking Experiments
The baseline system is a state-of-the-art hierarchi-
cal phrase-based system, and trained on six million
parallel sentences corpora available to the DARPA
BOLT Chinese-English task. This system includes
51 dense features (including translation probabili-
ties, provenance features, etc.) and about 50k sparse
features (mostly lexical and fertility-based). The
language model is a six-gram model trained on a
10 billion words monolingual corpus, including the
English side of our parallel corpora plus other cor-
pora such as Gigaword (LDC2011T07) and Google
News. We use 1275 sentences for tuning and 1239
sentences for testing from the LDC2010E30 corpus
respectively. There are four reference translations
for each input sentence in both tuning and testing
datasets.
We use a N-best list which is an intermediate out-
854
MIRA1 MIRA2 c-MIRA
dense dev 31.90 31.78 32.00
only test 30.89 30.89 31.07
dense dev 32.29 32.20 32.49
+sparse test 31.12 31.00 31.39
Table 3: BLEUs (%) on re-ranking experiments.
MIRA1 MIRA2 c-MIRA
about 1,966,720 35,120 400
Table 4: Times of updating model parameters.
put of the baseline system optimized on TER-BLEU
instead of BLEU. Before the re-ranking task, the ini-
tial BLEUs of the top-1 hypotheses on the tuning
and testing set are 31.45 and 30.56. The average
numbers of hypotheses per sentence are about 200
and 500, respectively for the tuning and testing sets.
Again, we use the best epoch on the tuning set for
testing. The BLEUs on dev and test sets are reported
in Table 3. We observe that the effectiveness of c-
MIRA is not harmed as the feature size is scaled up.
4.3 Analysis
To examine the simple search for hopes and fears
(Line 3?8 in Alg. 1), we use two hope/fear building
strategies to get E? and E ? : (1) simply connect each
e?i and e
?
i in Line 4?5 of Algorithm 1, (2) conduct a
slow beam search among the N-best lists of all for-
eign sentences from e1 to eM and use Eq. 5 and
6 to prune the stack. The stack size is 10. We ob-
serve that there is no significant difference between
the two strategies on the BLEU of the dev set. But
the second strategy is about 10 times slower.
We also consider more constraints in Eq. 3. By
beam search, we obtain one corpus-level oracle and
29 other hypotheses similar to (Chiang et al, 2008),
and optimize with SMO (Platt, 1998). Unfortu-
nately, experiments show that more constraints lead
to an overfitting and no improved performance.
As shown in Table 4, in one execution, our
method updates the parameters by only 400 times;
MIRA2 updates by 40 ? 878 = 35120 times; and
MIRA1 updates much more (about 1,966,720 times)
due to the SMO procedure. We are surprised to find
c-MIRA gets a higher training BLEU with such few
parameter updates. This probably suggests that there
is a gap between sentence-level BLEU and corpus-
level BLEU, so standard MIRAs need to update the
parameters more often.
Regarding simplicity, MIRA1 uses a strongly-
heuristic definition of a sentence BLEU, and
MIRA2 needs a pseudo-document with a decay rate
of ? = 0.9. In comparison, c-MIRA avoids both
the sentence level BLEU and the pseudo-document,
thus needs fewer variables.
5 Conclusion
We present a simple and effective MIRA batch tun-
ing algorithm without the heuristic-driven calcula-
tion of sentence-level BLEU, due to the indecom-
posability of a corpus-level BLEU. Our optimiza-
tion objective is directly defined on the corpus-level
hypotheses. This work simplifies the tuning pro-
cess, and avoid the mismatch between the sentence-
level BLEU and the corpus-level BLEU. This strat-
egy can be potentially applied to other optimiza-
tion paradigms, such as the structural SVM (Cherry
and Foster, 2012), SGD and AROW (Chiang, 2012),
and other forms of samples, such as forests (Chiang,
2012) and lattice (Cherry and Foster, 2012).
6 Acknowledgments
The key idea and a part of the experimental work
of this paper were developed in collaboration with
the IBM researcher when the first author was an in-
tern at IBM T.J. Watson Research Center. This re-
search is partially supported by Air Force Office of
Scientific Research under grant FA9550-10-1-0335,
the National Science Foundation under grant IIS RI-
small 1218863 and a Google research award.
References
A. Arun, C. Dyer, B. Haddow, P. Blunsom, A. Lopez,
and P. Koehn. 2009. Monte Carlo inference and maxi-
mization for phrase-based translation. In Proceedings
of the Thirteenth Conference on Computational Natu-
ral Language Learning (CoNLL), 102-110.
C. Cherry and G. Foster. 2012. Batch tuning strategies
for statistical machine translation. Conference of the
North American Chapter of the Association for Com-
putational Linguistics: Human Language Technolo-
gies (NAACL-HLT), 427-436.
855
D. Chiang. 2012. Hope and fear for discriminative train-
ing of statistical translation models. Journal of Ma-
chine Learning Research (JMLR), 1159-1187.
D. Chiang, K. Knight, and W. Wang. 2009. 11,001 new
features for statistical machine translation. Confer-
ence of the North American Chapter of the Associa-
tion for Computational Linguistics: Human Language
Technologies (NAACL-HLT), 218-226.
D. Chiang, Y. Marton, and P. Resnik. 2008. Online large-
margin training of syntactic and structural translation
features. In Proc. of Conference on Empirical Meth-
ods in Natural Language Processing (EMNLP), 224-
233.
D. Chiang. 2007. Hierarchical phrase-based translation.
Computational Linguistics, 33(2):201-228.
K. Crammer, O. Dekel, J. Keshet, S. Shalev-Shwartz,
and Y. Singer. 2006. Online passive-aggressive al-
gorithms. Journal of Machine Learning Research
(JMLR), 7:551-585.
V. Eidelman. 2012. Optimization strategies for online
large-margin learning in machine translation. Pro-
ceedings of the Seventh Workshop on Statistical Ma-
chine Translation, 480-489.
B. Haddow, A. Arun, and P. Koehn. 2011. SampleRank
training for phrase-based machine translation. Pro-
ceedings of the Sixth Workshop on Statistical Machine
Translation. Association for Computational Linguis-
tics, 261-271.
P. Koehn, H. Hoang, A. Birch, C. Burch, M. Federico, N.
Bertoldi, B. Cowan, W. Shen, C. Moran, R. Zens, C.
Dyer, O. Bojar, A. Constantin, and E. Herbst. 2007.
Moses: Open source toolkit for statistical machine
translation. Proceedings of the Annual Meeting of
the Association for Computational Linguistics (ACL),
177-180.
P. Liang, A. Bouchard-Cote, D. Klein, and B. Taskar.
2006. An end-to-end discriminative approach to ma-
chine translation. In Proceedings of the 21st Interna-
tional Conference on Computational Linguistics and
the 44th annual meeting of the Association for Com-
putational Linguistics, 761-768.
C. Lin and F. Och. 2004. Orange: a method for evaluat-
ing automatic evaluation metrics for machine transla-
tion. In Proc. of International Conference on Compu-
tational Linguistics (COLING), No. 501.
F. Och. 2003. Minimum error rate training in statistical
machine translation. Proceedings of the 41st Annual
Meeting on Association for Computational Linguistics
(ACL), 160-167.
F. Och and H. Ney. 2002. Discriminative training
and maximum entropy models for statistical machine
translation. Proceedings of the 40th Annual Meeting
on Association for Computational Linguistics (ACL),
295-302.
K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002.
BLEU: a method for automatic evaluation of machine
translation. Proceedings of the 40th annual meeting on
association for computational linguistics. Association
for Computational Linguistics (ACL), 311-318.
J. Platt. 1998. Sequetial minimal optimization: A fast al-
gorithm for training support vector machines. In Tech-
nical Report MST-TR-98-14. Microsoft Research.
I. Tsochantaridis, T. Hofman, T. Joachims, and Y. Altun.
2004. Support vector machine learning for interde-
pendent and structured output spaces. International
Conference on Machine Learning (ICML), 823-830.
T. Watanabe. 2012. Optimized online rank learning for
machine translation. Proceedings of Conference of the
North American Chapter of the Association for Com-
putational Linguistics: Human Language Technolo-
gies (NAACL-HLT), 253-262.
T. Watanabe, J. Suzuki, H. Tsukada, and H. Isozaki.
2007. Online large-margin training for statistical ma-
chine translation. Proceedings of Conference on Em-
pirical Methods in Natural Language Processing and
Computational Natural Language Learning (EMNLP-
CoNLL), 764-773.
856
