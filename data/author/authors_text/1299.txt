Proceedings of the Linguistic Annotation Workshop, pages 156?163,
Prague, June 2007. c?2007 Association for Computational Linguistics
PoCoS ? Potsdam Coreference Scheme1
 Olga Krasavina 
Moscow State University 
krasavina@gmx.net 
Christian Chiarcos 
University of Potsdam 
chiarcos@ling.uni-potsdam.de
 
 
 
Abstract1
This document outlines minimal design 
principles underlying annotation of 
coreference relations in PoCoS, a scheme 
for cross-linguistic anaphoric annotation. 
We identify language-independent princi-
ples for markable identification which are 
essential for comparability of annotations 
produced for different languages. We fur-
ther suggest a clear and motivated structure 
of annotation stages, the separation of a 
coarse-grained core and a family of more 
elaborate extended schemes, and strategies 
for the systematic treatment of ambiguity. 
Explicit mark-up of ambiguities is a novel 
feature. We implemented three instantia-
tions of PoCoS for German, English and 
Russian applied to corpora of newspaper 
texts. 
1 Introduction 
Anaphoric annotation is notoriously problematic 
because of ambiguity and subjectivity issues. One 
has to deal with them at two stages: 1) by design-
ing annotation guidelines; 2) by performing anno-
tation. As for 1), it is a well-known problem that 
different schemes propose different annotation de-
cisions. As for 2), different annotators may have 
different judgments on coreference-related issues. 
The current paper focuses on the general principles 
and strategies of annotating coreference ? the theo-
retical core that should logically precede any anno-
tation decisions or schemes, but has not been for-
mulated explicitly by now. 
The number of existing schemes released just in 
the last few years is overwhelming and is out of the 
                                                          
1 The research by Olga Krasavina was supported by Russian 
Foundation for the Humanities, grant 05-04-04240?. 
scope here. The MUC is still generally accepted as 
the most standard-like annotation scheme 
(Hirschman, 1997). Given its simplicity is its most 
important advantage, it has been criticized for its 
limited coverage and its contra-intuitive under-
standing of coreference. One of the most well-
known later approaches is MATE/GNOME (Poe-
sio, 2004). As the author fairly notices, ?there can 
be no such thing as a general-purpose anaphoric 
annotation instructions?, due to the complexity of 
phenomena associated with the term of anaphora. 
So, its essential idea is combining a ?general-
purporse markup scheme? (MATE) with applica-
tion-specific scheme instantiations (GNOME). In 
PoCoS, we adapted and elaborated this idea, by 
suggesting the Core and Extended Schemes. 
The PoCoS, the Potsdam Coreference Scheme, 
both adapts selected features of existing schemes 
and implements a set of innovative features. We 
distinguish between the Core and Extended 
Scheme: the Core Scheme is general and reusable, 
while the Extended Scheme supports a wider range 
of specific extensions, see fig. 1. Here, we are talk-
ing about English and German instantiations of the 
PoCoS Core Scheme. 
2 Coreference annotation 
Coreference is a relation between textual elements, 
?referring expressions?, which denote the same 
entity. Semantically, these expressions are proto-
typical objects or ?(discourse) referents? (Kart-
tunen, 1976). Given a pair of two coreferring ex-
pressions, the preceding expression is termed ante-
cedent, the subsequent one is termed anaphor. 
Subject to annotation are ?markables? defined as 
a cover-term for potential anaphors and their ante-
cedents. Coreference annotation consists of as-
signment of relations pointing from an anaphor to 
an antecedent markable. Whether two markables 
are co-referent, i.e. referring to the same discourse 
referent, can be determined by a substitution test. If 
156
the substitution of anaphor and antecedent yield 
the same interpretation of the text, these are 
deemed coreferential. 
Syntactically, a markable is typically a phrase 
with a nominal or a pronominal head. According to 
the referential properties a syntactic construction 
typically has, we distinguish between primary 
markables, i.e. potential anaphors, and secondary 
markables, expressions which can not serve as 
anaphors, but only as antecedents.  
3 Annotation principles 
3.1 A principled approach 
In order to develop an annotation scheme which 
is maximally consistent, we initially identified a 
set of axiomatic requirements: 
? CONSTITUENCY 
o a primary or secondary markable must be an 
independent syntactic constituent 
? COMPLETENESS 
o neither sub-tokens nor non-phrasal nomi-
nals are subject to annotation, only syntac-
tic words (tokens) and phrases are 
? CONSISTENCY 
o corresponding features have to be analyzed 
in a corresponding way 
CONSTITUENCY and COMPLETENESS are necessary 
pre-conditions for an alignment between syntactic 
and anaphoric annotation, CONSISTENCY implies 
that annotation principles must be formulated in a 
way that allows for inter-subjective and cross-
linguistically valid annotation decisions. While 
CONSTITUENCY and COMPLETENESS define con-
straints for markable identification, consistency 
also affects selection preferences among potential 
antecedents, and it motivates the explicit represen-
tation of anaphoric ambiguity in PoCoS. 
In addition to these requirements, we add the 
preference for MAXIMAL ANALYSIS. It suggests 
longer anaphoric chains are preferred to the shorter 
ones by annotation. This defines preferences for 
coding decisions by ambiguity (see 4.1). 
In the remainder of this section, annotation prin-
ciples employed in the PoCoS scheme are shortly 
presented and discussed as to their relationship to 
these four requirements. 
3.2 Markable identification 
Cross-linguistically consistent markable identifica-
tion strategies are a necessary pre-condition for a 
comparative evaluation of anaphor annotation and 
anaphor resolution across different languages. It 
has been controversial, however, how to set mark-
able boundaries. So, for example, Ge et al (1998) 
and, MUC (Hirschman, 1997) propose a minimal 
string constraint motivated by evaluation consid-
erations. This procedure leads to systematic viola-
tions of the CONSTITUENCY and COMPLETENESS 
principles, though, cf. the potential markables 
Denver and bankruptcy in ex. (1)  
(1) The [Denver]?-based con-
cern, which emerged from ban-
cruptcy ... its new, post-
[bancruptcy]? law structure 
..." (WSJ, 1328)
We explicitly propose a maximum size principle as 
an alternative to the minimum string constraint 
(see Principle 1 below). So, a markable consists of 
the head, usually a noun or a pronoun, and of all 
modifiers, attributes, relative clauses, appositions, 
and dislocated elements attached to the head. 
Principle 1 Maximum size 
One markable includes all modifications of its 
head. 
Prepositions can be regarded as modifications of a 
noun as well, and following this line of 
argumentation, the seemingly clear-cut 
differentiation between NPs and PPs becomes 
questionable, cf. the unclear status of Japanese 
postpositions that can also be interpreted as 
morphological case markers (Giv?n 2001:115f). 
Further, in most European languages, functional 
elements such as prepositions and determiners tend 
to be fused. In combination with the 
COMPLETENESS constraint, a possible NP-
preference for the selection of markables will 
result in the selection of either PPs or non-phrasal 
markables if preposition-determiner fusion occurs.  
In order to achieve a more consistent analysis, in 
which the syntactic status of a markable does not 
depend on surface phenomena such as the 
(optional) fusion of prepositions and determiner, 
function words are integrated into a markable if 
they modify it. As a consequence, CONSISTENCY 
157
considerations call for the choice of PPs rather than 
NPs as markables where possible. 
Principle 2 Syntactic characterization 
If a referring expression is modified by func-
tion words, e.g. a determiner or an adposition, 
these are to be integrated into the markable. 
Like Principle 1, Principle 2 originates from CON-
SISTENCY and COMPLETENESS requirements ap-
plied both within one language and considering 
cross-linguistic validity, as the function of inflec-
tional marking in one language and the function of 
prepositions in another language are exchangeable.  
If a markable includes another markable, both 
are specified as markables in annotation. Such 
treatment provides consistency across languages, 
(cf. the fragment of parallel text in ex. 2), and has 
an additional advantage of representing the syntac-
tic structure of a markable. 
(2)[Dieses Recht]right kann nicht in Anspruch genommen werden [im 
Falle einer Strafverfolgung auf Grund von Handlungen, die [gegen 
die Ziele [der Vereinten Nationen]UN]purp versto?en]prosec. 
[This right]right may not be invoked [in the case of prosecutions 
arising from acts contrary [to the purposes [of the United Na-
tions]UN]purp]prosec. 
[??? ?????]right ?? ????? ???? ???????????? [? ?????? ?????????????, 
??????????? ?? ?????????? ??????, ??????????????? [????? 
[??????????? ???????????? ?????]UN]purp]prosec. (www.unhchr.ch/udhr,  
shortened) 
3.3 Antecedent selection 
For interconnecting co-referring expressions three 
basic strategies can be employed: (i) leave this de-
cision to an annotator, (ii) connect all mentions to 
the first one, or (iii) connect each following men-
tion to the immediately preceding one. In line with 
previous research and in order to enhance consis-
tency, we opted for (iii), as Principle 3 states: 
Principle 3 Chain principle 
Mark the most recent mention of a referent as 
antecedent, so that all mentions of the same ref-
erent make up an ordered chain. 
Possessive pronouns can often be used at the be-
ginning of a sentence, in case they are resolved in 
the same sentence as in (3) and (4). The chain 
principle suggests selecting a pronoun as the chain-
initial element which is contra-intuitive in this 
case: a pronoun introduces no lexical material 
which serves for subsequent re-identification of a 
referent. In order to respect the inter-subjective 
intuition to identify the controller of the possessive 
as a markable, we posit an exception to the chain 
principle for the case of pronominal cataphora. 
According to the CONSISTENCY requirement (see 
3.1), any bound pronoun, no matter if its is chain-
initial or not, has to be treated this way.  
Principle 4 Cataphora at sentence level 
If a pronoun which is typically used as a bound 
pronoun is bound by an intrasentential controller, 
annotate a pointing relation to the controller rather 
than to a candidate antecedent in previous dis-
course. 
In the Core Scheme for German, English and 
Russian, Principle 4 applies to possessive pronouns 
only. 
(3) Through [his]a lawyers, 
[Mr. Antar]a has denied alle-
gations in the SEC suit?(WSJ, 3) 
(4) [Die einstige Fu?ball-
Weltmacht]d zittert [vor einem 
Winzling]s. Mit [seinem]s Tor 
zum 1:0 [f?r die Ukraine]u 
st?rzte [der 1,62 Meter gro?e 
Gennadi Subow]s [die deutsche 
Nationalelf]d vor?bergehend in 
ein Trauma? (PCC, 10374) 
?[The former football World Power]d is shiver-
ing [in the face of a mite]s. By [his]s goal that 
set the score to 1:0 [for Ukraine]u pitched 
[Gennadi Subow]s, 1.62 Meter tall, [the German 
National Eleven]d in a shock for a while?? 
158
3.4 Identifying pointing relations 
A special case for annotation is pronominal or 
nominal reference by plural or NPs or both to mul-
tiple concrete antecedents mentioned at different 
points in a text. Thus, they cannot be regarded as 
single constituent. Since a referent of a plural NP is 
not the same as the sum of its parts, we deal with 
multiple antecedents by introducing a separate an-
notation layer called groups. Group referents are 
linked to their anaphors by regular anaphoric rela-
tions, see (5).  
(5) [Montedison]m now owns 
about 72% of [Erbamont?s]e 
shares outstanding. [The com-
panies]m+e said ? a sale of all 
of [Erbamont?s]e assets ... 
[to Montedison]m ? [The compa-
nies]m+e said ? (WSJ, 660) 
Special treatment of groups is important as they 
introduce an exception to the Chain Principle. 
Formally, the same group of people can be referred 
to at different points of time. However, following 
the preference for MAXIMAL ANALYSIS (see 3.1), 
longer anaphoric chains are preferred, and thus, 
once a pre-established group reference exists, it is 
marked as an antecedent instead of establishing a 
new group referent. Accordingly, in ex. (5), the 
preferred antecedent of the second companies 
is the previously established group reference The 
companies. More generally, this is formulated in 
Principle 5.
Principle 5 Maximize anaphoric chains 
The annotation of anaphoric references is pre-
ferred over the annotation of alternative analy-
ses. 
This principle is motivated by CONSISTENCY and 
coverage considerations. 
4 Dealing with vagueness 
4.1 Ambiguity resolution strategies 
The problem of identifying an appropriate pointing 
relation is especially acute in connection with ana-
phoric ambiguity. As opposed to general annota-
tion strategies, however, the ambiguity strategies 
apply only in case of doubt, i.e. if the annotator 
perceives different readings as equally possible. 
Consider ex. (6) as a continuation of ex. (4): 
(6) Je kleiner [die Ki-
cker]u?/d? daherkommmen, desto 
gr??er wird [der Gegner]d?/u? 
geredet. (PCC, 10374) 
?The smaller [the kickers]u?/d? are, the 
greater [the rivals]d?/u? are rumoured to be.? 
Antecedent of die Kicker ?kickers? depends 
on the understanding of the ?size? metaphor, it can 
be either the Ukrainian team (presented as having 
short players), or the German team (which has not 
been favored in the first match), or a generic 
description (which would mean that the sentence is 
not directly linked with the discourse). Here, also 
Principle 5 can be applied, since we are facing 
alternative readings, and accordingly, the generic 
reading in the example is excluded. This 
application of Principle 5 is reformulated in 
Principle 6. 
Principle 6 Primacy of anaphora  
In case of uncertainty between different read-
ings prefer anaphoric interpretation to antece-
dentless one. 
However, in the example under consideration, 
we still have the choice between two possible 
antecedents. The substitution test (see Sec. 2) 
fails to determine a unique antecedent, as both 
possible substitutions are plausible, depending 
on whether ?size? refers to physical size or an-
ticipated defeat. From the preference for MAXI-
MAL ANALYSIS, however, a more rigid version 
of Principle 5 can be motivated, cf. Principle 7. 
Principle 7 Avoid ambiguous antecedents 
In case of two possible antecedents, primary 
markable is preferred to secondary ones or to 
group referents. 
In case of two primary markables are possible 
antecedents, choose the one which leads to the 
longer anaphoric chain. 
In ex. (6), this results in a preference for the Ger-
man team as the antecedent of die Kicker. 
Finally, in order to narrow down the scope of 
ambiguity, another exception to the chain principle 
is necessary. Markables with ambiguous reference 
should be avoided as antecedents, but rather the 
last unambiguously coreferential expression. 
 
159
Principle 8 Primary markables as preferred 
antecedents 
Prefer antecedents which are unambiguous in 
their reference to antecedents which are am-
biguous. 
4.2 Annotation of ambiguities 
In order to investigate the effect of ambiguity and 
to document its influence on inter-annotator-
agreement, ambiguities are to be explicitly marked. 
For this purpose, we classified ambiguities as fol-
lows.  
Ambiguous antecedent ambiguity of antece-
dent of a markable, cf. (6). 
Ambiguous relation ambiguity wrt relation be-
tween a markable and the context: 
(7) Weil [die Polizei]p das 
wei?, richten sich [die Beam-
ten]? ? auf viele Anzeigen ... 
ein. (PCC, 19442) 
?As [the police]p knows this, [the officials]? are 
expecting ? a lot of statements??  
The relation between ?the police? and ?the po-
licemen? is either bridging (part-whole) or corefer-
ence.  
Ambiguous idiomatic ambiguity wrt whether a 
markable could be either understood as coreferen-
tial or as a part of an idiom. In (8), der Spatz in der 
Hand, a definite NP in German, can be generic, 
part of an idiom, or referring:  
(8) Lieber [der Spatz in der 
Hand] als [die Taube auf dem 
Dach] (PCC, 12666) 
?A bird in the hand is worth two in the bush?  
(Context: a mayor finds an investor for his town 
willing to make only minimal investments). 
5 PoCoS annotation scheme 
PoCoS disposes of three annotation levels: mark-
ables, relations and attributes (5.1, 5.2. and 5.3). In 
what follows, we concentrate on the Core Scheme 
because of relevance and space considerations. 
5.1 Markables 
Primary markables are all potential anaphors, i.e. 
referential forms which can be used to indicate 
subsequent mentions of a previously introduced 
referent in the discourse, such as definite NPs, pro-
nouns, and proper names. Secondary markables are 
expressions that normally indicates non-reference 
(e.g. indefinites; in the Extended Scheme also 
clauses). Secondary markables are subject to anno-
tation only if they serve as antecedents of a pri-
mary markable.  
The basic distinctive feature between primary 
and secondary markables is if they can refer to 
previously mentioned nominals or not. Using the 
above-mentioned grammatical criteria, most prob-
able referring expressions (i.e. primary markables) 
can be extracted automatically from syntactic an-
notation, which is an important advantage. 
Further, using this differentiation a more precise 
definition of the coreference annotation task can be 
given. Coreference annotation is complete, if all 
primary markables are classified as having an an-
tecedent or not. 
5.2 Coreference Relations 
We distinguish between two types of coreference: 
nominal and non-nominal. The Core Scheme only 
deals with nominal coreference, which we define 
as reference of NPs to explicitly mentioned NPs 
establishing a relation of identity (cf. Mitkov?s 
(2002) ?identity-of-reference direct nominal 
anaphora?). If a relation other than identity holds 
between a primary markable and an element from 
the preceding context, e.g. the bridging relation, 
the relation remains underspecified and can be as-
signed later, as part of Extended Scheme. 
Differently from MUC, we do not consider 
predicative nominals as coreferential with the sub-
ject in the sense of textual coreference defined 
above (for similar view, see van Deemter and Kib-
ble, 1999), as the relationship with the hypothetical 
antecedent is expressed by syntactic means.  
5.3 Annotation principles  
In sec. 3 and 4, we outlined a small set of heuris-
tics serving to guide annotators to more consistent 
annotation decisions. These principles are, how-
ever, not equal in their restrictive force, but rather 
they build the following preference hierarchy (cf. 
Carlson et al, 2003): 
obligatory principles > exception principles > 
default principles > ambiguity principles 
Principles 1 and 2 are obligatory and do not allow 
exceptions; 4, 5 and 8 are exceptions to the default, 
i.e. the Chain Principle (3). 6 and 7 are applied 
only if interpretation-dependent ambiguities occur, 
thus being no exceptions to default principles. 
160
 Figure 1. PoCoS: Core Scheme, Extended Scheme and language-specific instantiations 
5.4 Attributes 
Markables and relations are enriched by a set of 
additional features. These features encode attrib-
utes of pointing relations (e.g. anaphora type) or 
specify parameters of anaphoricity (e.g. referential-
ity, ambiguity). Further, certain grammatical fea-
tures of markables are integrated which are of gen-
eral interest when analyzing patterns of anaphora 
in corpora and can be extracted from other pre-
existing annotations. This way we gain a common 
minimal representation of grammatical features 
which can be extracted from different annotation 
schemes. This allows us to abstract from language-
, tool- or annotation-specific expressions of, say, 
grammatical roles. As a consequence, the scheme 
is self-contained to a higher degree, and thus, the 
cross-linguistic validity of the assembled data is 
enhanced.  
5.5. Annotation procedure 
The scheme suggests structuring annotation into 
several annotation cycles performed manually or 
semi-automatically: 
I. Core Scheme Annotation 
1. Identify primary markables 
2. Connect markables with coreference links 
a.     assign to every primary markable a 
unique antecedent 
b. if antecedent is not a primary markable, 
annotate it is as secondary markable if 
necessary 
3. Set attribute values 
II. Extended Scheme: steps 1 to 3 accordingly 
These stages correspond to the 3 annotation levels 
within the Core and Extended Schemes respec-
tively, because annotating at all levels at the same 
time has proved to be very labor-intensive and 
more time-consuming than one level at a time. 
6 Application and evaluation 
The original annotation guidelines were drafted in 
2004 by the authors for the annotation of the Pots-
dam Commentary Corpus of German newspaper 
commentaries (PCC) (Stede, 2004) and the RST 
Discourse Treebank of Wall Street Journal articles 
(WSJ) (Carlson et al, 2003).  
After a series of annotation experiments, the 
PoCoS Core Scheme was applied to the PCC by 
two instructed annotators, students of linguistics, 
whose portions had an overlap of 19 texts (11%). 
Based upon these texts, inter-annotator agreement 
was calculated using different agreement scores 
along the methodology of Popescu-Belis et al 
(2004). So, with respect to German, we achieved 
moderate to substantial agreement (full chains, 
?=0.61 with union of markables; ?=0.77 with in-
tersection of markables). 
Part of the WSJ corpus has been performed in 
co-operation with A.A. Kibrik, Moscow State Uni-
versity. Fourteen instructed annotators, also stu-
dents of linguistics, worked on the RST Discourse 
Treebank with pair-wise overlapping portions. Re-
garding 8 texts from 6 annotators, we also found 
substantial agreement (?=0.71 with union; ?=0.96 
with intersection). 
161
These results are reasonable in the light of ? 
values reported for an annotation experiment by 
Artstein and Poesio (2005, p.22) on English which 
yielded ?=0.48. However, ? is affected by parame-
ters of the text as a whole, and thus should be in-
terpreted with certain reservations. The texts of the 
PCC are generally short, but very demanding in 
their interpretation.  
A detailed study of outliers revealed several 
sources of errors in both corpora. Besides ?soft 
errors? such as inclusion of punctuation and con-
junctions within markables, occasionally missed 
integration of function words into markables, or 
obviously missed anaphors, we found several 
?hard? errors on syntax (e.g. different assumptions 
about PP attachment), semantics (e.g. vagueness, 
exact relationship between abstract concepts in a 
given context), and pragmatics (e.g. differentiation 
between metonymy and bridging). Above, we sug-
gested the annotation of ambiguity as an attempt to 
capture typical semantic and pragmatic sources of 
disagreement (cf. sec. 4.2 for examples). 
In order to evaluate the impact of such ?hard er-
rors? in the German data, two instructed annotators 
corrected 13 texts from the overlapping part of the 
portions independently. As a concequence, the 
original ? values increased by about 7%: original ? 
= 0.69 (union)/0.82 (intersection), and corrected ? 
=0.76 (union)/0.89 (intersection). These results, 
however, still suffer from the special problems 
with the demanding ? though, very interesting ? 
type of texts assembled in the PCC as well.  
Note that in spite of these short remarks, this 
paper has focused on the presentation of the 
scheme principles rather than on its evaluation. 
Currently, the PCC is annotated with information 
structure and a more thorough evaluation address-
ing both information status and co-reference is in 
preparation. A corpus of Russian is currently under 
construction, which PoCoS is being applied to (cf. 
Krasavina et al 2007). 
7 Discussion 
The majority of earlier coreference annotation ex-
periences were dealing with English, including the 
standard-like MUC-scheme (Hirschman, 1997). 
MATE was an attempt to extend annotation to 
other languages than English (Poesio, 2004). For 
German, several annotation schemes appeared and 
were applied to annotation of corpora recently: for 
newspaper texts, such as the T?Ba-D/Z (Naumann, 
2006) and for hypertexts, Holler et al (2004). As 
for Slavic languages, the Prague Dependency 
Treebank has been recently enriched by corefer-
ence annotation, see Ku?ov? and Haji?ov? (2004) . 
For Russian, though, we are aware of no similar 
experiences so far. The current approach is an ad-
vance on the existing work as it attempts at provid-
ing language-independent and systematic annota-
tion principles, including a language-neutral reper-
toire of relations and a language-neutral apparatus 
for identification of markables. This makes the 
resulting annotation scheme extendable and appli-
cable across languages. 
The Core Scheme is comparable to MUC by 
Hirschman, 1997; DRAMA by Passonneau, 1996; 
MATE by Poesio, 2004. Its specific instantiations 
formalized in a family of Extended Scheme(s) are 
comparable to Rocha, 1997, GNOME by Poesio, 
2004. By distinguishing between fundamental 
(?obligatory?), project-specific (?recommended?) 
and language-specific (?optional?) levels of anno-
tation (cf. Leech and Wilson, 1996), a compromise 
between a general character and a greater level of 
detail is achieved.  
A central innovation is the dichotomy of pri-
mary and secondary markables. As both are de-
fined on the basis of their syntactic properties, we 
recommend identifying primary markables auto-
matically, but annotate secondary markables 
manually and only if needed. The separation be-
tween both leads to a reduction of the number of 
possible attribute values subject to annotation, and 
thus to reduction of complexity. The definition of 
primary and secondary markables makes use of 
language-specifics such as existence of a definite 
determiner, etc. These specifications, although 
formulated here specifically for German and Eng-
lish, are subject to language-specific alternative 
instantiations of the PoCoS Scheme. Note that in 
Russian, the differentiation between primary and 
secondary markables is made on the basis of dif-
ferent linguistic cues, as definiteness is not explic-
itly marked. Therefore, in Russian, secondary 
markables are only certain quantified expressions. 
Nevertheless, the function of primary and secon-
dary markables remains the same. Further, exis-
tence of a pre-determined set of potential anaphors 
allows to verify if all primary markables are as-
signed a relation or have been explicitly marked as 
non-referring.  
162
Another important novel aspect is the systematic 
treatment of ambiguity in the annotation of large 
corpora. This aspect has never been included in 
coreference annotation before (except for one ex-
periment described by Poesio and Artstein, 2005) 
and thus defines the task of coreference annotation 
in a more precise way. Moreover, we specified a 
set of heuristic rules to guide an annotator to a spe-
cific decision in case of ambiguity or vagueness. 
These rules are ranked according to their priority. 
Similarly, Versley (2006) has recently argued that 
a ?light-weight theory? of anaphoric ambiguity is 
due, in order to ensure consistent coding decisions.  
Finally, splitting annotation procedure into 
stages allows explicit structuring of the process, in 
existing approaches presented no more than im-
plicitly (cf. Naumann, 2006, see p. 12).  
8 Conclusion 
This paper has presented the general coreference 
annotation framework and the PoCoS Scheme for 
coreference annotation. As an innovative feature 
for coreference annotation, it implements ambigu-
ity resolution strategies and proposes annotation of 
ambiguities. Also, by introducing language-neutral 
criteria for identification of markables, it both re-
duces the notorious complexity of anaphoric anno-
tation on the systematic basis and enables applica-
bility of similar principles across languages. Thus, 
it has a better portability and cross-language com-
parability as compared to the previous work. One 
possible field of application of the scheme can be 
seen in its utilisation for the anaphoric annotation 
of parallel corpora, an idea which is currently ex-
plored by the authors. 
References  
Artstein, R. and ?. Poesio. 2005. Kappa3=Alpha (or 
Beta). Technical Report CSM-437, Univ. of Essex. 
Carlson, L., D. Marcu and M. E. Okurowski. 2003. 
Building a Discourse-Tagged Corpus in the Frame-
work of Rhetorical Structure Theory. Current direc-
tions in discourse and dialogue, Kluwer. 
Deemter van, K. and R  Kibble. 1999. What is corefer-
ence, and what should coreference annotation be? 
Proc. of the ACL Workshop on Coreference. 
Ge, M, J. Hale, and E. Charniak. 1998. A statistical ap-
proach to anaphora resolution. Proc. of the Sixth 
Workshop on very Large Corpora. 
Holler, A., J.F.Maas and A.Storrer. 2004. Exploiting 
Coreference Annotations for Text-to-Hypertext Con-
version. Proc. of LREC 2004, Lissabon, Portugal. 
Hirschman, L. 1997. MUC-7 coreference task defini-
tion. Version 3.0. 
Karttunen, L. 1976. Discourse referents. Syntax and 
Semantics. J. McCawley, New York Academic Press. 
Krasavina, O., Ch. Chiarcos and D. Zalmanov. 2007. 
Aspects of topicality in the use of demonstrative ex-
pressions in German, English and Russian. Proc. of 
DAARC-2007, Lagos, Portugal, 29-30 March. 
Ku?ov?, L. and E. Haji?ov? (2004). Prague Dependency 
Treebank: Enrichment of the Underlying Syntactic 
Annotation by Coreferential Mark-Up. The Prague 
Bulletin of Mathematical Linguistics 81. 
Leech, G. and J. Svartvik. 2003. A communicative 
grammar of English. London [u.a.].  
Leech, G. and A. Wilson. 1996. EAGLES Recommen-
dations for the Morphosyntactic Annotation of Cor-
pora. 
www.ilc.cnr.it/EAGLES/annotate/annotate.html 
Mitkov, R. 2002. Anaphora resolution. London [u.a.].  
Naumann, K. 2006. Manual for the Annotation of in-
document Referential Relations. http://www.sfs.uni-
tuebingen.de/de_tuebadz.shtml (July 2006). 
Passonneau, R. 1996. Instructions for applying Dis-
course Reference Annotation for Multiple Applica-
tions (DRAMA). Unpublished document. 
Poesio, M. 2004 The MATE/GNOME Proposals for 
Anaphoric Annotation, Revisited. Proc. of SIGDIAL. 
Poesio, M. and R. Artstein, 2005. Annotating (Ana-
phoric) Ambiguity. Proc. of Corpus Linguistics-05. 
Popescu-Belis, A., L. Rigouste, S. Salmon-Alt, and L- 
Romary. 2004, Online Evaluation of Coreference 
Resolution. Proc. of LREC 2004. 
Rocha de, M. 1997. Supporting anaphor resolution with 
a corpus-based probabilistic model. Proc. of the 
ACL'97 workshop on Operational factors in practical, 
robust anaphora resolution. Madrid, Spain. 
Stede, M. 2004. The Potsdam Commentary Corpus. 
Proc. of ACL-04 Workshop on Discourse Annota-
tion, Barcelona, July. 
Versley, Y. 2006. Disagreement Dissected: Vagueness 
as a Source of Ambiguity in Nominal (Co-) Refer-
ence. Proceedings of the ESSLLI 2006 Workshop on 
Ambiguity in Anaphora. 
163
Proceedings of the EACL 2009 Workshop on Language Technologies for African Languages ? AfLaT 2009, pages 17?24,
Athens, Greece, 31 March 2009. c?2009 Association for Computational Linguistics
Information Structure in African Languages: Corpora and Tools 
Christian Chiarcos*, Ines Fiedler**, Mira Grubic*, Andreas Haida**, Katharina 
Hartmann**, Julia Ritz*, Anne Schwarz**, Amir Zeldes**, Malte Zimmermann* 
 
* Universit?t Potsdam 
Potsdam, Germany 
{chiarcos|grubic| 
julia|malte}@ 
ling.uni-potsdam.de 
** Humboldt-Universit?t zu Berlin 
Berlin, Germany 
{ines.fiedler|andreas.haida| 
k.hartmann|anne.schwarz| 
amir.zeldes}@rz.hu-berlin.de 
 
Abstract 
In this paper, we describe tools and resources 
for the study of African languages developed 
at the Collaborative Research Centre ?Infor-
mation Structure?. These include deeply anno-
tated data collections of 25 subsaharan 
languages that are described together with 
their annotation scheme, and further, the cor-
pus tool ANNIS that provides a unified access 
to a broad variety of annotations created with a 
range of different tools. With the application 
of ANNIS to several African data collections, 
we illustrate its suitability for the purpose of 
language documentation, distributed access 
and the creation of data archives. 
1 Information Structure 
The Collaborative Research Centre (CRC) 
"Information structure: the linguistic means for 
structuring utterances, sentences and texts" 
brings together scientists from different fields of 
linguistics and neighbouring disciplines from the 
University of Potsdam and the Humboldt-
University Berlin. Our research comprises the 
use and advancement of corpus technologies for 
complex linguistic annotations, such as the 
annotation of information structure (IS). We 
define IS as the structuring of linguistic 
information in order to optimize information 
transfer within discourse: information needs to 
be prepared ("packaged") in different ways 
depending on the goals a speaker pursues within 
discourse.  
Fundamental concepts of IS include the 
concepts `topic?, `focus?, `background? and 
`information status?. Broadly speaking, the topic 
is the entity a specific sentence is construed 
about, focus represents the new or newsworthy 
information a sentence conveys, background is 
that part of the sentence that is familiar to the 
hearer, and information status refers to different 
degrees of familiarity of an entity.  
Languages differ wrt. the means of realization 
of IS, due to language-specific properties (e.g., 
lexical tone). This makes a typological 
comparison of traditionally less-studied 
languages to existing theories, mostly on 
European languages, very promising. Particular 
emphasis is laid on the study of focus, its 
functions and manifestations in different 
subsaharan languages, as well as the 
differentiation between different types of focus, 
i.e., term focus (focus on arguments/adjuncts), 
predicate focus (focus on verb/verb 
phrase/TAM/truth value), and sentence focus 
(focus on the whole utterance). 
We describe corpora of 25 subsaharan 
languages created for this purpose, together with 
ANNIS, the technical infrastructure developed to 
support linguists in their work with these data 
collections. ANNIS is specifically designed to 
support corpora with rich and deep annotation, as 
IS manifests itself on practically all levels of 
linguistic description. It provides user-friendly 
means of querying and visualizations for 
different kinds of linguistic annotations, 
including flat, layer-based annotations as used 
for linguistic glosses, but also hierarchical 
annotations as used for syntax annotation. 
2 Research Activities at the CRC 
Within the Collaborative Research Centre, there 
are several projects eliciting data in large 
amounts and great diversity. These data, 
originating from different languages, different 
modes (written and spoken language) and 
specific research questions characterize the 
specification of the linguistic database ANNIS. 
2.1 Linguistic Data Base 
The project ?Linguistic database for information 
structure: Annotation and Retrieval?, further 
17
database project, coordinates annotation 
activities in the CRC, provides service to projects 
in the creation and maintenance of data 
collections, and conducts theoretical research on 
multi-level annotations. Its primary goals, 
however, are the development and investigation 
of techniques to process, to integrate and to 
exploit deeply annotated corpora with multiple 
kinds of annotations. One concrete outcome of 
these efforts is the linguistic data base ANNIS 
described further below. For the specific 
facilities of ANNIS, its application to several 
corpora of African languages and its use as a 
general-purpose tool for the publication, 
visualization and querying of linguistic data, see 
Sect. 5. 
 
2.2 Gur and Kwa Languages 
 
Gur and Kwa languages, two genetically related 
West African language groups, are in the focus of 
the project ?Interaction of information structure 
and grammar in Gur and Kwa languages?, 
henceforth Gur-Kwa project. In a first research 
stage, the precise means of expression of the 
pragmatic category focus were explored as well 
as their functions in Gur and Kwa languages. For 
this purpose, a number of data collections for 
several languages were created (Sect. 3.1). 
Findings obtained with this data led to different 
subquestions which are of special interest from a 
cross-linguistic and a theoretical point of view.  
These concern (i) the analysis of syntactically 
marked focus constructions with features of 
narrative sentences (Schwarz & Fiedler 2007), 
(ii) the study of verb-centered focus (i.e., focus 
on verb/TAM/truth value), for which there are 
special means of realization in Gur and Kwa 
(Schwarz, forthcoming), (iii) the identification of 
systematic focus-topic-overlap, i.e., coincidence 
of focus and topic in sentence-initial nominal 
constituents (Fiedler, forthcoming). The project's 
findings on IS are evaluated typologically on 19 
selected languages. The questions raised by the 
project serve the superordinate goal to expand 
our knowledge of linguistically relevant 
information structural categories in the less-
studied Gur and Kwa languages as well as the 
interaction between IS, grammar and language 
type. 
2.3 Chadic Languages 
The project ?Information Structure in the Chadic 
Languages?, henceforth Chadic project, 
investigates focus phenomena in Chadic 
languages.  The Chadic languages are a branch of 
the Afro-Asiatic language family mainly spoken 
in northern Nigeria, Niger, and Chad. As tone 
languages, the Chadic languages represent an 
interesting subject for research into focus 
because here, intonational/tonal marking ? a 
commonly used means for marking focus in 
European languages ? is in potential conflict 
with lexical tone, and so, Chadic languages 
resort to alternative means for marking focus.  
The languages investigated in the Chadic 
project include the western Chadic languages 
Hausa, Tangale, and Guruntum and the central 
Chadic languages Bura, South Marghi, and Tera. 
The main research goals of the Chadic project 
are a deeper understanding of the following 
asymmetries: (i) subject focus is obligatorily 
marked, but marking of object focus is optional; 
(ii) in Tangale and Hausa there are sentences that 
are ambiguous between an object-focus 
interpretation and a predicate-focus 
interpretation, but in intonation languages like 
English and German, object focus and predicate 
focus are always marked differently from each 
other; (iii) in Hausa, Bole, and Guruntum there is 
only a tendency to distinguish different types of 
focus (new-information focus vs. contrastive 
focus), but in European languages like 
Hungarian and Finnish, this differentiation is 
obligatory. 
2.4 Focus from a Cross-linguistic 
Perspective 
The project "Focus realization, focus 
interpretation, and focus use from a cross-
linguistic perspective", further focus project, 
investigates the correspondence between the 
realization, interpretation and use of with an 
emphasis on focus in African and south-east 
Asian languages. It is structured into three fields 
of research: (i) the relation between differences 
in realization and differences in semantic 
meaning or pragmatic function, (ii) realization, 
interpretation and use of predicate focus, and (iii) 
association with focus.  
The relation between differences in realization 
and semantic/pragmatic differences (i) 
particularly pertains the semantic interpretation 
of focus: For Hungarian and Finnish, a 
differentiation between two semantic types of 
foci corresponding to two different types of 
focus realization was suggested, and we 
investigate whether the languages studied here 
have a similar distinction between two (or more) 
semantic focus types, whether this may differ 
18
from language to language, and whether 
differences in focus realization correspond to 
semantic or pragmatic differences.  
The investigation of realization, interpretation 
and use of predicate focus (ii) involves the 
questions why different forms of predicate focus 
are often realized in the same way, why they are 
often not obligatorily marked, and why they are 
often marked differently from term focus. 
Association with focus (iii) means that the 
interpretation of the sentence is influenced by the 
focusing of a particular constituent, marked by a 
focus-sensitive expression (e.g., particles like 
`only?, or quantificational adverbials like 
`always?), while usually, focus does not have an 
impact on the truth value of a sentence. The 
project investigates which focus-sensitive 
expressions there are in the languages studied, 
what kinds of constituents they associate with, 
how this association works, and whether it works 
differently for focus particles and 
quantificational adverbials. 
3 Collections of African Language Data 
at the CRC 
3.1 Gur and Kwa Corpora 
The Gur and Kwa corpora currently comprise  
data from 19 languages.  
Due to the scarceness of information available 
on IS in the Gur and Kwa languages, data had to 
be elicited, most of which was done during field 
research, mainly in West Africa, and some in 
Germany with the help of native speakers of the 
respective languages. The typologically diverse 
languages in which we elicited data by ourselves 
are: Baatonum, Buli, Byali, Dagbani, Ditammari, 
Gurene, Konkomba, Konni, Nateni, Waama, 
Yom (Gur languages) and Aja, Akan, Efutu, Ewe, 
Fon, Foodo, Lelemi, Anii (Kwa languages). 
The elicitation of the data based mainly on the 
questionnaire on information structure, 
developed by our research group (QUIS, see 
Section 4.2). This ensured that  comparable data 
for the typological comparison were obtained. 
Moreover, language-specific additional tasks and 
questionnaires tailored to a more detailed 
analysis or language-specific traits were 
developed. 
As the coding of IS varies across different 
types of texts, different text types were included 
in the corpus, such as (semi-)spontaneous 
speech, translations, mono- and dialogues. Most 
of the languages do not have a long literacy 
tradition, so that the corpus data mainly 
represents oral communication. 
In all, the carefully collected heterogeneous 
data provide a corpus that gives a comprehensive 
picture of IS, and in particular the focus systems, 
in these languages.  
3.2 Hausar Baka Corpus 
In the Chadic project, data from 6 Chadic 
languages are considered. 
One of the larger data sets annotated in the 
Chadic project is drawn from Hausar Baka 
(Randell, Bature & Schuh 1998), a collection of 
videotaped Hausa dialogues recording natural 
interaction in various cultural milieus, involving 
over fifty individuals of different age and gender. 
The annotated data set consists of approximately 
1500 sentences.  
The corpus was annotated according to the 
guidelines for Linguistic Information Structure 
Annotation (LISA, see Section 4.2). The Chadic 
languages show various forms of syntactic 
displacement, and in order to account for this, an 
additional annotation level was added: 
constituents are marked as ex-situ=?+?  if 
they occur displaced from their canonical, 
unmarked position. 
An evaluation of the focus type and the 
displacement status reveals tendencies in the 
morphosyntactic realization of different focus 
types, see Sect. 5.2. 
3.3 Hausa Internet Corpus 
Besides these data collections that are currently 
available in the CRC and in ANNIS, further 
resources are continuously created. As such, a 
corpus of written Hausa is created in cooperation 
with another NLP project of the CRC.   
The corpora previously mentioned mostly 
comprise elicited sentences from little-
documented languages with rather small 
language communities. Hausa, in contrast, is 
spoken by more than 24 million native speakers, 
with large amounts of Hausa material (some of it 
parallel to material in other, more-studied 
languages) available on the internet. This makes 
Hausa a promising language for the creation of 
resources that enable a quantitative study of 
information structure.  
The Hausa internet corpus is designed to cover 
different kinds of written language, including 
news articles from international radio stations 
(e.g., http://www.dw-world.de), religious texts, 
literary prose but also material similar to 
spontaneous spoken language (e.g., in chat logs). 
19
Parallel sections of the corpus comprise 
excerpts from the novel Ruwan Bagaja by 
Abubakar Imam, Bible and Qur?an sections, and 
the Declaration of Human Rights. As will be 
described in Section 4.3, these parallel sections 
open the possibility of semiautomatic 
morphosyntactic annotation, providing a unique 
source for the study of information structure in 
Hausa. Sect. 5.2 gives an example for 
bootstrapping  ex-situ constituents in 
ANNIS only on the basis of  morphosyntactic 
annotation. 
4 Data Elicitation and Annotation 
4.1 Elicitation with QUIS 
The questionnaire on information structure 
(Skopeteas et al, 2006) provides a tool for the 
collection of natural linguistic data, both spoken 
and written, and, secondly, for the elaboration of 
grammars of IS in genetically diverse languages. 
Focus information, for instance, is typically 
elicited by embedding an utterance in a question 
context. To avoid the influence of a mediator 
(working) language, the main body of QUIS is 
built on the basis of pictures and short movies 
representing a nearly culture- and language-
neutral context. Besides highly controlled 
experimental settings, less controlled settings 
serve the purpose of eliciting longer, cohesive, 
natural texts for studying categories such as 
focus and topic in a near-natural environment. 
4.2 Transcription and Manual Annotation 
In the CRC, the annotation scheme LISA has 
been developed with special respect to 
applicability across typologically different 
languages (Dipper et al, 2007). It comprises 
guidelines for the annotation of phonology, 
morphology, syntax, semantics and IS.  
The data mentioned above is, in the case of 
speech, transcribed according to IPA 
conventions, otherwise written according to 
orthographic conventions, and annotated with 
glosses and IS, a translation of each sentence into 
English or French, (optionally) additional notes, 
references to QUIS experiments, and references 
to audio files and metadata. 
4.3 (Semi-)automatic Annotation 
As to the automization of annotation, we pursue 
two strategies: (i) the training of classifiers on 
annotated data, and (ii) the projection of 
annotations on texts in a source language to 
parallel texts in a target language. 
Machine Learning. ANNIS allows to export 
query matches and all their annotated features to 
the table format ARFF which serves as input to 
the data mining tool WEKA (Witten & Frank, 
2005), where instances can be clustered, or used 
to train classifiers for any annotation level. 
Projection. Based on (paragraph-, sentence- 
or verse-) aligned sections in the Hausa internet 
corpus, we are about to project annotations from 
linguistically annotated English texts to Hausa, 
in a first step parts of speech and possibly  
nominal chunks. On the projected annotation, we 
will train a tagger/chunker to annotate the 
remaining, non-parallel sections of the Hausa 
internet corpus. Existing manual annotations 
(e.g. of the Hausar Baka corpus) will then serve 
as a gold standard for evaluation purposes. 
Concerning projection techniques, we expect 
to face a number of problems: (i) the question 
how to assign part of speech tags to categories 
existing only in the target language (e.g., the 
person-aspect complex in Hausa that binds 
together information about both the verb (aspect) 
and its (pronominal subject) argument),  (ii) 
issues of orthography: the official orthography 
Hausa (Boko) is systematically underspecified 
wrt. linguistically relevant distinctions. Neither 
vowel length nor different qualities of certain 
consonants (r) are represented, and also, there is 
no marking of tones (see Examples 1 and 2, fully 
specified word forms in brackets). To distinguish 
such homographs, however, is essential to the 
appropriate interpretation and linguistic analysis 
of  utterances.  
(1) ciki ? 1. [c?k?i, noun] 
stomach, 2. [c?k?, prep.] 
inside 
(2) dace ? 1. [d?ac?e, noun] 
coincidence, 2. [d?ac?e, verb] 
be appropriate 
 
We expect that in these cases, statistical 
techniques using context features may help to 
predict correct vowelization and tonal patterns. 
5 ANNIS ? the Linguistic Database of 
Information Structure Annotation 
5.1 Conception and Architecture 
ANNIS (ANNotation of Information Structure) 
is a web-based corpus interface built to query 
and visualize multilevel corpora. It allows the 
user to formulate queries on arbitrary, possibly 
nested annotation levels, which may be 
20
conflictingly overlapping or discontinuous. The 
types of annotations handled by ANNIS include, 
among others, flat, layer-based annotations (e.g., 
for glossing) and hierarchical trees (e.g., syntax). 
Source data. As an architecture designed to 
facilitate diverse and integrative research on IS, 
ANNIS can import formats from a broad variety 
of tools from NLP and manual annotation, the 
latter including EXMARaLDA (Schmidt, 2004), 
annotate (Brants and Plaehn, 2000), Synpathy 
(www.lat-mpi.eu/tools/synpathy/), MMAX2 
(M?ller and Strube, 2006), RSTTool (O'Donnell, 
2000), PALinkA (Orasan, 2003), Toolbox 
(Busemann & Busemann, 2008) etc. These tools 
allow researchers to annotate data for syntax, 
semantics, morphology, prosody, phonetics, 
referentiality, lexis and much more, as their 
research questions require. 
All annotated data are merged together via a 
general interchange format PAULA (Dipper 
2005, Dipper & G?tze 2005), a highly expressive 
standoff XML format that specifically allows 
further annotation levels to be added at a later 
time without disrupting the structure of existing 
annotations. PAULA, then, is the native format 
of ANNIS. 
Backend. The ANNIS server uses a relational 
database that offers many advantages including 
full Unicode support and regular expression 
searches. Extensive search functionalities are 
supported, allowing complex relations between 
individual word forms and annotations, such as 
all forms of overlapping, contained or adjacent 
annotation spans, dominance axes (children, 
ancestors etc., as well as common parent, left- or 
right-most child and more), etc. 
Search. In the user interface, queries can be 
formulated using the ANNIS Query Language 
(AQL). It is based on the definition of nodes to 
be searched for and the relationships between 
these nodes (see below for some examples). A 
graphical query builder is also included in the 
web interface to make access as easy as possible. 
Visualization. The web interface, realized as a 
window-based AJAX application written in Java, 
provides visualization facilities for search results. 
Available visualizations include token-based 
annotations, layered annotations, tree-like 
annotations (directed acyclic graphs), and a 
discourse view of entire texts for, e.g., 
coreference annotation. Multimodal data is 
represented using an embedded media player.  
Special features. By allowing queries on 
multiple, conflicting annotation levels 
simultaneously, the system supports the study of 
interdependencies between a potentially limitless 
variety of annotation levels.  
At the same time, ANNIS allows us to 
integrate and to search through heterogeneous 
resources by means of a unified interface, a 
powerful query language and a intuitive 
graphical query editor and is therefore 
particularly well-suited for the purpose of 
language documentation. In particular, ANNIS 
can serve as a tool for the publication of data 
collections via internet. A fine-grained user 
management allows granting privileged users 
access to specific data collections, to make a 
corpus available to the public, or to seal (but 
preserve) a resource, e.g., until legal issues 
(copyright) are settled. This also makes 
publishing linguistic data collections possible 
without giving them away. 
Moreover, ANNIS supports deep links to 
corpora and corpus queries. This means that 
queries and query results referred to in, e.g., a 
scientific paper, can be reproduced and quoted 
by means of (complex) links (see following 
example). 
5.2 Using ANNIS. An Example Query 
As an illustration for the application of ANNIS to 
the data collections presented above, consider a 
research question previously discussed in the 
study of object focus in Hausa. 
In Hausa, object focus can be realized in two 
ways: either ex-situ or in-situ (Section 3.2). It 
was found that these realizations do not differ in 
their semantic type (Green & Jaggar 2003, 
Hartmann & Zimmermann 2007): instead, the 
marked form signals that the focused constituent 
(or the whole speech act) is unexpected for the 
hearer (Zimmermann 2008). These assumptions 
are consistent with findings for other African 
languages (Fiedler et al 2006).  
In order to verify such claims on corpora with 
morphosyntactic and syntactic annotation for the 
example of Hausa, a corpus query can be 
designed on the basis of the Hausar Baka corpus 
that comprises not only annotations for 
grammatical functions and information-structural 
categories, but also an annotation of ex-situ 
elements. 
 
21
So, in (3), we look for ex-situ constituents 
(variable #1) in declarative sentences in the 
Hausa Bakar corpus, i.e., sentences that are not 
translated as questions (variable #2) such that 
#1 is included in #2 (#1 _i_ #2). 
(3) EX-SITU=?+? & 
TRANSLATION=?.*[^?]? &     #1 
_i_ #2 
Considering the first 25 matches for this query 
on Hausar Baka, 16 examples reveal to be 
relevant (excluding interrogative pronouns and 
elliptical utterances). All of these are directly 
preceded by a period (sentence-initial) or a 
comma (preceded by ee ?yes?, interjections or 
exclamations), with one exception, preceded by a 
sentence initial negation marker. 
Only seven examples are morphologically 
marked by focus particles (nee, cee), focus-
sensitive adverbs (kaw?i ?only?) or quantifiers 
(koomee ?every?). In nine cases, a personal 
pronoun follows the ex-situ constituent, followed 
by the verb. Together, these constraints describe 
all examples retrieved, and as a generalization, 
we can now postulate a number of patterns that 
only make use of morphosyntactic and syntactic 
annotation (token tok, morphological 
segmentation MORPH, parts of speech CLASS, 
nominal chunks CHUNK) with two examples 
given below: 
 
 (4) tok=/[,.!?]/ & 
CHUNK=?NC? & MORPH=/[cn]ee/ & 
#1 . #2 & #2 . #3 
 (5) tok=/[,.!?]/ & 
CHUNK=?NC? & CLASS=/PRON.*/ & 
CLASS=/V/ & #1 . #2 &   #2 . 
#3 & #3 . #4 
 
In (4), we search for a nominal chunk 
following a punctuation sign and preceding a 
focus particle (cee or nee), in (5), we search for a 
nominal chunk preceding a sequence of 
pronoun/aspect marker and  verb.  
One example matching template (5) from the 
Hausar Baka corpus is given in Fig. 1. 
While AQL can be used in this way to help 
linguists understand the grammatical realization 
of certain phenomena, and the grammatical 
context they occur in, patterns like (5) above are 
probably not too readable to an interested user. 
This deficit, however, is compensated by the 
graphical query builder that allows users to 
create AQL queries in a more intuitive way, cf. 
Fig. 2. 
Of course, these patterns are not exhaustive 
and overgenerate. However, they can be directly 
evaluated against the manual ex-situ annotation 
in the Hausar Baka corpus and further refined.  
So, the manual annotation of ex-situ 
constituents in the Hausar Baka corpus provides 
templates for the semi-automatic detection of ex-
situ constituents in a morphosyntactically 
annotated corpus of Hausa: The patterns generate 
a set of candidate examples from which a human 
annotator can then choose real ex-situ 
constituents. Indeed, for a better understanding 
of ex-situ object focus, a study with a larger 
database of more natural language would be of 
great advantage, and this pattern-based approach 
represents a way to create such a database of ex-
situ constructions in Hausa. 
Finally, it would also help find instances of 
predicate focus. When a V(P) constituent is 
focused in Hausa, it is nominalized, and fronted 
like a focused nominal constituent (Hartmann & 
Zimmermann 2007). 
5.3 Related Corpus Tools 
Some annotation tools come with search 
facilities, e.g. Toolbox (Busemann & Busemann, 
2008), a system for annotating, managing and 
 
Figure 2: ANNIS Query Builder, cf. example (5). 
 
Figure 1: ANNIS partitur view, Hausar Baka corpus. 
22
analyzing language data, mainly geared to 
lexicographic use, and ELAN (Hellwig et al, 
2008), an annotation tool for audio and video 
data.  
In contrast, ANNIS is not intended to provide 
annotation functionality. The main reason behind 
this is that both Toolbox and ELAN are problem-
specific annotation tools with limited capabilities 
for application to different phenomena than they 
were designed for. Toolbox provides an intuitive 
annotation environment and search facilities for 
flat, word-oriented annotations; ELAN, on the 
other hand, for annotations that stand in a 
temporal relation to each other. 
These tools ? as well as the other annotation 
tools used within the CRC ? are tailored to a 
particular type of annotation, neither of them 
being capable of sufficiently representing the 
data from all other tools. Annotation on different 
levels, however, is crucial for the investigation of 
information structural phenomena. In order to fill 
in this gap, ANNIS was designed primarily with 
the focus on visualization and querying of multi-
layer annotations. In particular, ANNIS allows to 
integrate annotations originating from different 
tools (e.g., syntax annotation created with 
Synpathy, coreference annotation created with 
MMAX2, and flat, time-aligned annotations 
created with ELAN) that nevertheless refer to the 
same primary data. In this respect, ANNIS, 
together with the data format PAULA and the 
libraries created for the work with both, is best 
compared to general annotation frameworks such 
as ATLAS, NITE and LAF.  
Taking the NITE XML Toolkit as a 
representative example for this kind of 
frameworks, it provides an abstract data model, 
XML-based formats for data storage and 
metadata, a query language, and a library with 
JAVA routines for data storage and manipulation, 
querying and visualization. Additionally, a set of 
command line tools and simple interfaces for 
corpus querying and browsing are provided, 
which illustrates how the libraries can be used to 
create one's own, project-specific corpus 
interfaces and tools.  
Similarly to ANNIS, NXT supports time-
aligned, hierarchical and pointer-based 
annotation, conflicting hierarchies and the 
embedding of multi-modal primary data. The 
data storage format is based on the bundling of 
multiple XML files similar to the standoff 
concept employed in LAF and PAULA.  
One fundamental difference between NXT and 
ANNIS, however, is to be seen in the primary 
clientele it targets: The NITE XML Toolkit is 
aimed at the developer and allows to build more 
specialized displays, interfaces, and analyses as 
required by their respective end users when 
working with highly structured data annotated on 
multiple levels.  
As compared to this, ANNIS is directly 
targeted at the end user, that is, a linguist trying 
to explore and to work with a particular set of 
corpora. Therefore, an important aspect of the 
ANNIS implementation is the integration with a 
data base and convenient means for visualization 
and querying.  
6 Conclusion 
In this paper, we described the Africanist projects 
of the CRC ?Information Structure? at the 
University of Potsdam and the Humboldt 
University of Berlin/Germany, together with 
their data collections from currently 25 
subsaharan languages. Also, we have presented 
the linguistic database ANNIS that can be used to 
publish, access, query and visualize these data 
collections. As one specific example of our work, 
we have described the design and ongoing 
construction of a corpus of written Hausa, the 
Hausa internet corpus, sketched the relevant NLP 
techniques for (semi)automatic morphosyntactic 
annotation, and the application of the ANNIS 
Query Language to filter out ex-situ constituents 
and their contexts, which are relevant with regard 
to our goal, a better understanding of focus and 
information structure in Hausa and other African 
languages. 
References  
T. Brants, O. Plaehn. 2000. Interactive Corpus 
Annotation. In: Proc. of LREC 2000, Athens, 
Greece. 
A. Busemann, K. Busemann. 2008. Toolbox 
Self-Training. Technical Report (Version 1.5.4 
Oct 2008)  http://www.sil.org/ 
J. Carletta, S. Evert, U. Heid, J. Kilgour, J. 
Robertson, H. Voormann. 2003. The NITE 
XML Toolkit: Flexible Annotation for Multi-
modal Language Data. Behavior Research 
Methods, Instruments, and Computers 35(3), 
353-363. 
J. Carletta, S. Evert, U. Heid, J. Kilgour. 2005. 
The NITE XML Toolkit: data model and 
query. Language Resources and Evaluation 
Journal, 313-334. 
23
S. Dipper. 2005. XML-based Stand-off 
Representation and Exploitation of Multi-
Level Linguistic Annotation. In: Proc. of 
Berliner XML Tage 2005 (BXML 2005), 
Berlin, Germany, 39-50. 
S. Dipper, M. G?tze. 2005. Accessing 
Heterogeneous Linguistic Data - Generic 
XML-based Representation and Flexible 
Visualization. In Proc. of the 2nd Language & 
Technology Conference: Human Language 
Technologies as a Challenge for Computer 
Science and Linguistics. Poznan, Poland, 206-
210. 
S. Dipper, M. G?tze, S. Skopeteas (eds.). 2007. 
Information structure in cross-linguistic 
corpora: Annotation guidelines for phonology, 
morphology, syntax, semantics and 
information structure. Interdisciplinary 
Studies on Information Structure 7,  147-187. 
Potsdam: University of Potsdam. 
I. Fiedler. forthcoming. Contrastive topic 
marking in Gbe. In Proc. of the 18th 
International Conference on Linguistics, 
Seoul, Korea, 21. - 26. July 2008. 
I. Fiedler, K. Hartmann, B. Reineke, A. Schwarz, 
M. Zimmermann.. forthcoming. Subject Focus 
in West African Languages. In M. 
Zimmermann, C. F?ry (eds.), Information 
Structure. Theoretical, Typological, and 
Experimental Perspectives. Oxford: Oxford 
University Press. . 
M. Green, P. Jaggar. 2003. Ex-situ and in-situ 
focus in Hausa: syntax, semantics and 
discourse. In J. Lecarme et al (eds.), Research 
in Afroasiatic Grammar 2 (Current Issues in 
Linguistic Theory). Amsterdam: John 
Benjamins. 187-213. 
K. Hartmann, M. Zimmermann. 2004. Nominal 
and Verbal Focus in the Chadic Languages. In 
F. Perrill et al (eds.), Proc. of the Chicago 
Linguistics Society. 87-101. 
K. Hartmann, M. Zimmermann. 2007. In Place - 
Out of Place? Focus in Hausa. In K. Schwabe, 
S. Winkler (eds.), On Information Structure, 
Meaning and Form: Generalizing Across 
Languages. Benjamins, Amsterdam: 365-403. 
B. Hellwig, D. Van Uytvanck, M. Hulsbosch. 
2008. ELAN ? Linguistic Annotator. Technical 
Report (as of 2008-07-31). http://www.lat-
mpi.eu/tools/elan/ 
?. Kiss.  1998. Identificational Focus Versus 
Information Focus. Language 74: 245-273. 
M. Krifka. 1992. A compositional semantics for 
multiple focus constructions, in Jacobs, J: 
Informationsstruktur und Grammatik, 
Opladen, Westdeutscher Verlag, 17-53. 
C. M?ller, M. Strube. 2006. Multi-Level 
Annotation of Linguistic Data with MMAX2. 
In: S. Braun et al (eds.), Corpus Technology 
and Language Pedagogy. New Resources, 
New Tools, New Methods. Frankfurt: Peter 
Lang, 197?214. 
M. O?Donnell. 2000. RSTTool 2.4 ? A Markup 
Tool for Rhetorical Structure Theory. In: Proc. 
of the International Natural Language 
Generation Conference (INLG'2000), 13-16 
June 2000, Mitzpe Ramon, Israel, 253?256. 
C. Orasan. 2003. Palinka: A Highly 
Customisable Tool for Discourse Annotation. 
In: Proc. of the 4th SIGdial Workshop on 
Discourse and Dialogue, Sapporo, Japan. 
R. Randell, A. Bature, R. Schuh. 1998. Hausar 
Baka.   http://www.humnet.ucla.edu/humnet/ 
aflang/hausarbaka/ 
T. Schmidt. 2004. Transcribing and Annotating 
Spoken Language with Exmaralda. In: Proc. 
of the LREC-Workshop on XML Based Richly 
Annotated Corpora, Lisbon 2004. Paris: 
ELRA. 
A. Schwarz. Verb and Predication Focus Markers 
in Gur. forthcoming. In I. Fiedler, A. Schwarz 
(eds.), Information structure in African 
languages (Typological Studies in Language),  
307-333. Amsterdam, Philadelphia: John 
Benjamins. 
A. Schwarz, I. Fiedler. 2007. Narrative focus 
strategies in Gur and Kwa. In E. Aboh et al 
(eds.): Focus strategies in Niger-Congo and 
Afroasiatic ? On the interaction of focus and 
grammar in some African languages, 267-286. 
Berlin: Mouton de Gruyter. 
S. Skopeteas, I. Fiedler, S. Hellmuth, A. 
Schwarz, R. Stoel, G. Fanselow, C. F?ry, M. 
Krifka. 2006. Questionnaire on information 
structure (QUIS). Interdisciplinary Studies on 
Information Structure 4.  Potsdam: University 
of Potsdam. 
I. H. Witten, E. Frank, Data mining: Practical 
machine learning tools and techniques, 2nd 
edn, Morgan Kaufman, San Francisco, 2005. 
M. Zimmermann. 2008. Contrastive Focus and 
Emphasis. In Acta Linguistica Hungarica 55: 
347-360.  
24
Proceedings of the Third Linguistic Annotation Workshop, ACL-IJCNLP 2009, pages 35?43,
Suntec, Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
By all these lovely tokens...?
Merging Conflicting Tokenizations
Christian Chiarcos, Julia Ritz and Manfred Stede
Sonderforschungsbereich 632 ?Information Structure?
University of Potsdam
Karl-Liebknecht-Str. 24-25, 14476 Golm, Germany
{chiarcos|julia|stede}@ling.uni-potsdam.de
Abstract
Given the contemporary trend to modular
NLP architectures and multiple annotation
frameworks, the existence of concurrent
tokenizations of the same text represents
a pervasive problem in everyday?s NLP
practice and poses a non-trivial theoretical
problem to the integration of linguistic an-
notations and their interpretability in gen-
eral. This paper describes a solution for
integrating different tokenizations using a
standoff XML format, and discusses the
consequences for the handling of queries
on annotated corpora.
1 Motivation
1.1 Tokens: Functions and goals
For most NLP tasks and linguistic annotations,
especially those concerned with syntax (part-of-
speech tagging, chunking, parsing) and the inter-
pretation of syntactic structures (esp., the extrac-
tion of semantic information), tokens represent
the minimal unit of analysis: words (lexemes,
semantic units, partly morphemes) on the one
hand and certain punctuation symbols on the other
hand. From a corpus-linguistic perspective, tokens
also represent the minimal unit of investigation,
the minimal character sequence that can be ad-
dressed in a corpus query (e.g. using search tools
like TIGERSearch (Ko?nig and Lezius, 2000) or
CWB (Christ, 1994)). Tokens also constitute the
basis for ?word? distance measurements. In many
annotation tools and their corresponding formats,
the order of tokens provides a timeline for the
sequential order of structural elements (MMAX
(Mu?ller and Strube, 2006), GENAU (Rehm et al,
2009), GrAF (Ide and Suderman, 2007), TIGER
XML (Ko?nig and Lezius, 2000)). In several multi-
?Taken from the poem September by Helen Hunt Jackson.
layer formats, tokens also define the absolute po-
sition of annotation elements, and only by refer-
ence to a common token layer, annotations from
different layers can be related with each other
(NITE (Carletta et al, 2003), GENAU).
Thus, by their function, tokens have the fol-
lowing characteristics: (i) tokens are totally or-
dered, (ii) tokens cover the full (annotated portion
of the) primary data, (iii) tokens are the smallest
unit of annotation, and (iv) there is only one sin-
gle privileged token layer. The last aspect is es-
pecially relevant for the study of richly annotated
data, as an integration and serialization of anno-
tations produced by different tools can be estab-
lished only by reference to the token layer. From
a corpus-linguistic perspective, i.e., when focus-
ing on querying of annotated corpora, tokens need
to be well-defined and all information annotated
to a particular text is to be preserved without any
corruption. We argue that for this purpose, char-
acteristic (iii) is to be abandoned, and we will de-
scribe the data format and an algorithm for merg-
ing different tokenizations and their respective an-
notations.
Our goal is a fully automated merging of anno-
tations that refer to different tokenizations (hence-
forth T ? and T ?) of the same text. We regard the
following criteria as crucial for this task:
Information preservation. All annotations ap-
plied to the original tokenizations should be pre-
served.
Theoretically well-defined notion of token. It
should be possible to give a plausible list of posi-
tive criteria that define character sequences as to-
kens. Knowledge about the token definition is es-
sential for formulating queries for words, e.g. in a
corpus search interface.
Integrative representation. All annotations that
are consistent with the merged tokenization should
refer to the merged tokenization. This is necessary
in order to query across multiple annotations orig-
35
inating from different annotation layers or tools.
Unsupervised merging. The integration of con-
flicting tokenizations should not require manual
interference.
1.2 Tokenization
Tokenization is the process of mapping sequences
of characters to sequences of words (cf. Guo
1997). However, different research questions or
applications induce different conceptions of the
term ?word?. For a shallow morphosyntactic anal-
ysis (part of speech tagging), a ?simple? tokeniza-
tion using whitespaces and punctation symbols as
delimiters seems acceptable for the examples in
(1). A full syntactic analysis (parsing), however,
could profit from the aggregation of complex nom-
inals into one token each.
(1) a. department store
b. Herzog-von der Heide1
c. Red Cross/Red Crescent movement
Similarly, examples (2a) and (2b) can be ar-
gued to be treated as one token for (mor-
pho)syntactic analyses, respectively. Despite in-
tervening whitespaces and punctuation symbols,
they are complex instances of the ?classical? part-
of-speech adjective. For certain semantic analyses
such as in information extraction, however, it may
be useful to split these compounds in order to ac-
cess the inherent complements (E 605, No. 22).
(2) a. E 605-intoxicated
b. No. 22-rated
Finally, (3) illustrates a morphology-based tok-
enization strategy: the principle of splitting at
morpheme boundaries (Marcus et al, 1993, PTB)
(token boundaries represented by square brack-
ets). Morphological tokenization may help distri-
butional (co-occurrence-based) semantics and/or
parsing; however, the resulting tokens might be
argued as being less intuitive to users of a corpus
search tool.
(3) a. [Mitchell][?s], [they][?ve], [do][n?t]
b. [wo][n?t], [ca][n?t], [ai][n?t]
These examples show that different applications
(tagging, parsing, information extraction) and the
focus on different levels of description (morphol-
ogy, syntax, semantics) require specialized tok-
enization strategies. When working with multiple
1Double surname consisting of Herzog and von der Heide.
tools for standard NLP tasks, thus, it is the norm
rather than the exception that they disagree in their
tokenization, as shown in ex. (4).
(4) doesn?t
a. [does][n?t] (Marcus et al, 1993, PTB)
b. [doesn][?][t] (Brants, 2000, TnT)
When creating a corpus that is annotated at multi-
ple levels and/or using several tools, different tok-
enizations are not always avoidable, as some tools
(automatic NLP tools, but also tools for manual
annotation) have integrated tokenizers. Another
challenge is the representation of token bound-
aries. Commonly, token boundaries are repre-
sented by a line break (?\n?) or the whitespace
?character? (? ?) ? in which case token-internal
whitespaces are replaced, usually by an under-
score (? ?) ?, thereby corrupting the original data.
This practice makes reconciling/merging the data
a difficult enterprise.
Given this background, we suggest an XML-
based annotation of token boundaries, such that
token boundaries are marked without affecting the
original primary data. In a straightforward XML
model, tokens are represented by XML elements
enclosing primary text slices (c.f. the BNC encod-
ing scheme (Burnard, 2007)). However, treating
tokens as spans of text by means of the XML hier-
archy is impossible for tokenization conflicts as in
(4.a) and (4.b).
2 Conflicting tokenizations:
Straightforward strategies
By ?straightforward strategies?, we mean ap-
proaches that aim to preserve the definition of to-
kens as atomic, minimal, unambiguous units of
annotation when unifying different tokenizations
(henceforth T ? and T ?) of the same text. By ?un-
supervised straightforward strategies?, we mean
tokenization strategies that operate on the primary
data only, without consulting external resources
such as dictionaries or human expertise.
Unsupervised straightforward strategies to the
task include:
1. no merging In a conservative approach, we
could create independent annotation projects for
every tokenization produced, and thus represent
all tokenizations independently. This, however,
rules out any integration or combined evaluation
of annotations to T ? and annotations to T ?.
36
2. normalization Adopt one of the source tok-
enizations, say T ?, as the ?standard? tokenization.
Preserve only the information annotated to T ? that
is consistent with T ?. Where tokenization T ? de-
viates from T ?, all annotations to T ? are lost.2
3. maximal tokens For every token boundary
in T ? that is also found in T ?, establish a token
boundary in the merged tokenization (cf. Guo?s
1997 ?critical tokenization?). However, with to-
kens assumed to be the minimal elements of anno-
tation, we lose linguistic analyses of fine-grained
tokens. With respect to (4.a) and (4.b), the max-
imal token would be the whole phrase doesn?t.
Again, this results in a loss of information, as all
annotations applied to does, doesn, n?t, ? and t re-
fer to units that are smaller than the resulting to-
ken.
4. maximal common substrings For every
token boundary in T ? or T ?, establish a token
boundary, thereby producing minimal tokens:
one token for every maximal substring shared
between T ? and T ? (cf. Guo?s 1997 ?shortest
tokenization?). By defining the original tokens
(?supertokens?) as annotations spanning over
tokens, all annotations are preserved. However,
the concept of ?token? loses its theoretical motiva-
tion; there is no guarantee that maximal common
substrings are meaningful elements in any sense:
The maximum common substring tokenization
of 4.a and 4.b is [does][n][?][t], but [n] is not
a well-defined token. It is neither defined with
respect to morphology (like PTB tokens) nor is
it motivated from orthography (like TnT tokens),
but it is just the remainder of their intersection.
As shown in Table 1, none of the strategies
sketched above fulfills all criteria identified in Sec-
tion 1.1: Avoiding a merging process counteracts
data integration; token normalization and maximal
tokens violate information preservation, and maxi-
mal common substrings violate the requirement to
specify a theoretically well-defined notion of to-
ken.
As an alternative, we propose a formalism for
the lossless integration and representation of con-
2Alternatively, transformation rules to map annotations
from T ? to T ? would have to be developed. This does, how-
ever, not guarantee information preservation, and, addition-
ally, it requires manual work, as such transformations are
annotation-specific. Thus, it is not an option for the fully
automated merging of tokenizations.
Table 1: Deficits of ?straightforward? merging ap-
proaches
no normalize max. max. common
merge tokens substrings
information preservation
+ ? ? +
well-defined tokens
+ + (?) ?
integrative
? + + +
unsupervised
(+) + + +
flicting tokenizations by abandoning the assump-
tion that tokens are an atomic, primitive con-
cept that represents the minimal unit of annota-
tion. Rather, we introduce annotation elements
smaller than the actual token ? so-called termi-
nals or terms for short ? that are defined accord-
ing to the maximum common substrings strategy
described above.
Then, tokens are defined as nodes that span
over a certain range of terms similar to phrase
nodes that dominate other nodes in syntax annota-
tions. The representation of conflicting tokeniza-
tions, then, requires a format that is capable to
express conflicting hierarchies. For this purpose,
we describe an extension of the PAULA format, a
generic format for text-oriented linguistic annota-
tions based on standoff XML.
3 Conflicting tokenizations in the
PAULA format
3.1 Annotation structures in PAULA 1.0
The PAULA format (Dipper, 2005; Dipper and
Go?tze, 2005) is a generic XML format, used as a
pivot format in NLP pipelines (Stede et al, 2006)
and in the web-based corpus interface ANNIS
(Chiarcos et al, 2008). It uses standoff XML rep-
resentations, and is conceptually closely related to
the formats NITE XML (Carletta et al, 2003) and
GraF (Ide and Suderman, 2007).
PAULA was specifically designed to support the
lossless representation of different types of text-
oriented annotations (layer-based/timeline anno-
tations, hierarchical annotations, pointing rela-
tions), optimized for the annotation of multiple
layers, including conflicting hierarchies and sim-
ple addition/deletion routines for annotation lay-
ers. Therefore, primary data is stored in a separate
37
Table 2: PAULA 1.0 data types
nodes (structural units of annotation)
token character spans in the primary data that form the basis
for higher-level annotation
markable (spans of) token(s) that can be annotated with lin-
guistic information. Markables represent flat, layer-based
annotations defined with respect to the sequence of tokens
as a general timeline.
struct hierarchical structures (DAGs or trees) are formed by
establishing a dominance relation between a struct (e.g.,
a phrase) node as parent, and tokens, markables, or other
struct nodes as children.
edges (relational units of annotation, connecting tokens,
markables, structs)
dominance relation directed edge between a struct
and its children
pointing relations directed edge between nodes in
general (tokens, markables, structs)
labels (annotations: node or edge labels)
features represent annotations attached to a particular
(structural or relational) unit of annotation
file. Multiple annotations are also stored in sepa-
rate files to avoid interference between concurrent
annotations. Annotations refer to the primary data
or to other annotations by means of XLinks and
XPointers.
As types of linguistic annotation, we distinguish
nodes (token, markable, struct), edges (dominance
and pointing relations) and labels (annotations), as
summarized in Table 2. Each type of annotation
is stored in a separate file, so that competing or
ambiguous annotations can be represented in an
encapsulated way.
PAULA 1.0 is already sufficiently expressive for
capturing the data-heterogeneity sketched above,
including the representation of overlapping seg-
ments, intersecting hierarchies, and alternative an-
notations (e.g., for ambiguous annotations), but
only for annotations above the token level. Fur-
ther, PAULA 1.0 relies on the existence of a
unique layer of non-overlapping, atomic tokens as
minimal units of annotation: For all nodes, their
position and sequential order is defined with re-
spect to the absolute position of tokens that they
cover; and for the special case of markables, these
are defined solely in terms of their token range.
Finally, PAULA 1.0 tokens are totally ordered,
they cover the (annotated) primary data com-
pletely, and they are non-overlapping. Only on
this basis, the extension and (token-)distance of
annotated elements can be addressed; and only
by means of unambiguous reference, information
from different layers of annotation can be com-
bined and evaluated.
3.2 Introducing terminal nodes
In our extension of the PAULA format, we in-
troduce the new concept of term nodes: atomic
terminals that directly point to spans of primary
data. Terms are subject to the same constraints as
tokens in PAULA 1.0 (total order, full coverage,
non-overlapping). So, terms can be used in place
of PAULA 1.0 tokens to define the extension and
position of super-token level and sub-token level
annotation elements.
Markables are then defined with respect to
(spans of) terminal nodes rather than tokens, such
that alternative tokenizations can be expressed as
markables in different layers that differ in their ex-
tensions.
Although terms adopt several functions for-
merly associated with tokens, a privileged token
layer is still required: In many query languages,
including ANNIS-QL (Chiarcos et al, 2008), to-
kens define the application domain of regular ex-
pressions on the primary data. More impor-
tantly, tokens constitute the basis for conventional
(?word?) distance measurements and (?word?)
coverage queries. Consequently, the constraints
on tokens (total order, full coverage and absence
of overlap) remain.
The resulting specifications for structural units
of annotation are summarized in Table 3. Distin-
guishing terminal elements and re-defining the to-
ken layer as a privileged layer of markables al-
lows us to disentangle the technical concept of
?atomic element? and ?token? as the convention-
ally assumed minimal unit of linguistic analysis.
3.3 A merging algorithm
In order to integrate annotations on tokens, it is
not enough to represent two tokenizations side by
side with reference to the same layer of terminal
nodes. Instead, a privileged token layer is to be es-
tablished and it has to be ensured that annotations
can be queried with reference to the token layer.
38
Table 3: PAULA extensions: revised node types
terms specify character spans in the primary data
that form the basis for higher-level annota-
tion
markable defined as above, with terms taking the
place of tokens
structs defined as above, with terms taking the
place of tokens
tokens sub-class of structs that are non-
overlapping, arranged in a total order,
and cover the full primary data
Then, all annotations whose segmentation is con-
sistent with the privileged token layer are directly
linked with tokens.
Alg. 3.1 describes our merging algorithm, and
its application to the four main cases of conflict-
ing tokenization is illustrated in Figure 1.3 The
following section describes its main characteris-
tics and the consequences for querying.
4 Discussion
Alg. 3.1 produces a PAULA project with one sin-
gle tokenization. So, it is possible to define queries
spanning across annotations with originally differ-
ent tokenization:
Extension and precedence queries are
tokenization-independent: Markables refer to
the term layer, not the tok layer, structs also
(indirectly) dominate term nodes.
Dominance queries for struct nodes and tokens
yield results whenever the struct node dominates
only nodes with tok-compatible source tokeniza-
tion: Structs dominate tok nodes wherever the
original tokenization was consistent with the
privileged tokenization tok (case A and C in Fig.
1).
Distance queries are defined with respect to the
tok layer, and are applicable to all elements that
are are defined with reference to the tok layer (in
figure 1: tok?a, tok?a, tok?b, tok?b in case A; tokab
in case B; toka, tokb, tokab in case C; tokab, tokc
in case D). They are not applicable to elements
that do not refer to the tok layer (B: toka, tokb; D:
toka, tokbc).
3Notation: prim ? primary data / tok, term ? annota-
tion layers / t ? L ? t is a node on a layer L / a..b ? con-
tinuous span from tok/term a to tok/term b / a, b ? list of
tok/term/markable nodes a, b / t = [a] ? t is a node (struct,
markable, tok) that points to a node, span or list a
The algorithm is unsupervised, and the token
concept of the output tokenization is well-defined
and consistent (if one of the input tokenizations
is adopted as target tokenization). Also, as shown
below, it is integrative (enabling queries across dif-
ferent tokenizations) and information-preserving
(reversible).
4.1 Time complexity
After a PAULA project has been created, the time
complexity of the algorithm is quadratic with re-
spect to the number of characters in the primary
data n. This is due to the total order of tokens:
Step 2 and 3.a are applied once to all original to-
kens from left to right. Step 5 can be reformulated
such that for every terminal node, the relationship
between the directly dominating tok? and tok? is
checked. Then, Step 5 is also in O(n). In terms of
the number of markables m, the time complexity
in Step 3.b is in O(n m): for every markable, the
corresponding term element is to be found, tak-
ing at most n repositioning operations on the term
layer. Assuming that markables within one layer
are non-overlapping4 and that the number of lay-
ers is bound by some constant c5, then m ? n c,
so that 3.b is in O(n? c).
For realistic scenarios, the algorithm is thus
quadratic.
4.2 Reversibility
The merging algorithm is reversible ? and, thus,
lossless ? as shown by the splitting algorithm in
Alg. 3.2. For reasons of space, the correctness
of this algorithm cannot be demonstrated here, but
broadly speaking, it just removes every node that
corresponds to an original token of the ?other? tok-
enization, plus every node that points to it, so that
only annotations remain that are directly applied
to the target tokenization.
4.3 Querying merged tokenizations
We focus in this paper on the merging of analy-
ses with different tokenizations for the purpose of
users querying a corpus across multiple annota-
4Although PAULA supports overlapping markables
within one single layer, even with identical extension, this is
a reasonable assumption: In practice, overlapping markables
within one single layer are rare. More often, there is even a
longer sequence of primary data between one markable of a
particular layer and the next. In our experience, such ?gaps?
occur much more often than overlapping markables.
5Again, this is a practical simplication. Theoretically, the
number of layers is infinite.
39
Alg. 3.1 Merging different tokenizations
0. assume that we have two annotations analysis? and analysis? for the same primary data, but with different tokenizations
1. create PAULA 1.0 annotation projects for analysis? and analysis? with primary data files prim? and prim? and token
layers tok? and tok? respectively.
2. harmonize primary data
if prim? equals prim?, then
(i) rename prim? to prim
(ii) set al references in analysis? from prim? to prim
(iii) create a new annotation project analysis by copying prim and all annotation layers from analysis? and analysis?
otherwise terminate with error msg
3. harmonize terminal nodes
create a new annotation layer term, then
(a) for all overlapping tokens t? ? tok? and t? ? tok?: identify the maximal common substrings of t? and t?
for every substring s, create a new element terms pointing to the corresponding character span in the primary data
for every substring s, redefine t? and t? as markables referring to terms
(b) redefine markable spans as spans of terminal nodes
for every token t = [terms? ..terms? ] ? tok? ? tok? and every markable m = [w..xty..z]: set m =
[w..xterms? ..terms?y..z]
4. select token layer
rename tok? to tok, or rename tok? to tok, (cf. the normalization strategy in Sect. 2) or
rename term to tok (cf. the minimal tokens strategy in Sect. 2)
5. token integration
for every original token ot = [a..b] ? (tok? ? tok?) \ tok:
if there is a token t ? tok such that t = [a..b], then define ot as a struct with ot = [t], else
if there are tokens t?, .., tn ? tok such that t?..tn form a continuous sequence of tokens and t? = [a..x] and tn = [y..b],
then define ot as a struct such that ot = [t?, .., tn],
otherwise: change nothing
Figure 1: Merging divergent tokenizations
40
Alg. 3.2 Splitting a PAULA annotation project
with two different tokenizations
0. given a PAULA annotation project analysis with token
layer tok, terminal layer term, and two layers l? and l?
(that may be identical to term or tok) that convey the
information of the original token layers tok? and tok?
1. create analysis? and analysis? as copies of analysis
2. if l? represents a totally ordered, non-overlapping list of
nodes that cover the primary data completely, then modify
analysis?:
a. for every node in l?: substitute references to tok? by
references to term?
b. remove l? from analysis?
c. if l? 6= tok?, remove tok? from analysis?
d. for every annotation element (node/relation) e in
analysis? that directly or indirectly points to another
node in analysis? that is no longer present, remove e
from analysis?
e. remove every annotation layer from analysis? that
does not contain an annotation element
f. for every markable in l?: remove references to term?,
define the extension of l? nodes directly in terms of
spans of text in prim?
g. if l? 6= term?, remove term?
3. perform step 2. for l? and analysis?
tion layers. Although the merging algorithm pro-
duces annotation projects that allow for queries in-
tegrating annotations from analyses with different
tokenization, the structure of the annotations is al-
tered, such that the behaviour of merged and un-
merged PAULA projects may be different. Obvi-
ously, token-level queries must refer to the priv-
ileged tokenization T ?. Operators querying for
the relative precedence or extension of markables
are not affected: in the merged annotation project,
markables are defined with reference to the layer
term: originally co-extensional elements E? and
E? (i.e. elements covering the same tokens in the
source tokenization) will also cover the same ter-
minals in the merged project. Distance operators
(e.g. querying for two tokens with distance 2, i.e.
with two tokens in between), however, will oper-
ate on the new privileged tokenization, such that
results from queries on analysis may differ from
those on analysis?. Dominance operators are
also affected, as nodes that directly dominated a
token in analysis? or analysis? now indirectly
dominate it in analysis, with a supertoken as an
intermediate node.
Alg. 3.3 Iterative merging: modifications of Alg.
3.1, step.3
if analysis? has a layer of terminal nodes term?, then let
T ? = term?, otherwise T ? = tok?
if analysis? has a layer of terminal nodes term?, then let
T ? = term?, otherwise T ? = tok?
create a new annotation layer term, then
1. for all overlapping terminals/tokens t? ? T ? and t? ?
T ?: identify the maximal common substrings of t? and
t?
for every substring s, create a new element terms
pointing to the corresponding character span in the pri-
mary data
for every substring s, redefine t? and t? as markables
referring to terms
2. redefine markable spans as spans of terminal nodes
for every node t = [terms? ..terms? ] ? T ? ? T ?
and every markable m = [w..xty..z]: set
m = [w..xterms? ..terms?y..z]
3. for all original terminals t ? T ??T ?: if t is not directly
pointed at, remove t from analysis
Accordingly, queries applicable to PAULA
projects before the merging are not directly appli-
cable to merged PAULA projects. Users are to be
instructed to keep this in mind and to be aware of
the specifications for the merged tokenization and
its derivation.6
5 Extensions
5.1 Merging more than two tokenizations
In the current formulation, Alg. 3.1 is applied to
two PAULA 1.0 projects and generates extended
PAULA annotation projects with a term layer.
The algorithm, however, may be applied itera-
tively, if step 3 is slightly revised, such that ex-
tended PAULA annotation projects can also be
merged, see Alg. 3.3.
5.2 Annotation integration
The merging algorithm creates a struct node for
every original token. Although this guarantees re-
versibility, one may consider to remove such re-
dundant structs. Alg. 3.4 proposes an optional
postprocessing step for the merging algorithm.
This step is optional because these operations are
6The information, however, is preserved in the format and
may be addressed by means of queries that, for example, op-
erate on the extension of terminals.
41
Alg. 3.4 Annotation integration: Optional post-
processing for merging algorithm
6.a. remove single-token supertoken
for every original token ot = [t] ? tok? ? tok? with
t ? tok: replace all references in analysis to ot by
references to t, remove ot
6.b. merging original token layers tok? and tok? (if
tok? 6= tok and tok? 6= tok)
define new ?super token? layer stok.
for every ot ? tok? ? tok?:
if ot = [t] for some t ? tok, then see 6.a
if ot = [t?, .., tn] for some t?, .., tn ? tok, and
there is ot? = [t?, .., tn] ? tok? ? tok? ? stok,
then replace all references in analysis to ot? by
references to ot, move ot to layer stok, remove
ot? from analysis
move all remaining ot ? tok? ? tok? to stok, remove
layers tok? and tok?
6.c. unify higher-level annotations
for every markable mark? = [term?..termn] and
term?, .., termn ? term:
if there is a markable mark? in analysis such
that mark? = [term?..termn], then replace all
references in analysis to mark? by references to
mark?, remove mark?
for every struct struct? = [c?, .., cn] that covers ex-
actly the same children as another struct struct? =
[c?, .., cn], replace all references to struct? by refer-
ences to struct?, remove struct?
destructive: We lose the information about the ori-
gin (analysis? vs. analysis?) of stok elements
and their annotations.
6 Summary and Related Reasearch
In this paper, we describe a novel approach for the
integration of conflicting tokenizations, based on
the differentiation between a privileged layer of
tokens and a layer of atomic terminals in a stand-
off XML format: Tokens are defined as structured
units that dominate one or more terminal nodes.
Terminals are atomic units only within the re-
spective annotation project (there is no unit ad-
dressed that is smaller than a terminal). By iter-
ative applications of the merging algorithm, how-
ever, complex terms may be split up in smaller
units, so that they are not atomic in an absolute
sense.
Alternatively, terms could be identified a priori
with the minimal addressable unit available, i.e.,
characters (as in the formalization of tokens as
charspans and charseqs in the ACE information
extraction annotations, Henderson 2000). It is not
clear, however, how a character-based term defini-
tion would deal with sub-character and zero exten-
sion terms: A character-based definition of terms
that represent traces is possible only by corrupt-
ing the primary data.7 Consequently, a character-
based term definition is insufficient unless we re-
strict ourselves to a particular class of languages,
texts and phenomena.
The role of terminals can thus be compared to
timestamps: With reference to a numerical time-
line, it is always possible to define a new event
between two existing timestamps. Formats specif-
ically designed for time-aligned annotations, e.g.,
EXMARaLDA (Schmidt, 2004), however, typi-
cally lack a privileged token layer and a formal
concept of tokens. Instead, tokens, as well as
longer or shorter sequences, are represented as
markables, defined by their extension on the time-
line.
Similarly, GrAF (Ide and Suderman, 2007), al-
though being historically related to PAULA, does
not have a formal concept of a privileged token
layer in the sense of PAULA.8 We do, however,
assume that terminal nodes in GrAF can be com-
pared to PAULA 1.0 tokens.
For conflicting tokenizations, Ide and Suderman
(2007) suggest that ?dummy? elements are defined
covering all necessary tokenizations for controver-
sially tokenized stretches of primary data. Such
dummy elements combine the possible tokeniza-
tions for strategies 1 (no merging) and 3 (maxi-
mal tokens), so that the information preservation
deficit of strategy 3 is compensated by strategy 1,
and the integrativity deficit of strategy 1 is com-
pensated by strategy 3 (cf. Table 1). However, to-
kens, if defined in this way, are overlapping and
thus only partially ordered, so that distance opera-
tors are no longer applicable.9
7Similarly, phonological units that are not expressed in
the primary data can be subject to annotations, e.g., short e
and o in various Arabic-based orthographies, e.g., the Ajami
orthography of Hausa. A term with zero extension at the po-
sition of a short vowel can be annotated as having the phono-
logical value e or o without having character status.
8https://www.americannationalcorpus.
org/graf-wiki/wiki/WikiStart#GraphModel,
2009/05/08
9This can be compensated by marking the base segmen-
tation differently from alternative segmentations. In the ab-
stract GrAF model, however, this can be represented only by
means of labels, i.e., annotations. A more consistent con-
42
Another problem that arises from the introduc-
tion of dummy nodes is their theoretical status, as
it is not clear how dummy nodes can be distin-
guished from annotation structured on a concep-
tual level. In the PAULA formalization, dummy
nodes are not necessary, so that this ambiguity is
already resolved in the representation.
References
Thorsten Brants. 2000. TnT A Statistical Part-of-
Speech Tagger. In Proceedings of the Sixth Con-
ference on Applied Natural Language Processing
ANLP-2000. Seattle, WA.
Lou Burnard (ed.). 2007. Reference Guide
for the British National Corpus (XML Edi-
tion). http://www.natcorp.ox.ac.uk/
XMLedition/URG/bnctags.html.
Jean Carletta, Stefan Evert, Ulrich Heid, Jonathan
Kilgour, Judy Robertson, and Holger Voormann.
2003. The NITE XML Toolkit: Flexible Annotation
for Multi-modal Language Data. Behavior Research
Methods, Instruments, and Computers 35(3), 353-
363.
Christian Chiarcos, Stefanie Dipper, Michael Go?tze,
Ulf Leser, Anke Lu?deling, Julia Ritz, and Manfred
Stede. 2009. A Flexible Framework for Integrating
Annotations from Different Tools and Tagsets TAL
(Traitement automatique des langues) 49(2).
Oli Christ. 1994. A modular and flexible architec-
ture for an integrated corpus query system. COM-
PLEX?94, Budapest, Hungary.
Stefanie Dipper. 2005. XML-based Stand-off Repre-
sentation and Exploitation of Multi-Level Linguistic
Annotation. In Rainer Eckstein and Robert Tolks-
dorf (eds:): Proceedings of Berliner XML Tage,
pages 39-50.
Stefanie Dipper and Michael Go?tze. 2005. Accessing
Heterogeneous Linguistic Data ? Generic XML-
based Representation and Flexible Visualization. In
Proceedings of the 2nd Language & Technology
Conference 2005, Poznan, Poland, pages 23?30.
Stefanie Dipper, Michael Go?tze. 2006. ANNIS:
Complex Multilevel Annotations in a Linguistic
Database. Proceedings of the 5th Workshop on NLP
and XML (NLPXML-2006): Multi-Dimensional
Markup in Natural Language Processing. Trento,
Italy.
Jin Guo. 1997. Critical Tokenization and its Proper-
ties, Computational Linguistic, 23(4), pp.569-596.
ception would encode structural information on the structural
level, and only linguistic annotation and metadata on the con-
tents level.
John C. Henderson. 2000. A DTD for Reference Key
Annotation of EDT Entities and RDC Relations
in the ACE Evaluations (v. 5.2.0, 2000/01/05),
http://projects.ldc.upenn.edu/ace/
annotation/apf.v5.2.0.dtd (2009/06/04)
Nancy Ide and Keith Suderman. 2007. GrAF: A
Graph-based Format for Linguistic Annotations. In
Proceedings of the Linguistic Annotation Work-
shop,held in conjunction with ACL 2007, Prague,
June 28-29, 1-8.
Esther Ko?nig and Wolfgang Lezius. 2000. A descrip-
tion language for syntactically annotated corpora.
In: Proceedings of the COLING Conference, pp.
1056-1060, Saarbru?cken, Germany.
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a large annotated
corpus of English: the Penn treebank. Computa-
tional Linguistics 19, pp.313-330.
Christoph Mu?ller and Michael Strube. 2006. Multi-
Level Annotation of Linguistic Data with MMAX2.
In: S. Braun et al (eds.), Corpus Technology and
Language Pedagogy. New Resources, New Tools,
New Methods. Frankfurt: Peter Lang, 197?214.
Georg Rehm, Oliver Schonefeld, Andreas Witt, Chris-
tian Chiarcos, and Timm Lehmberg. 2009.
SPLICR: A Sustainability Platform for Linguistic
Corpora and Resources. In: Text Resources and
Lexical Knowledge. Selected Papers the 9th Confer-
ence on Natural Language Processing (KONVENS
2008), Berlin, Sept. 30 ? Oct. 2, 2008. Mouton de
Gruyter.
Helmut Schmid. 2002. Tokenizing & Tagging. In
Lu?deling, Anke and Kyto?, Merja (Hrsg.) Corpus
Linguistics. An International Handbook. (HSK Se-
ries). Mouton de Gryuter, Berlin
Thomas Schmidt. 2004. Transcribing and Annotat-
ing Spoken Language with Exmaralda. Proceedings
of the LREC-workshop on XML Based Richly Anno-
tated Corpora. Lisbon, Portugal. Paris: ELRA.
Manfred Stede, Heike Bieler, Stefanie Dipper, and
Arthit Suriyawongkul. 2006. SUMMaR: Combin-
ing Linguistics and Statistics for Text Summariza-
tion. Proceedings of the 17th European Conference
on Artificial Intelligence (ECAI-06). pp 827-828.
Riva del Garda, Italy.
Ralph Weischedel, Sameer Pradhan, Lance Ramshaw
and Linnea Micciulla. 2006. OntoNotes Release
1.0. Linguistic Data Consortium, Philadelphia.
43
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 659?670,
Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational Linguistics
Towards robust multi-tool tagging. An OWL/DL-based approach
Christian Chiarcos
University of Potsdam, Germany
chiarcos@uni-potsdam.de
Abstract
This paper describes a series of experi-
ments to test the hypothesis that the paral-
lel application of multiple NLP tools and
the integration of their results improves the
correctness and robustness of the resulting
analysis.
It is shown how annotations created by
seven NLP tools are mapped onto tool-
independent descriptions that are defined
with reference to an ontology of linguistic
annotations, and how a majority vote and
ontological consistency constraints can be
used to integrate multiple alternative ana-
lyses of the same token in a consistent
way.
For morphosyntactic (parts of speech) and
morphological annotations of three Ger-
man corpora, the resulting merged sets of
ontological descriptions are evaluated in
comparison to (ontological representation
of) existing reference annotations.
1 Motivation and overview
NLP systems for higher-level operations or com-
plex annotations often integrate redundant modu-
les that provide alternative analyses for the same
linguistic phenomenon in order to benefit from
their respective strengths and to compensate for
their respective weaknesses, e.g., in parsing (Crys-
mann et al, 2002), or in machine translation (Carl
et al, 2000). The current trend to parallel and dis-
tributed NLP architectures (Aschenbrenner et al,
2006; Gietz et al, 2006; Egner et al, 2007; Lu??s
and de Matos, 2009) opens the possibility of ex-
ploring the potential of redundant parallel annota-
tions also for lower levels of linguistic analysis.
This paper evaluates the potential benefits of
such an approach with respect to morphosyntax
(parts of speech, pos) and morphology in German:
In comparison to English, German shows a rich
and polysemous morphology, and a considerable
number of NLP tools are available, making it a
promising candidate for such an experiment.
Previous research indicates that the integration
of multiple part of speech taggers leads to more
accurate analyses. So far, however, this line of re-
search focused on tools that were trained on the
same corpus (Brill and Wu, 1998; Halteren et al,
2001), or that specialize to different subsets of the
same tagset (Zavrel and Daelemans, 2000; Tufis?,
2000; Borin, 2000). An even more substantial in-
crease in accuracy and detail can be expected if
tools are combined that make use of different an-
notation schemes.
For this task, ontologies of linguistic annota-
tions are employed to assess the linguistic infor-
mation conveyed in a particular annotation and to
integrate the resulting ontological descriptions in a
consistent and tool-independent way. The merged
set of ontological descriptions is then evaluated
with reference to morphosyntactic and morpho-
logical annotations of three corpora of German
newspaper articles, the NEGRA corpus (Skut et
al., 1998), the TIGER corpus (Brants et al, 2002)
and the Potsdam Commentary Corpus (Stede,
2004, PCC).
2 Ontologies and annotations
Various repositories of linguistic annotation termi-
nology have been developed in the last decades,
ranging from early texts on annotation standards
(Bakker et al, 1993; Leech and Wilson, 1996)
over relational data base models (Bickel and
Nichols, 2000; Bickel and Nichols, 2002) to
more recent formalizations in OWL/RDF (or with
OWL/RDF export), e.g., the General Ontology of
Linguistic Description (Farrar and Langendoen,
2003, GOLD), the ISO TC37/SC4 Data Cate-
gory Registry (Ide and Romary, 2004; Kemps-
659
Snijders et al, 2009, DCR), the OntoTag ontology
(Aguado de Cea et al, 2002), or the Typological
Database System ontology (Saulwick et al, 2005,
TDS). Despite their common level of representa-
tion, however, these efforts have not yet converged
into a unified and generally accepted ontology of
linguistic annotation terminology, but rather, dif-
ferent resources are maintained by different com-
munities, so that a considerable amount of dis-
agreement between them and their respective defi-
nitions can be observed.1
Such conceptual mismatches and incompatibi-
lities between existing terminological repositories
have been the motivation to develop the OLiA ar-
chitecture (Chiarcos, 2008) that employs a shal-
low Reference Model to mediate between (onto-
logical models of) annotation schemes and several
existing terminology repositories, incl. GOLD, the
DCR, and OntoTag. When an annotation receives
a representation in the OLiA Reference Model,
it is thus also interpretable with respect to other
linguistic ontologies. Therefore, the findings for
the OLiA Reference Model in the experiments de-
scribed below entail similar results for an applica-
tion of GOLD or the DCR to the same task.
2.1 The OLiA ontologies
The Ontologies of Linguistic Annotations ?
briefly, OLiA ontologies (Chiarcos, 2008) ? re-
present an architecture of modular OWL/DL on-
tologies that formalize several intermediate steps
of the mapping between concrete annotations, a
Reference Model and existing terminology reposi-
tories (?External Reference Models? in OLiA ter-
minology) such as the DCR.2
The OLiA ontologies were originally develo-
ped as part of an infrastructure for the sustain-
able maintenance of linguistic resources (Schmidt
et al, 2006) where they were originally applied
1As one example, a GOLD Numeral is a De-
terminer (Numeral v Quantifier v Determiner,
http://linguistics-ontology.org/gold/2008/
Numeral), whereas a DCR Numeral is de-
fined on the basis of its semantic function,
without any references to syntactic categories
(http://www.isocat.org/datcat/DC-1334).
Thus, two in two of them is a DCR Numeral but not a GOLD
Numeral.
2The OLiA Reference Model is accessible via
http://nachhalt.sfb632.uni-potsdam.de/owl/
olia.owl. Several annotation models, e.g., stts.owl,
tiger.owl, connexor.owl, morphisto.owl can be
found in the same directory together with the corresponding
linking files stts-link.rdf, tiger-link.rdf,
connexor-link.rdf and morphisto-link.rdf.
to the formal representation and documentation of
annotation schemes, and for concept-based anno-
tation queries over to multiple, heterogeneous cor-
pora annotated with different annotation schemes
(Rehm et al, 2007; Chiarcos et al, 2008). NLP
applications of the OLiA ontologies include a pro-
posal to integrate them with the OntoTag ontolo-
gies and to use them for interface specifications
between modules in NLP pipeline architectures
(Buyko et al, 2008). Further, Hellmann (2010)
described the application of the OLiA ontologies
within NLP2RDF, an OWL-based blackboard ap-
proach to assess the meaning of text from gram-
matical analyses and subsequent enrichment with
ontological knowledge sources.
OLiA distinguishes three different classes of
ontologies:
? The OLIA REFERENCE MODEL specifies
the common terminology that different anno-
tation schemes can refer to. It is primarily
based on a blend of concepts of EAGLES and
GOLD, and further extended in accordance
with different annotation schemes, with the
TDS ontology and with the DCR (Chiarcos,
2010).
? Multiple OLIA ANNOTATION MODELs for-
malize annotation schemes and tag sets. An-
notation Models are based on the original
documentation and data samples, so that they
provide an authentic representation of the an-
notation not biased with respect to any partic-
ular interpretation.
? For every Annotation Model, a LINKING
MODEL defines subClassOf (v) relation-
ships between concepts/properties in the re-
spective Annotation Model and the Refe-
rence Model. Linking Models are interpre-
tations of Annotation Model concepts and
properties in terms of the Reference Model,
and thus multiple alternative Linking Models
for the same Annotation Model are possi-
ble. Other Linking Models specify v re-
lationships between Reference Model con-
cepts/properties and concepts/properties of
an External Reference Model such as GOLD
or the DCR.
The OLiA Reference Model (namespace olia)
specifies concepts that describe linguistic cate-
gories (e.g., olia:Determiner) and grammati-
cal features (e.g., olia:Accusative), as well
660
Figure 1: Attributive demonstrative pronouns
(PDAT) in the STTS Annotation Model
Figure 2: Selected morphosyntactic categories in the
OLiA Reference Model
Figure 3: Individuals for accusative and sin-
gular in the TIGER Annotation Model
Figure 4: Selected morphological features in the
OLiA Reference Model
as properties that define possible relations be-
tween those (e.g., olia:hasCase). More gen-
eral concepts that represent organizational in-
formation rather than possible annotations (e.g.,
MorphosyntacticCategory and CaseFeature)
are stored in a separate ontology (namespace
olia top).
The Reference Model is a shallow ontology: It
does not specify disjointness conditions of con-
cepts and cardinality or domain restrictions of
properties. Instead, it assumes that such con-
straints are inherited by means of v relationships
from an External Reference Model. Different Ex-
ternal Reference Models may take different posi-
tions on the issue ? as languages do3 ?, so that
this aspect is left underspecified in the Reference
Model.
3Based on primary experience with Western Euro-
pean languages, for example, one might assume that a
hasGender property applies to nouns, adjectives, pronouns
and determiners only. Yet, this is language-specific restric-
tion: Russian finite verbs, for example, show gender congru-
ency in past tense.
Figs. 2 and 4 show excerpts of category and fea-
ture hierarchies in the Reference Model.
With respect to morphosyntactic annotations
(parts of speech, pos) and morphological an-
notations (morph), five Annotation Models for
German are currently available: STTS (Schiller
et al, 1999, pos), TIGER (Brants and Hansen,
2002, morph), Morphisto (Zielinski and Simon,
2008, pos, morph), RFTagger (Schmid and Laws,
2008, pos, morph), Connexor (Tapanainen and
Ja?rvinen, 1997, pos, morph). Further Annotation
Models for pos and morph cover five different an-
notation schemes for English (Marcus et al, 1994;
Sampson, 1995; Mandel, 2006; Kim et al, 2003,
Connexor), two annotation schemes for Russian
(Meyer, 2003; Sharoff et al, 2008), an annotation
scheme designed for typological research and cur-
rently applied to approx. 30 different languages
(Dipper et al, 2007), an annotation scheme for
Old High German (Petrova et al, 2009), and an an-
notation scheme for Tibetan (Wagner and Zeisler,
2004).
661
Figure 5: The STTS tags PDAT and ART, their rep-
resentation in the Annotation Model and linking
with the Reference Model.
Annotation Models differ from the Reference
Model mostly in that they include not only con-
cepts and properties, but also individuals: An-
notation Model concepts reflect an abstract con-
ceptual categorization, whereas individuals re-
present concrete values used to annotate the
corresponding phenomenon. An individual is
applicable to all annotations that match the
string value specified by this individual?s hasTag,
hasTagContaining, hasTagStartingWith, or
hasTagEndingWith properties. Fig. 1 illus-
trates the structure of the STTS Annotation
Model (namespace stts) for the individual
stts:PDAT that represents the tag used for at-
tributive demonstrative pronouns (demonstrative
determiners). Fig. 3 illustrates the individuals
tiger:accusative and tiger:singular from
the hierarchy of morphological features in the
TIGER Annotation Model (namespace tiger).
Fig. 5 illustrates the linking between the STTS
Annotation Model and the OLiA Reference Model
for the individuals stts:PDAT and stts:ART.
2.2 Integrating different morphosyntactic
and morphological analyses
With the OLiA ontologies as described above, an-
notations from different annotation schemes can
now be interpreted in terms of the OLiA Reference
Model (or External Reference Models like GOLD
or the DCR).
As an example, consider the attributive demon-
strative pronoun diese in (1).
(1)
Diese
this
nicht
not
neue
new
Erkenntnis
insight
konnte
could
der
the
Markt
market
der
of.the
Mo?glichkeiten
possibilities
am
on.the
Sonnabend
Saturday
in
in
Treuenbrietzen
Treuenbrietzen
bestens
in.the.best.way
unterstreichen
underline
.
?The ?Market of Possibilities?, held this Saturday
in Treuenbrietzen, provided best evidence for this
well-known (lit. ?not new?) insight.? (PCC, #4794)
The phrase diese nicht neue Erkenntnis poses two
challenges. First, it has to be recognized that the
demonstrative pronoun is attributive, although it is
separated from adjective and noun by nicht ?not?.
Second, the phrase is in accusative case, although
the morphology is ambiguous between accusative
and nominative, and nominative case would be ex-
pected for a sentence-initial NP.
The Connexor analysis (Tapanainen and
Ja?rvinen, 1997) actually fails in both aspects (2).
(2) PRON Dem FEM SG NOM (Connexor)
The ontological analysis of this annotation begins
by identifying the set of individuals from the Con-
nexor Annotation Model that match it according
to their hasTag (etc.) properties. The RDF triplet
connexor:NOM connexor:hasTagContaining
?NOM?4 indicates that the tag is an application
of the individual connexor:NOM, an instance
of connexor:Case. Further, the annota-
tion matches connexor:PRON (an instance of
connexor:Pronoun), etc. The result is a set of
individuals that express different aspects of the
meaning of the annotation.
For these individuals, the Annotation Model
specifies superclasses (rdf:type) and other prop-
erties, i.e., connexor:NOM connexor:hasCase
connexor:NOM, etc. The linguistic unit repre-
sented by the actual token can now be character-
ized by these properties: Every property applica-
ble to a member in the individual set is assumed to
be applicable to the linguistic unit as well. In order
to save space, we use a notation closer to predicate
logic (with the token as implicit subject). In terms
of the Annotation Model, the token diese is thus
described by the following descriptions:
4RDF triplets are quoted in simplified form, with XML
namespaces replacing the actual URIs.
662
(3) rdf:type(connexor:Pronoun)
connexor:hasCase(connexor:NOM) ...
The Linking Model connexor-link.rdf
provides us with the information that (i)
connexor:Pronoun is a subclass of the Re-
ference Model concept olia:Pronoun, (ii)
connexor:NOM is an instance of the Reference
Model concept olia:Nominative, and (iii)
olia:hasCase is a subproperty of olia:hasCase.
Accordingly, the predicates that describe the to-
ken diese can be reformulated in terms of the Re-
ference Model. rdf:type(connexor:Pronoun)
entails rdf:type(olia:Pronoun), etc. Similarly,
we know that for some i:olia:Nominative it is
true that olia:hasCase(i), abbreviated here as
olia:hasCase(some olia:Nominative).
In this way, the grammatical information con-
veyed in the original Connexor annotation can
be represented in an annotation-independent and
tagset-neutral way as shown for the Connexor a-
nalysis in (4).
(4) rdf:type(olia:PronounOrDeterminer)
rdf:type(olia:Pronoun)
olia:hasNumber(some olia:Singular)
olia:hasGender(some olia:Feminine)
rdf:type(olia:DemonstrativePronoun)
olia:hasCase(some olia:Nominative)
Analogously, the corresponding RFTagger analy-
sis (Schmid and Laws, 2008) given in (5) can
be transformed into a description in terms of the
OLiA Reference Model such as in (6).
(5) PRO.Dem.Attr.-3.Acc.Sg.Fem (RFTagger)
(6) rdf:type(olia:PronounOrDeterminer)
olia:hasNumber(some olia:Singular)
olia:hasGender(some olia:Feminine)
olia:hasCase(some olia:Accusative)
rdf:type(olia:DemonstrativeDeterminer)
rdf:type(olia:Determiner)
For every description obtained from these (and
further) analyses, an integrated and consistent gen-
eralization can be established as described in the
following section.
3 Processing linguistic annotations
3.1 Evaluation setup
Fig. 6 sketches the architecture of the evalua-
tion environment set up for this study.5 The in-
put to the system is a set of documents with
5The code used for the evaluation setup is available under
http://multiparse.sourceforge.net.
Figure 6: Evaluation setup
TIGER/NEGRA-style morphosyntactic or mor-
phological annotation (Skut et al, 1998; Brants
and Hansen, 2002) whose annotations are used as
gold standard.
From the annotated document, the plain tok-
enized text is extracted and analyzed by one or
more of the following NLP tools:
(i) Morphisto, a morphological analyzer without
contextual disambiguation (Zielinski and Si-
mon, 2008),
(ii) two part of speech taggers: the TreeTag-
ger (Schmid, 1994) and the Stanford Tagger
(Toutanova et al, 2003),
(iii) the RFTagger that performs part of speech and
morphological analysis (Schmid and Laws,
2008),
(iv) two PCFG parsers: the StanfordParser (Klein
and Manning, 2003) and the BerkeleyParser
(Petrov and Klein, 2007), and
(v) the Connexor dependency parser (Tapanainen
and Ja?rvinen, 1997).
These tools annotate parts of speech, and those in
(i), (iii) and (v) also provide morphological fea-
tures. All components ran in parallel threads on
the same machine, with the exception of Mor-
phisto that was addressed as a web service. The set
of matching Annotation Model individuals for ev-
ery annotation and the respective set of Reference
Model descriptions are determined by means of
663
OLiA description ? Morphisto Connexor RF Tree Stanford Stanford Berkeley
Tagger Tagger Tagger Parser Parser
word class type(...)
PronounOrDeterminer 7 1(4/4)? 1 1 1 1 1 1
Determiner 5.5 0.5?? 0 1 1 1 1 1
DemonstrativeDeterminer 5.5 0.5?? 0 1 1 1 1 1
Pronoun 1.5 0.5?? 1 0 0 0 0 0
DemonstrativePronoun 1.5 0.5?? 1 0 0 0 0 0
morphology hasXY(...) n/a n/a n/a n/a
hasNumber(some Singular) 2.5 0.5 (2/4) 1 1 ? Morphisto produces four alternative candidate analyses
hasGender(some Feminine) 2.5 0.5 (2/4) 1 1 for this example, so every alternative analysis receives the
hasCase(some Accusative) 1.5 0.5 (2/4) 0 1 confidence score 0.25
hasCase(some Nominative) 1.5 0.5 (2/4) 1 0 ?? Morphisto does not distinguish attributive and substitutive
hasNumber(some Plural) 0.5 0.5 (2/4) 0 0 pronouns, it predicts type(Determiner unionsq Pronoun)
Table 1: Confidence scores for diese in ex. (1)
the Pellet reasoner (Sirin et al, 2007) as described
above.
A disambiguation routine (see below) then de-
termines the maximal consistent set of ontological
descriptions. Finally, the outcome of this process
is compared to the set of descriptions correspond-
ing to the original annotation in the corpus.
3.2 Disambiguation
Returning to examples (4) and (6) above, we
see that the resulting set of descriptions con-
veys properties that are obviously contradic-
ting, e.g., hasCase(some Nominative) besides
hasCase(some Accusative).
Our approach to disambiguation combines on-
tological consistency criteria with a confidence
ranking. As we simulate an uninformed approach,
the confidence ranking follows a majority vote.
For diese in (1), the consultation of all seven
tools results a confidence ranking as shown in Tab.
1: If a tool supports a description with its analy-
sis, the confidence score is increased by 1 (or by
1/n if the tool proposes n alternative annotations).
A maximal consistent set of descriptions is then
established as follows:
(i) Given a confidence-ranked list of available
descriptions S = (s1, ..., sn) and a result set
T = ?.
(ii) Let s1 be the first element of S =
(s1, ..., sn).
(iii) If s1 is consistent with every description t ?
T , then add s1 to T : T := T ? {s1}
(iv) Remove s1 from S and iterate in (ii) until S
is empty.
The consistency of ontological descriptions is de-
fined here as follows:6
? Two concepts A and B are consistent iff
A ? B or A v B or B v A
Otherwise, A and B are disjoint.
? Two descriptions pred1(A) and pred2(B)
are consistent iff
A and B are consistent or
pred1 is neither a subproperty
nor a superproperty of pred2
This heuristic formalizes an implicit disjoint-
ness assumption for all concepts in the on-
tology (all concepts are disjoint unless one
is a subconcept of the other). Further, it
imposes an implicit cardinality constraint on
properties (e.g., hasCase(some Accusative) and
hasCase(some Nominative) are inconsistent be-
cause Accusative and Nominative are sibling
concepts and thus disjoint).
For the example diese, the descriptions
type(Pronoun) and type(DemonstrativePro-
noun) are inconsistent with type(Determiner),
and hasNumber(some Plural) is inconsistent
with hasNumber(some Singular) (Figs. 2 and
4); these descriptions are thus ruled out. The
hasCase descriptions have identical confidence
scores, so that the first hasCase description that
the algorithm encounters is chosen for the set of
resulting descriptions, the other one is ruled out
because of their inconsistency.
6The OLiA Reference Model does not specify disjoint-
ness constraints, and neither do GOLD or the DCR as Exter-
nal Reference Models. The axioms of the OntoTag ontolo-
gies, however, are specific to Spanish and cannot be directly
applied to German.
664
PCC TIGER NEGRA
best-performing tool (StanfordTagger)
.960 .956 .990?
average (and std. deviation) for tool combinations
1 tool .868 (.109) .864 (.122) .870 (.113)
2 tools .928 (.018) .931 (.021) .943 (.028)
3 tools .947 (.014) .948 (.013) .956 (.018)
4 tools .956 (.006) .955 (.009) .963 (.013)
5 tools .959 (.006) .960 (.007) .964 (.009)
6 tools .963 (.003) .963 (.007) .965 (.007)
all tools .967 .960 .965
? The Stanford Tagger was trained on the NEGRA corpus.
Table 2: Recall for rdf:type descriptions for word classes
TIGER NEGRA
1 tool .678 (.106) .660 (.091)
Morphisto .573 .568
Connexor .674 .662
RFTagger .786 .751
2 tools .761 (.019) .740 (.012)
C+M .738 .730
M+R .769 .737
C+R .773 .753
all tools .791 .770
Table 3: Recall for morphological
hasXY() descriptions
The resulting, maximal consistent set of de-
scriptions is then compared with the ontological
descriptions that correspond to the original anno-
tation in the corpus.
4 Evaluation
Six experiments were conducted with the goal to
evaluate the prediction of word classes and mor-
phological features on parts of three corpora of
German newspaper articles: NEGRA (Skut et al,
1998), TIGER (Brants et al, 2002), and the Pots-
dam Commentary Corpus (Stede, 2004, PCC).
From every corpus 10,000 tokens were considered
for the analysis.
TIGER and NEGRA are well-known resources
that also influenced the design of several of the
tools considered. For this reason, the PCC was
consulted, a small collection of newspaper com-
mentaries, 30,000 tokens in total, annotated with
TIGER-style parts of speech and syntax (by mem-
bers of the TIGER project). None of the tools con-
sidered here were trained on this data, so that it
provides independent test data.
The ontological descriptions were evaluated for
recall:7
(7) recall(T ) =
?n
i=1 |Dpredicted(ti)?Dtarget(ti)|?n
i=1 |Dtarget(ti)|
In (7), T is a text (a list of tokens) with T =
(t1, ..., tn), Dpredicted(t) are descriptions retrieved
from the NLP analyses of the token t, and
Dtarget(t) is the set of descriptions that corres-
pond to the original annotation of t in the corpus.
7Precision and accuracy may not be appropriate measure-
ments in this case: Annotation schemes differ in their ex-
pressiveness, so that a description predicted by an NLP tool
but not found in the reference annotation may nevertheless
be correct. The RFTagger, for example, assigns demonstra-
tive pronouns the feature ?3rd person?, that is not found in
TIGER/NEGRA-style annotation because of its redundancy.
4.1 Word classes
Table 2 shows that the recall of rdf:type de-
scriptions (for word classes) increases continu-
ously with the number of NLP tools applied. The
combination of all seven tools actually shows a
better recall than the best-performing single NLP
tool. (The NEGRA corpus is an apparent excep-
tion only; the exceptionally high recall of the Stan-
ford Tagger reflects the fact that it was trained on
NEGRA.)
A particularly high increase in recall occurs
when tools are combined that compensate for their
respective deficits. Morphisto, for example, ge-
nerates alternative morphological analyses, so that
the disambiguation algorithm performs a random
choice between these. Morphisto has thus the
worst recall among all tools considered (PCC .69,
TIGER .65, NEGRA .70 for word classes). As
compared to this, Connexor performs a contextual
disambiguation; its recall is, however, limited by
its coarse-grained word classes (PCC .73, TIGER
.72, NEGRA .73). The combination of both tools
yields a more detailed and context-sensitive ana-
lysis and thus results in a boost in recall by more
than 13% (PCC .87, TIGER .86, NEGRA .86).
4.2 Morphological features
For morphological features, Tab. 3 shows the
same tendencies that were also observed for word
classes: The more tools are combined, the greater
the recall of the generated descriptions, and the re-
call of combined tools often outperforms the recall
of individual tools.
The three tools that provide morphological an-
notations (Morphisto, Connexor, RFTagger) were
evaluated against 10,000 tokens from TIGER and
NEGRA respectively. The best-performing tool
was the RFTagger, which possibly reflects the fact
665
that it was trained on TIGER-style annotations,
whereas Morphisto and Connexor were developed
on the basis of independent resources and thus dif-
fer from the reference annotation in their respec-
tive degree of granularity.
5 Summary and Discussion
With the ontology-based approach described in
this paper, the performance of annotation tools can
be evaluated on a conceptual basis rather than by
means of a string comparison with target annota-
tions. A formal model of linguistic concepts is ex-
tensible, finer-grained and, thus, potentially more
adequate for the integration of linguistic annota-
tions than string-based representations, especially
for heterogeneous annotations, if the tagsets in-
volved are structured according to different design
principles (e.g., due to different terminological tra-
ditions, different communities involved, etc.).
It has been shown that by abstracting from
tool-specific representations of linguistic anno-
tations, annotations from different tagsets can be
represented with reference to the OLiA ontologies
(and/or with other OWL/RDF-based terminology
repositories linked as External Reference Models).
In particular, it is possible to compare an existing
reference annotation with annotations produced by
NLP tools that use independently developed and
differently structured annotation schemes (such as
Connexor vs. RFTagger vs. Morphisto).
Further, an algorithm for the integration of dif-
ferent annotations has been proposed that makes
use of a majority-based confidence ranking and
ontological consistency conditions. As consis-
tency conditions are not formally defined in the
OLiA Reference Model (which is expected to in-
herit such constraints from External Reference
Models), a heuristic, structure-based definition of
consistency was applied.
This heuristic consistency definition is overly
rigid and rules out a number of consistent alter-
native analyses, as it is the case for overlapping
categories.8 Despite this rigidity, we witness an
increase of recall when multiple alternative analy-
ses are integrated. This increase of recall may re-
sult from a compensation of tool-specific deficits,
e.g., with respect to annotation granularity. Also,
the improved recall can be explained by a compen-
sation of overfitting, or deficits that are inherent to
8Preposition-determiner compounds like German am ?on
the?, for example, are both prepositions and determiners.
a particular approach (e.g., differences in the co-
verage of the linguistic context).
It can thus be stated that the integration of mul-
tiple alternative analyses has the potential to pro-
duce linguistic analyses that are both more robust
and more detailed than those of the original tools.
The primary field of application of this ap-
proach is most likely to be seen in a context where
applications are designed that make direct use of
OWL/RDF representations as described, for ex-
ample, by Hellmann (2010). It is, however, also
possible to use ontological representations to boot-
strap novel and more detailed annotation schemes,
cf. Zavrel and Daelemans (2000). Further, the
conversion from string-based representations to
ontological descriptions is reversible, so that re-
sults of ontology-based disambiguation and vali-
dation can also be reintegrated with the original
annotation scheme. The idea of such a reversion
algorithm was sketched by Buyko et al (2008)
where the OLiA ontologies were suggested as a
means to translate between different annotation
schemes.9
6 Extensions and Related Research
Natural extensions of the approach described in
this paper include:
(i) Experiments with formally defined consis-
tency conditions (e.g., with respect to restric-
tions on the domain of properties).
(ii) Context-sensitive disambiguation of mor-
phological features (e.g., by combination
with a chunker and adjustment of confidence
scores for morphological features over all to-
kens in the current chunk, cf. Kermes and
Evert, 2002).
(iii) Replacement of majority vote by more elab-
orate strategies to merge grammatical analy-
ses.
9The mapping from ontological descriptions to tags of a
particular scheme is possible, but neither trivial nor neces-
sarily lossless: Information of ontological descriptions that
cannot be expressed in the annotation scheme under consid-
eration (e.g., the distinction between attributive and substitu-
tive pronouns in the Morphisto scheme) will be missing in
the resulting string representation. For complex annotations,
where ontological descriptions correspond to different sub-
strings, an additional ?tag grammar? may be necessary to de-
termine the appropriate ordering of substrings according to
the annotation scheme (e.g., in the Connexor analysis).
666
(iv) Application of the algorithm for the ontolog-
ical processing of node labels and edge labels
in syntax annotations.
(v) Integration with other ontological knowledge
sources in order to improve the recall of
morphosyntactic and morphological analy-
ses (e.g., for disambiguating grammatical
case).
Extensions (iii) and (iv) are currently pursued in
an ongoing research effort described by Chiarcos
et al (2010). Like morphosyntactic and morpho-
logical features, node and edge labels of syntac-
tic trees are ontologically represented in several
Annotation Models, the OLiA Reference Model,
and External Reference Models, the merging al-
gorithm as described above can thus be applied
for syntax, as well. Syntactic annotations, how-
ever, involve the additional challenge to align dif-
ferent structures before node and edge labels can
be addressed, an issue not further discussed here
for reasons of space limitations.
Alternative strategies to merge grammatical a-
nalyses may include alternative voting strategies
as discussed in literature on classifier combina-
tion, e.g., weighted majority vote, pairwise voting
(Halteren et al, 1998), credibility profiles (Tufis?,
2000), or hand-crafted rules (Borin, 2000). A
novel feature of our approach as compared to exis-
ting applications of these methods is that confi-
dence scores are not attached to plain strings, but
to ontological descriptions: Tufis?, for example,
assigned confidence scores not to tools (as in a
weighted majority vote), but rather, assessed the
?credibility? of a tool with respect to the predicted
tag. If this approach is applied to ontological de-
scriptions in place of tags, it allows us to consider
the credibility of pieces of information regardless
of the actual string representation of tags. For ex-
ample, the credibility of hasCase descriptions can
be assessed independently from the credibility of
hasGender descriptions even if the original anno-
tation merged both aspects in one single tag (as the
RFTagger does, for example, cf. ex. 5).
Extension (v) has been addressed in previous re-
search, although mostly with the opposite perspec-
tive: Already Cimiano and Reyle (2003) noted that
the integration of grammatical and semantic ana-
lyses may be used to resolve ambiguity and un-
derspecifications, and this insight has also moti-
vated the ontological representation of linguistic
resources such as WordNet (Gangemi et al, 2003),
FrameNet (Scheffczyk et al, 2006), the linking of
corpora with such ontologies (Hovy et al, 2006),
the modelling of entire corpora in OWL/DL (Bur-
chardt et al, 2008), and the extension of existing
ontologies with ontological representations of se-
lected linguistic features (Buitelaar et al, 2006;
Davis et al, 2008).
Aguado de Cea et al (2004) sketched an ar-
chitecture for the closer ontology-based integra-
tion of grammatical and semantic information u-
sing OntoTag and several NLP tools for Spanish.
Aguado de Cea et al (2008) evaluate the benefits
of this approach for the Spanish particle se, and
conclude for this example that the combination of
multiple tools yields more detailed and more ac-
curate linguistic analyses of particularly proble-
matic, polysemous function words. A similar in-
crease in accuracy has also been repeatedly re-
ported for ensemble combination approaches, that
are, however, limited to tools that produce annota-
tions according to the same tagset (Brill and Wu,
1998; Halteren et al, 2001).
These observations provide further support for
our conclusion that the ontology-based integration
of morphosyntactic analyses enhances both the ro-
bustness and the level of detail of morphosyntac-
tic and morphological analyses. Our approach ex-
tends the philosophy of ensemble combination ap-
proaches to NLP tools that do not only employ dif-
ferent strategies and philosophies, but also differ-
ent annotation schemes.
Acknowledgements
From 2005 to 2008, the research on linguistic
ontologies described in this paper was funded
by the German Research Foundation (DFG) in
the context of the Collaborative Research Center
(SFB) 441 ?Linguistic Data Structures?, Project
C2 ?Sustainability of Linguistic Resources? (Uni-
versity of Tu?bingen), and since 2007 in the context
of the SFB 632 ?Information Structure?, Project
D1 ?Linguistic Database? (University of Pots-
dam). The author would also like to thank Ju-
lia Ritz, Angela Lahee, Olga Chiarcos and three
anonymous reviewers for helpful hints and com-
ments.
667
References
G. Aguado de Cea, A?. I. de Mon-Rego, A. Pareja-Lora,
and R. Plaza-Arteche. 2002. OntoTag: A semantic
web page linguistic annotation model. In Procee-
dings of the ECAI 2002 Workshop on Semantic Au-
thoring, Annotation and Knowledge Markup, Lyon,
France, July.
G. Aguado de Cea, A. Gomez-Perez, I. Alvarez de
Mon, and A. Pareja-Lora. 2004. OntoTag?s lin-
guistic ontologies: Improving semantic web anno-
tations for a better language understanding in ma-
chines. In Proceedings of the International Confe-
rence on Information Technology: Coding and Com-
puting (ITCC?04), Las Vegas, Nevada, USA, April.
G. Aguado de Cea, J. Puch, and J.A?. Ramos. 2008.
Tagging Spanish texts: The problem of ?se?. In Pro-
ceedings of the Sixth International Conference on
Language Resources and Evaluation (LREC 2008),
Marrakech, Morocco, May.
A. Aschenbrenner, P. Gietz, M.W. Ku?ster, C. Ludwig,
and H. Neuroth. 2006. TextGrid. A modular plat-
form for collaborative textual editing. In Procee-
dings of the International Workshop on Digital Lib-
rary Goes e-Science (DLSci06), pages 27?36, Ali-
cante, Spain, September.
D. Bakker, O. Dahl, M. Haspelmath, M. Koptjevskaja-
Tamm, C. Lehmann, and A. Siewierska. 1993.
EUROTYP guidelines. Technical report, European
Science Foundation Programme in Language Typol-
ogy.
B. Bickel and J. Nichols. 2000. The
goals and principles of AUTOTYP.
http://www.uni-leipzig.de/?autotyp/
theory.html. version of 01/12/2007.
B. Bickel and J. Nichols. 2002. Autotypologizing
databases and their use in fieldwork. In Proceedings
of the LREC 2002 Workshop on Resources and Tools
in Field Linguistics, Las Palmas, Spain, May.
L. Borin. 2000. Something borrowed, something
blue: Rule-based combination of POS taggers. In
Proceedings of the 2nd International Conference on
Language Resources and Evaluation (LREC 2000),
Athens, Greece, May, 31st ? June, 2nd.
S. Brants and S. Hansen. 2002. Developments in the
TIGER annotation scheme and their realization in
the corpus. In Proceedings of the Third Interna-
tional Conference on Language Resources and Eva-
luation (LREC 2002), pages 1643?1649, Las Pal-
mas, Spain, May.
S. Brants, S. Dipper, S. Hansen, W. Lezius, and
G. Smith. 2002. The TIGER treebank. In Procee-
dings of the Workshop on Treebanks and Linguistic
Theories, pages 24?41, Sozopol, Bulgaria, Septem-
ber.
E. Brill and J. Wu. 1998. Classifier combination
for improved lexical disambiguation. In Procee-
dings of the 36th Annual Meeting of the Association
for Computational Linguistics and the 17th Inter-
national Conference on Computational Linguistics
(COLING-ACL 1998), pages 191?195, Montre?al,
Canada, August.
P. Buitelaar, T. Declerck, A. Frank, S. Racioppa,
M. Kiesel, M. Sintek, R. Engel, M. Romanelli,
D. Sonntag, B. Loos, V. Micelli, R. Porzel, and
P. Cimiano. 2006. LingInfo: Design and applica-
tions of a model for the integration of linguistic in-
formation in ontologies. In Proceedings of the 5th
International Conference on Language Resources
and Evaluation (LREC 2006), Genoa, Italy, May.
A. Burchardt, S. Pado?, D. Spohr, A. Frank, and
U. Heid. 2008. Formalising Multi-layer Corpora in
OWL/DL ? Lexicon Modelling, Querying and Con-
sistency Control. In Proceedings of the 3rd Inter-
national Joint Conference on NLP (IJCNLP 2008),
Hyderabad, India, January.
E. Buyko, C. Chiarcos, and A. Pareja-Lora. 2008.
Ontology-based interface specifications for a NLP
pipeline architecture. In Proceedings of the Interna-
tional Conference on Language Resources and Eva-
luation (LREC 2008), Marrakech, Morocco, May.
M. Carl, C. Pease, L.L. Iomdin, and O. Streiter. 2000.
Towards a dynamic linkage of example-based and
rule-based machine translation. Machine Transla-
tion, 15(3):223?257.
C. Chiarcos, S. Dipper, M. Go?tze, U. Leser,
A. Lu?deling, J. Ritz, and M. Stede. 2008. A Flexible
Framework for Integrating Annotations from Differ-
ent Tools and Tag Sets. Traitement Automatique des
Langues, 49(2).
C. Chiarcos, K. Eckart, and J. Ritz. 2010. Creating and
exploiting a resource of parallel parses. In 4th Lin-
guistic Annotation Workshop (LAW 2010), held in
conjunction with ACL-2010, Uppsala, Sweden, July.
C. Chiarcos. 2008. An ontology of linguistic annota-
tions. LDV Forum, 23(1):1?16. Foundations of On-
tologies in Text Technology, Part II: Applications.
C. Chiarcos. 2010. Grounding an ontology of lin-
guistic annotations in the Data Category Registry.
In Workshop on Language Resource and Language
Technology Standards (LR&LTS 2010), held in con-
junction with LREC 2010, Valetta, Malta, May.
P. Cimiano and U. Reyle. 2003. Ontology-based se-
mantic construction, underspecification and disam-
biguation. In Proceedings of the Lorraine/Saarland
Workshop on Prospects and Recent Advances in the
Syntax-Semantics Interface, pages 33?38, Nancy,
France, October.
B. Crysmann, A. Frank, B. Kiefer, S. Mu?ller, G. Neu-
mann, J. Piskorski, U. Scha?fer, M. Siegel, H. Uszko-
reit, F. Xu, M. Becker, and H. Krieger. 2002. An
668
integrated architecture for shallow and deep proces-
sing. In Proceedings of 40th Annual Meeting of the
Association for Computational Linguistics, pages
441?448, Philadelphia, Pennsylvania, USA, July.
B. Davis, S. Handschuh, A. Troussov, J. Judge, and
M. Sogrin. 2008. Linguistically light lexical ex-
tensions for ontologies. In Proceedings of the Sixth
International Conference on Language Resources
and Evaluation (LREC 2008), Marrakech, Morocco,
May.
S. Dipper, M. Go?tze, and S. Skopeteas, editors. 2007.
Information Structure in Cross-Linguistic Corpora:
Annotation Guidelines for Phonology, Morpholo-
gy, Syntax, Semantics, and Information Structure.
Interdisciplinary Studies on Information Structure
(ISIS), Working Papers of the SFB 632; 7. Univer-
sita?tsverlag Potsdam, Potsdam, Germany.
M.T. Egner, M. Lorch, and E. Biddle. 2007. UIMA
Grid: Distributed large-scale text analysis. In Pro-
ceedings of the Seventh IEEE International Sym-
posium on Cluster Computing and the Grid (CC-
GRID?07), pages 317?326, Rio de Janeiro, Brazil,
May.
S. Farrar and D.T. Langendoen. 2003. Markup and
the GOLD ontology. In EMELD Workshop on Di-
gitizing and Annotating Text and Field Recordings.
Michigan State University, July.
A. Gangemi, R. Navigli, and P. Velardi. 2003. The On-
toWordNet project: Extension and axiomatization of
conceptual relations in WordNet. In R. Meersman
and Z. Tari, editors, Proceedings of On the Move
to Meaningful Internet Systems (OTM2003), pages
820?838, Catania, Italy, November.
P. Gietz, A. Aschenbrenner, S. Budenbender, F. Jan-
nidis, M.W. Ku?ster, C. Ludwig, W. Pempe, T. Vitt,
W. Wegstein, and A. Zielinski. 2006. TextGrid
and eHumanities. In Proceedings of the Second
IEEE International Conference on e-Science and
Grid Computing (E-SCIENCE ?06), pages 133?141,
Amsterdam, The Netherlands, December.
H. van Halteren, J. Zavrel, and W. Daelmans. 1998.
Improving data driven wordclass tagging by system
combination. In Proceedings of the 36th Annual
Meeting of the Association for Computational Lin-
guistics and the 17th International Conference on
Computational Linguistics (COLING-ACL 1998),
Montre?al, Canada, August.
H. van Halteren, J. Zavrel, and W. Daelmans. 2001.
Improving accuracy in word class tagging through
the combination of machine learning systems. Com-
putational Linguistics, 27(2):199?229.
S. Hellmann. 2010. The semantic gap of formalized
meaning. In The 7th Extended Semantic Web Confe-
rence (ESWC 2010), Heraklion, Greece, May 30th ?
June 3rd.
E. Hovy, M. Marcus, M. Palmer, L. Ramshaw, and
R. Weischedel. 2006. Ontonotes: the 90% solu-
tion. In Conference of the North American Chapter
of the Association for Computational Linguistics on
Human Language Technology (HLT-NAACL 2006),
pages 57?60, New York, June.
N. Ide and L. Romary. 2004. A registry of standard
data categories for linguistic annotation. In Procee-
dings of the Fourth Language Resources and Evalu-
ation Conference (LREC 2004), pages 135?39, Lis-
boa, Portugal, May.
M. Kemps-Snijders, M. Windhouwer, P. Wittenburg,
and S.E. Wright. 2009. ISOcat: remodelling meta-
data for language resources. International Journal
of Metadata, Semantics and Ontologies, 4(4):261?
276.
H. Kermes and S. Evert. 2002. YAC ? A recur-
sive chunker for unrestricted German text. In Pro-
ceedings of the Third International Conference on
Language Resources and Evaluation (LREC 2002),
pages 1805?1812, Las Palmas, Spain, May.
J.D. Kim, T. Ohta, Y. Tateisi, and J. Tsujii. 2003. GE-
NIA corpus ? A semantically annotated corpus for
bio-textmining. Bioinformatics, 19(1):180?182.
D. Klein and C.D. Manning. 2003. Accurate unlexi-
calized parsing. In Proceedings of the 41st Annual
Meeting of the Association for Computational Lin-
guistics, pages 423?430, Sapporo, Japan, July.
G. Leech and A. Wilson. 1996. EAGLES recommen-
dations for the morphosyntactic annotation of cor-
pora. Version of March 1996.
T. Lu??s and D.M. de Matos. 2009. High-performance
high-volume layered corpora annotation. In Procee-
dings of the Third Linguistic Annotation Workshop
(LAW-III) held in conjunction with ACL-IJCNLP
2009, pages 99?107, Singapore, August.
M. Mandel. 2006. Integrated annotation of biomedical
text: Creating the PennBioIE corpus. In Text Min-
ing Ontologies and Natural Language Processing in
Biomedicine, Manchester, UK, March.
M.P. Marcus, B. Santorini, and M.A. Marcinkiewicz.
1994. Building a large annotated corpus of En-
glish: The Penn Treebank. Computational linguis-
tics, 19(2):313?330.
R. Meyer. 2003. Halbautomatische morphosyntak-
tische Annotation russischer Texte. In R. Ham-
mel and L. Geist, editors, Linguistische Beitra?ge
zur Slavistik aus Deutschland und O?sterreich. X.
JungslavistInnen-Treffen, Berlin 2001, pages 92?
105. Sagner, Mu?nchen.
S. Petrov and D. Klein. 2007. Improved inference for
unlexicalized parsing. In Proceedings of the Confe-
rence of the North American Chapter of the Associ-
ation for Computational Linguistics on Human Lan-
guage Technology (HLT-NAACL 2007), pages 404?
411, Rochester, NY, April.
669
S. Petrova, C. Chiarcos, J. Ritz, M. Solf, and A. Zeldes.
2009. Building and using a richly annotated inter-
linear diachronic corpus: The case of Old High Ger-
man Tatian. Traitement automatique des langues et
langues anciennes, 50(2):47?71.
G. Rehm, R. Eckart, and C. Chiarcos. 2007. An OWL-
and XQuery-based mechanism for the retrieval of
linguistic patterns from XML-corpora. In Procee-
dings of Recent Advances in Natural Language Pro-
cessing (RANLP 2007), Borovets, Bulgaria, Septem-
ber.
G. Sampson. 1995. English for the computer: The SU-
SANNE corpus and analytic scheme. Oxford Uni-
versity Press.
A. Saulwick, M. Windhouwer, A. Dimitriadis, and
R. Goedemans. 2005. Distributed tasking in on-
tology mediated integration of typological databases
for linguistic research. In Proceedings of the 17th
Conference on Advanced Information Systems Engi-
neering (CAiSE?05), Porto, Portugal, June.
J. Scheffczyk, A. Pease, and M. Ellsworth. 2006.
Linking FrameNet to the suggested upper merged
ontology. In Proceedings of the Fourth Interna-
tional Conference on Formal Ontology in Informa-
tion Systems (FOIS 2006), pages 289?300, Balti-
more, Maryland, USA, November.
A. Schiller, S. Teufel, C. Thielen, and C. Sto?ckert.
1999. Guidelines fu?r das Tagging deutscher
Textcorpora mit STTS. Technical report, University
of Stuttgart, University of Tu?bingen.
H. Schmid and F. Laws. 2008. Estimation of condi-
tional probabilities with decision trees and an ap-
plication to fine-grained pos tagging. In Procee-
dings of the 22nd International Conference on Com-
putational Linguistics (COLING 2008), Manchester,
UK, August.
H. Schmid. 1994. Probabilistic part-of-speech tagging
using decision trees. In Proceedings of International
Conference on New Methods in Language Process-
ing, pages 44?49, Manchester, UK, September.
T. Schmidt, C. Chiarcos, T. Lehmberg, G. Rehm,
A. Witt, and E. Hinrichs. 2006. Avoiding data
graveyards: From heterogeneous data collected in
multiple research projects to sustainable linguistic
resources. In Proceedings of the E-MELD work-
shop on Digital Language Documentation: Tools
and Standards: The State of the Art, East Lansing,
Michigan, US, June.
S. Sharoff, M. Kopotev, T. Erjavec, A. Feldman, and
D. Divjak. 2008. Designing and evaluating Rus-
sian tagsets. In Proceedings of the 6th International
Conference on Language Resources and Evaluation
(LREC 2008), Marrakech, Morocco, May.
E. Sirin, B. Parsia, B.C. Grau, A. Kalyanpur, and
Y. Katz. 2007. Pellet: A practical OWL/DL rea-
soner. Web Semantics: Science, Services and Agents
on the World Wide Web, 5(2):51?53.
W. Skut, T. Brants, B. Krenn, and H. Uszkoreit. 1998.
A linguistically interpreted corpus of German news-
paper text. In In Proceedings of the ESSLLI Work-
shop on Recent Advances in Corpus Annotation,
Saarbru?cken, Germany, August.
M. Stede. 2004. The Potsdam Commentary Corpus.
In Proceedings of the 2004 ACL Workshop on Dis-
course Annotation, pages 96?102, Barcelona, Spain,
July.
P. Tapanainen and T. Ja?rvinen. 1997. A nonprojec-
tive dependency parser. In Proceedings of the 5th
Conference on Applied Natural Language Process-
ing, pages 64?71, Washington, DC, April.
K. Toutanova, D. Klein, C.D. Manning, and Y. Singer.
2003. Feature-rich part-of-speech tagging with a
cyclic dependency network. In Proceedings of the
2003 Conference of the North American Chapter
of the Association for Computational Linguistics on
Human Language Technology (HLT-NAACL 2003),
Edmonton, Canada, May.
D. Tufis?. 2000. Using a large set of EAGLES-
compliant morpho-syntactic descriptors as a tagset
for probabilistic tagging. In Proceedings of the 2nd
International Conference on Language Resources
and Evaluation (LREC 2000), pages 1105?1112,
Athens, Greece, May, 31st ? June, 2nd.
A. Wagner and B. Zeisler. 2004. A syntactically an-
notated corpus of Tibetan. In Fourth International
Conference on Language Resources and Evaluation
(LREC 2004), Lisboa, Portugal, May.
J. Zavrel and W. Daelemans. 2000. Bootstrapping a
tagged corpus through combination of existing het-
erogeneous taggers. In Proceedings of the 2nd In-
ternational Conference on Language Resources and
Evaluation (LREC 2000), Athens, Greece, May, 31st
? June, 2nd.
A. Zielinski and C. Simon. 2008. Morphisto: An
open-source morphological analyzer for German. In
Proceedings of the Conference on Finite State Meth-
ods in Natural Language Processing (FSMNLP), Is-
pra, Italy, September.
670
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 213?217,
Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational Linguistics
Towards the Unsupervised Acquisition of Discourse Relations
Christian Chiarcos
Information Sciences Institute
University of Southern California
4676 Admiralty Way, Marina del Rey, CA 90292
chiarcos@daad-alumni.de
Abstract
This paper describes a novel approach towards
the empirical approximation of discourse re-
lations between different utterances in texts.
Following the idea that every pair of events
comes with preferences regarding the range
and frequency of discourse relations connect-
ing both parts, the paper investigates whether
these preferences are manifested in the distri-
bution of relation words (that serve to signal
these relations).
Experiments on two large-scale English web
corpora show that significant correlations be-
tween pairs of adjacent events and relation
words exist, that they are reproducible on dif-
ferent data sets, and for three relation words,
that their distribution corresponds to theory-
based assumptions.
1 Motivation
Texts are not merely accumulations of isolated ut-
terances, but the arrangement of utterances conveys
meaning; human text understanding can thus be de-
scribed as a process to recover the global structure
of texts and the relations linking its different parts
(Vallduv?? 1992; Gernsbacher et al 2004). To capture
these aspects of meaning in NLP, it is necessary to
develop operationalizable theories, and, within a su-
pervised approach, large amounts of annotated train-
ing data. To facilitate manual annotation, weakly
supervised or unsupervised techniques can be ap-
plied as preprocessing step for semimanual anno-
tation, and this is part of the motivation of the ap-
proach described here.
Discourse relations involve different aspects of
meaning. This may include factual knowledge
about the connected discourse segments (a ?subject-
matter? relation, e.g., if one utterance represents
the cause for another, Mann and Thompson 1988,
p.257), argumentative purposes (a ?presentational?
relation, e.g., one utterance motivates the reader to
accept a claim formulated in another utterance, ibid.,
p.257), or relations between entities mentioned in
the connected discourse segments (anaphoric rela-
tions, Webber et al 2003). Discourse relations can
be indicated explicitly by optional cues, e.g., ad-
verbials (e.g., however), conjunctions (e.g., but), or
complex phrases (e.g., in contrast to what Peter said
a minute ago). Here, these cues are referred to as
relation words.
Assuming that relation words are associated with
specific discourse relations (Knott and Dale 1994;
Prasad et al 2008), the distribution of relation words
found between two (types of) events can yield in-
sights into the range of discourse relations possi-
ble at this occasion and their respective likeliness.
For this purpose, this paper proposes a background
knowledge base (BKB) that hosts pairs of events
(here heuristically represented by verbs) along with
distributional profiles for relation words. The pri-
mary data structure of the BKB is a triple where
one event (type) is connected with a particular re-
lation word to another event (type). Triples are fur-
ther augmented with a frequency score (expressing
the likelihood of the triple to be observed), a sig-
nificance score (see below), and a correlation score
(indicating whether a pair of events has a positive or
negative correlation with a particular relation word).
213
Triples can be easily acquired from automatically
parsed corpora. While the relation word is usually
part of the utterance that represents the source of
the relation, determining the appropriate target (an-
tecedent) of the relation may be difficult to achieve.
As a heuristic, an adjacency preference is adopted,
i.e., the target is identified with the main event of the
preceding utterance.1 The BKB can be constructed
from a sufficiently large corpus as follows:
? identify event types and relation words
? for every utterance
? create a candidate triple consisting of the
event type of the utterance, the relation
word, and the event type of the preceding
utterance.
? add the candidate triple to the BKB, if it
found in the BKB, increase its score by (or
initialize it with) 1,
? perform a pruning on all candidate triples, cal-
culate significance and correlation scores
Pruning uses statistical significance tests to evalu-
ate whether the relative frequency of a relation word
for a pair of events is significantly higher or lower
than the relative frequency of the relation word in
the entire corpus. Assuming that incorrect candi-
date triples (i.e., where the factual target of the rela-
tion was non-adjacent) are equally distributed, they
should be filtered out by the significance tests.
The goal of this paper is to evaluate the validity of
this approach.
2 Experimental Setup
By generalizing over multiple occurrences of the
same events (or, more precisely, event types), one
can identify preferences of event pairs for one or
several relation words. These preferences capture
context-invariant characteristics of pairs of events
and are thus to considered to reflect a semantic pre-
disposition for a particular discourse relation.
Formally, an event is the semantic representa-
tion of the meaning conveyed in the utterance. We
1Relations between non-adjacent utterances are constrained
by the structure of discourse (Webber 1991), and thus less likely
than relations between adjacent utterances.
assume that the same event can reoccur in differ-
ent contexts, we are thus studying relations be-
tween types of events. For the experiment described
here, events are heuristically identified with the main
predicates of a sentence, i.e., non-auxiliar, non-
causative, non-modal verbal lexemes that serve as
heads of main clauses.
The primary data structure of the approach de-
scribed here is a triple consisting of a source event, a
relation word and a target (antecedent) event. These
triples are harvested from large syntactically anno-
tated corpora. For intersentential relations, the tar-
get is identified with the event of the immediately
preceding main clause. These extraction preferences
are heuristic approximations, and thus, an additional
pruning step is necessary.
For this purpose, statistical significance tests are
adopted (?2 for triples of frequent events and re-
lation words, t-test for rare events and/or relation
words) that compare the relative frequency of a rela-
tion word given a pair of events with the relative fre-
quency of the relation word in the entire corpus. All
results with p ? .05 are excluded, i.e., only triples
are preserved for which the observed positive or neg-
ative correlation between a pair of events and a re-
lation word is not due to chance with at least 95%
probability. Assuming an even distribution of incor-
rect target events, this should rule these out. Ad-
ditionally, it also serves as a means of evaluation.
Using statistical significance tests as pruning crite-
rion entails that all triples eventually confirmed are
statistically significant.2
This setup requires immense amounts of data: We
are dealing with several thousand events (theoreti-
cally, the total number of verbs of a language). The
chance probability for two events to occur in adja-
cent position is thus far below 10?6, and it decreases
further if the likelihood of a relation word is taken
into consideration. All things being equal, we thus
need millions of sentences to create the BKB.
Here, two large-scale corpora of English are em-
ployed, PukWaC and Wackypedia EN (Baroni et al
2009). PukWaC is a 2G-token web corpus of British
English crawled from the uk domain (Ferraresi et al
2Subsequent studies may employ less rigid pruning criteria.
For the purpose of the current paper, however, the statistical sig-
nificance of all extracted triples serves as an criterion to evaluate
methodological validity.
214
2008), and parsed with MaltParser (Nivre et al
2006). It is distributed in 5 parts; Only PukWaC-
1 to PukWaC-4 were considered here, constitut-
ing 82.2% (72.5M sentences) of the entire corpus,
PukWaC-5 is left untouched for forthcoming evalu-
ation experiments. Wackypedia EN is a 0.8G-token
dump of the English Wikipedia, annotated with the
same tools. It is distributed in 4 different files; the
last portion was left untouched for forthcoming eval-
uation experiments. The portion analyzed here com-
prises 33.2M sentences, 75.9% of the corpus.
The extraction of events in these corpora uses
simple patterns that combine dependency informa-
tion and part-of-speech tags to retrieve the main
verbs and store their lemmata as event types. The
target (antecedent) event was identified with the last
main event of the preceding sentence. As relation
words, only sentence-initial children of the source
event that were annotated as adverbial modifiers,
verb modifiers or conjunctions were considered.
3 Evaluation
To evaluate the validity of the approach, three funda-
mental questions need to be addressed: significance
(are there significant correlations between pairs of
events and relation words ?), reproducibility (can
these correlations confirmed on independent data
sets ?), and interpretability (can these correlations
be interpreted in terms of theoretically-defined dis-
course relations ?).
3.1 Significance and Reproducibility
Significance tests are part of the pruning stage of the
algorithm. Therefore, the number of triples eventu-
ally retrieved confirms the existence of statistically
significant correlations between pairs of events and
relation words. The left column of Tab. 1 shows
the number of triples obtained from PukWaC sub-
corpora of different size.
For reproducibility, compare the triples identified
with Wackypedia EN and PukWaC subcorpora of
different size: Table 1 shows the number of triples
found in both Wackypedia EN and PukWaC, and the
agreement between both resources. For two triples
involving the same events (event types) and the same
relation word, agreement means that the relation
word shows either positive or negative correlation
PukWaC (sub)corpus Wackypedia EN triples
sentences triples common agreeing %
1.2M 74 20 12 60.0
4.8M 832 177 132 75.5
19.2M 7,342 938 809 86.3
38.4M 20,106 1,783 1,596 89.9
72.5M 46,680 2,643 2,393 90.5
Table 1: Agreement with respect to positive or nega-
tive correlation of event pairs and relation words be-
tween Wackypedia EN and PukWaC subcorpora of dif-
ferent size
PukWaC triples agreement (%)
total vs. H vs. T vs. H vs. T
B: but 11,042 6,805 1,525 97.7 62.2
H: however 7,251 1,413 66.9
T: then 1,791
Table 2: Agreement between but (B), however (H) and
then (T) on PukWaC
in both corpora, disagreement means positive corre-
lation in one corpus and negative correlation in the
other.
Table 1 confirms that results obtained on one re-
source can be reproduced on another. This indi-
cates that triples indeed capture context-invariant,
and hence, semantic, characteristics of the relation
between events. The data also indicates that repro-
ducibility increases with the size of corpora from
which a BKB is built.
3.2 Interpretability
Any theory of discourse relations would predict that
relation words with similar function should have
similar distributions, whereas one would expect dif-
ferent distributions for functionally unrelated rela-
tion words. These expectations are tested here for
three of the most frequent relation words found in
the corpora, i.e., but, then and however. But and
however can be grouped together under a general-
ized notion of contrast (Knott and Dale 1994; Prasad
et al 2008); then, on the other hand, indicates a tem-
poral and/or causal relation.
Table 2 confirms the expectation that event pairs
that are correlated with but tend to show the same
correlation with however, but not with then.
215
4 Discussion and Outlook
This paper described a novel approach towards the
unsupervised acquisition of discourse relations, with
encouraging preliminary results: Large collections
of parsed text are used to assess distributional pro-
files of relation words that indicate discourse re-
lations that are possible between specific types of
events; on this basis, a background knowledge base
(BKB) was created that can be used to predict an ap-
propriate discourse marker to connect two utterances
with no overt relation word.
This information can be used, for example, to fa-
cilitate the semiautomated annotation of discourse
relations, by pointing out the ?default? relation word
for a given pair of events. Similarly, Zhou et al
(2010) used a language model to predict discourse
markers for implicitly realized discourse relations.
As opposed to this shallow, n-gram-based approach,
here, the internal structure of utterances is exploited:
based on semantic considerations, syntactic patterns
have been devised that extract triples of event pairs
and relation words. The resulting BKB provides a
distributional approximation of the discourse rela-
tions that can hold between two specific event types.
Both approaches exploit complementary sources of
knowledge, and may be combined with each other
to achieve a more precise prediction of implicit dis-
course connectives.
The validity of the approach was evaluated with
respect to three evaluation criteria: The extracted as-
sociations between relation words and event pairs
could be shown to be statistically significant, and
to be reproducible on other corpora; for three
highly frequent relation words, theoretical predic-
tions about their relative distribution could be con-
firmed, indicating their interpretability in terms of
presupposed taxonomies of discourse relations.
Another prospective field of application can be
seen in NLP applications, where selection prefer-
ences for relation words may serve as a cheap re-
placement for full-fledged discourse parsing. In the
Natural Language Understanding domain, the BKB
may help to disambiguate or to identify discourse
relations between different events; in the context of
Machine Translation, it may represent a factor guid-
ing the insertion of relation words, a task that has
been found to be problematic for languages that dif-
fer in their inventory and usage of discourse mark-
ers, e.g., German and English (Stede and Schmitz
2000). The approach is language-independent (ex-
cept for the syntactic extraction patterns), and it does
not require manually annotated data. It would thus
be easy to create background knowledge bases with
relation words for other languages or specific do-
mains ? given a sufficient amount of textual data.
Related research includes, for example, the un-
supervised recognition of causal and temporal rela-
tionships, as required, for example, for the recog-
nition of textual entailment. Riaz and Girju (2010)
exploit distributional information about pairs of ut-
terances. Unlike approach described here, they are
not restricted to adjacent utterances, and do not rely
on explicit and recurrent relation words. Their ap-
proach can thus be applied to comparably small
data sets. However, they are restricted to a spe-
cific type of relations whereas here the entire band-
width of discourse relations that are explicitly real-
ized in a language are covered. Prospectively, both
approaches could be combined to compensate their
respective weaknesses.
Similar observations can be made with respect to
Chambers and Jurafsky (2009) and Kasch and Oates
(2010), who also study a single discourse relation
(narration), and are thus more limited in scope than
the approach described here. However, as their ap-
proach extends beyond pairs of events to complex
event chains, it seems that both approaches provide
complementary types of information and their re-
sults could also be combined in a fruitful way to
achieve a more detailed assessment of discourse re-
lations.
The goal of this paper was to evaluate the meth-
dological validity of the approach. It thus represents
the basis for further experiments, e.g., with respect
to the enrichment the BKB with information pro-
vided by Riaz and Girju (2010), Chambers and Ju-
rafsky (2009) and Kasch and Oates (2010). Other di-
rections of subsequent research may include address
more elaborate models of events, and the investiga-
tion of the relationship between relation words and
taxonomies of discourse relations.
216
Acknowledgments
This work was supported by a fellowship within
the Postdoc program of the German Academic Ex-
change Service (DAAD). Initial experiments were
conducted at the Collaborative Research Center
(SFB) 632 ?Information Structure? at the Univer-
sity of Potsdam, Germany. I would also like to
thank three anonymous reviewers for valuable com-
ments and feedback, as well as Manfred Stede and
Ed Hovy whose work on discourse relations on the
one hand and proposition stores on the other hand
have been the main inspiration for this paper.
References
M. Baroni, S. Bernardini, A. Ferraresi, and
E. Zanchetta. The wacky wide web: a collec-
tion of very large linguistically processed web-
crawled corpora. Language Resources and Eval-
uation, 43(3):209?226, 2009.
N. Chambers and D. Jurafsky. Unsupervised learn-
ing of narrative schemas and their participants. In
Proceedings of the Joint Conference of the 47th
Annual Meeting of the ACL and the 4th Inter-
national Joint Conference on Natural Language
Processing of the AFNLP: Volume 2-Volume 2,
pages 602?610. Association for Computational
Linguistics, 2009.
A. Ferraresi, E. Zanchetta, M. Baroni, and S. Bernar-
dini. Introducing and evaluating ukwac, a very
large web-derived corpus of english. In Proceed-
ings of the 4th Web as Corpus Workshop (WAC-4)
Can we beat Google, pages 47?54, 2008.
Morton Ann Gernsbacher, Rachel R. W. Robertson,
Paola Palladino, and Necia K. Werner. Manag-
ing mental representations during narrative com-
prehension. Discourse Processes, 37(2):145?164,
2004.
N. Kasch and T. Oates. Mining script-like struc-
tures from the web. In Proceedings of the NAACL
HLT 2010 First International Workshop on For-
malisms and Methodology for Learning by Read-
ing, pages 34?42. Association for Computational
Linguistics, 2010.
A. Knott and R. Dale. Using linguistic phenomena
to motivate a set of coherence relations. Discourse
processes, 18(1):35?62, 1994.
J. van Kuppevelt and R. Smith, editors. Current Di-
rections in Discourse and Dialogue. Kluwer, Dor-
drecht, 2003.
William C. Mann and Sandra A. Thompson. Rhetor-
ical Structure Theory: Toward a functional theory
of text organization. Text, 8(3):243?281, 1988.
J. Nivre, J. Hall, and J. Nilsson. Maltparser: A
data-driven parser-generator for dependency pars-
ing. In Proc. of LREC, pages 2216?2219. Cite-
seer, 2006.
R. Prasad, N. Dinesh, A. Lee, E. Miltsakaki,
L. Robaldo, A. Joshi, and B. Webber. The penn
discourse treebank 2.0. In Proc. 6th International
Conference on Language Resources and Evalua-
tion (LREC 2008), Marrakech, Morocco, 2008.
M. Riaz and R. Girju. Another look at causality:
Discovering scenario-specific contingency rela-
tionships with no supervision. In Semantic Com-
puting (ICSC), 2010 IEEE Fourth International
Conference on, pages 361?368. IEEE, 2010.
M. Stede and B. Schmitz. Discourse particles and
discourse functions. Machine translation, 15(1):
125?147, 2000.
Enric Vallduv??. The Informational Component. Gar-
land, New York, 1992.
Bonnie L. Webber. Structure and ostension in the
interpretation of discourse deixis. Natural Lan-
guage and Cognitive Processes, 2(6):107?135,
1991.
Bonnie L. Webber, Matthew Stone, Aravind K.
Joshi, and Alistair Knott. Anaphora and discourse
structure. Computational Linguistics, 4(29):545?
587, 2003.
Z.-M. Zhou, Y. Xu, Z.-Y. Niu, M. Lan, J. Su, and
C.L. Tan. Predicting discourse connectives for
implicit discourse relation recognition. In COL-
ING 2010, pages 1507?1514, Beijing, China, Au-
gust 2010.
217
Proceedings of the Fourth Linguistic Annotation Workshop, ACL 2010, pages 166?171,
Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational Linguistics
Creating and Exploiting a Resource of Parallel Parses
Christian Chiarcos? and Kerstin Eckart?? and Julia Ritz?
? Collaborative Research Centre 632 ?? Collaborative Research Centre 732
?Information Structure? ?Incremental Specification in Context?
Universita?t Potsdam Universita?t Stuttgart
{chiarcos|jritz}@uni-potsdam.de eckartkn@ims.uni-stuttgart.de
Abstract
This paper describes the creation of a re-
source of German sentences with multi-
ple automatically created alternative syn-
tactic analyses (parses) for the same text,
and how qualitative and quantitative inves-
tigations of this resource can be performed
using ANNIS, a tool for corpus querying
and visualization. Using the example of
PP attachment, we show how parsing can
benefit from the use of such a resource.
1 Introduction
In this paper, we describe the workflow and the
infrastructure to create and explore a corpus that
contains multiple parses of German sentences. A
corpus of alternative parses created by different
tools allows us to study structural differences be-
tween the parses in a systematic way.
The resource described in this paper is a collec-
tion of German sentences with -ung nominaliza-
tions extracted from the SDEWAC corpus (Faa?
et al, 2010), based on the DEWAC web corpus
(Baroni and Kilgarriff, 2006). These sentences
are employed for the study of lexical ambigui-
ties in German -ung nominalizations (Eberle et al,
2009); e.g., German Absperrung, derived from ab-
sperren ?to block?, can denote an event (?block-
ing?), a state (?blockade?) or an object (?barrier?).
Sortal disambiguation, however, is highly context-
dependent, and reliable and detailed analyses of
the linguistic context are crucial for a sortal dis-
ambiguation of these nominalizations.
More reliable and detailed linguistic analyses
can be achieved, for example, by combining the
information produced by different parsers: On the
basis of qualitative and quantitative analyses, gen-
eralized rules for the improvement of the respec-
tive parsers can be developed, as well as rules for
the mapping of their output to a tool-independent
representation, and weights for the parallel appli-
cation and combination of multiple parsers. This
approach has been previously applied to morpho-
logical and morphosyntactic annotations (Borin,
2000; Zavrel and Daelemans, 2000; Tufis?, 2000),
but only recently to syntax annotation (Francom
and Hulden, 2008; de la Clergerie et al, 2008).
Because of the complexity of syntax annotations
as compared to part of speech tags, however, novel
technologies have to be applied that allow us to
represent, to visualize and to query multiple syn-
tactic analyses of the same sentence.
This paper describes the workflow from raw text
to a searchable representation of the corpus. One
of the aims of this new resource is to assess po-
tential weaknesses in the parsers as well as their
characteristic strengths. For the example of am-
biguities in PP attachment, Sect. 4 shows how lin-
guistic analyses can be improved by combining in-
formation from different parsers.
2 Parsing
In order to maximize both coverage and gran-
ularity of linguistic analyses, we chose parsers
from different classes: A probabilistic constituent
parser and a rule-based parser that produces se-
mantically enriched dependency parses.
2.1 BitPar
BitPar (Schmid, 2006) is a probabilistic context
free parser using bit-vector operations (Schmid,
2004). Node categories are annotated along with
grammatical functions, part-of-speech tags and
morphological information in a parse tree. BitPar
analyses are conformant to the TIGER annotation
scheme (Brants et al, 2004), and the tool?s output
format is similar to the list-based bracketing for-
mat of the Penn Treebank (Bies et al, 1995). The
BitPar analysis of sentence (1) is visualized as the
right-most tree in Fig. 1.
166
(1) Der
the
Dax
Dax
reagiert
reacts
derzeit
presently
auf
on
die
the
Meldungen
messages
aus
from
London.
London
?Presently, the Dax [German stock index,
N.B.] is reacting to the news from London.?
2.2 B3 Tool
The second parser applied here is the B3 Tool
(Eberle et al, 2008), a rule-based parser that
provides syntactic-semantic analyses that com-
bine dependency parsing with FUDRT represen-
tations.1 The B3 Tool is developed on the basis
of a research prototype by Lingenio2 in the con-
text of a project on lexical ambiguities in German
nominalizations3.
For further processing, the output of the B3 Tool
is converted into a PTB-style bracketing format
similar to that used by BitPar. This transformation
involves the generation of a constituency graph
from the original dependency analysis: In the first
step, rules are used that insert nodes and projec-
tions as described by Eberle (2002). Then, another
transformation step is necessary: As the B3 Tool
aims for an abstract, flat semantics-oriented struc-
ture, certain aspects of the surface structure are not
represented in its output and need to be restored in
order to create analyses that can be aligned with
constituent-based representations. For example,
punctuation marks do not appear as leaves of the
syntactic tree, as their contribution is included in
the description of the head verb. Similarly, aux-
iliaries are not represented as individual words in
the B3 output, as their tense and aspect informa-
tion is integrated with the event description that
corresponds to the head verb.4 As we focus on the
integration of multiple syntactic analyses, leaves
from the B3 Tool output that represent semantic
information were not considered, e.g., information
on coreference.
The converted B3 analysis of sentence (1) is vi-
sualized as the left tree in Fig. 1.
1Flat Underspecified Discourse Representation Theory
(Eberle, 1997; Eberle, 2004)
2http://www.lingenio.de/English/
3Project B3 of the Collaborative Research Centre (Son-
derforschungsbereich) SFB 732, Stuttgart, Germany.
4For the study described here, punctuation marks were
added to the surface structure but auxiliaries not yet. There
are several possible approaches to dealing with these struc-
tural aspects (e.g. inserting empty elements, converting Bit-
Par into B3-like representations, etc.). The discussion of
these strategies is, however, beyond the scope of this tech-
nical paper.
3 Querying and Visualizing Alternative
Parses
In order to integrate multiple annotations created
by different tools, we employ a generic XML for-
mat, PAULA XML (Dipper and Go?tze, 2005).
PAULA XML is an XML linearization of the data
model underlying the ANNIS data base.5 It is
comparable to NITE XML (Carletta et al, 2005)
and GrAF (Ide, 2007). PAULA XML supports di-
verse data structures (trees, graphs, and flat spans
of tokens) and allows for conflicting hierarchies.
The integrated PAULA representation of the
multiple-parses corpus can be accessed using AN-
NIS, a web interface for querying and visualizing
richly annotated corpora. Fig. 1 shows the ANNIS
interface: top left is the query field; below that is
the ?match count? field (presenting the number of
instances matching the query). Below this field is
the list of corpora the user choses from. Matches
are visualized in the right window. Tokens and
token-level annotations are shown in a Key Word
In Context (KWIC) view (upper part of the search
result pane in Fig. 1), e.g., B3 morphology (2nd
row), BitPar parts of speech (3rd row), and BitPar
morphology (4th row). Trees are visualized with
the Tree view (below KWIC view).
4 Exploiting multiple parses
The goal of our research is to develop rules for
the combination of BitPar and B3 parses such that
the resulting merged parse provides more reliable
linguistic analyses than the ones provided by ei-
ther alone. The rule-based B3 Tool provides deep
semantic analyses. B3 parses are thus generally
richer in information than BitPar parses. Certain
ambiguities, however, are not resolved but rather
represented by underspecification. In this section,
we explore the possibility to employ BitPar parses
to resolve such underspecifications.
4.1 Studying PP attachment in ANNIS
The attachment of prepositional phrases is often
ambiguous between high attachment (e.g., PP as a
clausal adjunct) and low attachment (PP as a nom-
inal modifier). In such cases, the B3 Tool employs
underspecification, which is represented by a spe-
cial edge label xprep.6
5PAULA and ANNIS have been developed at the Col-
laborative Research Centre 632, http://www.sfb632.
uni-potsdam.de/?d1/annis/.
6The xprep label indicates underspecification as to
whether the PP has to be attached to its parent node or a node
167
Figure 1: ANNIS2 screenshot with query results
for QUERY 1
Using ANNIS, we retrieve all cases where a Bit-
Par PP corresponds to a B3 PP with the edge la-
beled xprep (the query used to accomplish this
will be referenced by QUERY 1 in the following).
Fig. 1 illustrates an example match: The B3 PP
(left tree) is attached to the root node with an edge
label xprep; in the BitPar analysis (right tree),
the prepositional phrase is correctly attached to the
other PP node.
Using an extended query, we conducted a quan-
titative analysis comparing the node labels as-
signed to the parent node of the respective PPs in
BitPar parses and B3 parses.
Considering only those matches where the B3
parent node was either VP or S (85%, 35 of 41),
high attachment is indicated by BitPar labels VP
or S for the BitPar parent node (34%, 12 of 35)
and low attachment by labels PP or NP (66%, 23
of 35). BitPar thus distinguishes low and high PP
attachment, with a preference for low attachment
in our data set.
Results of a subsequent qualitative analysis of
the first 20 matches retrieved by this query are
summarized in Tab. 1: Only 16% (3 of 19) Bit-
Par predictions are incorrect, 32% (6 of 19) are
possible (but different attachment would have pro-
duced a felicitous reading), and 53% (10 of 19) are
correct. BitPar analyses of PP attachment are thus
BitPar prediction correct possible incorrect total
low 57% 36% 7% 14
high 40% 20% 40% 5
low or high 53% 32% 16% 19?
? one match (non-sentence) excluded
Table 1: Qualitative analysis of the first 20
matches
relatively reliable, and where the B3 Tool indicates
underspecification with respect to PP attachment,
the point of attachment can be adopted from the
BitPar parse. With such a merging of BitPar parses
and B3 parses, a more detailed and more reliable
analysis is possible.
4.2 Merging B3 and BitPar parses
With the information from the comparison of Bit-
Par and B3 Tool attachments, a workflow is imag-
inable where both parsers are applied in paral-
lel, and then their output is merged into a com-
mon representation. As opposed to traditional ap-
proaches that reduce parse integration to a selec-
dominated by its parent.
168
tion between entire parses, cf. Crysmann et al
(2002), we employ a full merging between B3
parses and BitPar parses. This merging is based
on hand-crafted rules that express preferences be-
tween pieces of information from one parse or the
other in accordance with the results of quantitative
and qualitative analyses as described above.
B3 parses can be enriched with structural infor-
mation from BitPar, e.g., by the following exem-
plaric rule:7 if the B3 parse indicates underspec-
ification with respect to the PP attachment point
(QUERY 1), establish a dominance edge between
(i) the correspondent of the Bitpar PP (the PP
?from London? in the example) and (ii) the corre-
spondent of its parent node (the PP ?to the news?),
and delete the original, underspecified B3 edge.
The same procedure can also be applied to per-
form corrections of a parse, if further quantitative
and qualitative studies indicate that, for example,
the B3 parser systematically fails at a particular
phenomenon.
In some cases, we may also want to employ
context-dependent rules to exploit the advanta-
geous characteristics of a specific parser, e.g., to
preserve ambiguities. Example (2) illustrates that
PP attachment has an effect on the sortal interpre-
tation of Absperrung ?barrier/blocking/blockade?:
Different points of attachment can produce dif-
ferent possible readings. The PP by the police
specifies the subject of the nominalized verb ab-
sperren ?to block?. This indicates that here, the
event/state readings are preferred over the object
(=entity) reading.
(2) Die
the
Feuerwehr
fire brigade
unterstu?tzte
supported
die
the
Absperrung
blocking
durch
by
die
the
Polizei.
police
?The fire brigade supported the police?s
blockade/blocking.?
5 Conclusion
In this paper, we described the creation of a re-
source of German sentences with parallel parses
and the infrastructure employed to exploit this re-
source. We also identified possible fields of ap-
plication for this resource: By querying this re-
source one finds strong tendencies regarding the
relative reliability and level of detail of different
7Other formulations are possible, see Heid et al (2009)
for the enrichment of BitPar parses with lexical knowledge
from B3 parses.
parsers; on this basis, the strengths of several tools
can be weighted, as represented, e.g., by general-
ized, context-dependent rules to combine the out-
put of multiple parsers. Here, this approach was
illustrated for two parsers and their combination to
disambiguate PP attachment as part of a study of
German -ung nominalizations. A future perspec-
tive could be to add more tools to the comparison,
find out their characteristic strengths and perform
a sort of weighted voting to decide when an ana-
lysis should be enhanced by the information from
another one.
We have shown that the infrastructure provided
by the ANNIS data base and the underlying data
format PAULA can be employed to conduct this
kind of research. Although originally developed
for different purposes (representation and query-
ing of richly annotated corpora), its generic char-
acter allowed us to apply it with more than satis-
factory results to a new scenario.
Subsequent research may further exploit the po-
tential of the ANNIS/PAULA infrastructure and
the development of application-specific exten-
sions. In particular, it is possible to register in
ANNIS a problem-specific visualization for par-
allel parses that applies in place of the generic
tree/DAG view for the namespaces bitpar and
b3. Another extension pertains to the handling of
conflicting tokenizations: The algorithm described
by Chiarcos et al (2009) is sufficiently generic
to be applied to any PAULA project, but it may
be extended to account for B3-specific deletions
(Sect. 2.2). Further, ANNIS supports an annota-
tion enrichment cycle: Matches are exported as
WEKA tables, statistical, symbolic or neural clas-
sifiers can be trained on or applied to this data, and
the modified match table can be reintegrated with
the original corpus. This allows, for example, to
learn an automatic mapping between B3 and Bit-
Par annotations.
Acknowledgements
Collaborative Research Centre 732 (Universita?t
Stuttgart) and Collaborative Research Centre 632
(Humboldt Universita?t zu Berlin and Universita?t
Potsdam) are funded by Deutsche Forschungsge-
meinschaft (DFG).
169
References
Marco Baroni and Adam Kilgarriff. 2006. Large
linguistically-processed Web corpora for multiple
languages. In Proceedings of the 11th Conference of
the European Chapter of the Association for Com-
putational Linguistics, pages 87?90, Trento, Italy.
EACL.
Ann Bies, Mark Ferguson, Karen Katz, and
Robert MacIntyre. 1995. Bracketing guide-
lines for treebank ii style penn treebank
project. ftp://ftp.cis.upenn.edu/
pub/treebank/doc/manual/root.ps.gz
(May 31, 2010). version of January 1995.
Lars Borin. 2000. Something borrowed, something
blue: Rule-based combination of POS taggers. In
Proceedings of the 2nd International Conference on
Language Resources and Evaluation (LREC 2000),
Athens, Greece, May, 31st ? June, 2nd.
Sabine Brants, Stefanie Dipper, Peter Eisenberg, Sil-
via Hansen, Esther Ko?nig, Wolfgang Lezius, Chris-
tian Rohrer, George Smith, and Hans Uszkoreit.
2004. TIGER: Linguistic interpretation of a German
corpus. Research on Language and Computation,
2(4):597?620.
Jean Carletta, Stefan Evert, Ulrich Heid, and Jonathan
Kilgour. 2005. The NITE XML Toolkit: data
model and query. Language Resources and Eval-
uation Journal (LREJ), 39(4):313?334.
Christian Chiarcos, Julia Ritz, and Manfred Stede.
2009. By all these lovely tokens...: merging con-
flicting tokenizations. In Proceedings of the Third
Linguistic Annotation Workshop, pages 35?43. As-
sociation for Computational Linguistics.
Berthold Crysmann, Anette Frank, Kiefer Bernd, Ste-
fan Mueller, Guenter Neumann, Jakub Piskorski,
Ulrich Schaefer, Melanie Siegel, Hans Uszkoreit,
Feiyu Xu, Markus Becker, and Hans-Ulrich Krieger.
2002. An integrated architecture for shallow and
deep processing. In Proceedings of 40th Annual
Meeting of the Association for Computational Lin-
guistics, pages 441?448, Philadelphia, Pennsylva-
nia, USA, July.
Eric Villemonte de la Clergerie, Olivier Hamon,
Djamel Mostefa, Christelle Ayache, Patrick
Paroubek, and Anne Vilnat. 2008. PASSAGE:
from French Parser Evaluation to Large Sized
Treebank. In Proceedings of the 6th Conference on
Language Resources and Evaluation (LREC 2008),
Marrakech, Morocco, May.
Stefanie Dipper and Michael Go?tze. 2005. Accessing
Heterogeneous Linguistic Data ? Generic XML-
based Representation and Flexible Visualization. In
Proceedings of the 2nd Language & Technology
Conference 2005, pages 23?30, Poznan, Poland,
April.
Kurt Eberle, Ulrich Heid, Manuel Kountz, and Kerstin
Eckart. 2008. A tool for corpus analysis using par-
tial disambiguation and bootstrapping of the lexicon.
In Angelika Storrer, Alexander Geyken, Alexander
Siebert, and Kay-Michael Wu?rzner, editors, Text Re-
sources and Lexical Knowledge ? Selected Papers
from the 9th Conference on Natural Language Pro-
cessing (KONVENS 2008), pages 145?158, Berlin,
Germany. Mouton de Gruyter.
Kurt Eberle, Gertrud Faa?, and Ulrich Heid. 2009.
Proposition oder Temporalangabe? Disambigu-
ierung von -ung-Nominalisierungen von verba di-
cendi in nach-PPs. In Christian Chiarcos,
Richard Eckart de Castilho, and Manfred Stede, ed-
itors, Von der Form zur Bedeutung: Texte automa-
tisch verarbeiten / From Form to Meaning: Process-
ing Texts Automatically, Proceedings of the Biennial
GSCL Conference 2009, pages 81?91, Tu?bingen.
Gunter Narr Verlag.
Kurt Eberle. 1997. Flat underspecified representa-
tion and its meaning for a fragment of German. Ar-
beitspapiere des Sonderforschungsbereichs 340, Nr.
120, Universita?t Stuttgart, Stuttgart, Germany.
Kurt Eberle. 2002. Tense and Aspect Information
in a FUDR-based German French Machine Trans-
lation System. In Hans Kamp and Uwe Reyle, edi-
tors, How we say WHEN it happens. Contributions
to the theory of temporal reference in natural lan-
guage, pages 97?148. Niemeyer, Tu?bingen. Ling.
Arbeiten, Band 455.
Kurt Eberle. 2004. Flat underspecified representation
and its meaning for a fragment of German. Habil-
itationsschrift, Universita?t Stuttgart, Stuttgart, Ger-
many.
Gertrud Faa?, Ulrich Heid, and Helmut Schmid. 2010.
Design and application of a Gold Standard for mor-
phological analysis: SMOR as an example of mor-
phological evaluation. In Proceedings of the seventh
international conference on Language Resources
and Evaluation (LREC), Valetta, Malta.
Jerid Francom and Mans Hulden. 2008. Parallel Multi-
Theory Annotations of Syntactic Structure. In Pro-
ceedings of the Sixth International Language Re-
sources and Evaluation (LREC 2008), Marrakech,
Morocco, May.
Ulrich Heid, Kurt Eberle, and Kerstin Eckart. 2009.
Towards more reliable linguistic analyses: workflow
and infrastructure. Poster presentation at the GSCL
2009 workshop: Linguistic Processing Pipelines,
Potsdam.
Nancy Ide. 2007. GrAF: A Graph-based Format for
Linguistic Annotations. In Proceedings of the LAW
Workshop at ACL 2007, Prague.
Helmut Schmid. 2004. Efficient Parsing of Highly
Ambiguous Context-Free Grammars with Bit Vec-
tors. In Proceedings of the 20th International Con-
ference on Computational Linguistics, Coling?04,
volume 1, pages 162?168, Geneva, Switzerland.
170
Helmut Schmid. 2006. Trace Prediction and Recovery
With Unlexicalized PCFGs and Slash Features. In
Proceedings of COLING-ACL 2006, Sydney, Aus-
tralia.
Dan Tufis?. 2000. Using a large set of EAGLES-
compliant morpho-syntactic descriptors as a tagset
for probabilistic tagging. In Proceedings of the 2nd
International Conference on Language Resources
and Evaluation (LREC 2000), pages 1105?1112,
Athens, Greece, May, 31st ? June, 2nd.
Jakub Zavrel and Walter Daelemans. 2000. Boot-
strapping a Tagged Corpus through Combination of
Existing Heterogeneous Taggers. In Proceedings
of the 2nd International Conference on Language
Resources and Evaluation (LREC 2000), Athens,
Greece, May, 31st ? June, 2nd.
171
Proceedings of the Fifth Law Workshop (LAW V), pages 11?20,
Portland, Oregon, 23-24 June 2011. c?2011 Association for Computational Linguistics
OWL/DL formalization of the MULTEXT-East morphosyntactic
specifications
Christian Chiarcos
University of Potsdam, Germany
chiarcos@uni-potsdam.de
Tomaz? Erjavec
Joz?ef Stefan Institute, Slovenia
tomaz.erjavec@ijs.si
Abstract
This paper describes the modeling of
the morphosyntactic annotations of the
MULTEXT-East corpora and lexicons as
an OWL/DL ontology. Formalizing anno-
tation schemes in OWL/DL has the advan-
tages of enabling formally specifying in-
terrelationships between the various fea-
tures and making logical inferences based
on the relationships between them. We
show that this approach provides us with
a top-down perspective on a large set of
morphosyntactic specifications for multi-
ple languages, and that this perspective
helps to identify and to resolve concep-
tual problems in the original specifications.
Furthermore, the ontological modeling al-
lows us to link the MULTEXT-East spe-
cifications with repositories of annotation
terminology such as the General Ontol-
ogy of Linguistics Descriptions or the ISO
TC37/SC4 Data Category Registry.
1 Introduction
In the last 15 years, the heterogeneity of linguis-
tic annotations has been identified as a key prob-
lem limiting the interoperability and reusabil-
ity of NLP tools and linguistic data collections.
The multitude of linguistic tagsets complicates
the combination of NLP modules within a sin-
gle pipeline; similar problems exist in language
documentation, typology and corpus linguistics,
where researchers are interested to access and
query data collections on a homogeneous termi-
nological basis.
One way to enhance the consistency of lin-
guistic annotations is to provide explicit seman-
tics for tags by grounding annotations in termino-
logy repositories such as the General Ontology
of Linguistics Descriptions (Farrar and Langen-
doen, 2003, GOLD) or the ISO TC37/SC4 Data
Category Registry (Kemps-Snijders et al, 2009,
ISOcat). Reference definitions provide an inter-
lingua that allows the mapping of linguistic an-
notations from annotation scheme A to scheme
B. This application requires linking annotation
schemes with the terminological repository. This
relation can be formalized within the Linked Data
paradigm (Berners-Lee, 2006), which requires
the use of uniform resource identifiers (URIs),
the hypertext transfer protocol (HTTP), standard
representation formats (such as RDF) and links to
other URIs. Here, we propose a formalization of
this linking in OWL/DL, a notational variant of
the Description Logic SHOIN (D) that builds
on RDF and Linked Data.
Another way to enhance the consistency of
linguistic annotations is to make use of cross-
linguistic meta schemes or annotation standards,
such as EAGLES (Leech and Wilson, 1996). The
problem is that these enforce the use of the same
categories across multiple languages, and this
may be inappropriate for historically and geo-
graphically unrelated languages. For specific lin-
guistic and historical regions, the application of
standardization approaches has, however, been
performed with great success, e.g., for Western
(Leech and Wilson, 1996) and Eastern Europe
(Erjavec et al, 2003) or the Indian subcontinent
(Baskaran et al, 2008).
11
In this paper, we illustrate differences and
commonalities of both approaches by creating
an OWL/DL terminology repository from the
MULTEXT-East (MTE) specifications (Erjavec
et al, 2003; Erjavec, 2010), which define features
for the morphosyntactic level of linguistic de-
scription, instantiate them for 16 languages and
provide morphosyntactic tagsets for these lan-
guages. The specifications are a part of the MTE
resources, which also include lexicons and an an-
notated parallel corpus that use these morphosyn-
tactic tagsets.
The encoding of the MTE specifications fol-
lows the Text Encoding Initiative Guidelines, TEI
P5 (TEI Consortium, 2007), and this paper con-
centrates on developing a semi-automatic pro-
cedure for converting them from TEI XML to
OWL. While TEI is more appropriate for author-
ing the specifications and displaying them in a
book-oriented format, the OWL encoding has the
advantages of enabling formally specifying inter-
relationships between the various features (con-
cepts, or classes) and making logical inferences
based on the relationships between them, useful
in mediating between different tagsets and tools
(Chiarcos, 2008).
2 The MULTEXT-East (MTE)
Morphosyntactic Specifications
The MTE morphosyntactic specifications define
attributes and values used for word-level syntac-
tic annotation, i.e., they provide a formal gram-
mar for the morphosyntactic properties of the lan-
guages covered. The specifications also contain
commentary, bibliography, notes, etc. Follow-
ing the original MULTEXT proposal (Ide and
Ve?ronis, 1994), the specifications define 14 cat-
egories (parts of speech), and for each its at-
tributes, their values, and the languages that every
attribute-value pair is appropriate for. The mor-
phosyntactic specifications also define the map-
ping between the feature structures and mor-
phosyntactic descriptions (MSDs). MSDs are
compact strings used as tags for corpus annota-
tion and in the morphosyntactic lexicons. For
example, the MSD Ncmsn is equivalent to the
feature structure consisting of the attribute-value
pairs Noun, Type=common, Gender=masculine,
Number=singular, Case=nominative.
The specifications currently cover 16 lan-
guages, in particular: Bulgarian, Croatian,
Czech, English, Estonian, Hungarian, Macedo-
nian, Persian, Polish, Resian, Romanian, Rus-
sian, Serbian, Slovak, Slovene, and Ukrainian.
For a number of these languages the specifica-
tions have become a de-facto standard and, for
some, the MTE lexicons and corpora are still the
only publicly available datasets for this level of
linguistic description.1
Table 1 lists the defined categories and gives
the number of distinct attributes, attribute-value
pairs and the number of MTE languages which
distinguish the category. The feature-set is quite
large, as many of the languages covered have
very rich inflection, are typologically different
(inflectional, agglutinating), but also have inde-
pendent traditions of linguistic description; this
also leads to similar phenomena sometimes be-
ing expressed by different means (see Sect. 4.3).
Category Code Atts Att-Vals Langs
Noun N 14 68 16
Verb V 17 74 16
Adjective A 17 79 16
Pronoun P 19 97 16
Determiner D 10 32 3
Article T 6 23 3
Adverb R 7 28 16
Adposition S 4 12 16
Conjunction C 7 21 16
Numeral M 13 81 16
Particle Q 3 17 12
Interjection I 2 4 16
Abbreviation Y 5 35 16
Residual X 1 3 16
Table 1: MULTEXT categories with the number
of MULTEXT-East defined attributes, attribute-value
pairs and languages.
The specifications are encoded as a TEI doc-
ument, consisting of an introductory part, the
Common and the Language Specific Specifica-
tions, the latter two organized into tables by the
1The MTE specifications, as well as the other MTE re-
sources, are available from the Web page of the project at
http://nl.ijs.si/ME/.
12
<table n="msd.cat" xml:lang="en">
<head>Common specifications for Noun</head>
<row role="type">
<cell role="position">0</cell>
<cell role="name">CATEGORY</cell>
<cell role="value">Noun</cell>
<cell role="code">N</cell>
<cell role="lang">en</cell>
<cell role="lang">ro</cell>
<cell role="lang">sl</cell>
...
</row>
<row role="attribute">
<cell role="position">1</cell>
<cell role="name">Type</cell>
<cell>
<table>
<row role="value">
<cell role="name">common</cell>
<cell role="code">c</cell>
<cell role="lang">en</cell>
...
Figure 1: Common table for Noun
14 defined categories.
Figure 1 gives the start of the Common table
for Noun. It first gives the category, the lan-
guages that distinguish it, and then its attributes
with their values; the meaning of a particular row
or cell is given by its role attribute. As with the
category, each attribute-value is also qualified by
the languages that make use of the feature. Note
that MTE is a positional tagset that specifies the
position of the attribute in the MSD string, and
the one-letter code of its value, so that Nc would
correspond to Noun, Type=common.
The language-specific sections also contain ta-
bles for each category, which are similar to the
common tables in that they repeat the attributes
and their values, although only those appropri-
ate for the language. The language-specific ta-
bles can also contain localization information,
i.e., the names of the categories, attributes, their
values and codes in the particular language, in
addition to English. This enables expressing the
feature structures and MSDs either in English or
in the language in question. Furthermore, each
language-specific section can also contain an in-
dex listing all valid MSDs. This index is aug-
mented with frequency information and exam-
ples of usage drawn for a corpus.
In addition to the source TEI P5 XML, the
MTE specifications are delivered in various de-
rived formats, in particular HTML for reading
and as tabular files, which map the MSD tagset
into various feature decompositions.
3 Linking annotation schemes with
terminology repositories
3.1 Linguistic terminology initiatives
There have been, by now, several approaches
to develop terminology repositories and data
category registries for language resources, sys-
tems for mapping between diverse (morphosyn-
tactic) vocabularies and for integrating annota-
tions from different tools and tagsets, ranging
from early texts on annotation standards (Bakker
et al, 1993; Leech and Wilson, 1996) over re-
lational models and concept hierarchies (Bickel
and Nichols, 2002; Rosen, 2010) to more formal
specifications in OWL/RDF (or with OWL/RDF
export), e.g., the already mentioned GOLD and
ISOcat, OntoTag (Aguado de Cea et al, 2002)
or the Typological Database System ontology
(Saulwick et al, 2005).
Despite their common level of representation
these efforts have not yet converged into a unified
and generally accepted ontology of linguistic an-
notation terminology and there is still a consider-
able amount of disagreement between their def-
initions. As these repositories nevertheless play
an important role in their respective communi-
ties, it is desirable to link the MTE specifications
with the most representative of them, notably
with GOLD and the morphosyntactic profile of
ISOcat. As we argue below, different design de-
cisions in the terminology repositories make it
necessary to use a linking formalism that is capa-
ble of expressing both disjunctions and conjunc-
tions of concepts. For this reason, we propose the
application of OWL/DL.
By representing the MTE specifications, the
repositories, and the linking between them as
separate OWL/DL models, we follow the archi-
tectural concept of the OLiA architecture (Chiar-
cos, 2008), see Sect. 5.
13
3.2 Annotation mapping
The classic approach to link annotations with ref-
erence concepts is to specify rules that define a
direct mapping (Zeman, 2008). It is, however,
not always possible to find a 1:1 mapping.
One problem is conceptual overlap: A com-
mon noun may occur as a part of a proper name,
e.g., German Palais ?baroque-style palace? in
Neues Palais lit. ?new palace?, a Prussian royal
palace in Potsdam/Germany. Palais is thus both a
proper noun (in its function), and a common noun
(in its form). Such conceptual overlap is some-
times represented with a specialized tag, e.g., in
the TIGER scheme (Brants and Hansen, 2002).
ISOcat (like other terminological repositories)
does currently not provide the corresponding hy-
brid category, so that Palais is to be linked to both
properNoun/DC-1371 and commonNoun/DC-
1256 if the information carried by the original
annotation is to be preserved. Contractions pose
similar problems: English gonna combines going
(PTB tag VBG, Marcus et al, 1994) and to (TO).
If whitespace tokenization is applied, both tags
need to be assigned to the same token.
A related problem is the representation of am-
biguity: The SUSANNE (Sampson, 1995) tag
ICSt applies to English after both as a prepo-
sition and as a subordinating conjunction. The
corresponding ISOcat category is thus either
preposition/DC-1366 or subordinating
Conjunction/DC-1393. Without additional
disambiguation, ICSt needs to be linked to both
data categories.
Technically, such problems can be solved with
a 1:n mapping between annotations and refer-
ence concepts. Yet, overlap/contraction and am-
biguity differ in their meaning: While overlap-
ping/contracted categories are in the intersec-
tion (?) of reference categories, ambiguous cate-
gories are in their join (?). This difference is rel-
evant for subsequent processing, e.g., to decide
whether disambiguation is necessary. A mapping
approach, however, fails to distinguish ? and ?.
The linking between reference categories and
annotations requires a formalism that can distin-
guish intersection and join operators. A less ex-
pressive linking formalism that makes use of a
1:1 (or 1:n) mapping between annotation con-
cepts and reference concepts can lead to inconsis-
tencies when mapping annotation concepts from
an annotation scheme A to an annotation scheme
B if these use the same terms with slightly deviat-
ing definitions, as noted, for example, by Garab??k
et al (2009) for MTE.
3.3 Annotation linking with OWL/DL
OWL/DL is a formalism that supports the nec-
essary operators and flexibility. Reference con-
cepts and annotation concepts are formalized
as OWL classes and the linking between them
can be represented by rdfs:subClassOf (?).
OWL/DL provides owl:intersectionOf (?),
owl:unionOf (?) and owl:complementOf
(?) operators and it allows the definition of prop-
erties and restrictions on the respective concepts.
As an example, the MTE Definiteness=definite
refers to either a clitic determiner or (?) to the
?definite conjunction? of Hungarian verbs. More
precisely, it is in the intersection between these
and (?) a category for ambiguous feature values
(Sect. 4.3).
An OWL/DL-based formalization has the ad-
ditional advantage that it can be linked with exist-
ing terminology repositories that are available in
OWL or RDF, e.g., GOLD or ISOcat (Chiarcos,
2010). The linking to other terminology reposi-
tories will be subject of subsequent research. In
this paper, we focus on the development of an
OWL/DL representation of MTE morphosyntac-
tic specifications that represents a necessary pre-
condition for OWL/DL-based annotation linking.
4 Building the MTE ontology
We built the MTE ontology2 in a three-step sce-
nario: first, a preliminary OWL/DL model of the
common MTE specifications was created (Sect.
4.1); we then built language-specific subontolo-
gies and linked them to the common ontology
(Sect. 4.2); finally, the outcome of this process
2All MTE ontologies are available under
http://nl.ijs.si/ME/owl/ under a Creative
Commons Attribution licence (CC BY 3.0).
14
was discussed with a group of experts and revised
(Sect. 4.3).
4.1 Common specifications
Following the methodology described by Chiar-
cos (2008), the structure of the MTE ontology
was derived from the original documentation.
The initial ontology skeleton was created auto-
matically (the organization of the specifications
was exploited to develop an XSLT script that
mapped TEI XML to OWL), but subsequently
manually augmented with descriptions and ex-
amples found in the individual languages.
1. Two top-level concepts Morphosyn-
tacticCategory and Morphosyntac-
ticFeature represent root elements of
the MTE ontology. An object property
hasFeature maps a Morphosyntac-
ticCategory onto one or multiple
MorphosyntacticFeature values.
2. All MSD categories are subconcepts of
MorphosyntacticCategory, e.g., Noun,
Verb, Adjective, etc.
3. For every category, the MTE attribute
Type was used to infer subcategories, e.g.,
the concept ExclamativePronoun (?
Pronoun) for Pronoun/Type=exclamative.
4. From more specialized type attributes
(e.g., Wh Type, Coord Type, Sub Type,
and Referent Type), additional subcate-
gories were induced at the next deeper
level, e.g., SimpleCoordinatingCon-
junction (? CoordinatingConjunc-
tion) from Conjunction/Type=coordina-
ting, Coord Type=simple.
5. All remaining attributes are subconcepts
of MorphosyntacticFeature, e.g.,
Aspect, Case, etc.
6. For every subconcept of Morphosyntac-
ticFeature (e.g., Aspect) a corres-
ponding hasFeature subproperty (e.g.,
hasAspect) was introduced, with the mor-
phosyntactic feature as its range and the join
of morphosyntactic categories it can cooc-
cur with as its domain. An additional con-
straint restricts its cardinality to at most 1.
7. All attribute values are represented as
subclasses of the corresponding at-
tribute concept, e.g., AbessiveCase (for
Case=abessive) as a subconcept of Case.3
8. Every concept was automatically aug-
mented with a list of up to 10 examples for
every language which were drawn from the
language-specific MSD index.
4.2 Language-specific subontologies
Having represented the common MTE specifica-
tions in OWL, we decided to represent the an-
notation scheme for every language in a separate
OWL model, and to make use of the OWL im-
port mechanism to link it with the common spe-
cifications. The language-specific subontologies
do not specify their own taxonomy, but rather
inherit the concepts and properties of the com-
mon model. Unlike the common model, they in-
clude individuals that provide information about
the tags (MSDs) used for this particular language.
Every individual corresponds to an MSD tag.
We use data properties of the OLiA system on-
tology4 to indicate its string realization (e.g.,
system:hasTag ?Ncmsn?) and the designator
of its annotation layer (e.g., system:hasTier
?pos?). Additionally, rdfs:comment elements
contain all examples of the original MSD speci-
fications.
In accordance to the specified annotation val-
ues, every individual is defined as an instance
of the corresponding MorphosyntacticCate-
gory (e.g., Noun) and MorphosyntacticFea-
ture (e.g., SingularNumber) from the com-
mon specifications. Additionally, for every Mor-
phosyntacticFeature (e.g., Number, the su-
perconcept of SingularNumber), it is assigned
3This ontology does not contain individuals. In our
approach, individuals represent feature bundles in the
language-specific subontologies, corresponding to the indi-
vidual MSD tags. (or, in other application scenarios, the
token that the tag is applied to).
4http://nachhalt.sfb632.uni-potsdam.de/
owl/system.owl, prefix system
15
<mte:Noun rdf:ID="Ncmsn_sl">
<system:hasTag>Ncmsn</system:hasTag>
<system:hasTier>pos</system:hasTier>
<rdf:type
rdf:resource="...#CommonNoun"/>
<rdf:type
rdf:resource="...#MasculineGender"/>
<rdf:type
rdf:resource="...#SingularNumber"/>
<rdf:type
rdf:resource="...#NominativeCase"/>
<mte:hasGender rdf:resource="#Ncmsg_sl"/>
<mte:hasNumber rdf:resource="#Ncmsg_sl"/>
<mte:hasCase rdf:resource="#Ncmsg_sl"/>
<rdfs:comment>e.g., cas, svet, denar, ...
</mte:Noun>
Figure 2: MSD Ncmsn in the Slovene subontology
itself as target of the corresponding object prop-
erty (e.g., hasNumber).
Figure 2 shows the subontology entry for the
tag Ncmsn in the Slovene subontology. The indi-
vidual could thus be retrieved with the following
queries for ?singular noun?:
(1) Noun and hasNumber some
SingularNumber
(2) Noun and SingularNumber
The language-specific subontologies were fully
automatically created from the TEI XML using
XSLT scripts. During the revision of the com-
mon specifications, these scripts were updated
and reapplied.
4.3 Revision of the initial OWL model
After the automatic conversion from XML to
OWL the resulting ontology skeleton of the
common specifications was manually augmented
with descriptions, explanations and selected
examples from the language-specific MTE spe-
cifications. Furthermore, concept names with ab-
breviated or redundant names were adjusted, e.g.,
the concept CorrelatCoordConjunction
(Coord Type=correlat) was expanded to
CorrelativeCoordinatingConjunction,
and DefiniteDefiniteness (Definite-
ness=definite) was simplified to Definite.
Finally, if one attribute value represents a
specialization of another, the former was
recast as a subconcept of the latter (e.g.,
CliticProximalDeterminer ? CliticDe-
finiteDeterminer).
Moreover, a number of potential problems
were identified. Some of them could be ad-
dressed by consulting MTE-related publications
(Qasemizadeh and Rahimi, 2006; Dimitrova et
al., 2009; Derzhanski and Kotsyba, 2009), but
most were solved with the help of the original
authors of the MTE specifications and an open
discussion with these experts over a mailing list.
The problems fall in two general classes:
(a) terminological problems, and (b) conceptual
problems. By terminological problems we mean
that a term required a more precise definition
than provided in the MTE specifications; con-
ceptual problems pertain to design decisions in
a positional tagset (overload: the same annota-
tion refers to two different phenomena in dif-
ferent languages) and to artifacts of the creation
process of the MTE specifications (redundancies:
the same phenomenon is represented in different
ways for different languages). Figure 3 shows
a fragment of the MTE ontology that showed all
types of conceptual problems as described below.
Terminological problems include the use of
non-standard or language-specific terminology
(e.g., Clitic=burkinostka for conventional collo-
cations in Polish, or Case=essive-formal for Hun-
garian), and the need to understand design deci-
sions that were necessary for language-specific
phenomena (e.g., Numeral/Class=definite34 for
Czech and Polish quantifiers with the same pat-
terns of agreement as the numerals 3 and 4).
In the course of the revision, most non-
standard terms were replaced with conven-
tional, language-independent concept names, and
language-specific phenomena were documented
by adding relevant excerpts from discussions or
literature as owl:versionInfo.
For a few concepts, no language-independent
characterization could be found. For exam-
ple, Numeral/Form=m form refers to numer-
als with the suffix -ma in Bulgarian (a special
form of the numerals ?2? to ?7? for persons of
masculine gender). In the ontology, the con-
cept MFormNumeral is preserved, but it is con-
strained so that every instance matches the fol-
16
lowing OWL/DL expression:
(3) CardinalNumber and hasAnimacy some
Animate and hasGender some Masculine
Attribute overload means that one attribute
groups together unrelated phenomena from dif-
ferent languages. In a positional tagset, attribute
overload is a natural strategy to achieve compact
and yet expressive tags. As every attribute re-
quires its own position in the tag, the length of
MSD tags grows with the number of attributes.
Overload thus reduces tag complexity. To an on-
tological model, however, these complexity con-
siderations do not apply, whereas proper concep-
tual differentiations are strongly encouraged.
We thus decided to disentangle the various
senses of overloaded attributes. For example, the
MorphosyntacticFeature Definiteness,
is split up in three subconcepts (cf. Fig. 3).
CliticDeterminerType: presence of a post-
fixed article of Romanian, Bulgarian and
Persian nouns and adjectives.
ReductionFeature: the difference between
full and reduced adjectives in many Slavic
languages.
PersonOfObject: the so-called ?definite con-
jugation? of Hungarian verbs.
Value overload has a similar meaning to at-
tribute overload. Definiteness=definite, for ex-
ample, can refer to a clitic definite determiner
(a CliticDeterminerType in Romanian and
Bulgarian), to a clitic determiner that expresses
specificity (a CliticDeterminerType in Per-
sian), or to a verb with a definite 3rd-person di-
rect object (a PersonOfObject in Hungarian).
In the ontology, this is represented by defin-
ing Definite as a subconcept of the owl:join
(?) of CliticDefiniteDeterminer, Cli-
ticSpecificDeterminer and PersonOfOb-
ject. Additional concepts, e.g., Ambigu-
ousDefinitenessFeature, were created to
anchor ambiguous concepts like Definite in
the taxonomy (see Fig. 3).
Redundancy: For many languages, the MTE
specifications were created in a bottom-up fash-
ion, where existing NLP tools and lexicons were
Figure 3: Definiteness in the MTE ontology
integrated with a pre-existing taxonomy of an-
notation categories. Language-specific features
were introduced when necessary, but sometimes
in different ways for the same phenomenon in
closely related languages. The MTE specifica-
tions thus comprise a certain degree of redun-
dancy.
For example, the distinction between full and
reduced adjectives in Slavic languages is ex-
pressed differently: For Czech, reduced adjec-
tives are marked by Formation=nominal, but for
Polish by Definiteness=short-art.
In the ontology, such redundancies are re-
solved by owl:equivalentClass statements,
marked by ? in Fig. 3.
5 Summary and Discussion
We have described the semi-automatic creation
of an ontological model of the MTE morphosyn-
tactic specifications for 16 different languages.
Such a model may be fruitfully applied in
various ways, e.g., within an NLP pipeline that
uses ontological specifications of annotations
rather than their string representations (Buyko
et al, 2008; Hellmann, 2010). The ontolog-
ical modeling may serve also as a first step
towards an ontology-based documentation of
the annotations within a corpus query system
(Rehm et al, 2007; Chiarcos et al, 2008),
17
or even the ontological modeling of entire
corpora (Burchardt et al, 2008; Hellmann et
al., 2010) and lexicons (Martin et al, 2009).
As an interesting side-effect of the OWL con-
version of the entire body of MTE resources,
they could be easily integrated with existing
lexical-semantic resources as Linked Data, e.g.,
OWL/RDF versions of WordNet (Gangemi et
al., 2003), which are currently being assem-
bled by various initiatives, e.g., in the context
of the LOD2 project (http://lod2.eu)
and by the Open Linguistics Working
Group at the OpenKnowledge Foundation
(http://linguistics.okfn.org).
Another very important element is that the on-
tological modeling of the MTE annotations al-
lows it to be interpreted in terms of existing
repositories of annotation terminology such as
ISOcat and GOLD. A bridge between these ter-
minology repositories and the MTE ontology
may be developed, for example, by integrat-
ing the ontology in an architecture of modular
ontologies such as the Ontologies of Linguis-
tic Annotations (Chiarcos, 2008, OLiA), where
the linking between annotations and terminology
repositories is mediated by a so-called ?Refer-
ence Model? that serves as an interface between
different levels of representation.
The MTE ontology will be integrated in this
model as an annotation model, i.e., its concepts
will be defined as subconcepts of concepts of the
OLiA Reference Model and thereby inherit the
linking with GOLD (Chiarcos et al, 2008) and
ISOcat (Chiarcos, 2010). The linking with these
standard repositories increases the comparability
of MTE annotations and it serves an important
documentation function.
More important than merely potential applica-
tions of the MTE ontology, however, is that its
creation provides us with a new, global perspec-
tive on the MTE specifications. A number of
internal inconsistencies could be identified and
strategies for their resolution (or formalization)
were developed. Redundancies and overload
were documented, and we further added expert
definitions of controversial or non-standard con-
cepts. When used as a documentation, these spe-
cifications may prevent misunderstandings with
respect to the meaning of the actual annotations.
For later versions of the MTE morphosyntactic
specifications, they may even guide the refactor-
ing of the annotation scheme.
The result of the development process de-
scribed above is a prototype, that has to be aug-
mented with definitions for non-controversial and
well-understood concepts, which can be derived
from the linking with OLiA, GOLD and ISOcat.
As for its language type, our strategy to resolve
overload requires OWL/DL (owl:join). With-
out value overload and redundancy, the ontology
would be OWL/Lite, as were the initial ontolo-
gies (Sect. 4.1 and Sect. 4.2). However, the cur-
rent modeling is still sufficiently restricted to al-
low the application of reasoners, thereby open-
ing up the possibility to use SemanticWeb tech-
nologies on MTE data, to connect it with other
sources of information and to draw inferences
from such Linked Data.
We would also like to point out that the conver-
sion of the MTE specifications to OWL required
relatively little effort. The total time required
for conversion (without the revision phase) took
approximately four days of work for a compu-
tational linguist familiar with OWL and part-of-
speech tagsets in general (the most labor-intense
part were discussions and literature consultation
during the revision phase). Given the complexity
of the MTE specifications (a highly elaborate set
of morphosyntactic specifications for 16 typolog-
ically diverse languages and with more than thou-
sand tags for many of the languages), this may be
regarded an upper limit for the time necessary to
create OWL models for annotation schemes.
We have thus not only shown that the ontolog-
ical modeling of annotation schemes is possible
and that it allows us to use our data in novel ways
and to perform consistency control, but also that
this was achievable with relatively low efforts in
time and personnel.
18
Acknowledgements
The authors would like to thank the members of
the mocky-l mailing list for their invaluable in-
put; all errors in the paper remain our own. The
research on linguistic ontologies described in this
paper was partially funded by the German Re-
search Foundation (DFG) in the context of the
Collaborative Research Center (SFB) 632.
References
Guadalupe Aguado de Cea, Inmaculada ?Alvarez de
Mon-Rego, Antonio Pareja-Lora, and Rosario
Plaza-Arteche. 2002. OntoTag: A semantic web
page linguistic annotation model. In Proceedings
of the ECAI 2002 Workshop on Semantic Author-
ing, Annotation and Knowledge Markup, Lyon,
France, July.
Dik Bakker, Osten Dahl, Martin Haspelmath, Maria
Koptjevskaja-Tamm, Christian Lehmann, and
Anna Siewierska. 1993. EUROTYP guidelines.
Technical report, European Science Foundation
Programme in Language Typology.
S. Kalika Bali Baskaran, Tanmoy Bhattacharya,
Pushpak Bhattacharyya, Monojit Choudhury,
Girish Nath Jha, S. Rajendran, K. Saravanan,
L. Sobha, and KVS Subbarao. 2008. Designing
a common POS-tagset framework for Indian
languages. In 6th Workshop on Asian Language
Resources, pages 89?92, Hyderabad, India.
Tim Berners-Lee. 2006. Design issues: Linked data.
http://www.w3.org/DesignIssues/
LinkedData.html (May 11, 2011).
Balthasar Bickel and Johanna Nichols. 2002. Autoty-
pologizing databases and their use in fieldwork. In
Proceedings of the LREC 2002 Workshop on Re-
sources and Tools in Field Linguistics, Las Palmas,
Spain, May.
Sabine Brants and Silvia Hansen. 2002. Develop-
ments in the TIGER annotation scheme and their
realization in the corpus. In Proceedings of the 3rd
International Conference on Language Resources
and Evaluation (LREC 2002), pages 1643?1649,
Las Palmas, Spain, May.
Aljoscha Burchardt, Sebastian Pado?, Dennis Spohr,
Anette Frank, and Ulrich Heid. 2008. Formal-
ising Multi-layer Corpora in OWL/DL ? Lexicon
Modelling, Querying and Consistency Control. In
Proceedings of the 3rd International Joint Confer-
ence on NLP (IJCNLP 2008), Hyderabad, India,
January.
Ekaterina Buyko, Christian Chiarcos, and Antonio
Pareja-Lora. 2008. Ontology-based interface spec-
ifications for a NLP pipeline architecture. In Pro-
ceedings of the 6th International Conference on
Language Resources and Evaluation (LREC 2008),
Marrakech, Morocco, May.
Christian Chiarcos, Stefanie Dipper, Michael Go?tze,
Ulf Leser, Anke Lu?deling, Julia Ritz, and Manfred
Stede. 2008. A flexible framework for integrat-
ing annotations from different tools and tag sets.
Traitement Automatique des Langues (TAL), 49(2).
Christian Chiarcos. 2008. An ontology of linguis-
tic annotations. LDV Forum, 23(1):1?16. Foun-
dations of Ontologies in Text Technology, Part II:
Applications.
Christian Chiarcos. 2010. Grounding an ontology
of linguistic annotations in the Data Category Reg-
istry. In Proceedings of the LREC 2010 Workshop
on Language Resource and Language Technology
Standards (LR&LTS 2010), Valetta, Malta, May.
Ivan Derzhanski and Natalia Kotsyba. 2009. To-
wards a consistent morphological tagset for Slavic
languages: Extending MULTEXT-East for Polish,
Ukrainian and Belarusian. In Mondilex Third Open
Workshop, pages 9?26, Bratislava, Slovakia, April.
Ludmila Dimitrova, Radovan Garab??k, and Daniela
Majchra?kova?. 2009. Comparing Bulgarian
and Slovak Multext-East morphology tagset. In
Mondilex Second Open Workshop: Organization
and Development of Digital Lexical Resources,
pages 38?46, Kyiv, Ukraine, February.
Tomaz? Erjavec, Cvetana Krstev, Vladim??r Petkevic?,
Kiril Simov, Marko Tadic?, and Dus?ko Vitas. 2003.
The MULTEXT-East Morphosyntactic Specifica-
tions for Slavic Languages. In Proceedings of the
EACL 2003 Workshop on Morphological Process-
ing of Slavic Languages, pages 25?32.
Tomaz? Erjavec. 2010. MULTEXT-East Version 4:
Multilingual Morphosyntactic Specifications, Lex-
icons and Corpora. In Proceedings of the 7th Inter-
national Conference on Language Resources and
Evaluation (LREC 2010), Valetta, Malta, May.
Scott Farrar and D. Terence Langendoen. 2003. A
linguistic ontology for the semantic web. Glot In-
ternational, 7(3):97?100.
Aldo Gangemi, Roberto Navigli, and Paola Velardi.
2003. The OntoWordNet project: Extension and
axiomatization of conceptual relations in Word-
Net. In R. Meersman and Z. Tari, editors, Procee-
dings of On the Move to Meaningful Internet Sys-
tems (OTM 2003), pages 820?838, Catania, Italy,
November.
19
Radovan Garab??k, Daniela Majchra?kova?, and Lud-
mila Dimitrova. 2009. Comparing Bulgarian and
Slovak MULTEXT-East morphology tagset. In
Mondilex Second Open Workshop: Organization
and Development of Digital Lexical Resources,
pages 38?46, Kyiv, Ukraine. Dovira Publishing
House.
Sebastian Hellmann, Jo?rg Unbehauen, Christian
Chiarcos, and Axel-Cyrille Ngonga Ngomo. 2010.
The TIGER Corpus Navigator. In Proceedings
of the 9th International Workshop on Treebanks
and Linguistic Theories (TLT 2010), pages 91?102,
Tartu, Estonia, December.
Sebastian Hellmann. 2010. The semantic gap of for-
malized meaning. In Proceedings of the 7th Ex-
tended Semantic Web Conference (ESWC 2010),
Heraklion, Greece, May 30th ? June 3rd.
Nancy Ide and Jean Ve?ronis. 1994. MULTEXT
(Multilingual Tools and Corpora). In Proceedings
of the 15th International Conference on Computa-
tional Linguistics (COLING 1994), pages 90?96,
Kyoto.
Marc Kemps-Snijders, Menzo Windhouwer, Peter
Wittenburg, and Sue Ellen Wright. 2009. ISO-
cat: remodelling metadata for language resources.
International Journal of Metadata, Semantics and
Ontologies, 4(4):261?276.
Geoffrey Leech and Andrew Wilson. 1996.
Recommendations for the Morphosyntac-
tic Annotation of Corpora. EAGLES Re-
port EAG?TCWG?MAC/R, ILC, Pisa.
http://www.ilc.cnr.it/EAGLES96/
annotate/ (May 11, 2011).
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1994. Building a large annotated
corpus of English: The Penn Treebank. Computa-
tional Linguistics, 19(2):313?330.
Fabienne Martin, Dennis Spohr, and Achim Stein.
2009. Representing a resource of formal lexical-
semantic descriptions in the Web Ontology Lan-
guage. Journal for Language Technology and
Computational Linguistics, 21:1?22.
Behrang Qasemizadeh and Saeed Rahimi. 2006.
Persian in MULTEXT-East framework. In Tapio
Salakoski, Filip Ginter, Sampo Pyysalo, and Tapio
Pahikkala, editors, Advances in Natural Language
Processing, Proceedings of the 5th International
Conference on NLP (FinTAL 2006), pages 541?
551, Turku, Finland, August.
Georg Rehm, Richard Eckart, and Christian Chiar-
cos. 2007. An OWL-and XQuery-based mech-
anism for the retrieval of linguistic patterns from
XML-corpora. In Proceedings of Recent Advances
in Natural Language Processing (RANLP 2007),
Borovets, Bulgaria, September.
Alexandr Rosen. 2010. Mediating between incom-
patible tagsets. In Proceedings of the Workshop on
Annotation and Exploitation of Parallel Corpora
(AEPC), pages 53?62, Tartu, Estonia, December.
Geoffrey Sampson. 1995. English for the computer:
The SUSANNE corpus and analytic scheme. Ox-
ford University Press.
Adam Saulwick, Menzo Windhouwer, Alexis Dimi-
triadis, and Rob Goedemans. 2005. Distributed
tasking in ontology mediated integration of typo-
logical databases for linguistic research. In Procee-
dings of the 17th Conference on Advanced Infor-
mation Systems Engineering (CAiSE 2005), Porto,
Portugal, June.
TEI Consortium, editor. 2007. TEI P5: Guidelines
for Electronic Text Encoding and Interchange. TEI
Consortium.
Daniel Zeman. 2008. Reusable tagset conversion us-
ing tagset drivers. In Proceedings of the 6th Inter-
national Conference on Language Resources and
Evaluation (LREC 2008), Marrakech, Morocco,
May.
20
Proceedings of the 8th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities (LaTeCH) @ EACL 2014, pages 22?31,
Gothenburg, Sweden, April 26 2014.
c
?2014 Association for Computational Linguistics
New Technologies for Old Germanic. Resources and Research on Parallel
Bibles in Older Continental Western Germanic
Christian Chiarcos, Maria Sukhareva, Roland Mittmann,
Timothy Price, Jens Chobotsky, and Gaye Detmold
Goethe University Frankfurt, Germany
{lastname}@em.uni-frankfurt.de
Abstract
We provide an overview of on-going ef-
forts to facilitate the study of older Ger-
manic languages currently pursued at the
Goethe-University Frankfurt, Germany.
We describe created resources, such as a
parallel corpus of Germanic Bibles and a
morphosyntactically annotated corpus of
Old High German (OHG) and Old Saxon,
a lexicon of OHG in XML and a multi-
lingual etymological database. We discuss
NLP algorithms operating on this data,
and their relevance for research in the Hu-
manities.
RDF and Linked Data represent new and
promising aspects in our research, cur-
rently applied to establish cross-references
between etymological dictionaries, infer
new information from their symmetric clo-
sure and to formalize linguistic annota-
tions in a corpus and grammatical cate-
gories in a lexicon in an interoperable way.
1 Background
We describe on-going efforts at the Goethe Uni-
versity Frankfurt on the study of older Continen-
tal Western Germanic languages, in particular, Old
High German (OHG, ancestor of German), Old
Saxon (OS, ancestor of Low German) and (to a
lesser extent) Old Low Franconian (OLF, ancestor
of Dutch) and their relation to Old English (OE),
Gothic, German and other Germanic languages as
well as the relation of OHG and OS religious texts
to their Latin sources. This line of research is con-
ducted in the context of two larger efforts, the Old
German Reference Corpus and the LOEWE clus-
ter ?Digital Humanities?, in collaboration with the
Applied Computational Linguistics group at the
Goethe-Universitt Frankfurt.
The Old German Reference Corpus is a DFG-
funded project that emerged from the Deutsch Di-
achron Digital (DDD) initiative, conducted in co-
operation between HU Berlin, U Frankfurt and
U Jena, and aims to provide a morphosyntacti-
cally annotated, exhaustive reference corpus of
Old High German and Old Saxon. The LOEWE
cluster ?Digital Humanities?,
1
funded through a
programm of the State of Hessen, is a collabo-
ration between U Frankfurt, TU Darmstadt and
Freies Deutsches Hochstift Frankfurt aiming to
develop methodologies and infrastructures to fa-
cilitate information-technological support of re-
search in the humanities.
The collaboration between the humanities and
NLP described here is guided by different, though
converging interests: For the humanities, the lan-
guage resources, annotations, alignment and tools
created in collaboration with NLP researchers
represent novel instruments complementing tradi-
tional philological approaches, e.g., to investigate
emergence and decay of syntactic patterns.
From an NLP perspective, the Germanic lan-
guages provide a test-bed to develop strategies
for novel algorithms for alignment and annotation
projection. In particular, the abundance of parallel
(Bible) texts for all major language stages of most
Germanic languages, the excellent NLP support
for modern Germanic languages, and the availabil-
ity of a considerable body of annotated historical
texts allow us to study the impact of the factor
of diachronic relatedness when building resources
for low-resource languages.
2 Corpus Data
Along with annotated corpora provided by third
parties (Tab. 1), two important data sets have been
constructed in the course of our research. These
include a massive, verse-aligned Bibles corpus
1
http://www.digital-humanities-hessen.de
22
covering all Germanic languages, and the Old Ger-
man Reference Corpus. In additional, a thematical
alignment of quasi-parallel text within and across
biblical texts was extrapolated from the literature.
2.1 Germanic parallel Bible corpus
Bible data represents the majority of parallel data
available for historical Germanic languages, and
for the case of OS and OHG, gospel harmonies
represent even the majority of data currently
known. Hence, we began compiling a corpus of
Bible texts, excerpts and fragments for all Ger-
manic languages marked up with IDs for verses (if
possible), chapters and books. For data represen-
tation, we employed an XML version of the CES-
scheme developed by (Resnik et al., 1997). Hav-
ing outgrown the scale of Resnik?s earlier project
by far, we are currently in transition to TEI P5
XML format. At the moment, 271 texts with about
38.4M tokens have already been processed (Tab.
2). Copyright prevents redistributing most of this
data under a free or an academic license, but we
plan to share the extraction and conversion scripts
we used. . Except for automatically parsed Bibles
in modern English, German and Swedish, the texts
in this collection are not annotated. Where anno-
tations are available from other corpora (Tab. 1),
however, these were aligned with our Bibles.
2.2 Old German Reference Corpus
The Old German Reference Corpus (Referenzkor-
pus Altdeutsch) (Mittmann, 2013) is a joint project
in cooperation between HU Berlin, U Frankfurt
and U Jena, conducted in the wider context of the
Deutsch Diachron Digital (DDD) initiative. The
DDD initiative aims to provide deeply-annotated
reference corpora of different historical stages of
German. The Old German Reference Corpus com-
prises all preserved texts from the oldest stages of
continental Western Germanic (OHG and OS) dat-
ing from ca. 750 to 1050 CE, 650,000 tokens in
total. Among the largest coherent subcorpora are
Tatian (OHG), Otfrid of Weissenburg (OHG) and
the Heliand (OS). From these, only Tatian can be
verse-aligned with the gospels (and is included in
Tab. 1 and 2), while the Heliand and Otfrid are free
renderings of the gospels. For these, the literature
provides a section-level alignment only.
The DDD builds on the earlier efforts of the
TITUS project (Thesaurus of Indo-European Text
and Language Materials, Thesaurus Indogerman-
ischer Text- und Sprachmaterialien) that pro-
vided digitized editions of texts in old Germanic
languages as well as other Indo-European and
selected non-Indo-European languages (Gippert,
2011).
2
The annotations are mostly derived from the lit-
erature and existing glossaries that provide gram-
matical information for all known OHG and OS
words, together with their exact source. These
have been digitized, automatically applied to the
text, manually refined using the annotation soft-
ware ELAN,
3
augmented with metadata, and fi-
nally published via the ANNIS database (Linde
and Mittmann, 2013).
The annotated corpus is published under a CC-
BY-SA license over http://www.laudatio.
org, where ELAN and relANNIS files are pro-
vided. So far, the OHG Tatian is available, further
data sets are currently in preparation.
2.3 Thematical alignment within and across
biblical texts
Translations of religious texts are well-suited for
language comparison as well as NLP experiments
exploiting parallel data as they are not only faith-
fully translated, but also, they come with a verse-
level alignment which can serve as a basis for sta-
tistical word-level alignment, using, e.g., GIZA++
(Och and Ney, 2003). Where such a verse-level is
not explicitly given, it can be automatically iden-
tified for actual translations. However, for inde-
pendent compositions such as gospel harmonies,
alignment is harder to identify and can only be es-
tablished at the level of sections. In addition, sim-
ilar links also exist between different parts of the
Bible, e.g., parallel passages in different gospels.
For these, an index providing a coarse-grained
thematical alignment at the level of sections was
extrapolated from the literature. This index can
be exploited to increase the coverage of the align-
ment: where no exact translation is available (his-
torical language data is often fragmentary), a the-
matically matching section is retrieved. Further-
more, consulting the verse under consideration to-
gether with renderings of quasiparallel parts of the
same text allows historical linguists to grasp the
degree of grammatical variability for the phenom-
ena they are interested in. Language comparison
can thus be particularly well accomodated if mul-
2
http://titus.uni-frankfurt.de/texte/
texte2.htm#ahd and #asachs
3
http://www.lat-mpi.eu/tools/elan
23
language period syntax tok. corpus
English
Modern 19th CS 21K (Kroch et al., 2010)
British 18th CS 32K (Kroch et al., 2010)
Early 17th CS 22K (Kroch et al., 2004)
Modern 16th CS 21K (Kroch et al., 2004)
Middle 14th CS 66K (Kroch and Taylor, 2000)
Old 10th CS 78K (Taylor et al., 2003b)
DS 7K (Haug and J?hndal, 2008)
Icelandic Middle 16th CS 40K (R?ognvaldsson et al., 2012)
High Early Mod.16th CS 27K (Light, 2013)
German Old 9th CH 41K Sect. 2.2
Gothic 4th DS 56K (Haug and J?hndal, 2008)
Table 1: Verse-aligned older Germanic Bible texts
from various corpora with manual annotations for
morphosyntax and syntax (CH chunks, CS con-
stituents, DS dependencies)
after 1800- 1600- 1400- 1100- before
1900 1900 1800 1600 1400 1100
Insular West Germanic
English 2 2 2 6 3 (+2) 1
Pidgin/Creol 2
Scots (6) (1)
Frisian 2 (+8) (12) Continental West Germanic
Dutch 4 1 5 (1)
L. Franconian (47) 21
Afrikaans 3
German 3 1 (19) 1 (+4) 1 (+1) 1
dialects 3 (+2)
Yiddish 1
Low German 3 (+18) (66) (2) 1
Plautdietsch 2
Danish 1 North & East Germanic
Swedish 3 (3) (1)
Bokm?al 2
Nynorsk 2
Icelandic 1 1
Faroese 1
Norn (2)
Gothic 1
tokens 21.8M 3.2M 2.7M 9.2M 1.2M 0.2M
Table 2: Verse-aligned texts in the Germanic par-
allel Bible corpus (parentheses indicate marginal
fragments with less than 50,000 tokens)
tiple versions of the same passage in the same lan-
guage can be provided.
To exploit redundancy and to enlarge the num-
ber of parallel and quasi-parallel passages for a
given phenomenon searched in the corpus, cross-
references within the Bible and between the Bible
and derived texts have been identified. For ex-
ample, coarse-grained thematical alignment be-
tween different gospels is provided by the Euse-
bian Canon Tables and their subordinate Ammo-
nian sections and are extendable to the Latin Ta-
tian. For OS Heliand, a free adaptation of gospels,
we have only a section-level thematical alignment
with Tatian provided by Sievers (1872).
Information on these cross-references has been
digitized and employed to create an interlinked in-
dex of thematically similar sections in the gospels
and the OS and OHG gospel harmonies. Our Bible
West Germanic other reconstr.
lexicon OE OHG OS OLF OFr ON Got PGmc PIE
entries (XML, in K)
25 24 9 2 13 12 5 9 7
triples (RDF, in M)
1.2 1.6 .6 .2 .6 .7 .4 .2 .2
lemon:Words & links (in K)
OE 25 1
OHG 2 26 7 2 3 1
OS 1 4 9 1 2 1
ON 1 1 14
Got 1 1 1 1 6
PGmc 5 3 3 1 2 4 2 8
PIE 2 1 1 1 1 1 1 8
German 16 23 8 4 10 12 7 6 3
English 10 4 2 5 9 2
symmetric closure of etym. links (triples per lang. in K)
+11 +14 +11 +5 +9 +8 +5 +21 +9
links to (L)LOD data sets (triples per data set in K)
OLiA 24 22 8 2 12 11 5 8 7
lexvo 132 186 82 21 68 82 49 14 15
Glottolog 15 11 8 3 7 11 6 9 13
Table 3: Statistics on the etymological dictio-
naries, including Old Low Franconian (OLF),
Old Frisian (OFr), Old Norse (ON), Gothic
(Got), Proto-Germanic (PGmc) and Proto-Indo-
European (PIE)
data is thus accompanied with an index that links
disparate texts from different time periods and in
distinctive styles and variant languages on the ba-
sis of thematical similarity as identified in the liter-
ature. For gospels and gospel harmonies, we iden-
tified 4560 inter-text groups made up of the related
chunks between all the originals and languages in-
volved that represents the basis for a more fine-
grained level of alignment (Price, 2012).
3 Linked Lexicon Data
A large lexical database of etymologically linked
dictionaries of old Germanic languages (OS,
OHG, OE, Gothic, Old Norse, Old Frisian, Old
Low Franconian, Proto-Germanic; also Proto-
Indo-European) has been developed in the con-
text of the LOEWE cluster ?Digital Humanities?
at the U Frankfurt. Building on the etymologi-
cal and translational dictionaries of Old Germanic
languages by Gerhard K?obler,
4
the project ?Histor-
ical Linguistic Database? developed user-friendly
means of comparing etymologically related forms
between historical dialects and their daughter lan-
guages (Price, 2012). The original PDF data
were converted into an XML representation, cross-
references have been resolved and the results are
4
http://www.koeblergerhard.de/
ahdwbhin.html
24
imported into an XML database. A web interface
has been developed, that transforms user queries
into XQuery and visualizes the results in a conve-
nient way using XSLT.
To provide a machine-readable representation
of the etymological dictionaries, an RDF version
has been compiled. Applying the Linked Data
paradigm (Bizer et al., 2009) to etymological lex-
icons is particularly promising as they are char-
acterized by a heavy linkage across different lan-
guages, so that etymological lexicons for differ-
ent languages are very likely to complement each
other. RDF provides the means to represent the
cross-language linking using a uniform formalism,
and subsequently, to facilitate information aggre-
gation over multiple etymological lexicons as well
as language-specific lexical resources.
We converted the K?obler lexicons to RDF in
conformance to the Lemon model (McCrae et
al., 2011), an LMF-based vocabulary to repre-
sent machine-readable lexicons by using Semantic
Web standards. This conversion followed the three
main objectives:
(i) linkability: XML-based query languages
such as XQuery and XPath, used to create the user
interface to the lexicons, limit our lexicon to a
tree-structure representation. However, as our lex-
icons complement each other, it would be desir-
able to provide explicit cross-references between
these entries, and to allow them to be queried
jointly. Within the RDF data model, the relations
within and beyond a single lexicon can be repre-
sented and queried with equal ease, surmounting
constraint imposed by XML.
(ii) interoperability: Instead of resource-
specific abbreviations for languages and gram-
matical categories, we represent linguistic
information and meta data by reference to
community-maintained vocabularies publicly
available as part of the (Linguistic) Linked Open
Data cloud, namely lexvo (de Melo, to appear,
ISO 639-3 language codes), Glottolog (Nordhoff
and Hammarstr?om, 2011, language families) and
OLiA (Chiarcos, 2008, linguistic categories).
Reusing vocabularies shared among many parties
over the Web of Data has the advantage that
resources dealing with related phenomena in
the same language can be easily identified and
their information integrated without additional
conversion steps.
(iii) inference: The original lexicons were dis-
tributed in individual PDF files, and the XML rep-
resentation was created as a faithful representation
of their content, augmented with markup for rele-
vant linguistic features. These files, however, pro-
vided complementary information, so that, say, a
lexicon entry in the OS dictionary provided a ref-
erence to an etymological corresponding OHG en-
try, but this reference was not found in the OHG
dictionary. Such gaps can be easily detected (and
filled) through symmetric closure in the RDF data
model.
The results of this conversion are summarized in
Tab. 3. In the original XML (first row), every en-
try corresponds to a lemma of the language under
consideration, with different etymologies (and/or
senses) being associated with it. In RDF (second
row), each of these homographs (together with its
definition number) is defined as a lemon:Word
with a homography relation with the homograph
set (represented by a lemon:Word without defi-
nition number). The number of lemon:Words
is thus slightly higher than the number of en-
tries in the original dictionaries. Differently from
the XML, however, information from different
data sets can be easily aggregated, and triples
originating from one document can be comple-
mented with triples from another, shown here for
the symmetric closure of etymological relations
(third row) that can be easily generated using a
simple SPARQL pattern like CONSTRUCT { ?o
?p ?s } WHERE {?s ?p ?o}. The last row
shows links to other data sets from the (Linguis-
tic) Linked Open Data cloud. Most original en-
tries were complemented with grammatical infor-
mation using different (and not fully consistent)
abbreviations. For the most frequent abbrevia-
tions used, a link to the corresponding OLiA con-
cept was generated. These definitions are thus
interoperable beyond these lexicons and can be
compared, e.g., with those of lexical-semantic re-
sources for Modern German and English as com-
piled in (Eckle-Kohler et al., to appear). Similarly,
language abbreviations were mapped to ISO 639-
3 codes (in lexvo), or, where these were not avail-
able, to Glottolog. Even though the number of data
in historical languages is constantly increasing and
there is a demand for fine-grained language codes
for them, neither of the aforementioned resources
provide such codes. So we had to use a link to the
corresponding language family instead.
25
language period scheme corpus reference
English
Modern PTB (Taylor et al., 2003a; Kroch et al., 2010)
Early Mod. PPCEME (Kroch et al., 2004)
Middle PPME2 (Kroch and Taylor, 2000)
Old
YCOE (Taylor et al., 2003b)
PROIEL (Taylor et al., 2003b)
High German
Modern STTS (Schiller et al., 1999)
Early Mod. PCENHG (Light, 2013)
Old
Sect. 2.2
T-CODEX (Petrova et al., 2009)
Dutch Modern Alpino (Bouma et al., 2001)
Old Norse Menota (Haugen et al., 2008)
Danish Modern EAGLES (Leech and Wilson, 1996)
Swedish Modern Mamba (Nivre et al., 2006)
Icelandic IcePaHC (R?ognvaldsson et al., 2012)
Gothic PROIEL (Haug and J?hndal, 2008)
(a) Morphosyntactic annotations
language period scheme corpus reference
English
Modern
PTB (Taylor et al., 2003a; Kroch et al., 2010)
Stanford deps (De Marneffe and Manning, 2008)
Penn2Malt deps (Johansson and Nugues, 2007)
Early Mod. PPCEME (Kroch et al., 2004)
Middle PPME2 (Kroch and Taylor, 2000)
Old
YCOE (Taylor et al., 2003b)
PROIEL (Taylor et al., 2003b)
High German
Modern
TIGER (Brants et al., 2004)
T?uba-D/Z (Telljohann et al., 2003)
NEGRA (Skut et al., 1997)
Early Mod. PCENHG (Light, 2013)
Dutch Modern Alpino (Bouma et al., 2001)
Swedish Modern Mamba (Nivre et al., 2006)
Icelandic IcePaHC (R?ognvaldsson et al., 2012)
Gothic PROIEL (Haug and J?hndal, 2008)
(b) Syntactic annotations
Table 4: List of annotation schemes represented as OWL2/DL ontologies and relevant Germanic corpora
4 NLP methods applied
We sketch selected NLP applications developed on
the data described before, the automated phrase-
level alignment of quasi-parallel text, and two
experiments on annotation projection on parallel
text. All of these experiments are still in a rela-
tively early stage.
4.1 Automated phrase-level alignment of
quasi-parallel text
The needs of historical lingustics demand a more
fine-grained alignment than the currently avail-
able thematical alignment of Heliand with Ta-
tian and the gospels. We thus investigate parallel
phrase detection between Heliand (OS) and Tatian
(OHG), resp., Heliand and the West Saxon gospels
(OE).
To identify cognate phrases, we explore 6 types
of similarity metrics ?(w
OS
, w
OHG
) for every OS
word w
OS
and its potential OHG cognate w
OHG
.
1. geometry ?
g
= difference between the relative
positions of w
OS
and w
OHG
.
2. identity ?
i
(w
OS
, w
OHG
) = 1 iff w
OHG
=
w
OS
(0 otherwise)
3. lexicon ?
lex
(w
OS
, w
OHG
) = 1 iff w
OHG
?
W (0 otherwise) where W is a set of possible
OHG translations for w
OS
suggested by a lexicon,
i.e., either
direct etymological link in (the symmetric
closure of) the etymological dictionaries, or
indirect shared German gloss in the etymo-
logical dictionaries
4. orthography similarity measure based on
character replacement likelihood:
relative Levenshtein similarity
?
lev
(w
OS
, w
OHG
) = 1 ?
ld
|w
OS
|+|w
OHG
|
where ld is the standard Levenstein distance
and |w
OS
| and |w
OHG
| are the number of
characters in each word.
statistical character replacement probability
as approximated by a character-based statisti-
cal machine translation system (Neubig et al.,
2012)
5. normalization ?
norm
(w
OS
, w
OHG
) =
?
i
(w
?
OS
, w
OHG
) , with w
?
OS
being the OHG ?nor-
malization? of the original w
OS
. Here, normaliza-
tion uses a weighted Levenshtein distance and a
fixed list of OHG target words (Bollmann et al.,
2011).
6. cooccurrences ?
p
(w
OS
, w
OHG
) =
P (w
OS
|w
OHG
)P (w
OHG
|w
OS
), calculated
on thematically aligned sections from both texts.
For any two thematically aligned OS and OHG
word vectors, we thus span up a similarity ma-
trix between both word vectors on the basis of
these metrics. On the matrices, different opera-
tions can be applied to calculate similarity derived
metrics, including point-wise multiplication or ad-
dition, thresholds and a smoothing operator, that
aligns words due to the similarity of its neighbors.
The resulting matrix is then decoded by a greedy
algorithm that aligns the words with the highest
score, and then iterates for the remaining words.
At the moment, we provide a graphical interface
over a webpage that allows a philologist to dynam-
26
ically define an alignment function and that pro-
vides a graphical visualization of the result. Dur-
ing a partial qualitative evaluation a historical lin-
guist was asked to compare the results of align-
ment based on various metrics applied to a small
text passage. He took into consideration the over-
all match of the topic of the aligned passages as
well as the number of parallel passages that the
metrics failed to align. Eventually, it was indi-
cated that the best results can be achieved by com-
bining multiple metrics. A combination of either
direct lexicon-based or normalization-based align-
ment and geometrical alignment appears to be par-
ticularly promising. Yet, systematic experiments
to automatically explore this feature space are still
being prepared and depend on the availability of a
gold alignment for selected verses.
4.2 Projecting dependency relations
As shown in Tab. 1, we only possess shallow syn-
tactic annotations of OHG (and OS) text. We are
thus particularly interested in establishing richer
syntactic annotations. A challenging aspect in this
respect is the limited availability of parallel train-
ing data for historical language stages. However,
due to diachronic relatedness, we may expect that
syntactic patterns of Old Germanic languages are
preserved in their modern descendants. Such an
approach requires a consistent hyperlemmatiza-
tion, e.g., against a modern language
We tested this idea on Bible texts from four cor-
pora with closely related annotation schemes for
syntax (Tab. 1, corpora with CS-syntax): Icelandic
(IS), Early Modern High German (DE), Mid-
dle English (ME) and Old English (OE). These
schemes originate in the Penn Treebank scheme
(Taylor et al., 2003a), and we thus parsed a mod-
ern English Bible with a parser trained on the Penn
Treebank. As older Germanic languages are char-
acterized by a higher degree of word order flexi-
bility than Modern English, we converted histor-
ical and modern annotations to dependency rela-
tions using standard tools for this task (Johans-
son and Nugues, 2007). Word-alignment was ob-
tained with GIZA++ and 1:1 alignment was en-
forced using the translation table. Then, we pro-
jected dependency relations and the English words
as hyperlemmas for the historical texts. The his-
torical texts had comparable POS annotation that
was only slightly normalized across the corpora as
it preserved more morphological information than
Modern English POS tags.
On these projections, a fragment-aware parser
was trained using the English (hyper)lemmas and
the original POS tags (Spreyer and Kuhn, 2009).
We limited the amount of parallel data available to
a training set of 437 sentences per language and a
test set of 174 per language. Our hypothesis was
that in this setting, (projected) training data from
related languages can be used in place of train-
ing data for the language under consideration, if
the amount of data is sufficient and the languages
are sufficiently closely related. Furthermore, we
assumed that with an increasing number of lan-
guages considered (and thus training set size), the
quality of the projected annotations would contin-
uously improve as long as the languages are suffi-
ciently closely related.
For evaluation, we employed the unlabeled at-
tachment score (UAS) (Collins et al., 1999) on
the test data and compared with the (dependency
version of) the original annotation in these cor-
pora. Tab. 5 compares the performance of a
parser trained on target language data with parsers
trained on (hyperlemmatized) related languages.
The scores in the second column are the baseline
UAS where the parser was applied to the same
language as it was trained on. The third column
shows the difference with the parser applied to a
language but trained on projections into another
language. The fourth and the fifth column pro-
vides the results of the parser trained on one or
two additional related languages respectively.
The results showed that, among the West Ger-
manic languages (but not IS), a parser trained
on two or more related languages can reach the
same performance or even outperforms a parser
trained on the target language. Furthermore, a
parser trained on (projected) annotations from two
or more related languages is likely to outperform
a parser trained on a single related language. Ac-
cordingly, in absence of parallel texts for the target
language, the parser can be successfully trained on
annotation projections from two or more related
languages. It should be noted, however, that the
overall performance of the parser was relatively
poor. This may be, however, an artifact of the great
grammatical divergency between Modern English
(and, to a limited degree, ME: reduced morphol-
ogy, strict word order) and older Germanic lan-
guages (rich morphology, flexible word order).
Subsequent experiments will thus address the
27
inclusion of richer morphological features, projec-
tions from other languages and evaluation against
another set of dependency (DS) annotations for
Gothic and Old English (Tab. 1), for which related
annotation schemes for Latin, Greek and Czech
are available ? all of these languages are charac-
terized by rich morphology and flexible syntax.
on on related languages
Tgt Tgt Best monoling. Best biling. Triling.
lang. model ?UAS model ?UAS model ?UAS
DE .41 IS +.02
n.s.
+ME +.05
?
+OE +.04
??
IS .32 ME ?.06
???
+DE ?.03
n.s.
+OE ?.04
?
ME .60 IS ?.04
???
+OE ?.01
n.s.
+DE ?.02
n.s.
OE .30 ME .00
n.s.
+IS .00
n.s.
+DE .00
n.s.
Table 5: Performance of parsing models (UAS dif-
ference vs. 2nd col. with ?
2
:
?
p < .05,
??
p < .01,
???
p < .005)
4.3 Harmonization of grammatical features
Another line of studies addresses the projection of
grammatical features as represented in POS tags
and dependency labels. Unfortunately, modern
and historical language stages are annotated ac-
cording to a great variety of annotation schemes
which can not be trivially mapped to a general-
ization without substantial loss of information (as,
e.g., in the approach by Petrov et al., 2012). For
processing of multilingual corpora the problem of
heteroginity of linguistic annotations is very acute.
Above, we described an experiment that used PTB
style annotations only. This limitation was im-
posed by the annotation schema of the target cor-
pora that had PTB style syntactic annotations.
We thus follow Chiarcos (2008) and represent
the most relevant Germanic annotation schemes
as OWL2/DL ontologies, and link these to an
overarching Reference Model. Unlike a tagset,
whose string-based annotations require disjoint
categories at a fixed level of granularity, this
ontology-based approach allows to decompose the
semantics of annotations and consider all aspects
independently. For example, a tagger may cor-
rectly identify plural agreement but incorrectly as-
sume that it pertains a noun, as in the Penn Tree-
bank tag NNS. In the original tagset, a correspond-
ing tag for, say, adjectives, does not exist, but us-
ing the ontology, a plural adjective could neverthe-
less be represented in the form of different RDF
triples. With lexicon data being available in RDF
and linked to the OLiA Reference Model, as well
(Sect. 3), the incorrect word class can be spot-
ted, and corrected, but the agreement information
could remain unaffected.
These annotations have also been successfully
employed in ensemble combination architectures,
where information from different sources (say,
NLP tools) was integrated on the basis of the
Reference Model and disambiguated using onto-
logical axioms (Chiarcos, 2010; Pareja-Lora and
Aguado de Cea, 2010). In an annotation pro-
jection scenario, these sources could be projec-
tions from different languages annotated accord-
ing to different schemes, e.g., German, English,
Swedish or Latin. These experiments are currently
being conducted, but Annotation Models for sev-
eral schemes are already available (Tab. 4).
5 Digital Humanities
Our ultimate goal is to facilitate studies of histori-
cal and empirical linguists and philologists.
One research question under consideration is
whether the Heliand influenced Luther (Price,
2012), who, apparently, possessed one copy.
Based on a thorough comparison of thematically
aligned passages, evidence for or against this hy-
pothesis may be gathered, and this investigation
can be simplified by limiting the search to parallel
phrases automatically identified (Sect. 4.1).
Another research question pertains to divergen-
cies between, e.g., OHG texts and their Latin
source. As most OHG material is translated in a
literal fashion, and the word order was relatively
flexible, the OHG syntax may have been adjusted
to mirror the Latin original. Research of OHG
syntax thus concentrates on passages where OHG
syntax differs from the Latin source (Hinterh?olzl
and Petrova, 2009).
Different types of divergencies have been iden-
tified by qualitative research. Early translations
unlike modern ones tend to be very literal, of-
ten not being only word by word translation but
also preserving the syntax of the original. Nev-
ertheless, due to strong grammatical differences
between two languages, various divergencies on
(morpho)syntactic and lexical levels were un-
avoidable. Such, the transition from the Latin syn-
thetic to OHG analytic wordforms in case of the
deponent verbs is systematically observed. Also
the changes of the word position as well as miss-
ing a word in translation or adding a word that is
not present in the Latin original can be frequently
found. Such divergencies can be often explained
28
by stylistic or pragmatic reasons as well as by per-
sonal preferences of the translator.
This line of research is currently supported
through automated word-level alignment between
the OHG and Latin versions of Tatian. We built
a parallel corpus using GIZA++ and used the
TreeAligner (Lundborg et al., 2007) for search and
evaluation. On this basis, a philological compari-
son of OHG Tatian and its Latin source is being
conducted. More helpful, however, would be a
comparison of different syntactic patterns in OHG
and Latin which motivates our experiments in an-
notation projection (Sect. 4.2).
Finally, our experiments in the ontology-based
harmonization of different annotation schemes
(Sect. 4.3) will facilitate subsequent typological
and linguistic comparison across corpora with
manual annotations for syntax and/or morphology
according to different schemes.
6 Summary
We sketched major research directions on the de-
velopment of resources, NLP tools and algorithms
to facilitate the study Old Germanic languages
currently pursued at the Goethe-University Frank-
furt in the context of two related research initia-
tives, the LOEWE cluster ?Digital Humanities?
and the project ?Old German Reference corpus?.
Our efforts resulted in the creation of the fol-
lowing resources:
? a massive parallel corpus of TEI-
conformant Bibles including all con-
temporary Germanic languages as well as
early stages of Germanic languages (Sect.
2.1).
? an exhaustive, morphosyntactically anno-
tated corpus of OHG and OS with mor-
phosyntactic annotations. Annotations were
automatically derived from glossaries and
manually refined (Sect. 2.2).
? an index providing a thematical alignment
of the four gospels with each other as well as
with OHG and OS gospel harmonies (Sect.
2.3). This high quality alignment provides a
solid basis for further more fine-grained au-
tomatic alignment (Sect. 4.1).
? XML versions of lexical resources, includ-
ing etymological dictionaries of Old Ger-
manic languages (Sect. 3)
? an RDF-based linked etymological
database of Old Germanic languages
compiled from the latter (Sect. 3)
? a Linked Data representation of annotation
schemes for corpora, NLP tools and gram-
matical features in the linked lexicon data
(Sect. 3, 4.3)
The resources created provide an excellent test-
bed for various NLP algorithms, particularly for
experiments on alignment and annotation projec-
tion techniques: We developed different metrics
for quasi-parallel alignment applied to the cor-
pus of gospel harmonies (Sect. 4.1). For subse-
quent analysis, evaluation and refinement by his-
torical linguists, we provide a graphical visualiza-
tion and user interface in a form of a webpage.
This is an on-going project and further research
will aim at refining metrics and their combination.
Our massive parallel corpus is a perfect prereq-
uisite for annotation projection (Sect. 4.2). Our
experiments on annotation projections and cross-
lingual parser adaptation showed that it is possible
to use (hyperlemmatized) training data from mul-
tiple closely related languages in place of training
data for the language under consideration, and on
small sets of parallel training data available, this
did not lead to a significant loss of performance.
The only exception in the experiment (IS) is also
most remote from the other languages considered.
A severe limitation of this experiment was that
it required operating on (variants of) the same an-
notation scheme. Another line of our research is
focused on researching of ways to surmount such
restrictions. We thus adopt a modular approach
with annotation schemes linked to the OLiA Ref-
erence Model to harmonize annotations and gram-
matical features from lexicons (Sect. 4.3).
Finally, applications of these algorithms and re-
sources in research questions in philology, histor-
ical linguistics and comparative linguistics were
sketched in Sect. 5.
While most resources described in this pa-
per have been developed for several years at the
Goethe-University Frankfurt, the increased focus
on NLP and Linked Data represent novel develop-
ments pursued by the newly established Applied
Computational Linguistics Lab at the Goethe Uni-
versity Frankfurt. Different aspects of research
sketched in this paper thus describe on-going ac-
tivities at different degrees of completion.
29
Acknowledgements
The research of Christian Chiarcos, Maria
Sukhareva, Tim Price, Gaye Detmold, and Jens
Chobotsky described in this paper was supported
by the research cluster ?Digital Humanities? at the
Goethe-University Frankfurt, funded through the
LOEWE programme of the federal state of Hes-
sia. The research of Roland Mittmann was con-
ducted in the project ?Old German Reference cor-
pus?, funded by the Deutsche Forschungsgemein-
schaft (DFG).
References
Christian Bizer, Tom Heath, and Tim Berners-Lee.
2009. Linked Data ? The story so far. International
Journal on Semantic Web and Information Systems
(IJSWIS), 5(3):1?22.
Marcel Bollmann, Florian Petran, and Stefanie Dip-
per. 2011. Rule-based normalization of historical
texts. In Proceedings of the Workshop on Language
Technologies for Digital Humanities and Cultural
Heritage (LaTeCH-2011), pages 34?42, Hissar, Bul-
garia, September.
Gosse Bouma, Gertjan Van Noord, and Robert Malouf.
2001. Alpino: Wide-coverage computational analy-
sis of Dutch. Language and Computers, 37(1):45?
59.
Sabine Brants, Stefanie Dipper, Peter Eisenberg, Sil-
via Hansen-Schirra, Esther K?onig, Wolfgang Lezius,
Christian Rohrer, George Smith, and Hans Uszkor-
eit. 2004. Tiger: Linguistic interpretation of a ger-
man corpus. Research on Language and Computa-
tion, 2(4):597?620.
Christian Chiarcos. 2008. An ontology of linguistic
annotations. LDV Forum, 23(1):1?16.
Christian Chiarcos. 2010. Towards robust multi-tool
tagging. An OWL/DL-based approach. In Proc. of
the 48th Annual Meeting of the Association for Com-
putational Linguistics (ACL-2010), pages 659?670,
Uppsala, Sweden.
Michael Collins, Lance Ramshaw, Jan Haji?c, and
Christoph Tillmann. 1999. A statistical parser for
Czech. In Proc. of the 37th Annual Meeting of the
Association for Computational Linguistics (ACL-
1999), pages 505?512, Maryland, June.
Marie-Catherine De Marneffe and Christopher D Man-
ning. 2008. The Stanford typed dependencies rep-
resentation. In Proceedings of the COLING-2008
Workshop on Cross-Framework and Cross-Domain
Parser Evaluation, pages 1?8.
Gerard de Melo. to appear. Lexvo.org: Language-
related information for the linguistic linked data
cloud. Semantic Web Journal, pages 1?7.
Judith Eckle-Kohler, John McCrae, and Christian
Chiarcos. to appear. lemonUby ? A large, in-
terlinked, syntactically-rich resource for ontologies.
Semantic Web Journal: Multilingual Linked Open
Data.
Jost Gippert. 2011. The TITUS Project. 25 years
of corpus building in ancient languages. In Per-
spektiven einer corpusbasierten historischen Lin-
guistik und Philologie. Internationale Tagung des
Akademienvorhabens ?Alt?agyptisches W?orterbuch?
an der Berlin-Brandenburgischen Akademie der
Wissenschaften, pages 169?192, Berlin, December.
Dag TT Haug and Marius J?hndal. 2008. Creat-
ing a parallel treebank of the old Indo-European
bible translations. In Proceedings of the Language
Technology for Cultural Heritage Data Workshop
(LaTeCH 2008), pages 27?34, Marrakech, Morocco,
June.
Odd Einar Haugen, Tone Merete Bruvik, Matthew
Driscoll, Karl G Johansson, Rune Kyrkjeb?, and
Tarrin Wills. 2008. The Menota handbook: Guide-
lines for the electronic encoding of Medieval Nordic
primary sources.
Roland Hinterh?olzl and Svetlana Petrova. 2009. In-
formation Structure and Language Change: New
Approaches to Word Order Variation in Germanic.
Mouton de Gruyter.
Richard Johansson and Pierre Nugues. 2007. Ex-
tended constituent-to-dependency conversion for
English. In Proceedings of the 16th Nordic Con-
ference on Computational Linguistics (NoDaLiDa-
2007), pages 105?112, Tartu, Estonia, May.
Anthony Kroch and Ann Taylor. 2000. The
Penn-Helsinki Parsed Corpus of Middle English
(PPCME2). Department of Linguistics, University
of Pennsylvania. CD-ROM.
Anthony Kroch, Beatrice Santorini, and Lauren Delfs.
2004. The Penn-Helsinki Parsed Corpus of Early
Modern English (PPCEME). Department of Lin-
guistics, University of Pennsylvania. CD-ROM.
Anthony Kroch, Beatrice Santorini, and Ariel Diertani.
2010. The Penn-Helsinki Parsed Corpus of Modern
British English (PPCMBE). Department of Linguis-
tics, University of Pennsylvania. CD-ROM.
Geoffrey Leech and Andrew Wilson. 1996. EAGLES
guidelines: Recommendations for the morphosyn-
tactic annotation of corpora.
Caitlin Light. 2013. Parsed Corpus of Early
New High German (PCENHG), v. 0.5. Uni-
versity of Pennsylvania, http://enhgcorpus.
wikispaces.com/.
Sonja Linde and Roland Mittmann. 2013. Old German
Reference Corpus. Digitizing the knowledge of the
19th century. In Paul Bennett, Martin Durrell, Silke
30
Scheible, and Richard J. Whitt, editors, New Meth-
ods in Historical Corpus Linguistics = Korpuslin-
guistik und interdiziplinre Perspektiven auf Sprache
? Corpus linguistics and Interdisciplinary perspec-
tives on language (CLIP), volume 3 of Korpuslin-
guistik und interdiziplinre Perspektiven auf Sprache
? Corpus linguistics and Interdisciplinary perspec-
tives on language (CLIP), T?ubingen. Narr.
Joakim Lundborg, Torsten Marek, Ma?el Mettler, and
Martin Volk. 2007. Using the Stockholm
TreeAligner. In Proceedings of the 6th Workshop
on Treebanks and Linguistic Theories (TLT-2007),
pages 73?78.
John McCrae, Dennis Spohr, and Philipp Cimiano.
2011. Linking lexical resources and ontologies on
the semantic web with lemon. In The Semantic
Web: Research and Applications, pages 245?259.
Springer.
Roland Mittmann. 2013. Digitalisierung historischer
Glossare zur automatisierten Vorannotation von
Textkorpora am Beispiel des Altdeutschen. Journal
for Language Technology and Computational Lin-
guistics (JLCL), 27(2):39?52.
Graham Neubig, Taro Watanabe, Shinsuke Mori, and
Tatsuya Kawahara. 2012. Machine translation with-
out words through substring alignment. In Proc. of
the 50th Annual Meeting of the Association for Com-
putational Linguistics (ACL-2012), pages 165?174,
Jeju Island, Korea, July.
Joakim Nivre, Jens Nilsson, and Johan Hall. 2006. Tal-
banken05: A Swedish treebank with phrase struc-
ture and dependency annotation. In Proc. of the 5th
International Conference on Language Resources
and Evaluation (LREC-2006), pages 1392?1395.
Sebastian Nordhoff and Harald Hammarstr?om. 2011.
Glottolog/langdoc: Defining dialects, languages,
and language families as collections of resources. In
Proceedings of the First International Workshop on
Linked Science 2011 (LISC-2011).
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29(1):19?51.
Antonio Pareja-Lora and Guadalupe Aguado de Cea.
2010. Ontology-based interoperation of linguistic
tools for an improved lemma annotation in Span-
ish. In Proc. of the 6th International Conference on
Language Resources and Evaluation (LREC-2010),
Valetta, Malta, May.
Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012.
A universal part-of-speech tagset. In Proc. of the 8th
International Conference on Language Resources
and Evaluation (LREC-2012), pages 2089?2096, Is-
tanbul, Turkey.
Svetlana Petrova, Michael Solf, Julia Ritz, Christian
Chiarcos, and Amir Zeldes. 2009. Building and
using a richly annotated interlinear diachronic cor-
pus: The case of Old High German Tatian. TAL,
50(2):47?71.
Timothy Blaine Price. 2012. Multi-faceted alignment:
Toward automatic detection of textual similarity in
gospel-derived texts. In Proceedings of Historical
Corpora 2012, Frankfurt, Germany.
Philip Resnik, Mari Broman Olsen, and Mona Diab.
1997. Creating a parallel corpus from the book of
2000 tongues. In Proc. of the Text Encoding Initia-
tive 10th Anniversary User Conference (TEI-10).
Eir??kur R?ognvaldsson, Anton Karl Ingason, Einar Freyr
Sigurdsson, and Joel Wallenberg. 2012. The Ice-
landic Parsed Historical Corpus (IcePaHC). In Proc.
of the 8th International Conference on Language
Resources and Evaluation (LREC-2012), Istanbul,
Turkey, May.
Anne Schiller, Simone Teufel, Christine St?ockert, and
Christine Thielen. 1999. Guidelines f?ur das Tagging
deutscher Textcorpora mit STTS. Technical report,
Universit?aten Stuttgart und T?ubingen.
Wojciech Skut, Brigitte Krenn, Thorsten Brants, and
Hans Uszkoreit. 1997. An annotation scheme for
free word order languages. In Proc. of the 5th Con-
ference on Applied Natural Language Processing,
pages 88?95.
Kathrin Spreyer and Jonas Kuhn. 2009. Data-driven
dependency parsing of new languages using incom-
plete and noisy training data. In Proc. of the
13th Conference on Computational Natural Lan-
guage Learning (CoNLL-2009), pages 12?20, Boul-
der, CO, June.
Ann Taylor, Mitchell Marcus, and Beatrice Santorini.
2003a. The Penn Treebank: An overview. In Anne
Abeill, editor, Treebanks, pages 5?22. Springer,
Dordrecht.
Ann Taylor, Anthony Warner, Susan Pintzuk, and
Frank Beths. 2003b. The York-Toronto-Helsinki
parsed corpus of Old English prose.
Heike Telljohann, Erhard W Hinrichs, Sandra K?ubler,
Heike Zinsmeister, and Kathrin Beck. 2003. Style-
book for the T?ubingen treebank of written German
(T?uBa-D/Z). Technical report, Seminar f?ur Sprach-
wissenschaft, Universit?at T?ubingen, Germany.
31
Proceedings of the First Workshop on Applying NLP Tools to Similar Languages, Varieties and Dialects, pages 11?20,
Dublin, Ireland, August 23 2014.
Diachronic proximity vs. data sparsity in cross-lingual parser projection.
A case study on Germanic
Maria Sukhareva
Goethe University Frankfurt
sukharev@em.uni-frankfurt.de
Christian Chiarcos
Goethe University Frankfurt
chiarcos@em.uni-frankfurt.de
Abstract
For the study of historical language varieties, the sparsity of training data imposes immense prob-
lems on syntactic annotation and the development of NLP tools that automatize the process. In
this paper, we explore strategies to compensate the lack of training data by including data from
related varieties in a series of annotation projection experiments from English to four old Ger-
manic languages: On dependency syntax projected from English to one or multiple language(s),
we train a fragment-aware parser trained and apply it to the target language. For parser training,
we consider small datasets from the target language as a baseline, and compare it with models
trained on larger datasets from multiple varieties with different degrees of relatedness, thereby
balancing sparsity and diachronic proximity.
Our experiments show
(a) that including related language data to training data in the target language can improve
parsing performance,
(b) that a parser trained on data from two related languages (and none from the target language)
can reach a performance that is statistically not significantly worse than that of a parser
trained on the projections to the target language, and
(c) that both conclusions holds only among the three most closely related languages under
consideration, but not necessarily the fourth.
The experiments motivate the compilation of a larger parallel corpus of historical Germanic va-
rieties as a basis for subsequent studies.
1 Background and motivation
We describe an experiment on annotation projection (Yarowski and Ngai, 2001) between different Ger-
manic languages, resp., their historical varieties, with the goal to assess to what extent sparsity of parallel
data can be compensated by material from varieties related to the target variety, and studying the impact
of diachronic proximity onto such applications.
Statistical NLP of historical language data involves general issues typical for low-resource languages
(the lack of annotated corpora, data sparsity, etc.), but also very specific challenges such as lack of stan-
dardized orthography, unsystematized punctuation, and a considerable degree of morphological varia-
tion. At the same time, historical languages can be viewed as variants of their modern descendants rather
than entirely independent languages, a situation comparable to low-resource languages for which a di-
achronically related major language exists. Technologies for the cross-lingual adaptation of NLP tools or
training of NLP tools on multiple dialects or language stages are thus of practical relevance to not only
historical linguistics, but also to modern low-resource languages.
The final paper will be published under a Creative Commons Attribution 4.0 International Licence (CC-BY), http:
//creativecommons.org/licenses/by/4.0/.
11
in this context, historical language allows to study the impact of the parameter of diachronic related-
ness, as it can be adjusted relatively freely, e.g., by choosing dialects which common ancestor existed
just a few generations before rather than languages separated for centuries. A focused study of the im-
pact of diachronic relatedness on projected annotations requires sufficient amounts of parallel texts for
major language stages, and comparable annotations as a gold standard for evaluation. In this regard, the
Germanic languages provide us with a especially promising sandbox to develop such algorithms due to
the abundance of annotated corpora and NLP tools of the modern Germanic languages, most noteably
Modern English.
We employ annotation projection from EN to Middle English (ME), Old English (OE) and the less
closely related Early Modern High German (DE) and Middle Icelandic (IS) for which we possess com-
parable annotations, and test the following hypotheses:
(H1) Adding data from related varieties compensates the sparsity of target language training data.
(H2) Data from related languages compensates the lack of target language training data.
(H3) The greater the diachronic proximity, the better the performance of (H1) and (H2).
We test these hypotheses in the following setup: (1) Hyperlemmatization: Different historical variants
are normalized to a consistent standard, e.g., represented by a modern language (Bollmann et al., 2011).
We emulate hyperlemmatization by English glosses automatically obtained through SMT. (2) Projection:
We create training data for a fragment-aware dependency parser (Spreyer et al., 2010) using annotation
projection from modern English. (3) Combination and evaluation: Parser modules are trained on differ-
ent training data sets, and evaluated against existing gold annotations.
In our setting, we enforce data sparsity by using deliberately small training data sets. This is because
we emulate the situation of less-documented languages that will be in the focus of subsequent experi-
ments, namely, Old High German and Old Saxon, which are relatively poorly documented. We do hope,
however, that scalable NLP solutions can be developed if we add background information from their de-
scendants (Middle/Early Modern High German, Middle/Modern Low German), or closely related, and
better documented varieties (Old English, Middle Dutch).
Hence, the goal of our experiment is not to develop state-of-the-art parsers, but to detect statistically
significant differences in parsing performance. If these can be confirmed, this motivates creating a larger
corpus of parallel texts in Germanic languages as a basis for subsequent studies and more advanced,
projection-based technologies for older and under-resourced Germanic languages.
2 Languages and corpus data
We use parallel biblical texts in Old English (OE), Middle English (ME), Middle Icelandic (IS) and Early
Modern High German (DE). This selection is determined by the availability of syntactically annotated
corpora with closely related annotation schemes. As these schemes are derived from the Penn TreeBank
(PTB) bracketing guidelines (Taylor et al., 2003a), we decided to use Modern English (EN) as a source
for the projections.
The Germanic languages derive from Proto-Germanic as a common ancestor. OE and Old High
German separated in the 5th c. The antecessor of IS separated from this branch about 500 years earlier.
Among Germanic languages, great differences emerged, but most languages developed similarly towards
a loss of morphology and a more rigid syntax, a tendency particularly prevalent in EN.
As compared to this, OE had a relatively free OV word order, with grammatical roles conveyed through
morphological markers. The OE case marking system distinguished four cases, but eventually collapsed
during ME, resulting in a strict strict VO word order in EN (Trips, 2002; van Kemenade and Los, 2009;
Cummings, 2010).
Unlike EN, DE preserved four cases, and a relatively free word order (Ebert, 1976). A characteristic
of German are separable verb prefixes, leading to 1 : n mappings in the statistical alignment with EN.
12
Figure 1: Workflow
Unlike EN and DE, IS is a North Germanic language. It is assumed to be conservative, with relatively
free word order with both OV and VO patterns and a rich morphology that leads to many 1 : n alignments
with EN, e.g., for suffixed definite articles; we thus expect special challenges for annotation projection
under conditions with limited training data.
Different from the old languages, EN developed a rigid word order and a largely reduced morphol-
ogy. A direct adaptation of an existing English parser to (hyperlemmatized) OE, IS or DE is thus not
promising. Therefore, we employ an approach based on annotation projection.
The corpus data we used consists of parsed bible fragments from manually annotated corpora, mostly
the gospels of Matthew (Mt), Mark (Mr), John (J) and Luke (L), from which we drew a test set of 147
sentences and a training set of 437 sentences for every language.
ME and OE The Penn-Helsinki Parsed Corpus of Middle English (PPCME2)
1
and the York-Toronto-
Helsinki Parsed Corpus of Old English Prose (Taylor et al., 2003b, YCOE) use a variant of the PTB
annotation schema (Taylor et al., 2003a). YCOE contains the full West Saxon Gospel, but PPCME2
contains only a small fragment of a Wycliffite gospel of John, the ME data is thus complemented
with parts of Genesis (G) and Numbers (N).
IS The Icelandic Parsed Historical Corpus (R?ognvaldsson et al., 2012, IcePaHC) is annotated follow-
ing YCOE with slight modifications for specifics of IS. We use the gospel of John from Oddur
Gottsk?alksson?s New Testament, a direct translation from Luther.
DE The Parsed Corpus of Early New High German
2
contains three gospels from Luther?s Septembertes-
tament (1522). As an IcePaHC side-project, it adapts the IS annotation scheme.
EN For EN, we use the ESV Bible.
3
Due to a moderate number of archaisms, it is particularly well-
suited for automated annotation.
3 Experimental setup
We study the projection of dependency syntax, as it is considered particularly suitable for free word-order
languages like IS, OE and DE. The existing constituent annotations were thus converted with standard
tools for PTB conversion. Figure 1 summarizes the experimental setup.
For annotating EN, we created dependency versions of WSJ and Brown sections of the PTB with
the LTH Converter (Johansson and Nugues, 2007). We trained Malt 1.7.2 (Nivre, 2003), optimized its
features with MaltOptimizer (Ballesteros and Nivre, 2012), and parsed the EN bible using the resulting
feature model.
1
http://www.ling.upenn.edu/hist-corpora/PPCME2-RELEASE-3/index.html
2
http://enhgcorpus.wikispaces.com
3
http://esv.org
13
The ME, OE, DE and IS datasets were word aligned with EN using GIZA++ (Och and Ney, 2003).
1 : n alignments were resolved to the most probable 1 : 1 mapping. During annotation projection,
we assume that the aligned words represent the respective heads for the remaining n ? 1 words. These
dependent words are assigned the dependency relation FRAG to the word that got the highest score in
the translation table. This solution solves, among others, the problem of separable verb prefixes in DE,
for example, DE ruffen with prefix an would be aligned to English word call: As P (?call?|?an?) <
P (?call?|?ruffen?), the syntactic information of ?call? will be projected to ?ruffen? and ?an? will be
its dependent labeled with ?FRAG?. The projected dependency trees were checked on well-formedness,
sentences with cycles were dismissed from the data set.
We formed training sets containing 437 sentences for ME, OE, DE, IS. Monolingual data sets were
combined into bi-, tri- or quadrilingual training data sets with a simple concatenation, thereby creating
less sparse, but more heterogeneous training data sets. For every language, test data was taken from J,
174 sentences per language.
We used the projected dependencies to train fMalt (Spreyer et al., 2010), a fragment-aware dependency
parser, in order to maximize the gain of information from incomplete projections.
In our setting, fMalt used two features, POS and hyperlemmas.
POS The tagsets of the historical corpora originate in PTB, but show incompatible adaptations to the
native morphosyntax. Tagset extensions on grammatical case in OE, IS and DE were removed and
language-specific extensions for auxiliaries and modal verbs were leveled, in favor of a common,
but underspecified tagset for all four languages. As these generalized tags preserve information not
found in EN, they were fed into the parser.
(hyper-)lemma Lexicalization is utterly important for the dependency parsing (Kawahara and Uchi-
moto, 2007), but to generalize over specifics of historical language varieties, hyperlemmatization
needs to be performed. Similar to Zeman and Resnik (2008), we use projected English words as
hyperlemmas and feed them into the parser. Hyperlemmatization against a closely related languages
is acceptable as we can expect that the syntactic properties of words are likely to be similar.
The projected annotations were then evaluated against dependency annotations created analoguously to
the EN annotations from manual PTB-style constituency syntax. As LTH works exclusively on PTB
data, the historical corpora were converted with its antecessor Penn2Malt
4
using user-defined head-rules
(Yamada and Matsumoto, 2003).
4 Evaluation results
baseline ?UAS worst model ?UAS best model ?UAS
UAS +1 +2 +1 +2 +3
ME .60 +DE +.00
n.s.
+DE+IS -.01
n.s.
+OE +.01
n.s.
+OE+IS +.01
n.s.
-.00
n.s.
OE .31 +IS -.00
n.s.
+DE+IS -.02
n.s.
+DE +.02
n.s.
+ME+DE +.00
n.s.
+.02
n.s.
DE .41 +OE +.02
n.s.
+OE+IS +.03
?
+ME +.04
???
+ME+IS +.03
?
+.04
??
IS .32 +IS -.02
n.s.
+DE+OE -.02
n.s.
+ME +.00
n.s.
+ME+DE -.01
n.s.
-.04
??
(a) trained on target and related language(s)
baseline ?UAS worst model ?UAS best model ?UAS
UAS 1 2 1 2 3
ME .60 OE -.09
???
DE-IS -.01
n.s
IS -.05
???
IS+OE -.02
n.s.
-.02
n.s.
OE .31 DE -.03
?
ME-DE -.01
n.s.
ME -.02
n.s.
ME+IS -.01
n.s.
-.00
n.s.
DE .41 OE -.01
n.s.
OE-IS +.02
n.s.
IS +.02
n.s.
IS+ME +.05
???
+.04
??
IS .32 OE -.07
???
DE-OE -.02
n.s.
ME -.06
???
ME+DE -.02
n.s.
-.04
??
(b) trained on related language(s) alone
Table 1: Performance of best- and worst-performing parsing models (UAS diff. vs. baseline with ?
2
:
?
p < .05,
??
p < .01,
???
p < .005)
We evaluate the unlabeled attachment score (Collins et al., 1999, UAS), i.e., the proportion of tokens in
a sentence (without punctuation) that are assigned the correct head, on test sets of 174 sentences in each
language.
4
http://stp.lingfil.uu.se/ nivre/research/Penn2Malt.html
14
As a baseline for the evaluation we take the performance of the parser trained solely on the target
language data. As shown in Tab. 1 (second col.), the UAS scores mirror both the diachronic relatedness
(ME>DE>IS), as well as the relative loss of morphology (ME>DE>IS/OE), indicating that diachronic
relatedness may not be the only factor licensing the applicability of the annotation projection scenario
(H3). It is also important, though, to keep in mind that the OE and IS translations of the Bible had
considerable influence of Latin syntax, whereas DE and ME translations aimed for a language easy to
understand.
Table 1a gives the best and worst results for the unlabeled attachment score for the parser trained on
target and related language(s) (H1). With the exception of DE, we observed no significant differences in
UAS scores relative to the baseline. DE may benefit from ME because of its more flexible syntax (thus
closer to ME [and OE] than to Modern English), and from IS because of Luther?s direct influence on the
IS bible. That ME did not mutually benefit from German may be due to the good quality of ME annota-
tion projections (resulting from its proximity to EN). Parsers trained on trilingual and quadrilingual sets
exhibited no improvement over the bilingual sets. Taken together, we found no positive effect of using
additional training data from language stages diachronically separated for more than 500 years (e.g.,
OE/ME), but also, we did not find a negative effect among the West Germanic languages. If additional
training material is carefully chosen among particularly closely related varieties, however, the DE effect
can be replicated, and then, including related language data to training data in the target language can
improve parsing performance.
While in our setting, training data from related languages may (but does not have to) improve a parser
training if training data for the target language is available, it may very well be employed fruitfully if
no training data for the target language is available (H2): Table 1b shows that, unsurprisingly, parsers
trained only on one related language had the lowest performance in the experiment, so using multiple
train languages seems to compensate language-specific idiosyncrasies. The best-performing parsing
models trained on two or more related languages achieved a performance not significantly worse (if not
better) than models being trained on target language data. This effect extends to all languages except
for IS and indicates that a careful choice of additional training data from related varieties may facilitate
annotation projection. Equally important (and valid across all languages) is that none of the models
trained on one language outperformed any of the model trained on two languages. Using training data
from two related languages doesn?t seem to hurt performance in our setting. Adding a third language
did not yield systematic improvements, the scores for trilingual models are in the range of the bilingual
models.
Again, DE is exceptionally good, benefitting from being a direct source of the IS translation as well as
structurally comparable to ME. In both settings, the worst-performing language is IS, with a significant
drop in annotation projection quality with Western Germanic material added, indicating that diachronic
distance between Northern and Western Germanic languages limits the applicability of (H2), thereby
supporting (H3).
Taken together, our results indicate
1. a significant positive effect for the Western Germanic languages (ME, OE, DE) for (H2), and
2. a significant negative effect for Western and Northern Germanic languages (IS) for (H2)
As a tentative hypothesis, one may speculate that languages separated for 1000 years (OE-IS) or more
are too remote from each other to provide helpful background information, but that languages separated
within the last 750 years (ME-DE) or less are still sufficiently close. This novel assumption may provide
a guideline for future efforts to project annotations among related languages, and is thus of immense
practical relevance for developing future NLP tools for historical and less-resourced language varieties.
Ultimately, one may formulate rules of best practice like the following:
? If no syntactic annotations for a target language are available, annotation projection among closely
related languages may be a solution. Even with limited amounts of parallel data, diachronic dis-
tances of more than 500 years can be successfully bridged (EN/ME, baseline).
15
? If no syntactic annotations for a target language are available, a parser trained on hyperlemmatized
corpora in two languages may yield a performance comparable to a parser trained on small amounts
of target data. A parser trained on hyperlemmatized monolingual data may be significantly worse
(H2).
? The sparsity of parallel text to conduct annotation projection and train a (hyperlemmatized) parser
can only be compensated by adding parallel data from one related language if these are closely
diachronically related (with a separation being less than, say, 500 years ago) and at a similar de-
velopmental stage (DE/ME, H1). Adding data from multiple, equally remote languages does not
necessarily improve the results further.
At the current state, such recommendations would be premature, they require deeper investigation, but
with the confirmation of (H2) and (H3), we can now motivate larger-scale efforts to compile a massive
parallel corpus of historical Germanic language varieties as a basis for subsequent studies. Initial steps
towards this goal are described in the following section.
5 Towards a massive parallel corpus of historical Germanic languages
With the long-term goal to systematically assess the impact of the factor of diachronic proximity, we
focus on annotation projection among the Germanic languages as test field. The Germanic languages
represent a particularly well-resourced, well-documented and well-studied language family which devel-
opment during the last 1800 years is not only well-explored, but also documented with great amounts
of (parallel) data, ranging from the 4th century Gothic bible over a wealth of Bible translations since
the middle ages to the modern age of communication with its abundance of textual resources for even
marginal varieties. Motivated from our experiment, we thus began to compile a parallel corpus of his-
torical and dialectal Germanic language varieties. Primary source data for a massive parallel corpus of
historical varieties of any European language is mostly to be drawn from the Bible and related literature.
The Bible is the single most translated book in the world and available in a vast majority of world lan-
guages. It is also often the case that there are several biblical translation existing for a language. Bible
data also represents the majority of parallel data available for historical Germanic languages, and for the
case of OS and OHG, gospel harmonies represent even the majority of data currently known. Beyond
this, the corpus includes Bible excerpts and paraphrases from all Germanic languages and their major
historical stages.
Tab. 2 gives an overview over the current status of the Parallel Bible Corpus. At the moment, 271 texts
with about 38.4M tokens have been processed, converted from their original format and verse-aligned
according to their original markup or with a lexicon-supported geometric sentence aligner (T?oth et al.,
2008). In the table, ?text? means any document ranging from a small excerpt such as the Lord?s Prayer
(despite their marginal size valuable to develop algorithms for normalization/[hyper]lemmatization) over
gospel harmonies and paraphrases to the entire bible that has been successfully aligned with Bible verses.
The compiled corpus, excerpts and fragments for all Germanic languages marked up with IDs for verses,
chapters and books. For data representation, we employed an XML version of the CES-scheme de-
veloped by Resnik et al. (1997). Having outgrown the scale of Resnik?s earlier project by far, we are
currently in transition to TEI P5.
As it is compiled from different sources, the corpus cannot be released under a free or an academic
license. It contains material without explicit copyright statement, with proprietary content (e.g., from
existing corpora), or available for personal use only. Instead, we plan to share the extraction and con-
version scripts we used. For the experiments we aim to prepare, we focus on primary data, the texts in
this collection are not annotated. Where annotations are available from other corpora or can be produced
with existing tools, however, these annotated versions will be aligned with the Bibles and included in
subsequent experiments.
16
after 1800- 1600- 1400- 1100- before
1900 1900 1800 1600 1400 1100
West Germanic
English 2 2 2 6 3 (+2) 1
Pidgin/Creol 2
Scots (6) (1)
Frisian 2 (+8) (12)
Dutch 4 1 5 (1)
L. Franconian (47) (21)
Afrikaans 3
German 3 1 (19) 1 (+4) 1 (+1) 1
dialects 3 (+2)
Yiddish 1
Low German 3 (+18) (66) (2) 1
Plautdietsch 2
Danish 1 North & East Germanic
Swedish 3 (3) (1)
Bokm?al 2
Nynorsk 2
Icelandic 1 1
Faroese 1
Norn (2)
Gothic 1
tokens 21.8M 3.2M 2.7M 9.2M 1.2M 0.2M
Table 2: Verse-aligned texts in the Germanic parallel Bible corpus (parentheses indicate marginal frag-
ments with less than 50,000 tokens)
6 Summary and outlook
This paper describes a motivational experiment on annotation projection, or more precisely, strategies
to compensate data sparsity (the lack of parallel data) with material from related, but heterogeneous
varieties to facilitate cross-language parser adaptation for low-resource historical languages. We used a
fragment-aware dependency parser trained on annotation projections from ESV Bible to four historical
languages.
Our results indicate a lexicalized fragment-aware parser trained on a small amount of annotation pro-
jections can yield good results on closely related languages. In a situation of the absence of training
data for the target language (or, for example, in the situation where there is no parallel corpora for the
target language), a hyperlemmatized parser trained on (projected) annotations from two or more related
languages is likely to outperform a parser trained on a single related language.
We achieved statistically significant differences in parser performance trained on (a) target language
data, and (b) target language and data from related varieties, resp. (c) data from related varieties only.
These indicate that closely related languages (say, with a common ancestor about 750 years ago, such as
DE and ME) have some potential to compensate sparsity of parallel data in the target variety, wheres this
potential does not seem to exist for more remotely related languages (say, with a common ancestor more
than 1000 years ago such as OE and IS).
The experimental results revealed that the parser performance can, indeed, be improved by means of
including a related language to the training data, but we had a significant effect for only one language
under consideration, indicating that the diachronic proximity of the languages considered was possibly
too large, and thereby motivating subsequent experiments, and in particular, the creation of a larger
parallel corpus of historical Germanic language varieties. We described initial steps in the compilation
of this corpus.
Our experiment raises a number of open issues that are to be pursued in subsequent studies:
1. Our setup has a clear bias towards English (in the annotation schemes used and the source annota-
tions), and parser performance was strongly affected by the syntactic difference between the target
language and Modern English from which the syntactic dependencies were projected, indicating the
relevance of diachronic relatedness as well as the developmental state of a related language. Sub-
sequent experiments will hence address the inclusion of richer morphological features, projection
from other languages and evaluation against syntactic annotations according to other schemes not
derived from the Penn Treebank, as currently available, for example, for Old High German, Old
Norse, and Gothic.
17
2. The hyperlemmatization in our approach was achieved through alignment/SMT, and a similar
lexically-oriented approach has been suggested by (Zeman and Resnik, 2008). Alternative strate-
gies more suitable for scenarios with limited amounts of training data may include the use of ortho-
graphical normalization techniques (Bollmann et al., 2011) or substring-based machine translation
(Neubig et al., 2012) and are also subject to on-going research. We assume that SMT-based hyper-
lemmatization introduces more noise than these strategies, so that it is harder to achieve statistically
significant results. Our findings are thus likely to remain valid regardless of the hyperlemmatization
strategy. This hypothesis is, however, yet to be confirmed in subsequent studies.
3. Our experiment mostly deals with data translated from (or at least informed by) the Latin Vulgate.
Our data may be biased by translation strategies which evolved over time, from very literal trans-
lations (actually, glossings) of Latin texts in the early middle ages to Reformation-time translations
aiming to grasp the intended meaning rather than to preserve the original formulation. A focus on
classical languages is, however, inherent to the parallel material in our domain. A representative
investigation of annotation projection techniques thus requires the consideration of quasi-parallel
data along with parallel data. This can be found in the great wealth of medieval religious literature,
with Bible paraphrases, gospel harmonies, sermons and homilies as well as poetic and prose adap-
tations of biblical motives. The parallel corpus of Germanic languages thus needs to be extended
accordingly.
4. One may wonder how the annotation projection approach performs in comparison to direct applica-
tions of modern language NLP tools to normalized historical data language (Scheible et al., 2011).
While it is unlikely that such an approach could scale beyond closely related varieties, success-
ful experiments on the annotation of normalized historical language have been reported, although
mostly focused on token-level annotations (POS, lemma, morphology) of language stages which
syntax does not greatly deviate from modern rules (Rayson et al., 2007; Pennacchiotti and Zan-
zotto, 2008; Kestemont et al., 2010; Bollmann, 2013). For the annotation of more remotely related
varieties with more drastic differences in word order rigidity or morphology as considered here,
however, projection techniques are more promising as they have been successfully applied to un-
related languages, as well, but still benefit from diachronic proximity, cf. Meyer (2011) for the
projection-based morphological analysis of Modern and Old Russian.
The goal of our experiment was not to achieve state-of-the-art performance, but to show whether back-
ground material from related languages with different degrees of diachronic distance can help to com-
pensate data sparsity, in this case with an experiment on annotation projection. This hypothesis could be
confirmed and we found effects that ? even on the minimal amounts of data considered for this study ?
indicated statistically significant improvements.
It is thus to be expected that even greater improvements can be achieved by considering more closely
related pairs of languages, with greater amounts of data. The further exploration of this hypothesis is
the driving force behind our efforts to compile a massive corpus of parallel and quasi-parallel texts for
all major varieties of synchronic and historical Germanic languages. Algorithms successfully tested in
this context can be expected to be applicable to other scenarios in which, e.g., well-researched modern
languages may be employed to facilitate the creation of NLP tools for less-ressourced, related languages.
Our efforts are thus not specific to historical languages.
As the diachronic development and the diversification of the Germanic languages is well-documented
in this body of data, and the linguistic processes involved are well-researched, this data set represents an
extraordinarily valuable resource for philological and comparitve studies as well as Natural Language
Processing. In particular, we are interested in developing algorithms that explore and exploit the variable
degree of diachronic relatedness found between the languages in our sample. At the same time, we
cooperate with researchers from philology, historical and comparative linguistics, which research on
intertextuality, diachronic lexicology, phonology, morphology and syntax we aim to support with NLP
tools developed on the basis of this body of parallel text.
18
References
Miguel Ballesteros and Joakim Nivre. 2012. Maltoptimizer: A system for maltparser optimization. In Nicoletta
Calzolari (Conference Chair), Khalid Choukri, Thierry Declerck, Mehmet Uur Doan, Bente Maegaard, Joseph
Mariani, Asuncion Moreno, Jan Odijk, and Stelios Piperidis, editors, Proceedings of the Eight International
Conference on Language Resources and Evaluation (LREC?12), Istanbul, Turkey, may. European Language
Resources Association (ELRA).
Marcel Bollmann, Florian Petran, and Stefanie Dipper. 2011. Rule-based normalization of historical texts. In Pro-
ceedings of the Workshop on Language Technologies for Digital Humanities and Cultural Heritage (LaTeCH-
2011), pages 34?42, Hissar, Bulgaria, September.
Marcel Bollmann. 2013. POS tagging for historical texts with sparse training data. In Proceedings of the 7th
Linguistic Annotation Workshop and Interoperability with Discourse, pages 11?18, Sofia, Bulgaria, August.
Association for Computational Linguistics.
Michael Collins, Lance Ramshaw, Jan Haji?c, and Christoph Tillmann. 1999. A statistical parser for czech. In
Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational
Linguistics, pages 505?512. Association for Computational Linguistics.
Michael Cummings. 2010. An Introduction to the Grammar of Old English: A Systemic Functional Approach.
Functional Linguistics. Equinox Publishing Limited.
Robert P. Ebert. 1976. Infinitival complement constructions in Early New High German. Linguistische Arbeiten.
De Gruyter.
Richard Johansson and Pierre Nugues. 2007. Extended constituent-to-dependency conversion for English. In
Proceedings of NODALIDA 2007, pages 105?112, Tartu, Estonia, May 25-26.
Daisuke Kawahara and Kiyotaka Uchimoto. 2007. Minimally lexicalized dependency parsing. In Proceedings
of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, pages 205?208.
Association for Computational Linguistics.
Mike Kestemont, Walter Daelemans, and Guy De Pauw. 2010. Weigh your words: Memory-based lemma-retrieval
for Middle Dutch literary texts. In CLIN 2010. Computational linguistics in the Netherlands 20, Utrecht, The
Netherlands, May.
Roland Meyer. 2011. New wine in old wineskins? Tagging Old Russian via annotation projection from modern
translations. Russian linguistics, 35(2):267?281.
Graham Neubig, Taro Watanabe, Shinsuke Mori, and Tatsuya Kawahara. 2012. Machine translation without words
through substring alignment. In Proceedings of the 50th Annual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers), pages 165?174, Jeju Island, Korea, July. Association for Computational
Linguistics.
Joakim Nivre. 2003. An efficient algorithm for projective dependency parsing. In Proceedings of the 8th Interna-
tional Workshop on Parsing Technologies (IWPT).
Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models.
Computational linguistics, 29(1):19?51.
Marco Pennacchiotti and Fabio Massimo Zanzotto. 2008. Natural language processing across time: An empirical
investigation on italian. In Advances in Natural Language Processing, pages 371?382. Springer.
Paul Rayson, Dawn Archer, Alistair Baron, Jonathan Culpeper, and Nicholas Smith. 2007. Tagging the Bard:
Evaluating the accuracy of a modern POS tagger on Early Modern English corpora. In Proceedings of the 4th
Corpus Linguistics Conference (CL-2007), Birmingham, UK.
Philip Resnik, Mari Broman Olsen, and Mona Diab. 1997. Creating a parallel corpus from the book of 2000
tongues. In Proc. of the Text Encoding Initiative 10th Anniversary User Conference (TEI-10).
Eir??kur R?ognvaldsson, Anton Karl Ingason, Einar Freyr Sigurdhsson, and Joel Wallenberg. 2012. The Icelandic
Parsed Historical Corpus (IcePaHC). In LREC, pages 1977?1984.
Silke Scheible, Richard J. Whitt, Martin Durrell, and Paul Bennett. 2011. Evaluating an ?off-the-shelf? POS-
tagger on Early Modern German text. In Proceedings of the 5th ACL-HLT Workshop on Language Technology
for Cultural Heritage, Social Sciences, and Humanities (LaTeCH-2011), pages 19?23, Portland, OR, USA,
June.
19
Kathrin Spreyer, Lilja Ovrelid, and Jonas Kuhn. 2010. Training parsers on partial trees: A cross-language com-
parison. In Proc. of the 7th International Conference on Language Resources and Evaluation (LREC-2010),
Valletta, Malta, May.
Ann Taylor, Mitchell Marcus, and Beatrice Santorini. 2003a. The Penn treebank: an overview. In Treebanks,
pages 5?22. Springer.
Ann Taylor, Anthony Warner, Susan Pintzuk, and Frank Beths. 2003b. The york-toronto-helsinki parsed corpus
of old english prose. University of York.
Krisztina T?oth, Rich?ard Farkas, and Andr?as Kocsor. 2008. Sentence alignment of hungarian-english parallel
corpora using a hybrid algorithm. Acta Cybern., 18(3):463?478, January.
C. Trips. 2002. From OV to VO in Early Middle English. Linguistics today. John Benjamins Pub.
A. van Kemenade and B. Los. 2009. The Handbook of the History of English. Blackwell Handbooks in Linguis-
tics. John Wiley & Sons.
Hiroyasu Yamada and Yuji Matsumoto. 2003. Statistical dependency analysis with support vector machines. In
Proceedings of IWPT. Vol. 3. 2003.
David Yarowski and Grace Ngai. 2001. Inducing multilingual POS taggers and NP bracketers via robust projection
across aligned corpora. In Proceedings of NAACL 2001, pages 200?207.
Daniel Zeman and Philip Resnik. 2008. Cross-language parser adaptation between related languages. In IJCNLP-
08 Workshop on NLP for Less Privileged Languages, pages 35?41, Hyderabad, India, Jan.
20
