Proceedings of the 7th Workshop on Asian Language Resources, ACL-IJCNLP 2009, pages 153?160,
Suntec, Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
Thai National Corpus: A Progress Report 
 
 
Wirote Aroonmanakun 
Department of Linguistics  
Chulalongkorn University 
awirote@chula.ac.th 
Kachen Tansiri 
Thai National Corpus Project 
Chulalongkorn University 
kc.tansiri@gmail.com 
Pairit Nittayanuparp 
Thai National Corpus Project 
Chulalongkorn University 
cherngx@gmail.com 
 
  
 
Abstract 
 
This paper presents problems and solutions in 
developing Thai National Corpus (TNC). TNC 
is designed to be a comparable corpus of Brit-
ish National Corpus. The project aims to col-
lect eighty million words. Since 2006, the 
project can now collect only fourteen million 
words. The data is accessible from the TNC 
Web. Delay in creating the TNC is mainly 
caused from obtaining authorization of copy-
right texts. Methods used for collecting data 
and the results are discussed. Errors during the 
process of encoding data and how to handle 
these errors will be described. 
1 Thai National Corpus 
Thai National Corpus (TNC) is a general corpus 
of the standard Thai language (Aroonmanakun, 
2007). It is designed to be comparable to the 
British National Corpus (Aston and Burnard, 
1998) in terms of its domain and medium propor-
tions. However, only written texts are collected 
in the TNC, and the corpus size is targeted at 
eighty million words. In addition to domain and 
medium criteria, texts are also selected and cate-
gorized on the basis of their genres. We adopted 
Lee?s idea of categorizing texts into different 
genres based on external factors like the purpose 
of communication, participants, and the settings 
of communication (Lee 2001). Texts in the same 
genre share the same characteristics of language 
usages, e.g. discourse structure, sentence pat-
terns, etc. Moreover, since TNC is a representa-
tive of the standard Thai language at present, 
90% of the texts will be texts produced before 
1998. The rest 10% can be texts produced before 
1998 if they are published recently. Therefore, 
the structure of TNC is shaped on the dimensions 
of domain, medium, genres and time (see Table 
1). Texts that fit into the designed portion of 
these criteria will be selected. After that, copy-
right holders of each text will be contacted and 
asked to sign a permission form. To make this 
process easier, the same form is used for all cop-
yright holders. When authorization is granted, 
texts are randomly selected either from the be-
ginning, the middle, the end, or selected from 
many sections. Sampling size can vary, but the 
maximum size will not exceed 40,000 words or 
about 80 pages of A4 paper.  
In this TNC project, we use the TEI guideline, 
?TEI P4?, as the markup language. Three types 
of information are marked in the document: do-
cumentation of encoded data, primary data, and 
linguistic annotation. Documentation of encoded 
data is the markup used for contextual informa-
tion about the text. Primary data refers to the ba-
sic elements in the text, such as paragraphs, sec-
tions, sentences, etc. Linguistic annotation is the 
markup used for linguistic analysis, such as parts 
of speech, sentence structures, etc. The first two 
types are the minimum requirements for marking 
up texts. The structure of each document is 
represented in the following tags: 
<tncDoc  xml:id=?DocName?> 
<tncHeader> ?markup for contextual informa-
tion ?  
</tncHeader> 
<text> ?body text, markup for primary data e.g. 
<p> and linguistic analysis e.g. <w>,   <name> 
?.  
</text> 
</tncDoc> 
For linguistic annotation, we mark word 
boundaries and transcriptions for every word.  
Information of parts-of-speech will not be 
marked at present. The following is an example 
of markup in a document. 
<w tran="kot1maaj4">?</w><w 
tran="thaN3">	
</w> <w>3</w> <w 
tran="cha1bap1"></w><w tran="mii0">
153
</w><w tran="lak3sa1na1">?</w><w 
tran="mUUan4"></w><w tran="kan0">?
</w><w tran="juu1"></w><w tran="jaaN1">

</w><w tran="nUN1">
</w> 
We recognize that marking tags manually is a 
difficult and a time-consuming task, so for this 
project, two programs are used for tagging lan-
guage data and contextual information. TNC 
Tagger is used for segmenting words and mark-
ing basic tags <w> and <p> in the text. Word 
segmentation and transcription program pro-
posed in Aroonmanakun and Rivepiboon (2004) 
is used as a tagger. TNC Header is used for in-
putting contextual information and generating 
header tag for each text.  Output from TNC Tag-
ger will be combined with the header tag as an 
XML document. 
2 Data collection 
This section explains methods of data collection 
and the outcomes. First, we thought that texts 
could be collected easily from publishers. So, we 
first wrote a letter to three major publishers ask-
ing for collaboration. We thought that they 
would be able to provide us lot of texts in elec-
tronic formats. So, we asked them to give us a 
list of their publications and mark for us items 
that they have in electronic forms. It turned out 
that they did not even understand much about the 
corpus and the purpose of collecting texts. Thus, 
we did not receive positive responses as ex-
pected. Only one publisher was able to give us 
the list of their publications. The rest asked us to 
be more specific about the texts we want. The 
fault is ours because we did not make clear what 
texts that we want and how their rights on the 
texts will be protected. Thus, corresponding with 
the publishers did not go smoothly and quickly 
as it should be. We also learned that the publish-
ers are not the owners of all the texts. It depends 
on the agreement signed between the authors and 
the publishers. Normally, the author is the copy-
right holder. Publishers may hold the copyright 
for a certain period agreed by both parties. 
Later, before we wrote to a publisher asking 
for their helps, we searched and listed the title 
and the number of pages that we want from each 
text. Project details and samples of concordance 
output were enclosed to give them a  better un-
derstanding of the project. And we only asked 
the publishers to collaborate by providing us the 
contact address of the copyright holder of each 
text. This time we received a positive response 
from many publishers. From twenty two publish-
ers we contacted, only one publisher officially 
refused to collaborate for their own reasons. 
Fourteen publishers did not response. Seven of 
them sent us the information we requested. After 
we received the contact addresses from the pub-
lishers, we then wrote a letter directly to the au-
thor. A permission form in which selected publi-
cations are listed was attached in the letter. We 
asked them to sign a permission form and return 
it in the enclosed envelope. To make them feel 
easier to support us, we informed them that they 
may remove their works from the TNC anytime 
by writing a letter informing us to do so. We did 
not even ask for a copy of the book or the article. 
We will look for those texts and typing them in 
ourselves. By doing this, we did not put a burden 
on the copyright owners. In addition, we con-
tacted the P.E.N International-Thailand Centre, 
which is the association of publishers, editors, 
and novelists in Thailand, asking for contact ad-
dresses of novelists. For academic writers, we 
searched for their contact addresses from univer-
sity websites. Of those 780 authors we had con-
tacted, 250 of them granted us the permission to 
use their texts. We suspected that the address list 
we received from the P.E.N International-
Thailand Centre may be out-of-date because we 
received only 41 replies from 278 requests to 
novelists.   
For texts that are not copyrighted in Thai, e.g. 
news reports, documents from governments, 
laws and orders etc., they are collected prefera-
bly from those that are available in the internet. 
After texts were saved in electronic format 
and catalogued in the database, they were parsed 
by the TNC Tagger program. Texts will be word 
segmented and marked basic tags as described in 
the previous section. The process is not fully au-
tomatic. The program will ask a user to make a 
correction if any chunk of texts could not be 
parsed. This usually happened because there was 
a spelling error within that text chunk. After the 
text is parsed, contextual information of the text 
will be inserted by using the TNC Header pro-
gram. With these two programs, texts are con-
verted into an XML format that conforms to the 
TEI P4 standard. Some problems occurred dur-
ing this process will be discuss in section 4. 
3 TNC web 
It is now clear that collecting eighty million 
words is a long time process. At present, only 
fourteen million words are processed in the TNC. 
Nevertheless, it is a good idea to make the corpus 
154
accessible to the public. So, we had been devel-
oping a web interface to search the TNC, or the 
TNC web1.  
TNC web is a web interface for concordance 
software that will show not only keyword-in-
context but also collocations and distributions of 
the keyword. When users enter a keyword, the 
distribution of keyword in five major genres will 
be shown on the right window. Users can click 
on the frequency of occurrence in any genre on 
this window. A concordance window will then 
be displayed underneath. Users can filter the 
search by specifying a genre, a domain, pub-
lished year, authors? age range, and authors? 
gender. By doing this, users can search for the 
occurrence of the keyword in any specific con-
text. Figure 1 shows the screen of concordance 
search from TNC web. 
Collocation is searched by clicking on the icon 
?COLLOCATE?. Collocations within 1-3 words 
on the left and right contexts will be ranked by 
statistical measure. Frequency of occurrence in 
five major genres will also be shown. Users can 
click on these numbers to see the concordance 
context. Figures 2 and 3 shows the collocation of 
the keyword  ? ?run? using log-likelihood and 
mutual information . 
To make the processing time acceptable, the 
XML data was converted into MySQL database 
and PHP scripting language was used for web 
development. Co-occurrences of words are also 
stored as precache data. By doing this, the size of 
the data storage gets larger. The XML data of 14 
million words, which is about 365 megabytes, is 
expanded to 2,064 megabytes on the server. 
Though at present, the TNC is not balance and 
does not have a proportion of texts as planned, 
making it searchable through the web is still a 
useful idea. Users can get authentic data in vari-
ous genres. And it would be easier for us to ex-
plain to the public what the TNC is and how it 
can be used.  
4 Problems  
The difficulties of creating the TNC are 
grounded on management rather than technical 
problems. The most difficult part is to get copy-
right texts. Unexpected errors during the process 
of creating an annotation text are also another 
problem causing a delay in creating the TNC.  
                                                 
1 http://www.arts.chula.ac.th/~ling/ tnc2/ 
4.1 Getting more texts 
Though the use of corpora is quite well known to 
academics, it is little known to the public at 
large. Without understanding from the people 
especially writers and publishers, it is not easy to 
get the support and collaboration from them. 
This is the main obstruction causing a delay in 
creating the TNC. Implementing TNC web is one 
method of getting TNC known to the public. 
Another strategy that we plan to do is to public-
ize the project and praise those who contributed 
their texts to the project. At this moment, a num-
ber of famous novelists had granted us the per-
mission to include parts of their novels in the 
TNC. We could use these names to make other 
people feel that it is a privilege to have their texts 
as a part of TNC.  
Another strategy of promoting TNC is to 
show its worth. We plan to publish a series of 
linguistic papers that use TNC as data of analy-
sis, and demonstrate how basic information like 
word frequency and collocations in different ge-
nres can be used for teaching the Thai language.  
4.2 Validating data 
The delay in creating the TNC is also caused 
during the process of encoding data. As stated 
earlier in section 2, texts have to be parsed and 
encoded as XML data. During this process, dif-
ferent types of errors are found. These have to be 
handled to make the data correct and consistent.  
System errors (unintentional): This is an unin-
tentional typo that produces an ill-formed string. 
These errors are easier to detect and most people 
would agree that they should be corrected. For 
example, 