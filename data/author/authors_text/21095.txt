Proceedings of the 5th Workshop on Language Analysis for Social Media (LASM) @ EACL 2014, pages 53?61,
Gothenburg, Sweden, April 26-30 2014.
c?2014 Association for Computational Linguistics
Vowel and Diacritic Restoration for Social Media Texts
K?ubra Adal?
Dep. of Computer Eng.
Istanbul Technical University
Istanbul, Turkey
kubraadali@itu.edu.tr
G?uls?en Eryi
?
git
Dep. of Computer Eng.
Istanbul Technical University
Istanbul, Turkey
gulsen.cebiroglu@itu.edu.tr
Abstract
In this paper, we focus on two important
problems of social media text normaliza-
tion, namely: vowel and diacritic restora-
tion. For these two problems, we pro-
pose a hybrid model consisting both a dis-
criminative sequence classifier and a lan-
guage validator in order to select one of
the morphologically valid outputs of the
first stage. The proposed model is lan-
guage independent and has no need for
manual annotation of the training data. We
measured the performance both on syn-
thetic data specifically produced for these
two problems and on real social media
data. Our model (with 97.06% on syn-
thetic data) improves the state of the art
results for diacritization of Turkish by 3.65
percentage points on ambiguous cases and
for the vowel restoration by 45.77 percent-
age points over a rule based baseline with
62.66% accuracy. The results on real data
are 95.43% and 69.56% accordingly.
1 Introduction
In recent years, with the high usage of computers
and social networks like Facebook and Twitter, the
analysis of the social media language has become
a very popular and crucial form of business intelli-
gence. But unfortunately, this language is very dif-
ferent from the well edited written texts and much
more similar to the spoken language, so that, the
available NLP tools do not perform well on this
new platform.
As we all know, Twitter announced (at April
1st, 2013)
1
that it is shifting to a two-tiered ser-
vice where the basic free service ?Twttr? will only
allow to use consonants in the tweets. Although,
1
https://blog.twitter.com/2013/
annncng-twttr
this is a very funny joke, people nowadays are al-
ready very used to use this style of writing without
vowels in order to fit their messages into 140 char-
acters Twitter or 160 characters SMS messages.
As a result, the vowelization problem (Twttr ?
Twitter) is no more limited with some specific lan-
guage families (e.g.semitic languages) (Gal, 2002;
Zitouni et al., 2006) but it became a problem of so-
cial media text normalization in general.
Diacritics are some marks (e.g. accents, dots,
curves) added to the characters and have a wide
usage in many languages. The absence of these
marks in Web2.0 language is very common and
posses a big problem in the automatic process-
ing of this data by NLP tools. Although, in the
literature, the term ?diacritization? is used both
for vowel and diacritic restoration for semitic lan-
guages, in this paper, we use this term only for
the task of converting an ASCII text to its proper
form (with accents and special characters). A
Turkish example is the word ?dondu? (it is frozen)
which may be the ascii form of both ?dondu?(it is
frozen) or ?d?ond?u? (it returned) where the ambigu-
ity should be resolved according to the context. In
some studies, this task is also referred as ?unicodi-
fication?(Scannell, 2011) or ?deasciification?(T?ur,
2000).
In this paper, we focus on these two important
problems of social text normalization, namely: di-
acritization and vowelization. These two problems
compose almost the quarter (26.5%) of the nor-
malization errors within a 25K Turkish Tweeter
Data Set. We propose a two stage hybrid model:
firstly a discriminative model as a sequence classi-
fication task by using CRFs (Conditional Random
Fields) and secondly a language validator over the
first stage?s results. Although in this paper, we pre-
sented our results on Turkish (which is a highly ag-
glutinative language with very long words full of
un-ascii characters), the proposed model is totally
language independent and has no need for manual
53
annotation of the training data. For morpholog-
ically simpler languages, it would be enough to
use a lexicon lookup for the language validation
stage (whereas we used a morphological analyzer
for the case of Turkish). With our proposed model,
we obtained the highest results in the literature for
Turkish diacritization and vowelization.
The remaining of the paper is structured as fol-
lows: Section 2 discusses the related work, Sec-
tion 3 tries to show the complexity of diacritiza-
tion and the vowelization tasks by giving exam-
ples from an agglutinative language; Turkish. Sec-
tion 4 introduces our proposed model and Section
5 presents our experiments and results. The con-
clusion is given in Section 6.
2 Related Work
The vowelization problem is mostly studied for
semitic languages and many different methods are
applied to this problem. The problem is generally
referred as diacritization for these languages, since
diacritics are placed on consonants for the purpose
of vowel restoration. For example, the short vow-
els in Arabic are only pronounced by the use of
diacritics put on other consonants. Some of these
studies are as follows: Gal (2002) reports the re-
sults on Hebrew by using HMMs and Zitouni et
al. (2006) on Arabic by using maximum entropy
based models. Al-Shareef and Hain (Al-Shareef
and Hain, 2012) deals with the vowelization of
colloquial Arabic for automatic speech recogni-
tion task by using CRFs on speaker and contextual
information. Haertel et al. (2010) uses conditional
markov models for the vowel restoration problem
of Syriac. Nelken and Shieber (2005) uses a finite
state transducer approach for Arabic as well. To
the best of our knowledge, the vowelization work
on Turkish is the first study on a language which
do not possess the vowelization problem by its na-
ture. We believe that on that sense, our hybrid
model will be a good reference for future studies
in social media text normalization where the prob-
lem is disregarded in recent studies.
The diacritization task on the other hand is
not addressed as frequently as the vowelization
problem
2
. Some studies are as follows: Scan-
nell (2011) uses a Naive Bayes classifier for both
word-level and character-level modeling. Each
ambiguous character in the input is regarded as
2
Here, we exclude all the works done for semitic lan-
guages. The reason is explained on the former paragraph.
an independent classification problem. They are
using lexicon lookup which is not feasible for ev-
ery possible word surface form in agglutinative or
highly inflected languages. They refer to a lan-
guage model in ambiguous cases. They tested
their system for 115 languages as well as for Turk-
ish (92.8% on a much easier data set than ours (re-
fer to Section 5.1) . Simard and Deslauriers (2001)
tries to recover the missing accents in French.
They are using a generative statistical model for
this purpose. De Pauw et al. (2007) also test their
MBL (memory based learning) model on differ-
ent languages. Although they do not test for Turk-
ish, the most attractive part of theirs results is that
the performances for highly inflectional languages
differ sharply from the others towards the negative
side. Nguyen and Ock (2010) deals with the dia-
critization of Vietnamese by using Adaboost and
C4.5.
The work done so far for the diacritization
of Turkish are from T?ur (2000) (character-based
HMM model), Zemberek (2007), Y?uret and de la
Maza (Y?uret and de la Maza, 2006) (GPA: a kind
of decision list algorithms). We give the compar-
ison of the two later systems on our data set and
propose a discriminative equivalent of the HMM
approach used in T?ur (2000) (see Section 5 for fur-
ther discussions). For the vowelization, the only
study that we could find is from T?ur (2000) which
uses again the same character-level HMM model
into this problem (with an equivalent discrimina-
tive model given at Table 8 ?3ch model).
3 The complexity
This section tries to draw light upon the complex-
ity of diacritization and the vowelization tasks by
giving examples from an agglutinative language;
Turkish.
3.1 Turkish
Turkish is an agglutinative language which means
that words have theoretically an infinite number
of possible surface forms due to the iterative con-
catenation of inflectional and derivational suffixes.
As for other similar languages, this property of the
language makes impractical for Turkish words to
be validated by using a lexicon. And also, the in-
creasing length
3
of the words creates a big search
space especially for the vowelization task.
3
The average word length is calculated as 6.1 for Turkish
nouns and 7.6 for verbs in a 5 million word corpus(Ak?n and
Ak?n, 2007).
54
Turkish alphabet has 7 non-ascii characters that
don?t exist in the Latin alphabet (c?, ?g, ?,
?
I, ?o, s?,
?u) and the ascii counterparts of these letters (c, g,
i, I, o, s, u) are also valid letters in the alphabet
which causes an important disambiguation prob-
lem at both word and sentence level. The alphabet
contains 8 vowels (a(A), e(E), ?(I), i(
?
I), o(O), ?o(
?
O),
u(U), ?u(
?
U)) in total.
3.2 Diacritization
The following real example sentence taken from
social media ?Ruyamda evde oldugunu gordum.?,
written by using only the ascii alphabet, has two
possible valid diacritized versions:
1. ?R?uyamda evde oldu?gunu g?ord?um.?
(I had a dream that you were at home.)
2. ?R?uyamda evde ?old?u?g?un?u g?ord?um.?
(I had a dream that you died at home.)
As can be observed from this sentence some of
the asciified words (e.g. ?oldugunu?) has more
than one possible valid counterparts which causes
the meaning change of the whole sentence.
The problem is the decision of the appropri-
ate forms for the critical letters (C, G, I, O, S,
U)
4
. Although the problem seems like a multi-
class classification problem, it is in essence a
binary-classification task for each critical letter
and can be viewed as a binary sequence classifi-
cation task for the whole word so that the orig-
inal word will be chosen from (2
n
) possibilities
where n is the number of occurrence of critical
letters (C, G, I, O, S, U) in the ascii version.
For example the word ?OldUGUnU? has (2
5
=32)
possible transformations whereas only 2 of them
(?oldu?gunu? and ??old?u?g?un?u?) are valid Turkish
words. Figure 1 gives a second example and shows
all the possible (2
2
=4) diacritized versions of the
word ?aCI? where again only two of them are
valid words (emphasized with a bold background
colour): ?ac???(angle) and ?ac??(pain).
3.3 Vowelization
Vowelization on the other hand causes much more
complexity when compared to diacritization. Each
position
5
between consequent consonants, at the
4
From this point on, we will show the ascii versions of
these letters as capital letters meaning that they may appear
in the diacritized version of the word either in their ascii form
or in their diacritized form. Ex: the capital C will become
either c or c? after the processing.
5
For the sake of simplicity, we just assumed that only zero
or one vowel may appear between two consonants whereas
there exist some words with consecutive vowels (such as
Figure 1: Possible Diacritized Versions of ?aCI?
beginning or ending of the word may take one
vowel or not resulting a selection from 9 class
labels (the 8 vowel letters + the null charac-
ter). For example, the vowelization of the word
?slm?(?hi? written without vowels, with n=4 po-
sitions s l m ) will produce 9
4
= 6561 possibili-
ties where 39 of them are valid Turkish words (e.g.
?salam?(salami), ?sulama?(watering), ?sal?m?(my
raft), ?selam?(hi), ?s?lam?(my furlough) etc...).
Figure 2: Proposed Model
4 Proposed Model
Most of the previous work in the literature (Sec-
tion 2) uses either some (generative of discrimina-
tive) machine learning models or some nlp tools
(e.g. morphological analyzers, pos taggers, lin-
guistic rules) in order to solve the vowelization
?saat?(clock)) although very rarely
55
problem. As it is shown in the previous section,
for languages with higher number of vowels and
word length due to their rich inflectional morphol-
ogy, the search space gets very high very rapidly.
Since the problem is mostly similar to generation,
in order to increase the likelihood of the generated
output word, most of the approaches include char-
acter level probabilities or relationships. In this
case, it is unfair to expect from a machine learn-
ing system to generate morphologically valid out-
puts (especially for highly inflectional languages)
while trying to maximize the overall character se-
quence probability.
We propose a two stage model (Figure 2) which
has basically two components.
1. a discriminative sequence classifier
2. a language validator
4.1 Discriminative Sequence Classifier
In the first stage, we use CRFs
6
(Lafferty et al.,
2001) in order to produce the most probable out-
put words. This stage treats the diacritization and
vowelization as character level sequence labeling
tasks, but since it is a discriminative model, it is
also possible to provide neighboring words as fea-
tures into the system. During training, each in-
stance within a sequence has basically the follow-
ing main parts:
1. features related to the current and neighbor-
ing tokens (namely surface form or lemma)
2. features related to the current and neighbor-
ing characters
8
3. class label
The test data is also prepared similarly except
the gold standard class labels.
Table 1 and Table 2 show instance samples for
the sample words (?OldUGUnU? and ? s l m ?)
given in Section 3. As can be observed from the
tables, we have 7 different class labels in diacritic
restoration and 9 different class labels in vowel
restoration (one can refer to Section 3 for the de-
tails). The sequences represent words in focus and
each instance line within a sequence stands for the
character position in focus. The sample for dia-
critization has 5 character features and 2 word fea-
tures where the current character feature limits the
6
In this work, we used CRF++
7
which is an open source
implementation of CRFs.
8
The feature related to the current character is only avail-
able in diacritization model
number of the class labels to be assigned to that
position by 2. The sample for vowelization has 1
word feature and 6 character features.
Curr. Neig. Curr. Neig. Neig. Neig. Neig. Class
Letter Word(+1) Word Ch(-2) Ch(-1) Ch(+1) Ch(+2) Label
O GOrdUm OldUGUnU l d ?o
U GOrdUm OldUGUnU l d G U ?u
G GOrdUm OldUGUnU d U U n ?g
U GOrdUm OldUGUnU U G n U ?u
U GOrdUm OldUGUnU U n ?u
Table 1: Diacritization: Instance Representation
for the word ?oldugunu?
?OldUGUnU? 5 critical positions
Curr. Neig. Neig. Neig. Neig. Neig. Neig. Class
Word Ch(-3) Ch(-2) Ch(-1) Ch(+1) Ch(+2) Ch(+3) Label
slm s l m
slm s l m e
slm s l m a
slm s l m
Table 2: Vowelization: Instance Representation
for the word ?slm?
? s l m ? 4 possible vowel positions
CRFs are log-linear models and in order to
get advantage of the useful feature combinations,
one needs to provide these as new features to the
CRFs. In order to adopt a systematic way, we took
the features? combinations for character features
and word features separately. For character fea-
tures we took the combinations up to 6-grams for
?3ch and for the neighboring word features up to
4 grams. The number of features affects directly
the maximum amount of training data that could
be used during the experiments. The total number
of feature templates after the addition of feature
combinations ranges between 7 for the simplest
case and 30 for our model with maximum num-
ber of features. Three sample feature templates are
given below for the sample sequence of Table 1.
The templates are given in [pos,col] format, where
pos stands for the relative position of the token in
focus and col stands for the feature column num-
ber in the input file. U06 is the template for us-
ing the sixth
9
feature in Table 1 (Neigh. Ch(+1)).
U13 is a bigram feature combination of 2nd and
3th features (the current token and the next token).
U11 is a fourgram feature combination of 4th, 5th,
6th and 7th features of our feature set that refers
to the group of the previous two characters and the
next two characters.
9
in CRF++ feature templates the features indexes start
from 0.
56
U06 : %x[0, 5]
U13 : %x[0, 1]/%x[0, 2]
U11 : %x[0, 3]/%x[0, 4]/%x[0, 5]/%x[0, 6]
4.2 Language Validator
The n best sequences of the discriminative classi-
fier is then transferred to the language validator.
We use a two-level morphological analyzer (S?ahin
et al., 2013) for the Turkish case since in this ag-
glutinative language it is impractical to validate a
word by making a lexicon lookup. But this sec-
ond part may be replaced by any language valida-
tor (for other languages) which will filter only the
valid outputs from the n best results of the discrim-
inative classifier. Figure 2 shows an example case
of the process for vowelization. The system takes
the consonant sequence ?kd? and the 5 best output
of the first stage is produced as ?kidi, kedi, kad?,
kado, kada?. The language validator then chooses
the most probable valid word ?kedi? (cat) as its
output. One should notice that if none of the n
most probable results is a valid word, then the sys-
tem won?t produce any suggestion at all. We show
experimental results on the effect of the selection
of n in the next section.
5 Experimental Setup And Results
In this section, we first present our datasets and
evaluation strategy. We then continue with the di-
acritization experiments and finally we share the
results of our vowelization experiments.
5.1 Datasets and Evaluation Methodology
For both of the diacritization and vowelization
tasks, creating the labeled data is a straightforward
task since the reverse operations for these (con-
verting from formally written text to their Ascii
form or to a form without vowels) can be accom-
plished automatically for most of the languages
(except semitic languages where the vowels do not
appear in the formal form). To give an example
from Turkish, the word ?oldu?gunu? may be auto-
matically converted to the form ?OldUGUnU? for
diacritization and ? l d g n ? for vowelization ex-
periments. We used data from three different cor-
pora: METU Corpus (Say et al., 2002) and two
web corpora from Y?ld?z and Tantu?g (2012) and
Sak et al. (2011).
In order to judge different approaches fairly,
we aimed to create a decently though test set.
Since the vowelization task already comprises a
very high ambiguity, we focused to the ambigu-
ous diacritization samples. With this purpose, we
first took the Turkish dictionary and converted all
the lemmas within the dictionary into their Ascii
forms. We then created the possible diacritized
forms (Figure 1) and created a list of all ambigu-
ous lemmas (1221 lemmas in total) by finding all
the lemmas which could be produced as the out-
put of diacritization. For example ?ac??? and ?ac??
are put into this list after this operation. Although
this ambiguous lemmas list may be extended by
also considering interfusing surface forms, for the
sake of simplicity we just considered to take the
ambiguous lemmas from the dictionary. We then
searched our three corpora (and the WEB where
not available in these) for the words with an am-
biguous lemma and created our test set so that for
each ambiguous lemma there is exactly one sen-
tence consisting of it. As a result, we collected a
test set of 1157 sentences (17923 tokens) consist-
ing of 1871 ambiguous words
10
in total. The re-
maining sentences from the corpora are used dur-
ing training. Since the feature set size directly af-
fects the amount of usable training data, for differ-
ent experiment sets we used different size of train-
ing data each time trying to use the data from the
three corpora in equal amounts.
After evaluating with synthetically produced
training and test sets, we also tested our best per-
formed models on real data collected from social
media (25K tweets with at least one erroneous
token) and normalized manually (Eryi?git et al.,
2013). This data consists 58836 tokens that have
text normalization problems where 3.75% is due
to missing vowels and 22.8% is due to misuse of
Turkish characters. In order to separate these spe-
cific error sets, we first automatically aligned the
original and normalized tweets and then applied
some filters over the aligned data: e.g. Deasci-
ification errors are selected so that the character
length of the original word and its normalized
form should be the same and the differing letters
should only be the versions of the same Turkish
characters.
For the evaluation of diacritization, we provide
two accuracy scores: Accuracy over the entire
words (Acc
Overall
Equation 1) and accuracy over
the ambiguous words alone (Acc
Amb
Equation 2
10
One should note that each sentence in the test set con-
tains at least one or more ambiguous surface forms. The test
data will be available to the researches via http://...
57
over 1871 ambiguous words in the test set). Since
the vowelization problem is almost entirely am-
biguous, the two scores are almost the same for the
entire tests (# of words ? # of amb. words).
That is why, for the vowelization task we provide
only Acc
Overall
.
Acc
Overall
=
# of corr. diacritized words
# of words
(1)
Acc
Amb
=
# of corr. diacritized amb. words
# of amb. words
(2)
In the work of T?ur (2000), the accuracy score
is provided as the correctly determined characters
which we do not find useful for the given tasks:
Acc
Amb
=
# of corr. diacritized amb. chars
# of amb. chars
. This
score gives credit to the systems although the pro-
duced output word is not a valid Turkish word. For
example, if a vowelization system produces an in-
valid output as ?oldgn? for the input ? l d g n ?, it
will have a 1/5 (one correct character over 5 possi-
ble positions) score whereas in our evaluation this
output will be totally penalized.
5.2 Diacritization Experiments
For diacritization, we designed four sets of ex-
periments. The first set of experiments (Table 3)
presents the results of our baseline systems. We
provide four baseline systems. The first one is a
rule based diacritics restorer which creates all the
possible diacritics for a given input and outputs the
first morphologically valid one. As the proposed
model does, the rule based system also validates
its outputs by using the morphological analyzer
introduced in Section 4.2. One can see from the
table that the accuracy on the ambiguous words of
this system is nearly 70%. Our second baseline
uses a unigram language model in order to select
the most probable valid output of the morpholog-
ical analyzer. Our third baseline is a baseline for
our discriminative classifier (with only ?2 neigh-
boring characters) without the language validator
component. In this model, the top most output of
the CRF is accepted as the correct output word.
One can observe that this baseline although it per-
forms better than the rule based system, it is worse
than the second baseline with a language model
component. Our last baseline is the baseline for
the proposed system in this paper with a discrimi-
native classifier (using only ?2 neighboring char-
acters) and a language validator which chooses the
first valid output within the top 5 results of the
classifier. It outperforms all the previous base-
lines.
Acc Acc
System Overall Amb
Rule based 90.38 69.17
Rule based + Unigram LM 91.94 83.54
CRF ?2ch 87.93 77.24
CRF ?2ch + Lang.Valid. 94.88 88.51
Table 3: Diacritization Baseline Results
The second set of experiments given in Table 4
is for the feature selection of the proposed model.
We test with the neighboring characters up to ?3
and together with the surface form of the cur-
rent token sform
curr
and/or the first n charac-
ters of the current token firstnch
curr
as lemma
feature. For both of the first two sets of exper-
iments (Table 3 and Table 4) we used a train-
ing data of size 4591K (the max. possible size
for the most complex feature set in these experi-
ments; (last line of Table 4). It can be observed
from Table 4 that although ?3ch (2nd line) per-
forms better than ?2ch (1st line), when we use
these together with sform
curr
we obtain better
results with ?2ch (3rd line). Since ?3ch (7 char-
acters in total) will be very close to the whole
number of characters within the surface form, the
new feature?s help is more modest in?3ch model.
In these experiments we try to optimize on the
overall accuracies. Our highest score in this ta-
ble is with the?2ch+sform
curr
+first5ch
curr
(last line) but since the difference between this and
?2ch + sform
curr
is not statistically significant
(with McNemar?s test p<0.01) and the size of the
maximum possible training data could still be im-
proved for the latter model, we decided to continue
with ?2ch+ sform
curr
.
In the third set of diacritization experiments
(Table 5) we investigated the effect of using the
neighboring tokens as features. In this experi-
ment set, the training data size is decreased to a
much lower size, only 971K in order to be able
to train with ?2 neighboring tokens. Each line
of the table is the addition of the surface forms
for the precised positions to the model of the first
line ?2ch + sform
curr
. We tested with all the
combinations in the ?2 window size. For exam-
58
Acc Acc
Feature Combinations Overall Amb
?2ch 94.88 88.51
?3ch 95.76 91.05
?2ch+ sform
curr
96.26 91.60
?3ch+ sform
curr
96.20 91.71
?2ch+ first3ch
curr
95.29 90.17
?2ch+ first4ch
curr
95.60 89.06
?2ch+ first5ch
curr
95.95 90.72
?2ch+ sform
curr
+ first3ch
curr
96.23 91.82
?2ch+ sform
curr
+ first4ch
curr
96.26 91.82
?2ch+ sform
curr
+ first5ch
curr
96.28 91.60
Table 4: Diacritization Feature Selection I
Acc Acc
Features Overall Amb
?2ch+ sform
curr
95.29 90.61
+sform
0010
95.49 90.72
+sform
0011
95.39 90.39
+sform
0100
93.77 83.32
+sform
0110
95.39 90.28
+sform
0111
95.26 89.95
+sform
1100
95.24 89.83
+sform
1110
95.21 89.50
+sform
1111
95.11 89.17
Table 5: Diacritization Feature Selection II
ple sform
0010
means that the surface form of the
token at position +1 is added to the features. This
feature set outperformed all the other ones.
Acc Acc
System Overall Amb
Y?uret (2006) 95.93 91.05
Zemberek (2007) 87.71 82.55
?2ch+ sform
curr
96.15 92.04
?2ch+ sform
curr
+ sform
0010
97.06 94.70
Table 6: Diacritization Results Comparison with
Previous Work
Finally, in Table 6, we give the comparison re-
sults of our proposed model with the available
Turkish deasciifiers (the tools? original name given
by the authors) (Y?uret and de la Maza, 2006; Ak?n
and Ak?n, 2007). We both tested by ?2ch +
sform
curr
and?2ch+sform
curr
+sform
0010
.
Both of the models are tested with maximum pos-
sible size of training data: 10379K and 5764K suc-
cessively. Our proposed model for diacritization
outperformed all of the other methods with a suc-
cess rate of 97.06%. It outperformed the state of
the art by 1.13 percentage points in overall accu-
racy and by 3.65 percentage points in ambiguous
cases (both results statistically significant).
5.3 Vowelization Experiments
For the vowelization, we designed similar set of
experiments. In Table 7, we provide the results
for a rulebased baseline and our proposed model
with ?2ch. It is certainly a very time consuming
process to produce all the possible forms for the
vowelization task (see Section 3.3). Thus, for the
rule based baseline we stopped the generation pro-
cess once we find a valid output. The baseline of
the proposed model provides a 28.44 percentage
points improvements over the rule based system.
We did not try to compare our results with the
work of T?ur (2000) (an HMM model on charac-
ter level) firstly because the developed model was
not available for testing, secondly because the pro-
vided evaluation (see Section 5.1) was useless for
our purposes and finally because our ?3 charac-
ter model provided in the second line of Table 8 is
a discriminative counterpart of his 6-gram genera-
tive model.
Acc
System Overall
Rule based 16.89
CRF ?2ch+Lang.Valid. 45.33
Table 7: Vowelization Baseline Results
Table 8 gives the feature selection tests? results
similarly to the previous section. This time we ob-
tained the highest score with ?3ch + sform
curr
59.17%. In this set of experiments, we used
4445K of training data.
In order to investigate the impact of neighbor-
ing tokens, in the experiments given in Table 9,
we had to continue with ?2ch + sform
curr
with
Acc
Feature Combinations Overall
?2ch 45.33
?3ch 57.20
?2ch+ sform
curr
57.22
?3ch+ sform
curr
59.17
?2ch+ first3ch
curr
40.44
?2ch+ first4ch
curr
40.48
?2ch+ first5ch
curr
44.22
?2ch+ sform
curr
+ first3ch
curr
45.89
?2ch+ sform
curr
+ first4ch
curr
45.89
?2ch+ sform
curr
+ first5ch
curr
49.58
Table 8: Vowelization Feature Selection I
59
Acc
Features Overall
?2ch+ sform
curr
54.07
+sform
0010
50.89
+sform
0011
49.60
+sform
0100
31.84
+sform
0110
49.41
+sform
0111
47.78
+sform
1100
48.98
+sform
1110
47.88
+sform
1111
47.21
Table 9: Vowelization Feature Selection II
971K of training data.
11
We could not obtain any
improvement with the neighboring tokens. We re-
late these results to the fact that the neighboring
tokens are also in vowel-less form in the training
data so that this information do not help the dis-
ambiguation of the current token. Since we could
not add the word based features to this task by this
model, for future work we are planning to apply
a word based language model over the proposed
model?s possible output sequences.
In the final experiment set given in Table 10,
we trained our best performing model ?3ch +
sform
curr
with the maximum possible training
data (6653K). We also tested with different N val-
ues of CRF output. Although there is a slight in-
crease on the overall accuracy by passing from
N=5 to N=10, the increase is much higher when
we evaluate with Acc
topN
. Equation 3 gives the
calculation of this score which basically calculates
the highest score that could be obtained after per-
fect reranking of the top N results. In this score the
system is credited if the correct vowelized answer
is within the top N results of the system. We see
from the table that there is still a margin for the
improvement in top 10 results (up to 85.09% for
the best model). This strengthens our believe for
the need of a word based language model over the
proposed model outputs. Our vowelization model
in its current state achieves an accuracy score of
62.66% with a 45.77 percentage points improve-
ments over the rule based baseline.
11
If we select the larger model, it is going to be impossi-
ble to feed enough training data to the system. Since in this
set of experiments (Table 9) we only investigate the impact
of neighboring tokens, we had/preferred to select the smaller
character model.
Acc
topN
=
?
1 if result exists within top N
# of words
(3)
Acc Acc
System Overall top N
?3ch+ sform
curr
With Top 5 Poss. from CRF 62.05 80.21
?3ch+ sform
curr
With Top 7 Poss. from CRF 62.36 82.53
?3ch+ sform
curr
With Top 10 Poss. from CRF 62.66 85.09
Table 10: Vowelization Top N Results
Finally we test our best models on voweliza-
tion and diacritization errors from our Tweeter
data set and obtained 95.43% for diacritization and
69.56% for vowelization.
6 Conclusion And Future Work
In this paper, we proposed a hybrid model for the
diacritization and vowelization tasks which is an
emerging problem of social media text normaliza-
tion. Although the tasks are previously investi-
gated for different purposes especially for semitic
languages, to the best of our knowledge, this is
the first time that they are evaluated together for
the social media data on a language which do not
possess these problems in its formal form but only
in social media platform. We obtained the high-
est scores for the diacritization (97.06%) and vow-
elization (62.66%) of Turkish.
We have two future plans for the vowelization
part of the proposed model. The first one, as de-
tailed in previous section, is the application of a
word based language model over the valid CRF
outputs. The second one is the extension for par-
tial vowelization. Although in this work, we de-
signed the vowelization task as the overall genera-
tion of the entire vowels within a vowel-less word,
we observe from the social web data that people
also tend to write with partially missing vowels.
As an example, they are writing ?sevyrm? instead
of the word ?seviyorum? (I love). In this case, the
position between the consonants ?s? and ?v? is con-
strained to the letter ?e? and it is meaningless to
generate the other possibilities for the remaining 7
vowels. For this task, we are planning to focus on
constrained Viterbi algorithms during the decod-
ing stage.
60
The tool?s web api and the produced data sets
will be available to the researchers from the fol-
lowing address http://tools.nlp.itu.edu.tr/(Eryi?git,
2014)
Acknowledgment
This work is part of a research project supported
by TUBITAK 1001(Grant number: 112E276) as
an ICT cost action (IC1207) project.
References
Ahmet Afsin Ak?n and Mehmet D?undar Ak?n. 2007.
Zemberek, an open source nlp framework for turkic
languages. Structure.
Sarah Al-Shareef and Thomas Hain. 2012. Crf-based
diacritisation of colloquial Arabic for automatic
speech recognition. In INTERSPEECH. ISCA.
Guy De Pauw, Peter W. Wagacha, and Gilles-Maurice
de Schryver. 2007. Automatic diacritic restoration
for resource-scarce languages. In Proceedings of the
10th international conference on Text, speech and
dialogue, TSD?07, pages 170?179, Berlin, Heidel-
berg. Springer-Verlag.
G?uls?en Eryi?git, Fatih Samet C?etin, Meltem Yan?k,
Tanel Temel, and
?
Iyas C?ic?ekli. 2013. Turksent: A
sentiment annotation tool for social media. In Pro-
ceedings of the 7th Linguistic Annotation Workshop
and Interoperability with Discourse, pages 131?134,
Sofia, Bulgaria, August. Association for Computa-
tional Linguistics.
G?uls?en Eryi?git. 2014. ITU Turkish NLP web service.
In Proceedings of the Demonstrations at the 14th
Conference of the European Chapter of the Associa-
tion for Computational Linguistics (EACL), Gothen-
burg, Sweden, April. Association for Computational
Linguistics.
Ya?akov Gal. 2002. An hmm approach to vowel
restoration in Arabic and Hebrew. In Proceed-
ings of the ACL-02 workshop on Computational ap-
proaches to semitic languages, SEMITIC ?02, pages
1?7, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
Robbie A. Haertel, Peter McClanahan, and Eric K.
Ringger. 2010. Automatic diacritization for low-
resource languages using a hybrid word and con-
sonant cmm. In Human Language Technologies:
The 2010 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics, HLT ?10, pages 519?527, Stroudsburg, PA,
USA. Association for Computational Linguistics.
John D. Lafferty, Andrew McCallum, and Fernando
C. N. Pereira. 2001. Conditional random fields:
Probabilistic models for segmenting and labeling se-
quence data. In ICML, pages 282?289.
Rani Nelken and Stuart M. Shieber. 2005. Arabic di-
acritization using weighted finite-state transducers.
In Proceedings of the ACL Workshop on Compu-
tational Approaches to Semitic Languages, Semitic
?05, pages 79?86, Stroudsburg, PA, USA. Associa-
tion for Computational Linguistics.
Kiem-Hieu Nguyen and Cheol-Young Ock. 2010. Di-
acritics restoration in Vietnamese: letter based vs.
syllable based model. In Proceedings of the 11th
Pacific Rim international conference on Trends in
artificial intelligence, PRICAI?10, pages 631?636,
Berlin, Heidelberg. Springer-Verlag.
Muhammet S?ahin, Umut Sulubacak, and G?uls?en
Eryi?git. 2013. Redefinition of Turkish morphol-
ogy using flag diacritics. In Proceedings of The
Tenth Symposium on Natural Language Processing
(SNLP-2013), Phuket, Thailand, October.
Has?im Sak, Tunga G?ung?or, and Murat Sarac?lar. 2011.
Resources for Turkish morphological processing.
Lang. Resour. Eval., 45(2):249?261, May.
Bilge Say, Deniz Zeyrek, Kemal Oflazer, and Umut
?
Ozge. 2002. Development of a corpus and a tree-
bank for present-day written Turkish. In Proceed-
ings of the Eleventh International Conference of
Turkish Linguistics, Famaguste, Cyprus, August.
Kevin P. Scannell. 2011. Statistical unicodification of
African languages. Lang. Resour. Eval., 45(3):375?
386, September.
Michel Simard and Alexandre Deslauriers. 2001.
Real-time automatic insertion of accents in French
text. Nat. Lang. Eng., 7(2):143?165, June.
G?okhan T?ur. 2000. A statistical information extrac-
tion system for Turkish. Ph.D. thesis, Department of
Computer Engineering and the Institute of Engineer-
ing and Science of Bilkent University, Ankara.
Eray Y?ld?z and C?uneyd Tantu?g. 2012. Evaluation
of sentence alignment methods for English-Turkish
parallel texts. In Proceedings of the First Workshop
on Language Resources and Technologies for Turkic
Languages (LREC), Istanbul, Turkey, 23-25 May.
Deniz Y?uret and Michael de la Maza. 2006. The
greedy prepend algorithm for decision list induction.
In Proceedings of the 21st international conference
on Computer and Information Sciences, ISCIS?06,
pages 37?46, Berlin, Heidelberg. Springer-Verlag.
Imed Zitouni, Jeffrey S. Sorensen, and Ruhi Sarikaya.
2006. Maximum entropy based restoration of Ara-
bic diacritics. In Proceedings of the 21st Inter-
national Conference on Computational Linguistics
and the 44th annual meeting of the Association
for Computational Linguistics, ACL-44, pages 577?
584, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
61
Proceedings of the 5th Workshop on Language Analysis for Social Media (LASM) @ EACL 2014, pages 62?70,
Gothenburg, Sweden, April 26-30 2014.
c?2014 Association for Computational Linguistics
A Cascaded Approach for Social Media Text Normalization of Turkish
Dilara Toruno
?
glu
Dep. of Computer Eng.
Istanbul Technical University
Istanbul, Turkey
torunoglud@itu.edu.tr
G?uls?en Eryi
?
git
Dep. of Computer Eng.
Istanbul Technical University
Istanbul, Turkey
gulsen.cebiroglu@itu.edu.tr
Abstract
Text normalization is an indispensable
stage for natural language processing of
social media data with available NLP
tools. We divide the normalization prob-
lem into 7 categories, namely; letter case
transformation, replacement rules & lexi-
con lookup, proper noun detection, deasci-
ification, vowel restoration, accent nor-
malization and spelling correction. We
propose a cascaded approach where each
ill formed word passes from these 7 mod-
ules and is investigated for possible trans-
formations. This paper presents the first
results for the normalization of Turkish
and tries to shed light on the different chal-
lenges in this area. We report a 40 per-
centage points improvement over a lexicon
lookup baseline and nearly 50 percentage
points over available spelling correctors.
1 Introduction
With the increasing number of people using micro
blogging sites like Facebook and Twitter, social
media became an indefinite source for machine
learning area especially for natural language pro-
cessing. This service is highly attractive for infor-
mation extraction, text mining and opinion min-
ing purposes as the large volumes of data available
online daily. The language used in this platform
differs severely from formally written text in that,
people do not feel forced to write grammatically
correct sentences, generally write like they talk or
try to impress their thoughts within a limited num-
ber of characters (such as in Twitter 140 charac-
ters). This results with a totally different language
than the conventional languages. The research on
text normalization of social media gained speed
towards the end of the last decade and as always,
almost all of these elementary studies are con-
ducted on the English language. We know from
earlier research results that morphologically rich
languages such as Turkish differ severely from En-
glish and the methods tailored for English do not
fit for these languages. It is the case for text nor-
malization as well.
Highly inflectional or agglutinative languages
share the same characteristic that a unique lemma
in these languages may have hundreds of possible
surface forms. This increases the data sparsity in
statistical models. For example, it?s pointed out in
Hakkani-T?ur et al. (2000) that, it is due to Turk-
ish language?s inflectional and derivational mor-
phology that the number of distinct word forms
is very large compared to English distinct word
size (Table 1). This large vocabulary size is the
reason why the dictionary
1
lookup or similarity
based approaches are not suitable for this kind of
languages. And in addition to this, it is not an
easy task to collect manually annotated data which
could cover all these surface forms and their re-
lated mistakes for statistical approaches.
Corpus Size Turkish English
1M words 106,547 33,398
10M words 417,775 97,734
Table 1: Vocabulary sizes for two Turkish and En-
glish corpora (Hakkani-T?ur et al., 2000)
In this paper, we propose a cascaded approach
for the social text normalization (specifically for
Tweets) of Turkish language. The approach is
a combination of rule based and machine learn-
ing components for different layers of normaliza-
tion, namely; letter case transformation, replace-
ment rules & lexicon lookup, proper noun detec-
tion, deasciification, vowel restoration, accent nor-
malization and spelling correction. Following the
work of Han and Baldwin (2011), we divided the
work into two stages: ill formed word detection
1
For these languages, it is theoretically impossible to put
every possible surface form into a dictionary.
62
and candidate word generation. Our contribution
is: 1. a new normalization model which could be
applied to other morphologically rich languages as
well with appropriate NLP tools 2. the first re-
sults and test data sets for the text normalization
of Turkish.
The paper is structured as follows: Section 2
and 3 give brief information about related work
and morphologically rich languages, Section 4
presents our normalization approach and Section
5 the experimental setup, Section 6 gives our ex-
perimental results and discussions and Section 7
the conclusion.
2 Related Work
An important part of the previous studies have
taken the normalization task either as a lexi-
con lookup (together with or without replacement
rules) or as a statistical problem. There also ex-
ist many studies which use their combination. In
these studies, a lexicon lookup is firstly employed
for most common usage of slang words, abbrevi-
ations etc. and then a machine learning method
is employed for the rest. Zhang et al. (2013) uses
replacement rules and a graph based model in or-
der to select the best rule combinations. Wang and
Ng (2013) uses a beam search decoder. Hassan
and Menezes (2013) propose an unsupervised ap-
proach which uses Random Walks on a contextual
similarity bipartite graph constructed from n-gram
sequences. In Han and Baldwin (2011), word sim-
ilarity and context is used during lexicon lookup.
Cook and Stevenson (2009) uses an unsupervised
noisy channel model. Clark and Araki (2011)
makes dictionary lookup. Liu et al. (2012) uses
a unified letter transformation to generate possi-
ble ill formed words in order to use them in the
training phase of a noisy channel model. Eisen-
stein (2013) analyzes phonological factors in so-
cial media writing.
Others, treating the normalization task as a
machine translation (MT) problem which tries
to translate from an ill formed language to a
conventional one, form also another important
group. For example the papers from Kaufmann
and Kalita (2010), Pennell and Liu (2011), Aw et
al. (2006) and Beaufort et al. (2010) may be col-
lected under this group. Since the emergence of
social media is very recent, only the latest stud-
ies are focused on this area and the earlier ones
generally work for the text normalization in TTS
(text-to-speech), ASR (automatic speech recogni-
tion) systems or SMS messages. Social media nor-
malization poses new challenges on top of these,
for example Twitter statuses contains mentions
(@user name), hashtags (#topic), variant number
of emoticons ( e.g. :) :@ <3 @>? ) and spe-
cial keywords (RT - retweet, DM - direct message
etc.).
Although very rare, there are also some stud-
ies on languages other than English and these
are mostly for speech recognition and SMS mes-
sages , e.g. Panchapagesan et al. (2004) for Hindi
TTS, Nguyen et al. (2010) for Vietnamese TTS,
Jia et al. (2008) for Mandarin TTS, Khan and
Karim (2012) for Urdu SMS. To the best of our
knowledge, our study is the first attempt for the
normalization of social media data for morpholog-
ically rich languages.
3 Morphologically Rich Languages
Morphologically rich languages such as Turkish,
Finnish, Korean, Hebrew etc., pose significant
challenges for natural language processing tasks
(Tsarfaty et al., 2013; Sarikaya et al., 2009). As
stated previously, the highly productive morphol-
ogy of these languages results in a very large num-
ber of word forms from a given stem. Table 2 lists
only a few (among hundreds of possible) surface
forms for the Turkish stem ?ev? (house).
Surface form English
ev house
eve to the house
evde at the house
evdeki (which is) at the house
evdekiler those (who are) at the house
evdekilerde at those (who are)
Table 2: Some surface forms for ?ev? (house)
Sarikaya et al. (2009) list the emerging prob-
lems as below:
1. increase in dictionary size
2. poor language model probability estimation
3. higher out-of-vocabulary (OOV) rate
4. inflection gap for machine translation
2
That is why, the normalization methods pro-
posed so far (adapting MT or language models or
2
Since, the number of possible word surface forms after
inflections is very high, the alignment and translation accura-
cies in these languages are very badly affected.
63
lexicon lookup approaches) do not seem appropri-
ate for the processing of morphologically rich lan-
guages, as in our case for Turkish.
4 The Proposed Architecture
We divide the normalization task into two parts:
Ill-formed word detection and candidate genera-
tion. Figure 1 presents the architecture of the pro-
posed normalization approach. The following sub-
sections provide the details for both of these two
parts and their components.
Before sending the input into these stages, we
first use our tokenizer specifically tailored for
Twitter for splitting the tweets into meaningful to-
kens. Our tokenizer is actually the first step of
our normalization process since: 1. It intelligently
splits the wrongly written word-punctuation com-
binations (e.g. ?a,b? to [a , b]), while leaving ?Ah-
met?den? (from Ahmet) is left as it is since the
apostrophe sign is used to append inflectional fea-
tures to a proper noun.) 2. It does special pro-
cessing for emoticons and consecutive punctua-
tion marks so that they still reside together after
the tokenization (e.g. :D or !!!!! are output as they
occur).
Figure 1: Normalization architecture
4.1 Ill-formed Word Detection
As stated earlier, since it is not possible to use a
lexicon lookup table for morphologically rich lan-
guages, we use a morphological analyzer (S?ahin
et al., 2013) and an abbreviation list
3
and a list of
1045 abbreviations for controlling in-vocabulary
(IV) words (labeled with a +NC ?No Change? la-
bel for further use). By this way, we filter all the
out-of-vocabulary (OOV) words and transfer them
to the candidate generation process. Mentions
(@user name), hashtags (#topic), emoticons (:D) ,
vocatives (?ahahahaha?) and keywords (?RT?) are
also assumed to be OOV words since we want to
detect these and tag them with special labels to be
later used in higher-level NLP modules (e.g. POS
tagging, syntactic analysis).
4.2 Candidate Generation
In the candidate generation part, we have seven
components (rule based or machine learning mod-
els) which work sequentially. The outputs of each
of these components are controlled by the morpho-
logical analyzer and if the normalized form from a
component becomes an IV word then the process
is terminated and the output is labeled with a rele-
vant tag (provided in Table 3). Otherwise, the can-
didate generation process continues with the next
component over the original input (except for the
?Letter Case Transformation? and ?Replacement
Rules & Lexicon Lookup? components where the
input is replaced by the modified output although
it is still not an IV word, (see Section 4.2.1 and
4.2.2 for details).
Label Component
+NC No Change
+LCT Letter Case Transformation
+RR Replacement Rules & Lexicon Lookup
+PND Proper Noun Detection
+DA Deasciification
+VR Vowel Restoration
+AN Accent Normalization
+NoN No Suggested Normalization
Table 3: Component Labels
4.2.1 Letter Case Transformation
An OOV token, coming to this stage, may be in
one of the 4 different forms: lowercase, UPPER-
CASE, Proper Noun Case or miXEd CaSe. If
the token is in lowercase and does not possess
any specific punctuation marks for proper nouns
(i.e. ? (apostrophe) or . (period)) , it is directly
3
obtained from TLA (Turkish Language Association)
http://www.tdk.gov.tr/index.php?option=
com_content&id=198:Kisaltmalar
64
transferred to the next stage without any change
(e.g. umuttan (from hope)). If the token is in
Proper Noun Case (e.g. Umut?tan), it is accepted
as a correct proper noun (even if it does not oc-
cur within the morphological analyzer?s lexicon or
was previously detected as an OOV word), left un-
touched (taking the label +NC) and excluded from
all future evaluations.
For UPPERCASE, miXEd CaSe and lowercase
words, we convert them into Proper Noun Case if
they either contain an apostrophe (which is used
in Turkish to separate inflectional suffixes from a
proper noun) or a period (.) which is used for-
mally in Turkish to denote abbreviations. These
words are labeled with a ?+LCT? label after the
normalization. If the word does not contain any
of these two marks, it is then converted into low-
ercase form and processed by the morphological
analyzer as explained at the beginning of Sec-
tion 4.2. It should be noted that all words going
out from this component towards next stages are
transformed into lowercase from this point on.
?ahmet?ten? ? Proper Noun
?AHMET?TEN? ? Proper Noun
?EACL.?- Abbreviation
4.2.2 Replacement Rules & Lexicon Look-up
While normalizing the tweets, we have to deal
with the following problems:
1. Slang words
2. Character repetition in interjections
3. Twitter-specific words
4. Emo style writing
We created a slang word lexicon of 272 words.
This lexicon contains entries as the following:
?kib? for ?kendine iyi bak? (take care of your-
self ), ?nbr? for ?ne haber? (what?s up). The tokens
within the lexicon are directly replaced with their
normalized forms.
Repetition of some characters within a word is
a very common method to express exclamation
in messages, such as in ?l?utfeeeennnn? instead of
?l?utfen? (please), ?c?ooooooook? instead of ?c?ok?
(very) and ?ayyyyy? instead of ?ay? (oh!). We re-
duce the repeated characters into a single character
in the case that the consecutive occurrence count
is greater than 2.
The usage of Twitter-specific words such as
hashtags (?#topic?), mentions (?@user name?),
emoticons (?:)?), vocatives (?hahahhah?,
?h?o?o?o?o?o?) and keywords (?RT?) also causes
a host of problems. The recurring patterns in
vocatives are reduced into minimal forms during
the normalization process, as for ?haha? instead
of ?hahahhah? and ?h?o? instead of ?h?o?o?o?o?o?.
Emo style writing, as in the example ?$eker
4you? instead of ?s?eker senin ic?in? (sweety, it?s
for you), is another problematic field for the nor-
malization task. We created 35 replacement rules
with regular expressions in order to automatically
correct or label the given input for Twitter-specific
words and Emo style writing. Examples include
?$ ? s??, ? ? e?, ?3 ? e? and ?!? i?.
Through these replacement rules, we are able to
correct most instances of Emo style writing.
Our regular expressions also label the following
token types by the given specific labels for future
reference:
? Mentions: Nicknames that refer
to users on Twitter are labeled as e.g.
@mention[@dida]
? Hashtags: Hashtags that refer to trend-
ing topics on Twitter are labeled as e.g.
@hashtag[#geziparki]
? Vocatives: Vocatives are labeled as e.g.
@vocative[hehe]
? Smileys: Emoticons are labeled as e.g.
@smiley[:)]
? Twitter-specific Keywords: Keywords like
?RT?, ?DM?, ?MT?, ?Reply? etc. are labeled as
e.g. @keyword[RT]
Figure 2 shows the normalized version of a
tweet in informal Turkish that could be translated
like ?@dida what?s up, why don?t you call #of-
fended :(?, before and after being processed by this
component. Although the word ?aram?on? also
needs normalization as ?aram?yorsun? (you don?t
call), this transformation is not realized within the
current component and applied later in the accent
normalization component given in Section 4.2.6.
4.2.3 Proper Noun Detection
As previously stated, all OOV words coming to
this stage are in lowercase. In this component, our
aim is to detect proper nouns erroneously written
in lowercase (such as ?ahmetten? or ?ahmetden?)
and convert them to proper noun case with correct
formatting (?Ahmet?ten? for the aforementioned
examples).
65
@dida

nbr
 
neden

aram?on

#k?r?ld?m

: (

@mention[@dida] ne haber neden aram?on @hashtag[#k?r?ld?m] @smiley[: (]
Figure 2: Normalization with Replacement Rules & Lexicon Look-up
For this purpose, we use proper name gazetteers
from S?eker and Eryi?git (2012) together with a
newly added organization gazetteer of 122 tokens
in order to check whether a given word could
be a proper noun. Turkish proper nouns are
very frequently selected from common nouns such
as ?C?ic?ek? (flower), ?S?eker? (sugar) and ?
?
Ipek?
(silk). Therefore, it is quite difficult to recog-
nize such words as proper nouns when they are
written in lowercase, as the task could not be ac-
complished by just checking the existence of such
words within the gazetteers.
For our proper noun detection component, we
use the below strategy:
1. We reduce the size of the gazetteers by remov-
ing all words with length ? 2 characters, or with
a ratio value under our specified threshold (1.5).
Ratio value is calculated, according to the formula
given in Equation 1, considering the occurrence
counts from two big corpora, the METU-Sabanc?
Treebank (Say et al., 2002) and the web corpus
of Sak et al. (2011). Table 4 gives the counts for
three sample words. One may observe from the
table that ?ahmet? occured 40 times in proper case
and 20 times in lower case form within the two
corpora resulting in a ratio value of 2.0. Since the
ratio value for ?umut? is only 0.4 (which is un-
der our threshold), this noun is removed from our
gazetteers so that it would not be transformed into
proper case in case it is found to occur in low-
ercase form. A similar case holds for the word
?sa?glam? (healthy). Although it is a very frequent
Turkish family name, it is observed in our corpora
mostly as a common noun with a ratio value of
0.09.
ratio(w
n
) =
Occurence in Propercase(w
n
)
Occurence in Lowercase(w
n
)
(1)
2. We pass the tokens to a morphological an-
alyzer for unknown words (S?ahin et al., 2013)
and find possible lemmata as in the example be-
low. We then search for the longest possible stem
within our gazetteers (e.g. the longest stem for
?ahmetten? found within the name gazetteer is
Proper Case Lowercase Sense Ratio
Sa?glam=9 sa?glam=100 healthy Ratio=0.09
Umut=40 umut=100 hope Ratio=0.4
Ahmet=40 ahmet=20 n/a Ratio=2.0
Table 4: Example of Ratio Values
?ahmet?), and when a stem is found within the
gazetteers, the initial letter of the stem is capital-
ized and the inflectional suffixes after the stem are
separated by use of an apostrophe (?Ahmet?ten?).
If none of the possible stems is found within the
gazetteers, the word is left as is and transferred to
the next stage in its original form.
?ahmet +Noun+A3sg+Pnon+Abl?
?ahmette +Noun+A3sg+Pnom+Loc?
?ahmetten +Noun+A3sg+Pnon+Nom?
4.2.4 Deasciification
The role of the deasciifier is the reconstruction of
Turkish-specific characters with diacritics (i.e. ?,
?
I, s?, ?o, c?, ?g, ?u) from their ASCII-compliant coun-
terparts (i.e. i, I, s, o, c, g, u). Most users of so-
cial media use asciified letters, which should be
corrected in order to obtain valid Turkish words.
The task is also not straightforward because of the
ambiguity potential in asciified forms, as between
the words ?yasa? (law) and ?yas?a? (live). For
this stage, we use the deasciifier of Y?uret (Y?uret
and de la Maza, 2006) which implements the
GPA algorithm (which itself is basically a decision
tree implementation) in order to produce the most
likely deasciified form of the input.
4.2.5 Vowel Restoration
There is a new trend of omitting vowels in typ-
ing among the Turkish social media users, in or-
der to reduce the message length. In this stage, we
process tokens written with consonants only (e.g.
?svyrm?), which is how vowel omission often hap-
pens. The aim of the vowel restoration is the gen-
eration of the original word by adding vowels into
the appropriate places (e.g. ?svyrm? to ?seviyo-
rum? (I love)). We employed a vocalizer (Adal?
66
and Eryi?git, 2014) which uses CRFs for the con-
struction of the most probable vocalized output.
4.2.6 Accent Normalization
In the social media platform, people generally
write like they talk by transferring the pronounced
versions of the words directly to the written text.
Eisenstein (2013) also discusses the situation for
the English case. In the accent normalization mod-
ule we are trying to normalize this kind of writings
into proper forms. Some examples are given be-
low:
?gidicem? instead of ?gidece?gim?
(I?ll go)
?geliyonmu?? instead of ?geliyor musun??
(Are you coming?)
In this component, we first try to detect the most
common verb accents (generally endings such as
?-cem, -yom, -c?az? etc.) used in social media and
then uses regular expression rules in order to re-
place these endings with their equivalent morpho-
logical analysis. One should note that since in
most of the morphologically rich languages, the
verb also carries inflections related to the person
agreement, we produce rules for catching all the
possible surface forms of these accents.
Table 5 introduces some of these re-
placement rules (column 1 and column 3).
As a result, the word ?gidcem? becomes
?git+Verb+Pos+Fut+A1sg?
4
. We then use a
morphological generator and takes the cor-
rected output (if any) ?gidece?gim? (I?ll go) for
?git+Verb+Pos+Fut+A1sg?
5
.
We also have more complex replacement rules
in order to process more complex accent problems.
To give an example, the proper form of the word
?gidiyonmu? is actually ?gidiyor musun? (are you
going) and in the formal form it is the question
enclitic (?mu?) which takes the person agreement
(?-sun? 2. person singular) where as in the accent
form the person agreement appears before ?mu? as
a single letter ?gidiyonmu?.
4
Please note that, we also change the last letter of the stem
according to the harmonization rules of Turkish: the last let-
ters ?bcdg? are changed to ?pc?tk?.
5
the morphological tags in the table stands for: +Pos:
Positive, +Prog1: Present continuous tense, +A2sg: 2. per-
son singular, +Fut: Future tense, +A1sg: 1. person singular,
+A1pl: 1. person plural
Accent Correct Morph.
endings endings Analysis
+iyon +iyorsun +Verb+Pos+Prog1+A2sg
+cem +ece?gim +Verb+Pos+Fut+A1sg
+caz +aca?g?z +Verb+Pos+Fut+A1pl
Table 5: Accent Normalization Replacement
Rules
4.2.7 Spelling Correction
As the last component of our normalization ap-
proach, we propose to use a high performance
spelling corrector. This spelling corrector should
especially give a high precision score rather than
recall since the false positives have a very harm-
ing effect on the normalization task by producing
outputs with a totally different meaning. Unfortu-
nately, we could not find such a corrector for Turk-
ish. We tested with an MsWord plugin and the
spelling corrector of Zemberek (Ak?n and Ak?n,
2007) and obtained a negative impact by using
both. We are planning to create such a spelling
corrector as future work.
If an OOV word couldn?t still be normalized at
the end of the proposed iterative model (consisting
7 components), it is labeled with a ?+NoN? label
and left in its original input format.
5 Experimental Setup
In this section we provide information about our
used data sets, our evaluation strategy and the used
models in the experiments.
5.1 Data Sets
To test our success rates, we used a total of 1,200
tweets aligned and normalized manually. The
manual alignment is a one-to-many token align-
ment task from the original input towards the nor-
malized forms. To give an example, the slang us-
age ?kib? will be aligned to 3 tokens (?kendine
iyi bak? (take care of yourself )) on the normal-
ized tweet. Although there are cases for many-to-
one alignment (such as in ?cats,dogs?), these are
handled in the tokenization stage before the nor-
malization. We used half of this data set as our
validation set during the development of our pro-
posed components and reserved the remaining 600
tweets (collected from a different time slot) as a to-
tally unseen data set for using at the end. Table 6
provides some statistics over these data sets: the
number of tweets, the number of tokens and the
67
Data Sets # Tweets # Tokens # OOV
Validation Set 600 6,322 2,708
Test Set 600 7,061 2,192
Table 6: Description of the Data Sets
number of OOV tokens.
Besides the aforementioned datasets, we also
had access to a much bigger Twitter data set
consisting of 4,049 manually normalized tweets
(Eryi?git et al., 2013) (59,012 tokens in total). The
only difference of this data set is that the tweets
are not aligned on token level as in the previously
introduced data sets. That is why, it is not possi-
ble to use them for gold standard evaluation of our
system. But in order to be able to have an idea
about the performance of the previous approaches
regarding lexicon lookup, we decided to automat-
ically align this set and create a baseline lexicon
lookup model for comparison purposes. (see the
details in Section 5.3).
5.2 Evaluation Method
We evaluated our work both for ill formed word
detection and candidate generation separately. For
ill formed word detection, we provide precision
(P), recall (R), f-measure (F) and accuracy (Acc.)
scores. For candidate generation, we provide only
the accuracy scores (the number of correctly nor-
malized tokens over the total number of detected
ill formed words).
5.3 Compared Models
To the best of our knowledge this study is the
first attempt for the normalization of Turkish so-
cial media data. Since there are only spelling cor-
rector systems available for the task we compared
the proposed model with them. In other words, we
compared 3 different models with our proposed
system:
Model 1 (MsWord) is the model where we use an
api for getting the MsWord Turkish spelling sug-
gestions. Although this is not a tool developed for
normalization purposes we wanted to see its suc-
cess on our data sets. We accepted the top best
suggestion as the normalized version for the input
tokens.
Model 2 (Zemberek) (Ak?n and Ak?n, 2007) is also
an open source spelling corrector for Turkish.
Model 3 (Lookup Table) is a model that we devel-
oped with the aim of creating a baseline lookup
approach for comparison. For this purpose, we
first used GIZA++ (Och and Ney, 2000) in order
to automatically align the normalized tweets (us-
ing the 4,049 tweets? data set presented in Sec-
tion 5.1) and created a lookup table with the pro-
duced aligned token sequences. We then used this
lookup table to check for the existence of each ill
formed word and get its normalized counterpart.
6 Experimental Results
Table 7 and Table 8 gives the results of the ill
formed word detection for different systems for
the validation set and the test set consecutively. In
these experiments, we do not provide the results of
the ?Lookup Table? model since the ill formed de-
tection part of it is exactly the same with our pro-
posed model. For MsWord and Zemberek we con-
sidered each modified word as an ill formed word
detected by that system. We can see from the ta-
bles that our proposed model has an f-measure of
ill formed word detection 0.78. As it is explained
in Section 4.1, our ill formed word detection ap-
proach is very straightforward and it uses only a
morphological analyzer and an abbreviation list
in order to detect OOV words. Thus, one may
wonder why the scores for the proposed model
are not very close to 1 although it outperforms
all of its available rivals. This is because, there
exists nearly 20% of the ill formed tokens which
are not suspended to our morphological filter al-
though they are manually annotated as ill formed
by human annotators. This is certainly possible
for morphologically rich languages since a word
surface form may be the valid analysis of many
stems. The ill formed word ?c?al?s??c?m? is a good
example for this situation. Although this word
will be understood by most of the people as the ill
formed version of the word ?c?al?s?aca?g?m? (I?m go-
ing to work), it is considered by the morphological
analyzer as a valid Turkish word since although
very rare, it could also be the surface form of
the word ?c?al?s?? with additional derivational and
inflectional suffixes ?c?al?s?+?c?+m? meaning ?my
worker?.
Systems P R F Acc.
MsWord 0.25 0.59 0.35 0.58
Zemberek 0.21 0.17 0.19 0.21
Proposed Model 0.75 0.81 0.78 0.80
Table 7: Ill Formed Word Detection Evaluation
Results on Validation Set
68
Systems P R F Acc.
MsWord 0.24 0.19 0.21 0.56
Zemberek 0.11 0.29 0.20 0.11
Proposed Model 0.71 0.72 0.71 0.86
Table 8: Ill Formed Word Detection Evaluation
Results on Test Set
Data Set Systems Accuracy
MsWord 0.25
Validation Set Zemberek 0.21
Lookup Table 0.34
Proposed Model 0.75
MsWord 0.24
Test Set Zemberek 0.11
Lookup Table 0.31
Proposed Model 0.71
Table 9: Candidate Generation Results on Data
Sets
Table 9 gives the evaluation scores of each dif-
ferent system for both the validation and test data
sets. Although the lookup model is very basic,
one can observe from the table that it outperforms
both MsWord and Zemberek. Our proposed iter-
ative model obtains the highest scores (75% for
validation and 71% for test sets) with a relative
improvement of 40 percentage points over the lex-
icon lookup baseline.
7 Conclusion
In this paper we presented a cascaded normaliza-
tion model for Turkish which could also be applied
to the morphologically rich languages with appro-
priate NLP tools. The model has two main parts:
ill formed word detection and candidate word gen-
eration consisting of 7 normalization stages (let-
ter case transformation, replacement rules & lex-
icon lookup, proper noun detection, deasciifica-
tion, vowel restoration, accent normalization and
spelling correction) executed sequentially one on
top of the other one. We present the first and high-
est results for Turkish text normalization
6
of so-
cial media data with a 86% accuracy of ill formed
word detection and 71% accuracy for candidate
word generation. A morphological analyzer is
used for the detection of ill formed words. But
we believe the accuracy of this first detection stage
6
The produced test sets and the Web interface of the
Turkish Normalizer is available via http://tools.nlp.itu.edu.tr
(Eryi?git, 2014)
may be improved by the addition of a lexicon
lookup (before the morphological filter) consisting
the most frequent normalization cases extracted
from manually normalized data if available. Thus,
as a future work we plan to extend our work both
on the ill formed word detection and on the cre-
ation of a spelling corrector with social web data
in focus.
Acknowledgment
This work is part of our ongoing research project
?Parsing Turkish Web 2.0 Sentences? supported
by ICT COST Action IC1207 TUBITAK 1001
(grant no: 112E276). The authors want to thank
Turkcell Global Bilgi for sharing the manually
normalized data of user comments from the Tele-
com domain. We also want to thank Ozan Arkan
Can for his valuable discussions and helps during
the data preparation.
References
K?ubra Adal? and G?uls?en Eryi?git. 2014. Vowel and
diacritic restoration for social media texts. In 5th
Workshop on Language Analysis for Social Media
(LASM) at EACL, Gothenburg, Sweden, April. As-
sociation for Computational Linguistics.
Ahmet Afsin Ak?n and Mehmet D?undar Ak?n. 2007.
Zemberek, an open source nlp framework for turkic
languages. Structure.
AiTi Aw, Min Zhang, Juan Xiao, and Jian Su. 2006.
A phrase-based statistical model for sms text nor-
malization. In Proc. of the COLING/ACL on
Main conference poster sessions, COLING-ACL
?06, pages 33?40, Stroudsburg, PA, USA. Associ-
ation for Computational Linguistics.
Richard Beaufort, Sophie Roekhaut, Louise-Am?elie
Cougnon, and C?edrick Fairon. 2010. A hybrid
rule/model-based finite-state framework for normal-
izing sms messages. In Proc. of the 48th Annual
Meeting of the Association for Computational Lin-
guistics, ACL ?10, pages 770?779, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Eleanor Clark and Kenji Araki. 2011. Text normal-
ization in social media: progress, problems and ap-
plications for a pre-processing system of casual en-
glish. Procedia-Social and Behavioral Sciences,
27:2?11.
Paul Cook and Suzanne Stevenson. 2009. An
unsupervised model for text message normaliza-
tion. In Proc. of the Workshop on Computational
Approaches to Linguistic Creativity, CALC ?09,
pages 71?78, Stroudsburg, PA, USA. Association
for Computational Linguistics.
69
Jacob Eisenstein. 2013. Phonological factors in social
media writing. In Proc. of the Workshop on Lan-
guage Analysis in Social Media, pages 11?19, At-
lanta, Georgia, June. Association for Computational
Linguistics.
G?uls?en Eryi?git, Fatih Samet C?etin, Meltem Yan?k,
Tanel Temel, and
?
Iyas C?ic?ekli. 2013. Turksent:
A sentiment annotation tool for social media. In
Proc. of the 7th Linguistic Annotation Workshop
and Interoperability with Discourse, pages 131?134,
Sofia, Bulgaria, August. Association for Computa-
tional Linguistics.
G?uls?en Eryi?git. 2014. ITU Turkish NLP web service.
In Proc. of the Demonstrations at the 14th Confer-
ence of the European Chapter of the Association
for Computational Linguistics (EACL), Gothenburg,
Sweden, April. Association for Computational Lin-
guistics.
Dilek Z. Hakkani-T?ur, Kemal Oflazer, and G?okhan T?ur.
2000. Statistical morphological disambiguation for
agglutinative languages. In Proc. of the 18th confer-
ence on Computational linguistics - Volume 1, COL-
ING ?00, pages 285?291, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Bo Han and Timothy Baldwin. 2011. Lexical normali-
sation of short text messages: Makn sens a #twitter.
In Proc. of the 49th ACL HLT, pages 368?378, Port-
land, Oregon, USA, June. Association for Computa-
tional Linguistics.
Hany Hassan and Arul Menezes. 2013. Social text nor-
malization using contextual graph random walks. In
Proc. of the 51st ACL, pages 1577?1586, Sofia, Bul-
garia, August. Association for Computational Lin-
guistics.
Yuxiang Jia, Dezhi Huang, Wu Liu, Shiwen Yu, and
Haila Wang. 2008. Text normalization in Mandarin
text-to-speech system. In ICASSP, pages 4693?
4696. IEEE.
Max Kaufmann and Jugal Kalita. 2010. Syntactic nor-
malization of Twitter messages. In Proc. of the 8
th
International Conference on Natural Language Pro-
cessing (ICON 2010), Chennai, India. Macmillan In-
dia.
Osama A Khan and Asim Karim. 2012. A rule-based
model for normalization of sms text. In Tools with
Artificial Intelligence (ICTAI), 2012 IEEE 24th In-
ternational Conference on, volume 1, pages 634?
641. IEEE.
Fei Liu, Fuliang Weng, and Xiao Jiang. 2012. A
broad-coverage normalization system for social me-
dia language. In Proc. of the 50th ACL, pages 1035?
1044, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
Thu-Trang Thi Nguyen, Thanh Thi Pham, and Do-Dat
Tran. 2010. A method for vietnamese text normal-
ization to improve the quality of speech synthesis.
In Proc. of the 2010 Symposium on Information and
Communication Technology, SoICT ?10, pages 78?
85, New York, NY, USA. ACM.
Franz Josef Och and Hermann Ney. 2000. Giza++:
Training of statistical translation models.
K Panchapagesan, Partha Pratim Talukdar, N Sridhar
Krishna, Kalika Bali, and AG Ramakrishnan. 2004.
Hindi text normalization. In Fifth International
Conference on Knowledge Based Computer Systems
(KBCS), pages 19?22. Citeseer.
Deana Pennell and Yang Liu. 2011. A character-level
machine translation approach for normalization of
sms abbreviations. In IJCNLP, pages 974?982.
Muhammet S?ahin, Umut Sulubacak, and G?uls?en
Eryi?git. 2013. Redefinition of turkish morphology
using flag diacritics. In Proc. of The Tenth Sym-
posium on Natural Language Processing (SNLP-
2013), Phuket, Thailand, October.
Has?im Sak, Tunga G?ung?or, and Murat Sarac?lar. 2011.
Resources for Turkish morphological processing.
Lang. Resour. Eval., 45(2):249?261, May.
Ruhi Sarikaya, Katrin Kirchhoff, Tanja Schultz, and
Dilek Hakkani-Tur. 2009. Introduction to the spe-
cial issue on processing morphologically rich lan-
guages. Trans. Audio, Speech and Lang. Proc.,
17(5):861?862, July.
Bilge Say, Deniz Zeyrek, Kemal Oflazer, and Umut
?
Ozge. 2002. Development of a corpus and a tree-
bank for present-day written Turkish. In Proc. of the
Eleventh International Conference of Turkish Lin-
guistics, Famaguste, Cyprus, August.
G?okhan Ak?n S?eker and G?uls?en Eryi?git. 2012. Initial
explorations on using CRFs for Turkish named en-
tity recognition. In Proc. of COLING 2012, Mum-
bai, India, 8-15 December.
Reut Tsarfaty, Djam?e Seddah, Sandra K?ubler, and
Joakim Nivre. 2013. Parsing morphologically rich
languages: Introduction to the special issue. Com-
putational Linguistics, 39(1):15?22.
Pidong Wang and Hwee Tou Ng. 2013. A beam-
search decoder for normalization of social media
text with application to machine translation. In
Proc. of NAACL-HLT, pages 471?481.
Deniz Y?uret and Michael de la Maza. 2006. The
greedy prepend algorithm for decision list induc-
tion. In Proc. of the 21st international conference
on Computer and Information Sciences, ISCIS?06,
pages 37?46, Berlin, Heidelberg. Springer-Verlag.
Congle Zhang, Tyler Baldwin, Howard Ho, Benny
Kimelfeld, and Yunyao Li. 2013. Adaptive parser-
centric text normalization. In Proc. of the 51st ACL,
pages 1159?1168, Sofia, Bulgaria, August. Associa-
tion for Computational Linguistics.
70
