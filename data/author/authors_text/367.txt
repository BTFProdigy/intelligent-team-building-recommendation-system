Chinese Sketch Engine and 
the Extraction of Grammatical Collocations
Chu-Ren Huang  
Inst. of Linguistics  
Academia Sinica  
churen@sinica.edu.tw
Adam Kilgarriff 
Lexicography MasterClass 
Information Technology  
adam@lexmasterclass.com 
Yiching Wu 
Inst. of Linguistics 
Tsing Hua University 
d898702@oz.nthu.edu.tw 
Chih-Ming Chiu 
Inst. of Information Science 
Academia Sinica 
henning@hp.iis.sinica.edu.tw 
Simon Smith 
Dept. of Applied English 
Ming Chuan University 
ssmith@mcu.edu.tw 
Pavel Rychly 
Faculty of Informatics 
Masaryk University. 
pary@textforge.cz 
Ming-Hong Bai 
Inst. of Information Science 
Academia Sinica 
mhbai@sinica.edu.tw 
Keh-Jiann Chen 
Inst. of Information Science 
Academia Sinica 
kchen@iis.sinica.edu.tw
Abstract. This paper introduces a new 
technology for collocation extraction in Chinese. 
Sketch Engine (Kilgarriff et al, 2004) has 
proven to be a very effective tool for automatic 
description of lexical information, including 
collocation extraction, based on large-scale 
corpus. The original work of Sketch Engine was 
based on BNC. We extend Sketch Engine to 
Chinese based on Gigaword corpus from LDC. 
We discuss the available functions of the 
prototype Chinese Sketch Engine (CSE) as well 
as the robustness of language-independent 
adaptation of Sketch Engine. We conclude by 
discussing how Chinese-specific linguistic 
information can be incorporated to improve the 
CSE prototype.  
1. Introduction 
The accessibility to large scale corpora, at 
one billion words or above, has become both a 
blessing and a challenge for NLP research. How 
to efficiently use a gargantuan corpus is an 
urgent issue concerned by both users and corpora 
designers. Adam Kilgarriff et al (2004) 
developed the Sketch Engine to facilitate 
efficient use of corpora. Their claims are two 
folded: that genuine linguistic generalizations 
can be automatically extracted from a corpus 
with simple collocation information provided 
that the corpus is large enough; and that such a 
methodology is easily adaptable for a new 
language. The first claim was fully substantiated 
with their work on BNC. The current paper deals 
with the second claim by adapting the Sketch 
Engine to Chinese.  
2. Online Chinese Corpora: The State of 
the Arts 
2.1 Chinese Corpora 
The first online tagged Chinese corpus is 
Academia Sinica Balanced Corpus of Modern 
Chinese (Sinica Corpus), which has been 
web-accessible since November, 1996. The 
current version contains 5.2028 million words 
(7.8927 million characters). The corpus data was 
collected between 1990 and 1996 (CKIP, 
1995/1998). Two additional Chinese corpora 
were made available on line in 2003. The first is 
the Sinorama Chinese-English Parallel Text 
Corpus (Sinorama Corpus). The Sinorama 
Corpus is composed of 2,373 parallel texts in 
both Chinese and English that were published 
between 1976 and 2000. There are 103,252 pairs 
of sentences, composed of roughly 3.2 million 
48
English words and 5.3 million Chinese 
characters 1 . The second one is the modern 
Chinese corpus developed by the Center for 
Chinese Linguistics (CCL Corpus) at Peking 
University. It contains eighty-five million 
(85,398,433) simplified Chinese characters 
which were published after 1919 A.D. 
2.2 Extracting Linguistic Information from 
Online Chinese Corpora: Tools and Interfaces 
The Chinese corpora discussed above are 
all equipped with an online interface to allow 
users to extract linguistic generalizations. Both 
Sinica Corpus and CCL Corpus offer 
KWIC-based functions, while Sinorama Corpus 
gives sentence and paragraph aligned output. 
2.2.1 String Matching or Word Matching 
The basic unit of query that a corpus allows 
defines the set of information that can be 
extracted from that corpus. While there is no 
doubt that segmented corpus allows more precise 
linguistic generalizations, string-based 
collocation still afford a corpus of the robustness 
that is not restricted by an arbitrary word-list or 
segmentation algorithm. This robustness is of 
greatest value when extracting neologism or 
sub-lexical collocations. Since CCL Corpus is 
not segmented and tagged, string-based KWIC is 
its main tool for extracting generalizations. This 
comes with the familiar pitfall of word boundary 
ambiguity. For instance, a query of ci.yao ??
?secondary? may yield the intended result (la), as 
well as noise (1b). 
1a. ??????
dan zhe shi ci.yao de 
but this is secondary DE
1http://cio.nist.gov/esd/emaildir/lists/mt_list/msg0003
3.html 
?But this is secondary? 
 b. ????????!
ta ji ci yao.qiu ta da.fu 
he several time ask her answer 
?He had asked her to answer for several times? 
 Sinica Corpus, on the other hand, is fully 
segmented and allows word-based 
generalizations. In addition, Sinica Corpus also 
allows wildcards in its search. Users specify a 
wildcard of arbitrary length (*), or fixed length 
(?). This allows search of a class of words 
sharing some character strings.
2.2.2 Display of Extracted Data 
Formal restriction on the display of 
extracted data also constraints the type of 
information that can be obtained from that 
corpus. Sinica Corpus allows users to change 
window size from about 25 to 57 Chinese 
characters. However, since a Chinese sentence 
may be longer than 57 characters, Sinica Corpus 
cannot guarantee that a full sentence is displayed. 
CCL Corpus, on the other hand, is able to show a 
full output sentence, which may be up to 200 
Chinese characters. However, it does not display 
more than a full sentence. Thus it cannot show 
discourse information. Sinorama Corpus with 
TOTALrecall interface is most versatile in this 
respect. Aligned bilingual full sentences are 
shown with an easy link to the full text. 
In terms of size and completeness of 
extracted data, Sinica Corpus returns all matched 
examples. However, cut and paste must be 
performed for the user to build his/her dataset. 
CCL Corpus, on the other hand, limits data to 
500 lines per page, but allows easy download of 
output data. Lastly, Sinorama/TOTALrecall 
provides choices of 5 to 100 sentences per page. 
49
2.2.3 Refining Extracted Information: Filter 
and Sorter 
Both Sinica Corpus and CCL corpus allows 
users to process extracted information, using 
linguistic and contextual filter or sorter. The CCL 
corpus requires users to remember the rules, 
while Sinica Corpus allows users to fill in blanks 
and/or choose from pull-down menu. In 
particular, Sinica Corpus allows users to refine 
their generalization by quantitatively 
characterizing the left and right contexts. The 
quantitative sorting functions allowed include 
both word and POS frequency, as well as word 
mutual information.  
2.2.4 Extracting Grammatical Information 
Availability of grammatical information 
depends on corpus annotation. CCL and 
Sinorama Corpus do not have POS tags. Sinica 
Corpus is the only Chinese corpus allowing users 
to access an overview of a keyword?s syntactic 
behavior. Users can obtain a list of types and 
distribution of the keyword?s syntactic category. 
In addition, users can find possible collocations 
of the keyword from the output of Mutual 
Information (MI).  
The most salient grammatical information, 
such as grammatical functions (subject, object, 
adjunct etc.) is beyond the scope of the 
traditional corpus interface tools. Traditional 
corpora rely on the human users to arrive at these 
kinds of generalizations.
3. Sketch Engine: A New Corpus-based 
approach to Grammatical Information  
Several existing linguistically annotated 
corpus of Chinese, e.g. Penn Chinese Tree Bank 
(Xia et al, 2000), Sinica Treebank (Chen et al, 
2003), Proposition Bank (Xue and Palmer, 2003, 
2005) and Mandarin VerbNet (Wu and Liu, 
2003), suffer from the same problem. They are 
all extremely labor-intensive to build and 
typically have a narrow coverage. In addition, 
since structural assignment is theory-dependent 
and abstract, inter-annotator consistency is 
difficult to achieve. Since there is also no general 
consensus on the annotation scheme in Chinese 
NLP and linguistics, building an effective 
interface for public use is almost impossible. 
The Sketch Engine offers an answer to the 
above issues.
3.1 Initial Implementation and Design of the 
Sketch Engine 
The Sketch Engine is a corpus processing 
system developed in 2002 (Kilgarriff and 
Tugwell, 2002; Kilgarriff et al, 2004). The main 
components of the Sketch Engine are KWIC 
concordances, word sketches, grammatical 
relations, and a distributional thesaurus. In its 
first implementation, it takes as input basic BNC 
(British National Corpus, (Leech, 1992)) data: 
the annotated corpus, as well as list of lemmas 
with frequencies. In other words, the Sketch 
Engine has a relatively low threshold for the 
complexity of input corpus. 
The Sketch Engine has a versatile query 
system. Users can restrict their query in any 
sub-corpus of BNC. A query string may be a 
word (with or without POS specification), or a 
phrasal segment. A query can also be performed 
using Corpus Query Language (CQL). The 
output display format can be adjusted, and the 
displayed window of a specific item can be 
freely expanded left and right. Most of all, the 
Sketch Engine produces a Word Sketch 
(Kilgarriff and Tugwell, 2002) that is an 
automatically generated grammatical description 
of a lemma in terms of corpus collocations. All 
items in each collocation are linked back to the 
original corpus data. Hence it is similar to a 
50
Linguistic Knowledge Net anchored by a lexicon 
(Huang et al, 2001). 
 A Word Sketch is a one-page list of a 
keyword?s functional distribution and collocation 
in the corpus. The functional distribution 
includes: subject, object, prepositional object, 
and modifier. Its collocations are described by a 
list of linguistically significant patterns in the 
language. Word Sketch uses regular expressions 
over POS-tags to formalize rules of collocation 
patterns, e.g. (2) is used to retrieve the 
verb-object relation in English:
2. 1:?V? ?(DET|NUM|ADJ|ADV|N)?* 2:?N? 
The expression in (2) says: extract the data 
containing a verb followed by a noun regardless 
of how many determiners, numerals, adjectives, 
adverbs and nouns preceding the noun. It can 
extract data containing cook meals and cooking a 
five-course gala dinner, and cooked the/his/two 
surprisingly good meals etc.
The Sketch Engine also produces thesaurus 
lists, for an adjective, a noun or a verb, the other 
words most similar to it in their use in the 
language (Kilgarriff et al 2004). For instance, 
the top five synonym candidates for the verb kill
are shoot (0.249), murder (0.23), injure (0.229), 
attack (0.223), and die (0.212).2 It also provides 
direct links to the Sketch Difference which lists 
the similar and different patterns between a 
keyword and its similar word. For example, both 
kill and murder can occur with objects such as 
people and wife, but murder usually occurs with 
personal proper names and seldom selects animal 
nouns as complement whereas kill can take fox,
whale, dolphin, and guerrilla, etc. as its object. 
 The Sketch Engine adopts Mutual 
2 The similarity is measured and ranked adopting 
Lin?s (1998) mathematics. 
Information (MI) to measure the salience of a 
collocation. Salience data are shown against each 
collocation in Word Sketches and other Sketch 
Engine output. MI provides a measure of the 
degree of association of a given segment with 
others. Pointwise MI, calculated by Equation 3, 
is what is used in lexical processing to return the 
degree of association of two words x and y (a 
collocation).
3. 
)(
)|(log);(
xP
yxPyxI  
3.2 Application to Chinese Corpus 
In order to show the cross-lingual 
robustness of the Sketch Engine as well as to 
propose a powerful tool for collocation 
extraction based on a large scale corpus with 
minimal pre-processing; we constructed Chinese 
Sketch Engine (CSE) by loading the Chinese 
Gigaword to the Sketch Engine (Kilgarriff et al, 
2005). The Chinese Gigaword contains about 
1.12 billion Chinese characters, including 735 
million characters from Taiwan?s Central News 
Agency, and 380 million characters from China?s 
Xinhua News Agency3. Before loading Chinese 
Gigaword into Sketch Engine, all the simplified 
characters were converted into traditional 
characters, and the texts were segmented and 
POS tagged using the Academia Sinica 
segmentation and tagging system (Huang et al, 
1997). An array of machine was used to process 
the 1.12 million characters, which took over 3 
days to perform. All components of the Sketch 
Engine were implemented, including 
Concordance, Word Sketch, Thesaurus and 
Sketch Difference.  
 In our initial in-house testing of this 
prototype of the Chinese Sketch Engine, it does 
3http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?
catalogId=LDC2003T09 
51
produce the expected results with an easy to use 
interface. For instance, the Chinese Word Sketch 
correctly shows that the most common and 
salient object of dai.bu ??  ?to arrest? is
xian.fan ??  ?suspect?; the most common 
subject jing.fang ??!?police?; and the most 
common modifier dang.chang??.
 The output data of Thesaurus correctly 
verify the following set of synonyms from the 
Chinese VerbNet Project: that ren.wei ???to
think? behaves most like biao.shi ??  ?to 
express, to state? (salience 0.451), while yi.wei?
? ?to take somebody/something as? is more like 
jue.de?? ?to feel, think? (salience 0.488). The 
synonymous relation can be illustrated by (4) and 
(5).
4a. ????????????????????
?????????????????
ta ren.wei dao hai.wai tou.zi you yi ge guan.nian 
hen zhong.yao, jiu shi yao zhi.dao dang.di de 
you.xi gui.ze 
?He believes that for those investing overseas, 
there is a very important principle-one must know 
the local rules of the game, and accept them.? 
 b. ????????????????????
?????!
zhi.zheng.dang ye biao.shi, you.yu gong.shi 
zheng.yi tai da, kong.pa wu.fa quan.li zhi.chi 
?The KMT also commented that due to the many 
controversies surrounding PTV, it could not 
wholeheartedly support it either.? 
5a. ?????????????????????
????????
he.jia.ju jiu ren.wei??dian.shi you ji.ben yu.yan 
he wen.fa, yao jiang.jiu mai.dian he shi.chang??
?Ho Chia-chu says, "Television has its own 
fundamental language and grammar. You must 
consider selling points and the market."? 
b. ?????????????????????
???????????
ta biao.shi??wo xi.wang fuo.jiao.tu neng liao.jie, 
fu.quan she.hui yu jue.wu de she.hui shi bu 
xiang.he de??
?She says "I hope that followers of Buddhism can 
realize that a patriarchal society is incompatible 
with an enlightened society."? 
The above examples show that ren.wei and 
biao.shi can take both direct and indirect 
quotation. Yi.wei and jue.de, on the other hand, 
can only be used in reportage and cannot 
introduce direct quotation. 
Distinction between near synonymous pairs 
can be obtained from Sketch Difference. This 
function is verified with results from Tsai et al?s 
study on gao.xing?? ?glad? and kuai.le??!
?happy? (Tsai et al, 1998). Gao.xing ?glad? 
specific patterns include the negative imperative 
bie? ?don?t?. It also has a dominant collocation 
with the potentiality complement marker de?
(e.g. ta gao.xing de you jiao you tiao ????
???? ?she was so happy that she cried and 
danced?). In contrast, kuai.le ?happy? has the 
specific collocation with holiday nouns such as 
qiu.jie ??  ?Autumn Festival?. The Sketch 
Difference result is consistent with the account 
that gao.xing/kuai.le contrast is that inchoative 
state vs. homogeneous state. 
4. Evaluation and Future Developments 
An important feature of the prototype of the 
Chinese Sketch Engine is that, in order to test the 
robustness of the Sketch Engine design, the 
original regular expression patterns were adopted 
with minimal modification for Chinese. Even 
though both are SVO languages with similar 
surface word order, it is obvious that they differ 
substantially in terms of assignment of 
grammatical functions. In addition, the Sinica 
tagset is different from the BNC tagset and 
52
actually has much richer functional information. 
These are the two main directions that we will 
pursue in modification and improvement of the 
Chinese Sketch Engine. 
4.1 Word Boundary Representation 
Word breaks are not conventionalized in 
Chinese texts. This poses a challenge in Chinese 
language processing. The Chinese Sketch Engine 
inserted space after segmentation, which helps to 
visualize words. In the future, it will be trivial to 
allow the conventional alternative of no word 
boundary markups. However, it will not be trivial 
to implement fuzzy function to allow searches 
for non-canonical lemmas (i.e. lemmas that are 
segmented differently from the standard corpus). 
4.2 Sub-Corpora Comparison  
The Chinese Gigaword corpus is marked 
with two different genres, story and non-story. A 
still more salient sub-corpus demarcation is the 
one between Mainland China corpus and Taiwan 
corpus. Sketch Difference between lemmas form 
two sub-corpora is being planned. This would 
allow future comparative studies and would have 
wide applications in the localization adaptations 
of language related applications.  
4.3 Collating Frequency Information with 
POS
One of the convenient features of Sketch 
Engine that a frequency ranked word list is 
linked to all major components. This allows a 
very easy and informative reference. Since 
cross-categorical derivation with zero 
morphology is dominant in Chinese, it would 
help the processing greatly if POS information is 
added to the word list. Adding such information 
would also open the possibility of accessing the 
POS ranked frequency information. 
4.5 Fine-tuning Collocation Patterns  
The Sketch Engine relies on collocation 
patterns, such as (2) above, to extract 
collocations. The regular expression format 
allows fast processing of large scale corpora with 
good results. However, these patterns can be 
fine-tuned for better results. We give VN 
collocates with object function as example here. 
In (6), verbs are underlined with a single line, 
and the collocated nouns identified by English 
Word Sketch are underlined with double lines. 
Other nominal objects that the Sketch Engine 
misses are marked with a dotted line. 
6.a. In addition to encouraging kids to ask, think and 
do, parents need to be tolerant and appreciative to 
avoid killing a child's creative sense.
b. Children are taught to love their parents,
classmates, animals, nature . . . . in fact they are 
taught to love just about everything except to 
love China, their mother country. 
c. For example, the government deliberately chose 
not to teach Chinese history and culture, nor 
civics, in the schools. 
d. At the game there will be a lottery drawing for a 
motorcycle! And perhaps you'll catch a foul ball
or a home run.
The sentences in (6) show that the current Sketch 
Engine tend to only identify the first object when 
there are multiple objects. The resultant 
distributional information thus obtained will be 
valid given a sufficiently large corpus. However, 
if the collocation patterns are fine-tuned to allow 
treatment of coordination, richer and more 
precise information can be extracted. 
 A regular expression collocation pattern 
also runs the risk of mis-classification. For 
instance, speech act verbs often allow subject to 
occur in post-verbal positions, and intransitive 
53
verbs can often take temporal nouns in 
post-verbal positions too.  
7. a. ?you can say goodbye to your competitive 
career. 
b. `No,' said Scarlet, `but then I don't notice much.'
8. a. Where did you sleep last night?
  b. ?it arrived Thursday morning.
  c. From Arty's room came the sound of an 
accordion.
9. `I'll look forward to that.' `So will I.' 
Such non-canonical word orders are even more 
prevalent in Chinese. Chinese objects often occur 
in pre-verbal positions in various pre-posing 
constructions, such as topicalization. 
10. ???????????
quan.gu mian.bao, chi le hen jian.kang 
whole-grain bread, eat LE very healthy 
?Eating whole-grain bread is very healthy.? 
11a. ??????????????????
you ren chang.shi yao jiang zhe he.hua fen.lei,
que yue fen yue lei 
someone try to JIANG the lotus classify, but more 
classify more tired 
?People have tried to decide what category the 
lotus belongs in, but have found the effort 
taxing.? 
b. ??????????
wo yi.ding yao ba lao.da chu.diao
I must want BA the oldest (son) get rid of
?I really want to get rid of the older son.?
When objects are pre-posed, they tend to stay 
closer to the verb than the subject. Adding object 
marking information, such as ba?, jiang?, lian
?  would help correctly identify collocating 
pre-posed objects. However, for those unmarked 
pre-posed structures, closeness to the verb may 
not provide sufficient information. Several rules 
will need to be implemented jointly.  
 The above example underlines a critical 
issue. That is, whether relative position alone is 
enough to identify positional information. The 
Sketch Engine is in essence a powerful tool 
extracting generalizations from annotated corpus 
data. We have shown that it can extract useful 
grammatical information with POS tag alone. If 
the corpus is tagged with richer annotation, the 
Sketch Engine should be able to extract even 
richer information. 
 The Sinica Corpus tagset adapts to the fact 
that Chinese has a freer word order than English 
by incorporating semantic information with the 
grammatical category. For instance, locational 
and temporal nouns, proper nouns, and common 
nouns each are assigned a different tag. Verbs are 
sub-categorized according to activity and 
transitivity. Such information is not available in 
the BNC tagset and hence not used in the 
original Sketch Engine design. We will enrich the 
collocation patterns with the annotated linguistic 
information from the Sinica Corpus tagset. In 
particular, we are converting ICG lexical 
subcategorization frames (Chen and Huang 1990) 
to Sketch Engine collocation patters. These ICG 
frames, called Basic Patterns and Adjunct 
Patterns, have already been fully annotated 
lexically and tested on the Sinica Corpus. We 
expect their incorporation to improve Chinese 
Sketch Engine results markedly. 
6. Conclusion 
In this paper, we introduce a powerful tool 
for extraction of collocation information from 
large scale corpora. Our adaptation proved the 
cross-lingual robustness of the Sketch Engine. In 
particular, we show the robustness of the Sketch 
Engine by achieving better results through 
fine-tuning of the collocation patterns via 
integrating available grammatical knowledge. 
54
References 
Chen, Keh-Jiann and Huang, Chu-Ren. 1990.  
Information-based Case Grammar.  
Proceedings of the 13th COLING. Helsinki, 
Finland. 2:54-59. 
Chen, Keh-Jiann, Chu-Ren Huang, Feng-Yi Chen, 
Chi-Ching Luo, Ming-Chung Chang, and 
Chao-Jan Chen. 2003. Sinica Treebank: 
Design Criteria, Representational Issues and 
Implementation. In Anne Abeill?e, (ed.): 
Building and Using Parsed Corpora. Text, 
Speech and Language Technology,
20:231-248. Dordrecht: Kluwer.  
CKIP (Chinese Knowledge Information Processing 
Group). 1995/1998. The Content and 
Illustration of Academica Sinica Corpus.
(Technical Report no 95-02/98-04). Taipei: 
Academia Sinica  
Huang, Chu-Ren, Feng-Ju Lo, Hui-Jun Hsiao, 
Chiu-Jung Lu, and Ching-chun Hsieh. 2001. 
From Language Archives to Digital 
Museums: Synergizing Linguistic Databases. 
Presented at the IRCS workshop on linguistic 
Databases. University of Pennsylvania. 
Huang, Chu-Ren, Keh-Jiann Chen, and Lili Chang. 
1997. Segmentation Standard for Chinese 
Natural Language Processing. 
Computational Linguistics and Chinese 
Language Processing. 2(2):47-62.  
Kilgarriff, Adam and Tugwell, David. Sketching 
Words. 2002. In Marie-H?l?ne Corr?ard (ed.): 
Lexicography and Natural Language 
Processing. A Festschrift in Honour of B.T.S. 
Atkins. 125-137. Euralex.  
Kilgarriff, Adam, Chu-Ren Huang, Pavel Rychl?, 
Simon Smith, and David Tugwell. 2005. 
Chinese Word Sketches. ASIALEX 2005: 
Words in Asian Cultural Context. Singapore.  
Kilgarriff, Adam, Pavel Rychl?, Pavel Smrz and 
David Tugwell. 2004. The Sketch Engine. 
Proceedings of EURALEX, Lorient, France. 
(http://www.sketchengine.co.uk/) 
Leech, Geoffrey. 1992. 100 million words of 
English: the British National Corpus (BNC). 
Language Research 28(1):1-13 
Lin, Dekang. 1998. An Information-Theoretic 
Definition of Similarity. Proceedings of 
International Conference on Machine 
Learning. Madison, Wisconsin. 
(http://www.cs.umanitoba.ca/~lindek/publica
tion.htm) 
Tsai, Mei-Chih, Chu-Ren Huang, Keh-Jiann Chen, 
and Kathleen Ahrens. 1998. Towards a 
Representation of Verbal Semantics--An 
Approach Based on Near Synonyms. 
Computational Linguistics and Chinese 
Language Processing. 3(1): 61-74. 
Wu, Yiching and Liu, Mei-Chun. 2003. The 
Construction and Application of Mandarin 
Verbnet. Proceedings of the Third 
International Conference of Internet Chinese 
Education. 39-48. Taipei, Taiwan. 
Xia, Fei, Martha Palmer, Nianwen Xue, Mary Ellen 
Okurowski, John Kovarik, Fu-Dong Chiou, 
Shizhe Huang, Tony Kroch, and Mitch 
Marcus. 2000. Developing Guidelines and 
Ensuring Consistency for Chinese Text 
Annotation. Proceedings of the second 
International Conference on Language 
Resources and Evaluation (LREC 2000), 
Athens, Greece.  
    (http://www.cis.upenn.edu/~chinese/ctb.html)
Xue, Nianwen and Palmer, Martha. 2003. 
Annotating Propositions in the Penn Chinese 
Treebank. Proceedings of the Second Sighan 
Workshop. Sapporo, Japan. 
     (http://www.cis.upenn.edu/~xueniwen/) 
Xue, Nianwen and Palmer, Martha. 2005. 
Automatic Semantic Role Labeling for 
Chinese Verbs. Proceedings of the 19th 
International Joint Conference on Artificial 
Intelligence. Edinburgh, Scotland. 
     (http://www.cis.upenn.edu/~xueniwen/) 
Websites
Sinica Corpus.  
http://www.sinica.edu.tw/SinicaCorpus/  
British National Corpus (BNC). 
http://www.natcorp.ox.ac.uk/  
Center for Chinese Linguistics, PKU.  
http://ccl.pku.edu.cn/#  
Corpora And NLP (Natural Language Processing) 
for Digital Learning of English (CANDLE). 
http://candle.cs.nthu.edu.tw/candle/     
FrameNet.  
http://www.icsi.berkeley.edu/~framenet/  
Penn Chinese Treebank. 
http://www.cis.upenn.edu/~chinese/ctb.html  
Proposition Bank.  
http://www.cis.upenn.edu/~ace/  
Sinica Treebank.   
http://treebank.sinica.edu.tw/  
Sketch Engine (English).  
http://www.sketchengine.co.uk/     
Sketch Engine (Chinese).  
http://corpora.fi.muni.cz/chinese/  
Sou Wen Jie Zi-A Linguistic KnowledgeNet. 
http://words.sinica.edu.tw/ 
55
Improving Word Alignment by Adjusting Chinese Word Segmentation
Ming-Hong Bai1,2 Keh-Jiann Chen1 Jason S. Chang2
1 Institute of Information Science, Academia Sinica 
2 Department of Computer Science, National Tsing-Hua University 
mhbai@sinica.edu.tw kchen@iis.sinica.edu.tw jschang@cs.nthu.edu.tw
 
Abstract  
Most of the current Chinese word 
alignment tasks often adopt word 
segmentation systems firstly to identify 
words. However, word-mismatching 
problems exist between languages and will 
degrade the performance of word 
alignment. In this paper, we propose two 
unsupervised methods to adjust word 
segmentation to make the tokens 1-to-1 
mapping as many as possible between the 
corresponding sentences. The first method 
is learning affix rules from a bilingual 
terminology bank. The second method is 
using the concept of impurity measure 
motivated by the decision tree. Our 
experiments showed that both of the 
adjusting methods improve the 
performance of word alignment 
significantly. 
1 Introduction 
Word alignment is an important preprocessing task 
for statistical machine translation. There have been 
many statistical word alignment methods proposed 
since the IBM models have been introduced. Most 
existing methods treat word tokens as basic 
alignment units (Brown et al, 1993; Vogel et al, 
1996; Deng and Byrne, 2005), however, many 
languages have no explicit word boundary markers, 
such as Chinese and Japanese. In these languages, 
word segmentation (Chen and Liu, 1992; Chen and 
Bai, 1998; Chen and Ma, 2002; Ma and Chen, 
2003; Gao et al, 2005) is often carried out firstly 
to identify words before word alignment (Wu and 
Xia, 1994). However, the differences in 
lexicalization may degrade word alignment 
performance, for different languages may realize 
the same concept using different numbers of words 
(Ma et al, 2007; Wu, 1997). For instance, Chinese 
multi-syllabic words composed of more than one 
meaningful morpheme which may be translated to 
several English words. For example, the Chinese 
word ??? is composed of two meaning units, 
?? and ?, and is translated to Department of 
Education in English. The morphemes ?? and ? 
have their own meanings and are translated to 
Education and Department respectively. The 
phenomenon of lexicalization mismatch will 
degrade the performance of word alignment for 
several reasons. The first reason is that it will 
reduce the cooccurrence counts of Chinese and 
English tokens. Consider the previous example. 
Since ??? is treated as a single unit, it does not 
contribute to the occurrence counts of Education/
?? and Department/? token pairs. Secondly, the 
rarely occurring compound word may cause the 
garbage collectors effect (Moore, 2004; Liang et 
al., 2006), aligning a rare word in source language 
to too many words in the target language, due to 
the frequency imbalance with the corresponding 
translation words in English (Lee, 2004). Finally, 
the IBM models (Moore, 2004) impose the 
limitation that each word in the target sentence can 
be generated by at most one word in the source 
sentence. In this case, a many-to-one alignment, 
links a phrase in the source sentence to a single 
token in the target sentence, is not allowed, forcing 
most links of a phrase in the source sentence to be 
abolished. As in the previous example, when 
aligning from English to Chinese, ??? can only 
be linked to one of the English words, say 
Education, because of the limitation of the IBM 
model. However for remedy, many of the current 
word alignment methods combine the results of 
both alignment directions, via intersection or 
249
grow-diag-final heuristic, to improve the alignment 
reliability (Koehn et al, 2003; Liang et al, 2006; 
Ayan et al, 2006; DeNero et al, 2007). However 
the many-to-one link limitation will undermine the 
reliability due to the fact that some links are not 
allowed in one of the directions. 
In this paper, we propose two novel methods to 
adjust word segmentation so as to decrease the 
effect of lexicalization differences to improve word 
alignment performance. The main idea of our 
methods is to adjust Chinese word segmentation 
according to their translation derived from parallel 
sentences in order to make the tokens compatible 
to 1-to-1 mapping between the corresponding 
sentences. The first method is based on learning a 
set of affix rules from bilingual terminology bank, 
and adjusting the segmentation according to these 
affix rules when preprocessing the Chinese part of 
the parallel corpus. The second method is based on 
the so-called impurity measure, which was 
motivated by the decision tree (Duda et al, 2001). 
 
2 Related Works 
Our methods are motivated by the translation-
driven segmentation method proposed by Wu 
(1997) to segment words in a way to improve word 
alignment. However, Wu's method needs a 
translation lexicon to filter out the links which 
were not in the lexicon and the result was only 
evaluated on the sentence pairs which were 
covered by the lexicon.  
A word packing method has been proposed by 
Ma et al (2007) to improve the word alignment 
task. Before carrying out word alignment, this 
method packs several consecutive words together 
when those words believed to correspond to a 
single word in the other language. Our basic idea is 
similar to this, but on the contrary, we try to 
unpack words which are translations of several 
words in the other language. Since the word 
packing method treats the packed consecutive 
words as a single token, as we mentioned in the 
previous section, it weakens the association 
strength of translation pairs of their morphemes 
while applying the IBM word alignment model. 
A lot of morphological analysis methods have 
been proposed to improve the performance of word 
alignment for inflectional language (Lee et al, 
2003; Lee, 2004; Goldwater, 2005). They proposed 
to split a word into a morpheme sequence of the 
pattern prefix*-stem-suffix* (* denotes zero or 
more occurrences of a morpheme). Their 
experiments showed that morphological analysis 
can improve the quality of machine translation by 
reducing data sparseness and by making the tokens 
in two languages correspond more 1-to-1. 
However, these segmentation methods were 
developed from the monolingual perspective. 
3 Adjusting Word Segmentation 
The goal of word segmentation adjustment is to 
adjust the segmentation of Chinese words such that 
we have as many 1-to-1 links to the English words 
as possible. In this task, we will face the problem 
of finding the proper morpheme boundaries for 
Chinese words. The challenge is that almost all 
characters of Chinese are morphemes and therefore 
almost every character boundary in a word could 
be the boundary of a morpheme, there is no simple 
rules to find the suitable boundaries of morphemes. 
Furthermore, not all meaningful morphemes need 
to be segmented to meet the requirement of 1-to-1 
mapping. For example, washing machine/???
can be segmented into ?? and ? corresponding 
to washing and machine while heater/??? does 
not need, it depends on their translations.  
In this paper, we have proposed two different 
methods to solve this problem: 1. learning affix 
rules from terminology bank to segment 
morphemes and 2. using impurity measure to 
finding the morpheme boundaries. The detail of 
these methods will be described in the following 
sections. 
4 Affix Rule Method 
The main idea of this method is to segment a 
Chinese word according to some properly designed 
conditional dependent affix rules. As shown in 
Figure 1, each rule is composed of three 
conditional constraints, a) affix condition, b) 
English word condition and c) exception condition. 
In the affix condition, we place a underscore on the 
left of a morpheme, such as _?, to denote a suffix 
and on the right, such as ?_, to denote a prefix. 
The affix rules are applied to each word by 
checking the following three conditions:  
1. The target word has the affix. 
250
2. The English word which is the target of 
translation exists in the parallel sentence. 
3. The target word does not contain the 
morphemes in the exception list (The 
morpheme in the exception list shows an 
alternative segmentation.). 
 
If the target word satisfies all of the above 
conditions of any rule, then the morpheme should 
be separated from the word. The remaining 
problem will be how to derive the set of affix rules. 
 
affix English word exception
_? machine  
_? engine  
?_ vice  
?_ deputy ?? 
_? industry ?? 
Figure 1.  Samples of affix rules. 
 
4.1 Training Data 
We use an unsupervised method to extract affix 
rules from a Chinese-English terminology bank1. 
The bilingual terminology bank a total of 
1,046,058 English terms with Chinese transla-
tions in 63 categories. Among them, 60% or 
629,352 terms are compounds. We take the 
advantage of the terminology bank, that all 
terminologies are 1-to-1 well translated, to find the 
best morpheme segmentation from ambiguous 
segmentations of a Chinese word according to its 
English counterpart. Then we extracted affix rules 
from the word-to-morpheme alignment results of 
terms and translation.  
 
4.2 Word-to-Morpheme Alignment 
The training phase of word-to-morpheme 
alignment is based loosely on word-to-word 
alignment of the IBM model 1. Instead of using 
Chinese words, we considered all the possible 
morphemes. For example, consider the task of 
aligning Department of Education and ??? as 
                                                 
1 The bilingual terminology bank was compiled by the Na-
tional Institute for Compilation and Translation. It is freely 
download at http://terms.nict.gov.tw by registering your in-
formation. 
shown as Figure 2. We use the EM algorithm to 
train the translation probabilities of word-
morpheme pairs based on IBM model 1.  
 
 
Figure 2. Example of word-to-morpheme 
alignment. 
 
In the aligning phase, the original IBM model 1 
does not work properly as we expected. Because 
the English words prefer to link to single character 
and it results that some correct Chinese translations 
will not be linked. The reason is that the 
probability of a morpheme, say p(??|education), 
is always less than its substring, p(?|education), 
since whatever ?? occurs ? and ? always 
occur but not vice versa. So the aligning result will 
be ? /Education and ? /Department, ?  is 
abandoned. To overcome this problem, a constraint 
of alignment is imposed to the model to ensure that 
the aligning result covers every Chinese characters 
of a target word and no overlapped characters in 
the result morpheme sequence. For instances, both
? /Education    ? /Department and ? ?
/Education    ??/Department are not allowed 
alignment sequences. The constraint is applied to 
each possible aligning result. If the alignment 
violates the constraint, it will be rejected.  
Since the new alignment algorithm must 
enumerate all of the possible alignments, the 
process is very time consuming. Therefore, it is 
advantageous to use a bilingual terminology bank 
rather than a parallel corpus. The average length of 
terminologies is short and much shorter than a 
typical sentence in a parallel corpus. This makes 
words to morphemes alignment computationally 
feasible and the results highly accurate (Chang et 
al., 2001; Bai et al, 2006). This makes it possible 
to use the result as pseudo gold standards to 
evaluate affix rules as described in section 4.3. 
 
 
 
 
251
 
air|?? refrigeration|?? machine|? 
building|?? industry|? 
compound|?? steam|?? engine|? 
electronics|?? industry|? 
vice|? chancellor|?? 
Figure 3. Sample of word-to-morpheme alignment. 
4.3 Rule Extraction 
After the alignment task, we will get a word-to-
morpheme aligned terminology bank as shown in 
Figure 3. We can subsequently extract affix rules 
from the aligned terminology bank by the 
following steps: 
 
1) Generate candidates of affix rule: 
For each alignment, we produce all alignment 
links as affix rules. For instance, with 
(electronics|??  industry|? ), we would 
produce two rules: 
 
     (a) ??_, electronics 
     (b) _?, industry 
 
2) Evaluate the rules: 
The precision of each candidate rule is 
estimated by applying the rule to segment the 
Chinese terms. If a Chinese term contains the 
affix shown in the rule, the affix will be 
segmented. The results of segmentation are 
then to compare with the segmentation results 
of the alignments done by the algorithm of the 
section 4.2 as pseudo gold standards. Some 
example results of rule evaluations are shown 
in Figure 4.    
 
affix English word 
Rule 
Applied  
Correct 
segments precision
?_ master 458 378 0.825 
??_ periodic 130 100 0.769 
??_ video 46 40 0.870 
_? chain 147 107 0.728 
_? box 716 545 0.761 
Figure 4. Sample evaluations of candidate rules. 
3) Adding exception condition: 
In the third step, we sort the rules according to 
their precision rates in descending order, 
resulting in rules R1..Rn . And then for each Ri , 
we scan R1 to Ri-1, if there is a rule, Rj, have 
the same English word condition and the affix 
condition of Ri subsume that of Rj, then we 
add affix condition of Rj as exception 
condition of Ri. For example, _? , industry 
and _??, industry are rule candidates in the 
sorted table and have the same English word 
condition. Furthermore, the condition _? 
subsumes that of ??, we add ?? to the 
exception condition of the rule with a shorter 
affix. 
 
4) Reevaluate the rules with exception 
condition: 
After adding the exception conditions, the 
rules are reevaluated with considering the ex-
ception condition to get new evaluation scores. 
 
5) Select rules by scores: 
Finally, filter out the rules with scores lower 
than a threshold2. 
 
The reason of using exception condition is that 
an affix is usually an abbreviation of a word, such 
as _? is an abbreviation of ??. In general, a full 
morpheme is preferred to be segmented than its 
abbreviation while both occurred in a target word. 
For example, when applying rules to ????
/electronic industry, _?? ,industry is preferred 
than _?,industry. However, in the evaluation step, 
precision rate of _?,industry will be reduced when 
applying to full morphemes, such as ????
/electronic industry, and then could be filtered out 
if the precision is lower than the threshold.  
5 Impurity Measure Method 
The impurity measure was used by decision tree 
(Duda et al, 2001) to split the training examples 
into smaller and smaller subsets progressively 
according to features and hope that all the samples 
in each subset is as pure as possible. For 
convenient, they define the impurity function 
rather than the purity function of a subset as 
follows:  
 ??=
j
jj wPwPSimpurity )(log)()( 2  
                                                 
2 We set the threshold as 0.7.  
252
                     
 
(a) impurity value of ????.                   (b) impurity values of ?? and ??. 
Figure 5. Examples of impurity values. 
 
Where P(wj) is the fraction of examples at set S 
that are in category wj. By the well-known 
properties of entropy if all the examples are of the 
same category the impurity is 0; otherwise it is 
positive, with the greatest value occurring when 
the different classes are equal likely.  
5.1 Impurity Measure of Translation 
In our experiment, the impurity measure is used 
to split a Chinese word into two substrings and 
hope that all the characters in a substring are 
generated by the parallel English words as pure as 
possible. Here, we treat a Chinese word as a set of 
characters, the parallel English words as categories 
and the fraction of examples is redefined by the 
expected fraction number of characters that are 
generated by each English word. So we redefine 
the entropy impurity as follows: 
 
);|(log);|();( 2 fe,fe,fe,
e
efcefcfI
e
E ?
??
?=
In which f denotes the target Chinese word, e and f 
denote the parallel English and Chinese sentence 
that f belongs to and   is the expected 
fraction number of characters in f that are 
generated by word e. The expected fraction 
number can be defined as follows: 
);|( fe,efc
??
?
?? ??
??=
e
fe,
e fc
fc
ecp
ecp
efc
)|(
)|(
);|(  
Where p(c | e) denotes the translation probability 
of Chinese character c given English word e. 
 
For example, as shown in Figure 5, the impurity 
value of ????, Figure 5.(a), is much higher 
than values of ?? and ??, Figure 5.(b). Which 
means that the generating relations from English to 
Chinese tokens are purified by breaking ???? 
into ?? and ??.   
The translation probabilities between Chinese 
characters and English word can be trained using 
IBM model 1 by treating Chinese characters as 
tokens. 
5.2 Target Word Selection 
In this experiment, we treat the Chinese words 
which can be segmented into morphemes and 
linked to different English words as target words. 
In order to speedup our impurity method only tar-
get words will be segmented during the process. 
Therefore we investigate the actual distribution of 
target words first, we have tagged 1,573 Chinese 
words manually with target and non-target. It turns 
out that only 6.87% of the Chinese words are 
tagged as target and 94.4% of target words are 
nouns. The results show that most of the Chinese 
words do not need to be re-segmented and their 
POS distribution is very unbalanced. The results 
show that we can filter out the non-target words by 
simple clues. In our experiment, we use three fea-
tures to filter out non-target words: 
 
1) POS: Since 94.4% of the target words are 
nouns, we focus our experiment on nouns 
and filter out words with other POS.  
2) One-to-many alignment in GIZA++:  Only 
Chinese words which are linked to multiple 
English words in the result of GIZA++ are 
considered to be target words. 
3) Impurity measure: the target words are ex-
pected to have high impurity values. So the 
words with a impurity values larger than a 
threshold are selected as target words3. 
                                                 
3 In our experiment, we use 0.3 as our threshold. 
253
5.3 Best Breaking Point and we used these annotated data as our gold 
standard in testing.  The goal of segmentation adjustment using 
impurity is to find the best breaking point of a 
Chinese word according to parallel English words. 
When a word is broken into two substrings, the 
new substrings can be compared to original word 
by the information gain which is defined in terms 
of impurity as follows: 
Because of the modification of Chinese tokens 
caused by the word segmentation adjustment, a 
problem has been created when we wanted to 
compare the results to the copy which did not 
undergo adjustment. Therefore, after the alignment 
was done, we merged the alignment links related to 
tokens that were split up during adjustment. For 
example, the two links of foreign/?? minister/?
? were merged as foreign minister/????. 
),;(
2
1
),;(
2
1
),;(    
),,(
11
11
fefefe niE
i
EE
n
i
i
fIfIfI
fffIG
+
+
??
=
  
The evaluation of word alignment results are 
shown in Table 1, including precision-recall and 
AER evaluation methods. In which the baseline is 
alignment result of the unadjusted data. The table 
shows that after the adjustment of word 
segmentation, both methods obtain significant 
improvement over the baseline, especially for the 
English-Chinese direction and the intersection 
results of both directions. The impurity method in 
particular improves alignment in both English-
Chinese and Chinese-English directions.  
Where i denotes a break point in f,  denotes 
first i characters of f, and  denotes last n-i 
characters of f. If the information gain of a 
breaking point is positive, the result substrings are 
considered to be better, i.e. more pure than original 
word.  
if1
n
if 1+
The goal of finding the best breaking point can 
be achieved by finding the point which maximizes 
the information gain as the following formula: 
The improvement of intersection of both 
directions is important for machine translation. 
Because the intersection result has higher precision, 
a lot of machine translation method relies on 
intersecting the alignment results. The phrase-
based machine translation (Koehn et al, 2003) 
uses the grow-diag-final heuristic to extend the 
word alignment to phrase alignment by using the 
intersection result. Liang (Liang et al, 2006) has 
proposed a symmetric word alignment model that 
merges two simple asymmetric models into a 
symmetric model by maximizing a combination of 
likelihood and agreement between the models. 
This method uses the intersection as the agreement 
of both models in the training time. The method 
has reduced the alignment error significantly over 
the traditional asymmetric models.  
),,(maxarg 111
n
i
i
ni
fffIG +<?  
Note that a word can be separated into two 
substrings each time. If we want to segment a 
complex word composed of many morphemes, just 
split the word again and again like the construction 
of decision tree, until the information gain is 
negative or less than a threshold4. 
6 Experiments 
In order to evaluate the effect of our methods on 
the word alignment task, we preprocessed parallel 
corpus in three ways: First we use a state-of-the-art 
word segmenter to tokenize the Chinese part of the 
corpus. Then, we used the affix rules to adjust 
word segmentation. Finally, we do the same but by 
using the impurity measure method.  We used the 
GIZA++ package (Och and Ney, 2003) as the word 
alignment tool to align tokens on the three copies 
of preprocessed parallel corpora.  
In order to analyze the adjustment results, we 
also manually segment and link the words of 
Chinese sentences to make the alignments 1-to-1 
mapping as many as possible according to their 
translations for the 112 gold standard sentences.  
Table 2 shows the results of our analysis, the 
performance of impurity measure method is also 
slightly better than the affix rules in both recall and 
precision measure. 
We used the first 100,000 sentences of Hong 
Kong News parallel corpus from LDC as our 
training data. And 112 randomly selected parallel 
sentences were aligned manually with sure and 
possible tags, as described in (Och and Ney, 2000), 
                                                 
4 In our experiment, we set 0 as the threshold. 
254
 
 direction Recall precision F-score AER 
English-Chinese 68.3 61.2 64.6 35.7 
Chinese-English 79.6 67.0 72.8 27.8 baseline 
intersection 59.9 92.0 72.6 26.6 
English-Chinese 78.2 64.6 70.8 29.8 
Chinese-English 80.2 68.0 73.6 27.0 affix rules 
intersection 69.1 92.3 79.0 20.2 
English-Chinese 78.1 64.9 70.9 29.7 
Chinese-English 81.4 70.4 75.5 25.0 impurity 
intersection 70.2 91.9 79.6 19.8 
Table 1. Alignment results based on the standard word segmentation data. 
 
 recall precision 
affix rules 82.35 66.66 
impurity 84.31 67.72 
Table 2. Alignment results based on the manual 
word segmentation data. 
 
7 Conclusion 
In this paper, we have proposed two Chinese word 
segmentation adjustment methods to improve word 
alignment. The first method uses the affix rules 
learned from a bilingual terminology bank and 
then applies the rules to the parallel corpus to split 
the compound Chinese words into morphemes ac-
cording to its counterpart parallel sentence. The 
second method uses the impurity method, which 
was motivated by the method of decision tree. The 
experimental results show that both methods lead 
to significant improvement in word alignment per-
formance. 
 
Acknowledgements: This research was supported 
in part by the National Science Council of Taiwan 
under NSC Grants: NSC95-2422-H-001-031. 
References  
Necip Fazil Ayan and Bonnie J. Dorr. 2006. Going 
Beyond AER: An Extensive Analysis of Word 
Alignments and Their Impact on MT. In Proceedings 
of ACL 2006, pages 9-16, Sydney, Australia. 
Ming-Hong Bai, Keh-Jiann Chen and Jason S. Chang. 
2006. Sense Extraction and Disambiguation for 
Chinese Words from Bilingual Terminology Bank. 
Computational Linguistics and Chinese Language 
Processing, 11(3):223-244. 
Petter F. Brown, Stephen A. Della Pietra, Vincent J. 
Della Pietra, Robert L. Mercer. 1993. The 
Mathematics of Machine Translation: Parameter 
Estimation. Computational Linguistics, 19(2):263-
311.  
Jason S Chang, David Yu, Chun-Jun Lee. 2001. Statisti-
cal Translation Model for Phrases(in Chinese). Com-
putational Linguistics and Chinese Language Proc-
essing, 6(2):43-64. 
Keh-Jiann Chen, Ming-Hong Bai. 1998. Unknown 
Word Detection for Chinese by a Corpus-based 
Learning Method. International Journal of 
Computational linguistics and Chinese Language 
Processing, 1998, Vol.3, #1, pages 27-44.  
Keh-Jiann Chen, Wei-Yun Ma. 2002. Unknown Word 
Extraction for Chinese Documents. In Proceedings of 
COLING 2002, pages 169-175, Taipei, Taiwan.  
Keh-Jiann Chen, Shing-Huan Liu. 1992. Word 
Identification for Mandarin Chinese Sentences. In 
Proceedings of 14th COLING, pages 101-107.  
John DeNero, Dan Klein. 2007. Tailoring Word 
Alignments to Syntactic Machine Translation. In 
Proceedings of ACL 2007, pages 17-24, Prague, 
Czech Republic. 
Yonggang Deng, William Byrne. 2005. HMM word and 
phrase alignment for statistical machine translation. 
In Proceedings of HLT-EMNLP 2005, pages 169-176, 
Vancouver, Canada.  
Richard O. Duda, Peter E. Hart, David G. Stork. 2001. 
Pattern Classification. John Wiley & Sons, Inc.  
Jianfeng Gao, Mu Li, Andi Wu and Chang-Ning 
Huang.  2005. Chinese word segmentation and 
named entity recognition: a pragmatic approach. 
Computational Linguistics, 31(4) 
Sharon Goldwater, David McClosky. 2005. Improving 
Statistical MT through Morphological Analysis. In 
255
Proceedings of HLT/EMNLP 2005, pages 676-683, 
Vancouver, Canada.  
Philipp Koehn, Franz J. Och, Daniel Marcu. 2003. Sta-
tistical Phrase-Based Translation. In Proceedings of 
HLT/NAACL 2003, pages 48-54, Edmonton, Canada. 
Young-Suk Lee. 2004. Morphological Analysis for 
Statistical Machine Translation. In Proceedings of 
HLT-NAACL 2004, pages 57-60, Boston, USA.  
Young-Suk Lee, Kishore Papineni, Salim Roukos. 2003. 
Language Model Based Arabic Word Segmentation. 
In Proceedings of ACL 2003, pages 399-406, 
Sapporo, Japan.  
Percy Liang, Ben Taskar, Dan Klein. 2006. Alignment 
by Agreement. In Proceedings of HLT-NAACL 2006, 
pages 104-111, New York, USA.  
Wei-Yun Ma, Keh-Jiann Chen. 2003. A Bottom-up 
Merging Algorithm for Chinese Unknown Word 
Extraction. In Proceedings of ACL 2003, Second 
SIGHAN Workshop on Chinese Language Processing, 
pp31-38, Sapporo, Japan.  
Yanjun Ma, Nicolas Stroppa, Andy Way. 2007. 
Bootstrapping Word Alignment via Word Packing. In 
Proceedings of ACL 2007, pages 304-311, Prague, 
Czech Republic.  
Robert C. Moore. 2004. Improving IBM Word-
Alignment Model 1. In Proceedings of ACL 2004, 
pages 519-526, Barcelona, Spain.  
Franz Josef Och, Hermann Ney. A Systematic 
Comparison of Various Statistical Alignment Models, 
Computational Linguistics, volume 29, number 1, pp. 
19-51 March 2003. 
Franz J. Och, Hermann Ney., Improved Statistical 
Alignment Models, In Proceedings of the 38th An-
nual Meeting of the Association for Computational 
Linguistics, 2000, Hong Kong, pp. 440-447. 
Stefan Vogel, Hermann Ney, Christoph Tillmann. 1996. 
HMM-based word alignment in statistical translation. 
In Proceedings of COLING 1996, pages 836-841, 
Copenhagen, Denmark.  
Dekai Wu, Xuanyin Xia. 1994. Learning an English-
Chinese Lexicon from a Parallel Corpus. In 
Proceedings of AMTA 1994, pages 206-213, 
Columbia, MD.  
Dekai Wu. 1997. Stochastic Inversion Transduction 
Grammars and Bilingual Parsing of Parallel Corpora. 
Computational Linguistics, 23(3):377-403.  
256
Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 478?486,
Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
Acquiring Translation Equivalences of Multiword Expressions by 
Normalized Correlation Frequencies 
Ming-Hong Bai1,2 Jia-Ming You1 Keh-Jiann Chen1 Jason S. Chang2 
1 Institute of Information Science, Academia Sinica, Taiwan 
2 Department of Computer Science, National Tsing-Hua University, Taiwan 
mhbai@sinica.edu.tw, swimming@hp.iis.sinica.edu.tw, 
kchen@iis.sinica.edu.tw, jschang@cs.nthu.edu.tw 
 
Abstract 
In this paper, we present an algorithm for ex-
tracting translations of any given multiword 
expression from parallel corpora. Given a 
multiword expression to be translated, the 
method involves extracting a short list of tar-
get candidate words from parallel corpora 
based on scores of normalized frequency, 
generating possible translations and filtering 
out common subsequences, and selecting the 
top-n possible translations using the Dice 
coefficient. Experiments show that our ap-
proach outperforms the word alignment-
based and other naive association-based me-
thods. We also demonstrate that adopting the 
extracted translations can significantly im-
prove the performance of the Moses machine 
translation system. 
1 Introduction 
Translation of multiword expressions (MWEs), 
such as compound words, phrases, collocations 
and idioms, is important for many NLP tasks, 
including the techniques are helpful for dictio-
nary compilation, cross language information 
retrieval, second language learning, and machine 
translation. (Smadja et al, 1996; Gao et al, 2002; 
Wu and Zhou, 2003). However, extracting exact 
translations of MWEs is still an open problem, 
possibly because the senses of many MWEs are 
not compositional (Yamamoto and Matsumoto, 
2000), i.e., their translations are not composi-
tions of the translations of individual words. For 
example, the Chinese idiom ???? should be 
translated as ?turn a blind eye,? which has no 
direct relation with respect to the translation of 
each constituent (i.e., ?to sit?, ?to see? and ?to 
ignore?) at the word level.  
Previous SMT systems (e.g., Brown et al, 
1993) used a word-based translation model 
which assumes that a sentence can be translated 
into other languages by translating each word 
into one or more words in the target language. 
Since many concepts are expressed by idiomatic 
multiword expressions instead of single words, 
and different languages may realize the same 
concept using different numbers of words (Ma et 
al., 2007; Wu, 1997), word alignment based me-
thods, which are highly dependent on the proba-
bility information at the lexical level, are not 
well suited for this type of translation.  
To address the above problem, some methods 
have been proposed for extending word align-
ments to phrase alignments. For example, Och et 
al. (1999) proposed the so-called grow-diag-
final heuristic method for extending word 
alignments to phrase alignments. The method is 
widely used and has achieved good results for 
phrase-based statistical machine translation. 
(Och et al, 1999; Koehn et al, 2003; Liang et al, 
2006). Instead of using heuristic rules, Ma et al 
(2008) showed that syntactic information, e.g., 
phrase or dependency structures, is useful in ex-
tending the word-level alignment. However, the 
above methods still depend on word-based 
alignment models, so they are not well suited to 
extracting the translation equivalences of seman-
tically opaque MWEs due to the lack of word 
level relations between the translational corres-
pondences. Moreover, the aligned phrases are 
not precise enough to be used in many NLP ap-
plications like dictionary compilation, which 
require high quality translations. 
Association-based methods, e.g., the Dice 
coefficient, are widely used to extract transla-
tions of MWEs. (Kupiec, 1993; Smadja et al, 
1996; Kitamura and Matsumoto, 1996; Yama-
moto and Matsumoto, 2000; Melamed, 2001). 
The advantage of such methods is that associa-
tion relations are established at the phrase level 
instead of the lexical level, so they have the po-
tential to resolve the above-mentioned transla-
tion problem. However, when applying associa-
tion-based methods, we have to consider the fol-
lowing complications. The first complication, 
which we call the contextual effect, causes the 
extracted translation to contain noisy words. For 
478
example, translations of the Chinese idiom ??
?? (best of both worlds) extracted by a naive 
association-based method may contain noisy 
collocation words like difficult, try and cannot, 
which are not part of the translation of the idiom. 
They are actually translations of its collocation 
context, such as ??(difficult), ??(try), and 
??(cannot). This problem arises because naive 
association methods do not deal with the effect 
of strongly collocated contexts carefully. If we 
can incorporate lexical-level information to dis-
count the noisy collocation words, the contextual 
effect could be resolved. 
 
English (y) fy fx,y Dice(x,y)
quote out of context 22 19 0.56 
take out of context 17 11 0.35 
interpret out of context 2 2 0.08 
out of context 53 32 0.65 
Table 1. The Dice coefficient tends to select a com-
mon subsequence of translations. (The frequency of
???? ,fx, is 46.) 
 
The second complication, which we call the 
common subsequence problem, is that the Dice 
coefficient tends to select the common subse-
quences of a set of similar translations instead of 
the full translations. Consider the translations of 
???? (quote out of context) shown in the 
first three rows of Table 1. The Dice coefficient 
of each translation is smaller than that of the 
common subsequence ?out of context? in the last 
row. If we can tell common subsequence apart 
from correct translations, the common subse-
quence problem could be resolved. 
In this paper, we propose an improved preci-
sion method for extracting MWE translations 
from parallel corpora. Our method is similar to 
that of Smadja et al (1996), except that we in-
corporate lexical-level information into the asso-
ciation-based method. The algorithm works ef-
fectively for various types of MWEs, such as 
phrases, single words, rigid word sequences (i.e., 
no gaps) and gapped word sequences. Our expe-
riment results show that the proposed translation 
extraction method outperforms word alignment-
based methods and association-based methods. 
We also demonstrate that precise translations 
derived by our method significantly improve the 
performance of the Moses machine translation 
system. 
The remainder of this paper is organized as 
follows. Section 2 describes the methodology for   
extracting translation equivalences of MWEs. 
Section 3 describes the experiment and presents 
the results. In Section 4, we consider the appli-
cation of our results to machine translation. Sec-
tion 5 contains some concluding remarks. 
2 Extracting Translation Equivalences   
Our MWE translation extraction method is simi-
lar to the two-phase approach proposed by 
Smadja et al (1996). The two phases can be 
briefly described as follows:  
Phase 1: Extract candidate words correlated to 
the given MWE from parallel text. 
Phase 2:  
1. Generate possible translations for the 
MWE by combining the candidate words. 
2. Select possible translations by the Dice 
coefficient. 
We propose an association function, called the 
normalized correlation frequency, to extract 
candidate words in the phase 1. This method 
incorporates lexical-level information with asso-
ciation measure to overcome the contextual ef-
fect. In phase 2, we also propose a weighted fre-
quency function to filter out false common sub-
sequences from possible translations. The filter-
ing step is applied before the translation select-
ing step of phase 2.   
Before describing our extraction method, we 
define the following important terms used 
throughout the paper. 
Focused corpus (FC): This is the corpus 
created for each targeted MWE. It is a subset of 
the original parallel corpora, and is comprised of 
the selected aligned sentence pairs that contain 
the source MWE and its translations. 
Candidate word list (CW): A list of extracted 
candidate words for the translations of the 
source MWE. 
2.1 Selecting Candidate Words 
For a source MWE, we try to extract from the 
FC a set of k candidate words CW that are high-
ly correlated to the source MWE. We then as-
sume that the target translation is a combination 
of some words in CW. As noted by Smadja et al 
(1996), this two-step approach drastically reduc-
es the search space. 
However, translations of collocated context 
words in the source word sequence create noisy 
candidate words, which might cause incorrect 
extraction of target translations by naive statis-
tical correlation measures, such as the Dice coef-
479
ficient used by Smadja et al (1996). The need to 
avoid this context effect motivates us to propose 
a candidate word selection method that uses the 
normalized correlation frequency as an associa-
tion measure. 
The rationale behind the proposed method is 
as follows. When counting the word frequency, 
each word in the target corpus normally contri-
butes a frequency count of one. However, we are 
only interested in the word counts correlated to a 
MWE. Therefore, intuitively, we define the 
normalized count of a target word e as the trans-
lation probability of e given the MWE.  
We explain the concept of normalizing the 
correlation count in Section 2.1.1 and the com-
putation of the normalized correlation frequency 
in Section 2.1.2. 
2.1.1 Normalizing Correlation Count 
We propose an association measure called the 
normalized correlation frequency, which ranks 
the association strength of target words with the 
source MWE. For ease of explanation, we use 
the following notations: let f=f1,f2,?,fm and 
e=e1,e2,?,en be a pair of parallel Chinese and 
English sentences; and let w=t1,t2,?,tr be the 
Chinese source MWE. Hence, w is a subse-
quence of f.  
When counting the word frequency, each 
word in the target corpus normally contributes a 
frequency count of one. However, since we are 
interested in the word counts that correlate to w, 
we adopt the concept of the translation model 
proposed by Brown et al(1993). Each word e in 
a sentence e might be generated by some words, 
denoted as r, in the source sentence f. If r is 
non-empty the relation between r and w should 
fit one of the following cases: 
 
1) All words in r belong to w, i.e., wr ? , so 
we say that e is only generated by w. 
2) No words in r belong to w, i.e., wfr ?? , 
so we say that e is only generated by context 
words.  
3) Some words in r belong to w, while others 
are context words. 
 
Intuitively, In Cases 1 and 2, the correlation 
count of an instance e should be 1 and 0 respec-
tively. In Case 3, the normalized count of e is 
the expected frequency generated by w divided 
by the expected frequency generated by f. With 
that in mind, we define the weighted correlation 
count, wcc, as follows:  
 
?
?
??
??
?+
?+=
f
w
f
w
wfe
j
i
f j
f i
fep
fep
ewcc
||)|(
||)|(
),,;( , 
 
where ? is a very small smoothing factor in case 
e is not generated by any word in f. The proba-
bility p(e | f) is the word translation probability 
trained by IBM Model 1 on the whole parallel 
corpus. 
The rationale behind the weighted correlation 
count, wcc, is that if e is part of the translation of 
w, then its association with w should be stronger 
than other words in the context. Hence its wcc 
should be closer to 1. Otherwise, the association 
is weaker and the wcc should be closer to 0. 
2.1.2 Normalized Correlation 
Once the weighted correlation counts wcc is 
computed for each word in FC, we compute the 
normalized correlation frequency for each word 
e as the total sum of the  of all w 
in bilingual sentences (e, f)  in FC. The norma-
lized correlation frequency (ncf) is defined as 
follows: 
),,;( wfeewcc
 
?
=
=
n
i
iiewccencf
1
)()( ),,;();( wfew . 
 
We choose the top-n English words ranked by 
ncf as our candidate words and filter out those 
whose ncf is less than a pre-defined threshold. 
Table 2 shows the candidate words for the Chi-
nese term ???? (quote/take/interpret out of 
context) sorted by their ncf values. To illustrate 
the effectiveness ncf, we also display candidate 
words of the term with their Dice values in 
Tables 3. As shown in the tables, noise words 
such as justify, meaning and unfair are ranked 
lower using ncf than using Dice, while correct 
candidates, such as out, take and remark are 
ranked higher.  We present more experimental 
results in Section 3. 
 
2.2 Generation and Ranking of Candi-
date Translations 
After determining the candidate words, candi-
date translations of w can be generated by mark-
ing the candidate words in each sentence of FC. 
The word sequences marked in each sentence 
are deemed possible translations. At the same 
time, the weakly associated function words,  
480
Candidate words e freq ncf(e,w) 
context 54 31.55 
out 58 24.58 
quote 26 5.84 
take 23 4.81 
remark 8 1.84 
interpret 3 1.38 
piecemeal 1 0.98 
deliberate 3 0.98 
Table 2. Candidate words for the Chinese term 
???? sorted by their global normalized correla-
tion frequencies. 
 
Candidate words e freq dice(e,w) 
context 54 0.0399 
quote 26 0.0159 
deliberate 3 0.0063 
justify 3 0.0034 
interpretation 7 0.0032 
meaning 3 0.0029 
cite 3 0.0025 
unfair 4 0.0023 
Table 3. Candidate words for the Chinese term ??
??  sorted by their Dice coefficient values. 
 
which we fail to select in the candidate word 
selection stage, should be recovered. The rule is 
quite simple: if a function word is adjacent to 
any candidate word, it should be recovered. For 
example, in the following sentence, the function 
word of would be recovered and added to the 
marked sequence: 
 
?The financial secretary has 
been quoted out of context. 
??? ?? ? ?? ? ????.?  
 
 The marked words are shown in boldface.  
2.2.1 Generating Possible Translations 
Although we have selected a reliable candidate 
word list, it may still contain some noisy words 
due to the MWE?s collocation context. Consider 
the following example: 
 
...as quoted in the audit 
report, if taken out of con-
text...  
 
In this instance, quoted is a false positive; there-
fore, the marked word sequence m ?quoted tak-
en out of context? is not the correct translation. 
To avoid such false positives, we include m and 
all its subsequences as possible translations.  
quoted taken out of context 
quoted taken out of 
quoted taken out context 
quoted taken of context 
quoted out of context 
taken out of context 
? 
quoted out 
taken out 
quoted 
taken 
out 
context
Table 4. Example subsequences generated of w and 
add them to the candidate translation list.  
 
Table 4 shows the subsequences of m in the 
above example. The generation process is used 
to increase the coverage of correct translations in 
the candidate list; otherwise, many correct trans-
lations will be lost. However, the process may 
also trigger the side effect of the common sub-
sequence problem described in Section 1.  Since 
all candidates compete for the best translations 
by comparing their association strength with w, 
the common subsequences will have an advan-
tage. 
 
2.2.2 Filtering Common Subsequences 
To resolve the common subsequence effect prob-
lem, we evaluate each candidate translation, in-
cluding its subsequences, by a concept similar to 
the normalized correlation frequency. As men-
tioned in Section 1, the Dice coefficient tends to 
select the common subsequences of some candi-
dates because they have higher frequencies. To 
avoid this problem, we use the normalized corre-
lation frequency to filter out false common sub-
sequences from the candidate translation list. 
Here, we also use the weighted correlation count 
wcc to weight the frequency count of a candidate 
translation. Suppose we have a marked sequence 
in a sentence, m, whose subsequences are gener-
ated in the way described in the previous section. 
If the weighted count of m is assigned the score 
1, the weighted count (wc) of a subsequence t is 
then defined as follows: 
 
?
???
?=
tm
wfewmfet
e
ewccwc )),,;(1(),,,;( . 
 
The underlying concept of wc is that the original 
marked sequence m is supposed to be the most 
481
likely translation of w and the weighted count is 
set to 1. Then, if a subsequence t is generated by 
removing a word e from m, the weighted count 
of the subsequence is reduced by multiplying the 
complement probability of e generated by w. 
Note that the weighted correlation count wcc is 
the probability of the word e generated by w. 
After all  in each sentence of 
the FC have been computed, the weighted fre-
quency for a sequence t can be determined by 
summing the weighted frequencies over FC as 
follows:  
),,,;( wmfetwc
 
?
??
=
FC
wcwf
),(
),,,;();(
fe
wmfetwt . 
 
We compute the wf for each candidate transla-
tion and then sort the candidate translations by 
their wf values. 
Next, we filter out common subsequences 
based on the following rule: for a sequence t, if 
there is a super-sequence t' on the sorted candi-
date translation list and the wf value of t is less 
than that of t', then t is assumed be a common 
subsequence of real translations and removed 
from the list. 
 
candidate translation list freq wf 
quote out of context 19 17.55 
of context 35 15.45 
out of context 32 14.82 
quote of context 19 13.32 
out 35 11.92 
quote 23 11.63 
quote out 19 9.42 
Table 5. Part of the candidate translation list for the 
Chinese idiom, ????, sorted by the wf values. 
 
Table 5 shows an example of the rule?s appli-
cation. The candidate translation list is sorted by 
the translations? wf values. Then, candidates 2-7 
are removed because they are subsequences of 
the first candidate and their wf values are smaller 
than that of the first candidate. 
2.3 Selection of Candidate Translations 
Having removed the common subsequences of 
real translations from the candidate translation 
list of w, we can select the best translations by 
comparing their association strength with w for 
the remaining candidates.  The Dice coefficient 
is a good measure for assessing the association 
strength and selecting translations from the can-
didate list. For a candidate translation t, the Dice 
coefficient is defined as follows: 
 
)()(
),(2
),(
wt
wt
wt
pp
p
Dice += . 
 
Where p(t,w), p(t), p(w) are probabilities of  
(t,w), t, w derived from the training corpus.  
After obtaining the Dice coefficients of the 
candidate translations, we select the top-n candi-
date translations as possible translations of w. 
 
3 Experiments 
In our experiments, we use the Hong Kong Han-
sard and the Hong Kong News parallel corpora 
as training data. The training data was prepro-
cessed by Chinese word segmentation to identify 
words and parsed by Chinese parser to extract 
MWEs. To evaluate the proposed approach, we 
randomly extract 309 Chinese MWEs from 
training data, including dependent word pairs 
and rigid idioms. We then randomly select 103 
of those MWEs as the development set and use 
the other 206 as the test set. The reference trans-
lations of each Chinese MWE are manually ex-
tracted from the parallel corpora. 
 
3.1 Evaluation of Word Candidates 
To evaluate the method for selecting candidate 
words, we use the coverage rate, which is de-
fined as follows: 
 
?
?
?=
w w
ww
||
||1
A
CA
n
coverage , 
 
where n is the number of MWEs in the test set, 
Aw denotes the word set of the reference transla-
tions of w, and Cw denotes a candidate word list 
extracted by the system.  
Table 6 shows the coverage of our method, 
NCF, compared with the coverage of the IBM 
model 1 and the association-based methods MI, 
Chi-square, and Dice. As we can see, the top-10 
candidate words of NCF cover almost 90% of 
the words in the reference translations. Whereas, 
the coverage of the association-based methods 
and IBM model 1 is much lower than 90%. The 
result implies that the candidate extraction me-
thod can extract a more precise candidate set 
than other methods. 
 
482
Method Top10 Top20 Top30 
MI 0.514 0.684 0.760 
Chi-square 0.638 0.765 0.828 
Dice 0.572 0.735 0.803 
IBM 1 0.822 0.900 0.948
NCF 0.899 0.962 0.973 
Table 6. The coverage rates of the candidate words 
extracted by the compared methods 
 
Figure 1 shows the curve diagram of the cov-
erage rate of each method. As the figure shows, 
when the size of the candidate list is increased, 
the coverage rate of using NCF rises rapidly as n 
increases but levels off after n=20. Whereas, the 
coverage rates of other measures grow much 
slowly.  
 
 
Figure 1. The curve diagram of the coverage of 
the candidate word list compiled by each method. 
 
From the evaluation of candidate word selec-
tion, we find that the ncf method, which incorpo-
rates lexical-level information into association-
based measure, can effectively filter out noisy 
words and generates a highly reliable list of can-
didate words for a given MWE. 
 
3.2 Evaluating Extracted Translations 
To evaluate the quality of MWE translations 
extracted automatically, we use the following 
three criteria: 
 
1) Translation accuracy: 
This criterion is used to evaluate the top-n 
translations of the system. It treats each 
translation produced as a string and com-
pares the whole string with the given ref-
erence translations. If any one of the top-n 
hypothesis translations is included in the 
reference translations, it is deemed correct.   
2) WER (word error rate): 
This criterion compares the top-1 hypo-
thesis translation with the reference trans-
lations by computing the edit distance (i.e., 
the minimum number of substitutions, in-
sertions, and deletions) between the hypo-
thesis translation and the given reference 
translations. 
3) PER (position-independent word error 
rate): 
This criterion ignores the word order and 
computes the edit distance between the 
top-1 hypothesis translation and the given 
reference translations. 
 
We also use the MT task to evaluated our me-
thod with other systems. For that, we use the 
GIZA++ toolkit (Och et al, 2000 ) to align the 
Hong Kong Hansard and Hong Kong News pa-
rallel corpora. Then, we extract the translations 
of the given source sequences from the aligned 
corpus as the baseline. We use the following two 
methods to extract translations from the aligned 
results. 
 
1) Uni-directional alignment  
We mark all English words that were 
linked to any constituent of w in the pa-
rallel Chinese-English aligned corpora. 
Then, we extract the marked sequences 
from the corpora and compute the fre-
quency of each sequence. The top-n high 
frequency sequences are returned as the 
possible translations of w. 
2) Bi-directional alignments 
We use the grow-diag-final heuristic (Och 
et al, 1999) to combine the Chinese-
English and English-Chinese alignments, 
and then extract the top-n high frequency 
sequences as described in method 1. 
 
To determine the effect of the common subse-
quence filtering method, FCS, we divide the 
evaluation of our system into two phases: 
 
1) NCF+Dice: 
This system uses the normalized correla-
tion frequency, NCF, to select candidate 
words as described in Section 2.1. It then 
extracts candidate translations (described 
in Section 2.2), but FCS is not used. 
2) NCF+FCS+Dice: 
This is similar to system 1, but it uses 
FCS to filter out common subsequences 
(described in subsection 2.2.2). 
483
Method WER(%) PER(%) 
Uni-directional 4.84 4.02 
Bi-directional 5.84 5.12 
NCF+Dice 3.55 3.24 
NCF+FCS+Dice 2.45 2.23 
Table 7. Translation error rates of the systems. 
 
 
Method Top1 Top2 Top3 
Uni-directional 67.5 79.6 83.0 
Bi-directional 65.5 77.7 81.1 
NCF+Dice 72.8 85.9 88.3 
NCF+FCS+Dice 78.2 89.3 91.7 
Table 8. Translation accuracy rates of the systems. 
(%) 
 
Table 7 shows the word error rates for the 
above systems. As shown in the first and second 
rows, the translations extracted from uni-
directional alignments are better than those ex-
tracted from bi-directional alignments. This 
means that the grow-diag-final heuristic reduces 
the accuracy rate when extracting MWE transla-
tions.  
The results in the third row show that the 
NCF+Dice system outperforms the methods 
based on GIZA++. In other words, the NCF me-
thod can effectively resolve the difficulties of 
extracting MWE translations discussed in Sec-
tion 1. 
In addition, the fourth row shows that the 
NCF+FCS+Dice system also outperforms the 
NCF+Dice system.  Thus, the FCS method can 
resolve the common subsequence problem effec-
tively. 
Table 8 shows the translation accuracy rates 
of each system. The NCF+FCS+Dice system 
achieves the best translation accuracy. Moreover, 
it significantly improves the performance of 
finding MWE translation equivalences. 
 
4 Applying  MWE Translations to MT 
To demonstrate the usefulness of extracted 
MWE translations to existing statistical machine 
translation systems, we use the XML markup 
scheme provided by the Moses decoder, which 
allows the specification of translations for parts 
of a sentence. The procedure for this experiment 
consists of three steps: (1) the extracted MWE 
translations are added to the test set with the 
XML markup scheme, (2) after which the data is 
input to the Moses decoder to complete the 
translation task, (3) the results are evaluated 
 Moses  MWE +Moses
NIST06-sub 23.12 23.49 
NIST06 21.57 21.79 
 Table 9. BLEU scores of the translation results. 
 
using the BLEU metric (Papineni et al, 2002). 
4.1 Experimental Settings 
To train a translation model for Moses, we use 
the Hong Kong Hansard and the Hong Kong 
News parallel corpora as training data 
(2,222,570 sentence pairs). We also use the 
same parallel corpora to extract translations of 
MWEs. The NIST 2008 evaluation data (1,357 
sentences, 4 references) is used as development 
set and NIST 2006 evaluation data (1,664 sen-
tences, 4 references) is used as test set. 
4.2 Selection of MWEs 
Due to the limitation of the XML markup 
scheme, we only consider two types of MWEs: 
continuous bigrams and idioms. Since the goal 
of this experiment is not focus on extraction of 
MWEs, simple methods are applied to extract 
MWEs from the training data: (1) we collect all 
continuous bigrams from Chinese sentences in 
the training data and then simply filter out the 
bigrams by mutual information (MI) with a thre-
shold1, (2) we also extract all idioms from Chi-
nese sentences of the training data by collecting 
all 4-syllables words from the training data and 
filtering out obvious non-idioms, such as deter-
minative-measure words and temporal words by 
their part-of-speeches, because most Chinese 
idioms are 4-syllables words.  
In total, 33,767 Chinese bigram types and 
20,997 Chinese idiom types were extracted from 
training data; and the top-5 translations of each 
MWE were extracted by the method described in 
Section 2. Meanwhile 1,171 Chinese MWEs 
were added to the translations in the test set. The 
Chinese words covered by the MWEs in test 
data set were 2,081 (5.3%). 
 
4.3 Extra Information 
When adding the translations to the test data, 
two extra types of information are required by 
the Moses decoder. The first type comprises the 
function words between the translation and its 
context. For example, if ??  ??/economic 
cooperation is added to the test data, possible  
                                                 
1 We set the threshold at 5. 
484
source sentence ... ????<MWE>????</MWE>????? ... 
Moses ... entered blinded by the colourful community ... 
MWE+Moses ... entered the colourful community ... 
reference ... entered the colorful society ... 
source sentence ... ?????  <MWE>???  ??</MWE> ??? ... 
Moses ... do not want to see an escalation of crisis ... 
MWE+Moses ... do not want to see a further escalation of crisis ... 
reference ... don 't want to see the further escalation of the crisis ... 
source sentence ... ????????<MWE>?????</MWE> ... 
Moses ... the people 's interests ... 
MWE+Moses ... the people of the fundamental interests ... 
reference ... the fundamental interests of the masses ... 
Table 10. Examples of improved translation quality with the MWE translation equivalences. 
 
function words, such as ?in? or ?with?, should be 
provided for the translation. Because the Moses 
decoder does not generate function words that 
are context dependent, it treats a function word 
as a part of the translation. Therefore, we collect 
possible function words for each translation 
from the corpora when the conditional probabili-
ty is larger than a threshold2. 
The second type of information is the phrase 
translation probability and lexical weighting. 
Computing the phrase translation probability is 
trivial in the training corpora, but lexical weight-
ing (Koehn et al, 2003) needs lexical-level 
alignment. For convenience, we assume that 
each word in an MWE links to each word in the 
translations. Under this assumption, the lexical 
weighting is simplified as follows:   
 
??
??= ?= aji ji
n
i
w efpajij
ap
),(1
)|(
|}),(|{|
1
),|( ef
        ? ?
= ??
?
n
i e
ji
j
efp
1
)|(
||
1
ee
. 
 
Then, it is trivial to compute the simplified lexi-
cal weighting of each MWE correspondence 
when the word translation probability table is 
provided. Here, we use the IBM model 1 to learn 
the table from the training data. 
4.4 Evaluation Results 
We trained a model using Moses toolkit (Koehn 
et al, 2007) on the training data as our baseline 
system.  
Table 9 shows the influence of adding the 
MWE translations to the test data. In the first 
row (NIST06-sub), we only consider sentences 
containing MWE translations for BLEU score 
evaluation (726 sentences). In the second row, 
we took the whole NIST 2006 evaluation set 
into consideration (1,664 sentences). The Chi-
nese words covered by the MWEs in NIST06-
sub and NIST06 were 9.9% and 5.3% respec-
tively. 
Adding MWE translations to the test data sta-
tistically significantly lead to better results than 
those of the baseline. Significance was tested 
using a paired bootstrap (Koehn, 2004) with 
1000 samples (p<0.02). Although the improve-
ment in BLEU score seems small, it is actually 
reasonably good given that the MWEs account 
for only 5% of the NIST06 test set. Examples of 
improved translations are shown in Table 10. 
There is still room for improvement of the pro-
posed MWE extraction method in order to pro-
vide more MWE translation pairs or design a 
feasible way to incorporate discontinuous bilin-
gual MWEs to the decoder. 
5 Conclusions and Future Work 
We have proposed a high precision algorithm for 
extracting translations of multiword expressions 
from parallel corpora. The algorithm can be used 
to translate any language pair and any type of 
word sequence, including rigid sequences and 
discontinuous sequences. Our evaluation results 
show that the algorithm can cope with the diffi-
culties caused by indirect association and the 
common subsequence effects, leading to signifi-
cant improvement over the word alignment-
based extraction methods used by the state of the 
art systems and other association-based extrac-
tion methods. We also demonstrate that ex-
tracted translations significantly improve the                                                  
2 We set the threshold at 0.1. 
485
performance of the Moses machine translation 
system. 
In future work, it would be interesting to de-
velop a machine translation model that can be 
integrated with the translation acquisition algo-
rithm in a more effective way. Using the norma-
lized-frequency score to help phrase alignment 
tasks, as the grow-diag-final heuristic, would 
also be interesting direction to explore. 
 
Acknowledgement 
This research was supported in part by the Na-
tional Science Council of Taiwan under the NSC 
Grants: NSC 96-2221-E-001-023-MY3. 
References  
Brown, Peter F., Stephen A. Della Pietra, Vincent J. 
Della Pietra, Robert L. Mercer. 1993. The Mathe-
matics of Statistical Machine Translation: Parame-
ter Estimation. Computational Linguistics, 
19(2):263-311.  
Gao, Jianfeng, Jian-Yun Nie, Hongzhao He, Weijun 
Chen, Ming Zhou. 2002. Resolving Query Trans-
lation Ambiguity using a Decaying Co-occurrence 
Model and Syntactic Dependence Relations. In 
Proc. of SIGIR?02. pp. 183 -190. 
Kitamura, Mihoko and Yuji Matsumoto. 1996. Au-
tomatic Extraction of Word Sequence Correspon-
dences in Parallel Corpora. In Proc. of the 4th An-
nual Workshop on Very Large Corpora. pp. 79-87. 
Koehn, Philipp, Franz Josef Och, and Daniel Marcu. 
2003. Statistical Phrase-Based Translation. In Proc. 
of HLT/NAACL?03. pp. 127-133. 
Koehn, Philipp. 2004. Statistical significance tests for 
machine translation evaluation. In Proc. 
EMNLP?04. pp. 388-395. 
Koehn, Philipp, Hieu Hoang, Alexandra Birch, Chris 
Callison-Burch, Marcello Federico, Nicola Bertol-
di, Brooke Cowan, Wade Shen, Christine Moran, 
Richard Zens, Chris Dyer, Ondrej Bojar, Alexan-
dra Constantin, and Evan Herbst. 2007. Moses: 
Open source toolkit for statistical machine transla-
tion. In ACL?07, demonstration session. 
Kupiec, Julian. 1993. An Algorithm for Finding 
Noun Phrase Correspondences in Bilingual Corpo-
ra. In Proc. of ACL?93 . pp. 17-22. 
Liang, Percy, Ben Taskar, Dan Klein. 2006. Align-
ment by Agreement. In Proc. of HLT/NAACL?06. 
pp. 104-111. 
Ma, Yanjun, Nicolas Stroppa, Andy Way. 2007. 
Bootstrapping Word Alignment via Word Packing. 
In Proc. of ACL?07. pp. 304-311. 
Ma, Yanjun, Sylwia Ozdowska, Yanli Sun, and Andy 
Way. 2008. Improving Word Alignment Using 
Syntactic Dependencies. In Proc. of ACL/HLT?08 
Second Workshop on Syntax and Structure in Sta-
tistical Translation. pp. 69-77. 
Melamed, Ilya Dan. 2001. Empirical Methods for 
Exploiting parallel Texts. MIT press. 
Och, Franz Josef and Hermann Ney. 2000. Improved 
Statistical Alignment Models. In Proc. of ACL?00. 
pp. 440-447. 
Och, Franz Josef, Christoph Tillmann, and Hermann 
Ney. 1999. Improved Alignment Models for Sta-
tistical Machine Translation. In Proc. of 
EMNLP/VLC?99. pp. 20-28. 
Papineni, Kishore, Salim Roukos, Todd Ward, and 
Wei-Jing Zhu. 2002. BLEU: a Method for Auto-
matic Evaluation of Machine Translation. In Proc. 
of ACL?02. pp. 311-318. 
Smadja, Frank, Kathleen R. McKeown, and Vasileios 
Hatzivassiloglou. 1996. Translating Collocations 
for Bilingual Lexicons: A Statistical Approach. 
Computational Linguistics, 22(1):1-38. 
Wu, Dekai. 1997. Stochastic Inversion Transduction 
Grammars and Bilingual Parsing of Parallel Cor-
pora. Computational Linguistics, 23(3):377-403.  
Wu, Hua, Ming Zhou. 2003. Synonymous Colloca-
tion Extraction Using Translation Information. In 
Proc. of ACL?03. pp. 120-127. 
Yamamoto, Kaoru, Yuji Matsumoto. 2000. Acquisi-
tion of Phrase-level Bilingual Correspondence us-
ing Dependency Structure. In Proc. of COL-
ING?00. pp. 933-939. 
 
486
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 55?60,
Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational Linguistics
DOMCAT: A Bilingual Concordancer for Domain-Specific Computer 
Assisted Translation 
Ming-Hong Bai1,2 Yu-Ming Hsieh1,2 Keh-Jiann Chen1 Jason S. Chang2 
1 Institute of Information Science, Academia Sinica, Taiwan 
2 Department of Computer Science, National Tsing-Hua University, Taiwan 
mhbai@sinica.edu.tw, morris@iis.sinica.edu.tw, 
kchen@iis.sinica.edu.tw, jason.jschang@gmail.com 
 
Abstract 
In this paper, we propose a web-based 
bilingual concordancer, DOMCAT 1 , for 
domain-specific computer assisted 
translation. Given a multi-word expression 
as a query, the system involves retrieving 
sentence pairs from a bilingual corpus, 
identifying translation equivalents of the 
query in the sentence pairs (translation 
spotting) and ranking the retrieved sentence 
pairs according to the relevance between 
the query and the translation equivalents. 
To provide high-precision translation 
spotting for domain-specific translation 
tasks, we exploited a normalized 
correlation method to spot the translation 
equivalents. To ranking the retrieved 
sentence pairs, we propose a correlation 
function modified from the Dice coefficient 
for assessing the correlation between the 
query and the translation equivalents. The 
performances of the translation spotting 
module and the ranking module are 
evaluated in terms of precision-recall 
measures and coverage rate respectively. 
1 Introduction 
A bilingual concordancer is a tool that can retrieve 
aligned sentence pairs in a parallel corpus whose 
source sentences contain the query and the 
translation equivalents of the query are identified 
in the target sentences. It helps not only on finding 
translation equivalents of the query but also 
presenting various contexts of occurrence. As a 
result, it is extremely useful for bilingual 
                                                          
1 http://ckip.iis.sinica.edu.tw/DOMCAT/ 
lexicographers, human translators and second 
language learners (Bowker and Barlow 2004; 
Bourdaillet et al, 2010; Gao 2011).  
Identifying the translation equivalents, 
translation spotting, is the most challenging part of 
a bilingual concordancer. Recently, most of the 
existing bilingual concordancers spot translation 
equivalents in terms of word alignment-based 
method. (Jian et al, 2004; Callison-Burch et al, 
2005; Bourdaillet et al, 2010). However, word 
alignment-based translation spotting has some 
drawbacks. First, aligning a rare (low frequency) 
term may encounter the garbage collection effect 
(Moore, 2004; Liang et al, 2006) that cause the 
term to align to many unrelated words. Second, the 
statistical word alignment model is not good at 
many-to-many alignment due to the fact that 
translation equivalents are not always correlated in 
lexical level. Unfortunately, the above effects will 
be intensified in a domain-specific concordancer 
because the queries are usually domain-specific 
terms, which are mostly multi-word low-frequency 
terms and semantically non-compositional terms. 
Wu et al (2003) employed a statistical 
association criterion to spot translation equivalents 
in their bilingual concordancer. The association-
based criterion can avoid the above mentioned 
effects. However, it has other drawbacks in 
translation spotting task. First, it will encounter the 
contextual effect that causes the system incorrectly 
spot the translations of the strongly collocated 
context. Second, the association-based translation 
spotting tends to spot the common subsequence of 
a set of similar translations instead of the full 
translations. Figure 1 illustrates an example of 
contextual effect, in which ?Fan K'uan? is 
incorrectly spotted as part of the translation of the 
query term ?????? ? (Travelers Among 
Mountains and Streams), which is the name of the 
55
painting painted by ?Fan K'uan/?? ? since the 
painter?s name is strongly collocated with the 
name of the painting. 
 
Sung , Travelers Among Mountains and Streams , Fan 
K'uan 
???????? 
Figure 1. ?Fan K'uan? may be incorrectly spotted as 
part of the translation of ???????, if pure 
association method is applied. 
 
Figure 2 illustrates an example of common 
subsequence effect, in which ??????? (the 
River During the Qingming Festival/ Up the River 
During Qingming) has two similar translations as 
quoted, but the Dice coefficient tends to spot the 
common subsequences of the translations. 
(Function words are ignored in our translation 
spotting.) 
 
Expo 2010 Shanghai-Treasures of Chinese Art Along 
the River During the Qingming Festival 
2010?????????????????? 
Oversized Hanging Scrolls and Handscrolls Up the 
River During Qingming 
???????????? 
Figure 2. The Dice coefficient tends to spot the common 
subsequences ?River During Qingming?. 
Bai et al (2009) proposed a normalized 
frequency criterion to extract translation 
equivalents form sentence aligned parallel corpus. 
This criterion takes lexical-level contexture effect 
into account, so it can effectively resolve the above 
mentioned effect. But the goal of their method is to 
find most common translations instead of spotting 
translations, so the normalized frequency criterion 
tends to ignore rare translations. 
In this paper, we propose a bilingual 
concordancer, DOMCAT, for computer assisted 
domain-specific term translation. To remedy the 
above mentioned effects, we extended the 
normalized frequency of Bai et al (2009) to a 
normalized correlation criterion to spot translation 
equivalents. The normalized correlation inherits 
the characteristics of normalized frequency and is 
adjusted for spotting rare translations. These 
characteristics are especially important for a 
domain-specific bilingual concordancer to spot 
translation pairs of low-frequency and semantically 
non-compositional terms.  
The remainder of this paper is organized as 
follows.  Section 2 describes the DOMCAT system. 
In Section 3, we describe the evaluation of the 
DOMCAT system. Section 4 contains some 
concluding remarks. 
2 The DOMCAT System 
Given a query, the DOMCAT bilingual 
concordancer retrieves sentence pairs and spots 
translation equivalents by the following steps: 
 
1. Retrieve the sentence pairs whose source 
sentences contain the query term. 
2. Extract translation candidate words from the 
retrieved sentence pairs by the normalized 
correlation criterion. 
3. Spot the candidate words for each target 
sentence and rank the sentences by 
normalized the Dice coefficient criterion. 
 
In step 1, the query term can be a single word, a 
phrase, a gapped sequence and even a regular 
expression. The parallel corpus is indexed by the 
suffix array to efficiently retrieve the sentences.  
The step 2 and step 3 are more complicated and 
will be described from Section 2.1 to Section 2.3. 
2.1 Extract Translation Candidate Words 
After the queried sentence pairs retrieved from the 
parallel corpus, we can extract translation 
candidate words from the sentence pairs. We 
compute the local normalized correlation with 
respect to the query term for each word e in each 
target sentence. The local normalized correlation 
is defined as follows: 
 
?
?
??
??
??
???
f
q
f
qfeq
j
i
f j
f i
fep
fepelnc ||)|(
||)|(),,;(      (1) 
 
where q denotes the query term, f denotes the 
source sentence and e denotes the target sentence,  
? is a small smoothing factor. The probability p(e|f) 
is the word translation probability derived from the 
entire parallel corpus by IBM Model 1 (Brown et 
al., 1993). The sense of local normalized 
correlation of e can be interpreted as the 
probability of word e being part of translation of 
the query term q under the condition of sentence 
pair (e, f). 
56
Once the local normalized correlation is 
computed for each word in retrieved sentences, we 
compute the normalized correlation on the 
retrieved sentences. The normalized correlation is 
the average of all lnc values and defined as follows:  
 
?
?
?
n
i
iielncnenc 1
)()( ),,;(1);( feqq            (2) 
 
where n is the number of retrieved sentence pairs.  
After the nc values for the words of the retrieved 
target sentences are computed, we can obtain a 
translation candidate list by filtering out the words 
with lower nc values. 
To compare with the association-based method, 
we also sorted the word list by the Dice coefficient 
defined as follows: 
 
)()(
),(2),( q
qq freqefreq
efreqedice ??           (3) 
 
where freq is frequency function which  computes 
frequencies from the parallel corpus. 
 
Candidate words NC 
mountain 0.676 
stream 0.442 
traveler 0.374 
among 0.363 
sung 0.095 
k'uan 0.090 
Figure 3(a). Candidate words sorted by nc values. 
 
Candidate words Dice 
traveler 0.385 
reduced 0.176 
stream 0.128 
k'uan 0.121 
fan 0.082 
among 0.049 
mountain 0.035 
Figure 3(b). Candidate words sorted by Dice coefficient 
values. 
 
Figure 3(a) and (b) illustrate examples of 
translation candidate words of the query term ??
???? ? (Travelers Among Mountains and 
Streams) sorted by the nc values, NC, and the Dice 
coefficients respectively. The result shows that the 
normalized correlation separated the related words 
from unrelated words much better than the Dice 
coefficient. 
The rationale behind the normalized correlation 
is that the nc value is the strength of word e 
generated by the query compared to that of 
generated by the whole sentence. As a result, the 
normalized correlation can easily separate the 
words generated by the query term from the words 
generated by the context. On the contrary, the Dice 
coefficient counts the frequency of a co-occurred 
word without considering the fact that it could be 
generated by the strongly collocated context.  
 
2.2 Translation Spotting 
Once we have a translation candidate list and 
respective nc values, we can spot the translation 
equivalents by the following spotting algorithm. 
For each target sentence, first, spot the word with 
highest nc value. Then extend the spotted sequence 
to the neighbors of the word by checking their nc 
values of neighbor words but skipping function 
words. If the nc value is greater than a threshold ?, 
add the word into spotted sequence. Repeat the 
extending process until no word can be added to 
the spotted sequence. 
The following is the pseudo-code for the 
algorithm: 
 
S is the target sentence 
H is the spotted word sequence 
?is the threshold of translation candidate words 
 
Initialize: 
H? ?
emax?S[0] Foreach ei in S: If nc(ei) > nc(emax):  
emax ??ei 
If nc(emax )??:?
add?emax?to?H 
Repeat until no word add to H 
ej?left?neighbor?of?H?
If?nc(ej?)??:?
? ???add?ej?to?H?
ek?right?neighbor?of?H?
If nc(?ek?)???:?
? ???add?ek?to?H?
Figure 4: Pseudo-code of translation spotting process. 
 
57
2.3 Ranking 
The ranking mechanism of a bilingual 
concordancer is used to provide the most related 
translation of the query on the top of the outputs 
for the user. So, an association metric is needed to 
evaluate the relations between the query and the 
spotted translations. The Dice coefficient is a 
widely used measure for assessing the association 
strength between a multi-word expression and its 
translation candidates. (Kupiec, 1993; Smadja et 
al., 1996; Kitamura and Matsumoto, 1996; 
Yamamoto and Matsumoto, 2000; Melamed, 2001)  
The following is the definition of the Dice 
coefficient: 
 
)()(
),(2),( qt
qtqt freqfreq
freqdice ??            (4) 
 
where q denotes a multi-word expression to be 
translated, t denotes a translation candidate of q. 
However, the Dice coefficient has the common 
subsequence effect (as mentioned in Section 1) due 
to the fact that the co-occurrence frequency of the 
common subsequence is usually larger than that of 
the full translation; hence, the Dice coefficient 
tends to choose the common subsequence. 
To remedy the common subsequence effect, we 
introduce a normalized frequency for a spotted 
sequence defined as follows: 
 
?
?
?
n
i
iilnfnf
1
)()( ),,;(),( feqtqt            (5) 
 
where lnf is a function which compute normalized 
frequency locally in each sentence. The following 
is the definition of lnf: 
 
?
???
??
tH
feqfeqt
e
elnclnf )),,;(1(),,;(      (6) 
 
where H is the spotted sequence of the sentence 
pair (e,f), H-t are the words in H but not in t. The 
rationale behind lnf function is that: when counting 
the local frequency of t in a sentence pair, if t is a 
subsequence of H, then the count of t should be 
reasonably reduced by considering the strength of 
the correlation between the words in H-t and the 
query. 
Then, we modify the Dice coefficient by 
replacing the co-occurrence frequency with 
normalized frequency as follows: 
 
)()(
),(2),( qt
qtqt freqfreq
nfnf_dice ??        (7) 
 
The new scoring function, nf_dice(t,q), is 
exploited as our criterion for assessing the 
association strength between the query and the 
spotted sequences. 
3 Experimental Results 
3.1 Experimental Setting 
We use the Chinese/English web pages of the 
National Palace Museum 2  as our underlying 
parallel corpus. It contains about 30,000 sentences 
in each language. We exploited the Champollion 
Toolkit (Ma et al, 2006) to align the sentence pairs. 
The English sentences are tokenized and 
lemmatized by using the NLTK (Bird and Loper, 
2004) and the Chinese sentences are segmented by 
the CKIP Chinese segmenter (Ma and Chen, 2003). 
To evaluate the performance of the translation 
spotting, we selected 12 domain-specific terms to 
query the concordancer. Then, the returned spotted 
translation equivalents are evaluated against a 
manually annotated gold standard in terms of recall 
and precision metrics. We also build two different 
translation spotting modules by using the GIZA++ 
toolkit (Och and Ney, 2000) with the 
intersection/union of the bidirectional word 
alignment as baseline systems. 
To evaluate the performance of the ranking 
criterion, we compiled a reference translation set 
for each query by collecting the manually 
annotated translation spotting set and selecting 1 to 
3 frequently used translations. Then, the outputs of 
each query are ranked by the nf_dice function and 
evaluated against the reference translation set. We 
also compared the ranking performance with the 
Dice coefficient. 
3.2 Evaluation of Translation Spotting 
We evaluate the translation spotting in terms of the 
Recall and Precision metrics defined as follows: 
 
                                                          
2 http://www.npm.gov.tw 
58
||
||
1
)(
1
)()(
?
?
?
? ?? n
i
i
g
n
i
ii
g
H
HHRecall                     (8) 
||
||
1
)(
1
)()(
?
?
?
? ?? n
i
i
n
i
ii
g
H
HHPrecision                     (9) 
 
where i denotes the index of the retrieved 
sentence, )(iH  is the spotted sequences of the ith 
sentence returned by the concordancer,  and )(igH is 
the gold standard spotted sequences of the ith 
sentence. Table 1 shows the evaluation of 
translation spotting for normalized correlation, NC, 
compared with the intersection and union of 
GIZA++ word alignment. The F-score of the 
normalized correlation is much higher than that of 
the word alignment methods. It is noteworthy that 
the normalized correlation increased the recall rate 
without losing the precision rate. This may indicate 
that the normalized correlation can effectively 
conquer the drawbacks of the word alignment-
based translation spotting and the association-
based translation spotting mentioned in Section 1. 
 
 Recall Precision F-score 
Intersection 0.4026 0.9498 0.5656 
Union 0.7061 0.9217 0.7996 
NC 0.8579 0.9318 0.8933 
Table 1. Evaluation of the translation spotting 
queried by 12 domain-specific terms. 
 
We also evaluate the queried results of each 
term individually (as shown in Table 2). As it 
shows, the normalized correlation is quite stable 
for translation spotting. 
 
Query terms GIZA Intersection GIZA Union NC R P F R P F R P F 
??? (Maogong cauldron) 0.27 0.86 0.41 0.87 0.74 0.80  0.92 0.97 0.94 
????(Jadeite cabbage) 0.48 1.00 0.65 1.00 0.88 0.94  0.98 0.98 0.98 
?????(Travelers Among Mountains and Streams) 0.28 0.75 0.41 1.00 0.68 0.81 0.94 0.91 0.92
?????(Up the River During Qingming) 0.22 0.93 0.35 0.97 0.83 0.89  0.99 0.91 0.95
???(Ching-te-chen) 0.50 0.87 0.63 0.73 0.31 0.44 1.00 0.69 0.82
??(porcelain) 0.53 0.99 0.69 0.93 0.64 0.76 0.78 0.96 0.86
??(cobalt blue glaze) 0.12 1.00 0.21 0.85 0.58 0.69 0.94 0.86 0.90
??(inscription) 0.20 0.89 0.32 0.71 0.34 0.46  0.88 0.95 0.91
????(Three Friends and a Hundred Birds) 0.58 0.99 0.73 1.00 0.97 0.99 1.00 0.72 0.84
??(wild cursive script) 0.42 1.00 0.59 0.63 0.80 0.71 0.84 1.00 0.91
???(Preface to the Orchid Pavilion Gathering) 0.33 0.75 0.46 0.56 0.50 0.53 0.78 1.00 0.88
????(Latter Odes to the Red Cliff) 0.19 0.50 0.27 0.75 0.46 0.57 0.94 0.88 0.91
Table 2. Evaluation of the translation spotting for each term
3.3 Evaluation of Ranking 
To evaluate the performance of a ranking function, 
we ranked the retrieved sentences of the queries by 
the function. Then, the top-n sentences of the 
output are evaluated in terms of the coverage rate 
defined as follows: 
?coverage  
queries of #
top-nin on  translatia findcan  queries of #   (10) 
 
The meaning of the coverage rate can be 
interpreted as: how many percent of the query can 
find an acceptable translation in the top-n results.  
We use the reference translations, as described in 
Section 3.1, as acceptable translation set for each 
query of our experiment. Table 3 shows the 
coverage rate of the nf_dice function compared 
with the Dice coefficient. As it shows, in the 
outputs ranked by the Dice coefficient, uses 
usually have to look up more than 3 sentences to 
find an acceptable translation; while in the outputs 
ranked by the nf_dice function, users can find an 
acceptable translation in top-2 sentences. 
 
59
 
 dice nf_dice 
top-1 0.42  0.92 
top-2 0.75  1.00 
top-3 0.92  1.00 
Table 3. Evaluation of the ranking criteria. 
4 Conclusion and Future Works 
In this paper, we proposed a bilingual 
concordancer, DOMCAT, designed as a domain-
specific computer assisted translation tool. We 
exploited a normalized correlation which 
incorporate lexical level information into 
association-based method that effectively avoid the 
drawbacks of the word alignment-based translation 
spotting as well as the association-based translation 
spotting. 
In the future, it would be interesting to extend 
the parallel corpus to the internet to retrieve more 
rich data for the computer assisted translation. 
References  
Bai, Ming-Hong, Jia-Ming You, Keh-Jiann Chen, Jason 
S. Chang. 2009. Acquiring Translation Equivalences 
of Multiword Expressions by Normalized Correlation 
Frequencies. In Proceedings of EMNLP, pages 478-
486. 
Bird, Steven and Edward Loper. 2004. NLTK: The 
Natural Language Toolkit. In Proceedings of ACL, 
pages 214-217. 
Bourdaillet, Julien, St?phane Huet, Philippe Langlais 
and Guy Lapalme. 2010. TRANSSEARCH: from a 
bilingual concordancer to a translation finder. 
Machine Translation, 24(3-4): 241?271. 
Bowker, Lynne, Michael Barlow. 2004. Bilingual 
concordancers and translation memories: A 
comparative evaluation. In Proceedings of the 
Second International Workshop on Language 
Resources for Translation Work, Research and 
Training , pages. 52-61. 
Brown, Peter F., Stephen A. Della Pietra, Vincent J. 
Della Pietra, Robert L. Mercer. 1993. The 
Mathematics of Statistical Machine Translation: 
Parameter Estimation. Computational Linguistics, 
19(2):263-311. 
Callison-Burch, Chris, Colin Bannard and Josh 
Schroeder. 2005. A Compact Data Structure for 
Searchable Translation Memories. In Proceedings of 
EAMT. 
Gao, Zhao-Ming. 2011. Exploring the effects and use of 
a Chinese?English parallel concordancer. Computer-
Assisted Language Learning 24.3 (July 2011): 255-
275. 
Jian, Jia-Yan, Yu-Chia Chang and Jason S. Chang. 2004. 
TANGO: Bilingual Collocational Concordancer. In 
Proceedings of ACL, pages 166-169. 
Kitamura, Mihoko and Yuji Matsumoto. 1996. 
Automatic Extraction of Word Sequence 
Correspondences in Parallel Corpora. In Proceedings 
of WVLC-4 pages 79-87. 
Kupiec, Julian. 1993. An Algorithm for Finding Noun 
Phrase Correspondences in Bilingual Corpora. In 
Proceedings of ACL, pages 17-22. 
Liang, Percy, Ben Taskar, Dan Klein. 2006. Alignment 
by Agreement. In Proceedings of HLT-NAACL 2006, 
pages 104-111, New York, USA. 
Ma, Wei-Yun and Keh-Jiann Chen. 2003. Introduction 
to CKIP Chinese word segmentation system for the 
first international Chinese word segmentation 
bakeoff. In Proceedings of the second SIGHAN 
workshop on Chinese language processing, pages 
168-171. 
Ma, Xiaoyi. 2006. Champollion: A Robust Parallel Text 
Sentence Aligner. In Proceedings of the Fifth 
International Conference on Language Resources 
and Evaluation. 
Melamed, Ilya Dan. 2001. Empirical Methods for 
Exploiting parallel Texts. MIT press. 
Moore, Robert C. 2004. Improving IBM Word-
Alignment Model 1. In Proceedings of ACL, pages 
519-526, Barcelona, Spain. 
Och, Franz J., Hermann Ney., 2000, Improved 
Statistical Alignment Models, In Proceedings of ACL, 
pages 440-447. Hong Kong. 
Smadja, Frank, Kathleen R. McKeown, and Vasileios 
Hatzivassiloglou. 1996. Translating Collocations for 
Bilingual Lexicons: A Statistical Approach. 
Computational Linguistics, 22(1):1-38. 
Wu, Jian-Cheng, Kevin C. Yeh, Thomas C. Chuang, 
Wen-Chi Shei, Jason S. Chang.  2003. TotalRecall: A 
Bilingual Concordance for Computer Assisted 
Translation and Language Learning. In Proceedings 
of ACL, pages 201-204. 
Yamamoto, Kaoru, Yuji Matsumoto. 2000. Acquisition 
of Phrase-level Bilingual Correspondence using 
Dependency Structure. In Proceedings of COLING, 
pages 933-939. 
60
