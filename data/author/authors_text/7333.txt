A Representation for Complex and Evolving Data Dependencies 
in Generation 
C Me l l i sh  $, R Evans  t, L Cah i l l  t, C Doran  t, D Pa iva  t, M Reape $, D Scot t  t, N T ipper  t 
t Information Technology Research Institute, University of Brighton, Lewes Rd, Brighton, UK 
SDivision of Informatics, University of Edinburgh, 80 South Bridge, Edinburgh, UK 
rags@itri, brighton, ac. uk 
http :/www. itri. brighton, ac. uk/proj ect s/rags 
Abst rac t  
This paper introduces an approach to represent- 
ing the kinds of information that components 
in a natural language generation (NLG) sys- 
tem will need to communicate to one another. 
This information may be partial, may involve 
more than one level of analysis and may need 
to include information about the history of a 
derivation. We present a general representation 
scheme capable of handling these cases. In ad- 
dition, we make a proposal for organising inter- 
module communication i an NLG system by 
having a central server for this information. We 
have validated the approach by a reanalysis of 
an existing NLG system and through a full im- 
plementation of a runnable specification. 
1 In t roduct ion  
One of the distinctive properties of natural an- 
guage generation when compared with other 
language ngineering applications i that it has 
to take seriously the full range of linguistic rep- 
resentation, from concepts to morphology, or 
even phonetics. Any processing system is only 
as sophisticated as its input allows, so while a 
natural language understanding system might 
be judged primarily by its syntactic prowess, 
even if its attention to semantics, pragmatics 
and underlying conceptual analysis is minimal, 
a generation system is only as good as its deep- 
est linguistic representations. Moreover, any at- 
tempt to abstract away from individual gener- 
ation systems to a more generic architectural 
specification faces an even greater challenge: 
not only are complex linguistic representations 
required, able to support the dynamic evolu- 
tionary development of data during the gener- 
* Now at the MITRE Corporation, Bedford, MA, USA, 
cdoran@mitre, org. 
ation process, but they must do so in a generic 
and flexible fashion. 
This paper describes a representation devel- 
oped to meet these requirements. It offers a 
formally well-defined eclarative representation 
language, which provides a framework for ex- 
pressing the complex and dynamic data require- 
ments of NLG systems. The approach supports 
different levels of representation, mixed repre- 
sentations that cut across levels, partial and 
shared structures and 'canned' representations, 
as well as dynamic relationships between data 
at different stages in processing. We are using 
the approach to develop a high level data model 
for NLG systems as part of a generic generation 
architecture called RAGS 1. 
The framework has been implemented in the 
form of a database server for modular genera- 
tion systems. As proof of concept of the frame- 
work, we have reimplemented an existing NLG 
system. The system we chose was the Caption 
Generation System (CGS) (Mittal et al, 1995; 
Mittal et al, 1998). The reimplementation in- 
volved defining the interfaces to the modules of 
CGS in terms of the RAGS representations and 
then implementing modules that had the requi- 
site input and output representations. 
Generation systems, especially end-to-end, 
applied generation systems, have, unsurpris- 
ingly, many things in common. Reiter (1994) 
proposed an analysis of such systems in terms 
of a simple three stage pipeline. More recently, 
the RAGS project attempted to repeat he anal- 
1This work is supported by ESPRC grants 
GR/L77041 (Edinburgh) and GR/L77102 (Brighton), 
RAGS: Reference Architecture for Generation Systems. 
We would also like to acknowledge the contribution of 
Jo Calder to the ideas and formalisation described in 
this paper. In particular, parts of this paper are based 
on (Calder et al, 1999). 
119 
ysis (Cahill et al, 1999a), but found that while 
most systems did implement a pipeline, they 
did not implement the same pipeline - different 
functionalities occurred in different places and 
different orders in different systems. In order 
to accommodate his result, we sought to de- 
velop an architecture that is more general than 
a simple pipeline, and thus supports the range 
of pipelines observed, as well as other more com- 
plex control regimes (see (Cahill et al, 1999a; 
Cahill et al, 1999b)). In this paper, we argue 
that supporting such an architecture requires 
careful consideration of the way data represen- 
tations interact and develop. Any formal frame- 
work for expressing the architecture must take 
account of this. 
2 The  representat iona l  requ i rements  
o f  generat ion  sys tems 
We noted in the introduction that generation 
systems have to deal with a range of linguis- 
tic information. It is natural, especially in the 
context of a generic architecture proposal, to 
model this breadth in terms of discrete layers 
of representation: (1999a) introduce layers such 
as conceptual, semantic, rhetorical, syntactic 
and document structure, but the precise demar- 
cation is not as important here as the princi- 
ple. The different kinds of information are typi- 
cally represented differently, and built up sepa- 
rately. However the layers are far from indepen- 
dent: objects at one layer are directly related to 
those at others, forming chains of dependency 
from conceptual through rhetorical and seman- 
tic structure to final syntactic and document re- 
alisation. This means that data resources, such 
as grammars and lexicons, and processing mod- 
ules in the system, are often defined in terms of 
mixed  data: structures that include informa- 
tion in more than one representation layer. So 
the ability to represent such mixed structures 
in a single formal framework is an important 
property of a generic data proposal. 
In addition, it is largely standard in gener- 
ation as elsewhere in language applications, to 
make extensive use of par t ia l  representations, 
often using a type system to capture grades of 
underspecification. An immediate corollary of 
providing support for partial structures is the 
notion that they may become further specified 
over time, that data structures evolve. If the 
framework seeks to avoid over-commitment to 
particular processing strategies it needs to pro- 
vide a way of representing such evolution ex- 
plicitly if required, rather than relying on de- 
structive modification of a structure. Related 
to this, it should provide explicit support for 
representing a l te rnat ive  specifications at any 
point. Finally, to fully support efficient pro- 
cessing across the range of applications, from 
the simple to the most complex, the represen- 
tation must allow for compact sharing of infor- 
mation in tang led  structures (two structures 
which share components). 
In addition to these direct requirements of the 
generation task itself, additional requirements 
arise from more general methodological consid- 
erations: we desire a representation that is for- 
mally well  def ined,  allows for theoretical rea-  
son ing about the data and performance of sys- 
tems, and supports control regimes from simple 
deterministic pipelines to complex parallel ar- 
chitectures. 
3 The  Representat ion  Scheme 
In this section, we present our proposal for a 
general representation scheme capable of cover- 
ing the above requirements. Our formulation is 
layered: the foundation is a simple, flexible, rig- 
orously defined graph representation formalism, 
on top of which we introduce notions of com- 
plex types and larger data structures and rela- 
tionships between them. This much is sufficient 
to capture the requirements just discussed. We 
suppose a yet higher level of specification could 
capture a more constraining data model but 
make no specific proposals about this here, how- 
ever the following sections use examples that do 
conform to such a higher level data model. 
The lowest level of the representation scheme 
is: 
? re lat iona l :  the basic data entity is x -~ y, 
an ar row representing a relation from ob- 
ject x to object y; 
? typed:  objects and arrows have an asso- 
ciated type system, so it is possible to de- 
fine classes and subclasses of objects and 
arrows. 
At the most fundamental level, this is more or 
less the whole definition. There is no commit- 
ment to what object or arrow types there are or 
120 
how they relate to each other. So a representa- 
tion allowed by the scheme consists of: 
? a set of objects, organised into types; 
? a set of binary relations, organised into 
types; 
? a set of arrows, each indicating that a rela- 
tion holds between one object and another 
object. 
Sets,  sequences  and  funct ions  
For the next level, we introduce more struc- 
ture in the type system to support sets, se- 
quences and functions. Objects are always 
atomic (though they can be of type set, se- 
quence or function) - it is not possible to make 
an object which actually is a set of two other 
objects (as you might with data structures in a 
computer program). To create a set, we intro- 
duce a set type for the object, and a set mem- 
bership arrow type (el), that links the set's el- 
ements to the set. Similarly, for a sequence, we 
introduce a sequence type and sequence mem- 
ber arrow types (1-el, 2-el, 3-el, . . .  ), and for a 
function, we have a complex type which spec- 
ifies the types of the arrows that make up the 
domain and the range of the function. 
SemRep 
~ fun(Role.SemRep) 
7 V show SemRep SemRep 
Figure 1: The partial semantic representation 
of "The second chart shows the number of days 
on the market" 
As an example, consider Figure 1, which 
shows a semantic representation (SemRep) from 
the CGS reimplementation. Here, the tree 
nodes correspond to objects, each labelled with 
its type. The root node is of type SemRep, and 
although it is not an explicit sequence type, we 
can see that it is a triple, as it has three sequence 
member arrows (with types 1-el, 2-el and 3-el). 
Its first arrow's target is an object of type DR 
(Discourse Referent). Its second represents a set 
of SemPred (Semantic Predicate) objects, and in 
this case there's just one, of type show. Its third 
element is a (partial) function, from Role arrow 
types (agent and affected are both subtypes of 
Role) to SemReps. (In this case, the SemReps 
have not yet been fully specified.) 
Local  and  non- loca l  a r rows  
The second extension to the basic representa- 
tion scheme is to distinguish two different ab- 
stract kinds of arrows - local and non-local. 
Fundamentally we are representing just a homo- 
geneous network of objects and relationships. In 
the example above we saw a network of arrows 
that we might want to view as a single data 
structure, and other major data types might 
similarly appear as networks. Additionally, we 
want to be able to express relationships between 
these larger 'structures' - between structures 
of the same type (alternative solutions, or re- 
vised versions) or of different ypes (semantic 
and syntactic for example). To capture these 
distinctions among arrows, we classify our ar- 
row types as local or non-local (we could do 
this in the type system itself, or leave it as an 
informal distinction). Local arrows are used to 
build up networks that we think of as single 
data structures. Non-local arrows express rela- 
tionships between such data structures. 
All the arrow types we saw above were local. 
Examples of non-local arrows might include: 
real ises These arro~vs link something more ab- 
stract to something less abstract hat re- 
alises it. Chains of realises arrows might 
lead from the original conceptual input to 
the generator through rhetorical, seman- 
tic and syntactic structures to the actual 
words that express the input. 
revises These arrows link a structure to an- 
other one of the same type, which is con- 
sidered to be a 'better' solution - perhaps 
because it is more instantiated. It is impor- 
tant to note that parts of larger structures 
can be revised without revising the entire 
structure. 
coreference These arrows link structures 
which are somehow "parallel" and which 
perhaps hare some substructure, i.e., tan- 
gled structures. For instance, document 
representations may be linked to rhetorical 
representations, either as whole isomorphic 
structures or at the level of individual con- 
stituents. 
121 
Notice that the representation scheme does 
not enforce any kind of well-formedness with 
respect o local and non-local arrows. In fact, 
although it is natural to think of a 'structure' as 
being a maximal network of local arrows with 
a single root object, there's no reason why this 
should be so - networks with multiple roots rep- 
resent tangled structures (structures that share 
content), networks that include non-local links 
might be mixed representations, containing in- 
formation of more than one sort. Such tech- 
niques might be useful for improving generator 
efficiency, or representing canned text or tem- 
plates, cf. (Calder et al, 1999). 
Par t ia l  and  Opaque s t ruc tures  
Partial structures are essential when a module 
needs to produce a skeleton of a representa- 
tion that it does not have the competence to 
completely fill out. For instance, lexical choice 
brings with it certain syntactic commitments, 
but in most NLG systems lexical choice occurs 
some time before a grammar is consulted to 
flesh out syntactic structure in detail. 
Figure 2: A partial structure 
By simply leaving out local arrows, we can 
represent a range of partial structures. Con- 
sider Fig. 2, where the triangles represent local 
structure, representing a sentence object and its 
component verb phrase. There is a link to a sub- 
ject noun phrase object, but none of the local 
arrows of the actual noun phrase are present. In 
subsequent processing this local structure might 
be filled in. This is possible as long as the noun 
phrase object has been declared to be of the 
right type. 
An opaque structure is one which has an in- 
complete derivational history - for example part 
of a syntactic structure without any correspond- 
ing semantic structure. Three possible reasons 
for having such structures are (a) to allow struc- 
ture to be introduced that the generator is not 
capable of producing directly, (b) to prevent he 
generator from interfering with the structure 
thus built (for example, by trying to modify an 
idiom in an inappropriate way), or (c) to im- 
prove generator efficiency by hiding detail that 
may lead to wasteful processing. An opaque 
structure is represented simply by the failure 
to include a rea l i ses  arrow to that structure. 
Such structures provide the basis for a gener- 
alised approach to "canning". 
4 Imp lementat ion  
There are many ways that modules in an 
NLG system could communicate information 
using the representation scheme just outlined. 
Here we describe a particularly general model 
of inter-module communication, based around 
modules communicating with a single cen- 
tralised repository of data called the whiteboard 
(Calder et al, 1999). A whiteboard is a cumu- 
lative typed relational blackboard: 
? t yped  and  re lat iona l :  because it is based 
on using the above representation scheme; 
? a b lackboard :  a control architec- 
ture and data store shared between 
processing modules; typically, modules 
add/change/remove objects in the data 
store, examine its contents, and/or ask to 
be notified of changes; 
? cumulat ive :  unlike standard blackboards, 
once data is added, it can't be changed or 
removed. So a structure is built incremen- 
tally by making successive copies of it (or of 
constituents of it) linked by rev ises  links 
(although actually, there's no constraint on 
the order in which they are built). 
A whiteboard allows modules to add ar- 
rows (typically forming networks through ar- 
rows sharing source or target objects), to in- 
spect the set of arrows looking for particular 
configurations of types, or to be informed when 
a particular type of arrow (or group of arrows) 
is added. 
The whiteboard is an active database server. 
This means that it runs as an independent pro- 
cess that other modules connect o by appropri- 
ate means. There are essentially three kinds of 
interaction that a module might have with the 
whiteboard server: 
? pub l i sh  - add an arrow or arrows to the 
whiteboard; 
122 
? query  - look for an arrow or arrows in the 
whiteboard; 
? wa i t  - register interest in an arrow or ar- 
rows appearing in the whiteboard. 
In both query and wait ,  arrows are specified 
by type, and with a hierarchical type system on 
objects and relations, this amounts to a pattern 
that matches arrows of subtypes as well. The 
wait  function allows the whiteboard to take the 
initiative in processing - if a module wai ts  on a 
query then the whiteboard waits until the query 
is satisfied, and then tells the module about it. 
So the module does not have to continuously 
scan the whiteboard for work to do, but can 
let the whiteboard tell it as soon as anything 
interesting happens. 
Typically a module will start up and regis- 
ter interest in the kind of arrow that represents 
the module's input data. It will then wait for 
the whiteboard to notify it of instances of that 
data (produced by other modules), and when- 
ever anything turns up, it processes it, adding 
its own results to the whiteboard. All the mod- 
ules do this asynchronously, and processing con- 
tinues until no module has any more work to 
do. This may sound like a recipe for confusion, 
but more standard pipelined behaviour is not 
much different. In fact, pipelining is exactly a 
data-based constraint - the second module in a 
pipeline does not start until the first one pro- 
duces its output. 
However, to be a strict pipeline, the first mod- 
ule must produce all of its output before the sec- 
ond one starts. This can be achieved simply by 
making the first module produce all its output 
at once, but sometimes that is not ideal - for ex- 
ample if the module is recursive and wishes to 
react to its own output. Alternative strategies 
include the use of markers in the whiteboard, 
so that modules can tell each other that they've 
finished processing (by adding a marker), or 
extending the whiteboard architecture itself so 
that modules can tell the whiteboard that they 
have finished processing, and other modules can 
wait for that to occur. 
5 Reconst ruct ion  o f  the  Capt ion  
Generat ion  System 
In order to prove this representation scheme 
in practice, we have implemented the white- 
board in Sicstus Prolog and used it to support 
data communications between modules in a re- 
construction of the Caption Generation System 
(Mittal et al, 1995). CGS is a system developed 
at the University of Pittsburgh, which takes in- 
put from the SAGE graphics presentation sys- 
tem (Roth et al, 1994) and generates captions 
for the graphics SAGE produces. We selected it 
for this effort because it appeared to be a fairly 
simple pipelined system, with modules perform- 
ing clearly defined linguistic tasks. As such, we 
thought it would be a good test case for our 
whiteboard specification. 
Although the CGS is organised as a pipeline, 
shown in Figure 3, the representations commu- 
nicated between the modules do not correspond 
to complete, separate instances of RAGS data- 
type representations. Instead, the representa- 
tions at the various levels accumulate along the 
pipeline or are revised in a way that does not 
correspond exactly to module boundaries. Fig- 
ure 3 gives a simple picture of how the different 
levels of representation build up. The labels for 
the RAGS representations refer to the following: 
? I = conceptual; 
? II -- semantic; 
? I I I  = rhetorical; 
? IV = document; 
? V = syntactic. 
For instance, some semantic (II) information is 
produced by the Text Planning module, and 
more work is done on this by Aggregation, but 
the semantic level of representation is not com- 
plete and final until the Referring Expression 
module has run. Also, for instance, at the 
point where the Ordering module has run, there 
are partially finished versions of three different 
types of representation. It is clear from this that 
the interfaces between the modules are more 
complex than could be accounted for by just re- 
ferring to the individual evels of representation 
of RAGS. The ability to express combinations of 
structures and partial structures was fundamen- 
tal to the reimplementation of CGS. We high- 
light below a few of the interesting places where 
these features were used. 
123 
AbsSemRep 
I-el ~ ~  .................................... SemRep 
--(~------~_set{KBPredl ~ fun(Role,set(KBId)) I-el ~3-e l  
. . . .  /X  . . . . . . . .  
el agent affected . . . .  DR fun(Role,set(SemRep)) ~i/  ~ ..... ~ el?set(SemPredi~t A ~ . ? 
nresent set(KSld) 0 . . . . . .  v ? ~--"- ................. / agen, /  \a\] Jec,ea 
el / \ el . . . . .  " . . . . . . . . . .  ~ ?J / "k~ present S~mRep SemRep 
chart1 chart2 
Figure 4: Combined Abstract Semantic Representation a d Concrete Semantic Representation for 
the output: "These two charts present information about house sales from data-set ts-1740" 
CG$ aroh i ta ,~ lu 'e  RAGS representat/on$ 
II I l l  IV ~' SAGE 
- -  . . . . . . . . . .  
tuning II 
- . . . . . . . . . .  
I1 I11 iV  
--' . . . . . . . . . .  
I\[ I11 IV 
. . . . . . . . . .  I ;11@ 
11 III I v  v 
. . . . . . . . .  
II I11 IV V 
. . . . . . . . .  III1  
II 111 IV V 
l - -  . . . . . . . . . .  I I I I I  
FUF 
Figure 3: A RAGS view of the CGS system 
5.1 Referr ing Express ion Generat ion  
In many NLG systems, (nominal) referring ex- 
pression generation is an operation that is in- 
voked at a relatively late stage, after the struc- 
ture of individual sentences i  fairly well speci- 
fied (at least semantically). However, referring 
expression generation eeds to go right back to 
the original world model/knowledge base to se- 
lect appropriate semantic ontent o realise a 
particular conceptual item as an NP (whereas 
all other content has been determined much ear- 
lier). In fact, there seems to be no place to 
put referring expression generation i a pipeline 
without there being some resulting awkward- 
ness. 
In RAGS, pointers to conceptual items can 
be included inside the first, "abstract", level of 
semantic representation (AbsSemRep), which is 
intended to correspond to an initial bundling of 
conceptual material under semantic predicates. 
On the other hand, the final, "concrete", level 
of semantic representation (SemRep) is more 
like a fully-fledged logical form and it is no 
longer appropriate for conceptual material to 
be included there. In the CGS reimplementa- 
tion, it is necessary for the Aggregation mod- 
ule to reason about the final high-level semantic 
representation f sentences, which means that 
this module must have access to "concrete" se- 
mantic representations. The Referring Expres- 
sion generation module does not run until later, 
which means that these representations cannot 
be complete. 
Our way around this was to ensure that the 
initial computation of concrete semantics from 
abstract semantics (done as part of Aggrega- 
tion here) left a record of the relationship by 
including realises arrows between correspond- 
ing structures. That computation could not be 
completed whenever it reached conceptual ma- 
terial - at that point it left a "hole" (an ob- 
ject with no further specification) in the con- 
crete semantic representation li ked back to the 
conceptual material. When referring expression 
was later invoked, by following the arrows in the 
124 
resulting mixed structure, it could tell exactly 
which conceptual entity needed to be referred 
to and where in the semantic structure the re- 
sulting semantic expression should be placed. 
Figure 4 shows the resulting arrangement for 
one example CGS sentence. The dashed lines 
indicate realises, i.e. non-local, arrows. 
5.2 Handling Centering Information 
The CGS Centering module reasons about the 
entities that will be referred to in each sentence 
and produces a representation which records the 
forward and backward-looking centers (Grosz et 
al., 1995). This representation is later used by 
the Referring Expression generation module in 
making pronominalisation decisions. This in- 
formation could potentially also be used in the 
Realisation module. 
Since Centering is not directly producing re- 
ferring expressions, its results have to sit around 
until they can actually be used. This posed 
a possible problem for us, because the RAGS 
framework does not provide a specific level of 
representation for Centering information and 
therefore seems on first sight unable to account 
for this information being communicated be- 
tween modules. The solution to the problem 
came when we realised that Centering informa- 
tion is in fact a kind of abstract syntactic in- 
formation. Although one might not expect ab- 
stract syntactic structure to be determined until 
the Realisation module (or perhaps lightly ear- 
lier), the CGS system starts this computation i
the Centering module. 
Thus in the reimplementation, the Centering 
module computes (very partial) abstract syn- 
tactic representations for the entities that will 
eventually be realised as NPs. These represen- 
tations basically just indicate the relevant Cen- 
tering statuses using syntactic features. Figure 
5 shows an example of the semantics for a typi- 
cal output sentence and the two partial abstract 
syntactic representations computed by the Cen- 
tering module for what will be the two NPs in 
that sentence 2. As before, dashed lines indicate 
realises arrows. Of course, given the discussion 
of the last section, the semantic representation 
objects that are the source of these arrows are in 
fact themselves linked back to conceptual enti- 
ties by being the destination of realises arrows 
2FVM = Feature Value Matrix. 
from them. 
When the Referring Expression generation 
module runs, it can recover the Centering infor- 
mation by inspecting the partial syntactic rep- 
resentations for the phrases it is supposed to 
generate. These partial representations are then 
further instantiated by, e.g., Lexical Choice at 
later stages of the pipeline. 
6 Conc lus ion  
The representation scheme we have proposed 
here is designed specifically to support he re- 
quirements of the current state-of-the-art NLG 
systems, and our pilot implementation demon- 
strates the practical applicability of the pro- 
posal. Tangled, partial and mixed structures 
are of obvious utility to any system with a flex- 
ible control strategy and we have shown here 
how the proposed representation scheme sup- 
ports them. By recording the derivational his- 
tory of computations, it also supports decisions 
which partly depend on earlier stages of the 
generation process (e.g., possibly, lexical choice) 
and revision-based architectures which typically 
make use of such information. We have shown 
how the representation scheme might be the ba- 
sis for an inter-module communication model, 
the whiteboard, which supports a wide range of 
processing strategies that require the represen- 
tation of complex and evolving data dependem 
cies. The fact that the whiteboard is cumula- 
tive, or monotonic in a logical sense, means that 
the whiteboard also supports reasoning about 
the behaviour of NLG systems implemented in 
terms of it. This is something that we would 
like to exploit directly in the future. 
The reimplementation f the CGS system 
in the RAGS framework was a challenge to 
the framework because it was a system that 
had already been developed completely inde- 
pendently. Even though we did not always un- 
derstand the detailed motivation for the struc- 
ture of CGS being as it was, within a short time 
we reconstructed a working system with mod- 
ules that corresponded closely to the original 
CGS modules. The representation scheme we 
have proposed here was a key ingredient in giv- 
ing us the flexibility to achieve the particular 
processing scheme used by CGS whilst remain- 
ing faithful to the (relatively simple) RAGS 
data model. 
125 
SemRep 
fun(Role,setlSemRep)) 
sl S " ' .  
t t ~ .  
2 AbsSynRep "~ AbsSynRep _(:5 ~ ,  
, , / \ \ 
ckward-looking-cemer ckward.looking-cenler 
+ + 
Figure 5: Arrangement of centering information for the output sentence above 
The representation scheme is useful in situa- 
tions where modules need to be defined and im- 
plemented to work with other modules, possibly 
developed by different people. In such cases, the 
representation scheme we propose permits pre- 
cise definition of the interfaces of the modules, 
even where they are not restricted to a single 
'level' of representation. Even though the con- 
trol structure of CGS is quite simple, we found 
that the use of a centralised whiteboard was use- 
ful in helping us to agree on interfaces and on 
the exact contribution that each module should 
be making. Ultimately, it is hoped that the use 
of a scheme of this type will permit much more 
widespread 'plug-and-play' among members of 
the NLG community. 
Re ferences  
Lynne Cahill, Christy Doran, Roger Evans, Chris 
Mellish, Daniel Paiva, Mike Reape, Donia Scott, 
and Neil Tipper. 1999a. In Search of a Reference 
Architecture for NLG Systems. In Proceedings of 
the 7th European Workshop on Natural Language 
Generation, pages 77-85, Toulouse. 
Lynne Cahill, Christy Doran, Roger Evans, Chris 
Mellish, Daniel Paiva, Mike Reape, Donia Scott, 
and Neil Tipper. 1999b. Towards a Reference 
Architecture for Natural Language Genera- 
tion Systems. Technical Report ITRI-99-14, 
Information Technology Research Institute 
(ITRI), University of Brighton. Available at 
http://www, i t r i  .brighton. ac. uk/proj ects/rags.  
Jo Calder, Roger Evans, Chris Mellish, and Mike 
Reape. 1999. "Free choice" and templates: how 
to get both at the same time. In "May I speak 
freely?" Between templates and free choice in nat- 
ural language generation, number D-99-01, pages 
19-24. Saarbriicken. 
B.J. Grosz, A.K. Joshi, and S. Weinstein. 1995. 
Centering: a framework for modelling the local co- 
herence of discourse. Computational Linguistics, 
21 (2):203-226. 
V. O. Mittal, S. Roth, J. D. Moore, J. Mattis, and 
G. Carenini. 1995. Generating explanatory cap- 
tions for information graphics. In Proceedings of 
the 15th International Joint Conference on Ar- 
tificial Intelligence (IJCAI'95), pages 1276-1283, 
Montreal, Canada, August. 
V. O. Mittal, J. D. Moore, G. Carenini, and S. Roth. 
1998. Describing complex charts in natural lan- 
guage: A caption generation system. Computa- 
tional Linguistics, 24(3):431-468. 
Ehud Reiter. 1994. Has a consensus NL generation 
architecture appeared and is it psycholinguisti- 
cally plausible? In Proceedings of the Seventh In- 
ternational Workshop on Natural Language Gen- 
eration, pages 163-170, Kennebunkport, Maine. 
Steven F. Roth, John Kolojejchick, Joe Mattis, and 
Jade Goldstein. 1994. Interactive graphic design 
using automatic presentation knowledge. In Pro- 
ceedings of CHI'9~: Human Factors in Computing 
Systems, Boston, MA. 
126 
c? 2003 Association for Computational Linguistics
Document Structure
Richard Power? Donia Scott?
University of Brighton University of Brighton
Nadjet Bouayad-Agha?
University Pompeu Fabra
We argue the case for abstract document structure as a separate descriptive level in the anal-
ysis and generation of written texts. The purpose of this representation is to mediate between the
message of a text (i.e., its discourse structure) and its physical presentation (i.e., its organization
into graphical constituents like sections, paragraphs, sentences, bulleted lists, figures, and foot-
notes). Abstract document structure can be seen as an extension of Nunberg?s ?text-grammar?;
it is also closely related to ?logical? markup in languages like HTML and LaTEX. We show that
by using this intermediate representation, several subtasks in language generation and language
understanding can be defined more cleanly.
1. Introduction
When language is written, it appears as a collection of words set out on one or more
(actual or virtual) pages. In fact, much of what we tend to call ?text? has a strong
graphical component (Schriver 1997; Scott and Power 2001). Not only are the words
often accompanied by conventional graphics such as pictures or diagrams, but they
themselves form graphical elements such as titles, headings, chapters, sections, cap-
tions, paragraphs, and bulleted lists.
The overlay of graphics on text is in many ways equivalent to the overlay of
prosody on speech. Just as all speech has prosody (even if it is a monotone), so too do
all texts have layout (even if it is simple wrapped format, in a single face and font, and
makes rudimentary use of white space). And just as prosody undoubtedly contributes
to the meaning of utterances, so too does a text?s graphical presentation contribute to its
meaning. However, although there is a long tradition and rich linguistic framework for
describing and representing speech prosody (e.g., Halliday 1967; Chomsky and Halle
1968; Crystal 1969; Bolinger 1972; Pierrehumbert 1980; ?t Hart, Collier, and Cohen 1990;
Ladd 1996), the same is not true for text layout. Perhaps not surprisingly, therefore, few
natural language understanding (NLU) systems use graphical presentational features
to aid interpretation, and few natural language generation (NLG) systems attempt to
render the output texts in a principled way.
Of course, since all texts have a graphical dimension, all NLG systems will, by
definition, produce laid-out texts. In all but a few recent cases (the ICONOCLAST sys-
tem (Power 2000; Bouayad-Agha, Power, and Scott 2000; Bouayad-Agha, Scott, and
Power 2001; Bouayad-Agha 2001) and the DArtbio system (Bateman et al 2001)), this
is achieved by mapping directly from the underlying discourse structure (Arens and
? Information Technology Research Institute, University of Brighton, Lewes Road, Brighton BN2 4GJ,
UK. Email: {firstname.lastname}@itri.bton.ac.uk.
? Departament de Tecnologia, University Pompeu Fabra, Barcelona, Spain. Email: Nadjet.Bouayad@
tecm.upf.es.
212
Computational Linguistics Volume 29, Number 2
Hovy 1990; DiMarco et al 1995; Paris et al 1995; Power and Cavallotto 1996; Lavoie
and Rambow 1997; Mittal et al 1998). In other cases, the text is mapped onto pre-
determined genre-specific layout patterns?for example, for verbalizing mathematical
proofs (Huang and Fiedler 1997) or producing letters for customers (Coch 1996). If we
take, as most do, the level of discourse structure as representative of the underlying
message of a text, such systems are subject to a fundamental limitation. Simply put, for
each message there will be but one possible form of presentation.
As an illustration let us briefly consider the well-known consensus architecture
for NLG systems proposed by Reiter (1994). This architecture, based on a survey
of NLG systems from the 1980s and early 1990s, takes the form of a ?pipeline? in
which five modules are applied in sequence: content determination, sentence planning,
surface generation, morphology, and formatting. Sentence planning maps ?conceptual
structures into linguistic ones . . . grouping information into clauses and sentences?
(Reiter 1994, page 164), but formatting (specified, for example, by LaTEX markup) occurs
only in the final formatting stage. In consequence, the organization of material into
paragraphs, bulleted lists, etc., is considered only after the wording has been fixed.
Graphical presentation, however, clearly interacts with wording. For example, the
section of a message that, at the level of discourse, is composed of a list relation,
will be expressed differently depending on whether, at the presentational level, it is
mapped onto a vertical or horizontal list. Consider a simple example like the following,
taken from a patient information leaflet (PIL):
(1) Are you taking any of the following:
? Anticoagulants?
? Lithium?
? Methotrexate?
? Any other medicines which your doctor does not know about?
(Voltarol leaflet, Geigy; from APBI 1997)
If the very same content were presented instead as a horizontal list, we would expect
to get something like:
(2) Are you taking anticoagulants, lithium, methotrexate, or any other medicines which
your doctor does not know about?
Now all the information is packed into one sentence, with some missing and addi-
tional words, wildly different punctuation, and less generous use of upper-case letters.1
Mapping directly from discourse structure to graphical presentation during generation
therefore limits not only the choice of possible layout, but also the choice of possible
wording.
There have been some recent attempts to develop NLG systems that generate doc-
uments rather than just texts. Instead of producing text plans, they produce document
plans. Typically these are the text plans of old (i.e., structures of ordered content ele-
ments represented in terms of rhetorical structure theory (Mann and Thompson 1986,
1987)), but extended to include pictures or diagrams as content elements, and with
additional annotations for metalevel elements such as paragraph or sentence bound-
aries. Figure 1 shows the type of document plan proposed by Reiter and Dale (2000).
1 Indeed, it appears to be the case that the more graphical the presentation is, the greater the difference
in wording is likely to be over the unmarked case of plain text (Bouayad-Agha, Scott, and Power 2000).
213
Power, Scott, and Bouayad-Agha Document Structure
still very depleted.  Heavy rain fell on the 27th and 28th.
The month was slightly warmer than average with almost exactly the average rainfall, but rainfall for the year is 
Weather Summary for July 1996
DocumentPlan 
Relation = Sequence
Document Plan
Relation = NarrativeSequence
RainEventMsg
     [28th]
DocumentPlan
Relation = Contrast
DPDocument
Title = "Weather Summary for July 1996"
Relation = Sequence
RainEventMsg
     [27th]
MonthlyTemperatureMsg
MonthlyRainfallMsg TotalRainSoFarMsg
Nucleus Satellite
Figure 1
A document plan and associated text (Reiter and Dale 2000).
Although this approach allows for a more reasoned presentational format, by conflat-
ing discourse and presentational features into one structure, the possible generated
expressions of any given message are once again strongly limited relative to the set of
all possible valid expressions.
We wish to argue the case for a separate descriptive level in the analysis and gen-
eration of written texts, which we will call document structure. Informally, document
structure describes the organization of a document into graphical constituents like
sections, paragraphs, sentences, bulleted lists, and figures; it also covers some features
within sentences, including quotation and emphasis. Although document structure
applies equally to NLU and NLG, we will focus our attention here on its role in the
generation of appropriate presentations (both wording and layout) of texts. As we will
try to show, texts (unless they are fairly simple) cannot be produced to a satisfactory
standard unless document structure is specified earlier in the process than suggested
in previous works (e.g., Reiter 1994; Reiter and Dale 2000), so that interactions with
meaning and wording are taken into account.
The plan of the article is as follows. In section 2 we explain more fully what we
mean by document structure, acknowledging its origins in Nunberg?s (1990) work and
text markup languages such as LaTEX and HTML. Section 3 discusses the relationship
of document structure to rhetorical organization and syntax. Section 4 presents the
formal theory of document structure, and Section 5 shows how it is applied in the
ICONOCLAST system. Finally, Section 6 summarizes the argument and discusses some
other approaches to the representation and generation of layout.
214
Computational Linguistics Volume 29, Number 2
2. Defining Document Structure
2.1 Nunberg?s Text Grammar
Our point of departure has been the theory of text structure proposed by Nunberg
(1990) in The Linguistics of Punctuation. This book introduces two crucial clarifications.
First, it distinguishes text structure,2 which is realized by punctuation and layout, from
syntactic structure. Second, it distinguishes abstract features of text structure from the
concrete (or graphical) features through which they are expressed.
The distinction between text structure and syntax can best be explained by consid-
ering two interpretations of the word sentence. In linguistics, sentence is used mainly as
a syntactic category, defined by phrase structure rules such as S ? NP+VP. However,
a sentence can also be viewed orthographically as a portion of text starting with a
capital letter and ending in a period; to distinguish this from the syntactic category,
Nunberg calls it a text-sentence. Sometimes the two categories of sentence coincide,
but often they do not. Thus in the following passage:
(3) He entered the office. Disaster. The safe was open and the money had gone.
the first text-sentence is also a syntactic sentence, but the second is merely a noun,
and the third comprises two syntactic sentences (or three, if we count the whole as
well as its parts). Nunberg argues that if we have two kinds of category, then we need
two kinds of grammar: he calls them the lexical grammar (we prefer syntactic gram-
mar) and the text-grammar. In addition to text-sentence, the text-categories include
text-clause, paragraph, and section, and the text-grammar allows us to formulate con-
stituent structure rules such as
St ? Ct+
meaning that a text-sentence comprises one or more text-clauses.
In introducing the concepts text-sentence, text-clause, etc., it is convenient to explain
them in terms of their realization in punctuation and layout: thus a text-sentence
starts with a capital letter and ends in a period; a text-clause ends in a semicolon;
a paragraph begins on a new line with a tab. However, this is not strictly correct.
In Nunberg?s theory, these concepts represent abstract structural properties of the text
that may be realized differently according to context or convention. In the case of
paragraph this distinction is obvious, since we are all familiar with several devices for
expressing paragraph boundaries: instead of a new line with a tab, for example, an
editor might prefer two new lines (or some other vertical space) with no tab. However,
the abstract/concrete distinction also applies to the other text-categories. For example,
the passage:
(4) The safe was open; the money had gone.
contains two text-clauses, but the second has no semicolon because its ending coincides
with the closure of a larger unit, a text-sentence, which is marked by a period. Similarly,
the stop at the end of a text-sentence is often dropped when the sentence is an item
2 This should not be confused with the use of this term within the NLG literature to refer to the
discourse structure of a text.
215
Power, Scott, and Bouayad-Agha Document Structure
in a vertical list, for instance, in a sequence of instructions:
(5) To save the file:
1. Open the Save dialogue-box
2. Enter the filename
3. Click on the Save button
Thus text structure is realized by punctuation (and layout), but the two are not equiv-
alent.
2.2 Markup Languages
Nunberg?s notion of text structure, or our wider notion of document structure, has an
obvious connection to the markup languages (e.g., LaTEX, SGML) now in common use
as a method for specifying layout in an ASCII source file. The common philosophy
of these languages is that markup should abstract from the visual appearance of the
document, using concepts like paragraph that might be realized graphically in different
ways, depending on a separate style definition.
This approach has several advantages, of which the most obvious is flexibility.
An exact specification of the desired spatial layout can yield only one printed form
of the document; by employing abstract categories, definitions using LaTEX or SGML
can produce a range of printed forms, depending on which style file is used. Less
obviously, the markup language can be tailored to the genre of the document, so that,
for example, a poem may have a constituent marked stanza, whereas a letter may have
one marked address.
In practice, this separation of abstract structure from visual realization is not car-
ried through consistently; for reasons of convenience, authors sometimes prefer to
have direct control over appearance. Thus LaTEX, for example, allows both the abstract
tag em, meaning emphasis, and the visual tag it, meaning italic face. Vertical separation
is usually achieved through abstract tags like section and itemize but may also be
imposed directly using vspace. All these devices have counterparts in HTML: thus
a typical reference guide to HTML (Ford and Dixon 1996) explicitly distinguishes
?logical? tags such as <EM> from ?visual? tags such as <I>.
More subtly, the markup languages in common use do not attempt to cover struc-
tural units that are realized through punctuation rather than layout. Paragraphs may
be marked (albeit implicitly in LaTEX), but lower units such as text-sentence and text-
clause are not. No doubt there are good practical reasons for this approach, but some
opportunities for stylistic variation are thereby lost. Consider, for example, the simple
case of reported speech in example (6a). If this were marked up as a sentence contain-
ing a quotation, it could be punctuated differently, with the period outside the closing
quotation mark (6b), perhaps, or using double quote (6c), or even using a dash with
no quotation marks at all (6d) (as in James Joyce?s Ulysses):
(6)
(a) She said ?Come up and see me sometime.?
(b) She said ?Come up and see me sometime?.
(c) She said ?Come up and see me sometime.?
(d) She said?Come up and see me sometime.
Thus although markup languages provide some guidance toward a formal treat-
ment of document structure, they often deviate, for practical reasons, from the philo-
sophical ideal of separating abstract structure from visual presentation. On the one
216
Computational Linguistics Volume 29, Number 2
hand, some tags (e.g., italic face) are clearly visual and should not be included in
abstract document structure at all. On the other hand, some abstract categories (e.g.,
text-sentence, quoted speech) are omitted from the tag set and thus cannot be realized
in a range of different graphical styles.
Despite these compromises, markup languages are based on a key insight that is
highly relevant to natural language analysis and generation: layout can be matched to
wording through the mediation of abstract document structure. Consider the following three
versions of a passage adapted from a patient information leaflet:
(7)
(a) Elixir is a white cream.
It is used in the treatment of cold sores.
It contains aliprosan. This is effective against a range of viral skin disorders.
It should be used only on your lips and face.
(b) Elixir is a white cream.
It is used in the treatment of cold sores.
It contains aliprosan. This is effective against a range of viral skin disorders.
It should be used only on your lips and face.
(c) Elixir is a white cream. It is used in the treatment of cold sores. It contains aliprosan.
This is effective against a range of viral skin disorders. N.B. Elixir should be used only
on your lips and face.
Suppose that example (7a) has been produced by author A, a novice in document
design, and passed to a more experienced designer B for revision. The passage looks
odd because it has four very short paragraphs, but short paragraphs are common
in this genre, and B decides that the ugly appearance can be corrected simply by
realizing paragraphs through a vertical space with no tab. In addition, B notices that
boldface has been used for two different purposes: highlighting the product name
and emphasizing only; this ambiguity is removed by changing emphatic boldface to
small caps. Both these revisions, shown in version (7b), concern realization rather than
abstract structure, and consequently they do not affect the validity of the wording.
For final checking the passage is then passed to a senior expert C, whose prefer-
ences are more traditional: in particular, C dislikes short paragraphs and variations
in typeface. Glaring at the waste of space in version (7b), C takes out the paragraph
boundaries and removes the emphasis on only. These are not merely changes in graph-
ical realization: they also affect the abstract document structure. In general, such changes
endanger the validity of the wording. Reading through the new version, C notices that the
pronoun it in the final sentence now seems to refer to aliprosan, not Elixir, so it has
to be replaced by the product name. To reinstate the emphasis in this sentence, C also
inserts the expression N.B. These changes lead to version (7c).
In summary, abstract document structure interacts with wording, whereas visual
realization does not. This principle explains why abstract markup is useful; it also
shows where the boundary should be drawn. By applying this principle, we might
discover that a category previously treated as visual should be reclassified as abstract.
If, for example, the change in the realization of paragraph boundaries in examples
like version (7b) required a rewording of the text, we would have to extend our set
of abstract document categories so that there were two types of paragraph instead of
one.
217
Power, Scott, and Bouayad-Agha Document Structure
3. Document Structure and Rhetorical Structure
3.1 Form and Meaning
Logically there are four possible relationships between document structure (DS) and
rhetorical structure (RS): either DS is part of RS, or RS is part of DS, or they partially
overlap, or they are distinct from one another. Our view is that they should be distinct,
just as syntax is distinct from semantics. Document structure, like syntax, describes
the form of a (mainly) linguistic product. Rhetorical structure, like semantics, describes
meaning, interpreting meaning in a broad sense that includes pragmatic features.
As an example, suppose that approve(fda, elixir) is a semantic formula meaning that
the Food and Drug Administration (FDA) approves the medicine Elixir. This semantic
formula can be realized (in English) through a range of syntactic forms, including
[S [NP [DET the][N FDA]][VP [V approves][NP Elixir]]]
which would yield ?the FDA approves Elixir?; alternative syntactic forms could be
obtained by replacing descriptions with pronouns, or by putting the whole sentence
into the passive (e.g., ?it is approved by the FDA?). Now, suppose that we add a
second semantic formula contain(elixir, gestodene), and suppose that the author knows
that gestodene is a controversial ingredient. On this basis, a rhetorical relation of
concession might be applied to the two formulas:
concession(contain(elixir, gestodone), approve(fda, elixir))
where the second argument of concession is the central one and is supported by the
first argument.3 To realize this more complex message, we may need a linguistic form
that cannot be described only by a syntactic phrase marker. In other words, we need
to consider document structure as well as syntax. Ignoring possibilities for variations
in the wording of the constituent propositions and assuming that concession may be
marked with the discourse connectives although and however, we can choose among
the following realizations of the whole message:
(8)
(a) Although Elixir contains gestodene, it is approved by the FDA.
(b) The FDA approves Elixir although it contains gestodene.
(c) Elixir contains gestodene; however, it is approved by the FDA.
(d) Elixir contains gestodene. However, it is approved by the FDA.
(e) Elixir contains gestodene.
However, it is approved by the FDA.
In versions (8a) and (8b), the rhetorical relationship is realized within a single
syntactic sentence, although before adding punctuation we need to know that this
syntactic sentence is also a text-sentence. In versions (8c)?(8e), the arguments of the
concession relation are expressed in separate syntactic sentences, so that the rela-
tionship is realized through document structure as well as syntax. In each case, the
3 These are termed nucleus and satellite in RST (Mann and Thompson 1987).
218
Computational Linguistics Volume 29, Number 2
units realizing the arguments are coordinated in document structure, satellite precedes
nucleus, and the discourse connective however is placed within the nucleus.
Our claim, then, is that document structure combines with syntax in the real-
ization of the meaning of a document, and that rhetorical structure should be re-
garded as part of meaning, not part of document structure. However, as we will now
show, this principle of clear separation of meaning and form has not always been
observed.
3.2 Rhetorical Structure Theory
Rhetorical structure theory (Mann and Thompson 1986, 1987) was developed as a
method of analyzing the rhetorical organization of texts. Formally, the theory is re-
markably simple. It proposes that a text can be analyzed, by rhetorical function, into
a set of nested spans, each span being represented by a node on an ordered tree. Each
nonterminal node on this tree is labeled with a single term describing the relationship
that holds among its constituents. These constituents may have equal importance, in
which case the relation is said to be multinuclear, or one may be rhetorically subor-
dinated to the other, in which case they are said to fulfill the roles of satellite and
nucleus. Although this scheme is obviously intended as a first approximation, it has
been widely adopted, not only by literary analysts, but also by computational linguists,
especially in the NLG community.
One aspect of RST, perhaps more presentational than substantial, has led, in our
view, to confusion: both in the text of their article and the accompanying diagrams,
Mann and Thompson seem to assert that rhetorical relations hold between spans of
text, rather than between the meanings of these texts. In other words, they treat rhetor-
ical structure as part of document structure. Mann and Thompson assert this explicitly
(1987, page 4):
Relations are defined to hold between two non-overlapping text spans,
here called the nucleus and the satellite, denoted by N and S.
where
A text span is an uninterrupted linear sequence of text.
However, it is unclear whether their claim is intentional or simply the result of an
informal style of presentation.
Would it make any sense to treat rhetorical relations as holding literally between
text spans? For clearly pragmatic relations, such as restatement, this seems a possible
position. A text span, after all, is an instrument of the writer, so it makes sense to make
a statement about the function that the instrument is supposed to serve. For clearly
semantic relations, such as nonvolitional-cause, the position is harder to maintain.
In a text like ?Mary was sad because she lost her doll?, the causal relation plainly holds
between two events, not between two spans of text.
Leaving aside intuitive plausibility, the crucial question, we think, is whether the
argument in a document can be formalized without reference to the particular text
spans through which it is realized. Could the same argument be realized by two
English texts with a different structure, or by an English text and a French text? Could
someone forget a text but remember its argument? If so, it must be possible to treat
relations like concession and nonvolitional-cause as holding between ideas rather
than units of text. Rather than creating two kinds of rhetorical relation, it seems more
parsimonious to treat the relation between ideas as primary, so that the argument of
219
Power, Scott, and Bouayad-Agha Document Structure
concession
NUCLEUSSATELLITE
however, it is approved by the FDA.Elixir contains gestodene; 
concession
The FDA approves Elixir although it contains gestodene.
NUCLEUS SATELLITE
(8c)
(8b)
Figure 2
RST analysis.
a document can be planned before the writer (or NLG system) has considered issues
of wording or linear order.4
To illustrate this point, let us go back to example (8). Suppose that we want to
show that versions (8b) and (8c) express the same argument.
(8b) The FDA approves Elixir although it contains gestodene.
(8c) Elixir contains gestodene; however, it is approved by the FDA.
Figure 2 shows RST annotations for these texts, on the assumption that rhetorical
relations hold between text spans; note, incidentally, that since related spans must
be consecutive, the discourse connectives although and however have to be included
somewhat arbitrarily in one span or the other. These annotations fail to bring out that
the two texts express the same argument, since at a textual level the spans in (8b) and
(8c) are simply different, both in wording and position.
In Figure 3, instead, different document structures are specified for versions (8b)
and (8c) and linked to a common rhetorical structure; the dotted arrows express the
relation realizes, so that, for example, each text-sentence realizes the whole rhetori-
cal structure governed by the concession relation. Note that rhetorical structures are
always unordered, whereas document structures are ordered trees. Thus the two un-
ordered propositions in the rhetorical structure of Figure 3 are realized in different
orders in the two document structures.
This distinction between rhetorical structure and document structure accounts for
some of the difficulties encountered when RST is applied as an analytic tool. The
core of the problem is that when faced with a text to analyze, the analyst applies the
principles of RST analysis to the text itself rather than to the message underlying the
text. What the analyst really needs to do is, in some way, to ?get behind the text?
to its constituent propositions and the rhetorical relations that hold between them
(Scott and Paris 1995). But instead, by applying relations to text-spans, he or she is
heavily constrained by the evident document structure of the text, and the result is a
rhetorical structure that is isomorphic to the document structure. However, as we have
4 This proposal was first made by Scott and Souza (1990).
220
Computational Linguistics Volume 29, Number 2
TEXT?SENTENCE
TEXT?PHRASE TEXT?PHRASE
TEXT?PHRASE
although
Elixir is approved by the FDA
it contains gestodene
TEXT?PHRASE
TEXT?SENTENCE
TEXT?CLAUSE TEXT?CLAUSE
Elixir contains gestodene
TEXT?PHRASE TEXT?PHRASE
however it is approved by the FDA
approve(fda, elixir) contain(elixir, gestodene)
SATELLITE
concession
NUCLEUS
RHETORICAL STRUCTURE DOCUMENT STRUCTURE (8c)DOCUMENT STRUCTURE (8b)
Figure 3
Document structure realizes rhetorical structure.
seen from the above example, the underlying rhetorical structure is not necessarily
isomorphic to the document structure;5 this means that the analysis obtained in this
way is not necessarily an accurate representation of the actual discourse structure
of the text. Consider, for example, the following excerpt from a patient information
leaflet:
(9) IF you find your condition gets worse during treatmentA you may be allergic to the
creamD or have a skin infectionE.
STOP USING THE CREAMB AND TELL YOUR DOCTOR AS SOON AS POSSIBLEC
(Betnovate leaflet, Glaxo; from APBI 1997)
Careful reading of the text, combined with world knowledge, suggests that the
following logical condition holds between the propositional content of A and the pair
B and C:
IF <condition of patient worsens during treatment>
THEN <patient must stop taking cream>
AND <patient must tell patient?s doctor>
ENDIF
In other words, the rhetorical relation of condition holds between A as satellite and
the complex of B and C (joined by a list relation) as nucleus. We learn additionally
that the reason why the patient must carry out the imperative actions of B and C is
that he or she may be either allergic to the cream (D) or have a skin infection (E). In
other words, there is a causal relation between the complex of B and C (the effect) and
complex of D and E (the cause). Representing all this in RST would yield the structure
in Figure 4.
Most people would probably agree that what is depicted in the RST structure
shown in Figure 4 captures the intended meaning of the text in the example, and that
the text itself is of reasonable quality. However, a traditional RST analysis (i.e., of the
text itself, as opposed to its underlying meaning) would not be able to produce the
structure shown here. To explicate, let us go through what the typical RST analyst
would do with this text.
The analyst would probably start by segmenting the text into elementary ?text
spans? (i.e., clauses); this would lead to the same assignment of A?E given above. The
next step would focus on the first sentence: the discourse marker if clearly suggests
the condition relation; similarly, the marker or suggests the alternative relation.
So far so good. However, the next step would be to find a relation that holds among
5 This is discussed in more detail in Bouayad-Agha, Power, and Scott (2000) and Bouayad-Agha (2001)
and in section 5.3.
221
Power, Scott, and Bouayad-Agha Document Structure
PARAGRAPH
TEXT?SENTENCE
TEXT?PHRASETEXT?PHRASE TEXT?PHRASE TEXT?PHRASE
TEXT?PHRASE
TEXT?SENTENCE
D E
B
CA
D EC
list alternative
cause
condition
A
B
SN
N S
RHETORICAL STRUCTURE DOCUMENT STRUCTURE
Figure 4
Document structure is not always isomorphic with rhetorical structure.
SN
list
N
N N NN
C D E
A
B
alternative
condition
S
result
Figure 5
Analysis when RST is applied directly to text.
the text spans in the sentence; if this cannot be done, then according to the tenets of
RST, the text is not coherent. Following this rule, the analyst is likely to make D and E
the components of the identified (multinuclear) alternative relation. Next he would
attempt to assign the satellite and nucleus of the identified condition relation; the
choice would be between A and the complex of D and E. Since the marker if must
attach to the satellite of condition, the answer seems clear:
condition(alternative(D,E),A)
(corresponding to the RST structure shown in Figure 5). But it is also clearly wrong,
since we know from our semantic analysis that what really holds is that shown in
Figure 4:
condition(list(B,C),A)
Indeed, even the layout of the text reinforces, through the use of capital letters, the
strong relationship between A and the pair B and C.
In principle, an RST structure that is derived from the analysis of a given text
should, when used as the input to an NLG system, produce the very same text and
other semantically equivalent versions of it. By separating rhetorical structure from doc-
ument structure, we can now provide a coherent framework for achieving this result.
222
Computational Linguistics Volume 29, Number 2
For instance, we can now produce not only the original text of example (9) (shown
here with neutral layout):
(9b) If you find your condition gets worse during treatment, you may be
allergic to the cream or have a skin infection. Stop using the cream and
tell your doctor as soon as possible.
but also the following (in some contexts perhaps better) variant
(9c) If you find your condition gets worse during treatment, stop using the
cream and tell your doctor as soon as possible; you may be allergic to
the cream or have a skin infection.
Of course, NLG systems that ignore the level of document structure would still be able
to produce the text in version (9b) from the RST structure in Figure 5, but they would
not be able to produce version (9c). Moreover, they could also end up producing the
following incorrect text:6
(9c) # Stop using the cream and tell your doctor as soon as possible because
you may be allergic to the cream or have a skin infection if your
condition gets worse during treatment.
A number of other researchers have identified cases in which ?orthodox? RST
analysis of a text is problematic (e.g., Moore and Pollack 1992; Moser and Moore 1996;
Knott et al 2001). For example, Knott et al (2001) report on texts from a corpus of
museum labels that violate the RST principle of continuous constituency (i.e., adjacent
units must be linked by a relation) but are nonetheless coherent. These are cases in
which the satellite of a relation is not adjacent to its own nucleus in the text. In
all the texts that Knott et al discuss, the ?dislocated? relation is elaboration, and
they attribute the source of the problem to the relation itself: elaboration is not, they
claim, a proper relation; it is a very weak relation that commands a different treatment
from the other stronger ones.
Although there may well be a strong case to be made for the ?demotion? of
elaboration and for a special treatment of it in NLG systems, the phenomenon
of dislocated satellites that Knott et al (2001) describe is not, in fact, confined to
elaboration. Indeed, it corresponds precisely to the problem we have just seen with
example (9), which involves not elaboration, but condition. We have also reported
elsewhere other similar examples of nonisomorphic rhetorical and document structures
(Bouayad-Agha, Power, and Scott 2000). In all cases that we have seen, the principles of
RST (e.g., compositionality, nuclearity, continuous constituency) appear to be violated
only because they are being applied (in the orthodox manner) to the surface text
(i.e., at the level of document structure) rather than more properly to the underlying
propositional structure of the text (i.e., at the level of rhetorical structure).
But why would one want to produce a text whose document structure is not iso-
morphic with its rhetorical structure? One rather practical reason is that as a rhetorical
structure becomes more complex, it becomes increasingly difficult for the writer to pro-
duce a text that satisfies both the demands of coherence (as defined by theories such
6 This text would result from systems that treat the leaves of a rhetorical or text plan as ordered.
223
Power, Scott, and Bouayad-Agha Document Structure
as RST) and those of syntax. This happens quite frequently, for example, with condi-
tionals: syntax dictates that expressions using the subordinating discourse marker if
must have the antecedent and consequent in the same sentence. For example:
(10) If you eat too many sweets, you will become ill.
but not
(11) # If you eat too many sweets. You will become ill.
As the consequent or its antecedent becomes more complex, the chances of satis-
fying the syntactic constraints are reduced. Here is a typical example from a PIL:
(12) If you get any of the following:
Stomach pain, indigestion, heartburn or feeling sick for the first time.
Any sign of bleeding in the stomach or intestine, for example, passing black
stools.
. . .
An unexpected change in the amount of urine produced and/or its
appearance.
STOP taking the tablets and tell your doctor.
(Voltarol leaflet, Geigy; from APBI 1997)
Here the conditional is expressed within one big sentence that itself contains several
other sentences?indeed, paragraphs?each describing a set of symptoms organized
around areas of the body. In writing this text, the author has clearly chosen to remain
faithful to the rhetorical structure at the expense of syntax.
At other times, such as the example in Figure 6, taken from Knott et al (2001), it
is the rhetorical structure that loses out. In this case, the author has decided that the
content of the satellite associated with (9) warrants its own paragraph (perhaps for
reasons to do with its size).
4. Formal Theory of Document Structure
We will describe here the formal theory of document structure that we have developed
as part of the ICONOCLAST system (Power 2000; Bouayad-Agha, Power, and Scott
2000; Bouayad-Agha 2000; Bouayad-Agha, Scott, and Power 2001), which generates
multiple versions of the same message in different styles (i.e., with different wording
and layout). In describing the theory, we will concentrate on units above the level
of text-sentence; our treatment of the lower levels varies only slightly from that in
Nunberg?s theory, which is described in great detail in Nunberg (1990).
4.1 Basic Hierarchy of Document Units
Informally it seems clear that units of document structure are ranked: sentences are
grouped into paragraphs, paragraphs into sections, sections into chapters, and so forth.
The hierarchy of categories differs from one document type to another, but there is
always some hierarchy;7 there might for instance be subsubsections and subsections
7 Exceptionally, some elements?in particular, footnotes and pictures?will be ?floating.?
224
Computational Linguistics Volume 29, Number 2
2 3 . . .
. . .
. . .< >
. . .< >
(1) In the women?s quarters the business of running the household took place.
(2) Much of the furniture was made up of chests (3) arranged vertically in matching
pairs. ... (4) Female guests were entertained in these rooms, (5) which often had
beautifully carved wooden toilet boxes (6) with fold?away mirrors and sewing
boxes, (7) and folding screens, (8) painted with birds and flowers.
(9) Chests were used for storage of clothes. ...
1
N S
DOCUMENT STRUCTURE
4 8
TEXT
PARAGRAPH
TEXT?SENTENCETEXT?SENTENCETEXT?SENTENCE
PARAGRAPH
1
N S
N N
4 8
TEXT?SENTENCE
9
3
RHETORICAL STRUCTURE
2
N S
N S
9
Figure 6
Another example of nonisomorphic rhetorical and document structures.
between paragraphs and sections. As a basis for discussion, let us assume a hierarchy
of six levels, which we will number from 0 (assumed to be the lowest possible level
of document structure) to 5:8
0 text-phrase
1 text-clause
2 text-sentence
3 paragraph
4 section
5 chapter
The fundamental organizing principle of document structure is that a unit of a
given level is composed of one or more units of the next level down. This observation
could be expressed by a set of constituent structure rules, one for each level:
chapter ? section+
section ? paragraph+ (etc.)
Alternatively, we could generalize over this set of rules by introducing the symbol LN
to denote a unit of level N (so that L0 means text-phrase, L1 means text-clause, etc.).
A single rule will now cover units of all levels:
LN ? LN?1+ (N > 0)
8 We use text-sentence and text-clause in Nunberg?s sense, as units typically marked by a period and a
semicolon. However, unlike Nunberg, we use text-phrase for any constituent of a text-clause, whether it
is marked by a comma or not.
225
Power, Scott, and Bouayad-Agha Document Structure
(a)
(b)
SECTION
PARAGRAPH PARAGRAPHTEXT?SENTENCE
PARAGRAPH PARAGRAPH
SECTION
TEXT?SENTENCE
PARAGRAPH
Figure 7
Ill-formed (a) and well-formed (b) document structures.
Two consequences of this rule should be noted. First, it disallows document struc-
tures in which a unit contains a subunit of higher level?for instance, a text-sentence
may not contain a paragraph. Second, it disallows document structures in which
coordinated units have different levels. A section, for example, may not be formed
by coordinating two paragraphs and a text-sentence, as in Figure 7(a); the sentence
should be the only constituent of a further paragraph unit, as in Figure 7(b), so
that when the abstract document structure is realized graphically, the sentence will
be formatted with a paragraph break as well as with a capital letter and a
period.
This deals with the basic organization of text into hierarchical document units;
however, a full description should take account of many other patterns including
headings, bulleted lists, footnotes, and figures. We cannot deal with all these pat-
terns here, so we focus on what is probably the most complex problem: the treat-
ment of indented structures such as quotations, bulleted lists, and enumerated
lists.
4.2 Indented Document Units
At first sight it might seem that indentation is a feature of graphical realization
rather than underlying structure: in other words, that it belongs to concrete rather
than abstract document structure. We have several reasons for rejecting this view.
First, it is at least suggestive that both LaTEX and HTML include tags for indented
structures:
Pattern HTML tag LATEX tag
Quotation <QUOTE> \begin{quote}
Bulleted list <UL> \begin{itemize}
Enumerated list <OL> \begin{enumerate}
Description list <DL> \begin{description}
Second, one can find examples of vertical lists that seem structurally equivalent to
(say) a bulleted list but are presented without item markers and without the use of
horizontal indentation. Here is a case in point, taken from a PIL with formatting exactly
226
Computational Linguistics Volume 29, Number 2
preserved:
(13) If you experience any of the following or any other unusual effects,
tell your doctor:
Poor appetite or a slight sick feeling
Mild abdominal pains or fullness
Alterations in your sense of taste
Diarrhoea
Itching or rash
Pain in your muscles or joints
If you notice yellowing of the skin or eyes, tell your doctor
straight away.
(Lamisil, Sandoz; from APBI 1997)
Third, and most important of all, indented structures may introduce apparent viola-
tions of the hierarchical ranking described in the last section: for instance, a sentence
may contain a paragraph, provided that the paragraph is indented. We have already seen
this in the case of complex conditionals in example (12). However, the phenomenon
is much more widespread:
(14) In rare cases the treatment can be prolonged for another week; however, this is risky
since
? The side-effects are likely to get worse. Some patients have reported severe
headache and nausea.
? Permanent damage to the liver might result.
(15) The opening of Pride and Prejudice
It is a truth universally acknowledged, that a single man in possession of a
good fortune, must be in want of a wife. However little known the feelings
or views of such a man may be on his first entering a neighbourhood, this
truth is so well fixed in the minds of the surrounding families, that he is
considered as the rightful property of some one or other of their daughters.
is one of the most famous paragraphs in English literature.
In these examples, too, note that the important issue is not graphical indentation, but
what we might call logical indentation. Thus in the case of the quotation, the logical
indentation of the quoted paragraph might be shown without graphical indentation
(e.g., by using a distinctive font or character size):
(16) The opening of ?Pride and Prejudice?
It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a
wife. However little known the feelings or views of such a man may be on his first entering a neighbourhood,
this truth is so well fixed in the minds of the surrounding families, that he is considered as the rightful property
of some one or other of their daughters.
is one of the most famous paragraphs in English literature.
How can the formation rules for document structure be extended so as to ac-
commodate these patterns? Our main proposal, implemented in the ICONOCLAST
document planner, is that a document unit should be defined by (at least) two fea-
tures: its level and its indentation. The level is the usual ranking from L0 (text-phrase)
227
Power, Scott, and Bouayad-Agha Document Structure
"however, this is risky since"
"In rare cases ... for another week;"
"Permanent damage ... might result.""The side effects ... and nausea."
TEXT?CLAUSE (0)
TEXT?SENTENCE (0)
TEXT?PHRASE (0) TEXT?PHRASE (0)
PARAGRAPH (1) PARAGRAPH (1)
TEXT?CLAUSE (0)
Figure 8
Indented document structure (example (14)).
to L5 (chapter) or whatever hierarchy of units the author decides to employ; the inden-
tation is a value in the range I0 . . . IMax, where I0 means that the unit is not indented at
all, I1 means it is indented one place, and so forth, with IMax representing the deepest
embedding that the author is prepared to contemplate. The passages in examples 14?16
can then be described formally as unindented text-sentences (i.e., units with the cat-
egory [L2, I0]), which have among their constituents indented paragraphs (units with
the category [L3, I1]). Such structures can be permitted if we change the basic rule of
the last section so that a unit of indentation IN always outranks a unit of indentation
IN+1, no matter what their respective levels may be. Instead of one general rule, we
now need two: the first for unindented constituents, the second for indented ones.
Unindented constituents [LN, IM] ? [LN?1, IM]+
Indented constituents [LA, IM] ? [LB, IM+1]+
In the second rule, LA and LB are unrelated, so LB could represent a higher level than
LA (e.g., a paragraph inside a text-sentence). For most document types one would
presumably prefer to set an upper limit on the level of an indented constituent (e.g.,
an indented chapter seems ridiculous); this could be done for instance by adding the
constraint B < 4.
Figures 8 and 9 give document structures for examples (14) and (15), respectively;
the latter also describes example (16), which differs from (15) only in the graphical
realization of the indented paragraph. One feature of these analyses might at first
sight appear strange: they assign the minimal text level L0 to the node representing
the quotation or the bulleted list. How, one might ask, can a paragraph, or indeed a
list of paragraphs, be regarded as a text-phrase? Should it not be a unit higher than the
paragraph, perhaps some kind of section, or better, a new text category vertical list?
On first tackling indented structures, we followed precisely this reasoning, in-
troducing vertical list as a text category. However, despite its initial plausibility, this
decision has several irritating consequences. First, the concept vertical list has no re-
lationship to the text-level hierarchy. Does it belong between text-sentence and para-
graph, or perhaps between paragraph and section? Any placement seems arbitrary.
Second, since the vertical list in a document structure like that in Figure 8 is clearly
coordinated with a text-phrase, such an analysis would violate the rule that coordi-
nated constituents have the same level. Third, and perhaps most persuasively of all,
228
Computational Linguistics Volume 29, Number 2
"is one of ... English literature.""The opening of Pride and Prejudice"
"It is a truth universally ... daughters."
TEXT?SENTENCE (0)
TEXT?CLAUSE (0)
TEXT?PHRASE (0) TEXT?PHRASE (0)
PARAGRAPH (1)
TEXT?PHRASE (0)
Figure 9
Indented document structure (examples (15) and (16)).
it turns out that in their interactions with discourse connectives, vertical lists behave
like text-phrases, not like sentences, paragraphs, or higher units. Thus the vertical list in
Figure 8 is coordinated with the discourse connective since, which would not normally
link constituents higher than text-phrases (we will discuss this constraint more fully
in the next section).9
All these difficulties are removed by denying appearances and assigning the
vertical-list node a text-level of L0. With this treatment, no new arbitrary level in the
hierarchy of units is needed, the basic rule of document structure holds (i.e., coordi-
nated constituents have the same level), and the interaction of the unit with discourse
connectives can be described using the same rules that hold for nonindented struc-
tures. Note also that the difference in indentation between the node and its daughters
is sufficient to identify it as a vertical list; any extra feature (such as a new value in
the text-level hierarchy) would be redundant.
5. Methods of Document Structuring
5.1 Defining the Task
The aim of document structuring within NLG is to create a document structure that
satisfactorily realizes a particular rhetorical structure. This can be achieved through a
variety of architectures, as reflected in the RAGS framework.10 For example, systems
aimed at generating technical abstracts or captions for graphics would probably need
to specify a ?one paragraph only? limit quite early on in the process; in such cases,
document structuring would start before any rhetorical or syntactic decisions were
made (e.g., the RAGS reimplementation of the Caption Generation System [Mellish
et al 2000]). Alternatively, systems that need to generate texts with rich layout might
prefer to interleave document structuring with rhetorical structuring (e.g., Cahill et al
2001).
9 Note that a vertical list can also be coordinated with units larger than text-phrases, such as
text-sentences or paragraphs. The formal rules allow this because a text-phrase can be the only
constituent of a text-clause, which can in turn be the only constituent of a text-sentence, and so forth.
10 See The RAGS Reference Manual, http://www.itri.bton.ac.uk/projects/rags/RefMan/refman.ps.
229
Power, Scott, and Bouayad-Agha Document Structure
For simplicity of presentation, we will assume here an NLG architecture in which a
preliminary module selects simple propositions from a knowledge base and organizes
them into some kind of argument; the document structurer distributes the various
parts of this argument among units like paragraphs and text-sentences; a syntactic
realizer takes over in order to determine the wording of the propositions; finally, a
formatter decides how the abstract categories and features of document structure will
be realized graphically (e.g., whether paragraphs will be marked by a tab on a new
line, or by a vertical space). In the context of such an architecture, two issues are crucial:
what input does the document structurer receive from the earlier planning module,
and how does the output of the document structurer guide syntactic realization?
In ICONOCLAST, our initial assumption, following Scott and Souza (1990), was
that the rhetorical structure would take the form of a graph in which terminal nodes
represent simple propositions and nonterminal nodes represent rhetorical relation-
ships. By organizing all propositions into a single hierarchy, such an input simplifies
the task of the document structuring module; indeed, it could be argued that part
of the work has been done already. An alternative assumption is that the rhetorical
structure takes the form of a set of assertions, each describing a rhetorical relationship
between two propositions (Marcu 1997). With this flat representation, the document
structurer must take more responsibility for grouping the propositions. In this article,
we will focus on the first of these methods (i.e, starting from a hierarchical rhetori-
cal input). The second method (starting from a flat rhetorical input) is described in
Bouayad-Agha (2001).
Regarding the interface between document structuring and syntax, the difficult
issue is where the boundary should be drawn. Above the level of text-clause, it seems
clear that syntax plays little part; however, at the level in which text-phrases combine
to form text-clauses, there is an interplay between the ?syntactic? grammar and the
?text? grammar, as Nunberg (1990) has shown. As an example, consider the simple
rhetorical structure discussed earlier (example (8) and Figure 2):
concession(contain(elixir, gestodene), approve(fda, elixir))
As mentioned earlier, this rhetorical-semantic input could be realized through a text-
sentence comprising two text-clauses:
(8c) Elixir contains gestodene; however, it is approved by the FDA.
In this case it seems clear where the boundary should lie: the document structurer
decides that approve(fda, elixir) should be expressed in the first text-clause, and that
contain(elixir, gestodene) should be expressed in the second, along with the connec-
tive however. It might also impose constraints on the clauses that will realize these
propositions, for instance, by requiring declarative clauses rather than imperative or
interrogative ones. The rest is left to the syntactic realizer, which must decide how the
two propositions should be worded, and how the second clause should be combined
with the connective. Several alternative versions might result, each having exactly the
same document structure:
(8?) Elixir contains gestodene; the FDA, however, approves it.
(8?) Elixir contains gestodene; however, the FDA approves it.
230
Computational Linguistics Volume 29, Number 2
(8??) Gestodene is an ingredient of Elixir; Elixir is approved, however, by the
FDA.
Suppose, however, that the document structurer decides to realize the two propo-
sitions within the same text-clause, as in the following version:
(8??) Elixir is approved by the FDA although it contains gestodene.
Where now does the boundary lie? Should the document structurer create a text-
sentence containing a single text-clause, leave instructions that this text-clause should
express the whole concession relationship, and then wash its hands of the affair, leaving
everything else to the syntactic realizer? Or should it trespass into the domain of
syntactic realization by constructing a syntactic clause of the form S1 although S2, with
instructions that a subclause realizing approve(fda, elixir) should be inserted in position
S1 and a second subclause realizing contain(elixir, gestodene) in position S2?
In ICONOCLAST we have found it more convenient to adopt the latter policy. The
linguistic structure of a document is represented using a single tree in which nodes
may be labeled both with document structure features and with syntactic features.
The document structurer?s task is to build the upper part of this tree, extending from
the root all the way down to the nodes that express simple propositions. In the upper
reaches of the tree, nodes will be labeled with units like section and paragraph, and
syntactic features will be irrelevant; lower down, the document structure may have to
assign some syntactic features when constructing compound clauses. To simplify, we
assume that conjunctive adverbs like however will always be placed at the beginning
of a clause; this means that discourse connectives can be placed into the tree by the
document structurer, thereby limiting the task of the syntactic realizer to the wording
of the simple clauses that realize propositions.
Having clarified the document structurer?s task, we posed the following question:
given a well-formed rhetorical structure, together with a set of formation rules for
document structure and a set of discourse connectives for realizing rhetorical rela-
tions, can we enumerate all document structures that correctly realize the rhetorical
structure?and further, can we evaluate these document structures by some metric so
that we can choose the best? The generation of many alternative solutions was es-
sential to the project, which focused on the problem of controlling style in an NLG
system: by varying a set of stylistic parameters, the user of the system can influence
the evaluation metric that is applied to the set of potential solutions and so influence
the type of solution that will be preferred.
As mentioned above, we have explored two methods of enumerating and evaluat-
ing document structures, one (the focus of this article) assuming a hierarchical input,
the other (described in Bouayad-Agha [2001]) assuming a nonhierarchical input. The
two methods have much in common: they share the same formation rules for doc-
ument structure, the same discourse connectives, and (mainly) the same constraints
on the correct realization of rhetorical relationships. Before describing the hierarchical
method in detail, it will be useful to review the constraints that they share; these con-
straints will be needed, in some form or other, in any system that performs document
structuring.
5.2 Constraints on Realizing Rhetorical Structure
In order to realize a rhetorical structure R(A1, A2) as a document structure, several
decisions must be made:
231
Power, Scott, and Bouayad-Agha Document Structure
? What should be the level (e.g., section, paragraph, text-sentence) of the
document unit that realizes the whole relationship R(A1, A2)?
? What should be the levels of the units realizing the arguments A1 and
A2?
? Should the units realizing A1 and A2 be indented items, or should they
have the same indentation as the unit realizing R(A1, A2)?
? In what linear order should the units realizing A1 and A2 occur?
? Should the rhetorical relation R be expressed using a discourse
connective or left implicit?
? If a discourse connective is used, should it be linked to the span
realizing A1 or the span realizing A2?
These decisions are closely related, as the following examples show:
? If R(A1, A2) is realized through a text-sentence, then the arguments A1
and A2 cannot be realized through a higher unit, such as a paragraph,
unless they are indented one place further than R(A1, A2). (This follows
from the formation rules for document structure.)
? If R is a nucleus-satellite relation rather than a multinuclear one, the
arguments A1 and A2 should not be realized through indented items.11
? If a subordinating conjunction like although is used to express the
relation R, the arguments A1 and A2 should be realized within the same
syntactic clause; hence they should be text-phrases, rather than
text-clauses or some higher unit. Moreover, although should be attached
to the clause expressing A1 (assuming this is the satellite).
Constraints arising from the formation rules for document structure have already
been covered; we will therefore focus here on constraints that concern the realization
of rhetorical relations.
Leaving aside quotations for the time being, our first suggestion is that indentation
should be employed only for the arguments of a multinuclear relation. Vertical lists are
typically used when the items in the list play the same role in the discourse?for
instance, they might be symptoms of a disease or potential side effects of a medicine.
By definition, the arguments of a nucleus-satellite relation have different purposes; the
nucleus makes the main point, whereas the satellite?s role is supportive. Consider, for
example, the following rhetorical structure:
justify(list(tested(elixir), approve(fda, elixir)), safe(elixir))
which gives two reasons why Elixir is safe to use. The LIST relation is multinuclear,
whereas JUSTIFY is nucleus-satellite; according to our rule, then, the document struc-
tures in (17) and (18) should be avoided, whereas those in (19) and (20) should be
11 This constraint is based on the intuition that the items in a vertical list should have parallel roles in the
argument, a condition that clearly fails to hold for a nucleus-satellite relation.
232
Computational Linguistics Volume 29, Number 2
acceptable:
(17) ? Elixir is safe to use
? because it has been carefully tested and is approved by the FDA.
(18) ? Elixir has been carefully tested and is approved by the FDA,
? therefore, it is safe to use.
(19) Elixir is safe to use because
? it has been carefully tested
? it is approved by the FDA
(20) ? Elixir has been carefully tested
? Elixir is approved by the FDA
Therefore, it is safe to use.
Note that when the arguments of a multinuclear relation are presented within a
text-clause, syntax requires a connective like and or or. When they are presented as
indented items, the connective is instead often omitted, leaving the relation implicit;
the reader has to use common sense to divine whether the list represents a conjunction
or a disjunction.
5.2.1 Discourse Connectives. A comprehensive treatment of discourse connectives
will not be attempted here, but we will cover the three main categories identified by
Knott (1996): subordinating conjunctions, coordinating conjunctions, and conjunctive
adverbs.
The properties of a discourse connective can be fully specified by four features:
MEANING, SYNTAX, LOCUS, and SPELLING. As examples, here are three definitions for
the CONCESSION relation:
MEANING concession
SYNTAX subordinating conjunction
LOCUS satellite
spelling ?although?
meaning concession
syntax coordinating conjunction
locus nucleus
spelling ?but?
meaning concession
syntax conjunctive adverb
locus nucleus
spelling ?however?
The locus specifies which argument of the relation carries the discourse connec-
tive. For a nucleus-satellite relation, the argument is identified either by nucleus or
satellite; for a multinuclear relation it is identified by an ordinal specification such
as initial or final.
For each type of discourse connective, it is possible to state specific constraints on
the order of arguments, and on the document units that express them.12
12 Some of these are also mentioned by Scott and Souza (1990) and Rosner and Stede (1992).
233
Power, Scott, and Bouayad-Agha Document Structure
5.2.1.1 Subordinating Conjunction. The spans linked by a subordinating conjunction
can be arranged in either order (nucleus first or satellite first) but must be expressed
within the same text-clause. For example:
(21) Although it has no significant side effects, never give Elixir to other patients.
(22) Never give Elixir to other patients, although it has no significant side effects.
(23) # Although it has no significant side effects; never give Elixir to other patients.
(24) # Although it has no significant side effects. Never give Elixir to other patients.
(25) # Never give Elixir to other patients; although it has no significant side effects.
(26) # Never give Elixir to other patients. Although it has no significant side effects.
5.2.1.2 Coordinating Conjunction. Spans linked by a coordinating conjunction can oc-
cur in the same text-clause or in different text-clauses (or higher units) but must be
ordered so that the discourse connective is located in the final span (i.e., the second
span in the case of a nucleus-satellite relation):
(27) Elixir has no significant side effects, but never give it to other patients.
(28) # But never give Elixir to other patients, it has no significant side effects.
(29) Elixir has no significant side effects; but never give it to other patients.
(30) # But never give Elixir to other patients; it has no significant side effects.
(31) Elixir has no significant side effects. But never give it to other patients.
(32) # But never give Elixir to other patients. It has no significant side effects.
Of course examples (28), (30), and (32) are prohibited only as a means of realizing
a concession relation between the two propositions. They might be acceptable in a
text realizing a different rhetorical structure in which the satellite had already been
expressed.
5.2.1.3 Conjunctive Adverb. Spans linked by a conjunctive adverb can occur in differ-
ent text-clauses (or higher units), but not in the same text-clause. For a nucleus-satellite
relation they must be ordered so that the discourse connective is located in the second
span:
(33) # Elixir has no significant side-effects, however, never give it to other patients.
(34) # However, never give Elixir to other patients, it has no significant side-effects.
(35) Elixir has no significant side-effects; however, never give it to other patients.
(36) # However, never give Elixir to other patients; it has no significant side-effects.
(37) Elixir has no significant side-effects. However, never give it to other patients.
(38) # However, never give Elixir to other patients. It has no significant side-effects.
Again, examples (33), (34), (36), and (38) would be acceptable in realizations of different
rhetorical structures in which the satellite had already been presented.
5.3 Planning Document Structure Using Hierarchical Input
Using the hierarchical method, the input rhetorical structure is a tree in which the
terminal nodes are formulas representing elementary propositions (i.e., propositions
having no internal rhetorical complexity), whereas the nonterminal nodes are labeled
with rhetorical relations (see, for example, Figure 10). This tree is unordered: the roles
234
Computational Linguistics Volume 29, Number 2
concession
justifyapprove(fda, elixirplus)
ban(fda, elixir) contain(elixir, gestodene)
SATELLITE
NUCLEUS SATELLITE
NUCLEUS
Figure 10
Example of rhetorical structure.
of daughter nodes are shown by labels on the arcs (nucleus or satellite in the
case of a nucleus-satellite relation, or an integer greater than zero in the case of a
multinuclear relation).
The output is a linguistic structure, represented formally by an ordered tree in
which each node corresponds to a span of the document. Nodes are labeled with
document structure features (e.g., the level and indentation of the unit) and also with
syntactic features, which usually become relevant only at the level of text-clause or
below. Discourse connectives are already selected and positioned correctly in the tree;
the only task left to the syntactic realizer is to elaborate the tree further by generating
clauses that express the elementary propositions.
Our aim in ICONOCLAST has been to find a document-structuring method that
will generate all document structures that correctly realize an input rhetorical struc-
ture, given certain simplifying assumptions about the composition of the document
structure and the discourse connectives available in the lexicon. During this initial
enumeration of potential solutions, we are not concerned with good style: the pro-
cedure should generate clumsy realizations as well as elegant ones. But we do re-
quire a minimal standard of correctness. There is no point in considering solutions
that leave propositions in the rhetorical structure unexpressed in the document struc-
ture or group them wrongly. The strategy is first to define a procedure that gen-
erates all solutions that are worth considering at all; using this minimally correct
set as a basis, we can then posit further constraints that impose particular stylistic
preferences.
We assume that a minimally correct solution must satisfy three conditions:
1. The terminal nodes of the document structure must express all the
propositions in the rhetorical structure.
2. In addition to satisfying the document structure formation rules, the
solution must conform to correct syntax within text-clauses. For example,
two elementary propositions within a text clause must be linked by a
conjunction placed in the right position.
3. The document structure must be structurally compatible with the
rhetorical structure.
The first two of these conditions are obvious, but the third needs clarification. What
exactly is meant by ?structurally compatible??
We have explored two definitions of structural compatibility that are closely re-
lated to the mathematical notions of isomorphism and homomorphism (Landman
235
Power, Scott, and Bouayad-Agha Document Structure
(a)
approve(fda, elixirplus)
ban(fda, elixir) approve(fda, elixirplus)contain(elixir, gestodene)
ban(fda, elixir)
(b)
contain(elixir, gestodene)
PARAGRAPH
TEXT?SENTENCETEXT?SENTENCE
TEXT?CLAUSETEXT?CLAUSE TEXT?CLAUSE
TEXT?SENTENCETEXT?SENTENCE
PARAGRAPH
TEXT?SENTENCE
Figure 11
Isomorphic (a) and homomorphic (b) document structures.
1991; Bouayad-Agha, Power, and Scott 2000). Each notion can be conveniently ex-
pressed in terms of groupings of propositions in the rhetorical structure and the dis-
course structure. For an isomorphism (the strongest definition of compatibility), two
conditions must hold:
1. If a node in the document structure represents a span in which the set of
propositions expressed is P, there must be a corresponding node in the
rhetorical structure that dominates exactly the same set P of propositions.
2. If a node in the rhetorical structure dominates a set P of propositions,
there must be a node in the document structure representing a span in
which exactly this set P is expressed.
Informally, for an isomorphism, all groupings of propositions in the rhetorical struc-
ture must be transmitted faithfully to the document structure, and no new groupings
should be introduced. For a homomorphism from rhetorical structure to document
structure, only the first condition is required to be fulfilled. Any grouping found in
the document structure must correspond to a grouping in the rhetorical structure, but
the document structure may ?flatten out? the rhetorical structure by leaving some
groupings unexpressed.
These two kinds of compatibility, isomorphism and homomorphism, are illustrated
by document structures (a) and (b), respectively, in Figure 11, which are alternative
realizations of the rhetorical structure in Figure 10; to simplify, discourse connectives
have been left out. Solution (a) is isomorphic with the rhetorical structure, since the
propositions dominated by the justify relation are grouped together in a separate
text-sentence. Solution (b) is homomorphic only with the rhetorical structure, since
the propositions are expressed in three separate text-sentences, the internal grouping
236
Computational Linguistics Volume 29, Number 2
remaining implicit. Here are two texts that might result:
(39)
(a) Elixir contains gestodene; therefore, it is banned by the FDA. However, the FDA ap-
proves ElixirPlus.
(b) Elixir contains gestodene. Therefore, it is banned by the FDA. However, the FDA ap-
proves ElixirPlus.
Note that by losing a grouping from the rhetorical structure, (39b) introduces an
ambiguity: its form would also be consistent with an alternative rhetorical structure in
which the relation justify dominated concession. From the point of view of express-
ing the rhetorical input precisely, the isomorphic solution is always better. However,
when the resulting document structure is complex, or when the correct interpretation
can be inferred easily from the content, there might be stylistic reasons for preferring
a looser homomorphic solution. As a criterion for generating all minimally correct
solutions, therefore, we believe the homomorphic definition of compatibility is more
appropriate.13
Having decided what counts as a correct solution, our next task is to find an
efficient algorithm that will generate all and only these solutions. In ICONOCLAST,
this is accomplished through a constraint-solving method that formalizes the options
for realizing each part of the rhetorical structure, then eliminates those combined
choices that violate constraints. The technique has been explained fully elsewhere
(Power 2000), so we will confine ourselves here to a sketch of the main points.
For each node NR on the rhetorical structure, we can lay out some options on
how the rhetorical fragment dominated by this node will be realized in the document
structure. The crucial choices are as follows:
? What should be the level and indentation of the document structure
node that realizes the proposition or relationship NR?
? If NR is a nonterminal node, labeled with a rhetorical relation, what
discourse connective (if any) should express this relation in the
document structure?
? If NR is nonterminal, in what linear order should its daughter nodes be
realized in the document structure?
These decisions can be formalized by associating with each node four variables that
we will call level, indentation, connective, and position. The potential values
of these variables represent options for realizing the relevant part of the rhetorical
structure, and these options will be reduced by considering constraints on which com-
binations of values are allowed. Initially, the possibilities are as follows:
level: The level of the document structure unit realizing NR will be a document
unit along the hierarchy from text-phrase to chapter. In the program, it
13 We actually believe that even the less strict requirement of a homomorphism from RS to DS is too
strong, because one occasionally finds natural texts that violate it. For example, in Figure 4, RS and DS
are not only nonisomorphic, but nonhomomorphic, because there is a grouping in the DS (propositions
A, D, E) that is not found in the RS (no node in the RS dominates just these three propositions). This
raises the question of how one can distinguish nonhomomorphic solutions that are acceptable (like that
in Figure 4) from ones that are unacceptable (probably the great majority). To defer this difficult issue,
we have preferred in this article to confine our attention to homomorphic solutions. For further
discussion see Bouayad-Agha, Power, and Scott (2000).
237
Power, Scott, and Bouayad-Agha Document Structure
is convenient to represent this with an integer, so that constraints on a
higher or lower level can be implemented using the operations > and <;
we will here continue the notation introduced in Section 4.1, in which L0
means text-phrase, L1 means text-clause, and so forth.
indentation: The indentation of the document structure unit will be a value in
the range I0 to IMax, as explained in Section 4.2. Again, in the implemen-
tation, it is convenient to use an integer.
connective: The value of this variable is either ?, meaning that no connective
should be used, or a word from the lexicon. Thus if the node NR has
the label concession, the potential values might be ?, although, but, and
however.
position: This variable represents the order in which NR will be realized in the
document structure, in comparison with its sisters. The value must lie in
the range 1 . . .S, where S is the total number of sisters (including NR).
Thus if NR is an argument in a nucleus-satellite relation, the range will be
1 . . . 2; if it is an argument in a multinuclear relation, the range may be
larger.
The solution process consists in determining the set of options for each variable (these
are known in constraint logic programming as the domain of the variable), then im-
posing constraints on combinations of values, then enumerating all combinations that
satisfy the constraints. Each admissible combination of values can then be used as a
blueprint for building one of the document structures that may realize the input rhetor-
ical structure. The constraints imposed during the second phase of this algorithm are
essentially those described in the last section.
6. Examples of Document Structuring
We now give two examples of the document-structuring method outlined in the last
section. First, we look in detail at a very simple task, to make it clear how the method
works. Then we show some output for a more complex task, for which the program
will generate dozens of solutions even if the wording of individual propositions is
held constant.
6.1 Simple Example
To view the document-structuring method from close up, we will use a simplified
version of the task discussed in the last section. The rhetorical structure will comprise
just two propositions linked by a concession relation:
concession(ban(fda, elixir), approve(fda, elixirplus))
The method works by computing the options for realizing each constituent of the
rhetorical structure, where a constituent is any node in the rhetorical structure tree
along with its descendents. Thus in the present example there are three constituents?
the two propositions and the whole relationship?and for convenience we will label
them as follows:
A: approve(fda, elixirplus)
B: ban(fda, elixir)
C: concession(ban(fda, elixir), approve(fda, elixirplus))
238
Computational Linguistics Volume 29, Number 2
We can now begin to characterize the units in the document structure that will
realize the rhetorical constituents A, B, and C. For each unit, four choices must be
made: its level, its indentation, its position in relation to its sisters, and its connective.
We therefore have a total of twelve variables. Any combination of values that satis-
fies the constraints (as discussed in the last section) will serve as the blueprint for a
solution.
Following the usual technique for solving constraint satisfaction problems (Hen-
tenryck 1989), we assign to each variable a domain of potential values:
Constituent Level Indentation Position Connective
A (approve) {L0 . . . L3} {I0, I1} {P1, P2} C0
B (ban) {L0 . . . L3} {I0, I1} {P1, P2} C0
C (concession) {L0 . . . L3} {I0, I1} P1 {C0, Calt, Cbut, Chow}
Some of these assignments require some explanation:
? We make the simplifying assumption that the highest unit required will
be the paragraph (formalized as level L3), and that the maximum
indentation will be one place (formalized as I1).
? Since constituents A and B are sisters in the rhetorical structure, their
relative order is formalized by a choice between two positions, P1 and
P2. Constituent C, in contrast, has no sister in the rhetorical structure, so
as an ?only child,? it can have only one position value.
? Constituents A and B are not associated with a discourse connective,
because they are elementary propositions, so their value for the
connective variable is C? (meaning no connective). Constituent C is instead
associated with the concession relation, for which we assume that the
lexicon offers three connectives: although (Calt), but (Cbut), and however
(Chow). The initial domain for the variable connective(C) therefore
comprises these three possibilities along with C?, the option of leaving
the relation implicit.
Having assigned the initial domains, we next proceed to apply some constraints;
these will have the effect of reducing some of the domains. First of all, there are some
constraints applicable to the unit that will serve as the root of the whole document
structure:
Root Level: In a document generation task, we usually have some preconception
about the size of the whole document (e.g., it might be a chapter, or a
section). Since this is a small rhetorical structure, we might decree that the
whole text should consist of a paragraph, so that level(C) = L3.
Root Indentation: It makes no sense for a whole document to be an indented item,
so to realize the root constituent C we may stipulate that indentation(C) =
I0.
Having applied these constraints to the variables realizing C, we can impose some
further constraints that arise from the relationship between C and its direct constituents
A and B:
239
Power, Scott, and Bouayad-Agha Document Structure
Argument Indentation: As pointed out in the last section, it is permissible to
indent the arguments of a multinuclear relation, but not a nucleus-satellite
relation. Therefore, given that the indentation of C has been fixed as I0,
the indentations of A and B must also be I0.
Parental Domination: Since A and B are constituents of C in the rhetorical struc-
ture, the units realizing A and B in the document structure will occur
within the constituent realizing C. Given that all indentations have been
set to I0, this means that level(C) should outrank both level(A) and level(B),
and that consequently the option L3 should be removed from the domains
of the last two variables.
Sister Equality: Because A and B are sisters in the rhetorical structure (i.e., argu-
ments of the same relation), it is appropriate that they should be realized
in the document structure by units of the same level. We can therefore im-
pose the constraint level(A) = level(B). This does not immediately affect
the domains of these variables, but it does mean that as soon as one is
fixed, so is the other.
Sister Position: The units realizing the sisters A and B must occur in one of two
linear orders in the document structure?they cannot both come first, or
both second. We may therefore set the constraint position(A) = position(B).
Again this has no immediate effect on the domains, but as soon as one
value is fixed, so is the other.
Obligatory Connective: As Scott and Souza (1990) point out, an NLG system is
ill-equipped to judge when a rhetorical relation may be left implicit, so it
makes sense to play safe by always realizing the relation using a discourse
connective. Following this policy, we can remove C0 from the domain of
connective(C).
Through applying these constraints, the domains of the variables have been reduced
as follows:
Constituent Level Indentation Position Connective
A (approve) {L0 . . . L2} I0 {P1, P2} C0
B (ban) {L0 . . . L2} I0 {P1, P2} C0
C (concession) L3 I0 P1 {Calt, Cbut, Chow}
Before enumerating solutions, we need to impose a final set of constraints that are
conditional on the choice of discourse connective for C. These constraints have been
explained fully above, so here we only point out how they are stated in terms of our
variables.
Subordinating Conjunction: The units connected by although may occur in any
order, but they must be text-phrases. Therefore, if connective(C) = Calt,
then level(A) = level(B) = L0.
Coordinating Conjunction: We will assume that a coordinating conjunction like
but may link spans within a text-clause, or across text-clauses and text-
sentences, so that no constraint on the levels of A and B results. However,
the satellite must precede the nucleus, so we have position(B) = P1 (and
hence, by Sister Position, position(A) = P2).
240
Computational Linguistics Volume 29, Number 2
Conjunctive Adverb: A conjunctive adverb like however should link spans in units
of text-clause or higher,14 so we can impose the constraints level(A) > L0
and level(B) > L0. (Note that in the implementation, only one of these need
be applied, since the other results from Sister Equality.) For however, the
satellite must precede the nucleus, so again we have position(B) = P1 and
position(A) = P2.
With all potential interactions among decisions taken care of, enumeration can
proceed. In an implementation in constraint logic programming, this is accomplished
through a method called labeling, in which the remaining possible values for each
variable are tried one by one, with backtracking, until all permitted combinations
have been produced. For this example, this process can be understood most easily if
we explore in turn the possible values for connective(C).
Suppose first that connective(C) = Calt (i.e., that we try although). Through the
constraint Subordinating Conjunction, this choice immediately fixes all values of level,
yielding the following domains:
Constituent Level Indentation Position Connective
A (approve) L0 I0 {P1, P2} C0
B (ban) L0 I0 {P1, P2} C0
C (concession) L3 I0 P1 Calt
The only remaining issue is the relative orders of the spans realizing A and B. Enu-
merating arbitrarily on position(A), we first try the value P1; by Sister Position this
immediately yields position(B) = P2, whereupon all values in the table are fixed. We
therefore have our first complete solution:
Constituent Level Indentation Position Connective
A (approve) L0 I0 P1 C0
B (ban) L0 I0 P2 C0
C (concession) L3 I0 P1 Calt
This is still only a blueprint for a document structure, but with these specifications
the rest can be inferred. First, since the units realizing A and B are text-phrases, whereas
the root unit realizing C is a paragraph, the program can interpolate the units needed
to make a well-formed document structure: the paragraph has a single text-sentence,
which has a single text-clause, which comprises the two text-phrases. Next, since
although attaches to the satellite, the program coordinates it with the clause that will
syntactically realize B. The document structure is now complete, and after syntactic
realization of the two propositions we might obtain the following paragraph:
Solution 1: The FDA approves ElixirPlus, although it bans Elixir.
Backing up, the program can now try the alternative order in which position(A) = P2.
After inferring the complete document structure in the same way, we thereby obtain
a second solution:
Solution 2: Although the FDA bans Elixir, it approves ElixirPlus.
14 As Oates (2001) has shown, this is not true if multiple discourse connectives are allowed: For instance,
one might say ?The FDA bans Elixir but, however, it approves ElixirPlus.? But in the present example,
we assume, for simplicity, that only single discourse connectives are used.
241
Power, Scott, and Bouayad-Agha Document Structure
Having fully explored the possibilities with connective(C) = Calt, we back up and
try the next value, namely, Cbut. This time the constraint Coordinating Conjunction
applies, fixing the position values but leaving several possiblities for level:
Constituent Level Indentation Position Connective
A (approve) {L0 . . . L2} I0 P2 C0
B (ban) {L0 . . . L2} I0 P1 C0
C (concession) L3 I0 P1 Cbut
Enumerating on one of the level variables, for instance, level(A), we can now try in
turn the values L0, L1, and L2 (text-phrase, text-clause, and text-sentence); by Sister
Equality, any choice will be copied across to level(B), so that we obtain only three
further solutions rather than nine:
Solution 3: The FDA bans Elixir, but it approves ElixirPlus.
Solution 4: The FDA bans Elixir; but it approves ElixirPlus.
Solution 5: The FDA bans Elixir. But it approves ElixirPlus.
Finally, we try the remaining option, for which connective(C) = Chow. The constraint
Conjunctive Adverb now applies, fixing the order of A and B and ruling out solutions
for which these propositions are realized by text-phrases:
Constituent Level Indentation Position Connective
A (approve) {L1, L2} I0 P2 C0
B (ban) {L1, L2} I0 P1 C0
C (concession) L3 I0 P1 Chow
It remains to enumerate (as before) on level(A), trying in turn the values L1 and L2
(text-clause and text-sentence). Sister Equality again copies any selected value across
to level(B), so that we obtain just two more solutions:
Solution 6: The FDA bans Elixir; however, it approves ElixirPlus.
Solution 7: The FDA bans Elixir. However, it approves ElixirPlus.
Obviously further texts could be obtained by different wordings of the propo-
sitions or different placements of however (e.g., ?The FDA bans Elixir; the FDA ap-
proves ElixirPlus, however?). But these variations do not concern us here, since we
assume they are introduced during syntactic realization, not during document
structuring.
6.2 Complex Example
To examine a more complex example, it is convenient to use a version of ICONOCLAST
in which the wording of individual propositions is prespecified, so that the program?s
only task is to explore the set of possible document structures. The input to this
program is provided in the form of an XML file using the tags RhetRep (for rhetorical
relationships) and SemRep (for propositions) (Cahill et al 1999). The roles of satellite
and nucleus are distinguished implicitly by the order of the elements (satellite precedes
nucleus). Thus the example discussed in the last section
concession(ban(fda, elixir), approve(fda, elixirplus))
242
Computational Linguistics Volume 29, Number 2
Figure 12
Running the document planner.
could be encoded as follows:
<RhetRep relation=concession>
<SemRep prop="the FDA bans Elixir"/>
<SemRep prop="the FDA approves ElixirPlus"/>
</RhetRep>
Obviously this will sometimes lead to some clumsy wording (e.g., through inappro-
priate decisions on whether to use pronouns), but we can try to ignore this when
evaluating the generated document structures.
As a more complicated example we will consider a rhetorical structure with
two nucleus-satellite relations (evidence, concession) and one multinuclear relation
(list):
<RhetRep relation=concession>
<SemRep prop="Elixir contains gestodene"/>
<RhetRep relation=evidence>
<RhetRep relation=list>
<SemRep prop="the medicine has been thoroughly tested"/>
<SemRep prop="it has no significant side effects"/>
</RhetRep>
<SemRep prop="Elixir is safe to use"/>
</RhetRep>
</RhetRep>
The main idea here is that Elixir is safe to use although it contains gestodene; the
claim that Elixir is safe is supported by evidence comprising two conjoined facts: It
has been thoroughly tested, and it has no significant side effects.
Figure 12 shows a snapshot of the program running on this example. Through the
control panel on the left, the user can decide which XML model to use as input; in
the figure, this is set to ?Concession-Evidence-Conjunction,? the name given to this
243
Power, Scott, and Bouayad-Agha Document Structure
input model. Using the button labeled ?Number of versions,? the user can determine
the maximum number of versions that will be generated; since this has been set to
500, the program will return the first 500 solutions that it finds.15 The other buttons
control hard constraints and have been set deliberately to rather restrictive values (e.g.,
indented items have been allowed only to one level of indentation and may consist
only of text-phrases, not larger units like text-sentences or paragraphs). Even with
these restrictive settings, 58 solutions have been generated; they are presented in the
pane on the right, ordered (partially) from best to worst. The scores in parentheses
after the version number report the number of defects that the program detected for
that particular version: thus for each of the solutions that appear in the snapshot,
no defects were found.16 As a comparison, here is version 58, which came up at the
bottom of the class with six defects:
Version 58 (6)
Elixir contains gestodene.
However, the medicine has been thoroughly tested.
It has no significant side effects.
Consequently, Elixir is safe to use.
The specific defects cited here were ?Single-sentence paragraph? (occurring four times)
and ?Lost rhetorical grouping? (occurring twice). (The defects are explained below, and
the full set of solutions is given in the Appendix.)
At present the program looks for six stylistic defects, which are formulated mainly
by looking at generated solutions and making an intuitive judgment as to why they
are bad. We have not tried to give the stylistic assessment a sound theoretical or
empirical basis; the aim at this stage is to confirm that by applying some simple
intuitive principles, we can separate reasonably good solutions from obviously horrible
ones. The six defects are as follows (and we stress again that they are only provisional):
Nucleus precedes satellite: It is generally the case for English that the more im-
portant information is placed at the end of the sentence (i.e., end focus
[Quirk et al 1985]). For example, the rheme of a sentence comes after its
theme, and new information is typically placed after given information
(Halliday 1985; Givo?n 1988). There is also psycholinguistic evidence to
suggest that sentences that conform to this general pattern are processed
more easily (Yekovich, Walker, and Blackman 1979). Since by definition the
nucleus is more important than the satellite (Mann and Thompson 1986,
page 6), it thus makes sense to place the nucleus second. Obviously this
principle is debatable, and the best order might differ from one relation
to another, but we have noticed that for the very common relations such
as concession and evidence, the order satellite-nucleus seems to work
better. The program therefore scores a defect every time that a nucleus is
placed before its satellite.
Left-branching structure: Fodor, Bever, and Garrett (1974) report that left-branching
structures take more time to process and remember than right-branching
15 Obviously, if there are fewer than 500 solutions, it will return all the solutions it finds.
16 When it finds a defect in a version, the system also reports on the type of defect that it finds.
244
Computational Linguistics Volume 29, Number 2
ones. We have also noticed that when a document structure coordinates
two units of different sizes, it reads best when the smaller unit is placed
first. We believe that this may be related to the more general organizational
principle of end weight (Quirk et al 1985). Thus in the program, when
an elementary proposition is coordinated with a unit containing several
propositions, a defect is scored whenever the elementary proposition is
placed second.
Lost rhetorical grouping: As discussed, our method of document structuring does
not demand an isomorphism between rhetorical structure and document
structure; consequently, a grouping that is present in rhetorical structure
may be left implicit in the document structure. Although we allow a group-
ing to be lost in this way, a defect is scored every time it is found to have
occurred.
Single-sentence paragraph: Paragraphs containing a single text-sentence usually
look strange, so they are scored as a defect.
Oversimple text-clauses: We noticed this subtle defect only as a result of experi-
ence with the program. In most cases it looks odd to compose a sentence
from two text-clauses, each expressing a single proposition:
Elixir contains gestodene; therefore, it is banned by the FDA.
The FDA bans Elixir; however, it approves ElixirPlus.
Assuming it is agreed that these sentences are a little strange, why should
this be so? We would suggest the following reason. The semicolon is a
somewhat unusual device, more sophisticated than the comma, and one
therefore expects it to be used only when ordinary methods are unsatis-
factory. In these examples, containing only two propositions, a single text-
clause using conjunctions (e.g., since, although) instead of adverbs would
express the meaning equally clearly, so the semicolon seems unnecessary,
and therefore distracting. A defect is therefore scored every time this is
found to have happened.
Repeated discourse connective: If a rhetorical structure contains two relations of
the same type, one dominating the other, a defect is scored if they are
expressed using the same discourse connective. Here is a simple example
of this defect (repetition of although), followed by an alternative solution
that avoids the defect:
The FDA approves ElixirPlus although it bans Elixir although Elixir has
been thoroughly tested.
The FDA approves ElixirPlus but it bans Elixir although Elixir has been
thoroughly tested.
7. Discussion and Conclusion
Our main aim has been to introduce and motivate abstract document structure as an
important representational level in natural language processing. This proposal rests
on two separate claims: first, that it is useful to distinguish abstract document structure
from concrete graphical realization; second, that abstract document structure should
also be distinguished from rhetorical structure.
245
Power, Scott, and Bouayad-Agha Document Structure
7.1 Abstract versus Concrete
We argue that the transition from a rhetorical-semantic message to a fully specified
document can usefully be divided into two stages. During the first stage, the author
puts the message into words and organizes the words into higher linguistic units like
sentences, paragraphs, and bulleted lists. All decisions pertaining to the realization of
literal content take place during this stage. During the second stage, detailed format-
ting takes place: quotations are realized either by single or double quotes (or some
other method); emphasis is realized through italics, boldface, small capitals, or under-
lining; paragraphs are realized through an introductory tab or double line spacing;
and so forth. Decisions about format do not affect the factual or logical content of the
document, although they might convey ?meanings? of a subtler sort, communicated
through the typographical preferences of the authors (e.g., traditional versus trendy,
ornamental versus puritanical, compact versus expansive).
It is worth noting that similar distinctions are made in other branches of linguistics.
Thus in phonology, a distinction is made between a phonemic level and a phonetic
level. The word grass has a single phonemic representation but will be pronounced
differently by people from different regions or different social classes; these distinctions
are phonetic, not phonemic. To refer to an area in the garden as grass rather than lawn
is one kind of decision; to pronounce grass with a short or long vowel is another. A
theory that mapped directly from the semantic concept to the phonetic form would
miss a generalization that is not only obvious theoretically, but useful practically. The
invention of writing provides additional support for an intermediate phonemic level,
because the different pronunciations of grass are all written down in the same way;
similarly, we would argue, the representational level of abstract document structure
has received more recent support from the invention of markup languages like HTML
and LaTEX.
The concept of abstract document structure is not linked to any particular architec-
ture for natural language generation or understanding. In the RAGS ?reference archi-
tecture? for NLG (Mellish et al 2000; Cahill et al 2001), document structure is distin-
guished from rhetorical structure as a data type, with no commitment as to when these
two data structures are created during the generation process. The ICONOCLAST sys-
tem, described in this article, assumes that rhetorical planning fully precedes document
structuring: in other words, the RST tree has to be complete before the process of cre-
ating a document structure can begin. Such an architecture could be thought of as a
refinement of the standard pipeline (Reiter 1994), with the document-planning phase
divided into two parts (rhetorical planning and document structuring). However, the
ICONOCLAST method would work equally well if a partial assignment of document
structure was part of its input: This would be treated merely as a more specific set of
constraints on possible solutions, which is precisely the arrangement that is used in
the RAGS reimplementation of the Caption Generation System (Mellish et al 2000).
7.2 Document Structure versus Rhetorical Structure
In the terminology of HTML and other mark-up languages, tags like section and
description list are sometimes called logical, suggesting that they are rhetorical
rather than linguistic categories. We have argued that this is a mistake, comparable to
a confusion of syntax with semantics. In our view, the term rhetorical structure should
properly be applied to the higher-level pragmatic and semantic organization of the
message, with no commitment to the means by which this message will be expressed?
whether by speech, or gesture, or diagram, or written document. By contrast, the
categories section and description list are specific to a particular medium, the
written document; hence the term document structure. The two levels are easily confused
246
Computational Linguistics Volume 29, Number 2
because we often refer to spans of a document using a noun that describes their
rhetorical role (e.g., summary in an academic paper).
Some of the distinctions made in this article have parallels in work on document
analysis. Various representations for document structure have been proposed in the
document analysis community, of which the most developed is the Document Attribute
Format Specification (DAFS) (Dori et al 1997). In DAFS, the physical structure of a
document is distinguished from its logical structure; typical physical units are block,
frame, page, and page set, and typical logical units are sentence, paragraph, section,
and header. More formally, the units of logical structure, called textons, are organized
into levels from character (level 0), word (level 1), and sentence or phrase (level 2) up
to sections and whole documents; the lower levels (up to paragraph) are called sim-
ple textons, and the higher levels are called compound textons. Simple textons are
realized through blocks of text, whereas compound textons additionally have a head-
ing and (optionally) a trailer. There is considerable overlap here with our distinction
between concrete and abstract document structure; differences arise because the anal-
ysis community is concerned mainly with the relationship between logical structure
and physical structure (to use that community?s terminology), whereas the generation
community, coming from the opposite direction, is concerned mainly with the rela-
tionship between logical structure (i.e., abstract document structure) and rhetorical
structure.
Having drawn these distinctions, we have sketched a formal theory of abstract
document structure and shown through an implemented NLG system that this theory
allows us to enumerate systematically the high-level linguistic structures that can real-
ize a given rhetorical-semantic input. The formal description of document structure is
based on Nunberg?s (1990) text-grammar, which we have extended in two ways. First,
we introduce larger units such as sections and chapters; Nunberg instead focuses on
the levels relevant for punctuation (i.e., text-sentence and below). Secondly, we intro-
duce a second feature, abstract indentation. Whereas Nunberg categorizes units only
according to the feature we have called level (the hierarchy from text-phrase, text-
clause, etc., up to section and chapter), we categorize units according to two features,
level and indentation. This allows the generation of such patterns as bulleted lists,
including more complex cases in which one list is embedded within another. Using
this descriptive scheme, it has proved relatively easy to state constraints on the inter-
action between content, layout, and wording, especially as regards the use of discourse
connectives.
By introducing a formal scheme for representing document structure, we have
been able to define the task of document structuring in a simple and clear way. Fol-
lowing Scott and Souza (1990) and many other researchers on NLG, it is assumed
that the rhetorical input takes the form of an RST tree; the output is a tree rep-
resenting high-level linguistic structure, each node being labeled with a document
structure category defined by the features level and indentation. Our scheme is by
no means complete (e.g., it has no treatment of tables, or figures, or text presented
in boxes); however, it is sufficient to generate hundreds of alternative solutions even
for a rhetorical structure containing only four or five elementary propositions. By
clarifying the task of document structuring in this way, we have been able to de-
fine it as a constraint satisfaction problem and thus to implement a system in which
the relevant constraints are defined declaratively; this means that constraints can be
added or removed without changing the rest of the program. Such a system is use-
ful not only as a module in an NLG architecture, but also as a tool for theoretical
investigation: the results of any proposed combination of constraints can be quickly
tested.
247
Power, Scott, and Bouayad-Agha Document Structure
In pursuing this investigation, our methodology has been essentially the same as
Nunberg?s, relying largely on intuition as a means of separating the wheat from the
chaff. Moreover, by implementing the theory in a system that can enumerate solutions
systematically, we are able to test more thoroughly any proposed rule or constraint, at
least for simple examples. This methodology assumes, first, that intuition is a reliable
guide, and second, that constraints derived from small examples will apply also to
full-scale examples. In the initial stages of an investigation, these assumptions seem
reasonably safe. Many of the solutions generated by the program are so obviously
good or bad that there is no point in submitting them to the judgment of literary
experts or subjecting them to some other kind of empirical test. No doubt large-scale
examples will require additional constraints, but much can still be learned from simple
ones: an intrinsically bad paragraph will usually remain bad when placed into a larger
context.
As a contrast, it is interesting to consider the investigation into layout by Bateman
et al (2001). Their approach could not be more different from ours. Instead of sim-
ple examples, they analyze (and regenerate) an exceedingly complicated page from a
magazine. This page, which describes the game of hockey, includes several drawings,
a photograph, diagrams of the pitch, boxes of text, two headers, and a glossary, all laid
out in five different grids, each having a different division into columns. Their RST
analysis of this page is correspondingly complex, with 45 elementary propositions
and the same number of rhetorical relationships (the whole RST tree therefore has
nearly 100 nodes). To analyze such an example informally may be a useful source of
insights, but to attempt a complete formal analysis (and generation) of the page seems
bold in the extreme. However, despite this difference in approach, the framework
that emerges from Bateman et al?s work is broadly similar to ours. First, a distinc-
tion is made between ?layout structure? and ?physical layout? (Bateman et al 2001,
section 3.1); although the discussion concerns boxes in a grid rather than more con-
ventional linguistic units like section and paragraph, this distinction reflects the need
for an abstract level of representation that can be related more easily to the rhetor-
ical structure of the message. Secondly, in sections 4 and 5 of their article, Bateman
et al distinguish clearly between layout structure and rhetorical structure, pointing
out that the two are not necessarily isomorphic and that constraints on the mapping
must therefore be considered:
Mapping is generally achieved by placing parts of the RST-structure
in correspondence with particular nodes in layout structure. [. . .] As
we have now seen, however, this correspondence is complicated by
the fact that the layout structure and the RST tree need not remain
congruent.
(Bateman et al 2001, page 430)
However, Bateman and his colleagues do not provide a detailed account of the forma-
tion rules for layout structure, or of the constraints on the mapping between the RST
tree and the layout structure. We are unsure, for example, whether ?layout structure?
would include such patterns as sections, paragraphs, and bulleted lists. Nevertheless,
the role played by these two abstract representations seems similar?they mediate be-
tween rhetorical structure and physical layout?so there is some reason to think that
the two approaches are yielding results that are compatible.
Both in the Bateman et al study and in our own work, a problem arises as to how
the proposed representations and constraints should be validated. Our own approach,
at least provisionally, has been that the theory should be embodied in a program
248
Computational Linguistics Volume 29, Number 2
that can generate many alternative solutions and rank them using some kind of cost
function; at this point, we rely on intuition to judge whether the system has generated
a plausible set of solutions and ranked them in an appropriate order. For the very
complex examples considered by Bateman et al, the set of solutions could only be
sampled: Even keeping the wording of individual propositions constant, they would
number billions. Evaluation in this field has to take account of style as well as quality;
in other words, it has a subjective side as well as an objective one. The problem
is not just to generate a good solution, but to generate one that satisfies a set of
subjective preferences, so that, for example, different documents produced for the
same company will exhibit the desired consistency of style. Eventually, some kind
of empirical investigation will be needed (e.g., an expert evaluation, or a study of
the impression made on the intended readers). At the present state of knowledge,
however, such refinements seem exaggerated: If we can separate the satisfactory from
the barbaric, we will be more than content.
Acknowledgments
The research presented in this article was
carried out as part of the ICONOCLAST
project
(http://www.itri.bton.ac.uk/projects/iconoclast),
with funding from Engineering and
Physical Sciences Research Council grant
number L77102. We are extremely grateful
to Kees van Deemter and three anonymous
reviewers for their critical feedback on an
earlier draft of this article.
References
Arens, Yigal and Eduard Hovy. 1990. Text
layout as a problem of modality selection.
In Proceedings of the Fifth Conference on
Knowledge-Based Specification, RADC
Workshop, pages 87?94, Syracuse, New
York.
Association of British Pharmaceutical
Industry (ABPI). 1997. Compendium of
Patient Information Leaflets. Association of
British Pharmaceutical Industry, London.
Bateman, John, Thomas Kamps, Jorge
Kleinz, and Klaus Reichenberger. 2001.
Towards constructive text, diagram, and
layout generation for information
presentation. Computational Linguistics,
27(3):409?449.
Bolinger, Dwight, editor. 1972. Intonation.
Penguin, Harmonsworth, England.
Bouayad-Agha, Nadjet. 2000. Using an
abstract rhetorical representation to
generate a variety of pragmatically
congruent texts. In Proceedings of the 38th
Annual Meeting of the Association for
Computational Linguistics (ACL), Student
Workshop, pages 16?22, Hong Kong,
October.
Bouayad-Agha, Nadjet. 2001. The role of
document structure in text generation.
Ph.D. thesis, University of Brighton,
Brighton, U.K. Also available as Technical
Report ITRI-01-24, Information
Technology Research Institute, University
of Brighton, Brighton, U.K.
Bouayad-Agha, Nadjet, Richard Power, and
Donia Scott. 2000. Can text structure be
incompatible with rhetorical structure? In
Proceedings of the International Natural
Language Generation Conference, pages
194?200, Mitzpe Ramon, Israel, June
12?16.
Bouayad-Agha, Nadjet, Donia Scott, and
Richard Power. 2000. Integrating content
and style in documents: A case study of
patient information leaflets. Information
Design, 9(2):161?176.
Bouayad-Agha, Nadjet, Donia Scott, and
Richard Power. 2001. The influence of
layout on the interpretation of referring
expressions. In L. Degand, Y. Bestgen,
W. Spooren, and L. van Waes, editors,
Multidisciplinary Approaches to Discourse.
Amsterdam, Nodus, pages 133?141. Also
presented as a paper at the
Multidisciplinary Approaches to
Discourse (MAD) workshop, Ittre,
Belgium, August 2001. A slightly
modified version is also available as
Technical Report ITRI-01-23, Information
Technology Research Institute, University
of Brighton, Brighton, U.K.
Cahill, Lynne, John Carroll, Roger Evans,
Daniel Paiva, Richard Power, Donia Scott,
and Kees van Deemter. 2001. From rags to
riches: Exploiting the potential of a
flexible generation architecture. In
Proceedings of the 39th Annual Meeting of the
Association for Computational Linguistics
(ACL?01), Toulouse, France, pages 98?105.
Also available as Technical Report
ITRI-01-07, Information Technology
Research Institute, University of Brighton,
Brighton, U.K.
249
Power, Scott, and Bouayad-Agha Document Structure
Cahill, Lynne, Christine Doran, Roger
Evans, Chris Mellish, Daniel Paiva, Mike
Reape, Donia Scott, and Neil Tipper. 1999.
Towards a reference architecture for
natural language generation systems.
Technical Report ITRI-99-14, Information
Technology Research Institute, University
of Brighton, Brighton, U.K.
Chomsky, Noam and Morris Halle. 1968.
The Sound Pattern of English. Harper and
Row, New York.
Coch, Jose. 1996. Overview of AlethGen. In
Demonstrations and Posters of the Eighth
International Natural Language Generation
Workshop (INLG?96), Herstmonceux Castle,
Sussex, U.K., pages 25?28.
Crystal, David. 1969. Prosodic Systems and
Intonation in English. Cambridge
University Press, Cambridge.
DiMarco, Chrysanne, Graeme Hirst, Leo
Wanner, and John Wilkinson. 1995.
Healthdoc: Customizing patient
information and health education by
medical condition and personal
characteristics. In First International
Workshop on Artificial Intelligence in Patient
Education, Glasgow, August.
Dori, Dov, David Doermann, Christian Shin,
Robert Haralick, Ihsin Phillips, Mitchell
Buckman, and David Ross. 1997. The
representation of document structure: A
generic object-process analysis. In
P. Wang and H. Bunke, editors, Handbook
on Optical Character Recognition and
Document Image Analysis. World Scientific,
Singapore, pages 421?456.
Fodor, Janet, Thomas Bever, and Merril
Garrett. 1974. The Psychology of Language.
McGraw-Hill, New York.
Ford, Andrew and Tim Dixon. 1996.
Spinning the Web. International Thompson
Computer, London.
Givo?n, Talmy. 1988. The pragmatics of word
order: Predictability, importance and
attention. In M. Hammond, E. Moravcsik,
and J. Werth, editors, Studies in Syntactic
Typology. John Benjamins, Amsterdam,
pages 243?284.
Halliday, Michael. 1967. Intonation and
Grammar in British English. Mouton, the
Hague.
Halliday, Michael. 1985. An Introduction to
Functional Grammar. Edward Arnold,
Baltimore.
Hentenryck, Pascal Van. 1989. Constraint
Satisfaction in Logic Programming. MIT
Press, Cambridge.
Huang, Xiaorong and Armin Fiedler. 1997.
Proof verbalization as an application of
NLG. In Proceedings of the 16th International
Joint Conference on Artificial Intelligence
(IJCAI?97), Nagoya, Japan, pages 965?970.
Knott, Alistair. 1996. A Data-Driven
Methodology for Motivating a Set of Coherence
Relations. Ph.D. thesis, University of
Edinburgh, Edinburgh, U.K.
Knott, Alistair, John Oberlander, Mick
O?Donnell, and Chris Mellish. 2001.
Beyond elaboration: The interaction of
relations and focus in coherent text. In
T. Sanders, J. Schilperoord, and
W. Spooren, editors, Text Representation:
Linguistic and Psycholinguistics Aspects.
Benjamins, Amsterdam, pages 181?196.
Ladd, Robert. 1996. Intonational Phonology.
Cambridge University Press, Cambridge.
Landman, Fred. 1991. Structures for
Semantics, volume 45 in Studies in
Linguistics and Philosophy. Kluwer
Academic.
Lavoie, Benoit and Owen Rambow. 1997. A
fast and portable realizer for text
generation systems. In Proceedings of the
Fifth Conference on Applied Natural Language
Processing (ANLP?97), Washington, D.C.,
pages 265?68.
Mann, William and Sandra Thompson.
1986. Rhetorical structure theory:
Description and construction of text
structures. In Proceedings of the Third
International Workshop on Text Generation,
Nijmegen, the Netherlands, August.
Mann, William and Sandra Thompson.
1987. Rhetorical structure theory: A
theory of text organization. Technical
Report ISI/RS-87-190, Information
Sciences Institute, University of Southern
California, Marina del Rey.
Marcu, Daniel. 1997. From local to global
coherence: A bottom-up approach to text
planning. In Proceedings of the 14th National
Conference on Artificial Intelligence,
Providence, Rhode Island, July. AAAI,
Menlo Park, California, pages 629?635.
Mellish, Chris, Roger Evans, Lynne Cahill,
Christine Doran, Daniel Paiva, Mike
Reape, Donia Scott, and Neil Tipper. 2000.
A representation for complex and
evolving data dependencies in generation.
In Proceedings of the Sixth Applied Natural
Language Processing Conference (ANLP?00),
Seattle.
Mittal, Vibhu, Johanna Moore, Guiseppe
Carenini, and Steven Roth. 1998.
Describing complex charts in natural
language: A caption generation system.
Computational Linguistics, 24(3):431?468.
Moore, Johanna and Martha Pollack. 1992.
A problem for RST: The need for
multi-level discourse analysis.
Computational Linguistics, 18(4):537?544.
Moser, Megan and Johanna Moore. 1996.
250
Computational Linguistics Volume 29, Number 2
Towards a synthesis of two accounts of
discourse structure. Computational
Linguistics, 22(3):409?419.
Nunberg, Geoff. 1990. The Linguistics of
Punctuation, volume 18 in CSLI Lecture
Notes. CSLI, Stanford, California.
Oates, Sarah. 2001. Generating multiple
discourse markers in text. Master?s thesis,
University of Brighton, Brighton, U.K.
Also available as Technical Report
ITRI-01-25, Information Technology
Research Institute, University of Brighton,
Brighton, U.K.
Paris, Cecile, Keith Vander Linden, Marcus
Fischer, Anthony Hartley, Lynne
Pemberton, Richard Power, and Donia
Scott. 1995. A support tool for writing
multilingual instructions. In Proceedings of
the Fourteenth International Joint Conference
in Artificial Intelligence (IJCAI-95), pages
1398?1404. Also available as Technical
Report ITRI-95-11, Information
Technology Research Institute, University
of Brighton, Brighton, U.K.,
http://www.itri.bton.ac.uk/techreports/.
Pierrehumbert, Janet. 1980. The Phonology
and Phonetics of English Intonation. Ph.D.
thesis, Massachusetts Institute of
Technology, Cambridge.
Power, Richard. 2000. Planning texts by
constraint satisfaction. In Proceedings of the
18th International Conference in
Computational Linguistics (COLING),
Saarbru?cken, Germany, pages 642?648.
Power, Richard and Nico Cavallotto. 1996.
Multilingual generation of administrative
forms. In Proceedings of the Eighth
International Workshop on Natural Language
Generation, Herstmonceux Castle, Sussex,
U.K., pages 17?19.
Quirk, Randolph, Sidney Greenbaum,
Geoffrey Leech, and Jan Svartvik. 1985. A
Comprehensive Grammar of the English
Language. Longman, London.
Reiter, Ehud. 1994. Has a consensus NL
generation architecture appeared, and is it
psycholinguistically plausible? In
Proceedings of the Seventh International
Workshop on Natural Language Generation
(INLGW-1994), Kennebunkport, Maine,
pages 163?170.
Reiter, Ehud and Robert Dale. 2000. Building
Natural Language Generation Systems.
Cambridge University Press, Cambridge.
Rosner, Dietmar and Manfred Stede. 1992.
Customizing RST for the automatic
production of technical manuals. In
R. Dale, D. Roesner, E. H. Hovy, and
O. Stock, editors, Aspects of Automated
Natural Language Generation.
Springer-Verlag, Heidelberg, pages
199?214.
Schriver, Karen. 1997. Dynamics in Document
Design: Creating Text for Readers. Wiley
Computer, New York.
Scott, Donia and Clarisse de Souza. 1990.
Getting the message across in RST-based
text generation. In R. Dale, C. Mellish,
and M. Zock, editors, Current Research in
Natural Language Generation, volume 4 in
Cognitive Science Series. Academic Press,
New York, pages 47?73.
Scott, Donia and Cecile Paris. 1995.
Identifying the mapping of semantics
onto language: Going beyond the text. In
Working Papers of the AAAI Symposium on
Empirical Methods in Discourse Interpretation
and Generation, Stanford University,
Stanford, California, March.
Scott, Donia and Richard Power. 2001.
Generating textual diagrams and
diagrammatic texts. In H. Bunt and R-J.
Beun, editors, Cooperative Multimodal
Communication, volume 2155 in Lecture
Notes in Artificial Intelligence.
Springer-Verlag, Berlin, pages 13?29. Also
available as Technical Report ITRI-01-02,
Information Technology Research
Institute, University of Brighton,
Brighton, U.K.
?t Hart, Johan, Rene? Collier, and Antonie
Cohen. 1990. A Perceptual Study of
Intonation, in series Cambridge Studies in
Speech Science and Communication.
Cambridge University Press, Cambridge.
Yekovich, Frank, Carol Walker, and Harold
Blackman. 1979. The role of presupposed
and focal information in integrating
sentences. Journal of Verbal Learning and
Verbal Behavior, 18:535?548.
251
Power, Scott, and Bouayad-Agha Document Structure
Appendix. Solutions Found for the Example in Section 6.1
Number of versions = 58
Version 1 (0)
Elixir contains gestodene. However, the medicine has been thoroughly tested and it
has no significant side effects; consequently, Elixir is safe to use.
Version 2 (0)
Elixir contains gestodene; however, since
? the medicine has been thoroughly tested
? it has no significant side effects
Elixir is safe to use.
Version 3 (0)
Elixir contains gestodene. However, since
? the medicine has been thoroughly tested
? it has no significant side effects
Elixir is safe to use.
Version 4 (0)
Elixir contains gestodene; however,
? the medicine has been thoroughly tested
? it has no significant side effects
so Elixir is safe to use.
Version 5 (0)
Elixir contains gestodene. However,
? the medicine has been thoroughly tested
? it has no significant side effects
so Elixir is safe to use.
Version 6 (0)
Elixir contains gestodene. However,
? the medicine has been thoroughly tested
? it has no significant side effects;
consequently, Elixir is safe to use.
Version 7 (1)
Elixir contains gestodene. However, the medicine has been thoroughly tested and it
has no significant side effects. Consequently, Elixir is safe to use.
Lost rhetorical grouping
252
Computational Linguistics Volume 29, Number 2
Version 8 (1)
Elixir contains gestodene. However, the medicine has been thoroughly tested and it
has no significant side effects. Consequently, Elixir is safe to use.
Single-sentence paragraph
Version 9 (1)
Although Elixir contains gestodene since
? the medicine has been thoroughly tested
? it has no significant side effects
Elixir is safe to use.
Lost rhetorical grouping
Version 10 (1)
Although Elixir contains gestodene
? the medicine has been thoroughly tested
? it has no significant side effects
so Elixir is safe to use.
Lost rhetorical grouping
Version 11 (1)
Elixir contains gestodene but since
? the medicine has been thoroughly tested
? it has no significant side effects
Elixir is safe to use.
Lost rhetorical grouping
Version 12 (1)
Elixir contains gestodene but
? the medicine has been thoroughly tested
? it has no significant side effects
so Elixir is safe to use.
Lost rhetorical grouping
Version 13 (1)
Elixir contains gestodene; however, Elixir is safe to use since
? the medicine has been thoroughly tested
? it has no significant side effects.
Nucleus precedes satellite
253
Power, Scott, and Bouayad-Agha Document Structure
Version 14 (1)
Elixir contains gestodene. However, since the medicine has been thoroughly tested
and it has no significant side effects Elixir is safe to use.
Lost rhetorical grouping
Version 15 (1)
Elixir contains gestodene. However, Elixir is safe to use since
? the medicine has been thoroughly tested
? it has no significant side effects.
Nucleus precedes satellite
Version 16 (1)
Elixir contains gestodene; however, the medicine has been thoroughly tested and it
has no significant side effects so Elixir is safe to use.
Lost rhetorical grouping
Version 17 (1)
Elixir contains gestodene. However, the medicine has been thoroughly tested and it
has no significant side effects so Elixir is safe to use.
Lost rhetorical grouping
Version 18 (1)
Elixir contains gestodene; however, the medicine has been thoroughly tested and it
has no significant side effects; consequently, Elixir is safe to use.
Lost rhetorical grouping
Version 19 (1)
Elixir contains gestodene; however,
? the medicine has been thoroughly tested
? it has no significant side effects;
consequently, Elixir is safe to use.
Lost rhetorical grouping
Version 20 (1)
Elixir contains gestodene; however, since the medicine has been thoroughly tested and
it has no significant side effects Elixir is safe to use.
Lost rhetorical grouping
Version 21 (1)
Elixir contains gestodene. However,
? the medicine has been thoroughly tested
? it has no significant side effects.
Consequently, Elixir is safe to use.
Lost rhetorical grouping
254
Computational Linguistics Volume 29, Number 2
Version 22 (1)
Elixir contains gestodene.
However,
? the medicine has been thoroughly tested
? it has no significant side effects.
Consequently, Elixir is safe to use.
Single-sentence paragraph
Version 23 (2)
Elixir contains gestodene but since the medicine has been thoroughly tested and it has
no significant side effects Elixir is safe to use.
Lost rhetorical grouping
Lost rhetorical grouping
Version 24 (2)
? The medicine has been thoroughly tested
? it has no significant side effects
so Elixir is safe to use although Elixir contains gestodene.
Nucleus precedes satellite
Lost rhetorical grouping
Version 25 (2)
Elixir contains gestodene but the medicine has been thoroughly tested and it has no
significant side effects so Elixir is safe to use.
Lost rhetorical grouping
Lost rhetorical grouping
Version 26 (2)
Elixir contains gestodene but Elixir is safe to use since
? the medicine has been thoroughly tested
? it has no significant side effects.
Nucleus precedes satellite
Lost rhetorical grouping
Version 27 (2)
Elixir contains gestodene; however, Elixir is safe to use since the medicine has been
thoroughly tested and it has no significant side effects.
Nucleus precedes satellite
Lost rhetorical grouping
Version 28 (2)
Although Elixir contains gestodene since the medicine has been thoroughly tested and
it has no significant side effects Elixir is safe to use.
Lost rhetorical grouping
Lost rhetorical grouping
255
Power, Scott, and Bouayad-Agha Document Structure
Version 29 (2)
Elixir contains gestodene. However, Elixir is safe to use since the medicine has been
thoroughly tested and it has no significant side effects.
Nucleus precedes satellite
Lost rhetorical grouping
Version 30 (2)
Elixir contains gestodene.
However, the medicine has been thoroughly tested and it has no significant side
effects; consequently, Elixir is safe to use.
Single-sentence paragraph
Single-sentence paragraph
Version 31 (2)
Although Elixir contains gestodene the medicine has been thoroughly tested and it
has no significant side effects so Elixir is safe to use.
Lost rhetorical grouping
Lost rhetorical grouping
Version 32 (2)
Elixir contains gestodene. However, the medicine has been thoroughly tested; it has
no significant side effects; consequently, Elixir is safe to use.
Lost rhetorical grouping
Oversimple text-clauses
Version 33 (2)
Elixir contains gestodene.
However, since
? the medicine has been thoroughly tested
? it has no significant side effects
Elixir is safe to use.
Single-sentence paragraph
Single-sentence paragraph
Version 34 (2)
Elixir contains gestodene. However, the medicine has been thoroughly tested; it has
no significant side effects. Consequently, Elixir is safe to use.
Lost rhetorical grouping
Oversimple text-clauses
Version 35 (2)
Elixir contains gestodene. However, the medicine has been thoroughly tested. It has
no significant side effects. Consequently, Elixir is safe to use.
Lost rhetorical grouping
Lost rhetorical grouping
256
Computational Linguistics Volume 29, Number 2
Version 36 (2)
Elixir contains gestodene.
However,
? the medicine has been thoroughly tested
? it has no significant side effects
so Elixir is safe to use.
Single-sentence paragraph
Single-sentence paragraph
Version 37 (2)
Elixir contains gestodene.
However, the medicine has been thoroughly tested; it has no significant side effects.
Consequently, Elixir is safe to use.
Single-sentence paragraph
Oversimple text-clauses
Version 38 (2)
Elixir contains gestodene.
However, the medicine has been thoroughly tested. It has no significant side ef-
fects. Consequently, Elixir is safe to use.
Single-sentence paragraph
Lost rhetorical grouping
Version 39 (2)
Since
? the medicine has been thoroughly tested
? it has no significant side effects
Elixir is safe to use although Elixir contains gestodene.
Nucleus precedes satellite
Lost rhetorical grouping
Version 40 (2)
Elixir contains gestodene.
However,
? the medicine has been thoroughly tested
? it has no significant side effects;
consequently, Elixir is safe to use.
Single-sentence paragraph
Single-sentence paragraph
257
Power, Scott, and Bouayad-Agha Document Structure
Version 41 (2)
Although Elixir contains gestodene Elixir is safe to use since
? the medicine has been thoroughly tested
? it has no significant side effects.
Nucleus precedes satellite
Lost rhetorical grouping
Version 42 (3)
Elixir contains gestodene.
However, Elixir is safe to use since
? the medicine has been thoroughly tested
? it has no significant side effects.
Single-sentence paragraph
Nucleus precedes satellite
Single-sentence paragraph
Version 43 (3)
Since the medicine has been thoroughly tested and it has no significant side effects
Elixir is safe to use although Elixir contains gestodene.
Nucleus precedes satellite
Lost rhetorical grouping
Lost rhetorical grouping
Version 44 (3)
The medicine has been thoroughly tested and it has no significant side effects so Elixir
is safe to use although Elixir contains gestodene.
Nucleus precedes satellite
Lost rhetorical grouping
Lost rhetorical grouping
Version 45 (3)
Elixir contains gestodene.
However, since the medicine has been thoroughly tested and it has no significant
side effects Elixir is safe to use.
Single-sentence paragraph
Single-sentence paragraph
Lost rhetorical grouping
Version 46 (3)
Although Elixir contains gestodene Elixir is safe to use since the medicine has been
thoroughly tested and it has no significant side effects.
Nucleus precedes satellite
Lost rhetorical grouping
Lost rhetorical grouping
258
Computational Linguistics Volume 29, Number 2
Version 47 (3)
Elixir contains gestodene.
However, the medicine has been thoroughly tested. It has no significant side ef-
fects.
Consequently, Elixir is safe to use.
Single-sentence paragraph
Lost rhetorical grouping
Single-sentence paragraph
Version 48 (3)
Elixir is safe to use since
? the medicine has been thoroughly tested
? it has no significant side effects
although Elixir contains gestodene.
Nucleus precedes satellite
Nucleus precedes satellite
Lost rhetorical grouping
Version 49 (3)
Elixir contains gestodene but Elixir is safe to use since the medicine has been thor-
oughly tested and it has no significant side effects.
Nucleus precedes satellite
Lost rhetorical grouping
Lost rhetorical grouping
Version 50 (3)
Elixir contains gestodene; however, the medicine has been thoroughly tested; it has
no significant side effects; consequently, Elixir is safe to use.
Lost rhetorical grouping
Lost rhetorical grouping
Oversimple text-clauses
Version 51 (3)
Elixir contains gestodene.
However, the medicine has been thoroughly tested and it has no significant side
effects so Elixir is safe to use.
Single-sentence paragraph
Single-sentence paragraph
Lost rhetorical grouping
Version 52 (3)
Elixir contains gestodene.
However,
? the medicine has been thoroughly tested
? it has no significant side effects.
259
Power, Scott, and Bouayad-Agha Document Structure
Consequently, Elixir is safe to use.
Single-sentence paragraph
Lost rhetorical grouping
Single-sentence paragraph
Version 53 (4)
Elixir contains gestodene.
However, the medicine has been thoroughly tested; it has no significant side effects;
consequently, Elixir is safe to use.
Single-sentence paragraph
Single-sentence paragraph
Lost rhetorical grouping
Oversimple text-clauses
Version 54 (4)
Elixir is safe to use since the medicine has been thoroughly tested and it has no
significant side effects although Elixir contains gestodene.
Nucleus precedes satellite
Nucleus precedes satellite
Lost rhetorical grouping
Lost rhetorical grouping
Version 55 (4)
Elixir contains gestodene.
However, the medicine has been thoroughly tested and it has no significant side
effects.
Consequently, Elixir is safe to use.
Single-sentence paragraph
Lost rhetorical grouping
Single-sentence paragraph
Single-sentence paragraph
Version 56 (4)
Elixir contains gestodene.
However, Elixir is safe to use since the medicine has been thoroughly tested and
it has no significant side effects.
Single-sentence paragraph
Nucleus precedes satellite
Single-sentence paragraph
Lost rhetorical grouping
Version 57 (5)
Elixir contains gestodene.
However, the medicine has been thoroughly tested; it has no significant side effects.
Consequently, Elixir is safe to use.
260
Computational Linguistics Volume 29, Number 2
Single-sentence paragraph
Lost rhetorical grouping
Single-sentence paragraph
Oversimple text-clauses
Single-sentence paragraph
Version 58 (6)
Elixir contains gestodene.
However, the medicine has been thoroughly tested.
It has no significant side effects.
Consequently, Elixir is safe to use.
Single-sentence paragraph
Lost rhetorical grouping
Lost rhetorical grouping
Single-sentence paragraph
Single-sentence paragraph
Single-sentence paragraph
From RAGS to RICHES: exploiting the potential of a flexible generation
architecture  
Lynne Cahill  , John Carroll  , Roger Evans  , Daniel Paiva  ,
Richard Power

, Donia Scott  and Kees van Deemter 

ITRI, University of Brighton
Brighton, BN2 4GJ, UK
Firstname.Lastname@itri.bton.ac.uk
 School of Cognitive and Computing Sciences, University of Sussex
Brighton, BN1 9QH, UK
johnca@cogs.susx.ac.uk
Abstract
The RAGS proposals for generic speci-
fication of NLG systems includes a de-
tailed account of data representation,
but only an outline view of processing
aspects. In this paper we introduce a
modular processing architecture with a
concrete implementation which aims to
meet the RAGS goals of transparency
and reusability. We illustrate the model
with the RICHES system ? a generation
system built from simple linguistically-
motivated modules.
1 Introduction
As part of the RAGS (Reference Architecture for
Generation Systems) project, Mellish et al(2000)
introduces a framework for the representation of
data in NLG systems, the RAGS ?data model?.
This model offers a formally well-defined declar-
ative representation language, which supports the
complex and dynamic data requirements of gen-
eration systems, e.g. different levels of repre-
sentation (conceptual to syntax), mixed represen-
tations that cut across levels, partial and shared
structures and ?canned? representations. However

We would like to acknowledge the financial support of
the EPSRC (RAGS ? Reference Architecture for Generation
Systems: grant GR/L77102 to Donia Scott), as well as the
intellectual contribution of our partners at Edinburgh (Chris
Mellish and Mike Reape: grant GR/L77041 to Mellish) and
other colleagues at the ITRI, especially Nedjet Bouayad-
Agha. We would also like to acknowledge the contribution
of colleagues who worked on the RICHES system previ-
ously: Neil Tipper and Rodger Kibble. We are grateful to
our anonymous referees for their helpful comments.
RAGS, as described in that paper, says very little
about the functional structure of an NLG system,
or the issues arising from more complex process-
ing regimes (see for example Robin (1994), Inuie
et al, (1992) for further discussion).
NLG systems, especially end-to-end, applied
NLG systems, have many functionalities in com-
mon. Reiter (1994) proposed an analysis of such
systems in terms of a simple three stage pipeline.
More recently Cahill et al(1999) attempted to re-
peat the analysis, but found that while most sys-
tems did implement a pipeline, they did not im-
plement the same pipeline ? different functional-
ities occurred in different ways and different or-
ders in different systems. But this survey did
identify a number of core functionalities which
seem to occur during the execution of most sys-
tems. In order to accommodate this result, a ?pro-
cess model? was sketched which aimed to support
both pipelines and more complex control regimes
in a flexible but structured way (see (Cahill et al,
1999),(RAGS, 2000)). In this paper, we describe
our attempts to test these ideas in a simple NLG
application that is based on a concrete realisation
of such an architecture1 .
The RAGS data model aims to promote com-
parability and re-usability in the NLG research
community, as well as insight into the organisa-
tion and processing of linguistic data in NLG. The
present work has similar goals for the processing
aspects: to propose a general approach to organis-
ing whole NLG systems in a way which promotes
1More details about the RAGS project, the
RICHES implementation and the OASYS subsys-
tem can be found at the RAGS project web site:
http://www.itri.bton.ac.uk/projects/rags.
the same ideals. In addition, we aim to test the
claims that the RAGS data model approach sup-
ports the flexible processing of information in an
NLG setting.
2 The RAGS data model
The starting point for our work here is the RAGS
data model as presented in Mellish et al(2000).
This model distinguishes the following five levels
of data representation that underpin the genera-
tion process:
Rhetorical representations (RhetReps) define how propo-
sitions within a text are related. For example, the sen-
tence ?Blow your nose, so that it is clear? can be con-
sidered to consist of two propositions: BLOW YOUR
NOSE and YOUR NOSE IS CLEAR, connected by a re-
lation like MOTIVATION.
Document representations (DocReps) encode information
about the physical layout of a document, such as tex-
tual level (paragraph, orthographic sentence, etc.),
layout (indentation, bullet lists etc.) and their relative
positions.
Semantic representations (SemReps) specify information
about the meaning of individual propositions. For
each proposition, this includes the predicate and its
arguments, as well as links to underlying domain ob-
jects and scoping information.
Syntactic representations (SynReps) define ?abstract?
syntactic information such as lexical features (FORM,
ROOT etc.) and syntactic arguments and adjuncts
(SUBJECT, OBJECT etc.).
Quote representations These are used to represent literal
unanalysed content used by a generator, such as
canned text, pictures or tables.
The representations aim to cover the core com-
mon requirements of NLG systems, while avoid-
ing over-commitment on less clearly agreed is-
sues relating to conceptual representation on the
one hand and concrete syntax and document ren-
dering on the other. When one considers process-
ing aspects, however, the picture tends to be a lot
less tidy: typical modules in real NLG systems
often manipulate data at several levels at once,
building structures incrementally, and often work-
ing with ?mixed? structures, which include infor-
mation from more than one level. Furthermore
this characteristic remains even when one consid-
ers more purely functionally-motivated ?abstract?
NLG modules. For example, Referring Expres-
sion Generation, commonly viewed as a single
task, needs to have access to at least rhetorical and
document information as well as referencing and
adding to the syntactic information.
To accommodate this, the RAGS data model in-
cludes a more concrete representational proposal,
called the ?whiteboard? (Calder et al, 1999), in
which all the data levels can be represented in
a common framework consisting of networks of
typed ?objects? connected by typed ?arrows?. This
lingua franca allows NLG modules to manipulate
data flexibly and consistently. It also facilitates
modular design of NLG systems, and reusability
of modules and data sets. However, it does not in
itself say anything about how modules in such a
system might interact.
This paper describes a concrete realisation of
the RAGS object and arrows model, OASYS,
as applied to a simple but flexible NLG system
called RICHES. This is not the first such re-
alisation: Cahill et al, (2000) describes a par-
tial re-implementation of the ?Caption Generation
System? (Mittal et al, 1999) which includes an
objects and arrows ?whiteboard?. The OASYS
system includes more specific proposals for pro-
cessing and inter-module communication, and
RICHES demonstrates how this can be used to
support a modular architecture based on small
scale functionally-motivated units.
3 OASYS
OASYS (Objects and Arrows SYStem) is a soft-
ware library which provides:
  an implementation of the RAGS Object and
Arrows (O/A) data representation,
  support for representing the five-layer RAGS
data model in O/A terms,
  an event-driven active database server for
O/A representations.
Together these components provide a central core
for RAGS-style NLG applications, allowing sepa-
rate parts of NLG functionality to be specified in
independent modules, which communicate exclu-
sively via the OASYS server.
The O/A data representation is a simple
typed network representation language. An O/A
database consists of a collection of objects, each
of which has a unique identifier and a type, and
arrows, each of which has a unique identifier,
a type, and source and target objects. Such a
database can be viewed as a (possibly discon-
nected) directed network representation: the fig-
ures in section 5 give examples of such networks.
OASYS pre-defines object and arrow types re-
quired to support the RAGS data model. Two ar-
row types, el (element) and el(<integer>),
are used to build up basic network structures ?
el identifies its target as a member of the set rep-
resented by its source, el(3), identifies its tar-
get as the third element of the tuple represented
by its source. Arrow type realised by re-
lates structures at different levels of representa-
tion. for example, indicating that this SemRep
object is realised by this SynRep object. Arrow
type revised to provides for support for non-
destructive modification of a structure, mapping
from an object to another of the same type that
can be viewed as a revision of it. Arrow type
refers to allows an object at one level to indi-
rectly refer to an object at a different level. Object
types correspond to the types of the RAGS data
model, and are either atomic, tuples, sets or se-
quences. For example, document structures are
built out of DocRep (a 2-tuple), DocAttr (a set
of DocFeatAtoms ? feature-value pairs), DocRe-
pSeq (a sequence of DocReps or DocLeafs) and
DocLeafs.
The active database server supports multiple
independent O/A databases. Individual modules
of an application publish and retrieve objects and
arrows on databases, incrementally building the
?higher level?, data structures. Modules com-
municate by accessing a shared database. Flow
of control in the application is event-based: the
OASYS module has the central thread of execu-
tion, calls to OASYS generate ?events?, and mod-
ules are implemented as event handlers. A mod-
ule registers interest in particular kinds of events,
and when those events occur, the module?s hander
is called to deal with them, which typically will
involve inspecting the database and adding more
structure (which generates further events).
OASYS supports three kinds of events: pub-
lish events occur whenever an object or arrow is
published in a database, module lifecycle events
occur whenever a new module starts up or termi-
nates, and synthetic events ? arbitrary messages
passed between the modules, but not interpreted
by OASYS itself ? may be generated by mod-
ules at any time. An application starts up by ini-
tialising all its modules. This generates initialise
events, which at least one module must respond
to, generating further events which other modules
may respond to, and so on, until no new events
are generated, at which point OASYS generates
finalise events for all the modules and terminates
them.
This framework supports a wide range of archi-
tectural possibilities. Publish events can be used
to make a module wake up whenever data of a
particular sort becomes available for processing.
Lifecycle events provide, among other things, an
easy way to do pipelining: the second module in a
pipeline waits for the finalise event of the first and
then starts processing, the third waits similarly
for the second to finalise etc. Synthetic events
allow modules to tell each other more explicitly
that some data is ready for processing, in situa-
tion where simple publication of an object is not
enough.
RICHES includes examples of all three
regimes: the first three modules are pipelined us-
ing lifecycle events; LC and RE, FLO and REND
interact using synthetic events; while SF watches
the database specifically for publication events.
4 RICHES
The RICHES system is a simple generation sys-
tem that takes as input rhetorical plans and pro-
duces patient advice texts. The texts are intended
to resemble those found at the PharmWeb site
(http://www.pharmweb.net). These are
simple instructional texts telling patients how to
use certain types of medicines, such as nosedrops,
eye drops, suppositories etc.. An example text
from PharmWeb is shown in figure 1, alongside
the corresponding text produced by RICHES.
The main aim of RICHES is to demonstrate
the feasibility of a system based on both the RAGS
data model and the OASYS server model. The
modules collectively construct and access the data
representations in a shared blackboard space and
this allows the modules to be defined in terms of
their functional role, rather than say, the kind of
data they manipulate or their position in a pro-
cessing pipeline. Each of the modules in the sys-
 How to Use Nose Drops
1. Blow your nose gently, so that it is clear. 
  
2. Wash your hands. 
  
3. Unscrew the top of the bottle and draw some liquid into the dropper. 
  
4. Tilt your head back. 
  
5. Hold the dropper just above your nose and put the correct number of drops into your nostril. 
  
6. DO NOT let the dropper touch the inside of your nose. 
  
7. Keep your head tilted back for two to three minutes to help the drops run to the back of your nose. 
  
8. Replace the top on the bottle. 
 
KEEP ALL MEDICINES OUT OF THE REACH OF CHILDREN 
PharmWeb - Copyright?1994-2001. All rights reserved
  
  
Blow your nose so that it is clear. 
Wash your hands
Unscrew the top. Then draw the liquid into the dropper. 
Tilt your head back
Hold the dropper above your nose. Then put the drops into your nostril.
The dropper must not touch the inside.
Keep your head tilted back for two to three minutes so that the drops run to the back.
Replace the top on the bottle
Generated by RICHES version 1.0 (9/5/2001) on 9/5/2001 
?2001, ITRI, University of Brighton 
Figure 1: An example text from PharmWeb, together with the corresponding text generated by RICHES
tem is in itself very simple ? our primary interest
here is in the way they interact.
Figure 2 shows the structure of the system2.
The functionality of the individual modules is
briefly described below.
Rhetorical Oracle (RO) The input to the sys-
tem is a RhetRep of the document to be gen-
erated: a tree with internal nodes labelled with
(RST-style) rhetorical relations and RhetLeaves
referring to semantic proposition representations
(SemReps). RO simply accesses such a represen-
tation from a data file and initialises the OASYS
database.
Media Selection (MS) RICHES produces doc-
uments that may include pictures as well as text.
As soon as the RhetRep becomes available, this
module examines it and decides what can be il-
lustrated and what picture should illustrate it. Pic-
2The dashed lines indicate flow of information, solid ar-
rows indicate approximately flow of control between mod-
ules, double boxes indicate a completely reused module
(from another system), while a double box with a dashed
outer indicates a module partially reused. Ellipses indicate
information sources, as opposed to processing modules.
tures, annotated with their SemReps, are part of
the picture library, and Media Selection builds
small pieces of DocRep referencing the pictures.
Document Planner (DP) The Document Plan-
ner, based on the ICONOCLAST text planner
(Power, 2000) takes the input RhetRep and pro-
duces a document structure (DocRep). This
specifies aspects such as the text-level (e.g.,
paragraph, sentence) and the relative or-
dering of propositions in the DocRep. Its
leaves refer to SynReps corresponding to syntac-
tic phrases. This module is pipelined after MS,
to make sure that it takes account of any pictures
that have been included in the document.
Lexical Choice (LC) Lexical choice happens in
two stages. In the first stage, LC chooses the lex-
ical items for the predicate of each SynRep. This
fixes the basic syntactic structure of the proposi-
tion, and the valency mapping between semantic
and syntactic arguments. At this point the ba-
sic document structure is complete, and the LC
advises REND and SF that they can start pro-
cessing. LC then goes into a second phase, in-
TEXT
SENTENCE
RHETORICAL 
ORACLE
LEXICAL
FINALISER
RENDERER
LINGO
PICTURE
LIBRARY
SELECTION
MEDIUM FLO
LEXICON
CHOICE
OASYS
REFERRING
EXPRESSIONS
DOCUMENT
PLANNER
Figure 2: The structure of the RICHES system
terleaved with RE and FLO: for each sentence,
RE determines the referring expressions for each
noun phrase, LC then lexicalises them, and when
the sentence is complete FLO invokes LinGO to
realise them.
Referring Expressions (RE) The Referring
Expression module adapts the SynReps to add in-
formation about the form of a noun phrase. It de-
cides whether it should be a pronoun, a definite
noun phrase or an indefinite noun phrase.
Sentence Finaliser (SF) The Sentence Fi-
naliser carries out high level sentential organisa-
tion. LC and RE together build individual syntac-
tic phrases, but do not combine them into whole
sentences. SF uses rhetorical and document struc-
ture information to decide how to complete the
syntactic representations, for example, combin-
ing main and subordinate clauses. In addition, SF
decides whether a sentence should be imperative,
depending on who the reader of the document is
(an input parameter to the system).
Finalise Lexical Output (FLO) RICHES uses
an external sentence realiser component with its
own non-RAGS input specification. FLO provides
the interface to this realiser, extracting (mostly
syntactic) information from OASYS and convert-
ing it to the appropriate form for the realiser. Cur-
rently, FLO supports the LinGO realiser (Carroll
et al, 1999), but we are also looking at FLO mod-
ules for RealPro (Lavoie and Rambow, 1997) and
FUF/SURGE (Elhadad et al, 1997).
Renderer (REND) The Renderer is the module
that puts the concrete document together. Guided
by the document structure, it produces HTML for-
matting for the text and positions and references
the pictures. Individual sentences are produced
for it by LinGO, via the FLO interface. FLO actu-
ally processes sentences independently of REND,
so when REND makes a request, either the sen-
tence is there already, or the request is queued,
and serviced when it becomes available.
LinGO The LinGO realiser uses a wide-
coverage grammar of English in the LKB HPSG
framework, (Copestake and Flickinger, 2000).
The tactical generation component accepts in-
put in the Minimal Recursion Semantics formal-
ism and produces the target text using a chart-
driven algorithm with an optimised treatment of
modification (Carroll et al, 1999). No domain-
specific tuning of the grammar was required for
the RICHES system, only a few additions to the
lexicon were necessary.
5 An example: generation in RICHES
In this section we show how RICHES generates
the first sentence of the example text, Blow your
nose so that it is clear and the picture that accom-
panies the text.
The system starts with a rhetorical represen-
tation (RhetRep) provided by the RO (see Fig-
ure 3)3. The first active module to run is MS
3In the figures, labels indicate object types and the sub-
script numbers are identifiers provided by OASYS for each
which traverses the RhetRep looking at the se-
mantic propositions labelling the RhetRep leaves,
to see if any can be illustrated by pictures in the
picture library. Each picture in the library is en-
coded with a semantic representation. Matching
between propositions and pictures is based on the
algorithm presented in Van Deemter (1999) which
selects the most informative picture whose repre-
sentation contains nothing that is not contained in
the proposition. For each picture that will be in-
cluded, a leaf node of document representation is
created and a realised by arrow is added to it
from the semantic proposition object (see Figure
4).
  	


  



el(1) el(2)
  		
(motivation)
  	ffCan text structure be incompat ib le  with rhetorical structure? 
Nadjet Bouayad-Agha,  Richard Power and Donia  Scott 
Information Technology Research Institute 
University of Brighton 
Lewes Road 
Brighton BN2 4G J, UK 
first name. lastname@it ri.bton.ac.uk 
Abstract  
Scott and Souza (1990) have posed the problem 
of how a rhetorical structure (in which proposi- 
tions are linked by rhetorical relations, but not 
yet arranged in a linear order) can be realized 
by a text structure (in which propositions are 
ordered and linked up by appropriate discourse 
connectives). Almost all work on this problem 
assumes, implicitly or explicitly, that this map- 
ping is governed by a constraint on compatibil- 
ity of structure. We show how this constraint 
can be stated precisely, and present some coun- 
terexamples which seem acceptable ven though 
they violate compatibility. The examples are 
based on a phenomenon we call extraposition, 
in which complex embedded constituents of a 
rhetorical structure are extracted and realized 
separately. 
1 Introduct ion 
Text planning (or more broadly, document plan- 
ning) can be divided into two stages. In the 
first stage, material is selected, perhaps from a 
knowledge base, and organized rhetorically. In 
the second stage, the rhetorical structure is re- 
alized by a text structure (or document struc- 
ture), through which the material is distributed 
among sentences, paragraphs, vertical lists, and 
perhaps even diagrams. The RAtS (1999) pro- 
posal for a standard NLG architecture distin- 
guishes tile outputs of these two phases by the 
data types l:l.hetRep (rhetorical representation) 
and DocRep (document representation). 
We focus in this paper on the  second stage 
of text planning - -  the passage from RhetRep 
to DocRep. NLG researchers have addressed 
this issue in various ways, but everyone as- 
sumes some kind of structural compatibility be- 
tween rhetorical structure and text structure. 
The most popular discourse framework in NLG 
is R ST (Mann a.nd Thompson. 1988). which 
makes the crucial distinction between nucleus, 
which is the most important part of a message, 
and satellite, which is the peripheral part of the 
message. Scott and Souza (1990) provide guide- 
lines for the realisation of RST trees into a co- 
herent text. One of them is to avoid dangling 
sentences, that is, to avoid putting "information 
that is only weakly relevant o the message" in 
a separate sentence because it will feel as if it 
has been introduced as an afterthought or as 
introducing a new topic which is then abruptly 
abandoned, disrupting the comprehensibility of
the text. As an example, the authors provide 
the attributive satellite of an elaboration rela- 
tion. 
Marcu (1996), in order to build a valid text 
plan from a set of rhetorical assertions, uses 
the "nuclearity principle", that is the observa- 
tion in Mann and Thompson's framework that 
"whenever two large text spans are connected 
through a rhetorical relation, that rhetorical re- 
lation holds also between the most important 
parts of the constituent spans". Therefore, the 
resulting text plans are valid in the sense that 
they are isomorphic with one of the rhetorical 
structures that can be built from the rhetorical 
assertions using this nuclearity principle. 
Our aim in this paper is to formulate more 
precisely a notion of structural compatibility 
which is necessary in order to describe the real- 
isation of a RhetRep into various DocReps, and 
then .to discuss some examples (mostly taken 
from the domain of patient information leaflets) 
of apparently acceptable texts in which this no- 
.tion of compatibility is violated..:To discuss 
this issue clearly, an assmnption must be made 
about the kinds of information represented by 
rhetorical and text structure; we outline in sec- 
tion 2 the common assumption that these rep- 
resentations are trees, labelled respectively with 
rhetorical and textual categories, the rhetorical 
structure being unordered and the text struc- 
194 
ture ordered. Section 3 then defines a notion 
of .structural  compatibility that:is weaker than 
isomorphism; section 4 shows that we can find 
plausible counterexamples ven to this weaker 
formulation, and discusses why these passages 
occur. Section 5 discusses ome implications for 
NLG, and finally, section 6 raises further impor- 
tant issues. 
2 Rhetor ica l  s t ruc ture  and 
text  s t ruc ture  
To distinguish clearly between FthetRep and 
DocRep, we need to define the kinds of infor- 
mation that should be included in the two rep- 
resentations. Bateman and Rondhius (1997) 
compare several approaches to rhetorical rep- 
resentation, citing in particular RST (Mann 
and Thompson, 1988) and Segmented Discourse 
Representation Theory (Asher, 1993). These 
approaches share the idea that rhetorical repre- 
sentations are composed of propositions linked 
by rhetorical relations; SDRT includes as well 
the logical apparatus of DRT, thus covering 
notions like necessity and logical scope which 
are missing from RST. For the most part, 
NLG applications have used the RST frame- 
work, adapted in various ways; the most com- 
mon representation, proposed also as the RAGS 
standard, is that of a tree in which terminal 
nodes represent elementary propositions, while 
non-terminal nodes represent rhetorical rela- 
tionships. This representation, proposed for ex- 
ample by Scott and Souza (1990), is illustrated 
by figure 1, which might be realized by the fol- 
lowing passage: 
(1) Elixir occasionally provokes a mild allergic 
reaction B, because it contains gestodene C. 
However, Elixir has no serious side- 
effects A. 
Assuming an RST-based framework, an im- 
portant issue is whether the rhetorical represen- 
. tation should already.imply a linear order. Most 
researchers have followed Scott and Souza in as- 
suming that linear order should be left unspeci- 
fied; i t  is during the transition to the document 
representation that the material is distributed 
among linguistic units (or perhaps diagrams, in 
a multimedia document) arranged in a specific 
order. Thus the cause relation in figure 1. for 
example, could be realized with nucleus first, or 
satellite first, or satellite embedded within nu- 
cleus: 
not(serious-side -e ff ~ts(elixir)) 
NU~EUS S,~LLITE 
B C 
possible(allergic-reaction(elixir)) contain(elixir, gestodene) 
Figure 1: Rhetorical representation 
(2a) Elixir occasionally provokes a mild allergic 
reaction B, because it contains gestodene c. 
(2b) Because it contains gestodene C, Elixir 
occasionally provokes a mild allergic 
reaction B. 
(2c) Elixir, because it contains gestodene C, 
occasionally provokes a mild allergic 
reaction B . 
In the RAGS proposal, which aims to extract 
a useful common approach from current work 
in NLG, the DocRep comprises an ordered tree 
corresponding roughly to the 'logical markup' 
in notations like HTML and LaTeX. More pre- 
cisely, a distinction is made between abstract 
and concrete levels of representation, where the 
abstract representation corresponds to logical 
markup (e.g., concepts like 'paragraph' and :em- 
phasis'), while the concrete representation also 
covers graphical markup (concepts like ~vertical 
space' and 'bold face'). In terms of this dis- 
tinction, it is the AbsDocRep that is specified 
during text planning; graphical markup can be 
deferred to a later formatting stage. 
Figure 2 shows two alternative document rep- 
resentations expressing the rhetorical content in 
figure 1. Following Power (2000), the nodes of 
the tree are labelled with 'text-categories' us- 
ing a system that extends the 'text grammar' 
proposed by Nunberg (1990). 1 These document 
1Nunberg's terms 'text-phrase', 'text-clatise',and 
'text-sentence' refer to textual categories, which 
should not be confused with their syntactic oun- 
terparts. They are defined not by syntactic forma- 
tion rules but by their role in text-structure, which 
is typically marked as follows: tezt-sentences begin 
with a capital letter and end in a full stop; text- 
clauses are separated by semicolons; tezt-phrases are 
195 
PARAGRAPH 
TEXT-SENTENCE 
TEXT-PHRASE " TEXT-PHRASE 
B 
possible(allergic-reaction(elixir)) / 
TEXT-SENTENCE 
TEXT-PHRASE TEXT-PHRASE 
concession A 
"however" not(serious-side-effects(elixir)) 
TEXT-PHRASE TEXT-PHRASE 
cause C 
"because" contain(elixir, gestodene) 
TEXT-SENTENCE 
(b) ~ ~  / 
TEXT-CLAUSE TEXT-CLAUSE TEXT-CLAUSE 
C 
TEXT-PHRASE TEXT-PHRASE TEXT-PHRASE TEXT-PHRASE 
cause B concession A 
"consequently"possible(allergic-reaction(elixir)) "however" not(serious-side-effects(elixir)) 
Figure 2: Document  representations 
representations can now be passed to the tac- 
tical generator for the syntactic realization of 
the elementary propositions; the resulting texts 
might be as follows: 
(3a) Elixir occasionally provokes a mild allergic 
reaction B, because i t  contains gestodene C.
However, Elixir has no serious side- 
effects A. 
(3b) Elixir contains gestodeneC; consequently, 
it occasionally provokes a mild allergic 
reactionS; however, Elixir has no serious 
side-effects A .
3 Structural compatibi l i ty 
Summarising the argument so far. we have made 
three main points: 
o Rhetorical structure has typically been 
represented by unordered RST trees such 
as figure 1. 
o Document structure, which conveys in- 
formation similar to logical markup in 
HTML~ can be represented by ordered 
trees in which nodes are labelled with text- 
categories (figure 2). 
const i tuents  of text-clauses, ometimes eparated by 
commas, although within text-clauses the hierarchi- 
cal- structture is expressed mainly through syntax. 
A given rhetorical representation can be 
expressed by a variety of different docu- 
ment representations, in which the propo- 
sitions occur in different orders, and in 
different text-category configurations, and 
the rhetorical relations are expressed by 
different connectives. 
This formulation of the problem raises an obvi- 
ous question: how can we characterize the set of 
document representations that adequately real- 
ize a given rhetorical representation? Elsewhere 
(Power, 2000), we have argued that an adequate 
realization must meet three conditions: 
Cor rect  content :  
All propositions and 
nmst be expressed. 
rhetorical relations 
Wel l - fo rmed s t ructure :  
General formation rules for document 
structure must be respected (e.g. a text- 
sentence cannot  contain a paragraph, un- 
less tile paragraph is indented). 
S t ruc tura l  compat ib i l i ty :  
The docmnent representation mst orga- 
nize the propositions in a way that is com- 
patible with their organization in rhetori- 
cal structure. 
196 
The first two conditions are relatively straight- 
forward, but what is meant,exactly .by 'struc- 
tural compatibility'? 
Assuming that we are comparing two trees, 
the strongest notion of compatibility is isomor- 
phism, which can be defined for our purposes as 
follows: 
DocRep is isomorphic with RhetRep 
if they group the elementary propo- 
sitions in exactly the same way. 
More formally, every set of proposi- 
tions that is dominated by a node in 
DocRep should be dominated by a node 
in RhetRep, and vice-versa. 
Under this definition, the rhetorical representa- 
tion in figure 1 is isomorphic with the document 
representation i  figure 2a, but not with that in 
figure 2b: 
* Proceeding top-down and left-to-right, the 
five nodes in figure 1 dominate the proposi- 
tion sets {A,B, C}, {A}, {S,C},  {B}, and 
{c}. 
o Ignoring nodes that express discourse con- 
nectives, the nodes in figure 2a dominate 
the proposition sets {A,B,C},  {B,C},  
{B}, {C} (twice), and {A} (twice). These 
are exactly the same sets that were ob- 
tained for figure 1. 
* Tile corresponding sets for figure 2b are 
{A,B,C},  {C}, {B} (twice), and {A} 
(twice). Since the set {B,C} is missing 
from this list, there is a grouping in figure 
1 that is not realized in figure 2b, so these 
representations are not isomorphic. 
Since structures like figure 2b are common, iso- 
tnorphism seems too strong a constraint; we 
have therefore proposed (Power, 2000) the fol- 
lowing weaker notion of compatibility: 
DocRep is compatible with RhetRep 
if every grouping of the elementary 
propositions in Docgep is also found 
in R.hetRep. 
Formally, every set of propositionS 
that is dominated by a node in DocRep 
sh.ould be dominated by a node in 
RhetRep -- bat the converse is not re- 
quired. 
Under this constraint, we allow tim document 
representation t.oomit rhetorical groupings, but 
"you forfA~ T~ITE to take C ~  
your tablet" S U S _  1 NUC~USD 2 
"Go on as before" 
~,~J~ L EU S _ I N U C~.E~ S _2 
B C 
"take another assoon "wait until it is time 
as you remember" to take your next dose" 
Figure 3: Rhetorical representation of in- 
struct ion 
not to introduce new ones. The resulting struc- 
tures may be ambiguous, but this will not mat- 
ter if the unexpressed rhetorical relationships 
can .be inferred from the content. 
4 Extraposition 
The compatibility rule may be a useful text- 
planning heuristic, but as a constraint on ade- 
quacy it still seems too strong. Looking through 
our corpus of patient information leaflets, we 
have noticed some exceptions, especially in pas- 
sages giving conditional instructions: 
(4) If you forget to take your tablet A, take an- 
other as soon as you remember B or wait 
until it is time to take your next dose C. 
Then go on as before D. 
From the point of view of document structure, 
this passage is a paragraph comprising two text- 
sentences: thns the proposition D is separated 
from the other three propositions, which are 
grouped in tile .first sentence. However, rhetor- 
ically speaking, D belongs to the consequent of 
the conditional: it is the final step of the plan 
that should be activated .if_the patient forgets 
to take a dose (figure 3). Compatibility is vio- 
lated because tile DocRep contains a node (the 
first text-sentence) dominating the proposition 
set {A, B, C}. which is not dominated by any 
node in figure 3. 
Such examples might be explained as the re- 
sult of loose punctuation or layout, perhal)S 
197 
through imitation of the patterns of conversa- 
tion, in which extra:.materi~! is_often ~tagged. on- 
as an afterthought. Thus proposition D remains 
grouped with B and C - -  they occur consecu- 
tively - -  but through a minor relaxation of nor- 
mal punctuation it has been separated by a full- 
stop rather than a comma. However, this expla- 
nation fails to cover variations of the example 
in which the propositions in the consequent are 
not realized consecutively in the DocRep: 
(5) Consult your doctor immediately A if a 
rash develops B. It might become seriously 
infected C. 
In this example, A must be grouped rhetori- 
cally with C rather than with B, unless we take 
the radical step of allowing rhetorical structure 
to contradict logical structure. The proposition 
C cannot be logically conjoined with the con- 
ditional because it contains a hypothetical dis- 
course referent (the rash) that is bound to the 
antecedent, and is therefore inaccessible outside 
the conditional. 
If passages of this kind are not artifacts of 
loose punctuation, why do they occur? A plau- 
sible reason, we suggest, is that some com- 
plex rhetorical patterns cannot easily be real- 
ized in a way that maintains structural com- 
patibility, usually because text-clauses are over- 
loaded. Conditionals are especially prone to this 
problem because the only common discourse 
connective ('if') is a subordinating conjunction 
which can only link spans within a syntactic 
sentence (and thus within a text-clause). If ei- 
ther the antecedent or the consequent is com- 
plex, the author is faced with a tricky problem. 
We have found examples in patient informa- 
tion leaflets of conditional sentences so long that 
they are ahnost incomprehensible. More skilled 
authors, however, succeed in presenting the ma- 
terial clearly either by using layout (e.g., a com- 
plex antecedent is presented as an indented list), 
or by a trick of rhetorical reorganization that we 
will call eztraposition. It is this trick that intro- 
duces an incompatibility between RhetRep and 
DocRep. 
Extraposition typically occurs when a rhetor- 
ical representation R contains a complex em- 
bedded constituent C. To respect structural 
compatibility, R should be realized by a doc- 
ument unit that contains the realization of C: 
instead, in extraposition, a document unit real- 
ising/?. - C is coordinated with one realizing C. 
so that the extraposed material C is raised in 
the DocRep to the same level as R. To recon- 
...... struct ~:the:.: meanings.of .the:-.whole:. passage, .the 
reader has to plug C back into R. In most 
cases, the author facilitates this task through 
an explicit deictic reference to the extraposed 
material (Bouayad-Agha et al, 2000): 
(6) If you have any of the following, tell your 
doctor: 
difficulty in breathing 
. . . . . . . . . . .  al)dominal..Dains 
nausea or vomiting 
Occasionally, however, the author leaves the 
extraposition implicit, assuming that the reader 
can infer the correct location of C within R from 
the propositional content. In such cases, the ex- 
traposition looks like an afterthought, because 
the unit realizing R - C contains no signal that 
a gap in its content will be filled in later. 
We have also come across rare examples 
of another kind of incompatibil ity in which 
Marcu's (1996) principle of nuclearity is vio- 
lated by grouping together two satellites which 
have the same nucleus. Suppose that the rhetor- 
ical representation i figure 1 is realized by the 
following passage, in a context in which the 
reader knows nothing about gestodene: 
(7) Although Elixir has no serious side- 
effects A, it contains gestodene c. Conse- 
quently, it occasionally provokes a mild al- 
lergic reaction 8. 
The apparent concession relation between A 
and C here is paradoxical, since in rhetorical 
structure they are unrelated. Of course a con- 
trast between A and C nfight be perceived by 
a medical expert; however, one can construct 
similar examples in which the apparent relation 
is even less plausible: 
(8a) Although we usually work fl'om nine' to 
five A, today is Friday C. Consequently, we 
can go home early B. 
This may be rather loose, but many people find 
it acceptable. It could be explained as a rhetor- 
ical trick in which the sheer paradox of the con- 
cession serves as a signal that it is incomplete. 
The device might be spelled out as follows: 
Although Elixir has no serious side- 
effects A, there exists a contrasting 
state of a~hirs resulting fl'om the flzct 
that it contains gestodene c. This 
state of affairs is that it occasionally 
provokes a nfild allergic reaction t3. 
198 
Unlike the conditional examples above, this de- 
vice works only.when the-.rhetorically grouped 
propositions B and C are consecutive in the 
DocRep. Thus whatever view is taken of exam- 
ple (Sa) , everyone finds its variant (Sb) much 
worse: 
(Sb) # Today is Friday C although we usually 
work from nine to five A. Consequently, we 
can go home early s. 
5 Implications for NLG 
For many NLG applications, the notion of com- 
patibility defined above is a useful hard con- 
straint; even if violations of this constraint are 
sometimes acceptable, they are not essential. 
However, for some kinds of material (e.g., com- 
plex instructions), extraposition is a convenient 
rhetorical device which might improve the read- 
ability of the generated texts, so it is worth con- 
sidering how a text planner might be configured 
so as to allow solutions that violate compatibil- 
ity. 
In terms of the RAGS framework, there 
are broadly two possible approaches. First, 
we could introduce incompatibility by defin- 
ing transformations on the RhetRep; alterna- 
tively, we could relax the constraints govern- 
ing the transition from RhetRep to DocRep. 
The RAGS proposal (1999) allows for rhetorical 
transformations through a distinction between 
abstract and concrete rhetorical representa- 
tions. The abstract representation AbsRhetRep 
expresses the rhetorical content of the under- 
lying message, while the concrete RhetRep ex- 
presses the rhetorical structure directly realized 
in the text and corresponds to the representa- 
tion used by Scott and Souza (1990) to discuss 
textual realisation. If KhetRep is incompati- 
ble with AbsRhetRep, the text structure DocRep 
will also be incompatible with AbsRhetRep, 
even though the rules for realizing rhetorical 
structure by document structure are themselves 
compatibility-preserving, qYaalsformation oper- 
ations are also used by Marcu (2000) to map 
Japanese rhetorical structures onto English-like 
rhetorical structures, but these are mappings 
between two PdaetReps rather than from an 
AbsRhetRep to a RhetRep. 
If transformations are allowed, there are obvi- 
ous dangers that the message will be expressed 
in such a distorted way that the reader cannot 
recover the original intention. For this reason, 
rhetori(:al transformations must be defined with 
care. A fairly safe option would appear to be 
.... -the ..extraposition-iof.:a ,proposition. ~lab6rai~ing 
the antecedent of a conditional - - .even though 
such a transformation would violate Marcu's 
(1996) 'nuclearity principle' (assuming that the 
antecedent is regarded as the satellite). The fop - 
lowing examples how that this transformation 
leads to acceptable texts regardless of the order 
of nucleus and satellite within the conditional: 
(9a)~ Dcr.uot" use :Elixirif you :have had' an al: " 
lergic reaction to Elixir. An allergic reac- 
tion may be recognised as a rash, itching 
or shortness of breath. 
(9b) If you have had an allergic reaction to 
Elixir, do not use Elixir. An allergic re- 
action may be recognised as a rash, itching 
or shortness of'breath. 
However, the approach based on rhetorical 
transformations leads to difficulties when the 
acceptability of the resulting text depends on 
linear order as well as grouping. For instance, 
suppose that we try extraposing the elabora- 
tion of a satellite when the main relation is not 
a conditional, but a concession. The following 
passages how two texts that might result, but 
in this case the second version sounds anoma- 
lous: even if they are not grouped together in 
the DocRep, the satellite and its elaboration at 
least need to be consecutive. 
(10a) You should not stop taking Elixir, even 
though you might experience some mild 
effects. For example, feelings of dizziness 
and nausea are very common at the begin- 
ning of treatment. 
(lOb) # Even though you might experience some 
mild effects at tile beginning of tile treat- 
ment, you should not stop taking Elixir. 
For example, feelings of dizziness and nau- 
sea are very common at the beginning of 
treatment. 
A transformation from AbsKhetRep to 
RhetRep cannot distinguish these cases, so that 
10a is,allowed while 10b is protfibited; unless the 
l:l.hetRep is at least partially specified for linear 
order. Adhering strictly to the RAGS frame- 
work, where linear order is specified only in 
tbsDocRep, one would have to adopt the alter- 
native of building an incompatible /~bsDocRep 
from RhetRep. constraining the linear order at, 
this stage. 
199 
6 Conclusion 
We have discussed various examples Of extra- 
position. This phenomenon is due to various 
factors: the complexity of the material (exam- 
ple 4), the presence of logical information (5), 
the use of referring expressions to access infor- 
mation at various degrees of accessibility in the 
text structure (5,6,9), and the use of particular 
rhetorical strategies (7,8). This last group of ex- 
amples concerns.a concession constr.uction sim- 
ilar to the one discussed by Grote et al (1997), 
namely the substitution concession. This type 
of concession groups together the conceded part 
A and the explanation C but leaves the conclu- 
sion B unverbalised. The difference in the case 
of examples 7 and 8 is that A and C are grouped 
together but B is required to follow them be- 
cause there is not enough information for the 
reader to infer B from A and C. 
The extraposition phenomenon shows that 
the nucleus-satellite distinction is not the only 
factor influencing the segmentation f the mes- 
sage. In example 10, the injunction you should 
not stop taking Elixir obviously expresses the 
main intention of the author. However, the 
fact that the subordinated concession is placed 
after its main clause makes it available for 
further expansion. The sometimes compet- 
ing informational nd intentional roles of dis- 
course segments have been at the centre of 
the debate over the nucleus-satellite distinction 
(Moore and Pollack, 1992; Moser and Moore, 
1996; Bateman and Rondhius, 1997); the acces- 
sibility of discourse segments on the right fron- 
tier of a discourse structure is a phenomenon 
that has already been discussed by several re- 
searchers (Webber, 1991; Asher, 1993). Extra- 
position provides a useful and sometimes im- 
portant means of rearranging complex material 
in an abstract discourse representation in order 
to satisfy the constraints posed by linearisation 
into text. 
References 
N. Asher. 1993. Reference to Abstract Objects 
in Discourse. Kluwer Academic Publishers, 
Netherlands. 
J. Bateman and K. Rondhius. 1997. Coher- 
ence relations: Towards a general specifica- 
tion. Discourse Processes, 24(1):3-50. 
N. Bouayad-Agha, D. Scott, and R. Power. 
2000. Integrating content and style in doc- 
mnents: a case study of patient informa- 
tion leaflets. Information Design Journal, 
-9(2):161~176. - -  ? : - ' . : : -  
B. Grote, N. Lenke, and Stede M. 1997. 
Ma(r)king concessions in english and german. 
Discourse Processes, 24( 1):87-117. 
W. Mann and S. Thompson. 1988. Rhetorical 
structure theory: towards a functional theory 
of text organization. Text, 8(3):243-281. 
D. Marcu, L. Carlson, and M. Watanabe. 2000. 
The automatic translation of discourse struc- 
tures. In Proceedings of the North Ameri- 
can Chapter of the Association for Comptu- 
ational Linguistics (NAACL'2000), Seattle, 
Washington. 
D. Marcu. 1996. Building up rhetorical struc- 
ture trees. In Proceedings of AAAI-96. Amer- 
ican Association for Artificial Intelligence. 
D.J Moore and M.E. Pollack. 1992. A prob- 
lem for rst: The need for multi-level dis- 
course analysis. Computational Linguistics, 
18(4):537-544. 
M. Moser and J.D. Moore. 1996. Towards a 
synthesis of two accounts of discourse struc- 
ture. Computational Linguistics, 22(3):409- 
419. 
G. Nunberg. 1990. The Linguistics of Punctu- 
ation. CSLI, Stanford, USA. 
R. Power. 2000. Mapping rhetorical struc- 
tures to text structures by constraint satis- 
faction. Technical report, ITRI, University of 
Brighton. 
RAGS. 1999. The RAGS project: towards 
a reference architecture for natural lan- 
guage generation systems. Technical report, 
Information Technology Research Institute, 
Brighton, UK. 
D. Scott and C. de Souza. 1990. Getting the 
message across in RST-based text generation. 
In R. Dale, C. Mellish, and M. Zock, editors, 
Current Research in Natural Language Gen- 
eration. Cognitive Science Series, Academic 
Press. 
B.L Webber. 1991. Structure and ostension in 
the interpretation of discourse deixis. Lan- 
guage and Cognitive Processes, 6(2):107-135. 
200 
Evaluating text quality: judging output texts without a clear source 
 
 
 
Abstract 
We consider how far two attributes of 
text quality commonly used in MT 
evaluation ? intelligibility and fidelity ? 
apply within NLG. While the former 
appears to transfer directly, the latter 
needs to be completely re-interpreted. 
We make a crucial distinction between 
the needs of symbolic authors and 
those of end-readers. We describe a 
form of textual feedback, based on a 
controlled language used for specifying 
software requirements that appears well 
suited to authors? needs, and an 
approach for incrementally improving 
the fidelity of this feedback text to the 
content model. 
1 Introduction 
Probably the most critical questions that need to 
be addressed when evaluating automatically 
generated texts are: does the text actually say 
what it?s supposed to say and is it fluent, 
coherent, clear and grammatical? The answers to 
these questions say something important about 
how good the target texts are and ? perhaps 
more to the point ? how good the system that 
generated them is. There is no a priori reason 
why the target texts should be any better or 
worse when they result from natural language 
generation (NLG) or from machine translation 
(MT): indeed, they could result from the same 
language generator. Given this, it may be natural 
to assume that NLG could appropriately adopt 
evaluation methods developed for its more 
mature sister, MT. However, while this holds 
true for issues related to intelligibility (the 
second critical question), it does not apply as 
readily to issues of fidelity (the first question). 
We go beyond our recent experience of 
evaluating the AGILE system for producing 
multilingual versions of software user manuals 
(Hartley, Scott et al, 2000; Kruijff et al, 2000) 
and raise some open questions about how best to 
evaluate the faithfulness of an output text with 
respect to its input specification. 
2 Evaluating intelligibility 
The use of rating scales to assess the 
intelligibility of MT output has been widespread 
since the early days in the field. Typically, 
monolingual raters assign a score to each 
sentence in the output text. However, this does 
not amount to an agreed methodology, since the 
number of points on the scale and their 
definition have varied considerably. For 
example, Carroll (1966) used a nine-point scale 
where point 1 was defined as ?hopelessly 
unintelligible? and point 9 as ?perfectly clear 
and intelligible?; Nagao and colleagues (Nagao 
et al, 1985), in contrast, used a five-point scale, 
while Arnold and his colleagues (Arnold et al, 
1994) suggest a four-point discrimination. In 
evaluating the intelligibility of the AGILE output, 
we asked professional translators and authors 
who were native speakers of the languages 
concerned?Bulgarian, Czech and Russian?to 
score individual text fragments on a four-point 
scale. The evaluators were also asked to give a 
summative assessment of the output?s suitability 
as the first draft of a manual. 
In a single pass, AGILE is capable of 
generating several types of text, each 
Anthony Hartley and Donia Scott 
Information Technology Research Institute, 
University of Brighton 
UK 
{firstname.lastname}@itri.bton.ac.uk
constituting a section of a typical software user 
manual?i.e., overview, short instructions, full 
instructions, and functional descriptions?and 
appearing in one of two styles (personal/direct 
or impersonal/indirect). We evaluated all of 
these text types using the same method. The 
intelligibility evaluation was complemented by 
an assessment of the grammaticality of the 
output, conducted by independent native 
speakers trained in linguistics. Following an 
approach widely used in MT (e.g., Lehrberger 
and Bourbeau, 1987), the judges referred to a 
list of error categories for their annotations. 
 
3 Evaluating fidelity 
In MT, evaluating fidelity (or ?accuracy?) 
entails a judgment about the extent to which two 
texts ?say the same thing?. Usually, the two 
texts in question are the source (i.e., original) 
text and the (machine-)translated text and the 
judges are expert translators who are again 
invited to rate the relative information content of 
pairs of sentences on an anchored scale (e.g., 
Nagao et al, 1985). But others (e.g., Caroll, 
1966) have also compared the informativeness 
of the machine translation and a human 
translation deemed to serve as a benchmark. 
Interestingly, both of these researchers found a 
high correlation between the intelligibility 
evaluations and the fidelity evaluations, which 
suggests that it may be possible to infer fidelity 
from the (less costly) evaluation of 
intelligibility. However, at the current state-of-
the-art this approach does not guarantee to 
detect cases where the translation is perfectly 
fluent but also quite wrong. 
For NLG, the story is rather different. 
Lacking a source text, we are denied the 
relatively straightforward approach of detecting 
discrepancies between artifacts of the same type: 
texts. The question is, instead, whether the 
generated text ?says the same thing? as the 
message ? i.e., the model of the intended 
semantic content together with the pragmatic 
force of the utterance. 
The message is clearly only available 
through an external representation. In translation 
generally, this external representation is the 
source text and the task is commonly 
characterized as identifying the message ? 
which originates in the writer?s mental model ? 
in order to re-express it in the target language. In 
an NLG system, the one external representation 
that is commonly available is the particular 
domain model that serves as input to the 
generation system. This model may have been 
provided directly by an artificial agent, such as 
an expert system. Alternatively, it may have 
been constructed by a human agent as the 
intended instantiation of their mental model. 
Yet, whatever its origins, directly comparing 
this intermediate representation to the output 
text is problematic. 
A recent survey of complete NLG systems 
(Cahill et al, 1999) found that half of the 18 
systems examined accepted input directly from 
another system1. A typical example is the 
Caption Generation System (Mittal et al, 1998), 
which produces paragraph-sized captions to 
accompany the complex graphics generated by 
SAGE (Roth et al, 1994). The input to generation 
includes definitions of the graphical constituents 
that are used to by SAGE to convey information: 
?spaces (e.g., charts, maps, tables), graphemes 
(e.g., labels, marks, bars), their properties (e.g., 
color, shape) and encoders?the frames of 
reference that enable their properties to be 
interpreted/translated back to data values (e.g., 
axes, graphical keys).?2 For obvious reasons, 
this does not readily lend itself to direct 
comparison with the generated text caption. 
In the remaining half of the systems 
covered, the domain model is constructed by the 
user (usually a domain expert) through a 
technique that has come to be known as 
symbolic authoring: the ?author? uses a 
specially-built knowledge editor to construct the 
symbolic source of the target text. These editors 
are interfaces that allow authors to build the 
domain model using a representation that is 
more ?natural? to them than the artificial 
language of the knowledge base.3 The purpose 
of these representations is to provide feedback 
intended to make the content of the domain 
model more available to casual inspection than 
the knowledge representation language of the 
                                                           
1 By complete systems, we refer to systems that determine 
both ?what to say? and ?how to say it?, taking as input a 
specification that is not a hand-crafted simulation of some 
intermediate representation. 
2 Mittal et al, 1998, pg. 438. 
3 See Scott, Power and Evans, 1998. 
domain model. As such, they are obvious 
candidates as the standard against which to 
measure the content of the texts that are 
generated from them. 
We first consider the case of feedback 
presented in graphical mode, and then the option 
of textual feedback, using the WYSIWYM 
technology (Power and Scott, 1998; Scott, 
Power and Evans, 1998). We go on to make 
recommendations concerning the desirable 
properties of the feedback text. 
4 Graphical representations of content 
Symbolic authoring systems typically make use 
of graphical representations of the content of the 
domain model?for example, conceptual graphs 
(Caldwell and Korelsky, 1994). Once trained in 
the language of the interface, the domain 
specialist uses standard text-editing devices such 
as menu selection and navigation with a cursor, 
together with standard text-editing actions (e.g., 
select, copy, paste, delete) to create and edit the 
content specification of the text to be generated 
in one or several selected languages. 
The user of AGILE, conceived to be a 
specialist in the domain of the particular 
software for which the manual is required (i.e., 
CAD/CAM), models the procedures for how to 
use the software. AGILE?s graphical user 
interface (Hartley, Power et al, 2000) closely 
resembles the interface that was developed for 
an earlier system, DRAFTER, which generates 
software manuals in English and French (Paris 
et al, 1995). The design of the interface 
represents the components of the procedures 
(e.g., goals, methods, preconditions, sub-steps, 
side-effects) as differently coloured boxes. The 
user builds a model of the procedures for using 
the software by constructing a series of nested 
boxes and assigning labels to them via menus 
that enable the selection of concepts from the 
underlying domain ontology. 
4.1 The input specification for the user 
As part of our evaluation of AGILE, we asked 18 
IT professionals4 to construct a number of 
predetermined content models of various 
degrees of complexity and to have the system 
                                                           
4 There were six for each of the three Eastern European 
languages; all had some (albeit limited) experience of 
CAD/CAM systems and were fluent speakers of English. 
generate text from them in specified styles in 
their native language. Since the evaluation was 
not conducted in situ with real CAD/CAM 
system designers creating real draft manuals, we 
needed to find a way to describe to the 
evaluators what domain models we wanted them 
to build. Among the possible options were to 
give them a copy of either: 
? the desired model as it would appear to 
them in the interface (e.g., Figure 1); 
? the target text that would be produced 
from the model (e.g., Figure 2); 
? a ?pseudo-text? that described the model 
in a form of English that was closer to 
the language of the AGILE interface than 
to fluent English (e.g., Figure 3). 
 
Figure 1: Graphical display of content model 
 
Figure 2: Target text 
 
 
 
 
Figure 3: Pseudo-text input specification 
 
We rejected the first option because it 
amounted to a task of replication which could be 
accomplished successfully even without users 
having any real understanding of the meaning of 
Draw a line by specifying its start and end points. 
To draw a line 
Specify the start point of the line. 
Specify the end point of the line. 
the model they were building. Therefore, it 
would shed no light on how users might be able 
to build a graphical model externalising their 
own mental model. 
We discarded the second because a text may 
not necessarily make any explicit linguistic 
distinction between different components of the 
model?for example, between a precondition on 
a method and the first step in a method 
consisting of several steps5.  Thus, in general, 
target texts may not reflect every distinction 
available in the underlying domain model 
(without this necessarily causing any confusion 
in the mind of the reader). As a result of such 
underspecification, they are ill-suited to serving 
as a staring point from which a symbolic author 
could build a formal model. 
We opted, then, for providing our evaluators 
with a pseudo-text in which there was an 
explicit and regular relationship between the 
compo seudo-
textua of the 
pseudo
 
 
 
 
 
 
 
 
 
 
 
 
F
4.2 
This p
of ju
betwe
           
5 For ex
make su
medium
pluck th
hours.? 
We focused on (a), which was of course 
mediated by (c); that is, we focused on the issue 
of creating an accurate model. This is an easier 
issue than that of the fidelity of the output text to 
the model (b), while the representations in (d) 
are too remote from one another to permit useful 
comparison. 
To measure the correspondence between the 
actual models and the desired/target models, we 
adopted the Generation String Accuracy (GSA) 
metric (Bangalore, Rambow and Whittaker, 
2000; Bangalore and Rambow, 2000) used in 
evaluating the output of a NLG system. It 
extends the simple Word Accuracy metric 
suggested in the MT literature (Alshawi et al, 
1998), based on the string edit distance between 
some reference text and the output of the 
system. As it stands, this metric fails to account 
for some of the special properties of the text 
generation task, which involves ordering word 
tokens. Thus, corrections may involve re-
ordering tokens. In order not to penalise a 
misplaced constituent twice?as both a deletion 
and an insertion?the generation accuracy 
metric treats the deletion (D) of a token from 
one location and its insertion (I) at another 
location as a single movement (M). The 
remaining deletions, insertions, and substitutions 
(S) are counted separately. Generation accuracy 
is given by the following equation, where R is 
the number of (word) tokens in the reference nents of the procedures and their p
l expression.   Figure 4 is one 
-texts used in the evaluation. 
Draw an arc 
 First, start-tool the ARC command. 
M1. Using the Windows 
operating system: choose the 3 
Points option from the Arc 
flyout on the Draw toolbar. 
M2. Using the DOS or UNIX 
operating system: igure 4: fragment of a typical pseudo-text 
Evaluating the fidelity of the output 
articular set-up afforded us the possibility 
dging the fidelity of the ?translation? 
en the following representations: 
a) desired model and model produced 
b) model produced and output text 
c) pseudo-text and model produced 
d) pseudo-text and the output text 
                                                
ample, between: ?To cook a goose: Before starting, 
re the goose has been plucked. Put the goose in a 
 oven for 1.5 hours.? and ?To cook a goose: First 
e goose. Then put it in a medium oven for 1.5 
text.







+++
?= R
SDIMAccuracyGeneration 1  
For Bangalore and his colleagues, the 
reference text is the desired text; it is a gold 
standard given a priori by a corpus representing 
the target output of the system. The generation 
accuracy of a string from the actual output of the 
system is computed on the basis of the number 
of movements, substitutions, deletions and 
insertions required to edit the string into the 
desired form. 
In our case, the correspondence was 
measured between models rather than texts, but 
we found the metric ?portable?. The tokens are 
no longer textual strings but semantic entities. 
Although this method provided a useful 
quantitative measure of the closeness of the fit 
of the actual generated text to what was 
intended, it is not without problems, some of 
choose the Arc option from 
the  Draw menu. 
choose 3 Points option. 
 Specify the start point of the arc.
which apply irrespective of whether the metric is 
applied to texts or to semantic models. For 
example, it does not capture qualitative 
differences between the generated object and the 
reference object, that is, it does not distinguish 
trivial from serious mistakes. Thus, representing 
an action as the first step in a procedure rather 
than as a precondition would have less impact 
on the end-reader?s ability to follow the 
instructions than would representing a goal as a 
side-effect.6 
5 Textual representations of content 
Once the model they represent becomes 
moderately complex, graphical representations 
prove to be difficult to interpret and unwieldy to 
visualise and manipulate (Kim, 1990; Petre, 
1995). WYSIWYM offers an alternative, textual 
modality of feedback, which is more intuitive 
and natural. As we will discuss below, there is a 
sense in which, in its current form, the feedback 
text may be too natural. 
5.1 Current status of  WYSIWYM feedback 
text 
The main purpose of the text generated in 
feedback mode, as currently conceived, is to 
show the symbolic author the possibilities for 
further expanding the model under development. 
As with AGILE?s box representation, 
clicking on a coloured ?anchor? brings up a 
menu of legitimate fillers for that particular slot 
in the content representation. Instantiating green 
anchors is optional, but all red anchors must be 
instantiated for a model to be potentially 
complete (Figure 5). Once this is the case, 
authors tend to switch to output mode, which 
produces a natural text reflecting the specified 
model and nothing else. 
 
 
 
 
 
 
 
Figure 5: fragment of a typical feedback text 
 
                                                           
6 See Hartley et al(2000) for further discussion of this 
issue and the results of the AGILE evaluation. 
In WYSIWYM systems the same generator 
is used to produce both the feedback and output 
texts; this means that the feedback text can be as 
fluent as the output text. In its current 
instantiations, this is precisely what is produced, 
even when the generator is capable of producing 
texts of rather different styles for the different 
purposes.7 
5.2 Feedback in a controlled language 
The motivation for generating a new type of 
feedback text comes from two sources. 
The first is the pseudo-texts that we 
constructed by hand for the AGILE evaluation. 
As far as the form of the models actually 
constructed is concerned, they proved 
consistently reliable guides for the symbolic 
authors. Where they proved inadequate was in 
their identification of multiple references to the 
same domain model entity; several authors 
tended to create multiple instances of an entity 
rather than multiple pointers to a single instance. 
Let us now turn from the testing scenario, where 
authors have a defined target to hit, and consider 
instead a production setting where the author is 
seeking to record a mental model. It is a simple 
matter to have the system generate a second 
feedback text, complementing the present one, 
this time in the style of the pseudo-texts8 for the 
purpose of describing unambiguously, if 
rebarbatively, the state of a potentially complete 
model. 
The second is Attempto Controlled English 
(ACE: Fuchs and Schwitter, 1996; Fuchs, 
Schwertel and Schwitter, 1999), which allows 
domain specialists to interactively formulate 
software requirements specifications. The 
specialists are required to learn a number of 
compositional rules which they must then apply 
when writing their specifications. These are 
parsed by the system. 
For all sentences that it accepts, the system 
creates a paraphrase (Figure 6) that indicates its 
interpretations by means of brackets. These 
interpretations concern phenomena like 
anaphoric reference, conjunction and 
disjunction, attachment of prepositional phrases, 
relative clauses and quantifier scope. The user 
                                                           
7 As, for example, in the ICONOCLAST system (see 
http://www.itri.bton.ac.uk/projects/iconoclast). 
8 Modulo the reference problems, for which a solution is 
indicated below 
1. Do <red>this action</red> by using 
<green>this method</green>. 
2. Schedule <red>this event</red> by 
using <green>this method</green>. 
3. Schedule the appointment by using 
<green>this method</green>. 
either accepts the interpretation or rephrases the 
input to change it. 
 
 
 
 
 
 
 
 
 
 
Figure 6: ACE paraphrases 
 
The principle of making interpretations 
explicit appears to be good one in the NLG 
context too, especially for the person 
constructing the domain model. Moreover, in 
the context where the output text is required to 
be in a controlled language, the use of 
WYSIWYM relieves the symbolic author of the 
burden of learning the specialized writing rules 
of the given control language. 
Optimising the formulation of the controlled 
language feedback is matter of iteratively 
revising it via the testing scenario, using GSA as 
the metric, until authors consistently achieve 
total fidelity of the models they construct with 
the reference models. 
6 Conclusions 
So how can go about judging whether the 
products of NLG systems express the intended 
message? A first step towards this goal is to 
enable symbolic authors to satisfy themselves 
that they have built the domain model they had 
in mind. Graphical feedback is too difficult to 
interpret, while natural language output that is 
optimised for the end-reader may not show the 
unequivocal fidelity to the domain model that 
the symbolic author requires. 
We have suggested that textual feedback in 
a form close to a controlled language used for 
specifying software requirements is a good 
candidate for this task. We have further outlined 
a method for incrementally refining this 
controlled language by monitoring symbolic 
authors? ability to construct reference domain 
models on the basis of controlled language 
feedback. The trade-off between transparency 
and naturalness in the output text intended for 
the end-reader will involve design decisions 
based on, among other things, reader profiling. 
Assessing the fidelity of the end-reader text to 
the model is also a necessary step, but not one 
that can be conflated with or precede that of 
validating the accuracy of the model with 
respect to the author?s intentions. 
 
Acknowledgements 
The work described in the paper has been 
supported by EC INCO-COPERNICUS project 
PL961104 AGILE ?Automatic generation of 
Instructions in Languages of Eastern Europe?. 
The authors express their gratitude to all the 
partners of, and participants in, the AGILE 
project, upon whose work this paper reports. 
 
References 
Alshawi, H., Bangalore, S. and Douglas, S. (1998). 
Automatic acquisition of hierarchical transduction 
models for machine translation. Proceedings of the 
36th Annual Meeting of the Association for 
Computational Linguistics and the 17th 
International Conference on Computational 
Linguistics (COLING-ACL?98), Montreal, 
Canada, pp. 41 ? 47 
Arnold, D., Balkan, L., Lee Humphreys, R., Meijer, 
S. and Sadler, L. (1994). Machine translation: an 
introductory guide. Blackwell. 
Bangalore, S. and Rambow, O. (2000). Exploiting a 
Hierarchical Model for Generation. Proceedings of 
the 18th International Conference on 
Computational Linguistics (COLING?2000), 
Saarbruecken, Germany, pp. 42 ? 48. 
Bangalore, S., Rambow, O. and Whittaker, S. (2000). 
Evaluation Metrics for Generation. Proceedings of 
the 1st International Conference on Natural 
Language Generation, Mitzpe Ramon, Israel, pp. 1 
? 8. 
Cahill, L., Doran, C., Evans, R., Mellish, C., Paiva, 
D., Reape, M., Scott, D. and Tipper, N. (1999). In 
search of a reference architecture for NLG 
systems. Proceedings of the 7th European 
Workshop on Natural Language Generation 
(EWNLG'99), Toulouse, France, pp 77 ? 85. 
Caldwell, T. and Korelsky, T. (1994). Bilingual 
generation of job descriptions from quasi-
conceptual forms. Proceedings of the Fourth 
Conference on Applied Natural Language 
Processing (ANLP?94), pp. 1 ? 6. 
Input: 
The customer enters a card and a numeric personal 
code. If it is not valid then SM rejects the card. 
 
Paraphrase: 
The customer enters a card and [the customer 
enters] a numeric personal code. If [the personal 
code] is not valid then [SimpleMat] rejects the card.
Carroll, J.B. (1966). An experiment in evaluating the 
quality of translations. In J. Pierce. Language and 
machines: computers in translation and 
linguistics. Report by the Automatic Language 
Processing Advisory Committee (ALPAC). 
Publication 1416. National Academy of Sciences 
National Research Council, pp. 67 ? 75. 
Fuchs, N.E. and Schwitter, R. (1996). Attempto 
Controlled English (ACE). Proceedings of the 1st 
International Workshop on Controlled Language 
Applications (CLAW?96), Leuven, Belgium. 
Fuchs, N.E., Schwertel, U. and Schwitter, R. (1999). 
Attempto Controlled English (ACE) Language 
Manual Version 3.0, Technical Report 99.03, 
Department of Computer Science, University of 
Zurich, August 1999. 
Hartley, A., Power, R., Scott, D. and Varbanov, S. 
(2000). Design specification of the user interface 
for the AGILE final prototype. Deliverable INTF2 
of INCO-COPERNICUS project PL961104 
AGILE: ?Automatic. Generation of Instructions in 
Languages of Eastern Europe?. Available at 
http://www.itri.bton.ac.uk. 
Hartley, A., Scott, D., Kruijff-Korbayova, I., Sharoff, 
S. et al (2000). Evaluation of the final prototype. 
Deliverable EVAL2 of INCO-COPERNICUS 
project PL961104 AGILE: ?Automatic. Generation 
of Instructions in Languages of Eastern Europe?. 
Available at http://www.itri.bton.ac.uk. 
Kim, Y. (1990). Effects of conceptual data modelling 
formalisms on user validation and analyst 
modelling of information requirements.  PhD 
thesis, University of Minnesota. 
Kruijff, G-J., Teich, E., Bateman, J., Kruijff-
Korbayova, I. et al (2000). Multilinguality in a 
text generation system for three Slavic languages. 
Proceedings of the 18th International Conference 
on Computational Linguistics (COLING?2000), 
Saarbruecken, Germany, pp. 474 ? 480. 
Lehrberger, J. & Bourbeau, L. (1987) Machine 
translation: linguistic characterisitics of MT 
systems and general methodology of evaluation. 
John Benjamins. 
Mittal, V.O, Moore, J., Carenini, G. and Roth, S. 
(1998). Describing Complex Charts in Natural 
Language: A Caption Generation System. 
Computational Linguistics, 24(3), pp. 431 ? 468. 
Nagao, M. Tsujii, J. and Nakamura, J. (1985). The 
Japanese government project for machine 
translation. Computational Linguistics, 11(2-3), 
pp. 91 ? 109. 
Paris, C., Vander Linden, K., Fischer, M., Hartley, 
T., Pemberton, L., Power, R. and Scott, D. (1995). 
A Support Tool for Writing Multilingual 
Instructions. Proceedings of the Fourteenth 
International Joint Conference in Artificial 
Intelligence (IJCAI?95), pp. 1395 ? 1404.  
Petre, M. (1995). Why looking isn?t always seeing: 
readership skills and graphical programming, 
Communications of the ACM, 38(6), pp. 33 ? 42. 
Power, R. and Scott, D. (1998) Multilingual 
Authoring Using Feedback Texts. Proceedings of 
the 36th Annual Meeting of the Association for 
Computational Linguistics and the 17th 
International Conference on Computational 
Linguistics, Montreal, Canada, pp. 1053 ? 1059. 
Roth, S.F., Kolojejchick, J., Mattis, J. and Goldstein, 
J. (1994) Interactive graphics design using 
automatic presentation knowledge.  Proceedings 
of CHI?94: Human Factors in Computing 
Systems, Boston, M.A. 
Scott, D.R., Power, R., and Evans, R. (1998) 
Generation as a Solution to Its Own Problem. 
Proceedings of the 9th International Workshop on 
Natural Language Generation (INLG'98), Niagara-
on-the-Lake, Canada, pp. 256 ?265. 
 
 
 
Structural variation in generated health reports
Catalina Hallett and Donia Scott
Centre for Research in Computing
The Open University
Walton Hall
Milton Keynes MK7 6AA
{c.hallett,d.scott}@open.ac.uk
Abstract
We present a natural language gener-
ator that produces a range of medi-
cal reports on the clinical histories of
cancer patients, and discuss the prob-
lem of conceptual restatement in gen-
erating various textual views of the
same conceptual content. We focus on
two features of our system: the de-
mand for ?loose paraphrases? between
the various reports on a given patient,
with a high degree of semantic overlap
but some necessary amount of distinc-
tive content; and the requirement for
paraphrasing at primarily the discourse
level.
1 Introduction
Patient records are typically large collections of
documents that reflect the medical history of
a patient over a period of time. On average,
the electronic patient record of a cancer patient
contains information from over 150 documents,
representing consult notes, referral letters, letters
to and from the patient?s GP, hospital admission
and discharge notes, laboratory test results,
surgery and other treatment descriptions, and
drug dispensing notes. Although each document
in this collection will have a specified purpose,
there tends to be a high degree of redundancy
between documents, but the sheer volume of
information makes access extremely difficult.
The work presented in this paper is part of the
Clinical E-Science Framework project (CLEF),
which aims at providing tools to facilitate easy
access to a patient?s medical history. In particular,
we describe a natural language generation system
that produces a range of summarised reports
of patient records from data-encoded views
of patient histories which we call chronicles.
Although we are concentrating on cancer patients,
we aim to produce good quality reports without
the need to construct extensive domain models.
Our typical user is a GP or clinician who
uses electronic patient records at the point of
care to familiarise themselves with a patient?s
medical history and current situation. A number
of specific requirements arise from this particular
setting:
 Reports that provide a quick potted overview
of the patient?s history are essential; this type
of report should not be too long (ideally they
should fit entirely on a computer screen) and
should take less than a minute to read;
 At the same time, a complete view of the
medical history must always be available on
demand;
 Clinicians often need to examine a patient?s
history from a particular perspective (e.g.,
tests administered, treatments undertaken,
drugs prescribed), and having focussed
reports is also a requirement;
 Reports should be formatted to enhance
readability;
 The selection of events for inclusion in a
report should follow some basic rules:
33
? Events that deviate from what is
considered to be normal are more
important than normal events
(for example, an examination
of the lymphnodes that reveals
lymphadenopathy is more important
than an examination that doesn?t).
? Some events are more important than
others and should not only be included
in the report but also highlighted
(e.g., through colour coding, graphical
timelines or similar display features).
? Less important events should be
available on a need-to-know basis
These requirements impose important
restrictions on the content of the reports and
implicitly on the variety of lexical and syntactical
devices we can employ:
(a) the veracity of the report is essential, therefore
we are not at liberty to employ synonymy or
lexical paraphrasing that may alter (however
slightly) the meaning of the original input,
(b) we are required to maintain a certain
syntactical ordering throughout a report in order
to allow the user to quickly scan through the
report with ease, and
(c) we have to produce several types of reports
from the same input data.
In this paper, we focus on this last requirement,
describing the methods we employ for
reformulating content according to the type
and focus of the generated report.
2 Types of report
In the current implementation, the generator
produces two main types of report. The first is a
longitudinal report, which is intended to provide
a quick historical overview of the patient?s
illness, whilst preserving the main events (such
as diagnoses, investigations and interventions).
It presents the events in the patient?s history
ordered chronologically and grouped according
to type. In this type of report, events are
fully described (i.e., an event description includes
all the attributes of the event) and aggregation
is minimal (events with common attributes are
aggregated, but there is no aggregation through
generalization, for example). The following
example displays a fragment of a generated
longitudinal report1:
Example 1
The patient is diagnosed with grade
9 invasive medullary carcinoma of the
breast. She was 39 years old when
the first cell became malignant. The
history covers 1517 weeks, from week
180 to week 1697. During this time, the
patient attended 38 consults.
YEAR 3:
Week 183
 Radical mastectomy on the breast was
performed to treat primary cancer of the
left breast.
 Histopathology revealed primary cancer
of the left breast.
Week 191
 Examination of the abdomen revealed
no enlargement of the liver or of the
spleen.
 Examination of the axillary lymphnodes
revealed no lymphadenopathy of the left
axillary lymphnodes.
 Examination of the breast revealed no
recurrent cancer of the left breast.
 Testing of the blood revealed
no abnormality of the haemoglobin
concentration or of the leucocyte count.
 Radiotherapy was initiated to treat
primary cancer of the left breast.
Week 192
 First radiotherapy cycle was
performed.
 ...
The second type of report focusses on a given
type of event in a patient?s history, such as the
history of diagnoses, interventions, investigations
or drug prescription. Under this category fall
user-defined reports as well, where the user
selects classes of interesting events (for example,
Investigations of type CT scan and Interventions
of type surgery).
A report of the diagnoses, for example,
will focus on the Problem events that are
recorded in the chronicle (e.g., cancer, anaemia,
lymphadenopathy); other event types will only
1All the examples presented in this paper are extracted
from summaries produced by our Report generator.
34
appear if they are directly related to a Problem.
As it can be seen in Example 2, this type of report
is necessarily more condensed, since the events
do not have to appear chronologically and can be
grouped in larger clusters. Secondary events are
also more highly aggregated.
Example 2
 In week 483, primary cancer of the
right breast was revealed by the
histopathology report. The cancer was
treated with radical mastectomy on the
breast.
 In week 491, no abnormality of the
leucocyte count or of the haemoglobin
concentration, no lymphadenopathy of
the right axillary lymphnodes, no
enlargement of the spleen or of the
liver and no recurrent cancer of the
right breast were found. Radiotherapy
was initiated to treat primary cancer of
the right breast.
 In the weeks 492 to 496, 5
radiotherapy cycles were performed.
If the focus is on Interventions, the same
information in the previous example will be
presented as:
Example 3
 In week 483, histopathology revealed
primary cancer of the right breast.
Radical mastectomy on the breast
was performed to treat the cancer.
Radiotherapy was initiated to treat
primary cancer of the right breast.
 In the weeks 492 to 496, 5
radiotherapy cycles were performed.
In an Investigation-focussed report, the
intervention will be omitted, since they are
not directly relevant:
Example 4
 In week 483, histopathology revealed
primary cancer of the right breast
 In week 491, examination revealed no
abnormality of the leucocyte count or
of the haemoglobin concentration, no
lymphadenopathy of the right axillary
lymphnodes, no enlargement of the spleen
or of the liver and no recurrent cancer
of the right breast.
It is important to note that although the reports
are generated from the same input content, they
are not exact reformulations of each other, but
rather different views of the same content with a
large degree of overlap. This feature is a direct
result of the report requirements.
3 Input
As mentioned earlier, the input to our Report
Generator is a data-encoded chronicle of the
patient?s medical history. Technically, the
chronicle is the partial result of information
extraction applied on clinical narratives,
combined with structured data (such as radiology
results or demographic data), and supplemented
with inferences. However, in developing our
report generator, we are currently using a
Chronicle Simulator, which constructs invented
chronicles, allowing us to ignore for the time
being some problems that can appear when
using an information extraction system (being
developed in parallel). Firstly, the resulting
data is complete and correct, thus allowing us
to concentrate on the design and testing of the
generation and summarisation system without
having to take into account at this point errors in
the Information Extraction. Secondly, our data
on cancer patients is highly confidential, which
makes presentation of the output of the report
generator (e.g., for evaluation with real subjects,
or dissemination purposes) very difficult. Using
a simulator also means that we can have instant
access to a large number of randomly generated
chronicles, which at this stage of the project are
not yet available.
The Chronicle Simulator simulates the history
of a patient?s illness, and links the events in
the history in a manner that closely resembles
the expected output of the real Automatic
Chronicler. The current output format of the
simulator is a relational database that stores
six types of event2 (interventions, investigations,
consults, drugs, problems and loci) and 14
types of relation between events (e.g., Problem
2The term event is loosely used to denote dynamic
(such as interventions) as well as static concepts (such as
problems).
35
HAS-LOCUS Locus, Intervention CAUSED-BY
Problem, Intervention SUBPART-OF Intervention,
Investigation HAS-INDICATION Problem). Each
event has a variable number of attributes, and each
dynamic event is time-stamped with a start date
and an end date3. A typical chronicle contains
around 350 events and about 600 relations.
4 Architecture
The design of the Report Generator follows a
classical pipeline architecture, with a content
selector, content planner and syntactic realiser.
The Content Planner is tightly coupled to the
Content Selector, since part of the discourse
structure is already determined in the event
selection phase. Aggregation is mostly
conceptual rather than syntactic, and thus it
is performed in the content planning stage as well
as during realisation (Reape and Mellish, 1999).
4.1 Content selection
The Content selection process represents the most
important component of the Report Generator.
Although in some contexts it may be useful to
generate reports containing all the events in a
chronicle, the most useful types of report are
the focused, summarised ones, for which good
selection of important events is essential.
The process of content selection is currently
driven by two parameters of a report: type and
length. We define the concept of report spine to
represent a list of concepts that are essential to
the construction of a given type of report. For
example, in a report of the diagnoses, all events
of type Problem will be part of the spine. Events
linked to the spine through some kind of relation
may or may not be included in the summary,
depending on the type and length of the summary
(see Figure 1). The design of the system does
not restrict the spine to containing only events of
the same type. In future extensions to the system
where the user will be able to select facts they
want in the summary, a spine could contain, for
example, problems of type cancer, investigations
of type x-ray and interventions of type surgery.
3In the current implementation of the chronicle, time
stamps are week numbers starting with the date of the first
diagnosis.
Investigation
Intervention
Drug
Problem
Problem
Problem
Problem
Locus
Investigation
Locus
Locus
Intervention
Figure 1: Example of a generated spine structure
Spines are not predefined templates, but
structures that are constructed dynamically with
each request and they depend on the type of
request and on the length of the summary.
Important events are selected according to
semantic relations. The first step in the selection
process is to cluster related events based on the
relations stored in the chronicle. A cluster of
events may tell us, for example, that a patient
was diagnosed with cancer following a clinical
examination, for which she had a mastectomy to
remove the tumour, was given a histopathological
test of the removed tumour, which confirmed the
cancer, and had a complete radiotherapy course
to treat the cancer; the radiotherapy caused an
ulcer, which in turn was treated with some drug.
A typical chronicle contains a small number of
clusters, typically one or two large clusters and
several small ones. Smaller clusters are generally
not related to the main thread of events.
The summarisation process starts with the
removal of small clusters, which in the current
implementation are defined as clusters containing
at most three events4. This excludes some
specified types of information that will be
included in the report even when they only appear
in short clusters; for example, all reports will
contain essential information such as the initial
diagnosis and the cause of death (if available).
The next step is the selection of important
events, as defined by the type of report. Each
cluster of events is a graph, with some nodes
representing spine events. For each cluster, the
spine events are selected, as well as all nodes that
are at a distance of less than n from spine events,
4This threshold was set following a series of experiments.
36
where the depth n is a user-defined parameter
used to adjust the size of the report. For example,
in the cluster presented in Fig. 2, assuming
a depth value of 1, the content selector will
choose cancer, left breast and radiotherapy but
not radiotherapy cycle or ulcer.
Has_Locus
Caused_ByIs_Subpart_Of
Indic
ated
_By Has_Locus
cycle
radiotherapy ulcer
left breastradiotherapy
cancer
Figure 2: Example of a cluster
A document plan is typically a hierarchical
structure that contains and combines the
messages to be conveyed by the report generator.
Technically, a document plan is an ordered
collection of message clusters, where messages
within a cluster are combined using rhetorical
relations, while individual clusters are ordered
and linked according to the type of report.
The construction of document plans is partly
performed in the content selection phase,
since the content is selected according to the
relations between events, which in turn provide
information about the structure of the target
text. The actual document planner component
is concerned with the construction of complete
document plans, according to the type of report
and cohesive relations identified in the previous
stage. A report typically consists of three parts:
(a) a schematic description of the patient?s
demographic information (name, age, gender),
(b) a two sentence summary of the patient?s
record (presenting the time span of the illness,
the number of consults the patient attended, and
the number of investigations and interventions
performed) and
(c) the actual report of the record produced from
the events selected to be part of the content.
We focus here on this last part.
4.2 Document planning
The first stage in structuring the body of the
report is to combine messages linked through
attributive relations (e.g., combining messages of
type Problem with messages of type Locus if
the Problem has a HAS-LOCUS relation pointing
to a Locus). In the second stage, messages are
grouped according to specific rules, depending on
the type of report. For longitudinal reports, the
rules stipulate that events occurring in the same
week should be grouped together, and further
grouped into years. In event-specific reports,
patterns of similar events are first identified and
then grouped according to the week(s) they occur
in. For example, if in week 1 the patient was
examined for enlargement of the liver and of the
spleen with negative results and in week 2 the
patient was again examined with the same results
and had a mastectomy, two groups of events will
be constructed:
Example 5
 In weeks 1 and 2, examination of the
abdomen revealed no enlargement of the
liver or of the spleen.
 In week 2, the patient underwent a
mastectomy.
Within groups, messages are structured
according to discourse relations that are either
deduced from the input database or automatically
inferred by applying domain specific rules. At
the moment, the input provides three types of
rhetorical relation: Cause, Result and Sequence.
The domain specific rules specify the ordering
of messages, and always introduce a Sequence
relation. An example of such a rule is that a
histopathology event has to follow a biopsy
event, if both of them are present and they start
and end at the same time. These rules facilitate
the construction of a partial rhetorical structure
tree. Messages that are not connected in the tree
are by default assumed to be in a List relation to
other messages in the group, and their position is
set arbitrarily.
The document planner also applies aggregation
rules between similar messages and employs
ellipsis and conjunction in order to create a
more fluent text. Simple aggregation rules
state, for example, that two investigations with
37
Investigation
[id:03,
name:examination,
HAS?TARGET: {abdomen, breast}]
Investigation
HAS?TARGET: abdomen]
[id: 01,
name: examination,
Investigation
[id:02,
name:examination,
HAS?TARGET: breast]
Figure 3: Aggregation of Investigation messages on the HAS-TARGET field
the same name and two different target loci
can be collapsed into one investigation with
two target loci (Fig.3). Aggregation rules of
this type are designed to make the resulting
text more fluent, however they do not always
provide the degree of condensation required
by the summary. For example, each clinical
examination consists of examinations of the
abdomen for enlargement of internal organs (liver
and spleen) and examination of the lymphnodes.
Thus, each clinical examination will typically
consist of three independent Investigation events.
When fully aggregated according to conceptual
and syntactical rules, the three Investigation
messages are collapsed into one structure such
as:
Example 6
Examination revealed no enlargement
of the spleen or of the liver and no
lymphadenopathy of the axillary nodes.
However, this level of aggregation that only
takes into account the semantics of individual
messages may be not enough, since clinical
examinations are performed repeatedly and
consist of the same types of investigation. Two
approaches have been implemented in the Report
Generator, both of which make use of domain
specific rules. The first is to report only
events that deviate from the norm. In the case
of investigations, for example, this equates to
reporting only those that have abnormal results.
The second, which produces larger reports, is to
produce synthesised descriptions of events. In
the case of clinical examination for example, we
could describe a sequence of investigations such
as the one in example (5) as Clinical examination
was normal. If the examination deviates from the
norm on a restricted numbers of parameters only,
this can be described as Clinical examination was
normal, apart from an enlargement of the spleen.
4.3 Maintaining the thread of discourse
In producing multiple reports on the same patient
from different perspectives, or of different types,
we operate under the strong assumption that
event-focussed reports should be organised in a
way that emphasises the importance of the event
in focus. From a document structure viewpoint,
this equates to constructing rhetorical structures
where the focus event (i.e., the spine event) is
expressed in a nuclear unit, and skeleton events
are preferably in sattelite units.
Within sentences, spine events are assigned
salient syntactical roles that allows them to be
kept in focus. For example, a relation such as
Problem CAUSED-BY Intervention
is more likely to be expressed as :
The patient developed a Problem as a result of an
Intervention.
when the focus is on Problem events, and, when
the focus is on Interventions as:
An Intervention caused a Problem.
This kind of variation reflects the different
emphasis that is placed on spine events, although
the wording in the actual report may be different.
Rhetorical relations holding between simple event
descriptions are most often realised as a single
sentence (as in the examples above). Complex
individual events are realised in individual clauses
or sentences which are connected to other
accompanying events through the appropriate
rhetorical relation.
38
For example, a Problem event has a large
number of attributes, consisting of name, status,
existence, number of nodes counted, number
of nodes involved, clinical course, tumour size,
genotype, grade, tumour marker and histology,
as well as the usual time stamp. The selection
of attributes that are going to be included in a
Problem description depends on a number of
factors, including whether the Problem is a spine
or a skeleton event, and whether the event is
mentioned for the first time or is a subsequent
mention. Aditionally, the number of attributes
included in the description of a Problem is a
decisive factor in realising the Problem as a
phrase, a sentence or a group of sentences. In the
following two examples, there are two Problem
events (cancer and lymphnode count) linked
through an Investigation event (excision biopsy,
which is indicated by the first problem and has
as a finding the second problem. In Example 7,
the problems are first mentioned spine events,
while in Example 8, the problems are skeleton
events (the cancer is a subsequent mention and
the lymphnode count is a first mention), with the
Investigation being the spine event.
Example 7
A 10mm, EGFR +ve, HER-2/neu +ve,
oestrogen receptor positive cancer was
found in the left breast (histology:
invasive tubular adenocarcinoma).
Consequently, an excision biopsy was
performed which revealed no metastatic
involvement in the 5 nodes sampled.
Example 8
An excision biopsy on the left breast
was performed because of cancer. It
revealed no metastatic involvement in
the 5 nodes sampled.
As can be seen from the examples above,
the same basic rhetorical structure consisting
of three nodes and two relations (causality and
consequence) is realised differently in a Problem-
focussed report compared to an Investigation-
based report. The conceptual reformulation is
guided by the type of report, which in turn has
consequences at syntactical level.
5 Evaluation
Automatic evaluation of the generated reports
is not possible, as there is no gold standard
for such documents. Additionally, a full-blown
quantitative evaluation is not yet feasible, since
our users are cancer specialists who cannot
easily dedicate time to evaluating large numbers
of reports. However, we have conducted an
informal survey with two cancer clinicians to gain
feedback on the quality of the current output of
the Report Generator. To do this, we showed them
three patient records encoded as chronicles, and,
for each patient, two types of report produced
from that record: a longitudinal report, and
a summarised report of diagnoses. The three
patient records were selected to display a variety
of events and sizes (a 6-year history containing
621 events, a 12-year history with 1418 events,
and a 9-year history with 717 events).
Although they were (unusually) familiar with
the coding scheme of the chronicles, the
clinicians found it very difficult to extract a useful
overview of the patients? histories from the three
chronicles we showed them. In contrast, they
found the generated reports to be much more
useful and the quality of the text to be very good.
The clinicians commended the reports for their
ability to provide a quick and clear view of data
that would be otherwise difficult to access and
process. Most importantly, the various report
types were judged to be highly appropriate for use
in clinical care.
Whilst this preliminary evaluation was
conducted with the aim of finding early
shortcomings of the Report Generator and
receiving feedback from potential users, we
are now embarking on a more extensive formal
evaluation with cancer clinicians and medical
researchers with specialist knowledge in the area
of cancer. We believe, however, that the true test
of utility will be the actual use of the Report
Generator in practice.
6 Conclusions
We have described a system that generates a range
of health reports on individual cancer patients.
At present, our intended readership is composed
of clinicians and medical researchers, and the
39
type of report will depend on his or her stated
needs. Reports that are required at the point
of care (e.g., for a doctor interviewing a newly
referred patient, or a team of medics on ward
rounds) are likely to be short ?30-second? potted
histories. At other times longer, more detailed
reports will be required, as will reports that focus
on particular aspects of the patient?s ?journey?
through their disease (e.g., from the perspective
of the diagnoses that have been made, the drugs
they have been prescribed, or surgery they have
undergone). The system is fully implemented
in Java and currently generates this full range of
reports on-the-fly. A summarised report based on
about 1000 input events is constructed in less than
2 seconds, a speed which is highly appropriate to
the demands of clinical practice.
While the various types of generated report all
share the same input (i.e., the patient?s chronicle),
and thus will have a large degree of conceptual
overlap, clearly there will be occassions when
information that is included in some reports will
not be in others.
The range of reports for any given patient at any
given point in their illness thus present a special
class of paraphrase, with a looser adherance to
semantic equivalence between versions than is
typically found in other paraphrase generators, for
example Kozlowski et al(2003), McKeown et al
(1994), Power, Scott and Bouyaad-Agha (2003),
Rosner and Stede (1994),(1996), and Scott and
Souza (1990). In this sense, our Report Generator
is rather closer in spirit to Hovy?s PAULINE
system, which generates descriptions of given
news events from different perspectives and with
different stylistic goals (Hovy, 1988). However,
we achieve our goal with less reliance on
terminological variation and more on structural
variation at the discourse level. Syntactic
variation, where it does occur, is almost always
simply a side-effect of an earlier discourse choice.
Terminological variation is deliberately avoided
to prevent false implicatures; however, we are
about to introduce a further class of readership,
namely patients, at which stage we will make
fuller use of our lexical resources.
7 Acknowledgments
CLEF is supported in part by grant G0100852
under the E-Science Initiative. Thanks are due its
clinical collaborators at the Royal Marsden and
Royal Free hospitals, to colleagues at the National
Cancer Research Institute (NCRI) and NTRAC
and to its industrial collaborators. Special thanks
to Dr. Jeremy Rogers who provided us with the
automated Chronicle Simulator that we have used
in all our experiments.
References
Eduard H. Hovy. 1988. Generating natural language
under pragmatic constraints. Lawrence Erlbaum,
Hillsdale, New Jersey.
Raymond Kozlowski, Kathleen F. McCoy, and
K. Vijay-Shanker. 2003. Generation of single-
sentence paraphrases from predicate/argument
structure using lexico-grammatical resources.
In Kentaro Inui and Ulf Hermjakob, editors,
Proceedings of the Second International Workshop
on Paraphrasing, pages 1?8.
Kathleen McKeown, Karen Kukich, and James
Shaw. 1994. Practical issues in automatic
document generation. In Proceedings of the
Fourth Conference on Applied Natural-Language
Processing (ANLP-1994), pages 7?14, Stuttgart,
Germany.
Richard Power, Donia Scott, and Nadjet Bouayad-
Agha. 2003. Document structure. Computational
Linguistics, 29(2):211?260.
Mike Reape and Chris Mellish. 1999. Just what
is aggregation anyway? In Proceedings of
the 7th European Workshop on Natural Language
Generation (EWNLG?99), pages 20?29, Toulouse,
France.
Dietmar Ro?sner and Manfred Stede. 1994.
Generating multilingual documents from
a knowledge base: the TECHDOC project.
In Proceedings of the 15th conference on
Computational Linguistics (Coling?94), pages
339?343, Kyoto, Japan.
Donia Scott and Clarisse de Souza. 1990. Getting
the message across in RST-based text generation. In
R. Dale C. Mellish and M. Zock, editors, Current
Research in Natural Language Generation, pages
31 ? 56. Academic Press.
Manfred Stede. 1996. Lexical paraphrases
in multilingual sentence generation. Machine
Translation, 11:75?107.
40
Automatic generation of large-scale paraphrases
Richard Power and Donia Scott
Centre for Research in Computing
The Open University
Walton Hall
Milton Keynes MK7 6AA
{r.power,d.scott}@open.ac.uk
Abstract
Research on paraphrase has mostly fo-
cussed on lexical or syntactic variation
within individual sentences. Our con-
cern is with larger-scale paraphrases,
from multiple sentences or paragraphs
to entire documents. In this paper
we address the problem of generating
paraphrases of large chunks of texts.
We ground our discussion through a
worked example of extending an exist-
ing NLG system to accept as input a
source text, and to generate a range of
fluent semantically-equivalent alterna-
tives, varying not only at the lexical and
syntactic levels, but also in document
structure and layout.
1 Introduction
Much work on paraphrase generation has fo-
cussed on lexical variation and syntactic trans-
formation within individual sentences (Barzilay
and McKeown, 2001; Carroll et al, 1999; Dras,
1999; Inui and Nogami, 2001; Kozlowski et al,
2003; Langkilde and Knight, 1998; Takahashi
et al, 2001; Stede, 1999). Our interest in this
paper lies instead with variations at the level of
text structuring ? the way in which propositions
are grouped into units like paragraphs, sections,
and bulletted lists, and linked rhetorically by dis-
course connectives such as ?since?, ?nevertheless?,
and ?however?. Elsewhere, we have described a
text-structuring method in which the options for
organising propositions in a text are laid out as a
set of constraints, so that acceptable solutions can
be enumerated using constraint satisfaction and
evaluated using a cost metric (Power et al, 2003).
In this paper we show how this method, when
harnessed to a system for recognising rhetorical
structure in an input text, can be employed in or-
der to produce large-scale paraphrases fulfilling
purposes like improving coherence and achieving
a desired style of layout.
2 Text structure
The input to our text-structuring system (ICONO-
CLAST) is a rhetorical structure tree (Mann and
Thompson, 1983) in which the leaves are elemen-
tary propositions, specified either as semantic for-
mulas or as canned text. The following is a simple
example, containing one nucleus-satellite relation
(REASON) and one multinuclear relation (CON-
JUNCTION1):
reason
NUCLEUS: recommend(doctors, elixir)
SATELLITE: conjunction
1: quick-results(elixir)
2: few-side-effects(elixir)
Ignoring variations in the wording of proposi-
tions, ICONOCLAST generates over 20 texts re-
alising this input (or many more if a larger reper-
toire of discourse connectives is allowed). They
include the following two solutions, which lie at
stylistic extremes, the first compressing the mes-
sage into a sentence (suitable if space is at a pre-
mium), the second laying it out more expansively
in a list:
1This is the RST relation, LIST, which we have renamed
here to avoid possible confusion with the layout style of ver-
tical lists.
73
Solution 1
Doctors recommend Elixir since it gives quick
results and it has few side effects.
Solution 2
? Elixir gives quick results.
? Elixir has few side effects.
Therefore, it is recommended by doctors.
Comparing these solutions illustrates some of the
text-structuring options, and some ways in which
they interact.
? Propositions, or groups of propositions, can
be realised by different text categories. Thus
quick-results(elixir) is realised
by a text-phrase (in Nunberg?s sense (Nun-
berg, 1990)) in Solution 1, and by a text-
sentence (also a list item) in Solution 2.
? Rhetorical relations can be expressed by dif-
ferent discourse connectives or layout op-
tions. In Solution 1, REASON is realised by
?since? and CONJUNCTION by ?and?; in So-
lution 2 REASON is realised by ?therefore?
and CONJUNCTION (more implicitly) by a
bulletted list.
? Propositions may be realised in different or-
ders: for instance, the nucleus of the REA-
SON relation comes first in Solution 1, while
the satellite comes first in Solution 2. Note
that order is constrained by the choice of
discourse connective: ?therefore? requires
satellite-first; ?since? allows both orders.
These text-structuring decisions strongly influ-
ence the options for wording the individual propo-
sitions, mostly because they determine the order
in which propositions are presented. In Solution
1, the nucleus of the REASON relation is presented
first, so ?Elixir? has to be referenced by name, and
there is no particular reason for preferring passive
to active. In Solution 2, the same proposition oc-
curs at the end, when Elixir has been introduced
and established as the topic focus; it is therefore
appropriate to refer to Elixir by a pronoun, and to
promote this reference to the most salient position
in the clause by passivization.
Text structuring is controlled by hard con-
straints, which determine the set of solutions that
can be generated, and by preferences (or soft con-
straints), which allow a ranking of solutions from
best to worst. The purpose of hard constraints
is to avoid solutions that are clearly anomalous,
such as the following text in which the arguments
of the CONJUNCTION relation are separated, thus
altering the rhetorical interpretation:
Since Elixir gives quick results doctors recom-
mend it, and it has few side effects.
A more marginal case is the following solution,
in which the arguments of a nucleus-satellite re-
lation are expressed as items in a bulletted list.
In the default settings this is also considered an
anomaly, since a bulletted list usually implies a
parallelism among the items that is violated when
one argument dominates the other.
? Elixir gives quick results and has
few side-effects.
? Therefore, it is recommended by doctors.
The purpose of soft constraints is to represent
stylistic preferences. These include general prin-
ciples of prose quality that are likely to apply to
any context, as well as preferences specifically
linked to the purpose of the text and the nature
of the intended reader. Here are four examples
of preferences supported in ICONOCLAST: we
would assume that the first two are general, the
second two specific.
? Avoid single-sentence paragraphs This
would penalise a solution in which our ex-
ample was laid out in two paragraphs, one
for satellite and one for nucleus.
? Avoid discontinuity of reference As Kibble
and Power (2004) have shown, centering cri-
teria can be used to penalize solutions with
relatively many topic shifts.
? Avoid passivization In contexts requiring
an informal, popular style, there might be a
stronger tendency to favour active over pas-
sive.
? Avoid complex sentences For some con-
texts we might prefer to penalize solutions
in which many propositions are presented
within the same sentence (e.g., Solution 1).
All these preferences are implemented through a
cost metric. To calculate the cost of a solution,
74
the program first recognizes all violations, then
multiplies each by a weight representing its im-
portance before summing to obtain a total score.
During execution, the program can either enumer-
ate all solutions, ranking them from low cost to
high, or it can simply search for the best solution
using branch-and-bound optimization.
3 Controlling constraints and
preferences
ICONOCLAST was originally developed as a
component of a Natural Language Generation
system. It assumes that the propositional content
of the desired text is already formally encoded,
along with a rhetorical-structure tree represent-
ing the role of each proposition in the argument.
The program can also be run on a simplified in-
put in which propositions are replaced by canned
phrases; however, the quality in this case will
obviously suffer, since referring expressions and
clause structure cannot be adapted to context. By
itself, then, ICONOCLAST cannot be used in or-
der to paraphrase an independently provided text.
However, once a semantic model is available, the
system allows an unusual degree of flexibility and
precision in controlling paraphrases. The source
of this power lies in the use of explicitly encoded
constraints and preferences, which can be edited
through a direct-manipulation user interface in or-
der to guide the generator in the desired direc-
tions.
For hard constraints, the control interface
works mostly by buttons for switching constraints
on and off, or occasionally by menus for fixing
the value of a parameter. Examples of switches
are the following (also mentioned above):
Allow indented list for arguments of a
multinuclear relation (Yes/No)
Allow indented list for arguments of a
nucleus-satellite relation (No/Yes)
Allow discourse connective introducing
a list item (Yes/No)
The default in each case is the option given first,
which would allow (but not require) a solution
to our example in which the conjunction was re-
alised by a list including the discourse connective
?and?:
Doctors recommend Elixir because
? Elixir gives quick results
? And it has few side effects
An example of a parameter setting would be a
constraint fixing the textual unit governing the
whole text, or the maximum text level allowed for
an indented list item:
Root textual unit
(document/section/paragraph/text-sentence)
Maximum level for list item
(paragraph/text-sentence/text-clause)
By constraining the whole text to fit in a para-
graph, we could eliminate any solution requiring
multiple paragraphs (e.g., nucleus in one para-
graph and satellite in another). Under this set-
ting, both solutions 1 and 2 could be generated
(although solution 1 would have to be a single-
sentence paragraph). Further constraining the
root level to sentence would preserve solution
1 but eliminate solution 2.
For soft constraints, the user interface works
through sliders representing both the direction of
a preference and its intensity. In most cases, the
sliders are calibrated to an 11-point scale from
-5 to +5. A straightforward example is the di-
chotomy between active and passive voice, where
negative values penalize use of the passive, while
positive values penalize use of the active; the
central value (zero) represents neutrality. A cost
value is computed every time a proposition is re-
alised by a clause for which the grammar allows
passivization. Depending on the setting of the
11-point scale, a cost is incurred either for use
of the passive (negative values on the scale), or
for failure to use it (positive values on the scale);
the amount of cost varies from 1 to 5, again de-
pending on the setting. Thus if the user sets the
passivization slider to a value of -4, a cost of 4
accrues every time a proposition is realised by a
passive clause; or for a value of +2, a cost of 2
accrues every time a proposition that could have
been realised by a passive clause is realised by an
active one.
In practice, this method of evaluating solu-
tions typically means that every solution is flawed,
given a non-trivial semantic input and a suffi-
cient range of preferences. The reason is that
many decisions are trade-offs: avoiding cost on
75
one preference often means incurring cost else-
where. For instance, a preference to avoid the pas-
sive conflicts with the preference to preserve top-
ical coherence, which is expressed by penalizing
a ?salience violation? ? that is, a failure to equate
the backward-looking center in a clause with the
most salient forward-looking center (i.e., Cb with
Cp) (Kibble and Power, 2004). If salience re-
quires passivization, and passivization is penal-
ized, then a cost must be incurred somewhere: the
issue is which is the lesser evil.
We have considered two ways of control-
ling a paraphrase in a constraint-based gener-
ator: imposing/relaxing a hard constraint, and
changing a preference. A possibility that
we have not yet implemented is a hard con-
straint defined only on the current problem,
as opposed to the general settings illustrated
above. The constraint might state, for example,
that the proposition recommend(doctors,
elixir) should appear at the beginning of the
text, thus eliminating Solution 2. Or it might
state that the conjunction relation between the
other propositions should be realised by a bullet-
ted list, thus eliminating Solution 1. To support
constraints of this kind one would need a user in-
terface in which the user can select part of the
semantic input, perhaps by clicking on the cor-
responding part of the text, as in a WYSIWYM
interface (Power and Scott, 1998); a dialogue
box would then appear allowing a range of con-
straints specifically directed to the selected frag-
ment. Such an interface would mimic the typical
interaction between a human writer and human
critic ? e.g., the critic might highlight a para-
graph and advise the writer to reformat it as a list.
4 Deriving the rhetorical-semantic input
We have shown that by defining text-structuring
as a Constraint Satisfaction Problem, our method
allows considerable flexibility and precision in
controlling the generation of paraphrases (Power
et al, 2003). The question now is whether the
system can be extended so that it accepts a text as
input, rather than a formally encoded rhetorical-
semantic representation. Obviously the extended
system will require an extra component perform-
ing interpretation of the input text ? but how
much interpretation is needed in order to pro-
vide an encoding that the current ICONOCLAST
text-structurer can use? Can we extract suffi-
cient rhetorical and referential information to al-
low reasonable paraphrases, without depending
on a full semantic analysis of the original text?
In this section we consider three stages of inter-
pretation, which could be applied incrementally:
1. Rhetorical mark-up: The program marks
up the EDUs (Elementary Discourse Units)
(Marcu, 2000) in the input text ? what we
have been calling the elementary proposi-
tions ? and also identifies the rhetorical
relations among them, expressed through a
Rhetorical Structure Tree. Within EDUs
there is no mark-up: at this stage they are
treated as canned strings.
2. Coreference mark-up: The program identi-
fies noun-phrases referring to discourse en-
tities, and recognises chains referring to
the same entity. For each discourse entity,
enough semantic information is recovered to
allow a correct choice of pronoun (i.e., val-
ues are assigned to features like NUMBER,
GENDER, HUMAN), but no further semantic
analysis is assumed.
3. Clause transformations: The syntactic struc-
ture of each EDU is analysed sufficiently to
allow a reformulation that promotes a differ-
ent discourse entity as the most salient of the
clause (i.e., the Cp). Typically this would
mean a change of voice from active to pas-
sive, or vice-versa, although there might be
other variations like fronting that could be
explored.
We now discuss these stages in turn.
4.1 Recognising rhetorical structure
Maintaining the same example, suppose that the
input text is the following (a slight variation of
Solution 1):
Doctors recommend Elixir since it gives quick
results and has few side effects.
The goal at this stage is to interpret this text as
a set of elementary propositions, represented by
canned phrases, organised into a tree by rhetorical
relations. An example of the desired encoding, in
76
the format actually used as input to the current
system, is the following XML fragment:
<RhetRep relation=reason>
<SemRep prop="doctors recommend Elixir"/>
<RhetRep relation=conjunction>
<SemRep prop="it gives quick results"/>
<SemRep prop="it has few side-effects"/>
</RhetRep>
</RhetRep>
As can be seen, even though this representation
provides no analysis within propositions (EDUs),
the task of deriving the rhetorical structure and the
canned phrases is not trivial. First, the rhetorical
relations REASON and CONJUNCTION must be in-
ferred. Second, the correct tree structure must be
assigned, with REASON dominating CONJUNC-
TION. Third, the discourse connectives ?since?
and ?and? must be separated from the phrases
in which they occur ? the aim is that these
phrases should represent only the propositions.
Finally, where parts of a phrase have been elided
through aggregation (e.g., ?has few side-effects?),
the missing part (?it?) should be found and re-
placed.
If this level of interpretation is achieved, the
program will be able to generate several dozen
paraphrases, but referential continuity will be
poor unless we pose the additional constraint that
the order of propositions should remain the same
as in the original. Thus a successful paraphrase,
including some reformatting, would be the fol-
lowing:
Doctors recommend Elixir since:
? it gives quick results.
? it has few side effects.
However, with satellite preceding nucleus, as in
Solution 2, the text becomes incoherent because
the first mentions of Elixir are through a pronoun.
? It gives quick results.
? It has few side effects.
Therefore, doctors recommend Elixir.
4.2 Recognising coreference
Incoherence resulting from canned propositions
can be partly remedied if the analysis of the in-
put text is taken a stage further, by recognising
some simple semantic features on noun phrases,
and marking them up for coreference. The ele-
mentary propositions in our example could for in-
stance be marked up as follows:
<edu>
<np id=1 phrase="doctors"
class="human" number="plural"/>
recommend
<np id=2 phrase="Elixir"
class="thing" number="singular"/>
</edu>
<edu>
<pronoun id=2 phrase="it"/>
gives
<np id=3 phrase="quick results"
class="thing" number="plural"/>
</edu>
<edu>
<pronoun id=2 phrase="it"/>
has
<np id=4 phrase="few side-effects"
class="thing" number="plural"/>
</edu>
This further mark-up facilitates text-structuring in
two ways. First, since centering information is
now available (the Cb and Cp of each proposi-
tion can be computed), the evaluation of solu-
tions can take account of the centering prefer-
ences proposed by Kibble and Power (2004). Sec-
ondly, when realising individual propositions, the
referring expressions can be adapted to context,
perhaps by replacing a name/description with a
pronoun, or even eliding it altogether when two
propositions are aggregated. This means that the
program will be able to generate solutions such as
the following, in which the wordings of the propo-
sitions has been revised:
Since Elixir gives quick results and has few side-
effects, doctors recommend it.
This solution illustrates three ways in of revising
a proposition:
? Pronoun ? Name ?it gives quick results?
becomes ?Elixir gives quick results?.
? Elision ?it has few side-effects? becomes
?has few side-effects?.
? Name ? Pronoun ?doctors recommend
Elixir? becomes ?doctors recommend it?.
The generated paraphrases should now be more
fluent, but the program is still limited by its inabil-
ity to control the most salient referent in a propo-
sition (i.e., to modify the Cp). To add this op-
tion, we need the third level of interpretation men-
tioned above, in which the structure of a clause
can be transformed (e.g., from active to passive).
77
4.3 Clause transformations
Assuming that the analysis program can com-
pletely parse a clause identified as an EDU, it may
be able to apply a syntactic transformation which
expresses the same proposition with changed in-
formation focus. An obviously useful transforma-
tion is passivization ? or its opposite if the orig-
inal sentence is in the passive. Assuming that the
parser has correctly identified the main verb, and
that the program has access to a lexical database
including irregular morphology, it could derive
alternative formulations for the original proposi-
tions by a rule such as the following:
[NP1] recommends [NP2]?
[NP2] is recommended by [NP1]
Of course the program should not allow such
transformations for special verbs like ?be? and
?have?, so as to avoid clumsy renderings like ?few
side effects are had by Elixir?. However, when
used on an appropriate verb, passivization can im-
prove the fluency of the solution by promoting
the Cb of the proposition to the subject position,
so that it becomes the Cp; revisions of this kind
also provide more opportunities for favourable
pronominalization and elision. With this extra
resource, the solution just proposed can be im-
proved as follows:
Since Elixir gives quick results and has few side-
effects, it is recommended by doctors.
A more ambitious aim would be to transform be-
tween finite and reduced forms of a subordinate
clause. For instance, if the original text is ?De-
spite having few side-effects, Elixir is banned
by the FDA?, we could allow the transformation
of ?having few side-effects? into the finite clause
?Elixir has few side-effects, borrowing the subject
and tense from the main clause. This transforma-
tion would enable the system to generate a solu-
tion using a connective such as ?however? which
requires that full clauses are employed both for
the nucleus and the satellite. Alternatively, a fi-
nite clause could be transformed into the reduced
form, so allowing the connective ?despite?.
Conclusion
It is hard to conceive of an NLG system that
cannot produce alternative realisations, and thus
paraphrases. Most systems, however, are only
capable of producing variations at the lexical or
syntactic levels (or both). As such, they operate
very much like traditional Machine Translation
systems ? except that the source and target texts
are now in the same language ? and have similar
limitations. Additionally, most of them work with
input that is a representation of the meaning of a
(source) text, rather than the text itself.
The system described in this paper develops an
existing NLG system into a full-blown paraphase
generator capable of producing a wide range of
alternative renditions of the source text, with vari-
ations at three linguistic levels: lexical choice,
syntactic structure, and document structure. This
is in contrast to most existing paraphrase gener-
ators, which are constrained to vary only the first
or second of these levels (Barzilay and McKeown,
2001; Carroll et al, 1999; Dras, 1999; Inui and
Nogami, 2001; Kozlowski et al, 2003; Langkilde
and Knight, 1998; Takahashi et al, 2001; Stede,
1999). The range of lexical and syntactic varia-
tion in a paraphrase generator obviously depends
on how deeply the input text is interpreted, but
even with the relatively superficial analysis pro-
posed here, we can introduce variations for dis-
course connectives, referring expressions (in par-
ticular, when to use pronouns), and some clause
patterns (e.g., whether to use active or passive).
However, the innovation in our work lies in its
controlled variation in the third level, document
structure: just as the other paraphrase generators
provide multiple lexical-syntactic structures for
the same semantic structure, so our system pro-
vides multiple document structures for the same
discourse structure (i.e., for the same rhetori-
cal structure). The document structure solutions
serve not only to realise the rhetorical input, but
also to create a context that determines which of
the alternative syntactic realisations is most suit-
able for the elementary propositions.
Our paraphrase generator links an exist-
ing general-purpose discourse parser ? DAS
(Le Thanh et al, 2004)2 ? which builds a dis-
course tree automatically from an input text, to an
existing NLG system ?ICONOCLAST (Power
et al, 2003) ? which generates a wide range of
2Similar parsers have been developed by Marcu (2000)
and Corston-Oliver (1998)
78
formulations for a given discourse structure. We
have described here the issues that need to be
taken into account when turning any NLG sys-
tem into a fully-fledged paraphraser. We believe
that our approach to text-structuring, whereby op-
tions for organising propositions in a text are laid
out as a set of constraints, and acceptable solu-
tions are enumerated using constraint satisfaction
and evaluated using a cost metric, provides a par-
ticularly useful method for achieving large-scale
paraphrases. Although we are agnostic with re-
spect to the issue of psychological validity, it is
worth noting that our method reflects many of
the processes facing any writer or editor trying to
achieve their ideal text, but constrained by the lin-
guistic resources at hand (e.g., wording, syntax,
discourse and layout) which interact with each
other such that the final text is invariably a flawed
version of the ideal.
For evaluation of our system, two points need
to be addressed. The first concerns fidelity: are the
generated solutions equivalent in meaning to the
original input text? The second concerns qual-
ity: are the generated solutions ranked, by the
cost metric, in a way that corresponds to the pref-
erences of good judges? More practically, we
would like to explore the issue of usability: the
main question here is whether human users can
successfully manipulate the system?s constraints
and preferences in order to guide solutions in the
desired direction.
References
Regina Barzilay and Kathleen McKeown. 2001. Ex-
tracting paraphrases from a parallel corpus. In Pro-
ceedings of the 39th Annual Meeting of the Associ-
ation for Computational Linguistics, pages 50?57,
Toulouse.
J. Carroll, G. G. Minnen, D. Pearce, Y. Canning,
S. Devlin, and J. Tait. 1999. Simplifying text
for language-impaired readers. In Proceedings of
the 9th Conference of the European Chapter of the
Association for Computational Linguistics (EACL-
99), pages 269?270, Bergen, Norway.
S. Corston-Oliver. 1998. Computing Representations
of the Structure of Written Discourse. Ph.D. thesis,
University of California, Santa Barbara, CA, USA.
Mark Dras. 1999. Tree Adjoining Grammar and the
Reluctant Paraphrasing of Text. Ph.D. thesis, Mac-
quarie University, Australia.
Kentaro Inui and Masaru Nogami. 2001. A
paraphrase-based exploration of cohesiveness crite-
ria. In Proceedings of the 8th European Workshop
on Natural Language Generation (EWNLG-01).
Rodger Kibble and Richard Power. 2004. Optimising
referential coherence in text generation. Computa-
tional Linguistics, 30(4).
Raymond Kozlowski, Kathleen F. McCoy, and
K. Vijay-Shanker. 2003. Generation of single-
sentence paraphrases from predicate/argument
structure using lexico-grammatical resources. In
Proceedings of the Second International Workshop
on Paraphrasing, pages 1?8.
Irene Langkilde and Kevin Knight. 1998. Generation
that exploits corpus-based statistical knowledge. In
Proceedings of the 17th International Conference
on Computational Linguistics and the 36th Annual
Meeting of the Association for Computational Lin-
guistics (COLING-ACL98), pages 704?710, Mon-
treal.
H. Le Thanh, G. Abeysinghe, and C. Huyck. 2004.
Generating discourse structures for written texts.
In Proceedings of the 20th International Con-
ference on Computational Linguistics (COLING-
2004), pages 329?335.
W.C Mann and S.A. Thompson. 1983. Relational
propositions in discourse. Technical Report RR-83-
115, Information Sciences Institute.
D. Marcu. 2000. The theory and practice of dis-
course parsing and summarisation. MIT Press,
Cambridge, Massachusetts, USA.
Geoffrey Nunberg. 1990. The Linguistics of Punctu-
ation. CSLI Lecture Notes, No. 18. Center for the
Study of Language and Information, Stanford.
Richard Power and Donia Scott. 1998. Multilingual
authoring using feedback texts. In Proceedings of
17th International Conference on Computational
Linguistics and 36th Annual Meeting of the Associ-
ation for Computational Linguistics (COLING-ACL
98), pages 1053?1059, Montreal, Canada.
Richard Power, Donia Scott, and Nadjet Bouayad-
Agha. 2003. Document structure. Computational
Linguistics, 29(2):211?260.
Manfred Stede. 1999. Lexical semantics and knowl-
edge representation in multilingual text genera-
tion. Kluwer Academic Publishers, Boston.
Tetsuro Takahashi, Tomoyam Iwakura, Ryu Iida, At-
sushi Fujita, and Kentaro Inui. 2001. Kura: A
transfer- based lexico-structural paraphrasing en-
gine. In Proceedings of the Workshop on Automatic
Paraphrasing. (NLPRS 2001), Tokyo.
79
Reinterpretation of an existing?NLG system in a Generic Generation 
Architecture 
L. Cahill, C. Doran~ R. Evans, C. Meilish, D. Paiva,:M. Reape, D. Scott,, N. Tipper 
.Universities of Brighton and Edinburgh. 
Email rags@itri, brighton, ac. uk 
Abstract 
The RAGS project aims to define a reference ar- 
chitecture for Natural Language Generation (NLG) 
systems. Currently the major part of this archi- 
tecture consists of a set of datatype definitions for 
specifying the input and output formats for mod- 
ules within NLG systems. In this paper we describe 
our efforts to reinterpret an existing NLG system in 
terms of these definitions. The system chosen was 
the Caption Generation System. 
2. Which aspects of the RAGS repertoire would 
: . . . .  . . . .  - .... -,.= ., ~,~,aemaltybe'requireti~ftrr~strch~a-~reinterpretation; 
which would be unnecessary and which addi- 
tions to the RAGS repertoire would be moti- 
vated. 
1 Introduction 
The RAGS project ~ aims to define a reference ar- 
chitecture for natural anguage generation systems. 
Currently the major part of this architecture consists 
of a set of datatype definitions for specifying the 
input and output formats for modules within NLG 
systems. The intention is that such representations 
can be used to assist in reusability of components 
of NLG systems. System components that adhere 
to these representations, or use a format hat can be 
translated into such representations relatively eas- 
ily, can then, in principle, be substituted into other 
systems. Also, individual components could be de- 
veloped without the need for a complete system if 
datasets, based on the representations, were made 
available. 
In this paper we describe an attempt to reinterpret 
an existing NLG system in terms of the RAGS data 
definitions. The point of this exercise was to lem-n: 
1. Whether these data structures were sufficient 
to describe the input and output functionality 
of an existing, independently developed, ap- 
3. Whether studying the system would generate 
good ideas about possible reusable generation 
modules that could be developed. 
In this exercise it was important o choose a sys- 
tem that had been developed by people outside the 
RAGS project. Equally, it was important o have 
sufficient clear information about the system in the 
available literature, and/or by means of personal 
contact with the developers. The system chosen was 
the Caption Generation System (Mittal et al, 1995; 
Mittal et al, 1998) 3. This system was chosen be- 
cause, as well as fulfilling the criteria above, it ap- 
peared to be a relatively simple pipeline, thus avoid- 
ing complex control issues, with individual modules 
performing the varied linguistic tasks that the RAGS 
data structures had been designed to handle. 
The reinterpretation exercise took the form of 
coming up with an account of how the interfaces 
to the CGS modules corresponded to the RAGS 
model and reimplementing a working version of 
each module (apart from Text Planning and Realisa- 
tion) which was tested to ensure that, given appro- 
priate input, its output was correct (i.e. conforming 
to the global account) on key examples. Naturally, 
given the scope of this exercise, we had to gloss over 
some interesting implementational issues. The aim 
was not to produce a complete system or a system 
as good as CGS, but merely to demonstrate hat the 
broad functionality of the system could be repro- 
plied 2 NLG system. 
? Now at the MITRE Corporation, Bedford, MA, USA, 
cdoran.?mitre, org. 
tThis work was supported by ESPRC grants GR/L77041 
(Edinburgh) and GR/L77102 (Brighton), RAGS: Reference Ar- 
chitecture for Generation Systems. 
-'See (Paiva, 1998) for a definition of applied in this specific 
context. 
" . -ducedwithin:the RAGS .structures. 
In this paper we first describe the RAGS data 
structures. We then describe the CGS system 
3In addition to these published sources, we were greatly 
helped by the developers of the system who gave us the ben- 
efit of their own expertise as well as access to the original code 
of the system and a technical report hat included implementa- 
tional details such as system traces. 
69 
followed by our reinterpretation of the system in Abstract Rhetorical Abstract Rhetorical Repre- 
RAGS terms. Finally we discuss,, the :implications:. :. -._..sentations ,are--tree-structures with,rhetorical .rela- 
for RAGS of this exercise, tions at the internal nodes and Abstract Rhetorical 
2 The RAGS datatypes  
The RAGS project initially set out to develop a ref- 
erence architecture based on the three-stage pipeline 
suggested by Reiter (Reiter, 1994). However, a 
trees or Abstract Semantic Representations at the 
leaves. 
Rhetorical Abstract Rhetorical Representations 
are viewed as descriptions of sets of possible 
Rhetorical Representations. Each one may be trans- 
detailed analysis of existing applied NLG systems formed into some subset of the possible Rhetori- 
(Cahill and Reape~_~ l:998}:suggested~,that~ttch.an~ ar -~: ~<.eaLReprese, ntations by,,means ~ofa,set..o_f~.petmitted 
chitecture was not specific enough and not closely transformations, e.g. reversing the order of nucleus 
enough adhered to by the majority of the systems 
surveyed for this to be used as the basis of the archi- 
tecture. 
The abstract functionality of a generation system 
can be specified without specific reference to pro- 
cessing. The RAGS approach to this is to develop a 
data model, that is, to define the functional modules 
entirely in terms of the datatypes they manipulate 
and the operations they can perform on them. On 
top of such a model, more specific process models 
can be created in terms of constraints on the order 
and level of instantiation of different ypes of data in 
the data model. A 'rational reconstnaction' of some 
pipeline model might then be produced, but other 
process models would also be possible. 
The RAGS levels of representation are as fol- 
lows4: 
Conceptual The conceptual level of representa- 
tion is defined only indirectly through an API via 
which a knowledge base (providing the content 
from which generation takes place) can be viewed 
as if it were defined in a simple KL-ONE (Brach- 
man and Schmolze, 1985) like system. 
Abstract Semantic Abstract semantic representa- 
tions are the first level at which semantic predicates 
are associated with arguments. At this level, seman- 
tic predicates and roles are those used in the API to 
query the knowledge base and arguments are knowl- 
edge base entities. 
Semantic (Concrete) semantic representations 
provide a complete notation for "logical forms" 
where there is no longer any reference to ,the knowl- 
edge base. The representations are based on sys- 
tems such as SPL (Kasper, 1989) and DRT (Kamp 
and Reyle, 1993). 
4More details can be found in (Cahill et 
al., 1999) and at the RAGS project web site: 
ht tp  : / /www.  i t r i  . b r ighton ,  ac. uk/rags.  
and satellite or changing the rhetorical relation to 
one within a permitted set. 
Abstract Document Document structure defines 
the linear ordering of the constituents of the Rhetor- 
ical Representation with a POSITION feature, as 
well as two other features, TEXT-LEVEL, which 
takes values such as paragraph or sentence; and 
LAYOUT, which takes values such as wrapped-text 
and vertical list. It takes the form of a tree, usu- 
ally, but not necessarily, isomorphic to the Rhetor- 
ical Representation a d linked to it, but with these 
three features at the nodes instead of rhetorical rela- 
tions. 
Abstract Syntactic Abstract Syntactic Represen- 
tations capture high-level aspects of syntactic struc- 
ture in terms of notions such as lexical head, speci- 
fiers, modifiers and complements. This level of rep- 
resentation is compatible with approaches such as 
LFG f-structure, HPSG and Meteer's Text Structure. 
3 Partial and Mixed Representations 
For all of the RAGS levels partial representations 
are possible. Without this, it is not possible for a 
module to pass any result to another until that re- 
sult is completely determined, and this would im- 
pose an unwanted bias towards simple pipeline ar- 
chitectures into the model. There are many cases 
in NLG where a representation is built collabora- 
tively by several modules. For instance, many sys- 
tems have a referring expression generation module 
whose task is to complete a semantic representation 
which lacks those structures which will be realised 
as NPs. Such a functionality cannot be described 
unless partially complete semantic representations 
can be communicated. 
In addition, mixed representations are possible, 
where (possibly partial) representations at several 
levels are combined with explicit links between the 
elements. Many NLG modules have to be sensi- 
70 
tive to a number of levels at once (consider, for 
.......... instance, -aggregatiomxeferring,expmssion.,genera- 
tion and lexicalisation, all of which need to take 
into account rhetorical, semantic and syntactic on- 
straints). The input to most reusable realisation sys- 
tems is also best viewed as a mixture of semantic 
and abstract syntactic information. 
The extra flexibility of having partial and mixed 
representations turned out to be vital in the recon- 
struction of the CGS system. (Mellish et al, 2000). 
4 The CGS system 
The Caption Generation System (CGS) generates 
explanatory captions of graphical presentations (2- 
D charts and graphs). Its architecture is a pipeline 
with several modules, shown in the left hand part of 
Figure 1. An example of a diagram and its accom- 
panying text are given in Figure 2. The propositions 
are numbered for ease of reference throughout the 
paper. 
The input to CGS is a picture representation 
(graphical elements and its mapping from the data 
set) generated by SAGE plus its complexity metric. 
The text planning module (Moore and Paris (1993)) 
plans an explanation i  terms of high level discourse 
goals. The output of the planner is a partially or- 
dered plan with speech-acts as leaves. 
The ordering module receives as input the dis- 
course plan with links specifying the ordering re- 
lations between sub-trees and specifies an order for 
them based on heuristics uch as that the description 
should be done from left to right in the visual space. 
The aggregation module "only conjoins pairs of 
contiguous propositions about the same grapheme 
type 5 in the same space" (Mittai et al, 1999) and 
inserts cue phrases compatible with the propositions 
e o ( .=., "whereas" for contrastive ones). The internal 
order of the sentence constituents i determined by 
the centering module using an extension of the cen- 
tering theory of Grosz and colleagues (Grosz et al, 
1995). 
The referring expression module uses Date and 
Reiter's (Dale and Reiter, 1995) algorithm to con- 
struct the set of attributes that can uniquely identify 
a referent. There are'two, situations where the text 
planning module helps specifically in the generation 
of referring expressions: (1) when the complexity 
for expressing a graphic demands an example and 
5"Graphemes are the basic building blocks for constructing 
pictures. Marks, text, lines and bars are some of the different 
grapheme classes available in SAGE." (IVlittal et al, 1999). 
CGS architecture 
SAGE 
RAGS representations 
I I I  I I I  IV  V 
I II HI  IV  V 
? I I I  I I I  IV  " V . 
I I I  In  IV  v 
l -  .......... I /11  
1 It  I I I  IV V 
l -  .......... 
I 11 11I IV V 
.......... III1  
I I I  HI  IV  V 
; "  .......... I I I I I  
FUF 
Figure 1: A RAGS view of the CGS system. The 
labels for the RAGS representations refer to the fol- 
lowing: I = conceptual; II = semantic; III = rhetori- 
cal; IV = document; V = syntactic. 
it signals this both to SAGE (for highlighting the 
corresponding grapheme) and to the rest of the text 
generation modules; and (2) when in a specific sit- 
uation the referring algorithm would need several 
interactions for detecting that an entity is unique in 
? a certain visual space and.the planning could detect 
it in the construction of the description of this space. 
When this occurs, the text planner "circumvents he 
problem for the:.referring ,expression :module at the 
planning stage itself, processing the speech-acts ap- 
propriately to avoid this situation completely". 
After lexicalisation, which adds lexeme and ma- 
jor category information, the resulting functional 
descriptions are passed to the FUF/SURGE realiser 
that generates texts like the caption of Figure 2. 
71 
\ [ \ ]  
O 
te l  
O 
IZl 
ZS:3 
I21 ,:7-. ,,S . . . .  ; . . . .  .' ? 
O ~ ~Ipc~ q~L~ 
\] 
I 
\] 
=::::::;=a___.,____.__,_______~ 
. ,  , : ,  ; .  . ,  
Figure 2: (1) These two charts present information about house sales from data-set ts-1740. (2) In the two 
charts, the y-axis indicates the houses. (7) In the first chart, the left edge of the bar shows the house's elling 
price whereas (8) the right edge shows the asking price. (3) The horizontal position of the mark shows the 
agency estimate. (4) The color shows the neighbourhood and (5) shape shows the listing agency. (6) Size 
shows the number of rooms. (9) The second chart shows the number of days on the market. 
5 Reinterpretat ion f  CGS in RAGS 
Our reinterpretation f the CGS system defines the 
interfaces between the modules of CGS in terms 
of the RAGS data structures discussed above. In 
this section we discuss the input and output inter- 
faces for each CGS module in turn as well as any 
problems we encountered in mapping the structures 
into RAGS structures. Figure 1 shows the incre- 
mental build-up of the RAGS data levels across 
the pipeline. Here we have collapsed the Abstract 
Rhetorical and Rhetorical and the Abstract Seman- 
tic and Semantic. It is-interesting to note that the 
build up of levels of representation does not tend to 
correspond exactly with module boundaries. 
One of the major issues we faced in' our reinter- 
pretation was where to produce representations (or
partial representations) whose emergence was not 
defined clearly in the descriptions of CGS. For in- 
stance, many decisions about document structure 
are made only implicitly by the system. In most 
cases we have opted to produce all types of repre- 
sentations at the earliest point where they can con- 
ceivably have any content. This means, for instance, 
that our reimplementation assumes an (unimple- 
mented) text planner which produces an Abstract 
Rhetorical Representation with Abstract Semantic 
leaves and an Abstract Document Representation. 
Text Planner The input to the Longbow text plan- 
ner discussed in section 4 above is a representation 
of a picture in SAGE format (which has been an- 
notated to indicate the types of complexity of each 
grapheme) together with a goal, which can typi- 
cally be interpreted as "describe". It outputs an es- 
sentially fiat sequence of plan operators, each of 
which corresponds in the output? text .to .a.speech 
act. In our reinterpretation, we have assumed that 
this fiat structure needs to be translated into an Ab- 
stract Rhetorical Representation with (at least) min- 
imal structure. Such a structure is implicit in the 
plan steps, and our interpretation f the rhetorical 
structure for the example text corresponds closely to 
that of the post-processing trace produced by CGS. 
72 
I .AYOI  FII" * 'upped tel l  
" IU  ,I.EVIZL. p J t l~aph 
~ f ~ I O N :  2 
POSlllON I 
I.AYOtr'I+: -~pped tell 
TEX"T.L~ VEL 
(1) 
POSITION: I POSITION: 2 
LAYOUT: *T~,pl~n.l teat 
"IEXT-LEVEL: + 
(2) 
Po$ : I POSITION: 1 
LAYOUT: -mtpFcd te~t 
. TE.ICr-t.EVEL~ ?
0OSFI-K~N. 2 PosmoN: i 
POSIllON: I PosrnoN: I POsmoN. ~ FoSmON: 4 POSt'nON I PosrnoN: 2 
LAYOUT: ~pp~d lesl LAYOU'T. ~ppe,.f ~xt LAYO\[rF. ~apped lesl LAYOUT: ~+r~pS~d I?xt LAYOUT. ~'?~l~,Od ~est LAYOUT: ~Tappe~ text 
TEXT,LEVEL  7 "II~XT,LEVEI.: ~ "II~XT-LEVEL ? "I I~XT-LEVEL: ? TEXT-LEVEL  "+ TIE~XT-L.EVI:I.: ? 
(3) (4) (5) (6) (7) (8) 
Figure 3: Initial Document Structure 
. . .Z., 
However, we are still not entirely sure 
exactly CGS creates this structure, so 
posed it at the very beginning, onto the 
text planner. 
Already at this stage it is necessary 
about where 
we have im- 
output of the 
to make use 
of mixed RAGS representations. As well as this 
Abstract Rhetorical Representation, the text planner 
has to produce an Abstract Document Representa- 
tion, linked to the Abstract Rhetorical Representa- 
tion. This is already partially ordered - although the 
exact value of POSITION features cannot be speci- 
fied at this stage, the document tree is constructed 
so that propositions are already grouped together. 
In addition, we make explicit certain default infor- 
mation that the CGS leaves implicit at this stage, 
namely, that the LAYOUT feature is always wrapped 
text and that the TEXT-LEVEL feature of the top 
node is always paragraph. 
Ordering The ordering module takes the Abstract 
Document Representation a d the Abstract Rhetor- 
ical Representation as input and outputs an Abstract 
Document Representation with the POSITION fea- 
ture 's  value filled,for all :the nodes, .That is, it fixes. ? 
the linear order of the final output of the speech acts. 
In our example, the ordering is changed so that steps 
7 and 8 are promoted to appear before 3, 4, 5 and 6. 
The resulting structure is shown in figure 36 . 
6In this and the.following diagrams, objects are represented 
by circles with (labelled) arrows indicating the relations be-- 
Aggregation Although aggregation might seem 
like a self-contained process within NLG, in prac- 
tice it can make changes at a number of levels of 
representation a d indeed it may be the last opera- 
tion that has an effect on several levels. The aggre- 
gation module in our reinterpretation thus has the fi- 
nal responsibility to convert an Abstract Rhetorical 
Representation with Abstract Semantic Represen- 
tation leaves into a Rhetorical Representation with 
Semantic Representation leaves. The new Rhetori- 
cal Representation may be different from before as 
a result of speech acts being aggregated but whether 
different or not, it can now be considered final as 
it will no longer be changed by the system. The 
resulting Semantic Representations are no longer 
Abstract because further structure may have been 
determined for arguments to predicates. On the 
other hand, referring expressions have not yet been 
generated and so the (Concrete) Semantic Repre- 
sentations cannot be complete. The reconstruc- 
,.tion createspartia.i Semantic Representations with 
"holes" where the referring expressions (Semantic 
Representations) will be inserted. These "holes" are 
linked back to the knowledge base entities tfiat they 
correspond to. 
Because Aggregation affects text levels, it also af- 
fects the Abstract Document Representation, which 
has its TEXT-LEVEL feature's values all filled at this 
tween them. Dashed arrows indicate links between different 
levels of representation. 
73 
SemRep 
fun(Role,SemRep) 
DR preS  , . mRep 
? AbsSynRep ~ AbsSynRe~ 
/ " \  Y^.Z(" 
FVM (~ ~ ,un(Funs,~gS~c) (,~ ~M (~) lun(Funs.ArgSpec) 
0 ~ 0 0 
? + 
Adjs 
. . - ; . .  
Figure 4: Syntactic representations constructed by Centering 
point. It may also need to change the structure 
of the Abstract Document Representation, for in- 
stance, adding in a node for a sentence above two, 
now aggregated, clause nodes. 
Centering Because Centering comes before Re- 
ferring Expression generation and Realisation, all it 
can do is establish constraints that must be heeded 
by the later modules. At one stage, it seemed as if 
this required communicating a kind of information 
that was not covered by the RAGS datatypes. How- 
ever, the fact that an NP corresponds (or not) to a 
center of some kind can be regarded as a kind of 
abstract syntactic information. The reconstruction 
therefore has the centering module building a partial 
(unconnected) Abstract Syntactic representation for 
each Semantic Representation that will be realised 
as an NP, inserting a feature that specifies whether 
it constitutes a forward- or backward-facing cen- 
ter, approximately following Grosz et al(Grosz et 
al., 1995). This information is used to determine 
whether active or passive voice will be used. An 
example of such a partial Abstract Syntactic Repre- 
sentation is given in Figure 4. 
Referring Expression In our reconstruction of 
the CGS system, we have deviated from reproduc- 
ing the exact functionality for the referring expres- 
sion module and part of the lexical choice module. 
In the CGS system, the referring expression module 
computes association lists which can be used by the 
lexical choice module to construct referring expres- 
sions suitable for realisation. In our reconstruction, 
however, the referring expression module directly 
computes the Semantic Representations of referring 
expressions. 
We believe that this is a good example of a 
case where developing a system with the RAGS 
data structures in mind simplifies the task. There 
are undoubtedly many different ways in which the 
same results could be achieved, and there are many 
(linguistic, engineering etc.) reasons for choosing 
one rather than another. Our particular choice is 
driven by the desire for conceptual simplicity, rather 
than any strictly linguistic or computational motiva- 
tions. We considered for each module which RAGS 
level(s) it contributed to and then implemented it to 
manipulate that (or those) level(s). In this case, that 
meant a much more conceptually simple module 
which just adds information to the Semantic Rep- 
resentations. 
Lexical Choice In CGS, this module performs a 
range of tasks, including what we might call the 
later.stages of_referring expression generation and 
lexical choice, before converting the plan leaves 
into FDs (Functional Descriptions), which serve as 
the input to the FUF/SURGE module. In the re- 
construction, on the other hand, referring expres- 
sions have already been computed and the Rhetor- 
ical Representation, with its now complete Seman- 
tic Representations, needs to be "lexicalised" and 
74 
' ,t ~1  
" .  set 
Figure 5: Combined Semantic and Abstract Syntactic Representation 
translated into FUF/SURGE format. Lexicalisa- 
tion in our terms involves adding the lexeme and 
major category information to the Abstract Syntac- 
tic Representations for the semantic predicates in 
each Semantic Representation. The FUF/SURGE 
input format was regarded as a combination of Se- 
mantic and Abstract Syntactic information, and this 
can easily be produced from the RAGS representa- 
tions. The combined Semantic and Abstract Syn- 
tactic Representations for the plan step "These two 
charts present information about house sales from 
data set ts-1740" is shown in Figure 5. The boxes 
indicate suppressed subgraphs of the lexemes cor- 
responding to the word in the boxes and triangles 
indicate suppressed subgraphs of the two adjuncts. 
6 Conclusions 
The reconstruction of CGS has taken the form of 
working out in detail the RAGS representations 
passed between modules at each stage for a set 
of key examples and reimplementing the modules 
(apart from the Planner and Realiser) in a way that 
correctly reproduces these representations. The ac- 
tual implementation used an incrementally growing 
data store for the RAGS representations which the 
modules accessed in turn, though the passing of data 
could also have been achieved in other ways. 
The fact that the reconstruction has been success- 
ful indicates that the RAGS architecture is broadly 
adequate to redescribe this NLG system: 
? No changes to the existing levels of represen- 
tation were needed, though it was necessary to 
make extensive use of partial and mixed repre- 
sentations. 
o No new levels of representation needed to be 
introduced to capture the inter-module com- 
munication of the system. 
o All of the levels of representation_apart from 
the Conceptual level were used significantly in
the reconstruction. 
In some ways, i t  is unfortunate that none of the 
inter-module interfaces of CGS turned out to use a 
single level of RAGS representation. Given the mo- 
tivation for partial and mixed representations above, 
however, this did not really come as a surprise. It 
may well be that any really useful reusable modules 
for NLG will have to have this complexity. 
75 
In spite of the successful testing of the RAGS data 
model, somedifficulties were encountered: 
* It was difficult to determine the exact nature 
of the representations produced by the Planner, 
though in the end we were able to develop a 
system to automatically translate these into a 
format we could deal with. 
o Although the theoretical model o f  CGS has a 
simple modular structure, in practice the mod- 
ules are very tightly inte-gr~ifed and making-the " 
exact interfaces explicit was not always easy. 
? Referring expression generation requires fur- 
ther access to the "knowledge base" holding 
information about he graphic to be produced. 
This knowledge was only available via interac- 
tions with SAGE, and so it was not possible to 
determine whether the RAGS view of Concep- 
tual Representations was applicable. Our own 
implementation f referring expression gener- 
ation had to work around this problem in a non- 
portable way. 
? It became clear that there are many housekeep- 
ing tasks that an NLG system must perform 
following Lexical Choice in order for the final 
Semantic and Abstract Syntactic Representa- 
tions to be appropriate for direct input to a re- 
alisation system such as FUF. 
o The fact that the system was driving 
FUF/SURGE seems to have had a signif- 
icant effect on the internal representations 
used by CGS. The reconstruction echoed this 
and as a result may not be as general as could 
be desired. 
? Even though CGS only performs imple types 
of Aggregation, it is clear that this is a critical 
module for determining the final form of sev- 
eral levels of representation. 
The division of CGS into modules is different from 
that used in any NLG systems we have previously 
worked on and so has been a useful stimulus to think 
about ways in which reusable modules can be de- 
signed. We envisage reusmgat  least,the reimple- 
mentation of the Centering module in our further 
work. 
References 
R. Brachman and J. Schmolze. 1985. An overview of the KL- 
ONE knowledge representation system. Cognitive Science, 
9:171-216. 
Lynne Cahill and Mike Reape. 1998. Component asks 
in applied NLG .systems . . . .  Technical Report ITR!- 
99-05, ITRI, University of Brighton. obtainable at 
http:/lwww.itri.brighton.ac.uk/projects/rags/. 
Lynne Cahill, Christy Doran, Roger Evans, Chris Mellish, 
Daniel Paiva, Mike Reape, Donia Scott, and Neil Tipper. 
1999. In Search of a Reference Architecture for NLG Sys- 
tems. In Proceedings of the 7th European Workshop on Nat- 
ural Language Generation, pages 77-85, Toulouse. 
Robert Dale and Ehud Reiter. 1995. Computational interpre- 
tations of the Gricean maxims in the generation ofreferring 
expressions. Cognitive Science, 18:233-263. 
B J .  Grosz, A/K.J6shil-and S.Weinstein. 1995~ Centering: a 
framework for modelling the local coherence of discourse. 
Computational Linguistics, 21 (2):203-226. 
H. Kamp and U. Reyle. 1993. From discourse to logic: Intro- 
duction to model theoretic semantics of natural language, 
formal logic and discourse representation theory. Kluwer, 
Dordrecht; London. 
R. T. Kasper. 1989. A flexible interface for linking applica- 
tions to penman's sentence generator. In Proceedings of the 
DARPA Speech and Natural Language Workshop, Philadel- 
phia. 
C. Mellish, R. Evans, L. Cahill, C. Doran, D. Paiva, M. Reape, 
D. Scott, and N. Tipper. 2000. A representation forcomplex 
and evolving data dependencies in generation. In Proceed- 
ings of the Applied Natural Language Processing (ANLP- 
NAACL2000) Conference, Seattle. 
V. O. Mittal, S. Roth, J. D. Moore, J. Mattis, and G. Carenini. 
1995. Generating explanatory captions for information 
graphics. In Proceedings of the 15th International Joint 
Conference on Artificial Intelligence (IJCAI'95), pages 
1276-1283, Montreal, Canada, August. 
V. O. Mittal, J. D. Moore, G. Carenini, and S. Roth. 1998. 
Describing complex charts in natural anguage: A caption 
generation system. Computational Linguistics, 24(3):431- 
468. 
Daniel Paiva. 1998. A survey of applied natural lan- 
guage generation systems. Technical Report ITRI- 
98-03, Information Technology Research Insti- 
tute (ITRI), University of Brighton. Available at 
http://www.itri.brighton.ac.uk/techreports. 
Ehud Reiter. 1994. Has a consensus NL generation architec- 
ture appeared and is it psycholinguistically p ausible? In 
Proceedings of the Seventh International Workshop on Nat- 
ural Language Generation, pages 163-170, Kennebunkport, 
Maine. 
Acknowledgements 
We would like to thank the numerous people who have 
helped us in this work. The developers of CGS, especially 
Giuseppe Carenini and Vibhu Mittal; the RAGS consultants 
and other colleagues at Brighton and Edinburgh, who have con- 
tributed greatly to our development ofthe representations; and 
finally to the anonymous reviewers of this paper. 
76 
Composing Questions through
Conceptual Authoring
Catalina Hallett?
The Open University
Richard Power?
The Open University
Donia Scott?
The Open University
This article describes a method for composing fluent and complex natural language ques-
tions, while avoiding the standard pitfalls of free text queries. The method, based on Conceptual
Authoring, is targeted at question-answering systems where reliability and transparency
are critical, and where users cannot be expected to undergo extensive training in question
composition. This scenario is found in most corporate domains, especially in applications that
are risk-averse. We present a proof-of-concept system we have developed: a question-answering
interface to a large repository of medical histories in the area of cancer. We show that the method
allows users to successfully and reliably compose complex queries with minimal training.
1. Introduction
Where early attempts to build natural language question-answering systems focused on
accessing and presenting information held in (closed domain) databases (e.g., Hendrix
et al 1978; Templeton and Burger 1983; Kaplan 1984; Hafner and Godden 1985), the
advent of the World Wide Web has led to a shift towards (open domain) collections
of texts. However, despite significant advances in open domain question answering
since the simple pattern-matching systems of the first TREC competition in 1999,
current systems are still largely restricted to simple questions. They can, for example,
successfully find answers to questions like Which is the highest peak in Africa? or Who first
climbed Kilimanjaro? but they cannot correctly answer more complex questions like:
What is the median height of the top twelve highest peaks in Africa?
Which explorer who climbed Kilimanjaro but not Everest between 1960 and 1995 died in the last
three years before the age of 55?
How many of the explorers who climbed Kilimanjaro but not Everest between 1960 and 1995
did so more than three times during that period?
? Department of Computing, The Open University, Walton Hall, Milton Keynes, Buckinghamshire,
MK7 6AA, UK. E-mail: D.Scott@open.ac.uk; C.Hallett@open.ac.uk; R.Power@open.ac.uk.
The research presented here was supported in part by Medical Research Council grant G0100852
under the e-Science GRID Initiative. Special thanks are due our colleagues on CLEF (Alan Rector,
Jeremy Rogers, and James McKay) and to the CLEF clinical collaborators at the Royal Marsden and
Royal Free hospitals?see www.clinical-escience.org.
Submission received: 17 July 2005; revised submission received: 3 May 2006; accepted for publication:
28 July 2006.
? 2007 Association for Computational Linguistics
Computational Linguistics Volume 33, Number 1
There are many reasons why such queries are unlikely to be successful. For example,
although the first question is very simple to interpret, a correct answer is unlikely to be
available (in a retrievable form) in any individual document in the target collection.
A question-answering system would thus have to first retrieve the heights of each
of the top twelve highest peaks, probably from different documents, and apply some
calculations to obtain their median height, and then generate a response that aggregates
answers from multiple documents. The answer to the second question, on the other
hand, is very simple and likely to be found in a small number of documents, but
the question itself is not trivial to interpret and would require (among other things)
resolving the temporal information, correctly assuming that 55 refers to age at the time
of death, and interpreting the negation but not as referring to the climbing of Everest
only within the specified time span. For the third question, the difficulty comes from
a combination of complex question and complex answer. Retrieving aggregated results
from the World Wide Web also introduces issues of reliability because the sources may
not all be trusted, and there is no guarantee that a different selection of sources would
not yield a contrary result.
For many applications of question answering, the need for complex questions
and trusted answers is paramount?for example, in the medical, legal, and financial
domains, or indeed in any research area?and it is to this scenario that the work we
present here applies. Our goal is to develop a general and intuitive method by which
users can pose complex queries to data repositories; we are particularly concerned
with scenarios where the users are domain experts (i.e., clinicians, lawyers, financiers,
etc.) rather than database experts, where reliability of the answer is critical, where
the method of posing questions should be easy to learn, and where the questions
themselves should be transparent (i.e., clear and unambiguous) to both user and
system.
Current methods for querying databases typically make use of formal query
languages such as SQL. These languages are highly technical and require a great deal
of training to achieve the level of proficiency required to pose the kinds of complex
queries shown in the previous example. Successful query composition requires the user
to be proficient in the query language and have detailed knowledge of the structure
of the database to which the queries are being addressed. Users also need to be
fluent in any formal codes employed to refer to entities in the domain (e.g., disease
classifications, laws, bank codes). For example, in the medical domain alone there are a
large number of clinical terminologies and classifications, used for different purposes:
Some classifications, such as ICD-9, ICD-10, and OPCS-4, are employed in summarizing
the incidence of diseases and operations on a national or worldwide level; others,
such as CPT4 or ICD-9CM, manage the process of billing patients. Each covers a large
number of terms and associated codes: SNOMED-CT alone, to name the most widely
used medical terminology, currently contains some 365,000 individual concepts, and is
being updated continuously (College of American Pathologists 2004). Finally, because
database languages are not transparent, mistakes in query formulation can be difficult
to spot; so even where the system itself may be highly reliable, there is a reasonable
chance that?except for very highly experienced database programmers?the returned
answer may not be an accurate response to the intended question.
A well-known alternative to formal database languages is available in visual query
systems, which make use of graphical devices such as forms, diagrams, menus, and
pointers to communicate the content of a database to the user. They are also widely
used in commercial applications, and research shows that they are much preferred over
textual query languages like SQL, especially by casual and non-expert users (Capindale
106
Hallett, Scott, and Power Composing Questions through Conceptual Authoring
and Crawford 1990; Bell and Rowe 1992; Catarci and Santucci 1995). However, visual
interfaces are also problematic: empirical studies report high error rates by domain
experts using visual object-oriented modeling tools (Kim 1990), and a clear advantage
of text over graphics for understanding nested conditional structures (Petre 1995).
Natural language clearly provides a more intuitive means for users to pose their
questions, but this is also highly problematic because queries expressed in free natural
language are obviously very sensitive to errors of composition (e.g., misspellings,
ungrammaticalities) or processing (at the lexical, syntactic, or semantic level).
2. Natural Language Interfaces
In a typical natural language interface to a database (henceforth NLIDB), the user
requests database records through a query expressed in natural language. The ques-
tion is first parsed and analyzed semantically by a linguistic front-end, which trans-
lates it into an intermediate meaning representation language (typically, some form
of logic). The intermediate language expression is then translated into a database
language (usually SQL) that is supported by the underlying database management
system.
A large number of NLIDBs have been developed in the past 30 years, featuring a
wide range of techniques. The general drawback of these systems1 is that they normally
understand only a subset of natural language. Casual users cannot always discern
which constructions are valid or whether the lack of response from the system is due to
the unavailability of an answer or to an unaccepted input construction. On the positive
side, natural language is far more expressive than formal database query languages
such as SQL, so it is generally easier to ask complex questions using natural language
(NL) than a database language (a single natural language query will have to be trans-
lated into multiple SQL statements). Natural language queries are not only more user-
friendly for the non-expert user, but they also allow easier manipulation of temporal
constructions.
Broadly, research in NLIDBs has addressed the following issues:2
 domain knowledge acquisition (Frank et al 2005)
 interpretation of the NL input query, including parsing and semantic
disambiguation, semantic interpretation, and transformation of the query
to an intermediate logical form (Hendrix et al 1978; Zhang et al 1999;
Tang and Mooney 2001; Popescu, Etzioni, and Kautz 2003; Kate, Wong,
and Mooney 2005)
 translation to a database query language (Lowden et al 1991;
Androutsopoulos 1992)
 portability (Templeton and Burger 1983; Kaplan 1984; Hafner and Godden
1985; Androutsopoulos, Ritchie, and Thanitsch 1993; Popescu, Etzioni, and
Kautz 2003)
1 Leaving aside here the possibility of errors in parsing and interpretation.
2 The extent of NLIDBs research is such that it is beyond the scope of this article to reference a
comprehensive list of projects in this area. For a critical review of various NLIDBs, the reader is
referred to Androutsopoulos, Ritchie, and Thanisch (1995).
107
Computational Linguistics Volume 33, Number 1
In order to recover from errors in any of these steps, most advanced NLIDB systems also
incorporate some sort of cooperative user feedback module that will inform users when
the system cannot construct their query, and ask for clarification.
2.1 Our Solution: A Quasi-NL Interface
The solution that we propose partially overlaps with previous research in NLIDBs, in
that a logical representation is constructed using a NL interface, and then mapped
into the database query language. The difference lies in the nature of the NL interface,
which in our case uses a method that we call Conceptual Authoring; this replaces the
traditional method of free text entry followed by automatic interpretation.
There are two key ideas to Conceptual Authoring. The first (captured by ?Con-
ceptual?) is that all editing operations are defined directly on an underlying logical
representation, governed by a predefined ontology. Instead of typing in text, the user
builds the logical representation directly, so no problem of interpretation arises. The
second key idea (captured by ?Authoring?) is that the user interface presents the
developing logical representation, and the options for editing it, in a way that is
transparent to users?namely, natural language text, possibly supplemented by other
familiar media; users therefore feel that they are performing a familiar activity, a kind
of guided writing, rather than an unfamiliar activity akin to programming.
In general, then, Conceptual Authoring requires that some kind of formal knowl-
edge encoding is edited by direct manipulation of a familiar presentation, the presen-
tation being generated automatically from the underlying knowledge encoding, and
updated every time knowledge is added (or removed) through an editing operation.
The user need not be aware of the underlying formalism any more than a person using
a text editor need be aware of ASCII codes. Conceptual Authoring therefore depends
entirely on language generation technology; it does not use language interpretation
at all.
Various applications of Conceptual Authoring are possible, depending on the
nature of the underlying knowledge and the presentational medium. In the query
editor described in this article, the underlying knowledge is a set of assertions (i.e., an
A-box), and the presentational medium is natural language text. Elsewhere, we have
used the term WYSIWYM (What You See Is What You Meant) for various systems of this
kind that we have developed (Power and Scott 1998): as well as query interfaces they
include programs that generate technical documentation in multiple languages. We use
?Conceptual Authoring? as a more general term that would also cover applications in
which the underlying knowledge included conceptual definitions and rules as well as
assertions, and the presentation medium included diagrams as well as text?provided,
of course, that the diagrams were familiar to the relevant subject-matter experts (e.g., a
molecular structure diagram if the user were an organic chemist).
The basic idea of Conceptual Authoring is that a special kind of natural language
text is generated in order to present successive states of the underlying logical
representation. This text includes generic phrases, called ?place-holders?, which mark
attributes that currently have no value. Place-holders serve as the locations where new
objects may be added. By opening a pop-up menu on a place-holder, the user obtains
a list of short (generated) phrases describing the types of objects that are permissible
values of the attribute; when one of these options is selected, a new object of the
specified type is added. New text is then generated to present the modified logical
representation, including the attributes of the new object. As more information is added
108
Hallett, Scott, and Power Composing Questions through Conceptual Authoring
about an object, it will be presented by longer spans of text, comprising sentences or
perhaps even paragraphs. These spans of text are also mouse-sensitive, so that the
associated semantic material can be cut or copied. The cutting operation removes the
logical fragment that was previously the value of an attribute, and stores it in a buffer,
where it remains available for pasting into another suitable location. The text associated
with the fragment may or may not remain the same, depending on the context of the
new location.
As an illustration, suppose that the user wishes to define an event that might
naturally be expressed by the sentence The doctor examined the patient with a stethoscope.
The underlying logical structure could be an event object of type examined, with
attributes for actor, actee, and instrument; this will of course be only one among
many events allowed by the ontology. To define this content using a Conceptual
Authoring interface, the user begins from a text containing a place-holder for any kind
of event. By clicking on this place-holder, the user obtains a list of event patterns, each
shown as a short phrase corresponding to a specific event type from the ontology:
FEEDBACK TEXT
[Some event]
MENU OF OPTIONS
.....
consulted
examined
treated
visited
.....
When the user selects examined from this list, an event object of type examined is added
to the underlying semantic model, and the feedback text is regenerated to express the
new event and its attributes (as yet unspecified), which are shown by short phrases in
square brackets (the place-holders). A color code on place-holders indicates whether
an attribute is obligatory (it must be specified) or optional (it can be left unspecified);
here for convenience we use boldface for obligatory, and italics for optional. By clicking
on a place-holder, say the first, the user can now obtain options for specifying the
corresponding attribute (in this case the actor).
FEEDBACK TEXT
[Some person] examined [some person] [in some way]
MENU OF OPTIONS
.....
doctor
nurse
patient
.....
109
Computational Linguistics Volume 33, Number 1
By making successive choices in this way, the user will complete the desired proposi-
tion, perhaps through the following sequence:
[Some event].
[Some person] examined [some person] [in some way].
The doctor examined [some person] [in some way].
The doctor examined the patient [in some way].
The doctor examined the patient by using a stethoscope.
Note that because the feedback text is always generated by the system, we can try to
design feedback texts in a way that minimizes ambiguity. We might, for instance, prefer
to avoid the more natural phrase ?with a stethoscope?, which introduces the well-known
PP-attachment ambiguity, in favor of the slightly clumsy but unambiguous alternative
employed herein.
As well as introducing new objects on place-holders, the user can select a span
representing a filled slot and perform Cut or Copy. For instance, from the feedback
sentence reached in the last example, the user could select the span ?the patient? and
choose Cut, thus emptying the slot and reinstalling the place-holder:
The doctor examined [some person] by using a stethoscope.
Having freed up the slot in this way, the user might next select ?The doctor?, choose
Copy, select the place-holder ?[some person]?, and choose Paste. The Copy operation
here applies to the actual instance selected: It does not create a new instance of the same
type. Therefore, after the Paste operation, the doctor instance fills two slots, both the
actor and the actee of the event. The resulting coreference is shown by the wording of
the feedback text:
The doctor examined himself by using a stethoscope.
Conceptual Authoring (or WYSIWYM) has been applied as a tool for creating
knowledge content for multilingual generation of instruction manuals (Power and Scott
1998; Power, Scott, and Evans 1998; Scott, Power, and Evans 1998) and pharmaceutical
leaflets (Bouayad-Agha et al 2002). It has also been applied in a tool for posing queries
to a knowledge base of legal and regulatory information about maritime shipping
(Piwek et al 2000; Piwek 2002; Evans et al in press). In some ways the interface
resembles early menu-based techniques like Tennant, Ross, and Thompson (1983) and
Mueckstein (1985); however, this resemblance is only superficial, because in these
techniques the user edits a linguistic structure, whereas in Conceptual Authoring all
editing operations are defined on an underlying logical structure.
3. A Test Application: Electronic Health Records
Typically, an individual?s medical record is a collection of documents held in his or her
doctor?s office; most people will also have other records held at other sites, such as
110
Hallett, Scott, and Power Composing Questions through Conceptual Authoring
hospitals or clinics they have attended, or specialists they have seen. These records are
primarily textual, and the record of the average hospital patient will consist of a large
number of documents?around 100 narratives, plus hundreds of items of structured
data derived from laboratory, pharmacy, or other hospital subsystems. There is a
significant move?not just by medical providers, but by governments (e.g., the National
Programme for Information Technology in Medicine [NPfIT] in the UK, and various
e-Health initiatives in other countries)?to replace or supplement the current form of
patient records with electronic records; these are intended to be not simply electronic
text files of the existing records, but collections of ?messages? held in databases and
accessible at the point of care. One of the disadvantages of text-only health records is
that the information contained within them, because it is ?locked into? the text, is not
available for statistical manipulation and cannot be easily interrogated.
Previous studies (Gorman and Helfand 1995; Ely et al 2000; Jerome et al 2001;
Estrella et al 2004; Koonce, Giuse, and Todd 2004), as well as our own preliminary
analysis, show that free text queries written by medical professionals are mostly
complex and often highly ambiguous. From this we conclude that when querying
medical databases, such users need to be able to construct queries that are complex,
both in volume of material and in the organization of this material (e.g., into temporal
or conditional constructions). Traditionally, user interfaces to medical databases have
been complex visual interfaces that are unsuitable for use by a casual user (Nadkarni
and Brandt 1998; Shahar and Cheng 1999).
Electronic health records provide a good example of the kind of application
for which question-answering systems are required for accessing large collections of
trusted closed-domain data. Not only is there a requirement for complex queries of
the sort that are extremely difficult to achieve in current natural language question-
answering systems but, for obvious reasons, the veracity of the results of any query is
critical, making it doubly important that queries put to the system, and their resulting
responses, are unambiguous and clearly understandable to the user. Because the users
will be medical professionals, with great demands on their time, the ease of use
of the question-answering system is also extremely important. We have applied our
Conceptual Authoring question-answering method to one such application: the Clinical
E-Science Framework (CLEF).
3.1 The Clinical E-Science Framework
The Clinical E-Science Framework (CLEF) aims at providing a repository of well-
organized clinical histories that can be queried and summarized both for biomedical
research and clinical care (Rector et al 2003). In this context, the purpose of the query
interface is to provide efficient access to aggregated data for performing a variety of
tasks: assisting in diagnosis or treatment, identifying patterns in treatment, selecting
subjects for clinical trials, and monitoring the participants in clinical trials. Although
the CLEF architecture is largely independent of any particular area of medicine, it is
currently being applied to cancer, in collaboration with the Royal Marsden Hospital in
London, one of the primary centers for the treatment of cancer in Britain.
The current CLEF database repository contains 22,500 patient records,3 containing
a total of more than 400,000 database entries, some 3.5 million record components
3 At present, the repository contains records of deceased patients only. In the near future, it will grow
significantly with the addition of live patient records.
111
Computational Linguistics Volume 33, Number 1
and more than 5 gigabytes of data, implemented as a relational database that stores
patient records modeled on an archetype for cancer developed by Kalra et al (2001).
The information on each patient comes from hundreds of documents, and a single care
episode or clinical problem is likely to be mentioned repeatedly in several documents.
Within CLEF, a patient record is organized as a collection of individual entries, each
entry representing an instance of the cancer archetype.
3.2 Users and Extent
The CLEF query system is designed to answer questions relating to patterns in medical
histories over sets of patients in the repository. At this point, the system supports
attribute-centric queries asking for aggregated results, such as:
{Absolute count/percentage/statistical measure} of patients with certain characteristics.
The answers to such queries can be produced by simple interrogation of the
database, because they do not require inferences over the repository of patient records.
However, the query interface is also coupled with a data-mining module to provide
answers to more complex queries, such as
Given certain conditions, what is the treatment with the highest chance of success for a patient
with certain characteristics?
The query interface can also be used for accessing information about individual
patients.
The interface is designed for casual and moderate users who are familiar with the
semantic domain of the repository (but not with its actual structure or encoding) and
who require queries of little variance but with relatively high structural complexity.
Under this description come three primary types of users, each having a different goal
in interrogating the repository:
 clinicians, who use it for assisting in diagnosis or treatment
 medical researchers, who use it for identifying patterns in treatment,
selecting subjects for clinical trials, or monitoring the participants in
clinical trials
 hospital administrators, who use it for collecting information about
patterns of treatment, frequency of tests, hospital admissions, and so on
Among these, we expect those users with little or no knowledge of formal database
languages (e.g., SQL) to be the main beneficiaries of the query interface, although in the
Evaluation (Section 6) we will show that even for SQL-aware users, the query interface
represents an improved alternative to standard SQL. We also target the interface at users
who are unfamiliar with medical encoding schemes, such as SNOMED or ICD, or who
prefer to use natural language expressions instead of medical codes.
3.3 Previous Work on Querying Clinical Databases
There are a number of query systems for clinical databases, mostly designed for
formulating patient-centric queries and typically using visual interfaces. For example:
112
Hallett, Scott, and Power Composing Questions through Conceptual Authoring
Figure 1
Architecture of the CLEF query interface.
The Columbia-Presbyterian Medical Center Query Builder works off the medical
center?s data repository and generates both HL7 and Arden Syntax4 for several
categories of data; for example, patient demographics, laboratory values, medi-
cations, and diagnoses (Wilcox, Hripcsak, and Chen 1997). The user interface is a
simple HTML-based application that allows users to select the type of data they
want to query and to specify constraints on it.
TrialDB (formerly ACT/DB) is a clinical study data management system that provides
a complex visual interface for formulating attribute-centric temporal queries
(Nadkarni and Brandt 1998; Deshpande, Brandt, and Nadkarni 2001, 2003). The
interface allows for attributes to be searched and selected by specifying key words
or part of the attribute name/caption. Once an attribute is selected, the user may
optionally specify that an aggregate value for that attribute be returned. Searching
criteria can be combined using boolean operators.
KNAVE is a visualization and navigation model that enables clinicians to query a specific
patient record for time-oriented raw data, external interventions, abstractions, and
temporal patterns, and to visualize the results of the temporal query (Shahar and
Cheng 1999).
Natural language query interfaces have been used far less extensively and for more
restricted tasks. For example, the HERMES system (Rivera and Cercone 1998) allows
the formulation and interpretation of ad hoc queries relating to doctor and patient
demographic information, patients? personal details, visit information, and insurance
coverage information. It is designed as an aid to hospital administration, and not to
clinical care.
4. The CLEF Query Interface
The CLEF Query Tool has four components which are invoked in sequence whenever a
query is posed by the user (Figure 1). The first is the Query Editor, a natural language
interface which guides the user in building a clear and valid query. The output of
4 HL7 is an internationally adopted communication language used for healthcare data. It covers the whole
scope of healthcare communication (http://www.hl7.org). Arden Syntax is a standard specification of
defining and sharing modular health knowledge bases, providing procedural representations of medical
knowledge and explicit definitions.
113
Computational Linguistics Volume 33, Number 1
this component is a logical representation underlying the query text that the user has
created. The second component, the Query Transcoder, converts this logical represen-
tation to a Java encoding accepted by the CLEF database management system (DBMS).
In this form, the query is sent to the DBMS, which recodes it again into SQL and
submits it to the database. The result of the query, usually a list of records for relevant
patients, returns to the third component of the Query Tool, the Result Processor, which
transforms the raw data into an aggregated representation defining the content of the
answer. This representation then passes to the fourth and final component, the Answer
Renderer, which configures a convenient display for the user by combining fluent text
with diagrams (tables and charts).
We now describe these components in more detail.
4.1 Query Editor
The Query Editor allows the user to create a logical representation of the query by means
of Conceptual Authoring. When beginning a new query, the user is shown a minimally
specified feedback text based on a model of query structure in this domain; this model
is described in Section 5. By inserting content in the initial place-holders, the user can
build up the full text of a query in a few dozen choices, a process that takes a few
minutes once the user has become accustomed to the editing process (for details, see
Section 6). A query is potentially complete when all obligatory slots have been filled.
This is easy for the user to verify because obligatory place-holders are shown in red:
When no red text remains, the query is complete. At this point, the user can hit the
Submit button, whereupon the current A-box is passed to the Query Transcoder.
4.2 Query Transcoder
The Query Transcoder takes as input an A-box from the Query Editor, and recodes it
in the format expected by the DBMS. This conversion depends on a mapping between
the ontology (or T-box) employed by the Query Editor, and the concepts of the database
archetype. The T-box cannot be exactly the same as the archetype, because it has to serve
a different purpose?that of providing logical representations suitable for generating
linguistic structures like clauses and nominals.
4.3 Result Processor
The Result Processor receives the data returned by the DBMS, normally a set of records
for relevant patients, and constructs the logical representation of an answer for the user.
A typical result set received from the DBMS would list the patients that fulfilled the
requirements of the query, and specify, for each patient, the features AGE and GENDER
along with values for each of the query elements. For example, the query
How many patients between 30 and 70 years of age, who had a clinical diagnosis of malignant
neoplasm of breast and underwent surgery, had a haematoma after surgery?
may yield the result set shown in Figure 2.
From such data, the Result Processor plans aggregate presentations in which
patients are grouped according to the age/gender breakdown and the individual query
terms. For each query term, the data are split into a dynamically determined number of
age groups, and for each age group the patients are further subdivided by gender.
114
Hallett, Scott, and Power Composing Questions through Conceptual Authoring
Figure 2
Example of a result set.
4.4 Answer Renderer
The data thus organized are presented to the user in three types of formats: tables, charts
and text. Each individual chart is accompanied by an automatically generated caption
that explains its content.
Captions are generated using template-based techniques, where fillers are provided
by the same data that were used for generating the chart. For example, the results we
saw in Figure 2 are presented as an answer that includes the bar chart in Figure 3.
This is accompanied by a textual explanation in the form of a caption, a fragment of
which reads:
Your query has returned 965 patients between 30 and 70 years of age who had a clinical
diagnosis of malignant neoplasm of breast and underwent surgery. This chart displays
the distribution of patients in five age groups according to their gender and time of
haematoma after surgery.
? In the 30?39 years age group there were 163 patients (2 men and 161 women):
151 patients did not have haematoma after surgery, 12 patients had haematoma
after surgery.
? In the 40?49 years age group there were 326 patients (no men and 326 women):
304 patients did not have haematoma after surgery, 22 patients had haematoma
after surgery.
? In the 50?59 years age group there were 363 patients (8 men and 355 women):
337 patients did not have haematoma after surgery, 26 patients had haematoma
after surgery.
? In the 60?69 years age group there were 110 patients (2 men and 108 women):
97 patients did not have haematoma after surgery, 13 patients had haematoma
after surgery.
? In the 70?79 years age group there were 3 patients (one man and two women):
two patients did not have haematoma after surgery, one patient had haematoma
after surgery.
5. Query Model
A controlled editing environment is most effective when based on a model of the kinds
of queries that users will wish to make. There is a trade-off here between flexibility and
ease of use. If we have no preconceptions about the general nature of queries, we have
to provide users with a wide set of possible patterns, leaving them to search for the
particular pattern they happen to want. If instead we can assume that the query will
belong to a known set of patterns, the editor can help the user to get started by offering
a manageable list of alternatives, so avoiding the ?blank page? problem.
Investigations on a taxonomy of queries posed by general practitioners in an
outpatient setting has shown that in primary care, queries are relatively simple and
115
Computational Linguistics Volume 33, Number 1
Figure 3
Chart generated as part of a response displaying the distribution of patients who developed and
did not develop haematoma according to their age and gender.
generally ask for evidence-based advice for treatment decisions (Ely et al 2000). For
example, of 64 generic question types, the three most common are:
What is the drug of choice for condition X?
What is the cause of symptom X?
What test is indicated in situation X?
In contrast to these findings, our consultation with cancer clinicians revealed that
questions posed in a clinical research setting tend to have a more complex nature
and to be directed at groups of patients, searching for relationships rather than simple
values:
What is the average time of relapse in Acute Myeloid Leukaemia for patients with a complete
response after two cycles of treatment?
Can this time be linked to the cytogenetic findings in the original blood sample?
What is the median time between first drug treatment for metastatic breast cancer and death?
116
Hallett, Scott, and Power Composing Questions through Conceptual Authoring
Our policy in CLEF has been to aim first at a relatively specific model, under the
guidance of the relevant experts?clinicians and medical researchers in the area of
cancer.
5.1 Elements of a Basic Query
The structure of a typical query (according to our experts) is shown by the following
relatively simple example:
For all patients with cancer of the pancreas, what is the percentage alive at five years for those
who had a course of gemcitabine?
As can be seen, this query breaks down into three elements: the set of relevant patients,
defined by a problem; the partition of this set according to treatment; and the further
partition according to outcome, from which the percentage can be calculated. For
maximum clarity, the Query Editor can format the query so that these three elements
are marked explicitly and presented separately:
Relevant subjects: Patients with cancer of the pancreas.
Treatment profile: Patients who received a course of gemcitabine.
Outcome measure: Percentage of patients alive after five years.
Generalizing from this example, we can identify the following basic query pattern:
Relevant subjects: Patients with [some diagnosis].
Treatment profile: Patients who received [some treatment].
Outcome measure: [Measure] of patients [with some status] [at some point in time].
An important requirement on this formulation of the query is that it should
be unambiguous?namely, that users should understand correctly how the outcome
measure will be calculated. We assume that the calculation will proceed through the
following steps. First, retrieve all the patients in the database who satisfy the conditions
in the first two paragraphs (Relevant subjects and Treatment profile)?in this example,
all patients with cancer of the pancreas who received a course of gemcitabine. Call this
set S and let its cardinality (i.e., the number of patients in the set) be C(S). Next, find
the subset of S also satisfying the outcome condition?in this example, the patients still
alive after five years. Call this set M and its cardinality C(M). Finally, divide C(M) by
C(S) and express the result as a percentage.
With a slight elaboration of this basic pattern, we can obtain a second kind of query,
which requests a comparison rather than a single value:
For all patients with cancer of the pancreas, compare the percentage alive at five years for those
who had a course of gemcitabine with those who didn?t.
Again this can be presented to the user using a separate paragraph for each element:
Relevant subjects: Patients with cancer of the pancreas.
Treatment profile: Patients who received a course of gemcitabine, compared with
patients who did not.
Outcome measure: Percentage of patients alive after five years.
117
Computational Linguistics Volume 33, Number 1
For a comparison question we need to compute two outcome measures, so the steps in
the calculation have to be elaborated as follows. First, retrieve two sets of patients, S1
and S2, satisfying the conditions that we want to compare. In the example, S1 will be
the set of patients with cancer of the pancreas who had a course of gemcitabine; S2 will
be the set of patients with the same type of cancer but no gemcitabine treatment.5 Next,
for each set, find the subset of patients still alive after five years: Call these subsets M1
and M2. Finally, compute the measures to be compared by dividing C(M1) by C(S1), and
C(M2) by C(S2), and expressing the resulting ratios as percentages.
5.2 Complex Queries
Each element of a query can be made more complex in two ways. First, it can be replaced
by a conjunction or disjunction, so that the query in a sense becomes several queries
requiring several answers. Second, the content of the description can be elaborated, for
example by adding more qualifications. Here is an example of the first kind:
For all patients with a brain glioma, what percentages are still alive at 1, 2, and 5 years if they
take Imatinib Mesylate every day?
This can be analyzed as a single relevance group, single treatment, and multiple
outcome measures (survival at 1, 2, and 5 years). Separate answers for these measures
will be needed. An example of the second kind is the following:
For all patients with cancer of the vulva that is locally advanced and/or metastatic or recurrent,
and where this cannot be treated with either surgery or radiotherapy of any kind, what is the
survival rate for those given Taxol only?
We assume this is a single rather than a multiple query, and that separate answers are
not needed for the various conjunctions and disjunctions. The treatment profile (Taxol)
and the outcome measure (survival rate) have a content that can be easily specified?a
single choice from a menu would suffice. However, the set of relevant patients requires
a very elaborate description because there are so many qualifications.
5.3 Multiple Relevance Sets
When the phrase describing a relevance set includes a conjunction or disjunction, there
may be ambiguity over whether the intended query is single or multiple. Compare these
three patterns:
(1) For all patients with lung cancer, and for all patients with breast cancer . . .
(2) For all patients with lung cancer and breast cancer . . .
(3) For all patients with lung cancer or breast cancer . . .
Here (1) seems a clear case of a multiple query, whereas the others are ambiguous
but tending to a single-query interpetation. It is hard to eliminate such ambiguities
altogether while wording the query in a way that is reasonably natural, but at least we
can impose consistency by using different realization devices for the two cases?for
5 These sets are obviously disjoint.
118
Hallett, Scott, and Power Composing Questions through Conceptual Authoring
example, bulleted lists for conjunctions (or disjunctions) that imply multiple queries,
and discourse connectives (and, or) for ones that imply single queries. For example:
Relevant subjects:
? Patients younger than 60 years of age who have had bad prognosis
myelodysplastic syndrome only for at least six months
? Patients younger than 60 years of age who have had acute
myelogenous leukaemia caused by bad prognosis myelodysplastic
syndrome for at least six months
versus
Relevant subjects:
? Patients younger than 60 years of age who have either had bad
prognosis myelodysplastic syndrome only for at least six months or
acute myelogenous leukaemia caused by bad prognosis myelodysplastic
syndrome for at least six months
In the first we have two relevance sets; in the second we have only one.
5.4 Multiple Treatment Profiles
A similar ambiguity is found when several treatment profiles are mentioned. Either
there are several queries, or there is a single query concerning a logical combination of
the treatments. The following query text (written as an example by a medical researcher)
could be interpreted either way:
For all patients younger than 60 years of age who have either had bad prognosis myelodysplastic
syndrome only for at least six months or acute myelogenous leukaemia caused by bad prognosis
myelodysplastic syndrome for at least six months, what is the survival rate if you give them
intensified remission induction chemotherapy followed by either an autologous or allogeneic
bone marrow transplant?
Perhaps the researcher?s aim is to compare autologous bone marrow transplants
with allogeneic ones. Alternatively, it might not matter whether the transplant is
autologous or allogeneic provided that it is one or the other, as suggested by the singular
verb (?what is the survival?). In the query interface, the ambiguity can be avoided in the
same way as before, by using bullets to mark separate queries. For example:
Treatment profiles:
? Intensified remission induction chemotherapy followed by an
autologous bone marrow transplant
? Intensified remission induction chemotherapy followed by an
allogeneic bone marrow transplant
versus
Treatment profiles:
? Intensified remission induction chemotherapy followed by an
autologous or allogeneic bone marrow transplant
In the first we have two treatment profiles and hence separate queries; in the second we
have only one.
119
Computational Linguistics Volume 33, Number 1
5.5 Multiple Outcome Measures
There are several examples in which survival rates are requested at, say, one year,
two years, and five years. It makes no sense to combine these into a single query, so
they are always interpreted as separate queries.
5.6 Comparison Queries
Comparison queries are those that ask for certain outcomes of separate groups of
patients that do not share common diagnosis or treatment profiles.
Compare survival rates at 5 years after diagnosis for patients with adenocarcinoma who received
chemotherapy and patients with invasive ductal carcinoma who received radiotherapy.
We represent such queries as two independent queries, with separate profiles.
5.7 Elaborate Descriptions
Descriptions are boolean combinations of properties. A description can be elaborate
either because it contains many boolean operators, or because the properties are
themselves complicated. The following description of a reference set is elaborate in
both ways:
For all patients younger than 60 years of age who have either had bad prognosis myelodysplastic
syndrome only for at least six months or acute myelogenous leukaemia caused by bad prognosis
myelodysplastic syndrome for at least six months, what is the survival rate. . . ?
Complex boolean combinations of this kind often cannot be presented in running
prose without the scopes of the boolean operators becoming unclear. To avoid this
problem, the feedback text generator formats complex boolean combinations using
hierarchical layout:
Relevant subjects:
? Patients with the following properties:
a. They are younger than 60 years of age
AND
b. They have one of these properties:
b1. They have had bad prognosis myelodysplastic syndrome only
for at least six months
OR
b2. They have had acute myelogenous leukaemia caused by
bad prognosis myelodysplastic syndrome for at least six
months
Descriptions of treatment profiles can be elaborate in the same ways. The following
excerpt has two treatment profiles, the first using a combination of AND and NOT, the
second using AND combined with temporal sequence (marked by THEN).
. . . compare the survival rates over time for those who had no surgery but did have mitomycin C
injected into the bladder once a month, with those who had transurethral resection of the tumor
and then a single one-time injection of mitomycin C into the bladder.
120
Hallett, Scott, and Power Composing Questions through Conceptual Authoring
The corresponding part of the feedback text is laid out as follows:
Treatment profiles:
? a. NO surgery
AND
b. Mitomycin C injected into the bladder once a month
? a. Transurethral resection of the tumor
THEN
b. A single one-time injection of mitomycin C into the bladder
5.8 Representing Time
Queries about patient records contain many references to events occurring at particular
times: diagnoses, tests, treatments, deaths, and so forth. These time specifications are
crucial. To deal with them effectively, the query tool must meet two requirements.
First, the feedback text should express temporal relations naturally and unambiguously,
using familiar devices like tenses and adverbials. Second, the resulting conceptual
representation (in the A-box) must be aligned with the fields through which time is
represented in the database.
Like most databases, the CLEF medical records employ several types of time stamp.
First of all, an event has a valid time, the moment when it actually took place. For
example, if a mastectomy was performed on 29th January 2000, the valid time would be
some representation of this day, perhaps ?29-01-2000?, assuming a granularity calibrated
in days (rather than hours, weeks, etc.). Next, an event has a recording time, the
moment when it was written down. Obviously this might differ from the valid time,
although they would be the same if the doctor kept prompt records. We also use a
concept of query time, the moment when a query was formulated by the CLEF user:
this is needed in order to interpret deictic time references in the feedback text, based
for example on tenses or on phrases like ?after 1995?, which can be interpreted to mean
?from 1995 until now?.
For some events the valid time can be a single moment, specified for example by a
date. For events that last for longer intervals, like a whole course of treatment, two valid
time stamps have to be given, one for the start time and one for the end time. Of course
this distinction is related to granularity. With a granularity based on days, a week has
to be treated as an interval with a start date and an end date; with a granularity based
on weeks, the same week could be identified by a single time stamp (e.g., ?W40-2000?,
meaning the 40th week of the year 2000).
To model time effectively in queries, we need to provide a range of natural and
clear options, and map them to the time stamps used in the database. At present, the
temporal modifiers offered during query editing are as follows:
 between [date 1] and [date 2]: interpreted as a closed interval [date 1, date 2]
 after [some date]:interpreted as a closed interval [this date, query time]
 before [some date]
 in [this year]: interpreted as [01/01/this year, 31/12/this year]
 any of the above, where instead of a specific date the user enters an index
event after the surgery; in this case, the implied time will be computed by
the DBMS instead of explicitly entered by the user
121
Computational Linguistics Volume 33, Number 1
 event1 {while/at the same time as/during event2} : will be interpreted as two
overlapping time intervals corresponding to the two events
For example, such time expressions cover queries like: patients diagnosed with cancer
before 1999, or patients who received chemotherapy within 5 months of surgery. The interface
allows Allen?s 13 basic interval relationships to be expressed in natural language (Allen
1984).
In principle we could require users to associate a time stamp with every event
mentioned in a query; however, by imposing this further requirement on users we
would pay a high price in usability, virtually doubling the number of operations needed
in order to complete the query, and damaging the transparency of the resulting text.
In the CLEF query interface we have decided instead to associate default values to
time descriptions and to make the time stamp anchors visible only on demand in the
feedback text. The output text will contain all the time stamps, with the values either
entered by the user or defaulted, so allowing the user to review the query and amend it
where necessary.
6. Evaluation
The best evaluation of any question-answering system is one which looks at real users
making information-seeking requests in real-life contexts. Because the complete CLEF
system is not yet ready for deployment, this is impractical at this stage. However, we
have been able to perform usability tests on the query interface in isolation from the
full system, and this is what we report on here. Our current study does not cover
the Query to SQL Translation and the Answer Retrieval components, which are part of
the server components side of the query interface. This separation is not always possible
in practice. For example, we cannot at this stage test the full range of queries that can
be constructed in the interface, because some are not yet supported by the back-end.
Similarly, we can only assess the time necessary for editing queries, not for retrieving
answers, because this is almost entirely dependent on the communication procedure
and on the speed of the SQL translator.
We have thus far conducted two formal experiments, to address the following
questions:
 Are users able to successfully compose complex queries using the system?
 Can the system be used with minimal training?
 Are the queries, as presented in the interface, easily understandable?
6.1 Experiment 1: Query Composition
As mentioned earlier (Section 1), one of the main desiderata behind the design of our
querying method is that it should be intuitive. With respect to the system we have
implemented for CLEF, what this means is that medics and bio-informaticians should
be able to pose the kind of complex queries that they require, without the need for
extensive training, or for knowledge of the structure or language of the underlying
repository. This experiment tests the extent to which our querying method fulfills these
requirements.
122
Hallett, Scott, and Power Composing Questions through Conceptual Authoring
Subjects. Fifteen medics and bio-informaticians participated in the experiment. All had
previously been granted clearance6 to see the information in the confidential repository
of patient records. All subjects were knowledgeable in the domain of cancer, and all
but two had no knowledge of the representation language of the repository (SQL), or
of how the data contained therein were structured; none had any prior experience with
the query-formulation interface.
Methodology. Each subject was given a short (5?10 minute) introduction to the interface,
which included a demonstration of the construction of a fairly simple query. Subjects
were then given a set of four queries, which they were asked to compose using the
interface. To increase the difficulty of the task, the questions presented to the subjects
avoided, where possible, the wording required by the user interface, so that users were
obliged to think about the meaning rather than to aim for particular target phrases. To
avoid effects of practice, we varied randomly the order in which the questions in the
set were presented to subjects. Subjects were allowed as much time as they needed to
compose each query.
For each subject, we measured the time taken to build each query, and recorded the
number of operations used for constructing it.
Materials. The materials for the experiment consisted of the following set of four queries:
How many patients who received surgical treatment for malignant neoplasm of the central
portion of the breast had no curative radiotherapy?
How many patients between the ages of 40 and 60 when they were first diagnosed with lung
cancer (malignant neoplasm of bronchus or lung, unspec) received radiotherapy and had
a platelet count higher than 300 and a leukocytes count lower than 3?
What percentage of patients under the age of 60 treated for breast cancer (malignant neoplasm
of breast, unspec) died within 5 years of a mastectomy?
How many patients with acute lymphoid leukaemia have been given chemotherapy?
These are representative of the query types that emerged from an earlier requirements
analysis with oncologists and cancer bio-informaticians. They also vary in their levels of
structural complexity and in the number of interface operations required to successfully
complete them.
As can be seen, these questions are far more complex than the queries standardly
posed to search engines or to most other interactive query engines (as described,
for example in [Hovy, Hermjakob, and Ravichandran 2002]; [Soricut and Brill 2004];
[TREC 2005]).
Results. The main finding of this experiment is the achievement of 100% success in
subjects? ability to use the interface for the purpose for which it was intended: All
subjects successfully composed all queries. The mean completion time per query was
3.9 minutes (noting that subjects were under no time pressure to complete the individual
6 By the UK Medical Research Ethics Committee (MREC).
123
Computational Linguistics Volume 33, Number 1
Figure 4
Mean completion time for queries in order of occurrence.
queries).7 Figure 4, which gives the average time to completion across all subjects, shows
that subjects learned to use the interface quickly: they take much longer on their first
query, and their performance asymptotes by the time they get to the second query.
This effect is confirmed by an analysis of variance (ANOVA)8, which shows a highly
significant effect of order of presentation (F = 9.8427; p< .0001). Furthermore, significant
differences were found between subjects? performance on the first query they composed
compared to the second, third, and the fourth (each at p < .01 on the Tukey HSD
test). However, application of the same test showed no significant difference in subjects?
performance on the second versus third, second versus fourth, or the third versus fourth
composed query.
Because the queries vary in structural complexity, some will require the user to
perform more interface actions than others, and so one would predict a difference in
subjects? performance (i.e., time to completion) on the individual queries; this was borne
out by the analysis (ANOVA, F = 5.5015; p < .0028).
If the method is easy to learn, one would predict that subjects? proficiency with the
interface will increase fairly quickly as they move from the first query they encounter
to the last, irrespective of complexity. This can be tested by measuring subjects?
performance on the interface in terms of the number of interface operations (mouse
clicks and selections) they perform, normalized for complexity: a value of 1 would
mean that subjects perform twice as many operations as are required; a value of 0 would
mean that subjects perform the minimal number of required operations (i.e., perfect
performance). The result of such an analysis is shown in Figure 5. The picture that
emerges from this is one where, overall, subjects are very efficient, achieving an average
score of 0.19 over their first four encounters with the method. They make a fair number
of false starts when composing their first query, but become extremely proficient by
the time they get to their second query, and near perfect by the time they get to the
fourth. Analysis of variance9 shows a highly significant effect of order of presentation
(F = 7.4993; p < .0004). Once again, the Tukey HSD Test shows a significant difference
between the first query encountered and each of the subsequent ones (p <. 01), and that
the differences between the second and third, the second and fourth, and the third and
fourth, were nonsignificant.
7 For the last 5 subjects, all of whom used a version of the interface that had been improved to respond
faster to interface actions, this average went down to 2.7 minutes.
8 One-way ANOVA for correlated samples.
9 One-way ANOVA for correlated samples.
124
Hallett, Scott, and Power Composing Questions through Conceptual Authoring
Figure 5
Proficiency with the interface as a function of experience.
6.2 Experiment 2: Clarity of the Queries
Interfaces to databases based on natural language interpretation inevitably suffer from
the ambiguity and imprecision of the input texts, unless users can be trained in a
controlled language. Our method of composing queries avoids this problem altogether:
because the natural language feedback text is generated by the system rather than the
user, there is no need for the system to choose among alternative interpretations. Of
course, this does not guarantee that the query text is equally transparent to the user: this
will depend on the efficacy of our feedback text design?the point we wish to evaluate
in the present experiment, which explores the extent to which composed queries, as
presented in the feedback texts, can be clearly understood.
Subjects. Fifteen subjects participated in the experiment. Of these, ten had previously
participated in Experiment 1; the new subjects had the same profile as those previously
seen.
Methodology. Subjects were given a paper-based questionnaire containing 24 trials, each
showing a completed complex query as presented in the interface (i.e., as a ?feedback
text?). Each query was associated with three alternative interpretations, presented as full
natural language questions: only one of these represented the correct meaning; the other
two represented plausible but incorrect meanings. Subjects were given a forced-choice
task to identify which of the three alternatives corresponded to the meaning of the given
feedback text.
The queries were presented to all subjects in the same (random) order. We devised
five presentation sets, each containing a different ordering of the options for each query,
and these were randomly assigned to subjects. We suggested to subjects that a useful
strategy might be to read the alternatives before looking at the associated feedback text.
There was no time limit.
Materials. The materials comprised four examples, each of six patterns of ambiguity:
Type 1: Attachment of temporal expression. Most events can have a temporal expression
associated. When there is more than one event that could be subsumed by a temporal
expression, the text may become ambiguous. For example:
Relevant subjects: patients with a clinical diagnosis of breast cancer
Treatment: patients who did not receive adjuvant chemotherapy in the past year
Tests: [ ]
Outcome: absolute number of patients
125
Computational Linguistics Volume 33, Number 1
Options:10
 How many patients diagnosed with breast cancer had no adjuvant chemotherapy
in the past year?
 How many patients treated for breast cancer in the past year had no
adjuvant chemotherapy?
 How many patients diagnosed with breast cancer in the past year had no
adjuvant chemotherapy?
Type 2: Scope of conjunctions. Whenever a complex expression contains a combination
of conjunctions and disjunctions, potential ambiguities may occur, especially when
combined with negations or prepositional phrases. For example:
Relevant subjects: patients with a clinical diagnosis of invasive ductal carcinoma
Treatment: patients who received breast conservation surgery, no auxillary surgery,
and radiotherapy
Tests:[ ]
Outcome: absolute number of patients
Options:
 How many patients diagnosed with invasive ductal carcinoma underwent breast
conservation surgery, did not undergo auxillary surgery, and received
radiotherapy?
 How many patients diagnosed with invasive ductal carcinoma underwent
breast conservation surgery, did not undergo auxillary surgery, and did
not receive radiotherapy?
 How many patients diagnosed with invasive ductal carcinoma did not
undergo breast conservation surgery, did not undergo auxillary surgery,
and received radiotherapy?
Type 3: Scope of conjunctions plus attachment of temporal expression. This is an extension of
the first two cases, where a temporal expression post-modifies an expression that is part
of a conjunction of events. For example:
Relevant subjects: patients with a clinical diagnosis of malignant neoplasm,
unspecified
Treatment: patients who received radiotherapy and chemotherapy within 1 year
of the diagnosis
Tests:[ ]
Outcome:absolute number of patients
Options:
 How many patients diagnosed with cancer had radiotherapy and chemotherapy
both within 1 year of diagnosis?
 How many patients diagnosed with cancer had radiotherapy within
1 year of diagnosis and also had chemotherapy at any time?
10 In the examples that follow, the correct interpretations are indicated with italics.
126
Hallett, Scott, and Power Composing Questions through Conceptual Authoring
 How many patients diagnosed with cancer had radiotherapy and
chemotherapy and received any kind of treatment within 1 year of
diagnosis?
Type 4: Combination of various query components. Events in a query can be linked to each
other by various means, including temporal expressions, conjunctions, and disjunc-
tions. Complex combinations may render the feedback text ambiguous. For example:
Relevant subjects: patients with a clinical diagnosis of breast cancer and who had
nausea within 1 year of the chemotherapy
Treatment: patients who received [some surgical procedure] [at some point in time]
and chemotherapy but no radiotherapy within 1 year of the diagnosis
Tests:[ ]
Outcome: percentage of patients who were alive after 5 years of the diagnosis
Options:
 What percentage of patients diagnosed with breast cancer who underwent a
surgical procedure at any time, received chemotherapy within 1 year of the
diagnosis, had nausea within 1 year of the chemotherapy, and received no
radiotherapy within 1 year of the diagnosis, survived more than 5 years
after diagnosis?
 What percentage of patients diagnosed with breast cancer who underwent
a surgical procedure at any time, received chemotherapy at any time, had
nausea at any time after chemotherapy, and received no radiotherapy
within 1 year of the diagnosis, survived more than 5 years after diagnosis?
 What percentage of patients diagnosed with breast cancer who underwent
a surgical procedure at any time, received chemotherapy within 1 year of
the diagnosis, had nausea after chemotherapy but within 1 year of the
diagnosis, and received no radiotherapy within 1 year of the diagnosis,
survived more than 5 years after diagnosis?
Type 5: Complex queries, non-ambiguous components. We introduced this category in order
to test the readability of complex queries that do not necessarily contain ambiguous
components. Because most queries in the medical domain are likely to be very complex,
can the sheer number of query components render the query ambiguous to the users?
For example:
Relevant subjects: patients under the age of 50 at the time of diagnosis, with a
clinical diagnosis of breast cancer
Treatment: patients who received [some surgical procedure] [at some point in time]
and no chemotherapy within 1 year of the diagnosis
Tests: [ ]
Outcome: absolute number of patients
Options
 How many patients with breast cancer, under the age of 50, had a surgical
procedure at any time and did not have chemotherapy within 1 year of the
diagnosis?
127
Computational Linguistics Volume 33, Number 1
 How many patients with breast cancer, under the age of 50, had a surgical
procedure within one year of the diagnosis and did not have
chemotherapy within one year of the diagnosis?
 How many patients with breast cancer, below the age of 50, had a surgical
procedure within one year of the diagnosis and had chemotherapy after
one year of the diagnosis?
Type 6: Attachment/interpretation of outcome. The outcome section generally describes a
condition holding between a reference and a target set of patients. If the query contains
multiple features describing the patient set, it may be difficult to differentiate between
features that contribute to the reference set and features that contribute to the target set.
For example:
Relevant subjects: patients with a clinical diagnosis of breast cancer and who had
anaemia after chemotherapy
Treatment: patients who received chemotherapy
Tests:[ ]
Outcome: percentage of patients who were alive after 5 years from the diagnosis
Options:
 Of the patients diagnosed with breast cancer who developed anaemia after
chemotherapy, what percentage survived 5 years after diagnosis?
 Of the patients in the database, what percentage were diagnosed with
breast cancer, developed anaemia after chemotherapy, and survived
5 years after diagnosis?
 Of the patients diagnosed with breast cancer, what percentage developed
anaemia after chemotherapy and survived 5 years after diagnosis?
Results. If the presented feedback text is incomprehensible, the probability that subjects
will select the correct interpretation will be 0.33 (i.e., they will get the right answer only
a third of the time). Our results show that subjects? precision is 0.84; that is, on average,
they select the intended interpretation 84% of the time, rather than 33% as would be predicted if
their selections were random. Statistical analysis of these results, using a one-sample t-test,
shows this effect to be highly significant (mean = 0.8361, d = 0.5028, t = 16.76, p < .0001).
The breakdown by type of ambiguity is shown in Table 1.
Table 1
Interpretation of feedback texts.
Ambiguity Total correct Percent
Type 1 51 85
Type 2 54 90
Type 3 50 83
Type 4 48 80
Type 5 47 78
Type 6 51 85
128
Hallett, Scott, and Power Composing Questions through Conceptual Authoring
6.3 Summarizing the Evaluation
The true test of any system comes with its use in situ by the users for which it was
designed. Normally, this would be preceded by a bank of formal empirical studies
under more controlled conditions. For a question-answering system like the one we are
addressing in this article (which is but a small part of a much larger system), a formal
controlled evaluation would ideally cover a large number of exemplars of each type of
query supported by the system, and a large number of subjects. Given our constraints
on the number of available subjects (and the concomitant effect this has on the possible
design of any experiments), the evaluation reported here is necessarily more limited in
scope. This is not an unusual situation in system development, where evaluation must
proceed by gradual refinement through the application of rigor, wherever possible,
but also applying along the way intuition, common sense, and past experience. The
evaluation we have presented here shows what can be done during the early phases
of the development of a large and complex system whose components are in different
stages of completion, and where access to representative users is limited.
Given these caveats, the picture that emerges from this study is nonetheless very
encouraging. Our results suggest that our target users (medical researchers) can quickly
learn to construct queries of the type and complexity that they have identified as
relevant. Specifically:
 They are able to use the Conceptual Authoring method successfully to
compose complex queries, with no prior exposure to the method and
with the benefit of only minimal training.
 They become quickly proficient with the system, achieving near perfect
performance by their fourth attempt at query composition.
The study also indicates that the feedback texts employed to construct queries of a
high degree of structural complexity are not difficult to understand. This is extremely
important, as it means that users can be confident that they are obtaining an answer
that pertains to the question that they think they are asking, as opposed to an answer to
some other similar question.
Additionally, in a separate, informal study, we have found suggestive evidence
that the Conceptual Authoring method of query composition may be much more
user-friendly than the traditional method of direct SQL editing, even for extremely
skilled SQL coders with a high level of familiarity with the database and the domain
(Hallett, Scott, and Power 2006). Our tests showed that (an albeit small sample of) such
experts, even in a situation that is heavily biased towards optimal performance of
SQL codes, found it much easier to compose queries with the Conceptual Authoring
interface than in SQL. Not only did it take them more than three times longer, on
average, to compose the query in SQL, but they were not able to produce the complete
SQL in that time.
7. Conclusion
Most question-answering systems make use of natural language understanding and
allow users to pose simple questions to textual repositories. We have presented
here a generic method for composing natural language questions within a question-
answering system that avoids the well-know pitfalls of natural language understanding
129
Computational Linguistics Volume 33, Number 1
while allowing users to pose complex questions to data repositories. The method,
Conceptual Authoring, involves no natural language interpretation?only generation?
and is particularly well-suited to query interfaces to closed-domain systems. We have
elucidated the method through its use in the CLEF query tool, which has been designed
to meet the requirements of a particular context: the querying of large repositories
of electronic health records by doctors and medical researchers. Similar requirements
almost certainly apply in other fields of expertise (e.g., engineering, genomics, law,
finance), as data are increasingly available in machine-usable electronic form; they can
be summarized as follows:
 Users: The query tool must be usable by the relevant domain
experts?doctors, lawyers, or whomever?with no training in database
query languages.
 Training: The users must be able to use the query tool after minimal
learning time (minutes rather than hours).
 Time: After training, users must be able to construct complex queries in
a time comparable to writing the query down on paper?that is, a few
minutes.
 Reliability: The query tool must be close to 100% reliable, in the sense that
any query correctly formed by the user will be correctly transcoded into
the database query language and therefore answered by the system.
 Transparency: Queries must be presented to users in a form that is clear
and unambiguous, so that they know exactly what question they have
asked.
Although not exactly a requirement, a practical consideration is that the queries should
be frequent and important enough to justify the effort needed to meet the very stringent
requirements on usability and transparency. There is no point investing in a natural
language interface like the CLEF query tool except in contexts where the query results
are highly valuable.
In our view, transparent communication with expert users depends first and
foremost on using a familiar medium?the medium the experts use in their
normal work, which in this case means natural language. However, as argued in
Section 2, traditional natural language interfaces to database systems cannot meet the
requirements on reliability and training, because reliable interpretation of an input
text can be achieved only if the text conforms strictly to a controlled language (which
our users would not have time to learn). We therefore proposed a modification of
the traditional approach, in which the semantic representation of the query is edited
directly, through an interactive feedback text generated by the system. Otherwise the
approaches are the same: once obtained, the semantic representation is transcoded to
the database query language and passed to the database management system; when
the answer is returned, it is organized to suit the purposes of users, and presented in a
familiar display such as a text or diagram.
Ultimately, the value of such a tool must be proved in everyday use, but our
evaluation study provides some evidence that our approach can meet the requirements.
First, our studies were performed with the relevant users, in this case medical experts.
The training required for reaching a reliable level of performance was a matter of
minutes?usually a single demonstration followed by a single trial. Thereafter, most
130
Hallett, Scott, and Power Composing Questions through Conceptual Authoring
users could formulate fairly complex queries in a reasonably short time (3?4 minutes); in
contrast, we have found in informal tests that expert SQL coders take at least three times
as long, while often failing to achieve a complete query (Hallett, Scott, and Power 2006).
The reliability achieved over 60 queries was 100%, in the sense that all users managed to
formulate all their targets. Finally, a further experiment showed that the formulations
of the queries in the feedback texts were transparent, with accuracy rates of 80?90% on a
multiple-choice comprehension task with a random baseline of 33%.
These evaluation results offer strong support for Conceptual Authoring as an
approach to this class of problems: we know of no alternative approach that can
achieve similar success in meeting these requirements. However, there are several areas
where improvement should be possible. First, we need to find ways of facilitating
the development process: building and maintaining a system like the CLEF query tool
requires, at present, the hand-coding of linguistic and conceptual resources; as a step in
this direction, we have developed a method of automatically inferring relevant types
of queries for any database, and automatically constructing resources that inform a
Conceptual Authoring interface (Hallett 2006). Second, we cannot be sure yet that the
wording of feedback texts is optimal?perhaps with more research the comprehension
rates can be pushed higher. Finally, we have only begun to explore the possibilities for
improving the GUI for Conceptual Authoring.
References
Allen, James. 1984. Towards a general theory
of action and time. Artificial Intelligence,
23(2):123?154.
Androutsopoulos, I. 1992. Interfacing a
natural language front end to a relational
database. Masters thesis, Department of
Artificial Intelligence, University of
Edinburgh.
Androutsopoulos, I., G. Ritchie, and P.
Thanitsch. 1993. An efficient and portable
natural language query interface for
relational databases. In Proceedings of the
6th International Conference on Industrial
Engineering Applications of Artificial
Intelligence and Expert Systems Edinburgh,
pages 327?330, Edinburgh.
Androutsopoulos, I., G. D. Ritchie, and
P. Thanisch. 1995. Natural language
interfaces to databases?an introduction.
Natural Language Engineering, 2(1):29?81.
Bell, J. E. and L. A. Rowe. 1992. An
exploratory study of ad hoc query
languages to databases. In Proceedings of
the 8th International Conference on Data
Engineering, pages 606?613, Tempe, AZ.
Bouayad-Agha, Nadjet, Richard Power,
Donia Scott, and Anja Belz. 2002.
PILLS: Multilingual generation of
medical information documents with
overlapping content. In Proceedings
of the Third International Conference on
Language Resources and Evaluation,
pages 2111?2114, Las Palmas, Spain.
Capindale, R. A. and R. G. Crawford. 1990.
Using a natural language interface with
casual users. International Journal of
Man?Machine Studies, 32(3):341?361.
Catarci, T. and G. Santucci. 1995. Are visual
query languages easier to use than
traditional ones? An experimental proof.
In Proceedings of the International Conference
on Human-Computer Interaction (HCI95).
College of American Pathologists, 2004.
SNOMED Clinical Terms User Guide.
July 2004 release.
Deshpande, A., C. Brandt, and P. Nadkarni.
2001. Ad hoc query of patient data:
Meeting the needs of clinical studies.
Journal of the American Medical Informatics
Association, 9(4):369?382.
Deshpande, A., C. Brandt, and P. Nadkarni.
2003. Temporal query of attribute-value
patient data: Utilizing the constraints of
clinical studies. International Journal of
Medical Informatics, 70:59?77.
Ely, John W., Jerome A. Osheroff, Paul N.
Gorman, Mark H. Ebell, M. Lee Chambliss,
Eric A. Pifer, and P. Zoe Stavri. 2000. A
taxonomy of generic clinical questions:
Classification study. British Medical Journal,
321:429?432.
Estrella, Florida, Chiara del Frate, Tamas
Hauer, Richard McClatchey, Mohammed
Odeh, Dmitry Rogulin, Salvator Roberto
Amendolia, David Schottlander,
Tony Solomonides, and Ruth Warren.
2004. Resolving clinicians queries
131
Computational Linguistics Volume 33, Number 1
across a grids infrastructure. In
Proceedings of the 2nd International
HealthGRID Conference.
Evans, Roger, Paul Piwek, Lynne Cahill, and
Neil Tipper. In press. Natural language
processing in CLIME, a multilingual legal
advisory system. Natural Language
Engineering.
Frank, Annette, Hans-Ulrich Krieger, Feiyu
Xu, Hans Uszkoreit, Berthold Crysmann,
Brigitte Jorg, and Ulrich Schafer. 2005.
Querying structured knowledge sources.
In AAAI-05 Workshop on Question
Answering in Restricted Domains, pages
10?19, Pittsburgh, Pennsylvania.
Gorman, P. N. and M. Helfand. 1995.
Information seeking in primary care:
How physicians choose which clinical
questions to pursue and which to leave
unanswered. Medical Decision Making,
(15):113?119.
Hafner, Carole D. and Kurt Godden. 1985.
Portability of syntax and semantics in
datalog. ACM Transactions on Information
Systems, 3(2):141?164.
Hallett, Catalina. 2006. Generic querying of
relational databases using natural
language generation techniques. In
Proceedings of the 4th International Natural
Language Generation Conference (INLG?06),
pages 95?102, Sydney, Australia.
Hallett, Catalina, Donia Scott, and Richard
Power. 2006. Evaluation of the CLEF
query interface. Technical Report 2006/01,
Centre for Research in Computing, The
Open University.
Hendrix, Gary G., Earl D. Sacerdoti, Daniel
Sagalowicz, and Jonathan Slocum. 1978.
Developing a natural language interface to
complex data. ACM Transactions on
Database Systems, 3(2):105?147.
Hovy, E. H., U. Hermjakob, and
D. Ravichandran. 2002. A question/
answer typology with surface text
patterns. In Proceedings of the DARPA
Human Language Technology Conference,
pages 247?250, San Diego, CA.
Jerome, R. N., N. B. Giuse, K. W. Gish,
N. A. Sathe, and M. S. Dietrich. 2001.
Information needs of clinical teams:
Analysis of questions received by the
clinical informatics consult service.
Bulletin of the Medical Library Association,
89(2):177?184.
Kalra, Dipak, Anthony Austin, A. O?Connor,
D. Patterson, David Lloyd, and David
Ingram. 2001. Design and Implementation
of a Federated Health Record Server,
pages 1?13. Medical Records Institute
for the Centre for Advancement of
Electronic Records Ltd.
Kaplan, S. Jerrold. 1984. Designing a portable
natural language database query system.
ACM Transactions on Database Systems,
9(1):1?19.
Kate, R. J., Y. W. Wong, and R. J. Mooney.
2005. Learning to transform natural to
formal languages. In Proceedings of the
Twentieth National Conference on Artificial
Intelligence (AAAI-05), pages 1062?1068,
Pittsburgh, PA.
Kim, Y. 1990. Effects of conceptual data
modelling formalisms on user validation and
analyst modelling of information requirements.
Ph.D. thesis, University of Minnesota.
Koonce, Taneya Y., Nunzia Bettinsoli Giuse,
and Pauline Todd. 2004. Evidence-based
databases versus primary medical
literature: An in-house investigation on
their optimal use. Bulletin of the Medical
Library Association, 92(4):407?411.
Lowden, B. G. T., B. R. Walls, A. De Roeck,
C. J. Fox, and R. Turner. 1991. A formal
approach to translating English into SQL.
In Proceedings of the 9th British National
Conference on Databases, pages 110?127,
Wolverhampton, UK.
Mueckstein, Eva-Martin. 1985. Controlled
natural language interfaces (extended
abstract): The best of three worlds. In CSC
?85: Proceedings of the 1985 ACM thirteenth
annual conference on Computer Science,
pages 176?178, New York, NY.
Nadkarni, P. and C. Brandt. 1998. Data
extraction and ad hoc query of an
entity-attribute-value database. Journal
of the American Medical Informatics
Association, 5(6):511?527.
Petre, Marian. 1995. Why looking isn?t
always seeing: Readership skills and
graphical programming. Communications
of the ACM, 38(6):33?44.
Piwek, Paul. 2002. Requirements definition,
validation, verification and evaluation
of the clime interface and language
processing technology. Technical Report
ITRI-02-03, ITRI, University of Brighton.
Piwek, Paul, Roger Evans, Lynne Cahill,
and Neil Tipper. 2000. Natural language
generation in the MILE system. In
Proceedings of the IMPACTS in NLG
Workshop, pages 33?42, Schloss Dagstuhl,
Germany.
Popescu, Ana-Maria, Oren Etzioni, and
Henry Kautz. 2003. Towards a theory
of natural language interfaces to
databases. In IUI ?03: Proceedings of
the 8th international conference on
132
Hallett, Scott, and Power Composing Questions through Conceptual Authoring
Intelligent user interfaces, pages 149?157,
New York, NY.
Power, Richard and Donia Scott. 1998.
Multilingual authoring using feedback
texts. In Proceedings of 17th International
Conference on Computational Linguistics
and 36th Annual Meeting of the
Association for Computational Linguistics
(COLING-ACL 98), pages 1053?1059,
Montreal, Canada.
Power, Richard, Donia Scott, and Roger
Evans. 1998. What you see is what you
meant: direct knowledge editing with
natural language feedback. In Proceedings
of the 13th Biennial European Conference on
Artificial Intelligence, pages 675?681,
Brighton, UK.
Rector, Alan, Jeremy Rogers, Adel Taweel,
David Ingram, Dipak Kalra, Jo Milan,
Robert Gaizauskas, Mark Hepple,
Donia Scott, and Richard Power. 2003.
CLEF?joining up healthcare with
clinical and post-genomic research. In
Second UK E-Science ?All Hands Meeting?,
Nottingham, UK.
Rivera, Carlos and Nick Cercone. 1998.
Hermes: Natural language access to a
medical database. Technical report
CS-98-03, University of Regina, Canada.
Scott, Donia, Richard Power, and Roger
Evans. 1998. Generation as a solution
to its own problem. In Proceedings
of the 9th International Workshop on
Natural Language Generation,
pages 256?265, Niagara-on-the-Lake,
Canada.
Shahar, Yuval and Cleve Cheng. 1999.
Intelligent visualization and exploration of
time-oriented clinical data. In Proceedings
of HICSS, pages 4019?4030, Maui, HI.
Soricut, R. and E. Brill. 2004. Automatic
question answering: Beyond the factoid.
In Proceedings of the HLT/NAACL 2004,
pages 57?64, Boston, MA.
Tang, Lappoon R. and Raymond J. Mooney.
2001. Using multiple clause constructors
in inductive logic programming
for semantic parsing. In EMCL ?01:
Proceedings of the 12th European Conference
on Machine Learning, pages 466?477,
London, UK.
Templeton, Marjorie and John Burger. 1983.
Problems in natural-language interface to
DBMs with examples from EUFID. In
Proceedings of the First Conference on Applied
Natural Language Processing, pages 3?16,
Morristown, NJ.
Tennant, Harry R., Kenneth M. Ross, and
Craig W. Thompson. 1983. Usable natural
language interfaces through menu-based
natural language understanding. In CHI
?83: Proceedings of the SIGCHI Conference
on Human Factors in Computing Systems,
pages 154?160, New York, NY.
TREC. 2005. Question answering data.
http://trec.nist.gov/data/qa/t2005
qadata.html.
Wilcox, Adam, George Hripcsak, and
Cynthia Chen. 1997. Creating an
environment for linking knowledge-based
systems to a clinical database: A suite of
tools. In Proceedings of AMIA Annual Fall
Symposium, pages 303?307, Nashville, TN.
Zhang, Guogen, Wesley W. Chu, Frank
Meng, and Gladys Kong. 1999. Query
formulation from high-level concepts
for relational databases. In UIDIS ?99:
Proceedings of the 1999 User Interfaces
to Data Intensive Systems, page 64,
Washington, DC.
133

Proceedings of the 2011 Workshop on Biomedical Natural Language Processing, ACL-HLT 2011, pages 174?181,
Portland, Oregon, USA, June 23-24, 2011. c?2011 Association for Computational Linguistics
 Unlocking Medical Ontologies for Non-Ontology Experts 
  Shao Fen Liang Donia Scott School of Computer Science,  School of Informatics,  The University of Manchester, Oxford Road,  The University of Sussex, Falmer,  Manchester, M13 9PL, UK Brighton, BN1 9QH, UK Fennie.Liang@cs.man.ac.uk D.R.Scott@sussex.ac.uk  Robert Stevens Alan Rector School of Computer Science,  School of Computer Science, The University of Manchester, Oxford Road,  The University of Manchester, Oxford Road, Manchester, M13 9PL, UK Manchester, M13 9PL, UK Robert.Stevens@cs.man.ac.uk Rector@cs.man.ac.uk  Abstract 
Ontology authoring is a specialised task requiring amongst other things a deep knowledge of the ontology language being used. Understanding and reusing ontologies can thus be difficult for domain experts, who tend not to be ontology experts. To address this problem, we have developed a Natural Language Generation system for transforming the axioms that form the definitions of ontology classes into Natural Language paragraphs. Our method relies on deploying ontology axioms into a top-level Rhetorical Structure Theory schema. Axioms are ordered and structured with specific rhetorical relations under rhetorical structure trees. We describe here an implementation that focuses on a sub-module of SNOMED CT. With some refinements on articles and layout, the resulting paragraphs are fluent and coherent, offering a way for subject specialists to understand an ontology?s content without need to understand its logical representation. 1 Introduction SNOMED CT (Spackman and Campbell, 1998) is widely mandated and promoted as a controlled vocabulary for electronic health records in several countries including the USA, UK, Canada and Australia. It is managed by the International Health Terminology Standards Development Organisation (IHTSDO) 1 . SNOMED describes diagnoses, procedures, and the necessary anatomy, biological process (morphology2) and the relevant organisms that cause disease for over 400,000 distinct concepts. It is formulated using a Description                                                        1 http://www.w3.org/TR/owl-features/ 2 Literally, the altered structure as seen by the pathologist, but usually the evidence for the process that gave rise to it. 
Logic (DL) (Baader et al, 2005). Description logics, usually in the form of the Web Ontology Language (OWL)3 have become a common means of representing ontologies. Description logics in general and SNOMED in particular have been recognised as difficult to understand and reuse (Namgoong and Kim, 2007;Power et al, 2009). Even with the more or less human readable, Manchester OWL Syntax (Horridge et al, 2006) and using tools such as Prot?g? (Knublauch et al, 2004) the task of understanding ontologies remains non-trivial for most domain experts. Consider, for example, a clinician seeking information about the concept of thoracic cavity structure 4  (i.e., anything in the chest cavity). SNOMED provides the following six axioms: 1. <Structure of thoracic viscus>  SubClassOf <Thoracic cavity structure> 2. <Intrathoracic cardiovascular structure> SubClassOf <Thoracic cavity structure> 3. <Mediastinal structure>  SubClassOf  <Thoracic cavity structure> 4. <Thoracic cavity structure>   SubClassOf  <Structure of respiratory   system and/or intrathoracic structure> 5. <Thoracic cavity structure>  SubClassOf <Thoracic structure> 6. <Thoracic cavity structure>  SubClassOf  <Body cavity structure> 
                                                       3 http://www.w3.org/TR/owl-features/ 4 The SNOMED identifier for this class is ID: SCT_43799004 
174
Although these axioms are shown with the more readable Manchester OWL syntax, the represented meaning of Thoracic cavity structure will not be easy for the typical clinician to decode.  Ontology concepts can be much more complex than those shown above. Not only can there be more axioms, but there can be nested axioms to an arbitrary depth. So the comprehension problem facing the typical clinician is even greater than that just described. It should be reduced, however, if the ontological content were presented in a more coherent, fluent and natural way ? for example as: A thoracic cavity structure is a kind of structure of the respiratory system and/or intrathoracic structure, thoracic structure and body cavity structure. It includes a structure of the thoracic viscus, an intrathoracic cardiovascular structure and a mediastinal structure. or, with added layout, as: A thoracic cavity structure is a kind of  ? structure of the respiratory system and/or intrathoracic structure, ? thoracic structure, and  ? body cavity structure.  It includes  ? a structure of  the thoracic viscus,  ? an intrathoracic cardiovascular structure and  ? a mediastinal structure. In these (human-generated) texts, the author has chosen to retain the general form of the anatomical terms as they appear in SNOMED, signalling them through the use of italics and introducing in places a definite article (e.g., ?structure of the thoracic viscus?. While these terms (particularly in the peculiar form they take in SNOMED names5) still present a barrier to non-subject-specialists, nevertheless the ontological content rendered as natural language is now much more accessible to non-ontology specialists.  Using natural language descriptions is obviously one way of improving the transparency of ontologies. However, authoring such descriptions                                                        5  To reduce this problem somewhat, we use here the ?preferred term? for given SNOMED names, but even these can be quite peculiar, e.g., ?renal hypertension complicating pregnancy, childbirth and the puerperium - delivered with postnatal complication?. 
is tedious and time-consuming to achieve by hand. This is clearly an area where automatic generation could be beneficial. With this in mind, we have built a verbaliser that renders SNOMED concepts as fluent natural language paragraphs.  2 Mapping SNOMED to a Representation of Coherent Discourse Our goal is to use standard techniques for natural language generation (NLG) to generate fluent paragraph-sized texts for SNOMED concepts automatically.  Verbalisation is a two-staged process of deciding what to say and then how to say it. In our work the first of these is a non-issue: the content of our verbalisation will be SNOMED concepts. Our focus is therefore on deciding how to express the content. As with any NLG system, our task begins by organising the input content in such a way as to provide a structure that will lead to coherent text, as opposed to a string of apparently disconnected sentences. Given the nature of our problem, we need to focus on the semantics of the discourse that can accommodate the nature of ontology axioms. For this purpose, we have chosen to use Rhetorical Structure Theory (RST) (Mann and Thompson, 1987;Mann and Thompson, 1988), as a mechanism for organising the ontological content of the SNOMED input.   RST is a theory of discourse that addresses issues of semantics, communication and the nature of the coherence of texts, and plays an important role in computational methods for generating natural language texts (Hovy, 1990;Scott and Souza, 1990;Mellish et al, 1998;Power et al, 2003). According to the theory, a text is coherent when it can be described as a hierarchical structure composed of text spans linked by rhetorical relations that represent the relevance relation that holds between them  (among the set of 23 relations are EVIDENCE, MOTIVATION, CONTRAST, ELABORATION, RESULT, CAUSE, CONDITION, ANTITHESIS, ALTERNATIVE, LIST, CONCESSION and JUSTIFICATION). Relations can be left implicit in the text, but are more often signalled through discourse markers ? words or phrases such as ?because? for EVIDENCE, ?in order to? for ENABLEMENT, ?although? for ANTITHESIS,  
175
 Figure 1: axioms and their relations to the class Thoracic cavity structure  ?but? for CONCESSION, ?and? for LIST, ?or? for ALTERNATIVE, etc. (Sporleder and Lascarides, 2008;Callaway, 2003). They can also be signalled by punctuation (e.g., a colon for ELABORATION, comma between the elements of  LIST, etc.).  In RST, text spans are divided into a schema, containing either a nucleus (N) and satellite (S), or two or more nuclei. Nuclei contain the information that is critical to the communicative message; satellites contain less critical information, which support the statements of their nuclei. The relations among nuclei and satellites are often expressed as: RELATION(N,N)  RELATION(N,S) These expressions conveniently take the same form as those expressing the types of ontology axiom, e.g.: SubClassOf(A, B) EquivalentClasses(C, D) where, SubClassOf and EquivalentClasses express relations between A and B, and C and D. This suggests that with careful selection of RST relations, and applying appropriate discourse markers, ontologies can be represented as RST structures, and generated as natural language paragraphs that are not far from human written text.  To investigate the feasibility of this proposal, we have experimented with feeding axioms into RST trees, and have achieved a positive outcome. For example, the six axioms of the thoracic cavity structure concept that we have seen earlier can be organised into two groups of relations as shown in Figure 1. In the upper group are the super-classes of the thoracic cavity structure class, and in the lower are the sub-classes. This way of grouping the axioms can better present their relations to the class. 
This structure can now be transformed into the RST tree shown in Figure 2, where the most important element of the message is the class Thoracic cavity structure, and this forms the main nucleus of the RST tree. The remaining content is related to this through an ELABORATION relation, the satellite of which is composed of two items of a multinucleus LIST, each of which is itself a LIST. This structure can be expressed textually as (among others) the two natural language descriptions we have shown earlier. These texts satisfy the requirement of coherence (as defined by RST), since each part bears a rhetorical relation to the other, and the entire text is itself spanned by a single rhetorical relation.  Our exploration of RST has shown that some relations map well to the characteristic features of ontology axioms. For example: ? the LIST relation captures well those cases where a group of axioms in the ontology bear the same level of relation to a given class; ? the ELABORATION relation applies generally to connect different notions of axioms to a class (i.e., super-, sub- and defining- classes), in order to provide additional descriptive information to the class; ? the CONDITION relation generally applies in cases where an axiom has property restrictions.  We also found that some rhetorical relations appear to bear a one-to-one mapping with logical forms of axioms, such as ALTERNATIVE to the logical or, and LIST to the logical and. Our experience and the evidence over many practical cases have indicated that the full set of rhetorical relations is unlikely to be applied for ontology verbalisation. In particular, the set of so-called presentational relations are unlikely to apply, as ontology authors do not normally
176
 Figure 2: RST tree of the class Thoracic cavity structure with six axioms  create comparisons or attempt to state preferences amongst classes. (For example, SNOMED has no comparison operator between different treatments of diseases).  In addition, even within the set of informational relations (Moser and Moore, 1996), there are several that will not be found in ontologies. For example, since each axiom in an ontology is assumed to be true, using one axiom as an EVIDENCE of another axiom would be redundant. Similarly, using one axiom to JUSTIFY another axiom is not a conventional way of building ontologies. 3 Applying RST Our investigations have shown that it is possible to build a top-level RST schema to cover all axioms with different meanings related to a class (see Figure 3). In SNOMED, axioms relating to a concept (i.e., class) can be either direct or indirect. Direct axioms describe the topic class directly, in which the topic class is the first class appearing in those axioms. Indirect axioms provide extra information, typically about how a class is used with other classes. For example, the axiom <Structure of thoracic viscus>   SubClassOf(<Structure of viscus> and  <Thoracic cavity structure>) can be placed as direct information about structure of thoracic viscus; it can also be placed as indirect information about Structure of viscus or Thoracic cavity structure.  
Within the categories of direct and indirect information, axioms are also classified as either simple or complex. This distinction allows us to control the length of the verbalisation, since most complex axioms tend to be translated into longer sentences, involving as they do more properties and value restrictions.  Simple axioms, on the other hand, describe only class relations, the length of which can be better controlled.  For a given SNOMED class, our verbalisation process starts with its super-, sub- and equivalent-classes, within an ELABORATION relation.  The use of the ELABORATION relation allows the first part of the text to connect all classes relating to the topic class; the second part then starts to introduce more complex information directly related to the topic class. The ELABORATION relation is used until all the direct information has been included. Next the CONCESSION relation is applied to connect direct and indirect information. Additionally, each indirect axiom should have its own subject, and therefore, they cannot be combined smoothly into a single sentence. We therefore use LIST as the relation for these axioms, since they are equally weighted, and changing the order among them does not affect the meaning of the whole paragraph. Every complex axiom is translated using a CONDITION relation. This is because complex axioms contain conditional information to their subject class. For example: <Disorder of soft tissue of thoracic cavity> EquivalentTo(<Disorder of soft tissue of    body cavity>          and  (<RoleGroup> some 
177
  Figure 3: Top-level RST schema for SNOMED    (<Finding site> some     <Thoracic cavity structure>))       and (<RoleGroup> some     (<Finding site> some     <Soft tissues>))) The condition in this axiom starts from the first ?and? in the fourth line and extends to the end of the axiom.  This condition needs to be attached to the class Disorder of soft tissue of body cavity to be equivalent to the Disorder of soft tissue of thoracic cavity class. We apply this rule to all complex axioms in an ontology. 4 Verbalising Individual Axioms We use a template-based technique for verbalising the axioms as sentences. We have carefully selected translations of the SNOMED expressions. Our choice has been driven by an attempt to translate each axiom so as to preserve the meaning in the ontology and to avoid introducing misleading information. For example, the convention within ontologies is to conceptualise super-classes as an ?is a? relation. However, translating this term as the English string ?is a? can lead to misunderstanding, since the English expression can also be used to mean ?equal to?. Clearly, though, a class is not equal to its super-class. In this context, a more accurate translation is 
?is a kind of?.  We show some of these translations in Table 1.  Relation to the topic class X Translation wording With its simple super-class  X is a kind of ? With its complex super-class X is a kind of ? that ? With its simple sub-class X includes ? With its simple equivalent class X is defined as ?  With its complex equivalent class X is defined as ? that   Table 1: Translations for axiom types  Consider for example, the SNOMED content: <Benign hypertensive renal disease>   SubClassOf <Hypertensive renal disease>  <Benign arteriolar nephrosclerosis>   SubClassOf <Benign hypertensive renal     disease>  <Benign hypertensive heart AND renal  disease>   SubClassOf <Benign hypertensive renal     disease>  <Benign hypertensive renal disease>   SubClassOf <Hypertensive renal disease>  
178
  and (<Finding site> some     <Kidney structure>)  <Benign arteriolar nephrosclerosis>   SubClassOf <Benign hypertensive renal     disease>    and <Arteriolar nephrosclerosis>  <Benign hypertensive heart AND renal  disease>    EquivalentTo<Benign hypertensive renal     disease>    and <Benign hypertensive heart     disease>    and <Hypertensive heart AND     renal  disease>  Our generator describes Benign hypertensive renal disease with its super-class as ?Benign hypertensive renal disease is a kind of hypertensive renal disease.? and with its sub-classes as ?Benign hypertensive renal disease includes benign arteriolar nephrosclerosis and benign hypertensive heart and renal disease.? There are two sub-classes in the above sentence, and we have signalled their connection (in a LIST relation) with ?and? as the discourse marker. In those cases where there are more than two sub-classes, we use instead a comma ?,? except for the last mentioned, where we introduce ?and?. The same approach is applied to super-classes.  In those cases where a class has both super- and sub-classes to describe, we introduce the second sentence with ?It? thus achieving better linguistic cohesion by avoiding having to repeat the same subject from the first sentence.  To bridge simple-direct and complex-direct axioms, we use ?Additionally? to signal the introduction of more information relevant to the topic.  For example to continue from the above two sentences, we have  ?Additionally, benign hypertensive renal disease is a kind of hypertensive renal disease that has a finding site in a kidney structure.? All direct information should have been consumed at this point, and we now need some bridging expression to signal the introduction of the indirect axioms. For this we use ?Another relevant aspect of? or ?Other relevant aspects of?, depending on the number of axioms in the set. Continuing with our example, we now have 
?Other relevant aspects of benign hypertensive renal disease include the following: benign arteriolar nephrosclerosis is a kind of benign hypertensive renal disease and arteriolar nephrosclerosis; benign hypertensive heart and renal disease is defined as benign hypertensive renal disease, benign hypertensive heart disease and hypertensive heart and renal disease.? The improved transparency of the underlying ontological content can be clearly demonstrated by comparison with the SNOMED input from which it is derived. The output that we have shown so far has all been generated as running text with minimal formatting except for the use of italic face for SNOMED labels. This works well for simple examples, but as can be seen from the previous example, readability becomes increasingly challenged as the expressions become longer. For this reason, we have also included in our system the facility to use layout to convey the logical structure of the ontological content. For example, the content shown above can also be generated as  ?Benign hypertensive renal disease is a kind of hypertensive renal disease. It includes ? benign arteriolar nephrosclerosis  and ? benign hypertensive heart and renal disease. Additionally, benign hypertensive renal disease is a kind of hypertensive renal disease that has a finding site in a kidney structure. Other relevant aspects of benign hypertensive renal disease include the following:  ? benign arteriolar nephrosclerosis is defined as benign hypertensive renal disease and arteriolar nephrosclerosis;  ? benign hypertensive heart and renal disease is defined as benign hypertensive renal disease, benign hypertensive heart disease and hypertensive heart and renal disease.? 5 Issues Related to Fluency The quality of a text, whether human- or machine- generated, is to a large extent determined by its fitness for purpose. For example, the characteristics of a scientific article, a newspaper article or a twitter will be rather different, even though they may convey the same ?message?.  The same is true for natural language descriptions of 
179
ontological content, which can range from the fully-fluent to the closely literal (e.g., something likely to be thought of as a kind of ?SNOMED-ese?), depending on whether it is intended, say, for inclusion in a narrative summary of an electronic patient record (Hallett et al, 2006) or for ontology developers or users who want to know the precise ontological representation of some part of the ontology.  So far, our aim has been to generate descriptions that fall into the latter category. For this purpose we retain the full expressions of the pseudo-English labels found in the official SNOMED Descriptions document6, representing them within our generation process as ?quotes? (Mellish et al, 2006) and signalling them through the use of italics. The texts still need to be grammatical, however, and achieving this can be challenging. In what follows we give a few examples of why this is so. It is a convention of ontology design to treat each class as singular; we follow this convention, introducing each class with the indefinite article.  So, for example, the SNOMED labels <Intrathoracic cardiovascular structure> and < Structure of thoracic viscus> can be expressed straightforwardly as ?a structure of thoracic viscus? and ?an intratrathoracic cardiovascular structure?.  However, matters are not so simple. For example,  <Heart structure> will require the definite article (?the heart structure?) and while  <Structure of thoracic viscus> will attract an indefinite article at its front, it  would read much better if it also had a definite article within it, giving ?a structure of the thoracic viscus?.  A similar story holds for <Abdomen and pelvis> which properly should be ?the abdomen and pelvis? or ?the abdomen and the pelvis?. Achieving this level of grammaticality will rely on knowledge that, for example, the human body contains only one heart and abdomen. Interestingly, this information is not captured within the SNOMED                                                        6 http://www.nlm.nih.gov/research/umls/licensedcontent/snomedctarchive.html 
ontology, and so external resources will be required.  Additionally, introducing articles within the labels (as in ?abdomen and the pelvis?, above) will require some level of natural language interpretation of the labels themselves.   The same applies to number. While we currently follow the SNOMED convention of describing entities in the singular, there are occasions where the plural is called for. For example: <Abdominal vascular structure>  SubClassOf <Abdomial structure>   SubClassOf <Lower body part            structure> <Abdominal cavity structure>  SubClassOf <Abdominal structure>   SubClassOf <Lower body part            structure> would be better expressed as ?Lower body part structures include all abdominal structures?, instead of as currently ?A lower body part structure includes an abdominal structure?. Another issue to consider is the roles of properties in SNOMED. This problem can be characterised by the following example:  <Hypertension secondary to kidney transplant>   EquivalentTo (<Hypertension associated     with transplantation>       and (<After> some <Transplant of    kidney>))> which is currently verbalised as  Hypertension secondary to kidney transplant is defined as hypertension associated with transplantation that has an after in a transplant of kidney. In SNOMED, the property after is used to give an after-effect (i.e., ?Hypertension associated with transplantation? is an after-effect of a kidney transplant), and for a non-SNOMED expert, this meaning is not at all clear in the generated text. This applies to many properties in SNOMED. Consider for example, the properties ?finding site? and ?clinical course? as in: ?Chronic heart disease is defined as a chronic disease of cardiovascular system that is a heart disease, and has a clinical course in a chronic.? and ?Abdominal organ finding is a general finding of abdomen that has a finding site in a structure of abdominal viscus.? 
180
The extent to which issues such as these are treated within the generation process will, as we mentioned before, be a matter of how fluent the text needs to be for a given purpose. 6 Conclusion We have described a method for generating coherent and fairly fluent natural language descriptions of ontologies, and have shown how the method can be applied successfully to SNOMED CT, a medical terminology whose use is widely mandated. Through the application of Rhetorical Structure Theory, the ontological content is organised into a discourse schema that allows us to generate appropriate discourse markers, pronouns, punctuation and layout, thereby making it more easily accessible to those who are not fully familiar with the ontology language in use.  In its current form, the system is aimed at readers who care how the SNOMED is constructed ? for example, those wishing to know the precise meaning of a given class. We believe there is no single solution to satisfying a wider range of user interests, and thus of text types. While we continue to work towards improving the output of our system, evaluating the output with non-ontology specialists, and testing our method with other ontologies and ontology languages, achieving fully fluent natural language is beyond the scope of our system. We are not at this point overly concerned by this limitation, as the need for clarity and transparency of ontologies is, we believe, more pressing than the need for fully fluent natural language descriptions. Acknowledgments This work has been undertaken as part of the Semantic Web Authoring Tool (SWAT) project (see www.swatproject.org), supported by the UK Engineering and Physical Sciences Research Council (EPSRC) grant EP/G032459/1 to the University of Manchester, the University of Sussex, and the Open University.  References Franz Baader, Ian Horrocks and Ulrike Sattler. 2005. Description logics as ontology languages for the 
semantic web, Lecture Notes in Artificial Intelligence, 2605: 228-248. Charles B. Callaway. 2003. Integrating discourse markers into a pipelined natural language generation architecture, 41st Annual Meeting on Association for Computational Linguistics, 1: 264-271. Catalina Hallett, Richard Power and Donia Scott. 2006. Summarisation and Visualisation of e-Health Data Repositories. UK E-Science All-Hands Meeting, pages 18-21.  Matthew Horridge, Nicholas Drummond, John Goodwin, et al 2006. The Manchester OWL syntax. 2006 OWL: Experiences and Directions (OWLED?06).  Holger Knublauch, Ray W. Fergerson, Natalya Fridman Noy, et al 2004. The Prot?g? OWL plugin: an open development environment for Semantic Web applications. International Semantic Web Conference, pages 229-243.  William C. Mann and Sandra A. Thompson. 1987. Rhetorical Structure Theory: a theory of text organization, USC/Information Sciences Institute Technical Report Number RS-87-190 Marina del Rey, CA. William C. Mann and Sandra A. Thompson. 1988. Rhetorical Structure Theory: toward a functional theory of text organisation, Text, 8(3): 243-281. Chris Mellish, Donia Scott, Lynne Cahill Daniel Paiva, et al 2006. A reference architecture for natural language generation systems, Natural Language Engineering, 12(1): 1-34. Megan Moser and Johanna D. Moore. 1996. Toward a synthesis of two accounts of discourse structure, Computational Linguistics, 22(3): 409-420. Hyun Namgoong and Hong-Gee Kim. 2007. Ontology-based controlled natural language editor using CFG with lexical dependency. 6th international, the Semantic Web, and 2nd Asian Conference on Asian Semantic Web Conference, pages 353-366. Springer Verlag Berlin, Heidelberg. Richard Power, Robert Stevens, Donia Scott, et al 2009. Editing OWL through generated CNL. 2009 Workshop on Controlled Natural Language (CNL'09), Marettimo, Italy.  Kent A. Spackman and Keith E. Campbell. 1998. Compositional concept representation using SNOMED: Towards further convergence of clinical terminologies, Journal of the American Medical Informatics Association: 740-744. Caroline Sporleder and Alex Lascarides. 2008. Using automatically labelled examples to classify rhetorical relations: an assessment, Natural Language Engineering, 14(3): 369-416.   
181
INLG 2012 Proceedings of the 7th International Natural Language Generation Conference, pages 141?145,
Utica, May 2012. c?2012 Association for Computational Linguistics
KBGen ? Text Generation from Knowledge Bases as a New Shared Task
Eva Banik1, Claire Gardent2, Donia Scott3, Nikhil Dinesh4, and Fennie Liang5
1ebanik@comp-ling.co.uk, Computational Linguistics Ltd, London, UK
2claire.gardent@loria.fr, CNRS, LORIA, Nancy, France
3D.R.Scott@sussex.ac.uk, School of Informatics, University of Sussex, Brighton, UK
4dinesh@ai.sri.com, SRI International, Menlo Park, CA
5fennie.liang@cs.man.ac.uk, School of Computer Science, University of Manchester, UK
1 Introduction
In this paper we propose a new shared task, KB-
Gen, where the aim is to produce coherent descrip-
tions of concepts and relationships in a frame-based
knowledge base (KB). We propose to use the AURA
knowledge base for the shared task which contains
information about biological entities and processes.
We describe how the AURA KB provides an appli-
cation context for NLG and illustrate how this ap-
plication context generalizes to other biology KBs.
We argue that the easy availability of input data and
a research community ? both domain experts and
knowledge representation experts ? which actively
uses these knowledge bases, along with regular eval-
uation experiments, creates an ideal scenario for a
shared task.
2 Application Context and Motivation
One of the research challenges in the knowledge rep-
resentation community is to model complex knowl-
edge in order to be able to answer complex ques-
tions from a knowledge base (see e.g. the Deep
Knowledge Representation Challenge Workshop at
KCAP 20111). There are several applications of
such knowledge bases, perhaps most recently and
most prominently in the bioinformatics and educa-
tional informatics domain, where there are available
knowledge bases and reasoners that help scientists
answer questions, explain connections between con-
cepts, visualize complex processes, and help stu-
dents learn about biology. These uses of a knowl-
edge base are however difficult to implement with-
1http://sites.google.com/site/dkrckcap2011/home
out presenting the resulting answers and explana-
tions to the user in a clear, concise and coherent way,
which often requires using natural language.
2.1 The AURA Knowledge Base
The AURA biology knowledge base developed by
SRI International (Gunning et al, 2010) encodes in-
formation from a biology textbook (Reece et al,
2010)2. The purpose of this knowledge base is
to help students understand biological concepts by
allowing them to ask questions about the material
while reading the textbook. The KB is built on top
of a generic library of concepts (CLIB, Barker et al,
2001), which are specialized and/or combined to en-
code biology-specific information, and it is orga-
nized into a set of concept maps, where each con-
cept map corresponds to a biological entity or pro-
cess. The KB is being encoded by biologists and
currently encodes over 5,000 concept maps.
The AURA KB and its question answering sys-
tem is integrated with an electronic textbook appli-
cation3. The applicaton allows the students to ask
complex questions about relationships between con-
cepts, which are answered by finding a possible path
between the two concepts. The results are presented
to the students as graphs, for example the answer
produced by the system in response to the question
?what is the relationship between glycolysis and glu-
cose?? is illustrated in Fig 1.
These graphs are simplified representations of
2The development of the AURA knowledge base and related
tools and applications was funded by Vulcan Inc.
3A demo of the application will be presented in the demo
session at INLG 2012
141
Figure 1: Relationship between glycolysis and glucose
a path in the knowledge base that connects two
concepts, because presenting the full concept map
where the path was found would make it difficult for
the students to clearly see the relationship. However,
this simplification often obscures the connection by
not showing relevant information.
Given the inclusion of a few more relations from
the concept map of glycolysis (Fig 2), the answer to
the question could be generated as a complex sen-
tence or a paragraph of text, for example: ?Phos-
phorylation of glucose is the first step of the energy
investment phase of glycolysis? or ?In the first step
of the energy investment phase of glycolysis, called
phosphorylation, hexokinase catalyses the synthesis
of glucose-6-phosphate from glucose and a phos-
phate ion.?
2.2 BioCyc
Another situation in which graph-based representa-
tions are presented to the user is metabolic pathway
and genome databases, such as the BioCyc knowl-
edge base. BioCyc describes the genome, metabolic
pathways, and other important aspects of organisms
such as molecular components and their interactions
and currently contains information from 1,763 path-
Figure 2: Concept map of glycolysis
way/genome databases4.
When users query parts of the BioCyc knowledge
base, the system automatically produces a graph
to visualize complex biological processes. For ex-
ample, Fig 3 illustrates an automatically generated
graph from the knowledge base which shows the
process of glycolysis in an E. coli cell. Hovering the
mouse over the ? and 	 signs on the graph brings
up popups with additional information about gene
expressions , detailed chemical reactions in the pro-
cess, enzymes activated by certain chemicals, etc..
Figure 3: The process of glycolysis in E.coli
3 Input Data for Generation
Although there is a clear benefit from visualizing
complex processes in a graph form, one also has to
4http://www.biocyc.org
142
be well-versed in the notation and details of biolog-
ical processes in order to make sense of these rep-
resentations. Students of biology and non-experts
would certainly benefit from a more detailed ex-
planation of the process, presented as a few para-
phraphs of text along with graphs to emphasize the
most salient features of processes.
The paths and relations returned by reasoning al-
gorithms also present a good opportunity to pro-
vide inputs for natural language generation. These
chunks of data typically contain the right amount of
data because they consist of the information needed
to answer a question or describe a concept. Ad-
ditionally, many knowledge bases (including both
BioCyc and AURA) are encoded in a frame-based
representation, which has the advantage that frames
naturally correspond to linguistic units.
Frame-based systems (Minsky, 1981) are based
around the notion of frames or classes which repre-
sent collections of concepts. Each frame has an as-
sociated set of slots or attributes which can be filled
either by specific values or by other frames. Intu-
itively, frames correspond to situations, and each ter-
minal in the frame corresponds to answers to ques-
tions that could be asked about the situation, in-
cluding the participants in the situation, causes and
consequences, preceding and following situations,
purpose, etc. Frame-based representations may ei-
ther contain frames of generic concepts or instance
frames which represent information about particular
instances. Frames also have a kind-of slot, which
allows the assertion of a frame taxonomy, and the
inheritance of slots.
In the knowledge representation community,
frame-based representations are popular because
they make the encoding process more intuitive.
From a natural language generation perspective,
each frame (or a set of slots) corresponds to a lin-
guistic unit (sentence, noun phrase, clause, verb
phrase, etc), depending on the type of the frame and
the slots it contains. This organization of concepts
and relations in the knowledge base makes it easier
to select chunks of data from which coherent texts
can be generated.
Slots in these frame-based representations also
naturally correspond to the kind of flat semantic
representations and dependency structures that have
served as input to surface realization (Koller and
Striegnitz, 2002; Carroll and Oepen, 2005; White,
2006; Gardent and Kow, 2007; Nakatsu and White,
2010).
4 The shared task
We propose two tracks for the KBGen shared task: a
?complex surface realization? track, where the task
is to generate complex sentences from shorter in-
puts, and a ?discourse generation? track, where the
task is to generate longer texts made up from several
paragraphs. In the following, we describe the data
set from which the input to generation will be se-
lected; the methology we plan to use to extract text
size input for the generation challenge; and the two
tracks making up the KBGen challenge.
4.1 The AURA knowledge base as Input
Dataset
We propose to use the AURA knowledge base as
input data for the shared task for several reasons.
AURA contains a number of relations and therefore
provides varied input for generation5. The AURA
knowledge base contains linguistic resources that
can be used for generation (a morphological lexi-
con and a list of synonyms for each concept) and
the electronic textbook provides an application con-
text to evaluate the generated texts. There are regular
evaluation efforts to assess the educational benefits
of using the textbook application, and the next round
of these experiments will involve over 400 students
and biology teachers who will use the application
over an extended period of time. The evaluation of
the outputs generated for the shared task could form
part of these experiments.
4.2 Selecting Text Size Content for the Shared
Task
We propose to select data from the knowledge base
manually or semi-automatically, by selecting a set
of concepts to be described and including relevant
relations associated with the concepts. We would
first select a set of concept maps that are encoded in
most detail and have been reviewed by the encoders
for quality assurance. The input data for each con-
cept will then be a manually selected set of frames
5If there is interest, the systems developed to generate from
AURA could also be applied to the BioCyc data, which has a
more restricted set of relations.
143
from the concept map. The selected relations will be
reviewed one more time for quality and consistency
to filter out any errors in the data.
If there is interest in the community, we can
also envision a content selection challenge which
could provide input to the generation task. Although
frames in the knowledge base correspond well to
chunks of data for generation of descriptions, con-
tent selection for other communicative goals is far
from a trivial problem. One such challenge could
be for example comparing two concepts, or explain-
ing the relation between a process and its sub-type
(another process that is taxonomically related, but
different in certain parts).
4.3 Complex Surface Realization Track
For the complex surface realization track, a small
number of frames would be selected from the knowl-
edge base along with a small number of other rel-
evant relations (e.g., important parts or properties
of certain event participants, or certain relations be-
tween them, depending on the context). The output
texts to be generated would be complex sentences
describing the central entity/event in the data, or the
relationship between two concepts, such as the gly-
colysis example in section 2.1. This task would
involve aggregation and generating intrasentential
pronouns governed by syntax where necessary, but
it would not require the generation of any discourse
anaphora or referring expressions.
This track will differ from the deep generation
track of the Surface Realization Shared Task both in
form and in content. The form of the KBGen input
is a concept map extracted from an ontology rather
than a deep semantics extracted by conversion from
dependency parse trees. Similarly, its content is that
of a biology knowledge base rather than that of the
Penn Treebank textual corpus.
4.4 Discourse Generation Track
Inputs for the discourse generation task would in-
clude most frames from the concept map of an entity
or process. The output would be longer paragraphs
or 2-3 paragraphs of text, typically a description of
the subevents, results, etc, of a biological process,
or the description of the structure and function of an
entity. This task would involve text structuring and
the generation of pronouns.
4.5 Lexical Resources and potential
multilingual tracks
The knowledge base provides a mapping from con-
cepts to lexical items and a list of synonyms. It
also provides information about how specific slots
in event frames are mapped onto prepositions.
If there is interest in the community, the lex-
ical resources corresponding to the selected con-
tent could be translated to different languages semi-
automatically: the translation could be attempted
first automatically, with the help of available biol-
ogy/medical lexicons, and then the output would be
hand-corrected. Candidate languages for a multilin-
gual challenge would be French and Spanish. To
run the multilingual tracks we would need to create
multilingual development and test data and would
need to have access to French/Spanish speaking bi-
ologists.
5 Evaluation
Evaluation of the generated texts could be done both
with automatic evaluation metrics and using human
judgements. Automatic evaluation metrics could in-
clude BLUE (Papineni et al, 2002) or measuring
Levenshtein distance (Levenshtein, 1966) from hu-
man written texts. To obtain human judgements, bi-
ologists will be asked to compose texts conveying
the same content as the input for the generated texts.
The human-written texts will be presented to sub-
jects along with the generated outputs to obtain flu-
ency judgements, but the subjects will not be told
which kind of text they are judging. The evaluation
campaign could be coordinated with the evaluation
of the knowledge base and the electronic textbook
application, and/or publicized on social networking
sites or mechanical turk.
6 Next Steps
We invite feedback on this proposal with the aim
of refining our plan and discussing a suitable input
representation for the shared task in the next few
months. If there is sufficient interest in the shared
task, we would make the input data available in the
agreed format in late 2012, with the first evaluation
taking place in 2013. We would like to hear any
comments/suggestions/critisisms about the plan and
we are actively looking for people who would be in-
144
terested in getting involved in planning and running
the challenge.
References
Barker, K., B. Porter, and P. Clark. 2001. A library of
generic concepts for composing knowledgebases.
In Proceedings of the 1st Int Conf on Knowledge
Capture (K-Cap?01), 14?21.
Carroll, J., and S. Oepen. 2005. High efficiency real-
ization for a wide-coverage unification grammar.
2nd IJCNLP .
Gardent, C., and E. Kow. 2007. A symbolic ap-
proach to near-deterministic surface realisation
using tree adjoining grammar. In In 45th Annual
Meeting of the ACL.
Gunning, D., V. K. Chaudhri, P. Clark, K. Barker,
Shaw-Yi Chaw, M. Greaves, B. Grosof, A. Leung,
D. McDonald, S. Mishra, J. Pacheco, B. Porter,
A. Spaulding, D. Tecuci, and J. Tien. 2010.
Project halo update - progress toward digital aris-
totle. AI Magazine Fall:33?58.
Koller, Alexander, and Kristina Striegnitz. 2002.
Generation as dependency parsing. In Proceed-
ings of ACL.
Levenshtein, Vladimir I. 1966. Binary codes capable
of correcting deletions, insertions, and reversals.
Soviet Physics Doklady 10:707?710.
Minsky, Marvin. 1981. Mind design, chapter A
Framework for Representing Knowledge, 95?
128. MIT Press.
Nakatsu, Crystal, and Michael White. 2010. Gen-
erating with discourse combinatory categorial
grammar. submitted to Linguistic Issues in Lan-
guage Technology .
Papineni, Kishore, Salim Roukos, Todd Ward, and
Wei jing Zhu. 2002. Bleu: a method for automatic
evaluation of machine translation. 311?318.
Reece, Jane B., Lisa A. Urry, Michael L. Cain,
Steven A. Wasserman, Peter V. Minorsky, and
Robert B. Jackson. 2010. Campbell biology. Pear-
son Publishing.
White, Michael. 2006. Ccg chart realization from
disjunctive inputs. In Proceedings of the Fourth
International Natural Language Generation Con-
ference, 12?19. Sydney, Australia: Association
for Computational Linguistics.
145
