Proceedings of the SIGDIAL 2013 Conference, pages 457?461,
Metz, France, 22-24 August 2013. c?2013 Association for Computational Linguistics
Dialog State Tracking using Conditional Random Fields
Hang Ren, Weiqun Xu, Yan Zhang,Yonghong Yan
The Key Laboratory of Speech Acoustics and Content Understanding
Institute of Acoustics, Chinese Academy of Sciences
21 North 4th Ring West Road, Beijing, China, 100190
{renhang, xuweiqun, zhangyan, yanyonghong}@hccl.ioa.ac.cn
Abstract
This paper presents our approach to dialog
state tracking for the Dialog State Track-
ing Challenge task. In our approach we
use discriminative general structured con-
ditional random fields, instead of tradi-
tional generative directed graphic models,
to incorporate arbitrary overlapping fea-
tures. Our approach outperforms the sim-
ple 1-best tracking approach.
1 Introduction
Spoken dialog systems have been widely devel-
oped in recent years. However, when dialogs are
conducted in noisy environments or the utterance
itself is noisy, it is difficult for machines to cor-
rectly recognize or understand user utterances. In
this paper we present a novel dialog state track-
ing method, which directly models the joint prob-
ability of hypotheses onN -best lists. Experiments
are then conducted on the DSTC shared corpus,
which provides a common dataset and an evalua-
tion framework
The remainder of this paper is organized as fol-
lows. Section 2 reviews relevant studies in dia-
log state tracking. Section 3 introduces our new
approach and presents the model and features we
used in detail. Section 4 describes experiment set-
tings and gives the result. Section 5 concludes this
paper with a discussion for possible future direc-
tions.
2 Previous Work
For the task of dialog state tracking, previous
research focused on dynamic Bayesian models
(DBN)(Young et al, 2013). User goal, dialog his-
tory and other variables are modeled in a graphi-
cal model. Usually, Markov assumptions are made
and in each turn the dialog state is dependent on
the ASR outputs and the dialog state of the pre-
vious turn. Dependency on other features, such
as system action, dialog history could be assumed
as long as their likelihood is modeled. For a
POMDP-based dialog model, the state update rule
is as follows:
bt+1(st+1) = ?P (ot+1|st+1, at)?
st
P (st+1|st, at)bt(st) (1)
where bt(st) is the belief state at time t, ot+1 is the
observation at time t+ 1, at is the machine action.
Thus the dialog states are estimated incrementally
turn by turn.
Since each node has hundreds, or even thou-
sands, of possible assignments, approximation is
necessary to make efficient computation possible.
In POMDP-based dialog systems, two common
approaches are adopted (Young et al, 2013), i.e.,
N -best approximation and domain factorization.
In theN -best approach, the probability distribu-
tion of user goals are approximated using N -best
list. The hidden information state (HIS) model
(Young et al, 2010) makes a further simplification
that similar user goals are grouped into a single
entity called partition, inside which all user goals
are assigned the same probabilities. The Bayesian
update of dialog state (BUDS) model (Thomson
and Young, 2010) is a representative of the second
approach and adopts a different approximation
strategy, where each node is further divided into
sub-nodes for different domain concepts and in-
dependence assumptions of sub-nodes across con-
cepts are made. Recent studies have suggested
that a discriminative model may yield better per-
formance than a generative one (Bohus and Rud-
nicky, 2006). In a discriminative model, the emis-
sion part of the state update rule is modeled dis-
criminatively. Possible flawed assumptions in a
completely generative models could be mitigated
457
in this way, such as the approximation of obser-
vation probability using SLU scores (Williams,
2012a; Williams, 2012b).
3 Proposed Method
3.1 Discriminative State Tracking Model
Most previous methods model the distribution of
user goals for each turn explicitly, which can lead
to high computation cost. In our work, the joint
probability of all items on the N -best lists from
SLU is modeled directly and the state tracking re-
sult is generated at a post-processing stage. Thus
the state tracking problem is converted into a la-
beling task as is shown in equation 2, which in-
volves modeling the joint probability of the N -
best hypotheses.
bt(st) = P (H1,1, H1,2, ...,Ht,m?1, Ht,m) (2)
where Ht,m is a binary variable indicating the
truthfulness of the m-th hypothesis at turn t.
For each turn, the model takes into account all
the slots on theN -best lists from the first turn up to
the current one, and those slots predicted to be true
are added to the dialog state. The graphical model
is illustrated in figure 1. To predict dialog state at
turn t, the N -best items from turn 1 to t are all
considered. Hypotheses assigned true labels are
included in the dialog state. Compared to the DBN
approach, the dialog states are built ?jointly?. This
approach is reasonable because what the tracker
generates is just some combinations of all N -best
lists in a session, and there is no point guessing be-
yond SLU outputs. We leverage general structured
Conditional Random Fields (CRFs) to model the
probabilities of the N -best items, where factors
are used to strengthen local dependency. Since
CRF is a discriminative model, arbitrary overlap-
ping features can be added, which is commonly
considered as an advantage over generative mod-
els.
3.2 Conditional Random Fields
CRF is first introduced to address the problem
of label bias in sequence prediction (Lafferty et
al., 2001). Linear-chain CRFs are widely used to
solve common sequence labeling problem in nat-
ural language processing. General structured CRF
has also been reported to be successful in various
tasks (Sutton and McCallum, 2012).
In general structured CRF, factor templates are
utilized to specify both model structure and pa-
...
Hyp1
Hyp2
HypN
Turn t
Slot1=...
Slot2=...
...
Turn t-1
Figure 1: Dialog state update using CRFs, where
the 8 rectangles above denote N -best hypothe-
ses for each turn, and the box below represents
the dialog state up to the current turn. Con-
nections between rectangles denote ?Label-Label?
factors. ?Label-Observation? factors are not shown
for simplicity.
rameter tying (Sutton and McCallum, 2012). Fac-
tors are partitioned into a series of templates, and
factors inside each template share the same param-
eters.
p(y|x) = 1Z(x)
?
Cp?C
?
?c?Cp
?c(xc,yc; ?p), (3)
where C is the set of factor templates and x,y are
inputs and labels respectively. Template factors
are written as
?c(xc,yc; ?p) = exp
K(p)?
k=1
?pkfpk (xc,yc) (4)
and Z(x) is the normalizing function
Z(x) =
?
y
?
Cp?C
?
?c?Cp
?c(xc,yc; ?p) (5)
In the experiment we use Factorie1 to define and
train the model.
3.3 Model Structure and Features
In the model, slots in every N -best item up
to the current turn are represented as binary
variables. For simplification of data structure,
each slot in a single N -best item is extracted
and represented using different label vari-
ables, with the same rank indicating their
1Available from https://github.com/
factorie/factorie.
458
original places in the N -best list. For exam-
ple, the item slots: [from: Pittsburgh,
data: Tuesday], score: 0.85, rank: 2,
is converted to two slots: slots: [from:
Pittsburgh], score: 0.85, rank: 2 and
slots: [date: Tuesday], score: 0.85,
rank: 2. Label-label connections are specified
using factor templates between slot pairs, and
Label-observation templates are used to add
slot-wise features. Without label-label connection
the model is reduced to a maximum entropy
model, and with more connections added, the
graph tends to have loopy structures.
Two classes of feature sets (templates) in the ex-
periment are defined as follows.
(1) Label-Label factor templates are used to
strengthen the bond between certain slots.
Pairwise-slots of the same rank This template is
built for pairs of slots in a turn with the same
rank to bind their boolean assignment. To
avoid creating too many loops and make in-
ference efficient, the factors are added in such
an order that the slots involved in a single turn
are linked in a linear way.
Pairwise-slots with identical value Slots with
identical value may appear in the N -best
list for multiple times. Besides, user can
mention the same slot in different turns,
making these slots more reliable. Similar
ordering mechanism is utilized to avoid
redundant loops.
(2) Label-observation templates are used to add
features for the identification of the truthfulness of
slots.
SLU score and rank of slot The score generated
by the ASR and SLU components is a direct
indicator of the correctness degree of slots.
However, a slot?s true reliability is not neces-
sarily linear with its score. The relationship is
quite different for various ASR and SLU al-
gorithms, and scores produced by some ASR
are not valid probabilities. As we adopt a
data-driven approach, we are able to learn
this relationship from data. In addition to the
SLU score, the slot rank is also added to the
feature set.
Dialog history (grounding information) In
most spoken dialog systems, explicit and
implicit groundings are adapted to indicate
the correctness of the system belief. This
information is useful to determine the
correctness of slots. The grounding infor-
mation includes grounding type (implicit
or explicit grounding), user reply (negation
or confirmation) and corresponding SLU
scores.
Count of slots with identical value As previ-
ously mentioned, slots with identical values
can appear several times and slots with more
frequent occurrences are more likely to be
correct.
Domain-specific features Slots for some domain
concepts often have values with specific
forms. For example, in the DSTC data sets,
the route slots are usually filled with values
like ?61d?, ?35b?, and SLU often generates
noisy outputs like ?6d?, ?3d?. Thus the lexi-
cal form is a very useful feature.
Baseline Tracker The simple and fast 1-best
tracking algorithm is used as the baseline
tracker and exhibits a satisfying performance.
Thus the tracking result is added as an addi-
tional feature. This indicates the possibility
of combining tracking outputs from differ-
ent algorithms in this discriminative model,
which may improve the overall tracking per-
formance.
4 Experiment
4.1 Task and Data
The Dialog State Tracking Challenge (DSTC)2
aims at evaluating dialog state tracking algorithms
on shared real-user dialog corpus. In each dia-
log session, ASR and SLU results are annotated,
making it possible to conduct direct comparison
among various algorithms. For further details,
please refer to the DSTC handbook (Williams et
al., 2013b).
4.2 Corpus Preprocessing
The ASR and SLU components can generate many
noisy hypotheses which are completely wrong,
rendering the dialog corpus seriously imbalanced
at the level of slots (there are more wrong slots
than true slots). We use resampling to prevent
2http://research.microsoft.com/en-us/
events/dstc/
459
the model from biasing towards making negative
judgements. Before training, the total number of
correct slots in a set is counted, and equal num-
ber of wrong slots are sampled from the subset of
all the wrong slots. These chosen negative slots
plus all the positive slots together constitute the
effective slot set for model training, with remain-
ing slots fixed to their true value and regarded as
observed variables. To make full use of the dia-
log corpus, this process is repeated for eight times,
producing a bigger and balanced corpus.
4.3 Model Training
In the training phase, the log-likelihood function
is optimized using the LBFGS method with L2-
regularization. Loopy belief propagation is used
as the inference routine. It can be shown that for
factor graphs without loops, the marginal proba-
bilities produced by loopy belief propagation are
exact. Model selection is done according to the
log-likelihood on the development set.
4.4 Predicting and Tracking
For each dialog session, the predicted slot labels
are mapped to tracking results. To produce a N -
best list of tracking results, the top N configura-
tions of slots and corresponding probability scores
are generated. Gibbs sampling is adopted. The
sampling is repeated for 1000 times in each cor-
pus, after each sampling the configuration of slots
is mapped to certain tracking state. More efficient
inference routines, such as M-best belief propaga-
tion (Yanover and Weiss, 2004), could be utilized,
which would be suitable for practical real-time ap-
plication.
4.5 Results
After tracker outputs are generated based on the
sampling results, they are scored using evaluation
tools provided by the DSTC organizers. Several
metrics are evaluated, including precisions, ROC
performance, etc. Individual and joint slots are
scored respectively. And different schedules are
used, which indicats the turns included for evalu-
ation. Partial results are shown in table 1. A sys-
tematic analysis by the organizers is in the DSTC
overview paper (Williams et al, 2013a). The com-
plete challenge results can be found on DSTC
website. On the test sets of test1, test2 and test3,
the CRF-based model achieves better performance
than the simple baseline in most metrics. How-
ever, on test4, the performance degrades seriously
when there is a mismatch between training data
and test data, since test4 is produced by a different
group and does not match the training set. It shows
that the CRF-based model is very flexible and is
able to learn the properties of ASR and SLU, thus
adapting to a specific system. But it has a tendency
of overfitting .
Test1 Test4
Metric CRF BASE CRF BASE
ACC 0.987 0.983 0.960 0.986
L2 0.020 0.021 0.046 0.017
MRR 0.990 0.988 0.980 0.990
CA05 0.987 0.983 0.960 0.986
EER 0.015 0.983 0.021 0.012
Table 1: Results of slot ?Date? on Test1 and Test4
(schedule1 is used). The tracker used on Test4 is
trained on Test3. Details of the metrics can be
found in DSTC handbook(Williams et al, 2013b)
5 Conclusions and Future Directions
We proposed a CRF-based discriminative ap-
proach for dialog state tracking. Preliminary re-
sults show that it achieves better performance than
the 1-best baseline tracker in most metrics when
the training set and testing set match. This indi-
cates the feasibility of our approach which directly
models joint probabilities of the N -best items.
In the future, we will focus on the following
possible directions to improve the performance.
Firstly, we will enrich the feature set and add more
domain-related features. Secondly, interactions of
slots between dialog turns are not well modeled
currently. This problem can be alleviated by tun-
ing graph structures, which deservers further stud-
ies. Moreover, it is challenging to use online train-
ing methods, so that the performance could be im-
proved incrementally when more training samples
are available.
6 Acknowledgments
This work is partially supported by the Na-
tional Natural Science Foundation of China (Nos.
10925419, 90920302, 61072124, 11074275,
11161140319, 91120001), the Strategic Prior-
ity Research Program of the Chinese Academy
of Sciences (Grant Nos. XDA06030100,
XDA06030500), the National 863 Program (No.
2012AA012503) and the CAS Priority Deploy-
ment Project (No. KGZD-EW-103-2).
460
References
Dan Bohus and Alex Rudnicky. 2006. A ?k hypotheses
+ other? belief updating model. In Proceedings of
the 2006 AAAI Workshop on Statistical and Empiri-
cal Approaches for Spoken Dialogue Systems, pages
13?18, Menlo Park, California. The AAAI Press.
John Lafferty, Andrew Mccallum, and Fernando
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data. In Proc. 18th International Conf. on
Machine Learning, pages 282?289. Morgan Kauf-
mann, San Francisco, CA.
Charles A. Sutton and Andrew McCallum. 2012. An
introduction to conditional random fields. Founda-
tions and Trends in Machine Learning, 4(4):267?
373.
Blaise Thomson and Steve Young. 2010. Bayesian
update of dialogue state: A POMDP framework for
spoken dialogue systems. Computer Speech and
Language, 24(4):562?588.
Jason D. Williams, Antoine Raux, Deepak Ramachan-
dran, and Alan Black. 2013a. The dialog state track-
ing challenge. In Proceedings of the 14th SIGdial
workshop on Discourse and Dialogue.
Jason D. Williams, Antoine Raux, Deepak Ra-
machandran, and Alan Black. 2013b. Dia-
log state tracking challenge handbook. Avail-
able from http://research.microsoft.
com/apps/pubs/?id=169024.
Jason D. Williams. 2012a. Challenges and opportu-
nities for state tracking in statistical spoken dialog
systems: Results from two public deployments. Se-
lected Topics in Signal Processing, IEEE Journal of,
6(8):959 ?970.
Jason D. Williams. 2012b. A critical analysis of two
statistical spoken dialog systems in public use. In
SLT, pages 55?60. IEEE.
Chen Yanover and Yair Weiss. 2004. Finding the
m most probable configurations using loopy belief
propagation. Advances in Neural Information Pro-
cessing Systems, 16:289?296.
Steve Young, Milica Gas?ic?, Simon Keizer, Franc?ois
Mairesse, Jost Schatzmann, Blaise Thomson, and
Kai Yu. 2010. The hidden information state model:
A practical framework for POMDP-based spoken di-
alogue management. Computer Speech and Lan-
guage, 24(2):150?174.
Steve Young, Milica Gas?ic?, Blaise Thomson, and Ja-
son D. Williams. 2013. POMDP-based statistical
spoken dialog systems: A review. Proceedings of
the IEEE, 101(5):1160?1179.
461
Proceedings of the SIGDIAL 2014 Conference, pages 327?331,
Philadelphia, U.S.A., 18-20 June 2014.
c?2014 Association for Computational Linguistics
Markovian Discriminative Modeling for Dialog State Tracking
Hang Ren, Weiqun Xu, Yonghong Yan
The Key Laboratory of Speech Acoustics and Content Understanding
Institute of Acoustics, Chinese Academy of Sciences
21 North 4th Ring West Road, Beijing, China, 100190
{renhang, xuweiqun, yanyonghong}@hccl.ioa.ac.cn
Abstract
Discriminative dialog state tracking has
become a hot topic in dialog research com-
munity recently. Compared to genera-
tive approach, it has the advantage of be-
ing able to handle arbitrary dependent fea-
tures, which is very appealing. In this
paper, we present our approach to the
DSTC2 challenge. We propose to use dis-
criminative Markovian models as a natu-
ral enhancement to the stationary discrim-
inative models. The Markovian structure
allows the incorporation of ?transitional?
features, which can lead to more effi-
ciency and flexibility in tracking user goal
changes. Results on the DSTC2 dataset
show considerable improvements over the
baseline, and the effects of the Markovian
dependency is tested empirically.
1 Introduction
Spoken dialog systems (SDS) have become much
more popular these days, but still far from wide
adoption. One of the most outstanding problems
that affect user experience in an SDS is due to
automatic speech recognition (ASR) and spoken
language understanding (SLU) errors. While the
advancement of ASR technology has a positive ef-
fect on SDS, it is possible to improve the SDS user
experience by designing a module which explicitly
handles ASR and SLU errors. With accurately es-
timated dialog state, the dialog manager could se-
lect more effective and flexible dialog actions, re-
sulting in shorter dialogs and higher dialog success
rate. Dialog state tracking is the task of identifying
the correct dialog state (user action, user goal, etc.)
from ASR and SLU outputs in the presence of er-
rors. Commercial dialog systems these days usu-
ally use simple dialog state tracking strategies that
only consider the most probable SLU output. Pre-
vious research shows that several errors in dialog
state tracking can be rectified by considering the
full N-best results from the ASR and SLU compo-
nents (Williams, 2012). Thus it is very important
to develop robust and practical dialog state track-
ing models.
In statistical dialog state tracking, models
can be roughly divided into two major classes,
i.e. generative and discriminative. Generative
(Bayesian) dialog tracking models are prevalent
in early studies due to its close relationship with
the POMDP dialog management model (Young et
al., 2013). Generative models generally use Dy-
namic Bayesian Networks to model the observa-
tion probability P (O
t
|S
t
) and transition probabil-
ity P (S
t
|S
t?1
), where O
t
and S
t
are observations
and dialog state at turn t. In a discriminative
model, the conditional probability P (S
t
|O
t
1
) is
modeled directly, where O
t
1
is all the observations
from turn 1 to t. One problem with the generative
models is that the independent assumptions are al-
ways not realistic. For example, N-best hypothe-
ses are often assumed independent of each other,
which is flawed in realistic scenarios (Williams,
2012). Furthermore, it is intrinsically difficult for
generative models to handle overlapping features,
which prevents model designers from incorporat-
ing arbitrarily large feature set. Discriminative
model does not suffer from the above problems as
there is no need to make any assumptions about
the probabilistic dependencies of the features. As
a result. it is potentially able to handle much larger
feature sets and to make more accurate predic-
tions (Bohus and Rudnicky, 2006). Discrimina-
tive models also tend to be more data-driven, un-
like generative models in which many sub-models
parameters are heuristically tuned.
2 DSTC1 revisited
The first Dialog State Tracking Challenge
(DSTC1) for the first time provided a common
test bed for various state tracking methods, and
327
several participants employed various discrimi-
native models in the challenge. DSTC1 provided
real user dialog corpora in the domain of bus
route service to evaluate performance of various
state tracking methods. In DSTC1 there are 9
teams with 27 submissions, where discriminative,
generative and rule-based models are used in the
challenge. Maximum entropy models (Lee and
Eskenazi, 2013), conditional random fields (Lee,
2013) and neural networks (Henderson et al.,
2013) are the most frequently used discriminative
models, which gave competitive results on several
metrics. It has been empirically analyzed that dis-
criminative methods are especially advantageous
when the ASR/SLU confidence scores are poorly
estimated (Williams et al., 2013).
3 Discriminative modeling in dialog state
tracking
In the design of a slot-filling or task-oriented di-
alog systems, dialog state tracking can be consid-
ered as a classification problem, i.e. assigning pre-
defined values to a fixed number of slots. One
major problem in the formulation is that in com-
plex dialog scenarios the number of classes tends
to be very big, resulting in extremely sparse train-
ing instances for each class. This sparsity affects
the classification performance. A large predic-
tion domain also leads to computation inefficiency
which makes the model less practical. Usually we
could focus only on the on-list hypotheses, which
are the hypotheses appeared in the SLU results,
and all the other values in the slot value set are
grouped into a meta category Other. It is simi-
lar to the partition concept in HIS (Young et al.,
2010), and by doing this we could reduce the num-
ber of classes to a reasonable size. We use Y
t
to
denote the prediction domain at turn t. Although
the number of classes is reduced by focusing on
the dynamically generated Y
t
, some classes will
still suffer from the lack of training instances, and
what is even worse is that a large portion of the
classes will not have any training data, since in
practical SDS deployment it is hard to collect a
large dialog corpus. To handle the data sparseness
problem, parameters are often shared across dif-
ferent slots, or even data sets, and by doing this the
model complexity could be effectively controlled
and the overfitting problem would be alleviated.
Williams proposed to use various techniques from
multi-domain learning to improve model perfor-
Monday: 0.5
Thursday: 0.2
Other: 0.3
Monday: 0.7
Tuesday: 0.1
Thursday: 0.1
Other: 0.1
Observations 
from turn 1 to t
Turn t-1 Turn t
Figure 1: Markovian discriminative model depen-
dency diagram. In this figure the dialog state is
simplified to a single slot variable: date, the do-
main of the slot typically increases as dialog con-
tinues, which includes all the slot values appeared
as SLU results. As indicated by the arrows, S
t
depends on S
t?1
and O
t
1
. In stationary discrimi-
native model, there?s no dependency between ad-
jacent turns indicated by the upper arrow.
mance (Williams, 2013), which could be taken as
another way of parameter sharing.
3.1 Markovian discriminative model
A dialog can be naturally seen as a temporal se-
quence involving a user and an agent, where strong
dependencies exist between adjacent turns. In typ-
ical task-oriented dialogs, users often change their
goals when their original object cannot be satis-
fied. Even when the true user goal stays constant
in a dialog session, the agent?s perception of it will
tend to evolve and be more accurate as the con-
versation proceeds, and thus the dialog state will
often change. The states at adjacent turns are sta-
tistically correlated, and therefore it is important
to leverage this natural temporal relationship in
tracking dialog state. We enhance the stationary
discriminative model in a similar way as described
in (McCallum et al., 2000), by assuming Marko-
vian dependency between adjacent turns.
Thus, the original probability P (S
t
|O
t
1
) can be
factored into the following form:
P (S
t
|O
t
1
) = (1)
?
S
t?1
?S
P (S
t
|O
t
1
, S
t?1
)P (S
t?1
|O
t?1
1
)
The graphical model is shown is figure
1. Unlike stationary discriminative models,
328
we model the conditional transition probability
P (S
t
|O
t
1
, S
t?1
) instead of P (S
t
|O
t
1
) and the dia-
log state is updated according to equation 1 at each
turn. The feature functions in the structured model
can depend on the state of the previous turn, which
we call transitional features.
It is worth noting that stationary discriminative
model can include features built from dialog his-
tory (Metallinou et al., 2013). The major dif-
ference in utilizing this information from our ap-
proach is that by explicitly assuming the Marko-
vian dependency, the structured model is able to
exploit the whole probabilistic dialog state distri-
bution of the previous turn. The previous dialog
state S
t?1
is inferred from previous dialog history
O
t?1
1
, which contains higher level hypotheses than
the raw history features. Apart from that, the struc-
tured model can also use any stationary features
built from O
t
1
, which makes the stationary model
a special case of the structured one.
3.2 Neural network classifier
We use the family of multi-layer neural net-
works to model the transition probability
P (S
t
|O
t?1
1
, S
t?1
). To allow for the use of the
dynamic prediction domain, we utilize a forward
network structure similar to (Henderson et al.,
2013). Feature vectors for each class in Y
t
are
fed into the model and forwarded through several
hidden layers for non-linear transformation in the
hope that deeper layers may form higher abstrac-
tion of the raw inputs. The parameter vectors for
each class are shared. For each feature vector
the model generates a real score. The scores for
all the classes in Y
t
are then normalized using a
softmax function resulting in valid probabilities.
y
i
= W
l?1
? g
l?1
(. . . g
1
(W
1
?X
i
) . . .) (2)
P
Y
= Softmax(y
1
, . . . , y
|Y
t
|
) (3)
where g
1
to g
l?1
are sigmoid functions, W
i
is the
weight matrix for linear transformation at layer i
and X
i
= f(O
t
1
, y
i
) is the feature vector for class
i. We also test maximum entropy models, which
can be seen as a simple neural network without
hidden layers:
P (Y = y|O
t
1
) =
e
??f(O
t
1
,y)
?
y?Y
e
??f(O
t
1
,y)
(4)
4 DSTC2 challenge
DSTC2 is the second round of Dialog State Track-
ing Challenge, and it provides dialog corpora
collected from real human-machine dialogs in a
restaurant domain. The corpora are split into la-
beled training and development sets and unlabeled
test set. Test sets are collected from a SDS dif-
ferent from the training and development set to
reflect the mismatch in real deployment. Unlike
DSTC1, the user goal often changes in DSTC2
when the condition specified by the user cannot
be met. For evaluation DSTC2 defined a number
of metrics among which several featured metrics
are selected. Besides tracking user goals (the val-
ues of each slot), two additional states method and
requested slots are also defined, which track the
method to query and the slots requested by users
respectively. Further details about DSTC2 could
be found in (Henderson et al., 2014).
5 Feature set
We briefly describe the feature set used in our sys-
tem. We only use the live SLU information pro-
vided by the organizers, and no extra external data
is used. The features used can be divided into two
classes.
stationary features which only depend on the
observations and the class (slot value) pre-
dicted at current turn in the form of f(y
t
, O
t
).
transitional features that can also depends on
the predicted class at the previous turn in the
form of f(y
t
, y
t?1
, O
t
).
Stationary features include:
? SLU Scores: confidence scores of the current
prediction binned into boolean values, raw
scores are also added as real features.
? SLU Status: whether the prediction is denied,
informed and confirmed in the current turn.
? Dialog history: whether the prediction has
been denied, informed and confirmed in all
the dialog turns until the current one.
? User/system action: The most probable user
action and the machine action in the current
turn.
The transitional features are as follows:
? Transition1: whether the predictions in the
previous and the current turn are the same.
329
Name Model Class Hidden layers
Entry1 MEMM ?
Entry2 Structured NN [50]
Entry3 Structured NN [50, 30]
MLP Stationary NN [50, 30]
Table 1: Configurations of models. The model
MLP uses the same structure as Entry3, but with-
out the transitional features described in section 5.
Number in brackets denotes the number of units
used in each hidden layers.
? Transition2: joint feature of Transition1 in
conjunction with the machine action in cur-
rent turn, i.e. for each machine cation, Tran-
sision1 is replicated and only the one corre-
sponding to the machine action at current turn
is activated.
Transitional features are specific to Markovian
models while stationary features can be used in
any discriminative models.
6 Model training
Markovian models in various forms are tested to
find the most appropriate structure for the task.
Models for ?method? and ?state? are built sepa-
rately using similar structured models.
When using the maximum entropy model to
build the conditional probability, the Markovian
model is equivalent to the maximum-entropy
Markov model (MEMM) model introduced in
(McCallum et al., 2000). More sophisticated neu-
ral networks with different configurations are used
to fit the model to more complex patterns in the
input features. In tracking the state ?goal?, the
joint distribution of slots is built assuming differ-
ent slots are independent of each other. From the
perspective of practical implementation, one ad-
vantage of the simpler MEMM model is that the
training objective is convex. Thus the optimiza-
tion routine is guaranteed to find the global opti-
mum, while neural networks with hidden layers al-
ways have many local optima which require care-
ful initialization of the parameters. LBFGS (Liu
and Nocedal, 1989) is used in optimizing the batch
log-likelihood objective and L1 and L2 regulariz-
ers are used to penalize the model from overfitting.
We train the model on the training set, the devel-
opment set is used for model selection and models
produced at each training iteration are evaluated.
State Tracker ACC L2 CA05
Goal
Baseline 0.619 0.738 0.000
Entry1 0.707 0.447 0.223
Entry2 0.713 0.437 0.207
Entry3 0.718 0.461 0.100
MLP 0.713 0.448 0.128
Method
Baseline 0.875 0.217 0.000
Entry1 0.865 0.228 0.199
Entry2 0.871 0.211 0.290
Entry3 0.871 0.210 0.287
MLP 0.946 0.092 0.000
Requested
Baseline 0.884 0.196 0.000
Entry1 0.932 0.118 0.057
Entry2 0.947 0.093 0.218
Entry3 0.951 0.085 0.225
MLP 0.863 0.231 0.291
Table 2: Evaluation results on the DSTC2 test set.
ACC stands for accuracy, L2 measures the Eu-
clidean distance between the predicted distribution
and the ground truth vector with only the correct
hypothesis set to 1. CA05 is the correct accep-
tance rate when false acceptance rate is 5%. De-
tails of the metrics can be found in (Henderson et
al., 2014). Except L2, the larger the scores, the
better the performance.
In DSTC2 we submitted 3 trackers, an additional
tracker without the transitional features is trained
afterwards for comparison. Configurations of the
models are described in table 1.
7 Experiments and part of the results
Featured metrics on the test set are shown in ta-
ble 2. By most metrics our models are superior
to the simple baseline. Especially in tracking user
goals which is the most important state to track in
DSTC2, the discriminative trackers show consid-
erable performance gain. Judging from the per-
formance of Entry1 to Entry3, we can conclude
that the more complex 2-layer neural networks
have better performance. Markovian neural net-
works can fit to the training instances with much
more flexibility than the simple MEMM model.
We have also trained a standard multi-layer neural
network (MLP) model by disabling all the transi-
tional features. By comparing the model ?Entry 3?
and ?MLP?, which share the same network struc-
ture, we explicitly test the effect of the Marko-
vian structure. On the state ?goal? and ?requested?,
the Markovian model shows better tracking accu-
330
racies, which means that the Markovian structure
has a positive effect on fitting the target. But in
tracking the state ?method?, the MLP model has
the best performance among all the models com-
pared. Thus although the log-likelihood increases
considerably on the training set by adding the tran-
sitional features, the overfiting to the training set is
more serious in tracking ?method?.
8 Conclusion
We described the models used in the DSTC2 chal-
lenge. We proposed a novel approach to enhanc-
ing the model capability of stationary discrimina-
tive models in dialog state tracking by assuming
Markovian dependencies between adjacent turns.
The results showed better performance than the
simple baseline which uses the most probable hy-
pothesis, and we empirically compared the mod-
els with and without the Markovian dependency.
In future work, more discriminative models in dif-
ferent forms could be compared to evaluate their
capability, and the effects of the Markovian struc-
ture and transitional features needs to be further
studied.
Acknowledgments
We would like to thank the DSTC committee for
their great efforts in organizing the challenge. We
also thank the anonymous reviewers for their con-
structive comments.
This work is partially supported by the Na-
tional Natural Science Foundation of China (Nos.
10925419, 90920302, 61072124, 11074275,
11161140319, 91120001), the Strategic Prior-
ity Research Program of the Chinese Academy
of Sciences (Grant Nos. XDA06030100,
XDA06030500), the National 863 Program (No.
2012AA012503) and the CAS Priority Deploy-
ment Project (No. KGZD-EW-103-2).
References
Dan Bohus and Alex Rudnicky. 2006. A k-
hypotheses+ other belief updating model. In Proc.
of the AAAI Workshop on Statistical and Empirical
Methods in Spoken Dialogue Systems.
Matthew Henderson, Blaise Thomson, and Steve
Young. 2013. Deep neural network approach for
the dialog state tracking challenge. In Proceedings
of the SIGDIAL 2013 Conference, pages 467?471,
Metz, France, August. Association for Computa-
tional Linguistics.
Matthew Henderson, Blaise Thomson, and Jason
Williams. 2014. The second dialog state tracking
challenge. In Proceedings of the SIGDIAL 2014
Conference, Baltimore, U.S.A., June.
Sungjin Lee and Maxine Eskenazi. 2013. Recipe for
building robust spoken dialog state trackers: Dialog
state tracking challenge system description. In Pro-
ceedings of the SIGDIAL 2013 Conference, pages
414?422, Metz, France, August. Association for
Computational Linguistics.
Sungjin Lee. 2013. Structured discriminative model
for dialog state tracking. In Proceedings of the
SIGDIAL 2013 Conference, pages 442?451, Metz,
France, August. Association for Computational Lin-
guistics.
Dong C Liu and Jorge Nocedal. 1989. On the limited
memory bfgs method for large scale optimization.
Mathematical programming, 45(1-3):503?528.
Andrew McCallum, Dayne Freitag, and Fernando C. N.
Pereira. 2000. Maximum entropy markov mod-
els for information extraction and segmentation. In
Pat Langley, editor, ICML, pages 591?598. Morgan
Kaufmann.
Angeliki Metallinou, Dan Bohus, and Jason Williams.
2013. Discriminative state tracking for spoken di-
alog systems. In Proceedings of the 51st Annual
Meeting of the Association for Computational Lin-
guistics, pages 466?475, Sofia, Bulgaria, August.
Association for Computational Linguistics.
Jason Williams, Antoine Raux, Deepak Ramachan-
dran, and Alan Black. 2013. The dialog state track-
ing challenge. In Proceedings of the SIGDIAL 2013
Conference, page 404?413, Metz, France, August.
Association for Computational Linguistics.
Jason Williams. 2012. A critical analysis of two
statistical spoken dialog systems in public use. In
2012 IEEE Spoken Language Technology Workshop
(SLT), pages 55?60.
Jason Williams. 2013. Multi-domain learning and
generalization in dialog state tracking. In Proceed-
ings of the SIGDIAL 2013 Conference, pages 433?
441, Metz, France, August. Association for Compu-
tational Linguistics.
Steve Young, Milica Ga?si?c, Simon Keizer, Franc?ois
Mairesse, Jost Schatzmann, Blaise Thomson, and
Kai Yu. 2010. The hidden information state model:
A practical framework for POMDP-based spoken
dialogue management. Computer Speech & Lan-
guage, 24(2):150?174.
Steve Young, Milica Ga?si?c, Blaise Thomson, and Ja-
son D Williams. 2013. Pomdp-based statistical spo-
ken dialog systems: A review. Proceedings of the
IEEE, 101(5):1160?1179.
331
