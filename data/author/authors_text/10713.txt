Proceedings of NAACL HLT 2009: Short Papers, pages 197?200,
Boulder, Colorado, June 2009. c?2009 Association for Computational Linguistics
The independence of dimensions in multidimensional dialogue act
annotation
Volha Petukhova and Harry Bunt
Tilburg Center for Creative Computing
Tilburg University, The Netherlands,
{v.petukhova,h.bunt}@uvt.nl
Abstract
This paper presents empirical evidence for the
orthogonality of the DIT++ multidimensional
dialogue act annotation scheme, showing that
the ten dimensions of communication which
underlie this scheme are addressed indepen-
dently in natural dialogue.
1 Introduction
Studies of human dialogue behaviour indicate that
natural dialogue utterances are very often multifunc-
tional. This observation has inspired the develop-
ment of multidimensional approaches to dialogue
analysis and annotation, e.g. (Allen & Core, 1997) ,
(Larsson, 1998), (Popescu-Belis, 2005), (Bunt,
2006). The most frequently used annotation scheme
that implements this approach is DAMSL (Allen
and Core, 1997), which allows multiple labels to be
assigned to utterances in four layers: Communica-
tive Status, Information Level, Forward-Looking
Function (FLF) and Backward-Looking Function
(BLF). The FLF layer is subdivided into five classes,
including (roughly) the classes of commissive and
directive functions, well known from speech act the-
ory. The BLF layer has four classes: Agreement,
Understanding, Answer, and Information Relation.
These nine classes, also referred to as ?dimensions?,
form mutually exclusive sets of tags; no further mo-
tivation is given for the particular choice of classes.
Popescu-Belis (2005) argues that dialogue act
tagsets should seek a multidimensional theoretical
grounding and defines the following aspects of ut-
terance function that could be relevant for choosing
dimensions (1) the traditional clustering of illocu-
tionary forces in speech act theory into five classes:
Representatives, Commissives, Directives, Expres-
sives and Declarations; (2) turn management; (3) ad-
jacency pairs; (4) topical organization in dialogue;
(5) politeness functions; and (6) rhetorical roles.
Structuring an annotation scheme by grouping re-
lated communicative functions into clusters makes
the structure of the schema more transparent. Such
clusters or ?dimensions? are usually defined as a
set of functions related to the same type of infor-
mation, such as Acknowledging, Signalling Under-
standing and Signalling Non-understanding, or Dia-
logue Opening and Dialogue Closing. Bunt (2006)
shows that this does not always lead to a notion of
dimension that has any conceptual and theoretical
significance, and argues that some of the function
classes of DAMSL do not constitute proper dimen-
sions.
In particular, a theoretically grounded multidi-
mensional schema should provide an account of the
possible multifunctionality of dialogue utterances.
In (Bunt, 2006); (Bunt and Girard, 2005) a dimen-
sion in dialogue act analysis is defined as an aspect
of participating in dialogue which can be addressed:
? by dialogue acts which have a function specifi-
cally for dealing with this aspect;
? independently of the other dimensions.
The independence of dimensions, required by this
definition, has the effect that an utterance may have
a function in one dimension independent of the func-
tions that it may have in other dimensions, and helps
to explain why utterances may have multiple func-
tions. Moreover, it leads to more manageable and
197
more adaptable annotation schemas (compared to,
for instance, DAMSL and its derivatives), since it al-
lows annotators to leave out certain dimensions that
they are not interested in, or to extend the schema
with additional dimensions; and it allows restricting
or modifying the set of tags in a particular dimension
without affecting the rest of the schema.
Based on the above definition and extensive theo-
retical and empirical studies, 10 dimensions are de-
fined in the DIT++ dialogue act annotation scheme1:
the domain or task/activity (Task); feedback on the
processing of previous utterances by the speaker
(Auto-feedback) or by other interlocutors (Allo-
feedback); managing difficulties in the speaker?s ut-
terance production (Own-Communication Manage-
ment, OCM) or that of other interlocutors (Partner
Communication Management, PCM); the speaker?s
need for time to continue the dialogue (Time Man-
agement); establishing and maintaining contact
(Contact Management); the allocation of the next
turn (Turn Management); the way the speaker is
planning to structure the dialogue (Dialogue Struc-
turing); and attention for social aspects of the inter-
action (Social Obligations Management, SOM).
This paper investigates the independence of these
ten dimensions. In Section 2 we discuss the notion
of independence of dimensions and how it can be
tested. Section 3 reports test results and Section 4
draws conclusions.
2 Independence of dimensions
We define two dimensions D1 and D2 in an anno-
tation scheme to be independent iff (1) an utterance
may be assigned a value in D1 regardless of whether
it is assigned a value in D2; and (2) it is not the case
that whenever an utterance has a value in D1, this
determines its value in D2.2
Dependences between dimensions can be de-
termined empirically by analyzing annotated dia-
logue data. Dimension tags which always co-occur
are nearly certainly dependent; zero co-occurrence
scores also suggest possible dependences. Besides
co-occurrence scores, we also provide a statistical
analysis using the phi coefficient as a measure of
1For more information about the scheme and its dimensions
please visit http://dit.uvt.nl/
2See Petukhova and Bunt (2009) for a more extensive dis-
cussion.
relatedness. The phi measure is related to the chi-
square statistic, used to test the independence of cat-
egorical variables, and is similar to the correlation
coefficient in its interpretation.
If a dimension is not independent from other di-
mensions, then there would be no utterances in the
data which address only that dimension. We there-
fore also investigate to which extent it happens that
an utterance addresses only one dimension. We also
investigate whether a dimension is addressed only in
reaction to a certain other dimension. For example,
the answer dimension as defined in DAMSL cannot
be seen as independent, because answers need ques-
tions in order to exist. The test here is to examine the
relative frequencies of pairs <dimension tag, previ-
ous dimension tag>.
To sum up, we performed four tests, examining:
1. the relative frequency of communicative func-
tion co-occurrences across dimensions;
2. the extent of relatedness between dimensions
measure with the phi coefficient;
3. for all dimensions whether there are utterances
addressing only that dimension;
4. the relative frequency of pairs of dimension and
previous dimension.
3 Test results
Since different types of dialogue may have differ-
ent tag distributions, three different dialogue corpora
have been examined:
? The DIAMOND corpus3 of two-party instruc-
tional human-human Dutch dialogues (1,408
utterances);
? The AMI corpus4 of task-oriented human-
human multi-party English dialogues (3,897 ut-
terances);
? The OVIS corpus5 of information-seeking
human-computer Dutch dialogues (3,942 utter-
ances).
All three corpora were manually segmented and
tagged according to the DIT++ annotation scheme.
3For more information see Geertzen, J., Girard, Y., and
Morante R. 2004. The DIAMOND project. Poster at CATA-
LOG 2004.
4Augmented Multi-party Interaction (http:
//www.amiproject.org/)
5Openbaar Vervoer Informatie System (Public Transport In-
formation System) http://www.let.rug.nl/v?annoord/Ovis/
198
Table 1: Co-occurrences of communicative functions across dimensions in AMI corpus expressed in relative frequency in %
implicated and entailed functions excluded and included (in brackets).
The test results presented in this section are similar
for all three corpora.
The co-occurrence results in Table 1 show no
dependences between dimensions, although some
combinations of dimensions occur frequently, e.g.
time and turn management acts often co-occur. A
speaker who wants to win some time to gather his
thoughts and uses Stalling acts mostly wants to con-
tinue in the sender role, and his stalling behaviour
may be intended to signal that as well (i.e., to be
interpreted as a Turn Keeping act). But stalling be-
haviour does not always have that function; espe-
cially an extensive amount of stallings accompanied
by relatively long pauses may be intended to elicit
support for completing an utterance.
It is also interesting to have a look at co-
occurrences of communicative functions taking im-
plicated and entailed functions into account (the cor-
pora were reannotated for this purpose). An impli-
cated function is for instance the positive feedback
(on understanding and evaluating the preceding ut-
terance(s) of the addressee) that is implied by an ex-
pression of thanks; examples of entailed functions
are the positive feedback on the preceding utterance
that is implied by answering a question, by accept-
ing an invitation, or by rejecting an offer.
Co-occurrence scores are higher when entailed
and implicated functions are taken into account (the
scores given in brackets in Table 1). For example,
questions, which mostly belong to the Task dimen-
sion, much of the time have an accompanying Turn
Management function, either releasing the turn or
assigning it to another dialogue participant, allow-
ing the question to be answered. Similarly, when
accepting a request the speaker needs to have the
turn, so communicative functions like Accept Re-
quest will often be accompanied by functions like
Turn Take or Turn Accept. Such cases contribute to
the co-occurrence score between the Task and Turn
Management dimensions.
Table 1 shows that some dimensions do not oc-
cur in combination. We do not find combinations of
Contact and Time Management, Contact and Part-
ner Communication Management, or Partner Com-
munication Management and Discourse Structuring,
for example. Close inspection of the definitions of
the tags in these pairs of dimensions does not re-
veal combination restrictions that would make one
of these dimensions depend on the others.
Table 2 presents the extent to which dimensions
are related when the corpus data are annotated with
or without taking implicated and entailed functions
into account, according to the calculated phi coeffi-
cient.
No strong positive (phi values from .7 to 1.0) or
negative (-.7 to -1.0) relations are observed. There
is a weak positive association (.6) between Turn
and Time Management (see co-occurrence analysis
above) and between OCM and Turn Management
(.4). Weak negative associations are observed be-
tween Task and Auto-feedback (-.5) when entailed
and implicated functions are not considered; be-
tween Task and Contact Management (-.6); and be-
tween Auto- and Allo-feedback (-.6) when entailed
and implicated functions are included in the analy-
sis. The weak negative association means that an
utterance does not often have communicative func-
tions in these two dimensions simultaneously. Some
negative associations become positive if we take en-
tailed and implicated functions into account, be-
cause, as already noted, dialogue acts like answers,
accepts and rejects, imply positive feedback.
199
Table 2: Extent of relation between dimensions for AMI corpus expressed in the Phi coefficient (implicated and entailed functions
excluded (white cells) and included (grey cells)).
The third independence test, mentioned above,
shows that each dimension may be addressed by
an utterance which does not address any other di-
mension. The Task dimension is independently ad-
dressed in 28.8% of the utterances; 14.2% of the ut-
terances have a function in the Auto-Feedback di-
mension only; for the other dimensions these fig-
ures are 0.7% - Allo-Feedback; 7.4% - Turn Man-
agement; 0.3% - Time Management; 0.1% - Contact
Management; 1.9% - Discourse Structuring; 0.5% -
OCM; 0.2% - PCM; and 0.3% - SOM.
Table 3: Overview of relative frequency (in%) of pairs of di-
mension and previous dimensions by previous utterances ob-
served in AMI data, per dimension, drawn from the set of 5
pairs from the dialogue history.
We finally investigated the occurrences of tags
given the tags of the previous utterances, taking five
previous utterances into account. Table 3 shows no
evidence of dependences across the dialogue his-
tory. There are some frequent patterns, for example,
retractions and self-corrections often follow hesita-
tions because the speaker, while monitoring his own
speech and noticing that part of it needs revision,
needs time to construct the corrected part.
4 Conclusions
In this paper we investigated the independence of
the dimensions defined in the DIT++ dialogue act
annotation scheme, using co-occurrences matrices
and the phi coefficient for measuring relatedness be-
tween dimensions.
The results show that, although some dimensions
are more related and co-occur more frequently than
others, on the whole the ten DIT++ dimensions
may be considered to be independent aspects of
communication.
Acknowledgments
This research was conducted as part of ISO project
24617-2: Semantic annotation framework, Part 2:
Dialogue acts, and sponsored by Tilburg University.
References
James F. Allen and Mark G. Core. 1997. Draft of
DAMSL: Dialog Act Markup in Several Layers.
Jens Allwood. 2000. An activity-based approach to prag-
matics. In Bunt, H., and Black, W. (eds.) Abduction,
Belief and Context in Dialogue; Studies in Computa-
tional Pragmatics, pp. 47?80. Benjamins, Amsterdam.
Harry Bunt and Yann Girard. 2005. Designing an open,
multidimensional dialogue act taxonomy. In Gardent,
C., and Gaiffe, B. (eds). Proc. 9th Workshop on the
Semantics and Pragmatics of Dialogue, pp. 37?44.
Harry Bunt. 2006. Dimensions in dialogue annotation.
In Proceedings of LREC 2006.
Mark G. Core and James F. Allen. 1997. Coding dia-
logues with the DAMSL annotation scheme. In Work-
ing Notes: AAAI Fall Symposium on Communicative
Action in Humans and Machines, pp. 28?35.
Staffan Larsson. 1998. Coding Schemas for Dialogue
Moves. Technical report from the S-DIME project.
Volha Petukhova and Harry Bunt. 2009. Dimensions
in communication. TiCC Technical Report 2009-002,
Tilburg University.
Andrei Popescu-Belis. 2005. Dialogue Acts: One or
More Dimensions? ISSCO Working Paper 62, ISSCO.
200
Proceedings of the 8th International Conference on Computational Semantics, pages 157?168,
Tilburg, January 2009. c?2009 International Conference on Computational Semantics
Towards a Multidimensional Semantics of Discourse
Markers in Spoken Dialogue
Volha Petukhova and Harry Bunt
v.petukhova@uvt.nl; harry.bunt@uvt.nl
Abstract
The literature contains a wealth of theoretical and empirical anal-
yses of discourse marker functions in human communication. Some of
these studies address the phenomenon that discourse markers are often
multifunctional in a given context, but do not study this in systematic
and formal ways. In this paper we show that the use of multiple dimen-
sions in distinguishing and annotating semantic units supports a more
accurate analysis of the meaning of discourse markers. We present an
empirically-based analysis of the semantic functions of discourse mark-
ers in dialogue. We demonstrate that the multiple functions, which a
discourse marker may have, are automatically recognizable from utter-
ance surface-features using machine-learning techniques.
1 Introduction
Discourse markers are key indicators of discourse structure, and have been
shown to be useful devices for (a) segmenting discourse into meaningful
units, and (b) identifying relations between these units. The determination
of the meanings of discourse markers is often crucial for understanding the
communicated message.
Discourse markers have been studied for their role in the organization
of discourse structure in larger texts ([12], [16]), in argumentative dialogues
([6]), in interviews ([15], [10]) and in dialogues that are highly interactive in
nature and are characterized by rapid turn switching among participants,
such as task-oriented dialogues ([9]) or meeting conversations ([14]).
The research reported in this paper regards the use of discourse mark-
ers in spoken dialogue. In dialogue, discourse markers play an important
role in establishing boundaries between dialogue units and in indicating the
communicative functions of such units (see e.g. [14], [9], [10]).
157
(1) A1: it ties you on in terms of the technologies and the complexity that you want
A2: like for example voice recognition
A3: because that you might need to power a microphone and other things
A4: so thats one constraint there
In example (1) discourse markers are used by the speaker to indicate the
steps in a sequence of arguments: he makes a statement (Inform); then he
provides an example for this statement (Inform Exemplify); he justifies his
choice (Inform Justification); and he draws a conclusion (Inform Conclude).
An important goal of studies of dialogue structure is to explore possi-
ble meanings and functions of discourse markers in dialogue as reflected in
observable utterance features (prosodic, syntactic, lexical), to enable their
successful recognition and classification.
One aspect of the meaning of discourse markers is that they may not
only have a variety of semantic functions, but that they may also have sev-
eral functions simultaneously ? their multifunctionality (see [11], [1], [15]
among others). This paper introduces a formal and systematic, empirically-
based approach to the study of the multifunctionality of discourse markers.
We show how the multifunctionality of discourse markers can be described
systematically by using a multidimensional model of the interpretation of
communicative behaviour in dialogue (Section 2). Section 3 introduces the
analysed data and features. We illustrate the multifunctionality of discourse
markers in some detail for the example of and, as one of the most frequently
used and ambiguous dialogue markers. We provide the results of statisti-
cal and machine-learning experiments on the automatic recognizability of
discourse marker meanings, and give an overview of the observed multifunc-
tionality of markers that occur in our data (Section 4). Conclusions and
perspectives for further research are outlined in the final Section 5.
2 The notion of multifunctionality
The multifunctionality of discourse markers has been described first by
Schiffrin in [15]. She distinguishes between (1) ideational structure, with
relations between propositions, e.g. a cohesion relation, a topic relation or
a functional relation; (2) action structure, which describes the organisation
and constraints on the use of speech acts; (3) exchange structure, which is
?the outcome of decision procedures by which speakers alternate sequential
roles and define those alternations in relation to each other?. Schiffrin argues
that discourse markers may simultaneously have roles within each of these
three structures, e.g. the discourse marker and may ?coordinate ideas? and
158
?continue a speaker?s action?. However, the multifunctionality of discourse
markers in this study escaped extensive and formal description.
Hovy in [11] states that each discourse marker signals either (1) a ?seman-
tic interpropositional relation?, e.g. CAUSE or PART-OF, or (2) ?interper-
sonal intentions? (a communicative purpose of an utterance), e.g. to inform
someone about a fact, or to instruct someone to do something, or (3) both.
Moreover, according to Hovy each discourse marker ?articulates a rhetorical
relation?, such as Elaboration or Presentational-Sequence. Hovy argues that
there are several parallel simultaneous structures that underlie coherent dis-
course and argues that an adequate description of discourse requires at least
four distinct structural analyses: semantic, interpersonal/goal-oriented, at-
tentional/thematic, and rhetorical.
This approach seems to apply very well to the analysis of the meaning
of discourse markers in dialogue. Discourse markers may have various com-
municative purposes (also called communicative functions) in dialogue with
respect to the underlying task or goal, attention, topic or arguments, turn
management, etc. We only want to add that discourse markers may have
various communicative functions simultaneously. For example, if the speaker
wants to provide additional or more detailed information about something
that he mentioned before, he can signal the relation between the two pieces
of information by using discourse markers such as ?and?, ?also?, ?moreover?.
The discourse marker signals an elaboration relation and the communica-
tive purpose of the whole utterance, which contains the discourse marker, is
Inform with the rhetorical function Elaborate. Additionally, the discourse
marker is used here to show that the speaker wishes to continue in the
speaker role (Turn Keep function).
In our analysis by ?multifunctionality? we mean the phenomenon of hav-
ing multiple meanings simultaneously, which are related to the multiple
purposes that an utterance may have in communication.
There are different forms of multifunctionality. Allwood in [1] claims that
if an utterance is multifunctional, ?its multifunctionality can be sequential
and simultaneous?. Bunt in [5] examines this claim using empirical data from
several dialogue annotation experiments and concludes that sequential mul-
tifunctionality disappears if we take sufficiently fine-grained dialogue units
into account (so-called ?functional segments? rather than turns). A func-
tional segment is defined as ?a smallest(possibly discontinuous) stretch of
communicative behaviour that has one or more communicative functions?
([8]). It was shown in [5] that even if we consider fine-grained units of
communicative behaviour we do not get rid of simultaneous multifunction-
ality; and the minimum number of functions that one segment may have
159
in dialogue is 1.3 on average. The number of functions grows rapidly if we
take forms of multifunctionality into account such as implicated and entailed
functions, feedback levels, and indirect functions.
It is noticed in [5] that pragmatically implicated functions, e.g. an ex-
pression of thanks also expressing positive feedback, are a true source of
multifunctionality. Logically entailed functions, such as the positive feed-
back on understanding that is entailed by answering a question or accepting
an offer, can also be important. For the purpose of this study, however,
we left such forms of multifunctionality out of consideration. This has two
reasons. First, we believe that discourse markers as such do not signal any
implicated or entailed functions. Second, since we want to operate on the
basis of observable utterance features (prosodic and linguistic) that can be
extracted automatically from raw data, to investigate how dialogue partic-
ipants express and recognise the intended and explicitly indicated multiple
functions of dialogue utterances.
In the next section we first describe the relevant aspects of the semantic
framework that we will use to study the multiple meanings of discourse
markers in dialogue in a systematic fashion.
3 Semantic framework
The semantic framework of Dynamic Interpretation Theory (DIT, [3]) takes
a multidimensional view on dialogue, in the sense that it views participa-
tion in a dialogue as being engaged in several activities simultaneously, such
as trying to advance a task that motivates the dialogue, providing commu-
nicative feedback, taking turns, and so on. Communicative behaviour is
interpreted in terms of bundles of update operations on participants? infor-
mation states (or ?contexts?); such update operations consist of a semantic
(referential, propositional, or action-related) content and a communicative
function, which specifies what an addressee is supposed to do with the se-
mantic content in order to update his information state [5]. Consider the
following dialogue fragment:
(2) A1: that?s why i think the option of the kinetic thing
A2: which basically means as long as you shake it like an automatic watch
D1: -1.78
1
but
D2: are people gonna wanna shake their movie controller?
1
Here and further in text figures given in brackets indicate the token duration in sec-
onds; figures without brackets indicate silence pauses between tokens in seconds.
160
Utterance (D1) is multifunctional, since it indicates that (1) the speaker
wants to have the turn by interrupting the previous speaker (signalled by
?but? overlapping A3); (2) the speaker interpreted and evaluated the utter-
ances A1 and A2 successfully; and (3) the speaker encountered a problem
in applying the information from the previous utterances (due to the ad-
versative meaning of ?but? ) ? he probably does not agree with the previous
claim or needs some clarification, which is indeed expressed in D2. Thus,
as the example shows, the various functions of ?but? are related to different
?dimensions? of the interaction [4], such as the allocation of the speaker role
and the processing of previous utterances.
In DIT the information which can be addressed is divided into: the do-
main or task (Task), feedback on the processing of previous utterances by
the speaker (Auto-feedback) or by other interlocutors (Allo-feedback), manag-
ing difficulties in the speaker?s utterance production (Own-Communication
Management) or that of other interlocutors (Partner Communication Man-
agement), the speaker?s need for time to continue the dialogue (Time Man-
agement), establishing and maintaining contact (Contact Management), the
allocation of the next turn (Turn Management), the way the speaker is
planning to structure the dialogue (Dialogue Structuring), and attention for
social aspects of the interaction (Social Obligations Management).
It was observed in DIT that some utterances have communicative func-
tions that can be applied to any kind of semantic content (general-purpose
(GP) functions). In particular, they can be applied not only to content
information concerning a certain task or domain, but also to information
concerning the communication, e.g. an Inform like ?First of all we need to
discuss the project finances? is used to introduce a new topic into the dis-
cussion. Dimension-specific (DS) functions, by contrast, are applicable only
to information concerned with a specific dimension of communication, e.g.
using the utterance ?Let me see? the speaker indicates that he needs some
time to do something in preparation of continuing the dialogue (Stalling
act). The phenomenon of general-purpose functions means that, when a
stretch of communicative behaviour has a GP function, its full functional
characterization requires in addition also the specification of the dimension
that is addressed, so we get characterizations like Feedback Question and
Task Suggestion.
We found that discourse markers are used (i) as ?preface? of a range of GP
functions, in particular Informs of various rhetorical kinds; (ii) as indicators
of dialogue acts with a DS function, e.g. of topic shifts; and (iii) as full-
blown dialogue acts (without explicit semantic content), e.g. as a Turn Take
act. This means that discourse markers can have two kinds of meanings:
161
as a dialogue act, i.e. as a context update operator, and as an element
that contributes to the determination of the communicative function of a
dialogue act with either a GP- or a DS-function.
The DIT framework supports a ?multidimensional? semantics by relating
context update operators to different compartments of structured context
models which include, besides information states of the usual kind (beliefs
and goals related to a task domain), also a dialogue history, information
about the agent?s processing state, beliefs about dialogue partners? process-
ing states, information and goals concerning the allocation of turns, and so
on, relating to the various ?dimensions? that dialogue acts belong to. The
interpretation of a multifunctional stretch of communicative behaviour cor-
responds to updating the context models of the communicating agents in
multiple ways, combining the effects of each of the component functions.
For example:
(3) B1: what anybody wants to add about what they don?t like about remote controls
A1:0.48 and you keep losing them
Since it answers B?s Set-Question B1, utterance A1, which includes the
discourse marker and, updates the context model of participant B with the
information that
2
: (1) A believes that B wants to know which elements of a
given set have a given property ; (2) A believes that B believes that A knows
which elements of that set have that property ; (3) A believes to know which
elements of that set have that property ; and (4) A believes that B made the
turn available. Thus, the simultaneous performance of the turn management
and feedback acts through the use of A1, in particular of and, constitutes
the multidimensional interpretation of what A says.
4 Data analysis and classification experiments
4.1 Corpus data and automatically extracted features
For the empirical semantic analysis of discourse markers we selected three
meetings from the AMI meeting corpus.
3
Our data contain 17,335 words
which form 3,897 functional segments with an average length of 4.4 words.
Average turn length is 7.7 segments.
All the features that we used were low-level features, automatically ex-
tracted both from the transcriptions and from sound files. In this respect
our analysis differs from those where manually labelled intonational informa-
tion is used such as tones and pitch accents ([10]), or automatically derived
2
For a formal representation of updates in participants? information state see [13].
3
A
?
ugmented M
?
ulti-party I
?
nteraction (http://www.amiproject.org/).
162
syntactic information ([14], [16]) such as parts-of-speech. Our aim was to
discover how well a classifier can perform if no other external knowledge
sources are available and only the output of the speech recogniser is acces-
sible. The features relate to prosody, word occurrence, and collocations.
Prosodic features were minimum, maximum, mean, and standard devia-
tion of pitch (F0 in Hz), energy (RMS), voicing (fraction of locally unvoiced
frames and number of voice breaks), speaking rate (number of syllables per
second) and segment duration.
4
Word occurrence is represented by a bag-
of-words vector
5
indicating the presence or absence of words in the segment.
As lexical features bi- and trigram models were constructed.
4.2 Dialogue act tagset and notes on segmentation
The training data was manually annotated using the DIT
++
annotation
scheme.
6
The DIT
++
taxonomy is multilayered and multidimensional, with
a conceptually well-defined set of communicative functions, supporting dia-
logue act annotation in multiple dimensions simultaneously.
The utterances were segmented per dimension following the approach in
[8], which leads to a more accurate analysis of human communication than
the segmentation of dialogue in single sequences of utterances, since utter-
ances may contain functional ?holes? due to protractions, repairs, restarts,
etcetera. Moreover, participants may interrupt each other and talk simul-
taneously, and utterances may also spread over several turns. A meaningful
unit in this approach is a functional segment as defined in Section 3. An
example of per-dimension segmentation is given in Figure (1).
4.3 Results: multifunctionality of discourse markers
We do not aim in this paper to discuss all discourse markers which occur in
our corpus data, we rather demonstrate the minimal multifunctionality of
the most frequently used discourse markers in dialogue and discuss the case
of and in more detail.
Table 1 lists some discourse markers (DMs) identified in the studied cor-
pus with their absolute frequency in the corpus, gives an overview of their
4
We examined both raw and normalized versions of these features. Speaker-normalized
features were normalized by computing z-scores (z = (X- mean)/standard deviation),
where mean and standard deviation were calculated from all functional segments produced
by the same speaker in the dialogues. We also used normalizations by the first and prior
speaker turn.
5
With a size of 1,640 entries.
6
For more information about the tagset and the dimensions that are distinguished,
please visit: http://dit.uvt.nl/
163
Figure 1: Example of per-dimension segmentation.
observed mutlifunctionality by indicating the average number of commu-
nicative functions in our dialogues, and lists the observed communicative
functions. Note that all DMs serve more than one communicative func-
Table 1: Distribution and observed multifunctionality of discourse markers.
tion. And is the most multifunctional discourse marker in our corpus and
because the least multifunctional one. Because mostly prefaces Informs with
the rhetorical functions Justify or Explain, and only in 2.4% of all cases is
used to simultaneously perform Turn Keeping and Stalling acts. All dis-
course markers, except ?you know?, preface GP functions in Task or other
dimensions (often in Discourse Structuring and Feedback) and may perform
164
dialogue acts addressing other dimensions simultaneously, as we will illus-
trate for and below. This pattern is observed for 50.7% of all studied DMs.
A discourse marker may also perform full-fledged dialogue acts addressing
more than one dimension simultaneously (as in example 2). This is often the
case for Turn Management in combination with Feedback, Time Manage-
ment, Discourse Structuring and Own Communication Management (27.7%
of all discourse markers are observed to be used in this way). It was noticed
that at most 3 dialogue acts are performed by one discourse marker in a
given context, e.g. feedback, turn and time management acts. A third pat-
tern of DM use, which was observed in 18.2% of cases, is as a single dialogue
act, e.g. a turn taking act or a feedback act. In the rest (3.4%) discourse
markers are part of general purpose functions and do not perform a dialogue
act on their own.
And is one of the most frequently used discourse markers in our cor-
pus. The corpus contained 470 occurrences of and, where about 54.5% is
not used as a discourse marker and the rest of 45.5% as discourse marker.
Differentiating between and as non-DM and DM is important for segmenta-
tion purposes. Used in clause-initial position or as an autonomous segment,
and as DM so to speak brackets segments and helps define their boundaries.
We investigated the prosodic and durational differences, and differences in
surrounding material between the two basic uses of and, and performed
machine-learning recognition experiments.
Experiments using the RIPPER rule inducer [7] showed that the two uses
of and are well recognized automatically. An accuracy score of 80.6% was
obtained on unsegmented data. Baseline score, in this case the percentage
of the most frequent class (non-DMs), was 54.5%. There are significant
mean differences (p < .05) for both raw and speaker-normalized features in
terms of duration (DMs are almost twice as long as non-DMs: 289-327ms
and 173-217ms respectively); initial pause (there is no or a negligible small
pause before non-DMs, and initial pauses before DMs range between 59 and
228ms); mean pitch (and as DM has higher mean pitch: > 12Hz). Preceding
and following tokens as features also have high information gain. And as
DM is often so to speak backed up between um, uh, so, then and also.
As a discourse marker, and may have various and multiple communica-
tive functions (see Table 1). And may signal that the upcoming speech is
adding new information or used in explanatory sequences [15], like Inform
Explain in (4):
(4) A1: like you said a problem was how many components are in there
A2: um (0.4)
A3: 0.28 and (0.12) the power is basically a factor of that
165
A4: 0.55 um (0.47) and (0.32) this affects you in terms of the size of your device
A5: 0.59 um (0.26) and (0.16) that would have some impact
And can also mark the transition from one discussion topic to another
by introducing topic shifts, for example:
(5) A1: you could group plastic and rubber, but it might be easier to use one
D1: -0.29 mm-hmm
A2: 0.74 um (0.32)and (0.2) the other components are logic chips
Table 2: Overview of accuracy on the base-
line (BL) and the classifier on the prediction
of communicative functions of ?and? in differ-
ent dimensions obtained using 10-fold cross-
validation experiments. ? significant at p <
.05, one-tailed z-test.
In 57% of all cases and is used
as a marker of speaker contin-
uation (turn keeping) as illus-
trated in A3, A4 and A5 in (4).
And in A2 in (5) also has a pos-
itive allo-feedback function re-
lated to the utterance D1.
We trained the RIPPER rule in-
ducer to automatically classify
the communicative functions of
and in several dimensions. The
results are shown in Table 2.
The classifier outperforms the
baseline, which for all tasks is
the percentage of the majority
class (e.g. Elaboration in Task),
except for the classification of Discourse Structuring and Partner Commu-
nication Management functions, for which there were not enough instances
in the training set.
As for features, for the prediction of the Task dimension, the bag-of-
words feature representing word occurrence in the segment and word col-
location features were important. For example, Inform Elaborate is often
signalled by focusing adverbs like especially, mainly, additionally, etc, or
contains relative pronouns like who, whose, which and that. The pres-
ence of some expressions of comparision was noted in Exemplifications,
such as one of, rather than, like,comparing, by contrast, similar, etc. The
most frequent words that occurred in Suggestions were maybe, might, bet-
ter, should, could/can, probably and let?s; and Discourse Structuring func-
tions are marked by next, then, other and further. For all other dimensions
prosodic features were more important than the surrounding lexical mate-
rial. For example, for Turn Management functions duration, initial pause
166
and mean pitch are key features. Important is also the information about
the current and the previous speaker. Speaker switch is an important sign
of and in the Auto-Feedback dimension. Stallings were characterized by a
long duration (about 585ms) and long initial pause (365ms), and a pause
after (100ms). They also often were preceded and followed by um and uh.
5 Conclusions and future work
To summarize we can conclude that discourse markers are truly multifunc-
tional dialogue units. The analysis of discourse markers as important instru-
ments for the understanding of dialogue and its computational modelling can
only benefit from a multidimensional approach to the exploration of their
complex meaning.
We showed that discourse markers may simultaneously serve several com-
municative functions in different dimensions. They are good indicators of
(plentiful) general-purpose communicative functions, such as informs, elab-
orations of various kinds, suggestions, warnings, disagreements, etc., mostly
in relation to the task that underlies the dialogue, but they are also fre-
quently used to create or maintain the conditions for successful interaction
(indicating dialogue control acts). Our investigations showed that discourse
markers may have communicative functions in all the dimensions distin-
guished in DIT, except perhaps in Social Obligations Management. We
noted the importance of discourse markers for segmenting dialogue into
meaningful units, since they so to speak bracket functional segments. Binary
automatic classification of DM vs non-DM was successfully performed. The
automatic recognition of the various and multiple communicative functions
of discourse markers is even more important. Our automatic classification
experiments showed that machine learning techniques can be profitably used
in the automatic recognition of multiple meanings of dialogue markers.
For future work, we intend to extend the studies reported here in two
directions. First, we plan to collect more annotated data containing a richer
set of discourse markers and sufficient numbers of instances per class, so
that we may increase the accuracy of the classifier for further evaluation
of our model on unmarked examples (see [16]). Furthermore, since AMI
meetings are face-to-face interactions and video recordings are available, we
plan to consider other modalities besides speech audio, e.g. hand and head
gestures, for better understanding of discourse markers functions in support
of adequate computational dialogue modelling.
167
Acknowledgments
This research was conducted within the project ?Multidimensional Dialogue
Modelling?, sponsored by the Netherlands Organisation for Scientific Re-
search (NWO), under grant reference 017.003.090.
References
[1] Allwood, J. (1992). On dialogue cohesion. Gothenburg Papers in Theoretical Lin-
guistics 65. Gothenburg University, Department of Linguistics.
[2] Allwood, J. (2000). An activity-based approach to pragmatics. H. Bunt and W. Black
(eds.) Abduction, Belief and Context in Dialogue, Amsterdam: Benjamin, pp.47-81.
[3] Bunt, H. (2000). Dynamic Interpretation and Dialogue Theory. M.M. Taylor, D.G.
Bouwhuis and F. Neel (eds.) The Structure of Multimodal Dialogue, Vol 2., Ams-
terdam: John Benjamins, pp. 139?166.
[4] Bunt, H. (2006). Dimensions in Dialogue Act Annotation. Proceedings LREC 2006,
Genova.
[5] Bunt, H. (2007). Multifunctionality and Multidimensional Dialogue Act Annotation.
E. Ahlsen et al (ed.) Communication - Action - Meaning. Gothenburg, pp. 237 ?
259.
[6] Cohen, R. (1984). A computational theory of the function of clue words in argument
understanding. Coling-ACL 1984, Standford, pp. 251?258.
[7] Cohen, W.W. (1995). Fast effective rule induction. In Proceedings of the 12th Inter-
national Conference on Machine Learning (ICML?95), pp. 115?123.
[8] Geertzen, J. Petukhova, V. and Harry Bunt. (2007). A Multidimensional Approach
to Utterance Segmentation and Dialogue Act Classification. Proceedings of the 8th
SIGdial Workshop on Discourse and Dialogue, Antwerp, pp. 140?149.
[9] Heeman, P.A. and Allen, J.F. (1999). Speech repairs, intonational phrases and dis-
course markers: Modelling speakers utterances in spoken dialogue. Computational
Linguistics, 12(3): 1?45.
[10] Hirschberg, J. and Litman, D. (1993). Empirical studies on the disambiguqtion of
cue phrases. Computational Linguistics, 25(4): 501?530.
[11] Hovy, E.H. (1995). The multifunctionality of discourse markers. Proceedings of the
Workshop on Discourse Markers, Egmond-aan-Zee, The Nertherlands.
[12] Mann, W. and Thompson, S. (1988). Rhetorical structure theory: toward a functional
theory of text organisation. The MIT Press, Cambridge, MA.
[13] Morante, R. (2007). Computing Meaning in Interaction. PhD Thesis, Tilburg Uni-
versity.
[14] Popescu-Belis, A. and Zufferey, S. (2006). Automatic identification of discourse
markers in multiparty dialogues. Working paper 65, ISSCO, University of Geneva.
[15] Schiffrin, D. (1987). Discourse Markers. Cambridge: University Press.
[16] Sporleder, C. and Lascarides, A. (2008). Using Automatically Labelled Examples to
Classify Rhetorical Relations: An Assessment. Natural Language Engineering, 14.03:
369?416.
168
Incremental dialogue act understanding
Volha Petukhova
Tilburg Center for Creative Computing
Tilburg University, The Netherlands,
v.petukhova@uvt.nl
Harry Bunt
Tilburg Center for Creative Computing
Tilburg University, The Netherlands,
harry.bunt@uvt.nl
Abstract
This paper presents a machine learning-based approach to the incremental understanding of dia-
logue utterances, with a focus on the recognition of their communicative functions. A token-based
approach combining the use of local classifiers, which exploit local utterance features, and global
classifiers which use the outputs of local classifiers applied to previous and subsequent tokens, is
shown to result in excellent dialogue act recognition scores for unsegmented spoken dialogue. This
can be seen as a significant step forward towards the development of fully incremental, on-line meth-
ods for computing the meaning of utterances in spoken dialogue.
1 Introduction
When reading a sentence in a text, a human language understander obviously does not wait trying to
understand what he is reading until he has come to the end of the sentence. Similarly for participants
in a spoken conversation. There is overwhelming psycholinguistic evidence that human understanders
construct syntactic, semantic, and pragmatic hypotheses on the fly, while receiving the written or spoken
input. Dialogue phenomena such as backchannelling (providing feedback while someone else is speak-
ing), the completion of a partner utterance, and requests for clarification that overlap the utterance of the
main speaker, illustrate this. Evidence from the analysis of nonverbal behaviour in multimodal dialogue
lends further support to the claim that human understanding works incrementally, as input is being re-
ceived. Dialogue participants start to perform certain body movements and facial expressions that are
perceived and interpreted by others as dialogue acts (such as head nods, smiles, frowns) while another
participant is speaking, see e.g. Petukhova and Bunt (2009). As another kind of evidence, eye-tracking
experiments by Tanenhaus et al (1995), Sedivy et al (1999) and Sedivy (2003) showed that definite
descriptions are resolved incrementally when the referent is visually accessible.
Traditional models of language understanding for dialogue systems, by contrast, are pipelined, mod-
ular, and operate on complete utterances. Typically, such a system has an automatic speech recognition
module, a language understanding module responsible for syntactic and semantic analysis, an interpre-
tation manager, a dialogue manager, a natural language generation module, and a module for speech
synthesis. The output of each module is the input for another. The language understanding module typ-
ically performs the following tasks: (1) segmentation: identification of relevant segments in the input,
such as sentences;(2) lexical analysis: lexical lookup, possibly supported by morphological processing,
and by additional resources such as WordNet, VerbNet, or lexical ontologies; (3) parsing: construction
of syntactic interpretations; (4) semantic analysis: computation of propositional, referential, or action-
related content; and (5) pragmatic analysis: determination of speaker intentions.
Of these tasks, lexical analysis, being concerned with local information at word level, can be done
for each word as soon as it has been recognized, and is naturally performed as an incremental part
of utterance processing, but syntactic, semantic and pragmatic analysis are traditionally performed on
complete utterances. Tomita?s pioneering work in left-to-right syntactic parsing has shown that incre-
mental parsing can be much more efficient and of equal quality as the parsing of complete utterances
(Tomita (1986)). Computational approaches to incremental semantic and pragmatic interpretation have
235
been less successful (see e.g. Haddock (1989); Milward and Cooper (2009)), but work in computational
semantics on the design of underspecified representation formalisms has shown that such formalisms,
developed originally for the underspecified representation of quantifier scopes, can also be applied in
situations where incomplete input information is available (see e.g. Bos (2002); Bunt (2007), Hobbs
(1985), Pinkal (1999)) and as such hold a promise for incremental semantic interpretation.
Pragmatic interpretation, in particular the recognition of a speaker?s intentions in incoming dialogue
utterances, is another major aspect of language understanding for dialogue systems. Computational
modelling of dialogue behaviour in terms of dialogue acts aims to capture speaker intentions in the com-
municative functions of dialogue acts, and offers an effective integration with semantic content analysis
through the information state update approach (Poesio and Traum (1998)). In this approach, a dialogue
act is viewed as having as its main components a communicative function and a semantic content, where
the semantic content is the referential, propositional, or action-related information that the dialogue act
addresses, and the communicative function defines how an understander?s information state is to be up-
dated with that information.
Evaluation of a non-incremental dialogue system and its incremental counterpart reported in Aist
et al (2007) showed that the latter is faster overall than the former due to the incorporation of pragmatic
information in early stages of the understanding process. Since users formulate utterances incrementally,
partial utterances may be available for a substantial amount of time and may be interpreted by the system.
An incremental interpretation strategy may allow the system to respond more quickly, by minimizing the
delay between the time the user finishes and the time the utterance is interpreted DeVault and Stone
(2003).
This suggests that a dialogue system performance may benefit from reliable partial processing of
input. This paper is concerned with the automatic recognition of dialogue acts based on partially available
input and shows that in order to arrive at the best output prediction two different classification strategies
are needed: (1) local classification that is based on features observed in dialogue behaviour and that can
be extracted from the annotated data; and (2) global classification that takes the locally predicted context
into account.
This paper is structured as follows. In Section 2 we will outline performed experiments describing
the data, tagset, features, algorithms and evaluation metrics that have been used. Section 3 reports on the
experimental results, applying a variety of machine learning techniques and feature selection algorithms,
to assess the automatic recognition and classification of dialogue acts using simultaneous incremental
segmentation and dialogue act classification. In Section 4 we discuss strategies in management and
correction of the output of local classifies. Section 5 concludes.
2 Incremental understanding experiments
2.1 Related work
Nakano et al (Nakano et al (1999)) proposed a method for the incremental understanding of utterances
whose boundaries are not known. The Incremental Sentence Sequence Search (ISSS) algorithm finds
plausible boundaries of utterances, called significant utterances (SUs), which can be a full sentence or a
subsentential phrase, such as a noun phrase or a verb phrase. Any phrase that can change the belief state
is defined as a SU. In this sense an SU corresponds more or less with what we call a ?functional segment?,
which is defined as a minimal stretch of behaviour that has a communicative function (see Bunt et al
(2010)). ISSS maintains multiple possible belief states, and updates these each time a word hypothesis
is input. The ISSS approach does not deal with the multifunctionality of segments, however, and does
not allow segments to overlap.
Lendvai and Geertzen (Lendvai and Geertzen (2007)) proposed token-based dialogue act segmenta-
tion and classification, which was worked out in more detail in Geertzen (2009). This approach takes
dialogue data that is not segmented into syntactic or semantic units, but operates on the transcribed speech
as a stream of words and other vocal signs (e.g. laughs), including disfluent elements (e.g. abandoned
236
Dimension Frequency General-purpose function Frequency
Task 31.8 PropositionalQuestion 5.8
Auto-Feedback 20.5 Set Question 2.3
Allo-Feedback 0.7 Check Question 3.3
Turn Management 50.2 Propositional Answer 9.8
Social Obligation Management 0.5 Set Answer 3.9
Discourse Structuring 2.8 Inform 11.7
Own Communication Management 10.3 InformRhetorical 21.9
Time Management 26.7 Instruct 0.3
Partner Communication Management 0.3 Suggest 10.1
Contact Management 0.1 Request 5.6
Table 1: Distribution of functional tags across dimensions and general-purpose functions for the AMI corpus (in
%).
or interrupted words). Segmentation and classification of dialogue acts are performed simultaneously in
one step. Geertzen (2009) reports on classifier performance on this task for the DIAMOND data1 using
DIT++ labels. The success scores in terms of F-scores range from 47.7 to 81.7. It was shown that per-
forming segmentation and classification together results in better segmentation, but affects the dialogue
act classification negatively.
The incremental dialogue act recognition system proposed here takes the token-based approach for
building classifiers for the recognition (segmentation and classification) of multiple dialogue acts for each
input token, and adopts the ISSS idea for information-state updates based on partial input interpretation.
2.2 Tagset
The data selected for the experiments was annotated with the DIT++ tagset Release 42. The DIT tax-
onomy distinguishes 10 dimensions, addressing information about: the domain or task (Task), feedback
on communicative behaviour of the speaker (Auto-feedback) or other interlocutors (Allo-feedback), man-
aging difficulties in the speaker?s contributions (Own-Communication Management) or those of other
interlocutors (Partner Communication Management), the speaker?s need for time to continue the di-
alogue (Time Management), establishing and maintaining contact (Contact Management), about who
should have the next turn (Turn Management), the way the speaker is planning to structure the dialogue,
introducing, changing or closing a topic (Dialogue Structuring), and conditions that trigger dialogue acts
by social convention (Social Obligations Management), see Table 1.
For each dimension, at most one communicative function can be assigned, which is either a function
that can occur in this dimension alone (a dimension-specific (DS) function) or a function that can occur in
any dimension (a general-purpose (GP) function). Dialogue acts with a DS communicative function are
always concerned with a particular type of information, such as a Turn Grabbing act, which is concerned
with the allocation of the speaker role, or a Stalling act, which is concerned with the timing of utterance
production. GP functions, by contrast, are not specifically related to any dimension in particular, e.g.
one can ask a question about any type of semantic content, provide an answer about any type of content,
or request the performance of any type of action (such as Could you please close the door or Could you
please repeat that). These communicative functions include Question, Answer, Request, Offer, Inform,
and many other familiar core speech acts.
The tagset used in these studies contains 38 dimension-specific functions and 44 general-purpose
functions. A tag consists either of a pair consisting of a communicative function (CF ) and the addressed
dimension (D).
1For more information see Geertzen,J., Girard,Y., and Morante,R. 2004. The DIAMOND project. Poster at the 8th Work-
shop on the Semantics and Pragmatics of Dialogue (CATALOG 2004).
2For more information about the tagset and the dimensions that are identified, please visit:http://dit.uvt.nl/ or see
Bunt (2009).
237
Speaker Token Task Auto-F. Allo-F. TurnM. TimeM. ContactM. DS OCM PCM SOM
B it B;inf O O O O O O O O O
B has I:inf O O O O O O O O O
B to I:inf O O O O O O O O O
B look I:inf O O O O O O O O O
B you O O B:check O O O O O O O
B know O O E:check O O O O O O O
B cool I:inf O O O O O O O O O
D mmhmm O BE:positive O O O O O O O O
B and I:inf O O BE:t keep O O O O O O
B gimmicky E:inf O O O O O O O O O
Figure 1: Segment boundaries and dialogue act label encoding in different dimensions.
2.3 Features and data encoding
In the recognition experiments we used data from the AMI meeting corpus3. For training we used three
annotated AMI meetings that contain 17,335 tokens forming 3,897 functional segments. The distribution
of functional tags across dimensions is given in Table 1.
Features extracted from the data considered here relate to dialogue history: functional tags of the
10 previous turns; timing: token duration and floor-transfer offset4 computed in milliseconds; prosody:
minimum, maximum, mean, and standard deviation for pitch (F0 in Hz), energy (RMS), voicing (fraction
of locally unvoiced frames and number of voice breaks) and speaking rate (number of syllables per
second)5; and lexical information: token occurrence, bi- and trigram of those tokens. In total, 1,668
features are used for the AMI data.
To be able to identify segment boundaries, we assign to each token its communicative function label
and indicate whether a token starts a segment (B), is inside a segment (I), ends a segment (E), is out-
side a segment (O), or forms a functional segment on its own (BE). Thus, the class labels consist of a
segmentation prefix (IBOE) and a communicative function label, see example in Figure 1.
2.4 Classifiers and evaluation metrics
Awide variety of machine-learning techniques has been used for NLP tasks with various instantiations of
feature sets and target class encodings. For dialogue processing, it is still an open issue which techniques
are the most suitable for which task. We used two different types of classifiers to test their performance
on our dialogue data: a probabilistic one and a rule inducer.
As a probabilistic classifier we used Bayes Nets. This classifier estimates probabilities rather than
produce predictions, which is often more useful because this allows us to rank predictions. Bayes Nets
estimate the conditional probability distribution on the values of the class attributes given the values of
the other attributes.
As a rule induction algorithm we chose Ripper (Cohen (1995)). The advantage of a rule inducer is
that the regularities discovered in the data are represented as human-readable rules.
The results of all experiments were obtained using 10-fold cross-validation.7 As a baseline it is
common practice to use the majority class tag, but for our data sets such a baseline is not very useful
because of the relatively low frequencies of the tags in some dimensions. Instead, we use a baseline
3The A
?
ugmented M
?
ulti-party I
?
nteraction meeting corpus consists of multimodal task-oriented human-human multi-party
dialogues in English, for more information visit (http://www.amiproject.org/
4Difference between the time that a turn starts and the moment the previous turn ends.
5These features were computed using the PRAAT tool6. We examined both raw and normalized versions of these features.
Speaker-normalized features were obtained by computing z-scores (z = (X-mean)/standard deviation) for the feature, where
mean and standard deviation were calculated from all functional segments produced by the same speaker in the dialogues. We
also used normalizations by first speaker turn and by previous speaker turn.
7In order to reduce the effect of imbalances in the data, it is partitioned ten times. Each time a different 10% of the data is
used as test set and the remaining 90% as training set. The procedure is repeated ten times so that in the end, every instance has
been used exactly once for testing and the scores are averaged. The cross-validation was stratified, i.e. the 10 folds contained
approximately the same proportions of instances with relevant tags as in the entire dataset.
238
that is based on a single feature, namely, the tag of the previous dialogue utterance (see Lendvai et al
(2003))).
Several metrics have been proposed for the evaluation of a classifier?s performance: error metrics
and performance metrics. The word-based error rate metric, introduced in Ang et al (2005), measures
the percentage of words that were placed in a segment perfectly identical to that in the reference. The
dialogue act based metric (DER) was proposed in Zimmermann et al (2005). In this metric a word is
considered to be correctly classified if and only if it has been assigned the correct dialogue act type and
it lies in exactly the same segment as the corresponding word of the reference. We will use the combined
DERsc error metric to evaluate joint segmentation (s) and classification (c):
DERsc =
Tokens with wrong boundaries and/or function class
total number of tokens
? 100
To assess the quality of classification results, the standard F-score metric is used, which represents
the balance between precision and recall.
3 Classification results
Dialogue utterances are often multifunctional, having a function in more than one dimension (see e.g.
Bunt (2010)). This makes dialogue act recognition a complex task. Splitting up the output structure may
make the task more manageable; for instance, a popular strategy is to split a multi-class learning task
into several binary learning tasks. Sometimes, however, learning of multiple classes allows a learning
algorithm to exploit the interactions among classes. We will combine these two strategies. We have built
in total 64 classifiers for dialogue act recognition for the AMI data. Some of the tasks were defined as
binary ones, e.g. the dimension recognition task, others are multi-class learning tasks.
We first trained classifiers to recognize the boundaries of a segment and its communicative functions
(joint multi-class learning task) per dimension, see Table 2.
BL BayesNet Ripper
Dimensions F1 DERsc F1 DERsc F1 DERsc
Task 32.7 51.2 52.1 48.7 66.7 42.6
Auto-Feedback 43.2 84.4 62.7 33.9 60.1 45.6
Allo-Feedback 70.2 59.5 73.7 35.1 71.3 49.1
Turn Management:initial 34.2 95.2 57.0 58.4 54.3 81.3
Turn Management:close 33.3 92.7 54.2 46.9 49.3 87.3
Time Management 43.7 96.5 64.5 46.1 61.4 53.1
Discourse Structuring 41.2 35.1 72.7 19.9 50.2 30.9
Contact Management 59.9 53.2 71.4 49.9 83.3 37.2
Own Communication Management 36.5 87.9 68.3 51.3 58.3 76.8
Partner Communication Management 49.5 59.0 58.5 45.5 51.4 58.7
Social Obligation Management 34.5 47.5 86.5 35.9 83.3 44.3
Table 2: Overview of F-scores and DERsc for the baseline (BL) and the classifiers for joint segmentation and
classification for each DIT++ dimension, for the data of the AMI corpus.
The results show that both classifiers outperform the baseline by a broad margin. The Bayes Nets
classifier marginally outperforms the Ripper rule inducer, but shows no significant differences in overall
performance. Though the results obtained are quite encouraging, the performance on the joint segmen-
tation and classification task does not outperforms the two-step segmentation and classification task re-
ported in Geertzen et al (2007). There is a drop in F-scores compared to the results reported by Geertzen
et al (2007), which is explained by the fact that recall was quite low. This means that the classifiers
missed a lot of relevant cases. Looking more closely at the predictions made by the classifiers, we no-
ticed that beginnings and endings of many segments were not found. For example, the beginnings of Set
Questions are identified with perfect precision (100%), but about 60% of the segment beginnings were
not found. The reason that the classifiers still show a reasonable performance is that most tokens occur
239
inside segments and are better classified, e.g. the inside-tokens of Set Questions are classified with high
precision (83%) and reasonably high recall scores (76%). Still, this is rather worrying, since the correct
identification of, in particular, the start of a relevant segment is crucial for future decisions. These obser-
vations led us to the conclusion that the search space and the number of initially generated hypotheses
for classifiers should be reduced, and we split the classification task in such a way that a classifier needs
to learn one particular type of communicative function.
We trained a classifier for each general-purpose and dimension-specific function defined in the
DIT++ taxonomy, and observed that this has the effect that the various classifiers perform significantly
better. These functions were learned (1) in isolation; (2) as semantically related functions together, e.g.
all information-seeking functions (all types of questions) or all information-providing functions (all an-
swers and all informs). Both the recognition of communicative functions and that of segment boundaries
improves significantly. Table 3 gives an overview of the overall performance (best obtained scores) of
the trained classifiers after splitting the learning task.
BL BayesNet Ripper
Classification task F1 DERsc F1 DERsc F1 DERsc
General-purpose functions
Propositional Questions 47.0 39.1 94.9 3.9 75.8 23.5
Check Questions 43.8 56.4 68.5 19.6 61.3 33.1
Set Questions 44.8 52.1 74.1 18.6 76.3 17.7
Inform 45.8 39.9 79.8 18.7 66.5 30.5
Inform Rhetorical 37.2 38.9 69.1 13.4 68.7 23.9
Agreement 41.3 79.1 72.1 12.6 71.6 60.2
Propositional Answer 32.0 77.8 66.8 26.1 52.2 53.8
Set Answer 44.3 54.2 77.5 13.2 57.3 44.1
Suggest 45.8 38.4 65.6 17.3 48.8 35.6
Request 45.8 49.3 75.8 14.5 50.3 36.9
Instruct 46.3 49.3 60.5 14.5 46.3 36.9
Dimension-specific functions
Auto-Feedback 57.1 23.5 78.8 13.2 66.7 15.5
Allo-Feedback 89.3 4.4 95.1 2.9 94.3 3.9
Turn Management:initial 24.8 21.9 72.8 7.4 46.3 10.7
Turn Management:close 30.7 64.9 62.0 22.5 54.7 39.6
Time management 68.3 32.3 82.4 13.7 92.8 11.4
Discourse Structuring 40.7 13.6 72.6 2.5 74.5 1.7
Contact Management 21.4 48.6 89.2 5.7 92.3 3.6
Own Communication Management 26.7 48.6 78.0 11.6 68.1 20.0
Partner Communication Management 33.4 18.2 77.8 8.5 88.9 6.5
Social Obligation Management 60.0 18.7 88.9 8.3 90.1 5.5
Table 3: Overview of F-scores and DERsc for the baseline (BL) and the classifiers upon joint segmentation
and classification task for each DIT++ communicative function or cluster of functions. (Best scores indicated by
numbers in bold face.)
Segments having a general-purpose functions may address any of the ten DIT dimensions. The task
of dimension recognition can be approached in two ways. One approach is to learn segment boundaries,
communicative function label and dimension in one step (e.g. the class label B:task;inform). This task is
very complicated, however. First, it leads to data which are high dimensional and sparse, which will have
a negative influence on the performance of the trained classifiers. Second, in many cases the dimension
can be recognized reliably only with some delay; for the first few segment tokens it is often impossible
to say what the segment is about. For example:
(1) 1. What do you think who we?re aiming this at?
2. What do you think we are doing next?
3. What do you think Craig?
The three Set Questions in (1) start with exactly the same words, but they address different dimensions:
Question 1 is about the Task (in AMI - the design the television remote control); Question 2 serves the
240
purpose of Discourse Structuring; and Question 3 elicits feedback.
Another approach is to first recognize segment boundaries and communicative function, and define
dimension recognition as a separate classification task.
Tokens SetQuestion Task Auto-F. TurnM. Complex label (BIOE:D;CF)
label p label p label p label p label p
what B:setQ 0.85 O 0.71 O 1 O 0.68 O 0.933
you I:setQ 1 task 0.985 O 1 B:give 0.64 O 0.869
guys I:setQ 1 task 0.998 O 1 E:give 0.66 O 0.937
have I:setQ 1 task 0.997 O 1 O 1 I:task;setQ 0.989
already I:setQ 1 task 0.996 O 1 O 0.99 I:task;setQ 0.903
received I:setQ 1 task 0.987 O 1 O 1 I:task;setQ 0.813
um O 0.93 O 0.89 O 1 BE:keep 0.99 O 0.982
in I:setQ 1 task 0.826 O 1 O 0.89 I:task;setQ 0.875
your I:setQ 1 task 0.996 O 1 O 0.99 I:task;setQ 0.948
mails E:setQ 0.99 task 0.987 O 1 O 1 E:task;setQ 0.948
Figure 2: Predictions with indication of confidence scores (highest p class probability selected) for each token
assigned by five trained classifiers simultaneously.
We tested both strategies. The F-scores for the joint learning of complex class labels range from
23.0 (DERsc = 68.3) to 45.3 (DERsc = 63.8). For dimension recognition as a separate learning task
the F-scores are significantly higher, ranging from 70.6 to 97.7. The scores for joint segmentation and
function recognition in the latter case are those listed in Table 3. Figure 2 gives an example of predictions
made by five classifiers for the input what you guys have already received um in your mails.
4 Managing local classifiers
4.1 Global classification and global search
As shown in the previous section, given a certain input we obtain all possible output predictions (hypothe-
ses) from local classifiers. Some predictions are false, but once a local classifier has made a decision it
is never revisited. It is therefore important to base the decision on dialogue act labels not only on local
features of the input, but to take other parts of the output into account as well. For example, the partial
output predicted so far, i.e. the history of previous predictions, may be taken as features for the next
classification step, and helps to discover and correct errors. This is known as ?recurrent sliding window
strategy? (see Dietterich (2002)) when the true values of previous predictions are used as features. This
approach suffers from the label bias problem, however, when a classifier overestimates the importance
of certain features, and moreover does not apply in a realistic situation, since the true values of previous
predictions are not available to a classifier in real time. A solution proposed by Van den Bosch (1997) is
to apply adaptive training using the predicted output of previous steps as features.
We trained higher-level classifiers (often referred to as ?global?) that have, along with features ex-
tracted locally from the input data as described above, the partial output predicted so far from all local
classifiers. We used five previously predicted class labels, assuming that long distance dependencies
may be important, and taking into account that the average length of a functional segment in our data
is 4.4 tokens. Table 4 gives an overview of the results of applying these global classifiers. We see that
the global classifiers make more accurate predictions than the local classifiers, showing an improvement
of about 10% on average. The classifiers still make some incorrect predictions, because the decision
is sometimes based on incorrect previous predictions. An optimized global search strategy may lead to
further improvements of these results.
A strategy to optimize the use of output hypotheses, is to perform a global search in the output space
looking for best predictions. Our classifiers do not just predict the most likely class for an instance,
but also generate a distribution of output classes. Class distributions can be seen as confidence scores
of all predictions that led to a certain state. Our confidence models are constructed based on token
level information given the dialogue left-context (i.e. dialogue history, wording of the previous and
241
Classification task BayesNet Ripper
F1 DERsc F1 DERsc
Task 65.3 14.9 79.1 21.8
Auto-Feedback 72.9 8.1 77.8 7.2
Allo-Feedback 67.7 10.9 74.2 9.5
Turn Management:initial 72.2 11.5 69.5 11.4
Turn Management:close 82.7 5.0 83.0 4.9
Time Management 70.0 3.0 73.5 2.1
Discourse Structuring 72.3 4.9 63.7 3.6
Contact Management 79.1 4.5 84.3 4.6
Own Communication Management 66.0 2.4 68.3 2.3
Partner Communication Management 63.2 7.8 59.5 11.4
Social Obligation Management 88.4 0.9 81.6 1.7
Table 4: Overview of F-scores and DERsc of the global classifiers for the AMI data based on added previous
predictions of local classifiers.
currently produced functional segment). This is particular useful for dialogue act recognition because
the recognition of intentions should be based on the system?s understanding of discourse and not just on
the interpretation of an isolated utterance. Searching the (partial) output space for the best predictions
is not always the best strategy, however, since the highest-ranking predictions are not always correct
in a given context. A possible solution to this is to postpone the prediction until some (or all) future
predictions have been made for the rest of the segment. For training, the classifier then uses not only
previous predictions as additional features, but also some or all future predictions of local classifiers (till
the end of the current segment or to the beginning of the next segment, depending on what is recognized).
This forces the classifier to not immediately select the highest-ranking predictions, but to also consider
lower-ranking predictions that could be better in the context of the rest of the sequence.
Classification task BayesNet Ripper
F1 DERsc F1 DERsc
Task 82.6 9.5 86.1 8.3
Auto-Feedback 81.9 1.9 95.1 0.6
Allo-Feedback 96.3 0.6 95.7 0.5
Turn Management:initial 85.7 1.5 81.5 1.6
Turn Management:close 90.9 3.8 91.2 3.6
Time management 90.4 2.4 93.4 1.7
Discourse Structuring 82.1 1.7 78.3 1.8
Contact Management 87.9 1.2 94.3 0.6
Own Communication Management 78.4 2.2 81.6 2.0
Partner Communication Management 71.8 2.4 70.0 4.6
Social Obligation Management 98.6 0.4 98.6 0.5
Table 5: Overview of F-scores and DERsc of global classifiers for the AMI data per DIT++ dimension.
The results show the importance of optimal global classification for finding the best output prediction.
We performed similar experiments on the English MapTask data8 and obtained comparable results,
where F-scores on the global classification task range from 66.7 for Partner CommunicationManagement
and Discourse Structuring to 79.7 for Task and 91.2 for Allo-Feedback. For the MapTask corpus the
performance of human annotators on segmentation and classification has been assessed; standard kappa
scores reported in Bunt et al (2007) range between 0.92 and 1.00, indicating near perfect agreement
between two expert annotators9.
8For more information about the MapTask corpus see http://www.hcrc.ed.ac.uk/maptask/
9Note, however, that a slightly simplified version of the DIT++ tagset has been used here, called the LIRICS tagset, in
which the five DIT levels of processing in the Auto- and Allo-Feedback dimensions were collapsed into one.
242
5 Conclusions and future research
The incremental construction of input interpretation hypotheses is useful in a language understanding
system, since it has the effect that the understanding of a relevant input segment is already nearly ready
when the last token of the segment is received; when a dialogue act is viewed semantically as a recipe for
updating an information state, this means that the specification of the update operation is almost ready at
that moment, thus allowing an instantaneous response from the system. It may even happen that the con-
fidence score of a partially processed input segment is that high, that the systemmay decide to go forward
and update its information state without waiting until the end of the segment, and prepare or produce a
response based on that update. Of course, full incremental understanding of dialogue utterances includes
not only the recognition of communicative functions, but also that of semantic content. However, many
dialogue acts have no or only marginal semantic content, such as turn-taking acts, backchannels (m-hm)
and other feedback acts (okay), time management acts (Just a moment), apologies and thankings and
other social obligation management acts, and in general dialogue acts with a dimension-specific func-
tion; for these acts the proposed strategy can work well without semantic content analysis, and will
increase the system?s interactivity significantly. Moreover, given that the average length of a functional
segment in our data is no more than 4.4 tokens, the semantic content of such a segment tends not to be
very complex, and its construction therefore does not seem to require very sophisticated computational
semantic methods, applied either in an incremental fashion (see e.g. Aist et al (2007) and DeVault and
Stone (2003)) or to a complete segment.
Interactivity is however not the sole motivation for incremental interpretation. The integration of
pragmatic information obtained from the dialogue act recognition module, as proposed here, at early
processing stage can be beneficially used by the incremental semantic parser (but also syntactic parser
module). For instance, information about the communicative function of the incoming segment at early
processing stage can defuse a number of ambiguous interpretations, e.g. used for the resolution of
many anaphoric expressions. A challenge for future work is to integrate the incremental recognition of
communicative functions with incremental syntactic and semantic parsing, and to exploit the interaction
of syntactic, semantic and pragmatic hypotheses in order to understand incoming dialogue segments
incrementally in an optimally efficient manner.
Acknowledgments
This research was conducted within the project ?Multidimensional Dialogue Modelling?, sponsored by the Netherlands Organ-
isation for Scientific Research (NWO), under grant reference 017.003.090. We are also very thankful to anonymous reviewers
for their valuable comments.
References
Aist, G., J. Allen, E. Campana, C. Gomez Gallo, S. Stoness, M. Swift, and M. K. Tanenhaus (2007). Incremental
understanding in human-computer dialogue and experimental evidence for advantages over nonincremental
methods. In Proceedings of the 11th Workshop on the Semantics and Pragmatics of Dialogue, Trento, Italy, pp.
149?154.
Ang, J., Y. Liu, and E. Shriberg (2005). Automatic dialog act segmentation and classification in multiparty meet-
ings. In Proceedings of the ICASSP, Volume vol. 1, Philadelphia, USA, pp. 10611064.
Bos, J. (2002). Underspecification and resolution in discourse semantics. PhD Thesis. Saarbru?cken: Saarland
University.
Bunt, H. (2007). Semantic underspecification: which techniques for what purpose? In Computing Meaning, Vol.
3, pp. 55?85. Dordrecht: Springer.
Bunt, H. (2009). The DIT++ taxonomy for functional dialogue markup. In Proceedings of the AAMAS 2009
Workshop ?Towards a Standard Markup Language for Embodied Dialogue Acts? (EDAML 2009), Budapest.
Bunt, H. (2010). Multifunctionality in dialogue and its interpretation. Computer, Speech and Language, Special
issue on dialogue modeling.
243
Bunt, H., J. Alexandersson, J. Carletta, J.-W. Choe, A. Fang, K. Hasida, K. Lee, V. Petukhova, A. Popescu-Belis,
L. Romary, C. Soria, and D. Traum (2010). Language resource management ? Semantic annotation framework
? Part 2: Dialogue acts. ISO DIS 24617-2. Geneva: ISO Central Secretariat.
Bunt, H., V. Petukhova, and A. Schiffrin (2007). Lirics deliverable d4.4. multilingual test suites for semantically
annotated data. Available at http://lirics.loria.fr.
Cohen, W. (1995). Fast effective rule induction. In Proceedings of the 12th International Conference on Machine
Learning (ICML?95), pp. 115?123.
DeVault, D. and M. Stone (2003). Domain inference in incremental interpretation. In Proceedings of the Workshop
on Inference in Computational Semantics, INRIA Lorraine, Nancy, France.
Dietterich, T. (2002). Machine learning for sequential data: a review. In Proceedings of the Joint IAPR Interna-
tional Workshop on Structural, Syntactic, and Statistical Pattern Recognition, pp. 15?30.
Geertzen, J. (2009). Dialogue act recognition and prediction: exploration in computational dialogue modelling.
The Netherlands: Tilburg University.
Geertzen, J., V. Petukhova, and H. Bunt (2007, September). A multidimensional approach to utterance segmenta-
tion and dialogue act classification. In Proceedings of the 8th SIGdial Workshop on Discourse and Dialogue,
Antwerp, Belgium, pp. 140?149. Association for Computational Linguistics.
Haddock, N. (1989). Computational models of incremental semantic interpretation. Language and Cognitive
Processes Vol. 14 (3), SI337?SI380.
Hobbs, J. (1985). Ontological promiscuity. In Proceedings 23rd Annual Meeting of the ACL, Chicago, pp. 61?69.
Lendvai, P., v. d. A. Bosch, and E. Krahmer (2003). Machine learning for shallow interpretation of user utter-
ances in spoken dialogue systems. In Proceedings of EACL-03 Workshop on Dialogue Systems: interaction,
adaptation and styles of management, Budapest.
Lendvai, P. and J. Geertzen (2007). Token-based chunking of turn-internal dialogue act sequences. In Proceedings
of the 8th SIGdial Workshop on Discourse and Dialogue, Antwerp, Belgium, pp. 174?181.
Milward, D. and R. Cooper (2009). Incremental interpretation: applications, theory, and relationship to dynamic
semantics. In Proceedings COLING 2009, Kyoto, Japan, pp. 748?754.
Nakano, M., N. Miyazaki, J. Hirasawa, K. Dohsaka, and T. Kawabata (1999). Understanding unsegmented user ut-
terances in real-time spoken dialogue systems. In Proceedings of the 37th Annual Conference of the Association
of Computational Linguistics, ACL, pp. 200?207.
Petukhova, V. and H. Bunt (2009). Who?s next? speaker-selection mechanisms in multiparty dialogue. In Pro-
ceedings of the Workshop on the Semantics and Pragmatics of Dialogue, Stockholm,, pp. 19?26.
Pinkal, M. (1999). On semantic underspecification. In Computing Meaning, Vol. 1, pp. 33?56. Dordrecht: Kluwer.
Poesio, M. and D. Traum (1998). Towards an Axiomatization of Dialogue Acts. In Proceedings of the Twente
Workshop on the Formal Semantics and Pragmatics of Dialogue, Twente, pp. 309?347.
Sedivy, J. (2003). Pragmatic versus form-based accounts of referential contrast: Evidence for effects of informa-
tivity expectations. Journal of Psycolinguistic Research 32(1), 3?23.
Sedivy, J., M. Tanenhaus, C. Chambers, and G. Carlson (1999). Achieving incremental semantic interpretation
through contextual representation. Cognition 71, 109?147.
Tanenhaus, M., M. Spivey-Knowlton, K. Eberhard, and J. Sedivy (1995). Intergration of visual and linguistic
information in spoken language comprehension. Science 268, 1632?1634.
Tomita, M. (1986). Efficient parsing for natural language. Dordrecht: Kluwer.
Van den Bosch, A. (1997). Learning to pronounce written words: A study in inductive language learning. PhD
thesis. The Netherlands: Maastricht University.
Zimmermann, M., Y. Lui, E. Shriberg, and A. Stolcke (2005). Toward joint segmentation and classification of
dialog acts in multiparty meetings. In Proceedings of the Multimodal Interaction and Related Machine Learning
Algorithms Workshop (MLMI05), pp. 187?193. Springer.
244
