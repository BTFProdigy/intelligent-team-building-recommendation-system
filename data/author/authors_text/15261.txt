Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1066?1076,
Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational Linguistics
Translation with Source Constituency and Dependency Trees
Fandong Meng?? Jun Xie? Linfeng Song?? Yajuan Lu?? Qun Liu??
?Key Laboratory of Intelligent Information Processing
Institute of Computing Technology, Chinese Academy of Sciences
?University of Chinese Academy of Sciences
{mengfandong,xiejun,songlinfeng,lvyajuan}@ict.ac.cn
?Centre for Next Generation Localisation
Faculty of Engineering and Computing, Dublin City University
qliu@computing.dcu.ie
Abstract
We present a novel translation model, which
simultaneously exploits the constituency and
dependency trees on the source side, to com-
bine the advantages of two types of trees. We
take head-dependents relations of dependency
trees as backbone and incorporate phrasal n-
odes of constituency trees as the source side
of our translation rules, and the target side as
strings. Our rules hold the property of long
distance reorderings and the compatibility
with phrases. Large-scale experimental result-
s show that our model achieves significantly
improvements over the constituency-to-string
(+2.45 BLEU on average) and dependency-
to-string (+0.91 BLEU on average) model-
s, which only employ single type of trees,
and significantly outperforms the state-of-the-
art hierarchical phrase-based model (+1.12
BLEU on average), on three Chinese-English
NIST test sets.
1 Introduction
In recent years, syntax-based models have become a
hot topic in statistical machine translation. Accord-
ing to the linguistic structures, these models can be
broadly divided into two categories: constituency-
based models (Yamada and Knight, 2001; Graehl
and Knight, 2004; Liu et al, 2006; Huang et al,
2006), and dependency-based models (Lin, 2004;
Ding and Palmer, 2005; Quirk et al, 2005; Xiong
et al, 2007; Shen et al, 2008; Xie et al, 2011).
These two kinds of models have their own advan-
tages, as they capture different linguistic phenome-
na. Constituency trees describe how words and se-
quences of words combine to form constituents, and
constituency-based models show better compatibil-
ity with phrases. However, dependency trees de-
scribe the grammatical relation between words of
the sentence, and represent long distance dependen-
cies in a concise manner. Dependency-based mod-
els, such as dependency-to-string model (Xie et al,
2011), exhibit better capability of long distance re-
orderings.
In this paper, we propose to combine the advan-
tages of source side constituency and dependency
trees. Since the dependency tree is structurally sim-
pler and directly represents long distance depen-
dencies, we take dependency trees as the backbone
and incorporate constituents to them. Our mod-
el employs rules that represent the source side as
head-dependents relations which are incorporated
with constituency phrasal nodes, and the target side
as strings. A head-dependents relation (Xie et al,
2011) is composed of a head and all its dependents in
dependency trees, and it encodes phrase pattern and
sentence pattern (typically long distance reordering
relations). With the advantages of head-dependents
relations, the translation rules of our model hold the
property of long distance reorderings and the com-
patibility with phrases.
Our new model (Section 2) extracts rules from
word-aligned pairs of source trees (constituency
and dependency) and target strings (Section 3), and
translate source trees into target strings by employ-
ing a bottom-up chart-based algorithm (Section 4).
Compared with the constituency-to-string (Liu et al,
2006) and dependency-to-string (Xie et al, 2011)
models that only employ a single type of trees, our
1066
??/VV
???/NR ?/AD ???/NN
??/NR ?/M ??/JJ
??/OD
NP1
VP2
VP3
????? ? ????? ? ????
NR AD VV NR OD M JJ NN
NP1
CLP
QP
NP
NP
VP2
ADVP
VP3
NP
IP
(a)
(c)
Intel         will   launch  Asia     first              super     laptop
Chinese: ??? ? ?? ?? ?? ? ?? ???
English:  Intel will launch the first Ultrabook in Asia
ADVP NP
(b)
Figure 1: Illustration of phrases that can not be captured by a dependency tree (b) while captured by a constituency tree
(a), where the bold phrasal nodes NP1,VP2,VP3 indicate the phrases which can not be captured by dependency syn-
tactic phrases. (c) is the corresponding bilingual sentences. The subscripts of phrasal nodes are used for distinguishing
the nodes with same phrasal categories.
approach yields encouraging results by exploiting t-
wo types of trees. Large-scale experiments (Sec-
tion 5) on Chinese-English translation show that
our model significantly outperforms the state-of-
the-art single constituency-to-string model by av-
eraged +2.45 BLEU points, dependency-to-string
model by averaged +0.91 BLEU points, and hierar-
chical phrase-based model (Chiang, 2005) by aver-
aged +1.12 BLEU points, on three Chinese-English
NIST test sets.
2 Grammar
We take head-dependents relations of dependency
trees as backbone and incorporate phrasal nodes of
constituency trees as the source side of our transla-
tion rules, and the target side as strings. A head-
dependents relation consists of a head and all its de-
pendents in dependency trees, and it can represent
long distance dependencies. Incorporating phrasal
nodes of constituency trees into head-dependents
relations further enhances the compatibility with
phrases of our rules. Figure 1 shows an example of
phrases which can not be captured by a dependen-
cy tree while captured by a constituency tree, such
as the bold phrasal nodes NP1,VP2 and VP3. The
phrasal node NP1 in the constituency tree indicates
that ??? )P? is a noun phrase and it should
be translated as a basic unit, while in the depen-
dency tree it is a non-syntactic phrase. The head-
dependents relation in the top level of the dependen-
cy tree presents long distance dependencies of the
words ?=A?, ???, ????, and ?)P? in a
concise manner, which is useful for long distance re-
ordering. We adopt this kind of rule representation
to hold the property of long distance reorderings and
the compatibility with phrases.
Figure 2 shows two examples of our translation
rules corresponding to the top level of Figure 1-(b).
We can see that r1 captures a head-dependents rela-
tion, while r2 extends r1 by incorporating a phrasal
node VP2 to replace the two nodes ???/VV? and
?)P/NN?. As shown in Figure 1-(b), VP2 con-
sists of two parts, a head node ???/VV? and a
subtree rooted at the dependent node ?)P/NN?.
Therefore, we use VP2 and the POS tags of the t-
wo nodes VV and NN to denote the part covered
by VP2 in r2, to indicate that the source sequence
covered by VP2 can be translated by a bilingual
phrase. Since VP2 covers a head node ???/VV?,
we represent r2 by constructing a new head node
1067
1
??
??? ? 1
1
2
1 2
??? ? 1
Figure 2: Two examples of our translation rules corre-
sponding to the top level of Figure 1-(b). r1 captures a
head-dependents relation, and r2 extends r1 by incorpo-
rating a phrasal node VP2. ?x1:NN? indicates a substitu-
tion site which can be replaced by a subtree whose root
has POS tag ?NN?. ?x1:VP2|||VV NN? indicates a sub-
stitution site which can be replaced by a source phrase
covered by a phrasal node VP (the phrasal node consist-
s of two dependency nodes with POS tag VV and NN,
respectively). The underline denotes a leaf node.
VP2|||VV NN. For simplicity, we use a shorten for-
m CHDR to represent the head-dependents relations
with/without constituency phrasal nodes.
Formally, our grammar G is defined as a 5-tuple
G = ??, Nc, Nd,?, R?, where ? is a set of source
language terminals, Nc is a set of constituency
phrasal categories, Nd is a set of categories (POS
tags) for the terminals in ?, ? is a set of target lan-
guage terminals, and R is a set of translation rules
that include bilingual phrases for translating source
language terminals and CHDR rules for translation
and reordering. A CHDR rule is represented as a
triple ?t, s,??, where:
? t is CHDR with each node labeled by a ter-
minal from ? or a variable from a set X =
{x1, x2, ? ? ? } constrained by a terminal from ?
or a category from Nd or a joint category (con-
structed by the categories from Nc and Nd);
? s ? (X ??) denotes the target side string;
? ? denotes one-to-one links between nontermi-
nals in t and variables in s.
We use the lexicon dependency grammar (Hellwig,
2006) which adopts a bracket representation to ex-
press the head-dependents relation and CHDR. For
example, the left-hand sides of r1 and r2 in Figure 2
can be respectively represented as follows:
(=A) (?)?? (x1:NN)
(=A) (?) x1:VP2|||VV NN
??/VV
???/NR ?/AD ???/NN
??/NR?/M ??/JJ
??/OD
NP1
VP2
VP3
??? ? ?? ?? ?? ? ?? ???
Parseing      Labelling
???/NR ?/AD launch
Intel will launch ????? in Asia
Intel will launch in Asia
(a)
(b)
(c)
(d)
(e)
NP1
?/M
??/OD
Intel will launch in Asiathe    first(f)
Ultrabook
Ultrabook
???/NN
??/NR?/M ??/JJ
??/OD
NP1
r3
r4 r5
r6
r7
?/M
??/OD
r8
(x1:NR) (x2:AD) ?? (x3:???) x1 x2 launch x3
Intel???
? will
(??)(x1:M)x2:NP1|||JJ_NN x1 x2 in Aisa 
????? Ultrabook
?? (?) the first
Translation Rules
r3
r4
r5
r6
r7
r8
(g)
Figure 3: An example derivation of translation. (g) lists
all the translation rules. r3, r6 and r8 are CHDR rules,
while r4, r5 and r7 are bilingual phrases, which are used
for translating source terminals. The dash lines indicate
the reordering when employing a translation rule.
The formalized presentation of r2 in Figure 2-(b):
t = (=A) (?) x1:VP2|||VV NN
s = Intel will x1
?= x1:VP2|||VV NN ? x1
where the underline indicates a leaf node.
Figure 3 gives an example of the translation
derivation in our model, with the translation rules
1068
listed in (g). r3, r6 and r8 are CHDR rules, while
r4, r5 and r7 are bilingual phrases, which are used
for translating source language terminals. Given a
sentence to translate in (a), we first parse it into a
constituency tree and a dependency tree, then label
the phrasal nodes from the constituency tree to the
dependency tree, and yield (b). Then, we translate
it into a target string by the following steps. At the
root node, we apply rule r3 to translate the top level
head-dependents relation and results in four unfin-
ished substructures and target strings in (c). From
(c) to (d), there are three steps (one rule for one step).
We use r4 to translate ?=A? to ?Intel?, r5 to
translate ??? to ?will?, and r6 to translate the right-
most unfinished part. Then, we apply r7 to translate
the phrase ???)P? to ?Ultrabook?, and yield
(e). Finally, we apply r8 to translate the last frag-
ment to ?the first?, and get the final result (f).
3 Rule Extraction
In this section, we describe how to extract rules from
a set of 4-tuples ?C, T, S,A?, where C is a source
constituency tree, T is a source dependency tree, S
is a target side sentence, and A is an word alignmen-
t relation between T /C and S. We extract CHDR
rules from each 4-tuple ?C, T, S,A? based on GHK-
M algorithm (Galley et al, 2004) with three steps:
1. Label the dependency tree with phrasal nodes
from the constituency tree, and annotate align-
ment information to the phrasal nodes labeled
dependency tree (Section 3.1).
2. Identify acceptable CHDR fragments from the
annotated dependency tree for rule induction
(Section 3.2).
3. Induce a set of lexicalized and generalized
CHDR rules from the acceptable fragments
(Section 3.3).
3.1 Annotation
Given a 4-tuple ?C, T, S,A?, we first label phrasal
nodes from the constituency tree C to the depen-
dency tree T , which can be easily accomplished by
phrases mapping according to the common covered
source sequences. As dependency trees can capture
some phrasal information by dependency syntactic
??/VV
{3-3}{1-8}
???/NR
{1-1}{1-1}
?/AD
{2-2}{2-2}
???/NN
{6-6}{4-8}
??/NR
{7-8}{7-8}
?/M
{null}{4-5}
??/JJ
{6-6}{6-6}
??/OD
{4-5}{4-5}
NP1
<6-6>
VP2
<3-8>
VP3
<2-8>
Figure 4: An annotated dependency tree. Each node is
annotated with two spans, the former is node span and
the latter subtree span. The fragments covered by phrasal
nodes are annotated with phrasal spans. The nodes de-
noted by the solid line box are not nsp consistent.
phrases, in order to complement the information that
dependency trees can not capture, we only label the
phrasal nodes that cover dependency non-syntactic
phrases.
Then, we annotate alignment information to the
phrasal nodes labeled dependency tree T , as shown
in Figure 4. For description convenience, we make
use of the notion of spans (Fox, 2002; Lin, 2004).
Given a node n in the source phrasal nodes labeled
T with word alignment information, the spans of n
induced by the word alignment are consecutive se-
quences of words in the target sentence. As shown
in Figure 4, we annotate each node n of phrasal n-
odes labeled T with two attributes: node span and
subtree span; besides, we annotate phrasal span to
the parts covered by phrasal nodes in each subtree
rooted at n. The three types of spans are defined as
follows:
Definition 1 Given a node n, its node span nsp(n)
is the consecutive target word sequence aligned with
the node n.
Take the node ???/NR? in Figure 4 for example,
nsp(??/NR)={7-8}, which corresponds to the tar-
get words ?in? and ?Asia?.
Definition 2 Given a subtree T ? rooted at n, the
subtree span tsp(n) of n is the consecutive target
word sequence from the lower bound of the nsp of
1069
all nodes in T ? to the upper bound of the same set of
spans.
For instance, tsp()P/NN)={4-8}, which corre-
sponds to the target words ?the first Ultrabook in A-
sia?, whose indexes are from 4 to 8.
Definition 3 Given a fragment f covered by a
phrasal node, the phrasal span psp(f) of f is
the consecutive target word sequence aligned with
source string covered by f .
For example, psp(VP2)=?3-8?, which corresponds
to the target word sequence ?launch the first Ultra-
book in Asia?.
We say nsp, tsp and psp are consistent according
to the notion in the phrase-based model (Koehn et
al., 2003). For example, nsp(??/NR), tsp()P
/NN) and psp(NP1) are consistent while nsp(?
?/JJ) and nsp()P/NN) are not consistent.
The annotation can be achieved by a single pos-
torder transversal of the phrasal nodes labeled de-
pendency tree. For simplicity, we call the annotat-
ed phrasal nodes labeled dependency tree annotated
dependency tree. The extraction of bilingual phrases
(including the translation of head node, dependen-
cy syntactic phrases and the fragment covered by a
phrasal node) can be readily achieved by the algo-
rithm described in Koehn et al, (2003). In the fol-
lowing, we focus on CHDR rules extraction.
3.2 Acceptable Fragments Identification
Before present the method of acceptable fragments
identification, we give a brief description of CHDR
fragments. A CHDR fragment is an annotated frag-
ment that consists of a source head-dependents rela-
tion with/without constituency phrasal nodes, a tar-
get string and the word alignment information be-
tween the source and target side. We identify the ac-
ceptable CHDR fragments that are suitable for rule
induction from the annotated dependency tree. We
divide the acceptable CHDR fragments into two cat-
egories depending on whether the fragments con-
tain phrasal nodes. If an acceptable CHDR frag-
ment does not contain phrasal nodes, we call it
CHDR-normal fragment, otherwise CHDR-phrasal
fragment. Given a CHDR fragment F rooted at n,
we say F is acceptable if it satisfies any one of the
following properties:
CHDR-phrasal Rules
r9: (???)(?)x1:VP2|||VV_NN Intel will x1
r10: (x1:NR)(x2:AD)x3:VP2|||VV_NN x1 x2 x3
r11: (???)x1:VP3|||AD_VV_NN Intel x1
r12: (x1:NR)x2:VP3|||AD_VV_NN x1 x2
CHDR-normal Rules
r4: (x1:NR) (x2:AD) ?? (x3:NN) x1 x2 launch x3
Intel will launch x1r3: (???) (?)?? (x1:NN)
r2: (x1:NR) (x2:AD) ?? (x3:???) x1 x2 launch x3
r1: (???) (?)?? (x1:???) Intel will launch x1
r5: (???) (?) x1:VV (x2:???) Intel will x1 x2
r8: (x1:NR) (x2:AD) x3:VV (x4:NN) x1 x2 x3 x4
r6: (x1:NR) (x2:AD) x3:VV (x4:???) x1 x2 x3 x4
Intel will x1 x2r7: (???) (?) x1:VV (x2:NN)
(d)
??/VV
???/NR ?/AD ???/NN
Intel
1
will
2
launch
3
the first Ultrabook in Asia
4-8
(a)
Intel
1
will
2
launch the first Ultrabook in Asia
3-8
VP2
??/VV
???/NR ?/AD ???/NN(b)
(c)
Intel
1
will launch the first Ultrabook in Asia
2-8
VP3
??/VV
???/NR ?/AD ???/NN
VP2|||VV_NN
VP3|||AD_VV_NN
Figure 5: Examples of a CHDR-normal fragment (a), two
CHDR-phrasal fragments (b) and (c) that are identified
from the top level of the annotated dependency tree in
Figure 4, and the corresponding CHDR rules (d) induced
from (a), (b) and (c). The underline denotes a leaf node.
1. Without phrasal nodes, the node span of the
root n is consistent and the subtree spans of
n?s all dependents are consistent. For example,
Figure 5-(a) shows a CHDR-normal fragmen-
t that identified from the top level of the an-
notated dependency tree in Figure 4, since the
nsp(??/VV), tsp(=A/NR), tsp(?/AD)
and tsp()P/NN) are consistent.
1070
2. With phrasal nodes, the phrasal spans of
phrasal nodes are consistent; and for the other
nodes, the node span of head (if it is not cov-
ered by any phrasal node) is consistent, and the
subtree spans of dependents are consistent. For
instance, Figure 5-(b) and (c) show two CHDR-
phrasal fragments identified from the top level
of Figure 4. In Figure 5-(b), psp(VP2), tsp(=
A/NR) and tsp(?/AD) are consistent. In
Figure 5-(c), psp(VP3) and tsp(=A/NR)
are consistent.
The identification of acceptable fragments can be
achieved by a single postorder transversal of the an-
notated dependency tree. Typically, each acceptable
fragment contains at most three types of nodes: head
node, head of the related CHDR; internal nodes, in-
ternal nodes of the related CHDR except head node;
leaf nodes, leaf nodes of the related CHDR.
3.3 Rule Induction
From each acceptable CHDR fragment, we induce
a set of lexicalized and generalized CHDR rules.
We induce CHDR-normal rules and CHDR-phrasal
rules from CHDR-normal fragments and CHDR-
phrasal fragments, respectively.
We first induce a lexicalized form of CHDR rule
from an acceptable CHDR fragment:
1. For a CHDR-normal fragment, we first mark
the internal nodes as substitution sites. This
forms the input of a CHDR-normal rule. Then
we generate the target string according to the
node span of the head and the subtree spans of
the dependents, and turn the word sequences
covered by the internal nodes into variables.
This forms the output of a lexicalized CHDR-
normal rule.
2. For a CHDR-phrasal fragment, we first mark
the internal nodes and the phrasal nodes as sub-
stitution sites. This forms the input of a CHDR-
phrasal rule. Then we construct the output of
the CHDR-phrasal rule in almost the same way
with constructing CHDR-normal rules, except
that we replace the target sequences covered by
the internal nodes and the phrasal nodes with
variables.
For example, rule r1 in Figure 5-(d) is a lexicalized
CHDR-normal rule induced from the CHDR-normal
fragment in Figure 5-(a). r9 and r11 are CHDR-
phrasal rules induced from the CHDR-phrasal frag-
ment in Figure 5-(b) and Figure 5-(c) respectively.
As we can see, these CHDR-phrasal rules are par-
tially unlexicalized.
To alleviate the sparseness problem, we gener-
alize the lexicalized CHDR-normal rules and par-
tially unlexicalized CHDR-phrasal rules with un-
lexicalized nodes by the method proposed in Xie
et al, (2011). As the modification relations be-
tween head and dependents are determined by the
edges, we can replace the lexical word of each n-
ode with its category (POS tag) and obtain new
head-dependents relations with unlexicalized nodes
keeping the same modification relations. We gen-
eralize the rule by simultaneously turn the nodes of
the same type (head, internal, leaf) into their cate-
gories. For example, CHDR-normal rules r2 ? r7
are generalized from r1 in Figure 5-(d). Besides, r10
and r12 are the corresponding generalized CHDR-
phrasal rules. Actually, our CHDR rules are the su-
perset of head-dependents relation rules in Xie et
al., (2011). CHDR-normal rules are equivalent with
the head-dependents relation rules and the CHDR-
phrasal rules are the extension of these rules. For
convenience of description, we use the subscript to
distinguish the phrasal nodes with the same catego-
ry, such as VP2 and VP3. In actual operation, we use
VP instead of VP2 and VP3.
We handle the unaligned words of the target side
by extending the node spans of the lexicalized head
and leaf nodes, and the subtree spans of the lexical-
ized dependents, on both left and right directions.
This procedure is similar with the method of Och
and Ney, (2004). During this process, we might ob-
tain m(m ? 1) CHDR rules from an acceptable
fragment. Each of these rules is assigned with a frac-
tional count 1/m. We take the extracted rule set as
observed data and make use of relative frequency es-
timator to obtain the translation probabilities P (t|s)
and P (s|t).
4 Decoding and the Model
Following Och and Ney, (2002), we adopt a general
loglinear model. Let d be a derivation that convert a
1071
source phrasal nodes labeled dependency tree into a
target string e. The probability of d is defined as:
P (d) ?
?
i
?i(d)?i (1)
where ?i are features defined on derivations and ?i
are feature weights. In our experiments of this paper,
the features are used as follows:
? CHDR rules translation probabilities P (t|s)
and P (s|t), and CHDR rules lexical translation
probabilities Plex(t|s) and Plex(s|t);
? bilingual phrases translation probabilities
Pbp(t|s) and Pbp(s|t), and bilingual phrases
lexical translation probabilities Pbplex(t|s) and
Pbplex(s|t);
? rule penalty exp(?1);
? pseudo translation rule penalty exp(?1);
? target word penalty exp(|e|);
? language model Plm(e).
We have twelve features in our model. The values of
the first four features are accumulated on the CHDR
rules and the next four features are accumulated on
the bilingual phrases. We also use a pseudo transla-
tion rule (constructed according to the word order of
head-dependents relation) as a feature to guarantee
the complete translation when no matched rules can
be found during decoding.
Our decoder is based on bottom-up chart-based
algorithm. It finds the best derivation that convert
the input phrasal nodes labeled dependency tree into
a target string among all possible derivations. Giv-
en the source constituency tree and dependency tree,
we first generate phrasal nodes labeled dependency
tree T as described in Section 3.1, then the decoder
transverses each node in T by postorder. For each
node n, it enumerates all instances of CHDR rooted
at n, and checks the rule set for matched translation
rules. A larger translation is generated by substitut-
ing the variables in the target side of a translation
rule with the translations of the corresponding de-
pendents. Cube pruning (Chiang, 2007; Huang and
Chiang, 2007) is used to find the k-best items with
integrated language model for each node.
To balance the performance and speed of the de-
coder, we limit the search space by reducing the
number of translation rules used for each node.
There are two ways to limit the rule table size: by
a fixed limit (rule-limit) of how many rules are re-
trieved for each input node, and by a threshold (rule-
threshold) to specify that the rule with a score low-
er than ? times of the best score should be discard-
ed. On the other hand, instead of keeping the full
list of candidates for a given node, we keep a top-
scoring subset of the candidates. This can also be
done by a fixed limit (stack-limit) and a threshold
(stack-threshold).
5 Experiments
We evaluated the performance of our model by com-
paring with hierarchical phrase-based model (Chi-
ang, 2007), constituency-to-string model (Liu et al,
2006) and dependency-to-string model (Xie et al,
2011) on Chinese-English translation. First, we de-
scribe data preparation (Section 5.1) and systems
(Section 5.2). Then, we validate that our model sig-
nificantly outperforms all the other baseline models
(Section 5.3). Finally, we give detail analysis (Sec-
tion 5.4).
5.1 Data Preparation
Our training data consists of 1.25M sentence pairs
extracted from LDC 1 data. We choose NIST MT
Evaluation test set 2002 as our development set,
NIST MT Evaluation test sets 2003 (MT03), 2004
(MT04) and 2005 (MT05) as our test sets. The qual-
ity of translations is evaluated by the case insensitive
NIST BLEU-4 metric 2.
We parse the source sentences to constituency
trees (without binarization) and projective depen-
dency trees with Stanford Parser (Klein and Man-
ning, 2002). The word alignments are obtained by
running GIZA++ (Och and Ney, 2003) on the corpus
in both directions and using the ?grow-diag-final-
and? balance strategy (Koehn et al, 2003). We get
bilingual phrases from word-aligned data with algo-
rithm described in Koehn et al (2003) by running
Moses Toolkit 3. We apply SRI Language Modeling
Toolkit (Stolcke and others, 2002) to train a 4-gram
1Including LDC2002E18, LDC2003E07, LDC2003E14,
Hansards portion of LDC2004T07, LDC2004T08 and LD-
C2005T06.
2ftp://jaguar.ncsl.nist.gov/mt/resources/mteval-v11b.pl
3http://www.statmt.org/moses/
1072
System Rule # MT03 MT04 MT05 Average
Moses-chart 116.4M 34.65 36.47 34.39 35.17
cons2str 25.4M+32.5M 33.14 35.12 33.27 33.84
dep2str 19.6M+32.5M 34.85 36.57 34.72 35.38
consdep2str 23.3M+32.5M 35.57* 37.68* 35.62* 36.29
Table 1: Statistics of the extracted rules on training data and the BLEU scores (%) on the test sets of different systems.
The ?+? denotes that the rules are composed of syntactic translation rules and bilingual phrases (32.5M). The ?*?
denotes that the results are significantly better than all the other systems (p<0.01).
language model with modified Kneser-Ney smooth-
ing on the Xinhua portion of the English Gigaword
corpus. We make use of the standard MERT (Och,
2003) to tune the feature weights in order to maxi-
mize the system?s BLEU score on the development
set. The statistical significance test is performed by
sign-test (Collins et al, 2005).
5.2 Systems
We take the open source hierarchical phrase-based
system Moses-chart (with default configuration),
our in-house constituency-to-string system cons2str
and dependency-to-string system dep2str as our
baseline systems.
For cons2str, we follow Liu et al, (Liu et al,
2006) to strict that the height of a rule tree is no
greater than 3 and phrase length is no greater than
7. To keep consistent with our proposed model,
we implement the dependency-to-string model (X-
ie et al, 2011) with GHKM (Galley et al, 2004)
rule extraction algorithm and utilize bilingual phras-
es to translate source head node and dependency
syntactic phrases. Our dep2str shows comparable
performance with Xie et al, (2011), which can be
seen by comparing with the results of hierarchical
phrase-based model in our experiments. For dep2str
and our proposed model consdep2str, we set rule-
threshold and stack-threshold to 10?3, rule-limit to
100, stack-limit to 300, and phrase length limit to 7.
5.3 Experimental Results
Table 1 illustrates the translation results of our ex-
periments. As we can see, our consdep2str sys-
tem has gained the best results on all test sets, with
+1.12 BLEU points higher than Moses-chart, +2.45
BLEU points higher than cons2str, and +0.91 BLEU
points higher than dep2str, averagely on MT03,
MT04 and MT05. Our model significantly outper-
forms all the other baseline models, with p<0.01
on statistical significance test sign-test (Collins et
al., 2005). By exploiting two types of trees on
source side, our model gains significant improve-
ments over constituency-to-string and dependency-
to-string models, which employ single type of trees.
Table 1 also lists the statistical results of rules ex-
tracted from training data by different systems. Ac-
cording to our statistics, the number of rules extract-
ed by our consdep2str system is about 18.88% larger
than dep2str, without regard to the 32.5M bilingual
phrases. The extra rules are CHDR-phrasal rules,
which can bring in BLEU improvements by enhanc-
ing the compatibility with phrases. We will conduct
a deep analysis in the next sub-section.
5.4 Analysis
In this section, we first illustrate the influence of
CHDR-phrasal rules in our consdep2str model. We
calculate the proportion of 1-best translations in test
sets that employ CHDR-phrasal rules, and we cal-
l this proportion ?CHDR-phrasal Sent.?. Besides,
the proportion of CHDR-phrasal rules in all CHDR
rules is calculated in these translations, and we cal-
l this proportion ?CHDR-phrasal Rule?. Table 2
lists the using of CHDR-phrasal rules on test sets,
showing that CHDR-phrasal Sent. on all test sets
are higher than 50%, and CHDR-phrasal Rule on al-
l three test sets are higher than 10%. These results
indicate that CHDR-phrasal rules do play a role in
decoding.
Furthermore, we compare some actual transla-
tions of our test sets generated by cons2str, de-
p2str and consdep2str systems, as shown in Fig-
ure 6. In the first example, the Chinese input hold-
s long distance dependencies ???I ?? ?
... \u ... L? '??, which correspond
to the sentence pattern ?noun+adverb+prepositional
1073
System MT03 MT04 MT05
CHDR-phrasal Sent. 50.71 61.80 56.19
CHDR-phrasal Rule 10.53 13.55 10.83
Table 2: The proportion (%) of 1-best translations that
employs CHDR-phrasal rules (CHDR-phrasal Sent.) and
the proportion (%) of CHDR-phrasal rules in all CHDR
rules in these translations (CHDR-phrasal Rule).
phrase+verb+noun?. Cons2str gives a bad result
with wrong global reordering, while our consdep2str
system gains an almost correct result since we cap-
ture this pattern by CHDR-normal rules. In the sec-
ond example, we can see that the Chinese phrase
?2g?y? is a non-syntactic phrase in the depen-
dency tree, and this phrase can not be captured by
head-dependents relation rules in Xie et al, (2011),
thus can not be translated as one unit. Since we en-
code constituency phrasal nodes to the dependency
tree, ?2g?y? is labeled by a phrasal node ?VP?
(means verb phrase), which can be captured by our
CHDR-phrasal rules and translated into the correct
result ?reemergence? with bilingual phrases.
By combining the merits of constituency and
dependency trees, our consdep2str model learns
CHDR-normal rules to acquire the property of long
distance reorderings and CHDR-phrasal rules to ob-
tain good compatibility with phrases.
6 Related Work
In recent years, syntax-based models have witnessed
promising improvements. Some researchers make
efforts on constituency-based models (Graehl and
Knight, 2004; Liu et al, 2006; Huang et al, 2006;
Zhang et al, 2007; Mi et al, 2008; Liu et al, 2009;
Liu et al, 2011; Zhai et al, 2012). Some works pay
attention to dependency-based models (Lin, 2004;
Ding and Palmer, 2005; Quirk et al, 2005; Xiong et
al., 2007; Shen et al, 2008; Xie et al, 2011). These
models are based on single type of trees.
There are also some approaches combining mer-
its of different structures. Marton and Resnik (2008)
took the source constituency tree into account and
added soft constraints to the hierarchical phrase-
based model (Chiang, 2005). Cherry (2008) u-
tilized dependency tree to add syntactic cohesion
to the phrased-based model. Mi and Liu, (2010)
proposed a constituency-to-dependency translation
model, which utilizes constituency forests on the
source side to direct the translation, and depen-
dency trees on the target side to ensure grammati-
cality. Feng et al (2012) presented a hierarchical
chunk-to-string translation model, which is a com-
promise between the hierarchical phrase-based mod-
el and the constituency-to-string model. Most work-
s make effort to introduce linguistic knowledge in-
to the phrase-based model and hierarchical phrase-
based model with constituency trees. Only the work
proposed by Mi and Liu, (2010) utilized constituen-
cy and dependency trees, while their work applied
two types of trees on two sides.
Instead, our model simultaneously utilizes con-
stituency and dependency trees on the source side to
direct the translation, which is concerned with com-
bining the advantages of two types of trees in trans-
lation rules to advance the state-of-the-art machine
translation.
7 Conclusion
In this paper, we present a novel model that si-
multaneously utilizes constituency and dependency
trees on the source side to direct the translation. To
combine the merits of constituency and dependen-
cy trees, our model employs head-dependents rela-
tions incorporating with constituency phrasal nodes.
Experimental results show that our model exhibits
good performance and significantly outperforms the
state-of-the-art constituency-to-string, dependency-
to-string and hierarchical phrase-based models. For
the first time, source side constituency and depen-
dency trees are simultaneously utilized to direct the
translation, and the model surpasses the state-of-the-
art translation models.
Since constituency tree binarization can lead
to more constituency-to-string rules and syntactic
phrases in rule extraction and decoding, which im-
prove the performance of constituency-to-string sys-
tems, for future work, we would like to do research
on encoding binarized constituency trees to depen-
dency trees to improve translation performance.
Acknowledgments
The authors were supported by National Natural Sci-
ence Foundation of China (Contracts 61202216),
1074
MT05 ---- segment 448
??? ?? ? ?? ?? ??? ?? ?? ? ?? ?? ???
cons2srt: united nations with the indonesian government have expressed concern over the time limit for foreign troops .
consdep2srt: the united nations has expressed concern over the deadline of the indonesian government on foreign troops .
reference: The United Nations has expressed concern over the deadline the Indonesian government imposed on foreign troops.
??? ?? ?? ?? ??? ?? ?? ? ??? ?? ?? ?
dobjpobj
prep
advmod
nsubj
pnuct
the united nations has the deadline of the indonesian government on foreign troopsexpressed concern over .
?? ?? ?? ? ?? ?? ??? ??? 6$56?? ??
dep2srt: ?? again severe acute respiratory syndrome ( SARS ) case ??
consdep2srt: ?? reemergence of a severe acute respiratory syndrome ( SARS ) case??
reference: ?? the reemergence of a severe acute respiratory syndrome (SARS) case ??
MT04 ---- segment 194
dep cons & dep
??/VV
??/AD ?/DEG
VP
reemergence
???/NN
??/JJ ??/JJ??/VV
??/AD ?/DEG
again
???/NN
??/JJ ??/JJ
Figure 6: Actual examples translated by the cons2str, dep2str and consdep2str systems.
863 State Key Project (No. 2011AA01A207),
and National Key Technology R&D Program (No.
2012BAH39B03), Key Project of Knowledge Inno-
vation Program of Chinese Academy of Sciences
(No. KGZD-EW-501). Qun Liu.s work was
partially supported by Science Foundation Ireland
(Grant No. 07/CE/I1142) as part of the CNGL
at Dublin City University. Sincere thanks to the
anonymous reviewers for their thorough reviewing
and valuable suggestions. We appreciate Haitao Mi,
Zhaopeng Tu and Anbang Zhao for insightful ad-
vices in writing.
References
Colin Cherry. 2008. Cohesive phrase-based decoding for
statistical machine translation. In ACL, pages 72?80.
David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Proceedings of
the 43rd Annual Meeting on Association for Computa-
tional Linguistics, pages 263?270.
David Chiang. 2007. Hierarchical phrase-based transla-
tion. Computational Linguistics, 33(2):201?228.
Michael Collins, Philipp Koehn, and Ivona Kuc?erova?.
2005. Clause restructuring for statistical machine
translation. In Proceedings of the 43rd Annual Meet-
ing on Association for Computational Linguistics,
pages 531?540.
Yuan Ding and Martha Palmer. 2005. Machine trans-
lation using probabilistic synchronous dependency in-
sertion grammars. In Proceedings of the 43rd Annual
Meeting on Association for Computational Linguistic-
s, pages 541?548.
Yang Feng, Dongdong Zhang, Mu Li, Ming Zhou, and
Qun Liu. 2012. Hierarchical chunk-to-string transla-
tion. In Proceedings of the 50th Annual Meeting of
the Association for Computational Linguistics: Long
Papers-Volume 1, pages 950?958.
Heidi J Fox. 2002. Phrasal cohesion and statistical
machine translation. In Proceedings of the ACL-02
conference on Empirical methods in natural language
processing-Volume 10, pages 304?3111.
Michel Galley, Mark Hopkins, Kevin Knight, and Daniel
Marcu. 2004. What?s in a translation rule. In Pro-
1075
ceedings of HLT/NAACL, volume 4, pages 273?280.
Boston.
Jonathan Graehl and Kevin Knight. 2004. Training tree
transducers. In Proc. HLT-NAACL, pages 105?112.
Peter Hellwig. 2006. Parsing with dependency gram-
mars. An International Handbook of Contemporary
Research, 2:1081?1109.
Liang Huang and David Chiang. 2007. Forest rescoring:
Faster decoding with integrated language models. In
Annual Meeting-Association For Computational Lin-
guistics, volume 45, pages 144?151.
Liang Huang, Kevin Knight, and Aravind Joshi. 2006. S-
tatistical syntax-directed translation with extended do-
main of locality. In Proceedings of AMTA, pages 66?
73.
Dan Klein and Christopher D Manning. 2002. Fast exact
inference with a factored model for natural language
parsing. In Advances in neural information processing
systems, volume 15, pages 3?10.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Proceed-
ings of the 2003 Conference of the North American
Chapter of the Association for Computational Linguis-
tics on Human Language Technology-Volume 1, pages
48?54.
Dekang Lin. 2004. A path-based transfer model for ma-
chine translation. In Proceedings of the 20th interna-
tional conference on Computational Linguistics, pages
625?630.
Yang Liu, Qun Liu, and Shouxun Lin. 2006. Tree-to-
string alignment template for statistical machine trans-
lation. In Proceedings of the 21st International Con-
ference on Computational Linguistics and the 44th
annual meeting of the Association for Computational
Linguistics, pages 609?616.
Yang Liu, Yajuan Lu?, and Qun Liu. 2009. Improving
tree-to-tree translation with packed forests. In Pro-
ceedings of the Joint Conference of the 47th Annual
Meeting of the ACL and the 4th International Join-
t Conference on Natural Language Processing of the
AFNLP: Volume 2-Volume 2, pages 558?566.
Yang Liu, Qun Liu, and Yajuan Lu?. 2011. Adjoining
tree-to-string translation. In Proceedings of the 49th
Annual Meeting of the Association for Computational
Linguistics: Human Language Technologies-Volume
1, pages 1278?1287.
Yuval Marton and Philip Resnik. 2008. Soft syntactic
constraints for hierarchical phrased-based translation.
In Proceedings of ACL-08: HLT, pages 1003?1011.
Haitao Mi and Qun Liu. 2010. Constituency to depen-
dency translation with forests. In Proceedings of the
48th Annual Meeting of the Association for Computa-
tional Linguistics, pages 1433?1442.
Haitao Mi, Liang Huang, and Qun Liu. 2008. Forest-
based translation. In Proceedings of ACL-08: HLT,
pages 192?199.
Franz Josef Och and Hermann Ney. 2002. Discrimi-
native training and maximum entropy models for s-
tatistical machine translation. In Proceedings of the
40th Annual Meeting on Association for Computation-
al Linguistics, pages 295?302.
Franz Josef Och and Hermann Ney. 2003. A systemat-
ic comparison of various statistical alignment models.
Computational linguistics, 29(1):19?51.
Franz Josef Och and Hermann Ney. 2004. The alignmen-
t template approach to statistical machine translation.
Computational linguistics, 30(4):417?449.
Franz Josef Och. 2003. Minimum error rate training in
statistical machine translation. In Proceedings of the
41st Annual Meeting on Association for Computation-
al Linguistics-Volume 1, pages 160?167.
Chris Quirk, Arul Menezes, and Colin Cherry. 2005. De-
pendency treelet translation: Syntactically informed
phrasal smt. In Proceedings of the 43rd Annual
Meeting on Association for Computational Linguistic-
s, pages 271?279.
Libin Shen, Jinxi Xu, and Ralph Weischedel. 2008. A
new string-to-dependency machine translation algo-
rithm with a target dependency language model. In
Proceedings of ACL-08: HLT, pages 577?585.
Andreas Stolcke et al 2002. Srilm-an extensible lan-
guage modeling toolkit. In Proceedings of the inter-
national conference on spoken language processing,
volume 2, pages 901?904.
Jun Xie, Haitao Mi, and Qun Liu. 2011. A nov-
el dependency-to-string model for statistical machine
translation. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing,
pages 216?226.
Deyi Xiong, Qun Liu, and Shouxun Lin. 2007. A de-
pendency treelet string correspondence model for s-
tatistical machine translation. In Proceedings of the
Second Workshop on Statistical Machine Translation,
pages 40?47.
Kenji Yamada and Kevin Knight. 2001. A syntax-based
statistical translation model. In Proceedings of the
39th Annual Meeting on Association for Computation-
al Linguistics, pages 523?530.
Feifei Zhai, Jiajun Zhang, Yu Zhou, and Chengqing
Zong. 2012. Tree-based translation without using
parse trees. In Proceedings of COLING 2012, pages
3037?3054.
Min Zhang, Hongfei Jiang, AiTi Aw, Jun Sun, Sheng Li,
and Chew Lim Tan. 2007. A tree-to-tree alignment-
based model for statistical machine translation. MT-
Summit-07, pages 535?542.
1076
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 177?182,
October 25-29, 2014, Doha, Qatar. c?2014 Association for Computational Linguistics
Syntactic SMT Using a Discriminative Text Generation Model
Yue Zhang Kai Song? Linfeng Song?
SUTD, Singapore NEU, China ICT/CAS, China
yue zhang@sutd.edu.sg songkai.sk@alibaba-inc.com songlinfeng@ict.ac.cn
Jingbo Zhu Qun Liu
NEU, China CNGL, Ireland and ICT/CAS, China
zhujingbo@mail.neu.edu.cn qliu@computing.dcu.ie
Abstract
We study a novel architecture for syntactic
SMT. In contrast to the dominant approach
in the literature, the system does not rely
on translation rules, but treat translation
as an unconstrained target sentence gen-
eration task, using soft features to cap-
ture lexical and syntactic correspondences
between the source and target languages.
Target syntax features and bilingual trans-
lation features are trained consistently in
a discriminative model. Experiments us-
ing the IWSLT 2010 dataset show that the
system achieves BLEU comparable to the
state-of-the-art syntactic SMT systems.
1 Introduction
Translation rules have been central to hierarchi-
cal phrase-based and syntactic statistical machine
translation (SMT) (Galley et al., 2004; Chiang,
2005; Liu et al., 2006; Quirk et al., 2005; Marcu et
al., 2006; Shen and Joshi, 2008; Xie et al., 2011).
They are attractive by capturing the recursiveness
of languages and syntactic correspondences be-
tween them. One important advantage of trans-
lation rules is that they allow efficient decoding
by treating MT as a statistical parsing task, trans-
forming a source sentence to its translation via re-
cursive rule application.
The efficiency takes root in the fact that target
word orders are encoded in translation rules. This
fact, however, also leads to rule explosion, noise
and coverage problems (Auli et al., 2009), which
can hurt translation quality. Flexibility of function
word usage, rich morphology and paraphrasing all
add to the difficulty of rule extraction. In addition,
restricting target word orders by hard translation
rules can also hurt output fluency.
?
* Work done while visiting Singapore University of
Technology and Design (SUTD)
Figure 1: Overall system architecture.
A potential solution to the problems above is to
treat translation as a generation task, represent-
ing syntactic correspondences using soft features.
Both adequacy and fluency can potentially be im-
proved by giving full flexibility to target synthe-
sis, and leaving all options to the statistical model.
The main challenge to this method is a signifi-
cant increase in the search space (Knight, 1999).
To this end, recent advances in tackling complex
search tasks for text generation offer some so-
lutions (White and Rajkumar, 2009; Zhang and
Clark, 2011).
In this short paper, we present a preliminary in-
vestigation on the possibility of building a syn-
tactic SMT system that does not use hard transla-
tion rules, by utilizing recent advances in statisti-
cal natural language generation (NLG). The over-
all architecture is shown in Figure 1. Translation
is performed by first parsing the source sentence,
then transferring source words and phrases to their
target equivalences, and finally synthesizing the
target output.
We choose dependency grammar for both the
source and the target syntax, and adapt the syntac-
tic text synthesis system of Zhang (2013), which
performs dependency-based linearization. The
linearization task for MT is different from the
monolingual task in that not all translation options
are used to build the output, and that bilingual cor-
respondences need to be taken into account dur-
177
ing synthesis. The algorithms of Zhang (2013) are
modified to perform word selection as well as or-
dering, using two sets of features to control trans-
lation adequacy and fluency, respectively.
Preliminary experiments on the IWSLT1 2010
data show that the system gives BLEU compara-
ble to traditional tree-to-string and string-to-tree
translation systems. It demonstrates the feasibility
of leveraging statistical NLG techniques for SMT,
and the possibility of building a statistical transfer-
based MT system.
2 Approach
The main goal being proof of concept, we keep
the system simple by utilizing existing methods
for the main components, minimizing engineer-
ing efforts. Shown in Figure 1, the end-to-end
system consists of two main components: lexical
transfer and synthesis. The former provides can-
didate translations for (overlapping) source words
and phrases. Although lexicons and rules can
be used for this step, we take a simple statisti-
cal alignment-based approach. The latter searches
for a target translation by constructing dependency
trees bottom-up. The process can be viewed as
a syntax-based generation process from a bag of
overlapping translation options.
2.1 Lexical transfer
We perform word alignment using IBM model 4
(Brown et al., 1993), and then extract phrase pairs
according to the alignment and automatically-
annotated target syntax. In particular, consistent
(Och et al., 1999) and cohesive (Fox, 2002) phrase
pairs are extracted from intersected alignments in
both directions: the target side must form a pro-
jective span, with a single root, and the source side
must be contiguous. A resulting phrase pair con-
sists of the source phrase, its target translation, as
well as the head position and head part-of-speech
(POS) of the target span, which are useful for tar-
get synthesis. We further restrict that neither the
source nor the target side of a valid phrase pair
contains over s words.
Given an input source sentence, the lexical
transfer unit finds all valid target translation op-
tions for overlapping source phrases up to size s,
and feeds them as inputs to the target synthesis de-
coder. The translation options with a probability
1International Workshop on Spoken Language Transla-
tion, http://iwslt2010.fbk.eu
below ? ? P
max
are filtered out, where P
max
is the
probability of the most probable translation. Here
the probability of a target translation is calculated
as the count of the translation divided by the count
of all translations of the source phrase.
2.2 Synthesis
The synthesis module is based on the monolingual
text synthesis algorithm of Zhang (2013), which
constructs an ordered dependency tree given a bag
of words. In the bilingual setting, inputs to the al-
gorithm are translation options, which can be over-
lapping and mutually exclusive, and not necessar-
ily all of which are included in the output. As a
result, the decoder needs to perform word selec-
tion in addition to word ordering. Another differ-
ence between the bilingual and monolingual set-
tings is that the former requires translation ade-
quacy in addition to output fluency.
We largely rely on the monolingual system for
MT decoding. To deal with overlapping transla-
tion options, a source coverage vector is used to
impose mutual exclusiveness on input words and
phrases. Each element in the coverage vector is
a binary value that indicates whether a particular
source word has been translated in the correspond-
ing target hypothesis. For translation adequacy,
we use a set of bilingual features on top of the set
of monolingual features for text synthesis.
2.2.1 Search
The search algorithm is the best-first algorithm of
Zhang (2013). Each search hypothesis is a par-
tial or full target-language dependency tree, and
hypotheses are constructed bottom-up from leaf
nodes, which are translation options. An agenda
is used to maintain a list of search hypothesis to
be expanded, and a chart is used to record a set
of accepted hypotheses. Initially empty, the chart
is a beam of size k ? n, where n is the number
of source words and k is a positive integer. The
agenda is a priority queue, initialized with all leaf
hypotheses (i.e. translation options). At each step,
the highest-scored hypothesis e is popped off the
agenda, and expanded by combination with all hy-
potheses on the chart in all possible ways, with
the set of newly generated hypotheses e
1
, e
2
, ...e
N
being put onto the agenda, and e being put onto
the chart. When two hypotheses are combined,
they can be put in two different orders, and in each
case different dependencies can be constructed be-
tween their head words, leading to different new
178
dependency syntax
WORD(h) ? POS(h) ? NORM(size) ,
WORD(h) ? NORM(size), POS(h) ? NORM(size)
POS(h) ? POS(m) ? POS(b) ? dir
POS(h) ? POS(h
l
) ? POS(m) ? POS(m
r
) ? dir (h > m),
POS(h) ? POS(h
r
) ? POS(m) ? POS(m
l
) ? dir (h < m)
WORD(h) ? POS(m) ? POS(m
l
) ? dir ,
WORD(h) ? POS(m) ? POS(m
r
) ? dir
POS(h) ? POS(m) ? POS(m
1
) ? dir ,
POS(h) ? POS(m
1
) ? dir , POS(m) ? POS(m
1
) ? dir
WORD(h) ? POS(m) ? POS(m
1
) ? POS(m
2
) ? dir ,
POS(h) ? POS(m) ? POS(m
1
) ? POS(m
2
) ? dir ,
...
dependency syntax for completed words
WORD(h) ? POS(h) ? WORD(h
l
) ? POS(h
l
),
POS(h) ? POS(h
l
),
WORD(h) ? POS(h) ? POS(h
l
),
POS(h) ? WORD(h
l
) ? POS(h
l
) ,
WORD(h) ? POS(h) ? WORD(h
r
) ? POS(h
r
),
POS(h) ? POS(h
r
),
...
surface string patterns (B?bordering index)
WORD(B ? 1) ? WORD(B), POS(B ? 1) ? POS(B),
WORD(B ? 1) ? POS(B), POS(B ? 1) ? WORD(B),
WORD(B ? 1) ? WORD(B) ? WORD(B + 1),
WORD(B ? 2) ? WORD(B ? 1) ? WORD(B),
POS(B ? 1) ? POS(B) ? POS(B + 1),
...
surface string patterns for complete sentences
WORD(0), WORD(0) ? WORD(1),
WORD(size ? 1),
WORD(size ? 1) ? WORD(size ? 2),
POS(0), POS(0) ? POS(1),
POS(0) ? POS(1) ? POS(2),
...
Table 1: Monolingual feature templates.
hypotheses. The decoder expands a fixed number
L hypotheses, and then takes the highest-scored
chart hypothesis that contains over ? ? n words as
the output, where ? is a real number near 1.0.
2.2.2 Model and training
A scaled linear model is used by the decoder to
score search hypotheses:
Score(e) =
~
? ? ?(e)
|e|
,
where ?(e) is the global feature vector of the hy-
pothesis e, ~? is the parameter vector of the model,
and |e| is the number of leaf nodes in e. The
scaling factor |e| is necessary because hypothe-
ses with different numbers of words are compared
with each other in the search process to capture
translation equivalence.
While the monolingual features of Zhang
(2013) are applied (example feature templates
from the system are shown in Table 1), an addi-
tional set of bilingual features is defined, shown
phrase translation features
PHRASE(m) ? PHRASE(t), P (trans),
bilingual syntactic features
POS(th) ? POS(tm) ? dir ? LEN(path),
WORD(th) ? POS(tm) ? dir ? LEN(path),
POS(th) ? WORD(tm) ? dir ? LEN(path),
WORD(th) ? WORD(tm) ? dir ? LEN(path),
WORD(sh) ? WORD(sm) ? dir ? LEN(path),
WORD(sh) ? WORD(th) ? dir ? LEN(path),
WORD(sm) ? WORD(tm) ? dir ? LEN(path),
bilingual syntactic features (LEN(path) ? 3)
POS(th) ? POS(tm) ? dir ? LABELS(path),
WORD(th) ? POS(tm) ? dir ? LABELS(path),
POS(th) ? WORD(tm) ? dir ? LABELS(path),
WORD(th) ? WORD(tm) ? dir ? LABELS(path),
WORD(sh) ? WORD(sm) ? dir ? LABELS(path),
WORD(sh) ? WORD(th) ? dir ? LABELS(path),
WORD(sm) ? WORD(tm) ? dir ? LABELS(path),
POS(th) ? POS(tm) ? dir ? LABELSPOS(path),
WORD(th) ? POS(tm) ? dir ? LABELSPOS(path),
POS(th) ? WORD(tm) ? dir ? LABELSPOS(path),
WORD(th) ? WORD(tm) ? dir ? LABELSPOS(path),
WORD(sh) ? WORD(sm) ? dir ? LABELSPOS(path),
WORD(sh) ? WORD(th) ? dir ? LABELSPOS(path),
WORD(sm) ? WORD(tm) ? dir ? LABELSPOS(path),
Table 2: Bilingual feature templates.
in Table 2. In the tables, s and t represent the
source and target, respectively; h and m repre-
sent the head and modifier in a dependency arc,
respectively; h
l
and h
r
represent the neighboring
words on the left and right of h, respectively; m
l
and m
r
represent the neighboring words on the left
and right of m, respectively; m
1
and m
2
repre-
sent the closest and second closest sibling of m on
the side of h, respectively. dir represents the arc
direction (i.e. left or right); PHRASE represents
a lexical phrase; P(trans) represents the source-
to-target translation probability from the phrase-
table, used as a real-valued feature; path repre-
sents the shortest path in the source dependency
tree between the two nodes that correspond to the
target head and modifier, respectively; LEN(path)
represents the number of arcs on path, normalized
to bins of [5, 10, 20, 40+]; LABELS(path) repre-
sents the array of dependency arc labels on path;
LABELSPOS(path) represents the array of depen-
dency arc labels and source POS on path. In addi-
tion, a real-valued four-gram language model fea-
ture is also used, with four-grams extracted from
the surface boundary when two hypothesis are
combined.
We apply the discriminative learning algorithm
of Zhang (2013) to train the parameters ~?. The al-
gorithm requires training examples that consist of
full target derivations, with leaf nodes being input
translation options. However, the readily available
179
training examples are automatically-parsed target
derivations, with leaf nodes being the reference
translation. As a result, we apply a search pro-
cedure to find a derivation process, through which
the target dependency tree is constructed from a
subset of input translation options. The search
procedure can be treated as a constrained decod-
ing process, where only the oracle tree and its sub
trees can be constructed. In case the set of transla-
tion options cannot lead to the oracle tree, we ig-
nore the training instance.2 Although the ignored
training sentence pairs cannot be utilized for train-
ing the discriminative synthesizer, they are never-
theless used for building the phrase table and train-
ing the language model.
3 Experiments
We perform experiments on the IWSLT 2010
Chinese-English dataset, which consists of train-
ing sentence pairs from the dialog task (dialog)
and Basic Travel and Expression Corpus (BTEC).
The union of dialog and BTEC are taken as our
training set, which contains 30,033 sentence pairs.
For system tuning, we use the IWSLT 2004 test set
(also released as the second development test set
of IWSLT 2010), which contains 500 sentences.
For final test, we use the IWSLT 2003 test set (also
released as the first development test set of IWSLT
2010), which contains 506 sentences.
The Chinese sentences in the datasets are seg-
mented using NiuTrans3 (Xiao et al., 2012), while
POS-tagging of both English and Chinese is per-
formed using ZPar4 version 0.5 (Zhang and Clark,
2011). We train the English POS-tagger using the
WSJ sections of the Penn Treebank (Marcus et al.,
1993), turned into lower-case. For syntactic pars-
ing of both English and Chinese, we use the de-
fault models of ZPar 0.5.
We choose three baseline systems: a string-to-
tree (S2T) system, a tree-to-string (T2S) system
and a tree-to-tree (T2T) system (Koehn, 2010).
The Moses release 1.0 implementations of all
three systems are used, with default parameter set-
tings. IRSTLM5 release 5.80.03 (Federico et al.,
2008) is used to train a four-gram language models
2This led to the ignoring of over 40% of the training sen-
tence pairs. For future work, we will consider substitute or-
acles from reachable target derivations by using maximum
sentence level BLEU approximation (Nakov et al., 2012) or
METEOR (Denkowski and Lavie, 2011) as selection criteria.
3http://www.nlplab.com/NiuPlan/NiuTrans.ch.html
4http://sourceforge.net/projects/zpar/
5http://sourceforge.net/apps/mediawiki/irstlm
System T2S S2T T2T OURS
BLEU 32.65 36.07 28.46 34.24
Table 3: Final results.
SOURCE:?????????
REF: I have a terrible headache .
OURS: now , I have a headache .
SOURCE:??????????
REF: I ?d like a twin room with a bath please .
OURS: a twin room , I ?ll find a room with a bath .
SOURCE:??????????
REF: can you change yen into dollars ?
OURS: please change yen into dollars .
SOURCE:????? ?
REF: roast chicken , please .
OURS: please have roast chicken .
SOURCE:?????????
REF: take two tablets after every meal .
OURS: please eat after each meal .
SOURCE:????
REF: check , please .
OURS: I have to check - out , please .
SOURCE:?????????????
REF: yes , well , that ?s our specialty .
OURS: ah , the food that ?s right .
SOURCE:?????
REF: my air conditioner is n?t working .
OURS: the air - conditioner does n?t work .
Table 4: Sample output sentences.
over the English training data, which is applied to
the baseline systems and our system. Kneser-Ney
smoothing is used to train the language model.
We use the tuning set to determine the optimal
number of training iterations. The translation op-
tion filter ? is set to 0.1; the phrase size limit s is
set to 5 in order to verify the effectiveness of syn-
thesis; the number of expanded nodes L is set to
200; the chart factor k is set to 16 for a balance be-
tween efficiency and accuracy; the goal parameter
? is set to 0.8.
The final scores of our system and the baselines
are shown in Table 3. Our system gives a BLEU
of 34.24, which is comparable to the baseline sys-
tems. Some example outputs are shown in Table 4.
Manual comparison does not show significant dif-
ferences in overall translation adequacy or fluency
between the outputs of the four systems. However,
an observation is that, while our system can pro-
duce more fluent outputs, the choice of translation
options can be more frequently incorrect. This
suggests that while the target synthesis component
is effective under the bilingual setting, a stronger
lexical selection component may be necessary for
better translation quality.
180
4 Related work
As discussed in the introduction, our work is
closely related to previous studies on syntactic
MT, with the salient difference that we do not rely
on hard translation rules, but allow free target syn-
thesis. The contrast can be summarized as ?trans-
lation by parsing? vs ?translation by generation?.
There has been a line of research on genera-
tion for translation. Soricut and Marcu (2006) use
a form of weighted IDL-expressions (Nederhof
and Satta, 2004) for generation. Bangalore et al.
(2007) treats MT as a combination of global lex-
ical transfer and word ordering; their generation
component does not perform lexical selection, re-
lying on an n-gram language model to order target
words. Goto et al. (2012) use a monotonic phrase-
based system to perform target word selection, and
treats target ordering as a post-processing step.
More recently, Chen et al. (2014) translate source
dependencies arc-by-arc to generate pseudo target
dependencies, and generate the translation by re-
ordering of arcs. In contrast with these systems,
our system relies more heavily on a syntax-based
synthesis component, in order to study the useful-
ness of statistical NLG on SMT.
With respect to syntax-based word ordering,
Chang and Toutanova (2007) and He et al. (2009)
study a simplified word ordering problem by as-
suming that the un-ordered target dependency tree
is given. Wan et al. (2009) and Zhang and Clark
(2011) study the ordering of a bag of words, with-
out input syntax. Zhang et al. (2012), Zhang
(2013) and Song et al. (2014) further extended this
line of research by adding input syntax and allow-
ing joint inflection and ordering. de Gispert et al.
(2014) use a phrase-structure grammer for word
ordering. Our generation system is based on the
work of Zhang (2013), but further allows lexical
selection.
Our work is also in line with the work of Liang
et al. (2006), Blunsom et al. (2008), Flanigan et
al. (2013) and Yu et al. (2013) in that we build a
discriminative model for SMT.
5 Conclusion
We investigated a novel system for syntactic ma-
chine translation, treating MT as an unconstrained
generation task, solved by using a single discrim-
inative model with both monolingual syntax and
bilingual translation features. Syntactic corre-
spondence is captured by using soft features rather
than hard translation rules, which are used by most
syntax-based statistical methods in the literature.
Our results are preliminary in the sense that
the experiments were performed using a relatively
small dataset, and little engineering effort was
made on fine-tuning of parameters for the base-
line and proposed models. Our Python imple-
mentation gives the same level of BLEU scores
compared with baseline syntactic SMT systems,
but is an order of magnitude slower than Moses.
However, the results demonstrate the feasibility of
leveraging text generation techniques for machine
translation, directly connecting the two currently
rather separated research fields. The system is not
strongly dependent on the specific generation al-
gorithm, and one potential of the SMT architec-
ture is that it can directly benefit from advances in
statistical NLG technology.
Acknowledgement
The work has been supported by the Singa-
pore Ministration of Education Tier 2 project
T2MOE201301 and the startup grant SRG ISTD
2012 038 from SUTD. We thank the anonymous
reviewers for their constructive comments.
References
Michael Auli, Adam Lopez, Hieu Hoang, and Philipp
Koehn. 2009. A systematic analysis of translation
model search spaces. In Proc. WMT, pages 224?
232.
Srinivas Bangalore, Patrick Haffner, and Stephan Kan-
thak. 2007. Statistical machine translation through
global lexical selection and sentence reconstruction.
In Proc. ACL, pages 152?159.
Phil Blunsom, Trevor Cohn, and Miles Osborne. 2008.
A discriminative latent variable model for statistical
machine translation. In Proc. ACL, pages 200?208.
Peter F. Brown, Stephen Della Pietra, Vincent J. Della
Pietra, and Robert L. Mercer. 1993. The mathe-
matics of statistical machine translation: Parameter
estimation. Computational Linguistics, 19(2):263?
311.
Pi-Chuan Chang and Kristina Toutanova. 2007. A dis-
criminative syntactic word order model for machine
translation. In Proc. ACL, pages 9?16.
Hongshen Chen, Jun Xie, Fandong Meng, Wenbin
Jiang, and Qun Liu. 2014. A dependency edge-
based transfer model for statistical machine transla-
tion. In Proc. COLING 2014, pages 1103?1113.
181
David Chiang. 2005. A hierarchical phrase-based
model for statistical machine translation. In Proc.
ACL, pages 263?270.
Adria` de Gispert, Marcus Tomalin, and Bill Byrne.
2014. Word ordering with phrase-based grammars.
In Proc. EACL, pages 259?268.
Michael Denkowski and Alon Lavie. 2011. Meteor
1.3: Automatic metric for reliable optimization and
evaluation of machine translation systems. In Proc.
WMT, pages 85?91.
Marcello Federico, Nicola Bertoldi, and Mauro Cet-
tolo. 2008. IRSTLM: an open source toolkit for
handling large scale language models. In Proc. In-
terspeech, pages 1618?1621.
Jeffrey Flanigan, Chris Dyer, and Jaime Carbonell.
2013. Large-scale discriminative training for statis-
tical machine translation using held-out line search.
In Proc. NAACL, pages 248?258.
Heidi Fox. 2002. Phrasal cohesion and statistical ma-
chine translation. In Proc. EMNLP, pages 304?311.
Michel Galley, Mark Hopkins, Kevin Knight, and
Daniel Marcu. 2004. What?s in a translation rule?
In Proc. HLT-NAACL, pages 273?280.
Isao Goto, Masao Utiyama, and Eiichiro Sumita. 2012.
Post-ordering by parsing for Japanese-English sta-
tistical machine translation. In Proc. ACL, pages
311?316.
Wei He, Haifeng Wang, Yuqing Guo, and Ting Liu.
2009. Dependency based Chinese sentence realiza-
tion. In Proc. ACL/AFNLP, pages 809?816.
Kevin Knight. 1999. Squibs and Discussions: Decod-
ing Complexity in Word-Replacement Translation
Models. Computational Linguistics, 25(4):607?
615.
Phillip Koehn. 2010. Statistical Machine Translation.
Cambridge University Press.
P. Liang, A. Bouchard-Cote, D. Klein, and B. Taskar.
2006. An end-to-end discriminative approach to
machine translation. In Proc. COLING/ACL, pages
761?768.
Yang Liu, Qun Liu, and Shouxun Lin. 2006. Tree-
to-string alignment template for statistical machine
translation. In Proc. COLING/ACL, pages 609?616.
Daniel Marcu, Wei Wang, Abdessamad Echihabi, and
Kevin Knight. 2006. SPMT: Statistical machine
translation with syntactified target language phrases.
In Proc. EMNLP, pages 44?52.
Mitchell P. Marcus, Mary Ann Marcinkiewicz, and
Beatrice Santorini. 1993. Building a large anno-
tated corpus of English: The penn treebank. Com-
putational linguistics, 19(2):313?330.
Preslav Nakov, Francisco Guzman, and Stephan Vo-
gel. 2012. Optimizing for sentence-level BLEU+1
yields short translations. In Proc. Coling, pages
1979?1994.
Mark-Jan Nederhof and Giorgio Satta. 2004. Idl-
expressions: a formalism for representing and pars-
ing finite languages in natural language processing.
J. Artif. Intell. Res.(JAIR), 21:287?317.
Franz Josef Och, Christoph Tillmann, and Hermann
Ney. 1999. Improved alignment models for statis-
tical machine translation. In Proc. EMNLP, pages
20?28.
Chris Quirk, Arul Menezes, and Colin Cherry. 2005.
Dependency treelet translation: Syntactically in-
formed phrasal smt. In Proc. ACL, pages 271?279.
Libin Shen and Aravind Joshi. 2008. LTAG depen-
dency parsing with bidirectional incremental con-
struction. In Proc. EMNLP, pages 495?504.
Linfeng Song, Yue Zhang, Kai Song, and Qun Liu.
2014. Joint morphological generation and syntactic
linearization. In Proc. AAAI, pages 1522?1528.
Radu Soricut and Daniel Marcu. 2006. Stochastic lan-
guage generation using widl-expressions and its ap-
plication in machine translation and summarization.
In Proc. ACL, pages 1105?1112.
Stephen Wan, Mark Dras, Robert Dale, and Ce?cile
Paris. 2009. Improving grammaticality in statisti-
cal sentence generation: Introducing a dependency
spanning tree algorithm with an argument satisfac-
tion model. In Proc. EACL, pages 852?860.
Michael White and Rajakrishnan Rajkumar. 2009.
Perceptron reranking for CCG realization. In Proc.
the EMNLP, pages 410?419.
Tong Xiao, Jingbo Zhu, Hao Zhang, and Qiang Li.
2012. NiuTrans: An open source toolkit for phrase-
based and syntax-based machine translation. In
Proc. ACL Demos, pages 19?24.
Jun Xie, Haitao Mi, and Qun Liu. 2011. A novel
dependency-to-string model for statistical machine
translation. In Proc. EMNLP, pages 216?226.
Heng Yu, Liang Huang, Haitao Mi, and Kai Zhao.
2013. Max-violation perceptron and forced decod-
ing for scalable MT training. In Proc. EMNLP,
pages 1112?1123.
Yue Zhang and Stephen Clark. 2011. Syntax-based
grammaticality improvement using CCG and guided
search. In Proc. EMNLP, pages 1147?1157.
Yue Zhang, Graeme Blackwood, and Stephen Clark.
2012. Syntax-based word ordering incorporating a
large-scale language model. In Proc. EACL, pages
736?746.
Yue Zhang. 2013. Partial-tree linearization: General-
ized word ordering for text synthesis. In Proc. IJ-
CAI, pages 2232?2238.
182
Proceedings of the 15th Conference on Computational Natural Language Learning: Shared Task, pages 76?80,
Portland, Oregon, 23-24 June 2011. c?2011 Association for Computational Linguistics
ETS: An Error Tolerable System for Coreference Resolution
Hao Xiong , Linfeng Song , Fandong Meng , Yang Liu , Qun Liu and Yajuan Lu?
Key Lab. of Intelligent Information Processing
Institute of Computing Technology
Chinese Academy of Sciences
P.O. Box 2704, Beijing 100190, China
{xionghao,songlinfeng,mengfandong,yliu,liuqun,lvyajuan}@ict.ac.cn
Abstract
This paper presents our error tolerable sys-
tem for coreference resolution in CoNLL-
2011(Pradhan et al, 2011) shared task (closed
track). Different from most previous reported
work, we detect mention candidates based on
packed forest instead of single parse tree, and
we use beam search algorithm based on the
Bell Tree to create entities. Experimental re-
sults show that our methods achieve promising
results on the development set.
1 Introduction
Over last decades, there has been increasing inter-
est on coreference resolution within NLP commu-
nity. The task of coreference resolution is to iden-
tify expressions in a text that refer to the same dis-
course entity. This year, CoNLL1 holds a shared
task aiming to model unrestricted coreference in
OntoNotes.2 The OntoNotes project has created a
large-scale, accurate corpus for general anaphoric
coreference that covers entities and events not lim-
ited to noun phrases or a limited set of entity types.
And Pradhan et al (2007) have ever used this corpus
for similar unrestricted coreference task.
Our approach to this year?s task could be divided
into two steps: mention identification and creation
of entities. The first stage is conducted on the anal-
ysis of parse trees produced by input data. The of-
ficial data have provided gold and automatic parse
trees for each sentences in training and development
1http://conll.bbn.com/
2http://www.bbn.com/ontonotes/
set. However, according to statistics, almost 3%
mentions have no corresponding constituents in au-
tomatic parse trees. Since only automatic parse trees
will be provided in the final test set, the effect of
parsing errors are inevitable. To alleviate this issue,
based on given automatic parse trees, we modify a
state-of-the-art parser (Charniak and Johnson, 2005)
to generate packed forest, and determine mention
candidates among all constituents from both given
parse tree and packed forest. The packed forest is a
compact representation of all parse trees for a given
sentence. Readers can refer to (Mi et al, 2008) for
detailed definitions.
Once the mentions are identified, the left step is
to group mentions referring to same object into sim-
ilar entity. This problem can be viewed as binary
classification problem of determining whether each
mention pairs corefer. We use a Maximum Entropy
classifier to predict the possibility that two mentions
refer to the similar entity. And mainly following the
work of Luo et al (2004), we use a beam search
algorithm based on Bell Tree to obtain the global
optimal classification.
As this is the first time we participate competi-
tion of coreference resolution, we mainly concen-
trate on developing fault tolerant capability of our
system while omitting feature engineering and other
helpful technologies.
2 Mention Detection
The first step of the coreference resolution tries to
recognize occurrences of mentions in documents.
Note that we recognize mention boundaries only on
development and test set while generating training
76
Figure 1: Left side is parse tree extracted from develop-
ment set, and right side is a forest. ?my daughter? is a
mention in this discourse, however it has no correspond-
ing constituent in parse tree, but it has a corresponding
constituent NP0 in forest.
instances using gold boundaries provided by official
data.
The first stage of our system consists of following
three successive steps:
? Extracting constituents annotated with NP,
NNP, PRP, PRP$ and VBD POS tags from sin-
gle parse tree.
? Extracting constituents with the same tags as
the last step from packed forest.
? Extracting Named Entity recognized by given
data.
It is worth mentioning that above three steps will
produce duplicated mentions, we hence collect all
mentions into a list and discard duplicated candi-
dates. The contribution of using packed forest is that
it extends the searching space of mention candidates.
Figure 1 presents an example to explain the advan-
tage of employing packed forest to enhance the men-
tion detection process. The left side of Figure 1 is
the automatic parse tree extracted from development
set, in which mention ?my daughter? has no corre-
sponding constituent in its parse tree. Under nor-
mal strategy, such mention will not be recognized
and be absent in the clustering stage. However, we
find that mention has its constituent NP0 in packed
forest. According to statistics, when using packed
forest, only 0.5% mentions could not be recognized
while the traditional method is 3%, that means the
theoretical upper bound of our system reaches 99%
compared to baseline?s 97%.
Since the requirement of this year?s task is
to model unrestricted coreference, intuitively, we
should not constraint in recognizing only noun
phrases but also adjective phrase, verb and so on.
However, we find that most mentions appeared in
corpus are noun phrases, and our experimental re-
sults indicate that considering constituents annotated
with above proposed POS tags achieve the best per-
formance.
3 Determining Coreference
This stage is to determine which mentions belong to
the same entity. We train a Maximum Entropy clas-
sifier (Le, 2004) to decide whether two mentions are
coreferent. We use the method proposed by Soon, et
al.?s to generate the training instances, where a posi-
tive instance is formed between current mention Mj
and its closest preceding antecedent Mi, and a neg-
ative instance is created by paring Mj with each of
the intervening mentions, Mi+1, Mi+2,...,Mj?1.
We use the following features to train our classi-
fier.
Features in Soon et al?s work (Soon et al, 2001)
Lexical features
IS PREFIX: whether the string of one mention is
prefix of the other;
IS SUFFIX: whether the string of one mention is
suffix of the other;
ACRONYM: whether one mention is the acronym
of the other;
Distance features
SENT DIST: distance between the sentences con-
taining the two mentions;
MEN DIST: number of mentions between two
mentions;
Grammatical features
IJ PRONOUN: whether both mentions are pro-
noun;
I NESTED: whether mention i is nested in an-
other mention;
J NESTED: whether mention j is nested in an-
other mention;
Syntax features
HEAD: whether the heads of two mentions have
the same string;
HEAD POS: whether the heads of two mentions
have the same POS;
HEA POS PAIRS: pairs of POS of the two men-
tions? heads;
77
Semantic features
WNDIST: distance between two mentions in
WordNet;
I ARG0: whether mention i has the semantic role
of Arg0;
J ARG0: whether mention j has the semantic role
of Arg0;
IJ ARGS: whether two mentions have the seman-
tic roles for similar predicate;
In the submitted results, we use the L-BFGS pa-
rameter estimation algorithm with gaussian prior
smoothing (Chen and Rosenfeld, 1999). We set the
gaussian prior to 2 and train the model in 100 itera-
tions.
3.1 Creation of Entities
This stage aims to create the mentions detected in
the first stage into entities, according to the predic-
tion of classifier. One simple method is to use a
greedy algorithm, by comparing each mention to its
previous mentions and refer to the one that has the
highest probability. In principle, this algorithm is
too greedy and sometimes results in unreasonable
partition (Ng, 2010). To address this problem, we
follow the literature (Luo et al, 2004) and propose
to use beam search to find global optimal partition.
Intuitively, creation of entities can be casted as
partition problem. And the number of partitions
equals the Bell Number (Bell, 1934), which has a
?closed? formula B(n) = 1e
??
k=0
kn
k! . Clearly, this
number is very huge when n is large, enumeration of
all partitions is impossible, so we instead designing
a beam search algorithm to find the best partition.
Formally, the task is to optimize the following ob-
jective,
y? = argmax
??P
?
e??
Prob(e) (1)
where P is all partitions, Prob(e) is the cost of
entity e. And we can use the following formula to
calculate the Prob(e),
Prob(e) =
?
i?e,j?e
pos(mi,mj)
+
?
i?e,j /?e
neg(mi,mj)
(2)
where pos(mi,mj) is the score predicted by clas-
sifier that the possibility two mentions mi and mj
group into one entity, and neg(mi,mj) is the score
that two mentions are not coreferent.
Theoretically, we can design a dynamic algorithm
to obtain the best partition schema. Providing there
are four mentions from A to D, and we have ob-
tained the partitions of A, B and C. To incorporate
D, we should consider assigning D to each entity of
every partition, and generate the partitions of four
mentions. For detailed explanation, the partitions
of three mentions are [A][B][C], [AB][C], [A][BC]
and [ABC], when considering the forth mention D,
we generate the following partitions:
? [A][B][C][D], [AD][B][C], [A][BD][C],
[A][B][CD]
? [AB][C][D], [ABD][C],[AB][CD]
? [A][BC][D], [AD][BC], [A][BCD]
? [ABC][D], [ABCD]
The score of partition [AD][B][C] can be
calculated by score([A][B][C]) + pos(A,D) +
neg(B,D) + neg(C,D). Since we can computer
pos and neg score between any two mentions in
advance, this problem can be efficiently solved by
dynamic algorithm. However, in practice, enumer-
ating the whole partitions is intractable, we instead
exploiting a beam with size k to store the top k parti-
tions of current mention size, according to the score
the partition obtain. Due to the scope limitation, we
omit the detailed algorithm, readers can refer to Luo
et al (2004) for detailed description, since our ap-
proach is almost similar to theirs.
4 Experiments
4.1 Data Preparation
The shared task provided data includes information
of lemma, POS, parse tree, word sense, predicate
arguments, named entity and so on. In addition to
those information, we use a modified in house parser
to generate packed forest for each sentence in devel-
opment set, and prune the packed forest with thresh-
old p=3 (Huang, 2008). Since the OntoNotes in-
volves multiple genre data, we merge all files and
78
Mention MUC BCUBED CEAFM CEAFE BLANC
baseline 58.97% 44.17% 63.24% 45.08% 37.13% 62.44%
baseline gold 59.18% 44.48% 63.46% 45.37% 37.47% 62.36%
sys forest 59.07% 44.4% 63.39% 45.29% 37.41% 62.41%
sys btree 59.44% 44.66% 63.77% 45.62% 37.82% 62.47%
sys forest btree 59.71% 44.97% 63.95% 45.91% 37.96% 62.52%
Table 1: Experimental results on development set (F score).
Mention MUC BCUBED CEAFM CEAFE BLANC
sys1 54.5% 39.15% 63.91% 45.32% 37.16% 63.18%
sys2 53.06% 35.55% 59.68% 38.24% 32.03% 50.13%
Table 2: Experimental results on development set with different training division (F score).
take it as our training corpus. We use the sup-
plied score toolkit 3 to compute MUC, BCUBED,
CEAFM, CEAFE and BLANC metrics.
4.2 Experimental Results
We first implement a baseline system (baseline)
that use single parse tree for mention detection
and greedy algorithm for creation of entities. We
also run the baseline system using gold parse tree,
namely baseline gold. To investigate the contribu-
tion of packed forest, we design a reinforced sys-
tem, namely sys forest. And another system, named
as sys btree, is used to see the contribution of beam
search with beam size k=10. Lastly, we combine
two technologies and obtain system sys forest btree.
Table 1 shows the experimental results on devel-
opment data. We find that the system using beam
search achieve promising improvement over base-
line. The reason for that has been discussed in last
section. We also find that compared to baseline,
sys forest and baseline gold both achieve improve-
ment in term of some metrics. And we are glad to
find that using forest, the performance of our sys-
tem is approaching the system based on gold parse
tree. But even using the gold parse tree, the im-
provement is slight. 4 One reason is that we used
some lexical and grammar features which are dom-
3http://conll.bbn.com/download/scorer.v4.tar.gz
4Since under task requirement, singleton mentions are fil-
tered out, it is hard to recognize the contribution of packed for-
est to mention detection, while we may incorrectly resolve some
mentions into singletons that affects the score of mention detec-
tion.
inant during prediction, and another explanation is
that packed forest enlarges the size of mentions but
brings difficulty to resolve them.
To investigate the effect of different genres to de-
velop set, we also perform following compared ex-
periments:
? sys1: all training corpus + WSJ development
corpus
? sys2: WSJ training corpus + WSJ development
corpus
Table 2 indicates that knowledge from other genres
can help coreference resolution. Perhaps the reason
is the same as last experiments, where syntax diver-
sity affects the task not very seriously.
5 Conclusion
In this paper, we describe our system for CoNLL-
2011 shared task. We propose to use packed for-
est and beam search to improve the performance of
coreference resolution. Multiple experiments prove
that such improvements do help the task.
6 Acknowledgement
The authors were supported by National Natural
Science Foundation of China, Contracts 90920004.
We would like to thank the anonymous reviewers
for suggestions, and SHUGUANG COMPUTING
PLATFORM for supporting experimental platform.
79
References
E.T. Bell. 1934. Exponential numbers. The American
Mathematical Monthly, 41(7):411?419.
E. Charniak and M. Johnson. 2005. Coarse-to-fine n-
best parsing and maxent discriminative reranking. In
Proceedings of the 43rd Annual Meeting on Associ-
ation for Computational Linguistics, pages 173?180.
Association for Computational Linguistics.
Stanley F. Chen and Ronald Rosenfeld. 1999. A gaussian
prior for smoothing maximum entropy models. Tech-
nical report, CMU-CS-99-108.
Liang Huang. 2008. Forest reranking: Discriminative
parsing with non-local features. In Proceedings of
ACL-08: HLT, pages 586?594, Columbus, Ohio, June.
Z. Le. 2004. Maximum entropy modeling toolkit for
Python and C++.
X. Luo, A. Ittycheriah, H. Jing, N. Kambhatla, and
S. Roukos. 2004. A mention-synchronous corefer-
ence resolution algorithm based on the bell tree. In
Proceedings of the 42nd Annual Meeting on Associa-
tion for Computational Linguistics, pages 135?es. As-
sociation for Computational Linguistics.
H. Mi, L. Huang, and Q. Liu. 2008. Forestbased transla-
tion. In Proceedings of ACL-08: HLT, pages 192?199.
Citeseer.
Vincent Ng. 2010. Supervised noun phrase coreference
research: The first fifteen years. In Proceedings of the
48th Annual Meeting of the Association for Compu-
tational Linguistics, pages 1396?1411, Uppsala, Swe-
den, July. Association for Computational Linguistics.
Sameer Pradhan, Lance Ramshaw, Ralph Weischedel,
Jessica MacBride, and Linnea Micciulla. 2007. Unre-
stricted Coreference: Identifying Entities and Events
in OntoNotes. In in Proceedings of the IEEE Inter-
national Conference on Semantic Computing (ICSC),
September 17-19.
Sameer Pradhan, Lance Ramshaw, Mitchell Marcus,
Martha Palmer, Ralph Weischedel, and Nianwen Xue.
2011. Conll-2011 shared task: Modeling unrestricted
coreference in ontonotes. In Proceedings of the Fif-
teenth Conference on Computational Natural Lan-
guage Learning (CoNLL 2011), Portland, Oregon,
June.
W.M. Soon, H.T. Ng, and D.C.Y. Lim. 2001. A ma-
chine learning approach to coreference resolution of
noun phrases. Computational Linguistics, 27(4):521?
544.
80
