Proceedings of the Second ACL Workshop on Effective Tools and Methodologies for Teaching NLP and CL, pages 57?61,
Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
Teaching Language Technology at the North-West University 
 
Sul?ne Pilon Gerhard B van Huyssteen Bertus van Rooy 
sktsp@puk.ac.za ntlgbvh@puk.ac.za ntlajvr@puk.ac.za 
Research Focus Area: Languages and Literature in the South African Context North-West University, 
Potchefstroom  
2531 
 South Africa  
   
Abstract 
The BA Language Technology program 
was recently introduced at the North-West 
University and is, to date, the only of its 
kind in South Africa. This paper gives an 
overview of the program, which consists 
of computational linguistic subjects as 
well as subjects from languages, computer 
science, mathematics, and statistics. A 
brief discussion of the content of the pro-
gram and specifically the computational 
linguistics subjects, illustrates that the BA 
Language Technology program is a voca-
tionally directed, future oriented teaching 
program, preparing students for both fu-
ture graduate studies and a career in lan-
guage technology. By means of an 
example, it is then illustrated how stu-
dents and researchers alike benefit from 
working side by side on research and de-
velopment projects by using a problem-
based, project-organized approach to cur-
riculum design and teaching.  
1 Introduction 
A new undergraduate teaching program, BA Lan-
guage Technology, was recently introduced at the 
Potchefstroom Campus of the North-West Univer-
sity (NWU). The introduction of this program was 
motivated by two factors: 
(a) a need within the Faculty of Arts to develop 
teaching programs that are relevant, vocationally 
directed, and future-oriented; and 
(b) a need in the South African higher education 
system for capacity building in the field of in lan-
guage technology (PanSALB & DACST, 2000). 
To date, the BA Language Technology program 
is the only one of its kind in South Africa. It has 
therefore remained imperative that the program 
equips students adequately to fill positions in the 
emerging South African language technology in-
dustry. At the same time, students should be able 
to continue with graduate studies, and therefore the 
program had to be designed in such a way that stu-
dents receive an academic training that incorpo-
rates a solid theoretical component alongside the 
need to get enough practical experience. These two 
imperatives are reflected in the program structure, 
and also in the project-based learning approach 
that we adopted. 
2 Program Structure  
After wide consultation with international and lo-
cal role players and experts, a program was de-
signed that combines language subjects and natural 
sciences (mainly computer science, mathematics 
and statistics) with a core group of computational 
linguistic and language technology subjects. This 
section offers an overview of the BA Language 
Technology program. An example of a typical pro-
gram will be given and the modules which form 
part of the program will be discussed briefly. 
The program has a basic core of compulsory 
modules, but allows some room for students to 
take modules based on personal interest and abil-
ity. A student who excels in computer program-
ming can choose to take additional modules from 
that field after completing the compulsory mod-
ules. Students may also choose to take more lan-
guage or mathematics modules after completing 
their compulsory modules. There are also a number 
of general formative subjects that all students at the 
University must take, which are not being dis-
cussed here. The basic course structure is presented 
in Table 1.   
57
Table 1: BA Language Technology compulsory modules with choices 
 
The various general formative modules offered at 
the university include academic literacy, study 
skills, computer literacy and information skills, 
philosophy and academic and scientific writing 
courses. The elective modules from which the stu-
dents can choose are mathematics, computer sci-
ence and languages. The languages from which the 
students can choose are Afrikaans, English or 
Setswana (regular university courses) or introduc-
tory courses (foreign language level) in two South 
African languages, Setswana and isiZulu and two 
foreign European languages, German and French.  
Students are encouraged to take at least one 
South African language. This is motivated in part 
by trends in the macro-political environment. In 
government policy documents, such as the final 
language policy presented to cabinet, language 
technology is principally regarded as a means to 
promote multilingualism and increase access of 
information in a country with eleven official lan-
guages. In the context of the program itself, it is 
expected that students acquire and/or improve their 
proficiency in the various languages; students are 
also expected to develop basic knowledge of the 
structure of the particular languages. This basic 
knowledge is then developed further in the module 
?Linguistics for language technology students? 
(second year, first semester). The module includes 
components of phonetics, morphology and syntax, 
to enable students to learn how to do detailed lin-
guistic data analysis.  
In the first semester of the second year, students 
are introduced to Language Technology. An over-
view of the field of study is given and it is indi-
cated how the knowledge students gained in the 
modules they have completed, should be put to use 
within the field. The course also focuses on the 
relationship between a more practical language 
technology orientation and a more theoretical natu-
ral language processing (NLP) orientation, to en-
able students to see the broader picture and 
develop a sense for the coherence of the teaching 
program.  
Language technologies are the subject of two 
modules in the second semester of the third year. 
They spend equal amounts of time on speech-
based technologies and text-based technologies. 
The focus of these courses is specific language 
technology applications. At any given time, there 
are a number of ongoing projects at the university. 
Students are involved in these projects, learning to 
develop the specific applications, but also develop-
ing general skills for other types of applications, 
within the framework of project-based learning, as 
will be outlined later in this paper. Students are 
expected to participate in ongoing projects on vari-
ous levels, ranging from annotating corpora to in-
tricate programming ? depending on their aptitude 
and preferences.  
This is followed by a six-month internship in the 
first semester of the fourth year, at an approved 
company or higher education or research institu-
tion. Apart from extending their training in the de-
velopment of language technology applications, 
the internship is intended to let students get a ?real 
YEAR 1 YEAR 2 YEAR 3 YEAR 4 
First semester First semester First semester First semester 
Modules Modules Modules Modules 
Computer Science  
(programming) 
Language Technology: 
Introduction 
Introduction to NLP Language technology: 
Internship 
2 Languages 1 Language 1 CHOICE  
Statistics (introduction) Computer Science  
(programming) 
2 General formative mod-
ules 
 
Mathematics 1 CHOICE   
Applied Mathematics    
2 General formative modules    
Second semester Second semester Second semester Second semester 
Modules Modules Modules Modules 
Computer Science  
(programming) 
Language Technology: 
Linguistics for language 
technology students 
Language Technology: 
Speech applications 
Advanced NLP 
1 Language 1 CHOICE Language Technology: 
Text applications 
Language Technology 
Project 
Statistics (Inferential) 2 General formative mod-
ules 
1 CHOICE  
1 CHOICE    
58
world? experience in the language technology in-
dustry before they have to make career decisions.  
In their final semester, students have to com-
plete a supervised project, which fits in with cur-
rent research at the university. It is important that 
students should be positive about this project and 
therefore students are consulted when project to-
pics are chosen. In this stage of the program, stu-
dents have very little class in order to enable them 
to work on their projects on a full-time base, which 
provides for more practical experience. 
Students are introduced to Natural Language 
Processing in the first semester of the third year. 
This course focuses mainly on statistical tech-
niques for the analysis of the kinds of phonetic, 
morphological and syntactic data that were intro-
duced in the second semester of the second year. 
The logic is that students must be able to analyze 
data manually as linguists first, in order to develop 
an appreciation for the capabilities, power and 
limitations of statistical NLP methods.  
An advanced NLP course is offered in the se-
cond semester after students have completed their 
internship and while they are working on their own 
projects. This course is tailored to the individual 
interests and needs of the students. The specific 
NLP techniques relevant to their projects, as well 
as problems they encountered during their intern-
ships, serve as guiding principles for the selection 
of content. At the same time, we incorporate a se-
lection of hot topics in NLP research and some 
techniques for dealing with semantic data. 
As computational linguistics is a relatively new 
field of study in South Africa, students and lectur-
ers/researchers have to learn together, even by 
making mistakes and taking ?wrong? sidetracks 
during the learning process. In order to facilitate 
these circumstances, a problem-oriented and pro-
ject-organized approach, based on the educational 
system developed at the Aalborg University, Den-
mark, since 1974 (Kjersdam & Enemark, 1994), 
was taken in the design of the curricula of the Lan-
guage Technology and NLP modules. This means 
that the content of some of the Language Technol-
ogy and NLP subjects vary from year to year, de-
pending on the current project(s) being conducted 
at the university. However, by working alongside 
each other on research and development projects, 
both students and lecturers engage in active learn-
ing, proving to yield excellent results in the acquir-
ing of knowledge in the field. The next section 
describes how various research and development 
projects are integrated in the undergraduate and 
graduate teaching programs, in order to facilitate 
hands-on, outcome-based learning.  
3  Teaching Approach: Problem-Based, 
Project-Organized Learning 
Problem-Based Learning (PBL; also called pro-
blem-oriented education) can be defined as learn-
ing ?based on working with unsolved, relevant and 
current problems from society/real life? By ana-
lyzing the problems in depth the students learn and 
use the disciplines and theories which are consid-
ered to be necessary to solve the problems posed, 
i.e. the problem defines the subjects and not the 
reverse? (Kjersdam & Enemark, 1994: 16; cf. 
Schwartz et al, 2001; Macdonald, 2002). This ap-
proach is successfully implemented world-wide in 
the teaching of specifically more applied sciences, 
such as, inter alia, medicine (Albanese & Mitchell, 
1993; Barrows and Tamblyn, 1980; Moore et al, 
1994), and engineering (De Graaf & Kolmos, 
2003; Fink, 2002). 
Within the context of computational linguistics, 
this "applied-teaching approach" maintains a dy-
namic triangular equilibrium between training, re-
search and product development, serving 
researchers, students, and the industry alike. A pro-
ject-organized approach offers lecturers an oppor-
tunity to align course material with their research 
projects, while students are enabled to gain ?com-
prehensive knowledge of the development of theo-
retical and methodological tools? (Kjersdam and 
Enemark, 1994: 17). Therefore, after completion of 
their formal studies, students should be able to 
contribute to research and the development of 
original paradigms to solve new and complex 
problems in the future. 
In the BA Language Technology program, PBL 
is incorporated with project-organized education in 
two ways. On the one hand various project-based 
modules are included in the curriculum. For in-
stance in the third year of study, the modules 
?Language Technology: Speech Applications? and 
?Language Technology: Text Applications? are 
introduced, where students have to develop various 
small modules for both speech and text technologi-
cal applications (e.g. a simple rule-based stemmer). 
In the final year of study, the largest part of the 
year is spent on independent project work, which is 
59
conducted either at the university, or while doing 
an internship elsewhere. These projects are on a 
much larger scale than the third year projects, with 
the possibility to build on the work of the previous 
year (e.g. to develop a more sophisticated stemmer, 
using more advanced NLP techniques).  
On the other hand, some of the other modules 
(e.g. the ?Natural Language Processing? modules) 
are more project-driven, since they are organized 
around existing research projects. Students are 
mostly drawn in on a so-called ?design-oriented? 
level, i.e. where they have to deal with ?know-how 
problems which can be solved by theories and 
knowledge they have acquired in their lectures? 
(Kjersdam & Enemark, 1994: 7). After the project 
and the problems related to the project are ex-
plained to students, they get involved by collecting 
data, identifying possible/different solutions, for-
mulating rules and algorithms, analyzing data, 
evaluating different components, etc. In this way 
they get know-how and experience in theoretical, 
methodological, and implementation issues. 
This can be illustrated by a recent example, 
where work on a spelling checker project was inte-
grated in the curricula of various modules. In this 
project, involving the development of spelling 
checkers for five different South African lan-
guages, a variety of NLP techniques were imple-
mented in the various spelling checkers, depending 
on the orthographical complexity of and resources 
available for a specific language. For instance, lan-
guages such as Tswana and Northern Sotho have a 
relatively simple orthographical structure (in the 
sense that it is more disjunctive), and a straight-
forward lexicon-based approach to spelling check-
ing therefore suffice for these languages. In 
contrast, Afrikaans, Zulu and Xhosa are ortho-
graphically more complex languages, requiring a 
spelling checking approach based on morphologi-
cal analysis or decomposition, which is of course 
more interesting from a computational linguistic 
perspective. For all of these languages, almost no 
resources were available at the start of the project, 
posing a huge but interesting challenge (e.g. could 
available technologies for other languages, such as 
a Porter stemmer, be adapted for these lan-
guages?). 
From the onset of the spelling checker project, 
students were involved in all aspects of the project. 
Using Jurafsky & Martin (2000) as a point of de-
parture, students were introduced to the basic pro-
blems of spelling checking, relating it to the 
current project and specifically to the challenges 
posed by spelling checking for Afrikaans (e.g. pro-
ductive concatenative compound formation, deri-
vational word formation, etc.). Students were 
thoroughly involved in all discussions of the aims 
of the project, potential problems and possible so-
lutions, as well as the general system architecture 
(i.e. students were involved on the design-oriented 
level). Students were therefore introduced to basic 
concepts such as tokenization, stemming, and 
Levenshtein Distance (for purposes of generating 
suggestions), within a real-world context.  
 After the planning and design phase, each stu-
dent got involved in solving different problems of 
the project, e.g. developing a stemmer (using fi-
nite-state techniques) and a compound analyzer 
(using machine-learning techniques), the automatic 
generation of a lexicon, evaluating spelling check-
ers (within the broader context of the evaluation of 
NLP applications), etc. Although each student 
worked separately on different problems, they 
were forced to extend their experience by helping 
each other with their different tasks, thereby ex-
panding their general knowledge and experience. 
In this way, students also came to learn that differ-
ent problems call for different approaches: to use 
finite-state techniques for hyphenation in Afri-
kaans is simply to labor-intensive, while machine 
learning offers highly efficient solutions to the 
problem. An introduction to machine learning was 
therefore also introduced in the curriculum. 
The advantages of this approach proved to be 
many: not only did the project benefit from the 
sub-projects of each of the students, but students 
got the feeling that they were involved in ?impor-
tant? and relevant work. They got the opportunity 
to apply the theoretical knowledge they acquired in 
the classes in a practical, hands-on environment, to 
improve their understanding of the theories and 
concepts of the study field, and to solve real-world 
problems. Additionally, members of staff were 
enabled to harmonize their research and teaching 
responsibilities, optimizing the quality and quantity 
of their outputs. Moreover, existing students were 
motivated to continue with their studies in compu-
tational linguistics on MA level (where they are 
working on more advanced problems), while un-
dergraduate student numbers increased (which can 
be ascribed to a greater awareness of language 
technology in the community, brought about par-
60
tially by media coverage of the project, focusing 
on the promotion of multilingualism and language 
empowerment). 
4 Conclusion 
Since its very inception, the BA Language Tech-
nology program at the North-West University was 
designed as a vocationally directed, future-oriented 
teaching program. A curriculum with a core of 
computational linguistic subjects, strengthened by 
a strong foundation in languages, computer sci-
ence, mathematics, and statistics, equips students 
both with enough practical experience to start 
working in the industry, and with enough theoreti-
cal knowledge to continue with postgraduate stu-
dies.  
By taking a problem-based, project-organized 
approach to curriculum design, students and re-
searchers alike benefit from working side by side 
on research and development projects (as illustra-
ted by the incorporation of a spelling checker pro-
ject in the curricula of various subjects). The same 
approach is followed in other subjects, such as 
"Language Technology: Speech Applications", 
where students are working in collaboration with 
their lecturers on various speech-based projects. As 
new research projects are initiated, the curricula of 
the various subjects are adapted accordingly. For 
example, in 2005 a new research project on syntac-
tic parsing commenced ? consequently, new stu-
dents are confronted with other problems than their 
predecessors, while still learning, for example, 
about the differences between linguistic and statis-
tical approaches to NLP. With the help of students 
in the program and others involved, the program is 
constantly evaluated and adjusted accordingly, 
thereby ensuring that it delivers well-educated and 
informed students, prepared for the challenges of a 
career in language technology. 
References  
Albanese MA & Mitchell S. 1993. Problem-based learn-
ing: A review of literature on its outcomes and im-
plementation issues. Academic Medicine 68, 52-81. 
Barrows HS & Tamblyn RM. 1980. Problem-Based 
Learning: An Approach to Medical Education. New 
York: Springer Publishing Company. 
De Graaff, E & Kolmos, A. 2003. Characteristics of 
Problem-Based Learning. International Journal of 
Engineering Education 19(5). 
Fink, FK. 2002. Problem-Based Learning in engineering 
education: a catalyst for regional industrial develop-
ment. World Transactions on Engineering and Tech-
nology Education 1(1): 29-32. 
Jurafsky, D & Martin, JH. 2000. Speech and language 
processing : an introduction to natural language 
processing. Upper Saddle River: Prentice Hall, 2000. 
Kjersdam F & Enemark S. 1994. The Aalborg Experi-
ment: Project Innovation in University Education. 
Aalborg: Aalborg University Press. 
Macdonald R. 2002. Problem-based learning: some ref-
erences. Available at: [WWW:]www.ics.ltsn.ac.uk/ 
pub/pbl [Accessed 5 May 2003]. 
Moore GT, Block SD, Briggs Style C & Mitchell R. 
1994. The influence of the New Pathway curriculum 
on Harvard medical students. Academic Medicine 69, 
983-989. 
Pan South African Language Board (PanSALB) & De-
partment of Arts, Culture, Science and Technology 
(DACST). 2000. The development of Human Lan-
guage Technologies in South Africa: Strategic Plan-
ning. (Report by the joint steering committee). 
Pretoria: Government Printers. Available at: 
www.dac.gov.za/about_us/cd_nat_language/lan-
guage_planning/hlt_strategic_plan/hlt_strategic_plan
2.htm#policy [Accessed April 1, 2005]. 
Schwartz P, Mennin S & Webb G. 2001. Problem-
based Learning: Case Studies, Experience and Prac-
tice. London: Kogan Page. 
 
61
Proceedings of the NAACL HLT Workshop on Extracting and Using Constructions in Computational Linguistics, pages 39?46,
Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics
Learning Rules and Categorization Networks for Language  
Standardization 


Gerhard B van Huyssteen Marelie H Davel 
Human Language Technology Group Human Language Technology Group 
Council for Scientific and Industrial Research Council for Scientific and Industrial Research 
Pretoria, South Africa Pretoria, South Africa 
gvhuyssteen@csir.co.za  mdavel@csir.co.za 
 
 
 
 
 
 
Abstract 
In this research, we use machine learning 
techniques to provide solutions for descriptive 
linguists in the domain of language standardi-
zation. With regard to the personal name con-
struction in Afrikaans, we perform function 
learning from word pairs using the De-
fault&Refine algorithm. We demonstrate how 
the extracted rules can be used to identify ir-
regularities in previously standardized con-
structions and to predict new forms of unseen 
words. In addition, we define a generic, auto-
mated process that allows us to extract con-
structional schemas and present these visually 
as categorization networks, similar to what is 
often being used in Cognitive Grammar. We 
conclude that computational modeling of con-
structions can contribute to new descriptive 
linguistic insights, and to practical language 
solutions. 
1 Introduction 
In the main, constructionist approaches to grammar 
focus on discovering generalizations in language 
by analyzing clusters of usage-based instances of 
linguistic phenomena. Similarly, computational 
linguistic approaches to grammar learning aim to 
discover these very same patterns, using automated 
techniques such as machine learning (ML).  
In this research, we use techniques from ML to 
analyze and predict irregular phenomena with li-
mited data available, and then represent these phe-
nomena visually in a way that is compatible with 
the Cognitive Grammar descriptive framework (as 
a constructionist approach to grammar; henceforth 
CG). Our grand goal is to develop language tech-
nology tools that could be used in descriptive lin-
guistics. Specifically, we aim to (1) develop a 
predictor that could suggest derivational forms for 
novel base-forms; and (2) automatically extract 
categorization networks (i.e. constructional sche-
mas and the relationships between them) from a 
dataset, which could serve as a heuristic input to 
descriptive linguistics. 
2 Contextualization  
This research originates from a practical problem 
related to language standardization. Similar to 
standardization bodies for languages like Dutch, 
and German, the ?Afrikaanse Taalkommisie? (TK) 
is the official body responsible for the description 
and regulation of Afrikaans spelling. The TK regu-
larly publishes the official orthography of Afri-
kaans in the form of the Afrikaanse Woordelys en 
Spelre?ls (?Afrikaans Wordlist and Spelling 
Rules?; AWS (Taalkommissie, 2009)).  
One of the challenges faced by the TK is to 
standardize the spelling of foreign place names 
(including names of countries, cities, regions, 
provinces, etc.), and their derived forms (i.e. adjec-
tives, such as Amerika?ans ?American?; and per-
sonal names, such as Amerika?ner ?person from 
America?). In the absence of sufficient usage-based 
39
evidence, many variant forms are often being ac-
cepted, either related to spelling or derivation; 
compare for instance the variant spelling forms 
Maskat or Masqat or Muskat ?Muscat?, or the va-
riant derivational forms Turkmenistan?i or Turkme-
nistan?ner ?person from Turkmenistan?. The TK is 
therefore challenged with the task to give guide-
lines regarding spelling and derivation, while faced 
with highly irregular and sparse data containing 
many variants.  
We contribute to address this challenge by dis-
covering the constructions in seemingly unsyste-
matic and irregular data. Based on our tools and 
outputs, the TK could then revise existing irregu-
larities and variants, or use these tools to guide 
future decisions.  
3 Related Work 
3.1 Constructional Schemas 
Morphological constructions can be defined as 
composite symbolic assemblies (i.e. complex 
form-meaning pairings) smaller than phrases, con-
sisting of component structures between which 
valence relations hold (Van Huyssteen, 2010; see 
also Tuggy, 2005). One of the main component 
structures in morphological constructions is the 
morpheme, which is simply defined as a simplex 
symbolic unit in the language system (i.e. it does 
not contain smaller symbolic units as subparts). 
More schematic symbolic assemblies (i.e. less spe-
cified in their characterization) are referred to as 
constructional schemas.  
Constructional schemas can be represented as a 
network with relationships of categorization hold-
ing between different constructional schemas; 
these categorization networks provide the structur-
al description of a construction (Langacker, 2008: 
222). In the representations used in CG, categori-
zation relationships of elaboration (i.e. full instan-
tiations of a schema), extension (i.e. partial 
instantiations), and correspondence are specified. 
Entrenchment and ease of activation is indicated 
by the thickness of boxes: the thicker the line of a 
box, the more prototypical that unit is (Langacker, 
2008: 226; see also Figure 5).  
 The aim of descriptive linguistics is to postulate 
categorization networks that describe a construc-
tion in a language, based on usage data. Our re-
search contributes to this aim by automatically 
creating visual representations of such language 
models. For our current research, we are specifical-
ly interested in the personal name construction in 
Afrikaans. 
3.2 Afrikaans Personal Name Construction 
Formation of personal names by means of a per-
sonal name creating derivational suffix (NRPERS) is 
a productive process in many languages. The spe-
cific category that we are investigating in this re-
search is personal names derived from place 
names, such as Trinidad?ees ?person from Trini-
dad?.  
In one of the standard works on derivation in 
Afrikaans, Kempen (1969) identifies a number of 
NRPERS suffixes that are used in derivations from 
place names. He finds that there is no obvious sys-
tematicity in their distribution (based on a dataset 
of 132 instances), but concludes that, in derivations 
of foreign place names, the -ees and -s morphemes 
are most frequently used, with some distribution 
also over -i, -n (especially -aan) and -r. In addition 
to some of the morphemes mentioned by Kempen 
(1969), Combrink (1990) also mentions a few, 
while excluding others. In as far as we know, no 
other description of this construction in Afrikaans 
has been done, and based on the difference be-
tween Combrink (1990) and Kempen (1969), we 
can also deduct that there is no comprehensive un-
derstanding of this construction.  
Personal names from place names can be formed 
in four basic ways in Afrikaans: (1) suffixation 
(Aruba?an ?Arubian?); (2) zero derivation (Aber-
deen ?person from Aberdeen?); (3) clipping and 
back-formation (Turk<Turkye ?person from Tur-
key?; Armeen<Armeni? ?person from Armenia?); 
and (4) lexicalization (Cornwallis>Korni?r ?person 
from Cornwallis?). In a rather large number of cas-
es (119 in our dataset of 1,034; see 5.1) none of the 
above strategies can be applied, and then paraph-
rasing is being used (e.g. ? persoon van Akkra ?a 
person from Accra?).  
Variants of morphemes (i.e. allomorphs) exist 
for phonological reasons, of which a linking ele-
ment is the most prominent (Combrink, 1990). 
Compare for example -aar in Brussel?aar ?person 
from Brussels? (where the base-form is polysyllab-
ic) vs. -enaar in Delft?enaar ?person from Delft? 
(where the base-form is monosyllabic; Delftenaar 
could therefore also be analyzed as Delft?en?aar). 
40
For our purposes, we consider -enaar as an allo-
morph (i.e. elaboration) of ?aar, and is identified 
as such in our categorization network (see Figure 
5). Similarly, we classify morphemes as allo-
morphs in cases where an allomorph exists due to 
identical vowel deletion (e.g. -an as a variant of -
aan when it combines with a base-form ending on 
an -a, as in Afrika?an ?person from Africa?), as well 
as consonant doubling after a short, stressed sylla-
ble in the auslaut (e.g. -mer as a variant of -er, as 
in Amsterdam?mer ?person from Amsterdam?).  
3.3 Automatic Extraction of Constructional 
Schemas 
Computational modeling of morphology is a vast 
subfield in computational linguistics, gaining 
popularity since the 1980s. Pioneering work in the 
field has been done within the two-level morphol-
ogy framework, and elaborations on this frame-
work can be considered the basis of state-of-the-art 
morphological analyzers today. However, since 
constructing such analyzers manually is hugely 
expensive in terms of time and human effort, the 
approach does not scale well for new languages.  
To overcome this obstacle, many computational 
linguists have developed techniques towards the 
automatic learning of morphology (e.g. Goldsmith, 
2001). A key goal is to be able to produce a mor-
phological analysis of the words of a corpus when 
only provided with the unannotated corpus.   
We are interested in the related goal of function 
learning: given a base-form of a word, learn other 
forms of the word. Most typically, function learn-
ing takes pairs of words (base-forms plus in-
flected/derived forms) as input to discover patterns 
in the data. This is also the paradigm used in the 
current paper. 
Several ML techniques have been used to solve 
specific function learning tasks (such as learning 
the past tense form of the English verb). Ap-
proaches include the use of decision trees, neural 
networks, inductive logic programming, and statis-
tical approaches (Shalonova & Flach, 2007). 
We are not aware of any work related to the au-
tomated learning of categorization networks spe-
cifically. 
4 Approach 
Our research has two complementary goals, dealt 
with separately: (1) to develop a predictor that can 
suggest potential derivational forms for novel base-
forms (and alternative forms for existing base-
forms with irregular forms); and (2) to automati-
cally extract categorization networks that are easily 
interpretable by linguists.  
4.1 Prediction of Derivational Forms 
In order to analyze existing and predict new deri-
vational forms, we use the Default&Refine (D&R) 
algorithm (Davel & Barnard, 2004). This algorithm 
extracts context-sensitive rules from discrete data, 
and is particularly effective when learning from 
small training sets. It has the additional advantage 
that rules generated are interpretable by humans. 
When applied to the grapheme-to-phoneme predic-
tion task, it has been shown to outperform compar-
ative algorithms (Davel & Barnard, 2008). 
The D&R algorithm defines a set of templates 
and then uses a greedy search to find the most gen-
eral rule (matching the templates) that describes 
the training data in question. Examples that are 
successfully explained by this rule are removed 
from the data set and the process repeated. When-
ever a new rule contradicts examples previously 
dealt with successfully, these are again added to 
the training data to be ?re-explained? by a later 
rule. The rule set therefore captures hierarchical 
default behavior: the last rule defines the default 
behavior for a specific pattern, and acts as a back-
off rule to the second-last (more refined) rule, 
which would capture deviations from default beha-
vior. The second-last rule would then act as back-
off to the third-last rule, and so forth. Rules are 
therefore explicitly ordered according to the re-
verse rule extraction order. (The rule extracted first 
is matched last.)  
Once a set of rules have been generated, these 
describe the training data completely. In addition, 
by tracing each of the possible rules that may apply 
to a new pattern (in order), various alternative de-
rivational forms are identified, along with the evi-
dence supporting each option (as in Table 2). 
4.2 Extraction of Categorization Networks 
While the D&R rules extracted in Section Error! 
Reference source not found. provide a perspec-
tive on the phenomena that occur, these rule sets 
could become extremely large and, accordingly, 
more difficult to interpret. We therefore attempt to 
extract categorization networks (a la CG) as visual 
41
representations in a fully automated fashion. These 
networks are more easily interpretable, especially 
to humans.  
An iterative string matching process is used to 
structure ?potential morphemes? within a directed 
tree. Our main assumptions are that: 
? the only input to the process consists of a 
set of unannotated word pairs: base-form + 
derivational form; 
? a morpheme is added as a suffix; 
? allomorphs are either shorter than the main 
morpheme (i.e. characters removed) or 
longer (i.e. characters added); and 
? preference is given to larger strings that 
occur systematically in the training data. 
The following steps are followed: 
1. Generate a list of initial transformation classes  
based on the word pairs provided.  These are 
derived through a comparison based on the 
longest common substring of the derivational 
form and its respective base-form (see Table 
1).  The classes specify the character string to 
be removed from the base-form (if any), and 
the replacement string; note that ellipses indi-
cates the base-form (or part of it), and curly 
brackets indicate deletions (i.e. in China, de-
lete the -a, and then add -ees). If a place name 
and its personal name are identical, the class 
will be ?0?. 
 
Table 1: Examples of transformation classes 
Place 
name  
Personal 
name 
Class (constructional 
schema) 
Aberdeen Aberdeen [[x] [0]] 
Amerika Amerikaner [[?] [ner]] 
China Chinees [[?{a}] [ees]] 
 
2. Create a list of all transformation classes and, 
per transformation class, a set of all deriva-
tional forms (referred to as the transformation 
derivations set). 
3. For each transformation derivations set, find 
the largest end-of-word string common to all 
members of that set (the set best string). The 
set of all ?set best strings? are referred to as the 
best string list and can be interpreted as a set 
of candidate morphemes. 
4. For each transformation derivations set, con-
sider the elements in the best string list, and 
determine if any subsets of the current set exist 
that match a larger string currently in the best 
string list. If so, partition the set into subsets 
accordingly. (Each subset is therefore identi-
fied by both a transformation class and a best 
string. For example, three different sets, each 
with a different best string may be related to a 
single transformation class. This makes it poss-
ible to identify situations where an allomorph 
is created in other ways than simply adding the 
morpheme as a suffix.) 
5. For each subset, update the set best string 
based on the latest partition; update the best 
string list to reflect new best strings created. 
6. Repeat steps (4) and (5) until no further 
changes are made. The set of morphemes are 
considered stable, and it now remains to struc-
ture these elements into a visual categorization 
network. 
7. In order to create the categorization network, 
we start with an empty directed graph. For 
each set best string, create a list of all the trans-
formation classes that are applicable (as calcu-
lated above) and add these transformation 
classes from largest to smallest to a single 
branch of the tree. (One branch is created for 
each string in the best string list, and is a first 
attempt at capturing a morpheme along with its 
different variations.)   
8. Consider the nodes at each level (all nodes that 
have the same node as parent) and wherever 
one node fully contains another, move the con-
tained node to become the parent of the other 
(cutting the link between the original parent 
node and the contained node). This process en-
sures that morpheme candidates that are ac-
tually variations of other morphemes are 
suppressed at each level of the tree.  
9. Now combine any nodes that occur in different 
places in the tree but have identical transfor-
mation classes, by merging the lower node 
with the higher node. Only identical transfor-
mation classes are merged. 
10. For each node in the final tree, consider 
whether the left hand side of the transforma-
tion class can be refined, specifically by add-
ing additional matching characters based on 
the final transformation derivations set. 
The result of this process is a set of final transfor-
mation classes, each describing a constructional 
schema, and the relationships among these con-
structional schemas, displayed as a categorization 
network. 
42
Figure 1: Number of words, rules and initial trans-
formations for the various person-x data sets 
5 Experimental Setup and Results 
5.1 Data 
The dataset that we use is the list of foreign place 
names and their corresponding personal names 
from the AWS (Taalkommissie, 2009). For pur-
poses of brevity, we only report on suffixation and 
back-formation, and exclude cases with variant 
morphemes, zero derivation and clipping, as well 
as all cases of paraphrasing. 732 instances are re-
tained (from the original dataset of 1,034 in-
stances).  
A supplementary dataset consisting of adjectival 
derivations of place names was also taken from the 
AWS and treated in the same manner as the per-
sonal names; this dataset is used in Section 6.3 to 
verify certain of the findings. This set contains 786 
instances. 
5.2 Development of Predictor 
The full dataset is highly irregular, containing 
many transformation classes that occur only once. 
We are interested in these irregularities (in order to 
identify words that may need further review), as 
well as in more systematic phenomena that occur 
in the data. We therefore create different data sets; 
in each set (referred to as person-x) we only retain 
those instances that occur x or more times in the 
transformations. (The person-1 set therefore con-
tains all training data, including all exceptions, 
while the person-6 set only contains transforma-
tions supported by 6 or more instances.) In Figure 
 
 Figure 2: Cross-validated rule accuracy for the per-
son-x and adjective-x data sets. 
 
1 the number of words and number of unique 
transformation classes are displayed for each per-
son-x data set.  
In order to verify the accuracy of our extracted 
rules, we use 10-fold cross-validation to obtain a 
mean accuracy per data set, as depicted in Figure 2 
(labeled ?person?). We also generate a rule set 
from the training and test data combined: this larg-
er set is used to extract categorization networks.  
When the rule set is structured as a graph (called 
a rule network), the data can be interpreted as fol-
lows: the root node indicates the default transfor-
mation, which applies unless any child node is 
matched by the base-form, which again only ap-
plies unless a child of the child node matches the 
base-form (and so forth), which indicates that a 
more refined rule should be applied. A small part 
of a rule network is displayed in Figure 3, with 
each node listing the end-of-word string of the 
base-form that will trigger the rule, the transforma-
tion rule that will be applied, and the number of 
instances of the rule in the training data. The com-
plete rule network is very large: 266 nodes for the 
person-1 data set, as indicated in Figure 1.  
As was expected, a large number of exceptional 
rules are generated, indicating much inconsistency 
in how derivations are formed. For the person-1 
data set, 217 exceptions are identified. For each of 
these exceptions, alternatives are suggested in or-
der of prototypicality by tracing the rule network, 
as illustrated for the base-form Smirna in Table 2. 
Automatically generated tables like these provide a 
practical tool for language standardization. 
43
 
Figure 3: A small subsection of a rule network 
 
 
Table 2: Alternative suggestions for the exception: 
Smirna -> Smirnioot 
Alternative Instances Examples 
Smirna 1 Smirna>Smirnioot 
Smirnees 1 Navarra>Navarrees 
Smirnaan 58 Sparta>Spartaan 
Astana>Astanaan 
Smirnaer 155 Hiroshima>Hiroshimaer 
Breda>Bredaer 
 
5.3 Development of Categorization Networks 
The categorization network in Figure 5 was com-
piled automatically, as described in 4.2. Note that 
this specific categorization network is based on 
construction schemas with three or more support-
ing examples per node; for the sake of brevity, we 
do not include the full categorization network 
(based on all the examples) in this paper. 
The relative prototypicality of constructional 
schemas (indicated by the thickness of lines in 
Figure 5) is determined post hoc by observing dis-
tribution frequencies. We obtain four natural clus-
ters in this way: highly prototypical (hundred or 
more instantiations), prototypical (forty or more 
instantiations), less prototypical (three or more in-
stantiations), and unprototypical (less than three 
instantiations, therefore also including exceptions); 
the latter category is not included in Figure 5.  
Full instantiations of a schema (i.e. relationships 
of elaboration) is indicated with solid arrows; the 
highest node in our network represents the seman-
tic pole, and is here simply indicated as [[PLACE X] 
[NRPERS]]. For each node in the network, we also 
indicate the class frequency, and provide three ex-
amples of the base-form.  
6 Discussion 
6.1 Predictor 
The extracted rules immediately provide us with: 
? An indication of the predictability of the 
data (rule accuracy); 
? A set of all exceptions (single instances 
that require an individual rule to describe 
that instance); and 
? A predictor of new forms (applying the 
rules to unseen words).  
From the accuracies depicted in Figure 2, it is clear 
that the full data set, including all phenomena that 
only occur once, describes a difficult learning task, 
with an overall accuracy of only 63.2% achieved. 
When more systematic phenomena are investigated 
(i.e. transformations with six or more instances), 
our classification accuracy quickly increases above 
80%, indicating that the predictor is in fact usable. 
An error analysis reveals that improvements may 
be possible by taking pronunciation information 
into account (stress patterns, syllable information, 
consonant categories, etc.).  
A standardization body such as the TK could 
use the automatically generated list of exceptions 
(similar to Table 2) to review prior standardization 
decisions.  In addition, the predictor can be used to 
suggest derivational forms for novel base-forms, 
which could then be verified with usage data. 
6.2 Categorization Networks 
From Figure 5, observe that we have identified 
seven basic morphemes (i.e. nodes on the highest 
level), viz. -aan, -aar, -ees, -er, -i, -iet and -?r; 
with the exception of the latter, all these corres-
pond to the morphemes identified by Kempen 
(1969) and Combrink (1990). Linguistically speak-
ing, -?r is actually an extension of the [[?] [er]] 
construction, since the e-trema is used in Afrikaans 
orthography as a variant of the letter ?e? to signify 
a syllable with a null onset, preceded by a syllable 
without a coda. However, our algorithm treated -er 
and -?r as two separate morphemes.  
We can also observe that the [[?] [er]] con-
structional schema can be considered the most pro-
totypical schema (based on frequency). Other 
prototypical constructional schemas include [[?a] 
[an]], [[?] [ner]] and [[?] [?r]] (with the latter 
two actually instantiations of [[?] [er]]). Within a 
44
CG framework, it is assumed that these prototypi-
cal constructional schemas are more likely to be 
activated for the categorization of novel examples. 
This observation contradicts Kempen?s (1969) 
finding that there is no obvious systematicity in the 
distribution of personal name forming suffixes, as 
well as his finding that the -ees and -s morphemes 
are most frequently used. Conversely, we did not 
find in our data significant evidence for the promi-
nence that Kempen (1969) and Combrink (1990) 
give to morphemes/allomorphs such as -der, -lees, 
-naar, -aner, -een, -ein/-yn or -ioot; that does not 
mean that these do not exist ? they are just not as 
prominent as these previous descriptions might 
have made us believe.  
Furthermore, if we look at allomorphs due to 
linking elements, we identified six, viz. -nees,        
-enaar, -iaan, -ner, -ter and -i?r. With the excep-
tion of -nees, all these have also been identified by 
Kempen (1969) and Combrink (1990). If we look 
closely at the instantiations of [[?] [nees]], we see 
that all base-form examples end on the stressed 
syllables [an] or [on], with the exception of Bali 
and Mali. A standardization body could therefore 
investigate whether these two examples could not 
be classified better under the [[?] [?r]] construc-
tional schema, resulting in, for example, Bali??r, as 
we also find in Dutch. If this could be the case, 
then it would make sense why -nees has not been 
identified by other morphologists, since it would 
then be a case of an allomorph due to consonant 
doubling, and not due to a linking element.  
A similar closer look at -ees vs. -nees shows that 
all instantiations of the base-forms of [[?] [nees]] 
end on a stressed syllable, while those for [[?] 
[ees]] are unstressed. In the data, there is only one 
exception to the latter schema, viz.  Gaboen?ees 
?person from Gabon?. Since Gaboen ends on a 
stressed syllable, it would actually fit better under 
the [[?] [nees]] constructional schema. Support 
for this hypothesis comes from Donaldson (1993), 
where he indicates that it should be spelled Ga-
boen?nees. In the absence of usage data, and based 
on this categorization network, the TK could there-
fore reconsider the spelling of Gaboen?ees.   
Several similar observations can be made re-
garding inconsistencies in the data (e.g. inconsis-
tencies regarding base-forms ending on [stan]). In 
this sense, categorization networks like these could 
be a helpful descriptive tool for a standardization 
body in finding systematicity in data and rules. 
6.3 Supplementary Data: Adjectival Deriva-
tions 
In order to validate the generic process, the full 
process (as described in 4.1 and 4.2) is repeated 
using the supplementary data set of adjectival 
forms described in 5.1. Results are positive: a simi-
larly efficient learning curve is obtained (see Fig-
ure 2) and the categorization network, although 
quite different, is similarly interpretable (Figure 4). 
 
Figure 4: Categorization network for the adjective-4 
data set 
7 Conclusion and Future Work 
In this paper, we presented a methodology to au-
tomatically discover constructional schemas from 
highly irregular data, and to represent these in a 
way that is both interpretable by computers (pre-
dictive rule sets) and humans (categorization net-
works). The graphical representation is by and 
large compatible with one of the major Construc-
tion Grammar theories, viz. CG: we show proto-
typical examples (based on frequency), and also 
indicate relationships of elaboration. In future 
work, these representations could be further re-
fined, to also indicate relationships of extensions 
and correspondences. We have illustrated how 
these representations could provide insight in our 
knowledge of the morphology of Afrikaans, as 
well as providing practical language solutions for 
language standardization (such as the predictor and 
the tables with alternative suggestions).  
Other future work will continue in two direc-
tions: (1) refining the current tool for predicting 
derivational forms by taking additional features 
45
into account, incorporating data that was left out in 
our current experiments (such as zero derivations), 
and benchmarking our results with regard to alter-
native approaches; and (2) applying our algorithm 
to describe other morphological constructions.  
Acknowledgments 
Van Huyssteen is jointly affiliated with North-
West University. Support by NWU is hereby ac-
knowledged.  
Part of this research was made possible through 
a research grant by the South African National Re-
search Foundation (FA207041600015).  
We would like to extend our gratitude to Handr? 
Groenewald and Martin Puttkammer for their help. 
References  
Combrink, J.G.H. 1990. Afrikaanse morfologie [Afri-
kaans morphology]. Pretoria: Academica. 
Davel, M. & Barnard, E. 2004. A default-and-
refinement approach to pronunciation prediction. 
Proceedings of the 15th Annual Symposium of the 
Pattern Recognition Association of South Africa. 
Grabouw, November 2004. pp 119-123.  
Davel, M. & Barnard, E. 2008. Pronunciation Prediction 
with Default & Refine. Computer Speech and Lan-
guage. 22: 374-393.  
Donaldson, B.C. 1993. A Grammar of Afrikaans. Berlin: 
Mouton de Gruyter. 
Goldsmith, J. 2001. Unsupervised Learning of the Mor-
phology of a Natural Language. Computational Lin-
guistics 27, pp. 153-198. 
Kempen, W. 1969. Samestelling, afleiding en woord-
soortelike meerfunksionaliteit in Afrikaans [Com-
pounding, derivation and change of part-of-speech 
category in Afrikaans]. Kaapstad: Nasou. 
Langacker, R.W. 2008. Cognitive Grammar: A Basic 
Introduction. Oxford: Oxford University Press. 
Shalonova, K. & Flach, P. 2007. Morphology learning 
using tree of aligned suffix rules. ICML Workshop: 
Challenges and Applications of Grammar Induction. 
Taalkommissie. (comp.). 2009. Afrikaanse Woordelys 
en Spelre?ls [Afrikaans Wordlist and Spelling Rules]. 
Tenth edition. Kaapstad: Pharos Dictionaries. 
Tuggy, D. 2005. Cognitive Approach to Word-
Formation. In: ?tekauer, P. & Lieber, R. (eds.). 
Handbook of Word-Formation. Dordrecht: Springer. 
pp. 233-265. 
Van Huyssteen, GB. 2010. (Re)defining Component 
Structures in Morphological Constructions: A Cogni-
tive Grammar Perspective. In: Michel, S & Onysko, 
A (eds.). Cognitive Approaches to Word-Formation. 
Berlin: Mouton de Gruyter. pp. 97-126. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 5: Categorization network for the person-4 
data set 
46
Proceedings of the First Workshop on Computational Approaches to Compound Analysis, pages 20?30,
Dublin, Ireland, August 24 2014.
Automatic Compound Processing: Compound Splitting and Semantic
Analysis for Afrikaans and Dutch
Ben Verhoeven
CLiPS - Computational Linguistics
University of Antwerp
Antwerp, Belgium
ben.verhoeven@uantwerp.be
Walter Daelemans
CLiPS - Computational Linguistics
University of Antwerp
Antwerp, Belgium
walter.daelemans@uantwerp.be
Menno van Zaanen
TiCC, School of Humanities
Tilburg University
Tilburg, the Netherlands
mvzaanen@uvt.nl
Gerhard van Huyssteen
Centre for Text Technology (CTexT)
North-West University
Potchefstroom, South Africa
gerhard.vanhuyssteen@nwu.ac.za
Abstract
Compounding, the process of combining several simplex words into a complex whole, is a pro-
ductive process in a wide range of languages. In particular, concatenative compounding, in
which the components are ?glued? together, leads to problems, for instance, in computational
tools that rely on a predefined lexicon. Here we present the AuCoPro project, which focuses
on compounding in the closely related languages Afrikaans and Dutch. The project consists of
subprojects focusing on compound splitting (identifying the boundaries of the components) and
compound semantics (identifying semantic relations between the components). We describe the
developed datasets as well as results showing the effectiveness of the developed datasets.
1 Introduction
In many human language technology applications (e.g. machine translators and spelling checkers), many
concatenatively written compounds are processed incorrectly. One of the reasons for this is that these
applications rely on a predefined lexicon and the productive nature of the process of compound formation
automatically results in incomplete lexicons. For example, consider the novel Afrikaans (Afr.) compound
ministerskatkis ?treasury of a minister? that should be segmented as minister+skatkis minister+treasury.
Should it be incorrectly segmented as minister s+kat+kis minister LINK+cat+coffin
1
(where LINK
refers to a linking morpheme), one would get the (possible but improbable) interpretation ?coffin of a
minister?s cat?. From a technological perspective, deficiencies related to automatic compound splitting
(also known as compound segmentation) are particularly problematic, since many other technologies
(such as morphological analyzers, or semantic parsers) might rely on highly accurate compound splitting.
For more advanced natural language processing applications like information extraction, question an-
swering and machine translation systems, proper semantic analysis of compounds might also be required.
With semantic analysis of compounds we refer to the task of determining that the Dutch (Du.) compound
keuken+tafel kitchen+table construes ?table in kitchen?, while Du. baby+tafel baby+table means ?table
for a baby? (and not, fatally so, *?table in a baby?). Internationally, research on automatic compound
analysis has focused almost exclusively on English; very little work in this regard has been done for
other languages (see section 4.1).
Concatenative compounding is a highly productive process in many languages of the world, such as
West-Germanic languages (Afrikaans, Dutch, Frisian, German, and to a far lesser extent English), Nordic
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
1
Note that compound boundaries are marked using a ?+? sign and the start of a linking morpheme is indicated by an ? ?
sign.
20
languages (Danish, Icelandic, Norwegian, and Swedish) and Modern Greek; our focus in this research
is only on Afrikaans and Dutch. Next to derivation, the process of right-headed, recursive compounding
is the most productive word-formation process in these two languages. While almost all parts-of-speech
categories can be found as components of compounds, noun+noun compounds are by far the most fre-
quent type, while noun+verb compounding is generally considered to be non-productive in Germanic
languages (Don, 2009, p. 378). Components of a compound sometimes need to be ?glued? together
using linking morphemes. The occurrence of linking morphemes in Afrikaans and Dutch compounds is
well-known (Neijt et al., 2010), like Afr. besigheid s+besluit business LINK+decision ?business deci-
sion?.
Besides regular compounding, one also finds, amongst others, phrasal compounds (e.g. Afr.
help-my-fris-lyk-hemp help-me-strong-look-shirt ?gym vest?), (neo)classical compounds (e.g. Afr.
neuro+wetenskap neuro+science ?neuroscience?, or Du. bio+logie bio+logy ?biology?), separable ver-
bal compounds (e.g. Du. op+bellen up+call ?to phone?), reduplicative compounds (e.g. Afr. speel -
+speel play LINK+play ?easily?), and compounding compounds (i.e. where the two left constituents
are normally a phrase, but joined in a compound through the right-most constituent, e.g. Du. on-
der+water+camera under+water+camera ?under-water camera?). Except for the latter, none of these
marginal types of compounds were considered as data for any of the systems developed in this research
project.
In section 2 we provide an overview of the automatic compound processing (AuCoPro) project, which
forms the background of this research. Sections 3 and 4 provide details of each of the subprojects relating
to compound splitting and semantic analysis, with details about related research, the development of
datasets, and our experiments. We conclude with a discussion of results and future work in section 5.
2 Overview: The AuCoPro Project
Running from 2012 to 2013, the AuCoPro project was funded by the Dutch Language Union and the
Department of Arts and Culture of the South African Government in a programme to support collab-
orative research in human language technology between Belgium, The Netherlands and South Africa.
Additional funding was provided by the South African National Research Foundation, and the European
Network on Word Structure (NetWordS). The partners involved in the project were the University of
Antwerp (Belgium), Tilburg University (The Netherlands), and North-West University (South Africa).
The primary aim of the project was to develop resources (including annotation protocols, and training
and testing data) for the development of robust compound splitters (subproject 1), and first-generation
compound analyzers (subproject 2) for Afrikaans and Dutch, through a combination of cross-language
transfer (allowing technology recycling), data pooling, and various machine learning approaches. In a
subpart of subproject 2 we also aimed to gain insight in compound semantics by unifying perspectives
from computational semantics (
?
O S?eaghdha, 2008), typological studies (Scalise and Bisetto, 2009), and
construction-based approaches to word-formation (specifically cognitive grammar (Langacker, 2008)
and construction morphology (Booij, 2010)); the results of which can be found in Van Huyssteen (2014)
and Van Huyssteen and Verhoeven (2014).
Deliverables included eight peer-reviewed publications, a technical report on annotation guidelines
for compound processing, and six datasets. All deliverables are available in the open-source domain at
https://sourceforge.net/projects/aucopro, while more information about the project
is available at http://tinyurl.com/aucopro.
3 Compound Splitting
The aim of subproject 1 was to develop datasets that can be used to build robust compound splitters
for Afrikaans and Dutch, or for a cross-lingual analysis of the use of compounds in the closely related
languages Afrikaans and Dutch. Based on existing datasets containing words that are morphologically
analyzed, we extracted (potential) compounds, removed unwanted morphological information, and re-
analysed and corrected them.
21
In the AuCoPro datasets, compounds are analyzed in a shallow manner: no deep hierarchical ordering
of components is performed. Compounds consisting of more than two elements are annotated by indicat-
ing the location of the boundaries, so for instance, Du. bloem+boll en+veld flower+bulb LINK+field
?bulb field? consists of four components, viz. bloem, boll-, -en-, and veld, without any indication of
their syntagmatic relations. The parts bloem, boll- and veld are all simplex words, which we will call
constituents. Constituents are the meaningful parts of a compound. These constituents are prototyp-
ically independent words, but in some cases affixoids (i.e. forms that are somewhere between a word
and an affix in its development) can also occur in compounds (e.g. boer in Du. krant en+boer newspa-
per LINK+farmer ?newspaper seller? does not have the literal meaning of farmer; see Booij (2010)).
In some cases a word may undergo morphophonological changes in the context of a compound. For
instance, in the bloembollenveld example, boll- is an allomorph (or allograph) of bol ?bulb?.
As mentioned above, some compounds require linking morphemes (indicated by LINK in the exam-
ples above) to ?glue? components together. Besides ordinary linking morphemes like -e-, -en-, and -s- (in
both languages), we also defined hyphens as linking morphemes. In the orthographies of Afrikaans and
Dutch in general a hyphen is used in cases of vowel collision, i.e. between compound constituents when
the left-hand constituent ends on a vowel, and the right-hand constituent begins with the same vowel, for
example Afr. see -+eend sea LINK+duck ?seaduck?.
We also mentioned above that marginal compound types such as phrasal compounds, reduplicative
compounds, separable verbal compounds, etc. were not considered as part of the datasets. Similarly, we
excluded synthetic compounds from the datasets when the right-hand element of a synthetic compound
is a non-word (e.g. in Du. blauw+ogig blue+eye-ADJR
2
?blue-eyed?, *ogig is not a valid independent
word in Dutch). However, for this subproject we accepted and annotated compounding compounds,
since they can generally be split quite easily (e.g. Afr. drie+vlak+regering three+level+government
?three-level government?).
To demonstrate the effectiveness of the developed datasets, we started building and evaluating com-
pound splitters for both Dutch and Afrikaans based on the data only. A compound splitter takes a word
as input, and provides as output the input string divided into valid compound components. Note that
these results are only to illustrate that these datasets can be used successfully as training data for such
systems. The actual results can potentially be improved, as the systems are not optimized.
3.1 Related Research
In general, the problem of splitting compounds is found in a wide range of languages. Some of these
languages show non-concatenative compound formation (i.e. compounds are written with whitespaces
between constituents), such as English. Compounds in these languages fall under the umbrella term
multiword expressions (MWEs), which also includes idioms and collocations. Ramisch et al. (2013)
show that this is a quite active research field.
Focusing on concatenative compounding (i.e. where constituents are written conjunctively so that a
compound is always written as a single string without any whitespaces), previous work on Afrikaans has
been performed in the context of the development of spelling checkers (Van Zaanen and Van Huyssteen,
2002; Van Huyssteen and Van Zaanen, 2004). Van Huyssteen and Van Zaanen (2004) describe a com-
pound splitter for Afrikaans. To our knowledge, no stand-alone compound splitter for Dutch is available.
Research done in this field is over ten years old (e.g. Pohlmann and Kraaij (1996)), uses expensive re-
sources (e.g. Ordelman et al. (2003)), does complete morphological analysis (e.g. De Pauw et al. (2004)),
and/or has not been released for re-use in the open-source domain.
3.2 Dataset Development
The datasets developed during this subproject are based on compounds taken from existing (morpho-
logically annotated) datasets. For Dutch, a few morphologically annotated datasets exist, although none
focus on compounds specifically. The development of the Dutch dataset is based on the e-Lex dataset.
3
2
Adjectiviser.
3
This dataset was extended with a compound dataset extracted from CELEX by Lieve Macken (LT3, UGent).
22
The e-Lex dataset contains words annotated with more morphological information than required for
our dataset, but it also contains morphologically annotated non-compound words. After removing non-
compound words (and removing duplicates), 71,274 potential Dutch compounds remained.
For Afrikaans, the situation is more difficult. No dataset containing compound boundary and linking
morpheme boundary information is freely available. The Afrikaans AuCoPro dataset is based on the
PUK-Protea corpus as well as the CTexT Afrikaans spelling checking lexicon (CTexT, 2005; Pilon et al.,
2008). Both corpora do not describe any morphological information. To identify potential compounds,
a longest string matching algorithm (Van Huyssteen and Van Zaanen, 2004) is applied. This algorithm
identifies compounds by searching for known (simplex) words from the left and right ends of the potential
compound, taking the possibility of the occurrence of linking morphemes into account. This algorithm
seems to identify most compounds as well as some non-compounds, which resulted in a list of 77,651
potential Afrikaans compounds.
After this automatic collection and cleanup (for Dutch) and automatic identification and annotation (for
Afrikaans), annotators checked each compound for correct linking morpheme and compound boundaries.
For Afrikaans, seven annotators together checked 25,266 compounds. For Dutch, two annotators checked
26,000 potential compounds. In the end, this resulted in 18,497 and 21,997 true compounds for Afrikaans
and Dutch respectively.
To be able to calculate inter-annotator agreement, subsets of approximately 1,000 words were an-
notated by pairs of annotators. For Dutch in total 6,000 words were used to calculate inter-annotator
agreement and for Afrikaans 12,818 words. This leads to an average Cohen?s Kappa of 98.6 and 97.6 for
Afrikaans and Dutch respectively.
The annotators had access to an annotation manual (Verhoeven et al., 2014), which was developed
specifically for this project. The manual is based on the annotation guidelines that were developed
during the CKarma project (CTexT, 2005; Pilon et al., 2008). These initial guidelines only apply to
Afrikaans, and was hence extended to handle Dutch compounds as well as more complicated cases
not foreseen in the original CKarma guidelines. During the annotation process, regular discussions
between the annotators took place, which resulted in changes in the data and (minor) modifications to
the annotation guidelines.
3.3 Experiments
One of the reasons for creating the compound splitting datasets is to show their usefulness in the de-
velopment of automatic compound splitting systems. These systems search for compound boundaries,
effectively identifying the simplex words in compounds. This information is essential, for instance, when
developing spelling correction systems or machine translation systems for languages that have productive
compound formation processes.
As a classifier, we used the algorithm developed by Liang (1983). This system, which is used as
the hyphenation method in the L
A
T
E
X typesetting system, identifies letter combinations that either allow
or disallow boundary breaks. Even though the task of compound boundary detection is different from
hyphenation (or syllabification), the tasks are similar enough to use the same method. Since the system
is trainable, instead of hyphenation breaks, compound boundaries are provided.
Since no separate annotated gold standard test set is available, we performed leave-one-out evaluation
(using all but one instance for training and the remaining instance for testing; all instances are evaluated
once) using the full dataset. This approach is preferred over, for instance, 10-fold cross validation, which
each time removes 10% of the training data for testing. Additionally, it does not depend on a ?lucky?
selection of test data from the training data, as all compounds are tested.
Evaluating the datasets using this system (which does not have any additional tuning parameters)
results in classification accuracies of 88.28% and 91.48% on the word level for Afrikaans and Dutch
respectively. We assume that further improvements are possible with alternative systems and parameter
optimization.
23
4 Compound Semantics
The automatic processing of the semantics of compounds (or other complex nominals) is a topic in
computational linguistics that, although it has been studied regularly in the past, cannot be considered
a solved problem. Although previous research was often promising, it also had an almost exclusive
focus on English noun-noun (NN) compounds. In recent years, more languages have been studied (e.g.
German (Hinrichs et al., 2013) and Italian (Celli and Nissim, 2009)), and this project added Dutch and
Afrikaans to the list.
It is worth noting that a number of different operationalizations of compound interpretation have been
studied. The most notable are semantic classification of the constituent relation according to a limited
set of semantic categories (e.g.
?
O S?eaghdha (2008)), and the generation of possible paraphrases for
the compound that express its meaning more explicitly (Hendrickx et al., 2013). Our study adopts the
classification model, in which the set of semantic relations to be predicted (the classification scheme) is
crucial.
4.1 Related Research
Several attempts have been made in the past to postulate appropriate classification schemes for noun-
noun compound semantics. These schemes are mainly inventory-based in that they present a limited list
of predefined possible classes of semantic relations a compound can manifest.
In some cases, proposed classes are abstractly represented by a paraphrasing preposition (Lauer, 1995;
Girju et al., 2005; Lapata and Keller, 2004). For example, all compounds that can be paraphrased by
putting the preposition ?of? between the constituents belong to the class OF, e.g. a car door is the
?door of a car?. Another possibility is using predicate-based classes where the relations between the
constituents are not merely described by a preposition, but by definitions or paraphrasing predicates for
each class. The class AGENT would contain compounds that could be paraphrased as ?X is performed
by Y? (Kim and Baldwin, 2005), e.g. enemy activity can be paraphrased as ?activity is performed by
the enemy?. Different schemes vary from 9 to 43 classes with Cohen?s Kappa scores for inter-annotator
agreement ranging from 52% to 62% (Barker and Szpakowicz, 1998; Girju et al., 2005; Moldovan et al.,
2004; Nakov, 2008;
?
O S?eaghdha, 2008).
With regard to the information used by the classifier to assign the classes to the compounds (the fea-
tures of a compound to be analyzed), two main approaches are available, viz. taxonomy-based methods,
or corpus-based methods.
Taxonomy-based methods (also called semantic network similarity (
?
O S?eaghdha, 2009)) base their fea-
tures on a word?s location in a taxonomy or hierarchy of terms. Most of the taxonomy-based techniques
use WordNet (Miller, 1995) for these purposes; especially the hyponym information in the hierarchy
is used. A bag of words is created of all hyponyms and the instance vector contains binary values for
each feature (the feature being whether the considered word from the bag of words is a hyponym of the
constituent or not). Kim and Baldwin (2005) reached an accuracy of 53.3% using only WordNet. Other
research was based on Wikipedia as a semantic network (Strube and Ponzetto, 2006).
Corpus-based methods use co-occurrence information of the constituents of the selected compounds
in a corpus. The underlying idea (the distributional hypothesis) is that the set of contexts in which a
word occurs, is an implicit representation of the semantics of this word (Harris, 1968). The lexical sim-
ilarity measure assumes that compounds have a similar semantic interpretation when their respective
constituents are semantically similar. Two compounds, for example flour can and corn bag will be con-
sidered similar if they have similar modifying constituents (flour and corn) and similar head constituents
(can and bag). The co-occurrences of both constituents will be combined to calculate a measure of sim-
ilarity for the entire compound. This approach implicitly uses the lexical semantic knowledge also used
in taxonomy-based methods but without the need for a taxonomy. Performances of up to 64% F-score
have been reached (
?
O S?eaghdha and Copestake, 2013).
Corpus-based and taxonomy-based methods have also been combined by several researchers. Accu-
racies of 58.35% (
?
O S?eaghdha, 2007), 73.9% (Tratz and Hovy, 2010) and even 82.47% (Nastase et al.,
2006) were reported.
24
4.2 Dataset Development
For this project, we developed datasets of semantically annotated compounds for Afrikaans and Dutch.
This section describes these new resources.
The annotation scheme and guidelines that we used as basis, were developed by
?
O S?eaghdha (2008)
for semantic annotation of English NN compounds. For purposes of our project, some adaptations were
in order, while Dutch and Afrikaans examples were added (Verhoeven et al., 2014).
?
O S?eaghdha (2008)
describes eleven classes of compounds; six of these classes are semantically specific (see Table 1).
Class Definition Example
BE
The compound can be rewritten as ?N2 which is (like) (a) N1? with N1
and N2 being the two constituents nouns.
woman doctor
HAVE
The compound denotes some sort of possession. Part-whole com-
pounds, typical one-to-many possession, compounds expressing condi-
tions or properties and meronymic compounds belong here.
car door
IN The compound denotes a location in time or place. garden party
ACTOR
The compound denotes a characteristic event or situation and one of the
constituents is a salient entity.
enemy activity
INST
The compound denotes a characteristic event and there is no salient en-
tity present.
cheese knife
ABOUT The compound describes a topical relation between its constituents. film character
Table 1: Overview of semantically specific categories in the semantics annotation scheme.
The other five categories are less specific. The MISTAG and NONCOMPOUND categories serve
to classify compounds that do not belong in the dataset. The REL class describes compounds with a
clear meaning that does not belong to any of the other classes, but of which the relation between the
constituents seems productive (e.g. sodium chloride). The LEX category is almost the same as REL,
but the relation does not seem to be productive (e.g. monkey business). The UNKNOWN category is for
correct NN compounds of which the meaning is not clear enough to annotate.
As a subpart of this subproject, we also developed an annotation protocol for nominal compounds that
do not have a noun as first constituent (XN) (Verhoeven and Van Huyssteen, 2013). Such XN compounds
had thus far mostly been neglected, despite the fact that they are fairly productive in some Germanic
languages (although far less frequent than NN compounds). Our annotation guidelines followed the
general approach of
?
O S?eaghdha (2008).
In the course of the project, several datasets were developed. For both Dutch and Afrikaans there were
two annotation rounds for NN compounds and one smaller annotation experiment for XN compounds.
An overview of the semantics data can be found in Table 2, including the average Cohen?s Kappa scores.
The Dutch NN compounds were taken from the same raw compound list of 71,274 compounds de-
scribed in section 3.2 above. Subsequent annotations were performed by students in linguistics at the
University of Antwerp, all native speakers of Dutch. The first dataset was annotated by one student, and
a subset of 500 compounds by one of the authors in order to calculate inter-annotator agreement. The
second round of data was annotated by three students, with the data divided between them in such a way
that we had two annotations for each compound. For the XN compound dataset, only 600 compounds
were annotated.
The NN compounds for the Afrikaans dataset were taken from the CKarma list of split compounds
(see section 3.2 above). The complete Afrikaans dataset was annotated by three undergraduate linguistics
students, all native speakers of Afrikaans. This resulted in three annotations for each compound. With
regard to the XN compound subpart, a large dataset of 4,553 compounds was annotated.
4.3 Experiments
The data from the first annotation rounds were used for semantic classification experiments that were
based on those conducted by
?
O S?eaghdha (2008). We used the annotations made by the main annotator
25
language annotation type # items # annotators avg. Kappa score
Afrikaans NN-Round1 1,449 3 53.4
Afrikaans NN-Round2 2,328 3 37.6
Afrikaans XN 4,553 3 33.5
Dutch NN-Round1 1,766 2 60.0
Dutch NN-Round2 2,000 3 51.0
Dutch XN 600 2 48.6
Table 2: Overview of semantics data.
for each language in order to maintain his or her consistency of annotation. What follows is a description
of our own experimental setup. In our classification experiment, classifiers trained by machine learning
methods use feature vectors arising from a combination of the distributional hypothesis (as proposed
above) with the idea of analogical reasoning. It is assumed that the semantic category of a compound
can be predicted by comparing compounds with similar meanings (
?
O S?eaghdha, 2008).
4.3.1 Vector Creation
For every compound constituent, the co-occurrence context was calculated. For this purpose, for each
instance of the constituents in the corpus, the surrounding n words (that belong to the 10,000 most
frequent words of the corpus) were held in memory. The relative frequencies of these context words (the
number of times the word appeared in the context of the constituent, divided by the frequency of the
constituent in the corpus) for each constituent were stored.
For Dutch, the Twente News Corpus (Ordelman et al., 2007) was used. This is a 340 million word
corpus of newspaper articles. For Afrikaans, we used the Taalkommissie corpus (Taalkommissie, 2011),
a 60 million word corpus that consists of a variety of text genres.
A concatenation of the constituent data was used to create the instance vector. This is a new but very
simple technique of composition whereby each instance vector thus contains the relative frequencies for
the 1,000 most frequent words for each constituent (hence 2,000 per compound). Compounds of which
one or both of the constituents did not appear in the corpus were excluded from the data.
The classification experiment dealt with those compounds that were annotated with a semantically
specific category. This means that only compounds with the category tags BE, HAVE, IN, INST, AC-
TOR and ABOUT were used for the experiments. The final vector set for Afrikaans contained 1,439
compounds, while the final vector set for Dutch had 1,447 compounds.
4.3.2 Results
As machine learning method, we used the SMO algorithm, which is WEKA?s (Witten et al., 2011)
support vector machines (SVM) implementation, in a 10-fold cross-validation setup.
Since this was the first research on both Dutch and Afrikaans (Verhoeven et al., 2012), we assumed
a majority baseline which represents the accuracy that can be obtained by always guessing the most
frequent class as the output class. For Dutch, this baseline is 29.5% (428 instances of class IN on a total
of 1,447 compounds) (Verhoeven, 2012). For Afrikaans, this baseline is 28.2% (407 instances of class
ABOUT on a total of 1,439 instances).
The outcome of these experiments showed that the semantic relation between compound constituents
in Dutch and Afrikaans can be learned using our simple new composition method of concatenating
the constituent vectors into a compound vector. F-scores of 47.8 (Dutch) and 51.1 (Afrikaans) were
achieved using the counts of three context words left and right of the constituent for computing their
semantic representation. The approach turned out to be robust for varying sizes of context (different
numbers of context words), as well as for the way corpus counts were done: on either lemmas or word
forms (Verhoeven, 2012; Verhoeven and Daelemans, 2013). Our results are a good improvement of our
baselines, and provide a baseline for future research.
26
4.3.3 WordNet-based method for Afrikaans
In another subpart of this subproject, we experimented with an alternative approach, namely to use the
Afrikaans WordNet (CTexT, 2011) to infer compound semantics of Afrikaans compounds (Botha et al.,
2013). We followed the same approach as Kim and Baldwin (2005), and achieved precision results
similar to the general approach described above. i.e. 50.49% using the Afrikaans WordNet, vs. 50.80%
reported by Verhoeven et al. (2012). However, recall was much worse: 29.27% in this approach, vs.
51.60% using the other approach. This poor recall can be attributed to the small size of the Afrikaans
WordNet, which only contains 10,045 synsets, compared to 115,424 synsets in the Princeton WordNet
(Miller, 1995). We therefore conclude that a WordNet-approach holds much promise, on the premise
that the WordNet is large enough to ensure good coverage.
5 Discussion
We described machine learning approaches to the segmentation and semantic interpretation of com-
pounds in Dutch and Afrikaans, two related languages where concatenative compounding is a highly
productive morphological process. Success of machine learning approaches to any natural language pro-
cessing task is based on the presence of sufficient high quality training data and relevant information
sources allowing the classification problem to be solved.
For compound splitting, high annotator agreement in the annotation of the training data and high
generalization accuracy could be obtained for both languages using a statistical pattern induction method
working on the orthography of the input compounds, without need for other information sources. Further
improvement can be achieved here with more and richer training data. Other methods for sequence
learning could lead to further improvements as well, although Liang?s method (1983) turns out to be a
strong algorithm for this task.
The task of compound interpretation is much more difficult, both for people (who reached relatively
low annotation agreement for both languages) and for machine learners, suggesting that crucial infor-
mation is missing in the semantic representations we used for our compound constituents. Nevertheless,
also for this task, we were able to set a standard, well above baseline, for future work in compound in-
terpretation for Dutch and Afrikaans. Further improvement can potentially be found in many directions:
more fine-grained and more learnable semantic relation types, more consistently annotated training data
(and much more of it from different domains), and better semantic representations for the constituents,
for example using deep learning (Mikolov et al., 2013).
Acknowledgments
The AuCoPro project was funded through a research grant from the Nederlandse Taalunie (Dutch Lan-
guage Union) and the South African Department of Arts and Culture (DAC), as well as grants from the
South African National Research Foundation (NRF) (grant number 81794), and the European Network
on Word Structure (NetWordS) (European Science Foundation) (Grant number: 5570). Views expressed
in this publication cannot be ascribed to any of these funding organizations.
We would also like to acknowledge the contributions of numerous students and colleagues, including
Zandr?e Botha, Roald Eiselen, Joanie Liversage, Benito Trollip, Nanette van den Bergh (North-West
University); Natasja Loyens, Maxim Baetens, Frederik Vaassen (University of Antwerp); Chris Emmery,
Suzanne Aussems (Tilburg University).
References
Ken Barker and Stan Szpakowicz. 1998. Semi-Automatic Recognition of Non- Modifier Relationships . Proceed-
ings of the 17th International Conference on Computational Linguistics, pages 96?102.
Geert Booij. 2010. Construction Morphology. Oxford University Press, Oxford.
Zandr?e Botha, Roald Eiselen, and Gerhard van Huyssteen. 2013. Automatic compound semantic analysis using
wordnets. In Proceedings of the Twenty-Fourth Annual Symposium of the Pattern Recognition Association of
South Africa, Johannesburg, South Africa.
27
Fabio Celli and Malvina Nissim. 2009. Automatic Identification of Semantic Relation in Italian complex nominals.
In Proceedings of the Eighth International Conference on Computational Semantics (IWCS-8), Tilburg, The
Netherlands.
CTexT. 2005. CKarma (C5 KompositumAnaliseerder vir Robuuste Morfologiese Analise). [C5 Compound
Analyser for Robust Morphological Analysis]. Centre for Text Technology (CTexT), North-West University,
Potchefstroom, South Africa.
CTexT. 2011. Afrikaans WordNet. Centre for Text Technology (CTexT), North-West University, Potchefstroom,
South Africa.
Guy De Pauw, Tom Laureys, Walter Daelemans, and Hugo Van Hamme. 2004. A Comparison of Two Different
Approaches to Morphological Analysis of Dutch. In Proceedings of the Workshop of the ACL Special Interest
Group on Computational Phonology (SIGPHON), Barcelona, Spain.
Jan Don. 2009. IE, Germanic: Dutch. In Rochelle Lieber and Pavol
?
Stekauer, editors, The Oxford Handbook of
Compounding, pages 370?385. Oxford University Press, Oxford, UK.
Roxana Girju, Dan Moldovan, Marta Tatu, and Daniel Antohe. 2005. On the semantics of noun compounds.
Computer Speech and Language, 19:479?496.
Zellig Harris. 1968. Mathematical structures of language. Interscience, New York.
Iris Hendrickx, Zornitsa Kozareva, Preslav Nakov, Diarmuid
?
O S?eaghdha, Stan Szpakowicz, and Tony Veale. 2013.
SemEval-2013 Task 4: Free Paraphrases of Noun Compounds. In Proceedings of the Seventh International
Workshop on Semantic Evaluation (SemEval 2013), pages 138?143, Atlanta, Georgia, USA. Association for
Computational Linguistics.
Erhard Hinrichs, Verena Henrich, and Reinhild Barkey. 2013. Using Part-Whole Relations for Automatic Deduc-
tion of Compound-internal Relations in GermaNet. Language Resources and Evaluation, 24(3):363?372.
Su Nam Kim and Timothy Baldwin. 2005. Automatic Interpretation of Noun Compounds Using WordNet Simi-
larity. Wall Street Journal, pages 945?956.
Ronald Langacker. 2008. Cognitive Grammar: A Basic Introduction. Oxford University Press, New York.
Mirella Lapata and Frank Keller. 2004. The Web as a Baseline: Evaluating the Performance of Unsupervised
Web-based Models for a Range of NLP Tasks. In Proceedings of the Human Language Technology Conference
of the North American Chapter of the Association for Computational Linguistics, pages 121?128. Association
for Computational Linguistics, Boston.
Mark Lauer. 1995. Designing Statistical Language Learners: Experiments on Noun Compounds. Ph.D. thesis,
Macquarie University.
Franklin Mark Liang. 1983. Word Hy-phen-a-tion by Com-put-er. Ph.D. thesis, Stanford University, Stanford,
USA.
Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig. 2013. Linguistic regularities in continuous space word repre-
sentations. In Proceedings of NAACL-HLT, pages 746?751.
George Miller. 1995. WordNet: a lexical database for English. Communications of the ACM, 38(11):39?41.
Dan Moldovan, A Badulescu, Marta Tatu, Daniel Antohe, and Roxana Girju. 2004. Models for the Semantic
Classification of Noun Compounds. In Proceedings of the HLT-NAACL Workshop on Computational Lexical
Semantics, pages 60?67. MA: Association for Computational Linguistics, Boston.
Preslav Nakov. 2008. Noun Compound Interpretation Using Paraphrasing Verbs: Feasibility Study. In Pro-
ceedings of the 13th International Conference on Artificial Intelligence: Methodology, Systems, Applications
(AIMSA08).
Vivi Nastase, Jelber Sayyad-Shirabad, Marina Sokolova, and Stan Szpakowicz. 2006. Learning Noun-Modifier
Semantic Relations with Corpus-based and WordNet-based Features. In Proceedings of the 21st National Con-
ference on Artificial Intelligence, pages 781?787. MA: American Association for Artificial Intelligence, Boston,
aaai-06 edition.
Anneke Neijt, Robert Schreuder, and Carel Jansen. 2010. Van boekenbonnen en fe?everhale: De tussenklank e(n)
in Nederlands en Afrikaanse samestellingen: vorm of betekenis? [The interfix e(n) in Dutch and Afrikaans
compounds: form or meaning?]. Nederlandse Taalkunde, 15(2):125?147.
28
Diarmuid
?
O S?eaghdha and Ann Copestake. 2013. Interpreting compound nouns with kernel methods. Journal of
Natural Language Engineering, Special Issue on the Semantics of Noun Compounds, 19:331?356.
Diarmuid
?
O S?eaghdha. 2008. Learning compound noun semantics. Ph.D. thesis, University of Cambridge,
Cambridge, UK.
Roeland Ordelman, Arjan Van Hessen, and Franciska De Jong. 2003. Compound decomposition in Dutch large
vocabulary speech recognition. In Proceedings of Eurospeech 2003, pages 225?228, Geneva, Switzerland.
Roeland Ordelman, Franciska de Jong, Arjan van Hessen, and Hendri Hondorp. 2007. TwNC: a Multifaceted
Dutch News Corpus. ELRA Newsletter 12, pages 3?4.
Diarmuid
?
O S?eaghdha. 2007. Annotating and Learning Compound Noun Semantics. In Proceedings of the ACL
2007 Student Research Workshop, pages 73?78. Association for Computational Linguistics, Prague.
Diarmuid
?
O S?eaghdha. 2009. Semantic classification with WordNet kernels. In Computational Linguistics,
NAACL-Short ?09, pages 237?240. Association for Computational Linguistics.
Sulene Pilon, Martin Puttkammer, and Gerhard Van Huyssteen. 2008. Die ontwikkeling van ?n woordafbreker en
kompositumanaliseerder vir Afrikaans. Literator, 29(1):21?41.
Renee Pohlmann and Wesley Kraaij. 1996. Improving the precision of a text retrieval system with compound
analysis. In Proceedings of the 7th Computational Linguistics in the Netherlands (CLIN 1996), pages 115?129,
Eindhoven, The Netherlands.
Carlos Ramisch, Aline Villavicencio, and Valia Kordoni. 2013. Introduction to the special issue on multiword
expressions: From theory to practice and use. ACM Transactions on Speech and Language Processing, 10(2):1?
10.
Sergio Scalise and Antonietta Bisetto. 2009. The classification of compounds. In Rochelle Lieber and Pavol
?
Stekauer, editors, The Oxford Handbook of Compounding, pages 34?53. Oxford University Press, Oxford.
Michael Strube and Simone Paolo Ponzetto. 2006. WikiRelate! Computing semantic relatedness using Wikipedia.
In Proceedings of the 21st National Conference on Artificial Intelligence (AAAI-06), Boston, MA.
Taalkommissie. 2011. Taalkommissiekorpus 1.1. Taalkommissie van die Suid-Afrikaanse Akademie vir Weten-
skap en Kuns. Centre for Text Technology (CTexT), North-West University, Potchefstroom, South Africa.
Stephen Tratz and Ed Hovy. 2010. A Taxonomy, Dataset, and Classifier for Automatic Noun Compound Inter-
pretation. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages
678?687. Uppsala: Association for Computational Linguistics.
Gerhard Van Huyssteen and Menno Van Zaanen. 2004. Learning Compound Boundaries for Afrikaans Spelling
Checking. In Proceedings of First Workshop on International Proofing Tools and Language Technologies, pages
101?108, Patras.
Gerhard Van Huyssteen and Ben Verhoeven. 2014. A Taxonomy for Dutch and Afrikaans Compounds. In
Proceedings of the First Workshop on Computational Approaches to Compound Analysis (ComAComA), Dublin,
Ireland.
Gerhard Van Huyssteen. 2014. Morfologie. In Wannie Carstens and Nerina Bosman, editors, Kontempor?ere
Afrikaanse Taalkunde, pages 171?208. Van Schaik Uitgewers, Pretoria, South Africa.
Menno Van Zaanen and Gerhard Van Huyssteen. 2002. Improving a Spelling Checker for Afrikaans. In Compu-
tational Linguistics in the Netherlands 2002-Selected Papers from the Thirteenth CLIN Meeting, page 143156,
Groningen, the Netherlands.
Ben Verhoeven and Walter Daelemans. 2013. Semantic Classification of Dutch Noun-Noun Compounds: A
Distributional Semantics Approach. CLIN Journal, 3:2?18.
Ben Verhoeven and Gerhard Van Huyssteen. 2013. More Than Only Noun-Noun Compounds: Towards an
Annotation Scheme for the Semantic Modelling of Other Noun Compound Types. In Proceedings of the 9th
Joint ISO - ACL SIGSEM Workshop on Interoperable Semantic Annotation, Potsdam, Germany.
Ben Verhoeven, Walter Daelemans, and Gerhard B. Van Huyssteen. 2012. Classification of noun-noun com-
pound semantics in Dutch and Afrikaans. In Proceedings of the Twenty-Third Annual Symposium of the Pattern
Recognition Association of South Africa (PRASA 2012), pages 121?125, Pretoria, South Africa.
29
Ben Verhoeven, Gerhard Van Huyssteen, Menno Van Zaanen, and Walter Daelemans. 2014. Annotation guidelines
for compound analysis. CLiPS Technical Report Series (CTRS), 5.
Ben Verhoeven. 2012. A computational semantic analysis of noun compounds in Dutch. Master?s thesis, Univer-
sity of Antwerp, Antwerp, Belgium.
Ian Witten, Eibe Frank, and Mark Hall. 2011. Data Mining: Practical Machine Learning Tools and Techniques
(Google eBook). Elsevier.
30
Proceedings of the First Workshop on Computational Approaches to Compound Analysis, pages 31?40,
Dublin, Ireland, August 24 2014.
 
A Taxonomy for Afrikaans and Dutch Compounds 
  Gerhard B van Huyssteen Centre for Text Technology North-West University Potchefstroom, South Africa gerhard.vanhuyssteen@nwu.ac.za 
Ben Verhoeven CLiPS - Computational Linguistics University of Antwerp Antwerp, Belgium ben.verhoeven@uantwerpen.be    
Abstract The linguistic categorisation of compounds dates back to some of the earliest work in linguistics. The cross-linguistic compound taxonomy of Bisetto and Scalise (2005), later refined in Scalise and Bisetto (2009), is well-known in linguistics for understanding the grammatical relations in compounds. Although this taxonomy has not been used extensively in the field of computational linguistics, it has the potential to influence choices with regard to compound annotation and understanding in natural language processing. For example, their 2005 taxonomy formed the basis for the large-scale, multilingual database of compounds, called CompoNet. The aim of this paper is to examine their latest taxonomy critically, especially with a view on rigorous implementation in computational environments (e.g. for the morphological annotation of compounds). We propose a number of general improvements of their taxonomy, as well as some language-specific refinements.  
1 Introduction The CompoNet database1 is a large database of compounds from 27 different languages, which was developed at the Department of Foreign Languages of the University of Bologna, in collaboration with native speaker linguists. The database can be used to study compounding of a given language, of a given family (e.g. Germanic, Slavic, etc.), and compounding in general from a typological perspective. Fields in the database include, inter alia, the compound and its part-of-speech (POS) category; the components in the compound and their respective POS categories; the structure of the compound (e.g. [N+N]); whether it is endocentric or exocentric, and an indication of the position of the categorial and semantic head; some inflectional information (plural and gender); glosses; and the classification category of the compound.  With regard to the latter, the well-known classification taxonomy of Bisetto and Scalise (2005) is used (see Figure 1). This classification scheme is based on the view that the grammatical relations between the components of a compound are similar to those in syntactic constructions, viz. subordinate, attributive, and coordinate relations. In addition, each of these types can be endocentric or exocentric, depending of the presence (endocentric) or absence (exocentric) of a head constituent. In a project on automatic compound processing (the AuCoPro project; see http://tinyurl.com/aucopro), we investigated various aspects related to the computational processing of compounds (Verhoeven et al., 2014). In a specific subpart of this project, we aimed to gain more insight in compound semantics in general by drawing from perspectives from computational semantics (i.e. ? S?aghdha, 2008), typological studies (e.g. Lieber, 2009a; Scalise & Bisetto, 2009), and 
                                                            This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/  1 http://componet.sslmit.unibo.it/ 
31
 
construction-based approaches to word-formation (i.e. cognitive grammar (Langacker, 2008) and construction morphology (Booij, 2010)). In addition, we specifically wanted to add Afrikaans compounds to the CompoNet database (as Afrikaans was not included in the original CompoNet project), as well as revise the existing Dutch compounds in CompoNet (based on the insights of the AuCoPro project). As a first phase, we made 56 changes to the Dutch database (mostly correcting minor spelling and classification errors, as well as adding a few additional, prototypical examples), and added 144 Afrikaans compounds to the database (compared to a total of 188 Dutch compounds; the 144 Afrikaans compounds were representative of all part-of-speech categories that can be found in Afrikaans compounds). However, soon after the project commenced, we encountered some limitations with the original CompoNet annotation guidelines, specifically with regard to the classification of compounds. In Section 2 we give an overview of these problems, and discuss some recent literature on the classification of compounds. In Section 3 we describe our solution to these limitations by postulating a classification scheme that would be suitable for rigorous implementation in computational environments (e.g. for the morphological annotation of compounds). We conclude this paper with a discussion of future research. 
2 Previous work In a publication of this nature, it is impossible to discuss all previous research, or even the details of some of the literature influencing our own taxonomy for Afrikaans and Dutch (see Section 3); suffice to point to the overview and summary provided by Scalise and Bisetto (2009), as well as applications of their framework by Lieber (2009a, 2009b). In the remainder of this section we therefore only focus on those aspects that influenced our own taxonomy. During the initial phase of the project, we encountered a number of stumbling-blocks with regard to the annotation guidelines. As indicated above, compound classification in the CompoNet database is based on Bisetto and Scalise (2005) (see Figure 1). However, since then, Scalise and Bisetto (2009) have revised their original taxonomy (see Figure 2), and the dilemma was therefore that we could not take cognisance of these new insights (e.g. the distinction between root and verbal-nexus compounds, or between attributives and appositives), since we had to stay as close as possible to the original annotation guidelines for purposes of cross-lingual compatibility. Table 1 provides a summary of some of the most important notions in Scalise and Bisetto?s (2009) taxonomy, some additional remarks by Lieber (2009a, 2009b), and examples provided by them. Other summaries of their framework include Arcodia et al. (2009); Arnaud and Renner (2014); Vercellotti and Mortensen (2012).  
compounds
subordinate attributive coordinate
endo exo endo exo endo exo   Figure 1. Compound taxonomy of Bisetto and Scalise (2005)   
SUB ATAP COORD
ground verbal-nexus attributive appositive
endo exo endo exo endo exo endo exo endo exo   Figure 2. Compound taxonomy of Scalise and Bisetto (2009) 
32
 
Concept Key definitional aspects Examples Subordinate ? Components share a head-complement relation (subordination) ? Argumental relation between components (Lieber, 2009a: 93) ? At least one of the features of the head constituent is to match the encyclopaedic features that characterise the non-head ? Includes synthetic compounds (Lieber, 2009b: 359), and neoclassical compounds ? Among the most widely attested of compound types (specifically endocentric; Lieber, 2009a: 93) 
See below under ?Ground subordinate? and ?Verbal-nexus subordinate? 
Ground subordinate ? Corresponds to root/primary compounds ? Lexemes can be both simple and complex ? When complex and includes a verb, it is incapable of influencing the interpretation of the compound [no examples provided] ? Semantic relation between constituents is influenced by semantico-encyclopaedic information ? NN compounds with an ?of? relation (Lieber, 2009a: 88), but also if they have a (quasi-)argumental relation (e.g. cookbook author) (Lieber, 2009b: 359) 
windmill (endocentric) mushroom soup (endocentric) love story (endocentric) steam boat (endocentric) coffee cup (endocentric)  
Verbal-nexus subordinate ? Corresponds to secondary/syntactic compounds ? Presence of verb (or any other deverbal constituent) as head ? Verbs select the non-head semantically, be it an argument (bookseller) or a complement/adjunct (street seller) ? Quintessential example is synthetic compound (Lieber, 2009a: 88) 
truck driver (endocentric) cost containment (endocentric) city employee (endocentric) pickpocket (exocentric) killjoy (exocentric) cut-throat (exocentric) Attributive ? Non-head (often an adjective) expresses a quality of the head [often a noun] (i.e. head is modified by a non-head expressing a ?property? of the head) ? The non-head fulfils at least one of the encyclopaedic features of the head; it has an ?adjectival? function ? Clear argumental relationship between constituents lacks (Lieber, 2009b: 359) ? Default semantic type (Lieber, 2009a: 97) ? Most frequently attested in the languages of the world (Lieber, 2009a: 97) 
high-school (endocentric) blue-eyed (endocentric) blue cheese (endocentric) atomic bomb (endocentric) redskin (exocentric) greenhouse (exocentric) freelance (exocentric) 
Appositive ? Non-head expresses a property of the head by means of a noun acting as an attribute ? Noun plays an attributive role and is often interpreted metaphorically ? Non-head can also be a verb [when the head is an adjective] ? NN compounds cannot be paraphrased with ?of? (Lieber, 2009a: 88) 
snail mail (endocentric) swordfish (endocentric) mushroom cloud (endocentric) Du. druipnat (endocentric) 
Coordinate ? Constituents with an ?and? relation ? Two semantic heads, but only one act as categorial head ? Could be additive (Baden-W?rttemberg), or redundant (palm tree) ? Coordinates could be, inter alia, reduplicates (It. lecca-lecca ?lolly-pop?) 
bittersweet (endocentric) poet-doctor (endocentric) woman doctor (endocentric) Austria-Hungary (exocentric) mother-child (exocentric) north-east (exocentric) Table 1. Verbatim summary of Scalise and Bisetto (2009) with additional remarks by Lieber (2009a, 2009b), and our remarks in square brackets  There are two significant differences between these two taxonomies: the label ATAP (ATtributive-APpositive) is introduced in the 2009 version; and a new categorisation level is introduced in the 2009 version to make a distinction between root and verbal-nexus compounds. With the introduction of the ?artificial? ATAP label (placed on the same hierarchical level as subordinate and coordinate compounds) as a superordinate category for attributive and appositive compounds, Scalise and Bisetto (2009) lost some ?correctness?. In the new taxonomy attributives and appositives are therefore on the same categorisation level as verbal-nexus and ground compounds, which, in our opinion, is incorrect. (F?bregas and Scalise (2012) later replace attributive compounds to its original hierarchical level, and then distinguish between two types of attributive compounds, viz. true attributives, and appositives. Also see Arnaud and Renner (2014), and Vercellotti and Mortensen (2012: 572) for a critique of the categorisation levels used by Scalise and Bisetto (2009).) 
33
 
The only annotation protocol available for CompoNet is the article by Bisetto and Scalise (2005), as well as some notes for some of the languages on the CompoNet website (only available to registered users). In our experience, these guidelines were not always explicit or elaborate enough (see also Vercellotti and Mortensen, 2012: 547), and in addition, were sometimes difficult to interpret given other discussions in the literature (notably F?bregas and Scalise, 2012; Lieber, 2009a, 2009b; Scalise and Bisetto, 2009). Two examples suffice. Firstly, in Table 1 we indicated that Scalise and Bisetto (2009: 48-49) distinguish between subordinate and attributive compounds by the manner in which the head selects the non-head: in subordinate compounds ?at least one of the features of the head constituent is to match the encyclopaedic features that characterise the non-head? (with apple cake as an example), while in attributive compounds ?the non-head fulfils at least one of the encyclopaedic features of the head? (with snail mail as an example). In our opinion, this should be the other way round: in SNAIL and MAIL the property SLOW provides the match between the two constituents, whereas APPLE fulfils the INGREDIENT part of the concept CAKE.  A second example that confuses, comes from Lieber (2009a): on p. 98, with regard to dog bed as an example of an attributive compound, she states that ?there is no verbal element here, so a subordinate interpretation is ruled out?. However, on p. 93 she lists table leg as one of the first examples of endocentric subordinate compounds, despite the fact that there is also no verbal element in table leg. Similarly, Vercellotti and Mortensen (2012: 549) interprets Scalise and Bisetto?s (2009) differentiation between verbal-nexus and ground compounds on the basis that the former have verb-argument/adjunct relations, while the latter have no verbs. However, Scalise and Bisetto (2009: 51) says about ground compounds containing complex lexemes: ?when they include a verb, this is incapable of influencing the interpretation of the compound? (our emphasis). Although examples like these might be trivial (and does not take away anything from the overall insight in the categorisation of compounds), they do cause some confusion for the annotator who is provided with these publications as annotation guidelines. Lastly, one of the problems we had with the original taxonomy was that it was not rich enough to allow for all compound types in Afrikaans and Dutch to be categorised, or at least not powerful enough to distinguish between various kinds of compounds. For example, in the original database a separable complex verb (SCV) like the Dutch (Du.) neer+gooien down+throw ?to throw down? was categorised as an attributive compound, while it should in reality rather be categorised as ?Other? (OTH), a category in CompoNet reserved for examples that do not fit any of the other categories. Other examples include the difference between synthetic compounds (like the Afrikaans (Afr.) gras+sny-er grass+cut-extN ?lawn mower?2) and parasynthetic compounds (Afr. glad+maak-ing smooth+make-extN ?smoothing?), compounding compounds (Du. oude+mannen+huis old+men+house ?retirement home for men?), and reduplications (Afr. speel_-+speel play_LINK+play ?easily?). This illustrates that any taxonomy should at least provide for a slot for language-specific or other marginal phenomena ? an aspect we will introduce in Section 3.    
3 New proposal In motivating why they came up with a revised taxonomy, Scalise and Bisetto (2009: 49) state that, given ?the evolution of science, the need has arisen to add further levels of analysis to the classification?. They also invite further amendments to their newly proposed taxonomy, but warn that ?anyone wanting to follow up on this issue will necessarily have to come to grips ? with the diverse compound formations that populate the languages of the world? (Scalise and Bisetto, 2009: 53). In as such, our new proposal wants to suggest some refinements to the general taxonomy of Scalise and Bisetto (2009) on the one hand, and on the other hand wants to make some language-specific changes pertaining to Afrikaans and Dutch (with the possibility that it could also be applicable to other (Germanic) languages). Furthermore, it should be kept in mind that our taxonomy also has a secondary aim, namely to serve as a structure for annotation of compounds in a database like CompoNet. Our proposed taxonomy is presented in Figure 3, while Table 2 (as an Appendix) explicates this taxonomy with construction schemas for prototypical endocentric compounds, as well as an Afrikaans example for each instance. Although only Afrikaans examples are listed, we do claim that the                                                             2 Following the conventions in CompoNet, we use the following abbreviations: extN=nominaliser; extV=verbaliser; extAdj=adjectiviser; extAdv=adverbialiser; Sw=semi-word. 
34
 
taxonomy holds true for Dutch: all categorial patterns listed by De Haas & Trommelen (1993) have been accounted for in some or other way in the taxonomy. In the remainder of this section, we explain and motivate only those aspects of our taxonomy that differ from Scalise and Bisetto (2009).  
Co
m
po
un
di
ng
Su
bo
rd
in
at
e 
co
m
po
un
d
Co
or
di
na
te 
co
m
po
un
d
(N
eo
-)c
las
sic
al
 
co
m
po
un
d
A
ttr
ib
ut
iv
e 
co
m
po
un
d
A
pp
os
iti
ve
 
co
m
po
un
d
En
do
-
ce
nt
ric
V
er
ba
l-n
ex
us
 
co
m
po
un
d
G
ro
un
d 
co
m
po
un
d
Pa
ra
sy
nt
he
tic
 
co
m
po
un
d
Co
m
po
un
di
ng
 
co
m
po
un
d
En
do
-
ce
nt
ric
hi
er
ar
ch
ica
l
Ph
ra
sa
l 
co
m
po
un
d
En
do
-
ce
nt
ric
Se
pa
ra
bl
e 
co
m
pl
ex
 v
er
b
En
do
-
ce
nt
ric
Ph
ra
sa
l 
co
m
po
un
d
Ex
o-
ce
nt
ric
En
do
-
ce
nt
ric
G
ro
un
d 
co
m
po
un
d
Ex
o-
ce
nt
ric
G
ro
un
d 
co
m
po
un
d
la
ng
ua
ge
 sp
ec
ifi
c/
m
ar
gi
na
l
Semosyntactic 
level
Morphosyntactic 
level
Morphosemantic 
level
G
ro
un
d 
co
m
po
un
d
Re
du
pl
ic
ati
on
W
or
d-
fo
rm
ati
on
D
er
iv
at
io
n
Ph
ra
sa
l 
co
m
po
un
d
G
ro
un
d 
co
m
po
un
d
Ph
ra
sa
l 
co
m
po
un
d
G
ro
un
d 
co
m
po
un
d
Word-formation 
process
Ph
ra
sa
l 
co
m
po
un
d
 Figure 3. Taxonomy for Afrikaans and Dutch compounds (adapted from Van Huyssteen, 2014) 
35
 
One of the important aspects of any taxonomy, is that taxa of the same type should be placed on the same taxonomic level/rank (e.g. dog and cat are on the same taxonomic rank), and that criteria for such ranks should be made explicit. In our taxonomy, we show that compounding, derivation, reduplication, etc., are all word-formation processes. We explicitly include reduplication here, in order to clarify that we do not consider examples like Afr. dokter-dokter doctor-doctor ?play doctor?, or Du. snel+snel quick+quick ?very quick? to be compounds, as some authors like Kempen (1969) believe, but rather consider it a separate word-formation process (following F?bregas and Scalise, 2012, and Van Huyssteen, 2004). Note also the dotted line that links derivation with parasynthetic compounds, because parasynthetic compounds are formed through a derivational process: compounding by means of derivation (Booij and Van Santen, 1998: 178; see discussion below).  With regard to compounding specifically, we maintain the three taxonomic ranks of Scalise and Bisetto (2009) (unlike Vercellotti and Mortensen (2012) who added another level). On the semosyntactic level, the grammatical relations between constituents in compounds are used as classification criterion, and four types of relations are distinguished: subordinate, attributive, appositive, and coordinate. These four taxa operate on the same level of categorisation, and not like in the 2009-version of the Scalise and Bisetto taxonomy, where attributive and appositive were positioned on the same level as verbal-nexus and ground compounds. Following Vercellotti and Mortensen?s (2012) insight that subordinate, attributive and appositive compounds are more similar to each other than to coordinate compounds (i.e. the latter is not hierarchical), we lump them together with a dotted line in an area marked ?hierarchical? (indicating their shared characteristic).  Note also that Vercellotti and Mortensen (2012) discard the notion of appositive compounds, since: (1) it ?is unclear how many languages would need this category, given the difficulty distinguishing the category?; and (2) ??appositive? is already in the literature as a type of coordinate compound? (2012: 574). We have to agree to some degree with them on both accounts, but nonetheless maintain appositive as a useful label. Compare an appositive compound like Du. sleutel+woord key+word ?keyword? with a coordinate compound like Du. dichter-zanger poet-singer ?idem?. A sleutelwoord is a word that is like a key, but nonetheless still a word; it is not a key that is also a word. In contrast, a dichter-zanger is a singer that happens to be a poet as well, but could just as well be paraphrased as a poet that happens to be a singer. Hence, we maintain that there is a difference between appositives and coordinates, with the former being right-headed, and the latter (at least semantically) dual-headed. Similarly, an appositive is subtly different from an attributive compound (and it is therefore often difficult to distinguish the two from each other; see also Arcodia et al. (2009), and Arnaud and Renner (2014)). A sleutelwoord is not a kind of word of the same order as a Du. taboe+woord taboo+word ?taboo word?, or a Du. mode+woord fashion+word ?trendy word?: a sleutelwoord is a word that is like a key, while a taboewoord is not like a taboo ? the word is a taboo; a modewoord is not like the fashion, it is fashion. We maintain that appositives most often have an ?is like? metaphorical interpretation, while attributives have a literal ?(that/which) is? relation. On the semosyntactic level, we can now formulate high-level construction schemas (Booij, 2010) for each of the four major endocentric compound types, as the bold parts in (1) to (4). To illustrate, read (1) as follows: on the phonological pole, a word [a]Xi (table) can combine with another word [b]Xk (leg) to form a new word [ab]Xk (table leg), which as a whole (k) should be interpreted on the semantic pole as [LEGj of TABLEi]k; note that i, j and k are indices that mark the identity of constituents on the phonological and semantic poles (i.e. on the left and right of the double-arrow respectively). (1) Subordinate compounds: [[a]Xi [b]Xj]Xk ?   [SEMj of SEMi]k  where the X of [a]=N/V/Adj/Adv/Num/P/Phrase/Sw; the X of [b]=N/Adj/V/V-extN/ V-extAdj/Sw3 (2) Attributive compounds: [[a]Xi [b]Xj]Xk ?   [SEMj is SEMi]k  where the X of [a]=Adj/Adv/AP/Num/Phrase; the X of [b]=N/Adj (3) Appositive compounds: [[a]Xi [b]Xj]Xk ?   [SEMj like SEMi]k  where the X of [a]=N/V/P/Phrase; the X of [b]=N/Adj (4) Coordinate compounds: [[a]Xi [b]Xj]Xk ?   [SEMi and/or SEMj]k  where X=N/V/Adj/Adv/P                                                             3 In Afrikaans, a pronoun can also act as head, as in the construction Afr. ma-hulle mother-they ?mother and them?. 
36
 
On the second taxonomic rank, the morphosyntactic level, compounds are distinguished in terms of the morphosyntactic (categorial) nature of the constituents, i.e. whether it is a lexical word, a phrase, or semi-word; in (1) to (4) these constituents are indicated in italics. All four types of compounds can be formed by means of ground words (i.e. uninflected words), which could be either simplex (e.g. gebruik in Afr. gebruik+sfeer usage+sphere ?usage sphere?), or complex (e.g. Afr. gebruik-er use-extN ?user? in gebruiker+vriendelik user+friendly ?user friendly?). All the major word categories can function as constituents in compounds, including N, V, Adj, Adv, Num, and P.  All except coordinate compounds can take phrasal elements as non-heads; these could range from full sentences (Afr. Sannie-gaan-weeshuis-toe-rokkie Sannie-goes-orphanage-to-dress ?worn-out dress?), phrases (NP, VP, AP, PP), or phrase-like phrases (Lieber, 2009b: 363) as in some parasynthetic compounds. Only subordinate compounds can have deverbal constituents as heads where the verb selects the non-head semantically as argument or as complement/adjunct (resulting in synthetic compounds). Lastly, it seems thus far as if only subordinate compounds can have semi-words as constituents, resulting in (neo-)classical compounds. The third taxonomic rank pertains to headedness, defined on the morphosemantic level. Without being ignorant about the ongoing debate on headedness in morphology circles, we simply maintain Scalise and Bisetto?s (2009) definition and interpretation of the head as the semantic head of the compound (see also Booij, 1992). Whereas they indicate that all three major compound types can be both endocentric or exocentric (universally speaking), we claim that all compound types in Afrikaans and Dutch can be endocentric, but only the following can be exocentric:4 (5) Subordinate, ground: [[a]V [b]N]V (Du. knip+oog snip+eye ?to wink?), or [[a]V [b]N]N (Afr. suip+lap booze+cloth ?drunkard?) (6) Attributive, ground: [[a]Adj [b]N]N (Afr. rooi+kop red+head ?ginger (derogatory)?), or [[a]N [b]N]N (Du. spleet+oog slit-eye ?Asian person (derogatory)?5) Finally, another important addition to our taxonomy is the grouping of language specific/marginal cases (on the right-hand side of Figure 3). This choice should be understood in terms of the computational needs of this project, where one often needs a category for instances that do not fit the other main categories well. Such a category is currently called ?Other? in CompoNet, and is used as a ?dustbin? for anything that cannot be categorised as ?Subordinate?, ?Attributive?, ?Appositive? or ?Coordinate?. However, instead of having a very vague ?Other? category, we try to be precise and explicit about these language specific categories. With regard to Afrikaans and Dutch, we identify three categories, viz. compounding compounds (Afr. samestellende samestellings), parasynthetic compounds (Afr. samestellende afleidings), and separable complex verbs (Afr. samekoppelings).  Compounding compounds are compounds that are formed with a noun as head, and either a NP (Adj+N, or Num+N) or PP (P+N) as non-head. Note that this is a specific kind of construction, and should as such not be confused with recursiveness in compounding. Unlike in subordinate, attributive and appositive phrasal compounds, the NP or PP in compounding compounds can only have two constituents. Also, a binary, left-branching interpretation of the compound as a recursive compound is impossible. Compare for instance a jocular example like Du. gescheurde+broek+hersteller ripped+pants+repairer ?repairer of ripped pants?. If we would assume that hersteller first combined with broek to form broekhersteller, then a gescheurde broekhersteller would have been a ?pants repairer who was ripped?. In other words, in compounding compounds, the compound as a whole is formed by means of the usual process of compounding (Booij and Van Santen, 1998: 179). In contrast, 
                                                            4 Note that an example like Afr. wag-?-bietjie wait-a-bit ?Buffalo Thorn (tree type)? should not be analysed as exocentric, since it is actually a back-formation of wag-?-bietjie-boom wait-a-bit-tree ?Buffalo Thorn?. There is a handful of highly lexicalised phrases (written concatenatively with hyphens, indicating their word status) that are exocentric, e.g. Afr. een-twee-drie one-two-three ?quickly?, or Du. vergeet-me-niet-je forget-me-not-DIM ?idem?. Most of these cases are names of plants, birds, food, etc., and in our opinion, are not productive in Afrikaans and Dutch. However, this will need to be established through future research. Other problematic examples include highly lexicalised (metaphoric) compounds (like Du. pad(den)+stoel frog+chair ?mushroom?), or simplexes that were diachronically speaking endocentric compounds (like Afr. hard+loop fast+walk ?run?, which is still today considered an endocentric attributive compound in Dutch). For our purposes we consider both these cases as simplexes, but it could also be a theme for future research. 5 The compound spleetoog can also refer to a squinted eye, in which case it is endocentric. 
37
 
in parasynthetic compounds, the compound is formed by means of derivation; compare for instance Du. vijf+jaar-s five+year-extAdv ?five-yearly?, or Afr. besluit+ne(e)m-ing decision+take-extN ?decision making?.  Lastly, we also include separable complex verbs in our taxonomy as a language specific category, and specifically as endocentric ground compounds. There is a vast literature on whether examples like Du. op+zoeken up+look ?look up/search for?, and Afr. af+sny off+cut ?cut off? should be seen as compounds or not. Suffice to point the interested reader to Booij?s (2010) recent summary and discussion of the topic, and to state that we consider separable complex verbs as language specific compounds, based on the fact that they follow the same stress pattern as other compounds in Afrikaans and Dutch (i.e. main stress on the left-hand constituent). 
4 Conclusion In this paper, we have evaluated Bisetto and Scalise?s (2005) and Scalise and Bisetto?s (2009) compound taxonomies for purposes of revising the Dutch part of CompoNet, and to extend CompoNet by adding Afrikaans as a new language. Similar to Vercellotti and Mortensen?s (2012) critique of these taxonomies, we also suggested some changes, which might actually be more of interest to linguists. However, in our case we had a very practical aim as well, namely to explicate various aspects of the framework for practical analysis and annotation of Afrikaans and Dutch data in the CompoNet database. As is illustrated by Table 2 (in the appendix), we were able to comprehensively formalise the various patterns of compounding in Afrikaans and Dutch, and in the next phase of the project we will revise the original Afrikaans and Dutch data based on our taxonomy, in order to develop two supplementary databases (not part of the official CompoNet, but still using all their fields and conventions). Such databases could in future be used for comparative research, not only between Afrikaans and Dutch, but also with other languages in the CompoNet database. Specific topics that need to be investigated in future include phrasal compounds (e.g. if we perhaps missed some patterns, what kind of phrases occur in which kinds of compounds?), exocentric compounds (i.e. do they only occur as ground compounds, or was our data skewed?; do we really need to include exocentricity in a compounding taxonomy for Afrikaans and Dutch), and (neo-)classical compounds (i.e. are (neo-)classical compounds always subordinate compounds?). Another topic pertains to the productivity of verbal compounds. Booij (2007: 92) states that Germanic languages do not have processes of verbal compounding, but that in Frisian occasionally new NV compounds do occur; we suspect that the same might be true for Afrikaans. Other topics of comparative research on compounding in Afrikaans and Dutch include whether (and why) Afrikaans has more A+N compounds than Dutch, the controversial topic of left-headed constructions in Dutch (e.g. Du. kabinet-Zuma cabinet-Zuma vs. Afr. Zuma-kabinet Zuma-cabinet ?cabinet of (president) Zuma?), the difference of spreading of interfixes (linking morphemes), and differing stress patterns in compounding compounds in these two languages. Acknowledgements The Automatic Compound Processing (AuCoPro) project (http://tinyurl.com/aucopro) was funded through a research grant from the Nederlandse Taalunie (Dutch Language Union) and the South African Department of Arts and Culture (DAC), as well as grants from the South African National Research Foundation (NRF) (grant number 81794), and the European Network on Word Structure (NetWordS) (European Science Foundation) (Grant number: 5570). Views expressed in this publication cannot be ascribed to any of these funding organisations. We would also like to acknowledge the contributions of Benito Trollip, who populated the first version of the Afrikaans section in the CompoNet database. Thank you also to the anonymous reviewers for their comments and suggestions. References Giorgio F. Arcodia, Nicola Grandi and Fabio Montermini. 2009. Hierarchical NN compounds in a cross-linguistic perspective. Rivista di Linguistica, 21(1):11-33. Pierre J.L. Arnaud and Vincent Renner. 2014. English and French [NN]N lexical units: A categorial, morphological and semantic comparison. Word Structure, 7(1):1-28. 
38
 
Antonietta Bisetto and Sergio Scalise. 2005. The classification of compounds. Lingue e Linguaggio, 4(2):319-332. Geert Booij. 1992. Compounding in Dutch. Rivista di Linguistica, 4:37-59.  Geert Booij. 2007. The grammar of words. Oxford University Press, Oxford. Geert Booij. 2010. Construction Morphology. Oxford University Press, Oxford. Geert Booij and Ariane Van Santen. 1998. Morfologie. Amsterdam University Press, Amsterdam. Antonio F?bregas and Sergio Scalise. 2012. Morphology: From Data to Theories. Oxford University Press. Wim De Haas and Mieke Trommelen. 1993. Morfologisch Handboek van het Nederlands [Morphologic Handbook of Dutch]. SDU Uitgeverij. Walter Haeseryn, Kirsten Romijn, Guido Geerts, Jaap de Rooij & Maarten Cornelis van den Toorn. 1997. Algemene Nederlandse Spraakkunst [ANS]. Martinus Nijhoff, Groningen. Willem Kempen, 1969. Samestelling, Afleiding en Woordsoortelike Meerfunksionaliteit in Afrikaans [Compounding, Derivation and Conversion in Afrikaans]. Nasou, Cape Town, South Africa. Ronald Langacker. 2008. Cognitive Grammar: A Basic Introduction. Oxford University Press, New York. Rochelle Lieber. 2009a. A Lexical Semantic Approach to Compounding. In Rochelle Lieber and Pavol ?tekauer, editors, The Oxford Handbook of Compounding, pages 78-104. Oxford University Press, Oxford. Rochelle Lieber. 2009b. IE, Germanic: English. In Rochelle Lieber and Pavol ?tekauer, editors, The Oxford Handbook of Compounding, pages 34?53. Oxford University Press, Oxford. Diarmuid ? S?aghdha. 2008. Learning compound noun semantics. Ph.D. thesis, University of Cambridge, Cambridge, UK. Sergio Scalise and Antonietta Bisetto. 2009. The classification of compounds. In Rochelle Lieber and Pavol ?tekauer, editors, The Oxford Handbook of Compounding, pages 34?53. Oxford University Press, Oxford. Gerhard Van Huyssteen. 2004. Motivating the composition of Afrikaans reduplications: a cognitive grammar analysis. In G?nter Radden and Klaus-Uwe Panther, editors, Studies in Linguistic Motivation, pages 269-292. Mouton de Gruyter, Berlin. Gerhard Van Huyssteen. 2014. Morfologie [Morphology]. In Wannie Carstens and Nerina Bosman, editors, Kontempor?re Afrikaanse Taalkunde [Contemporary Afrikaans Linguistics], pages 171-208. Van Schaik Uitgewers, Pretoria, South Africa. Mary Lou Vercellotti and David R. Mortensen. 2012. A classification of compounds in American Sign Language: an evaluation of the Bisetto and Scalise framework. Morphology, 22(4):545-579. Ben Verhoeven, Menno van Zaanen, Walter Daelemans and Gerhard Van Huyssteen. 2014. Automatic Compound Processing: Compound Splitting and Semantic Analysis for Afrikaans and Dutch. In Proceedings of the First Workshop on Computational Approaches to Compound Analysis (ComAComA), Dublin, Ireland.     
39
 
Appendix 
Subor
dinate
 
VerbN
ex [[a]N [[b]V extAdj]Adj]Adj hand+vervaardig-de hand+produce-extAdj hand-made [[a]N [[b]V extN]N]N gras+sny-er grass+cut-extN lawn mower [[a]V [[b]V extN]N]N eet+sta(a)k-ing eat+strike-extN hunger strike [[a]Adj [[b]V extN]N]N kaal+nael-er naked+run-extN streaker [[a]Adv [[b]V extAdj]Adj]Adj dig+bebos-te thick+afforest-extAdj thickly wooded 
G 
[[a]N [b]N]N tafel+poot table+leg table leg [[a]N [b]Adj]Adj kleur+blind colour+blind colour blind [[a]P [b]N]N buite+kamer outside+room outside room [[a]Num [b]N]N twee+klank two+sound diphthong [[a]V [b]N]N stryk+plank iron+board ironing board [[a]N [b]V]V raad+pleeg advice+commit consult Ph [[a]VP [b]N]N skop-skiet-en-donder-film kick-shoot-and-hit-movie action movie [[a]NP [b]N]N kaas-en-wyn-onthaal cheese-and-wine-party cheese and wine party 
NeoC
 [[a]Sw [b]Sw]N hidro+logie hydro+logy hydrology [[a]Sw [b]N]N bio+brandstof bio+fuel biofuel [[a]N [b]Sw]N Japan(n)+(o)logie Japan+ology Japanese studies 
Attrib
utive G 
[[a]Adj [b]N]N blou+draad blue+wire galvanised wire [[a]Num [b]N]N tien+kamp ten+camp decathlon [[a]Adv [b]N]N terug+weg back+way the way back [[a]Adv [b]Adj]Adj donker+blond dark+blonde dark blonde [[a]Num [b]Adj]Adj twee+maandeliks two+monthly bimonthly 
Ph [[a]AP [b]N]N los-en-vas-praatjies loose-and-set-talks random chatting [[a]NP [b]N]N kop-aan-kop-botsing head-on-head-collision head-on collision [[a]PP [b]N]N in-die-lug-vraag in-the-air-question rhetorical question 
Appo
sitive G 
[[a]N [b]N]N treffer+liedjie hit+song hit song [[a]N [b]Adj]Adj yster+sterk iron+strong strong as iron [[a]V [b]Adj]Adj spring+lewendig jump+lively alive and well [[a]P [b]Adj]Adj deur+nat through+wet soaked Ph [[a]VP [b]Adj]Adj kielie-my-maag-lekker tickle-my-stomach-nice idem [[a]NP [b]Adj]Adj sonsak-in-Ibiza-mooi sunset-in-Ibiza-pretty idem 
Coord
 G [[a]N [b]N]N skrywer-boer writer-farmer writer-farmer [[a]Adj [b]Adj]Adj stom+verbaas mute+surprised very surprised [[a]V [b]V]V sit+l? sit-lie sit and lie [[a]P [b]P]P voor+op before+above first 
CC Ph [[[a]Adj [b]N]NP [c]N]N sosiale+sekerheid(s)+reg social+security+law social security law [[[a]Num [b]N]NP [c]N]N twee+sitplek+motor two+seat+car two-seater [[[a]P [b]N]PP [c]N]N buite+boord+motor out+board+motor outboard motor 
SCV G [[a]P [b]V]V in+gooi in+throw throw in [[a]Adv [b]V]V neer+gooi down+throw throw down [[a]N [b]V]V vleis+braai meat+roast barbeque 
Para S
ynth Ph [[a]PP extN]N ter+aarde+bestel(l)-ing to+earth+deliver-extN burial [[a]NP extN]N groot+skaal-s large+scale-extAdj large-scale [[a]vP extN]N alleen+lo(o)p-er alone+walk-extN loner G [[a]Adj [b]N extAdj]Adj blou+kleur-ig blue+colour-extAdj blue-coloured [[a]Num [b]N extAdj]Adj een+bla(a)r-ig one+leaf-extAdj monopetalous  Table 2. Prototypical endocentric compounds in Afrikaans and Dutch (with Afrikaans examples)6   
                                                            6 Abbreviations: VerbNex=verbal-nexus; G=ground; Ph=phrasal; NeoC=(neo-)classical; Coord=coordinate; CC=compounding compound; SCV=separable complex verb; ParaSynt=parasynthetic 
40
