Proceedings of the EACL 2009 Workshop on GEMS: GEometical Models of Natural Language Semantics, pages 9?16,
Athens, Greece, 31 March 2009. c?2009 Association for Computational Linguistics
Word Space Models of Lexical Variation
Yves Peirsman
Research Foundation ? Flanders &
QLVL, University of Leuven
Leuven, Belgium
yves.peirsman@arts.kuleuven.be
Dirk Speelman
QLVL, University of Leuven
Leuven, Belgium
dirk.speelman@arts.kuleuven.be
Abstract
In the recognition of words that are typical
of a specific language variety, the classic
keyword approach performs rather poorly.
We show how this keyword analysis can be
complemented with a word space model
constructed on the basis of two corpora:
one representative of the language variety
under investigation, and a reference cor-
pus. This combined approach is able to
recognize the markers of a language va-
riety as words that not only have a sig-
nificantly higher frequency as compared
to the reference corpus, but also a differ-
ent distribution. The application of word
space models moreover makes it possible
to automatically discover the lexical alter-
native to a specific marker in the reference
corpus.
1 Introduction
Different varieties of the same language often
come with their lexical peculiarities. Some words
may be restricted to a specific register, while other
ones may have different meanings in different re-
gions. In corpus linguistics, the most straightfor-
ward way of finding such words that are typical
of one language variety is to compile a corpus of
that variety and compare it to a reference corpus
of another variety. The most obvious comparison
takes on the form of a keyword analysis, which
looks for the words that are significantly more fre-
quent in the one corpus as compared to the other
(Dunning, 1993; Scott, 1997; Rayson et al, 2004).
For the purposes of a language-variational study,
this classic keyword approach often does not suf-
fice, however. As Kilgarriff has argued, keyword
statistics are far too sensitive to high frequencies
or topical differences to be used in the study of vo-
cabulary differences (Kilgarriff, 2001). We there-
fore put forward an approach that combines key-
word statistics with distributional models of lex-
ical semantics, or word space models (Sahlgren,
2006; Bullinaria and Levy, 2007; Pado? and Lap-
ata, 2007; Peirsman, 2008). In this way, we not
only check whether two words have significantly
different frequencies in the two relevant language
varieties, but also to what degree their distribution
varies between the corpora.
In this paper, we will focus on the lexical dif-
ferences between two regional varieties of Dutch.
Dutch is interesting because it is the official lan-
guage of two neighbouring countries, Belgium and
the Netherlands. Between these two countries,
there exists a considerable amount of lexical vari-
ation (Speelman et al, 2006). There are words
much more frequently used in one of the two va-
rieties as well as terms that have a different mean-
ing in the two regions. We will call such words
markers of a specific lect ? a general term for re-
giolects, dialects, or other language varieties that
are specific to a certain region, genre, etc. By con-
structing a word space model on the basis of two
corpora instead of one, we will show how the dis-
tributional approach to lexical semantics can aid
the recognition of such lectal variation.
In the next section, we will point out the weak-
nesses of the classic keyword approach, and show
how word space models can provide a solution. In
section 3, we will discuss how our approach recog-
nizes markers of a given lect. In section 4, we will
demonstrate how it can automatically find the al-
ternatives in the other language variety. Section 5
wraps up with conclusions and an outlook for fu-
ture research.
2 Bilectal Word Spaces
Intuitively, the most obvious way of looking for
words that mark a particular language variety, is
to take a corpus that represents this variety, and
calculate its keywords with respect to a reference
9
?2 log-likelihood
keyword ?2 keyword log-likelihood
frank/noun (?franc?) 262492.0 frank/noun (?franc?) 335587.3
meer/adj (?more?) 149505.0 meer/adj (?more?) 153811.6
foto/noun (?photograph?) 84286.7 Vlaams/adj (?Flemish?) 93723.2
Vlaams/adj (?Flemish?) 83663.0 foto/noun (?photograph?) 87235.1
veel/adj (?much?/?many?) 73655.5 vrijdag/noun (?Friday?) 77865.5
Belgisch/adj (?Belgian?) 62280.2 veel/adj (?much?/?many?) 74167.1
vrijdag/noun (?Friday?) 59135.9 Belgisch/adj (?Belgian?) 64786.0
toekomst/noun (?future?) 42440.5 toekomst/noun (?future?) 55879.1
dossier/noun (?file?) 34623.3 dossier/noun (?file?) 45570.0
Antwerps/adj (?Antwerp?) 33659.1 ziekenhuis/noun (?hospital?) 44093.3
Table 1: Top 10 keywords for the Belgian newspaper corpus, as compared to the Twente Nieuws Corpus.
corpus (Dunning, 1993; Scott, 1997; Rayson et al,
2004). This keyword approach has two important
weaknesses, however. First, it has been shown that
statistically significant differences in the relative
frequencies of a word may arise from high abso-
lute frequencies rather than real lexical variation
(Kilgarriff, 2001). Second, in the explicit com-
parison of two language varieties, the keyword ap-
proach offers no way of telling what word in the
reference corpus, if any, serves as the alternative
to an identified marker. Word space models offer
a solution to both of these problems.
We will present this solution on the basis of two
corpora of Dutch. The first is the Twente Nieuws
Corpus (TwNC), a 300 million word corpus of
Netherlandic Dutch newspaper articles from be-
tween 1999 and 2002. The second is a corpus of
Belgian Dutch we compiled ourselves, with the
goal of making it as comparable to the Twente
Nieuws Corpus as possible. With newspaper arti-
cles from six major Belgian newspapers from the
years 1999 to 2005, it totals over 1 billion word
tokens. Here we will work with a subset of this
corpus of around 200 million word tokens.
2.1 Keywords
As our starting point, we calculated the keywords
of the Belgian corpus with respect to the Nether-
landic corpus, both on the basis of a chi-square test
(with Yates? continuity correction) (Scott, 1997)
and the log-likelihood ratio (Dunning, 1993). We
considered only words with a total frequency of
at least 200 that moreover occurred at least five
times in each of the five newspapers that make up
the Belgian corpus. This last restriction was im-
posed in order to exclude idiosyncratic language
use in any of those newspapers. The top ten re-
sulting keywords, listed in Table 1, show an over-
lap of 90% between the tests. The words fall into
a number of distinct groups. Frank, Vlaams, Bel-
gisch and Antwerps (this last word appears only in
the ?2 top ten) indeed typically occur in Belgian
Dutch, simply because they are so tightly con-
nected with Belgian culture. Dossier may reflect
a Belgian preference for this French loanword.
Why the words meer, veel, vrijdag, toekomst and
ziekenhuis (only in the log-likelihood top ten) are
in the lists, however, is harder to explain. There
does not appear to be a linguistically significant
difference in use between the two language va-
rieties, neither in frequency nor in sense. The
presence of foto, finally, may reflect certain pub-
lishing habits of Belgian newspapers, but again,
there is no obvious difference in use between Bel-
gium and the Netherlands. In sum, these Belgian
keywords illustrate the weakness of this approach
in the modelling of lexical differences between
two language varieties. This problem was already
noted by Kilgarriff (2001), who argues that ?[t]he
LOB-Brown differences cannot in general be in-
terpreted as British-American differences?. One
of the reasons is that ?for very common words,
high ?2 values are associated with the sheer quan-
tity of evidence and are not necessarily associated
with a pre-theoretical notion of distinctiveness?.
One way to solve this issue is presented by Speel-
man et al (2008). In their so-called stable lexical
markers analysis, the word frequencies in one cor-
pus are compared to those in several reference cor-
pora. The keyness of a word then corresponds to
the number of times it appears in the resulting key-
word lists of the first corpus. This repetitive test
10
helps filter out spurious keywords whose statistical
significance does not reflect a linguistically signif-
icant difference in frequency. Here we explore an
alternative solution, which scores candidate mark-
ers on the basis of their contextual distribution in
the two corpora, in a so-called bilectal word space.
2.2 Bilectal Word Spaces
Word space models (Sahlgren, 2006; Bullinaria
and Levy, 2007; Pado? and Lapata, 2007; Peirsman,
2008) capture the semantic similarity between two
words on the basis of their distribution in a cor-
pus. In these models, two words are similar when
they often occur with the same context words, or
when they tend to appear in the same syntactic re-
lationships. For our purposes, we need to build a
word space on the basis of two corpora, more or
less in the vein of Rapp?s (1999) method for the
identification of translation equivalents. The main
difference is that we use two corpora of the same
language, each of which should be representative
of one of the language varieties under investiga-
tion. All other variables should be kept as constant
as possible, so that we can attribute differences in
word use between the two corpora to lexical dif-
ferences between the two lects. Next, we select
the words that occur in both corpora (or a subset
of the nmost frequent words to reduce dimension-
ality) as the dimensions of the word space model.
For each target word, we then build two context
vectors, one for each corpus. These context vec-
tors contain information about the distribution of
the target word. We finally calculate the similarity
between two context vectors as the cosine of the
angle between them.
One crucial parameter in the construction of
word space models is their definition of distribu-
tion. Some models consider the syntactic relation-
ships in which a target word takes part (Pado? and
Lapata, 2007), while other approaches look at the
collocation strength between a target and all of the
words that occur within n words to its left and
right (Bullinaria and Levy, 2007). With these last
word-based approaches, it has been shown that
small context sizes in particular lead to good mod-
els of the semantic similarity between two words
(Bullinaria and Levy, 2007; Peirsman, 2008). So
far, we have therefore performed experiments with
context sizes of one, two and three words to the
left and right of the target. These all gave very sim-
ilar results. Experiments with other context sizes
and with syntactic features will be carried out in
the near future. In this paper, we report on the
results of a word-based model with context size
three.
In order to identify the markers of Belgian
Dutch, we start from the keyword lists above. For
each of the keywords, we get their context vector
from the Belgian corpus, and find the 100 most
similar context vectors from the Netherlandic cor-
pus. The words that correspond to these context
vectors are called the ?nearest neighbours? to the
keyword. In the construction of our word space
model, we selected from both corpora the 4,000
most frequent words, and used the cross-section
of 2,538 words as our set of dimensions or context
features. The model then calculated the point-wise
mutual information between the target and each
of the 2,538 context words that occurred at least
twice in its context. All words in the Netherlandic
Dutch corpus with a frequency of at least 200, plus
the target itself, were considered possible nearest
neighbours to the target.
Generally, where there are no major differences
in the use of a keyword between the two lects,
it will have itself as its nearest neighbour. If
this is not the case, this may identify the key-
word as a marker of Belgian Dutch. For exam-
ple, six words from the lists above have them-
selves as their nearest neighbour: meer, foto, veel,
vrijdag, toekomst and ziekenhuis. These are in-
deed the keywords that made little sense from a
language-variational perspective. Dossier is its
own second nearest neighbour, which indicates
that there is slightly less of a match between its
Belgian and Netherlandic use. Finally, the words
linked to Belgian culture ? frank, Vlaams, Bel-
gisch and Antwerps ? are much lower in their
own lists of nearest neighbours, or totally absent,
which correctly identifies them as markers of Bel-
gian Dutch. In short, the keyword analysis ensures
that the word occurs much more frequently in Bel-
gian Dutch than in Netherlandic Dutch; the word
space approach checks if it also has a different dis-
tribution in the two corpora.
For markers of Belgian Dutch, we can interpret
the nearest neighbour suggested by the system as
the other variety?s alternative to that marker. For
instance, dossier has rapport as its nearest neigh-
bour, a synonym which indeed has a high keyword
value for our Netherlandic Dutch corpus. Simi-
larly, the culture-related words have their Dutch
11
equivalents as their distributionally most simi-
lar words: frank has gulden (?guilder?), Vlaams
and Belgisch both have Nederlands (?Dutch?), and
Antwerps has Amsterdams (?Amsterdam (adj.)?).
This makes intuitive sense if we take meaning to
be a relative concept, where for instance a con-
cept like ?currency of this country? is instantiated
by the franc in Belgium and the guilder in Holland
? at least in the pre-Euro period. These findings
suggest that our combined method can be applied
more generally in order to automatically discover
lexical differences between the two language vari-
eties.
3 Recognizing lectal differences
First we want to investigate whether a bilectal
word space model can indeed contribute to the cor-
rect identification of markers of Belgian Dutch on
a larger scale. We therefore had both types of
approaches ? the simple keyword approach and
the combined method ? suggest a top 2,000 of
possible markers on the basis of our two corpora.
The combined approach uses the same word space
method we described above, with 2,538 dimen-
sions and a context size of three. Basing itself
on the lists of nearest neighbours, it then reorders
the list of keywords, so as to arrive at a ranking
that reflects lectal variation better than the original
one. To this goal, each keyword receives a new
score, which is the multiplication of two individ-
ual numbers. The first number is its rank in the
original keyword list. At this point we considered
only the 5,000 highest scoring keywords. The sec-
ond is based on a list that ranks the words accord-
ing to their difference in distribution between the
two corpora. Words that do not occur in their own
list of 100 nearest neighbours appear at the top of
the list (rank 1), followed by words that are their
own 100th nearest neighbour (rank 2), and so on
to the words that have themselves as nearest neigh-
bour (rank 101). In the future we plan to consider
different numbers of neighbours in order to pun-
ish words with very different distributions more
or less heavily. At this stage, however, restrict-
ing the method to 100 nearest neighbours gives
fine results. These two ranks are then multiplied
to give a combined score, on the basis of which a
final list of candidates for lectal variation is com-
puted. The lower this combined score (reflecting
either high keyword values, very different distri-
butions in the two corpora, or both), the higher
candidate marker evaluation
frank/noun (?franc?) culture
Vlaams/adj (?Flemish?) culture
match/noun (?match?) literature
info/noun (?info?)
rijkswacht/noun (?state police?) RBBN
weekend/noun (?weekend?)
schepen/noun (?alderman?) RBBN
fr./noun (?franc?) culture
provinciaal/adj (?provincial?) RBBN
job/noun (?job?) RBBN
Table 2: Top ten candidate markers suggested by
the combined method on the basis of the log-
likelihood ratio.
the likelihood that the word is a marker of Belgian
Dutch. This approach thus ensures that words that
have very different distributions in the two corpora
are promoted with respect to the original keyword
list, while words with very similar distributions are
downgraded.
As our Gold Standard we used the Reference
List of Belgian Dutch (Referentiebestand Belgisch
Nederlands, RBBN), a list of almost 4,000 words
and expressions that are typical of Belgian Dutch
(Martin, 2005). These are classified into a number
of groups ? culturally-related terms (e.g., names
of political parties), Belgian markers that are not
lexicalized in Netherlandic Dutch, markers that
are lexicalized in Netherlandic Dutch, etc. We
used a subset of 717 one-word nouns, verbs and
adjectives that appear at least 200 times in our
Belgian corpus to evaluate our approach. Even
if we informally explore the first ten candidate
markers, the advantages of combining the log-
likelihood ratio with the word space model already
become clear (see table 2). Four of these candi-
dates are in the RBBN gold standard. Similarly,
frank, Vlaams and fr. are culturally related to Bel-
gium, while match has been identified as a typ-
ically Belgian word in previous corpus-linguistic
research (Geeraerts et al, 1999). Info and week-
end are not present in the external sources we con-
sulted, but nevertheless show an interesting distri-
bution with respect to their respective synonyms.
In the Belgian corpus, info occurs more often than
the longer and more formal information (32,009
vs 30,171), whereas in the Dutch corpus the latter
is used about 25 times as frequently as the former
(1,681 vs 41,429). Similarly, the Belgian corpus
12
500 1000 1500 2000
0.0
0
0.0
5
0.1
0
0.1
5
0.2
0
0.2
5
0.3
0
number of candidates
F?
sco
re
chi?squared
log?likelihood
chi?squared + word space
log?likelihood + word space
0.0 0.1 0.2 0.3 0.4 0.5
0.0
0
0.0
5
0.1
0
0.1
5
0.2
0
0.2
5
0.3
0
recall
pre
cis
ion
chi?squared
log?likelihood
chi?squared + word space
log?likelihood + word space
Figure 1: Precision and recall figures of the keyword methods and the combined approaches.
contains far more instances of weekend than of
its synonym weekeinde (35,406 vs 6,390), while
the Dutch corpus shows the reverse pattern (6,974
vs 28,234). These words are thus far better can-
didate markers than the original keywords meer,
foto, veel, vrijdag, toekomst or ziekenhuis, which
have disappeared from the top ten.
Let us now evaluate the methods more broadly,
on the basis of the top 2,000 keywords they sug-
gest. The left plot in Figure 1 shows their F-scores
in function of the number of suggested markers;
the right graph plots precision in function of re-
call. The two keyword approaches score rather
similarly, with the log-likelihood ratio achieving
slightly better results than the chi-square test. This
superiority of the log-likelihood approach was al-
ready noted by Rayson et al (2004). Both com-
bined methods give a very clear advantage over the
simple keyword statistics, again with the best re-
sults for the log-likelihood ratio. For example, ten
of the first 100 candidates suggested by both key-
word approaches are present in our Gold Standard,
giving a precision of 10% and a recall of 1.4% (F-
score 2.4%). Adding our word space model makes
this figure rise to 29 correct markers, resulting in
a precision of 29% and a recall of 4% (F-score
7.1%). This large advantage in performance is
maintained further down the list. At 1000 can-
didates, the keyword approaches have a recall of
around 20% (chi-square 19%, log-likelihood 21%)
and a precision of around 14% (chi-square 14%,
log-likelihood 15%). At the same point, the com-
bined approaches have reached a recall of over
30% (chi-square 31%, log-likelihood 32%) with
a precision of around 22% (chi-square 22%, log-
likelihood 23%). Expressed differently, the best
keyword approach needs around 500 candidates
to recover 10% of the gold standard, 1000 to re-
cover 20% and 2000 to recover 40%. This linear
increase is outperformed by the best combined ap-
proach, which needs only 300, 600 and 1500 can-
didate markers to reach the same recall figures.
This corresponds to relative gains of 40%, 40%
and 25%. As these results indicate, the perfor-
mance gain starts to diminish after 1000 candi-
dates. Future experiments will help determine if
this issue can be resolved with different parameter
settings.
Despite these large gains in performance, the
combined method still has problems with a num-
ber of Belgian markers. A manual analysis of
these cases shows that they often have several
senses, only one of which is typical of Belgian
Dutch. The Reference List for instance contains
fout (?mistake?) and mossel (?mussel?) as Belgian
markers, with their specialized meanings ?foul (in
sports)? and ?weakling?. Not only do these words
have very low keyword values for the Belgian cor-
pus; they also have very similar distributions in
the two corpora, and are their own first and sec-
ond neighbour, respectively. Sometimes a fail-
ure to recognize a particular marker is more due
13
top 100 top 500
class n % n %
in Gold Standard 29 29% 127 25.4%
in Van Dale 11 22% 47 9.4%
related 2 2% 23 4.6%
cultural terms 25 25% 60 12%
total 67 67% 257 51.4%
Table 3: Manual analysis of the top 500 words
suggested by the combined approach.
to the results of one individual method. This
is for instance the case with the correct Belgian
marker home (?(old people?s) home?). Although
the word space model does not find this word in its
own list of nearest Netherlandic neighbours, it re-
mains low on the marker list due to its fairly small
log-likelihood ratio. Conversely, punt, graad and
klaar are rather high on the keyword list of the
Belgian corpus, but are downgraded, as they have
themselves as their nearest neighbour. This is
again because their status as a marker only applies
to one infrequent meaning (?school mark?, ?two-
year cycle of primary education? and ?clear?) in-
stead of the dominant meanings (?final stop, point
(e.g., in sports)?, ?degree? and ?ready?), which are
shared between the two regional varieties. How-
ever, this last disadvantage applies to all markers
that are much more frequently used in Belgium but
still sometimes occur in the Netherlandic corpus
with a similar distribution.
Finally, because our Gold Standard is not an
exhaustive list of Belgian Dutch markers, the re-
sults in Figure 1 are an underestimate of real per-
formance. We therefore manually went through
the top 500 markers suggested by the best com-
bined approach and classified them into three new
groups. The results of this analysis are pre-
sented in Table 3. First, we consulted the Van
Dale Groot Woordenboek der Nederlandse taal
(Den Boon and Geeraerts, 2005), the major dictio-
nary of Dutch, which contains about 3,000 words
marked with the label ?Belgian Dutch?. 11% of
the first 100 and 9.4% of the first 500 candidates
that were initially judged incorrect carry this label
or have a definition that explicitly refers to Bel-
gium. Second, we counted the words that are mor-
phologically related to words in the Gold Standard
or to Belgian words found in Van Dale. These are
for instance compound nouns one of whose parts
is present in the Gold Standard, which means that
0 20 40 60 80 100
0.0
0.2
0.4
0.6
0.8
1.0
number of nearest neighbours
rec
all
nouns
adjectives
verbs
Figure 2: Percentage of markers of Belgian Dutch
whose Netherlandic alternative is present among
their n nearest neighbours.
they are correct markers of Belgian Dutch as well.
They represent 2% of the top 100 and 4.6% of the
top 500. Third, we counted the words that are in-
herently linked to Belgian culture, mostly in the
form of place names. This group corresponds to
25% of the first 100 and 12% of the first 500 can-
didate markers. This suggests that the true preci-
sion of our method at 100 and 500 candidates is
thus at least 67% and 51.4%, respectively.
4 Finding alternatives
The Reference List of Belgian Dutch not only
lists Belgian Dutch words and expressions, but
also gives their Netherlandic Dutch alternative, if
one exists. Our word space model offers us a
promising way of determining this alternative au-
tomatically, by looking at the nearest Netherlandic
neighbours to a Belgian marker. As our Gold Stan-
dard, we selected from the Reference List those
words with a frequency of at least 200 in the Bel-
gian corpus whose Dutch alternative also had a
frequency of at least 200 in the Dutch corpus. This
resulted in a test set of 315 words: 240 nouns,
45 verbs and 30 adjectives. For each of these
words, we used our word space model to find the
100 nearest Netherlandic neighbours, again with
context size three but now with as dimensions all
words shared between the two corpora, in order to
improve performance. We then determined if the
14
Dutch alternative was indeed in the list of nearest
neighbours to the target. We started by looking
at the single nearest neighbour only, and then step
by step extended the list to include the 100 nearest
neighbours. If a word had itself among its nearest
neighbours, this neighbour was discarded and re-
placed by the next one down the list. The results
are shown in Figure 2. 11 out of 30 adjectives
(36.7%), 10 out of 45 verbs (22.2%) and 56 out
of 240 nouns (23.3%) had their Dutch alternative
as their nearest neighbour. At ten nearest neigh-
bours, these figures had risen to 60.0%, 48.9%
and 44.6%. These encouraging results underpin
the usefulness of word space models in language-
variational research.
A manual analysis of Belgian markers for which
the approach does not find the Netherlandic alter-
native again reveals that a large majority of these
errors occur when polysemous words have only
one, infrequent meaning that is typical of Bel-
gian Dutch. For example, the dominant sense
of the word tenor is obviously the ?male singer?
meaning. In Belgium, however, this term can
also refer to a leading figure, for instance in a
political party or a sports discipline. Since this
metaphorical sense is far less frequent than the lit-
eral one, the context vector fails to pick it up, and
almost all nearest Netherlandic neighbours are re-
lated to opera or music. One way to solve this
problem would be to abandon word space models
that build only one context vector per word. In-
stead, we could cluster all individual contexts of a
word, with the aim of identifying context clusters
that correspond to the several senses of that word
(Schu?tze, 1998). This is outside the scope of the
current paper, however.
5 Conclusions and future research
We have presented an application of word space
models to language-variational research. To our
knowledge, the construction of word space mod-
els on the basis of two corpora of the same lan-
guage instead of one is new to both variational
linguistics and Natural Language Processing. It
complements the classic keyword approach in that
it helps recognize those keywords that, in addition
to their different relative frequencies in two lan-
guage varieties, also have a substantially different
distribution. An application of this method to Bel-
gian Dutch showed that the keywords that pass this
test indeed much more often represent markers of
the language variety under investigation. More-
over, often the word space model also succeeded
in identifying the Netherlandic Dutch alternative
to the Belgian marker.
As the development of this approach is still in its
early stages, we have committed ourselves more
to its general presentation than to the precise pa-
rameter settings. In the near future, we therefore
aim to investigate more fully the possible varia-
tion that the method allows. First, we will focus
on the implementation of the word space model,
by studying word-based models with other context
sizes as well as syntax-based approaches. Sec-
ond, we want to examine other ways in which
the word-based model and the classic keyword ap-
proach can be combined, apart from the multipli-
cation of ranks that we have proposed here. While
this large freedom in parameter settings could be
seen as a weakness of the proposed method, the
fact that we obtained similar results for all settings
we have tried out so far, adds to our confidence
that word space models present a sensible com-
plementation of the classic keyword approaches,
irrespective of the precise parameter settings.
In addition to those modelling issues, there are
a number of other extensions we would like to ex-
plore. First, the Gold Standard we have used so
far is rather limited in scope. We therefore plan
to incorporate more sources on language variation
to test the robustness of our approach. Finally, as
we have observed a number of times, the method
in its present form is not sensitive to possibly in-
frequent meanings of a polysemous word. This
may be solved by the application of a clustering
approach that is able to cluster a word?s contexts
into several sense clusters (Schu?tze, 1998). Still,
the promising results in this paper encourage us to
believe that the current approach has a future as a
new method in language-variational research and
as a tool for lexicography.
References
John A. Bullinaria and Joseph P. Levy. 2007. Ex-
tracting semantic representations from word co-
occurrence statistics: A computational study. Be-
haviour Research Methods, 39:510?526.
Ton Den Boon and Dirk Geeraerts. 2005. Van Dale
Groot Woordenboek van de Nederlandse taal (14e
ed.). Van Dale Lexicografie, Utrecht/Antwerp.
Ted Dunning. 1993. Accurate methods for the statis-
15
tics of surprise and coincidence. Computational
Linguistics, 19:61?74.
Dirk Geeraerts, Stefan Grondelaers, and Dirk Speel-
man. 1999. Convergentie en Divergentie in de Ned-
erlandse Woordenschat. Meertens Instituut, Ams-
terdam.
Adam Kilgarriff. 2001. Comparing corpora. Interna-
tional Journal of Corpus Linguistics, 6(1):1?37.
Willy Martin. 2005. Het Belgisch-Nederlands
anders bekeken: het Referentiebestand Belgisch-
Nederlands (RBBN). Technical report, Vrije Uni-
versiteit Amsterdam, Amsterdam, Holland.
Sebastian Pado? and Mirella Lapata. 2007.
Dependency-based construction of semantic space
models. Computational Linguistics, 33(2):161?199.
Yves Peirsman. 2008. Word space models of seman-
tic similarity and relatedness. In Proceedings of the
13th ESSLLI Student Session, pages 143?152.
Reinhard Rapp. 1999. Automatic identification of
word translations from unrelated English and Ger-
man corpora. In Proceedings of the 37th Annual
Meeting of the Association for Computational Lin-
guistics (ACL), pages 519?526, College Park, Mary-
land.
Paul Rayson, Damon Berridge, and Brian Francis.
2004. Extending the cochran rule for the com-
parison of word frequencies between corpora. In
Proceedings of the 7ie`mes Journe?es Internationales
d?Analyse Statistique des Donne?es Textuelles (JADT
2004), pages 926?936, Louvain-la-Neuve, Belgium.
Magnus Sahlgren. 2006. The Word-Space Model.
Using Distributional Analysis to Represent Syntag-
matic and Paradigmatic Relations Between Words
in High-dimensional Vector Spaces. Ph.D. thesis,
Stockholm University, Stockholm, Sweden.
Hinrich Schu?tze. 1998. Automatic word sense dis-
crimination. Computational Linguistics, 24(1):97?
124.
Mike Scott. 1997. PC analysis of key words ? and key
key words. System, 25(2):233?245.
Dirk Speelman, Stefan Grondelaers, and Dirk Geer-
aerts. 2006. A profile-based calculation of re-
gion and register variation: The synchronic and di-
achronic status of the two main national varieties
of Dutch. In Andrew Wilson, Dawn Archer, and
Paul Rayson, editors, Corpus Linguistics around the
World, pages 195?202. Rodopi, Amsterdam.
Dirk Speelman, Stefan Grondelaers, and Dirk Geer-
aerts. 2008. Variation in the choice of adjectives
in the two main national varieties of Dutch. In
Gitte Kristiansen and Rene? Dirven, editors, Cogni-
tive Sociolinguistics. Language Variation, Cultural
Models, Social Systems, pages 205?233. Mouton de
Gruyter, Berlin.
16
Proceedings of the EACL 2012 Joint Workshop of LINGVIS & UNCLH, pages 16?24,
Avignon, France, April 23 - 24 2012. c?2012 Association for Computational Linguistics
Looking at word meaning.
An interactive visualization of Semantic Vector Spaces for Dutch synsets
Kris Heylen, Dirk Speelman and Dirk Geeraerts
QLVL, University of Leuven
Blijde-Inkomsstraat 21/3308, 3000 Leuven (Belgium)
{kris.heylen, dirk.speelman, dirk.geeraerts}@arts.kuleuven.be
Abstract
In statistical NLP, Semantic Vector Spaces
(SVS) are the standard technique for the
automatic modeling of lexical semantics.
However, it is largely unclear how these
black-box techniques exactly capture word
meaning. To explore the way an SVS struc-
tures the individual occurrences of words,
we use a non-parametric MDS solution of
a token-by-token similarity matrix. The
MDS solution is visualized in an interac-
tive plot with the Google Chart Tools. As
a case study, we look at the occurrences of
476 Dutch nouns grouped in 214 synsets.
1 Introduction
In the last twenty years, distributional models of
semantics have become the standard way of mod-
eling lexical semantics in statistical NLP. These
models, aka Semantic Vector Spaces (SVSs) or
Word Spaces, capture word meaning in terms
of frequency distributions of words over co-
occurring context words in a large corpus. The
basic assumption of the approach is that words
occurring in similar contexts will have a simi-
lar meaning. Speficic implementations of this
general idea have been developed for a wide va-
riety of computational linguistic tasks, includ-
ing Thesaurus extraction and Word Sense Dis-
ambiguation, Question answering and the model-
ing of human behavior in psycholinguistic experi-
ments (see Turney and Pantel (2010) for a general
overview of applications and speficic models). In
recent years, Semantic Vector Spaces have also
seen applications in more traditional domains of
linguistics, like diachronic lexical studies (Sagi et
al., 2009; Cook and Stevenson, 2010; Rohrdantz
et al, 2011) , or the study of lexical variation
(Peirsman et al, 2010). In this paper, we want to
show how Semantic Vector Spaces can further aid
the linguistic analysis of lexical semantics, pro-
vided that they are made accessible to lexicolo-
gists and lexicographers through a visualization
of their output.
Although all applications mentioned above as-
sume that distributional models can capture word
meaning to some extent, most of them use SVSs
only in an indirect, black-box way, without an-
alyzing which semantic properties and relations
actually manifest themselves in the models. This
is mainly a consequence of the task-based evalu-
ation paradigm prevalent in Computational Lin-
guistics: the researchers address a specific task
for which there is a pre-defined gold standard;
they implement a model with some new features,
that usually stem from a fairly intuitive, common-
sense reasoning of why some feature might bene-
fit the task at hand; the new model is then tested
against the gold standard data and there is an eval-
uation in terms of precision, recall and F-score.
In rare cases, there is also an error analysis that
leads to hypotheses about semantic characteristics
that are not yet properly modeled. Yet hardly ever,
there is in-depth analysis of which semantics the
tested model actually captures. Even though task-
based evaluation and shared test data sets are vital
to the objective comparison of computational ap-
proaches, they are, in our opinion, not sufficient
to assess whether the phenomenon of lexical se-
mantics is modeled adequately from a linguistic
perspective. This lack of linguistic insight into
the functioning of SVSs is also bemoaned in the
community itself. For example, Baroni and Lenci
(2011) say that ?To gain a real insight into the
16
abilities of DSMs (Distributional Semantic Mod-
els, A/N) to address lexical semantics, existing
benchmarks must be complemented with a more
intrinsically oriented approach, to perform direct
tests on the specific aspects of lexical knowledge
captured by the models?. They go on to present
their own lexical database that is similar to Word-
Net, but includes some additional semantic rela-
tions. They propose researchers test their model
against the database to find out which of the en-
coded relations it can detect. However, such an
analysis still boils down to checking whether a
model can replicate pre-defined structuralist se-
mantic relations, which themselves represent a
quite impoverished take on lexical semantics, at
least from a linguistic perspective. In this pa-
per, we want to argue that a more linguistically
adequate investigation of how SVSs capture lex-
ical semantics, should take a step back from the
evalution-against-gold-standard paradigm and do
a direct and unbiased analysis of the output of
SVS models. Such an analysis should compare
the SVS way of structuring semantics to the rich
descriptive and theoretic models of lexical se-
mantics that have been developed in Linguistics
proper (see Geeraerts (2010b) for an overview of
different research traditions). Such an in-depth,
manual analyis has to be done by skilled lexicolo-
gists and lexicographers. But would linguists, that
are traditionally seen as not very computation-
ally oriented, be interested in doing what many
Computational Linguists consider to be tedious
manual analysis? The answer, we think, is yes.
The last decade has seen a clear empirical turn
in Linguistics that has led linguists to embrace
advanced statistical analyses of large amounts of
corpus data to substantiate their theoretical hy-
potheses (see e.g. Geeraerts (2010a) and other
contributions in Glynn and Fischer (2010) on re-
search in semantics). SVSs would be an ideal
addition to those linguists? methodological reper-
toire. This creates the potential for a win-win sit-
uation: Computational linguists get an in-depth
evaluation of their models, while theoretical lin-
guists get a new tool for doing large scale empir-
ical analyses of word meaning. Of course, one
cannot just hand over a large matrix of word sim-
ilaties (the raw output of an SVS) and ask a lexi-
cologist what kind of semantics is ?in there?. In-
stead, a linguist needs an intuitive interface to ex-
plore the semantic structure captured by an SVS.
In this paper, we aim to present exactly that: an in-
teractive visualization of a Semantic Vector Space
Model that allows a lexicologist or lexicographer
to inspect how the model structures the uses of
words.
2 Token versus Type level
SVSs can model lexical semantics on two levels:
1. the type level: aggregating over all occur-
rences of a word, giving a representation of
a word?s general semantics.
2. the token level: representing the semantics
of each individual occurrence of a word.
The type-level models are mostly used to retrieve
semantic relations between words, e.g. synonyms
in the task of thesaurus extraction. Token-level
models are typically used to distinguish between
the different meanings within the uses of one
word, notably in the task of Word Sense Disam-
biguation or Word Sense Induction. Lexicological
studies on the other hand, typically combine both
perspectives: their scope is often defined on the
type level as the different words of a lexical field
or the set of near-synonyms referring to the same
concept, but they then go on to do a fine-grained
analysis on the token level of the uses of these
words to find out how the semantic space is pre-
cisely structured. In our study, we will also take
a concept-centered perspective and use as a start-
ing point the 218 sets of Dutch near-synonymous
nouns that Ruette et al (2012) generated with
their type-level SVS. For each synset, we then im-
plement our own token-level SVS to model the
individual occurrences of the nouns. The result-
ing token-by-token similarity matrix is then visu-
alized to show how the occurrences of the differ-
ent nouns are distributed over the semantic space
that is defined by the synset?s concept. Because
Dutch has two national varieties (Belgium and
the Netherlands) that show considerable lexical
variation, and because this is typically of inter-
est to lexicologists, we will also differentiate the
Netherlandic and Belgian tokens in our SVS mod-
els and their visualization.
The rest of this paper is structured as follows.
In the next section we present the corpus and
the near-synonym sets we used for our study.
Section 4 presents the token-level SVS imple-
mented for modeling the occurrences of the nouns
17
in the synsets. In section 5 we discuss the vi-
sualization of the SVS?s token-by-token similar-
ity matrices with Multi Dimensional Scaling and
the Google Visualization API. Finally, section 6
wraps up with conclusions and prospects for fu-
ture research.
3 Dutch corpus and synsets
The corpus for our study consists of Dutch news-
paper materials from 1999 to 2005. For Nether-
landic Dutch, we used the 500M words Twente
Nieuws Corpus (Ordelman, 2002)1, and for Bel-
gian Dutch, the Leuven Nieuws Corpus (aka Me-
diargus corpus, 1.3 million words2). The corpora
were automatically lemmatized, part-of-speech
tagged and syntactically parsed with the Alpino
parser (van Noord, 2006).
Ruette et al (2012) used the same corpora
for their semi-automatic generation of sets of
Dutch near-synonymous nouns. They used a so-
called dependency-based model (Pado? and Lap-
ata, 2007), which is a type-level SVS that models
the semantics of a target word as the weighted co-
occurrence frequencies with context words that
apear in a set of pre-defined dependency relations
with the target (a.o. adjectives that modify the
target noun, and verbs that have the target noun
as their subject). Ruette et al (2012) submitted
the output of their SVS to a clustering algorithm
known as Clustering by Committee (Pantel and
Lin, 2002). After some further manual cleaning,
this resulted in 218 synsets containing 476 nouns
in total. Table 1 gives some examples.
CONCEPT nouns in synset
INFRINGEMENT inbreuk, overtreding
GENOCIDE volkerenmoord, genocide
POLL peiling, opiniepeiling, rondvraag
MARIHUANA cannabis, marihuana
COUP staatsgreep, coup
MENINGITIS hersenvliesontsteking, meningitis
DEMONSTRATOR demonstrant, betoger
AIRPORT vliegveld, luchthaven
VICTORY zege, overwinning
HOMOSEXUAL homo, homoseksueel, homofiel
RELIGION religie, godsdienst
COMPUTER SCREEN computerschem, beeldscherm, monitor
Table 1: Dutch synsets (sample)
1Publication years 1999 up to 2002 of Algemeen Dag-
blad, NRC, Parool, Trouw and Volkskrant
2Publication years 1999 up to 2005 of De Morgen, De
Tijd, De Standaard, Het Laatste Nieuws, Het Nieuwsblad
and Het Belang van Limburg
4 Token-level SVS
Next, we wanted the model the individual oc-
currences of the nouns. The token-level SVS
we used is an adaptation the approach proposed
by Schu?tze (1998). He models the semantics
of a token as the frequency distribution over its
so-called second order co-occurrences. These
second-order co-occurrences are the type-level
context features of the (first-order) context words
co-occuring with the token. This way, a token?s
meaning is still modeled by the ?context? it oc-
curs in, but this context is now modeled itself by
combining the type vectors of the words in the
context. This higher order modeling is necessary
to avoid data-sparseness: any token only occurs
with a handful of other words and a first-order co-
occurrence vector would thus be too sparse to do
any meaningful vector comparison. Note that this
approach first needs to construct a type-level SVS
for the first-order context words that can then be
used to create a second-order token-vector.
In our study, we therefore first constructed a
type-level SVS for the 573,127 words in our cor-
pus with a frequency higher than 2. Since the fo-
cus of this study is visualization rather than find-
ing optimal SVS parameter settings, we chose set-
tings that proved optimal in our previous studies
(Peirsman et al, 2008; Heylen et al, 2008; Peirs-
man et al, 2010). For the context features of this
SVS, we used a bag-of-words approach with a
window of 4 to the left and right around the tar-
gets. The context feature set was restricted to the
5430 words, that were the among the 7000 most
frequent words in the corpus, (minus a stoplist of
34 high-frequent function words) AND that oc-
curred at least 50 times in both the Netherlandic
and Belgian part of the corpus. The latter was
done to make sure that Netherlandic and Belgian
type vectors were not dissimilar just because of
topical bias from proper names, place names or
words relating to local events. Raw co-occurrence
frequencies were weighted with Pointwise Mutual
Information and negative PMI?s were set to zero.
In a second step, we took a random sample of
100 Netherlandic and a 100 Belgian newspaper
issues from the corpus and extracted all occur-
rences of each of the 476 nouns in the synsets
described above. For each occurrence, we built
a token-vector by averaging over the type-vectors
of the words in a window of 5 words to the left
18
and right of the token. We experimented with two
averaging functions. In a first version, we fol-
lowed Schu?tze (1998) and just summed the type
vectors of a token?s context words, normalizing
by the number of context words for that token:
~owi =
?n
j?Cwi
~cj
n
where ~owi is the token vector for the i
th occur-
rence of noun w and Cwi is the set of n type
vectors ~cj for the context words in the window
around that ith occurrence of noun w. How-
ever, this summation means that each first order
context word has an equal weight in determining
the token vector. Yet, not all first-order context
words are equally informative for the meaning of
a token. In a sentence like ?While walking to
work, the teacher saw a dog barking and chasing
a cat?, bark and cat are much more indicative of
the meaning of dog than say teacher or work.
In a second, weighted version, we therefore in-
creased the contribution of these informative con-
text words by using the first-order context words?
PMI values with the noun in the synset. PMI can
be regarded as a measure for informativeness and
target-noun/context-word PMI-values were avail-
able anyway from our large type-level SVS. The
PMI of a noun w and a context word cj can now
be seen as a weight pmiwcj . In constructing the to-
ken vector ~owi for the ith occurrence of noun w ,
we now multiply the type vector ~cj of each con-
text word with the PMI weight pmiwcj , and then
normalize by the sum of the pmi-weights:
~owi =
?n
j?Cwi
pmiwcj ? ~cj
?n
j pmi
w
cj
The token vectors of all nouns from the same
synset were then combined in a token by second-
order-context-feature matrix. Note that this ma-
trix has the same dimensionality as the underlying
type-level SVS (5430). By calculating the cosine
between all pairs of token-vectors in the matrix,
we get the final token-by-token similarity matrix
for each of the 218 synsets 3.
3string operations on corpus text files were done with
Python 2.7. All matrix calculations were done in Matlab
R2009a for Linux
5 Visualization
The token-by-token similarity matrices reflect
how the different synonyms carve up the ?seman-
tic space? of the synset?s concept among them-
selves. However, this information is hard to grasp
from a large matrix of decimal figures. One pop-
ular way of visualizing a similarity matrix for
interpretative purposes is Multidimensional Scal-
ing (Cox and Cox, 2001). MDS tries to give an
optimal 2 or 3 dimensional representation of the
similarities (or distances) between objects in the
matrix. We applied Kruskal?s non-metric Multi-
dimensional Scaling to the all the token-by-token
similarity matrices using the isoMDS function in
the MASS package of R. Our visualisation soft-
ware package (see below) forced us to restrict our-
selves to a 2 dimensional MDS solution for now,
even tough stress levels were generally quite high
(0.25 to 0.45). Future implementation may use 3D
MDS solutions. Of course, other dimension re-
duction techniques than MDS exist: PCA is used
in Latent Semantic Analysis (Landauer and Du-
mais, 1997) and has been applied by Sagi et al
(2009) for modeling token semantics. Alterna-
tively, Latent Dirichlect Allocation (LDA) is at
the heart of Topic Models (Griffiths et al, 2007)
and was adapted by Brody and Lapata (2009) for
modeling token semantics. However, these tech-
niques all aim at bringing out a latent structure
that abstracts away from the ?raw? underlying
SVS similarities. Our aim, on the other hand,
is precisely to investigate how SVSs structure se-
mantics based on contextual distribution proper-
ties BEFORE additional latent structuring is ap-
plied. We therefore want a 2D representation of
the token similarity matrix that is as faithful as
possible and that is what MDS delivers 4.
In a next step we wanted to intergrate the 2
dimensional MDS plots with different types of
meta-data that might be of interest to the lexi-
cologist. Furthermore, we wanted the plots to
be interactive, so that a lexicologist can choose
which information to visualize in the plot. We
opted for the Motion Charts5 provided by Google
4Stress is a measure for that faithfulness. No such indi-
cation is directly available for LSA or LDA. However, we do
think LSA and LDA can be used to provide extra structure to
our visualizations, see section 6.
5To avoid dependence on commercial software, we also
made an implementation based on the plotting options of
R and the Python Image Library( https://perswww.
19
Chart Tools6, which allows to plot objects with
2D co-ordinates as color-codable and re-sizeable
bubbles in an interactive chart. If a time-
variable is present, the charts can be made dy-
namic to show the changing position of the ob-
jects in the plot over time7. We used the R-
package googleVis (Gesmann and Castillo,
2011), an interface between R and the Google
Visualisation API, to convert our R datamatri-
ces into Google Motion Charts. The interac-
tive charts, both those based on the weighted
and unweighted token-level SVSs, can be ex-
plored on our website ( https://perswww.
kuleuven.be/?u0038536/googleVis).
To illustrate the information that is avail-
able through this visualization, we discuss the
weighted chart for the concept COMPUTER
SCREEN (Figure 1 shows a screen cap, but we
strongly advise to look at the interactive version
on the website). In Dutch, this concept can be ref-
ered to with (at least) three near-synonyms, which
are color coded in the chart: beeldscherm (blue),
computerscherm (green) and monitor (yellow).
Each bubble in the chart is an occurrence (token)
of one these nouns. As Figure 2 shows, roling
over the bubbles makes the stretch of text visible
in which the noun occurs (These contexts are also
available in the lower right side bar). This usage-
in-context allows the lexicologist to interpret the
precise meaning of the occurrence of the noun.
The plot itself is a 2D representation of the seman-
tic distances between all tokens (as measured with
a token-level SVS) and reflects how the synonyms
are distributed over the ?semantic space?. As can
be expected with synonyms, they partially popu-
late the same area of the space (the right hand side
of the plot). Hovering over the bubbles and look-
ing at the contexts, we can see that they indeed
all refer to the concept COMPUTER SCREEN (See
example contexts 1 to 3 in Table 2). However, we
also see that a considerable part on the left hand
side of the plot shows no overlap and is only popu-
lated by tokens of monitor. Looking more closely
kuleuven.be/?u0038536/committees)
6(http://code.google.com/apis/chart/
interactive/docs/gallery/motionchart.
html)
7Since we worked with synchronic data, we did not
use this feature. However, Motion Charts have been used
by Hilpert (http://omnibus.uni-freiburg.de/
?mh608/motion.html) to visualize language change in
MDS plots of hand coded diachronic linguistic data.
at these occurrences, we see that they are instan-
tiations of another meaning of monitor, viz. ?su-
pervisor of youth leisure activities? (See example
context 4 in Table 2). Remember that our corpus
is stratified for Belgian and Netherlandic Dutch.
We can make this stratification visible by chang-
ing the color coding of the bubbles to COUNTRY
in the top right-hand drop-down menu. Figure 3
shows that the left-hand side, i.e. monitor-only
area of the plot, is also an all-Belgian area (hov-
ering over the BE value in the legend makes the
Belgian tokens in the plot flash). Changing the
color coding to WORDBYCOUNTRY makes this
even more clear. Indeed the youth leader mean-
ing of monitor is only familiar to speakers of Bel-
gian Dutch. Changing the color coding to the
variable NEWSPAPER shows that the youth leader
meaning is also typical for the popular, working
class newspapers Het Laatste Nieuws (LN) and
Het Nieuwsblad (NB) and is not prevelant in the
Belgian high-brow newspapers. In order to pro-
vide more structure to the plot, we also experi-
mented with including different K-means cluster-
ing solutions (from 2 up to 6 clusters) as color-
codable features, but these seem not very infor-
mative yet (but see section 6).
nr example context
1 De analisten houden met e?e?n oog de computerschermen
in de gaten
The analists keep one eye on the computer screen
2 Met een digitale camera... kan je je eigen foto op het
beeldscherm krijgen
With a digital camera, you can get your own photo on the
computer screen
3 Met een paar aanpassingen wordt het beeld op de moni-
toren nog completer
With a few adjustments, the image on the screen becomes
even more complete
4 Voor augustus zijn de speelpleinen nog op zoek naar mon-
itoren
For August, the playgrounds are still looking for supervi-
sors
Table 2: Contexts (shown in chart by mouse roll-over)
On the whole, the token-level SVS succeeds
fairly well in giving an interpretable semantic
structure to the tokens and the chart visualizes
this. However, SVSs are fully automatic ways of
modeling semantics and, not unexpectedly, some
tokens are out of place. For example, in the lower
left corner of the yellow cluster with monitor to-
kens referring to youth leader, there is also one
blue Netherlandic token of beeldscherm. Thanks
to the visualisation, such outliers can easily be
20
detected by the lexicologist who can then report
them to the computational linguist. The latter can
then try to come up with a model that gives a bet-
ter fit.
Finally, let us briefly look at the chart of another
concept, viz. COLLISION with its near-synonyms
aanrijding and botsing. Here, we expect the lit-
eral collissions (between cars), for which both
nouns can be used, to stand out form the figura-
tive ones (differences in opinion between people),
for which only botsing is apropriate in both vari-
eties of Dutch. Figure 4 indeed shows that the
right side of the chart is almost exclusively popu-
lated by botsing tokens. Looking at their contexts
reveals that they indeed overwhelmingly instan-
tiate the metaphorical meaning og collision. Yet
also here, there are some ?lost? aanrijding tokens
with a literal meaning and the visualization shows
that the current SVS implementation is not yet a
fully adequate model for capturing the words? se-
mantics.
6 General discussion
Although Vector Spaces have become the main-
stay of modeling lexical semantics in current sta-
tistical NLP, they are mostly used in a black box
way, and how exactly they capture word meaning
is not very clear. By visualizing their output, we
hope to have at least partially cracked open this
black box. Our aim is not just to make SVS out-
put easier to analyze for computer linguists. We
also want to make SVSs accessible for lexicolo-
gists and lexicographers with an interest in quanti-
tative, empirical data analysis. Such co-operation
brings mutual benefits: Computer linguists get ac-
cess to expert evaluation of their models. Lexicol-
ogists and lexicographers can use SVSs to iden-
tify preliminary semantic structure based on large
quantities of corpus data, instead of heaving to
sort through long lists of unstructured examples
of a word?s usage (the classical concordances). To
our knowledge, this paper is one of the first at-
tempts to visualize Semantic Vector Spaces and
make them accessible to a non-technical audi-
ence.
Of course, this is still largely work in progress
and a number of improvements and extensions are
still possible. First of all, the call-outs for the
bubbles in the Google Motion Charts were not
designed to contain large stretches of text. Cur-
rent corpus contexts are therefore to short to ana-
lyze the precise meaning of the tokens. One op-
tion would be to have pop-up windows with larger
contexts appear by clicking on the call-outs.
Secondly, we didn?t use the motion feature that
gave the charts its name. However, if we have
diachronic data, we could e.g. track the centroid
of a word?s tokens in the semantic space through
time and at the same time show the dispersion of
tokens around that centroid8.
Thirdly, in the current implementation, one im-
portant aspect of the black-box quality of SVSs
is not dealt with: it?s not clear which context
features cause tokens to be similar in the SVS
output, and, consequently, the interpreation of
the distances in the MDS plot remains quite ob-
scure. One option would be to use the cluster
solutions, that are already available as color cod-
able variables, and indicate the highest scoring
context features that the tokens in each cluster
have in common. Another option for bringing out
sense-distinguishing context words was proposed
by Rohrdantz et al (2011) who use Latent Dirich-
let Allocation to structure tokens. The loadings
on these latent topics could also be color-coded in
the chart.
Fourthly, we already indicated that two dimen-
sional MDS solutions have quite high stress val-
ues and a three dimensional solution would be
better to represent the token-by-token similari-
ties. This would require the 3D Charts, which are
not currently offered by the Google Chart Tools.
However both R and Matlab do have interactive
3D plotting functionality.
Finally, and most importantly, the plots cur-
rently do not allow any input from the user. If
we want the plots to be the starting point of an in-
depth semantic analysis, the lexicologist should
be able to annotate the occurrences with variables
of their own. For example, they might want to
code whether the occurrence refers to a laptop
screen, a desktop screen or cell phone screen, to
find out whether their is a finer-grained division of
labor among the synonyms. Additionally, an eval-
uation of the SVS?s performance might include
moving wrongly positioned tokens in the plot and
thus re-group tokens, based on the lexicologist?s
insights. Tracking these corrective movements
might then be valuable input for the computer lin-
guists to improve their models. Of course, this
8This is basically the approach of Sagi et al (2009) but
after LSA and without interactive visualization
21
goes well beyond our rather opportunistic use of
the Google Charts Tool.
References
Marco Baroni and Alessandro Lenci. 2011. How
we BLESSed distributional semantic evaluation. In
Proceedings of the GEMS 2011 Workshop on GE-
ometrical Models of Natural Language Semantics,
pages 1?10, Edinburgh, UK. Association for Com-
putational Linguistics.
Samuel Brody and Mirella Lapata. 2009. Bayesian
Word Sense Induction. In Proceedings of the 12th
Conference of the European Chapter of the ACL
(EACL 2009), pages 103?111, Athens, Greece. As-
sociation for Computational Linguistics.
Paul Cook and Suzanne Stevenson. 2010. Automat-
ically Identifying Changes in the Semantic Orien-
tation of Words. In Proceedings of the Seventh
International Conference on Language Resources
and Evaluation (LREC?10), pages 28?34, Valletta,
Malta. ELRA.
Trevor Cox and Michael Cox. 2001. Multidimen-
sional Scaling. Chapman & Hall, Boca Raton.
Dirk Geeraerts. 2010a. The doctor and the seman-
tician. In Dylan Glynn and Kerstin Fischer, edi-
tors, Quantitative Methods in Cognitive Semantics:
Corpus-Driven Approaches, pages 63?78. Mouton
de Gruyter, Berlin.
Dirk Geeraerts. 2010b. Theories of Lexical Semantics.
Oxford University Press, Oxford.
Markus Gesmann and Diego De Castillo. 2011. Using
the Google Visualisation API with R: googleVis-
0.2.4 Package Vignette.
Dylan Glynn and Kerstin Fischer. 2010. Quanti-
tative Methods in Cognitive Semantics: Corpus-
driven Approaches, volume 46. Mouton de Gruyter,
Berlin.
Thomas L. Griffiths, Mark Steyvers, and Joshua
Tenenbaum. 2007. Topics in Semantic Represen-
tation. Psychological Review, 114:211?244.
Kris Heylen, Yves Peirsman, Dirk Geeraerts, and Dirk
Speelman. 2008. Modelling Word Similarity. An
Evaluation of Automatic Synonymy Extraction Al-
gorithms. In Proceedings of the Language Re-
sources and Evaluation Conference (LREC 2008),
pages 3243?3249, Marrakech, Morocco. ELRA.
Thomas K Landauer and Susan T Dumais. 1997. A
Solution to Plato?s Problem: The Latent Semantic
Analysis Theory of Acquisition, Induction and Rep-
resentation of Knowledge. Psychological Review,
104(2):240?411.
Roeland J F Ordelman. 2002. Twente Nieuws Cor-
pus (TwNC). Technical report, Parlevink Language
Techonology Group. University of Twente.
Sebastian Pado? and Mirella Lapata. 2007.
Dependency-based construction of semantic
space models. Computational Linguistics,
33(2):161?199.
Patrick Pantel and Dekang Lin. 2002. Document clus-
tering with committees. In Proceedings of the 25th
annual international ACM SIGIR conference on Re-
search and development in information retrieval,
SIGIR ?02, pages 199?206, New York, NY, USA.
ACM.
Yves Peirsman, Kris Heylen, and Dirk Geeraerts.
2008. Size matters: tight and loose context defini-
tions in English word space models. In Proceedings
of the ESSLLI Workshop on Distributional Lexical
Semantics, pages 34?41, Hamburg, Germany. ESS-
LLI.
Yves Peirsman, Dirk Geeraerts, and Dirk Speelman.
2010. The automatic identification of lexical varia-
tion between language varieties. Natural Language
Engineering, 16(4):469?490.
Christian Rohrdantz, Annette Hautli, Thomas Mayer,
Miriam Butt, Daniel A Keim, and Frans Plank.
2011. Towards Tracking Semantic Change by Vi-
sual Analytics. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies, pages
305?310, Portland, Oregon, USA, June. Associa-
tion for Computational Linguistics.
Tom Ruette, Dirk Geeraerts, Yves Peirsman, and Dirk
Speelman. 2012. Semantic weighting mechanisms
in scalable lexical sociolectometry. In Benedikt
Szmrecsanyi and Bernhard Wa?lchli, editors, Aggre-
gating dialectology and typology: linguistic vari-
ation in text and speech, within and across lan-
guages. Mouton de Gruyter, Berlin.
Eyal Sagi, Stefan Kaufmann, and Brady Clark. 2009.
Semantic Density Analysis: Comparing Word
Meaning across Time and Phonetic Space. In Pro-
ceedings of the Workshop on Geometrical Mod-
els of Natural Language Semantics, pages 104?
111, Athens, Greece. Association for Computa-
tional Linguistics.
Hinrich Schu?tze. 1998. Automatic word sense dis-
crimination. Computational Linguistics, 24(1):97?
124.
Peter D. Turney and Patrick Pantel. 2010. From Fre-
quency to Meaning: Vector Space Models of Se-
mantics. Journal of Artificial Intelligence Research,
37(1):141?188.
Gertjan van Noord. 2006. At Last Parsing Is Now
Operational. In Verbum Ex Machina. Actes de la
13e conference sur le traitement automatique des
langues naturelles (TALN06), pages 20?42, Leuven,
Belgium. Presses universitaires de Louvain.
22
Figure 1: Screencap of Motion Chart for COMPUTER SCREEN
Figure 2: token of beeldscherm with context
23
Figure 3: COMPUTER SCREEN tokens stratified by country
Figure 4: Screencap of Motion Chart for COLLISION
24
