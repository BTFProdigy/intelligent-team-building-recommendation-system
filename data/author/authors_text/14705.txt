Coling 2010: Poster Volume, pages 1363?1372,
Beijing, August 2010
Applying Syntactic, Semantic and Discourse Constraints in Chinese
Temporal Annotation
Nianwen Xue
Brandeis University
xuen@brandeis.edu
Yuping Zhou
Brandeis University
yzhou@brandeis.edu
Abstract
We describe a Chinese temporal annota-
tion experiment that produced a sizable
data set for the TempEval-2 evaluation
campaign. We show that while we have
achieved high inter-annotator agreement
for simpler tasks such as identification of
events and time expressions, temporal re-
lation annotation proves to be much more
challenging. We show that in order to im-
prove the inter-annotator agreement it is
important to strategically select the anno-
tation targets, and the selection of annota-
tion targets should be subject to syntactic,
semantic and discourse constraints.
1 Introduction
Event-based temporal inference is a fundamen-
tal natural language technology that attempts to
determine the temporal location of an event as
well as the temporal ordering between events. It
supports a wide range of natural language appli-
cations such as Information Extraction, Question
Answering and Text Summarization. For some
genres of text (such as news), a temporal order-
ing of events can be the most informative summa-
rization of a document (Mani and Wilson, 2000;
Filatova and Hovy, 2001). Temporal inference
is especially important for multi-document sum-
marization where events extracted from multiple
documents need to be put in a chronological or-
der (Lin and Hovy, 2001; Barzilay et al, 2002)
to make logical sense. Event-based temporal in-
ference is also necessary for Question Answer-
ing (Harabagiu and Bejan, 2005; Harabagiu and
Bejan, 2006). For example, to answer ?When
was Beijing Olympics held??, events extracted
from natural language text have to be associated
with a temporal location, whereas to answer ?how
many terrorists have been caught since 9/11??,
temporal ordering of multiple events is the pre-
requisite. Event-based temporal inference has
also been studied extensively in the context of
Information Extraction, which typically involves
extracting unstructured information from natural
language sources and putting them into a struc-
tured database for querying or other forms of in-
formation access. For event extraction, this means
extracting the event participants as well as its tem-
poral location. Generally, an event has to occur in
a specific time and space, and the temporal loca-
tion of an event provides the necessary context for
accurately understanding that event.
Being able to infer the temporal location of an
event in Chinese text has many additional applica-
tions. Besides Information Extraction, Question
Answering and Text Summarization, knowing the
temporal location of an event is also highly valu-
able to Machine Translation. To translate a lan-
guage like Chinese into a language like English
in which tense is grammatically marked with in-
flectional morphemes, an MT system will have
to infer the necessary temporal information to
determine the correct tense for verbs. Statisti-
cal MT systems, the currently dominant research
paradigm, typically do not address this issue di-
rectly or even indirectly.
As machine learning approaches are gaining
dominance in computational linguistics and pro-
ducing state-of-the-art results in many areas, they
have in turn fueled the demand for large quan-
tities of human-annotated data of various types
1363
that machine learning algorithms can be trained
on and evaluated against. In the temporal in-
ference domain, this has led to the creation of
TimeBank (Pustejovsky et al, 2003), which is an-
notated based on the TimeML language (Puste-
jovsky et al, 2005). TimeML is becoming an ISO
standard for annotating events and time expres-
sions (ISO/TC 37/SC 4/WG 2, 2007). A version
of the TimeBank has been provided as a shared
public resource for TempEval-2007, the first tem-
poral evaluation campaign aimed at automatically
identifying temporal relations between events and
time expressions as well the temporal ordering be-
tween events.
In this paper, we report work for a Chinese tem-
poral annotation project as part of the 2010 multi-
lingual temporal evaluation campaign (TempEval-
2)1. Besides Chinese, TempEval-2 also includes
English, French, Italian, Korean and Spanish.
Our temporal annotation project is set up within
the confines of BAT2, a database-driven multilin-
gual temporal annotation tool that is also used
to support other TempEval-2 languages. The
TempEval-2 evaluation framework takes a divide-
and-conquer approach to temporal annotation.
With the eventual goal being the annotation of
temporal relations between events and between
events and time expressions, the TempEval-2 an-
notation consists of a series of event and temporal
annotation subtasks. The idea is that each of these
subtasks will be easier to annotate than the larger
task as a whole and is less demanding on the an-
notators. The hope is that this will lead to more
consistent annotation that will be easier to learn
for automatic systems as well.
The rest of the paper will be organized as fol-
lows. In Section 2, we briefly describe the seven
layers of annotation. In Section 3, we describe our
annotation procedure. In Section 4, we address a
major issue that arises from our annotation effort,
which is the question of how to select annotation
targets. Our experience, some positive and some
negative, shows that temporal annotation can be
carried out much more smoothly and with higher
quality when the right annotation targets are pre-
sented to the annotators. This is especially true
1http://www.timeml.org/tempeval2/
2http://www.timeml.org/site/bat
during the annotation of temporal relations be-
tween events and between events and time expres-
sions, which are more complex than simpler anno-
tation tasks such as identifying the events and time
expressions. Section 5 concludes our paper.
2 Layers of annotation
2.1 Events and time expressions
The ultimate goal for a temporal annotation
project is to determine the temporal relationship
between events, and between events and time ex-
pressions. In order to achieve that objective,
events and time expressions must be first iden-
tified. Specifically, this means marking up text
spans in a document that can be used to represent
the events and time expressions. Events in partic-
ular are abstract objects and a full description of
an event would include its participants and tempo-
ral and spatial location. The TempEval annotation
framework simplifies this by just marking a verb
or a noun that best represents an event. The verb
or noun can be considered as an ?event anchor?
that represents the most important aspect of the
event. This is illustrated in (1), where the verbs
?? (?attend?), ?? (?hold?) and the noun ?
? (?ceremony?) are marked as event anchors.
(1) ???
State Council
???
Vice Premier
???
Zou Jiahua
??
attend
?
ASP
??
today
??
hold
?
DE
??
commissioning
??
ribbon-cutting
??
ceremony
?
.
?Vice Premier Zou Jiahua of the State Coun-
cil attended today?s commissioning ribbon-
cutting ceremony?.
Once the text spans of event anchors are anno-
tated, these events are then annotated with a set of
attributes. The TempEval annotation framework
allows variations across languages in the number
of attributes one can define as well as the values
for these attributes. For example, in the English
annotation, one of the event attributes is grammat-
ical tense which can be read off the morphological
inflections of a verb. Chinese verbs, on the other
hand, are not inflected for tense. Instead, in the
1364
Chinese annotation, we have a more fully devel-
oped aspect attribute that has eight possible val-
ues: Actual, Experiential, Complementive, Delim-
itative, Progressive, Durative, Inceptive, and Con-
tinuative, largely based on the theoretical work of
Xiao and McEnery (2004).
The most important attribute for both English
and Chinese, however, is the Class attribute. The
values for this attribute include Reporting, As-
pectual, Perception, I-Action, I-State, State, and
Occurrence. The different values of the Class
attribute effectively constitute a classification of
events, and they are defined in the TimeML spec-
ification language (Pustejovsky et al, 2005).
The other building block in the TempEval anno-
tation framework is time expressions. Like events,
time expressions are marked with both text spans
and a set of attributes. The annotation of time
expressions is relatively straightforward, and we
follow the TimeML standards in our annotation
study. In TimeML, time expressions are formally
called TIMEX3s, and they have two obligatory at-
tributes: Type and Value. The value of Type is one
of time, date, duration or set. The Value attribute
is essentially a normalized time value based on
the TIDES standard for annotating time expres-
sions (Ferro et al, 2004). The normalization al-
lows easy comparison of time expression. For ex-
ample, there are three time expressions in (2), ?
????(?1992?),????? (?1996?) and?
? (?this year?). Note that even though ???
?? ? ????? (? 1992 to 1996?) forms
one duration, it is annotated as two time expres-
sions. All three time expressions in the sentence
are dates, and their normalized values are 1992,
1996, and 1997 respectively. To determine the
normalized value for ?? (?this year?), we need
to know the document creation time, and fortu-
nately this information is available in the meta-
data for the Chinese Treebank documents.
(2) ?????
1992
?
to
?????
1996
??
Shanghai
?? ?? ??
GDP
??
per year on average
??
grow
???????
14.2%
?
,
??
this year
?
DE
??
growth
??
speed
?
also
?
will
??
reach
?????
13%
??
above
?
?From 1992 to 1996, Shanghai?s GDP on av-
erage grows at14.2% per year. This year the
(GDP) growth will also reach above 13%.?
2.2 Temporal relations
Once the events and time expressions are in place,
we are in a position to annotate various temporal
relations that are defined over them. (Since events
and time expressions are entities that temporal re-
lation is defined upon, we will subsume them un-
der the cover term ?temporal entity? when conve-
nient.) The ultimate goal of temporal annotation
is to identify all temporal relations in text. This
goal cannot be achieved by manually annotating
temporal relation of all temporal entities for three
reasons. First, it is infeasible, given the number of
temporal entities in a typical document. Second,
it is unnecessary due to the transitive property of
certain types of temporal relation. For example, if
e1, e2 and e3 are all events, and if e1 is before e2,
and e2 is before e3, there is no need to also an-
notate the relation between e1 and e3. Third, the
result of annotating all temporal entity pairs does
not reflect the natural temporal relations that exist
in text. Verhagen et al (2009) found that a major
contributor to high inter-annotator disagreement
was hard-to-classify cases that annotators were in-
structed not to avoid. If a temporal relation is not
made clear in text, then it should not be present in
annotation.
Since it is infeasible, unnecessary and even
detrimental to manually annotate all possible rela-
tions between temporal entities, the question then
becomes one of selecting which temporal rela-
tions to annotate. The TempEval-2 evaluation
starts by annotating the following temporal rela-
tions, which it considers to be a priority:
1. between an event and a time expression
2. between an event and the document creation
time
3. between a subordinating event and its corre-
sponding subordinated event
1365
4. between a main event and its immediately
preceding main event
The TempEval-2 annotation uses six values for
all temporal relations, and they are Before, Before-
or-Overlap, Overlap, Overlap-or-After, After and
Vague. The Vague value is only used as the last
resort when the annotator really cannot determine
the temporal relationship between a pair of tem-
poral entities. In the meantime, the TempEval-2
also allows variations from language to language
regarding specific annotation strategies for each
subtask. For Chinese temporal annotation, most
of the decisions we have to make revolve around
one central question, and that is which temporal
entity pair to annotate.
2.2.1 Relation between events and time
expressions
The annotation of the relationship between
events and time expressions involves i) determin-
ing which event is related to which time expres-
sion, and ii) what is the nature of this relation-
ship. In (3), for example, there are three events
and three time expressions that enter into the tem-
poral relation annotation. If the annotator is re-
quired to annotate all possible event/time combi-
nations, there will be nine possible pairs. There
are at least three possible strategies to go about
selecting event/time pairs to annotate. The first
strategy is to annotate all possible pairs. This
seems to add unnecessary burden to the annota-
tor because if we know that e1 overlaps t1, we
can infer the temporal relationship between e1 and
t3 by virtue of the fact that t1 occurs before t3.
The second strategy is to allow the annotator to
freely choose which event/time pair to annotate
based on whether there is a clear temporal rela-
tion between them. This eliminates the possibility
that the annotator is forced to annotate hard-to-
classify and inconsequential relations, but leaving
this decision to the annotator entirely might lead
to low inter-annotator agreement where annota-
tors choose to annotate different event/time pairs.
(3) ?? ?? ?? ??
International Monetary Fund
[t1???
21st
]
?
at
??
here
[e1??
publish
]?
one
?
CL
??
preliminary
??
assessment
??
report
?
,
??
again
[e2??
lower
]?
AS
?
its
?
regarding
[t2?
this
] [t3?
next
]?
two
?
year
??
global
??
economic
??
growth
??
speed
?
DE
[e3
??
forecast
]?
.
?The International Monetary Fund on 21
published a preliminary assessment report,
again lowering its forecast of the global eco-
nomic growth for this year and next year.?
In our annotation, we adopt a third strategy. In-
stead of simply asking which event bears a tem-
poral relation to which temporal expression in the
same sentence, we ask annotators to judge which
event(s) a given temporal expression is intended
to modify. In essence, this amounts to asking the
annotator to first make a syntactic decision about
which events fall within the scope of a time ex-
pression. In (3), all three events e1, e2 and e3
fall within the scope of t1, and none of them are
in the scope of t2 and t3. This approach reduces
the number of fuzzy temporal relations that an-
notators might disagree on due to preference for
thoroughness vs. accuracy.
2.2.2 Temporal relation between
subordinating event and subordinated
event
The two tasks in the TempEval framework that
deal with event pairs are to annotate temporal re-
lation between the subordinating event and the
subordinated event, as well as the relation in
main event pairs. The division of labor between
them is quite clear: the former deals with intra-
sentential temporal relations whereas the latter
handles inter-sentential relations. It is not imme-
diately clear, however, how each of the two types
of relations should be defined.
Unlike in the event/time annotation where syn-
tactic notions are invoked in selecting event/time
pairs to annotate, our definitions of subordinat-
ing and subordinated events are primarily based
on semantic criteria. The subordinating event is
roughly the predicate while the subordinated event
is one of its arguments, provided that both the
1366
predicate and the argument are anchors of events.
For example, in (4), there are two subordinating
and subordinated event pairs. e2 is a subordinated
event of e1, and e4 is a subordinated event of e3.
(4) ??
Guangdong
[e1??]
hold
[e2???]
symposium
[e3
??]
introduce
[e4??]
tax reform
?
and
??
processing
??
trade
??
accounting
??
regulation
?Guangdong held a symposium introducing
the tax reform and the accounting regulations
on processing trade.?
An alternative to using the notion of predicate-
argument structure in determining the subordinat-
ing/subordinated events is to resort to syntactic re-
lations such as the verb and its object. The net re-
sult would be the same for Example (4). However,
the same argument that motivates the annotation
of the predicate-argument structures in the Prop-
bank (Palmer et al, 2005) and the Chinese Prop-
bank (Xue and Palmer, 2009) also applies to tem-
poral annotation. That is, the predicate-argument
structure and temporal relations tend to hold con-
stant in spite of the syntactic alternations and vari-
ations. For example, the temporal relation be-
tween the noun??? (?symposium?) event and
the verb?? (?hold?) event remains the same in
(5) in spite of the change in the syntactic relation
between them. If only event pairs in a verb-object
relation are annotated, the temporal relation be-
tween e2 and e1 in (5) would be lost.
(5) [e2???]
symposium
?
PREP
??
Guangdong
[e1??]
hold
?The symposium was held in Guangdong.?
2.2.3 Temporal relations between main
events
The purpose of annotating the temporal relation
between main events is to capture the temporal or-
dering of events scattered in different sentences
that constitute the main chain of events covered
in the article. Annotation of the temporal relation
between main events is further divided into two
steps. In the first step, main events are first iden-
tified among all events in a sentence, and then the
temporal relation between the main events in adja-
cent pairs of sentences is annotated. As a first ap-
proximation, we define ?main event? as follows:
a main event is the event expressed by the main
verb of the top-most level clause of a sentence.
The underlying assumption is that good writing
would place words representing important events
in prominent positions of a sentence and the first
choice of a prominent position in a sentence is
probably the main verb. An additional stipulation
is that in case of a co-ordinated construction in-
volving two or more main verbs at the top-most
level, the event represented by the first is the main
event of the sentence. This is to ensure that each
sentence has only one main event. As we shall
see in Section 3, this seemingly simple turns out
to be surprisingly difficult, as reflected in the low
inter-annotator agreement.
2.2.4 Temporal relation between events and
the document creation time
In this layer, all the events identified in a doc-
ument are annotated according to their temporal
relation to the document creation time. This task
is particularly challenging and intellectually inter-
esting for Chinese. As an isolating language (Li
and Thompson, 1981), Chinese has a small word
to morpheme ratio. That is, the majority of its
words consist of single morphemes. As a result, it
lacks the inflectional morphology that grammat-
ically marks tense. Tense directly encodes the
temporal location of an event in natural language
text and the lack of observable grammatical tense
makes it that much harder to determine the tem-
poral location of an event in Chinese text. This is
not to say, however, that Chinese speakers do not
attempt to convey the temporal location of events
when they speak or write, or that they cannot inter-
pret the temporal location when they read Chinese
text, or even that they have a different way of rep-
resenting the temporal location of events. In fact,
there is evidence that the temporal location is rep-
resented in Chinese in exactly the same way as it is
represented in English and most world languages:
in relation to the moment of speech. One piece of
evidence to support this claim is that Chinese tem-
poral expressions like ?? (?today?),?? (?to-
morrow?) and ?? (?yesterday?) all assume a
1367
temporal deixis that is the moment of speech in re-
lation to which all temporal locations are defined.
Annotating the temporal relation between events
and document creation time would then directly
capture the temporal location of events.
3 Annotation procedure and annotation
consistency
The data set consists of 60 files taken from the
Chinese Treebank (Xue et al, 2005). The source
of these files is Xinhua newswire. It goes through
a two-phase double blind and adjudication pro-
cess. The first phase involves three annotators,
with each file annotated by two annotators; the
second phase involves two judges, with each dou-
ble annotated document assigned to a single judge
for disagreement resolution. The inter-annotator
agreement between the two annotators (A and B)
as the agreement between each annotator and the
judge (J) are presented in Table 1. The agree-
ment is measured in terms of F1-score3, which is
a weighted average between precision and recall.
The F1-score is calculated as follows:
F = 2 ? precision ? recallprecision + recall (1)
The agreement statistics in Table 1 clearly show
that event and time expression annotations are
easier but temporal relations are harder as re-
flected in the lower inter-annotator agreement
scores. This is somewhat expected because rela-
tions involve two temporal entities while we are
only dealing with one temporal entity with event
and time expression annotations. The figures also
show the seemingly simple task of main event an-
notation (which only involves picking one event
per sentence as the main event) has a surprisingly
low inter-annotator agreement score. One reason
might be that in a less grammaticalized language
like Chinese, it is not always clear which verb is
the main verb when the syntactic tree information
is not displayed in the annotation interface. An-
other reason is that annotators sometimes disre-
3For a subset of the tasks, the total number of annotated
instances for the two annotators is the same. This subset
includes identification of main events, the temporal relation
between the main events in two adjacent sentences, and the
temporal relation between an event and the document cre-
ation time.
Layer f(A, B) f(A, J) f(B, J)
event-extent 0.90 0.93 0.94
timex-extent 0.86 0.88 0.93
main-events 0.74 0.90 0.82
tlinks-main-events 0.65 0.70 0.75
tlinks-dct-events 0.77 0.86 0.90
tlinks-e-t 0.75 0.88 0.83
tlinks-sub-e 0.53 0.74 0.70
Table 1: Inter-annotator agreement for the sub-
tasks: event-extent, the textual extent of an event
anchor; timex-extent, the textual span of a time
expression; tlinks-main-event, the temporal rela-
tion between the main events; tlinks-dct-events,
the temporal link between an event and the doc-
ument creation time; tlinks-e-t, the temporal re-
lation between an event and a time expression;
tlinks-sub-e, the temporal relation between a sub-
ordinating event and a subordinated event.
gard the syntax-based rule when it runs too much
afoul to their intuition, a point that we will come
back to and discuss in greater detail in Section 4.
It is worth noting that the annotation of the tem-
poral relation between an event and a time ex-
pression, and between a subordinating event and
a subordinated event involves two decisions. The
annotator needs to first decide which pairs of tem-
poral entities to annotate, and then decide what
temporal relation should be assigned to each tem-
poral entity pair. To take a closer look at which
of these two decisions creates more of a prob-
lem for the annotator, we computed the agreement
figures for these two steps respectively. In Table
2, Column 3 presents the figure for just identify-
ing which pair to annotate, and Column 4 is the
agreement for just assigning the temporal relation,
assuming the same pair of temporal entities are
found by both annotators.
Layer all identification f relation
tlinks-e-t 0.75 0.86 0.89
tlinks-sub-e 0.53 0.60 0.87
Table 2: Detailed agreement for event-time and
subordinating-subordinated events
From Table 2, it is clear that for both tasks,
1368
there is lower agreement between the annotators
in deciding which pair to annotate. Once the two
annotators agree on which pair to annotate, deter-
mining the temporal relation is relatively easier, as
reflected in higher agreement.
4 Detailed discussion
As described in Section 2, when annotating the
temporal relation between an event and a time ex-
pression, the annotators are instructed to annotate
an event-time pair if the event is falling within the
syntactic scope of the time expression. When an-
notating the relation between subordinating and
subordinated events, the annotators are instructed
to select event pairs based on the semantic notion
of predicate-argument structure. This assumes
a certain level of linguistic sophistication on the
part of the annotators. From the lower agreement
score in identifying event-time pairs (Table 2), it
is clear that our annotators, who are not trained
linguists, lack in this type of specialized knowl-
edge. They are better at making the more in-
tuitive judgment regarding the temporal relation
between two temporal entities. One solution is
obviously to find better trained linguists to per-
form these tasks, but it may not always be fea-
sible. Since our data is taking from the Chinese
Treebank and has already been annotated with
syntactic structures and predicate-argument struc-
tures (from the Chinese Propbank annotation (Xue
and Palmer, 2009)), an alternative is to extract the
event-time or event-event pairs using the syntactic
and predicate-argument structures as constraints.4
The annotation of main events and their rela-
tions presents a different challenge. Our first ap-
proximation is to select main events based on syn-
tactic considerations. A main event is equated
with the matrix verb in a sentence. In many
cases this turns out to be unintuitive. Two of the
recurring counter-intuitive cases involve directly
quoted speech and coordination structures.
Directly quoted speech In Chinese newswire
text, it is often the case that the source of informa-
tion is explicitly cited in the form of direct quota-
tions. (6) is such an example:
4See a similar approach in Bethard et al (2007).
(6) ??
Song-Jian
?
say
?
,
?
?
??
nowadays
?
,
??
China
?
already
?
can
??
produce
??
tens-of-thousands
?
CL
??
digital
??
telephone
?????
PBX
??
?Song Jian said, ?nowadays, China is capa-
ble of producing tens of thousands of digital
telephone PBX.? ?
While the event represented by the underlined
verb ? (?say?) may very well be important in
some natural language processing applications
(for example, sometimes the source of the target
information is crucial), it is not normally part of
the intended information being covered by a news
article. And it does not make much sense to anno-
tate its temporal relation to adjacent main events
that are on a par with what was said, not the saying
event itself. The point would be even clearer when
such a case is contrasted with a case in which a
similar semantic relation is formulated in a differ-
ent syntactic structure, as shown in (7):
(7) ?
according to
??
official
??
authority
??
source
??
divulge
?
,
??
this-year
??
China
??
government
??
determine
?
DE
??
economic
???
growth rate
?
be
????
8%
?
?According to some official sources in posi-
tion of authority, the economic growth rate
determined by the Chinese government is
8%.?
Because of the presence of the preposition
? (?according to?), the underlined reporting verb
?? (?divulge?), similar to? (?say?) in (6) with
respect to its semantic relation to the following
material, would not be annotated as representing
the main event of the sentence. The difference
in the annotation of the main event between (7)
and (6) seems to be an undesirable artifact of the
purely syntax-based annotation rule for identify-
ing main events.
1369
Co-ordination structure Co-ordination by no
means is a rare occurrence in the data, and of-
ten times, all events within a co-ordination struc-
ture, taken together, represent the main event of
the sentence. For example, in (8), both events
represented by the underlined verbs seem to be
equally significant and should be included in the
same chain of events. Given the prevalence of co-
ordination between verbs, the stipulation that only
the first one counts significantly undermines the
coverage of the task and goes against the annota-
tor?s intuitions.
(8) ??
This year
??
September
?
,
?
many
?
CL
??
foreign
??
oil
??
company
?
with
?
Kazakstan
??
national
??
oil
??
company
??
sign
?
LE
???
a series of
???
?century
???
contract?
?
,
??
these
??
contract
?
will
?
in
??
future
??
40
?
years
?
within
??
generate
?????
700-billion
??
dollar
?
DE
??
enormous
??
profit
?
?In September of this year, many foreign oil
companies signed a series of ?century con-
tract? with Kazakstan National Oil Company.
These contracts will generate an enormous
profit of 700-billion dollars.?
The issue in the annotation of the temporal re-
lation between main events seem to be more in the
selection of main event pairs than in the determi-
nation of the nature of their relationship. Our cur-
rent rule states that any two main events in consec-
utive sentences form a pair for annotation. This
task suffers a low level of inter-annotator agree-
ment partly because many main events identified
by syntactic criteria are not actually main events
in our intended sense. Often times, two consecu-
tive main events come from different levels of the
discourse structure or different chains of events,
which puts annotators in a hard-to-classify situa-
tion.
To achieve high inter-annotator consistency
when annotating the temporal relation between
events from different sentences, we believe the se-
lection of event pairs has to be informed by the
discourse structure of the document. This only
makes sense given that the annotation of tempo-
ral relation between events and time expressions
within one sentence is informed by the syntactic
structure, and the temporal relation between sub-
ordination and subordinating events benefits from
an understanding of the predicate-argument struc-
ture.
The specific type of discourse structure we have
in mind is the kind represented in the Penn Dis-
course Treebank (Miltsakaki et al, 2004). The
Penn Discourse Treebank-style of annotation can
inform temporal relation annotation in at least two
ways. First, the Penn Discourse Treebank anno-
tates the discourse relation between two adjacent
sentences. The discourse relation holds between
two abstract objects such as events or proposi-
tions. If a discourse relation holds between two
events, the temporal relation between those two
events might also be what we are interested in for
temporal annotation. The implicit assumption is
that the discourse structure of a document repre-
sents the important temporal relations within that
document as well. (9) is an example taken from
the Penn Discourse Treebank. The discourse re-
lation, characterized by the discourse connective
?in particular?, holds between the events anchored
by?dropped? and ?fell?. The temporal relation be-
tween these events also happens to be what we
would be interested in if we are to annotate the
main events between two adjacent sentences. No-
tice that in (9), material that is irrelevant to the
discourse relation is taken out of the two argu-
ments of this discourse relation, which are marked
in italics and bold face respectively.
(9) Meanwhile, the average yield on taxable
funds dropped nearly a tenth of a percent-
age point, the largest drop since midsum-
mer. implicit = in particular The average
seven-day compound yield, which assumes
that dividends are reinvested and that current
rates continue for a year, fell to 8.47%, its
lowest since late last year, from 8.55% the
week before, according to Donoghue?s.
The Penn Discourse Treebank also marks attri-
butions when annotating discourse relations. In
1370
(10), for example, ?he says? will be marked as a
case of attribution and the ?say? verb would be
marked as the main event of the sentence if syn-
tactic criteria are followed. Having attributions
identified would directly help with the temporal
annotation of examples like (6), where the main
event is embedded in direct quoted speech.
(10) When Mr. Green won a $240,000 verdict in
a land condemnation case against the State
in June 1983, [he says] Judge O?Kicki
unexpectedly awarded him an additional
$100,000.
As of now, the data we use for our temporal
annotation experiment have not yet been anno-
tated with discourse structures. In order to make
our temporal annotation sensitive to the discourse
structure, we either have to annotate the discourse
structure in a separate pass, or to incorporate the
key elements of the discourse structure when de-
veloping guidelines for temporal annotation.
5 Conclusion
We described a Chinese temporal annotation ex-
periment that produced a sizable data set for
the TempEval-2 annotation campaign. We show
that while we have achieved high inter-annotator
agreement for simpler tasks such as identifica-
tion of events and time expressions, temporal rela-
tion annotation proves to be much more challeng-
ing. We show that in order to improve annotation
consistency it is important to strategically select
the annotation targets, and this selection process
should be subject to syntactic, semantic and dis-
course constraints.
Acknowledgements
This work is supported by the National Sci-
ence Foundation via Grant No. 0855184 entitled
?Building a community resource for temporal in-
ference in Chinese?. All views expressed in this
paper are those of the authors and do not neces-
sarily represent the view of the National Science
Foundation.
References
Regina Barzilay, Noemie Elhadad, and Kathleen McK-
eown. 2002. Inferring strategies for sentence order-
ing in multidocument news summarization. Journal
of Artificial Intelligence Research, 17:35?55.
Steven Bethard, James H. Martin, and Sara Klin-
genstein. 2007. Finding Temporal Structure in
Text: Machine Learning of Syntactic Temporal Re-
lations. International Journal of Semantic Comput-
ing, 11(4).
Lisa Ferro, Laurie Gerber, Inderjeet Mani, Beth Sund-
heim, and George Wilson. 2004. TIDES 2003 Stan-
dard for the Annotation of Temporal Expressions.
Elena Filatova and Eduard Hovy. 2001. Assigning
Time-Stamps to Event Clauses. In Proceedings of
the Workshop on Temporal and Spatial Information
Processing, Toulouse.
Sanda Harabagiu and Cosmin Adrian Bejan. 2005.
Question Answering Based on Temporal Inference.
In Proceedings of the AAAI-2005 Workshop on In-
ference for Textual Question Answering, Pittsburgh,
Pennsylvania.
Sanda Harabagiu and Cosmin Adrian Bejan. 2006. An
Answer Bank for Temporal Inference. In Proceed-
ings of LREC 2006, Genoa, Italy.
ISO/TC 37/SC 4/WG 2. 2007. Language Resource
Management ? Semantic Annotation Framework
(SemAF) ? Part 1: Time and events.
Charles Li and Sandra Thompson. 1981. Mandarin
Chinese: A Functional Reference Grammar. Berke-
ley, Los Angeles, London: University of California
Press.
Chin-Yew Lin and Eduard Hovy. 2001. Neats: A mul-
tidocument summarizer. In Proceedings of the Doc-
ument Understanding Workshop.
Inderjeet Mani and George Wilson. 2000. Robust
temporal processing of news. In Proceedings of the
ACL?2000, Hong Kong, China.
Eleni Miltsakaki, Rashmi Prasad, Aravind Joshi, and
Bonnie Webber. 2004. The Penn Discourse Tree-
Bank. In Proceedings of the Language Resources
and Evaluation Conference, Lisbon, Portugal.
Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005. The Proposition Bank: An annotated cor-
pus of semantic roles. Computational Linguistics,
31(1):71?106.
James Pustejovsky, Patrick Hanks, Roser Sauri,
Andrew See, David Day, Lisa Ferro, Robert
Gaizauskas, Marcia Lazo, Andrea Setzer, and Beth
1371
Sundheim. 2003. The TimeBank Corpus. Corpus
Linguistics, pages 647?656.
James Pustejovsky, Bob Ingria, Roser Sauri, Jose Cas-
tano, Jessica Littman, Rob Gaizauskas, Andrea Set-
zer, G. Katz, and I. Mani. 2005. The specification
language TimeML. In I. Mani, J. Pustejovsky, and
R. Gaizauskas, editors, The Language of Time: a
Reader. Oxford University Press.
Marc Verhagen, Robert Gaizauskas, Frank Schilder,
Mark Hepple, Jessica Moszkowicz, and James
Pustejovsky. 2009. The TempEval Challenge:
Identifying Temporal Relation in Text. Language
Resources and Evaluation, 43(1):161?179.
Richard Xiao and Tony McEnery. 2004. Aspect in
Mandarin Chinese: A Corpus-based Study. Ams-
terdam: John Benjamins.
Nianwen Xue and Martha Palmer. 2009. Adding se-
mantic roles to the Chinese Treebank. Natural Lan-
guage Engineering, 15(1):143?172.
Nianwen Xue, Fei Xia, Fu dong Chiou, and Martha
Palmer. 2005. The Penn Chinese TreeBank: Phrase
Structure Annotation of a Large Corpus. Natural
Language Engineering, 11(2):207?238.
1372
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 69?77,
Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational Linguistics
PDTB-style Discourse Annotation of Chinese Text
Yuping Zhou
Computer Science Department
Brandeis University
Waltham, MA 02452
yzhou@brandeis.edu
Nianwen Xue
Computer Science Department
Brandeis University
Waltham, MA 02452
xuen@brandeis.edu
Abstract
We describe a discourse annotation scheme
for Chinese and report on the preliminary re-
sults. Our scheme, inspired by the Penn Dis-
course TreeBank (PDTB), adopts the lexically
grounded approach; at the same time, it makes
adaptations based on the linguistic and statisti-
cal characteristics of Chinese text. Annotation
results show that these adaptations work well
in practice. Our scheme, taken together with
other PDTB-style schemes (e.g. for English,
Turkish, Hindi, and Czech), affords a broader
perspective on how the generalized lexically
grounded approach can flesh itself out in the
context of cross-linguistic annotation of dis-
course relations.
1 Introduction
In the realm of discourse annotation, the Penn Dis-
course TreeBank (PDTB) (Prasad et al, 2008) sep-
arates itself by adopting a lexically grounded ap-
proach: Discourse relations are lexically anchored
by discourse connectives (e.g., because, but, there-
fore), which are viewed as predicates that take ab-
stract objects such as propositions, events and states
as their arguments. In the absence of explicit dis-
course connectives, the PDTB asks the annotator to
fill in a discourse connective that best describes the
discourse relation between these two sentences, in-
stead of selecting from an inventory of predefined
discourse relations. By keeping the discourse an-
notation lexically grounded even in the case of im-
plicit discourse relations, the PDTB appeals to the
annotator?s judgment at an intuitive level. This is in
contrast with an approach in which the set of dis-
course relations are pre-determined by linguistic ex-
perts and the role of the annotator is just to select
from those choices (Mann and Thompson, 1988;
Carlson et al, 2003). This lexically grounded ap-
proach led to consistent and reliable discourse anno-
tation, a feat that is generally hard to achieve for dis-
course annotation. The PDTB team reported inter-
annotator agreement in the lower 90% for explicit
discourse relations (Miltsakaki et al, 2004).
In this paper we describe a discourse annota-
tion scheme for Chinese that adopts this lexically
grounded approach while making adaptations when
warranted by the linguistic and statistical properties
of Chinese text. This scheme is shown to be practi-
cal and effective in the annotation experiment.
The rest of the paper is organized as follows: In
Section 2, we review the key aspects of the PDTB
annotation scheme under discussion in this paper. In
Section 3, we first show that some key features of
Chinese make adaptations necessary in Section 3.1,
and then in Section 3.2, we present our systematic
adaptations that follow from the differences outlined
in Section 3.1. In Section 4, we present the prelim-
inary annotation results we have so far. And finally
in Section 5, we conclude the paper.
2 The PDTB annotation scheme
As mentioned in the introduction, discourse relation
is viewed as a predication with two arguments in the
framework of the PDTB. To characterize the pred-
ication, the PDTB annotates its argument structure
and sense. Two types of discourse relation are dis-
tinguished in the annotation: explicit and implicit.
69
Although their annotation is carried out separately, it
conforms to the same paradigm of a discourse con-
nective with two arguments. In what follows, we
highlight the key points that will be under discussion
in the following sections. To get a more compre-
hensive and detailed picture of the PDTB scheme,
see the PDTB 2.0 annotation manual (Prasad et al,
2007).
2.1 Annotation of explicit discourse relations
Explicit discourse relations are those anchored by
explicit discourse connectives in text. Explicit con-
nectives are drawn from three grammatical classes:
? Subordinating conjunctions: e.g., because,
when, since, although;
? Coordinating conjunctions: e.g., and, or, nor;
? Discourse adverbials: e.g., however, other-
wise, then, as a result, for example.
Not all uses of these lexical items are considered to
function as a discourse connective. For example,
coordinating conjunctions appearing in VP coordi-
nations, such as ?and? in (1), are not annotated as
discourse connectives.
(1) More common chrysotile fibers are curly and
are more easily rejected by the body, Dr. Moss-
man explained.
The text spans of the two arguments of a discourse
connective are marked up. The two arguments, Arg1
and Arg2, are defined based on the physical location
of the connective: Arg2 is the argument expressed
by the clause syntactically bound to the connective,
and Arg1 is the other argument. There are no restric-
tions on how many clauses can be included in the
text span for an argument other than the Minimality
Principle: Only as many clauses and/or sentences
should be included in an argument selection as are
minimally required and sufficient for the interpreta-
tion of the relation.
2.2 Annotation of implicit discourse relations
In the case of implicit discourse relations, annotators
are asked to insert a discourse connective that best
conveys the implicit relation; when no such connec-
tive expression is appropriate, the implicit relation
is further distinguished as the following three sub-
types:
? AltLex: when insertion of a connective leads
to redundancy due to the presence of an alter-
natively lexicalized expression, as in (2).
? EntRel: when the only relation between the
two arguments is that they describe different as-
pects of the same entity, as in (3).
? NoRel: when neither a lexicalized discourse re-
lation nor entity-based coherence is present. It
is to be noted that at least some of the ?NoRel?
cases are due to the adjacency constraint (see
below for more detail).
(2) And she further stunned her listeners by re-
vealing her secret garden design method: [Arg1
Commissioning a friend to spend five or six
thousand dollars . . . on books that I ultimately
cut up.] [Arg2 AltLex After that, the layout had
been easy.
(3) [Arg1 Hale Milgrim, 41 years old, senior vice
president, marketing at Elecktra Entertainment
Inc., was named president of Capitol Records
Inc., a unit of this entertainment concern].
[Arg2 EntRel Mr. Milgrim succeeds David
Berman, who resigned last month].
There are restrictions on what kinds of implicit
relations are subjected to annotation, presented be-
low. These restrictions do not have counterparts in
explicit relation annotation.
? Implicit relations between adjacent clauses in
the same sentence not separated by a semi-
colon are not annotated, even though the rela-
tion may very well be definable. A case in point
is presented in (4) below, involving an intra-
sentential comma-separated relation between a
main clause and a free adjunct.
? Implicit relations between adjacent sentences
across a paragraph boundary are not annotated.
? The adjacency constraint: At least some part
of the spans selected for Arg1 and Arg2 must
belong to the pair of adjacent sentences initially
identified for annotation.
(4) [MC The market for export financing was liber-
alized in the mid-1980s], [FA forcing the bank
to face competition].
70
2.3 Annotation of senses
Discourse connectives, whether originally present in
the data in the case of explicit relations, or filled in
by annotators in the case of implicit relations, along
with text spans marked as ?AltLex?, are annotated
with respect to their senses. There are three levels in
the sense hierarchy:
? Class: There are four major semantic classes:
TEMPORAL, CONTINGENCY, COMPARISON,
and EXPANSION;
? Type: A second level of types is further de-
fined for each semantic class. For example,
under the class CONTINGENCY, there are two
types: ?Cause? (relating two situations in a di-
rect cause-effect relation) and ?Condition? (re-
lating a hypothetical situation with its (possi-
ble) consequences);1
? Subtype: A third level of subtypes is defined
for some, but not all, types. For instance, under
the type ?CONTINGENCY:Cause?, there are two
subtypes: ?reason? (for cases like because and
since) and ?result? (for cases like so and as a
result).
It is worth noting that a type of implicit relation,
namely those labeled as ?EntRel?, is not part of the
sense hierarchy since it has no explicit counterpart.
3 Adapted scheme for Chinese
3.1 Key characteristics of Chinese text
Despite similarities in discourse features between
Chinese and English (Xue, 2005), there are differ-
ences that have a significant impact on how dis-
course relations could be best annotated. These dif-
ferences can be illustrated with (5):
(5) ??
according to reports
?
,
[AO1 ??
Dongguan
??
Customs
?
in total
??
accept
??
company
??
contract
??
record
?????
8400 plus
? ]
CLASS
?[AO2
,
?
compare
??
pilot
?
before
?
slight
?
EXIST
?? ]
increase
?
,
[AO3??
company
1There is another dimension to this level, i.e. literal or prag-
matic use. If this dimension is taken into account, there could be
said to be four types: ?Cause?, ?Pragmatic Cause?, ?Condition?,
and ?Pragmatic Condition?. For details, see Prasad et al (2007).
??
respond/response
?? ]
well/good
?
,
[AO4??
generally
??
acknowledge
?? ]
accept/acceptance
?
.
?According to reports, [AO1 Dongguan District
Customs accepted more than 8400 records of com-
pany contracts], [AO2 a slight increase from before
the pilot]. [AO3 Companies responded well], [AO4
generally acknowledging acceptance].?
This sentence reports on how a pilot program
worked in Dongguan City. Because all that is said
is about the pilot program, it is perfectly natural to
include it all in a single sentence in Chinese. Intu-
itively though, there are two different aspects of how
the pilot program worked: the number of records
and the response from the affected companies. To
report the same facts in English, it is more natural
to break them down into two sentences or two semi-
colon-separated clauses, but in Chinese, not only are
they merely separated by comma, but also there is no
connective relating them.
This difference in writing style necessitates re-
thinking of the annotation scheme. If we apply the
PDTB scheme to the English translation, regardless
of whether the two pieces of facts are expressed in
two sentences or two semi-colon-separated clauses,
at least one discourse relation will be annotated, re-
lating these two text units. In contrast, if we apply
the same scheme to the Chinese sentence, no dis-
course relation will be picked out because this is
just one comma-separated sentence with no explicit
discourse connectives in it. In other words, the dis-
course relation within the Chinese sentence, which
would be captured in its English counterpart follow-
ing the PDTB procedure, would be lost when anno-
tating Chinese. Such loss is not a sporadic occur-
rence but rather a very prevalent one since it is asso-
ciated with the customary writing style of Chinese.
To ensure a reasonable level of coverage, we need to
consider comma-delimited intra-sentential implicit
relations when annotating Chinese text.
There are some complications associated with this
move. One of them is that it introduces into dis-
course annotation considerable ambiguity associ-
ated with the comma. For example, the first in-
stance of comma in (5), immediately following ??
?? (?according to reports?), clearly does not indi-
cate a discourse relation, so it needs to be spelt out in
71
the guidelines how to exclude such cases of comma
as discourse relation indicators. We think, however,
that disambiguating the commas in Chinese text is
valuable in its own right and is a necessary step in
annotating discourse relations.
Another complication is that some comma-
separated chunks are ambiguous as to whether they
should be considered potential arguments in a dis-
course relation. The chunks marked AO2 and AO4
in (5) are examples of such cases. They, judging
from their English translation, may seem clear cases
of free adjuncts in PDTB terms (Prasad et al, 2007),
but there is no justification for treating them as such
in Chinese. The lack of justification comes from at
least three features of Chinese:
? Certain words, for instance, ???? (?re-
spond/response?), ???? (?well/good?) and
???? (?accept/acceptance?), are ambiguous
with respect to their POS, and when they com-
bine, the resulting sentence may have more
than one syntactic analysis. For example, AO3
may be literally translated as ?Companies re-
sponded well? or ?Companies? response was
good?.
? There are no inflectional clues to differenti-
ate free adjuncts and main clauses. For ex-
ample, one can be reasonably certain that ??
?? (?acknowledge?) functions as a verb in (5),
however, there is no indication whether it is
in the form corresponding to ?acknowledging?
or ?acknowledged? in English. Or putting it
differently, whether one wants to express in
Chinese the meaning corresponding to the -ing
form or the tensed form in English, the same
form ???? could apply.
? Both subject and object can be dropped in Chi-
nese, and they often are when they are infer-
able from the context. For example, in the two-
sentence sequence below, the subject of (7) is
dropped since it is clearly the same as the sub-
ject of the previous sentence in (6) .
(6) [S1
recent
?
five
?
years
?
since
?
,
?
Shanghai
??
through
??
actively
??
from
?
other
?
province
?
city
?
procure
??
export
??
supply
??
,
?
organize
??
China
??
East
??
Export
??
Commodity
??
Fair
???
etc.
?
event,
???
strengthen
??
port
??
to
?
whole country
??
DE
?
connection
??
capability
??
.
?]
?[S1 In the past five years, Shanghai strength-
ened the connection of its port to other areas
of the country through actively procuring ex-
port supplies from other provinces and cities,
and through organizing events such as the East
China Export Commodities Fair.]?
(7) [S2??
At the same time
?
,
??
develop
??
transnational
??
operation
?
,
??
vigorously
??
open up
???
diversified
???]
market
?[S2 At the same time, (it) developed transna-
tional operations (and) vigorously opened up
diversified markets.]?
Since the subject can be omitted from the en-
tire sentence, absence or presence of subject in
a clause is not an indication whether the clause
is a main clause or a free adjunct, or whether it
is part of a VP coordination without a connec-
tive. So if we take into account both the lack of
differentiating inflectional clues and the possi-
bility of omitting the subject, AO4 in (5) may
be literally translated as ?generally acknowl-
edging acceptance?, or ?(and) generally ac-
knowledged acceptance?, or ?(companies) gen-
erally acknowledged acceptance?, or ?(compa-
nies) generally acknowledged (they) accepted
(it)?.
Since in Chinese, there is no reliable indicator dis-
tinguishing between main clauses and free adjuncts,
or distinguishing between coordination on the clause
level without the subject and coordination on the VP
level, we will not rely on these distinctions in anno-
tation, as the PDTB team does in their annotation.
These basic decisions directly based on linguistic
characteristics of Chinese lead to more systematic
adaptations to the annotation scheme, to which we
will turn in the next subsection.
3.2 Systematic adaptations
The main consequence of the basic decisions de-
scribed in Section 3.1 is that we have a whole lot
72
more tokens of implicit relation than explicit rela-
tion to deal with. According to a rough count on
20 randomly selected files from Chinese Treebank
(Xue et al, 2005), 82% are tokens of implicit rela-
tion, compared to 54.5% in the PDTB 2.0. Given
the overwhelming number of implicit relations, we
re-examine where it could make an impact in the an-
notation scheme. There are three such areas.
3.2.1 Procedural division between explicit and
implicit discourse relation
In the PDTB, explicit and implicit relations are
annotated separately. This is probably partly be-
cause explicit connectives are quite abundant in En-
glish, and partly because the project evolved in
stages, expanding from the more canonical case of
explicit relation to implicit relation for greater cov-
erage. When annotating Chinese text, maintaining
this procedural division makes much less sense: the
landscape of discourse relation (or at least the key
elements of it) has already been mapped out by the
PDTB work and to set up a separate task to cover
18% of the data does not seem like a worthwhile
bother without additional benefits for doing so.
So the question now is how to annotate explicit
and implicit relations in one fell swoop? In Chi-
nese text, the use of a discourse connective is al-
most always accompanied by a punctuation or two
(usually period and/or comma), preceding or flank-
ing it. So a sensible solution is to rely on punctu-
ations as the denominator between explicit and im-
plicit relations;and in the case of explicit relation,
the connective will be marked up as an attribute of
the discourse relation. This unified approach simpli-
fies the annotation procedure while preserving the
explicit/implicit distinction in the process.
One might question, at this point, whether such
an approach can still call itself ?lexically grounded?.
Certainly not if one interprets the term literally ; but
in a broader sense, our approach can be seen as an
instantiation of a generalized version of it, much the
same way that the PDTB is an, albeit different, in-
stantiation of it for English. The thrust of the lexi-
cally grounded approach is that discourse annotation
should be a data-driven, bottom-up process, rather
than a top-down one, trying to fit data into a pre-
scriptive system. Once the insight that a discourse
connective functions like a predicate with two ar-
guments is generalized to cover all discourse rela-
tions, there is no fundamental difference between
explicit and implicit discourse relations: both work
like a predicate whether or not there is a lexicaliza-
tion of it. As to what role this distinction plays in
the annotation procedure, it is an engineering issue,
depending on a slew of factors, among which are
cross-linguistic variations. In the case of Chinese,
we think it is more economical to treat explicit and
implicit relations alike in the annotation process.
To treat explicit and implicit relations alike actu-
ally goes beyond annotating them in one pass; it also
involves how they are annotated, which we discuss
next.
3.2.2 Annotation of implicit discourse relations
In the PDTB, treatment of implicit discourse rela-
tions is modeled after that of explicit relations, and at
the same time, some restrictions are put on implicit,
but not explicit, relations. This is quite understand-
able: implicit discourse relations tend to be vague
and elusive, so making use of explicit relations as a
prototype helps pin them down, and restrictions are
put in place to strike a balance between high relia-
bility and good coverage. When implicit relations
constitute a vast majority of the data as is the case
with Chinese, both aspects need to be re-examined
to strike a new balance.
In the PDTB, annotators are asked to insert a
discourse connective that best conveys the implicit
discourse relation between two adjacent discourse
units; when no such connective expression is ap-
propriate, the implicit discourse relation is further
distinguished as ?AltLex?, ?EntRel?, and ?NoRel?.
The inserted connectives and those marked as ?Al-
tLex?, along with explicit discourse connectives, are
further annotated with respect to their senses.
When a connective needs to be inserted in a ma-
jority of cases, the difficulty of the task really stands
out. In many cases, it seems, there is a good rea-
son for not having a connective present and because
of it, the wording rejects insertion of a connective
even if it expresses the underlying discourse relation
exactly (or sometimes, maybe the wording itself is
the reason for not having a connective). So to try
to insert a connective expression may very well be
too hard a task for annotators, with little to show for
their effort in the end.
73
Furthermore, the inter-annotator agreement for
providing an explicit connective in place of an im-
plicit one is computed based on the type of explicit
connectives (e.g. cause-effect relations, temporal re-
lations, contrastive relations, etc.), rather than based
on their identity (Miltsakaki et al, 2004). This sug-
gests that a reasonable degree of agreement for such
a task may only be reached with a coarse classifica-
tion scheme.
Given the above two considerations, our solution
is to annotate implicit discourse relations with their
senses directly, bypassing the step of inserting a con-
nective expression. It has been pointed out that to
train annotators to reason about pre-defined abstract
relations with high reliability might be too hard a
task (Prasad et al, 2007). This difficulty can be
overcome by associating each semantic type with
one or two prototypical explicit connectives and ask-
ing annotators to consider each to see if it expresses
the implicit discourse relation. This way, annotators
have a concrete aid to reason about abstract relations
without having to choose one connective from a set
expressing roughly the same relation or having to
worry about whether insertion of the connective is
somehow awkward.
It should be noted that annotating implicit rela-
tions directly with their senses means that sense an-
notation is no longer restricted to those that can be
lexically expressed, but also includes those that can-
not, notably those labeled ?EntRel/NoRel? in the
PDTB.2 In other words, we annotate senses of dis-
course relations, not just connectives and their lex-
ical alternatives (in the case of AltLex). This ex-
pansion is consistent with the generalized view of
the lexically grounded approach discussed in Sec-
tion 3.2.1.
With respect to restrictions on implicit relation,
we will adopt them as they prove to be necessary
in the annotation process, with one exception. The
exception is the restriction that implicit relations be-
tween adjacent clauses in the same sentence not sep-
arated by a semi-colon are not annotated. This re-
striction seems to apply mainly to a main clause and
any free adjunct attached to it in English; in Chinese,
however, the distinction between a main clause and a
2Thus ?EntRel? and ?NoRel? are treated as relation senses,
rather than relation types, in our scheme.
free adjunct is not as clear-cut for reasons explained
in Section 3.1. So this restriction is not applicable
for Chinese annotation.
3.2.3 Definition of Arg1 and Arg2
The third area that an overwhelming number of
implicit relation in the data affects is how Arg1 and
Arg2 are defined. As mentioned in the introduc-
tion, discourse relations are viewed as a predication
with two arguments. These two arguments are de-
fined based on the physical location of the connec-
tive in the PDTB: Arg2 is the argument expressed by
the clause syntactically bound to the connective and
Arg1 is the other argument. In the case of implicit
relations, the label is assigned according to the text
order.
In an annotation task where implicit relations con-
stitute an overwhelming majority, the distinction of
Arg1 and Arg2 is meaningless in most cases. In addi-
tion, the phenomenon of parallel connectives is pre-
dominant in Chinese. Parallel connectives are pairs
of connectives that take the same arguments, exam-
ples of which in English are ?if..then?, ?either..or?,
and ?on the one hand..on the other hand?. In Chi-
nese, most connectives are part of a pair; though
some can be dropped from their pair, it is considered
?proper? or formal to use both. (8) below presents
two such examples, for which parallel connectives
are not possible in English.
(8) a. ??
London
??
stock market
?
because
??
coincide
???
Bank Holiday
?
,
?
therefore
??
NEG
???
open market
?London Stock Market did not open because it
was Bank Holiday.?
b. ??
Although
??
they
?
NEG
?
leave
?
land
?
,
?
NEG
?
leave
?
home village
?
,
?
but
??
strict
?
PART
?
speak
?
already
??
no longer
?
be
??
tradition
??
sense
?
PREP
?
DE
???
peasant
?Although they do not leave land or their home
village, strictly speaking, they are no longer
peasants in the traditional sense.?
In the PDTB, parallel connectives are annotated dis-
continuously; but given the prevalence of such phe-
nomenon in Chinese, such practice would generate
74
a considerably high percentage of essentially repeti-
tive annotation among explicit relations.
So the situation with Chinese is that distinguish-
ing Arg1 and Arg2 the PDTB way is meaningless
in most cases, and in the remaining cases, it of-
ten results in duplication. Rather than abandoning
the distinction altogether, we think it makes more
sense to define Arg1 and Arg2 semantically. It will
not create too much additional work beyond distinc-
tion of different senses of discourse relation in the
PDTB. For example, in the semantic type CONTIN-
GENCY:Cause, we can define ?reason? as Arg1 and
?result? as Arg2. In this scheme, no matter which
one of? (?because?) and? (?therefore?) appears
without the other, or if they appear as a pair in a
sentence, or if the relation is implicit, the Arg1 and
Arg2 labels will be consistently assigned to the same
clauses.
This approach is consistent with the move from
annotating senses of connectives to annotating
senses of discourse relations, pointed out in Section
3.2.2. For example, in the PDTB?s sense hierarchy,
?reason? and ?result? are subtypes under type CON-
TINGENCY:Cause: ?reason? applies to connectives
like ?because? and ?since? while ?result? applies
to connectives like ?so? and ?as a result?. When
we move to annotating senses of discourse relations,
since both types of connectives express the same un-
derlying discourse relation, there will not be further
division under CONTINGENCY:Cause, and the ?rea-
son?/?result? distinction is an intrinsic property of
the semantic type. We think this level of generality
makes sense semantically.
4 Annotation experiment
To test our adapted annotation scheme, we have con-
ducted annotation experiments on a modest, yet sig-
nificant, amount of data and computed agreement
statistics.
4.1 Set-up
The agreement statistics come from annotation con-
ducted by two annotators in training so far. The data
set consists of 98 files taken from the Chinese Tree-
bank (Xue et al, 2005). The source of these files is
Xinhua newswire. The annotation is carried out on
the PDTB annotation tool3.
4.2 Inter-annotator agreement
To evaluate our proposed scheme, we measure
agreement on each adaption proposed in Section
3, as well as agreement on argument span deter-
mination. Whenever applicable, we also present
(roughly) comparable statistics of the PDTB (Milt-
sakaki et al, 2004). The results are summarized in
Table 1.
Chinese PDTB
tkn no. F(p/r) (%) (%)
rel-ident 3951*
95.4
N/A
(96.0/94.7)
rel-type 3951 95.1 N/A
imp-sns-type 2967 87.4 72
arg-order 3059 99.8 N/A
argument span
exp-span-xm 1580 84.2 90.2
exp-span-pm 1580 99.6 94.5
imp-span-xm 5934 76.9 85.1
overall-bnd- 14039*
87.7
N/A
(87.5/87.9)
Table 1: Inter-annotator agreement in various aspects
of Chinese discourse annotation: rel-ident, discourse
relation identification; rel-type, relation type classifica-
tion; imp-sns-type, classification of sense type of im-
plicit relations; arg-order, order determination of Arg1
and Arg2. For agreement on argument spans, the
naming convention is <type-of-relation>-<element-as-
independent-token>-<matching-method>. exp: explicit
relations; imp: implicit relations; span: argument span;
xm: exact match; pm: partial match; bnd: boundary. *:
number of tokens agreed on by both annotators.
The first adaption we proposed is to annotate ex-
plicit and implicit discourse relations in one pass.
This introduces two steps, at which agreement can
each be measured: First, the annotator needs to
make the judgment, at each instance of the punctu-
ations, whether there is a discourse relation (a step
we call ?relation identification?); second, once a dis-
course relation is identified, the annotator needs to
classify the type as one of ?Explicit?, ?Implicit?, or
?AltLex? (a step we call ?relation type classifica-
tion?). The agreement at these two steps is 95.4%
3http://www.seas.upenn.edu/?pdtb/tools.shtml#annotator
75
and 95.1% respectively.
The second adaption is to bypass the step of in-
serting a connective when annotating an implicit dis-
course relation and classify the sense directly. The
third adaptation is to define Arg1 and Arg2 semanti-
cally for each sense. To help annotators think about
relation sense abstractly and determine the order of
the arguments, we put a helper item alongside each
sense label, like ?Causation: ??arg1??arg2?
(?Causation: because arg1 therefore arg2?). This
approach works well, as evidenced by 87.4%4 and
99.8% agreement for the two processes respectively.
To evaluate agreement on determining argument
span, we adopt four measures. In the first three,
explicit and implicit relations are calculated sepa-
rately (although they are actually annotated in the
same process) to make our results comparable to
the published PDTB results. Each argument span is
treated as an independent token and either exact or
partial match (i.e. if two spans share one boundary)
counts as 1. The fourth measure is less stringent than
exact match and more stringent than partial match:
It groups explicit and implicit relation together and
treats each boundary as an independent token. Typ-
ically, an argument span has two boundaries, but it
can have four (or more) boundaries when an argu-
ment span is interrupted by a connective and/or an
AltLex item.
Evidently, determining argument span is the most
challenging aspect of discourse annotation. How-
ever, it should be pointed out that agreement was on
an overall upward trend, which became especially
prominent after we instituted a restriction on im-
plicit relations across a paragraph boundary towards
the end of the training period. It restricts full anno-
4Two more points should be made about this number. First,
it may be partially attributed to our differently structured sense
hierarchy. It is a flat structure containing the following 12 val-
ues: ALTERNATIVE, CAUSATION, CONDITIONAL, CONJUNC-
TION, CONTRAST, EXPANSION, PROGRESSION, PURPOSE,
RESTATEMENT, TEMPORAL, EntRel, and NoRel. Aside from in-
cluding EntRel and NoRel (the reason and significance of which
have been discussed in Section 3.2.2), the revision was by and
large not motivated by Chinese-specific features, so we do not
address it in detail in this paper. Second, in making the compar-
ison with the PDTB result, the 12-value structure is collapsed
into 5 values: TEMPORAL, CONTINGENCY, COMPARISON, EX-
PANSION, and EntRel/NoRel, which must be different from the
5 values in Miltsakaki et al (2004), judging from the descrip-
tions.
tation to only three specific situations so that most
loose and/or hard-to-delimit relations across para-
graph boundaries are excluded. This restriction ap-
pears to be quite effective, as shown in Table 2.
num Overall Arg Span
of boundary span-em
rel.?s F(p/r) (%) (%)
last 5 wks 1103 90.0 (90.0/89.9) 80.8
last 3 wks 677 91.0 (91.0/91.0) 82.5
last 2 wks 499 91.8 (91.8/91.8) 84.2
Table 2: Inter-annotator agreement on argument span
during the last 5 weeks of training.
5 Conclusions
We have presented a discourse annotation scheme
for Chinese that adopts the lexically ground ap-
proach of the PDTB while making systematic adap-
tations motivated by characteristics of Chinese text.
These adaptations not only work well in practice, as
evidenced by the results from our annotation exper-
iment, but also embody a more generalized view of
the lexically ground approach to discourse annota-
tion: Discourse relations are predication involving
two arguments; the predicate can be either covert
(i.e. Implicit) or overt, lexicalized as discourse con-
nectives (i.e. Explicit) or their more polymorphous
counterparts (i.e. AltLex). Consistent with this
generalized view is a more semantically motivated
sense annotation scheme: Senses of discourse rela-
tions (as opposed to just connectives) are annotated;
and the two arguments of the discourse relation are
semantically defined, allowing the sense structure
to be more general and less connective-dependent.
These framework-level generalizations can be ap-
plied to discourse annotation of other languages.
Acknowledgments
This work is supported by the IIS Division of the Na-
tional Science Foundation via Grant No. 0910532
entitled ?Richer Representations for Machine Trans-
lation?and by the CNS Division via Grant No.
0855184 entitled ?Building a community resource
for temporal inference in Chinese?. All views ex-
pressed in this paper are those of the authors and do
76
not necessarily represent the view of the National
Science Foundation.
References
Lynn Carlson, Daniel Marcu, and Mary Ellen Okurowski.
2003. Building a Discourse-Tagged Corpus in the
Framework of Rhetorical Structure Theory. In Current
Directions in Discourse and Dialogue. Kluwer Aca-
demic Publishers.
William Mann and Sandra Thompson. 1988. Rhetori-
cal structure theory. Toward a functional theory of text
organization. Text, 8(3):243?281.
Eleni Miltsakaki, Rashmi Prasad, Aravind Joshi, and
Bonnie Webber. 2004. Annotating discourse con-
nectives and their arguments. In Proceedings of the
HLT/NAACL Workshop on Frontiers in Corpus Anno-
tation, pages 9?16, Boston, MA, May.
Rashmi Prasad, Eleni Miltsakaki, Nikhil Dinesh, Alan
Lee, Aravind Joshi, Livio Robaldo, and Bonnie Web-
ber, 2007. The Penn Discourse Treebank 2.0 Annota-
tion Manual. The PDTB Research Group, December.
Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt-
sakaki, Livio Robaldo, Aravind Joshi, and Bonnie
Webber. 2008. The Penn Discourse Treebank 2.0.
In Proceedings of the 6th International Conference on
Language Resources and Evaluation (LREC 2008).
Nianwen Xue, Fei Xia, Fu dong Chiou, and Martha
Palmer. 2005. The Penn Chinese TreeBank: Phrase
Structure Annotation of a Large Corpus. Natural Lan-
guage Engineering, 11(2):207?238.
Nianwen Xue. 2005. Annotating the Discourse Con-
nectives in the Chinese Treebank. In Proceedings of
the ACL Workshop on Frontiers in Corpus Annotation,
Ann Arbor, Michigan.
77
Proceedings of the Fifth Law Workshop (LAW V), pages 161?169,
Portland, Oregon, 23-24 June 2011. c?2011 Association for Computational Linguistics
Discourse-constrained Temporal Annotation
Yuping Zhou
Brandeis University
Waltham, MA 02452
yzhou@brandeis.edu
Nianwen Xue
Brandeis University
Waltham, MA 02452
xuen@brandeis.edu
Abstract
We describe an experiment on a temporal or-
dering task in this paper. We show that by se-
lecting event pairs based on discourse struc-
ture and by modifying the pre-existent tem-
poral classification scheme to fit the data bet-
ter, we significantly improve inter-annotator
agreement, as well as broaden the coverage of
the task. We also present analysis of the cur-
rent temporal classification scheme and pro-
pose ways to improve it in future work.
1 Introduction
Event-based temporal inference is a fundamental
natural language technology aimed at determining
the temporal anchoring and relative temporal or-
dering between events in text. It supports a wide
range of natural language applications such as In-
formation Extraction (Ji, 2010), Question Answer-
ing (Harabagiu and Bejan, 2005; Harabagiu and
Bejan, 2006) and Text Summarization (Lin and
Hovy, 2001; Barzilay et al, 2002). Creating con-
sistently annotated domain-independent data suffi-
cient to train automatic systems has been the bot-
tleneck. While low-level temporal annotation tasks
such as identifying events and time expressions are
relatively straightforward and can be done with high
consistency, high-level tasks necessary to eventually
arrange events in a document in a temporal order
have proved to be much more challenging.
Among these high-level tasks, the task of annotat-
ing the temporal relation between main events stands
out as probably the most challenging. This task was
the only task in the TempEval campaigns (Verha-
gen et al, 2009; Verhagen et al, 2010) to deal with
inter-sentential temporal relations, and also the only
one to directly tackle event ordering. The idea is
that events covered in an article are scattered in dif-
ferent sentences, with some, presumably important
ones, expressed as predicates in prominent positions
of a sentence (i.e. the ?main event? of the sentence).
By relating main events from different sentences of
an article temporally, one could get something of a
chain of important events from the article.
This task, in both previously reported attempts,
one for English (Verhagen et al, 2009) and the other
for Chinese (Xue and Zhou, 2010), has the lowest
inter-annotator agreement (at 65%) among all tasks
focusing on annotating temporal relations. Verha-
gen et al (2009) attribute the difficulty, shared by all
tasks annotating temporal relations, mainly to two
factors: rampant temporal vagueness in natural lan-
guage and the fact that annotators are not allowed to
skip hard-to-classify cases.
Xue and Zhou (2010) take a closer look at this
task specifically. They report that part of the diffi-
culty comes from ?wrong? main events (in the sense
that they are not main events in the intended sense)
being selected in the preparation step. This step is a
separate task upstream of the temporal relation task.
The ?wrong? main events produced in this step be-
come part of event pairs whose temporal relation it
makes no sense to annotate, and often is hard-to-
classify. The reason ?wrong? main events get se-
lected is because the selection is based on syntactic
criteria. In fact, these syntactic criteria produce re-
sults so counter-intuitive that this seemingly simple
161
preparation task only achieves 74% inter-annotator
agreement.
Another part of the difficulty comes from me-
chanical pairing of main events for temporal relation
annotation. Simply pairing up main events from ad-
jacent sentences oversimplifies the structure within
an article and is prone to produce hard-to-classify
cases for temporal relation annotation. Both causes
point to the need for a deeper level of text analysis to
inform temporal annotation. For this, Xue and Zhou
(2010) suggest introduction of discourse structure as
annotated in the Penn Discourse Treebank (PDTB)
into temporal relation annotation.
So the previous two reports, taken together, seem
to suggest that the reason this task is especially chal-
lenging is because the difficulty associated with tem-
poral vagueness in natural language, which is shared
by all tasks dealing with temporal relation, is com-
pounded by the problem of having to annotate far-
fetched pairs that should not be annotated, which is
unique for the only task dealing with inter-sentential
temporal relations. These two problems are the foci
of our experiment done on Chinese data.
The paper is organized as follows: In Section 2,
we describe the annotation scheme; in Section 3, we
describe the annotation procedure; in Section 4 we
report and discuss the experiment results. And fi-
nally we conclude the paper.
2 Annotation Scheme
As stated in the introduction, there are two prob-
lems to be addressed in our experiment. The first
problem is that ?wrong? main events get identified
and main events that do not bear any relation are
paired up for temporal annotation. To address this
problem, we follow the suggestion by Xue and Zhou
(2010), namely using a PDTB-style discourse struc-
ture to pick out and pair up main events. We be-
lieve that adopting a discourse-constrained approach
to temporal annotation will not only improve anno-
tation consistency but also increase the Informative-
ness Value of the annotated data, under the assump-
tion that temporal relations that accord with the dis-
course structure are more valuable in conveying the
overall information of a document. Since there is no
Chinese data annotated with PDTB-style discourse
structure available, we have to develop our own. The
scheme for this step is described in Section 2.1.
The second problem is that there is too much tem-
poral vagueness in natural language with respect to
the temporal classification scheme. Since we can-
not change the way natural language works, we try
to model the classification scheme after the data it is
supposed to classify. The scheme for the temporal
annotation is covered in Sections 2.2 and 2.3.
2.1 Discourse-constrained selection of main
events and their pairs
2.1.1 Discourse annotation scheme
The PDTB adopts a lexically grounded approach
to discourse relation annotation (Prasad et al, 2008).
Based on discourse connectives like ?since?, ?and?,
and ?however?, discourse relation is treated as a
predicate taking two abstract objects (AO?s) (such
as events, states, and propositions) as arguments.
For example, in the sentence below, ?since? is the
lexical anchor of the relation between Arg1 and
Arg2 (example from Prasad et al (2007)).
(1) Since [Arg2 McDonald?s menu prices rose
this year], [Arg1 the actual decline may have
been more].
This notion is generalized to cover discourse rela-
tions that do not have a lexical anchor, i.e. im-
plicit discourse relations. For example, in the two-
sentence sequence below, although no discourse
connective is present, a discourse relation similar to
the one in (1) is present between Arg1 and Arg2 (ex-
ample from Prasad et al (2007)).
(2) [Arg1 Some have raised their cash positions to
record levels]. [Arg2 High cash positions help
buffer a fund when the market falls].
Based on this insight, we have fashioned a scheme
tailored to linguistic characteristics of Chinese text.
The linguistic characteristics of Chinese text rele-
vant to discussion here can be illustrated with the
following sentence.
(3) ??
according to reports
?
,
[AO1 ??
Dongguan
??
Customs
?
in total
??e1
accept
??
company
??
contract
??
record
?????
8400 plus
? ]
CL
?[AO2
,
?
compare
??
pilot
?
before
162
?
slight
?e2
EXIST
?? ]
increase
?
,
[AO3??
company
??e3
respond/response
?? ]
well/good
?
,
[AO4??
generally
??e4
acknowledge
?? ]
accept/acceptance
?
?According to reports, [AO1 Dongguan District
Customs acceptede1 more than 8400 records
of company contracts], [AO2 (showinge2) a
slight increase from before the pilot]. [AO3
Companies respondede3 well], [AO4 generally
acknowledginge4 acceptance].?
One feature is that it is customary to have complex
ideas packed into one sentence in Chinese. The sen-
tence above reports on how a pilot program worked
in Dongguan City. Because all that is said is about
the pilot program, it is perfectly natural to include
it all in a single sentence in Chinese. Intuitively
though, there are two different aspects of how the
pilot program worked: the number of records and
the response from the affected companies. To report
the same facts in English, it is probably more natural
to break them down into two sentences, but in Chi-
nese, not only are they merely separated by comma,
but also there is no connective relating them.
Another feature is that grammatical relation be-
tween comma-separated chunks within a sentence
is not always clear. In the above sentence, for in-
stance, although the grammatical relations between
AO1 and AO2, and between AO3 and AO4 are clear
in the English translation (i.e. the first in each pair is
the main clause and the second an adjunct), it is not
at all clear in the original. This is the result of sev-
eral characteristics of Chinese, for example, there is
no inflectional clues on the verb to indicate its gram-
matical function in the sentence.
Based on these features of Chinese text1, we have
decided to use punctuation as the main potential
indicator for discourse relations: the annotator is
asked to judge, at every instance of comma, pe-
riod, colon and semi-colon, if it is an indicator for
discourse relation; if both chunks separated by the
punctuation are projections of a predicate, then there
is a discourse relation between them. Applying this
scheme to the sentence in (3), we have four abstract
objects as marked up in the example.
1A more detailed justification for this scheme is presented in
Zhou and Xue (2011).
To determine the exact text span of each argu-
ment of a relation, we adopt the Minimality Princi-
ple formulated in Prasad et al (2007): only as many
clauses and/or sentences should be included in an ar-
gument selection as are minimally required and suf-
ficient for the interpretation of the relation. Apply-
ing this principle to the sentence in (3), we can de-
limit the three sets of discourse relations as follows:
AO1?AO2, (AO1,AO2)?(AO3,AO4), and AO3?AO4.
2.1.2 Selection and pairing-up of main events
Selection of main events is done on the level of the
simplex abstract object, with one main event per sim-
plex AO. The main event corresponds to the predi-
cate heading the simplex AO. In (3), there are four
simplex AO?s, AO1-4 ( which further form two com-
plex AO?s, (AO1,AO2) and (AO3,AO4)). The an-
chors for the four main events are the underlined
verbs labeled as ?e1-4?.
Pairing up the main events is done on the level
of discourse relation. In the case of a relation
only involving simplex AO?s, the main events of
the two AO?s pair up; in the case of a relation
involving complex AO?s, the discourse relation is
distributed among the simplex AO?s to form main
event pairs. For example, with the discourse relation
(AO1,AO2)?(AO3,AO4), four pairs of main events
are formed: e1?e3, e1?e4, e2?e3, and e2?e4. This
gets tedious fast as the number of simplex AO?s in
a complex AO increases; in this experiment, the an-
notator relies on her discretion in such cases. This
problem should be addressed in a more elegant way
in the future.
It is worth noting that in addition to picking out
right main events and event pairs for temporal anno-
tation, this scheme also broadens the coverage of the
task. In the old scheme based on syntactic criteria,
there is a stipulation: one main event per sentence.
Because the new discourse-constrained scheme is
tailored to the characteristics of Chinese text, it is
able to expose more main events (in the intended
sense) to temporal annotation.
2.2 Classification scheme for temporal relation
annotation
By modifying the six-value scheme used in Tem-
pEval (containing before, overlap, after, before-or-
overlap, overlap-or-after and vague), our classifica-
163
tion scheme has seven values in it: before, overlap,
after, not-before, not-after, groupie, and irrelevant.
2.2.1 The values ?not-before? and ?not-after?
The values ?not-before? and ?not-after? are
equivalent to ?overlap-or-after? and ?before-or-
overlap? in the TempEval scheme. The reason we
made this seemingly vacuous change is because we
found that the old values were used for two different
purposes by annotators. In addition to their intended
use, i.e. to capture indeterminacy between the two
simplex values, they were also used to label a spe-
cific case of ?overlap?. An example of such misuse
of the value ?before-or-overlap? is presented below:
(4) ????
1996
?
year
?
,
[e1 ??]
generate
?
ASP
??
first
?
CL
??
local
??
Chinese
??
judge
?
,
?
until
??
at present
?
,
?
already
?
EXIST
?
close
??
20
?
CL
??
local
??
Chinese
[e2
??]
hold the post
??
judicial
??
official
?
.
?The first local ethnic Chinese judge [e1 assumed]
the office in 1996; up until now, there have been
close to 20 ethnic Chinese locals [e2 holding] the
posts of judicial officials.?
The reason for such use is probably because it repre-
sents two alternative ways of looking at the temporal
relation between the two events : either e1 is before
the later bulk of e2 or e1 overlaps the beginning tip
of e2. To avoid such mis-uses, we made the above
change.
2.2.2 The value ?groupie?
This value is set up for two events whose tempo-
ral relation to each other is unclear, but are known to
happen within the same temporal range. For exam-
ple, the temporal relation between the events repre-
sented by the underlined verbs should be classified
as ?groupie?.
(5) ?
today
?
yesterday
?
two
?
day
?
,
??
Hong Kong
??
SAR
????
CPPCC
??
member
?
also
[e1 ??]
inspect
?
ASP
??
Ningbo
???
development district
?
,
??
Ningbo
???
Xitianxin
??
Textile
????
Ltd.
?
,
[e2 ??]
tour
?
ASP
???
Tianyi Pavilion
?
,
??
Chiang
??
ancestral home
?
.
?Yesterday and today, CPPCC members from Hong
Kong SAR also [e1 visited] Ningbo Development
District and Ningbo Xitianxin Textile Ltd., and [e2
toured] Tianyi Pavilion and the ancestral home of
Chiang Kai-shek.?
In this example, the common range shared by the
two events is expressed in the form of a time ex-
pression, ?????? (?yesterday and today?), but
it does not have to be the case. It can be in the form
of another event (e.g., ????????? (?during
the process of project construction?)), or another en-
tity with a time stamp (e.g., ?????? (?in the
Eighth Five-year Plan period?)).
It should be noted that the linguistic phenomenon
captured by this value can occur in a situation where
the internal temporal relation between two events
can be classified with another value. So ideally, this
value should be set up as a feature parallel to the
existent classification scheme. But due to technical
restrictions imposed on our experiment, we grouped
it with all the others and instructed the annotators
to use it only when none of the five more specific
values applies.
2.2.3 The value ?irrelevant?
We substituted this value for the old one ?vague?
because it is too vague. Anything that cannot fit into
the classification scheme would be labeled ?vague?,
but in fact, some cases are temporally relevant and
probably should be characterized in the classifica-
tion scheme. Case in point are those we now label
?groupie?.
This change reflects our guiding principle for de-
signing the classification scheme. If the relation be-
tween two events is temporally relevant, we should
try to characterize it in some way; if too many rela-
tions are temporally relevant but too vague to fit into
the classification scheme (comfortably), then the ad-
equacy of the scheme is questionable.
2.3 An additional specification: which event?
In addition to the classification scheme, it is also
necessary to specify which event should be con-
sidered for temporal annotation. This question has
164
never been clearly addressed, probably because it
seems self-evident: the event in question is the one
expressed by the event anchor (usually a verb). This
intuitive answer actually accounts for some too-
vague-to-classify cases. In some cases, the event
that is easily annotated (and should be the one being
annotated in our opinion) is not the event expressed
by the verb, as is the case in (6).
(6) ?
PREP
??
absorb
??
foreign business
??
invest
??
aspect
?
,
??
China
?
now
?
already
??
become
??
world
?
POSTP
??
utilize
??
foreign fund
??
most
?
DE
???
developing
???
country.
?With regard to attracting foreign business invest-
ments, China has now become the developing coun-
try that utilizes the most foreign funds in the world.?
This sentence is taken from an article summarizing
China?s economic progress during the ?Eighth Five-
Year Plan? period (from 1991 to 1995). The an-
chor for the main event of the sentence is clearly
???? (?become?), but should the event it repre-
sents, the process of China becoming the develop-
ing country that utilizes the most foreign funds, be
considered for the temporal relation annotation? It
is both counter-intuitive and impractical.
Intuitively, the sentence is a statement of the cur-
rent state with regard to attracting foreign business
investments, not of the process leading up to that
state. If we were to consider the process of ?be-
coming? in relation to other events temporally, we
would have to ask, when are the starting and ending
points of this process? How does one decide when it
is not made clear in the article? One could conceiv-
ably go as far back as to when China did not use one
cent of foreign funds. Should it be restricted to the
?Eighth Five-Year Plan? period since it is the target
period of the whole article? But why use the five-
year period, when there are more specific, syntac-
tically explicit aspectual/temporal modifiers in the
sentence, i.e. ???? (?now already?), to restrict it?
To make use of these in-sentence aspectual/temporal
modifiers, we have to go with our intuition that the
event is the current state of China with regard to uti-
lizing foreign investments, i.e. the temporal location
of the event is at present.
So the event that should be considered for tem-
poral annotation is not the one represented by the
event anchor itself, but rather the one described by
the whole clause/sentence headed by the event an-
chor. This allows all sorts of temporal clues in the
same clause/sentence to help decide the temporal lo-
cation of the event, hence makes the annotation task
easier in many cases.
3 Annotation procedure
The annotation process consists of two separate
stages, with a different annotation procedure in place
for each. The first stage involves only one annotator,
and it deals with picking out pairs of event anchors
based on the discourse relation as described in Sec-
tion 2.1. The output of this stage defines the targets
for the next stage of annotation: temporal relation
annotation. Temporal relation annotation is a two-
phase process, including double-blind annotation by
two annotators and then adjudication by a judge.
With this procedure in place, the results we re-
port in Section 4 are all from the second stage. Two
annotators go through ten weeks of training, which
includes annotating 10 files each week, submitting
them to adjudication, and then attending a training
session at the end of each week. In the training ses-
sion, the judge discusses with the annotators her ad-
judication notes from the previous week, as well as
specific questions the annotators raise.
The data set consists of 100 files taken from the
Chinese Treebank (Xue et al, 2005). The source of
these files is Xinhua newswire. The annotation is
carried out within the confines of the Brandeis An-
notation Tool (BAT)2 (Verhagen, 2010).
4 Evaluation and discussion
Table 1 reports the inter-annotator agreement of tem-
poral annotation, both between the two annotators
(A and B) and between each annotator and the judge
(J), over a training period of ten weeks. Each week,
10 files are assigned, averaging about 315 event
pairs for annotation.
Table 1 shows that annotators have taken up the
temporal annotation scheme fairly quickly, reaching
75% agreement within three weeks. After several
2http://timeml.org/site/bat-versions/bat-redesign
165
Week No. of tokens f(A, B) f(A, J) f(B, J)
1 310 0.4806
2 352 0.6278
3 308 0.7532
4 243 0.7737
5 286 0.8007 0.8601 0.8566
6 299 0.7659 0.8662 0.8896
7 296 0.7973 0.8784 0.8784
8 323 0.7988 0.8978 0.8793
9 358 0.8212 0.9106 0.8966
10 378 0.8439 0.9365 0.8995
Table 1: Inter-annotator agreement over 10 weeks of
training.
weeks of consolidation and fine-tuning, the agree-
ment slowly reaches the lower 80% towards the end
of the 10-week training period. This level of agree-
ment is a substantial improvement over the previ-
ously reported results, at 65%, for both English and
Chinese data (Verhagen et al, 2009; Xue and Zhou,
2010). This indicates that the general direction of
our experiment is on the right track.
Table 2 below is the confusion matrix based on
the annotation data from the final 4 weeks:
a b o na nb g i
a 148 3 19 0 1 0 1
b 0 344 29 1 0 0 7
o 14 10 1354 3 3 2 82
na 0 0 3 3 0 0 0
nb 0 0 1 0 1 0 0
g 2 1 9 0 0 13 1
i 3 7 67 0 0 1 572
Table 2: Confusion matrix on annotation from Weeks
7-10: a=after; b=before; o=overlap; na=not-after;
nb=not-before; g=groupie; i=irrelevant.
The matrix is fairly clean except when the value
?overlap? is concerned. This value really stands out
in more than one way. It is the most nebulous one in
the whole scheme, prone to be confused with all six
other values. In particular, it is most likely to be con-
fused with the value ?irrelevant?. It is also the most
used value among all seven values, covering roughly
half of the tokens. We will discuss this value in more
detail in Section 4.2 below.
The value ?groupie? may also seem troublesome
if we look at mis-classification as a percentage of its
total occurrences, however, it may not be as bad as it
seems. As pointed out in Section 2.2.2, despite the
fact that the linguistic phenomenon this value cap-
tures can, and does, co-occur with temporal relations
represented by other values, we had to set it up as an
opposing value to the rest due to technical restric-
tions. If/when this value is set up as a stand-alone
feature to capture the linguistic phenomenon fully,
the percentage of mis-classification should drop sig-
nificantly because the number of total occurrences
will increase dramatically.
The overall distribution of values shown in Table
2 is very skewed. At one end of the distribution
spectrum is the value ?overlap?, covering half of
the data; at the other end are the values ?not-before?
and ?not-after?, covering less than 0.3% of the token
combined. It raises the question if such a classifica-
tion scheme is well-designed to produce data useful
for machine learning.
To shed light on what is behind the numbers and
to uncover trends that numbers do not show, we also
take a closer look at the annotation data. Three is-
sues stand out.
4.1 Event anchor
In our current scheme, effort is made to pick out the
predicate from a clause as the event anchor for tem-
poral annotation. Our experiment suggests maybe
this step should be skipped since it, in practice, un-
dermines a specification of the scheme. The specifi-
cation is that the event to be considered for temporal
annotation is the one being described by the whole
clause, but the practice of displaying a mere word to
the annotator in effect instructs the annotator to con-
centrate on the word itself, rather than the clause.
Despite repeated reminder during training sessions,
the suggestive power of the display still sometimes
gets the upper hand. (7) presents such an example
concerning e1 and e2.
(7) ?
PREP
?
this
??
period
?
,
??
West Africa
??
peacekeeping
??
force
?
once
[e1 ??]
dispatch
???
fighter jet
??
bomb
??
rebel
??
position
?
,
[e2 ??]
bomb-dead
??
rebel
?
about
???
50 plus
166
??
CL
?During this period, West African Peacekeeping
Force [e1 dispatched] fighter jets and bombed rebel
positions, [e2 killing] about 50 rebel troops.?
One annotator classified the relation as ?before?, ob-
viously thinking of the event of dispatching fighter
jets as e1; had he considered the event of dispatch-
ing fighter jets and bombing the rebel positions, the
event being described by the clause, the value would
have easily been ?overlap?.
Since displaying the single-word event anchor
sometimes leads annotators astray, this step proba-
bly should be skipped. Doing so also simplifies the
annotation process.
4.2 The value ?overlap?
As pointed out above, the value ?overlap? is quite
a troubling character in the classification scheme: it
is both the most-used and probably the least well-
defined. Annotation data show that when it is con-
fused with ?after?, ?before?, ?not-after?, and ?not-
before?, it usually involves a perceptually punc-
tual event (?pp-event? henceforth) and a perceptu-
ally lasting event (?pl-event? henceforth), and the is-
sue is whether the pp-event coincides with one of the
temporal edges of the pl-event. If it does, then the
value is ?overlap?; otherwise, it is ?after?/?before?.
And on top of it is the factor of how sure one is
of the issue: if one is sure, either way, the value
is ?overlap?/?after?/?before?; otherwise, it is ?not-
after?/?not-before?. Below is an example on which
the two annotators disagree as to whether the rela-
tion between e1 and e2 should be classified as ?be-
fore? or ?overlap?.
(8) ??
in addition
?
,
??
Brazil
??
woman
???
national team
?
PREP
??
S. America
???
soccer match
?
POSTP
?
,
[e1 ??]
sweep
??
thousand-troop
?
like
?
roll
?
mat
?
,
[e2 ??]
ascend
?
ASP
??
champion
??
throne
?
.
?In addition, in the South America Cup, Brazil-
ian Women?s national team totally [e1 annihilated]
all their opponents and [e2 ascended] the throne of
champion.?
In this example, e2 is the pp-event and e1 is the pl-
event. Depending on when one thinks e2 happened,
either as soon as the last match ended or at the later
medal ceremony, (and if the former, whether there is
temporal overlap between e1 and e2), it is classified
as either ?before? or ?overlap; and if one is unsure,
it can be classified as ?not-after?.
Such cases again raise the same question as the
drastically uneven distribution of values shown in
Table 2: Does the current classification scheme slice
the temporal pie the right way? Let us make a poster
child out of ?overlap?: it seems to both impose too
stringent a condition and not make enough distinc-
tion. It imposes too stringent a condition on those
cases like (8) to which whether there is temporal
overlap seems beside the point. At the same time,
it does not make enough distinction for cases like
(4), in which an event does share one edge of an-
other event temporally: once such cases are classi-
fied as ?overlap?, the specific information regard-
ing the edge is lost. Such information could be very
useful in temporal inference. Since it is infeasible
to annotate the temporal relation between all events
in an article, temporal inference is needed to expand
the scope of temporal annotation. For example, if it
is known from annotation that e1 is before e2 and
e2 is before e3, then it can be inferred e1 is before
e3. In the case of ?overlap?, whenever it is one of
the premises, no inference can be made, but if the
?edge? information is supplied, some inferences are
possible.
To make finer-grained distinctions in the classifi-
cation scheme runs counter to the conventional wis-
dom that a coarser-grained scheme would do a bet-
ter job handling vagueness. But our experiment has
proven the conventional wisdom wrong: our seven-
value system achieved much higher agreement than
the old six-value system. So the key is not fewer, but
better, distinctions, ?better? in the sense that they
characterize the data in a more intuitive and insight-
ful way. Temporal relation in natural language is
?too? vague only when we judge it against a sys-
tem of temporal logic, in fact, we think the right
word to describe temporal relation in natural lan-
guage is ?flexible?: it is as precise as the situation
calls for. To characterize the flexibility better, for
starters, ?overlap? needs to be restructured for rea-
sons put forth above, and ?not-before? and ?not-
167
after? should be discarded since they obviously do
not carry weight.
4.3 Objective vs. subjective temporal reference
A major contributor to uncertainty and disagreement
in annotation is subjective temporal reference. Sub-
jective temporal reference is made based on the au-
thor?s perspective of the temporal axis, for example,
???? (?today?), ???? (?at present), and ????
(?past?). In this group, references with a fixed span
do not constitute a problem once the point of utter-
ance is determined (e.g. literal use of ?today?, ?this
month?); it is those with an elastic temporal span that
cause disagreement. For example, ?at present? can
have a span of a second, or several minutes, or a cou-
ple of hours, or even years depending on the context.
When an event modified with this type of tempo-
ral expression is paired with another event modified
with direct reference to a point/span on the tempo-
ral axis (i.e. with an objective reference), annotation
becomes tricky. The event pair e1-e2 in the two-
sentence sequence below is such an example.
(9) ??
past
?
,
?
PREP
??
Yangtze River
?
POSTP
?
build
??
bridge
?
be
?
CL
????
national affair
?
,
??
nowadays
??
almost
[e1
??]
become
????
common scene.
??????
1992-year,
??
Jiangsu
???
Yangzhong County
??
farmer
[e2 ??]
raise funds
??
build-finish
?
ASP
??
Yangzhong
??
Yangtze
??
Bridge
?
,
?
and
??
Hubei
?
DE
??
Chibi
??
Yangtze
??
Bridge
?
total
??
invest
???
300 million plus
?
Yuan
?
,
??
all
?
depend
??
private
??
raise funds
??
build-finish
?
.
?In the past, building a bridge on Yangtze River was
a national affair, nowadays it almost [e1becomes]
a common scene. In 1992, farmers in Yangzhong
County, Jiangsu Province [e2raised] funds and com-
pleted Yangzhong Yangtze Bridge, while Chibi
Yangtze Bridge in Hubei Province cost more than
300 million Yuan, all from private fund-raising.?
This is taken from a piece written in 1997. In the
context, it is clear that the contrast is between the
situation before the opening-up of China and the sit-
uation about 20 years later. So it is reasonable to as-
sume that the year 1992 falls inside the span of what
the author considered nowadays; at the same time, it
seems also reasonable to assume a narrow interpre-
tation of ???? (?nowadays?) that does not include
the year 1992 in the span. These two interpretations
would result in ?overlap? and ?after? respectively,
and actually did so in our experiment.
There are also extreme cases in which objective
and subjective temporal references come in direct
conflict. For example,
(10) ?
while
??
reporter
[e1 ??]
ask about
?
China
?
Russia
??
relationship
?
DE
??
status
?
and
??
cooperation
??
prospect
?
when
?
,
???
Jiang Zemin
??
President
[e2 ?]
say
?...
, ...
?When a reporter [e1 asked] about the status of
China-Russia relationship and the prospects for co-
operation, President Jiang Zemin [e2 said], ...?
The relation between e1 and e2 is before based
on objective reference, but overlap according to
the subjective reference, indicated by ??..??
(?when?). This problem should be factored in when
a new classification scheme is designed.
5 Conclusions
In this paper, we have described an experiment that
focuses on two aspects of the task of annotating
temporal relation of main events: annotation tar-
get selection and a better-fitting temporal classifica-
tion scheme. Experiment results show that selecting
main event pairs based on discourse structure and
modeling the classification scheme after the data im-
proves inter-annotator agreement dramatically. Re-
sults also show weakness of the current temporal
classification scheme. For that, we propose a re-
structuring along the lines of what this experiment
has proven working: making more intuitive and in-
sightful distinctions that characterize the data bet-
ter. This direction can be taken to improve other
high-level temporal annotation tasks that have been
plagued by the same ?vagueness? problem.
Acknowledgments
This work is supported by the National Science
Foundation via Grant No. 0855184 entitled ?Build-
ing a community resource for temporal inference
168
in Chinese?. All views expressed in this paper are
those of the authors and do not necessarily represent
the view of the National Science Foundation.
References
Regina Barzilay, Noemie Elhadad, and Kathleen McKe-
own. 2002. Inferring strategies for sentence ordering
in multidocument news summarization. Journal of Ar-
tificial Intelligence Research, 17:35?55.
Sanda Harabagiu and Cosmin Adrian Bejan. 2005.
Question Answering Based on Temporal Inference. In
Proceedings of the AAAI-2005 Workshop on Inference
for Textual Question Answering, Pittsburgh, Pennsyl-
vania.
Sanda Harabagiu and Cosmin Adrian Bejan. 2006. An
Answer Bank for Temporal Inference. In Proceedings
of LREC 2006, Genoa, Italy.
Heng Ji. 2010. Challenges from information extrac-
tion to information fusion. In Proceedings of COLING
2010, pages 507?515, Beijing, China, August.
Chin-Yew Lin and Eduard Hovy. 2001. Neats: A mul-
tidocument summarizer. In Proceedings of the Docu-
ment Understanding Workshop.
Rashmi Prasad, Eleni Miltsakaki, Nikhil Dinesh, Alan
Lee, Aravind Joshi, Livio Robaldo, and Bonnie Web-
ber, 2007. The Penn Discourse Treebank 2.0 Annota-
tion Manual. The PDTB Research Group, December.
Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt-
sakaki, Livio Robaldo, Aravind Joshi, and Bonnie
Webber. 2008. The Penn Discourse Treebank 2.0.
In Proceedings of the 6th International Conference on
Language Resources and Evaluation (LREC 2008).
Marc Verhagen, Robert Gaizauskas, Frank Schilder,
Mark Hepple, Jessica Moszkowicz, and James Puste-
jovsky. 2009. The TempEval Challenge: Identifying
Temporal Relation in Text. Language Resources and
Evaluation, 43(1):161?179.
Marc Verhagen, Roser Sauri, Tommaso Caselli, and
James Pustejovsky. 2010. Semeval-2010 task 13:
Tempeval-2. In Proceedings of the 5th International
Workshop on Semantic Evaluation, pages 57?62, Up-
psala, Sweden, July. Association for Computational
Linguistics.
Marc Verhagen. 2010. The Brandeis Annotation Tool.
In Language Resources and Evaluation Conference,
LREC 2010, pages 3638?3643, Malta.
Nianwen Xue and Yuping Zhou. 2010. Applying Syn-
tactic, Semantic and Discourse Constraints to Chinese
Temporal Annotation. In Proceedings of COLING
2010, pages 1363?1372, Beijing, China, August.
Nianwen Xue, Fei Xia, Fu dong Chiou, and Martha
Palmer. 2005. The Penn Chinese TreeBank: Phrase
Structure Annotation of a Large Corpus. Natural Lan-
guage Engineering, 11(2):207?238.
Yuping Zhou and Nianwen Xue. 2011. A PDTB-inspired
Discourse Annotation Scheme for Chinese. Submitted
to EMNLP 2011.
169
