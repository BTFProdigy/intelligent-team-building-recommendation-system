Building a Bilingual WordNet-Like Lexicon: 
the New Approach and Algorithms 
Yang Liu, Shiwen Yu, Jiangsheng Yu 
Institute of Computaitional Linguistics, Peking Unviersity 
Beijing, 100871, China 
{liuyang, yusw, yujs} @ pku.edu.cn 
 
 
Abstract 
A bilingual concept MRD is of significance for 
IE, MT, WSD and the like. However, it is 
reasonably difficult to build such a lexicon for 
there exist two ontologies, also, the evolution of 
such a lexicon is quite challenging. In this 
paper, we would like to put forth the new 
approach to building a bilingual WordNet-like 
lexicon and to dwell on some of the pivotal 
algorithms. 
A characteristic of this new approach is to 
emphasize the inheritance and transformation 
of the existent monolingual lexicon.  On the one 
hand, we have extracted all the common 
knowledge in WordNet as the semantic basis 
for further use. On the other hand, we have 
developed a visualized developing tool for the 
lexicographers to interactively operate on to 
express the bilingual semantics. The bilingual 
lexicon has thus gradually come into being in 
this natural process. 
ICL now has benefited a lot by employing 
this new approach to build CCD (Chinese 
Concept Dictionary), a bilingual WordNet-like 
lexicon, in Peking University. 
1 Introduction 
As the processing of content information has 
nowadays become the center of NLP, a 
bilingual concept MRD is of increasingly great 
significance for IE, MT, WSD and the like. And 
it is for sure that the computational linguists 
would find such a lexicon indispensable and 
useful as semantic information when facing 
ambiguities in languages in their applications. 
At the same time, Princeton University?s 
WordNet, after so many years? development, 
has exerted a profound influence on semantic 
lexicons [Vossen, 1998]. 
      When building a Chinese-English bilingual 
concept MRD, we must take the issue of 
compatibility with WordNet into account. In 
other words, for each English concept in 
WordNet, there should exist a corresponding 
Chinese concept in the bilingual lexicon and 
vice versa. Such a bilingual lexicon can offer 
better reusability and openness. 
The Institute of Computational Linguistics 
(ICL), Peking University, with this point of 
view, has launched the Project CCD (Chinese 
Concept Dictionary). 
The expectant CCD might be described as 
follows [Yu et al 2001]: it should carry the 
main relations already defined in WordNet with 
more or less updates to reflect the reality of 
contemporary Chinese, and it should be a 
bilingual concept lexicon with the parallel 
Chinese-English concepts to be simultaneously 
included. 
      Such a bilingual WordNet-like lexicon of 
Chinese-English concepts can largely meet our 
need of applications. 
However, it is by no means easy to build 
such a lexicon. It is quite obvious that there 
synchronously exist two ontologies in the same 
lexicon. One is in the English culture and the 
other is in the Chinese culture. As there might 
be different concepts and relations in each 
language, the mapping of the relevant concepts 
in different languages is inevitable. Also, the 
evolution of such a lexicon with passing of 
time, an issue linked closely to the mapping 
issue, is quite challenging. 
In conclusion, it?s a quite demanding job to 
build such a lexicon, especially for the design of 
the approach and the realization of the 
developing tool. Any fruitful solution should 
give enough consideration to the complexity of 
these issues. 
2 The New Approach to Building a Bilingual 
WordNet-Like Lexicon 
The distinct principles of organization of 
WordNet can be described below: concepts, 
viz. synsets, act as the basic units of lexical 
semantics, and the hyponymy of the concepts 
acts as the basic relation among others. Upon 
this tree structure of hyponymy, there also exist 
some other semantic relations like holonymy, 
antonymy, attribute, entailment, cause, etc., 
which further interweave all the concepts in the 
lexicon into a huge semantic network, say 
99,643 synset nodes all told in WordNet 1.6. 
      What really counts and takes a lot of trouble 
in building WordNet itself is how to set up all 
these synsets and relations properly, and, how 
to maintain the semantic consistencies in case 
of frequent occurrences of modifications during 
the revision [Beckwith et al 1993]. As the 
desirable developing tool based directly on a 
large-scale network has not yet appeared, due to 
the connatural complexity of net structure, this 
problem is all the way a Gordian knot for the 
lexicographers. 
      To build a Chinese WordNet in the same 
route just as Princeton had taken and then to 
construct the mapping between these two 
WordNets may be not a satisfying idea. 
So, it is crucial that we had better find an 
approach to reusing the English common 
knowledge already described in WordNet as the 
semantic basis for Chinese when building the 
bilingual lexicon. And this kind of reusing 
should contain some capabilities of adjustments 
to the bilingual concepts besides word-for-word 
translations. If we can manage it, not only the 
building of the monolingual Chinese lexicon 
benefits but also the mapping between 
Chinese-English [Liu et al 2002]. Actually, the 
practice of mapping has now become a direct 
and dynamic process and the evolution of the 
bilingual lexicon is no longer a problem. A 
comparatively high efficiency may be achieved. 
Such are the essential ideas of the new 
solution.  A characteristic of this approach is to 
emphasize the inheritance and transformation 
of the already existent monolingual lexicon.  
Accordingly, it deals with 2 processes. The 
first process simply gets the semantic basis for 
further use and the lexicographers? work always 
focuses on the second. In fact, the bilingual 
lexicon has just gradually come into being in 
this more natural process. 
2.1 The Inheritance Process of WordNet 
This process is intended to extract the common 
hyponymy information in WordNet as the 
semantic basis for future use. 
      However, to extract the full hyponyms for a 
certain concept is by no means easy. As we 
have examined, the number of hyponyms for a 
synset ranges from 0 to 499 with a maximal 
hyponymy depth of 15 levels in WordNet. This 
shows the structure of the potential hyponymy 
tree is quite unbalanced. Due to this high 
complexity, the ordinary searching algorithm 
can hardly do. If one inputs the word entity as 
entry in WordNet 1.6 and tries to search its full 
hyponyms, he will get nothing but a note of 
failure. Sure enough, if the entry is not entity 
but another word, say entrance, the searching 
will probably do. The cases actually depend on 
the location of the entry word in the potential 
hyponymy tree in WordNet. The higher the 
level of the entry word, the less possibility of 
success the searching will have. 
      By now, we have got a refined searching 
algorithm for getting the full hyponymy 
information in WordNet [Liu et al 2002]. 
By and large, it involves a series of Two 
Way Scanning action and of Gathering/Sieving 
and Encoding action, with each round of the 
series intending to get information of nodes on 
one same level in the hyponymy tree. 
      By this special algorithm, the complexity of 
searching is greatly reduced. We can even get 
all the 45,148 hyponyms for the topmost entry 
word entity, in 100 or so seconds, on an 
ordinary PC. People who are interested in it can 
find more details about the algorithm in [Liu et 
al, 2002]. 
2.2 The Transformation Process of WordNet 
This process is for the lexicographers to 
interactively operate on the hyponymy tree to 
express the bilingual semantics. The bilingual 
lexicon will gradually come into being in this 
process. 
      For this task, we have designed and realized 
a visualized and data-sensitive tree control with 
8 well-defined operations on it, some of the 
pivotal algorithms for which will be discussed 
later. 
      After extracting the hyponymy information 
for each initial semantic unit in WordNet 
respectively, we then organize the information 
into a hyponymy tree by using the above tree 
control. Every tree node, viz. synset, still carries 
all other semantic relations already described in 
WordNet. The lexicographers can now operate 
on the tree interactively. 
The actual practices of the lexicographers 
are as follows: 
      (i) For each tree node in English, if there 
exists a corresponding Chinese concept, the 
lexicographers simply translate the English 
concept into Chinese. 
      (ii) If there does not, cases may be that the 
English concept is either too general or too 
specific for Chinese. 
      (ii1) For the former case, the lexicographers 
can create new hyponyms in Chinese for the 
English concept and link all these new 
hyponyms in Chinese with the English concept. 
(ii2) For the latter case, the lexicographers 
just delete the English concept in a special way, 
which means the English concept has no 
equivalent in Chinese and only links the 
English concept with its hypernym. 
In fact, all the above-mentioned semantic 
manipulations concerning hyponymy relation  
have already been encoded into the 8 visualized 
operations on the hyponymy tree. In addition, in 
the 8 operations, some other semantic relations 
already described in the synsets in WordNet are 
all properly dealt with through systematic and 
reasonable calculations. 
      We can see these adjustments clearly in the 
description of the algorithms. 
      Now, it is of much significance that the 
lexicographers need simply operate on the 
hyponymy tree to express their semantic 
intention and no longer care for lots of details 
about the background database, for the 
foreground operations have already fulfilled all 
the automatic modifications of the database. 
      In this way, the problems of mapping 
between the bilingual concepts and evolution of 
the bilingual lexicon are dynamically resolved. 
Our developing tool for building the 
bilingual WordNet-like lexicon has come out as 
below. 
 
 
 
 
 
 
 
 
 
 
 
The interface view shows the hyponymy 
tree for the entry food, which is one of the 25 
initial semantic units of noun in WordNet with 
the category value of 13. For the currently 
chosen node, the lexicographers can further 
adopt a proper operation on it when needed. 
This new kind of Visualized Auxiliary 
Construction of Lexicon is characteristic of the 
inheritance and transformation of the existent 
monolingual lexicon.  We call it Vacol model 
for short. 
      As we see, the new approach, in fact, is 
independent of any specific languages and 
actually offers a general solution for building a 
bilingual WordNet-like lexicon. 
3 Tree Operations and their Algorithms 
As the lexicographers always work on the tool, 
the visualized, data-sensitive tree control with 
operations on it is the key to the new approach. 
By now, we?ve schemed a set of algorithms 
based on the Treeview control in the Microsoft 
Visual Studio 6.0 and eventually implemented a 
data-sensitive tree control with operations on it. 
3.1 Tree Operations 
The 8 operations that we have semantically well 
defined are listed as follows. When choosing a 
synset node in the hyponymy tree, these are the 
operations from which the lexicographers can 
further adopt one. 
 
      [1] To add a synset as brother node; 
      [2] To add a synset as child node; 
      [3] To delete the synset node (not including 
its descendants if exist); 
[4] To delete the synset node (including all 
its descendants if exist); 
      [5] To cut the subtree; 
      [6] To copy the subtree; 
      [7] To paste the subtree as brother node; 
[8] To paste the subtree as child node. 
 
      These operations are all to edit the tree, with 
respectively No. 1, 2 for addition, No. 3, 4 for 
deletion, and No. 5, 6, 7, 8 for batch movement. 
      In fact, all these operations have been 
carefully decided on to make them concise 
enough, capable enough and semantically 
meaningful enough. 
      It is easy to prove that any facultative tree 
form can be attained by iterative practices of 
these 8 operations. 
3.2 Algorithms for the Tree Operations 
The data structure of a hyponymy tree with n 
nodes can be illustrated by the following table: 
 
Pos1 Ptr11 Ptr12 ? Ptr1m BasicInfo1 
Pos2 Ptr21 Ptr22 ? Ptr2m BasicInfo2 
? ? ? ? ? ? 
Posn Ptrn1 Ptrn2 ? Ptrnm BasicInfon 
 
      There are 3 parts of information in each 
record: the structural information {Posi}, the 
relation information {Ptri1 (viz. hyponymy), 
Ptri2, ? , Ptrim} and all other pieces of basic 
information {BasicInfoi} which are relevant 
only to the concept proper. 
      Among these 3 parts of information, {Posi} 
is used for the tree structure whereas both {Ptri1, 
Ptri2, ? , Ptrim} and {BasicInfoi} for lexical 
semantics. It should be noticed that Posi only 
stands for a special encoding for the tree in the 
foreground and is somewhat different from 
Ptri1, a relational pointer of hyponymy, which 
represents its specific semantics in the 
background database. And it is the relations in 
{Ptri2, ? , Ptrim} that have highly contributed to 
the dense net structure of WordNet. 
      After these analyses, we find that each 
operation should just properly deal with these 3 
parts of information. First, it is crucial that two 
sorts of consistencies should be maintained. 
One is that of the structural information {Posi} 
of the tree and the other is that of the relation 
information {Ptri1, Ptri2, ? , Ptrim} of the 
lexicon. Following that, the cases of the basic 
information {BasicInfoi} are comparatively 
simple for only English-Chinese translations 
are involved. 
      Before we can go on to dwell on the 
algorithms, we still need a little while to touch 
on the structural information {Posi}. When we 
say a position Posi, we actually mean the 
location of a certain node in the tree and it 
serves to organize the tree. For example, a Posi 
by the value ?005001002? is to represent such a 
location of a node in a tree: at the 1st level, its 
ancestor being the 5th; at the 2nd level, its 
ancestor being the 1st; and at the 3rd level, its 
ancestor viz. itself now being the 2nd. In fact, 
such an encoding onto a linear string does fully 
express the structural information in a tree and 
makes all the tree operations algorithms 
feasible by direct and systematic calculations of 
the new position. 
      If we don?t want to badger with much of the 
details, the algorithms for tree operations can be 
described in a general way. Although for each 
line of the pseudocode, there indeed are lots of 
jobs to do for the programmer. 
The algorithms described below are suitable 
for the non-batch-movement operations, viz. 
operations [1, 2, 3, 4]. And the batch-movement 
operations, viz. operations [5, 6, 7, 8], can be 
regarded as their iterative practices. 
 
The lexicographers trigger an action on nodei; 
IF the action is in operations [1, 2, 3, 4] 
    CASE the action 
       Operations [1]: 
           Add a node with its Pos = NewBrother (Posi); 
       Operations [2]: 
           Add a node with its Pos = NewChild (Posi); 
       Operations [3]: 
           Delete the node with Pos = Posi; 
       Operations [4]: 
    Delete all the nodes with their Pos satisfying 
conditions of being descendants of nodei; 
    END CASE 
    Recalculate Pos of the rest nodes in the table 
according to the operation and current Posi; 
    Replace all relevant Ptrj1, Ptrj2 , ? , Ptrjm with new 
ones according to the operation and current nodei; 
    Refresh the tree; 
ELSE IF 
The lexicographers translate current BasicInfoi from 
English to Chinese; 
END IF 
 
      The algorithms have some nice features. 
      Since the structural information {Pos}, 
defined as the primary key of the table, is kept 
in order, the maintenance of tree structure can 
always be completed in a single pass. 
      The maintenance of consistencies of the 
relation information {Ptrj1, Ptrj2, ? , Ptrjm} in 
the lexicon is also limited to a local section of 
the table. 
4 Conclusions 
ICL, Peking University has launched the 
Project CCD since Sept., 2000. Due to the nice 
features of the new approach, we do have 
benefited a lot by employing it to build CCD. 
By now, we have fulfilled more than 32,000 
Chinese-English concept pairs in noun. 
      In the near future, ICL wants to come to a 
total amount of 100,000 or so bilingual 
concepts, which might largely meet our need of 
applications. 
What is more, as the byproducts of the new 
approach and experiences, we have even found 
some errors and faults of semantic expressing 
with WordNet 1.6. 
For example, in the lexicon there are many 
occurrences of a node with multiple-father in 
the identical category (772 times in noun, e.g. 
{radish}) or a node with single-father in the 
other category (2,172 times in noun, e.g. 
{prayer_wheel}). 
In verb, there even exists a node with father 
being oneself (e.g. {reserve, hold, book}). 
      These phenomena are quite abnormal and 
puzzling according to the specification of 
WordNet.  Something may have gone wrong 
with the classification or implementation. 
      There are also many undisciplined locations 
of relational pointers (e.g. ?@? and ?~?, 
respectively 7 and 451 times in noun) in DAT 
files and some other problems. 
Acknowledgements 
This work is a component of researches on 
Chinese Information Extraction funded by 
National Foundation of Natural Science No. 
69973005 and Project 985 in Peking Univ. 
We are especially grateful to Prof. WANG 
Fengxin and Prof. LU Chuan, our linguistics 
advisors, for their unforgettable discussion and 
support. Many thanks go to the fellows who 
have participated in and collaborated on the 
work, among whom we would like to mention 
Mr. ZHANG Huarui, Ms. SONG Chunyan, Dr. 
LI Zuowen, Ms. ZAN Hongying and others. 
Thanks also to the participants to the 1st Global 
WordNet Conference 2002, Mysore, India, for 
their valuable advice and comment. 
References 
Beckwith, R., Miller, G. A. and Tengi, R. (1993) 
Design and Implementation of the WordNet Lexical 
Database and Searching Software. Description of 
WordNet. 
 
Carpuat, M. and Ngai, G. et al (2002) Creating a 
Bilingual Ontology: A Corpus-Based Approach for 
Aligning WordNet and HowNet. GWC2002, India, 
pp 284-292. 
 
Chang, J. S. and You, G. N. et al (2002) Building a 
Bilingual Wordnet and Semantic Concordance from 
Corpus and MRD. WCLS2002, Taipei, China, pp 
209-224. 
 
Cook, G. and Barbara, S. (1995) Principles & 
Practice in Applied Linguistics. Oxford: Oxford 
University Press. 
 
Fellbaum, C. (1993) English Verbs as a Semantic 
Net. Description of WordNet. 
 
Fellbaum, C. (1999) WordNet: an Electronic Lexical 
Database. Cambridge, Mass.: MIT Press. 
 
Kamps, J. (2002) Visualizing WordNet Structure. 
GWC2002, India, pp 182-186. 
 
Keil, F. C. (1979) Smantic and Conceptual 
Development: an Ontological Perspective. 
Cambridge, Mass.: Harvard University Press. 
 
Liu, Y., Yu, J. S., Yu, S. W. (2002)  A Tree-Structure 
Solution for the Development of ChineseNet. 
GWC2002, India, pp 51-56. 
 
Miller, G. A. (1993) Noun in WordNet: a Lexical 
Inheritance System. Description of WordNet. 
 
Miller, G. A. et al (1993) Introduction to WordNet: 
An On-line Lexical Database. Description of 
WordNet. 
 
Pavelek, P., Pala, K. (2002) VisDic ? a New Tool for 
WordNet Editing. GWC2002, India, pp 192-195. 
 
Touretzky, D. S. (1986) The Mathematics of 
Inheritance Systems. Los Altos, Calif.: Morgan 
Kaufmann. 
 
Vossen, P. (1998) EuroWordNet: a Multilingual 
Database with Lexical Semantic Networks. 
Dordrecht: Kluwer. 
 
Wong, S. H. S. and Pala, K. (2002) Chinese 
Characters and Top Ontology in EuroWordNet. 
GWC2002, India, pp 122-133. 
 
Yu, J. S. (2002) Evolution of WordNet-Like Lexicon. 
GWC2002, India, pp 134-142. 
 
Yu, J. S. and Yu, S. W. et al (2001) Introduction to 
CCD. ICCC2001, Singapore, pp 361-366. 
News-Oriented Automatic Chinese Keyword Indexing 
Li Sujian1 
lisujian@pku.
edu.cn 
Wang Houfeng1 
wanghf@pku.edu.
cn 
Yu Shiwen1 
Yusw@pku.edu.
cn 
Xin Chengsheng2 
csxin@peoplemail.
com.cn 
1Institute of Computational Linguistics, Peking University, 100871 
2The Information Center of PEOPLE?S DAILY, 100733 
 
 
Abstract 
In our information era, keywords are very 
useful to information retrieval, text clus-
tering and so on.  News is always a do-
main attracting a large amount of 
attention.  However, the majority of news 
articles come without keywords, and in-
dexing them manually costs highly.  Aim-
ing at news articles? characteristics and 
the resources available, this paper intro-
duces a simple procedure to index key-
words based on the scoring system.  In the 
process of indexing, we make use of some 
relatively mature linguistic techniques and 
tools to filter those meaningless candidate 
items.  Furthermore, according to the hi-
erarchical relations of content words, 
keywords are not restricted to extracting 
from text. These methods have improved 
our system a lot.  At last experimental re-
sults are given and analyzed, showing that 
the quality of extracted keywords are sat-
isfying. 
1 Introduction 
With more and more information flowing into our 
life, it is very important to lead people to gain 
more important information in time as short as 
possible.  Keywords are a good solution, which 
give a brief summary of a document?s content.  
With keywords, people can quickly find what they 
are most interested in and read them carefully.  
That will save us a lot of time.  In addition, key-
words are also useful to the research of information 
retrieval, text clustering, and topic search [Frank 
1999].  Manually indexing keywords will cost 
highly.  Thus, automatically indexing keywords 
from text is of great interests. 
News is always the main domain that people 
pay a large amount of attention to.  Unfortunately, 
only a small fraction of documents in this field 
have keywords.  However, compared to unre-
stricted text, news articles are relatively easy to 
extract keywords from, because they have the fol-
lowing characteristics.  Firstly, a news document is 
always short in length, and usually, only important 
words or phrases repeat.  Secondly, as a rule, the 
purpose of news articles is to illustrate an event or 
a thing for readers.  Then this kind of articles usu-
ally place more emphasis on some name entities 
such as persons, places, organizations and so on.  
Lastly, important content often occurs the first time 
in the title, or in the anterior part of the whole text, 
especially the first paragraph or the first sentence 
in every paragraph.  These characteristics will help 
us in keywords indexing. 
Several methods have been proposed for ex-
tracting English keywords from text.  For example, 
Witten[1999] adopted Na?ve Bayes techniques, and 
Turney[1999] combined decision trees and genetic 
algorithm in his system.  These systems achieved 
satisfying results. However, they need a large 
amount of training documents with keywords, 
which are just what we are in need of now.  For the 
Chinese language, some researchers adopt the 
structure of PAT tree and make use of mutual in-
formation to obtain keywords [Chien 1997, Yang 
2002].  Unfortunately, the construction of PAT tree 
will cost a lot of space and time.  In this paper, 
aiming at the characteristics of news-oriented arti-
cles, resources and techniques of current situation, 
we will introduce a simple procedure to index 
keywords from text. Section 2 will describe the 
architecture of the whole system.  In section 3, we 
will introduce every module in detail, including 
how to obtain candidate keywords, how to filter 
out the meaningless items, and how to score possi-
ble keyword candidates according to their feature 
values.  In section 4, experimental results will be 
given and analyzed.  At last, we will end with the 
conclusion. 
2 
3 
3.1 
System Overview 
Keyword indexing can also be called keyword ex-
traction.  The definition of a keyword is not re-
stricted to one word in our conception.  Here, a 
keyword can be seen as a Chinese character string, 
which might consist of more than one Chinese 
word.  These character strings can summarize the 
content of the document they are in. 
Aiming at the task of keywords indexing, our 
system is designed and composed of three modules.  
As in figure 1, the first module is to recognize 
some Chinese character strings according to their 
frequency, and pick out those named entities in the 
text as the candidate keywords.  The second mod-
ule is a filter to remove all the meaningless charac-
ter strings from the set of candidates. And the third 
module is a selector, which evaluates every candi-
date according to its feature values and choose 
from the candidate set those keywords with higher 
score.  The higher score a character string has, the 
more content it will cover of the article it is in. 
 In our system, there are three kinds of lexicons. 
The lexicon of proper nouns is used to recognize 
named entities.  The general lexicon includes Chi-
nese words in common use, which is adopted for 
the segmentation and POS tagging of the text.  And 
the lexicon of content words is used to expand the 
set of keywords.  They will be introduced in detail 
in the following section. 
System Design 
Recognizer Module 
Character strings Recognizer
Selector
Filter
Segmentation
filter
Keywords
expansion
Feature
computation
Chinese character
strings
POS tagging
filter
Filter of items with
punctuations and
function words
Filter of overlapped
and dependent items
Recognizer through
Frequency Statistics
Named Entities
Recognizer
Original text
Candidate items with
feature values
Fig.1. System Architecture
keywords
Proper Nouns
Lexicon
Content Words
Lexicon
General
Lexicon
It can be seen that one document is composed of a 
set of character strings.  Every character string has 
its frequency in the document.  In general, those 
character strings that occur several times can re-
flect the topic of the document.  So, we take them 
out as keyword candidates. In addition, named en-
tities, such as person names, place names, organi-
zations, translation terms, titles of person and so on, 
are usually very important for the document with-
out reference to their frequency.  They will also be 
picked out from the text by named entities recog-
nizer and input into the filter module with other 
character strings.  
Unlike English, there are no explicit word 
boundaries in Chinese sentences, which makes it 
especially difficult to tell whether a character 
string is composed of one word or more than one 
word.  Due to this characteristic, we don?t use a 
dictionary, but get those character strings only ac-
cording to their frequency statistics.  We set a 
threshold value as 2 for the Chinese character 
strings considering the length of news documents.  
Suppose that a character string is c1c2?cn, and 
f(c1c2?cn) represents its frequency, then we ex-
tract c1c2?cn from text only if f(c1c2?cn) equals to 
or is more than 2.  That is, only a character string 
occurs two or more than two times, it can be se-
lected as a candidate keyword. 
There are two kinds of named entities.  The first 
are those which have rules of composition, mainly 
Chinese names and foreign terms.  They can be 
recognized with statistical and rule-based methods 
combined.  Chinese names are composed of family 
names and first names, whose lengths are respec-
tively 1 or 2 Chinese characters.  Furthermore, 
there is a relatively stable set of family names, 
which often provide the anchor to search a name. 
For foreign terms, there are a relatively set of Chi-
nese characters which are generally used as 
translation characters.  Due to the limitation of the 
paper?s length, we don?t introduce the process of 
recognition in detail here.  The other kind of 
named entities is mainly composed of proper 
nouns which represent names of places, organiza-
tions, person titles, etc.  They often occur in news 
documents, but don?t have rules of composition.  
Thus, we collect such words into our proper nouns 
lexicon.  Then the module can find these named 
entities through looking up in this lexicon. 
3.2 Filter Module 
So far, Chinese character strings are generated only 
through frequency statistics. Thus, some of them 
stand out just because of simple repetition and are 
probably not meaningful units of language.  We 
need to filter out those meaningless items.  As in 
figure 1, we adopt four kinds of filters in filter 
module. They work as follows. 
(1) Filter of Overlapped and Dependent Items  
 
evident that such character strings can?t serve as 
For two character strings S1 and S2, with S1 as a 
substring of S2, and the frequency of S1 is equal to 
that of S2, then S1 is overlapped by S2. In fact, we 
can set a threshold td for f(S1)-f(S2), where the 
function f(.) represents the frequency of some 
character string. If the value of f(S1)-f(S2) is less 
than td, then the string S1 is dependent on S2.  
Here, the overlapped and dependent substring will 
be removed from the candidate set. 
(2) Filter of Items with Punctuations and Func-
tion words 
The recognizer module treats equally all symbols 
in the text, such as Chinese characters and 
punctuations, etc. Thus when conducting the 
process of frequency statistics, for a character 
string, there might exist some punctuations and 
function words such as ???, ???, ???, ???, etc. 
These punctuations and function words usually 
occur in the head or tail of a character string.  It?s 
character strings can?t serve as keywords of an ar-
ticle, and they should be deleted from the candi-
date set. 
(3) Segmentation Filter 
We find the first occurrence position of every can-
didate keyword and get the sentence at the position.  
Then the sentence is segmented.  According to the 
segmented result, we can verify whether the char-
acter string is meaningful.  First of all, we get the 
segmentation result of the character string in the 
segmented sentence.  Suppose the character string 
ci?cj in the original text with the sentence 
c1c2?ci-1ci?cjcj+1?cn as its context, if the 
segmentation tool segments ci-1ci or cjcj+1 into one 
word, then ci?cj will not be regarded as an inte-
grated unit.  That is, this item will be seen as 
meaningless and filtered out from the set of candi-
date keywords.  Here we don?t adopt the method of 
conducting frequency statistics of words after seg-
mentation, but use segmentation tool after fre-
quency statistics of character strings.  There are 
some reasons. Above all, although the segmenta-
tion technique is relatively mature, its precision is 
still not high enough.  Then, for the same character 
string, its segmentation results often differ in dif-
ferent sentences.  Thus, it?s difficult to compute the 
frequency of a character string precisely.  Further-
more, now we only need to segment one sentence 
for a candidate keyword.  That will save us a great 
deal of time. 
(4) POS Filter 
Because keywords provide a brief summary for 
one document, they should be words or phrases 
that represent some meaning units such as nouns 
and noun phrases.  Therefore, a single word whose 
part of speech is preposition, adverb, adjective, or 
conjunctive is filtered out.  At the same time, verb 
phrases, adjective phrases, preposition phrases are 
also excluded from the candidate set.  The same as 
segmentation filter, we only do the POS tagging 
for the sentence where every candidate keyword 
occurs the first time.  If a candidate item is made of 
more than one word, it will have a sequence of 
POS tags according to which we can assign a 
phrase category.  The POS tags or phrase catego-
ries are the basis for POS filtering. 
Only conducting frequency statistics of charac-
ter strings can?t refine the candidate set well, and 
we utilize the relatively mature linguistic segmen-
tation and POS tagging techniques so that we can 
further improve the quality of the candidate key-
words.  Here, the general lexicon with about 
60,000 Chinese words is applied to the processes 
of segmentation and POS tagging. 
3.3 Selector Module 
After several filtering, now we can get a reduced 
set of candidate keywords.  Most character strings 
in the set are meaningful and reflect the content of 
the document to some extent.  For every candidate 
now, we adopt several features to describe it. The 
features include frequency, length, position of the 
first occurrence, part of speech and whether it is a 
proper noun or in a pair of specific punctuations, as 
in table 1.  At the same time, through the process-
ing of several linguistic tools in filter module, we 
can assign a value to every feature in every candi-
date item.   
feature meaning of feature 
freq Frequency of an item 
len Length of an item 
is_noun Whether an item is a noun phrase 
in_title Whether the first occurrence of an item is in the title of one document 
in_seg1 
Whether the first occurrence of an 
item is in the first paragraph of one 
document 
is_proper 
Whether an item is a proper noun, 
for example: person name, organi-
zation, translation term, place 
name, title of a person etc. 
in_sign 
Whether an item is bracketed by a 
pair of specific punctuations such 
as ???? and ????. 
Table 1. Features of candidate keywords 
We can find that the candidate set is still too 
large to select from it the keywords.  Then we will 
conduct feature calculation to refine the candidate 
set.  We have known that every candidate item has 
a feature-value set.  These feature values are our 
basis to evaluate every candidate item.  We com-
pute a score for every candidate keyword through 
the module of feature computation.  The higher the 
score, the more relevant the candidate is to the 
document. 
We compute the percentage how much manually 
indexed keywords of different lengths cover in the 
set of automatically generated candidates.  As in 
figure 2, Length represents the length of keywords 
and percentage denotes the corresponding percent-
age that keywords of this length are in the set.  The 
higher the percentage, the more likely the key-
words of this length are to be selected.  Therefore, 
we can make a conclusion that the score of a can-
didate is directly proportional to the percentage of 
its length.  Then we can acquire the relation be-
tween score and length of a candidate.  At the same 
time, we can also see that the score is directly 
proportional to a candidate?s frequency.  In 
addition, score is relevant to other features in table 
1.  Thus, we get formula 1, as following. 
 
Fig. 2. Relations between Percentage Selected 
and Length of Keywords 
??
???=
???= ??
otherwise0
feature i  thesatisfiesck  if1)(
)1.7)((
100ln)()(
th
)(
Ffi
2
ckf
fw
cklen
ckFreqckscore
i
cki
i
 (1) 
Where ck represents a candidate keyword, the 
function freq(ck) gets the frequency of ck, len(ck) 
represents its length, that is, the number of Chinese 
characters every item includes. F represents all the 
binary features of a candidate keyword as in table 
1. Every feature except the features of freq and len 
are denoted by fi.  fi(ck) is a binary function and its 
value is 0 or 1.  If a candidate item ck satisfies the 
ith feature, then the value is set to 1, otherwise, it?s 
set to 0.  wi is the corresponding weight of feature 
fi.  For features is_noun, in_title, in_seg1, 
is_proper and in_sign, we set their weights to 7, 13, 
5, 11 and 3 respectively by experience.  After each 
candidate keyword gets a score, we choose those 
whose scores rank higher as keywords.   
??
(physical
training)
????
(physical
management)
????
(sports)
??(track
and field)
??
(ball) ...
...
???
(pingpang)
???
(badminton)
??
(football) ...
Fig.3. A Sample Tree Structure of Content Words
 
Now the keywords we get are all selected from 
the original text.  However, some keywords may 
express the content of the document, but they don?t 
occur in the text.  Therefore, we have constructed 
one list of content words with hierarchical relations 
as in figure 3.  That is content words lexicon.  The 
lexicon contains about 1,200 words which are of-
ten used as keywords.  As the content words lexi-
con available now, we can look up in it and expand 
obtained keywords to a higher level, i.e., if a se-
lected keyword has a parent in the lexicon, the par-
ent word will be expanded as a keyword. 
4 Experimental Results and Analysis 
We select 37 news articles from China Daily as our 
testing material from which experts have manually 
extracted keywords.  There are 23 articles about 
national politics, 10 articles of international poli-
tics, and 4 sports news articles.  Here, we auto-
matically extracted keywords from them and 
evaluated the results with the standard measures of 
precision and recall, which are defined as follows: 
Where P represents precision, and R represents 
recall. In general, these two measures in one sys-
tem are opposite to each other.  When precision is 
higher, recall will be lower. Otherwise, when pre-
cision is improved, recall will decrease.  In table 2, 
we illustrate our experimental results.  The first 
three rows give measures for articles about differ-
ent styles and the figures in parentheses represent 
the number of articles.  The fourth row gives the 
average measure of our system.  For comparison, 
we also illustrate the results of Chien?s [1997] 
PAT-tree-based method from his experiments in 
the last row.  From this table, we can see that more 
emphasis is placed on precision in Chien?s system.  
However, we incline to enhancing recall when pre-
cision and recall are assured relatively balanced.  
When precision is lower, perhaps more noise is 
introduced into the set of candidate keywords.  Be-
cause we have adopted segmentation and POS tag-
ging tools which can verify whether a candidate 
character string is a meaningful unit and found that 
the noise introduced now is more or less relevant 
to the content of the article, we don?t have to worry 
more about precision.    Therefore, we hope to 
generate more keywords automatically under the 
condition that the number of noise words is ac-
cepted. 
 
 Recall Precision
National politics (23) 0.452 0.401 
International Politics (10) 0.644 0.594 
Sports news (4) 0.629 0.482 
Average 0.523 0.462 
Chien?s (exact match) 0.30 0.43 
Table 2. Experimental Results 
It has to be pointed out that there are no satis-
factory results in extracting keywords from texts 
[Chien, 1997].  Although some keywords extracted 
are the same as manually extracted ones in mean-
ing, they are often different due to one or two 
characters mismatched.  According to our analysis 
of experimental results, though only 46% of ex-
tracted keywords appear in the set of manual key-
words, the rest are also relevant to the text and 
adapt to the need of information retrieval.  At the 
same time, about 52% of the manual keywords are 
generated by the automatically indexing method, 
however, we can often find a substitute for most of 
the rest in the set of automatically generated key-
words.   
manually indexing keywords ofnumber 
recognized  keywords genuine ofnumber R
llyautomatica indexing keywords ofnumber 
recognized  keywords genuine ofnumber P
=
=
Most of the keywords missed occur only once 
in the text, but they are mostly proper nouns of 
places, organizations or titles of person.  And this 
reveals that we need to further improve the tech-
niques to recognize proper nouns. 
5 Conclusion and Future Work 
We have described a system for automatically in-
dexing keywords from texts.  One document is in-
putted into the recognizer module, the filter 
module and the selector module consecutively, 
with keywords output.  Here we utilize the mature 
techniques available now such as string frequency 
statistics, segmentation and POS tagging tools.  
Then, according to features, we propose our 
method to evaluate directly every candidate key-
word and select those with higher scores as key-
words.  At the same time, we break through the 
tradition of generating keywords only from the 
original text and acquire some keywords through 
looking up in the lexicon of content words with 
hierarchical relations. The experimental results 
show that our system can perform comparably to 
the state of the art. 
Owing to the limit of the training corpus, the 
parameters in scoring formula are set by experi-
ence values.  With our method, we can cumulate 
more and more documents with keywords.  Then 
we can adopt machine-learning methods to conduct 
keyword indexing, which can make parameters 
more objective.  That will be our further work. 
References 
[Chien 1997] Chien, L. F., PAT-Tree-Based Keyword 
Extraction for Chinese Information Retrieval, Pro-
ceedings of the ACM SIGIR International Confer-
ence on Information Retrieval, 1997, pp. 50--59.  
[Frank 1999] Frank E., Paynter G.W., Witten I.H., Gut-
win C., and Nevill-Manning C.G., Domain-specific 
keyphrase extraction, Proc. Sixteenth International 
Joint Conference on Artificial Intelligence, Morgan 
Kaufmann Publishers, San Francisco, CA, 1999, pp. 
668-673. 
[Lai 2002] Yu-Sheng Lai, Chung-Hsien Wu, Meaning-
ful term extraction and discriminative term selection 
in text categorization via unknown-word methodol-
ogy, ACM Transactions on Asian Language Informa-
tion Processing (TALIP), Vol.1, No.1, March 2002, 
pp. 34-64. 
[Liu 1998] Liu Ting, Wu Yan, Wang Kaizhu, An Chi-
nese Word Automatic Segmentation System Based 
on String Frequency Statistics Combined with Word 
Matching, Journal of Chinese Information Processing, 
Vol.12, No.1, 1998, pp. 17-25. 
[Ong 1999] T. Ong and H. Chen,  Updateable PAT-Tree 
Approach to Chinese Key Phrase Extraction Using 
Mutual Information: A Linguistic Foundation for 
Knowledge Management, Proceedings of the Second 
Asian Digital Libaray Conference, Taipei, Taiwan, 
Novemeber 8-9, 1999.  
[Turney 1999] Turney, P.D., Learning to Extract Key-
phrases from Text, NRC Technical Report ERB-1057, 
National Research Council, Canada, 1999. 
[Witten 1999] Witten I.H., Paynter G.W., Frank E., 
Gutwin C., and Nevill-Manning C.G., KEA: Practical 
automatic keyphrase extraction, Proc. DL '99, 1999, 
pp. 254-256.  
[Yang 2002] Wenfeng Yang, Chinese keyword extrac-
tion based on max-duplicated strings of the docu-
ments, Proceedings of the 25th annual international 
ACM SIGIR conference on Research and develop-
ment in information retrieval, 2002, pp. 439-440. 
The Semantic Knowledge-base of Contemporary Chinese 
and its Applications in WSD? 
 
Hui Wang 
Institute of Computational Linguistics 
Peking University 
Beijing 100871, China 
whui@pku.edu.cn 
Shiwen Yu 
Institute of Computational Linguistics 
Peking University 
Beijing 100871, China 
yusw@pku.edu.cn 
                                                        
? Supported by China National Fundamental Research Program (973) (PN: G1998030507-4). 
 
Abstract 
The Semantic Knowledge-base of Con-
temporary Chinese (SKCC) is a large 
scale Chinese semantic resource devel-
oped by the Institute of Computational 
Linguistics of Peking University. It pro-
vides a large amount of semantic informa-
tion such as semantic hierarchy and 
collocation features for 66,539 Chinese 
words and their English counterparts. Its 
POS and semantic classification represent 
the latest progress in Chinese linguistics 
and language engineering. The descrip-
tions of semantic attributes are fairly 
thorough, comprehensive and authorita-
tive. The paper introduces the outline of 
SKCC, and indicates that it is effective for 
word sense disambiguation in MT appli-
cations and is likely to be important for 
general Chinese language processing. 
Key words:  Semantic knowledge-base, 
lexical semantic, computational lexicog-
raphy, word sense disambiguation
?WSD?, Chinese language processing 
1 Introduction 
Semantic resources play an important role in many 
areas of Natural Language Processing (NLP). The 
Institute of Computational Linguistics (ICL) of 
Peking University has been engaged in research 
and development of the Semantic Knowledge-base 
of Contemporary Chinese (SKCC) in the last eight 
years. This lexicon-building project was a collabo-
ration with the Institute of Computing Technology, 
Chinese Academy of Sciences during 1994-1998, 
and resulted in a machine-readable bilingual lexi-
con suitable for use with Machine Translation ap-
plications, which contained a fairly complete 
characterization of the semantic classification, va-
lence specifications and collocation properties for 
49 thousands Chinese words and their English 
counterparts (Wang Hui, 1998).  
Since 2001, the further development of SKCC 
has been co-conducted by ICL and Chinese De-
partment of Peking University. At present, SKCC 
has made great progress. Not only is the scale ex-
tended to 66,539 entries, but also the quality has 
been immensely improved. The semantic classifi-
cation in the updated edition of SKCC is the em-
bodiment of the very latest progress in Chinese 
linguistics and language engineering, while the 
semantic descriptions are comprehensive and thor-
ough. It can provide rich lexical semantic informa-
tion for various NLP applications. 
2 Outline of SKCC 
2.1 Scale and Structure 
SKCC consists of one general database and six 
sub-databases. The general database contains 
shared attributes of all the 66,539 entries, while the 
sub-databases provide detailed descriptions of the 
distinctive semantic attributes associated with the 
parts of speech (POS). For example, the verb data-
base has 16 attribute fields, noun database and ad-
jective database has 15 attribute fields respectively. 
Database 
Name 
Entries Attribute
fields 
Attribute
value 
nouns 38,478 15 5
verbs 21,142 16 3
adjective 5,577 15 8
pronouns 236 15 3
adverbs 997 11 1
numerals 109 11 1
General  66,539 8 5
Total 133,07 91 1
Table 1  Scale of SKCC 
All of the six sub-databases can be linked to 
the general database through four key fields, 
namely ENTRY, POS, HOMOMORPHISM and 
SENSE.  As a result, the son knots can inherit all 
information from their father knots (Figure 1). 
 
Figure 1 Main structure of SKCC 
2.2 Semantic Hierarchy 
One of the most outstanding characteristics of 
SKCC is that its semantic hierarchy is based on 
grammatical analysis, rather than merely on gen-
eral knowledge (as illustrated in Figure 2 below). 
This classification system represents the latest pro-
gress in Chinese semantics. It is very useful for 
NLP applications(Zhan Weidong, 1997), as well as 
compatible with various semantic resources, such 
as Wordnet (Christiane Fellbaum. 1998), Chinese 
concept dictionary (CCD)( Yu Jiangsheng, 2002), 
HowNet(Dong Zhendong, 2000) etc.  Currently, 
the classification of all of the 66,539 entries has 
already been completed. 
?1?Verbs 
state  
emotion/cognition  
event           change 
weather 
body functions 
perception 
consumption 
motion 
creation 
contact 
possession 
communication 
competition 
social behavior 
other event 
?2?Adjectives 
description of event 
property of object    
measurable value       concentration 
                 speed  
temperature 
speed 
length 
height 
width 
depth 
rigidity 
humidity 
thickness 
tightness 
size 
value 
immeasurable value       vision 
tactility 
tone 
taste 
shape 
quality 
content 
color 
property of human           age 
character 
relation 
condition 
property of space          one dimension 
two dimension 
three dimension 
property of time 
General Database 
Noun Database 
Verb Database  
Adjective Database 
Numeral Database 
Adverb Database
Pronoun Database 
(3) Nouns 
entity           organism        person        individual              profession 
                                                                            identity 
                                                                           relation 
                                                                name 
group                  organization 
society 
animal               beast               
 bird ? 
plant                    tree 
 flower ? 
microbe 
object            artifact               building 
                          works 
food 
clothes 
bill 
                                                instrument                tool 
                                                                                      vehicle 
?                            sports- instrument 
furniture  
? 
                natural object           celestial body 
weather 
geography         land 
                                                   water 
? 
excrement 
shape 
part              body-part                      
object-part 
abstraction           attribute       measurable 
immeasurable          property of human 
information                           description of event 
field                                       property of object 
physiological state  
motivation 
rule                         
psycho feature            feelings 
cognition 
process             event              
                         natural phenomenon          visible phenomenon 
time                   specific time                     audible phenomenon 
                         relative time 
space                location 
direction 
 
 
 
 
 
?4?adverbs 
   degree  
range  
time  
location  
frequency  
manner 
negation  
modality 
?5?numerals 
cardinal number 
ordinal number  
amount 
auxiliary 
Figure 2  Semantic hierarchy in SKCC 
2.3 Comprehensive Semantic Descriptions 
There is close correlation between lexical meaning 
and its distribution. Oriented to MT and IR, one 
aim of SKCC is to provide detailed semantic de-
scription and collocation behavior that in many 
cases is likely to be uniquely associated with a sin-
gle sense.  For example, following attribute fields 
have been filled with values in the verb database 
(see table 2). 
ENTRY Commonly used Chinese 
word or idiom phrase 
PRONUNCIATION Chinese Pinyin with tones 
such as ?chi3zi5? for ??
??(ruler) 
PART OF 
SPEECH 
POS tagging of per word or 
idiom 
SUB-
CATEGORY 
Sub-category tagging of per 
word or idiom 
POSs All POS tagging of per 
word 
HOMOMORPHISM Homograph number  
SENSE Sense number of per 
polysemous word  
DEFINITION Sense definition  
SEMANTIC 
CATEGORY 
Semantic categories of per 
word or idiom.  A word can 
be tagged with two or more 
semantic categories. For 
instance, the noun ???? 
(greengrocery) belong to 
?plant | food? categories. 
VALENCE Valence number of each 
entry. For example, ??
??(cough) is a one-valence 
verb?while ???(eat) is a 
two-valence one, 
???(give) is three-valence. 
AGENT Actor of action or motion.  
OBJECT Object of action. 
DATIVE Beneficiary or suffer of 
action.  
TRANSLATION English counterpart of per 
word or idiom.  
ECAT POS tagging of per English 
word or phrase.  
ILLUSTRATIONS Corpus-derived example 
sentences showing authen-
tic contexts of a word or 
idiom. 
Table 2 Semantic attributes in the verb database of SKCC 
 
To sum up, the above attributes fall into five 
kinds of information below:  
(1)  Basic information of entry, such as vocabulary 
item, part of speech, sub-category, homograph 
and pronunciation; 
(2)  Descriptions of word meaning, including sense 
number, definition, and semantic categories;  
(3)  Semantic valence, thematic roles and combina-
torial properties for per words; this is the most 
important part of SKCC and especially useful 
for WSD and lexical semantics research; 
(4)  English translation and its POS tagging. If a 
Chinese word has two or more English 
counterparts, it will be regarded as different 
entries respectively, and the collocation 
information will also be given in relevant 
fields. This can significantly improve the 
quality of Chinese-English MT system. 
(5)  Corpus-derived authentic examples of a word 
in context, showing how it is used, how 
phrases are formed around it, and so on. 
3 Application in WSD 
As a large-scale lexical knowledge base, SKCC 
combines the features of many of the other re-
sources commonly exploited in NLP work: it in-
cludes definitions and English translations for in-
dividual senses of words within it, as in a bilingual 
dictionary; it organizes lexical concepts into a con-
ceptual hierarchy, like a thesaurus; and it includes 
other links among words according to several se-
mantic relations, including semantic role, colloca-
tion information etc. As such it currently provides 
the broadest set of lexical information in a single 
resource. The kind of information recorded and 
made available through SKCC is of a type usable 
for various NLP applications, including machine 
translation, automatic abstraction, information re-
trieval, hypertext navigation, thematic analysis, 
and text processing.  
In this section, we shall focus on the automatic 
disambiguation of Chinese word senses involving 
SKCC since it is most troublesome, and essential 
for all the above NLP applications (Ide, 1998).  
3.1 Determination of the polysemous words 
and homographs 
In general terms, word sense disambiguation 
(WSD) task necessarily involves two steps: (1) the 
determination of all the polysemous words and 
homographs in the text or discourse; and (2) a 
means to assign each occurrence of a word to the 
appropriate sense. 
Step (1) can be easily accomplished by reliance 
on SKCC.  Firstly, each entry denotes one single 
sense of per word in SKCC. Thus, if a word has 
two or more senses, it will be regard as different 
entries, and the ?SENSE? field will be filled with 
different number (as ???in table 3). 
ENTRY ? 1 ? 2 
POS n n  
SENSE 1 2 
DEFINITION vegetable cooked vege-
table, egg, 
fish, meat...etc
TRANSLATION vegetable dish 
ILLUSTRATIONS ?? 
grow 
 vegetables 
?? 
potherb 
?? 
meat or fish 
????
four dishes 
and a bowl 
of soup 
Table 3 Two senses of Chinese noun ??? 
Secondly, SKCC marked all of the homo-
graphs in ?HOMOMORPHISM? field, such as two 
verbs ???with different pronunciation in table 4. 
ENTRY ? 1 ? 2 
PRONUNCIATION Kan4 Kan1 
HOMOMORPHISM A B  
DEFINITION see; 
watch; 
look at  
look after;
take care of
TRANSLATION see look after 
Table 4 Homographs in SKCC 
Therefore, if either of the ?SENSE? and 
?HOMOMORPHISM? fields is filled with value in 
SKCC, the entry must be a polysemous word or 
homograph. 
3.2 WSD based on semantic categories  
The senses of most Chinese polysemous words and 
homographs belong to different semantic catego-
ries, and have different syntagmatic features in 
context (Wang Hui, 2002) . SKCC gives detailed 
description of such information in ?AGENT? 
and/or ?OBJECT? fields as illustrated in table 5 
below. 
ENTRY ?? 1 ?? 2 
POS  a a 
SENSE 1 2 
DEFINITION (of food, 
drink, 
smell) 
light; 
weak  
(of business)
slack 
SEMANTIC 
CATEGORY 
taste condition 
AGENT food | drink| 
plant 
?business? 
TRANSLATION light slack  
Table 5 Polysemous adjectives in SKCC 
Based on the above description, the target 
word ???? in following POS-tagged text can be 
accurately disambiguated: 
[1]  ?/m ?/q ??/a ?/u ???/n  
A cup of light Longjing tea. 
[2]  ???/t ??/v ?/u ?/n ?/d ?/a ???/n 
??/d ??/a? 
When the season is busy, few farmers go to 
town and the business is rather slack. 
In sentence[1], the word modified by ???? 
is the noun???(tea) , which is a kind of ?drink?; 
while the word???? in sentence [2] is a predicate 
of ?business?.  According to the different values 
in ?AGENT? field, it is easy to judge that these 
two ???? belong to two semantic categories, viz. 
the former is ?light??and the latter is ?slack?. 
3.3 WSD based on collocation information 
As for the polysemous words or homographs be-
longing to the same semantic category, the differ-
ence between them usually manifests at the 
collocation level. According to a study in cognitive 
science, people often disambiguate word sense us-
ing only a few other words in a given context (fre-
quently only one additional word) ( Choueka, 
1983). Thus, the relationships between one word 
and others can be effectively used to resolve ambi-
guity. For example, Chinese verb ??? has two 
senses: one is ???? (look for) and the other is ?
??? (give change).  Only when the verb co-
occurs with the noun ??? (money), it can be inter-
preted as ?give change?; Otherwise, it means ?look 
for? (see table 6).  
ENTRY ? 1 ? 2 
HOMOMORPHISM A B 
SENSE 1 2 
DEFINITION look for; 
seek try to 
find;   
give change 
AGENT person entity 
OBJECT entity ?money? 
DATIVE  person 
TRANSLATION look for give change 
Table 6  Different senses of verb ???  
According to table 6, the verb ??? in sen-
tence [1] below must be ?look for?, because its 
object is ??? (person), a kind of ?entity?; while ?
??in sentence [2] has two objects, namely, indi-
rect object ?? ? (me) and direct object ??
?(money). Thus, its meaning is ?give change?. 
[1]??/r ?/d  ??/v  ?/v  ?/n? 
They will go out to look for sb. 
[2]???/n ?/d ??/d ?/v ?/r ?/n ? 
The seller has not given change to me. 
By making full use of SKCC and a large scale 
POS-tagged corpus of Chinese, a multi-levels 
WSD model is developed and has already been 
used in a Chinese-English MT application. 
4 Conclusion 
SKCC is a well-structured Chinese-English bilin-
gual semantic resource, as described in the paper, it 
has more than 66,000 Chinese words and their 
English counterparts classified, and the accurate 
description of about 1.5 million attributes further 
enriched the abundance of lexical semantic knowl-
edge. It not only provides a deductive system of 
word meaning and valuable semantic knowledge 
for Chinese language processing, but also has great 
theoretical significance in lexical semantics and 
computational lexicography research. 
Acknowledgement 
We appreciate all the members participated in 
SKCC project, especially Prof. Lu Jianming, Dr. 
Zhan Weidong, Mr. Li Kangnian and Dr. Chang 
Baobao. The blithesome collaboration with Dr. 
Ying Chenjin and Mr. Guo qingjian from Chinese 
Department is memorable for all of us. Lastly, 
thanks our colleagues and friends for their kindly 
discussion with the authors. 
References 
 
Choueka, Y. and S. Lusignan, 1983.  ?A Connec-
tionist Scheme for Modeling Word Sense Dis-
ambiguation,? Cognition and Brain Theory. 6 
(1). pp.89-120. 
Christiane Fellbaum. 1998. WordNet: an electronic 
lexical database. Mass: MIT Press.  
Dong Zhendong, Dong Qiang. 200. ?Hownet?. 
http:// www.keenage.com. 
Ide, Nancy; Jean V?ronis. 1998. ?Introduction to 
the Special Issue on Word Sense 
Disambiguation: The State of the Art?, 
Computational Linguistics. Vol.24, No.1. 
pp1-40 
Wang Hui, Zhan Weidong, Liu Qun. 1998. ?De-
sign of Semantic Dictionary of Modern Chi-
nese?. Proceedings from 1998 International 
Conference on Chinese Information Process-
ing. Beijing: Tsinghua University Press. 
pp361-367. 
Wang Hui. 2002. ?Chinese Word Sense Disam-
biguation in Machine Translation?. Proceed-
ings from Chinese National Symposium on 
Machine Translation. Beijing: Publishing 
House of Electronics Industry. pp.34-43. 
Yu Jiangsheng, Yu Shiwen. 2002. ?Structure and 
Design of CCD?. Chinese Information Proc-
essing. 16 (4): 12-20. 
Zhan Weidong, Liu Qun. 1997. ?The important 
role of semantic classification in Chinese-
English MT?. Language Engineering. 
Tsinghua University Press. 286-291. 
 
Chinese Word Segmentation at Peking University 
Duan Huiming  Bai Xiaojing  Chang Baobao  Yu Shiwen 
Institute of Computational Linguistics, Peking University 
{duenhm, baixj, chbb, yusw}@pku.edu.cn 
 
Abstract 
 
Word segmentation is the first step in Chinese 
information processing, and the performance 
of the segmenter, therefore, has a direct and 
great influence on the processing steps that 
follow. Different segmenters will give 
different results when handling issues like 
word boundary. And we will present in this 
paper that there is no need for an absolute 
definition of word boundary for all segmenters, 
and that different results of segmentation shall 
be acceptable if they can help to reach a 
correct syntactic analysis in the end.  
Keyword: automatic Chinese word 
segmentation, word segmentation evaluation, 
corpus, natural language processing 
 
 
1. Introduction 
 
On behalf of the Institute of Computational 
Linguistics, Peking University, we would like 
to thank ACL-SIGHAN for sponsoring the 
First International Chinese Word 
Segmentation Bakeoff, which provides us an 
opportunity to present our achievement of the 
past decade. 
We know for sure that it is very difficult to 
settle on a scientific and appropriate method 
of evaluation, and it might be even more 
difficult than word segmentation itself. We are 
also clear that each step in Chinese 
information processing requires great efforts, 
and a satisfactory result in word segmentation, 
though critical, does not necessarily guarantee 
good results in the following steps. 
From the test results of this evaluation, we 
are very gratified to see that we have done a 
good job both as a test corpus provider and as 
a participant. According to the rule, we did not 
test on the corpus we provided, but it is quite 
encouraging that our supply tops the test 
corpus list to be elected by other participants. 
Section 2 and Section 3 describes our work 
in the Bakeoff as the test corpus provider and 
the participant respectively. 
 
2. The test corpus provider 
 
2.1 Corpus 
The corpus we provided to the sponsor 
includes: 
? A training set from People?s Daily 
(January, 1998) 
? A test set from People?s Daily (Page 4 of 
January 1, 1998) 
Data from People?s Daily features standard 
Chinese, little language error, a wide coverage 
of linguistic phenomenon and topics, which 
are required for statistic training. Meanwhile, 
the corpus we provided is a latest version 
manually validated, hence a high level of 
correctness and consistency. 
 
2.2 Specification 
When processing a corpus, we need a detailed 
and carefully designed specification for 
guidance. And when using the corpus for NLP 
evaluation, we also need such a specification 
to ensure a fair contest for different systems 
within a common framework. 
We provided the latest version of our 
specification, which has been published in the 
Journal of Chinese Information Processing. 
Based on our experience of large-scale corpus 
processing in recent years, the current version 
gave us different perspectives in a consistent 
way, and we hope it will also help others in 
this field know better of our segmented and 
POS-tagged corpus. 
 
3. The participant 
 
3.1 Training and testing 
Our research on word segmentation has been 
focusing on People?s Daily. As we are one of 
the two providers of Chinese corpora in GB 
code in this Bakeoff, we had to test on the 
Penn Chinese treebank. 
Not all the training and test corpus we got 
came from the Mainland China. Some were 
GB data converted from BIG5 texts of Taiwan. 
It is commonly known that in the Mainland, 
Hong Kong and Taiwai, the Chinese langauge 
is used diversely not only in the sense of 
different coding systems, but in respect of 
different wordings as well. 
While training our segmenter, we studied 
the guidelines and training corpus of Penn 
Chinese treebank, tracing the differences and 
working on them. The main difference 
between the work of U. Penn and that of ours 
is notion of ?word?. For instance:
Differences of ?Word? U. Penn PKU 
Chinese name ??????? ?  ??, ?  ?? 
Number + ??|???? 11.6????????? 11.6?  ??????  ?  ?
Monosyllabic verb + complement ???????? ?  ???  ???  ? 
Time word ?????????? ??  ??????  ?? 
Noun + suffix ??? ????????? ???  ?????  ? 
Disyllabic verb + ??? ??????? ??  ????  ? 
? ?   
These are different combinations in regard 
of words which follow certain patterns, and 
can therefore be handled easily by applying 
rules to the grogram. The real difficulty for us, 
however, is the following items: 
U. Penn PKU 
??  ?? ???? 
??  ?? ???? 
??  ?? ???? 
??  ?? ???? 
??  ?? ???? 
?  ?  ? ??? 
? ? ? ? 
The Open Track allows us to use our own 
recourses, so we had to find the lexical 
correspondence to reduce the negtive effect 
caused by the difference between Penn 
Chinese treebank and our own corpus. 
However, as the training corpus is small, we 
could not remove all the negative effect, and 
the untackled problems remained to affect our 
test result. 
Further, as we have been working on 
language data from the Mainland China, the 
lexicon of our segmenter does not contain 
words used in Taiwan. Such being the case, 
we added into our lexicon the entries that were 
not known (i.e., not found in the training set) 
and could not be handled by the rule-based 
makeshift either. But because we are not very 
familiar with the Chinese language used in 
Taiwan, we could not make a complete patch 
due to the limit of time. 
 
3.2 Result analysis 
From the test result that the sponsor provided, 
we can see our segmenter failed to score when 
the notion of ?word? and the recognition of 
unknown words are involved. 
 
Example 1: 
[U. Penn] ?? ?? ? ? ???   ? 
?? ?? ??? ?? ? ? ?? ? 
?? ? ? ? ?? ?? ? ?? ?? 
? ? ? ? ?? ? ?? ?? ?? ?
?? ?? ? ?? ? ?? ? ?? ? 
? ?? ?? ? ??? ? 
[PKU] ?? ?? ? ? ? ? ? ? 
?? ?? ??? ?? ? ? ?? ? 
?? ? ??  ?? ?? ? ?? ?? 
? ? ? ? ?? ? ?? ?? ?? ?
?? ?? ? ?? ? ?? ? ?? ? 
? ?? ?? ? ??? ? 
 
Example 2: 
[U. Penn] ? ? ??  ?? ?? ?? 
? ? ?? ?? ? ? ?? ? ?? ? 
?? ? ?? ?? ? ?? ?? ???
? ? ? ? ? ? ? ? ?? ? ? ?
? ??? ? ? ? ? ? ? ? ? ? 
?? ? ?? ? ? ?? ? ?? ? 
[PKU] ? ? ? ? ?? ?? ?? ? 
? ?? ?? ? ? ?? ? ?? ? ?
? ? ?? ?? ? ?? ?? ???
? ? ? ? ? ? ? ? ?? ? ? ?
? ??? ??  ? ? ? ? ? ??  
?? ? ?? ? ? ?? ? ?? ? 
 
In addition, there are also cognitive 
differences concerning the objective world, 
which did come up to influence our fine score. 
 
Example 3: 
[U. Penn] ??? ? ? ??? ? ? ? 
?? ?? ? ? ? ? ? ? ? ?? ? 
? ? ?? ?? ? CPU ? ?? ? ? 
? ? ? ? ? ?? ??? ? ? ?
? ? 
[PKU] ??? ? ? ??? ? ? ? 
?? ?? ? ? ? ??  ? ? ?? ? 
? ? ?? ?? ? CPU ? ?? ? ? 
? ? ? ? ? ?? ??? ? ??
? ? 
 
Example 4: 
[U. Penn] ? ? ????  ?? ? ? 
?? ? ? ? ? ? ?? ? ? ?? ? 
? ?? ? ? ?? ? ? ? ?? ? ?
? ?? ?? ?? ?? ? ? ??  
?? ? 
[PKU] ? ? ? ??? ?? ? ? ?
? ? ? ? ??  ?? ? ? ?? ? 
? ?? ? ? ?? ??  ? ?? ? ?
? ?? ?? ?? ?? ? ? ? ? 
?? ? 
 
The recognition of unknown words has long 
been a bottleneck for word segmentation 
technique. So far we have not found a good 
solution, but we are confident about a progress 
in this respect in the near future. 
 
4. Conclusion 
 
Word segmentation is the first step yet a key 
step in Chinese information processing, but 
we have not found a perfect solution up till 
now. From an engineering perspective, we 
think there is no need for a unique result of 
segmentation. All roads lead to Rome. The 
approach you take, technical or non-technical, 
will be a good one if the expected result is 
achieved. And it would be more desirable if 
the processing program in each step can 
tolerate or even correct the errors made in the 
previous step. 
We learn from our experience that the 
computer processing of natural language is a 
complex issue, which requires a solid 
fundamental research (on the language itself) 
to ensure a higher accuracy of automation. It 
is definitely hard to achieve an increase of one 
percent or even less in the accuracy of word 
segmentation, but we are still confident and 
will keep working in this respect. 
 
Finally, we would like to thank Dr. Li Baoli 
and Dr. Bing SWEN for their great efforts on 
the maintenance of our segmentation program. 
 
Reference 
Yu, Shiwen, DUAN, Hui-ming, ZHU, Xue-feng, 
Bing SWEN. 2002. The Specification of Basic 
Processing of Contemporary Chinese Corpus. 
Journal of Chinese Information Processing, 
Issue 5 & Issue 6, 2002.  
Yu, Shiwen, et al 2002. The Grammatical 
Knowledge-base of Contemporary Chinese ? 
A Complete Specification (Second Version). 
Beijing: Tsinghua University Press. 
Liu, Yuan, et al 1994. Specification and 
Automation of Word Segmentation of 
Contemporary Chinese for Information 
Processing. Beijing: Tsinghua University 
Press. 
Fie Xia. 2000. The segmentation guidelines for 
the Penn Chinese tree bank (3.0). see 
http://www.cis.upenn.edu/~chinese/segguide.3
rd.ch.pdf 
 
  
A Unicode based Adaptive Segmentor 
Q. Lu, S. T. Chan, R. F. Xu, T. S. Chiu 
Dept. Of Computing, 
The Hong Kong Polytechnic University, 
Hung Hom, Hong Kong 
{csluqin,csrfxu}@comp.polyu.edu.hk 
B. L. Li, S. W. Yu 
The Institute of Computational Linguistics, 
Peking University, 
Beijing, China 
{libi,yusw}@pku.edu.cn 
 
Abstract 
This paper presents a Unicode based 
Chinese word segmentor. It can handle 
Chinese text in Simplified, Traditional, or 
mixed mode. The system uses the strategy 
of divide-and-conquer to handle the 
recognition of personal names, numbers, 
time and numerical values, etc in the pre-
processing stage. The segmentor further 
uses tagging information to work on 
disambiguation. Adopting a modular 
design approach, different functional parts 
are separately implemented using 
different modules and each module 
tackles one problem at a time providing 
more flexibility and extensibility. Results 
show that with added pre-processing 
modules and accessorial modules, the 
accuracy of the segmentor is increased 
and the system is easily adaptive to 
different applications. 
1 Introduction 
The most difficult problem in Chinese word 
segmentation is due to overlapping ambiguities [1-
2]. The recognition of names, foreign names, and 
organizations are quite unique for Chinese. Some 
systems can already achieve very high accuracy [3], 
but they heavily rely on manual work in getting the 
system to be trained to work certain language 
environment. However, for many applications, we 
need to look at the cost to achieve high accuracy. 
In a competitive environment, we also need to 
have systems that are quickly adaptive to new 
requirements with limited resources available. 
In this paper, we report a Unicode based Chinese 
word segmentor. The segmentor can handle 
Chinese text in Simplified, Traditional, or mixed 
mode where internally only one dictionary is 
needed. The system uses the strategy of divide-
and-conquer to handle the recognition of personal 
names, numbers, time and numerical values. The 
system has a built-in new word extractor that can 
extract new words from running text, thus save 
time on training and getting the system quickly 
adaptive to new language environment. The 
Bakeoff results in the open text for our system in 
all categories have shown that it works reasonably 
good for all different corpora. 
The rest of the paper is organized as follows. 
Section 2 presents our system design objectives 
and components. Section 3 discusses more 
implementation details. Section 4 gives some 
performance evaluations. Section 5 is the 
conclusion. 
2 Design Objectives and Components 
With the wide use of Unicode based operating 
systems such as Window 2000 and Window XP, 
we now see more and more text data written in 
both the Simplified form and the Traditional form 
to co-exist on the same system. It is also likely that 
text written in mixed mode. Because of this reality, 
the first design objective of this system is its ability 
to handle the segmentation of Chinese text written 
in either Simplified Chinese, Traditional Chinese, 
or mixed mode.  As an example, we should be able 
to segment the same sentence in different forms 
such as the example given below:   
 
The second design objective is to adopt the 
modular design approach where different 
functional parts are separately implemented using 
independent modules and each module tackles one 
problem at a time. Using this modular approach, 
we can isolate problems and fine tune each module 
with minimal effect on other modules in the system. 
  
Special features like adding new rules or new 
dictionary can be easily done without affecting 
other modules. Consequently, the system is more 
flexible and can be easily extended.  
The third design objective of the system is to make 
the segmentor adaptive to different application 
domains. We consider it having more practical 
value if the segmentor can be easily trained using 
some semi-automatic process to work in different 
domains and work well for text with different 
regional variations. We consider it essential that 
the segmentor has tools to help it to obtain regional 
related information quickly even if annotated 
corpora are not available. For instance, when it 
runs text from Hong Kong, it must be able to 
recognize the personal names such as  if 
such a name(quadra-gram) appears in the text often. 
 
Figure 1. System components 
Figure 1 shows the two major components, the 
segmentor and data manager. The segmentor is the 
core component of the system. It has a pre-
processor, the kernel, and a post-processor. As the 
system has to maintain a number of tables such as 
the dictionaries, family name list, etc., a separate 
component called data manager is responsible in 
handling the maintenance of these data.  The pre-
processor has separate modules to handle 
paragraphs, ASCII code, numbers, time, and 
proper names including personal names, place and 
organizational names, and foreign names. The 
kernel supports different segmentation algorithms. 
It is the application or user?s choice to invoke the 
preferred segmentation algorithms that at current 
time include the basic maximum matching and 
minimum matching in both forward and backward 
mode. These can also be used to build more 
complicated algorithms later on. In addition, the 
system provides segmentation using part-of-speech 
tagging information to help resolve ambiguity. The 
post-processor applies morphological rules which 
cannot be easily applied using a dictionary.   
The data manager helps to maintain the knowledge 
base in the system. It also has an accessory 
software called the new word extractor which can 
collect statistical information based on character 
bi-grams, tri-grams and quadra-grams to semi-
automatically extract words and names so that they 
can be used by the segmentor to improve 
performance especially when switching to a new 
domain. Another characteristic of this segmentor is 
that it provides tagging information for segmented 
text. The tagging information can be optionally 
omitted if not needed by an application. 
3 Implementation Details 
The basic dictionary of this system was provided 
by Peking University [4] and we also used the 
tagging data from [4]. The data structure for our 
dictionaries are very similar to that discussed in [5]. 
As our program needs to handle both Simplified 
and Traditional Chinese characters, Unicode is the 
only solution for dealing with more than one script 
at the same time. 
Even though it is our design objective to support 
both Simplified and Traditional Chinese, we do not 
want to keep two different sets of dictionaries for 
Simplified and Traditional Chinese. Even if two 
versions are kept, it would not serve well for text 
in mixed mode. For example, Traditional Chinese 
word of ?the day after tomorrow? should be , 
and for Simplified Chinese, it should be . 
However sometimes we can see the word  
appears in a Traditional Chinese text. We cannot 
say that it is wrong because the sentence is still 
semantically correct especially in Unicode 
environment. Therefore the segmentor should be 
able to segment those words correctly such as in 
the examples: ? ?, and in ?  
?. We must also deal with dictionary 
maintenance related to Chinese variants. For 
example, characters  are variants, so are 
. 
Data manager Segmentor 
Pre-
Processor 
Kernel 
Post 
Processor 
New Word
Extractor
Knowledge-
base 
  
In order to keep the dictionary maintenance simple, 
our system uses a single dictionary which only 
keeps the so called canonical form of a word. In 
our system, the canonical form of a word is its 
?simplified form?.  We quoted the word 
?simplified? because only certain characters have 
simplified forms such as  to , but for  
, there is no simplified form. In the case of 
variants, we simply choose one of them as the 
canonical character.  The canonical characters are 
maintained in the traditional-simplified character 
conversion table as well as in a variant table.  
Whenever a new word, item, is added into the 
dictionary, it must be added using a function 
CanonicalConversion(), which takes item as an 
input. During segmentation, the corresponding 
dictionary look up function will first convert the 
token to its canonical form before looking up in the 
dictionary.  
The personal name recognizers (separate for 
Chinese names and foreign names) use the 
maximum-likelihood algorithm with consideration 
of commonly used Chinese family names, given 
names, and foreign name characters. It works for 
Chinese names of length up to 5 characters. In the 
following examples you can see that our system 
successfully recognized the name . This 
is done using our algorithm, not by putting her 
name in our dictionary: 
 
Organization names and place names are 
recognized mainly using special purpose 
dictionaries. The segmentor uses tagging 
information to help resolve ambiguity. The 
disambiguation is mostly based on rules such as  
p + (n + f) -> p + n + f 
which would word to correct 
  
For efficiency reasons, our system uses only about 
20 rules. The system is flexible enough for new 
rules to be added to improve performance.  
The new word extractor is an accessory program to 
extract new words from running text based on 
statistical data which can either be grabbed from 
the internet or collected from other sources. The 
basic statistical data include bi-gram frequency, tri-
gram frequency, and quadra-gram frequencies. In 
order to further example whether a bi-gram, say  
, is indeed a word, we further collect forward 
conditional frequency of  , and 
the back-ward conditional frequency of , 
. For an i-gram token, we also 
use the (i+1)-gram statistics to eliminate those i-
grams that are only a part of (i+1) ? gram word.  
For instance, if the frequency of bi-gram  is 
very close to the frequency of tri-gram , it 
is less likely that  is a word. Of course, 
whether  is a word depends on quadra-gram 
results.  Using the statistical result, a set of rules 
was applied to these i-grams to eliminate entries 
that are not considered new words. Minimal 
manual work is required to identify whether the 
remaining candidates are new words. Before words 
are added into the dictionary, part-of-speech 
information are added manually (although not 
necessary) before using the canonical function. 
The following table shows examples of bi-grams 
which are found by the new word extractor using 
one year Hong Kong Commercial Daily News data. 
 
 
 
4 Performance Evaluation 
The valuation metrics used in [6] were adopted 
here. 
1
3
N
N
recall =     (1) 
 
2
3
N
Npresicion =     (2) 
  
precisionrecall
precisionrecallrecallprecisionF +
??= 2),(1   (3) 
where N  1  denotes the number of words in the 
annotated corpus, N 2 denotes the number of words 
identified by the segmentation algorithm , and N 3 is 
the number of words correctly identified. 
We participated in the open tests for all four 
corpora. The results are shown in the following 
table. 
The worst performance in the 4 tests were for the 
CTB(UPenn) data. From the observation from the 
testing data, we found that the main problem with 
have with CTB data is the difference in word 
granularity. To confirm our observation, we have 
done an analysis of combining errors and 
overlapping errors. The results show that the ratios 
of combining errors in all the error types are 
0.8425(AS), 0.87684(CTB), 0.82085(HK), and 
0.77102(PK). The biggest problem we have with 
AS data, on the other hand is due to out of 
vocabulary mistakes. Even though our new word 
extractor can help us to reduce this problem, but 
we have not trained our system using data from 
Taiwan.  Our best performance was on PK data 
because we used a very similar dictionary. The 
additional training of data for HK was done using 
one year Commercial Daily( ). 
The following table summarizes the execution 
speed of our program for the 4 different 
sources: 
Data No. of 
chars 
Processi
ng Time 
(sec.) 
Processin
g Rate 
(char/sec) 
Segmentat
ion Rate 
(char/sec) 
AS 18,743 4.703 3,985 7,641 
CTB 62,332 10.110 6,165 7,930 
HK 57,432 10.329 5,560 7,109 
PK 28,458 4.829 5,893 10,970 
 
The program initialization needs around 2.25 
seconds mainly to load the dictionaries and other 
data into the memory before the segmentation can 
start. If we only count the segmentation time, the 
rate of segmentation on the average is around 
7,500 characters for the first three corpora. It 
seems that the processing speed for Peking U. data 
is faster. This may be because the dictionaries we 
used are closer to the PK system, thus it would 
take less time to work on disambiguation.  
5 Conclusion 
In this paper, design and algorithms of a general-
purposed Unicode based segmentor is proposed. It 
is able to process Simplified and Traditional 
Chinese appear in the same text. Sophisticated pre-
processing and other auxiliary modules help 
segmenting text more accurately. User interactions 
and modules can be easily added with the help of 
its modular design. A built-in new word extractor 
is also implemented for extracting new words from 
running text. It saves much time on training and 
thus it can be quickly adapted to new environments. 
Acknowledgement 
We thank the PI of ITF Grant by ITC of 
HKSARG (ITS/024/01) entitled: Towards Cost-
Effective E-business in the News Media & 
Publishing Industry for the use of HK Commercial 
Daily. 
References 
[1] Automatic Segmentation and Tagging for Chinese 
Text ( ) , K.Y. Liu, 
Commercial Press, 2000 
[2] Segmentation Issues in Chinese Information 
Processing,  (C.N. Huang Issue No. 
1, 1997) 
[3] The design and Implementation of a Modern General 
Purpose Segmentation System (B. Lou,  R. Song, W.L. 
Li, and Z.Y. Luo, Journal of Chinese Information 
Processing, Issue No. 5, 2001) 
[4] (Institute of 
Computational Linguistics, Peking Univ., 2002) 
[5] 
  Journal of Chinese information 
processing vol. 14, no. 1, 2001) 
[6] Chinese Word Segmentation and Information 
Retrieval, Palmer D., and Burger J., In AAAI 
Symposium Cross-Language Text and Speech 
Retrieval 1997 
Proceedings of the Linguistic Annotation Workshop, pages 125?131,
Prague, June 2007. c?2007 Association for Computational Linguistics
Building Chinese Sense Annotated Corpus  
with the Help of Software Tools 
Yunfang Wu 
School of Electronic Engineering and 
Computer Science, Peking University, 
Beijing 100871 
wuyf@pku.edu.cn 
Peng Jin 
School of Electronic Engineering and 
Computer Science, Peking University, 
Beijing 100871 
jandp@pku.edu.cn 
Tao Guo 
School of Electronic Engineering and 
Computer Science, Peking University, 
Beijing 100871 
gtwcq@pku.edu.cn 
Shiwen Yu 
School of Electronic Engineering and 
Computer Science, Peking University, 
Beijing 100871 
yusw@pku.edu.cn 
 
 
Abstract 
This paper presents the building procedure 
of a Chinese sense annotated corpus. A set 
of software tools is designed to help hu-
man annotator to accelerate the annotation 
speed and keep the consistency. The soft-
ware tools include 1) a tagger for word 
segmentation and POS tagging, 2) an an-
notating interface responsible for the sense 
describing in the lexicon and sense anno-
tating in the corpus, 3) a checker for con-
sistency keeping, 4) a transformer respon-
sible for the transforming from text file to 
XML format, and 5) a counter for sense 
frequency distribution calculating. 
1 Introduction 
There is a strong need for a large-scale Chinese 
corpus annotated with word senses both for word 
sense disambiguation (WSD) and linguistic re-
search. Although much research has been carried 
out, there is still a long way to go for WSD tech-
niques to meet the requirements of practical NLP 
programs such as machine translation and infor-
mation retrieval. It was argued that no fundamen-
tal progress in WSD could be made until large-
scale lexical resources were built (Veronis, 2003). 
In English a word sense annotated corpus SEM-
COR (Semantic Concordances) (Landes et al, 
1999) has been built, which was later trained and 
tested by many WSD systems and stimulated large 
amounts of WSD work. In Japanese the Hinoki 
Sensebank is constructed (Tanaka et al, 2006). In 
the field of Chinese corpus construction, plenty of 
attention has been paid to POS tagging and syn-
tactic structures bracketing, for instance the Penn 
Chinese Treebank (Xue et al, 2002) and Sinica 
Corpus (Huang et al, 1992), but very limited 
work has been done with semantic knowledge 
annotation. Huang et al (2004) introduced the 
Sinica sense-based lexical knowledge base, but as 
is well known, Chinese pervasive in Taiwan is not 
the same as mandarin Chinese. SENSEVAL-3 
provides a Chinese word sense annotated corpus, 
which contains 20 words and 15 sentences per 
meaning for most words, but obviously the data is 
too limited to achieve wide coverage, high accu-
racy WSD systems. 
This paper is devoted to building a large-scale 
Chinese corpus annotated with word senses. A 
small part of the Chinese sense annotated corpus 
has been adopted as one of the SemEval-2007 
tasks namely ?Multilingual Chinese-English Lexi-
cal Sample Task? This paper concentrates on the 
description of the manually annotating schemes 
125
with the help of software tools. The software tools 
will help human annotators mainly in the two as-
pects: 1) Reduce the labor time and accelerate the 
speed; 2) Keep the inter-annotator agreement. The 
overall procedure along with the software tools is 
illustrated in figure 1.
.
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
            Preprocessing                                                                                 
Tagger: word segmentation and POS tagging
 
 
Annotating interface: word sense annotating
 
 
 
 
Checker: consistency checking 
 
 
 
 
Word sense annotated corpus
 
 
 
 
 
                                                                                                                                                      Postprocessing
Transformer: XML format transforming Counter: sense frequency distribution calculating
 
This paper is so organized as follows. In section 
2 the preprocessing stage (word segmentation and 
POS tagging) is discussed. Then in section 3 the 
annotating scheme and the annotating interface 
are demonstrated in detail. The strategy to keep 
consistency is addressed in section 4. And then in 
section 5 and 6 the two postprocessing stages are 
respectively presented. Finally in section 7 con-
clusions are drawn and future works are presented. 
2 Word segmentation and POS tagging 
The input data for word sense annotating is firstly 
word segmented and POS tagged using Peking 
University?s POS tagger (Yu et al, 2003). The 
POS tagging precision is up to 97.5%, which lays 
a sound foundation for researches on sense anno-
tating. This is actually to make use of the full-
fledged syntactic processing techniques to deal 
with the semantic annotation problems. Different 
senses of one ambiguous word sometimes behave 
so differently that they bear different POS tags. 
Take ???/hold? in sentence (1) as an example. 
The noun of ???/hold? means ?confidence?, but 
the verb means ?grasp?.  
(1) a ?(have)  ??/n(confidence)  
b ??/v(grasp)  ?(ZHU)  ??(chance) 
Due to the unique characteristic of Chinese lan-
guage that lacks word inflection, the ambiguous 
words with different POSs are very common. Ac-
cording to the research of Li (1999), after POS 
tagging the ratio of ambiguous word occurrences 
in the text of People?s Daily is reduced from 42% 
to 26%. Therefore the emphasis of manually sense 
annotating in this paper falls on the ambiguous 
words with the same part of speech. This will in 
turn save 16% of the annotation effort compared 
with the sense annotating before the preprocessing 
of POS tagging. 
Fig.1.The overall procedure along with the software tools 
3 Word sense annotating 
The resulting lexical knowledge base in this pro-
ject will contain three major components: 1) a 
corpus annotated with Chinese word senses 
namely Chinese Senses Pool (CSP); 2) a lexicon 
containing sense distinction and description 
namely Chinese Semantic Dictionary (CSD); 3) 
the linking between the CSD and the Chinese 
Concept Dictionary (CCD) (Liu et al, 2002). The 
corpus CSP, the lexicon CSD and CCD constitute 
a highly relational and tightly integrated system: 1) 
In CSD the sense distinctions are described rely-
ing on the corpus; 2) In CSP the word occurrences 
are assigned sense tags according to the sense en-
126
try specified in CSD; 3) The linking between the 
sense entry in CSD and CCD synsets are estab-
lished. The dynamic model is shown in figure 2. A 
software tool is developed in Java to be used as 
the word sense annotating interface (figure 3), 
which embodies the spirit of the dynamic model 
properly.
  
. 
 
 
 
 
 
 
 
 
             
 
 
 
 
 
 
 
      
 
 
 
 
 
 
 
3.1 Sense describing in the lexicon and sense 
annotating in the corpus 
In this project the lexicon CSD containing sense 
descriptions and the corpus CSP annotated with 
senses are built interactively, simultaneously and 
dynamically. On one hand, the sense distinctions in 
the lexicon are made relying heavily on the corpus 
usage. On the other hand, using the sense informa-
tion specified in the lexicon the human annotators 
assign semantic tags to all the instances of the 
word in a corpus.  
In the word sense annotating interface, the sen-
tences from CSP containing the target ambiguous 
words are displayed in the upper section, and the 
word senses with feature-based description from 
CSD are displayed in the bottom section. 
Through reading the context in the corpus, the 
human annotator decides to add or delete or edit a 
sense entry in the lexicon. The default value of the 
range of the context is within a sentence, and the 
surrounding characters in the left and right of the 
target word can be specified by the annotator. An-
notators can do four kinds of operations in CSD: 1) 
Add a sense entry and then fill in all the features; 2) 
Delete a sense entry along with all its feature de-
scription; 3) Edit a sense entry and change any of 
the features; 4) Select a sample sentence form the 
CSP and add it to the lexicon in the corresponding 
sense entry. 
        
 
interactive construction 
 
linking 
 
indirect relation  
Corpus 
CSP 
CCD Lexicon 
CSD 
Fig 2. The dynamic model between the CSP, CSD and CCD 
Fig3. The word sense annotating interface 
127
According to the sense specification in CSD the 
human annotator assigns semantic tags to the word 
occurrences in CSP. The operation is quite easy. 
When the annotator double clicks the appropriate 
sense entry in CSD the sense tag is automatically 
added to the target word.  
The notable feature in this word sense annotat-
ing interface is that it provides flexible searching 
schemes. 1) Search sequentially (forward or back-
ward) all the instances of an ambiguous words re-
gardless of the annotating state; 2) Search sequen-
tially (forward or backward) the already annotated 
instances; 3) Search sequentially (forward or back-
ward) the yet un-annotated instances and 4) Search 
the instances of a specific ambiguous word (the 
window named Find/Replace in figure3, and again 
is shown in figure 4 for clearness). 
The tool of Find/Replace is widely used in this 
project and has proven to be effective in annotating 
word senses. It allows the annotator to search for a 
specific word to finish tagging all its occurrences 
in the same period of time rather than move se-
quentially through the text. The consistency is 
more easily kept when the annotator manages 
many different instances of the same word than 
handle a few occurrences of many different words 
in a specific time frame, because the former 
method enables the annotator to establish an inte-
grative knowledge system about a specific word 
and its sense distinction. Also the tool of 
Find/Replace provides flexible searching schemes 
for a specific ambiguous word. For instance, 
search in the corpus with different directions (for-
ward/backward) and search with different annotat-
ing states (annotated/un-annotated/both). Using the 
tool the annotator can also replace some specific 
word occurrences in the corpus (often with special 
POS tags) with a sense tag, thus can finish annotat-
ing the corpus quickly and with a batch method. 
For instance the POS tag of ?vq? (means verb 
complement) often uniquely corresponds to a spe-
cific verb sense such as ??/vq??/vq!8?. 
There is the status bar in the bottom line of the 
word sense annotating interface, and there clearly 
show the annotating status: the total word occur-
rences, the serial number of the current processing 
instance and the number of the already annotated 
instances.  
 
 
Fig.4  The tool of Find/Replace 
 
3.2 Linking between CSD and CCD 
The feature-based description of word meanings in 
CSD describes mainly the syntagmatic information, 
such as the subcategory frames of verbs, the se-
mantic categories of the head noun of adjectives, 
but cannot include the paradigmatic relations. 
WordNet is a popular open resource and has been 
widely experimented in WSD researches. Chinese 
Concept Dictionary (CCD) is a WordNet-like Chi-
nese lexicon (Liu et al, 2002), which carries the 
main relations defined in WordNet and can be seen 
as a bilingual concept lexicon with the parallel 
Chinese-English concepts to be simultaneously 
included. So the linking between the sense entries 
in CSD and the synsets in CCD is tried to establish 
in this project. After the linking has been estab-
lished, the paradigmatic relations (such as hy-
pernym / hyponym, meronym / holonym) ex-
pressed in CCD can map automatically to the sense 
entry in CSD. What?s more, the many existing 
WSD approaches based on WordNet can be trained 
and tested on the Chinese sense tagged corpus. 
In the right section of the word sense annotating 
interface there displays the synset information 
from CCD. When coping with a specific ambigu-
ous word (such as ??/open?) in CSD, the linking 
between CSD and CCD is automatically estab-
lished with the word itself (??/open?) as the pri-
mary key. And then all the synsets of the word 
(??/open?) in CCD, along with the hypernyms of 
each sense (expressed by the first word in a synset), 
are displayed in the right section. A synset selec-
tion window (namely Set synsets) containing the 
offset numbers of the synsets then appears in the 
right section. The annotator clicks on the appropri-
ate box(es) before the corresponding offset number 
and then the offset number is automatically added 
128
to the feature ?CCD? in the currently selected 
sense entry in CSD. 
The linking is now done manually. Unfortu-
nately some of the ambiguous words existing in 
CSD are not included in CCD. This also provides a 
good way to improve the coverage and quality of 
CCD.  
4 Consistency Checking 
Consistency is always an important concern for 
hand-annotated corpus, and is even critical for the 
sense tagged corpus due to the subtle meanings to 
handle. A software tool namely Sense Consistency 
Checker is developed in the checking procedure. 
The checker extracts all the instances of a specific 
ambiguous word into a checking file with the for-
mat of the sense concordances (as shown in figure 
5 ). The checking file enables the checker to have a 
closer examination of how the senses are used and 
distributed, and to form a general view of how the 
sense distinctions are made. The inter-annotator in-
agreement thus can be reached quickly and cor-
rectly. As illustrated in figure 5, it is obviously an 
error to assign the same semantic tag to ??/drive 
??/car? and ???/meeting ?/held?. Simply as 
it is the checker greatly accelerates the checking 
speed and improve the consistency. 
 
 
Fig. 5. Some example sentences in the checking file of ??/open? 
 
Together five researchers took part in the anno-
tation, of which three are majored in linguistics 
and two are majored in computational linguistics. 
In this project the annotators are also checkers, 
who check other annotators? work. A text gener-
ally is first tagged by one annotator and then veri-
fied by two checkers. 
After the preprocessing of word segmentation 
and Pos tagging, the word sense annotating and 
the consistency checking, the Chinese word sense 
annotated corpus is constructed. And then other 
software tools are needed to do further processing 
in the sense annotated corpus. 
5 XML format transforming 
The original format of the Chinese sense anno-
tated corpus is in text file as shown in figure 6. In 
the text file the sign following ?/? denotes the 
POS tag, and the number following ?!? indicates 
the sense ID. The text file complies with the other 
language resources at the Institute of Computa-
tional Linguistics, Peking University, which pro-
vides a quite easy way to make full use of the ex-
isting resources and techniques at ICL/PKU when 
constructing the sense annotated corpus.  
At the same time in order to exchange and 
share information easily with other language re-
sources in the world, a software tool namely Text-
to-XML Transformer is developed to change the 
text to XML format (as shown in figure 7). In the 
XML file, the item ?pos? denotes the POS tag of 
the word, and the item ?senseid? denotes sense ID 
of the ambiguous word. 
Thus there are two kinds of format for the Chi-
nese sense annotated corpus, each of which has its 
advantages and can be adopted to meet different 
requirements in different situations. 
 
129
 
 
 
 
 
Fig. 6. The sense annotated corpus in text file 
??/a  ?/u  ??/vn  ?/vt!2  ??/b  ??/n  ?/p  ?/m  ?/q!1  ?/r2  ??/n  ??/n  ??/vi  ?/u  ??/d  ??/a  
?/u  ??/n  ?/w  ??/vn  ??/n  ??/d  ??/vt  ?/w  ??/t  ???/n  ?/r  ?/q  ??/vn  ??/n  ?/d  ?/vt!3  ?
/v  9000/m  ?/m  ?/q ?/w 
 
<head date="20000201" page="01" articleno="003" passageno="019"> 
<passage> 
????????????????????????????????????????????????? 
??? 9000?? 
</passage> 
<postagging> 
<word id="0" pos="a" senseid=""> 
<token>??</token> 
</word> 
<word id="1" pos="u" senseid=""> 
<token>?</token> 
</word> 
<word id="2" pos="vn" senseid=""> 
<token>??</token> 
</word> 
<word id="3" pos="vt" senseid="2"> 
<token>?</token> 
</word> 
??   ?? 
 
Fig. 7. The sense annotated corpus in XML format 
 
6 Sense frequency calculating 
Word sense frequency distribution in the real texts 
is a vital kind of information both for the algo-
rithms of word sense disambiguation and for the 
research on lexical semantics. In the postprocess-
ing stage a software tool namely Sense Frequency 
Counter is developed to make statistics on the 
sense frequency distribution. Quite valuable in-
formation can be acquired through the counter 
based on the sense annotated corpus: 1) The 
amount of all the instances of an ambiguous word; 
2) The number of the already annotated instances; 
3) The occurrence of each sense of an ambiguous 
word and 4) The sense frequency. Table 1 illus-
trates the sense frequency distribution of ambigu-
ous verb ??/open? in 10 day?s People?s Daily. 
7 Conclusions 
This paper describes the overall building proce-
dure of a Chinese sense annotated corpus. The 
corpus is firstly word segmented and POS tagging 
using Peking University?s tagger in the preproc-
essing stage. Then the lexicon Chinese Semantic 
Dictionary (CSD) containing sense descriptions 
and the corpus Chinese Senses Pool (CSP) anno-
tated with senses are built interactively, simulta-
neously and dynamically using the word sense 
annotating interface. At the same time the linking 
between the sense entries in CSD and the synsets 
in Chinese Concept Dictionary (CCD) are manu-
ally established. And then the Sense Consistency 
Checker is used to keep the inter-annotator 
agreement. Finally two software tools are devel-
oped to do further processing based on the sense 
annotated corpus. A software tool namely Text-to-
XML Transformer is developed to change the text 
to XML format, and the Sense Frequency Counter 
is developed to make statistics on the sense fre-
quency distribution. The annotation schemes and 
all the software tools have been experimented in 
building the SemEval-2007 task 5 ?Multilingual 
Chinese-English Lexical Sample Task?, and have 
proven to be effective. 
 
 
130
Table 1 the sense frequency distribution of ambiguous verb ??/open? 
Ambiguous verbs Sense ID Occurrences Frequency(%) 
? 8 30 32.26
? 4 13 13.98
? 6 12 12.90
? 7 8 8.60
? 0 6 6.45
? 1 6 6.45
? 9 4 4.30
? 12 4 4.30
? 11 3 3.23
? 2 3 3.23
? 10 3 3.23
? 14 1 1.08
? 15 0 0.00
? 3 0 0.00
? 5 0 0.00
? 13 0 0.00
Acknowledgments. This research is supported by 
Humanity and Social Science Research Project of 
China State Education Ministry (No. 06JC740001) 
and National Basic Research Program of China 
(No. 2004CB318102). 
References 
Huang, Ch. R and Chen, K. J. 1992. A Chinese Corpus 
for Linguistics Research. In Proceedings of COL-
ING-1992. 
Huang, Ch. R., Chen, Ch. L., Weng C. X. and Chen. K. 
J. 2004. The Sinica Sense Management System: De-
sign and Implementation. In Recent advancement in 
Chinese lexical semantics. 
Landes, S., Leacock, C. and Tengi, R. 1999. Building 
Semantic Concordances. In Christiane Fellbaum 
(Ed.) WordNet: an Electronic Lexical Database. 
MIT Press, Cambridge. 
Li, J. 1999. The research on Chinese word sense dis-
ambiguation. Doctoral dissertation in computer sci-
ence department of Tsinghua University. 
Liu, Y., Yu, S. W. and Yu, J.S. 2002. Building a Bilin-
gual WordNet-like Lexicon: the New Approach and 
Algorithms. In Proceedings of COLING 2002.  
Tanaka, T., Bond F. and Fujita, S. 2006. The Hinoki 
Sensebank----A large-scale word sense tagged cor-
pus of Japanese. In Proceedings of the Workshop on 
Frontiers in Linguistically Annotated Corpora 2006. 
Veronis, J. 2003. Sense Tagging: Does It Make Sense? 
In Wilson et al (Eds). Corpus Linguistics by the 
Rule: a Festschrift for Geoffrey Leech.  
Xue, N., Chiou, F. D. and Palmer, M. 2002. Building a 
Large-Scale Annotated Chinese Corpus. In Proceed-
ings of COLING 2002. 
Yu, S. W., Duan, H. M., Zhu, X. F., Swen, B. and 
Chang, B. B. 2003. Specification for Corpus Proc-
essing at Peking University: Word Segmentation, 
POS tagging and Phonetic Notation. Journal of Chi-
nese Language and Computing. 
 
131
Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 19?23,
Prague, June 2007. c?2007 Association for Computational Linguistics
SemEval-2007 Task 5: Multilingual Chinese-English Lexical Sample 
Peng Jin, Yunfang Wu and Shiwen Yu 
Institute of Computational Linguistics  
 Peking University, Beijing China 
{jandp, wuyf, yusw}@pku.edu.cn 
 
 
Abstract 
The Multilingual Chinese-English lexical 
sample task at SemEval-2007 provides a 
framework to evaluate Chinese word sense 
disambiguation and to promote research. 
This paper reports on the task preparation 
and the results of six participants. 
1 Introduction 
The Multilingual Chinese-English lexical sample 
task is designed following the leading ideas of the 
Senseval-3 Multilingual English-Hindi lexical 
sample task (Chklovski et al, 2004). The ?sense 
tags? for the ambiguous Chinese target words are 
given in the form of their English translations. 
The data preparation is introduced in the second 
section. And then the participating systems are 
briefly described and their scores are listed.  
In the conclusions we bring forward some sug-
gestion for the next campaign. 
2 Chinese Word Sense Annotated Corpus 
All the training and test data come from the 
People?s Daily in January, February and March of 
2000. The People?s Daily is the most popular 
newspaper in China and is open domain. Before 
manually sense annotating, the texts have been 
word-segmented and part of speech (PoS) tagged 
according to the PoS tagging scheme of Institute of 
Computational Linguistics in Peking University 
(ICL/PKU). The corpus had been used as one of 
the gold-standard data set for the second 
international Chinese word segmentation bakeoff 
in 2005.1
2.1 Manual Annotation 
The sense annotated corpus is manually con-
structed with the help of a word sense annotating 
interface developed in Java. Three native annota-
tors, two major in Chinese linguistics and one ma-
jor in computer science took part in the construc-
tion of the sense-annotated corpus. A text generally 
is first annotated by one annotator and then veri-
fied by two checkers. Checking is of course a nec-
essary procedure to keep the consistency. Inspired 
by the observation that checking all the instances 
of a word in a specific time frame will greatly im-
prove the precision and accelerate the speed, a 
software tool is designed in Java to gather all the 
occurrences of a word in the corpus into a check-
ing file with the sense KWIC (Key Word in Con-
text) format in sense tags order. The inter-
annotator agreement gets to 84.8% according to 
Wu. et al (2006). 
The sense entries are specified in the Chinese 
Semantic Dictionary (CSD) developed by 
ICL/PKU. The sense distinctions are made mainly 
according to the Contemporary Chinese Dictionary, 
the most widely used dictionary in mandarin Chi-
nese, with necessary adjustment and improvement 
is implemented according to words usage in real 
texts. Word senses are described using the feature-
based formalism.  The features, which appear in 
the form ?Attribute =Value?, can incorporate ex-
tensive distributional information about a word 
sense. The feature set constitutes the representation 
of a sense, while the verbal definitions of meaning 
                                                 
1 http://sighan.cs.uchicago.edu/bakeoff2005/ 
19
serve only as references for human use. The Eng-
lish translation is assigned to each sense in the at-
tribute ?English translation? in CSD. 
Based on the sense-annotated corpus, a sense is 
replaced by its English translation, which might 
group different senses together under the same 
English word. 
2.2 Instances selection 
In this task together 40 Chinese ambiguous words: 
19 nouns and 21 verbs are selected for the evalua-
tion. Each sense of one word is provided at least 15 
instances and at most 40 instances, in which 
around 2/3 is used as the training data and 1/3 as 
the test data. Table 1 presents the number of words 
under each part of speech, the average number of 
senses for each PoS and the number of instances 
respectively in the training and test set. 
 
 # Average 
senses 
# training 
instances 
# test 
instances
19 
nouns 
2.58 1019 364 
21 
verbs 
3.57 1667 571 
 
Table 1: Summary of the sense inventory and 
number of training data and test set 
 
In order to escape from the sense-skewed distri-
bution that really exists in the corpus of People?s 
Daily, many instances of some senses have been 
removed from the sense annotated corpus. So the 
sense distribution of the ambiguous words in this 
task does not reflect the usages in real texts. 
3 Participating Systems 
In order to facilitate participators to select the fea-
tures, we gave a specification for the PoS-tag set. 
Both word-segmented and un-segmented context 
are provided. 
Two kinds of precisions are evaluated. One is 
micro-average: 
 
??
==
=
N
i
i
N
i
imir nmP
11
/  
 
N  is the number of all target word-types. is 
the number of labeled correctly to one specific tar-
get word-type and  is the number of all test in-
stances for this word-type. 
im
in
The other is macro-average: 
 
?
=
=
N
i
imar NpP
1
/ ,  iii nmp /=
 
All teams attempted all test instances. So the re-
call is the same with the precision. The precision 
baseline is obtained by the most frequent sense. 
Because the corpus is not reflected the real usage, 
the precision is very low. 
Six teams participated in this word sense disam-
biguation task. Four of them used supervised learn-
ing algorithms and two used un-supervised method. 
For each team two kinds of precision are given as 
in table 2.  
 
Team Micro-average Macro-average
SRCB-WSD 0.716578 0.749236 
I2R 0.712299 0.746824 
CITYU-HIF 0.710160 0.748761 
SWAT 0.657754 0.692487 
TorMd 0.375401 0.431243 
HIT 0.336898 0.395993 
baseline 0.4053 0.4618 
 
Table 2: The scores of all participating systems 
 
As follow the participating systems are briefly 
introduced. 
SRCB-WSD system exploited maximum entropy 
model as the classifier from OpenNLP2 The fol-
lowing features are used in this WSD system: 
 
? All the verbs and nouns in the context, that is, 
the words with tags ?n, nr, ns, nt, nz, v, vd, vn?  
? PoS of the left word and the right word 
?noun phrase, verb phrase, adjective phrase, 
time phrase, place phrase and quantity phrase. 
These phrases are considered as constituents of 
context, as well as words and punctuations which 
do not belong to any phrase.  
?the type of these phrases which are around the 
target phrases   
                                                 
2 http:// maxent.sourceforge.net/ 
20
? word category information comes from Chi-
nese thesaurus 
 
I2R system used a semi-supervised classification 
algorithm (label propagation algorithm) (Niu, et al, 
2005). They used three types of features: PoS of 
neighboring words with position information, un-
ordered single words in topical context, and local 
collocations.  
In the label propagation algorithm (LP) (Zhu 
and Ghahramani, 2002), label information of any 
vertex in a graph is propagated to nearby vertices 
through weighted edges until a global stable stage 
is achieved. Larger edge weights allow labels to 
travel through easier. Thus the closer the examples, 
the more likely they have similar labels (the global 
consistency assumption). In label propagation 
process, the soft label of each initial labeled exam-
ple is clamped in each iteration to replenish label 
sources from these labeled data. Thus the labeled 
data act like sources to push out labels through 
unlabeled data. With this push from labeled exam-
ples, the class boundaries will be pushed through 
edges with large weights and settle in gaps along 
edges with small weights. If the data structure fits 
the classification goal, then LP algorithm can use 
these unlabeled data to help learning classification 
plane. 
CITYU-HIF system was a fully supervised one 
based on a Na?ve Bayes classifier with simple fea-
ture selection for each target word.  The features 
used are as follows: 
 
? Local features at specified positions: 
PoS of word at w-2, w-1, w1, w2
Word at w-2, w-1, w1, w2
? Topical features within a given window: 
Content words appearing within w-10 to w10
? Syntactic features: 
PoS bi-gram at w-2w0 , w-1w0 , w0w1 , w0w2
PoS tri-gram at w-2 w-1w0 and w0w1w2
 
One characteristic of this system is the incorpo-
ration of the intrinsic nature of each target word in 
disambiguation. It is assumed that WSD is highly 
lexically sensitive and each word is best character-
ized by different lexical information. Human 
judged to consider for each target word the type of 
disambiguation information if they found useful.  
During disambiguation, they run two Na?ve Bayes 
classifiers, one on all features above, and the other 
only on the type of information deemed useful by 
the human judges. When the probability of the best 
guess from the former is under a certain threshold, 
the best guess from the latter was used instead.  
SWAT system uses a weighted vote from three 
different classifiers to make the prediction. The 
three systems are: a Na?ve Bayes classifier that 
compares similarities based on Bayes' Rule, a clas-
sifier that creates a decision list of context features, 
and a classifier that compares the angles between 
vectors of the features found most commonly with 
each sense. The features include bigrams, and tri-
grams, and unigrams are weighted by distance 
from the ambiguous word. 
TorMd used an unsupervised naive Bayes classi-
fier. They combine Chinese text and an English 
thesaurus to create a `Chinese word'--`English 
category' co-occurrence matrix. This system gener-
ated the prior-probabilities and likelihoods of a 
Na?ve Bayes word sense classifier not from sense-
annotated (in this case English translation anno-
tated) data, but from this word--category co-
occurrence matrix. They used the Macquarie The-
saurus as very coarse sense inventory. 
They asked a native speaker of Chinese to map 
the English translations of the target words to ap-
propriate thesaurus categories. Once the Na?ve 
Bayes classifier identifies a particular category as 
the intended sense, the mapping file is used to label 
the target word with the corresponding English 
translation. They rely simply on the bag of words 
that co-occur with the target word (window size of 
5 words on either side). 
HIT is a fully unsupervised WSD system, which 
puts bag of words of Chinese sentences and the 
English translations of target ambiguous word to 
search engine (Google and Baidu). Then they 
could get al kinds of statistic data. The correct 
translation was found through comparing their 
cross entropy. 
4 Conclusion 
The goal of this task is to create a framework to 
evaluate Chinese word sense disambiguation and 
to promote research. 
21
 
Scores Target 
Word 
Sen
se # 
Train
ing # 
Test 
# 
Base-
line SRCB
-WSD
I2R CITY
U-HIF
SWA
T-MP
TOR
MD 
HIT 
? 3 63 20 .50 .70 .80 .75 .75 .55 .55 
?? 3 73 27 .370 .778 .815 .741 .778 .481 .407 
? 4 69 23 .435 .696 .609 .696 .696 .174 .174 
? 9 222 77 .130 .506 .506 .481 .532 .169 .091 
? 8 197 67 .150 .567 .552 .537 .433 .119 .104 
? 4 58 20 .50 .60 .50 .55 .60 .30 .30 
?? 2 47 16 .625 .875 .875 .875 .563 .50 .438 
? 5 105 36 .278 .694 .667 .611 .889 .25 .139 
? 3 56 18 .50 .667 .722 .667 .667 .389 .333 
? 4 106 39 .256 .718 .615 .641 .538 .256 .256 
? 5 132 44 .227 .659 .75 .727 .568 .25 .114 
?? 2 56 20 .50 .90 .95 .95 .60 .50 .50 
? 4 103 34 .294 .765 .706 .765 .559 .294 .294 
?? 2 20 8 .50 .75 .75 .75 .625 .375 .50 
? 2 46 16 .625 .938 .813 .813 .875 .563 .438 
?? 2 60 18 .556 .667 .722 .778 .722 .444 .556 
? 2 40 14 .429 .571 .643 .571 .571 .143 .286 
?? 2 29 10 .60 .80 .70 .90 .80 .30 .30 
? 2 37 13 .769 .769 .769 .769 .769 .462 .462 
? 4 110 37 .270 .730 .676 .676 .541 .216 .216 
?? 2 38 14 .714 .930 1.0 .929 .786 .714 .571 
Ave. 3.5
7 
1667 571 .342/ 
.44 
.685/   
.728 
.676/   
.721 
.671/   
.723 
.618/   
.66 
.30/     
.355 
.263/   
.335 
 
 Table 3: Performance on verbs. Micro / macro average precisions are spitted by ?/? at the last row. 
 
Together six teams participate in this WSD task, 
four of them adopt supervised learning methods 
and two of them used unsupervised algorithms. All 
of the four supervised learning systems exceed ob-
viously the baseline obtained by the most frequent 
sense. It is noted that the performances of the first 
three systems are very close. Two unsupervised 
methods? scores are below the baseline. More 
unlabeled data maybe improve their performance.  
Although the SRCB-WSD system got the high-
est scores among the six participants, it does not 
perform always better than other system from table 
2 and table 3. But to each word, the four super-
vised systems always predict correctly more in-
stances than the two un-supervised systems.  
Besides the corpus, we provide a specification of 
the PoS tag set. Only SRCB-WSD system utilized 
this knowledge in feature selection. We will pro-
vide more instances in the next campaign. 
22
Scores Target 
Word 
Sen
se # 
Train
ing # 
Test 
# 
Base-
line SRCB
-WSD
I2R CITY
U-HIF
SWA
T-MP
TOR
MD 
HIT 
? 3 68 25 .40 .88 .84 .88 .76 .72 .32 
?? 2 53 18 .611 .611 .722 .722 .833 .556 .333 
? 2 56 19 .526 .842 .842 .684 .789 .474 .632 
?? 3 48 21 .476 .571 .591 .619 .619 .429 .619 
?? 2 50 17 .588 .824 .824 .824 .647 .706 .529 
? 3 53 18 .50 .778 .722 .778 .611 .50 .222 
?? 3 64 22 .455 .591 .591 .636 .545 .318 .364 
?? 2 60 20 .50 1.0 .95 1.0 1.0 .50 .50 
?? 2 38 14 .714 1.0 1.0 1.0 1.0 .643 .571 
?? 2 45 15 .533 .733 .733 .60 .467 .467 .467 
? 3 67 23 .435 .783 .783 .739 .696 .348 .696 
?? 2 44 17 .353 .529 .589 .588 .588 .353 .529 
?? 3 50 18 .556 .611 .611 .722 .722 .50 .111 
?? 2 39 14 .714 .929 .786 .714 .786 .857 .571 
?? 2 47 16 .625 .813 .813 .938 1.0 .438 .563 
?? 3 88 32 .313 .656 .563 .625 .656 .281 .344 
?? 3 65 25 .40 .88 1.0 .92 .60 .56 .44 
?? 2 41 14 .714 .786 .714 .786 .643 .714 .50 
?? 2 43 16 .625 .875 .938 1.0 .875 .438 .50 
Ave. 2.4
5 
1019 364 .506/ 
.528
.766/   
.773 
.761/ 
.769
.772/  
.778 
.72/     
.728 
.50/     
.516 
.456/   
.464 
  
Table 4: Performance on nouns. Micro / macro average precisions are spitted by ?/? at the last row. 
 
5 Acknowledgements 
This research is supported by Humanity and Social 
Science Research Project of China State Education 
Ministry (No. 06JC740001) and National Basic 
Research Program of China (No. 2004CB318102). 
We would like to thank Tao Guo and Yulai Pei 
for their hard work to guarantee the quality of the 
corpus. Huiming Duan provides us the corpus 
which has been word-segmented and PoS-tagged 
and gives some suggestions during the manual an-
notation. 
References 
Rada Mihalcea, Timothy Chklovski and Adam Kilgar-
riff. 2004. The Senseval-3 English lexical sample 
task. Proceedings of SENSEVAL-3. 25-28. 
Timothy Chklovski, Rada Mihalcea, Ted Pedersen and 
Amruta Purandare. 2004. The Senseval-3 Multilin- 
 
 
gual English-Hindi lexical sample task. Proceedings of 
SENSEVAL-3. 5-8. 
Xiaojin Zhu, Zoubin Ghahramani. 2002. Learning from 
Labeled and Unlabeled Data with Label Propagation. 
CMU CALD tech report CMU-CALD-02-107. 
Yunfang Wu, Peng Jin, Yangsen Zhang, and Shiwen Yu. 
2006. A Chinese Corpus with Word Sense Annota-
tion. Proceedings of ICCPOL, Singapore, 414-421. 
Zhen-Yu Niu, Dong-Hong Ji and Chew-Lim Tan. 2005. 
Word Sense Disambiguation Using Label Propaga-
tion Based Semi Supervised Learning. Proceedings 
of the 43rd Annual Meeting of the Association for 
Computational Linguistics.395-402 
23
Coling 2010: Poster Volume, pages 1238?1246,
Beijing, August 2010
Semi-Supervised WSD in Selectional Preferences
with Semantic Redundancy 
Xuri TANG1,5  , Xiaohe CHEN1 , Weiguang QU2,3 and Shiwen YU4
1. School of Chinese Language and Literature, Nanjing Normal University 
{xrtang,chenxiaohe5209}@126.com
2. Jiangsu Research Center of Information Security & Privacy Technology
3. School of Computer Science, Nanjing Normal University 
 wgqu_nj@163.com 
4. Institute of Computational Linguistics , Peking University 
yusw@pku.edu.cn
5. College of Foreign Studies, Wuhan Textile University 
Abstract
This paper proposes a semi-supervised 
approach for WSD in Word-Class 
based selectional preferences. The 
approach exploits syntagmatic and 
paradigmatic semantic redundancy in 
the semantic system and uses 
association computation and minimum 
description length for the task of WSD. 
Experiments on Predicate-Object 
collocations and Subject-Predicate 
collocations with polysemous 
predicates in Chinese show that the 
proposed approach achieves a precision 
which is 8% higher than the semantic-
association based baseline. The semi-
supervised nature of the approach 
makes it promising for constructing 
large scale selectional preference 
knowledge base. 
1 Introduction 
This paper addresses word sense 
disambiguation (WSD) which is required in 
the construction of selectional preference (SP) 
knowledge database. In previous literature of 
SP, four different types of formalization 
models are explicitly or implicitly employed. 
Two types are distinguished in Li and 
Abe(1998):
Word Model: ?=),|( rvnP     (1) 
Class Model: ?=),|( rvCP         (2) 
where v stands for verb, n for noun, C for the 
semantic class of n, r for the grammatical 
relation between v and n, and P for the 
preference strength. Most of the 
researches(Resnik 1996; Li and Abe 1998; 
Ciaramita and Johnson 2000; Brockmann and 
Lapata 2003; Light and Greiff 2002) uses the 
class model, and a few(Erk 2007) uses the 
word model. The other two types of model are 
given as below: 
Class-Only Model: ?=),|( rCCP vn        (3) 
Word-Class Model: ?=),,|,( rCvCnP vn  (4) 
where ,  are semantic classes for the 
noun and verb respectively. Class-Only model 
considers solely the semantic classes, while 
Word-Class model considers both words and 
semantic classes. Agirre and Martinez(2001) 
and Zheng et al2007) adopted the Class-only 
Model in research, while in McCarthy and  
Carroll(2003) and Merlo and Stevenson(2001) 
the Word-Class Model is employed. 
nC vC
Among the four models, the Word-Class 
Model is the type which possesses the most 
granulated knowledge and is the most potential 
in applications. McCarthy and Carroll(2003) 
reports that the Word-Class Model performs 
well in unsupervised WSD. In other NLP tasks 
such as metaphor recognition, this model may 
be indispensable. For instance, to distinguish 
the  predicate verb  ???(float)?  in  Ex(1a) as 
Ex. 1
a.
? ? ? ?
leaf floats b.
? ? ? ?
price floats
1238
literal and Ex(1b) as metaphorical requires 
different interpretations of the verb.  
The present research is concerned with 
WSD as in the Word-Class model. Particularly, 
it aims at disambiguating predicates in subject-
predicate (Subj-Pred) and predicate-object 
(Pred-Obj) constructions. The motivations 
behind the research are two folds. Firstly, 
semi-supervised and unsupervised WSD in SP 
are not fully explored. Merlo and 
Stevenson(Merlo and Stevenson 2001) 
employs supervised learning from large 
annotated corpus, which is difficult to obtain. 
One known unsupervised learning approach 
for WSD in SP is McCarthy and Carroll(2003) 
which addresses the issue via conditional 
probability. The other motivation derives from 
the fact few research is done on selectional 
preferences in languages other than English, as 
is stated in Brockmann and Lapata(2003). For 
instance, studies on construction of SP 
knowledge database in Chinese can only be 
found in Wu et al2005), Zhen et al2007), Jia 
and Yu(2008) and some others.  
The basic idea of the approach proposed for 
WSD in the paper is that the most acceptable 
interpretation of senses for a given 
construction is the pair of senses which 
encodes the most redundant information in the 
semantic system of the language. Two 
principles, namely Syntagmatic Redundancy 
Principle and Paradigmatic Redundancy 
Principle, are proposed in the paper to capture 
the intuition. Two corresponding devices are 
employed to model the two principles: 
Association for Syntagmatic Redundancy 
Principle and Minimum Description Length for 
Paradigmatic Redundancy Principle. Two 
experiments are conducted in the paper. The 
first is based on semantic association, 
achieving a 61.98% precision for predicates in 
Subj-Preds and 62.54% in Pred-Objs. This 
experiment is used as baseline as the approach 
is also used in McCarthy and Carroll(2003) for 
verb and adjective disambiguation. In the 
second experiment, both semantic association 
and MDL are employed, the precision of WSD 
amounts to 69.88% and 69.09% for predicates 
in Subj-Preds and Pred-Objs respectively, 
indicating that a combination of the two 
devices are fairly effective in disambiguating 
word senses for SP. 
The rest of the paper is organized as below. 
The second part gives further illustration of the 
rationale for the approach. The third part 
describes the procedure and the fourth part 
discusses the experiment result. The thesis 
concludes with some speculations in further 
researches. 
2 Rationale
2.1 Task Formalization 
Consider a Subj-Pred or Pred-Obj 
collocation C=< , > , where  is 
the word of predicate and  is the word of 
argument.  has M senses, denoted by set 
.  has N senses, denoted by .
The possible interpretation of C has M*N 
possibilities, denoted by 
={ | =< , >},
where  is called a sense collocation. The 
task of WSD is to search for a particular sense 
collocation in  and assign it to C as its 
interpretation. At the initial stage, each sense 
collocation in  is considered to have an 
even number of frequency, namely 
. Accordingly, for each 
, , For each 
, .
predW
arg ?
CS
CS
)M?
sf ipred(
s i 1)arg =
argW
W
i
j
i
j
?
) =
N/
predW
argS
jsarg
arg
M/1
predW
arg
S?
/(1 N
pred
f (
predS
SC =
(f ij?
i
preds
args i ?
W
S pred
i
j
?
=
S
argS
i
preds
)
?
2.2 Syntagmatic Redundancy Principle 
Syntagmatic Redundancy Principle (SRP) 
can be stated as following: among all possible 
sense collocations for a word collocation, the 
most appropriate is the one in which senses 
exhibit the most redundant information 
between each other. 
 The syntagmatic redundancy between 
words has been noticed very early by linguists 
and has been applied in WSD. Firth(1957) 
argues that there exists ?mutual expectancy? 
between words in collocations, and the 
meaning of word is partially encoded in its 
juxtaposition. Lyons(1977:261) comments that 
Porzig has noticed in 1934 the ?essential 
meaning relation? between words of 
collocations like ?dog barks? and ?tree fells? 
1239
and emphasizes that the meanings of 
collocationally restricted lexemes such as 
?bark? and ?fell? can only be explained by 
taking into account the collocates they occur 
with. This notion is also employed in 
Yarowsky(1995) for WSD, in which the key is 
the ?one-sense-per-collocation? statement. 
McCarthy and Carroll(2003) also uses this 
type of redundancy for disambiguation in SP.  
SRP can be explained as a statistic 
correlation between  and . The more 
co-relevant these two senses are, the more 
likely the pair is to be accepted as the 
appropriate interpretation.  This can be 
described as below: 
preds args
),(maxarg arg
ji
pred
i
j ssAssoc=?    (5) 
where is the function for 
sense association. Four methods can be 
considered for association computation: 
conditional probability (Formula 6 and 7), 
Lift(Han and Kamber 2006:261) (Formula 8), 
All-Confidence(Han and Kamber 2006:263)  
(Formula 9) and cosine (Formula 10). Note 
that two versions of conditional probability are 
considered, as are denoted in Formula 6 and 7. 
The first version, Cond-Prob 1, takes argument 
sense as condition, while the second version 
Cond-Prob 2 takes predicate sense as condition. 
  ),( arg
ji
pred ssAssoc
)(
),(
)|(
arg
arg
arg j
ij
predji
pred sp
ssp
ssp =             (6) 
)(
),(
)|( argarg i
pred
ij
predj
pred
i
sp
ssp
ssp =                 (7) 
)(*)(
),(
),(
arg
arg
arg ji
pred
ji
predji
pred spsp
ssp
sslift =              (8) 
))(),(max(
),(
),(_
arg
arg
arg j
pred
i
ji
predji
pred cfsf
ssf
ssconfall =         (9) 
)(*)(
),(
),(cos
arg
arg
arg ji
pred
ji
predji
pred
spsp
ssp
ssine =            (10) 
2.3 Paradigmatic Redundancy Principle 
Paradigmatic Redundancy Principle (PRP) 
can be stated as following: among all possible 
sense collocations for a word collocation, the 
most appropriate is the one which is also 
implicitly or explicitly expressed by other 
synonymous, metonymic or metaphorical word 
collocations.
Ex(2) illustrates the explicit redundancy in 
synonymous and metaphorical ways, in which 
the sense collocation ?[Price| ? ? ]
[QuantityChange|??]? is expressed by five 
word collocations, each with a different 
predicate : ?? (change), ?? (float), ??
(adjust),??(go up and down), ??(alter).  
Ex 2.
a.
????
price changes     b.
????
price floats     c.
? ? ? ?
price adjusts
d.
? ? ? ?
SULFHJRHVXSDQGGRZQe. ????price alters
Ex(3) reveals the implicit redundancy in 
metonymic way, in which the meaning ??
(human) ? ? (is eased)? is implicitly 
expressed in all the six collocations, 
established by  semantic relatedness among the 
arguments ????? (Maradona)?, ???
(student)?, ???(work)?, ???(labour)?, ??
?(driving)?, and ???(life)?.
Ex 3. 
a.
???????
Maradona is eased         b.
?? ?? ?
Student is eased
c.
?????
work is eased               d. 
?? ?? ?
labour is eased
e.
?? ?? ?
driving is eased             f. 
?????
Life is eased
To apply PRP, WSD in SP is casted as an 
issue of model selection. Given a set of word 
collocations , the process of WSD is to 
assign to each word collocation one sense 
collocation from a number of possibilities. 
Those assigned sense collocations form a set, 
or a model for ? . The goal of WSD in SP is 
to select from all those models the one which 
best interprets ? . For this purpose, Miminum 
Description Length(Barron et al 1998; Michell  
2003; MacKay 2003) can be used. MDL 
selects models by relying on induction bias 
based on Occam?s Razor, which stipulates that 
the simplest solution is usually the correct one. 
One way to interpret MDL in Bays? analysis is 
as below(Michell 2003:124): 
?
)|()(minarg' mDLmLm DM +=            (11) 
In (11)?  is the model description 
length when model m  is considered, 
 is the data description length when 
model  is used for description. The model 
with minimum length is the best model. 
)(mLM
)|( mDLD
m
1240
For model description length, we have 
adopted the method used in (Li and Abe 1998) 
which considers only the size of the model: 
)log(
2
1)(
)( NmsizemLM
?
=                   (12) 
where size(m) is the number of sense 
collocation contained in model m , and N is 
the number of word collocation in 
consideration. In this study, the set of word 
collocation with the same predicate word, 
denoted by ? , is used as the unit for model 
description length calculation instead of the 
whole corpus, so as to reduce computation 
complexity. Accordingly, each word 
collocation in ?  can be assigned one and only 
one sense collocation in the model m , out of 
all the potential sense collocations as is 
explained in section 2.1. 
Data description length is calculated on 
model and , as is denoted in formulas 
(13),  (14)  and (15) below. The  calculation  is   
m ?
??
?
?=?=? )
)(
log())(log()|(
2Num
f
pmL
i
ji
j
?
?
         (13) 
?
?
+=
m
k
l
i
j
i
j
i
j
i
j
k
l
i
j
wfff
??
?????
,
),(*)()()(         (14) 
??
?
?
?
?
=
=
><><=
k
pred
k
pred
ilj
lk
pred
ji
pred
k
l
i
j
s
sssrel
ssssrelw
i
pred
predargarg
argarg
s if                                 0
s if                ),(
             
),,,(),( ??
 (15) 
based on the probability of sense collocation 
, which in turn is calculated on a 
modified frequency of the collocation 
>=< jipred
i
j ss arg,?
)( ijf ? .
The frequency is modified by counting the 
explicit occurrence of the sense collocation 
itself and the implicit occurrence expressed by 
other sense collocations in ? . This idea is 
equivalent to enlarge the corpus by 1 fold, thus 
the overall collocation number is the two times 
of the original number.  
The modified frequency is a sum of two 
parts, denoted in formula (14). The first part is 
, the frequency of . The second part is 
the weighted frequency of . The weight is 
determined by the relatedness of the sense 
collocation  and all the other sense 
collocation in the model m. According to
this formula, if the sense collocation is found 
to be more similar to other sense collocations, 
it should obtain a higher modified frequency, 
and thus more likely to be the correct one for 
the word collocation.
)( ijf ?
i
j?
i
j?
i
j?
k
l?
The way to calculate the weight is given in 
formula (15). If two sense collocations have 
identical predicate sense, namely ,
then the weight between the two sense 
collocations is measured by rel , the 
semantic relatedness between the argument 
sense and . Otherwise, 0 is returned. 
There are different ways to measure sense 
relatedness. The present study has used 
semantic similarity based on HowNet(Liu and 
i 2002) to calculate the semantic relatedness. 
k
pred
i s=preds
),( argarg
lj ss
jsarg lsarg
L
3 Procedure
Figure 1 maps out the procedure for WSD in 
SP in the present study. The procedure is 
divided into two phases: data collection and 
disambiguation. The collocation data are 
collected from three sources: Sketch Engine, 
Collocation Dictionary and HowNet Examples. 
Two types of collocation data are collected: 
subject-predicate collocations (Subj-Pred) and 
predicate-object collocations (Pred-Obj) from 
Sketch Engine and Collocation Dictionary. 
Collocation Retriever reduces HowNet 
examples into Subj-Preds and Pred-Objs using 
simple heuristic methods. As a result, about 
70,000 subject-predicate collocations and 
106,000 predicate-object collocations are 
obtained.
Figure 1. WSD Procedure 
In disambiguation phase, two devices are
employed to filter out unlikely sense 
collocations: Association-Based Sense 
Collocation Filter, following SRP, and MDL-
Based Sense Collocation Filter, following PRP. 
Colloc Dict. 
HowNet Examples
MDL-Based Sense Colloc Filter
Assoc-Based Sense Colloc Filter
Collocation Retriever
Data Combination
Sketch Engine
Output
1241
In this phase, Subj-Preds and Pred-Objs are 
processed independently but following the 
same route.   
Each phase alone can perform WSD 
independently. Accordingly, two experiments 
are conducted to evaluate the method proposed 
in this paper. The first experiment uses 
association-based filter for word sense 
disambiguation, which is also used as the 
baseline. The approach is also used in 
(McCarthy and Carroll 2003) to disambiguate 
verbs and adjectives in collocations. To be 
particular, the method used by McCarthy and 
Carroll(2003) is formula (6). The second 
experiment is based on the result of the first 
one so as to observe the improvement obtained 
by MDL-Based approach. In the second 
experiment, unsupervised and semi-supervised 
WSD are also investigated by including some 
annotated collocations in the evaluation data. 
Two corpora are constructed for evaluation. 
One corpus is a set of 1034 subject-predicate 
constructions. The other is a set of 1841 
predicate-object constructions. Both are 
manually annotated by the authors with sense 
definitions defined in HowNet(Dong 2006). 
All together there are 52 highly ambiguous 
predicates involved in the study. 
4 Experiments and Discussion 
4.1 Collocation Retriever 
The major task in data collocation is in 
Collocation Retriever, which retrieves 
collocations from HowNet examples. Ex(4) 
gives a partial entry structure in HowNet,  
Ex 4. 
W_C=??
E_C=??~???~???????
?~
DEF=[change|?]
in which W_C stands for Chinese Word, DEF 
for definition, E_C for Examples of Chinese, 
and the wave ?~? for the word in question. 
From E_C, possible Subj-Preds such as ???
(public opinion) ??(floats)?, ???(index) 
??(floats)? can be retrieved, in which the 
sense of ???(float)? is annotated with DEF. 
But there are also noises. A simple heuristic 
method is applied to automatically filter out 
unwanted collocations. The heuristic method 
checks whether the collocation retrieved from 
HowNet share possible sense collocations with 
collocations in Collocation Dictionary. If yes, 
it is accepted as a collocation of the type, 
otherwise, it is rejected. Procedures are given 
below:
(a) Use Subj-Pred collocations and Pred-Obj 
collocations in Collocation Dictionary to build 
sense collocation set edSubj Pr?? and Objed??Pr ;
(b) For each example sentence in E_C, 
segment it using ICTCLAS1 to obtain an array 
of words. Words before ?~? forms potential 
Subj-Pred collocations and Words 
after form potential Pred-Obj collocations 
.
edSubj Pr??
ObjedB ?Pr
(c) For each or ,
construct possible sense collocation set 
edSubja Pr??? edSubjBb Pr??
a?  or 
b? , if ?????
? edSubja Pr
 or ?????
?Objedb Pr , add 
it as a Subj-Pred collocation or Pred-Obj 
collocation.
Evaluation on partial retrieved collocations 
shows that about 70% of obtained collocations 
are valid collocations, while about 30% are 
errors. Thus manual edition has been applied 
to rid those invalid collocations. 
4.2 Association-Based Filter 
Association-Based Sense Collocation Filter 
filters out those sense collocations that are very 
unlikely to be the right interpretation for a 
word collocation. Table 1 gives association 
computation result for the six senses related to 
the predicate ? ? (rough)? in Subj-Pred 
collocation ??? (personality) ? (rough)?. 
The 2nd , 3rd, 4th, and 6th are very unlikely 
interpretations and should be filtered, while the 
5th seems to be the most appropriate. 
Table 1. Association-Based Filter Example 
No.Pred Sense Arg Sense Assoc. Dgr
1 [Behavior|??][careless|??] 0.0019
2 [Behavior|??][coarse|?] 0.0002
3 [Behavior|??][hoarse|??] 0.0004
4 [Behavior|??][roughly|??] 0.0002
5 [Behavior|??][vulgar|?] 0.0071
6 [Behavior|??][widediameter|?] 0.0002
Following the procedure in Figure 1, to filter 
out those unlikely sense collocations, average 
1 A Chinese segmentation system, please refer to 
http://www.ictclas.org for further information. 
1242
association value is used as the filter and those 
below the average are dropped and those above 
are chosen for MDL-Based Filter. In Table 1, 
the average is 0.0017, and the 1rd and 5th are 
chosen.
However, in order to obtain a baseline and 
to decide which association computation 
model to use, we have followed the definition 
in Formula 5 and perform WSD test by 
choosing the sense collocation with highest 
association as the correct sense tags. for used 
this step solely for WSD, as is defined in 
Formula 4. Table 2 gives the experiment 
results for Subj-Pred and Pred-Obj collocations 
with all the association computation models 
denoted in Formula 6-10.
Table 2. WSD Result by Association 
Subj-Pred(%) Pred-Obj(%)
Cond-Prob 1 61.98 62.54
Cond-Prob 2 55.15 42.4
Lift 63.09 40.84
All_Conf 56.16 48.54
Cosine 58.83 55.72
One interesting phenomenon about all the 
five models is null-invariance. In selecting 
models for association computation, null-
invariance is an important feature to be 
considered(Han and Kamber 2006). A model 
with null-invariance is not influenced by 
additional irrelevant data and thus is more 
stable. In the experiment, the model Lift is the 
only one not featured with null-invariance. The 
experiments show that Lift is not stable in 
different collocation types, achieving high 
precision in Subj-Pred but low precision in 
Pred_Obj.
A second interesting phenomenon is 
collocation directionality exposed by the 
experiments, which can be observed in the two 
models of conditional probability: Cond-Prob 
1, with argument as condition, and Cond-Prob 
2, with predicate as condition. Directionality in 
collocation has been noticed earlier in some 
researches, for example Qu(2008). Our 
experiment shows that when using Cond-Prob 
1, we are able to get a precision of 61.98% and 
62.54% for Subj-Pred and Pred-Obj 
respectively, while Cond-Prob 2 gets a much 
lower precision. This fact can be interpreted 
that arguments tend to have a stronger 
selectional preference strength, and the 
possible selection range is comparatively 
narrower, while predicates have weaker 
selectional preference strength and a wider 
selectional range. 
4.3 MDL-Based Filter 
MDL-Based Filter takes as input result from 
Association-Based Filter using Cond-Prob 1 
for association computation and average 
association as filter. Table 3 and 4 give the 
final experiment outcome for Pred-Obj and 
Subj-Pred constructions and individual 
predicates.
It can be seen in Table 3 that MDL-Based 
Filter Several inferences can be made from the 
experiments. Firstly, comparison between 
Association-Based WSD (Table 2) and MDL 
WSD (Table 3) shows that MDL can improve 
overall performance up to 8%. As is mentioned 
earlier, Association-Based WSD is used as 
baseline in the present study. Given the fact 
that the average number of senses for word in 
question is fairly high, the improvement is 
considered as significant.  
Table 3. General WSD Results2
Ave. 
N.O.S.
Assoc.  
WSD (%) 
MDL
WSD (%) 
Subj-Pred 4.16 61.98 69.09
Pred-Obj 5.03 62.54 69.88
Analysis on the individual predicates in 
Table 4 gives a clearer picture of WDL-based 
WSD. Firstly, it can be seen that MDL is 
especially effective when the demarcation of 
word senses is clear-cut. Predicate words such 
as ??? (quiet)?, ??? (dirty)?, ???
(difficult)? in Subj-Preds and ??? (beat)?, 
???(touch)? and ???(break)? in Pred-Objs 
are successfully disambiguated in Table 4. 
These words generally have 2 or 3 senses, and 
the   senses    generally    differ    in   terms   of 
abstractness and concreteness, as is indicated 
in table 5. This is due to the fact that the 
arguments in these collocations are clearly 
delimitated in HowNet and this delimitation is 
well captured by the modified frequency 
calculation defined in formula (14). Via the 
formula, the concrete sense collocations can  
2 In Table 3 and 4, Ave. N.O.S stands for average number 
of senses of predicates, N.O.S stands for number of 
senses of the predicate, Assoc. WSD stands for 
Association-based WSD, and MDL WSD stands for 
MDL-based WSD. 
1243
Table 4. Detailed WSD Experiment Results 
Results for Pred-Obj. Results for Subj-Pred. 
Pred. 
N. 
O. 
S
Assoc. 
WSD
(%)
MDL
WSD
(%)
Pred. 
N. 
O. 
S. 
Assoc.
WSD
(%)
MDL
WSD
(%)
?(v) 5 69.23 80.77 ??(a) 2 61.14 92.00
?(v) 14 70.59 70.59 ?(v) 2 72.73 86.36
?(v) 6 56.25 90.62 ??(a) 2 47.83 58.7
??(v) 3 72.22 88.89 ?(a/v) 5 52.17 78.26
?(v) 9 50 60.53 ??(a) 3 56.76 81.08
?(v) 8 86.67 93.33 ?(a) 5 40 40 
?(v) 5 68.75 62.5 ??(v) 2 55.17 41.38
??(v) 3 73.91 81.16 ??(a) 3 75.76 93.94
?(v) 17 55.93 44.07 ?(a) 4 96.3 66.67
??(v) 3 80.36 78.57 ??(a) 3 47.37 42.11
??(v) 2 66.67 92.31 ?(a) 6 88.24 88.24
??(v) 2 57.14 80.95 ?(a) 6 46 60 
?(v) 6 76.27 79.66 ??(v) 3 44.44 44.44
??(v) 3 83.33 100 ??(a) 2 38.46 65.38
?(v) 8 63.64 63.64 ??(a) 2 93.33 53.33
?(v) 3 77.14 80 ??(v) 3 85.19 88.89
??(v) 2 88.24 100 ?(a) 10 50 50 
??(v) 2 83.87 80.65 ??(v) 2 60.53 63.16
?(v) 9 61.84 68.42 ?(a/v) 9 39.66 53.45
??(v) 3 40.28 51.39 ?(a) 6 59.46 51.35
?(v) 4 48.08 53.85 ?(v) 6 48.72 74.36
??(v) 3 73.49 73.49 ??(v) 3 48.15 44.44
??(v) 2 15.32 40 ??(a) 2 88.57 57.14
??(v) 2 84.91 83.02 ?(a) 6 68.18 40.91
?(v) 3 86.54 85.58 ?(v) 8 52.03 65.04
?(v) 4 72.51 72.99 ??(a) 2 95.35 95.35
Table 5. Word Sense Distinction 
Pred Concrete  Sense Abstract Sense(s) 
?? [quiet|?] [calm|??], 
[peaceful|?]
?? [dirty|?] [despicable|??], 
[immoral|???]
?? [difficult|?] [poor|?]
?? [beat|?] [MakeBetter|??], 
[cultivate|??]
?? [touch|?] [excite|??]
?? [break|??] [obstruct|??]
increase the  modified  frequency  of  concrete 
sense collocations, and the abstract sense 
collocation can increase the modified 
frequency of abstract sense collocations, thus 
leading to the clear demarcation of abstract 
senses and concrete senses. 
The role of semantic relevance can also be 
clearly noticed in the predicates which have a 
decreased precision in MDL in Table 4. Via 
Paradigmatic Redundancy Principle, the 
information encoded in one collocation are 
diffused to other collocations. Consequently, 
errors can be diffused. This explains why the 
precisions of some predicates such as ??
(sink)?, ???(dumb)?, ???(dark)? in Subj-
Pred and ??(open)?, ??(harness)? in Pred-
Objs decrease after MDL. Further analysis 
shows that this is because MDL has diffused 
the errors produced by Association Filter. For 
instance, at Association Filter phase, the 
collocation ???(box) ?(sink)? is assigned 
with the only sense collocation ?[tool|?? ]
[very| ? ]? and all other potential sense 
collocations are filtered. When MDL is applied, 
other collocations such as ???(machine) ?
(heavy)?, ???(pick)?(heavy)?, ???(chaw) 
?(heavy)?, ???(basket) ?(heavy)?, ???
(box) ?(heavy)?, ???(furniture) ?(heavy)?, 
in which the arguments are tightly correlated 
with that of ???(box) ?(sink)?? all takes 
the sense ?[very|? ]?, thus leading to the 
decrease of precision. 
The diffusion of senses can also best seen in 
the comparison between those predicates 
whose WSD are semi-supervised and those 
whose WSD are not supervised. Some 
predicates have collocations successfully 
retrieved from HowNet examples in which the 
word sense is already identified. These 
collocations are diffused in MDL filtering and 
play important roles in improving precision, 
while some other predicates do not have such 
resource. In Table 4, those unsupervised 
predicates are ???(fall)?, ??(collapse)?, ??
?(exquisite)?, ???(dumb)?, ???(wide)?, 
??? (develop)? in Subj-Preds and ???
(spread)?, ??? (brush)?, ??? (get into)?, 
??(bring)?, and ???(mar)? in Pred-Objs. 
The other predicates are semi-supervised. As 
can be seen in Table 4, most of these 
unsupervised predicates generally have a 
precision of 40%-60%, while those semi-
supervised predicates enjoy are much higher 
precision between 50%-100%. The explanation 
1244
for the result is straight forward. When one 
sense collocation of one word collocation is 
correctly identified, by way of Paradigmatic 
Redundancy Principle, the sense collocation 
which is similar to the correctly identified will 
have a higher modified frequency and is thus 
singled out as the best choice. This feature of 
MDL has great significance in the process of 
annotating large scale collocation data. With 
only a small number of annotated collocations 
for each predicate, a fairly high precision can 
be achieved for all the rest of the data through 
MDL.
5 Conclusion
The present paper believes that the Word-
Class Model gives the fullest description for 
selectional preference and thus makes efforts 
to disambiguate predicates in selectional 
preferences. From the perspective of semantic 
system, two principles of semantic redundancy, 
namely the Syntagmatic Redundancy Principle 
and Paradigmatic Redundancy Principle, are 
proposed in the paper and are applied in WSD 
in SP via Association Computation and 
Minimum Description Length. The 
experiments show that the approach proposed 
is fairly encouraging in disambiguation of 
polysemous predicates, especially under semi-
supervised conditions when a small portion of 
data is annotated. With such a tool, we are able 
to build large scale selectional preference 
knowledge database based on Word-Class 
Models, which can be applied in various tasks, 
of which metaphor recognition is the particular 
one we bear in mind.  
Acknowledgement 
This work is supported by Chinese National 
Fund of Social Science under Grant 
07BYY050 and Chinese National Science 
Fund under Grant 60773173 and Chinese 
National Fund of Social Science under Grant 
10CYY021. We are also grateful to the 
autonomous reviewers for their valuable 
advice and suggestions. 
References 
Agirre, E., and D. Mart?nez. 2001. Learning class-
to-class selectional preferences. Paper read at 
Proceedings of the Conference on Natural 
Language Learning, at Toulouse, France. 
Barron, A. R., J. Rissanen, and B. Yu. 1998. The 
Minimum Description Length Principle in 
coding and modeling. IEEE Transactions on 
Information Theory 44 (6):2743-2760. 
Brockmann, C., and M. Lapata. 2003. Evaluating 
and combining approaches to selectional 
preference acquisition. Paper read at Proceedings 
of the European Association for Computational 
Linguistics, at Budapest, Hungary. 
Ciaramita, M., and M. Johnson. 2000. Explaining 
away ambiguity: Learning verb selectional 
preference with Bayesian networks. In 
Proceedingsofthe18thInternationalConferenceon
ComputationalLinguistics (COLING 2000), 187-
193. 
Dong, Z. 2006. HowNet and the Computation of 
Meaning. River Edge, NJ: World Scientific. 
Erk, K. 2007. A Simple, Similarity-based Model for 
Selectional Preferences. Paper read at 
Proceedings of the 45th Annual Meeting of the 
Association of Computational Linguistics, at 
Prague, Czech Republic. 
Firth, J. R. 1957. A Synopsis of Linguistic Theory, 
1930-1955. In Studies in Linguistic Analysis. 
Oxford: Blackwell, 1-32. 
Han, J., and M. Kamber. 2006. Data Ming: 
Concepts and Techniques. Singapore: Elsevier. 
Jia Yuxiang and Yu Shiwen. 2008. Automatic 
Acquisition of Selectional Preference and Its 
Application to Metaphor Processing. Paper read 
at the Fourth National Student Conference on 
Computationl Linguistics, at Taiyuan, Shangxi, 
China. 
Li, H., and N. Abe. 1998. Generalizing Case 
Frames Using a Thesaurus and the MDL 
Principle. Computational Linguistics 24 (2):217-
244. 
Light, M., and W. Greiff. 2002. Statistical models 
for the induction and use of selectional 
preferences. Cognitive Science 87:1-13. 
Liu, Qun and Li Sujian. 2002. Word Similarity 
Computation Based on HowNet. In Proceedings 
of the 3rd Chinese Lexical Semantics. Taibei, 
China. 
Lyons, J. 1977. Semantics. Cambridge: Cambridge 
University Press. 
1245
MacKay, D. J. C. 2003. Information Theory, 
Inference, and Learning Algorithms. Cambridge: 
Cambridge University Press. 
McCarthy, D., and J. Carroll. 2003. Disambiguating 
Nouns, Verbs, and Adjectives Using 
Automatically Acquired Selectional Preferences. 
Computational Linguistics 29 (4):639-654. 
Merlo, P., and S. Stevenson. 2001. Automatic Verb 
Classification Based on Statistical Distributions 
of Argument Structure. Computational 
Linguistics 27 (3):374-408. 
Michell, Tom M.. Machine Learning. Translated by 
Zen Huajun and Zhang Yinkui. Beijing: China 
Machine Press. 
Resnik, P. 1996. Selectional constraints: an 
information-theoretic model and its 
computational realization. Cognition 61:127-159. 
Qu, Weiguang. 2008. Lexical Sense 
Disambiguation in Modern Chinese. Beijing: 
Science Press. 
Wu, Yunfang, Duan Huiming and Yu Shiwen. 2005. 
Verb?s Selectional Preference on Object. Spoken 
and Written Language in Practice 2005(2):121-
128. 
Yarowsky, D. 1995. Unsupervised Word Sense 
Disambiguation Rivaling Supervised Methods. 
Paper read at Proceedings of the 33rd Annual 
Meeting of the Association for Computational 
Linguistics, at Cambridge, MA. 
Zheng, Xuling, Zhou Changle, Li Tangqiu and 
Chen Yidong. 2007. Automatic Acquisition of 
Chinese Semantic Collocation Rules Based on 
Association Rule Mining Technique. Journal of 
Xiamen University (Natural Science) 46(3):331-
336. 
1246
R. Dale et al (Eds.): IJCNLP 2005, LNAI 3651, pp. 1017 ? 1028, 2005. 
? Springer-Verlag Berlin Heidelberg 2005 
Extracting Terminologically Relevant Collocations in the 
Translation of Chinese Monograph* 
Byeong-Kwu Kang, Bao-Bao Chang, Yi-Rong Chen, and Shi-Wen Yu 
The Institute of Computational Linguistics, Peking University, Beijing, 100871?China 
{kbg43, chbb, chenyr, yusw}@pku.edu.cn 
Abstract. This paper suggests a methodology which is aimed to extract the 
terminologically relevant collocations for translation purposes. Our basic idea is 
to use a hybrid method which combines the statistical method and linguistic 
rules. The extraction system used in our work operated at three steps: (1) 
Tokenization and POS tagging of the corpus; (2) Extraction of multi-word units 
using statistical measure; (3) Linguistic filtering to make use of syntactic 
patterns and stop-word list. As a result, hybrid method using linguistic filters 
proved to be a suitable method for selecting terminological collocations, it has 
considerably improved the precision of the extraction which is much higher 
than that of purely statistical method. In our test, hybrid method combining 
?Log-likelihood ratio? and ?linguistic rules? had the best performance in the 
extraction. We believe that terminological collocations and phrases extracted in 
this way, could be used effectively either to supplement existing terminological 
collections or to be used in addition to traditional reference works. 
1   Introduction 
Communication between different individuals and nations is not always easy, 
especially when more than one language is involved. This kind of communication can 
include translation problems, which can be solved by the translators who bridge the 
gap between two different languages.  
Through the past decade, China and Korea have been undergoing large economic, 
cultural exchange, which invariably affects all aspects of communication, particularly 
translation. New international contacts, foreign investments as well as cross-cultural 
communication have caused an enormous increase in the volume of translations 
produced and required. But by now, most of all this translation work has been 
conducted by translators alone, which bears the burden of an enormous translation 
task to them.  
In order to accomplish these tasks with maximum efficiency and quality, a new 
translation method supported by computer technology has been suggested. MAHT, 
also known as computer-assisted translation involves some interaction between 
translator and the computer. It seems to be more suited for the needs of many 
                                                          
*  This work has been supported by The National Basic Research Program of China(973 
program, No. 2004CB318102) and the 863 program (No. 2001AA114210, 2002AA117010). 
1018 B.-K. Kang et al 
organizations which have to handle the translation of the documents.  Computer-
assisted translation systems are based on ?translation memory? and ?terminology 
databases?. With translation memory tools, translators have immediate access to 
previous translations of the text, which they can then accept or modify.   
Terminology management systems also can prove very useful in supporting 
translator?s work [2, 11]. Most translators use some sort of glossary or terminology 
database, especially in the translation of the technical documents or academic 
monograph. Many translation bureaux have the collection of the terminology data 
bases. But time pressure and costs make it difficult to get glossary building task done 
fully manually. Thus there is a pressing need for the tool which is computationally 
supported. For Chinese, other than for English, terminology management tools are not 
so sophisticated that they could provide wide enough coverage to be directly usable 
for the translators.  
We are contemplating, in this article, situations where computational support is 
sought to extract the term candidate, construct or enhance such terminology 
databases. Our work will be more focused on the problem of terminologically relevant 
collocation extraction.  
In order to extract multiword terms from the domain corpus, three main strategies 
have been proposed in the literature. First, linguistic rule-based systems propose to 
extract relevant terms by making use of parts of speech, lexicons, syntax or other 
linguistic structure [2, 4]. This methodology is language dependent rather than 
language independent, and the system requires highly specialized linguistic 
techniques to identify the possible candidate terms. Second, purely statistical systems 
extract discriminating multiword terms from the text corpora by means of association 
measures [5, 6, 7]. As they use plain text corpora and only require the information 
appearing in texts, such systems are highly flexible and extract relevant units 
independently from the domain and the language of the input text. Finally, hybrid 
methodologies define co-occurrences of interest in terms of syntactical patterns and 
statistical regularities [1, 3, 9].  
There is no question that the term extraction work comes into play when the tools 
are parameterized in such a way as to provide as much relevant material (maximizing 
recall and precision), and as little ?noise? as possible.  As seen in the literature, 
neither purely rule-based approach nor statistic based approach could bring an 
encouraging result alone[3, 4]. The main problem is the "noise".  So we need to find a 
combined technique for reducing this ?noise?.  In this paper, we have taken a hybrid 
approach which combines the linguistic rules and statistical method. First, we applied 
a linguistic filter which selects candidates from the corpus. Second, the statistical 
method was used to extract the word class  combinations. And then, the results of 
several experiments were evaluated and compared with each other. 
2   Methodology Overview 
The basic idea in our work is that the extraction tool operates on pre-processed corpus 
which contains the results of tokenizing word and word class annotation (POS-
tagging). Figure1 contains an annotated sentence from one of the Chinese academic 
monograph[18]. 
 Extracting Terminologically Relevant Collocations in the Translation 1019 
<s id=2> 
??/p  ??/n  ??/n  ?/u  ??/d  ???/v  ?/w  ??/n  ???/d  ?
?/a  ?/u  ??/v  ?/p  ??/n  ??/n  ?/p  ???/n  ??/v  ??/n  ?
/w 
Fig. 1. Sample annotated text (tagged by the Peking University Tagger) 
And the extraction routine used in our work operated at three steps: 
(1)Tokenization and POS Tagging; (2)Extraction of the candidates from the corpus; 
(3)Linguistic  filtering(making use of syntactic patterns and stop-word list). The 
schema in Figure2 summarizes the three steps of pre-processing and extracting the 
term candidate. The extraction is automatic once the appropriate templates are 
designed. 
 
Fig. 2. Simplified schema of term extraction from a corpus 
3   Statistical Method 
Statistical methods in computational linguistics generally share the fundamental 
approach to language viewed as a string of characters, tokens or other units, where 
patterns are discovered on the basis of their recurrence and co-occurrence. 
Accordingly, when we approach the extraction of multi-word terms from a statistical 
point of view, we initially retrieve the word sequences which are not only frequent in 
their occurrence but also collocating each other.  
Before a statistical methodology could be developed, some characteristics of terms 
in Chinese had to be established. In Chinese, the length of terms can vary from single 
word to multi-words(n-gram), with the majority of entries being less than 4-word 
items, usually two word items(bi-gram) (See in 4.3). The number of n-grams with n>4 
Raw Corpus 
Annotated  text 
List of extraction result 
List of Term candidate 
filtered
Step 2. Extraction based on statistical information
Step 3.    Linguistic  filtering  
Step 1.   Tokenization and POS Tagging 
1020 B.-K. Kang et al 
is very small, and the occurrence of which is also rare. Therefore, the problems of bi-
grams, tri-grams and 4-grams are primarily taken into considerations in our work. 
Now let us consider the correlation between two neighboring words A and B. 
Assuming that these two words are terminologically relevant units, we can intuitively 
expect that they occur more often than random chance. From a statistical point of 
view, this probability can be measured by several statistical methods, such as ?co-
occurrence frequency?, ?Mutual Information?, ?Dice coefficient?, ?Chi-square test?, 
?log-likelihood?, etc[1, 6, 15]. 
Table 1 lists several statistical measures which have been widely used in extracting 
collocations. In table 1: XY represents any two word item? X stands for all words 
except X?  N is the size of corpus? Xf  and XP  are frequency and probability of X 
respectively? XYf  and XYP  are frequency and probability of XY respectively?And 
assuming that two words X and Y are independent of each other, the formulas are 
represented as follows: 
Table 1. Statistical methods used in multi word extraction 
Method Formula 
Frequency(Freq) XYf  
Mutual Information 
(MI) 2log
XY
X Y
P
P P
 
Dice Formula 
(Dice) 
2 XY
X Y
f
f f+  
Log-likelihood(Log-L) 
( )
2 log
( ) ( )
Y
XY XY
f
X Y X Y
ff
XY XY X Y XY
P P P P
P P P P
?  
Chi-squared(Chi) 
2( )
( )( )( )( )
XY XY XY XY
XY XYXY XY XY XY XY XY
N f f f f
f f f f f f f f
?
+ + + +
 
For the purposes of this work, we used these five statistics to measure the 
correlation of neighboring words. The statistical criterion of judgments is the value of 
measures which can judge the probability whether they belong to the rigid 
collocations or not. From a statistical point of view, we can say that if the value of 
measure is high, the two word combination is more likely to be a rigid collocation. 
And XY could be accepted as a collocation if its statistical value is larger than a given 
threshold. Those bi-gram candidates with correlation coefficient smaller than a pre-
defined threshold are considered to occur randomly and should be discarded. Others 
are sorted according to their correlation coefficient in descending order.  
Tri-gram and 4-gram candidates were processed in the same way. To compute the 
correlation coefficient of all tri-grams, we just considered a tri-gram as the 
 Extracting Terminologically Relevant Collocations in the Translation 1021 
combination of one bi-gram and one word, and then calculated their correlation 
coefficient. Similarly, a 4-gram was considered either as the combination of a tri-
gram and a word, or the combination of two bi-grams [12].  
As mentioned before, our methodology was tested on pre-processed corpus which 
contained the result of word class annotation. The extraction test was delivered on word 
sequence (POS tags) combinations. And the test corpus was a Chinese academic 
monograph [18]. The size of this corpus is 0.2 million Chinese characters, including 
about 5,000 sentences. In our test, the extraction of multi-word units was based on 
65,663 candidate bi-grams. Among these candidates, when their correlation coefficients 
were higher than a given threshold, they were considered as multi-word unit, and then 
sorted in descending order. The results of experiment are shown in Figure3. 
0
10
20
30
40
50
60
70
80
90
100 200 300 400 500 1000
Highly valued candidates
P
r
e
c
i
s
i
o
n
(
%
)
MI
DICE
LogL
Chi
 
Fig. 3. Comparison of Extraction Performance between different statistical measures 
Table 2. The sample result sorted by Chi Square value 
1stWord 2ndWord Chi LogL DICE MI 
?? 
?
? 7822.14 1278.48 517.581 5.28183 
??
 ?? 4233.43 42.8348 2520 10.4636 
?? ?
?
 3085.64 160.647 4560 7.59925 
?? ? 1461.41 424.818 767.36 3.90891 
?? ? 809.168 38.2226 844 7.66964 
?
? 
??
 752.637 124.353 787.243 5.16173 
?? ? 619.694 111.527 1600 5.02194 
??
 
?
 582.425 52.0341 516.444 6.40501 
?? ? 549.119 286.884 17037.1 2.66906 
?
?
 
?
 336.283 58.0757 2166.67 5.13281 
?
 
?
? 296.196 52.8541 544.348 4.96744 
? ? 228.596 122.119 523.597 2.2667 
1022 B.-K. Kang et al 
An examination of the results first showed a significant difference in precision. 
Checked by hand, the precisions of Chi-square value and Log-likelihood ratio were 
relatively high. In contrast, the precisions of Mutual information and Dice formula 
were not so ideal.  
Considering the size of the corpus and the terminological richness of the texts, this 
result is not very encouraging. Regardless of any statistical measure, the precision and 
coverage of the extraction are not so high that could be directly used in the application 
system.  
More over, as shown in table 2, the purely statistical system extracts all multi-word 
units regardless of their types, so that we can also find sequences like ???
[zengjia](add)? [le](auxiliary word)?, ??? [butong](different)? [de](auxiliary 
word)?, ??[ye](also)?[shi](be)?, ???[zhuanhuan](change)?[wei](become)?, etc., 
for which we have no use in terminology. Clearly the output must be thoroughly 
filtered before the result can be used in any productive way. 
On the whole, the somewhat disappointing outcome of the statistical method 
provoked us to rethink the methodology and tried to include more linguistic 
information in the extraction of terminology. 
4   Hybrid Method Combining Statistical Method and Linguistic 
Rules 
To improve the precision and recall of the extraction system, it was decided to use 
two criteria determining whether a sequence was terminologically relevant or not. The 
first was to use the frequent syntactic patterns of terms. The idea underlying this 
method is that multi-word terms are constructed according to more or less fixed 
syntactic patterns, and if such patterns are identified for each language, it is possible 
to extract them from a POS tagged corpus. The second was to use a stop-word filter 
that a term can never begin or end in a stop-word. This would filter out things not 
relevant with the domain-specific collocation or term. 
4.1   Syntactic Patterns of Terms in Chinese 
Before a methodology for extracting the terminologically relevant word units could be 
developed, some characteristics of terms in Chinese had to be established. We were 
especially interested in the following: How many words do terms usually have in 
Chinese? What is the structure of multi-word units in terms of syntax and morphology? 
What kind of terms can be successfully retrieved by computational methods?  
To find answers to the above questions, an existing terminology database could be 
used as a sample. Because the source text to be tested in our work is related with 
computational or linguistic domain, we selected the terminology database of 
computational linguistics which was constructed by Peking University. This term 
bank currently contains over 6,500 entries in English and Chinese.  
An analysis of 6,500 term entries in Chinese showed that the length of terms can 
vary from 1 to over 6 words, with the majority of entries being two-word items, 
usually a ?noun+noun? sequence. The second most frequent type is a single-word 
term. As less than 5% of all entries exceed 4 words and single word terms can be 
 Extracting Terminologically Relevant Collocations in the Translation 1023 
identified with the use of monolingual or bilingual dictionary 1 , we decided that 
automatic extraction should be limited to sequences of 2-4 words. 
 
0 1000 2000 3000 4000
1 word
2 word
3 word
4 word
5 word
6 word
etc
  
0 500 1000 1500
n+n
vn+n
n+vn
n+v
a+n
b+n
v+v
v+n
vn+Ng
n+Ng
d+v
etc
 
 Fig. 4. Length of Chinese terms     Fig. 5. Syntactic patterns of two word terms 
As the next step we manually analyzed the syntactic patterns of Chinese terms and 
ordered them according to frequency. These patterns were needed for the second part 
of the experiment, the ?linguistically motivated? filtering. According to the analysis 
of the existing terms, multi-word terms have some kinds of fixed syntactic patterns. In 
many cases, these syntactic patterns are based on the combinations of different two 
word classes, such as ?noun+noun?, ?gerend verb+noun?, ?adjective+noun?, 
?noun+suffix? etc.  We found that there were about 30 syntactic patterns which 
covered almost 95% in the two word combinations. Therefore, we decided that these 
patterns could be used filtering in the extraction. In figure 6, certain types of word 
combinations are more typical for technical vocabulary than for general language.  
More than three word combinations also can be divided into two small parts whose 
syntactic structures are the same as those of two word terms. For example: ?(n+n)+n?, 
?(vn+n)+n?, ?(v+n)+(n+vn)?, ?(a+n)+(vn+n)?, etc. Therefore when we extracted 
three-word or four-word units, we didn?t set another syntactic rule for them. We just 
considered tri-gram as the combination of one bi-gram and one word. Similarly, 4-
gram was considered as the combination of different two bi-grams.  
Although we admit that these syntactic patterns are typical for certain type of 
technical prose only, we don?t think that they could filter out all the irrelevant units. If 
                                                          
1
  To extract a glossary of terms from a corpus, we must first identify single-word terms. But it 
might be slightly confusing for the computer to identify the single word terms alone. So we 
would like to set aside this problem for the sake of achieving efficiency. But we believe that 
the translator might not be troubled with single terms if he has some kind of dictionary in the 
translation of the source text. 
1024 B.-K. Kang et al 
we extract all combinations of a certain POS-shape, additional filters are needed 
afterwards, to identify those combinations which are terminologically relevant. 
Char*Patterns={"n+n","vn+n","n+vn","n+v","a+n","b+n","v+v","v+n"
,"vn+Ng","n+Ng","d+v","m+n","h+n","f+v","a+v","f+n","j+n","a+Ng
","vn+k","b+vn","b+Ng","Ag+n","v+Ng","a+nz","vn+v","nz+n","b+k
","v+k","j+n","nz+v",null}; 
Fig. 6. The syntactic patterns for filtering2 
4.2   Stop-Word Filter in Chinese 
When we examine multi word units regardless of their type, we can easily find some 
words which have no use in terminology. These irrelevant or meaningless data is a 
noise for extracting desired data. To resolve this problem, we can make use of the stop 
word list to be filtered. In the system, it would filter out things irrelevant with the 
domain-specific collocation or term. But how can we make the set of stop words? 
Indeed, the stop word list is rather flexible than firmly fixed in their usage. Whenever 
the words are frequent and meaningless in text, they can be stop words in a given task. 
For practical purposes, we used the word frequency data of the large technical 
domain corpora which was constructed by Beijing Language and Cultural University. 
In this data, we randomly selected the 2,000 words most highly frequent in their 
usage. And then we examined whether the frequent words were terminologically 
relevant or not. The analysis of the word data showed that 77.6% were domain 
dependent which could be the part of term, and 22.4% were general words. It means 
that terminologically irrelevant words amounted to about 450 words of the highly 
frequent 2000 words in technical corpora. The results are shown in Table 3. 
Table 3. The results of analysis on the high frequency words  
Frequency TerminologicallyRelevant words 
Terminologically
Irrelevant words Example 
1-100 44(44%) 56(56%) ?(aux), ?(be), ?(and), ?(at), ?(middle), etc. 
101-200 58(58%) 42(42%) ??(provide),?(to),?(serve 
as),??(possess), etc. 
201-500 229(76.3%) 71(23.7%) ? (good),?? (for),?(some),
?(only),??(other), etc. 
501-1000 408(81.6%) 92(18.4%) ? ? (quite), ? (see), ? ?(arose), ??(indicate),etc. 
1001-2000 813(81.3%) 187(18.7%) ??(leave),??(engage),?
?(even),??(need not),etc 
Total 1552(77.6%) 448(22.4%)  
                                                          
2
 These POS patterns are based on the tag sets of Peking University. 
 Extracting Terminologically Relevant Collocations in the Translation 1025 
According to these analyzed data, we made the set of stop words which amounted 
to about 450 words. And we used them for filtering out the frequent, meaningless 
words in a given text before the output can be used in any productive way.  
5   Experiments  
The hybrid methods combining statistical measure and linguistic rules were tested on 
pre-processed corpus. Based on the statistical method, the extraction test was limited 
to the boundary of the frequent syntactic patterns first, and then filtered out by the 
stop word list. Three different statistical measures were used to enhance the precision 
of the extraction, such as Log-likelihood ratio, Chi-square test and Mutual 
information. Because of the poor performance in our first test, Dice formula was not 
used in hybrid method any more. Therefore, we have delivered three different 
experiments using like ?LogL + Liguistic Filter?, ?Chi + Liguistic Filter?, ?MI + 
Liguistic Filter? methods.  
In Figure 7, we present the comparative results of precision rate among these 
different experiments. In order to measure the precision rate of the result, we used the 
grammatical criterion: A multi word n-gram could be considered as accurate result if 
it is grammatically appropriate. By grammatical appropriation, we refer to compound 
noun phrase or compound verb phrase, since with majority of multi-word terms have 
these structures.  
As a result, hybrid method using linguistic filters proved to be a suitable method for 
selecting terminological collocations, and it has considerably improved the precision of 
the extraction. The precision was much higher than that of purely statistical method, 
retrieving appropriate result almost 10%-20% higher than in the first experiment. In 
our test, hybrid method combining ?Log-likelihood ratio? and ?linguistic rules? had the 
best performance in the extraction. The precision was higher than 90%. According to 
their performance, the results of different experiments can be arranged like: 
LogL+Filter   >   Chi+Filter  >  MI+Filter  >  LogL  >  Chi  >  MI  >  Dice 
0
20
40
60
80
100
120
100 200 300 400 500 1000
Highly valued candidates
P
r
e
c
i
s
i
o
n
(
%
)
MI
DICE
LogL
Chi
MI+Filter
LogL+Filter
Chi+Filter
 
Fig. 7. Comparison of Extraction Performance between statistical measures and hybrid measure 
1026 B.-K. Kang et al 
In the analysis of the extraction data, we examined the precision of every 100 
multi-word candidates which sorted in descending order. Considering the size of 
corpus, we compared the results within the highly valued 1000 candidates. A sample 
of the highly valued output is seen in Table 4. 
Table 4. The sample result sorted by Log-likelihood ratio 
1stWord 2ndWord LogL+Filter CHI+Filter MI+Filter 
?? ?? 1026.38 3748.65 4.20189 
?? ?? 1020.43 5102.98 4.93017 
?? ?? 981.323 3651.52 4.23672 
?? ?? 899.731 7805.59 6.16647 
?? ?? 734.213 2284.06 3.76964 
?? ??? 718.016 14931.3 7.80401 
??? ??? 557.888 13569.4 8.11656 
?? ?? 537.196 2361.49 4.60008 
? ?? 500.011 12919.7 8.26776 
?? ?? 363.259 3535.04 6.19858 
?? ?? 355.499 2053.22 5.29117 
? ?? 345.551 6733.13 7.55539 
?? ?? 339.45 6092.73 7.41208 
?? ?? 329.536 1061.09 3.76944 
?? ?? 316.792 8130.74 8.08733 
As seen in Table 4, although not all these units would be considered terms in the 
traditional sense of the word, most of them either contain terms or include 
terminologically relevant collocations. Besides, our extraction started from these two 
word items, expanded to extract multi-word units like three word or four word units. 
Finally we could extract multi word units such as the following sample: 
Table 5. The sample of multi-word terms 
 Terminologically relevant units 
Two word units 
? ? ? ? (grammatical function), ? ? ? ? (directional 
complement),  ?????(specification), ????(container 
classifier), ????(usage frequency), etc. 
Three word units 
??????(grammatical knowledge-base), ??????
(Chinese Information Processing), ? ? ? ? ? ? (speech 
recognition system), etc. 
Four word units  
????????(MT system design), ????????
(language information processing technology), ???????
(context free grammar), etc.  
On the whole, as we think that the performance of the extraction was quite good, 
this method could be applicable in the translation system.  
 Extracting Terminologically Relevant Collocations in the Translation 1027 
6   Conclusions and Future Work 
The paper presents a methodology for the extraction of terminological collocations 
from academic documents for translation purposes. It shows that statistical methods 
are useful because they can automatically extract all the possible multi word units 
according to the correlation coefficient. But the purely statistical system extracts all 
multi-word units regardless of their types, so that we also find sequences which are 
meaningless in terminology. Clearly the output must be thoroughly filtered before the 
result can be used in any productive way. To improve the precision of the extraction 
system, we decided to use linguistic rules determining whether a sequence was 
terminologically relevant or not.  The frequent syntactic patterns of terminology and 
the stop-word list were used to filter out the irrelevant candidates. As a consequence, 
hybrid method using linguistic filters proved to be a suitable method for selecting 
terminological collocations, and it has considerably improved the precision of the 
extraction. The precision was much higher than that of purely statistical method.  
We believe that terminological collocations and phrases extracted in this way, 
could be used effectively either to supplement existing terminological collections or 
to be used in addition to traditional reference works. 
In future we envisage the development of techniques for the alignment of exact 
translation equivalents of multi-word terms in Chinese and Korean, and one way of 
doing so is by finding correspondences between syntactic patterns in both languages. 
Translation memory systems already store translations in a format similar to a parallel 
corpus, and terminology tools already involve functions such as ?auto-translate? that 
statistically calculate the most probable translation equivalent. By refining these 
functions and making them language specific, we could soon be facing a new 
generation of tools for translators. It remains to be seen, however, whether they can 
really be implemented into translation environments on broad scale. 
References 
1. Chang Bao-Bao, Extraction of Translation Equivalent Pairs from Chinese-English Parallel 
Corpus, Terminology Standardization and Information Technology, pp24-29, 2002. 
2. Bourigault, D. Lexter, A Natural Language Processing Tool for Terminology Extraction. 
In Proceedings of  7th EURALEX International Congress, 1996. 
3. Daille, B. Study and Implementation of Combined Techniques for Automatic Extraction of 
Terminology. In The balancing act combining symbolic and statistical approaches to 
language. MIT Press,  1995. 
4. Ulrich Heid, A linguistic bootstrapping approach to the extraction of term candidates from 
German text, http://www.ims.uni-stuttgart.de/~uli/papers.html, 2000 . 
5. Sayori Shimohata, Toshiyuki Sugio, JunjiI Nagata, Retrieving Domain-Specific 
Collocations By Co-Occurrences and Word Order Constraints, Computational 
Intelligence, Vol 15, pp92-100, 1999. 
6. Shengfen Luo, Maosong Sun Nation,Two-Character Chinese Word Extraction Based on 
Hybrid of Internal and Contextual Measures, 2003 
7. Smadja, F. Retrieving Collocations From Text: XTRACT. In Computational Linguistics, 
19(1) (pp 143--177).1993. 
1028 B.-K. Kang et al 
8. David Vogel, Using Generic Corpora to Learn Domain-Specific Terminology, Workshop 
on Link Analysis for Detecting Complex Behavior, 2003 
9. Dias, G. & Guillor?, S. & Lopes, J.G.P. Multiword Lexical Units Extraction. In 
Proceedings of the International Symposium on Machine Translation and Computer 
Language Information Processing. Beijing, China. 1999. 
10. Feng Zhi-Wei, An Introduction to Modern Terminology, Yuwen press, China, 1997. 
11. Ga?l Dias etc, Combining Linguistics with Statistics for Multiword Term Extraction, In 
Proc. of Recherche d'Informations Assistee par Ordinateur, 2000. 
12. Huang Xuan-jing & Wu Li-de & Wang Wen-xin, Statistical Acquisition of Terminology 
Dictionary, the Fifth Workshop on Very Large Corpora, 1997 
13. Jiangsheng Yu? ? ?Automatic Detection of Collocation http://icl.pku.edu.cn/yujs/ 2003 
14. Jong-Hoon Oh, Jae-Ho Kim, Key-Sun Choi, Automatic Term Recognition Through EM 
Algorithm, http://nlplab.kaist.ac.kr/, 2003 
15. Patrick Schone and Daniel Jurafsky, Is Knowledge-Free Induction of Multiword Unit 
Dictionary Headwords a Solved Problem?, In proceedings of EMNLP, 2001. 
16. Philip Resnik, I. Dan Melamed, Semi-Automatic Acquisition of Domain-Specific 
Translation Lexicons, Proceedings of the fifth conference on Applied natural language 
processing, pp 340-347, 1997. 
17. Sui Zhi-Fang, Terminology Standardization using the NLP Technology, Issues in Chinese 
Information Processing,pp341-352, 2003. 
18. Yu Shi-wen, A Complete Specification on The Grammatical Knowledge-base of 
Contemporary Chinese, Qinghua Univ. Press, 2003 
Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 371?374,
Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational Linguistics
PengYuan@PKU: Extracting Infrequent Sense Instance with the 
Same N-gram Pattern for the SemEval-2010 Task 15 
Peng-Yuan Liu1  Shui Liu2  Shi-Wen Yu1  Tie-Jun Zhao2  
1Institute of Computational Linguistics, Peking University, Beijing, China 
2Department of Computer Science, Harbin Institute of Technology, Harbin, China 
{liupengyuan,yusw}@pku.edu.cn,{tjzhao,liushui}@mtlab.hit.edu.cn 
  
 
Abstract 
 
This paper describes our infrequent sense 
identification system participating in the 
SemEval-2010 task 15 on Infrequent Sense 
Identification for Mandarin Text to Speech 
Systems. The core system is a supervised 
system based on the ensembles of Na?ve 
Bayesian classifiers. In order to solve the 
problem of unbalanced sense distribution, we 
intentionally extract only instances of 
infrequent sense with the same N-gram pattern 
as the complemental training data from an 
untagged Chinese corpus ? People?s Daily of 
the year 2001. At the same time, we adjusted 
the prior probability to adapt to the 
distribution of the test data and tuned the 
smoothness coefficient to take the data 
sparseness into account. Official result shows 
that, our system ranked the first with the best 
Macro Accuracy 0.952. We briefly describe 
this system, its configuration options and the 
features used for this task and present some 
discussion of the results. 
1 Introduction 
We participated in the SemEval-2010 task 15 on 
Infrequent Sense Identification for Mandarin 
Text to Speech Systems. This task required 
systems to disambiguating the homograph word, 
a word that has the same POS (part of speech) 
but different pronunciation. In this case, we still 
considered it as a WSD (word sense 
disambiguation) problem, but it  is a little 
different from WSD. In this task, two or more 
senses of the same word may correspond to one 
pronunciation. That is, the sense granularity is 
coarser than traditional WSD.  
The challenge of this task is the much skewed 
distribution in real text: the most frequent 
pronunciation accounts for usually over 80%. In 
fact, in the training data provided by the 
organizer , we found that the sense distribution 
of some words are distinctly unbalanced. For 
each of these words, there are fewer than ten 
instances of one sense whereas the dominant 
sense instances are hundreds or more. At the 
same time, according to the task description on 
the task 15 of SemEval-
2010(http://semeval2.fbk.eu/semeval2.php?locati
on=tasks), the test dataset of this task is 
intentionally divided into the infrequent 
pronunciation instances and the frequent ones by 
half and half. Apparently, if we use traditional 
methods and only the provided training dataset  
to train whatever classifier, it is very likely that 
we will  get an disambiguation result that all (at 
least the overwhelming number) the test 
instances of these words would be labeled with 
the most frequent pronunciation (sense) tag. 
Then our system is meaningless for the target of 
the task  is focused on the performance of 
identifying the infrequent sense. 
In order to solve the problem of the 
unbalanced sense distribution in the training data 
and the  fairly balanced sense distribution in the 
test data, we designed our PengYuan@PKU 
system, which attempts to extract infrequent 
sense instances only and adjust the prior 
probability so as to counteract the problem as far 
as possible. The core system is a supervised 
system based on the ensembles of Na?ve 
Bayesian classifiers. The complemental training 
data is extracted from an untagged Chinese 
corpus ? People?s Daily of the year 2001 
automatically. Besides the motivation of 
investigating the function of our method of 
compensating infrequent sense instances, we are 
also interested in the role where the smoothness 
plays when it encounters with such a data 
sparseness here. 
In section 2, we will describe our system that 
includes the core classifier, its configuration 
options and features. In section 3, we will show 
the official results of this task and present some 
analyses and discussions. Section 4 is related 
371
works. The conclusion and future work are in 
section 5. 
2 System Description 
2.1 Na?ve Bayesian Classifier and Features 
For a na?ve Bayesian classifier, the joint 
probability of observing a certain combination of 
context features with a particular sense is 
expressed as: 
1 2
1
( , ,..., , ) ( ) ( | )
n
n i
i
p F F F S p S p F S
=
= ?          (1) 
In equation (1), (F1, F2,?, Fn) is feature 
variables, S is classification variable and p(S) is 
the prior probability of classification variable. 
Any  parameter  that  has  a  value  of zero  
indicates that  the  associated word never occurs 
with  the  specified  sense  value.  These zero 
values are smoothed by additive smoothing 
method as expressed below: 
( , )( | ) ( )
i k
i k
k
C F SP F S C S N
l+= +    , ??(0,1)    (2) 
In equation (2), ?is the smoothness variable. 
C(Sk) is the times of instances with Sk label. 
C(Fi,Sk) is the concurrences times of Fi and Sk. N 
is the times of total words in the corpus. 
The features and their weights of context used 
in one single Na?ve Bayesian classifier are 
described in Table 1. 
 
Features Description weights 
w-i?wi 
Content words appearing 
within the window of ?i 
words on each side of the 
target word 
1 
wj/j 
j?[-3,3] 
Word forms and their 
position information of the 
words at fixed positions 
from the target word. 
3 
wk-1wk 
k?(-i,i] 
word bigrams appearing 
within the window of ?i 
1 when 
i>3, else 
3 
Pk-1Pk 
k?(-i,i] 
POS bigrams appearing 
within the window of ?i 1 
 
Table 1: Features and their weights used in one 
Na?ve Bayesian classifier 
2.2 Ensembles the Na?ve Bayesian 
Classifiers 
The ensemble strategy of our system is like 
Pederson (2000). The windows of context have 
seven different sizes (i): 3, 5, 7, 9, 11, 13 and 15 
words. The first step in the ensemble approach is 
to train a separate Na?ve Bayesian classifier for 
each of the seven window sizes. 
Each of the seven member classifiers votes for 
the most probable sense given the particular 
context represented by that classifier; the 
ensemble disambiguates by assigning the sense 
that receives the majority of the votes. 
2.3 Infrequent Sense Instances Acquisition 
N-gram Increasing Instances Number 
(-1,1) 246 
(-2,0) 229 3-gram 
(0,2) 551 
1026(9135) 
(-1,0) 1123 2-gram (0,1) 1844 2967(9135) 
 
Table 2: The overview of the training data before and 
after the extracting stage 
 
Sense Distribution 
After 
Target 
Words Before 
(O)  (O+E3)  (O+E2) 
 ? 128 51 128 66 128 2621 
 ? 503 83 503 83 503 194 
 ?? 168 13 168 16 168 23 
 ? 175 10 175 27 175 88 
 ? 487 42 487 63 487 267 
 ?? 134 44 134 44 134 49 
 ?? 125 11 125 11 125 12 
 ? 2020 8 2020 12 2020 25 
 ? 300 3 300 6 300 32 
 ? 268 3 268 4 268 45 
 ? 1625 41 1625 346 1625 1625 
 ? 144 13 144 15 144 33 
 ?? 136 8 136 9 136 16 
 ? 1666 253 1666 847 1666 1567 
 ? 142 17 142 17 142 17 
 ? 438 76 438 136 438 414 
 
Table 3: The sense distributions of the training data 
before and after the extracting stage 
Our system uses a special heuristic rule to extract 
the sense labeled infrequent sense instances 
automatically. The heuristic rule assumes that 
one sense per N-gram which we testified initially 
through investigating a Chinese sense-tagged 
corpus STC (Wu et al, 2006). Our assumption is 
inspired by the celebrated one sense per 
collocation supposition (Yarowsky, 1993). STC 
is an ongoing project of building a sense-tagged 
                                                          
1 We intentionally control the sense distribution of word 
(???) and change it from approximately 2.5:1 to 1:2 so as 
to investigate the influence. 
372
corpus which contained the sense-tagged 1, 2 and 
3 months of People?s Daily of the year 2000. 
According to our investigation, to any target 
multi-sense word, given a specific N-gram (N>1) 
including the target word, we will expect to see 
the same label that range from 88.6% to 99.2% 
of the time on average. So, based on the training 
data, we can extract instance with the same N -
gram pattern from the untagged Chinese corpus 
and we assume if the N-gram is the same then 
the sense-label is the same. 
For all the 16 multiple-sense target words in 
the training data of task 15, we found the N-gram 
of infrequence sense instances and  extracted2 the 
instances with the same N-gram from People?s 
Daily of the year 2001(about 116M bytes). We 
extracted as many as possible until the total 
number of them is equal to the dominant sense 
instance number. We appointed the same N-gram 
instances the same sense tag and (merge?) it into 
the original training corpus. Table 2 and 3 show 
the overview and the sense distribution of the 
training data before and after the extracting stage. 
Number 9135 in brackets of Table 2 is the 
instance number of original training corpus. O, 
O+E3, O+E2 in Table 3 mean original training 
data, original training data plus extracted 3-gram 
instances and original training data plus extracted 
2-gram instances respectively. Limited to the 
scale of the corpus, the unbalance sense 
distribution of some words does not improve 
much. 
2.4 Other Configuration Options 
Systems Training Data p(S) ? 
_3.001 O+E3 0.5 0.001 
_3.1 O+E3 0.5 0.1 
_2.001 O+E2 0.5 0.001 
_2.1 O+E2 0.5 0.1 
 
Table 4: The system configuration 
To formula (1), we tune the prior probability of 
classification variable p(S) as a constant to match 
the sense distribution of test data. Considering 
the data sparseness as there may have been in the 
test stage, to formula (2), we set 2 kinds of?to 
investigate  the effect of smoothness. 
In total, we develop four systems based on 
various configuration options. They are showed 
in Table 4. 
                                                          
2 In order to guarantee the extracted instances are not 
duplicated in the training data or in the test data in case, our 
system filters the repeated instances automatically if they 
are already in the original training or test dataset. 
3 Results and Discussions 
3.1 Official Results 
System 
ID 
Micro  
Accuracy 
Macro 
Accuracy 
Rank 
_3.001 0.974 0.952 1/9 
_3.1 0.965 0.942 2/9 
_2.001 0.965 0.941 3/9 
_2.1 0.965 0.942 2/9 
Baseline 0.924 0.895  
 
Table 5: Official results 1 of PengYuan@PKU 
 
Precision Words 
_3.001 _3.1 _2.001 _2.1 baseline 
?   0.844 0.789 0.789 0.789 0.711 
?   0.976 0.962 0.969 0.962 0.863 
?? 0.901 0.901 0.901 0.901 0.901 
?   0.978 0.989 0.978 0.989 0.957 
?   0.925 0.853  0.864 0.853  0.925 
?? 0.956 0.944 0.956 0.944 0.700  
?? 0.971 0.956 0.956 0.956 0.956 
?   0.998  0.997 0.997 0.997 0.996 
?   0.987 0.974 0.974 0.974 0.987 
?   0.956 0.963 0.971 0.963 0.956 
?   0.983 0.975  0.969 0.975  0.978 
?   0.924 0.949 0.937 0.949 0.886 
?? 0.986 0.986 0.986 0.986 0.959 
?   0.986 0.989 0.989 0.989 0.869  
?   0.875    0.900 0.875    0.900 0.838   
?   0.981 0.946 0.953 0.946 0.844 
 
Table 6: Official results 2 of PengYuan@PKU 
Macro Accuracy is the average disambiguation 
precision of each target word. Micro Accuracy is 
the disambiguation precision of total instances of 
all words. For task 15 whose instance 
distribution of the target words is very 
unbalanced in the test dataset, Macro Accuracy 
maybe a better evaluation indicator. Our systems 
achieved from 1st to 4th position (ranked by 
Macro Accuracy) out of all nine systems that 
participated in this task. Our best system is 
PengYuan@PKU_3.001 which uses original 
training data plus extracted 3-gram instances as 
our training data, P(S) is tuned to 0.5 and?is 
equal to 0.001.  
3.2 Discussions 
From the official result in Table 5 and Table 6 
we can see, for this task, our classifier and 
strategy of extracting infrequency instances is 
effective. Basically, for each target word, the 
373
performances of our systems are superior to the 
baseline.  
From Table 6, we also see the performances of 
our systems are influenced by different ? and 
different instance extracting patterns. 
Comparatively smaller probability ? of 
nonoccurrence features is better. Using the 
Extracting 3-gram instances is better than that of 
using 2-gram. (By using the 3-gram method of 
extracting instances, we obtain a better result 
than that of 2-gram.) 
Our original idea for the system is two-folds. 
On one hand, we consider the relieving of data 
sparseness through more instances extracted by 
2-gram pattern can achieve a better performance 
than that of 3-gram pattern, though the instances 
extracted through 2-gram pattern induce more 
noise. On the other hand, we assume that the 
performance would be better if we had given a 
larger probability of nonoccurrence features, for 
this strategy favors more infrequent sense 
instances. However the unbalance of sense 
distribution in the real test data as is shown in 
Table 5 went beyond our expectation. It is very 
hard for us to evaluate our system from the 
viewpoint of smoothness and instance sense 
distribution. 
4 Related Work 
To our knowledge, the methods of auto-
acquiring sense-labeled instances include using 
parallel corpora like Gale et al (1992) and Ng et 
al. (2003), extracting by monosemous relative of 
WordNet like Leacock et al (1998), Mihalcea 
and Moldovan (1999), Agirre and Mart?nez 
(2004), Mart?nez et al (2006) and PengYuan et 
al. (2008). The method proposed by Mihalcea 
and Moldovan (2000) is also an effective way. 
5 Conclusion and Future Work 
We participated in the SemEval-2010 task 15 on 
Infrequent Sense Identification for Mandarin 
Text to Speech Systems. Official results show 
our system which extract infrequent sense 
instances is effective.  
For the future studies, we will focus on how to 
identify the infrequent sense instances effectively 
based on the plan to change the proposition 
between dominant sense and infrequent sense 
step by step. 
 
Acknowledgments 
This work was supported by the project of 
National Natural Science Foundation of China 
(No.60903063) and China Postdoctoral Science 
Foundation funded project (No.20090450007). 
References  
Claudia Leacock, Martin Chodorow and George A. 
Miller, Using  Corpus Statistics and WordNet 
Relations for Sense Identification. Computational 
Linguistics, 1998, 24(1):147~166 
David Mart?inez, Eneko Agirre and Xinglong Wang. 
Word relatives in context for word sense 
disambiguation.  Proceedings of the 2006 
Australasian Language Technology Workshop 
(ALTW2006), 2006:42~50 
David Yarowsky. 1993. One sense per collocation. 
Proceedings of the ARPA Workshop on Human 
Language Technology. 
Eneko Agirre and David Mart?inez. Unsupervised 
WSD based  on  automatically retrieved  examples:  
The  importance of bias. Proceedings of the 
International Conference on Empirical Methods  in  
Natural Language Processing, EMNLP, 
2004:25~32 
Hwee Tou Ng, Bin Wang, Yee Seng Chan. Exploiting 
Parallel Texts for Word Sense Disambiguation: An 
Empirical Study. Proceeding of the 41st ACL, 455-
462, Sappora, Japan. 
Liu Peng-yuan Zhao Tie-jun Yang Mu-yun Li Zhuang. 
2008. Unsupervised Translation Disambiguation 
Based on Equivalent PseudoTranslation Model. 
Journal of Electronics & Information Technology. 
30(7):1690-1695. 
Rada Mihalcea and Dan I. Moldovan. 1999. An 
automatic method for generating sense tagged 
corpora. Proceedings of AAAI-99, Orlando, FL, 
July, pages 461?466. 
Rada Mihalcea and Dan .I. Moldovan. 2000. An 
iterative approach to word sense disambiguation. 
Proceedings of FLAIRS-2000, pages 219?223, 
Orlando, FL, May. 
Ted. Pedersen. 2000. A Simple Approach to Building 
Ensembles of Na?ve Bayesian Classifiers for Word 
Sense Disambiguation.  Proceedings  of  the  First 
Annual  Meeting  of  the  North  American  Chapter  
of  the  Association  for Computational Linguistics, 
pages 63-69, Seattle, WA, May.  
Yunfang Wu, Peng Jin, Yangsen Zhang, and Shiwen 
Yu. 2006. A Chinese corpus with word sense 
annotation. Proceedings of ICCPOL-2006. 
William A. Gale, Kenneth W. Church and David 
Yarowsky. A method for disambiguating word 
senses in a large corpus. Computers and the 
Humanities, 26(2):415-539 
374
Proceedings of the Multiword Expressions: From Theory to Applications (MWE 2010), pages 11?18,
Beijing, August 2010
Construction of a Chinese Idiom Knowledge Base and Its Applications 
 
Lei Wang  
Key Laboratory of Computational 
Linguistics of Ministry of Education 
Department of English, Peking University 
wangleics@pku.edu.cn 
Shiwen Yu  
Key Laboratory of Computational 
Linguistics of Ministry of Education,  
Peking University 
yusw@pku.edu.cn 
Abstract 
Idioms are not only interesting but also 
distinctive in a language for its continuity 
and metaphorical meaning in its context. 
This paper introduces the construction of 
a Chinese idiom knowledge base by the 
Institute of Computational Linguistics at 
Peking University and describes an 
experiment that aims at the automatic 
emotion classification of Chinese idioms. 
In the process, we expect to know more 
about how the constituents in a fossilized 
composition like an idiom function so as 
to affect its semantic or grammatical 
properties. As an important Chinese 
language resource, our idiom knowledge 
base will play a major role in applications 
such as linguistic research, teaching 
Chinese as a foreign language and even as 
a tool for preserving this non-material 
Chinese cultural and historical heritage. 
1  Introduction 
An idiom is a multi-word expression that has a 
figurative meaning that is comprehended in 
regard to a common use of that expression that 
is separate from the literal meaning or definition 
of the words of which it is made (McArthur, 
1992). From a linguistic perspective, idioms are 
usually presumed to be figures of speech that 
are contradictory to the principle of 
compositionality. The words that construct an 
idiom no longer keep their original meaning or 
popular sense, while in the process of its 
formation it develops a specialized meaning as 
an entity whose sense is different from the 
literal meanings of the constituent elements.  
Although an idiom is an expression not 
readily analyzable from its grammatical 
structure or from the meaning of its component 
words, it is the distinctive form or construction 
of a particular language that has a unique form 
or style characteristic only of that language. An 
idiom is also used, in most cases, with some 
intention of the writer or to express certain 
emotion or attitude. Thus in nature, idioms are 
exaggerative and descriptive and do not belong 
to the plain type.  
Therefore, to classify idioms according to 
its emotional property or descriptive property is 
important for many practical applications. In 
recent years, emotion classification has become 
a very popular task in the area of Natural 
Language Processing (NLP), which tries to 
predict sentiment (opinion, emotion, etc.) from 
texts. Most research has focused on subjectivity 
(subjective/objective) or polarity 
(positive/neutral/negative) classification. The 
applications with this respect include human or 
machine translation, automatic text 
classification or Teaching Chinese as a Foreign 
Language (TCFL). For example, when a student 
learning Chinese as a foreign language 
encounters an idiom in his or her reading or 
conversation, for better understanding it is 
important for him or her to know whether the 
idiom is used to indicate an appreciative or 
derogatory sense which is very crucial to 
understand the attitude of the idiom user. 
Another example is that long articles about 
politics in newspapers often include a lot of 
idiom usage to boost their expressiveness and 
these idioms may carry emotional information. 
Obviously by knowing the emotional 
inclination we may easily obtain a clue about 
the general attitude of the particular medium. 
We may even be able to detect or monitor 
automatically the possible hostile attitude from 
certain electronic media which today provide so 
huge amount of information that seems hard for 
human processing on a daily basis.  
The rest of this paper is organized as 
follows. Section 2 describes the construction of 
11
a Chinese Idiom Knowledge Base (CIKB) and 
introduces its several applications so far. 
Section 3 concludes the related work that serves 
as the basis of the building of CIKB and the 
emotion classification experiment introduced in 
this paper. Section 4 describes the classification 
method, feature settings, the process of emotion 
classification and the analysis of the result. 
Section 5 includes conclusions and our future 
work. 
2 Chinese Idioms and Chinese Idiom 
Knowledge Base 
Generally an idiom is a metaphor ? a term 
requiring some background knowledge, 
contextual information, or cultural experience, 
mostly to use only within a particular language, 
where conversational parties must possess 
common cultural references. Therefore, idioms 
are not considered part of the language, but part 
of a nation?s history, society or culture. As 
culture typically is localized, idioms often can 
only be understood within the same cultural 
background; nevertheless, this is not a definite 
rule because some idioms can overcome 
cultural barriers and easily be translated across 
languages, and their metaphoric meanings can 
still be deduced. Contrary to common 
knowledge that language is a living thing, 
idioms do not readily change as time passes. 
Some idioms gain and lose favor in popular 
literature or speeches, but they rarely have any 
actual shift in their constructs as long as they do 
not become extinct. In real life, people also 
have a natural tendency to over exaggerate what 
they mean or over describe what they see or 
hear sometimes and this gives birth to new 
idioms by accident.  
Most Chinese idioms (??: ch?ng1  y?, 
literally meaning ?set phrases?) are derived 
from ancient literature, especially Chinese 
classics, and are widely used in written Chinese 
texts. Some idioms appear in spoken or 
vernacular Chinese. The majority of Chinese 
idioms consist of four characters, but some have 
fewer or more. The meaning of an idiom 
usually surpasses the sum of the meanings 
                                                                 
1 The marks on the letters in a Pinyin are for the five tones 
of Chinese characters.   
carried by the few characters, as Chinese idioms 
are often closely related with the fable, story or 
historical account from which they were 
originally born. As their constructs remain 
stable through history, Chinese idioms do not 
follow the usual lexical pattern and syntax of 
modern Chinese language which has been 
reformed many a time. They are instead highly 
compact and resemble more ancient Chinese 
language in many linguistic features.  
Usually a Chinese idiom reflects the moral 
behind the story that it is derived. (Lo, 1997) 
For example, the idiom ?????? (p? f? ch?n 
zh?u) literally means ?smash the cauldrons and 
sink the boats.? It was based on a historical 
story where General Xiang Yu in Qin Dynasty 
(221 B. C. ? 207 B. C.) ordered his army to 
destroy all cooking utensils and boats after they 
crossed a river into the enemy?s territory. He 
and his men won the battle for their ?life or 
death? courage and ?no-retreat? policy. 
Although there are similar phrases in English, 
such as ?burning bridges? or ?crossing the 
Rubicon?, this particular idiom cannot be used 
in a losing scenario because the story behind it 
does not indicate a failure. Another typical 
example is the idiom ?????? (gu? ti?n l? 
xi?) which literally means ?melon field, under 
the plum trees?. Metaphorically it implies a 
suspicious situation. Derived from a verse 
called ????? (j?n z? x?ng, meaning ?A 
Gentleman?s Journey?) from Eastern Han 
Dynasty (A. D. 25 ? A. D. 220), the idiom is 
originated from two lines of the poem ????
????????? (gu? ti?n b? n? l?, l? xi? b? 
zh?ng gu?n) which describe a code of conduct 
for a gentleman that says ?Don't adjust your 
shoes in a melon field and don?t tidy your hat 
under plum trees? in order to avoid suspicion of 
stealing. However, most Chinese idioms do not 
possess an allusion nature and are just a 
combination of morphemes that will give this 
set phrase phonetic, semantic or formal 
expressiveness. For example, the idiom ???
??? (hu?n ti?n x? d?, metaphorically meaning 
?be highly delighted?) literally means ?happy 
heaven and joyful earth?; or in the idiom ???
??? (l?ng d?ng r? y?, meaning ?be thrown 
into the jail?), the word ???? is just the sound 
of a prisoner?s fetters. 
12
For the importance of idioms in Chinese 
language and culture, an idiom bank with about 
6,790 entries were included in the most 
influential Chinese language knowledge base ? 
the Grammatical Knowledge base of 
Contemporary Chinese (GKB) completed by 
the Institute of Computational Linguistics at 
Peking University (ICL), which has been 
working on language resources for over 20 
years and building many knowledge bases on 
Chinese language. Based on that, the Chinese 
Idiom Knowledge Base (CIKB) had been 
constructed from the year 2004 to 2009 and 
collects more than 38, 000 idioms with more 
semantic and pragmatic properties added. 
Basically the properties of each entry in 
CIKB can be classified into four categories: 
lexical, semantic, syntactic and pragmatic, each 
of which also includes several fields in its 
container -- the SQL database. Table 1 shows 
the details about the fields. 
 
Categories Properties 
Lexical idiom, Pinyin2, full Pinyin3, 
bianti4, explanation, origin 
Semantic synonym, antonym, literal 
translation, free translation, 
English equivalent 
Syntactic compositionality, syntactic 
function 
Pragmatic frequency, emotion, event 
(context), grade 
 
Table 1. Property categories of CIKB. 
 
There are three fields of translation as we 
can see in Table 1. In spite of the fact that a 
                                                                 
2 Pinyin (??, literally ?phonetics?, or more literally, 
?spelling sound? or ?spelled sound?), or more formally 
Hanyu Pinyin (????, Chinese Pinyin), is currently the 
most commonly used Romanization system for standard 
Mandarin. The system is now used in mainland China, 
Hong Kong, Macau, parts of Taiwan, Malaysia and 
Singapore to teach Mandarin Chinese and internationally 
to teach Mandarin as a second language. It is also often 
used to spell Chinese names in foreign publications and 
can be used to enter Chinese characters on computers and 
cell phones. 
3 full Pinyin, a form of Pinyin that replaces the tone marks 
with numbers 1 to 5 to indicate the five tones of Chinese 
characters for the convenience of computer processing. 
4 bianti, a variant form of the idiom that was caused by 
random misuse, literary malapropism, etc. 
literal translation of an idiom will not reflect its 
metaphorical meaning generally, it will still be 
of value to those who expect to get familiar 
with the constituent characters and may want to 
connect its literal meaning with its metaphorical 
meaning, especially for those learners of 
Chinese as a foreign language. 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1. The hierarchical structure of CIKB. 
 
The idioms are classified into three grades 
in terms of appearance in texts and complexity 
of annotation. The most commonly used 3,000 
idioms serve as the core idioms based on the 
statistics obtained from the corpus of People?s 
Daily (the year of 1998), a newspaper that has 
the largest circulation in China. Another 11,000 
idioms are selected into a category named as 
basic idioms (fully annotated in every field) and 
the total 38,117 forms the whole knowledge 
base. Its hierarchical structure can be seen in 
Figure 1. 
The syntactic category aims at NLP tasks 
like automatic identification or machine 
translation. Compared with English idioms, the 
identification of Chinese idioms is not so 
difficult for its fossilized structure, i.e. 
continuity in a text. To build a lexicon like 
CIKB will complete the task successfully. As 
for machine translation, however, it is 
completely another story because the 
compositional complexity of Chinese idioms 
enables them to function as different syntactic 
constituents with variable part-of-speech (POS). 
We classify them into nine categories according 
to its compositional relations of the morphemes 
and into seven categories according to its 
syntactic functions that they may serve in a 
sentence, as is shown in Table 2. 
 
 
 
 
CIKB 38,117 
 
 
   Basic 11,000 
Core 3,000 
13
No. Compositionality Tag No. Syntactic function Tag 
1 modifier-head construction pz 1 as a noun IN 
2 subject-predicate phrase zw 2 as a verb IV 
3 Coordination bl 3 as an adjective IA 
4 predicate-object phrase db 4 as a complement IC 
5 predicate-complement dbu 5 as an adverbial ID 
6 predicate-object-complement dbb 6 as a classifier IB 
7 serial verb ld 7 as a modifier IM 
8 pivotal verb jy    
9 Repetition fz    
 
Table 2.  Compositionality and syntactic functions of idioms. 
 
Upon the completion of CIKB, a few 
research projects have been conducted to 
investigate possible applications. Li (2006) 
investigates the frequency and formation of 
idiom usage in People?s Daily and Wang (2010) 
selects 1,000 popular idioms from CIKB to 
compile a book for Chinese learners. On the 
basis of CIKB, we also made a couple of 
attempts on the automatic classification of 
idioms to identify the token-level characteristics 
of an idiom. This paper will focus on the 
emotion classification of idioms with machine 
learning method and the work will be elaborated 
in section 4. Here we define the emotion types 
as ?appreciative (A)?, ?derogatory (D)? and 
?neutral (N)?.  
3 Related Work on Idiom Knowledge 
Base and Its Applications 
There has not been much work on the 
construction of an idiom corpus or an idiom 
knowledge base. With this respect, Birke and 
Sarkar (2006) and Fellbaum (2007) are 
exceptions. Birke and Sarkar (2006) constructed 
a corpus of English idiomatic expressions with 
automatic method. They selected 50 expressions 
and collected about 6,600 examples. They call 
the corpus TroFi Example Base, which is 
available on the Web. 
As far as idiom identification is concerned, 
the work is classified into two kinds : one is for 
idiom types and the other is for idiom tokens. 
With the former, phrases that can be interpreted 
as idioms are found in text corpora, typically for 
lexicographers to compile idiom dictionaries. 
Previous studies have mostly focused on the 
idiom type identification (Lin, 1999; Baldwin et 
al., 2003; Shudo et al, 2004). However, there 
has been a growing interest in idiom token 
identification recently (Katz and Giesbrecht, 
2006; Hashimoto et al, 2006; Cook et al , 2007). 
Our work elaborated in section 4 is also an 
attempt in this regard. 
    Despite the recent enthusiasm for 
multiword expressions, the idiom token 
identification is in an early stage of its 
development. Given that many language 
teaching and learning tasks like TCFL have been 
developed as a result of the availability of 
language resources, idiom token identification 
should also be developed when adequate idiom 
resources are provided. To this end, we have 
constructed the CIKB and hope to find 
applications of value, for example, emotion 
classification, event classification and text 
analysis based on idiom usage and its context.  
According to the granularity of text, 
emotion analysis of texts can be divided into 
three levels: text (Pang et al, 2002; Cui et al, 
2006), sentence (Pang et al, 2004), word 
(Hatzivassiloglou et al, 1997; Wiebe 2000). 
According to the sources of emotion prediction, 
classification methods can be divided into 
knowledge based methods and machine learning 
based methods. The former uses lexicons or 
knowledge bases to build a new lexicon that 
contains emotion words. WordNet is often used 
to compute the emotion prediction of words 
(Hatzivassiloglou et al, 1997; Andrea 2005). 
Meanwhile, incorporating knowledge into the 
machine learning architecture as features is a 
popular trend and untagged copra are often used 
to do emotion classification research (Turney et 
al., 2002; Akkaya et al, 2009).  
14
4 An NLP Application of Emotion 
Classification on CIKB 
In this paper, we focus on the emotion prediction 
of idioms conducted by machine learning 
method. To do this, we aim to investigate how 
the compositional constituents of an idiom affect 
its emotion orientation from the token level, 
especially for multi-word expressions with so 
obvious an exaggerative and descriptive nature 
like idioms. From CIKB, 20,000 idioms are 
selected as the training corpus and 3,000 idioms 
as the test corpus. The detailed distribution of 
idioms in each emotion group is shown in Table 
3. We can see that neutral has the largest number 
of idioms, accounting for 41.08% and 36.67% in 
the training and test corpus respectively, but 
there is not a big difference between groups. 
 
 
Training corpus Test corpus 
number percentage number Percentage 
Appreciative(A) 6967 34.84% 1011 33.70% 
Neutral(N) 8216 41.08% 1100 36.67% 
Derogatory(D) 4817 24.08% 889 29.63% 
 
Table 3.  The distribution of idioms in each emotion group. 
 
Support Vector Machine (SVM) (Cortes 
and Vapnik, 1995) is adopted as the 
classification method to predict emotions in 
idioms. LIBLINEAR (Fan et al, 2008), a 
library for large SVM linear classification, is 
used for implementation. The solver is set be 
L2-loss SVM dual. Parameter C is set to be 2-5. 
Three classes of features and their various 
combinations are examined and used, including 
Chinese characters, words and part-of-speeches. 
Detailed features and related abbreviations are 
shown as in Table 4. 
Because Chinese sentences are written in 
a consecutive string of characters, we need to 
segment a sentence into individual words to 
obtain the word feature. ICTCLAS (Zhang et 
al., 2003), a tool developed by the Institute of 
Computing Technology of Chinese Academy 
of Sciences (ICT), is used for word 
segmentation and part-of-speech tagging. We 
adopt precision, recall and F-score (?=1) as the 
evaluation parameters. From Table 5 we can 
see that i_cb has a better performance than i_cu, 
which indicates that a bigram model usually 
performs better than a unigram model. But 
when we segment the idioms and use i_wu, we 
find that the performance gets bad. This may 
be because the compositionality of Chinese 
idioms is quite fossilized and the errors caused 
by segmentation introduce some noise.  
 
Features and their abbreviations Idiom(i) Explanation(e) 
Chinese characters character unigram(i_cu, e_cu) ?5 ? 
character bigram(i_cb, e_cb) ? ? 
Words word unigram(i_wu, e_wu) ? ? 
word bigram(i_wb, e_wu) ? ? 
Word/part-of-speech word/pos unigram(i_wpu, e_wpu) ? ? 
word/pos bigram(i_wpb, e_wpb) ? ? 
 
Table 4.  Features selected for emotion prediction. 
                                                                 
5 ??? indicates  the feature is selected while ??? indicates the feature is not selected. 
15
We want to know whether we will have a 
better performance if we add more features 
from the other fields of CIKB. Obviously the 
most relevant feature will be the explanation of 
an idiom. Therefore we add the texts in the 
explanation field as features in the experiment.  
We find that by adding more features from the 
explanation field, the performance does 
improve. But when the POS feature is 
introduced, the performance gets bad. This may 
be because as Chinese idioms keep 
grammatical properties of ancient Chinese 
language and its POS is very different from the 
setting of the tool designed primarily for 
modern Chinese, more noise is introduced by 
using POS here. Finally we can see that the 
combination i_cu+i_cb+e_wu+e_wb achieves 
the best performance in both Chinese character 
features and word features.  
Most importantly, we notice that although 
for idioms themselves segmentation does not 
affect the performance in a positive way, 
segmentation of the explanations does improve 
the performance. Thus we may conclude that 
the compositionality of an idiom is very 
different from its explanation which is written 
in modern Chinese while the idiom itself is still 
character-based and keeps its original 
morphemes that are inherited from ancient 
Chinese language.  
 
Features or features 
combined 
Result 
Precision Recall F-score 
i_cu 63.23% 75.16% 68.68% 
i_cb 65.78% 78.24% 71.47% 
i_wu 62.51% 73.42% 68.35% 
i_wpu 60.03% 71.89% 65.43% 
i_cu+e_wu 66.40% 80.05% 72.59% 
i_cu+e_wpu 65.68% 77.95% 71.29% 
i_cu+e_wb 65.08% 76.14% 70.18% 
I_cu+i_cb 67.33% 80.82% 73.46% 
i_cu+i_cb+e_wu 68.55% 81.37% 74.41% 
i_cu+i_cb+e_wu+e_wb  70.18% 82.71% 75.93% 
 
Table 5. The result of emotion classification with idioms and their explanations. 
 
55%
60%
5%
70%
75%
80%
1k 2k 5k 10k 15k 20k
Size of training data
A
c
c
u
r
a
c
y
 
Figure 2. Learning curve of the feature combination i_cu+i_cb+e_wu+e_wb. 
 
Figure 2 shows the learning curve of the 
best classifier with the feature combination 
i_cu+i_cb+e_wu+e_wb. We can see that the 
accuracy keeps improving with the increase of 
the size of training set, and peaks at 20,000 
idioms. It shows the potential to improve the 
16
performance of emotion classification by 
enlarging the training data set. 
5  Conclusions and Future Work 
This paper introduces the construction of CIKB 
by ICL at Peking University and its several 
applications so far. One application ? the 
emotion classification of idioms ? was 
elaborated to show our effort in exploring the 
token-level characteristics of Chinese idioms. 
Therefore we select a number of idioms from 
CIKB to classify them into three emotion 
groups. SVM is employed for automatic 
classification. Three classes of features are 
examined and experiments show that certain 
feature combinations achieve good 
performance. The learning curve indicates that 
performance may be further improved with the 
increase of training data size.  
Now we also hope to classify the idioms 
into categories according to their usage in 
context, i.e., under what circumstances they are 
often used (event classification). Various 
linguistic features and real-world knowledge 
will be considered to incorporate into the 
machine learning classifier to improve 
classification result. The work is in progress 
and we hope the emotion classification and the 
event classification will be compared to 
determine their underlining relations and hope 
that more applications can be found in our 
future work based on CIKB. 
Acknowledgements  
The work in this paper is supported by a grant 
from the 973 National Basic Research Program 
of China (No. 2004CB318102). The authors 
are grateful to Dr. Li Yun and Professor Zhu 
Xuefeng for their work on CIKB and the 
anonymous reviewers for their helpful advice 
to improve the paper. 
 
References 
 
Akkaya, Cem, Janyce Wiebe, and Rada 
Mihalcea. 2009. Subjectivity Word Sense 
Disambiguation. In Proceedings of the 
2009 Conference on Empirical Methods in 
Natural Language Processing: Volume 1: 
pp.190-199. 
Andrea, Esuli. 2005. Determining the Semantic 
Orientation of Terms through Gloss 
Classification. In Proceedings of the 14th 
ACM International Conference on 
Information and Knowledge Management : 
pp.617-624.  
Baldwin, Timothy, Colin Bannard, Takaaki 
Tanaka, and Dominic Widdows. 2003. An 
Empirical Model of Multiword Expression 
Decomposability. In Proceedings of the 
ACL 2003 Workshop on Multiword 
Expressions: Analysis, Acquisition and 
Treatment - Volume 18: pp.89-96. 
Cook, Paul, Afsaneh Fazly, and Suzanne 
Stevenson. 2007. Pulling Their Weight : 
Exploiting Syntactic Forms for the 
Automatic Identification of Idiomatic 
Expressions in Context. In Proceedings of 
the Workshop on A Broader Perspective 
on Multiword Expressions: pp. 41-48. 
Cortes, Corinna and Vladimir Vapnik. 1995. 
Support-Vector Networks. Machine 
Learning, 20(3): pp. 273-297. 
Cui, Hang, Vibhu Mittal, and Mayur Datar. 
2006. Comparative Experiments on 
Sentiment Classification for Online 
Product Reviews. In Proceedings of the 
21st National Conference on Artificial 
Intelligence-Volume 2: pp.1265-1270. 
Fan, Rong-En, Chang Kai-Wei, Cho-Jui Hsieh, 
Xiang-Rui Wang, Chih-Jen Lin. 2008. 
LIBLINEAR: A Library for Large Linear 
Classification. Journal of Machine 
Learning Research 9 (2008): 
pp.1871-1874. 
Fellbaum, Christiane. 2007. Idioms and 
Collocations: Corpus-based Linguistic 
and Lexicographic Studies (Research in 
Corpus and Discourse). Continuum 
International Publishing Group Ltd. , 
London, UK. 
Hashimoto, Chikara, Satoshi Sato, and 
Takehito Utsuro. 2006. Japanese Idiom 
Recognition: Drawing a Line between 
Literal and Idiomatic Meanings. In 
Proceedings of the COLING/ACL on 
17
Main Conference Poster Sessions: pp. 
353-360. 
Hatzivassiloglou, Vasileios, and Kathleen 
McKeown. 1997. Predicting the Semantic 
Orientation of Adjectives. In Proceedings 
of the Eighth Conference on European 
Chapter of the Association for 
Computational Linguistics: pp.174-181. 
Katz, Graham, and Eugenie Giesbrecht. 2006. 
Automatic Identification of 
Non-compositional Multi-word 
Expressions Using Latent Semantic 
Analysis. In Proceedings of the Workshop 
on Multiword Expressions: Identifying 
and Exploiting Underlying Properties: 
pp.12-19. 
Li, Yun, Zhang Huarui, Wang Hongjun, and 
Yu Shiwen. 2006. Investigation on the 
Frequency and Formation of Idioms in 
People?s Daily. In Proceedings of the 7th 
Chinese Lexicon and Semantics Workshop: 
pp.241-248. 
Lin, Dekang. 1999. Automatic Identification of 
Noncompositional Phrases. In 
Proceedings of the 37th Annual Meeting 
of the Association for Computational 
Linguistics on Computational Linguistics: 
pp.317-324. 
Lo, Wing Huen. 1997. Best Chinese Idioms 
(Vol. 3). Hai Feng Publishing Co., Hong 
Kong, China.  
McArthur, Tom. 1992. The Oxford Companion 
to the English Language. Oxford 
University Press, Oxford, UK. 
Pang, Bo and Lillian Lee. 2004. A Sentimental 
Education: Sentiment Analysis Using 
Subjectivity Summarization Based on 
Minimum Cuts. In Proceedings of the 
42nd Annual Meeting on Association for 
Computational Linguistics: pp.271-278. 
Pang, Bo, Lillian Lee, and Shivakumar 
Vaithyanathan. 2002. Thumb up? 
Sentiment Classification Using Machine 
Learning Techniques. In Proceedings of 
the ACL-02 Conference on Empirical 
Methods in Natural Language Processing: 
pp.79-86. 
Shudo, Kosho, Toshifumi Tanabe, Masahito 
Takahashi, and Kenji Yoshimura. 2004. 
MWEs as Nonpropositional Content 
Indicators. In Proceedings of the 
Workshop on Multiword Expressions: 
Integrating Processing: pp.32-39. 
Turney, Peter D. 2002. Thumps Up or Thumps 
Down? Semantic Orientation Applied to 
Unsupervised Classification of Reviews. 
In Proceedings of the 40th Annual 
Meeting on Association for Computational 
Linguistics: pp.417-424. 
Wang, Lei. Forthcoming 2010. 1,000 Idioms 
for Chinese Learners. Peking University 
Press, Beijing, China. 
Wiebe, Janyce. 2000. Learning Subjective 
Adjectives from Corpora. In Proceedings 
of the Seventeenth National Conference on 
Artificial Intelligence and Twelfth 
Conference on Innovative Applications of 
Artificial Intelligence: pp.735-740. 
Zhang, Huaping, Yu Hongkui, Xiong Deyi,  
Liu Qun. 2003. HHMM-based Chinese 
Lexical Analyzer ICTCLAS. In 
Proceedings of the Second SIGHAN 
Workshop on Chinese Language 
Processing: pp.184-187. 
 
18
Semantic Computing and Language Knowledge Bases1 
 
Lei Wang  
Key Laboratory of Computational Linguistics 
of Ministry of Education 
Department of English, Peking University 
wangleics@pku.edu.cn 
Shiwen Yu  
Key Laboratory of Computational 
Linguistics of Ministry of Education, 
Peking University 
yusw@pku.edu.cn 
                                                 
1 This work is supported by the National Natural Science Foundation of China (No. 60970083) and Chiang Ching-kuo 
Foundation for International Scholarly Exchange (2009).  
Abstract 
As the proposition of the next-generation 
Web ? semantic Web, semantic computing 
has been drawing more and more attention 
within the circle and the industries. A lot of 
research has been conducted on the theory 
and methodology of the subject, and 
potential applications have also been 
investigated and proposed in many fields. 
The progress of semantic computing made 
so far cannot be detached from its 
supporting pivot ? language resources, for 
instance, language knowledge bases. This 
paper proposes three perspectives of 
semantic computing from a macro view and 
describes the current status of affairs about 
the construction of language knowledge 
bases and the related research and 
applications that have been carried out on 
the basis of these resources via a case study 
in the Institute of Computational Linguistics 
at Peking University. 
 
1 Introduction 
Semantic computing is a technology to compose 
information content (including software) based 
on meaning and vocabulary shared by people 
and computers and thereby to design and 
operate information systems (i.e., artificial 
computing systems). Its goal is to plug the 
semantic gap through this common ground, to 
let people and computers cooperate more 
closely, to ground information systems on 
people?s life world, and thereby to enrich the 
meaning and value of the entire life world. 
(Hasida, 2007) The task of semantic computing 
is to explain the meaning of various constituents 
of sentences (words or phrases) or sentences 
themselves in a natural language. We believe 
that semantic computing is a field that addresses 
two core problems: First, to map the semantics 
of user with that of content for the purpose of 
content retrieval, management, creation, etc.; 
second, to understand the meanings (semantics) 
of computational content of various sorts, 
including, but is not limited to, text, video, 
audio, network, software, and expressing them 
in a form that can be processed by machine.
 
Figure 1. Human-computer interaction is handicapped without semantic computing. 
But the way to the success of semantic 
computing is not even and it has taken a quite 
long time for researchers to make some 
progress in this field. The difficulties of 
semantic computing involve many aspects: 
ambiguity, polysemy, domain of quantifier, 
metaphor, etc. Different individuals will have 
different understanding of the same word or the 
same sentence. Research on the theory and 
methodology of semantic computing still has a 
long way to go. 
Now we provide an example in a search 
engine to show how difficult for the computer 
to understand the meaning of a word. We input 
two sentences into Google.com Translate and 
the following results were returned: 
 
Example 1   
I bought a table with three dollars.?20091016 Google: ???? 3 ????? 
I bought a table with three legs.   ?20091016 Google: ???? 3????? 
 
We know that the word ?table? has two 
common meanings in English (a wooden object 
and a structured data report). But in Chinese 
they correspond to two different words (? bi?o 
and ?? zhu? zi2). From Example 1, we can 
see that the search engine cannot distinguish the 
two senses and translate them both as ?. Thus, 
without semantic analysis queries in a search 
engine may result in very poor performance. 
The first principle of a search engine is based 
on shallow Natural Language Processing (NLP) 
techniques, for instance, string matching, while 
future direction of search engines should aim at 
content index and the understanding of user?s 
intention. Semantic computing becomes 
applicable only with the development of deep 
NLP techniques. Machine Translation (MT) is 
the first application of digital computers in the 
non-digital world and semantic information is 
indispensable in MT research and applications. 
However, there has been no breakthrough to the 
extent of Natural Language Understanding 
(NLU) and semantic computing may serve as 
the key to some success in this field.  
2 Related Work on Semantic Computing 
Semantics is an interesting but controversial 
topic. Many a theory has been proposed in 
attempt to describe what meaning really means. 
                                                 
2  Pinyin is currently the most commonly used 
Romanization system for standard Mandarin. The system 
is now used in mainland China, Hong Kong, Macau, parts 
of Taiwan, Malaysia and Singapore to teach Mandarin 
Chinese and internationally to teach Mandarin as a second 
language. It is also often used to spell Chinese names in 
foreign publications and can be used to enter Chinese 
characters on computers and cell phones. 
But up until now there has not been a theory 
that can describe the meaning of various 
language units (words, phrases and sentences) 
so perfectly that was accepted universally, even 
though Fillmore?s proposition of Framework 
semantics (1976) is successful enough. Since 
Gildea et al (2002) initiated the research on 
automatic semantic role labeling, many 
evaluations have been conducted internationally, 
such as Senseval-3 and SemEval 2007, as well 
as CoNLL SRL Shared Task 2004, 2005 and 
2008. Word Sense Disambiguation (WSD) is 
also a very important research subject and a lot 
of work has been done in this regard, such as 
Lesk (1986), Gale et al (1998), Jin et a l. (2007) 
and Qu et al (2007) as the Chinese counterpart. 
As to the research on computing word sense 
relatedness, Dagan et al(1993) did some pilot 
work and Lee (1997) and Resnik (1999) 
contributed to the research on semantic 
similarity.  
In recent years, semantics-based analysis 
such as data and web mining, analysis of social 
networks and semantic system design and 
synthesis have begun to draw more attention 
from researchers. Applications using semantics 
such as search engines and question answering 
(Li et al, 2002), content-based multimedia 
retrieval and editing, natural language interfaces 
(Yokoi et al, 2005) based on semantics have 
also been attracting attentions. Even semantic 
computing has been applied to areas like music 
description, medicine and biology and GIS 
systems and architecture. The whole idea is how 
to realize human-centered computing. 
 
 
3 The Theory and Methodology of 
Semantic Computing 
3.1 Important Questions That Need to Be 
Asked about Semantic Computing 
In the past few years there has been a growing 
interest in the field of semantics and semantic 
computing. But there are questions that have 
been always lingering on researchers? minds. 
What on earth semantics is? What is the best 
way to describe the meaning of a language unit? 
How can natural languages be processed so that 
we are able to benefit from human-computer 
interaction, or even interpersonal 
communication? It seems that no one can give 
satisfactory answers to these questions. But it is 
now commonly agreed that the study of 
semantic computing or knowledge 
representation is a central issue in 
computational linguistics. The major 
contributions on this topic are collected in 
Computational Linguistics (1987-2010) and 
International Journal of Semantic Computing 
(2007-2010). Research in computing semantics 
is, however, rather heterogeneous in scope, 
methods, and results. The traditional ?wh? and 
?how? questions need to be asked again to 
understand the consequences of conceptual and 
linguistic decisions in semantic computing: 
What? What should be computed in terms 
of semantics? Each word is a world and its 
meaning can be interpreted differently. Despite 
the interest that semantics has received from the 
scholars of different disciplines since the early 
history of humanity, a unifying theory of 
meaning does not exist, no matter whether we 
view a language from a lexical or a syntactic 
perspective. In practice, the quality and type of 
the expressed concepts again depend upon the 
one who uses it: any language speaker or writer, 
a linguist, a psychologist, a lexicographer, or a 
computer. In psycholinguistics and 
computational linguistics, semantic knowledge 
is modeled with very deep and formal 
expressions. Often semantic models focus on 
some very specific aspect of language 
communication, according to the scientific 
interest of a researcher. In natural language 
processing, lexical entries or semantic attributes 
typically express linguistic knowledge as 
commonsensically understood and used by 
humans. The entries or attributes are entirely 
formatted in some knowledge representation 
and can be manipulated by a computer.  
Where? What are the sources of semantic 
knowledge? Traditionally, individual 
introspection is often a source of obtaining 
word senses. However, individual introspection 
brings about both theoretical and 
implementation problems. Theoretically, it is 
because ?different researchers with different 
theories would observe different things about 
their internal thoughts...? (Anderson 1989). 
With regard to implementation, it is because 
consistency becomes a major problem when the 
size of the lexicon or the syntactic tree bank 
exceeds a few thousands entries or annotation 
tags. Despite the scientific interest of such 
experiments, they cannot be extensively 
repeated for the purpose of acquiring mass word 
sense definitions. On-line corpora and 
dictionaries are widely available today and 
provide experimental evidence of word uses and 
word definitions. The major advantage of 
on-line resources is that in principle they 
provide the basis for very large experiments, 
even though at present the methods of analysis 
and application are not fully developed and 
need further research to get satisfactory results.  
How? Semantic computing can be realized 
at various levels. The hard work is to implement 
a system in a real domain, or the more 
conceptual task of defining an effective 
mathematical framework to manipulate the 
objects defined within a linguistic model. Quite 
obviously the ?hows? in the literature about 
semantic computing are much more important 
than the ?whats? and ?wheres?. The 
methodology that really works in semantic 
computing is deeply related to the ultimate 
objective of NLP research, which still cannot be 
defined adequately so far.  
3.2 The Perspectives of Semantic Computing 
from a Macro View 
Why semantic computing (or NLU) has posed 
so great a challenge? We may attribute this to 
two major reasons: First, it is based on the 
knowledge of human language mechanism. If 
fully-developed complicated brains are often 
seen as a crowning achievement of biological 
evolution, the interpersonal communication is 
no simpler than human biological mechanism. 
Language has to be a crucial part of the 
evolutionary process, which has not been fully 
understood by scientific research. Second, in 
NLP research the language is both the target and 
the tool. Current NLP research focuses on either 
speech or written texts only. However, in the 
real world scenario, reading and interaction 
between humans are multi-dimensional 
(through different forms of information such as 
text, speech, or images and utilizing our 
different senses such as vision, hearing). It is 
necessary to rely on the advancements of brain 
science, cognitive science and other related 
fields and work in collaboration to produce 
better results. Linguistics, especially 
computational linguistics, has made its own 
contribution, and semantic computing will play 
an important role in NLP. 
There are complex many-to-many relations 
between the form and the meaning of a 
language. Semantic computing is not only the 
way but also the ultimate goal of natural 
language understanding. Although it is hard, we 
should not give up. Here we propose that the 
main contents of semantic computing include 
the following three aspects: 
? semantic computing on the ontological 
perspective 
? semantic computing on the cognitive 
perspective 
? semantic computing on the pragmatic 
perspective 
As for ontologies, much progress has been 
made worldwide. The remarkable achievements 
in English include: WordNet by Princeton 
University, PropBank by University of 
Pennsylvania, etc. Also there are quite a number 
of efforts made on building ontologies in 
Chinese, which will be elaborated in Section 5.  
In the last few years, the main direction of 
semantic computing is to disambiguate 
language units and constructions. In the 
following Example 2, the word ?? y? bi?o 
has two meanings in different contexts. In 
Chinese, word segmentation is also a problem 
that needs to be addressed. In Example 3, 
segmenting the word ??? b?i ti?n ? as ?/
??  or ?? /?  can result in different 
understanding of the sentences. 
 
Example 2 
???????? t? de y? bi?o h?n du?n zhu?ng (She has a graceful appearance.) 
???????? t? de y? bi?o h?n j?ng qu? (Her meters are very accurate.) 
 
Example 3 
????????b?i ti?n ? f?i gu? l?i le (A white swan flies toward us.) 
????????b?i ti?n ? k? y? k?n ji? (A goose can guard our house at daytime.) 
 
As to WSD tasks on the word level, some 
problems can be solved when ontology is 
applied. But ambiguity can also appear on the 
syntactic level. For this, it is usually difficult for 
ontologies to do much, so we may seek help 
from language knowledge bases (See Section 5). 
The following examples of syntactic semantic 
analysis will illustrate how different syntactic 
structures will change the meaning of sentences:  
 
Example 4 
?????????????                    --??????? 
zh? y?ng de di?n y?ng b? sh? l? j? sh? sh?n me?        -- g?i di?n y?ng sh? l? j? 
If a movie as such is not rubbish, what is it?          -- It is rubbish.  
??????????????                  -- ???????? 
zh? y?ng de di?n y?ng z?n me n?ng shu? sh? l? j? ne?   -- g?i di?n y?ng b? sh? l? j? 
How can a movie as such be rubbish?               -- It is not rubbish.  
 
 
Example 5 
?????, ??????               -- ??????? 
m? zh? sh? m? zh? , q? q? sh? q? q?       -- m? zh? b? sh? q? q?  
A grasshopper is a grasshopper, while a cricket is a cricket.  -- A grasshopper is not a cricket. 
Rule?A is A, while B is B.  ???A is not B. 
???, ????d?ng sh? d?ng, m?o sh? m?o  
Ding is ding, while mao is mao.    ? being conscientious 
 
With respect to semantic computing on 
cognitive level, we will use metaphor as an 
example. For a long time, NLP research has 
focused on ambiguity resolution. Can NLU be 
realized after ambiguity resolution? Metaphor, 
insinuation, pun, hyperbole (exaggeration), 
humor, personification, as well as intended 
word usage or sentence composing, pose a great 
challenge to NLU research. If the computer can 
deal with metaphors, it will greatly improve the 
ability of natural language understanding.  
First, let?s discuss the rhetorical function of 
a metaphor. Metaphor is extensively and 
skillfully used in the Chinese classic ?Book of 
Songs? to boost expressiveness.  
 
Example 6 
Simile:   ?????????3???????????         --??????? 
z? b? zh? d?ng ?sh?u r? f?i p?ng ?q? w? g?o m? ? shu? sh? w?i r?ng?-- ?w?i f?ng ?b? x?? 
(Your hair is like disordered grass.)   
Metaphor???????????   --??????? 
t? sh?n zh? sh? ?k? y? g?ng y??      --?xi?o y?? h? m?ng? 
(Rocks from another mountain can be used to carve jade. Metaphorically this phrase means a  
change of method may solve the current problem.) 
 
                                                 
3 For the purpose of conciseness, only the underlined parts that contain metaphors are translated. 
Also, many Chinese idioms are 
metaphorical expressions: ???? t?ng zh?u 
g?ng j? (Literally, to cross the river in the same 
boat; metaphorically, to work together with one 
heart while in difficulty), ???? t?ng qi?ng 
ti? b? (Literally, walls of brass and iron; 
metaphorically, impregnable). The Chinese 
language makes use of lots of idioms or 
idiomatic expressions that are derived from 
ancient Chinese stories and fables. These 
idioms and idiomatic expressions are often used 
metaphorically and reflect historical and 
cultural background of the language. They are 
the most precious relics to the Chinese language 
and culture. Therefore the Chinese Idiom 
Knowledge Base (CIKB) was also built in 2009. 
CIKB consists of 38,117 entries and describes 
many attributes of Chinese idioms. Among the 
attributes, ?literal translation?, ?free translation? 
and ?English equivalent? are very valuable.  
The linguistic function of metaphor is also 
important. Metaphor is the base of new word 
creation and polysemy production (sense 
evolution), for example, ??? l? j? xi?ng 
(recycle) and ?? b?ng d? (virus) are used in a 
computer setting and words like ?? g?o f?ng 
(peak), ?? p?ng j?ng (bottleneck) and ??
xi?n su? (clue) are endowed with new meanings 
which have not been included in traditional 
Chinese dictionaries. Besides, metaphor creates 
new meanings in sentence level, for instance, in 
?????????d? qi? sh? r?n l?i de m? q?n 
(The earth is the mother of humanity.), the word 
?? (mother) has a different meaning. So, 
metaphor understanding is beyond the scope of 
ambiguity resolution. Metaphor, linguistics, and 
human cognitive mechanisms are inextricably 
interlinked. So metaphor becomes a fort that 
must be conquered in NLU research.  
From an NLP perspective, metaphors can 
be summarized into the following categories as 
in Table 1. As for the NLP tasks of metaphor 
computing, we can conclude that there are three 
tasks to be accomplished: First, metaphor 
recognition. For instance, how can we 
distinguish ????? from ?????? 
h?i y?ng z? yu?n k?o ch? (investigation of 
ocean resources); Second, metaphor 
understanding and translation. For instance, ?
???? actually means ????????
??zh? sh? xi?ng h?i y?ng y? y?ng f?ng f? 
(Knowledge is as rich as the ocean.). Third, 
metaphor generation. For instance, how phrases 
such as ?????x?n x? de h?i y?ng (ocean 
of information) and ????? xi?n hu? de 
h?i y?ng (ocean of flowers) can be generated 
successfully by computer? 
  
Perspective of grammatical 
properties 
Perspective of language unites of  
metaphorical expressions 
Nominal ????? z? gu? de hu? du? 
(flower of the country), ??
?? ? sh?ng m?ng de l? 
ch?ng (life journey) 
Word-formation 
level 
?? lu?n sh?(egg-like stone), ???
x?ng r?n y?n (apricot-like eyes) 
Verb ???? x?n ch?o p?ng p?i 
(heart wave ), ???? f?ng 
f?i l? xi?ng (let f dream fly) 
Word level ?? ch?o li? (t ide), ?? zh?o y?ng 
(morning sun) 
Adjective ?????????zh? pi?n  
w?n zh?ng xi? de g?n b?(This 
article is written drily), ??
???????zh? p i?n w?n  
zh?ng q?ng t?ng gu? shu? 
(This article is like plain soup 
and water.) 
Phrase level ????? zh? sh? de h?i y?ng (ocean 
of knowledge), ??????? b? 
zh?ng x?ng f? de zh?ng zi (to sow the 
seeds of happiness) 
Adverb ? ? ? ? ch?n cu? h? 
shu?(absolute nonsense) 
Sentence level ??????q? ch? h? q? y?u (Cars 
drink gasoline.), ???? n? r?n sh? 
shu? (A woman is water.) 
  Discourse level ??????????????????
??????d? q? hu?ng y?ng ?r, m? ji?o 
zh? sh?ng t??t? sh? j?ng qi? m?ng, b? d? 
d?o li?o x? ? (To scare away the 
nightingales for their noise has my dream 
in which I went to the west to meet my 
dear husband.) 
 
Table 1.  Categories of metaphors from NLP perspective. 
 
Currently we focus on recognition and 
understanding of metaphors on phrase and 
sentence level. The automatic processing 
methods of metaphors can be summarized as 
two: First, rule (or logic)-based method, i.e., 
finding the conflicts between the target and the 
source, and search their common properties. 
 
Example 7 
?????????zh? g? r?n sh? y? t?u sh? zi (This man is a lion)   
? only the target and the source 
????????n? g? r?n sh? l?o h? li (That man is an old fox.)   
? only the target and the source 
???????????????????s?n l?n l? j? y?u y?ng m?ng de sh? zi, y? y?u ji?o 
hu? de h? li (In the forest, there are both brave lions and sly foxes.)    
--- find out properties of the sources 
????????????????zh? g? r?n sh? y?ng m?ng de, n? g? r?n sh? ji?o hu? de 
 (This man is brave, while that man is sly.) 
 
The utterance ???????????
h? b?i y?u g? l?o t?i t?i ch? t? ku?i (An old lady 
in Hebei eats clay.) is not in conformity with 
common sense, but it is not a metaphor; 
whereas ???????n?n r?n d?u sh? d?ng 
w? (All men are animals.) is logical but it may 
be a metaphor in certain context and may not be 
in another context.  
Second, empirical (statistical) method i.e., 
providing machine with a large number of 
samples and training a model. Yu Shiwen 
presided over the national 973 project 
?Database for text content understanding? 
(2004-2009), which includes a subtask named 
?Analysis of Metaphorical Expressions and 
Their Pointed Contents in Chinese Texts?. In 
this project, various machine learning methods 
have been applied to do semantic analyses from 
the token level. Among them, Wang Zhimin 
completed her doctoral thesis ?Chinese Noun 
Phrase Metaphor Recognition? in 2006. Jia 
Yuxiang studied verb metaphor recognition and 
?X is Y? type metaphor understanding and 
generation. Qu Weiguang presided over the 
National Natural Science Fund Project 
?Research on Key Technologies in Chinese 
Metaphor Understanding? (2008-2010).  
    From a statistical point of view, metaphor 
recognition can be seen as a problem to 
compute the conditional probability p(m|c) to 
decide whether ?? is a metaphor in context c. 
The reversed order of two variants m and c will 
not change the value of unified probability of 
p(m|c) and p(c|m),while the relation between 
unified probability and conditional probability 
can be written as:  
 
                                  (1)    
 
Then,                                        
                                  (2)                                                
 
Given c?p(c) is a constant. Then, 
 
                                  (3)                                                     
 
Given a threshold? , if             >? , 
then we can deem this ?? is a metaphor.  
Then the problem becomes how to 
compute            . We can compute it 
based on large-scale annotated corpus and get  
 
                            (4)  
 
Nm ? the times of ?? as a metaphor in the 
corpus; 
N  ? the total times of ?? in the corpus. 
 
Then we simplify ?? and its context c 
into: W-k  ? W-1 ?? W1 ? Wi , where W-k, ?, 
W-1, W1,?, Wi represent the n-gram of ?? 
and its syntactic and semantic attributes 
respectively.  
 
                                   (5) 
 
                                    (6) 
 
N(Ws) stands for the times of 
co-occurrence of ?? as a metaphor and word 
W with designated attributes at position. Here 
an important hypothesis of independence is: 
words at different position s is not correlated 
with the word ??. 
Last, we will discuss semantic computing 
on the pragmatic perspective, which is more or 
less unique of Chinese language. First, the 
change of construction in Chinese will affect 
the meaning of a sentence even though the 
words themselves are not changed. The 
emphasized meaning of the construction is not 
equal to the combination of the underlying 
meaning from each element in the construction. 
The meaning reflects the distribution of quantity 
of entities and the relative locations among 
entities. Although the underlying syntactic 
relationship among the main verb, the agent and 
the object(s) still exists, such syntactic 
relationship is only secondary. As in the 
sentence ??????????zh? zh?ng 
chu?ng k? y? shu? s?n g? r?n (This bed can 
sleep three people.) is different in meaning from 
the sentence ??????????(Three 
people can sleep on this bed.). Second, the 
)|()()|()( mcpmpcmpcp ?
)/)|()()|( cpmcpmpcmp ?
)|()()|( mcpmpcmp ?
)|()( mcpmp
NNmp m /)( ?
)|()|()|()|()|( 11 mWpmWpmWpmWpmcp ik ?? ???
),,1,1,,(,/)()|( iksNWNmWp wss ?? ???? ??
)|()( mcpmp
semantic direction of the complement in 
verb-complement constructions and the 
adverbial phrase in verb-adverbial constructions 
also change the semantic roles of each 
constituent. For instance, ????????
? w?n zh?ng ? xi? w?n le ((The article) is 
completed.) or ????????? l?o sh? ? 
xi? l?i le ((The teacher) is tired for writing.) or 
????????????xi?ng p?n p?n d? 
zh? le y? p?n hu? sh?ng m?(aromatically fried a 
plate of peanuts). Here the ontology cannot 
provide enough information to reflect the 
process and result of change in semantic roles. 
Thus the Generalized Valence Mode (GVM) is 
proposed to describe not only participants of the 
action, but also the change of participants? states. 
Third, our ultimate goal will be to achieve 
?semantic harmony?. For instance, in both 
English and Chinese we can say ??? b? ch? 
l?i (pull out) or ??? ch? j?n q? (thrust 
into), but we never say ??? (thrust out) or 
??? (pull into). It is alright to say ???
???????n? g? d? p?n gu? t? d?u ch? le 
(That big apple he eats it all.) , but it is 
awkward to say??????????n? k? 
xi?o h? t?o t? d?u ch? le (That small chestnut he 
eats it all.). In fact we can say ??????
?????n? k? xi?o h? t?o s?ng sh? d?u ch? le 
(That small chestnut the squirrel eats it all.).  
Figure 2. Empirical (statistical) method of metaphor processing. 
 
Professor Lu Jianming (2010) remarked on 
the realization of semantic harmony. The 
principle of semantic constraint of words 
essentially requires that the words in sentences 
should be harmonic in terms of meaning. 
Analysis of ill-formed sentences and automatic 
language generation will benefit from the 
research in semantic harmony. Semantic 
computing on the pragmatic level has unique 
characteristics with respect to Chinese language. 
The solution of these problems poses a great 
challenge and will make great contribution to 
the understanding of the essence and 
universality of languages. 
4 Potential Applications of Semantic 
Computing ? a Case Study on 
Automatic Metaphor Processing in 
Search Engines 
Nowadays, search engines are developing very 
rapidly and some of them have won great 
economic success. In terms of semantic 
computing, Baidu.com takes the lead and has 
unveiled the search concept ?Box computing? 
which introduces semantic analysis. The 
precision and recall of a search engine are 
always the essential issue that a user is 
concerned. Therefore we will find the value of 
semantic computing first in a search engine.  
Certainly, if metaphor can be understood 
properly by a computer, the precision of search 
engines will be improved. Let?s take the phrase 
?? q? f?i(take off) as an example. Literally ?
? means an aircraft takes off such as in ??
???? h?ng b?n q? f?i sh? ji?n (the time for 
the airplane to take off). Sometimes we also use 
it in phrases like ???? j?ng j? q? f?i 
(economic take-off) or ???????? 
d?ng f?ng m?i n? g? t?n q? f?i (Oriental 
beauties take off in the music arena.) to mean 
metaphorically. If the literal sense and its 
metaphorical sense can be distinguished 
successfully, we will find the exact information 
that we need. Meanwhile, we hope that through 
this the recall of search engine will also be 
improved. For example, in Chinese we often 
use the phrase ????? z? gu? de hu? du? 
(flowers of the country) metaphorically to refer 
to ?? ?r tong (children). So web pages 
describing ????? should also be related 
to the query word ??. 
We also observe that the phrases ???? 
j?n r?ng f?ng b?o (financial storm) and ???
?  j?n r?ng h?i xi?o(financial tsunami) 
metaphorically refer to ???? j?n r?ng w?i 
j? (financial crisis). But when we input the 
query ????  into a search engine, the 
results were only web pages with ???? or 
??//??. But when we use the query???
? or????, there were no web pages with 
the results ????. We know that the phrase 
??? ch?o y?u y? has literal usage (to fry 
squids) and metaphorical usage (to fire sb. from 
his/her job). When we input the phrase into the 
search engine, we find the result with 
metaphorical usage takes up 65% while other 
usage only accounts for 35% (Wang, 2006). 
Therefore we may conclude that whether 
metaphor is understood will seriously affect 
precision and recall.  
Another important application lies in 
machine translation and cross-lingual search. 
Correct metaphor recognition and 
understanding is the precondition of correct 
translation. Machine translation can be a 
framework to evaluate the performance of 
metaphor recognition and understanding, and 
also is a tool to realize cross-lingual search. For 
instance, a well-known Chinese female 
volleyball player got a nickname as ??? ti? 
l?ng tou. Shall we translate it literally as ?iron 
hammer? or more metaphorically as ?iron fist? 
in order to let a user of search engine have a 
better sense of what it actually means? 
Translation is culture-bound. When we see the 
sentence ???????g?i di?n y?ng sh? j? l?i, 
how should we translate the word ?? (a 
chicken?s rib) here? And how shall we 
distinguish its literal meaning with its 
metaphorical meaning (?????????sh? 
zh? w? w?i q? zh? k? x?, tasteless to eat but a 
waste to cast away) in order to understand better 
the sentence ?The movie is a chicken?s rib?? 
Therefore when we investigate the 
feasibility analysis of applications of automatic 
metaphor recognition, we propose there are still 
three solutions to the above-mentioned 
problems: 
? To overcome the limitedness of source 
domain words 
? To recognize metaphors in web pages 
and build metaphor indexes. Offline 
processing often makes good use of the 
advantages of a search engine. 
? Before realizing query understanding, 
let users choose metaphorical or literal 
meaning of the query through 
human-computer interaction. 
5 Language Knowledge Bases as the 
Foundation of Semantic Computing 
As the foundation of semantic computing, 
language knowledge bases are in great demand. 
The achievements on language knowledge 
bases for Chinese-centered multilingual 
information processing include: Chinese LDC, 
Comprehensive Language Knowledge Base 
(CLKB) by ICL at Peking University, HowNet 
by Zhendong Dong, Chinese Dependency Tree 
Bank by Harbin Institute of Technology, etc. 
Language knowledge base is an 
indispensable component for NLP system, and 
its quality and scale determines the failure or 
success of the system to a great extent. For the 
past two decades, a number of important 
language knowledge bases have been built 
through the effort of people in Institute of 
Computational Linguistics (ICL) at Peking 
University. Among them, the Grammatical 
Knowledge Base of Contemporary Chinese 
(GKB) (Yu et al, 2000) is the most influential.   
Based on GKB, various research projects 
have been initiated. For instance, a project on 
the quantitative analysis of ?numeral-noun? 
construction of Chinese was conducted by 
Wang (2009) to further analyze the attributes of 
Chinese words. A project aiming at the emotion 
prediction of entries in CIKB was completed by 
Wang (2010) to further understand how the 
compositional elements of a fossilized construct 
like an idiom function from the token level.  
Offset Synset Csyncet Hypernym Hyponym Definition Cdefinition 
07632177 teacher  
instructor  
 
??  
??  
??  
?? 
?? 
??  
???  
??? 
? 
07235322  
 
07086332 
07162304 
07209465 
07243767 
07279659 
07297622 
07341176 
07401098 
? 
a person 
whose 
occupation 
is teaching  
 
?????
???  
 
 
Offset Synset Csyncet Hypernym Hyponym Definition Cdefinition 
07331418  husband 
hubby 
married_
man  
  
 
?? 
??  
??  
??  
??  
??  
??  
??  
???  
? 
07391044  
 
071094820
719596807
255726073
28008  
 
a married 
man;  
a woman's 
partner in 
marriage  
 
?????  
?????
?????  
 
Offset Synset Csyncet Hypernym Hyponym Definition Cdefinition 
07414666  
 
Mister  
Mr.  
 
?? 
??  
??  
??  
??  
??  
07391044  
 
 
 a form of 
address for 
a man 
 
?????
???  
  
 
 
Table 2. The Synset of the word ?? ji?o sh? and its related Synsets. 
 
Following GKB, language knowledge bases 
of large scale, high quality and various type 
(words and texts, syntactic and semantics, 
multi-lingual) have been built, such as the 
Chinese Semantic Dictionary (CSD) for 
Chinese-English machine translation, the 
Chinese Concept Dictionary (CCD) for 
cross-language text processing, the multi-level 
Annotated Corpus of Contemporary Chinese, 
etc. The projects as a whole won the Science 
and Technology Progress Award issued by 
Ministry of Education of China in 2007.  
As mentioned in Section 3, the word ?? 
(virus) has two senses in both English and 
Chinese: one is in biology and the other is in 
computer science. When we want to do 
cross-lingual information retrieval, the two 
senses need to be distinguished. Hence, CCD 
can serve as a useful tool to complete the task 
for it organizes semantic knowledge from a 
different angle. Concepts in CCD are 
represented by Synsets, i.e. sets of synonyms as 
in Table 2. For instance, the concept ?? is in 
a Synset {?? ?? ?? ?? ?? ?? 
??? ??? ?} and all the concepts form 
a network to associate the various semantic 
relations between or among the concepts: 
hypernym-hyponym, part-whole, antonym, 
cause and entailment, by which we can retrieve 
information in either an extensive or a 
contractive way so as to improve the precision 
or recall of a search engine. It can also provide 
support for WSD tasks. 
In 2009, the various knowledge bases built 
by ICL were integrated into the CLKB. The 
integration of heterogeneous knowledge bases 
is realized by a resolution of ?a pivot of word 
sense?. Three basic and important knowledge 
bases, GKB, CSD and CCD have been 
integrated into a unified system which includes 
language processing module, knowledge 
retrieval module and knowledge exploration 
module.  
Although there are some fundamental 
resources on semantic computing, it needs 
further improvement, updating, integration and 
specification to form a collective platform to 
perform more complicated NLP tasks. To 
further improve the result of semantic 
computing, innovative projects for new tasks 
should also be launched, for instance:  
? metaphor knowledge base 
? ultra-ontology dynamic knowledge 
base (generalized valence mode) 
? the integration of information based 
on multi-lingual translation  
6 Concluding Remarks 
Why semantics is so useful in the first place? 
Linguists and psychologists are interested in the 
study of word senses to shed light on important 
aspects of human communication, such as 
concept formation and language use. 
Lexicographers need computational aids to 
analyze in a more compact and extensive way 
word definitions in dictionaries. Computer 
scientists need semantics for the purpose of 
natural language processing and understanding. 
Therefore, the significance of semantic 
computing in NLP is obvious and more research 
needs to be done with this respect. 
All in all, we may conclude that the 
methods of semantic computing can be 
summarized as the following:  
? The research of applicable language 
model    
? The research of effective algorithms   
? To build language knowledge bases as 
its foundation   
Semantic computing is a long-term 
research subject. We hope more progress can be 
made if a clearer view can be provided for the 
direction of its development and the pavement 
for future research can be constructed more 
solidly with more work done.  
Acknowledgements 
Our work is based on the long-term 
accumulation of the language resources that 
have been built by the colleagues of ICL and it 
is their contributions that make our achievement 
possible today. Parts of the content in this paper 
were presented by Shiwen Yu on the 
conferences in Hangzhou (International 
Workshop on Connected Multimedia 2009) and 
Suzhou (the 11th Chinese Lexical Semantics 
Workshop 2010), and many thanks should be 
given to those who offered valuable thoughts 
and advice. The authors also want to extend 
their gratitude toward CIPS-Sighan for this 
valuable opportunity to demonstrate our 
viewpoints and work. 
References 
Anderson, J. R. 1989.  A Theory of the Origins 
of Human Knowledge. Artificial 
Intelligence. 40(1-3): 313-351. 
Carreras, X. and Marques L. 2004. Introduction 
to the CoNLL-2004 Shared Task: Semantic 
Role Labeling. Proceedings of the CoNLL 
2004: 89-97. 
Dagan, I. et al 1993. Contextual Word 
Similarity and Estimation from Sparse 
Data. In Proceedings of the 31st Annual 
Meeting on the Association for 
Computational Linguistics (ACL):164-171 
Fillmore, C. J.. 1976. Frame Semantics and the 
Nature of Language. In Annals of the New 
York Academy of Sciences: Conference on 
the Origin and Development of Language 
and Speech:20-32 
Gale, William A., Kenneth W. Church, and 
David Yarowsky. 1993. A Method for 
Disambiguation Word Senses in a Large 
Corpus. Computers and the Humanities. 
26(5-6): 415-439  
Gildea, Denial and Denial Jurafsky. 2002. 
Automatic Labeling of Semantic Roles. 
Computational Linguistics, 28(3): 
245-288. 
Hasida, K. 2007. Semantic Authoring and 
Semantic Computing. Sakurai, A. et al 
(Eds.): JSAI 2003/2004, LNAI 3609, 
137?149. 
Ide, Nancy and Jean V?ronis. 1998. 
Introduction to the Special Issue on Word 
Sense Disambiguation: The State of the Art, 
Computational Linguistics, 24(1) : 2-40. 
Jin, Peng, Wu Yunfang, Yu Shiwen. 
SemEval-2007 Task 05: Multilingual 
Chinese-English Lexical Sample. In 
Proceedings of SemEval-2007: 19-23. 
Johansson, Richard and Pierre Nugues. 2008. 
Dependency-based Syntactic-semantic 
Analysis with PropBank and NomBank. In 
Proceedings of the Twelfth Conference on 
Computational Natural Language 
Learning: 183-187. 
Lee, Lillian. Similarity-Based Approaches to 
Natural Language Processing. Ph.D. thesis. 
Harvard University. 
Lesk, Michal. 1986. Automatic Sense 
Disambiguation: How to Tell a Pine from 
an Ice Cream Cone. In Proceedings of the 
5th Annual International Conference on 
Systems Documentation: 24-26. 
Li, Sujian, Zhang Jian, Huang Xiong and Bai 
Shuo. 2002. Semantic Computation in 
Chinese Question-Answering System, 
Journal of Computer Science and 
Technology, 17(6) : 993-999. 
Lu, Jianming. 2010. Foundations of Rhetoric -- 
The Law of Semantic Harmony. Rhetoric 
Learning, 2010(1): 13-20. 
Qu, Weiguang, Sui Zhifang, et al 2007. A 
Collocation-based WSD Model: 
RFR-SUM. In Proceedings of the 20 th 
International Conference on Industrial, 
Engineering, and Other Applications of 
Applied Intelligent Systems:23-32. 
Schutze, Hinrich. 1998. Automatic Word Sense 
Discrimination. Computational Linguistics, 
24(1):97-124. 
Resnik, Philip. 1999. Semantic Similarity in a 
Taxonomy: An Information-Based 
Measure and its Application to Problems of 
Ambiguity in Natural Language, Journal 
of Artificial Intelligence Research 11: 
95-130. 
Wang, Lei and Yu Shiwen. Forthcoming 2010. 
Construction of Chinese Idiom Knowledge 
Base and Its Applications. In Proceedings 
of Coling 2010 Multi-word Expressions 
Workshop. 
Wang, Meng et al 2009. Quantitative Research 
on Grammatical Characteristics of Noun in 
Contemporary Chinese. Journal of Chinese 
Information Processing, 22(5): 22-29. 
Wang, Zhiming. 2006. Recent Developments in 
Computational Approach to Metaphor 
Research. Journal of Chinese Information 
Processing, 20(4): 16-24. 
Xue, Nianwen and Martha Palmer. 2005. 
Automatic Semantic Role Labeling for 
Chinese Verbs. In Proceedings of the 19th 
International Joint Conference on 
Artificial Intelligence:1160-1165 
Yu, Shiwen et al. 2003. Introduction to 
Grammatical Knowledge Base of 
Contemporary Chinese (Second Edition) 
(in Chinese), Tsinghua University Press, 
Beijing, China.  
Studies on Automatic Recognition of Common Chinese Adverb?s 
Usages Based on Statistical Methods 
Hongying Zan 
College of Informa-
tion Engineering, 
Zhengzhou Univer-
sity 
iehyzan@zzu.edu.cn 
Junhui Zhang 
College of Infor-
mation Engineer-
ing, Zhengzhou 
University 
zhangj.zzu@gmail
.com 
Xuefeng Zhu 
Key Laboratory of 
Computational Lin-
guistics(Peking 
University) of 
China Ministry 
Education 
yusw@pku.edu.cn 
Shiwen Yu 
Key Laboratory of 
Computational Lin-
guistics(Peking 
University) of 
China Ministry 
Education 
yusw@pku.edu.cn 
 
Abstract 
The study on Automatic Recognizing 
usages of Modern Chinese Adverbs 
is one of the important parts of the 
NLP-oriented research of Chinese 
Functional words Knowledge Base. 
To solve the problems of the existing 
rule-based method of adverbs? usages 
recognition based on the previous 
work, this paper has studied auto-
matically recognizing common Chi-
nese adverbs? usages using statistical 
methods. Three statistical models, viz. 
CRF, ME, and SVM, are used to la-
bel several common Chinese ad-
verbs? usages on the segmentation 
and part-of-speech tagged corpus of 
People?s Daily(Jan 1998). The ex-
periment results show that statistical-
based method is effective in auto-
matically recognizing of several 
common adverbs? usages and has 
good application prospects. 
1 Introduction 
Chinese vocabulary can be divided into func-
tional words and notional words. In  the field 
of Natural Language Processing(NLP), many 
studies on text computing or word meaning 
understanding are focused on the notional 
words, rarely involving functional words. 
Especially in some common NLP application 
fields, such as text summarization, text clas-
sification, information retrieval, and so on, 
the researchers mainly take notional words as 
features, and list some functional word as 
stop words without considering their influ-
ence on text meaning. This will impact the 
deep analysis of text semantic, especailly for 
chinese, and become the bottleneck of ma-
chine understanding on text content, and im-
pede further improving the performance of 
application systems. Due to Chinese lacking 
morphological changes(Li X., 2005), Chi-
nese functional words undertake the gram-
matical functions and grammatical meanings, 
and in other language these functions are 
mainly undertaken by morphological 
changes. So, functional words play an more 
important role in Chinese semantic under-
standing and grammatical analysis. The 
study on functional words of modern Chi-
nese semantic in Chinese text processing and 
understanding has great significance. 
Yu(Yu S., 2004), Liu(Liu, Y., 2004), et al 
have defined the generalized functional 
words as adverbs, conjunctions, prepositions, 
modal particles, auxiliary, and localizer 
words. From the statistic, the number of 
modern Chinese adverbs is about 1000 with 
the broad definition standard. Compared with 
other fuctional words, the adverbs number is 
much larger. The function and usages of 
modern Chinese adverbs vary widely from 
each other, especially some common adverbs. 
Therefore for modern Chinese text under-
standing, adverbs are the important text fea-
tures which can not be neglected. For the 
modern Chinese adverbs, only using the 
segmentation and part-of-speech tagging in-
formation for Chinese text automatic proc-
essing and understanding is not enough. So, 
particular study on the usage of adverbs in 
texts comprehensive is indispensable, and the 
automatic identification of adverbs? usage in 
some extend is of great significance. 
2 Related Researches 
The work of automatically recognizing us-
ages of adverbs of modern Chinese is part of 
the NLP-oriented research of Modern Chi-
nese Functional Words Knowledge Base. Yu 
et al proposed the idea of building the ?Trin-
ity? knowledge-base of generalized func-
tional words(Yu, S., 2004), and defined the 
generalized functional words as adverbs, 
conjunctions, prepositions, modal particles, 
auxiliary, and localizer words(Yu, S., 
2004)(Liu, Y., 2004). Zan et al described 
adverb?s usages using formal rules(Zan, H., 
2007a), and initially built the machine-
oriented modern Chinese adverb dictionary 
and the usage rule base(Zan, H., 2007b),. 
Hao et al imported the dictionary and rule 
base(Hao, L., 2007). Based on the previous 
work, Liu et al realized an automatically 
rule-based recognizing system and got preci-
sion at 74.89%(Liu, R., 2008). 
The rule-based method has the advantage 
of simple, intuitive, strong pertinence, etc, 
but it also has the shortcomings of lower 
coverage, and it is difficult to be further op-
timized or generalized. For example, there 
are some adverbs which different usages are 
difficult to describe using formal rules, such 
as: 
?1??????????????? 
[(1)It is Sunday, you can sleep in at 
will.] 
?2??????????????????
?????? 
[(2)They were always talking while lis-
tensing report, so they catched nothing 
of the report content.] 
 
In the adverb usage dictionary, the adverb 
?jinguan??/ ? has two meanings: 
<d_jin3guan3_1> and <d_jin3guan3_2>. 
The meaning of ?jinguan??/ ? in sentence 
(1) is belong to <d_jin3guan3_1>, it means 
the action or behavior can be without any 
limitations; the meaning of ?jinguan??/ ? 
in sentence (2) is belong to <d_jin3guan3_2>, 
it means the action or behavior is continu-
ously. This two meanings are very easy to 
distinguish manually, but they are hard to 
identify automatically. The two meanings? 
discrimination cannot accurately describe 
using formal rules. 
Moreover, the rule-based method also ex-
ists some other problem, for example, some 
adverbs? usages require modifying verb 
phrase, or clauses, or used in imperative, and 
so on. These problems need deep syntactic 
even semantic knowledge to solve. But this 
is lack in the segmentation and part-of-
speech tagging corpus. So, the rule-based 
method will be unable to identify the ad-
verbs? usages in such situations. 
To solve the problems of the existing rule-
based method of adverbs? usages recognition, 
based on the foundation of the previous work, 
this article considers using statistical method 
to recognize adverbs? usages automatically. 
This method can be continuously optimized 
according to actual training data and lan-
guage model, it will avoid the limitations of 
rule-based method. 
3 Studies on Automatic Recognition 
of Adverbs? Usages Based on Sta-
tistical methods 
In NLP, the research can be divided into 
three questions: point, sequence, and struc-
ture(Vapnik V., 1998). For the Chinese ad-
verbs? usages recognition task, it can be 
taken as a point question which classify the 
context of adverbs, and also can be taken as a 
sequence question which recognize the ad-
verb sequence in the sentence. So, we choose 
three statistical models: Conditional Random 
Fields(CRF), Maximum Entropy(ME), and 
Support Vector Machine(SVM), which have 
good performance and used widely in the 
field of machine learning. CRF and ME 
model can be used in sequence tagging, and 
SVM is a better statistical models in catego-
ries.  
3.1 Statistical models 
CRF is advanced by J. Lafferty(Lafferty J., 
2001). It is one of the undirected graph mod-
els. Given input sequence corresponding 
conditional probability of label sequence, 
this model?s training target is to find the 
maximum of conditional probability. It has 
been widely used in the field of NLP, such as 
Chinese Word Segmentation(Miao X., 2007), 
Named Entity Recognition(Chen W., 
2006)(Shi S., 2006)(Guo J., 2007)(Zhang J., 
2006), Syntactic Analysis(Fei Sha, 2003), 
and so on. 
ME has been widely used for classifica-
tion problem. The basic idea of ME is to dig 
the potential constraint conditions in the 
known event sets, and then choose a model 
which must satisfy the known constraint 
conditions, while possibly let the unknown 
event uniform distribution. In the NLP appli-
cations, the language model based ME does 
not dependent on domain knowledge, and is 
independent of the specific task. It has been 
use in many key fields of NLP, and has 
achieved good results in Named Entity Rec-
ognition(Wang J., 2005), POS tag-
ging(Zhang L., 2008), Chunking Analy-
sis?Li S., 2003?, Text Emotional Tenden-
cies Classification(Liu, K. 2008). 
SVM is a statiscal machine learning 
method and has good performance in classi-
fication(Vapnik V., 1998). In NLP, SVM is 
widely used in Phrases recognition(Li, G., 
2005), Word Sense Disambiguation(Yu, K., 
2005)(Lu, Z., 2006), Text classification, and 
so on. SVM has good generalization ability, 
and can well classify the data in the training 
sample limited circumstances. To the usage 
recognition of adverbs, the available data is 
limited, so using SVM may be good. 
CRF, ME and SVM are the outstanding 
statistical models in machine learning. CRF 
can well consider the mutual influence be-
tween usage marks, and overcomes the prob-
lem of marker offset. This is good for some 
rare usage recognition of adverb. The lan-
guage model built by ME method is inde-
pendent to specific tasks, and domain knowl-
edge. ME can effectively use context infor-
mation, and comprehensively evaluate the 
various characteristics. SVM has good gen-
eralization ability, and can well classify the 
data in the training sample limited circum-
stances. The advantages of these models are 
beneficial to recognize adverbs? usages cor-
rectly. 
In this paper, we use CRF++
1
, the ME 
toolkit maxent
2
 of Zhang Le, and LibSVM
3
 
toolkit as the automatic tagging tool in our 
experiments. 
3.2 Feature Selection of Models 
Linguists Firth once said ?You shall know a 
word by the company it keeps?(Firth, 1957). 
This refers to the mean of a word can only be 
                                                 
1
 CRF++: Yet Another Toolkit[CP/OL]. 
http://www.chasen.org/~taku/software/CRF++ 
2
 
http://homepages.inf.ed.ac.uk/s0450736/maxent_toolkit.html 
3
 http://www.csie.ntu.edu.tw/~cjlin/libsvm 
judged and identified from the words associ-
ated with it. To the adverbs? usage recogni-
tion, it also needs to get the word?s usage 
knowledge from the contexts. Through ana-
lyzing some examples, we found that words 
and part of speech in the contexts are useful 
to identify adverbs? usages. Therefore, in our 
experiment, to CRF and ME model, we se-
lect 3 template features as table 1. The value 
of n can take 2, 3, 4, 5, 6, and 7. 
 
Table 1 Feature Template 
ID Meanings 
T1 words, within the destined context window 
n 
T2 the part of speech, within the destined con-
text window n 
T3 the words + part of speech + the combina-
tion of both, within the destined context 
window n 
 
In the SVM experiment, the feature is nu-
meric characteristics. To the adverb in the 
sentence, through selecting the window size 
of the context, and then calculating the mu-
tual information(MI) of the features in the 
window and the adverb, the result of MI as 
feature vector. The MI between word w and 
word u can be calculated as follows, 
p
pp
I
21
*
log=
     (1) 
Where: 
p1: the frequency of u in the corpus 
p2: the frequency of t in the corpus 
p: the co-occurrence frequency of w and u 
4 Experiments and Results Analysis 
4.1 Experimental Corpus 
The experimental data is the segmentation 
and part-of-speech tagged corpus of People's 
Daily(Jan 1998). First, we use the rule-based 
method(Liu, R., 2008) to tag the adverbs? 
usages in the experimental data. Then, we 
manually check the tagging results and get 
he standard corpus for experiment data. Ob-
serving the experiment data, the usage distri-
bution of many adverbs? is very imbalance. 
Some adverbs have hardly appeared, and 
some usages of some adverbs have hardly 
appeared. If we choose this kind of adverbs 
for statistical experiment, it will bring great 
effect to the experiment results. Therefore, 
after analyzing the corpus, we consider to 
choose seven common Chinese adverbs 
which usage distribution is somewhat bal-
anced in the corpus as the object of statistical 
learning. 
4.2 Performance Evaluation 
In the experiment, we use the precision(P) as 
the evaluation measure of the experimental 
results. To the word W and its usage i, we 
define P as followed: 
iusageofnumbertagthe
iusageofnumbertagcorrectthe
P =
   (2) 
4.3 Analysis of Experimental Results 
In order to verify the performance of models, 
to every adverb, we use 4 fold cross-
validation experiments. The results are the 
average results of cross-validation. 
 
Experiment 1: Performance comparison ex-
periment of Statistical methods and rule 
method 
Aiming at the different statistical models, 
by selecting different feature, we did 3 
groups experimental separately. For CRF and 
ME, we select T1 while n=2. To SVM we 
take MI as feature while the window size is 2. 
Results are shown in Table 2. 
 
Table 2 The experiment result of rule-based 
method and the statistic-based method 
Method 
 
Adverb 
Rule- 
based 
CRF ME SVM 
bian/? 0.409 0.459 0.453 0.876 
fenbie/?? 0.506 0.673 0.679 0.905 
Jiu/? 0.339 0.776 0.608 0.59 
tebie/?? 0.697 0.783 0.652 0.932 
yi/? 0.511 0.91 0.71 0.974 
shifen/?? 0.712 0.95 0.865 0.993 
xianhou/?? 0.963 0.575 0.59 0.846 
average 
precision  
0.55 0.729 0.66 0.885 
 
From Table 2 we can see that the statistic-
based results are better than the rule-based 
results on the whole. The average precision 
has been raised from 55% to 88.5%. It can 
clearly be seen that the statistical method has 
better adaptability and good application 
prospect in automatic identification of mod-
ern Chinese adverbs? usages. 
At the same time, we can see that the sta-
tistical result of adverb ?xian ??hou/ ? is 
obviously lower than the rule-based method. 
This is because the different usage of it can 
be easily distinguished from its rule, so the 
precision of rule-based method is higher than 
statistic-based method. To these words, we 
consider to use the method that combines the 
statistics-based and rules-based method. 
 
Experiment 2: Statistical experiment under 
different feature template 
By choosing different feature templates, 
this experiment to analyze the influence of 
different feature to the statistical method. 
Figure 1 is the average results of 6 ad-
verbs(removing adverb ? ??xian hou/ ?) 
using three models. The abscissa 1-6 is the 
feature in the template T1 while n take 2, 3, 4, 
5, 6, 7 separately. Figure 2 is the average 
results of these adverbs using CRF and ME 
with template T1, T2, and T3(see Table 1). 
The abscissa 1-3, 4-6, 7-9 ,10-12, 13-15, 16-
18, is T1, T2, T3 while n take 2, 3 ,4 ,5, 6, 7. 
From Figure 1 and Figure 2, we can see 
that the precision of statistical results have 
not great changes by choosing different con-
text window. In general it can be achieved 
the best result within the window size (-4, +4) 
of the context. So, in the current scale of 
corpus, big window size may be not better 
when recognizing usages of adverbs, and it 
may bring more noise for recognizing with 
the increase of window size. But observing 
experimental results of specific words, we 
found that it?s not all of the words exist this 
phenomenon. Figure 3 and Figure 4 is the 
result of adverb ? ?jiu/ ? and ? ?bian/ ? using 
three models with T1(n=2,?,7). 
From Figure 3 and Figure 4, we can see 
that to different adverbs, the results of three 
models are not same, and even have big dif-
ference. To adverb ??jiu/ ?, CRF is the best, 
SVM is the worst. To adverb ?bian/??, 
SVM is the best, and the difference between 
CRF and ME is not very large. (Ma Z., 2004) 
also pointed out that every adverb needs to 
be synthetically analyzed and researched. 
00.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
1 2 3 4 5 6
????
?
?
?
CRF
ME
SVM
 
Figure 1 Average result of three models with 
T1(n=2,?,7) 
 
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18
????
?
?
?
CRF
ME
 
  Figure 2 Average result of CRF and ME with T1, T2, 
T3(n=2,..,7)  
 
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
1 2 3 4 5 6
????
?
?
?
CRF
ME
SVM
Figure 3 Adverb Result of adverb ?jiu/?? using three 
models with T1(n=2,?7) 
 
 
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
1 2 3 4 5 6
????
?
?
?
CRF
ME
SVM
Figure 4 Adverb Result of adverb ?bian/?? using 
three models with T1(n=2,?7) 
 
So, to different adverb, we may be select 
different statistical model based on its own 
characteristics. For some common Chinese 
adverb, it?s very important to study and con-
trast case-by-case. 
5 Conclusions 
The article makes a preliminary study on 
automatically recognizing common adverbs? 
usages. From the experimental results wen 
can see, compared with the rule-based 
method, statistic-based method has obvious 
advantages.  
This article is a continuation of the work 
of Functional Word Knowledge Base. Fur-
thermore, we will study the method that 
combines the rule-based method and the 
statistic-based method to automatically rec-
ognizing adverbs? usages, and further en-
hance the recognition precision. We hope 
our study can help the Chinese lexical se-
mantic analysis, and make a good base to 
the Chinese text machine understanding and 
the application of natural language process-
ing. 
Acknowledgement 
The work in this paper was supported by the 
China National Natural Science Foundation 
(No. 60970083), the Open Project Program 
of the Key Laboratory of Computational 
Linguistics(Peking University)(KLCL 1004) 
of China Ministry Education, and the Out-
standing Young Talents Technology Inno-
vation Foundation of Henan Province(No. 
104100510026). 
References 
Chen Wenliang, Zhang Yujie, Hitoshi Isahara. 
Chinese named entity recognition with con-
ditional random fields. In 5
th
 SIGHAN 
Workshop on Chinese Language Processing, 
Australia, 2006. 
Fei Sha , Fernando Pereira. Shallow parsing with 
conditional random fields. In: the proceed-
ings of Human Language Technology/North 
American chapter of the Association for 
Computational Linguistics annual meeting, 
2003: 213-220. 
Firth J R., A Synopsis of L inguistic Theory 1930 
- 1955 In Studies on L inguistic Analysis. L 
ondon: B lackwell 1957?101-126 
Guo Jiaqing, Studies on the Chinese Named En-
tity Recognition based on conditional ran-
dom fields. Doctoral dissertation of  the 
Shenyang Aviation Industry Colledge, China. 
2007. 
Hao, Liping, Zan, Hongying, Zhang, Kunli, Re-
search on Chinese Adverb Usage for Ma-
chine Recognition. In?Proceedings of the 
7
th
 International Conference on Chinese 
Computing (ICCC2007): 122-125 
Lafferty, J., McCallum, A., Pereira F,. Condi-
tional random fields: probabilistic models 
for segmenting and labeling sequence data. 
In the Proceedings of International Confer-
ence on Machine Learning, 2001: 282-289. 
Li, Xiaoqi, et al The teaching materials on the 
modern Chinese funciotnal word. Peking 
University press, Beijing, China, 2005. (in 
Chinese)  
Li, Guozheng, Wang, Meng, Introduction on the 
Support Vector Machine. The electronic In-
dustry Press. Beijing, China, 2005. 
LI, Sujian, Liu, Qun, Yang Zhifeng, Chunk 
Parsing with Maximum Entropy Principle, 
Chinese Journal of Computers, 2003(12), 
1722-1727. 
Liu, Kang; Zhao, Jun, Sentence Sentiment 
Analysis Based on Cascaded CRFs Model, 
Journal of Chinese Information Processing, 
2008(1), 123-128. 
Liu, Rui,. et al The Automatic Recognition Re-
search on Contemporary Chinese Language, 
Computer Science, 2008(8A): 172-174. (in 
Chinese) 
Liu, Yun, The construcion of Chinese funtional 
words konwledge base. Peking University. 
Postdoctoral reports of Peking University. 
2004.  
Lu, Zhimao, Liu, ting, Survey of the statitical 
word sense disambiguation study. Jounal of 
Electroniics, 2006.2 
Ma,.Zhen, Study Methodology of the Modern 
Chinese Function Words. Commercial 
Press.2004.(in Chinese) 
Miao Xuelei. A Random Conditional Fields 
Based Method to Chinese Word Sense Dis-
ambiguation Research. Shenyang Institute of 
Aeronautical Engineering. 2007. 
Shi Shumin, Wang Zhiqiang, Zhou Lang, Chi-
nese Named Entity Recognition based on 
conditional random fields. In the Proceed-
ings of the 3
rd
 students computational lin-
guistics conference . 2006.(In Chinese) 
Vapnik V., Statistical Learning Theory. Wiley-
Interscience ublication. John Wiley&Sons, 
Inc,1998 
Wang, Jiangwei, Chinese named entity recogni-
tion Based on Maximum Entropy, Doctoral 
dissertation of Nanjing University of Science 
and Technology, 2005. 
Yu, Kun, Guan, Gang, Zhou, Ming. Resume in-
formation extraction with cascaded hybrid 
model. Proceedings of the 43rd Annual 
Meeting on Association for Computational 
Linguistics. Ann Arbor, Michigan. 2005?
499-506 
Yu, Shiwen, et al Knowledge-base of General-
ized Functional Words of Contemporary 
Chinese[J]. Journal of Chinese Language and 
Computing, 13(1): 89-98. 2004. 
Zan, Hongying, Zhang Kunli, Chai,Yumei Yu, 
Shiwen. The Formal Description of Modern 
Chinese adverbs? usages. In Proceedings of 
the 9
th
 Chinese Lexical Semantics Work-
shop(CLSW-2007), 52-56. 2007. (in Chinese) 
Zan, Hongying, Zhang, Kunli, Chai,Yumei, Yu, 
Shiwen. Studies on the Functional Word 
Knowledge Base of Contemporary Chinese. 
Journal of Chinese Information Process-
ing,2007(5): 107-111. (in Chinese) 
Zhang Jian, Studies on the English Named Entity 
Recognition based on conditional random 
fields. Doctoral dissertation of  the Harbin 
Industry University, China. 2006. 
Zhang, Lei, Study of Chinese POS Tagging 
Based on Maximum Entropy, Doctoral dis-
sertation of Dalian University of Technology, 
2008. 
Chinese Word Sense Induction with Basic Clustering Algorithms 
Yuxiang Jia1,2, Shiwen Yu1, Zhengyan Chen3 
1Key Laboratory of Computational Linguistics, Ministry of Education, China 
2College of Information and Engineering, Zhengzhou University, Zhengzhou, China 
3Department of Information Technology, Henan Institute of Education, Zhengzhou, China
{yxjia,yusw}@pku.edu.cn  chenzhengyan1981@163.com 
 
 
Abstract 
Word Sense Induction (WSI) is an 
important topic in natural langage 
processing area. For the bakeoff task 
Chinese Word Sense Induction (CWSI), 
this paper proposes two systems using 
basic clustering algorithms, k-means and 
agglomerative clustering. Experimental 
results show that k-means achieves a 
better performance. Based only on the 
data provided by the task organizers, the 
two systems get FScores of 0.7812 and 
0.7651 respectively. 
1 Introduction 
Word Sense Induction (WSI) or Word Sense 
Discrimination is a task of automatically discov-
ering word senses from un-annotated text. It is 
distinct from Word Sense Disambiguation 
(WSD) where the senses are assumed to be 
known and the aim is to decide the right mean-
ing of the target word in context. WSD generally 
requires the use of large-scale manually anno-
tated lexical resources, while WSI can overcome 
this limitation. Furthermore, automatically in-
duced word senses can improve performance on 
many natural language processing tasks such as 
information retrieval (Uzuner et al, 1999), in-
formation extraction (Chai and Biermann, 1999) 
and machine translation (Vickrey et al, 2005). 
WSI is typically treated as a clustering prob-
lem. The input is instances of the ambiguous 
word with their accompanying contexts and the 
output is a grouping of these instances into 
classes corresponding to the induced senses. In 
other words, contexts that are grouped together 
in the same class represent a specific word sense. 
The task can be formally defined as a two 
stage process, feature selection and word cluster-
ing. The first stage determines which context 
features to consider when comparing similarity 
between words, while the second stage apply 
some process that clusters similar words using 
the selected features. So the simplest approaches 
to WSI involve the use of basic word co-
occurrence features and application of classical 
clustering algorithms, more sophisticated tech-
niques improve performance by introducing new 
context features, novel clustering algorithms, or 
both. (Denkowski, 2009) makes a comprehen-
sive survey of techniques for unsupervised word 
sense induction. 
Two tasks on English Word Sense Induction 
were held on SemEval2007 (Agirre and Soroa, 
2007) and SemEval2010 (Manandhar and Kla-
paftis, 2010) respectively, which greatly pro-
mote the research of English WSI. 
However, the study on Chinese Word Sense 
Induction (CWSI) is inadequate (Zhu, 2009), 
and Chinese word senses have their own charac-
teristics. The methods that work well in English 
may not work well in Chinese. So, as an explo-
ration, this paper proposes simple approaches 
utilizing basic features and basic clustering algo-
rithms, such as partitional method k-means and 
hierarchical agglomerative method. 
The rest of this paper is organized as follows. 
Section 2 briefly introduces the basic clustering 
algorithms. Section 3 describes the feature set. 
Section 4 gives experimental details and analysis. 
Conclusions and future work are given in Sec-
tion 5. 
2 Clustering Algorithms 
Partitional clustering and hierarchical clustering 
are the two basic types of clustering algorithms. 
Partitional clustering partitions a given dataset 
into a set of clusters without any explicit 
structure, while hierarchical clustering creates a 
hierarchy of clusters. 
The k-means algorithm is the most notable 
partitional clustering method. It takes a simple 
two step iterative process, data assignment and 
relocation of means, to divide the dataset into a 
specified number of clusters, k. 
Hierarchical clustering algorithms are either 
top-down or bottom-up. Bottom-up algorithms 
treat each instance as a singleton cluster at the 
beginning and then successively merge pairs of 
clusters until all clusters have been merged into 
a single cluster. Bottom-up clustering is also 
called hierarchical agglomerative clustering, 
which is more popular than top-down clustering. 
We use k-means and agglomerative algo-
rithms for the CWSI task, and compare the per-
formances of the two algorithms. 
Estimating the number of the induced clusters, 
k, is difficult for general clustering problems. 
But in CWSI, it is simplified because the sense 
number of the target word is given beforehand. 
CLUTO (Karypis, 2003), a clustering toolkit, 
is used for implementation. The similarity be-
tween objects is computed using cosine function. 
The criterion functions for k-means and agglom-
erative algorithms are I2 and UPGMA respec-
tively. Biased agglomerative approach is chosen 
in stead of the traditional agglomerative ap-
proach. 
3 Feature Set 
For each target word, instances are extracted 
from the XML data file. Then the encoding of 
the instance file is transformed from UTF-8 to 
GB2312. Word segmentation and part-of-speech 
tagging is finished with the tool ICTCLAS 1 . 
Then the following three types of features are 
extracted: 
1. The part-of-speech of the target word 
2. Words before and after the target word 
within window of size 3 with position informa-
tion 
3. Unordered single words in all the contex-
tual sentences without the target word, punctua-
tions and symbols of the part-of-speech ?nx? 
(Each word is only counted once, which is dif-
                                                 
1http://ictclas.org/ 
ferent from the word frequency in the bag-of-
words model) 
The target word is not necessarily a seg-
mented word. Their relations are as follows: 
1. The target word is a segmented word.  
E.g. ?/d  ?/v  ?/r  ??/n 
Don?t dial my phone. 
The target word is ??? (dial) and the seg-
mented word is also ??? (dial). So they match. 
2. The target word is inside of a segmented 
word. 
E.g.?/p  ??/n  ???/v 
       deal with media 
The target word is ??? (deal), but the seg-
mented word is ????? (deal with). Then we 
split the segmented word and specify the part-of-
speech of the target word as ?1?. 
3. The target word is the combination of two 
segmented words. 
E.g. ?/v  ?/v  ?/w  ?????/nz  ?/w 
       launching the ?Culture Revolution? 
The target word is ???? (launching), but it 
is split into two segmented words ??? (start) 
and ??? (move). Then we combine the two 
segmented words and specify the part-of-speech 
of the target word as ?2?. 
4. The target word is split into two segmented 
words. 
E.g. ?/v  ?/v  ?/u  ?/j  ??/n 
       blow up northeast wind 
The target word is ????, but it is segmented 
into two words ??? (east) and ???? (north 
wind). In this case, we specify the postion of 
first segmented word as the position of the target 
word and the part-of-speech of the target word 
as ?3?.  
If the target word occurs more than once in an 
instance, we consider the first occurrence. 
4 Experiments 
4.1 Data Sets 
Two data sets are provided. The trial set contains 
50 target words and 50 examples for each target 
word. The test set consists of 100 new target 
word and 50 examples for each target word. 
Both data sets are collected from the internet. 
Table 1 shows the distribution of sense num-
bers of the target words in the two data sets. We 
can see that two sense words dominate and three 
sense words are the second majority. The word 
??? (beat) in the trial set has 21 senses. 
 
Table 1. Distribution of sense numbers 
sense number 2 3 4 6 7 8 21
trial set 39 9 1 0 0 0 1 
test set 77 10 7 4 1 1 0 
 
Table 2. Distribution of relations between target 
words and segmented words 
relation type 1 2 3 4 Total
trial set 2314 105 68 12 2499
test set 4031 710 212 47 5000
 
As is shown in table 2, the total instance 
number in the trial set is 2499 because there is a 
target word has only 49 instances. About 7.4% 
of the instances in the trial set and 19.38% of the 
instances in the test set have mismatched target 
words and segmented words (with relation types 
2, 3 and 4). 
4.2 Evaluation Metrics 
The official performance metric for the CWSI 
task is FScore (Zhao and Karypis, 2005). Given 
a particular class Ci of size ni and a cluster Sr of 
size nr, suppose irn  examples in the class Ci be-
long to Sr. The F value of this class and cluster is 
defined to be: 
),(),(
),(*),(*2
),(
riri
riri
ri SCRSCP
SCRSCPSCF
+
= , 
where
r
i
r
ri n
nSCP =),( is the precision value 
and 
i
i
r
ri n
nSCR =),( is the recall value defined 
for class Ci and cluster Sr. The FScore of class Ci 
is the maximum F value attained at any cluster, 
that is 
),(max)( riSi
SCFCFScore
r
=  
and the FScore of the entire clustering solution 
is 
?
=
=
c
i
i
i CFScore
n
nFScore
1
)(  
where c is the number of classes and n is the size 
of the clustering solution. 
Another two metrics, Entropy and Purity 
(Zhao and Karypis, 2001), are also employed in 
this paper to measure our system performance. 
Entropy measures how the various classes of 
word senses are distributed within each cluster, 
while Purity measures the extent to which each 
cluster contained word senses from primarily 
one class. The entropy of cluster Sr is defined as 
r
i
r
c
i r
i
r
r n
n
n
n
c
SE ?
=
?=
1
log
log
1
)(  
The entropy of the entire clustering solution is 
then defined to be the sum of the individual clus-
ter entropies weighted according to the cluster 
size. That is 
?
=
=
k
r
r
r SE
n
nEntropy
1
)(  
The purity of a cluster is defined to be 
)(max
1
)( iri
r
r nn
SP = , 
which is the fraction of the overall cluster size 
that the largest class of examples assigned to that 
cluster represents. The overall purity of the clus-
tering solution is obtained as a weighted sum of 
the individual cluster purities and is given by 
?
=
=
k
r
r
r SP
n
nPurity
1
)(  
In general, the larger the values of FScore and 
Purity, the better the clustering solution is. The 
smaller the Entropy values, the better the cluster-
ing solution is. 
The above three metrics are defined to evalu-
ate the result of a single target word. Macro av-
erage metrics are used to evaluate the overall 
performance of all the target words. 
4.3 Results 
The overall performance on the trial data is 
shown in table 3. From the Macro Average En-
tropy and Macro Average Purity, we can see that 
k-means works better than agglomerative 
method. The detailed results of the k-means sys-
tem are shown in table 4. 
 
Table 3. Result comparison on the trial data 
 Entropy Purity 
k-means 0.4858 0.8288 
agglomerative 0.5328 0.8020 
 
Table 4. Detailed results of k-means system 
TargetWord SenseNum Entropy Purity
?? 2 0.855 0.72 
?? 2 0.692 0.78 
?? 2 0.377 0.92 
?? 3 0.207 0.94 
?? 2 0.833 0.7 
?? 2 0 1 
?? 2 0.592 0.82 
?? 2 0.245 0.959
?? 2 0.116 0.98 
?? 3 0.396 0.82 
?? 2 0.201 0.96 
?? 2 0.201 0.96 
?? 3 0.181 0.9 
?? 2 0.122 0.98 
?? 2 0.327 0.92 
?? 2 0.653 0.82 
?? 2 0 1 
?? 2 0.855 0.72 
?? 2 0.5 0.8 
?? 2 0.312 0.92 
?? 2 0.519 0.86 
?? 3 0.534 0.72 
?? 2 0.846 0.7 
? 21 0.264 0.48 
?? 2 0.521 0.88 
?? 3 0 1 
?? 2 0.76 0.78 
?? 3 0.205 0.92 
?? 2 0.854 0.72 
?? 2 0.449 0.9 
?? 2 0.467 0.9 
?? 2 0.881 0.7 
?? 2 0.402 0.92 
?? 2 0.39 0.92 
?? 2 0.793 0.76 
?? 2 0.904 0.68 
?? 2 0.943 0.64 
?? 3 0.548 0.74 
?? 2 0.583 0.86 
?? 2 0.999 0.52 
?? 2 0.242 0.96 
?? 2 0.75 0.74 
?? 3 0.464 0.84 
?? 2 0.181 0.96 
?? 2 0.672 0.78 
?? 2 0.471 0.82 
?? 3 0.543 0.7 
?? 2 0.347 0.9 
?? 4 0.508 0.66 
?? 2 0.583 0.86 
 
The official results on the test set are shown in 
table 5. Our k-means system and agglomerative 
system rank 5 and 8 respectively among all the 
18 systems. 
 
Table 5. System ranking 
Rank FScore Rank FScore
1 0.7933 6 0.7788 
2 0.7895 7 0.7729 
3 0.7855 8* 0.7651 
4 0.7849 9 0.7598 
5* 0.7812 18 0.5789 
 
5 Conclusions and Future Work 
This paper tries to build basic systems for Chi-
nese Word Sense Induction (CWSI) task. Basic 
clustering algorithms including k-means and 
agglomerative methods are studied. No extra 
language resources are used except the data 
given by the task organizers. 
To improve the performance of CWSI sys-
tems, we will introduce new features and study 
novel clustering algorithms. We will also inves-
tigate the bakeoff data sets to find some more 
characteristics of Chinese word senses. 
Acknowledgements 
The authors are grateful to the organizers of the 
Word Sense Induction task for their hard work to 
provide such a good research platform. The 
work in this paper is supported by grants from 
the National Natural Science Foundation of 
China (No.60773173, No.60970083). 
References 
D. Vickrey, L. Biewald, M. Teyssler, and D. Koller. 
2005. Word sense disambiguation for machine 
translation. In Proceedings of HLT/EMNLP2005, 
pp. 771-778. 
E. Agirre and A. Soroa. 2007. Semeval-2007 task 02: 
Evaluating word sense induction and discrimina-
tion systems. In Proceedings of SemEval2007, pp. 
7-12. 
G. Karypis. 2002. CLUTO - a clustering toolkit. 
Technical Report 02-017, Dept. of Computer Sci-
ence, University of Minnesota. Available at 
http://www.cs.umn.edu?cluto. 
H. Zhu. 2009. Research into Automatic Word Sense 
Discrimination on Chinese. PhD Dissertation of 
Peking University. 
J. Y. Chai and A. W. Biermann. 1999. The use of 
word sense disambiguation in an information ex-
traction system. In Proceedings of AAAI/IAAI1999, 
pp. 850-855. 
M. Denkowski. 2009. A Survey of Techniques for 
Unsupervised Word Sense Induction. Language & 
Statistics II Literature Review. 
O. Uzuner, B. Katz, and D. Yuret. 1999. Word sense 
disambiguation for information retrieval. In Pro-
ceedings of AAAI/IAAI1999, pp.985. 
S. Manandhar and I. P. Klapaftis. 2010. SemEval-
2010 Task 14: Evaluation Setting forWord Sense 
Induction &Disambiguation Systems. In Proceed-
ings of SemEval2010, pp. 117-122. 
Y. Zhao and G. Karypis. 2005. Hierarchical cluster-
ing algorithms for document datasets. Data Mining 
and Knowledge Discovery, 10(2):141?168. 
Y. Zhao and G. Karypis. 2001. Criterion functions for 
document clustering: Experiments and analysis. 
Technical Report 01?40, Dept. of Computer Sci-
ence, University of Minnesota. Available at 
http://cs.umn.edu/?karypis/publications. 
