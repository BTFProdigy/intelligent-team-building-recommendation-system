Proceedings of the 2nd Workshop on Building Educational Applications Using NLP,
pages 69?76, Ann Arbor, June 2005. c?Association for Computational Linguistics, 2005
Evaluating State-of-the-Art Treebank-style Parsers for
Coh-Metrix and Other Learning Technology Environments
Christian F. Hempelmann, Vasile Rus, Arthur C. Graesser, and Danielle S. McNamara
Institute for Intelligent Systems
Departments of Computer Science and Psychology
The University of Memphis
Memphis, TN 38120, USA
{chmplmnn, vrus, a-graesser, dsmcnamr}@memphis.edu
Abstract
This paper evaluates a series of freely
available, state-of-the-art parsers on a
standard benchmark as well as with
respect to a set of data relevant for
measuring text cohesion. We outline
advantages and disadvantages of exist-
ing technologies and make recommen-
dations. Our performance report uses
traditional measures based on a gold
standard as well as novel dimensions
for parsing evaluation. To our knowl-
edge this is the first attempt to eval-
uate parsers accross genres and grade
levels for the implementation in learn-
ing technology.
1 Introduction
The task of syntactic parsing is valuable to
most natural language understanding applica-
tions, e.g., anaphora resolution, machine trans-
lation, or question answering. Syntactic parsing
in its most general definition may be viewed as
discovering the underlying syntactic structure of
a sentence. The specificities include the types
of elements and relations that are retrieved by
the parsing process and the way in which they
are represented. For example, Treebank-style
parsers retrieve a bracketed form that encodes
a hierarchical organization (tree) of smaller el-
ements (called phrases), while Grammatical-
Relations(GR)-style parsers explicitly output re-
lations together with elements involved in the
relation (subj(John,walk)).
The present paper presents an evaluation of
parsers for the Coh-Metrix project (Graesser et
al., 2004) at the Institute for Intelligent Systems
of the University of Memphis. Coh-Metrix is a
text-processing tool that provides new methods
of automatically assessing text cohesion, read-
ability, and difficulty. In its present form, v1.1,
few cohesion measures are based on syntactic
information, but its next incarnation, v2.0, will
depend more heavily on hierarchical syntactic
information. We are developing these measures.
Thus, our current goal is to provide the most
reliable parser output available for them, while
still being able to process larger texts in real
time. The usual trade-off between accuracy and
speed has to be taken into account.
In the first part of the evaluation, we adopt
a constituent-based approach for evaluation, as
the output parses are all derived in one way or
another from the same data and generate simi-
lar, bracketed output. The major goal is to con-
sistently evaluate the freely available state-of-
the-art parsers on a standard data set and across
genre on corpora typical for learning technology
environments. We report parsers? competitive-
ness along an array of dimensions including per-
formance, robustness, tagging facility, stability,
and length of input they can handle.
Next, we briefly address particular types of
misparses and mistags in their relation to mea-
sures planned for Coh-Metrix 2.0 and assumed
to be typical for learning technology applica-
tions. Coh-Metrix 2.0 measures that centrally
rely on good parses include:
causal and intentional cohesion, for which the
main verb and its subject must be identified;
69
anaphora resolution, for which the syntactic re-
lations of pronoun and referent must be identi-
fied;
temporal cohesion, for which the main verb and
its tense/aspect must be identified.
These measures require complex algorithms
operating on the cleanest possible sentence
parse, as a faulty parse will lead to a cascad-
ing error effect.
1.1 Parser Types
While the purpose of this work is not to propose
a taxonomy of all available parsers, we consider
it necessary to offer a brief overview of the var-
ious parser dimensions. Parsers can be classi-
fied according to their general approach (hand-
built-grammar-based versus statistical), the way
rules in parses are built (selective vs. genera-
tive), the parsing algorithm they use (LR, chart
parser, etc.), type of grammar (unification-based
grammars, context-free grammars, lexicalized
context-free grammars, etc.), the representation
of the output (bracketed, list of relations, etc.),
and the type of output itself (phrases vs gram-
matical relations). Of particular interest to our
work are Treebank-style parsers, i.e., parsers
producing an output conforming to the Penn
Treebank (PTB) annotation guidelines. The
PTB project defined a tag set and bracketed
form to represent syntactic trees that became a
standard for parsers developed/trained on PTB.
It also produced a treebank, a collection of hand-
annotated texts with syntactic information.
Given the large number of dimensions along
which parsers can be distinguished, an evalua-
tion framework that would provide both parser-
specific (to understand the strength of differ-
ent technologies) and parser-independent (to be
able to compare different parsers) performance
figures is desirable and commonly used in the
literature.
1.2 General Parser Evaluation Methods
Evaluation methods can be broadly divided
into non-corpus- and corpus-based methods
with the latter subdivided into unannotated
and annotated corpus-based methods (Carroll
et al, 1999). The non-corpus method sim-
ply lists linguistic constructions covered by the
parser/grammar. It is well-suited for hand-
built grammars because during the construction
phase the covered cases can be recorded. How-
ever, it has problems with capturing complex-
ities occuring from the interaction of covered
cases.
The most widely used corpus-based eval-
uation methods are: (1) the constituent-
based (phrase structure) method, and (2) the
dependency/GR-based method. The former has
its roots in the Grammar Evaluation Interest
Group (GEIG) scheme (Grishman et al, 1992)
developed to compare parsers with different un-
derlying grammatical formalisms. It promoted
the use of phrase-structure bracketed informa-
tion and defined Precision, Recall, and Cross-
ing Brackets measures. The GEIG measures
were extended later to constituent information
(bracketing information plus label) and have
since become the standard for reporting auto-
mated syntactic parsing performance. Among
the advantages of constituent-based evaluation
are generality (less parser specificity) and fine
grain size of the measures. On the other hand,
the measures of the method are weaker than ex-
act sentence measures (full identity), and it is
not clear if they properly measure how well a
parser identifies the true structure of a sentence.
Many phrase boundary mismatches spawn from
differences between parsers/grammars and cor-
pus annotation schemes (Lin, 1995). Usually,
treebanks are constructed with respect to infor-
mal guidelines. Annotators often interpret them
differently leading to a large number of different
structural configurations.
There are two major approaches to evaluate
parsers using the constituent-based method. On
the one hand, there is the expert-only approach
in which an expert looks at the output of a
parser, counts errors, and reports different mea-
sures. We use a variant of this approach for
the directed parser evaluation (see next section).
Using a gold standard, on the other hand, is a
method that can be automated to a higher de-
gree. It replaces the counting part of the former
method with a software system that compares
the output of the parser to the gold standard,
70
highly accurate data, manually parsed ? or au-
tomatically parsed and manually corrected ? by
human experts. The latter approach is more
useful for scaling up evaluations to large collec-
tions of data while the expert-only approach is
more flexible, allowing for evaluation of parsers
from new perspectives and with a view to spe-
cial applications, e.g., in learning technology en-
vironments.
In the first part of this work we use the gold
standard approach for parser evaluation. The
evaluation is done from two different points of
view. First, we offer a uniform evaluation for the
parsers on section 23 from the Wall Street Jour-
nal (WSJ) section of PTB, the community norm
for reporting parser performance. The goal of
this first evaluation is to offer a good estimation
of the parsers when evaluated in identical en-
vironments (same configuration parameters for
the evaluator software). We also observe the fol-
lowing features which are extremely important
for using the parsers in large-scale text process-
ing and to embed them as components in larger
systems.
Self-tagging: whether or not the parser does tag-
ging itself. It is advantageous to take in raw text
since it eliminates the need for extra modules.
Performance: if the performance is in the mid
and upper 80th percentiles.
Long sentences: the ability of the parser to han-
dle sentences longer than 40 words.
Robustness: relates to the property of a parser
to handle any type of input sentence and return
a reasonable output for it and not an empty line
or some other useless output.
Second, we evaluate the parsers on narrative
and expository texts to study their performance
across the two genres. This second evaluation
step will provide additional important results
for learning technology projects. We use evalb
(http://nlp.cs.nyu.edu/evalb/) to evaluate the
bracketing performance of the output of a parser
against a gold standard. The software evaluator
reports numerous measures of which we only re-
port the two most important: labelled precision
(LR), labelled recall (LR) which are discussed in
more detail below.
1.3 Directed Parser Evaluation Method
For the third step of this evaluation we looked
for specific problems that will affect Coh-Metrix
2.0, and presumably learning technology appli-
cations in general, with a view to amending
them by postprocessing the parser output. The
following four classes of problems in a sentence?s
parse were distinguished:
None: The parse is generally correct, unambigu-
ous, poses no problem for Coh-Metrix 2.0.
One: There was one minor problem, e.g., a mis-
labeled terminal or a wrong scope of an adver-
bial or prepositional phrase (wrong attachment
site) that did not affect the overall parse of the
sentence, which is therefore still usable for Coh-
Metrix 2.0 measures.
Two: There were two or three problems of the
type one, or a problem with the tree structure
that affected the overall parse of the sentence,
but not in a fatal manner, e.g., a wrong phrase
boundary, or a mislabelled higher constituent.
Three: There were two or more problems of the
type two, or two or more of the type one as
well as one or more of the type two, or another
fundamental problem that made the parse of the
sentence completely useless, unintelligible, e.g.,
an omitted sentence or a sentence split into two,
because a sentence boundary was misidentified.
2 Evaluated Parsers
2.1 Apple Pie
Apple Pie (AP) (Sekine and Grishman, 1995)
extracts a grammar from PTB v.2 in which S
and NP are the only true non-terminals (the
others are included into the right-hand side of
S and NP rules). The rules extracted from the
PTB have S or NP on the left-hand side and a
flat structure on the right-hand side, for instance
S ? NP VBX JJ. Each such rule has the most
common structure in the PTB associated with
it, and if the parser uses the rule it will gener-
ate its corresponding structure. The parser is
a chart parser and factors grammar rules with
common prefixes to reduce the number of active
nodes. Although the underlying model of the
parser is simple, it can?t handle sentences over
40 words due to the large variety of linguistic
71
constructs in the PTB.
2.2 Charniak?s Parser
Charniak presents a parser (CP) based on prob-
abilities gathered from the WSJ part of the PTB
(Charniak, 1997). It extracts the grammar and
probabilities and with a standard context-free
chart-parsing mechanism generates a set of pos-
sible parses for each sentence retaining the one
with the highest probability (probabilities are
not computed for all possible parses). The prob-
abilities of an entire tree are computed bottom-
up. In (Charniak, 2000), he proposes a gen-
erative model based on a Markov-grammar. It
uses a standard bottom-up, best-first probabilis-
tic parser to first generate possible parses before
ranking them with a probabilistic model.
2.3 Collins?s (Bikel?s) Parser
Collins?s statistical parser (CBP; (Collins,
1997)), improved by Bikel (Bikel, 2004), is based
on the probabilities between head-words in parse
trees. It explicitly represents the parse proba-
bilities in terms of basic syntactic relationships
of these lexical heads. Collins defines a map-
ping from parse trees to sets of dependencies,
on which he defines his statistical model. A
set of rules defines a head-child for each node
in the tree. The lexical head of the head-
child of each node becomes the lexical head of
the parent node. Associated with each node is
a set of dependencies derived in the following
way. For each non-head child, a dependency is
added to the set where the dependency is identi-
fied by a triplet consisting of the non-head-child
non-terminal, the parent non-terminal, and the
head-child non-terminal. The parser is a CYK-
style dynamic programming chart parser.
2.4 Stanford Parser
The Stanford Parser (SP) is an unlexical-
ized parser that rivals state-of-the-art lexical-
ized ones (Klein and Manning, 2003). It
uses a context-free grammar with state splits.
The parsing algorithm is simpler, the grammar
smaller and fewer parameters are needed for the
estimation. It uses a CKY chart parser which
exhaustively generates all possible parses for a
sentence before it selects the highest probabil-
ity tree. Here we used the default lexicalized
version.
3 Experiments and Results
3.1 Text Corpus
We performed experiments on three data sets.
First, we chose the norm for large scale parser
evaluation, the 2416 sentences of WSJ section
23. Since parsers have different parameters that
can be tuned leading to (slightly) different re-
sults we first report performance values on the
standard data set and then use same parameter
settings on the second data set for more reliable
comparison.
The second experiment is on a set of three nar-
rative and four expository texts. The gold stan-
dard for this second data set was built manually
by the authors starting from CP?s as well as SP?s
output on those texts. The four texts used ini-
tially are two expository and two narrative texts
of reasonable length for detailed evaluation:
The Effects of Heat (SRA Real Science Grade 2
Elementary Science): expository; 52 sentences,
392 words: 7.53 words/sentence;
The Needs of Plants (McGraw-Hill Science):
expository; 46 sentences, 458 words: 9.96
words/sentence;
Orlando (Addison Wesley Phonics Take-Home
Reader Grade 2): narrative; 65 sentences, 446
words: 6.86 words/sentence;
Moving (McGraw-Hill Reading - TerraNova Test
Preparation and Practice - Teachers Edition
Grade 3): narrative, 33 sentences, 433 words:
13.12 words/sentence.
An additional set of three texts was cho-
sen from the Touchstone Applied Science As-
sociates, Inc., (TASA) corpus with an average
sentence length of 13.06 (overall TASA average)
or higher.
Barron17: expository; DRP=75.14 (college
grade); 13 sentences, 288 words: 22.15
words/sentence;
Betty03: narrative; DRP=56.92 (5th grade); 14
sentences, 255 words: 18.21 words/sentence;
Olga91: expository; DRP=74.22 (college grade);
12 sentences, 311 words: 25.92 words/sentence.
72
We also tested all four parsers for speed on a
corpus of four texts chosen randomly from the
Metametrix corpus of school text books, across
high and low grade levels and across narrative
and science texts (see Section 3.2.2).
G4: 4th grade narrative text, 1,500 sentences,
18,835 words: 12.56 words/sentence;
G6: 6th grade science text, 1,500 sentences,
18,237 words: 12.16 words/sentence;
G11: 11th grade narrative text, 1,558 sentences,
18,583 words: 11.93 words/sentence;
G12: 12th grade science text, 1,520 sentences,
25,098 words: 16.51 words/sentence.
3.2 General Parser Evaluation Results
3.2.1 Accuracy
The parameters file we used for evalb was
the standard one that comes with the package.
Some parsers are not robust, meaning that for
some input they do not output anything, leading
to empty lines that are not handled by the evalu-
ator. Those parses had to be ?aligned? with the
gold standard files so that empty lines are elim-
inated from the output file together with their
peers in the corresponding gold standard files.
In Table 1 we report the performance values
on Section 23 of WSJ. Table 2 shows the results
for our own corpus. The table gives the average
values of two test runs, one against the SP-based
gold standard, the other against the CP-based
gold standard, to counterbalance the bias of the
standards. Note that CP and SP possibly still
score high because of this bias. However, CBP
is clearly a contender despite the bias, while AP
is not.1 The reported metrics are Labelled Pre-
cision (LP) and Labelled Recall (LR). Let us de-
note by a the number of correct phrases in the
output from a parser for a sentence, by b the
number of incorrect phrases in the output and
by c the number of phrases in the gold standard
for the same sentence. LP is defined as a/(a+b)
and LR is defined as a/c. A summary of the
other dimensions of the evaluation is offered in
Table 3. A stability dimension is not reported
1AP?s performance is reported for sentences < 40
words in length, 2,250 out of 2,416. SP is also not ro-
bust enough and the performance reported is only on
2,094 out of 2,416 sentences in section 23 of WSJ.
because we were not able to find a bullet-proof
parser so far, but we must recognize that some
parsers are significantly more stable than oth-
ers, namely CP and CBP. In terms of resources
needed, the parsers are comparable, except for
AP which uses less memory and processing time.
The LP/LR of AP is significantly lower, partly
due to its outputting partial trees for longer sen-
tences. Overall, CP offers the best performance.
Note in Table 1 that CP?s tagging accuracy is
worst among the three top parsers but still de-
livers best overall parsing results. This means
that its parsing-only performance is slighstly
better than the numbers in the table indicate.
The numbers actually represent the tagging and
parsing accuracy of the tested parsing systems.
Nevertheless, this is what we would most likely
want to know since one would prefer to input
raw text as opposed to tagged text. If more
finely grained comparisons of only the parsing
aspects of the parsers are required, perfect tags
extracted from PTB must be provided to mea-
sure performance.
Table 4 shows average measures for each of
the parsers on the PTB and seven expository
and narrative texts in the second column and
for expository and narrative in the fourth col-
umn. The third and fifth columns contain stan-
dard deviations for the previous columns, re-
spectively. Here too, CP shows the best result.
3.2.2 Speed
All parsers ran on the same Linux Debian ma-
chine: P4 at 3.4GHz with 1.0GB of RAM.2 AP?s
and SP?s high speeds can be explained to a large
degree by their skipping longer sentences, the
very ones that lead to the longer times for the
other two candidates. Taking this into account,
SP is clearly the fastest, but the large range of
processing times need to be heeded.
3.3 Directed Parser Evaluation Results
This section reports the results of expert rating
of texts for specific problems (see Section 1.3).
The best results are produced by CP with an av-
erage of 88.69% output useable for Coh-Metrix
2.0 (Table 6). CP also produces good output
2Some of the parsers also run under Windows.
73
Table 1: Accuracy of Parsers.
Parser Performance(LP/LR/Tagging - %)
WSJ 23 Expository Narrative
Applie Pie 43.71/44.29/90.26 41.63/42.70 42.84/43.84
Charniak?s 84.35/88.28/92.58 91.91/93.94 93.74/96.18
Collins/Bikel?s 84.97/87.30/93.24 82.08/85.35 67.75/85.19
Stanford 84.41/87.00/95.05 75.38/85.12 62.65/87.56
Table 2: Performance of parsers on the narrative and expository text (average against CP-based
and SP-based gold standard).
File Performance (LR/LP - %)
AP CP CBP SP
Heat 48.25/47.59 91.96/93.77 92.47/94.14 92.44/91.85
Plants 41.85/45.89 85.34/88.02 78.24/88.45 81.00/85.62
Orlando 45.82/49.03 85.83/91.88 65.87/93.97 57.75/90.72
Moving 37.77/41.45 88.93/92.74 53.94/91.68 76.56/84.97
Barron17 43.22/42.95 89.74/91.32 80.49/89.32 87.22/86.31
Betty03 46.53/44.67 90.77/90.74 87.95/85.21 74.53/80.91
Olga91 32.29/32.69 77.65/80.04 61.61/75.43 61.65/70.60
Table 3: Evaluation of Parsers with Respect to the Criteria Listed at the Top of Each Column.
Parser Self-tagging Performance Long-sentences Robustness
AP Yes No No No
CP Yes Yes Yes Yes
CBP Yes Yes Yes Yes
SP Yes Yes No No
Table 4: Average Performance of Parsers.
Parser Ave. (LR/LP - %) S.D. (%) Ave. on S.D. on
Exp+Nar (LR/LP - %) Exp+Nar (%)
AP 42.73/43.61 1.04/0.82 42.24/43.46 5.59/5.41
CP 90.00/92.80 4.98/4.07 87.17/89.79 4.85/4.66
CBP 78.27/85.95 9.22/1.17 74.36/88.31 14.24/6.51
SP 74.14/86.56 10.93/1.28 75.88/84.42 12.66/7.11
74
Table 5: Parser Speed in Seconds.
G4 G6 G11 G12
#sent 619 3336 4976 2215
AP 144 89 144 242
CP 647 499 784 1406
CBP 485 1947 1418 1126
SP 449 391 724 651
Ave. 431 732 768 856
most consistently at a standard deviation over
the seven texts of 8.86%. The other three candi-
dates are clearly trailing behing, namely by be-
tween 5% (SP) and 11% (AP). The distribution
of severe problems is comparable for all parsers.
Table 6: Average Performance of Parsers over
all Texts (Directed Evaluation).
Ave. (%) S.D. (%)
AP 77.31 15.00
CP 88.69 8.86
CBP 79.82 18.94
SP 83.43 11.42
As expected, longer sentences are more prob-
lematic for all parsers, as can be seen in Ta-
ble 7. No significant trends in performance dif-
ferences with respect to genre difference, narra-
tive (Orlando, Moving, Betty03) vs. expository
texts (Heat, Plants, Barron17, Olga91), were de-
tected (cf. also speed results in Table 5). But
we assume that the difference in average sen-
tence length obscures any genre differences in
our small sample.
The most common non-fatal problems (type
one) involved the well-documented adjunct at-
tachment site issue, in particular for preposi-
tional phrases ((Abney et al, 1999), (Brill and
Resnik, 1994), (Collins and Brooks, 1995)) as
well as adjectival phrases (Table 8)3. Similar
misattachment issues for adjuncts are encoun-
tered with adverbial phrases, but they were rare
3PP = wrong attachment site for a prepositional
phrase; ADV = wrong attachment site for an adverbial
phrase; cNP = misparsed complex noun phrase; &X =
wrong coordination
Table 7: Correlation of Average Performance
per Text for all Parsers and Average Sentence
Length (Directed Evaluation).
Text perf. (%) length (#words)
Heat 92.31 7.54
Plants 90.76 9.96
Orlando 93.46 6.86
Moving 90.91 13.12
Barron17 76.92 22.15
Betty03 71.43 18.21
Olga91 60.42 25.92
in our corpus.
Another common problem are deverbal nouns
and denominal verbs, as well as -ing/VBG
forms. They share surface forms leading to am-
biguous part of speech assignments. For many
Coh-Metrix 2.0 measures, most obviously tem-
poral cohesion, it is necessary to be able to dis-
tinguish gerunds from gerundives and deverbal
adjectives and deverbal nouns.
Table 8: Specific Problems by Parser.
PP ADV cNP &X
AP 13 10 8 9
CP 15 1 2 7
CBP 10 0 0 13
SP 22 6 3 4
Sum 60 17 13 33
Problems with NP misidentification are par-
ticularly detrimental in view of the impor-
tant role of NPs in Coh-Metrix 2.0 mea-
sures. This pertains in particular to the mistag-
ging/misparsing of complex NPs and the coor-
dination of NPs. Parses with fatal problems
are expected to produce useless results for algo-
rithms operating with them. Wrong coordina-
tion is another notorious problem of parsers (cf.
(Cremers, 1993), (Grootveld, 1994)). In our cor-
pus we found 33 instances of miscoordination,
of which 23 involved NPs. Postprocessing ap-
proaches that address these issues are currently
under investigation.
75
4 Conclusion
The paper presented the evaluation of freely
available, Treebank-style, parsers. We offered
a uniform evaluation for four parsers: Apple
Pie, Charniak?s, Collins/Bikel?s, and the Stan-
ford parser. A novelty of this work is the evalua-
tion of the parsers along new dimensions such as
stability and robustness and across genre, in par-
ticular narrative and expository. For the latter
part we developed a gold standard for narrative
and expository texts from the TASA corpus. No
significant effect, not already captured by vari-
ation in sentence length, could be found here.
Another novelty is the evaluation of the parsers
with respect to particular error types that are
anticipated to be problematic for a given use of
the resulting parses. The reader is invited to
have a closer look at the figures our tables pro-
vide. We lack the space in the present paper to
discuss them in more detail. Overall, Charniak?s
parser emerged as the most succesful candidate
of a parser to be integrated where learning tech-
nology requires syntactic information from real
text in real time.
ACKNOWLEDGEMENTS
This research was funded by Institute for Educa-
tions Science Grant IES R3056020018-02. Any
opinions, findings, and conclusions or recom-
mendations expressed in this article are those
of the authors and do not necessarily reflect the
views of the IES. We are grateful to Philip M.
McCarthy for his assistance in preparing some
of our data.
References
S. Abney, R. E. Schapire, and Y. Singer. 1999.
Boosting applied to tagging and pp attachment.
Proceedings of the 1999 Joint SIGDAT Confer-
ence on Empirical Methods in Natural Language
Processing and Very Large Corpora, pages 38?45.
D. M. Bikel. 2004. Intricacies of collins? parsing
model. Computational Linguistics, 30-4:479?511.
E. Brill and P. Resnik. 1994. A rule-based approach
to prepositional phrase attachment disambigua-
tion. In Proceedings of the 15th International Con-
ference on Computational Linguistics.
J. Carroll, E. Briscoe, and A. Sanfilippo, 1999.
Parser evaluation: current practice, pages 140?
150. EC DG-XIII LRE EAGLES Document EAG-
II-EWG-PR.1.
E. Charniak. 1997. Statistical parsing with a
context-free grammar and word statistics. Pro-
ceedings of the Fourteenth National Conference
on Artificial Intelligence, AAAI Press/MIT Press,
Menlo Park.
E. Charniak. 2000. A maximum-entropy-inspired
parser. In Proceedings of the North-American
Chapter of Association for Computational Lin-
guistics, Seattle, Washington.
M. Collins and J. Brooks. 1995. Prepositional phrase
attachment through a backed-off model. In Pro-
ceedings of the Third Workshop on Very Large
Corpora, Cambridge.
M. Collins. 1997. Three generative, lexicalised mod-
els for statistical parsing. In Proceedings of the
35th Annual Meeting of the Association for Com-
putational Linguistic, Madrid, Spain.
C. Cremers. 1993. On Parsing Coordination Cate-
gorially. Ph.D. thesis, Leiden University.
A. C. Graesser, D.S. McNamara, M. M. Louwerse,
and Z. Cai. 2004. Coh-metrix: Analysis of text on
cohesion and language. Behavior Research Meth-
ods, Instruments, and Computers, 36-2:193?202.
R. Grishman, C. MacLeod, and J. . Sterling. 1992.
Evaluating parsing strategies using standardized
parse files. In Proceedings of the Third Conference
on Applied Natural Language Processing, pages
156?161.
M. Grootveld. 1994. Parsing Coordination Genera-
tively. Ph.D. thesis, Leiden University.
D. Klein and C. Manning. 2003. Accurate unlexi-
calized parsing. In Proceedings of the 41st Annual
Meeting of the Association for Computational Lin-
guistic, Sapporo, Japan.
D. Lin. 1995. A dependency-based method for eval-
uating broad-coverage parsers. Proceedings of In-
ternational Joint Conference on Artificial Intelli-
gence, pages 1420?1427.
A. Ratnaparkhi, J. Renyar, and S. Roukos. 1994. A
maximum entropy model for prepositional phrase
attachment. In Proceedings of the ARPA Work-
shop on Human Language Technology.
S. Sekine and R. Grishman. 1995. A corpus-
based probabilistic grammar with only two non-
terminals. Proceedings of the International Work-
shop on Parsing Technologies, pages 216?223.
76
WHY NLP SHOULD MOVE INTO IAS 
 
Victor RASKIN 
CERIAS and NLP Lab, Purdue University  
1356 Heavilon Hall 324 
W. Lafayette, IN 47907-1356 USA  
vraskin@purdue.edu 
Sergei NIRENBURG 
CRL, New Mexico State University 
286 New Science Building 
Las Cruces, NM 88003 USA 
sergei@crl.nmsu.edu
 
Mikhail J. ATALLAH 
CERIAS and Department 
of Computer Science 
Purdue University 
1315 Recitation Hall 215 
W. Lafayette, IN 47907-
1315 USA 
mja@cs.purdue.edu 
Christian F. 
HEMPELMANN 
CERIAS and NLP Lab, 
Purdue University  
1356 Heavilon Hall 324 
W. Lafayette, IN 47907-
1356 USA  
hempelma@purdue.edu 
Katrina E. 
TRIEZENBERG 
CERIAS and NLP Lab, 
Purdue University  
1356 Heavilon Hall 324 
W. Lafayette, IN 47907-
1356 USA  
kattriez@purdue.edu
 
Abstract 
The paper introduces the ways in which 
methods and resources of natural language 
processing (NLP) can be fruitfully employed 
in the domain of information assurance and 
security (IAS). IAS may soon claim a very 
prominent status both conceptually and in 
terms of future funding for NLP, alongside 
or even instead of established applications, 
such as machine translation (MT). After a 
brief summary of theoretical premises of 
NLP in general and of ontological semantics 
as a specific approach to NLP developed 
and/or practiced by the authors, the paper 
reports on the interaction between NLP and 
IAS through brief discussions of some 
implemented and planned NLP-enhanced 
IAS systems at the Center for Education and 
Research in Information Assurance and 
Security (CERIAS). The rest of the paper 
deals with the milestones and challenges in 
the future interaction between NLP and IAS 
as well as the role of a representational, 
meaning-based NLP approach in that future. 
 
1 Introduction 
With new applications, NLP sees new 
challenges and has to develop additional 
functionalities. For a few decades, it was driven 
predominantly, if not exclusively, by MT. This 
application, while emphasizing certain 
functionalities, has a limited use for a reasoning 
functionality. Increasingly, the current 
applications, such as data mining and question 
answering bring reasoning to the front of NLP. 
Applications come, for the most part, from real 
life, and in real life, computer systems keep 
getting attacked by hackers and industrial or 
political adversaries and need to be protected 
with the help of automatic systems. Information 
security provides this protection by preventing 
unauthorized use and detecting intrusions. 
Information assurance guarantees the 
authenticity of transmitted and stored 
information. In the last five years, since the 
inception of CERIAS with the help of a massive 
grant from the Eli Lilly Foundation, two of the 
co-authors have led a pioneering effort in 
exploring the possibility of applying the 
methods and resources of NLP to IAS. Another 
co-author has led a decade-long effort in 
developing the resources of ontological 
semantics and testing them in various 
implementations of NLP applications. This 
paper is the result of all these efforts as well as 
of the excellent work of the participating and 
actively contributing graduate and 
undergraduate research assistants. 
 
2 Basic Premises 
Nirenburg and Raskin (2002) views NLP as an 
application of both linguistics and cognitive 
science. This application is a theory of itself, 
which defines the format of its descriptions, e.g., 
meaning representations for texts (TMRs). The 
theory is associated with methodologies to 
produce these descriptions. Applications tend to 
dictate the content of the descriptions they need 
in order to be successfully implemented and 
thus, to a large extent, the methodology of 
implementation, which is, thus, arrived at 
systematically and not by just trial and error and 
guesswork, as Chomskian linguistics would 
have us believe. 
 
In general, one of the choices in NLP is the 
method-driven vs. the problem-driven approach. 
The former espouses the use of a particular 
method in as many applications as possible. The 
danger here is that both the applications and the 
level of results that is declared satisfactory are 
molded to what is allowed by the method: ?To a 
hammer, everything looks like a nail.? 
 
Problem-oriented NLP chains back from the 
needs of an application and happily accepts 
eclectic or pipelined approaches if this 
arrangement promises better results.  
 
We approach IAS from the problem-oriented 
point of view. It is a growing family of 
applications that society needs to protect its 
computer systems and databases from 
unauthorized use and destructive attacks. It is 
the goal of NLP to serve the existing IAS needs 
as well as helping the IAS community to 
discover new ways to adapt the existing NLP 
resources and to order the development of new 
resources. 
 
3 NLP Applications to IAS 
 
3.1 IAS Needs 
Most generally, IAS develops software to: 
 
? encrypt  and decrypt data; 
? preclude unauthorized use of 
computer systems and data with a vast 
array of protective measures; 
? detect  intrusion, including virus 
recognition and anti-virus protection. 
 
Much of IAS deals with signals and information 
other than texts in natural language (NL) but 
there are enough applications for textual data, 
and this is where the methods and resources of 
NLP come into the picture. 
 
3.2 NLP/IAS Interface 
CERIAS has taken a leading role in 
investigating how NLP can be utilized for IAS, 
and the initial efforts, as early as 1998, were 
devoted to identifying the text-based subtasks in 
IAS. To date, the following applications have 
been recognized and addressed, in chronological 
order: 
 
? using machine translation for an 
additional layer of encryption; 
? generating mnemonics for random-
generated passwords; 
? declassification or downgrading of 
classified information; 
? NL watermarking; 
? preventing theft of intellectual 
property; 
? forensic IAS, specifically, tracing 
leaks in divulging protected 
information; 
? tamperproofing textual data; 
? enhancing the acceptance of IAS 
products by the users with the help of 
computational humor. 
 
In the rest of the section, we will characterize 
these tasks briefly, with an emphasis on the NLP 
contribution to their solution, a contribution 
which is largely constitutive in nature in the 
sense that they would probably not exist if NLP 
could not offer the know-how to implement 
them. 
 
3.2.1 MT for Encryption 
Inspired by the most obvious connection 
between encryption and NL, the largely 
apocryphal World War II episode, when instead 
of an elaborate code, the American and British 
General Headquarters in Europe used the native 
speakers of Navajo (Shawnee, in another 
version, involving the Pacific theater) to 
communicate in open, uncoded language and 
were never ?decoded,? the idea was to use a 
family of existing or rapidly deployable MT 
systems (see Nirenburg and Raskin 1998) to add 
a level of encryption in an ?exotic? language. 
Raskin et al?Page 2 
Once proposed (Raskin et al 2001), the idea 
failed to catch and has never been implemented, 
partially because there was no research 
challenge in that, but also because it would 
involve the ?security by obscurity? principle 
disdained by IAS: one should assume that the 
adversary is at least as smart and knowledgeable 
as we, the good guys, are. Also, an MT system, 
even if publicly available, is too long and messy 
a ?key,? another IAS no-no. 
 
3.2.2 Mnemonics for Random-Generated 
Passwords 
Passwords are sometimes dismissed in IAS as 
too weak and ineffective a protection measure. 
Reality is, however, that for an absolute majority 
of computer users, this remains the only 
protection against unauthorized use and abuse 
and the loss of data, and the users weaken it 
considerably by changing the passwords 
randomly generated for them by the computer at 
the time the accounts are created to something 
that is easy for them to remember. The weakness 
of such passwords is that they can be vulnerable 
to a brute-force attack because the space of 
possible passwords to be tried by the attacker 
becomes much smaller than that for random-
generated ones. Here and elsewhere, IAS 
measures hardly ever exclude the possibility of a 
successful attack (e.g., using a random generator 
to try every possible alphanumeric combination 
to access the account) but rather ?raising the 
ante? for the adversary, making the attack 
costlier and more complicated. 
 
We implemented Versions 1 and 2 of the 
automatic mnemonic text (jingle) generator 
(AMTG). Both versions take a randomly 
generated alphanumeric password as input and 
generate a funny and memorable two-line text 
(jingle). AMTG-1 implemented after the first 6 
months of research limited the input to 8-letter 
(no digits) case-insensitive passwords and 
generated a rigidly formatted, uniform-meter, 
single-tune jingles, whose funniness depended 
on the verb antonymy between the first and 
second lines (here and throughout this section, 
see Raskin et al 2001 for examples and further 
discussion). AMTG-2 removes the rigid 
limitation on the password format and accepts 3-
8-symbol alphanumeric, case-sensitive input 
while generating two lines of purported political 
satire (see McDonough 2000). The proof-of-
concept software was implemented by 
McDonough and is in preparation for patenting.  
 
3.2.3 Natural Language Downgrading 
Increasingly, in interagency exchanges in the 
government, international coalition 
communication, and exchanges among business 
partners, there has been a need to develop an 
intricate architecture for combining a ?high? 
network and a ?low? network. Authorized users, 
with access to the high network, where sensitive 
data is stored and exchanged, must have access 
to the low network, but not the other way 
around. If this is all there is to it, the 
communication between the two networks is 
assured with the help of a variety of switches 
and one-way filters: the low-network 
information can propagate up but the high-
network information must not leak down. There 
are enough technical and conceptual problems 
with such one-way filters, but they are 
multiplied manifold if there is also a need to 
share some high-network information with the 
low-network users in a way that removes all the 
sensitive data. In this context the essentially 
semantic ability to recognize a sensitive message 
comes into play. We are focusing only on 
sanitizing textual information. In other words, 
for each classified text T there must be generated 
a sanitized, downgraded text T?, from which all 
sensitive data are removed according to a certain 
list of criteria. We are doing this by utilizing the 
NLP resources developed by the ontological-
semantic approach (Nirenburg and Raskin 
2002), which allows deep-meaning penetration 
and, as a result, much enhanced sensitive 
information detection and removal (see 
Mohamed 2001) than that allowed by any 
keyword-based approach, straightforward or 
statistical. 
 
3.2.4 Intellectual Property Protection 
Essentially the same methods of detection and 
seamless replacement developed for 
downgrading can be used to intercept and 
prevent deliberate or inadvertent divulging of 
proprietary and/or classified information. This is 
much easier to do offline, of course, but there is 
also an increasing need in inconspicuous 
Raskin et al?Page 3 
interception and sanitizing of e-mail online. 
Here, somewhat less than in straightforward 
downgrading, which can all be done offline, a 
half-way solution may be best: instead of letting 
the system detect the sensitive information and 
replace it, all fully automatically, a simpler and 
coarser-grain-sized system can only flag 
possible violations to a human, who makes the 
final determination. 
 
3.2.5 Natural Language Watermarking 
We have developed software capable of 
embedding a hidden textual watermark in a 
textual message without changing the meaning 
of the text at all and the wording only slightly if 
necessary. Let T be a NL text, and let W be a 
string that is much shorter than T. We wish to 
generate NL text T? such that:  T? has essentially 
the same meaning as T; T' contains W as a secret 
watermark, and the presence of W would hold up 
in court if revealed (e.g., W could say, ?This is 
the Property of X, and was licensed to Y on date 
Z?); the watermark W is not readable from T' 
without knowledge of the secret key that was 
used to introduce W; for someone who knows 
the secret key, W can be obtained from T' 
without knowledge of T (so there is no need to 
permanently store the original, non-watermarked 
copy of copyrighted material);  unless someone 
knows the secret key, W is difficult to remove 
from T' without drastically changing the 
meaning of T'; the process by which W is 
introduced into T to obtain T' is not secret, 
rather, it is the secret key that gives the scheme 
its security. We developed a technique (Atallah 
et al 2001, 2002) which embeds portions of W?s 
bitstring in the underlying syntactic and 
semantic (TMR) structures, respectively, of a 
selection of sentences in a text by manipulating 
those sentences slightly with the help of 
meaning-preserving syntactic and semantic 
information. The semantic technique is much 
more complex and allows for a much wider 
bandwidth, i.e., the use of much fewer 
watermark bearing sentences, thus making the 
later technique usable for such short sentences as 
wire agency releases. It also furthers that 
advantage by making it unnecessary to double 
the number of engaged and manipulated 
sentences and disposing of the marker-bearing 
sentences that precede each watermark-bearing 
sentence in the earlier, syntactic approach. 
 
3.2.6 Tracing the Leaks 
By embedding different, personalized 
watermarks in different copies of the same 
document, we can trace a leak to a particular 
recipient of classified or proprietary information. 
Thus, the watermark may state something like, 
?Copy #47 issued to Jane Smith.? An additional 
research problem that needs to be addressed in 
such a system is the adversary collusion: the 
watermark should be such that the comparison 
of two differently watermarked copies of the 
same document not lead to the discovery and 
removal of the watermarks. 
 
 3.2.7 Tamperproofing as Extensions of 
Watermarking 
The watermarking technique can be interestingly 
reversed from the search for the most robust, 
indestructible watermark to that for the most 
brittle one, so that any tampering with a 
document would invariably lead to the removal 
of the watermark (see Atallah, Raskin et al 
2002) and thus signal the tampering. The initial 
research in this area demonstrates, interestingly 
and not quite unexpectedly, that designing the 
most brittle watermark is as challenging as 
designing the most robust and resilient one. 
 
3.2.8. Enhancing Customer Acceptance of IAS 
Products with Computational Humor. 
One of the biggest issues in IAS has been the 
refusal to deploy the acquired IAS products 
because of the reluctance to learn, install, and 
debug the developed systems. One approach to 
resolving this very real problem is to reward the 
system administrators (sysadmins) for making 
the effort by entertaining them throughout the 
process of installing and maintaining the product 
with the help of humor-generating intelligent 
embodied agents (see Nijholt 2002, Stock and 
Strapparava 2002). The current state of the art in 
computational humor is rapidly making it 
increasingly feasible. The idea does have a 
shock value to it, both for the better and for the 
worse: some hard-core techies in IAS, and, as a 
matter of fact, in NLP, think that computational 
humor is a hoax. Usually, a little homework 
Raskin et al?Page 4 
changes this attitude (see Raskin 1996, 2002; 
Raskin and Attardo 1994). 
 
4 Perspectives, Challenges, Milestones 
NLP deals with texts in NL, and in Section 3.2.1 
above, we clearly stated that the applicability of 
NLP to IAS depends on the use of textual data in 
IAS systems. This statement was, actually, a 
considerable simplification. 
 
For lower end, non-semantic NLP methods, 
those dependent on Boolean keywords, syntax, 
and/or statistics, the presence of textual data is 
indeed essential. For ontological semantics, 
which is a system of text meaning 
representation, the ?text? itself may be in any 
non-natural-language format, including any 
scientific or logical formalism, as long as it has 
conceptual content. That content is directly 
representable with the help of the ontology, 
bypassing any NL lexicon if necessary. In other 
words, the ontology is equally applicable to a 
formal language as it is to a NL if a lexicon for 
the former is accessible. 
 
Nevertheless, what applications of ontological 
semantics can contribute most obviously and  on 
a broader scale, is extending research and 
application paradigms in IAS by including NL 
data sources and adapting the appropriate NLP 
applications, their goals and results to them. 
These include: 
? inclusion of NL data sources as an 
integral part of the overall data 
sources in information security 
applications, and 
? formal specification of the 
information security community 
know-how for the support of routine 
and time-efficient measures to prevent 
and counteract computer attacks 
Where does NL data play a role in IAS? The 
applications listed in Section 3.2 provide the 
obvious examples. In addition, system 
administrator (sysadmin) logs, the standard 
object of data-mining efforts in IAS with the 
purpose of intrusion detection, are written in a 
sublanguage of a NL and can be allowed to 
contain more complex language if the 
processing systems are capable of treating it; 
however, all the pre-NLP studies ignore the NL 
clues in the logs and thus miss out on a great 
deal of important content. Similarly, to use 
another example, if an InfoSec task involves 
human alongside software agents, NLP is the 
most efficient way of handling interagent 
communication (see Nirenburg and Raskin 
2002, Ch. 1, and references there). 
In the past, all the above tasks, if at all 
attempted, were supported by either keyword-
based search technology or through stochastic 
mechanisms of matching and determination of 
differences between two documents. These 
approaches have approached the ceiling of their 
capabilities. 
An ontology provides a new, content-oriented, 
knowledge- and meaning-based approach to 
form the basis of the NLP component of the 
information security research paradigm. The 
difference between this knowledge-based 
approach and the old ?expert system? approach 
is that the former concentrates on feasibility, for 
example, by using a gradual automation 
approach to various application tasks. The 
ontological approach also deals, albeit at a much 
more sophisticated level, with encoding and 
using the community know-how for automatic 
training and decision support systems. The 
cumulative knowledge of the information 
security community about the classification of 
threats, their prevention and about defense 
against computer attacks should be formalized, 
and this knowledge must be brought to bear in 
developing an industry-wide, constantly 
upgradeable manual for computer security 
personnel that may involve a number of delivery 
vehicles, including an online question-answer 
environment and a knowledge-based decision 
support system with dynamic replanning 
capabilities for use by computer security 
personnel. The underlying knowledge for both 
of these avenues of information security 
paradigm extension can, as it happens, be 
formulated in a single standard format. The 
knowledge content will readily enjoy dual use in 
both NL data inclusion and decision support, 
and it is made possible through the use of 
ontologies. Fig. 1 below shows a generic scheme 
of interaction of the ontological resources 
applied to a conceptual domain, such as 
Raskin et al?Page 5 
information security. The language-independent 
single ontology defines the content of most 
lexical entries in the lexicon and in the 
onomasticon (proper noun lexicon) of each NL. 
The fact database contains all the remembered 
event instances, and text meaning 
representations (TMR) are automatically 
generated for each text by the analyzer part of 
the processing system. The output, whether in 
NL or any other knowledge representation 
system, is produced by the generator from the 
TMRs. Some other static and dynamic resources 
are left out of the figure for simplification. 
 
Figure 1. Application of the Ontological 
Paradigm to a Domain (e.g., IAS) 
 
The attraction of using ontology, a conceptual 
structure for a domain of inquiry, is penetrating 
the IAS community only slightly more slowly 
than other disciplines. Since Raskin et al 2001 
and, especially, Raskin et al 2002, the prospect 
of having a tangled hierarchy, or a lattice, 
bringing together all the main concepts in IAS, 
with a convenient public Web interface has 
found considerable support. The most practical 
interest has so far been along the lines of 
standardizing the IAS terminology. Research-
wise, this is not the most challenging ontology-
related issue among the ones listed above but, as 
many IAS gatherings amply demonstrate, 
different terminological dialects confuse and 
slow down many professional discussions. Much 
more practically and damagingly, the non-
standard use of terms makes rapid responses to 
infections by CERT much more difficult 
because additional exchanges with the authors of 
reports are necessary to establish what is 
actually being reported. 
 
Ontological semantics can develop as many 
useful tools to support the common language 
project, the standardization initiative in the IAS 
community (see Howard and Meunier 2002), 
with Web-interfaced, public-access ontological-
semantic tools, as the implemented resources 
and their enhancements in this project will allow 
(e.g., dictionaries, both standard and dialectal; 
terminological ambiguity checker and corrector; 
mini-machine-translator from non-standard to 
standard usage). 
 
Starting with such more or less obvious 
overlapping points, NLP can be used to enhance 
and enrich the IAS agenda by making many less 
obvious applications work in the domain. At the 
same time, the ever-changing and increasingly 
complex real-life and contentful needs of IAS 
will place demands on NLP, stimulating and 
guiding its development. We believe that 
content-, not formalism-oriented NLP 
approaches, such as ontological semantics, 
rather than non-meaning-based and/or non-
representational approaches will be of most use 
to IAS. As in most fields populated by people 
trained in formalisms (and that includes both 
NLP and theoretical linguistics), there is a 
temptation to engage in a battle of formalisms to 
achieve maximum elegance, regardless of the 
formalized content?and, to add insult to injury, 
to be blissfully unaware of being not content-
oriented. In linguistics, the practical task that 
used to provide a check against pure formalism-
based approaches, the need to describe natural 
languages, has largely disappeared from the 
agenda. In NLP, there is more incentive to pay 
attention to content in contemporary 
applications, such as intelligent searches or 
question answering, than there was in MT, so 
the balance is changing in favor of content. In 
IAS, the practical task of preventing and 
countermanding hostile actions is fully 
dependent on understanding the content and 
goals of the actions, so the representation of 
meaning is a sine qua non of success, and this 
makes ontological semantics well suited for IAS 
applications. An ontological semanticist has the 
responsibility of identifying and sometimes 
discovering an IAS application of NLP 
Raskin et al?Page 6 
resources and of convincing the IAS community 
of the validity and importance of the application.  
 
5 Conclusion 
 
More and more interesting applications of NLP 
to IAS are being discovered, and the partial list 
above will be obsolete by the time this paper is 
presented. It is clear, therefore, that IAS is an 
important, enduring, and extremely well-funded 
field, whose needs NLP has every interest to 
serve and which will, therefore, determine, to an 
important extent, the development of NLP in the 
future. NLP, go for IAS! 
 
Acknowledgments 
 
The authors are grateful to CERIAS, with its 
pioneering multidisciplinary environment, and, 
especially, to its director, Eugene H. ?Spaf? 
Spafford, for his vision in continuing to 
encourage and to support  their work 
 
References 
 
Atallah, M., Raskin, V., Crogan, M., Hempelmann, 
C., Kerschbaum, F., Mohamed, D., and Naik, S. 
(2001). Natural language watermarking: Design, 
analysis, and a proof-of-concept implementation. 
In I. S. Moskowitz (ed.), ?Information Hiding: 4th 
International Workshop, IH 2001, Pittsburgh, PA, 
USA, April 2001 Proceedings?, I. S. Moskowitz, 
ed., Springer-Verlag, Berlin, pp. 185-199. 
Atallah, M., Raskin, V., Hempelmann, C., Karahan, 
M., Sion, R., Topkara, U., and Triezenberg, K. E. 
(2002). Natural language watermarking and 
tamperproofing. Submitted to ih2002: Information 
Hiding Workshop 2002. 
Howard, J. D., and Meunier, P. C. (2002). Using a 
?common language? for computer security 
incident information. In ?Computer Security 
Handbook, 4th ed.?, M. Kabay and S. Bosworth, 
eds.,  New York: Wiley. 
McDonough, C. J. (2000). Complex Events in an 
Ontological-Semantic Natural Language 
Processing System. An unpublished Ph.D. thesis, 
Purdue University, W. Lafayette, IN. 
Mohamed, D. (2001). Ontological Semantics 
Methods for Automatic Downgrading. An 
unpublished M. A. thesis, Purdue University, W. 
Lafayette, IN. 
Nijholt, A. (2002). Embodied agents: A new impetus 
to humor research. In: Stock et al, pp. 101-111. 
Nirenburg, S., and Raskin, V. (1998). Universal 
grammar and lexis for quick ramp-up of MT 
systems. In ?Proceedings of ACL/COLING ?98. 
Vol. 2?, Montreal: University of Montreal, pp. 
975-979 
Nirenburg, S., and Raskin, V. (2002). Ontological 
Semantics. Cambridge, MA: MIT Press 
(forthcoming). 
Raskin, V. (1996). Computer implementation of the 
general theory of verbal humor. In: ?Automatic 
Interpretation and Generation of Verbal Humor. 
International Workshop on Computational 
Humor, IWCH ?96. Twente Workshop on 
Language Technology, TWLT 12?, J. Hulstijn and 
A. Nijholt, eds., Enschede, NL: University of 
Twente, pp. 9-19. 
Raskin, V. (2002). Quo vadis computational humor. 
In: Stock et al 2002, pp. 31-46. 
Raskin, V., Atallah, M. J., McDonough, C. J., and 
Nirenburg, S. (2001). Natural language 
processing for information assurance and 
security: An overview and implementations. In 
?NSPW '00: Proceedings of  Workshop on New 
Paradigms in Information Security, Cork, Ireland, 
September 2000?, M. Shaeffer, ed., New York: 
ACM Press, pp. 51-65. 
Raskin, V., and Attardo, S. (1994). Non-literalness 
and non-bona-fide in Language: An approach to 
formal and computational treatments of humor. 
Pragmatics and Cognition 2/1, pp. 31-69. 
Raskin, V., Hempelmann, C. F., Triezenberg, K. E., 
and Nirenburg, S. (2002). Ontology in information 
security: A useful theoretical foundation and 
methodological tool. In ?Proceedings. New 
Security Paradigms Workshop 2001. September 
10th-13th, Cloudcroft, NM, USA?, V Raskin and 
C. F. Hempelmann, eds., New York: ACM Press, 
pp. 53-59. 
Stock, O., Strapparava, C., and Nijholt A., eds. 
(2002), Proceedings of The April Fools' Day 
Workshop on Computational Humour April 2002, 
Twente Workshop on Language Technology-
TWLT 20, An Initiative of HAHAcronym, 
European Project IST-2000-30039, Trento, Italy: 
ITC-irst. 
Stock, O., and Strapparava, C. (2002). Humorous 
agent for humorous acronyms: The HAHAcronym 
Project. In: Stock et al 2002, pp. 125-135. 
 
 
Raskin et al?Page 7 
The Genesis of a Script for Bankruptcy in Ontological Semantics
Victor
Raskin
1,3
Sergei
Nirenburg
2,3
Christian F.
Hempelmann
1
Inna
Nirenburg
3
Katrina E.
Triezenberg
1
1
CERIAS and Linguistics Program
Purdue University
West Lafayette, IN
vraskin, hempelma, kattriez@purdue.edu
2
ILIT
University of Maryland, Baltimore County
Baltimore, MD
sergei@cs.umbc.edu
3
Onyx Consulting, Inc.
iniren_99@yahoo.com
Abstract
This paper describes the creation of a script in
the framework of ontological semantics as the
formal representation of the complex event
BANKRUPTCY. This script for BANKRUPTCY
serves as the exemplary basis for a discussion
of the general motivations for including
scripts in NLP, as well as the discovery proc-
ess for, and format of, scripts for the purposes
of processing coreference and inferencing
which are required, for example, in high-end
Q&A and IE applications.
1 Introduction
A spate of advanced new applications has called for a
massive effort in script acquisition. Conceptualized as
complex events, they have been provided for in the on-
tology since its inception (see Carlson and Nirenburg,
1990) and their format has always been reasonably well-
defined as well as constantly adjusted to the consecutive
releases (see Nirenburg and Raskin, 2003, Section 7.1.5;
cf. Moreno Ortiz et al 2002). Throughout the early and
mid-1990s, however, lower-end NLP applications, such
as knowledge- and meaning-based MT, did not neces-
sitate a heavy use of scripts. The new generation of
higher-end Q&A and similar IE applications make it
necessary to recognize individual events and their ef-
fects as part of scripts, both because humans do and
because such recognition is necessary for establishing
(co)reference relations. Thus, in the following text, only
the availability of the BANKRUPTCY script can relate (i)
and (ii) (and thus determine whose bankruptcy it is in
the latter), which may be immediately adjacent in a text:
(i) ACME, Inc., was actually doomed the moment Jorge
Jimenez and 52 other employees were laid off without a
warning.
(ii) That bankruptcy was not, however, the last blow.
As an example, we will sketch out the creation proc-
ess of the BANKRUPTCY script. In Section 2, we will
describe the status of scripts in ontological semantics,
and in Section 3 the format of their representation. Sec-
tion 4 deals with the heuristics/discovery of the infor-
mation that goes into a script, a sort of knowledge
engineering, if you will. Section 5 presents the resulting
script BANKRUPTCY, formatted to a certain grain size of
the information discovered in Section 4. Section 6
touches briefly upon just a few of the problems script
acquisitions poses.
2 Scripts in Ontological Semantics
In order to represent the meaning of connected text, not
simply that of a sequence of ostensibly independent
sentences, several things must happen. One of the most
obvious connections across sentence boundaries is co-
reference. The TMR in ontological semantics allows for
the specification of co-reference, and special procedures
exist for treating at least facets of this phenomenon in
extant applications of ontological semantics (see Niren-
burg and Raskin, 2003, Section 8.6.1). Discourse rela-
tions among propositions can also hold across sentence
boundaries, and ontological semantics includes facilities
for both detecting and representing them as well (ibid,
Section 8.6.3).
There are, however, additional strong connections
among elements of many texts. These have to do with
the understanding that individual propositions may hold
well-defined places in ?routine,? ?typical? sequences of
events (often called complex events, scripts or scenar-
ios) that happen in the world, with a well-specified set
of object-like entities that appear in different roles
throughout that sequence. For example, if the sequence
of events describes a state visit, the ?actors? may, under
various circumstances, include the people who meet (the
?principals?), their handlers, security personnel and
journalists, possibly, a guard of honor; the ?props? may
include airplanes, airports, meeting spaces, documents,
etc. All these actors and props will fill case roles and
other properties in the typical component events of the
standard event sequence for a state visit, such as travel,
arrival, greetings, discussions, negotiations, press con-
ferences, joint statements, etc. The component events
are often optional; alternatively, some component
events stand in a disjunctive relation with some others
(that is, of several components only one may actually be
realized in a particular instantiation of the overall com-
plex event), and their relative temporal ordering may be
fuzzy.
Such typical scripts can be expressed in natural lan-
guage using expository texts or narratives, sets of the
above (indeed, one conceptual story can be ?gathered?
from several textual sources), plus text in tables, pic-
tures, TV and movie captions, etc. The notion of script
is clearly recursive, as every component event can itself
be considered a script, at a different level of granularity.
The notion of script, under a variety of monikers, was
popularized in computer science by Minsky (1975),
Schank and Abelson (1977), Charniak (1972), and their
colleagues in the 1970s. However, at that time, no real-
istic-size implementation of natural language processing
using scripts could be undertaken, in part, because there
was no clear idea about the required inventory of
knowledge sources, their relations and content. Script-
based theories of semantics were proposed in theoretical
linguistics (Fillmore 1985, Raskin 1986) but were over-
shadowed by the fashion for formal semantics, which is
not descriptive in nature, focusing instead on the ele-
ments of semantics capturable by such logical devices
as quantifiers (see Raskin 1994). Moreover, the size of
the task of creating the ontological semantic knowledge
sources, which are a sine qua non of script representa-
tion, was at the time underestimated by the practitioners
and overestimated by critics. It can be said that onto-
logical semantics is a descendant of the script-oriented
approach to natural language processing, especially in
the strategic sense of accentuating semantic content, that
is, the quantity and quality of stored knowledge required
for descriptions and applications. Ontological semantics
certainly transcends the purview and the granularity
levels of the older approach as well as offering an en-
tirely different take on coverage of world and language
knowledge and on its applicability. Ontological seman-
tics has also the advantage of having been implemented,
tested, and (constantly) improved in actual applications.
In the script-based approach to processing text in-
puts, the scripts in the ontology that get instantiated
from the text input provide expectations for processing
further sentences in a text. Indeed, if a sentence in a text
can be seen as instantiating a script in the nascent TMR,
the analysis and disambiguation of subsequent sentences
can be aided by the expectation that propositions con-
tained in them are instantiations of event types that are
listed as components of the activated script. Obviously,
the task of activating the appropriate script from the
input is far from straightforward. Also, not all sentences
and clauses in the input text necessarily fit a given
script?there can be deviations and fleeting extraneous
meanings that must be recognized as such and con-
nected to other elements of the TMR through regular
discourse relations, that is, through a weaker connection
than that among the elements of a complex event.
Scripts usually describe situations with multiple
agents. Each of these agents can be said, in some sense,
to carry out their own plans that are made manifest
through the reported component events in a script. Plans
are special kinds of scripts that describe the process of
attaining a goal by an agent or its proxies. Goals are
represented in ontological semantics as postconditions
(effects) of events (namely, steps in plans or compo-
nents of general scripts). For example, if an agent?s goal
is to own a TV set, this goal would be attained on a suc-
cessful completion of one of a number of possible plans.
In other words, it will be listed in the ontology as the
postcondition (effect) of such events as BUY, BORROW,
LEASE, STEAL, MANUFACTURE. Note that the plans can
be activated only if all the necessary preconditions for
their triggering hold. Thus, the ontology, in the precon-
dition property of BUY, for example, will list the re-
quirement that the agent must have enough money (see
McDonough 2000).
Manipulating plans and goals is especially important
in some applications of ontological semantics, for in-
stance, in advice giving applications where the system is
entrusted with recognizing the intentions (goals) of an
agent or a group of agents based on processing texts
about their behavior. Goal- and plan-directed processing
relies on the results of the analysis of textual input, as
recorded in the basic TMR, as well as the complemen-
tary knowledge about relevant (complex) events and
objects and their instances, stored in the ontology and
the Fact Database (see Nirenburg and Raskin, 2003,
Section 7.2), and instantiated in the extended TMR. It is
clear that reasoning based on the entire amount of
knowledge in the extended TMR can be much richer
than if only those facts mentioned in the input texts
were used for inference making. Richer possibilities for
reasoning would yield better results for any NLP appli-
cation, provided it is supplied with the requisite infer-
ence making programs, for instance, for resolving
translation mismatches. The reason we are making a
distinction among NLP applications is the extent to
which an application depends on such capabilities. For
example, MT practitioners have typically assumed that
this application does not really need machinery for in-
ference making. This belief is clearly based on the per-
ception that acquiring the knowledge necessary to
support reasoning is prohibitively expensive or even
outright infeasible, and therefore one must make do
with simpler approaches. Of course, should MT devel-
opers be able to obtain such resources, they would use
them. Ontological semantics has among its goals that of
supplying application builders with exactly this kind of
knowledge.
A good if unusual example for a family of applica-
tions for which knowledge representation at the level of
complex events is crucial but where its integration has
so far been carefully avoided is computational humor
(see, for instance, Raskin 1996; Stock and Strapparava
2002). Here, the analysis and generation of ambigu-
ity?generally the key issue for semantics, and, ac-
cordingly NLP?is a key requirement for a text to be
funny. Computational humor aims to increase the ac-
ceptability of natural language interaction between hu-
man and machine by injecting relevant humor into
natural language interfaces. The most developed theory
of humor?not only in the framework of script-based
semantics?and the formalized model based on it (At-
tardo and Raskin 1991) have at their core the notion of
incongruity conceptualized as two partially overlapping
scripts in a relation of opposition. Earlier attempts at
computational humor have simply hardwired two com-
plex events in such a relation into templates (Raskin and
Attardo 1994; Binsted and Ritchie 1997) instead of
aiming at true generation based on an operational model
of humor. And true humor generation is impossible
without the identification of scripts in an appropriate
relation of opposition, e.g., sexual vs. religious. On this
basis, the overlap between the two scripts can be ana-
lyzed and generated, for example, in puns, where one
lexical item from each of the two scripts are brought to
overlap in one surface form through sound similarity
(Hempelmann 2003). This is just an example?esoteric,
as it may seem to some?of how the set of script-
requiring NLP applications may expand with time and
need.
Obviously, as mentioned above, in addition to the
knowledge, efficient reasoning procedures must be de-
veloped. Such procedures must conform to a number of
constraints, an example of which is the following. It is
common knowledge that, unless a limit is imposed on
making inferences from knowledge units in rich knowl-
edge bases, the inferencing process can go too far or
even not halt at all. In advanced applications, for exam-
ple, advice giving again, a good candidate for such a
limit is deriving the active goals and plans of all rele-
vant agents in the world. However, even applications
that involve more or less direct treatment of basic text
meaning, such as MT, will benefit from making fewer
inferences. There will always be difficult cases, such as
the need to understand the causal relation in The sol-
diers fired at the women and I saw some of them fall to
select the correct reference for them?in Hebrew, for
example, the choice of the pronoun (the masculine otam
or the feminine otan will depend on the gender of the
antecedent). Such cases are not overly widespread, and
a prudent system would deliberately trigger the neces-
sary inferences when it recognizes that there is a need
for them. In general, any event is, in fact, complex, that
is, one can almost always find subevents of an event;
whether and to what extent it is necessary to represent it
as a script is a matter of grain size dictated by whether
an application needs this information for reasoning, and
that, in turn, is largely determined by the nature of the
corpora in the domain served by the application.
3 Format of Scripts
Scripts are represented in ontological semantics using
the ontological property HAS-PARTS. It has temporal
semantics if it appears in events, and spatial semantics if
it appears in physical objects, e.g., to indicate that an
automobile consists of an engine, wheels, the chassis,
etc. The properties PRECONDITION and EFFECT also carry
information necessary for various kinds of reasoning
and apply to any event, complex or otherwise. Scripts
require an extension to the specification format. The
reason for that is the need to bind the case roles and
other property values in component events to establish
co-reference. Also, the HAS-PARTS slot of scripts should
allow for the specification of rather advanced combina-
tions of component events. Therefore, the format of the
filler of HAS-PARTS in scripts should allow a) Boolean
operators and, or and not, as well as IF, THEN/ELSE and
b) loop statements. Scripts also need statements about
partial temporal ordering of their components. For this
purpose, a special new property, COMPONENT-
RELATIONS is introduced.
Component events in a script have a peculiar status.
They are not regular instances of concepts, as no instan-
tiation occurs in the ontology?instantiation is one of
the two main operations in generating TMRs, the other
being matching selectional restrictions in order to com-
bine individual concept instances?but their meaning is
different from that of the general concepts to which they
are related. Thus, asking questions in the context of a
class at school is clearly different from the general idea
of asking questions. In order to represent this difference,
the notion of ontological instance is introduced. In an
ontological instance, some properties are constrained
further as compared to their ?parent? concept. The con-
straints typically take the form of cross-reference to the
filler of another component event in the same script.
For reasons of clarity and convenience, instead of
describing the component events and component rela-
tions directly in the fillers of corresponding slots in the
concept specification for the complex event, we use the
device of reification by just naming them in a unique
way in that location (we identify ontological instances
by appending letters, not numbers as in the case of real
instances) and describe their content separately, at the
same level as the main script. As a result, the format of
the ontological description of a script is a set of onto-
logical concept frames.
Reification in ontological semantics is a mechanism
for allowing the definition of properties on properties by
elevating properties from the status of slots in frames to
the level of a free-standing concept frame. It is desirable
from the point of view of nonproliferation of elements
of metalanguage to avoid introducing a concept of, say
D R I V E R  if it could always be referred to as
DRIVE.AGENT. However, this brings about certain diffi-
culties. For example, if we want to state that somebody
is a driver of trucks, we would have to say that there is
an instance of DRIVE in which the THEME is TRUCK and
the AGENT is the person in question. There is no direct
relationship between THEME and AGENT, and it would
take a longer inference chain to realize that TRUCK is, in
fact, the value of a property of DRIVER, too, not only of
DRIVE. The more properties one would want to add to
DRIVER and not to DRIVE, the more enticing it would be
to reify the property DRIVE.AGENT and treat it as a sepa-
rate concept. In principle, we can use reification on the
fly, while building a TMR, when we need to add a
property to a property, which is prohibited in the static
knowledge sources such as the ontology and the lexi-
con. As we will see in the example below, reification
also facilitates the specification of scripts.
In the example below, we present a simplified view
of the script/complex event TEACH. As illustrated,
T E A C H  has as PRECONDITION two events?that the
teacher knows the material and the students do not; as
EFFECT, it has the event that the students (now) know
the material. The process of teaching is presented as
follows: the teacher presents the material to the stu-
dents, the students ask the teacher questions about this
material, and the teacher answers these questions. The
above is admittedly a gross simplification of the actual
state of affairs but will serve well for the purposes of
illustration.
The ontological instances introduced in the process
are: TEACH-KNOW-A, -B AND - C , TEACH-DESCRIBE,
TEACH-REQUEST-INFO, TEACH-ANSWER, TEACH-AFTER-A
AND -B. The constraints in these instances are all refer-
ences to fillers of slots in other components of the script
or the script itself. Reference is expressed using the tra-
ditional dot notation (m.s[.f] is read as ?the filler of the
[facet f of the] slot s of the frame m?). Ontological in-
stances are not indexed in the Fact Repository. They
appear in appropriate slots of scripts and their fillers are
all references to fillers of other ontological instances
within the same script or the script itself. They are
PART-OF (inverse of HAS-PARTS) of the script in which
they are listed but instance-of their corresponding basic
concept, that is, TEACH-DESCRIBE-A is the first ontologi-
cal instance of DESCRIBE that is at the same time PART-
OF TEACH.
teach
is-a value communicative-event
agent sem human
default teacher
theme sem knowledge
destination sem human
default student
precondition default (teach-know-a teach-know-b)
effect default teach-know-c
has-parts value (teach-describe
repeat (teach-request-information
teach-answer)
until teach-know-c)
component-relations 
value (teach-after-a teach-after-b)
component-modalities
value (teach-modality-a)
teach-know-a
instance-of value know
patient value teach.agent.sem
theme     value teach.theme.sem
teach-know-b
instance-of value know
patient value teach.destination.sem
theme      value teach.theme.sem
teach-modality-a
type value epistemic
scope value teach-know-b
value value 0
teach-know-c
instance-of value know
patient value teach.destination.sem
theme      value teach.theme.sem
teach-describe
instance-of value describe
agent       value teach.agent.sem
theme       value teach.theme.sem
destination value teach.destination.sem
teach-request-information
instance-of value request-information
agent       value teach.destination.sem
theme       value teach.theme.sem
destination value teach.agent.sem
teach-answer
instance-of value answer
agent      value teach.agent.sem
theme       value teach.request-information.theme.sem
destination value teach.destination.sem
teach-after-a
domain value teach-describe
range value teach-request-information
teach-after-b
domain value teach-request-information
range value teach-answer
4 Heuristics
As massive research on expert systems in the 1980s
abundantly demonstrated, knowledge engineering re-
quires human intelligence and stubbornly resists auto-
mation. Moreover, human intelligence must be devoted
to heuristics, another highly non-trivial intellectual
process. Deciding what goes into a script requires
knowledge engineering and heuristics. Part of the prob-
lem is similar to the task of extending the ontology to a
new domain?something the ontological semantics
community has had to face a number of times for vari-
ous applications, most recently for information security
applications (Raskin et al, 2002). There are three main
sources for obtaining and structuring the required in-
formation to chart out a new domain or to fill out a new
script:
? dictionaries, encyclopedias, thesauri;
? textbooks and reference books;
? pertinent corpora, most conveniently websites.
General common sense or a small sample of perti-
nent texts brings up a small number of apparently basic
terms. These terms are looked up in the first source, and
that leads to the second. A selection of key terms forms
the basis of an Internet search that brings up the cor-
pora. Thus, in the case of bankruptcy, the term itself
brings up an informative entry from Barron?s Finance
and Investment Handbook (1995).
?BANKRUPTCY State of insolvency of an individ-
ual or an organization?in other words, an inability to
pay debts. There are two kinds of legal bankruptcy un-
der U S. law: involuntary, when one or more creditors
petition to have a debtor judged insolvent by a court;
and voluntary, when the debtor brings the petition. In
both cases, the objective is an orderly and equitable
settlement of obligations.
The 1978 Bankruptcy Reform Act removed some of
the rigidities of the old law and permitted more flexibil-
ity in procedures. The Bankruptcy Reform, Act of 1984
curtailed some of the more liberal provisions (mainly
affecting consumer bankruptcy) of the 1978 act.
Chapter 7 of the 1978 act, dealing with
LIQUIDATION, provides for a court appointed interim
trustee with broad powers and discretion to make man-
agement changes, arrange unsecured financing, and
generally operate the debtor business in such a way as to
prevent loss. Only by filing an appropriate bond is the
debtor able to regain possession from the trustee.
Chapter 11, which deals with REORGANIZATION,
provides that, unless the court rules otherwise, the
debtor remains in possession of the business and in
control of its operation. Debtor and creditors are al-
lowed considerable flexibility in working together. The
1978 law relaxes the old absolute priority rule, which
gave creditor claims categorical precedence over owner-
ship claims. It also makes possible the negotiation of
payment schedules, the restructuring of debt, and even
the granting of loans by the creditor to the debtor.?
The entry, while somewhat cryptical, offers a pretty
good guide for what to look for in a textbook or in legal
sources. It can easily lead to a number of sources of the
textbook category, such as Summers (1989), Caplan
(1992), Davidson (1992). The pertinent information,
thus acquired, helps to identify the corpora, which
should be both essential for the domain and crucial for
the application(s), such as the various bankruptcy-
related pages at http://www.uslaw.com/. Just as in field
linguistics (cf. Samarin 1967), the corpora should be
varied, multi-sourced, and as representative/exhaustive
as possible. The corpora give us a good sense of the
grain size of the information to be included in the
script?see more on this in Section 6.
The most important step is to structure this informa-
tion in the script. Models of the script?s series of events
obtained at the previous stage and their key concepts
need to be checked against the ontology before the
scripting takes place, to avoid later, costly adaptation of
newly introduced concepts to the existing inventory.
The models will also tend to pay too much attention to
details from the field to which they belong. These de-
tails have to be weeded out and the parts of the models
to be united into the script have to be translated into
ontological concepts, existing and, if necessary, newly
acquired.
The methods for doing this are not easy to formulate
as recommendations, let alne rules. A similar situation
in lexical and ontological acquisition leads, with experi-
ence, to pretty well-established routines and, as a result
of adhering to them, quite good uniformity among dif-
ferent acquirers. Our work on routine acquisition of full-
fledged scripts has only been going on for slightly over
a year and has included only two domains so far, the
financial domain and the domain of meetings. We hope
to be able to make enough useful generalizations in the
style of Chapter 9 on acquisition of ontological concepts
and lexical entries in Nirenburg and Raskin (2003) as
we acquire more practical experience. The discovery of
heuristic rules remains a major challenge, possibly un-
attainable.
The following are the factors to be identified in the
script as concepts:
? the candidates for component events;
? the concepts involved in/created by the series of
events;
? the goals of the component events;
? their temporal and causal relations leading to
their groupings into subscripts;
? decision forks, such as whether to file Chapter 7
or Chapter 11 bankruptcies.
5 Formatted Script
The results of the operations described in Section 4 are
incorporated in the script for BANKRUPTCY below (for
legibility the FACET types SEM and VALUE are omitted in
this example):
BANKRUPTCY
is-a financial-event
agent owe.agent
owe.beneficiary
precondition approach-bankruptcy
has-parts (IF modality.pay.value = 0
THEN bankrupt-chapter-7
ELSE bankrupt-chapter-11)
APPROACH-BANKRUPTCY
is-a financial-event
agent corporation-a
has-parts
(IF
AND
owe
agent corporation-a
beneficiary human-a
employed-by corporation-a
lending-institution-a
corporation-b
theme money
pay
agent corporation-a
beneficiary human-a
lending-institution-a
corporation-b
theme money
THEN bankruptcy
agent corporation-a
beneficiary human-a
lending-institution-a
corporation-b)
PAY.MODALITY
type potential
scope pay
value <1
BANKRUPT.MODALITY
type epistemic
scope bankruptcy
value 0.6
BANKRUPT-CHAPTER-7
is-a financial-event
agent owe.agent
owe.beneficiary
precondition bankruptcy
has-parts (AND bankrupt.declare
bankrupt.business-activity
bankrupt.appoint
bankrupt.change-event
bankrupt.pay)
BANKRUPT-CHAPTER-11
is-a financial-event
agent owe.agent
owe.beneficiary
precondition bankruptcy
has-parts (AND bankrupt.declare
bankrupt.legal-case
bankrupt.audit
(IF modality.bankrupt.audit.value = 0
THEN bankrupt-appoint)
bankrupt.planning-event
bankrupt.follow-plan
(IF modality.pay.value = 0
THEN bankrupt-chapter-7
ELSE modality.pay.value = 1))
BANKRUPT.DECLARE
instance-of declare
agent owe.agent
owe.beneficiary
destination owe.agent
path judicial-branch
BANKRUPT.BUSINESS-ACTIVITY
instance-of business-activity
beneficiary owe.agent
BANKRUPT.BUSINESS-ACTIVITY.MODALITY
type epistemic
scope bankrupt.business-activity
value 0
BANKRUPT.AUDIT.MODALITY
type epiteuctic
scope bankrupt-audit
value ?
BANKRUPT.APPOINT
instance-of appoint
theme manager-corporation
beneficiary owe.agent
agent judicial-branch
BANKRUPT.CHANGE-EVENT
instance-of change-event
theme asset
destination money
agent manager-corporation
beneficiary owe.agent
BANKRUPT.PAY
instance-of pay
theme money
agent owe.agent
beneficiary owe.beneficiary
BANKRUPT.LEGAL-CASE
instance-of legal-case
theme money
agent human
beneficiary owe.agent
BANKRUPT.LEGAL-CASE.MODALITY
type epistemic
scope bankrupt.legal-case
value 0
BANKRUPT.AUDIT
instance-of audit
agent judicial-branch
beneficiary owe.agent
theme cash-flow
asset
debt
BANKRUPT.PLANNING-EVENT
instance-of planning-event
agent owe.agent
judicial-branch
BANKRUPT.FOLLOW-PLAN
instance-of follow-plan
agent owe.agent
6 Grain Size Issues
The script above, even though much more complex than
the script for TEACH is presented in its simplest and
probably coarsest form. The gain is parsimony, in the
sense of minimizing the need to acquire new lexical
entries or concepts. Are there losses? A text may men-
tion, for instance, a supplier?s refusal to ship stuff to the
bankrupt corporation. It does that because the corpora-
tion cannot pay it for the supplies. Can we consider it
covered in the script? What if a text mentions the in-
ability to meet the payroll? Meeting the payroll may
deserve a script of its own. It may be seen to be covered
sufficiently in the script above, but laying off employees
may not. To owe a loan is actually to owe an installment
payment on a certain date, and to be unable to pay the
loan means, actually, the inability to pay an installment
payment of the loan on a certain date. The script above
also omits the entire credit ratings game.
The rationale for having the scripts is, not surpris-
ingly, to do what Schank declared his group would do a
quarter of a century ago (Schank, 1975; Schank and
Abelson, 1977) and, unlike them, to deliver a workable
non-toy product, in which the whole script is evoked
when any element of it at any level of the script hierar-
chy occurs lexically in the text. The simplistic repre-
sentation above obligates our analyzer to reduce any
such pertinent lexical material to the level of owing and
paying. Is it possible? The alternative is to develop
much more elaborate scripts, involving a great deal
more of ontological acquisition and change.
A more complex and more accurate level of repre-
sentation, with all the intermediate subsidiary scripts
embedded in other scripts as well as component simple
events enriched with precondition and effect (and, we
increasingly believe, goal values), will be much costlier,
so the question is whether the gain in analysis makes it
worthwhile. We expect this to be dictated by the needs
of the current and future applications as manifested in
their goals and the nature of the texts in the pertinent
corpora. But much more effort will have to be devoted
to developing more specific grain-size recommenda-
tions, rules of thumb and repair/recovery procedures for
cases when the grain size of the script is not sufficient to
handle a text.
References:
Attardo, S., and V. Raskin 1991. Script theory re-
vis(it)ed. Joke similarity and joke representation
model. HUMOR 4:3-4, 293-347.
Barron?s Finance and Investment Handbook, 1995. 4th
ed., ed. by J. Downes and J. E. Goodman. New York:
Barron?s.
Binsted, K. and G. Ritchie 1997. Computational rules
for generating punning riddles. HUMOR 10:1, 25-76.
Caplan, S. 1992. Saving Your Business: How to Survive
Chapter 11 Bankruptcy and Successfully Reorganize
Your Company. Englewood Cliffs, NJ: Prentice Hall
Carlson, L., and S. Nirenburg 1990. World Modeling
for NLP. Technical Report CMU-CMT-90-121,
Center for Machine Translation, Carnegie Mellon
University, Pittsburgh, PA. A short version appeared
in: Proceedings of the 3rd Conference on Applied
Natural Language Processing, Trento, Italy, April.
Charniak, E. 1972. Toward a Model of Children's Story
Comprehension. Artificial Intelligence Technical Re-
port Number 266, Department of Computer Science,
Massachusetts Institute of Technology, Cambridge,
MA, December.
Davidson, R. L. 1992. The Small Business Bankruptcy
Kit. New York: Wiley.
Fillmore, C. J. 1985. Frames and the Semantics of Un-
derstanding. In: V. Raskin (ed.), Round Table Dis-
cussion on Frame/Script Semantics, Part I, Quaderni
di Semantica VI: 2, 222-254.
Hempelmann, C. F. 2003. Paronomasic Puns: Target
Recoverability towards Automatic Generation. Un-
published Ph.D. thesis, Interdepartmental Program in
Linguistics, Purdue University, West Lafayette, IN.
McDonough, C. J. 2000. Complex Events in an On-
tologic-Semantic Natural Language Processing Sys-
tem.  Unpublished Ph.D. thesis, Department of
English, Purdue University, West Lafayette, IN.
Minsky, M. 1975. A Framework for Representing
Knowledge. In: P. H. Winston (ed.), The Psychology
of Computer Vision. New York: McGraw Hill, 211-
77.
Moreno Ortiz, A., V. Raskin, and S. Nirenburg (2002)
New Developments in Ontological Semantics. In:
Proceedings of the Third International Conference
on Language Resources and Evaluation (LREC
2002). Las Palmas de Gran Canaria, Spain. May 29-
31, pp. 1196-1202.
Nirenburg, S., and V. Raskin 2003. Ontological Seman-
tics. Cambridge, MA: MIT Press (forthcoming).
Raskin, V. 1986. Script-Based Semantic Theory. In: D.
G. Ellis and W. A. Donohue (eds.), Contemporary Is-
sues in Language and Discourse Processes,
Hillsdale, NJ: Erlbaum, 23-61.
Raskin, V. 1994. Frawley: Linguistic Semantics. A Re-
view Article. Language 70: 3, 552-556.
Raskin, V. 1996. Computer Implementation of the Gen-
eral Theory of Humor. In: J. Hulstijn and A, Nijholt
(eds.), Automatic Interpretation and Generation of
Verbal Humor. Twente Workshop on Language
Technology TWLT 12, The Hague: CIP, 9-19.
Raskin, V., and S. Attardo 1994. Non-Literalness and
Non-Bona-Fide in Language: Approaches to Formal
and Computational Treatments of Humor. Cognition
and Pragmatics 2:1.
Raskin, V., C. F. Hempelmann, K. E. Triezenberg, and
S. Nirenburg 2002. Ontology in Information Secu-
rity: A Useful Theoretical Foundation and Methodo-
logical Tool. In: V. Raskin and C. F. Hempelmann
(eds.), Proceedings. New Security Paradigms Work-
shop 2001. September 10th-13th, Cloudcroft, NM,
USA, New York: ACM Press, 53-59.
Samarin, W. J. 1967. Field Linguistics. New York: Holt,
Rinehart and Winston.
Schank, R. 1975. Conceptual Information Processing.
Amsterdam: North-Holland.
Schank, R., and R. Abelson 1977. Scripts, Plans, Goals,
and Understanding. Hillsdale, NJ: Erlbaum.
Stock, O., and C. Strapparava 2002. Humorous Agents
for Humorous Acronyms: The HAHAcronym Pro-
ject. In: O. Stock, C. Strapparava, and A. Nijholt
(eds.) 2002. The April Fools? Day Workshop on
Computational Humor. April 2002, ITC-irst, Trento.
Twente Workshop on Language Technology TWLT
20. Trento: ITC-irst, 125-135.
Summers, M. 1989. Bankruptcy Explained, a Guide for
Businesses. New York: Wiley.
Semantic Forensics:
An Application of Ontological Semantics to Information Assurance
Victor Raskin, Christian F. Hempelmann, and Katrina E. Triezenberg
NLP Lab and CERIAS
Purdue University
{vraskin, hempelma, kattriez}@purdue.edu
Abstract
The paper deals with the latest application of
natural language processing (NLP), specifically of
ontological semantics (ONSE) to natural language
information assurance and security (NL IAS). It
demonstrates how the existing ideas, methods,
and resources of ontological semantics can be
applied to detect deception in NL text (and,
eventually, in data and other media as well). After
stating the problem, the paper proceeds to a brief
introduction to ONSE, followed by an equally
brief survey of our 5-year-old effort in
?colonizing? IAS. The main part of the paper
deals with the following issues:
? human deception detection abilities and NLP
modeling of it;
? manipulation of fact repositories for this
purpose beyond the current state of the art;
? acquisition of scripts for complex ontological
concepts;
? degrees of lying complexity and feasibility of
their automatic detection.
This is not a report on a system
implementation but rather an application-
establishing proof-of-concept effort based on the
algorithmic and machine-tractable recombination
and extension of the previously implemented
ONSE modules. The strength of the approach is
that it emphasizes the use of the existing NLP
applications, with very few domain- and goal-
specific adjustments, in a most promising and
growing new area of IAS. So, while clearly
dealing with a new application, the paper
addresses theoretical and methodological
extensions of ONSE, as defined currently, that
will be useful for other applications as well.
1 The Problem
The proposed application falls within the rapidly
growing domain of cyber forensics, and the
inclusion of NLP in it is a desirable and mutually
beneficial goal. Forensic science, in general,
encompasses any scientific discipline that is
concerned with the direct application of scientific
principles and theories to law enforcement
(Saferstein 2004), that is, the systematic search
for, discovery, and application of clues to event
reconstruction?for the purposes of justice. As
with any of the other traditional forensic sciences
(e.g., DNA, Serology, Latent Fingerprint Analysis
etc.) the development of the cyber forensics
Figure 1: Resources of Ontological Semantics
discipline is based on a sound scientific
foundation, compliance with legal requirements,
and a unified maturation process (Palmer 2002;
Rogers & Seigfried 2004; Whitcomb 2002). The
current foundation for cyber forensics is
multidisciplinary in nature and combines
established pure sciences (e.g., computer science,
math) and applied sciences (e.g., information
technology, engineering, and now NLP). Cyber
forensics is still in search of its theory and
methodology; NLP comes into it on strong and
explicit theoretical foundations (see Nirenburg
and Raskin 2004: 34-91).
As far as we know, no similar research has
been undertaken yet. The Patrick group at the
University of Sydney reported on a "bag-of-
words" system comparing the Nigerian e-mails
with Reuters' financial reports and concluding that
the presence of the personal pronouns I/me and
you in the former but not in the latter violates the
interpersonal relations of the register in the
former, thus leading to characterizing them as
scams (Herke-Couchman et al 2003; Whitelaw
and Argamon 2004). The difference in the
proposed approach is that it goes beyond treating
words as just character strings and represents their
meanings, as well as those of the sentences and of
their text, explicitly and manipulates them
logically, as it were, rather than statistically. The
result, typical for the comparison of
computational semantics with computational
statistics, is that a semantic forensics system is
capable of identifying specific facts/events that
contribute to the deception and of understanding
what those events are?the characterization of the
text as fraudulent comes then as a trivial side
effect. The Patrick approach can, however, be
used to assists semantic forensics by pre-
identifying some texts as suspicious cheaply and
thus reducing the general semantic forensics to a
more targeted and feasible task (see Section 6
below). Also, their ScamSeek Project has declared
an intention to move towards true meaning
features (http://www.cs.usyd.edu.au/~lkmrl/scam-
seek.htm).
Outside of NLP, the British-centered
linguistic forensics community (IAFL) has been
engaged in traditional largely qualitative stylistic
research in the spirit of the 1960s? text attribution,
an effort to break the anonymity of a text and to
identify its authorship for the purposes of law
enforcement (McMenamin 2002, Gibbons 2003,
Olsson 2004).
While other disciplines within cyber forensics
explore largely non-textual materials?and those
which look at texts, with the above-mentioned
exceptions. do not do so linguistically?semantic
forensics, as defined here, uses NLP to identify
the clues of deception in NL texts in order to
reconstruct the described events as they actually
occurred. Now, it can be argued, with reason, that
the truthful elements in NL texts are also clues for
event reconstruction and should be included in
semantic forensics, and, of course, in a way they
are. But those, if indeed truthful, do not come
under the task of reconstructing events; rather,
they establish the events. Besides, the truthful
elements of NL texts get the text meaning
representation (TMR) in the normal course of
events, so no special semantic forensic effort
needs to be developed with regard to them. This is
not set in concrete, however, because the
identification and exploration of deception clues
clearly involves the non-deceptive TMRs and
their fragments.
Semantic forensics is firmly based on ONSE,
and a semantic forensic analysis of the text
presupposes and follows the regular ONSE
process of automatic meaning representation of
each input sentence and, ultimately, the text. The
next section offers a brief introduction into the
ONSE process of meaning representation, with an
emphasis on analysis rather than generation and
with a bias towards IAS applications. It can be
largely skipped by those familiar with ONSE.
2 Ontological Semantics in Brief
ONSE contains several modules, with an ontology
at the center; the other important modules are
lexicons of languages and a fact repository, in
which information about the world is stored, and,
of course, the analyzer and generator. The
analytical goal of ONSE is to produce a TMR for
NL input as well as NL or other output for each
TMR (see figure 1).
PAY
definition value ?to compensate
somebody for goods
or services rendered?
is-a value EVERYDAY-
FINANCIAL-EVENT
subclasses value PAY-TAX
SUBSCRIBE-TO
agent sem HUMAN
relaxable-to ORGANIZATION
theme default MONEY
sem COMMODITY
relaxable-to EVENT
patient sem HUMAN
relaxable-to ORGANIZATION
Figure 2: Ontological Concept PAY
The ontology is a tangled hierarchy (lattice)
of concepts, beginning at the root ALL, branching
into OBJECT, EVENT, and PROPERTY, and so forth.
Each node of the hierarchy is a concept with a set
of properties, many of which are inherited from
its ancestors, and at least one property other than
the IS-A property is distinguished from its parent
node as well as from its sibling nodes. The
ontological concept for PAY might therefore look
like figure 2 (cf. Nirenburg and Raskin 2004:
196ff.).
As we see, the IS-A and SUBCLASSES slots are
filled with other ontological concepts, as are
AGENT, THEME, and PATIENT, the case-role slots.
VALUE, SEM, RELAXABLE-TO and DEFAULT are all
facets of their slots.
good-adj1
cat adj
SYN-STRUC
1 root $var1
cat n
mods root good
2 root $var0
cat adj
subj root $var1
cat n
SEM-STRUC
modality type evaluative
value value >0.75
relaxable-to >0.6
scope ^$var1
attributed-to *speaker*
Figure 3: Lexical Entry for ?good?
Lexicons contain the actual words of a
language, in contrast to the ontology?s universal,
language-independent concepts. The entry for
each word in the lexicon contains all possible
senses of that word, labeled with a part of speech
and a sense number. The lexical entry for the
English word p a y  contains three senses,
respectively pay-n1, pay-n2, and pay-v1. Each of
the senses is then assigned, most importantly, the
information about the acceptable syntactic
environments for the sense, or SYN-STRUC, and
information about the word?s meaning, or SEM-
STRUC. It is in SEM-STRUC that each lexical item
is linked to one or more ontological concepts, or
to literals. The lexical entry for the English
adjective good looks something like figure 3.
When a text is fed into the ONSE system, its
lexical items are identified, as well as several
TMR parameters, such as discourse relations
including modalities, aspect, information about
ordering and duration in time, style, and sets of
concepts working together. The first step in
building a TMR is finding meanings for heads of
clauses in the syntactic representation of input,
which are most commonly verbs. The TMR,
however, will typically end up containing more
event instances than there are verbs in the original
text. After identifying these events, building the
TMR is a (non-trivial) matter of fitting all the
other information of the text into the filler slots of
the events and the additional parameters. In figure
4 are the much-simplified TMRs for three related
sentences, which demonstrate how small changes
in texts affect TMRs.
Who won the match?
win-1
theme value sports-match-2
request-information-1
theme value win-1.agent
Did Arsenal win the match?
win-1
agent value Arsenal
theme value sports-match-1
request-information-1
theme value win-1
Was it Arsenal who won the match?
win-1
agent value Arsenal
theme value sports-match-1
request-information-1
theme value win-1
modality-1
type salience
scope win-1.theme
value 1
Figure 4: TMR Example
The next section reviews the NL IAS
applications discovered and explored?from
initial steps to pilot implementations?in the
ongoing effort to export NLP into computer and
information security.
3  Applications of NLP to Information
Assurance and Security
In the last 5 years, a CERIAS-based team led by a
computer scientist and an NLP expert has steadily
expanded its groundbreaking effort in improving,
focusing, and strengthening information assurance
and security by applying the NLP resources to
them. The result has been a growing number of
applications, some of them NL counterparts of
pre-existing applications, others NL extensions
and developments of known applications, and still
others unique to NL IAS. In the most
implemented one, NL watermarking (see Atallah
et al 2002), a sophisticated mathematical
procedure, based on a secret large prime number,
selects certain sentences in a text for watermark
bearing and transforms their TMRs into bitstrings
that contribute up to 4 bits per sentence to the
watermark. The goal of the software is, of course,
to embed a robust watermark in the hidden
semantic meaning of NL text, represented as its
TMR in tree structure. The NLP role is to
?torture? the TMR tree of the sentence, whose
contributing bits do not fit the watermark, so that
they do. The tool for that is a number of
minuscule TMR tree transformations, resulting in
such surface changes as The coalition forces
bombed Kabul ?  The coalition forces bombed
the capital of Afghanistan. The applications are
summarized in table 1.
4  Human Deception Detection and Its
NLP Modeling
Like all NLP systems, a Semantic Forensic (SF)
NLP system models a human faculty. In this case,
it is the human ability to detect deception (DD),
i.e., to know when they are being lied to and to
attempt to reconstruct the truth. The former ability
is a highly desirable but, interestingly, not
necessary precondition for DD (see an
explanation below, in the Feasibility section). The
latter functionality is the ultimate goal of SF NLP
but, like all full automation in NLP, it may not be
easily attainable.
Humans detect lying by analyzing meaning of
what they hear or read and compare that meaning
to other parts of the same discourse, to their
previously set expectations, and to their
knowledge of the world. Perhaps the easiest lie to
detect is a direct contradiction: If one hears first
that John is in Barcelona today and then that he is
not, one should suspect that one of the two
statements is incorrect and to investigate?if one
is interested, a crucial point. The harder type of
deception to perceive is by omission: The first
author was pushed into SF after having read a
detailed profile of Howard Dean, then a leading
contender for the Democratic nomination in the
US 2004 presidential election, and noticed that the
occupation of every single adult mentioned in the
article was indicated with the exception of the
candidate?s father, who had been a stockbroker.
Glossing over, such as saying that one has not had
much opportunity to talk to John lately, which
may be technically true, while covering up a
major fallout with John, is yet more complicated.
And perhaps topping the hierarchy is lying by
telling the truth: when a loyal secretary tells the
boss? jealous wife that her husband is not in the
office because he is running errands downtown,
she may well be telling the truth (though not the
whole truth?but, realistically, can one tell the
whole truth ever??is it even a useful notion,
especially given the fact that language
underdetermines reality (cf. Barwise and Perry
1983)); but what she wants to accomplish is for
the wife to infer, incorrectly, that this is all the
boss is doing downtown. It is the latter,
linguistically interesting type that was the focus of
Raskin (1987).
Application Function Implementation Reference
Mnemonic String Generator Generates jingles corresponding to
random-generated passwords
Pilot Raskin et al
2001a
Syntactic NL Watermarking Embeds the watermark in the syntactic
tree of a sentence
Pilot/demo Atallah et al
2001
Semantic NL Watermarking Embeds the watermark in the TMR tree
of a sentence
Pilot Atallah et al
2002
NL Tamperproofing Embeds a brittle watermark to detect any
changes to the text
Pilot Atallah et al
2002
NL Sanitization Seamlessly removes and replaces
sensitive information
Proof of concept Mohamed
2001
Automatic Terminology
Standardizer
Translates different terminological
dialects in IAS into TMRs
Proof of concept Raskin et al
2002a
Perimeter Protection Sanitizes outgoing e-mail online Proof of concept Raskin et al
2001b
NL Streaming Processor Interprets incoming information before it
is complete
Research Raskin et al
2002b
NL Steganalysis Detects the presence of a hidden
message
Research Raskin et al
2002b
Semantic Mimicking Creates a meaningful cohesive text to
hide a secret message
Research Bennett 2003
Web Crawler for Planned
Attacks
Crawls the web in search of credible
information on computer attacks
Research Raskin et al
2002b
Ontological support for Non-NL
data
Helps to classify incoming strings in a
computer attack
Initial Research Raskin 2004
Table 1: NL IAS Applications
A new TMR contradicting a previously
processed one should lead to a fact repository
flag, and this is where we are moving next.
5  Using the Fact Repository for
Deception Detection
The fact repository (FR?see Nirenburg and
Raskin 2004: 350-1), so far the least developed
static resource in ONSE, records the remembered
event instances. In principle, it should record all
of them. Realistically, it records them selectively
to suit the needs of an implementation. Thus, in
CRESP, a small QA system for queries about the
2000 Olympics in Sydney, the FR remembered all
the nations, all the participants, all the competitive
events, and all the results. A SF NLP system may
start at the same level of prominence (and detect
one?s lie about having participated in the Games
and/or achieved a better result), but like almost all
NLP systems with reasoning abilities, it will be
only as powerful as its FR allows.
A contradiction will be flagged when two
TMR (fragments) are discovered: For example,
one having been just processed for J o h n
is/was/will be in Barcelona at noon on the 25
th
 (of
July 2004) and the other in the FR for John
is/was/will be in Valencia at noon on the 25
th
 (of
July 2004)?or their paraphrases (see figure 5).
human-17
name John-23
location Barcelona
time noon, July 25, 2004
human-89
name John-23
location Valencia
time noon, July 25, 2004
Figure 5: Fact Repository Sample Entries
In the case of Papa Dean?s occupation,
apparently too shameful for the reporter to
mention even after he had divulged the Park
Avenue childhood, hereditary Republicanism, and
discriminatory country club and even though there
are still a few stockbrokers on this side of the
bars, the FR will easily detect it by presenting this
information, very simplistically, as in figure 6.
To detect a gloss-over, it is not quite enough
to receive a new TMR which contains an event
involving a different interaction between these
two individuals at the same time. The co-
reference microtheory (see Nirenburg and Raskin
2004: 301-5) will have to be able to determine or
at least to suspect that these events are indeed one
and the same event rather than two consecutive or
even parallel events. Even the time parameters are
not a trivial task to equate, as in the case of I have
not much opportunity to talk to John lately and
John insulted me last May. It would be trivial, of
course, if the temporal adverbials were since that
night at Maude?s and that night at Maude?s,
respectively, but a human sleuth does not get such
incredibly easy clues most of the time and has to
operate on crude proximity and hypothesizing.
Also helping him or her is a powerful inferencing
engine, obviously a must for an NLP system of
any reasonable complexity, reinforced by a
microtheory of euphemisms, which must contain
representative sets of event types that people lie
about and of fossilized, clich?-like ways of lying
about them, as in How is this paper??Well? it?s
different!
human-1
name Howard Dean
age adult
occupation physician
human-2
name Judy Dean
age adult
occupation physician
human-3
name Papa Dean
age adult (very: rather dead, actually)
occupation unknown
Figure 6: Fact Repository Sample Entries
The reason we think that the loyal secretary?s
type of lying is harder to detect is not because it
may involve more inferencing of a more complex
kind?this is not necessarily so. It has to do with
the notion of the whole truth: It is not realistic to
expect a human, let alne an SF NLP to suspect
any information to be incomplete and subject
every single TMR to the ?and what else did he do
downtown? type of query. But, in many cases, this
is necessary to do, which brings up the useful
distinction between general and targeted SF.
6  Feasibility of Semantic Forensic
Systems
A general SF (GSF) task is, basically, a fishing
expedition. An SF NLP system may indeed
expose obvious contradictions and many
omissions. It is a long and expensive process,
however, definitely overloading the system?s FR.
Inferring from every established contradiction or
omission, while possibly valuable forensically, is
an unaffordable luxury in this kind of task. It may,
however, be a necessary evil: for instance, if an
SF NLP system is to address a source that is
known to be tainted or if it to be used to classify
texts by the degree of their trustworthiness?quite
a possible assignment.
Humans do a degree of general SF under
similar circumstances. But even in an exchange
without a prior agenda, such as a conversation
with a stranger under neutral, casual, indifferent
circumstances, the SF/DD module may not be
activated unless flagged by, again, a
contradiction, an omission, etc. And such a flag
will transform general SF into targeted SF (TSF).
Now, TSF is what professional forensics does
for a living, and there is no reason why the entry-
level SF NLP systems should not be all TSF.
Even in the case of the Dean text, a TSF system
(?look for anything compromising in the
candidate?s background?) will be able to detect
the occupation omission much faster. A TSF is
simpler and cheaper, and the FR use is much more
reasonable and manageable: it can store only very
selective, limited material. The flip side of a TSF
system is the easy ability to overlook highly
related information an inference away, so we have
reasons to suspect that a quality TSF NLP system
is not that much simpler than, say, a limited
domain GSF system.
What is important to realize is that some NLP
systems with SF capabilities are within reach in
ONSE, using the already available resources,
possibly with some modifications, primarily if not
entirely on the static side, and that is not much
different than changing domains for a ?regular?
NLP system (see Raskin et al 2002b).
7  Using Scripts of Complex Events for
Deception Detection
A main tool for DD, in particular TSF, is the
expansion of the ontology by acquiring scripts of
complex events, already found necessary for other
higher-end NLP tasks (see Raskin et al 2003).
There are strong connections among elements
of many texts. These have to do with the
understanding that individual propositions may
hold well-defined places in ?routine,? ?typical?
sequences of events (often called complex events,
scripts or scenarios) that happen in the world,
with a well-specified set of object-like entities
that appear in different roles throughout that
sequence. A script captures the entities of such an
event and their temporal and causal sequences, as
shown for the complex event BANKRUPTCY in
figure 7.
As a general tool in ONSE, the scripts that get
instantiated from the text input provide
expectations for processing further sentences in a
text. Indeed, if a sentence in a text can be seen as
instantiating a script in the nascent TMR, the
analysis and disambiguation of subsequent
sentences can be aided by the expectation that
propositions contained in them are instantiations
of event types that are listed as components of the
activated script.
BANKRUPTCY
is-a financial-event
agent corporation-1
human-1
lending-institution-1
corporation-2
human-2
precondition approach-bankruptcy
has-parts (IF
AND
modality.scope = pay
modality.value < .5
THEN bankruptcy-chapter-7
ELSE bankruptcy-chapter-11)
BANKRUPTCY-APPROACH-STATE
is-a financial-event
agent bankruptcy.agent
destination bankruptcy
agent bankruptcy.agent
has-parts
(IF
AND
owe
agent corporation-1
human-1
beneficiary human-2
employed-by    corporation-1
lending-institution-2
corporation-2
theme money
pay
agent corporation-1
human-1
beneficiary human-2
lending-institution-1
corporation-2
theme money
THEN bankruptcy
agent corporation-1
human-1
CONCEAL
is-a sales-event
agent bankruptcy.agent
theme assets
owned-by bankruptcy.agent
precondition bankruptcy
agent bankruptcy.agent
time.sales-event  ?  time.bankruptcy-approach-state
Figure 7: Simplified Fragments of Scripts in the
BANKRUPTCY Domain
In addition, the expectations that scripts
provide play a crucial role for DD, namely in the
detection of omission, in two complementary
ways.
The more obvious one is the need for an
expectation of what information is to be found in
a text in order to be able to infer gaps. A common
attempt at deception in bankruptcy cases, for
example, is concealment of pre-bankruptcy
conversions of property from creditors, which is a
major factor considered by the courts in
determining whether there was an intent to hinder,
delay or defraud in a bankruptcy. Thus, if a sale of
assets by a company prior to its filing bankruptcy
is found in a text and there is no mention of how
closely to the filing this conversion took place,
this needs to raise a flag that possibly
concealment took place. This can be established
since CONCEALMENT is defined as part of the
script BANKRUPTCY, which is instantiated for the
TMR of the text. If it can be established, from the
text itself or the FR, that the sale of the assets took
place while the company was approaching the
state of bankruptcy, the omission of the specific
time of sale in the report constitutes deception.
Here, the script facilitates the targeting of SF (see
previous section) by mapping where omissions in
the text point to the omission of crucial
information.
The second mechanism by which scripts
facilitate DD is when an event that occurs
commonly or exclusively as a subevent of a
script, which is otherwise not mentioned, is found
in a text. Here, the inference should be that the
larger context of this subevent, captured by the
script, is to be concealed. If, for example, a
company issues a report that mentions the layoff
of some of its employees, this should lead to the
inference that it approaches the state of
bankruptcy, for which layoffs are a possible
subevent.
Simplified to a few subevents, these two
DD mechanisms on the basis of scripts can be
summarized as follows (cf. figure 8): 1. If a
necessary element of a script is missing it is likely
to be intentionally omitted. 2. If an element that
commonly occurs as part of a script is found in a
text, but no other element of it, that is, the script is
underinstantiated, the script is likely to be
intentionally omitted.
SCRIPT
has-part
AND
event-1 found in text
event-2 found in text
event-3 not found in text
event-4 found in text
SCRIPT
has-part
AND
event-1 not found in text
event-2 not found in text
event-3 found in text
event-4 not found in text
Figure 8: Simplified Script Structures
8 Conclusion
The main thrust of the paper has been not so much
the establishment of a sexy application as to
demonstrate that the rich resources of NLP, in
general, and ONSE, in particular, are versatile
enough to be extended to interesting new uses and
that getting there involves theoretical and
methodological developments that are generally
good for the field rather than just for SF (e.g.,
who will refuse a microtheory of euphemisms?).
Throughout, we have insinuated, ever so subtly,
that the tasks in hand are not manageable by any
of the past or current meaning-avoiding, non-
representational approaches. This is not to say that
a good SF NLP system must be statistics-free:
Crude measures are good to have for heuristic and
other startup purposes?but it is TMR elements
that such statistics will be counting. We have left
out many aspects of SF, such as potential demand,
which is great, and other practical considerations.
As resources permit, we have been moving
consistently to enrich our ONSE resources with
IAS capabilities and functionalities, and SF is the
latest but, very probably, not the last of those.
9 Acknowledgments
We are grateful to the two anonymous referees for
their thought-provoking remarks. We appreciate
Professor Jon Patrick?s unsolicited comments as
well as his making two hard-to-access papers
from his research group available to us. We have
profited greatly from the cooperation with our
CERIAS colleagues and from the Center?s
support for the NL IAS endeavors over the last 5
years.
10 References
Atallah, M. J., V. Raskin, M. Crogan, C. F.
Hempelmann, F. Kerschbaum, D. Mohamed,
and S. Naik. 2001. Natural Language
Watermarking: Design, Analysis, and a Proof-
of-Concept Implementation. In: I. S.
Moskowitz (ed.), Information Hiding: 4th
International Workshop, IH 2001, Pittsburgh,
PA, USA, April 2001 Proceedings. Berlin:
Springer, 185-199.
Atallah, M. J., V. Raskin, C. F. Hempelmann, M.
Karahan, R. Sion, U. Topkara, and K. E.
Triezenberg. 2002. Natural Language
Watermarking and Tamperproofing. In: F. A.
P. Petitcolas (ed.), Information Hiding: 5th
International Workshop, IH 2002,
Proceedings. Berlin: Springer, 196-210.
Barwise, J., and J. Perry. 1983. Situations and
Attitudes. Cambridge, MA: MIT Press.
Bennett, K. 2003. Semantic mimicking. CERIAS
TR (www.cerias.purdue.edu), Purdue
University, W. Lafayette, IN.
Herke-Couchman, M., C. Whitelaw, and J. Patrick
2003. Identifying interpersonal features using
systemic features, AAAI Symposium.
Gibbons, J. 2003. Forensic Linguistics: An
Introduction to Language in the Justice
System. Oxford: Blackwell.
McMenamin, G. R. 2002. Forensic Linguistics:
Advances in Forensic Stylistics. Boca Raton,
LA: CRC Press.
Mohamed, D. 2001. Ontological Semantics
Methods for Automatic Downgrading. An
unpublished Masters? thesis, Program in
Linguistics and CERIAS, Purdue University.
Nirenburg, S. and V. Raskin. 2004. Ontological
Semantics. Cambridge, MA: MIT Press
(forthcoming).
Olsson, J. 2004. Forensic Linguistics: An
Introduction to Language, Crime and the
Law. London-New York: Continuum.
Palmer, G. 2002. Forensic analysis in a digital
world. International Journal of Digital
Evidence, Spring 2002, 1.
Raskin, V. 1987. The semantics of lying. In: R.
Crespo, B. D. Smith, and H. Schultinik (eds.),
Aspects of  Language: Studies in Honour of
Mario Alinei, Vol. II. Theoretical and Applied
Semantics. Amsterdam: Rodopi, 443-469.
Raskin, V. 2004. Natural Language Information
Assurance and Security. Tutorial, COLING
2004, Geneva, Switzerland. August 22.
Raskin, V., M. J. Atallah, C. J. McDonough, and
S. Nirenburg. 2001a. Natural Language
Processing for Information Assurance and
Security: An Overview and Implementations.
In: M. Schaefer (ed.), Proceedings. New
Security Paradigm Workshop. September
18th-22nd, 2000, Ballycotton,  County Cork
Ireland. New York: ACM Press, 51-65.
Raskin, V., M. J. Atallah, C. F. Hempelmann, and
D. Mohamed. 2001b. Hybrid Data and Text
System for Downgrading Sensitive
Documents. CERIAS TR.
Raskin, V., C. F. Hempelmann, K. E.
Triezenberg, and S. Nirenburg. 2002a.
Ontology in information security: A useful
theoretical foundation and methodological
tool. In: V. Raskin & C. F. Hempelmann
(eds.), Proceedings. New Security Paradigms
Workshop 2001. September 10th-13th,
Cloudcroft, NM, USA, New York: ACM
Press, 53-59.
Raskin, V., S. Nirenburg, M. J. Atallah, C. F.
Hempelmann, and K. E. Triezenberg. 2002b.
Why NLP should move into IAS. In: Steven
Krauwer (ed.), Proceedings of the Workshop
on a Roadmap for Computational Linguistics,
Taipei, Taiwan: Academia Sinica, 2002, 1-7.
Raskin, V., S. Nirenburg, C. F. Hempelmann, I.
Nirenburg, K. E. Triezenberg. 2003. The
Genesis of a Script for Bankruptcy in
Ontological Semantics. Proceedings of the
HLT-NAACL 2003 Workshop on Text
Meaning. Available at:
http://acl.ldc.upenn.edu/W/W03/W03-
0905.pdf
Rogers, M. and K. Seigfried. 2004. The future of
computer forensics: A needs analysis survey.
Computers and Security, 23, 1, 12-16.
Saferstein, R. 2004. Criminalistics: An
introduction to forensic science.  New York:
Prentice Hall.
Whitcomb, C. 2002. A historical perspective of
digital evidence: A forensic scientist?s view.
International Journal of Digital Evidence,
Spring 2002, 1
Whitelaw, C., and Sh. Argamon 2004. Systemic
functional features in stylistic text
classification. Ms., Sydney Language
Technology Research Group, University of
Sydney, Sydney, Australia.
