Computing relative polarity
for textual inference
Rowan Nairn, Cleo Condoravdi, Lauri Karttunen
Palo Alto Research Center
rnairn@gmail.com , condorav@parc.com , Lauri.Karttunen@parc.com
Abstract
Semantic relations between main and complement sentences are of great signifi-
cance in any system of automatic data processing that depends on natural lan-
guage. In this paper we present a strategy for detecting author commitment to
the truth/falsity of complement clauses based on their syntactic type and on the
meaning of their embedding predicate. We show that the implications of a predi-
cate at an arbitrary depth of embedding about its complement clause depend on a
globally determined notion of relative polarity. We, moreover, observe that different
classes of complement-taking verbs have a different effect on the polarity of their
complement clauses and that this effect depends recursively on their own embed-
ding. A polarity propagation algorithm is presented as part of a general strategy of
canonicalization of linguistically-based representations, with a view to minimizing
the demands on the entailment and contradiction detection process.
1 Introduction
In a 1971 article titled ?The Logic of English Predicate Complement Con-
structions? [9] Lauri Karttunen, 29, wrote:
It is evident that logical relations between main sentences and their comple-
ments are of great significance in any system of automatic data processing
that depends on natural language. For this reason, the systematic study of
such relations, of which this paper is an example, will certainly have a great
practical value, in addition to what it may contribute to the theory of the
semantics of natural languages.
It is only now that this 35-year old prediction is becoming a reality in the
context of automated question answering and reasoning initiatives such as the
pascal Textual Entailment Challenge (see [7]) and the arda-sponsored aquaint
project (see [10], [12], [4]).
Recognizing whether a given piece of text can be strictly or plausibly in-
ferred from, or is contradicted by, another piece of text is, arguably, a minimal
criterion for Natural Language Understanding (see [2]). We call this task lo-
cal textual inference. Textual inferences may be based on purely linguistic
knowledge, assumptions about language use by collaborative rational agents,
knowledge about the world, or any combination thereof. The semantics of
complement constructions is an important part of local textual inference. It
has the added advantage of carving out a well-circumscribed domain of infer-
ences based primarily on linguistic knowledge.
A system that computes textual inferences should be able to deduce, for
example, that (1b) and (1c) follow from (1a).
(1) a. Ed forgot to close the door.
b. Ed intended to close the door.
c. Ed did not close the door.
There is a clear difference between the two embedding predicates forget to and
intend to. (1c) does not follow from (1b). A speaker or author of (1b) may well
believe in the truth of (1c) but he is not committed to it by virtue of having
said (1b). In the following we focus on cases where the author?s commitment
to the truth of a complement clause arises solely from the larger sentence it
belongs to, leaving aside other sources of information about the beliefs of the
author. The author of (1a) is committed to both (1b) and (1c) but due to
different aspects of the meaning of forget to, as we will show shortly.
The fact that forgetting to do something entails not doing it does not arise
solely from the meaning of the verb forget but depends also on the type of its
complement. Consider the difference between forget to and forget that.
(2) a. Ed forgot that the door was closed.
b. The door was closed.
(2a) commits the author to the view that the complement (2b) is true rather
than false. Furthermore, with forget that this commitment is preserved under
negation and in questions.
(3) a. Ed did not forget that the door was closed.
b. Did Ed forget that the door was closed?
(2a), (3a) and (3b) are alike in committing the speaker to (2b). The difference
between forget that and forget to is striking.
(4) a. Ed did not forget to close the door.
b. Did Ed forget to close the door?
In contrast to (1a), in a narrative text (4a) commits the author to the view
that Ed closed the door, the opposite of (1b). 1 (4b) is noncommittal either
way.
The different semantic behaviors of forget that and forget to have been
known for a long time. There is a large body of linguistic literature, start-
1 In a spoken dialogue it is of course possible, typically with a special intonation, to use
(4a) to contradict (1a): Ed didn?t ?forget? to close the door. He never intended to do it.
ing with Kiparsky & Kiparsky 1971 [11] and Karttunen 1971 [8], about fac-
tive constructions such as forget/remember/know/. . . that and implicative con-
structions such as forget/remember/manage/bother/. . . to. A common view is
that factive constructions presuppose rather than entail that the complement
sentence is true. 2 Implicative constructions have entailments and some of
them also carry presuppositions. For example, (1a) entails (1c) and presup-
poses (1b). (4a) carries the same presupposition as (1a) but the opposite
entailment. While the entailments of implicative constructions are generally
quite clear, it is often difficult to pin down exactly what is being presupposed.
It may be argued, for example, that (1b) is too specific. Maybe the presuppo-
sition is more vague: Ed ought to have closed the door or Ed was expected to
close the door. All the examples in (5) entail that Ed did not open the door
but presuppose a different reason for this fact.
(5) Ed didn?t manage/bother/dare/happen to open the door.
In this paper we focus on building a partial computational semantics for
implicative constructions ignoring for the time being the presuppositional as-
pects of their meaning. However, we handle simple factive constructions and
the interaction between implicative and factive verbs. The work was carried
out in the context of the aquaint project using the xle engine for parsing and
semantic analysis. 3 The aquaint project conducted a pascal-like experiment
on local textual inferences based on a more nuanced task. Given a sentence A,
we may conclude either that B is true or that B is false or that the answer
is unknown, that is, B or its negation cannot be inferred from A alone. In
contrast, the pascal test collapses false and unknown into false. 4
We faced two initial challenges. The first is that there are several types of
implicative verbs. Some yield an entailment in both affirmative and negative
environments but there are others, ?one-way implicatives?, that yield entail-
ments only in one or the other environment. Furthermore, the entailment may
be either positive or negative depending on the polarity of the environment.
For example, forget to yields a negative entailment in a positive environment,
(1a), and a positive entailment in a negative environment, (4a). But man-
age to works in the opposite way. This type of semantic information is not
available in or deducible from any public lexical database such as WordNet,
VerbNet or FrameNet. We had to compile ourselves a table of ?implication
signatures? for a large class of complement-taking constructions.
The second challenge is that implicative and factive constructions may be
stacked together. The polarity of the environment of an embedding predicate
is determined relatively to the chain of predicates or sentential operators it
is in the scope of. Although it may not be obvious at the first glance, (6)
2 This is not to say that there is a common view on how the notion of presupposition should
be construed theoretically.
3 http://www2.parc.com/istl/groups/nltt/xle/
4 For a critical look at the pascal task, see Zaenen, Karttunen and Crouch [12].
commits the author to the view that Ed did not open the door.
(6) Ed didn?t manage to remember to open the door.
In 6 remember is in a positive clause but the relative polarity of that clause
is negative. The computation of relative polarity must be a recursive process.
2 Implication signatures
We focused on complement-taking verbs, especially those that take infinitival
or that complements. Taking the verbs in order of decreasing frequency in the
British National Corpus (BNC), 5 we determined their natural implications
(if any). Judgments were based on agreement by multiple annotators using
resources such as Google search and the Linguist?s Search Engine to sample
the relevant constructions in the wild. In particular cases it can be difficult to
decide between entailments, that is, what the author is actually committed
to, and conversational implicatures, that is, what a reader/hearer may feel
entitled to infer. For example, Ed did not refuse to participate might lead the
hearer to conclude that Ed participated. But the speaker could continue with
He was not even eligible indicating the opposite. For this reason we classify
refuse to as a one-way implicative. Of the 1250 relevant verbs in our lexicon
we classified 400 on a first pass. Roughly a third of those carried some kind
of implication: a positive or negative entailment, a factive or a counterfactive
presupposition. Conversational implicatures were flagged for later attention.
Figure 1 shows the classifications of the resulting lookup table.
Word in Relative Polarity
subcat frame (+) positive (-) negative
Entailment
Two-way manage to (+) positive (-) negative
implicatives forget to (-) negative (+) positive
One-way force to (+) positive none
+implicatives refuse to (-) negative none
One-way attempt to none (-) negative
-implicatives hesitate to none (+) positive
Presupposition
Factives forget that (+) positive (+) positive
Counterfactives pretend that (-) negative (-) negative
Entailment/Presupposition
Neutral want to none none
Fig. 1. Some examples from our verb markup table
5 http://www.natcorp.ox.ac.uk/
3 Theoretical and technical prerequisites
Our approach to textual inference relies on parsed text that is further trans-
formed by a process of canonicalization. The mechanism for entailment and
contradiction detection (ecd) combines structural matching and inference-
based techniques. It operates on packed representations, encoding ambigui-
ties, without the need for disambiguation. We will not discuss ecd any further
here. Instead we will focus on describing in more detail some of the relevant
features of the representations on which it operates.
Input text is syntactically analyzed by the xle parser, based on a broad cov-
erage, hand-coded grammar of English. Linguistic semantic representations
are constructed from the parse output, using skolemization and flattening em-
bedded structures to clausal form. These logical forms are in turn canonical-
ized to more uniform representations via packed term rewriting as described in
Crouch [3]. The implication projection algorithm to be described in the next
section forms part of this component of canonicalization and is implemented
as a set of recursive rewrite rules that operate on packed representations. 6
The canonicalized representations that are input to ecd are essentially a
kind of description logic with contexts. 7 Roughly, each verbal predication
corresponds to a constructed concept, an event type with role restrictions.
The main concept is provided by a mapping of the verbal predicate to a
concept in some background ontology. The role restrictions come from various
arguments and modifiers. The constructed concept is named by the skolem
introduced by the verbal predicate. Flattening replaces embedded expressions
with complex internal structure, such as clausal complements, with atomic
first order terms, contexts. The information about the level of embedding of
an expression is preserved by associating its content with the corresponding
context. Negation and intensional operators also trigger the introduction of
new contexts. Contexts thus serve as scope markers since their use enables
globally represented information, such as the scope of operators, to be made
locally accessible.
The content of the top level context, designated as t, represents what the
author of the sentence is taken to be committed to. In general, we tie truth
of a sentence to the instantiability of the skolem corresponding to its head
predicate. This, in effect, amounts to the familiar existential closure over
events: if the skolem corresponding to a clause?s head predicate denotes an
event description, an instantiability declaration for that skolem means that the
event description is instantiated. Therefore, an implication that a complement
clause is true/false can be construed as an existential/negative existential
implication, which in our terms is an implication about the instantiation/non-
instantiation of the event type described by the embedded clause.
6 Packing is xle?s mechanism for ambiguity management and operates independently of
canonicalization and inference.
7 For more details see Bobrow et al [1], Crouch [3] and Condoravdi et al [2].
Instantiability is always relative to a context, in the simplest case the
context of origin of the skolem. In order to become author commitment, an
instantiability declaration has to be associated with the top level context t.
When two contexts stand in certain relations to one another, in particular
the relations of veridicality and antiveridicality, information can be inherited
from one to another. Lifting rules lift assertions from a lower context to a
higher context, either as they are, when the two contexts are veridical to one
another, or by switching the polarity of instantiability assertions, when the two
contexts stand in an antiveridical relation. Negation introduces a context that
is antiveridical with respect to the immediately higher context. To illustrate,
(7) gives the contextual structure for a negative sentence like Ed didn?t leave
Paris and (8) the corresponding instantiability assertions (leave ev57 is the
name for the constructed event type of Ed leaving Paris). One important thing
to note is that the assertion instantiable(leave ev57) in not58 is lifted as
uninstantiable(leave ev57) to the top level context t, thus capturing the
intuitive meaning that the event type of Ed leaving Paris was not instantiated.
(7) context(t)
context(not58) new context triggered by negation
context relation(not t not58)
antiveridical(not58 t) interpretation of negation
(8) not58: instantiable(leave ev57)
t: uninstantiable (leave ev57) entailment of negation
Lexical entailments and presuppositions are similarly overtly spelled out in
the representations operated on by ecd. This way the process of canonicaliza-
tion prepackages some of the local textual inferences. The challenge of course
is to figure out which context the relevant instantiability assertions ought to
be lifted to, which is what the implication projection algorithm determines.
4 The implication projection algorithm
Aside from the onerous task of classifying hundreds of verbs, the complica-
tions of this problem stem from the interaction of multiple embedded clauses.
As mentioned previously, the entailment yielded by a complement-taking con-
struction is dependent on the polarity of the context it appears in. This
polarity in turn is not locally determined but dependent on the embedding
structure of contexts. Therefore, a verb in a negative clause is not necessarily
in a negative environment since the negativity of a not may be neutralized by
another negative, as for example in (9).
(9) Ed refused not to attempt to leave.
Here the normal negative entailment licensed by not attempt is neutralized by
the negative polarity setting due to the higher-level predicate refuse. Notice
that refuse does not simply negate the entailment. It cancels it entirely. Em-
bedding within a verb such as refuse can also license entailments that were not
available previously. Consider (10a), which is compatible with either (10b) or
(10c).
(10) a. Ed attempted to leave.
b. Ed left.
c. Ed didn?t leave.
(11), on the other hand, implies (10c).
(11) Ed refused to attempt to leave.
Evidently, it is not enough to look at the immediate outer context of a
complement construction. The polarity of any context depends on the se-
quence of potential polarity switches stretching back to the top context. Each
complement-taking verb, operating on its parent context?s polarity, either
switches, preserves or simply sets the polarity for its embedded context, as
specified by an entry in the lookup table.
Furthermore, this means that polarity is a relative notion. If the sequence
of polarity switches was started at a level below the top context then the final
polarity value might turn out different. Thus when we talk about the polarity
of a context we mean polarity relative to some ancestor context. Normally, it
is the top context which interests us the most, but it may be useful to infer
the implications of a clause for other contexts. For example, it is probably
useful to infer (12b) from (12a). The algorithm provides for this generality.
(12) a. John believes that Ed managed to leave.
b. John believes that Ed left.
Every context C then has associated with it a set of ancestor contexts
relative to which its polarity is positive (denoted ?C) and a set of contexts
relative to which its polarity is negative (denoted 	C). Every context, includ-
ing the top one, is positive relative to itself. The polarity sets of a context
are computed in terms of its parent?s sets (?p(C) and 	p(C)) with reference to
the verb (Vp(C),C) which links the two contexts and its signature in the lookup
table (sige(Vp(C),C)) where the environment superscript e is either positive +
or negative ?.
?C =def {C} ?
?
?
?
?
?
?
?
?p(C) if sig+(Vp(C),C) = +
	p(C) if sig?(Vp(C),C) = +
? otherwise
	C =def
?
?
?
?
?
?
?
?p(C) if sig+(Vp(C),C) = ?
	p(C) if sig?(Vp(C),C) = ?
? otherwise
Figure 2 shows the example sentence Ed did not forget to force Dave to leave
parsed and with relative polarities assigned to each context. To get to this
Fig. 2. After the polarity propagation pass
situation the algorithm first assigns the top context the polarity sets {#Top}
and ?. It then recursively computes the polarity sets for each embedded
context using the context-linking verb as an index to the lookup table. Not
is treated in the same way as forget to ? they both invert the polarity sets.
Force is a one-way implicative that disregards the negative polarity set of its
parent.
Recall that we needed to work out which concepts should be instantiated in
which contexts and, now that we have marked the contexts appropriately with
relative polarities, we can extract that information. The head event skolem
of a context, and presumably all its role fillers, should be made instantiable
not only in the context it arises in but also in all contexts relative to which
its originating context has positive polarity. Similarly, an event should be
made uninstantiable in all contexts relative to which its originating context
has negative polarity.
instantiables(C) =def {head(C ?) | C ? ?C?}
uninstantiables(C) =def {head(C ?) | C ? 	C?}
From the polarity marking in Figure 2 we can conclude that the event concept
corresponding to the sentence Dave left is in fact instantiable at the top level
(as well as in the #Force and #Forget contexts) and thus we can attribute
it as a commitment of the speaker.
5 Conclusion and Further Work
The present study is, as far as we know, the first systematic implementation
of textual inferences arising from the six types of implicative verbs presented
in Figure 1 and their interaction with factive verbs.
In this work we have focused on cases where the judgement of whether the
author is committed to the truth or the falsity of a complement clause can be
made reliably from the sentence in question. Further work is needed at least
in the following three areas.
Lexicographic gaps. In our classification we only considered simple ver-
bal and adjectival complements. We have yet to study and determine the
semantics of complement constructions associated with nominals in colloca-
tions such as take the trouble to, have the foresight to, take time to, for which
there is virtually no literature.
Conversational implicatures. It is well known that constructions such
as be able to yield a negative entailment in a negative environment. Ed was not
able to open the door entails Ed did not open the door. There is no entailment
in the corresponding affirmative sentence. Yet, if the author writes Ed was
able to open the door and says nothing to indicate that the door was not
opened, the reader is likely to infer, and justifiably so, that Ed opened the
door. This kind of conversational implicature is cancelable (Grice [6]). It is
not a contradiction to say Ed was able to open the door but he kept it closed. If
a student asks his professor Did you have the time to read my paper? and the
professor answers Yes but has not read the paper, the answer can be literally
true and very misleading at the same time. 8
Degrees of ?factivity?. Factive verbs and constructions do not consti-
tute a uniform class. Looking at the pattern of usage of verbs such as mention
that, report that, say that, etc. on Google, we observed that in cases such as
He did not mention that Coalition allies now plan to leave it was virtually
always clear from the context that the author believed the complement to be
true. The verb report is similar to mention but there are also cases where
...did not report that X was meant to suggest that X is false. On the other
hand, ...did not deny that X suggests that X is true, whereas ...denied that X
is noncommittal with respect to X.
Acknowledgements
This material is based in part on work funded by the U.S. Government, and
any opinions, findings, conclusions, or recommendations expressed in this ma-
terial are those of the authors and do not necessarily reflect the views of the
U.S. Government.
8 For a seminal paper on invited inferences, see [5].
References
[1] Bobrow, D., C. Condoravdi, R. Crouch, R. Kaplan, L. Karttunen, T. King,
V. de Paiva and A. Zaenen, A basic logic for textual inference, in: Proceedings
of the AAAI Workshop on Inference for Textual Question Answering,
Pittsburgh, PA, 2005, http://www2.parc.com/istl/groups/nltt/papers/
textual-inference.pdf.
[2] Condoravdi, C., R. Crouch, R. Stolle, V. de Paiva and D. Bobrow, Entailment,
intensionality and text understanding, in: Proceedings of the Workshop on
Text Meaning, Human Language Technology Conference (HLT-NAACL-2003),
Edmonton, Canada, 2003, http://www2.parc.com/spl/members/stolle/
Papers/condoravdi-textmeaning.pdf.
[3] Crouch, R., Packed rewriting for mapping semantics to KR, in: Proceedings
of the Sixth International Workshop on Computational Semantics, Tilburg,
the Netherlands, 2005, http://www2.parc.com/istl/groups/nltt/papers/
iwcs05_crouch.pdf.
[4] Crouch, R., R. Sauri and A. Fowler, AQUAINT pilot knowledge-based
evaluation: Annotation guidelines (2005), http://www2.parc.com/istl/
groups/nltt/papers/aquaint_kb_pilot_evaluation_guide.pdf.
[5] Geis, M. and A. Zwicky, On invited inferences, Linguistic Inquiry 2 (1971),
pp. 561?565.
[6] Grice, H. P., Logic and conversation, in: P. Cole and J. L. Morgan, editors,
Speech Acts, Academic Press, New York, NY, 1989 pp. 41?58.
[7] Ido Dagan, O. G. and B. Magnini, The PASCAL recognising textual entailment
challenge, in: Proceedings of the PASCAL Challenges Workshop on Recognising
Textual Entailment, Southampton, U.K., 2005, http://www.cs.biu.ac.il/
~glikmao/rte05/dagan_et_al.pdf.
[8] Karttunen, L., Implicative verbs, Language 47 (1971), pp. 340?358.
[9] Karttunen, L., The logic of English predicate complement constructions (1971),
distributed by the Indiana University Linguistics Club. http://www2.parc.
com/istl/members/karttune/publications/english_predicate.pdf.
[10] Karttunen, L. and A. Zaenen, Veridicity, in: G. Katz, J. Pustejovsky and
F. Schilder, editors, Annotating, Extracting and Reasoning about Time and
Events, number 05151 in Dagstuhl Seminar Proceedings (2005), http://drops.
dagstuhl.de/opus/volltexte/2005/314.
[11] Kiparsky, P. and C. Kiparsky, Fact, in: D. Steinberg and L. Jakobovits,
editors, Semantics. An Inderdisciplinary Reader, Cambridge University Press,
Cambridge, England, 1971 .
[12] Zaenen, A., L. Karttunen and R. Crouch, Local textual inference: can it be
defined or circumscribed?, in: Workshop on the Empirical Modeling of Semantic
Equivalence and Entailment, Ann Arbor, MI, 2005, http://www2.parc.com/
istl/members/karttune/publications/acl2005workshop.pdf.
Proceedings of the Workshop on Textual Entailment and Paraphrasing, pages 16?21,
Prague, June 2007. c?2007 Association for Computational Linguistics
Precision-focused Textual Inference
D. G. Bobrow, C. Condoravdi, R. Crouch, V. de Paiva, L. Karttunen, T. H. King, R. Nairn, L. Price, A. Zaenen
Palo Alto Research Center
Abstract
This paper describes our system as used in
the RTE3 task. The system maps premise and
hypothesis pairs into an abstract knowledge
representation (AKR) and then performs en-
tailment and contradiction detection (ECD)
on the resulting AKRs. Two versions of ECD
were used in RTE3, one with strict ECD and
one with looser ECD.
1 Introduction
In the RTE textual entailment challenge, one is given
a source text T and a hypothesis H, and the task is to
decide whether H can be inferred from T. Our sys-
tem interprets inference in a strict way. Given the
knowledge of the language embedded in the system,
does the hypothesis logically follow from the infor-
mation embedded in the text? Thus we are empha-
sizing precision, particularly in question-answering.
This was reflected in our results in the RTE3 chal-
lenge. We responded correctly with YES to relatively
few of the examples, but on the QA-type examples,
we achieved 90-95% average precision.
The methodology employed is to use the linguis-
tic information to map T and H onto a logical form in
AKR, our Abstract Knowledge Representation. The
AKR is designed to capture the propositions the au-
thor of a statement is committed to. For the sake of
ECD, the representation of T may include elements
that are not directly expressed in the text. For ex-
ample, in the AKR of John bought a car includes the
fact that the car was sold. The AKR of John forgot to
buy milk includes the fact that John did not buy milk.
Our reasoning algorithm tries to determine whether
the AKR of H is subsumed by the AKR of T and detect
cases when they are in conflict.
The Entailment and Contradiction Detection
(ECD) algorithm makes a distinction that is not part
of the basic RTE challenge. If T entails the negation
of H, we answer NO (Contradiction). On the other
Process Output
Text-Breaking Delimited sentences
Named-entity recognition Type-marked Entities
Morphological Analysis Word stems plus features
LFG Parsing Functional Structure
Semantic processing Scope, Predicate-
argument structure
AKR rules Conceptual, Contextual,
Temporal Structure
Figure 1: The processing pipeline: processes with
their ambiguity-enabled packed outputs
hand, if there is no direct entailment we answer UN-
KNOWN. We do not try to construct a likely scenario
that would link T and H. Nor have we tried to col-
lect data on phrases that would tend to indicate such
likely associations between T and H. That approach
is clearly very useful (e.g. (Hickl et al, 2006)), and
could be used as a backup strategy with our more
formal entailment approach. We have chosen to fo-
cus on strict structural and lexical entailments.
This paper describes the processing pipeline for
mapping to AKR, the ECD algorithm, the challenges
we faced in processing the RTE data and a summary
of our results on RTE3.
2 Process Pipeline
Figure 1 shows the processing pipeline for mapping
texts to AKR. The input is a text of one or more
sentences.
All components of the system are ?ambiguity en-
abled? (Maxwell and Kaplan, 1991). This allows
each component to accept ambiguous input in a
?packed? format, process it without unpacking the
ambiguities, and then pass packed input to the next
stage. The syntactic component, LFG Parsing, also
has a stochastic disambiguation system which al-
lows us to pass the n-best on to the semantics (Rie-
zler et al, 2002); for the RTE3 challenge, we used
16
n=50.
The parser takes the output of the morphology
(i.e. a series of lemmata with their tags) and pro-
duces a tree (constituent-structure) and a depen-
dency structure (functional-structure) represented as
an attribute-value matrix. The functional-structure
is of primary importance for the semantics and
AKR. In particular, it encodes predicate-argument
relations, including long-distance dependencies, and
provides other syntactic features (e.g. number, tense,
noun type).
The output of the syntax is input for the seman-
tics that is produced by an ambiguity enabled packed
rewriting system. The semantics is described in de-
tail in (Crouch and King, 2006). Semantic process-
ing assigns scope to scope-bearing elements such as
negation and normalizes the output of the syntax.
This normalization includes reformulating syntactic
passives as actives (e.g. The cake was eaten by Mary.
/ Mary ate the cake.), resolving many null pronouns
(e.g. Laughing, John entered the room / Johni laugh-
ing, Johni entered the room.), and canonicalizing
measure phrases, comparatives, and dates. More
complex normalizations involve converting nominal
deverbals into the equivalent verbal form, identify-
ing arguments of the verb from the arguments of
the nominal (Gurevich et al, 2006). For example,
the semantic representation of Iraq?s destruction of
its WMD is similar to the representation of Iraq de-
stroyed its WMD.
The final main task of the semantics rules is to
convert words into concepts and syntactic grammat-
ical functions into roles. The mapping onto concepts
uses WordNet (Fellbaum, 1998) to map words into
lists of synsets. The named entity types provided by
the morphology and syntax are used to create more
accurate mapping of proper nouns since these are
not systematically represented in WordNet. The se-
mantic rules use the grammatical function subcat-
egorization information from the verb and the role
information found in extended VerbNet (Kipper et
al., 2000) to map syntactic subjects, objects, and
obliques into more abstract thematic roles such as
Agent, Theme, and Goal (Crouch and King, 2005).
This mapping into thematic-style roles allows the
system to correctly align the arguments in pairs like
(1) and (2), something which is impossible using just
syntactic functions. In the first, the object and sub-
ject have a common thematic role in the alternation
between transitive and intransitive; while in the sec-
ond, the common role is shared by the subjects.
(1) John broke the vasesyn:object,sem:patient.
The vasesyn:subject,sem:patient broke.
(2) Johnsyn:subject,sem:agent ate the cake.
Johnsyn:subject,sem:agent ate.
The goal of these semantic normalizations is to
abstract away from the syntactic representation so
that sentences with similar meaning have similar se-
mantic representations. However, the semantics is
still fundamentally a linguistic level of representa-
tion; further abstraction towards the meaning is done
in the mapping from semantics to AKR. The AKR
is the level of representation that is used to deter-
mine entailment and contradiction in our RTE3 sys-
tem. A preliminary description of its logic was pro-
vided in (Bobrow et al, 2005). The AKR mapping
converts grammatical tense and temporal modifiers
into temporal relations, identifies anaphoric refer-
ents and makes explicit the implied relation between
complement clauses and the main verb (e.g. for
manage, fail) (Nairn et al, 2006). AKR also deals
with standard phrases that are equivalent to simple
vocabulary terms. For example, take a flight to New
York is equivalent to fly to New York. These uses
of ?light? verbs (e.g. take, give) are not included
in synonyms found in WordNet. Another class of
phrasal synonyms involve inchoatives (e.g. take a
turn for the worse/worsen). We included a special
set of transformation rules for phrasal synonyms:
some of the rules are part of the mapping from se-
mantics to AKR while others are part of the ECD
module. The mapping to AKR is done using the same
ambiguity-enabled ordered rewriting system that the
semantics uses, allowing the AKR mapping system
to efficiently process the packed output of the se-
mantics.
The AKR for a sentence like Bush claimed that
Iraq possessed WMDs in Figure 2 introduces two
contexts: a top level context t, representing the com-
mitments of the speaker of sentence, and an embed-
ded context claim cx:37 representing the state of af-
fairs according to Bush?s claim. The two contexts
are related via the Topic role of the claim event.
The representation contains terms like claim:37 or
17
Conceptual Structure
subconcept(claim:37,[claim-1,. . .,claim-5])
role(Topic,claim:37,claim cx:37)
role(Agent,claim:37,Bush:1)
subconcept(Bush:1,[person-1])
alias(Bush:1,[Bush])
role(cardinality restriction,Bush:1,sg)
subconcept(possess:24,[possess-1,own-1,possess-3])
role(Destination,possess:24,wmd:34)
role(Agent,possess:24,Iraq:19)
subconcept(Iraq:19,[location-1,location-4])
alias(Iraq:19,[Iraq])
role(cardinality restriction,Iraq:19,sg)
subconcept(wmd:34,
[weapon of mass destruction-1])
role(cardinality restriction,wmd:34,pl)
Contextual Structure
context(t)
context(claim cx:37)
context relation(t,claim cx:37,crel(Topic,claim:37))
instantiable(Bush:1,t)
instantiable(Iraq:19,t)
instantiable(claim:37,t)
instantiable(Iraq:19,claim cx:37)
instantiable(possess:24,claim cx:37)
instantiable(wmd:34,claim cx:37)
Temporal Structure
temporalRel(After,Now,claim:37)
temporalRel(After,claim:37,possess:24)
Figure 2: AKR for Bush claimed that Iraq possessed
WMDs.
Bush:1 which refer to the kinds of object that the
sentence is talking about. The subconcept facts ex-
plicitly link these terms to their concepts in Word-
Net. Thus claim:37 is stated to be some subkind
of the type claim-1, etc., and wmd:34 to be some
subkind of the type weapon of mass destruction-
1. Terms like claim:37 and wmd:34 do not refer
to individuals, but to concepts (or types or kinds).
Saying that there is some subconcept of the kind
weapon of mass destruction-1, where this subcon-
cept is further restricted to be a kind of WMD pos-
sessed by Iraq, does not commit you to saying that
there are any instances of this subconcept.
The instantiable assertions capture the commit-
ments about the existence of the kinds of object de-
scribed. In the top-level context t, there is a com-
mitment to an instance of Bush and of a claim:37
event made by him. However, there is no top-level
commitment to any instances of wmd:34 possessed
by Iraq:19. These commitments are only made in
the embedded claim cx:37 context. It is left open
whether these embedded commitments correspond,
or not, to the beliefs of the speaker. Two distinct
levels of structure can thus be discerned in AKR: a
conceptual structure and a contextual structure. The
conceptual structure, through use of subconcept and
role assertions, indicates the subject matter. The
contextual structure indicates commitments as to the
existence of the subject matter via instantiability as-
sertions linking concepts to contexts, and via context
relations linking contexts to contexts. In addition,
there is a temporal structure that situates the events
described with respect to the time of utterance and
temporally relates them to one another.
3 Entailment and Contradiction Detection
ECD is implemented as another set of rewrite rules,
running on the same packed rewrite system used to
generate the AKR representations. The rules (i) align
concept and context terms in text (T) and hypoth-
esis (H) AKRs, (ii) calculate concept subsumption
orderings between aligned T and H terms, and (iii)
check instantiability and uninstantiability claims in
the light of subsumption orderings to determine
whether T entails H, T contradicts H, or T neither
entails not contradicts H. For the purposes of RTE3,
both contradiction and neither contradiction nor en-
tailment are collapsed into a NO (does not follow)
judgment.
One of the novel features of this approach is that
T and H representations do not need to be disam-
biguated before checking for entailment or contra-
diction. The approach is able to detect if there is one
reading of T that entails (or contradicts) one reading
of H. The T and H passages can in effect mutually
disambiguate one another through the ECD. For ex-
ample, although plane and level both have multiple
readings, they can both refer to a horizontal surface,
and in that sense The plane is dry entails The level is
dry, and vice versa.
The first phase of ECD aligns concepts and con-
text terms in the T and H AKRs. Concepts are repre-
18
sented as lists of WordNet hypernym lists, in Word-
Net sense order. Two concept terms can be aligned
if a sense synset of one term (i.e. the first element
of one of the term?s hypernym lists) is contained in
a hypernym list of the other term. The alignment
can be weighted according to word sense; so a con-
cept overlap on the first senses of a T and H term
counts for more than a concept overlap on the n and
mth senses. However, no weightings were used in
RTE3. For named entities, alignment demands not
only a concept overlap, but also an intersection in
the ?alias? forms of the proper nouns. For exam-
ple,?George Bush? may be aligned with ?George?
or with ?Bush?. Context alignment relies on associ-
ating each context with an indexing concept, usually
the concept for the main verb in the clause heading
the context. Contexts are then aligned on the basis
of these concept indices.
Typically, an H term can align with more than one
T term. In such cases all possible alignments are
proposed, but the alignment rules put the alternative
alignments in different parts of the choice space.
Having aligned T and H terms, rules are applied to
determine concept specificity and subsumption rela-
tions between aligned terms. Preliminary judgments
of specificity are made by looking for hypernym in-
clusion. For example, an H term denoting the con-
cept ?person? is less specific than a T term denot-
ing ?woman?. These preliminary judgments need to
be revised in the light of role restrictions modifying
the terms: a ?tall person? is neither more nor less
specific than a ?woman?. Revisions to specificity
judgments also take into account cardinality modi-
fiers: while ?person? is less specific than ?woman?,
?all persons? is judged to be more specific than ?all
women?.
With judgments of concept specificity in place,
it is possible to determine entailment relations on
the basis of (un)instantiability claims in the T and
H AKRs. For example, suppose the T and H AKRs
contain the facts in (3).
(3) T: instantiable(C T, Ctx T)
H: instantiable(C H, Ctx H)
where concept C T is aligned with C H, C T is
judged to be more specific than C H, and context
Ctx T is aligned with context Ctx H. In this case,
the hypothesis instantiability claim is entailed by
the text instantiability claim (existence of something
more specific entails existence of something more
general). This being so, the H instantiability claim
can be deleted without loss of information.
If instead we had the (un)instantiability claims in
(4) for the same alignments and specificity relations,
(4) T: instantiable(C T, Ctx T)
H: uninstantiable(C H, Ctx H)
we would have a contradiction: the text says that
there is something of the more specific type C T,
whereas the hypothesis says there are no things of
the more general type C H. In this case, the rules
explicitly flag a contradiction.
Once all (un)instantiability claims have been
compared, it is possible to judge whether the text en-
tails or contradicts the hypothesis. Entailed hypothe-
sis (un)instantiability assertions are deleted from the
representation. Consequently, if there is one T and H
AKR readings and one set of alignments under which
all the H (un)instantiability assertions have been re-
moved, then there is an entailment of H by T. If
there is a pair of readings and a set of alignments
under which a contradiction is flagged, then there
is a contradiction. If there is no pair of readings or
set of alignments under which there is either an en-
tailment or a contradiction, then T and H are merely
consistent with one another. There are exceptional
cases such as (5) where one reading of T entails H
and another reading contradicts it.
(5) T: John did not wait to call for help.
H: John called for help.
Our ECD rules detect such cases.
WordNet often misses synonyms needed for the
alignment in the ECD. In particular, the hierarchy
and synsets for verbs are one of WordNet?s least de-
veloped parts. To test the impact of the missing syn-
onyms, we developed a variation on the ECD algo-
rithm that allows loose matching.
First, in concept alignment, if a verb concept in H
does not align with any verb concept in T, then we
permit it to (separately) align with all the text verb
concepts. We do not permit the same loose align-
ment for noun concepts, since we judge WordNet
information to be more reliable for nouns. This free
alignment of verbs might sound risky, but in gen-
eral these alignments will not lead to useful concept
19
specificity judgments unless the T and H verbs have
very similar arguments / role restrictions.
When such a loose verb alignment is made, we
explicitly record this fact in a justification term in-
cluded in the alignment fact. Similarly, when judg-
ing concept specificity, each rule that applies adds a
term to a list of justifications recorded as part of the
fact indicating the specificity relation. This means
that when the final specificity judgments are deter-
mined, each judgment has a record of the sequence
of decisions made to reach it.
(Un)instantiability comparisons are made as in
strict matching. However, the criteria for detect-
ing an entailment are selectively loosened. If no
contradiction is flagged, and there is a pairing of
readings and alignments under which just a single
H instantiability assertion is left standing, then this
is allowed through as a loose entailment. However,
further rules are applied to block those loose entail-
ments that are deemed inappropriate. These block-
ing rules look at the form of the justification terms
gathered based on specificity judgments.
These blocking rules are manually selected. First,
a loose matching run is made without any block-
ing rules. Results are dumped for each T-H pair,
recording the expected logical relation and the jus-
tifications collected. Blocking rules are created by
detecting patterns of justification that are associated
with labeled non-entailments. One such blocking
rule says that if you have just a single H instantia-
bility left, but the specificity justifications leading to
this have been shown to be reliable on training data,
then the instantiability should not be eliminated as a
loose entailment.
4 Challenges in Processing the RTE Data
The RTE3 data set contains inconsistencies in
spelling and punctuation between the text and the
hypothesis. To handle these, we did an automatic
prepass where we compared the strings in the pas-
sage text to those in the hypothesis. Some of the
special cases that we handled include:
? Normalize capitalization and spacing
? Identify acronyms and shorten names
? Title identification
? Spelling correction
Role names in VerbNet are in part intended to cap-
ture the relation of the argument to the event be-
ing described by the verb. For example, an object
playing an Agent role is causally involved in the
event, while an object playing a Theme or Patient
role is only supposed to be affected. This allows
participants in an action to be identified regardless
of the syntactic frame chosen to represent the verb;
this was seen in (1) and (2). Sometimes the roles
from VerbNet are not assigned in such a way as to
allow such transparent identification across frames
or related verbs. Consider an example. In Ed trav-
els/goes to Boston VerbNet identifies Ed as playing a
Theme role. However, in Ed flies to Boston VerbNet
assigns Ed an Agent role; this difference can make
determining contradiction and entailment between T
and H difficult. We have tried to compensate in our
ECD, by using a backoff strategy where fewer role
names are used (by projecting down role names to
the smaller set). As we develop the system further,
we continue to experiment with which set of roles
works best for which tasks.
Another open issue involves identifying alterna-
tive ways vague relations among objects appear in
text. We do not match the expression the Boston
team with the team from Boston. To improve our re-
call, we are considering loose matching techniques.
5 Summary of our results on RTE3
We participated in the RTE challenge as a way to
understand what our particular techniques could do
with respect to a more general version of textual en-
tailment. The overall experiment was quite enlight-
ening. Tables 1 and 2 summarize how we did on the
RTE3 challenge. System 1 is our standard system
with strict ECD. System 2 used the looser set of ECD
rules.
Gold Sys Cor- R P F
YES YES rect
IE 105 6 5 0.048 0.83 0.20
IR 87 4 4 0.046 1.00 0.21
QA 106 10 9 0.085 0.90 0.28
SUM 112 11 7 0.063 0.64 0.20
Total 410 31 25 0.060 0.84 0.22
Table 1: System 1 with Strict ECD
20
Gold Sys Cor- R P F
YES YES rect
IE 105 15 10 0.095 0.67 0.25
IR 87 6 4 0.046 0.67 0.18
QA 106 14 13 0.12 0.93 0.34
SUM 112 17 10 0.089 0.59 0.23
Total 410 52 37 0.088 0.71 0.25
Table 2: System 2 with Loose ECD
As can be seen, we answered very few of the ques-
tions; only 31 of the possible 410 with a YES answer.
However, for those we did answer (requiring only
linguistic, and not world knowledge), we achieved
high precision: up to 90% on QA. However, we were
not perfect even from this perspective. Here are sim-
plified versions of the errors where our system an-
swered YES, and the answer should be NO with an
analysis of what is needed in the system to correct
the error.
The wrong result in (6) is due to our incomplete
coverage of intensional verbs (seek, want, look for,
need, etc.).
(6) T: The US sought the release of hostages.
H: Hostages were released.
The object of an intensional verb cannot be assumed
to exist or to occur. Intensional verbs need to be
marked systematically in our lexicon.
The problem with (7) lies in the lack of treatment
for generic sentences.
(7) T: Girls and boys are segregated in high school
during sex education class.
H: Girls and boys are segregated in high school.
The natural interpretation of H is that girls and boys
are segregated in high school ALL THE TIME. Be-
cause we do not yet handle generic sentences prop-
erly, our algorithm for calculating specificity pro-
duces the wrong result here. It judges segregation in
H to be less specific than in T whereas the opposite
is in fact the case. Adding the word ?sometimes? to
H would make our YES the correct answer.
The distinction between generic and episodic
readings is difficult to make but crucial for the in-
terpretation of bare plural noun phrases such as girls
and boys. For example, the most likely interpreta-
tion of Counselors are available is episodic: SOME
counselors are available. But Experts are highly
paid is weighted towards a generic reading: MOST
IF NOT ALL experts get a good salary.
These examples are indicative of the subtlety of
analysis necessary for high precision textual infer-
ence.
References
Danny Bobrow, Cleo Condoravdi, Richard Crouch,
Ronald Kaplan, Lauri Karttunen, Tracy Holloway
King, Valeria de Paiva, and Annie Zaenen. 2005. A
basic logic for textual inference. In Proceedings of the
AAAI Workshop on Inference for Textual Question An-
swering.
Dick Crouch and Tracy Holloway King. 2005. Unify-
ing lexical resources. In Proceedings of the Interdisci-
plinary Workshop on the Identification and Represen-
tation of Verb Features and Verb Classes.
Dick Crouch and Tracy Holloway King. 2006. Se-
mantics via F-structure rewriting. In Proceedings of
LFG06. CSLI On-line Publications.
Dick Crouch, Mary Dalrymple, Ron Kaplan, Tracy King,
John Maxwell, and Paula Newman. 2007. XLE docu-
mentation. Available on-line.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. The MIT Press.
Olga Gurevich, Richard Crouch, Tracy Holloway King,
and Valeria de Paiva. 2006. Deverbal nouns in knowl-
edge representation. In Proceedings of FLAIRS 2006.
Andres Hickl, John Williams, Jeremy Bensley, Kirk
Roberts, Bryan Rink, and Ying Shi. 2006. Recog-
nizing textual entailment with LCC?s GROUNDHOG
system. In The Second PASCAL Recognising Textual
Entailment Challenge.
Karin Kipper, Hoa Trang Dang, and Martha Palmer.
2000. Class-based construction of a verb lexicon. In
AAAI-2000 17th National Conference on Artificial In-
telligence.
John Maxwell and Ron Kaplan. 1991. A method for
disjunctive constraint satisfaction. Current Issues in
Parsing Technologies.
Rowan Nairn, Cleo Condoravdi, and Lauri Karttunen.
2006. Computing relative polarity for textual infer-
ence. In Proceedings of ICoS-5.
Stefan Riezler, Tracy Holloway King, Ron Kaplan, Dick
Crouch, John Maxwell, and Mark Johnson. 2002.
Parsing the Wall Street Journal using a Lexical-
Functional Grammar and discriminative estimation
techniques. In Proceedings of the Annual Meeting of
the Association for Computational Linguistics.
21
