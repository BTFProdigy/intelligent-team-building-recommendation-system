Proceedings of the Second Workshop on Psychocomputational Models of Human Language Acquisition, pages 20?27,
Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
Using Morphology and Syntax Together 
in Unsupervised Learning 
Yu Hu and Irina Matveeva  
Department of  
Computer Science 
The University of Chicago 
Chicago IL 60637 
yuhu@cs.uchicago.edu
matveeva 
@uchicago.edu 
John Goldsmith 
Departments of Linguistics and 
Computer Science  
The University of Chicago 
Chicago IL 60637 
ja-goldsmith 
@uchicago.edu 
 
Colin Sprague 
Department of Linguistics 
The University of Chicago 
Chicago IL 60637 
sprague 
@uchicago.edu 
  
Abstract 
Unsupervised learning of grammar is a 
problem that can be important in many 
areas ranging from text preprocessing 
for information retrieval and 
classification to machine translation. 
We describe an MDL based grammar 
of a language that contains morphology 
and lexical categories. We use an 
unsupervised learner of morphology to 
bootstrap the acquisition of lexical 
categories and use these two learning 
processes iteratively to help and 
constrain each other. To be able to do 
so, we need to make our existing 
morphological analysis less fine 
grained. We present an algorithm for 
collapsing morphological classes 
(signatures) by using syntactic context. 
Our experiments demonstrate that this 
collapse preserves the relation between 
morphology and lexical categories 
within new signatures, and thereby 
minimizes the description length of the 
model. 
1 Introduction 
Our long term goal is the development of 
methods which will allow one to produce 
optimal analyses from arbitrary natural language 
corpora, where by optimization we understand 
an MDL (minimum description length; 
Rissanen, 1989) interpretation of the term: an 
optimal analysis is one which finds a grammar 
which simultaneously minimizes grammar 
length and data compression length. Our specific 
and primary focus is on morphology, and on 
how knowledge of morphology can be a useful 
step towards a more complete knowledge of a 
language?s linguistic structure. 
Our strategy is based on the following 
observation: knowing the rightmost suffix of a 
word is very useful information in inferring (or 
guessing) a word?s part of speech (POS), but due 
to the ambiguity of many suffixes, it is even 
better to know both a word?s suffix and the 
range of other suffixes that the word?s stem 
appears with elsewhere, i.e., its signature. As we 
will see below, this conjunction of ?better? 
information is what we call the signature 
transform, and in this paper, we explore how 
knowledge of signature transform can be merged 
with knowledge of the context vector to draw 
conclusions about morphology and syntax.  
In the distant future, we would like to be able 
to use the signature transform in a general 
process of grammar induction, but that day is 
not here; we therefore test our experiments by 
seeing how well we are able to predict POS as 
assigned by an available tagger (TreeTagger; 
Schmid 1994). In particular, we wish to decrease 
the uncertainty of a word?s POS through the 
morphological analysis described here. This 
decrease of uncertainty will enter into our 
calculation through an increase in the 
probability assigned to our test corpus once the 
corpus has been augmented with TreeTagger 
assigned POS tags. But to be clear on our 
20
process: we analyze a completely raw text 
morphologically, and use the POS tags from 
TreeTagger only to evaluate the signature 
transforms that we generate. 
We assume without argument here that any 
adequate natural language grammar will contain 
a lexicon which includes both lexical stems 
which are specified for morphological 
properties, such as the specific affixes with 
which they may occur, and affixes associated 
with lexical categories. We also explicitly note 
that many affixes are homophonous: they are 
pronounced (or written) identically, but have 
different morphological or syntactic 
characteristics, such as the English plural ?s and 
the verbal 3rd person singular present ?s. 
We focus initially on unsupervised learning 
of morphology for three reasons: first, because 
we already have a quite successful unsupervised 
morphological learner; second, the final suffix of 
a word is typically the strongest single indicator 
of its syntactic category; and third, analysis of a 
word into a stem T plus suffix F allows us 
(given our knowledge that the suffix F is a 
stronger indicator of category than the stem T) 
to collapse many distinct stems into a single 
cover symbol for purposes of analysis, 
simplifying our task, as we shall see.1 We 
eschew the use of linguistic resources with hand-
(i.e., human-)assigned morphological infor-
mation in order for this work to contribute, 
eventually, to a better theoretical understanding 
of human language acquisition. 
We present in this paper an algorithm that 
modifies the output of the morphology analyzer 
by combining redundant signatures. Since we 
ultimately want to use signatures and signature 
transforms to learn syntactic categories, we 
developed an algorithm that uses the syntactic 
contextual information. We evaluate the changes 
to the morphological analysis from the 
standpoint of efficient and adequate 
representation of lexical categories. This paper 
presents a test conducted on English, and thus 
can only be considered a preliminary step in the 
                                                          
1 See Higgins 2002 for a study similar in some ways; 
Higgins uses morphology as a bootstrap heuristic in one 
experimental set-up. This paper is heavily indebted to prior 
work on unsupervised learning of position categories such 
as Brown et al1992, Sch?tze 1997, Higgins 2002, and 
others cited there.  
eventually development of a language-
independent tool for grammar induction based 
on morphology. Nonetheless, the concepts that 
motivate the process are language-independent, 
and we are optimistic that similar results would 
be found in tests based on texts from other 
languages.  
In section 2 we discuss the notion of 
signature and signature transform, and section 3 
present a more explicit formulation of the 
general problem. In section 4 we present our 
algorithm for signature collapse. Section 5 
describes the experiments we ran to test the 
signature collapsing algorithm, and section 6 
presents and discusses our results. 
2 Signatures and signature transforms 
We employ the unsupervised learning of 
morphology developed by Goldsmith 
(Goldsmith, 2001). Regrettably, some of the 
discussion below depends rather heavily on 
material presented there, but we attempt to 
summarize the major points here. 
Two critical terms that we employ in this 
analysis are signature and signature transform. 
A signature found in a given corpus is a pair of 
lists: a stem-list and a suffix-list (or in the 
appropriate context, a prefix-list). By definition 
of signature ?, the concatenation of every stem 
in the stem-list of ? with every suffix in the 
suffix-list of ? is found in the corpus, and a 
morphological analysis of a corpus can be 
viewed as a set of signatures that uniquely 
analyze each word in the corpus. For example, a 
corpus of English that includes the words jump, 
jumps, jumped, jumping, walk, walks, walked, 
and walking might include the signature ?1 
whose stem list is { jump, walk } and whose 
suffix list is { ?, ed, ing , s }. For convenience, 
we label a signature with the concatenation of its 
suffixes separated by period ?.?. On such an 
analysis, the word jump is analyzed as belonging 
to the signature ?.ed.ing.s, and it bears the 
suffix ?. We say, then, that the signature 
transform of jump is ?.ed.ing.s_ ?, just as the 
signature transform of jumping is 
?.ed.ing.s_ing; in general, the signature 
transform of a word W, when W is morpho-
logically analyzed as stem T followed by suffix 
F, associated with signature ?, is defined as ?_F. 
21
In many of the experiments described below, 
we use a corpus in which all words whose 
frequency rank is greater than 200 have been 
replaced by their signature transforms. This 
move is motivated by the observation that high 
frequency words in natural languages tend to 
have syntactic distributions poorly predictable 
by any feature other than their specific identity, 
whereas the distribution properties of lower 
frequency words (which we take to be words 
whose frequency rank is 200 or below) are better 
predicted by category membership.  
In many cases, there is a natural connection 
between a signature transform and a lexical 
category. Our ultimate goal is to exploit this in 
the larger context of grammar induction. For 
example, consider the signature ?.er.ly, which 
occurs with stems such as strong and weak; in 
fact, words whose signature transform is 
?.er.ly_ ? are adjectives, those whose signature 
transform is ?.er.ly_er are comparative 
adjectives, and those whose signature transform 
is ?.er.ly_ly are adverbs. 
The connection is not perfect, however. 
Consider the signature ?.ed.ing.s and its four 
signature transforms. While most words whose 
? -transform is ?.ed.ing.s_s are verbs (indeed, 
3rd person singular present tense verbs, as in he 
walks funny), many are in fact plural nouns (e.g., 
walks in He permitted four walks in the eighth 
inning is a plural noun). We will refer to this 
problem as the signature purity problem?it is 
essentially the reflex of the ambiguity of 
suffixes. 
In addition, many 3rd person singular present 
tense verbs are associated with other signature 
transforms, such as ?.ing.s_s, ?.ed.s_s, and so 
forth; we will refer to this as the signature-
collapsing problem, because all other things 
being equal, we would like to collapse certain 
signatures, such as ?.ed.ing.s and ?.ed.ing, 
since a stem that is associated with the latter 
signature could have appeared in the corpus with 
an -s suffix; removing the ?.ed.ing signature and 
reassigning its stems to the ?.ed.ing.s signature 
will in general give us a better linguistic analysis 
of the corpus, one that can be better used in the 
problem of lexical category induction. This is 
the reflex of the familiar data sparsity concern.2   
Since we ultimately want to use signatures 
and signature transforms to learn syntactic 
categories, we base the similarity measure 
between the signatures on the context.   
3 A more abstract statement of the 
problem  
A minimum description length (MDL) analysis 
is especially appropriate for machine learning of 
linguistic analysis because simultaneously it 
puts a premium both on analytical simplicity and 
on goodness of fit between the model and the 
data (Rissanen 1989).  
We will present first the mathematical 
statement of the MDL model of the morphology, 
in (1), following the analysis in Goldsmith 
(2001), followed by a description of the meaning 
of the terms of the expressions, and then present 
the modified version which includes additional 
terms regarding part of speech (POS) 
information, in (2) and (3).  
(1) Morphology 
a. Grammar g =   
[ ])|(log)(minarg gDataprobgLength
Gg
?
?
 
b. =)(gLength  
 ? ?
=? <?
??
???
? +
stemsofsetTt ti itfreqt
W
||0 ][
1log
)]([
][log ?  
? ?
=? <?
+
affixesofsetFf fi iffreq||0 ][
1log  
??
?? ?
??
???
? +?+ ? ? ?
?
f f
W
f ][
][log
][
][log  
                                                          
2 The signature-collapsing problem has another side to it as 
well. An initial morphological analysis of English will 
typically give rise to a morphological analysis of words 
such as move, moves, moved, moving with a signature 
whose stems include mov and whose affixes are e.ed.es.ing. 
A successful solution to the signature-collapsing problem 
will collapse ?.ed.ing.s with e.ed.es.ing, noting that ? ~ e, 
ed ~ed, es ~ s, and ing ~ ing in an obvious sense. 
22
c. =)|(log gDataprob  
?
+=? ?
??
?
?
??
?
?
?
+
+
? ?
?
?
, ),|(log
)|(log
)(log
ftw
Dataw tfprob
tprob
prob
 
 
Equation (1a) states that our goal is to find 
the (morphological) grammar that 
simultaneously minimizes the sum of its own 
length and the compressed length of the data it 
analyzes, while (1b) specifies the grammar 
length (or model length) as the sum of the 
lengths of the links between the major 
components of the morphology: the list of letters 
(or phonemes) comprising the morphemes, the 
morphemes (stems and affixes), and the 
signatures. We use square brackets ?[.]? to 
denote the token counts in a corpus containing a 
given morpheme or word. The first line of (1b) 
expresses the notion that each stem consists of a 
pointer to its signature and a list of pointers to 
the letters that comprise it; ?(t) is the signature 
associated with stem t, and we take its 
probability to be 
][
)]([
W
t? , the empirical count of 
the words associated with ?(t) divided by the 
total count of words in the data. The second line 
expresses the idea that the morphology contains 
a list of affixes, each of which contains a list of 
pointers to the letters that comprise it. The third 
line of (1b) expresses the notion that a signature 
consists of a list of pointers to the component 
affixes. (1c) expresses the compressed length of 
each word in the data.3 
We now consider extending this model to 
include part of speech labeling, as sketched in 
(2). The principal innovation in (2) is the 
addition of part of speech tags; each affix is 
associated with one or more POS tags. As we 
                                                          
3 We do not sum over all occurrences of a word in the 
corpus; we count the compressed length of each word type 
found in the corpus. This decision was made based on the 
observation that the (compressed length of the) data term 
grows much faster than the length of the grammar as the 
corpus gets large, and the loss in ability of the model to 
predict word frequencies overwhelms any increase in 
model simplicity when we count word tokens in the data 
terms. We recognize the departure from the traditional 
understanding of MDL here, and assume the responsibility 
to explain this in a future publication. 
have seen, a path from a particular signature ? to 
a particular affix f constitutes what we have 
called a particular signature transform ?_f ; and 
we condition the probabilities of the POS tags in 
the data on the preceding signature 
transformation. As a result, our final model takes 
the form in (3). 
 
(2)  
t1
t2
t3
tn
...
Stems Signatures Affixes POSs
?1
?2
?m
...
f1
f2
f3
fk
...
?1
?2
?3
?l
...
 
(3) 
a. Grammar g =   [ ])|(log)(minarg gDataprobgLength
Gg
?
?
 
b. =)(gLength  
? ?
=? <?
??
???
? +
stemsofsetTt ti itfreqt
W
||0 ][
1log
)]([
][log ?
 
? ?
=? <?
+
affixesofsetFf fi iffreq||0 ][
1log  
?? ??? ?
?? ?
??
?
?
?
??
??
?
?
??
?
++?+
? ?
? ??
?
?
?
f
f
f
f
W
f
][
][log
][
][log
][
][log
 
c. =)|(log gDataprob  
 ?
+=? ?
??
?
?
??
?
?
?
+
+
+
? ??
?
??
, ),|(log
),|(log
)|(log)(log
ftw
Dataw fprob
tfprob
tprobprob
 
 
The differences between the models are 
found in the added final term in (3b), which 
specifies the information required to predict, or 
specify, the part of speech given the signature 
23
transform, and the corresponding term in the 
corpus compression expression (3c).  
The model in (3) implicitly assumes that the 
true POSs are known; in a more complete 
model, the POSs play a direct role in assigning a 
higher probability to the corpus (and hence a 
smaller compressed size to the data). In the 
context of such a model, an MDL-based learning 
device searches for the best assignment of POS 
tags over all possible assignments. Instead of 
doing that in this paper, we employ the 
TreeTagger (Schmid, 1994) based tags (see 
section 5 below), and make the working 
assumption that optimization of description 
length over all signature-analyses and POS tags 
can be approximated by optimization over all 
signature-analyses, given the POS tags provided 
by TreeTagger. 
4 The collapsing of signatures 
We describe in this section our proposed 
algorithm, using context vectors to collapse 
signatures together, composed of a sequence of 
operations, all but the first of which may be 
familiar to the reader:  
Replacement of words by signature-
transforms: The input to our algorithm for 
collapsing signatures is a modified version of 
the corpus which integrates the (unsupervised) 
morphological analyses in the following way. 
First of all, we leave unchanged the 200 most 
frequent words (word types). Next, we replace 
words belonging to the K most reliable 
signatures (where K=50 in these experiments) 
by their associated signature transforms, and we 
in effect ignore all other words, by replacing 
them by a distinguished ?dummy? symbol. In 
the following, we refer to our high frequency 
words and signature transforms together as 
elements?so an element is any member of the 
transformed corpus other than the ?dummy?.   
Context vectors based on mutual 
information: By reading through the corpus, we 
populate both left and right context vectors for 
each element (=signature-transform and high-
frequency word)  by observing the elements that 
occur adjacent to it. The feature indicating the 
appearance of a particular word on the left is 
always kept distinct from the feature indicating 
the appearance of the same word on the right. 
The features in a context vector are thus 
associated with the members of the element 
vocabulary (and indeed, each member of the 
element vocabulary occurs as two features: one 
on the left, one on the right). We assign the 
value of each feature y of x?s context vector as 
the pointwise mutual information of the 
corresponding element pair (x, y), defined as 
)()(
),(log
yprxpr
yxpr . 
Simplifying context vectors with ?idf?: In 
addition, because of the high dimensionality of 
the context vector and the fact that some features 
are more representative than others, we trim the 
original context vector. For each context vector, 
we sort features by their values, and then keep 
the top N (in general, we set N to 10) by setting 
these values to 1, and all others to 0. However, 
in this resulting simplified context vector, not all 
features do equally good jobs of distinguishing 
syntactical categories. As Wicentowski (2002) 
does in a similar context, we assign a weight  
if
w  to each feature fi in a fashion parallel to 
inverse document frequency (idf; see Sparck 
Jones 1973), or 
inappearsfeaturethiselements
elementsdistincttotal
#
#log . 
We view these as the diagonal elements of a 
matrix M (that is, mi,i = ifw ). We then check the 
similarity between two simplified context 
vectors by computing the weighted sum of the 
dot product of them. That is, given two 
simplified context vectors c and d, their 
similarity is defined as cTMd. If this value is 
larger than a threshold ? that is set as one 
parameter, we deem these two context vectors to 
be similar. Then we determine the similarity 
between elements by checking whether both left 
and right simplified context vectors of them are 
similar (i.e., their weighted dot products exceed 
a threshold ?). In the experiments we describe 
below, we explore four settings ? for this 
threshold: 0.8 (the most ?liberal? in allowing 
greater signature transform collapse, and hence 
greater signature collapse), 1.0, 1.2, and 1.5. 
Calculate signature similarity: To avoid 
considering many unnecessary pairs of 
signatures, we narrow the candidates into 
signature pairs in which the suffixes of one 
constitute a subset of suffixes of the other, and 
we set a limit to the permissible difference in the 
24
lengths of the signatures in the collapsed pairs, 
so that the difference in number of affixes 
cannot exceed 2. For each such pair, if all 
corresponding signature transforms are similar 
in the sense defined in the preceding paragraph, 
we deem the two signatures to be similar. 
Signature graph: Finally, we construct a 
signature graph, in which each signature is 
represented as a vertex, and an edge is drawn 
between two signatures iff they are similar, as 
just defined. In this graph, we find a number of 
cliques, each of which, we believe, indicates a 
cluster of signatures which should be collapsed. 
If a signature is a member of two or more 
cliques, then it is assigned to the largest clique 
(i.e., the one containing the largest number of 
signatures).4  
5 Experiments 
We obtain the morphological analysis of the 
Brown corpus (Ku?era and Francis, 1967) using 
the Linguistica software (http://linguistica. 
uchicago.edu), and we use the TreeTagger to 
assign a Penn TreeBank-style part-of-speech tag 
to each token in the corpus. We then carry out 
our experiment using the Brown corpus 
modified in the way we described above. Thus, 
for each token of the Brown corpus that our 
morphology analyzer analyzed, we have the 
following information: its stem, its signature 
                                                          
4 Our parameters are by design restrictive, so 
that we declare only few signatures to be similar, 
and therefore the cliques that we find in the 
graph are relatively small. One way to enlarge 
the size of collapsed signatures would be to 
loosen the similarity criterion. This, however, 
introduces too many new edges in the signatures 
graph, leading in turn to spurious collapses of 
signatures. We take a different approach, and 
apply our algorithms iteratively. The idea is that 
if in the first iteration, two cliques did not have 
enough edges between their elements to become 
a single new signature, they may be more 
strongly connected in the second iteration if 
many of their elements are sufficiently similar. 
On the other hand, cliques that were dissimilar 
in the first iteration remain weakly connected in 
the second.  
 
(i.e., the signature to which the stem is 
assigned), the suffix which the stem attains in 
this occurrence of the word (hence, the 
signature-transform), and the POS tag. For 
example, the token polymeric is analyzed into 
the stem polymer and the suffix ic, the stem is 
assigned to the signature ?.ic.s, and thus this 
particular token has the signature transform 
?.ic.s_ic. Furthermore, it was assigned POS-tag 
JJ, so that we have the following entry: 
?polymeric JJ ?.ic.s_ic?. 
Before performing signature collapsing, we 
calculate the description length of the 
morphology and the compressed length of the 
words that our algorithm analyzes and call it 
baseline description length (DL0). 
Now we apply our signature collapsing 
algorithm under several different parameter 
settings for the similarity threshold ?, and 
calculate the description length DL? of the 
resulting morphological and lexical analysis 
using  (3).  We know that the smaller the set of 
signatures, the smaller is the cost of the model. 
However, a signature collapse that combines 
signatures with different distributions over the 
lexical categories will result in a high cost of the 
data term (3c). The goal was therefore to find a 
method of collapsing signatures such that the 
reduction in the model cost will be higher than 
the increase in the compressed length of the data 
so that the total cost will decrease.  
As noted above, we perform this operation 
iteratively, and refer to the description length of 
the ith iteration, using a threshold ?, as ? iiterDL = . 
We used random collapsing in our 
experiments to ensure the expected relationship 
between appropriate collapses and description 
length. For each signature collapsing, we created 
a parallel situation in which the number of 
signatures collapsed is the same, but their choice 
is random.  We calculate the description length 
using this ?random? analysis as 
?
randomDL . We 
predict that this random collapsing will not 
produce an improvement in the total description 
length. 
25
6 Results and discussion 
Table 1 presents the description length, broken 
into its component terms (see (3)), for the 
baseline case and the alternative analyses 
resulting from our algorithm. The table shows 
the total description length of the model, as well 
as the individual terms: the signature term 
DL(?), the suffix term DL(F), the lexical 
categories term, DL(P), total morphology, 
DL(M), and the compressed length of the data, 
DL(D). We present results for two iterations for 
four threshold values (?=0.8,1.0,1.2,1.5) using 
our collapsing algorithm.  
Table 2 presents 
?
randomDL  derived from the 
random collapsing, in a fashion parallel to Table                
1. We show the results for only one iteration of 
random collapsing, since the first iteration 
already shows a substantial increase in 
description length. 
Figure 1 and Figure 2 present graphically the 
total description length from Tables 1 and 2 
respectively. The reader will see that all 
collapsing of signatures leads to a shortening of 
the description length of the morphology per se, 
and an increase in the compressed length of the 
data. This is an inevitable formal consequence of 
the MDL-style model used here. The empirical 
question that we care about is whether the 
combined description length increases or 
decreases, and what we find is that when 
collapsing the signatures in the way that we 
propose to do, the combined description length 
decreases, leading us to conclude that this is, 
overall, a superior linguistic description of the 
data. On the other hand, when signatures are 
collapsed randomly, the combined description 
length increases. This makes sense; randomly 
decreasing the formal simplicity of the 
grammatical description should not improve the 
overall analysis. Only an increase in the formal 
simplicity of a grammar that is grammatically 
sensible should have this property. Since our 
goal is to develop an algorithm that is 
completely data-driven and can operate in an  
Compa rison of DL 
362,500
363,000
363,500
364,000
364,500
365,000
365,500
366,000
DL0 DL1 DL2
?=0.8 ?=1 ?=1.2 ?=1.5  
Figure 1 Comparison of DL, 2 iterations and 4 
threshold values 
Compa rison of ra ndomly c olla psing DL
364,000
364,500
365,000
365,500
366,000
366,500
367,000
367,500
368,000
DL0 Drandom
D
L
?=0.8 ?=1 ?=1.2 ?=1.5
 
Figure 2 Comparison of DLs with random 
collapse of signatures (see text)
 DL0 8.0 1
=
=
?
iterDL  
8.0
2
=
=
?
iterDL
0.1
1
=
=
?
iterDL
0.1
2
=
=
?
iterDL
2.1
1
=
=
?
iterDL
2.1
2
=
=
?
iterDL  
5.1
1
=
=
?
iterDL  
5.1
2
=
=
?
iterDL
#? 50 41 35 41 34 44 42 46 45 
DL(?) 47,630 45,343 42,939 45,242 43,046 44,897 44,355 46,172 45,780 
DL(F) 160 156 156 153 143 158 147 163 164 
DL(P) 2,246 2,087 1,968 2,084 1,934 2,158 2,094 2,209 2,182 
DL(M) 50,218 47,768 45,244 47,659 45,304 47,395 46,777 48,724 48,306 
DL(D) 315,165 316,562 318,687 316,615 318,172 316,971 317,323 315,910 316,251 
Total 
DL 
365,383 364,330 363,931 364,275 363,476 364,367 364,101 364,635 364,558 
Table 1.   DL and its individual components for baseline and the resulting cases when collapsing 
signatures using our algorithm. 
26
 
 DL0 8.0=?
randomDL  
0.1=?
randomDL  
2.1=?
randomDL  
5.1=?
randomDL  
#? 50 41 41 44 46 
DL(?) 47,630 44,892 45,126 45,788 46,780 
DL(F) 160 201 198 187 177 
DL(P) 2,246 2,193 2,195 2,212 2,223 
DL(M) 50,218 47,468 47,700 48,369 49,362 
DL(D) 315,165 320,200 319,551 318,537 316,874 
Total DL 365,383 367,669 367,252 366,907 366,237 
Table 2. DL and its individual components for baseline and the 
resulting cases when collapsing signatures randomly.
 
 
 
unsupervised fashion, we take this evidence as 
supporting the appropriateness of our algorithm as 
a means of collapsing signatures in a 
grammatically and empirically reasonable way. 
We conclude that the collapsing of signatures 
on the basis of similarity of context vectors of 
signature transforms (in a space consisting of high 
frequency words and signature transforms) 
provides us with a useful and significant step 
towards solving the signature collapsing problem. 
In the context of the broader project, we will be 
able to use signature transforms as a more effective 
means for projecting lexical categories in an 
unsupervised way. 
As Table 1 shows, we achieve up to 30% 
decrease in the number of signatures through our 
proposed collapse. We are currently exploring 
ways to increase this value through powers of the 
adjacency matrix of the signature graph. 
In other work in progress, we explore the 
equally important signature purity problem in 
graph theoretic terms: we split ambiguous 
signature transforms into separate categories when 
we can determine that the edges connecting left-
context features and right-context features can be 
resolved into two sets (corresponding to the 
distinct categories of the transform) whose left-
features have no (or little) overlap and whose right 
features have no (or little) overlap. We employ the 
notion of minimum cut of a weighted graph to 
detect this situation.
 
References  
Brown, Peter F., Vincent J. Della Pietra, Peter V. 
deSouza, Jennifer C. Lai, and Robert L. Mercer. 
1992. Class-based n-gram models of natural 
language. Computational Linguistics, 18(4): 467-
479.  
Goldsmith, John. 2001. Unsupervised learning of the 
morphology of a natural language. Computational 
Linguistics, 27(2): 153-198.  
Higgins, Derrick. 2002. A Multi-modular Approach to 
Model Selection in Statistical NLP. University of 
Chicago Ph.D. thesis. 
Schmid, Helmut. 1994. Probabilistic part-of-speech 
tagging using decision trees.. International 
Conference on New Methods in Language 
Processing 
Kucera, Henry and W. Nelson Francis. 1967. 
Computational Analysis of Present-day American 
English. Brown University Press.  
Rissanen, Jorma. 1989. Stochastic Complexity in 
Statistical Inquiry. Singapore: World Scientific.  
Sch?tze, Hinrich. 1997. Ambiguity Resolution in 
Language Learning. CSLI Publications. Stanford 
CA.  
Sparck Jones, Karen. 1973. Index term weighting. 
Information Storage and Retrieval 9:619-33. 
Wicentowski, Richard. 2002. Modeling and Learning 
Multilingual Inflectional Morphology in a Minimally 
Supervised Framework. Johns Hopkins University 
Ph.D. thesis. 
27
Proceedings of the Second Workshop on Psychocomputational Models of Human Language Acquisition, pages 28?35,
Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
The SED heuristic for morpheme discovery:  
a  look at Swahili 
 
 
Yu Hu and Irina Matveeva  
Department of  
Computer Science 
The University of Chicago 
Chicago IL 60637 
yuhu@cs.uchicago.edu
matveeva 
@uchicago.edu  
John Goldsmith 
Departments of Linguistics and 
Computer Science  
The University of Chicago 
Chicago IL 60637 
ja-goldsmith 
@uchicago.edu 
 
Colin Sprague 
Department of Linguistics 
The University of Chicago 
Chicago IL 60637 
sprague 
@uchicago.edu  
  
Abstract 
This paper describes a heuristic for 
morpheme- and morphology-learning 
based on string edit distance. 
Experiments with a 7,000 word corpus 
of Swahili, a language with a rich 
morphology, support the effectiveness 
of this approach. 
1 Introduction 
This paper describes work on a technique for the 
unsupervised learning of the morphology of 
natural languages which employs the familiar 
string edit distance (SED) algorithm (Wagner 
and Fischer 1974 and elsewhere) in its first 
stage;  we refer to it here as the SED heuristic. 
The heuristic finds 3- and 4-state finite state 
automata (FSAs) from untagged corpora. We 
focus on Swahili, a Bantu language of East 
Africa, because of the very high average number 
of morphemes per word, especially in the verbal 
system, a system that presents a real challenge to 
other systems discussed in the literature.1 
In Section 2, we present the SED heuristic, 
with precision and recall figures for its 
application to a corpus of Swahili. In Section 3, 
we propose three elaborations and extensions of 
                                                     
1 An earlier version of this paper, with a more detailed 
discussion of the material presented in Section 3, is 
available at Goldsmith et al(2005). 
this approach, and in Section 4, we describe and 
evaluate the results from applying these 
extensions to the corpus of Swahili.2  
2 SED-based heuristic 
Most systems designed to learn natural language 
morphology automatically can be viewed as 
being composed of an initial heuristic 
component and a subsequent explicit model. The 
initial or bootstrapping heuristic, as the name 
suggests, is designed to rapidly come up with a 
set of candidate strings of morphemes, while the 
model consists of an explicit formulation of 
either (1) what constitutes an adequate 
morphology for a set of data, or (2) an objective 
function that must be optimized, given a corpus 
of data, in order to find the correct 
morphological analysis.  
The best known and most widely used 
heuristic is due to Zellig Harris (1955) (see also 
Harris (1967) and Hafer and Weiss (1974) for an 
evaluation based on an English corpus), using a 
notion that Harris called successor frequency 
(henceforth, SF). Harris' notion can be 
succinctly described in contemporary terms: if 
we encode all of the data in the data structure 
known as a trie, with each node in the trie 
dominating all strings which share a common 
                                                     
2 SED has been used in unsupervised language learning in a 
number of studies; see, for example, van Zaanen (2000) 
and references there, where syntactic structure is studied in 
a similar context. To our knowledge, it has not been used in 
the context of morpheme detection. 
28
string prefix,3 then each branching node in the 
trie is associated with a morpheme break. For 
example, a typical corpus of English may 
contain the words governed, governing, 
government, governor, and governs. If this data 
is encoded in the usual way in a trie, then a 
single node will exist in the trie which represents 
the string prefix govern and which dominates 
five leaves corresponding to these five words. 
Harris's SF-based heuristic algorithm would 
propose a morpheme boundary after govern on 
this basis. In contemporary terms, we can 
interpret Harris?s heuristic as providing sets of 
simple finite state automata, as in (1), which 
generate a string prefix (PF1) followed by a set 
of string suffixes (SFi) based on the 
measurement of a successor frequency greater 
than 1 (or some threshold value) at the string 
position following PF1. 
(1)  
SF1
SF3
PF1 SF2
 
A variant on the SF-based heuristic, 
predecessor frequency (henceforth, PF), calls for 
encoding words in a trie from right to left. In 
such a PF-trie, each node dominates all strings 
that share a common string suffix. In general, we 
expect SF to work best in a suffixing language, 
and PF to work best in prefixing language; 
Swahili, like all the Bantu languages, is 
primarily a prefixing language, but it has a 
significant number of important suffixes in both 
the verbal and the nominal systems. 
Goldsmith (2001) argues for using the 
discovery of signatures as the bootstrapping 
heuristic, where a signature is a maximal set of 
stems and suffixes with the property that all 
combinations of stems and suffixes are found in 
the corpus in question. We interpret Goldsmith?s 
signatures as extensions of FSAs as in (1) to 
                                                     
3 We use the terms string prefix and string suffix in the 
computer science sense: a string S is a string prefix of a 
string X iff there exists a string T such that X = S.T, where 
?.? is the string concatenation operator; under such 
conditions, T is likewise a string suffix of X. Otherwise, we 
use the terms prefix and suffix in the linguistic sense, and a 
string prefix (e.g., jump) may be a linguistic stem, as in 
jump-ing. 
FSAs as in (2); (2) characterizes Goldsmith?s 
notion of signature in term of FSAs. In 
particular, a signature is a set of forms that can 
be characterized by an FSA of 3 states. 
(2)  
PF1 SF1
PF3 SF2
PF2
 
 
We propose a simple alternative heuristic 
which utilizes the familiar dynamic 
programming algorithm for calculating string-
edit distance, and finding the best alignment 
between two arbitrary strings (Wagner and 
Fischer 1974). The algorithm finds subsets of 
the data that can be exactly-generated by 
sequential finite state automata of 3 and 4 states, 
as in (3), where the labels mi should be 
understood as cover terms for morphemes in 
general. An automaton exactly-generates a set of 
strings S if it generates all strings in S and no 
other strings; a sequential FSA is one of the 
form sketched graphically in (1)-(3), where there 
is a unique successor to each state. 
(3)  
M1 M4
M3 M6
M2
M7
M9
M5 M8
 
2.1 First stage: alignments. 
If presented with the pair of strings anapenda 
and anamupenda from an unknown language, it 
is not difficult for a human being to come up 
with the hypothesis that mu is a morpheme 
inside a larger word that is composed of at least 
two morphemes, perhaps ana- and -penda. The 
SED heuristic makes this observation explicit by 
building small FSAs of the form in (4), where at 
most one of m1 or m4 may be null, and at most 
one of m2 and m3 may be null: we refer to these 
as elementary alignments. The strings m2 and m3 
are called counterparts; the pairs of strings m1 
and m4 are called the context (of the 
counterparts). (Indeed, we consider this kind of 
string comparison to be a plausible candidate for 
human language learning; see Dahan and Brent 
1999). 
 
29
 
 
(4)  
1 432m1 m4
m3
m2
 
The first stage of the algorithm consists of 
looking at all pairs of words S, T in the corpus, 
and passing through the following steps:  
We apply several initial heuristics to 
eliminate a large proportion of the pairs of 
strings before applying the familiar SED 
algorithm to them, in view of the relative 
slowness of the SED algorithm; see Goldsmith 
et al(2005) for further details.  
We compute the optimal alignment of S and 
T using the SED algorithm, where alignment 
between two identical letters (which we call 
twins) is assigned a cost of 0, alignment between 
two different letters (which we call siblings) is 
assigned a cost of 1.5, and a letter in one string 
not aligned with a segment on the other string 
(which we call an orphan) is assigned a cost of 
1. An alignment as in (5) is thus assigned a cost 
of 5, based on a cost of 1.5 assigned to each 
broken line, and 1  to each dotted line that ends 
in a square box. 
(5)   
n i l i m u p e n d a
n i t a k a m u p e n d a  
There is a natural map from every alignment 
to a unique sequence of pairs, where every pair 
is either of the form (S[i], T[j]) (representing 
either a twin or sibling case) or of the form (S[i], 
0) or (0, T[j]) (representing the orphan case). We 
then divide the alignment up into perfect and 
imperfect spans: perfect spans are composed of 
maximal sequences of twin pairs, while 
imperfect spans are composed of maximal 
sequences of sibling or orphan pairs. This is 
illustrated in (6). 
(6)  
 
 
 
 
 
 
There is a natural equivalence between 
alignments and sequential FSAs as in (4), where 
perfect spans correspond to pairs of adjacent 
states with unique transitions and imperfect 
spans correspond to pairs of adjacent states with 
two transitions, and we will henceforth use the 
FSA notation to describe our algorithm. 
2.2 Collapsing alignments 
As we noted above (4), for any elementary 
alignment, a context is defined: the pair of 
strings (one of them possibly null) which 
surround the pair of counterparts. Our first goal 
is to collapse alignments that share their context. 
We do this in the following way. 
Let us define the set of strings associated 
with the paths leaving a state S as the production 
of state S. A four-state sequential FSA, as in (4), 
has three states with non-null productions; if this 
particular FSA corresponds to an elementary 
alignment, then two of the state-productions 
contain exactly one string?and these state-
productions define the context? and one of the 
state-productions contains exactly two strings 
(one possibly the null string)?this defines the 
counterparts. If we have two such four-state 
FSAs whose context are identical, then we 
collapse the two FSAs into a single conflated 
FSA in which the context states and their 
productions are identical, and the states that 
produced the counterparts are collapsed by 
creating a state that produces the union of the 
productions of the original states. This is 
illustrated in (7): the two FSAs in (7a) share a 
context, generated by their states 1 and 3, and 
they are collapsed to form the FSA in (7b), in 
which the context states remain unchanged, and 
the counterpart states, labeled ?2?, are collapsed 
to form a new state ?2? whose production is the 
union of the productions of the original states. 
(7)  
a.  
1 432m1 m4
1 432m1 m4
m7
m8
m3
m2
 
 
n i   l i   m u p e n d a
n i   t a k a   m u p e n d a
30
 
 
b. 
1 432m1 m4
m8
m7
m3
m2
 
2.3 Collapsing the resulting sequential 
FSAs 
We now generalize the procedure described in 
the preceding section to collapse any two 
sequential FSAs for which all but one of the 
corresponding states have exactly the same 
production. For example, the two sequential 
FSAs in (8a) are collapsed into (8b). 
Three and four-state sequential FSAs as in 
(8b), where at least two of the state-transitions 
generate more than one morpheme, form the set 
of templates derived from our bootstrapping 
heuristic. Each such template can be usefully 
assigned a quantitative score based on the 
number of letters ?saved? by the use of the 
template to generate the words, in the following 
sense. The template in (8b) summarizes four 
words: aliyesema, alimfuata, anayesema, and 
anamfuata. The total string length of these 
words is 36, while the total number of letters in 
the strings associated with the transitions in the 
FSA is 1+4+12 = 17; we say that the FSA saves 
36-17 = 19 letters. In actual practice, the 
significant templates discovered save on the 
order of 200 to 5,000 letters, and ranking them 
by the number of letters saved is a good measure 
of how significant they are in the overall 
morphology of the language. We refer to this 
score as a template?s robustness; we employ this 
quantity again in section 3.1 below. 
By this ranking, the top template found in our 
Swahili corpus of 50,000 running words was one 
that generated a and wa (class 1 and 2 subject 
markers) and followed by 246 correct verb 
continuations (all of them polymorphemic); the 
first 6 templates are summarized informally in 
Table 1. We note that the third and fourth 
template can also be collapsed to form a 
template of the form in (3), a point we return to 
below. Precision, recall, and F-score for these 
experiments are given in Table 2.  
 
(8)   
a. 
1 432a yesema
na
li
1 432a mfuata
na
li
 
 
b.  
1 432a
na
li yesema
mfuata  
 
State 1 State 2 State 3 
a, wa (sg., pl. 
human subject 
markers) 
246 stems  
ku, hu 
(infinitive, 
habitual 
markers) 
51 stems  
wa (pl. subject 
marker) 
ka, li (tense 
markers) 
25 stems 
a (sg. subject 
marker) 
ka, li (tense 
markers) 
29 stems 
a (sg. subject 
marker) 
ka, na (tense 
markers 
28 stems 
37 strings w (passive 
marker) 
a 
Table 1 Top templates in Swahili 
 
 Precision Recall  F-score 
SED 0.77 0.57 0.65 
SF 0.54 0.14 0.22 
PF 0.68 0.20 0.31 
Table 2 Results 
31
3 Further developments 
In this section, we describe three developments 
of the SED-based heuristic sketched in section 2. 
The first disambiguates which state it is that 
string material should be associated with in 
cases of ambiguity; the second collapses 
templates associated with similar morphological 
structure; the third uses the FSAs to predict 
words that do not actually occur in the corpus by 
hypothesizing stems on the basis of the 
established FSAs and as yet unanalyzed words 
in the corpus. 
3.1 Disambiguating FSAs 
In the case of a sequential FSA, when the final 
letter of the production of a (non-final) state S 
are identical, then that letter can be moved from 
being the string-suffix of all of the productions 
of state S to being the string-prefixes of all of 
the productions of the following state. More 
generally, when the n final letters of the 
productions of a state are identical, there is an n-
way ambiguity in the analysis, and the same 
holds symmetrically for the ambiguity that arises 
when the n initial letters of the production of a 
(non-initial) state.  
Thus two successive states, S and T, must (so 
to speak) fight over which will be responsible 
for generating the ambiguous string. We employ 
two steps to disambiguate these cases.  
Step 1: The first step is applicable when the 
number of distinct strings associated with states 
S and T are quite different in size (typically 
corresponding to the case where one generates 
grammatical morphemes and the other generates 
stems); in this case, we assign the ambiguous 
material to the state that generates the smaller 
number of strings. There is a natural motivation 
for this choice from the perspective of our desire 
to minimize the size of the grammar, if we 
consider the size of the grammar to be based, in 
part, on the sum of the lengths of the morphemes 
produced by each state. 
Step 2: It often happens that an ambiguity 
arises with regard to a string of one or more 
letters that could potentially be produced by 
either of a pair of successive states involving 
grammatical morphemes. To deal with this case, 
we make a decision that is also (like the 
preceding step) motivated by a desire to 
minimize the description length of the grammar. 
In this case, however, we think of the FSA as 
containing explicit strings (as we have assumed 
so far), but rather pointers to strings, and the 
?length? of a pointer to a string is inversely 
proportional to the logarithm of its frequency. 
Thus the overall use of a string in the grammar 
plays a crucial role in determining the length of 
a grammar, and we wish to maximize the 
appearance in our grammar of morphemes that 
are used frequently, and minimize the use of 
morphemes that are used rarely. 
We implement this idea by collecting a table 
of all of the morphemes produced by our FSA, 
and assigning each a score which consists of the 
sum of the robustness scores of each template 
they occur in (see discussion just above (8)). 
Thus morphemes occurring in several high 
robustness templates will have high scores; 
morphemes appearing in a small number of 
lowly ranked templates will have low scores. 
To disambiguate strings which could be 
produced by either of two successive states, we 
consider all possible parsings of the string 
between the states, and score each parsing as the 
sum of the scores of the component morphemes; 
we chose the parsing for which the total score is 
a maximum. 
 For example, Swahili has two common tense 
markers, ka and ki, and this step corrected a 
template from {ak}+{a,i}+{stems} to 
{a}+{ka,ki}+{stems}, and others of similar 
form. It also did some useful splitting of joined 
morphemes, as when it modified a template 
{wali} + {NULL, po} + {stems} to {wa} + {li, 
lipo} + {stems}. In this case, wali should indeed 
be split into wa + li (subject and tense markers, 
resp.), and while the change creates an error (in 
the sense that lipo is, in fact, two morphemes; po 
is a subordinate clause marker), the resulting 
error occurs considerably less often in the data, 
and the correct template will better be able to be 
integrated with out templates. 
3.2 Template collapsing 
From a linguistic point of view, the SED-based 
heuristic creates too many FSAs because it stays 
too close to the data provided by the corpus. The 
only way to get a more correct grammar is by 
collapsing the FSAs, which will have as a 
32
consequence the generation of new words not 
found in the corpus. We apply the following 
relatively conservative strategy for collapsing 
two templates. 
We compare templates of the same number 
of states, and distinguish between states that 
produce grammatical morphemes (five or fewer 
in number) and those that produce stems (that is, 
lexical morphemes, identified as being six or 
more in number). We collapse two templates if 
the productions of the corresponding states 
satisfy the following conditions: if the states 
generate stems, then the intersection of the 
productions must be at least two stems, while if 
the states are grammatical morphemes, then the 
productions of one pair of corresponding states 
must be identical, while for the other pair, the 
symmetric difference of the productions must be 
no greater than two in number (that is, the 
number of morphemes produced by the state of 
one template but not the other must not exceed 
2).  
3.3 Reparsing words in the corpus and 
predicting new words 
When we create robust FSAs?that is, FSAs that 
generate a large number of words?we are in a 
position to go back to the corpus and reanalyze a 
large number of words that could not be 
previously analyzed. That is, a 4-state FSA in 
which each state produced two strings generates 
8 words, and all 8 words must appear in the 
corpus for the method described so far in order 
for this particular FSA to generate any of them. 
But that condition is unlikely to be satisfied for 
any but the most common of morphemes, so we 
need to go back to the corpus and infer the 
existence of new stems (as defined operationally 
in the preceding paragraph) based on their 
occurrence in several, but not all possible, 
words.  If there exist 3 distinct words in the 
corpus which would all be generated by a 
template if a given stem were added to the 
template, we add that stem to the template. 
4 Experiments and Results 
In this section, we present three sets of 
evaluations of the refinements of the SED 
heuristics described in the preceding section. We 
used a corpus of 7,180 distinct words occurring 
in 50,000 running words from a Swahili 
translation of the Bible obtained on the internet. 
4.1 Disambiguating FSAs 
In order to evaluate the effects of the 
disambiguating of FSAs described in section 
3.1, we compare precision and recall of the 
identification of morpheme boundaries using the 
SED method with and without the 
disambiguation procedure described above. In 
Figures 1 and 2, we graph precision and recall 
for the top 10% of the templates, displayed as 
the leftmost point, for the top 20% of the 
templates, displayed as the second point from 
the left; and so on, because the higher ranked 
FSAs are more intrinsically more reliable than 
the lower ranked ones. We see that 
disambiguation repairs almost 50% of the 
previous errors, and increases recalls by about 
10%. With these increases in precision and 
recall, it is clear that the disambiguating step 
provides a considerably more accurate 
morpheme boundary discovery procedure. 
Precision
0.7
0.75
0.8
0.85
0.9
0.95
1
10 20 30 40 50 60 70 80 90 10
0
Deciles(%)
Pr
ec
is
io
n
Without
With
 
Figure 1 Comparison of precision 
 
Compare Recalls 
0.3
0.34
0.38
0.42
0.46
0.5
10 20 30 40 50 60 70 80 90 100
Deciles(%)
R
ec
al
ls
Without
With
Figure 2 Comparison of recall 
33
4.2 Template collapsing 
The second refinement discussed above 
consists of finding pairs of similar templates, 
collapsing them as appropriate, and thus creating 
patterns that generate new words that did not 
participate in the formation of the original 
templates. These new words may or may not 
themselves appear in the corpus. We are, 
however, able to judge their morphological well-
formedness by inspection. We list in Table 3 the 
entire list of eight templates that are collapsed in 
this step. 
All of the templates which are collapsed in 
this step are in fact of the same morphological 
structure (with one very minor exception4): they 
are of the form subject marker + tense marker + 
stem, and the collapsing induced in this 
procedure correctly creates larger templates of 
precisely the same structure, generating new 
words not seen in the corpus that are in fact 
correct from our (non-native speaker) 
inspection. We submitted the new words to 
Yahoo to test the words ?existence? by their 
existence on the internet, and actually found an 
average of 87% of the predicted words in a 
template; see the last column in Table 3 for 
details. 
4.3 Reparsing 
After previous refinements, we obtain a 
number of robust FSAs, for example, those 
collapsed templates in Table 3. With them, we 
then search the corpus for those words that can 
only be partly fitted into these FSAs and 
generate associated stems. Table 4 shows the 
reparsed words that had not been parsed by 
earlier templates and also newly added stems for 
some robust FSAs (the four collapsed templates 
in Table 3).  Stems such as anza ?begin? and 
fanya ?do? are thus added to the first template, 
and all words derived by prepending a tense 
marker and a subject marker are indeed accurate 
words. As the words in Table 4 suggest, the 
reparsing process adds new, common stems to 
the stem-column of the templates, thus making it 
                                                     
4 The exception involves the distinct morpheme po, a 
subordinate clause marker which must ultimately be 
analyzed as appearing in a distinct template column to the 
right of the tense markers. 
easier for the collapsing function to find 
similarities across related templates. 
In future work, we will take use the larger 
templates, populated with more stems, and input 
them to the collapsing function described in 3.2.  
5 Conclusions 
On the basis of the experiments with Swahili 
described in this paper, the SED heuristic 
appears to be a useful tool for the discovery of 
morphemes in languages with rich 
morphologies, and for the discovery of the FSAs 
that constitute the morphologies of those 
languages. 
Ultimately, the value of the heuristic is best 
tested against a range of languages with complex 
concatenative morphologies. While a thorough 
discussion would take us well beyond the limits 
of this paper, we have applied the SED heuristic 
to English, Hungarian, and Finnish as well as 
Swahili. For English, unsurprisingly, the method 
works as well as the SF and PF methods, though 
a bit more slowly, while for Hungarian and 
Finnish, the results appear promising, and a 
comparison with Creutz and Lagus (2004) for 
Finnish, for example, would be appealing. 
34
 
  
One Template 
 
The other template Collapsed Template 
% found on 
Yahoo search 
1 {a}-{ka,na}-{stems} {a}-{ka,ki}-{stems} {a}-{ka,ki,na}-{stems} 86 (37/43) 
2 {wa}-{ka,na}-{stems} {wa}-{ka,ki}-{stems} {wa}-{ka,ki,na}-{stems} 95 (21/22) 
3 {a}-{ka,ki,na}-{stems} {wa}-{ka,ki,na}-{stems} {a,wa}-{ka,ki,na}-{stems} 84 (154/183) 
4 {a}-{liye,me}-{stems} {a}-{liye,li}-{stems} {a}-{liye,li,me}-{stems} 100 (21/21) 
5 {a}-{ki,li}-{stems} {wa}-{ki,li}-{stems} {a,wa}-{ki,li}-{stems} 90 (36/40) 
6 {a}-{lipo,li}-{stems} {wa}-{lipo,li}-{stems} {a,wa}-{lipo,li}-{stems} 90 (27/30) 
7 {a,wa}-{ki,li}-{stems} {a,wa}-{lipo,li}-{stems} {a,wa}-{ki,lipo,li}-{stems} 74 (52/70) 
8 {a}-{na,naye}-{stems} {a}-{na,ta}-{stems} {a}-{na,ta,naye}-{stems} 80 (12/15) 
Table 3  Collapsed Templates and Created Words Sample. 
 
 
 
 
 Template Reparsed Words Not Parsed 
Before 
Added Stems  
1 {a, wa}-{ka,ki,na}-{stems} akawakweza, akiwa, anacho, 
akibatiza,  ? 
toka, anza, waita, fanya, enda, ? 
2 {a}-{li,liye,me }-{stems} ameinuka, ameugua, alivyo,  
aliyoniagiza,  ? 
zaliwa, kuwa, fanya, sema 
3 {a, wa}-{ki,li,lipo}-{stems} alimtoboa,  alimtaka,  
waliamini,  ? 
pata, kuwa, kaa, fanya, chukua, 
fika, ? 
4 {a} ? {na,naye,ta}-{stems} analazwa,  atanitukuza,  anaye,  
anakuita,   ? 
ingia, sema 
Table 4 Reparsed words and "discovered" stems 
 
References 
Creutz, Mathias, and Krista Lagus. (2004). Induction 
of a simple morphology for highly inflecting 
languages. Proceedings of the Workshop of 
SIGPHON (Barcelona). 
Dahan, Delphine, and Michael Brent. (1999). On the 
discovery of novel world-like units from 
utterances. Journal of Experimental Psychology: 
General  128: 165-185. 
Goldsmith, John. (2001).  Unsupervised Learning of 
the Morphology of a Natural Language. 
Computational Linguistics 27(2): 153-198. 
Goldsmith, John, Yu Hu, Irina Matveeva, and Colin 
Sprague. 2005. A heuristic for morpheme 
discovery based on string edit distance. Technical 
Report TR-2005-4. Department of Computer 
Science. University of Chicago. 
Hafer, M. A., Weiss, S. F.  (1974). Word 
segmentation by letter successor varieties. 
Information Storage and Retrieval 10: 371-385. 
Harris, Zellig. (1955). From Phoneme to Morpheme. 
Language 31: 190-222. 
Harris, Zellig. (1967). Morpheme Boundaries within 
Words: Report on a Computer Test. 
Transformations and Discourse Analysis Papers 
73.  
Oliver, Antoni, Irene Bastell?n, and Llu?s M?rquez. 
(2003). Uso de Internet para aumentar la cobertura 
de un sistema de adquisici?n l?xica del ruso. 
SEPLN 2003. 
Wagner, R. A., Fischer, M. J.  (1974). The string-to-
string correction problem. Journal of the 
Association for Computing Machinery 21(1): 168-
73. 
van Zaanen,  Menno. 2000. ABL: Alignment-Based 
Learning. Proceedings of the 17th Conference on 
Computational Linguistics, vol. 2. p. 961-67.
 
35
Proceedings of the Eighth Meeting of the ACL Special Interest Group on Computational Phonology at HLT-NAACL 2006, pages 32?40,
New York City, USA, June 2006. c?2006 Association for Computational Linguistics
Exploring variant definitions of pointer length in MDL
Aris Xanthos
Department of Linguistics
University of Chicago
Chicago IL 60637
axanthos@uchicago.edu
Yu Hu
Department of
Computer Science
University of Chicago
Chicago IL 60637
yuhu@uchicago.edu
John Goldsmith
Departments of Linguistics and
Computer Science
University of Chicago
Chicago IL 60637
goldsmith@uchicago.edu
Abstract
Within the information-theoretical frame-
work described by (Rissanen, 1989; de
Marcken, 1996; Goldsmith, 2001), point-
ers are used to avoid repetition of phono-
logical material. Work with which we
are familiar has assumed that there is only
one way in which items could be pointed
to. The purpose of this paper is to de-
scribe and compare several different meth-
ods, each of which satisfies MDL?s ba-
sic requirements, but which have different
consequences for the treatment of linguis-
tic phenomena. In particular, we assess
the conditions under which these different
ways of pointing yield more compact de-
scriptions of the data, both from a theoret-
ical and an empirical perspective.
1 Introduction
The fundamental hypothesis underlying the Mini-
mum Description Length (MDL) framework (Rissa-
nen, 1989; de Marcken, 1996; Goldsmith, 2001) is
that the selection of a model for explaining a set of
data should aim at satisfying two constraints: on the
one hand, it is desirable to select a model that can be
described in a highly compact fashion; on the other
hand, the selected model should make it possible to
model the data well, which is interpreted as being
able to describe the data in a maximally compact
fashion. In order to turn this principle into an op-
erational procedure, it is necessary to make explicit
the notion of compactness. This is not a trivial prob-
lem, as the compactness (or conversely, the length)
of a description depends not only on the complexity
of the object being described (in this case, either a
model or a set of data given a model), but also on
the ?language? that is used for the description.
Consider, for instance, the model of morphology
described in Goldsmith (2001). In this work, the
data consist in a (symbolically transcribed) corpus
segmented into words, and the ?language? used to
describe the data contains essentially three objects:
a list of stems, a list of suffixes, and a list of sig-
natures, i.e. structures specifying which stems asso-
ciate with which suffixes to form the words found in
the corpus. The length of a particular model (or mor-
phology) is defined as the sum of the lengths of the
three lists that compose it; the length of each list is in
turn defined as the sum of the lengths of elements in
it, plus a small cost for the list structure itself1. The
length of an individual morpheme (stem or suffix) is
taken to be proportional to the number of symbols in
it.
Calculating the length of a signature involves the
notion of pointer, with which this paper is primar-
ily concerned. The function of a signature is to re-
late a number of stems with a number of suffixes.
Since each of these morphemes is spelled once in
the corresponding list, there is no need to spell it
again in a signature that contains it. Rather, each
signature comprises a list of pointers to stems and
a list of pointers to suffixes. A pointer is a sym-
bol that stands for a particular morpheme, and the
recourse to pointers relies on the assumption that
1More on this in section 2.1 below
32
their length is lesser than that of the morphemes
they replace. Following information-theoretic prin-
ciples (Shannon, 1948), the length of a pointer to a
morpheme (under some optimal encoding scheme)
is equal to -1 times the binary logarithm of that mor-
pheme?s probability. The length of a signature is the
sum of the lengths of the two lists it contains, and
the length of each list is the sum of the lengths of
the pointers it contains (plus a small cost for the list
itself).
This work and related approaches to unsupervised
language learning have assumed that there is only
one way in which items could be pointed to, or iden-
tified. The purpose of this paper is to describe, com-
pare and evaluate several different methods, each of
which satisfies MDL?s basic requirements, but which
have different consequences for the treatment of lin-
guistic phenomena. One the one hand, we contrast
the expected description length of ?standard? lists of
pointers with polarized lists of pointers, which are
specified as either (i) pointing to the relevant mor-
phemes (those that belong to a signature, or undergo
a morpho-phonological rule, for instance) or (ii)
pointing to their complement (those that do not be-
long to a signature, or do not undergo a rule). On the
other hand, we compare (polarized) lists of pointers
with a method based on binary strings specifying
each morpheme as relevant or not (for a given sig-
nature, rule, etc.). In particular, we discuss the con-
ditions under which these different ways of pointing
are expected to yield more compact descriptions of
the data.
The remainder of this paper is organized as fol-
lows. In the next section, we give a formal review
of the standard treatment of lists of pointers as de-
scribed in (Goldsmith, 2001); then we successively
introduce polarized lists of pointers and the method
of binary strings, and make a first, theoretical com-
parison of them. Section three is devoted to an em-
pirical comparison of these methods on a large nat-
ural language corpus. In conclusion, we discuss the
implications of our results in the broader context of
unsupervised language learning.
2 Variant definitions of pointers
In order to simplify the following theoretical discus-
sion, we temporarily abstract away from the com-
plexity of a full-blown model of morphology. Given
a set of N stems and their distribution, we consider
the general problem of pointing to a subset of M
stems (with 0 < M ? N ), first by means of ?stan-
dard? lists of pointers, then by means of polarized
ones, and finally by means of binary strings.
2.1 Expected length of lists of pointers
Let ? denote a set of N stems; we assume that the
length of a pointer to a specific stem t ? ? is its
inverse log probability ? log pr(t).2 Now, let {M}
denote the set of all subsets of ? that contain exactly
0 < M ? N stems. The description length of a
list of pointers to a particular subset ? ? {M} is
defined as the sum of the lengths of the M pointers
it contains, plus a small cost of for specifying the list
structure itself, defined as ?(M) := 0 if M = 0 and
logM bits otherwise3:
DLptr(?) := ?(M)?
?
t??
log pr(t)
The expected length of a pointer is equal to the
entropy over the distribution of stems:
hstems := Et?? [? log pr(t)] = ?
?
t??
pr(t) log pr(t)
Thus, the expected description length of a list of
pointers to M stems (over all subsets ? ? {M})
is:
E??{M} [DLptr(?)] = 1|{M}|
?
??{M}
DLptr(?)
= ?(M) +Mhstems
(1)
This value increases as a function of both the num-
ber of stems which are pointed to and the entropy
over the distribution of stems. Since 0 ? hstems ?
logN , the following bounds hold:
0 ? hstems ? E??{M} [DLptr(?)]
? logN +Nhstems ? (N + 1) logN
2Here and throughout the paper, we use the notation log x
to refer to the binary logarithm of x; thus entropy and other
information-theoretic quantities are expressed in terms of bits.
3Cases where the argument of this function can have the
value 0 will arise in the next section.
33
2.2 Polarization
Consider a set of N = 3 equiprobable stems, and
suppose that we need to specify that a given morpho-
phonological rule applies to one of them. In this con-
text, a list with a single pointer to a stem requires
log 1 ? log 13 = 1.58 bits. Suppose now that the
rule is more general and applies to two of the three
stems. The length of the new list of pointers is thus
log 2 ? 2 log 13 = 4.17 bits. It appears that for such
a general rule, it is more compact to list the stems to
which it does not apply, and mark the list with a flag
that indicates the ?negative? meaning of the point-
ers. Since the flag signals a binary choice (either the
list points to stems that undergo the rule, or to those
that do not), log 2 = 1 bit suffices to encode it, so
that the length of the new list is 1.58 + 1 = 2.58
bits.
We propose to use the term polarized to refer to
lists of pointers bearing a such flag. If it is useful to
distinguish between specific settings of the flag, we
may speak of positive versus negative lists of point-
ers (the latter being the case of our last example).
The expected description length of a polarized list
of M pointers is:
E??{M} [DLpol(?)] = 1 + ?(M?) + M?hstems
with M? := min(M,N ?M)
(2)
From (1) and (2), we find that in general, the ex-
pected gain in description length by polarizing a list
of M pointers is:
E??{M} [DLptr(?)?DLpol(?)]
=
?
??
??
?1 iff M ? N2
?1 + ?(M)? ?(N ?M) + (2M ?N)hstems
otherwise
Thus, if the number of stems pointed to is lesser than
or equal to half the total number of stems, using a
polarized list rather than a non-polarized one means
wasting exactly 1 bit for encoding the superfluous
flag. If the number of stems pointed to is larger than
that, we still pay 1 bit for the flag, but the reduced
number of pointers results in an expected saving of
?(M) ? ?(N ? M) bits for the list structure, plus
(2M ?N) ? hstems bits for the pointers themselves.
Now, let us assume that we have no informa-
tion regarding the number M of elements which are
0 500 1000 1500 2000
0
100
0
300
0
500
0
Polarized vs. non?polarized lists
Total number of stems N
De
scr
ipti
on 
len
gth
 ga
in (i
n bi
ts)
s=0
s=1
s=2
s=10
Figure 1: Expected gain in description length by us-
ing polarized rather than non-polarized lists of point-
ers.
pointed to, i.e. that it has a uniform distribution be-
tween 1 and N (M ? U [1, N ]). Let us further as-
sume that stems follow a Zipfian distribution of pa-
rameter s, so that the probability of the k-th most
frequent stem is defined as:
f(k,N, s) := 1/k
s
HN,s with HN,s :=
N?
n=1
1/ns
where HN,s stands for the harmonic number of order
N of s. The entropy over this distribution is:
hZipfN,s :=
s
HN,s
N?
k=1
log k
ks + logHN,s
Armed with these assumptions, we may now com-
pute the expected description length gain of polar-
ization (over all values of M ) as a function of N
and s:
EM
(E??{M} [DLptr(?)?DLpol(?)]
)
=?1+ 1N
?N
M=1 ?(M)? ?(M?) + (M ? M?)hZipfN,s
Figure 1 shows the gain calculated for N = 1,
400, 800, 1200, 1600 and 2000, and s = 0, 1, 2
and 10. In general, it increases with N , with a
slope that depends on s: the greater the value of s,
the lesser the entropy over the distribution of stems;
since the entropy corresponds to the expected length
34
Figure 2: Two ways of pointings to stems: by means
of a polarized list of pointers, or a binary string.
of a pointer, its decrease entails a decrease in the
number of bits that can be saved by using polarized
lists (which generally use less pointers). However,
even for an aberrantly skewed distribution of stems4,
the expected gain of polarization remains positive.
Since the value of s is usually taken to be slightly
greater than 1 for natural languages (Mandelbrot,
1953), it seems that polarized lists generally entail
a considerable gain in description length.
2.3 Binary strings
Consider again the problem of pointing to one out
of three equiprobable stems. Suppose that the list of
stems is ordered, and that we want to point to the
first one, for instance. An alternative to the recourse
to a list of pointers consists in using a binary string
(in this case 100) where the i-th symbol is set to 1
(or +) if the i-th stem is being pointed to, and to 0
(or -) otherwise. Figure 2 gives a schematic view of
these two ways of pointing to items.
There are two main differences between this
method and the previous one. On the one hand,
the number of symbols in the string is constant and
equal to the total number N of stems, regardless of
the number M of stems that are pointed to. On the
other hand, the compressed length of the string de-
pends on the distribution of symbols in it, and not on
the distribution of stems. Thus, by comparison with
the description length of a list of pointers, there is a
loss due to the larger number of encoded symbols,
and a gain due to the use of an encoding specifically
4In the case s = 10, the probability of the most frequent
stem is .999 for N = 2000.
tailored for the relevant distribution of pointed ver-
sus ?unpointed? elements.
The entropy associated with a binary string is en-
tirely determined by the number of 1?s it contains,
i.e. the number M of stems which are pointed to,
and the length N of the string:
hbinN,M := ?
M
N log
M
N ?
N ?M
N log
N ?M
N
The compressed length of a binary string pointing to
M stems is thus:
DLbin(M) := NhbinN,M (3)
It is maximal and equal to N bits when M = N2 ,
and minimal and equal to 0 when M = N , i.e. when
all stems have a pointer on them. Notice that binary
strings are intrinsically polarized, so that intervert-
ing 0?s and 1?s results in the same description length
regardless of their distribution.5
The question naturally arises, under which con-
ditions would binary strings be more or less com-
pact than polarized lists of pointers. If we assume
again that the distribution of the number of elements
pointed to is uniform and the distribution of stems is
Zipfian of parameter s, (2) and (3) justify the follow-
ing expression for the expected description length
gain by using binary strings rather than polarized
lists (as a function of N and s):
EM
[E??{M}[DLpol(?)]?DLbin(M)
]
= 1 + 1N
?N
M=1 ?(M?) + M?hZipfN,s ?NhbinN,M
Figure 3 shows the gain calculated for N = 1, 400,
800, 1200, 1600 and 2000, and s = 0, 1, 2 and 3.
For s small, i.e. when the entropy over the distri-
bution of stems is greater or not much lesser than
that of natural languages, the description length of
binary strings is considerably lesser than that of po-
larized lists. The difference decreases as s increases,
5As one the reviewers has indicated to us, the binary strings
approach is actually very similar to the method of combinato-
rial codes described by (Rissanen, 1989). This method con-
sists in pointing to one among  NM
 possible combinations of
M stems out of N . Under the assumption that these combi-
nations have a uniform probability, the cost for pointing to M
stems is log  NM
 bits, which is in general slightly lesser than
the description length of the corresponding binary string (the
difference being maximal for M = N/2, i.e. when the binary
string encoding cannot take advantage of any compression).
35
0 500 1000 1500 2000
?
100
0
0
100
0
300
0
Binary strings vs. polarized lists(uniform distribution of M)
Total number of stems N
De
scr
ipti
on 
len
gth
 ga
in (i
n bi
ts)
s=0
s=1
s=2
s=3
Figure 3: Expected gain in description length by us-
ing binary strings rather than polarized lists under
the assumption that M ? U [1, N ].
until at some point (around s = 2), the situation re-
verses and polarized lists become more compact. In
both cases, the trend increases with the number N
of stems (within the range of values observed).
By contrast, it is instructive to consider a case
where the distribution of the number of elements
pointed to departs from uniformity. For instance, we
can make the assumption that M follows a binomial
distribution (M ? B[N, p]).6 Under this assump-
tion (and, as always, that of a Zipfian distribution of
stems), the expected description length gain by us-
ing binary strings rather than polarized lists is:
EM
[E??{M}[DLptr(?)]?DLbin(M)
]
= ?NM=1 pr(M)
(
1+?(M?)+M?hZipfN,s?NhbinN,M
)
with pr(M) = (NM
)pM (1? p)N?M
Letting N and s vary as in the previous computation,
we set the probability for a stem to have a pointer on
it to p = 0.01, so that the distribution of pointed ver-
sus ?unpointed? elements is considerably skewed.7
6This model predicts that most of the time, the number M
of elements pointed to is equal to N ? p (where p denotes the
probability for a stem to have a pointer on it), and that the prob-
ability pr(M) of other values of M decreases as they diverge
from N ? p.
7By symmetry, the same results would be found with p =
0.99.
0 500 1000 1500 2000
?
150
?
50
0
50
Binary strings vs. polarized lists(binomial distribution of M, p = 0.01)
Total number of stems N
De
scr
ipti
on 
len
gth
 ga
in (i
n bi
ts) s=0
s=1
s=2
s=3
Figure 4: Expected gain in description length by us-
ing binary strings rather than polarized lists under
the assumption that M ? B[N, 0.01].
As shown on figure 4, under these conditions, the ab-
solute value of the gain of using binary strings gets
much smaller in general, and the value of s for which
the gain becomes negative for N large gets close to 1
(for this particular value, it becomes positive at some
point between N = 1200 and N = 1600).
Altogether, under the assumptions that we have
used, these theoretical considerations suggest that
binary strings generally yield shorter description
lengths than polarized lists of pointers. Of course,
data for which these assumptions do not hold could
arise. In the perspective of unsupervised learning,
it would be particularily interesting to observe that
such data drive the learner to induce a different
model depending on the representation of pointers
being adopted.
It should be noted that nothing prevents binary
strings and lists of pointers from coexisting in a sin-
gle system, which would select the most compact
one for each particular case. On the other hand, it is
a logical necessity that all lists of pointers be of the
same kind, either polarized or not.
3 Experiments
In the previous section, by assuming frequencies of
stems and possible distributions of M (the num-
ber of stems per signature), we have explored the-
oretically the differences between several encoding
36
0 500 1000 1500 2000 25000
.00
00
0.0
010
0.0
020
Frequency as a function of rank
 (English corpus)
Rank
Fre
que
ncy
Figure 5: Frequency versus rank (stems) in English
corpus.
methods in the MDL framework. In this section, we
apply these methods to the problem of suffix discov-
ery in natural language corpora, in order to verify the
theoretical predictions we made previously. Thus,
the purpose of these experiments is not to state that
one encoding is preferable to the others; rather, we
want to answer the three following questions:
1. Are our assumptions on the frequency of stems
and size of signatures appropriate for natural
language corpora?
2. Given these assumptions, do our theoretical
analyses correctly predict the difference in de-
scription length of two encodings?
3. What is the relationship between the gain in de-
scription length and the size of the corpus?
3.1 Experimental methodology
In this experiment, for the purpose of calculating
distinct description lengths while using different en-
coding methods, we modified Linguistica8 by imple-
menting list of pointers and binary strings as alter-
native means to encode the pointers from signatures
to their associated stems9. As a result, given a set
8The source and binary files can be freely downloaded at
http://linguistica.uchicago.edu.
9Pointers to suffixes are not considered here.
0 50 100 150 200
0.0
0.1
0.2
0.3
0.4
0.5
Distribution of the number of stems
 per signature (English corpus)
Number of stems
Pro
por
tion
 of 
sig
nat
ure
s
Figure 6: Distribution of number of stems per signa-
ture (English corpus)
of signatures, we are able to compute a description
length for each encoding methods.
Within Linguistica, the morphology learning pro-
cess can be divided into a sequence of heuristics,
each of which searches for possible incremental
modifications to the current morphology. For exam-
ple, in the suffix-discovery procedure, ten heuristics
are carried out successively; thus, we have a dis-
tinct set of signatures after applying each of the ten
heuristics. Then, for each of these sets, we encode
the pointers from each signature to its correspond-
ing stems in three rival ways: as a list of pointers
(polarized or not), as traditionally understood, and
as a binary string. This way, we can compute the to-
tal description length of the signature-stem-linkage
for each of the ten sets of signatures and for each of
three two ways of encoding the pointers. We also
collect statistics on word frequencies and on the dis-
tribution of the size of signatures M , i.e. the number
M of stems which are are pointed to, both of which
are important parametric components in our theoret-
ical analysis.
Experiments are carried out on two orthographic
corpora (English and French), each of which has
100,000 word tokens.
3.2 Frequency of stems and size of signatures
The frequency of stems as a function of their rank
and the distribution of the size of signatures are plot-
37
0 100 200 300 400 500 6000
.00
00
0.0
010
0.0
020
Frequency as a function of rank
 (French corpus)
Rank
Fre
que
ncy
Figure 7: Frequency versus rank (stems) in French
corpus.
ted in figures 5 and 6 for the English corpus, and in
figures 7 and 8 for the French corpus. These graphs
show that in both the English and the French cor-
pora, stems appear to have a distribution similar to a
Zipfian one. In addition, in both corpora, M follows
a distribution whose character we are not sure of, but
which appears more similar to a binomial distribu-
tion. To some extent, these observations are consis-
tent with the assumptions we made in the previous
theoretical analysis.
3.3 Description length of each encoding
The description length obtained with each encoding
method is displayed in figures 9 (English corpus)
and 10 (French corpus), in which the x-axis refers to
the set of signatures resulting from the application
of each successive heuristics, and the y-axis corre-
sponds to the description length in bits. Note that
we only plot description lengths of non-polarized
lists of pointers, because the number of stems per
signature is always less than half the total number of
stems in these data (and we expect that this would
be true for other languages as well).10
These two plots show that in both corpora, there is
always a gain in description length by using binary
strings rather than lists of pointers for encoding the
pointers from signatures to stems. This observation
is consistent with our conclusion in section 2.3, but
10See figures 6 and 8 as well as section 2.2 above.
0 50 100 150
0.0
0.1
0.2
0.3
0.4
0.5
Distribution of the number of stems
 per signature (French corpus)
Number of stems
Pro
por
tion
 of 
sig
nat
ure
s
Figure 8: Distribution of number of stems per signa-
ture (French corpus)
it is important to emphasize again that for other data
(or other applications), lists of pointers might turn
out to be more compact.
3.4 Description length gain as a function of
corpus size
In order to evaluate the effect of corpus size on
the gain in description length by using binary string
rather than lists of variable-length pointers, we ap-
plied Linguistica to a number of English corpora of
different sizes ranging between 5,000 to 200,000 to-
kens. For the final set of signatures obtained with
each corpus, we then compute the gain of binary
strings encoding over lists of pointers as we did in
the previous experiments. The results are plotted in
figure 11.
This graph shows a strong positive correlation be-
tween description length gain and corpus size. This
is reminiscent of the results of our theoretical simu-
lations displayed in figures 3 and 4. As before, we
interpret the match between the experimental results
and the theoretical expectations as evidence support-
ing the validity of our theoretical predictions.
3.5 Discussion of experiments
These experiments are actually a number of case
studies, in which we verify the applicability of our
theoretical analysis on variant definitions of pointer
lengths in the MDL framework. For the particu-
38
2 4 6 8 10
0
200
00
600
00
DL of lists and binary strings(English corpus)
Heuristics
De
scr
ipti
on 
len
gth
 (in 
bits)
ListsBinary strings
1 3 5 7 9
Figure 9: Comparison of DL of 10 successive mor-
phologies using pointers versus binary strings (En-
glish corpus).
lar application we considered, learning morphology
with Linguistica, binary strings encoding proves to
be more compact than lists of variable-length point-
ers. However, the purpose of this paper is not to
predict that one variant is always better, but rather to
explore the mathematics behind different encodings.
Armed with the mathematical analysis of different
encodings, we hope to be better capable of making
the right choice under specific conditions. In partic-
ular, in the suffix-discovery application (and for the
languages we examined), our results are consistent
with the assumptions we made and the predictions
we derived from them.
4 Conclusion
The overall purpose of this paper has been to illus-
trate what was for us an unexpected aspect of us-
ing Minimum Description Length theory: not only
does MDL not specify the form of a grammar (or
morphology), but it does not even specify the pre-
cise form in which the description of the abstract
linkages between concepts (such as stems and sig-
natures) should be encoded and quantitatively eval-
uated. We have seen that in a range of cases, us-
ing binary strings instead of the more traditional
frequency-based pointers leads to a smaller overall
grammar length, and there is no guarantee that we
will not find an even shorter way to accomplish the
2 4 6 8 10
0
500
0
100
00
150
00
DL of lists and binary strings(French corpus)
Heuristics
De
scr
ipti
on 
len
gth
 (in 
bits)
ListsBinary strings
1 3 5 7 9
Figure 10: Comparison of DL of 10 successive
morphologies using pointers versus binary strings
(French corpus)
same thing tomorrow11. Simply put, MDL is em-
phatically an evaluation procedure, and not a discov-
ery procedure.
We hope to have shown, as well, that a system-
atic exploration of the nature of the difference be-
tween standard frequency-based pointer lengths and
binary string based representations is possible, and
we can develop reasonably accurate predictions or
expectations as to which type of description will be
less costly in any given case.
Acknowledgements
This research was supported by a grant of the Swiss
National Science Foundation to the first author.
References
C. de Marcken. 1996. Unsupervised Language Acquisi-
tion. Ph.D. thesis, MIT, Cambridge, MA.
J. Goldsmith. 2001. The unsupervised learning of natu-
ral language morphology. Computational Linguistics,
27(2):153?198.
B. Mandelbrot. 1953. An informational theory of the
statistical structure of language. In Willis Jackson, ed-
itor, Communication Theory, the Second London Sym-
posium, pages 486?502. Butterworth: London.
11See note 5.
39
0 50000 100000 150000 200000
0
200
00
400
00
600
00
DL gain of binary strings vs. lists(English corpus)
Corpus size
De
scr
ipti
on 
len
gth
 ga
in (i
n bi
ts)
Figure 11: DL gain from using binary string versus
size of corpus (English corpus)
J. Rissanen. 1989. Stochastic Complexity in Statistical
Inquiry. World Scientific Publishing Co, Singapore.
C.E. Shannon. 1948. A mathematical theory of commu-
nication. Bell Systems Technical Journal, 27:379?423.
40
