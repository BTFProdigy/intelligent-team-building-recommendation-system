Proceedings of the ACL-08: HLT Workshop on Mobile Language Processing, pages 10?12,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
A Wearable Headset Speech-to-Speech Translation System 
 
 
Kriste Krstovski, Michael Decerbo, Rohit Prasad, David Stallard, Shirin Saleem, 
Premkumar Natarajan 
Speech and Language Processing Department 
BBN Technologies 
10 Moulton Street, Cambridge, MA, 02138 
{krstovski, mdecerbo, rprasad, stallard, ssaleem, prem}@bbn.com 
 
 
 
 
Abstract 
In this paper we present a wearable, headset 
integrated eyes- and hands-free speech-to-
speech (S2S) translation system. The S2S sys-
tem described here is configured for translin-
gual communication between English and 
colloquial Iraqi Arabic. It employs an n-gram 
speech recognition engine, a rudimentary 
phrase-based translator for translating recog-
nized Iraqi text, and a rudimentary text-to-
speech (TTS) synthesis engine for playing 
back the English translation. This paper de-
scribes the system architecture, the functional-
ity of its components, and the configurations 
of the speech recognition and machine transla-
tion engines.  
1 Background 
Humanitarian personnel, military personnel, and 
visitors in foreign countries often need to commu-
nicate with residents of a host country. Human in-
terpreters are inevitably in short supply, and 
training personnel to speak a new language is diffi-
cult. Under the DARPA TRANSTAC and Babylon 
programs, various teams have developed systems 
that enable two-way communication over a lan-
guage barrier (Waibel et al, 2003; Zhou et al, 
2004; Stallard et al, 2006). The two-way speech-
to-speech (S2S) translation systems seek, in prin-
ciple, to translate any utterance, by using general 
statistical models trained on large amounts of 
speech and text data.  
The performance and usability of such two-way 
speech-to-speech (S2S) translation systems is 
heavily dependent on the computational resources, 
such as processing power and memory, of the plat-
form they are running on. To enable open-ended 
conversation these S2S systems employ powerful 
but highly memory- and computation-intensive 
statistical speech recognition and machine transla-
tion models. Thus, at the very minimum they re-
quire the processing and memory configuration of 
common-of-the-shelf (COTS) laptops.  
Unfortunately, most laptops do not have a form 
factor that is suitable for mobile users. The size, 
weight, and shape of laptops render them unsuit-
able for handheld use. Moreover, simply carrying 
the laptop can be infeasible for users, such as mili-
tary personnel, who are already overburdened with 
other equipment. Embedded platforms, on the 
other hand, offer a more suitable form factor in 
terms of size and weight, but lack the computa-
tional resources required to run more open-ended 
2-way S2S systems. 
In previous work, Prasad et al (2007) reported 
on the development of a S2S system for Windows 
Mobile based handheld computers. To overcome 
the challenges posed by the limited resources of 
that platform, the PDA version of the S2S system 
was designed to be more constrained in terms of 
the ASR and MT vocabulary. As described in de-
tail in (Prasad et al, 2007), the PDA based S2S 
system configured for English/Iraqi S2S translation 
delivers fairly accurate translation at faster than 
real-time.  
In this paper, we present ongoing development 
work on an S2S system that runs on an even more 
constrained hardware platform; namely, a proces-
sor embedded in a wearable headset with just 32 
MB of memory. Compared to the PDA based sys-
10
tem described in (Prasad et al, 2007), the wearable 
system is designed for both eyes- and hands-free 
operation. The headset-integrated translation de-
vice described in this paper is configured for two-
way conversation in English/Iraqi. The target do-
main is the force protection, which includes sce-
narios of checkpoints, house searches, civil affairs, 
medical, etc.   
In what follows, we discuss the hardware and 
software details of the headset-integrated transla-
tion device. 
2 Hardware Platform  
The wearable S2S system described in this paper 
runs on a headset-integrated computational plat-
form developed by Integrated Wave Technologies, 
Inc. (IWT). The headset-integrated platform em-
ploys a 200 MHz StrongARM integer processor 
with a total of just 32MB RAM available for both 
the operating system and the translation software. 
The operating system currently running on the 
platform is Embedded Linux. 
There are two audio cards on the headset plat-
form for two-way communication through separate 
audio input and output channels. The default sound 
card uses the headset integrated close-talking mi-
crophone as an audio input and the second audio 
card can be used with an ambient microphone 
mounted on the device or an external microphone. 
In addition, each headset earpiece contains inner 
and outer set of speakers. The inner earpiece 
speakers are for the English speaking user who 
wears the headset, whereas the outer speakers are 
for the foreign language speaker who is not re-
quired to wear the headset. 
3 Software Architecture 
Depicted in Figure 1 is the software system archi-
tecture for the headset-integrated wearable S2S 
system. We are currently using a fixed-phrase Eng-
lish-to-Iraqi speech translation module from IWT 
for translating from English to Iraqi. In the Iraqi-
to-English (I2E) direction, we use an n-gram ASR 
engine to recognize Iraqi speech, a custom, phrase-
based ?micro translator? for translating Iraqi text to 
English text, and finally a TTS module for convert-
ing the English text into speech.  The rest of this 
paper focuses on the components of the Iraqi-to-
English translation module. 
 
Fixed point ASR Engine: The ASR engine uses 
phonetic hidden Markov models (HMM) with one 
or more forms of the following parameter tying: 
Phonetic-Tied Mixture (PTM), State-Tied Mixture 
(STM), and State-Clustered-Tied Mixture (SCTM) 
models. 
For the headset-integrated platform, we use a 
fixed-point ASR engine described in (Prasad et al, 
2007). As in (Prasad et al, 2007) for real-time per-
formance we use the compact PTM models in both 
recognition passes of our two-pass ASR decoder. 
Phrase-based Micro Translator: Phrase-based 
statistical machine translation (SMT) has been 
widely adopted as the translation engine in S2S 
systems. Such SMT engines require only a large 
corpus of bilingual sentence pairs to deliver robust 
performance on the domain of that corpus. How-
ever, phrase-based SMT engines require significant 
amount of memory, even when configured for me-
dium vocabulary tasks. Given the limited memory 
on the headset platform, we chose to develop in-
stead a phrase-based ?micro translator? module, 
which acts like a bottom-up parser. The micro-
translator uses translation rules derived from our 
phrase-based SMT engine. Rules are created auto-
matically by running the SMT engine on a small 
training corpus and recording the phrase pairs it 
used in decoding it. These phrase pairs then be-
come rules which are treated just as though they 
had been written by hand. The micro translator 
currently makes no use of probabilities.  Instead, as 
shown in Figure 2, for any given Arabic utterance, 
the translator greedily chooses the longest match-
ing source phrase that does not overlap a source 
phrase already chosen. The target phrases for these 
source phrases are then output as the translation. 
These target phrases come out in source-language 
 
Figure 1. Software architecture of the S2S system. 
 
 
11
order, as no language model is currently used for 
reordering.  
The micro translator currently consists of 1300 
rules and 2000 words. Its memory footprint is just 
32KB. This small memory footprint is achieved by 
representing the rules in binary format rather than 
text format.  
 
 
English Playback using TTS: To play the Eng-
lish translation to the headset user we developed a 
rudimentary TTS module. The TTS module parses 
the output of the I2E translator to extract each 
translated word. It then uses the list of extracted 
words to read the appropriate pre-recorded (or syn-
thesized) audio. Once the word pronunciations au-
dio files are read we splice the beginning and the 
end of the audio files to reduce the amount of si-
lence and concatenate them into a single file which 
is then played to the user on the inner earphone 
speakers. 
The total memory footprint of our current Iraqi 
to English translation module running on the head-
set-integrated platform is just 9MB. The current 
configuration of the translation module?s Iraqi 
ASR engine yields word error rate (WER) of 20% 
on test-set utterances without out-of-vocabulary 
(OOV) words.  
4 Conclusions and Future Work 
In this paper we have presented the initial setup of 
a speech-to-speech translation system configured 
for the headset platform. Our current work is fo-
cused on expanding the vocabulary of the Iraqi-to-
English translation module by exploiting the rich 
morphology of Iraqi Arabic. In particular, we are 
investigating the use of morphemes (prefix, stems, 
and suffixes) for expanding the effective vocabu-
lary of the headset translator. We are also develop-
ing use cases for performing a formal evaluation of 
both the usability and performance of the headset 
translator. 
References  
Alex Waibel, Ahmed Badran, Alan W Black, Robert 
Frederking, Donna Gates ,Alon Lavie, Lori Levin, 
Kevin Lenzo, Laura Mayfield Tomokiyo, J?urgen 
Reichert, Tanja Schultz, Dorcas Wallace, Monika 
Woszczyna and Jing Zhang. 2003. ?Speechalator: 
Two-way Speech-to-Speech Translation on a Con-
sumer PDA,? Proc. 8th European Conference on 
Speech Communication and Technology 
(EUROSPEECH 2003), Geneva, Switzerland. 
Bowen Zhou, Daniel D?echelotte and Yuqing Gao. 
2004. ?Two-way Speech-to-Speech Translation on 
Handheld Devices,? Proc. 8th International Confer-
ence on Spoken Language Processing, Jeju Island, 
Korea. 
David Stallard, Frederick Choi, Kriste Krstovski, Prem 
Natarajan and Shirin Saleem. 2006. ?A Hybrid 
Phrase-based/Statistical Speech Translation System,? 
Proc. The 9th International Conference on Spoken 
Language Processing (Interspeech 2006 - ICSLP), 
Pittsburg, PA. 
David Stallard, John Makhoul, Frederick Choi, Ehry 
Macrostie, Premkumar Natarajan, Richard Schwartz 
and Bushra Zawaydeh. 2003. ?Design and Evaluation 
of a Limited two-way  Speech Translator,? Proc. 8th 
European Conference on Speech Communication and 
Technology (EUROSPEECH 2003), Geneva, Swit-
zerland. 
Rohit Prasad, Kriste Krstovski, Frederick Choi, Shirin 
Saleem, Prem Natarajan, Michael Decerbo and David 
Stallard. 2007. ?Real-Time Speech-to-Speech Trans-
lation for PDAs,? Proc. IEEE International Confer-
ence on Portable Information Devices (IEEE Portable 
2007), Orlando, FL. 
 
 
 
 
Figure 2.  Decoding in micro translator. 
 
12
Proceedings of the 6th Workshop on Statistical Machine Translation, pages 207?216,
Edinburgh, Scotland, UK, July 30?31, 2011. c?2011 Association for Computational Linguistics
A Minimally Supervised Approach for Detecting and Ranking Document 
Translation Pairs 
 
 
Kriste Krstovski David A. Smith 
Department of Computer Science  Department of Computer Science 
University of Massachusetts Amherst University of Massachusetts Amherst 
Amherst, MA 01003, USA Amherst, MA 01003, USA 
kriste@cs.umass.edu dasmith@cs.umass.edu 
 
 
 
 
 
 
Abstract 
We describe an approach for generating a 
ranked list of candidate document transla-
tion pairs without the use of bilingual dic-
tionary or machine translation system. We 
developed this approach as an initial, filter-
ing step, for extracting parallel text from 
large, multilingual?but non-parallel?
corpora. We represent bilingual documents 
in a vector space whose basis vectors are 
the overlapping tokens found in both lan-
guages of the collection. Using this repre-
sentation, weighted by tf?idf, we compute 
cosine document similarity to create a 
ranked list of candidate document transla-
tion pairs. Unlike cross-language informa-
tion retrieval, where a ranked list in the 
target language is evaluated for each source 
query, we are interested in, and evaluate, 
the more difficult task of finding translated 
document pairs. We first perform a feasi-
bility study of our approach on parallel col-
lections in multiple languages, representing 
multiple language families and scripts. The 
approach is then applied to a large bilingual 
collection of around 800k books. To avoid 
the computational cost of )( 2nO document 
pair comparisons, we employ locality sen-
sitive hashing (LSH) approximation algo-
rithm for cosine similarity, which reduces 
our time complexity to )log( nnO . 
1 Introduction 
A dearth of parallel data has been, and still is, a 
major problem for developing highly reliable sta-
tistical machine translation systems in many lan-
guages and domains. There have been many 
proposed approaches for alleviating this problem 
by utilizing techniques for creating and extracting 
parallel documents, sentences or phrases from 
comparable bilingual data available on the open 
web (Resnik and Smith, 2003), such as Wikipedia 
articles (Smith et. al, 2010), to name a few, or 
through digitized archives from various sources 
(Zhao and Vogel, 2002), (Munteanu and Marcu, 
2005). 
In general, in the process of utilizing comparable 
corpora to obtain sentence-aligned bilingual text, 
the first step involves performing initial filtering 
where text entities from both language collections 
are compared to each other and based on compari-
son score they are matched and grouped as poten-
tial translation candidate pairs. After this initial 
step, text entity pairs or tuples are further analyzed 
in order to extract parallel sentence pairs. In this 
paper we only focus on this initial step. We present 
a novel exploration of approaches that retrieve ac-
tual document translation pairs without the use of 
any bilingual resources such as lexicons or sen-
tence aligned bitext. 
Rather than solving separate retrieval or translation 
problems for each source language document, we 
retrieve translation pairs from the space of all pos-
sible bilingual document pairs. Most machine 
207
translation (MT) and information retrieval (IR) 
systems rely on conditional probabilities; in con-
trast, we require comparable scores or probabilities 
over all document pairs. To avoid directly comput-
ing the similarity of all pairs, we use a randomized 
approximation algorithm based on locality sensi-
tive hashing (LSH).  
For this joint approach, we represent each docu-
ment in both languages using an n-dimensional 
feature vector template which consists of the set of 
intersecting words which are found across all 
documents in both language collections. For each 
dimension i.e. word, in the feature vector template 
we calculate tf?idf score for the given document. 
Unlike other approaches, where documents or their 
word representations are first translated from for-
eign language to English using bilingual dictionary 
(Fung and Cheung, 2004), (Munteanu and Marcu, 
2005) and (Uszkoreit et. al., 2010) in our approach 
we don?t utilize any existing MT type artifact. In 
other words, for a given language pair we don?t use 
translation lexicon by training an existing statisti-
cal machine translation system using sentence 
aligned parallel bilingual data in the same language 
or existing translation lexicon. Earlier work done 
by Enright and Kondrak (2007) uses only hapax 
words to represent and rank (based on the overlap 
number) translation documents pair in a parallel 
bilingual collection which is an easier task to 
evaluation due to the presence of a one-to-one 
matching among the bilingual documents. Most 
recently, Patry and Langlais (2011) show an im-
provement over this method by using an IR system 
to first retrieve translation document candidates 
and then identify translation document pairs by 
training a classifier.  
We start off by giving detailed explanation of the 
above mentioned data representation. We then test 
the feasibility of our approach using aligned paral-
lel document data from three different bilingual 
collections in several languages and writing sys-
tems. Results from these tests are given in section 
3. The goal of developing our approach was to util-
ize it as an initial filtering step in developing paral-
lel corpora from large, multilingual collections, 
such as the collection of more than 800K English 
and German books we describe in section 4. Since 
we start with no information on the possible trans-
lation pairs in our large collection and in order to 
verify the potential of our method, we first show 
results on retrieving 17 known parallel book pairs 
embedded in a small randomly selected subset of 
1K books (section 4.1). Since performing cosine 
similarity across all document pairs is computa-
tionally expensive with time complexity of 
)( 2nO we utilize the LSH based approximation 
algorithm for the cosine similarity measurement 
based on the work by Ravichandran et. al (2005). 
A brief overview of this approach is given in Sec-
tion 5, which is followed by our implementation 
results explained and analyzed in section 6. To 
conclude the paper, we give a brief outlook on fu-
ture work. 
2 Document Representation 
In Figure 1, we depict the process that we use to 
represent documents from bilingual collections in 
vector space and perform similarity measurements. 
We start by computing a word frequency count for 
each of the documents in our collection and creat-
ing a word frequency list. For each language, we 
take a union of the words in each document?s fre-
quency list to construct a global word list for the 
given language. The two global word lists are then 
intersected, and a list of overlapping words is cre-
ated. From the initial list of overlapping words in 
both languages, we remove stop words by using 
stop word lists (words with high document fre-
quency). The space-separated tokens extracted in 
this process are not necessarily words in the lin-
guistic sense; therefore, we further refine the over-
lapping word list by removing tokens that contain 
non-alphanumeric characters. We make one excep-
tion for tokens (such as might appear in a time/date 
format) that contain hyphens, backslashes, apos-
trophes, and periods so long as these characters do 
not occur at the beginning or at the end of the to-
ken.  
We call this list of overlapping tokens a feature 
vector template, where each token in the list is one 
feature. Using this feature vector template we go 
back and represent each document in the bilingual 
collection using the template vector by computing 
the tf?idf value for each token in the template vec-
tor over each particular document. Now that we 
have the original documents from both languages 
represented in a language-independent space, we 
compute vector similarity across all document 
pairs in order to come up with a single ranked list. 
We talk more in detail about the similarity metrics 
208
that we have considered and decided to use in the 
following section.  
 
  
Figure 1. Process of creating and representing each 
document of a bilingual collection in an independ-
ent vector space.  
3 Motivational Experiments 
3.1 Evaluation Collections 
We start off by evaluating the above proposed ap-
proach of determining candidate document transla-
tion pairs using three different parallel collections: 
Europarl, created by Koehn (2005), UN Arabic 
English Parallel Text (LDC2004E13) and the Ara-
bic News Translation Part 1 (LDC2004T17). The 
purposes of first testing our approach using the 
Europarl corpus were twofold: This collection con-
tains parallel documents (sessions of the European 
Parliament) that are further aligned at the speech 
and sentence level, which allows us to test align-
ment accuracy at several levels of granularity. Sec-
ond, this collection contains parallel data from 
different groups of languages (Germanic, Ro-
mance, Slavic, Hellenic, etc.) and therefore is use-
ful to observe the performance of our approach 
across different language families, which in turn 
are important to observe the difference in the cog-
nate rates and the size of the overlapping words. In 
addition to the Europarl corpus we use the two 
English-Arabic parallel collections to test our ap-
proach across various alphabets (Arabic in addition 
to the Latin, Greek and Cyrillic found in the Eu-
roparl collection). Shown in Table 1 are basic sta-
tistics for all 3 corpora on the language pairs 
considered. We give min, max and median values 
over the number of words in each document. 
 
Collection # doc. Pairs Lang. Min Max  Median
En 92 109030 46800.5Europarl 
en-de 654 De 95 99753 43161.0
En 4872 59284 10706.5Europarl 
en-bg 430 Bg 4771 56907 10167.0
En 92 109793 46790.5Europarl 
en-es 642 Es 104 114770 48989.0
En 92 93886 21290.0Europarl 
en-gr 412 Gr 103 93304 21122.0
En 66 47784 691.5Newswire 
en-ar 230 Ar 62 34272 560.0
En 17672 71594 23027.0UN en-ar 430 Ar 15478 62448 19682.0
 
Table 1. Document length statistics over 6 Parallel 
Collections. 
 
From the Europarl collection we sentence aligned 
sessions in the following four language pairs where 
the English language is the source language: Eng-
lish-German, English-Spanish, English-Bulgarian 
and English-Greek. The foreign language in all 
four language pairs is selected from a different 
language group (Germanic, Romanic, Slavic), with 
Greek being a more isolated branch. For the Arabic 
language we used two parallel document collec-
tions in different domains ? newswire and docu-
ments published by the United Nations. The 
Newswire parallel collection consisted of 1526 
news stories which we combined based on the 
news story publication date and obtained 230 par-
allel documents. The purpose of combining the 
news articles is to increase the number of words 
present in each document since the original size of 
209
the news articles was not at a level to be treated as 
a document as in the case of the remaining two 
collections. The UN parallel collection consists of 
34,575 document pairs.  
3.2 Similarity Metrics 
We considered five similarity metrics proposed at 
one time or another for vector space models in IR: 
Cosine (shown below), Dice, Product, Jaccard and 
Euclidean. 
 
  ? ?
?
22
ii
ii
yx
yx                        (1)  
 
Document similarity using the cosine metric relies 
on the angle between the vector representations 
and it is length invariant. The Dice metric relies on 
the number of common tokens between the two 
documents. Euclidean computes the similarity as a 
point distance between the two vector representa-
tions and is not normalized by the vector length 
which does not make it vector invariant. Jaccard 
distance is the ratio of the intersection and the un-
ion of the two vector representations while the 
product coefficient is simply the inner product of 
the two vectors. While there is no clear evidence 
across the literature whether one similarity metric 
is more useful across a range of tasks compared to 
another, the cosine similarity metric is mostly pre-
ferred. Shown in Figure 2 are the precision vs. re-
call plots of the above similarity measurements 
when used with our method. Tests were done on 
our set of 654 English-German sessions from the 
Europarl collections. To test the impact of the 
document length on the performance of the metric 
we performed two types of tests across all 5 met-
rics. In the first type we performed similarity 
analysis on the full document length (marked as 
100%) and on the final 10% of each document 
(marked as 10%). We deliberately omitted the top 
part of the document to avoid any inadvertent in-
clusion of session date, topic, title, etc. (As it 
turned out, this was not a problem in our data.) We 
perform similarity measurements across all docu-
ment pairs, and we generate a single ranked list. As 
can be seen from the plot, all five metrics yield 
better performance when all words in documents 
are considered compared to only considering 10%. 
The performance ranking of all five metrics was 
identical on both versions of the document set. 
Even though depicted in the above plot, the Jac-
card distance performed pretty much the same as 
the Dice distance and therefore there is no visible 
difference between the two. While on the 10% ver-
sion of the collection, the Euclidean distance has 
the worst precision, it could still be explored as a 
metric to obtain document translation pairs with 
the original collection with a modest to moderate 
recall range for P=1. The Jaccard distance along 
with the Dice distance yield the highest precision 
values across all recall values but they achieve the 
same recall range for P=1 as the Cosine metric. 
Since we are only interested in top-N document 
pairs that have P=1 and furthermore there are ap-
proximate algorithms for the Cosine similarity 
metrics we decided to further utilize this metric. 
The same metric has been previously used in de-
termining potential translation candidates on sen-
tence level by Munteanu and Marcu (2005) and in 
our case we are extending it to perform pair-wise 
document similarity.  
 
  
Figure 2. Precision vs. recall plot using various 
similarity measurements on the Europarl English-
German collection. 
 
When run on the same English-German collection, 
Enright?s and Kondrak?s (2007) approach achieves 
mean reciprocal rank (MRR) of 0.989 when using 
document specific hapax words and MRR=0.795 
when using collection specific hapax words. With 
the above explained approach we obtain 
MRR=0.995. 
210
3.3 Post Filtering Approaches 
To further improve the precision of our approach 
we tested out two types of filtering the initial re-
sults. Since we threat documents as ?bag of words? 
and since the Cosine metric uses the angle between 
the vector representations and is length invariant 
there may be instances of source documents that 
would yield high cosine coefficients over all target 
documents. In these instances, multiple document 
pairs with the same source document may be 
ranked high. To alleviate this problem, we consider 
two types of filtering the initial results. We go over 
the single ranked list and we only keep the top five 
document pairs for a given source document, thus 
introducing ?diversity? in the ranked list. The sec-
ond filter is motivated by the basic assumption 
used in the machine translation field that the length 
of the target sentence is in a given length range of 
the source sentence. We extend this assumption on 
a document level and we filter out all document 
pairs from the ranked list that are not in the ?20% 
range of the source document length. Both of the 
above values were selected based on empirical 
evidence without detailed explanation. Shown in 
Figure 3 are the effects of these two simple filter-
ing techniques.  
 
  
Figure 3. Diversity and length based filtering ef-
fects on the English-German Europarl collection. 
 
Compared to the diversity filter, the length based 
filter yields better gain in precision while a combi-
nation of both methods achieves the highest recall 
range for P=1. 
3.4 Target Languages and Writing Systems 
Shown in Figure 4 are the precision/recall results 
on all six collections explained in Section 3.1. 
Post-filtering steps explained in the previous sec-
tion were not utilized on these results. Our ap-
proach yields best precision on the Arabic News 
Translation Part 1 collection while the worst per-
formance is on the UN Arabic English Parallel 
Text. While the performance on the English-
German and English-Spanish collections is some-
what the same, out of all 4 Europarl collections we 
achieve best results on the Greek collection and 
worst results on the Bulgarian target language.  
 
  
Figure 4. Precision vs. recall on 5 different lan-
guage pairs using cosine similarity distance metric.  
 
In Table 2, we give the vector template length for 
each collection. 
 
Collection # of overlapping tokens 
Europarl en-de 37785
Europarl en-es 36476
Europarl en-bg 29360
Europarl en-gr 17220
UN en-ar 3945
Newswire en-ar 1262
 
Table 2. Number of overlapping words (vector 
template length) in the six parallel collections. 
 
Unsurprisingly, due to the difference in script and 
language family, the feature vector templates for 
the English-Arabic collections have the smallest 
lengths. 
211
Shown in Figure 5 are effects of the trivial diver-
sity and length based filtering on the above preci-
sion vs. recall results. Bulgarian has improve 
substantially and so has the UN Arabic, but recall 
on the Arabic newswire is truncated on reaching 
P=0.4. 
 
  
Figure 5. Precision vs. recall on 6 collections using 
div=5 and length filtering with ?20%. 
3.5 Randomly Selected Documents 
While useful to evaluate the feasibility of our ap-
proach, the previous parallel bilingual collections 
are unrealistic because there is, by the corpus? de-
sign, a translation for each document. To observe 
the performance on a bilingual document collec-
tion where there is no a priori information on trans-
lation pairs we created ten random subsets from the 
Europarl English-German collection. These subsets 
were created by randomly selecting 50% (328 
documents) of the English and 5% (33 documents) 
of the German documents for each subset collec-
tion. Shown in  is interpolated average precision 
over the ten subsets. The Mean Average Precision 
(MAP) obtained was 0.986. 
4 Multilingual Book Collection 
Our multilingual book collection consists of 
around 800k books in German and English lan-
guages. It is a subset of a larger Internet Archive1 
collection of books in over 200 languages. The 
whole collection consists of OCRed books incor-
porating a small number of human transcribed 
                                                          
1 http://www.archive.org/details/texts/ 
books from Project Gutenberg2. The collection was 
initially annotated with author and language infor-
mation using the existing database obtained from 
the Internet Archive. This database originally con-
tained incorrect language metadata. Using the 
freely available language identifier TextCat (Cav-
nar and Trenkle, 2005) we tagged the whole book 
collection and extracted 705692 English and 96752 
German books. This process had the additional 
benefit of cleaning the German book collection of 
books written in the Fraktur script due to the bad 
OCR output. (Incredibly noisy OCR was simply 
recognized as ?not German? by the character n-
gram models.) Shown in Table 3 are word length 
statistics over the books in the collection.  
 
Language # of books
# of uniq. 
words Min Max 
Me-
dian 
German 96752 5030095 33 2372278 109820
English 705692 20001702 37 5155032 75016
 
Table 3. Bilingual book collection statistics. 
 
  
Figure 6. Average precision interpolated at 11 
points over ten randomly created subsets consisting 
of 50% English and 10% German documents from 
the English-German Europarl collection. 
4.1 Development Set 
Moving onto our book collection, we start off by 
evaluating the method on a smaller randomly se-
lected subset of 1000 books in both languages. 
Since it is not feasible to perform a full recall 
                                                          
2 http://www.gutenberg.org 
212
evaluation on the whole book set we include 17 
known book translation pairs in the 1000 random 
bilingual book collection. The 17 book translation 
pairs were constructed by hand by running a previ-
sion version of our full algorithm and indentifying 
translation pairs. Shown in Figure 7 is the preci-
sion vs. recall plot on the 17 book pairs. As in the 
case of the 10 randomly selected Europarl subsets, 
we also performed diversity and length based fil-
tering of the initial results prior to computing pre-
cision vs. recall. 
 
  
Figure 7. Precision vs. recall running our method 
on a 1000 randomly selected bilingual book subset 
with 17 book translation pairs inserted. 
5 LSH Based Approximate Algorithm for 
Cosine Similarity 
Due to the collection size and length of each book 
it is infeasible to perform cosine similarity over all 
possible book pairs, i.e. approximately 68.2B com-
parisons. This brute force approach has time com-
plexity of )( 2knO  where n is the number of books 
in the collection and k is the vector template 
length. We therefore employ a fast cosine similar-
ity calculation approach developed by Charikar 
(2002) and utilized by Ravichandran et. al (2005) 
for creating similarity lists of nouns in  large col-
lection. In this section we give a summary of this 
approach and explain how it was applied for our 
task.  
Locality Sensitive Hashing (LSH), initially intro-
duced by Idyik and Motwani (1998), is used for 
finding approximate nearest neighbors in high di-
mensional spaces. In general, their approach 
hashes query vectors into bins where the probabil-
ity of collision is higher due to the fact that vectors 
in the same bin share the same locality. Their ap-
proach reduces the approximate nearest neighbor 
problem on the Hamming space.  
Charikar expanded this approach and showed that 
the probability of collision of hashed vectors for 
appropriately chosen hash function h is related to 
the angle between the vectors as: 
 
 ?
? ),(1)]()(Pr[ yxyhxh ???  (2) 
 
This is closely related to the cosine function. From 
the above equation we thus have: 
 
})])()(Pr[1cos{()),(cos( ?? yhxhyx ???   (3) 
 
Charikar uses a hash function based on random 
hyperplanes and creates a fingerprint for each 
original vector using the following approach: 
Generate d, k-dimensional random vectors from a 
standard normal (Gaussian) distribution: 
{ 1r , 2r ,?.. }dr . For each original vector x use the 
following hash function to generate a fingerprint of 
d bits: 
 
??
??
?
?
?? ?
?
01
00)(
ii
ii
r rxif
rxifxh   (4) 
 
By doing this we represent each vector in our 
original vector set into a bit stream that reduces our 
vector space representation from k to d dimensions, 
where d << k. Having bit stream as our data repre-
sentation, the probability of hash collision, i.e. the 
probability of two vectors being equal 
)]()(Pr[ yhxh ? , is equivalent to the Hamming 
distance between the two bit streams: 
 
         Pr[h(x) ? h(y)] ? HDd   (5) 
  
Therefore, performing fast cosine similarity boils 
down to finding the Hamming distance between 
the two bit streams.  
Now that we have an approximate method of find-
ing the cosine similarity between two vectors, we 
use Ravichandran?s (2005) formulation of the fast 
213
search algorithm developed by Charikar, which in 
turn used Indyk and Motwani?s orginal PLEB 
(Point Location in Equal Balls) algorithm as a 
starting point. The steps of this algorithm are out-
lined in the next subsection. For more detailed ex-
planation of this algorithm the reader is referred to 
Section 5 of Charikar?s work (2002).  
5.1 Nearest Neighbor Search Algorithm 
We now outline the steps of the fast search algo-
rithm. For more detailed explanation of the algo-
rithmic implementation users are referred to 
Section 3 of Ravichandran?s work (2005): 
 
? For all m documents represented in the vector 
space using the template vector, compute LSH 
d-bit signature using the formula given in (4).  
? Generate q permutations of length d.  
? For each of the q permutations, generate m 
permuted LSH signatures. 
? For each of the q permutation bins, 
lexicographically sort the m permutated bit 
vectors.  
? For each lexicographically sorted bin, go over 
the m bit streams and compute the Hamming 
distance between the current bit stream and the 
subsequent b bit streams in the sorted list start-
ing from the top. 
? If the Hamming distance is above a previously 
set threshold, output the book pair along with 
the Hamming distance result. 
 
Compared to Ravichandran?s algorithm for creat-
ing noun similarity lists, in our approach we deal 
with two distinct groups of documents: those in 
each language. We start off by creating a single list 
of documents and we represent each document in 
this list using the LSH based fingerprint. We then 
generate q permutation vector bins, and we 
lexicographically sort each bin. In our beam search 
approach, since we have documents in two differ-
ent languages, we only consider documents that 
have a different language. The results of the beam 
search for each bin are then combined. Since in 
each beam the same permutation is performed over 
all fingerprints, the Hamming distance across all 
bins for a given document pair would be the same. 
Therefore after combining the results we remove 
duplicate document pairs and sort by the Hamming 
distance to obtain the final ranked list.  The run-
time of this algorithm is dominated by the 
O(qn logn)  step of sorting the permuted bit vec-
tors in each of the bins. 
6 Detecting and Ranking Book Transla-
tion Pairs in a Large Book Collection 
Using the previously explained method we proc-
essed the large book collection by first computing 
the vector template. For the large book collection, 
the vector template size k, i.e. the number of over-
lapping tokens obtained, was 638,005. After re-
moving stop words and unwanted tokens 
(explained in Section 2) the template vector length 
was reduced to 563,053. Shown in Table 4 are sta-
tistics over the number of vector template tokens 
whose tf?idf values are greater than zero across the 
two languages.  
 
Language Min Max Median
German 7 7212 229
English 11 6637 585
 
Table 4. Statistics over the number of tokens in the 
vector representation of each book whose tf?idf are 
greater than zero. 
 
Once processed and represented in vector space, 
we proceed with computing the approximate co-
sine similarity across the bilingual collection. We 
precompute the Hamming distance based on a co-
sine similarity threshold of 0.18 which is equiva-
lent to different Hamming distance values 
depending on the length of the LSH based finger-
print. For the book collection we experimented 
with 4 different sets of values for the number of 
hyperplane based hash functions, the number of 
permutations and the length of the beam search. 
For each of these parameters in our setup we cre-
ated ranked lists as explained in Section 5.1. We 
then went over the top 300 book pairs in each list 
and annotated the correct book translations. Based 
on the human annotation we then computed aver-
age precision over the ranked list. Shown in Table 
5 are the results for LSH based fingerprint of size 
d=500. Due to the randomness introduced by the 
permutations, there is not a monotonic increase in 
accuracy, but in general more permutations and 
wider beams show substantial improvements. 
 
214
q\b AP Time [hrs] 
b=25 0.307 24.9
b=50 0.213 41.1q=25 
b=100 0.280 67.2
b=25 0.488 99.6
b=50 0.388 164.4q=100 
b=100 0.461 269.1
b=25 0.357 199.2
b=50 0.412 328.8q=200 
b=100 0.455 538.2
b=25 0.489 498.1
b=50 0.490 822.0q=500 
b=100 0.493 1345.5
 
Table 5. Average precision on the large English-
German book collection across various parameters 
of the LSH based search algorithm. 
 
For the above given results for d=500, we calcu-
lated an estimated time that it would take to per-
form the fast cosine similarity if the algorithm 
were to be run in serial fashion. Shown in Figure 8 
is a scatter plot of the time vs. the average preci-
sion obtained. 
 
  
Figure 8. Estimated serial time vs. average preci-
sion with d=500 dimensional LSH based finger-
prints. 
 
In summary, while increasing the number of per-
mutations and the beam search over different val-
ues increases the average precision the time cost 
required is significantly larger especially for in-
creasing the number of permutations. 
7 Future Work 
In the future we plan on experimenting with larger 
dimensionality d for the LSH fingerprint, the num-
ber of random permutations q i.e. bins and the 
beam search parameter b. In order to further im-
prove the average precision we would also like to 
experiment with different longest common subse-
quence (LCS) based approaches for re-ranking the 
cosine based ranked lists. Furthermore, we plan on 
exploring more accurate joint models of transla-
tion. It would also be interesting to observe the 
performance of our system on other language pairs, 
such as English-Chinese and languages with 
resource-poor bilingual collections.  
8 Conclusion 
This paper presents and evaluates a new approach 
to detecting and ranking document translation 
pairs. We showed that this simple method achieves 
high precision vs. recall on parallel bilingual col-
lections where there is one document translation 
for each source document. We also showed that the 
method is capable of detecting document transla-
tions in random subsets where no known document 
translation information is available. Using an ap-
proximation algorithm for cosine similarity, we 
showed that this method is useful for detecting and 
ranking document translation pairs in a large 
bilingual collection with hundreds of thousands of 
books and billions of possible book pairs. This 
method is conceivable to be used for other lan-
guages and collection genres and also on other 
types of translation methods such as transliteration. 
While in some instances other simple methods of 
aligning the dictionaries might be needed, as in the 
case of the Chinese language. 
Acknowledgments 
This work was supported in part by the Center for 
Intelligent Information Retrieval and in part by 
NSF grant #IIS-0910884. Any opinions, findings 
and conclusions or recommendations expressed in 
this material are the authors' and do not necessarily 
reflect those of the sponsor. 
References  
Alexandre Patry and Philippe Langlais, 2011. Identify-
ing Parallel Documents from a Large Bilingual Col-
lection of Texts: Application to Parallel Article 
215
Extraction in Wikipedia. Proceedings of the 4th 
Workshop on Building and Using Comparable Cor-
pora, pages 87-95, Portland, OR. 
Bing Zhao and Stephan Vogel. 2002. Adaptive Parallel 
Sentences Mining from Web Bilingual News Collec-
tion. Proceedings of IEEE International Conference 
on Data Mining, pages 745-750. Maebashi City, Ja-
pan. 
Deepak Ravichandran, Patrick Pantel, and Eduard 
Hovy. 2005. Randomized Algorithms and NLP: Us-
ing Locality Sensitive Hash Function for High Speed 
Noun Clustering. Proceedings of the 43rd Annual 
Meeting on Association for Computational Linguis-
tics, pages 622?629, Morristown, NJ. 
Dragos Stefan Munteanu and Daniel Marcu. 2005. Im-
proving Machine Translation Performance by Ex-
ploiting Non-Parallel Corpora. Computational 
Linguistics, 31(4): 477-504. 
Jacob Uszkoreit, Jay Ponte, Ashok Popat and Moshe 
Dubiner, 2010. Large Scale Parallel Document Min-
ing for Machine Translation. Proceedings of the 23rd 
International Conference on Computational Linguis-
tics (Coling 2010), pp. 1101-1109. Beijing, China. 
Jason R. Smith, Chris Quirk, and Kristina Toutanova, 
2010. Extracting Parallel Sentences from Compara-
ble Corpora using Document Level Alignment, Pro-
ceedings of Human Language Technologies: The 
2010 Annual Conference of the North American 
Chapter of the ACL (HLT NAACL?10), Los Ange-
les, California. 
Jessica Enright and Grzegorz Kondrak 2007. A Fast 
Method for Parallel Document Identification, Pro-
ceedings of Human Language Technologies: The 
Conference of the North American Chapter of the 
Association for Computational Linguistics (HLT-
NAACL?07) companion volume, pages 29-32, Roch-
ester, NY. 
Matthew Snover, Bonnie Dorr, and Richard Schwartz. 
2008. Language and Translation Model Adaptation 
using Comparable Corpora. Proceedings of Confer-
ence on Empirical Methods in Natural Language 
Processing (EMNLP?08), pages 856?865, Honolulu, 
HI. 
Moses S. Charikar. 2002. Similarity estimation tech-
niques from rounding algorithms. In Proceedings of 
the thiry-fourth annual ACM symposium on Theory 
of computing (STOC?02), pages 380?388, New 
York, NY. 
Pascale Fung and Percy Cheung. 2004. Mining Very-
Non-Parallel Corpora: Parallel Sentence and Lexicon 
Extraction via Bootstrapping and EM. In Proceedings 
of Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP?04), Barcelona, Spain. 
Philip Resnik and Noah Smith. 2003. The Web as a 
Parallel Corpus. Computational Linguistics, 29(3): 
349-380. 
Philipp Koehn, 2005. Europarl: A Parallel Corpus for 
Statistical Machine Translation. MT Summit 2005. 
Phuket, Thailand. 
Piotr Indyk and Rajeev Motwani. 1998. Approximate 
nearest neighbors: towards removing the curse of di-
mensionality. In Proceedings of the thirtieth annual 
ACM symposium on Theory of computing (STOC 
?98), pages 604?613, New York, NY. 
William B. Cavnar and John M. Trenkle. 1994. N-
Gram-Based Text Categorization. Proceedings of the 
Third Annual Symposium on Document Analysis 
and Information Retrieval, pages 161-175, Las Ve-
gas, NV.  
216
Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 252?261,
Sofia, Bulgaria, August 8-9, 2013 c?2013 Association for Computational Linguistics
Online Polylingual Topic Models for Fast Document Translation Detection
Kriste Krstovski
School of Computer Science
University of Massachusetts Amherst
Amherst, MA, 01003
kriste@cs.umass.edu
David A. Smith
School of Computer Science
University of Massachusetts Amherst
Amherst, MA, 01003
dasmith@cs.umass.edu
Abstract
Many tasks in NLP and IR require ef-
ficient document similarity computations.
Beyond their common application to ex-
ploratory data analysis, latent variable
topic models have been used to represent
text in a low-dimensional space, indepen-
dent of vocabulary, where documents may
be compared. This paper focuses on the
task of searching a large multilingual col-
lection for pairs of documents that are
translations of each other. We present
(1) efficient, online inference for repre-
senting documents in several languages in
a common topic space and (2) fast ap-
proximations for finding near neighbors in
the probability simplex. Empirical evalu-
ations show that these methods are as ac-
curate as?and significantly faster than?
Gibbs sampling and brute-force all-pairs
search.
1 Introduction
Statistical topic models, such as latent Dirich-
let alocation (LDA) (Blei et al, 2003), have
proven to be highly effective at discovering hid-
den structure in document collections (Hall et al,
2008, e.g.). Often, these models facilitate ex-
ploratory data analysis, by revealing which col-
locations of terms are favored in different kinds
of documents or which terms and topics rise and
fall over time (Blei and Lafferty, 2006; Wang and
McCallum, 2006). One of the greatest advan-
tages in using topic models to analyze and process
large document collections is their ability to rep-
resent documents as probability distributions over
a small number of topics, thereby mapping doc-
uments into a low-dimensional latent space?the
T -dimensional probability simplex, where T is the
number of topics. A document, represented by
some point in this simplex, is said to have a par-
ticular ?topic distribution?.
Representing documents as points in a low-
dimensional shared latent space abstracts away
from the specific words used in each document,
thereby facilitating the analysis of relationships
between documents written using different vocab-
ularies. For instance, topic models have been used
to identify scientific communities working on re-
lated problems in different disciplines, e.g., work
on cancer funded by multiple Institutes within the
NIH (Talley et al, 2011). While vocabulary mis-
match occurs within the realm of one language,
naturally this mismatch occurs across different
languages. Therefore, mapping documents in dif-
ferent languages into a common latent topic space
can be of great benefit when detecting document
translation pairs (Mimno et al, 2009; Platt et al,
2010). Aside from the benefits that it offers in the
task of detecting document translation pairs, topic
models offer potential benefits to the task of creat-
ing translation lexica, aligning passages, etc.
The process of discovering relationship be-
tween documents using topic models involves: (1)
representing documents in the latent space by in-
ferring their topic distributions and (2) comparing
pairs of topic distributions to find close matches.
Many widely used techniques do not scale ef-
ficiently, however, as the size of the document
collection grows. Posterior inference by Gibbs
sampling, for instance, may make thousands of
passes through the data. For the task of comparing
topic distributions, recent work has also resorted
to comparing all pairs of documents (Talley et al,
2011).
This paper presents efficient methods for both
252
of these steps and performs empirical evaluations
on the task of detected translated document pairs
embedded in a large multilingual corpus. Unlike
some more exploratory applications of topic mod-
els, translation detection is easy to evaluate. The
need for bilingual training data in many language
pairs and domains also makes it attractive to mit-
igate the quadratic runtime of brute force transla-
tion detection. We begin in ?2 by extending the
online variational Bayes approach of Hoffman et
al. (2010) to polylingual topic models (Mimno et
al., 2009). Then, in ?3, we build on prior work
on efficient approximations to the nearest neighbor
problem by presenting theoretical and empirical
evidence for applicability to topic distributions in
the probability simplex and in ?4, we evaluate the
combination of online variational Bayes and ap-
proximate nearest neighbor methods on the trans-
lation detection task.
2 Online Variational Bayes for
Polylingual Topic Models
Hierarchical generative Bayesian models, such as
topic models, have proven to be very effective
for modeling document collections and discover-
ing underlying latent semantic structures. Most
current topic models are based on Latent Dirich-
let Allocation (LDA) (Blei et al, 2003). In some
early work on the subject, Blei and Jordan (2003)
showed the usefulness of LDA on the task of auto-
matic annotation of images. Hall et al (2008) used
LDA to analyze historical trends in the scientific
literature; Wei and Croft (2006) showed improve-
ments on an information retrieval task. More re-
cently Eisenstein et al (2010) modeled geographic
linguistic variation using Twitter data.
Aside from their widespread use on monolin-
gual text, topic models have also been used to
model multilingual data (Boyd-Graber and Blei,
2009; Platt et al, 2010; Jagarlamudi and Daume?,
2010; Fukumasu et al, 2012), to name a few.
In this paper, we focus on the Polylingual Topic
Model, introduced by Mimno et al (2009). Given
a multilingual set of aligned documents, the PLTM
assumes that across an aligned multilingual doc-
ument tuple, there exists a single, tuple-specific,
distribution across topics. In addition, PLTM as-
sumes that for each language?topic pair, there ex-
ists a distribution over words in that language ?l.
As such, PLTM assumes that the multilingual cor-
pus is created through a generative process where
D T
T
...
D
wz
N1
wz
NL
...
1E
LE
1K
LK
Figure 1: Polylingual topic model (PLTM)
first a document tuple is generated by drawing a
tuple-specific distribution over topics ?1 which, as
it is the case with LDA, is drawn from a Dirich-
let prior ? ? Dir (?) . For each of the languages
l in the tuple and for each of the N words wln in
the document the generative process: first chooses
a topic assignment zln ?Multinomial (?) which
is then followed by choosing a word wln from a
multinomial distribution conditioned on the topic
assignment and the language specific topics distri-
bution over words ?l?Dir (?l). Both? and ?1,...,L
are symmetric priors, i.e. the priors are exchange-
able Dirichlet distributions. Finally, each word
is generated from a language- and topic-specific
multinomial distribution ?lt as selected by the topic
assignment variable zln:
wln ? p
(
wln | zln, ?ln
)
(1)
Figure 1 shows a graphical representation of
the PLTM using plate notation. In their original
work Mimno et al (2009) used the Gibbs sam-
pling approach as a posterior inference algorithm
to assign topics distributions over their test collec-
tion. While more straightforward to implement,
this sampling approach is inherently slow when
applied to large collections which makes the orig-
inal PLTM work practically infeasible to be used
on real-world data sets.
In general, performing posterior inference over
the latent variables of a Bayesian model is usu-
ally done with two of the three approximate ap-
proaches, Gibbs sampling, variational Bayes (VB)
and expectation-propagation. While Gibbs Sam-
pling is a variation of Markov Chain Monte Carlo
method (MCMC) which generates a sample from
the true posterior after converging to a stationary
1In the traditional LDA model ? is used to specify the
document specific distribution over topics.
253
distribution; in VB, a set of free variational param-
eters characterizes a simpler family of probabil-
ity distributions. These variational parameters are
then optimized by finding the minimum Kullback-
Leibler (KL) divergence between the variational
distribution q (?, z, ?|?, ?, ?) and the true pos-
terior P (?, z, ?|w,?, ?). From an algorithmic
perspective, the variational Bayes approach fol-
lows the Expectation-Maximization (EM) proce-
dure where for a given document, the E-step up-
dates the per document variational parameters ?d
and ?d while holding the per words-topic distribu-
tion parameter ? fixed. It then updates the vari-
ational parameter ? using the sufficient statistics
computed in the E step. In order to converge to
a stationary point, both approaches require going
over the whole collection multiple times which
makes their time complexity to grown linearly
with the size of the data collection. The mere fact
that they require continuous access to the whole
collection makes both inference approaches im-
practicable to use on very large or streaming col-
lections. To alleviate this problem, several algo-
rithms have been proposed that draws from belief
propagation (Zeng et al, 2012), the Gibbs sam-
pling approach such as (Canini et al, 2009), vari-
ational Bayes (Hoffman et al, 2010) as well as
a combination of the latter two (Hoffman et al,
2012) to name a few. In this paper we use Hoff-
man et al (2010) approach. Hoffman et al (2010)
proposed a new inference approach called Online
LDA which relies on the stochastic gradient de-
scent to optimize the variational parameters. This
approach can produce good estimates of LDA pos-
teriors in a single pass over the whole collection.
2.1 Algorithmic Implementation
We now derive an online variational Bayes algo-
rithm for PLTM to infer topic distributions over
multilingual collections. Figure 2 shows the vari-
ational model and free parameters used in our ap-
proach. As in the case of Hoffman et al (2010),
our algorithm updates the variational parameters
?ld and ?ld on each batch of documents while the
variational parameter ? is computed as a weighted
average of the value on the previous batch and its
approximate version ??. Averaging is performed
using a decay function whose parameters control
the rate at which old values of ?l are forgotten.
Within the E step of the VB approach, we com-
pute the updates over the variational parameter ?l
T
. . .
D
T z
N1
z
NL
. . .
J 1I LI
1E LE
1O LO
Figure 2: Graphical model representation of the
free variational parameters for the online varia-
tional Bayes approximation of the PLTM posterior
for each language L present in our document tuple
while the update on the ? parameter accumulates
the language specific sufficient statistics:
?mk = ?+
?
l
?
w
?mlwk nmlw (2)
We detail these steps in Algorithm 1.
2.2 Performance Analysis
To demonstrate the efficacy of online PLTM, we
ran topic inference on a subset of the English-
Spanish Europarl collection consisting of ?64k
parallel speeches and compared the accuracy re-
sults vs. the training and inference speed against
the original PLTM model using topic sets of
T=50,100, 200 and 500. We explain in details
the evaluation task and the performance metric
used in ?4. Shown in Figure 3 are the results of
these comparisons. Our speed measurements were
performed on Xeon quad processors with a clock
speed of 2.66GHz and a total of 16GB of memory.
As we increase the number of topics we gain in
accuracy over the evaluation task across both in-
ference approaches. When we increase the num-
ber of topics from 50 to 500 the speed improve-
ment obtained by Online VB PLTM drops by a
factor of 2.9 within the training step and by a
factor of 4.45 in the test step. Our total running
time for the Online VB PLTM with T=500 ap-
proaches the running time of the Gibbs sampling
approach with T=50. The gradual drop in speed
improvement with the increase of the number top-
ics is mostly attributed to the commutation of the
254
Algorithm 1 Online variational Bayes for PLTM
initialize ?l randomly
obtain the tth mini-batch of tuples Mt
for t = 1 to ? do
?t ?
(
1
t0+t
)?
E step:
initialize ?t randomly
for each document tuple in mini-batch t
for m in Mt do
repeat
for l ? 1, . . . ,L do
?mlwk ?
exp {Eq [log ?mk ]} ?
exp
{
Eq
[
log ?mlkw
]}
end for
?mk = ?+
?
l
?
w ?mlwk nmlwuntil convergence
end for
M step:
for l ? 1, . . . ,L do
??lkw = ? +D
?
m ?mlwknmlw
?ltkw ? (1? ?t)?
l(t?1)
kw + ?t??lkwend for
end for
0 2000 4000 6000 8000 10000 12000
0
10
20
30
40
50
60
70
80
90
100
A
cc
ur
ac
y 
[%
 @
 R
an
k 1
.]
Running time [sec]
Accuracy vs. Running time
 
 
Gibbs sampling
Online VB
T=50
T=100
T=200 T=500 T=500T=200T=100
T=50
Figure 3: Speed vs. accuracy comparison between
Online VB PLTM and Gibbs Sampling PLTM at
T=50,100, 200 and 500. We used a Python imple-
mentation of Online VB and Mallet?s Java imple-
mentation of PLTM with in-memory Gibbs Sam-
pling using 1000 iterations.
0 50 100 250 500 750 1,000
0
20,000
40,000
60,000
80,000
100,000
120,000
140,000
160,000
180,000
200,000
Collection size [k]
Tr
ai
ni
ng
 ti
m
e 
[se
c]
Collection size vs. training time
 
 
Gibbs sampling T=50
Online VB T=50
Gibbs sampling T=500
Online VB T=500
Figure 4: Collection size vs. training time compar-
ison between Online VB PLTM and Gibbs Sam-
pling PLTM using multilingual collections of 50k,
100k, 250k, 500k, 750k and 1M speech pairs.
digamma function (Asuncion et al, 2009) whose
time complexity increases linearly with the num-
ber of topics.
While a multilingual collection of ?64k docu-
ment pairs is considered relatively big, our goal
of deriving the Online VB PLTM approach was to
be able to utilize PLTM on very large multilingual
collections. To analyze the potential of using On-
line VB PLTM on such collections we ran speed
comparisons within the training step by creating
multilingual collections of different lengths multi-
plying the original English-Spanish Europarl col-
lection. Speed comparisons using collections of
length 50K, 100K, 250K, 500K, 750K and 1M are
shown in Figure 4. Training was performed with
the number of topics T set to T=50 and T=500.
As we increase the collection size we observe
the real benefit of using Online VB compared to
Gibbs sampling. This is mostly attributed to the
fact that the Gibbs sampling approach requires
multiple iterations over the whole collection in or-
der to achieve a convergence point. For collec-
tion sizes of 50k and 100k the training time for
the Online VB PLTM with T=500 approaches the
training time of Gibbs sampling with T=50 and as
we increase the collection size this proximity dis-
sipates.
In Figure 5 we show a sample set of the aligned
topics extracted using Online VB PLTM with
T=400 on the English-Spanish Europarl collec-
tion. For a given topic tuple words are ordered
based on probability of occurrence within the
given topic.
255
	




	



	

