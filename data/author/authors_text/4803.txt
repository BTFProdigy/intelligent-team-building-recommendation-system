Event Detection and Summarization in Weblogs with Temporal Collocations 
Chun-Yuan Teng and Hsin-Hsi Chen 
Department of Computer Science and Information Engineering 
National Taiwan University 
Taipei, Taiwan 
{r93019, hhchen}@csie.ntu.edu.tw 
Abstract 
 
This paper deals with the relationship between weblog content and time. With the proposed temporal mutual information, we analyze 
the collocations in time dimension, and the interesting collocations related to special events. The temporal mutual information is 
employed to observe the strength of term-to-term associations over time. An event detection algorithm identifies the collocations that 
may cause an event in a specific timestamp. An event summarization algorithm retrieves a set of collocations which describe an event. 
We compare our approach with the approach without considering the time interval. The experimental results demonstrate that the 
temporal collocations capture the real world semantics and real world events over time. 
 
1. 
2. 
Introduction 
Compared with traditional media such as online news 
and enterprise websites, weblogs have several unique 
characteristics, e.g., containing abundant life experiences 
and public opinions toward different topics, highly 
sensitive to the events occurring in the real world, and 
associated with the personal information of bloggers. 
Some works have been proposed to leverage these 
characteristics, e.g., the study of the relationship between 
the content and bloggers? profiles (Adamic & Glance, 
2005; Burger & Henderson, 2006; Teng & Chen, 2006), 
and content and real events (Glance, Hurst & Tornkiyo, 
2004; Kim, 2005; Thelwall, 2006; Thompson, 2003). 
In this paper, we will use temporal collocation to 
model the term-to-term association over time.  In the past, 
some useful collocation models (Manning & Sch?tze, 
1999) have been proposed such as mean and variance, 
hypothesis test, mutual information, etc. Some works 
analyze the weblogs from the aspect of time like the 
dynamics of weblogs in time and location (Mei, et al, 
2006), the weblog posting behavior (Doran, Griffith & 
Henderson, 2006; Hurst, 2006), the topic extraction (Oka, 
Abe & Kato, 2006), etc. The impacts of events on social 
media are also discussed, e.g., the change of weblogs after 
London attack (Thelwall, 2006), the relationship between 
the warblog and weblogs (Kim, 2005; Thompson, 2003), 
etc. 
This paper is organized as follows. Section 2 defines 
temporal collocation to model the strength of term-to-term 
associations over time.  Section 3 introduces an event 
detection algorithm to detect the events in weblogs, and 
an event summarization algorithm to extract the 
description of an event in a specific time with temporal 
collocations. Section 4 shows and discusses the 
experimental results.  Section 5 concludes the remarks. 
Temporal Collocations 
We derive the temporal collocations from Shannon?s 
mutual information (Manning & Sch?tze, 1999) which is 
defined as follows (Definition 1). 
Definition 1 (Mutual Information) The mutual 
information of two terms x and y is defined as: 
)()(
),(log),(),(
yPxP
yxPyxPyxI =  
where P(x,y) is the co-occurrence probability of x and y, 
and P(x) and P(y) denote the occurrence probability of x 
and y, respectively. 
Following the definition of mutual information, we 
derive the temporal mutual information modeling the 
term-to-term association over time, and the definition is 
given as follows.  
 Definition 2 (Temporal Mutual Information) Given 
a timestamp t and a pair of terms x and y, the temporal 
mutual information of x and y in t is defined as: 
)|()|(
)|,(log)|,()|,(
tyPtxP
tyxPtyxPtyxI =
where P(x,y|t) is the probability of co-occurrence of terms 
x and y in timestamp t, P(x|t) and P(y|t) denote the 
probability of occurrences of x and y in timestamp t, 
respectively. 
To measure the change of mutual information in time 
dimension, we define the change of temporal mutual 
information as follows. 
Definition 3 (Change of Temporal Mutual 
Information) Given time interval [t1, t2], the change of 
temporal mutual information is defined as: 
12
12
21
)|,()|,(),,,(
tt
tyxItyxIttyxC ?
?=  
where C(x,y,t1,t2) is the change of temporal mutual 
information of terms x and y in time interval [t1, t2], I(x,y| 
t1) and I(x,y| t2) are the temporal mutual information in 
time t1 and t2, respectively. 
3. Event Detection 
Event detection aims to identify the collocations 
resulting in events and then retrieve the description of 
events. Figure 1 sketches an example of event detection. 
The weblog is parsed into a set of collocations. All 
collocations are processed and monitored to identify the 
plausible events.  Here, a regular event ?Mother?s day? 
and an irregular event ?Typhoon Chanchu? are detected.  
The event ?Typhoon Chanchu? is described by the words  
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1: An Example of Event Detection
?Typhoon?, ?Chanchu?, ?2k?, ?Eye?, ?Path? and 
?chinaphillippine?.  
The architecture of an event detection system includes 
a preprocessing phase for parsing the weblogs and 
retrieving the collocations; an event detection phase 
detecting the unusual peak of the change of temporal 
mutual information and identifying the set of collocations 
which may result in an event in a specific time duration; 
and an event summarization phase extracting the 
collocations related to the seed collocations found in a 
specific time duration. 
The most important part in the preprocessing phase is 
collocation extraction. We retrieve the collocations from 
the sentences in blog posts. The candidates are two terms 
within a window size. Due to the size of candidates, we 
have to identify the set of tracking terms for further 
analysis. In this paper, those candidates containing 
stopwords or with low change of temporal mutual 
information are removed. 
In the event detection phase, we detect events by 
using the peak of temporal mutual information in time 
dimension.  However, the regular pattern of temporal 
mutual information may cause problems to our detection. 
Therefore, we remove the regular pattern by seasonal 
index, and then detect the plausible events by measuring 
the unusual peak of temporal mutual information. 
If a topic is suddenly discussed, the relationship 
between the related terms will become higher. Two 
alternatives including change of temporal mutual 
information and relative change of temporal mutual 
information are employed to detect unusual events. Given 
timestamps t1 and t2 with temporal mutual information 
MI1 and MI2, the change of temporal mutual information 
is calculated by (MI2-MI1). The relative change of 
temporal mutual information is calculated by (MI2-
MI1)/MI1. 
For each plausible event, there is a seed collocation, 
e.g., ?Typhoon Chanchu?. In the event description 
retrieval phase, we try to select the collocations with the 
highest mutual information with the word w in a seed 
collocation. They will form a collocation network for the 
event.  Initially, the seed collocation is placed into the 
network.  When a new collocation is added, we compute 
the mutual information of the multiword collocations by 
the following formula, where n is the number of 
collocations in the network up to now. 
?= n iMInInformatioMutualMultiwo  
If the multiword mutual information is lower than a 
threshold, the algorithm stops and returns the words in the 
collocation network as a description of the event.  Figure 
2 sketches an example.  The collocations ?Chanchu?s 
path?, ?Typhoon eye?, and ?Chanchu affects? are added 
into the network in sequence based on their MI. 
We have two alternatives to add the collocations to 
the event description. The first method adds the 
collocations which have the highest mutual information 
as discussed above. In contrast, the second method adds 
the collocations which have the highest product of mutual 
information and change of temporal mutual information. 
 
 
 
 
 
 
Figure 2: An Example of Collocation network 
4. 
4.1. 
Experiments and Discussions 
Temporal Mutual Information versus 
Mutual Information 
In the experiments, we adopt the ICWSM weblog data 
set (Teng & Chen, 2007; ICWSM, 2007). This data set 
collected from May 1, 2006 through May 20, 2006 is 
about 20 GB. Without loss of generality, we use the 
English weblog of 2,734,518 articles for analysis. 
To evaluate the effectiveness of time information, we 
made the experiments based on mutual information 
(Definition 1) and temporal mutual information 
(Definition 2). The former called the incremental 
approach measures the mutual information at each time 
point based on all available temporal information at that 
time. The latter called the interval-based approach 
considers the temporal mutual information in different 
time stamps.  Figures 3 and 4 show the comparisons 
between interval-based approach and incremental 
approach, respectively, in the event of Da Vinci Code.   
We find that ?Tom Hanks? has higher change of 
temporal mutual information compared to ?Da Vinci 
Code?. Compared to the incremental approach in Figure 4, 
the interval-based approach can reflect the exact release 
date of ?Da Vinci Code.? 
 rd
=i 1 4.2. Evaluation of Event Detection 
We consider the events of May 2006 listed in 
wikipedia1 as gold standard. On the one hand, the events 
posted in wikipedia are not always complete, so that we 
adopt recall rate as our evaluation metric.  On the other 
hand, the events specified in wikipedia are not always 
discussed in weblogs.  Thus, we search the contents of 
blog post to verify if the events were touched on in our 
blog corpus. Before evaluation, we remove the events 
listed in wikipedia, but not referenced in the weblogs. 
 
 
 
 
 
 
 
 
 
 
 
Figure 3: Interval-based Approach in Da Vinci Code  
 
 
 
 
 
 
 
 
Figure 4: Incremental Approach in Da Vinci Code 
gure 5 sketches the idea of evaluation.  The left side 
of t s figure shows the collocations detected by our event 
dete tion system, and the right side shows the events 
liste  in wikipedia.  After matching these two lists, we 
can find that the first three listed events were correctly 
identified by our system.  Only the event ?Nepal Civil 
War? was listed, but not found. Thus, the recall rate is 
75% in this case. 
 
 
 
 
 
 
 
Figure 5: Evaluation of Event Detection Phase 
As discussed in Section 3, we adopt change of 
temporal mutual information, and relative change of 
temporal mutual information to detect the peak. In Figure 
6, we compare the two methods to detect the events in 
weblogs. The relative change of temporal mutual 
information achieves better performance than the change 
of temporal mutual information. 
                                                     
1 http://en.wikipedia.org/wiki/May_2006 
Table 1 and Table 2 list the top 20 collocations based 
on these two approaches, respectively. The results of the 
first approach show that some collocations are related to 
the feelings such as ?fell left? and time such as ?Saturday 
night?. In contrast, the results of the second approach 
show more interesting collocations related to the news 
events at that time, such as terrorists ?zacarias 
moussaoui? and ?paramod mahajan.? These two persons 
were killed in May 3. Besides, ?Geena Davis? got the 
golden award in May 3. That explains why the 
collocations detected by relative change of temporal 
mutual information are better than those detected by 
change of temporal mutual information. 
-20
-15
-10
-5
0
5
10
1 3 5 7 9 11 13 15 17 19
Time (day)
M
ut
ua
l i
nf
or
m
at
io
n
Da-Vinci Tom Hanks
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 6: Performance of Event Detection Phase 
-15
-10
-5
0
5
10
1 3 5 7 9 11 13 15 17 19
Time (day)
M
ut
ua
l i
nf
or
m
at
io
n
Da-Vinci Tom Hanks
Collocations CMI Collocations CMI 
May 03 9276.08 Current music 1842.67
Illegal immigrants 5833.17 Hate studying 1722.32
Feel left 5411.57 Stephen Colbert 1709.59
Saturday night 4155.29 Thursday night 1678.78
Past weekend 2405.32 Can?t believe 1533.33
White house 2208.89 Feel asleep 1428.18
Red sox 2208.43 Ice cream 1373.23
Album tool 2120.30 Oh god 1369.52
Sunday morning 2006.78 Illegalimmigration 1368.12
16.56
f 
CMI
32.50
31.63
29.09
28.45
28.34
28.13Sunday night 1992.37 Pretty cool 13
Table 1: Top 20 collocations with highest change o
temporal mutual information 
Collocations CMI Collocations 
casinos online 618.36 Diet sodas 
zacarias moussaoui 154.68 Ving rhames 
Tsunami warning 107.93 Stock picks 
Conspirator zacarias 71.62 Happy hump 
Artist formerly 57.04 Wong kan 
Federal  
Jury 
41.78 Sixapartcom 
movabletype Wed 3 39.20 Aaron echolls 27.48
Pramod mahajan 35.41 Phnom penh 25.78
BBC  
Version 
35.21 Livejournal 
sixapartcom 
23.83  Fi
hi
c
dGeena davis 33.64 George yeo 20.34
Table 2: Top 20 collocations with highest relative change 
of mutual information 
4.3. Evaluation of Event Summarization 
As discussed in Section 3, we have two methods to 
include collocations to the event description. Method 1 
employs the highest mutual information, and Method 2 
utilizes the highest product of mutual information and 
change of temporal mutual information. Figure 7 shows 
the performance of Method 1 and Method 2. We can see 
that the performance of Method 2 is better than that of 
Method 1 in most cases. 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 7: Overall Performance of Event Summarization 
The results of event summarization by Method 2 are 
shown in Figure 8. Typhoon Chanchu appeared in the 
Pacific Ocean on May 10, 2006, passed through 
Philippine and China and resulted in disasters in these 
areas on May 13 and 18, 2006.  The appearance of the 
typhoon Chanchu cannot be found from the events listed 
in wikipedia on May 10.  However, we can identify the 
appearance of typhoon Chanchu from the description of 
the typhoon appearance such as ?typhoon named? and 
?Typhoon eye.  In addition, the typhoon Chanchu?s path 
can also be inferred from the retrieved collocations such 
as ?Philippine China? and ?near China?. The response of 
bloggers such as ?unexpected typhoon? and ?8 typhoons? 
is also extracted.   
 
 
 
 
 
 
 
 
 
 
Figure 8: Event Summarization for Typhoon Chanchu 
5. Concluding Remarks 
This paper introduces temporal mutual information to 
capture term-term association over time in weblogs. The 
extracted collocation with unusual peak which is in terms 
of relative change of temporal mutual information is 
selected to represent an event.  We collect those 
collocations with the highest product of mutual 
information and change of temporal mutual information 
to summarize the specific event.  The experiments on 
ICWSM weblog data set and evaluation with wikipedia 
event lists at the same period as weblogs demonstrate the 
feasibility of the proposed temporal collocation model 
and event detection algorithms. 
Currently, we do not consider user groups and 
locations. This methodology will be extended to model 
the collocations over time and location, and the 
relationship between the user-preferred usage of 
collocations and the profile of users. 
Acknowledgments 
Research of this paper was partially supported by 
National Science Council, Taiwan (NSC96-2628-E-002-
240-MY3) and Excellent Research Projects of National 
Taiwan University (96R0062-AE00-02). 
References 
Adamic, L.A., Glance, N. (2005). The Political 
Blogosphere and the 2004 U.S. Election: Divided 
They Blog. In: Proceedings of the 3rd International 
Workshop on Link Discovery, pp. 36--43. 
Burger, J.D., Henderson J.C. (2006). An Exploration of 
Observable Features Related to Blogger Age. In: 
Proceedings of AAAI 2006 Spring Symposium on 
Computational Approaches to Analysing Weblogs, pp. 
15--20. 
Doran, C., Griffith, J., Henderson, J. (2006). Highlights 
from 12 Months of Blogs. In: Proceedings of AAAI 
2006 Spring Symposium on Computational 
Approaches to Analysing Weblogs, pp. 30--33. 
Glance, N., Hurst, M., Tornkiyo, T. (2004). Blogpulse: 
Automated Trend Discovery for Weblogs. In: 
Proceedings of WWW 2004 Workshop on the 
Weblogging Ecosystem: Aggregation, Analysis, and 
Dynamics. 
Hurst, M. (2006). 24 Hours in the Blogosphere. In: 
Proceedings of AAAI 2006 Spring Symposium on 
Computational Approaches to Analysing Weblogs, pp. 
73--77. 
ICWSM (2007). http://www.icwsm.org/data.html 
Kim, J.H. (2005). Blog as an Oppositional Medium? A 
Semantic Network Analysis on the Iraq War Blogs. In: 
Internet Research 6.0: Internet Generations. 
 
Manning, C.D., Sch?tze, H. (1999). Foundations of 
Statistical Natural Language Processing, The MIT 
Press, London England. 
Mei, Q., Liu, C., Su, H., Zhai, C. (2006). A Probabilistic 
Approach to Spatiotemporal Theme Pattern Mining on 
Weblogs. In: Proceedings of the 15th International 
Conference on World Wide Web, Edinburgh, Scotland, 
pp. 533--542. 
Oka, M., Abe, H., Kato, K. (2006). Extracting Topics 
from Weblogs Through Frequency Segments. In: 
Proceedings of WWW 2006 Annual Workshop on the 
Weblogging Ecosystem: Aggregation, Analysis, and 
Dynamics. 
Teng, C.Y., Chen, H.H. (2006). Detection of Bloggers? 
Interest: Using Textual, Temporal, and Interactive 
Features. In: Proceeding of IEEE/WIC/ACM 
International Conference on Web Intelligence, pp. 
366--369. 
Teng, C.Y., Chen, H.H. (2007). Analyzing Temporal 
Collocations in Weblogs. In: Proceeding of 
International Conference on Weblogs and Social 
Media, 303--304. 
Thelwall, M. (2006). Blogs During the London Attacks: 
Top Information Sources and Topics. In: Proceedings 
of 3rd Annual Workshop on the Weblogging 
Ecosystem: Aggregation, Analysis and Dynamics. 
Thompson, G. (2003). Weblogs, Warblogs, the Public 
Sphere, and Bubbles. Transformations, 7(2). 
Proceedings of the 8th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 81?90,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Licensing German Negative Polarity Items in LTAG
Timm Lichte
University of Tu?bingen
Collaborative Research Center 441
timm.lichte@uni-tuebingen.de
Laura Kallmeyer
University of Tu?bingen
Collaborative Research Center 441
lk@sfs.uni-tuebingen.de
Abstract
Our paper aims at capturing the distri-
bution of negative polarity items (NPIs)
within lexicalized Tree Adjoining Gram-
mar (LTAG). The condition under which
an NPI can occur in a sentence is for it to
be in the scope of a negation with no quan-
tifiers scopally intervening. We model this
restriction within a recent framework for
LTAG semantics based on semantic uni-
fication. The proposed analysis provides
features that signal the presence of a nega-
tion in the semantics and that specify its
scope. We extend our analysis to mod-
elling the interaction of NPI licensing and
neg raising constructions.
1 Introduction
1.1 Negative Polarity Items
NPIs are distributionally restricted to linguistic en-
vironments that exhibit a trigger for negativity (see
e.g., Ladusaw, 1980; Linebarger, 1987; Zwarts,
1997). More precisely, NPIs seek to be placed
within the scope of a negative operator at the level
of semantics. We say that the NPI has to be li-
censed by an exponent of negativity, the licenser.
Examples in German can be found in (1)?(5) (the
NPI is underlined while the licenser is in bold
face).
(1) a. Hans
Hans
war
was
nicht
not
sonderlich
very
zufrieden
happy
mit
with
seiner
his
Arbeit
work
b.*Hans war sonderlich zufrieden mit seiner
Arbeit
(2) a. Er
he
hat
has
es
it
nicht
not
wahrhaben
accept to be true
wollen
want
(?He did not want to accept it to be true?)
b.*Er hat es wahrhaben wollen.
(3) a. Es
it
schert
bothers
ihn
him
nicht
not
(?He does not give a damn about it?)
b.*Es schert ihn.
(4) a. Du
you
brauchst
need
diese
these
Bu?cher
books
nicht
not
zu
to
lesen
read
(?You need not read these books?)
b.*Du brauchst diese Bu?cher zu lesen.
(5) a. Niemand
nobody
hat
has
auch nur einen Cent
even one cent
gespendet.
donated
(?Nobody has donated any cent at all.?)
b.*Auch nur einen Cent hat niemand
gespendet.
We will mainly be concerned with verbal NPIs
such as wahrhaben wollen (?accept to be true?) and
scheren (?to give a damn about?). Another group
of NPIs we will pay closer attention to are min-
imizers, here exemplified by auch nur ein Cent
(?any Cent at all?). They are quantifiers denot-
ing the bottom line of a scale and therefore show
affinity with negation due to pragmatic reasons.
Furthermore, minimizers as quantifiers are subject
to particular position restrictions with respect to
negation (see next section). A group of NPIs we
will leave aside in this paper, however, is that of
adjectival NPIs such as sonderlich (?very?).
1.2 NPI Licensers
Various items and constructions can license NPIs.
Besides the more obvious ones such as not, no-
body and never, also (among others) few, re-
81
strictors of universal quantifiers, conditional ante-
cendents and questions can license at least some
of the NPIs. There has been much controversy
about what the characterizing logical property of
licensers is. One proposal is based on the notion
of downward entailment (DE, Ladusaw, 1980),
which holds for operators whose truth value is per-
sistent over specification. While the DE property
can be found in most of the licensers, there are
some, such as questions, where it is hard to detect
(see van der Wouden, 1997 for an overview).1
In our proposal we don?t make use of DE as an
NPI licensing criterion. Instead we only require
the negation operator (?) in the semantic represen-
tation as licensing feature. We thereby restrict our-
selves to triggers of ?classic? negation; we go even
further and only implement non-contrastive nega-
tion. We use this term after Jacobs (1982) where
non-contrastive negation (NCN) and contrastive
negation (CN) are examined for German. They
differ in that sentences with CN can be extended
by a but-phrase (Sondern-Phrase) while adding a
but-phrase to sentences with NCN gives odd re-
sults. Put differently, CN focuses on parts of a
sentence while NCN does not.2 Whether CN or
NCN is available, is indicated by intonation and
position of the negative element. However, am-
biguous indications are possible. In our analysis,
we leave aside intonation and stick to unambigu-
ous NCN as far as possible.
1.3 Semantic Scope and Range of Licensing
It is not sufficient for an NPI to just co-occur
with a licenser in the same sentence; it has to be
in the licenser?s scope. Furthermore, additional
constraints have been proposed in the literature.
One of the most extensively discussed requires the
NPI to be c-commanded by the licenser on sur-
face structure (c-command constraint, Ladusaw,
1980). As Hoeksema (2000) points out, the c-
command constraint is too restrictive when ap-
plied to languages with a considerably freer word
order than English, e.g. Dutch and German (see
(4) for an example that does not respect the c-
command constraint). He also points out that
the need for the c-command constraint only arises
1Giannakidou (1997) therefore proposes the idea of non-
veridicality as being the basic logical property of NPI-
licensers - eventually facing the problem of being less restric-
itive than required.
2If CN is available NPIs can only be licensed in the part
focused by CN.
from capturing the distribution of minimizers. All
other NPIs obey a simple scope constraint in terms
of Linebarger?s immediate scope constraint (ISC,
Linebarger, 1980; Linebarger, 1987), namely that
no other propositional operators (i.e. ?logical ele-
ments? that are capable of entering into scope am-
biguities) may intervene between the licenser and
the NPI on LF.
While the ISC seems to hold for quantifiers,
quantificational adverbs and operators that con-
join propositions such as because, there are in
fact some operators that may scopally intervene.
Among them are non-quantificational adverbs,
minimizers and modals, as in (6):
(6) Peter
Peter
hat
has
keinen
no
Finger
finger
ru?hren
move
mu?ssen.
must
(?Peter didn?t need to lift a finger.?)
In (6), the negation always has wide scope with
respect to the modal mu?ssen (must), hence mu?ssen
intervenes between negation and NPI, but still the
sentence is grammatical.
Thus, our criterion for an NPI to be licensed is
1. to be in the scope of a negation that is seman-
tically interpreted in the same finite clause, and
2. not to allow regular quantifiers to scopally in-
tervene between negation and NPI. In this paper,
we will also refer to these criterions as immedi-
ate scope.3 Minimizers seem to add a third crite-
rion, namely that the licenser has to syntactically
c-command the minimizer.
Independently from the ISC, one has to keep in
mind that negative elements in German are able to
cancel each other out, that is to constitute double
negation. We will come back to this briefly in sec-
tion 3.
1.4 Neg Raising Constructions
We extend our analysis to so-called neg raising
(NR, cf. Horn, 1978) constructions because there
are interesting interactions between NPI licensing
and neg raising.
3Note that with this approach, one negation can even li-
cense several NPIs as in (i):
(i) Kein
no
Schu?ler
pupil
hat
has
jemals
ever
in
in
den
the
Ferien
holidays
sonderlich
particularly
viel
much
gelernt.
learned
(?No pupil has ever learned very much during the hol-
idays.?)
82
An example of a NR-verb is glauben (?believe?)
in (7).
(7) Hans
Hans
glaubt
believes
nicht,
not
dass
that
Peter
Peter
kommt.
comes
(?Hans does not believe that Peter is com-
ing.?)
The negation can either take scope at its surface
position, i.e., scope over glauben, or it can scope
within the embedded sentence. Hence, two inter-
pretations are generally available: (a) ?believe(p)
and (b) believe(?p). The second reading is possi-
ble only with NR-verbs.
In LTAG, lexical material is generated at its sur-
face structure position, there is no movement out-
side the lexicon. Therefore it is natural to assume
with respect to sentences as (7), that the negation
is syntactically generated in the matrix clause and
that neg raising attitude verbs such as glauben al-
low for semantic lowering of an attached negation.
This negation then receives wide scope within the
sentential complement. In this, we follow the
HPSG analysis proposed in Sailer (to appear).
The presence of an NPI in the embedded sen-
tence as in (8) forces the negation to scope un-
der the bridge verb, that is the (b)-interpretation
is chosen.
(8) Hans
Hans
glaubt
believes
nicht,
not
dass
that
Peter
Peter
sonderlich
very
glu?cklich
happy
sein
be
wird.
will
(?Hans does not believe that Peter will be
very happy.?)
2 The LTAG Semantics Framework
We use the Kallmeyer and Romero (2005) frame-
work for semantics. Each elementary tree is linked
to a semantic representation containing Ty2 terms
and scope constraints. Ty2 terms are typed ?-
terms providing individuals and situations as basic
types. The terms can be labeled, and they can con-
tain meta-variables. The scope constraints are sub-
ordination constraints of the form x ? y (?y is a
component of x?) with x and y being either propo-
sitional labels or propositional meta-variables.
The semantic representations are equipped with
feature structure descriptions. Semantic compu-
tation is done on the derivation tree and consists
of certain feature value equations between mother
and daughter nodes of edges in the derivation tree.
l1 : laugh( 1 )
?
?
?
NP
[
GLOBAL
[
I 1
]
]
VP
[
B
[
P l1
]
]
?
?
?
np vp
john(x) l2 : always( 3 ),3 ? 4
[
GLOBAL
[
I x
]
] ?
?
?
VPr
[
B
[
P l2
]
]
VPf
[
B
[
P 4
]
]
?
?
?
Figure 1: LTAG semantics of (9)
The meta-variables from the semantic representa-
tions can occur in the feature structure descrip-
tions. In this case they can receive values follow-
ing from the feature value equations performed on
the derivation tree.
As an example see Fig. 1 showing the deriva-
tion tree for (9) with semantic representations and
semantic feature structure descriptions as node la-
bels.
(9) John always laughs
The additional feature equations in this example
are depicted with dotted links. They arise from
top-bottom feature identifications parallel to the
unifications performed in FTAG (Vijay-Shanker
and Joshi, 1988) and from identifications of global
features. They yield 1 = x and 4 = l1. Apply-
ing these identities to the semantic representations
after having built their union leads to (10). The
constraint 3 ? l1 states that l1 : laugh(x) is a
component of 3 .
(10)
john(x), l2 : always( 3 ),
l1 : laugh(x),
3 ? l1
We assume a scope window for quantifiers
specifying an upper boundary MAXS (?maximal
scope?) and a lower boundary MINS (?minimal
scope?) for the nuclear scope. In this we follow
Kallmeyer and Romero (2005). In addition, how-
ever, we make use of the feature MINP (?minimal
proposition?). In their analysis, which was devel-
oped for English, MINS and MINP are the same, in
other words, there is no separate MINP feature. In
German, the minimal scope of a quantifier seems
to depend not only on the verb the quantifier at-
taches to but also on other factors (see Kallmeyer
83
and Romero, 2006 in this volume for the influ-
ence of word order on quantifier scope in Ger-
man). This justifies the assumption that German
MINS if different from English MINS. The scope
order is of course such that MAXS is higher than
MINS which is in turn higher than MINP.
In order to deal with NPI-licensing we intro-
duce three new features: a global and a local NEG-
feature and the global feature N-SCOPE. Not sur-
prisingly, the latter represents the scope of a nega-
tive operator, while the former is needed to check
the presence of a negative operator. The next sec-
tion offers detailed examples.
3 The Analysis of Licensers
In this section we give the elementary trees for
non-contrastive nicht (not) and niemand (nobody).
A strong trigger for NCN is nicht attached to
the verb. Based on the topological field theory
for German the attachment takes place at the right
satzklammer, a position that together with the left
satzklammer contains the verbal expression.4 As
an example see the derivation for (11) in Fig. 2.
(11) Peter
Peter
ruft
calls
Hans
Hans
nicht
not
an
PART
(?Peter does not call Hans?)
Similar to Gerdes (2002), the VP nodes carry fea-
tures VF (?Vorfeld?), LK (?Linke Satzklammer?),
MF (?Mittelfeld?), and RK (?Rechte Satzklammer?)
for the topological fields. In German, the vorfeld,
the position preceding the left satzklammer, must
be filled by exactly one constituent. We guaran-
tee this with the feature VF: The different VF fea-
tures at the highest VP node in the tree for ruft an
make sure that adjunction to the vorfeld is obliga-
tory. At the same time, elements adjoining to any
of the topological fields (see the tree for Peter)
have a foot node feature VF = ? and have equal
top and bottom features VF at their root. When
4Exceptions to this generalization are found with verbs
that express movement:
(i) a. Peter
Peter
geht
goes
nicht
not
ins
to the
Kino.
movies
(?Peter does not go to the movies?)
b. *...
...
dass
that
Peter
Peter
ins
to the
Kino
movies
nicht
not
geht.
goes
(?... that Peter does not go to the movies?)
Here the NC-nicht is always attached to the adverb that ex-
presses the direction or target of the movement, thus not to the
second satzklammer directly. For this paper, we leave these
cases aside.
VP
[V F+]
[V F?]
V
[LK+, RK?]
VP
[V F?,MF+]
ruft NPnom VP
[V F?,MF+]
NPacc V
[LK?, RK+]
an
NPacc
Hans
V
nicht V [RK+]?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
VP
[V F 10 ]
[V F 10 ]
NP VP[V F?]?
Peter
NPnom
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
Figure 2: Syntactic analysis for (11)
adjoining to the vorfeld, these receive values +.
Consequently, further adjunctions of similar ele-
ments at the new root node are not possible. An
adjunction at the foot node of the auxiliary tree of
the vorfeld element can be excluded by some other
feature. This guarantees that exactly one element
gets adjoined into the vorfeld.
Note that we consider the base position of the
subject NP being in the mittelfeld and consider the
subject as being moved into the vorfeld. Alterna-
tively, any other element could be moved in to the
vorfeld instead.
The semantic combination of nicht and ruft an
is shown in Fig. 3.
The MINP feature from ruft indicates the propo-
sition contributed by the verb which is the mini-
mal proposition of the whole elementary tree. It is
included in the scope of all operators (quantifiers,
negation, modals, . . . ) attaching to this verb (An
exception is of course neg raising where the scope
of the negation does not include the MINP value of
the NR-verb.).
The unifications between the two feature struc-
tures in Fig. 3 are depicted with dotted lines. They
yield in particular 9 = 7 , therefore, with con-
straint 7 ? l1, l1 is in the scope of the negation.
The presence of a negation is indicated by a
global NEG = yes. In case there is no negation,
we have to make sure we obtain NEG = no and not
just an unspecified NEG value. Therefore, the VP
spine is articulated with non-global NEG features
that switch from no to yes once a negation occurs.
Here this is the case at node position V, conse-
quently 6 = 5 = 4 = 3 = yes. The topmost
84
l1 : call( 1 , 2 )
7 ? l1
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
GLOBAL
?
?
N-SCOPE 7
MINP l1
NEG 3
?
?
VP?
[
T
[
NEG 3
]
B
[
NEG 4
]
]
VP2
[
T
[
NEG 4
]
B
[
NEG 5
]
]
VP22
[
T
[
NEG 5
]
B
[
NEG 6
]
]
V
[
T
[
NEG 6
]
B
[
NEG no
]
]
NPnom
[
GLOBAL
[
I 1
]
]
NPacc
[
GLOBAL
[
I 2
]
]
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
v
l2 : ? 9
?
?
?
Vr
[
B
[
NEG yes
]
]
Vf
[
GLOBAL
[
N-SCOPE 9
]
]
?
?
?
Figure 3: Semantic computation for ... ruft ...
nicht an
NEG then becomes the global NEG.
Cases of double negation, though not consid-
ered here, could be captured by assuming that each
negation on the verbal spine makes the value of
the local NEG feature switch (from no to yes or, if
there was already negation, from yes to no). This
way, double negation would lead to a global NEG
feature with value no.
The negative quantifier niemand has the distri-
bution of an NP. The elementary trees in Fig. 4
for niemand reflect the ?? reading which is pre-
ferred by an analysis assuming that the NPI must
be in the scope of a negation with no quantifiers in-
tervening. The features NEG, MINP and N-SCOPE
work in the same way as in the case of nicht. The
global I feature linked to the initial tree with the
trace passes the argument variable to the verb.
Note that this is an analysis for the case where
niemand is ?moved?. If niemand is in base posi-
tion, the lexical item comes with an initial tree that
is substituted at the corresponding NP slot. How-
ever, since the NEG-feature can only be switched
to yes by adjoining an auxiliary tree carrying
negation to a VP node, even in these cases we
need an additional VP auxiliary tree contributing
the sentential negation.5
5Another option would be to let the initial tree of niemand
directly access the semantic features of a VP node.
?
?
?
?
?
?
?
VP
[V F 20 ]
[V F 20 ]
NP VP
[V F?]
?
niemand
NPnom
?
?
?
?
?
?
?
?
Semantics:
VP
[V F 20 ]
[V F 20 ]
NP VP
[V F?]
?
niemand
l2 : forall(x, 7 , 8 ),
l3 : person(x),
l4 : ? 9 ,
7 ? l3, 8 ? l4
?
?
?
VPr
[
B
[
NEG yes
]
]
VPf
[
GLOBAL
[
N-SCOPE 9
]
]
?
?
?
NPnom
? [
GLOBAL
[
I x
]
]
Figure 4: Lexical entry for niemand
4 The Analysis of NPIs
For this paper we restrict ourselves to verbal NPIs
and minimizers.
As an example for a verbal NPI consider
scheren (?to give a damn about sth.?) in (3). Its
lexical entry is shown in Fig. 5. As in the case of
ruft, the verbal spine is articulated with the NEG
feature. Furthermore, GLOBAL contains the re-
quirement of a negation (NEG = yes). In partic-
ular, the topmost NEG feature on the verbal spine
is yes while the value of the lowest NEG feature is
no. This means that at some point on the verbal
spine a negation must be added that switches the
value from no to yes.
Concerning the scope relation between NPI and
negation, the following should hold: 1. the NPI
must be in the scope of the negation, and 2. quan-
tifiers must not intervene between negation and
NPI.
The first condition is guaranteed with constraint
9 ? l1.
In order to capture the second restriction, the
distinction between MINS and MINP allows us
to draw a border line between the domain where
quantifiers can take scope and the domain where
the negation and the NPI are positioned. Other
scope taking operators (modals, adverbs, . . . )
are not concerned by this limit. This border line
is the MINS value, and the crucial NPI-specific
constraint is 8 ? 9 stating that the negation must
85
VP
[V F+]
[V F?]
V
[LK+, RK?]
VP
[V F?,MF+]
schert NPnom VP
[V F?,MF+]
NPacc V
[LK?, RK+]
?
l1 : scheren( 1 , 2 )
7 ? 8 , 8 ? l1,
8 ? 9 , 9 ? l1
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
GLOBAL
?
?
?
?
?
?
MINP l1
MINS 8
MAXS 7
N-SCOPE 9
NEG yes
?
?
?
?
?
?
VP?
[
T
[
NEG yes
]
B
[
NEG 4
]
]
VP2
[
T
[
NEG 4
]
B
[
NEG 5
]
]
VP22
[
T
[
NEG 5
]
B
[
NEG 6
]
]
V
[
T
[
NEG 6
]
B
[
NEG no
]
]
NPnom
[
GLOBAL
[
I 1
]
]
NPacc
[
GLOBAL
[
I 2
]
]
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
Figure 5: Lexical entry for schert
scope under the minimal scope of all quantifiers.
The scope relations then can be summarised as in
Fig. 6.
no NPI involved:
MAXS
MINS ?
MINP
NPI involved:
MAXS
MINS
?
NPI
MINP
Figure 6: Scope relations of MAXS, MINS and ?
with and without the involvement of an NPI.
As mentioned in 1.3 minimizers show a more
restrictive distribution than verbal NPIs. In addi-
tion to the two licensing conditions of verbal NPIs
stated above minimizers also obey a third licensing
condition in German: the negation must precede
the minimizer in the same clause or the negation
must have wide scope with respect to the sentence
containing the minimizer, such as in NR construc-
tions. Consider the minimizer auch nur einen Cent
(?any cent at all?) in example (5) and its proposed
lexical entry in Fig. 7.
?
?
?
?
?
?
?
VP
NP VP?
auch nur einen Cent
NPnom
?
?
?
?
?
?
?
?
l1 : exists(x, 1 , 2 )
l2 : Cent(x)
1 ? l2, 2 ? 6 , 4 ? l1,
5 ? 4
?
?
?
?
?
?
?
?
?
?
VPf
?
?
?
?
?
?
?
?
?
GLOBAL
?
?
?
?
N-SCOPE 4
MINS 5
MINP 6
NEG yes
?
?
?
?
T
[
NEG no
]
B
[
NEG no
]
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
[
GLOBAL
[
I x
]
]
Figure 7: Lexical entry for auch nur einen Cent
We propose a multicomponent lexical entry for
minimizers here, since they have to access the se-
mantic feature structure of the VP spine, and there-
fore have to be adjoined. This is different from
verbal NPIs (that are part of the VP spine by def-
inition), but similar to the negative quantifier nie-
mand. As for verbal NPIs the presence of a nega-
tion is ensured by the global NEG feature, that is
required to be yes. The scope condition is satis-
fied by the constraints 4 ? l1 and 5 ? 4 : the for-
mer one ensures that the semantic contribution of
auch nur einen Cent is part of N-SCOPE, while the
latter one prohibits any intervening regular quanti-
fier (by requiring N-SCOPE to be a subexpression
of MINS).6
In order to meet the third condition we have to
make sure that the negation appears somewhere to
the left of the minimizer. In other words, the nega-
tion is not attached between the right satzklammer
and the minimizer, but somewhere else (as ensured
by the global NEG feature). Remember that the
position of a negation is signaled by the local NEG
feature on the VP spine and its switch from no to
yes. One way to exploit this is to let the mini-
mizer semantically specify the VP node to which
6Note that, though being quantifiers, minimizers are not
concerned by the MAXS-MINS scope window. Instead, their
scope window is specified by N-SCOPE as upper limit and
MINP as lower limit (the latter results from constraint 2 ? 6 .
86
it can be attached. This is accomplished by the
VPf feature in the lexical entry for auch nur einen
Cent, where the local NEG is required to be no,
while the global NEG is yes. Thereby it is guaran-
teed that somewhere between the position where
the adjunction of the minimizer takes place and the
maximal projection of the VP the NEG feature has
to switch to yes with the aid of a negative item.
5 The Analysis of Neg Raising
Now let us turn to the neg raising examples from
section 1.4. Attitude verbs that optionally offer
neg raising are mapped onto two lexical entries
representing a non-NR- and a NR-reading. In
the latter, the negation takes wide scope within
the embedded clause. In other words, quantifiers
cannot scopally intervene between the embedding
verb and the negation. This is exemplified in (12).
(12) Peter
Peter
glaubt
believes
nicht,
not
dass
that
jeder
each
seiner
of his
Freunde
friends
kommen
come
wird.
will.
(?Peter does not believe that each of his
friends will come?)
The NR-reading (believes(p, ? ? ? ? ? ? ?) does not
exclude that Peter believes that some of his friends
will come. A reading where Peter believes that
none of his friends will come is not available. In
other words, the quantifier has to scope under the
negation.
The lexical entry for glaubt with the NR-
reading is shown in Fig. 8. In the syntax we as-
sume a substitution node for the sentential com-
plement. Long-distance dependencies are then
analysed with multicomponents. This choice was
motivated because in German, taking into ac-
count scrambling, more movement-based word or-
der variations are possible than in English. For
these we need multicomponents anyway (see the
elementary tree set for niemand), and then senten-
tial complements might be treated in parallel. The
S substitution node carries a syntactic feature NR
indicating that this is a neg raising construction.
The lowering of the negation is expressed as fol-
lows: the N-SCOPE of glaubt (variable 7 ), i.e., the
scope of the attaching negation, does not contain
the MINP of glaubt as in non-NR readings. In-
stead, it contains the MAXS (variable 9 ) of the em-
bedded sentence (constraint 7 ? 9 ). This MAXS
is usually contained in the propositional argument
VP
[V F+]
[V F?]
V
[LK+, RK?]
VP
[V F?,MF+]
glaubt NPnom VP
[V F?,MF+]
V
[LK?, RK+]
S
[nr+]
?
l1 : believe( 1 , 8 )
8 ? 7
7 ? 9
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
GLOBAL
?
?
MINP l1
N-SCOPE 7
NEG no
?
?
VP?
[
T
[
NEG yes
]
B
[
NEG 4
]
]
VP1
[
T
[
NEG 4
]
B
[
NEG 5
]
]
VP12
[
T
[
NEG 5
]
B
[
NEG 6
]
]
V
[
T
[
NEG 6
]
B
[
NEG no
]
]
S
[
GLOBAL
[
N-SCOPE 7
MAXS 9
]
]
NPnom
[
GLOBAL
[
I 1
]
]
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
Figure 8: Lexical entry for glaubt
of believe (see Kallmeyer and Romero, 2005); in
this special neg raising entry we even require the
N-SCOPE to be contained in this argument (con-
straint 8 ? 7 ). The MAXS feature 9 marks the
upper limit for the scope of all quantifiers occur-
ring inside the embedded clause. Consequently,
wide scope of the lowered negation with respect
to the embedded sentence is ensured.
The lexical entry for glaubt with NR-reading
also has to make sure that a negative element is at-
tached to its verbal spine. In this respect its seman-
tic feature structure resembles the one of a ver-
bal NPI, that is the NEG value has to be switched
to yes by adjunction. However, semantically the
negation is interpreted in the embedded sentence
and NPIs cannot be licensed in the matrix clause.
Therefore, the value of the global NEG feature is
no.
The complementizer of the embedded clause
takes care of setting the value of the embedded
global NEG to yes by identifying the NEG feature
of its S node with the topmost NEG feature on the
87
verbal spine of the embedded clause. In a non-NR-
reading, the complementizer only passes the NEG
value upwards, i.e., the global NEG of the embed-
ded clause specifies whether a negation is present
in the embedded clause.
S [nr+]
Comp VP [V F+]?
dass
[
S
[
T
[
NEG yes
]
]
]
Figure 9: Complementizer dass in neg raising con-
struction
With this analysis, if a NR-verb embeds an NPI
as in (8), the NPI requires the NR-reading; oth-
erwise the global NEG feature of the embedded
clause is no.
Next, we want to give an example derivation
of a sentence that contains an unlicensed NPI and
which amounts to contradicting scope constraints.
It concerns the following sentence:
(13) *Hans
Hans
glaubt
believes
nicht,
not,
dass
that
es
it
jeden
everybody
schert.
bothers
(?Hans doesn?t believe that everybody
gives a damn about it.?)
The NPI schert is not licensed due to the inter-
vening quantifier jeden (every). The defective
dervation of (13) is shown in Fig. 10. Syntacti-
cally, the S leaf of the Hans glaubt nicht tree
is substituted by the dass es schert tree and the
jeder tree is substituted into the dass es schert
tree. This works fine. In the semantic represen-
tation, however, we observe a clash of the scope
constraints. Remember that we analyse the ver-
bal NPI schert as requiring immediate scope, that
is MINS ? N-SCOPE. On the other side, the
NR-verb glauben demands the negation to have
wide scope with respect to the embedded sentence,
hence N-SCOPE ? MAXS (constraint l2 ? 3 ) . If
we put these two constraints together we obtain
the constraint MINS = MAXS, which means that
the area where quantifiers take scope (the MAXS-
MINS window) is empty and hence there cannot
be any quantifiers. A quantifer such as jeden is
then ruled out due to two semantic constraints it
contributes: its semantic content is a subexpres-
sion of MAXS (constraint 3 ? l3) and MINS is
a subexpression of its nuclear scope (constraint
6 ? l2). However, this can only hold if MINS
6= MAXS which is not true for (13) as has been
shown.
Hans glaubt nicht
l1 : believe(Hans, 1 )
l5 : ?l2
1 ? l2, l2 ? 3
?
?
?
?
?
?
?
GLOBAL
?
?
MINP l1
N-SCOPE 7
NEG no
?
?
Sf
[
GLOBAL
[
N-SCOPE 7
MAXS 3
]
]
?
?
?
?
?
?
?
dass es schert
l2 : es schert( 4 , es)
7 ? l2
?
?
?
?
GLOBAL
?
?
?
?
MINP l2
MINS 7
N-SCOPE 7
NEG yes
?
?
?
?
?
?
?
?
jeden
l3 : every(x, 5 , 6 )
l4 : person(x)
5 ? l4, 3 ? 6 , 6 ? 7
3 ? l3
?
?
?
?
GLOBAL
[
I x
]
NP
[
GLOBAL
[
MINS 7
MAXS 3
]
]
?
?
?
?
Figure 10: Defective derivation tree for Hans
glaubt nicht, dass es jeden schert
6 Conclusion and further research
We propose an LTAG analysis of the distribution
of German NPIs. The crucial criterion for an NPI
is the requirement to be in the scope of a nega-
tion that is semantically in the same finite clause
such that no quantifier can scopally intervene be-
tween negation and NPI. Technically we achieved
this using the features NEG and N-SCOPE, that sig-
nal the presence of a negation and make its imme-
diate scope available for the NPI. 7 The specific
constraints for quantifiers when occurring with
7Note however, that, even though we have called the fea-
ture signalling the presence of a potential NPI licenser NEG,
we might as well call it differently and give it a different
meaning (for example, encoding downward entailment in-
stead of negation). The licensing mechanism and the way this
feature is used could stay the same. In this sense our analysis
is independent from the concrete logical characterization of
NPI licensers.
88
NPI licensing negations are obtained by a distinc-
tion between the feature MINS characterizing the
lower boundary of quantifier scope and the mini-
mal proposition contributed by a verb that charac-
terizes the lower boundary for the scope of nega-
tions.
We think LTAG is particularly well suited to de-
scribe this phenomenon since the relation between
licenser and licensee can be localized within sin-
gle elementary trees.8 The only exception are neg
raising constructions where the licensing property
needs to be passed down to the embedded clause.
This is not non-local either and can be easily mod-
elled in LTAG. This shows that LTAG?s extended
domain of locality has advantages not only for
syntax (see Kroch, 1987) but also for semantics.
The analyses discussed in this paper have
demonstrated the usefulness of semantic feature
structure descriptions that specify the combination
possibilities of semantic representations and that
are separated from the semantic representations
themselves. On the one hand the semantic features
encode the contributions of the semantic represen-
tations to functional applications. I.e., they state
which elments are contributed as possible argu-
ments for other semantic expressions and which
arguments need to be filled. They thereby simu-
late lambda abstraction and functional application.
On the other hand they also serve to model the
scopal behaviour of different operators and to cap-
ture the different boundaries for scope. The com-
bination of LTAG?s extended domain of locality
with a semantics using feature structure unifica-
tion enables us to capture these constraints within
a mildly context-sensitive framework: The struc-
tures underlying the computation of syntax and se-
mantics are the context-free derivation trees.
One line of further research we want to pursue is
an extension of the proposed analysis to adjectival
and adverbial NPIs. We already started working
on this. But for reasons of space we left this out in
this paper.
Acknowledgements
For many inspiring discussions of the topics
treated in this paper, we are grateful to our col-
leagues Wolfgang Maier, Frank Richter, Manfred
8In the HPSG analysis from Soehn (2006) for example,
where we do not have an extended domain of locality, one
has to specify explicitely that the licenser of an NPI must be
found within the next complete clause containing the NPI.
Sailer and Jan-Philipp So?hn. Furthermore, the pa-
per benefitted a lot from the useful comments of
three anonymous reviewers.
References
Kim Gerdes. 2002. DTAG? In Proceedings of TAG+6
Workshop, pages 242?251. Venice.
Anastasia Giannakidou. 1997. The Landscape of Po-
larity Items. Ph.D. thesis, Rijksuniversiteit Gronin-
gen.
Jack Hoeksema. 2000. Negative Polarity Items: Trig-
gering, Scope and C-Command. In Laurence Horn
and Yasuhiko Kato, editors, Negation and Polarity,
pages 115?146. Oxford University Press, Oxford.
Laurence R. Horn. 1978. Remarks on Neg-Raising.
In Peter Cole, editor, Pragmatics, pages 129?220.
Academic Press, New York, San Francisco, London.
Joachim Jacobs. 1982. Syntax und Semantik der Nega-
tion im Deutschen. Wilhelm Fink Verlag, Mu?nchen.
Laura Kallmeyer and Maribel Romero. 2005. Scope
and Situation Binding in LTAG using Semantic Uni-
fication. Research on Language and Computation.
57 pages, submitted.
Laura Kallmeyer and Maribel Romero. 2006. Quan-
tifier Scope in German: An MCTAG Analysis.
In Proceedings of The Eighth International Work-
shop on Tree Adjoining Grammar and Related For-
malisms (TAG+8), Sydney, Australia, July.
Anthony S. Kroch. 1987. Unbounded Dependen-
cies and Subjacency in a Tree Adjoining Grammar.
In A. Manaster-Ramer, editor, Mathematics of Lan-
guage, pages 143?172. John Benjamins, Amster-
dam.
William Ladusaw. 1980. Polarity Sensitivity as Inher-
ent Scope relations. Garland Press, New York.
Marcia Linebarger. 1980. The Grammar of Negative
Polarity. Ph.D. thesis, MIT. cited after the repro-
duction by the Indiana University Linguistics Club,
Indiana, 1981.
Marcia Linebarger. 1987. Negative Polarity and
Grammatical Representation. Linguistics and Phi-
losophy, 10:325?387.
Manfred Sailer. to appear. ?Don?t Believe? in Under-
specified Semantics. an LRS Analysis of Neg Rais-
ing. Empirical Issues in Formal Syntax and Seman-
tics 6.
Jan-Philipp Soehn. 2006. ?Uber Ba?rendienste und er-
staunte Bauklo?tze - Idiome ohne freie Lesart in der
HPSG. Ph.D. thesis, Fiedrich-Schiller Universita?t
Jena.
89
Ton van der Wouden. 1997. Negative Contexts. Collo-
cation, Polarity and Multiple Negation. Routledge,
London.
K. Vijay-Shanker and Aravind K. Joshi. 1988. Fea-
ture Structures Based Tree Adjoining Grammar. In
Proceedings of COLING, pages 714?719, Budapest.
Frans Zwarts. 1997. Three Types of Polarity. In
Fritz Hamm and Erhard W. Hinrichs, editors, Plu-
rality and Quantification, pages 177?237. Kluwer
Academic Publishers, Dordrecht.
90
Coling 2008: Proceedings of the workshop on Grammar Engineering Across Frameworks, pages 1?8
Manchester, August 2008
TuLiPA: Towards a Multi-Formalism Parsing Environment for
Grammar Engineering
Laura Kallmeyer
SFB 441
Universita?t Tu?bingen
D-72074, Tu?bingen, Germany
lk@sfs.uni-tuebingen.de
Yannick Parmentier
CNRS - LORIA
Nancy Universite?
F-54506, Vand?uvre, France
parmenti@loria.fr
Timm Lichte
SFB 441
Universita?t Tu?bingen
D-72074, Tu?bingen, Germany
timm.lichte@uni-tuebingen.de
Johannes Dellert
SFB 441 - SfS
Universita?t Tu?bingen
D-72074, Tu?bingen, Germany
{jdellert,kevang}@sfs.uni-tuebingen.de
Wolfgang Maier
SFB 441
Universita?t Tu?bingen
D-72074, Tu?bingen, Germany
wo.maier@uni-tuebingen.de
Kilian Evang
SFB 441 - SfS
Universita?t Tu?bingen
D-72074, Tu?bingen, Germany
Abstract
In this paper, we present an open-source
parsing environment (Tu?bingen Linguistic
Parsing Architecture, TuLiPA) which uses
Range Concatenation Grammar (RCG)
as a pivot formalism, thus opening the
way to the parsing of several mildly
context-sensitive formalisms. This en-
vironment currently supports tree-based
grammars (namely Tree-Adjoining Gram-
mars (TAG) and Multi-Component Tree-
Adjoining Grammars with Tree Tuples
(TT-MCTAG)) and allows computation not
only of syntactic structures, but also of the
corresponding semantic representations. It
is used for the development of a tree-based
grammar for German.
1 Introduction
Grammars and lexicons represent important lin-
guistic resources for many NLP applications,
among which one may cite dialog systems, auto-
matic summarization or machine translation. De-
veloping such resources is known to be a complex
task that needs useful tools such as parsers and
generators (Erbach, 1992).
Furthermore, there is a lack of a common frame-
work allowing for multi-formalism grammar engi-
neering. Thus, many formalisms have been pro-
posed to model natural language, each coming
with specific implementations. Having a com-
mon framework would facilitate the comparison
c
? 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
between formalisms (e.g., in terms of parsing com-
plexity in practice), and would allow for a better
sharing of resources (e.g., having a common lex-
icon, from which different features would be ex-
tracted depending on the target formalism).
In this context, we present a parsing environ-
ment relying on a general architecture that can
be used for parsing with mildly context-sensitive
(MCS) formalisms1 (Joshi, 1987). Its underly-
ing idea is to use Range Concatenation Grammar
(RCG) as a pivot formalism, for RCG has been
shown to strictly include MCS languages while be-
ing parsable in polynomial time (Boullier, 2000).
Currently, this architecture supports tree-based
grammars (Tree-Adjoining Grammars and Multi-
Component Tree-Adjoining Grammars with Tree
Tuples (Lichte, 2007)). More precisely, tree-
based grammars are first converted into equivalent
RCGs, which are then used for parsing. The result
of RCG parsing is finally interpreted to extract a
derivation structure for the input grammar, as well
as to perform additional processings (e.g., seman-
tic calculus, extraction of dependency views).
The paper is structured as follows. In section 2,
we present the architecture of the TuLiPA parsing
environment and show how the use of RCG as a
pivot formalism makes it easier to design a modu-
lar system that can be extended to support several
dimensions (syntax, semantics) and/or formalisms.
In section 3, we give some desiderata for gram-
mar engineering and present TuLiPA?s current state
1A formalism is said to be mildly context sensitive (MCS)
iff (i) it generates limited cross-serial dependencies, (ii) it is
polynomially parsable, and (iii) the string languages gener-
ated by the formalism have the constant growth property (e.g.,
{a
2
n
|n ? 0} does not have this property). Examples of MCS
formalisms include Tree-Adjoining Grammars, Combinatory
Categorial Grammars and Linear Indexed Grammars.
1
with respect to these. In section 4, we compare
this system with existing approaches for parsing
and more generally for grammar engineering. Fi-
nally, in section 5, we conclude by presenting fu-
ture work.
2 Range Concatenation Grammar as a
pivot formalism
The main idea underlying TuLiPA is to use RCG
as a pivot formalism for RCG has appealing for-
mal properties (e.g., a generative capacity lying be-
yond Linear Context Free Rewriting Systems and
a polynomial parsing complexity) and there ex-
ist efficient algorithms, for RCG parsing (Boullier,
2000) and for grammar transformation into RCG
(Boullier, 1998; Boullier, 1999).
Parsing with TuLiPA is thus a 3-step process:
1. The input tree-based grammar is converted
into an RCG (using the algorithm of
Kallmeyer and Parmentier (2008) when deal-
ing with TT-MCTAG).
2. The resulting RCG is used for parsing the in-
put string using an extension of the parsing
algorithm of Boullier (2000).
3. The RCG derivation structure is interpreted to
extract the derivation and derived trees with
respect to the input grammar.
The use of RCG as a pivot formalism, and thus
of an RCG parser as a core component of the sys-
tem, leads to a modular architecture. In turns, this
makes TuLiPA more easily extensible, either in
terms of functionalities, or in terms of formalisms.
2.1 Adding functionalities to the parsing
environment
As an illustration of TuLiPA?s extensibility, one
may consider two extensions applied to the system
recently.
First, a semantic calculus using the syn-
tax/semantics interface for TAG proposed by Gar-
dent and Kallmeyer (2003) has been added. This
interface associates each tree with flat semantic
formulas. The arguments of these formulas are
unification variables, which are co-indexed with
features labelling the nodes of the syntactic tree.
During classical TAG derivation, trees are com-
bined, triggering unifications of the feature struc-
tures labelling nodes. As a result of these unifica-
tions, the arguments of the semantic formulas are
unified (see Fig. 1).
S
NP?x VP
NP
j
V NP?y NP
m
John loves Mary
name(j,john) love(x,y) name(m,mary)
; love(j,m),name(j,john),name(m,mary)
Figure 1: Semantic calculus in Feature-Based
TAG.
In our system, the semantic support has been in-
tegrated by (i) extending the internal tree objects to
include semantic formulas (the RCG-conversion is
kept unchanged), and (ii) extending the construc-
tion of the derived tree (step 3) so that during the
interpretation of the RCG derivation in terms of
tree combinations, the semantic formulas are car-
ried and updated with respect to the feature unifi-
cations performed.
Secondly, let us consider lexical disambigua-
tion. Because of the high redundancy lying within
lexicalized formalisms such as lexicalized TAG,
it is common to consider tree schemata having a
frontier node marked for anchoring (i.e., lexical-
ization). At parsing time, the tree schemata are
anchored according to the input string. This an-
choring selects a subgrammar supposed to cover
the input string. Unfortunately, this subgrammar
may contain many trees that either do not lead to
a parse or for which we know a priori that they
cannot be combined within the same derivation
(so we should not predict a derivation from one
of these trees to another during parsing). As a re-
sult, the parser could have poor performance be-
cause of the many derivation paths that have to
be explored. Bonfante et al (2004) proposed to
polarize the structures of the grammar, and to ap-
ply an automaton-based filtering of the compatible
structures. The idea is the following. One compute
polarities representing the needs/resources brought
by a given tree (or tree tuple for TT-MCTAG).
A substitution or foot node with category NP re-
flects a need for an NP (written NP-). In the same
way, an NP root node reflects a resource of type
NP (written NP+). Then you build an automaton
whose edges correspond to trees, and states to po-
larities brought by trees along the path. The au-
tomaton is then traversed to extract all paths lead-
ing to a final state with a neutral polarity for each
category and +1 for the axiom (see Fig. 2, the state
2
7 is the only valid state and {proper., trans., det.,
noun.} the only compatible set of trees).
0
John
1 1
eats
2 2
a
3 3
cake
4
0 1
NP+
2
S+
3
S+ NP-
4
S+
5
S+ NP-
6
S+ NP+
7
S+
proper.
intrans.
trans.
det.
det.
noun.
noun.
Figure 2: Polarity-based lexical disambiguation.
In our context, this polarity filtering has been
added before step 1, leaving untouched the core
RCG conversion and parsing steps. The idea is
to compute the sets of compatible trees (or tree
tuples for TT-MCTAG) and to convert these sets
separately. Indeed the RCG has to encode only
valid adjunctions/substitutions. Thanks to this
automaton-based ?clustering? of the compatible
tree (or tree tuples), we avoid predicting incompat-
ible derivations. Note that the time saved by using
a polarity-based filter is not negligible, especially
when parsing long sentences.2
2.2 Adding formalisms to the parsing
environment
Of course, the two extensions introduced in the
previous section may have been added to other
modular architectures as well. The main gain
brought by RCG is the possibility to parse not
only tree-based grammars, but other formalisms
provided they can be encoded into RCG. In our
system, only TAG and TT-MCTAG have been
considered so far. Nonetheless, Boullier (1998)
and S?gaard (2007) have defined transformations
into RCG for other mildly context-sensitive for-
malisms.3
To sum up, the idea would be to keep the core
RCG parser, and to extend TuLiPA with a specific
conversion module for each targeted formalism.
On top of these conversion modules, one should
also provide interpretation modules allowing to de-
code the RCG derivation forest in terms of the in-
put formalism (see Fig. 3).
2An evaluation of the gain brought by this technique when
using Interaction Grammar is given by Bonfante et al (2004).
3These include Multi-Component Tree-Adjoining Gram-
mar, Linear Indexed Grammar, Head Grammar, Coupled
Context Free Grammar, Right Linear Unification Grammar
and Synchronous Unification Grammar.
Figure 3: Towards a multi-formalism parsing envi-
ronment.
An important point remains to be discussed. It
concerns the role of lexicalization with respect to
the formalism used. Indeed, the tree-based gram-
mar formalisms currently supported (TAG and TT-
MCTAG) both share the same lexicalization pro-
cess (i.e., tree anchoring). Thus the lexicon format
is common to these formalisms. As we will see
below, it corresponds to a 2-layer lexicon made of
inflected forms and lemma respectively, the latter
selecting specific grammatical structures. When
parsing other formalisms, it is still unclear whether
one can use the same lexicon format, and if not
what kind of general lexicon management module
should be added to the parser (in particular to deal
with morphology).
3 Towards a complete grammar
engineering environment
So far, we have seen how to use a generic parsing
architecture relying on RCG to parse different for-
malisms. In this section, we adopt a broader view
and enumerate some requirements for a linguistic
resource development environment. We also see
to what extent these requirements are fulfilled (or
partially fulfilled) within the TuLiPA system.
3.1 Grammar engineering with TuLiPA
As advocated by Erbach (1992), grammar en-
gineering needs ?tools for testing the grammar
with respect to consistency, coverage, overgener-
ation and accuracy?. These characteristics may
be taken into account by different interacting soft-
ware. Thus, consistency can be checked by a semi-
automatic grammar production device, such as the
XMG system of Duchier et al (2004). Overgen-
eration is mainly checked by a generator (or by
a parser with adequate test suites), and coverage
and accuracy by a parser. In our case, the TuLiPA
system provides an entry point for using a gram-
mar production system (and a lexicon conversion
3
tool introduced below), while including a parser.
Note that TuLiPA does not include any generator,
nonetheless it uses the same lexicon format as the
GenI surface realizer for TAG4.
TuLiPA?s input grammar is designed using
XMG, which is a metagrammar compiler for tree-
based formalisms. In other terms, the linguist de-
fines a factorized description of the grammar (the
so-called metagrammar) in the XMG language.
Briefly, an XMG metagrammar consists of (i) ele-
mentary tree fragments represented as tree descrip-
tion logic formulas, and (ii) conjunctive and dis-
junctive combinations of these tree fragments to
describe actual TAG tree schemata.5 This meta-
grammar is then compiled by the XMG system to
produce a tree grammar in an XML format. Note
that the resulting grammar contains tree schemata
(i.e., unlexicalized trees). To lexicalize these, the
linguist defines a lexicon mapping words with cor-
responding sets of trees. Following XTAG (2001),
this lexicon is a 2-layer lexicon made of morpho-
logical and lemma specifications. The motivation
of this 2-layer format is (i) to express linguistic
generalizations at the lexicon level, and (ii) to al-
low the parser to only select a subgrammar accord-
ing to a given sentence, thus reducing parsing com-
plexity. TuLiPA comes with a lexicon conversion
tool (namely lexConverter) allowing to write a lex-
icon in a user-friendly text format and to convert it
into XML. An example of an entry of such a lexi-
con is given in Fig. 4.
The morphological specification consists of a
word, the corresponding lemma and morphologi-
cal features. The main pieces of information con-
tained in the lemma specification are the ?ENTRY
field, which refers to the lemma, the ?CAT field
referring to the syntactic category of the anchor
node, the ?SEM field containing some semantic in-
formation allowing for semantic instantiation, the
?FAM field, which contains the name of the tree
family to be anchored, the ?FILTERS field which
consists of a feature structure constraining by uni-
fication the trees of a given family that can be
anchored by the given lemma (used for instance
for non-passivable verbs), the ?EQUATIONS field
allowing for the definition of equations targeting
named nodes of the trees, and the ?COANCHORS
field, which allows for the specification of co-
anchors (such as by in the verb to come by).
4http://trac.loria.fr/?geni
5See (Crabbe?, 2005) for a presentation on how to use the
XMG formalism for describing a core TAG for French.
Morphological specification:
vergisst vergessen [pos=v,num=sg,per=3]
Lemma specification:
?ENTRY: vergessen
?CAT: v
?SEM: BinaryRel[pred=vergessen]
?ACC: 1
?FAM: Vnp2
?FILTERS: []
?EX:
?EQUATIONS:
NParg1 ? cas = nom
NParg2 ? cas = acc
?COANCHORS:
Figure 4: Morphological and lemma specification
of vergisst.
From these XML resources, TuLiPA parses a
string, corresponding either to a sentence or a con-
stituent (noun phrase, prepositional phrase, etc.),
and computes several output pieces of informa-
tion, namely (for TAG and TT-MCTAG): deriva-
tion/derived trees, semantic representations (com-
puted from underspecified representations using
the utool software6, or dependency views of the
derivation trees (using the DTool software7).
3.2 Grammar debugging
The engineering process introduced in the preced-
ing section belongs to a development cycle, where
one first designs a grammar and corresponding
lexicons using XMG, then checks these with the
parser, fixes them, parses again, and so on.
To facilitate grammar debugging, TuLiPA in-
cludes both a verbose and a robust mode allow-
ing respectively to (i) produce a log of the RCG-
conversion, RCG-parsing and RCG-derivation in-
terpretation, and (ii) display mismatching features
leading to incomplete derivations. More precisely,
in robust mode, the parser displays derivations step
by step, highlighting feature unification failures.
TuLiPA?s options can be activated via an intu-
itive Graphical User Interface (see Fig. 5).
6See http://www.coli.uni-saarland.de/
projects/chorus/utool/, with courtesy of Alexander
Koller.
7With courtesy of Marco Kuhlmann.
4
Figure 5: TuLiPA?s Graphical User Interface.
3.3 Towards a functional common interface
Unfortunately, as mentioned above, the linguist
has to move back-and-forth from the gram-
mar/lexicon descriptions to the parser, i.e., each
time the parser reports grammar errors, the linguist
fixes these and then recomputes the XML files and
then parses again. To avoid this tedious task of re-
sources re-compilation, we started developing an
Eclipse8 plug-in for the TuLiPA system. Thus, the
linguist will be able to manage all these resources,
and to call the parser, the metagrammar compiler,
and the lexConverter from a common interface (see
Fig. 6).
Figure 6: TuLiPA?s eclipse plug-in.
The motivation for this plug-in comes from
the observation that designing electronic gram-
mars is a task comparable to designing source
8See http://www.eclipse.org
code. A powerful grammar engineering environ-
ment should thus come with development facili-
ties such as precise debugging information, syntax
highlighting, etc. Using the Eclipse open-source
development platform allows for reusing several
components inherited from the software develop-
ment community, such as plug-ins for version con-
trol, editors coupled with explorers, etc.
Eventually, one point worth considering in the
context of grammar development concerns data en-
coding. To our knowledge, only few environments
provide support for UTF-8 encoding, thus guaran-
tying the coverage of a wide set of charsets and
languages. In TuLiPA, we added an UTF-8 sup-
port (in the lexConverter), thus allowing to design
a TAG for Korean (work in progress).
3.4 Usability of the TuLiPA system
As mentioned above, the TuLiPA system is made
of several interacting components, that one cur-
rently has to install separately. Nonetheless, much
attention has been paid to make this installation
process as easy as possible and compatible with
all major platforms.9
XMG and lexConverter can be installed by com-
piling their sources (using a make command).
TuLiPA is developed in Java and released as an ex-
ecutable jar. No compilation is needed for it, the
only requirement is the Gecode/GecodeJ library10
(available as a binary package for many platforms).
Finally, the TuLiPA eclipse plug-in can be installed
easily from eclipse itself. All these tools are re-
leased under Free software licenses (either GNU
GPL or Eclipse Public License).
This environment is being used (i) at the Univer-
sity of Tu?bingen, in the context of the development
of a TT-MCTAG for German describing both syn-
tax and semantics, and (ii) at LORIA Nancy, in the
development of an XTAG-based metagrammar for
English. The German grammar, called GerTT (for
German Tree Tuples), is released under a LGPL li-
cense for Linguistic Resources11 and is presented
in (Kallmeyer et al, 2008). The test-suite cur-
rently used to check the grammar is hand-crafted.
A more systematic evaluation of the grammar is in
preparation, using the Test Suite for Natural Lan-
guage Processing (Lehmann et al, 1996).
9See http://sourcesup.cru.fr/tulipa.
10See http://www.gecode.org/gecodej.
11See http://infolingu.univ-mlv.
fr/DonneesLinguistiques/
Lexiques-Grammaires/lgpllr.html
5
4 Comparison with existing approaches
4.1 Engineering environments for tree-based
grammar formalisms
To our knowledge, there is currently no available
parsing environment for multi-component TAG.
Existing grammar engineering environments for
TAG include the DyALog system12 described in
Villemonte de la Clergerie (2005). DyALog is a
compiler for a logic programming language using
tabulation and dynamic programming techniques.
This compiler has been used to implement efficient
parsing algorithms for several formalisms, includ-
ing TAG and RCG. Unfortunately, it does not in-
clude any built-in GUI and requires a good know-
ledge of the GNU build tools to compile parsers.
This makes it relatively difficult to use. DyALog?s
main quality lies in its efficiency in terms of pars-
ing time and its capacity to handle very large re-
sources. Unlike TuLiPA, it does not compute se-
mantic representations.
The closest approach to TuLiPA corresponds to
the SemTAG system13, which extends TAG parsers
compiled with DyALog with a semantic calculus
module (Gardent and Parmentier, 2007). Unlike
TuLiPA, this system only supports TAG, and does
not provide any graphical output allowing to easily
check the result of parsing.
Note that, for grammar designers mainly inter-
ested in TAG, SemTAG and TuLiPA can be seen
as complementary tools. Indeed, one may use
TuLiPA to develop the grammar and check spe-
cific syntactic structures thanks to its intuitive pars-
ing environment. Once the grammar is stable, one
may use SemTAG in batch processing to parse
corpuses and build semantic representations using
large grammars. This combination of these 2 sys-
tems is made easier by the fact that both use the
same input formats (a metagrammar in the XMG
language and a text-based lexicon). This approach
is the one being adopted for the development of a
French TAG equipped with semantics.
For Interaction Grammar (Perrier, 2000), there
exists an engineering environment gathering the
XMG metagrammar compiler and an eLEtrOstatic
PARser (LEOPAR).14 This environment is be-
ing used to develop an Interaction Grammar for
French. TuLiPA?s lexical disambiguation module
12See http://dyalog.gforge.inria.fr
13See http://trac.loria.fr/?semconst
14See http://www.loria.fr/equipes/
calligramme/leopar/
reuses techniques introduced by LEOPAR. Unlike
TuLiPA, LEOPAR does not currently support se-
mantic information.
4.2 Engineering environments for other
grammar formalisms
For other formalisms, there exist state-of-the-art
grammar engineering environments that have been
used for many years to design large deep grammars
for several languages.
For Lexical Functional Grammar, one may cite
the Xerox Linguistic Environment (XLE).15 For
Head-driven Phrase Structure Grammar, the main
available systems are the Linguistic Knowledge
Base (LKB)16 and the TRALE system.17 For
Combinatory Categorial Grammar, one may cite
the OpenCCG library18 and the C&C parser.19
These environments have been used to develop
broad-coverage resources equipped with semantics
and include both a generator and a parser. Un-
like TuLiPA, they represent advanced projects, that
have been used for dialog and machine translation
applications. They are mainly tailored for a spe-
cific formalism.20
5 Future work
In this section, we give some prospective views
concerning engineering environments in general,
and TuLiPA in particular. We first distinguish be-
tween 2 main usages of grammar engineering en-
vironments, namely a pedagogical usage and an
application-oriented usage, and finally give some
comments about multi-formalism.
5.1 Pedagogical usage
Developing grammars in a pedagogical context
needs facilities allowing for inspection of the struc-
tures of the grammar, step-by-step parsing (or gen-
eration), along with an intuitive interface. The idea
is to abstract away from technical aspects related to
implementation (intermediate data structures, opti-
mizations, etc.).
15See http://www2.parc.com/isl/groups/
nltt/xle/
16See http://wiki.delph-in.net/moin
17See http://milca.sfs.uni-tuebingen.de/
A4/Course/trale/
18See http://openccg.sourceforge.net/
19See http://svn.ask.it.usyd.edu.au/trac/
candc/wiki
20Nonetheless, Beavers (2002) encoded a CCG in the
LKB?s Type Description Language.
6
The question whether to provide graphical or
text-based editors can be discussed. As advo-
cated by Baldridge et al (2007), a low-level text-
based specification can offer more flexibility and
bring less frustration to the grammar designer, es-
pecially when such a specification can be graph-
ically interpreted. This is the approach chosen
by XMG, where the grammar is defined via an
(advanced or not) editor such as gedit or emacs.
Within TuLiPA, we chose to go further by using
the Eclipse platform. Currently, it allows for dis-
playing a summary of the content of a metagram-
mar or lexicon on a side panel, while editing these
on a middle panel. These two panels are linked
via a jump functionality. The next steps concern
(i) the plugging of a graphical viewer to display
the (meta)grammar structures independently from
a given parse, and (ii) the extension of the eclipse
plug-in so that one can easily consistently modify
entries of the metagrammar or lexicon (especially
when these are split over several files).
5.2 Application-oriented usage
When dealing with applications, one may demand
more from the grammar engineering environment,
especially in terms of efficiency and robustness
(support for larger resources, partial parsing, etc.).
Efficiency needs optimizations in the parsing
engine making it possible to support grammars
containing several thousands of structures. One
interesting question concerns the compilation of a
grammar either off-line or on-line. In DyALog?s
approach, the grammar is compiled off-line into
a logical automaton encoding all possible deriva-
tions. This off-line compilation can take some
minutes with a TAG having 6000 trees, but the re-
sulting parser can parse sentences within a second.
In TuLiPA?s approach, the grammar is compiled
into an RCG on-line. While giving satisfactory re-
sults on reduced resources21 , it may lead to trou-
bles when scaling up. This is especially true for
TAG (the TT-MCTAG formalism is by definition a
factorized formalism compared with TAG). In the
future, it would be useful to look for a way to pre-
compile a TAG into an RCG off-line, thus saving
the conversion time.
Another important feature of grammar engineer-
ing environments consists of its debugging func-
21For a TT-MCTAG counting about 300 sets of trees and an
and-crafted lexicon made of about 300 of words, a 10-word
sentence is parsed (and a semantic representation computed)
within seconds.
tionalities. Among these, one may cite unit and
integration testing. It would be useful to extend
the TuLiPA system to provide a module for gen-
erating test-suites for a given grammar. The idea
would be to record the coverage and analyses of
a grammar at a given time. Once the grammar is
further developed, these snapshots would allow for
regression testing.
5.3 About multi-formalism
We already mentioned that TuLiPA was opening
a way towards multi-formalism by relying on an
RCG core. It is worth noticing that the XMG
system was also designed to be further extensi-
ble. Indeed, a metagrammar in XMG corresponds
to the combination of elementary structures. One
may think of designing a library of such structures,
these would be dependent on the target gram-
mar formalism. The combinations may represent
general linguistic concepts and would be shared
by different grammar implementations, following
ideas presented by Bender et al (2005).
6 Conclusion
In this paper, we have presented a multi-formalism
parsing architecture using RCG as a pivot formal-
ism to parse mildly context-sensitive formalisms
(currently TAG and TT-MCTAG). This system has
been designed to facilitate grammar development
by providing user-friendly interfaces, along with
several functionalities (e.g., dependency extrac-
tion, derivation/derived tree display and semantic
calculus). It is currently used for developing a core
grammar for German.
At the moment, we are working on the extension
of this architecture to include a fully functional
Eclipse plug-in. Other current tasks concern op-
timizations to support large scale parsing and the
extension of the syntactic and semantic coverage
of the German grammar under development.
In a near future, we plan to evaluate the parser
and the German grammar (parsing time, correction
of syntactic and semantic outputs) with respect to
a standard test-suite such as the TSNLP (Lehmann
et al, 1996).
Acknowledgments
This work has been supported by the Deutsche
Forschungsgemeinschaft (DFG) and the Deutscher
Akademischer Austausch Dienst (DAAD, grant
7
A/06/71039). We are grateful to three anonymous
reviewers for valuable comments on this work.
References
Baldridge, Jason, Sudipta Chatterjee, Alexis Palmer,
and Ben Wing. 2007. DotCCG and VisCCG: Wiki
and programming paradigms for improved grammar
engineering with OpenCCG. In King, Tracy Hol-
loway and Emily M. Bender, editors, Proceedings of
the GEAF07 workshop, pages 5?25, Stanford, CA.
CSLI.
Beavers, John. 2002. Documentation: A CCG Imple-
mentation for the LKB. LinGO Working Paper No.
2002-08, CSLI, Stanford University, Stanford, CA.
Bender, Emily, Dan Flickinger, Frederik Fouvry, and
Melanie Siegel. 2005. Shared representation in mul-
tilingual grammar engineering. Research on Lan-
guage & Computation, 3(2):131?138.
Bonfante, Guillaume, Bruno Guillaume, and Guy Per-
rier. 2004. Polarization and abstraction of grammat-
ical formalisms as methods for lexical disambigua-
tion. In Proceedings of the International Conference
on Computational Linguistics (CoLing 2004), pages
303?309, Geneva, Switzerland.
Boullier, Pierre. 1998. Proposal for a natural lan-
guage processing syntactic backbone. Rapport de
Recherche 3342, INRIA.
Boullier, Pierre. 1999. On TAG and Multicomponent
TAG Parsing. Rapport de Recherche 3668, INRIA.
Boullier, Pierre. 2000. Range concatenation gram-
mars. In Proceedings of the International Workshop
on Parsing Technologies (IWPT 2000), pages 53?64,
Trento, Italy.
Crabbe?, Benoit. 2005. Grammatical development with
XMG. In Proceedings of the conference on Logical
Aspects of Computational Linguistics 2005 (LACL
05), pages 84?100, Bordeaux, France.
Duchier, Denys, Joseph Le Roux, and Yannick Parmen-
tier. 2004. The Metagrammar Compiler: An NLP
Application with a Multi-paradigm Architecture. In
Proceedings of the 2nd International Mozart/Oz
Conference (MOZ?2004), pages 175?187, Charleroi,
Belgium.
Erbach, Gregor. 1992. Tools for grammar engineer-
ing. In 3rd Conference on Applied Natural Lan-
guage Processing, pages 243?244, Trento, Italy.
Gardent, Claire and Laura Kallmeyer. 2003. Semantic
Construction in FTAG. In Proceedings of the Con-
ference of the European chapter of the Association
for Computational Linguistics (EACL 2003), pages
123?130, Budapest, Hungary.
Gardent, Claire and Yannick Parmentier. 2007. Sem-
tag: a platform for specifying tree adjoining gram-
mars and performing tag-based semantic construc-
tion. In Proceedings of the International Confer-
ence of the Association for Computational Linguis-
tics (ACL 2007), Companion Volume Proceedings of
the Demo and Poster Sessions, pages 13?16, Prague,
Czech Republic.
Joshi, Aravind K. 1987. An introduction to Tree Ad-
joining Grammars. In Manaster-Ramer, A., editor,
Mathematics of Language, pages 87?114. John Ben-
jamins, Amsterdam.
Kallmeyer, Laura and Yannick Parmentier. 2008. On
the relation between Multicomponent Tree Adjoin-
ing Grammars with Tree Tuples (TT-MCTAG) and
Range Concatenation Grammars (RCG). In Pro-
ceedings of the 2nd International Conference on
Language and Automata Theories and Applications
(LATA 2008), pages 277?288, Tarragona, Spain.
Kallmeyer, Laura, Timm Lichte, Wolfgang Maier, Yan-
nick Parmentier, and Johannes Dellert. 2008. De-
velopping an MCTAG for German with an RCG-
based Parser. In Proceedings of the Language, Re-
source and Evaluation Conference (LREC 2008),
Marrakech, Morocco.
Lehmann, Sabine, Stephan Oepen, Sylvie Regnier-
Prost, Klaus Netter, Veronika Lux, Judith Klein,
Kirsten Falkedal, Frederik Fouvry, Dominique Esti-
val, Eva Dauphin, Herve? Compagnion, Judith Baur,
Lorna Balkan, and Doug Arnold. 1996. TSNLP ?
Test Suites for Natural Language Processing. In Pro-
ceedings of the International Conference on Compu-
tational Linguistics (Coling 1996), volume 2, pages
711?716, Copenhagen, Denmark.
Lichte, Timm. 2007. An MCTAG with tuples for co-
herent constructions in German. In Proceedings of
the 12th Conference on Formal Grammar, Dublin,
Ireland.
Perrier, Guy. 2000. Interaction grammars. In Pro-
ceedings of the International Conference on Compu-
tational Linguistics (CoLing 2000), pages 600?606,
Saarbruecken, Germany.
S?gaard, Anders. 2007. Complexity, expressivity and
logic of linguistic theories. Ph.D. thesis, University
of Copenhagen, Copenhagen, Denmark.
Villemonte de la Clergerie, ?Eric. 2005. DyALog: a
tabular logic programming based environment for
NLP. In Proceedings of the workshop on Constraint
Satisfaction for Language Processing (CSLP 2005),
pages 18?33, Barcelona, Spain.
XTAG-Research-Group. 2001. A lexicalized tree
adjoining grammar for english. Technical Re-
port IRCS-01-03, IRCS, University of Pennsylva-
nia. Available at http://www.cis.upenn.
edu/?xtag/gramrelease.html.
8
