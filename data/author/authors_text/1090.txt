Proceedings of the Workshop on A Broader Perspective on Multiword Expressions, pages 33?40,
Prague, June 2007. c?2007 Association for Computational Linguistics
Spanish Adverbial Frozen Expressions
Dolors Catal?
Autonomous University of Barcelona
Campus Sabadell, 08202, Spain
fLEXSEM 
dolors.catala@uab.cat
Jorge Baptista
Univ.Algarve, Campus de Gambelas 
P-8005-139 Faro,  Portugal
L2F ? INESC-ID Lisboa, Portugal
jbaptis@ualg.pt
Abstract
This paper  presents  an electronic  diction-
ary  of  Spanish  adverbial  frozen  expres-
sions. It focuses on their formal description
in view of natural language processing and
presents  an  experiment  on  the  automatic
application of this data to real texts using
finite-state techniques. The paper makes an
assessment  of  the  advantages  and
limitations  of  this  method  for  the
identification  of  these  multiword  units  in
texts.
1 Introduction
We have undertaken the construction of an elec-
tronic dictionary of compound adverbs, or adver-
bial  frozen  expressions  (Catal?  2003).  This
dictionary  completes  the  DELACs,  i.e.,  the
dictionary of compound words of Spanish (Blanco
and Catal? (1998)). 
These adverbial frozen expressions (a tontas  y
a locas = by fits and starts, como anillo al dedo =
like a glove; a ojo de buen cubero = at a guess) 1
have often been considered as exceptions but they
constitute an important part of the lexicon. 
Their formal description highlights many prob-
lems for NLP applications. On the one hand, they
are multiword expressions functioning as meaning
units, so they have to be recognized as a block and
are not to be analyzed as a free sequence of simple
words. On the other hand, they present, sometimes,
some lexical variation that can take complex lexi-
cal syntactical patterns. 
1 Approximate translations of examples do not intend to
be fully acceptable,  but to illustrate syntactic phenom-
ena.
For example, some adverbs show combinatorial
constraints between discontinuous elements:
d?a s?, d?a no /  a?o si, a?o no,*d?a si, a?o no 
?on even days/years?. 
Others yet present long distance dependencies:
[Yo estudio] con todas mis/*sus fuerzas 
?(I study) with all my/his strength?); 
Lexical variation of the compound elements is of-
ten constraint in an unpredictable way:
[Juan  aprob?]  por  los/*todos los/*sus/*unos
pelos
?(John passed the exam) with difficulties?
Some allow for a theoretically infinite paradigm as
in the expression <Card>  veces  seguidas  ?<num-
ber> of times in a row?, where  Card stands for a
numeral,  whose  meaning  is  compositional  but
whose form is fixed:
[Eso sucedi?] Card veces seguidas
?(It happened) <number> of times in a row?
since  the  adjective  does  not  allow  for  any
variation:
*[Eso sucedi?] Card veces continuas
?(It happened) <number> of times in a row?
In some cases, the adjective can not be reduced:
[Juan dijo esto] en voz baja / *en voz
?(John said this) in low voice/in voice?
nor can it be placed before the noun:
[Juan dijo esto] en voz baja / *en baja voz
?(John said this) in voice low /in low voice?
2 The Dictionary
The theoretical  and methodological  framework
adopted  is  the  lexicon-grammar  based  on  the
principles of the transformational grammar of Har-
ris  (1976,  1997)  developed  by  Maurice  Gross
33
(1986). In this perspective, the adverbial frozen ex-
pressions  are  formalized  in  the  frame  of  simple
sentences  and their  network of paraphrastic  rela-
tions.  Adverbs  are  predicates  that  necessarily
apply on other predicates and have a basic influ-
ence in their selection. For example, some adverbs
are  only  associated  with  a  limited  number  of
verbs2:
[Juan duerme/pernocta/pasa la noche] al raso
?(John sleeps) in the open air?
While some others are only used in a negative sen-
tence:
[Juan no aceptar?] por nada del mundo 
?(John will not accept) by no means? 
*[Juan aceptar?] por nada del mundo 
?(John will accept) by no means?
Others impose a specific tense:
[Juan  llegar?] en  breve '(John  will come
shortly?
*[John  lleg?] en  breve ?(John  has  come)
shortly?
2.1 Classification 
We apply the notion of adverbs to syntactically
different structures of traditional terminology such
as  underived  (primary)  adverbs  (bien,  ?well?)  or
derived  forms  (profundamente ?deeply?),
circumstantial  complements  (al  amanecer ?at
dawn?),  and circumstantial  clauses  (hasta  que la
muerte nos separe ?until death do us part?). 
We considered the sequence Prep Det C Modif 3
as the basic structure that formally define and clas-
sify  compound  adverbs,  adopting  the  concept  of
generalized adverb proposed by M. Gross (1986)
for French adverbs. 
Based on this, we defined 15 formal classes for
Spanish  compound  adverbs.  Table  1  (below)
shows the current state of the dictionary, the inter-
nal structure of each class, an illustrative example
and the number of compound adverbs collected so
far. 
Further  than  this  classification  based  on  their
internal  structure,  we  have  proposed  different
types  of  semantic-functional  groups  presented  in
terms  of  Finite  State  Transducers  (FSTs),  as  in
2 In the examples, (argument) simple sentences are given
in brackets.
3 Prep =  preposition;  Det =  determiner;  C =  lexical
constant, usually a noun;  Modif = modifier, such as an
adjective (Adj) or a prepositional phrase.
Fig.1. In this graph, all adverbial expressions have
the  same  general  meaning  (?quickly?).  Similar
graphs can be used, for example, to compare the
distribution  of  semantically  ?equivalent?
expressions and to structure the co-occurrence of
those adverbs with their argument predicates.
Class Structure Example Size
PC Prep C sin ambajes 869
PDETC Prep Det C al contado 585
PAC Prep Adj C sin previo aviso 157
PCA Prep C Adj a brazo partido 291
PCDC Prep C de C  a cuerpo de rey 168
PCPC Prep C Prep C de cabo a rabo 149
PCONJ Prep C Conj C en cuerpo y alma 131
PCDN Prep C de N a condici?n de 233
PCPN Prep C Prep N de espaldas a 51
PV Prep V W sin querer 127
PF frozen sentence que yo sepa 169
PECO (como) Adj que C sordo como una tapia 797
PVCO (V) como C (beber) como una esponja 532
PPCO (V) como Prep C (desaparecer) como
 por ensalmo
46
PJC Conj C y no se hable m?s 91
TOTAL 4396
Table 1. Classification of Spanish compound adverbs.
Fig.1 Finite-State graph (simplified) for semantic
clustering of adverbs
2.2 Microstructure  of Dictionary
The description takes the shape of binary matrices
(see Table 2, for an example), in which each line
corresponds  to  a  lexical  entry,  and  the  columns
represent different information. The set of matrices
constitute the lexicon-grammar of adverbial frozen
expressions.  Next,  we present  a brief  description
of the microstructure of the dictionary. 
34
N0 V
Prep
Det
C
PreMod
Mod
Pr?p D?t C
Pr?p D?t Adj C
Conj
DiaSys English equivalent
hum Vact - - acto - seguido - - + - immediately afterwards
hum llegar a la hora - horada + - - familiar on the nose
hum Vact por - voluntad - propia - + - - with one?s own will
hum comprar a el por - mayor - - - commerce wholesale
hum dormir con los ojos medio abiertos - - - - with one?s eyes half open
Table 2. Class PCA (extract)
The first column concerns the syntactic-seman-
tic  nature  of  the  subject.  We  adopted  G.  Gross
(1995)  and Le  Pesant and Mathieu-Colas  (1989)
basic  typology,  distinguishing  the  following
semantic  classes:  human,  animal,  vegetal,  con-
crete, and abstract.
The  second  column  refers  to  the  verb  most
commonly used with the adverb, for example:
[salir] a cuerpo gentil 
?(to go out) without cloak?; 
[cerrar Nconc] a cal y canto
?(to close something) under lock and key?.
The following columns contain the elements of
the structure: Prep, Det, C, and Modif, e.g.:
[Esta  gente  lleg? en este  pa?s]  con las  manos
vac?as 
?These  people  arrived  in  this  country  with
empty hands?
Naturally,  in Spanish the modifier  can be placed
before C:
[Se peleaban] a la menor ocasi?n 
?(they  were  fighting  each  others)  at  the  least
occasion/opportunity?.
The next columns correspond to their syntactic
(distributional  and  transformational)  properties:
?+?  indicates  that  the  expression  admits  this
property,  and  ?-  ?  that  it  does  not.  Relevant
properties  depend on the class:  some have to do
with permutation of elements of the compound or
their reduction to zero (zeroing); see ?2.3, below.
Diasystem  information  (Hausmann  1989)  is
provided  in  next  field  (DiaSys)  such  as  these
categories  (marked  in  bold,  in  the  examples
below): 
- diatopy: 
[Juan trabaja] al cohete (Uruguay/Argentina)
?(John works) in vain?; 
- diachrony : 
[Juan  convoca  a  los  estudiantes]  a  voz  de
apellido (out of use) 
?(John summons the students) by their family
name?; 
- diafrequency : 
[Juan se sirvi?] a barba regada (unusual) 
?(John served himself) abundantly?
- diastratic:
[Juan  recita] de  carretilla (familiar/
colloquial) 
?(John recites) by heart?; 
- diatechnical : 
[El torero clav? la  banderilla] de sobaquillo
(bullfighting) ?(the  bull  fighter  has  pinched
the bull) on its side; 
- diaintegrative : 
[Juan vino] motu propio (latinism) 
?(John came) voluntarily?. 
Finally,  we  have  included  French  translation
equivalents.  These  equivalence  relations  are  also
currently being extended to other languages, such
as Portuguese (Palma, in prep.).
2.3 Syntactic properties
We will  only  consider  here  the  most  prominent
properties, considering all classes of adverbs under
study.
One of the properties indicates the possibility to
transform  the  initial  structure  in  to  a  more
analytical phrase like de (modo + manera) C-a ?in
a  C-a way/manner?,  where  C-a is  an  adjective,
morphologically  related  to  the  constant  (frozen
element)  C;  naturally  the  meaning  of  the  two
structures is the same:
[La candidatura se aprob?] por unanimidad
=  [La  candidatura  se  aprob?]  de  manera
un?nime
35
?(His application was approved) by unanimity/in
an unanimous way?
[Juan lo ha dicho] con todos los respetos 
= [Juan lo ha dicho] de manera respetuosa 
?(John  has  said  so)  with  all  due  respect/  in  a
respectful manner?.
Another, similar, property shows the possibility
to transform the initial structure in an adverb based
on the same type of  C-a adjective and the suffix
-mente. This  property  concerns  classes  PC  and
PDETC :
[La candidatura se aprob?] por unanimidad
= [La candidatura se aprob?] un?nimemente
?(His application was approved) unanimously?
[Juan lo ha dicho] con todos los respetos 
= [Juan lo ha dicho] respetuosamente
?(John has said so) respectfully?.
Property  Conj concerns  classes  PC,  PDETC,
PAC and PCA. It highlights the eventual anaphoric
effect  of  the  adverb.  We  consider  it  as  a
conjunction-adverb, since in sentences like:
[Juan estudia] en consecuencia 
?(John studies) in consequence?
[Juan se march?] por lo tanto 
?(John went away) for that much?
we need a (trans-)phrastic context such as :
[Juan  quiere  aprobar], en  consecuencia,
[estudia]. 
?(John  wants  to  succeed  in  school),  in
consequence (he studies)?
[Ana se enfad? con Juan], por lo tanto,  [?ste se
march?]
?(Ana get  bored with  John),  for  that  much (he
went away)?
The  next  property  concerns  classes  PCA and
PAC.  It  describes  the  possible  omission  of  the
modifier:
[Los ni?os andan] en fila india 
?(The kids walk) in Indian line?
= [los ni?os andan] en fila 
?(The kids walk) in line?
Other  property indicates  the  possibility of
moving modifier from its basic position to the left
of C; it only concerns class PCA:
[Juan encontr? a Ana] en hora buena 
= [Juan encontr? a Ana] en buena hora
?(John met Ana) in good time/in time?
We have  also  noted  the  possibility  of  zeroing
the second element of the compound, i.e., the free
or frozen prepositional phrase.  It concerns classes
PCDC, PCPC, PCONJ, PCPN, and PCDN:
[Juan estudia] con la mejor voluntad del mundo
= [Juan estudia] con la mejor voluntad
?(John studies) with the best will (of the world)?
[Juan vive] al margen de la sociedad 
= [Juan vive] al margen
?(John lives) at the margin (of society)?
[Juan vive] de espaldas a la calle 
= [Juan vive] de espaldas
?(John lives) with his back (turned to the street)?
Certain  permutations have been noted,  but  not
dealt with in a transformational way:
[Juan se enamor? de Ana] por decirlo as?
= [Juan se enamor? de Ana] por as? decirlo
?(John fall in love with Ana) as it were?
Finally,  we  consider  the  possibility  of
substitution  of  the  second  element  by  a
subordinate  clause  (finite  or  infinitive);  this
property concerns PCDN and PCPN:
[Le consultar?] en caso de duda
= [Le consultar?] en caso de que haya duda
?(He will consult him) in case of doubt/in case
there is any doubt?
[Juan se march?] por miedo al fuego 
= [Juan se march?] por miedo a que haya fuego
?(He went away) for fear of fire/there being fire?
[Juan se sujet?] por miedo a una ca?da
?(John hold tight) by fear of a fall?
= [Juan se sujet?] por miedo a caer
?(John hold tight) by fear of to fall?
A  strictly  statistically,  corpus-based  approach
that only contemplates strings of words in view to
produce  lexicon  entries  (Manning  and  Sch?tze
2003) cannot but fail to put in relation such formal
variants  of  equivalent  expressions.  On  the  other
hand,  many  formal  variations  are  very  much
dependent on the particular  lexical  combinations,
and  cannot  be  generalized,  hence  the  need  to
describe their syntactic properties systematically. 
While  very  time-consuming,  our  method
provides a fine-grained linguistic description, and
is directly exploitable by finite-state methods. 
With  the  aim  of  retrieving  the  adverbial
expressions  from  texts  using  the  information
encoded in the lexicon matrices, it should be noted
36
that most but not all  properties referred to above
can  be  directly  formalized  using  the  finite-state
methods we are currently using. In the following
lines, we present this methodology. 
3 Formalization
In order to apply to texts the set of matrices that
constitute  the  Lexicon-Grammar  and  thus  to
identify  and  tag  compound  adverbs,  we  have
followed the  methodology proposed  by Senellart
(1998)  and  Silberztein  (2000),  and  adapted  by
Paumier (2003, 2004) for the UNITEX system 4. This
method consists  of intersecting linguistic data on
matrices  with  a  finite-state  graph  (called  a
reference graph) in order to generate automatically
a finite-state transducer (FST) that can be applied
to a corpus5. 
Fig.2 Reference graph (simplified) for class PCA
Fig.2 shows a (simplified)  reference graph for
class  PCA.  In the  graph,  variable  @X stands  for
column X in the matrix. For each line in the matrix
the  system builds  a sub-graph by replacing  each
variable for the content of the corresponding col-
umns  in  the  matrix.  If  that  columns  is  a  binary
property, the corresponding variable in the graph
functions as a switch, allowing for the rest of that
graph?s path to be build in case of a ?+? or, else,
collapsing the graph at that point, if a ?-? is found
at  that  property.  It  is  also  possible  to  deny  a
property  (!@X),  which  has  the  opposite  effect.
Another utility of the system is the inclusion of a
variable  @% that outputs the number of each entry
line in the matrix, thus enabling the user to easily
put  in  correspondence  a  given  result  to  the
corresponding lexical entry. The set of sub-graphs
(one per each entry in the matrix) is automatically
gathered  in  a  finite-state  transducer  that  can  be
directly applied to texts. 
In Fig. 2, class PCA reference graph includes:
two  delimiters  of  the  compound  expression,
<ADV_> and  <_ADV> ; the  @% variable; the top-
4 www.univ-mlv.fr/~unitex.
5 See Paumier (2004), for further details.
most  path describe  the full  expression,  while  the
second and third paths, below, depend on proper-
ties described by variables @H and @I; these corre-
spond  to  the  permutation  of  the  adjective  [Ap]
and its reduction to zero [Az], respectively.
Similar graphs have been built to other classes6.
The  set  of  classes  thus  formalized  constitute  an
electronic dictionary of 2,930 entries (67% of all
compound entries collected so far). 
4 An experiment on texts
The  aim  of  this  experiment  is  to  assess  the
advantages  and  limitations  of  the  methodology
described in ?3 in the identification of multiword
units, in this case, compound adverbs, in real texts
in Spanish.
The FSTs were applied to a fragment of a cor-
pus of journalistic text taken from the newspaper
El Mundo,  of  about  2  Mb and  171.5  K (~24  K
different)  words.  The  system  retrieved  2,276
matches, corresponding to 461 different entries. 
Table 3 shows the breakdown of these matches
per  class  and  its  percentage,  followed  by  the
number of different entries (types) matched by the
system and the corresponding percentage of each
class entries. 
class
class
size matches
%
matches
entrie
s
%
entries
PC 869 849 0.37 215 0,47
PCDN 233 489 0.22 12 0,03
PDETC 585 406 0.18 119 0,26
PCPN 51 238 0.10 23 0,05
PCA 291 134 0.06 19 0,04
PF 169 42 0.02 7 0,02
PAC 157 38 0.02 23 0,05
PCONJ 131 22 0.01 9 0,02
PCPC 149 21 0.01 12 0,03
PCDC 168 17 0.01 12 0,03
PV 127 16 0.01 10 0,02
2,930 2,272 461
Table 3. Breakdown of matches per class.
Classes  PC,  PCDN,  PDETC,  PCPN and  PCA
are  the  only  classes  with  over  100  matches;
together  they  constitute  93% of  the  matches,  all
other classes have residual expression. 
6 In this paper, however, we did not deal with classes of
comparative adverbs (PECO, PVCO and PPCO) or class
PJC,  which pose particular  problems to  their  recogni-
tion.
37
On  the  other  hand,  classes  PC  and  PDETC
present  the  larger  number  of  dictionary  entries
matched. Notice that, despite the number of entries
in the matrices, only 461 entries (16%) were found
in the corpus.
Class  PC  alone  represents  47%  of  the  total
entries  matched  by  the  system  (215/461),
immediately followed by class PDETC, with 26%
of  matched  entries  (119/461).  Matches  for  these
two classes together constitute 55% of the total of
strings  matched  by  the  system  (1,255/2,272).
These two figures make PC and PDETC the most
prominent classes for this experiment, in view of
the  assessment  of  the  finite-state  methods  here
used  to  identify  compound  adverbs  in  texts.  For
lack of space, analysis of results will thus focus on
these  classes  and  only  major  phenomena,  i.e.,
those situations with major impact on results, will
be taken in consideration here.
5 Results and discussion
We went  through  the  concordances  manually,
and confirmed a precision of 77.4% (974/1,255) 7.
We discuss these results below.
The  major  reason  for  incorrect  matching  has
been  found  to  correspond  to  cases  where  the
matched  sequence  is  not  the  target  compound
adverb but part of a longer, free word sequence, or
part  of  a  compound  word;  in  the  following
example, the adverb de accidente ?accidentally? is
an  ambiguous  string  since  it  overlaps  with  the
compound  noun  seguros  de  accidente ?accident
insurances? 
Antes de iniciar un rodaje, se prev? cualquier eventualidad.
Se contratan seguros de accidente, enfermedad y muerte para
las personas clave del proyecto [PC_0010]
while in the next  example, the string  de derecho
?by  law/right?  overlaps  a  (free)  prepositional
phrase which includes a compound noun  derecho
de veto ?right of veto?:
Yo creo  que  no  se puede  pretender  ejercer una  especie  de
derecho de veto, porque esto querr?a decir que el Gobierno
es reh?n [PC_0243]
7 Since  we started  with a  previously,  manually  build,
electronic  dictionary,  we can  not  compute  recall.  We
define  precision as  the  number of  correct  matches on
total matches.
In some few cases, incorrect matches were the
result of an inadequate treatment of contractions of
prepositions  and  determiners.  In  classes  PCDN,
PCPN,  the  second  preposition  often  appears
contracted with the determiner of the free NP. In
the next example, contraction of a + el = al has not
been correctly described:
coches ser?n introducidos en el mercado nip?n en el mes de
octubre,  con  ocasi?n  del  Sal?n  de  Tokio.  Con respecto al
Tigra,  que se produce en exclusiva para todo el mundo en
Figuer [PC_0686]
This problem is to be fixed on a next version of the
reference FSTs.
In  some  cases,  especially  when  the  adverb  is
marked  as  a  conjunction-adverb  (Conj),  it  often
appears  between  comas  or  at  the  beginning  of
sentences, followed by coma. 
se  hab?a  montado  su  particular  Guerra  de  los  Mundos  de
tema ferroviario. Tambi?n hay quien piensa, por cierto, que a
este Gobierno se lo van a cargar no sus errores, sino las cos
[PC_0145]
privatizar  el  99,9% de las  empresas y entes  p?blicos  de la
Comunidad  y ya est? trabajando en ello.  Por cierto, le ha
arrebatado el control del Canal de Isabel II a Pedroche y lo
[PC_0145] 
We  have  annotated  these  cases  so  that  this
information can be added to the matrices and used
in disambiguation tasks.
Finally,  many  temporal  adverbs  have  only
partially been identified. 
puede seguir as??- exigi? al Gobierno de Gonz?lez que fije un
calendario  electoral  antes  del  17  de este  mes.  Tras  de  lo
cual,  el  a?n  secretario  general  de  CDC  sostuvo  que,  si
[PDETC_0076] 
zo de Erez, consigui? dos objetivos. En primer lugar, Israel se
comprometi? a iniciar,  a finales de  este mes, la evacuaci?n
gradual  de  tres  ciudades  palestinas:  Jenin,  Kalkilia
[PDETC_0076]
This  occurs  because  matrices  only  included
simple  word combinations.  As others have noted
previously  (Baptista  and  Catal?  2002;  Baptista
2003a,b),  time-related  adverbs  may be  described
by FST methods as those used here.  Those local
grammars could easily be integrated in the system. 
38
6 Conclusion
The taxonomic approach adopted here, the system-
atic  survey  of  the  lexicon  and  its  formal
representation,  resulted  in  a  complex  linguistic
database of Spanish compound adverbs. This may
have many applications, not strictly in Linguistics,
but also in Didactics and in Lexicography.
It can further be used in several applications on
natural  language  processing.  The  relatively  high
precision (77,4%) of the finite state methods used
in  this  paper  are  very encouraging,  and  in  some
cases,  discussed  above,  they  can  and  will  be
improved in a future version both of the reference
graphs and of the lexicon-grammar matrices. 
However,  the  major  difficulty  to  a  better
identification of compound adverbs in texts seems
to  reside  in  the  fact  that  no  syntactic  analysis
(parsing)  has  been  performed  on  the  text.
Therefore,  there  is  no  possibility  of  using
information  regarding  (sub-)phrases  and  other
constituents of the compounds in order to preclude
incorrect matching. 
Another aspect that hinders better results has to
do  with  the  formal  variation  of  compound
adverbial  expressions.  Adverbs  present  more
problems for their recognition as the limit between
free sequence and fixed sequence is more difficult
to  establish  than  in  others  categories  of
compounds. The building of electronic dictionaries
may benefit from a (more) corpus-based approach,
so as to retrieve variants of a given lexical entry,
but  a  careful  and  time-consuming  verification  is
needed  in  order  to  group  variants  as  different
expressions of the same meaning unit.
Finally,  the  relatively  small  portion  of  the
dictionary matched on the corpus imposes that  it
should be tested on texts of a more diverse nature
and of a larger size, thus probably yielding a larger
perspective  of  the  use  of  these  idiomatic
expressions. Still, it is now possible to consider the
study of the distribution of these adverbs, trying to
specify  the  type  of  predicates  (verbs,  nouns,
adjectives, mainly) on which they operate.
Acknowledgement 
This research was supported by the Spanish Ministerio
de Ciencia y Tecnologia in the framework of the project
grant  HP-2004-0098,  and  Conselho  de  Reitores  das
Universidades Portuguesas, project grant E-111/-05.
References
Jorge  Baptista  2003a.  Some  Families  of  Compound
Temporal  Adverbs  in  Portuguese.  Proceedings  of
Workshop  on Finite-State  Methods  for  Natural
Language Processing: 97-104, ACL, Hungary.
Jorge Baptista 2003b. Evaluation of Finite-State Lexical
Transducers  of  Temporal  Adverbs  for  Lexical
Analysis  of  Portuguese  Texts.  Computational
Processing of the Portuguese Language. Proceedings
of  PROPOR?2003.  Lecture  Notes  in  Computer
Science/Lecture Notes in Artificial Intelligence 2721:
235-242, Springer, Berlin.
Jorge  Baptista  and  Dolors  Catal?  2002.  Compound
Temporal  Adverbs  in  Portuguese  and  in  Spanish.
Advances in Natural Language Processing,  Lecture
Notes  in  Computer  Science/Lecture  Notes  in
Artificial  Intelligence  2389:  133-136,  Springer,
Berlin.
Jorge  Baptista  and  Dolors  Catal?  2006.  Les adverbes
compos?s dans le domaine du travail.  Mots, Termes,
et Contextes:  249-263, AUF/LTT and ?d. Archives
Contemporaines, Paris.
Xavier  Blanco  and  Dolors  Catal?  1998.  Quelques
remarques  sur  un  dictionnaire  ?lectronique
d?adverbes  compos?s  en  espagnol.  Linguisticae
Investigationes  Supplementa 11  (2):  213-232,  John
Benjamins Pub. Co., Amsterdam/Philadelphia.
Gaston Gross  1995.  ? propos de  la  notion d?humain.
Lexiques  Grammaires  Compar?s  en  Fran?ais.
inguisticae  Investigationes  Supplementa 17:  71-80,
John Benjamins Pub. Co., Amsterdam/Philadelphia.
Maurice  Gross  1986.  Grammaire  transformationnelle
du fran?ais: syntaxe de l?adverbe, ASSTRIL, Paris.
Zellig  S.  Harris  1976  Notes  du  cours  de  syntaxe,  Le
Seuil, Paris. 
Zellig  S.  Harris.  A  Theory  of  Language  and
Information.  A  Mathematical  Approach,  Clarendon
Press, Oxford.
Franz  J.  Haussmann  1989.  Die  Markierung  in
allgemeinen  einsprachigen  W?rterbuch:  eine
?bersicht,  W?rterb?cher,  Dictionaries,
Dictionnaires, vol 1: 651, Berlin/ New York, Walter
de Gruyter.
Denis  Le  Pesant  and  Michel  Mathieu-Colas.  1998.
Introduction  aux  classes  d'objets   Langages 131:
6-33, Larousse, Paris.
Ch.  Manning  and  H.  Sch?tze  2003.  Foundations  of
Statistical Natural Language Processing, MIT Press,
London/Cambridge, MA
39
Cristina  Palma  (in  preparation).  Estudo  Contrastivo
Portugu?s-Espanhol de Adv?rbios Compostos, Univ.
Algarve, Faro.
S?bastien Paumier 2004.  Unitex - manuel d'utilisation,
Univ. Marne-la-Vall?e, Paris.
Jean  Senellart  1998.  Reconnaissance  automatique  des
entr?es du lexique-grammaire des phrases fig?es.  Le
Lexique-Grammaire.  Travaux  de  Linguistique 37:
109-125, Duculot, Bruxelles.
Max  Silberztein  2000.  Intex (Manual),  ASSTRIL/LADL,
Paris.
40
Proceedings of the Seventeenth Conference on Computational Natural Language Learning: Shared Task, pages 96?101,
Sofia, Bulgaria, August 8-9 2013. c?2013 Association for Computational Linguistics
Rule-based System for Automatic Grammar Correction
Using Syntactic N-grams for English Language Learning (L2)
Grigori Sidorov?, Anubhav Gupta?, Martin Tozer?, Dolors Catala?, Angels Catena? and Sandrine Fuentes?
?Centro de Investigacio?n en Computacio?n, Instituto Polite?cnico Nacional (IPN), Mexico
? Departament de Filologia Francesa i Roma`nica, Universitat Auto`noma de Barcelona, Spain
www.cic.ipn.mx\?sidorov,
{anubhav.gupta, tozer.martin}@e-campus.uab.cat,
{dolors.catala, angels.catena, sandrine.fuentes}@uab.cat
Abstract
We describe the system developed for the
CoNLL-2013 shared task?automatic En-
glish L2 grammar error correction. The
system is based on the rule-based ap-
proach. It uses very few additional re-
sources: a morphological analyzer and a
list of 250 common uncountable nouns,
along with the training data provided by
the organizers. The system uses the syn-
tactic information available in the train-
ing data: this information is represented
as syntactic n-grams, i.e. n-grams ex-
tracted by following the paths in depen-
dency trees. The system is simple and
was developed in a short period of time
(1 month). Since it does not employ
any additional resources or any sophisti-
cated machine learning methods, it does
not achieve high scores (specifically, it has
low recall) but could be considered as a
baseline system for the task. On the other
hand, it shows what can be obtained using
a simple rule-based approach and presents
a few situations where the rule-based ap-
proach can perform better than ML ap-
proach.
1 Introduction
There are two main approaches in the design of the
modern linguistic experiments and the develop-
ment of the natural language processing applica-
tions: rule-based and machine learning-based. In
practical applications of machine learning (ML),
the best results are achieved by the methods that
use supervised learning, i.e., that are based on
manually prepared training data for learning. It
is also worth mentioning what can be considered
a general rule for the combination of these two
approaches: a system based on the mixed ap-
proach should obtain better results if each part
of the system is applied according to its ?com-
petence?. Specifically, some problems are better
solved by the application of the rules?like the
rules for choosing the correct allomorph of the ar-
ticle ?a? vs. ?an?, while other problems are better
solved by the usage of ML methods?such as de-
ciding the presence or absence of a definite or an
indefinite determiner.
This paper describes the system developed for
the CoNLL-2013 shared task. The task consists
of grammar correction in texts written by people
learning English as a second language (L2). There
are five types of errors considered in the task: noun
number, subject-verb agreement, verb form, ar-
ticle/determiner and choice of preposition. The
training data processed by the Stanford parser (de
Marneffe et al, 2006) is provided. This data is part
of the NUCLE corpus (Dahlmeier et al, 2013).
The data also contains the error types and the cor-
rected version.
Development of the systemwas started only two
months before the deadline, so it is also an inter-
esting example of what can be done in a rather
short period of time and with relatively little ef-
fort: only one person-month joint effort in total.
In our system, we considered mainly the rule-
based approach. Note that we used the ConLL
data to extract preposition patterns, which can be
considered as a very reduced form of machine
learning with yes/no classifier, as well as to con-
struct rules directly from the data.
Another feature of our system is the widespread
use of the syntactic information present in the pro-
vided data. In our previous works, we general-
ized the use of syntactic information in NLP by
introducing the concept of syntactic n-grams, i.e.
n-grams constructed by following the dependency
paths in a syntactic tree (Sidorov et al, 2012;
Sidorov et al, 2013). Note that they are not n-
grams of POS tags, as could be assumed from the
name; the name refers to the manner in which they
96
Figure 1: Example of syntactic tree (for extraction
of syntactic n-grams).
are constructed. That is to say, in a dependency
relation, there is always a head word and a depen-
dent word. In the syntactic tree, this relation is
graphically represented by an arrow: head? de-
pendent. As it can be observed in Fig. 1, we can
also use the tree hierarchy?the head word is al-
ways ?higher? in the syntactic tree.
The algorithm for the construction of syntactic
n-grams is as follows: we start from the root word
and move to each dependent word following the
dependency relations. At each step, the sequence
of previous elements in the route taken are taken
into account. The last n words in the sequence
correspond to the syntactic n-gram. This could be
reformulated as: we should take the last n words
of the (unique) path from the root to the current
word.
In other words, we start from the root and reach
one of the dependent words. If we want to con-
struct bigrams, then we have a bigram already. If
we need other elements of the n-gram, then we
move to the word that is dependent and continue to
the words that are dependent on it. If a word has
several dependent words, we consider them one
after another and thus, obtain several syntactic n-
grams. Note that the head word always appears
before the dependent word in the syntactic n-gram
during the construction process.
For example, from the tree presented in Fig. 1,
the following syntactic bigrams can be extracted:
likes-also, likes-dog, dog-my, likes-eating, eating-
sausage. Note that only two syntactic 3-grams
can be constructed: likes-dog-my, likes-eating-
sausage. The construction process is the follow-
ing: we start with the root word like. It has several
dependent words: dog, also, eating. Considering
them one after another, we obtain three syntactic
bigrams. Then we move on to the word dog. It
has only one dependent word: my. This is another
bigram dog-my. However, the path from like also
goes through it, so this is also the 3-gram like-dog-
my, etc.
The reader can compare these syntactic n-grams
with traditional n-grams and consider their advan-
tages: there are a lot less syntactic n-grams, they
are less arbitrary, they have linguistic interpreta-
tion, etc.
Note that syntactic n-grams can be formed by
words (lemmas, stems), POS tags, names of de-
pendency relations, or they can be mixed, i.e., a
combination of the mentioned types. Being n-
grams, they can be applied in any machine learn-
ing task where traditional n-grams are applied.
However, unlike traditional n-grams, they have a
clear linguistic interpretation and can be consid-
ered as an introduction of linguistic (syntactic) in-
formation into machine learning methods. Previ-
ously, we obtained better results by applying the
syntactic n-grams to opinion mining and author-
ship attribution tasks compared to the traditional
n-grams. Further in this paper, it is described how
we use syntactic n-grams for the formulation of
rules in our system and for the extraction of pat-
terns.
The system described in this paper does not ob-
tain high scores. In our opinion, it could be con-
sidered a baseline system for the grammar correc-
tion task due to its simplicity, its use of very few
additional resources and the speed of its develop-
ment. Concretely, if a more sophisticated system
outperforms ours, it reflects well upon that system.
If it performs more poorly, its design should be
revised. On the other hand, this paper also dis-
cusses the few situations where the rule-based sys-
tem can outperform an ML approach. As we men-
tioned earlier, the ideal system would combine
both these approaches. To quote Tapanainen and
Voutilainen (1994), ?don?t guess if you know?.
Further below, we describe the lexical resources
that we used, the processing of each type of error
and the evaluation of the system.
2 The System?s Linguistic Resources
The system consists of several program modules
written in the Python programming language. We
used only three types of linguistic resources:
? The provided corpus NUCLE data was pro-
cessed with the Stanford parser. It was
used for the extraction of patterns to identify
97
preposition errors and for the formulation of
rules.
? A list of the 250 most common uncountable
nouns1. This list was used for processing the
possibility of using the nouns in plural form.
? A morphological analysis system for English
that in our case was based on the FreeL-
ing morphological dictionary (Padro? et al,
2010).
The FreeLing dictionary is a freely available
text file which contains more than 71,000 word
forms with standard POS tags. It has the follow-
ing data: for each word form, it contains a list of
lemmas and POS tags. An example of the entries:
...abandon abandon VB abandon VBP
abandoned abandon VBD abandon VBN
abandoning abandon VBG
abandonment abandonment NN
abandons abandon VBZ...
This list can also be easily reordered by lemmas.
It is therefore very easy to apply this word list to
both morphological analysis and generation. The
morphological analysis simply consists of search-
ing for a word form in the list, while the mor-
phological generation involves searching the list
of lemmas and then finding the word form with
the necessary POS tag, i.e., for the generation, the
input consists in the lemma and the POS tag. For
example, if we want to generate the VBZ form of
the verb take, then we search in the list ordered ac-
cording to the lemma take; there are several forms:
take took VBP, take taken VBN, take takes VBZ and
choose the form that has the POS tag VBZ.
3 Error Processing
In accordance with the rules of the ConLL shared
task, only five types of errors were considered:
noun number, incorrect preposition, choice of de-
terminer or article, subject-verb agreement and
verb form. More error types are marked in the
corpus, but they are much more complex, being
related to the meaning and content.
Let us see examples of the errors:
? Preposition error: ?...the need of habitable
environment...?, where ?for? should be used.
1List of 250 most common uncountable nouns.
www.englishclub.com>Learn English>Vocabulary>Nouns.
? Nn error: ?...people are getting more con-
scious of the damages...?, the word ?damage?
in singular should be used.
? SVA error: ?...relevant information are read-
ily available...?, where ?is? should be used in-
stead.
? Vform error: ?The solution can be obtain
by using technology...?, where ?obtained?
should appear.
? ArtOrDet error: ?...It is also important to cre-
ate a better material...?, where ?a? should not
be used.
The total number of errors marked in the train-
ing and the test data for ConLL 2013 are presented
by type in Table 1.
Table 1: Numbers of errors in training and test data
listed by type.
Error type Training Test
Vform (Verb form) 1,451 122
SVA (Subject-verb agreement) 1,529 124
ArtOrDet 6,654 690
Nn (Noun number) 3,773 396
Prep (Preposition) 2,402 311
Note that the errors related to the noun num-
ber should be processed first since later, an agree-
ment error could be produced if the noun number
is changed. If the agreement error is introduced by
the modification of the noun number, it is not the
error committed by the student, however it is con-
sidered as such in the current version of the task.
Probably, it can be considered as some sort of sec-
ondary error. The order in which other errors are
processed is irrelevant.
3.1 Noun Number Error Processing
The only rule we implemented in this case was that
uncountable nouns do not have a plural. We used
a list of the 250 most common uncountable nouns
(as mentioned in the Section 2) to determine the
possibility of a plural form for a noun. For ex-
ample: ...ethics, evidence, evolution, failure, faith,
fame, fiction, flour, flu, food, freedom...
We made an exception for the noun ?time? and
do not consider it as uncountable, because its use
in the common expressions such as ?many times?
98
is much more frequent than its use as an uncount-
able noun as in ?theory of time? or ?what time is
it now??. More sophisticated systems should ana-
lyze the contexts obtained from vast data sets (cor-
pora), i.e. consider n-grams or syntactic n-grams.
Note that word sense disambiguation would be
helpful in the resolution of the mentioned ambigu-
ities. Also, the rule that considers the presence of
the dependent words like ?many, a lot of, amount
of? could be added.
3.2 Subject-Verb Agreement and Verb Form
Error Processing
We consider these two types of errors together be-
cause they are related to a similar and a rather sim-
ple grammatical phenomenon. To correct these
errors we used syntactic information to formulate
the rules. This is logical because we cannot rely
on the context words (neighbours) as they appear
in texts (traditional n-grams). Note that the rules
are also related to the modal verbs and the passive
constructions.
The rules for the agreement are very simple: 1)
if the noun is in plural and the VBZ tag is present,
then change the tag to VB, 2) if the noun is in
singular and the VB tag is present, then change
the tag to VBZ. The corresponding morphological
generation is also performed.
The rules for verb form correction are as fol-
lows: 1) if we have a modal verb, then the depend-
ing verb should have a VB tag, 2) if we have an
auxiliary verb ?have?, then the main verb should
have a VB tag (perfect tense), etc. Moreover, the
FreeLing morphological dictionary is utilized to
identify the correct verb form. Note that there are
some assumptions here about what drives the verb
form, e.g., that a noun or a modal verb are correct
and the verb needs to change. This appears to be
a reasonable assumption, but may not always be
correct.
3.3 Preposition Error Processing
It is well-known that prepositions depend on lex-
ical units that are their heads, see (Eeg-Olofsson
and Knutsson, 2003). But what should be done
if we want to consider the dependent word? Say,
that in the PP attachment task, the lexical unit is
the preferred solution as well. In general, it would
be an ideal solution in grammar correction, but in
the case of our system, very little training data was
used. If we consider that the dependent word is a
lexical unit, we will have less recall. We are there-
fore practically obliged to consider that it is a POS
tag.
To process the prepositions, we used the train-
ing data provided by the organizers. Specifically,
we extracted preposition patterns. We apply the
concept of syntactic n-grams to include both the
head word of the preposition and the dependent
word into the pattern. The pattern data corre-
sponds to syntactic n-grams because they are con-
structed using syntactic dependencies. As we
mentioned previously, syntactic n-grams can con-
sist of words, POS tags or a combination. In our
case, we used mixed syntactic n-grams: the head
word is the lexical unit, while the dependent word
is the POS tag, as shown in Table 2.
For example, the first line corresponds to the er-
roneous phrase ?...unwelcomed among public...?,
where ?among? should be substituted by ?by?.
Note that there can be other words between these
three words in the surface representation of the
sentence, but the parser allows the extraction of
the syntactic n-gram, which represents the ?pure?
pattern.
In order to choose the syntactic n-gram type, our
first consideration was that the head word should
be a lexical unit (word), because this determines
the choice of the preposition. We used a POS
tag for the dependent element, because we consid-
ered that using a word there would be too specific.
Thus, our final syntactic n-gram for the first line
was ?...unwelcomed among NN...?, which should
be changed to ?...unwelcomed by NN...?. The syn-
tactic n-gram for the second line was ?...trouble for
NN...?, which should be changed to ?...trouble in
NN...?, etc. Note that insertion of prepositions is
not considered, but deletion can be performed, i.e.,
changing the preposition to nothing.
The rule for the system is formulated in the fol-
lowing way: if we find a relation ?preposition? in
the dependency tree, then for the preposition that
corresponds to this relation, we search the list of
the extracted patterns. If we find the pattern, then
we change the preposition. It is quite clear that
the training data is too limited to obtain patterns
for a great majority of words. Our list contained
only 1,896 elements. These patterns should be ex-
tracted from a very large corpus or a dictionary.
3.4 Article or Determiner Error Processing
In this case, we found only two clear rules, both
related to the article ?a?: 1) choice of the allo-
99
Table 2: Examples of patterns for prepositions.
Preposition Preposition Head word Head word Dependent word Dependent word
(error) (correction) (lemma) (POS) (lemma) (POS)
among by unwelcomed VBN public NN
for in trouble NN development NN
on in practice NN October NNP
on in face VBG field NN
morph ?a/an?, and 2) the fact that the article ?a?
cannot be used with nouns in plural. Other rules
would be too complex for a manually created rule-
based system. The first rule takes into the account
the immediate neighbor: the choice depends on its
phonetic properties. The second rule considers the
syntactically related head word, which cannot be
in plural if we use the indefinite article.
4 Evaluation of the System
For the evaluation, the organizers provided data
similar to the training data from the same NU-
CLE corpus, which also contained syntactic in-
formation. The evaluation results were provided
by the organizers using their evaluation script in
Python (Dahlmeier and Ng, 2012). The results ob-
tained with this script for our system are: precision
17.4 %, recall 1.8%, and F1 measure 3.3% (the
preliminary scores were: 12.4%, 1.2% and 2.2%
correspondingly). See the final remarks in this
section, where we argue that the real values should
be: precision 25%, recall 2.6%, and F1 measure
4.7%.
The results are low, but as we mentioned previ-
ously, our system uses a rule-based approach with
very few additional resources, so it cannot com-
pete with ML based approaches that additionally
rely on vast lexical resources and the Internet. Due
to its simplicity, low use of additional resources,
and very short development time, we consider our
system a possible baseline system for the task. On
the other hand, we showed that in some cases the
rules should be used as a complementary tech-
nique for ML learning methods: don?t guess if you
know.
The low recall of the system is to be expected
as we process only clearly defined errors, ignoring
more complex cases.
It is always interesting to perform an analysis of
the errors committed by a system. Let us analyze
the supposed errors committed by our system
for the noun number error type. It performed 18
corrections, 3 of which coincide with the marks
in the corpus data. Two of them are clear errors
of the system: ?traffic jam?, where the word
?jam? is used in a sense other than that of the
?substance?, and ?many respects?, where again
the word ?respect? has a different meaning to that
of the uncountable noun. There are 13 cases listed
below, that our system marked as errors, because
they are uncountable nouns in plural, but they
are not marked in the corpus. Let us consider the
nouns in capital letters:
...peaceful(JJ) LIVINGS(NNS)
2
...,
...life(NN) QUALITIES(NNS)...,
...Many(JJ) science(NN) FICTIONS(NNS)...,
...does(VBZ) not(RB) have(VB) enough(JJ)
LANDS(NNS)...,
...indicates(VBZ) that(IN) the(DT) FOODS(NNS)
the(DT) people(NNS) eat(VBP)...,
...problem(NN) of(IN) public(JJ) TRANSPORTA-
TIONS(NNS)...,
...healthcare(NN) consume(VBP) large(JJ)
QUANTITIES(NNS) of(IN) energy...,
...this(DT) society(NN) may(MD) lack(VB) of(IN)
LABOURS(NNS)...
Note that the words ?equipment? and ?usage?
in plural were marked as errors in the corpus. In
our opinion, it is inconsistent to mark these two as
errors, and not to mark the words from this list as
such. While it is true that their use in plural is pos-
sible, it is clearly forced and is much less probable.
At least, students of English should learn to use
these words in singular only. Some of these mis-
takes (but not all) were corrected by the organizers
for the final scoring data. If we consider all these
cases as correctly marked errors, then the preci-
sion of our system is around 25%, recall 2.6%, and
F1 measure 4.7%.
2?LIVINGS? is encountered 5 times and ?QUANTITIES?
is encountered 2 times
100
5 Conclusions
In this paper we have described the system pre-
sented for the CoNLL-2013 shared task for gram-
mar correction in English (L2). The system uses
a rule-based approach and relies on very few addi-
tional resources: a list of 250 uncountable nouns, a
morphological analyzer and the training data from
the NUCLE corpus provided by the organizers.
The system uses syntactic n-grams for rule formu-
lation, i.e., n-grams that are constructed by follow-
ing the dependency paths in a parsed tree.
We analyzed various situations in which a rule
based technique can give better results than ML
techniques: don?t guess if you know. These cases
are: 1) two rules for the article ?a?, and 2) the
rules for uncountable nouns (in this case, word
sense disambiguation would help to determine if
the sense in the text is an uncountable noun or
has some other use), and 3) the subject-verb agree-
ment rule. In the case of prepositions, ML learn-
ing is definitely better. Otherwise, vast resources
would need to be used, which in any case, would
resemble machine learning. We are not sure about
verb form errors: the rules which we formulated
are rather simple, but the performance of various
ML methods should be analysed in order to decide
which technique is better.
The system is simple and was developed in a
very short time. It does not obtain high scores and
could be considered as a baseline system for the
task.
Acknowledgements
This work was done under partial support of the
Mexican Government (CONACYT, SNI, COFAA-
IPN, SIP-IPN 20120418, 20121823), CONACYT-
DST India (?Answer Validation through Textual
Entailment?), Mexico City Government (ICYT
PICCO10-120), and FP7-PEOPLE-2010- IRSES:
Web Information Quality - Evaluation Initiative
(WIQ-EI) European Commission project 269180.
References
Daniel Dahlmeier and Hwee Tou Ng. 2012. Better
evaluation for grammatical error correction. In Pro-
ceedings of the 2012 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics (NAACL 2012), pages 568?572.
Daniel Dahlmeier, Hwee Tou Ng, and Siew Mei Wu.
2013. Building a large annotated corpus of learner
English: The NUS corpus of learner English.
M.C. de Marneffe, B. MacCartney, and C.D. Manning.
2006. Generating typed dependency parses from
phrase structure parses. In LREC 2006.
Jens Eeg-Olofsson and Ola Knutsson. 2003. Auto-
matic grammar checking for second language learn-
ers ? the use of prepositions. In Proceedings of
Nodalida?03.
Llus Padro?, Miquel Collado, Samuel Reese, Marina
Lloberes, and Irene Castello?n. 2010. Freeling
2.1: Five years of open-source language processing
tools. In Proceedings of 7th Language Resources
and Evaluation Conference (LREC 2010), ELRA.
G. Sidorov, F. Velasquez, E. Stamatatos, A. Gel-
bukh, and L. Chanona-Hernandez. 2012. Syntac-
tic dependency-based n-grams as classification fea-
tures. LNAI 7630, pages 1?11.
G. Sidorov, F. Velasquez, E. Stamatatos, A. Gel-
bukh, and L. Chanona-Hernandez. 2013. Syntactic
dependency-based n-grams: More evidence of use-
fulness in classification. LNCS 7816 (Proc. of CI-
CLing), pages 13?24.
Pasi Tapanainen and Atro Voutilainen. 1994. Tagging
accurately - don?t guess if you know. In Proceedings
of ANLP ?94.
101
