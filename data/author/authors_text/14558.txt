Proceedings of the Multiword Expressions: From Theory to Applications (MWE 2010), pages 11?18,
Beijing, August 2010
Construction of a Chinese Idiom Knowledge Base and Its Applications 
 
Lei Wang  
Key Laboratory of Computational 
Linguistics of Ministry of Education 
Department of English, Peking University 
wangleics@pku.edu.cn 
Shiwen Yu  
Key Laboratory of Computational 
Linguistics of Ministry of Education,  
Peking University 
yusw@pku.edu.cn 
Abstract 
Idioms are not only interesting but also 
distinctive in a language for its continuity 
and metaphorical meaning in its context. 
This paper introduces the construction of 
a Chinese idiom knowledge base by the 
Institute of Computational Linguistics at 
Peking University and describes an 
experiment that aims at the automatic 
emotion classification of Chinese idioms. 
In the process, we expect to know more 
about how the constituents in a fossilized 
composition like an idiom function so as 
to affect its semantic or grammatical 
properties. As an important Chinese 
language resource, our idiom knowledge 
base will play a major role in applications 
such as linguistic research, teaching 
Chinese as a foreign language and even as 
a tool for preserving this non-material 
Chinese cultural and historical heritage. 
1  Introduction 
An idiom is a multi-word expression that has a 
figurative meaning that is comprehended in 
regard to a common use of that expression that 
is separate from the literal meaning or definition 
of the words of which it is made (McArthur, 
1992). From a linguistic perspective, idioms are 
usually presumed to be figures of speech that 
are contradictory to the principle of 
compositionality. The words that construct an 
idiom no longer keep their original meaning or 
popular sense, while in the process of its 
formation it develops a specialized meaning as 
an entity whose sense is different from the 
literal meanings of the constituent elements.  
Although an idiom is an expression not 
readily analyzable from its grammatical 
structure or from the meaning of its component 
words, it is the distinctive form or construction 
of a particular language that has a unique form 
or style characteristic only of that language. An 
idiom is also used, in most cases, with some 
intention of the writer or to express certain 
emotion or attitude. Thus in nature, idioms are 
exaggerative and descriptive and do not belong 
to the plain type.  
Therefore, to classify idioms according to 
its emotional property or descriptive property is 
important for many practical applications. In 
recent years, emotion classification has become 
a very popular task in the area of Natural 
Language Processing (NLP), which tries to 
predict sentiment (opinion, emotion, etc.) from 
texts. Most research has focused on subjectivity 
(subjective/objective) or polarity 
(positive/neutral/negative) classification. The 
applications with this respect include human or 
machine translation, automatic text 
classification or Teaching Chinese as a Foreign 
Language (TCFL). For example, when a student 
learning Chinese as a foreign language 
encounters an idiom in his or her reading or 
conversation, for better understanding it is 
important for him or her to know whether the 
idiom is used to indicate an appreciative or 
derogatory sense which is very crucial to 
understand the attitude of the idiom user. 
Another example is that long articles about 
politics in newspapers often include a lot of 
idiom usage to boost their expressiveness and 
these idioms may carry emotional information. 
Obviously by knowing the emotional 
inclination we may easily obtain a clue about 
the general attitude of the particular medium. 
We may even be able to detect or monitor 
automatically the possible hostile attitude from 
certain electronic media which today provide so 
huge amount of information that seems hard for 
human processing on a daily basis.  
The rest of this paper is organized as 
follows. Section 2 describes the construction of 
11
a Chinese Idiom Knowledge Base (CIKB) and 
introduces its several applications so far. 
Section 3 concludes the related work that serves 
as the basis of the building of CIKB and the 
emotion classification experiment introduced in 
this paper. Section 4 describes the classification 
method, feature settings, the process of emotion 
classification and the analysis of the result. 
Section 5 includes conclusions and our future 
work. 
2 Chinese Idioms and Chinese Idiom 
Knowledge Base 
Generally an idiom is a metaphor ? a term 
requiring some background knowledge, 
contextual information, or cultural experience, 
mostly to use only within a particular language, 
where conversational parties must possess 
common cultural references. Therefore, idioms 
are not considered part of the language, but part 
of a nation?s history, society or culture. As 
culture typically is localized, idioms often can 
only be understood within the same cultural 
background; nevertheless, this is not a definite 
rule because some idioms can overcome 
cultural barriers and easily be translated across 
languages, and their metaphoric meanings can 
still be deduced. Contrary to common 
knowledge that language is a living thing, 
idioms do not readily change as time passes. 
Some idioms gain and lose favor in popular 
literature or speeches, but they rarely have any 
actual shift in their constructs as long as they do 
not become extinct. In real life, people also 
have a natural tendency to over exaggerate what 
they mean or over describe what they see or 
hear sometimes and this gives birth to new 
idioms by accident.  
Most Chinese idioms (??: ch?ng1  y?, 
literally meaning ?set phrases?) are derived 
from ancient literature, especially Chinese 
classics, and are widely used in written Chinese 
texts. Some idioms appear in spoken or 
vernacular Chinese. The majority of Chinese 
idioms consist of four characters, but some have 
fewer or more. The meaning of an idiom 
usually surpasses the sum of the meanings 
                                                                 
1 The marks on the letters in a Pinyin are for the five tones 
of Chinese characters.   
carried by the few characters, as Chinese idioms 
are often closely related with the fable, story or 
historical account from which they were 
originally born. As their constructs remain 
stable through history, Chinese idioms do not 
follow the usual lexical pattern and syntax of 
modern Chinese language which has been 
reformed many a time. They are instead highly 
compact and resemble more ancient Chinese 
language in many linguistic features.  
Usually a Chinese idiom reflects the moral 
behind the story that it is derived. (Lo, 1997) 
For example, the idiom ?????? (p? f? ch?n 
zh?u) literally means ?smash the cauldrons and 
sink the boats.? It was based on a historical 
story where General Xiang Yu in Qin Dynasty 
(221 B. C. ? 207 B. C.) ordered his army to 
destroy all cooking utensils and boats after they 
crossed a river into the enemy?s territory. He 
and his men won the battle for their ?life or 
death? courage and ?no-retreat? policy. 
Although there are similar phrases in English, 
such as ?burning bridges? or ?crossing the 
Rubicon?, this particular idiom cannot be used 
in a losing scenario because the story behind it 
does not indicate a failure. Another typical 
example is the idiom ?????? (gu? ti?n l? 
xi?) which literally means ?melon field, under 
the plum trees?. Metaphorically it implies a 
suspicious situation. Derived from a verse 
called ????? (j?n z? x?ng, meaning ?A 
Gentleman?s Journey?) from Eastern Han 
Dynasty (A. D. 25 ? A. D. 220), the idiom is 
originated from two lines of the poem ????
????????? (gu? ti?n b? n? l?, l? xi? b? 
zh?ng gu?n) which describe a code of conduct 
for a gentleman that says ?Don't adjust your 
shoes in a melon field and don?t tidy your hat 
under plum trees? in order to avoid suspicion of 
stealing. However, most Chinese idioms do not 
possess an allusion nature and are just a 
combination of morphemes that will give this 
set phrase phonetic, semantic or formal 
expressiveness. For example, the idiom ???
??? (hu?n ti?n x? d?, metaphorically meaning 
?be highly delighted?) literally means ?happy 
heaven and joyful earth?; or in the idiom ???
??? (l?ng d?ng r? y?, meaning ?be thrown 
into the jail?), the word ???? is just the sound 
of a prisoner?s fetters. 
12
For the importance of idioms in Chinese 
language and culture, an idiom bank with about 
6,790 entries were included in the most 
influential Chinese language knowledge base ? 
the Grammatical Knowledge base of 
Contemporary Chinese (GKB) completed by 
the Institute of Computational Linguistics at 
Peking University (ICL), which has been 
working on language resources for over 20 
years and building many knowledge bases on 
Chinese language. Based on that, the Chinese 
Idiom Knowledge Base (CIKB) had been 
constructed from the year 2004 to 2009 and 
collects more than 38, 000 idioms with more 
semantic and pragmatic properties added. 
Basically the properties of each entry in 
CIKB can be classified into four categories: 
lexical, semantic, syntactic and pragmatic, each 
of which also includes several fields in its 
container -- the SQL database. Table 1 shows 
the details about the fields. 
 
Categories Properties 
Lexical idiom, Pinyin2, full Pinyin3, 
bianti4, explanation, origin 
Semantic synonym, antonym, literal 
translation, free translation, 
English equivalent 
Syntactic compositionality, syntactic 
function 
Pragmatic frequency, emotion, event 
(context), grade 
 
Table 1. Property categories of CIKB. 
 
There are three fields of translation as we 
can see in Table 1. In spite of the fact that a 
                                                                 
2 Pinyin (??, literally ?phonetics?, or more literally, 
?spelling sound? or ?spelled sound?), or more formally 
Hanyu Pinyin (????, Chinese Pinyin), is currently the 
most commonly used Romanization system for standard 
Mandarin. The system is now used in mainland China, 
Hong Kong, Macau, parts of Taiwan, Malaysia and 
Singapore to teach Mandarin Chinese and internationally 
to teach Mandarin as a second language. It is also often 
used to spell Chinese names in foreign publications and 
can be used to enter Chinese characters on computers and 
cell phones. 
3 full Pinyin, a form of Pinyin that replaces the tone marks 
with numbers 1 to 5 to indicate the five tones of Chinese 
characters for the convenience of computer processing. 
4 bianti, a variant form of the idiom that was caused by 
random misuse, literary malapropism, etc. 
literal translation of an idiom will not reflect its 
metaphorical meaning generally, it will still be 
of value to those who expect to get familiar 
with the constituent characters and may want to 
connect its literal meaning with its metaphorical 
meaning, especially for those learners of 
Chinese as a foreign language. 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1. The hierarchical structure of CIKB. 
 
The idioms are classified into three grades 
in terms of appearance in texts and complexity 
of annotation. The most commonly used 3,000 
idioms serve as the core idioms based on the 
statistics obtained from the corpus of People?s 
Daily (the year of 1998), a newspaper that has 
the largest circulation in China. Another 11,000 
idioms are selected into a category named as 
basic idioms (fully annotated in every field) and 
the total 38,117 forms the whole knowledge 
base. Its hierarchical structure can be seen in 
Figure 1. 
The syntactic category aims at NLP tasks 
like automatic identification or machine 
translation. Compared with English idioms, the 
identification of Chinese idioms is not so 
difficult for its fossilized structure, i.e. 
continuity in a text. To build a lexicon like 
CIKB will complete the task successfully. As 
for machine translation, however, it is 
completely another story because the 
compositional complexity of Chinese idioms 
enables them to function as different syntactic 
constituents with variable part-of-speech (POS). 
We classify them into nine categories according 
to its compositional relations of the morphemes 
and into seven categories according to its 
syntactic functions that they may serve in a 
sentence, as is shown in Table 2. 
 
 
 
 
CIKB 38,117 
 
 
   Basic 11,000 
Core 3,000 
13
No. Compositionality Tag No. Syntactic function Tag 
1 modifier-head construction pz 1 as a noun IN 
2 subject-predicate phrase zw 2 as a verb IV 
3 Coordination bl 3 as an adjective IA 
4 predicate-object phrase db 4 as a complement IC 
5 predicate-complement dbu 5 as an adverbial ID 
6 predicate-object-complement dbb 6 as a classifier IB 
7 serial verb ld 7 as a modifier IM 
8 pivotal verb jy    
9 Repetition fz    
 
Table 2.  Compositionality and syntactic functions of idioms. 
 
Upon the completion of CIKB, a few 
research projects have been conducted to 
investigate possible applications. Li (2006) 
investigates the frequency and formation of 
idiom usage in People?s Daily and Wang (2010) 
selects 1,000 popular idioms from CIKB to 
compile a book for Chinese learners. On the 
basis of CIKB, we also made a couple of 
attempts on the automatic classification of 
idioms to identify the token-level characteristics 
of an idiom. This paper will focus on the 
emotion classification of idioms with machine 
learning method and the work will be elaborated 
in section 4. Here we define the emotion types 
as ?appreciative (A)?, ?derogatory (D)? and 
?neutral (N)?.  
3 Related Work on Idiom Knowledge 
Base and Its Applications 
There has not been much work on the 
construction of an idiom corpus or an idiom 
knowledge base. With this respect, Birke and 
Sarkar (2006) and Fellbaum (2007) are 
exceptions. Birke and Sarkar (2006) constructed 
a corpus of English idiomatic expressions with 
automatic method. They selected 50 expressions 
and collected about 6,600 examples. They call 
the corpus TroFi Example Base, which is 
available on the Web. 
As far as idiom identification is concerned, 
the work is classified into two kinds : one is for 
idiom types and the other is for idiom tokens. 
With the former, phrases that can be interpreted 
as idioms are found in text corpora, typically for 
lexicographers to compile idiom dictionaries. 
Previous studies have mostly focused on the 
idiom type identification (Lin, 1999; Baldwin et 
al., 2003; Shudo et al, 2004). However, there 
has been a growing interest in idiom token 
identification recently (Katz and Giesbrecht, 
2006; Hashimoto et al, 2006; Cook et al , 2007). 
Our work elaborated in section 4 is also an 
attempt in this regard. 
    Despite the recent enthusiasm for 
multiword expressions, the idiom token 
identification is in an early stage of its 
development. Given that many language 
teaching and learning tasks like TCFL have been 
developed as a result of the availability of 
language resources, idiom token identification 
should also be developed when adequate idiom 
resources are provided. To this end, we have 
constructed the CIKB and hope to find 
applications of value, for example, emotion 
classification, event classification and text 
analysis based on idiom usage and its context.  
According to the granularity of text, 
emotion analysis of texts can be divided into 
three levels: text (Pang et al, 2002; Cui et al, 
2006), sentence (Pang et al, 2004), word 
(Hatzivassiloglou et al, 1997; Wiebe 2000). 
According to the sources of emotion prediction, 
classification methods can be divided into 
knowledge based methods and machine learning 
based methods. The former uses lexicons or 
knowledge bases to build a new lexicon that 
contains emotion words. WordNet is often used 
to compute the emotion prediction of words 
(Hatzivassiloglou et al, 1997; Andrea 2005). 
Meanwhile, incorporating knowledge into the 
machine learning architecture as features is a 
popular trend and untagged copra are often used 
to do emotion classification research (Turney et 
al., 2002; Akkaya et al, 2009).  
14
4 An NLP Application of Emotion 
Classification on CIKB 
In this paper, we focus on the emotion prediction 
of idioms conducted by machine learning 
method. To do this, we aim to investigate how 
the compositional constituents of an idiom affect 
its emotion orientation from the token level, 
especially for multi-word expressions with so 
obvious an exaggerative and descriptive nature 
like idioms. From CIKB, 20,000 idioms are 
selected as the training corpus and 3,000 idioms 
as the test corpus. The detailed distribution of 
idioms in each emotion group is shown in Table 
3. We can see that neutral has the largest number 
of idioms, accounting for 41.08% and 36.67% in 
the training and test corpus respectively, but 
there is not a big difference between groups. 
 
 
Training corpus Test corpus 
number percentage number Percentage 
Appreciative(A) 6967 34.84% 1011 33.70% 
Neutral(N) 8216 41.08% 1100 36.67% 
Derogatory(D) 4817 24.08% 889 29.63% 
 
Table 3.  The distribution of idioms in each emotion group. 
 
Support Vector Machine (SVM) (Cortes 
and Vapnik, 1995) is adopted as the 
classification method to predict emotions in 
idioms. LIBLINEAR (Fan et al, 2008), a 
library for large SVM linear classification, is 
used for implementation. The solver is set be 
L2-loss SVM dual. Parameter C is set to be 2-5. 
Three classes of features and their various 
combinations are examined and used, including 
Chinese characters, words and part-of-speeches. 
Detailed features and related abbreviations are 
shown as in Table 4. 
Because Chinese sentences are written in 
a consecutive string of characters, we need to 
segment a sentence into individual words to 
obtain the word feature. ICTCLAS (Zhang et 
al., 2003), a tool developed by the Institute of 
Computing Technology of Chinese Academy 
of Sciences (ICT), is used for word 
segmentation and part-of-speech tagging. We 
adopt precision, recall and F-score (?=1) as the 
evaluation parameters. From Table 5 we can 
see that i_cb has a better performance than i_cu, 
which indicates that a bigram model usually 
performs better than a unigram model. But 
when we segment the idioms and use i_wu, we 
find that the performance gets bad. This may 
be because the compositionality of Chinese 
idioms is quite fossilized and the errors caused 
by segmentation introduce some noise.  
 
Features and their abbreviations Idiom(i) Explanation(e) 
Chinese characters character unigram(i_cu, e_cu) ?5 ? 
character bigram(i_cb, e_cb) ? ? 
Words word unigram(i_wu, e_wu) ? ? 
word bigram(i_wb, e_wu) ? ? 
Word/part-of-speech word/pos unigram(i_wpu, e_wpu) ? ? 
word/pos bigram(i_wpb, e_wpb) ? ? 
 
Table 4.  Features selected for emotion prediction. 
                                                                 
5 ??? indicates  the feature is selected while ??? indicates the feature is not selected. 
15
We want to know whether we will have a 
better performance if we add more features 
from the other fields of CIKB. Obviously the 
most relevant feature will be the explanation of 
an idiom. Therefore we add the texts in the 
explanation field as features in the experiment.  
We find that by adding more features from the 
explanation field, the performance does 
improve. But when the POS feature is 
introduced, the performance gets bad. This may 
be because as Chinese idioms keep 
grammatical properties of ancient Chinese 
language and its POS is very different from the 
setting of the tool designed primarily for 
modern Chinese, more noise is introduced by 
using POS here. Finally we can see that the 
combination i_cu+i_cb+e_wu+e_wb achieves 
the best performance in both Chinese character 
features and word features.  
Most importantly, we notice that although 
for idioms themselves segmentation does not 
affect the performance in a positive way, 
segmentation of the explanations does improve 
the performance. Thus we may conclude that 
the compositionality of an idiom is very 
different from its explanation which is written 
in modern Chinese while the idiom itself is still 
character-based and keeps its original 
morphemes that are inherited from ancient 
Chinese language.  
 
Features or features 
combined 
Result 
Precision Recall F-score 
i_cu 63.23% 75.16% 68.68% 
i_cb 65.78% 78.24% 71.47% 
i_wu 62.51% 73.42% 68.35% 
i_wpu 60.03% 71.89% 65.43% 
i_cu+e_wu 66.40% 80.05% 72.59% 
i_cu+e_wpu 65.68% 77.95% 71.29% 
i_cu+e_wb 65.08% 76.14% 70.18% 
I_cu+i_cb 67.33% 80.82% 73.46% 
i_cu+i_cb+e_wu 68.55% 81.37% 74.41% 
i_cu+i_cb+e_wu+e_wb  70.18% 82.71% 75.93% 
 
Table 5. The result of emotion classification with idioms and their explanations. 
 
55%
60%
5%
70%
75%
80%
1k 2k 5k 10k 15k 20k
Size of training data
A
c
c
u
r
a
c
y
 
Figure 2. Learning curve of the feature combination i_cu+i_cb+e_wu+e_wb. 
 
Figure 2 shows the learning curve of the 
best classifier with the feature combination 
i_cu+i_cb+e_wu+e_wb. We can see that the 
accuracy keeps improving with the increase of 
the size of training set, and peaks at 20,000 
idioms. It shows the potential to improve the 
16
performance of emotion classification by 
enlarging the training data set. 
5  Conclusions and Future Work 
This paper introduces the construction of CIKB 
by ICL at Peking University and its several 
applications so far. One application ? the 
emotion classification of idioms ? was 
elaborated to show our effort in exploring the 
token-level characteristics of Chinese idioms. 
Therefore we select a number of idioms from 
CIKB to classify them into three emotion 
groups. SVM is employed for automatic 
classification. Three classes of features are 
examined and experiments show that certain 
feature combinations achieve good 
performance. The learning curve indicates that 
performance may be further improved with the 
increase of training data size.  
Now we also hope to classify the idioms 
into categories according to their usage in 
context, i.e., under what circumstances they are 
often used (event classification). Various 
linguistic features and real-world knowledge 
will be considered to incorporate into the 
machine learning classifier to improve 
classification result. The work is in progress 
and we hope the emotion classification and the 
event classification will be compared to 
determine their underlining relations and hope 
that more applications can be found in our 
future work based on CIKB. 
Acknowledgements  
The work in this paper is supported by a grant 
from the 973 National Basic Research Program 
of China (No. 2004CB318102). The authors 
are grateful to Dr. Li Yun and Professor Zhu 
Xuefeng for their work on CIKB and the 
anonymous reviewers for their helpful advice 
to improve the paper. 
 
References 
 
Akkaya, Cem, Janyce Wiebe, and Rada 
Mihalcea. 2009. Subjectivity Word Sense 
Disambiguation. In Proceedings of the 
2009 Conference on Empirical Methods in 
Natural Language Processing: Volume 1: 
pp.190-199. 
Andrea, Esuli. 2005. Determining the Semantic 
Orientation of Terms through Gloss 
Classification. In Proceedings of the 14th 
ACM International Conference on 
Information and Knowledge Management : 
pp.617-624.  
Baldwin, Timothy, Colin Bannard, Takaaki 
Tanaka, and Dominic Widdows. 2003. An 
Empirical Model of Multiword Expression 
Decomposability. In Proceedings of the 
ACL 2003 Workshop on Multiword 
Expressions: Analysis, Acquisition and 
Treatment - Volume 18: pp.89-96. 
Cook, Paul, Afsaneh Fazly, and Suzanne 
Stevenson. 2007. Pulling Their Weight : 
Exploiting Syntactic Forms for the 
Automatic Identification of Idiomatic 
Expressions in Context. In Proceedings of 
the Workshop on A Broader Perspective 
on Multiword Expressions: pp. 41-48. 
Cortes, Corinna and Vladimir Vapnik. 1995. 
Support-Vector Networks. Machine 
Learning, 20(3): pp. 273-297. 
Cui, Hang, Vibhu Mittal, and Mayur Datar. 
2006. Comparative Experiments on 
Sentiment Classification for Online 
Product Reviews. In Proceedings of the 
21st National Conference on Artificial 
Intelligence-Volume 2: pp.1265-1270. 
Fan, Rong-En, Chang Kai-Wei, Cho-Jui Hsieh, 
Xiang-Rui Wang, Chih-Jen Lin. 2008. 
LIBLINEAR: A Library for Large Linear 
Classification. Journal of Machine 
Learning Research 9 (2008): 
pp.1871-1874. 
Fellbaum, Christiane. 2007. Idioms and 
Collocations: Corpus-based Linguistic 
and Lexicographic Studies (Research in 
Corpus and Discourse). Continuum 
International Publishing Group Ltd. , 
London, UK. 
Hashimoto, Chikara, Satoshi Sato, and 
Takehito Utsuro. 2006. Japanese Idiom 
Recognition: Drawing a Line between 
Literal and Idiomatic Meanings. In 
Proceedings of the COLING/ACL on 
17
Main Conference Poster Sessions: pp. 
353-360. 
Hatzivassiloglou, Vasileios, and Kathleen 
McKeown. 1997. Predicting the Semantic 
Orientation of Adjectives. In Proceedings 
of the Eighth Conference on European 
Chapter of the Association for 
Computational Linguistics: pp.174-181. 
Katz, Graham, and Eugenie Giesbrecht. 2006. 
Automatic Identification of 
Non-compositional Multi-word 
Expressions Using Latent Semantic 
Analysis. In Proceedings of the Workshop 
on Multiword Expressions: Identifying 
and Exploiting Underlying Properties: 
pp.12-19. 
Li, Yun, Zhang Huarui, Wang Hongjun, and 
Yu Shiwen. 2006. Investigation on the 
Frequency and Formation of Idioms in 
People?s Daily. In Proceedings of the 7th 
Chinese Lexicon and Semantics Workshop: 
pp.241-248. 
Lin, Dekang. 1999. Automatic Identification of 
Noncompositional Phrases. In 
Proceedings of the 37th Annual Meeting 
of the Association for Computational 
Linguistics on Computational Linguistics: 
pp.317-324. 
Lo, Wing Huen. 1997. Best Chinese Idioms 
(Vol. 3). Hai Feng Publishing Co., Hong 
Kong, China.  
McArthur, Tom. 1992. The Oxford Companion 
to the English Language. Oxford 
University Press, Oxford, UK. 
Pang, Bo and Lillian Lee. 2004. A Sentimental 
Education: Sentiment Analysis Using 
Subjectivity Summarization Based on 
Minimum Cuts. In Proceedings of the 
42nd Annual Meeting on Association for 
Computational Linguistics: pp.271-278. 
Pang, Bo, Lillian Lee, and Shivakumar 
Vaithyanathan. 2002. Thumb up? 
Sentiment Classification Using Machine 
Learning Techniques. In Proceedings of 
the ACL-02 Conference on Empirical 
Methods in Natural Language Processing: 
pp.79-86. 
Shudo, Kosho, Toshifumi Tanabe, Masahito 
Takahashi, and Kenji Yoshimura. 2004. 
MWEs as Nonpropositional Content 
Indicators. In Proceedings of the 
Workshop on Multiword Expressions: 
Integrating Processing: pp.32-39. 
Turney, Peter D. 2002. Thumps Up or Thumps 
Down? Semantic Orientation Applied to 
Unsupervised Classification of Reviews. 
In Proceedings of the 40th Annual 
Meeting on Association for Computational 
Linguistics: pp.417-424. 
Wang, Lei. Forthcoming 2010. 1,000 Idioms 
for Chinese Learners. Peking University 
Press, Beijing, China. 
Wiebe, Janyce. 2000. Learning Subjective 
Adjectives from Corpora. In Proceedings 
of the Seventeenth National Conference on 
Artificial Intelligence and Twelfth 
Conference on Innovative Applications of 
Artificial Intelligence: pp.735-740. 
Zhang, Huaping, Yu Hongkui, Xiong Deyi,  
Liu Qun. 2003. HHMM-based Chinese 
Lexical Analyzer ICTCLAS. In 
Proceedings of the Second SIGHAN 
Workshop on Chinese Language 
Processing: pp.184-187. 
 
18
Semantic Computing and Language Knowledge Bases1 
 
Lei Wang  
Key Laboratory of Computational Linguistics 
of Ministry of Education 
Department of English, Peking University 
wangleics@pku.edu.cn 
Shiwen Yu  
Key Laboratory of Computational 
Linguistics of Ministry of Education, 
Peking University 
yusw@pku.edu.cn 
                                                 
1 This work is supported by the National Natural Science Foundation of China (No. 60970083) and Chiang Ching-kuo 
Foundation for International Scholarly Exchange (2009).  
Abstract 
As the proposition of the next-generation 
Web ? semantic Web, semantic computing 
has been drawing more and more attention 
within the circle and the industries. A lot of 
research has been conducted on the theory 
and methodology of the subject, and 
potential applications have also been 
investigated and proposed in many fields. 
The progress of semantic computing made 
so far cannot be detached from its 
supporting pivot ? language resources, for 
instance, language knowledge bases. This 
paper proposes three perspectives of 
semantic computing from a macro view and 
describes the current status of affairs about 
the construction of language knowledge 
bases and the related research and 
applications that have been carried out on 
the basis of these resources via a case study 
in the Institute of Computational Linguistics 
at Peking University. 
 
1 Introduction 
Semantic computing is a technology to compose 
information content (including software) based 
on meaning and vocabulary shared by people 
and computers and thereby to design and 
operate information systems (i.e., artificial 
computing systems). Its goal is to plug the 
semantic gap through this common ground, to 
let people and computers cooperate more 
closely, to ground information systems on 
people?s life world, and thereby to enrich the 
meaning and value of the entire life world. 
(Hasida, 2007) The task of semantic computing 
is to explain the meaning of various constituents 
of sentences (words or phrases) or sentences 
themselves in a natural language. We believe 
that semantic computing is a field that addresses 
two core problems: First, to map the semantics 
of user with that of content for the purpose of 
content retrieval, management, creation, etc.; 
second, to understand the meanings (semantics) 
of computational content of various sorts, 
including, but is not limited to, text, video, 
audio, network, software, and expressing them 
in a form that can be processed by machine.
 
Figure 1. Human-computer interaction is handicapped without semantic computing. 
But the way to the success of semantic 
computing is not even and it has taken a quite 
long time for researchers to make some 
progress in this field. The difficulties of 
semantic computing involve many aspects: 
ambiguity, polysemy, domain of quantifier, 
metaphor, etc. Different individuals will have 
different understanding of the same word or the 
same sentence. Research on the theory and 
methodology of semantic computing still has a 
long way to go. 
Now we provide an example in a search 
engine to show how difficult for the computer 
to understand the meaning of a word. We input 
two sentences into Google.com Translate and 
the following results were returned: 
 
Example 1   
I bought a table with three dollars.?20091016 Google: ???? 3 ????? 
I bought a table with three legs.   ?20091016 Google: ???? 3????? 
 
We know that the word ?table? has two 
common meanings in English (a wooden object 
and a structured data report). But in Chinese 
they correspond to two different words (? bi?o 
and ?? zhu? zi2). From Example 1, we can 
see that the search engine cannot distinguish the 
two senses and translate them both as ?. Thus, 
without semantic analysis queries in a search 
engine may result in very poor performance. 
The first principle of a search engine is based 
on shallow Natural Language Processing (NLP) 
techniques, for instance, string matching, while 
future direction of search engines should aim at 
content index and the understanding of user?s 
intention. Semantic computing becomes 
applicable only with the development of deep 
NLP techniques. Machine Translation (MT) is 
the first application of digital computers in the 
non-digital world and semantic information is 
indispensable in MT research and applications. 
However, there has been no breakthrough to the 
extent of Natural Language Understanding 
(NLU) and semantic computing may serve as 
the key to some success in this field.  
2 Related Work on Semantic Computing 
Semantics is an interesting but controversial 
topic. Many a theory has been proposed in 
attempt to describe what meaning really means. 
                                                 
2  Pinyin is currently the most commonly used 
Romanization system for standard Mandarin. The system 
is now used in mainland China, Hong Kong, Macau, parts 
of Taiwan, Malaysia and Singapore to teach Mandarin 
Chinese and internationally to teach Mandarin as a second 
language. It is also often used to spell Chinese names in 
foreign publications and can be used to enter Chinese 
characters on computers and cell phones. 
But up until now there has not been a theory 
that can describe the meaning of various 
language units (words, phrases and sentences) 
so perfectly that was accepted universally, even 
though Fillmore?s proposition of Framework 
semantics (1976) is successful enough. Since 
Gildea et al (2002) initiated the research on 
automatic semantic role labeling, many 
evaluations have been conducted internationally, 
such as Senseval-3 and SemEval 2007, as well 
as CoNLL SRL Shared Task 2004, 2005 and 
2008. Word Sense Disambiguation (WSD) is 
also a very important research subject and a lot 
of work has been done in this regard, such as 
Lesk (1986), Gale et al (1998), Jin et a l. (2007) 
and Qu et al (2007) as the Chinese counterpart. 
As to the research on computing word sense 
relatedness, Dagan et al(1993) did some pilot 
work and Lee (1997) and Resnik (1999) 
contributed to the research on semantic 
similarity.  
In recent years, semantics-based analysis 
such as data and web mining, analysis of social 
networks and semantic system design and 
synthesis have begun to draw more attention 
from researchers. Applications using semantics 
such as search engines and question answering 
(Li et al, 2002), content-based multimedia 
retrieval and editing, natural language interfaces 
(Yokoi et al, 2005) based on semantics have 
also been attracting attentions. Even semantic 
computing has been applied to areas like music 
description, medicine and biology and GIS 
systems and architecture. The whole idea is how 
to realize human-centered computing. 
 
 
3 The Theory and Methodology of 
Semantic Computing 
3.1 Important Questions That Need to Be 
Asked about Semantic Computing 
In the past few years there has been a growing 
interest in the field of semantics and semantic 
computing. But there are questions that have 
been always lingering on researchers? minds. 
What on earth semantics is? What is the best 
way to describe the meaning of a language unit? 
How can natural languages be processed so that 
we are able to benefit from human-computer 
interaction, or even interpersonal 
communication? It seems that no one can give 
satisfactory answers to these questions. But it is 
now commonly agreed that the study of 
semantic computing or knowledge 
representation is a central issue in 
computational linguistics. The major 
contributions on this topic are collected in 
Computational Linguistics (1987-2010) and 
International Journal of Semantic Computing 
(2007-2010). Research in computing semantics 
is, however, rather heterogeneous in scope, 
methods, and results. The traditional ?wh? and 
?how? questions need to be asked again to 
understand the consequences of conceptual and 
linguistic decisions in semantic computing: 
What? What should be computed in terms 
of semantics? Each word is a world and its 
meaning can be interpreted differently. Despite 
the interest that semantics has received from the 
scholars of different disciplines since the early 
history of humanity, a unifying theory of 
meaning does not exist, no matter whether we 
view a language from a lexical or a syntactic 
perspective. In practice, the quality and type of 
the expressed concepts again depend upon the 
one who uses it: any language speaker or writer, 
a linguist, a psychologist, a lexicographer, or a 
computer. In psycholinguistics and 
computational linguistics, semantic knowledge 
is modeled with very deep and formal 
expressions. Often semantic models focus on 
some very specific aspect of language 
communication, according to the scientific 
interest of a researcher. In natural language 
processing, lexical entries or semantic attributes 
typically express linguistic knowledge as 
commonsensically understood and used by 
humans. The entries or attributes are entirely 
formatted in some knowledge representation 
and can be manipulated by a computer.  
Where? What are the sources of semantic 
knowledge? Traditionally, individual 
introspection is often a source of obtaining 
word senses. However, individual introspection 
brings about both theoretical and 
implementation problems. Theoretically, it is 
because ?different researchers with different 
theories would observe different things about 
their internal thoughts...? (Anderson 1989). 
With regard to implementation, it is because 
consistency becomes a major problem when the 
size of the lexicon or the syntactic tree bank 
exceeds a few thousands entries or annotation 
tags. Despite the scientific interest of such 
experiments, they cannot be extensively 
repeated for the purpose of acquiring mass word 
sense definitions. On-line corpora and 
dictionaries are widely available today and 
provide experimental evidence of word uses and 
word definitions. The major advantage of 
on-line resources is that in principle they 
provide the basis for very large experiments, 
even though at present the methods of analysis 
and application are not fully developed and 
need further research to get satisfactory results.  
How? Semantic computing can be realized 
at various levels. The hard work is to implement 
a system in a real domain, or the more 
conceptual task of defining an effective 
mathematical framework to manipulate the 
objects defined within a linguistic model. Quite 
obviously the ?hows? in the literature about 
semantic computing are much more important 
than the ?whats? and ?wheres?. The 
methodology that really works in semantic 
computing is deeply related to the ultimate 
objective of NLP research, which still cannot be 
defined adequately so far.  
3.2 The Perspectives of Semantic Computing 
from a Macro View 
Why semantic computing (or NLU) has posed 
so great a challenge? We may attribute this to 
two major reasons: First, it is based on the 
knowledge of human language mechanism. If 
fully-developed complicated brains are often 
seen as a crowning achievement of biological 
evolution, the interpersonal communication is 
no simpler than human biological mechanism. 
Language has to be a crucial part of the 
evolutionary process, which has not been fully 
understood by scientific research. Second, in 
NLP research the language is both the target and 
the tool. Current NLP research focuses on either 
speech or written texts only. However, in the 
real world scenario, reading and interaction 
between humans are multi-dimensional 
(through different forms of information such as 
text, speech, or images and utilizing our 
different senses such as vision, hearing). It is 
necessary to rely on the advancements of brain 
science, cognitive science and other related 
fields and work in collaboration to produce 
better results. Linguistics, especially 
computational linguistics, has made its own 
contribution, and semantic computing will play 
an important role in NLP. 
There are complex many-to-many relations 
between the form and the meaning of a 
language. Semantic computing is not only the 
way but also the ultimate goal of natural 
language understanding. Although it is hard, we 
should not give up. Here we propose that the 
main contents of semantic computing include 
the following three aspects: 
? semantic computing on the ontological 
perspective 
? semantic computing on the cognitive 
perspective 
? semantic computing on the pragmatic 
perspective 
As for ontologies, much progress has been 
made worldwide. The remarkable achievements 
in English include: WordNet by Princeton 
University, PropBank by University of 
Pennsylvania, etc. Also there are quite a number 
of efforts made on building ontologies in 
Chinese, which will be elaborated in Section 5.  
In the last few years, the main direction of 
semantic computing is to disambiguate 
language units and constructions. In the 
following Example 2, the word ?? y? bi?o 
has two meanings in different contexts. In 
Chinese, word segmentation is also a problem 
that needs to be addressed. In Example 3, 
segmenting the word ??? b?i ti?n ? as ?/
??  or ?? /?  can result in different 
understanding of the sentences. 
 
Example 2 
???????? t? de y? bi?o h?n du?n zhu?ng (She has a graceful appearance.) 
???????? t? de y? bi?o h?n j?ng qu? (Her meters are very accurate.) 
 
Example 3 
????????b?i ti?n ? f?i gu? l?i le (A white swan flies toward us.) 
????????b?i ti?n ? k? y? k?n ji? (A goose can guard our house at daytime.) 
 
As to WSD tasks on the word level, some 
problems can be solved when ontology is 
applied. But ambiguity can also appear on the 
syntactic level. For this, it is usually difficult for 
ontologies to do much, so we may seek help 
from language knowledge bases (See Section 5). 
The following examples of syntactic semantic 
analysis will illustrate how different syntactic 
structures will change the meaning of sentences:  
 
Example 4 
?????????????                    --??????? 
zh? y?ng de di?n y?ng b? sh? l? j? sh? sh?n me?        -- g?i di?n y?ng sh? l? j? 
If a movie as such is not rubbish, what is it?          -- It is rubbish.  
??????????????                  -- ???????? 
zh? y?ng de di?n y?ng z?n me n?ng shu? sh? l? j? ne?   -- g?i di?n y?ng b? sh? l? j? 
How can a movie as such be rubbish?               -- It is not rubbish.  
 
 
Example 5 
?????, ??????               -- ??????? 
m? zh? sh? m? zh? , q? q? sh? q? q?       -- m? zh? b? sh? q? q?  
A grasshopper is a grasshopper, while a cricket is a cricket.  -- A grasshopper is not a cricket. 
Rule?A is A, while B is B.  ???A is not B. 
???, ????d?ng sh? d?ng, m?o sh? m?o  
Ding is ding, while mao is mao.    ? being conscientious 
 
With respect to semantic computing on 
cognitive level, we will use metaphor as an 
example. For a long time, NLP research has 
focused on ambiguity resolution. Can NLU be 
realized after ambiguity resolution? Metaphor, 
insinuation, pun, hyperbole (exaggeration), 
humor, personification, as well as intended 
word usage or sentence composing, pose a great 
challenge to NLU research. If the computer can 
deal with metaphors, it will greatly improve the 
ability of natural language understanding.  
First, let?s discuss the rhetorical function of 
a metaphor. Metaphor is extensively and 
skillfully used in the Chinese classic ?Book of 
Songs? to boost expressiveness.  
 
Example 6 
Simile:   ?????????3???????????         --??????? 
z? b? zh? d?ng ?sh?u r? f?i p?ng ?q? w? g?o m? ? shu? sh? w?i r?ng?-- ?w?i f?ng ?b? x?? 
(Your hair is like disordered grass.)   
Metaphor???????????   --??????? 
t? sh?n zh? sh? ?k? y? g?ng y??      --?xi?o y?? h? m?ng? 
(Rocks from another mountain can be used to carve jade. Metaphorically this phrase means a  
change of method may solve the current problem.) 
 
                                                 
3 For the purpose of conciseness, only the underlined parts that contain metaphors are translated. 
Also, many Chinese idioms are 
metaphorical expressions: ???? t?ng zh?u 
g?ng j? (Literally, to cross the river in the same 
boat; metaphorically, to work together with one 
heart while in difficulty), ???? t?ng qi?ng 
ti? b? (Literally, walls of brass and iron; 
metaphorically, impregnable). The Chinese 
language makes use of lots of idioms or 
idiomatic expressions that are derived from 
ancient Chinese stories and fables. These 
idioms and idiomatic expressions are often used 
metaphorically and reflect historical and 
cultural background of the language. They are 
the most precious relics to the Chinese language 
and culture. Therefore the Chinese Idiom 
Knowledge Base (CIKB) was also built in 2009. 
CIKB consists of 38,117 entries and describes 
many attributes of Chinese idioms. Among the 
attributes, ?literal translation?, ?free translation? 
and ?English equivalent? are very valuable.  
The linguistic function of metaphor is also 
important. Metaphor is the base of new word 
creation and polysemy production (sense 
evolution), for example, ??? l? j? xi?ng 
(recycle) and ?? b?ng d? (virus) are used in a 
computer setting and words like ?? g?o f?ng 
(peak), ?? p?ng j?ng (bottleneck) and ??
xi?n su? (clue) are endowed with new meanings 
which have not been included in traditional 
Chinese dictionaries. Besides, metaphor creates 
new meanings in sentence level, for instance, in 
?????????d? qi? sh? r?n l?i de m? q?n 
(The earth is the mother of humanity.), the word 
?? (mother) has a different meaning. So, 
metaphor understanding is beyond the scope of 
ambiguity resolution. Metaphor, linguistics, and 
human cognitive mechanisms are inextricably 
interlinked. So metaphor becomes a fort that 
must be conquered in NLU research.  
From an NLP perspective, metaphors can 
be summarized into the following categories as 
in Table 1. As for the NLP tasks of metaphor 
computing, we can conclude that there are three 
tasks to be accomplished: First, metaphor 
recognition. For instance, how can we 
distinguish ????? from ?????? 
h?i y?ng z? yu?n k?o ch? (investigation of 
ocean resources); Second, metaphor 
understanding and translation. For instance, ?
???? actually means ????????
??zh? sh? xi?ng h?i y?ng y? y?ng f?ng f? 
(Knowledge is as rich as the ocean.). Third, 
metaphor generation. For instance, how phrases 
such as ?????x?n x? de h?i y?ng (ocean 
of information) and ????? xi?n hu? de 
h?i y?ng (ocean of flowers) can be generated 
successfully by computer? 
  
Perspective of grammatical 
properties 
Perspective of language unites of  
metaphorical expressions 
Nominal ????? z? gu? de hu? du? 
(flower of the country), ??
?? ? sh?ng m?ng de l? 
ch?ng (life journey) 
Word-formation 
level 
?? lu?n sh?(egg-like stone), ???
x?ng r?n y?n (apricot-like eyes) 
Verb ???? x?n ch?o p?ng p?i 
(heart wave ), ???? f?ng 
f?i l? xi?ng (let f dream fly) 
Word level ?? ch?o li? (t ide), ?? zh?o y?ng 
(morning sun) 
Adjective ?????????zh? pi?n  
w?n zh?ng xi? de g?n b?(This 
article is written drily), ??
???????zh? p i?n w?n  
zh?ng q?ng t?ng gu? shu? 
(This article is like plain soup 
and water.) 
Phrase level ????? zh? sh? de h?i y?ng (ocean 
of knowledge), ??????? b? 
zh?ng x?ng f? de zh?ng zi (to sow the 
seeds of happiness) 
Adverb ? ? ? ? ch?n cu? h? 
shu?(absolute nonsense) 
Sentence level ??????q? ch? h? q? y?u (Cars 
drink gasoline.), ???? n? r?n sh? 
shu? (A woman is water.) 
  Discourse level ??????????????????
??????d? q? hu?ng y?ng ?r, m? ji?o 
zh? sh?ng t??t? sh? j?ng qi? m?ng, b? d? 
d?o li?o x? ? (To scare away the 
nightingales for their noise has my dream 
in which I went to the west to meet my 
dear husband.) 
 
Table 1.  Categories of metaphors from NLP perspective. 
 
Currently we focus on recognition and 
understanding of metaphors on phrase and 
sentence level. The automatic processing 
methods of metaphors can be summarized as 
two: First, rule (or logic)-based method, i.e., 
finding the conflicts between the target and the 
source, and search their common properties. 
 
Example 7 
?????????zh? g? r?n sh? y? t?u sh? zi (This man is a lion)   
? only the target and the source 
????????n? g? r?n sh? l?o h? li (That man is an old fox.)   
? only the target and the source 
???????????????????s?n l?n l? j? y?u y?ng m?ng de sh? zi, y? y?u ji?o 
hu? de h? li (In the forest, there are both brave lions and sly foxes.)    
--- find out properties of the sources 
????????????????zh? g? r?n sh? y?ng m?ng de, n? g? r?n sh? ji?o hu? de 
 (This man is brave, while that man is sly.) 
 
The utterance ???????????
h? b?i y?u g? l?o t?i t?i ch? t? ku?i (An old lady 
in Hebei eats clay.) is not in conformity with 
common sense, but it is not a metaphor; 
whereas ???????n?n r?n d?u sh? d?ng 
w? (All men are animals.) is logical but it may 
be a metaphor in certain context and may not be 
in another context.  
Second, empirical (statistical) method i.e., 
providing machine with a large number of 
samples and training a model. Yu Shiwen 
presided over the national 973 project 
?Database for text content understanding? 
(2004-2009), which includes a subtask named 
?Analysis of Metaphorical Expressions and 
Their Pointed Contents in Chinese Texts?. In 
this project, various machine learning methods 
have been applied to do semantic analyses from 
the token level. Among them, Wang Zhimin 
completed her doctoral thesis ?Chinese Noun 
Phrase Metaphor Recognition? in 2006. Jia 
Yuxiang studied verb metaphor recognition and 
?X is Y? type metaphor understanding and 
generation. Qu Weiguang presided over the 
National Natural Science Fund Project 
?Research on Key Technologies in Chinese 
Metaphor Understanding? (2008-2010).  
    From a statistical point of view, metaphor 
recognition can be seen as a problem to 
compute the conditional probability p(m|c) to 
decide whether ?? is a metaphor in context c. 
The reversed order of two variants m and c will 
not change the value of unified probability of 
p(m|c) and p(c|m),while the relation between 
unified probability and conditional probability 
can be written as:  
 
                                  (1)    
 
Then,                                        
                                  (2)                                                
 
Given c?p(c) is a constant. Then, 
 
                                  (3)                                                     
 
Given a threshold? , if             >? , 
then we can deem this ?? is a metaphor.  
Then the problem becomes how to 
compute            . We can compute it 
based on large-scale annotated corpus and get  
 
                            (4)  
 
Nm ? the times of ?? as a metaphor in the 
corpus; 
N  ? the total times of ?? in the corpus. 
 
Then we simplify ?? and its context c 
into: W-k  ? W-1 ?? W1 ? Wi , where W-k, ?, 
W-1, W1,?, Wi represent the n-gram of ?? 
and its syntactic and semantic attributes 
respectively.  
 
                                   (5) 
 
                                    (6) 
 
N(Ws) stands for the times of 
co-occurrence of ?? as a metaphor and word 
W with designated attributes at position. Here 
an important hypothesis of independence is: 
words at different position s is not correlated 
with the word ??. 
Last, we will discuss semantic computing 
on the pragmatic perspective, which is more or 
less unique of Chinese language. First, the 
change of construction in Chinese will affect 
the meaning of a sentence even though the 
words themselves are not changed. The 
emphasized meaning of the construction is not 
equal to the combination of the underlying 
meaning from each element in the construction. 
The meaning reflects the distribution of quantity 
of entities and the relative locations among 
entities. Although the underlying syntactic 
relationship among the main verb, the agent and 
the object(s) still exists, such syntactic 
relationship is only secondary. As in the 
sentence ??????????zh? zh?ng 
chu?ng k? y? shu? s?n g? r?n (This bed can 
sleep three people.) is different in meaning from 
the sentence ??????????(Three 
people can sleep on this bed.). Second, the 
)|()()|()( mcpmpcmpcp ?
)/)|()()|( cpmcpmpcmp ?
)|()()|( mcpmpcmp ?
)|()( mcpmp
NNmp m /)( ?
)|()|()|()|()|( 11 mWpmWpmWpmWpmcp ik ?? ???
),,1,1,,(,/)()|( iksNWNmWp wss ?? ???? ??
)|()( mcpmp
semantic direction of the complement in 
verb-complement constructions and the 
adverbial phrase in verb-adverbial constructions 
also change the semantic roles of each 
constituent. For instance, ????????
? w?n zh?ng ? xi? w?n le ((The article) is 
completed.) or ????????? l?o sh? ? 
xi? l?i le ((The teacher) is tired for writing.) or 
????????????xi?ng p?n p?n d? 
zh? le y? p?n hu? sh?ng m?(aromatically fried a 
plate of peanuts). Here the ontology cannot 
provide enough information to reflect the 
process and result of change in semantic roles. 
Thus the Generalized Valence Mode (GVM) is 
proposed to describe not only participants of the 
action, but also the change of participants? states. 
Third, our ultimate goal will be to achieve 
?semantic harmony?. For instance, in both 
English and Chinese we can say ??? b? ch? 
l?i (pull out) or ??? ch? j?n q? (thrust 
into), but we never say ??? (thrust out) or 
??? (pull into). It is alright to say ???
???????n? g? d? p?n gu? t? d?u ch? le 
(That big apple he eats it all.) , but it is 
awkward to say??????????n? k? 
xi?o h? t?o t? d?u ch? le (That small chestnut he 
eats it all.). In fact we can say ??????
?????n? k? xi?o h? t?o s?ng sh? d?u ch? le 
(That small chestnut the squirrel eats it all.).  
Figure 2. Empirical (statistical) method of metaphor processing. 
 
Professor Lu Jianming (2010) remarked on 
the realization of semantic harmony. The 
principle of semantic constraint of words 
essentially requires that the words in sentences 
should be harmonic in terms of meaning. 
Analysis of ill-formed sentences and automatic 
language generation will benefit from the 
research in semantic harmony. Semantic 
computing on the pragmatic level has unique 
characteristics with respect to Chinese language. 
The solution of these problems poses a great 
challenge and will make great contribution to 
the understanding of the essence and 
universality of languages. 
4 Potential Applications of Semantic 
Computing ? a Case Study on 
Automatic Metaphor Processing in 
Search Engines 
Nowadays, search engines are developing very 
rapidly and some of them have won great 
economic success. In terms of semantic 
computing, Baidu.com takes the lead and has 
unveiled the search concept ?Box computing? 
which introduces semantic analysis. The 
precision and recall of a search engine are 
always the essential issue that a user is 
concerned. Therefore we will find the value of 
semantic computing first in a search engine.  
Certainly, if metaphor can be understood 
properly by a computer, the precision of search 
engines will be improved. Let?s take the phrase 
?? q? f?i(take off) as an example. Literally ?
? means an aircraft takes off such as in ??
???? h?ng b?n q? f?i sh? ji?n (the time for 
the airplane to take off). Sometimes we also use 
it in phrases like ???? j?ng j? q? f?i 
(economic take-off) or ???????? 
d?ng f?ng m?i n? g? t?n q? f?i (Oriental 
beauties take off in the music arena.) to mean 
metaphorically. If the literal sense and its 
metaphorical sense can be distinguished 
successfully, we will find the exact information 
that we need. Meanwhile, we hope that through 
this the recall of search engine will also be 
improved. For example, in Chinese we often 
use the phrase ????? z? gu? de hu? du? 
(flowers of the country) metaphorically to refer 
to ?? ?r tong (children). So web pages 
describing ????? should also be related 
to the query word ??. 
We also observe that the phrases ???? 
j?n r?ng f?ng b?o (financial storm) and ???
?  j?n r?ng h?i xi?o(financial tsunami) 
metaphorically refer to ???? j?n r?ng w?i 
j? (financial crisis). But when we input the 
query ????  into a search engine, the 
results were only web pages with ???? or 
??//??. But when we use the query???
? or????, there were no web pages with 
the results ????. We know that the phrase 
??? ch?o y?u y? has literal usage (to fry 
squids) and metaphorical usage (to fire sb. from 
his/her job). When we input the phrase into the 
search engine, we find the result with 
metaphorical usage takes up 65% while other 
usage only accounts for 35% (Wang, 2006). 
Therefore we may conclude that whether 
metaphor is understood will seriously affect 
precision and recall.  
Another important application lies in 
machine translation and cross-lingual search. 
Correct metaphor recognition and 
understanding is the precondition of correct 
translation. Machine translation can be a 
framework to evaluate the performance of 
metaphor recognition and understanding, and 
also is a tool to realize cross-lingual search. For 
instance, a well-known Chinese female 
volleyball player got a nickname as ??? ti? 
l?ng tou. Shall we translate it literally as ?iron 
hammer? or more metaphorically as ?iron fist? 
in order to let a user of search engine have a 
better sense of what it actually means? 
Translation is culture-bound. When we see the 
sentence ???????g?i di?n y?ng sh? j? l?i, 
how should we translate the word ?? (a 
chicken?s rib) here? And how shall we 
distinguish its literal meaning with its 
metaphorical meaning (?????????sh? 
zh? w? w?i q? zh? k? x?, tasteless to eat but a 
waste to cast away) in order to understand better 
the sentence ?The movie is a chicken?s rib?? 
Therefore when we investigate the 
feasibility analysis of applications of automatic 
metaphor recognition, we propose there are still 
three solutions to the above-mentioned 
problems: 
? To overcome the limitedness of source 
domain words 
? To recognize metaphors in web pages 
and build metaphor indexes. Offline 
processing often makes good use of the 
advantages of a search engine. 
? Before realizing query understanding, 
let users choose metaphorical or literal 
meaning of the query through 
human-computer interaction. 
5 Language Knowledge Bases as the 
Foundation of Semantic Computing 
As the foundation of semantic computing, 
language knowledge bases are in great demand. 
The achievements on language knowledge 
bases for Chinese-centered multilingual 
information processing include: Chinese LDC, 
Comprehensive Language Knowledge Base 
(CLKB) by ICL at Peking University, HowNet 
by Zhendong Dong, Chinese Dependency Tree 
Bank by Harbin Institute of Technology, etc. 
Language knowledge base is an 
indispensable component for NLP system, and 
its quality and scale determines the failure or 
success of the system to a great extent. For the 
past two decades, a number of important 
language knowledge bases have been built 
through the effort of people in Institute of 
Computational Linguistics (ICL) at Peking 
University. Among them, the Grammatical 
Knowledge Base of Contemporary Chinese 
(GKB) (Yu et al, 2000) is the most influential.   
Based on GKB, various research projects 
have been initiated. For instance, a project on 
the quantitative analysis of ?numeral-noun? 
construction of Chinese was conducted by 
Wang (2009) to further analyze the attributes of 
Chinese words. A project aiming at the emotion 
prediction of entries in CIKB was completed by 
Wang (2010) to further understand how the 
compositional elements of a fossilized construct 
like an idiom function from the token level.  
Offset Synset Csyncet Hypernym Hyponym Definition Cdefinition 
07632177 teacher  
instructor  
 
??  
??  
??  
?? 
?? 
??  
???  
??? 
? 
07235322  
 
07086332 
07162304 
07209465 
07243767 
07279659 
07297622 
07341176 
07401098 
? 
a person 
whose 
occupation 
is teaching  
 
?????
???  
 
 
Offset Synset Csyncet Hypernym Hyponym Definition Cdefinition 
07331418  husband 
hubby 
married_
man  
  
 
?? 
??  
??  
??  
??  
??  
??  
??  
???  
? 
07391044  
 
071094820
719596807
255726073
28008  
 
a married 
man;  
a woman's 
partner in 
marriage  
 
?????  
?????
?????  
 
Offset Synset Csyncet Hypernym Hyponym Definition Cdefinition 
07414666  
 
Mister  
Mr.  
 
?? 
??  
??  
??  
??  
??  
07391044  
 
 
 a form of 
address for 
a man 
 
?????
???  
  
 
 
Table 2. The Synset of the word ?? ji?o sh? and its related Synsets. 
 
Following GKB, language knowledge bases 
of large scale, high quality and various type 
(words and texts, syntactic and semantics, 
multi-lingual) have been built, such as the 
Chinese Semantic Dictionary (CSD) for 
Chinese-English machine translation, the 
Chinese Concept Dictionary (CCD) for 
cross-language text processing, the multi-level 
Annotated Corpus of Contemporary Chinese, 
etc. The projects as a whole won the Science 
and Technology Progress Award issued by 
Ministry of Education of China in 2007.  
As mentioned in Section 3, the word ?? 
(virus) has two senses in both English and 
Chinese: one is in biology and the other is in 
computer science. When we want to do 
cross-lingual information retrieval, the two 
senses need to be distinguished. Hence, CCD 
can serve as a useful tool to complete the task 
for it organizes semantic knowledge from a 
different angle. Concepts in CCD are 
represented by Synsets, i.e. sets of synonyms as 
in Table 2. For instance, the concept ?? is in 
a Synset {?? ?? ?? ?? ?? ?? 
??? ??? ?} and all the concepts form 
a network to associate the various semantic 
relations between or among the concepts: 
hypernym-hyponym, part-whole, antonym, 
cause and entailment, by which we can retrieve 
information in either an extensive or a 
contractive way so as to improve the precision 
or recall of a search engine. It can also provide 
support for WSD tasks. 
In 2009, the various knowledge bases built 
by ICL were integrated into the CLKB. The 
integration of heterogeneous knowledge bases 
is realized by a resolution of ?a pivot of word 
sense?. Three basic and important knowledge 
bases, GKB, CSD and CCD have been 
integrated into a unified system which includes 
language processing module, knowledge 
retrieval module and knowledge exploration 
module.  
Although there are some fundamental 
resources on semantic computing, it needs 
further improvement, updating, integration and 
specification to form a collective platform to 
perform more complicated NLP tasks. To 
further improve the result of semantic 
computing, innovative projects for new tasks 
should also be launched, for instance:  
? metaphor knowledge base 
? ultra-ontology dynamic knowledge 
base (generalized valence mode) 
? the integration of information based 
on multi-lingual translation  
6 Concluding Remarks 
Why semantics is so useful in the first place? 
Linguists and psychologists are interested in the 
study of word senses to shed light on important 
aspects of human communication, such as 
concept formation and language use. 
Lexicographers need computational aids to 
analyze in a more compact and extensive way 
word definitions in dictionaries. Computer 
scientists need semantics for the purpose of 
natural language processing and understanding. 
Therefore, the significance of semantic 
computing in NLP is obvious and more research 
needs to be done with this respect. 
All in all, we may conclude that the 
methods of semantic computing can be 
summarized as the following:  
? The research of applicable language 
model    
? The research of effective algorithms   
? To build language knowledge bases as 
its foundation   
Semantic computing is a long-term 
research subject. We hope more progress can be 
made if a clearer view can be provided for the 
direction of its development and the pavement 
for future research can be constructed more 
solidly with more work done.  
Acknowledgements 
Our work is based on the long-term 
accumulation of the language resources that 
have been built by the colleagues of ICL and it 
is their contributions that make our achievement 
possible today. Parts of the content in this paper 
were presented by Shiwen Yu on the 
conferences in Hangzhou (International 
Workshop on Connected Multimedia 2009) and 
Suzhou (the 11th Chinese Lexical Semantics 
Workshop 2010), and many thanks should be 
given to those who offered valuable thoughts 
and advice. The authors also want to extend 
their gratitude toward CIPS-Sighan for this 
valuable opportunity to demonstrate our 
viewpoints and work. 
References 
Anderson, J. R. 1989.  A Theory of the Origins 
of Human Knowledge. Artificial 
Intelligence. 40(1-3): 313-351. 
Carreras, X. and Marques L. 2004. Introduction 
to the CoNLL-2004 Shared Task: Semantic 
Role Labeling. Proceedings of the CoNLL 
2004: 89-97. 
Dagan, I. et al 1993. Contextual Word 
Similarity and Estimation from Sparse 
Data. In Proceedings of the 31st Annual 
Meeting on the Association for 
Computational Linguistics (ACL):164-171 
Fillmore, C. J.. 1976. Frame Semantics and the 
Nature of Language. In Annals of the New 
York Academy of Sciences: Conference on 
the Origin and Development of Language 
and Speech:20-32 
Gale, William A., Kenneth W. Church, and 
David Yarowsky. 1993. A Method for 
Disambiguation Word Senses in a Large 
Corpus. Computers and the Humanities. 
26(5-6): 415-439  
Gildea, Denial and Denial Jurafsky. 2002. 
Automatic Labeling of Semantic Roles. 
Computational Linguistics, 28(3): 
245-288. 
Hasida, K. 2007. Semantic Authoring and 
Semantic Computing. Sakurai, A. et al 
(Eds.): JSAI 2003/2004, LNAI 3609, 
137?149. 
Ide, Nancy and Jean V?ronis. 1998. 
Introduction to the Special Issue on Word 
Sense Disambiguation: The State of the Art, 
Computational Linguistics, 24(1) : 2-40. 
Jin, Peng, Wu Yunfang, Yu Shiwen. 
SemEval-2007 Task 05: Multilingual 
Chinese-English Lexical Sample. In 
Proceedings of SemEval-2007: 19-23. 
Johansson, Richard and Pierre Nugues. 2008. 
Dependency-based Syntactic-semantic 
Analysis with PropBank and NomBank. In 
Proceedings of the Twelfth Conference on 
Computational Natural Language 
Learning: 183-187. 
Lee, Lillian. Similarity-Based Approaches to 
Natural Language Processing. Ph.D. thesis. 
Harvard University. 
Lesk, Michal. 1986. Automatic Sense 
Disambiguation: How to Tell a Pine from 
an Ice Cream Cone. In Proceedings of the 
5th Annual International Conference on 
Systems Documentation: 24-26. 
Li, Sujian, Zhang Jian, Huang Xiong and Bai 
Shuo. 2002. Semantic Computation in 
Chinese Question-Answering System, 
Journal of Computer Science and 
Technology, 17(6) : 993-999. 
Lu, Jianming. 2010. Foundations of Rhetoric -- 
The Law of Semantic Harmony. Rhetoric 
Learning, 2010(1): 13-20. 
Qu, Weiguang, Sui Zhifang, et al 2007. A 
Collocation-based WSD Model: 
RFR-SUM. In Proceedings of the 20 th 
International Conference on Industrial, 
Engineering, and Other Applications of 
Applied Intelligent Systems:23-32. 
Schutze, Hinrich. 1998. Automatic Word Sense 
Discrimination. Computational Linguistics, 
24(1):97-124. 
Resnik, Philip. 1999. Semantic Similarity in a 
Taxonomy: An Information-Based 
Measure and its Application to Problems of 
Ambiguity in Natural Language, Journal 
of Artificial Intelligence Research 11: 
95-130. 
Wang, Lei and Yu Shiwen. Forthcoming 2010. 
Construction of Chinese Idiom Knowledge 
Base and Its Applications. In Proceedings 
of Coling 2010 Multi-word Expressions 
Workshop. 
Wang, Meng et al 2009. Quantitative Research 
on Grammatical Characteristics of Noun in 
Contemporary Chinese. Journal of Chinese 
Information Processing, 22(5): 22-29. 
Wang, Zhiming. 2006. Recent Developments in 
Computational Approach to Metaphor 
Research. Journal of Chinese Information 
Processing, 20(4): 16-24. 
Xue, Nianwen and Martha Palmer. 2005. 
Automatic Semantic Role Labeling for 
Chinese Verbs. In Proceedings of the 19th 
International Joint Conference on 
Artificial Intelligence:1160-1165 
Yu, Shiwen et al. 2003. Introduction to 
Grammatical Knowledge Base of 
Contemporary Chinese (Second Edition) 
(in Chinese), Tsinghua University Press, 
Beijing, China.  
