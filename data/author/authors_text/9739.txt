Proceedings of the IJCNLP-08 Workshop on NLP for Less Privileged Languages, pages 19?26,
Hyderabad, India, January 2008. c?2008 Asian Federation of Natural Language Processing
Prototype Machine Translation System From Text-To-Indian Sign 
Language 
Tirthankar Dasgupta 
IIT, Kharagpur 
tirtha@ 
cse.iitkgp.ernet.in 
Sandipan Dandpat 
IIT, Kharagpur 
sandipan@
cse.iitkgp.ernet.in 
Anupam Basu 
IIT, Kharagpur 
anupambas@ 
gmail.com 
Abstract 
This paper presents a prototype Text-To-
Indian Sign Language (ISL) translation 
system. The system will help dissemination 
of information to the deaf people in India. 
The current system takes English sentence 
as input, performs syntactic analysis, and 
generates the corresponding ISL structure. 
Since ISL does not have any written form, 
the output is represented in terms of pre-
recorded video streams. The system uses 
Lexical Functional Grammar (LFG) for-
malism for representing ISL syntax.   
1 Introduction 
The All India Federation of the deaf estimates 
around 4 million deaf people and more than 10 
million hard of hearing people in India (Zeshan et 
al, 2004). Studies revealed that, one out of every 
five deaf people in the world is from India. More 
than 1 million deaf adults and around 0.5 million 
deaf children in India uses Indian Sign Language 
(henceforth called ISL) as a mode of communica-
tion (Zeshan et al 2004). ISL is not only used by 
the deaf people but also by the hearing parents of 
the deaf children, the hearing children of deaf  
adults and hearing deaf educators (Zeshan et al 
2004).  
Due to their inability in accessing information 
through common broadcast modes like television, 
radio etc., and communication for the deaf com-
munity in common places like railway, bank, and 
hospitals is difficult.  
Efforts to extend the existing means of commu-
nication for the hearing impaired include close cir-
cuit captioning in television and communication 
through interpreter. The first approach assumes a 
good knowledge in written languages like English, 
Hindi, or Bengali. The second approach is not al-
ways practically feasible.  
A large section of the hearing impaired in India 
uses ISL as their mode of communication. How-
ever, due to the inherent difficulty in their written 
texts, an automatic Text-to-ISL translation system 
could help to make more information and services 
accessible to the hearing impaired. Moreover, the 
system will not only improve information access, 
but it can also be used as an educational tool to 
learn ISL.  
Though some work has been done on machine 
translation (MT) from English to American or Brit-
ish Sign Language (SL) (Huenerfauth, 2003), but 
for ISL, MT systems are still in its infancy. The 
underlying architecture for most of the systems are 
based on:  
 
I. Direct translation: This requires knowledge 
of both the source and the target language. 
Moreover, word order of the output may not 
be the desired one.  
II. Statistical MT: It requires large parallel cor-
pora    which is very difficult to collect. 
III. Transfer based architecture. As ISL does not   
relate to other SLs of either Asia or Europe 
(Zeshan, 2003), the existing systems transfer 
grammar rules cannot be applied to translate 
English to ISL.  
 
Further, some of the systems are domain specific 
in nature, and cannot be used to generic systems. 
Hence, most of the above systems remain unusable 
for the deaf community of India. This is the prime 
motivation behind building a generic English Text-
to-ISL translation system. 
The objective of this paper is to present a proto-
type English-to-ISL generic machine translation 
19
system. Currently the system takes simple English 
sentences as input and generates ISL-gloss which 
may then be converted into the Hamburg Notation 
System (HamNoSys)1 (Prillwitz et. al, 1989). The 
HamNoSys representation will provide signing 
instructions to the sign synthesis module, to gener-
ate an animated representation of ISL to the user. 
Lexical Functional grammar (LFG) f-structure is 
used to represent ISL syntax.  
The paper is organized as follows: Section 2 
presents linguistic issues related to ISL. Section 3 
presents a brief summery of the related works. Sec-
tion 4 presents the overall system architecture. Sec-
tion 5 presents system evaluation and results. Sec-
tion 6 presents the sign synthesis via HamNoSys, 
and Section 7 presents conclusion and future work.  
2 ISL Linguistic Issues 
Indian Sign Language (ISL) is a visual-spatial lan-
guage which provides linguistic information using 
hands, arms, face, and head/body postures. A sign 
is a sequential or parallel construction of its man-
ual and non-manual components. A manual com-
ponent can be defined by several parameters like 
hand shape, orientation, position, and movements 
where as non-manual components are defined by 
facial expressions, eye gaze, and head/body pos-
ture (Zeshan, 2003). However, there exist some 
signs which may contain only manual or non-
manual components. For example the sign ?Yes? is 
signed by vertical head nod and it has no manual 
component.  
ISL lexicon is categorized according to the spa-
tial behavior of the signs (Zeshan, 2003). There are 
three open lexical classes: i) Signs whose place of 
articulation are fixed, like, ?hand?, ?teeth?, ?eye?, 
?me?, and ?you? as shown in Fig. 1. ii) Signs 
whose place of articulation can change, like, 
?good,? ?friend,? and ?marry? as shown in Fig. 2. 
iii) Directional signs are those where there is a 
movement between two points in space. For exam-
ple, in the sentence ?I help him? the head word is 
?help? and direction of the sign is from subject ?I? 
to the object ?him? (Fig. 3). Directional signs gen-
erally show verbal property (Zeshan, 2003). Apart 
from the directional signs, ISL morphology is 
mostly derivational in nature and there are no af-
fixes in signs. The closed lexical class contains 
                                                 
1 www.sign-lang.uni-hamburg.de/Projekte/HamNoSys 
classifier hand shapes, discourse markers, and non-
manual signs (Zeshan, 2003). A classifier hand 
shape contains specification related to hand con-
figuration that represents the characteristics of a 
referent. For example, consider the sentence ?Put 
the cup on the table?. Here the hand configuration 
will contain shape of a ?cup? added with a move-
ment to express the event ?put?.  
ISL discourse structure is classified into manual 
and non-manual markers. Manual discourse mark-
ers can occur either in clause final position (as in, 
?it?s over, what else we can do??) or in clause ini-
tial position (like, ?well, I have nothing to say?). 
The non-manual marker like ?head nodding? oc-
curs only in clause final position after the last 
manual sign of the clause.  
 
             
Me Eye 
 
Fig.1: Signs whose place of articulation is fixed 
(Vasistha et. al 1998) 
 
 
 
 
Friend
 
 
 
 
Fig. 2: Signs whose place of ar-
ticulation can change (Vasistha 
et. al 1998)
 
 
Fig. 3:  Directional Sign, ?I help you?. Taken 
from AYJNIHH workbook video CD.  
3 The State-of-Art for Text-to-Sign Lan-
guage 
In spite of the advancements in modern computer 
science technology, there is a paucity of research 
in developing machine translation (MT) system on 
sign language particularly in India (Zeshan et al 
2004). Some of the MT systems for other sign lan-
20
guage are briefly described below. The underlying 
MT architecture can be classified into i) Direct 
translation system, ii) Transfer based architecture 
and iii) Statistical MT. 
The direct translation approach generates the SL 
by direct replacement of the words of input English 
sentence. Generally the word order of the SL re-
mains the same as that of the English text. How-
ever, as in the case of English to ISL, the target SL 
may not allow the same word order. Also, the sys-
tem assumes a strong knowledge of both the Eng-
lish as well as the target SL. 
Some of the direct translation systems include:  
 
? TESSA: A Speech-To-British Sign Language 
(BSL) translation system that aims to provide a 
communication aid between a deaf person and a 
Post Office clerk. The system uses formulaic 
grammar approach where a set of pre-defined 
phrases are stored and translation is done by us-
ing a phrase lookup table. However, the use of 
small set of sentences as templates makes 
TESSA a very domain specific system. It as-
sumes a very restricted discourse between the 
participants (Cox, 2002). 
? The SignSynth project (Grieve- smith 1998; 
Grieve-smith, 1999) uses ASCII-Stokoe model 
for the representation of Signs. The animated 
output is generated by converting ASCII-Stokoe 
into VRML (Virtual Reality Modeling Lan-
guage). In his another project Grieve-Smith pro-
posed a Text to American Sign Language (ASL) 
machine translation system. The system has been 
evaluated in the weather information domain. 
 
In a transfer architecture system, the source lan-
guage representation is transformed into a suitable 
syntactically/semantically correct target language 
form by applying proper transfer grammar rules. 
These rules are dependent upon both the source 
and the target language. However, as the 
source/target language changes new rules are need 
to be added. The transfer grammar approach is not 
only used in text to SL MT systems but also in 
text-to-text MT systems, like the Shakti MT sys-
tem which is used to translate English text to Hindi 
(Bharati et. al., 2001; Bharati et. al., 2003). The 
transfer architecture systems include: 
 
? The ViSiCAST translator, which is a English to 
British Sign Language (BSL) translation tool 
(Marshall & S?f?r, 2001; Bangham et al, 2000). 
The system uses HPSG (Pollard and Sag, 1994) 
formalism to represent source text into BSL and 
the grammar is implemented using a Prolog based 
system ALE. The system handles discourse phe-
nomena by using Discourse Representation Struc-
ture (DRS) (Bos et. al, 1994) and the phonology is 
represented in HamNoSys. This is one of the most 
successful system developed so far (Huenerfauth, 
2003). 
? The ASL workbench (Speers, 2001) is a Text-
To-ASL MT system which uses Lexical Functional 
Grammar (LFG) (Kaplan, 1989) formalism to rep-
resent English f-structure into ASL. The system 
uses a very sophisticated phonological model 
which is based on Movement-Hold principle of 
ASL phonology (Lidell & Johnson 1989). 
? The TEAM project is a Text-To-ASL translation 
system where, the STAG (Synchronous Tree Ad-
joining Grammar) formalism is used to represent 
source text into ASL syntactic structure (Zhao et 
al, 2000). The system maintains a bilingual lexicon 
to identify the valid word-sign pair. The output of 
the linguistic module was a written ASL gloss no-
tation. The manual and non-manual information, 
including the morphological variation, are embed-
ded with in the ASL gloss notation. The output of 
the synthesis module uses animated human models 
(Avatar). 
 
In addition, An Example based MT system for 
English-Dutch sign language was proposed by 
(Morrissey and Way, 2005). Stein et.al. (2006) has 
proposed a statistical MT system which uses Hid-
den Markov Model and IBM models for training 
the data. However, due to paucity of well anno-
tated corpora, the system has been evaluated using 
a very small set of data. 
3.1 Indian Scenario 
INGIT is a Hindi-To-Indian Sign Language (ISL) 
Machine Translation system has been built for the 
railway reservation domain (Kar et. al, 2006). The 
system takes input from the reservation clerk and 
translates into ISL. The output of the system is an 
animated representation of the ISL-gloss strings 
via HamNoSys. INGIT is based on Hybrid-
formulaic grammar approach unlike TESSA which 
uses purely formulaic approach. Here, Fluid Con-
struction Grammar (FCG) (Steels and Beule, 2006) 
21
is used to implement the Formulaic grammar. This 
is the only Hindi text-to-ISL machine translation 
tool encountered by us so far. However, the system 
is domain specific in nature and cannot be used for 
generic purpose. Further, the system does not have 
to handle any structural divergence between the 
source and the target language, as in most of the 
cases both Hindi and ISL show the same word or-
der. 
4 ISL MT Architecture 
In order to overcome the above mentioned prob-
lem, we initially developed a direct translation sys-
tem, however due to its inherent drawbacks, as 
mentioned in section 3, we need some other ap-
proach. One of the most popular techniques is to 
use statistical or case based MT system. However 
ISL does not have any written form, so it is very 
difficult to find any natural source of parallel cor-
pora. Niedle et al (2000) have proposed an ap-
proach to collect corpus for statistical MT research, 
in his approach first, annotation standard for the 
various hand shape movements was developed, 
then the Sign Language performances were re-
corded, and finally the recorded videos were 
manually transcribed. This is a very slow and ex-
pensive process. Due to the difficulty in obtaining 
parallel corpora of ISL, the statistical MT ap-
proaches may not be a feasible solution to our 
problem. Hence we decided to build a rule based 
transfer grammar MT system discussed in this sec-
tion. 
The system architecture of the proposed English 
Text-To-ISL MT system is composed of the fol-
lowing four essential modules (see Fig. 4): 
 
1. Input text preprocessor and parser 
2. LFG f-structure representation 
3. Transfer Grammar Rules 
4. ISL Sentence Generation 
5. ISL  synthesis 
4.1 Text Analysis & Syntactic Parsing 
The current Text-To-ISL translator takes simple 
English sentence as an input to the parser. We de-
fine simple sentence as, a sentence containing only 
one main verb. The input sentence is then parsed 
using the Minipar parser (Lin, 1998) and a depend-
ency structure is constructed from the parse tree. 
However, before parsing, the input text is passed to 
the preprocessing unit, where we try to identify the 
frozen phrases2 and temporal expressions3 which 
the syntactic parser is unable to identify. We pre-
pare a phrase lookup table consisting of 350 frozen 
phrases and temporal expressions which are identi-
fied before the input text is parsed. The parsing 
stage also includes classification of plural nouns. 
The plurality is identified using an English mor-
phological analyzer. 
 
 
 
Fig. 4: Architecture of the Text-to-ISL MT system 
4.2 LFG Representation 
The Minipar generated dependency structure is 
more akin towards the LFG functional structure (f-
structure). The f-structure encodes grammatical 
relation (like subject, object, and tense) of the input 
sentence. It represents the internal structure of a 
sentence. This includes the representation of the 
higher syntactic and functional information of a 
sentence. This higher syntactic and functional in-
formation of a sentence is represented as a set of 
attribute-value pairs. In an attribute-value pair, the 
attribute corresponds to the name of a grammatical 
symbol (e.g. NUM, TENSE) or a syntactic function 
(e.g. SUBJ, OBJ) and the value is the corresponding 
feature possessed by the concerning constituent. 
For example, Fig. 5 shows the attribute-value pair 
for the sentence ?John Played Cricket?. The main 
advantage of f-structure is in its abstract represen-
tation of syntactic and grammatical information of 
a sentence. 
 
                                                 
2 Phrases that are composed of Idioms, and Metaphor 
3 Temporal Expressions contains Time, Day and Date. 
22
 
 
 
 
 
 
 
 
 F
4.3 ISL Generation 
In the generation stage, English f-structure is con-
verted to ISL f-structure by applying proper trans-
fer grammar rules. Two main operations are per-
formed during the generation phase: a) Lexical 
selection and b) Word order correspondence. 
Lexical selection is done using an English-ISL bi-
lingual lexicon. For example word like ?Dinner? in 
English is replaced by ?NIGHT FOOD? in ISL and 
?Mumbai? is replaced by the sign of ?BOMBAY?. 
 
(1) English: ?I had dinner with Sita? 
      ISL: ?I SITA WITH NIGHT FOOD FINISH? 
 
ISL has essentially a Subject-Object-Verb word 
order (unlike English which is Subject-Verb-
Object). For Example, (2) shows the change in 
word order from English to ISL.  
 
(2)  English: ?I have a computer? 
 ISL: ?I COMPUTER HAVE?. 
 
However, in some cases the sign sentence de-
pends upon the directionality of the verb as in (3). 
 
(3) English: ?I help you? 
 ISL: ?HELP + < hand movement from I-
            to-YOU>?. 
 
For sentences having only a subject and a verb, 
the subject always precedes the verb. Like: 
 
(4) English: ?The woman is deaf? 
 ISL:  ?WOMAN DEAF?. 
 
However, if the sentence contains a dummy sub-
ject (5), then the subject is removed from the out-
put. 
 
 (5) English: ?It is raining outside? 
 ISL: ?OUTSIDE RAINING? 
For negative sentences, a negation mark is used 
after the verb (6). The second bracket indicates a 
parallel non-manual component is attached with 
the sign ?LATE?.  
 
 (6) English: ?I am not late?  
 ISL: ?I {LATE + NOT}?. 
 
ig. 5: Attribute-Value pair for the sentence ISL has separate rules to handle adjectives oc-
curring before a noun. In most of the cases an ad-
jective must occur after the noun. However, if the 
adjective specifies a color then it should precede 
the noun (see (7) & (8)).  
?John Played Cricket? 
 
(7) English: ?The beautiful girl is playing?  
 ISL: ?GIRL BEAUTIFUL PLAY?  
 
(8) English: ?I see a black cat?  
 ISL: ?I BLACK CAT SEE?. 
 
WH-Interrogative markers (like who, what, 
when, and why) always occur at the end of the sen-
tence.  
 
 (9) English: ?When is your birthday?? 
 ISL: ?YOUR BIRTHDAY TIME+  
            QUESTION?. 
 
In case of yes/no type of questions, the sentence 
is followed by a non-manual yes-no marker 
(Zeshan, 2004). 
 
(10) English: ?Is the man deaf?? 
 ISL: ?MAN {DEAF} yes-no? 
 
Since ISL does not have any articles or conjunc-
tions, they are removed from the generated output 
as shown in example (2)-(10). 
5 System Evaluation  
Evaluating a Text-to-ISL MT system is difficult 
due to the absence of ISL written orthography. 
Hence, standard techniques for evaluating Text-
Text MT systems are not applicable for Text-to-
ISL systems. However, we have evaluated the sys-
tem based on the feedbacks of the ISL experts. The 
generated outputs of the system are shown to the 
ISL experts and are classified as either valid or 
invalid according to their understandability and 
quality. The system was evaluated on a set of 208 
23
sentences4. Table 1.1 summarizes the performance 
of the system. The overall system performance is 
around 90%. Most of the errors are due to com-
pound sentences and directional verbs5. To under-
stand the relative performance of the system on the 
simple sentences, we conducted two experiments 
removing compound construction and directional 
verbs. From the current experimental set up, 7% 
errors are propagated due to directional verbs and 
around 4% errors are due to compound construc-
tions.  
 
 No. of Sentences 
Accuracy 
(%) 
Overall Corpus size 208 89.4 
Sentences without di-
rectional verbs 193 96.37 
Sentences without 
compound construc-
tions 
201 92.53 
 
6 ISL Synthesis 
The ISL sentences thus generated are displayed via 
a stream of pre recorded videos or icons. However, 
it has been observed that the current approach of 
ISL synthesis is highly criticized (Grieve-Smith, 
1999). As, representing ISL signs by pre-recorded 
video will result in loss of information related to 
discourse, classifier predicate, and directionality of 
sign. Also, storing sign video takes a lot of mem-
ory overhead. To overcome this crisis further de-
velopments are in progress. We represent ISL signs 
by HamNoSys and the generated HamNoSys string 
will be passed to the signing avatar.  
6.1 HamNoSys 
Sign language does not have any written form. In 
order to define a sign we need a notation system. 
The Hamburg sign language Notation system 
(HamNoSys) is a phonetic transcription system 
used to transcribe signing gestures. It is a syntactic 
representation of a sign to facilitate computer 
processing. HamNoSys is composed of several 
parameters by which a signing gesture can be de-
fined like: 
                                                 
4  Corpus collected from ??A? level Introductory course in 
Indian Sign Language? Work Book AYJNIHH. 
5 Verbs corresponding to directional signs.
 
? Dominant hand?s shape. 
? Hand location with respect to the body. 
? Extended finger orientation. 
? Palm orientation 
? Movements (straight, circular or curved) 
? Non-manual signs. 
 
Fig. 9 shows an example where HamNoSys 
representation of the word ?WOMAN? is ex-
plained.  
 
 
 
 
 
 
In this example, the parameters like movement 
and non-manual signs are not present, as the sign 
?WOMAN? in ISL does not have these expres-
sions. Fig. 10 shows the ISL representation of 
?WOMAN?. 
 
 
 
 
7 Conclusion and Future works 
The paper presents a prototype text to ISL transla-
tion system. Our approach uses LFG f-structure to 
represent ISL syntax. As ISL does not have any 
written form, there is no standard source of ISL 
corpus. Hence, statistical MT methods are not fea-
sible under such a condition. Our system is still 
under development stage. The sign synthesis mod-
ule using an animated avatar has not been devel-
oped yet. We generate ISL output using pre-
recorded ISL videos. Further morphological func-
tionalities like, discourse, directionality, and classi-
fier predicates are handled minimally 
Table1.1: Evaluation Results 
Fig. 9: HamNoSys representation of ?WOMAN? 
Fig. 10: Sign of  ?WOMAN? 
(Vashista et.al, 1998) 
Extended Finger orientation
Handshape
Location
Palm
?? \  ???  
24
In the next stage of our work, we will try to 
handle directional sign, discourse, and classifiers. 
The sign representation should be done using an 
animated avatar via HamNoSys notation. We will 
also develop the sign annotation tool and finally, a 
larger corpus will be built for a better evaluation 
and results. 
References 
N. Badler, R. Bindiganavale, J. Allbeck, W. Schuler, L. 
Zhao, S. Lee, H. Shin, and M. Palmer 2000. Param-
eterized Action Representation and Natural Language 
Instructions for Dynamic Behavior Modification of 
Embodied Agents. AAAI Spring Symposium.  
J. A. Bangham, S. J. Cox, R. Elliot, J. R. W. Glauert, I. 
Marshall, S. Rankov, and M. Wells. 2000. Virtual 
signing: Capture, animation, storage and transmission 
? An overview of the ViSiCAST project. IEEE Semi-
nar on Speech and language processing for disabled 
and elderly people. 
A. Bharati, D. M. Sharma, R. Sangal. 2001. AnnCorra : 
An Introduction, Technical Report no: TR-LTRC-
014, LTRC, IIIT Hyderabad, Mar 2001, 
http://www.iiit.net/ltrc/ Publications/Techreports/TR-
LTRC-14 
A. Bharati, R. Moona, P. Reddy, B. Sankar, D.M. 
Sharma, R. Sangal, Machine Translation: The Shakti 
Approach, Pre-Conference Tutorial at ICON-2003. 
J. Bos, E. Mastenbroek, S. McGlashan, S. Millies, M. 
Pinkal. 1994. A Compositional DRS-based Formal-
ism for NLP Applications. Report 59. Universitaet 
des Saarlandes.  
S. Cox, M. Lincoln, J. Tryggvason, M. Nakisa, M . 
Wells, M. Tutt, S. Abbott. 2002. Tessa, a system to 
aid communication with deaf people. Fifth interna-
tional ACM conference on Assistive technologies. 
M. Huenerfauth. 2003. A Survey and Critique of 
American Sign Language Natural Language Genera-
tion and Machine Translation Systems. Technical Re-
port MS-CIS-03-32, Computer and Information Sci-
ence, University of Pennsylvania. 
A. Joshi, L. Levy and M. Takahashi. 1975. Tree Ad-
junct Grammar. Journal of computer and system sci-
ences. 
P. Kar, M. Reddy, A. Mukherjee, A. M. Raina. 2007. 
INGIT: Limited Domain Formulaic Translation from 
Hindi Strings to Indian Sign Language. ICON. 
Ronald M. Kaplan. 1989. The formal architecture of 
lexical-functional grammar. Journal of Information-
Science and Engineering 5: 305-322.  
Scott Liddell and R. E. Johnson. 1989. American Sign 
Language: The phonological base. Sign Language 
Studies 64: 195-277. 
D. Lin. 1998. Dependency-based evaluation of MINI-
PAR. In Workshop on the Evaluation of Parsing Sys-
tems, Granada, Spain,  
I. Marshall and ?. S?f?r. 2001. Extraction of semantic 
representations from syntactic SMU link grammar 
linkages.. In G. Angelova, editor, Proceedings of Re-
cent Advances in Natural Lanugage Processing, pp: 
154-159, Tzigov Chark, Bulgaria, September. 
S. Morrissey and A. Way. 2005. An Example-Based 
Approach to Translating Sign Language. In Proceed-
ings of Workshop Example-Based Machine Transla-
tion (MT X -05), Phuket, Thailand. 
C. Neidle, J. Kegl, D. MacLaughlin, B. Bahan, and R. 
G. Lee. 2000. The Syntax of American Sign Lan-
guage: Functional Categories and Hierarchical 
Structure. Cambridge, MA: The MIT Press. 
C. J. Pollard, and I. A. Sag. 1994. Head-driven Phrase 
Structure Grammar. University of Chicago Press, 
Chicago, IL. 
S. Prillwitz, R. Leven, H. Zienert, T. Hamke, and J. 
Henning. 1989. HamNoSys Version 2.0: Hamburg 
Notation System for Sign Languages: An Introduc-
tory Guide, volume 5 of International Studies on Sign 
Language and Communication of the Deaf. Signum 
Press, Hamburg, Germany,  
?. S?f?r and I. Marshall. 2001. .The architecture of an 
English-text-to-Sign-Languages translation system.. 
In G. Angelova, editor, Recent Advances in Natural 
Language Processing (RANLP), pp: 223-228. Tzigov 
Chark, Bulgaria. 
G. Angus Smith. 1998. Sign synthesis and sign phonol-
ogy. Proceedings of the First High Desert  Student 
Conference in Linguistics. 
G. Angus Smith. 1999. English to American Sign Lan-
guage machine translation of weather reports. Pro-
ceedings of the Second High Desert Student Confer-
ence in Linguistics. 
A. Speers. 1995. SL-Corpus: A computer tool for sign 
language corpora. Georgetown University.  
A. Speers. 2001. Representation of American Sign Lan-
guage for Machine Translation. PhD Dissertation, 
Department of Linguistics, Georgetown University. 
L. Steels and J. Beule. 2006, Unify and Merge in Fluid 
Construction Grammar, In: Lyon C., Nehaniv, L. & 
A. Cangelosi, Emergence and Evolution of Linguistic 
Communication, Lecture Notes in Computer Science. 
Springe-Verlag: Berlin,. 
25
D. Stein, J. Bungeroth and H. Ney. 2006. Morpho-
Syntax Based Statistical Methods for Sign Language 
Translation. In Proceedings of the 11th Annual 
conference of the European Association for Machine 
Translation. Oslo, Norway. 
M. Vasishta, J. Woodward and S. DeSantis. 1998. An 
Introduction to Indian Sign Language. All India Fed-
eration of the Deaf  (Third Edition). 
Elizabeth Winston. 1993. Spatial mapping in compara-
tive discourse frames in an American Sign Language 
lecture. Doctor of Philosophy in Linguistics diss., 
Georgetown University. 
L. Zhao, K. Kipper, W. Schuler, C. Vogler, N. Badler, 
and M. Palmer. 2000. A Machine Translation System 
from English to American Sign Language. Associa-
tion for Machine Translation in the Americas. 
U. Zeshan. 2003. Indo-Pakistani Sign Language Gram-
mar: A Typological Outline. Sign Language Studies - 
Volume 3, Number 2 , pp. 157-212. 
U. Zeshan. 2004. Interrogative Constructions in Signed 
Languages. Crosslinguistic Perspectives Language - 
Volume 80, Number 1, pp. 7-39. 
U. Zeshan, M. Vasishta, M. Sethna. 2004. Implementa-
tion of Indian sign language in educational settings- 
Volume 15, Number 2, Asia Pacific Disability Reha-
bilitation Journal, pp. 15-35 
26
A Multilingual Multimedia Indian Sign Language Dictionary Tool 
Tirthankar 
Dasgupta 
IIT, Kharagpur 
tirtha@iitkgp
.ernet.in 
Sambit 
Shukla 
NIT, Rourkela 
sks.at.nit
r@gmail.co
m 
Sandeep 
Kumar 
NIT, Allahabad. 
mnnit.sand
eep@gmail.
com 
Synny Diwakar 
NIT, Suratkal 
sunny.diwaka
rnitk@gmail.
com 
Anupam Basu 
IIT, Kharagpur 
Anupam-
bas@gmail.
com 
 
Abstract 
This paper presents a cross platform multi-
lingual multimedia Indian Sign Language 
(ISL) dictionary building tool. ISL is a lin-
guistically under-investigated language 
with no source of well documented elec-
tronic data. Research on ISL linguistics 
also gets hindered due to a lack of ISL 
knowledge and the unavailability of any 
educational tools. Our system can be used 
to associate signs corresponding to a given 
text. The current system also facilitates the 
phonological annotation of Indian signs in 
the form of HamNoSys structure. The gen-
erated HamNoSys string can be given as 
input to an avatar module to produce an 
animated sign representation.  
1 Introduction 
A sign language is a visual-gesture language that 
uses hand, arm, body, and face to convey thoughts 
and meanings. It is a language that is commonly 
developed in deaf communities, which includes 
deaf people, their friends and families as well as 
people who are hard of hearing. Despite common 
misconceptions, sign languages are complete natu-
ral languages, with their own syntax and grammar. 
However, sign languages are not universal. As is 
the case in spoken language, every country has got 
its own sign language with high degree of gram-
matical variations.  
 The sign language used in India is com-
monly known as Indian Sign Language (hence-
forth called ISL). However, it has been argued that 
possibly the same SL is used in Nepal, Sri Lanka, 
Bangladesh, and border regions of Pakistan 
(Zeshan et al, 2004). Different dialects of ISL 
with broad lexical variation are found in different 
parts of the Indian subcontinent. However, the 
grammatical structure is same for all dialects 
(Zeshan, 2003).  
The All India Federation of the Deaf estimates 
around 4 million deaf people and more than 10 
million hard of hearing people in India (Zeshan et 
al, 2004). Studies revealed that, one out of every 
five deaf people in the world are from India. More 
than 1 million deaf adults and around 0.5 million 
deaf children uses Indian Sign Language as a 
mode of communication (Zeshan et al 2004). 
However, an UNESCO report (1980) found that 
only 5% of the deaf get any education in India. 
The reason behind such a low literacy rate can be 
due to the following reasons: a) Till the early 20th 
century, deafness in India, is considered as a pun-
ishment for sins and signing is strictly discouraged 
(Zeshan et. al, 2004). b) Until the late 1970?s, it 
has been believed that, there were no such lan-
guage called ISL. c) Lack of research in ISL lin-
guistics. d) Unavailability of well documented and 
annotated ISL lexicon. e) Unavailability of any 
ISL learning tool. f) Difficulties in getting sign 
language interpreters. 
 Linguistic studies on ISL were started 
around 1978 and it has been found that ISL is a 
complete natural language, instigated in India, 
having its own morphology, phonology, syntax, 
and grammar (Vasishta et. al, 1978; Zeshan et.al, 
2004). The research on ISL linguistics and phono-
logical studies get hindered due to lack of linguis-
tically annotated and well documented ISL data. A 
dictionary of around 1000 signs in four different 
regional varieties was released (Vasishta et.al, 
The 6th Workshop on Asian Languae Resources, 2008
57
1978). However, these signs are based on graphi-
cal icons which are not only difficult to understand 
but also lack phonological features like move-
ments and non-manual expressions.  
As it has been specified above,  ISL is not only 
used by the deaf people but also by the hearing 
parents of the deaf children, the hearing children 
of deaf  adults and hearing deaf educators (Zeshan 
et al 2004). Therefore the need to build a system 
that can associate signs to the words of spoken 
language, and which can further be used to learn 
ISL, is significant. Further associating signs of 
different SL (like ASL1 , BSL2 and ISL) to a word 
will help the user to learn foreign SLs simultane-
ously. 
 Several works have been done on building 
multimedia-based foreign SL dictionaries as dis-
cussed in (Buttussi et. al., 2007). However no such 
system is currently available for ISL. moreover, 
most of the current systems suffer from the follow-
ing limitations:  
? Most of the systems are native language specific 
and hence, cannot be used for ISL.  
? Most of the systems provide a word-sign search 
but very few systems provide a sign-word or 
sign-sign search. 
? Very few systems are cross platform. 
? Systems lack sophisticated phonological infor-
mation like hand-shape, orientations, move-
ments, and non-manual signs.  
In order to overcome the above mentioned crisis, 
and based on the limitations of the current sys-
tems, our objective is to: 
? Build a cross platform multilingual multimedia 
SL-Dictionary tool which can be used to create a 
large SL lexicon.  
? This tool can be used to associate signs to the 
words, phrases, or sentences of a spoken lan-
guage text.  
? The sign associated with each word is composed 
of its related part-of-speech and semantic senses.  
? The input text (word, phrase, or a sentence) may 
be in any language (like English or Hindi) and 
the associated sign can be in any standard sign 
language (ASL or ISL).  
? This tool can also be used to associate complex 
SL phonological features like hand shape, palm 
                                                 
                                                
1 ASL: American Sign Language. 
2 BSL: British Sign Language. 
orientation, locations, movements, and non-
manual expressions.  
? The phonological features are expressed in terms 
of HamNoSys (Prillwitz et. al, 1989). 
? Facilitate search options like word-sign and 
search by HamNoSys. 
? The generated lexicon is exported in XML file 
format and the sign is stored in the form of digi-
tal videos.  
? The video segments are captured using webcams 
connected with the system. It is possible to at-
tach multiple webcams to the system to capture 
video segments from multiple angles. This fea-
ture enables a user to better understand some of 
the complex sign language attributes. 
 
The organization of the paper is as follows: Sec-
tion 2 gives a brief introduction to ISL phonology. 
Section 3 presents related works on ISL Diction-
ary. Section 4 presents the overall system architec-
ture of the SL-dictionary tool. Section 5 and 6 pre-
sents a brief discussion related HamNoSys repre-
sentation, and the HamNoSys editor. Section 7 
presents conclusion and future work. 
2 ISL Phonology 
Indian Sign Language (ISL) is a visual-spatial lan-
guage which provides linguistic information using 
hands, arms, face, and head/body postures. The 
signer often uses the 3D space around his body to 
describe an event (Zeshan, 2003). Unlike spoken 
languages where the communication medium is 
dependent on sound, in sign language, the com-
munication medium depends upon the visual 
channel. In spoken language, a word is composed 
of phonemes. Two words can be distinguished by 
at least one phoneme. In SL, a sign is composed of 
cheremes3 and similarly two signs can differ by at 
least one chereme (Stokoe, 1978). A sign is a se-
quential or parallel construction of its manual and 
non-manual cheremes. A manual chereme can be 
defined by several parameters like: 
? Hand shape. 
? Hand location 
? Orientation. 
? Movements (straight, circular or curved) 
 
3 The term chereme (originally proposed by William 
Stokoe (Stokoe, 1978)) in Greek means ?hand?. It is 
equivalent to the phonemes of spoken languages.   
The 6th Workshop on Asian Languae Resources, 2008
58
Non-manual cheremes are defined by: 
? Facial expressions. 
? Eye gaze and Head/body posture (Zeshan, 
2003). 
However, there exist some signs which may con-
tain only manual or non-manual components. For 
example the sign ?Yes? is signed by vertical head 
nod and it has no manual component. 
ISL signs can be generally classified into three 
classes: One handed, two handed, and non-manual 
signs. Fig. 1 shows the overall Indian sign hierar-
chy. 
 
Fig. 1: ISL Type Hierarchy 
 
One handed signs: the one handed signs are repre-
sented by a single dominating hand. One handed 
signs can be either static or movement related. 
Each of the static and movement signs is further 
classified into manual and non-manual signs. Fig. 
2 shows examples of one handed static signs with 
non-manual and manual components.  
                 
Fig. 2: One Handed static manual sign (Ear) and 
non-manual sign (Headache).   
      
Two hand signs: As in the case of one hand signs, 
similar classification can be applied to two handed 
signs. However, two handed signs with move-
ments can be further distinguished as:  
Type0: Signs where both hands are active (see Fig 
3). 
Type1: Signs where one hand (dominant) is more 
active compared to the other hand (non-dominant) 
as shown in Fig 3. 
 
           
Flag 
Long 
Fig.3 : Two handed sign "long"(both the hands are 
moving) and ?Flag? (only the dominant right hand 
is moving) 
3 Related works on ISL dictionary 
Linguistic studies on ISL are in their infancy as 
compared to other natural languages like English, 
Hindi, or Bengali and also to other SLs. Linguistic 
work on ISL began during late 1970?s. Before that, 
the existence of ISL was not acknowledged. In 
1977 a survey was conducted (see Vasistha et. al., 
1998 for documentation) and it was revealed that 
ISL is a complete natural language instigated at 
the Indian subcontinent. Vasistha collected signs 
from four major states of India (Delhi, Mumbai, 
Kolkata, and Bangalore) and released four diction-
aries of ISL regional varieties. The Ramkrishna 
Mission vidyalaya, Coimbatore has published an-
other ISL dictionary in 2001. However, all these 
dictionaries are based on iconic representations of 
signs. As a result some of the important phono-
logical information like, movements and non-
manual expression gets lost. No other work of its 
kind has so far been reported (Zeshan, 2004).  
 Several works have been done in building 
ASL and BSL dictionary tools. Some of the sys-
tems are briefly discussed below: 
Headache Ear 
? (Wilcox et. al, 1994) developed a multimedia 
ASL dictionary tool, which prerecorded digital 
video frames. 
? (Geitz et.al, 1996) developed a VRML based 
ASL finger spelled system, which ran on inter-
net. 
? Sign Smith (VCOM3D, 2004) is a 3D illustrated 
dictionary of ASL. It is also used as educational 
software as well as an authoring tool to create 
ASL content.  
? (Buttussi et. al, 2007) proposes an Italian Sign 
Language dictionary tool. This tool uses H-
animator to generate signing avatar. This tool 
provides multiple search functionality like word-
sign, sign-word, and sign-sign search. This tool 
also facilitates association of one or more SL for 
a given input word.     
The 6th Workshop on Asian Languae Resources, 2008
59
4 SL-Dictionary 
The primary objective of the SL-dictionary tool is 
to provide an easy to use GUI to create a multilin-
gual multimedia SL dictionary by which a user can 
associate signs as well as the parameters defining a 
sign, corresponding to a given text. The overall 
architecture of the system is shown in Fig. 4. The 
system has been divided into two modules: a) Ex-
pert module and b) User Module.  
 The expert module has got three main 
units: a) Input Text Processing Unit b) Visual Data 
Capture Unit (VDCU) c) Sign Storage Unit and d) 
HamNoSys Editor.  
Input Text Processing Unit: In this unit a SL ex-
pert chooses the input spoken language (like, Eng-
lish, or Hindi) and the target sign language (like, 
ISL, or ASL) and then enters a text. The input to 
the system may be word, phrase, or sentences. If 
the text is a word the system generates all possible 
meanings, with the help of WordNet4, along with 
the part of speech (POS)5 of that particular word. 
In order to get the exact part-of-speech of a word, 
the SL expert has to enter an example sentence 
corresponding to that word. This sentence is given 
as an input to the POS-tagger to get the correct 
POS of the word. A word may have multiple 
senses as returned by WordNet. The user can se-
lect one or more senses from the list. 
Visual Data Capture Unit: Sign corresponding to a 
word sense is signed by the user which is captured 
by the Visual Data Capture Unit (VDCU). The 
VDCU is connected through multiple webcams, 
placed at different angular positions with respect 
to the signer. As a result different articulation 
points of a signs are getting stored with in the da-
tabase. This will enable the SL learner to under-
stand a particular sign easily. Fig.5 shows how a 
sign from multiple angles is getting captured. 
Storage Unit: The input text along with its anno-
tated information, the digital video sign, and the 
phonological parameters defining the sign are 
stored with in a database which is further exported 
into an XML formatted file (see Fig. 6). The pho-
nological parameters are expressed in the form of 
HamNoSys (discussed in section 5). 
                                                 
4 wordnet.princeton.edu/ 
5 We have used the Stanford Part-of-Speech tagger 
(nlp.stanford.edu/software/tagger.shtml) 
 
Fig. 4: System Architecture of ISL-Dictionary 
 
 
 
 
 
 
 
 
 
 
 
 
Fig.5: capturing video signs from multiple angle 
 
 
Fig.6: The ISL-dictionary XML Format 
 
Searching: The search engine of the current sys-
tem takes a spoken language text as input parses 
the XML formatted dictionary and sequentially 
searches the dictionary. If a match is found, then 
The 6th Workshop on Asian Languae Resources, 2008
60
the sign corresponding to the lexical entry is being 
displayed. 
5 Sign language notation systems 
As it has been mentioned above, Sign language 
does not have any written form. Hence, In order to 
define a sign we need some notation system. There 
are a number of phonological notation systems for 
the representation of SL as discussed in (Smith 
et.al, 2003). One of the popular among them is 
Stokoe notation (Stokoe, 2003; Smith et.al, 2003). 
Stokoe defines a sign by three parameters: a) 
Hand-shape or designator (dez) b) location or 
place of articulation with respect to the body (tab) 
and c) movements or signation (sig). 
 HamNoSys (Prillwitz et. al, 1989) is a 
phonetic transcription system, based on Stokoe 
notation, used to transcribe signing gestures. It is a 
syntactic representation of a sign to facilitate com-
puter processing. HamNoSys extends the tradi-
tional Stokoe based notation system by further 
expanding sign representation by some more pa-
rameters. These parameters can be defined as: 
? Dominant hand?s shape. 
? Location of the dominant and the non-dominant 
hand with respect to the body. 
? Extended finger orientation of both dominant 
and non-dominant hand. 
? Palm orientation of both hands. 
? Movements (straight, circular, or curved) 
? Non-manual signs. 
Fig. 7 shows examples of different HamNoSys 
symbols and their descriptions. 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
Fig. 8 shows an example where HamNoSys repre-
sentation of the word ?WOMAN? is explained. 
Here, the parameters like movement and non-
manual signs are not present, as the sign 
?WOMAN? in ISL does not have these expres-
sions. Fig.9 shows the ISL representation of 
?WOMAN?.  
 
 
             
 
 
 
 
Fig. 8: HamNoSys representation of ?WOMAN? 
                            
 
 
 
  
           
6 HamNoSys Editor 
Transcribing a sign by HamNoSys is not a trivial 
task. A user who is transcribing a sign should be 
an expert in both HamNoSys as well as ISL. 
Moreover he has to remember all the HamNoSys 
symbols and their corresponding meanings in or-
der to define a sign. In India it is very difficult to 
find such a person. Hence our main goal behind 
building a HamNoSys editor is that, it can be used 
by an ISL expert with little or no knowledge in 
HamNoSys. The tool should provide an easy to 
use GUI that can be used to transcribe 
phonological information of a sign. 
 The HamNoSys editor provides a set of 
graphical images (most of the images are collected 
from www.sign-lang.uni-amburg.de/Projekte/ 
HamNoSys) for most of the phonological parame-
ters of a sign, like, Hand-shape, orientation, loca-
tion and movements. Based on the parameters, an 
ISL expert can choose a set of images and the sys-
tem will automatically generate the corresponding 
HamNoSys of the sign. This HamNoSys string can 
be given as an input to a signing avatar module to 
generate animated sign representation. 
 A signing avatar is a virtual human char-
acter that performs sign language. However, this 
character needs a set of instructions which will 
guide its movement. These instructions can be 
provided in the form of HamNoSys (Marshall and 
S?f?r, 2001). 
Fig.7: HamNoSys symbols and there descriptions
Palm 
Extended Finger orientation 
?? \  ???  H   f  v?? 
Handshape 
Location 
Fig.9: Sign of ?WOMAN? 
The 6th Workshop on Asian Languae Resources, 2008
61
   
 
Fig, 11: Twelve basic hand-shape classes 
 
Fig.10: HamNoSys Parameters
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig.12: GUI to express finger and palm orientations 
Fig.13: GUI to choose various hand locations     
near the human face 
The 6th Workshop on Asian Languae Resources, 2008
62
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig 14: GUI showing various straight movement parameters
 
Fig.10 shows the five basic parameters of Ham-
NoSys. For each of these parameters there exist 
interfaces through which a SL expert can choose 
the desired parameters to define a sign. For exam-
ple, the right hand side of Fig.11 shows the twelve 
basic hand-shape classes. Each of these base hand-
shapes may contain several derived hand-shapes as 
defined in HamNoSys (version 4.0). If a particular 
hand-shape is selected, then the HamNoSys sym-
bol corresponding to the hand-shape gets stored in 
the XML database (see Fig.6). Similarly, separate 
interfaces have been provided to identify palm 
orientation (see Fig,12), hand location (see 
Fig.13), movements (see Fig.14), and non-manual 
signs.   
 Due to its symbolic structure, HamNoSys 
is fairly easy to write, and understand. However, 
there are some drawbacks on this notation system 
that make it difficult to be used universally for all 
sign languages (Smith and Edmondson, 2004). For 
example, HamNoSys uses some fixed set of sym-
bols to define a sign however it is possible that a 
particular sign in any sign language may not be 
defined by 'the fixed set of symbols. For example 
HamNoSys does not have well defined symbols 
for non-manual expressions. Consider the sign 
?BITTER?, in ISL the representation is shown in 
Fig.15. It can be observed that it is very difficult to 
represent the facial expressions like eyebrow by 
HamNoSys. Currently we have a collection of 
around 979 sign icons (published by Vasistha et. al 
1998), which we are trying to transcribe in Ham-
NoSys. Out of these, 16% of the signs contain 
non-manual features which we are unable to repre-
sent in HamNoSys.  
 
  
Fig.15: ISL representation of 
"BITTER" 
 
7 Conclusion and Future works 
The paper presents an approach towards building a 
multimedia SL dictionary tool. This tool can be 
used to prepare a well documented ISL dictionary. 
The system is intended to take any Indian lan-
guage text as input and can store signs in any SL. 
Currently the system takes English, Hindi and 
Bengali texts as input and can store signs in ISL 
only. The system also provides an easy to use GUI 
The 6th Workshop on Asian Languae Resources, 2008
63
to include phonological information of a sign in 
the form of HamNoSys string. The generated 
HamNoSys string can then be used as an input to 
the signing avatar module to produce animated 
sign output. 
 In the next phase of our work we will im-
prove the system so that it can associate signs in 
any other SL (like, ASL and BSL). Further, 
WordNet as well as POS Tagger corresponding to 
Hindi and Bengali languages should also be inte-
grated with the system. Also, support has to be 
built so that system can perform sign-to-word and 
sign to sign search.  We will also perform proper 
evaluation of the HamNoSys editor in order to 
understand its utility to the SL user. 
References 
Buttussi F., Chittaro L., Coppo M. 2007. Using Web3D 
technologies for visualization and search of signs in 
an international sign language dictionary. Proceed-
ings of the twelfth international conference on 3D 
web technology. Perugia, Italy Pages: 61 ? 70 Year 
of Publication: 2007 ISBN:978-1-59593-652-3  
Geitz, S., Hanson, T., Maher, S. 1996. Computer gener-
ated 3-dimensional models of manual alphabet hand-
shapes for the World Wide Web. In Assets ?96: 
Proceedings of the second annual ACM confer-
ence on Assistive technologies, ACM Press, New 
York, NY, USA, 27?31. 
Marshall I. and S?f?r ?. 2001.Extraction of semantic 
representations from syntactic SMU link grammar 
linkages.. In G. Angelova, editor, Proceedings of 
Recent Advances in Natural Lanugage Processing, 
pp: 154-159, Tzigov Chark, Bulgaria, September. 
Prillwitz P., Regina Leven, Heiko Zienert, Thomas 
Hamke, and Jan Henning. 1989. HamNoSys Version 
2.0: Hamburg Notation System for Sign Languages: 
An Introductory Guide, volume 5 of International 
Studies on Sign Language and Communication of 
the Deaf. Signum Press, Hamburg, Germany,  
Smith G., Angus. 1999. English to American Sign Lan-
guage machine translation of weather reports. Pro-
ceedings of the Second High Desert Student Confer-
ence in Linguistics. 
Smith,K.C., Edmondson, W. 2004. The Development 
of a Computational Notation for Synthesis of Sign 
and Gesture, GW03(312-323). 
Speers, A. 1995. SL-Corpus: A computer tool for sign 
language corpora., Georgetown University.  
Stokoe W. C., 1960. Sign language structure: an out-
line of the visual communication systems of the 
American deaf. 2nd edition, 1978. Silver Spring, 
MD: Linstok Press. 
VCOM3D,2004. Sign smith products. 
http://www.vcom3d.com. 
Wilcox, S., Scheibman, J., Wood, D., Cokely, D., and 
stokoe, w. c. 1994. Multimedia dictionary of Ameri-
can Sign Language. In Assets ?94: Proceedings of 
the first annual ACM conference on Assistive tech-
nologies, ACM Press, New York, NY, USA, 9?16. 
Vasishta M., Woodward J., DeSantis S. 1998, ?An In-
troduction to Indian Sign Language?, All India Fed-
eration of the Deaf (Third Edition). 
Zeshan U., 2003,?Indo-Pakistani Sign Language 
Grammar: A Typological Outline?, Sign Language 
Studies - Volume 3, Number 2, , pp. 157-212  
Zeshan U., Madan M. Vasishta, Sethna M. 2004, ?im-
plementation of indian sign language in educational 
settings?- Volume 15, Number 2, Asia Pacific Dis-
ability Rehabilitation Journal, , pp. 15-35 
 
The 6th Workshop on Asian Languae Resources, 2008
64
Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 345?354, Dublin, Ireland, August 23-29 2014.
Influence of Target Reader Background and Text Features on Text 
Readability in Bangla: A Computational Approach 
 
 
Manjira Sinha 
Department of Computer 
Science and Engineering 
Indian Institute of Technology 
Kharagpur 
West Bengal, India 
manjira@cse.iitkgp.e
rnet.in 
Tirthankar Dasgupta 
Department of Computer 
Science and Engineering 
Indian Institute of 
Technology Kharagpur 
West Bengal, India 
tirtha@cse.iitkgp.e
rnet.in 
Anupam Basu 
Department of Computer 
Science and Engineering 
Indian Institute of 
Technology Kharagpur 
West Bengal, India 
anupam@cse.iitkgp.e
rnet.in 
 
  
Abstract 
In this paper, we have studied the effect of two important factors influencing text readability in 
Bangla: the target reader and text properties. Accordingly, at first we have built a novel Bangla 
readability dataset of 135 documents annotated by 50 readers from two different backgrounds. 
We have identified 20 different features that can affect the readability of Bangla texts; the 
features were divided in two groups, namely, ?classic? and ?non-classic?. Preliminary 
correlation analysis reveals that text features have varying influence on the text hardness stated 
by the two groups. We have employed support vector machine (SVM) and support vector 
regression (SVR) techniques to model the reading difficulties of Bangla texts. In addition to 
developing different models targeted towards different type of readers, separate combinations 
of features were tested to evaluate their comparative contributions. Our study establishes that 
the perception of text difficulty varies largely with the background of the reader. To the best of 
our knowledge, no such work on text readability has been recorded earlier in Bangla.  
1 Introduction 
Readability of a text generally refers to how well a reader is able to comprehend the content of a text, 
through reading (Dale and Chall, 1948). Readability is a complex cognitive phenomenon where, the 
cognitive load of a text for a reader depends on both the characteristics of a text like, lexical choice, 
syntactic complexity, semantic complexity, discourse level complexity and on the background of the 
user. Several experiments have already established that readability of texts are quite language 
dependent and existing readability measures in English cannot directly be used to compute readability 
of other languages like, Bangla and Hindi (Sinha et al., 2012). Yet, compared to the numerous 
readability measures in English and other European languages(Benjamin, 2012), few initiatives have 
been taken to compute text readability in a Eastern Indo-Aryan language like Bangla or any other 
Indian languages which are structurally very different from many of their Indo-European cousins such 
as English, which is of West-Germanic descent (Sinha et al., 2012). One important factor that affects 
the readability of a text is the background of the respective reader. According to Dale (Dale, 1949), 
?The interpretation of the expressed thought is related more to the reader?s informational background 
and motivations than to the internal evidences of the expressional facility of the author?. Reader?s 
background is a complex derivative of one?s educational and socio-economic state. As per one of the 
pioneering works in readability by Dale and Chall (1949), the outcome of reading depends on many 
characteristics of the prospective readers including ?reading abilities, interests, age, sex, intellectual 
This work is licensed under a Creative Commons Attribution 4.0 International License. 
345
maturity, background of information etc.?  However, we do not know of any such investigations for 
Bangla text readability that have investigate the way background of a reader affect the readability of 
text. Such language specific study is needed as Bangla as a language is very different from English 
and the inapplicability of English readability formulae for Bangla text has already been established. 
Considering the above issues as our motivation, in this paper we have developed models to predict 
reading difficulty of a Bangla document perceived according to different target reader groups. To 
categorize among different reader groups, we have considered age, education and socio-economic data 
as indicators of comprehension ability. In addition, we have also explored the impact of different types 
of text features on text comprehensibility in Bangla. However, development and evaluation of such 
model requires availability of well-annotated resources. To the best of our knowledge, no 
automatically accessible data annotated according to the reading difficulty level is available for 
Bangla. Therefore, we have developed a digital resource pool of Bangla text documents in Unicode 
encoding that can be used for various NLP tasks such as feature extraction, document analysis etc. 
Such a dataset is essential to analyze readability of text documents based on the target reader. Next, 
we have visualized the text readability problem from a machine learning perspective as a classification 
problem using support vector machines (SVM) and an estimation problem using support vector 
regression (SVR). Our study is based on a wide range of textual features, from the syntactic and 
lexical features of a text like, its average sentence length, average word length in terms of visual units, 
to discourse level features like, number of jukta-akshars (consonant conjuncts) , number of different 
parts of speeches, named entity and lexical relations (refer to section 3). Although regression analysis 
has been previously used to model the text readability in Bangla, reader group specific analysis and 
machine learning techniques like support vectors have not been used so far. We have considered two 
target reader groups namely Group-1(or Adult group) with average age of 23 Yrs and Group-2 (or 
minor?s group) with average age of 15 Yrs.   
The organization of the paper is as follows: section 2 presents a brief literature survey on existing 
readability metrics for English and Bangla; section 3 defines the features of a text considered in this 
study, and empirical data collection, section 4 discusses the experiment observations, the prediction 
techniques and presents the results and validations for the two techniques. Finally, section 5 offers 
conclusion and perspective. 
2 Related Works 
The quantitative analysis of text readability started with L.A. Sherman in 1880 (Sherman, 1893). Till 
date, English and other languages have got over 200 readability metrics (DuBay, 2004; Rabin et al., 
1988).The existing quantitative approaches towards predicting readability of a text can be broadly 
classified into three categories (Benjamin, 2012):  
Classical methods: they analyze the syntactic features of a text like sentence length, paragraph 
length etc. The examples are Flesch Reading Ease Score (Flesch, 1948), FOG index (Gunning, 1968), 
Fry graph (Fry, 1968), SMOG (McLaughlin, 1969) etc. The formulae do not take into account the 
background of the reader and the semantic features of the text such as whether the actual contents are 
making sense or not. Despite their shortcomings, these simple metrics are easy to calculate and 
provide a rough estimation of reading difficulty of a text provided. 
Cognitively motivated methods: texts are analyzed based on the cognitive features like, cohesion, 
organization and users? background. Proposition and inference model (Kintsch and Van Dijk, 1978), 
prototype theory (Rosch, 1978), latent semantic analysis (Landauer et al., 1998), Coh-metrix (Graesser 
et al., 2004) are some prominent members of this group. This group of models moves beyond the 
surface features of a text and try to measure objectively the different cognitive indicators associated 
with text and the reader. However, it has been observed that, many situations, some traditional 
indicators perform as well as the newer and more difficult versions (Crossley et al., 2007). 
Statistical language modeling: This class of approaches incorporates the power machine learning 
methods to the field of readability. They are particularly useful in determining readability of web texts 
(Collins-Thompson and Callan, 2005; Collins-Thompson and Callan, 2004; Si and Callan, 2003) (Liu 
et al., 2004). SVM has been used to identify grammatical patterns within a text and classification 
based on it (Schwarm and Ostendorf, 2005; Heilman et al., 2008; Petersen and Ostendorf, 2009). 
Although, these methods sound promising, the problem is that they cannot act as standalone measure: 
346
they need an amount of training data for classifiers appropriate to a particular user group and often 
these measures takes into account complex text features which for resource poor languages need 
manual effort to annotate. 
In Bangla, only a couple of works have been executed on text readability. Das and Roychoudhury 
(Das and Roychoudhury, 2006) studied a miniature model with respect to one parametric and two 
parametric fits. They have used seven paragraphs from seven literary texts. They considered two 
structural features of a text: average sentence length and number of syllables per 100 words. They 
found the two-parametric fit as better performer. Sinha et al. (Sinha et al., 2012) has developed two 
readability formulae for Bangla texts using regression analysis. For their study sixteen texts of length, 
about 100 words were used. They have considered six structural or syntactic features of a text for the 
work. They have demonstrated that the English readability formulae such as Flesch Reading Ease 
Index, SMOG Index do not perform appropriately while being applied to Bangla documents. They 
have found the textual features like average word length, number of polysyllabic words and number of 
jukta-akshars in a text to be the most influential ones. Both the works mentioned have taken into 
account a small subset of potentially important text features; none them have considered feature such 
as the extent of text cohesion. Moreover, their study did not explore the influence of readers? 
background on text readability. In our study, we have addressed the issue of readers? background as 
well as the effect of features at different textual level. 
3 Empirical Data Collection 
As mentioned, there is no annotated data present in Bangla, which can provide a direct classification 
of text difficulty for Bangla readers. Therefore, we have undertaken an effort to annotate the 
experiment texts with the target readers of Bangla.  
3.1 Participants 
Our objective in this study is to investigate how readability varies with the background of the reader. 
Therefore, two different target reader groups have been considered to study the relationship of effect 
of text parameters on comprehension and user background. SEC1 or socio-economic classification has 
been stated according to the standards of Market Research Society of India (MRSI). MRSI has defined 
12 socio-economic strata: A1 to E3, in the decreasing order. These strata have been designed based on 
the education level of the chief wage earner of the family and the number of ?consumer durables? (as 
per a predefined list including agricultural land) owned by the family. It has been seen that this way of 
grading reflect the social and economic position of a household in terms of fields such as education, 
awareness etc. As can be inferred from the chart, the participants range from classes C2 to E1 (C2, D1, 
D2, E1), which represents the medium to low social-economic classes.  
Type Background 
Mean age 
(Standard 
deviation) 
Group 1 (adult): 25 native speakers 
of Bangla 
Education: pursuing graduation 22.8 (1.74) 
SEC: C2-E1 
Group 2 (minors): 25 native 
speakers of Bangla 
Education: pursuing secondary or higher 
secondary 
15 (1.24) 
SEC: C2-E2 
Table1: User Statistics 
3.2 Readability corpus preparation 
We have stated in the introduction about the scarcity of annotated digital resource pool in Bangla 
useful for automatic processing. Although there are a few works on text readability in Bangla, the data 
is not available in accessible formats. To address the problem, we have developed a corpus of Bangla 
documents. The current size of the resource is about 250 documents of length about 2000 words 
spanning over broad categories such as News, literature, blogs, articles etc. A number of different text 
                                                 
1 http://imrbint.com/research/The-New-SEC-system-3rdMay2011.pdf 
347
features were computed against each document. The descriptions of the features and the justification 
for them have been stated below. 
3.3 Feature selection: 
Inferring from the cognitive load theory (Paas et al., 2003), we have assumed that the cognitive load 
exerted by a text on a reader depends on syntactic and lexical properties of a text like, average 
sentence length, average word length, number of polysyllabic words and as well as discourse features 
like the counts of the different parts of speeches and the number of co-references one has to resolve in 
order to comprehend the text. The logic behind such assumptions is as follows: while processing a text 
a user has to parse the sentences in it and extract semantically relevant meaning from those sentences 
and the words. In order to process a sentence, one has to take into account the length of the sentence 
and types of words contained in it; in addition, to infer the meaning of a sentence, it is important to 
establish the connections or the nature of dependencies among the different words in a sentence. The 
role of a word is determined by its parts of speech and its way of use in that context; apart from it, the 
words can have varied complexity based on factors like their length, count of syllables. Similarly, at 
the discourse level, a reader not only has to comprehend each sentence or paragraph, but also has to 
infer the necessary co-references among them to understand the message conveyed by the text. The 
complexity of this task depends on the number of entities (noun, proper nouns) in the text, how one 
entity is connected with other, relationships like synonymy, polysemy, and hyponymy. To capture the 
effects of all these parameters in our readability models, we have considered text features over a broad 
range. The details of the features are presented in Table 2. The word features like average word length, 
average syllable per word, sentence features like average sentence length and discourse features like 
number of polysyllabic words, number of jukta-akshars (consonant conjuncts) have been calculated as 
stated by Sinha et al. (Sinha et al., 2012), as the features need customizations for Bangla. The 
calculations based on lexical chains have been followed from Galley and McKeown (Galley and 
McKeown, 2003).  
 
Feature Description 
word features 
average word length Bangla orthographic word consists of a combination of four types of graphemes2, 
each of them is considered as a single visual unit. Average word length is total 
word length in terms of visual units divided by number of words. 
average syllable per word Total word length in terms of syllable divided by total number of words. 
sentence features 
average sentence length Total sentence length in terms of words divided by number of sentence. 
$(noun phrase) Average number of NP per sentence 
$(verb phrase) Average number of VP per sentence 
$(adjective) Average number of adjectives per sentence 
$(postposition) Average number of postpositions per sentence. Bangla grammar has postpositions, 
instead of prepositions present in English. Unlike English, postpositions in Bangla 
do not belong to separate part of speech. The postpositions require their object 
noun to take possessive, objective or locative case. Suffixes act as the case 
markers.  
$(entity) average number of named entity per sentence 
$(unique entity) Average number of unique entity per sentence 
$(clauses) Average number of clauses per sentence 
                                                 
2 http://en.wikipedia.org/wiki/Bengali_alphabet#Characteristics_of_the_orthographic_word 
348
discourse features 
Number of polysyllabic 
words and normalized 
measure for 30 sentences 
Polysyllabic words are the words whose count of syllable exceeds 2. 
number of jukta-akshars 
(consonant conjuncts) 
Total number of jukta-akshars in a text of 2000 words. It is an important feature 
for Bangla because each of the clusters has separate orthographic and 
phonemic (in some cases) representation than the constituents consonants.  
#(noun phrase) Total number of NP in the document 
#(verb phrase) Total number of VP in the document 
#(adjective) Total number of adjective in the document. 
#(postposition) Total number of postpositions in the document. 
#(entity) Total number of named entity in the document 
#(unique entity) Total number of unique entity in the document 
#(lexical chain)* Total number of lexical chain in the document 
average lexical chain 
length* 
Computed over the document 
Table2: Details of text features considered for the study 
The features marked with * in the above table have been manually annotated against each text. The other 
features, though they are computed automatically, a round of manual checking was incorporated for the sake of 
correctness. 
Expert annotations and user annotations: 
Since there is no formal ranking of Bangla texts according to their reading levels, therefore, the 
documents were then annotated by language experts to approximate the suitable reading level for each 
document. However, to develop any practical readability application, feedbacks from actual users are 
necessary. From the resource pool mentioned in Introduction, 135 texts were chosen for the present 
study: two sets of distinct 45 texts were for each group: for the adult group those were the texts 
annotated by experts to have relatively high reading level and for the minor?s group, the texts were 
annotated as having relatively low reading level; pairwise t-test were performed between the two type 
of text features to assure that their difference is significant (p<0.05).  
The rest 45 texts are common to both the groups to account for the difference in comprehension for 
the same document and the assumption that may in some cases group 2 participants have comparable 
reading skill as of group 1: consequently, the texts annotated by experts as demanding high reading 
level were selected for this purpose. These were required to ensure that the experimental data spans 
over a broad range and is unbiased. The text details are presented in table 2 below. 
 
Source of Texts  
Number of texts  
Gr.1 Gr.2 common 
Literary corpora_classical  5  5 5 
Literary corpora_contemporay 6  5 6 
News corpora_general news 6  6  5 
News corpora_interview 5 6 6 
Blog corpora_personal 6  5 5 
Blog corpora_official 5 5 5 
Article corpora_ scholar 6 7  7 
Article corpora_general 6  6 6 
Table3: Text details 
Each participant was asked 2 questions: ?How easy was it for you to understand/comprehend the 
text?? and ?How interesting was the reading to you??. Against each question, they were to answer on a 
5 point scale (1=easy, 5=very hard). Inter-rater reliability was measured through Krippendorff?s alpha3 
                                                 
3 http://en.wikipedia.org/wiki/Krippendorff's_alpha 
349
and ? = 0.81 was found. Therefore, we concluded that annotators agree more often than would have 
occurred by chance. We have measured the correlation between the outcomes of two questions 
corresponding to each of the fifty annotators; and found that in each case the correlation was greater 
than 0.8 (p < 0.05). Therefore, the questions can be considered as equivalent, and subsequently we 
have considered the rating for the first question as user input for our readability models. 
Corresponding to each text, the average of the user ratings was considered for further processing.  
4 Analysis and Model Development 
4.1 Correlation coefficients 
We have performed partial spearman correlation between each of the features and user rating. Table 4 
presents some of the examples from each type of features due to the space limitation; results 
corresponding to other features are also described subsequently. The following features have selected 
as they have been used in the existing literature for Bangla (Sinha et al., 2012). The correlations are 
presented separately for the distinct texts and the common texts delivered to the two groups of users. 
This will allow us to investigate is there any significance difference of reading feedbacks between the 
different target populations. 
 
Feature Correlation coefficient r (Significance 
(if p<0.05) p value) 
 Different texts Common texts 
 Gr. 1 Gr. 2 Gr.1 Gr. 2 
Word features 
average sentence length 0.8 (0.0017) 0.33(0.2011) 0.75 (0.0013) 0.54 (0.08) 
average word length 0.60 (0.0142) 0.73(0.0041) 0.66 (0.0026) 0.8 (0.0032) 
Sentence features 
average syllable per 
word 
0.66 (0.06) 0.64(0.0047) 0.60(0.07) 0.75(0.0043) 
Discourse features 
number of polysyllabic 
words 
0.73 (0.0013) 0.74 (0.0008) 0.67(0.0021) 0.65(0.0006) 
normalized measure for 
30 sentences 
0.76(0.0011) 0.66 (0.0041) 0.65 (0.0015) 0.66(0.0032) 
number of jukta-akshars  0.87 (0.0018) 0.39 (0.1228) 0.81 (0.0024) 0.85 (0.0043) 
Table 4: Correlation coefficients (user rating vs text features) 
Some interesting observations can be made from the above table: 
? Average sentence length or mean number of words per sentence have been long found to be a 
strong predictor of text difficulty [1]. In our case, while this holds true for the adult data, the 
correlation is less for the minors and it is not significant. 
? Average syllable per word does not hold significant correlation for the adult data in both cases 
but it does for the minor?s group  
? Jukta-akshars or consonant conjuncts have major impact on text readability in Bangla (Sinha 
et al., 2012). For adult data, it can be seen that this feature has a strong and significant 
correlation, which not true for the user data of group 2 for separate texts. On the other hand, for 
the common texts this feature was found to have high significant correlation with both the 
reader groups. This is may be due to the nature of the common texts.  
? Apart from the above two cases, the above table also presents evidence in support of the fact 
that the reader?s perception of text difficulty in relation to text features changes with the target 
reader background. 
The impact of the remaining features has been discussed here with respect to the two different types of 
text scenarios: 
350
Distinct texts for two groups: 
? In case of the readers from the first group, the user ratings have high correlation (? > 0.65) 
with $(clauses), #(verb phrases), #( unique entity), #(lexical chain) and  average lexical chain 
length. The correlations are also significant. However, the correlations with $(noun phrase), 
$(verb phrase) $(postpositions), #(postpositions), #(adjective) were found to be insignificant. 
The correlation of user annotation with features such as $(entity), $(unique entity) were found 
to be low (? < 0.45) but significant.  
? The group 2 readers were found to show high (? > 0.65) and significant correlation with $(verb 
phrases), $(unique entity), $(clauses), #(entity), #(lexical chain) and average lexical chain span. 
The correlations with $(postposition), #(postpositions) were not significant. Features like 
$(noun phrase), $(adjective) and #(adjective) were found to have low (? < 0.45) but significant 
correlations with user ratings. 
Common texts for both groups: 
? It has been observed that the group 2 user ratings have higher correlation with the sentence level 
features than the discourse level features. In particular, features such as number of $(noun 
phrase), $(adjective), $(unique entity) and $(clauses) have high correlation with the text 
difficulty ratings provided by the minor?s group. Among the discourse level features #(entity) 
and #(unique entity)have a high correlation, but #(verb phrase), #(adjective) were found to have 
not significant influence. 
? On the other hand, the adult data are more inclined towards discourse features such as #(noun 
phrase) and #(verb phrase),  #(unique entity) in a document. This may be due to the ability of 
the older people to comprehend the text as a whole rather than inferring meaning from 
individual units at a time. From sentence level feature $(clause) was found to be significant and 
important in terms of correlation, but $(noun phrase), $(adjective) do not bear significant 
correlation. 
? Properties like lexical chain, which require a reader to establish connections among different 
attributes of a concept have great significance for both group1 and group2 annotations.  
? For both the user groups the influence of average $(postposition and #(postposition) were found 
to be little and insignificant. 
From the above discussions, it is evident that the two different target reader groups show a large 
difference in their reading pattern and perception of text difficulty. The difference has been observed 
in both the cases: when they were presented with different type of texts and with same texts. 
Therefore, it has been established that the target reader background plays an important role in 
modelling text difficulty. Accordingly, in the following sections, we have developed different models 
of different reader groups, and in the process we have also shown that the models have different 
parameter values and configurations. 
4.2 Computational modelling 
Analyses of correlation coefficients give an estimation of trend in user ratings against text features. 
The next step is to develop suitable models for automatic readability prediction. To achieve the 
objective, we have used machine-learning methods such as support vector machine (SVM) and 
support vector regression (SVR) techniques. In addition, we have also presented a comparative study 
of performances of different text features in readability model building in this section. The features 
have been used in three combinations. First they were divided in  two categories i) comprising of only 
the six features mentioned in table 4 as they represent the ?classical? features used extensively to 
model text readability, and ii) second category consists of the rest 14 features and the group is termed 
?non-classical? , this yielded the first two combinations. The third combination consists of all the 
features. Therefore, we have evaluated six different types of SVM and SVR models for each group. 
We have employed a binary SVM classifier here. Given a training set instance-class pairs (?? ,??  ), i 
= 1?l, where ?? ?  ?
?   and ? ?   1,?1 l  , the general equation of a SVM is (Manning et al., 2008): 
351
12
?
?
 ? +  ? ??
l
?
 ?? ?????????,
? = ?????? ??????,? = ?????????????? ????         ? (equation: 1) 
 
?? ?
?
? ?? + ? ? 1?  ?? , ?? ????? ???????? ? 0               ?  (equation: 2) 
 
In this work, we have taken 90 texts against each group of users by combining the 45 reader group 
specific texts and 45 common texts (refer to section 3). Then for each category of reader, the texts 
were shuffled randomly. We have used 70 texts for training and 20 texts for evaluation of the model 
and performed 2-fold cross validation. The minimum, maximum and median of the rating distribution 
lie respectively at (2.33), (8.4) and (5.92) for adult (group1) and at (1.83), (8.2) and (5.5) for minor 
(group 2). To train and test the SVM models, we needed to spit the data in two classes ( easy and 
hard), this has been done by assigning the ratings less than the median in to class easy (label ?-1?) and 
the rest to the class hard (label ?1?), i.e., the user ratings were mapped to the label space ?. In case of 
SVR, the label space mapping was not required. The text features were mapped to the feature space ?? . 
Although we have tested four types of kernel functions: linear, polynomial, radial basis and sigmoid 
on the data using LIBSVM (Chang and Lin, 2011) software, here only the results corresponding to 
linear and polynomial kernels have been presented as the other two kernels performed poorly.  To 
evaluate the quality of the classifications for SVM, multiple correlation (R) and percentage of texts 
accurately classified (Acc) have been used. R denotes the extent to which the predictions are close to 
the actual classes and its square (R2) indicates the percentage of dependent variable variation that can 
be explained by the model. Therefore, while percentage accuracy is an indicator to how well the model 
has performed to classify, R indicates the extent of explanatory power it posses. A better fit will have 
large R-value as well as Acc. For SVR, root mean square error (RMSE) has been reported instead of 
Acc; a good fit will have less RMSE. Below tables present, the SVM and SVR results for adult and 
minor?s data for different kernels and different combination of features. The kernels were evaluated 
for a number of SVM parameter combinations and only the result corresponding to the most efficient 
one is presented.  
Features Classic features Non-classic features All features 
SVM parameters C = 10; d = 2; r = 0; ? = 1/6 = 0.1; ?? = 0.01 (total support vector = 28) 
Kernel R Acc. R Acc. R Acc.  
linear 0.75 76% 0.73 79% 0.80 87% 
Polynomial 0.73 75% 0.72 75% 0.75 79.5% 
Table 5: SVM for group1 readers 
Features Classic features Non-classic features All features 
SVM parameters C = 1; d = 2; r = 0; ? = 1/6 = 0.1; ?? = 0.001 (total support vector = 22 ) 
Kernel R Acc. R Acc R Acc.  
Linear 0.75 75% 0.72 77% 0.83 86% 
Polynomial 0.71 70% 0.73 72% 0.78 76% 
Table 6: SVM for group2 readers 
Features Classic Non-classic features All features 
Kernel R RMSE R RMSE R RMSE 
linear 0.56 1.6 0.53 1.7 0.68 1.1 
Polynomial 0.43 2.2 0.47 11.2 0.56 23.3 
Table 7: SVR for group1 readers 
Features Classic Non-classic features All 
Kernel R RMSE R RMSE R RMSE 
linear 0.50 1.5 0.54 1.4 0.65 1.2 
Polynomial 0.47 3.1 0.45 15.5 0.51 29.7 
352
Table 8: SVR for group2 readers 
From table 5 and table 6, it can be seen that the SVM for the two target reader groups differ 
significantly in term of parameter attributes and their accuracy. It is also evident that incorporating 
only non-classic features versus classic features improves the accuracy of SVM very slightly and both 
types of features have similar explanatory power; combining both the classic and non -classic feature 
improves the accuracy and multiple correlations significantly. The SVR from table 7 and table 8 show 
the similar trend in terms of feature performances: classic and non-classis features have comparable 
RMSE and R, but there is significant gain when the two types are taken together. The regression 
equations for group1 and group2 readers differ in the coefficients of the feature variables; these imply 
that the two groups require different readability models. Moreover, the linear kernel was found to 
perform better than the polynomial kernel in all the cases. 
5 Conclusion 
In this paper, we have studied the effect of two important factors affecting text readability in Bangla: 
the target reader and text properties. We have found that the perception of text difficulty varies largely 
with the background of the reader. Accordingly, we have developed computational models to compute 
readability of Bangla text documents based on the target reader group. In order to achieve our goal we 
have first developed a novel Bangla dataset annotated in terms of text readability by users with 
varying age group. A preliminary analysis of the reading pattern of each target group was performed 
by analysing the correlation of text features with user annotations. Next, we have applied the SVM 
classifier to classify text documents into two different classes namely, hard and easy; the SVM for the 
two reader groups have different properties, implying the difference between two corresponding 
models. We have also compared the performance of the classifier based on the feature set they use. 
We observed that in contrast to applying only the classical features or the non-classic features, 
performance of the classifier improves if both types of features are used. This is true for both the adult 
as well as the minor?s dataset. Overall, we have achieved an accuracy of around 86% for the minor?s 
dataset and 87% for the adult dataset respectively. In addition to classification, support vector 
regression has been used to model text difficulty from an estimation perspective. The result of the 
SVR also establishes our previous findings. To the best of our knowledge, no such work on text 
readability has been recorded earlier in Indian languages, especially in Bangla. The next step of this 
study is to analyse the performance of the readability formula from one group (say adult) when applied 
to the other group (say minors) and vice versa. We will also repeat our study with more spread apart 
user groups spread over less diverse economic strata. In future, we are planning to develop for multi-
class text readability models. The work will also be extended to model text comprehensibility for 
reading disabilities in Bangla.  
Reference 
Benjamin, R. (2012). Reconstructing readability: Recent developments and recommendations in the analysis of 
text difficulty. Educational Psychology Review, 24:1?26. 
Chang, C.-C. and Lin, C.-J. (2011). Libsvm: a library for support vector machines. ACM Transactions on 
Intelligent Systems and Technology (TIST), 2(3):27. 
Collins-Thompson, K. and Callan, J. (2004). A language modeling approach to predicting reading difficulty. In 
Proceedings of HLT/NAACL, volume 4. 
Collins-Thompson, K. and Callan, J. (2005). Predicting reading difficulty with statistical language models. 
Journal of the American Society for Information Science and Technology, 56(13):1448?1462. 
Dale, E. (1949). Readability. 
Dale, E. and Chall, J. (1948). A formula for predicting readability. Educational research bulletin, pages 11?28. 
Das, S. and Roychoudhury, R. (2006). Readability modelling and comparison of one and two parametric fit: A 
case study in bangla*. Journal of Quantitative Linguistics, 13(01):17?34. 
DuBay, W. (2004). The principles of readability. Impact Information, pages 1?76. 
Flesch, R. (1948). A new readability yardstick. Journal of applied psychology, 32(3):221. 
353
Fry, E. (1968). A readability formula that saves time. Journal of reading, 11(7):513?578. 
Galley, M. and McKeown, K. (2003). Improving word sense disambiguation in lexical chaining. In IJCAI, 
volume 3, pages 1486?1488. 
Graesser, A., McNamara, D., Louwerse, M., and Cai, Z. (2004). Coh-metrix: Analysis of text on cohesion and 
language. Behavior Research Methods, 36(2):193?202. 
Gunning, R. (1968). The technique of clear writing. McGraw-Hill NewYork, NY. 
Heilman, M., Collins-Thompson, K., and Eskenazi, M. (2008). An analysis of statistical models and features for 
reading difficulty prediction. In Proceedings of the Third Workshop on Innovative Use of NLP for Building 
Educational Applications, pages 71?79. Association for Computational Linguistics. 
Kintsch, W. and Van Dijk, T. (1978). Toward a model of text comprehension and production. Psychological 
review, 85(5):363. 
Landauer, T., Foltz, P., and Laham, D. (1998). An introduction to latent semantic analysis. Discourse processes, 
25(2-3):259?284. 
Liu, X., Croft, W., Oh, P., and Hart, D. (2004). Automatic recognition of reading levels from user queries. In 
Proceedings of the 27th annual international ACM SIGIR conference on Research and development in 
information retrieval, pages 548?549. ACM. 
Manning, C. D., Raghavan, P., and Sch?tze, H. (2008). Introduction to information retrieval, volume 1. 
Cambridge University Press Cambridge. 
McLaughlin, G. (1969). Smog grading: A new readability formula. Journal of reading, 12(8):639?646. 
Paas, F., Renkl, A., and Sweller, J. (2003). Cognitive load theory and instructional design: Recent developments. 
Educational psychologist, 38(1):1?4. 
Petersen, S. E. and Ostendorf, M. (2009). A machine learning approach to reading level assessment. Computer 
Speech & Language, 23(1):89?106. 
Rabin, A., Zakaluk, B., and Samuels, S. (1988). Determining difficulty levels of text written in languages other 
than english. Readability: Its past, present & future. Newark DE: International Reading Association, pages 
46?76. 
Rosch, E. (1978). Principles of categorization. Fuzzy grammar: a reader, pages 91?108. 
Schwarm, S. and Ostendorf, M. (2005). Reading level assessment using support vector machines and statistical 
language models. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, 
pages 523?530. Association for Computational Linguistics. 
Sherman, L. (1893). Analytics of literature: A manual for the objective study of english poetry and prose. 
Boston: Ginn. 
Si, L. and Callan, J. (2003). A semisupervised learning method to merge search engine results. ACM 
Transactions on Information Systems (TOIS), 21(4):457?491. 
Sinha, M., Sharma, S., Dasgupta, T., and Basu, A. (2012). New readability measures for Bangla and Hindi texts. 
In Proceedings of COLING 2012: Posters, pages 1141?1150, Mumbai, India. The COLING 2012 Organizing 
Committee. 
 
354
Proceedings of the ACL Student Research Workshop, pages 123?129,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Psycholinguistically Motivated Computational Models on the Organization 
and Processing of Morphologically Complex Words 
 
 
Tirthankar Dasgupta 
Department of Computer Science and Engineering,  
Indian Institute of Technology Kharagpur 
 tirtha@cse.iitkgp.ernet.in 
 
  
 
Abstract 
In this work we present psycholinguisti-
cally motivated computational models for 
the organization and processing of Ban-
gla morphologically complex words in 
the mental lexicon. Our goal is to identify 
whether morphologically complex words 
are stored as a whole or are they orga-
nized along the morphological line. For 
this, we have conducted a series of psy-
cholinguistic experiments to build up hy-
pothesis on the possible organizational 
structure of the mental lexicon. Next, we 
develop computational models based on 
the collected dataset. We observed that 
derivationally suffixed Bangla words are 
in general decomposed during processing 
and compositionality between the stem 
and the suffix plays an important role in 
the decomposition process. We observed 
the same phenomena for Bangla verb se-
quences where experiments showed non-
compositional verb sequences are in gen-
eral stored as a whole in the ML and low 
traces of compositional verbs are found 
in the mental lexicon.  
1 Introduction 
Mental lexicon is the representation of the words 
in the human mind and their associations that 
help fast retrieval and comprehension (Aitchison, 
1987). Words are known to be associated with 
each other in terms of, orthography, phonology, 
morphology and semantics. However, the precise 
nature of these relations is unknown. 
An important issue that has been a subject of 
study for a long time is to identify the fundamen-
tal units in terms of which the mental lexicon is 
organized. That is, whether lexical representa-
tions in the mental lexicon are word based or are 
they organized along morphological lines. For 
example, whether a word such as ?unimaginable? 
is stored in the mental lexicon as a whole word 
or do we break it up ?un-? , ?imagine? and ?-
able?, understand the meaning of each of these 
constituent and then recombine the units to com-
prehend the whole word. 
Such questions are typically answered by de-
signing appropriate priming experiments (Mars-
len-Wilson et al, 1994) or other lexical decision 
tasks. The reaction time of the subjects for re-
cognizing various lexical items under appropriate 
conditions reveals important facts about their 
organization in the brain. (See Sec. 2 for models 
of morphological organization and access and 
related experiments). 
A clear understanding of the structure and the 
processing mechanism of the mental lexicon will 
further our knowledge of how the human brain 
processes language. Further, these linguistically 
important and interesting questions are also high-
ly significant for computational linguistics (CL) 
and natural language processing (NLP) applica-
tions. Their computational significance arises 
from the issue of their storage in lexical re-
sources like WordNet (Fellbaum, 1998) and rais-
es the questions like, how to store morphologi-
cally complex words, in a lexical resource like 
WordNet keeping in mind the storage and access 
efficiency. 
There is a rich literature on organization and 
lexical access of morphologically complex words 
where experiments have been conducted mainly 
for derivational suffixed words of English, He-
brew, Italian, French, Dutch, and few other lan-
guages (Marslen-Wilson et al, 2008; Frost et al, 
1997; Grainger, et al, 1991; Drews and Zwitser-
lood, 1995). However, we do not know of any 
such investigations for Indian languages, which 
123
are morphologically richer than many of their 
Indo-European cousins. Moreover, Indian lan-
guages show some distinct phenomena like, 
compound and composite verbs for which no 
such investigations have been conducted yet. On 
the other hand, experiments indicate that mental 
representation and processing of morphologically 
complex words are not quite language indepen-
dent (Taft, 2004). Therefore, the findings from 
experiments in one language cannot be genera-
lized to all languages making it important to 
conduct similar experimentations in other lan-
guages.  
This work aims to design cognitively moti-
vated computational models that can explain the 
organization and processing of Bangla morpho-
logically complex words in the mental lexicon. 
Presently we will concentrate on the following 
two aspects: 
? Organization and processing of Bangla Poly-
morphemic words: our objective here is to de-
termine whether the mental lexicon decompos-
es morphologically complex words into its 
constituent morphemes or does it represent the 
unanalyzed surface form of a word. 
? Organization and processing of Bangla com-
pound verbs (CV): compound verbs are the 
subject of much debate in linguistic theory. No 
consensus has been reached yet with respect to 
the issue that whether to consider them as uni-
tary lexical units or are they syntactically as-
sembled combinations of two independent lex-
ical units. As linguistic arguments have so far 
not led to a consensus, we here use cognitive 
experiments to probe the brain signatures of 
verb-verb combinations and propose cognitive 
as well as computational models regarding the 
possible organization and processing of Bangla 
CVs in the mental lexicon (ML). 
With respect to this, we apply the different 
priming and other lexical decision experiments, 
described in literature (Marslen-Wilson et al, 
1994; Bentin, S. and Feldman, 1990) specifically 
for derivationally suffixed polymorphemic words 
and compound verbs of Bangla. Our cross-modal 
and masked priming experiment on Bangla deri-
vationally suffixed words shows that morpholog-
ical relatedness between lexical items triggers a 
significant priming effect, even when the forms 
are phonologically/orthographically unrelated. 
These observations are similar to those reported 
for English and indicate that derivationally suf-
fixed words in Bangla are in general accessed 
through decomposition of the word into its con-
stituent morphemes. Further, based on the expe-
rimental data we have developed a series of 
computational models that can be used to predict 
the decomposition of Bangla polymorphemic 
words. Our evaluation result shows that decom-
position of a polymorphemic word depends on 
several factors like, frequency, productivity of 
the suffix and the compositionality between the 
stem and the suffix.  
The organization of the paper is as follows: 
Sec. 2 presents related works; Sec. 3 describes 
experiment design and procedure; Sec. 4 presents 
the processing of CVs; and finally, Sec. 5 con-
cludes the paper by presenting the future direc-
tion of the work. 
2 Related Works 
2.1 Representation of polymorphemic words 
Over the last few decades many studies have at-
tempted to understand the representation and 
processing of morphologically complex words in 
the brain for various languages. Most of the stu-
dies are designed to support one of the two mu-
tually exclusive paradigms: the full-listing and 
the morphemic model. The full-listing model 
claims that polymorphic words are represented as 
a whole in the human mental lexicon (Bradley, 
1980; Butterworth, 1983). On the other hand, 
morphemic model argues that morphologically 
complex words are decomposed and represented 
in terms of the smaller morphemic units. The 
affixes are stripped away from the root form, 
which in turn are used to access the mental lex-
icon (Taft and Forster, 1975; Taft, 1981; MacK-
ay, 1978). Intermediate to these two paradigms is 
the partial decomposition model that argues that 
different types of morphological forms are 
processed separately. For instance, the derived 
morphological forms are believed to be 
represented as a whole, whereas the representa-
tion of the inflected forms follows the morphem-
ic model (Caramazza et al, 1988).  
Traditionally, priming experiments have been 
used to study the effects of morphology in lan-
guage processing. Priming is a process that re-
sults in increase in speed or accuracy of response 
to a stimulus, called the target, based on the oc-
currence of a prior exposure of another stimulus, 
called the prime (Tulving et al, 1982). Here, 
subjects are exposed to a prime word for a short 
duration, and are subsequently shown a target 
word. The prime and target words may be mor-
phologically, phonologically or semantically re-
124
lated. An analysis of the effect of the reaction 
time of subjects reveals the actual organization 
and representation of the lexicon at the relevant 
level. See Pulverm?ller (2002) for a detailed ac-
count of such phenomena.  
It has been argued that frequency of a word in-
fluences the speed of lexical processing and thus, 
can serve as a diagnostic tool to observe the na-
ture and organization of lexical representations.  
(Taft, 1975) with his experiment on English in-
flected words, argued that lexical decision res-
ponses of polymorphemic words depends upon 
the base word frequency. Similar observation for 
surface word frequency was also observed by 
(Bertram et al, 2000;Bradley, 1980;Burani et al, 
1987;Burani et al, 1984;Schreuder et al, 1997; 
Taft 1975;Taft, 2004) where it has been claimed 
that words having low surface frequency tends to 
decompose. Later, Baayen(2000) proposed the 
dual processing race model that proposes that a 
specific morphologically complex form is ac-
cessed via its parts if the frequency of that word 
is above a certain threshold of frequency, then 
the direct route will win, and the word will be 
accessed as a whole. If it is below that same thre-
shold of frequency, the parsing route will win, 
and the word will be accessed via its parts. 
2.2 Representation of Compound Verbs 
A compound verb (CV) consists of a sequence of 
two verbs (V1 and V2) acting as a single verb 
and expresses a single expression of meaning. 
For example, in the sentence 
 ??????? ? ???  ??? ? (/ruTigulo kheYe phela/) 
?bread-plural-the eat and drop-pres. Imp?  
?Eat the breads? 
the verb sequence ????  ??? ? (eat drop)? is an 
example of CV. Compound verbs are a special 
phenomena that are abundantly found in Indo-
European languages like Indian languages.  
A plethora of works has been done to provide 
linguistic explanations on the formation of such 
word, yet none so far has led to any consensus. 
Hook (1981) considers the second verb V2 as an 
aspectual complex comparable to the auxiliaries. 
Butt (1993) argues CV formations in Hindi and 
Urdu are either morphological or syntactical and 
their formation take place at the argument struc-
ture. Bashir (1993) tried to construct a semantic 
analysis based on ?prepared? and ?unprepared 
mind?. Similar findings have been proposed by 
Pandharipande (1993) that points out V1 and V2 
are paired on the basis of their semantic compa-
tibility, which is subject to syntactic constraints. 
Paul (2004) tried to represent Bangla CVs in 
terms of HPSG formalism. She proposes that the 
selection of a V2 by a V1 is determined at the 
semantic level because the two verbs will unify if 
and only if they are semantically compatible. 
Since none of the linguistic formalism could sa-
tisfactorily explain the unique phenomena of CV 
formation, we here for the first time drew our 
attention towards psycholinguistic and neuro-
linguistic studies to model the processing of 
verb-verb combinations in the ML and compare 
these responses with that of the existing models. 
3 The Proposed Approaches 
3.1 The psycholinguistic experiments 
We apply two different priming experiments 
namely, the cross modal priming and masked 
priming experiment discussed in (Forster and 
Davis, 1984; Rastle et al, 2000;Marslen-Wilson 
et al, 1994; Marslen-Wilson et al, 2008) for 
Bangla morphologically complex words. Here, 
the prime is morphologically derived form of the 
target presented auditorily (for cross modal prim-
ing) or visually (for masked priming). The sub-
jects were asked to make a lexical decision 
whether the given target is a valid word in that 
language. The same target word is again probed 
but with a different audio or visual probe called 
the control word. The control shows no relation-
ship with the target. For example, baYaska 
(aged) and baYasa (age) is a prime-target pair, 
for which the corresponding control-target pair 
could be naYana (eye) and baYasa (age). 
 Similar to (Marslen-Wilson et al, 2008) the 
masked priming has been conducted for three 
different SOA (Stimulus Onset Asynchrony), 
48ms, 72ms and 120ms. The SOA is measured as 
the amount of time between the start the first 
stimulus till the start of the next stimulus. 
Table 1: Dataset for the experiment, + implies 
related, and - implies unrelated. 
There were 500 prime-target and control-
target pairs classified into five classes. Depend-
ing on the class, the prime is related to the target 
Class Example 
M+S+O+ nibAsa(residence)-nibAsi(resident) 
M+S+O- mitra(friend) - maitri (friendship) 
M?+S-O+ Ama(Mango)- AmadAni (import) 
M-S+O- jantu(Animal)- bAgha (Tiger) 
M-S-O+ ghaDi(watch)-ghaDiYAla (croco-
dile) 
125
either in terms of morphology, semantics, ortho-
graphy and/or Phonology (See Table 1).  
The experiments were conducted on 24 highly 
educated native Bangla speakers. Nineteen of 
them have a graduate degree and five hold a post 
graduate degree. The age of the subjects varies 
between 22 to 35 years. 
Results: The RTs with extreme values and in-
correct decisions were excluded from the data. 
The data has been analyzed using two ways 
ANOVA with three factors: priming (prime and 
control), conditions (five classes) and prime du-
rations (three different SOA). We observe strong 
priming effects (p<0.05) when the target word is 
morphologically derived and has a recognizable 
suffix, semantically and orthographically related 
with respect to the prime; no priming effects are 
observed when the prime and target words are 
orthographically related but share no morpholog-
ical or semantic relationship; although not statis-
tically significant (p>0.07), but weak priming is 
observed for prime target pairs that are only se-
mantically related. We see no significant differ-
ence between the prime and control RTs for oth-
er classes.  
We also looked at the RTs for each of the 500 
target words. We observe that maximum priming 
occurs for words in [M+S+O+](69%), some 
priming is evident in [M+S+O-](51%) and 
[M'+S-O+](48%), but for most of the words in 
[M-S+O-](86%) and [M-S-O+](92%) no priming 
effect was observed. 
3.2 Frequency Distribution Models of Morpho-
logical Processing 
From the above results we saw that not all poly-
morphemic words tend to decompose during 
processing, thus we need to further investigate 
the processing phenomena of Bangla derived 
words. One notable means is to identify whether 
the stem or suffix frequency is involved in the 
processing stage of that word. For this, we apply 
different frequency based models to the Bangla 
polymorphemic words and try to evaluate their 
performance by comparing their predicted results 
with the result obtained through the priming ex-
periment.  
Model-1: Base and Surface word frequency ef-
fect- It states that the probability of decomposi-
tion of a Bangla polymorphemic word depends 
upon the frequency of its base word. Thus, if the 
stem frequency of a polymorphemic word 
crosses a given threshold value, then the word 
will decomposed into its constituent morpheme. 
Similar claim has been made for surface word 
frequency model where decomposition depends 
upon the frequency of the surface word itself. 
We have evaluated both the models with the 500 
words used in the priming experiments discussed 
above. We have achieved an accuracy of 62% 
and 49% respectively for base and surface word 
frequency models. 
Model-2: Combining the base and surface word 
frequency- In a pursuit towards an extended 
model, we combine model 1 and 2 together. We 
took the log frequencies of both the base and the 
derived words and plotted the best-fit regression 
curve over the given dataset. 
The evaluation of this model over the same set 
of 500 target words returns an accuracy of 68% 
which is better than the base and surface word 
frequency models. However, the proposed model 
still fails to predict processing of around 32% of 
words. This led us to further enhance the model. 
For this, we analyze the role of suffixes in mor-
phological processing. 
Model-3: Degree of Affixation and Suffix Prod-
uctivity: we examine whether the regression 
analysis between base and derived frequency of 
Bangla words varies between suffixes and how 
these variations affect morphological decomposi-
tion. With respect to this, we try to compute the 
degree of affixation between the suffix and the 
base word. For this, we perform regression anal-
ysis on sixteen different Bangla suffixes with 
varying degree of type and token frequencies. 
For each suffix, we choose 100 different derived 
words. We observe that those suffixes having 
high value of intercept are forming derived 
words whose base frequencies are substantially 
high as compared to their derived forms. Moreo-
ver we also observe that high intercept value for 
a given suffix indicates higher inclination to-
wards decomposition. 
Next, we try to analyze the role of suffix 
type/token ratio and compare them with the 
base/derived frequency ratio model. This has 
been done by regression analysis between the 
suffix type-token ratios with the base-surface 
frequency ratio.  
We further tried to observe the role of suffix 
productivity in morphological processing. For 
this, we computed the three components of prod-
uctivity P, P* and V as discussed in (Hay and 
Plag, 2004). P is the ?conditioned degree of 
productivity? and is the probability that we are 
encountering a word with an affix and it is 
representing a new type. P* is the ?hapaxed-
conditioned degree of productivity?. It expresses 
the probability that when an entirely new word is 
126
encountered it will contain the suffix. V is the 
?type frequency?. Finally, we computed the 
productivity of a suffix through its P, P* and V 
values. We found that decomposition of Bangla 
polymorphemic word is directly proportional to 
the productivity of the suffix. Therefore, words 
that are composed of productive suffixes (P val-
ue ranges between 0.6 and 0.9) like ?-oYAlA?, 
?-giri?, ?-tba? and ?-panA? are highly decom-
posable than low productive suffixes like ?-Ani?, 
?-lA?, ?-k?, and ?-tama?. The evaluation of the 
proposed model returns an accuracy of 76% 
which comes to be 8% better than the preceding 
models. 
Combining Model-2 and Model-3: One impor-
tant observation that can be made from the above 
results is that, model-3 performs best in deter-
mining the true negative values. It also possesses 
a high recall value of (85%) but having a low 
precision of (50%). In other words, the model 
can predict those words for which decomposition 
will not take place. On the other hand, results of 
Model-2 posses a high precision of 70%. Thus, 
we argue that combining the above two models 
can better predict the decomposition of Bangla 
polymorphemic words. Hence, we combine the 
two models together and finally achieved an 
overall accuracy of 80% with a precision of 87% 
and a recall of 78%. This surpasses the perfor-
mance of the other models discussed earlier. 
However, around 22% of the test words were 
wrongly classified which the model fails to justi-
fy. Thus, a more rigorous set of experiments and 
data analysis are required to predict access me-
chanisms of such Bangla polymorphemic words. 
3.3 Stem-Suffix Compositionality 
Compositionality refers to the fact that meaning 
of a complex expression is inferred from the 
meaning of its constituents. Therefore, the cost 
of retrieving a word from the secondary memory 
is directly proportional to the cost of retrieving 
the individual parts (i.e the stem and the suffix). 
Thus, following the work of (Milin et al, 2009) 
we define the compositionality of a morphologi-
cally complex word (We) as: 
C(We)=?1H(We)+?2H(e)+?3H(W|e)+ ?4H(e|W) 
Where, H(x) is entropy of an expression x, 
H(W|e) is the conditional entropy between the 
stem W and suffix e  and ? is the proportionality 
factor whose value is computed through regres-
sion analysis. 
Next, we tried to compute the compositionali-
ty of the stem and suffixes in terms of relative 
entropy D(W||e) and Point wise mutual informa-
tion (PMI). The relative entropy is the measure 
of the distance between the probability distribu-
tion of the stem W and the suffix e. The PMI 
measures the amount of information that one 
random variable (the stem) contains about the 
other (the suffix).  
We have compared the above three techniques 
with the actual reaction time data collected 
through the priming and lexical decision experi-
ment. We observed that all the three information 
theoretic models perform much better than the 
frequency based models discussed in the earlier 
section, for predicting the decomposability of 
Bangla polymorphemic words. However, we 
think it is still premature to claim anything con-
crete at this stage of our work. We believe much 
more rigorous experiments are needed to be per-
formed in order to validate our proposed models. 
Further, the present paper does not consider fac-
tors related to age of acquisition, and word fami-
liarity effects that plays important role in the 
processing of morphologically complex words. 
Moreover, it is also very interesting to see how 
stacking of multiple suffixes in a word are 
processed by the human brain. 
4 Organization and Processing of Com-
pound Verbs in the Mental Lexicon 
Compound verbs, as discussed above, are special 
type of verb sequences consisting of two or more 
verbs acting as a single verb and express a single 
expression of meaning. The verb V1 is known as 
pole and V2 is called as vector. For example, 
???? ???? ? (getting up) is a compound verb 
where individual words do not entirely reflects 
the meaning of the whole expression. However, 
not all V1+V2 combinations are CVs. For exam-
ple, expressions like, ????? ???? ?(take and then 
go) and ? ???? ?? ??? (return back) are the ex-
amples of verb sequences where meaning of the 
whole expression can be derived from the mean-
ing of the individual component and thus, these 
verb sequences are not considered as CV. The 
key question linguists are trying to identify for a 
long time and debating a lot is whether to con-
sider CVs as a single lexical units or consider 
them as two separate units. Since linguistic rules 
fails to explain the process, we for the first time 
tried to perform cognitive experiments to under-
stand the organization and processing of such 
verb sequences in the human mind. A clear un-
derstanding about these phenomena may help us 
to classify or extract actual CVs from other verb 
127
sequences. In order to do so, presently we have 
applied three different techniques to collect user 
data. In the first technique, we annotated 4500 
V1+V2 sequences, along with their example sen-
tences, using a group of three linguists (the ex-
pert subjects). We asked the experts to classify 
the verb sequences into three classes namely, 
CV, not a CV and not sure. Each linguist has 
received 2000 verb pairs along with their respec-
tive example sentences. Out of this, 1500 verb 
sequences are unique to each of them and rest 
500 are overlapping. We measure the inter anno-
tator agreement using the Fleiss Kappa (Fleiss et 
al., 1981) measure (?) where the agreement lies 
around 0.79. Next, out of the 500 common verb 
sequences that were annotated by all the three 
linguists, we randomly choose 300 V1+V2 pairs 
and presented them to 36 native Bangla speakers. 
We ask each subjects to give a compositionality 
score of each verb sequences under 1-10 point 
scale, 10 being highly compositional and 1 for 
noncompositional. We found an agreement of 
?=0.69 among the subjects. We also observe a 
continuum of compositionality score among the 
verb sequences. This reflects that it is difficult to 
classify Bangla verb sequences discretely into 
the classes of CV and not a CV. We then, com-
pare the compositionality score with that of the 
expert user?s annotation. We found a significant 
correlation between the expert annotation and the 
compositionality score. We observe verb se-
quences that are annotated as CVs (like, ???? 
???  ,??? ?? ,??? ?? ) have got low compositio-
nality score (average score ranges between 1-4) 
on the other hand high compositional values are 
in general tagged as not a cv (???? ??? (come and 
get), ???? ?? (return back), ???? ?????? (kept), 
????? ??? (roll on floor)). This reflects that verb 
sequences which are not CV shows high degree 
of compositionality. In other words non CV 
verbs can directly interpret from their constituent 
verbs. This leads us to the possibility that com-
positional verb sequences requires individual 
verbs to be recognized separately and thus the 
time to recognize such expressions must be 
greater than the non-compositional verbs which 
maps to a single expression of meaning. In order 
to validate such claim we perform a lexical deci-
sion experiment using 32 native Bangla speakers 
with 92 different verb sequences. We followed 
the same experimental procedure as discussed in 
(Taft, 2004) for English polymorphemic words. 
However, rather than derived words, the subjects 
were shown a verb sequence and asked whether 
they recognize them as a valid combination. The 
reaction time (RT) of each subject is recorded. 
Our preliminarily observation from the RT anal-
ysis shows that as per our claim, RT of verb se-
quences having high compositionality value is 
significantly higher than the RTs for low or non-
compositional verbs. This proves our hypothesis 
that Bangla compound verbs that show less com-
positionality are stored as a hole in the mental 
lexicon and thus follows the full-listing model 
whereas compositional verb phrases are indivi-
dually parsed. However, we do believe that our 
experiment is composed of a very small set of 
data and it is premature to conclude anything 
concrete based only on the current experimental 
results.  
5 Future Directions 
In the next phase of our work we will focus on 
the following aspects of Bangla morphologically 
complex words: 
The Word Familiarity Effect: Here, our aim is to 
study the role of familiarity of a word during its 
processing. We define the familiarity of a word 
in terms of corpus frequency, Age of acquisition, 
the level of language exposure of a person, and 
RT of the word etc. 
Role of suffix types in morphological decompo-
sition: For native Bangla speakers which mor-
phological suffixes are internalized and which 
are just learnt in school, but never internalized. 
We can compare the representation of Native, 
Sanskrit derived and foreign suffixes in Bangla 
words. 
Computational models of organization and 
processing of Bangla compound verbs: presently 
we have performed some small set of experi-
ments to study processing of compound verbs in 
the mental lexicon. In the next phase of our work 
we will extend the existing experiments and also 
apply some more techniques like, crowd sourc-
ing and language games to collect more relevant 
RT and compositionality data. Finally, based on 
the collected data we will develop computational 
models that can explain the possible organiza-
tional structure and processing mechanism of 
morphologically complex Bangla words in the 
mental lexicon. 
Reference 
Aitchison, J. (1987). ?Words in the mind: An intro-
duction to the mental lexicon?. Wiley-Blackwell, 
128
Baayen R. H. (2000). ?On frequency, transparency 
and productivity?. G. Booij and J. van Marle (eds), 
Yearbook of Morphology, pages 181-208, 
Baayen R.H. (2003). ?Probabilistic approaches to 
morphology?. Probabilistic linguistics, pages 229-
287. 
Baayen R.H., T. Dijkstra, and R. Schreuder. (1997). 
?Singulars and plurals in dutch: Evidence for a pa-
rallel dual-route model?. Journal of Memory and 
Language, 37(1):94-117. 
Bashir, E. (1993), ?Causal Chains and Compound 
Verbs.? In M. K. Verma ed. (1993). 
Bentin, S. & Feldman, L.B. (1990). The contribution 
of morphological and semantic relatedness to repe-
tition priming at short and long lags: Evidence 
from Hebrew. Quarterly Journal of Experimental 
Psychology, 42, pp. 693?711. 
Bradley, D. (1980). Lexical representation of deriva-
tional relation, Juncture, Saratoga, CA: Anma Li-
bri, pp. 37-55. 
Butt, M. (1993), ?Conscious choice and some light 
verbs in Urdu.? In M. K. Verma ed. (1993). 
Butterworth, B. (1983). Lexical Representation, Lan-
guage Production, Vol. 2, pp. 257-294, San Diego, 
CA: Academic Press. 
Caramazza, A., Laudanna, A. and Romani, C. (1988). 
Lexical access and inflectional morphology. Cog-
nition, 28, pp. 297-332. 
Drews, E., and Zwitserlood, P. (1995).Morphological 
and orthographic similarity in visual word recogni-
tion. Journal of Experimental Psycholo-
gy:HumanPerception andPerformance, 21, 1098?
1116. 
Fellbaum, C. (ed.). (1998). WordNet: An Electronic 
Lexical Database, MIT Press. 
Forster, K.I., and Davis, C. (1984). Repetition prim-
ing and frequency attenuation in lexical access. 
Journal of Experimental Psychology: Learning, 
Memory, and Cognition, 10, 680?698. 
Frost, R., Forster, K.I., & Deutsch, A. (1997). What 
can we learn from the morphology of Hebrew? A 
masked-priming investigation of morphological re-
presentation. Journal of Experimental Psychology: 
Learning, Memory, and Cognition, 23, 829?856. 
Grainger, J., Cole, P., & Segui, J. (1991). Masked 
morphological priming in visual word recognition. 
Journal of Memory and Language, 30, 370?384. 
Hook, P. E. (1981). ?Hindi Structures: Intermediate 
Level.? Michigan Papers on South and Southeast 
Asia, The University of Michigan Center for South 
and Southeast Studies, Ann Arbor, Michigan. 
Joseph L Fleiss, Bruce Levin, and Myunghee Cho 
Paik. 1981. The measurement of interrater agree-
ment. Statistical methods for rates and propor-
tions,2:212?236. 
MacKay,D.G.(1978), Derivational rules and the inter-
nal lexicon. Journal of Verbal Learning and Verbal 
Behavior, 17, pp.61-71. 
Marslen-Wilson, W.D., & Tyler, L.K. (1997). Disso-
ciating types of mental computation. Nature, 387, 
pp. 592?594. 
Marslen-Wilson, W.D., & Tyler, L.K. (1998). Rules, 
representations, and the English past tense. Trends 
in Cognitive Sciences, 2, pp. 428?435. 
Marslen-Wilson, W.D., Tyler, L.K., Waksler, R., & 
Older, L. (1994). Morphology and meaning in the 
English mental lexicon. Psychological Review, 
101, pp. 3?33. 
Marslen-Wilson,W.D. and Zhou,X.( 1999). Abstract-
ness, allomorphy, and lexical architecture. Lan-
guage and Cognitive Processes, 14, 321?352. 
Milin, P., Kuperman, V., Kosti?, A. and Harald R., H. 
(2009). Paradigms bit by bit: an information-
theoretic approach to the processing of paradig-
matic structure in inflection and derivation, Anal-
ogy in grammar: Form and acquisition, pp: 214?
252. 
Pandharipande, R. (1993). ?Serial verb construction in 
Marathi.? In M. K. Verma ed. (1993). 
Paul, S. (2004). An HPSG Account of Bangla Com-
pound Verbs with LKB Implementation, Ph.D. Dis-
sertation. CALT, University of Hyderabad. 
Pulverm?ller, F. (2002). The Neuroscience of Lan-
guage. Cambridge University Press. 
Stolz, J.A., and Feldman, L.B. (1995). The role of 
orthographic and semantic transparency of the base 
morpheme in morphological processing. In L.B. 
Feldman (Ed.) Morphological aspects of language 
processing. Hillsdale, NJ: Lawrence Erlbaum As-
sociates Inc. 
 Taft, M., and Forster, K.I.(1975). Lexical storage and 
retrieval of prefix words. Journal of Verbal Learn-
ing and Verbal Behavior, Vol.14, pp. 638-647. 
Taft, M.(1988). A morphological decomposition 
model of lexical access. Linguistics, 26, pp. 657-
667. 
Taft, M. (2004). Morphological decomposition and 
the reverse base frequency effect. Quarterly Jour-
nal of Experimental Psychology, 57A, pp. 745-765 
Tulving, E., Schacter D. L., and Heather A.(1982). 
Priming Effects in Word Fragment Completion are 
independent of Recognition Memory. Journal of 
Experimental Psychology: Learning, Memory and 
Cognition, vol.8 (4). 
129
