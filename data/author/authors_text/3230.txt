Proceedings of the ACL 2007 Student Research Workshop, pages 91?96,
Prague, June 2007. c?2007 Association for Computational Linguistics
Clustering Hungarian Verbs on the Basis of Complementation Patterns
Kata Ga?bor
Dept. of Language Technology
Linguistics Institute, HAS
1399 Budapest, P. O. Box 701/518
Hungary
gkata@nytud.hu
Eniko? He?ja
Dept. of Language Technology
Linguistics Institute, HAS
1399 Budapest, P. O. Box 701/518
Hungary
eheja@nytud.hu
Abstract
Our paper reports an attempt to apply an un-
supervised clustering algorithm to a Hun-
garian treebank in order to obtain seman-
tic verb classes. Starting from the hypo-
thesis that semantic metapredicates underlie
verbs? syntactic realization, we investigate
how one can obtain semantically motivated
verb classes by automatic means. The 150
most frequent Hungarian verbs were clus-
tered on the basis of their complementation
patterns, yielding a set of basic classes and
hints about the features that determine ver-
bal subcategorization. The resulting classes
serve as a basis for the subsequent analysis
of their alternation behavior.
1 Introduction
For over a decade, automatic construction of wide-
coverage structured lexicons has been in the center
of interest in the natural language processing com-
munity. On the one hand, structured lexical data-
bases are easier to handle and to expand because
they allow making generalizations over classes of
words. On the other hand, interest in the automatic
acquisition of lexical information from corpora is
due to the fact that manual construction of such re-
sources is time-consuming, and the resulting data-
base is difficult to update. Most of the work in
the field of acquisition of verbal lexical properties
aims at learning subcategorization frames from cor-
pora e.g. (Pereira et al, 1993; Briscoe and Car-
roll, 1997; Sass, 2006). However, semantic group-
ing of verbs on the basis of their syntactic distribu-
tion or other quantifiable features has also gained at-
tention (Schulte im Walde, 2000; Schulte im Walde
and Brew, 2002; Merlo and Stevenson, 2001; Dorr
and Jones, 1996). The goal of these investigations is
either the validation of verb classes based on (Levin,
1993), or finding algorithms for the categorization of
new verbs.
Unlike these projects, we report an attempt to
cluster verbs on the basis of their syntactic proper-
ties with the further goal of identifying the seman-
tic classes relevant for the description of Hungarian
verbs? alternation behavior. The theoretical ground-
ing of our clustering attempts is provided by the
so-called Semantic Base Hypothesis (Levin, 1993;
Koenig et al, 2003). It is founded on the observation
that semantically similar verbs tend to occur in simi-
lar syntactic contexts, leading to the assumption that
verbal semantics determines argument structure and
the surface realization of arguments. While in Eng-
lish semantic argument roles are mapped to confi-
gurational positions in the tree structure, Hungarian
codes complement structure in its highly rich nom-
inal inflection system. Therefore, we start from the
examination of case-marked NPs in the context of
verbs.
The experiment discussed in this paper is the first
stage of an ongoing project for finding the semantic
verb classes which are syntactically relevant in Hun-
garian. As we do not have presuppositions about
which classes have to be used, we chose an unsu-
pervised clustering method described in (Schulte
im Walde, 2000). The 150 most frequent Hunga-
rian verbs were categorized according to their comp-
91
lementation structures in a syntactically annotated
corpus, the Szeged Treebank (Csendes et al, 2005).
We are seeking the answer to two questions:
1. Are the resulting clusters semantically coherent
(thus reinforcing the Semantic Base Hypothe-
sis)?
2. If so, what are the alternations responsible for
their similar behavior?
The subsequent sections present the input features
[2] and the clustering methods [3], followed by the
presentation of our results [4]. Problematic issues
raised by the evaluation are discussed in [5]. Future
work is outlined in [6]. The paper ends with the con-
clusions [7].
2 Feature Space
As currently available Hungarian parsers (Babarczy
et al, 2005; Ga?bor and He?ja, 2005) cannot be used
satisfactorily for extracting verbal argument struc-
tures from corpora, the first experiment was carried
out using a manually annotated Hungarian corpus,
the Szeged Treebank. Texts of the corpus come from
different topic areas such as business news, daily
news, fiction, law, and compositions of students. It
currently comprises 1.2 million words with POS tag-
ging and syntactic annotation which extends to top-
level sentence constituents but does not differentiate
between complements and adjuncts.
When applying a classification or clustering algo-
rithm to a corpus, a crucial question is which quan-
tifiable features reflect the most precisely the lin-
guistic properties underlying word classes. (Brent,
1993) uses regular patterns. (Schulte im Walde,
2000; Schulte im Walde and Brew, 2002; Briscoe
and Carroll, 1997) use subcategorization frame
frequencies obtained from parsed corpora, poten-
tially completed by semantic selection information.
(Merlo and Stevenson, 2001) approximates diathesis
alternations by hand-selected grammatical features.
While this method has the advantage of working on
POS-tagged, unparsed corpora, it is costly with res-
pect to time and linguistic expertise. To overcome
this drawback, (Joanis and Stevenson, 2003) de-
velop a general feature space for supervised verb
classification. (Stevenson and Joanis, 2003) inves-
tigate the applicability of this general feature space
to unsupervised verb clustering tasks. As unsuper-
vised methods are more sensitive to noisy features,
the key issue is to filter out the large number of
probably irrelevant features. They propose a semi-
supervised feature selection method which outper-
forms both hand-selection of features and usage of
the full feature set.
As in our experiment we do not have a pre-defined
set of semantic classes, we need to apply unsu-
pervised methods. Neither have we manually de-
fined grammatical cues, not knowing which alter-
nations should be approximated. Hence, similarly
to (Schulte im Walde, 2000), we represent verbs by
their subcategorization frames.
In accordance with the annotation of the treebank,
we included both complements and adjuncts in sub-
categorization patterns. It is important to note, how-
ever, that not only practical considerations lead us
to this decision. First, there are no reliable syntactic
tests for differentiating complements from adjuncts.
This is due to the fact that Hungarian is a highly in-
flective, non-configurational language, where con-
stituent order does not reveal dependency relations.
Indeed, complements and adjuncts of verbs tend to
mingle. In parallel, Hungarian presents a very rich
nominal inflection system: there are 19 case suf-
fixes, and most of them can correspond to more than
one syntactic function, depending on the verb class
they occur with. Second, we believe that adjuncts
can be at least as revealing of verbal meaning as
complements are: many of them are not productive
(in the sense that they cannot be added to any verb),
they can only appear with predicates the meaning of
which is compatible with the semantic role of the ad-
junct. For these considerations we chose to include
both complements and adjuncts in subcategorization
patterns.
Subcategorization frames to be extracted from
the treebank are composed of case-marked NPs
and infinitives that belong to a children node of
the verb?s maximal projection. As Hungarian is a
non-configurational language, this operation simply
yields a non-ordered list of the verb?s syntactic de-
pendents. There was no upper bound on the num-
ber of syntactic dependents to be included in the
frame. Frame types were obtained from individual
frames by omitting lexical information as well as
every piece of morphosyntactic description except
92
for the POS tag and the case suffix. The generaliza-
tion yielded 839 frame types altogether.1
3 Clustering Methods
In accordance with our goal to set up a basis for
a semantic classification, we chose to perform the
first clustering trial on the 150 most frequent verbs
in the Szeged Treebank. The representation of verbs
and the clustering process were carried out based on
(Schulte im Walde, 2000). The data to be compared
were the maximum likelihood estimates of the pro-
bability distribution of verbs over the possible frame
types:
p(t|v) = f(v, t)f(v) (1)
with f(v) being the frequency of the verb, and
f(v, t) being the frequency of the verb in the frame.
These values have been calculated for each of the
150 verbs and 839 frame types.
Probability distributions were compared using re-
lative entropy as a distance measure:
D(x?y) =
n?
i=1
xi ? log xiyi (2)
Due to the large number of subcategorization
frame types, verbs? representation comprise a lot of
zero probability figures. Using relative entropy as
a distance measure compels us to apply a smoothing
technique to be able to deal with these figures. How-
ever, we do not want to lose the information coded
in zero frequencies - namely, the presumable incom-
patibility of the verb with certain semantic roles as-
sociated with specific case suffixes. Since we work
with the 150 most frequent verbs, we wish to use
a method which is apt to reflect that a gap in the
case of a high-frequency lemma is more likely to be
an impossible event than in the case of a relatively
less frequent lemma (where it might as well be acci-
dental). That is why we have chosen the smoothing
technique below:
fe = 0, 001f(v) if
fc(t, v) = 0
(3)
1The order in which syntactic dependents appear in the sen-
tence was not taken into account.
where fe is the estimated and fc is the observed fre-
quency.
Two alternative bottom-up clustering algorithms
were then applied to the data:
1. First we employed an agglomerative clustering
method, starting from 150 singleton clusters.
At every iteration we merged the two most sim-
ilar clusters and re-counted the distance mea-
sures. The problem with this approach, as
Schulte im Walde notes on her experiment, is
that verbs tend to gather in a small number of
big classes after a few iterations. To avoid this,
we followed her in setting to four the maximum
number of elements occuring in a cluster. This
method - and the size of the corpus - allowed
us to categorize 120 out of 150 verbs into 38
clusters, as going on with the process would
have led us to considerably less coherent clus-
ters. However, the results confronted us with
the chaining effect, i.e. some of the clusters
had a relatively big distance between their least
similar members.
2. In the second experiment we put a restriction
on the distance between each pair of verbs be-
longing to the same cluster. That is, in order for
a new verb to be added to a cluster, its distance
from all of the current cluster members had to
be smaller than the maximum distance stated
based on test runs. In this experiment we could
categorize 71 verbs into 23 clusters. The con-
venience of this method over the first one is its
ability to produce popular yet coherent clusters,
which is a particularly valuable feature given
that our goal at this stage is to establish basic
verb classes for Hungarian. However, we are
also planning to run a top-down clustering al-
gorithm on the data to get a probably more pre-
cise overview of their structure.
4 Results
With both methods we describe in Section 3, a big
part of the verbs showed a tendency to gather to-
gether in a few but popular clusters, while the rest
of them were typically paired with their nearest
synonym (e.g.: za?r (close) with ve?gez (finish) or
antonym (e.g.: u?l (sit) with a?ll (stand)). Naturally,
93
method 1 (i.e. placing an upper limit on the num-
ber of verbs within a cluster) produced more clus-
ters and gave more valuable results on the least fre-
quent verbs. On the other hand, method 2 (i.e. plac-
ing an upper limit on the distance between each pair
of verbs within the class) is more efficient for iden-
tifying basic verb classes with a lot of members.
Given our objective to provide a Levin-type classi-
fication for Hungarian, we need to examine whether
the clusters are semantically coherent, and if so,
what kind of semantic properties are shared among
class members. The three most popular verb clusters
were investigated first, because they contain many
of the most frequent verbs and yet are characterized
by strong inter-cluster coherence due to the method
used. The three clusters absorbed one third of the 71
categorized verbs. The clusters are the following:
C-1 VERBS OF BEING: marad (remain), van (be),
lesz (become), nincs (not being)
C-2 MODALS: megpro?ba?l (try out), pro?ba?l (try),
szokik (used to), szeret (like), akar (want),
elkezd (start), fog (will), k??va?n (wish), kell
(must)
C-3 MOVEMENT VERBS: indul (leave), jo?n (come),
elindul (depart), megy (go), kimegy (go out),
elmegy (go away)
Verb clusters C-1 and C-3 exhibit intuitively
strong semantic coherence, whereas C-2 is best de-
fined along syntactic lines as ?modals?. A subclass
of C-2 is composed of verbs which express some
mental attitude towards undertaking an action, e.g.
(szeret (like), akar (want), k??va?n (wish)), but for the
rest of the verbs it is hard to capture shared meaning
components.
It can be said in general about the clusters ob-
tained that many of them can be anchored to ge-
neral semantic metapredicates or one of the argu-
ments? semantic role, e.g.: CHANGE OF STATE
VERBS (ero?so?dik (get stronger), gyengu?l (intransi-
tive weaken), emelkedik (intransitive rise)), verbs
with a beneficiary role (biztos??t (guarantee), ad
(give), nyu?jt (provide), ke?sz??t(make)), VERBS OF
ABILITY (sikeru?l (succeed), lehet (be possible), tud
(be able, can)). Some clusters seem to result from a
tighter semantic relation, e.g. VERBS OF APPEA-
RANCE or VERBS OF JUDGEMENT were put to-
gether. In other cases the relation is broader as verbs
belonging to the class seem to share only aspectual
characteristics, e.g. AGENTIVE VERBS OF CONTI-
NUOS ACTIVITIES (u?l (be sitting), a?ll (be standing),
lakik (live somewhere), dolgozik (work)). At the
other end of the scale we find one group of verbs
which ?accidentally? share the same syntactic pat-
terns without being semantically related (foglalkozik
(deal with sg), tala?lkozik (meet sy), rendelkezik (dis-
pose of sg)).
5 Evaluation and Discussion
As (Schulte im Walde, 2007) notes, there is no
widely accepted practice of evaluating semantic
verb classes. She divides the methods into two major
classes. The first type of methods assess whether the
resulting clusters are coherent enough, i. e. elements
belonging to the same cluster are closer to each other
than to elements outside the class, according to an
independent similarity/distance measure. However,
relying on such a method would not help us eva-
luating the semantic coherence of our classes. The
second type of methods use gold standards. Widely
accepted gold standards in this field are Levin?s verb
classes or verbal WordNets. As we do not dispose
of a Hungarian equivalent of Levin?s classification
? that is exactly why we experiment with automatic
clustering ? we cannot use it directly.
We also run across difficulties when considering
Hungarian verbal WordNet (Kuti et al, 2005) as the
standard for evaluation. Mapping verb clusters to
the net would require to state semantic relatedness
in terms of WordNet-type hierarchy relations. How-
ever, if we try to capture the distance between verbal
meanings by the number of intermediary nodes in
the WordNet, we face the problem that the semantic
distance between mother-children nodes is not uni-
form.
As our work is about obtaining a Levin-type verb
classification, it could be an obvious choice to eva-
luate semantic classes by collecting alternations spe-
cific to the given class. Hungarian language hardly
lends itself to this method because of its peculiar
syntactic features. The large number of subcatego-
rization frames and the optionality of most comple-
ments and adjuncts yield too much possible alterna-
94
acc ins abl ela
indul - ins/com source source
jo?n - ins/com source source
elindul - ins/com source source
megy - ins/com source source
kimegy - ins/com source source
elmegy - ins/com source source
Table 1: The semantic roles of cases beside C-3 verb
cluster
tions. Hence, we decided to narrow down the scope
of investigation. We start from verb clusters and the
meaning components their members share. Then we
attempt to discover which semantic roles can be li-
cenced by these meaning components. If verbs in
the same cluster agree both in being compatible with
the same semantic roles and in the syntactic encod-
ing of these roles, we consider that they form a cor-
rect cluster.
To put it somewhat more formally, we represent
verb classes by matrices with a) nominal case suf-
fixes in columns and b) individual verb lemmata in
rows. The first step of the evaluation process is to fill
in the cells with the semantic roles the given suffix
can code in the context of the verb. We consider the
clusters correct, if the corresponding matrices meet
two requirements:
1. They have to be specific to the cluster.
2. Cells in the same column have to contain the
same semantic role.
Tables 1. and 2. illustrate coherent and distinctive
case matrices2.
According to Table 1. ablative case, just as e-
lative, codes a physical source in the environment
of movement verbs. Both cases having the same
semantic role, the decision between them is deter-
mined by the semantics of the corresponding NP.
These cases code an other semantic role ? cause ?
in the case of verbs of existence (Table 2).
It is important to note that we do not dispose of a
preliminary list of semantic roles. To avoid arbitrary
2Com is for comitative ? approximately encoding the mean-
ing ?together with? , ins is for the instrument of the described
event, source denotes a starting point in the space, cause refers
to entity which evoked the eventuality described by the verb.
acc ins abl ela
marad - com cause material
van - com cause material
lesz - com cause material
nincs - com cause material
Table 2: The semantic roles of cases beside C-1 verb
cluster
or vague role specifications, we need more than one
persons to fill in the cells, based on example sen-
tences.
6 Future Work
There are two major directions regarding our fu-
ture work. With respect to the automatic cluster-
ing process, we have the intention of widening the
scope of the grammatical features to be compared
by enriching subcategorization frames by other mor-
phological properties. We are also planning to test
top-down clustering methods such as the one de-
scribed in (Pereira et al, 1993). On the long run, it
will be inevitable to make experiments on larger cor-
pora. The obvious choice is the 180 million words
Hungarian National Corpus (Va?radi, 2002). It is a
POS-tagged corpus but does not contain any syntac-
tic annotation; hence its use would require at least
some partial parsing such as NP analysis to be em-
ployable for our purposes. The other future direc-
tion concerns evaluation and linguistic analysis of
verb clusters. We define well-founded verb classes
on the basis of semantic role matrices. These se-
mantic roles can be filled in a sentence by case-
marked NPs. Therefore, evaluation of automatically
obtained clusters presupposes the definition of such
matrices, which is our major linguistic task in the
future. When we have the supposed matrices at our
disposal, we can start evaluating the clusters via ex-
ample sentences which illustrate case suffix alterna-
tions or roles characteristic to specific classes.
7 Conclusions
The experiment of clustering the 150 most frequent
Hungarian verbs is the first step towards finding the
semantic verb classes underlying verbs? syntactic
distribution. As we did not have presuppositions
95
about the relevant classes, neither any gold standard
for automatic evaluation, the results have to serve
as input for a detailed linguistic analysis to find out
at what extent they are usable for the syntactic des-
cription of Hungarian. However, as demonstrated
in Section 4, the verb clusters we got show surpris-
ingly transparent semantic coherence. These results,
obtained from a corpus which is by several orders of
magnitude smaller than what is usual for such pur-
poses, is a reinforcement of the usability of the Se-
mantic Base Hypothesis for language analysis. Our
further work will emphasize both the refinement of
the clustering methods and the linguistic interpre-
tation of the resulting classes.
References
Anna Babarczy, Ba?lint Ga?bor, Ga?bor Hamp, Andra?s
Ka?rpa?ti, Andra?s Rung and Istva?n Szakada?t. 2005.
Hunpars: mondattani elemzo? alkalmaza?s [Hunpars: A
rule-based sentence parser for Hungarian]. Proceed-
ings of the 3th Hungarian Conference of Computa-
tional Linguistics (MSZNY05), pages 20-28, Szeged,
Hungary.
Michael R. Brent. 1993. From grammar to lexicon: un-
supervised learning of lexical syntax. Computational
Linguistics, 19(2):243?262, MIT Press, Cambridge,
MA, USA.
Ted Briscoe and John Carroll. 1997. Automatic Extrac-
tion of Subcategorization from Corpora. Proceedings
of the 5th Conference on Applied Natural Language
Processing (ANLP-97), pages 356?363, Washington,
DC, USA.
Do?ra Csendes, Ja?nos Csirik, Tibor Gyimo?thy and Andra?s
Kocsor. 2005. The Szeged Treebank. LNCS series
Vol. 3658, 123-131.
Bonnie J. Dorr and Doug Jones. 1996. Role of Word
Sense Disambiguation in Lexical Acquisition: Predict-
ing Semantics from Syntactic Cues. Proceedings of
the 14th International Conference on Computational
Linguistics (COLING-96), pages 322?327, Kopen-
hagen, Denmark.
Kata Ga?bor and Eniko? He?ja. 2005. Vonzatok e?s sza-
bad hata?rozo?k szaba?lyalapu? kezele?se [A Rule-based
Analysis of Complements and Adjuncts]. Proceedings
of the 3th Hungarian Conference of Computational
Linguistics (MSZNY05), pages 245-256, Szeged, Hun-
gary.
Eric Joanis and Suzanne Stevenson. 2003. A general
feature space for automatic verb classification. Pro-
ceedings of the 10th Conference of the EACL (EACL
2003), pages 163?170, Budapest, Hungary.
Jean-Pierre Koenig, Gail Mauner and Breton Bienvenue.
2003. Arguments for Adjuncts. Cognition, 89, 67-
103.
Judit Kuti, Pe?ter Vajda and Ka?roly Varasdi. 2005.
Javaslat a magyar igei WordNet kialak??ta?sa?ra [Pro-
posal for Developing the Hungarian WordNet of
Verbs]. Proceedings of the 3th Hungarian Conference
of Computational Linguistics (MSZNY05), pages 79?
87, Szeged, Hungary.
Beth Levin. 1993. English Verb Classes And Alterna-
tions: A Preliminary Investigation. Chicago Univer-
sity Press.
Paola Merlo and Suzanne Stevenson. 2001. Automatic
Verb Classification Based on Statistical Distributions
of Argument Structure. Computational Linguistics,
27(3), pages 373-408.
Fernando C. N. Pereira, Naftali Tishby and Lillan Lee.
1993. Distributional Clustering of English Words.
31st Annual Meeting of the ACL, pages 183-190,
Columbus, Ohio, USA.
Ba?lint Sass. 2006. Igei vonzatkeretek az MNSZ tagmon-
dataiban [Exploring Verb Frames in the Hungarian Na-
tional Corpus]. Proceedings of the 4th Hungarian
Conference of Computational Linguistics (MSZNY06),
pages 15?22, Szeged, Hungary.
Sabine Schulte im Walde. 2000. Clustering Verbs Se-
mantically According to their Alternation Behaviour.
Proceedings of the 18th International Conference on
Computational Linguistics (COLING-00), pages 747?
753, Saarbru?cken, Germany.
Sabine Schulte im Walde and Chris Brew. 2002. Induc-
ing German Semantic Verb Classes from Purely Syn-
tactic Subcategorisation Information. Proceedings of
the 40th Annual Meeting of the Association for Com-
putational Linguistics, pages 223-230, Philadelphia,
PA.
Sabine Schulte im Walde. to appear. The Induction of
Verb Frames and Verb Classes from Corpora. Corpus
Linguistics. An International Handbook., Anke Lu?de-
ling and Merja Kyto? (eds). Mouton de Gruyter, Berlin.
Suzanne Stevenson and Eric Joanis. 2003. Semi-
supervised Verb Class Discovery Using Noisy Fea-
tures. Proceedings of the 7th Conference on Computa-
tional Natural Language Learning (CoNLL-03), pages
71-78, Edmonton, Canada.
Tama?s Va?radi. 2002. The Hungarian National Corpus.
Proceedings of the Third International Conference on
Language Resources and Evaluation, pages 385?389,
Las Palmas, Spain.
96
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 51?57,
Avignon, France, April 23 - 27 2012. c?2012 Association for Computational Linguistics
Automatically Generated Customizable Online Dictionaries
Eniko? He?ja
Dept. of Language Technology
Research Institute for Linguistics, HAS
P.O.Box. 360 H-1394, Budapest
eheja@nytud.hu
Da?vid Taka?cs
Dept. of Language Technology
Research Institute for Linguistics, HAS
P.O.Box. 360 H-1394, Budapest
takdavid@nytud.hu
Abstract
The aim of our software presentation is
to demonstrate that corpus-driven bilingual
dictionaries generated fully by automatic
means are suitable for human use. Pre-
vious experiments have proven that bilin-
gual lexicons can be created by applying
word alignment on parallel corpora. Such
an approach, especially the corpus-driven
nature of it, yields several advantages over
more traditional approaches. Most im-
portantly, automatically attained translation
probabilities are able to guarantee that the
most frequently used translations come first
within an entry. However, the proposed
technique have to face some difficulties, as
well. In particular, the scarce availability of
parallel texts for medium density languages
imposes limitations on the size of the result-
ing dictionary. Our objective is to design
and implement a dictionary building work-
flow and a query system that is apt to ex-
ploit the additional benefits of the method
and overcome the disadvantages of it.
1 Introduction
The work presented here is part of the pilot project
EFNILEX 1 launched in 2008. The project objec-
tive was to investigate to what extent LT methods
are capable of supporting the creation of bilingual
dictionaries. Need for such dictionaries shows up
specifically in the case of lesser used languages
where it does not pay off for publishers to in-
vest into the production of dictionaries due to the
low demand. The targeted size of the dictionaries
is between 15,000 and 25,000 entries. Since the
1EFNILEX is financed by EFNIL
completely automatic generation of clean bilin-
gual resources is not possible according to the
state of the art, we have decided to provide lex-
icographers with bilingual resources that can fa-
cilitate their work. These kind of lexical resources
will be referred to as proto-dictionaries hencefor-
ward.
After investigating some alternative approaches
e.g. hub-and-spoke model (Martin, 2007), align-
ment of WordNets, we have decided to use word
alignment on parallel corpora. Former experi-
ments (He?ja, 2010) have proven that word align-
ment is not only able to help the dictionary cre-
ation process itself, but the proposed technique
also yields some definite advantages over more
traditional approaches. The main motivation be-
hind our choice was that the corpus-driven nature
of the method decreases the reliance on human in-
tuition during lexicographic work. Although the
careful investigation of large monolingual corpora
might have the same effect, being tedious and
time-cosuming it is not affordable in the case of
lesser used languages.
In spite of the fact that word alignment has
been widely used for more than a decade within
the NLP community to produce bilingual lexi-
cons e.g. Wu and Xia (1994) and several ex-
perts claimed that such resources might also be
useful for lexicographic purposes e.g. Bertels et
al. (2009), as far as we know, this technique has
not been exploited in large-scale lexicographic
projects yet e.g. Atkins and Rundell (2008).
Earlier experiments has shown that although
word alignment has definite advantages over more
traditional approaches, there are also some diffi-
culties that have to be dealt with: The method in
itself does not handle multi-word expressions and
51
the proto-dictionaries comprise incorrect trans-
lation candidates, as well. In fact, in a given paral-
lel corpus the number of incorrect translation can-
didates strongly depends on the size of the proto-
dictionary, as there is a trade-off between preci-
sion and recall.
Accordingly, our objective is to design and im-
plement a dictionary query system that is apt to
exploit the benefits of the method and overcome
the disadvantages of it. Hopefully, such a sys-
tem renders the proto-dictionaries helpful for not
only lexicographers, but also for ordinary dictio-
nary users.
In Section 2 the basic generation process is in-
troduced along with the difficulties we have to
deal with. The various features of the Dictionary
Query System are detailed in Section 3. Finally,
a conclusion is given and future work is listed in
Section 4.
The proto-dictionaries are available at:
http://efnilex.efnil.org
2 Generating Proto-Dictionaries ?
One-Token Translation Pairs
2.1 Input data
Since the amount of available parallel data is cru-
cial for this approach, in the first phase of the
project we have experimented with two diffe-
rent language pairs. The Dutch-French language
pair represents well-resourced languages while
the Hungarian-Lithuaninan language pair repre-
sents medium density languages. As for the for-
mer, we have exploited the French-Dutch paral-
lel corpus which forms subpart of the Dutch Pa-
rallel Corpus (Macken et al 2007). It consists
of 3,606,000 French tokens, 3,215,000 Dutch to-
kens and 186,945 translation units2 (TUs). As for
Hungarian and Lithuanian we have built a paral-
lel corpus comprising 4,189,000 Hungarian and
3,544,000 Lithuanian tokens and 262,423 TUs.
Because our original intention is to compile dic-
tionaries covering every-day language, we have
decided to focus on literature while collecting the
texts. However, due to the scarce availability
of parallel texts we made some concessions that
might be questionable from a translation point of
view. First, we did not confine ourselves purely
2The size of the parallel corpora is given in terms of trans-
lation units instead of in terms of sentence pairs, for many-
to-many alignment was allowed, too.
to the literary domain: The parallel corpus com-
prises also philosophical works. Secondly, in-
stead of focusing on direct translations between
Lithuanian and Hungarian we have relied mainly
on translations from a third language. Thirdly, we
have treated every parallel text alike, regardless of
the direction of the translation, although the DPC
contains that information.
2.2 The Generation Process
As already has been mentioned in Section 1,
word alignment in itself deals only with one-token
units. A detailed description of the generation
process of such proto-dictionaries has been given
in previous papers, e. g. He?ja (2010). In the
present paper we confine ourselves to a schematic
overview. In the first step the lemmatized versions
of each input text have been created by means of
morhological analysis and disambiguation3.
In the second step parallel corpora have been
created. We used Hunalign (Varga et al 2005)
for sentence alignment.
In the next step word alignment has been per-
formed with GIZA++ (Och and Ney, 2003). Dur-
ing word alignment GIZA++ builds a dictionary-
file that stores translation candidates, i.e. source
and target language lemmata along with their
translation probabilities. We used this dictio-
nary file as the starting point to create the proto-
dictionaries.
In the fourth step the proto-dictionaries have
been created. Only the most likely translation
candidates were kept on the basis of some suit-
able heuristics, which has been developed while
evaluating the results manually.
Finally, the relevant example sentences were
provided in a concordance to give hints on the use
of the translation candidates.
2.3 Trade-off between Precision and Recall
At this stage of the workflow some suitable
heuristics need to be introduced to find the best
translation candidates without the loss of too
many correct pairs. Therefore, several evaluations
were carried out.
3The analysis of the Lithuanian texts was performed
by the Lithuanian Centre of Computational Linguistics
(Zinkevic?ius et al 2005). The Hungarian texts were anno-
tated with the tool-chain of the Research Institute for Lin-
guistics, HAS (Oravecz and Dienes, 2002).
52
It is important to note that throughout the man-
ual evaluation we have focused on lexicographi-
cally useful translation candidates instead of per-
fect translations. The reason behind this is that
translation synonymy is rare in general language
e.g. Atkins and Rundell (2008, p. 467), thus other
semantic relations, such as hyponymy or hyper-
onymy, were also considered. Moreover, since the
word alignment method does not handle MWEs in
itself, partial matching between SL and TL trans-
lation candidates occurs frequently. In either case,
provided example sentences make possible to find
the right translation.
We considered three parameters when search-
ing for the best translations: translational proba-
bility, source language lemma frequency and tar-
get language lemma frequency (ptr, Fs and Ft,
respectively).
The lemma frequency had to be taken into ac-
count for at least two reasons. First, a minimal
amount of data was necessary for the word align-
ment algorithm to be able to estimate the transla-
tional probability. Secondly, in the case of rarely
used TL lemmas the alignment algorithm might
assign high translational probabilities to incor-
rect lemma pairs if the source lemma occurs fre-
quently in the corpus and both members of the
lemma pair recurrently show up in aligned units.
Results of the first evaluation showed that
translation pairs with relatively low frequency
and with a relatively high translational probability
yielded cc. 85% lexicographically useful trans-
lation pairs. Although the precision was rather
convincing, it has also turned out that the size of
the resulting proto-dictionaries might be a serious
bottleneck of the method (He?ja, 2010). Whereas
the targeted size of the dictionaries is between
15,000 and 25,000 entries, the proto-dictionaries
comprised only 5,521 Hungarian-Lithuanian and
7,007 French-Dutch translation candidates with
the predefined parameters. Accordingly, the cov-
erage of the proto-dictionaries should be aug-
mented.
According to our hypothesis in the case of more
frequent source lemmata even lower values of
translation probability might yield the same result
in terms of precision as in the case of lower fre-
quency source lemmata. Hence, different evalua-
tion domains need to be determined as a function
of source lemma frequency. That is:
1. The refinement of the parameters yields ap-
proximately the same proportion of correct
translation candidates as the basic parameter
setting,
2. The refinement of the parameters ensures a
greater coverage.
Detailed evaluation of the French-Dutch trans-
lation candidates confirmed the first part of our
hypothesis. We have chosen a parameter setting in
accordance with (1) (see Table 1). 6934 French-
Dutch translation candidates met the given con-
ditions. 10 % of the relevant pairs was manually
evaluated. The results are presented in Table 1.
?OK? denotes the lexicographically useful transla-
tion candidates. For instance, the first evaluation
range (1st row of Table 1) comprised translation
candidates where the source lemma occurs at least
10 times and at most 20 times in the parallel cor-
pus. With these parameters only those pairs were
considered where the translation probability was
at least 0.4. As the 1st and 2nd rows of Table 1
show, using different ptr values as cut-off param-
eters give similar results (87%), if the two source
lemma frequencies also differ.
Fs ptr OK
10 ? LF ? 20 p ? 0.4 83%
100 ? LF ? 200 p ? 0.06 87%
500 ? LF p ? 0.02 87.5%
Table 1: Evaluation results of the refined French-
Dutch proto-dictionary.
The manual evaluation of the Hungarian-
Lithuanian translation candidates yielded the
same result. We have used this proto-dictionary
to confirm the 2nd part of our hypothesis, i.e. that
the refinement of these parameters may increase
the size of the proto-dictionary. Table 2 presents
the results. Expected refers to the expected
number of correct translation candidates, esti-
mated on the basis of the evaluation sample. 800
translation candidates were evaluated altogether,
200 from each evaluation domain. As Table 2
shows, it is possible to increase the size of the
dictionary through refining the parameters: with
fine-tuned parameters the estimated number of
useful translation candidates was 13,605 instead
of 5,521.
53
Fs ptr OK Expected
5 ? LF < 30 p > 0.3 64% 4,296
30 ? LF < 90 p > 0.1 80% 4,144
90 ? LF < 300 p > 0.07 89% 3,026
300 ? LF p > 0.04 79% 2,139
13,605
Table 2: Evaluation results of the refined Hungarian-
Lithuanian proto-dictionary.
However, we should keep in mind when search-
ing for the optimal values for these parameters
that while we aim at including as many translation
candidates as possible, we also expect the gener-
ated resource to be as clean as possible. That is, in
the case of proto-dictionaries there is a trade-off
between precision and recall: the size of the re-
sulting proto-dictionaries can be increased only at
the cost of more incorrect translation candidates.
This leads us to the question of what parame-
ter settings are useful for what usage scenarios?
We think that the proto-dictionaries generated by
this method with various settings match well dif-
ferent user needs. For instance, when the settings
are strict so that the minimal frequencies and pro-
babilities are set high, the dictionary will contain
less translation pairs, resulting in high precision
and relatively low coverage, with only the most
frequently used words and their most frequent
translations. Such a dictionary is especially useful
for a novice language learner. Professional trans-
lators are able to judge whether a translation is
correct or not. They might be rather interested in
special uses of words, lexicographically useful but
not perfect translation candidates, and more sub-
tle cross-language semantic relations, while at the
same time, looking at the concordance provided
along with the translation pairs, they can easily
catch wrong translations which are the side-effect
of the method. This kind of work may be sup-
ported by a proto-dictionary with increased recall
even at the cost of a lower precision.
Thus, the Dictionary Query System described
in Section 3 in more detail, should support various
user needs.
However, user satisfaction has to be evaluated
in order to confirm this hypothesis. It forms part
of our future tasks.
Figure 1: The customized dictionary: the distribu-
tion of the Lithuanian-Hungarian translation candi-
dates. Logarithmic frequency of the source words on
the x-axis, translation probability on the y-axis.
3 Dictionary Query System
As earlier has been mentioned, the proposed
method has several benefits compared to more tra-
ditional approaches:
1. A parallel corpus of appropriate size gua-
rantees that the most relevant translations be
included in the dictionary.
2. Based on the translational probabilities it is
possible to rank translation candidates ensur-
ing that the most likely used translation va-
riants go first within an entry.
3. All the relevant example sentences from the
parallel corpora are easily accessible facili-
tating the selection of the most appropriate
translations from possible translation candi-
dates.
Accordingly, the Dictionary Query System
presents some novel features. On the one hand,
users can select the best proto-dictionary for their
purposes on the Cut Board Page. On the other
hand, the innovative representation of the gene-
rated bilingual information helps to find the best
translation for a specific user in the Dictionary
Browser Window.
3.1 Customizable proto-dictionaries: the Cut
Board Page
The dictionary can be customized on the Cut
Board Page. Two different charts are displayed
54
Figure 2: The customized dictionary: the distribution
of the candidates. Logarithmic frequency ratio of the
source and target words on the x-axis, translation prob-
ability on the y-axis.
here showing the distribution of all word pairs of
the selected proto-dictionary.
1. Plot 1 visualizes the distribution of the log-
arithmic frequency of the source words and
the relevant translation probability for each
word pair, selected by the given custom cri-
teria.
2. Plot 2 visualizes the distribution of the
logarithmic frequency ratio of the target
and source words and the corresponding
translation probability for each word pair,
selected by the given custom criteria..
Proto-dictionaries are customizable by the follow-
ing criteria:
1. Maximum and minimum ratio of the relative
frequencies of the source and target words
(left and right boundary on Plot 1).
2. Overall minimum frequency of either the
source and the target words (left boundary
on Plot 2).
3. Overall minimum translation probability
(bottom boundary on both plots).
4. Several more cut off intervals can be defined
in the space represented by Plot 2: word
pairs falling in rectangles given by their left,
right and top boundaries are cut off.
After submitting the given parameters the charts
are refreshed giving a feedback to the user and
the parameters are stored for the session, i. e. the
dictionary page shows only word pairs fitting the
selected criteria.
3.2 Dictionary Browser
The Dictionary Browser displays four different
types of information.
1. List of the translation candidates ranked by
their translation probabilities. This guaran-
tees that most often used translations come
first in the list (from top to bottom). Abso-
lute corpus frequencies are also displayed.
2. A plot displaying the distribution of the po-
ssible translations of the source word accord-
ing to translation probability and the ratio of
corpus ferquency between the source word
and the corresponding translation candidate.
3. Word cloud reflecting semantic relations bet-
ween source and target lemmata. Words in
the word cloud vary in two ways.
First, their size depends on their translation
probabilities: the higher the probability of
the target word, the bigger the font size is.
Secondly, colours are assigned to target
words according to their frequency ratios rel-
ative to the source word: less frequent target
words are cool-coloured (dark blue and light
blue) while more frequent target words are
warm-coloured (red, orange). Target words
with a frequency close to that of the source
word get gray colour.
4. Provided example sentences with the source
and target words highlighted, displayed by
clicking one of the translation candidates.
According to our hypothesis the frequency ra-
tios provide the user with hints about the se-
mantic relations between source and target words
which might be particularly important when cre-
ating texts in a foreign language. For instance,
the Lithuanian lemma karieta has four Hungar-
ian eqivalents: ?kocsi? (word with general mean-
ing, e.g. ?car?, ?railway wagon?, ?horse-drown ve-
hicle?), ?hinto?? (?carriage?), ?konflis? (?a horse-
drawn vehicle for public hire?), ?ja?rmu?? (?vehi-
cle?). The various colours of the candidates indi-
cate different semantic relations: the red colour of
55
Figure 3: The Dictionary Browser
?kocsi? marks that the meaning of the target word
is more general than that of the source word. Con-
versely, the dark blue colour of ?konflis? shows
that the meaning of the target word is more spe-
cial. However, this hypothesis should be tested in
the future which makes part of our future work.
3.3 Implementation
The online research tool is based on the LAMP
web architecture. We use a relational database
to store all the data: the multilingual corpus text,
sentences and their translations, the word forms
and lemmata and all the relations between them.
The implementation of such a data structure and
the formulation of the queries is straightforward
and efficient. The data displayed in the dictionary
browser as well as the distributional dataset pre-
sented on the charts is selected on-the-fly. The
size of the database is log-linear with the size of
the corpus and the dictionary.
4 Conclusions and Future Work
Previous experiments have proven that corpus-
driven bilingual resources generated fully by au-
tomatic means are apt to facilitate lexicographic
work when compiling bilingual dictionaries.
We think that the proto-dictionaries generated
by this technique with various settings match well
different user needs, and consequently, beside lex-
icographers, they might also be useful for end
users, both for language learners and for profes-
sional translators. A possible future work is to
further evaluate the dictionaries in real world use
cases.
Some new assumptions can be formulated
which connect the statistical properties of the
translation pairs, e.g. their frequency ratios and
the cross-language semantic relations between
them. Based on the generated dictionaries such
hypotheses may be further examined in the future.
In order to demonstrate the generated proto-
dictionaries, we have designed and implemented
an online dictionary query system, which exploits
the advantages of the data-driven nature of the ap-
plied technique. It provides different visualiza-
tions of the possible translations based on their
translation probabilities and frequencies, along
with their relevant contexts in the corpus. By pre-
setting different selection criteria the contents of
the dictionaries are customizable to suit various
usage scenarios.
The dictionaries are publicly available at
http://efnilex.efnil.org.
56
References
Beryl T. Sue Atkins and Michael Rundell. 2008. The
Oxford Guide to Practical Lexicography. OUP Ox-
ford.
Ann Bertels, Ce?drick Fairon, Jo?rg Tiedemann, and
Serge Verlinde. 2009. Corpus paralle`les et corpus
cible?s au secours du dictionnaire de traduction. In
Cahiers de lexicologie, number 94 in Revues, pages
199?219. Classiques Garnier.
Eniko? He?ja. 2010. The role of parallel corpora in
bilingual lexicography. In Nicoletta Calzolari (Con-
ference Chair), Khalid Choukri, Bente Maegaard,
Joseph Mariani, Jan Odijk, Stelios Piperidis, Mike
Rosner, and Daniel Tapias, editors, Proceedings
of the Seventh International Conference on Lan-
guage Resources and Evaluation (LREC?10), Val-
letta, Malta, may. European Language Resources
Association (ELRA).
Lieve Macken, Julia Trushkina, Hans Paulussen, Lidia
Rura, Piet Desmet, and Willy Vandeweghe. 2007.
Dutch parallel corpus : a multilingual annotated
corpus. In Proceedings of Corpus Linguistics 2007.
Willy Martin. 2007. Government policy and the plan-
ning and production of bilingual dictionaries : The
dutch approach as a case in point. International
Journal of Lexicography, 20(3):221?237.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29(1):19?51.
Csaba Oravecz and Pe?ter Dienes. 2002. Efficient
stochastic part-of-speech tagging for hungarian. In
Proceedings of the Third International Conference
on Language Resources and Evaluation, pages
710?717, Las Palmas.
Da?niel Varga, La?szlo? Ne?meth, Pe?ter Hala?csy, Andra?s
Kornai, Viktor Tro?n, and Viktor Nagy. 2005. Par-
allel corpora for medium density languages. In
Recent Advances in Natural Language Processing
(RANLP 2005), pages 590?596.
Dekai Wu and Xuanyin Xia. 1994. Learning an
english-chinese lexicon from a parallel corpus. In
In Proceedings of the First Conference of the As-
sociation for Machine Translation in the Americas,
pages 206?213.
Vytautas Zinkevic?ius, Vidas Daudaravic?ius, and Erika
Rimkute?. 2005. The Morphologically annotated
Lithuanian Corpus. In Proceedings of The Second
Baltic Conference on Human Language Technolo-
gies, pages 365?370.
57
