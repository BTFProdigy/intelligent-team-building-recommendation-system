Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 137?139,
Seoul, South Korea, 5-6 July 2012. c?2012 Association for Computational Linguistics
A Mixed-Initiative Conversational Dialogue System for Healthcare
Fabrizio Morbini and Eric Forbell and David DeVault and Kenji Sagae and
David R. Traum and Albert A. Rizzo
Institute for Creative Technologies
University of Southern California
Los Angeles, CA 90094, USA
{morbini,forbell,devault,sagae,traum,rizzo}@ict.usc.edu
Abstract
We present a mixed initiative conversational
dialogue system designed to address primar-
ily mental health care concerns related to
military deployment. It is supported by a
new information-state based dialogue man-
ager, FLoReS (Forward-Looking, Reward
Seeking dialogue manager), that allows both
advanced, flexible, mixed initiative interac-
tion, and efficient policy creation by domain
experts. To easily reach its target population
this dialogue system is accessible as a web ap-
plication.
1 Introduction
The SimCoach project is motivated by the challenge
of empowering troops and their significant others in
regard to their healthcare, especially with respect to
issues related to the psychological toll of military
deployment. SimCoach virtual humans are not de-
signed to act as therapists, but rather to encourage
users to explore available options and seek treatment
when needed by fostering comfort and confidence in
a safe and anonymous environment where users can
express their concerns to an artificial conversational
partner without fear of judgment or possible reper-
cussions.
SimCoach presents a rich test case for all compo-
nents of a dialogue system. The interaction with the
virtual human is delivered via the web for easy ac-
cess. As a trade-off between performance and qual-
ity, the virtual human has access to a limited set of
pre-rendered animations.
The Natural Language Understanding (NLU)
module needs to cope with both chat and military
Figure 1: Bill Ford, a SimCoach character. SimCoach
virtual humans are accessible through a web browser.
The user enters natural language input in the text field
on the bottom of the screen. The simcoach responds with
text, speech and character animation. The text area to the
right shows a transcript of the dialogue.
slang and a broad conversational domain. The dia-
logue policy authoring module needs to support non-
dialogue experts given that important parts of the di-
alogue policy are contributed by experts in psycho-
metrics and mental health issues in the military, and
others with familiarity with the military domain.
The dialogue manager (DM) must be able to take
initiative when building rapport or collecting the in-
formation it needs, but also respond appropriately
when the user takes initiative.
2 Supporting Mixed Initiative Dialogues
There is often a tension between system initiative
and performance of the system?s decision-making
for understanding and actions. A strong system-
initiative policy reduces the action state space since
137
user actions are only allowed at certain points in
the dialogue. System initiative also usually makes
it easier for a domain expert to design a dialogue
policy that will behave as desired.1 Such systems
can work well if the limited options available to the
user are what the user wants to do, but can be prob-
lematic otherwise, especially if the user has a choice
of whether or not to use the system. In particular,
this approach may not be well suited to an appli-
cation like SimCoach. At the other extreme, some
systems allow the user to say anything at any time,
but have fairly flat dialogue policies, e.g., (Leuski et
al., 2006). These systems can work well when the
user is naturally in charge, such as in interviewing
a character, but may not be suitable for situations
in which a character is asking the user questions, or
mixed initiative is desired.
True mixed initiative is notoriously difficult for a
manually constructed call-flow graph, in which the
system might want to take different actions in re-
sponse to similar stimuli, depending on local utili-
ties. Reinforcement learning approaches (Williams
and Young, 2007; English and Heeman, 2005) can
be very useful at learning local policy optimizations,
but they require large amounts of training data and a
well-defined global reward structure, are difficult to
apply to a large state-space and remove some of the
control, which can be undesirable (Paek and Pierac-
cini, 2008).
Our approach to this problem is a forward-looking
reward seeking agent, similar to that described in
(Liu and Schubert, 2010), though with support for
complex dialogue interaction and its authoring. Au-
thoring involves design of local subdialogue net-
works with pre-conditions and effects, and also qual-
itative reward categories (goals), which can be in-
stantiated with specific reward values. The dialogue
manager, called FLoReS, can locally optimize pol-
icy decisions, by calculating the highest overall ex-
pected reward for the best sequence of subdialogues
from a given point. Within a subdialogue, authors
can craft the specific structure of interaction.
Briefly, the main modules that form FLoReS are:
? The information state, a propositional knowl-
1Simple structures, such as a call flow graph (Pieraccini and
Huerta, 2005) and branching narrative for interactive games
(Tavinor, 2009) will suffice for authoring.
edge base that keeps track of the current state
of the conversation. The information state sup-
ports missing or unknown information by al-
lowing atomic formulas to have 3 possible val-
ues: true, false and null.
? A set of inference rules that allows the sys-
tem to add new knowledge to its information
state, based on logical reasoning. Forward in-
ference facilitates policy authoring by provid-
ing a mechanism to specify information state
updates that are independent of the specific di-
alogue context.2
? An event handling system, that allows the in-
formation state to be updated based on user in-
put, system action, or other classes of author-
defined events (such as system timeouts).
? A set of operators. Operators represent lo-
cal dialogue structure (trees), and can also be
thought of as reusable subdialogues. Each state
within the subdialogue can include a reward
for reaching that state. Rewards are functions
of the goals of the system, and are the main
method used to decide what to do when there is
more than one applicable operator. Operators
have preconditions and effects. Effects specify
changes to the information state. The precondi-
tions define when an operator can be activated.
3 Sample Dialogue
In this demo, the user will interact with the Sim-
Coach character Bill Ford, using a standard web
browser and typing text. The virtual human, driven
by FLoReS, will respond using pre-rendered anima-
tions encoded as H.264 video, delivered via a stan-
dard web server. Table 1 shows an excerpt from a
sample conversation with Bill Ford that illustrates
some of the features of this dialogue manager.
The excerpt starts from a rapport building
smalltalk sub-dialogue on the topic of barbecuing
which is interrupted by a user question about con-
fidentiality. The system responds to the user inter-
ruption and then re-starts the interrupted smalltalk
because it is still the most valuable conversation con-
tinuation available at that moment.
2For example: every time the user says that s/he has night-
mares we want to update the information state to include that
s/he also has sleeping problems.
138
Dialogue transcript Notes
Ask anybody about me, and
they?ll tell you that I love to
BBQ
BBQ Smalltalk The character is equipped
with a few operators for
smalltalk about a few topics.
BBQ is one of them.
Is this conversation se-
cret?
We don?t share your info
with anyone who can per-
sonally identify you. The
techs can see what we say,
but just to tell that the site is
working. But they have no
idea who said it, just what
was said
Did that help you?
Yes it did.
Great.
Confidentiality QA
Here the system is inter-
rupted by a user question and
it decides that answering it is
the best course of action.
Like I was saying, I love to
BBQ
BBQ Smalltalk After answering the question,
the best course of action is to
awaken the paused operator
about the BBQ smalltalk.
What is PTSD?
PTSD, or post-traumatic
stress disorder is an anxiety
condition associated with
serious traumatic events.
It can come with survivor
guilt, reliving the trauma in
dreams, numbness, and lack
of involvement with reality.
What is PTSD QA
Again the BBQ smalltalk is
interrupted by another ques-
tion from the user.
So, is PTSD something
you?re worried about. I only
ask, because you?ve been
asking about it. ...
PTSD Topic Interest QA
After answering the second
question the system decides
to ignore the paused operator
and load a follow-up operator
related to the important topic
raised by the user?s question.
The selection is based on the
expected reward that talking
about PTSD can bring to the
system.
Table 1: An excerpt of a conversation with Bill Ford that
shows opportunistic mixed initiative behavior.
Next, the user asks a question about the impor-
tant topic of post-traumatic stress disorder (PTSD).
That allows operators related to the PTSD topic to
become available and at the next chance the most
rewarding operator is no longer the smalltalk sub-
dialogue but one that stays on the PTSD topic.
4 Conclusion
We described the SimCoach dialogue system which
is designed to facilitate access to difficult health con-
cerns faced by military personnel and their fami-
lies. To easily reach its target population, the sys-
tem is available on the web. The dialogue is driven
by FLoReS, a new information-state and plan-based
DM with opportunistic action selection based on ex-
pected rewards that supports non-expert authoring.
Acknowledgments
The effort described here has been sponsored by the
U.S. Army. Any opinions, content or information
presented does not necessarily reflect the position or
the policy of the United States Government, and no
official endorsement should be inferred.
References
M.S. English and P.A. Heeman. 2005. Learning mixed
initiative dialogue strategies by using reinforcement
learning on both conversants. In HLT-EMNLP.
Anton Leuski, Ronakkumar Patel, David Traum, and
Brandon Kennedy. 2006. Building effective question
answering characters. In Proceedings of the 7th SIG-
dial Workshop on Discourse and Dialogue, pages 18?
27.
Daphne Liu and Lenhart K. Schubert. 2010. Combin-
ing self-motivation with logical planning and inference
in a reward-seeking agent. In Joaquim Filipe, Ana
L. N. Fred, and Bernadette Sharp, editors, ICAART (2),
pages 257?263. INSTICC Press.
Tim Paek and Roberto Pieraccini. 2008. Automating
spoken dialogue management design using machine
learning: An industry perspective. Speech Commu-
nication, 50(89):716 ? 729. Evaluating new methods
and models for advanced speech-based interactive sys-
tems.
Roberto Pieraccini and Juan Huerta. 2005. Where do we
go from here? Research and commercial spoken dia-
log systems. In Proceedings of the 6th SIGdial Work-
shop on Discourse and Dialogue, Lisbon, Portugal,
September.
Grant Tavinor. 2009. The art of videogames. New Di-
rections in Aesthetics. Wiley-Blackwell, Oxford.
J.D. Williams and S. Young. 2007. Scaling POMDPs for
spoken dialog management. IEEE Trans. on Audio,
Speech, and Language Processing, 15(7):2116?2129.
139
Proceedings of the SIGDIAL 2013 Conference, pages 372?374,
Metz, France, 22-24 August 2013. c?2013 Association for Computational Linguistics
Roundtable: An Online Framework for Building Web-based         Conversational Agents 
 Eric Forbell and Nicolai Kalisch and Fabrizio Morbini and Kelly Christoffersen  and Kenji Sagae and David Traum and Albert A. Rizzo Institute for Creative Technologies University of Southern California Los Angeles, CA 90094, USA {lastname}@ict.usc.edu 
   
Abstract 
We present an online system that provides a complete web-based sandbox for creating, testing and publishing embodied conversation-al agents. The tool, called Roundtable, em-powers many different types of authors and varying team sizes to create flexible interac-tions by automating many editing workflows while limiting complexity and hiding architec-tural concerns. Finished characters can be pub-lished directly to web servers, enabling highly interactive applications.  1 Introduction To support the creation of a virtual guide system called SimCoach (Rizzo et al 2011) designed to help military service personnel and their families understand behavioral healthcare issues and learn about support resources, a core virtual human architecture that included a new dialogue man-agement approach was developed (Morbini et al, 2012b). SimCoach is an embodied, conversa-tional virtual human guide delivered via the web and is supported by a flexible information state dialogue manager called FLoReS designed to support mixed initiative dialogue with conversa-tional systems. Morbini et al (2012a) provide a detailed description of the dialogue manager. Although FLoReS supports a wide variety of virtual human character behaviors, these must be specified in dialogue policies that must be au-thored manually. Initially, authoring for this dia-logue manager required coding of policies using a custom programming language. Therefore sig-nificant training for content authors was neces-sary, as well as substantial support from dialogue 
system developers in managing resources such as training data for the language understanding sys-tem. To improve the accessibility of the system to non-technical subject matter experts and other creative staff, it became clear that additional tools were necessary. In this demonstration, we present Roundtable: a web-based authoring envi-ronment for virtual human characters that is de-signed for use by subject matter experts who are qualified for content authoring in targeted do-mains, but who may not possess technical skills in programming or experience in dialogue sys-tem design.  2 Supporting rapid authoring of dia-logue agents for the web Roundtable is a complete web-based authoring system enabling the end-to-end creation, valida-tion, testing and web publishing of virtual human characters using the SimCoach virtual human architecture. The system provides features that empower many types of authors, team sizes and makeups. The system allows an author to select from a set of preconfigured 3D character models, model the dialogue policy through behavior tem-plates and more direct subdialogue editing, train and test the natural language understanding com-ponent, render animation performances associat-ed with character behaviors and utterances, and test both text-based and fully animated interac-tions. Finally, the complete character dataset can be exported and deployed to a live, highly avail-able server environment, where interaction data can be monitored and periodically collected for analysis and refinement, all from within the same browser environment (Figure 1). The entire sys-tem, from authoring to end-user interaction with 
372
the virtual human character, is web-based and requires only a current web browser for content authors and end users.   (a)
 (b)
  (c)
  (d)
  Figure 1:  Selected modules from the Roundtable character authoring system (a) character project browser; (b) dialogue policy editor; (c) training data manager (d) action and animation asset man-ager 
At the core of the authoring application is an object-oriented information model and set of management systems that span the following roles: ? Dialogue content management, respon-sible for persistence, search, validation and retrieval operations of all dialogue el-ements including subdialogue networks; information state variables and effects; goals and effects; and dialogue action an-notations that provide the mapping to the action database. ? Training data management, concerned with managing training items for a data-driven natural language understanding module, as well as providing support for running regressions when updating the training set.   ? Action management, provides data op-erations for managing potentially large sets of virtual human performance-related assets, including utterance text, speech au-dio when not system-generated, annotated nonverbal behavior schedules, as well as non-performance actions which include web-hosted videos, digested web articles, or any arbitrary HTML effect. ? Deployment management, enabling rapid deployment of locally tested charac-ters to highly available web servers as well as review and data warehousing functions for both analytic and refinement purposes. The information model is implemented in a re-lational database that fully specifies, relates and allows inquiry and validation of authored infor-mation. Additionally, a complete web application programming interface (API) powers the Roundtable application, providing a transactional framework for data operations as well as user privilege enforcement, but which also allows application expansion. The information model also serves to decouple the authoring representation from the data struc-tures necessary to drive dialogue behavior at runtime. Prior to realizing an authored character in the FLoReS engine, project dialogue data ele-ments are exported into the format expected by the runtime target, a process that we expect to expand in the future to support different dialogue managers and language understanding configura-tions.  
373
 Figure 2: The interactive virtual human character published to the web, accessible by current brows-ers.  3 Demo script This demonstration will show how to build a simple conversational virtual human character using Roundtable, from acquiring an account (http://authoring.simcoach.org, free for academic research) to obtaining the URL for the newly created character, and all of the steps in between. The workflow to build a character is as follows: 1. In the project module (Figure 1a) we create a new character by providing a unique name and selecting an existing 3D character mod-el.  2. Opening the newly created project brings up the interaction module (Figure 1b) where we choose from a list of available subdialogue templates that can be used for common dia-logue behaviors (question-answer, greeting, etc.). The provided Greeting and Goodbye templates are used to define the character?s conversational behavior when initiating and ending an interaction, respectively. Invoking the Question-Answer template, we can quickly define how the character will re-spond to a specific question or statement. Each template requires a name and sample text for any user or system utterance.  3. Following the template-based subdialogue generation, we create training data for the natural language understanding component by providing possible user utterances associ-ated with each user dialogue act in the tem-plates used (Figure 1c).  4. The last task is to refine system utterances, which are generated automatically during the step of policy authoring, and generate anima-tion data. From the action module, we can search and inspect all system actions. For any system action, with a single button click, 
we can synthesize audio and render anima-tions (Figure 1d).  5. Finally, we navigate to the test module, compile our character project, and are then able to chat with the new character to ensure expected behavior. At this point, the charac-ter is ready to be deployed, with its unique URL, and is immediately accessible on the web (Figure 2). 4 Conclusion  We described the Roundtable online authoring framework that has been designed to support non-expert users in rapidly creating embodied, conversational virtual characters of varying complexities.  The tool, being web-based, re-quires zero configuration to get started and au-thored virtual characters can be deployed to In-ternet-facing web servers immediately, expand-ing the reach of many dialogue-driven applica-tions.  Acknowledgments The effort described here has been sponsored by the U.S. Army. Any opinions, content or infor-mation presented does not necessarily reflect the position or the policy of the United States Gov-ernment, and no official endorsement should be inferred. References  A. Rizzo, B. Lange, J.G. Buckwalter, E. Forbell, J. Kim, K. Sagae, J. Williams, B.O. Rothbaum, J. Difede, G. Reger, T. Parsons, and P. Kenny. An in-telligent virtual human system for providing healthcare information and support. In J.D. West-wood et al, editor, Technology and Informatics. IOS Press, 2011. Fabrizio Morbini, David Devault, Kenji Sagae, Jillian Gerten, Angela Nazarian and David Traum FLo-ReS: A Forward Looking, Reward Seeking, Dia-logue Manager in proceedings of International Workshop on Spoken Dialog Systems (IWSDS-2012), Ermenonville, France, November 2012b. Fabrizio Morbini, Eric Forbell, David DeVault, Kenji Sagae, David Traum and Albert Rizzo. A Mixed-Initiative Conversational Dialogue System for Healthcare. Demonstration in SIGdial 2012, the 13th Annual SIGdial meeting on Discourse and Dialogue, Seoul, South Korea, 2012a.    
374
Proceedings of the SIGDIAL 2014 Conference, pages 69?73,
Philadelphia, U.S.A., 18-20 June 2014.
c
?2014 Association for Computational Linguistics
Improving Classification-Based Natural Language Understanding with
Non-Expert Annotation
Fabrizio Morbini and Eric Forbell and Kenji Sagae
Institute for Creative Technologies
University of Southern California
Los Angeles, CA 90094, USA
{morbini,forbell,sagae}@ict.usc.edu
Abstract
Although data-driven techniques are com-
monly used for Natural Language Under-
standing in dialogue systems, their effi-
cacy is often hampered by the lack of ap-
propriate annotated training data in suffi-
cient amounts. We present an approach
for rapid and cost-effective annotation of
training data for classification-based lan-
guage understanding in conversational di-
alogue systems. Experiments using a web-
accessible conversational character that in-
teracts with a varied user population show
that a dramatic improvement in natural
language understanding and a substantial
reduction in expert annotation effort can
be achieved by leveraging non-expert an-
notation.
1 Introduction
Robust Natural Language Understanding (NLU)
remains a challenge in conversational dialogue
systems that allow arbitrary natural language input
from users. Although data-driven approaches are
now commonly used to address the NLU problem
as one of classification, e.g. (Heintze et al., 2010;
Leuski and Traum, 2010; Moreira et al., 2011),
where input utterances are mapped automatically
into system-specific categories, the dependence of
such approaches on training data annotated with
semantic classes or dialogue acts creates a chicken
and egg problem: user utterances are needed to
create the annotated training data necessary for
NLU by classification, but these cannot be col-
lected without a working system that users can in-
teract with.
Common solutions to this problem include the
use of Wizard-of-Oz data collection, where a hu-
man expert manually provides the functionality of
data-driven modules while data is collected from
users, or the use of scenario authors who attempt
to anticipate user input to create an initial set of
training data. While these options offer practical
ways around the training data acquisition prob-
lem, they typically require substantial work from
system experts and provide suboptimal solutions:
data-driven approaches work best when utterances
in the training data are drawn from the same distri-
bution as those encountered in actual system use,
but the conditions under which training data is col-
lected (a human expert filling in for systems mod-
ules, or a human expert generating possible user
utterances) are quite different from those where
users interact with the final system. High qual-
ity results are often obtained through an iterative
process where an initial training set is authored
by a scenario designer, but NLU resources are
gradually updated based on real user data over
time (Gandhe et al., 2011). Although this can ulti-
mately produce training data composed primarily
of real user utterances, and therefore result in bet-
ter performance from data-driven models, an ex-
pert annotator is required to perform manual clas-
sification of user utterances. This is a laborious
process that assumes availability and willingness
of the annotator for as long as it takes to collect
enough user utterances, which may range from
weeks to months or even years, depending on the
size of the domain and the number and type of ut-
terance categories.
The main question we address is whether an-
notation by non-experts can be leveraged to speed
up utterance classification and lower its cost. We
present a technique that frames the annotation of
training data as a human intelligence task suit-
able for crowdsourcing. Although there are sim-
ilarities between our technique and active learning
(e.g. see (Gambck et al., 2011)), an important dif-
ference is that our technique does not reduce the
annotation effort by reducing the size of the data
to be labeled, but by casting the annotation task
into a simpler problem. This allows us to take ad-
vantage of the entire data generated by the users.
Through an experiment with a conversational dia-
69
logue system deployed on the web, we show that a
dramatic improvement in the quality of NLU can
be achieved with non-expert data annotation, re-
ducing the time required of an expert annotator by
70%.
2 Improving understanding with data
Our approach for creating accurate utterance clas-
sifiers for NLU in conversational dialogue systems
is based on a simple strategy, which we describe
next in general terms. NLU is assumed to be per-
formed through multiclass classification.
The first step is to create a small initial train-
ing dataset T
0
either through Wizard-of-Oz data
collection or by generation of utterances by a sys-
tem developer or content author. This training set
is used to train a NLU model M
0
. Although this
model is likely to be inadequate, it allows users
to interact with an initial version of the system.
As input utterances are collected from real users,
these utterances are annotated with their desired
NLU output labels. Periodically, at time i, we add
to the initial training dataset T
0
the annotated user
utterances accumulated up to that point. We train
a new NLU model M
i
using this augmented train-
ing set, T
i
.
1
We also keep aside a small fraction
of utterances to test the performance of the NLU
models, that is, at each time i we also have an eval-
uation set E
i
and the union of E
i
and T
i
is the en-
tire set of user utterances collected up to time i. As
more utterances are added and annotated, an NLU
model M
i
is expected to surpass the initial model
M
0
. In general, we replace the running NLU
model M
r
whenever we have a better perform-
ing M
i
model. This straightforward process can
be used to obtain increasingly more accurate lan-
guage understanding, at the cost of data annotation
in the form of labelling utterances with categories
that are defined according to the needs of the spe-
cific system and the specific domain. The cate-
gories may be based on dialogue acts, e.g. (Core
and Allen, 1997; Bunt et al., 2010), user informa-
tion needs, e.g. (Moreira et al., 2011), or stand
in for entire semantic frames, e.g. (DeVault and
Traum, 2013). The technical nature of the task of
categorizing utterances in schemes such as these
usually means that substantial time is required of
an expert annotator.
2.1 Annotation as a human intelligence task
Although the task of annotating NLU training data
involves assigning categories with technical defi-
1
For every time i and j with i < j it holds that T
i
? T
j
.
nitions to utterances, and therefore would appear
to require knowledge of these technical defini-
tions, in fact the task requires primarily the type
of language understanding that is common to all
native speakers of a given language. Our main hy-
pothesis is that this annotation can be structured
as a trivial task that requires no specific exper-
tise, and that annotations performed this way can
have a substantial impact on the quality of utter-
ance classification. We define the NLU annotation
task as follows.
Before annotation begins, each utterance cate-
gory in the system is associated with one or more
canonical utterance(s) that capture the meaning
and communicative intent of that category. These
canonical utterances allow for trivial generation
of surface text from NLU categories by simple
lookup.
Given a set of dialogues between the system
and individual users, each dialogue is split into
segments. Segments are typically composed of
a user utterance and the preceding system utter-
ance. In cases where users produce multiple utter-
ances without intervening system utterances, seg-
ments may consist of a system utterance followed
by consecutive user utterances, so that there is ex-
actly one segment corresponding to each user ut-
terance u in the dialogue and each segment starts
with a system utterance and ends with u.
Annotators work on one dialogue at a time, and
within a dialogue they are presented with one seg-
ment at a time, following the order in which the
utterances appear in the dialogue. Assignment
of a system category to the utterance targeted in
a segment is a multiple choice task, involving n
choices, one of which is none of the above. The re-
maining n?1 choices are generated automatically
by running the current NLU utterance classifier on
the target utterance, and generating the canonical
surface realizations of each of the n ? 1 highest
scoring categories. The annotator is then asked to
choose the option containing language that means
the same as the targeted utterance in the segment.
The choice of n depends on the quality of the cur-
rent NLU model, and must be made to balance the
length of the list of options with the expected num-
ber of times the appropriate choice is not in the list
of options. The more none of the above annota-
tions are performed, the less effective the annota-
tion exercise will be in reducing the effort required
by an annotation expert.
The utterances annotated as none of the above
are given to an expert for annotation. The impact
70
System Hello and welcome.
...
User Are you married?
System Yeah, forty-four years this September. I can?t be-
lieve Linda?s stuck with me this long.
System Okay, let?s get to it. Why are you here today?
User I?ve been having trouble sleeping lately.
System This must be hard for you.
System Are you feeling stressed at all?
User Yes, quite a bit
System So, I?ve got some questions I need to ask you, to get
to know you better.
System Just double checking, you haven?t been sleeping
good. Is that right?
User That?s right
System Have you been having any nightmares?
User Every once in a while, but mostly I can?t stay asleep
...
Figure 1: Excerpt of a sample interaction with a
Simcoach character over the web. User input is
typed into a text box on a web page.
of this procedure on how quickly user utterances
are annotated as training examples for the NLU
and how much expert time is saved depends on
the quality of the initial classification model and
the choice of n. These are practical factors that are
expected to vary greatly from one dialogue system
to another. In the next section, we present one ap-
plication of this procedure to an existing conversa-
tional dialogue system deployed on the web, and
show examples of dialogue segments and annota-
tion options.
3 Experiment
To test our hypothesis that language understand-
ing can be improved with much reduced expert ef-
fort, we applied the framework described above to
a system that implements a conversational char-
acter that talks with users about issues relating
to mental and behavioral disorders and presents
health care options. The system is publicly ac-
cessible at http://www.simcoach.org, and receives
traffic on the order of one hundred users per week.
Of these, about one quarter engage the system in
a meaningful dialogue with multiple turns, with
the dialogues containing on average 16 user utter-
ances. Because our process depends crucially on
user traffic to generate data for annotation, a web-
accessible system is ideally suited for it. An ex-
cerpt from a typical interaction with the system is
shown in Figure 1. The system and the NLU clas-
sifier based on Maximum Entropy models (Berger
et al., 1996) are described respectively in (Rizzo et
al., 2011) and (Sagae et al., 2009).
3.1 Data collection
Starting with an initial system deployed with an
NLU model trained with data generated by an au-
thor attempting to anticipate user behavior, we ap-
plied the approach described in section 2 to im-
prove NLU accuracy over a period of approxi-
mately five months. The initial accuracy of the
NLU classifier was 62%, measured as the number
of utterances classified correctly divided by the to-
tal number of user utterances. This accuracy fig-
ure was obtained only after the five months of data
annotation, using the heldout set of manually an-
notated dialogues.
Although the data annotation procedure as de-
scribed in section 2 could in principle be per-
formed continuously as user data come in, we
instead performed all of our annotation in three
rounds, the first consisting of approximately 2,000
user utterances, the second one month later, con-
sisting of an additional 1,000 utterances. The last
round, collected about two months later, contained
about 2,000 utterances. We used five annotators
2
working in parallel, and the average speed of each
annotator exceeded 500 utterances per hour.
The total number of NLU utterance classes in
the system is 378, although only 120 classes were
used by annotators in all rounds of annotation to
cover all of the utterances collected
3
. In our an-
notation exercise we set the number of multiple
choice items at n = 6, including 5 choices gener-
ated from categories chosen by the NLU classifier,
and one none of the above choice. Figure 2 shows
a sample dialogue segment with the corresponding
multiple choice items. During annotation, clicking
on a multiple choice item advances the annotation
by presenting the next segment containing a user
utterance to be annotated.
3.2 Results
Of the utterances in the three rounds of data col-
lection, respectively 29%, 34% and 17% were
marked by annotators as none of the above. These
were given to a developer of the NLU system who
assigned a category to each of them. In this ex-
pert annotation step the choice is not restricted to
a small set of options, and may be any of the cat-
egories in the system. Given this rate of use of
2
The non-expert annotators belonged to the same team
that developed the system but did not participate in the de-
velopment of the NLU module and the NLU classes used in
the particular dialogue system used.
3
This difference is a further evidence of the difficulty of
correctly anticipating how the end users will interact with the
dialogue system.
71
System Okay, let?s get to it. Why are you here today?
User I?ve been having trouble sleeping lately.
Which of the following options correspond most
closely to the last user utterance? If none of them have
the same general meaning as the user utterance, select
?none of the above.?
(a) I have been in a bad mood lately
(b) I have nightmares often
(c) I haven?t been sleeping well
(d) My family is worried about me
(e) I eat too much
(f) None of the above
Figure 2: Example of a dialogue segment with cor-
responding multiple choice items. The annotation
task consists of choosing the item that has approx-
imately the same meaning and communicative in-
tent as the targeted utterance (the user utterance).
the none of the above category, the need for ex-
pert annotation is not eliminated, but the amount
of expert effort necessary is reduced by over 70%.
The NLU classification accuracy figures ob-
tained after each round of annotation are shown in
Table 1. In the table, Our Approach represents the
results obtained by the technique described here.
A large improvement is observed after the first
round of annotation, with a more modest improve-
ment observed after the other two rounds. The ini-
tial jump in accuracy after round 1 is explained
by the fact that the initial model based on a sys-
tem author?s expectation of what users may say to
the system (approximately 3,000 utterances) is im-
proved using utterances that users did in fact pro-
duce in real interactions with the system. Clearly,
a more well-matched distribution of utterances in
the training data produces higher accuracy.
To assess the value of our approach, we com-
pare it with two other reasonable experimental
conditions: a baseline where only expert annota-
tion is used (Expert Only), and a condition where
no expert annotation is used (No Expert). The Ex-
pert Only condition is meant to represent what can
be achieved with the same workload for the expert
used in Our Approach. This is achieved by random
selection of user utterances to create a set with
the same number of utterances set aside for ex-
pert annotation in Our Approach. The expert then
annotates each of these utterances to create train-
ing data. For the No Expert condition, we used
only utterances annotated by non-experts, leaving
out completely utterances labeled as none of the
NLU accuracy after
each annotation round [%]
Base 1st 2nd 3rd
round round round
Our Approach 62 70 73 78
Expert Only 62 64 68 70
No Expert 62 64 65 71
Table 1: NLU accuracy obtained using the initial
training dataset T
0
, after one round of annotation
with T
1
(2,013 utterances), after two rounds of an-
notation with T
2
(additional 948 utterances), and
after three rounds with T
3
(additional 1806 utter-
ances). Accuracy is estimated on the same heldout
set of dialogues E
3
for all conditions, accounting
for roughly 10% of the annotated data.
above. Both Expert Only and No Expert condi-
tions achieve significantly lower performance than
the approach described here. This indicates that
expert annotation is important, but also that cheap
and fast non-expert annotation can provide sub-
stantial improvements to NLU.
4 Conclusion
We described a framework for annotation of train-
ing data by non-experts that can provide dramatic
improvements to natural language understanding
in dialogue systems that perform NLU through ut-
terance classification. Our approach transforms
the annotation NLU training data into a task that
can be performed by anyone with language profi-
ciency. Annotation is structured as a simple mul-
tiple choice task, easily delivered over the web.
Using our approach with a conversational char-
acter on the web, we improved NLU accuracy
from 62% to 78% using only less than 30% of the
effort it would be required of an expert to annotate
data without non-expert annotation.
Acknowledgments
We thank Kelly Christoffersen, Nicolai Kalisch
and Tomer Mor-Barak for data annotation and up-
dates to the SimCoach system, David Traum for
insightful discussions, and the anonymous review-
ers. The effort described here has been sponsored
by the U.S. Army. Any opinions, content or infor-
mation presented does not necessarily reflect the
position or the policy of the United States Govern-
ment, and no official endorsement should be in-
ferred.
72
References
Adam L. Berger, Vincent J. Della Pietra, and Stephen
A. Della Pietra. 1996. A maximum entropy ap-
proach to natural language processing. Comput.
Linguist., 22(1):39?71, March.
Harry Bunt, Jan Alexandersson, Jean Carletta, Jae-
Woong Choe, Alex Chengyu Fang, Koiti Hasida,
Kiyong Lee, Volha Petukhova, Andrei Popescu-
Belis, Laurent Romary, Claudia Soria, and David
Traum. 2010. Towards an iso standard for dia-
logue act annotation. In Nicoletta Calzolari (Con-
ference Chair), Khalid Choukri, Bente Maegaard,
Joseph Mariani, Jan Odijk, Stelios Piperidis, Mike
Rosner, and Daniel Tapias, editors, Proceedings
of the Seventh International Conference on Lan-
guage Resources and Evaluation (LREC?10), Val-
letta, Malta, may. European Language Resources
Association (ELRA).
Mark G. Core and James F. Allen. 1997. Coding di-
alogues with the DAMSL annotation scheme. In
David Traum, editor, Working Notes: AAAI Fall
Symposium on Communicative Action in Humans
and Machines, pages 28?35, Menlo Park, Califor-
nia. AAAI, American Association for Artificial In-
telligence.
David DeVault and David Traum. 2013. A method
for the approximation of incremental understanding
of explicit utterance meaning using predictive mod-
els in nite domains. In Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
Atlanta, GA, June.
Bjrn Gambck, Fredrik Olsson, and Oscar Tckstrm.
2011. Active learning for dialogue act classification.
In INTERSPEECH, pages 1329?1332. ISCA.
Sudeep Gandhe, Michael Rushforth, Priti Aggar-
wal, and David Traum. 2011. Evaluation of
an integrated authoring tool for building advanced
question-answering characters. In 12th Annual Con-
ference of the International Speech Communication
Association (InterSpeech 2011), Florence, Italy, Au-
gust.
Silvan Heintze, Timo Baumann, and David Schlangen.
2010. Comparing local and sequential models
for statistical incremental natural language under-
standing. In Raquel Fern?andez, Yasuhiro Kata-
giri, Kazunori Komatani, Oliver Lemon, and Mikio
Nakano, editors, SIGDIAL Conference, pages 9?16.
The Association for Computer Linguistics.
Anton Leuski and David R. Traum. 2010. Practical
language processing for virtual humans. In Twenty-
Second Annual Conference on Innovative Applica-
tions of Artificial Intelligence (IAAI-10).
Catarina Moreira, Ana Cristina Mendes, Lu??sa Coheur,
and Bruno Martins. 2011. Towards the rapid devel-
opment of a natural language understanding mod-
ule. In Proceedings of the 10th International Con-
ference on Intelligent Virtual Agents, IVA?11, pages
309?315, Berlin, Heidelberg. Springer-Verlag.
Albert A. Rizzo, Belinda Lange, John G. Buckwalter,
E. Forbell, Julia Kim, Kenji Sagae, Josh Williams,
Barbara O. Rothbaum, JoAnn Difede, Greg Reger,
Thomas Parsons, and Patrick Kenny. 2011. An in-
telligent virtual human system for providing health-
care information and support. In Studies in Health
Technology and Informatics.
Kenji Sagae, Gwen Christian, David DeVault, and
David R. Traum. 2009. Towards natural language
understanding of partial speech recognition results
in dialogue systems. In Short Paper Proceedings of
the North American Chapter of the Association for
Computational Linguistics - Human Language Tech-
nologies (NAACL HLT) 2009 conference.
73
