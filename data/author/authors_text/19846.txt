Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 1718?1727, Dublin, Ireland, August 23-29 2014.
Towards multimodal modeling of physicians? diagnostic
confidence and self-awareness using medical narratives
Joseph Bullard
?
Cecilia Ovesdotter Alm
?
Qi Yu
?
Pengcheng Shi
?
Anne Haake
?
?
College of Computing and Information Sciences
?
College of Liberal Arts
Rochester Institute of Technology
jtb4478@cs.rit.edu
coagla|qi.yu|spcast|arhics@rit.edu
Abstract
Misdiagnosis is a problem in the medical field, often related to physicians? cognitive errors.
Overconfidence is considered a major cause of such errors. Intelligent diagnostic support sys-
tems could benefit from understanding how aware physicians are of their performance when they
estimate their confidence in a diagnosis (i.e. a physician?s diagnostic self-awareness). Shed-
ding light on the cognitive processes related to such awareness could also help improve medical
education. We use a multimodal dataset of medical narratives to computationally model diagnos-
tic confidence and self-awareness based on physicians? linguistic and eye movement behaviors.
Dermatologists viewed images of cutaneous conditions, providing a description, diagnosis, and
certainty level for each image case, while their speech and eye movements were recorded. We
define both a generalized and a personalized approach to binning confidence levels, used in clas-
sification experiments. We also introduce truly multimodal features, which focus on combining
linguistic and eye movement data into multimodal attributes. Results indicate that combinations
of multiple modalities can outperform their constituent modalities in isolation for these problems.
1 Introduction
Misdiagnosis in the medical field is estimated to be as high as 10%-15% (Berner and Graber, 2008;
Croskerry, 2009). Such errors can result in incorrect or delayed treatment, causing patients to experience
additional suffering. Graber et al. (2002) describe three types of diagnostic errors: no-fault errors, result-
ing from atypical disease presentation or limitations of medical knowledge; system errors, resulting from
problems with the health care system; and cognitive errors, resulting from biases or faulty interpretation
on the part of a physician. Cognitive errors in particular have potential for substantial reduction through
education and training aimed at developing clinicians? metacognitive skills. Understanding the cognitive
processes of physicians during diagnosis is also of critical importance for building human-centered di-
agnostic support systems, which could help detect and flag problematic diagnostic self-awareness cases.
Examples of cognitive errors include settling on a final diagnosis too early, without ever considering the
correct diagnosis (Berner and Graber, 2008), or confirmation bias, in which only evidence to confirm a
diagnostic hypothesis is considered (Croskerry, 2003). Overconfidence is generally thought to be a major
cause of such errors (Berner and Graber, 2008; Croskerry, 2008). For example, an overconfident physi-
cian may not question her original thoughts or explore alternative diagnoses until later in the treatment
process. In general, overconfidence may be a systemic problem, reinforced by patients? preferences for
confident doctors, and by a professional environment that favors decisive actions (Katz, 1984). Similarly,
underconfidence can erode patients? trust in their providers. In this study, we view the interplay between
confidence
1
and correctness as a two-dimensional problem (see Figure 1). Ideally, physicians would
have high confidence when correct and low confidence when incorrect, indicated by the upper-left and
lower-right quadrants in Figure 1.
This work is licensed under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings
footer are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
1
For consistency, this paper uses the term confidence, treated as interchangeable with certainty and similar synonymous
expressions which may have been used by clinicians in the medical narratives, such as sure, certain, confident, etc.
1718
Appropriate
Confidence
Overconfidence
Underconfidence
Appropriate
Confidence
Confident
Not confident
Correct Incorrect
Figure 1: Two-dimensional view of the confidence and correctness relationship as it relates to diagnostic
self-awareness. A similar conceptual model is presented by Pon-Barry and Shieber (2011). Ideally,
physicians should have high confidence when they are correct and low confidence when incorrect.
Contribution Diagnostic self-awareness is an important phenomenon with implications for clinical
training and practice, yet has received little focus from a computational perspective. We report on com-
putational modeling for predicting the confidence and correctness interplay in diagnosis using features
of physicians? speech, eye movements, and combinations thereof, as dermatologists performed medical
image inspection tasks while narrating their diagnostic thought process. In dermatology, visual expertise
and clinical knowledge are both important. A motivation behind our multimodal approach is that medi-
cal image inspection relies on both the physician?s visual perceptual expertise and conceptual knowledge
base, each of which can be regarded as expressed by eye movement behavior and linguistic behavior,
respectively. We aim to apply this decision modeling to intelligent diagnostic support and clinical tutor-
ing systems. Here we solve a foundational problem by successfully modeling the complex relationship
between physicians? confidence in and correctness of their diagnoses. We also make contributions in
multimodal and linguistic feature analysis: carefully assessing feature modalities that represent physi-
cians? behaviors, and introducing a novel multimodal feature type that focuses on fusing eye movement
and verbal data.
2 Previous Work
Although there are many causes of diagnostic errors (Graber et al., 2005), those resulting from cognitive
errors may be the most challenging to reduce (Croskerry, 2003; Graber et al., 2002), while their reduction
provides high impact. Examples of such errors include flawed perception, biased heuristics, and settling
on a final diagnosis too early (Graber et al., 2002), all of which can be caused by overconfidence (Berner
and Graber, 2008; Croskerry, 2008). Underconfidence may also be a problem if it prevents a physician
from pursuing a correct diagnosis (Friedman et al., 2005).
There is evidence for links between speech and confidence in terms of prosodic features, such as
pitch and loudness (Scherer et al., 1973; Pon-Barry and Shieber, 2011; Kimble and Seidel, 1991), as
well as other characteristics of spoken language, such as speech disfluencies (Womack et al., 2012)
and hedges (Smith and Clark, 1993). Prosodic features have been identified and successfully used in
intelligent tutoring systems (Liscombe et al., 2005), where a student?s confidence (or lack thereof) can
play a key role in effective system response. In medical diagnosis, prosodic and lexical features have
been useful indicators of physicians? confidence and diagnostic correctness, individually (Womack et al.,
2013; McCoy et al., 2012). Other potentially useful information may be evident in speech as well. In
a study by Womack et al. (2012) on a similar dataset, the authors found a relationship between speech
characteristics and physician experience: attending (experienced) physicians used more filled pauses and
spoke more than resident (in-training) physicians. Additionally, verbal features may expose differences
in diagnostic reasoning that may be useful predictors of confidence. Rogers (1996) analyzed a dataset of
spoken chest X-ray examinations by radiologists, remarking that reasoning styles influence physicians?
expectations, and confirmations or contradictions of those expectations can affect their self-reported
confidence levels.
1719
Most relevant literature focuses on linguistic features. Language, as the primary form of human ex-
pression, is certainly critical. However, analyzing meaning may require going beyond linguistic infer-
ence, depending on the context or application. Previous studies have successfully incorporated multiple
expressive modalities when examining linguistic and cognitive processes, such as facial expressions for
video sentiment analysis (P?erez-Rosas et al., 2013) and pointing gestures for referring actions (Gatt and
Paggio, 2013). In such studies, the additional modalities were carefully chosen based on the nature of
the performed tasks. Here, we deal with experts (dermatologists) inspecting images (skin conditions) for
diagnostic purposes, a task that heavily involves their use of visual perceptual expertise, in addition to
conceptual domain knowledge. For this reason, we incorporate features of their eye movements in our
study. There is evidence for ties between perceptual expertise and eye movements during image inspec-
tion tasks (Li et al., 2012b), and we explore if such ties may also relate to a physician?s confidence and
diagnostic self-awareness.
Integrating different expressive modalities is challenging. Previous work involving multimodality has
predominantly treated each in isolation. We further address this challenge by identifying and exploring
truly multimodal features that focus on combining verbal and eye movement data into complex multi-
modal attributes, as it seems reasonable that the two modalities together could be more informative if
linked, and that such complex features represent a natural interactive extension of multimodal semantics.
Evidence for ties between speech and eye movements specifically was found by Li et al. (2012a), in
which sequences of fixations and saccadic eye movements were identified to predominantly align with
particular conceptual units of thought (e.g. primary lesion type) expressed verbally in medical narratives.
3 Data Description and Analysis
This study takes advantage of a dataset previously reported on by Womack et al. (2013), which is briefly
described here for clarity, as Womack et al.?s work ignored the eye movement data. A group of 29 derma-
tologists (11 attending physicians, 18 residents) were each shown a series of 30 images of dermatological
conditions in random order and asked to narrate their diagnosis of each condition. They were asked to
provide a description of the case, a list of differential diagnoses to consider, a final diagnosis, and their
certainty of their final diagnosis, as a percentage. The physicians? verbal descriptions were recorded as
audio and later manually transcribed in detail, including pauses, disfluencies, and other speech phenom-
ena.
2
During this process, the physicians? eye movements were also tracked. Each image was displayed
on a 22? LCD monitor (1650x1050 pixels) with an attached 250Hz SensoMotoric Instruments RED
remote eye-tracker while IViewX software was recording the eye movements.
In this study, the time-aligned pair of verbal description and eye movements for one physician viewing
one image is henceforth called a narrative. Figure 2a shows an example of a verbal description for
one narrative and Figure 2b shows a visualization of the corresponding eye movements. The correct
diagnoses for all images were known for the experiment and each narrative was assigned a binary label
of correct or incorrect.
3
For the purposes of this multimodal study, 238 of the 870 narratives were
excluded due to technical issues that had occurred with the eye tracking or audio capture equipment,
or because the physicians had provided no confidence values for their diagnoses. The remaining 632
narratives were used for the analysis and experimentation reported on in this paper.
3.1 Case Studies towards Understanding Physicians? Confidence and Correctness
The physicians tended to evaluate their confidence towards the upper end of the spectrum, with a me-
dian of 70% confident over all narratives. But diagnostic confidence may be affected by many factors,
including professional experience, case difficulty, and personality. We examine both individual images
and physicians at the extremes of confidence to gain insight into the relationship between confidence and
correctness in the dataset. Table 1 summarizes information for the three image cases that received the
2
Some transcription imperfections may occur.
3
A limited number of narratives in the dataset were labeled half correct if one of two final diagnoses given was correct, and
partially correct if the final diagnosis was too broad. Here, we consider half to be correct, because in such cases the correct
diagnosis was still identified, but partial to be incorrect, because the correct diagnosis was technically not identified.
1720
... um two ... pa- ... pink to purple
macules ... on the ... volar wrist
differential diagnosis ... um fixed
drug eruption ... bites ... urticaria
... uh ... diagnosis fixed drug erup-
tion percent certainty fifty percent
next ...
(a) Sample verbal description. Ellipses
(?...?) show pauses.
(b) Sample eye movement visualization. Circles represent fixations, where the
center is the point of fixation and the radius is proportional to the time fixating at
that point. Lines represent saccades (movements) between fixation points.
Figure 2: Sample verbal description and eye movements for one narrative. The final diagnosis is correct
and the physician was 50% confident.
Confidence Conf. % Correct Rank
Highest
100 100 2
90 100 5
90 100 1
Lowest
50 24 25
50 35 29
45 0 20
Table 1: Images receiving highest and lowest me-
dian confidence values. Difficulty ranking pro-
vided by a dermatology expert with 1 reflecting
the easiest image and 30 the most difficult.
Confidence Conf. % Correct Exp.
Highest
90 53 R
85 50 A
85 41 R
Lowest
38 39 A
30 48 R
15 37 R
Table 2: Most and least confident physicians by
median confidence values given over all images.
The last column shows experience level: experi-
enced attending (A) or resident (R) physician.
highest median confidence values and the three that received the lowest. A domain expert (dermatolo-
gist and clinical educator) who was not a subject in the experiment gave each image a unique difficulty
ranking from 1 to 30, where the image ranked number 1 was considered the easiest to support a correct
diagnosis, and 30 the most difficult. As expected, the highest confidence images were among the easiest,
and vice versa. Accordingly, the higher confidence images were correctly diagnosed by every physician,
while those receiving the lowest confidence were correctly diagnosed much less often. The negative
correlation between image difficulty and median physician confidence was significant using Spearman?s
rank correlation (r
s
= ?0.544, p < 0.005). In other words, higher levels of case difficulty were associ-
ated with lower levels of physician confidence. In contrast, examination of the most and least confident
physicians yields less intuitive results. The physicians with the highest and lowest median confidence
values are shown in the top and bottom halves of Table 2, respectively. Notably, each of the two groups
contained both resident dermatologists-in-training and attending physicians with careers spanning mul-
tiple decades. Also, the most confident physicians were only correct roughly half of the time, and the
least confident physicians? correctness appears quite similar. While this may reflect the sample size, the
observation is interesting nonetheless. Clearly, this points to how complicated diagnostic self-awareness
is, and how potentially useful it would be to computationally infer a physician?s self-awareness for diag-
nostic cases based on their behaviors.
1721
3.2 Confidence Binning
Nearly all confidence values given were multiples of five, or simply numbers close to 100, such as 99%.
4
This makes discretization preferable to using real-numbered values for confidence. Additionally, the
analyses in Section 3.1 revealed patterns of over- or underconfidence in individual physicians. What this
indicates is that ?high? and ?low? confidence involve different numerical values in the minds of different
physicians. This subjectivity could be problematic in doctor-patient interactions and it adds complexity
for predictive modeling involving confidence. To explore the impact, we devise two alternative binary
binning schemes: generalized bins, based on the performance of all physicians in the dataset, and per-
sonalized bins, based on each individual physician?s performance in the training data only. In terms of
application, consider a diagnostic support system which could establish a history for each physician who
uses it. Such a system could implement a generalized binning scheme and predictive model for new
users, and later, after learning from repeated exposure to a given physician, switch to a model based on
that physician?s individual performance. In addition, binning choice may be influenced by context: in a
clinical tutoring system, it may be preferable to compare learners to experienced physicians as a target
population. For the generalized binning scheme, a confidence value greater than or equal to the median
over all physicians is considered high, while a value below is considered low. This results in a slight
imbalance towards high confidence (56% of narratives).
5
We construct the personalized binning scheme
similarly, but using a given physician?s own median confidence in the training data as the dividing line.
In this case, high confidence accounts for 58% of the narratives, similar to that of the generalized bins.
Calling a physician?s median confidence high lets us better distinguish the problem cases: cases of under-
confidence should be strictly less than their ?typical? confidence, while cases of overconfidence should
be at or above typical. The binning scheme used does not affect the correctness value for each narrative,
but it does change the distribution of high and low confidence, with the generalized scheme favoring
over- and underconfidence, and the personalized scheme favoring appropriate confidence. Arguably, the
latter is a better reflection of the expected: over- and underconfidence as the minority classes.
4 Approach and Methodology
There are many ways to approach the problem of predicting physicians? diagnostic self-awareness. Here
we formulate two classification problems, each tested under both binning schemes, yielding a total of
four classification models. We also outline the performance evaluation experiments for the models.
4.1 Classification Problems
We define two classification problems based on the chart in Figure 1 (above). First, we define Confidence
Only, which ignores correctness (the horizontal dimension of Figure 1) and predicts only confidence as
a binary high or low. Intuitively, low confidence might be considered a warning sign for a diagnosis,
alerting a physician to seek additional insight or information.
6
This first problem was used as a stepping
stone to explore and better understand confidence, before incorporating correctness. Next, we define
Confidence & Correctness, which relates confidence with the correctness of the diagnosis (considering
all four quadrants in Figure 1, individually) to better address the more problematic, but interesting, cases.
Distinguishing these four classes could be of use to intelligent tutoring or clinical support systems, which
could respond differently to over- or underconfident users. In general, the full separation of these classes
could ultimately allow for deeper analysis of physician self-awareness.
4.2 Model Evaluation
Before any development took place, the 632 narratives were randomly divided into three subsets: 442
(70%) for training (dev-train), 95 (15%) for testing during development and tuning (dev-test), and 95
4
There were only a few exceptions: one physician gave three values of 3%, another gave a 33% and a 66% (rounded down
from ?two-thirds?), and a third gave a 33%. The latter three cases could also seem intuitive depending on how many conditions
were listed in the differential diagnosis. For example, 66% might indicate that one disease seemed twice as likely as a another.
5
Other simple binning schemes dividing up the 0-100% range were explored, but this binary version allowed for a more
systematic approach to both generalized and personalized binning, without sacrificing performance.
6
Normally, a physician would likely administer tests after the differential diagnosis, before reaching a final diagnosis.
1722
(15%) for final summative evaluation after all development was completed (heldout-test). All three
subsets have similar class distributions. Each of the four classification models were evaluated in two
ways: (1) by training the model on the union of the dev-train and dev-test sets and testing on the heldout-
test set, and (2) by running 50 randomized iterations of 10-fold cross-validation on the entire collection
of 632 narratives. The first evaluation experiment addresses the problem of overfitting by excluding the
heldout-test set from all development, while the second addresses the problem of sampling bias in the
initial set divisions. The results are described in Section 5.2.
5 Models and Results
Here we describe the development and performance of each of the four computational models outlined
in Section 4. We report on logistic regression, which had the best performance in all metrics for all
experiments, after dimensionality reduction (see Section 5.1). The feature selection and modeling was
implemented in Python with the scikit-learn machine learning library (Pedregosa et al., 2011).
5.1 Feature Extraction and Selection
A total of 60 features were examined (see Table 3). The features represented three modalities, moti-
vated by the task the physicians performed and knowledge about dimensions of clinical expertise in this
domain: verbal, composed of lexical, prosodic, and structural features of the narratives; eye movement,
consisting of features of fixations and saccadic eye movements; and truly multimodal features, consisting
of overlapping or simultaneously occurring features from the other two modalities, to reflect integrated
multimodal semantics. Continuing with the theme of personalization, we also created a fourth category
of personal features, with demographics of the physician and statistics about their confidence and cor-
rectness in the training data, in order to model their ?past? performance. The latter simulates how a
system could learn from experience with a particular physician.
As discussed in Section 2, verbal features of confidence have been studied before, and many of the
verbal features used here are inspired by previous work. Some verbal features are based on word choice,
such as amplifiers (e.g. definitely, sure) and modals (e.g. could, might),
7
while other have to do with
silences (or pauses) or prosody. The eye movement and multimodal features are mostly concerned with
fixations, as it seems intuitive that fixation may be associated with thoughtfulness about a particular area
of the image, which may in turn reflect a physician?s confidence.
Initial feature selection was performed on the development data (dev-train and dev-test) using
scikit-learn?s random forest ensemble classifier. This allowed for human-friendly inspection of
useful features. Random forests (Breiman, 2001) are an ensemble method in which numerous decision
trees are constructed, each trained on a randomized subset of the development data, which allows for the
utility of features to be evaluated on many sub-distributions of the data. The importance of a feature can
then be approximated as the sum of the error reduction at each node that splits on that feature, weighted
by the population size at that node. This reflects the fact that features used near the root of the tree often
handle a larger number of individuals. The importance values for all features will sum to 1. We consider
any feature that appeared in the top 20 of the ranked features for any model to be important, and all such
types of features are marked in bold in Table 3. Interestingly, the useful features for all classification
models were almost the same, with a few transpositions in the ordering. The exception was past confi-
dence, which was useful under generalized, but disappeared under personalized, as expected, since the
personalized scheme effectively normalizes each physician?s confidence values.
Interpreting the results for the verbal features, silence duration (statistics about the durations of all
silences) and the duration of narrative were most useful. Intuitively, this may relate to thoughtfulness or
contemplation. Additionally, words per second, or speech rate, was also useful, again perhaps relating to
more careful or thorough inspection/diagnosis. As discussed earlier, ties between speech and confidence
have been well-studied, while eye movements are underreported. It seems intuitive that eye movement
7
Such word-choice features were mostly based on lexical lists, and some overlap may occur. The cutaneous
conditions feature contained multiword expressions. These could be improved by using resources such as UMLS
(http://www.nlm.nih.gov/research/umls/) or WordNet (http://wordnet.princeton.edu/).
1723
Verbal (29)
Duration of narrative
Number of silences
Silence duration (?, ?, ?)
Duration of initial silence
Number of filled pauses
Word type-token ratio
Words per second
Cutaneous conditions (n, %)
Pronouns 1st (n, %)
Pronouns 3rd (n, %)
Modals (n, %)
Amplifier words (n, %)
Speculative words (n, %)
Negations (n, %)
Pitch (m, M , ?)
Intensity (m, M , ?)
Eye movement (11)
Fixation duration (?, ?, ?) Number of fixations
Saccade duration (?, ?, ?) % image area fixated
Saccade amplitude (?, ?, ?)
Multimodal (14)
% of initial silence time fixating
% of total silent time fixating
% of total fixation time silent
Words per second during fixation
Pitch during fixations (?, range)
Intensity during fixations (?, range)
Pitch of filled pauses (m, M , ?)
Intensity of filled pauses (m, M , ?)
Personal (6)
Attending vs. Resident Past correctness
Years of experience
Past confidence (m, M , ?)
Table 3: Features examined for classification (60 total), grouped by modality. Symbols in parentheses
indicate statistics over all occurrences of a feature in a narrative: raw count (n), raw count divided by
the total number of words (%), sum (?), mean (?), standard deviation (?), min (m), max (M ), range
(range). Useful features are boldfaced. If a feature has multiple statistics, the useful ones are underlined.
features may be more related to correctness. For example, the most useful eye movement feature was
% image area fixated, computed using a grid overlaid onto the image. If more of the image was fixated
upon, then it may have contained more areas of interest, or more visual evidence may have been sought,
which may also be related to case difficulty. Similarly, features of saccade amplitude (the angle of a
saccadic eye movement) may reflect physicians feeling a need to explore additional visual evidence by
switching focus between distant areas in an image. It is not surprising that the useful individual features
from verbal and eye movement modalities were also useful when combined as multimodal features. In
particular, simultaneous silence and fixation were the most useful, which again might indicate contem-
plation and analytical cognitive processing. This suggests that expression of confidence and diagnostic
self-awareness is at least partially a multimodal phenomenon.
Although the random forest method could be used for dimensionality reduction, we instead use Princi-
ple Component Analysis (PCA) in evaluation below, as it gave better performance gains in development.
The purpose of the random forest method was to examine which verbal, eye movement, and multimodal
features were most informative for classification, as we are interested in understanding how these modal-
ities relate to confidence and correctness. The latent features resulting from PCA are linear combinations
of the features, and thus would not allow for such inspection. The number of PCA components was
optimized for classification accuracy in cross-validation for each of the four classification models. Each
problem had a different number of principal components, indicating that both the binning scheme and the
classification problem type affected which features were identified as more collectively discriminative
by PCA.
5.2 Results and Evaluation
Heldout narratives We addressed the problem of overfitting by withholding 15% (n = 95) of the
narratives as an unseen final evaluation set. All predictive models performed well above their respective
majority class baselines (see Table 4). The Confidence Only models were able to reach higher accuracy,
precision, and recall than the joint Confidence & Correctness models. The exception is the accuracy
relative to baseline for personalized Confidence Only, which may be due to its higher baseline. As men-
tioned in Section 3.2, the generalized binning scheme is biased towards over- and underconfidence, and
the personalized towards appropriate confidence. The per-class metrics (not shown here) reflect this fact,
with overconfidence having higher precision and recall under generalized binning than under personal-
ized. Additionally, under the personalized scheme underconfidence is particularly underrepresented and
thus more difficult to predict.
1724
Binning Problem N Majority Class % BL % Acc. P R
Generalized
Conf. Only 2 High Confidence 53 76 (+23) 0.76 0.76
Conf. & Corr. 4 Overconfidence 37 53 (+16) 0.42 0.42
Personalized
Conf. Only 2 High Confidence 65 77 (+12) 0.75 0.73
Conf. & Corr. 4 Appropriate High 37 53 (+16) 0.38 0.42
Table 4: Performance metrics for the heldout-test set under each binning scheme with logistic regression
and PCA. All four models performed well above the majority class baselines (% BL) of their respective
problems (each with N many class labels). Precision (P) and recall (R) are each macro-averaged.
Random cross-validation A potential drawback of the initial development strategy used here is that
the initial random splits may bias classification models. To address this problem, after the heldout testing,
50 randomized iterations of 10-fold cross-validation were performed on the total collection of narratives,
the results of which are in Table 5. The personalized binning scheme was designed to mimic a sys-
tem that could adapt to a physician?s performance history, and thus the statistics used for personalized
confidence binning were recomputed on the training data within each individual cross-validation fold.
It is therefore not possible to establish a baseline for the personalized confidence binning outside of
a given fold. Instead, we take the mean of the percent accuracy above baseline from each test fold
(
1
k
?
k
i=1
(accuracy
i
? baseline
i
)). All models performed well above their respective baselines, which
is in line with observations from heldout testing.
Binning Generalized Personalized
Problem C.O. C&C C.O. C&C
Acc. above
baseline
+14 +9 +13 +12
Precision 0.70 0.25 0.69 0.32
Recall 0.70 0.38 0.57 0.37
Table 5: Performance metrics for logistic re-
gression with 50 randomized iterations of cross-
validation using all narratives for Confidence Only
(C.O.) and Confidence & Correctness (C&C). We
average the accuracy above baseline from each in-
dividual fold. Precision and recall are each macro-
averaged for each problem.
Feature Generalized Personalized
modality C.O. C&C C.O. C&C
V +13 +9 +12 +11
E +7 +6 +11 +10
MM +7 +4 +6 +5
V+E +13 +9 +13 +11
V+MM +14 +8 +11 +11
E+MM +10 +6 +13 +11
V+E+MM +14 +9 +13 +12
Table 6: Modality study with cross-validation for
Verbal (V), Eye movement (E), and Multimodal
(MM) features, measured in accuracy above re-
spective baselines, averaged over all folds. Most
modality combinations equaled or slightly im-
proved on constituent modalities in isolation.
Modality study We also performed a study within the cross-validation testing to investigate the impact
of different feature modality combinations on classification (see Table 6). Importantly, the verbal modal-
ity alone was more powerful than the eye movement or multimodal features, but most combinations of
modalities resulted in slightly higher or equal accuracy compared to their isolated constituent modali-
ties. This suggests that, as we projected, considering multiple modalities of a physician?s behavior can
help reveal their confidence and self-awareness, but also that verbal features are the most informative,
likely since verbal expression is the primary means to tap into physicians? rich and tacit conceptual un-
derstanding of a diagnostic case. The multimodal features, which focused on combining verbal and eye
movement data, did not improve performance over baselines as much as the simple combination of the
individual verbal and eye movement features. One reason for this could be that a person?s speech and
eye movements are not perfectly temporally aligned (Vaidyanathan et al., 2012), and this asynchronous
relationship may affect the meaningfulness of our multimodal feature measurements. Additionally, these
eye movement features may be at a much finer spatial or temporal scale than the verbal features.
1725
6 Conclusions
This study examined a dataset of medical narratives consisting of verbal descriptions, eye movements,
and self-reported confidence values, and used it to model physicians? confidence in diagnosis, as well
as their diagnostic self-awareness. The Confidence Only problem involves the expression of confidence
based on clinicians? belief, but it is important to understand the relationship to clinicians? actual diag-
nostic performance. This distinction is key because, while predicting confidence alone is a stepping
stone, self-awareness is the ability to additionally align one?s confidence with unknown correctness,
which involves human intuitive and analytical reasoning (another topic of interest to the medical field,
see Hochberg et al. (2014)). Case studies of the most and least confident physicians revealed a com-
plex relationship between confidence and correctness, and highlighted the need for exploring clinical
self-awareness. We also defined a personalized binning scheme for physician confidence levels, taking
into account a physician?s past confidence when drawing the line between high and low confidence, and
compared this to a generalized binning scheme based on performance of all physicians. In tandem, these
approaches to confidence binning could be used by an intelligent diagnostic support system.
We incorporated previously unused eye movement information from this dataset, and introduced truly
multimodal features which directly combined physicians? verbal and eye movement behaviors. While
physicians? eye movement and multimodal features were not individually as powerful as verbal features,
combinations of the three groups mostly produced classification improvements that were slightly better
than, or at least as good as, their constituent feature groups in isolation. The best performance for the
majority of models was achieved by considering features from all three modalities. This suggests that
eye movements help convey confidence and diagnostic self-awareness. The multimodal features did not
help as much, which we believe is explained by the more flexible temporal relationship between speech
and eye movements in the human mind. We leave the multimodal alignment challenge to future work.
Some pitch features implemented without speaker-dependent analysis were useful for classification, but
future work may benefit from pitch feature representations that adapt to demographic variation. Another
area for future work beyond the scope of this study includes examining alternative ways of combining
confidence and correctness classes, such as merging the diagonals of Figure 1 into a binary classifica-
tion of appropriate vs. inappropriate (i.e. the union of over- and underconfidence). Such alternatives
may present additional challenges for classification, but could also provide benefits for simpler clinical
support applications that may not be concerned with differentiating all four classes.
Acknowledgements
This work was supported by a seed award, and its dissemination partially by a Kodak Endowed Chair
award, both from the Golisano College of Computing and Information Sciences at RIT. The original data
collection was supported by NIH grant 1 R21 LM01003901A1. The content is solely the responsibility
of the authors and does not necessarily represent the official views of the National Institutes of Health.
The authors also thank Rui Li, and appreciate the helpful comments from reviewers.
References
Eta S. Berner and Mark L. Graber. 2008. Overconfidence as a cause of diagnostic error in medicine. The American
Journal of Medicine, 121(5A):S2?S23.
Leo Breiman. 2001. Random forests. Machine Learning, 45:5?32.
Pat Croskerry. 2003. The importance of cognitive errors in diagnosis and strategies to minimize them. Academic
Medicine, 78(8):775?780, August.
Pat Croskerry. 2008. Overconfidence in clinical decision making. The American Journal of Medicine,
121(5A):S24?S29.
Pat Croskerry. 2009. A universal model of diagnostic reasoning. Academic Medicine, 84(8):1022?1028, August.
Charles P. Friedman, Guido G. Gatti, Timothy M. Franz, Gwendolyn C. Murphy, Frederic M. Wolf, Paul S. Heck-
erling, Paul L. Fine, Thomas M. Miller, and Arthur S. Elstein. 2005. Do physicians know when their diagnoses
are correct? Journal of General Internal medicine, 20:334?339, April.
1726
Albert Gatt and Patrizia Paggio. 2013. What and where: An empirical investigation of pointing gestures and de-
scriptions in multimodal referring actions. In Proceedings of the 14th European Workshop on Natural Language
Generation, pages 82?91, Sofia, Bulgaria, August 8-9.
Mark Graber, Ruthanna Gordon, and Nancy Franklin. 2002. Reducing diagnostic errors in medicine: What?s the
goal? Academic Medicine, 77(10):981?992, October.
Mark L. Graber, Nancy Franklin, and Ruthanna Gordon. 2005. Diagnostic error in internal medicine. Archives of
Internal Medicine, 165:1493?1499, July 11.
Limor Hochberg, Cecilia Ovesdotter Alm, Esa M. Rantanen, Caroline M. DeLong, and Anne Haake. 2014. Deci-
sion style in a clinical reasoning corpus. BioNLP 2014.
Jay Katz. 1984. Why doctors don?t disclose uncertainty. Hastings Center Report, 14:35?44.
Charles E. Kimble and Steven D. Seidel. 1991. Vocal signs of confidence. Journal of Nonverbal Behavior,
15:99?105.
Rui Li, Jeff Pelz, Pengcheng Shi, Cecilia Ovesdotter Alm, and Anne Haake. 2012a. Learning eye movement
patterns for characterization of perceptual expertise. In ETRA 2012 Proceedings of the Symposium on Eye
Tracking Research and Applications, pages 393?396, Santa Barbara, CA, March 28-30.
Rui Li, Jeff Pelz, Pengcheng Shi, and Anne Haake. 2012b. Learning image-derived eye movement patterns for
characterization of perceptual expertise. In Proceedings of CogSci 2012, pages 1900?1905.
Jackson Liscombe, Julia Hirschberg, and Jennifer J. Venditti. 2005. Detecting certainness in spoken tutorial
dialogues. In Proceedings of Interspeech 2005, pages 1837?1840, Lisbon, Portugal.
Wilson McCoy, Cecilia Ovesdotter Alm, Cara Calvelli, Jeff B. Pelz, Pengcheng Shi, and Anne Haake. 2012. Link-
ing uncertainty in physicians? narratives to diagnostic correctness. In Proceedings of the ACL-2012 Workshop
on Extra-Propositional Aspects of Meaning in Computational Linguistics (ExProM-2012), pages 19?27, Jeju,
Republic of Korea, 13 July.
Fabian Pedregosa, Gael Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Math-
ieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, Jake Vanderplas, Alexandre Passos, David Cour-
napeau, Matthieu Brucher, Matthieu Perrot, and Edouard Duchesnay. 2011. Scikit-learn: Machine learning in
Python. Journal of Machine Learning Research, 12:2825?2830.
Ver?onica P?erez-Rosas, Rada Mihalcea, and Louis-Phillippe Morency. 2013. Utterance-level multimodal sentiment
analysis. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages
973?982, Sofia, Bulgaria, August 4-9.
Heather Pon-Barry and Stuart M. Shieber. 2011. Recognizing uncertainty in speech. EURASIP Journal on
Advances in Signal Processing, 2011(251753).
Erika Rogers. 1996. A study of visual reasoning in medical diagnosis. In Proceedings of the Eighteenth Annual
Conference of the Cognitive Science Society, pages 213?218, La Jolla, California, 12-15 July.
Klaus R. Scherer, Harvey London, and Jared J. Wolf. 1973. The voice of confidence: Paralinguistic cues and
audience evaluation. Journal of Research in Personality, 7:31?44, June.
Vicki L. Smith and Herbert H. Clark. 1993. On the course of answering questions. Journal of Memory and
Language, 32(1):25?38.
Preethi Vaidyanathan, Jeff Pelz, Wilson McCoy, Cara Calvelli, Cecilia Ovesdotter Alm, Pengcheng Shi, and Anne
Haake. 2012. Visualinguistic approach to medical image understanding. In Proceedings of the AMIA 2012
Annual Symposium, Chicago, Illinois, November.
Kathryn Womack, Wilson McCoy, Cecilia Ovesdotter Alm, Cara Calvelli, Jeff B. Pelz, Pengcheng Shi, and Anne
Haake. 2012. Disfluencies as extra-propositional indicators of cognitive processing. In Proceedings of the
ACL-2012 Workshop on Extra-Propositional Aspects of Meaning in Computational Linguistics (ExProM-2012),
pages 1?9, Jeju, Republic of Korea, 13 July.
Kathryn Womack, Cecilia Ovesdotter Alm, Cara Calvelli, Jeff B. Pelz, Pengcheng Shi, and Anne Haake. 2013.
Markers of confidence and correctness in spoken medical narratives. In Proceedings of Interspeech 2013, pages
2549?2553, Lyon, France, August 25-29.
1727
LAW VIII - The 8th Linguistic Annotation Workshop, pages 129?138,
Dublin, Ireland, August 23-24 2014.
Towards Automatic Annotation of Clinical Decision-Making Style
Limor Hochberg
1
Cecilia O. Alm
1
Esa M. Rantanen
1
Qi Yu
2
Caroline M. DeLong
1
Anne Haake
2
1 College of Liberal Arts 2 College of Computing & Information Sciences
Rochester Institute of Technology
lxh6513|coagla|emrgsh|qi.yu|cmdgsh|anne.haake@rit.edu
Abstract
Clinical decision-making has high-stakes outcomes for both physicians and patients, yet little
research has attempted to model and automatically annotate such decision-making. The dual
process model (Evans, 2008) posits two types of decision-making, which may be ordered on
a continuum from intuitive to analytical (Hammond, 1981). Training clinicians to recognize
decision-making style and select the most appropriate mode of reasoning for a particular context
may help reduce diagnostic error (Norman, 2009). This study makes preliminary steps towards
detection of decision style, based on an annotated dataset of image-based clinical reasoning in
which speech data were collected from physicians as they inspected images of dermatological
cases and moved towards diagnosis (Hochberg et al., 2014). A classifier was developed based on
lexical, speech, disfluency, physician demographic, cognitive, and diagnostic difficulty features.
Using random forests for binary classification of intuitive vs. analytical decision style in physi-
cians? diagnostic descriptions, the model improved on the baseline by over 30%. The introduced
computational model provides construct validity for decision styles, as well as insights into the
linguistic expression of decision-making. Eventually, such modeling may be incorporated into
instructional systems that teach clinicians to become more effective decision makers.
1 Introduction
Diagnostic accuracy is critical for both physicians and patients, but there is insufficient training on clini-
cal decision-making strategy in medical schools, towards avoiding diagnostic error (Graber et al., 2012;
Croskerry & Norman, 2008). Berner and Graber (2008) estimate that diagnostic error in medicine occurs
at a rate of 5-15%, and that two-thirds of diagnostic errors involve cognitive root causes.
The dual process model distinguishes between intuitive and analytic modes of reasoning (Kahneman
& Frederick, 2002; Evans, 1989). Use of the intuitive system, while efficient, may lead to cognitive
errors based on heuristics and biases (Graber, 2009). Croskerry (2003) distinguished over 30 such biases
and heuristics that underlie diagnostic error, including anchoring, base-rate neglect, and hindsight bias.
Hammond?s (1981) Cognitive Continuum Theory proposes that decision-making lies on a continuum
from intuitive to analytical reasoning. Intuitive reasoning is described as rapid, unconscious, moderately
accurate, and employing simultaneous use of cues and pattern recognition (Hammond, 1981). Analytical
decision-making is described as slow, conscious, task-specific, more accurate, making sequential use of
cues, and applying logical rules (Hammond, 1996). Much reasoning is quasirational: between the two
poles of purely intuitive and purely analytical decision-making (Hamm, 1988; Hammond, 1981).
Cader et al. (2005) suggested that cognitive continuum theory is appropriate for the evaluation of
decision-making in medical contexts. The current study links to another work (Hochberg et al., 2014),
where the cognitive continuum was applied to physician decision-making in dermatology. Decision style
was manually assessed in physician verbalizations during medical image inspection. Figure 1 shows the
4-point annotation scheme, ranging from intuitive to analytical; the two intermediate points on the scale
reflect the presence of both styles, with intuitive (BI) or analytical (BA) reasoning more prevalent.
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
129
Figure 1: Four narratives along the intuitive-analytical decision-making continuum, for which annotators
agreed on their labels, where I=Intuitive, BI=Both-Intuitive, BA=Both-Analytical, A=Analytical. The
narratives were produced by different physicians for the same image case (left, used with permission
from Logical Images, Inc.), and all four physicians were correct in their final diagnosis. (Confidence
mentions were removed in narratives presented to annotators, to avoid any potential bias.)
This work describes computational modeling for automatic annotation of decision style using this
annotated dataset, on the basis of linguistic, speaker, and image case features.
1.1 Contributions
To date, this appears to be the first study attempting to computationally predict physician decision style.
Similar to the case of affect, automatic annotation of decision style can be characterized as a subjective
natural language processing problem (Alm, 2011). This adds special challenges to the modeling process.
Accordingly, this work details a thorough process for moving from manual to automatic annotation.
This study contributes to cognitive psychology, annotation methodology, and clinical computational
linguistic analysis. Methodologically, the study details a careful process for selecting and labeling manu-
ally annotated data for modeling in the realm of subjective natural language phenomena, thus addressing
the need for their characterization (Alm, 2011). Theoretically, acceptable annotator reliability on deci-
sion style, along with successful computational modeling, will lend construct validity to the dual process
model. From a linguistic perspective, the identification of discriminative features for intuitive and analyt-
ical reasoning provides a springboard for further studying decision-making using language as a cognitive
sensor.
Practically, prediction of decision style would also be useful for determining whether individuals are
using the appropriate style for a particular task, based on analyses linking decision style to task perfor-
mance. Importantly, detection of decision style from observable linguistic behaviors allows for objective
measurement that avoids biases present in self-report surveys (Sj?oberg, 2003; Allinson & Hayes, 1996).
130
2 Data and Manual Decision Style Annotation
The annotated corpus used in this study was introduced in Hochberg et al. (2014), which also discusses
the manual annotation scheme and annotator strategies in greater detail. For clarity, the dataset and
annotation scheme are described here briefly.
The dataset consisted of spoken narratives collected from 29 physicians as they examined 30 clinical
images of dermatological cases, for a total of 867
1
narratives. Physicians described their reasoning
process as they advanced towards a diagnosis, and they also estimated their confidence
2
in their final
diagnosis. Narratives were assessed for correctness (based on final diagnoses) and image cases were
evaluated for difficulty by a practicing dermatologist.
3
For the manual annotation of decision style, anonymized text transcripts of the narratives were pre-
sented to two annotators with graduate training in cognitive psychology.
4
Analytical reasoning considers
more alternatives in greater detail. Thus, it was expected to be associated with longer narratives, as
Figure 1 illustrates. Therefore, annotators were asked not to use length as a proxy for decision style.
Narratives were randomized to ensure high-quality annotation, and 10% of narratives were duplicated
to measure intra-annotator reliability. For analysis, primary ratings were used, and secondary ratings (on
duplicated narratives) were used to measure intra-annotator consistency. The kappa scores and proportion
agreement, detailed below, motivate the labeling and data selection process used for classification and
modeling in this work.
Figure 2 shows the distribution of annotation labels for both annotators, respectively, for the whole
dataset, on the original 4-point scale. In comparison, Figure 3 shows the annotators? distributions across
a collapsed 2-point scale of intuitive vs. analytical, where, for each annotator, narratives labeled BI were
assigned to I and those labeled BA assigned to A.
Figure 2: The distribution of ratings among the
decision-making spectrum, on a 4-point scale.
Figure 3: The distribution of ratings among the
decision-making spectrum, on a 2-point scale.
Annotator agreement was well above chance for both the 4-point (Figure 4) and 2-point (Figure 5)
scales. Notably, the annotators were in full agreement or agreed within one rating for over 90% of nar-
ratives on the original 4-point scale. This pattern of variation reveals both the fuzziness of the categories
and also that the subjective perception of decision-making style is systematic.
Annotator agreement was also assessed via linear weighted kappa scores (Cohen, 1968). As shown in
Figure 6, inter-annotator reliability was moderate, and intra-annotator reliability was moderate (Annota-
tor 2) to good (Annotator 1); see Landis and Koch (1977) and Altman (1991).
Since both proportion agreement and kappa scores were slightly higher for the 2-point scale, the
automatic annotation modeling discussed below used this binary scale. In addition, the distribution of
1
One narrative was excluded due to extreme brevity, and two physicians each skipped an image during data collection.
2
For consistency, this paper uses the term confidence, treated as interchangeable with certainty and similar synonymous
expressions used by clinicians in the medical narratives, such as sure, certain, confident, just certainty percentages, etc.
3
Some imperfections may occur in the data, e.g., in transcriptions, difficulty ratings, or annotations (or in extracted features).
4
Annotator instructions included decision style definitions, a description of the 4-point scale and example narratives. Anno-
tators were asked to focus on decision style as present in the text rather than speculate beyond it.
131
Figure 4: Inter- and intra-annotator reliability for
the 4-point scheme, by proportion agreement. The
reference line shows chance agreement (25%).
(A1=Annotator 1; A2=Annotator 2).
Figure 5: Inter- and intra-annotator reliability for
the 2-point scheme, by proportion agreement. The
reference line shows chance agreement (50%).
(A1=Annotator 1; A2=Annotator 2).
Figure 6: Annotator reliability, as measured by linear weighted kappa scores on the 2-pt and 4-pt scales.
data across binary classes was more balanced compared to the 4-point scale, as shown by the contrast
between Figures 2 and 3, further making it a suitable starting point for computational modeling.
2.1 Data Selection and Labeling for Computational Modeling
This section details the systematic method used to select data for model development. The goal of the
work was to develop a computational model that could automatically annotate narratives as intuitive
or analytical, based on lexical, speech, disfluency, physician demographic, cognitive, and diagnostic
difficulty features. The study employed a supervised learning approach, and since no real ground truth
was available, it relied on manual annotation of each narrative for decision style. However, annotators did
not always agree on the labels, as discussed above. Thus, strategies were developed to label narratives,
including in the case of disagreement (Figure 7).
The dataset used for modeling consisted of 672 narratives.
5
Annotators were in full agreement for 614
ratings on the binary scale of intuitive vs. analytical (Figure 8).
6
Next, 49 narratives were assigned a
binary label based on the center of gravity of both annotators? primary ratings (Figure 9). For example,
if a narrative was rated as Intuitive and Both-Analytical by Annotators 1 and 2, respectively, the center of
gravity was at Both-Intuitive, resulting in an Intuitive label. Finally, 9 narratives were labeled using the
annotators? secondary ratings,
7
available for 10% of narratives, to resolve annotator disagreement.
8
5
Within a reasonable time frame, the text data are expected to be made publicly available.
6
Excluding also narratives lacking confidence or correctness information.
7
Collected to measure intra-annotator reliability.
8
For example, if the primary ratings of Annotator 1 and Annotator 2 were Both-Analytical and Both-Intuitive, respectively,
but both annotators? secondary ratings were intuitive (e.g., Both-Intuitive or Intuitive), the narrative was labeled Intuitive.
132
Narratives with disagreements that could not be resolved in these ways were excluded. As perception
of decision-making style is subject to variation in human judgment, this work focused on an initial
modeling of data which represent the clearer-cut cases of decision style (rather than the disagreement
gray zone on this gradient perception continuum). From the perspective of dealing with a subjective
problem, this approach enables an approximation of ground truth, as a validation concept.
9
Figure 7: Narrative labeling pipeline. 614 narratives were labeled due to full binary agreement, and
center-of-gravity and secondary rating strategies were used to label an additional 58 narratives for which
annotators were not in agreement.
Figure 8: Demonstration of initial corpus labeling,
in which 614 narratives were labeled on the basis
of binary agreement.
Figure 9: Demonstration of center-of-gravity
strategy, used to label an additional 49 narratives.
2.2 Relationship Between Physicians? Diagnostic Correctness and Decision Style
Using the 672 narratives selected for modeling, Table 1 shows the relationship of physicians? diagnostic
correctness by decision style (intuitive vs. analytical on a binary scale).
Correct Incorrect Total
Intuitive 158 186 344
Analytical 106 222 328
Total 264 408 672
Table 1: Distribution of diagnostic correctness by decision style.
Overall, there was a slightly higher prevalence of intuitive reasoning, and there were more incorrect
than correct diagnoses.
10
Table 1 also suggests a relationship between correctness and decision-making
style, where for correct diagnoses, intuitive reasoning was more dominant. The opposite trend held
for incorrect diagnoses: analytical reasoning was more frequent. Indeed, a chi-square test revealed a
significant relationship between correctness and decision style, ?
2
(1, N = 672) = 13.05, p < 0.01.
This pattern is in line with claims that intuitive reasoning is linked to better performance when much
information is to be processed; mechanisms of intuitive reasoning and pattern recognition allow individ-
uals to overcome the limitations of their working memory (Evans, 2008). However, others have linked
intuitive reasoning to decreased diagnostic accuracy, as intuitive reasoning may be prey to inappropriate
9
Modeling of fuzzier, hard to label data, is left to future work. One possible approach is to learn the labels by using a
k-nearest neighbor classifier, which identifies the most similar narratives and uses their labels to make the prediction.
10
Contributing factors to the proportion of incorrect diagnoses might include case difficulty levels in the experimental sce-
nario, and that physicians did not have access to additional information, such as patient history or follow-up tests.
133
heuristics and biases (Croskerry, 2003). Viewed from the perspective of cognitive continuum theory, the
higher prevalence of incorrect diagnoses may be due to the use of decision styles that were not suited to
the task demands of the particular case (Hammond, 1981). Finally, it might be the case that diagnostic
difficulty was a moderating variable, where physicians preferred intuitive reasoning for less challenging
cases, and analytical reasoning for more difficult cases.
3 Methods
A model was developed for the binary prediction case (intuitive vs. analytical), since the 2-point rating
scheme had slightly higher annotator agreement (see Section 2). Model development and analysis were
performed using the WEKA data mining software package (Hall et al., 2009). The dataset was split into
80% development and 20% final test sets (Table 2).
11
Parameter tuning was performed using 10-fold
cross-validation on the best features in the development set.
12
80% Development Set 20% Final Test Set
Intuitive 276 (51%) 68 (51%)
Analytical 263 (49%) 65 (49%)
Total 539 133
Table 2: Class label statistics.
3.1 Features
Three feature types were derived from the spoken narratives to study the linguistic link to decision-
making style: lexical (37), speech (13), and disfluency (3) features. Three other feature types relevant to
decision-making were demographic (2), cognitive (2), and difficulty (2) features (Table 3).
Type Feature Description / Examples
Lexical
exclusion but, without
inclusion both, with
insight think, know
tentative maybe, perhaps
cause because, therefore
cognitive process know, whether
. . .
Speech
speech length number of tokens
pitch min, max, mean, st. dev., time of min/max
intensity min, max, mean, st. dev., time of min/max
Disfluency
silent pauses number of
fillers like, blah
nonfluencies uh, um
Demographic
gender male, female
status resident, attending
Cognitive
confidence percentage
correctness binary
Difficulty
expert rating ordinal ranking
% correctness/image percentage
Table 3: Six feature types. The listed lexical features are a sub-sample of the total set.
Relevant lexical features were extracted with the Linguistic Inquiry and Word Count (LIWC) software,
which calculates the relative frequency of syntactic and semantic classes in text samples based on val-
11
This split rests on the assumption that physicians may share common styles. Thus, the testing data will represent different
physicians, but the styles themselves have been captured by the training data so that they can be correctly classified; the same
rationale can be applied to image cases. To further investigate the phenomenon and identify the degree of inter- and intra-
individual variation in decision style, future work could experiment with holding out particular images and physicians.
12
In Section 4.1, parameters were tuned for each case of feature combinations in a similar way.
134
idated, researched dictionaries (Tausczik & Pennebaker, 2010). Disfluency features were silent pauses,
and the frequency of fillers and nonfluencies as computed by LIWC. Speech features are in Table 3.
Besides linguistic features, three additional groups of features were included, with an eye towards
application. Demographic features were gender and professional status, while cognitive features were
physician confidence in diagnosis and correctness of the final diagnosis. Difficulty features consisted
of an expert-assigned rank of diagnostic case difficulty, and the percent of correct diagnoses given by
physicians for each image, calculated on the development data only. In an instructional system, a trainee
could input a demographic profile, and the system could also collect performance data over time, while
also taking into account stored information on case difficulty when available. This information could
then be used in modeling of decision style in spoken or written diagnostic narratives.
3.2 Feature Selection
WEKA?s CfsSubsetEval, an attribute evaluator, was used for feature selection,
13
using 10-fold cross-
validation on the development set only. Features selected by the evaluator in at least 5 of 10 folds were
considered best features. The best features from the entire feature set were: 2nd person pronouns, con-
junctions, cognitive process, insight, cause, bio, and time words, plus silent pauses, speech length, time of
min. pitch, standard deviation of pitch, time of min. intensity, and difficulty: percent correctness/image.
Feature selection, using the same attribute evaluator, was also performed on only the lexical fea-
tures, which could be a starting point for analysis of decision-making style in text-only data. The best
lexical features
14
included conjunctions, cause, cognitive process, inclusion, exclusion, and perception
words. These lexical items seem associated with careful examination and reasoning, which might be
more present in analytical decision-making and less present in intuitive decision-making. Some cate-
gories, especially inclusion (e.g., with, and), exclusion (e.g., but, either, unless), and cause words (e.g.,
affect, cause, depend, therefore), seem particularly good representatives of logical reasoning and justifi-
cation, a key feature of analytical reasoning. But as shown in the next section, when available, speech
and disfluency information is useful, and potentially more so than some lexical features.
15
4 Results and Discussion
Table 4 lists the results for the Random Forest (Breiman, 2001) and Logistic Regression (Cox, 1972)
classifiers on the best features (as selected from all features) on the final test set, after training on the
development set. These results suggest that decision style can be quantified and classified on a binary
scale; the percent error reduction (compared to baseline performance) for both classifiers is substantial.
Classifier %Acc %ER Pr Re
Random Forest 88 76 88 88
Logistic Regression 84 67 84 84
Majority Class Baseline 51 ? ? ?
Table 4: Performance on final test set; reduction in error is calculated relative to majority class baseline.
Precision and recall are macro-averages of the two classes.
4.1 Feature Combination Exploration
A study of feature combinations was performed on the final test set with Random Forest (Table 5) to
explore the contribution of each feature type towards automatic annotation. The best performance was
achieved after applying feature selection on all features. Lexical and disfluency features were useful for
determining decision style, and the best linguistic features (chosen with feature selection) were slightly
more useful. These latter feature types improve on the performance achieved when considering only
13
With BestFirst search method.
14
Best lexical features were: function words, singular pronouns, prepositions, conjunctions, quantifiers, and cognitive pro-
cess, cause, discrepancy, tentative, inclusion, exclusion, perception, see, bio, motion, time, and assent words.
15
Feature selection was also performed only on the linguistic (lexical, speech, and disfluency) features as a group. The best
features of these types were: second personal pronouns, conjunctions, cognitive process, insight, cause, bio, and time words;
silent pauses; and speech length, time of minimum pitch, standard deviation of pitch, and time of minimum intensity. They
could represent a starting for point for analyzing speech data not enhanced by additional speaker and task information.
135
speech length and silent pauses, which were apparent characteristics to the human annotators and among
the best features (see Section 3.2.).
Demographic features improved somewhat over the baseline, indicating an association between gen-
der, professional status, and decision-making, and adding cognitive features increased performance. Im-
portantly, overall these findings hint at linguistic markers as key indicators of decision style.
Features Accuracy
All* 88
All 85
(Lexical + Speech + Disfluency)* 86
Lexical + Speech + Disfluency 84
Lexical + Disfluency 84
Only speech length and silent pauses 81
Disfluency 79
Lexical 77
Demographic + Cognitive 68
Demographic 64
Majority Class Baseline 51
Table 5: Performance on final test set. Star (*) indicates the use of feature selection (see Section 3.2.)
4.2 Limitations
In this study, doctors diagnosed solely on the basis of visual information (e.g., without tests or follow-
up), so their speech may reflect only part of the clinical reasoning process. In addition, most decision
style ratings on the 4-point scale were in the distribution center (Figure 2), so the binary labels used in
the study only partially reflect purely intuitive or purely analytical reasoning. However, since clinician
reasoning in the current dataset can be reliably measured by human and computational classification,
linguistic features of decision style must be present. Finally, the LIWC software used for lexical features
matches surface strings rather than senses; future work might operate on the sense rather than token level.
5 Related Work
Lauri et al. (2001) asked nurses in five countries to rate statements representative of intuitive or analytical
decision-making on a 5-point scale. They found that reasoning varies with context and that styles in the
middle of the cognitive continuum predominate. In this work, annotation ratings were prevalent in the
middle of the spectrum. Thus, both studies endorse that most decision-making occurs in the central part
of the continuum (Hamm, 1988; Hammond, 1981). Womack et al. (2012) proposed that silent pauses in
physician narration may indicate cognitive processing. Here, silent pauses were also important, perhaps
because analytical decision-making may recruit more cognitive resources than intuitive decision-making.
6 Conclusion
This work suggests that decision style is revealed in language use, in line with claims that linguistic
data reflect speakers? cognitive processes (Pennebaker & King, 1999; Tausczik & Pennebaker, 2010).
Theoretically, the study adds validity to the dual process and cognitive continuum theories. Methodolog-
ically, it articulates a method of transitioning from manual to automatic annotation of fuzzy semantic
phenomena, including label adjudication and data selection for computational modeling. Future work
may investigate modeling of the 4-point decision scale, as well as whether particular variables, such as
difficulty or expertise, mediate the relationship between diagnostic correctness and decision style.
Practically, automatic detection of decision style is useful for both clinical educational systems and
mission-critical environments. Clinical instructional systems can assess whether trainees are using the
appropriate style for a particular task (Hammond, 1981), and they can help users determine and attend to
their own decision styles, towards improving diagnostic skill (Norman, 2009). Finally, in mission-critical
environments, linguistic markers of decision-making style may be used to determine the optimal modes
of reasoning for a particular task in high-stakes human factors domains.
136
Acknowledgements
This work was supported by a COLA Faculty Development grant, Xerox award, and NIH award R21
LM01002901. Many thanks to the annotators and reviewers. This content is solely the responsibility of
the authors and does not necessarily represent the official views of the National Institutes of Health.
References
Allinson, C. W., & Hayes, J. (1996). The cognitive style index: A measure of intuition-analysis for organizational
research. Journal of Management Studies, 33(1), 119-135.
Alm, C. O. (2011, June). Subjective natural language problems: Motivations, applications, characterizations, and
implications. Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human
Language Technologies: Short papers-Volume 2 (pp. 107-112). Association for Computational Linguistics.
Altman, D. (1991). Practical statistics for medical research. London: Chapman and Hall.
Berner, E. S., & Graber, M. L. (2008). Overconfidence as a cause of diagnostic error in medicine. American
Journal of Medicine, 121, S2-S23.
Breiman, L. (2001). Random forests. Machine Learning, 45(1), 5-32.
Cader, R., Campbell, S., & Watson, D. (2005). Cognitive continuum theory in nursing decision-making. Journal
of Advanced Nursing, 49(4), 397-405.
Cohen, J. (1968). Weighted kappa: Nominal scale agreement provision for scaled disagreement or partial credit.
Psychological Bulletin, 70(4), 213-220.
Cox, D. R. (1972). Regression models and life tables. Journal of the Royal Statistical Society, Series B, 34(2),
187-220.
Croskerry, P. (2003). The importance of cognitive errors in diagnosis and strategies to minimize them. Academic
Medicine, 78, 775-780.
Croskerry, P., & Norman, G. (2008). Overconfidence in clinical decision making. The American Journal of
Medicine, 121(5), S24-S29.
Evans, J. (1989). Bias in human reasoning: Causes and consequences. Hillsdale, NJ: Erlbaum.
Evans, J. (2008). Dual-processing accounts of reasoning, judgment and social cognition. Annual Review of Psy-
chology, 59, 255-278.
Graber, M. (2009). Educational strategies to reduce diagnostic error: Can you teach this stuff? Advances in Health
Sciences Education, 14, 63-69.
Graber, M. L., Kissam, S., Payne, V. L., Meyer, A. N., Sorensen, A., Lenfestey, N., ... & Singh, H. (2012).
Cognitive interventions to reduce diagnostic error: A narrative review. BMJ Quality & Safety, 2(7), 535-557.
Hall, M., Frank, E., Holmes, G., Pfahringer, B., Reutemann, P., & Witten, I. H. (2009). The WEKA data mining
software: An update. ACM SIGKDD Explorations Newsletter, 11(1), 10-18.
Hamm, R. M. (1988). Clinical intuition and clinical analysis: Expertise and the cognitive continuum. In J. Dowie
& A.S. Elstein (Eds.), Professional judgment: A reader in clinical decision making (pp. 78-105). Cambridge,
England: Cambridge University Press.
Hammond, K. R. (1981). Principles of organization in intuitive and analytical cognition (Report #231). Boulder,
CO: University of Colorado, Center for Research on Judgment & Policy.
Hammond, K. R. (1996). Human judgement and social policy: Irreducible uncertainty, inevitable error, unavoid-
able injustice. New York, NY: Oxford University Press.
Hochberg, L., Alm, C. O., Rantanen, E. M., DeLong, C.M., & Haake, A. (2014). Decision style in a clinical
reasoning corpus. In Proceedings of the BioNLP Workshop (pp. 83-87). Baltimore, MD: Association for Com-
putational Linguistics.
Kahneman, D., & Frederick, S. (2002). Representativeness revisited: Attribute substitution in intuitive judgment.
In T. Gilovich, D. Griffin, & D. Kahneman (Eds.), Heuristics of intuitive judgment: Extensions and applications
(pp. 49-81). New York, NY: Cambridge University Press.
137
Lauri, S., Salanter?a, S., Chalmers, K., Ekman, S. L., Kim, H. S., K?appeli, S., & MacLeod, M. (2001). An
exploratory study of clinical decision-making in five countries. Journal of Nursing Scholarship, 33(1), 83-90.
Landis, J. R., & Koch, G. G. (1977). The measurement of observer agreement for categorical data. Biometrics,
33(1), 159-174.
Norman, G. (2009). Dual processing and diagnostic errors. Advances in Health Sciences Education, 14(1), 37-49.
Pennebaker, J. W., & King, L. A. (1999). Linguistic styles: Language use as an individual difference. Journal of
Personality and Social Psychology, 77(6), 1296-1312.
Sj?oberg, L. (2003). Intuitive vs. analytical decision making: Which is preferred? Scandinavian Journal of Man-
agement, 19(1), 17-29.
Tausczik, Y. R., & Pennebaker, J. W. (2010). The psychological meaning of words: LIWC and computerized text
analysis methods. Journal of Language and Social Psychology, 29(1), 24-54.
Womack, K., McCoy, W., Alm, C. O., Calvelli, C., Pelz, J. B., Shi, P., & Haake, A. (2012, July). Disfluencies
as extra-propositional indicators of cognitive processing. Proceedings of the Workshop on Extra-Propositional
Aspects of Meaning in Computational Linguistics (pp. 1-9). Association for Computational Linguistics.
138
