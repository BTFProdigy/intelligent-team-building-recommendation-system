Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1?11,
MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational Linguistics
On Dual Decomposition and Linear Programming Relaxations
for Natural Language Processing
Alexander M. Rush David Sontag Michael Collins Tommi Jaakkola
MIT CSAIL, Cambridge, MA 02139, USA
{srush,dsontag,mcollins,tommi}@csail.mit.edu
Abstract
This paper introduces dual decomposition as a
framework for deriving inference algorithms
for NLP problems. The approach relies on
standard dynamic-programming algorithms as
oracle solvers for sub-problems, together with
a simple method for forcing agreement be-
tween the different oracles. The approach
provably solves a linear programming (LP) re-
laxation of the global inference problem. It
leads to algorithms that are simple, in that they
use existing decoding algorithms; efficient, in
that they avoid exact algorithms for the full
model; and often exact, in that empirically
they often recover the correct solution in spite
of using an LP relaxation. We give experimen-
tal results on two problems: 1) the combina-
tion of two lexicalized parsing models; and
2) the combination of a lexicalized parsing
model and a trigram part-of-speech tagger.
1 Introduction
Dynamic programming algorithms have been re-
markably useful for inference in many NLP prob-
lems. Unfortunately, as models become more com-
plex, for example through the addition of new fea-
tures or components, dynamic programming algo-
rithms can quickly explode in terms of computa-
tional or implementational complexity.1 As a re-
sult, efficiency of inference is a critical bottleneck
for many problems in statistical NLP.
This paper introduces dual decomposition
(Dantzig and Wolfe, 1960; Komodakis et al, 2007)
as a framework for deriving inference algorithms in
NLP. Dual decomposition leverages the observation
that complex inference problems can often be
decomposed into efficiently solvable sub-problems.
The approach leads to inference algorithms with the
following properties:
1The same is true for NLP inference algorithms based on
other exact combinatorial methods, for example methods based
on minimum-weight spanning trees (McDonald et al, 2005), or
graph cuts (Pang and Lee, 2004).
? The resulting algorithms are simple and efficient,
building on standard dynamic-programming algo-
rithms as oracle solvers for sub-problems,2 to-
gether with a method for forcing agreement be-
tween the oracles.
? The algorithms provably solve a linear program-
ming (LP) relaxation of the original inference
problem.
? Empirically, the LP relaxation often leads to an
exact solution to the original problem.
The approach is very general, and should be appli-
cable to a wide range of problems in NLP. The con-
nection to linear programming ensures that the algo-
rithms provide a certificate of optimality when they
recover the exact solution, and also opens up the
possibility of methods that incrementally tighten the
LP relaxation until it is exact (Sherali and Adams,
1994; Sontag et al, 2008).
The structure of this paper is as follows. We
first give two examples as an illustration of the ap-
proach: 1) integrated parsing and trigram part-of-
speech (POS) tagging; and 2) combined phrase-
structure and dependency parsing. In both settings,
it is possible to solve the integrated problem through
an ?intersected? dynamic program (e.g., for integra-
tion of parsing and tagging, the construction from
Bar-Hillel et al (1964) can be used). However,
these methods, although polynomial time, are sub-
stantially less efficient than our algorithms, and are
considerably more complex to implement.
Next, we describe exact polyhedral formula-
tions for the two problems, building on connec-
tions between dynamic programming algorithms
and marginal polytopes, as described in Martin et al
(1990). These allow us to precisely characterize the
relationship between the exact formulations and the
2More generally, other exact inference methods can be
used as oracles, for example spanning tree algorithms for non-
projective dependency structures.
1
LP relaxations that we solve. We then give guaran-
tees of convergence for our algorithms by showing
that they are instantiations of Lagrangian relaxation,
a general method for solving linear programs of a
particular form.
Finally, we describe experiments that demonstrate
the effectiveness of our approach. First, we con-
sider the integration of the generative model for
phrase-structure parsing of Collins (2003), with the
second-order discriminative dependency parser of
Koo et al (2008). This is an interesting problem
in its own right: the goal is to inject the high per-
formance of discriminative dependency models into
phrase-structure parsing. The method uses off-the-
shelf decoders for the two models. We find three
main results: 1) in spite of solving an LP relax-
ation, empirically the method finds an exact solution
on over 99% of the examples; 2) the method con-
verges quickly, typically requiring fewer than 10 it-
erations of decoding; 3) the method gives gains over
a baseline method that forces the phrase-structure
parser to produce the same dependencies as the first-
best output from the dependency parser (the Collins
(2003) model has an F1 score of 88.1%; the base-
line method has an F1 score of 89.7%; and the dual
decomposition method has an F1 score of 90.7%).
In a second set of experiments, we use dual de-
composition to integrate the trigram POS tagger of
Toutanova and Manning (2000) with the parser of
Collins (2003). We again find that the method finds
an exact solution in almost all cases, with conver-
gence in just a few iterations of decoding.
Although the focus of this paper is on dynamic
programming algorithms?both in the experiments,
and also in the formal results concerning marginal
polytopes?it is straightforward to use other com-
binatorial algorithms within the approach. For ex-
ample, Koo et al (2010) describe a dual decompo-
sition approach for non-projective dependency pars-
ing, which makes use of both dynamic programming
and spanning tree inference algorithms.
2 Related Work
Dual decomposition is a classical method for solv-
ing optimization problems that can be decomposed
into efficiently solvable sub-problems. Our work is
inspired by dual decomposition methods for infer-
ence in Markov random fields (MRFs) (Wainwright
et al, 2005a; Komodakis et al, 2007; Globerson and
Jaakkola, 2007). In this approach, the MRF is de-
composed into sub-problems corresponding to tree-
structured subgraphs that together cover all edges
of the original graph. The resulting inference algo-
rithms provably solve an LP relaxation of the MRF
inference problem, often significantly faster than
commercial LP solvers (Yanover et al, 2006).
Our work is also related to methods that incorpo-
rate combinatorial solvers within loopy belief prop-
agation (LBP), either for MAP inference (Duchi et
al., 2007) or for computing marginals (Smith and
Eisner, 2008). Our approach similarly makes use
of combinatorial algorithms to efficiently solve sub-
problems of the global inference problem. However,
unlike LBP, our algorithms have strong theoretical
guarantees, such as guaranteed convergence and the
possibility of a certificate of optimality. These guar-
antees are possible because our algorithms directly
solve an LP relaxation.
Other work has considered LP or integer lin-
ear programming (ILP) formulations of inference in
NLP (Martins et al, 2009; Riedel and Clarke, 2006;
Roth and Yih, 2005). These approaches typically
use general-purpose LP or ILP solvers. Our method
has the advantage that it leverages underlying struc-
ture arising in LP formulations of NLP problems.
We will see that dynamic programming algorithms
such as CKY can be considered to be very effi-
cient solvers for particular LPs. In dual decomposi-
tion, these LPs?and their efficient solvers?can be
embedded within larger LPs corresponding to more
complex inference problems.
3 Background: Structured Models for NLP
We now describe the type of models used throughout
the paper. We take some care to set up notation that
will allow us to make a clear connection between
inference problems and linear programming.
Our first example is weighted CFG parsing. We
assume a context-free grammar, in Chomsky normal
form, with a set of non-terminals N . The grammar
contains all rules of the form A ? B C and A ?
w where A,B,C ? N and w ? V (it is simple
to relax this assumption to give a more constrained
grammar). For rules of the form A ? w we refer
to A as the part-of-speech tag for w. We allow any
non-terminal to be at the root of the tree.
2
Given a sentence with n words, w1, w2, . . . wn, a
parse tree is a set of rule productions of the form
?A ? B C, i, k, j? where A,B,C ? N , and
1 ? i ? k < j ? n. Each rule production rep-
resents the use of CFG rule A ? B C where non-
terminal A spans words wi . . . wj , non-terminal B
spans words wi . . . wk, and non-terminal C spans
words wk+1 . . . wj . There are O(|N |3n3) such rule
productions. Each parse tree corresponds to a subset
of these rule productions, of size n? 1, that forms a
well-formed parse tree.3
We now define the index set for CFG parsing as
I = {?A? B C, i, k, j?: A,B,C ? N ,
1 ? i ? k < j ? n}
Each parse tree is a vector y = {yr : r ? I},
with yr = 1 if rule r is in the parse tree, and yr =
0 otherwise. Hence each parse tree is represented
as a vector in {0, 1}m, where m = |I|. We use Y
to denote the set of all valid parse-tree vectors; the
set Y is a subset of {0, 1}m (not all binary vectors
correspond to valid parse trees).
In addition, we assume a vector ? = {?r : r ?
I} that specifies a weight for each rule production.4
Each ?r can take any value in the reals. The optimal
parse tree is y? = arg maxy?Y y ? ? where y ? ? =?
r yr?r is the inner product between y and ?.
We use yr and y(r) interchangeably (similarly for
?r and ?(r)) to refer to the r?th component of the
vector y. For example ?(A ? B C, i, k, j) is a
weight for the rule ?A? B C, i, k, j?.
We will use similar notation for other problems.
As a second example, in POS tagging the task is to
map a sentence of n words w1 . . . wn to a tag se-
quence t1 . . . tn, where each ti is chosen from a set
T of possible tags. We assume a trigram tagger,
where a tag sequence is represented through deci-
sions ?(A,B) ? C, i? where A,B,C ? T , and
i ? {3 . . . n}. Each production represents a tran-
sition where C is the tag of word wi, and (A,B) are
3We do not require rules of the form A ? wi in this repre-
sentation, as they are redundant: specifically, a rule production
?A ? B C, i, k, j? implies a rule B ? wi iff i = k, and
C ? wj iff j = k + 1.
4We do not require parameters for rules of the formA? w,
as they can be folded into rule production parameters. E.g.,
under a PCFG we define ?(A ? B C, i, k, j) = logP (A ?
B C | A) + ?i,k logP (B ? wi|B) + ?k+1,j logP (C ?
wj |C) where ?x,y = 1 if x = y, 0 otherwise.
the previous two tags. The index set for tagging is
Itag = {?(A,B)? C, i? : A,B,C ? T , 3 ? i ? n}
Note that we do not need transitions for i = 1 or i =
2, because the transition ?(A,B) ? C, 3? specifies
the first three tags in the sentence.5
Each tag sequence is represented as a vector z =
{zr : r ? Itag}, and we denote the set of valid tag
sequences, a subset of {0, 1}|Itag|, as Z . Given a
parameter vector ? = {?r : r ? Itag}, the optimal
tag sequence is arg maxz?Z z ? ?.
As a modification to the above approach, we will
find it convenient to introduce extended index sets
for both the CFG and POS tagging examples. For
the CFG case we define the extended index set to be
I ? = I ? Iuni where
Iuni = {(i, t) : i ? {1 . . . n}, t ? T}
Here each pair (i, t) represents word wi being as-
signed the tag t. Thus each parse-tree vector y will
have additional (binary) components y(i, t) spec-
ifying whether or not word i is assigned tag t.
(Throughout this paper we will assume that the tag-
set used by the tagger, T , is a subset of the set of non-
terminals considered by the parser, N .) Note that
this representation is over-complete, since a parse
tree determines a unique tagging for a sentence:
more explicitly, for any i ? {1 . . . n}, Y ? T , the
following linear constraint holds:
y(i, Y ) =
n?
k=i+1
?
X,Z?N
y(X ? Y Z, i, i, k) +
i?1?
k=1
?
X,Z?N
y(X ? Z Y, k, i? 1, i)
We apply the same extension to the tagging index
set, effectively mapping trigrams down to unigram
assignments, again giving an over-complete repre-
sentation. The extended index set for tagging is re-
ferred to as I ?tag.
From here on we will make exclusive use of ex-
tended index sets for CFG parsing and trigram tag-
ging. We use the set Y to refer to the set of valid
parse structures under the extended representation;
5As one example, in an HMM, the parameter ?((A,B) ?
C, 3) would be logP (A|??)+logP (B|?A)+logP (C|AB)+
logP (w1|A) + logP (w2|B) + logP (w3|C), where ? is the
start symbol.
3
each y ? Y is a binary vector of length |I ?|. We
similarly use Z to refer to the set of valid tag struc-
tures under the extended representation. We assume
parameter vectors for the two problems, ?cfg ? R|I
?|
and ?tag ? R|I
?
tag|.
4 Two Examples
This section describes the dual decomposition ap-
proach for two inference problems in NLP.
4.1 Integrated Parsing and Trigram Tagging
We now describe the dual decomposition approach
for integrated parsing and trigram tagging. First, de-
fine the set Q as follows:
Q = {(y, z) : y ? Y, z ? Z,
y(i, t) = z(i, t) for all (i, t) ? Iuni} (1)
Hence Q is the set of all (y, z) pairs that agree
on their part-of-speech assignments. The integrated
parsing and trigram tagging problem is then to solve
max
(y,z)?Q
(
y ? ?cfg + z ? ?tag
)
(2)
This problem is equivalent to
max
y?Y
(
y ? ?cfg + g(y) ? ?tag
)
where g : Y ? Z is a function that maps a parse
tree y to its set of trigrams z = g(y). The benefit of
the formulation in Eq. 2 is that it makes explicit the
idea of maximizing over all pairs (y, z) under a set
of agreement constraints y(i, t) = z(i, t)?this con-
cept will be central to the algorithms in this paper.
With this in mind, we note that we have effi-
cient methods for the inference problems of tagging
and parsing alone, and that our combined objective
almost separates into these two independent prob-
lems. In fact, if we drop the y(i, t) = z(i, t) con-
straints from the optimization problem, the problem
splits into two parts, each of which can be efficiently
solved using dynamic programming:
(y?, z?) = (arg max
y?Y
y ? ?cfg, arg max
z?Z
z ? ?tag)
Dual decomposition exploits this idea; it results in
the algorithm given in figure 1. The algorithm opti-
mizes the combined objective by repeatedly solving
the two sub-problems separately?that is, it directly
Set u(1)(i, t)? 0 for all (i, t) ? Iuni
for k = 1 to K do
y(k) ? arg max
y?Y
(y ? ?cfg ?
?
(i,t)?Iuni
u(k)(i, t)y(i, t))
z(k) ? arg max
z?Z
(z ? ?tag +
?
(i,t)?Iuni
u(k)(i, t)z(i, t))
if y(k)(i, t) = z(k)(i, t) for all (i, t) ? Iuni then
return (y(k), z(k))
for all (i, t) ? Iuni,
u(k+1)(i, t)? u(k)(i, t)+?k(y(k)(i, t)?z(k)(i, t))
return (y(K), z(K))
Figure 1: The algorithm for integrated parsing and tag-
ging. The parameters ?k > 0 for k = 1 . . .K specify
step sizes for each iteration, and are discussed further in
the Appendix. The two arg max problems can be solved
using dynamic programming.
solves the harder optimization problem using an ex-
isting CFG parser and trigram tagger. After each
iteration the algorithm adjusts the weights u(i, t);
these updates modify the objective functions for the
two models, encouraging them to agree on the same
POS sequence. In section 6.1 we will show that the
variables u(i, t) are Lagrange multipliers enforcing
agreement constraints, and that the algorithm corre-
sponds to a (sub)gradient method for optimization
of a dual function. The algorithm is easy to imple-
ment: all that is required is a decoding algorithm for
each of the two models, and simple additive updates
to the Lagrange multipliers enforcing agreement be-
tween the two models.
4.2 Integrating Two Lexicalized Parsers
Our second example problem is the integration of
a phrase-structure parser with a higher-order depen-
dency parser. The goal is to add higher-order fea-
tures to phrase-structure parsing without greatly in-
creasing the complexity of inference.
First, we define an index set for second-order un-
labeled projective dependency parsing. The second-
order parser considers first-order dependencies, as
well as grandparent and sibling second-order depen-
dencies (e.g., see Carreras (2007)). We assume that
Idep is an index set containing all such dependen-
cies (for brevity we omit the details of this index
set). For convenience we define an extended index
set that makes explicit use of first-order dependen-
4
cies, I ?dep = Idep ? Ifirst, where
Ifirst = {(i, j) : i ? {0 . . . n}, j ? {1 . . . n}, i 6= j}
Here (i, j) represents a dependency with head wi
and modifier wj (i = 0 corresponds to the root sym-
bol in the parse). We use D ? {0, 1}|I
?
dep| to denote
the set of valid projective dependency parses.
The second model we use is a lexicalized CFG.
Each symbol in the grammar takes the form A(h)
where A ? N is a non-terminal, and h ? {1 . . . n}
is an index specifying that wh is the head of the con-
stituent. Rule productions take the form ?A(a) ?
B(b) C(c), i, k, j? where b ? {i . . . k}, c ? {(k +
1) . . . j}, and a is equal to b or c, depending on
whether A receives its head-word from its left or
right child. Each such rule implies a dependency
(a, b) if a = c, or (a, c) if a = b. We take Ihead
to be the index set of all such rules, and I ?head =
Ihead?Ifirst to be the extended index set. We define
H ? {0, 1}|I
?
head| to be the set of valid parse trees.
The integrated parsing problem is then to find
(y?, d?) = arg max
(y,d)?R
(
y ? ?head + d ? ?dep
)
(3)
where R = {(y, d) : y ? H, d ? D,
y(i, j) = d(i, j) for all (i, j) ? Ifirst}
This problem has a very similar structure to the
problem of integrated parsing and tagging, and we
can derive a similar dual decomposition algorithm.
The Lagrange multipliers u are a vector in R|Ifirst|
enforcing agreement between dependency assign-
ments. The algorithm (omitted for brevity) is identi-
cal to the algorithm in figure 1, but with Iuni, Y , Z ,
?cfg, and ?tag replaced with Ifirst, H, D, ?head, and
?dep respectively. The algorithm only requires de-
coding algorithms for the two models, together with
simple updates to the Lagrange multipliers.
5 Marginal Polytopes and LP Relaxations
We now give formal guarantees for the algorithms
in the previous section, showing that they solve LP
relaxations of the problems in Eqs. 2 and 3.
To make the connection to linear programming,
we first introduce the idea of marginal polytopes in
section 5.1. In section 5.2, we give a precise state-
ment of the LP relaxations that are being solved
by the example algorithms, making direct use of
marginal polytopes. In section 6 we will prove that
the example algorithms solve these LP relaxations.
5.1 Marginal Polytopes
For a finite set Y , define the set of all distributions
over elements in Y as ? = {? ? R|Y| : ?y ?
0,
?
y?Y ?y = 1}. Each ? ? ? gives a vector of
marginals, ? =
?
y?Y ?yy, where ?r can be inter-
preted as the probability that yr = 1 for a y selected
at random from the distribution ?.
The set of all possible marginal vectors, known as
the marginal polytope, is defined as follows:
M = {? ? Rm : ?? ? ? such that ? =
?
y?Y
?yy}
M is also frequently referred to as the convex hull of
Y , written as conv(Y). We use the notation conv(Y)
in the remainder of this paper, instead ofM.
For an arbitrary set Y , the marginal polytope
conv(Y) can be complex to describe.6 However,
Martin et al (1990) show that for a very general
class of dynamic programming problems, the cor-
responding marginal polytope can be expressed as
conv(Y) = {? ? Rm : A? = b, ? ? 0} (4)
where A is a p?m matrix, b is vector in Rp, and the
value p is linear in the size of a hypergraph repre-
sentation of the dynamic program. Note that A and
b specify a set of p linear constraints.
We now give an explicit description of the re-
sulting constraints for CFG parsing:7 similar con-
straints arise for other dynamic programming algo-
rithms for parsing, for example the algorithms of
Eisner (2000). The exact form of the constraints, and
the fact that they are polynomial in number, is not
essential for the formal results in this paper. How-
ever, a description of the constraints gives valuable
intuition for the structure of the marginal polytope.
The constraints are given in figure 2. To develop
some intuition, consider the case where the variables
?r are restricted to be binary: hence each binary
vector ? specifies a parse tree. The second con-
straint in Eq. 5 specifies that exactly one rule must
be used at the top of the tree. The set of constraints
in Eq. 6 specify that for each production of the form
6For any finite set Y , conv(Y) can be expressed as {? ?
Rm : A? ? b} where A is a matrix of dimension p ?m, and
b ? Rp (see, e.g., Korte and Vygen (2008), pg. 65). The value
for p depends on the set Y , and can be exponential in size.
7Taskar et al (2004) describe the same set of constraints, but
without proof of correctness or reference to Martin et al (1990).
5
?r ? I?, ?r ? 0 ;
X
X,Y,Z?N
k=1...(n?1)
?(X ? Y Z, 1, k, n) = 1 (5)
?X ? N , ?(i, j) such that 1 ? i < j ? n and (i, j) 6= (1, n):
X
Y,Z?N
k=i...(j?1)
?(X ? Y Z, i, k, j) =
X
Y,Z?N
k=1...(i?1)
?(Y ? Z X, k, i? 1, j)
+
X
Y,Z?N
k=(j+1)...n
?(Y ? X Z, i, j, k) (6)
?Y ? T, ?i ? {1 . . . n} : ?(i, Y ) =
X
X,Z?N
k=(i+1)...n
?(X ? Y Z, i, i, k) +
X
X,Z?N
k=1...(i?1)
?(X ? Z Y, k, i? 1, i) (7)
Figure 2: The linear constraints defining the marginal
polytope for CFG parsing.
?X ? Y Z, i, k, j? in a parse tree, there must be
exactly one production higher in the tree that gener-
ates (X, i, j) as one of its children. The constraints
in Eq. 7 enforce consistency between the ?(i, Y )
variables and rule variables higher in the tree. Note
that the constraints in Eqs.(5?7) can be written in the
form A? = b, ? ? 0, as in Eq. 4.
Under these definitions, we have the following:
Theorem 5.1 Define Y to be the set of all CFG
parses, as defined in section 4. Then
conv(Y) = {? ? Rm : ? satisifies Eqs.(5?7)}
Proof: This theorem is a special case of Martin et al
(1990), theorem 2.
The marginal polytope for tagging, conv(Z), can
also be expressed using linear constraints as in Eq. 4;
see figure 3. These constraints follow from re-
sults for graphical models (Wainwright and Jordan,
2008), or from the Martin et al (1990) construction.
As a final point, the following theorem gives an
important property of marginal polytopes, which we
will use at several points in this paper:
Theorem 5.2 (Korte and Vygen (2008), page 66.)
For any set Y ? {0, 1}k, and for any vector ? ? Rk,
max
y?Y
y ? ? = max
??conv(Y)
? ? ? (8)
The theorem states that for a linear objective func-
tion, maximization over a discrete set Y can be
replaced by maximization over the convex hull
?r ? I?tag, ?r ? 0 ;
X
X,Y,Z?T
?((X,Y )? Z, 3) = 1
?X ? T , ?i ? {3 . . . n? 1}:
X
Y,Z?T
?((Y,Z)? X, i) =
X
Y,Z?T
?((Y,X)? Z, i+ 1)
?X ? T , ?i ? {3 . . . n? 2}:
X
Y,Z?T
?((Y,Z)? X, i) =
X
Y,Z?T
?((X,Y )? Z, i+ 2)
?X ? T,?i ? {3 . . . n} : ?(i,X) =
X
Y,Z?T
?((Y,Z)? X, i)
?X ? T : ?(1, X) =
X
Y,Z?T
?((X,Y )? Z, 3)
?X ? T : ?(2, X) =
X
Y,Z?T
?((Y,X)? Z, 3)
Figure 3: The linear constraints defining the marginal
polytope for trigram POS tagging.
conv(Y). The problem max??conv(Y) ? ?? is a linear
programming problem.
For parsing, this theorem implies that:
1. Weighted CFG parsing can be framed as a linear
programming problem, of the form max??conv(Y) ??
?, where conv(Y) is specified by a polynomial num-
ber of linear constraints.
2. Conversely, dynamic programming algorithms
such as the CKY algorithm can be considered to
be oracles that efficiently solve LPs of the form
max??conv(Y) ? ? ?.
Similar results apply for the POS tagging case.
5.2 Linear Programming Relaxations
We now describe the LP relaxations that are solved
by the example algorithms in section 4. We begin
with the algorithm in Figure 1.
The original optimization problem was to find
max(y,z)?Q
(
y ? ?cfg + z ? ?tag
)
(see Eq. 2). By the-
orem 5.2, this is equivalent to solving
max
(?,?)?conv(Q)
(
? ? ?cfg + ? ? ?tag
)
(9)
To formulate our approximation, we first define:
Q? = {(?, ?) : ? ? conv(Y), ? ? conv(Z),
?(i, t) = ?(i, t) for all (i, t) ? Iuni}
6
The definition of Q? is very similar to the definition
of Q (see Eq. 1), the only difference being that Y
and Z are replaced by conv(Y) and conv(Z) re-
spectively. Hence any point inQ is also inQ?. It fol-
lows that any point in conv(Q) is also inQ?, because
Q? is a convex set defined by linear constraints.
The LP relaxation then corresponds to the follow-
ing optimization problem:
max
(?,?)?Q?
(
? ? ?cfg + ? ? ?tag
)
(10)
Q? is defined by linear constraints, making this a
linear program. Since Q? is an outer bound on
conv(Q), i.e. conv(Q) ? Q?, we obtain the guaran-
tee that the value of Eq. 10 always upper bounds the
value of Eq. 9.
In Appendix A we give an example showing
that in general Q? includes points that are not in
conv(Q). These points exist because the agreement
between the two parts is now enforced in expecta-
tion (?(i, t) = ?(i, t) for (i, t) ? Iuni) rather than
based on actual assignments. This agreement con-
straint is weaker since different distributions over
assignments can still result in the same first order
expectations. Thus, the solution to Eq. 10 may be
in Q? but not in conv(Q). It can be shown that
all such solutions will be fractional, making them
easy to distinguish from Q. In many applications of
LP relaxations?including the examples discussed
in this paper?the relaxation in Eq. 10 turns out to
be tight, in that the solution is often integral (i.e., it
is in Q). In these cases, solving the LP relaxation
exactly solves the original problem of interest.
In the next section we prove that the algorithm
in Figure 1 solves the problem in Eq 10. A similar
result holds for the algorithm in section 4.2: it solves
a relaxation of Eq. 3, whereR is replaced by
R? = {(?, ?) : ? ? conv(H), ? ? conv(D),
?(i, j) = ?(i, j) for all (i, j) ? Ifirst}
6 Convergence Guarantees
6.1 Lagrangian Relaxation
We now show that the example algorithms solve
their respective LP relaxations given in the previ-
ous section. We do this by first introducing a gen-
eral class of linear programs, together with an op-
timization method, Lagrangian relaxation, for solv-
ing these LPs. We then show that the algorithms in
section 4 are special cases of the general algorithm.
The linear programs we consider take the form
max
x1?X1,x2?X2
(?1 ? x1 + ?2 ? x2) such that Ex1 = Fx2
The matricesE ? Rq?m andF ? Rq?l specify q lin-
ear ?agreement? constraints between x1 ? Rm and
x2 ? Rl. The setsX1,X2 are also specified by linear
constraints, X1 = {x1 ? Rm : Ax1 = b, x1 ? 0}
and X2 =
{
x2 ? Rl : Cx2 = d, x2 ? 0
}
, hence the
problem is an LP.
Note that if we set X1 = conv(Y), X2 =
conv(Z), and define E and F to specify the agree-
ment constraints ?(i, t) = ?(i, t), then we have the
LP relaxation in Eq. 10.
It is natural to apply Lagrangian relaxation in
cases where the sub-problems maxx1?X1 ?1 ?x1 and
maxx2?X2 ?2 ? x2 can be efficiently solved by com-
binatorial algorithms for any values of ?1, ?2, but
where the constraints Ex1 = Fx2 ?complicate? the
problem. We introduce Lagrange multipliers u ? Rq
that enforce the latter set of constraints, giving the
Lagrangian:
L(u, x1, x2) = ?1 ? x1 + ?2 ? x2 + u ? (Ex1 ? Fx2)
The dual objective function is
L(u) = max
x1?X1,x2?X2
L(u, x1, x2)
and the dual problem is to find minu?Rq L(u).
Because X1 and X2 are defined by linear con-
straints, by strong duality we have
min
u?Rq
L(u) = max
x1?X1,x2?X2:Ex1=Fx2
(?1 ? x1 + ?2 ? x2)
Hence minimizing L(u) will recover the maximum
value of the original problem. This leaves open the
question of how to recover the LP solution (i.e., the
pair (x?1, x
?
2) that achieves this maximum); we dis-
cuss this point in section 6.2.
The dual L(u) is convex. However, L(u) is
not differentiable, so we cannot use gradient-based
methods to optimize it. Instead, a standard approach
is to use a subgradient method. Subgradients are tan-
gent lines that lower bound a function even at points
of non-differentiability: formally, a subgradient of a
convex function L : Rn ? R at a point u is a vector
gu such that for all v, L(v) ? L(u) + gu ? (v ? u).
7
u(1) ? 0
for k = 1 to K do
x(k)1 ? arg maxx1?X1(?1 + (u
(k))TE) ? x1
x(k)2 ? arg maxx2?X2(?2 ? (u
(k))TF ) ? x2
if Ex(k)1 = Fx
(k)
2 return u
(k)
u(k+1) ? u(k) ? ?k(Ex
(k)
1 ? Fx
(k)
2 )
return u(K)
Figure 4: The Lagrangian relaxation algorithm.
By standard results, the subgradient for L at a point
u takes a simple form, gu = Ex?1 ? Fx
?
2, where
x?1 = arg max
x1?X1
(?1 + (u
(k))TE) ? x1
x?2 = arg max
x2?X2
(?2 ? (u
(k))TF ) ? x2
The beauty of this result is that the values of x?1 and
x?2, and by implication the value of the subgradient,
can be computed using oracles for the two arg max
sub-problems.
Subgradient algorithms perform updates that are
similar to gradient descent:
u(k+1) ? u(k) ? ?kg
(k)
where g(k) is the subgradient ofL at u(k) and ?k > 0
is the step size of the update. The complete sub-
gradient algorithm is given in figure 4. The follow-
ing convergence theorem is well-known (e.g., see
page 120 of Korte and Vygen (2008)):
Theorem 6.1 If limk?? ?k = 0 and
??
k=1 ?k =
?, then limk?? L(u(k)) = minu L(u).
The following proposition is easily verified:
Proposition 6.1 The algorithm in figure 1 is an in-
stantiation of the algorithm in figure 4,8 with X1 =
conv(Y), X2 = conv(Z), and the matrices E and
F defined to be binary matrices specifying the con-
straints ?(i, t) = ?(i, t) for all (i, t) ? Iuni.
Under an appropriate definition of the step sizes ?k,
it follows that the algorithm in figure 1 defines a
sequence of Lagrange multiplers u(k) minimizing a
dual of the LP relaxation in Eq. 10. A similar result
holds for the algorithm in section 4.2.
8with the caveat that it returns (x(k)1 , x
(k)
2 ) rather than u
(k).
6.2 Recovering the LP Solution
The previous section described how the method in
figure 4 can be used to minimize the dualL(u) of the
original linear program. We now turn to the problem
of recovering a primal solution (x?1, x
?
2) of the LP.
The method we propose considers two cases:
(Case 1) If Ex(k)1 = Fx
(k)
2 at any stage during
the algorithm, then simply take (x(k)1 , x
(k)
2 ) to be the
primal solution. In this case the pair (x(k)1 , x
(k)
2 ) ex-
actly solves the original LP.9 If this case arises in the
algorithm in figure 1, then the resulting solution is
binary (i.e., it is a member of Q), and the solution
exactly solves the original inference problem.
(Case 2) If case 1 does not arise, then a couple of
strategies are possible. (This situation could arise
in cases where the LP is not tight?i.e., it has a
fractional solution?or where K is not large enough
for convergence.) The first is to define the pri-
mal solution to be the average of the solutions en-
countered during the algorithm: x?1 =
?
k x
(k)
1 /K,
x?2 =
?
k x
(k)
2 /K. Results from Nedic? and Ozdaglar
(2009) show that as K ? ?, these averaged solu-
tions converge to the optimal primal solution.10 A
second strategy (as given in figure 1) is to simply
take (x(K)1 , x
(K)
2 ) as an approximation to the primal
solution. This method is a heuristic, but previous
work (e.g., Komodakis et al (2007)) has shown that
it is effective in practice; we use it in this paper.
In our experiments we found that in the vast ma-
jority of cases, case 1 applies, after a small number
of iterations; see the next section for more details.
7 Experiments
7.1 Integrated Phrase-Structure and
Dependency Parsing
Our first set of experiments considers the integration
of Model 1 of Collins (2003) (a lexicalized phrase-
structure parser, from here on referred to as Model
9We have that ?1 ? x
(k)
1 + ?2 ? x
(k)
2 = L(u
(k), x(k)1 , x
(k)
2 ) =
L(u(k)), where the last equality is because x(k)1 and x
(k)
2 are de-
fined by the respective argmax?s. Thus, (x(k)1 , x
(k)
2 ) and u
(k)
are primal and dual optimal.
10The resulting fractional solution can be projected back to
the setQ, see (Smith and Eisner, 2008; Martins et al, 2009).
8
Itn. 1 2 3 4 5-10 11-20 20-50 **
Dep 43.5 20.1 10.2 4.9 14.0 5.7 1.4 0.4
POS 58.7 15.4 6.3 3.6 10.3 3.8 0.8 1.1
Table 1: Convergence results for Section 23 of the WSJ
Treebank for the dependency parsing and POS experi-
ments. Each column gives the percentage of sentences
whose exact solutions were found in a given range of sub-
gradient iterations. ** is the percentage of sentences that
did not converge by the iteration limit (K=50).
1),11 and the 2nd order discriminative dependency
parser of Koo et al (2008). The inference problem
for a sentence x is to find
y? = arg max
y?Y
(f1(y) + ?f2(y)) (11)
where Y is the set of all lexicalized phrase-structure
trees for the sentence x; f1(y) is the score (log prob-
ability) under Model 1; f2(y) is the score under Koo
et al (2008) for the dependency structure implied
by y; and ? > 0 is a parameter dictating the relative
weight of the two models.12 This problem is simi-
lar to the second example in section 4; a very sim-
ilar dual decomposition algorithm to that described
in section 4.2 can be derived.
We used the Penn Wall Street Treebank (Marcus
et al, 1994) for the experiments, with sections 2-21
for training, section 22 for development, and section
23 for testing. The parameter ? was chosen to opti-
mize performance on the development set.
We ran the dual decomposition algorithm with a
limit of K = 50 iterations. The dual decomposi-
tion algorithm returns an exact solution if case 1 oc-
curs as defined in section 6.2; we found that of 2416
sentences in section 23, case 1 occurred for 2407
(99.6%) sentences. Table 1 gives statistics showing
the number of iterations required for convergence.
Over 80% of the examples converge in 5 iterations or
fewer; over 90% converge in 10 iterations or fewer.
We compare the accuracy of the dual decomposi-
tion approach to two baselines: first, Model 1; and
second, a naive integration method that enforces the
hard constraint that Model 1 must only consider de-
11We use a reimplementation that is a slight modification of
Collins Model 1, with very similar performance, and which uses
the TAG formalism of Carreras et al (2008).
12Note that the models f1 and f2 were trained separately,
using the methods described by Collins (2003) and Koo et al
(2008) respectively.
Precision Recall F1 Dep
Model 1 88.4 87.8 88.1 91.4
Koo08 Baseline 89.9 89.6 89.7 93.3
DD Combination 91.0 90.4 90.7 93.8
Table 2: Performance results for Section 23 of the WSJ
Treebank. Model 1: a reimplementation of the genera-
tive parser of (Collins, 2002). Koo08 Baseline: Model 1
with a hard restriction to dependencies predicted by the
discriminative dependency parser of (Koo et al, 2008).
DD Combination: a model that maximizes the joint score
of the two parsers. Dep shows the unlabeled dependency
accuracy of each system.
 50
 60
 70
 80
 90
 100
 0  10  20  30  40  50
Per
cen
tage
Maximum Number of Dual Decomposition Iterations
f score% certificates% match K=50
Figure 5: Performance on the parsing task assuming a
fixed number of iterations K. f-score: accuracy of the
method. % certificates: percentage of examples for which
a certificate of optimality is provided. % match: percent-
age of cases where the output from the method is identical
to the output when using K = 50.
pendencies seen in the first-best output from the de-
pendency parser. Table 2 shows all three results. The
dual decomposition method gives a significant gain
in precision and recall over the naive combination
method, and boosts the performance of Model 1 to
a level that is close to some of the best single-pass
parsers on the Penn treebank test set. Dependency
accuracy is also improved over the Koo et al (2008)
model, in spite of the relatively low dependency ac-
curacy of Model 1 alone.
Figure 5 shows performance of the approach as a
function ofK, the maximum number of iterations of
dual decomposition. For this experiment, for cases
where the method has not converged for k ? K,
the output from the algorithm is chosen to be the
y(k) for k ? K that maximizes the objective func-
tion in Eq. 11. The graphs show that values of K
less than 50 produce almost identical performance to
K = 50, but with fewer cases giving certificates of
optimality (with K = 10, the f-score of the method
is 90.69%; with K = 5 it is 90.63%).
9
Precision Recall F1 POS Acc
Fixed Tags 88.1 87.6 87.9 96.7
DD Combination 88.7 88.0 88.3 97.1
Table 3: Performance results for Section 23 of the WSJ.
Model 1 (Fixed Tags): a baseline parser initialized to the
best tag sequence of from the tagger of Toutanova and
Manning (2000). DD Combination: a model that maxi-
mizes the joint score of parse and tag selection.
7.2 Integrated Phrase-Structure Parsing and
Trigram POS tagging
In a second experiment, we used dual decomposi-
tion to integrate the Model 1 parser with the Stan-
ford max-ent trigram POS tagger (Toutanova and
Manning, 2000), using a very similar algorithm to
that described in section 4.1. We use the same train-
ing/dev/test split as in section 7.1. The two models
were again trained separately.
We ran the algorithm with a limit of K = 50 it-
erations. Out of 2416 test examples, the algorithm
found an exact solution in 98.9% of the cases. Ta-
ble 1 gives statistics showing the speed of conver-
gence for different examples: over 94% of the exam-
ples converge to an exact solution in 10 iterations or
fewer. In terms of accuracy, we compare to a base-
line approach of using the first-best tag sequence
as input to the parser. The dual decomposition ap-
proach gives 88.3 F1 measure in recovering parse-
tree constituents, compared to 87.9 for the baseline.
8 Conclusions
We have introduced dual-decomposition algorithms
for inference in NLP, given formal properties of the
algorithms in terms of LP relaxations, and demon-
strated their effectiveness on problems that would
traditionally be solved using intersections of dy-
namic programs (Bar-Hillel et al, 1964). Given the
widespread use of dynamic programming in NLP,
there should be many applications for the approach.
There are several possible extensions of the
method we have described. We have focused on
cases where two models are being combined; the
extension to more than two models is straightfor-
ward (e.g., see Komodakis et al (2007)). This paper
has considered approaches for MAP inference; for
closely related methods that compute approximate
marginals, see Wainwright et al (2005b).
A Fractional Solutions
We now give an example of a point (?, ?) ? Q?\conv(Q)
that demonstrates that the relaxation Q? is strictly larger
than conv(Q). Fractional points such as this one can arise
as solutions of the LP relaxation for worst case instances,
preventing us from finding an exact solution.
Recall that the constraints for Q? specify that ? ?
conv(Y), ? ? conv(Z), and ?(i, t) = ?(i, t) for all
(i, t) ? Iuni. Since ? ? conv(Y), ? must be a con-
vex combination of 1 or more members of Y; a similar
property holds for ?. The example is as follows. There
are two possible parts of speech, A and B, and an addi-
tional non-terminal symbol X . The sentence is of length
3, w1 w2 w3. Let ? be the convex combination of the
following two tag sequences, each with probability 0.5:
w1/A w2/A w3/A and w1/A w2/B w3/B. Let ? be
the convex combination of the following two parses, each
with probability 0.5: (X(A w1)(X(A w2)(B w3))) and
(X(A w1)(X(B w2)(A w3))). It can be verified that
?(i, t) = ?(i, t) for all (i, t), i.e., the marginals for single
tags for ? and ? agree. Thus, (?, ?) ? Q?.
To demonstrate that this fractional point is not in
conv(Q), we give parameter values such that this frac-
tional point is optimal and all integral points (i.e., ac-
tual parses) are suboptimal. For the tagging model, set
?(AA? A, 3) = ?(AB ? B, 3) = 0, with all other pa-
rameters having a negative value. For the parsing model,
set ?(X ? A X, 1, 1, 3) = ?(X ? A B, 2, 2, 3) =
?(X ? B A, 2, 2, 3) = 0, with all other rule parameters
being negative. For this objective, the fractional solution
has value 0, while all integral points (i.e., all points inQ)
have a negative value. By Theorem 5.2, the maximum of
any linear objective over conv(Q) is equal to the maxi-
mum over Q. Thus, (?, ?) 6? conv(Q).
B Step Size
We used the following step size in our experiments. First,
we initialized ?0 to equal 0.5, a relatively large value.
Then we defined ?k = ?0 ? 2??k , where ?k is the num-
ber of times that L(u(k
?)) > L(u(k
??1)) for k? ? k. This
learning rate drops at a rate of 1/2t, where t is the num-
ber of times that the dual increases from one iteration to
the next. See Koo et al (2010) for a similar, but less ag-
gressive step size used to solve a different task.
Acknowledgments MIT gratefully acknowledges the
support of Defense Advanced Research Projects Agency
(DARPA) Machine Reading Program under Air Force Research
Laboratory (AFRL) prime contract no. FA8750-09-C-0181.
Any opinions, findings, and conclusion or recommendations ex-
pressed in this material are those of the author(s) and do not
necessarily reflect the view of the DARPA, AFRL, or the US
government. Alexander Rush was supported under the GALE
program of the Defense Advanced Research Projects Agency,
Contract No. HR0011-06-C-0022. David Sontag was supported
by a Google PhD Fellowship.
10
References
Y. Bar-Hillel, M. Perles, and E. Shamir. 1964. On formal
properties of simple phrase structure grammars. In
Language and Information: Selected Essays on their
Theory and Application, pages 116?150.
X. Carreras, M. Collins, and T. Koo. 2008. TAG, dy-
namic programming, and the perceptron for efficient,
feature-rich parsing. In Proc CONLL, pages 9?16.
X. Carreras. 2007. Experiments with a higher-order
projective dependency parser. In Proc. CoNLL, pages
957?961.
M. Collins. 2002. Discriminative training methods for
hidden markov models: Theory and experiments with
perceptron algorithms. In Proc. EMNLP, page 8.
M. Collins. 2003. Head-driven statistical models for nat-
ural language parsing. In Computational linguistics,
volume 29, pages 589?637.
G.B. Dantzig and P. Wolfe. 1960. Decomposition princi-
ple for linear programs. In Operations research, vol-
ume 8, pages 101?111.
J. Duchi, D. Tarlow, G. Elidan, and D. Koller. 2007.
Using combinatorial optimization within max-product
belief propagation. In NIPS, volume 19.
J. Eisner. 2000. Bilexical grammars and their cubic-time
parsing algorithms. In Advances in Probabilistic and
Other Parsing Technologies, pages 29?62.
A. Globerson and T. Jaakkola. 2007. Fixing max-
product: Convergent message passing algorithms for
MAP LP-relaxations. In NIPS, volume 21.
N. Komodakis, N. Paragios, and G. Tziritas. 2007.
MRF optimization via dual decomposition: Message-
passing revisited. In International Conference on
Computer Vision.
T. Koo, X. Carreras, and M. Collins. 2008. Simple semi-
supervised dependency parsing. In Proc. ACL/HLT.
T. Koo, A.M. Rush, M. Collins, T. Jaakkola, and D. Son-
tag. 2010. Dual Decomposition for Parsing with Non-
Projective Head Automata. In Proc. EMNLP, pages
63?70.
B.H. Korte and J. Vygen. 2008. Combinatorial optimiza-
tion: theory and algorithms. Springer Verlag.
M.P. Marcus, B. Santorini, and M.A. Marcinkiewicz.
1994. Building a large annotated corpus of English:
The Penn Treebank. In Computational linguistics, vol-
ume 19, pages 313?330.
R.K. Martin, R.L. Rardin, and B.A. Campbell. 1990.
Polyhedral characterization of discrete dynamic pro-
gramming. Operations research, 38(1):127?138.
A.F.T. Martins, N.A. Smith, and E.P. Xing. 2009. Con-
cise integer linear programming formulations for de-
pendency parsing. In Proc. ACL.
R. McDonald, F. Pereira, K. Ribarov, and J. Hajic. 2005.
Non-projective dependency parsing using spanning
tree algorithms. In Proc. HLT/EMNLP, pages 523?
530.
Angelia Nedic? and Asuman Ozdaglar. 2009. Approxi-
mate primal solutions and rate analysis for dual sub-
gradient methods. SIAM Journal on Optimization,
19(4):1757?1780.
B. Pang and L. Lee. 2004. A sentimental education:
Sentiment analysis using subjectivity summarization
based on minimum cuts. In Proc. ACL.
S. Riedel and J. Clarke. 2006. Incremental integer linear
programming for non-projective dependency parsing.
In Proc. EMNLP, pages 129?137.
D. Roth and W. Yih. 2005. Integer linear program-
ming inference for conditional random fields. In Proc.
ICML, pages 737?744.
Hanif D. Sherali and Warren P. Adams. 1994. A hi-
erarchy of relaxations and convex hull characteriza-
tions for mixed-integer zero?one programming prob-
lems. Discrete Applied Mathematics, 52(1):83 ? 106.
D.A. Smith and J. Eisner. 2008. Dependency parsing by
belief propagation. In Proc. EMNLP, pages 145?156.
D. Sontag, T. Meltzer, A. Globerson, T. Jaakkola, and
Y. Weiss. 2008. Tightening LP relaxations for MAP
using message passing. In Proc. UAI.
B. Taskar, D. Klein, M. Collins, D. Koller, and C. Man-
ning. 2004. Max-margin parsing. In Proc. EMNLP,
pages 1?8.
K. Toutanova and C.D. Manning. 2000. Enriching the
knowledge sources used in a maximum entropy part-
of-speech tagger. In Proc. EMNLP, pages 63?70.
M. Wainwright and M. I. Jordan. 2008. Graphical Mod-
els, Exponential Families, and Variational Inference.
Now Publishers Inc., Hanover, MA, USA.
M. Wainwright, T. Jaakkola, and A. Willsky. 2005a.
MAP estimation via agreement on trees: message-
passing and linear programming. In IEEE Transac-
tions on Information Theory, volume 51, pages 3697?
3717.
M. Wainwright, T. Jaakkola, and A. Willsky. 2005b. A
new class of upper bounds on the log partition func-
tion. In IEEE Transactions on Information Theory,
volume 51, pages 2313?2335.
C. Yanover, T. Meltzer, and Y. Weiss. 2006. Linear
Programming Relaxations and Belief Propagation?An
Empirical Study. In The Journal of Machine Learning
Research, volume 7, page 1907. MIT Press.
11
Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1288?1298,
MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational Linguistics
Dual Decomposition for Parsing with Non-Projective Head Automata
Terry Koo Alexander M. Rush Michael Collins Tommi Jaakkola David Sontag
MIT CSAIL, Cambridge, MA 02139, USA
{maestro,srush,mcollins,tommi,dsontag}@csail.mit.edu
Abstract
This paper introduces algorithms for non-
projective parsing based on dual decomposi-
tion. We focus on parsing algorithms for non-
projective head automata, a generalization of
head-automata models to non-projective struc-
tures. The dual decomposition algorithms are
simple and efficient, relying on standard dy-
namic programming and minimum spanning
tree algorithms. They provably solve an LP
relaxation of the non-projective parsing prob-
lem. Empirically the LP relaxation is very of-
ten tight: for many languages, exact solutions
are achieved on over 98% of test sentences.
The accuracy of our models is higher than pre-
vious work on a broad range of datasets.
1 Introduction
Non-projective dependency parsing is useful for
many languages that exhibit non-projective syntactic
structures. Unfortunately, the non-projective parsing
problem is known to be NP-hard for all but the sim-
plest models (McDonald and Satta, 2007). There has
been a long history in combinatorial optimization of
methods that exploit structure in complex problems,
using methods such as dual decomposition or La-
grangian relaxation (Lemare?chal, 2001). Thus far,
however, these methods are not widely used in NLP.
This paper introduces algorithms for non-
projective parsing based on dual decomposition. We
focus on parsing algorithms for non-projective head
automata, a generalization of the head-automata
models of Eisner (2000) and Alshawi (1996) to non-
projective structures. These models include non-
projective dependency parsing models with higher-
order (e.g., sibling and/or grandparent) dependency
relations as a special case. Although decoding of full
parse structures with non-projective head automata
is intractable, we leverage the observation that key
components of the decoding can be efficiently com-
puted using combinatorial algorithms. In particular,
1. Decoding for individual head-words can be ac-
complished using dynamic programming.
2. Decoding for arc-factored models can be ac-
complished using directed minimum-weight
spanning tree (MST) algorithms.
The resulting parsing algorithms have the following
properties:
? They are efficient and easy to implement, relying
on standard dynamic programming and MST al-
gorithms.
? They provably solve a linear programming (LP)
relaxation of the original decoding problem.
? Empirically the algorithms very often give an ex-
act solution to the decoding problem, in which
case they also provide a certificate of optimality.
In this paper we first give the definition for non-
projective head automata, and describe the parsing
algorithm. The algorithm can be viewed as an in-
stance of Lagrangian relaxation; we describe this
connection, and give convergence guarantees for the
method. We describe a generalization to models
that include grandparent dependencies. We then in-
troduce a perceptron-driven training algorithm that
makes use of point 1 above.
We describe experiments on non-projective pars-
ing for a number of languages, and in particu-
lar compare the dual decomposition algorithm to
approaches based on general-purpose linear pro-
gramming (LP) or integer linear programming (ILP)
solvers (Martins et al, 2009). The accuracy of our
models is higher than previous work on a broad
range of datasets. The method gives exact solutions
to the decoding problem, together with a certificate
of optimality, on over 98% of test examples for many
of the test languages, with parsing times ranging be-
tween 0.021 seconds/sentence for the most simple
languages/models, to 0.295 seconds/sentence for the
1288
most complex settings. The method compares favor-
ably to previous work using LP/ILP formulations,
both in terms of efficiency, and also in terms of the
percentage of exact solutions returned.
While the focus of the current paper is on non-
projective dependency parsing, the approach opens
up new ways of thinking about parsing algorithms
for lexicalized formalisms such as TAG (Joshi and
Schabes, 1997), CCG (Steedman, 2000), and pro-
jective head automata.
2 Related Work
McDonald et al (2005) describe MST-based parsing
for non-projective dependency parsing models with
arc-factored decompositions; McDonald and Pereira
(2006) make use of an approximate (hill-climbing)
algorithm for parsing with more complex models.
McDonald and Pereira (2006) and McDonald and
Satta (2007) describe complexity results for non-
projective parsing, showing that parsing for a variety
of models is NP-hard. Riedel and Clarke (2006) de-
scribe ILP methods for the problem; Martins et al
(2009) recently introduced alternative LP and ILP
formulations. Our algorithm differs in that we do not
use general-purpose LP or ILP solvers, instead using
an MST solver in combination with dynamic pro-
gramming; thus we leverage the underlying struc-
ture of the problem, thereby deriving more efficient
decoding algorithms.
Both dual decomposition and Lagrangian relax-
ation have a long history in combinatorial optimiza-
tion. Our work was originally inspired by recent
work on dual decomposition for inference in graph-
ical models (Wainwright et al, 2005; Komodakis
et al, 2007). However, the non-projective parsing
problem has a very different structure from these
models, and the decomposition we use is very dif-
ferent in nature from those used in graphical mod-
els. Other work has made extensive use of de-
composition approaches for efficiently solving LP
relaxations for graphical models (e.g., Sontag et
al. (2008)). Methods that incorporate combinato-
rial solvers within loopy belief propagation (LBP)
(Duchi et al, 2007; Smith and Eisner, 2008) are
also closely related to our approach. Unlike LBP,
our method has strong theoretical guarantees, such
as guaranteed convergence and the possibility of a
certificate of optimality.
Finally, in other recent work, Rush et al (2010)
describe dual decomposition approaches for other
NLP problems.
3 Sibling Models
This section describes a particular class of models,
sibling models; the next section describes a dual-
decomposition algorithm for decoding these models.
Consider the dependency parsing problem for a
sentence with n words. We define the index set
for dependency parsing to be I = {(i, j) : i ?
{0 . . . n}, j ? {1 . . . n}, i 6= j}. A dependency
parse is a vector y = {y(i, j) : (i, j) ? I}, where
y(i, j) = 1 if a dependency with head word i and
modifier j is in the parse, 0 otherwise. We use i = 0
for the root symbol. We define Y to be the set of all
well-formed non-projective dependency parses (i.e.,
the set of directed spanning trees rooted at node 0).
Given a function f : Y 7? R that assigns scores to
parse trees, the optimal parse is
y? = argmax
y?Y
f(y) (1)
A particularly simple definition of f(y) is f(y) =
?
(i,j)?I y(i, j)?(i, j) where ?(i, j) is the score for
dependency (i, j). Models with this form are often
referred to as arc-factored models. In this case the
optimal parse tree y? can be found efficiently using
MST algorithms (McDonald et al, 2005).
This paper describes algorithms that compute y?
for more complex definitions of f(y); in this sec-
tion, we focus on algorithms for models that capture
interactions between sibling dependencies. To this
end, we will find it convenient to define the follow-
ing notation. Given a vector y, define
y|i = {y(i, j) : j = 1 . . . n, j 6= i}
Hence y|i specifies the set of modifiers to word i;
note that the vectors y|i for i = 0 . . . n form a parti-
tion of the full set of variables.
We then assume that f(y) takes the form
f(y) =
n?
i=0
fi(y|i) (2)
Thus f(y) decomposes into a sum of terms, where
each fi considers modifiers to the i?th word alone.
In the general case, finding y? =
argmaxy?Y f(y) under this definition of f(y)
is an NP-hard problem. However for certain
1289
definitions of fi, it is possible to efficiently compute
argmaxy|i?Zi fi(y|i) for any value of i, typically
using dynamic programming. (Here we use Zi to
refer to the set of all possible values for y|i: specifi-
cally, Z0 = {0, 1}n and for i 6= 0, Zi = {0, 1}n?1.)
In these cases we can efficiently compute
z? = argmax
z?Z
f(z) = argmax
z?Z
?
i
fi(z|i) (3)
where Z = {z : z|i ? Zi for i = 0 . . . n} by
simply computing z?|i = argmaxz|i?Zi fi(z|i) for
i = 0 . . . n. Eq. 3 can be considered to be an approx-
imation to Eq. 1, where we have replaced Y with
Z . We will make direct use of this approximation
in the dual decomposition parsing algorithm. Note
that Y ? Z , and in all but trivial cases, Y is a strict
subset of Z . For example, a structure z ? Z could
have z(i, j) = z(j, i) = 1 for some (i, j); it could
contain longer cycles; or it could contain words that
do not modify exactly one head. Nevertheless, with
suitably powerful functions fi?for example func-
tions based on discriminative models?z? may be a
good approximation to y?. Later we will see that
dual decomposition can effectively use MST infer-
ence to rule out ill-formed structures.
We now give the main assumption underlying sib-
ling models:
Assumption 1 (Sibling Decompositions) A model
f(y) satisfies the sibling-decomposition assumption
if: 1) f(y) =
?n
i=0 fi(y|i) for some set of functions
f0 . . . fn. 2) For any i ? {0 . . . n}, for any value
of the variables u(i, j) ? R for j = 1 . . . n, it is
possible to compute
argmax
y|i?Zi
?
?fi(y|i)?
?
j
u(i, j)y(i, j)
?
?
in polynomial time.
The second condition includes additional terms in-
volving u(i, j) variables that modify the scores of
individual dependencies. These terms are benign for
most definitions of fi, in that they do not alter de-
coding complexity. They will be of direct use in the
dual decomposition parsing algorithm.
Example 1: Bigram Sibling Models. Recall that
y|i is a binary vector specifying which words are
modifiers to the head-word i. Define l1 . . . lp to be
the sequence of left modifiers to word i under y|i,
and r1 . . . rq to be the set of right modifiers (e.g.,
consider the case where n = 5, i = 3, and we have
y(3, 1) = y(3, 5) = 0, and y(3, 2) = y(3, 4) = 1:
in this case p = 1, l1 = 2, and q = 1, r1 = 4). In
bigram sibling models, we have
fi(y|i) =
p+1?
k=1
gL(i, lk?1, lk) +
q+1?
k=1
gR(i, rk?1, rk)
where l0 = r0 = START is the initial state, and
lp+1 = rq+1 = END is the end state. The functions
gL and gR assign scores to bigram dependencies to
the left and right of the head. Under this model cal-
culating argmaxy|i?Zi
(
fi(y|i)?
?
j u(i, j)y(i, j)
)
takes O(n2) time using dynamic programming,
hence the model satisfies Assumption 1.
Example 2: Head Automata Head-automata
models constitute a second important model type
that satisfy the sibling-decomposition assumption
(bigram sibling models are a special case of head
automata). These models make use of functions
gR(i, s, s?, r) where s ? S, s? ? S are variables in a
set of possible states S, and r is an index of a word
in the sentence such that i < r ? n. The function
gR returns a cost for taking word r as the next depen-
dency, and transitioning from state s to s?. A similar
function gL is defined for left modifiers. We define
fi(y|i, s0 . . . sq, t0 . . . tp) =
q?
k=1
gR(i, sk?1, sk, rk) +
p?
k=1
gL(i, tk?1, tk, ll)
to be the joint score for dependencies y|i, and left
and right state sequences s0 . . . sq and t0 . . . tp. We
specify that s0 = t0 = START and sq = tp = END.
In this case we define
fi(y|i) = maxs0...sq ,t0...tp
fi(y|i, s0 . . . sq, t0 . . . tp)
and it follows that argmaxy|i?Zi fi(y|i) can be com-
puted inO(n|S|2) time using a variant of the Viterbi
algorithm, hence the model satisfies the sibling-
decomposition assumption.
4 The Parsing Algorithm
We now describe the dual decomposition parsing al-
gorithm for models that satisfy Assumption 1. Con-
sider the following generalization of the decoding
1290
Set u(1)(i, j)? 0 for all (i, j) ? I
for k = 1 to K do
y(k) ? argmax
y?Y
?
(i,j)?I
(
?(i, j) + u(k)(i, j)
)
y(i, j)
for i ? {0 . . . n},
z(k)|i ? argmax
z|i?Zi
(fi(z|i)?
?
j
u(k)(i, j)z(i, j))
if y(k)(i, j) = z(k)(i, j) for all (i, j) ? I then
return (y(k), z(k))
for all (i, j) ? I,
u(k+1)(i, j)? u(k)(i, j)+?k(z(k)(i, j)?y(k)(i, j))
return (y(K), z(K))
Figure 1: The parsing algorithm for sibling decompos-
able models. ?k ? 0 for k = 1 . . .K are step sizes, see
Appendix A for details.
problem from Eq. 1, where f(y) =
?
i fi(y|i),
h(y) =
?
(i,j)?I ?(i, j)y(i, j), and ?(i, j) ? R for
all (i, j):1
argmax
z?Z,y?Y
f(z) + h(y) (4)
such that z(i, j) = y(i, j) for all (i, j) ? I (5)
Although the maximization w.r.t. z is taken over the
set Z , the constraints in Eq. 5 ensure that z = y for
some y ? Y , and hence that z ? Y .
Without the z(i, j) = y(i, j) constraints, the
objective would decompose into the separate max-
imizations z? = argmaxz?Z f(z), and y
? =
argmaxy?Y h(y), which can be easily solved us-
ing dynamic programming and MST, respectively.
Thus, it is these constraints that complicate the op-
timization. Our approach gets around this difficulty
by introducing new variables, u(i, j), that serve to
enforce agreement between the y(i, j) and z(i, j)
variables. In the next section we will show that these
u(i, j) variables are actually Lagrange multipliers
for the z(i, j) = y(i, j) constraints.
Our parsing algorithm is shown in Figure 1. At
each iteration k, the algorithm finds y(k) ? Y us-
ing an MST algorithm, and z(k) ? Z through sep-
arate decoding of the (n + 1) sibling models. The
u(k) variables are updated if y(k)(i, j) 6= z(k)(i, j)
1This is equivalent to Eq. 1 when ?(i, j) = 0 for all (i, j).
In some cases, however, it is convenient to have a model with
non-zero values for the ? variables; see the Appendix. Note that
this definition of h(y) allows argmaxy?Y h(y) to be calculated
efficiently, using MST inference.
for some (i, j); these updates modify the objective
functions for the two decoding steps, and intuitively
encourage the y(k) and z(k) variables to be equal.
4.1 Lagrangian Relaxation
Recall that the main difficulty in solving Eq. 4 was
the z = y constraints. We deal with these con-
straints using Lagrangian relaxation (Lemare?chal,
2001). We first introduce Lagrange multipliers u =
{u(i, j) : (i, j) ? I}, and define the Lagrangian
L(u, y, z) = (6)
f(z) + h(y) +
?
(i,j)?I
u(i, j)
(
y(i, j)? z(i, j)
)
If L? is the optimal value of Eq. 4 subject to the
constraints in Eq. 5, then for any value of u,
L? = max
z?Z,y?Y,y=z
L(u, y, z) (7)
This follows because if y = z, the right term in Eq. 6
is zero for any value of u. The dual objective L(u)
is obtained by omitting the y = z constraint:
L(u) = max
z?Z,y?Y
L(u, y, z)
= max
z?Z
(
f(z)?
?
i,j
u(i, j)z(i, j)
)
+max
y?Y
(
h(y) +
?
i,j
u(i, j)y(i, j)
)
.
Since L(u) maximizes over a larger space (y may
not equal z), we have that L? ? L(u) (compare this
to Eq. 7). The dual problem, which our algorithm
optimizes, is to obtain the tightest such upper bound,
(Dual problem) min
u?R|I|
L(u). (8)
The dual objective L(u) is convex, but not differen-
tiable. However, we can use a subgradient method
to derive an algorithm that is similar to gradient de-
scent, and which minimizes L(u). A subgradient of
a convex function L(u) at u is a vector du such that
for all v ? R|I|, L(v) ? L(u) + du ? (v ? u). By
standard results,
du(k) = y
(k) ? z(k)
is a subgradient for L(u) at u = u(k), where z(k) =
argmaxz?Z f(z)?
?
i,j u
(k)(i, j)z(i, j) and y(k) =
1291
argmaxy?Y h(y) +
?
i,j u
(k)(i, j)y(i, j). Subgra-
dient optimization methods are iterative algorithms
with updates that are similar to gradient descent:
u(k+1) = u(k) ? ?kdu(k) = u
(k) ? ?k(y
(k) ? z(k)),
where ?k is a step size. It is easily verified that the
algorithm in Figure 1 uses precisely these updates.
4.2 Formal Guarantees
With an appropriate choice of the step sizes ?k, the
subgradient method can be shown to solve the dual
problem, i.e.
lim
k??
L(u(k)) = min
u
L(u).
See Korte and Vygen (2008), page 120, for details.
As mentioned before, the dual provides an up-
per bound on the optimum of the primal problem
(Eq. 4),
max
z?Z,y?Y,y=z
f(z) + h(y) ? min
u?R|I|
L(u). (9)
However, we do not necessarily have strong
duality?i.e., equality in the above equation?
because the sets Z and Y are discrete sets. That
said, for some functions h(y) and f(z) strong du-
ality does hold, as stated in the following:
Theorem 1 If for some k ? {1 . . .K} in the al-
gorithm in Figure 1, y(k)(i, j) = z(k)(i, j) for all
(i, j) ? I, then (y(k), z(k)) is a solution to the max-
imization problem in Eq. 4.
Proof. We have that f(z(k)) + h(y(k)) =
L(u(k), z(k), y(k)) = L(u(k)), where the last equal-
ity is because y(k), z(k) are defined as the respective
argmax?s. Thus, the inequality in Eq. 9 is tight, and
(y(k), z(k)) and u(k) are primal and dual optimal.
Although the algorithm is not guaranteed to sat-
isfy y(k) = z(k) for some k, by Theorem 1 if it does
reach such a state, then we have the guarantee of an
exact solution to Eq. 4, with the dual solution u pro-
viding a certificate of optimality. We show in the
experiments that this occurs very frequently, in spite
of the parsing problem being NP-hard.
It can be shown that Eq. 8 is the dual of an LP
relaxation of the original problem. When the con-
ditions of Theorem 1 are satisfied, it means that the
LP relaxation is tight for this instance. For brevity
we omit the details, except to note that when the LP
relaxation is not tight, the optimal primal solution to
the LP relaxation could be recovered by averaging
methods (Nedic? and Ozdaglar, 2009).
5 Grandparent Dependency Models
In this section we extend the approach to consider
grandparent relations. In grandparent models each
parse tree y is represented as a vector
y = {y(i, j) : (i, j) ? I} ? {y?(i, j) : (i, j) ? I}
where we have added a second set of duplicate vari-
ables, y?(i, j) for all (i, j) ? I. The set of all valid
parse trees is then defined as
Y = {y : y(i, j) variables form a directed tree,
y?(i, j) = y(i, j) for all (i, j) ? I}
We again partition the variables into n + 1 subsets,
y|0 . . . y|n, by (re)defining
y|i = {y(i, j) : j = 1 . . . n, j 6= i}
?{y?(k, i) : k = 0 . . . n, k 6= i}
So as before y|i contains variables y(i, j) which in-
dicate which words modify the i?th word. In addi-
tion, y|i includes y?(k, i) variables that indicate the
word that word i itself modifies.
The set of all possible values of y|i is now
Zi = {y|i : y(i, j) ? {0, 1} for j = 1 . . . n, j 6= i;
y?(k, i) ? {0, 1} for k = 0 . . . n, k 6= i;
?
k
y?(k, i) = 1}
Hence the y(i, j) variables can take any values, but
only one of the y?(k, i) variables can be equal to 1
(as only one word can be a parent of word i). As be-
fore, we define Z = {y : y|i ? Zi for i = 0 . . . n}.
We introduce the following assumption:
Assumption 2 (GS Decompositions)
A model f(y) satisfies the grandparent/sibling-
decomposition (GSD) assumption if: 1) f(z) =
?n
i=0 fi(z|i) for some set of functions f0 . . . fn. 2)
For any i ? {0 . . . n}, for any value of the variables
u(i, j) ? R for j = 1 . . . n, and v(k, i) ? R for
k = 0 . . . n, it is possible to compute
argmax
z|i?Zi
(fi(z|i)?
?
j
u(i, j)z(i, j)?
?
k
v(k, i)z?(k, i))
in polynomial time.
1292
Again, it follows that we can approxi-
mate y? = argmaxy?Y
?n
i=0 fi(y|i) by
z? = argmaxz?Z
?n
i=0 fi(z|i), by defining
z?|i = argmaxz|i?Zi fi(z|i) for i = 0 . . . n. The
resulting vector z? may be deficient in two respects.
First, the variables z?(i, j) may not form a well-
formed directed spanning tree. Second, we may
have z??(i, j) 6= z
?(i, j) for some values of (i, j).
Example 3: Grandparent/Sibling Models An
important class of models that satisfy Assumption 2
are defined as follows. Again, for a vector y|i de-
fine l1 . . . lp to be the sequence of left modifiers to
word i under y|i, and r1 . . . rq to be the set of right
modifiers. Define k? to the value for k such that
y?(k, i) = 1. Then the model is defined as follows:
fi(y|i) =
p+1?
j=1
gL(i, k
?, lj?1, lj)+
q+1?
j=1
gR(i, k
?, rj?1, rj)
This is very similar to the bigram-sibling model, but
with the modification that the gL and gR functions
depend in addition on the value for k?. This al-
lows these functions to model grandparent depen-
dencies such as (k?, i, lj) and sibling dependencies
such as (i, lj?1, lj). Finding z?|i under the definition
can be accomplished inO(n3) time, by decoding the
model using dynamic programming separately for
each of the O(n) possible values of k?, and pick-
ing the value for k? that gives the maximum value
under these decodings.
A dual-decomposition algorithm for models that
satisfy the GSD assumption is shown in Figure 2.
The algorithm can be justified as an instance of La-
grangian relaxation applied to the problem
argmax
z?Z,y?Y
f(z) + h(y) (10)
with constraints
z(i, j) = y(i, j) for all (i, j) ? I (11)
z?(i, j) = y(i, j) for all (i, j) ? I (12)
The algorithm employs two sets of Lagrange mul-
tipliers, u(i, j) and v(i, j), corresponding to con-
straints in Eqs. 11 and 12. As in Theorem 1, if at any
point in the algorithm z(k) = y(k), then (z(k), y(k))
is an exact solution to the problem in Eq. 10.
Set u(1)(i, j)? 0, v(1)(i, j)? 0 for all (i, j) ? I
for k = 1 to K do
y(k) ? argmax
y?Y
?
(i,j)?I
y(i, j)?(i, j)
where ?(i, j) = ?(i, j) + u(k)(i, j) + v(k)(i, j).
for i ? {0 . . . n},
z(k)|i ? argmax
z|i?Zi
(fi(z|i) ?
?
j
u(k)(i, j)z(i, j)
?
?
j
v(k)(j, i)z?(j, i))
if y(k)(i, j) = z(k)(i, j) = z(k)? (i, j) for all (i, j) ? I
then
return (y(k), z(k))
for all (i, j) ? I,
u(k+1)(i, j)? u(k)(i, j)+?k(z(k)(i, j)?y(k)(i, j))
v(k+1)(i, j)? v(k)(i, j)+?k(z
(k)
? (i, j)?y
(k)(i, j))
return (y(K), z(K))
Figure 2: The parsing algorithm for grandparent/sibling-
decomposable models.
6 The Training Algorithm
In our experiments we make use of discriminative
linear models, where for an input sentence x, the
score for a parse y is f(y) = w ? ?(x, y) where
w ? Rd is a parameter vector, and ?(x, y) ? Rd
is a feature-vector representing parse tree y in con-
junction with sentence x. We will assume that the
features decompose in the same way as the sibling-
decomposable or grandparent/sibling-decomposable
models, that is ?(x, y) =
?n
i=0 ?(x, y|i) for some
feature vector definition ?(x, y|i). In the bigram sib-
ling models in our experiments, we assume that
?(x, y|i) =
p+1?
k=1
?L(x, i, lk?1, lk) +
q+1?
k=1
?R(x, i, rk?1, rk)
where as before l1 . . . lp and r1 . . . rq are left and
right modifiers under y|i, and where ?L and ?R
are feature vector definitions. In the grandparent
models in our experiments, we use a similar defi-
nition with feature vectors ?L(x, i, k?, lk?1, lk) and
?R(x, i, k?, rk?1, rk), where k? is the parent for
word i under y|i.
We train the model using the averaged perceptron
for structured problems (Collins, 2002). Given the
i?th example in the training set, (x(i), y(i)), the per-
ceptron updates are as follows:
? z? = argmaxy?Z w ? ?(x
(i), y)
? If z? 6= y(i), w = w+?(x(i), y(i))??(x(i), z?)
1293
The first step involves inference over the set Z ,
rather than Y as would be standard in the percep-
tron. Thus, decoding during training can be achieved
by dynamic programming over head automata alone,
which is very efficient.
Our training approach is closely related to local
training methods (Punyakanok et al, 2005). We
have found this method to be effective, very likely
because Z is a superset of Y . Our training algo-
rithm is also related to recent work on training using
outer bounds (see, e.g., (Taskar et al, 2003; Fin-
ley and Joachims, 2008; Kulesza and Pereira, 2008;
Martins et al, 2009)). Note, however, that the LP re-
laxation optimized by dual decomposition is signifi-
cantly tighter than Z . Thus, an alternative approach
would be to use the dual decomposition algorithm
for inference during training.
7 Experiments
We report results on a number of data sets. For
comparison to Martins et al (2009), we perform ex-
periments for Danish, Dutch, Portuguese, Slovene,
Swedish and Turkish data from the CoNLL-X
shared task (Buchholz and Marsi, 2006), and En-
glish data from the CoNLL-2008 shared task (Sur-
deanu et al, 2008). We use the official training/test
splits for these data sets, and the same evaluation
methodology as Martins et al (2009). For com-
parison to Smith and Eisner (2008), we also re-
port results on Danish and Dutch using their alter-
nate training/test split. Finally, we report results on
the English WSJ treebank, and the Prague treebank.
We use feature sets that are very similar to those
described in Carreras (2007). We use marginal-
based pruning, using marginals calculated from an
arc-factored spanning tree model using the matrix-
tree theorem (McDonald and Satta, 2007; Smith and
Smith, 2007; Koo et al, 2007).
In all of our experiments we set the value K, the
maximum number of iterations of dual decompo-
sition in Figures 1 and 2, to be 5,000. If the al-
gorithm does not terminate?i.e., it does not return
(y(k), z(k)) within 5,000 iterations?we simply take
the parse y(k) with the maximum value of f(y(k)) as
the output from the algorithm. At first sight 5,000
might appear to be a large number, but decoding is
still fast?see Sections 7.3 and 7.4 for discussion.2
2Note also that the feature vectors ? and inner productsw ??
The strategy for choosing step sizes ?k is described
in Appendix A, along with other details.
We first discuss performance in terms of accu-
racy, success in recovering an exact solution, and
parsing speed. We then describe additional experi-
ments examining various aspects of the algorithm.
7.1 Accuracy
Table 1 shows results for previous work on the var-
ious data sets, and results for an arc-factored model
with pure MST decoding with our features. (We use
the acronym UAS (unlabeled attachment score) for
dependency accuracy.) We also show results for the
bigram-sibling and grandparent/sibling (G+S) mod-
els under dual decomposition. Both the bigram-
sibling and G+S models show large improvements
over the arc-factored approach; they also compare
favorably to previous work?for example the G+S
model gives better results than all results reported in
the CoNLL-X shared task, on all languages. Note
that we use different feature sets from both Martins
et al (2009) and Smith and Eisner (2008).
7.2 Success in Recovering Exact Solutions
Next, we consider how often our algorithms return
an exact solution to the original optimization prob-
lem, with a certificate?i.e., how often the algo-
rithms in Figures 1 and 2 terminate with y(k) = z(k)
for some value of k < 5000 (and are thus optimal,
by Theorem 1). The CertS and CertG columns in Ta-
ble 1 give the results for the sibling and G+S models
respectively. For all but one setting3 over 95% of the
test sentences are decoded exactly, with 99% exact-
ness in many cases.
For comparison, we also ran both the single-
commodity flow and multiple-commodity flow LP
relaxations of Martins et al (2009) with our mod-
els and features. We measure how often these re-
laxations terminate with an exact solution. The re-
sults in Table 2 show that our method gives exact
solutions more often than both of these relaxations.4
In computing the accuracy figures for Martins et al
only need to be computed once, thus saving computation.
3The exception is Slovene, which has the smallest training
set at only 1534 sentences.
4Note, however, that it is possible that the Martins et al re-
laxations would have given a higher proportion of integral solu-
tions if their relaxation was used during training.
1294
Ma09 MST Sib G+S Best CertS CertG TimeS TimeG TrainS TrainG
Dan 91.18 89.74 91.08 91.78 91.54 99.07 98.45 0.053 0.169 0.051 0.109
Dut 85.57 82.33 84.81 85.81 85.57 98.19 97.93 0.035 0.120 0.046 0.048
Por 92.11 90.68 92.57 93.03 92.11 99.65 99.31 0.047 0.257 0.077 0.103
Slo 85.61 82.39 84.89 86.21 85.61 90.55 95.27 0.158 0.295 0.054 0.130
Swe 90.60 88.79 90.10 91.36 90.60 98.71 98.97 0.035 0.141 0.036 0.055
Tur 76.34 75.66 77.14 77.55 76.36 98.72 99.04 0.021 0.047 0.016 0.036
Eng1 91.16 89.20 91.18 91.59 ? 98.65 99.18 0.082 0.200 0.032 0.076
Eng2 ? 90.29 92.03 92.57 ? 98.96 99.12 0.081 0.168 0.032 0.076
Sm08 MST Sib G+S ? CertS CertG TimeS TimeG TrainS TrainG
Dan 86.5 87.89 89.58 91.00 ? 98.50 98.50 0.043 0.120 0.053 0.065
Dut 88.5 88.86 90.87 91.76 ? 98.00 99.50 0.036 0.046 0.050 0.054
Mc06 MST Sib G+S ? CertS CertG TimeS TimeG TrainS TrainG
PTB 91.5 90.10 91.96 92.46 ? 98.89 98.63 0.062 0.210 0.028 0.078
PDT 85.2 84.36 86.44 87.32 ? 96.67 96.43 0.063 0.221 0.019 0.051
Table 1: A comparison of non-projective automaton-based parsers with results from previous work. MST: Our first-
order baseline. Sib/G+S: Non-projective head automata with sibling or grandparent/sibling interactions, decoded via
dual decomposition. Ma09: The best UAS of the LP/ILP-based parsers introduced in Martins et al (2009). Sm08:
The best UAS of any LBP-based parser in Smith and Eisner (2008). Mc06: The best UAS reported by McDonald
and Pereira (2006). Best: For the CoNLL-X languages only, the best UAS for any parser in the original shared task
(Buchholz and Marsi, 2006) or in any column of Martins et al (2009, Table 1); note that the latter includes McDonald
and Pereira (2006), Nivre and McDonald (2008), and Martins et al (2008). CertS/CertG: Percent of test examples
for which dual decomposition produced a certificate of optimality, for Sib/G+S. TimeS/TimeG: Seconds/sentence for
test decoding, for Sib/G+S. TrainS/TrainG: Seconds/sentence during training, for Sib/G+S. For consistency of timing,
test decoding was carried out on identical machines with zero additional load; however, training was conducted on
machines with varying hardware and load. We ran two tests on the CoNLL-08 corpus. Eng1: UAS when testing on
the CoNLL-08 validation set, following Martins et al (2009). Eng2: UAS when testing on the CoNLL-08 test set.
(2009), we project fractional solutions to a well-
formed spanning tree, as described in that paper.
Finally, to better compare the tightness of our
LP relaxation to that of earlier work, we consider
randomly-generated instances. Table 2 gives results
for our model and the LP relaxations of Martins et al
(2009) with randomly generated scores on automata
transitions. We again recover exact solutions more
often than the Martins et al relaxations. Note that
with random parameters the percentage of exact so-
lutions is significantly lower, suggesting that the ex-
actness of decoding of the trained models is a special
case. We speculate that this is due to the high perfor-
mance of approximate decoding with Z in place of
Y under the trained models for fi; the training algo-
rithm described in section 6 may have the tendency
to make the LP relaxation tight.
7.3 Speed
Table 1, columns TimeS and TimeG, shows decod-
ing times for the dual decomposition algorithms.
Table 2 gives speed comparisons to Martins et al
(2009). Our method gives significant speed-ups over
 0
 5
 10
 15
 20
 25
 30
 0  1000  2000  3000  4000  5000%
 of 
He
ad 
Au
tom
ata
 Re
com
put
ed
Iterations of Dual Decomposition
% recomputed, g+s% recomputed, sib
Figure 3: The average percentage of head automata that
must be recomputed on each iteration of dual decompo-
sition on the PTB validation set.
the Martins et al (2009) method, presumably be-
cause it leverages the underlying structure of the
problem, rather than using a generic solver.
7.4 Lazy Decoding
Here we describe an important optimization in the
dual decomposition algorithms. Consider the algo-
rithm in Figure 1. At each iteration we must find
z(k)|i = argmax
z|i?Zi
(fi(z|i)?
?
j
u(k)(i, j)z(i, j))
1295
Sib Acc Int Time Rand
LP(S) 92.14 88.29 0.14 11.7
LP(M) 92.17 93.18 0.58 30.6
ILP 92.19 100.0 1.44 100.0
DD-5000 92.19 98.82 0.08 35.6
DD-250 92.23 89.29 0.03 10.2
G+S Acc Int Time Rand
LP(S) 92.60 91.64 0.23 0.0
LP(M) 92.58 94.41 0.75 0.0
ILP 92.70 100.0 1.79 100.0
DD-5000 92.71 98.76 0.23 6.8
DD-250 92.66 85.47 0.12 0.0
Table 2: A comparison of dual decomposition with lin-
ear programs described by Martins et al (2009). LP(S):
Linear Program relaxation based on single-commodity
flow. LP(M): Linear Program relaxation based on
multi-commodity flow. ILP: Exact Integer Linear Pro-
gram. DD-5000/DD-250: Dual decomposition with non-
projective head automata, with K = 5000/250. Upper
results are for the sibling model, lower results are G+S.
Columns give scores for UAS accuracy, percentage of so-
lutions which are integral, and solution speed in seconds
per sentence. These results are for Section 22 of the PTB.
The last column is the percentage of integral solutions on
a random problem of length 10 words. The (I)LP experi-
ments were carried out using Gurobi, a high-performance
commercial-grade solver.
for i = 0 . . . n. However, if for some i, u(k)(i, j) =
u(k?1)(i, j) for all j, then z(k)|i = z
(k?1)
|i . In
lazy decoding we immediately set z(k)|i = z
(k?1)
|i if
u(k)(i, j) = u(k?1)(i, j) for all j; this check takes
O(n) time, and saves us from decoding with the i?th
automaton. In practice, the updates to u are very
sparse, and this condition occurs very often in prac-
tice. Figure 3 demonstrates the utility of this method
for both sibling automata and G+S automata.
7.5 Early Stopping
We also ran experiments varying the value of K?
the maximum number of iterations?in the dual de-
composition algorithms. As before, if we do not find
y(k) = z(k) for some value of k ? K, we choose
the y(k) with optimal value for f(y(k)) as the final
solution. Figure 4 shows three graphs: 1) the accu-
racy of the parser on PTB validation data versus the
value for K; 2) the percentage of examples where
y(k) = z(k) at some point during the algorithm,
hence the algorithm returns a certificate of optimal-
ity; 3) the percentage of examples where the solution
 50
 60
 70
 80
 90
 100
 0  200  400  600  800  1000
Pe
rce
nta
ge
Maximum Number of Dual Decomposition Iterations
% validation UAS% certificates% match K=5000
Figure 4: The behavior of the dual-decomposition parser
with sibling automata as the value of K is varied.
Sib P-Sib G+S P-G+S
PTB 92.19 92.34 92.71 92.70
PDT 86.41 85.67 87.40 86.43
Table 3: UAS of projective and non-projective decoding
for the English (PTB) and Czech (PDT) validation sets.
Sib/G+S: as in Table 1. P-Sib/P-G+S: Projective versions
of Sib/G+S, where the MST component has been re-
placed with the Eisner (2000) first-order projective parser.
returned is the same as the solution for the algorithm
with K = 5000 (our original setting). It can be seen
for K as small as 250 we get very similar accuracy
to K = 5000 (see Table 2). In fact, for this set-
ting the algorithm returns the same solution as for
K = 5000 on 99.59% of the examples. However
only 89.29% of these solutions are produced with a
certificate of optimality (y(k) = z(k)).
7.6 How Good is the Approximation z??
We ran experiments measuring the quality of z? =
argmaxz?Z f(z), where f(z) is given by the
perceptron-trained bigram-sibling model. Because
z? may not be a well-formed tree with n dependen-
cies, we report precision and recall rather than con-
ventional dependency accuracy. Results on the PTB
validation set were 91.11%/88.95% precision/recall,
which is accurate considering the unconstrained na-
ture of the predictions. Thus the z? approximation is
clearly a good one; we suspect that this is one reason
for the good convergence results for the method.
7.7 Importance of Non-Projective Decoding
It is simple to adapt the dual-decomposition algo-
rithms in figures 1 and 2 to give projective depen-
dency structures: the set Y is redefined to be the set
1296
of all projective structures, with the argmax over Y
being calculated using a projective first-order parser
(Eisner, 2000). Table 3 shows results for projec-
tive and non-projective parsing using the dual de-
composition approach. For Czech data, where non-
projective structures are common, non-projective
decoding has clear benefits. In contrast, there is little
difference in accuracy between projective and non-
projective decoding on English.
8 Conclusions
We have described dual decomposition algorithms
for non-projective parsing, which leverage existing
dynamic programming and MST algorithms. There
are a number of possible areas for future work. As
described in section 7.7, the algorithms can be easily
modified to consider projective structures by replac-
ing Y with the set of projective trees, and then using
first-order dependency parsing algorithms in place
of MST decoding. This method could be used to
derive parsing algorithms that include higher-order
features, as an alternative to specialized dynamic
programming algorithms. Eisner (2000) describes
extensions of head automata to include word senses;
we have not discussed this issue in the current pa-
per, but it is simple to develop dual decomposition
algorithms for this case, using similar methods to
those used for the grandparent models. The gen-
eral approach should be applicable to other lexical-
ized syntactic formalisms, and potentially also to de-
coding in syntax-driven translation. In addition, our
dual decomposition approach is well-suited to paral-
lelization. For example, each of the head-automata
could be optimized independently in a multi-core or
GPU architecture. Finally, our approach could be
used with other structured learning algorithms, e.g.
Meshi et al (2010).
A Implementation Details
This appendix describes details of the algorithm,
specifically choice of the step sizes ?k, and use of
the ?(i, j) parameters.
A.1 Choice of Step Sizes
We have found the following method to be effec-
tive. First, define ? = f(z(1)) ? f(y(1)), where
(z(1), y(1)) is the output of the algorithm on the first
iteration (note that we always have ? ? 0 since
f(z(1)) = L(u(1))). Then define ?k = ?/(1 + ?k),
where ?k is the number of times that L(u(k
?)) >
L(u(k
??1)) for k? ? k. Hence the learning rate drops
at a rate of 1/(1+ t), where t is the number of times
that the dual increases from one iteration to the next.
A.2 Use of the ?(i, j) Parameters
The parsing algorithms both consider a general-
ized problem that includes ?(i, j) parameters. We
now describe how these can be useful. Re-
call that the optimization problem is to solve
argmaxz?Z,y?Y f(z) + h(y), subject to a set of
agreement constraints. In our models, f(z) can
be written as f ?(z) +
?
i,j ?(i, j)z(i, j) where
f ?(z) includes only terms depending on higher-
order (non arc-factored features), and ?(i, j) are
weights that consider the dependency between i
and j alone. For any value of 0 ? ? ?
1, the problem argmaxz?Z,y?Y f2(z) + h2(y) is
equivalent to the original problem, if f2(z) =
f ?(z) + (1 ? ?)
?
i,j ?(i, j)z(i, j) and h2(y) =
?
?
i,j ?(i, j)y(i, j). We have simply shifted the
?(i, j) weights from one model to the other. While
the optimization problem remains the same, the al-
gorithms in Figure 1 and 2 will converge at differ-
ent rates depending on the value for ?. In our ex-
periments we set ? = 0.001, which puts almost
all the weight in the head-automata models, but al-
lows weights on spanning tree edges to break ties in
MST inference in a sensible way. We suspect this is
important in early iterations of the algorithm, when
many values for u(i, j) or v(i, j) will be zero, and
where with ? = 0 many spanning tree solutions y(k)
would be essentially random, leading to very noisy
updates to the u(i, j) and v(i, j) values. We have
not tested other values for ?.
Acknowledgments MIT gratefully acknowledges the
support of Defense Advanced Research Projects Agency
(DARPA) Machine Reading Program under Air Force Research
Laboratory (AFRL) prime contract no. FA8750-09-C-0181.
Any opinions, findings, and conclusion or recommendations ex-
pressed in this material are those of the author(s) and do not
necessarily reflect the view of the DARPA, AFRL, or the US
government. A. Rush was supported by the GALE program of
the DARPA, Contract No. HR0011-06-C-0022. D. Sontag was
supported by a Google PhD Fellowship.
1297
References
H. Alshawi. 1996. Head Automata and Bilingual Tiling:
Translation with Minimal Representations. In Proc.
ACL, pages 167?176.
S. Buchholz and E. Marsi. 2006. CoNLL-X Shared
Task on Multilingual Dependency Parsing. In Proc.
CoNLL, pages 149?164.
X. Carreras. 2007. Experiments with a Higher-Order
Projective Dependency Parser. In Proc. EMNLP-
CoNLL, pages 957?961.
M. Collins. 2002. Discriminative Training Methods
for Hidden Markov Models: Theory and Experiments
with Perceptron Algorithms. In Proc. EMNLP, pages
1?8.
J. Duchi, D. Tarlow, G. Elidan, and D. Koller. 2007. Us-
ing Combinatorial Optimization within Max-Product
Belief Propagation. In NIPS, pages 369?376.
J. Eisner. 2000. Bilexical grammars and their cubic-
time parsing algorithms. Advances in Probabilistic
and Other Parsing Technologies, pages 29?62.
T. Finley and T. Joachims. 2008. Training structural
svms when exact inference is intractable. In ICML,
pages 304?311.
A.K. Joshi and Y. Schabes. 1997. Tree-Adjoining
Grammars. Handbook of Formal Languages: Beyond
Words, 3:69?123.
N. Komodakis, N. Paragios, and G. Tziritas. 2007. MRF
Optimization via Dual Decomposition: Message-
Passing Revisited. In Proc. ICCV.
T. Koo, A. Globerson, X. Carreras, and M. Collins. 2007.
Structured Prediction Models via the Matrix-Tree The-
orem. In Proc. EMNLP-CoNLL, pages 141?150.
B.H. Korte and J. Vygen. 2008. Combinatorial Opti-
mization: Theory and Algorithms. Springer Verlag.
A. Kulesza and F. Pereira. 2008. Structured learning
with approximate inference. In NIPS.
C. Lemare?chal. 2001. Lagrangian Relaxation. In Com-
putational Combinatorial Optimization, Optimal or
Provably Near-Optimal Solutions [based on a Spring
School], pages 112?156, London, UK. Springer-
Verlag.
A.F.T. Martins, D. Das, N.A. Smith, and E.P. Xing. 2008.
Stacking Dependency Parsers. In Proc. EMNLP,
pages 157?166.
A.F.T. Martins, N.A. Smith., and E.P. Xing. 2009. Con-
cise Integer Linear Programming Formulations for De-
pendency Parsing. In Proc. ACL, pages 342?350.
R. McDonald and F. Pereira. 2006. Online Learning
of Approximate Dependency Parsing Algorithms. In
Proc. EACL, pages 81?88.
R. McDonald and G. Satta. 2007. On the Complexity of
Non-Projective Data-Driven Dependency Parsing. In
Proc. IWPT.
R. McDonald, F. Pereira, K. Ribarov, and J. Hajic?. 2005.
Non-Projective Dependency Parsing using Spanning
Tree Algorithms. In Proc. HLT-EMNLP, pages 523?
530.
O. Meshi, D. Sontag, T. Jaakkola, and A. Globerson.
2010. Learning Efficiently with Approximate Infer-
ence via Dual Losses. In Proc. ICML.
A. Nedic? and A. Ozdaglar. 2009. Approximate
Primal Solutions and Rate Analysis for Dual Sub-
gradient Methods. SIAM Journal on Optimization,
19(4):1757?1780.
J. Nivre and R. McDonald. 2008. Integrating Graph-
Based and Transition-Based Dependency Parsers. In
Proc. ACL, pages 950?958.
V. Punyakanok, D. Roth, W. Yih, and D. Zimak. 2005.
Learning and Inference over Constrained Output. In
Proc. IJCAI, pages 1124?1129.
S. Riedel and J. Clarke. 2006. Incremental Integer Linear
Programming for Non-projective Dependency Parsing.
In Proc. EMNLP, pages 129?137.
A.M. Rush, D. Sontag, M. Collins, and T. Jaakkola.
2010. On Dual Decomposition and Linear Program-
ming Relaxations for Natural Language Processing. In
Proc. EMNLP.
D.A. Smith and J. Eisner. 2008. Dependency Parsing by
Belief Propagation. In Proc. EMNLP, pages 145?156.
D.A. Smith and N.A. Smith. 2007. Probabilistic Mod-
els of Nonprojective Dependency Trees. In Proc.
EMNLP-CoNLL, pages 132?140.
D. Sontag, T. Meltzer, A. Globerson, T. Jaakkola, and
Y. Weiss. 2008. Tightening LP Relaxations for MAP
using Message Passing. In Proc. UAI.
M. Steedman. 2000. The Syntactic Process. MIT Press.
M. Surdeanu, R. Johansson, A. Meyers, L. Ma`rquez, and
J. Nivre. 2008. The CoNLL-2008 Shared Task on
Joint Parsing of Syntactic and Semantic Dependencies.
In Proc. CoNLL.
B. Taskar, C. Guestrin, and D. Koller. 2003. Max-margin
Markov networks. In NIPS.
M. Wainwright, T. Jaakkola, and A. Willsky. 2005. MAP
estimation via agreement on trees: message-passing
and linear programming. In IEEE Transactions on In-
formation Theory, volume 51, pages 3697?3717.
1298
