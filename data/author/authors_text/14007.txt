Proceedings of the Workshop on Negation and Speculation in Natural Language Processing, pages 69?77,
Uppsala, July 2010.
Evaluating a Meta-Knowledge Annotation Scheme for Bio-Events 
 
 
Raheel Nawaz1 Paul Thompson1,2 Sophia Ananiadou1,2 
1School of Computer Science, University of Manchester, UK 
2National Centre for Text Mining, University of Manchester, UK  
E-mail: nawazr@cs.man.ac.uk, paul.thompson@manchester.ac.uk, 
sophia.ananiadou@manchester.ac.uk 
 
  
 
Abstract 
The correct interpretation of biomedical texts 
by text mining systems requires the recogni-
tion of a range of types of high-level informa-
tion (or meta-knowledge) about the text. Ex-
amples include expressions of negation and 
speculation, as well as pragmatic/rhetorical in-
tent (e.g. whether the information expressed 
represents a hypothesis, generally accepted 
knowledge, new experimental knowledge, 
etc.) Although such types of information have 
previously been annotated at the text-span 
level (most commonly sentences), annotation 
at the level of the event is currently quite 
sparse. In this paper, we focus on the evalua-
tion of the multi-dimensional annotation 
scheme that we have developed specifically 
for enriching bio-events with meta-knowledge 
information. Our annotation scheme is in-
tended to be general enough to allow integra-
tion with different types of bio-event annota-
tion, whilst being detailed enough to capture 
important subtleties in the nature of the meta-
knowledge expressed in the text. To our 
knowledge, our scheme is unique within the 
field with regards to the diversity of meta-
knowledge aspects annotated for each event, 
whilst the evaluation results have confirmed 
its feasibility and soundness.  
1 Introduction 
The ability to recognise high-level information 
(or meta-knowledge) relating to the interpreta-
tion of texts is an important task for text mining 
systems. There are several types of meta-
knowledge that fall under this category. For ex-
ample, the detection of expressions of specula-
tion and negation is important across all do-
mains, although the way in which these phenom-
ena are expressed may be domain-specific. In 
scientific texts, it is also important to be able to 
determine other types of information, such as the 
author?s rhetorical/pragmatic intent (de Waard et 
al., 2009). This would correspond to whether the 
information expressed represents a hypothesis, 
accepted knowledge, new experimental knowl-
edge, etc.  
The ability to distinguish between these dif-
ferent types of information can be important for 
tasks such as  building and updating models of 
biological processes, like pathways (Oda et al, 
2008), and curation of biological databases 
(Ashburner et al, 2000). Central to both of these 
tasks is the identification of new knowledge that 
can enhance these resources, e.g. to build upon 
an existing, but incomplete model of a biological 
process (Lisacek et al, 2005) or to ensure that 
the database is kept up to date. Any new knowl-
edge added should be supported though evi-
dence, which could include linking hypotheses 
with experimental findings. It is also important to 
take into account inconsistencies and contradic-
tions reported in the literature. 
The production of annotated corpora can help 
to train text mining systems to recognise types of 
meta-knowledge, such as the above. Although a 
number of such corpora have already been pro-
duced, different annotation schemes are required 
according to the exact domain under considera-
tion, as well as the types of task that will be un-
dertaken by the text mining system.  
The work described in this paper is focused on 
the design and evaluation of the meta-knowledge 
annotation scheme described in Nawaz et al, 
(2010). The annotation scheme has been specifi-
cally designed to recognise a range of meta-
knowledge types for events extracted from bio-
medical texts (henceforth bio-events). The aim is 
to facilitate the development of more useful sys-
tems in the context of various biomedical infor-
mation extraction (IE) and textual inference (TI) 
tasks. Although the scheme has been designed 
69
for application to existing bio-event corpora, it is 
intended to be applied to any type of bio-relation 
corpora, and can easily be tailored for other types 
of relations/events within the domain. 
1.1  Bio-Event Representation of Text 
Searching for relevant information in electronic 
documents is most commonly carried out by en-
tering keywords into a search engine. However, 
such searches will normally return a huge num-
ber of documents, many of which will be irrele-
vant to the user?s needs.  
A more promising and efficient way of search-
ing is over events that have been extracted from 
texts through the application of natural language 
processing methods. An event is a structured rep-
resentation of a certain piece of information con-
tained within the text, which is usually anchored 
to a particular word in the text (typically a verb 
or noun) that is central to the description of the 
event. Events are often represented by a tem-
plate-like structure with slots that are filled by 
the event participants. Each event participant is 
also assigned a role within the event. These par-
ticipants can be entities, concepts or even other 
events. This kind of event representation allows 
the information contained in a text to be repre-
sented as a collection of nested events.  
A bio-event is an event specialised for the 
biomedical domain. Kim et al (2008) define a 
bio-event as a dynamic bio-relation involving 
one or more participants. These participants can 
be bio-entities or (other) bio-events, and are each 
assigned a semantic role/slot like theme and 
cause etc. Each bio-event is typically assigned a 
type/class from a chosen bio-event taxon-
omy/ontology, e.g., the GENIA Event Ontology 
(Kim et al, 2008). Similarly, the bio-entities are 
also assigned types/classes from a chosen bio-
term taxonomy/ontology, e.g., the Gene Ontol-
ogy (Ashburner et al, 2000). 
As an example, consider the simple sentence 
shown in Figure 1. 
This sentence contains a single bio-event, an-
chored to the verb activates. Figure 2 shows a 
typical structured representation of this bio-
event. 
The fact that the verb is anchored to the verb 
activates allows the event-type of positive regu-
lation to be assigned. The event has two slots, 
i.e. theme and cause whose labels help to charac-
terise the contribution that the slot filler makes 
towards the meaning of the event. In this case, 
the slots are filled by the subject and object of 
the verb activates, both of which correspond to 
different types of bio-entities (i.e. operon and 
protein).  
IE systems trained to extract bio-events from 
texts allow users to formulate semantic queries 
over the extracted events. Such queries can  
specify semantic restrictions on the events in 
terms of event types, semantic role labels and 
named entity types etc. (Miyao et al, 2006), in 
addition to particular keywords. For example, it 
would be possible to search only for those texts 
containing bio-events of type nega-
tive_regulation where the cause is an entity of 
type protein. Such queries provide a great deal 
more descriptive power than traditional keyword 
searches over unstructured documents.  Bio-
medical corpora that have been manually anno-
tated with event level information (e.g., Pyysalo 
et al, 2007; Kim et al, 2008; Thompson et al, 
2009) facilitate the training of systems such as 
those described above.  
Whilst event-based querying has advantages 
for efficient searching, the extracted events have 
little practical use if they are not accompanied by 
meta-knowledge information to aid in their inter-
pretation.  
1.2 Existing Meta-knowledge Annotation 
Various corpora of biomedical literature (ab-
stracts and/or full papers) have been produced 
that feature some degree of meta-knowledge an-
notation. These corpora vary in both the richness 
of the annotation added, and the type/size of the 
units at which the meta-knowledge annotation 
has been performed. Taking the unit of annota-
tion into account, we can distinguish between 
annotations that apply to continuous text-spans, 
and annotations that have been performed at the 
event level. 
Text-Span Annotation: Such annotations have 
mostly been carried out at the sentence level. 
They normally concentrate on a single aspect (or 
The results suggest that the narL gene product 
activates the nitrate reductase operon. 
 
Figure 1. A Simple Sentence from a Biomedi-
cal Abstract 
Figure 2. Typical Structured Representation 
of the Bio-Event mentioned in Figure 1 
EVENT-TRIGGER: activates 
EVENT-TYPE: positive_regulation 
THEME: nitrate reductase operon: operon 
CAUSE: narL gene product: protein 
 
70
dimension) of meta-knowledge, normally either 
speculation/certainty level, (e.g., Light et al, 
2004; Medlock & Briscoe, 2007; Vincze et al, 
2008) or general information content/rhetorical 
intent, e.g., background, methods, results, in-
sights. This latter type of annotation has been 
attempted both on abstracts, (e.g., McKnight & 
Srinivasan, 2003; Ruch et al, 2007) and full pa-
pers, (e.g. Teufel et al, 1999; Langer et al, 2004; 
Mizuta & Collier, 2004), with the number of dis-
tinct annotation categories varying between 4 
and 14.  
Despite the availability of these corpora, anno-
tation at the sentence level can often be too 
granular. In terms of information content, a sen-
tence may describe, for example, both an ex-
perimental method and its results. The situation 
becomes more complicated if a sentence contains 
an expression of speculation. If this is only 
marked at the sentence level, there may be con-
fusion about which part(s) of the sentence are 
affected by the speculative expression.  
Certain corpora and associated systems have 
attempted to address these issues. The BioScope 
corpus (Vincze et al, 2008) annotates the scopes 
of negative and speculative keywords, whilst 
Morante & Daelemans (2009) have trained a sys-
tem to undertake this task. The scheme described 
by Wilbur et al (2006) applies annotation to 
fragments of sentences, which are created on the 
basis of changes in the meta-knowledge ex-
pressed. The scheme consists of multiple annota-
tion dimensions which capture aspects of both 
certainty and rhetorical/pragmatic intent, 
amongst other things. Training a system to auto-
matically annotate these dimensions is shown to 
be highly feasible (Shatkay et al, 2008). 
Event-Level Annotation: Explicit annotation of 
meta-knowledge at the event-level is currently 
rather minimal within biomedical corpora. 
Whilst several corpora contain annotations to 
distinguish positive and negative events (e.g. 
Sanchez-Graillet & Poesio, 2007; Pyysalo et al, 
2007), the annotation of the GENIA Event Cor-
pus (Kim et al, 2008) is slightly more extensive, 
in that it additionally annotates certainty level. 
To our knowledge, no existing bio-event corpus 
has attempted annotation that concerns rhetori-
cal/pragmatic intent.  
 
1.3 The Need for an Event-Centric Meta-
Knowledge Annotation Scheme 
In comparison to meta-knowledge annotation 
carried out at the text-span level, the amount of 
annotation carried out at the event level is quite 
sparse. The question thus arises as to whether it 
is possible to use systems trained on text-span 
annotated corpora to assign meta-knowledge to 
bio-events, or whether new annotation at the 
event level is required.  
Some corpora seem better suited to this pur-
pose than others ? whilst sentence-level annota-
tions are certainly too granular for an event-
centric view of the text, sentence fragments, such 
as those identified by Wilbur et al (2006), are 
likely to correspond more closely to the extent of 
text that describes an event and its slots. Like-
wise, knowing the scopes of negative and specu-
lative keywords within a sentence may be a use-
ful aid in determining whether they affect the 
interpretation of a particular event.   
However, the information provided in these 
corpora is still not sufficiently precise for event-
level meta-knowledge annotation. Even within a 
text fragment, there may be several different bio-
events, each with slightly different meta-
knowledge interpretations. In a similar way, not 
all events that occur within the scope of a nega-
tion or speculation keyword are necessarily af-
fected by it.  
  Based on these observations, we have devel-
oped a meta-knowledge annotation scheme that 
is specifically tailored to bio-events. Our scheme 
annotates various different aspects or dimensions 
of meta-knowledge. A close examination of a 
large number of relevant bio-events has resulted 
in a scheme that has some similarities to previ-
ously proposed schemes, but has a number of 
differences that seem especially relevant when 
dealing with events, e.g. the annotation of the 
manner of the event. The scheme is intended to 
be general enough to allow integration with ex-
isting bio-event annotation schemes, whilst being 
detailed enough to capture important subtleties in 
the nature of the meta-knowledge expressed 
about the event.  
1.4 Lexical Markers of Meta-Knowledge 
Most of the existing corpora mentioned above 
annotate text spans or events with particular 
categories (e.g. certainty level or general infor-
mation type) in different meta-knowledge di-
mensions. However, what they do not normally 
do is to annotate lexical clues or keywords used 
to determine the correct values.  
A number of previous studies have demon-
strated the importance of lexical markers (i.e., 
words or phrases) that can accompany statements 
in scientific articles in determining the intended 
71
interpretation of the text (e.g. Hyland, 1996; Ri-
zomilioti 2006). We also performed a similar 
study (Thompson et al, 2008) although, in con-
trast to other studies, we took a multi-
dimensional approach to the categorisation of 
such lexical items, acknowledging that several 
types of important information may be expressed 
through different words in the same sentence. As 
an example, let us consider the example sentence 
in Figure 3.  
The author?s pragmatic/rhetorical intent to-
wards the statement that the catalytic role of 
these side chains is associated with their interac-
tion with the DNA substrate is encoded by the 
word indicate, which shows that the statement 
represents an analysis of the evidence stated at 
the beginning of the sentence, i.e., that the muta-
tions at positions 849 and 668 have DNA-
binding properties. Furthermore, the author?s 
certainty level (i.e., their degree of confidence) 
towards this analysis is shown by the word may. 
Here, the author is uncertain about the validity of 
their analysis. 
Whilst our previous work served to demon-
strate that the different aspects of meta-
knowledge that can be specified lexically within 
texts require a multi-dimensional analysis to cor-
rectly capture their subtleties, it showed that the 
presence of particular lexical items is not the 
only important feature for determining meta-
knowledge categories. In particular, their pres-
ence does not guarantee that the ?expected? in-
terpretation can be assumed (S?ndor, 2007). In 
addition, not all types of meta-knowledge are 
indicated through explicit markers. Mizuta & 
Collier (2004) note that  rhetorical zones may be 
indicated not only through explicit lexical mark-
ers, but also through features such as the main 
verb in the clause and the position of the sen-
tence within the article or abstract. 
For these reasons, we perform annotation on 
all relevant instances, regardless of the presence 
of lexical markers. This will allow systems to be 
trained that can learn to determine the correct 
meta-knowledge category, even when lexical 
markers are not present. However, due to the 
proven importance of lexical markers in deter-
mining certain meta-knowledge dimensions, our 
annotation scheme annotates such markers, 
whenever they are present. 
2 Annotation Scheme 
The annotation scheme we present here is a 
slightly modified version of our original meta-
knowledge annotation scheme (Nawaz et al, 
2010). The modified scheme consists of five 
meta-knowledge dimensions, each with a set of 
complete and mutually-exclusive categories, i.e., 
any given bio-event belongs to exactly one cate-
gory in each dimension. Our chosen set of anno-
tation dimensions has been motivated by the 
major information needs of biologists discussed 
earlier, i.e., the ability to distinguish between 
different intended interpretations of events. 
In order to minimise the annotation burden, 
the number of possible categories within each 
dimension has been kept as small as possible, 
whilst still respecting important distinctions in 
meta-knowledge that have been observed during 
our corpus study.     
The advantage of using a multi-dimensional 
scheme is that the interplay between different 
values of each dimension can reveal both subtle 
and substantial differences in the types of meta-
knowledge expressed in the surrounding text. 
Therefore, in most cases, the exact rhetori-
cal/pragmatic intent of an event can only be de-
termined by considering a combination of the 
values of different dimensions. This aspect of our 
scheme is further discussed in section 3. 
 
Figure 4 provides an overview of the annota-
tion scheme. The boxes with the light-coloured 
(grey) background correspond to information 
that is common to most bio-event annotation 
schemes, i.e., the participants in the event, to-
gether with an indication of the class or type of 
Figure 4. Bio-Event Annotation 
 
Figure 3. Example Sentence 
 
The DNA-binding properties of mutations at posi-
tions 849 and 668 may indicate that the catalytic 
role of these side chains is associated with their 
interaction with the DNA substrate. 
 
72
the event. The boxes with the darker (green) 
backgrounds correspond to our proposed meta-
knowledge annotation dimensions and their pos-
sible values. The remainder of this section pro-
vides brief details of each annotation dimension.  
2.1 Knowledge Type (KT) 
This dimension is responsible for capturing the 
general information content of the event. Whilst 
less detailed than some of the previously pro-
posed sentence-level schemes, its purpose is to 
form the basis of distinguishing between the 
most critical types of rhetorical/pragmatic intent, 
according to the needs of biologists. Each event 
is thus classified into one of the following four 
categories: 
Investigation: Enquiries or investigations, which 
have either already been conducted or are 
planned for the future, typically marked by lexi-
cal clues like examined, investigated and studied, 
etc.  
Observation: Direct observations, often repre-
sented by lexical clues like found, observed and 
report, etc.  Simple past tense sentences typically 
also describe observations. Such events represent 
experimental knowledge.  
Analysis: Inferences, interpretations, specula-
tions or other types of cognitive analysis, typi-
cally expressed by lexical clues like suggest, in-
dicate, therefore and conclude etc. Such events, 
if they are interpretations or reliable inferences 
based on experimental results, can also constitute 
another type of (indirect) experimental knowl-
edge. Weaker inferences or speculations, how-
ever, may be considered as hypotheses which 
need further proof through experiments.  
General: Scientific facts, processes, states or 
methodology. This is the default category for the 
knowledge type dimension. 
2.2 Certainty Level (CL) 
The value of this dimension is almost always 
indicated through the presence/absence of an ex-
plicit lexical marker. In scientific literature, it is 
normally only applicable to events whose KT 
corresponds either to Analysis or General. In the 
case of Analysis events, CL encodes confidence 
in the truth of the event, whilst for General 
events, there is a temporal aspect, to account for 
cases where a particular process is explicitly 
stated to occur most (but not all) of the time, us-
ing a marker such as normally, or only occasion-
ally, using a marker like sometimes.  Events cor-
responding to direct Observations are not open to 
judgements of certainty, nor are Investigation 
events, which refer to things which have not yet 
happened or have not been verified.  
Regarding the choice of values for the CL di-
mension, there is an ongoing discussion as to 
whether it is possible to partition the epistemic 
scale into discrete categories (Rubin, 2007). 
However, the use of a number of distinct catego-
ries is undoubtedly easier for annotation pur-
poses and has been proposed in a number of pre-
vious schemes. Although recent work has sug-
gested the use of  four or more categories (Shat-
kay et al, 2008; Thompson et al, 2008), our ini-
tial analysis of bio-event corpora has shown that 
only three levels of certainty seem readily distin-
guishable for bio-events. This is in line with 
Hoye (1997), whose analysis of general English 
showed that there are at least three articulated 
points on the epistemic scale.  
We have chosen to use numerical values for 
this dimension, in order to reduce potential anno-
tator confusions or biases that may be introduced 
through the use of labels corresponding to par-
ticular lexical markers of each category, such as 
probable or possible, and also to account for the 
fact that slightly different interpretations apply to 
the different levels, according to whether the 
event has a KT value of Analysis or General.  
L3: No expression of uncertainty or speculation 
(default category)  
L2: High confidence or slight speculation.  
L1: Low confidence or considerable speculation; 
typical lexical markers include may, might and 
perhaps.  
2.3 Source 
The source of experimental evidence provides 
important information for biologists. This is 
demonstrated by its annotation during the crea-
tion of the Gene Ontology (Ashburner et al, 
2000) and in the corpus created by Wilbur et al 
(2006). The Source dimension can also help in 
distinguishing new experimental knowledge 
from previously reported knowledge. Our 
scheme distinguishes two categories, namely: 
Other: The event is attributed to a previous 
study. In this case, explicit clues (citations or 
phrases like previous studies etc.) are normally 
present. 
Current: The event makes an assertion that can 
be (explicitly or implicitly) attributed to the cur-
rent study. This is the default category, and is 
assigned in the absence of explicit lexical or con-
textual clues. 
73
2.4 Polarity 
This dimension identifies negated events. Al-
though certain bio-event corpora are annotated 
with this information, it is still missing from oth-
ers. The indication of whether an event is ne-
gated is vital, as the interpretation of a negated 
event instance is completely opposite to the in-
terpretation of a non-negated (positive) instance 
of the same event.  
We define negation as the absence or non-
existence of an entity or a process. Negation is 
typically expressed by the adverbial not and the 
nominal no. However, other lexical devices like 
negative affixals (un- and in-, etc.), restrictive 
verbs (fail, lack, and unable, etc.), restrictive 
nouns (exception, etc.), certain adjectives (inde-
pendent, etc.), and certain adverbs (without, etc.) 
can also be used. 
2.5 Manner 
Events may be accompanied by a word or phrase 
which provides an indication of the rate, level, 
strength or intensity of the interaction. We refer 
to this as the Manner of the event. Information 
regarding manner is absent from the majority of 
existing bio-event corpora, but yet the presence 
of such words can be significant in the correct 
interpretation of the event. Our scheme distin-
guishes 3 categories of Manner, namely:  
High: Typically expressed by adverbs and adjec-
tives like strongly, rapidly and high, etc.  
Low: Typically expressed by adverbs and adjec-
tives like weakly, slightly and slow, etc.  
Neutral: Default category assigned to all events 
without an explicit indication of manner. 
3 Hyper-Dimensions 
Determining the pragmatic/rhetorical intent be-
hind an event is not completely possible using 
any one of our explicitly annotated dimensions. 
Although the Knowledge Type value forms the 
basis for this, it is not in itself sufficient. How-
ever, a defining feature of our annotation scheme 
is that additional information can be inferred by 
considering combinations of some of the explic-
itly annotated dimensions. We refer to this addi-
tional information as ?latent? or ?hyper? dimen-
sions of our scheme. We have identified two 
such hyper-dimensions. 
3.1 New Knowledge 
The isolation of events describing new knowl-
edge can be important in certain tasks undertaken 
by biologists, as explained earlier. Events with 
the Knowledge Type of Observation could corre-
spond to new knowledge, but only if they repre-
sent observations from the current study, rather 
than observations cited from elsewhere. In a 
similar way, an Analysis drawn from experimen-
tal results in the current study could be treated as 
new knowledge, but generally only if it repre-
sents a straightforward interpretation of results, 
rather than something more speculative.  
 Hence, we consider New Knowledge to be a 
hyper-dimension of our scheme. Its value (either 
Yes or No) is inferred by considering a combina-
tion of the value assignments for the KT, Source 
and CL dimensions.  
Table 1 shows the inference table that can be 
used to obtain the value for the New Knowledge 
hyper-dimension from the assigned values of the 
Source, KT and CL dimensions. The symbol ?X? 
indicates a ?don?t care condition?, meaning that 
this value does not have any impact on the result.  
 
Source 
(Annotated) 
KT 
(Annotated) 
CL 
(Annotated) 
New  
Knowledge 
(Inferred) 
Other X X No 
X X L2 No 
X X L1 No 
Current Observation L3 Yes 
Current Analysis L3 Yes 
X General X No 
X Investigation X No 
 
Table 1. Inference-Table for New Knowledge 
Hyper-Dimension 
 
3.2 Hypothesis 
A further hyper-dimension of our scheme is Hy-
pothesis. The binary value of this hyper-
dimension can be inferred by considering the 
values of KT and CL. Events with a KT value of 
Investigation can always be assumed to be a hy-
pothesis, However, if the KT value is Analysis, 
then only those events with a CL value of L1 or 
L2 (speculative inferences made on the basis of 
results) should be considered as hypothesis, to be 
matched with more definite experimental evi-
dence when available. A value of L3 in this in-
stance would normally be classed as new knowl-
edge, as explained in the previous section.   
Table 2 shows the inference table that can be 
used to get the value for the Hypothesis hyper-
dimension.  
 
74
KT 
(Annotated) 
CL 
(Annotated) 
Hypothesis 
(Inferred) 
General X No 
Observation X No 
Analysis L3 No 
Analysis L2 Yes 
Analysis L1 Yes 
Investigation X Yes 
 
Table 2. Inference-Table for Hypothesis 
Hyper-Dimension 
4 Evaluation 
The annotation scheme has been evaluated 
through a small annotation experiment. We ran-
domly choose 70 abstracts from the GENIA 
Pathway Corpus, which collectively contain over 
2600 annotated bio-events. Two of the authors 
independently annotated these bio-events using a 
set of annotation guidelines. These guidelines 
were developed following an analysis of the 
various bio-event corpora and the output of the 
initial case study (Nawaz et al, 2010). 
The highly favourable results of this experi-
ment further confirmed the feasibility and 
soundness of the annotation scheme. The re-
mainder of this section discusses the results in 
more detail. 
 
Dimension Cohen?s Kappa 
Knowledge Type 0.9017 
Certainty Level 0.9329 
Polarity 0.9059 
Manner 0.8944 
Source 0.9520 
Table 3. Inter-Annotator Agreement 
4.1 Inter-Annotator Agreement 
We have used the familiar measure of Cohen?s 
kappa (Cohen, 1960) for assessing the quality of 
annotation. Table 3 shows the kappa values for 
each annotated dimension. The highest value of 
kappa was achieved for the Source dimension, 
while the KT dimension yielded the lowest kappa 
value. Nevertheless, the kappa scores for all an-
notation dimensions were in the good region 
(Krippendorff, 1980).  
4.2 Category Distribution 
Knowledge Type:  The most prevalent category 
found in this dimension was Observation, with 
45% of all annotated events belonging to this 
category. Only a small fraction (4%) of these 
events was represented by an explicit lexical clue 
(mostly sensory verbs).  In most cases the tense, 
local context (position within the sentence) or 
global context (position within the document) 
were found to be important factors. 
The second most common category (37% of 
all annotated events) was General. We discov-
ered that most (64%) of the events belonging to 
this category were processes or states embedded 
in noun phrases (such as c-fos expression). More 
than a fifth of the General events (22%) ex-
pressed known scientific facts, whilst a smaller 
fraction (14%) expressed experimental/scientific 
methods (such as stimulation and incubation 
etc.). Explicit lexical clues were found only for 
facts, and even then in only 1% of cases. 
Analysis was the third most common category, 
comprising 16% of all annotated events. Of the 
events belonging to this category, 44% were de-
ductions (CL=L1), whilst the remaining 54% 
were hedged interpretations (CL=L2/L3). All 
Analysis events were marked with explicit lexical 
clues. 
The least common category was Investigation 
(1.5% of all annotated events). All Investigation 
events were marked with explicit lexical clues. 
Certainty Level: L3 was found to be the most 
prevalent category, corresponding to 93% of all 
events. The categories L2 and L1 occurred with 
frequencies of 4.3% and 2.5%, respectively. The 
relative scarcity of speculative sentences in sci-
entific literature is a well documented phenome-
non (Thompson et al, 2008; Vincze et al, 2008). 
Vincze et al (2008) found that less than 18% of 
sentences occurring in biomedical abstracts are 
speculative. Similarly, we found that around 20% 
of corpus events belong to speculative sentences. 
Since speculative sentences contain non-
speculative events as well, the frequency of 
speculative events is expected to be much less 
than the frequency of speculative sentences. In 
accordance with this hypothesis, we found that 
only 7% of corpus events were expressed with 
some degree of speculation. We also found that 
almost all speculated events had explicit lexical 
clues.  
Polarity:  Our event-centric view of negation 
showed just above 3% of the events to be ne-
gated. Similarly to speculation, the expected fre-
75
quency of negated events is lower than the fre-
quency of negated sentences. Another reason for 
finding fewer negated events is the fact that, in 
contrast to previous schemes, we draw a distinc-
tion between events that are negated and events 
expressed with Low manner. For example, cer-
tain words like limited and barely are often con-
sidered as negation clues. However, we consider 
them as clues for Low manner. In all cases, nega-
tion was expressed through explicit lexical clues. 
Manner: Whilst only a small fraction (4%) of 
events contains an indication of Manner, we 
found that where present, manner conveys vital 
information about the event. Our results also re-
vealed that indications of High manner are three 
times more frequent than the indications of Low 
manner. We also noted that both High and Low 
manners were always indicated through the use 
of explicit clues. 
Source: Most (99%) of the events were found to 
be of the Current category. This is to be ex-
pected, as authors tend to focus on current work 
in within abstracts. It is envisaged, however, that 
this dimension will be more useful for analyzing 
full papers. 
Hyper-dimensions: Using the inference tables 
shown in section 3, we calculated that almost 
57% of the events represent New Knowledge, and 
just above 8% represent Hypotheses.  
5 Conclusion and Future Work 
We have evaluated a slightly modified version of 
our meta-knowledge annotation scheme for bio-
events, first presented in Nawaz et al (2010). 
The scheme captures key information regarding 
the correct interpretation of bio-events, which is 
not currently annotated in existing bio-event cor-
pora, but which we have shown to be critical in a 
number of text mining tasks undertaken by bi-
ologists. The evaluation results have shown high 
inter-annotator agreement and a sufficient num-
ber of annotations along each category in every 
dimension. These results have served to confirm 
the feasibility and soundness of the annotation 
scheme, and provide promising prospects for its 
application to existing and new bio-event cor-
pora. 
We are currently working on a large scale an-
notation effort, involving multiple independent 
annotators. Although our main objective is to 
enrich the entire GENIA event corpus with meta-
knowledge information, we also plan to create a 
small corpus of full papers enriched with bio-
event and meta-knowledge annotations. 
Acknowledgments 
The work described in this paper has been 
funded by the Biotechnology and Biological Sci-
ences Research Council through grant numbers 
BBS/B/13640, BB/F006039/1 (ONDEX) 
References  
M. Ashburner, C. A. Ball, J. A. Blake, D. Botstein, H. 
Butler, J. M. Cherry, A. P. Davis, K. Dolinski, S. 
S. Dwight, J. T. Eppig, M. A. Harris, D. P. Hill, L. 
Issel-Tarver, A. Kasarskis, S. Lewis, J. C. Matese, 
J. E. Richardson, M. Ringwald, G. M. Rubin and 
G. Sherlock.  2000. Gene ontology: tool for the 
unification of biology.  Nature Genetics 25:25-29. 
J. Cohen. 1960. A coefficient of agreement for nomi-
nal scales. Educational and Psychological Meas-
urement 20: 37?46. 
A. de Waard, B. Shum, A. Carusi, J. Park, M. Sam-
wald and ?. S?ndor. 2009. Hypotheses, Evidence 
and Relationships: The HypER Approach for Rep-
resenting Scientific Knowledge Claims. In Pro-
ceedings of the Workshop on Semantic Web Appli-
cations in Scientific Discourse. Available at:  
http://oro.open.ac.uk/18563/ 
L. Hoye. 1997. Adverbs and Modality in English. 
London & New York: Longman 
K. Hyland. 1996. Talking to the Academy: Forms of 
Hedging in Science Research Articles. Written 
Communication 13(2):251-281. 
K. Hyland. 2005. Metadiscourse: Exploring Interac-
tion in Writing. London: Continuum 
J. Kim, T. Ohta and J. Tsujii. 2008. Corpus annotation 
for mining biomedical events from literature. BMC 
Bioinformatics 9:10 
K. Krippendorff. 1980. Content Analysis: An Intro-
duction to Its Methodology. Beverly Hills: Sage 
Publications 
H. Langer, H. Lungen and P. S. Bayerl. 2004. Text 
type structure and logical document structure. In 
Proceedings of the ACL Workshop on Discourse 
Annotation, pages 49-56 
M. Light, X. T. Qui and P. Srinivasan. 2004. The lan-
guage of bioscience: Facts, speculations, and 
statements in between. In Proceedings of the Bio-
Link 2004 Workshop on Linking Biological Litera-
ture, Ontologies and Databases: Tools for Users, 
pages 17-24. 
F. Lisacek, C. Chichester, A. Kaplan and A. Sandor. 
2005. Discovering Paradigm Shift Patterns in Bio-
medical Abstracts: Application to Neurodegenera-
tive Diseases. In Proceedings of SMBM 2005, 
pages 212-217 
76
L. McKnight and P. Srinivasan. 2003. Categorization 
of sentence types in medical abstracts. In Proceed-
ings of the 2003 Annual Symposium of AMIA, 
pages 440-444. 
B. Medlock and T. Briscoe. 2007. Weakly supervised 
learning for hedge classification in scientific litera-
ture. In Proceedings of ACL 2007, pages 992- 999. 
Y. Miyao, T. Ohta, K. Masuda, Y. Tsuruoka, K. Yo-
shida, T. Ninomiya and J. Tsujii. 2006. Semantic 
Retrieval for the Accurate Identification of Rela-
tional Concepts in Massive Textbases. In Proceed-
ings of COLING-ACL 2006, pages 1017-1024. 
Y. Mizuta and N. Collier. 2004. Zone identification in 
biology articles as a basis for information extrac-
tion. In Proceedings of the joint NLPBA/BioNLP 
Workshop on Natural Language for Biomedical 
Applications, pages 119-125. 
R. Morante and W. Daelemans. 2009. A metalearning 
approach to processing the scope of negation. In 
Proceedings of CoNLL 2009, pages 21-29. 
R. Nawaz, P. Thompson, J. McNaught and S. 
Ananiadou. 2010. Meta-Knowledge Annotation of 
Bio-Events. In Proceedings of LREC 2010, pages 
2498-2507. 
K. Oda, J. Kim, T. Ohta, D. Okanohara, T. Matsuzaki,  
Y. Tateisi and J. Tsujii. 2008. New challenges for 
text mining: mapping between text and manually 
curated pathways. BMC Bioinformatics 9(Suppl 3): 
S5. 
S. Pyysalo, F. Ginter, J. Heimonen, J. Bjorne, J. 
Boberg, J. Jarvinen and T. Salakoski. 2007. BioIn-
fer: a corpus for information extraction in the bio-
medical domain. BMC Bioinformatics 8:50. 
V. Rizomilioti. 2006. "Exploring Epistemic Modality 
in Academic Discourse Using Corpora." Informa-
tion Technology in Languages for Specific Pur-
poses 7, pages 53-71 
V. L. Rubin. 2007. Stating with certainty or stating 
with doubt: Intercoder reliability results for manual 
annotation of epistemically modalized statements. 
In Proceedings of NAACL-HLT 2007, Companion 
Volume,  pages 141-144. 
P. Ruch, C. Boyer, C. Chichester, I. Tbahriti, A. 
Geissb?hler, P. Fabry, J. Gobeill, V. Pillet, D. 
Rebholz-Schuhmann and C. Lovis. 2007. Using 
argumentation to extract key sentences from bio-
medical abstracts. International Journal of Medical 
Informatics 76(2-3):195-200. 
O. Sanchez-Graillet and M. Poesio. 2007. Negation of 
protein-protein interactions: analysis and extrac-
tion. Bioinformatics 23(13):i424-i432 
?. S?ndor. 2007. Modeling metadiscourse conveying 
the author?s rhetorical strategy in biomedical re-
search abstracts. Revue Fran?aise de Linguistique 
Appliqu?e 200(2):97-109. 
H. Shatkay, F. Pan, A. Rzhetsky and W. J. Wilbur.  
2008. Multi-dimensional classification of biomedi-
cal text: toward automated, practical provision of 
high-utility text to diverse users. Bioinformatics 
24(18): 2086-2093. 
S. Teufel, J. Carletta and M. Moens. 1999. An annota-
tion scheme for discourse-level argumentation in 
research articles. In Proceedings of EACL 1999, 
pages  110-117. 
S. Teufel, A. Siddharthan and C. Batchelor. 2009. 
Towards discipline-independent argumentative 
zoning: Evidence from chemistry and computa-
tional linguistics. In Proceedings of EMNLP-09, 
pages 1493-1502 
P. Thompson, S. Iqbal, J. McNaught and S. 
Ananiadou. 2009. Construction of an annotated 
corpus to support biomedical information extrac-
tion. BMC Bioinformatics 10: 349. 
P. Thompson, G. Venturi, J. McNaught, S. Monte-
magni and S. Ananiadou. 2008. Categorising Mo-
dality in Biomedical Texts. In Proceedings of the 
LREC 2008 Workshop on Building and Evaluating 
Resources for Biomedical Text Mining, pages 27-
34. 
V. Vincze, G. Szarvas, R. Farkas, G. Mora and J. 
Csirik. 2008. The BioScope corpus: biomedical 
texts annotated for uncertainty, negation and their 
scopes. BMC Bioinformatics 9(Suppl 11): S9. 
W. J. Wilbur, A. Rzhetsky and H. Shatkay. 2006. 
New directions in biomedical text annotations: 
definitions, guidelines and corpus construction. 
BMC Bioinformatics 7: 356. 
 
77
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 37?46,
Jeju, Republic of Korea, 12 July 2012. c?2012 Association for Computational Linguistics
A Three-Way Perspective on Scientific Discourse Annotation for       Knowledge Extraction   Maria Liakata Aberystwyth University, UK / EMBL-EBI, UK liakata@ebi.ac.uk Paul Thompson University of Manchester, UK paul.thompson@manchester.ac.uk Anita de Waard Elsevier Labs, USA / UiL-OTS, Universiteit Utrecht, NL a.dewaard@elsevier.com    Raheel Nawaz University of Manchester, UK raheel.nawaz@cs.man.ac.uk Henk Pander Maat UiL-OTS, Universiteit Utrecht, NL h.l.w.pandermaat@uu.nl Sophia Ananiadou University of Manchester, UK sophia.ananiadou@manchester.ac.uk   Abstract 
This paper presents a three-way perspective on the annotation of discourse in scientific literature. We use three different schemes, each of which focusses on different aspects of discourse in scientific articles, to annotate a corpus of three full-text papers, and compare the results. One scheme seeks to identify the core components of scientific investigations at the sentence level, a second annotates meta-knowledge pertaining to bio-events and a third considers how epistemic knowledge is conveyed at the clause level. We present our analysis of the comparison, and a discussion of the contributions of each scheme.  1 Introduction The literature boom in the life sciences over the past few years has sparked increasing interest into text mining tools, which facilitate the automatic extraction of useful knowledge from text (Ananiadou et al, 2006; Ananiadou  &  McNaught, 2006; Zweigenbaum et al, 2007; Cohen  &  Hunter, 2008). Most of these tools have focussed on entity recognition and relation extraction and with few exceptions, e.g., (Hyland, 1996; Light et al, 2004; S?ndor, 2007; Vincze et al, 2008), do not take into account the discourse context of the knowledge extracted. However, failure to take this context into account results in the loss of information vital for the correct interpretation of extracted knowledge, e.g. the scope of the relations, or the level of certainty with which they are expressed. A particular piece of 
knowledge may represent, e.g., an accepted fact, hypothesis, results of an experiment, analysis based on experimental results, factual or speculative statements etc. Furthermore, this knowledge may represent the author's current work, or work reported elsewhere. The ability to recognise different discourse elements automatically provides crucial information for the correct interpretation of extracted knowledge, allowing scientific claims to be linked to experimental evidence, or newly reported experimental knowledge to be isolated. The importance of categorising such knowledge becomes more pronounced as analysis moves from abstracts to full papers, where the content is richer and linguistic constructions are more complex (Cohen et al, 2010). Analysis of full papers is extremely important, since less than 8% of scientific claims occur in abstracts (Blake, 2010). Various different schemes for annotating discourse elements in scientific texts have been proposed. The schemes vary along several axes, including perspective, motivation, complexity and the granularity of the units of text to which the scheme is applied. Faced with such variety, it is important to be able to select the best scheme(s) for the purpose at hand. Answers to questions such as the following can help in the selection process: 1. What are the relative merits of the different schemes? 2. What are the similarities and differences between schemes? 3. Can annotation according to multiple schemes provide enhanced information?  
37
Category Description Hypothesis An unconfirmed statement which is a stepping stone of the investigation Motivation The reasons behind an investigation Background Generally accepted background knowledge and previous work Goal A target state of the investigation where intended discoveries are made Object-New An entity which is a product or main theme of the investigation Object-New-Advantage Advantage of an object Object-New-Disadvantage Disadvantage of an object Method-New Means by which authors seek to achieve a goal of the investigation Method-New-Advantage Advantage of a Method Method-New-Disadvantage Disadvantage of a Method Method-Old A method mentioned pertaining to previous work Method-Old-Advantage Advantage of a Method Method-Old-Disadvantage Disadvantage of a Method Experiment An experimental method Model A statement about a theoretical model or framework Observation The data/phenomena recorded in an investigation Result Factual statements about the outputs, interpretation of observations Conclusion Statements inferred from observations & results  Table 1. The CoreSC Annotation scheme: layers 1 & 2 	 ?4. Is there any advantage in merging annotation schemes or is it better to allow complementary and different dimensions of scientific discourse annotation?	 ?As a starting point to addressing such questions, we provide a comparison of three different schemes for the annotation of discourse elements within scientific papers. Each scheme has a different perspective and motivation:, one is content-driven, seeking to identify the main components of a scientific investigation, another is driven by the need to describe events of biomedical relevance and the third focusses on how epistemic knowledge is conveyed in discourse.  These different viewpoints mean that the schemes vary in both the type and complexity of the discourse elements identified, as well as the types of units to which the annotation is applied, i.e. complete sentences, segments of sentences, or specific relations/events occurring within these sentences. To facilitate the comparison, we have annotated three full papers according to each of the schemes. The analysis resulting from this three-way annotation considers mappings between schemes, their relative merits, and how the information annotated by the different schemes can 
complement each other to provide enriched details about knowledge extracted from the texts. In the following sections, we firstly provide a description of the three schemes, and then explain how they have been used in our corpus annotation. Finally we discuss the results from the comparison, and the features of each scheme. 2 Sentence annotation: CoreSC scheme  The reasoning behind this scheme is that a paper is the human-readable representation of a scientific investigation. Therefore, the goal of the annotation is to retrieve the content model of scientific investigations as reflected within scientific discourse. The hypothesis is that there is a set of core scientific concepts (CoreSC), which constitute the key components of a scientific investigation. CoreSCs consist of 11 concepts originating from the CISP (Core Information about Scientific Papers) meta-data (Soldatova  &  Liakata, 2007), which are a subset of classes from the EXPO ontology for the description of scientific experiments (Soldatova  &  King, 2006). The CoreSCs are: Motivation, Goal, Object, Background, Hypothesis, Method, Model, Experiment, Observation, Result and Conclusion. 
38
Figure 1.  Bio-Event Representation 
The CoreSC scheme (Liakata et al, 2010; Liakata et al, 2012) implements the above-mentioned concepts as a 3-layered sentence-based annotation scheme. This means that each sentence in a document is assigned one of the 11 CoreSC concepts. The scheme also considers a layer designated to properties of the concepts (e.g. New Method vs Old Method) as well as identifiers which link instances of the same concept across sentences. A short definition of CoreSC categories and their properties can be found in Table 1.  The CoreSC scheme is accompanied by 47-page annotation guidelines, and has been used by 16 domain experts to annotate a corpus of 265 full papers from physical chemistry & biochemistry (Liakata  &  Soldatova, 2009; Liakata et al, 2010). This corpus consists of 40,000 sentences, containing over 1 million words and was developed in three phases (for details see Liakata et al (2012)). Inter-annotator agreement between experts was measured in terms of Cohen?s kappa (Cohen, 1960) on 41 papers and ranged between 0.5 and 0.7. Machine learning classifiers have been trained on the CoreSC corpus, achieving > 51% accuracy across the eleven categories. The most accurately predicted category is Experiment, the category describing experimental methods (Liakata et al, 2012). Classifiers trained on 1000 Biology abstracts annotated with CoreSC have obtained an accuracy of over 80% (Guo et al, 2010). Models trained on the CoreSC corpus papers have been used to create automatic summaries of the papers, which have been evaluated in a question answering task (Liakata et al, 2012). Lastly, the CoreSC scheme was used to annotate 50 papers from Pubmed Central pertaining to Cancer Risk Assessment. A web tool (SAPIENTA 1 ) allows users to annotate their full papers with Core Scientific concepts, and can be combined with manual annotation. A UIMA framework 2 implementation of this code for large-scale annotation of CoreSC concepts is in progress. 3 Event annotation: Meta-knowledge for bio-events The motivation for this annotation scheme is to allow the training of more sophisticated event-                                                1 http://www.sapientaproject.com/software 2 http://uima.apache.org/ 
based information extraction systems. In contrast to the sentence-based scheme described in section 2, this scheme is applied at the level of events (Ananiadou et al, 2010), of which there may be several within a single sentence. 3.1 Bio-Events Events are template-like, structured representations of pieces of knowledge contained within sentences. Normally, events are ?anchored? to a trigger (typically a verb or noun) around which the knowledge expressed is organised. Each event has one of more participants, which describe different aspects of the event. Participants can correspond to entities or other events, and are often labelled with semantic roles, e.g., CAUSE, THEME, LOCATION, etc. The work described here focusses specifically on bio-events, which are complex structured relations representing fine-grained relations between bio-entities and their modifiers. Figure 1 provides some examples of bio-events. Event extraction systems (Bj?rne et al, 2009; Miwa et al, 2010; Miwa et al, 2012; Quirk et al, 2011) are typically trained on text corpora, in which events and their participants have been manually annotated by domain experts. Research into bio-event extraction has been boosted by the two recent shared tasks at BioNLP 2009/2011 (Kim et al, 2011; Pyysalo et al, In Press). Several gold standard event annotated corpora exist; examples include the GENIA Event Corpus (Kim et al, 2008), GREC (Thompson et al, 2009) and BioInfer (Pyysalo et al, 2007), in addition to the corpora produced for the shared tasks. 
3.2 Meta-knowledge Annotation Until recently, the only attempts to recognise information relating to the correct interpretation of events were restricted to sparse details regarding negation and speculation (Kim et al, 2011). 
39
In order to address this problem, a multi-dimensional annotation scheme especially tailored to bio-events was developed (Nawaz et al, 2010; Thompson et al, 2011). The scheme identifies and categorises several different types of contextual details regarding events (termed meta-knowledge), including discourse information. Different types of meta-knowledge are encoded through five distinct dimensions (Figure 2). The advantage of using multiple dimensions is that the interplay between the assigned values in each dimension can reveal both subtle and substantial differences in the types of meta-knowledge expressed. In the majority of cases, meta-knowledge is expressed through the presence of particular ?clue? words or phrases, although other features can also come into play, such as the tense of the event trigger, or the relative position within the text. 
Figure 2: Meta-knowledge annotation 	 ?The annotation task consists of assigning an appropriate value from a fixed set for each dimension, as well as marking the textual evidence for this assignment. The five meta-knowledge dimensions and their values are as follows: Knowledge Type (KT): Captures the general information content of the event. Each event is classified as one of: Investigation (enquiries and examinations, etc.), Observation (direct experimental observations), Analysis (inferences, interpretations and conjectures, etc.), Fact (known facts), Method (methods) or Other (general events that provide incomplete information or do not fit into any other category).  Certainty Level (CL): Encodes the confidence or certainty level ascribed to the event in the given text. The epistemic scale is partitioned into three distinct levels: L3 (no expression of uncertainty), 
L2 (high confidence or slight speculation) and L1 (low confidence or considerable speculation). Polarity: Identifies negated events. Negation is defined as the absence or non-existence of an entity or a process. Manner: Captures information about the rate, level, strength or intensity of the event, using three values: High, Low, or Neutral (no indication of rate/intensity). Source:  Encodes the source of the knowledge being expressed by the event as Current (the current study) or Other (any other source).      Of these five dimensions, only KT, CL and Source were considered during the comparison with the other two schemes, since they are directly related to discourse analysis.  The GENIA event corpus, consisting of 1000 abstracts with 36,115 events (Kim et al, 2008) has been annotated with meta-knowledge by 2 annotators, supported by 64-page annotation guidelines 3  (Thompson et al, 2011). Inter-annotator agreement rates ranged between 0.84?0.93 (Cohen?s Kappa).  Research has been carried out into the automatic assignment of Manner values to events (Nawaz et al, In Press).  In addition, the EventMine-MK service (Miwa et al, In Press), based on EventMine (Miwa et al, 2010) facilitates automatic extraction of biomedical events with meta-knowledge assigned. The performance of EventMine-MK in assigning different meta-knowledge values to events ranges between 57% and 87% (macro-averaged F-Score) on the BioNLP?09 Shared Task corpus (Kim et al 2011). EventMine-MK is available as a component of the U-Compare interoperable text mining system4 (Kano et al, 2011). 4 Clause annotation: Segments for epistemic knowledge The third scheme we consider uses a Discourse Segment Type classification of segments at, roughly, a clause level, i.e., each segment has a main verb. This means that the level of granularity of argumentational elements in this scheme lies between the other two schemes, i.e. it is usually more granular than CoreSC, but sometimes less granular than the event-based scheme.                                                  3 http://www.nactem.ac.uk/meta-knowledge/ 4 http://www.nactem.ac.uk/ucompare/ 
40
 Table 2:  Discourse Segment Types 	 ?The segment annotation scheme identifies a taxonomy of discourse segment types that seem to be exclusive and useful (de Waard & Pander Maat, 2009). Three classes of segment types are defined:  ? Basic segment types: segments referring directly to the topic of study ? see Table 2.  ? ?Other?-segment types: segments referring to conceptual or experimental work in other research papers than the current one ? Regulatory segment types: ?regulatory? clauses that control and introduce other segments.  A list of segment types is presented in Table 2; further details, including a list of all segment types and correlations with verb tense can be found in de Waard  &  Pander Maat (2009). The focus of this work is to identify linguistic features that characterise these discourse segment types, according to three aspects: ? Verb tense, aspect, mood and voice ? Semantic verb class ? Epistemic modality markers So far, 6 full-text papers (comprising about 2300 segments) have been manually annotated with segment types and correlated with the above features. A first automated validation was promising (de Waard, Buitelaar and Eigener, 2009). The need for parsing at a clause level is especially prominent in biological text, since specific semantic roles are played by particular clause types. We give four examples of typical 
clause constructions that play a specific rhetorical role: firstly, reporting clauses are often sentence-initial ?that? matrix clauses (1a): 1. a.  This suggests that  1.b. miR-372 and miR-373 caused the observed  selective growth advantage. Secondly, descriptions confirming certain accepted characteristics of biological entities are often given as nonrestrictive relative clauses (2b):  2.a. We also generated BJ/ET cells expressing the  RASV12-ERTAM chimera gene,  2. b. which is only active when tamoxifen is added  Thirdly, a subordinate gerund clause is often used to describe a method (3a), with a main (finite) clause describing a result (3b) and fourthly, experimental goals are often given as a (mostly sentence-initial) clause with a to-infinitive (4a) often preceding a past-tense methods clause (4b). 3. a. Using fluorescence microscopy and luciferase assays, b. we observed potent and specific miRNA activity expressed from each miR-Vec (Figure S2). 4. a. To identify miRNAs that can interfere with this process  4. b. we transduced BJ/ET fibroblasts with miR-Lib  However, the lack of simple robust clause parsers has prevented the automated identification of semantic roles at the clause level. Therefore, this scheme has so far only been manually 
Segment Description Examples  Fact knowledge accepted to be true, a known fact. mature miR-373 is a homolog of miR-372,  Hypothesis  a proposed idea, not supported by evidence This could for instance be a result of high mdm2 levels  Problem unresolved, contradictory, or unclear issue However, further investigation is required to demonstrate the exact mechanism of LATS2 action Goal research goal To identify novel functions of miRNAs, Method  experimental method Using fluorescence microscopy and luciferase assays,  Result a restatement of the outcome of an experiment all constructs yielded high expression levels of mature miRNAs   Implication  an interpretation of the results, in light of data our procedure is sensitive enough to detect mild growth differences   Other-Hypothesis an idea proposed by others [It is generally believed that] transcription factors are the final common pathway driving differentiation] Regulatory-Hypothesis a matrix clause introducing a hypothesis It is generally believed that [transcription factors are the final common pathway driving differentiation] 
41
implemented. Despite being less widely implemented than the other two schemes, we believe that the segment scheme offers some useful pointers for linguistic features that can identify particular rhetorical classes in the text, and secondly, offers an interesting perspective on the fact that in biological text, several rhetorical moves are made within a single sentence.  5 Data and methods Three papers already annotated according to the GENIA event annotation scheme (Kim et al, 2008), were further annotated according to the three annotation schemes described above. We obtained all corresponding CoreSCs, events and segments per sentence. Each sentence has a single CoreSC annotation and one or more segment annotations (depending on the number of clauses). Event annotations in a sentence may range from zero to multiple, according to whether any relevant biomedical events are described in the sentence.  Events within a sentence are mapped to segments by identifying which segment contains the trigger for a particular event. The three meta-knowledge dimensions for events considered in this comparison, i.e., KT, CL and Source, result in 16 different combinations of values encountered in the three papers. The numbers for CoreSC and Segment labels encountered were 12 and 22, respectively. Confusion matrices were obtained for each paper and for each pair of annotation schemes. Note that, as bio-events are largely unconcerned with describing methodology, the Methods sections of these papers do not contain event annotation or meta-knowledge annotation. The pairwise confusion matrices from each paper were combined, resulting in three matrices (Tables 3, 4 and 5), which describe the associations between the annotation schemes in the three papers examined. We have highlighted the highest frequencies per row and where appropriate also the highest values per column. The use of two different colours aims to facilitate readability. 6 Results and Discussion We present the results from analysing the pairwise confusion matrices for the three schemes and discuss the merits of each scheme. 
6.1 Event Meta-knowledge v. CoreSC In Tables 3 (and 5), the meta-knowledge categories combine KT, CL and Source ((O)ther) values. Table 3 shows some straightforward and expected mappings, e.g.,Method (Met,L3) events are almost always found within CoreSC Experiment or Method sentences, whilst Investigation events (Inv,L3) occur most frequently within CoreSC Goal or Motivation sentences.  For other categories, information from the two schemes can complement each other in different ways. For example, KT and Source information about events can help to distinguish different types of information within CoreSC Background sentences (top left corner of Table 3). Such information mainly corresponds to facts, observations from previous studies, or analyses of information. Conversely, information from the CoreSC scheme can help to further classify the interpretation of events. For example, events with an analytical interpretation (Ana,L1,L2,L3) may occur as background information to a study (Bac), as hypotheses (Hyp),  as part of observations (Obs), when reporting the results of the current study (Res) or when making concluding remarks about the study (Con). CoreSCs can also help to further refine events relating to outcomes (Obs,L3) according to whether they pertain to (Obs)ervations, (Res)ults or (Con)clusions. CoreSC Conclusion, Result and Observation sentences contain mainly Observation events concerned with the current study. However, such sentences often also include an analytical part, with varying levels of certainty, which event information can help to isolate. The CL annotated for events is also useful in helping to determine the confidence with which information is stated in CoreSC Conclusion and Hypothesis sentences.  Due to the nature of bio-event annotation, only a small number of events correspond to methods. Thus, CoreSC provides a more detailed characterisation of method-related sentences, i.e., Experiment, Method_New, Model and Object. 6.2 Discourse Segments v. CoreSC In most cases, there seems to be natural mapping between the two schemes (See Table 4). CoreSC Observation maps to Result, CoreSC Method and Experiment map to Method, CoreSC Hypothesis maps to Hypothesis, CoreSC Goal maps to Goal, 
42
CoreSC Conclusion maps to Implication and Hypothesis, CoreSC Result maps to Implication and Result, and Problem is equivalent to CoreSC Motivation. The bulk of CoreSC Background maps to Fact and Other-Implication, but the ?Other? Segment categories provide a substantial refinement of the CoreSC Background category.   
 Table 3. Event Meta-knowledge vs CoreSC    On the other hand, CoreSC refines Method, Result and Implication segments. CoreSC Result may include both Fact and Method clauses, which can be captured by the Segment scheme, since annotation is performed at the clause level. CoreSC Conclusion maps to both Implication and Hypothesis segments, suggesting that there may be differences in the certainty levels of these conclusions. This is supported by preliminary classification experiments (paper in progress).  	 ?6.3 Discourse Segments v. Event Meta-Knowledge	 ? Some straightforward mappings exist between segment and event meta-knowledge categories (Table 5). For example, Investigation events (Inv, L3) are generally found within Goal and Problem segments; Method events (Met,L3) are normally found within Method segments, Observation events (Obs,L3) are found mainly within Result, Fact and Implication segments and (Ana,L1,L2) events correspond mainly to Hypotheses and Implications. Whilst these are similar findings to the comparison between event meta-knowledge and CoreSCs, the variance of the distribution is often smaller when mapping from Events to Segments. This is to be expected ? the information encoded by many events has the scope of roughly a clause, which corresponds closely to the scope of 
discourse segments. This could permit cleaner one-to-one mappings between categories. 
 Table 4: Segments vs CoreSC 	 ?  Hypothesis and Implication segments mainly contain (Ana)lysis events. The differing certainty levels of events can help to refine information about the statements made within these segments. Likewise, these segment types could help to refine the nature of the analysis described by the event.   Similarly to the CoreSC scheme, the results suggest that Result segments could be refined by the meta-knowledge scheme to distinguish between results emerging from direct experimental observations, and those obtained through analysis of experimental observations. Another interesting result is that Fact segments can contain Fact, (Ana)lysis or (Obs)ervation events. This may suggest that Fact segments are actually a rather general category, containing a range of different information. Few events occur within the Regulatory segments, as these mainly introduce content-bearing segments.  The majority of Method segments and a significant number of the Result segments do not correspond to events, as none of the methods sections have been annotated with event information, for reasons explained previously.  
	 ?Table 5: Segments vs Event Meta-Knowledge 
Sheet1
Page 1
Bac Con Exp Goa Hyp Met_New Met_Old Mod Mot Obj_New Obs Res0 42 24 49 7 7 25 1 13 6 7 47 54Obs,L3,O 166 0 0 0 0 0 3 0 12 0 0 2Ana,L3,O 33 1 0 0 0 0 0 1 0 0 0 0Ana,L2,O 3 0 0 0 0 0 0 0 0 0 0 0Fact,L3,O 7 0 0 0 0 0 0 0 0 0 0 0Fact,L3 24 1 0 1 0 0 0 0 5 3 0 2Oth,L3 125 30 0 8 16 5 3 2 8 3 9 42Ana,L1 2 10 0 0 6 0 0 0 1 0 0 6Ana,L2 30 15 0 1 14 0 0 2 1 0 8 33Ana,L3 11 11 0 0 2 1 2 0 3 0 14 28Met,L3 4 1 15 1 0 5 0 0 0 0 2 6Inv,L2 0 0 0 0 0 0 0 0 0 0 1 1Inv,L3 5 3 1 6 2 4 3 0 8 0 1 1Inv,L3,O 0 0 0 0 2 0 1 0 0 0 0 0Obs,L1 1 0 0 0 0 0 0 0 0 0 0 0Obs,L2 1 0 0 0 0 0 0 0 0 0 1 0Obs,L3 31 34 3 1 10 3 0 2 7 1 59 87
Sheet1
Page 1
Bac Con Exp Goa Hyp Met_New Met_Old Mod Mot Obj_New Obs ResFact 118 3 0 3 7 0 0 1 15 7 5 34OtherFact 70 4 0 0 0 0 0 3 1 0 0 0OtherGoal 2 1 0 0 0 0 0 0 0 0 0 0OtherHypothesis 14 0 0 0 0 0 0 0 0 0 0 0OtherImplication 124 1 0 0 3 0 0 1 5 0 0 1OtherMethod 5 0 0 0 0 0 3 0 0 0 0 2OtherProblem 1 0 0 0 0 0 0 0 0 0 0 0OtherResult 64 1 0 0 0 0 6 0 0 3 0 9RegFact 1 3 0 0 0 0 0 0 0 0 0 2Implication 13 58 0 0 2 0 0 3 1 0 3 80RegImplication 5 6 0 1 0 0 0 0 0 0 1 10Method 6 2 54 2 2 32 0 6 1 0 8 13Goal 2 0 5 12 6 9 2 2 4 0 0 5RegGoal 0 1 0 0 0 0 0 0 0 0 0 0Hypothesis 24 31 0 5 34 1 0 5 0 0 0 12RegHypothesis 6 4 0 0 2 0 0 1 0 0 0 2Problem 7 6 0 0 0 0 2 0 11 0 0 2RegProblem 0 3 0 0 0 0 0 0 0 0 0 0Result 13 6 1 1 2 0 0 2 8 0 112 75RegResult 1 0 0 0 0 0 0 0 0 1 1 2Intertextual 4 0 7 0 1 0 0 0 0 0 0 3Intratextual 2 0 1 0 0 0 0 2 0 0 8 4
Sheet1
Page 1
0 Ana Ana Ana Ana Ana Fact Fact Met Oth Inv Inv Inv ObsObsObsObsL1 L2 L2,OL3 L3,OL3 L3,O L3 L3 L2 L3 L3,OL1 L2 L3 L3,OHypothesis 8 18 26 1 0 0 0 0 1 39 0 4 1 0 0 14 0Implication 22 2 30 0 34 2 2 0 0 38 2 1 0 0 0 27 0OtherHypothesis 0 0 3 1 0 0 0 0 0 9 0 1 0 0 0 0 0OtherImplication 8 1 6 1 4 28 0 3 3 27 0 2 0 1 0 5 46RegImplication 11 0 2 0 0 1 0 0 0 5 0 1 0 0 0 3 0RegHypothesis 1 0 0 0 0 0 0 0 0 6 0 1 0 0 0 7 0Fact 15 0 18 0 6 0 28 0 0 55 0 1 0 0 1 44 25RegFact 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 5 0OtherGoal 1 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0OtherProblem 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0Method 80 0 1 0 0 0 0 0 23 9 0 2 0 0 0 8 3OtherMethod 7 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0Goal 13 0 0 0 0 0 1 0 0 18 0 11 1 0 0 3 0RegGoal 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0Problem 9 4 0 0 2 0 0 0 0 5 0 8 0 0 0 0 0RegProblem 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0Result 51 0 14 0 20 0 0 0 6 18 0 0 0 0 1 103 7OtherResult 11 0 1 0 0 1 0 1 0 10 0 0 0 0 0 12 47OtherFact 4 0 1 0 0 2 5 3 0 7 0 0 0 0 0 2 54RegResult 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0Intertextual 13 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0Intratextual 17 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0280 4 35 0 28 3 34 4 29 127 0 24 2 0 2 178 136
43
7 Related Work A number of schemes for annotating scientific discourse elements at the sentence level have been proposed. Certain schemes have been aimed at abstracts, e.g., (McKnight  &  Srinivasan, 2003; Ruch et al, 2007; Hirohata et al, 2008; Bj?rne et al, 2009). The work of Hirohata et al (2009) has been integrated with the MEDIE service5 (Miyao et al, 2006), allowing the user to query facts using conclusions, results, etc. For full papers, the most notable work has focussed on argumentative zoning (AZ) (Teufel et al, 1999; Teufel  &  Moens, 2002; Teufel et al, 2009; Teufel, 2010). An important aspect of AZ involves capturing the attribution of knowledge claims and citation function, and the scheme has been tested on information extraction and summarisation tasks with Computational Linguistics papers. AZ was modified for the annotation of biology papers by Mizuta et al (2005) in order to facilitate information extraction, and more recently Teufel et al (2009) extended the AZ scheme to better accommodate the life sciences and chemistry in particular, producing AZ-II. Scientific discourse annotation has also targeted the retrieval of speculative text to help improve curation. For a recent overview see de Waard and Pander Maat (2012).  Modality and negation in text have also been the focus of recent workshops (Farkas et al(2010), Morante & Sporleder (2012)). Finally, Shatkay et al(2008) define a multi-dimensional scheme, which combines several of the above-mentioned aspects.      Recent work has compared schemes to discover mappings and relative merits. Liakata et al (2010) compared AZ-II and CoreSC on 36 papers annotated with both schemes and found that CoreSC provides finer granularity in distinguishing content categories (e.g. methods, goals and outcomes) while the strength of AZ-II lies in detecting the attribution of knowledge claims and identifying the different functions of background information. Guo et al (2010) compared three schemes for the identification of discourse structure in scientific abstracts from cancer research assessment articles. The work showed a subsumption relation between the scheme of Hirohata et al (2008), a cut-down version of the                                                 5 http://www.nactem.ac.uk/medie/ 
scheme proposed by Teufel et al (2009) and CoreSC (1st layer), from general to specific.	 ?8  Conclusion We have compared three different schemes, each taking a different perspective to the annotation of scientific discourse. The comparison shows that the three schemes are complementary, with different strengths and points of focus. CoreSC offers a fine-grained characterisation of methods, outcomes and objectives. It has been used to annotate a collection of 265 full papers, and subsequently CoreSC recognition has been fully automated, creating the online SAPIENTA tool. The discourse segment annotation scheme can help to provide a finer-grained characterisation of background work, and could also help to split multi-clause CoreSC sentences into appropriate segments. Recognition of event meta-knowledge has been fully automated in the U-Compare framework, and the KT values of the scheme can help to provide a finer-grained analysis of certain segment and sentence types. The CL dimension also allows confidence values to be ascribed to the Conclusion, Result, Implication and Hypothesis categories of the other two schemes.   Future work will focus on annotating texts with several discourse perspectives to investigate the advantages of the schemes. Ideally we would like to propose a unified approach for scientific discourse annotation, but recognize that choices such as the unit of annotation are often task-oriented, and that users should be able to mix and match discourse segments as required. This said, the analysis in this paper paves the way for potential harmonisation, revealing points of union and intersection between the schemes. Acknowledgements This work has been supported through funding for Maria  Liakata by JISC, the Leverhulme Trust and EBI-EMBL. It has also been supported by the BBSRC through grant number BB/G013160/1UK (Automated Biological Event Extraction from the Literature for Drug Discovery), the MetaNet4U project (ICT PSP Programme, Grant Agreement: No. 270893) and the JISC-funded ISHER project.  
44
References  Ananiadou, S., Kell, D.B. and Tsujii, J. (2006). Text mining and its potential applications in systems biology. Trends Biotechnol, 24(12): 571-9. Ananiadou, S. and McNaught, J., Eds. (2006). Text Mining for Biology and Biomedicine. Boston / London, Artech House. Ananiadou, S., Pyysalo, S., Tsujii, J. and Kell, D.B. (2010). Event extraction for systems biology by text mining the literature. Trends Biotechnol, 28(7): 381-90. Bj?rne, J., Heimonen, J., Ginter, F., Airola, A., Pahikkala, T. and Salakoski, T. (2009). Extracting Complex Biological Events with Rich Graph-Based Feature Sets. In Proceedings of the BioNLP 2009 Workshop Companion Volume for Shared Task, pp.  10-18. Blake, C. (2010). Beyond genes, proteins, and abstracts: Identifying scientific claims from full-text biomedical articles. Journal of Biomedical Informatics, 43(2): 173-189. Cohen, J. (1960). A coefficient of agreement for nominal scales. Educational and psychological measurement, 20: 37-46. Cohen, K.B. and Hunter, L. (2008). Getting started in text mining. PLoS Comput Biol, 4(1): e20. Cohen, K.B., Johnson, H.L., Verspoor, K., Roeder, C. and Hunter, L.E. (2010). The structural and content aspects of abstracts versus bodies of full text journal articles are different. BMC Bioinformatics, 11: 492. de Waard, A., Buitelaar, P., Eigner, T. (2009). Identifying the epistemic value of discourse segments in biology texts. Proceedings of the Eighth International Conference on Computational Semantics, pp. 351-354 de Waard, A. and Pander Maat, H. (2009). Categorizing Epistemic Segment Types in Biology Research Articles. In Proceedings of the Workshop on Linguistic and Psycholinguistic Approaches to Text Structuring (LPTS 2009) de Waard, A. and Pander Maat, H. (2012). Knowledge Attribution in Scientific Discourse: A Taxonomy of Types and Overview of Features, In Proceedings of the Workshop on Detecting Structure in Scholarly Discourse (DSDD), ACL 2012. Farkas, R.	 ?Vincze, V., M?ra, G., Csirik, J. and Szarvas, G. 2010. The CoNLL-2010 Shared Task: Learning to Detect Hedges and their Scope in Natural Language Text. In Proceedings of the Fourteenth Conference on Computational Natural Language Learning, Uppsala, Sweden. 
Association for Computational Linguistics, pp. 1- 12. Guo, Y., Korhonen, A., Liakata, M., Silins, I., LiSun, L. and Stenius, U. (2010). Identifying the information structure of scientific abstracts: An investigation of three different schemes. In Proceedings of BioNLP 2010, pp.  99-107. Hirohata, K., Okazaki, N., Ananiadou, S. and Ishizuka, M. (2008). Identifying Sections in Scientific Abstracts using Conditional Random Fields. In Proceedings of the 3rd International Joint Conference on Natural Language Processing, pp.  381-388. Hyland, K. (1996). Writing without conviction? Hedging in science research articles. Applied Linguistics, 17(4): 433-454. Kano, Y., Miwa, M., Cohen, K.B., Hunter, L.E., Ananiadou, S. and Tsujii, J. (2011). U-Compare: A modular NLP workflow construction and evaluation system. IBM Journal of Research and Development, 55(3): 11:1-11:10. Kilicoglu, H. and Bergler, S. (2008). Recognizing speculative language in biomedical research articles: a linguistically motivated perspective. BMC Bioinformatics, 9(Suppl 11): S10. Kim, J.-D., Ohta, T. and Tsujii, J. (2008). Corpus annotation for mining biomedical events from literature. BMC Bioinformatics, 9(10). Kim, J.D., Ohta, T., Pyysalo, S., Kano, Y. and Tsujii, J. (2011). Extracting Bio-Molecular Events from Literature - The BioNLP'09 Shared Task. Computational Intelligence, 27(4): 513-540. Liakata, M., Saha, S., Dobnik, S., Batchelor, C. and Rebholz-Schuhmann, D. (2012). Automatic recognition of conceptualisation zones in scientific articles and two life science applications. Bioinformatics, 28 (7). Liakata, M. and Soldatova, L.N. (2009). The ART corpus. Technical Report. Aberystwth University. Liakata, M., Teufel, S., Siddharthan, A. and Batchelor, C. (2010). Corpora for the conceptualisation and zoning of scientific papers. In Proceedings of LREC, pp.  2054-2061. Light, M., Qiu, X.Y. and Srinivasan, P. (2004). The language of bioscience: Facts, speculations, and statements in between. In Proceedings of the BioLink 2004 Workshop at HLT/NAACL, pp.  17?24. McKnight, L. and Srinivasan, P. (2003). Categorization of sentence types in medical abstracts. In AMIA Annu Symp Proc, pp.  440-4. Miwa, M., Saetre, R., Kim, J.D. and Tsujii, J. (2010). Event extraction with complex event 
45
classification using rich features. J Bioinform Comput Biol, 8(1): 131-46. Miwa, M., Thompson, P. and Ananiadou, S. (2012). Boosting automatic event extraction from the literature using domain adaptation and coreference resolution. Bioinformatics.  Miwa, M., Thompson, P., McNaught, J, Kell, D.B and Ananiadou, S. (In Press). Extracting semantically enriched events from biomedical literature. BMC Bioinformatics.  Miyao, Y., Ohta, T., Masuda, K., Tsuruoka, Y., Yoshida, K., Ninomiya, T. and Tsujii, J. (2006). Semantic Retrieval for the Accurate Identification of Relational Concepts in Massive Textbases. In Proceedings of ACL, pp.  1017-1024. Mizuta, Y., Korhonen, A., Mullen, T. and Collier, N. (2005). Zone Analysis in Biology Articles as a Basis for Information Extraction. International Journal of Medical Informatics,75(6): 468-487. Morante R., and Sporleder C, (2012). Modality and negation: An introduction to the special issue. Computational Linguistics, 38(2): 1?38. Nawaz, R., Thompson, P. and Ananiadou, S. (In Press). Identification of Manner in Bio-Events. Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC 2012). Nawaz, R., Thompson, P., McNaught, J. and Ananiadou, S. (2010). Meta-Knowledge Annotation of Bio-Events. In Proceedings of LREC 2010, pp.  2498-2507. Pyysalo, S., Ginter, F., Heimonen, J., Bjorne, J., Boberg, J., Jarvinen, J. and Salakoski, T. (2007). BioInfer: a corpus for information extraction in the biomedical domain. BMC Bioinformatics, 8: 50. Pyysalo, S., Ohta, T., Rak, R., Sullivan, D., Mao, C., Wang, C., Sobral, B., Tsujii, J. and Ananiadou, S. (In Press). Overview of the ID, EPI and REL tasks of BioNLP Shared Task 2011. BMC Bioinformatics. Quirk, C., Choudhury, P., Gamon, M. and Vanderwende, L. (2011). MSR-NLP Entry in BioNLP Shared Task 2011. In Proceedings of BioNLP Shared Task 2011 Workshop, pp.  155-163. Ruch, P., Boyer, C., Chichester, C., Tbahriti, I., Geissbuhler, A., Fabry, P., Gobeill, J., Pillet, V., Rebholz-Schuhmann, D., Lovis, C. and Veuthey, A.L. (2007). Using argumentation to extract key sentences from biomedical abstracts. Int J Med Inform, 76(2-3): 195-200. S?ndor, ?. (2007). Modeling metadiscourse conveying the author?s rhetorical strategy in biomedical 
research abstracts. Revue Fran?aise de Linguistique Appliqu?e, 200(2): 97-109. Shatkay, H., Pan, F., Rzhetsky, A. and Wilbur, W.J. (2008). Multi-dimensional classification of biomedical text: toward automated, practical provision of high-utility text to diverse users. Bioinformatics, 24(18): 2086-2093. Soldatova, L.N. and King, R.D. (2006). An ontology of scientific experiments. Journal of the Royal Society Interface, 3(11): 795-803. Soldatova, L.N. and Liakata, M. (2007). An ontology methodology and cisp-the proposed core information about scientific papers., Aberystwyth University. Technical Report JISC Project Report. Teufel, S. (2010). The Structure of Scientific Articles: Applications to Citation Indexing and Summarization. Stanford, CA, CSLI Publications. Teufel, S., Carletta, J. and Moens, M. (1999). An annotation scheme for discourse-level argumentation in research articles. In Proceedings of EACL, pp.  110-117. Teufel, S. and Moens, M. (2002). Summarizing scientific articles: experiments with relevance and rhetorical status. Computational Linguistics, 28(4): 409-445. Teufel, S., Siddharthan, A. and Batchelor, C. (2009). Towards discipline-independent argumentative zoning: Evidence from chemistry and computational linguistics. In Proceedings of EMNLP 2009, pp.  1493-1502. Thompson, P., Iqbal, S.A., McNaught, J. and Ananiadou, S. (2009). Construction of an annotated corpus to support biomedical information extraction. BMC Bioinformatics, 10: 349. Thompson, P., Nawaz, R., McNaught, J. and Ananiadou, S. (2011). Enriching a biomedical event corpus with meta-knowledge annotation. BMC Bioinformatics, 12: 393. Vincze, V., Szarvas, G., Farkas, R., Mora, G. and Csirik, J. (2008). The BioScope corpus: biomedical texts annotated for uncertainty, negation and their scopes. BMC Bioinformatics, 9(Suppl 11): S9. Zweigenbaum, P., Demner-Fushman, D., Yu, H. and Cohen, K.B. (2007). Frontiers of biomedical text mining: current progress. Briefings in Bioinformatics, 8(5): 358-375.  
46
