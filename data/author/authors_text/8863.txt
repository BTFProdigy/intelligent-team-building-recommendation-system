Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1218?1226,
Beijing, August 2010
A Methodology for Automatic Identification of Nocuous Ambiguity 
 
Hui Yang1            Anne de Roeck1            Alistair Willis1            Bashar Nuseibeh1, 2 
1Department of Computing, The Open University 
2Lero, University of Limerick 
 {h.yang, a.deroeck, a.g.willis, b.nuseibeh}@open.ac.uk 
 
Abstract 
Nocuous ambiguity occurs when a lin-
guistic expression is interpreted differ-
ently by different readers in a given con-
text. We present an approach to auto-
matically identify nocuous ambiguity 
that is likely to lead to misunderstand-
ings among readers. Our model is built 
on a machine learning architecture. It 
learns from a set of heuristics each of 
which predicts a factor that may lead a 
reader to favor a particular interpretation. 
An ambiguity threshold indicates the ex-
tent to which ambiguity can be tolerated 
in the application domain. Collections of 
human judgments are used to train heu-
ristics and set ambiguity thresholds, and 
for evaluation. We report results from 
applying the methodology to coordina-
tion and anaphora ambiguity. Results 
show that the method can identify nocu-
ous ambiguity in text, and may be wid-
ened to cover further types of ambiguity. 
We discuss approaches to evaluation. 
1 Introduction 
Traditional accounts of ambiguity have generally 
assumed that each use of a linguistic expression 
has a unique intended interpretation in context, 
and attempted to develop a model to determine it 
(Nakov and Hearst, 2005; Brill and Resnik, 
1994). However, disambiguation is not always 
appropriate or even desirable (Poesio and Art-
stein, 2008). Ambiguous text may be interpreted 
differently by different readers, with no consen-
sus about which reading is the intended one. At-
tempting to assign a preferred interpretation may 
therefore be inappropriate. Misunderstandings 
among readers do occur and may have undesir-
able consequences. In requirements engineering 
processes, for example, this results in costly im-
plementation errors (Boyd et al, 2005).  
Nonetheless, most text does not lead to sig-
nificant misinterpretation. Our research aims to 
establish a model that estimates how likely an 
ambiguity is to lead to misunderstandings. Our 
previous work on nocuous ambiguity (Chantree 
et al, 2006; Willis et al, 2008) cast ambiguity 
not as a property of a text, but as a property of 
text in relation to a set of stakeholders. We drew 
on human judgments - interpretations held by a 
group of readers of a text ? to establish criteria 
for judging the presence of nocuous ambiguity. 
An ambiguity is innocuous if it is read in the 
same way by different people, and nocuous oth-
erwise. The model was tested on co-ordination 
ambiguity only. 
In this paper, we implement, refine and extend 
the model. We investigate two typical ambiguity 
types arising from coordination and anaphora. 
We extend the previous work (Willis et al, 
2008) with additional heuristics, and refine the 
concept of ambiguity threshold. We experiment 
with alternative machine learning algorithms to 
find optimal ways of combining the output of the 
heuristics. Yang et al (2010a) describes a com-
plete implementation in a prototype tool running 
on full text. Here we present our experimental 
results, to illustrate and evaluate the extended 
methodology. 
The rest of the paper is structured as follows. 
Section 2 introduces the methodology for auto-
matic detection of nocuous ambiguity. Sections 
3 and 4 provide details on how the model is ap-
plied to coordination and anaphora ambiguity. 
Experimental setup and results are reported in 
Section 5, and discussed in Section 6. Section 7 
reports on related work. Conclusions and future 
work are found in Section 8.          
1218
2 Methodology for Nocuous Ambiguity 
Identification 
This section describes the main ideas underpin-
ning our model of ambiguity. We distinguish 
between structural and interpretative aspects. 
The former captures the fact that text may have 
structure (i.e. syntax) which, in principle, per-
mits multiple readings. These are relatively 
straightforward to identify from the linguistic 
constructs present in the text. The latter ac-
knowledges that if text is interpreted in the same 
way by different readers, it has a low risk of be-
ing misunderstood. Modelling interpretive as-
pects requires access to human judgments about 
texts. Our approach has three elements, which 
we describe in turn: collection of human judg-
ments; heuristics that model those judgments, 
and a machine learning component to train the 
heuristics.  
 
Human judgments. We define an ambiguity as 
nocuous if it gives rise to diverging interpreta-
tions. Wasow et al (2003) suggests that ambigu-
ity is always a product of the meaning that peo-
ple assign to language, and thus a subjective 
phenomenon. We capture individual interpreta-
tions of instances of ambiguity by surveying par-
ticipants, asking them for their interpretation. 
We use this information to decide whether, 
given some ambiguity threshold, a particular 
instance is seen as innocuous or nocuous de-
pending on the degree of dissent between judges. 
A key concept in determining when ambiguity 
is nocuous is the ambiguity threshold. Different 
application areas may need to be more or less 
tolerant of ambiguity (Poesio and Artstein, 2008). 
For instance, requirements documents describing 
safety critical systems should seek to avoid mis-
understandings between stakeholders. Other 
cases, such as cookbooks, could be less sensitive. 
Willis et al (2008)?s general concept of ambigu-
ity threshold sought to implement a flexible tol-
erance level to nocuous ambiguity. Given an 
instance of ambiguous text, and a set of judg-
ments as to the correct interpretation, the cer-
tainty of an interpretation is the percentage of 
readers who assign that interpretation to the text. 
For example, in Table 1 below (sec. 3.1), the 
certainty of the two interpretations, HA and LA 
of expression (a) are 12/17=71% and 1/17=5.9% 
respectively. Here, an expression shows nocuous 
ambiguity if none of the possible interpretations 
have a certainty exceeding the chosen threshold. 
Later in this section, we will describe further 
experiments with alternative, finer grained ap-
proaches to setting and measuring thresholds, 
that affect the classifier?s behaviour. 
 
Heuristics. Heuristics capture factors that may 
favour specific interpretations. Each heuristic 
embodies a hypothesis, drawn from the literature, 
about a linguistic phenomenon signifying a pre-
ferred reading. Some use statistical information 
(e.g., word distribution information obtained 
from a generic corpus, the BNC 1 , using the 
Sketch Engine2). Others flag the presence of sur-
face features in the text, or draw on semantic or 
world knowledge extracted from linguistic re-
sources like WordNet3 or VerbNet4. 
 
Machine learning (ML). Individual heuristics 
have limited predictive power: their effective-
ness lies in their ability to operate in concert. 
Importantly, the information they encapsulate 
may be interdependent. We harness this by using 
ML techniques to combine the outputs of indi-
vidual heuristics. ML is an established method 
for recognizing complex patterns automatically, 
making intelligent decisions based on empirical 
data, and learning of complex and nonlinear re-
lations between data points. Our model uses su-
pervised learning ML techniques, deducing a 
function from training data, to classify instances 
of ambiguity into nocuous or innocuous cases. 
The classifier training data consists of pairs of 
input objects (i.e. vectors made up of heuristics 
scores) and desired outputs (i.e. the class labels 
determined by the distribution of human judg-
ments as captured by thresholds). To select an 
appropriate ML algorithm for the nocuity classi-
fier, we tested our datasets (described in later 
sections) on several algorithms in the WEKA5 
package (e.g., decision tree, J48, Naive Bayes, 
SVM, Logistic Regression, LogitBoost, etc.)  
To train, and validate, a nocuity classifier for 
a particular form of ambiguity, we build a data-
set of judgments, and select heuristics that model 
                                                 
1
 http://www.natcorp.ox.ac.uk/ 
2
 http://sketchengine.co.uk/ 
3
 http://wordnet.princeton.edu/ 
4
 http://verbs.colorado.edu/~mpalmer/projects/verbnet.html 
5
 http://www.cs.waikato.ac.nz/~ml/index.html 
1219
the information underlying the human judge-
ments about a preferred interpretation.  
We validated the approach on two forms of 
ambiguity. Sections 3 and 4 discuss how the 
methodology is applied to forms of coordination 
and anaphoric ambiguity, and evaluate the per-
formance of the final classifiers.                       
3 Automatic Identification of Nocuous 
Coordination Ambiguity 
Our previous work on nocuous ambiguity has 
focused on coordination ambiguity: a common 
kind of structural ambiguity. A coordination 
structure connects two words, phrases, or clauses 
together via a coordination conjunction (e.g., 
?and?, ?or?, etc) as in the following examples:  
 
(1) They support a typing system for architec-
tural components and connectors.  
(2) It might be rejected or flagged for further 
processing. 
 
     In (1), the coordination construction ?architec-
tural components and connectors? consists of a 
near conjunct (NC) (i.e. ?components?), a far 
conjunct (FC) (i.e. ?connectors?), and the at-
tached modifier (M) (i.e. ?architectural?). This 
construction allows two bracketings correspond-
ing to high modifier attachment ([architectural 
[components and connectors]]) or low modifier 
attachement ([[architectural components] and 
connector]). Our aim is to refine Chantree et al
(2006) and Willis et al(2008), hence our focus is 
on the two phenomena they treated: modification 
in noun phrase coordination (as in (1)) and in 
verb phrase coordination (as in (2)).   
     We implemented the heuristics described in 
the earlier work, and introduced two further ones 
(local document collocation frequency, and se-
mantic similarity). We used the Chantree et al
(2006) dataset of human judgments, but em-
ployed the LogitBoost algorithm for implement-
ing the nocuity classifier (rather than the Logis-
tic Regression equation). The following subsec-
tions give more detail. 
3.1 Building a dataset 
Coordination instances. Our dataset was col-
lected and described by Chantree et al (2006). It 
contains 138 coordination instances gathered 
from a set of requirement documents. Noun 
compound conjunctions account for the majority 
(85.5%) of cases (118 instances). Nearly half of 
these arose as a result of noun modifiers, while 
there are 36 cases with adjective and 18 with 
preposition modifiers. 
 
Human judgment collection. The coordination 
instances containing potential ambiguity were 
presented to a group of 17 computing profes-
sionals including academic staff or research stu-
dents. For each instance, the judges were asked 
to select one of three options: high modifier at-
tachment (HA), low modifier attachment (LA), 
or ambiguous (A). Table 1 shows the judgment 
count for two sample instances. In instance (a) in 
table 1, the certainty of HA is 12/17=71%, and 
the certainty of LA is 1/17=6%. Instance (b) was 
judged mainly to be ambiguous.  
 
 
 Judgments 
 HA LA A 
(a) security and privacy requirements 12 1 4 
(b) electrical characteristics and interface 4 4 9 
Table 1. Judgment count for the sample instances (HA=high at-
tachment; LA=low attachment; and A=Ambiguous) 
 
We set an ambiguity threshold, ?, to determine 
whether the distribution of interpretations is 
nocuous or innocuous with respect to that par-
ticular ?. If the certainty of neither interpretation, 
HA or LA, exceeds the threshold ?, we say this 
is an instance of nocuous coordination. Other-
wise it is innocuous. Here, (a) displays nocuous 
ambiguity for ?>71%. 
0
10
20
30
40
50
60
70
80
90
100
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Ambiguity Thresholds 
Am
bi
gu
iti
e
s 
(%
)
Inno
Nocu
 
Figure 1. Proportions of interpretations at different ambiguity 
thresholds in the coordination instances 
Figure 1 shows the systematic relationship be-
tween ambiguity threshold and the incidence of 
nocuous ambiguity in the dataset. Low thresh-
olds can be satisfied with a very low certainty 
scores resulting in few instances being consid-
ered nocuous. At high thresholds, almost all in-
stances are classified as nocuous unless the 
judges report a consensus interpretation.  
1220
3.2 Heuristics to predict Nocuity 
Each heuristic tests a factor favouring a high or 
low modifier attachment (HA or LA). We im-
plemented and extended Willis et al (2008). 
 
Coordination matching favours HA when the 
head words of near and far conjuncts are fre-
quently found coordinated in a general corpus 
like BNC, suggesting they may form a single 
syntactic unit. 
 
Distribution similarity measures how often two 
words are found in the same contexts. It favours 
HA where it detects a strong distributional simi-
larity between the headwords of the two con-
juncts, suggesting these form a syntactic unit 
(Kilgariff 2003).  
 
Collocation frequency favours LA when the 
modifier is collocated much more frequently 
with the headword of the near conjunct than the 
far conjunct, in the document, or in the BNC. 
 
Morphology favours HA when the conjunct 
headwords share a morphological marker (suf-
fix) (Okumura and Muraki 1994).  
 
Semantic similarity favours HA when the con-
junct headwords display strong similarity in the 
taxonomic structure in WordNet6.  
3.3 Nocuity classification 
To train, and test, the nocuity classifier, each 
ambiguity training/test instance is represented as 
an attribute-value vector, with the values set to 
the score of a particular heuristic. The class label 
of each instance (nocuous (Y) or innocuous (N) 
at a given ambiguity threshold) is determined by 
the certainty measure as discussed earlier. We 
selected the LogitBoost algorithm for building 
the classifier, because it outperformed other can-
didates on our training data than. To determine 
whether a test instance displays nocuity or not, 
we presented its feature vector to the classifier, 
and obtained a predicted class label (Y or N). 
4 Automatic Identification of Nocuous 
Anaphora Ambiguity 
An anaphor is an expression referring to an an-
tecedent, usually a noun phrase (NP) found in 
                                                 
6
 Implemented by the NLP tool - Java WordNet Similarity Library. 
http://nlp.shef.ac.uk/result/software.html 
the preceding text. Anaphora ambiguity occurs 
when there are two or more candidate antece-
dents, as in example (3). 
 
(3) The procedure shall convert the 24 bit image to 
an 8 bit image, then display it in a dynamic window. 
 
In this case, both of the NPs, ?the 24 bit im-
age? and ?an 8 bit image?, are considered poten-
tial candidate antecedents of the anaphor ?it?. 
Anaphora ambiguity is difficult to handle due 
to contextual effects spread over several sen-
tences. Our goal is to determine whether a case 
of anaphora ambiguity is nocuous or innocuous, 
automatically, by using our methodology.  
4.1 The building of the Dataset 
Anaphora instances. We collected 200 anaph-
ora instances from requirements documents from 
RE@UTS website 7 . We are specifically con-
cerned with 3rd person pronouns, which are 
widespread in requirements texts. The dataset 
contains different pronoun types. Nearly half  
the cases (48%) involve subject pronouns, al-
though pronouns also occurred in objective and 
possessive positions (15% and 33%, respec-
tively).  Pronouns in prepositional phrases (e.g., 
?under it?) are rarer (4% - only 8 instances).  
 
Human judgment collection. The instances 
were presented to a group of 38 computing pro-
fessionals (academic staff, research students, 
software developers). For each instance, the 
judges were asked to select the antecedent from 
the list of NP candidates. Each instance was 
judged by at least 13 people. Table 2 shows an 
example of judgment counts, where 12 out of 13 
judges committed to ?supervisors? as the antece-
dent of ?they?, whereas 1 chose ?tasks?.   
 
1. Supervisors may only modify tasks they supervise to the 
agents they supervise.  
 Response 
Percent 
Response 
Count 
(a) supervisors 
(b) tasks 
92.3% 
7.7% 
12 
1 
Table 2. Judgment count for an anaphora ambiguity instance. 
 
Ambiguity threshold. Given an anaphor, the 
interpretation certainty of a particular NP candi-
date is calculated as the percentage of the judg-
ments for this NP against the total judgments for 
the instance. For example, consider the example 
in Table 2. The certainty of the NP ?supervisors? 
                                                 
7
 http://research.it.uts.edu.au/re/ 
1221
is 12/13=92.3% and the certainty of the NP 
?tasks? is 1/13=7.7%. Thus, at an ambiguity 
threshold of, for instance, ? = 0.8, the ambiguity 
in Table 2 is innocuous because the agreement 
between the judges exceeds the threshold. 
Figure 2 shows the relationship between am-
biguity threshold and occurrence of nocuous 
ambiguity. As in Figure 1, the number of nocu-
ous ambiguities increases with threshold ?. For 
high thresholds (e.g., ??0.9), more than 60% of 
instances are classified as nocuous. Below 
threshold (??0.4), fewer than 8 cases are judged 
nocuous. Also, comparing Figures 1 and 2 would 
appear to suggest that, in technical documents, 
anaphora ambiguity is less likely to lead to mis-
understandings than coordination.  
0
10
20
30
40
50
60
70
80
90
100
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Ambiguity Thresholds
Am
bi
gu
iti
e
s 
(%
)
Inno
Nocu
Figure 2. Proportions of interpretations at different ambiguity 
thresholds in the anaphora instances. 
4.2 Antecedent Preference Heuristics 
Drawing on the literature on anaphoric reference, 
we developed 12 heuristics of three types: re-
lated to linguistic properties of text components, 
to context and discourse information, or to sta-
tistical information drawn from standard corpora. 
Yang et al (2010b) gives more detail. A heuris-
tic marks candidate antecedents which it favours, 
or disfavours. For instance, heuristics favour 
definite NPs as antecedents, candidate NPs 
which agree in number and syntactic role with 
the anaphor, and those which share a syntactic 
collocation pattern in the text. They also favour 
those which respect the semantic constraints 
(e.g., animacy) propagated from subcategorisa-
tion information, and reward proximity to the 
anaphor. They disfavour candidate antecedents 
that occur in prepositional phrases, and those 
occupying a syntactic role distinct from the ana-
phor. Note: not all NPs are marked by all heuris-
tics, and some heuristics are interdependent.   
4.3 Nocuous Ambiguity Identification 
Unlike coordination ambiguity, where judges 
chose for high or low modifier attachment, 
anaphora have scope over a variable set of po-
tential antecedents, depending on each particular 
instance. To accommodate this, we developed an 
antecedent classifier which assigns a weighted 
antecedent tag to each NP candidate associated 
with an instance. Tag information is used subse-
quently to predict the whether the instance dis-
plays nocuous ambiguity. 
The antecedent classifier is built using the Na-
ive Bayes algorithm within the WEKA package 
and is trained to return three classes of candidate 
antecedent: positive (Y), questionable (Q), or 
negative (N). In an innocuous case, a candidate 
NP will be classed as Y if its interpretation cer-
tainty exceeds the threshold set by ?, and tagged 
as N otherwise; in a nocuous case, it will be 
classed as N if its certainty is 0%, and classified 
as Q otherwise.  
 
1. The LPS operational scenarios represent sequences of activi-
ties performed by operations personnel as they relate to the LPS 
software. 
 Response Label 
(a) the LPS operational scenarios 
(b) sequences of activities 
(c) activities 
(d) operations personnel 
33.3% 
66.7% 
0% 
0% 
Q 
Q 
N 
N 
Table 3. The determination of antecedent label for the NP candi-
dates in a NOCUOUS ambiguity case (? =0.8) 
 
2. Testing performed to demonstrate to the acquirer that a 
CSCI system meets its specified requirements. 
 Response 
Percent 
Class 
Label 
(a) Testing 
(b) the acquirer 
(c) a CSCI system 
0% 
16.7% 
83.3% 
N 
N 
Y 
Table 4. The determination of antecedent label for the NP candi-
dates in a INNOCUOUS ambiguity case (? =0.8) 
 
Antecedent Class Label  
Y Q N 
? = 0.5 181 54 623 
? = 0.6 160 99 599 
? = 0.7 137 149 572 
? = 0.8 107 209 542 
? = 0.9 77 261 520 
? = 1.0 41 314 503 
Table 5. The distribution of three antecedent class label at different 
ambiguity thresholds 
 
Table 3 and 4 illustrate antecedent labels for 
NP antecedent candidates in a nocuous and in-
nocuous case. Candidates (a) and (b) in Table 3 
are labeled Q because their certainty falls below 
the threshold (? = 0.8). For the same threshold, 
candidate (c) in Table 4 is tagged as Y. Table 5 
1222
shows the distribution of tags at certainty thresh-
olds ? ? 0.5 for all (858) candidate antecedents 
in our sample. 
Our intended application is a system to alert 
experts to risk of misunderstandings. This sug-
gests we should emphasise recall even at the ex-
pense of some precision (Berry et al 2003). We 
developed two versions of the algorithm that 
determines whether an instance is nocuous or not, 
depending on the contribution made by its ante-
cedent candidates tagged Y. We relax constraints 
by introducing two concepts: a weak positive 
threshold W
Y
 and a weak negative threshold WN 
set at 0.5 and 0.4, respectively8. The rationale for 
weak thresholds is that antecedent preference 
reflects a spectrum with Y (high), Q (medium), 
and N (low). Weak positive and negative thresh-
olds act as buffers to the Q area. Antecedent NPs 
that fall in the W
Y
 or WN buffer area are treated 
as possible false negative (FN) for the classifica-
tion of the label Q. An antecedent tag Y/N is la-
beled as weak positive or negative depending on 
these thresholds. The algorithm for identifying 
nocuous ambiguity is given in Figure 3. It treats 
as innocuous those cases where the antecedent 
label list contains one clear Y candidate, whose 
certainty exceeds all others by a margin.  
 
Given an anaphora ambiguity instance with multiple potential NPs, 
the antecedent classifier returns a label list, },,,{ 21 nrrrR K= , for 
individual NPs. 
 
Parameters:  
1) W
Y
 - the threshold for the weak positive label. The label Y is 
viewed as weak positive when the positive prediction score ri < WY 
2) W
N
 - the threshold for the weak negative label. The label N is 
viewed as weak negative when the negative prediction score ri < 
W
N
 
 
Procedure: 
if the label list R contains  
         (one Y, no Q, one or more N ) 
    or  
         (no Y, one Q, one or more N but not weak negative ) 
    or  
        (one Y but not weak positive, any number of Q or N)    
then 
         the ambiguity is INNOCUOUS 
else 
         the ambiguity is NOCUOUS          
Figure 3. The algorithm for nocuous ambiguity identification 
5 Experiments and Results 
In all experiments, the performance was evalu-
ated using 5-fold cross-validation, using  stan-
                                                 
8
 Weak positive and negative thresholds are set experimentally. 
dard measures of Precision (P), Recall (R), F-
measure (F), and Accuracy. We use two naive 
baselines: BL-1 assumes that all ambiguity in-
stances are innocuous; BL-2 assumes that they 
are all nocuous. For fair comparison against the 
baselines, for both forms of ambiguity, we only 
report the performance of our ML-based models 
when the incidence of nocuous ambiguities falls 
between 10% ~ 90% of the set (see Figures 1 
and 2). We first report our findings for the iden-
tification of nocuous coordination ambiguities 
and then discuss the effectiveness of our model 
in distinguishing possible nocuous ambiguities 
from a set of ambiguity instances.    
5.1 Nocuous Coordination Ambiguity Iden-
tification 
Willis et al(2008) demonstrated the ability of 
their approach to adapt to different thresholds by 
plotting results against the two na?ve base lines. 
Since we extended and refined their approach 
described we plot our experimental results (CM-
1), for comparison, using the same measures, 
against their evaluation data (CM-2), in Figure 4.   
0
10
20
30
40
50
60
70
80
90
100
40 45 50 55 60 65 70 75 80
Ambiguity Threshold (%)
Ac
cu
ra
cy
 (%
) BL-1
BL-2
CM-1
CM-2
Figure 4. The performance comparison of the ML-based models, 
CM-1 and CM-2, to the two baseline models, BL-1 and BL-2, in 
nocuous coordination ambiguity identification.  
 
Our CM-1 model performed well with an ac-
curacy of above 75% on average at all ambiguity 
threshold levels. As expected, at very high and 
very low thresholds, we did not improve on the 
naive baselines (which have perfect recall and 
hence high accuracy). The CM-1 model dis-
played its advantage when the ambiguity thresh-
old fell in the range between 0.45 and 0.75 (a 
significantly wider range than reported for CM-2 
Willis et al(2008)). CM-1 maximum improve-
ment was achieved around the 58% crossover 
point where the two na?ve baselines intersect and  
our model achieved around 21% increased accu-
1223
racy. This suggests that the combined heuristics 
do have strong capability of distinguishing 
nocuous from innocuous ambiguity at the weak-
est region of the baseline models. 
Figure 4 also shows that, the CM-1 model 
benefitted from the extended heuristics and the 
LogitBoost algorithm with an increased accuracy 
of around 5.54% on average compared with CM-
2.  This suggests that local context information 
and semantic relationships between coordinating 
conjuncts provide useful clues for the identifica-
tion of nocuous ambiguity. Furthermore, the 
LogitBoost algorithm is more suitable for deal-
ing with a numeric-attribute feature vector than 
the previous Logistic Regression algorithm.  
5.2 Nocuous Anaphora Ambiguity Identifi-
cation 
We report on two implementations: one with 
weak thresholds (AM-1) and one without (AM-
2). We compare both approaches using the base-
lines, BL-1 and BL-2 (in Figure 5). It shows that 
AM-1 and AM-2 achieve consistent improve-
ments on baseline accuracy at high thresholds 
(??0.75). Here also, the improvement maximises 
around the 83% threshold point where the two 
baselines intersect. However, the ML-based 
models perform worse than BL-1 at the lower 
thresholds (0.5???0.7). One possible explanation 
is that, at low thresholds, performance is affected 
by lack of data for training of the Q class label, 
an important indicator for nocuous ambiguity 
(see Table 5). This is also consistent with the 
ML models performing well at higher thresh-
olds, when enough nocuous instances are avail-
able for training. 
0
10
20
30
40
50
60
70
80
90
100
50 55 60 65 70 75 80 85 90 100
Ambiguity Threshold (%)
Ac
cu
ra
cy
 
(%
)
BL-1
BL-2
AM-1
AM-2
 
Figure 5. The performance comparison of the ML-based models, 
AM-1 and AM-2, to the two baseline models, BL-1 and BL-2, in 
nocuous anaphora ambiguity identification.  
     
 Figure 5 further shows that the model with 
weak thresholds (AM-1) did not perform as well 
as the model without weak thresholds (AM-2) on 
accuracy. Although both models perform much 
better than the baselines on precision (more ex-
perimental results are reported in Yang et al 
(2010b)), the actual precisions for both models 
are relatively low, ranging from 0.3 ~ 0.6 at dif-
ferent thresholds. When the AM-1 model at-
tempts to discover more nocuous instances using 
weak thresholds, it also introduces more false 
positives (innocuous instances incorrectly 
classed as nocuous). The side-effect of introduc-
ing false positives for AM-1 is to lower accu-
racy. However, the AM-1 model outperforms 
both AM-2 and BL-2 models on F-measure 
(Figure 6), with an average increase of 5.2 and 
3.4 percentage points respectively. This reveals 
that relaxing sensitivity to the ambiguity thresh-
old helps catch more instances of nocuous 
anaphora ambiguity.             
10
15
20
25
30
35
40
45
50
55
60
50 55 60 65 70 75 80 85 90 100
Ambiguity Threshold (%)
F-
m
e
a
su
re
 
(%
) BL-2
AM-1
AM-2
Figure 6. The performance comparison of the ML-based models, 
AM-1 and AM-2, to the baseline model BL-2 (na?ve nocuous) 
6 Discussions 
We presented judges with sentences containing 
ambiguities without any surrounding context, 
even though contextual information (e.g., dis-
course focus) clearly contributes to interpreta-
tion. This is a weakness in our data collection 
technique. Besides contextual information, van 
Deemter?s Principle of Idiosyncratic Interpreta-
tion (1998) suggests that some factors, including 
the reader?s degree of language competence, can 
affect perceptions of ambiguity. Similarly, fa-
miliarity with a domain, including tacit specialist 
information (Polanyi, 1966), and the extent to 
which this is shared by a group, will have an ef-
fect on the extent to which stakeholders arrive at 
diverging interpretations. 
In our case, we extracted instances from re-
quirements documents covering several techni-
1224
cal domains. Judgements are sensitive to the 
backgrounds of the participants, and the extent 
to which stakeholder groups share such a back-
ground. Also, we used several large, generic NL 
resources, including the BNC and WordNet. The 
performance of several heuristics would change 
if they drew on domain specific resources. Dif-
ferent interpretations may be compatible, and so 
not necessarily contribute to misunderstanding.  
Finally, we used different machine learning 
algorithms to tackle different types of ambiguity 
instances: LogitBoost for coordination ambigu-
ity and Naive Bayes for anaphora ambiguity. 
The main reason is that coordination heuristics 
returned numeric values, whereas the anaphora 
heuristics were Boolean. Our method assumes 
tailoring of the ML algorithm to the choice of 
heuristic. These limitations indicate that the 
methodology has a high degree of flexibility, but 
also that it has several interdependent compo-
nents and background assumptions that have to 
be managed if an application is to be developed. 
7 Related Work 
Many researchers have remarked on the fact that 
some ambiguities are more likely than others to 
lead to misunderstandings, and suggested classi-
fying them accordingly. Poesio (1996) discussed 
cases where multiple readings are intended to 
coexist, and distinguished between language in-
herent and human disambiguation factors from a 
philosophical perspective. His notion of ?per-
ceived ambiguity? suggests that human percep-
tions are what actually cause an ambiguity to be 
misunderstood. Van Deemter?s (2004) ?vicious 
ambiguity? refers to an ambiguity that has no 
single, strongly preferred interpretation. He pro-
posed quantifying ?viciousness? using probabili-
ties taken from corpus data. Van Rooy (2004) 
defined a notion of ?true ambiguity?: a sentence 
is truly ambiguous only if there are at least two 
interpretations that are optimally relevant. These 
last two approaches rely on probability analysis 
of language usage, and not directly on human 
perception, which we believe to be the key to 
evaluating ambiguity. Our work differs in that it 
takes into account the distribution of interpreta-
tions arrived at by a group of human judges en-
gaged with a text. Our model treats ambiguity 
not as a property of a linguistic construct or a 
text, or a relation between a text and the percep-
tions of a single reader, but seeks to understand 
the mechanisms that lead to misunderstandings 
between people in a group or process. 
    Poesio et al(2006) have pointed out that dis-
ambiguation is not always necessary; for in-
stance, in some complex anaphora cases, the fi-
nal interpretation may not be fully specified, but 
only ?good enough?. Our work does not attempt 
disambiguation. It seeks to highlight the risk of 
multiple interpretations (whatever those are).   
8 Conclusions and Future Work 
We have presented a general methodology for 
automatically identifying nocuous ambiguity 
(i.e. cases of ambiguity where there is a risk that 
people will hold different interpretations) rela-
tive to some tolerance level set for such a risk. 
The methodology has been implemented in a 
ML based architecture, which combines a num-
ber of heuristics each highlighting factors which 
may affect how humans interpret ambiguous 
constructs. We have validated the methodology 
by identifying instances of nocuous ambiguity in 
coordination and anaphoric constructs. Human 
judgments were collected in a dataset used for 
training the ML algorithm and evaluation. Re-
sults are encouraging, showing an improvement 
of approximately 21% on accuracy for coordina-
tion ambiguity and about 3.4% on F-measure for 
anaphora ambiguity compared with naive base-
lines at different ambiguity threshold levels. We 
showed, by comparison with results reported in 
Willis et al(2008) that the methodology can be 
fine tuned, and extended to other ambiguity 
types, by including different heuristics.  
Our method can highlight the risk of different 
interpretations arising: this is not a task a single 
human could perform, as readers typically have 
access only to their own interpretation and are 
not routinely aware that others hold a different 
one. Nonetheless, our approach has limitations, 
particularly around data collection, and for 
anaphora ambiguity at low thresholds. We en-
visage further work on the implementation of 
ambiguity tolerance thresholds 
Several interesting issues remain to be inves-
tigated to improve our system?s performance and 
validate its use in practice. We need to explore 
how to include different and complex ambiguity 
types (e.g., PP attachment and quantifier scop-
1225
ing), and investigate whether these are equally 
amenable to a heuristics based approach.  
Acknowledgement  
This work is supported financially by UK EPSRC for 
the MaTREx project (EP/F068859/1), and Irish SFI 
for the grant 03/CE2/I303_1. 
References 
Daniel M. Berry, Erik Kamsties, and Michael M. 
Krieger.  2003. From Contract Drafting to Soft-
ware Specification: Linguistic Sources of Ambigu-
ity. Technical Report, School of Computer Sci-
ence, University of Waterloo.  
Stephen Boyd, Didar Zowghi, and Alia Farroukh.  
2005. Measuring the Expressiveness of a Con-
strained Natural Language: An Empirical Study. In 
Proceedings of the 13th IEEE International Con-
ference on Requirements Engineering (RE?05), 
Washington, DC, pages 339-52. 
Eric Brill and Philip Resnik.  1994. A Rule-Based 
Approach to Prepositional Phrase Attachment Dis-
ambiguation. In Proceedings of the 15th Interna-
tional Conference on Computational Linguistics, 
pages 1198-204. 
Francis Chantree, Bashar Nuseibeh, Anne de Roeck, 
and Alistair Willis.  2006. Identifying Nocuous 
Ambiguities in Natural Language Requirements. 
In Proceedings of 14th IEEE International Re-
quirements Engineering Conference (RE'06), Min-
neapolis, USA, pages 59-68. 
Adam Kilgarriff.  2003. Thesauruses for Natural Lan-
guage Processing. In Proceedings of NLP-KE, 
pages 5-13. 
Preslav Nakov and Marti  Hearst.  2005. Using the 
Web as an Implicit Training Set: Application to 
Structural Ambiguity Resolution. In Proceedings 
of HLT-NAACL?05, pages 835-42. 
Akitoshi Okumura and Kazunori Muraki.  1994. 
Symmetric Pattern Matching Analysis for English 
Coordinate Structures. In Proceedings of the 4th 
Conference on Applied Natural Language Proc-
essing, pages 41-46. 
Massimo Poesio. 1996. Semantic Ambiguity and Per-
ceived Ambiguity In Semantic Ambiguity and Un-
derspecification edited by K. van Deemter and S. 
Peters, pages 159-201. 
Massimo Poesio and Ron Artstein. 2008. Introduction 
to the Special Issue on Ambiguity and Semantic 
Judgements. Research on Language & Computa-
tion 6: 241-45. 
Massimo Poesio, Patick Sturt, Ron Artstein, and Ruth 
Filik. 2006. Underspecification and Anaphora: 
Theoretical Issues and Preliminary Evidence. Dis-
course Processes 42(2): 157-75. 
Michael Polanyi.  1966. The Tacit Dimension. RKP, 
London. 
Kees van Deemter. 1998. Ambiguity and Idiosyn-
cratic Interpretation. Journal of Semantics 15(1): 
5-36. 
Kees van Deemter. 2004. Towards a Probabilistic 
Version of Bidirectional Ot Syntax and Semantics. 
Journal of Semantics 21(3): 251-80. 
Robert van Rooy. 2004. Relevance and Bidirectional 
Ot. In Optimality Theory and Pragmatic, edited by 
R. Blutner and H. Zeevat, pages 173-210. 
Thomas Wasow, Amy Perfors, and David Beaver. 
2003. The Puzzle of Ambiguity. In Morphology 
and the Web of Grammar: Essays in Menory of 
Steven G. Lapointe, edited by O. Orgun and P. 
Sells. 
Alistair Willis, Francis Chantree, and Anne De 
Roeck. 2008. Automatic Identification of Nocuous 
Ambiguity. Research on Language & Computa-
tion 6(3-4): 1-23. 
Hui Yang, Alistair Willis, Anne de Roeck, and Ba-
shar Nuseibeh. 2010a. Automatic Detection of 
Nocuous Coordination Ambiguities in Natural 
Language Requirements. In Proceedings of the 
25th IEEE/ACM International Conference on 
Automated Software Engineering Conference 
(ASE?10). (In press) 
Hui Yang, Anne de Roeck, Alistair Willis, and Ba-
shar Nuseibeh. 2010b. Extending Nocuous Ambi-
guity Analysis for Anaphora in Natural Language 
Requirements. In Proceedings of the 18th Interna-
tional Requirements Engineering Conference 
(RE?10). (In press) 
 
1226
Proceedings of the Workshop on Innovative Hybrid Approaches to the Processing of Textual Data (Hybrid2012), EACL 2012, pages 97?105,
Avignon, France, April 23 2012. c?2012 Association for Computational Linguistics
A Generalised Hybrid Architecture for NLP
Alistair Willis
Department of Computing
The Open University,
Milton Keynes, UK
a.g.willis@open.ac.uk
Hui Yang
Department of Computing
The Open University,
Milton Keynes, UK
h.yang@open.ac.uk
Anne De Roeck
Department of Computing
The Open University,
Milton Keynes, UK
a.deroeck@open.ac.uk
Abstract
Many tasks in natural language process-
ing require that sentences be classified from
a set of discrete interpretations. In these
cases, there appear to be great benefits in
using hybrid systems which apply multiple
analyses to the test cases. In this paper, we
examine a general principle for building hy-
brid systems, based on combining the re-
sults of several, high precision heuristics.
By generalising the results of systems for
sentiment analysis and ambiguity recogni-
tion, we argue that if correctly combined,
multiple techniques classify better than sin-
gle techniques. More importantly, the com-
bined techniques can be used in tasks where
no single classification is appropriate.
1 Introduction
The success of hybrid NLP systems has demon-
strated that complex linguistic phenomena and
tasks can be successfully addressed using a com-
bination of techniques. At the same time, it is
clear from the NLP literature, that the perfor-
mance of any specific technique is highly depen-
dent on the characteristics of the data. Thus, a
specific technique which performs well on one
dataset might perform very differently on another,
even on similar tasks, and even if the two datasets
are taken from the same domain. Also, it is possi-
ble that the properties affecting the effectiveness
of a particular technique may vary within a single
document (De Roeck, 2007).
As a result of this, for many important NLP
applications there is no single technique which
is clearly to be preferred. For example, recent
approaches to the task of anaphora resolution
include syntactic analyses (Haghighi and Klein,
2009), Maximum Entropy models (Charniak and
Elsner, 2009) and Support Vector Machines (Yang
et al, 2006; Versley et al, 2008). The perfor-
mance of each of these techniques varies depend-
ing upon the particular choice of training and test
data.
This state of affairs provides a particular op-
portunity for hybrid system development. The
overall performance of an NLP system depends
on complex interactions between the various phe-
nomena exhibited by the text under analysis, and
the success of a given technique can be sensitive
to the different properties of that text. In partic-
ular, the text?s or document?s properties are not
generally known until the document comes to be
analysed. Therefore, there is a need for systems
which are able to adapt to different text styles at
the point of analysis, and select the most appropri-
ate combination of techniques for the individual
cases. This should lead to hybridising techniques
which are robust or adaptive in the face of varying
textual styles and properties.
We present a generalisation of two hybridi-
sation techniques first described in Yang et al
(2012) and Chantree et al (2006). Each uses
hybrid techniques in a detection task: the first is
emotion detection from suicide notes, the second
is detecting nocuous ambiguity in requirements
documents. The distinguishing characteristic of
both tasks is that a successful solution needs to
accommodate uncertainty in the outcome. The
generalised methodology described here is partic-
ularly suited to such tasks, where as well as se-
lecting between possible solutions, there is a need
to identify a class of instances where no single so-
lution is most appropriate.
97
2 Hybridisation as a Solution to
Classification Tasks
The methodology described in this paper pro-
poses hybrid systems as a solution to NLP tasks
which attempt to determine an appropriate inter-
pretation from a set of discrete alternatives, in par-
ticular where no one outcome is clearly prefer-
able. One such task is nocuous ambiguity detec-
tion. For example, in sentence (1), the pronoun he
could refer to Bill, John or to John?s father.
(1) When Bill met John?s father, he was pleased.
Here, there are three possible antecedents for he,
and it does not follow that all human readers
would agree on a common interpretation of the
anaphor. For example, readers might divide be-
tween interpreting he as Bill or as John?s father.
Or perhaps a majority of readers feel that the
sentence is sufficiently ambiguous that they can-
not decide on the intended interpretation. These
are cases of nocuous ambiguity (Chantree et al,
2006), where a group of readers do not interpret a
piece of text in the same way, and may be unaware
that the misunderstanding has even arisen.
Similarly, as a classification task, sentiment
analysis for sentences or fragments may need
to accommodate instances where multiple senti-
ments can be identified, or possibly none at all.
Example (2) contains evidence of both guilt and
love:
(2) Darling wife, ? I?m sorry for everything.
Hybrid solutions are particularly suited to such
tasks, in contrast to approaches which use a single
technique to select between possible alternatives.
The hybrid methodology proposed in this paper
approaches such tasks in two stages:
1. Define and apply a set of heuristics, where
each heuristic captures an aspect of the phe-
nomenon and estimates the likelihood of a
particular interpretation.
2. Apply a combination function to either com-
bine or select between the values contributed
by the individual heuristics to obtain better
overall system performance.
The model makes certain assumptions about
the design of heuristics. They can draw on a mul-
titude of techniques such as a set of selection fea-
tures based on domain knowledge, linguistic anal-
ysis and statistical models. Each heuristic is a
partial descriptor of an aspect of a particular phe-
nomenon and is intended as an ?expert?, whose
opinion competes against the opinion offered by
other heuristics. Heuristics may or may not be in-
dependent. The crucial aspect is that each of the
heuristics should seek to maximise precision or
complement the performance of another heuristic.
The purpose of step 2 is to maximise the contri-
bution of each heuristic for optimal performance
of the overall system. Experimental results anal-
ysed below show that selecting an appropriate
mode of combination helps accommodate dif-
ferences between datasets and can introduce ad-
ditional robustness to the overall system. The
experimental results also show that appropriate
combination of the contribution of high precision
heuristics significantly increases recall.
For the tasks under investigation here, it proves
possible to select combination functions that al-
low the system to identify behaviour beyond clas-
sifying the subject text into a single category. Be-
cause the individual heuristics are partial descrip-
tions of the whole language model of the text, it
is possible to reason about the interaction of these
partial descriptions, and identify cases where ei-
ther none, or many, of the potential interpretations
of the text are possible. The systems use either a
machine learning technique or a voting strategies
to combine the individual heuristics.
In sections 3 and 4, we explore how the pre-
viously proposed solutions can be classed as in-
stances of the proposed hybridisation model.
3 Case study: Sentiment Analysis
Following Pang et al (2002) and the release of the
polarity 2.0 dataset, it is common for sentiment
analysis tasks to attempt to classify text segments
as either of positive or negative sentiment. The
task has been extended to allow sentences to be
annotated as displaying both positive and negative
sentiment (Wilson et al, 2009) or indicating the
degree of intensity (Thelwall et al, 2010).
The data set used for the 2011 i2b2 shared chal-
lenge (Pestian et al, 2012) differs from this model
by containing a total of 15 different sentiments to
classify the sentences. Each text fragment was
labelled with zero, one or more of the 15 senti-
ments. For example, sentence (2) was annotated
with both Love and Guilt. The fragments varied
between phrases and full sentences, and the task
aims to identify all the sentiments displayed by
98
each text fragment.
In fact, several of the proposed sentiments were
identified using keyword recognition alone, so the
hybrid framework was applied only to recognise
the sentiments Thankfulness, Love, Guilt, Hope-
lessness, Information and Instruction; instances
of the other sentiments were too sparse to be reli-
ably classified with the hybrid system. A keyword
cue list of 984 terms was manually constructed
from the training data based on their frequency in
the annotated set; no other public emotion lexicon
was used. This cue list was used both to recognise
the sparse sentiments, and as input to the CRF.
3.1 Architecture
An overview of the architecture is shown in figure
1. Heuristics are used which operate at the word
level (Conditional Random Fields), and at the
sentence level (Support Vector Machine, Naive
Bayes and Maximum Entropy). These are com-
bined using a voting strategy that selects the most
appropriate combination of methods in each case.
Input
text
?
Preprocess
text
?
Negation
detection
? ?
Combine
values
?
Token level Sentence level
classifier classifiers
CRF SVM
NB
ME
Figure 1: Architecture for sentiment classification task
The text is preprocessed using the tokeniser,
POS tagger and chunker from the Genia tagger,
and parsed using the Stanford dependency parser.
This information, along with a negation recog-
niser, is used to generate training vectors for the
heuristics. Negation is known to have a major ef-
fect on sentiment interpretation (Jia et al, 2009).
3.2 Sentiment recognition heuristics
The system uses a total of four classifiers for each
of the emotions to be recognised. The only token-
level classification was carried out using CRFs
(Lafferty et al, 2001) which have been success-
fully used on Named Entity Recognition tasks.
However, both token- and phrase-level recogni-
tion are necessary to capture cases where sen-
tences convey more than one sentiment. The
CRF-based classifiers were trained to recognise
each of the main emotions based on the main key-
word cues and the surrounding context. The CRF
is trained on the set of features shown in figure 2,
and implemented using CRF++1.
Feature Description
Words word, lemma, POS tag, phrase
chunk tag
Context 2 previous words and 2 following
words with lemma, POS tags and
chunk tags
Syntax Dependency relation label and
the lemma of the governer word
in focus
Semantics Is it negated?
Figure 2: Features used for CRF classifier
Three sentence-level classifiers were trained
for each emotion, those being Naive Bayes and
Maximum Entropy learners implemented by the
MALLET toolkit2, and a Support Vector Machine
model implemented using SVM light3 with the
linear kernel. In each case, the learners were
trained using a feature vector using the two fea-
ture vectors as shown in figure 3.
Feature vector Description
Words word lemmas
Semantics negation terms identified by
the negative term lexicon,
and cue terms from the emo-
tion term lexicon
Figure 3: Features used for sentence-level classifiers
A classifier was built for each of the main emo-
tions under study. For each of the six emotions,
four learners were trained to identify whether the
text contains an instance of that emotion. That is,
an instance of text receives 6 groups of results,
and each group contains 4 results obtained from
different classifiers estimating whether one par-
ticular emotion occurs. The combination func-
tion predicts the final sentiment(s) exhibited by
the sentence.
1http://crfpp.sourceforge.net/
2http://mallet.cs.umass.edu/
3http://svmlight.joachims.org/
99
3.3 Combination function
To combine the outputs of the heuristics, Yang et
al. (2012) use a voting model. Three different
combination methods are investigated:
Any If a sentence is identified as an emotion in-
stance by any one of the ML-based models, it
is considered a true instance of that emotion.
Majority If a sentence is identified as an emotion
instance by two or more of the ML-based
models, it is considered a true instance of
that emotion.
Combined If a sentence is identified as an emo-
tion instance by two or more of the ML-
based models or it is identified as an emo-
tion instance by the ML-based model with
the best precision for that emotion, it is con-
sidered a true instance of that emotion.
This combined measure reflects the intuition
that where an individual heuristic is reliable for a
particular phenomenon, then that heuristic?s vote
should be awarded a greater weight. The preci-
sion scores of the individual heuristics is shown
in table 1, where the heuristic with the best preci-
sion for that emotion is highlighted.
Emotion CRF NB ME SVM
Thankfulness 60.6 58.8 57.6 52.6
Love 76.2 68.5 77.6 76.9
Guilt 58.1 46.8 35.3 58.3
Hopelessness 73.5 63.3 68.7 74.5
Information 53.1 41.0 48.1 76.2
Instruction 76.3 63.6 70.9 75.9
Table 1: Precision scores (%) for individual heuristics
3.4 Results
Table 2 reports the system performance on 6 emo-
tions by both individual and combined heuristics.
In each case, the best performer among the four
individual heuristics is highlighted. As can be
seen from the table, the Any combinator and the
Combined combinators both outperform each of
the individual classifiers. This supports the hy-
pothesis that hybrid systems work better overall.
3.5 Additional comments
The overall performance improvement obtained
by combining the individual measures raises the
question of how the individual elements interact.
Table 3 shows the performance of the combined
systems on the different emotion classes. For
each emotion, the highest precision, recall and f-
measure is highlighted.
As we would have expected, the Any strategy
has the highest recall in all cases, while the Major-
ity strategy, with the highest bar for acceptance,
has the highest precision for most cases. The
Any and Combined measures appear to be broadly
comparable: for the measures we have used, it ap-
pears that the precision of the individual classi-
fiers is sufficiently high that the combination pro-
cess of improving recall does not impact exces-
sively on the overall precision.
A further point of interest is that table 2 demon-
strates that the Naive Bayes classifier often re-
turns the highest f-score of the individual classi-
fiers, even though it never has the best precision
(table 1). This supports our thesis that a success-
ful hybrid system can be built from multiple clas-
sifiers with high precision, rather than focussing
on single classifiers which have the best individ-
ual performance (the Combined strategy favours
the highest precision heuristic).
4 Nocuous ambiguity detection
It is a cornerstone of NLP that all text contains
a high number of potentially ambiguous words or
constructs. Only some of those will lead to misun-
derstandings, where two (or more) participants in
a text-mediated interchange will interpret the text
in different, and incompatible ways, without real-
ising that this is the case. This is defined as nocu-
ous ambiguity (Willis et al, 2008), in contrast to
innocuous ambiguity, where the text is interpreted
in the same way by different readers, even if that
text supports different possible analyses.
The phenomenon of nocuous ambiguity is par-
ticularly problematic in high stake situations. For
example, in software engineering, a failure to
share a common interpretation of requirements
stated in natural language may lead to incorrect
system implementation and the attendant risk of
system failure, or higher maintenance costs. The
systems described by Chantree et al (2006) and
Yang et al (2010a) aim not to resolve ambigu-
100
Individual heuristics Hybrid models
Emotion CRF NB ME SVM Any Majority Combined
Thankfulness 59.5 59.6 61.9 60.3 63.9 63.0 64.2
Love 63.7 69.3 66.5 61.5 72.0 70.3 71.0
Guilt 35.3 40.5 27.7 37.8 46.3 29.9 45.8
Hopelessness 63.2 64.1 59.9 57.0 67.3 65.4 67.3
Information 42.3 47.7 43.7 43.4 50.2 45.5 47.8
Instruction 65.7 65.7 63.4 58.8 72.1 65.4 72.0
Table 2: F-scores (%) for individual and combined heuristics (sentiment analysis)
Any Majority Combined
P R F P R F P R F
Thankfulness 52.6 81.6 63.9 60.6 65.7 63.0 55.0 77.1 64.2
Love 68.7 75.6 72.0 77.9 64.0 70.3 74.6 67.7 71.0
Guilt 46.6 46.2 46.3 50.0 21.4 29.9 50.5 41.9 45.8
Hopelessness 64.1 70.8 67.3 80.3 55.2 65.4 66.3 68.4 67.3
Information 40.9 64.9 50.2 49.9 41.8 45.5 45.2 50.7 47.8
Instruction 68.5 76.1 72.1 80.8 54.9 65.4 70.3 73.7 72.0
Table 3: Precision, recall and F-scores (%) for the combined systems (sentiment analysis)
ous text in requirements, but to identify where in-
stances of text might display nocuous ambiguity.
These systems demonstrate how, for hybrid
systems, the correct choice of combination func-
tion is crucial to how the individual heuristics
work together to optimise overall system perfor-
mance.
4.1 Nocuous Ambiguity: Coordination
Chantree et al (2006) focus on coordination at-
tachment ambiguity, which occurs when a mod-
ifier can attach to one or more conjuncts of a
coordinated phrase. For example, in sentence
(3), readers may divide over whether the modi-
fier short attaches to both books and papers (wide
scope), or only to books (narrow scope).
(3) I read some short books and papers.
In each case, the coordination involves a near
conjunct, (books in (3)), a far conjunct, (papers)
and a modifier (short). The modifier might also
be a PP, or an adverb in the case where a VP con-
tains the conjunction. In disambiguation, the task
would be to identify the correct scope of the mod-
ifier (i.e. which of two possible bracketings is the
correct one). For nocuous ambiguity detection,
the task is to identify to what extent people inter-
pret the text in the same way, and to flag the in-
stance as nocuous if they diverge relative to some
threshold.
4.1.1 The dataset
17 human judgements were collected for each
of 138 instances of sentences exhibiting coor-
dination ambiguity drawn from a collection of
software requirements documents. The majority
of cases (118 instances) were noun compounds,
with some adjective and some preposition modi-
fiers (36 and 18 instances respectively). Partici-
pants were asked to choose between wide scope
or narrow scope modifier attachment, or to indi-
cate that they experienced the example as ambigu-
ous. Each instance is assigned a certainty for wide
and narrow scope modification reflecting the dis-
tribution of judgements. For instance, if 12 judges
favoured wide scope for some instance, 3 judges
favoured narrow scope and 1 judge thought the
instance ambiguous, then the certainty for wide
scope is 71% (12/17), and the certainty for nar-
row scope is 18% (3/17).
A key concept in nocuous ambiguity is that of
an ambiguity threshold, ? . For some ? :
? if at least ? judges agree on the interpretation
101
of the text, then the ambiguity is innocuous,
? otherwise the ambiguity is nocuous.
So for ? = 70%, at least 70% of the judges must
agree on an interpretation. Clearly, the higher ?
is set, the more agreement is required, and the
greater the number of examples which will be
considered nocuous.
4.1.2 Selectional heuristics
A series of heuristics was developed, each cap-
turing information that would lead to a preference
for either wide or narrow scope modifier attach-
ment. Examples from Chantree et al (2006) pro-
pose seven heuristics, including the following:
Co-ordination Matching If the head words
of the two conjuncts are frequently co-
ordinated, this is taken to predict wide
modifier scope.
Distributional Similarity If the head words of
the two conjuncts have high distributional
similarity (Lee, 1999), this is taken to pre-
dict wide modifier scope.
Collocation Frequency If the head word of the
near conjunct has a higher collocation with
the modifier than the far conjunct, this is
taken to predict narrow modifier scope.
Morphology If the conjunct headwords have
similar morphological markers, this is taken
to predict wide modifier scope (Okumura
and Muraki, 1994).
As with the sentiment recognition heuristics
(section 3.2), each predicts one interpretation of
the sentence with high precision, but potentially
low recall. Recall of the system is improved by
combining the heuristics, as described in the next
section. Note that for the first three of these
heuristics, Chantree et al (2006) use the British
National Corpus4, accessed via the Sketch Engine
(Kilgarriff et al, 2004), although a domain spe-
cific corpus could potentially be constructed.
4.1.3 Combining the heuristics
Chantree et al (2006) combine the heuristics
using the logistic regression algorithms contained
in the WEKA machine learning package (Witten
and Frank, 2005). The regression algorithm was
4http://www.natcorp.ox.ac.uk/
trained against the training data so that the text
was interpreted as nocuous either if there was ev-
idence for both wide and narrow modifier scope
or if there was no evidence for either.
This system performed reasonably for mid-
range ambiguity thresholds (around 50% < ? <
80%; for high and low thresholds, naive base-
lines give very high accuracy). However, in sub-
sequent work, Yang et al (2010b) have demon-
strated that by combining the results in a similar
way, but using the LogitBoost algorithm, signifi-
cant improvements can be gained over the logis-
tic regression approach. Their paper suggests that
LogitBoost provides an improvement in accuracy
of up to 21% in the range of interest for ? over
that of logistic regression.
We believe that this improvement reflects that
LogitBoost handles interacting variables better
than logistic regression, which assumes a linear
relationship between individual variables. This
supports our hybridisation method, which as-
sumes that the individual heuristics can interact.
In these cases, the heuristics bring into play dif-
ferent types of information (some structural, some
distributional, some morphological) where each
relies on partial information and favours one par-
ticular outcome over another. It would be unusual
to find strong evidence of both wide and narrow
scope modifier attachment from a single heuristic
and the effect of one heuristic can modulate, or
enhance the effect of another. This is supported by
Chantree et al?s (2006) observation that although
some of the proposed heuristics (such as the mor-
phology heuristic) perform poorly on their own,
their inclusion in the regression model does im-
prove the overall performance of the system
To conclude, comparing the results of Chantree
et al (2006) and Yang et al (2010b) demonstrates
that the technique of combining individual, high
precision heuristics is a successful one. However,
the combination function needs careful consider-
ation, and can have as large an effect on the final
results as the choice of the heuristics themselves.
4.2 Nocuous Ambiguity: Anaphora
As example (1) demonstrates, nocuous ambigu-
ity can occur where there are multiple possible
antecedents for an anaphor. Yang et al (2010a)
have addressed the task of nocuous ambiguity de-
tection for anaphora in requirements documents,
in sentences such as (4), where the pronoun it has
102
three potential antecedents (italicised).
(4) The procedure shall convert the 24 bit image
to an 8 bit image, then display it in a dynamic
window.
As with the coordination task, the aim is to
identify nocuous ambiguity, rather than attempt to
disambiguate the sentence.
4.2.1 The dataset
The data set used for the anaphora task con-
sisted of 200 sentences collected from require-
ments documents which contained a third person
pronoun and multiple possible antecedents. Each
instance was judged by at least 13 people.
The concept of ambiguity threshold, ? , remains
central to nocuous ambiguity for anaphora. The
definition remains the same as in section 4.1.1, so
that an anaphor displays innocuous ambiguity if
there is an antecedent that at least ? judges agree
on, and nocuous ambiguity otherwise. So if, say,
75% of the judges considered an 8 bit image to
be the correct antecedent in (4), then the sentence
would display nocuous ambiguity at ? = 80%,
but innocuous ambiguity at ? = 70%.
For innocuous cases, the potential antecedent
NP with certainty of at least ? is tagged as Y,
and all other NPs are tagged as N. For nocuous
cases, potential antecedents with ? greater than 0
are tagged as Q (questionable), or are tagged N
otherwise (? = 0, ie. unselected).
4.2.2 Selectional Heuristics
The approach to this task uses only one selec-
tion function (Naive Bayes), but uses the output
to support two different voting strategies. Twelve
heuristics (described fully in Yang et al (2010a))
fall broadly into three types which signal the like-
lihood that the NP is a possible antecedent:
linguistic such as whether the potential an-
tecedent is a definite or indefinite NP
contextual such as the potential antecedent?s re-
cency, and
statistical such as collocation frequencies.
To treat a sentence, the classifier is applied to
each of the potential antecedents and assigns a
pair of values: the first is the predicted class of
the antecedent (Y, N or Q), and the second is the
associated probability of that classification.
Given a list of class assignments to potential an-
tecedents with associated probabilities, a weak
positive threshold, WY , and a weak negative
threshold, WN :
if the list of potential antecedents contains:
one Y, no Q, one or more N
or
no Y, one Q, one or more N but no weak
negatives
or
one strong positive Y , any number of Q or N
then
the ambiguity is INNOCUOUS
else
the ambiguity is NOCUOUS
where a classification Y is strong positive if its
associated probability is greater than WY , and a
classification N is weak negative if its associated
probability is smaller than WN .
Figure 4: Combination function for nocuous anaphora
detection with weak thresholds
4.2.3 The combination function
As suggested previously, the choice of com-
bination function can strongly affect the system
performance, even on the same set of selectional
heuristics. Yang et al (2010a) demonstrate two
different combination functions which exploit the
selectional heuristics in different ways. Both
combination functions use a voting strategy.
The first voting strategy states that a sentence
exhibits innocuous ambiguity if either:
? there is a single antecedent labelled Y, and all
others are labelled N, or
? there is a single antecedent labelled Q, and
all others are labelled N.
The second strategy is more sophisticated, and
depends on the use of weak thresholds: intu-
itively, the aim is to classify the text as innocu-
ous if is (exactly) one clearly preferred antecedent
among the alternatives. The combination function
is shown in figure 4. The second clause states
that a single potential antecedent labelled Q can
be enough to suggest innocuous ambiguity if all
the alternatives are N with a high probability.
103
Model without Model with
weak thresholds weak thresholds
? P R F P R F
0.50 27.2 55.0 45.7 24.1 95.0 59.7
0.60 33.9 67.5 56.3 30.9 97.5 68.1
0.70 45.1 76.2 66.9 43.9 98.4 78.8
0.80 58.0 85.0 77.7 56.1 97.9 85.5
0.90 69.1 88.6 83.9 67.4 98.4 90.1
1.0 82.2 95.0 92.1 82.0 99.4 95.3
Table 4: Precision, Recall and f-measure (%) for the
two combination functions (anaphora)
Task Selectional
heuristics
Combination
functions
Sentiment CRF Voting
analysis NB - any
SVM - majority
ME - combined
Nocuous 3 distributional logistic
ambiguity metrics regression
(coordin-
ation) 4 others LogitBoost
Nocuous NB Voting
ambiguity
(anaphora) Voting
(+ threshold)
Table 5: Hybridisation approaches used
The performance of the two voting strategies
is shown in table 4. It is clear that the improved
overall performance of the strategy with weak
thresholds is due to the improved recall when the
functions are combined; the precision is compa-
rable in both cases. Again, this shows the desired
combinatorial behaviour; a combination of high
precision heuristics can yield good overall results.
5 Conclusion
The hybridised systems we have considered are
summarised in table 5. This examination suggests
that hybridisation can be a powerful technique for
classifying linguistic phenomena. However, there
is currently little guidance on principles regarding
hybrid system design. The studies here show that
there is room for more systematic study of the de-
sign principles underlying hybridisation, and for
investigating systematic methodologies.
This small scale study suggests several prin-
ciples. First, the sentiment analysis study has
shown that a set of heuristics and a suitable com-
bination function can outperform the best individ-
ually performing heuristic or technique. In partic-
ular, our results suggest that hybrid systems of the
kind described here are most valuable when there
is significant interaction between the various lin-
guistic phenomena present in the text. This occurs
both with nocuous ambiguity (where competition
between the different interpretations creates dis-
agreement overall), and with sentiment analysis
(where a sentence can convey multiple emotions).
As a result, hybridisation is particularly power-
ful where there are multiple competing factors, or
where it is unclear whether there is sufficient evi-
dence for a particular classification.
Second, successful hybrid systems can be built
using multiple heuristics, even if each of the
heuristics has low recall on its own. Our case
studies show that with the correct choice of hy-
bridisation functions, high precision heuristics
can be combined to give good overall recall while
maintaining acceptable overall precision.
Finally, the mode of combination matters. The
voting system is successful in the sentiment anal-
ysis task, where different outcomes are not exclu-
sive (the presence of guilt does not preclude the
presence of love). On the other hand, the log-
itBoost combinator is appropriate when the dif-
ferent interpretations are exclusive (narrow modi-
fier scope does preclude wide scope). Here, logit-
Boost can be interpreted as conveying the degree
of uncertainty among the alternatives. The coor-
dination ambiguity case demonstrates that the in-
dividual heuristics do not need to be independent,
but if the method of combining them assumes in-
dependence, the benefits of hybridisation will be
lost (logistic regression compared to LogitBoost).
This analysis has highlighted the interplay be-
tween task, heuristics and combinator. Currently,
the nature of this interplay is not well understood,
and we believe that there is scope for investigating
the broader range of hybrid systems that might be
applied to different tasks.
Acknowledgments
The authors would like to thank the UK Engi-
neering and Physical Sciences Research Coun-
cil who funded this work through the MaTREx
project (EP/F068859/1), and the anonymous re-
viewers for helpful comments and suggestions.
104
References
Francis Chantree, Bashar Nuseibeh, Anne De Roeck,
and Alistair Willis. 2006. Identifying nocuous
ambiguities in natural language requirements. In
Proceedings of 14th IEEE International Require-
ments Engineering conference (RE?06), Minneapo-
lis/St Paul, Minnesota, USA, September.
Eugene Charniak and Micha Elsner. 2009. EM works
for pronoun anaphora resolution. In Proceedings of
the 12th Conference of the European Chapter of the
Association for Computational Linguistics (EACL
?09), pages 148?156.
Anne De Roeck. 2007. The role of data in NLP:
The case for dataset profiling. In Nicolas Nicolov,
Ruslan Mitkov, and Galia Angelova, editors, Re-
cent Advances in Natural Language Processing IV,
volume 292 of Current Issues in Linguistic Theory,
pages 259?266. John Benjamin Publishing Com-
pany, Amsterdam.
Aria Haghighi and Dan Klein. 2009. Simple coref-
erence resolution with rich syntactic and semantic
features. In Proceedings of the 2009 Conference on
Empirical Methods in Natural Language Process-
ing, pages 1152?1161, Singapore, August.
Lifeng Jia, Clement Yu, and Weiyi Meng. 2009.
The effect of negation on sentiment analysis and
retrieval effectiveness. In The 18th ACM Confer-
ence on Information and Knowledge Management
(CIKM?09), Hong Kong, China, November.
Adam Kilgarriff, Pavel Rychly, Pavel Smrz, and David
Tugwell. 2004. The sketch engine. Technical Re-
port ITRI-04-08, University of Brighton.
John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data. In Proceedings of the International
Conference on Machine Learning (ICML-2001),
pages 282?289.
Lillian Lee. 1999. Measures of distributional simi-
larity. In Proceedings of the 37th Annual Meeting
of the Association for Computational Linguistics,
pages 25?32, College Park, Maryland, USA, June.
Association for Computational Linguistics.
Akitoshi Okumura and Kazunori Muraki. 1994. Sym-
metric pattern matching analysis for english coor-
dinate structures. In Proceedings of the 4th Con-
ference on Applied Natural Language Processing,
pages 41?46.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up? Sentiment classification using
machine learning techniques. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 79?86, Philadelphia, July.
John P. Pestian, Pawel Matykiewicz, Michelle Linn-
Gust, Brett South, Ozlem Uzuner, Jan Wiebe,
K. Bretonnel Cohen, John Hurdle, and Christopher
Brew. 2012. Sentiment analysis of suicide notes:
A shared task. Biomedical Informatics Insights,
5(Suppl 1):3?16.
Mike Thelwall, Kevan Buckley, Georgios Paltoglou,
Di Cai, and Arvid Kappas. 2010. Sentiment in
short strength detection informal text. Journal of
the American Society for Information Science &
Technology, 61(12):2544?2558, December.
Yannick Versley, Alessandro Moschitti, Massimo Poe-
sio, and Xiaofeng Yang. 2008. Coreference sys-
tems based on kernels methods. In Proceedings
of the 22nd International Conference on Compu-
tational Linguistics (Coling 2008), pages 961?968,
Manchester, August.
Alistair Willis, Francis Chantree, and Anne DeRoeck.
2008. Automatic identification of nocuous ambigu-
ity. Research on Language and Computation, 6(3-
4):355?374, December.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2009. Recognizing contextual polarity: An explo-
ration of features for phrase-level sentiment analy-
sis. Computational Linguistics, 35(3):399?433.
Ian H. Witten and Eibe Frank. 2005. Data mining:
Practical machine learning tools and techniques.
Morgan Kaufmann, 2nd edition.
Xiaofeng Yang, Jian Su, and Chew Lim Tan. 2006.
Kernel-based pronoun resolution with structured
syntactic knowledge. In Proceedings of the 21st In-
ternational Conference on Computational Linguis-
tics and 44th Annual Meeting of the ACL, pages 41?
48, Sydney, July.
Hui Yang, Anne De Roeck, Vincenzo Gervasi, Al-
istair Willis, and Bashar Nuseibeh. 2010a. Ex-
tending nocuous ambiguity analysis for anaphora
in natural language requirements. In 18th Interna-
tional IEEE Requirements Engineering Conference
(RE?10), Sydney, Australia, Oct.
Hui Yang, Anne De Roeck, Alistair Willis, and Bashar
Nuseibeh. 2010b. A methodology for automatic
identification of nocuous ambiguity. In 23rd Inter-
national Conference on Computational Linguistics
(COLING 2010), Beijing, China.
Hui Yang, Alistair Willis, Anne De Roeck, and Bashar
Nuseibeh. 2012. A hybrid model for automatic
emotion recognition in suicide notes. Biomedical
Informatics Insights, 5(Suppl. 1):17?30, January.
105
