Coling 2010: Poster Volume, pages 99?107,
Beijing, August 2010
Toward Qualitative Evaluation of Textual Entailment Systems
Elena Cabrio
FBK-Irst, University of Trento
cabrio@fbk.eu
Bernardo Magnini
FBK-Irst
magnini@fbk.eu
Abstract
This paper presents a methodology for a
quantitative and qualitative evaluation of
Textual Entailment systems. We take ad-
vantage of the decomposition of Text Hy-
pothesis pairs into monothematic pairs,
i.e. pairs where only one linguistic phe-
nomenon at a time is responsible for en-
tailment judgment, and propose to run TE
systems over such datasets. We show
that several behaviours of a system can
be explained in terms of the correlation
between the accuracy on monothematic
pairs and the accuracy on the correspond-
ing original pairs.
1 Introduction
Since 2005, Recognizing Textual Entailment
(RTE) has been proposed as a task whose aim is
to capture major semantic inference needs across
applications in Computational Linguistics (Dagan
et al, 2009). Systems are asked to automatically
judge whether the meaning of a portion of text, re-
ferred as Text (T), entails the meaning of another
text, referred as Hypothesis (H). This evaluation
provides useful cues for researchers and develop-
ers aiming at the integration of TE components in
larger applications (see, for instance, the use of a
TE engine in the QALL-ME project system1, the
use in relation extraction (Romano et al, 2006),
and in reading comprehension systems (Nielsen
et al, 2009)).
Although the RTE evaluations showed pro-
gresses in TE technologies, we think that there is
1http://qallme.fbk.eu/
still large room for improving qualitative analysis
of both the RTE datasets and the system results.
In particular, we intend to focus this paper on the
following aspects:
1. There is relatively poor analysis of the lin-
guistic phenomena that are relevant for the
RTE datasets, and very little is known about
the distribution of such phenomena, and
about the ability of participating systems to
correctly detect and judge them in T,H pairs.
Experiments like the ablation tests attempted
in the last RTE-5 campaign on lexical and
lexical-syntactic resources go in this direc-
tion, although the degree of comprehension
is still far from being optimal.
2. We are interested in the correlations among
the capability of a system to address single
linguistic phenomena in a pair and the ability
to correctly judge the pair itself. Despite the
strong intuition about such correlation (i.e.
the more the phenomena for which a system
is trained, the better the final judgment), no
empirical evidences support it.
3. Although the ability to detect and manage
single phenomena seems to be a crucial fea-
ture of high performing systems, very little is
known about how systems manage to com-
bine such results in a global score for a pair.
The mechanism underlying such composi-
tion may shed light on meaning composition
related to TE tasks.
4. Finally, we are interested in the relation be-
tween the above mentioned items over the
different kinds of pairs represented in RTE
99
datasets, specifically entailment, contradic-
tion and unknown pairs. In this case the in-
tuition is that some phenomena are more rel-
evant for a certain judgment rather than for
another.
To address the issues above, we propose an
evaluation methodology aiming at providing a
number of quantitative and qualitative indicators
about a TE system. The method is based on
the decomposition of T,H pairs into monothematic
pairs, each representing one single linguistic phe-
nomenon relevant for entailment judgment. Eval-
uation is carried out both on the original T,H pair
and on the monothematic pairs originated from it.
We define a correlation index between the accu-
racy of the system on the original T,H pairs and
the accuracy on the corresponding monothematic
pairs. We investigate the use of such correlations
on different subsets of the evaluation dataset (i.e.
positive vs negative pairs) and we try to induce
regular patterns of evaluation.
The method we propose has been tested on a
sample of 60 pairs, each decomposed in the corre-
sponding monothematic pairs, and using two sys-
tems that obtained similar performances in RTE-
5. We show that the main features and differences
of these systems come to light when evaluated us-
ing qualitative criteria. Futhermore, we compare
such systems with two different baseline systems,
the first one performing Word Overlap, while the
second one is an ideal system that knows a priori
the probability of a linguistic phenomenon to be
associated with a certain entailment judgement.
The paper is structured as follows. Sec-
tion 2 explains the procedure for the creation of
monothematic pairs starting from RTE pairs. Sec-
tion 3 presents the evaluation methodology we
propose, while Section 4 describes our pilot study.
Section 5 concludes the paper and proposes future
developments.
2 Decomposing RTE pairs
Our proposal on qualitative evaluation takes ad-
vantage of previous work on specialized entail-
ment engines and monothematic datasets. A
monothematic pair is defined (Magnini and
Cabrio, 2009) as a T,H pair in which a certain
phenomenon relevant to the entailment relation is
highlighted and isolated. The main idea is to cre-
ate the monothematic pairs basing on the phenom-
ena that are actually present in the original RTE
pairs, so that the actual distribution of the linguis-
tic phenomena involved in the entailment relation
emerges.
For the decomposition procedure, we refer to
the methodology described in (Bentivogli et al,
2010), consisting of a number of steps carried out
manually. The starting point is a [T,H] pair taken
from one of the RTE data sets, that should be
decomposed in a number of monothematic pairs
[T,Hi], where T is the original Text and Hi are
the Hypotheses created for each linguistic phe-
nomenon relevant for judging the entailment re-
lation in [T,H]. In details, the procedure for the
creation of monothematic pairs is composed of the
following steps:
1. Individuate the phenomena contributing to
the entailment decision in [T,H].
2. For each linguistic phenomenon i:
(a) Detect a general entailment rule ri for
i, and instantiate it using the part of T
expressing i as the left hand side (LHS)
of the rule, and information from H on i
as the right side (RHS).
(b) substitute the portion of T that matches
the LHS of ri with the RHS of ri.
(c) consider the result of the previous step
as Hi, and compose the monothematic
pair [T,Hi]. Mark the pair with phe-
nomenon i.
3. Assign an entailment judgment to each
monothematic pair.
Relevant linguistic phenomena are grouped us-
ing both fine-grained categories and broader cate-
gories, defined referring to widely accepted clas-
sifications in the literature (e.g. (Garoufi, 2007))
and to the inference types typically addressed in
RTE systems: lexical, syntactic, lexical-syntactic,
discourse and reasoning. Each macro category in-
cludes fine-grained phenomena (Table 2 lists the
phenomena detected in RTE-5 datasets).
100
Text snippet (pair 125) Phenomena Judg.
T Mexico?s new president, Felipe Calderon, seems to be doing
all the right things in cracking down on Mexico?s drug traffickers. [...]
H Felipe Calderon is the outgoing President of Mexico. lexical:semantic-opposition C
syntactic:argument-realization, syntactic:apposition
H1 Mexico?s outgoing president, Felipe Calderon, seems to be doing all lexical:semantic-opposition C
all the right things in cracking down on Mexico?s drug traffickers. [...]
H2 The new president of Mexico, Felipe Calderon, seems to be doing syntactic:argument-realization E
all the right things in cracking down on Mexico?s drug traffickers. . [...]
H3 Felipe Calderon is Mexico?s new president. syntactic:apposition E
Table 1: Application of the decomposition methodology to an original RTE pair
Table 1 shows an example of the decompo-
sition of a RTE pair (marked as contradiction)
into monothematic pairs. At step 1 of the
methodology both the phenomena that preserve
the entailment and those that break the entailment
rules causing a contradiction in the pair are
detected, i.e. argument realization, apposition
and semantic opposition (column phenomena in
the table). While the monothematic pairs created
basing on the first two phenomena preserve the
entailment, the semantic opposition generates a
contradiction (column judgment). As an example,
let?s apply step by step the procedure to the
phenomenon of semantic opposition. At step 2a
of the methodology the general rule:
Pattern: x? / ? y
Constraint: semantic opposition(y,x)
is instantiated (new? / ?outgoing), and at step
2b the substitution in T is carried out (Mexico?s
outgoing president, Felipe Calderon [...]). At
step 2c a negative monothematic pair T,H1 is
composed (column text snippet in the table) and
marked as semantic opposition (macro-category
lexical), and the pair is judged as contradiction.
3 Evaluation methodology
Aim of the evaluation methodology we propose is
to provide quantitative and qualitative indicators
about the behaviours of actual TE systems.
3.1 General Method
The basic assumption of the evaluation methodol-
ogy is that the more a system is able to correctly
solve the linguistic phenomena underlying the en-
tailment relation separately, the more the system
should be able to correctly judge more complex
pairs, in which different phenomena are present
and interact in a complex way. Such assumption is
motivated by the notion of meaning composition-
ality, according to which the meaning of a com-
plex expression e in a language L is determined
by the structure of e in L and the meaning of the
constituents of e in L (Frege, 1892). In a parallel
way, we assume that it is possible to understand
the entailment relation of a T,H pair (i.e. to cor-
rectly judge the entailment/contradiction relation)
only if all the phenomena contributing to such re-
lation are solved.
According to such assumption, we expect that
the higher the accuracy of a system on the
monothematic pairs and the compositional strat-
egy, the better its performances on the original
RTE pairs. Furthermore, the precision a system
gains on single phenomena should be maintained
over the general dataset, thanks to suitable mech-
anisms of meaning combination.
Given a dataset composed of original RTE pairs
[T,H], a dataset composed of all the monothe-
matic pairs derived from it [T,H]mono, and a TE
system S, the evaluation methodology we propose
consists of the following steps:
1. Run S both on [T,H] and on [T,H]mono, to
obtain the accuracies of S both on the RTE
original and on monothematic pairs;
2. Extract data concerning the behaviour of S on
each phenomenon or on categories of phe-
nomena, and calculate separate accuracies.
This way it is possible to evaluate how much
a system is able to correctly deal with single
or with categories of phenomena;
3. Calculate the correlation between the ability
of the system to correctly judge the monothe-
matic pairs of [T,H]mono with respect to the
101
ability to correctly judge the original ones
in [T,H]. Such correlation is expressed
through a Correlation Index (CI), as defined
in Section 3.2;
4. In order to check if the same CI is main-
tained over both entailment and contradiction
pairs (i.e. to verify if the system has peculiar
strategies to correctly assign both judgments,
and if the high similarity of monothematic
pairs does not bias its behaviour), we calcu-
late a Deviation Index (DI) as the difference
between the CIs on entailment and on con-
tradiction pairs, as explained in more details
in Section 3.3.
3.2 Correlation Index (CI)
As introduced before, we assume that the ac-
curacy obtained on [T,H]mono should positively
correlate with the accuracy obtained on [T,H].
We define aCorrelation Index as the ratio between
the accuracy of the system on the original RTE
dataset and the accuracy obtained on the monothe-
matic dataset, as follows:
CI = acc[T,H]acc[T,H]mono
(1)
We expect the correlation index of an optimal
ideal system (or the human goldstandard) to be
equal to 1, i.e. 100% accuracy on the monothe-
matic dataset should correspond to 100% accu-
racy on the original RTE dataset. For this reason,
we consider CI = 1 as the ideal correlation, and
we calculate the difference between such ideal CI
and the correlation obtained for a system S.
Given such expectations, CIS can assume three
different configurations with respect to the upper-
bound (i.e. the ideal correlation):
? CIS ?= 1 (ideal correlation): When CIS ap-
proaches to 1, the system shows high corre-
lation with the ideal behaviour assumed by
the compositionality principle. As a conse-
quence, we can predict that improving sin-
gle modules will correspondingly affect the
global performance.
? CIS < 1 (missing correlation): The system
is not able to exploit the ability in solving sin-
gle phenomena to correctly judge the origi-
nal RTE pairs. This may be due to the fact
that the system does not adopt suitable com-
bination mechanisms and loses the potential-
ity shown by its performances on monothe-
matic pairs.
? CIS > 1 (over correlation): The system does
not exploit the ability to solve single linguis-
tic components to solve the whole pairs, and
has different mechanisms to evaluate the en-
tailment. Probably, such a system is not in-
tended to be modularized.
Beside this ?global? correlation index calcu-
lated on the complete RTE data and on all the
monothematic pairs created from it, the CI can
also be calculated i) on categories of phenomena,
to verify which phenomena a system is more able
to solve both when isolated and when interacting
with other phenomena, e.g. :
CIlex =
acc[T,H]lex
acc[T,H]mono?lex
(2)
including in [T,H]lex all the pairs in which at
least one lexical phenomenon is present and con-
tribute to the entailment/contradiction judgments,
and in [T,H]mono?lex all the monothematic pairs
in which a lexical phenomenon is isolated; or ii)
on kind of judgment (entailment, contradiction,
unknown), allowing deeper qualitative analysis of
the performances of a system.
3.3 Deviation Index (DI)
We explained that a low CI (i.e. < 1) of a system
reflects the inability to correctly exploit the poten-
tially promising results obtained on monothematic
pairs to correctly judge RTE pairs. Actually, it
could also be the case that the system does not
perform a correct combination because even the
results got on the monothematic pairs were due to
chance (e.g. a word overlap system performs well
on monothematic pairs because of the high sim-
ilarity between T and H, and not because it has
linguistic strategies).
We detect such cases by decomposing the eval-
uation datasets, separating positive (i.e. entail-
ment) from negative (i.e. contradiction, unknown)
examples both in [T,H] and in [T,H]mono, and
102
independently run S on the new datasets. Then,
we have more fine grained evaluation patterns
through which we can analyze the system be-
haviour.
In the ideal case, we expect to have good cor-
relation between the accuracy obtained on the
monothematic pairs and the accuracy obtained on
the original ones (0 < CIpos ? 1 and 0 <
CIneg ? 1). On the contrary, we expect that sys-
tems either without a clear composition strategy or
without strong components on specific linguistic
phenomena (e.g. a word overlap system), would
show a significant difference of correlation on the
different datasets. More specifically, situations of
inverse correlation on the entailment and contra-
diction pairs (e.g. over correlation on contradic-
tion pairs and missing correlation on entailment
pairs) may reveal that the system itself is affected
by the nature of the dataset (i.e. its behaviour
is biased by the high similarity of [T,H]mono),
and weaknesses in the ability of solving phenom-
ena that more frequently contribute to the assign-
ment of a contradiction (or an entailment) judg-
ment come to light.
We formalize such intuition defining a Devia-
tion Index (DI) as the difference between the cor-
relation indexes, respectively, on entailment and
contradiction/unknown pairs, as follows:
|DI| = CIpos ? CIneg (3)
For instance, an high Deviation Index due to
a missing correlation on positive entailment pairs
and an over correlation for negative pairs, is in-
terpreted as an evidence that the system has low
accuracy on [T,H]mono - T and H are very sim-
ilar and the system has no strategies to under-
stand that the phenomenon that is present has to
be judged as contradictory -, and a higher accu-
racy on [T,H], probably due to chance. In the
ideal case DIS ?= 0, since we assumed the ideal
CIs on both positive and negative examples to be
as close as possible to 1 (see Section 3.2).
4 Experiments and discussion
This Section describes the experimental setup of
our pilot study, carried out using two systems that
took part in RTE-5 i.e EDITS and VENSES. We
show the results obtained and the qualitative anal-
ysis performed basing on the proposed evaluation
methodology. Their respective CIs and DIs are
compared with two baselines: a word overlap sys-
tem, and a system biased by the knowledge of
the probability that a linguistic phenomenon con-
tributes to the assignment of a certain entailment
judgment.
4.1 Dataset
The evaluation method has been tested on a
dataset composed of 60 pairs from RTE-5 test set
([T,H]RTE5?sample, composed of 30 entailment,
and 30 contradiction randomly extracted exam-
ples), and a dataset composed of all the monothe-
matic pairs derived by the first one following
the procedure described in Section 2. The sec-
ond dataset [T,H]RTE5?mono is composed of 167
pairs (135 entailment, 32 contradiction examples,
considering 35 different linguistic phenomena)2.
On average, 2.78 monothematic pairs have been
created from the original pairs. In this pilot study
we decided to limit our analysis to entailment and
contradiction pairs since, as observed in (Ben-
tivogli et al, 2010), in most of the unknown pairs
no linguistic phenomena relating T to H could be
detected.
4.2 TE systems
EDITS The EDITS system (Edit Distance Tex-
tual Entailment Suite)3 (Negri et al, 2009) as-
sumes that the distance between T and H is a
characteristic that separates the positive pairs, for
which entailment holds, from the negative pairs,
for which entailment does not hold (two way
task). It is based on edit distance algorithms, and
computes the [T,H] distance as the overall cost of
the edit operations (i.e. insertion, deletion and
substitution) required to transform T into H. For
our experiments we applied the model that pro-
duced EDITS best run at RTE-5 (acc. on test set:
60.2%). The main features are: Tree Edit Dis-
tance algorithm on the parsed trees of T and H,
Wikipedia lexical entailment rules, and PSO opti-
mized operation costs (Mehdad et al, 2009).
2http://hlt.fbk.eu/en/Technology/TE- Specialized Data
3Available as open source at http://edits.fbk.eu/
103
VENSES The other system used in our ex-
periments is VENSES4 (Delmonte et al, 2009),
that obtained performances similar to EDITS at
RTE-5 (acc. on test set: 61.5%). It applies a
linguistically-based approach for semantic infer-
ence, and is composed of two main components:
i) a grammatically-driven subsystem validates the
well-formedness of the predicate-argument struc-
ture and works on the output of a deep parser pro-
ducing augmented head-dependency structures;
and ii) a subsystem detects allowed logical and
lexical inferences basing on different kind of
structural transformations intended to produce a
semantically valid meaning correspondence. Also
in this case, we applied the best configuration of
the system used in RTE-5.
Baseline system 1: Word Overlap algorithm
The first baseline applies a Word Overlap (WO)
algorithm on tokenized text. The threshold to sep-
arate positive from negative pairs has been learnt
on the whole RTE-5 training dataset.
Baseline system 2: Linguistic biased system
The second baseline is produced by a more so-
phisticated but biased system. It exploits the
probability of linguistic phenomena to contribute
more to the assignment of a certain judgment than
to another. Such probabilities are learnt on the
[T,H]RTE5?mono goldstandard: given the list of
the phenomena with their frequency in monothe-
matic positive and negative pairs (columns 1,2,3
of Table 2), we calculate the probability P of phe-
nomenon i to appear in a positive (or in a negative)
pair as follows:
P (i|[T,H]positive) = #(i|[T,H]RTE5?positive?mono)#(i|[T,H]RTE5?mono)
(4)
For instance, if the phenomenon apposition ap-
pears in 11 monothematic positive pairs and in 6
negative pairs, it has a probability of 64.7% to ap-
pear in positive examples and 35.3% to appear in
negative ones. Such knowledge is then stored in
the system, and is used in the classification phase,
assigning the most probable judgment associated
to a certain phenomenon.
4http://project.cgm.unive.it/venses en.html
When applied to [T,H]RTE5?sample, this sys-
tem uses a simple combination strategy: if phe-
nomena associated with different judgments are
present in a pair, and one phenomenon is associ-
ated with a contradiction judgment with a proba-
bility > 50%, the pair is marked as contradiction,
otherwise it is marked as entailment.
4.3 Results
Following the methodology described in Sec-
tion 3, at step 1 we run EDITS and VENSES
on [T,H]RTE5?sample, and on [T,H]RTE5?mono
(Table 3 reports the accuracies obtained).
At step 2, we calculate the accuracy of ED-
ITS and VENSES on each single linguistic phe-
nomenon, and on categories of phenomena. Ta-
ble 2 shows the distribution of the phenomena on
the dataset, reflected in the number of positive and
negative monothematic pairs created for each phe-
nomenon. As can be seen, some phenomena ap-
pear more frequently than others (e.g. corefer-
ence, general inference). Furthermore, some lin-
guistic phenomena allow only the creation of pos-
itive or negative examples, while others can con-
tribute to the assignment of both judgments. Due
to the small datasets we used, some phenomena
appear rarely; the accuracy on them cannot be
considered completely reliable.
Nevertheless, from these data the main features
of the systems can be identified. For instance,
EDITS obtains the highest accuracy on positive
monothematic pairs, while it seems it has no pe-
culiar strategies to deal with phenomena caus-
ing contradiction (e.g. semantic opposition, and
quantity mismatching). On the contrary, VENSES
shows an opposite behaviour, obtaining the best
results on the negative cases.
At step 3 of the proposed evaluation methodol-
ogy, we calculate the correlation index between
the ability of the system to correctly judge the
monothematic pairs of [T,H]RTE5?mono with re-
spect to the ability to correctly judge the original
ones in [T,H]RTE5?sample.
Table 3 compares EDITS and VENSES CI with
the two baseline systems described before. As can
be noticed, even if EDITS CI outperforms theWO
system, they show a similar behaviour (high ac-
curacy on monothematic pairs, and much lower
104
phenomena # [T,H] EDITS VENSES
RTE5?mono % acc. % acc.
pos. neg. pos. neg. pos. neg.
lex:identity 1 3 100 0 100 33.3
lex:format 2 - 100 - 100 -
lex:acronymy 3 - 100 - 33.3 -
lex:demonymy 1 - 100 - 100 -
lex:synonymy 11 - 90.9 - 90.9 -
lex:semantic-opp. - 3 - 0 - 100
lex:hypernymy 3 - 100 - 66.6 -
lex:geo-knowledge 1 - 100 - 100 -
TOT lexical 22 6 95.4 0 77.2 66.6
lexsynt:transp-head 2 - 100 - 50 -
lexsynt:verb-nom. 8 - 87.5 - 25 -
lexsynt:causative 1 - 100 - 100 -
lexsynt:paraphrase 3 - 100 - 66.6 -
TOT lex-syntactic 14 - 92.8 - 42.8 -
synt:negation - 1 - 0 - 0
synt:modifier 3 1 100 0 33.3 100
synt:arg-realization 5 - 100 - 40 -
synt:apposition 11 6 100 33.3 54.5 83.3
synt:list 1 - 100 - 100 -
synt:coordination 3 - 100 - 33.3 -
synt:actpass-altern. 4 2 100 0 25 50
TOT syntactic 28 9 96.4 22.2 42.8 77.7
disc:coreference 20 - 95 - 50 -
disc:apposition 3 - 100 - 0 -
disc:anaphora-zero 5 - 80 - 20 -
disc:ellipsis 4 - 100 - 25 -
disc:statements 1 - 100 - 0 -
TOT discourse 33 - 93.9 - 36.3 -
reas:apposition 2 1 100 0 50 100
reas:modifier 3 - 66.6 - 100 -
reas:genitive 1 - 100 - 100 -
reas:relative-clause 1 - 100 - 0 -
reas:elliptic-expr. 1 - 100 - 0 -
reas:meronymy 1 1 100 0 100 0
reas:metonymy 3 - 100 - 33.3 -
reas:representat. 1 - 100 - 0 -
reas:quantity - 5 - 0 - 80
reas:spatial 1 - 100 - 0 -
reas:gen-inference 24 10 87.5 50 37.5 90
TOT reasoning 38 17 89.4 35.2 42.1 82.3
TOT (all phenom) 135 32 93.3 25 45.9 81.2
Table 2: Systems? accuracy on phenomena
on the RTE sample). According to our defini-
tion, their CIs (0 < CI < 1) show a good ability
of the systems to deal with linguistic phenomena
when isolated, but a scarce ability in combining
them to assign the final judgment. EDITS CI is
not far from the CI of the linguistic biased base-
line system, even if we were expecting a higher
CI for the latter system. The reason is that beside
the linguistic phenomena that allow only the cre-
ation of negative monothematic pairs, all the phe-
nomena that allow both judgments have a higher
probability to contribute to the creation of positive
monothematic pairs.
Comparing the CI of the four analyzed systems
with the ideal correlation (CIS ?= 1, see Section
3.2), VENSES is the closest one (? = 0.15), even
if it shows a light over correlation (probably due
to the nature of the dataset). The second closest
acc. % acc. % CI
RTE5?sample RTE5?mono
EDITS 58.3 80.8 0.72
VENSES 60 52.6 1.15
Word Overlap 38.3 77.24 0.49
ling baseline 68.3 86.8 0.79
Table 3: Evaluation on RTE pairs and on
monothematic pairs
categories of linguistic phenomena
RTE5 data lex. lex-synt. synt. disc. reas.
EDITS sample 47.8 64.3 51.7 75 62.5
mono 75 92.8 78.3 93.9 72.7
CI 0.63 0.69 0.66 0.79 0. 85
VENSES sample 47.2 42.8 62 46.4 67.5
mono 75 42.8 51.3 33 54.5
CI 0.62 1 1.2 1.4 1.23
WO sample 36.3 57.1 34.4 50 35
baseline mono 78.5 71.4 72.9 96.9 69
CI 0.46 0.79 0.47 0.51 0.5
ling- sample 82.6 92.8 58.6 82.1 70
biased mono 96.4 100 75.6 96.9 80
baseline CI 0.85 0.92 0.77 0.84 0.87
Table 4: Evaluation on categories of phenomena
one is the linguistic biased system (? = 0.21),
showing that the knowledge of the most probable
judgment assigned to a certain phenomenon can
be a useful information.
Table 4 reports an evaluation of the four sys-
tems on categories of linguistic phenomena.
To check if the same CI is maintained over
both entailment and contradiction pairs, we cal-
culate a Deviation Index as the difference be-
tween the CIs on entailment and on contradiction
pairs (step 4 of our methodology). As described
in Section 3, we created four datasets dividing
both [T,H]RTE5?sample and [T,H]RTE5?mono
into positive (i.e. entailment) and negative (i.e.
contradiction) examples. We run EDITS and
VENSES on the datasets and we calculate the
CI on positive and on negative examples sepa-
rately. If we obtained missing correlation be-
tween the accuracy on the monothematic pairs
and the accuracy on RTE original ones, it would
mean that the potentiality that the systems show
on monothematic pairs is not exploited to cor-
rectly judge more complex pairs, therefore com-
positional mechanisms should be improved.
Table 5 shows that the DIs of the linguistic bi-
ased system and of VENSES are close to the ideal
case (DIS ?= 0), indicating a good capacity to
correctly differentiate entailment from contradic-
tion cases. EDITS results demonstrate that the
105
Figure 1: Correlation Index on entailment and contradiction pairs for EDITS and VENSES
% acc. RTE5 % acc. RTE5 CI DI
sample mono
EDITS E 83.3 94.7 0.88 0.5
C 33.3 24 1.38
VENSES E 50 47.01 1.08 0.16
C 70 75.7 0.92
WO E 50 88 0.56 0.24
baseline C 26.6 33 0.80
ling-biased E 96.6 98.5 0.98 0.03
baseline C 40 39.4 1.01
Table 5: Evaluation on entail. and contr. pairs
shallow approach implemented by the system has
no strategies to correctly judge negative examples
(similarly to the WO system), therefore should be
mainly improved with this respect.
We also calculated the CI for every pair of the
dataset, putting into relation each original pair
with all the monothematic pairs derived from it.
Figure 1 shows EDITS and VENSES?s CI on each
pair of our sample.5 Even if the systems obtained
similar performances in the challenge, the second
system seems to behave in an opposite way with
respect to EDITS, showing higher CI for negative
cases than for the positive ones.
5The ideal case CI=1 corresponds to 0 on the logarithmic
scale.
5 Conclusion and Future work
We have proposed a methodology for the evalu-
ation of TE systems based on the analysis of the
system behaviour on monothematic pairs with re-
spect to the behaviour on corresponding original
pairs. Through the definition of two indicators,
a Correlation Index and a Deviation Index, we
infer evaluation patterns which indicate strength
and weaknesses of the system. As a pilot study,
we have compared two systems that took part in
RTE-5. We discovered that, although the two sys-
tems have similar accuracy on RTE-5 datasets,
they show significant differences in their respec-
tive abilities to manage different linguistic phe-
nomena and to properly combine them. We hope
that the analysis provided by our methodology
may bring interesting elements both to TE system
developers and for deep discussion on the nature
of TE itself.
As future work, we plan to refine the evaluation
methodology introducing the possibility to assign
different relevance to the phenomena.
6 Acknowledgements
Thanks to Professor Rodolfo Delmonte and to
Sara Tonelli for running the VENSES system on
our data sets.
106
References
Bentivogli, Luisa, Bernardo Magnini, Ido Dagan,
Hoa Trang Dang, and Danilo Giampiccolo. 2009.
The Fifth PASCAL Recognizing Textual Entailment
Challenge. Proceedings of the TAC 2009 Workshop
on Textual Entailment. Gaithersburg, Maryland. 17
November.
Bentivogli, Luisa, Elena Cabrio, Ido Dagan,
Danilo Giampiccolo, Medea Lo Leggio, and
Bernardo Magnini. 2010. Building Textual En-
tailment Specialized Data Sets: a Methodology
for Isolating Linguistic Phenomena Relevant to
Inference. Proceedings of the 7th International
Conference on Language Resources and Evaluation
(LREC) . Valletta, Malta. 19-21 May.
Dagan, Ido, Bill Dolan, Bernardo Magnini, and
Dan Roth. 2009. Recognizing textual entailment:
Rational, evaluation and approaches. Natural Lan-
guage Engineering (JNLE), Volume 15, Special Is-
sue 04, October 2009, pp i-xvii. Cambridge Univer-
sity Press.
Delmonte, Rodolfo, Sara Tonelli, Rocco Tripodi.
2009. Semantic Processing for Text Entailment
with VENSES. Proceedings of the TAC 2009 Work-
shop on Textual Entailment. To appear. Gaithers-
burg, Maryland. 17 November.
Garoufi, Konstantina. 2007. Towards a Better Un-
derstanding of Applied Textual Entailment. Mas-
ter Thesis. Saarland University. Saarbru?cken, Ger-
many.
Gottlob, Frege. 1892. U?ber Sinn und Bedeutung.
Zeitschrift fu?r Philosophie und philosophische Kri-
tik. 100.25-50.
Magnini, Bernardo, and Elena Cabrio. 2009. Combin-
ing Specialized Entailment Engines. Proceedings of
the 4th Language & Technology Conference (LTC
?09). Poznan, Poland. 6-8 November.
Mehdad, Yashar, Matteo Negri, Elena Cabrio,
Milen Kouylekov, and Bernardo Magnini. 2009.
Using Lexical Resources in a Distance-Based Ap-
proach to RTE. Proceedings of the TAC 2009 Work-
shop on Textual Entailment. Gaithersburg, Mary-
land. 17 November.
Negri, Matteo, Milen Kouylekov, Bernardo Magnini,
Yashar Mehdad, and Elena Cabrio. 2009. Towards
Extensible Textual Entailment Engines: The EDITS
Package. AI*IA 2009: Emergent Perspectives in
Artificial Intelligence, Lecture Notes in Computer
Science. Volume 5883. ISBN 978-3-642-10290-5.
Springer-Verlag Berlin Heidelberg, p. 314.
Nielsen, Rodney D., Wayne Ward, and James H. Mar-
tin. 2009. Recognizing entailment in intelligent tu-
toring systems. In Ido Dagan, Bill Dolan, Bernardo
Magnini and Dan Roth (Eds.) The Journal of Nat-
ural Language Engineering, (JNLE). , 15, pp 479-
501. Copyright Cambridge University Press, Cam-
bridge, United Kingdom.
Romano, Lorenza, Milen Ognianov Kouylekov,
Idan Szpektor, Ido Kalman Dagan, and Al-
berto Lavelli, 2006. Investigating a Generic
Paraphrase-Based Approach for Relation Extrac-
tion. Proceedings of the 11th Conference of the
European Chapter of the Association for Computa-
tional Linguistics (EACL 2006). Trento, Italy. 3-7
April.
107
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 208?212,
Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational Linguistics
Combining Textual Entailment and Argumentation Theory
for Supporting Online Debates Interactions
Elena Cabrio and Serena Villata
INRIA
2004 Route des Lucioles BP93
06902 Sophia-Antipolis cedex, France.
{elena.cabrio, serena.villata}@inria.fr
Abstract
Blogs and forums are widely adopted by on-
line communities to debate about various is-
sues. However, a user that wants to cut in on
a debate may experience some difficulties in
extracting the current accepted positions, and
can be discouraged from interacting through
these applications. In our paper, we combine
textual entailment with argumentation theory
to automatically extract the arguments from
debates and to evaluate their acceptability.
1 Introduction
Online debate platforms, like Debatepedia1, Twit-
ter2 and many others, are becoming more and more
popular on the Web. In such applications, users are
asked to provide their own opinions about selected
issues. However, it may happen that the debates
become rather complicated, with several arguments
supporting and contradicting each others. Thus, it
is difficult for potential participants to understand
the way the debate is going on, i.e., which are the
current accepted arguments in a debate. In this pa-
per, we propose to support participants of online de-
bates with a framework combining Textual Entail-
ment (TE) (Dagan et al, 2009) and abstract argu-
mentation theory (Dung, 1995). In particular, TE
is adopted to extract the abstract arguments from
natural language debates and to provide the rela-
tions among these arguments; argumentation theory
is then used to compute the set of accepted argu-
ments among those obtained from the TE module,
1http://debatepedia.idebate.org
2http://twitter.com/
i.e., the arguments shared by the majority of the par-
ticipants without being attacked by other accepted
arguments. The originality of the proposed frame-
work lies in the combination of two existing ap-
proaches with the goal of supporting participants in
their interactions with online debates, by automat-
ically detecting the arguments in natural language
text, and identifying the accepted ones. We evaluate
the feasibility of our combined approach on a set of
arguments extracted from a sample of Debatepedia.
2 First step: textual entailment
TE was proposed as an applied framework to cap-
ture major semantic inference needs across applica-
tions in NLP, e.g. (Romano et al, 2006; Barzilay
and McKeown, 2005; Nielsen et al, 2009). It is de-
fined as a relation between two textual fragments,
i.e., the text (T) and the hypothesis (H). Entailment
holds if the meaning of H can be inferred from the
meaning of T, as interpreted by a typical language
user. Consider the pairs in Example 1 and 2.
Example 1.
T1: Research shows that drivers speaking on a mobile
phone have much slower reactions in braking tests than
non-users, and are worse even than if they have been
drinking.
H:The use of cell-phones while driving is a public hazard.
Example 2 (Continued).
T2: Regulation could negate the safety benefits of having
a phone in the car. When you?re stuck in traffic, calling
to say you?ll be late can reduce stress and make you less
inclined to drive aggressively to make up lost time.
H:The use of cell-phones while driving is a public hazard.
208
A system aimed at recognizing TE should detect an
entailment relation between T1 and H (Example 1),
and a contradiction between T2 and H (Example 2).
As introduced before, our paper proposes an
approach to support the participants in forums or
debates to detect the accepted arguments among
those expressed by the other participants on a
certain topic. As a first step, we need to (i) automat-
ically recognize a participant?s opinion on a certain
topic as an argument, as well as to (ii) detect its
relationship with the other arguments. We therefore
cast the described problem as a TE problem, where
the T-H pair is a pair of arguments expressed by
two different participants on a certain topic. For in-
stance, given the argument ?The use of cell-phones
while driving is a public hazard? (that we consider
as H as a starting point), participants can support it
expressing arguments from which H can be inferred
(Example 1), or can contradict such argument with
opinions against it (Example 2). Since in debates
arguments come one after the other, we extract
and compare them both with respect to the main
issue, and with the other participants? arguments
(when the new argument entails or contradicts one
of the arguments previously expressed by another
participant). For instance, given the same debate as
before, a new argument T3 may be expressed by a
third participant with the goal of contradicting T2
(that becomes the new H (H1) in the pair), as shown
in Example 3.
Example 3 (Continued).
T3: If one is late, there is little difference in apologizing
while in their car over a cell phone and apologizing in
front of their boss at the office. So, they should have the
restraint to drive at the speed limit, arriving late, and
being willing to apologize then; an apologetic cell phone
call in a car to a boss shouldn?t be the cause of one being
able to then relax, slow-down, and drive the speed-limit.
T2? H1: Regulation could negate the safety benefits of
having a phone in the car. When you?re stuck in [...]
TE provides us with the techniques to detect both
the arguments in a debate, and the kind of relation
underlying each couple of arguments. The TE sys-
tem returns indeed a judgment (entailment or con-
tradiction) on the arguments? pairs, that are used as
input to build the argumentation framework, as de-
scribed in the next Section.
3 Second step: argumentation theory
Starting from a set of arguments and the attacks (i.e.,
conflicts) among them, a (Dung, 1995)-style argu-
mentation framework allows to detect which are the
accepted arguments. Such arguments are consid-
ered as believable by an external evaluator who has
a full knowledge of the argumentation framework,
and they are determined through the acceptability
semantics (Dung, 1995). Roughly, an argument is
accepted, if all the arguments attacking it are re-
jected, and it is rejected if it has at least an argument
attacking it which is accepted. An argument which
is not attacked at all is accepted.
Definition 1. An abstract argumentation framework (AF)
is a pair ?A,?? where A is a set of arguments and??
A?A is a binary relation called attack.
Aim of the argumentation-based reasoning step is
to provide the participant with a complete view on
the arguments proposed in the debate, and to show
which are the accepted ones. In our framework, we
first map contradiction with the attack relation in ab-
stract argumentation; second, the entailment relation
is viewed as a support relation among abstract argu-
ments. The support relation (Cayrol and Lagasquie-
Schiex, 2011) may be represented as: (1) a relation
among the arguments which does not affect their ac-
ceptability, or (2) a relation among the arguments
which leads to the introduction of additional attacks.
Consider a support relation among two argu-
ments, namely Ai and Aj . If we choose (1), an at-
tack towards Ai or Aj does not affect the acceptabil-
ity of Aj or Ai, respectively. If we choose (2), we
introduce additional attacks, and we have the follow-
ing two options: [Type 1] Ai supports Aj then Ak
attacks Aj , and [Type 2] Ai supports Aj then Ak at-
tacks Ai. The attacks of type 1 are due to inference:
Ai entails Aj means that Ai is more specific of Aj ,
thus an attack towards Aj is an attack also towards
Ai. The attacks of type 2, instead, are more rare,
but they may happen in debates: an attack towards
the more specific argument Ai is an attack towards
the more general argument Aj . In Section 4, we will
consider only the introduction of attacks of type 1.
For Examples 1, 2, and 3, the TE phase returns
the following couples: T1 entails H, T2 attacks H,
T3 attacks H1 (i.e. T2). The argumentation module
209
maps each element to its corresponding argument: H
? A1, T1? A2, T2? A3, and T3? A4 . The resulting
AF (Figure 1) shows that the accepted arguments
are {A1, A2, A4}, meaning that the issue ?The use of
cell-phones while driving is a public hazard? (A1) is
considered as accepted. Figure 2 visualizes the com-
plete framework of the debate ?Use of cell phones
while driving? on Debatepedia. Accepted arguments
are double bordered.
A1A4 A3
A2
Figure 1: The AF built from the results of the TE module
for Example 1, 2 and 3, without introducing additional
attacks. Plain arrows represent attacks, dashed arrows
represent supports.
A1
A4 A3
A2
A5 A6
A7 A8
A9
A11
A10
Figure 2: The AF built from the results of the TE module
for the entire debate. Grey attacks are of type 1. For
picture clarity, we introduce type 1 attacks only fromA11.
The same attacks hold from A10 and A3.
4 Experimental setting
We experiment the combination of TE and argumen-
tation theory to support the interaction of online de-
bates participants on Debatepedia, an encyclopedia
of pro and con arguments on critical issues.
Data set. To create the data set of arguments pairs
to evaluate our task3, we randomly selected a set of
topics (reported in column Topics, Table 1) of De-
batepedia debates, and for each topic we coupled all
the pros and cons arguments both with the main ar-
gument (the issue of the debate, as in Example 1
3Data available for the RTE challenges are not suitable for
our goal, since the pairs are extracted from news and are not
linked among each other (they do not report opinions on a cer-
tain topic). http://www.nist.gov/tac/2010/RTE/
and 2) and/or with other arguments to which the
most recent argument refers, e.g., Example 3. Using
Debatepedia as case study provides us with already
annotated arguments (pro ? entailment4, and cons
? contradiction), and casts our task as a yes/no en-
tailment task. As shown in Table 1, we collected 200
T-H pairs, 100 used to train the TE system, and 100
to test it (each data set is composed by 55 entailment
and 45 contradiction pairs).5 Test set pairs concern
completely new topics, never seen by the system.
TE system. To detect which kind of relation un-
derlies each couple of arguments, we used the
EDITS system (Edit Distance Textual Entailment
Suite), an open-source software package for recog-
nizing TE6 (Kouylekov and Negri, 2010). EDITS
implements a distance-based framework which as-
sumes that the probability of an entailment relation
between a given T-H pair is inversely proportional
to the distance between T and H. Within this frame-
work, the system implements different approaches
to distance computation, providing both edit dis-
tance algorithms and similarity algorithms.
Evaluation. To evaluate our combined approach,
we carry out a two-step evaluation: we assess (i) the
performances of the TE system to correctly assign
the entailment/contradiction relations to the pairs
of arguments in the Debatepedia data set; (ii) how
much such performances impact on the goals of the
argumentation module, i.e. how much a wrong as-
signment of a relation between two arguments leads
to an incorrect evaluation of the accepted arguments.
For the first evaluation, we run the EDITS sys-
tem off-the-shelf on the Debatepedia data set, ap-
plying one of its basic configurations (i.e. the dis-
tance entailment engine combines cosine similarity
as the core distance algorithm; distance calculated
on lemmas; stopword list included). EDITS accu-
racy on the training set is 0.69, on the test set 0.67
(a baseline applying a Word Overlap algorithm on
tokenized text is also considered, and obtains an ac-
curacy of 0.61 on the training set and 0.62 on the test
set). Even using a basic configuration of EDITS, and
a small data set (100 pairs for training) performances
4Arguments ?supporting? another argument without infer-
ence are left for future work.
5Available at http://bit.ly/debatepedia_ds
6Version 3.0 available at http://edits.fbk.eu/
210
Training set Test set
Topic #argum #pairs Topic #argum #pairs
TOT. yes no TOT. yes no
Violent games boost aggressiveness 16 15 8 7 Ground zero mosque 9 8 3 5
China one-child policy 11 10 6 4 Mandatory military service 11 10 3 7
Consider coca as a narcotic 15 14 7 7 No fly zone over Libya 11 10 6 4
Child beauty contests 12 11 7 4 Airport security profiling 9 8 4 4
Arming Libyan rebels 10 9 4 5 Solar energy 16 15 11 4
Random alcohol breath tests 8 7 4 3 Natural gas vehicles 12 11 5 6
Osama death photo 11 10 5 5 Use of cell phones while driving 11 10 5 5
Privatizing social security 11 10 5 5 Marijuana legalization 17 16 10 6
Internet access as a right 15 14 9 5 Gay marriage as a right 7 6 4 2
Vegetarianism 7 6 4 2
TOTAL 109 100 55 45 TOTAL 110 100 55 45
Table 1: The Debatepedia data set.
on Debatepedia test set are promising, and in line
with performances of TE systems on RTE data sets.
As a second step of the evaluation, we consider
the impact of EDITS performances on arguments ac-
ceptability, i.e., how much a wrong assignment of a
relation to a pair of arguments affects the computa-
tion of the set of accepted arguments. We identify
the accepted arguments both in the correct AF of
each Debatepedia debate of the data set (the gold-
standard, where relations are correctly assigned),
and on the AF generated basing on the relations
assigned by EDITS. Our combined approach ob-
tained the following performances: precision 0.74,
recall 0.76, accuracy 0.75, meaning that the TE sys-
tem mistakes in relation assignment propagate in the
AF , but results are still satisfying and foster further
research in this direction.
5 Related work
DebateGraph7 is an online system for debates, but
it is not grounded on argument theory to decide
the accepted arguments. Chasnevar and Maguit-
man?s (2004) system provides recommendations on
language patterns using indices computed from Web
corpora and defeasible argumentation. No NLP is
used for automatic arguments detection. Carenini
and Moore (2006) present a computational frame-
work to generate evaluative arguments. Based on
users? preferences, arguments are produced follow-
ing argumentation guidelines to structure evaluative
arguments. Then, NL Generation techniques are ap-
plied to return the argument in natural language. Un-
like them, we do not create the arguments, but we
7http://debategraph.org
use TE to detect them in texts, and we use Dung?s
model to identify the accepted ones. Wyner and van
Engers (2010) present a policy making support tool
based on forums, where NLP and argumentation are
coupled to provide well structured statements. Be-
side the goal, several points distinguish our proposal
from this one: (i) the user is asked to write the in-
put text using Attempt to Controlled English, with
a restricted grammar and vocabulary, while we do
not support the participant in writing the text, but
we automatically detect the arguments (no language
restriction); (ii) a mode indicates the relations be-
tween the statements, while we infer them using TE;
(iii) no evaluation of their framework is provided.
6 Future challenges
Several research lines are considered to improve the
proposed framework: first, the use of NLP to de-
tect the arguments from text will make argumenta-
tion theory applicable to reason in real scenarios. We
plan to use the TE module to reason on the introduc-
tion of the support relation in abstract argumentation
theory. We plan to extend our model by consider-
ing also other kinds of relationships among the ar-
guments. Moreover, given the promising results we
obtained, we plan to extend the experimentation set-
ting both increasing the size of the Debatepedia data
set, and to improve the TE system performances to
apply our combined approach in other real applica-
tions (considering for instance the presence of un-
related arguments, e.g. texts that do not entail nor
contradict).
211
References
Barzilay R. and McKeown K.R. 2005. Sentence fu-
sion for multidocument news summarization. Compu-
tational Linguistics, 31(3). pp. 297-327.
Carenini G. and Moore J.D. 2006. Generating and eval-
uating evaluative arguments. Artificial Intelligence,
volume 170, n. 11. pp. 925-952.
Cayrol C. and Lagasquie-Schiex M.C. 2011. Bipolarity
in Argumentation Graphs: Towards a Better Under-
standing. Proceedings of SUM 2011. pp.137-148
Chesn?evar C.I. and Maguitman A.G. 2004. An Argumen-
tative Approach to Assessing Natural Language Us-
age based on the Web Corpus. Proceedings of ECAI.
pp.581-585.
Dagan I. and Dolan B. and Magnini B. and Roth D.
2009. Recognizing textual entailment: Rational, eval-
uation and approaches. Natural Language Engineer-
ing (JNLE), Special Issue 04, volume 15. pp. i-xvii.
Cambridge University Press.
Dung P.M. 1995. On the Acceptability of Arguments
and its Fundamental Role in Nonmonotonic Reason-
ing, Logic Programming and n-Person Games. Artifi-
cial Intelligence, volume 77, n.2. pp.321-358.
Kouylekov M. and Negri M. 2010. An Open-Source
Package for Recognizing Textual Entailment. Proceed-
ings of ACL 2010 System Demonstrations. pp.42-47.
Nielsen R.D. and Ward W. and Martin J.H. 2009. Recog-
nizing entailment in intelligent tutoring systems. The
Journal of Natural Language Engineering, (JNLE),
volume 15. pp. 479-501. Cambridge University Press.
Romano L. and Kouylekov M. O. and Szpektor I. and
Dagan I. and Lavelli A. 2006. Investigating a Generic
Paraphrase-Based Approach for Relation Extraction.
Proceedings of EACL 2006. pp. 409-416.
Wyner A. and van Engers T. 2010. A framework
for enriched, controlled on-line discussion forums for
e-government policy-making. Proceedings of eGov
2010.
212
Proceedings of the Workshop on Negation and Speculation in Natural Language Processing, pages 86?94,
Uppsala, July 2010.
Contradiction-Focused Qualitative Evaluation of Textual Entailment
Bernardo Magnini
FBK-Irst
Trento, Italy
magnini@fbk.eu
Elena Cabrio
FBK-Irst, University of Trento
Trento, Italy
cabrio@fbk.eu
Abstract
In this paper we investigate the rela-
tion between positive and negative pairs
in Textual Entailment (TE), in order to
highlight the role of contradiction in TE
datasets. We base our analysis on the de-
composition of Text-Hypothesis pairs into
monothematic pairs, i.e. pairs where only
one linguistic phenomenon at a time is re-
sponsible for entailment judgment and we
argue that such a deeper inspection of the
linguistic phenomena behind textual en-
tailment is necessary in order to highlight
the role of contradiction. We support our
analysis with a number of empirical ex-
periments, which use current available TE
systems.
1 Introduction
Textual Entailment (TE) (Dagan et al, 2009) pro-
vides a powerful and general framework for ap-
plied semantics. TE has been exploited in a series
of evaluation campaigns (RTE - Recognizing Tex-
tual Entailment) (Bentivogli et al, 2009), where
systems are asked to automatically judge whether
the meaning of a portion of text, referred as Text
(T), entails the meaning of another text, referred
as Hypothesis (H).
RTE datasets have been mainly built with the
purpose of showing the applicability of the TE
framework to different semantic applications in
Computational Linguistics. Starting from 2005,
[T,H] pairs were created including samples from
summarization, question answering, information
extraction, and other applications. This evaluation
provides useful cues for researchers and develop-
ers aiming at the integration of TE components in
larger applications (see, for instance, the use of a
TE engine for question answering in the QALL-
ME project system
1
, the use in relation extraction
(Romano et al, 2006), and in reading comprehen-
sion systems (Nielsen et al, 2009)).
Although the RTE evaluations showed pro-
gresses in TE technologies, we think that there is
still large room for improving qualitative analysis
of both the RTE datasets and the system results. In
particular, we intend to focus this paper on contra-
diction judgments and on a deep inspection of the
linguistic phenomena that determine such judg-
ments. More specifically, we address two distin-
guishing aspects of TE: (i) the variety of linguis-
tic phenomena that are relevant for contradiction
and how their distribution is represented in RTE
datasets; (ii) the fact that in TE it is not enough to
detect the polarity of a sentence, as in traditional
semantic analysis, but rather it is necessary to ana-
lyze the dependencies between two sentences (i.e.
the [T,H] pair) in order to establish whether a con-
tradiction holds between the pair. Under this re-
spect we are interested to investigate both how
polarity among Text and Hypothesis affects the
entailment/contradiction judgments and how dif-
ferent linguistic phenomena interact with polarity
(e.g. whether specific combinations of phenomena
are more frequent than others).
As an example, let us consider the pair:
T: Mexico?s new president, Felipe Calderon, seems to be
doing all the right things in cracking down on Mexico?s drug
traffickers.[...]
H: Felipe Calderon is the outgoing President of Mexico.
In order to detect the correct contradiction judg-
ment between T and H it is necessary to solve the
semantic inference that being the new President of
a country is not compatible with being the outgo-
ing President of the same country. This kind of
inference requires that (i) the semantic opposition
is detected, and that (ii) such opposition is consid-
1
http://qallme.fbk.eu/
86
Text snippet (pair 125) Phenomena Judg.
T Mexico?s new president, Felipe Calderon, seems to be doing
all the right things in cracking down on Mexico?s drug traffickers. [...]
lexical:semantic-opposition C
H Felipe Calderon is the outgoing President of Mexico. syntactic:argument-realization
syntactic:apposition
H1 Mexico?s outgoing president, Felipe Calderon, seems to be lexical:semantic-opposition C
doing all the right things in cracking down on Mexico?s drug
traffickers. [...]
H2 The new president of Mexico, Felipe Calderon, seems to be syntactic:argument-realization E
doing all the right things in cracking down on Mexico?s drug
traffickers. [...]
H3 Felipe Calderon is Mexico?s new president. syntactic:apposition E
Table 1: Application of the decomposition methodology to an original RTE pair
ered relevant for the contradiction judgment in the
specific context of the pair.
In order to address the issues above, we pro-
pose a methodology based on the decomposition
of [T,H] pairs into monothematic pairs, each rep-
resenting one single linguistic phenomenon rele-
vant for entailment judgment. Then, the analy-
sis is carried out both on the original [T,H] pair
and on the monothematic pairs originated from
it. In particular, we investigate the correlations on
positive and on negative pairs separately, and we
show that the strategies adopted by the TE sys-
tems to deal with phenomena contributing to the
entailment or to the contradiction judgment come
to light when analyzed using qualitative criteria.
We have experimented the decomposition method-
ology over a dataset of pairs, which either are
marked with a contradiction judgment, or show a
polarity phenomenon (either in T or H) which, al-
though present, is not relevant for cotradiction.
The final goal underlying our analysis of con-
tradiction in current RTE datasets is to discover
good strategies for systems to manage contradic-
tion and, more generally, entailment judgments.
To this aim, in Section 5 we propose a comparison
between two systems participating at the last RTE-
5 campaign and try to analyze their behaviour ac-
cording to the decomposition into monothematic
pairs.
The paper is structured as follows. Section 2
presents the main aspects related to contradiction
within the RTE context. Section 3 explains the
procedure for the creation of monothematic pairs
starting from RTE pairs. Section 4 describes the
experimental setup of our pilot study, as well as
the results of the qualitative analysis. Section 5
outlines the preliminary achievements in terms of
comparison of systems? strategies in order to man-
age contradiction. Finally, Section 6 reports on
previous work on contradiction and textual entail-
ment.
2 Contradiction and Textual Entailment
In RTE, two kinds of judgment are allowed: two
ways (yes or no entailment) or three way judg-
ment. In the latter, systems are required to decide
whether the hypothesis is entailed by the text (en-
tailment), contradicts the text (contradiction), or
is neither entailed by nor contradicts the text (un-
known). The RTE-4 and RTE-5 datasets are anno-
tated for a 3-way decision: entailment (50% of the
pairs), unknown (35%), contradiction (15%). This
distribution among the three entailment judgments
aims at reflecting the natural distribution of en-
tailment in a corpus, where the percentage of text
snippets neither entailing nor contradicting each
other is higher than the contradicting ones. Even if
this balance seems artificial since in a natural set-
ting the presence of unknown pairs is much higher
than the other two judgments (as demonstrated in
the Pilot Task proposed in RTE-5 (Bentivogli et
al., 2009)), the reason behind the choice of RTE
organizers is to maintain a trade-off between the
natural distribution of the data in real documents,
and the creation of a dataset balanced beween pos-
itive and negative examples (as in two way task).
As already pointed out in (Wang, 2009), the
similarity between T?s and H?s in pairs marked as
entailment and contradiction is much higher with
respect to the similarity between T?s and H?s in
pairs marked as unknown. To support this in-
tuition, (Bentivogli et al, 2009) provides some
data on the lexical overlap between T?s and H?s
in the last RTE Challenges. For instance, in RTE-
4 the lexical overlap is 68.95% in entailment pairs,
67.97% in contradiction pairs and only 57.36% in
87
the unknown pairs. Similarly, in RTE-5 the lexical
overlap between T?s and H?s is 77.14% in entail-
ment pairs, 78.93% in contradiction pairs and only
62.28% in the unknown pairs.
For this reason, for contradiction detection it is
not sufficient to highlight mismatching informa-
tion between sentences, but deeper comprehension
is required. For applications in information anal-
ysis, it can be very important to detect incompat-
ibility and discrepancies in the description of the
same event, and the contradiction judgment in the
TE task aims at covering this aspect. More specif-
ically, in the RTE task the contradiction judgment
is assigned to a T,H pair when the two text frag-
ments are extremely unlikely to be true simultane-
ously.
According to Marneffe et al (2008), contra-
dictions may arise from a number of different
constructions, defined in two primary categories:
i) those occurring via antonymy, negation, and
numeric mismatch, and ii) contradictions arising
from the use of factive or modal words, structural
and subtle lexical contrasts, and world knowledge.
Comparing the distribution of contradiction types
for RTE-3 and the real contradiction corpus they
created collecting contradiction ?in the wild? (e.g.
from newswire, Wikipedia), they noticed that in
the latter there is a much higher rate of negations,
numeric and lexical contradictions with respect
to RTE dataset, where contradictions of category
(ii) occur more frequently. Analyzing RTE data
of the previous challenges, we noticed that the
tendency towards longer and more complex
sentences in the datasets in order to reproduce
more realistic scenarios, is also reflected in more
complex structures determining contradictions.
For instance, contradictions arising from overt
negation as in (pair 1663, RTE-1 test set):
T: All residential areas in South Africa are segregated by
race and no black neighborhoods have been established in
Port Nolloth.
H: Black neighborhoods are located in Port Nolloth.
are infrequent in the datasets of more recent RTE
challenges. For instance, in RTE-5 test set, only in
4 out of 90 contradiction pairs an overt negation
is responsible for the contradiction judgment.
In agreement with (Marneffe et al, 2008), we
also remarked that most of the contradiction
involve numeric mismatch, wrong appositions,
entity mismatch and, above all, deeper inferences
depending on background and world knowledge,
as in (pair 567, RTE-5 test set):
T: ?[...] we?ve done a series of tests on Senator Kennedy
to determine the cause of his seizure. He has had no further
seizures, remains in good overall condition, and is up and
walking around the hospital?.
H: Ted Kennedy is dead.
These considerations do not mean that overt
negations do not appear in the RTE pairs. On the
contrary, they are often present in T,H pairs, but
most of the times their presence is irrelevant in the
assignment of the correct entailment judgment to
the pair. For instance, the scope of the negation
can be a phrase or a sentence with additional infor-
mation with respect to the relevant parts of T and
H that allow to correctly judge the pair. This fact
could be misleading for systems that do not cor-
recly exploit syntactic information, as the experi-
ments using Linear Distance described in (Cabrio
et al, 2008).
3 Decomposing RTE pairs
The qualitative evaluation we propose takes
advantage of previous work on monothematic
datasets. A monothematic pair (Magnini and
Cabrio, 2009) is defined as a [T,H] pair in which a
certain phenomenon relevant to the entailment re-
lation is highlighted and isolated. The main idea is
to create such monothematic pairs on the basis of
the phenomena which are actually present in the
original RTE pairs, so that the actual distribution
of the linguistic phenomena involved in the entail-
ment relation emerges.
For the decomposition procedure, we refer to
the methodology described in (Bentivogli et al,
2010), consisting of a number of steps carried
out manually. The starting point is a [T,H] pair
taken from one of the RTE datasets, that should be
decomposed in a number of monothematic pairs
[T,H
i
]
mono
, where T is the original Text and H
i
are the Hypotheses created for each linguistic phe-
nomenon relevant for judging the entailment rela-
tion in [T,H].
In detail, the procedure for the creation of
monothematic pairs is composed of the following
steps:
1. Individuate the linguistic phenomena which
contribute to the entailment in [T,H].
2. For each phenomenon i:
88
(a) Individuate a general entailment rule r
i
for the phenomenon i, and instantiate
the rule using the portion of T which ex-
presses i as the left hand side (LHS) of
the rule, and information from H on i as
the right hand side (RHS) of the rule.
(b) Substitute the portion of T that matches
the LHS of r
i
with the RHS of r
i
.
(c) Consider the result of the previous step
as H
i
, and compose the monothematic
pair [T,H
i
]
mono
. Mark the pair with
phenomenon i.
3. Assign an entailment judgment to each
monothematic pair.
Relevant linguistic phenomena are grouped us-
ing both fine-grained categories and broader cate-
gories. Macro categories are defined referring to
widely accepted linguistic categories in the liter-
ature (e.g. (Garoufi, 2007)) and to the inference
types typically addressed in RTE systems: lexical,
syntactic, lexical-syntactic, discourse and reason-
ing. Each macro category includes fine-grained
phenomena (Table 2 reports a list of some of the
phenomena detected in RTE-5 dataset).
Table 1 shows an example of the decomposi-
tion of a RTE pair (marked as contradiction) into
monothematic pairs. At step 1 of the methodology
both the phenomena that preserve the entailment
and the phenomena that break the entailment rules
causing a contradiction in the pair are detected,
i.e. argument realization, apposition and seman-
tic opposition (column phenomena in the table).
While the monothematic pairs created basing on
the first two phenomena preserve the entailment,
the semantic opposition generates a contradiction
(column judgment).
As an example, let?s apply step by step the
procedure to the phenomenon of semantic oppo-
sition. At step 2a of the methodology the general
rule:
Pattern: x ? / ? y
Constraint: semantic opposition(y,x)
is instantiated (new? / ?outgoing), and at step
2b the substitution in T is carried out (Mexico?s
outgoing president, Felipe Calderon [...]). At
step 2c a negative monothematic pair T,H
1
is
composed (column text snippet in the table) and
marked as semantic opposition (macro-category
lexical), and the pair is judged as contradiction.
In (Bentivogli et al, 2010), critical issues con-
cerning the application of such procedure are dis-
cussed in detail, and more examples are provided.
Furthermore, a pilot resource is created, composed
of a first dataset with 60 pairs from RTE-5 test
set (30 positive, and 30 negative randomly ex-
tracted examples), and a dataset composed of all
the monothematic pairs derived by the first one
following the procedure described before. The
second dataset is composed of 167 pairs (134 en-
tailment, 33 contradiction examples, considering
35 different linguistic phenomena).
2
4 Analysis and discussion
Our analysis has been carried out taking advan-
tage of the pilot resource created by Bentivogli
et al (2010). From their first dataset we ex-
tracted a sample of 48 pairs ([T,H]
sample?contr
)
composed of 30 contradiction pairs and 18 entail-
ment pairs, the latter containing either in T or in
H a directly or an indirectly licensed negation.
3
Furthermore, a dataset of 129 monothematic pairs
(96 entailment and 33 contradiction examples),
i.e. [T,H]
mono?contr
, was derived by the pairs
in [T,H]
sample?contr
applying the procedure de-
scribed in Section 3. The linguistic phenomena
isolated in the monothematic pairs (i.e. considered
relevant to correctly assign the entailment judg-
ment to our sample) are listed in Table 2.
In RTE datasets only a subpart of the potentially
problematic phenomena concerning negation and
negative polarity items is represented. At the same
time, the specificity of the task lies in the fact that
it is not enough to find the correct representation
of the linguistic phenomena underlying a sentence
meaning, but correct inferences should be derived
from the relations that these phenomena contribute
to establish between two text fragments. The
mere presence of a negation in T is not relevant
for the TE task, unless the scope of the negation (a
token or a phrase) is present as non-negated in H
2
Both datasets are freely available at
http://hlt.fbk.eu/en/Technology/TE Specialized Data
3
Following (Harabagiu et al, 2006) overt (directly li-
censed) negations include i) overt negative markers such as
not, n?t; ii) negative quantifiers as no, and expressions such
as no one and nothing; iii) strong negative adverbs like never.
Indirectly licensed negations include: i) verbs or phrasal
verbs (e.g. deny, fail, refuse, keep from); ii) prepositions (e.g.
without, except); weak quantifiers (e.g. few, any, some), and
iv) traditional negative polarity items (e.g. a red cent or any-
more).
89
phenomena # pairs [T,H]
RTE5?mono?contr
entailment contradiction
# mono probab. # mono probab.
lex:identity 1 0.25 3 0.75
lex:format 2 1 - -
lex:acronymy 1 1 - -
lex:demonymy 1 1 - -
lex:synonymy 6 1 - -
lex:semantic-opp. - - 3 1
lex:hypernymy 2 1 - -
TOT lexical 13 0.68 6 0.32
lexsynt:transp-head 2 1 - -
lexsynt:verb-nom. 6 1 - -
lexsynt:causative 1 1 - -
lexsynt:paraphrase 2 1 - -
TOT lexical-syntactic 11 1 - -
synt:negation - - 1 1
synt:modifier 3 0.75 1 0.25
synt:arg-realization 4 1 - -
synt:apposition 9 0.6 6 0.4
synt:list 1 1 - -
synt:coordination 2 1 - -
synt:actpass-altern. 4 0.67 2 0.33
TOT syntactic 23 0.7 10 0.3
disc:coreference 16 1 - -
disc:apposition 2 1 - -
disc:anaphora-zero 3 1 - -
disc:ellipsis 3 1 - -
disc:statements 1 1 - -
TOT discourse 25 1 - -
reas:apposition 1 0.5 1 0.5
reas:modifier 2 1 - -
reas:genitive 1 1 - -
reas:meronymy 1 0.5 1 0.5
reas:quantity - - 5 1
reas:spatial 1 1 - -
reas:gen-inference 18 0.64 10 0.36
TOT reasoning 24 0.59 17 0.41
TOT (all phenomena) 96 0.74 33 0.26
Table 2: Occurrences of linguistic phenomena in
TE contradiction pairs
(or viceversa), hence a contradiction is generated.
For this reason, 18 pairs of [T,H]
sample?contr
are judged as entailment even if a negation is
present, but it is not relevant to correctly assign
the entailment judgment to the pair as in (pair
205, RTE-5 test set):
T: A team of European and American astronomers say
that a recently discovered extrasolar planet, located not far
from Earth, contains oceans and rivers of hot solid water. The
team discovered the planet, Gliese 436 b [...].
H: Gliese 436 b was found by scientists from America and
Europe.
As showed in Table 2, only in one pair of
our sample the presence of a negation is relevant
to assign the contradiction judgment to the pair.
In the pairs we analyzed, contradiction mainly
arise from quantity mismatching, semantic oppo-
sition (antonymy), mismatching appositions (e.g.
the Swiss Foreign Minister x contradicts y is the
Swiss Foreign Minister), and from general infer-
ence (e.g. x became a naturalized citizen of the
U.S. contradicts x is born in the U.S.). Due to the
small sample we analyzed, some phenomena ap-
pear rarely, and their distribution can not be con-
sidered as representative of the same phenomenon
in a natural setting. In 27 out of 30 contradiction
pairs, only one monothematic pair among the ones
derived from each example was marked as con-
tradiction, meaning that on average only one lin-
guistic phenomenon is responsible for the contra-
diction judgment in a TE original pair. Hence the
importance of detecting it.
Given the list of the phenomena isolated in
[T,H]
mono?contr
with their frequency both in
monothematic positive pairs and monothematic
negative pairs, we derived the probability of lin-
guistic phenomena to contribute more to the as-
signment of a certain judgment than to another
(column probab. in Table 2). Such probability P
of a phenomenon i to appear in a positive (or in a
negative) pair is calculated as follows:
P (i|[T,H]
positive
) =
#(i|[T,H]
RTE5?positive?mono
)
#(i|[T,H]
RTE5?mono
)
(1)
For instance, if the phenomenon semantic op-
position appears in 3 pairs of our sample and all
these pairs are marked as contradiction, we as-
sign a probability of 1 to a pair containing a se-
mantic opposition to be marked as contradiction.
If the phenomenon apposition (syntax) appears in
9 monothematic positive pairs and in 6 negative
pairs, that phenomenon has a probability of 0.6 to
appear in positive examples and 0.4 to appear in
negative examples. Due to their nature, some phe-
nomena are strongly related to a certain judgment
(e.g. semantic opposition), while other can appear
both in positive and in negative pairs. Learning
such correlations on larger datasets could be an in-
teresting feature to be exploited by TE systems in
the assignment of a certain judgment if the phe-
nomenon i is detected in the pair.
Table 3 reports the cooccurrences of the linguis-
tic phenomena relevant to inference in the pairs
marked as contradiction. On the first horizontal
row all the phenomena that at least in one pair
determine contradiction are listed, while in the
first column there are all the phenomena cooc-
curring with them in the pairs. The idea un-
delying this table is to understand if it is possi-
ble to identify recurrent patterns of cooccurrences
between phenomena in contradiction pairs. As
can be noticed, almost all phenomena occur to-
gether with expressions requiring deeper inference
90
l
e
x
:
i
d
e
n
t
i
t
y
l
e
x
:
s
e
m
o
p
p
o
s
i
t
i
o
n
s
y
n
t
:
n
e
g
a
t
i
o
n
s
y
n
t
:
m
o
d
i
fi
e
r
s
y
n
t
:
a
p
p
o
s
i
t
i
o
n
s
y
n
t
:
a
c
t
p
a
s
s
a
l
t
e
r
n
r
e
a
s
:
m
e
r
o
n
y
m
y
r
e
a
s
:
q
u
a
n
t
i
t
y
r
e
a
s
:
g
e
n
i
n
f
e
r
e
n
c
e
lex:identity 1 1
lex:format 1
lex:acronymy 1
lex:synonymy 1 1 1 1
lex:hypernymy 1
lexsynt:vrb-nom 1 1 1
lexsynt:caus. 1
synt:modifier 1
synt:arg-realiz. 1 1
synt:apposition 2 3
synt:coord. 1
synt:actpass 1 1
disc:coref. 3 1 4
disc:apposition
disc:anaph-0 1 1
disc:ellipsis 1 1 2
disc:statements 1
reas:genitive 1
reas:meronymy 1
reas:gen-infer. 1 1 3 1 2 1
Table 3: Cooccurrencies of phenomena in contra-
diction pairs
(reas:general inference), but this is due to the fact
that this category is the most frequent one. Beside
this, it seems that no specific patterns can be high-
lighted, but it could be worth to extend this analy-
sis increasing the number of pairs of the sample.
5 Comparing RTE systems? behaviour
on contradiction pairs
As introduced before, from a contradiction pair it
is possible to extract on average 3 monothematic
pairs (Bentivogli et al, 2009), and only one of
these monothematic pairs is marked as contradic-
tion. This means that on average only one lin-
guistic phenomenon is responsible for the contra-
diction judgment in a RTE pair, while the others
maintain the entailment relation (i.e. it is possible
to correcly apply an entailment rule as exemplified
in Section 3). On the contrary, in a pair judged
as entailment, all the monothematic pairs derived
from it are marked as entailment.
These observations point out the fact that if a
TE system is able to correctly isolate and judge
the phenomenon that generates the contradiction,
the system should be able to assign the correct
judgment to the original contradiction pair, despite
possible mistakes in handling the other phenom-
ena present in that pair.
In order to understand how it is possible to
take advantage of the data analyzed so far to
improve a TE system, we run two systems that
took part into the last RTE challenge (RTE-5) on
[T,H]
mono?contr
.
The first system we used is the EDITS system
(Edit Distance Textual Entailment Suite) (Negri et
al., 2009)
4
, that assumes that the distance between
T and H is a characteristics that separates the pos-
itive pairs, for which entailment holds, from the
negative pairs, for which entailment does not hold
(it is developed according to the two way task). It
is based on edit distance algorithms, and computes
the [T,H] distance as the overall cost of the edit op-
erations (i.e. insertion, deletion and substitution)
that are required to transform T into H. In partic-
ular, we applied the model that produced EDITS
best run at RTE-5 (acc. on RTE-5 test set: 60.2%).
The main features of this run are: Tree Edit Dis-
tance algorithm on the parsed trees of T and H,
Wikipedia lexical entailment rules, and PSO opti-
mized operation costs, as described in (Mehdad et
al., 2009).
The other system used in our experiments
is VENSES
5
(Delmonte et al, 2009), that ob-
tained performances similar to EDITS at RTE-5
(acc. on test set: 61.5%). VENSES applies a
linguistically-based approach for semantic infer-
ence, composed of two main components: i) a
grammatically-driven subsystem that validates the
well-formedness of the predicate-argument struc-
ture and works on the output of a deep parser
producing augmented (i.e. fully indexed) head-
dependency structures; and ii) a subsystem that
detects allowed logical and lexical inferences bas-
ing on different kind of structural transformations
intended to produce a semantically valid mean-
ing correspondence. The system has a pronomi-
nal binding module that works at text/hypothesis
level separately for lexical personal, possessive
and reflexive pronouns, which are substituted by
the heads of their antecedents. Also in this case,
we applied the same configuration of the system
used in RTE evaluation.
Table 4 reports EDITS and VENSES accuracies
on the monothematic pairs of [T,H]
mono?contr
.
As said before, the accuracy reported for some
very rare phenomena cannot be considered com-
pletely reliable. Nevertheless, from these data the
main features of the systems can be identified. For
instance, EDITS obtains the highest accuracies on
the positive monothematic pairs, while it seems it
has no peculiar strategies to deal with phenomena
4
http://edits.fbk.eu/
5
http://project.cgm.unive.it/venses en.html
91
phenomena EDITS VENSES
% acc. % acc.
pos. neg. pos. neg.
lex:identity 100 0 100 33.3
lex:format 100 - 100 -
lex:acronymy 100 - 0 -
lex:demonymy 100 - 100 -
lex:synonymy 80.3 - 80.3 -
lex:semantic-opp. - 0 - 100
lex:hypernymy 100 - 100 -
TOT lexical 96.7 0 80 66.6
lexsynt:transp-head 100 - 50 -
lexsynt:verb-nom. 83.3 - 16 -
lexsynt:causative 100 - 100 -
lexsynt:paraphrase 100 - 100 -
TOT lexical-syntactic 95.8 - 66.5 -
synt:negation - 0 - 0
synt:modifier 100 0 33.3 100
synt:arg-realization 100 - 50 -
synt:apposition 100 33.3 55.5 83.3
synt:list 100 - 100 -
synt:coordination 100 - 50 -
synt:actpass-altern. 100 0 25 50
TOT syntactic 100 22.2 52.3 77.7
disc:coreference 95 - 50 -
disc:apposition 100 - 0 -
disc:anaphora-zero 100 - 33.3 -
disc:ellipsis 100 - 33.3 -
disc:statements 100 - 0 -
TOT discourse 99 - 23.3 -
reas:apposition 100 0 100 100
reas:modifier 50 - 100 -
reas:genitive 100 - 100 -
reas:meronymy 100 0 100 0
reas:quantity - 0 - 80
reas:spatial 100 - 0 -
reas:gen-inference 87.5 50 37.5 90
TOT reasoning 89.5 35.2 72.9 82.3
TOT (all phenomena) 96.2 25 59 81.2
Table 4: RTE systems? accuracy on phenomena
that generally cause contradiction (e.g. seman-
tic opposition, negation, and quantity mismatch-
ing). On the contrary, VENSES shows an oppo-
site behaviour, obtaining the best results on the
negative cases. Analysing such data it is possible
to hypothesize systems? behaviours: for example,
on the monothematic dataset EDITS produces a
pretty high number of false positives, meaning that
for this system if there are no evidences of con-
tradiction, a pair should be marked as entailment
(in order to improve such system, strategies to de-
tect contradiction pairs should be thought). On the
contrary, VENSES produces a pretty high number
of false negatives, meaning that if the system is not
able to find evidences of entailment, it assigns the
contradiction value to the pairs (for this system,
being able to correctly detect all the phenomena
contributing to entailment in a pair is fundamen-
tal, otherwise it will be marked as contradiction).
6 Related Work
Condoravdi et al (2003) first proposed contra-
diction detection as an important NLP task, then
(Harabagiu et al, 2006) provided the first em-
pirical results for it, focusing on contradiction
caused by negation, antonymy, and paraphrases.
Voorhees (2008) carries out an analysis of RTE-
3 extended task, examining systems? abilities to
detect contradiction and providing explanations
of their reasoning when making entailment deci-
sions.
Beside defining the categories of construction
from which contradiction may arise, Marneffe et
al. (2008) provide the annotation of the RTE
datasets (RTE-1 and RTE-2) for contradiction.
Furthermore, they also collect contradiction ?in
the wild? (e.g. from newswire, Wikipedia) to sam-
ple naturally occurring ones.
6
Ritter et al (2008) extend (Marneffe et al,
2008)?s analysis to a class of contradiction that can
only be detected using backgroud knowledge, and
describe a case study of contradiction detection
based on functional relations. They also automat-
ically generate a corpus of seeming contradiction
from the Web text.
7
Furthermore, some of the systems presented in
the previous editions of the RTE challenges at-
tempted specic strategies to focus on the phe-
nomenon of negation. For instance, (Snow et al,
2006) presents a framework for recognizing tex-
tual entailment that focuses on the use of syntactic
heuristics to recognize false entailment. Among
the others, heuristics concerning negation mis-
match and antonym match are defined. In (Tatu
et al, 2007) the logic representation of sentences
with negated concepts was altered to mark as
negated the entire scope of the negation. (Ferran-
dez et al, 2009) propose a system facing the en-
tailment recognition by computing shallow lexical
deductions and richer inferences based on seman-
tics, and features relating to negation are extracted.
In (Iftene et al, 2009) several rules are extracted
and applied to detect contradiction cases.
7 Conclusion
We have proposed a methodology for the qualita-
tive analysis of TE systems focusing on contradic-
tion judgments and on the linguistic phenomena
that determine such judgments. The methodology
is based on the decomposition of [T,H] pairs into
monothematic pairs, each representing one sin-
gle linguistic phenomenon relevant for entailment
6
Their corpora are available at http://www-
nlp.stanford.edu/projects/contradiction.
7
Available at http://www.cs.washington.edu/research/ au-
contraire/
92
judgment.
In particular, the phenomena from which con-
tradiction may arise and their distribution in RTE
datasets have been highlighted, and a pilot study
comparing the performancies of two RTE systems
both on monothematic pairs and on the corre-
sponding original ones has been carried out. We
discovered that, although the two systems have
similar performances in terms of accuracy on the
RTE-5 datasets, they show significant differences
in their respective abilities to correctly manage dif-
ferent linguistic phenomena that generally cause
contradiction. We hope that the analysis of con-
tradiction in current RTE datasets may bring inter-
esting elements to TE system developers to define
good strategies to manage contradiction and, more
generally, entailment judgments.
8 Acknowledgements
This work has been partially supported by the
LiveMemories project (Active Digital Memo-
ries of Collective Life) funded by the Au-
tonomous Province of Trento under the call ?Ma-
jor Projects?. We would like to thank Professor
Rodolfo Delmonte and Sara Tonelli for running
the VENSES system on our datasets.
References
Bentivogli, Luisa, Bernardo Magnini, Ido Dagan,
Hoa Trang Dang, and Danilo Giampiccolo. 2009.
The Fifth PASCAL RTE Challenge. Proceedings of
the TAC 2009 Workshop on Textual Entailment. To
appear. Gaithersburg, Maryland. 17 November.
Bentivogli, Luisa, Elena Cabrio, Ido Dagan,
Danilo Giampiccolo, Medea Lo Leggio, and
Bernardo Magnini. 2010. Building Textual En-
tailment Specialized Data Sets: a Methodology
for Isolating Linguistic Phenomena Relevant to
Inference. Proceedings of the 7th LREC conference.
Valletta, Malta. 19-21 May.
Cabrio, Elena, Milen Ognianov Kouylekov and
Bernardo Magnini, 2008. Combining Specialized
Entailment Engines for RTE-4, Proceedings of the
Text Analysis Conference (TAC 2008). Gaithersburg,
Maryland, USA, 17-18 November.
Condoravdi, Cleo, Dick Crouch, Valeria de Paiva,
Reinhard Stolle, and Daniel Bobrow. 2003. Entail-
ment, Intentionality and Text Understanding Pro-
ceedings of the HLT-NAACL 2003 Workshop on Text
Meaning. Edmonton, Alberta, Canada. 31 May.
Dagan, Ido, Bill Dolan, Bernardo Magnini, and
Dan Roth. 2009. Recognizing textual entailment:
Rational, evaluation and approaches. Natural Lan-
guage Engineering (JNLE), Volume 15, Special Is-
sue 04, October 2009, pp i-xvii. Cambridge Univer-
sity Press.
De Marneffe, Marie-Catherine, Anna N. Rafferty and
Christopher D. Manning. 2008. Finding Contradic-
tions in Text. Proceedings of ACL-08: HLT, pages
10391047. Columbus, Ohio, USA, June.
Delmonte, Rodolfo, Sara Tonelli, Rocco Tripodi.
2009. Semantic Processing for Text Entailment with
VENSES. Proceedings of the TAC 2009 Workshop
on TE. Gaithersburg, Maryland. 17 November.
Garoufi, Konstantina. 2007. Towards a Better Un-
derstanding of Applied Textual Entailment. Master
Thesis. Saarland University. Saarbr?ucken, Germany.
Ferr?andez,
?
Oscar, Rafael Mu?noz, and Manuel Palomar.
2009. Alicante University at TAC 2009: Experi-
ments in RTE. Proceedings of the TAC 2009 Work-
shop on Textual Entailment. Gaithersburg, Mary-
land. 17 November.
Harabagiu, Sanda, Andrew Hickl, and Finley Lacatusu.
2006. Negation, Contrast and Contradiction in Text
Processing. In Proceedings of AAAI-06. Boston,
Massachusetts. July 16-20.
Iftene, Adrian, Mihai-Alex Moruz 2009. UAIC
Participation at RTE-5. Proceedings of the TAC
2009 Workshop on Textual Entailment. To appear.
Gaithersburg, Maryland. 17 November.
Magnini, Bernardo, and Elena Cabrio. 2009. Com-
bining Specialized Entailment Engines. Proceed-
ings of the LTC ?09 conference. Poznan, Poland.
6-8 November.
Mehdad, Yashar, Matteo Negri, Elena Cabrio,
Milen Kouylekov, and Bernardo Magnini. 2009.
Using Lexical Resources in a Distance-Based Ap-
proach to RTE. Proceedings of the TAC 2009 Work-
shop on TE. Gaithersburg, Maryland. 17 November
2009.
Negri, Matteo, Milen Kouylekov, Bernardo Magnini,
Yashar Mehdad, and Elena Cabrio. 2009. Towards
Extensible Textual Entailment Engines: the EDITS
Package. AI*IA 2009: Emergent Perspectives in Ar-
tificial Intelligence. Lecture Notes in Computer Sci-
ence, Springer-Verlag, pp. 314-323. 2009.
Nielsen, Rodney D., Wayne Ward, and James H. Mar-
tin. 2009. Recognizing entailment in intelligent tu-
toring systems. In Ido Dagan, Bill Dolan, Bernardo
Magnini and Dan Roth (Eds.) The Journal of Natu-
ral Language Engineering, (JNLE). 15, pp 479-501.
Copyright Cambridge University Press, Cambridge,
United Kingdom.
Ritter, Alan, Doug Downey, Stephen Soderland, and
Oren Etzioni. 2008. It?s a Contradiction - No, it?s
not: A Case Study using Functional Relations. Pro-
ceedings of 2008 Conference on Empirical Methods
93
in Natural Language Processing. Honolulu, Hawaii.
25-27 October.
Romano, Lorenza, Milen Ognianov Kouylekov,
Idan Szpektor, Ido Kalman Dagan, and Al-
berto Lavelli. 2006. Investigating a Generic
Paraphrase-Based Approach for Relation Extrac-
tion. Proceedings of EACL 2006. Trento, Italy. 3-7
April.
Snow, Rion, Lucy Vanderwende, and Arul Menezes.
2006. Effectively using syntax for recognizing false
entailment. Proceedings of the main conference
on Human Language Technology Conference of the
North American Chapter of the Association of Com-
putational Linguistics. New York, 4-9 June.
Tatu, Marta, Dan I. Moldovan. 2007. COGEX at
RTE 3. Proceedings of the ACL-PASCAL Workshop
on Textual Entailment and Paraphrasing. Prague,
Czech Republic, 28-29 June.
Voorhees, Ellen M. 2008. Contradictions and Justifi-
cations: Extentions to the Textual Entailment Task.
Proceedings of ACL-08: HLT. Columbus, Ohio,
USA. 15-20 June.
Wang, Rui, and Yi Zhang. 2009. Recognizing Tex-
tual Relatedness with Predicate-Argument Struc-
tures. Proceedings of the 2009 Conference on Em-
pirical Methods in Natural Language Processing.
Singapore, 6-7 August.
94
Towards Component-Based Textual Entailment
Elena Cabrio1,2 and Bernardo Magnini1
1FBK-irst, Trento, Italy
2University of Trento, Italy
{cabrio,magnini}@fbk.eu
Abstract
In the Textual Entailment community, a shared effort towards a deeper understanding of the core
phenomena involved in textual inference is recently arose. To analyse how the common intuition
that decomposing TE would allow a better comprehension of the problem from both a linguistic
and a computational viewpoint, we propose a definition for strong component-based TE, where each
component is in itself a complete TE system, able to address a TE task on a specific phenomenon
in isolation. We review the literature according to our definition, trying to position relevant work as
more or less close to our idea of strong component-based TE. Several dimensions of the problem are
discussed: i) the implementation of system components to address specific inference types, ii) the
analysis of the phenomena relevant to component-based TE, and iii) the development of evaluation
methodologies to assess TE systems capabilities to address single phenomena in a pair.
1 Introduction
The Recognizing Textual Entailment (RTE) task (Dagan et al (2009)) aims at capturing a broad range
of inferences that are relevant for several Natural Language Processing applications, and consists of
deciding, given two text fragments, whether the meaning of one text (the hypothesis H) is entailed, i.e.
can be inferred, from another text (the text T).
Although several approaches to face this task have been experimented, and progresses in TE tech-
nologies have been shown in RTE evaluation campaigns, a renewed interest is rising in the TE community
towards a deeper and better understanding of the core phenomena involved in textual inference. In line
with this direction, we are convinced that crucial progress may derive from a focus on decomposing the
complexity of the TE task into basic phenomena and on their combination. This belief demonstrated
to be shared by the RTE community, and a number of recently published works (e.g. Sammons et al
(2010), Bentivogli et al (2010)) agree that incremental advances in local entailment phenomena are
needed to make significant progress in the main task, which is perceived as omnicomprehensive and not
fully understood yet. According to this premise, the aim of this work is to systematize and delve into the
work done so far in component-based TE, focusing on the aspects that contribute to highlight a common
framework and to define a clear research direction that deserves further investigation.
Basing on the original definition of TE, that allows to fomulate textual inferences in an application
independent way and to take advantage of available datasets for training provided in the RTE evaluation
campaigns, we intend to analyse how the common intuition of decomposing TE would allow a better
comprehension of the problem from both a linguistic and a computational viewpoint. Aspects related to
meaning compositionality, which are absent in the original proposal, could potentially be introduced into
TE and may bring new light into textual inference.
In this direction, we propose a definition for ?strong? component-based TE, where each component
is in itself a complete TE system, able to address a TE task on a specific phenomenon in isolation.
Then, we review the literature in the TE field according to our definition, trying to position relevant
work as more or less close to our idea of strong component-based TE. We have analysed and carried
out research on several dimensions of the problem, including: i) the definition and implementation of
320
system components able to address specific inference types (Section 2); ii) the analysis of the phenomena
relevant to component-based TE (Section 3); iii) the development of methodologies for the analysis of
component-based TE systems, providing a number of qualitative indicators to assess the capabilities that
systems have to address single phenomena in a pair and to combine them (Section 4).
2 Component-based TE framework
We define a component-based TE architecture as a set of clearly identifiable TE modules that can be
singly used on specific entailment sub-problems and can be then combined to produce a global entailment
judgement. Each component receives a certain example pair as input, and outputs an entailment judgment
concerning the inference type it is built to address. In other words, each component is in turn a TE
system, that performs the same task focusing only on a certain sub-aspect of entailment. According
to our proposal the following requirements need to be fulfilled in component-based TE architecture: i)
each compenent must provide a 3-way judgment (i.e. entailment, contradiction, unknown) on a specific
aspect underlying entailment, where the unknown judgement might be interpreted as the absence of the
phenomenon in the TE pair; ii) in a component-based architecure, the same inference type (e.g. temporal,
spatial inferences) can not be covered by more than one component; this is because in the combination
phase we do not want that the same phenomen is counted more than one time.
No specific constraints are defined with respect to how such components should be implemented,
i.e. they can be either a set of classifiers or rule-based modules. In addition, linguistic processing and
annotation of the input data (e.g. parsing, NER, semantic role labeling) can be required by a component
according to the phenomenon it considers. An algorithm is then applied to judge the entailment relation
between T and H with respect to that specific aspect. Unlike similarity algorithms, with whom algorithms
performing entailment are often associated in the literature, the latter are characterized by the fact that
the relation on which they are asked to judge is directional. According to such definition, the nature
of the TE task is not modified, since each sub-task independently performed by the system components
keeps on being an entailment task. Suitable composition mechanisms should then be applied to combine
the output of each single module to obtain a global judgment for a pair.
The definition presented above provides a strong interpretation of the compositional framework for
TE, that can be described as a continuum that tends towards systems developed combining identifiable
and separable components addressing specific inference types. A number of works in the literature can
be placed along this continuum, according to how much they get closer to this interpretation.
Systems addressing TE exploiting machine learning techniques with a variety of features, including
lexical-syntactic and semantic features (e.g. Kozareva and Montoyo (2006), Zanzotto et al (2007)) tend
towards the opposite extreme of this framework, since even if linguistic features are used, they bring
information about a specific aspect relevant to the inference task but they do not provide an independent
judgment on it. These systems are not modular, and it is difficult to assess the contribution of a cer-
tain feature in providing the correct overall judgment for a pair. A step closer towards the direction of
component-based TE is done by Bar-Haim et al (2008), that model semantic inference as application
of entailment rules specifying the generation of entailed sentences from a source sentence. Such rules
capture semantic knowledge about linguistic phenomena (e.g. paraphrases, synonyms), and are applied
in a transformation-based framework. Even if these rules are clearly identifiable, their application per se
does not provide any judgment about an existing entailment relation between T and H.
A component-based system has been developed by Wang and Neumann (2008), based on three spe-
cialized RTE-modules: (i) to tackle temporal expressions; (ii) to deal with other types of NEs; (iii) to deal
with cases with two arguments for each event. Besides these precision-oriented modules, two robust but
less accurate backup strategies are considered, to deal with not yet covered cases. In the final stage, the
results of all specialized and backup modules are joint together, applying a weighted voting mechanism.
Getting closer to the definition of component-based TE presented at the beginning of this Section, in
Magnini and Cabrio (2009) we propose a framework for the definition and combination of specialized
entailment engines, each of which able to deal with a certain aspect of language variability. A distance-
321
based framework is assumed, where the distance d between T and H is inversely proportional to the
entailment relation in the pair. We assume an edit distance approach (Kouylekov and Magnini (2005)),
where d is estimated as the sum of the costs of the edit operations (i.e. insertion, deletion, substitution),
which are necessary to transform T into H. Issues underlying the combination of the specialized entail-
ment engines are discussed, i.e. the order of application and the combination of individual results in
order to produce a global result.
3 Linguistic analysis and resources for component-based TE
The idea underlying component-based TE is that each component should independently solve the en-
tailment relation on a specific phenomenon relevant to inference, and then the judgments provided by
all the modules are combined to obtain an overall judgment for a pair. Our definition abstracts from the
different theories underlying the categorization of linguistic phenomena, so a straightforward relation
between TE component and linguistic phenomena cannot be defined a priori. Some work has already
been done in investigating in depth sub-aspects of entailment, and in developing ad hoc resources to
assess the impact of systems components created to address specific inference types. Earlier works in the
field (e.g. Vanderwende et al (2005), Clark et al (2007)) carried out partial analysis of the data sets in
order to evaluate how many entailment examples could be accurately predicted relying only on lexical,
syntactic or world knowledge. Bar-Haim et al (2005) defined two intermediate models of textual entail-
ment, corresponding to lexical and lexical-syntactic levels of representation, and a sample from RTE-1
data set was annotated according to each model.
A step further, other RTE groups have developed focused data sets with the aim of investigating
and experimenting on specific phenomena underlying language variability. For instance, to evaluate a
contradiction detection module Marneffe et al (2008) created a corpus where contradictions arise from
negation, by adding negative markers to the RTE-2 test data. Kirk (2009) describes his work of building
an inference corpus for spatial inference about motion, while Akhmatova and Dras (2009) experiment
current approaches on hypernymy acquisition to improve entailment classification.
The first systematic work of annotation of TE data sets is done by Garoufi (2007), that propose a
scheme for manual annotation of textual entailment data sets (ARTE). The aim is to highlight a wide
variety of entailment phenomena in the data, in relation to three levels, i.e. Alignment, Context and
Coreference. 23 different features are extracted for positive entailment annotation, while for the negative
pairs a more basic scheme is conceived. The ARTE scheme has been applied to the complete positive
entailment RTE-2 Test Set (400 pairs), and to a random 25% portion of the negative entailment Test Set.
More recently, in Bentivogli et al (2010) we present a methodology for the creation of specialized
TE data sets, made of monothematic T-H pairs, i.e. pairs in which a certain phenomenon relevant to the
entailment relation is highlighted and isolated (Magnini and Cabrio (2009)). Such monothematic pairs
are created basing on the phenomena that are actually present in the RTE pairs, so that the distribution of
the linguistic phenomena involved in the entailment relation emerges. A number of steps are carried out
manually, starting from a T-H pair taken from one of the RTE data sets, and decomposing it in a number of
monothematic pairs T-Hi, where T is the original text and Hi are the hypotheses created for each linguistic
phenomenon relevant for judging the entailment relation in T-H. Phenomena are grouped using both fine-
grained and broader categories (e.g. lexical, syntactic, lexical-syntactic, discourse and reasoning). After
applying the proposed methodology, all the monothematic pairs T-Hi relative to the same phenomenon i
are grouped together, resulting in several data sets specialized for phenomenon i. Unlike previous work
of analysis of RTE data, the result of this study is a resource that allows evaluation of TE systems on
specific phenomena relevant to inference, both when isolated and when interacting with the others (the
annotation of RTE data with the linguistic phenomena underlying the entailment/contradiction relations
in the pairs is also provided). A pilot study has been carried out on 90 pairs from RTE-5 data set.1
Highlighting the need of resources for solving textual inference problems in the context of RTE,
Sammons et al (2010) challenge the NLP community to contribute to a joint, long term effort in this
1The resulting data sets are freely available at http://hlt.fbk.eu/en/Technology/TE_Specialized_Data
322
direction, making progress both in the analysis of relevant linguistic phenomena and their interaction, and
developing resources and approaches that allow more detailed assessment of RTE systems. The authors
propose a linguistically-motivated analysis of entailment data based on a step-wise procedure to resolve
entailment decision, by first identifying parts of T that match parts of H, and then identifying connecting
structure. Their inherent assumption is that the meanings of T and H could be represented as sets of
n-ary relations, where relations could be connected to other relations (i.e. could take other relations as
arguments). The authors carried out a feasibility study applying the procedure to 210 examples from
RTE-5, marking for each example the entailment phenomena that are required for the inference.
4 Evaluation in component-based TE
The evaluation measure adopted in the RTE challenges is accuracy, i.e. the percentage of pairs correctly
judged by a TE system. In the last RTE-5 and RTE-6 campaigns, participating groups were asked to
run ablation tests, to evaluate the contribution of publicly available knowledge resources to the systems?
performances. Such ablation tests consist of removing one module at a time from a system, and rerunning
the system on the test set with the other modules, except the one tested. The results obtained were not
satisfactory, since the impact of a certain resource on system performances is really dependent on how it
is used by the system. In some cases, resources like WordNet demonstrated to be very useful, while for
other systems their contribution is limited or even damaging, as observed also in Sammons et al (2010).
To provide a more detailed evaluation of the capabilities of a TE system to address specific infer-
ence types, in Cabrio and Magnini (2010) we propose a methodology for a qualitative evaluation of TE
systems, that takes advantage of the decomposition of T-H pairs into monothematic pairs (described in
Section 3). The assumption is that the more a system is able to correctly solve the linguistic phenomena
underlying the entailment relation separately, the more the system should be able to correctly judge more
complex pairs, in which different phenomena are present and interact in a complex way. According to
such assumption, the higher the accuracy of a system on the monothematic pairs and the compositional
strategy, the better its performances on the original RTE pairs. The precision a system gains on single
phenomena should be maintained over the general data set, thanks to suitable mechanisms of meaning
combination. A number of quantitative and qualitative indicators about strength and weaknesses of TE
systems result from the application of this methodology. Comparing the qualitative analysis obtained
for two TE systems, the authors show that several systems? behaviors can be explained in terms of the
correlation between the accuracy on monothematic pairs and the accuracy on the corresponding original
pairs. In a component based framework, such analysis would allow a separate evaluation of TE modules,
focusing on their ability to correctly address the inference types they are built to deal with.
5 Conclusions
This paper provides a definition for strong component-based TE framework, exploiting the common
intuition that decomposing the complexity of TE would allow a better comprehension of the problem
from both a linguistic and a computational viewpoint. We have reviewed the literature according to
our definition, trying to position relevant works as more or less close to our idea of strong component-
based TE. We hope that the analysis of the different dimensions of the problem we provided may bring
interesting elements for future research works. In this direction, we propose a research program in
which for different applications (e.g. domain, genre) specific TE component-based architectures could
be optimized, i.e. composed by modules that meet the requirements of that specific genre/domain.
References
Akhmatova, E. and M. Dras (2009). Using hypernymy acquisition to tackle (part of) textual entailment.
In Proceedings of TextInfer 2009, Singapore. 6 August.
323
Bar-Haim, R., J. Berant, I. Dagan, I. Greental, S. Mirkin, E. Shnarch, and I. Szpektor (2008). Efficient
semantic deduction and approximate matching over compact parse forests. In Proceedings of the TAC
2008 Workshop on TE, Gaithersburg, Maryland, USA. 17 November.
Bar-Haim, R., I. Szpektor, and O. Glickman (2005). Definition and analysis of intermediate entailment
levels. In Proceedings of the ACL 2005 Workshop on Empirical Modeling of Semantic Equivalence
and Entailment, Ann Arbor, Michigan. 30 June.
Bentivogli, L., E. Cabrio, I. Dagan, D. Giampiccolo, M. L. Leggio, and B. Magnini (2010). Building
textual entailment specialized data sets: a methodology for isolating linguistic phenomena relevant to
inference. In Proceedings of LREC 2010, Valletta, Malta. 19-21 May.
Bentivogli, L., B. Magnini, I. Dagan, H. Dang, and D. Giampiccolo (2009). The fifth pascal recogniz-
ing textual entailment challenge. In Proceedings of the TAC 2009 Workshop on TE, Gaithersburg,
Maryland. 17 November.
Cabrio, E. and B. Magnini (2010). Toward qualitative evaluation of textual entailment systems. In
Proceedings of COLING 2010: Posters, Beijing, China. 23-27 August.
Clark, P., P. Harrison, J. Thompson, W. Murray, J. Hobbs, and C. Fellbaum (2007). On the role of lexical
and world knowledge in rte3. In Proceedings of the ACL-07 Workshop on TE and Paraphrasing,
Prague, Czech Republic. 28-29 June.
Dagan, I., B. Dolan, B. Magnini, and D. Roth (2009). Recognizing textual entailment: Rational, evalua-
tion and approaches. Natural Language Engineering (JNLE) 15(Special Issue 04), i?xvii.
Garoufi, K. (2007). Towards a better understanding of applied textual entailment. In Master Thesis,
Saarland University. Saarbru?cken, Germany.
Kirk, R. (2009). Building an annotated textual inference corpus for motion and space. In Proceedings of
TextInfer 2009, Singapore. 6 August.
Kouylekov, M. and B. Magnini (2005). Tree edit distance for textual entailment. In Proceedings of
RALNP-2005, Borovets, Bulgaria. 21-23 September.
Kozareva, Z. and A. Montoyo (2006). Mlent: The machine learning entailment system of the university
of alicante. In Proc. of the second PASCAL Challenge Workshop on RTE, Venice, Italy. 10 April.
Magnini, B. and E. Cabrio (2009). Combining specialized entailment engines. In Proceedings of LTC?09,
Poznan, Poland. 6-8 November.
Marneffe, M. D., A. Rafferty, and C. Manning (2008). Finding contradictions in text. In Proceedings of
ACL-08, Columbus, OH, 15-20 June.
Sammons, M., V. Vydiswaran, and D. Roth (2010). Ask not what textual entailment can do for you... In
Proceedings of ACL-10, Uppsala, Sweden. 11-16 July.
Vanderwende, L., D. Coughlin, and B. Dolan (2005). What syntax can contribute in entailment task. In
Proceedings of the First PASCAL Challenges Workshop on RTE, Southampton, U.K., 11-13 April.
Wang, R. and G. Neumann (2008). An accuracy-oriented divide-and-conquer strategy. In Proceedings
of the TAC 2008 Workshop on TE, Gaithersburg, Maryland. 17 November.
Zanzotto, F., M. Pennacchiotti, and A. Moschitti (2007). Shallow semantics in fast textual entailment
rule learners. In Proceedings of the ACL-PASCAL Workshop on TE and Paraphrasing, Prague, Czech
Republic. 23-30 June.
324
JEP-TALN-RECITAL 2012, Atelier DEFT 2012: D?fi Fouille de Textes, pages 15?24,
Grenoble, 4 au 8 juin 2012. c?2012 ATALA & AFCP
Key-concept extraction from French articles with KX
Sara Tonelli1 Elena Cabrio2 Emanuele Pianta1
(1) FBK, via Sommarive 18, Povo (Trento), Italy
(2) INRIA, 2004 Route des Lucioles BP93, Sophia Antipolis cedex, France
satonelli@fbk.eu, elena.cabrio@inria.fr, pianta@fbk.eu
R?SUM?
Nous pr?sentons une adaptation du syst?me KX qui accomplit l?extraction non supervis?e et
multilingue des mots-cl?s, pour l?atelier d??valuation francophone en fouille de textes (DEFT
2012). KX s?lectionne une liste de mots-cl?s (avec leur poids) dans un document, en combinant
des annotations linguistiques de base avec des mesures statistiques. Pour l?adapter ? la langue
fran?aise, un analyseur morphologique pour le Fran?ais a ?t? ajout? au syst?me pour d?river les
patrons lexicaux. De plus, des param?tres comme les seuils de fr?quence pour l?extraction de
collocations, et les index de relevance des concepts-cl?s ont ?t? calcul?s et fix?s sur le corpus
d?apprentissage. En concernant les pistes de DEFT 2012, KX a obtenu de bons r?sultats (Piste 1 -
avec terminologie : 0.27 F1 ; Piste 2 : 0.19 F1) en demandant un effort r?duit pour l?adaptation
du domaine et du langage.
ABSTRACT
We present an adaptation for the French text mining challenge (DEFT 2012) of the KX system
for multilingual unsupervised key-concept extraction. KX carries out the selection of a list of
weighted keywords from a document by combining basic linguistic annotations with simple
statistical measures. In order to adapt it to the French language, a French morphological
analyzer (PoS-Tagger) has been added into the extraction pipeline, to derive lexical patterns.
Moreover, parameters such as frequency thresholds for collocation extraction and indicators for
key-concepts relevance have been calculated and set on the training documents. In the DEFT
2012 tasks, KX achieved good results (i.e. 0.27 F1 for Task 1 - with terminological list, and 0.19
F1 for Task 2) with a limited additional effort for domain and language adaptation.
MOTS-CL?S : Extraction de mots-cl?s, patrons linguistiques, terminologie.
KEYWORDS: Key-concept extraction, linguistic patterns, terminology.
1 Introduction
Key-concepts are simple words or phrases that provide an approximate but useful characterization
of the content of a document, and offer a good basis for applying content-based similarity
functions. In general, key-concepts can be used in a number of interesting ways both for human
and automatic processing. For instance, a quick topic search can be carried out over a number
15
of documents indexed according to their key-concepts, which is more precise and efficient
than full-text search. Also, key-concepts can be used to calculate semantic similarity between
documents and to cluster the texts according to such similarity (Ricca et al, 2004). Furthermore,
key-concepts provide a sort of quick summary of a document, thus they can be used as an
intermediate step in extractive summarization to identify the text segments reflecting the content
of a document. (Jones et al, 2002), for example, exploit key-concepts to rank the sentences in a
document by relevance, counting the number of key-concept stems occurring in each sentence.
In the light of the increasing importance of key-concepts in several applications, from search
engines to digital libraries, a recent task for the evaluation of key-concept extraction was also
proposed at SemEval-2010 campaign (Kim et al, 2010)
In this work, we present an adaptation of the KX system for multilingual key-concept extraction
(Pianta et Tonelli, 2010) for the French text mining challenge (DEFT 2012) task. A preliminary
version of KX for French took part in the DEFT 2011 campaign on ?Abstract ? article matching?
(Tonelli et Pianta, 2011), and achieved good performances in both tracks (0.990 and 0.964 F1
respectively).
Compared to the previous version of KX, we have now integrated into the extraction pipeline a
French morphological analyzer (Chrupala et al, 2008). This allows us to exploit morphological
information while selecting candidate key-concepts, while in the version used at DEFT 2011 the
selection was made using regular expressions and black lists.
The paper is structured as follows : in Section 2 we detail the architecture of KX (i.e. our key-
concepts extraction tool), providing an insight into its parameters configuration. In Section 3 we
present the setting defined and adopted for the DEFT 2012 task, while in Section 4 we report the
system performances on the training and on the test sets. Finally, we draw some conclusions, and
discuss future improvements of our approach in Section 5.
2 Key-concept extraction with KX
This section describes in details the basic KX architecture for unsupervised key-concept extraction.
KX can handle texts in several languages (i.e. English, Italian, French, Finnish and Swedish), and
it is distributed with the TextPro NLP Suite1 (Pianta et al, 2008). KX architecture is the same
across all languages, except for the module selecting multiword expressions, that is based on PoS
tags (this is the only language-dependent part of the system). In order to perform this selection,
a morphological analyzer/PoS tagger has been integrated for each of the five languages, and
some selection rules have been manually defined. More details on the French rules are reported
in Section 2.2 and in Section 3.
2.1 Pre-processing of the reference corpus
If a domain corpus is available, the extraction of key-concepts from a single document can be
preceded by a pre-processing step, during which key-concepts are extracted from the corpus and
their inverse document frequency (IDF) at corpus level is computed by applying the standard
formula :
1
http://textpro.fbk.eu/
16
I DFk = log NDFk
where N is the number of documents in the corpus, and DFk is the number of documents in thecorpus that contain the key-concepts k. The I DF of a rare term tends to be high, while the I DF
of a frequent one is likely to be low. Therefore, I DF may be a good indicator for distinguishing
between common, generic words and specific ones, which are good candidates for being a
key-concept. For DEFT 2012, we have used as a reference corpus all the documents contained in
the training and in the test sets (468 documents in total).
2.2 Key-concept extraction
Figure 1 shows KX work-flow for the key-concept extraction process : starting from a document,
a list of key-concepts ranked by relevance is provided as the output of the system. The same
work-flow applies both to i) the extraction of key-concepts from a single document, and to ii) the
extraction of different statistics including IDF from a reference corpus, which can be optionally
used as additional information when processing a single document. For more information, see
above and Section 2.3.
FIG. 1 ? Key-concept extraction workflow with KX
As a first step, the system takes a document in input and tokenize the text. Then, all possible
n-grams composed by any token sequence are extracted, for instance ??clipse de soleil?, ?tous les?,
?ou chacun?. The user can set the max length of the selected n-grams : for DEFT 2012 we set such
length to six.
Then, from the n-gram list a sublist of multiword expressions (MWE) is derived, i.e. combinations
of words expressing a unitary concept, for example ?proc?s de travail? or ??conomie politique?.
17
In the selection step, the user can choose to rely only on local (document) evidence or to make
use also of global (corpus) evidence. As for the first case, a frequency threshold called MinDoc
can be set, which corresponds to the minimum number of occurrences of n-grams in the current
document. If a reference corpus is also available, another threshold can be added, MinCorpus,
which corresponds to the minimum number of occurrences of an n-gram in the corpus. KX marks
an n-gram in a document as a multiword term if it occurs at least MinCorpus times in the
corpus or at least MinDoc times in the document. The two parameters depend on the size of the
reference corpus and the document respectively. In our case, the corpus was the set of documents
used in the training and in the test set (see Section 2.1).
A similar, frequency-based, strategy is used to solve ambiguities in how sequences of contiguous
multiwords should be segmented. For instance, given the sequence ?retour des bonnes mani?res?
we need to decide whether we recognize ?retour des bonnes? or ?bonnes mani?res?. To this
purpose, the strength of each alternative MWE is calculated as follows, and then the stronger
one is selected.
St reng thcol loc = docF requenc y ? corpusF requenc y
In the next step, the single words and the MWEs are ranked by frequency to obtain a first list
of key-concepts. Thus, frequency is the baseline ranking parameter, based on the assumption
that important concepts are mentioned more frequently than less important ones. Frequency is
normalized by dividing the number of key-concept occurrences by the total number of tokens in
the current document.
As shown in Figure 1, the first key-concepts list is obtained by applying black and white lists
almost at every step of the process. A black list is applied to discard n-grams containing one of
the language-specific stopwords defined by the user, for example ?avons?, ?peut?, ?puis?, ?parce?.
Also single words corresponding to stopwords are discarded when the most frequent tokens
are included into the first key-concept list. For example, in French we may want to exclude all
key-concepts containing the words ?toi?, ?tr?s?, ?finalement?, etc.
When deriving multiword expressions (MWEs) from the n-gram list, KX applies another selection
strategy. This selection is crucial because only MWEs are selected as candidate key-concepts, since
they correspond to combinations of words expressing a unitary concept, for example ?r?gime de
despotisme familial? or ?reproduction mat?rielle?. The n-grams are analyzed with the Morfette
morphological analyzer (Chrupala et al, 2008) in order to select as multiword expressions only
the n-grams that match certain lexical patterns (i.e. part-of-speech). This is the so-called linguistic
filter. For example, one of the patterns admitted for 3-grams is the following :
[SP]? [O]? [SP]
This means that a 3-gram is a candidate multiword term if it is composed by a single or plural
noun (S and P respectively), followed by a preposition (defined as O), followed by another noun.
This is matched for example by the 3-gram ?proc?s [S] de [O] travail [S]?.
Finally, black and white lists can be manually compiled also for key-concepts, to define expressions
that should never be selected as relevant key-concepts, as well as terms that should always be
included in the key-concept rank. For example, the preposition ?de? is very frequent in documents,
so it can happen that it is selected as single-word key-concept. In order to avoid this, ?de? can be
included in the key-concept black list.
18
2.3 First key-concept ranking
Different techniques are used to re-rank the frequency-based list of key-concepts obtained in
the previous step according to their relevance. If a reference corpus is available, as in our case,
additional information can be used to understand which key-concepts are more specific to a
document, and therefore are more likely to be relevant for such document.
In order to find the best ranking mechanism, and to tailor it to the type of key-concepts we want
to extract, the following parameters can be set :
Key-concept IDF : This parameter takes into account the fact that, given a data collection, a
concept that is mentioned in many documents is less relevant to our task than a concept oc-
curring in few documents. To activate it, a reference corpus must undergo a pre-processing
step in which the key-concepts are extracted from each document in the corpus, and the
corresponding inverse document frequency (IDF) is computed, as described in Section 2.1.
When this parameter is activated, for each key-concept found in the current document, its
I DF computed over the reference corpus is retrieved and multiplied by the key-concept
frequency at document level.
Key-concept length : Number of tokens in a key-concept. Concepts expressed by longer phrases
are expected to be more specific, and thus more informative. When this parameter is
activated, the frequency is multiplied by the key-concept length. For example, if ?expression
verbale? has frequency 6 and ?expression verbale des ?motions? has frequency 5, the
activation of the key-concept length parameter gives ?expression verbale? = 6 * 2 = 12 and
?expression verbale des ?motions? = 5 * 4 = 20. In this way, the 4-gram is assigned a higher
ranking than the 2-gram.
Position of first occurrence : Important concepts are expected to be mentioned before less
relevant ones. If the parameter is activated, the frequency score will be multiplied by the
PosFact factor computed as :
PosFact =
DistF romEnd
Max Index
2
where Max Index is the length of the current document, and DistF romEnd is Max Index
minus the position of the first key-concept occurrence in the text.
A configuration file allows the user to independently activate such parameters. The key-concept
relevance is then calculated by multiplying the normalized frequency of a key-concept by the
score obtained by each active parameter. We eventually obtain a ranking of key-concepts ordered
by relevance. The user can also set the number of top ranked key-concepts to consider as best
candidates.
2.4 Final key-concept ranking
Section 2.3 described the first set of ranking strategies, that can be optionally followed by another
set of operations to adjust the preliminary ranking. Again, such operations can be independently
activated through a separate configuration file. The parameters have been introduced to deal
19
with the so-called nested key-concepts (Frantzi et al, 2000), i.e. those that appear within other
longer candidate key-concepts. After the first ranking, which is still influenced by the key-concept
frequency, nested (shorter) key-concepts tend to have a higher ranking than the containing
(longer) ones, because the former are usually more frequent than the latter. However, in some
settings, for example in scientific articles, longer key-concepts are generally preferred over
shorter ones because they are more informative and specific. In such cases, the user may want
to adjust the ranking in order to give preference to longer key-concepts and to reduce or set to
zero the score of nested key-concepts. These operations are allowed by activating the following
parameters :
Shorter concept subsumption : It happens that two concepts can occur in the key-concept list,
such that one is a specification of the other. Concept subsumption and boosting (see below)
are used to merge or rerank such couples of concepts. If a key-concept is (stringwise)
included in a longer key-concept with a higher frequency-based score, the score of the
shorter key-concept is transferred to the count of the longer one. For example, if ?expression
verbale? has frequency 4 and ?expression verbale des ?motions? has frequency 6, by activa-
ting this parameter the relevance of ?expression verbale des ?motions? is 6 + 4 = 10, while
the relevance of ?expression verbale? is set to zero. The idea behind this strategy is that
nested key-concepts can be deleted from the final key-concept list without losing relevant
information, since their meaning is nevertheless contained in the longer key-concepts.
Longer concept boosting : This parameter applies in case a key-concept is (stringwise) included
in a longer key-concept with a lower relevance. Its activation should better balance the
ranking in order to take into account that longer n-grams are generally less frequent, but
not less relevant, than shorter ones. The parameter is available in two different versions,
having different criteria for computing such boosting. With the first option, the average
score between the two key-concepts relevance is computed. Such score is assigned to the
less frequent key-concepts and subtracted from the frequency score of the higher ranked
one. With the second option, the longer key-concepts is assigned the frequency of the shorter
one. In none of the two variants key-concepts are deleted from the relevance list, as it
happens by activating the Shorter concept subsumption parameter.
For example, if ?expression verbale? has score 6 and ?expression verbale des ?motions? has
score 4, by activating the first option of this parameter the relevance of ?expression verbale?
becomes 6 - ((6 + 4) / 2) = 1, while the relevance of ?expression verbale des ?motions? is
set to 5, i.e. (6 + 4) / 2 .
With the second option, both the relevance of ?expression verbale des ?motions? and of
?expression verbale? is set to 6.
The examples above show that these parameters set by the user can change the output of the
ranking by deleting some entries and boosting some others. After applying one cycle of subsump-
tion/boosting, the order of the concepts can dramatically change, producing the conditions for
further subsumption/boosting of concepts. The user can set the number of iterations for the
application of this re-ranking mechanism, and each cycle increases the impact of the re-ranking
on the key-concept list. The parameters can be activated together and in different combinations.
If all parameters are set, the short concept subsumption procedure is applied first, then the longer
concept boosting is run on the output of the first re-ranking, so that the initial relevance-based
list goes through two reordering steps.
20
3 KX configuration for the DEFT 2012 task
As introduced before (Section 2.2), to port KX to the French language and, in particular, to adapt
it to the DEFT 2012 task, the Morfette morphological analyzer (Chrupala et al, 2008) has been
integrated into the system, to select as multiword expressions only the n-grams matching certain
lexical patterns (i.e. part-of-speech). Such lexical patterns are learned on the gold standard, and
manually formalized and added into the system as a linguistic filter. In order to speed up this
process, we took advantage of the set of lexical patterns defined for Italian, and we checked
if they could be applied also for French. Moreover, new patterns were added in compliance
with DEFT training data requirements. For example, the following n-grams have been added as
allowed patterns (i.e. candidate multiword terms) :
? 6-grams : [SP]-[O]-[SP]-[O]-[S]-[JK], where S and P correspond to singular or plural nouns,
O to the prepositions (also in combination with the article), and J and K to singular or plural
adjectives (e.g. ?soul?vement [S] des [O] M?tis [S] dans l? [O] Ouest [S] canadien [J]?) ;
? 5-grams : [SP]-[O]-[SP]-[O]-[P], (e.g. ?gestion [S] des [O] troupeaux [P] de [O] rennes [P]?) ;
? 4-grams : [SP]-[JK]-[0]-[S], (e.g. ?histoire [S] canonique [J] de la [0] traduction [S]?) ;
? 3-grams : [S]-[SP]-[JK], (e.g. ?fran?ais [S] langue [S] premi?re [J]?).
We compiled black lists both for common French stopwords (containing e.g. articles, prepositions,
a few numbers, and functional verbs) and stopphrases (prepositional structures such as ?au sujet
de?, ?en dehors de?, ?en face de?), since we do not want them to be selected as key-concepts.
As for the IDF value mentioned in Section 2.1, it has been computed for 86,419 key-concepts
extracted from DEFT 2012 training and test set. Among the key-concepts with the highest
IDF (i.e. best candidates for final selection), we find ?inversions culturelles?, ?hypertextualit??,
?am?nagement terminologique?. These are key-concepts that occur only in one document of the
reference corpus. Among the key-concepts with a low IDF, instead, we find very common terms
and expressions such as ?rapport?, ?partie? and ?exemple?, which are likely to be discarded as
key-concepts.
The standard KX architecture has also been adapted to one of the two tracks of DEFT 2012,
namely the one in which a terminological list was provided. For that track, the set of documents
to be processed was accompanied by a list of domain terminology. By comparing the gold key-
concepts in the training set with this list, we observed that all terms in the terminology were
also gold key-concepts. Therefore, we modified KX so that, in the final re-ranking, the candidate
key-concepts being present in the terminology list were significantly boosted. This adaptation
lead to an improvement of almost 0.8 P/R/F1 on the test set (see Section 4).
4 Evaluation
Since KX does not require supervision, we used the training set to identify the best parameter
setting, which was then applied in the test phase. The results obtained on the training and on the
test set are discussed in the following subsections.
21
4.1 System evaluation on the training set
We report in Table 1 the best parameter setting on the training documents. Note that the reported
evaluation measures have been computed using our own scorer, which counts as correct each
key-concept exactly matching with the gold standard (case-insensitive). The results reported for
the test set, instead, have been computed by the task organizers with another scorer, which may
apply a slightly different strategy.
We extracted for each document the top k key-concepts, with k being the number of key-
concepts assigned to each document in the training set (this number may vary from document to
document). For this reason, Precision and Recall are the same.
Task 1 : Task 2 :
with terminology w/o terminology
KX Parameters
1. MinCorpus 8 8
2. MinDoc 3 3
3. Use corpusId f Yes Yes
4. Multiply relevance by key-concept length Yes Yes
5. Consider position of first occurrence No No
6. Shorter concept subsumption No No
7. Longer concept boosting No No
8. Boost key-concepts in terminology list Yes No
P/R/F1 on training set F1 0.18 F1 0.15
TAB. 1 ? Best parameter combination for training set
The results obtained on the training set suggest that the key-concepts required in this task should
not be too specific, since the parameters aimed at preferring specific (i.e. longer) key-concepts
are not activated in the best performing setting (we refer to parameters n. 6 and 7 in the above
Table). Also the position of the first key-concept occurrence is not relevant, since the parameter
n. 5 is not part of the best setting. This is in contrast with KX setting used for Semeval 2010
(Pianta et Tonelli, 2010). In that case, boosting the relevance of specific key-concepts, and of
those occurring in the article abstract had a positive effect on the final performance. Note also
that the performance measured on French documents in DEFT is around 0.10 points lower
than that achieved at Semeval on English scientific articles. We believe that this is not due to
a different system performance on the two languages, but rather on the evaluation strategy,
because Semeval scorer required the key-concepts to be stemmed and took into account some
syntactic variations of the same key-concept (Kim et al, 2010).
4.2 System evaluation on the test set
For each task, we submitted three system runs, testing different parameter combinations. Specifi-
cally, for Task 1 (with terminological list), the three runs had the following configurations :
1. Parameter setting reported in Section 4.1 (with boosting of key-concepts in terminology
22
list) ;
2. Parameter setting as in Section 4.1 but Consider position of first occurrence activated (with
boosting of key-concepts in terminology list) ;
3. Parameter setting as in Section 4.1 but terminology list is not taken into account.
As for Task 2 (without terminological list), the three runs had the following configurations :
1. Parameter setting reported in Section 4.1 ;
2. Parameter setting as in Section 4.1 but Consider position of first occurrence activated ;
3. Parameter setting reported in Section 4.1 but system run only on article abstracts.
Task 1 : Task 2 :
with terminology w/o terminology
KX Run 1 0.2682 0.1880
KX Run 2 0.2737 0.1901
KX Run 3 0.1976 0.1149
TAB. 2 ? KX performance on test set
We decided to activate the parameter Consider position of first occurrence, even if it was not
part of the best performing setting in the training phase, because it achieved good results in
the Semeval 2010 challenge on English. The results confirm that, in both tasks, this yielded a
(limited) improvement.
In both tasks, the third run was used to exploit configurations that were not tested in the training
phase. In Task 1, the third run was obtained without taking into account the terminology list.
The difference in performance between Run 1 and Run 3 confirms that this information is indeed
very relevant. In Task 2, the third run concerned the extraction of key-concepts only from the
abstracts, and not from the whole articles. Also in this case, the initial hypothesis that the abstract
may contain all relevant key-concepts proved to be wrong.
At DEFT 2012, 10 teams submitted at least one run in Task 1, and 9 teams in Task 2. The best
performing run of KX was ranked 6th out of 10 in Task 1 and 5th out of 9 in Task 2. In Task 1
the mean F1 for the best submission of each team was 0.3575, the median was 0.3321 and the
standard deviation 0.2985, with system performances ranging from 0.0428 (lowest performance)
to 0.9488 (best run). In Task 2 the mean F1 for the best submission of each team was 0.2045,
the median was 0.1901 and the standard deviation 0.1522, with system performances ranging
from 0.0785 (lowest performance) to 0.5874 (best run).
These results show that the use of terminology significantly improves the overall system perfor-
mance, as confirmed in Table 2. However, KX seems to be more competitive in the second task
compared to other systems. This confirms that KX strength lies in its domain-independence and
in the fact that is does not require any additional information to achieve a good performance.
Furthermore, we believe that the second task is more realistic than the first one : in a real
application scenario, it is unlikely that a terminological list, containing only the key-concepts to
be identified, is actually available.
23
5 Conclusions
In this paper, we presented the French version of the KX system, and we described the experiments
we carried out for our participation at DEFT 2012. KX achieved good results with few adjustments
of the parameter setting and a limited additional effort for domain and language adaptation. Our
system requires no supervision and its English and Italian versions are distributed as a standalone
key-concept extractor. Its extension, which takes into account a reference terminological list,
proved to be effective and achieved a moderate improvement in the first task of the evaluation
challenge.
A limitation of our system is that it is not able to identify key-concepts that are not present
in the document. This kind of concepts amounted to around 20% of the gold key-concepts in
the training set, and this feature strongly affected the outcome of our evaluation. A strategy to
exploit external knowledge sources to extract common subsumers of the given key-concepts may
be investigated in the future.
Acknowledgements
The development of KX has been partially funded by the European Commission under the contract
number FP7-248594, PESCaDO project.
R?f?rences
CHRUPALA, G., DINU, G. et van GENABITH, J. (2008). Learning Morphology with Morfette. In
Proceedings of the 6th International Conference on Languages Resources and Evaluations (LREC
2008), Marrakech, Morocco.
FRANTZI, K., ANANIADOU, S. et MIMA, H. (2000). Automatic recognition of multi-word terms :
the C-value/NC-value. Journal of Digital Libraries, 3(2):115?130.
JONES, S., LUNDY, S. et PAYNTER, G. (2002). Interactive Document Summarisation Using Auto-
matically Extracted Keyphrases. In Proceedings of the 35th Hawaii International Conference on
System Sciences, Hawaii.
KIM, S. N., MEDELYAN, O., KAN, M.-Y. et BALDWIN, T. (2010). SemEval-2010 Task 5 : Automatic
keyphrase extraction from scientific articles. In Proceedings of SemEval 2010, Task 5 : Keyword
extraction from Scientific Articles, Uppsala, Sweden.
PIANTA, E., GIRARDI, C. et ZANOLI, R. (2008). The TextPro tool suite. In Proceedings of the 6th
Language Resources and Evaluation Conference (LREC), Marrakech, Morocco.
PIANTA, E. et TONELLI, S. (2010). KX : A flexible system for Keyphrase eXtraction. In Proceedings
of SemEval 2010, Task 5 : Keyword extraction from Scientific Articles, Uppsala, Sweden.
RICCA, F., TONELLA, P., GIRARDI, C. et PIANTA, E. (2004). An empirical study on keyword-based
web site clustering. In Proceedings of the 12th IWPC, Bari, Italy.
TONELLI, S. et PIANTA, E. (2011). Matching documents and summaries using key-concepts. In
Proceedings of DEFT 2011, Montpellier, France.
24
Proceedings of the 3rd Workshop on the People?s Web Meets NLP, ACL 2012, pages 34?43,
Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational Linguistics
Extracting Context-Rich Entailment Rules from Wikipedia Revision History
Elena Cabrio
INRIA
2004, route de Lucioles BP93
06902 Sophia Antipolis, France.
elena.cabrio@inria.fr
Bernardo Magnini
FBK
Via Sommarive 18
38100 Povo-Trento, Italy.
magnini@fbk.eu
Angelina Ivanova
University of Oslo
Gaustadalle?en 23B
Ole-Johan Dahls hus
N-0373 Oslo, Norway.
angelii@ifi.uio.no
Abstract
Recent work on Textual Entailment has shown
a crucial role of knowledge to support entail-
ment inferences. However, it has also been
demonstrated that currently available entail-
ment rules are still far from being optimal. We
propose a methodology for the automatic ac-
quisition of large scale context-rich entailment
rules from Wikipedia revisions, taking advan-
tage of the syntactic structure of entailment
pairs to define the more appropriate linguis-
tic constraints for the rule to be successfully
applicable. We report on rule acquisition ex-
periments on Wikipedia, showing that it en-
ables the creation of an innovative (i.e. ac-
quired rules are not present in other available
resources) and good quality rule repository.
1 Introduction
Entailment rules have been introduced to provide
pieces of knowledge that may support entailment
judgments (Dagan et al, 2009) with some degree of
confidence. More specifically, an entailment rule is
defined (Szpektor et al, 2007) as a directional rela-
tion between two sides of a pattern, corresponding
to text fragments with variables (typically phrases
or parse sub-trees). The left-hand side (LHS) of
the pattern entails the right-hand side (RHS) of the
same pattern under the same variable instantiation.
Given the Text-Hypothesis pair (T-H) in Example 1:
Example 1.
T: Dr. Thomas Bond established a hospital in Philadel-
phia for the reception and cure of poor sick persons.
H: Dr. Bond created a medical institution for sick people.
a (directional) lexical rule like:
1) LHS: hospital? RHS: medical institution
probability: 0.8
brings to a TE system (aimed at recognizing that
a particular target meaning can be inferred from
different text variants in several NLP application,
e.g. Question Answering or Information Extraction)
the knowledge that the word hospital in Text can
be aligned, or transformed, into the word medical
institution in the Hypothesis, with a probability 0.8
that this operation preserves the entailment relation
among T and H. Similar considerations apply for
more complex rules involving verbs, as:
2) LHS: X establish Y ? RHS: X create Y
probability: 0.8
where the variables may be instantiated by any tex-
tual element with a specified syntactic relation with
the verb. Both kinds of rules are typically ac-
quired either from structured sources (e.g. WordNet
(Fellbaum, 1998)), or from unstructured sources ac-
cording for instance to distributional properties (e.g.
DIRT (Lin and Pantel, 2001)). Entailment rules
should typically be applied only in specific contexts,
defined in (Szpektor et al, 2007) as relevant con-
texts. Some existing paraphrase and entailment ac-
quisition algorithms add constraints to the learned
rules (e.g. (Sekine, 2005), (Callison-Burch, 2008)),
but most do not. Because of a lack of an adequate
representation of the linguistic context in which the
34
rules can be successfully applied, their concrete use
reflects this limitation. For instance, rule 2 (ex-
tracted from DIRT) fails if applied to ?The mathe-
matician established the validity of the conjecture?,
where the sense of establish is not a synonym of
create (but of prove, demonstrate), decreasing sys-
tem?s precision. Moreover, these rules often suffer
from lack of directionality, and from low accuracy
(i.e. the strength of association of the two sides of
the rule is often weak, and not well defined). Such
observations are also in line with the discussion on
ablation tests carried out at the last RTE evaluation
campaigns (Bentivogli et al, 2010).
Additional constraints specifying the variable
types are therefore required to correctly instantiate
them. In this work, we propose to take advantage
of Collaboratively Constructed Semantic Resources
(CSRs) (namely, Wikipedia) to mine information
useful to context-rich entailment rule acquisition.
More specifically, we take advantage of material ob-
tained through Wikipedia revisions, which provides
at the same time real textual variations from which
we may extrapolate the relevant syntactic context,
and several simplifications with respect to alterna-
tive resources. We consider T-H pairs where T is a
revision of a Wikipedia sentence and H is the origi-
nal sentence, as the revision is considered more in-
formative then the revised sentence.
We demonstrate the feasibility of the proposed
approach for the acquisition of context-rich rules
from Wikipedia revision pairs, focusing on two case
studies, i.e. the acquisition of entailment rules for
causality and for temporal expressions. Both phe-
nomena are highly frequent in TE pairs, and for both
there are no available resources yet. The result of
our experiments consists in a repository that can be
used by TE systems, and that can be easily extended
to entailment rules for other phenomena.
The paper is organized as follows. Section 2
reports on previous work, highlighting the speci-
ficity of our work. Section 3 motivates and de-
scribes the general principles underlying our ac-
quisition methodology. Section 4 describes in de-
tails the steps for context-rich rules acquisition from
Wikipedia pairs. Section 5 reports about the experi-
ments on causality and temporal expressions and the
obtained results. Finally, Section 6 concludes the pa-
per and suggests directions for future improvements.
2 Related work
The use of Wikipedia revision history in NLP tasks
has been previously investigated by a few works.
In (Zanzotto and Pennacchiotti, 2010), two versions
of Wikipedia and semi-supervised machine learning
methods are used to extract large TE data sets sim-
ilar to the ones provided for the RTE challenges.
(Yatskar et al, 2010) focus on using edit histories
in Simple English Wikipedia to extract lexical sim-
plifications. Nelken and Yamangil (2008) compare
different versions of the same document to collect
users? editorial choices, for automated text correc-
tion, sentence compression and text summarization
systems. (Max and Wisniewski, 2010) use the revi-
sion history of French Wikipedia to create a corpus
of natural rewritings, including spelling corrections,
reformulations, and other local text transformations.
In (Dutrey et al, 2011), a subpart of this corpus is
analyzed to define a typology of local modifications.
Because of its high coverage, Wikipedia is used
by the TE community for lexical-semantic rules ac-
quisition, named entity recognition, geographical in-
formation1 (e.g. (Mehdad et al, 2009), (Mirkin et
al., 2009), (Iftene and Moruz, 2010)), i.e. to provide
TE systems with world and background knowledge.
However, so far it has only been used as source of
factual knowledge, while in our work the focus is on
the acquisition of more complex rules, concerning
for instance spatial or temporal expressions.
The interest of the research community in produc-
ing specific methods to collect inference and para-
phrase pairs is proven by a number of works in the
field, which are relevant to the proposed approach.
As for paraphrase, Sekine?s Paraphrase Database
(Sekine, 2005) is collected using an unsupervised
method, and focuses on phrases connecting two
Named Entities. In the Microsoft Research Para-
phrase Corpus2, pairs of sentences are extracted
from news sources on the web, and manually an-
notated. As for rule repositories collected using dis-
tributional properties, DIRT (Discovery of Inference
Rules from Text)3 is a collection of inference rules
1http://www.aclweb.org/aclwiki/index.
php?title=RTE_Knowledge_Resources
2http://research.microsoft.com/en-us/
downloads
3http://www.aclweb.org/aclwiki/index.
php?title=DIRT_Paraphrase_Collection
35
(Lin and Pantel, 2001), obtained extracting binary
relations between a verb and an object-noun (or a
small clause) from dependency trees. Barzilay and
Lee (2003) present an approach for generating sen-
tence level paraphrases, learning structurally simi-
lar patterns of expression from data and identifying
paraphrasing pairs among them using a comparable
corpus. Since the data sets cited so far are para-
phrase collections, rules are bidirectional, while one
of the peculiarities of the entailment relation is the
directionality, addressed in our work.
Aharon et al (2010) presented FRED, an algo-
rithm for generating entailment rules between pred-
icates from FrameNet. Moreover, the TEASE col-
lection of entailment rules (Szpektor et al, 2004)
consists of 136 templates provided as input, plus
all the learned templates. Their web-based extrac-
tion algorithm is applied to acquire verb-based ex-
pressions. No directionality of the pairs is specified,
but additional guessing mechanisms it are proposed.
In (Szpektor and Dagan, 2008), two approaches for
unsupervised learning of unary rules (i.e. between
templates with a single variable) are investigated.
In (Zhao et al, 2009), a pivot approach for ex-
tracting paraphrase patterns from bilingual paral-
lel corpora is presented, while in (Callison-Burch,
2008) the quality of paraphrase extraction from par-
allel corpora is improved by requiring that phrases
and their paraphrases have the same syntactic type.
Our approach is different from theirs in many re-
spects: their goal is paraphrase extraction, while we
are extracting directional entailment rules; as textual
resources for pattern extraction they use parallel cor-
pora (using patterns in another language as pivots),
while we rely on monolingual Wikipedia revisions
(taking benefit from its increasing size); the para-
phrases they extract are more similar to DIRT, while
our approach allows to focus on the acquisition of
rules for specific phenomena frequent in entailment
pairs, and not covered by other resources.
3 General methodology
The general approach we have implemented is based
on the idea that, given a seed word, we extract all
the entailment rules from Wikipedia revision pairs
where the seed word appears as the head of the rule
either in T or H. The head is the non-variable part
of the rule on which the other parts depend (i.e. the
word establish is the head of rule 2).
Entailment judgment. A Wikipedia revision may
be consistent with the original sentence, bringing to
an entailment relation, or it may introduce inconsis-
tency, expressing a contradiction w.r.t. the original
sentence. We manually checked a sample of revision
pairs (?200), and we found out that in about 95%
of the revisions entailment is preserved, in line with
(Zanzotto and Pennacchiotti, 2010). We assume this
one as the default case in our experiments.
Monothematic pairs. The capability of automatic
extraction of entailment rules is affected by the com-
plexity of the pairs from which we extract the rules.
In our experiments we take advantage of revision
pairs with minimal difference between T and H, and
we assume that for such pairs we have only one rule
to extract. Under this perspective, T-H pairs derived
from Wikipedia revisions have strong similarity with
monothematic pairs (i.e. pairs where the entailment
judgment is due to only one linguistic phenomenon,
as suggested in (Bentivogli et al, 2010)). Section
4.2 describes the algorithm for filtering out revision
pairs with more than one phenomenon.
Directionality. A Wikipedia revision, in principle,
may be interpreted as either T entailing H, or as H
entailing T. However, through a manual inspection
of a revision sample (?200 pairs), it came out that
in most of the cases the meaning of the revised sen-
tence (T) entails the meaning of the original one (H).
Given such observation, for our experiments (Sec-
tions 4 and 5) we assume that for all revision pairs,
the revised sentence (T) entails the original one (H).
Context of a rule. We have defined the notion of
context of a rule R as a set of morpho-syntactic con-
straints C over the application of R in a specific T-H
pair. Ideally, the set of such constraints should be
the minimal set of constraints over R such that the
proportion of successful applications of R is max-
imized (e.g. the precision-recall mean is highest).
Intuitively, given an entailment rule, in absence of
constraints we have the highest recall (the rule is al-
ways applied when the LHS is activated in T and
the RHS is activated in H), although we may find
cases of wrong application of the rule (i.e. low preci-
sion). On the other side, as syntactic constraints are
36
required (e.g. the subject of a verb has to be a noun)
the number of successful applications increases, al-
though we may find cases where the constraints pre-
vent the correct application (e.g. low recall).
In the absence of a data set where we can em-
pirically estimate precision and recall of rule appli-
cation, we have approximated the ideal context on
the basis of linguistic intuitions. More specifically,
for different syntactic heads of the rules, we define
the most appropriate syntactic constraints through a
search algorithm over the syntactic tree produced on
T and H (see Section 4.4 for a detailed explanation).
4 Entailment rules acquisition
In the next sections, the steps for the acquisition of
rules from Wikipedia pairs are described in detail.
4.1 Step 1: preprocessing Wikipedia dumps
We downloaded two dumps of the English
Wikipedia (one dated 6.03.2009, Wiki 09, and
one dated 12.03.2010, Wiki 10).4 We used the
script WikiExtractor.py5 to extract plain text from
Wikipedia pages, discarding any other information
or annotation, but keeping the reference to the orig-
inal document. For our goal, we consider only non-
identical documents present in both Wiki 09 and Wiki
10 (i.e. 1,540,870 documents).
4.2 Step 2: extraction of entailment pairs
For both Wiki 09 and Wiki 10 each document has
been sentence-splitted, and the sentences of the two
versions have been aligned to create pairs. To mea-
sure the similarity between the sentences in each
pair, we adopted the Position Independent Word Er-
ror Rate (PER) (Tillmann et al, 1997), a metric
based on the calculation of the number of words
which differ between a pair of sentences (diff func-
tion in (1)). Such measure is based on Levenshtein
distance, but works at word level, and allows for re-
ordering of words and sequences of words between
the two texts (e.g. a translated text s and a reference
translation r). It is expressed by the formula:
PER(s, r) = diff(s,r)+diff(r,s)?r? (1)
4http://en.wikipedia.org/wiki/Wikipedia:
Database_download
5http://medialab.di.unipi.it/wiki/
Wikipedia_Extractor
Pairs are clustered according to different thresholds:
? Pairs composed by identical sentences were
discarded; if only one word was different in the
two sentences, we checked if it was a typo cor-
rection using (Damerau, 1964) distance. If that
was the case, we discarded such pairs as well.
? Pairs in which one of the sentences contains the
other one, meaning that the users added some
information to the new version, without modi-
fying the old one (set a: 1,547,415 pairs).
? Pairs composed by very similar sentences,
where users carried out minor editing (PER <
0.2) (set b: 1,053,114 pairs). We filtered out
pairs where differences were correction of mis-
spelling and typos, and two-word sentences.
? Pairs composed by sentences where major edit-
ing was carried out (0.2 < PER < 0.6), but still
describe the same event (set c: 2,566,364).
? Pairs in which the similarity between sentences
is low (PER > 0.6) were discarded.
To extract entailment rules, we consider only the
pairs contained in set b. For each pair, we intuitively
set the sentence extracted from Wiki 10 as the Text,
since we assume that it contains more (and more
precise) information w.r.t. the sentence extracted
from Wiki 09. We set the sentence extracted from
Wiki 09 as the Hypothesis (see Examples 2 and 3).
Example 2.
T: The Oxford Companion to Philosophy says ?there is
no single defining position that all anarchists hold [...]?
H: According to the Oxford Companion to Philosophy
?there is no single defining position that all anarchists
hold [...] ?
Example 3.
T: Bicycles are used by all socio-economic groups be-
cause of their convenience [...].
H: Bicycles are used by all socio-economic groups due to
their convenience [...].
4.3 Step 3: extraction of entailment rules
Pairs in set b are collected in a data set, and pro-
cessed with the Stanford parser (Klein and Manning,
37
2003); chunks are extracted from each pair using
the script chunklink.pl.6 The assumption underlying
our approach is that the difference between T and
H (i.e. the editing made by the user on a specific
structure) can be extracted from such pairs and
identified as an entailment rule. The rule extraction
algorithm was implemented to this purpose. In
details, for each sentence pair the algorithm itera-
tively compares the chunks of T and H to extract
the ones that differ. It can be the case that several
chunks of H are identical to a given chunk of T, as in:
T:<NP>[The DT][Oxford NNP][Companion NNP]
</NP><PP>[to TO]</PP> <NP>[Philosophy NNP]
</NP><VP>[says VBZ]</VP>...
H:<PP>[According VBG]</PP><PP>[to TO]</PP>
<NP>[the DT][Oxford NNP][Companion NNP]</NP>
<PP>[to TO]</PP><NP>[Philosophy NNP]</NP>...
Therefore, to decide for instance which chunk
<PP>[to TO]</PP> from H corresponds to the
identical chunk in T, the algorithm checks if the
previous chunks are equal as well. If this is the
case, such chunks are matched. In the example
above, the second chunk <PP>to</PP> from H
is considered as a good match because previous
chunks in T and H are equal as well (<NP>the
Oxford Companion</NP>). If the previous
chunks in T and H are not equal, the algorithm
keeps on searching. If such match is not found, the
algorithm goes back to the first matching chunk
and couples the chunk from T with it. Rules are
created setting the unmatched chunks from T as
the left-hand side of the rule, and the unmatched
chunks from H as the right-hand side of the rule.
Two consecutive chunks (different in T and H) are
considered part of the same rule. For instance, from
Examples 2 and 3:
2) <LHS> says </LHS>
<RHS> according to </RHS>
3) <LHS> because of </LHS>
<RHS> due to </RHS>
On the contrary, two non consecutive chunks gener-
ate two different entailment rules.
6http://ilk.uvt.nl/team/sabine/
chunklink/README.html
4.4 Step 4: rule expansion with minimal
context
As introduced before, our work aims at providing
precise and context-rich entailment rules, to maxi-
mize their correct application to RTE pairs. So far,
rules extracted by the rule extraction algorithm (Sec-
tion 4.3) are too general with respect to our goal.
To add the minimum context to each rule (as dis-
cussed in Section 3), we implemented a rule expan-
sion algorithm: both the file with the syntactic rep-
resentation of the pairs (obtained with the Stanford
parser), and the file with the rules extracted at Step 3
are provided as input. For every pair, and separately
for T and H, the words isolated in the corresponding
rule are matched in the syntactic tree of that sen-
tence, and the common subsumer node is detected.
Different strategies are applied to expand the rule,
according to linguistic criteria. In details, if the
common subsumer node is i) a Noun Phrase (NP)
node, the rule is left as it is; ii) a Prepositional
Phrase node (PP), all the terminal nodes of the
subtree below PP are extracted; iii) a clause intro-
duced by a subordinating conjunction (SBAR), all
the terminal nodes of the subtree below SBAR are
extracted; iv) an adjectival node (ADJP), all the
terminal nodes of the tree below the ADJP node
are extracted; v) a Verbal Phrase node (VP), the
dependency tree under the VP node is extracted.
For Example 3 (see Figure 1), the LHS of the rule
because of is matched in the syntactic tree of T and
the prepositional phrase (PP) is identified as com-
mon subsumer node. All the terminal nodes and the
PoS of the tree below PP are then extracted. The
same is done for the RHS of the rule, where the com-
mon subsumer node is an adjectival phrase (ADJP).
5 Experiments and results
In the previous section, we described the steps
carried out to acquire context-rich entailment rules
from Wikipedia revisions. To show the applicability
of the adopted methodology, we have performed
two experiments focusing, respectively, on entail-
ment rules for causality and temporal expressions.
In particular, as case studies we chose two seeds:
the conjunction because to derive rules for causality,
and the preposition before for temporal expressions.
38
(a) LHS rule (b) RHS rule
Figure 1: Rule expansion with minimal context (Example 3)
causality (because) temporal exp. (before)
(PP(RB because)(IN of)(NP(JJ)(NNS))? (SBAR(IN before)(S))?
(ADJP(JJ due)(PP(TO to)(NP(JJ)(NNS)))) (ADVP(RB prior)(PP(TO to)(S)
e.g.: because of contractual conflicts ? due to contractual conflicts e.g.: before recording them ? prior to recording them
(SBAR(IN because)(S))? (VP(PP(IN on)(NP(DT the) (ADVP(RB prior)(PP(TO to)(NP(DT)(NN))))?
(NNS grounds)))(SBAR (IN that)(S) (SBAR(IN before)(NP(DT)(NN)))
e.g.: because it penalized people ? on the grounds that it penalized people e.g.: prior to the crash ? before the crash
(PP(RB because)(IN of)(NP(DT)(NN)))? (PP(IN as)(NP (SBAR(IN until)(NP(CD)))?
(NP(DT a)(NN result))(PP(IN of)(NP(DT)(NN))))) (SBAR(IN before)(NP(CD)))
e.g.: because of an investigation ? as a result of an investigation e.g.: until 1819 ? before 1819
Table 1: Sample of extracted entailment rules.
Accordingly, we extracted from set b only the pairs
containing one of these two seeds (either in T or
in H) and we built two separate data sets for our
experiments. We run the rule extraction algorithm,
and then we filtered again the rules acquired, to
collect only those containing one of the two seeds
(either in the LHS or in the RHS). This second
filtering has been done because there could be pairs
in which either because or before are present, but
the differences in T and H do not concern those
seeds. The algorithm for rule expansion has then
been applied to the selected rules to add the minimal
context. The resulting rule for Example 3 is:
<rule ruleid="23" docid="844" pairid="15">
<LHS> (PP
(RB 8 because) (IN 9 of)(NP
(PRP 10 their)
(NN 11 convenience))) </LHS>
<RHS> (ADJP
(JJ 8 due)(PP
(TO 9 to) (NP
(PRP 10 their)
(NN 11 convenience)))) </RHS>
</rule>
To create entailment rules balancing high-
precision with their recall (Section 3), when the
words of the context added to the rule in Step 4
are identical we substitute them with their PoS. For
Example 3, the rule is generalized as follows:
<rule ruleid="23" docid="844" pairid="15">
<LHS> (PP
(RB because) (IN of)(NP
(PRP)
(NN))) </LHS>
<RHS> (ADJP
(JJ due)(PP
(TO to) (NP
(PRP)
(NN)))) </RHS>
</rule>
The intuition underlying the generalization phase is
to allow a more frequent application of the rule,
while keeping some constraints on the allowed con-
text. The application of the rule from Example 3 is
39
allowed if the subtrees below the seed words are the
same (the rule can be applied in another T-H pair as,
e.g. because of his status? due to his status).
Contradictions (e.g. antonyms and semantic op-
positions) are generally very infrequent, but in cer-
tain cases they can have high impact (one of the most
frequent rule collected for temporal expression is be-
fore S? after S). For this reason, we used WordNet
(Fellbaum, 1998) to identify and filter antonyms out
during the generalization phase. We also checked
for awkward inconsistencies due to mistakes of the
algorithm on noisy Wikipedia data (e.g. rules with
the same seed word in both the LHS and the RHS),
and we automatically filtered them out. Table 1 re-
ports a sample of rules extracted for each seed word.
Statistics about the resulting data sets, i.e. the num-
ber of acquired rules both before and after the gener-
alization phase are shown in Table 2. Identical rules
are collapsed into a unique one, but the value of their
frequency is kept in the header of that rule. Such in-
dex can then be used to estimate the correctness of
the rule and, according to our intuition, the probabil-
ity that the rule preserves the entailment relation.7
causality temporal exp.
# rules before gen. 1671 813
# rules after gen. 977 457
rules frequency ? 2 66 27
Table 2: Resulting sets of entailment rules
5.1 Evaluation
Due to the sparseness of the phenomena under con-
sideration (i.e. causality and temporal expressions)
in RTE data sets, evaluating the acquired rules on
such data does not provide interesting results.
For this reason, (following (Zhao et al, 2009),
(Callison-Burch, 2008), (Szpektor et al, 2004)), we
opted for a manual analysis of a sample of 100
rules per set, including all the rules whose fre-
quency is ?2 (Table 2), plus a random set of rules
with frequency equal to 1. Two annotators with
skills in linguistics annotated such rules according
7It is difficult to compare our results with related work, since
such phenomena are not covered by other resources. The cor-
rect comparison would be with the subset of e.g. DIRT para-
phrases dealing with causality and temporal relations, if any.
to five possible values (rules have been presented
with the sentence pairs from which they have been
acquired): entailment=yes (YES), i.e. correctness of
the rule; entailment=more-phenomena (+PHEN), i.e.
the rule is correct, but more than one phenomenon
is involved, see Section 5.2; entailment=unknown
(UNK), i.e. there is no entailment between the LHS
and the RHS of the rule, often because the editing
changed the semantics of the proposition; entail-
ment=unknown:reverse entailment (REV), wrong
directionality, i.e. the RHS of the rule entails the
LHS; entailment=error (ERR), i.e. the rule is wrong,
either because the editing in Wiki10 was done to cor-
rect mistakes, or because the rule is not well-formed
due to mistakes produced by our algorithm.
The inter-annotator agreement has been calcu-
lated, counting when judges agree on the assigned
value. It amounts to 80% on the sample of rules
for causality, and to 77% on the sample of rules for
temporal expressions. The highest inter-annotator
agreement is for correct entailment rules, whereas
the lowest agreement rates are for unknown and er-
ror judgments. This is due to the fact that detecting
correct rules is straightforward, while it is less clear
whether to consider a wrong rule as well-formed but
with an unknown judgment, or to consider it as not
appropriate (i.e. error). Table 3 shows the outcomes
of the analysis of the two sets of rules, as resulting
after a reconciliation phase carried out by the an-
notators. Such results, provided both for the whole
samples8 and for the rules whose frequency is ?2
only, are discussed in the next section.
YES +PHEN UNK REV ERR
caus.
all 67 2 13 8 10
fr?2 80.3 0 16.7 1.5 1.5
temp.
all 36 6 23 7 28
fr?2 52 3.7 37 7.3 0
Table 3: Accuracy (%) of the extracted sets of rules.
5.2 Discussion and error analysis
Due to the amount of noisy data present in
Wikipedia, on average 19% of the collected rules
8We are aware of the fact that including all the most frequent
rules in the sample biases the results upwards, but our choice is
motivated by the fact that we aim at verifying that with redun-
dancy the accuracy is actually improved.
40
include editing done by the users for spelling and
typos corrections, or are just spam (Table 3). To dis-
card such cases, spell-checkers or dictionary-based
filters should be used to improve our filtering tech-
niques. Moreover, to select only reliable rules we
consider making use of their frequency in the data to
estimate the confidence that a certain rule maintains
the entailment. The accuracy of the rules occurring
more than once is indeed much higher than the ac-
curacy estimated on the whole sample. Also the per-
centage of incorrect rules is strongly reduced when
considering redundant rules. Our assumption about
the directionality of entailment rules extracted from
Wikipedia versions is also verified (less than 10% of
the rules per set are tagged as reverse-entailment).
However, since the acquisition procedure privi-
leges precision, only a few rules appear very fre-
quently (Table 2), and this can be due to the con-
straints defined for the context extraction. This fact
motivates also the lower precision of the rules for
temporal expressions, where 73% of the sample we
analyzed involved rules with frequency equal to 1.
Moreover, in most of the rules annotated as un-
known, the editing of Wiki10 changed the semantics
of the pair, e.g. before 1990 ? 1893, or when x
produced? because x produced. Further strategies
to empirically estimate precision and recall of rule
application should be experimented as future work.
Indeed, several rules appearing only once represent
correct rules, and should not be discarded a priori.
Finally, the idea of using only very similar pairs to
extract entailment rules is based on the assumption
that such rules should concern one phenomenon at a
time (Bentivogli et al, 2010). Despite the strategies
adopted to avoid multiple phenomena per rule, in
about 10% of the cases two phenomena (e.g lexical
and syntactic) are collapsed on consecutive tokens,
making it complex to separate them automatically:
e.g. in because of his divorce settlement cost? due
to the cost of his divorces settlement, the causative
(because of x? due to x) and the argument realiza-
tion (x cost? cost of x) rules should be separated.
6 Conclusion and future work
We have presented a methodology for the automatic
acquisition of entailment rules from Wikipedia re-
vision pairs. The main benefits are the follow-
ing: i) potential large-scale acquisition, given the in-
creasing size of Wikipedia revisions; ii) new cover-
age, because Wikipedia revisions contain linguistic
phenomena (e.g. causality, temporal expressions),
which are not covered by existing resources: as a
consequence, the coverage of current TE systems
can be significantly extended; iii) quality: we intro-
duce the notion of context of a rule as the minimal
set of syntactic features maximizing its successful
application, and we have implemented it as a search
over the syntactic representation of revision pairs.
Results obtained on two experimental acquisi-
tions on causality and temporal expressions (seeds
because and before) show both good quality and
coverage of the extracted rules. The obtained re-
sources9: i) cover entailment and paraphrasing as-
pects not represented in other similar sets of rules,
ii) can be easily extended by applying the algorithms
to automatically collect rules for other phenomena
relevant to inference; and iii) are periodically up-
dated, as Wikipedia revisions change continuously.
We consider such aspects as part of our future work.
These results encourage us to further improve the
approach, considering a number of directions. First,
we plan to improve our filtering techniques to ex-
clude revision pairs containing more than one phe-
nomenon considering the syntactic structure of the
sentence. Moreover, we are planning to carry out
more extended evaluations, according to two pos-
sible strategies: i) applying the instance-based ap-
proach (Szpektor et al, 2007) on the Penn Treebank
data (i.e. for each PTB sentence that contains the
LHS of an entailment rule from our set, a pair sen-
tence will be generated by replacing the LHS of the
rule with its RHS. Human judges will then judge
each pair); ii) integrating the extracted rules into
existing TE systems. However, this evaluation has
to be carefully designed, as the ablation tests car-
ried on at the RTE challenges show. In particular,
as RTE tasks are moving towards real applications
(e.g. summarization) we think that knowledge re-
flecting real textual variations produced by humans
(as opposed to knowledge derived from linguistic re-
sources) may introduce interesting and novel hints.
9Available at http://www.aclweb.org/aclwiki/
index.php?title=Textual_Entailment_
Resource_Pool. We encourage its integration into TE
systems, to obtain feedback on its utility in TE tasks.
41
Acknowledgments
This work has been partially supported by the EC-
funded project EXCITEMENT (FP7 ICT-287923).
References
Roni Ben Aharon, Idan Szpektor, Ido Dagan. 2010. Gen-
erating Entailment Rules from FrameNet. Proceedings
of the ACL 2010 Conference Short Papers. July 11-16.
Uppsala, Sweden.
Regina Barzilay, Lillian Lee. 2003. Learning to Para-
phrase: An Unsupervised Approach Using Multiple-
Sequence Alignment. Proceedings of the HLT-
NAACL. May 27-June 1. Edmonton, Canada.
Luisa Bentivogli, Peter Clark, Ido Dagan, Hoa T. Dang,
Danilo Giampiccolo. 2010. The Sixth PASCAL Rec-
ognizing Textual Entailment Challenge. Proceedings
of the TAC 2010 Workshop on TE. November 15-16.
Gaithersburg, Maryland.
Luisa Bentivogli, Elena Cabrio, Ido Dagan, Danilo Gi-
ampiccolo, Medea Lo Leggio, Bernardo Magnini.
2010. Building Textual Entailment Specialized Data
Sets: a Methodology for Isolating Linguistic Phenom-
ena Relevant to Inference. Proceedings of the Seventh
conference on International Language Resources and
Evaluation. May 19-21. Malta.
Chris Callison-Burch. 2008. Syntactic constraints on
paraphrases extracted from parallel corpora. Pro-
ceedings of the Conference on Empirical Methods in
Natural Language Processing (EMNLP2008) October
25-27. Honolulu, Hawaii.
Ido Dagan, Bill Dolan, Bernardo Magnini, Dan Roth.
2009. Recognizing textual entailment: Rational, eval-
uation and approaches. Natural Language Engineer-
ing (JNLE). Special Issue 04, volume 15, i-xvii. Cam-
bridge University Press.
Fred J. Damerau. 1964. A technique for computer de-
tection and correction of spelling errors. Commun.
ACM, 7 (3), pages 171?176. ACM, New York, NY,
USA.
Camille Dutrey, Houda Bouamor, Delphine Bernhard and
Aurelien Max 2011. Local modifications and para-
phrases in Wikipedia?s revision history. SEPLN jour-
nal (Revista de Procesamiento del Lenguaje Natural),
46:51-58.
Christiane Fellbaum. 1998. WordNet: An Electronic
Lexical Database. Language, Speech and Communi-
cation. MIT Press.
Adrian Iftene, Mihai-Alex Moruz. 2010. UAIC Partici-
pation at RTE-6. Proceedings of the TAC 2010 Work-
shop on TE. November 15-16. Gaithersburg, Mary-
land.
Dan Klein, Christopher D. Manning. 2003. Accurate
Unlexicalized Parsing. Proceedings of the 41st Meet-
ing of the Association for Computational Linguistics.
July 7-12. Sapporo, Japan.
Dekang Lin, Patrick Pantel. 2001. Discovery of Infer-
ence Rules for Question Answering. Natural Language
Engineering 7(4):343-360.
Rowan Nairn, Cleo Condoravdi, Lauri Karttunen. 2006.
Computing relative polarity for textual inference. In-
ference in Computational Semantics (ICoS-5). April
20-21. Buxton, UK.
Aurelien Max, Guillaume Wisniewski. 2010. Mining
naturally-occurring corrections and paraphrases from
wikipedia?s revision history. Proceedings of the Sev-
enth conference on International Language Resources
and Evaluation. May 19-21. Valletta, Malta.
Yashar Mehdad, Matteo Negri, Elena Cabrio,
Milen Kouylekov, Bernardo Magnini. 2009. Using
Lexical Resources in a Distance-Based Approach to
RTE. Proceedings of the TAC 2009 Workshop on TE.
November 17. Gaithersburg, Maryland.
Shachar Mirkin, Roy Bar-Haim, Jonathan Beran, Ido Da-
gan, Eyal Shnarch, Asher Stern, Idan Szpektor. 2009.
Addressing Discourse and Document Structure in the
RTE Search Task. Proceedings of the TAC 2009 Work-
shop on TE. November 17. Gaithersburg, Maryland.
Rani Nelken, Elif Yamangil. 2008. Mining Wikipedia?s
Article Revision History for Training Computational
Linguistics Algorithms. Proceedings of the AAAI
Workshop on Wikipedia and Artificial Intelligence.
July 13-14, Chicago, Illinois.
Satoshi Sekine. 2005. Automatic Paraphrase Discovery
based on Context and Kwywords between NE Pairs.
Proceedings of the International Workshop on Para-
phrasing (IWP-05). October 14. Jeju Island, South
Korea.
Idan Szpektor, Hristo Tanev, Ido Dagan, Bonaven-
tura Coppola. 2004. Scaling Web-based Acquisition of
Entailment Relations. Proceedings of the 2004 Con-
ference on Empirical Methods in Natural Language
Processing. July 25-26. Barcelona, Spain.
Idan Szpektor, Ido Dagan. 2008. Learning Entailment
Rules for Unary Templates. Proceedings of the 22nd
International Conference on Computational Linguis-
tics (Coling 2008). August 18-22. Manchester, UK.
Idan Szpektor, Eyal Shnarch, Ido Dagan. 2007.
Instance-based Evaluation of Entailment Rule Acqui-
sition. Proceedings of the 45th Annual Meeting of the
Association of Computational Linguistics. June 23-
30. Prague, Czech Republic.
Christoph Tillmann, Stephan Vogel, Hermann Ney,
Alex Zubiaga, Hassan Sawaf. 1997. Accelerated DP
based search for statistical translation. Proceedings
42
of the European Conf. on Speech Communication and
Technology, pages 26672670. September. Rhodes,
Greece.
Mark Yatskar, Bo Pang, Cristian Danescu-Niculescu-
Mizil, Lillian Lee. 2010. For the sake of simplicity:
Unsupervised extraction of lexical simplifications from
Wikipedia. Proceedings of the NAACL, pp. 365-368,
2010. Short paper. June 1-6. Los Angeles, USA.
Fabio Massimo Zanzotto, Marco Pennacchiotti. 2010.
Expanding textual entailment corpora from Wikipedia
using co-training. Proceedings of the COLING-
Workshop on The Peoples Web Meets NLP: Collabo-
ratively Constructed Semantic Resources. August 28.
Beijing, China.
Shiqi Zhao, Haifeng Wang, Ting Liu, Sheng Li. 2009.
Extracting Paraphrase Patterns from Bilingual Paral-
lel Corpora. Journal of Natural Language Engineer-
ing, 15 (4): 503:526.
43
