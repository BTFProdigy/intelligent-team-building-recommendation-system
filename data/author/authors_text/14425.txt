Proceedings of the NAACL HLT 2010 Second Louhi Workshop on Text and Data Mining of Health Documents, pages 53?60,
Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics
Characteristics and Analysis of Finnish and Swedish  Clinical Intensive Care Nursing Narratives   Helen Allvinf, Elin Carlssonf, Hercules Dalianisf, Riitta Danielsson-Ojalaa, Vidas Daudaravi?iusb, Martin Hasself, Dimitrios Kokkinakisc, Helj? Lund-gren-Lainea, Gunnar Nilssonf, ?ystein Nytr?d, Sanna Salanter?a, Maria Skeppstedtf, Hanna Suominene, Sumithra Velupillaif aDepartment of Nursing Science, University of Turku, VSSHP, Turku, Finland, bVytautas Magnus University, Lithuania, cDepartment of Swedish, University of Gothenburg, Sweden, dIDI, The Norwegian University of Science and Technology, Norway, eNICTA Canberra Research Laboratory and Australian National University, Australia fDepartment of Computer and Systems Sciences/Stockholm University Forum 100 SE-164 40 Kista, Sweden http://www.dsv.su.se/hexanord 
Abstract 
We present a comparative study of Finnish and Swedish free-text nursing narratives from intensive care. Although the two languages are linguistically very dissimilar, our hypothe-sis is that there are similarities that are impor-tant and interesting from a language technology point of view. This may have im-plications when building tools to support pro-ducing and using health care documentation. We perform a comparative qualitative analysis based on structure and content, as well as a comparative quantitative analysis on Finnish and Swedish Intensive Care Unit (ICU) nurs-ing narratives. Our findings are that ICU nurs-ing narratives in Finland and Sweden have many properties in common, but that many of these are challenging when it comes to devel-oping language technology tools. 
1 Introduction The purpose of this study1 is to do content and lexical analysis of nursing narratives written in an                                                            1 Our research on the Stockholm EPR Corpus (Dalianis et al, 2009) has been approved by Etikpr?vningsn?mnden i Stock-holm, (the Regional Vetting Board), reference number 
Intensive Care Unit (ICU). The ultimate goal of our research is to define linguistic similarities and language-specific aspects that differentiate clinical narratives in Finnish and Swedish in order to lay groundwork for developing internationally appli-cable language technology solutions and create a framework for characterising and comparing clini-cal narratives. Free text is handy for information entry but a challenge for information extraction, care handover and other uses of gathered informa-tion. Language technology can alleviate some of these problems in retrospective analysis by offer-ing a more semantically informed interpretation and abstraction. However, the most promising po-tential of language technology is to interactively improve, interpret and code during text entry so that the resulting structured, coded, free text can be validated immediately. The critical bottleneck to-day is namely information handover and reuse, and extensive text is simply not used nor is useful. In-teractively validated, semantically processed text could be more usable and support abstraction, visualization and query tools for the benefit of cli-nicians, patients, researchers and quality adminis-trators.                                                                                               2009/1742-31/5. Our research on the Finnish Corpus (Salan-ter? et al, 2009) has been approved by the Ethical committee of the Hospital District of South West Finland, reference number 2/2009, ?66. 
53
In this paper, we analyze Finnish and Swedish ICU nursing narratives from both qualitative and quantitative perspectives. Our data includes textual nursing documentation of adult patients with a protracted inpatient period. We have chosen ICUs because of their international similarity in decision making (Lauri & Salanter? 2002) and nursing documentation because it covers the entire inpa-tient period. 2 Background 
2.1 Clinical text Clinical text covers the text documents produced for clinical work by clinicians and occurs in clini-cal information systems. It is written by clinicians, that is, professionals (physicians, nurses, therapists and other specialist) responsible for patient care. Its primary purpose is to serve patient care as a summary or hand-over note. However, clinical text is also written for legal requirements, care continu-ity and purposes of reimbursement, management and research. Clinical text covers every care phase and, depending on the purpose, documents differ. Documents that describe the patient?s state, current health problems and socio-medical history are very different from those describing a care plan, its ac-tualization and evaluation of care outcomes. Again, these differ from diagnostic notes, lab results, ra-diography readings, pathology reports and dis-charge documents that plan further care at discharge.  Finally, clinical text may have been entered in ?real time?, in retrospect, or as a sum-mary, by the bedside or elsewhere. The enterer can be a clinician, secretary who transcribes a dictate, speech recognition software or another system that generates or synthesizes text, (McDonald 1997, Thoroddsen et al, 2009.).  2.2 Legal requirements for clinical documen-tation in different countries In several countries clinical documentation is based on law. In Finland, the Ministry of Social Affairs and Health (Statutes of Finland, 298/2009) defines that to ensure good care, all necessary and wide-ranging information has to be registered in patient records. In Sweden, the National Board of Health and Welfare has a similar approach (Pa-tientdatalagen 2008:355). Clinical text should be 
explicit and intelligible, and only generally well-known, accepted concepts and abbreviations are allowed to be used. It should detail adequately the patient?s conditions, care and recovery.  2.3 Special features of ICU and nursing An ICU is an essential component of most large hospitals with high quality care.  ICUs provide care for critically ill patients and focus on condi-tions that are life-threatening and require compre-hensive care and constant monitoring (Webster's 2010). This task is fairly similar universally. It is based on optional, international guidelines focus-ing on triage, admission, discharge and education. This international similarity was evident when nurses? decision making was studied in Canada, Finland, Northern Ireland, Switzerland, Norway and the USA (Lauri & Salanter? 2002); the study showed that decision making of ICU nurses was the most uniform in different countries when com-pared with nurses working in public health care, psychiatric care, and short and long term care. Clinical text written by nurses, that is, nursing narratives, both in Finland and in Sweden is based on the care process which stands for gathering in-formation from the patient, setting goals for care, implementing nursing interventions, and evaluat-ing the results of given care. In Finland, the na-tional standardized documentation model has been implemented with the Finnish care classification (assessment, interventions and outcomes of care) (Tanttu & Ikonen 2007). The Swedish VIPS model provides a structure for the documentation process with key words that reflect the nursing process (Ehrenberg et al, 1996).  ICU nursing narratives can be lengthy, espe-cially when the patient stay in the ICU is pro-longed. As much as 60 A4 pages equivalents of written text may be gathered during one period of care. However, clinicians have somewhat different opinion on how to organize the information they write. For example, headings are often inconsistent and text under headings can cover a lot of other issues than those directly concerning the given heading. (Suominen et al, 2009.)  2.4 Related studies Since most of the available clinical documents are in free-text form, a number of stylistically oriented efforts to characterize the data from various angles 
54
have taken place. This may include various topics, from viewing detailed information about specific items (e.g. readability, Kim et al, 2007) to identi-fying patterns and structures in order to provide better technology to automatically process the sublanguage (Pakhomov et al, 2006). The majority of such efforts investigate different aspects of lin-guistic features at a monolingual level, for in-stance, Hahn & Wermter (2004); Tomanek et al, (2007); Chung (2009); Harkema et al, (2009); while for a thorough review of various related is-sues see Meystre et al, (2008). In the Nordic con-text, Josefsson (1999) discusses Swedish clinical language and shows examples on how verb con-structions in a clinical setting differ from a non clinical setting.  One claim is that the physician unmarks the verb forms for agentivity when writ-ing about the patient and what actions she takes, for example, Patienten hallucinerar [The patient hallucinates] instead of the normal form  Patienten f?r hallucinationer [The patient experiences hallu-cinations].   Helles? (2005) describes nurses' general use of the language function in the nursing discharge notes. She finds that the text in the nursing dis-charge notes is information-dense and character-ized by technical terms, and that the use of standardised templates helped nurses improve the completeness, structure and content of the informa-tion. Comparisons at a monolingual level between written clinical text and lay text has been carried out by Dalianis et al, (2009). A contrastive com-putational linguistics study was carried out be-tween the Stockholm EPR Corpus (SEPR) and a general language corpus, both written Swedish text. The findings showed that SEPR contained longer words and that the vocabulary was highly domain-specific. Other work is described in Ownby, (2005). Comparing clinical text at a crosslingual level has, to our knowledge, only been done by Borin et al, (2007).  3 Analysis of Finnish and Swedish ICU nursing narratives  The analyzed nursing narratives origin from one ICU in a university-affiliated hospital both in Fin-land and Sweden. Our inclusion criterion was an ICU inpatient period of at least 5 days and patient's age of at least 16 years. The Finnish data includes nursing narratives from 514 patient records (496 
unique patients, 18 rebounds, a patient record is defined as each inpatient period of at least 5 days per patient) between January 2005 and August 2006. The Swedish data includes nursing narra-tives from 379 patient records (333 unique pa-tients, 46 rebounds) between January 2006 and May 2008. Since we did not have complete admis-sion and discharge documents from both countries, our analysis is performed on daily nursing narra-tives. These documents are written by ICU nurses during the actual inpatient period from the patient admission to the discharge.    3.1 Qualitative analysis A manual content analysis was performed by four health care professionals (i.e., three native Finnish speakers knowing Swedish, one Swedish native speaker) and one native Swedish speaking lan-guage consultant. Three average-sized patient re-cords each from Finland and Sweden were chosen for our analysis (average size 2,389 words for Fin-land and 5,169 words for Sweden). In the analysis, we considered special features (Table 1) of daily notes both from the structural and content related points of view.  The style and context of both Finnish and Swed-ish text is very similar. For health care profession-als, and especially with an ICU background, all the texts are intelligible and the meaning of a writer becomes evident from the context even in the pres-ence of numerous linguistic and grammatical mis-takes; almost all the sentences are lacking both grammatical subjects and objects. It is evident that in both countries, the narratives are written from a professional to a professional in order to support information transfer, remind about important facts, and supplement numerical data.  A feature common for all the six records is that they rarely contain any subjects or objects when nurses are writing about patients. However, in the Swedish nursing narratives the word patient is used as a subject or object much more often than in the Finnish narratives. The abbreviation pat. is mostly used for this reference and she/he is never used for this purpose. In the whole data, pat. is 40 percent more common than she/he, which is the most common personal pronoun. It seems that the word patient or pat. is used more when the profes-sionals are writing about relatives. In general, pro-nouns are used infrequently in the narratives, and  
55
  Table 1. Special structural and contextual features of Finnish and Swedish daily ICU nursing narratives. The original examples are added in ().  I very rarely. If the reader is not a health care pro-fessional, a risk for confusing the subject (i.e., the patient or nurse) arises. However, the context makes it almost always clear who is referred to.  Approximately half of the narratives do not contain any verb. The most common tense is perfect, but 
without the auxiliary has. When the meaning does not contain a subject it becomes ?unnatural? to use has. Instead, the supine form is used, for example slept, lain, and eaten. Both present and past parti- ciples without be-verb are common, for example, Breathing: Ventilator parameters unchanged. 
Special features of Finnish narratives   Special features of Swedish narratives   Structure Examples Structure Examples 
Headings are used in 2 out of 3 patient records. Headings are typi-cally used as subjects or subjects are partially used.  
Diuresis: occasionally profuse. (Diureesi: ajoittain runsasta.)  Pupils move under eyelids but does not open eyes. (Pupillit liikkuvat luomien alla, mutta ei avaa silmi??n.)  
Headings are used in all daily narra-tives. In Swedish daily narratives, the structure of headings seems to be obligatory. The headings are used typically as subjects.  
Circulation: Stable with ino-trop. (Cirkulation: Stabil med ino-tropi.)  Reacts only for pain stimula-tion during the suction of intu-bation tube. (Reagerar enbart vid sm?rt-stimuli vid sugning i tuben.) 
Present and past participles are typical but verbs of be, is and are are not used.  
Consciousness remained un-changed. (Tajunta pysynyt ennallaan.)  Blood pressure low. (Verenpaine matala.) 
Present and past participles are typical but verbs of be, is and are are not used.  
Breathing: Ventilator parame-ters unchanged. (Andning: Ventilator paramet-rarna of?r?ndrade.) 
Complete sentences are rarely used.  
No spontaneous movements, rigidifies. (Ei spontaania liikett?, j?ykiste-lee.)  Husband and daughter have been staying a long time beside the patient. (Mies ja tyt?r olleet pitk??n potilaan vierell?.) 
Complete sentences are rarely used.  
Light sedation, looks up now and then. (L?tt sederad, tittar upp ibl-and.)  She took the wedding ring and the watch home. (Hon tog med sig vigselring och klocka hem.) 
Misspellings are found but the content or meaning is still clear.  Hemodynamic ? hemodynamic (Hemodynamiikka ? henody-namiikka) Misspellings are found but the content or meaning is still clear.  
The motther is informed. (Mammman ?r informered.)  Magnesium is addded. (Magnesium har tilllsatts.) Content Examples Content  Examples 
The word patient as a subject or object is infrequently mentioned. If this word is mentioned it is not abbreviated.  
Oxidates well or ventilates well. (Happeutuu hyvin tai ventiloituu hyvin.)  
The word patient is used more often than in Finnish narratives as a subject or object. It is also replaced with abbreviations of Pat or Pt.  
Patient got a percutanous tracheostomy today. (Patienten har f?tt en perkutan trakeostomi idag.)  Very worried about patient?s condition. (Mycket oroliga ?ver patien-tens tillst?nd.)  Pt. wakes up for talking and appears to be adequate. (Pt. vakner p? tilltal och up-plevs som adekvat.) 
Signs are typically used: e.g., >, <, -->, +, -.  
The height for the drain raised from 10 --> 20 mmHg. (Dreneerausrajaa nostettu 10  --> 20 mmHg.)  Got medicine --> good response. (Sai l??kett? -->hyv? vaste.) 
Many different abbreviations are used. The origin of entire word is Swedish, English, Latin, professional or ICU typical.  
em. [eftermiddag, afternoon], HR [heart rate], VF [Ven-tricula/Fibrillation, Ventricular Fibrillation]  
56
The use of headings is frequent and good ? most of the time the content matches the headings (Tables 1 and 3). In addition, headings are used similarly in the Swedish and Finnish documents. Most of the time the headings are considered as subjects of the sentence, for example, Consciousness: Unchanged. Liquor brighter than yesterday. However, in the use of headings there are two interesting findings: If the headings are to be cho-sen freely, as in the Finnish narratives, nurses tend to use their own headings and hence many syno-nyms or closely related concepts are used; for ex-ample, hemodynamics versus blood pressure and pulse or breathing versus oxidation. If the headings are obligatory, as in the Swedish narratives, nurses tend to write their observations under the heading which is somehow closest to the subject; for exam-ple, body temperature under circulation or level of sedation under sleep. For both languages the use of different abbrevia-tions is very common. Almost every daily nursing narrative included several abbreviations. Most of the abbreviations are typical for an ICU domain: CVP [central venous pressure], PEEP [Positive End-Expiratory Pressure], EN [Enteral Nutrition], TPN [Total Parenteral Nutrition], pO2 [partial pressure of oxygen], pCO2 [partial pressure of carbon dioxide], MV [Minute Ventilation] and MAP [Mean Arterial Pressure]. From a language technology point of view this means that ICU nurs-ing narratives contain language-independent vo-cabulary. However, nurses in both countries also use many language dependent abbreviations. 
3.2 Quantitative analysis The Finnish data set (n=514) was quantitatively analyzed using the morphological analyser FinT-WOL and the disambiguator FinCG, (Lingsoft 2010), and the Swedish data set (n=379) using the GTA, Granska Text Analyzer (Knutsson et al, 2003). Both data sets are rich in terms of amount of text and vocabulary (Table 2). It is also clear that the amount of text written per day and patient varies a lot in both data sets. More complex words were spelled in numerous ways. For example, the pharmacological substance Noradrenalin had ap-proximately 350 and 60 different spellings in the Finnish and Swedish data sets, respectively. This problem is part of a more general issue of refer-
ence resolution e.g. when mapping different lexical terms referring to the same concept. In our quantitative analysis, we have included punctuation characters. In the Swedish data there was a large amount of html-tags and other format-ting characters, which has a high impact on the total number of tokens (see Table 2). Moreover, as Finnish is highly inflective, FinCG produces alter-native lemmas, hence it is possible to reduce the sparseness of the data by processing the output by choosing only one alternative lemma (see total number of types in Table 2).  To further illustrate the richness of ICU nursing language, the number of unique bigrams (e.g., ?is not?, ?oxidate well? and ?night time? (note: a mis-spelled compound) are the most common ones for Finnish) and trigrams (e.g., ?oxygeneated and ven-tilated?, ?and ventilate well? are among the most common ones for Finnish) were 368,166 (275,205 after FinCG) and 745,407 (356,307 after FinCG) for Finnish patient records. For the Swedish data, the number of unique bigrams was 469,455 (344,127 after GTA) and 1,064,944 (905,539 after GTA). Examples of common Swedish ICU bi-grams and trigrams include ?circulation stabile?, ?during night?, ?in connection with?, and ?with good effect?. Of the content of Finnish nursing narratives, 11% are verbs, 7% nouns and less than 1% pronouns. For Swedish nursing narratives, the respective percentages are 11%, 27% and 2%. One reason for the high numbers for nouns in the Swed-ish data might be due to the large amount of (obligatory) headings relative to the Finnish data (see Table 3).  To support fluent information flow, language technology is needed to strengthen referential con-gruence. Much of this richness of vocabulary is explained by abbreviations and personal differ-ences in professional jargon. In particular, abbre-viations were common. Based on the analysis of the most common words, abbreviations were rela-tively established in Swedish data. For the Finnish data, abbreviations were less standard but RR, SR, CVP, h, ad, ml, ok, vas. [vasen, left] and oik. [oikea, right] were extremely common. Thus, ref-erential congruence can be strengthened by spell-ing out the most common abbreviations automatically. Adding topical content headings is another way to support information flow. Topical content head-ings were mandatory for Swedish data, but no de-
57
fault headings for Finnish existed. However, the headings for Finnish were established in terms of content. In Table 3, we see that the headings for both languages cover similar topics, which indi-cates that the clinical information need is similar for professionals in both countries (and languages). Thus, we recommend forming a standardized set of headings from which the user can voluntarily se-lect the ones to be used. This does not exclude add-ing other headings. Another alternative is to develop language technology for topic segmenta-tion and labeling. We have promising results from this approach (see, e.g., Suominen 2009).  Temporal expressions (e.g., time, evening, night) were often used in both data sets. This poses the question of tense analysis of verbs being unneces-sary and the time-related words being enough to imply the needed temporal information. It is also interesting to note that the negations inte [not, Swe], ingen [none, Swe], ej [not, Swe] and ei [no/not, Fin] are all among the most common types, which is an important property to take into account in information extraction applications. Furthermore, words regarding the oral cavity, such as breathing and mucus, as well as relations, such as daughter, son, wife, and husband are very com-mon in both data sets.  Inspired by the tf?idf-measure from information retrieval, we also analyzed the most common words in terms of a) the number of patients in whose documents the word was used and b) the number of daily nursing narratives in which the word was used. Here, we found, in both data sets, that those words that were used for all patients as well as all daily narratives, were very similar in both data sets, and were related to the most com-mon headings, temporal expressions, negations and monitoring (e.g., increase, continue, begin).  The amount of Protected Health Information (PHI) in form of person names was equal in both of the data sets: 1.5 person names per thousand tokens. This is notable, since this has implications when it comes to integrity issues and reuse of data for research purposes. FinCG did not recognize 36% of the content of Finnish nursing narratives. However, words marked as unrecognized by FinCG also included punctuation marks. In our previous study (see Suominen 2009 and references therein), we tai-lored FinCG by extending approximately 35,000 clinical terms. The extension not only substantially 
improved the applicability of FinCG to the health domain but also initiated piloting of our language technology components in an authentic healthcare environment in the fall 2008. This lead to the re-lease of commercial language technology for Fin-nish health records (Lingsoft 2010).   Data Finnish  Swedish  Total number of patients  514  379  Total number of  tokens,  types (unique tokens) and types after processing 
 1,227,909 63,328 38,649 
 1,959,271 - 41,883 Number of tokens per patient: Minimum Maximum Average Standard deviation 
 540 14,118 2,389 1,635   
 92 36,830 5,169 5,271 Total number of  daily documents and shifts  5,915 17,103  4,700 ? Number of tokens per daily document: Minimum Maximum Average Standard deviation 
  0 915 208 87 
  5 9,389 417 239  Table 2. Comparison of Finnish and Swedish ICU data sets: total amount of text per patient. A daily document, i.e. nursing narrative, contains all text written about a given patient during a calendar day.  Finnish n ? Swedish  n = Hemodynamics  7,800  Respiratory  11,301  Consciousness  6,900  Circulation 10,630  Relatives  5,700  Elimination  10,041  Diuresis  5,400  Nutrition  8,258  Breathing  4,500  Communication  5,880  Oxygenation  3,600  Event Time  5,681  Other  3,200  Pain  4,732  Excretion  590  Psychosocial  4,682  Hemodialysis  370  Sleep  4,438  Pulse  160  Skin  4,402  Skin  160  Activity  3,794   Table 3. Comparison of Finnish and Swedish ICU data sets: the most common headings. For the Finnish data, where default headings were not given, we approxi-mated the amount of heading by using an automated heuristics followed by manual combination of headings with the same meaning. 
58
For Swedish, GTA handles unknown words dif-ferently than FinCG. However, by comparing the ICU words with a Swedish general language cor-pus (PAROLE, Gellerstam et al (2000)), we found that 69% of the types are not included in PAROLE, which indicates a need for tailoring GTA (or simi-lar tools for Swedish) with domain-specific ICU terms.  4 Conclusions The purpose of this study was to do content and lexical analysis of nursing narratives written in an ICU. Our findings are that, even though the Fin-nish and Swedish languages are not linguistically closely related, the way of writing clinical nursing ICU narratives in both countries is very similar. Moreover, the written context made sentences clear for content experts, even though the texts were full of specialized jargon, misspellings, ab-breviations, and missing subjects and objects. However, these characteristics make clinical text challenging for language technology. For example coreference resolution as in the case of noradrena-lin. We have also shown that the content characteris-tics of Finnish and Swedish ICU nursing narratives are very similar. This implies that developing tools for documentation support in ICUs is not country or language dependant in that respect. Developing such tools may improve possibilities for informa-tion extraction and text mining, enabling the possi-bilities to reuse the vast amounts of important practice-based information and evidence captured in clinical narratives. The framework we have in-troduced here could easily be employed in other studies of clinical texts. 6 Future work In the future, we will use the results of this study in developing language technology for Finnish, Swe-dish and other Nordic ICU narratives. We will study how to identify abbreviations, misspellings and normalize and correct them, by using various distance measures and concept management tech-niques. We will also study how to automatically identify important parts of text and highlight them. Furthermore, we are interested in studying text provenance and pragmatics in this particular set-ting. In addition, we will evaluate the influence of 
these technology components in clinical practice. We will also address similarities and differences in clinical text written by various professional groups or at other hospital wards and health care units. Finally, we are eager to seek possibilities to incor-porate laymen's information needs and their inter-action with health care providers into our study. Acknowledgments We would like to thank Nordforsk and the Nordic Council of Ministers for the funding of our research network HEXAnord ? HEalth teXt Analysis network in the Nordic and Baltic countries and NICTA, funded by the Australian Government as represented by the De-partment of Broadband, Communications and the Digi-tal Economy and the Australian Research Council through the ICT Centre of Excellence program. We would also like to thank the Department of Information Technology and TUCS, University of Turku, Finland. References Lars Borin, Natalia Grabar, Catalina Hallett, Davis Hardcastle, Maria Toporowska Gronostaj, Dimitrios Kokkinakis, Sandra Williams and Alistair Willis. 2007. Empowering the patient with language tech-nology. SemanticMining NoE 507505: Deliverable D27.2. <http://gup.ub.gu.se/gup/record/index.xsql?pubid=53590>  Grace Yuet-Chee Chung. 2009. Towards identifying intervention arms in randomized controlled trials: ex-tracting coordinating constructions.  Journal of Bio-medical Informatics. 42(5):790?800  Hercules Dalianis, Martin Hassel and Sumithra Velupil-lai. 2009. The Stockholm EPR Corpus - Characteris-tics and Some Initial Findings. Proceedings of ISHIMR 2009, Evaluation and implementation of e-health and health information initiatives: interna-tional perspectives. 14th International Symposium for Health Information Management Research, Kal-mar, Sweden, 14-16 October, 2009, pp 243-249, pdf. Awarded best paper.  Anna Ehrenberg, Margareta Ehnfors and Ingrid Thorell-Ekstrand. 1996. Nursing documentation in patient re-cords: experience of the use of the VIPS model. Journal of Advanced Nursing 24, 853?867.  Martin Gellerstam, Yvonne Cederholm, and Torgny Rasmark. The bank of Swedish. In: Proceedings of LREC 2000 -- The 2nd International Conference on Language Resources and Evaluation, pages 329?333, Athens, Greece.  Udo Hahn and Joachim Wermter. 2004. High-performance tagging on medical texts. Proceedings of the 20th international conference on Computa-tional Linguistics. Geneva, Switzerland.  
59
Henk Harkema, Dowling JN, Thornblade T, Chapman WW. 2009. ConText: an algorithm for determining negation, experiencer, and temporal status from clin-ical reports. Journal of Biomedical Informatics 2009;42(5):839?51.  Ragnhild Helles?. 2005. Information handling in the nursing discharge notes, Journal of Clinical Nursing, Volume 15 Issue 1, 11 - 21. Blackwell publishing  Gunl?g Josefsson. 1999. F? feber eller tempa? N?gra tankar om agentivitet i medicinskt fackspr?k, Alla tiders spr?k: en v?nskrift till Gertrud Pettersson. Pages 127. Institutionen f?r nordiska spr?k. Lund. (In Swedish)  Hyeoneui Kim, Sergey Goryachev, Craciela Rosemblat, Allen Browne, Alla Keselman and Qing Zeng-Treitler. 2007. Beyond surface characteristics: a new health text-specific readability measurement. AMIA Annual Symp. 11:418-22.  Ola Knutsson, Johnny Bigert, and Vigg Kann. 2003. A robust shallow parser for Swedish. In Proceedings 14th Nordic Conf. on Comp. Ling. NODALIDA. Sirkka Lauri and Sanna Salanter?;. 2002. Developing an instrument to measure and describe clinical decision making in different nursing fields. Journal of Profes-sional Nursing. Mar-Apr;18(2), 93-100.  Lingsoft. 2010, Lingsoft Oy, http://www.lingsoft.fi/  Clement J. McDonald. 1997. The Barriers to Electronic Medical Record Systems and How to Overcome Them. JAMIA. 1997;4:213?221.   St?phane M. Meystre, Guergana K. Savova, Karin C. Kipper-Schuler and John E. Hurdle. 2008. Extracting Information from Textual Documents in the Elec-tronic Health Record: a Review of Recent Research. Yearbook Med Inform. 2008:128-44.  Raymond L. Ownby 2005. Influence of Vocabulary and Sentence Complexity and Passive Voice on the Readability of Consumer-Oriented Mental Health In-formation on the Internet. AMIA Annual Symposium Proceedings. 2005: 585?588. Serguei V. S. Pakhomov, Anni Coden and Christopher G. Chute. 2006. Developing a corpus of clinical notes manually annotated for part-of-speech. International Journal of Medical Informatics. 2006 Jun;75(6):418-29. Epub 2005 Sep 19. Patientdatalagen (2008:355) Svensk f?rfattnings-samling, Socialdepartementet, 2008, Stockholm. (In Swedish)  Hanna Suominen. 2009. Machine Learning and Clinical Text: Supporting Health Information Flow. TUCS Dissertations No 125, Turku Centre for Computer Science, 2009, Turku, Finland.  Hanna Suominen, Helj? Lundgr?n-Laine, Sanna Salan-ter?, Helena Karsten, and Tapio Salakoski. 2009. In-formation flow in intensive care narratives. In Chen J, Chen C, Ely J, Hakkani-Tr D, He J, Hsu H.-H, Liao L, Liu C, Pop  M, Ranganathan S, Reddy C.K, 
Ruan J, Song Y, Tseng V.S, Ungar L, Wu D, Wu Z, Xu K, Yu H, Zelikovsky A, editors. Proceedings IEEE International Conference on Bioinformatics and Biomedicine Workshops, BIBM 2009, pages 325?330. Institute of Electrical and Electronics Engi-neers, Los Alamitos, California, USA.  Kaarina Tanttu and Helena Ikonen. 2007. Nationally standardized electronic nursing documentation in Finland by the year 2007. Stud Health Technol In-form.122:540-1.  Asta Thoroddsen, Kaija Saranto, Anna Ehrenberg, Wal-ter Sermeus. 2009. Models, standards and structures of nursing documentation in European countries. Stud Health Technol Inform.146:327-31.  Katrin Tomanek, Joachim Wermter and Udo Hahn. 2007. A Reappraisal of sentence and token splitting for life sciences documents. Stud Health Technol In-form. 129 (Pt 1):524-8. Webster?s 2010. Webster?s New World Medical Dic-tionary. http://www.medterms.com/script/main/hp.asp,last visited February 2, 2010. 
60
Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR) @ EACL 2014, pages 66?73,
Gothenburg, Sweden, April 26-30 2014.
c
?2014 Association for Computational Linguistics
Segmentation of patent claims for improving their readability
Gabriela Ferraro
1 2
, Hanna Suominen
1?4
, Jaume Nualart
1 3
1
NICTA / Locked Bag 8001, Canberra ACT 2601, Australia
2
The Australian National University
3
University of Canberra
4
University of Turku
firstname.lastname@nicta.com.au
Abstract
Good readability of text is important
to ensure efficiency in communication
and eliminate risks of misunderstanding.
Patent claims are an example of text whose
readability is often poor. In this paper,
we aim to improve claim readability by
a clearer presentation of its content. Our
approach consist in segmenting the origi-
nal claim content at two levels. First, an
entire claim is segmented to the compo-
nents of preamble, transitional phrase and
body, using a rule-based approach. Sec-
ond, a conditional random field is trained
to segment the components into clauses.
An alternative approach would have been
to modify the claim content which is, how-
ever, prone to also changing the mean-
ing of this legal text. For both segmen-
tation levels, we report results from sta-
tistical evaluation of segmentation perfor-
mance. In addition, a qualitative error
analysis was performed to understand the
problems underlying the clause segmenta-
tion task. Our accuracy in detecting the
beginning and end of preamble text is 1.00
and 0.97, respectively. For the transitional
phase, these numbers are 0.94 and 1.00
and for the body text, 1.00 and 1.00. Our
precision and recall in the clause segmen-
tation are 0.77 and 0.76, respectively. The
results give evidence for the feasibility of
automated claim and clause segmentation,
which may help not only inventors, re-
searchers, and other laypeople to under-
stand patents but also patent experts to
avoid future legal cost due to litigations.
1 Introduction
Clear language is important to ensure efficiency in
communication and eliminate risks of misunder-
standing. With written text, this clarity is mea-
sured by readability. In the last years, we have
witnessed an increasing amount work towards im-
proving text readability. In general, these efforts
focus on making general text easier to understand
to non-native speakers and people with special
needs, poor literacy, aphasia, dyslexia, or other
language deficits.
In this paper, we address making technical text
more readable to laypeople, defined as those with-
out professional or specialised knowledge in a
given field. Technical documentation as scientific
papers or legal contracts are two genres of writ-
ten text that are difficult to understand (Alberts
et al., 2011). An extreme example that takes the
worst from both these worlds is the claim section
of patent documents: it defines the boundaries of
the legal protection of the invention by describing
complex technical issues and using specific legal
jargon (Pressman, 2006). Moreover, due to inter-
national conventions, each patent claim must be
written into a single sentence. This leads to very
long sentences with complex syntactic structures
that are hard to read and comprehend not only for
laypeople but also for technical people who are not
trained to read patent claims.
As an example of other efforts with similar
goals to improve the readability of technical text to
laypeople, we mention the CLEF eHealth shared
tasks in 2013 and 2014 (Suominen et al., 2013).
However, instead of inventors, researchers, and
other claim readers, they target patients and their
next-of-kins by developing and evaluating tech-
nologies to improve the readability of clinical re-
ports and help them in finding further information
related to their condition in the Internet.
Some proposals have also been made in order to
improve claim readability, for example, by apply-
ing simplification, paraphrasing, and summarisa-
tion methods (see Section 2). However, these ap-
proaches modify the claim content. This increases
66
the risk of changing also the meaning, which is not
desirable in the context of patent claims and other
legal documents.
In this paper, we propose an alternative method
that focuses on clarifying the presentation of the
claim content rather than its modification. Since
readability strongly affects text comprehension
(Inui et al., 2003), the aim of this study is to make
the content of the patent claims more legible and
consequently make them easier to comprehend.
As the first steps towards this improved presen-
tation of the patent claims, we propose to segment
the original text. Our approach is data driven and
we perform the segmentation at two levels: first,
an entire claim is segmented into three compo-
nents (i.e., preamble, transition, and body text) and
second, the components are further segmented into
clauses. At the first level, we use a rule-based
method and at the second level, we apply a con-
ditional random field.
We evaluate segmentation performance statisti-
cally at both levels and in addition, we analyse er-
rors in clause segmentation qualitatively; because
our performance at the first level is almost perfect
(i.e., for detecting the beginning and end of the
preamble, the accuracy percentages are 100 and
97 and these numbers are 94 and 100 for the tran-
sition and 100 and 100 for the body text), we focus
on the errors at the second level alone. In com-
parison, we have the precision of 77 per cent and
recall of 76 per cent in clause segmentation. Even
though this performance at the second level is not
perfect, it is significantly better than the respec-
tive percentages of 41 and 29 (0.2 and 0.3) for a
baseline based on both punctuation and keywords
(punctuation only).
The rest of the paper is organised as follows:
Section 2 describes as background information
of this study includes an explanation about what
patent claims are, how to read them, and what kind
of related work exists on claim readability. Sec-
tion 3 outlines our materials and methods. Section
4 presents the experiments results and discussion.
Finally, conclusions and ideas for future work are
presented in Section 5.
2 Background
2.1 Patent claims
Patent documents have a predefined document
structure that consists of several sections, such as
the title, abstract, background of the invention, de-
[Toolholder]
p
, [comprising]
t
[a holder body with
an insert site at its forward end comprising a
bottom surface and at least one side wall where
there projects a pin from said bottom surface
upon which there is located an insert having
a central bore, a clamping wedge for wedging
engagement between a support surface of the
holder and an adjacent edge surface of said
insert and an actuating screw received in said
wedge whilst threadably engaged in a bore of
said holder, said support surface and said edge
surface are at least partially converging down-
wards said wedge clamp having distantly pro-
vided protrusions for abutment against the top
face and the edge surface of said insert, char-
acterised in that the wedge consists of a pair of
distantly provided first protrusions for abutment
against a top face of the insert, and a pair of
distantly provided second protrusions for abut-
ment against an adjacent edge surface]
b
.
Figure 1: An example patent claim. We have used
brackets to illustrate claim components and the
sub-scripts p, t, and b correspond to the preamble,
transition, and body text, respectively.
scription of the drawings, and claims. As already
mentioned, the claims can be seen as the most im-
portant section as they define the scope of legal
protection of the invention. In most modern patent
laws, patent applications must have at least one
claim (Pressman, 2006).
The claims are written into a single sentence be-
cause of international conventions. Figure 1 pro-
vides an example claim.
Furthermore, a claim should be composed by, at
least, the following parts,
1. Preamble is an introduction, which describes
the class of the invention.
2. Transition is a phrase or linking word that re-
lates the preamble with the rest of the claim.
The expressions comprising, containing, in-
cluding, consisting of, wherein and charac-
terise in that are the most common transi-
tions.
3. Body text describes the invention and recites
its limitations.
We have also included an illustration of these
claim components in Figure 1.
Because a claim is a single sentence, special
punctuation conventions have been developed and
are being used by patent writers. Modern claims
follow a format where the preamble is separated
67
Table 1: Per claim demographics
Training set Test set
# tokens mean 60 66
min 7 8
max 440 502
# boundaries mean 5 5
min 1 1
max 53 41
from the transition by a comma, the transition
from the body text by a colon, and each invention
element in the body text by a semicolon (Radack,
1995). Other specifications regarding punctua-
tion are the following text elaboration and element
combination conventions:
- A claim should contain a period only in
the end.
- A comma should be used in all natu-
ral pauses.
- The serial comma
1
should be used to separate
the elements of a list.
- Dashes, quotes, parentheses, and abbrevia-
tions should be avoided.
Because a claim takes the form of a single sen-
tence, long sentences are common. Meanwhile,
in the general discourse (e.g., news articles) sen-
tences are composed of twenty to thirty words,
claim sentences with over a hundred words are
very frequent (see, e.g., Table 1 related to mate-
rials used in this paper). As a consequence, claims
usually contain several subordinate and coordi-
nate clauses, as they enable the aforementioned
elaboration and the combination of elements of
equal importance, respectively.
As claims are difficult to read and interpret, sev-
eral books and tutorials suggest how claims should
be read (Radack, 1995; Pressman, 2006). The first
step towards reading a claim is to identify its com-
ponents (i.e., preamble, transition, and body text).
Another suggestion is to identify and highlight the
different elements of the invention spelled out in
the body text of the claims.
1
The serial comma (also known as the Oxford comma)
is the comma used mediately before a coordination con-
junction (e.g., CDs, DVDs, and magnetic tapes where the
last comma indicates that DVDs and magnetic tapes are
not mixed). http://oxforddictionaries.com (ac-
cessed 28 Feb, 2014)
The clear punctuation marks and lexical mark-
ers enable the claim component segmentation, as
suggested above. Moreover, the predominance
of intra-sentential syntactic structures (e.g., subor-
dinate and coordinate constructions) favours seg-
menting patent claims into clauses. These clauses
can then be presented as a sequence of segments
which is likely to improve claim readability.
2.2 Related work
So far, not many studies have addressed the prob-
lem of improving the readability of patents claims.
In particular, to the best of our knowledge, there
is no research that specifically targets the problem
of presenting the claims in a more readable lay-
out. Consequently, we focus on efforts devoted to
claim readability in general with an emphasis on
text segmentation.
We begin by discussing three studies that ad-
dress text simplification in patent claims. Note that
these approaches modify the claim content which
may also change their meaning. This is riskier in
the context of patent documents and other legal
text than our approach of clarifying the presen-
tation. Moreover, in order achieve a reasonable
performance, the methods of these studies require
sophisticated tools for discourse analysis and syn-
tactic parsing. Usually these tools also need to be
tailored to the genre of claim text.
First, a parsing methodology to simplify sen-
tences in US patent documents has been pro-
posed (Sheremetyeva, 2003). The resulting analy-
sis structure is a syntactic dependency tree and the
simplified sentences are generated based on the in-
termediate chunking structure of the parser. How-
ever, neither the tools used to simplify sentences
nor the resulting improvement in readability has
been formally measured.
Second, simplification of Japanese claim sen-
tences has been addressed through a rule-based
method (Shinmori et al., 2003). It identifies the
discourse structure of a claim using cue phrases
and lexico-syntactic patterns. Then it paraphrases
each discourse segment.
Third, a claim simplification method to para-
phrase and summarise text has been intro-
duced (Bouayad-Agha et al., 2009). It is multilin-
gual and consists of claim segmentation, corefer-
ence resolution, and discourse tree derivation. In
claim segmentation, a rule-based system is com-
pared to machine learning with the conclusion of
68
the former approach outperforming the latter. The
machine learning approach is, however, very sim-
ilar to the clause segmentation task described in
this paper. They differ in the features used to
characterized the clause boundaries and in eval-
uation. For the evaluation, these authors use the
cosine similarity to calculate a 1:1 term overlap
between the automated solution and gold standard
set whereas we assess whether a token is an accu-
rate segment boundary or not.
We continue by discussing a complementary
method to our approach of improving the read-
ability of claims through their clearer presentation
without modifying the text itself. This work by
Shinmori et al. (2012) is inspired by the fact that
claims must be understood in the light of the def-
initions provided in the description section of the
patents. It aims to enrich the content by aligning
claim phrases with relevant text from the descrip-
tion section. For the evaluation, the authors have
inspected 38 patent documents. The automated
method generates 35 alignments for these docu-
ments (i.e., twenty correct and fifteen false) and
misses only six. It would be interesting to test if
this alignment method and the claim segmentation
proposed in this paper complement each other.
We end by noting that the task of segmenting
claim phrases is similar to the task of detecting
phrase boundaries by Sang and D?ejean (2001) in
the sense that the segments we want to identify are
intra-sentential. However, the peculiar syntactic
style of claims makes the phrase detection strate-
gies not applicable (see Ferraro (2012) for a de-
tailed study on the linguistic idiosyncrasy of patent
claims).
3 Materials and methods
In this paper, we performed statistical experiments
and qualitative error analyses related to two seg-
mentation tasks (see Figure 2):
1. Segmenting claims section to the components
for preamble, transition, and body text.
2. Segmenting each claim to subordinate and
coordinate clauses.
For Task 1, we developed a rule-based method
using the General Architecture for Text Engineer-
ing (GATE) (Cunningham et al., 2011). The sys-
tem had three rules, one for each of the claim parts
we were interested in identifying. The rules were
Table 2: Dataset demographics
# claims # segments # words
Training set 811 4397 48939
Development set 10 15 260
Test set 80 491 5517
written in terms of JAPE grammars.
2
In order to
process the rules, the GATE pipeline illustrated in
Figure 3 was applied. Because transitions should
match with the first instance of a closed set of key-
words (we used comprise, consist, wherein, char-
acterize, include, have, and contain), our first rule
identified a transition and, using its boundary in-
dices, we restricted the application of our further
rules. This resulted in the following application
order:
transition ?? preamble ?? body text.
Our two other rules relied on lexico-syntactic
patterns and punctuation marks. Note that even
though punctuation conventions have been devel-
oped for claim writing (see Section 2.1), their fol-
lowing is not mandatory. This led us to experi-
ment these more complex rules. The first task was
applied to the complete dataset (training, develop-
ment, and test sets merged into one single dataset)
described in Table 2.
For Task 2, our method was based on supervised
machine learning (ML). To train this ML classi-
fier, we used a patent claim corpus annotated with
clause boundaries. This corpus was provided by
the TALN Research Group from Universitat Pom-
peu Fabra. The aim of the segmentation classifier
was to decide whether a claim token is a segment
boundary or not, given a context. Thus, every to-
ken was seen as a candidate for placing a segment
boundary. Following standard ML traditions, we
split the dataset in training, development, and test
sets (Tables 2 and 1).
The corpus was analysed with a transitional
3
version of Bohnet?s parser (Bohnet and Kuhn,
2012). It was one of the best parsers in the CoNLL
Shared Task 2009 (Haji?c et al., 2009).
2
JAPE, a component of GATE, is a finite state transducer
that operates over annotations based on regular expressions.
3
Patent claim sentences can be very long which im-
plies long-distance dependencies. Therefore, transition-
based parsers, which typically have a linear or quadratic com-
plexity (Nivre and Nilsson, 2004; Attardi, 2006), are better
suited for parsing patent sentences than graph-based parsers,
which usually have a cubic complexity.
69
Figure 2: Example of the claim segmentation experiments
ANNI Tokenizer ?? RegEx Sentence Splitter ?? OpenNLP
POS Tagger ?? Noun Phrase Chunker ?? JAPE
Figure 3: GATE pipeline for Task 1
In order to characterise the clause boundaries,
the following features were used for each token in
the corpus:
- lemma of the current token,
- part-of-speech (POS) tag
4
of the current to-
ken as well as POS-tags of the two immedi-
ately preceding and two immediately subse-
quent words,
- syntactic head and dependent of the current
token, and
- syntactic dependency relation between the
current token and its head and dependent to-
kens.
Moreover, the fifteen most frequent lemmas and
five most frequent POS-tags and punctuation
marks were used as features we called segmenta-
tion keywords (Table 3).
For classification we used the CRF++ toolkit,
an open source implementation of conditional ran-
dom fields (Lafferty et al., 2001). This framework
for building probabilistic graphical models to seg-
ment and label sequence data has been success-
fully applied to solve chunking (Sha and Pereira,
4
The POS-tag corresponds to the Peen Tree Bank tag set
(Marcus et al., 1993) whereas IN = preposition or conjunc-
tion, subordinating; CC = Coordinating Conjunction; VBN =
Verb, past participle; VBG = verb, gerund or present partici-
ple; WRB = Wh-adverb.
Table 3: The most frequent lemmas and POS-tags
in the beginning of a segment.
Rank Lemmas Abs. Freq. Rel. Freq.
1 and 675 0.137
2 wherein 554 0.112
3 for 433 0.088
4 which 174 0.035
5 have 158 0.032
6 to 155 0.031
7 characterize 152 0.031
8 a 149 0.030
9 the 142 0.028
10 say 140 0.028
11 is 64 0.013
12 that 62 0.012
13 form 59 0.012
14 in 58 0.011
15 when 56 0.011
Rank POS-tag Abs. Freq. Rel. Freq.
1 IN 739 0.150
2 CC 686 0.139
3 VBN 511 0.104
4 VBG 510 0.104
5 WRB 409 0.083
2003), information extraction (Smith, 2006), and
other sequential labelling problems. We compared
the results obtained by CRF++ with the following
baselines:
- Baseline 1: each punctuation mark is a seg-
ment boundary, and
- Baseline 2: each punctuation mark and key-
word is a segment boundary.
70
Table 4: Evaluation of claim components
Correct Incorrect
Preamble Beginning 100% 0%
End 97% 3%
Transition Beginning 94% 6%
End 100% 0%
Body text Beginning 100% 0%
End 100% 0%
Performance in Task 1 was assessed using the
accuracy. Due to the lack of a corpus anno-
tated with claims components, we selected twenty
claims randomly and performed the annotation
ourselves (i.e., one of the authors annotated the
claims). The annotator was asked to assess
whether the beginning and ending of a claim com-
ponent was successfully identified.
Performance in Task 2 was evaluated using the
precision, recall, and F-score on the test set. We
considered that clause segmentation is a precision
oriented task, meaning that we emphasised the de-
mand for a high precision at the expense of a pos-
sibly more modest recall.
In order to better understand errors in clause
segmentation, we analysed errors qualitatively us-
ing content analysis (Stemler, 2001). This method
is commonly used in evaluation of language tech-
nologies. Fifty segmentation errors were ran-
domly selected and manually analysed by one of
the authors.
4 Results and discussion
4.1 Statistical performance evaluation in
Tasks 1 and 2
We achieved a substantial accuracy in Task 1,
claim component segmentation (Table 4). That
is, the resulting segmentation was almost perfect.
This was not surprising since we were processing
simple and well defined types of segments. How-
ever, there was a small mismatch in the bound-
ary identification for the preamble and the transi-
tion segments.
Our ML method clearly outperformed both its
baselines in Task 2 (Table 5). It had the precision
of 77 per cent and recall of 76 per cent in clause
segmentation. The respective percentages were 41
and 29 for the baseline based on both punctuation
and keywords. If punctuation was used alone, both
the precision and recall were almost zero.
Table 5: Evaluation of claim clauses
Precision Recall F-score
Baseline 1 0.2% 0.3% 2.6%
Baseline 2 41% 29% 34%
CRF++ 77% 76% 76%
4.2 Qualitative analysis of errors in Task 2
The most common errors in clause segmentation
were due to two reasons: first, ambiguity in co-
ordinating conjunctions (e.g., commas as wll as
and, or, and other particles) and second, consec-
utive segmentation keywords.
Segmentation errors caused by ambiguous coor-
dinating conjunctions were due to the fact that not
all of them were used as segment delimiters. Let
us illustrate this with the following automatically
segmented claim fragment with two coordinating
conjunctions (a segment is a string between square
brackets, the integer sub-script indicating the seg-
ment number, and the conjunctions in italics):
. . . [said blade advancing member comprises a worm
rotatable by detachable handle]
1
[or key]
2
[and meshin-
georm wheel secured to a shift]
3
. . .
In this example, the two conjunctions were con-
sidered as segment delimiters which resulted in
an incorrect segmentation. The correct analysis
would have been to maintain the fragment as a sin-
gle segment since simple noun phrases are not an-
notated as individual segments in our corpus.
Segmentation errors due to consecutive seg-
mentation keywords resulted in undesirable seg-
ments only once in our set of fifty cases. This hap-
pened because the classifier segmented every en-
counter with a segmentation keyword, even when
the keywords were consecutive. We illustrate this
case with the following example, which contains
two consecutive keywords, a verb in past partici-
ple (selected) and a subordinate conjunction (for).
Example (a) shows a wrong segmentation, while
example (b) shows its correct segmentation.
. . . (a) [said tool to be]
1
[selected]
2
[for the next work-
ing operation]
3
. . .
. . . (b) [said tool to be selected]
1
[for working]
2
. . .
In general, correcting both these error types
should be relatively straightforward. First, to solve
the problem of ambiguous commas, a possible so-
lution could be to constrain their application as
keywords, for example, by combining commas
71
with other context features. Second, segmentation
errors caused by consecutive segmentation key-
words could be solved, for example, by applying a
set of correction rules after the segmentation algo-
rithm (Tjong and Sang, 2001).
5 Conclusion and future work
In this paper we have presented our on-going re-
search on claim readability. We have proposed a
method that focuses on presenting the claims in
a clearer way rather than modifying their text con-
tent. This claim clarity is an important characteris-
tic for inventors, researchers, and other laypeople.
It may also be useful for patent experts, because
clear clauses may help them to avoid future legal
cost due to litigations. Moreover, better capabili-
ties to understand patent documents contribute to
democratisation of the invention and, therefore, to
human knowledge.
For future work, we plan to conduct a user-
centered evaluation study on claim readability. We
wish to ask laypeople and patents experts to as-
sess the usability and usefulness of our approach.
Furthermore, we plan to consider text highlight-
ing, terminology linking to definitions, and other
content enrichment functionalities as ways of im-
proving claim readability.
Acknowledgments
NICTA is funded by the Australian Government
through the Department of Communications and
the Australian Research Council through the ICT
Centre of Excellence Program. We also express
our gratitude to the TALN Research Group from
Universitat Pompeu Fabra for their corpus devel-
opment. Finally, we thank the anonymous review-
ers of The 3rd Workshop on Predicting and Im-
proving Text Readability for Target Reader Popu-
lations (PITR 2014), held in conjunction with the
14th Conference of the European Chapter of the
Association for Computational Linguistics (EACL
2014), for their comments and suggestions.
References
D. Alberts, C. Barcelon Yang, D. Fobare-DePonio,
K. Koubek, S. Robins, M. Rodgers, E. Simmons,
and D. DeMarco. 2011. Introduction to patent
searching. In M Lupu, J Tait, . Mayer, and A J
Trippe, editors, Current Challenges in Patent In-
formation Retrieval, pages 3?44, Toulouse, France.
Springer.
G. Attardi. 2006. Experiments with a multilanguage
non-projective dependency parser. In Proceedings
of the Tenth Conference on Computational Natural
Language Learning, CoNLL-X ?06, pages 166?170,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
B. Bohnet and J. Kuhn. 2012. The best of both worlds:
a graph-based completion model for transition-
based parsers. In Proceedings of the 13th Confer-
ence of the European Chapter of the Association for
Computational Linguistics, EACL ?12, pages 77?87,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
N. Bouayad-Agha, G. Casamayor, G. Ferraro, S. Mille,
V. Vidal, and Leo Wanner. 2009. Improving the
comprehension of legal documentation: the case of
patent claims. In Proceedings of the 12th Interna-
tional Conference on Artificial Intelligence and Law,
ICAIL ?09, pages 78?87, New York, NY, USA. As-
sociation for Computing Machinery.
H. Cunningham, D. Maynard, K. Bontcheva, V. Tablan,
N. Aswani, I. Roberts, G. Gorrell, A. Funk,
A. Roberts, D. Damljanovic, T. Heitz, M. A. Green-
wood, H. Saggion, J. Petrak, Y. Li, and W. Peters.
2011. Text Processing with GATE (Version 6). Gate-
way Press CA, Shefield. UK.
G. Ferraro. 2012. Towards Deep Content Extrac-
tion: The Case of Verbal Relations in Patent Claims.
PhD Thesis. Department of Information and Com-
munication Technologies, Pompeu Fabra Univesity,
Barcelona. Catalonia. Spain.
J. Haji?c, M. Ciaramita, R. Johansson, D. Kawahara,
M. A. Mart, L. M?arquez, A. Meyers, J. Nivre,
S. Pad, J. Stepanek, et al. 2009. The CoNLL-2009
shared task: syntactic and semantic dependencies
in multiple languages. In Proceedings of the Thir-
teenth Conference on Computational Natural Lan-
guage Learning: Shared Task, page 118, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
K. Inui, A. Fujita, T. Takahashi, R. Iida, and T. Iwakura.
2003. Text simplification for reading assistance: A
project note. In In Proceedings of the 2nd Interna-
tional Workshop on Paraphrasing: Paraphrase Ac-
quisition and Applications, IWP ?03, pages 9?16,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
D. Lafferty, A. McCallum, and F. C. N. Pereira. 2001.
Conditional random fields: Probabilistic models for
segmenting and labeling sequence data. In Proceed-
ings of the Eighteenth International Conference on
Machine Learning, ICML ?01, pages 282?289, San
Francisco, CA, USA. Morgan Kaufmann Publishers
Inc.
M. P. Marcus, B. Santorini, and M. A. Marcinkiewicz.
1993. Building a large annotated corpus of En-
glish: The Penn Treebank. Computational Linguis-
tics, 19(2):313?330.
72
J. Nivre and J. Nilsson. 2004. Memory-based depen-
dency parsing. In Proceedings of the Eight Confer-
ence on Computational Natural Language Learning,
CoNLL ?04, Stroudsburg, PA, USA. Association for
Computational Linguistics.
D. Pressman. 2006. Patent It Yourself. Nolo, Berkeley,
CA.
D. V. Radack. 1995. Reading and understanding patent
claims. JOM, 47(11):69?69.
E. T. K. Sang and H. D?ejean. 2001. Introduction to the
CoNLL-2001 shared task: Clause identification. In
W. Daelemans and R. Zajac, editors, Proceedings of
the Fith Conference on Computational Natural Lan-
guage Learning, volume 7 of CoNLL ?01, pages 53?
57, Toulouse, France.
F. Sha and F. Pereira. 2003. Shallow parsing with con-
ditional random fields. In Proceedings of the 2003
Conference of the North American Chapter of the
Association for Computational Linguistics on Hu-
man Language Technology, volume 1 of NAACL ?03,
pages 134?141, Stroudsburg, PA, USA. Association
for Computational Linguistics.
S. Sheremetyeva. 2003. Natural language analysis
of patent claims. In Proceedings of the ACL 2003
Workshop on Patent Processing, ACL ?03, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
A. Shinmori, M. Okumura, Y. Marukawa, and
M. Iwayama. 2003. Patent claim processing for
readability: structure analysis and term explana-
tion. In Proceedings of the ACL-2003 Workshop on
Patent Corpus Processing, volume 20 of PATENT
?03, pages 56?65, Stroudsburg, PA, USA. Associa-
tion for Computational Linguistics.
A. Shinmori, M. Okumura, and Marukawa. 2012.
Aligning patent claims with the ?detailed descrip-
tion? for readability. Journal of Natural Language
Processing, 12(3):111?128.
A. Smith. 2006. Using Gazetteers in discrimina-
tive information extraction. In Proceedings of the
Tenth Conference on Computational Natural Lan-
guage Learning, CoNLL ?06, pages 10?8, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
S. Stemler. 2001. An overview of content analy-
sis. Practical Assessment, Research and Evaluation,
7(17).
H. Suominen, S. Salantera, S. Velupillai, W. W. Chap-
man, G. Savova, N. Elhadad, S. Pradhan, B. R.
South, D. L. Mowery, G. J. F. Jones, J. Leveling,
L. Kelly, L. Goeuriot, Da Martinez, and Gu Zuc-
con. 2013. Overview of the ShARe/CLEF eHealth
Evaluation Lab 2013. In Pa Forner, H M?uller, R Pa-
rades, P Rosso, and B Stein, editors, Information
Access Evaluation: Multilinguality, Multimodality,
and Visualization. Proceedings of the 4th Interna-
tional Conference of the CLEF Initiative, volume
8138 of Lecture Notes in Computer Science, pages
212?231, Heidelberg, Germany. Springer.
E. F. Tjong and Kim Sang. 2001. Memory-
based clause identification. In Proceedings of the
2001 workshop on Computational Natural Lan-
guage Learning - Volume 7, ConLL ?01, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
73
