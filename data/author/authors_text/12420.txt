Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 949?957,
Suntec, Singapore, 2-7 August 2009. c?2009 ACL and AFNLP
Incremental HMM Alignment for MT System Combination
Chi-Ho Li
Microsoft Research Asia
49 Zhichun Road, Beijing, China
chl@microsoft.com
Xiaodong He
Microsoft Research
One Microsoft Way, Redmond, USA
xiaohe@microsoft.com
Yupeng Liu
Harbin Institute of Technology
92 Xidazhi Street, Harbin, China
ypliu@mtlab.hit.edu.cn
Ning Xi
Nanjing University
8 Hankou Road, Nanjing, China
xin@nlp.nju.edu.cn
Abstract
Inspired by the incremental TER align-
ment, we re-designed the Indirect HMM
(IHMM) alignment, which is one of the
best hypothesis alignment methods for
conventional MT system combination, in
an incremental manner. One crucial prob-
lem of incremental alignment is to align a
hypothesis to a confusion network (CN).
Our incremental IHMM alignment is im-
plemented in three different ways: 1) treat
CN spans as HMM states and define state
transition as distortion over covered n-
grams between two spans; 2) treat CN
spans as HMM states and define state tran-
sition as distortion over words in compo-
nent translations in the CN; and 3) use
a consensus decoding algorithm over one
hypothesis and multiple IHMMs, each of
which corresponds to a component trans-
lation in the CN. All these three ap-
proaches of incremental alignment based
on IHMM are shown to be superior to both
incremental TER alignment and conven-
tional IHMM alignment in the setting of
the Chinese-to-English track of the 2008
NIST Open MT evaluation.
1 Introduction
Word-level combination using confusion network
(Matusov et al (2006) and Rosti et al (2007)) is a
widely adopted approach for combining Machine
Translation (MT) systems? output. Word align-
ment between a backbone (or skeleton) translation
and a hypothesis translation is a key problem in
this approach. Translation Edit Rate (TER, Snover
et al (2006)) based alignment proposed in Sim
et al (2007) is often taken as the baseline, and
a couple of other approaches, such as the Indi-
rect Hidden Markov Model (IHMM, He et al
(2008)) and the ITG-based alignment (Karakos et
al. (2008)), were recently proposed with better re-
sults reported. With an alignment method, each
hypothesis is aligned against the backbone and all
the alignments are then used to build a confusion
network (CN) for generating a better translation.
However, as pointed out by Rosti et al (2008),
such a pair-wise alignment strategy will produce
a low-quality CN if there are errors in the align-
ment of any of the hypotheses, no matter how good
the alignments of other hypotheses are. For ex-
ample, suppose we have the backbone ?he buys a
computer? and two hypotheses ?he bought a lap-
top computer? and ?he buys a laptop?. It will be
natural for most alignment methods to produce the
alignments in Figure 1a. The alignment of hypoth-
esis 2 against the backbone cannot be considered
an error if we consider only these two translations;
nevertheless, when added with the alignment of
another hypothesis, it produces the low-quality
CN in Figure 1b, which may generate poor trans-
lations like ?he bought a laptop laptop?. While it
could be argued that such poor translations are un-
likely to be selected due to language model, this
CN does disperse the votes to the word ?laptop? to
two distinct arcs.
Rosti et al (2008) showed that this problem can
be rectified by incremental alignment. If hypoth-
esis 1 is first aligned against the backbone, the
CN thus produced (depicted in Figure 2a) is then
aligned to hypothesis 2, giving rise to the good CN
as depicted in Figure 2b.1 On the other hand, the
1Note that this CN may generate an incomplete sentence
?he bought a?, which is nevertheless unlikely to be selected
as it leads to low language model score.
949
Figure 1: An example bad confusion network due
to pair-wise alignment strategy
correct result depends on the order of hypotheses.
If hypothesis 2 is aligned before hypothesis 1, the
final CN will not be good. Therefore, the obser-
vation in Rosti et al (2008) that different order
of hypotheses does not affect translation quality is
counter-intuitive.
This paper attempts to answer two questions: 1)
as incremental TER alignment gives better perfor-
mance than pair-wise TER alignment, would the
incremental strategy still be better than the pair-
wise strategy if the TER method is replaced by
another alignment method? 2) how does transla-
tion quality vary for different orders of hypotheses
being incrementally added into a CN? For ques-
tion 1, we will focus on the IHMM alignment
method and propose three different ways of imple-
menting incremental IHMM alignment. Our ex-
periments will also try several orders of hypothe-
ses in response to question 2.
This paper is structured as follows. After set-
ting the notations on CN in section 2, we will
first introduce, in section 3, two variations of the
basic incremental IHMM model (IncIHMM1 and
IncIHMM2). In section 4, a consensus decoding
algorithm (CD-IHMM) is proposed as an alterna-
tive way to search for the optimal alignment. The
issues of alignment normalization and the order of
hypotheses being added into a CN are discussed in
sections 5 and 6 respectively. Experiment results
and analysis are presented in section 7.
Figure 2: An example good confusion network
due to incremental alignment strategy
2 Preliminaries: Notation on Confusion
Network
Before the elaboration of the models, let us first
clarify the notation on CN. A CN is usually de-
scribed as a finite state graph with many spans.
Each span corresponds to a word position and con-
tains several arcs, each of which represents an al-
ternative word (could be the empty symbol , ?) at
that position. Each arc is also associated with M
weights in an M -way system combination task.
Follow Rosti et al (2007), the i-th weight of an
arc is ?r 11+r , where r is the rank of the hypothe-
sis in the i-th system that votes for the word repre-
sented by the arc. This conception of CN is called
the conventional or compact form of CN. The net-
works in Figures 1b and 2b are examples.
On the other hand, as a CN is an integration
of the skeleton and all hypotheses, it can be con-
ceived as a list of the component translations. For
example, the CN in Figure 2b can be converted
to the form in Figure 3. In such an expanded or
tabular form, each row represents a component
translation. Each column, which is equivalent to
a span in the compact form, comprises the alter-
native words at a word position. Thus each cell
represents an alternative word at certain word po-
sition voted by certain translation. Each row is as-
signed the weight 11+r , where r is the rank of the
translation of some MT system. It is assumed that
all MT systems are weighted equally and thus the
950
Figure 3: An example of confusion network in tab-
ular form
rank-based weights from different system can be
compared to each other without adjustment. The
weight of a cell is the same as the weight of the
corresponding row. In this paper the elaboration
of the incremental IHMM models is based on such
tabular form of CN.
Let EI1 = (E1 . . . EI) denote the backbone CN,
and e?J1 = (e?1 . . . e?J) denote a hypothesis being
aligned to the backbone. Each e?j is simply a word
in the target language. However, each Ei is a span,
or a column, of the CN. We will also use E(k) to
denote the k-th row of the tabular form CN, and
Ei(k) to denote the cell at the k-th row and the
i-th column. W (k) is the weight for E(k), and
Wi(k) = W (k) is the weight for Ei(k). pi(k)
is the normalized weight for the cell Ei(k), such
that pi(k) = Wi(k)?
i Wi(k)
. Note that E(k) contains
the same bag-of-words as the k-th original trans-
lation, but may have different word order. Note
also that E(k) represents a word sequence with
inserted empty symbols; the sequence with all in-
serted symbols removed is known as the compact
form of E(k).
3 The Basic IncIHMM Model
A na??ve application of the incremental strategy to
IHMM is to treat a span in the CN as an HMM
state. Like He et al (2008), the conditional prob-
ability of the hypothesis given the backbone CN
can be decomposed into similarity model and dis-
tortion model in accordance with equation 1
p(e?J1 |EI1) =
?
aJ1
J?
j=1
[p(aj |aj?1, I)p(e?j |eaj )] (1)
The similarity between a hypothesis word e?j and
a span Ei is simply a weighted sum of the similar-
ities between e?j and each word contained in Ei as
equation 2:
p(e?j |Ei) =
?
Ei(k)?Ei
pi(k) ? p(e?j |Ei(k)) (2)
The similarity between two words is estimated in
exactly the same way as in conventional IHMM
alignment.
As to the distortion model, the incremental
IHMM model also groups distortion parameters
into a few ?buckets?:
c(d) = (1 + |d? 1|)?K
The problem in incremental IHMM is when to ap-
ply a bucket. In conventional IHMM, the transi-
tion from state i to j has probability:
p?(j|i, I) = c(j ? i)?I
l=1 c(l ? i)
(3)
It is tempting to apply the same formula to the
transitions in incremental IHMM. However, the
backbone in the incremental IHMM has a special
property that it is gradually expanding due to the
insertion operator. For example, initially the back-
bone CN contains the option ei in the i-th span and
the option ei+1 in the (i+1)-th span. After the first
round alignment, perhaps ei is aligned to the hy-
pothesis word e?j , ei+1 to e?j+2, and the hypothesis
word e?j+1 is left unaligned. Then the consequent
CN have an extra span containing the option e?j+1
inserted between the i-th and (i + 1)-th spans of
the initial CN. If the distortion buckets are applied
as in equation 3, then in the first round alignment,
the transition from the span containing ei to that
containing ei+1 is based on the bucket c(1), but
in the second round alignment, the same transition
will be based on the bucket c(2). It is therefore not
reasonable to apply equation 3 to such gradually
extending backbone as the monotonic alignment
assumption behind the equation no longer holds.
There are two possible ways to tackle this prob-
lem. The first solution estimates the transition
probability as a weighted average of different dis-
tortion probabilities, whereas the second solution
converts the distortion over spans to the distortion
over the words in each hypothesis E(k) in the CN.
3.1 Distortion Model 1: simple weighting of
covered n-grams
Distortion Model 1 shifts the monotonic alignment
assumption from spans of CN to n-grams covered
by state transitions. Let us illustrate this point with
the following examples.
In conventional IHMM, the distortion probabil-
ity p?(i + 1|i, I) is applied to the transition from
state i to i+1 given I states because such transition
951
jumps across only one word, viz. the i-th word of
the backbone. In incremental IHMM, suppose the
i-th span covers two arcs ea and ?, with probabili-
ties p1 and p2 = 1? p1 respectively, then the tran-
sition from state i to i+ 1 jumps across one word
(ea) with probability p1 and jumps across nothing
with probability p2. Thus the transition probabil-
ity should be p1 ? p?(i+ 1|i, I) + p2 ? p?(i|i, I).
Suppose further that the (i + 1)-th span covers
two arcs eb and ?, with probabilities p3 and p4 re-
spectively, then the transition from state i to i+ 2
covers 4 possible cases:
1. nothing (??) with probability p2 ? p4;
2. the unigram ea with probability p1 ? p4;
3. the unigram eb with probability p2 ? p3;
4. the bigram eaeb with probability p1 ? p3.
Accordingly the transition probability should be
p2p4p?(i|i, I) + p1p3p?(i+ 2|i, I) +
(p1p4 + p2p3)p?(i+ 1|i, I).
The estimation of transition probability can be
generalized to any transition from i to i? by ex-
panding all possible n-grams covered by the tran-
sition and calculating the corresponding probabil-
ities. We enumerate all possible cell sequences
S(i, i?) covered by the transition from span i to
i?; each sequence is assigned the probability
P i?i =
i??1?
q=i
pq(k).
where the cell at the i?-th span is on some row
E(k). Since a cell may represent an empty word,
a cell sequence may represent an n-gram where
0 ? n ? i? ? i (or 0 ? n ? i ? i? in backward
transition). We denote |S(i, i?)| to be the length of
n-gram represented by a particular cell sequence
S(i, i?). All the cell sequences S(i, i?) can be clas-
sified, with respect to the length of corresponding
n-grams, into a set of parameters where each ele-
ment (with a particular value of n) has the proba-
bility
P i?i (n; I) =
?
|S(i,i?)|=n
P i?i .
The probability of the transition from i to i? is:
p(i?|i, I) =
?
n
[P i?i (n; I) ? p?(i+ n|i, I)]. (4)
That is, the transition probability of incremental
IHMM is a weighted sum of probabilities of ?n-
gram jumping?, defined as conventional IHMM
distortion probabilities.
However, in practice it is not feasible to ex-
pand all possible n-grams covered by any transi-
tion since the number of n-grams grows exponen-
tially. Therefore a length limit L is imposed such
that for all state transitions where |i? ? i| ? L, the
transition probability is calculated as equation 4,
otherwise it is calculated by:
p(i?|i, I) = maxq p(i
?|q, I) ? p(q|i, I)
for some q between i and i?. In other words, the
probability of longer state transition is estimated
in terms of the probabilities of transitions shorter
or equal to the length limit.2 All the state transi-
tions can be calculated efficiently by dynamic pro-
gramming.
A fixed value P0 is assigned to transitions to
null state, which can be optimized on held-out
data. The overall distortion model is:
p?(j|i, I) =
{
P0 if j is null state
(1? P0)p(j|i, I) otherwise
3.2 Distortion Model 2: weighting of
distortions of component translations
The cause of the problem of distortion over CN
spans is the gradual extension of CN due to the
inserted empty words. Therefore, the problem
will disappear if the inserted empty words are re-
moved. The rationale of Distortion Model 2 is
that the distortion model is defined over the ac-
tual word sequence in each component translation
E(k).
Distortion Model 2 implements a CN in such a
way that the real position of the i-th word of the k-
th component translation can always be retrieved.
The real position of Ei(k), ?(i, k), refers to the
position of the word represented by Ei(k) in the
compact form of E(k) (i.e. the form without any
inserted empty words), or, if Ei(k) represents an
empty word, the position of the nearest preceding
non-empty word. For convenience, we also denote
by ??(i, k) the null state associated with the state
of the real word ?(i, k). Similarly, the real length
2This limit L is also imposed on the parameter I in distor-
tion probability p?(i?|i, I), because the value of I is growing
larger and larger during the incremental alignment process. I
is defined as L if I > L.
952
of E(k), L(k), refers to the number of non-empty
words of E(k).
The transition from span i? to i is then defined
as
p(i|i?) = 1?
k W (k)
?
k
[W (k) ? pk(i|i?)] (5)
where k is the row index of the tabular form CN.
Depending on Ei(k) and Ei?(k), pk(i|i?) is
computed as follows:
1. if both Ei(k) and Ei?(k) represent real
words, then
pk(i|i?) = p?(?(i, k)|?(i?, k), L(k))
where p? refers to the conventional IHMM
distortion probability as defined by equa-
tion 3.
2. if Ei(k) represents a real word but Ei?(k) the
empty word, then
pk(i|i?) = p?(?(i, k)|??(i?, k), L(k))
Like conventional HMM-based word align-
ment, the probability of the transition from a
null state to a real word state is the same as
that of the transition from the real word state
associated with that null state to the other real
word state. Therefore,
p?(?(i, k)|??(i?, k), L(k)) =
p?(?(i, k)|?(i?, k), L(k))
3. if Ei(k) represents the empty word but
Ei?(k) a real word, then
pk(i|i?) =
{
P0 if?(i, k) = ?(i?, k)
P0P?(i|i?; k) otherwise
where P?(i|i?; k) = p?(?(i, k)|?(i?, k), L(k)).
The second option is due to the constraint that
a null state is accessible only to itself or the
real word state associated with it. Therefore,
the transition from i? to i is in fact composed
of the first transition from i? to ?(i, k) and the
second transition from ?(i, k) to the null state
at i.
4. if both Ei(k) and Ei?(k) represent the empty
word, then, with similar logic as cases 2
and 3,
pk(i|i?) =
{
P0 if?(i, k) = ?(i?, k)
P0P?(i|i?; k) otherwise
4 Incremental Alignment using
Consensus Decoding over Multiple
IHMMs
The previous section describes an incremental
IHMM model in which the state space is based on
the CN taken as a whole. An alternative approach
is to conceive the rows (component translations)
in the CN as individuals, and transforms the align-
ment of a hypothesis against an entire network to
that against the individual translations. Each in-
dividual translation constitutes an IHMM and the
optimal alignment is obtained from consensus de-
coding over these multiple IHMMs.
Alignment over multiple sequential patterns has
been investigated in different contexts. For ex-
ample, Nair and Sreenivas (2007) proposed multi-
pattern dynamic time warping (MPDTW) to align
multiple speech utterances to each other. How-
ever, these methods usually assume that the align-
ment is monotonic. In this section, a consensus
decoding algorithm that searches for the optimal
(non-monotonic) alignment between a hypothesis
and a set of translations in a CN (which are already
aligned to each other) is developed as follows.
A prerequisite of the algorithm is a function
for converting a span index to the corresponding
HMM state index of a component translation. The
two functions ? and ?? s defined in section 3.2 are
used to define a new function:
??(i, k) =
{
??(i, k) if Ei(k) is null
?(i, k) otherwise
Accordingly, given the alignment aJ1 = a1 . . . aJ
of a hypothesis (with J words) against a CN
(where each aj is an index referring to the span
of the CN), we can obtain the alignment a?k =
??(a1, k) . . . ??(aJ , k) between the hypothesis and
the k-th row of the tabular CN. The real length
function L(k) is also used to obtain the number of
non-empty words of E(k).
Given the k-th row of a CN, E(k), an IHMM
?(k) is formed and the cost of the pair-wise align-
ment, a?k, between a hypothesis h and ?(k) is de-
fined as:
C(a?k;h, ?(k)) = ? logP (a?k|h, ?(k)) (6)
The cost of the alignment of h against a CN is then
defined as the weighted sum of the costs of the K
alignments a?k:
C(a;h,?) =
?
k
W (k)C(a?k;h, ?(k))
953
= ?
?
k
W (k) logP (a?k|h, ?(k))
where ? = {?(k)} is the set of pair-wise IHMMs,
and W (k) is the weight of the k-th row. The op-
timal alignment a? is the one that minimizes this
cost:
a? = argmaxa
?
k
W (k) logP (a?k|h, ?(k))
= argmaxa
?
k
W (k)[
?
j
[
logP (??(aj , k)|??(aj?1, k), L(k)) +
logP (ej |Ei(k))]]
= argmaxa
?
j
[
?
k
W (k) logP (??(aj , k)|??(aj?1, k), L(k)) +
?
k
W (k) logP (ej |Ei(k))]
= argmaxa
?
j
[logP ?(aj |aj?1) +
logP ?(ej |Eaj )]
A Viterbi-like dynamic programming algorithm
can be developed to search for a? by treating CN
spans as HMM states, with a pseudo emission
probability as
P ?(ej |Eaj ) =
K?
k=1
P (ej |Eaj (k))W (k)
and a pseudo transition probability as
P ?(j|i) =
K?
k=1
P (??(j, k)|??(i, k), L(k))W (k)
Note that P ?(ej |Eaj ) and P ?(j|i) are not true
probabilities and do not have the sum-to-one prop-
erty.
5 Alignment Normalization
After alignment, the backbone CN and the hypoth-
esis can be combined to form an even larger CN.
The same principles and heuristics for the con-
struction of CN in conventional system combina-
tion approaches can be applied. Our incremen-
tal alignment approaches adopt the same heuris-
tics for alignment normalization stated in He et al
(2008). There is one exception, though. All 1-
N mappings are not converted to N ? 1 ?-1 map-
pings since this conversion leads to N ? 1 inser-
tion in the CN and therefore extending the net-
work to an unreasonable length. The Viterbi align-
ment is abandoned if it contains an 1-N mapping.
The best alignment which contains no 1-N map-
ping is searched in the N-Best alignments in a way
inspired by Nilsson and Goldberger (2001). For
example, if both hypothesis words e?1 and e?2 are
aligned to the same backbone span E1, then all
alignments aj={1,2} = i (where i 6= 1) will be
examined. The alignment leading to the least re-
duction of Viterbi probability when replacing the
alignment aj={1,2} = 1 will be selected.
6 Order of Hypotheses
The default order of hypotheses in Rosti et al
(2008) is to rank the hypotheses in descending of
their TER scores against the backbone. This pa-
per attempts several other orders. The first one is
system-based order, i.e. assume an arbitrary order
of the MT systems and feeds all the translations
(in their original order) from a system before the
translations from the next system. The rationale
behind the system-based order is that the transla-
tions from the same system are much more similar
to each other than to the translations from other
systems, and it might be better to build CN by
incorporating similar translations first. The sec-
ond one is N-best rank-based order, which means,
rather than keeping the translations from the same
system as a block, we feed the top-1 translations
from all systems in some order of systems, and
then the second best translations from all systems,
and so on. The presumption of the rank-based or-
der is that top-ranked hypotheses are more reliable
and it seemed beneficial to incorporate more reli-
able hypotheses as early as possible. These two
kinds of order of hypotheses involve a certain de-
gree of randomness as the order of systems is arbi-
trary. Such randomness can be removed by impos-
ing a Bayes Risk order on MT systems, i.e. arrange
the MT systems in ascending order of the Bayes
Risk of their top-1 translations. These four orders
of hypotheses are summarized in Table 1. We also
tried some intuitively bad orders of hypotheses, in-
cluding the reversal of these four orders and the
random order.
7 Evaluation
The proposed approaches of incremental IHMM
are evaluated with respect to the constrained
Chinese-to-English track of 2008 NIST Open MT
954
Order Example
System-based 1:1 . . . 1:N 2:1 . . . 2:N . . . M:1 . . . M:N
N-best Rank-based 1:1 2:1 . . . M:1 . . . 1:2 2:2 . . . M:2 . . . 1:N . . . M:N
Bayes Risk + System-based 4:1 4:2 . . . 4:N . . . 1:1 1:2 . . . 1:N . . . 5:1 5:2 . . . 5:N
Bayes Risk + Rank-based 4:1 . . . 1:1 . . . 5:1 4:2 . . . 1:2 . . . 5:2 . . . 4:N . . . 1:N . . . 5:N
Table 1: The list of order of hypothesis and examples. Note that ?m:n? refers to the n-th translation from
the m-th system.
Evaluation (NIST (2008)). In the following sec-
tions, the incremental IHMM approaches using
distortion model 1 and 2 are named as IncIHMM1
and IncIHMM2 respectively, and the consensus
decoding of multiple IHMMs as CD-IHMM. The
baselines include the TER-based method in Rosti
et al (2007), the incremental TER method in Rosti
et al (2008), and the IHMM approach in He et
al. (2008). The development (dev) set comprises
the newswire and newsgroup sections of MT06,
whereas the test set is the entire MT08. The 10-
best translations for every source sentence in the
dev and test sets are collected from eight MT sys-
tems. Case-insensitive BLEU-4, presented in per-
centage, is used as evaluation metric.
The various parameters in the IHMM model are
set as the optimal values found in He et al (2008).
The lexical translation probabilities used in the
semantic similarity model are estimated from a
small portion (FBIS + GALE) of the constrained
track training data, using standard HMM align-
ment model (Och and Ney (2003)). The back-
bone of CN is selected by MBR. The loss function
used for TER-based approaches is TER and that
for IHMM-based approaches is BLEU. As to the
incremental systems, the default order of hypothe-
ses is the ascending order of TER score against the
backbone, which is the order proposed in Rosti
et al (2008). The default order of hypotheses
for our three incremental IHMM approaches is
N-best rank order with Bayes Risk system order,
which is empirically found to be giving the high-
est BLEU score. Once the CN is built, the final
system combination output can be obtained by de-
coding it with a set of features and decoding pa-
rameters. The features we used include word con-
fidences, language model score, word penalty and
empty word penalty. The decoding parameters are
trained by maximum BLEU training on the dev
set. The training and decoding processes are the
same as described by Rosti et al (2007).
Method dev test
best single system 32.60 27.75
pair-wise TER 37.90 30.96
incremental TER 38.10 31.23
pair-wise IHMM 38.52 31.65
incremental IHMM 39.22 32.63
Table 2: Comparison between IncIHMM2 and the
three baselines
7.1 Comparison against Baselines
Table 2 lists the BLEU scores achieved by
the three baseline combination methods and
IncIHMM2. The comparison between pairwise
and incremental TER methods justifies the supe-
riority of the incremental strategy. However, the
benefit of incremental TER over pair-wise TER is
smaller than that mentioned in Rosti et al (2008),
which may be because of the difference between
test sets and other experimental conditions. The
comparison between the two pair-wise alignment
methods shows that IHMM gives a 0.7 BLEU
point gain over TER, which is a bit smaller than
the difference reported in He et al (2008). The
possible causes of such discrepancy include the
different dev set and the smaller training set for
estimating semantic similarity parameters. De-
spite that, the pair-wise IHMM method is still a
strong baseline. Table 2 also shows the perfor-
mance of IncIHMM2, our best incremental IHMM
approach. It is almost one BLEU point higher than
the pair-wise IHMM baseline and much higher
than the two TER baselines.
7.2 Comparison among the Incremental
IHMM Models
Table 3 lists the BLEU scores achieved by
the three incremental IHMM approaches. The
two distortion models for IncIHMM approach
lead to almost the same performance, whereas
CD-IHMM is much less satisfactory.
For IncIHMM, the gist of both distortion mod-
955
Method dev test
IncIHMM1 39.06 32.60
IncIHMM2 39.22 32.63
CD-IHMM 38.64 31.87
Table 3: Comparison between the three incremen-
tal IHMM approaches
els is to shift the distortion over spans to the dis-
tortion over word sequences. In distortion model 2
the word sequences are those sequences available
in one of the component translations in the CN.
Distortion model 1 is more encompassing as it also
considers the word sequences which are combined
from subsequences from various component trans-
lations. However, as mentioned in section 3.1,
the number of sequences grows exponentially and
there is therefore a limit L to the length of se-
quences. In general the limit L ? 8 would ren-
der the tuning/decoding process intolerably slow.
We tried the values 5 to 8 for L and the variation
of performance is less than 0.1 BLEU point. That
is, distortion model 1 cannot be improved by tun-
ing L. The similar BLEU scores as shown in Ta-
ble 3 implies that the incorporation of more word
sequences in distortion model 1 does not lead to
extra improvement.
Although consensus decoding is conceptually
different from both variations of IncIHMM, it
can indeed be transformed into a form similar to
IncIHMM2. IncIHMM2 calculates the parameters
of the IHMM as a weighted sum of various proba-
bilities of the component translations. In contrast,
the equations in section 4 shows that CD-IHMM
calculates the weighted sum of the logarithm of
those probabilities of the component translations.
In other words, IncIHMM2 makes use of the sum
of probabilities whereas CD-IHMM makes use
of the product of probabilities. The experiment
results indicate that the interaction between the
weights and the probabilities is more fragile in the
product case than in the summation case.
7.3 Impact of Order of Hypotheses
Table 4 lists the BLEU scores on the test set
achieved by IncIHMM1 using different orders of
hypotheses. The column ?reversal? shows the im-
pact of deliberately bad order, viz. more than one
BLEU point lower than the best order. The ran-
dom order is a baseline for not caring about or-
der of hypotheses at all, which is about 0.7 BLEU
normal reversal
System 32.36 31.46
Rank 32.53 31.56
BR+System 32.37 31.44
BR+Rank 32.6 31.47
random 31.94
Table 4: Comparison between various orders of
hypotheses. ?System? means system-based or-
der; ?Rank? means N-best rank-based order; ?BR?
means Bayes Risk order of systems. The numbers
are the BLEU scores on the test set.
point lower than the best order. Among the orders
with good performance, it is observed that N-best
rank order leads to about 0.2 to 0.3 BLEU point
improvement, and that the Bayes Risk order of
systems does not improve performance very much.
In sum, the performance of incremental alignment
is sensitive to the order of hypotheses, and the op-
timal order is defined in terms of the rank of each
hypothesis on some system?s n-best list.
8 Conclusions
This paper investigates the application of the in-
cremental strategy to IHMM, one of the state-of-
the-art alignment methods for MT output com-
bination. Such a task is subject to the prob-
lem of how to define state transitions on a grad-
ually expanding CN. We proposed three differ-
ent solutions, which share the principle that tran-
sition over CN spans must be converted to the
transition over word sequences provided by the
component translations. While the consensus de-
coding approach does not improve performance
much, the two distortion models for incremental
IHMM (IncIHMM1 and IncIHMM2) give superb
performance in comparison with pair-wise TER,
pair-wise IHMM, and incremental TER. We also
showed that the order of hypotheses is important
as a deliberately bad order would reduce transla-
tion quality by one BLEU point.
References
Xiaodong He, Mei Yang, Jianfeng Gao, Patrick
Nguyen, and Robert Moore 2008. Indirect-HMM-
based Hypothesis Alignment for Combining Out-
puts from Machine Translation Systems. Proceed-
ings of EMNLP 2008.
Damianos Karakos, Jason Eisner, Sanjeev Khudanpur,
and Markus Dreyer 2008. Machine Translation
956
System Combination using ITG-based Alignments.
Proceedings of ACL 2008.
Evgeny Matusov, Nicola Ueffing and Hermann Ney.
2006. Computing Consensus Translation from Mul-
tiple Machine Translation Systems using Enhanced
Hypothesis Alignment. Proceedings of EACL.
Nishanth Ulhas Nair and T.V. Sreenivas. 2007. Joint
Decoding of Multiple Speech Patterns for Robust
Speech Recognition. Proceedings of ASRU.
Dennis Nilsson and Jacob Goldberger 2001. Sequen-
tially Finding the N-Best List in Hidden Markov
Models. Proceedings of IJCAI 2001.
NIST 2008. The NIST Open Machine
Translation Evaluation. www.nist.gov/
speech/tests/mt/2008/doc/
Franz J. Och and Hermann Ney 2003. A Systematic
Comparison of Various Statistical Alignment Mod-
els. Computational Linguistics 29(1):pp 19-51
Kishore Papineni, Salim Roukos, Todd Ward and Wei-
Jing Zhu 2002. BLEU: a Method for Automatic
Evaluation of Machine Translation. Proceedings of
ACL 2002
Antti-Veikko I. Rosti, Spyros Matsoukas, and Richard
Schwartz 2007. Improved Word-level System Com-
bination for Machine Translation. Proceedings of
ACL 2007.
Antti-Veikko I. Rosti, Bing Zhang, Spyros Matsoukas,
and Richard Schwartz 2008. Incremental Hypoth-
esis Alignment for Building Confusion Networks
with Application to Machine Translation System
Combination. Proceedings of the 3rd ACL Work-
shop on SMT.
Khe Chai Sim, William J. Byrne, Mark J.F. Gales,
Hichem Sahbi, and Phil C. Woodland 2007. Con-
sensus Network Decoding for Statistical Machine
Translation System Combination. Proceedings of
ICASSP vol. 4.
Matthew Snover, Bonnie Dorr, Rich Schwartz, Linnea
Micciulla and John Makhoul 2006. A Study of
Translation Edit Rate with Targeted Human Anno-
tation. Proceedings of AMTA 2006
957
Proceedings of the ACL-HLT 2011 Student Session, pages 1?5,
Portland, OR, USA 19-24 June 2011. c?2011 Association for Computational Linguistics
Word Alignment Combination over Multiple Word Segmentation 
 
 
Ning Xi, Guangchao Tang, Boyuan Li, Yinggong Zhao 
State Key Laboratory for Novel Software Technology, 
Department of Computer Science and Technology, 
Nanjing University, Nanjing, 210093, China 
 {xin,tanggc,liby,zhaoyg}@nlp.nju.edu.cn 
 
 
 
 
 
 
Abstract 
In this paper, we present a new word alignment 
combination approach on language pairs where 
one language has no explicit word boundaries. 
Instead of combining word alignments of dif-
ferent models (Xiang et al, 2010), we try to 
combine word alignments over multiple mono-
lingually motivated word segmentation. Our 
approach is based on link confidence score de-
fined over multiple segmentations, thus the 
combined alignment is more robust to inappro-
priate word segmentation. Our combination al-
gorithm is simple, efficient, and easy to 
implement. In the Chinese-English experiment, 
our approach effectively improved word align-
ment quality as well as translation performance 
on all segmentations simultaneously, which 
showed that word alignment can benefit from 
complementary knowledge due to the diversity 
of multiple and monolingually motivated seg-
mentations. 
1 Introduction 
Word segmentation is the first step prior to word 
alignment for building statistical machine transla-
tions (SMT) on language pairs without explicit 
word boundaries such as Chinese-English.  Many 
works have focused on the improvement of word 
alignment models. (Brown et al, 1993; Haghighi et 
al., 2009; Liu et al, 2010). Most of the word 
alignment models take single word segmentation 
as input. However, for languages such as Chinese, 
it is necessary to segment sentences into appropri-
ate words for word alignment. 
A large amount of works have stressed the im-
pact of word segmentation on word alignment. Xu 
et al (2004), Ma et al (2007), Chang et al (2008), 
and Chung et al (2009) try to learn word segmen-
tation from bilingually motivated point of view; 
they use an initial alignment to learn word segmen-
tation appropriate for SMT. However, their per-
formance is limited by the quality of the initial 
alignments, and the processes are time-consuming. 
Some other methods try to combine multiple word 
segmentation at SMT decoding step (Xu et al, 
2005; Dyer et al, 2008; Zhang et al, 2008; Dyer et 
al., 2009; Xiao et al, 2010). Different segmenta-
tions are yet independently used for word align-
ment. 
Instead of time-consuming segmentation optimi-
zation based on alignment or postponing segmenta-
tion combination late till SMT decoding phase, we 
try to combine word alignments over multiple 
monolingually motivated word segmentation on 
Chinese-English pair, in order to improve word 
alignment quality and translation performance for 
all segmentations. We introduce a tabular structure 
called word segmentation network (WSN for short) 
to encode multiple segmentations of a Chinese sen-
tence, and define skeleton links (SL for short) be-
tween spans of WSN and words of English 
sentence. The confidence score of a SL is defined 
over multiple segmentations. Our combination al-
gorithm picks up potential SLs based on their con-
fidence scores similar to Xiang et al (2010), and 
then projects each selected SL to link in all seg-
mentation respectively. Our algorithm is simple, 
efficient, easy to implement, and can effectively 
improve word alignment quality on all segmenta-
tions simultaneously, and alignment errors caused 
1
by inappropriate segmentations from single seg-
menter can be substantially reduced. 
Two questions will be answered in the paper: 1) 
how to define the link confidence over multiple 
segmentations in combination algorithm? 2) Ac-
cording to Xiang et al (2010), the success of their 
word alignment combination of different models 
lies in the complementary information that the 
candidate alignments contain. In our work, are 
multiple monolingually motivated segmentations 
complementary enough to improve the alignments? 
The rest of this paper is structured as follows: 
WSN will be introduced in section 2. Combination 
algorithm will be presented in section 3. Experi-
ments of word alignment and SMT will be reported 
in section 4. 
2  Word Segmentation Network 
We propose a new structure called word segmenta-
tion network (WSN) to encode multiple segmenta-
tions. Due to space limitation, all definitions are 
presented by illustration of a running example of a 
sentence pair: 
 
???? (xia-yu-lu-hua)  
Road is slippery when raining 
 
We first introduce skeleton segmentation. Given 
two segmentation S1 and S2 in Table 1, the word 
boundaries of their skeleton segmentation is the 
union of word boundaries (marked by ?/?) in S1 
and S2. 
 
 Segmentation 
S1 ? / ? / ?? 
S2 ?? / ? / ? 
skeleton ? / ? / ? / ? 
 
Table 1: The skeleton segmentation of two seg-
mentations S1 and S2. 
 
The WSN of S1 and S2 is shown in Table 2.  As 
is depicted, line 1 and 2 represent words in S1 and 
S2 respectively, line 3 represents skeleton words. 
Each column, or span, comprises a skeleton word 
and words of S1 and S2 with the skeleton word as 
their morphemes at that position. The number of 
columns of a WSN is equal to the number of skele-
ton words. It should be noted that there may be 
words covering two or more spans, such as ???? 
in S1, because the word ???? in S1 is split into 
two words ??? and ??? in S2.  
S1 ? 1 ? 2 ?? 3 
S2 ?? 1 ? 2 ? 3 
skeleton ? 1 ? 2 ? 3 ? 4 
 
Table 2:  The WSN of Table 1. Subscripts 
indicate indexes of words. 
 
The skeleton word can be projected onto words 
in the same span in S1 and S2. For clarity, words in 
each segmentation are indexed (1-based), for ex-
ample, ???? in S1 is indexed by 3. We use a pro-
jection function       to denote the index of the 
word onto which the j-th skeleton word is project-
ed in the k-th segmentation, for example,       
  and        . 
In the next, we define the links between spans of 
the WSN and English words as skeleton links (SL), 
the subset of all SLs comprise the skeleton align-
ment (SA). Figure 1 shows an SA of the example. 
 
Figure 1: An example alignment between WSN in 
Table 2 and English sentence ?Road is slippery 
when raining?. (a) skeleton link; (b) skeleton 
alignment. 
 
Each span of the WSN comprises words from 
different segmentations (Figure 1a), which indi-
cates that the confidence score of a SL can be de-
fined over words in the same span. By projection 
function, a SL can be projected onto the link for 
each segmentation. Therefore, the problem of 
combining word alignment over different segmen-
tations can be transformed into the problem of se-
lecting SLs for SA first, and then project the 
selected SLs onto links for each segmentation re-
spectively. 
3  Combination Algorithm 
Given k alignments    over segmentations    
respectively         ), and       is the pair 
Road  
  
? 1 ? 2 ?? 3 
?? 1 ? 2 ? 3 
? 1 ? 2 ? 3 ? 4 
 
(a) 
  
(b) 
 
?? 3 
? 2 
? 3 
 
Road is slippery when raining  
2
of the Chinese WSN and its parallel English sen-
tence. Suppose     is the SL between the j-th span 
   and i-th English word   ,    
   is the link between 
the j-th Chinese word   
  in    and   . Inspired by 
Huang (2009), we define the confidence score of 
each SL as follows 
 (   |   )  ?             
           (1) 
 
where          
       is the confidence score of the 
link        
 , defined as 
 (       
 |   )
 ?    (       
 |   )              
       
(2) 
where c-to-e link posterior probability is defined as 
    (       
 |   )  
            
  
?               
   
    
  
 (3) 
and I is the length of  . E-to-c link posterior prob-
ability     (       
 |   )  can be defined similarly,  
Our alignment combination algorithm is as fol-
lows.  
1. Build WSN for Chinese sentence. 
2. Compute the confidence score for each SL 
based on Eq. (1). A SL     gets a vote from    
if        
  appears in             . Denote 
the set of all SLs getting at least one vote by 
  . 
3. All SLs in    are sorted in descending order 
and evaluated sequentially. A SL     is includ-
ed if its confidence score is higher than a tuna-
ble threshold  , and one of the following is 
true1: 
? Neither    nor    is aligned so far; 
?    is not aligned and its left or right neigh-
boring word is aligned to    so far; 
?    is not aligned and its left or right 
neighboring word is aligned to    so far. 
4. Repeat 3 until no more SLs can be included. 
All included SLs comprise   . 
5. Map SLs in    on each    to get k new align-
ments   
  respectively, i.e.   
          
      
   2         . For each  , we sort all 
                                                          
1 SLs getting   votes are forced to be included without further 
examination. 
2 Two or more SLs in    may be projected onto one links in 
  
 , in this case, we keep only one in   
 . 
links in   
  in ascending order and evaluated 
them sequentially  Compare   
  and   , A link 
    
  is removed from   
  if it is not appeared in 
  , and one of the following is true: 
? both   
 and    are aligned in   
 ; 
? There is a word which is neither left nor 
right neighboring word of    but aligned 
to   
  in   
 ; 
? There is a word which is neither left nor 
right neighboring word of   
  but aligned 
to    in   
 . 
The heuristic in step 3 is similar to Xiang et al 
(2010), which avoids adding error-prone links. We 
apply the similar heuristic again in step 5 in each 
  
            to delete error-prone links. The 
weights in Eq. (1) and   can be tuned in a hand-
aligned dataset to maximize word alignment F-
score on any   
  with hill climbing algorithm. 
Probabilities in Eq. (2) and Eq. (3) can be estimat-
ed using GIZA. 
4 Experiment 
4.1   Data 
Our training set contains about 190K Chinese-
English sentence pairs from LDC2003E14 corpus. 
The NIST?06 test set is used as our development 
set and the NIST?08 test set is used as our test set. 
The Chinese portions of all the data are prepro-
cessed by three monolingually motived segmenters 
respectively. These segmenters differ in either 
training method or specification, including 
ICTCLAS (I)3, Stanford segmenters with CTB (C) 
and PKU (P) specifications4 respectively. We used 
a phrase-based MT system similar to (Koehn et al, 
2003), and generated two baseline alignments us-
ing GIZA++ enhanced by gdf heuristics (Koehn et 
al., 2003) and a linear discriminative word align-
ment model (DIWA) (Liu et al, 2010) on training 
set with the three segmentations respectively. A 5-
gram language model trained from the Xinhua por-
tion of Gigaword corpus was used.  The decoding 
weights were optimized with Minimum Error Rate 
Training (MERT) (Och, 2003). We used the hand-
aligned set of 491 sentence pairs in Haghighi et al 
(2009), the first 250 sentence pairs were used to 
tune the weights in Eq. (1), and the other 241 were 
                                                          
3 http://www.ictclas.org/ 
4 http://nlp.stanford.edu/software/segmenter.shtml 
3
[???] [?] [380] [?] [??] [???] 
relief funds worth 3.8 million us dollars from the national foodstuff department 
[??] [??] [???] [??] [??] 
chief executive in the hksar  
[???] [?] [380] [?] [??] [???] [??] [??] [???] [??] [??] 
Figure 2: Two examples (left and right respectively) of word alignment on segmentation C. Baselines 
(DIWA) are in the top half, combined alignments are in the bottom half. The solid line represents the cor-
rect link while the dashed line represents the bad link. Each word is enclosed in square brackets. 
used to measure the word alignment quality. Note 
that we adapted the Chinese portion of this hand-
aligned set to segmentation C. 
4.2 Improvement of Word Alignment 
We first evaluate our combination approach on the 
hand-aligned set (on segmentation C). Table 3 
shows the precision, recall and F-score of baseline 
alignments and combined alignments. 
As shown in Table 3, the combination align-
ments outperformed the baselines (setting C) in all 
settings in both GIZA and DIWA. We notice that 
the higher F-score is mainly due to the higher pre-
cision in GIZA but higher recall in DIWA. In 
GIZA, the result of C+I and C+P achieve 8.4% and 
9.5% higher F-score respectively, and both of them 
outperformed C+P+I, we speculate it is because 
GIZA favors recall rather than DIWA, i.e. GIZA 
may contain more bad links than DIWA, which 
would lead to more unstable F-score if more 
alignments produced by GIZA are combined, just 
as the poor precision (69.68%) indicated. However, 
DIWA favors precision than recall (this observa-
tion is consistent with Liu et al (2010)), which 
may explain that the more diversified segmenta-
tions lead to better results in DIWA. 
 
 GIZA DIWA 
setting P R F P R F 
C 61.84 84.99 71.59 83.12 78.88 80.94 
C+P 80.16 79.80 79.98 84.15 79.41 81.57 
C+I 82.96 79.28 81.08 84.41 81.69 83.03 
C+I+P 69.68 85.17 77.81 83.38 82.98 83.18 
 
Table 3: Alignment precision, recall and F-score.  
C: baseline, C+I: Combination of C and I. 
 
Figure 2 gives baseline alignments and com-
bined alignments on two sentence pairs in the 
training data. As can be seen, alignment errors 
caused by inappropriate segmentations by single 
segmenter were substantially reduced.  For exam-
ple, in the second example, the word ??????
?? hksar? appears in segmentation I of the Chi-
nese sentence, which benefits the generation of the 
three correct links connecting for words ??
?? ,????, ????? respectively in the com-
bined alignment. 
4.3   Improvement in MT performance 
We then evaluate our combination approach on the 
SMT training data on all segmentations. For effi-
ciency, we just used the first 50k sentence pairs of 
the aligned training corpus with the three segmen-
tations to build three SMT systems respectively. 
Table 4 shows the BLEU scores of baselines and 
combined alignment (C+P+I, and then projected 
onto C, P, I respectively). Our approach achieves 
improvement over baseline alignments on all seg-
mentations consistently, without using any lattice 
decoding techniques as Dyer et al (2009).  The 
gain of translation performance purely comes from 
improvements of word alignment on all segmenta-
tions by our proposed word alignment combination. 
 
 GIZA DIWA 
Segmentation B Comb B Comb 
C 19.77 20.9 20.18 20.71 
P 20.5 21.16 20.41 21.14 
I 20.11 21.14 20.46 21.30 
 
Table 4: Improvement in BLEU scores. B:Baseline 
alignment, Comb: Combined alignment. 
4
5 Conclusion 
We evaluated our word alignment combination 
over three monolingually motivated segmentations 
on Chinese-English pair. We showed that the com-
bined alignment significantly outperforms the 
baseline alignment with both higher F-score and 
higher BLEU score on all segmentations. Our work 
also proved the effectiveness of link confidence 
score in combining different word alignment mod-
els (Xiang et al, 2010), and extend it to combine 
word alignments over different segmentations. 
Xu et al (2005) and Dyer et al (2009) combine 
different segmentations for SMT. They aim to 
achieve better translation but not higher alignment 
quality of all segmentations. They combine multi-
ple segmentations at SMT decoding step, while we 
combine segmentation alternatives at word align-
ment step. We believe that we can further improve 
the performance by combining these two kinds of 
works. We also believe that combining word 
alignments over both monolingually motivated and 
bilingually motivated segmentations (Ma et al, 
2009) can achieve higher performance. 
In the future, we will investigate combining 
word alignments on language pairs where both 
languages have no explicit word boundaries such 
as Chinese-Japanese. 
Acknowledgments 
This work was supported by the National Natural 
Science Foundation of China under Grant No. 
61003112, and the National Fundamental Research 
Program of China (2010CB327903). We would 
like to thank Xiuyi Jia and Shujie Liu for useful 
discussions and the anonymous reviewers for their 
constructive comments. 
 
References  
Peter F. Brown, Stephen A. Della Pietra, Vincent J. Del-
la Peitra, Robert L. Mercer. 1993. The Mathematics 
of statistical machine translation: parameter estima-
tion. Computational Linguistics, 19(2):263-311. 
Pi-Chuan Chang, Michel Galley, and Christopher D. 
Manning. 2008. Optimizing Chinese word segmenta-
tion for machine translation performance.  In Pro-
ceedings of third workshop on SMT, Pages:224-232. 
Tagyoung Chung and Daniel Gildea. 2009. Unsuper-
vised tokenization for machine translation. In Pro-
ceedings of EMNLP, Pages:718-726. 
Christopher Dyer, Smaranda Muresan, and Philip Res-
nik. 2008. Generalizing word lattice translation. In 
Proceedings of ACL, Pages:1012-1020. 
Christopher Dyer. 2009. Using a maximum entropy 
model to build segmentation lattices for mt. In Pro-
ceedings of NAACL, Pages:406-414. 
Franz Josef Och. 2003. Minimum error rate training in 
statistical machine translation. In Proceedings of 
ACL, Pages:440-447. 
Aria Haghighi, John Blitzer, John DeNero, and Dan 
Klein. 2009. Better word alignments with supervised 
ITG models. In Proceedings of ACL, Pages: 923-931. 
Fei Huang. 2009. Confidence measure for word align-
ment. In Proceedings of ACL, Pages:932-940. 
Philipp Koehn, Franz Josef Och and Daniel Marcu. 
2003. Statistical phrase-based translation. In Pro-
ceedings of HLT-NAACL, Pages:48-54. 
Yang Liu, Qun Liu, Shouxun Lin. 2010. Discriminative 
word alignment by linear modeling. Computational 
Linguistics, 36(3):303-339. 
Yanjun Ma, Nicolas Stroppa, and Andy Way. 2007. 
Bootstrapping word alignment via word packing. In 
Proceedings of ACL, Pages:304-311. 
Yanjun Ma and Andy Way. 2009. Bilingually motivated 
domain-adapted word segmentation for statistical 
machine translation. In Proceedings of EACL, Pag-
es:549-557. 
Bing Xiang, Yonggang Deng, and Bowen Zhou. 2010. 
Diversify and combine: improving word alignment 
for machine translation on low-resource languages. 
In Proceedings of ACL, Pages:932-940. 
Xinyan Xiao, Yang Liu, Young-Sook Hwang, Qun Liu, 
Shouxun Lin. 2010.  Joint tokenization and transla-
tion. In Proceedings of COLING, Pages:1200-1208. 
Jia Xu, Richard Zens, and Hermann Ney. 2004. Do we 
need Chinese word segmentation for statistical ma-
chine translation?  In Proceedings of the ACL 
SIGHAN Workshop, Pages: 122-128. 
Jia Xu, Evgeny Matusov, Richard Zens, and Hermann 
Ney. 2005. Integrated Chinese word segmentation in 
statistical machine translation. In Proceedings of 
IWSLT. 
Ruiqiang Zhang, Keiji Yasuda, and Eiichiro Sumita. 
2008. Improved statistical machine translation by 
multiple Chinese word segmentation. In Proceedings 
of the Third Workshop on SMT, Pages:216-223. 
5
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 285?290,
Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational Linguistics
Enhancing Statistical Machine Translation with Character Alignment 
 
Ning Xi, Guangchao Tang, Xinyu Dai, Shujian Huang, Jiajun Chen 
State Key Laboratory for Novel Software Technology, 
Department of Computer Science and Technology, 
Nanjing University, Nanjing, 210046, China 
{xin,tanggc,dxy,huangsj,chenjj}@nlp.nju.edu.cn 
 
  
Abstract 
The dominant practice of statistical machine 
translation (SMT) uses the same Chinese word 
segmentation specification in both alignment 
and translation rule induction steps in building 
Chinese-English SMT system, which may suf-
fer from a suboptimal problem that word seg-
mentation better for alignment is not necessarily 
better for translation. To tackle this, we propose 
a framework that uses two different segmenta-
tion specifications for alignment and translation 
respectively: we use Chinese character as the 
basic unit for alignment, and then convert this 
alignment to conventional word alignment for 
translation rule induction. Experimentally, our 
approach outperformed two baselines: fully 
word-based system (using word for both 
alignment and translation) and fully charac-
ter-based system, in terms of alignment quality 
and translation performance. 
1 Introduction 
Chinese Word segmentation is a necessary step in 
Chinese-English statistical machine translation 
(SMT) because Chinese sentences do not delimit 
words by spaces. The key characteristic of a Chi-
nese word segmenter is the segmentation specifi-
cation1. As depicted in Figure 1(a), the dominant 
practice of SMT uses the same word segmentation 
for both word alignment and translation rule induc-
tion. For brevity, we will refer to the word seg-
mentation of the bilingual corpus as word segmen-
tation for alignment (WSA for short), because it 
determines the basic tokens for alignment; and refer 
to the word segmentation of the aligned corpus as 
word segmentation for rules (WSR for short), be-
cause it determines the basic tokens of translation 
                                                          
1 We hereafter use ?word segmentation? for short. 
rules2, which also determines how the translation 
rules would be matched by the source sentences. 
It is widely accepted that word segmentation with 
a higher F-score will not necessarily yield better 
translation performance (Chang et al, 2008; Zhang 
et al, 2008; Xiao et al, 2010). Therefore, many 
approaches have been proposed to learn word 
segmentation suitable for SMT. These approaches 
were either complicated (Ma et al, 2007; Chang et 
al., 2008; Ma and Way, 2009; Paul et al, 2010), or 
of high computational complexity (Chung and 
Gildea 2009; Duan et al, 2010). Moreover, they 
implicitly assumed that WSA and WSR should be 
equal. This requirement may lead to a suboptimal 
problem that word segmentation better for align-
ment is not necessarily better for translation. 
To tackle this, we propose a framework that uses 
different word segmentation specifications as WSA 
and WSR respectively, as shown Figure 1(b). We 
investigate a solution in this framework: first, we 
use Chinese character as the basic unit for align-
ment, viz. character alignment; second, we use a 
simple method (Elming and Habash, 2007) to 
convert the character alignment to conventional 
word alignment for translation rule induction. In the 
                                                          
2 Interestingly, word is also a basic token in syntax-based rules. 
Word alignment 
Bilingual Corpus 
Aligned Corpus 
WSA
Translation Rules
WSA 
WSR 
Rule induction 
Decoding 
Translation Results WSR
Word alignment 
Bilingual Corpus 
Aligned Corpus 
WSA
Translation Rules 
WSA
WSR
Rule induction 
Decoding 
Translation Results WSR
Aligned Corpus 
WSR
Conversion 
(b) WSA?WSR 
Figure 1. WSA and WSR in SMT pipeline
(a)  WSA=WSR 
285
experiment, our approach consistently outper-
formed two baselines with three different word 
segmenters: fully word-based system (using word 
for both alignment and translation) and fully char-
acter-based system, in terms of alignment quality 
and translation performance. 
The remainder of this paper is structured as fol-
lows: Section 2 analyzes the influences of WSA and 
WSR on SMT respectively; Section 3 discusses 
how to convert character alignment to word align-
ment; Section 4 presents experimental results, fol-
lowed by conclusions and future work in section 5. 
2 Understanding WSA and WSR 
We propose a solution to tackle the suboptimal 
problem: using Chinese character for alignment 
while using Chinese word for translation. Character 
alignment differs from conventional word align-
ment in the basic tokens of the Chinese side of the 
training corpus3. Table 1 compares the token dis-
tributions of character-based corpus (CCorpus) and 
word-based corpus (WCorpus). We see that the 
WCorpus has a longer-tailed distribution than the 
CCorpus. More than 70% of the unique tokens ap-
pear less than 5 times in WCorpus. However, over 
half of the tokens appear more than or equal to 5 
times in the CCorpus.  This indicates that modeling 
word alignment could suffer more from data 
sparsity than modeling character alignment.  
Table 2 shows the numbers of the unique tokens 
(#UT) and unique bilingual token pairs (#UTP) of 
the two corpora. Consider two extensively features, 
fertility and translation features, which are exten-
sively used by many state-of-the-art word aligners. 
The number of parameters w.r.t. fertility features 
grows linearly with #UT while the number of pa-
rameters w.r.t. translation features grows linearly 
with #UTP. We compare #UT and #UTP of both 
corpora in Table 2. As can be seen, CCorpus has 
less UT and UTP than WCorpus, i.e. character 
alignment model has a compact parameterization 
than word alignment model, where the compactness 
of parameterization is shown very important in sta-
tistical modeling (Collins, 1999). 
Another advantage of character alignment is the 
reduction in alignment errors caused by word seg- 
                                                          
3 Several works have proposed to use character (letter) on both 
sides of the parallel corpus for SMT between similar (European) 
languages (Vilar et al, 2007; Tiedemann, 2009), however, 
Chinese is not similar to English. 
Frequency Characters (%) Words (%) 
1 27.22 45.39 
2 11.13 14.61 
3 6.18 6.47 
4 4.26 4.32 
5(+) 50.21 29.21 
Table 1 Token distribution of CCorpus and WCorpus 
 
Stats. Characters Words 
#UT 9.7K 88.1K 
#UTP 15.8M 24.2M 
Table 2 #UT and #UTP in CCorpus and WCorpus 
 
mentation errors. For example, ??? (Cheney)? 
and ?? (will)? are wrongly merged into one word 
???  by the word segmenter, and ??? 
wrongly aligns to a comma in English sentence in 
the word alignment; However, both ? and ? align 
to ?Cheney? correctly in the character alignment. 
However, this kind of errors cannot be fixed by 
methods which learn new words by packing already 
segmented words, such as word packing (Ma et al, 
2007) and Pseudo-word (Duan et al, 2010). 
As character could preserve more meanings than 
word in Chinese, it seems that a character can be 
wrongly aligned to many English words by the 
aligner. However, we found this can be avoided to a 
great extent by the basic features (co-occurrence 
and distortion) used by many alignment models. For 
example, we observed that the four characters of the 
non-compositional word ????? (Arafat)? align 
to Arafat correctly, although these characters pre-
serve different meanings from that of Arafat. This 
can be attributed to the frequent co-occurrence (192 
times) of these characters and Arafat in CCorpus. 
Moreover,?  usually means France in Chinese, 
thus it may co-occur very often with France in 
CCorpus. If both France and Arafat appear in the 
English sentence, ? may wrongly align to France. 
However, if ? aligns to Arafat, ? will probably 
align to Arafat, because aligning ? to Arafat could 
result in a lower distortion cost than aligning it to 
France. 
Different from alignment, translation is a pattern 
matching procedure (Lopez, 2008). WSR deter-
mines how the translation rules would be matched 
by the source sentences. For example, if we use 
translation rules with character as WSR to translate 
name entities such as the non-compositional word 
????, i.e. translating literally, we may get a 
wrong translation. That?s because the linguistic 
286
knowledge that the four characters convey a spe-
cific meaning different from the characters has been 
lost, which cannot always be totally recovered even 
by using phrase in phrase-based SMT systems (see 
Chang et al (2008) for detail). Duan et al (2010) 
and Paul et al, (2010) further pointed out that 
coarser-grained segmentation of the source sen-
tence do help capture more contexts in translation. 
Therefore, rather than using character, using 
coarser-grained, at least as coarser as the conven-
tional word, as WSR is quite necessary. 
3 Converting Character Alignment to Word 
Alignment 
In order to use word as WSR, we employ the same 
method as Elming and Habash (2007)4 to convert 
the character alignment (CA) to its word-based 
version (CA?) for translation rule induction. The 
conversion is very intuitive: for every Eng-
lish-Chinese word pair ??, ?? in the sentence pair, 
we align ? to ? as a link in CA?, if and only if there 
is at least one Chinese character of ? aligns to ? in 
CA.  
Given two different segmentations A and B of the 
same sentence, it is easy to prove that if every word 
in A is finer-grained than the word of B at the cor-
responding position, the conversion is unambiguity 
(we omit the proof due to space limitation). As 
character is a finer-grained than its original word, 
character alignment can always be converted to 
alignment based on any word segmentation. 
Therefore, our approach can be naturally scaled to 
syntax-based system by converting character 
alignment to word alignment where the word seg-
mentation is consistent with the parsers. 
We compare CA with the conventional word 
alignment (WA) as follows: We hand-align some 
sentence pairs as the evaluation set based on char-
acters (ESChar), and converted it to the evaluation 
set based on word (ESWord) using the above con-
version method. It is worth noting that comparing 
CA and WA by evaluating CA on ESChar and 
evaluating WA on ESWord is meaningless, because 
the basic tokens in CA and WA are different. 
However, based on the conversion method, com-
paring CA with WA can be accomplished by evalu-
ating both CA? and WA on ESWord. 
                                                          
4 They used this conversion for word alignment combination 
only, no translation results were reported. 
4 Experiments 
4.1 Setup 
FBIS corpus (LDC2003E14) (210K sentence pairs) 
was used for small-scale task. A large bilingual 
corpus of our lab (1.9M sentence pairs) was used for 
large-scale task. The NIST?06 and NIST?08 test sets 
were used as the development set and test set re-
spectively. The Chinese portions of all these data 
were preprocessed by character segmenter (CHAR), 
ICTCLAS word segmenter 5  (ICT) and Stanford 
word segmenters with CTB  and PKU specifica-
tions6 respectively. The first 100 sentence pairs of 
the hand-aligned set in Haghighi et al (2009) were 
hand-aligned as ESChar, which is converted to 
three ESWords based on three segmentations re-
spectively. These ESWords were appended to 
training corpus with the corresponding word seg-
mentation for evaluation purpose. 
Both character and word alignment were per-
formed by GIZA++ (Och and Ney, 2003) enhanced 
with gdf heuristics to combine bidirectional align-
ments (Koehn et al, 2003). A 5-gram language 
model was trained from the Xinhua portion of 
Gigaword corpus. A phrase-based MT decoder 
similar to (Koehn et al, 2007) was used with the 
decoding weights optimized by MERT (Och, 2003). 
4.2 Evaluation 
We first evaluate the alignment quality. The method 
discussed in section 3 was used to compare char-
acter and word alignment. As can be seen from 
Table 3, the systems using character as WSA out-
performed the ones using word as WSA in both 
small-scale (row 3-5) and large-scale task (row 6-8) 
with all segmentations. This gain can be attributed 
to the small vocabulary size (sparsity) for character 
alignment. The observation is consistent with 
Koehn (2005) which claimed that there is a negative 
correlation between the vocabulary size and trans-
lation performance without explicitly distinguish-
ing WSA and WSR. 
We then evaluated the translation performance. 
The baselines are fully word-based MT systems 
(WordSys), i.e. using word as both WSA and WSR, 
and fully character-based systems (CharSys). Table  
 
                                                          
5 http://www.ictclas.org/ 
6 http://nlp.stanford.edu/software/segmenter.shtml 
287
  Word alignment Character alignment 
  P R F P R F 
S 
CTB 76.0 81.9 78.9 78.2 85.2 81.8 
PKU 76.1 82.0 79.0 78.0 86.1 81.9 
ICT 75.2 80.8 78.0 78.7 86.3 82.3 
L 
CTB 79.6 85.6 82.5 82.2 90.6 86.2 
PKU 80.0 85.4 82.6 81.3 89.5 85.2 
ICT 80.0 85.0 82.4 81.3 89.7 85.3 
Table 3 Alignment evaluation. Precision (P), recall (R), 
and F-score (F) with ? ? 0.5 (Fraser and Marcu, 2007) 
 
 WSA WSR CTB PKU ICT 
S word word 21.52 20.99 20.95char word 22.04 21.98 22.04
L word word 22.07 22.86 22.23 char word 23.41 23.51 23.05 
Table 4 Translation evaluation of WordSys and pro-
posed system using BLEU-SBP (Chiang et al, 2008) 
 
4 compares WordSys to our proposed system. Sig-
nificant testing was carried out using bootstrap 
re-sampling method proposed by Koehn (2004) 
with a 95% confidence level. We see that our pro-
posed systems outperformed WordSys in all seg-
mentation specifications settings. Table 5 lists the 
results of CharSys in small-scale task. In this setting, 
we gradually set the phrase length and the distortion 
limits of the phrase-based decoder (context size) to 
7, 9, 11 and 13, in order to remove the disadvantage 
of shorter context size of using character as WSR 
for fair comparison with WordSys as suggested by 
Duan et al (2010). Comparing Table 4 and 5, we 
see that all CharSys underperformed WordSys. This 
observation is consistent with Chang et al (2008) 
which claimed that using characters, even with 
large phrase length (up to 13 in our experiment) 
cannot always capture everything a Chinese word 
segmenter can do, and using word for translation is 
quite necessary. We also see that CharSys under-
performed our proposed systems, that?s because the 
harm of using character as WSR outweighed the 
benefit of using character as WSA, which indicated 
that word segmentation better for alignment is not 
necessarily better for translation, and vice versa. 
We finally compared our approaches to Ma et al 
(2007) and Ma and Way (2009), which proposed 
?packed word (PW)? and ?bilingual motivated 
word (BS)? respectively. Both methods iteratively 
learn word segmentation and alignment alterna-
tively, with the former starting from word-based 
corpus and the latter starting from characters-based 
corpus. Therefore, PW can be experimented on all 
segmentations. Table 6 lists their results in small- 
Context Size 7 9 11 13 
BLEU 20.90 21.19 20.89 21.09 
Table 5 Translation evaluation of CharSys. 
 
System WSA WSR CTB PKU ICT 
WordSys word word 21.52 20.99 20.95
Proposed char word 22.04 21.98 22.04
PW PW PW 21.24 21.24 21.19 
Char+PW char PW 22.46 21.87 21.97 
BS BS BS 19.76 
Char+BS char BS 20.19 
Table 6 Comparison with other works 
 
scale task, we see that both PW and BS underper-
formed our approach. This may be attributed to the 
low recall of the learned BS or PW in their ap-
proaches. BS underperformed both two baselines, 
one reason is that Ma and Way (2009) also em-
ployed word lattice decoding techniques (Dyer et al, 
2008) to tackle the low recall of BS, which was 
removed from our experiments for fair comparison. 
Interestingly, we found that using character as 
WSA and BS as WSR (Char+BS), a moderate gain 
(+0.43 point) was achieved compared with fully 
BS-based system; and using character as WSA and 
PW as WSR (Char+PW), significant gains were 
achieved compared with fully PW-based system, 
the result of CTB segmentation in this setting even 
outperformed our proposed approach (+0.42 point). 
This observation indicated that in our framework, 
better combinations of WSA and WSR can be found 
to achieve better translation performance. 
5 Conclusions and Future Work 
We proposed a SMT framework that uses character 
for alignment and word for translation, which im-
proved both alignment quality and translation per-
formance. We believe that in this framework, using 
other finer-grained segmentation, with fewer am-
biguities than character, would better parameterize 
the alignment models, while using other coars-
er-grained segmentation as WSR can help capture 
more linguistic knowledge than word to get better 
translation. We also believe that our approach, if 
integrated with combination techniques (Dyer et al, 
2008; Xi et al, 2011), can yield better results. 
 
Acknowledgments 
We thank ACL reviewers. This work is supported 
by the National Natural Science Foundation of 
China (No. 61003112), the National Fundamental 
Research Program of China (2010CB327903). 
288
References  
Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della 
Peitra, and Robert L. Mercer. 1993. The mathematics 
of statistical machine translation: parameter estima-
tion. Computational Linguistics, 19(2), pages 
263-311. 
Pi-Chuan Chang, Michel Galley, and Christopher D. 
Manning. 2008. Optimizing Chinese word segmenta-
tion for machine translation performance.  In Pro-
ceedings of third workshop on SMT, pages 224-232. 
David Chiang, Steve DeNeefe, Yee Seng Chan and 
Hwee Tou Ng. 2008. Decomposability of Translation 
Metrics for Improved Evaluation and Efficient Algo-
rithms. In Proceedings of Conference on Empirical 
Methods in Natural Language Processing, pages 
610-619. 
Tagyoung Chung and Daniel Gildea. 2009. Unsuper-
vised tokenization for machine translation. In Pro-
ceedings of Conference on Empirical Methods in 
Natural Language Processing, pages 718-726. 
Michael Collins. 1999. Head-driven statistical models 
for natural language parsing. Ph.D. thesis, University 
of Pennsylvania. 
Xiangyu  Duan, Min Zhang,  and  Haizhou Li. 2010. 
Pseudo-word for phrase-based machine translation. In 
Proceedings of the Association for Computational 
Linguistics, pages 148-156. 
Christopher Dyer, Smaranda Muresan, and Philip Resnik. 
2008. Generalizing word lattice translation. In Pro-
ceedings of the Association for Computational Lin-
guistics, pages 1012-1020. 
Jakob Elming and Nizar Habash. 2007. Combination of 
statistical word alignments based on multiple pre-
processing schemes. In Proceedings of the Associa-
tion for Computational Linguistics, pages 25-28. 
Alexander Fraser and Daniel Marcu. 2007. Squibs and 
Discussions: Measuring Word Alignment Quality for 
Statistical Machine Translation. In Computational 
Linguistics, 33(3), pages 293-303. 
Aria Haghighi, John Blitzer, John DeNero, and Dan 
Klein. 2009. Better word alignments with supervised 
ITG models. In Proceedings of the Association for 
Computational Linguistics, pages 923-931. 
Phillip Koehn, H. Hoang, A. Birch, C. Callison-Burch, 
M. Federico, N. Bertoldi, B. Cowan,W. Shen, C. 
Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin, E. 
Herbst. 2007. Moses: Open source toolkit for statis-
tical machine translation. In Proceedings of the Asso-
ciation for Computational Linguistics, pages 177-180.  
Philipp Koehn. 2004. Statistical significance tests for 
machine translation evaluation. In Proceedings of the 
Conference on Empirical Methods on Natural Lan-
guage Processing, pages 388-395. 
Philipp Koehn. 2005. Europarl: A parallel corpus for 
statistical machine translation. In Proceedings of the 
MT Summit. 
Adam David Lopez. 2008. Machine translation by pat-
tern matching. Ph.D. thesis, University of Maryland. 
Yanjun Ma, Nicolas Stroppa, and Andy Way. 2007. 
Bootstrapping word alignment via word packing. In 
Proceedings of the Association for Computational 
Linguistics, pages 304-311. 
Yanjun Ma and Andy Way. 2009. Bilingually motivated 
domain-adapted word segmentation for statistical 
machine translation. In Proceedings of the Conference 
of the European Chapter of the ACL, pages 549-557. 
Franz Josef Och. 2003. Minimum error rate training in 
statistical machine translation. In Proceedings of the 
Association for Computational Linguistics, pages 
440-447. 
Franz Josef Och and Hermann  Ney. 2003. A systematic 
comparison of various statistical alignment models. 
Computational Linguistics, 29(1), pages 19-51. 
Michael Paul, Andrew Finch and Eiichiro Sumita. 2010. 
Integration of multiple bilingually-learned segmenta-
tion schemes into statistical machine translation. In 
Proceedings of the Joint Fifth Workshop on Statistical 
Machine Translation and MetricsMATR, pages 
400-408. 
J?rg Tiedemann. 2009. Character-based PSMT for 
closely related languages. In Proceedings of the An-
nual Conference of the European Association for 
machine Translation, pages 12-19. 
David Vilar, Jan-T. Peter and Hermann Ney. 2007. Can 
we translate letters? In Proceedings of the Second 
Workshop on Statistical Machine Translation, pages 
33-39. 
Xinyan Xiao, Yang Liu, Young-Sook Hwang, Qun Liu 
and Shouxun Lin. 2010.  Joint tokenization and 
translation. In Proceedings of the 23rd International 
Conference on Computational Linguistics, pages 
1200-1208. 
Ning  Xi, Guangchao  Tang,  Boyuan  Li, and  Yinggong 
Zhao. 2011. Word alignment combination over mul-
tiple word segmentation. In Proceedings of the ACL 
2011 Student Session, pages 1-5. 
Ruiqiang Zhang, Keiji Yasuda, and Eiichiro Sumita. 
2008. Improved statistical machine translation by 
multiple Chinese word segmentation. In Proceedings 
289
of the Third Workshop on Statistical Machine Trans-
lation, pages 216-223. 
 
290
Proceedings of the SIGDIAL 2014 Conference, pages 89?97,
Philadelphia, U.S.A., 18-20 June 2014.
c
?2014 Association for Computational Linguistics
Back to the Blocks World: Learning New Actions through Situated
Human-Robot Dialogue
Lanbo She
1
, Shaohua Yang
1
, Yu Cheng
2
, Yunyi Jia
2
, Joyce Y. Chai
1
, Ning Xi
2
1
Department of Computer Science and Engineering
Michigan State University
East Lansing, MI 48824, USA
{shelanbo, jchai, yangshao}@cse.msu.edu
2
Department of Electrical and Computer Engineering
Michigan State University
East Lansing, MI 48824, USA
{chengyu9, jiayunyi, xin}@egr.msu.edu
Abstract
This paper describes an approach for a
robotic arm to learn new actions through
dialogue in a simplified blocks world. In
particular, we have developed a three-
tier action knowledge representation that
on one hand, supports the connection be-
tween symbolic representations of lan-
guage and continuous sensorimotor repre-
sentations of the robot; and on the other
hand, supports the application of existing
planning algorithms to address novel situ-
ations. Our empirical studies have shown
that, based on this representation the robot
was able to learn and execute basic actions
in the blocks world. When a human is
engaged in a dialogue to teach the robot
new actions, step-by-step instructions lead
to better learning performance compared
to one-shot instructions.
1 Introduction
When a new generation of robots start to work
side-by-side with their human partners in joint
tasks (Christensen et al., 2010), they will often
encounter new objects or are required to perform
new actions. It is important for the robots to au-
tomatically learn new knowledge about the en-
vironment and the tasks from their human part-
ners. To address this issue, this paper describes
our recent work on action learning through dia-
logue. As a first step, we limit our investigation to
a simple blocks world motivated by Terry Wino-
grad?s early work (Winograd, 1972). By using
an industrial robotic arm (SCHUNK) in this small
world, we are interested in addressing the follow-
ing questions. First, human language has a dis-
crete and symbolic representation, but the robot
arm has a continuous representation for its move-
ments. Where should the connections between the
symbolic representation and the continuous repre-
sentation take place so that human language can
be used to direct the robot?s movements? Second,
when the robot learns new tasks from its human
partner, how to represent the acquired knowledge
effectively so that it can be applied in novel situa-
tions? Third, during human-robot dialogue, when
the robot fails to perform the expected actions due
to the lack of knowledge, how should the human
teach the robot new actions? through step-by-step
instructions or one-shot instructions?
With these questions in mind, we have devel-
oped a three-tier action knowledge representation
for the robotic arm. The lower level connects to
the physical arm and defines the trajectories of
executing three atomic actions supported by the
arm (i.e., open gripper, close gripper, move). The
middle level defines primitive operators such as
Open Grip, Close Grip and MoveTo in the fash-
ion of the traditional AI planner (Fikes and Nils-
son, 1971) and directly links to the lower level.
The upper-level captures the high-level actions ac-
quired by learning from the human. These high-
level actions are represented as the desired goal
states of the environment as a result of these ac-
tions. This three-tier representation allows the
robot to automatically come up with a sequence of
lower-level actions by applying existing planning
algorithms.
Based on this representation, we implemented
a dialogue system for action learning and further
conducted an empirical study with human sub-
jects. In particular, we compared the dialogue
89
Figure 1: An example setup and dialogue. Objects
are marked with labels only for the illustration pur-
pose.
based on the step-by-step instructions (i.e., one
step at a time and wait for the robot?s response
at each step before going to the next step) with
the one-shot instructions (i.e., give the instruction
with all steps at once). Our empirical results have
shown that the three-tier knowledge representation
can capture the learned new action and apply it
to novel situations. Although the step-by-step in-
structions resulted in a lengthier teaching process
compared to the one-shot instructions, they led to
better learning performance for the robot.
2 Related Work
Over forty years ago, Terry Winograd developed
SHRDLU (Winograd, 1972) to demonstrate nat-
ural language understanding using a simulated
block-moving arm. One aspect he did not address,
but mentioned in his thesis (Winograd, 1972) as
an important aspect, was learning new actions
through natural language. Motivated by Wino-
grad?s early work, we start our initial investigation
on action learning in a physical blocks world and
with a physical robotic arm. The blocks world is
the most famous domain used for planning in ar-
tificial intelligence. Thus it allows us to focus on
mechanisms that, on one hand, connect symbolic
representations of language with lower-level con-
tinuous sensorimotor representations of the robot;
and on the other hand, support the use of the plan-
ning algorithms to address novel situations.
Most previous work on following human in-
structions are based on supervised learning (Kol-
lar et al., 2010; Tellex et al., 2011; Chen et al.,
2010) or reinforcement learning (Branavan et al.,
2012; Branavan et al., 2010). These types of learn-
ing may not be adequate in time-critical situations
where only resources available to the robot is its
human partners. Thus it is desirable that humans
can engage in a natural language dialogue to teach
robots new skills. Using natural language dialogue
to learn new skills have been explored previously
by (Allen et al., 2007) where an artificial agent was
developed to acquire skills through natural lan-
guage instructions (i.e., find restaurant). But this
work only grounds language to symbolic interface
widgets on web pages.
In the robotics community, previous work has
applied learning by demonstration to teach robots
new skills (Cakmak et al., 2010). To potentially
allow natural language instructions, previous work
has also explored connecting language with lower-
level control systems (Kress-Gazit et al., 2008;
Siskind, 1999; Matuszek et al., 2012). Different
from these previous works, here we investigate the
use of natural language dialogue for learning ac-
tions. Previous work described in (Cantrell et al.,
2012; Mohan et al., 2013) is most similar to our
work. Here we focus on both grounded learning
and the use of planning for action learning.
3 Dialogue System
Figure 2: System Architecture
We developed a dialogue system to support
learning new actions. An example setup is shown
in Figure 1, in which a SCHUNK arm is used to
manipulate blocks placed on a surface. In H
1
,
the human starts to ask the robot to stack the blue
block (i.e., B
1
) on top of the red block (i.e., R
1
).
The robot does not understand the action ?stack?,
so it asks the human for instructions. Then the hu-
90
Figure 3: Example semantic representation and
action frame for the human utterance ?stack the
blue block on the red block on your right.?
man provides detailed steps to accomplish this ac-
tion (i.e., H
2
to H
8
) and also observes the robot?s
response in each step. Note that during this pro-
cess, another unknown action (i.e., ?grab? as in
H
2
) is encountered. The robot thus needs to learn
this action first. The robot is able to keep track
of the dialogue structure so that actions and sub-
actions can be learned accordingly. Once the robot
receives a confirmation from the human that the
corresponding action is successfully performed
(i.e., H
6
and H
9
), it acquires the new action and
explicitly represents it in its knowledge base for
future use. Instead of representing the acquired
knowledge as specific steps as illustrated by the
human, the acquired action is represented by the
expected final state, which represents the changes
of environment as a result of the action. The new
action can be directly applied to novel situations
by applying planning algorithms. Figure 2 shows
the system structure. Next we explain main system
modules in detail.
Natural Languge Processing: Natural language
processing modules capture semantic information
from human language inputs. In particular, the
Intention Recognizer is used to recognize
human intent (e.g., Command and Confirmation).
The Semantic Processor, implemented as
Combinatory Categorial Grammar (CCG)
1
, is
used to generate semantic representation. Current
semantic information includes the actions (e.g.,
stack) and their roles (e.g., Theme and Destina-
tion). The roles are further represented by objects?
properties (Color, Location and Spatial Relation).
An example semantic representation of ?H1: Stack
the blue block on the red block on your right.? is
shown in Figure 3.
1
We utilized OpenCCG, which could be found at:
http://openccg.sourceforge.net/
Perception Modules: Besides interpreting human
language, the robot also continuously perceives
the shared environment with its camera. Ob-
jects in video frames are recognized through vi-
sion system (Collet et al., 2011), and further repre-
sented as a Vision Graph (computed by Vision
Graph Builder), which captures objects and
their properties (in the numerical form). The robot
can also access to its own internal status, such as
the location of the gripper and whether it?s open
or closed. Combining the robot?s state and en-
vironment information, the Discrete State
Builder can represent the entire environment as
a conjunction of predicates, which will be later
used for action planning.
Referential Grounding: To make the semantic
representation meaningful, it must be grounded to
the robot?s representation of perception. We use
the graph-based approach for referential ground-
ing as described in (Liu et al., 2012)(Liu et al.,
2013). Once the references are grounded, the se-
mantic representation becomes a Grounded Action
Frame. For example, as shown in Figure 3, ?the
blue block? refers to B1 and ?the red block on your
right? refers to R1.
Dialogue Manager: The Dialogue Manager
is used to decide what dialog acts the system
should perform give a situation. It is composed by:
a representation of dialogue state, a space of sys-
tem activity and a dialogue policy. The dialogue
status is computed based on the human intention a
dialogue state captures (from semantic representa-
tion) and the Grounded Action Frame. The
current space of system activities includes asking
for instructions, confirming, executing actions and
updating its action knowledge base with new ac-
tions. The dialogue policy stores the (dialogue
state, system activities) pairs. During interaction,
the Dialogue Manager will first identify the
current dialogue state and then apply the dialogue
acts associated with that state as specified in the
dialogue policy.
Action Modules: The Action Modules are
used to realize a high-level action from the
Grounded Action Frame with the physi-
cal arm and to learn new actions. For re-
alizing high-level actions, if the action in the
Grounded Action Frame has a record in
the Action Knowledge, which keeps track
of all the knowledge about various actions, the
91
Discrete Planner will do planning to find a
sequence of primitive actions to achieve the high-
level action. Then these primitive actions will se-
quentially go through Continuous Planner
and be translated to the trajectories of arm motors.
By following these trajectories, the arm can per-
form the high-level action. For learning new ac-
tions, these modules will calculate state changes
before and after applying the action on the focus
object. Such changes of the state are generalized
and stored as knowledge representation of the new
action.
Response Generator: Currently, the Response
Generator is responsible for language genera-
tion to realize the detail sentence. In our current
investigation, the speech feedback is simple, so we
just used a set of pre-defined templates to do lan-
guage generation. And the parameters in the tem-
plates will be realized during run time.
4 Action Learning through Dialogue
To realize the action learning functionality we
have developed a set of action related processes
including an action knowledge base, action execu-
tion processes and action learning processes. Next
we give detailed explanations.
4.1 Action Modules
Figure 4: Execution example for ?Pick up the blue
block?.
As shown in Figure 4, the action knowledge
base is a three-level structure, which consists of
High-level action Knowledge, Discrete Planner
and Continuous Planner.
4.1.1 Continuous Planner
This lowest level planner defines three primitive
actions: open (i.e., open gripper), close (i.e., close
gripper) and move (i.e., move to the destination).
Each primitive action is defined as a trajectory
computing function, implemented as inverse kine-
matics. The outputs of these functions are control
commands sendt to each arm motor to keep the
arm following the trajectory.
4.1.2 Discrete Planner
The Discrete Planner is used to decompose a
high-level action into a sequence of primitive ac-
tions. In our system, it is implemented as a
STRIPS (Fikes and Nilsson, 1971) planner, which
is defined as a quadruple ?P,O, I,G?:
? P: Set of predicates describing a domain.
? O: Set of operators. Each is specified by a set
of preconditions and effects. An operator is
applicable only when its preconditions could
be entailed in a state.
? I: Initial state, the starting point of a problem.
? G: Goal state, which should be achieved if the
problem is solved.
In our system, O set includes Open Gripper,
Close Gripper and 8 different kinds of
MoveTo (She et al., 2014). And the P set
consists of two dimensions of the environment:
? Arm States: G Open/Close (i.e., whether the
gripper is open or closed), G Full/Empty
(i.e., whether the gripper has an object in it)
and G At(x) (i.e, location of the arm).
? Object States: Top Uclr/Clr(o) (i.e., whether
the block o has another block on its top),
In/Out G(o) (i.e., whether o is within the
gripper fingers or not) and On(o,x) (i.e., o is
supported by x).
The I and G are captured real-time during the
dialogue interaction.
4.1.3 High-level action Knowledge
The high-level actions represent actions specified
by the human partner. They are modeled as de-
sired goal states rather than the action sequence
taught by human. For example, the ?Stack(x,y)?
could be represented as ?On(x,y)?G Open?. If the
human specifies a high-level action out of the ac-
tion knowledge base, the dialogue manager will
verbally request for instructions to learn the action.
92
Figure 5: Learning process illustration. After hearing the stack action, the robot cannot perform. So the
human gives step by step instruction. When the instruction is completed, new knowledge of Grab(x) and
Stack(x,y) are learned in the high-level action knowledge base as the combination of the goal state of the
robotic arm and the changes of the state for the involved objects.
4.2 Action Execution
Given a Grounded Action Frame, it is
firstly checked with the high-level action knowl-
edge base. If the knowledge base has its record
(e.g., the Pickup and ClearTop in Figure 4.), a goal
state describing the action effect will be retrieved.
This goal state, together with the initial state cap-
tured from the current environment, will be sent
to the Discrete Planner. And, through au-
tomated planning, a sequence of primitive actions
will be generated to complete the task, which can
be immediately executed by the arm.
Take the ?Pick up? action frame in Figure 4
as an example. By checking the grounded ac-
tion frame with the high-level action knowledge,
a related goal state (i.e., ?G Close?Top Clr(B1)
?In G(B1)?On(B1,air)?) can be retrieved. At
the same time, the Discrete Evn Builder
translates the real world environment as a con-
junction of predicates, which serves as the ini-
tial state. Given the combination of initial state
and goal state, the STRIPS planner can search for
a path of primitive actions to solve the problem.
For example, the PickUp(B1) in Figure 4 can be
solved by Open Grip, MoveTo(B1), Close Grip
and MoveTo(air).
The primitive actions are executed by the con-
tinuous planner and control process in the lower
robotic system. For the ?open? and ?close?, they
are executed by controlling the position of the
gripper fingers. For the ?move?, a task-space tra-
jectory is first planned based on the minimum-time
motion planning algorithm to move the robot end-
effector from the current position to the final posi-
tion. A kinematic controller with redundancy res-
olution (Zhang et al., 2012) is then used to gener-
ate the joint movements for the robot to track the
planned trajectory. Achieving the end of the tra-
jectory indicates the action completion.
4.3 Action Learning
Figure 5 illustrates the system internal process of
acquiring action knowledge from the dialogue in
Figure 1.
At the beginning of the dialogue, the grounded
action frame Stack(B1, R1) captured from the first
human utterance is not in the action knowledge,
so it will be pushed to the top of the unknown ac-
tion stack as a new action waiting to be learned.
The environment state at this point is calculated as
shown in the figure. Then the robot will verbally
request instructions. During the instruction, it?s
possible that another unknown action Grab(B1) is
referred. The same as the Stack action, it will be
pushed to the top of unknown action stack waiting
to be learned.
In the next instruction, the human says ?Open
your gripper?. This sentence can be translated as
action frame Open and the goal state ?G Open?
can be retrieved from the action knowledge base.
After executing the action sequence, the grip-
per state will be changed from ?G Close? to
?G Open?, as shown in Figure 5. In the follow-
ing two instructions, the human says ?Move to the
blue block? and ?Close gripper?. Similarly, these
two instructions are translated as action frames
Move(B1) and Close, then are executed accord-
93
ingly. After executing these two steps, the state of
B1 is changed from ?Out G(B1)? to ?In G(B1)?.
At this point, the previous unknown action
Grab(B1) is achieved, so the human says ?Now
you achieve the grab action? as a signal of teach-
ing completion. After acknowledging the teach-
ing completion, the action learning module will
learn the new action representation by combining
the arm state with the state changes of the argu-
ment objects in the unknown action frame. For
example, the argument object of unknown action
Grab(B1) is B1. By comparing the original state
of B1, [(Out G B1)?(Top Clr B1)?(On B1 table)]
with the final state, [(In G B1)?(Top Clr B1)?(On
B1 table)], B1 is changed from (Out G B1) to
(In G B1). So, the learning module will gener-
alize such state changes and acquire the knowl-
edge representation of the new action Grab(x) as
G Close?In G(x).
5 Empirical Studies
The objectives of our empirical studies are two
folds. First, we aim to exam whether the current
representation can support planning algorithms
and execute the learned actions in novel situations.
Second, we aim to evaluate how extra effort from
the human partner through step-by-step instruc-
tions may affect the robot?s learning performance.
5.1 Instruction Effort
Previous work on mediating perceptual differ-
ences between humans and robots have shown that
a high collaborative effort from the robot leads to
better referential grounding (Chai et al., 2014).
Motivated by this previous work, we are inter-
ested in examining how different levels of effort
from human partners may affect the robot?s learn-
ing performance. More specifically, we model two
levels of variations:
? Collaborative Interaction: In this setting, a
human partner provides step-by-step instruc-
tions. At each step, the human will observe
the the robot?s response (i.e., arm movement)
before moving to the next step. For exam-
ple, to teach ?stack?, the human would is-
sue ?pick up the blue block?, observe the
robot?s movement, then issue ?put it on the
red block? and observe the robot movement.
By this fashion, the human makes extra effort
to make sure the robot follows every step cor-
rectly before moving on. The human partner
can detect potential problems and respond to
immediate feedback from the robot.
? Non-Collaborative Interaction: In this set-
ting, the human only provides a one-shot in-
struction. For example, to teach ?stack?,
the human first issues a complete instruction
?pick up the blue block and put it on top of
the red block? and then observes the robot?s
responses. Compared to the collaborative set-
ting, the non-collaborative setting is poten-
tially more efficient.
5.2 Experimental Tasks
Similar to the setup shown in Figure 1, in the
study, we have multiple blocks with different col-
ors and sizes placed on a flat surface, with a
SCHUNK arm positioned on one side of the sur-
face and the human subject seated on the opposite
side. The video stream of the environment is sent
to the vision system (Collet et al., 2011). With the
pre-trained object model of each block, the vision
system could capture blocks? 3D positions from
each frame. Five human subjects participated in
our experiments
2
. During the study, each sub-
ject was informed about the basic actions the robot
can perform (i.e., open gripper, close gripper, and
move to) and was instructed to teach the robot sev-
eral new actions through dialogue. Each subject
would go through the following two phases:
5.2.1 Teaching/Learning Phase
Each subject was asked to teach the following five
new actions under the two strategies (i.e., step-
by-step instructions vs. one-shot instructions):
{Pickup, Grab, Drop, ClearTop, Stack} Each time,
the subject can choose any blocks they think are
useful to teach the action. After finishing teaching
one action (either under step-by-step instructions
or under one-shot instructions), we would survey
the subject whether he/she thinks the teaching is
completed and the corresponding action is suc-
cessfully performed by the robot. We record the
teaching duration and then re-arrange the table top
setting to move to the next action.
For the teaching/learning phase, we use two
metrics for evaluation: 1) Teaching Completion
Rate(R
t
) which stands for the number of actions
successfully taught and performed by the robot;
2)Teaching Completion Duration (D
t
which mea-
sures the amount of time taken to teach an action.
2
More human subjects will be recruited to participate in
our studies.
94
5.2.2 Execution Phase
The goal of learning is to be able to apply the
learned knowledge in novel situations. To evalu-
ate such capability, for each action, we designed
10 additional setups of the environment which
are different from the environment where the ac-
tion was learned. For example, as illustrated in
Figure 6, the human teaches the pick Up action
by instructing the robot how to perform ?pick up
the blue block(i.e., B1)? under the environment
in 6(a). Once the knowledge is acquired about the
action ?pick up?, we will test the acquired knowl-
edge in a novel situation by instructing the robot to
execute ?pick up the green block(i.e., G1)? in the
environment shown in 6(b).
(a) Learning: the human
teaches the robot how to
?pick up the blue block
(i.e., B1)? during the learn-
ing phase
(b) Execution: the human
asks the robot to ?pick up
the green block (i.e., G1)?
after the robot acquires the
knowledge about ?pick up?
Figure 6: Examples of a learning and an execution
setup.
For the execution phase, we also used
two factors to evaluate: 1) Action Sequence
Generation(R
g
) which measures how many high-
level actions among the 10 execution scenarios
where the corresponding lower-level action se-
quences are correctly generated; 2) Action Se-
quence Execution(R
ge
) which measures the num-
ber of high level actions that are correctly executed
based on the lower level action sequences.
5.3 Empirical Results
Our experiments resulted in a total of 50 action
teaching dialogues. Half of these are under the
step-by-step instructions (i.e., collaborative inter-
action) and half are under one-shot instructions
(i.e., non-collaborative). As shown in Figure 7,
5 out of the 50 teaching dialogues were consid-
ered as incomplete by the human subjects and all
of them are from the Non-Collaborative setting.
For each of the 45 successful dialogues, an action
would be learned and acquired. For each of these
acquired actions, we further tested its execution
under 10 different setups.
Figure 7: The teaching completion result of the
50 teaching dialogues. ?1? stands for the dialogue
where the subject considers the teaching/learning
as complete since the robot performs the corre-
sponding action correctly; and ?0? indicates a fail-
ure in learning. The total numbers of teaching
completion are listed in the bottom row.
Figure 8: The teaching completion duration re-
sults. The durations under the non-collaborative
strategy are smaller than the collaborative strategy
in most cases.
5.3.1 Teaching Performance
The result of teaching completion is shown in Fig-
ure 7. Each subject contributes two columns: the
?Non? stands for the Non-Collaborative strategy
and the ?Col? column refers to the Collaborative
strategy. As the table shows, all the 5 uncom-
pleted teaching are from the Non-Collaborative
strategy. In most of these 5 cases, the subjects
thought the actual performed actions were differ-
ent from their expectations. For example, in one of
the ?stack? failures, the human one-shot instruc-
tion was ?move the blue block to the red block on
the left.?. She thought the arm would put the blue
block on the top of red block, open gripper and
then move away. However, based on the robot?s
knowledge, it just moved the blue block above
the red block and stopped there. So the subject
considered this teaching as incomplete. On the
other hand, in the Collaborative interactions, the
robot?s actual actions could also be different from
the subject?s expectation. But, as the instruction
95
Figure 9: Each bar represents the number of suc-
cessfully generated action sequences during test-
ing. The solid portion of each bar represents the
number of successfully executed action sequences.
The number of successfully execution is always
smaller than or equal to the generation. This is be-
cause we are dealing with dynamic environment,
and the inaccurate real-time localization will make
some correct action sequence fail to be executed.
was given step-by-step, the instructors could no-
tice the difference from the immediate feedback
and adjust their follow-up steps, which contributed
to a higher completion rate.
The duration of each teaching task is shown in
Figure 8. Bar heights represent average teaching
duration, the ranges stand for standard error of
the mean (SEM). The 5 actions are represented
by different groups. As shown in the figure, the
teaching duration under the Collaborative strategy
tends to take more time. Because in the Collab-
orative case, the human needs to plan next step
after observing the robot?s response to a previous
step. If an exception happens, a sub-dialogue is
often arranged to do correction. But in the Non-
Collaborative case, the human comes up with an
entire instruction at the beginning, which appears
more efficient.
5.3.2 Execution Performance
Figure 9 illustrates the action sequence generation
and execution results in the execution phase.
As shown in Figure 9, testing results of actions
learned under the Collaborative strategy are higher
than the ones using Non-Collaborative, this is be-
cause teaching under the Collaborative strategy is
more likely to be successful. One exception is the
Clear Top action, which has lower generation rate
under the Col setting. By examining the collected
data, we noticed that our system failed to learn the
knowledge of Clear Top in one of the 5 teaching
phases using Col setting, although the human sub-
ject labeled it as successful. Another phenomenon
shown in Figure 9 is that the generation results are
always larger than or equal with the correspond-
ing execution results. This is caused by inaccurate
localization and camera calibration, which intro-
duced exceptions during executing the action se-
quence.
6 Conclusion
This paper describes an approach to robot action
learning in a simplified blocks world. The sim-
plifications of the environment and the tasks allow
us to explore connections between symbolic repre-
sentations of natural language and continuous sen-
sorimotor representations of the robot which can
support automated planning for novel situations.
This investigation is only our first step. Many is-
sues have not been addressed. For example, the
world is full of uncertainties. Our current ap-
proach can only either succeed or fail executing
an action based on the acquired knowledge. There
is no approximation or reasoning of the uncertain
states which may affect potential execution. Also,
when the robot fails to execute an action, there is
no explanation why it fails. If the robot can artic-
ulate its internal representations regarding where
the problem occurs, the human can provide better
help or targeted teaching. These are the directions
we will pursue in our future work.
7 Acknowledgment
This work was supported by IIS-1208390 from the
National Science Foundation and N00014-11-1-
0410 from the Office of Naval Research.
References
James F. Allen, Nathanael Chambers, George Fergu-
son, Lucian Galescu, Hyuckchul Jung, Mary D.
Swift, and William Taysom. 2007. Plow: A collab-
orative task learning agent. In AAAI, pages 1514?
1519. AAAI Press.
S. R. K. Branavan, Luke S. Zettlemoyer, and Regina
Barzilay. 2010. Reading between the lines: Learn-
ing to map high-level instructions to commands. In
Proceedings of the 48th Annual Meeting of the As-
sociation for Computational Linguistics, ACL ?10,
pages 1268?1277, Stroudsburg, PA, USA. Associa-
tion for Computational Linguistics.
S.R.K. Branavan, Nate Kushman, Tao Lei, and Regina
Barzilay. 2012. Learning high-level planning from
96
text. In Proceedings of the 50th Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 1: Long Papers), pages 126?135, Jeju Island,
Korea, July. Association for Computational Linguis-
tics.
Maya Cakmak, Crystal Chao, and Andrea Lockerd
Thomaz. 2010. Designing interactions for robot ac-
tive learners. IEEE T. Autonomous Mental Develop-
ment, 2(2):108?118.
R. Cantrell, K. Talamadupula, P. Schermerhorn, J. Ben-
ton, S. Kambhampati, and M. Scheutz. 2012. Tell
me when and why to do it! run-time planner model
updates via natural language instruction. In Human-
Robot Interaction (HRI), 2012 7th ACM/IEEE Inter-
national Conference on, pages 471?478, March.
Joyce Y. Chai, Lanbo She, Rui Fang, Spencer Ottarson,
Cody Littley, Changsong Liu, and Kenneth Han-
son. 2014. Collaborative effort towards common
ground in situated human robot dialogue. In Pro-
ceedings of 9th ACM/IEEE International Confer-
ence on Human-Robot Interaction, Bielefeld, Ger-
many.
David L. Chen, Joohyun Kim, and Raymond J.
Mooney. 2010. Training a multilingual sportscaster:
Using perceptual context to learn language. J. Artif.
Int. Res., 37(1):397?436, January.
H. I. Christensen, G. M. Kruijff, and J. Wyatt, editors.
2010. Cognitive Systems. Springer.
Alvaro Collet, Manuel Martinez, and Siddhartha S.
Srinivasa. 2011. The MOPED framework: Object
Recognition and Pose Estimation for Manipulation.
Richard E. Fikes and Nils J. Nilsson. 1971. Strips: A
new approach to the application of theorem proving
to problem solving. In Proceedings of the 2Nd Inter-
national Joint Conference on Artificial Intelligence,
IJCAI?71, pages 608?620, San Francisco, CA, USA.
Morgan Kaufmann Publishers Inc.
Thomas Kollar, Stefanie Tellex, Deb Roy, and Nicholas
Roy. 2010. Toward understanding natural language
directions. In Proceedings of the 5th ACM/IEEE
International Conference on Human-robot Interac-
tion, HRI ?10, pages 259?266, Piscataway, NJ, USA.
IEEE Press.
Hadas Kress-Gazit, Georgios E. Fainekos, and
George J. Pappas. 2008. Translating structured
english to robot controllers. Advanced Robotics,
22(12):1343?1359.
Changsong Liu, Rui Fang, and Joyce Chai. 2012. To-
wards mediating shared perceptual basis in situated
dialogue. In Proceedings of the 13th Annual Meet-
ing of the Special Interest Group on Discourse and
Dialogue, pages 140?149, Seoul, South Korea.
Changsong Liu, Rui Fang, Lanbo She, and Joyce Chai.
2013. Modeling collaborative referring for situated
referential grounding. In Proceedings of the SIG-
DIAL 2013 Conference, pages 78?86, Metz, France.
Cynthia Matuszek, Evan Herbst, Luke S. Zettlemoyer,
and Dieter Fox. 2012. Learning to parse nat-
ural language commands to a robot control sys-
tem. In Jaydev P. Desai, Gregory Dudek, Ous-
sama Khatib, and Vijay Kumar, editors, ISER, vol-
ume 88 of Springer Tracts in Advanced Robotics,
pages 403?415. Springer.
Shiwali Mohan, James Kirk, and John Laird. 2013. A
computational model for situated task learning with
interactive instruction. In Proceedings of ICCM
2013 - 12th International Conference on Cognitive
Modeling.
Lanbo She, Yu Cheng, Joyce Chai, Yunyi Jia, Shaohua
Yang, and Ning Xi. 2014. Teaching robots new ac-
tions through natural language instructions. In RO-
MAN.
Jeffrey Mark Siskind. 1999. Grounding the lexical se-
mantics of verbs in visual perception using force dy-
namics and event logic. J. Artif. Int. Res., 15(1):31?
90, February.
Stefanie Tellex, Thomas Kollar, Steven Dickerson,
Matthew R. Walter, Ashis Gopal Banerjee, Seth J.
Teller, and Nicholas Roy. 2011. Understanding nat-
ural language commands for robotic navigation and
mobile manipulation. In Wolfram Burgard and Dan
Roth, editors, AAAI. AAAI Press.
T. Winograd. 1972. Procedures as a representation for
data in a computer program for understanding natu-
ral language. Cognitive Psychology, 3(1):1?191.
Huatao Zhang, Yunyi Jia, and Ning Xi. 2012. Sensor-
based redundancy resolution for a nonholonomic
mobile manipulator. In IROS, pages 5327?5332.
97
