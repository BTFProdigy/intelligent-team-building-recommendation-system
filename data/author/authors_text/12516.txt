Representing and Visualizing
Calendar Expressions in Texts
Delphine Battistelli
Univ. Paris-Sorbonne (France)
email: Delphine.Battistelli@paris-sorbonne.fr
Javier Couto
INCO, FING, UdelaR (Uruguay)
email: jcouto@fing.edu.uy
Jean-Luc Minel
MoDyCo, CNRS-Univ. ParisX (France)
email: Jean-Luc.Minel@u-paris10.fr
Sylviane R. Schwer
LIPN, CNRS-Univ. ParisXIII (France)
email: Sylviane.Schwer@lipn.univ-paris13.fr
Abstract
Temporal expressions that refer to a part of a calendar area in terms of
common calendar divisions are studied. Our claim is that such a ?cal-
endar expression" (CE) can be described by a succession of operators
operating on a calendar base (CB). These operators are categorized: a
pointing operator that transform a CB into a CE; a focalizing/shifting op-
erator that reduces or shifts the CE into another CE, and finally a zoning
operator that provides the wanted CE from this last CE. Relying on these
operators, a set of annotations is presented which are used to automat-
ically annotate biographic texts. A software application, plugged in the
platformNavitext, is described that builds a calendar view of a biographic
text.
365
366 Battistelli, Couto, Minel, and Schwer
1 Introduction
Taking into account temporality expressed in texts appears as fundamental, not only
in a perspective of global processing of documents, but also in the analysis of the
structure of a document.1 The analysis of temporality within texts has been studied
principally by considering verbal times (e.g. Song and Cohen (1991); Hitzeman et al
(1995) and temporal adverbials (see below).
Our approach is focused on temporal adverbials ? in French ? that refer directly
to text units concerning common calendar divisions, that we name ?calendar expres-
sions? (CEs for short). Several analyses of this kind of expressions has generated
a lot of interest, ranging from their automatic recognition and annotation in texts to
their analysis in terms of discursive frames (Charolles, 1997; Tannen, 1997), following
work of Halliday (1994) which put the emphasis on the importance of the temporal
adverbial expressions as modes of discursive organization.
Nowadays, in the field of temporality processing, automatic identification and an-
notation tasks of CEs are the most developed, mainly because identifying and anno-
tating expressions which contain calendar units are considered? a priori ? as trivial
tasks. Those tasks have been particularly explored in three contexts:
1. Systems which aim to set events on a time scale depending on their duration
and according to a hierarchy of unities called granularities (Schilder and Habel,
2001);
2. Systems for summarizing multi-documents (Barzilay et al, 2001); and
3. QA systems (Pustejovsky et al, 1993; Harabagiu and Bejan, 2005).
Please note that the proposition of the well-known standard temporalmeta-language
named TimeML (Pustejovsky et al, 2003) initially took place in the context of a QA
systems worshop (Pustejovsky, 2002), and mainly integrates two schemes of annota-
tions ? namely TIDES TIMEX2 (Ferro et al, 2004) and Sheffield STAG (Setzer and
Gaizauskas, 2000) ? which were essentially put forward from the analysis of CEs.
In this paper, we propose a formal description of CEs in written French texts, by ex-
plicitly distinguishing several classes of linguistic markers which must be interpreted
as successive operators. This work is driven in order to propose a set of fine and
well-defined annotations which will be used to navigate temporally in an annotated
document. Our approach differs from the preceding ones in two crucial ways:
? Our goal is not to link a CE to an event, neither to fix it on a ?temporal line",
using a set of values relying on ISO 8601 standard format (Mani and Wilson,
2000; Setzer and Gaizauskas, 2000; Filatova and Hovy, 2001); instead our goal
is to link CEs between themselves, that is to say to establish their qualitative
relative positions (the set of those relations is named ?proper text calendar?);
? We design CE semantics as algebraic expressions.
1This research is funded with an ANR grant (Projet Blanc Conique).
Representing and Visualizing Calendar Expressions in Texts 367
The remainder of this paper is organized as follows. In the next section, we in-
troduce an algebra of CEs. In Section 3 we describe a software application, which
exploits functional representation, built with previous way exhibited operators and
plugged in the NaviTexte platform, aiming to support text reading. Finally, conclu-
sions and future research directions are presented in Section 4.
2 An Algebra for Calendar Expressions
We postulate that a CE, say E , used to refer to a calendar area can be described by a
succession of operators applied on an argument, named calendar base (CB), say B,
that bears a granulariry and a value for anchoring allowing fixing it in the calendar
system used and that gives access at the calendar area described by the CE.
Each operator gives a piece of the processing following a specific order: on B is
applied a pointing operation, usually expressed by a determinant, whose result is an
CE, E1 part of E . On E1 is applied a second kind of operator expressing the useful
part of this base (all, the beginning, the middle, the end, a fuzzy area around) given as
result a new CE E2 which is part of E and is associated with a piece of the calendar
that cuts the time line in three areas (illustrated by Figure 1):
? the former half-line (A),
? the Useful portion (U),
? posterior half-line (P)2.
The useful part can also be obtained either by shifting, like in ?trois semaines plus
tard" (three weeks later), or by zooming, as in ?l?automne de cette ann?e l?" (the au-
tumn of this present year).3 A third kind of operator gives access at the area described
by the complete CE E: selecting one of the three portioned areas, like in ?jusqu?en
avril 2006" (until April 2006).
Figure 1: Partition of the time line for a unary CE
The order of operators is the following: a pointing operator OpPointing, followed
by one or more focalising or shifting operatorsOpFocalising/Shi f ting+ and finally at
least one zoning operator OpZoning?.4 Some operators can be omitted, usually when
2This Time line is pragmatically limited bounded. For instance, (P) can be naturally limited by the
present moment, as we do in Figure 1.
3For such deictic CEs, the CB has the granularity year, and the value current.
4Usually one, but we also can find two zoning operators, for instance in ?jusqu?? avant No?l (until before
Christmas"). In this case, the order of the operators is more constraint than the order of Focalising/Shifting
operators. Therefore we use the ? symbol instead of +
368 Battistelli, Couto, Minel, and Schwer
they do not provide any new information. In sum, the representation of CEs has the
following generic form: OpZoning?(OpFocalising/Shi f ting+(OpPoin-ting(CB)).
For instance, let us analyse the CE E=?Avant le d?but de la fin de l?ann?e 2008"
(before the beginning of the end of the year 2008). B=?ann?e 2008". Firstly, the
operator of pointing, triggered by the identification of ?l?" (the contraction of ?le")
is applied, given E1=L?ann?e 2008".5 Secondly, two operators of focalising/shifting
are applied successively: the first one triggered by ?la fin de" , provides E ?2 and the
second one, triggered by ?le d?but de", provides E2. Finally an operator of zoning is
associated with ?avant", provided E . Consequently, the CE ?avant le d?but de la fin
de l?ann?e 2008" is produced as avant (le d?but de (la fin de(l?(ann?e 2008)))). The
sequence of this CE is depicted and visualized in Figure 2.
Figure 2: Computation of ?avant le d?but de la fin de l?ann?e 2008"
Each operator is characterized by its arity (the number of its arguments) and type.
With regard to arity, in this paper we focus on unary operators.
2.1 Unary operators
Three types of operators have been defined: pointing, focalising/shifting and zoning.
The pointing operator is trivial (it transforms B into a CE of type E1) but the two
others need some refinements.
Focalising/Shifting operators
Focalising/Shifting operators transform a CE of type E1 into a CE of type E2. Several
kinds of focalising/shifting time may be expressed. For instance, in the expression ?au
d?but de mai 2005" (at the beginning of may 2005) the focalising/shifting is localised
inside the BC (mai 2005), whereas in the expression ?trois semaines avant mai 2005"
(three weeks before may 2005) it is outside the BC. Consequently, six sub-operators
have been identified and are shown Table 1. It should be noted that ShiftingBeginning
and ShiftingAfter operators refers to a family of operators, because for these ones it is
necessary to precise two parameters, the granularity and the value of the shifting.
For some reasons of implementation, except for the operator IdShifting, which
refers at the identity, all others operators are treated as idempotent. In other words, we
consider as equivalent these two expressions ?au d?but du d?but des ann?es 1980" (at
the beginning of the early eighties) and ?au d?but des ann?es 1980? (in the early of
eighties). The next version will improve at this point.
Zoning operators
A Zoning operator transforms a CE of type E2, associated to the useful portion U of
Figure 1, into the CE E analysed. A Zoning operator refers to one of the six possible
5This pointing operator, as mentioned previously, is not an operator of the CE algebra, but all the other
operators are part of the CE algebra.
Representing and Visualizing Calendar Expressions in Texts 369
Table 1: Focalising/Shifting operators
Operators Examples
IdShifting ? en 1945
? au mois d?ao?t
ZoomBeginning ? ? l?aube des ann?es 1980
? au d?but de mai 1945
ZoomMiddle ? au milieu des ann?es 1980
ZoomEnding ? ? la fin des ann?es 1980
ShiftingBefore (granularity, -n) ? 10 jours avant le 14 juillet 2005
ShiftingAfter (granularity, +n) ? 10 jours apr?s le 14 juillet 2005
zones6 built from A, P and U: that is A, A+U, U, U+P, P, A+P. These six kinds of
zoning are associated with a set of prepositions, whose prototypes are shown Table 2.
Fuzzy expressions like ?peu avant? (short before) can double this number. Table 2
also illustrates the the ZoningAbout operator <U>. Further, note that ZoningId is not
expressed, but has to be taken into account.
Table 2: Zoning operators
Operators Expression
ZoningBefore [A] avant fin avril 2008
ZoningUntil [A+U] jusqu?? fin avril 2008
ZoningId [U] [ /0] fin avril 2008
ZoningAbout <U> vers la fin avril 2008
ZoningSince [U+P] depuis la fin avril 2008
ZoningAfter [P] apr?s fin avril 2008
ZoningApart [A+P] except? fin avril 2008
2.2 N-ary or sequence operators
As mentioned before, it is necessary to use several N-ary operators to represent some
CE. For instance, a binary operator is used for representing an expression like ?entre
fin mai 2005 et avril 2006" (between the end of may 2005 and april 2006). This oper-
ator, Between, applies to two CEs, so for the preceding expression the representation
is Between ((ZoomEnding(Pointing(may 2005), Pointing(april 2006)). Moreover, a
sequence operator is needed to represent a CE like ?le mardi 21, le mercredi 22 et le
vendredi 24 mai 1980" (on Tuesday 21, Wednesday 22 and Friday 24 of May). The
study of these operators, associated with even more complex CEs with quantifications,
is currently under investigation.
6The empty zone, expressed by ?jamais? (never) and the full zone, that is A+U+P, expressed by ?tou-
jours? (always) are CE, but not associated with unary operators associated to a BC, as defined here, hence
excluded of our precedent study.
370 Battistelli, Couto, Minel, and Schwer
3 Application
Many applications which exploit temporal expressions in texts, in particular in the area
of information extraction, have been implemented (Pazienza, 1999). Our application
is plugged into the textual navigation workstation NaviTexte (Couto, 2006; Couto and
Minel, 2007), in order to combine a traditional linear reading with a chronological
one. With this intention, we have undertaken the construction of a computerized aided
reading of biographies. Consequently, we have addressed two issues. First, identifying
temporal expressions and ordering chronologically text segments in which they are
included. Second, building calendar views of the text and navigating through these
views.
3.1 Identifying and ordering calendar expressions
From the linguistic study presented above, we have defined a set of annotations which
are used to automatically annotate biographic texts. This process is carried out by
transducers which put XML7 annotations through the processed text. These annota-
tions describe on the one hand, the granularity of CEs, and on the other hand, the
kind of identified operator. For instance, the following XML code illustrates how the
temporal expression ?avant le d?but de la fin de l?ann?e 2008" (Before the beginning
of the end of the year 2008) will be annotated:
<UT Type="Expression Calendaire" Nro="7">
<Annotation Nom="Grain">Annee</Annotation>
<Annotation Nom="Annee">2008</Annotation>
<Annotation Nom="RelationCalendrier">Absolue</Annotation>
<Annotation Nom="OpTempR?O?gion1">Avant</Annotation>
<Annotation Nom="OpTempD?O?placement1">FocalFin</Annotation>
<Annotation Nom="OpTempD?O?placement2">FocalDebut</Annotation>
<Chaine>
avant le debut de la fin de l?annee 2008
</Chaine>
</UT>
From these annotations, an automatic ordering relying on values of CEs can be
carried out. A first implementation took only into account disjoined CEs, because they
are linearly ordered. Intersecting CEs, like ?En juin 2007 (. . . ) en ?t? 2007" (in June
2007 (. . . ) in summer 2007) requires a more powerful formalism. A formalism relying
both on S-Languages (Schwer, 2002b) and granules (Schwer, 2002a) is required to
provide a full automatic ordering.
3.2 Building a text calendar view
A new kind of view, a calendar one, has been built in the NaviTexte platform. This
view is built from texts which contain CEs annotated as described above. An example
is shown in Figure 3. Conceptually, a calendar view is a graph coordinated with a two-
dimensional grid. In the left part of the view, lexical chains of various occurrences
of CEs in the text are displayed. By default, those are ordered according to their
order of appearance in the text, but it is possible to display a chronological order,
7A DTD is defined in Couto (2006)
Representing and Visualizing Calendar Expressions in Texts 371
by using options offered in the panel located in bottom of the view. Nodes in the
graph represent these lexical chains. The visual representation of a CE depends of the
functional representation computed as described before Figure 2.
A simple CE, with only a pointing operator like in ?l?ann?e 2008" (the year 2008)
is always visualised like a white ellipse. An operator of focalising/Shifting like ?la fin
de" (the end of) selects an area of the ellipse and blackens it. Finally, a zoning operator
like ?avant" (before) is visualised by a bold line displaying the area that is referred to.
The plug-in is implemented with the JGaph package and we largely use some of
its functionalities, like zooming or the partial layout cache. We also use html tooltip
text in Swing to contextualise a CE in the original text. For example, in Figure 3,
the whole paragraph which contains the CE ?en 1953? (in 1953) is displayed and the
occurrence of a CE is highlighted.
3.3 Evaluation
Two kinds of evaluation could be performed on this work: (i) evaluation of automatic
recognition and semantic annotation of CEs in text, (ii) evaluation of the calendar
view. The former calls for a classical protocol in NLP, whereas the latter is more
complex to carry out.
So far, only recognition has been carried out by Teissedre (2007) who computed
recall and precision on three kinds of corpora. Due to the fact that an annotation is
made up of several fields the recall has been computed like this: a score zero when
a CE is not identified, a score 1 when the identification is total, and 0.5 when the
identification is partial. Applying these rules, recall is 0.8 and precision is 0.9.
We would like to make two remarks on this result. First, quantified CEs like ?tous
les mardis? (every Tuesday) or ?un mardi sur deux? (one Tuesday out of two) and
n-aries (n? 3) CEs like "entre 2008 et 2009 et en juin 2010" (between 2008 and 2009
and in june 2010) are identified but are not yet taken into account in the semantic
annotation process. Second, syntactic ambiguities like in ?il a dormi deux jours avant
No?l? (he slept two days before Christmas) are not taken into account either. However
in this example, there are two possible syntactic structures. In the first case, "avant
No?l" is the CE and the operator is the Regionalisation one; in the second case, "deux
jours avant No?l" is the CE and the operator is the Shifting one. Presently, our analysis
provides only the second one like in Aunargue et al (2001) but we intend to upgrade
it in order to provide both analyses.
Evaluation of the calendar view should be studied from a cognitive point of view
and is highly dependent on the application. We plan to work with cognitive scien-
tists to build a relevant protocol to study this aspect of evaluation which calls for the
specification of a set of navigation operations based on the algebra of operators.
4 Conclusion
We proposed an algebra of CEs with three kinds of operators to analyse calendar
expressions and build a functional representation of these expressions. We described
an implementation of this approach in the platformNaviTexte and we have shown how
the functional representation is used to visualise a calendar view of a text. In future
work, we will rely on a methodology presented in Battistelli and Chagnoux (2007) in
372 Battistelli, Couto, Minel, and Schwer
Figure 3: Example of calendar view in NaviTexte
order to take into account several temporal axis, and thus several calendar structures,
which are expressed in texts by different levels of enunciations, like citations.
References
Aunargue, M., M. Bras, L. Vieu, and N. Asher (2001). The syntax and semantics of
locating adverbials. Cahiers de Grammaire 26, 11?35.
Barzilay, R., N. Elhadad, and K. McKeown (2001). Sentence ordering in multidocu-
ment summarization. In First International Conference on Human Language Tech-
nology Research (HLT-01), pp. 149?156.
Battistelli, D. and M. Chagnoux (2007). Repr?senter la dynamique ?nonciative et
modale de textes. In actes TALN?07 (Traitement automatique du langage naturel,
pp. 13?23.
Charolles, M. (1997). L?encadrement du discours ? univers, champs, domaines et
espaces. In Cahiers de recherche linguistique, Volume 6 of LANDISCO, pp. 1?73.
Universit? Nancy 2.
Couto, J. (2006). Mod?lisation des connaissances pour une navigation textuelle
assist?e. La plate-forme logicielle NaviTexte. Ph. D. thesis, Universit? Paris-
Sorbonne.
Couto, J. and J.-L. Minel (2007). Navitexte, a text navigation tool. In , Lecture Notes
in Artificial Intelligence 4733, pp. 251?259. Springer-Verlag.
Representing and Visualizing Calendar Expressions in Texts 373
Ferro, L., L. Gerber, I. Mani, B. Sundheim, and G. Wilson (2004). Standard for the
annotation of temporal expressions. Technical report, timex2.mitre.org, MITRE
Corporation.
Filatova, E. and E. Hovy (2001). Assigning time-stamps to event-clauses. In Work-
shop on Temporal and Spatial Information Processing, ACL?2001, pp. 88?95.
Halliday, M. A. K. (1994). An introduction to functional grammar. London: Edward
Arnold.
Harabagiu, S. and C. A. Bejan (2005). Question answering based on temporal infer-
ence. In AAAI-2005 Workshop on Inference for Textual Question Answering.
Hitzeman, J., M.Moens, and C. Grover (1995). Algorithms for analyzing the temporal
structure of discourse. In EACL?95, pp. 253?260.
Mani, I. and G. Wilson (2000). Robust temporal processing of news. In Proceedings
38th ACL, pp. 69?76.
Pazienza, M. T. (1999). Information Extraction, toward scalable, adaptable systems.
New York: Springer-Verlag.
Pustejovsky, J. (Ed.) (2002). TERQAS 2002: An ARDA Workshop on Advanced Ques-
tion Answering Technology.
Pustejovsky, J., J. Castano, R. Ingria, R. Sauri, R. Gaizauskas, A. Setzer, and G. Katz
(2003). Timeml: Robust specification of event and temporal expressions in text. In
IWCS-5 Fifth International Workshop on Computational Semantics.
Pustejovsky, J., R. Knippen, J. Lintman, and R. Sauri (1993). Temporal and event
information in natural language text. Lexique 11, 123?164.
Schilder, F. and C. Habel (2001). From temporal expressions to temporal informa-
tion: Semantic tagging of news messages. In Proceedings of ACL?01 workshop on
temporal and spatial information processing, pp. 65?72.
Schwer, S. R. (2002a). Reasoning with intervals on granules. Journal of Universal
Computer Science 8 (8), 793?808.
Schwer, S. R. (2002b). S-arrangements avec r?p?titions. Comptes Rendus de
l?Acad?mie des Sciences de Paris S?rie I 334, 261?266.
Setzer, A. and R. Gaizauskas (2000). Annotating events and temporal information in
newswire texts. In Proceeedings 2rd LRC, pp. 64?66.
Song, F. and R. Cohen (1991). Tense interpretation in the context of narrative. In 9th
AAAI, pp. 131?136.
Tannen, D. (1997). Framing in Discourse. Oxford: Oxford University Press.
Teissedre, C. (2007). La temporalit? dans les textes : de l?annotation s?mantique ? la
navigation textuelle. Master?s thesis, Universit? Paris-Sorbonne.
Proceedings of the 7th Linguistic Annotation Workshop & Interoperability with Discourse, pages 223?227,
Sofia, Bulgaria, August 8-9, 2013. c?2013 Association for Computational Linguistics
Enunciative and modal variations in newswire texts in French: From 
guideline to automatic annotation 
Marine Damiani 
MoDyCo, UMR 7114, Universit? Paris 
Ouest 
marinedamiani@gmail.com 
Delphine Battistelli  
STIH, EA 4509, Universit? Paris Sorbonne 
delphine.battistelli@paris-
sorbonne.fr 
Abstract 
In this paper we present the development of a 
corpus of French newswire texts annotated 
with enunciative and modal commitment in-
formation. The annotation scheme we propose 
is based on the detection of predicative cues - 
referring to an enunciative and/or modal varia-
tion - and their scope at a sentence level. We 
describe how we have improved our annota-
tion guideline by using the evaluation (in 
terms of precision, recall and F-Measure) of a 
first round of annotation produced by two ex-
pert annotators and by our automatic annota-
tion system. 
1 Introduction 
This paper concerns the design of a reference 
corpus that can be used to evaluate an automatic 
annotation system of enunciative and modal 
commitment in newswire texts in French. This 
complex linguistic phenomenon refers to the fact 
that a situation can be presented as certain, or 
only possible/probable, by an enunciator who can 
be the author of the text but who can also be an-
other enunciator (explicitly named or not) from 
whom the author reports some content that he has 
heard, read, imagined, etc. Different kinds of lin-
guistic cues are involved. In addition to the need 
to identify and semantically classify these cues, 
one has to deal with the question of their scope. 
This question is even more complex as many 
cues can be present together in a sentence, thus 
complexifying the interpretation of the interac-
tion of different scopes (see Example 1.). 
 
1. M. Arabi a exprim?cue1 [le souhaitcue2 [d?aider la 
Syrie ? surmonter cette phase]scope2]scope1] // [Mr. 
Arabi expressedcue1 [a desirecue2 [to help Syria 
overcome this phase.]scope2]scope1 
 
Another major difficulty concerns the fact 
that evidential and modal characteristics are very 
similar (see for example a noun like desire). Our 
work addresses the question of annotating these 
cues and their semantic scope. Unlike most other 
approaches, we have chosen not to treat these 
two kinds of characteristics separately, since 
both are implicated in what is called enunciative 
commitment. We will focus here on our practice 
for the development of a reference corpus.  
After a brief presentation of the theoretical 
background (section 2), we describe which kinds 
of linguistic cues are considered and what kind 
of semantic scopes are then encountered (section 
3). Our annotation procedure aims to delimit tex-
tual segments that are semantically impacted by 
the presence of enunciative and modal cues. In 
this light, we will focus only on what we will 
describe below as predicative cues. Then we will 
explain how we have improved our annotation 
guideline by using the evaluation of a first round 
of annotation produced for the same task by two 
expert annotators and by our automatic annota-
tion system (section 4). 
2 The phenomenon of enunciative and 
modal commitment  
In the field of linguistics, the notion of modality 
can be considered from an enunciative perspec-
tive (see Bally, 1932 Benveniste, 1966; Culioli, 
1973). From this perspective, which is the one 
we adopt here, the construction of an utterance 
(or a text) has to take into account certain lan-
guage operations such as predication or opera-
tions of commitment, the expression of which 
leaves a certain number of surface linguistic 
traces (or cues). The enunciator?s degree of 
commitment to a predicative content is marked 
in the utterance by different kinds of linguistic 
traces. In other words, it can be said that in dis-
course the enunciator expresses different degrees 
of commitment to the truth of the propositional 
content.  
Very close to this issue is thus the long tradi-
tion of tracking veridicality in discourse. Wheth-
er ? in the most recent work - under the term of 
?factuality degrees of events? (Sauri and 
Pustejovsky, 2012), ?event veridicality? (De 
Marneffe et al, 2012), ?detection of uncertainty? 
(CoNLL-2010 Shared Task) or ?attributions? and 
223
?private states? (Wilson and Wiebe, 2005), this 
notion refers to the relationship between lan-
guage and reader commitment. In our approach, 
we do not attempt to access the notion of veridi-
cality directly but rather via the organization of 
the text into different textual segments that have 
different enunciative and modal validation con-
texts. However, the cues we have to take into 
account to achieve this goal are mostly the same 
as in veridicality studies (modal verbs, reported 
speech verbs, verb of propositional attitude, 
hedging adverbs, and so on). Moreover, beyond 
traditional lexical cues, we also include in our 
work other cues such as morphological inflection 
(e.g. inflection of the French conditional tense), 
syntactic constructions such as subordinate 
clauses of condition or prepositional construc-
tions (e.g. according to X, at first sight?). Fur-
thermore, we have to take into account the fact 
that a lot of cues are embedded (as seen in Ex-
ample 1 with express and a desire). If we want to 
interpret the enunciative and modal context of 
the textual segment to help Syria overcome this 
phase, we have to consider the fact that it is em-
bedded in the segment a desire to help Syria 
overcome this phase. From this point of view our 
work is related to Kilicoglu (2012) who studied 
?embedding predications?. Thus, we do not only 
consider the type of cues we find in text but also 
the way they interact. This methodology also 
enables us to consider cues that play a role at a 
discursive level. This question of discursive 
markers is discussed in (Charolles et al, 2005). 
Although modality markers in French - in 
their close relationship with the markers of evi-
dentiality - have been systematically described 
(see for example Gosselin, 2010; Le Querler, 
2004) there is still no reference corpus proposing 
the annotation of enunciative and modal charac-
teristics as a discursive delimitation task and this 
is the goal we seek to achieve. This problem of 
identifying modal cues related to a scope was 
initially researched in biomedical texts (Vincze 
et al, 2008). This applicative task made it possi-
ble to renew the linguistic approach to modality 
by adopting a more concrete approach, focusing 
first on the variety of cues that can be identified 
in a text. This perspective also enables the issue 
of the influence of textual genre on modality 
markers to be addressed. 
In the next section, we present the way we 
propose to annotate this enunciative and modal 
commitment variation in text in terms of cues 
and scopes. 
3 Annotating enunciative and modal 
commitment in term of cues and scope  
Our annotation goal is to define in which enunci-
ative and modal context a propositional content 
occurs. Observation of the cues in our corpus 
showed that there are two kinds of cues: predica-
tive cues that lead to the opening of a new textual 
segment (this kind of cue has the syntactic prop-
erty of governing another textual segment, e.g. 
cue1 in Example 2.) and what we called modifier 
cues (mainly adverbs and some adjectives, e.g. 
cue2 in Example 2.). The identification of pre-
dicative cues (and their scope) leads to split the 
text into different textual segments and then the 
identification of modifier cues influence the vali-
dation context of the textual segment previously 
identified.  
 
2. Paul veutcue1 s?rementcue2 que [Mary vienne.] 
scope // Paul certainlycue1 wantscue2 [Mary to 
come] scope. 
 
The annotation task we present here consists 
in annotating these predicative cues (that lead to 
modify the level of enunciative and/or modal 
commitment of a textual segment) and their 
scope. The scope of a predicative cue corre-
sponds to the textual segment impacted by the 
variation in the level of enunciative and/or modal 
commitment. Table 1 presents the four classes of 
predicative cues that we consider and for each of 
them gives some examples of the syntactic com-
ponents that can be under the scope of the cue.  
 
Cues  Scope  
Verbs  Direct and/or indirect object 
Reporting verb, 
modal verbs 
Paul prometcue qu?[il viendra]scope / 
Paul promisescue that [he will 
come]scope 
Paul veutcue[venir]scope / Paul 
wantscue [to come]scope 
Nouns Noun complements, relative 
clause 
Predicative 
nouns  
C'est son souhaitcue [d'?tre impli-
qu?]scope / It is his wishcue [to be 
involved]
 scope 
Morphological  All the verb complements 
Future, condi-
tional  
John viendracue [plus tard]
 scope / 
John willcue [come later]
 scope 
Syntactic Main clause 
Subordinate 
clauses of condi-
tion 
 
 
Prepositional 
construction 
[Mary refuse de donner son appro-
bation]
 scope ? moins que Paul ac-
ceptecue / [Mary refuses to give her 
approval]
 scope unless Paul ac-
ceptscue 
D?apres Paulcue, [Mary va venir]
 
scope / According to Paulcue, [Mary 
is coming]
 scope 
Table 1: Cues and associated scopes 
224
 As can be seen, depending on the type of pre-
dicative cue, the syntactic dependents we consid-
er in the scope vary. This description of what we 
consider as a predicative cue and how to delimit 
the corresponding scope is reported in the first 
version of an annotation guideline. In order to 
refine our descriptions and measure their rele-
vance on the corpus, the following section pre-
sents the inter-annotator agreement between two 
expert annotators and the first results of the au-
tomatic system for the same annotation task. This 
evaluation process should lead to the production 
of a more precise guideline that can reveal fine 
discursive shades and also stimulate reflection on 
how best to deal with syntactic and semantic in-
formation in the automatic annotation system. 
4 Annotation and evaluation process 
Our final goal is to develop an automatic annota-
tion system that produces the annotation of 
enunciative and modal cues and their scope in 
newswire texts. In this light, we have to build a 
guideline of our annotation aim and a reference 
corpus that can be used to evaluate the system.  
 
Figure 1.Workflow of guideline improvement 
 
 
Figure 1 illustrates the steps in the workflow 
applied to improve our annotation guideline. For 
this purpose, two annotators (henceforth A1 and 
A2), both of them experts in linguistics, worked 
together to build a guideline and then the refer-
ence corpus1. First of all, the two annotators de-
fined the annotation goals together (see step 1 in 
Figure 1). Then they annotated separately a cor-
pus of 20 newswire texts (see step 2a in Figure 
3). This corpus contains 256 predicative cues and 
their associated scopes (see Table 2). 
 
  
# Sent Total Verbs Nouns Morpho Syntactic 
199 256 210 4 11 31 
 
Table 2: Corpus statistics 
                                                 
1
 Our annotation process is based on Morante and 
Daelemans (2012). 
 
This manual annotation task was carried out 
using the Glozz Annotation Tool (Widl?cher and 
Mathet, 2012) that relies on the URS (Unit-
Relation-Schema) meta model and produces an 
xml output. The model permits to annotate textu-
al units that can be embedded or not (in our case 
the predicative cues and their scope) and rela-
tions (for us, the opening relation links the pre-
dicative cue to its scope).  
 
After this first annotation round, inter-
annotator agreement was calculated (see table 3). 
The results show that the agreement between the 
two annotators is high for the cues but not very 
good for the scopes. By comparing the two sets 
of annotations in detail, we observed in our cor-
pus that some textual segments can be either in-
cluded or excluded from the scope depending on 
the annotator?s interpretation. Example (3) shows 
the scope annotation proposed by annotator A1. 
As we can see, the textual segment qui a d?but? 
lundi is included in the scope by this annotator 
but it is excluded in the annotation proposed by 
A2. In this particular case, we consider that both 
interpretations are acceptable since we cannot 
say for sure if this segment is presented from the 
viewpoint of the journalist or from the viewpoint 
of the source un de ses avocats. The same phe-
nomenon is often observed with temporal adver-
bials that cannot be interpreted unambiguously as 
being a part of the scope or not. In these two 
kinds of cases the annotator needs to use the con-
text and his linguistic background to decide. This 
raises the issue - already mentioned in Farkas et 
al. (2010) ? as to whether it is advisable to set a 
strict boundary for the scope. 
We propose to address this issue by evaluat-
ing the scope annotation both strictly and more 
flexibly. In the flexible interpretation we distin-
guish the segments that are detected with an ex-
act match boundary from those that are detected 
with different boundaries but that are still correct 
in the interpretation (as in example 3).  
 
 
3. [Le proc?s devant un tribunal militaire d'un 
blogueur ?gyptien arr?t? pour avoir critiqu? l'ar-
m?e, qui a d?but? lundi, a ?t? ajourn? ? di-
manche]scope, a indiqu?cue mardi un de ses avocats. 
// [The trial before a military court of an Egyptian 
blogger arrested for criticizing the army, which 
began on Monday, has been postponed to Sun-
day]scope, saidcue one of his lawyers on Tuesday. 
 
 
To measure the distinction of using strict or 
flexible boundaries for scope, we propose to dis-
tinguish the scope evaluation (for strict scope 
boundaries) from the weighted scope evaluation 
(for flexible boundaries).  
225
Flexible boundaries are calculated with a 0.5 fac-
tor as follows: 
????????	????????? ?
?? ? 0.5	 ? ??
???  
????????	?????? ?
?? ? 0.5	 ? ??
???  
? SB (strict boundaries): the number of enti-
ties with a strict scope boundary 
? FB (flexible boundaries): the number of 
entities with a flexible scope boundary 
? Ref: the number of reference entities (i.e. 
ideally identified) 
? Rel: the number of relevant entities (i.e. 
correctly identified) 
 
The distinction between the evaluation of 
scope and weighted scope revealed that in a sig-
nificant number of cases (in this experimentation 
about 10 %) the two annotators disagreed in their 
annotation but that both interpretations were cor-
rect. This observation helped us to rethink our 
annotation goals and based on the result of inter-
annotator agreement, the two annotators pro-
duced a common adjudicated version of their 
annotation2 (step 4 in Figure 1). This new anno-
tated version is the result of a reflection on the 
two annotators? disagreements and considers the 
context to delimit scope boundaries. 
 
Adjudicated /System precision recall F1 
 Cues 0.85 0.86 0.86 
 Scopes 0.79 0.72 0.76 
 Weighted Scopes 0.84 0.77 0.80 
SB FB Rel Ref 
185 22 256 234 
 
Table 3: IAA: the annotations of annotator A1 are 
evaluated against the annotations of annotator A2 
 
Adjudicated /System precision recall F1 
 Cues 0.83 0.85 0.84 
 Scopes 0.52 0.59 0.55 
 Weighted Scopes 0.67 0.76 0.71 
SB FB Rel Ref 
59 33 100 113 
 
Table 4: System evaluation: annotations from the sys-
tem are evaluated against the adjudicated version  
 
In a second step, we evaluated the first anno-
tation version of our automatic system (step 2b in 
Figure 1) on a subset of the corpus against the 
annotation of the adjudicated version (see table 
4). The subset corpus contains 100 cues and their 
associated scopes. Our automatic annotation sys-
tem is based on the analysis dependency syntac-
tic parser combined with scope detection rules 
(see Battistelli and Damiani, 2013). The results 
                                                 
2
 This adjudicated version is available for consultation: 
http://vmoaxc.1fichier.com/predicative_cue_scope.zip 
of this evaluation show that the detection of cues 
is good, as with the manual annotation, while the 
scope detection is not as good. This can be ex-
plained partly by the fact that the syntactic parser 
analysis produces some analysis errors (tagging 
or parsing errors, wrong syntactic attachment 
especially with coordinating conjunctions). 
Moreover, this evaluation shows that with an 
automatic system, distinguishing strict and flexi-
ble boundaries can highlight the results in anoth-
er way. Indeed, if we look at the scope evalua-
tion, the F-measure is not really satisfactory. If 
we take into account only this measure, it could 
be concluded that our system is not efficient. 
However, with the measure of weighted scope 
we see that while in many cases the scope did not 
match exactly with the reference corpus, it was 
not wrong either. This phenomenon of scope 
boundaries that are not easily decidable repre-
sents 10% of disagreement in the IAA (ie 22 cas-
es) and 30% in the system evaluation (ie 33 cas-
es), and has to be taken into account to improve 
the guideline and the annotation system. This 
first annotation experiment on a small corpus 
helped us to define new annotation goals that 
must be integrated both in the new version of the 
guideline (step 6 in Figure 1) and in the automat-
ic annotation system.  
5 Conclusion 
In this paper, we have focused on a methodology 
to produce a reference corpus proposing the an-
notation of enunciative and modal commitment 
information as a discursive delimitation task. The 
annotation scheme we propose is based on the 
detection of predicative cues and their scopes. 
The results of the evaluation presented here show 
that the most challenging task is not to find the 
predicative cues but to delimit their scopes and 
beyond this delimitation question to define how 
to assess whether a scope is correct or not. Next 
step of our work is to launch a larger annotation 
campaign involving more human annotators and 
a bigger corpus. In this second step, our model 
will integrate modifier cues such as hedging ad-
verbs that modify the semantic value of the tex-
tual segments that have been first delimited and 
introduce discursive cues that can impact more 
than a single sentence At last, in order to make 
our work available for the community our guide-
line and reference corpus will soon be available 
on Chronolines project website3. 
                                                 
3
 http://www.chronolines.fr/ 
226
References  
Bally, C. 1932. Linguistique g?n?rale et Linguistique 
fran?aise. Paris : Leroux, 2?d. (1944), Berne. 
Battistelli, D. and Damiani, M. 2013. Analyzing mod-
al and enunciative discursive heterogeneity: how to 
combine semantic resources and a syntactic parser 
analysis. In IWCS 2013 Workshop: WAMM, 
Potsdam. 
Benveniste, E. 1966. Probl?mes de linguistique g?n?-
rale, 1, Paris : Gallimard. 
Charolles, M., Le Draoulec, A., P?ry-Woodley, M. P. 
and Sarda, L. 2005. Temporal and spatial dimen-
sions of discourse organisation. Journal of French 
Language Studies, 15(2), 115. 
Culioli, A. 1973. Sur quelques contradictions en lin-
guistique. Communications, 20(1), 83-91. 
De Marneffe, M. C., Manning, C. D. and Potts, C. 
2012. Did it happen? The pragmatic complexity of 
veridicality assessment. Computational Linguistics 
38(2):301-333. 
Farkas R., Vincze V., M?ra G, Csirik J. and Szarvas 
G. 2010. The CoNLL 2010 Shared Task: Learning 
to Detect Hedges and their Scope in Natural Lan-
guage Text. In Proceedings of the 2010 Conference 
on Computational Natural Language Learning. 
Kilocoglu, H.H. 2012. Embedding predications. PhD 
Dissertation, Concordia University, Montreal.  
Morante, R. and Daelemans, W. 2012. ConanDoyle-
neg: Annotation of negation in Conan Doyle sto-
ries. In Proceedings of the Eighth International 
Conference on Language Resources and Evaluation 
(LREC). 
Sauri, R. and Pustejovsky, J. 2012. Are You Sure That 
This Happened? Assessing the Factuality Degree 
of Events in Text. Computational Linguistics, 
38(2):261-299. 
Widl?cher A. and Mathet Y. 2012. The Glozz Plat-
form: A Corpus Annotation and Mining Tool. In 
Proceedings of the 2012 ACM symposium on 
Document engineering, 171-180. 
Wilson, T. and Wiebe, J. 2005. Annotating Attribu-
tions and Private States. In ACL 2005 Workshop: 
Frontiers in Corpus Annotation II: Pie in the Sky, 
53-60. 
 
227
Proceedings of the 2014 Workshop on Biomedical Natural Language Processing (BioNLP 2014), pages 107?111,
Baltimore, Maryland USA, June 26-27 2014.
c?2014 Association for Computational Linguistics
Symptom recognition issue
Laure Martin
MoDyCo
Paris Ouest University
laure.martin.1988
@gmail.com
Delphine Battistelli
MoDyCo
Paris Ouest University
del.battistelli
@gmail.com
Thierry Charnois
LIPN
Paris 13 University
thierry.charnois
@lipn.univ-paris13.fr
Abstract
This work focuses on signs and symptoms
recognition in biomedical texts abstracts.
First, this specific task is described from a
linguistic point of view. Then a method-
ology combining pattern mining and lan-
guage processing is proposed. In the ab-
sence of an authoritative annotated cor-
pus, our approach has the advantage of
being weakly-supervised. Preliminary ex-
perimental results are discussed and reveal
promising avenues.
1 Introduction
Our work is part of the Hybride
1
Project, which
aims to expand the Orphanet encyclopedia. Or-
phanet is the reference portal for information on
rare diseases (RD) and orphan drugs, for all audi-
ences. A disease is considered rare if it affects less
than 1 person in 2,000. There are between 6,000
and 8,000 RD. 30 million people are concerned in
Europe. Among its activities, Orphanet maintains
an RD encyclopedia by manually monitoring sci-
entific publications. Hybride Project attempts to
automatically acquire new RD-related knowledge
from large amounts of scientific publications. The
elements of knowledge about a disease are varied:
onset, prevalence, signs and symptoms, transmis-
sion mode, disease causes (etiology).
In this article, we investigate the automatic
recognition of signs and symptoms in abstracts
from scientific articles. Although named entity
recognition in the biomedical domain has been
extensively studied, signs and symptoms seem to
have been left aside, for there is very little work on
the subject. First, the linguistic issue of our study
is presented in section 2, then the state of the art
and the description of our lexical resources in sec-
tion 3. Then our corpus and general method are
1
http://hybride.loria.fr/
presented in section 4. First experiments are intro-
duced in section 5. Finally, the work to come is
presented in section 6.
2 Signs and symptoms
Signs and symptoms both refer to the features of a
disease, except that a symptom (or functional sign)
is noticed and described by a patient, whilst a clin-
ical sign is observed by a healthcare professional.
In thesauri and medical ontologies, these two no-
tions are generally put together in the same cate-
gory. Moreover, in texts ?particularly in our cor-
pus of abstracts from scientific articles? there is
no morphological or syntactic difference between
sign and symptom. The difference is only seman-
tic, so it is impossible for non-specialists in the
medical field to tell the difference from the linguis-
tic context alone. In example (1), clinical signs are
in bold and symptoms are italicized.
(1) Cluster headache (CH) is a primary
headache disease characterized by re-
current short-lasting attacks of excruci-
ating unilateral periorbital pain accom-
panied by ipsilateral autonomic signs
(lacrimation, nasal congestion, ptosis,
miosis, lid edema, and eye redness).
Furthermore, the diagnosis is established by the
symptoms and the clinical signs together. We did
not, therefore, try to distinguish them.
Signs and symptoms take on the most varied lin-
guistic forms, as is noticeable in the corpus (which
will be described in more detail below). In its sim-
plest form, a sign or symptom is a noun, which
may be extended by complements, such as adjec-
tives or other nouns (example 2). They also appear
in other, more complex, forms, ranging from a sin-
gle phrase to a whole sentence (example 3).
(2) With disease progression patients
additionally develop weakness and
107
wasting of the limb and bulbar mus-
cles.
(3) Diagnosis is based on clini-
cal presentation, and glycemia
and lactacidemia levels, after a
meal (hyperglycemia and hypo-
lactacidemia), and after three to
four hour fasting (hypoglycemia and
hyperlactacidemia).
In addition to their variety, the linguistic units
representing signs and symptoms present some
syntactic ambiguities, particularly ambiguities
concerning prepositional attachment and coordi-
nation scope. In example (2), the first occur-
rence of ?and? is ambiguous, for we don?t know
if ?weakness? and ?wasting? should be grouped
together as a single manifestation of the disease,
or if ?weakness? on the one hand and ?wasting of
the limbs and bulbar muscles? on the other hand
are two separate entities, as annotated here.
In addition to these syntactic ambiguities, two
annotation difficulties also arise. The first one con-
sists in correctly delimiting the linguistic units of
the signs and symptoms (example 4a). We agreed
with experts in the field that, generally, pieces
of information such as adjectives of intensity or
anatomical localizations were not part of the units;
nevertheless, this information is interesting in that
it provides the linguistic context for the signs and
symptoms. The second difficulty concerns ellip-
tical constructions: where two signs can be dis-
tinguished, only one can be annotated because the
two nouns have an adjective in common (exam-
ple 4b).
(4) In the severe forms, paralysis (4a)
concerns the neck, shoulder, and proxi-
mal muscles, followed by involvement
of the muscles of the distal upper ex-
tremities, the diaphragm and respiratory
muscles, which may result in respira-
tory compromise or arrest (4b).
Eventually, the last difficulty that was met dur-
ing the corpus observation is the semantic ambi-
guity existing between sign or symptom and dis-
ease denominations. A disease can be the clinical
sign of another disease. A clinical sign may be
included in a disease name or conversely. In ex-
ample (5), the clinical sign is in bold and the name
of the disease is underlined.
(5) The adult form results in progressive
limb-girdle myopathy beginning with
the lower limbs, and affects the respira-
tory system.
3 State of the art
Signs and symptoms have seldom been studied
for themselves in the field of biomedical informa-
tion extraction. They are often included in more
general categories such as ?clinical concepts?
(Wagholikar et al., 2013), ?medical problems?
(Uzuner et al., 2011) or ?phenotypic information?
(South et al., 2009). Moreover, most of the studies
are based on clinical reports or narrative corpora
?the Mayo Clinic corpus (Savova et al., 2010) or
the 2010i2b2/VA Challenge corpus (Uzuner et al.,
2011)?, except for the Swedish MEDLEX Cor-
pus (Kokkinakis, 2006), which comprises teaching
material, guidelines, official documents, scientific
articles from medical journals, etc. Our work aims
at scientific monitoring and is therefore based on a
corpus of abstracts from scientific articles.
Most of the information extraction systems de-
veloped in the works previously cited use lexi-
cal resources, such as the Unified Medical Lan-
guage System (UMLS) or Medical Subject Head-
ings (MeSH) thesauri for the named entity extrac-
tion task. The UMLS comprises over 160 con-
trolled vocabularies such as MeSH, which is a
generic medical thesaurus containing over 25,000
descriptors. However, as Albright et al. (2013)
pointed out, UMLS was not originally designed
for annotation, so some of the semantic types over-
lap. They add that ?the sheer size of the UMLS
schema increases the complexity of the annotation
task and slows annotation, while only a small pro-
portion of the annotation types present are used.?
That is why they decided to work with UMLS se-
mantic groups instead of types, except for signs
and symptoms ?originally a semantic type in the
Disorders semantic group?, that they used inde-
pendently.
In a genetic disease context, a sign or symp-
tom may be phenotype-related. A phenotype is
all the observable characteristics of a person, such
as their morphology, biochemical or physiological
properties. It results from the interactions between
a genotype (expression of an organism?s genes)
and its environment. As many rare diseases are
genetic, many signs and symptoms may be found
in lists of phenotype anomalies. For that reason,
108
we chose to use the Human Phenotype Ontology
? HPO (Khler et al., 2014) as a lexical resource.
To our knowledge, HPO has not yet been used
in any study on signs and symptoms extraction.
Nevertheless, it should be recalled that phenotype
anomalies are not always clinical signs, and signs
or symptoms are not all phenotype-related. Even
so, we decided to use HPO as a lexical resource
because it lists 10,088 terms describing human
phenotype anomalies and can be easily collected.
Just a very few studies take advantage of consid-
ering the linguistic contexts of sign and symptom
entities. Kokkinakis (2006), after a first annotation
step of his corpus with MeSH, states that 75% of
the signs and symptoms co-occur with up to five
other signs and symptoms in a sentence. This al-
lowed him to develop new annotation rules. We
can also mention the MedLEE system (Friedman,
1997), which provides, for each concept, its type
(e.g. ?problem?), value (e.g. ?pain?) and modi-
fiers such as the degree (e.g. ?severe?) or the body
location (e.g. ?chest?).
As far as we are concerned, our approach is
based on the combination of NLP and pattern min-
ing techniques. We will see that the linguistic con-
texts mentioned above are part of the patterns au-
tomatically discovered with our text mining tool.
4 Corpus and general method
As mentioned above, HPO was selected as the
lexical resource for this project. With the list of
phenotype anomalies as queries, we compiled a
corpus of 306,606 abstracts from the MEDLINE
database with the PubMed search engine. These
abstracts are from articles published within the last
365 days. They consist of an ID, a title and a para-
graph. Then, we applied HPO and kept only the
sentences containing a unit annotated as a sign or
symptom. As already pointed out, signs and symp-
toms are not all phenotype-related, so our pre-
annotation is incomplete. Nonetheless, this first
annotation is quick and cheap, and it initiates the
process.
Figure 1 illustrates the successive steps in the
approach. In step 1, HPO (f) is used to annotate a
first corpus (a) by a single projection of HPO terms
onto the texts. This annotated corpus provides a
first learning corpus (b) to discover patterns (c) by
a text mining method (step 2; this method is de-
tailed below). These patterns are then validated by
an expert (step 3), as linguistic patterns (d). Step
Figure 1: Iterative process of our sign and symp-
tom extraction method
4 consists in using these patterns to annotate new
corpora (e) and extract new terms (here with the
semantic type of sign or symptom), which will
be added to the resources (f). The process is fi-
nally repeated (back to step 1, with enriched lexi-
cal resources). This incremental process has the
advantage of being weakly-supervised and non-
dependent on the corpus type.
Sequential pattern mining was first introduced
by Agrawal et al. (1995) in the data mining field.
It was adapted to information extraction in texts by
B?echet et al. (2012). It is a matter of locating, in a
set of sequences, sequences of items having a fre-
quency above a given threshold (called ?support?).
Pattern mining is done in an ordered sequence of
items base, where each sequence corresponds to a
text unit (the sentence here). An item represents a
word in this sequence, generally the inflected form
or the lemma or even the part of speech if the aim
is to identify generic patterns. A number of param-
eters can be adapted along with the application.
Contrary to classical Machine Learning ap-
proaches which produce numerical models that are
unintelligible for humans, data mining allows the
discovery of symbolic patterns which can be inter-
preted by an expert. In the absence of authoritative
annotated corpora for the recognition of signs and
symptoms, manual validation of the patterns step
is necessary, and often a large number of patterns
still remains. To overcome this difficulty, B?echet
et al. (2012) suggested adding constraints in or-
der to reduce the results. In continuation of this
work, we make use of the sequential patterns ex-
traction tool SDMC
2
, which makes it possible to
2
https://sdmc.greyc.fr/
109
apply various constraints and condensed represen-
tations extraction (patterns without redundancy).
We adapted pattern mining to our field of ap-
plication. Thus we first propose to use TreeTag-
ger (Schmidt, 1994) as a pretreatment, in order
to mark up different types of item (inflected form,
lemma, part of speech). To narrow down the num-
ber of patterns returned by the tool, we introduce
several constraints specific to our application: lin-
guistic membership constraints (for example, we
can choose to return only patterns containing at
least one sign or symptom name), or the ?gap?
constraint (Dong and Pei, 2007), corresponding to
possible gaps between items in the pattern. Thus a
gap of maximal value n means that at most n items
(words) are between each item of the pattern in the
corresponding sequences (sentences).
5 First experiment
Annotating the first MEDLINE corpus of Ab-
stracts with HPO provided us with a corpus of
10,000 annotated sentences. The 13,477 annotated
units were replaced by a keyword ?SYMPTOM?
in order to facilitate the discovery of patterns.
Then we used SDMC to mine the corpus for max-
imal patterns, with a minimal support of 10, a
length between 3 and 50 words and a gap con-
straint of g(0,0), i.e. the words are consecutive
(no gap allowed). We were mining for lemma se-
quences only.
Results produced 988 patterns, among which
326 contained the keyword symptom. Based on
these patterns, several remarks can already be
made:
? Several annotated signs or symptoms are
regularly associated with a third term,
which can be another sign or symptom:
{symptom}{symptom}{and}{stress};
? HPO annotation limitations (see sec-
tion 3) are made visible by some contexts:
{disease}{such}{as}{symptom};
? Some contexts are particularly recurrent,
such as {be}{associate}{with}{symptom}
or {characterize}{by}{symptom};
? Some temporal and chronologi-
cal ordering contexts are present:
{@card@}{%}{follow}{by}{symptom};
? The term ?patient? is quite regular
({patient}{have}{severe}{symptom}),
but after the evaluation, these occurrences
turned out to be disease-related more than
sign or symptom-related;
? The body location proved to
be another regular context:
{frontotemporal}{symptom}{ftd}.
Firstly, a linguistics expert selected the pat-
terns that he considered the most relevant. These
patterns were then classified in three categories:
strong if they seem to strongly imply the pres-
ence of signs and symptoms (43 patterns), mod-
erate (309 patterns) and weak (45 patterns). Sec-
ondly, these patterns were applied on a new cor-
pus of MEDLINE abstracts in order to annotate
the sign and symptom contexts. For the moment,
only strong patterns have been applied.
25 abstracts were randomly selected among all
the scientific articles published within the last
month and dealing with Pompe disease. These
25 articles were manually annotated for signs and
symptoms by an expert and thus constituted a gold
standard. Then, we compared the manual annota-
tion to our automatically annotated contexts. If
the annotated sentence includes signs or symp-
toms, we consider that the annotation is relevant.
Among the 25 abstracts (225 sentences), 27 con-
texts were extracted with our method. 23 were
correct, 4 were irrelevant; 70 sentences were not
annotated by the system. Thus the results were
23.7 in recall, reaching 82.2 in precision (36.8 in
F-score).
6 Conclusions
Sign/disease ambiguity is the cause of 3 of the 4
irrelevant annotations, i.e. diseases were in the
same linguistic context than signs. Thus the sen-
tences were annotated but they contained diseases,
not signs. The forth irrelevant annotation indi-
cates a diagnosis test; it highlights that causes and
consequences of a disease can be easily confused
by non-specialists. Most of the left out sentences
contain signs or symptoms expressed by complex
units, such as Levels of creatinkinase in serum
were high. (36%). 27% of these sentences are
about gene mutations, which can be considered as
causes of diseases or as clinical signs. Others con-
tain patterns which have not been selected by the
expert but can be easily added to improve the re-
call.
110
The context annotation is only a first step to-
wards sign and symptom extraction. So far, we
have not solved the problem of unit delimitation.
In order to achieve this, we have two working hy-
potheses. We intend to compare chunking and
syntactic analysis results in defining the scope of
sign and symptom lexical units. Chunking will
be conducted with an NLP tool such as TreeTag-
ger, and syntactic analysis will use a dependency
parser such as the Stanford Parser (ref.). The latter
should allow us to delimit some recurring syntac-
tic structures (e.g. agents, enumerations, etc.).
We also intend to compare our results with re-
sults provided by CRFs. First the features will be
classical (bag of words, among others), and sec-
ond, we will add the contexts obtained with the
text mining to the features. This should enable
us to compare our method to others. Finally, we
are going to develop an evaluation interface to fa-
cilitate the work of the expert. In the absence of
comparable corpora, the evaluation can only be
manual. Our current sample of 50 abstracts is
just a start, and needs to be expanded in order to
strengthen the evaluation.
Acknowledgments
This research was supported by the Hybride
Project ANR-11-BS02-002.
References
Rakesh Agrawal and Ramakrishnan Srikant. 1995.
Mining Sequential Patterns. Proceedings of
ICDE?95.
Daniel Albright, Arrick Lanfranchi, Anwen Fredrik-
sen, William F. Styler IV, Colin Warner, Jena D.
Hwang, Jinho D. Choi, Dmitriy Dligach, Rodney D.
Nielsen, James Martin, Wayne Ward, Martha Palmer
ans Guergana K. Savova. 2013. Towards compre-
hensive syntactic and semantic annotations of the
clinical narrative. Journal of the American Medical
Informatics Association, 20:922?930.
Nicolas B?echet, Peggy Cellier, Thierry Charnois and
Bruno Cr?emilleux. 2012. Discovering linguistic
patterns using sequence mining. Proceedings of
Springer LNCS, 13th International Conference on
Intelligent Text Processing and Computational Lin-
guistics - CICLing?2012, 1:154?165.
Guozhu Dong and Jian Pei. 2007. Sequence Data Min-
ing. Springer.
Carol Friedman. 1997. Towards a Comprehensive
Medical Language Processing System: Methods and
Issues. Proceedings of the AMIA Annual Fall Sym-
posium, 1997:595?599.
Sebastian K?ohler, Sandra C. Doelken, Christopher J.
Mungall, Sebastian Bauer, Helen V. Firth, Is-
abelle Bailleul-Forestier, Graeme C. M. Black,
Danielle L. Brown, Michael Brudno, Jennifer
Campbell, David R. FitzPatrick, Janan T. Eppig, An-
drew P. Jackson, Kathleen Freson, Marta Girdea,
Ingo Helbig, Jane A. Hurst, Johanna J?ahn, Laird G.
Jackson, Anne M. Kelly, David H. Ledbetter, Sa-
har Mansour, Christa L. Martin, Celia Moss, An-
drew Mumford, Willem H. Ouwehand, Soo-Mi
Park, Erin Rooney Riggs, Richard H. Scott, Sanjay
Sisodiya, Steven Van Vooren, Ronald J. Wapner, An-
drew O. M. Wilkie, Caroline F. Wright, Anneke T.
Vulto-van Silfhout, Nicole de Leeuw, Bert B. A.
de Vries, Nicole L. Washingthon, Cynthia L. Smith,
Monte Westerfield, Paul Schofield, Barbara J. Ruef,
Georgios V. Gkoutos, Melissa Haendel, Damian
Smedley, Suzanna E. Lewis and Peter N. Robinson.
2014. The Human Phenotype Ontology project:
linking molecular biology and disease through phe-
notype data. Nucleic Acids Research, 42:966?974.
Dimitrios Kokkinakis. 2006. Developing Resources
for Swedish Bio-Medical Text-Mining. Proceed-
ings of the 2nd International Symposium on Seman-
tic Mining in Biomedicine (SMBM)
Guergana K. Savova, James J. Masanz, Philip V.
Ogren, Jiaping Zheng, Sunghwan Sohn, Karin C.
Kipper-Schuler, Christopher G. Chute. 2010. Mayo
clinical Text Analysis and Knowledge Extraction
System (cTAKES): architecture, component evalua-
tion and applications. Journal of the American Med-
ical Informatics Association, 17:507?513.
Helmut Schmidt. 1994. Probabilistic Part-of-Speech
Tagging Using Decision Trees. Proceedings of In-
ternational Conference on New Methods in Lan-
guage Processing.
Brett R. South, Shuying Shen, Makoto Jones, Jennifer
Garvin, Matthew H. Samore, Wendy W. Chapman
and Adi V. Gundlapalli. 2009. Developing a man-
ually annotated clinical document corpus to identify
phenotypic information for inflammatory bowel dis-
ease. Summit on Translational Bioinformatics 2009
?
Ozlem Uzuner, Brett R. South, Shuying Shen, Scott L.
DuVall. 2011. 2010 i2b2/VA challenge on con-
cepts, assertions, and relations in clinical text. Jour-
nal of the American Medical Informatics Associa-
tion, 18:552?556.
Kavishwar B. Wagholikar, Manabu Torii, Siddartha R.
Jonnalagadda and Hongfang Liu. 2013. Pooling
annotated corpora for clinical concept extraction.
Journal of Biomedical Semantics, 4:3.
Alfred V. Aho and Jeffrey D. Ullman. 1972. The
Theory of Parsing, Translation and Compiling, vol-
ume 1. Prentice-Hall, Englewood Cliffs, NJ.
111
