Proceedings of ACL-08: HLT, Short Papers (Companion Volume), pages 5?8,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
Surprising parser actions and reading difficulty
Marisa Ferrara Boston, John Hale
Michigan State University
USA
{mferrara,jthale}@msu.edu
Reinhold Kliegl, Shravan Vasishth
Potsdam University
Germany
{kliegl,vasishth}@uni-potsdam.de
Abstract
An incremental dependency parser?s proba-
bility model is entered as a predictor in a
linear mixed-effects model of German read-
ers? eye-fixation durations. This dependency-
based predictor improves a baseline that takes
into account word length, n-gram probabil-
ity, and Cloze predictability that are typically
applied in models of human reading. This
improvement obtains even when the depen-
dency parser explores a tiny fraction of its
search space, as suggested by narrow-beam
accounts of human sentence processing such
as Garden Path theory.
1 Introduction
A growing body of work in cognitive science char-
acterizes human readers as some kind of probabilis-
tic parser (Jurafsky, 1996; Crocker and Brants, 2000;
Chater and Manning, 2006). This view gains sup-
port when specific aspects of these programs match
up well with measurable properties of humans en-
gaged in sentence comprehension.
One way to connect theory to data in this man-
ner uses a parser?s probability model to work out
the surprisal or log-probability of the next word.
Hale (2001) suggests this quantity as an index
of psycholinguistic difficulty. When the transi-
tion from previous word to current word is low-
probability, from the parser?s perspective, the sur-
prisal is high and the psycholinguistic claim is that
behavioral measures should register increased cog-
nitive difficulty. In other words, rare parser ac-
tions are cognitively costly. This basic notion has
proved remarkably applicable across sentence types
and languages (Park and Brew, 2006; Demberg and
Keller, 2007; Levy, 2008).
The present work uses the time spent looking at
a word during reading as an empirical measure of
sentence processing difficulty. From the theoretical
side, we calculate word-by-word surprisal pre-
dictions from a family of incremental depen-
dency parsers for German based on Nivre (2004);
these parsers differ only in the size k of the beam
used in the search for analyses of longer and longer
sentence-initial substrings. We find that predictions
derived even from very narrow-beamed parsers im-
prove a baseline eye-fixation duration model. The
fact that any member of this parser family derives
a useful predictor shows that at least some syn-
tactic properties are reflected in readers? eye fixa-
tion durations. From a cognitive perspective, the
utility of small k parsers for modeling comprehen-
sion difficulty lends credence to the view that the
human processor is a single-path analyzer (Frazier
and Fodor, 1978).
2 Parsing costs and theories of reading
difficulty
The length of time that a reader?s eyes spend fix-
ated on a particular word in a sentence is known
to be affected by a variety of word-level factors
such as length in characters, n-gram frequency and
empirical predictability (Ehrlich and Rayner, 1981;
Kliegl et al, 2004). This last factor is the one mea-
sured when human readers are asked to guess the
next word given a left-context string.
Any role for parser-derived syntactic factors
5
Figure 1: Dependency structure of a PSC sentence.
would have to go beyond these word-level influ-
ences. Our methodology imposes this requirement
by fitting a kind of regression known as a lin-
ear mixed-effects model to the total reading times
associated with each sentence-medial word in the
Potsdam Sentence Corpus (PSC) (Kliegl et al,
2006). The PSC records the eye-movements of 272
native speakers as they read 144 German sentences.
3 The Parsing Model
The parser?s outputs define a relation on
word pairs (Tesnie`re, 1959; Hays, 1964). The
structural description in Figure 1 is an example
output that depicts this dependency relation using
arcs. The word near the arrowhead is the dependent,
the other word its head (or governor).
These outputs are built up by monotonically
adding to an initially-empty set of dependency re-
lations as analysis proceeds from left to right. To
arrive at Figure 1 the Nivre parser passes through
a number of intermediate states that aggregate four
data structures, detailed below in Table 1.
? A stack of already-parsed unreduced words.
? An ordered input list of words.
h A function from dependent words to heads.
d A function from dependent words to arc types.
Table 1: Parser configuration.
The stack ? holds words that could eventually be
connected by new arcs, while ? lists unparsed words.
h and d are where the current set of dependency arcs
reside. There are only four possible transitions
from configuration to configuration. Left-Arc
and Right-Arc transitions create dependency re-
Error type Amount
Noun attachment 4.2%
Prepositional Phrase attachment 3.0%
Conjunction 1.9%
Adverb ambiguity 1.8%
Other 1.1%
Total error 12.1%
Table 2: Parser errors by category.
lations between the top elements in ? and ? , while
Shift and Reduce transitions manipulate ?.
When more than one transition is applicable, the
parser decides between them by consulting a proba-
bility model derived from the Negra and Tiger news-
paper corpora (Skut et al, 1997; Ko?nig and Lezius,
2003). This model is called Stack3 because it con-
siders only the parts-of-speech of the top three el-
ements of ? along with the top element of ? . On
the PSC this model achieves 87.9% precision and
79.5% recall for unlabeled dependencies. Most of
the attachments it gets wrong (Table 2) represent al-
ternative readings that would require semantic guid-
ance to rule out.
To compare ?serial? human sentence processing
models against ?parallel? models, our implemen-
tation does beam search in the space of Nivre-
configurations. The number of configurations main-
tained at any point is a changeable parameter k.
3.1 Surprisal
In Figure 1 the thermometer beneath the Ger-
man preposition ?in? graphically indicates a
high surprisal prediction derived from the depen-
dency parser. Greater cognitive effort, reflected in
reading time, should be observed on ?in? as com-
6
pared to ?alte.? The difficulty prediction at ?in? ul-
timately follows from the frequency of verbs tak-
ing prepositional complements that follow nominal
complements in the training data. Equation 1 ex-
presses the general theory: the surprisal of a word,
on a language model, is the logarithm of the pre-
fix probability eliminated in the transition from one
word to the next.
surprisal(n) = log2
(?n?1
?n
)
(1)
The prefix-probability ?n of an initial substring is
the total probability of all grammatical analyses that
derive w = w1...wn as a left-prefix (Equation 2).
?n =
?
d?D(G,wv)
Prob(d) (2)
In a complete parser, every member of D is in cor-
respondence with a state transition sequence. In the
beam-search approximation, only the top k config-
urations are retained from prefix to prefix, which
amounts to choosing a subset of D.
4 Study
The study addresses whether surprisal is a signif-
icant predictor of reading difficulty and, if it is,
whether the beam-size parameter k affects the use-
fulness of the calculated surprisal values in account-
ing for reading difficulty.
Using total reading time as a dependent measure,
we fit a baseline linear mixed-effects model (Equa-
tion 3) that takes into account word-level predictors
log frequency (lf), log bigram frequency (bi), word
length (len), and human predictability given the left
context (pr).
log (TRT ) = (3)
5.4? 0.02lf ? 0.01bi ? 0.59len?1 ? 0.02pr
All of the word-level predictors were statistically
significant at the ? level 0.05.
Beyond this baseline, we fitted ten other lin-
ear mixed-effects models. To the inventory of word-
level predictors, each of the ten regressions uniquely
added the surprisal predictions calculated from a
parser that retains at most k=1...9,100 analyses at
each prefix. We evaluated the change in relative
quality of fit due to surprisal with the Deviance In-
formation Criterion (DIC) discussed in Spiegelhal-
ter et al (2002). Whereas the more commonly ap-
plied Akaike Information Criterion (1973) requires
the number of estimated parameters to be deter-
mined exactly, the DIC facilitates the evaluation of
mixed-effects models by relaxing this requirement.
When comparing two models, if one of the models
has a lower DIC value, this means that the model fit
has improved.
4.1 Results and Discussion
Table 3 shows that the linear mixed-effects model of
German reading difficulty improves when surprisal
values from the dependency parser are used as pre-
dictors in addition to the word-level predictors. The
coefficients on the baseline predictors remained un-
changed (Equation 3) when any of the parser-based
predictors was added.
Table 3 also suggests the returns to be had in
accounting for reading time are greatest when the
beam is limited to a handful of parses. Indeed,
a parser that handles a few analyses at a time
(k=1,2,3) is just as valuable as one that spends far
greater memory resources (k=100). This observa-
tion is consistent with Brants and Crocker?s (2000)
observation that accuracy can be maintained even
when restricted to 1% of the memory required for
exhaustive parsing. The role of small k depen-
dency parsers in determining the quality of statisti-
cal fit challenges the assumption that cognitive func-
tions are global optima. Perhaps human parsing is
boundedly rational in the sense of the bound im-
posed by Stack3 (Simon, 1955).
5 Conclusion
This study demonstrates that surprisal calculated
with a dependency parser is a significant predictor of
reading times, an empirical measure of cognitive dif-
ficulty. Surprisal is a significant predictor even when
examined alongside the more commonly used pre-
dictors, word length, predictability, and n-gram fre-
quency. The viability of parsers that consider just a
small number of analyses at each increment is con-
sistent with conceptions of the human comprehender
that incorporate that restriction.
7
Model Coefficient Std. Error t value DIC
Baseline - - - 144511.1
k=1 0.033691 0.002285 15 143964.9
k=2 0.038573 0.002510 15 143946.2
k=3 0.037320 0.002693 14 143990.4
k=4 0.041035 0.002853 14 143975.7
k=5 0.048692 0.002953 16 143910.9
k=6 0.046580 0.003063 15 143951.6
k=7 0.045008 0.003118 14 143974.4
k=8 0.042039 0.003165 13 144006.4
k=9 0.040657 0.003225 13 144023.9
k=100 0.029467 0.003878 8 144125.4
Table 3: Coefficients and standard errors from the multiple regressions using different versions of surprisal (baseline
predictors? coefficients are not shown for space reasons). t values > 2 are statistically significant at ? = 0.05. The
table also shows DIC values for the baseline model (Equation 3) and the models with baseline predictors plus surprisal.
References
H. Akaike. 1973. Information theory and an extension
of the maximum likelihood principle. In B. N. Petrov
and F. Caski, editors, 2nd International Symposium on
Information Theory, pages 267?281, Budapest, Hun-
gary.
T. Brants and M. Crocker. 2000. Probabilistic pars-
ing and psychological plausibility. In Proceedings of
COLING 2000: The 18th International Conference on
Computational Linguistics.
N. Chater and C. Manning. 2006. Probabilistic mod-
els of language processing and acquisition. Trends in
Cognitive Sciences, 10:287?291.
M. W. Crocker and T. Brants. 2000. Wide-coverage
probabilistic sentence processing. Journal of Psy-
cholinguistic Research, 29(6):647?669.
V. Demberg and F. Keller. 2007. Data from eye-tracking
corpora as evidence for theories of syntactic process-
ing complexity. Manuscript, University of Edinburgh.
S. F. Ehrlich and K. Rayner. 1981. Contextual effects
on word perception and eye movements during read-
ing. Journal of Verbal Learning and Verbal Behavior,
20:641?655.
L. Frazier and J. D. Fodor. 1978. The sausage machine: a
new two-stage parsing model. Cognition, 6:291?325.
J. Hale. 2001. A probabilistic Earley parser as a psy-
cholinguistic model. In Proceedings of 2nd NAACL,
pages 1?8. Carnegie Mellon University.
D.G. Hays. 1964. Dependency theory: A formalism and
some observations. Language, 40:511?525.
D. Jurafsky. 1996. A probabilistic model of lexical and
syntactic access and disambiguation. Cognitive Sci-
ence, 20:137?194.
R. Kliegl, E. Grabner, M. Rolfs, and R. Engbert. 2004.
Length, frequency, and predictability effects of words
on eye movements in reading. European Journal of
Cognitive Psychology, 16:262?284.
R. Kliegl, A. Nuthmann, and R. Engbert. 2006. Track-
ing the mind during reading: The influence of past,
present, and future words on fixation durations. Jour-
nal of Experimental Psychology: General, 135:12?35.
E. Ko?nig and W. Lezius. 2003. The TIGER language -
a description language for syntax graphs, Formal def-
inition. Technical report, IMS, Universita?t Stuttgart,
Germany.
R. Levy. 2008. Expectation-based syntactic comprehen-
sion. Cognition, 106(3):1126?1177.
J. Nivre. 2004. Incrementality in deterministic depen-
dency parsing. In Incremental Parsing: Bringing En-
gineering and Cognition Together, Barcelona, Spain.
Association for Computational Linguistics.
J. Park and C. Brew. 2006. A finite-state model of hu-
man sentence processing. In Proceedings of the 21st
International Conference on Computational Linguis-
tics and the 44th Annual Meeting of the ACL, pages
49?56, Sydney, Australia.
H. Simon. 1955. A behavioral model of rational choice.
The Quarterly Journal of Economics, 69(1):99?118.
W. Skut, B. Krenn, T. Brants, and H. Uszkoreit. 1997.
An annotation scheme for free word order languages.
In Proceedings of the Fifth Conference on Applied
Natural Language Processing ANLP-97, Washington,
DC.
D. J. Spiegelhalter, N. G. Best, B. P. Carlin, and
A. van der Linde. 2002. Bayesian measures of model
complexity and fit (with discussion). Journal of the
Royal Statistical Society, 64(B):583?639.
L. Tesnie`re. 1959. Ele?ments de syntaxe structurale. Edi-
tions Klincksiek, Paris.
8
Proceedings of the 2010 Workshop on Cognitive Modeling and Computational Linguistics, ACL 2010, pages 36?44,
Uppsala, Sweden, 15 July 2010. c?2010 Association for Computational Linguistics
The role of memory in superiority violation gradience
Marisa Ferrara Boston
Cornell University
Ithaca, NY, USA
mfb74@cornell.edu
Abstract
This paper examines how grammatical and
memory constraints explain gradience in
superiority violation acceptability. A com-
putational model encoding both categories
of constraints is compared to experimental
evidence. By formalizing memory capac-
ity as beam-search in the parser, the model
predicts gradience evident in human data.
To predict attachment behavior, the parser
must be sensitive to the types of nominal
intervenors that occur between a wh-filler
and its head. The results suggest memory
is more informative for modeling violation
gradience patterns than grammatical con-
straints.
1 Introduction
Sentences that include twowh-words, as in Exam-
ple (1), are often considered difficult by English
speakers.
(1) *Diego asked what1 who2 read?
This superiority effect holds when a second wh-
word, who in this example, acts as a barrier to at-
tachment of the first wh-word and its verb (Chom-
sky, 1973).
The difficulty is ameliorated when the wh-
words are switched to which-N, or which-Noun,
form as in Examples (2) and (3) (Karttunen, 1977;
Pesetsky, 1987). This is confirmed by experimen-
tal evidence (Arnon et al, To appear; Hofmeister,
2007).
(2) ?Diego asked which book who read?
(3) ?Diego asked what which girl read?
Memory is often implicated as the source of this
gradience, though it is unclear which aspects of
memory best model experimental results. This
computational model encodes grammatical and
memory-based constraints proposed in the liter-
ature to account for the phenomenon. The re-
sults demonstrate that as memory resources are in-
creased, the parser can model the human pattern if
it is sensitive to the types of nominal intervenors.
This supports memory-based accounts of superi-
ority violation (SUV) gradience.
2 Explanations for SUV gradience
This section details grammatical and reductionist
explanations for SUV gradience, motivating the
encoding of various constraints in the computa-
tional model.
2.1 Grammatical explanations
Grammatical accounts of gradience rely on intrin-
sic discourse differences between phrases that al-
low for SUVs and those that do not. In this work,
which-N phrases are examples of the former, and
so-called bare wh-phrases (including who and
what) the latter1. Rizzi (1990) incorporates ideas
from Pesetsky?s D-Linking, or discourse-linking,
hypothesis (1987) into a grammatical account of
SUV gradience, Relativized Minimality. He ar-
gues that referential phrases like which-N refer
to a pre-established set in the discourse and are
not subject to the same constraints on attachment
as non-referential phrases, like what. Which book
delimits a set of possible discourse entities, books,
and is more restrictive than what, which could in-
stead delimit sets of books, cats, or abstract en-
tities. The Relativized Minimality hypothesis ac-
counts for SUV gradience on the basis of this cate-
gorical separation on wh-phrases in the discourse.
1Both bare phrases and which-N phrases could have the
appropriate discourse conditions to allow for superiority vio-
lations, and vice versa. However, to relate the theory?s pre-
dictions to the experiment modeled here, I use a categorical
split between which-N and bare wh-phrases.
36
2.2 Reductionist explanations
Many grammatical accounts, particularly those
that are grounded in cognitive factors, incorporate
some element of processing or memory in their ex-
planations (Phillips, Submitted). Reductionist ac-
counts are different; their proponents do not be-
lieve that superiority requires a grammatical ex-
planation. Rather, SUVs that appear ungrammat-
ical, such as Example (1), are the result of severe
processing difficulty alone.
These accounts attribute processing difficulty to
memory: severe memory resource limitations ac-
count for ungrammatical sentences in SUVs, and
increased memory resources allow for more ac-
ceptable sentences. This is the central idea be-
hind Hofmeister?s Memory Facilitation Hypothe-
sis (2007):
Memory Facilitation Hypothesis
Linguistic elements that encode more informa-
tion (lexical, semantic, syntactic, etc.) facili-
tate their own subsequent retrieval from memory
(Hofmeister, 2007, p.4)2.
This memory explanation is central to activation-
based memory hypotheses previously proposed
in the psycholinguistic literature, such as CC-
READER (Just and Carpenter, 1992), ACT-R
(Lewis and Vasishth, 2005), and 4CAPS (Just and
Varma, 2007). This work considers activation,
and manipulates memory resources by varying the
number of analyses the parser considers at each
parse step.
Table 1 lists memory factors that may contribute
to SUV gradience. They are sensitive to the mem-
ory resources available during syntactic parsing,
but account for memory differently. Below I de-
scribe these variations.
2.2.1 Distance and the DLT
Distance, as measured by the number of words
between, for example, a wh-word and its verb,
has been argued to affect sentence comprehen-
sion (Wanner and Maratsos, 1978; Rambow and
Joshi, 1994; Gibson, 1998). Experimental evi-
dence supports this claim, but there exist a num-
ber of anomalous results that resist explanation in
terms of distance alone (Gibson, 1998; Hawkins,
1999; Gibson, 2000). For example, it is not the
case that processing difficulty increases solely as
2Recent work by Hofmeister and colleagues attributes the
advantage to a decrease in memory interference rather than
retrieval facilitation (Submitted), but the spirit of the work
remains the same.
a function of the number of words in a sentence.
However, it is possible that SUV gradience could
be affected by this simple metric.
The Dependency Locality Theory (DLT) (Gib-
son, 2000) is a more linguistically-informed mea-
sure of distance. The DLT argues that an accurate
model of sentence processing difficulty is sensitive
to the number and discourse-status (given or new)
of nominal intervenors that occur across a particu-
lar distance. The DLT?s sensitivity to discourse-
newness integrates aspects of D-linking: which
book, for example, requires that books already be a
part of the discourse, though what does not (Gun-
del et al, 1993; Warren and Gibson, 2002). The
DLT has been demonstrated to model difficulty in
ways that simple distance alone can not (Grodner
and Gibson, 2005).
This study also considers a stronger version of
the DLT, Intervenors. Intervenors considers both
the number and part-of-speech (POS) of nominal
intervenors between a wh-word and its head. This
feature is sensitive to nuanced differences between
nominal intervenors, providing a more accurate
model of the Memory Facilitation Hypothesis.
2.2.2 Stack memory
Distance can also be measured in terms of the
parser?s internal resources. The computational
model described here incorporates a stack mem-
ory. Although stacks are not accurate models of
human memory (McElree, 2000), this architec-
tural property may provide insight into how mem-
ory affects SUV gradience.
2.2.3 Activation and interference
Sentence processing difficulty has been attributed
to the amount of time it takes to retrieve a word
from memory. Lewis & Vasishth (2005) find sup-
port for this argument by applying equations from
a general cognitive model, ACT-R (Adaptive Con-
trol of Thought-Rational) (Anderson, 2005), to a
sentence processsing model. Their calculation of
retrieval time, henceforth retrieval, is sensitive to a
word?s activation and its similarity-based interfer-
ence with other words in memory (Gordon et al,
2002; Van Dyke and McElree, 2006). Activation,
Interference, and the conjunction of the two in the
form of Retrieval, are considered in this work.
The grammatical and memory-based accounts
described above offer several explanations for
SUV gradience. They can be represented along a
continuum, where the type of information consid-
37
Hypothesis Sensitive to
Distance String distance between words.
DLT Number of nominal intervenors.
Intervenors POS of nominal intervenors.
Stack Memory Elements currently in parser memory.
Baseline Activation Amount structure is activated in memory.
Interference Amount of competition from similar words in memory.
Retrieval Retrieval time of word from memory.
Table 1: Memory-based sentence processing theories.
ered in memory varies from the simple (Distance)
to complex (Retrieval), as in (4).
(4) Distance < DLT < Intervenors < Stack Memory
< Activation < Interference < Retrieval
Despite this representation, in this work I con-
sider each as an independent theory. Together,
they form the hypothesis set in the model, se-
lected because they represent the major explana-
tions posited for gradience in SUVs and related
phenomena, like islands.
The computational model not only formalizes
the memory accounts, but also provides a frame-
work for memory-based factors that require a
computational model, such as retrieval. The re-
sults determine memory factors that best account
for SUV gradience patterns.
3 Methodology
The test set for SUV gradience is the experimental
results from Arnon et al (To appear). The experi-
ment tests gradience across four conditions, shown
in Examples (5)-(8).
(5) Pat wondered what who read. (bare.bare)
(6) Pat wondered what which student read.
(bare.which)
(7) Pat wondered which book who read. (which.bare)
(8) Pat wondered which book which student read.
(which.which)
The conditions substitute the wh-type of both wh-
fillers and wh-intervenors in the island context.
In Example (5) both the filler and intervenor are
bare (the bare.bare condition), whereas in Exam-
ple (8), both the filler and intervenor are which-Ns
(which.which). Examples (6) and (7) provide the
other possible configurations.
Arnon and colleagues find which.which to be
the fastest condition. Figure 1 depicts these re-
sults. The other conditions are more difficult,
Figure 1: Reading time is fastest in the
which.which condition (Arnon et al, To appear,
p.5).
at varying levels: the which.bare condition is
less difficult than the bare.which condition, and
both are less difficult than the bare.bare condi-
tion. These results roughly pattern with accept-
ability judgments discussed in syntactic literature
(Pesetsky, 1987).
Corpora for superiority processing results do
not exist. Further, few studies on SUVs incorpo-
rate the same structures, techniques, and experi-
mental conditions. Although Arnon et al consid-
ered 20 lexical variations, the unlexicalized parser
can not distinguish these variations. Therefore, the
parser is only evaluated on these four sentences;
however, they are taken to represent classes of
structures that generalize to all SUV gradience in
English.
3.1 The parsing model
The computational model is based on Nivre?s
(2004) dependency parsing algorithm. The al-
gorithm builds directed, word-to-word analyses
of test input following the Dependency Gram-
mar syntactic formalism (Tesnie`re, 1959; Hays,
1964). Figure 2 depicts the full dependency anal-
ysis of the which.which condition from Example
38
Figure 2: A dependency analysis of the
which.which condition.
(8), where heads point to their dependents via arcs.
The Nivre parser assembles dependency struc-
ture incrementally by passing through parser states
that aggregate four data structures, shown in Table
2. The stack ? holds parsed words that require fur-
ther analysis, and the list ? holds words yet to be
parsed. h and d encode the current list of depen-
dency relations.
? A stack of already-parsed unreduced words.
? An ordered input list of words.
h A function from dependent words to heads.
d A function from dependent words to arc types.
Table 2: Parser configuration.
The parser transitions from state to state via four
possible actions. Shift and Reducemanipulate
?. LeftArc and RightArc build dependencies
between ?1 (the element at the top of the stack)
and ?1 (the next input word); LeftArc makes
?1 the dependent, and RightArc makes ?1 the
head.
The parser determines actions by consulting a
probability model derived from the Brown Corpus
(Francis and Kucera, 1979). The corpus is con-
verted to dependencies via the Pennconverter tool
(Johansson and Nugues, 2007). The parser is then
simulated on these dependencies, providing a cor-
pus of parser states and subsequent actions that
form the basis of the training data. Because the
parser is POS-based, this corpus is manipulated in
two ways to sensitize it to the differences in the
experimental conditions. First, the corpus is given
finer-grained POS tags for each of the wh-words,
described in Table 3.
Secondly, which-N dependencies are encoded
as DPs (determiner phrases) and are headed by
the wh-phrase (Abney, 1987). This ensures the
parser differentiates a wh-word retrieval from a
simple noun retrieval, which is necessary for sev-
eral of the memory-based constraints. Other noun
phrases are headed by their nouns. The corpus is
Original POS Wh Example
WP WP-WHAT what
WP WP-WHO who
WDT WDT-WHICH which book
WDT WDT-WHAT what book
IN IN-WHETHER whether
WRB WRB how/why/when
Table 3: POS for wh fillers and intervenors.
Figure 3: The relevant attachment is between
which and read.
not switched to a fully DP analysis to preserve as
many of the original relationships as possible.
I extend the Nivre algorithm to allow for beam
search within the parser state space. This allows
the parser to consider different degrees of paral-
lelism k, and manipulate the amount of memory
allotted to incremental parse states. This manipu-
lation serves as a model of variation in an individ-
ual?s memory as a sentence is parsed.
3.2 Evaluation
To determine how well the accounts model the ex-
perimental data, I consider the likelihood of the
parser resolving the island-violating dependency
between wh-fillers and their verbs in the Arnon et
al. data. In terms of the dependency parser, the test
determines whether the parser creates a LeftArc
attachment in a state where which or what is ?1
and read is ?1 . The dependency structure associ-
ated with this parser state is depicted in Figure 3
for the which.which condition.
This evaluation is categorical rather than statis-
tical: SUV-processing is based on the decision to
form an attachment in a superiority-violating con-
text, given four experimental sentences. While fu-
ture work will incorporate more experiments for
robust statistical analysis, this work focuses on a
small subset that generalizes to the greater phe-
nomenon.
3.3 Encoding constraints
The parser determines actions on the basis of prob-
abilistic models, or features. In this work, I en-
39
code each of the grammatical and memory-based
explanations as its own feature. I normalize the
weights from the LIBLINEAR (Lin et al, 2008)
SVM classification tool to determine probabilities
for each parser action (LeftArc, RightArc,
Shift, Reduce) . The features are sensitive to
specific aspects of the current parser state, allow-
ing an examination of whether the features sug-
gest the superiority violating LeftArc action in
the context depicted in Figure 3. The prediction is
that attachment will be easiest in the which.which
condition and impossible in the other conditions
when memory resources are limited (k=1), as in
Table 4.
Condition b.b b.w w.b w.w
Attachment N N N Y
Table 4: LeftArc attachments given Arnon et al
(To appear) results. Y = Yes, N=No.
Table 5 depicts the full list of grammatical and
memory-based features considered in this study,
which are detailed below.
3.3.1 Grammatical constraint
In Relativized Minimality, referential noun
phrases override superiority violations, whereas
non-referential noun phrases do not. This con-
straint is included as a probabilistic feature of
the parser, RELMIN, specified in Table 5. The
condition holds if a non-referential NP (what) is
in ?1 (RELMIN=Yes). But the violation condition
does not hold (RELMIN=No) if a non-referential
NP (which) is in ?1 . The feature categorically
separates which-N and bare wh-phrases to capture
the Relativized Minimality predictions for these
experimental sentences. The probabilistic feature
also adds a grammatical gradience component to
the model, which is not proposed by the original
hypothesis.
3.3.2 Memory constraints
The parser encodes each of the memory accounts
provided in Table 1 as probabilistic features. DIS-
TANCE, the simplest feature, determines parser ac-
tions on the basis of how far apart ?1 and ?1 are
in the string.
DLT and INTERVENORS require parser sen-
sitivity to the nominal intervenors between ?1
and ?1 according to Gibson?s DLT specification
(2000). Table 6 provides a list of the nominal inter-
venors considered. Gibson?s hierarchy is extended
to include nominal wh-words to more accurately
model the experimental conditions.
Intervenor POS Example
NN book
NNS books
PRP they
NNP Pat
NNPS Americans
WP-WHAT what
WP-WHO who
WDT-WHICH which book
WDT-WHAT what book
Table 6: POS for nominal intervenors.
The sequence of STACKNEXT features are sen-
sitive to the parser?s memory, in the form of the
POS of elements at varying depths of the stack.
These features are found to have high overall ac-
curacy in the Nivre parser (Nivre, 2004) and in hu-
man sentence processing modeling (Boston et al,
2008).
ACTIVATION, INTERFERENCE, and RE-
TRIEVAL predictions are based on the sequence
of Lewis & Vasisth (2005) calculations provided
in Equations 1-4. These equations require some
notion of duration, which is calculated as a func-
tion of parser actions and word retrieval times.
Table 7 describes this calculation, motivated by
the production rule time in Lewis & Vasisth?s
ACT-R model.
Transition Time
LEFT 50 ms + 50 ms + Retrieval Time
RIGHT 50 ms + 50 ms + Retrieval Time
SHIFT 50ms
REDUCE 0ms
Table 7: How time is determined in the parser.
Because only words at the top of the stack can
be retrieved, the following will be described for
?1 . Retrieval time for ?1 is based on its activation
A, calculated as in Equation 1.
Ai = Bi +
?
j
W jSji (1)
Total activation is the sum of two quantities, the
word?s baseline activation Bi and similarity-based
interference for that word, calculated in the sec-
ond addend of the equation. The baseline activa-
tion, provided in Equation 2, increases with more
40
Feature Feature Type Includes
Grammar
RELMIN Yes/No ?1 wh?word :: intervenorswh?word(?1 ...?1 )
Memory
DISTANCE String Position ?1 ? ?1
DLT Count intervenorsnom(?1 ...?1 )
INTERVENORS POS intervenorsnom(?1 ...?1 )
STACK1NEXT POS ?1 :: ?1
STACK2NEXT POS ?1 :: ?2 :: ?1
STACK3NEXT POS ?1 :: ?2 :: ?3 :: ?1
ACTIVATION Value baselineActivation(?1 )
INTERFERENCE Value interference(?1 )
RETRIEVAL Time (ms.) retrievalTime(?1 )
Table 5: Feature specification. :: indicates concatenation.
recent retrievals at time tj . This implementation
follows standard ACT-R practice in setting the de-
cay rate d to 0.5 (Lewis and Vasishth, 2005; An-
derson, 2005).
Bi = ln
?
?
n?
j=1
tj
?d
?
? (2)
?1 ?s activation can decrease if competitors, or
other words with similar grammatical categories,
have already been parsed. In Equation (1), W j de-
notes weights associated with the retrieval cues j
that are shared with these competitors, and Sji
symbolizes the strengths of association between
cues j and the retrieved item i (?1 ). For this
model, weights are set to 1 because there is only
one retrieval cue j in operation: the POS. The
strength of association Sji is computed as in Equa-
tion 3.
Sji = Smax ? ln(fanj ) (3)
The fan, fanj , is the number of words that have
the same grammatical category as cue j, the POS.
The maximum degree of association between sim-
ilar items in memory is Smax which is set to 1.5
following Lewis & Vasishth.
To get the retrieval time, in milliseconds, of ?1 ,
the activation value calculated in Equation 1 is in-
serted in Equation 4. The implementation follows
Lewis & Vasishth in setting F to 0.14.
T i = Fe?Ai (4)
The time T i is the quantity the parser is sensi-
tive to in determining attachments based on the
RETRIEVAL feature. Because it is possible that
SUVs are better modeled by only part of the re-
trieval equation, such as baseline activation or in-
terference, the implementation also considers AC-
TIVATION and INTERFERENCE features. The fea-
tures are sensitive to the quantities in the addends
in Equation 1, Bi and
?
j
W jSji respectively.
4 Results
The results focus on whether the parser chooses
a LeftArc attachment when it is in the config-
uration depicted in Figure 3 given the grammati-
cal and memory constraints listed in Table 5. Ta-
ble 8 depicts the outcome, where Y signifies a
LeftArc attachment is preferred and N that it is
not.
Only one feature correctly patterns with the ex-
perimental evidence: INTERVENORS. It allows a
LeftArc in the which.which condition, and dis-
allows the arc in other conditions. The INTER-
VENORS feature also patterns with the experimen-
tal evidence as more memory is added. Table 9 de-
picts the LeftArc attachment for increasing lev-
els of k with this feature. At k=1, the parser only
chooses the attachment for the which.which con-
dition. At k=2, the parser chooses the attachment
for both which.which and which.bare. At k=3, it
chooses the attachment for all conditions. This
mimics the decreases in difficulty evident in Fig-
ure 1, and provides support for reductionist theo-
ries: if memory is restricted (k=1), only the easi-
est attachment is allowed. As memory increases,
more attachments are possible.
INTERVENORS is sensitive to the nominal in-
41
Condition b.b b.w w.b w.w
Experiment N N N Y
Grammar
RELMIN=YES N N N N
RELMIN=NO N N N N
Memory
DISTANCE N N N N
DLT N N N N
INTERVENORS N N N Y
STACK1NEXT N N N N
STACK2NEXT Y N Y N
STACK3NEXT Y Y Y Y
ACTIVATION N N N N
INTERFERENCE Y N N N
RETRIEVAL Y N N N
Table 8: LeftArc attachments for the experi-
mental data.
Condition b.b b.w w.b w.w
INTERVENORS K=1 N N N Y
INTERVENORS K=2 N N Y Y
INTERVENORS K=3 Y Y Y Y
Table 9: INTERVENORS allows more attachments
as k increases.
tervenors between which and read. RETRIEVAL,
INTERFERENCE, and particularly DLT, should
also be sensitive to these intervenors. Despite their
similarity, none of these features are able to model
the attachment behavior in the experimental data.
The STACK3NEXT feature differs from the
other features in that it allows the LeftArc at-
tachment to occur in any of the conditions. Al-
though this does not match the interpretation of
the experimental results followed in this paper, it
leaves open the possibility that the feature could
model the data according to a different measure of
parsing difficulty, such as surprisal (Hale, 2001).
The RELMIN constraint is not able to model the
experimental results for gradience.
5 Discussion
The results demonstrate that modeling the exper-
imental data for SUV gradience requires a parser
that can vary memory resources as well as be sen-
sitive to the types of the nominal intervenors cur-
rently in memory. The gradience is modeled by
increasing memory resources, in the form of in-
creases in the beam-width. This demonstrates the
usefulness of varying both the types and amounts
of memory resources available in a computational
model of human sentence processing.
The positive results from the INTERVENORS
feature confirms the discourse accessibility hierar-
chy encoded in the DLT (Gundel et al, 1993; War-
ren and Gibson, 2002), but only when wh-words
are included as nominal intervenors. The results
also suggest that it is the type, and not just the
number of intervenors as suggested by the DLT,
that is important.
Further, the INTERVENORS feature does not
pattern with the DLT hypothesis. DLT assumes
that increasing the number of nominal inter-
venors causes sentence processing difficulty (Gib-
son, 2000; Warren and Gibson, 2002). Here, the
number of intervenors is increased, but sentence
processing is relatively easier. This effect is ex-
plained by the intrinsic difference between the
DLT and INTERVENORS features: INTERVENORS
provides more information to the parser, in the
form of the POS of all intervenors. This indicates
that certain intervenors help, rather than hinder,
the retrieval process.
The negative results demonstrate that other rep-
resentations of memory do not model SUV gra-
dience. If we consider this along the continuum
from (4), those features that take into account less
information than INTERVENORS (DISTANCE and
DLT) are too restrictive. Of those features that
are more complex than INTERVENORS, many are
too permissive, or permit the wrong attachments.
This pattern is also visible in the STACKNEXT
features: STACK1NEXT is too restrictive, while
STACK3NEXT too permissive. STACK2NEXT un-
fortunately permits the wrong attachments. This
pattern in the continuum indicates that an interme-
diate amount of memory information is required
to adequately model these results.
INTERFERENCE, which also considers competi-
tors in the intervening string, would seem likely
to pattern with the INTERVENORS results. In
fact, similarity-based interference and retrieval
have previously been argued to account for these
gradience patterns (Hofmeister et al, Submitted).
However, the only words considered as competi-
tors with which for both features in this model
are other wh-words. For the which.which con-
dition, for example, INTERFERENCE would only
consider the second which a competitor. IN-
TERVENORS, on the other hand, considers book,
42
which, and student as possible intervenors. This
suggests that the INTERFERENCE measure in re-
trieval would be more accurate if it considered
more competitors, a consideration for future work.
Hofmeister (2007) suggests that it is not a sin-
gle memory factor, but a number of factors, that
contribute to SUV gradience. Some features, such
as INTERFERENCE or DLT, may be more accurate
when they are considered in addition to other fea-
tures. It is also likely that probabilistic models that
include many features will be more robust than
single-feature models, particularly when tested on
similar phenomena, like islands. I leave these pos-
sibilities to future work.
Although the variable beam-width INTER-
VENORS feature patterns well with the Arnon et
al. results, it does not capture the reading time dif-
ference between the bare.bare and the bare.which
conditions; both are unavailable at k=2 and avail-
able at k=3. Although this may indicate a prob-
lem with the feature itself, it is also possible that a
more gradient evaluation technique is needed. As
suggested in Section 4, determining accuracy on
the basis of attachment alone may be insufficient
to correctly model the full experimental evidence
in terms of reading times. This is an empirical
question that can be tested with this computational
model. In future work, I consider the role of parser
difficulty, via linking hypotheses such as surprisal,
in modeling the experimental data.
The interpretation of Relativized Minimality
used here as a grammatical constraint could not
derive the experimental results. LeftArc is not
preferred when the parser is in a SUV context
(RELMIN=Yes)?an expected result as attachments
should not occur in SUV contexts. However, the
which.which, which.bare, and the bare.which con-
ditions are not violations because they include
non-referential NPs. Even with the RELMIN=NO
feature, the parser does not select LeftArc at-
tachments, suggesting grammatical gradience is
not useful in modeling the SUV gradience results.
This model does not attempt to capture exper-
imental evidence that SUVs and similar phenom-
ena, like islands, are better modeled by grammati-
cal constraints (Phillips, 2006; Sprouse et al, Sub-
mitted). Not only does this work only focus on one
kind of grammatical constraint for SUV gradience,
but the results reported here do not reveal whether
the intervention effect itself is better modeled by
grammatical or reductionist factors. Rather, the
results demonstrate that the gradience in the inter-
vention effect is better modeled by memory than
by the gradient grammatical feature. Future work
with this computational model will allow for an
examination of those memory factors and gram-
matical factors most useful in exploring the source
of the intervention effect itself.
6 Conclusion
This study considers grammatical and memory-
based explanations for SUV gradience in a hu-
man sentence processing model. The results sug-
gest that gradience is best modeled by a parser
that can vary memory resources while being sen-
sitive to the types of nominal intervenors that have
been parsed. Grammatical and other memory con-
straints do not determine correct attachments in
the SUV environment. The results argue for a the-
ory of language that accounts for SUV gradience
in terms of specific memory factors.
Acknowledgments
I am grateful to Sam Epstein, John T. Hale, Philip
Hofmeister, Rick Lewis, Colin Phillips, students
of the University of Michigan Rational Behavior
and Minimalist Inquiry course, and two anony-
mous reviewers for helpful comments and sugges-
tions on this work.
References
S. Abney. 1987. The English noun phrase in its sen-
tential aspect. Ph.D. thesis, MIT, Cambridge, MA.
J. R. Anderson. 2005. Human symbol manipulation
within an integrated cognitive architecture. Cogni-
tive Science, 29:313?341.
I. Arnon, N. Snider, P. Hofmeister, T. F. Jaeger, and
I. Sag. To appear. Cross-linguistic variation in
a processing account: The case of multiple wh-
questions. In Proceedings of Berkeley Linguistics
Society, volume 32.
M. F. Boston, J. T. Hale, R. Kliegl, and S. Vasishth.
2008. Surprising parser actions and reading diffi-
culty. In Proceedings of ACL-08: HLT Short Papers,
pages 5?8.
N. Chomsky. 1973. Conditions on transformations.
In Stephen Anderson and Paul Kiparsky, editors, A
Festschrift for Morris Halle, pages 232?286. Holt,
Reinhart and Winston, New York.
W. N. Francis and H. Kucera. 1979. Brown corpus
manual. Technical report, Department of Linguis-
tics, Brown University, Providence, RI.
43
E. Gibson. 1998. Linguistic complexity: locality of
syntactic dependencies. Cognition, 68:1?76.
E. Gibson. 2000. Dependency locality theory: A
distance-based theory of linguistic complexity. In
A. Marantz, Y. Miyashita, and W. O?Neil, editors,
Image, language, brain: Papers from the First Mind
Articulation Symposium. MIT Press, Cambridge,
MA.
P. C. Gordon, R. Hendrick, and W. H. Levine. 2002.
Memory-load interference in syntactic processing.
Psychological Science, 13(5):425?430.
D. J. Grodner and E. A. F. Gibson. 2005. Conse-
quences of the serial nature of linguistic input for
sentential complexity. Cognitive Science, 29:261?
91.
J. K. Gundel, N. Hedberg, and R. Zacharski. 1993.
Cognitive status and the form of referring expres-
sions in discourse. Language, 69:274?307.
J. T. Hale. 2001. A probabilistic earley parser as a
psycholinguistic model. In Proceedings of NAACL
2001, pages 1?8.
J. A. Hawkins. 1999. Processing complexity and filler-
gap dependencies across grammars. Language,
75(2):244?285.
D. G. Hays. 1964. Dependency Theory: A formalism
and some observations. Language, 40:511?525.
P. Hofmeister, I. Arnon, T. F. Jaeger, I. A. Sag, and
N. Snider. Submitted. The source ambiguity prob-
lem: distinguishing the effects of grammar and pro-
cessing on acceptability judgments. Language and
Cognitive Processes.
P. Hofmeister. 2007. Retrievability and gradience in
filler-gap dependencies. In Proceedings of the 43rd
Regional Meeting of the Chicago Linguistics Soci-
ety, Chicago. University of Chicago Press.
R. Johansson and P. Nugues. 2007. Extended
constituent-to-dependency conversion for English.
In Proceedings of NODALIDA 2007, Tartu, Estonia.
M. A. Just and P.A. Carpenter. 1992. A capacity theory
of comprehension: Individual differences in work-
ing memory. Psychological Review, 98:122?149.
M. A. Just and S. Varma. 2007. The organization
of thinking: What functional brain imaging reveals
about the neuroarchitecture of complex cognition.
Cognitive, Affective, and Behavioral Neuroscience,
7(3):153?191.
L. Karttunen. 1977. Syntax and semantics of ques-
tions. Linguistics and Philosophy, 1:3?44.
R. Lewis and S. Vasishth. 2005. An activation-based
model of sentence processing as skilled memory re-
trieval. Cognitive Science, 29:1?45.
C.-J. Lin, R. C. Weng, and S. S. Keerthi. 2008. Trust
region newton method for large-scale regularized lo-
gistic regression. Journal of Machine Learning Re-
search, 9.
B. McElree. 2000. Sentence comprehension is me-
diated by content-addressable memory structures.
Journal of Psycholinguistic Research, 29(2):111?
123.
J. Nivre. 2004. Incrementality in deterministic depen-
dency parsing. In Proceedings of the Workshop on
Incremental Parsing (ACL), pages 50?57.
D. Pesetsky. 1987. Wh-in-situ: movement and unse-
lective binding. In Eric Reuland and A. ter Meulen,
editors, The representation of (In)Definiteness,
pages 98?129. MIT Press, Cambridge, MA.
C. Phillips. 2006. The real-time status of island phe-
nomena. Language, 82:795?823.
C. Phillips. Submitted. Some arguments and non-
arguments for reductionist accounts of syntactic
phenomena. Language and Cognitive Processes.
O. Rambow and A. K. Joshi. 1994. A processing
model for free word-order languages. In Charles
Clifton, Jr., Lyn Frazier, and Keith Rayner, editors,
Perspectives on sentence processing, pages 267?
301. Erlbaum, Hillsdale, NJ.
L. Rizzi. 1990. Relativized Minimality. MIT Press.
J. Sprouse, M. Wagers, and C. Phillips. Sub-
mitted. A test of the relation between work-
ing memory capacity and syntactic island effects.
http://ling.auf.net/lingBuzz/001042.
L. Tesnie`re. 1959. E?le?ments de syntaxe structurale.
Editions Klincksiek.
J. A. Van Dyke and B. McElree. 2006. Retrieval in-
terference in sentence comprehension. Journal of
Memory and Language, 55:157?166.
E. Wanner and M. Maratsos. 1978. An ATN approach
in comprehension. In Morris Halle, Joan Bresnan,
and George Miller, editors, Linguistic theory and
psychological reality, pages 119?161. MIT Press,
Cambridge, MA.
T. Warren and Edward Gibson. 2002. The influence of
referential processing on sentence complexity. Cog-
nition, 85:79?112.
44
