2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 407?416,
Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational Linguistics
A Hierarchical Dirichlet Process Model for Joint Part-of-Speech and
Morphology Induction
Kairit Sirts
Institute of Cybernetics at
Tallinn University of Technology
kairit.sirts@phon.ioc.ee
Tanel Aluma?e
Institute of Cybernetics at
Tallinn University of Technology
tanel.alumae@phon.ioc.ee
Abstract
In this paper we present a fully unsupervised
nonparametric Bayesian model that jointly in-
duces POS tags and morphological segmen-
tations. The model is essentially an infi-
nite HMM that infers the number of states
from data. Incorporating segmentation into
the same model provides the morphological
features to the system and eliminates the need
to find them during preprocessing step. We
show that learning both tasks jointly actually
leads to better results than learning either task
with gold standard data from the other task
provided. The evaluation on multilingual data
shows that the model produces state-of-the-art
results on POS induction.
1 Introduction
Nonparametric Bayesian modeling has recently be-
come very popular in natural language processing
(NLP), mostly because of its ability to provide pri-
ors that are especially suitable for tasks in NLP (Teh,
2006). Using nonparametric priors enables to treat
the size of the model as a random variable with its
value to be induced during inference which makes
its use very appealing in models that need to decide
upon the number of states.
The task of unsupervised parts-of-speech (POS)
tagging has been under research in numerous pa-
pers, for overview see (Christodoulopoulos et al,
2010). Most of the POS induction models use the
structure of hidden Markov model (HMM) (Rabiner,
1989) that requires the knowledge about the num-
ber of hidden states (corresponding to the number
of tags) in advance. According to our consider-
ations, supplying this information is not desirable
for two opposing reasons: 1) it injects into the sys-
tem a piece of knowledge which in a truly unsu-
pervised setting would be unavailable; and 2) the
number of POS tags used is somewhat arbitrary any-
way because there is no common consensus of what
should be the true number of tags in each language
and therefore it seems unreasonable to constrain the
model with such a number instead of learning it from
the data.
Unsupervised morphology learning is another
popular task that has been extensively studied by
many authors. Here we are interested in learning
concatenative morphology of words, meaning the
substrings of the word corresponding to morphemes
that, when concatenated, will give the lexical repre-
sentation of the word type. For the rest of the paper
we will refer to this task as (morphological) segmen-
tation.
Several unsupervised POS induction systems
make use of morphological features (Blunsom and
Cohn, 2011; Lee et al, 2010; Berg-Kirkpatrick et
al., 2010; Clark, 2003; Christodoulopoulos et al,
2011) and this approach has been empirically proved
to be helpful (Christodoulopoulos et al, 2010). In a
similar fashion one could think that knowing POS
tags could be useful for learning morphological seg-
mentations and in this paper we will study this hy-
pothesis.
In this paper we will build a model that combines
POS induction and morphological segmentation into
one learning problem. We will show that the unsu-
pervised learning of both of these tasks in the same
407
model will lead to better results than learning both
tasks separately with the gold standard data of the
other task provided. We will also demonstrate that
our model produces state-of-the-art results on POS
tagging. As opposed to the compared methods, our
model also induces the number of tags from data.
In the following, section 2 gives the overview
of the Dirichlet Processes, section 3 describes the
model setup followed by the description of infer-
ence procedures in section 4, experimental results
are presented in section 5, section 6 summarizes the
previous work and last section concludes the paper.
2 Background
2.1 Dirichlet Process
Let H be a distribution called base measure. Dirich-
let process (DP) (Ferguson, 1973) is a probability
distribution over distributions whose support is the
subset of the support of H:
G ? DP (?,H), (1)
where ? is the concentration parameter that controls
the number of values instantiated by G.
DP has no analytic form and therefore other rep-
resentations must be developed for sampling. In the
next section we describe Chinese Restaurant Process
that enables to obtain samples from DP.
2.2 Chinese Restaurant Process
Chinese Restaurant Process (CRP) (Aldous, 1985)
enables to calculate the marginal probabilities of the
elements conditioned on the values given to all pre-
viously seen items and integrating over possible DP
prior values.
Imagine an infinitely big Chinese restaurant with
infinitely many tables with each table having ca-
pacity for infinitely many customers. In the begin-
ning the restaurant is empty. Then customers, corre-
sponding to data points, start entering one after an-
other. The first customer chooses an empty table to
sit at. Next customers choose a new table with prob-
ability proportional to the concentration parameter
? or sit into one of the already occupied tables with
probability proportional to the number of customers
already sitting there. Whenever a customer chooses
an empty table, he will also pick a dish from H to
be served on that table. The predictive probability
distribution over dishes for the i-th customer is:
P (xi = ?k|x?i, ?,H) =
n?k + ?
i? 1 + ?pH(?k), (2)
where x?i is the seating arrangement of customers
excluding the i-th customer and n?k is the number of
customers eating dish ?k and pH(?) is the probability
according to H .
2.3 Hierarchical Dirichlet Process
The notion of hierarchical Dirichlet Process (HDP)
(Teh et al, 2006) can be derived by letting the base
measure itself to be a draw from a DP:
G0|?0, H ? DP (?0, H) (3)
Gj |?,G0 ? DP (?,G0) j = 1 ? ? ? J (4)
Under HDP, CRP becomes Chinese Restaurant
Franchise (Teh et al, 2006) with several restaurants
sharing the same franchise-wide menu G0. When a
customer sits at an empty table in one of the Gj-th
restaurants, the event of a new customer entering the
restaurant G0 will be triggered. Analogously, when
a table becomes empty in one of the Gj-th restau-
rants, it causes one of the customers leaving from
restaurant G0.
3 Model
We consider the problem of unsupervised learning
of POS tags and morphological segmentations in a
joint model. Similarly to some recent successful at-
tempts (Lee et al, 2010; Christodoulopoulos et al,
2011; Blunsom and Cohn, 2011), our model is type-
based, arranging word types into hard clusters. Un-
like many recent POS tagging models, our model
does not assume any prior information about the
number of POS tags. We will define the model as
a generative sequence model using the HMM struc-
ture. Graphical depiction of the model is given in
Figure 1.
3.1 Generative story
We assume the presence of a fixed length vocabu-
lary W . The process starts with generating the lex-
icon that stores for each word type its POS tag and
morphological segmentation.
408
? Draw a unigram tag distribution from the re-
spective DP;
? Draw a segment distribution from the respec-
tive DP;
? For each tag, draw a tag-specific segment distri-
bution from HDP with the segment distribution
as base measure;
? For each word type, draw a tag from the uni-
gram tag distribution;
? For each word type, draw a segmentation from
the respective tag-specific segment distribution.
Next we proceed to generate the HMM parame-
ters:
? For each tag, draw a bigram distribution from
HDP with the unigram tag distribution as base
measure;
? For each tag bigram, draw a trigram distribu-
tion from HDP with the respective bigram dis-
tribution as base measure;
? For each tag, draw a Dirichlet concentration pa-
rameter from Gamma distribution and an emis-
sion distribution from the symmetric Dirichlet.
Finally the standard HMM procedure for generat-
ing the data sequence follows. At each time step:
? Generate the next tag conditioned on the last
two tags from the respective trigram HDP;
? Generate the word from the respective emission
distribution conditioned on the tag just drawn;
? Generate the segmentation of the word deter-
ministically by looking it up from the lexicon.
3.2 Model setup
The trigram transition hierarchy is a HDP:
GU ? DP (?U , H) (5)
GBj ? DP (?B, GU ) j = 1 ? ? ?? (6)
GTjk ? DP (?T , GBj ) j, k = 1 ? ? ??, (7)
where GU , GB and GT denote the unigram, bigram
and trigram context DP-s respectively, ?-s are the
w1 w2 w3
s1 s2 s3
t1 t2 t3 Gjk Gj GU
Ej j
Gj GS S
...
...
...
B
j=1...
T
H
TS
k=1...
j=1...
Figure 1: Plate diagram representation of the model. ti-
s, wi-s and si-s denote the tags, words and segmentations
respectively. G-s are various DP-s in the model, Ej-s and
?j-s are the tag-specific emission distributions and their
respective Dirichlet prior parameters. H is Gamma base
distribution. S is the base distribution over segments.
Coupled DP concetrations parameters have been omitted
for clarity.
respective concentration parameters coupled for DP-
s of the same hierarchy level. Emission parame-
ters are drawn from multinomials with symmetric
Dirichlet priors:
Ej |?j , H ?
?
Mult(?)Dir(?j)d? j = 1 ? ? ??,
(8)
where each emission distribution has its own Dirich-
let concentration parameter ?j drawn from H .
Morphological segments are modelled with an-
other HDP where the groups are formed on the basis
of tags:
GS ? DP (?S , S) (9)
GTSj ? DP (?TS , GS) j = 1 ? ? ??, (10)
where GTSj are the tag-specific segment DP-s and
GS is their common base distribution with S as base
measure over all possible strings. S consists of two
components: a geometric distribution over the seg-
ment lengths and collapsed Dirichlet-multinomial
over character unigrams.
4 Inference
We implemented Gibbs sampler to draw new val-
ues for tags and Metropolis-Hastings sampler for re-
sampling segmentations. We use a type-based col-
409
lapsed sampler that draws the tagging and segmen-
tation values for all tokens of a word type in one step
and integrates out the random DP measures by using
the CRP representation. The whole procedure alter-
nates between three sampling steps:
? Sampling new tag value for each word type;
? Resampling the segmentation for each type;
? Sampling new values for all parameters.
4.1 Tag sampling
The tags will be sampled from the posterior:
P (T|W,S,w,?), (11)
where W is the set of words in the vocabulary, T
and S are tags and segmentations assigned to each
word type, w is the actual word sequence, and ? de-
notes the set of all parameters relevant for tag sam-
pling. For brevity, we will omit ? notation in the
formulas below. For a single word type, this poste-
rior can be factored as follows:
P (Ti = t|T?i,S,W,w) ?
P (Si|Ti = t,T?i,S?i)?
P (Wi|Ti = t,T?i,W?i)?
P (w|Ti = t,T?i,W),
(12)
where ?i in the subscript denotes the observations
with the i-th word type excluded.
The first term is the segmentation likelihood and
can be computed according to the CRP formula:
P (Si|Ti = t,T?i,S?i) =
|Wi|?
j=1
?
s?Si
(
n?Sits
n?Sit? + ?
+ ?(m
?Si
s + ?P0(s))
(n?Sit? + ?)(m?Si? + ?)
)
,
(13)
where the outer product is over the word type count,
nts and ms denote the number of customers ?eat-
ing? the segment s under tag t and the number of
tables ?serving? the segment s across all restaurants
respectively, dot represents the marginal counts and
? and ? are the concentration parameters of the re-
spective DP-s. ?Si in upper index means that the
segments belonging to the segmentation of the i-th
word type and not calculated into likelihood term yet
have been excluded.
The word type likelihood is calculated accord-
ing to the collapsed Dirichlet-multinomial likeli-
hood formula:
P (Wi|Ti = t,T?i,W?i,w) =
|Wi|?1?
j=0
ntWi + j + ?
nt? + j + ?N
(14)
where ntWi is the number of times the word Wi has
been tagged with tag t so far, nt? is the number of
total word tokens tagged with the tag t and N is the
total number of words in the vocabulary.
The last factor is the word sequence likelihood
and covers the transition probabilities. Relevant tri-
grams are those three containing the current word,
and in all contexts where the word token appears in:
P (w|Ti = t,T?i,W) ?
?
c?CWi
P (t|t(c?2), t(c?1))?
P (t(c+1)|t(c?1), t)?
P (t(c+2)|t, t(c+1))
(15)
where CWi denotes all the contexts where the word
type Wi appears in, t(c) are the tags assigned to the
context words. All these terms can be calculated
with CRP formulas.
4.2 Segmentation sampling
We sample the whole segmentation of a word type
as a block with forward-filtering backward-sampling
scheme as described in (Mochihashi et al, 2009).
As we cannot sample from the exact marginal
conditional distribution due to the dependen-
cies between segments induced by the CRP, we
use the Metropolis-Hastings sampler that draws
a new proposal with forward-filtering backward-
sampling scheme and accepts it with probability
min(1, P (Sprop)P (Sold) ), where Sprop is the proposed seg-
mentation and Sold is the current segmentation of a
word type. The acceptance rate during experiments
varied between 94-98%.
For each word type, we build a forward filter-
ing table where we maintain the forward variables
?[t][k] that present the probabilities of the last k
characters of a t-character string constituting a seg-
ment. Define:
?[0][0] = 1 (16)
410
?[t][0] = 0, t > 0 (17)
Then the forward variables can be computed recur-
sively by using dynamic programming algorithm:
?[t][k] = p(ctt?k)
t?k?
j=0
?[t? k][j], t = 1 ? ? ?L,
(18)
where cnm denotes the characters cm ? ? ? cn of a string
c and L is the length of the word.
Sampling starts from the end of the word because
it is known for certain that the word end coincides
with the end of a segment. We sample the begin-
ning position k of the last segment from the forward
variables ?[t][k], where t is the length of the word.
Then we set t = t ? k and continue to sample the
start of the previous to the last segment. This pro-
cess continues until t = 0. The segment probabili-
ties, conditioned on the tag currently assigned to the
word type, will be calculated according to the seg-
mentation likelihood formula (13).
4.3 Hyperparameter sampling
All DP and Dirichlet concentration parameters are
given vague Gamma(10, 0.1) priors and new values
are sampled by using the auxiliary variable sampling
scheme described in (Escobar and West, 1995) and
the extended version for HDP-s described in (Teh
et al, 2006). The segment length control parame-
ter is given uniform Beta prior and its new values
are sampled from the posterior which is also a Beta
distribution.
5 Results
5.1 Evaluation
We test the POS induction part of the model on
all languages in the Multext-East corpora (Erjavec,
2010) as well as on the free corpora from CONLL-
X Shared Task1 for Dutch, Danish, Swedish and
Portuguese. The evaluation of morphological seg-
mentations is based on the Morpho Challenge gold
segmented wordlists for English, Finnish and Turk-
ish2. We gathered the sentences from Europarl cor-
pus3 for English and Finnish, and use the Turkish
1http://ilk.uvt.nl/conll/free_data.html
2http://research.ics.tkk.fi/events/
morphochallenge2010/datasets.shtml
3http://www.statmt.org/europarl/
text data from the Morpho Challenge 20094. Es-
tonian gold standard segmentations have been ob-
tained from the Estonian morphologically annotated
corpus5.
We report three accuracy measures for tagging:
greedy one-to-one mapping (1-1) (Haghighi and
Klein, 2006), many-to-one mapping (m-1) and V-
measure (V-m) (Rosenberg and Hirschberg, 2007).
Segmentation is evaluated on the basis of standard
F-score which is the harmonic mean of precision and
recall.
5.2 Experimental results
For each experiment, we made five runs with ran-
dom initializations and report the results of the me-
dian. The sampler was run 200 iterations for burnin,
after which we collected 5 samples, letting the sam-
pler to run for another 200 iterations between each
two sample. We start with 15 segmenting iterations
during each Gibbs iteration to enable the segmenta-
tion sampler to burnin to the current tagging state,
and gradually reduce this number to one. Segmenta-
tion likelihood term for tagging is calculated on the
basis of the last segment only because this setting
gave the best results in preliminary experiments and
it also makes the whole computation less expensive.
The first set of experiments was conducted to test
the model tagging accuracy on different languages
mentioned above. The results obtained were in gen-
eral slightly lower than the current state-of-the-art
and the number of tags learned was generally bigger
than the number of gold standard tags. We observed
that different components making up the corpus log-
arithmic probability have different magnitudes. In
particular, we found that the emission probability
component in log-scale is roughly four times smaller
than the transition probability. This observation mo-
tivated introducing the likelihood scaling heuristic
into the model to scale the emission probability up.
We tried a couple of different scaling factors on
Multext-East English corpus and then set its value
to 4 for all languages for the rest of the experi-
ments. This improved the tagging results consis-
tently across all languages.
4http://research.ics.tkk.fi/events/
morphochallenge2009/datasets.shtml
5http://www.cl.ut.ee/korpused/
morfkorpus/index.php?lang=eng
411
POS induction results are given in Table 1. When
comparing these results with the recently published
results on the same corpora (Christodoulopoulos et
al., 2011; Blunsom and Cohn, 2011; Lee et al,
2010) we can see that our results compare favorably
with the state-of-the-art, resulting with the best pub-
lished results in many occasions. The number of tag
clusters learned by the model corresponds surpris-
ingly well to the number of true coarse-grained gold
standard tags across all languages. There are two
things to note here: 1) the tag distributions learned
are influenced by the likelihood scaling heuristic and
more experiments are needed in order to fully under-
stand the characteristics and influence of this heuris-
tic; 2) as the model is learning the coarse-grained
tagset consistently in all languages, it might as well
be that the POS tags are not as dependent on the mor-
phology as we assumed, especially in inflectional
languages with many derivational and inflectional
suffixes, because otherwise the model should have
learned a more fine-grained tagset.
Segmentation results are presented in Table 2.
For each language, we report the lexicon-based pre-
cision, recall and F-measure, the number of word
types in the corpus and and number of word types
with gold segmentation available. The reported stan-
dard deviations show that the segmentations ob-
tained are stable across different runs which is prob-
ably due to the blocked sampler. We give the seg-
mentation results both with and without likelihood
scaling heuristic and denote that while the emission
likelihood scaling improves the tagging accuracy, it
actually degrades the segmentation results.
It can also be seen that in general precision score
is better but for Estonian recall is higher. This can
be explained by the characteristics of the evalua-
tion data sets. For English, Finnish and Turkish we
use the Morpho Challenge wordlists where the gold
standard segmentations are fine-grained, separating
both inflectional and derivational morphemes. Espe-
cially derivational morphemes are hard to learn with
pure data-driven methods with no knowledge about
semantics and thus it can result in undersegmenta-
tion. On the other hand, Estonian corpus separates
only inflectional morphemes which thus leads to
higher recall. Some difference can also come from
the fact that the sets of gold-segmented word types
for other languages are much smaller than in Esto-
6
8
10
12
14
16
18
20
22
24
0 100 200 300 400 500 600 700 800 900 1000
?10
5 ?
log(
p)
Iteration
Joint
POS tagging
Segmentation
Figure 2: Log-likelihood of samples plotted against iter-
ations. Dark lines show the average over five runs, grey
lines in the back show the real samples.
nian and thus it would be interesting to see whether
and how the results would change if the evaluation
could be done on all word types in the corpus for
other languages as well. In general, undersegmen-
tation is more acceptable than oversegmentation, es-
pecially when the aim is to use the resulting segmen-
tations in some NLP application.
Next, we studied the convergence characteristics
of our model. For these experiments we made five
runs with random initializations on Estonian cor-
pus and let the sampler run up to 1100 iterations.
Samples were taken after each ten iterations. Fig-
ure 2 shows the log-likelihood of the samples plot-
ted against iteration number. Dark lines show the
averages over five runs and gray lines in the back-
ground are the likelihoods of real samples showing
also the variance. We first calculated the full like-
lihood of the samples (the solid line) that showed
a quick improvement during the first few iterations
and then stabilized by continuing with only slow im-
provements over time. We then divided the full like-
lihood into two factors in order to see the contribu-
tion of both tagging and segmentation parts sepa-
rately. The results are quite surprising. It turned
out that the random tagging initializations are very
good in terms of probability and as a matter of fact
much better than the data can support and thus the
tagging likelihood drops quite significantly after the
first iteration and then continues with very slow im-
provements. The matters are totally different with
segmentations where the initial random segmenta-
tions result in a low likelihood that improves heavily
412
Types 1-1 m-1 V-m Induced True Best Pub.
Bulgarian 15103 50.3 (0.9) 71.9 (3.8) 54.9 (2.2) 13 (1.6) 12 - 66.5? 55.6?
Czech 17607 46.0 (1.0) 60.7 (1.6) 46.2 (0.7) 12 (0.8) 12 - 64.2? 53.9?
Danish 17157 53.2 (0.2) 69.5 (0.1) 52.7 (0.4) 14 (0.0) 25 43.2? 76.2? 59.0?
Dutch 27313 60.5 (1.9) 74.0 (1.6) 59.1 (1.1) 22 (0.0) 13 55.1? 71.1? 54.7?
English 9196 67.4 (0.1) 79.8 (0.1) 66.7 (0.1 13 (0.0) 12 - 73.3? 63.3?
Estonian 16820 47.6 (0.9) 64.5 (1.9) 45.6 (1.4) 14 (0.5) 11 - 64.4? 53.3?
Farsi 11319 54.9 (0.1) 65.3 (0.1) 52.1 (0.1) 13 (0.5) 12 - - -
Hungarian 19191 62.1 (0.7) 71.4 (0.3) 56.0 (0.6) 11 (0.9) 12 - 68.2? 54.8?
Polish 19542 48.5 (1.8) 59.6 (1.9) 45.4 (1.0) 13 (0.8) 12 - - -
Portuguese 27250 45.4 (1.1) 71.3 (0.3) 55.4 (0.3) 21 (1.1) 16 56.5? 78.5? 63.9?
Romanian 13822 44.3 (0.5) 60.5 (1.7) 46.7 (0.5) 14 (0.8) 14 - 61.1? 52.3?
Serbian 16813 40.1 (0.2) 60.1 (0.2) 43.5 (0.2) 13 (0.0) 12 - 64.1? 51.1?
Slovak 18793 44.1 (1.5) 56.2 (0.8) 41.2 (0.6) 14 (1.1) 12 - - -
Slovene 16420 51.6 (1.5) 66.8 (0.6) 51.6 (1.0) 12 (0.7) 12 - 67.9? 56.7?
Swedish 18473 50.6 (0.1) 60.3 (0.1) 55.8 (0.1) 17 (0.0) 41 38.5? 68.7? 58.9?
Table 1: Tagging results for different languages. For each language we report median one-to-one (1-1), many-to-one
(m-1) and V-measure (V-m) together with standard deviation from five runs where median is taken over V-measure.
Types is the number of word types in each corpus, True is the number of gold tags and Induced reports the median
number of tags induced by the model together with standard deviation. Best Pub. lists the best published results so far
(also 1-1, m-1 and V-m) in (Christodoulopoulos et al, 2011)?, (Blunsom and Cohn, 2011)? and (Lee et al, 2010)?.
Precision Recall F1 Types Segmented
Estonian without LLS 43.5 (0.8) 59.4 (0.6) 50.3 (0.7) 16820 16820
with LLS 42.8 (1.1) 54.6 (0.7) 48.0 (0.9)
English without LLS 69.0 (1.3) 37.3 (1.5) 48.5 (1.1) 20628 399
with LLS 59.8 (1.8) 29.0 (1.0) 39.1 (1.3)
Finnish without LLS 56.2 (2.5) 29.5 (1.7) 38.7 (2.0) 25364 292
with LLS 56.0 (1.1) 28.0 (0.6) 37.4 (0.7)
Turkish without LLS 65.4 (1.8) 44.8 (1.8) 53.2 (1.7) 18459 293
with LLS 68.9 (0.8) 39.2 (1.0) 50.0 (0.6)
Table 2: Segmentation results on different languages. Results are calculated based on word types. For each language
we report precision, recall and F1 measure, number of word types in the corpus and number of word types with gold
standard segmentation available. For each language we report the segmentation result without and with emission
likelihood scaling (without LLS and with LLS respectively).
with the first few iterations and then stabilizes but
still continues to improve over time. The explana-
tion for this kind of model behaviour needs further
studies and we leave it for future work.
Figure 3 plots the V-measure against the tagging
factor of the log-likelihood for all samples. It can
be seen that the lower V-measure values are more
spread out in terms of likelihood. These points cor-
respond to the early samples of the runs. The sam-
ples taken later during the runs are on the right in
the figure and the positive correlation between the
V-measure and likelihood values can be seen.
Next we studied whether the morphological seg-
10.35
10.4
10.45
10.5
10.55
10.6
10.65
10.7
10.75
10.8
10.85
10.9
0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5
?10
5 ?
log(
p)
V-measure
Figure 3: Tagging part of log-likelihood plotted against
V-measure
413
1-to-1 m-to-1 V-m
Fixed seg 40.5 (1.5) 53.4 (1.0) 37.5 (1.3)
Learned seg 47.6 (0.4) 64.5 (1.9) 45.6 (1.4)
Precision Recall F1
Fixed tag 36.7 (0.3) 56.4 (0.2) 44.5 (0.3)
Learned tag 42.8 (1.1) 54.6 (0.7) 48.0 (0.9)
Morfessor 51.29 52.59 51.94
Table 3: Tagging and segmentation results on Estonian
Multext-East corpus (Learned seg and Learned tag) com-
pared to the semisupervised setting where segmentations
are fixed to gold standard (Fixed seg) and tags are fixed
to gold standard (Fixed tag). Finally the segmentatation
results from Morfessor system for comparison are pre-
sented.
mentations and POS tags help each other in the
learning process. For that we conducted two semisu-
pervised experiments on Estonian corpus. First we
provided gold standard segmentations to the model
and let it only learn the tags. Then, we gave the
model gold standard POS tags and only learned the
segmentations. The results are given in Table 3.
We also added the results from joint unusupervised
learning for easier comparison. Unfortunately we
cannot repeat this experiment on other languages
to see whether the results are stable across differ-
ent languages because to our knowledge there is no
other free corpus with both gold standard POS tags
and morphological segmentations available.
From the results it can be seen that the unsu-
pervised learning results for both tagging and seg-
mentation are better than the results obtained from
semisupervised learning. This is surprising because
one would assume that providing gold standard data
would lead to better results. On the other hand, these
results are encouraging, showing that learning two
dependent tasks in a joint model by unsupervised
manner can be as good or even better than learn-
ing the same tasks separately and providing the gold
standard data as features.
Finally, we learned the morphological segmen-
tations with the state-of-the-art morphology induc-
tion system Morfessor baseline6 (Creutz and Lagus,
2005) and report the best results in the last row of
Table 3. Apparently, our joint model cannot beat
Morfessor in morphological segmentation and when
6http://www.cis.hut.fi/projects/morpho/
using the emission likelihood scaling that influences
the tagging results favorably, the segmentation re-
sults get even worse. Altough the semisupervised
experiments showed that there are dependencies be-
tween tags and segmentations, the conducted exper-
iments do not reveal of how to use these dependen-
cies for helping the POS tags to learn better morpho-
logical segmentations.
6 Related Work
We will review some of the recent works related
to Bayesian POS induction and morphological seg-
mentation.
One of the first Bayesian POS taggers is described
in (Goldwater and Griffiths, 2007). The model pre-
sented is a classical HMM with multinomial transi-
tion and emission distributions with Dirichlet priors.
Inference is done using a collapsed Gibbs sampler
and concentration parameter values are learned dur-
ing inference. The model is token-based, allowing
different words of the same type in different loca-
tions to have a different tag. This model can actu-
ally be classified as semi-supervised as it assumes
the presence of a tagging dictionary that contains
the list of possible POS tags for each word type -
an assumption that is clearly not realistic in an unsu-
pervised setting.
Models presented in (Christodoulopoulos et al,
2011) and (Lee et al, 2010) are also built on
Dirichlet-multinomials and, rather than defining a
sequence model, present a clustering model based
on features. Both report good results on type basis
and use (among others) also morphological features,
with (Lee et al, 2010) making use of fixed length
suffixes and (Christodoulopoulos et al, 2011) using
the suffixes obtained from an unsupervised morphol-
ogy induction system.
Nonparametric Bayesian POS induction has been
studied in (Blunsom and Cohn, 2011) and (Gael et
al., 2009). The model in (Blunsom and Cohn, 2011)
uses Pitman-Yor Process (PYP) prior but the model
itself is finite in the sense that the size of the tagset is
fixed. Their model also captures morphological reg-
ularities by modeling the generation of words with
character n-grams. The model in (Gael et al, 2009)
uses infinite state space with Dirichlet Process prior.
The model structure is classical HMM consisting
414
only of transitions and emissions and containing no
morphological features. Inference is done by us-
ing beam sampler introduced in (Gael et al, 2008)
which enables parallelized implementation.
One close model for morphology stems from
Bayesian word segmentation (Goldwater et al,
2009) where the task is to induce word borders from
transcribed sentences. Our segmentation model is in
principle the same as the unigram word segmenta-
tion model and the main difference is that we are us-
ing blocked sampler while (Goldwater et al, 2009)
uses point-wise Gibbs sampler by drawing the pres-
ence or absence of the word border between every
two characters.
In (Goldwater et al, 2006) the morphology is
learned in the adaptor grammar framework (John-
son et al, 2006) by using a PYP adaptor. PYP adap-
tor caches the numbers of observed derivation trees
and forces the distribution over all possible trees to
take the shape of power law. In the PYP (and also
DP) case the adaptor grammar can be interpreted as
PYP (or DP) model with regular PCFG distribution
as base measure.
The model proposed in (Goldwater et al, 2006)
makes several assumptions that we do not: 1) seg-
mentations have a fixed structure of stem and suffix;
and 2) there is a fixed number of inflectional classes.
Inference is performed with Gibbs sampler by sam-
pling for each word its stem, suffix and inflectional
class.
7 Conclusion
In this paper we presented a joint unsupervised
model for learning POS tags and morphological
segmentations with hierarchical Dirichlet Process
model. Our model induces the number of POS clus-
ters from data and does not contain any hand-tuned
parameters. We tested the model on many languages
and showed that by introcing a likelihood scaling
heuristic it produces state-of-the-art POS induction
results. We believe that the tagging results could
further be improved by adding additional features
concerning punctuation, capitalization etc. which
are heavily used in the other state-of-the-art POS in-
duction systems but these features were intentionally
left out in the current model for enabling to test the
concept of joint modelling of two dependent tasks.
We found some evidence that the tasks of POS
induction and morphological segmentation are de-
pendent by conducting semisupervised experiments
where we gave the model gold standard tags and seg-
mentations in turn and let it learn only segmentations
or tags respectively and found that the results in fully
unsupervised setting are better. Despite of that, the
model failed to learn as good segmentations as the
state-of-the-art morphological segmentation model
Morfessor. One way to improve the segmentation
results could be to use segment bigrams instead of
unigrams.
The model can serve as a basis for several further
extensions. For example, one possibility would be
to expand it into multilingual setting in a fashion of
(Naseem et al, 2009), or it could be extended to add
the joint learning of morphological paradigms of the
words given their tags and segmentations in a man-
ner described by (Dreyer and Eisner, 2011).
Acknowledgments
We would like to thank the anonymous reviewers
who helped to improve the quality of this paper.
This research was supported by the Estonian Min-
istry of Education and Research target-financed re-
search theme no. 0140007s12, and by European So-
cial Funds Doctoral Studies and Internationalisation
Programme DoRa.
References
D. Aldous. 1985. Exchangeability and related topics.
In E?cole d?e?te? de Probabilite?s de Saint-Flour, XIII?
1983, pages 1?198. Springer.
Taylor Berg-Kirkpatrick, Alexandre Bouchard-Co?te?,
John DeNero, and Dan Klein. 2010. Painless unsu-
pervised learning with features. In Human Language
Technologies: The 2010 Annual Conference of the
North American Chapter of the Association for Com-
putational Linguistics, pages 582?590.
Phil Blunsom and Trevor Cohn. 2011. A hierarchical
Pitman-Yor process HMM for unsupervised Part of
Speech induction. In Proceedings of the 49th Annual
Meeting of the Association for Computational Linguis-
tics: Human Language Technologies - Volume 1, pages
865?874.
Christos Christodoulopoulos, Sharon Goldwater, and
Mark Steedman. 2010. Two decades of unsupervised
POS induction: How far have we come? In Proceed-
415
ings of the 2010 Conference on Empirical Methods in
Natural Language Processing, pages 575?584.
Christos Christodoulopoulos, Sharo Goldwater, and
Mark Steedman. 2011. A Bayesian mixture model
for PoS induction using multiple features. In Proceed-
ings of the 2011 Conference on Empirical Methods in
Natural Language Processing, pages 638?647, Edin-
burgh, Scotland, UK.
Alexander Clark. 2003. Combining distributional and
morphological information for Part of Speech induc-
tion. In Proceedings of the Tenth Conference on Eu-
ropean Chapter of the Association for Computational
Linguistics - Volume 1, pages 59?66.
Mathias Creutz and Krista Lagus. 2005. Inducing
the morphological lexicon of a natural language from
unannotated text. In In Proceedings of the Inter-
national and Interdisciplinary Conference on Adap-
tive Knowledge Representation and Reasoning, pages
106?113.
Markus Dreyer and Jason Eisner. 2011. Discover-
ing morphological paradigms from plain text using a
Dirichlet Process mixture model. In Proceedings of
the 2011 Conference on Empirical Methods in Natural
Language Processing, pages 616?627.
Toma Erjavec. 2010. MULTEXT-East version 4: Mul-
tilingual morphosyntactic specifications, lexicons and
corpora. In Proceedings of the Seventh International
Conference on Language Resources and Evaluation.
Michael D. Escobar and Mike West. 1995. Bayesian
density estimation and inference using mixtures. Jour-
nal of the American Statistical Association, 90(430).
Thomas S. Ferguson. 1973. A Bayesian analysis of
some nonparametric problems. The Annals of Statis-
tics, 1(2):209?230.
Jurgen Van Gael, Yunus Saatci, Yee Whye Teh, and
Zoubin Ghahramani. 2008. Beam sampling for the
infinite Hidden Markov Model. In Proceedings of the
25th International Conference on Machine Learning,
pages 1088?1095.
Jurgen Van Gael, Andreas Vlachos, and Zoubin Ghahra-
mani. 2009. The infinite HMM for unsupervised PoS
tagging. In Proceedings of the 2009 Conference on
Empirical Methods in Natural Language Processing:
Volume 2 - Volume 2, pages 678?687.
Sharon Goldwater and Tom Griffiths. 2007. A fully
Bayesian approach to unsupervised Part-of-Speech
tagging. In Proceedings of the 45th Annual Meeting
of the Association of Computational Linguistics, pages
744?751, Prague, Czech Republic.
Sharon Goldwater, Thomas L. Griffiths, and Mark John-
son. 2006. Interpolating between types and tokens by
estimating power-law generators. In Advances in Neu-
ral Information Processing Systems 18, Cambridge,
MA.
Sharon Goldwater, Thomas L. Griffiths, and Mark John-
son. 2009. A Bayesian framework for word segmen-
tation: Exploring the effects of context. Cognition,
112:21?54.
Aria Haghighi and Dan Klein. 2006. Prototype-driven
learning for sequence models. In Proceedings of
the Human Language Technology Conference of the
NAACL, Main Conference, pages 320?327, New York
City, USA.
Mark Johnson, Thomas L. Griffiths, and Sharon Goldwa-
ter. 2006. Adaptor grammars: A framework for speci-
fying compositional nonparametric Bayesian models.
In Advances in Neural Information Processing Sys-
tems 19, pages 641?648.
Yoong Keok Lee, Aria Haghighi, and Regina Barzilay.
2010. Simple type-level unsupervised POS tagging.
In Proceedings of the 2010 Conference on Empirical
Methods in Natural Language Processing, pages 853?
861.
Daichi Mochihashi, Takeshi Yamada, and Naonori Ueda.
2009. Bayesian unsupervised word segmentation with
nested Pitman-Yor language modeling. In Proceed-
ings of the Joint Conference of the 47th Annual Meet-
ing of the ACL and the 4th International Joint Confer-
ence on Natural Language Processing of the AFNLP:
Volume 1 - Volume 1, pages 100?108.
Tahira Naseem, Benjamin Snyder, Jacob Eisenstein, and
Regina Barzilay. 2009. Multilingual part-of-speech
tagging: Two unsupervised approaches. Journal of Ar-
tificial Intelligence Research, 36:1?45.
Lawrence R. Rabiner. 1989. A tutorial on Hidden
Markov Models and selected applications in speech
recognition. In Proceedings of the IEEE, pages 257?
286.
Andrew Rosenberg and Julia Hirschberg. 2007. V-
measure: A conditional entropy-based external cluster
evaluation measure. In Proceedings of the 2007 Joint
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning (EMNLP-CoNLL), pages 410?420,
Prague, Czech Republic.
Yee Whye Teh, Michel I. Jordan, Matthew J. Beal, and
David M. Blei. 2006. Hierarchical Dirichlet pro-
cesses. Journal of the American Statistical Associa-
tion, 101(476):1566?1581.
Yee Whye Teh. 2006. A hierarchical Bayesian language
model based on Pitman-Yor processes. In Proceedings
of the 21st International Conference on Computational
Linguistics and 44th Annual Meeting of the Associa-
tion for Computational Linguistics, pages 985?992.
416
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 265?271,
Baltimore, Maryland, USA, June 23-25 2014.
c?2014 Association for Computational Linguistics
POS induction with distributional and morphological information
using a distance-dependent Chinese restaurant process
Kairit Sirts
Institute of Cybernetics at
Tallinn University of Technology
sirts@ioc.ee
Jacob Eisenstein
School of Interactive Computing
Georgia Institute of Technology
jacobe@gatech.edu
Micha Elsner
Department of Linguistics
The Ohio State University
melsner0@gmail.com
Sharon Goldwater
ILCC, School of Informatics
University of Edinburgh
sgwater@inf.ed.ac.uk
Abstract
We present a new approach to inducing the
syntactic categories of words, combining
their distributional and morphological prop-
erties in a joint nonparametric Bayesian
model based on the distance-dependent
Chinese Restaurant Process. The prior
distribution over word clusterings uses a
log-linear model of morphological similar-
ity; the likelihood function is the probabil-
ity of generating vector word embeddings.
The weights of the morphology model
are learned jointly while inducing part-of-
speech clusters, encouraging them to co-
here with the distributional features. The
resulting algorithm outperforms competi-
tive alternatives on English POS induction.
1 Introduction
The morphosyntactic function of words is reflected
in two ways: their distributional properties, and
their morphological structure. Each information
source has its own advantages and disadvantages.
Distributional similarity varies smoothly with syn-
tactic function, so that words with similar syntactic
functions should have similar distributional proper-
ties. In contrast, there can be multiple paradigms
for a single morphological inflection (such as past
tense in English). But accurate computation of
distributional similarity requires large amounts of
data, which may not be available for rare words;
morphological rules can be applied to any word
regardless of how often it appears.
These observations suggest that a general ap-
proach to the induction of syntactic categories
should leverage both distributional and morpho-
logical features (Clark, 2003; Christodoulopoulos
et al, 2010). But these features are difficult to
combine because of their disparate representations.
Distributional information is typically represented
in numerical vectors, and recent work has demon-
strated the utility of continuous vector represen-
tations, or ?embeddings? (Mikolov et al, 2013;
Luong et al, 2013; Kim and de Marneffe, 2013;
Turian et al, 2010). In contrast, morphology is
often represented in terms of sparse, discrete fea-
tures (such as morphemes), or via pairwise mea-
sures such as string edit distance. Moreover, the
mapping between a surface form and morphology
is complex and nonlinear, so that simple metrics
such as edit distance will only weakly approximate
morphological similarity.
In this paper we present a new approach for in-
ducing part-of-speech (POS) classes, combining
morphological and distributional information in a
non-parametric Bayesian generative model based
on the distance-dependent Chinese restaurant pro-
cess (ddCRP; Blei and Frazier, 2011). In the dd-
CRP, each data point (word type) selects another
point to ?follow?; this chain of following links
corresponds to a partition of the data points into
clusters. The probability of word w
1
following w
2
depends on two factors: 1) the distributional simi-
larity between all words in the proposed partition
containing w
1
and w
2
, which is encoded using a
Gaussian likelihood function over the word embed-
dings; and 2) the morphological similarity between
w
1
and w
2
, which acts as a prior distribution on the
induced clustering. We use a log-linear model to
capture suffix similarities between words, and learn
the feature weights by iterating between sampling
and weight learning.
We apply our model to the English section of
the the Multext-East corpus (Erjavec, 2004) in or-
der to evaluate both against the coarse-grained and
265
fine-grained tags, where the fine-grained tags en-
code detailed morphological classes. We find that
our model effectively combines morphological fea-
tures with distributional similarity, outperforming
comparable alternative approaches.
2 Related work
Unsupervised POS tagging has a long history in
NLP. This paper focuses on the POS induction
problem (i.e., no tag dictionary is available), and
here we limit our discussion to very recent sys-
tems. A review and comparison of older systems
is provided by Christodoulopoulos et al (2010),
who found that imposing a one-tag-per-word-type
constraint to reduce model flexibility tended to
improve system performance; like other recent
systems, we impose that constraint here. Recent
work also shows that the combination of morpho-
logical and distributional information yields the
best results, especially cross-linguistically (Clark,
2003; Berg-Kirkpatrick et al, 2010). Since then,
most systems have incorporated morphology in
some way, whether as an initial step to obtain pro-
totypes for clusters (Abend et al, 2010), or as
features in a generative model (Lee et al, 2010;
Christodoulopoulos et al, 2011; Sirts and Alum?ae,
2012), or a representation-learning algorithm (Yat-
baz et al, 2012). Several of these systems use a
small fixed set of orthographic and/or suffix fea-
tures, sometimes obtained from an unsupervised
morphological segmentation system (Abend et al,
2010; Lee et al, 2010; Christodoulopoulos et al,
2011; Yatbaz et al, 2012). Blunsom and Cohn?s
(2011) model learns an n-gram character model
over the words in each cluster; we learn a log-
linear model, which can incorporate arbitrary fea-
tures. Berg-Kirkpatrick et al (2010) also include
a log-linear model of morphology in POS induc-
tion, but they use morphology in the likelihood
term of a parametric sequence model, thereby en-
couraging all elements that share a tag to have the
same morphological features. In contrast, we use
pairwise morphological similarity as a prior in a
non-parametric clustering model. This means that
the membership of a word in a cluster requires only
morphological similarity to some other element in
the cluster, not to the cluster centroid; which may
be more appropriate for languages with multiple
morphological paradigms. Another difference is
that our non-parametric formulation makes it un-
necessary to know the number of tags in advance.
3 Distance-dependent CRP
The ddCRP (Blei and Frazier, 2011) is an extension
of the CRP; like the CRP, it defines a distribution
over partitions (?table assignments?) of data points
(?customers?). Whereas in the regular CRP each
customer chooses a table with probability propor-
tional to the number of customers already sitting
there, in the ddCRP each customer chooses another
customer to follow, and sits at the same table with
that customer. By identifying the connected compo-
nents in this graph, the ddCRP equivalently defines
a prior over clusterings.
If c
i
is the index of the customer followed by
customer i, then the ddCRP prior can be written
P (c
i
= j) ?
{
f(d
ij
) if i 6= j
? if i = j,
(1)
where d
ij
is the distance between customers i and j
and f is a decay function. A ddCRP is sequential if
customers can only follow previous customers, i.e.,
d
ij
=? when i > j and f(?) = 0. In this case,
if d
ij
= 1 for all i < j then the ddCRP reduces to
the CRP.
Separating the distance and decay function
makes sense for ?natural? distances (e.g., the num-
ber of words between word i and j in a document,
or the time between two events), but they can also
be collapsed into a single similarity function. We
wish to assign higher similarities to pairs of words
that share meaningful suffixes. Because we do not
know which suffixes are meaningful a priori, we
use a maximum entropy model whose features in-
clude all suffixes up to length three that are shared
by at least one pair of words. Our prior is then:
P (c
i
= j|w, ?) ?
{
e
w
T
g(i,j)
if i 6= j
? if i = j,
(2)
where g
s
(i, j) is 1 if suffix s is shared by ith and
jth words, and 0 otherwise.
We can create an infinite mixture model by com-
bining the ddCRP prior with a likelihood function
defining the probability of the data given the cluster
assignments. Since we are using continuous-valued
vectors (word embeddings) to represent the distri-
butional characteristics of words, we use a multi-
variate Gaussian likelihood. We will marginalize
over the mean ? and covariance ? of each clus-
ter, which in turn are drawn from Gaussian and
inverse-Wishart (IW) priors respectively:
? ? IW (?
0
,?
0
) ? ? N (?
0
,
?
/
?
0
) (3)
266
The full model is then:
P (X,c,?,?|?,w, ?) (4)
=
K
?
k=1
P (?
k
|?)p(?
k
|?
k
,?)
?
n
?
i=1
(P (c
i
|w, ?)P (x
i
|?
z
i
,?
z
i
)),
where ? are the hyperparameters for (?,?) and z
i
is the (implicit) cluster assignment of the ith word
x
i
. With a CRP prior, this model would be an infi-
nite Gaussian mixture model (IGMM; Rasmussen,
2000), and we will use the IGMM as a baseline.
4 Inference
The Gibbs sampler for the ddCRP integrates over
the Gaussian parameters, sampling only follower
variables. At each step, the follower link c
i
for a
single customer i is sampled, which can implicitly
shift the entire block of n customers fol(i) who fol-
low i into a new cluster. Since we marginalize over
the cluster parameters, computing P (c
i
= j) re-
quires computing the likelihood P (fol(i),X
j
|?),
where X
j
are the k customers already clustered
with j. However, if we do not merge fol(i)
with X
j
, then we have P (X
j
|?) in the overall
joint probability. Therefore, we can decompose
P (fol(i),X
j
|?) = P (fol(i)|X
j
,?)P (X
j
|?) and
need only compute the change in likelihood due to
merging in fol(i):
1
:
P (fol(i)|X
j
,?) = pi
?nd/2
?
d/2
k
|?
k
|
?
k
/2
?
d/2
n+k
|?
n+k
|
?
n+k
/2
?
d
?
i=1
?
(
?
n+k
+1?i
2
)
?
(
?
k
+1?i
2
)
, (5)
where the hyperparameters are updated as ?
n
=
?
0
+ n, ?
n
= ?
0
+ n, and
?
n
=
?
0
?
0
+ x?
?
0
+ n
(6)
?
n
= ?
0
+Q+ ?
0
?
0
?
0
T
? ?
n
?
n
?
T
n
, (7)
where Q =
?
n
i=1
x
i
x
T
i
.
Combining this likelihood term with the prior,
the probability of customer i following j is
P (c
i
= j|X
,
?,w, ?)
? P (fol(i)|X
j
,?)P (c
i
= j|w, ?). (8)
1
http://www.stats.ox.ac.uk/
?
teh/re-
search/notes/GaussianInverseWishart.pdf
Our non-sequential ddCRP introduces cycles
into the follower structure, which are handled in the
sampler as described by Socher et al (2011). Also,
the block of customers being moved around can po-
tentially be very large, which makes it easy for the
likelihood term to swamp the prior. In practice we
found that introducing an additional parameter a
(used to exponentiate the prior) improved results?
although we report results without this exponent as
well. This technique was also used by Titov and
Klementiev (2012) and Elsner et al (2012).
Inference also includes optimizing the feature
weights for the log-linear model in the ddCRP
prior (Titov and Klementiev, 2012). We interleave
L-BFGS optimization within sampling, as in Monte
Carlo Expectation-Maximization (Wei and Tanner,
1990). We do not apply the exponentiation parame-
ter a when training the weights because this proce-
dure affects the follower structure only, and we do
not have to worry about the magnitude of the like-
lihood. Before the first iteration we initialize the
follower structure: for each word, we choose ran-
domly a word to follow from amongst those with
the longest shared suffix of up to 3 characters. The
number of clusters starts around 750, but decreases
substantially after the first sampling iteration.
5 Experiments
Data For our experiments we used the English
word embeddings from the Polyglot project (Al-
Rfou? et al, 2013)
2
, which provides embeddings
trained on Wikipedia texts for 100,000 of the most
frequent words in many languages.
We evaluate on the English part of the Multext-
East (MTE) corpus (Erjavec, 2004), which provides
both coarse-grained and fine-grained POS labels
for the text of Orwell?s ?1984?. Coarse labels con-
sist of 11 main word classes, while the fine-grained
tags (104 for English) are sequences of detailed
morphological attributes. Some of these attributes
are not well-attested in English (e.g. gender) and
some are mostly distinguishable via semantic anal-
ysis (e.g. 1st and 2nd person verbs). Many tags are
assigned only to one or a few words. Scores for the
fine-grained tags will be lower for these reasons,
but we argue below that they are still informative.
Since Wikipedia and MTE are from different
domains their lexicons do not fully overlap; we
2
https://sites.google.com/site/rmyeid/
projects/polyglot
267
Wikipedia tokens 1843M
Multext-East tokens 118K
Multext-East types 9193
Multext-East & Wiki types 7540
Table 1: Statistics for the English Polyglot word embeddings
and English part of MTE: number of Wikipedia tokens used
to train the embeddings, number of tokens/types in MTE, and
number of types shared by both datasets.
take the intersection of these two sets for training
and evaluation. Table 1 shows corpus statistics.
Evaluation With a few exceptions (Biemann,
2006; Van Gael et al, 2009), POS induction sys-
tems normally require the user to specify the num-
ber of desired clusters, and the systems are evalu-
ated with that number set to the number of tags in
the gold standard. For corpora such as MTE with
both fine-grained and coarse-grained tages, pre-
vious evaluations have scored against the coarse-
grained tags. Though coarse-grained tags have
their place (Petrov et al, 2012), in many cases
the distributional and morphological distinctions
between words are more closely aligned with the
fine-grained tagsets, which typically distinguish
between verb tenses, noun number and gender,
and adjectival scale (comparative, superlative, etc.),
so we feel that the evaluation against fine-grained
tagset is more relevant here. For better comparison
with previous work, we also evaluate against the
coarse-grained tags; however, these numbers are
not strictly comparable to other scores reported on
MTE because we are only able to train and evalu-
ate on the subset of words that also have Polyglot
embeddings. To provide some measure of the dif-
ficulty of the task, we report baseline scores using
K-means clustering, which is relatively strong base-
line in this task (Christodoulopoulos et al, 2011).
There are several measures commonly used for
unsupervised POS induction. We report greedy
one-to-one mapping accuracy (1-1) (Haghighi and
Klein, 2006) and the information-theoretic score V-
measure (V-m), which also varies from 0 to 100%
(Rosenberg and Hirschberg, 2007). In previous
work it has been common to also report many-to-
one (m-1) mapping but this measure is particularly
sensitive to the number of induced clusters (more
clusters yield higher scores), which is variable for
our models. V-m can be somewhat sensitive to the
number of clusters (Reichart and Rappoport, 2009)
but much less so than m-1 (Christodoulopoulos
et al, 2010). With different number of induced
and gold standard clusters the 1-1 measure suffers
because some induced clusters cannot be mapped
to gold clusters or vice versa. However, almost half
the gold standard clusters in MTE contain just a
few words and we do not expect our model to be
able to learn them anyway, so the 1-1 measure is
still useful for telling us how well the model learns
the bigger and more distinguishable classes.
In unsupervised POS induction it is standard to
report accuracy on tokens even when the model it-
self works on types. Here we report also type-based
measures because these can reveal differences in
model behavior even when token-based measures
are similar.
Experimental setup For baselines we use K-
means and the IGMM, which both only learn from
the word embeddings. The CRP prior in the IGMM
has one hyperparameter (the concentration param-
eter ?); we report results for ? = 5 and 20. Both
the IGMM and ddCRP have four hyperparameters
controlling the prior over the Gaussian cluster pa-
rameters: ?
0
, ?
0
, ?
0
and ?
0
. We set the prior scale
matrix ?
0
by using the average covariance from
a K-means run with K = 200. When setting the
average covariance as the expected value of the IW
distribution the suitable scale matrix can be com-
puted as ?
0
= E [X] (?
0
? d? 1), where ?
0
is the
prior degrees of freedom (which we set to d + 10)
and d is the data dimensionality (64 for the Poly-
glot embeddings). We set the prior mean ?
0
equal
to the sample mean of the data and ?
0
to 0.01.
We experiment with three different priors for the
ddCRP model. All our ddCRP models are non-
sequential (Socher et al, 2011), allowing cycles
to be formed. The simplest model, ddCRP uni-
form, uses a uniform prior that sets the distance
between any two words equal to one.
3
The second
model, ddCRP learned, uses the log-linear prior
with weights learned between each two Gibbs iter-
ations as explained in section 4. The final model,
ddCRP exp, adds the prior exponentiation. The ?
parameter for the ddCRP is set to 1 in all experi-
ments. For ddCRP exp, we report results with the
exponent a set to 5.
Results and discussion Table 2 presents all re-
sults. Each number is an average of 5 experiments
3
In the sequential case this model would be equivalent to
the IGMM (Blei and Frazier, 2011). Due to the nonsequen-
tiality this equivalence does not hold, but we do expect to see
similar results to the IGMM.
268
Fine types Fine tokens Coarse tokens
Model K Model K-means Model K-means Model K-means
K-means 104 or 11 16.1 / 47.3 - 39.2 / 62.0 - 44.4 / 45.5 -
IGMM, ? = 5 55.6 41.0 / 45.9 23.1 / 49.5 48.0 / 64.8 37.2 / 61.0 48.3 / 58.3 40.8 / 55.0
IGMM, ? = 20 121.2 35.0 / 47.1 14.7 / 46.9 50.6 / 67.8 44.7 / 65.5 48.7 / 60.0 48.3 / 57.9
ddCRP uniform 80.4 50.5 / 52.9 18.6 / 48.2 52.4 / 68.7 35.1 / 60.3 52.1 / 62.2 40.3 / 54.2
ddCRP learned 89.6 50.1 / 55.1 17.6 / 48.0 51.1 / 69.7 39.0 / 63.2 48.9 / 62.0 41.1 / 55.1
ddCRP exp, a = 5 47.2 64.0 / 60.3 25.0 / 50.3 55.1 / 66.4 33.0 / 59.1 47.8 / 55.1 36.9 / 53.1
Table 2: Results of baseline and ddCRP models evaluated on word types and tokens using fine-grained tags, and on tokens
using coarse-grained tags. For each model we present the number of induced clusters K (or fixed K for K-means) and 1-1 / V-m
scores. The second column under each evaluation setting gives the scores for K-means with K equal to the number of clusters
induced by the model in that row.
with different random initializations. For each eval-
uation setting we provide two sets of scores?first
are the 1-1 and V-m scores for the given model,
second are the comparable scores for K-means run
with the same number of clusters as induced by the
non-parametric model.
These results show that all non-parametric mod-
els perform better than K-means, which is a strong
baseline in this task (Christodoulopoulos et al,
2011). The poor performace of K-means can be
explained by the fact that it tends to find clusters
of relatively equal size, although the POS clus-
ters are rarely of similar size. The common noun
singular class is by far the largest in English, con-
taining roughly a quarter of the word types. Non-
parametric models are able to produce cluster of
different sizes when the evidence indicates so, and
this is clearly the case here.
From the token-based evaluation it is hard to
say which IGMM hyperparameter value is better
even though the number of clusters induced differs
by a factor of 2. The type-base evaluation, how-
ever, clearly prefers the smaller value with fewer
clusters. Similar effects can be seen when com-
paring IGMM and ddCRP uniform. We expected
these two models perform on the same level, and
their token-based scores are similar, but on the type-
based evaluation the ddCRP is clearly superior. The
difference could be due to the non-sequentiality,
or becuase the samplers are different?IGMM en-
abling resampling only one item at a time, ddCRP
performing blocked sampling.
Further we can see that the ddCRP uniform and
learned perform roughly the same. Although the
prior in those models is different they work mainly
using the the likelihood. The ddCRP with learned
prior does produce nice follower structures within
each cluster but the prior is in general too weak
compared to the likelihood to influence the cluster-
ing decisions. Exponentiating the prior reduces the
number of induced clusters and improves results,
as it can change the cluster assignment for some
words where the likelihood strongly prefers one
cluster but the prior clearly indicates another.
The last column shows the token-based evalua-
tion against the coarse-grained tagset. This is the
most common evaluation framework used previ-
ously in the literature. Although our scores are not
directly comparable with the previous results, our
V-m scores are similar to the best published 60.5
(Christodoulopoulos et al, 2010) and 66.7 (Sirts
and Alum?ae, 2012).
In preliminary experiments, we found that di-
rectly applying the best-performing English model
to other languages is not effective. Different lan-
guages may require different parametrizations of
the model. Further study is also needed to verify
that word embeddings effectively capture syntax
across languages, and to determine the amount of
unlabeled text necessary to learn good embeddings.
6 Conclusion
This paper demonstrates that morphology and dis-
tributional features can be combined in a flexi-
ble, joint probabilistic model, using the distance-
dependent Chinese Restaurant Process. A key ad-
vantage of this framework is the ability to include
arbitrary features in the prior distribution. Future
work may exploit this advantage more thoroughly:
for example, by using features that incorporate
prior knowledge of the language?s morphological
structure. Another important goal is the evaluation
of this method on languages beyond English.
Acknowledgments: KS was supported by the
Tiger University program of the Estonian Infor-
mation Technology Foundation for Education. JE
was supported by a visiting fellowship from the
Scottish Informatics & Computer Science Alliance.
We thank the reviewers for their helpful feedback.
269
References
Omri Abend, Roi Reichart, and Ari Rappoport. 2010.
Improved unsupervised pos induction through pro-
totype discovery. In Proceedings of the 48th An-
nual Meeting of the Association of Computational
Linguistics, pages 1298?1307.
Rami Al-Rfou?, Bryan Perozzi, and Steven Skiena.
2013. Polyglot: Distributed word representations
for multilingual nlp. In Proceedings of the Thir-
teenth Annual Conference on Natural Language
Learning, pages 183?192, Sofia, Bulgaria. Associ-
ation for Computational Linguistics.
Taylor Berg-Kirkpatrick, Alexandre B. C?ot?e, John
DeNero, and Dan Klein. 2010. Painless unsuper-
vised learning with features. In Proceedings of Hu-
man Language Technologies: The Conference of the
North American Chapter of the Association for Com-
putational Linguistics, pages 582?590.
Chris Biemann. 2006. Unsupervised part-of-speech
tagging employing efficient graph clustering. In Pro-
ceedings of the 21st International Conference on
Computational Linguistics and 44th Annual Meet-
ing of the Association for Computational Linguistics,
pages 7?12.
David M Blei and Peter I Frazier. 2011. Distance
dependent chinese restaurant processes. Journal of
Machine Learning Research, 12:2461?2488.
Phil Blunsom and Trevor Cohn. 2011. A hierarchi-
cal pitman-yor process hmm for unsupervised part
of speech induction. In Proceedings of the 49th An-
nual Meeting of the Association of Computational
Linguistics, pages 865?874.
Christos Christodoulopoulos, Sharon Goldwater, and
Mark Steedman. 2010. Two decades of unsuper-
vised POS induction: How far have we come? In
Proceedings of the Conference on Empirical Meth-
ods in Natural Language Processing.
Christos Christodoulopoulos, Sharon Goldwater, and
Mark Steedman. 2011. A Bayesian mixture model
for part-of-speech induction using multiple features.
In Proceedings of the Conference on Empirical
Methods in Natural Language Processing.
Alexander Clark. 2003. Combining distributional and
morphological information for part of speech induc-
tion. In Proceedings of the European chapter of the
ACL.
Micha Elsner, Sharon Goldwater, and Jacob Eisenstein.
2012. Bootstrapping a unified model of lexical and
phonetic acquisition. In Proceedings of the 50th An-
nual Meeting of the Association of Computational
Linguistics.
Toma?z Erjavec. 2004. MULTEXT-East version 3:
Multilingual morphosyntactic specifications, lexi-
cons and corpora. In LREC.
A. Haghighi and D. Klein. 2006. Prototype-driven
learning for sequence models. In Proceedings of
the Human Language Technology Conference of the
North American Chapter of the Association for Com-
putational Linguistics.
Joo-Kyung Kim and Marie-Catherine de Marneffe.
2013. Deriving adjectival scales from continuous
space word representations. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing.
Yoong Keok Lee, Aria Haghighi, and Regina Barzi-
lay. 2010. Simple type-level unsupervised pos tag-
ging. In Proceedings of the Conference on Empiri-
cal Methods in Natural Language Processing, pages
853?861.
Minh-Thang Luong, Richard Socher, and Christo-
pher D Manning. 2013. Better word representations
with recursive neural networks for morphology. In
Proceedings of the Thirteenth Annual Conference on
Natural Language Learning.
Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.
2013. Linguistic regularities in continuous space
word representations. In Proceedings of Human
Language Technologies: The Conference of the
North American Chapter of the Association for Com-
putational Linguistics, pages 746?751.
Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012.
A universal part-of-speech tagset. In Proceedings of
LREC, May.
Carl Rasmussen. 2000. The infinite Gaussian mixture
model. In Advances in Neural Information Process-
ing Systems 12, Cambridge, MA. MIT Press.
Roi Reichart and Ari Rappoport. 2009. The nvi cluster-
ing evaluation measure. In Proceedings of the Ninth
Annual Conference on Natural Language Learning,
pages 165?173.
A. Rosenberg and J. Hirschberg. 2007. V-measure:
A conditional entropy-based external cluster evalua-
tion measure. In Proceedings of the Joint Confer-
ence on Empirical Methods in Natural Language
Processing and Computational Natural Language
Learning, pages 410?42.
Kairit Sirts and Tanel Alum?ae. 2012. A hierarchi-
cal Dirichlet process model for joint part-of-speech
and morphology induction. In Proceedings of Hu-
man Language Technologies: The Conference of the
North American Chapter of the Association for Com-
putational Linguistics, pages 407?416.
Richard Socher, Andrew L Maas, and Christopher D
Manning. 2011. Spectral chinese restaurant pro-
cesses: Nonparametric clustering based on similar-
ities. In Proceedings of the Fifteenth International
Conference on Artificial Intelligence and Statistics,
pages 698?706.
270
Ivan Titov and Alexandre Klementiev. 2012. A
bayesian approach to unsupervised semantic role in-
duction. In Proceedings of the 13th Conference of
the European Chapter of the Association for Com-
putational Linguistics.
Joseph Turian, Lev-Arie Ratinov, and Yoshua Bengio.
2010. Word representations: A simple and general
method for semi-supervised learning. In Proceed-
ings of the 48th Annual Meeting of the Association
for Computational Linguistics, pages 384?394, Up-
psala, Sweden, July. Association for Computational
Linguistics.
Jurgen Van Gael, Andreas Vlachos, and Zoubin
Ghahramani. 2009. The infinite HMM for unsu-
pervised PoS tagging. In Proceedings of the Con-
ference on Empirical Methods in Natural Language
Processing, pages 678?687, Singapore.
Greg CG Wei and Martin A Tanner. 1990. A
monte carlo implementation of the em algorithm
and the poor man?s data augmentation algorithms.
Journal of the American Statistical Association,
85(411):699?704.
Mehmet Ali Yatbaz, Enis Sert, and Deniz Yuret. 2012.
Learning syntactic categories using paradigmatic
representations of word context. In Proceedings of
the Conference on Empirical Methods in Natural
Language Processing, pages 940?951.
271
Transactions of the Association for Computational Linguistics, 1 (2013) 255?266. Action Editor: Kristina Toutanova.
Submitted 11/2012; Published 5/2013. c?2013 Association for Computational Linguistics.
Minimally-Supervised Morphological Segmentation
using Adaptor Grammars
Kairit Sirts
Institute of Cybernetics
Tallinn University of Technology
sirts@phon.ioc.ee
Sharon Goldwater
School of Informatics
The University of Edinburgh
sgwater@inf.ed.ac.uk
Abstract
This paper explores the use of Adaptor Gram-
mars, a nonparametric Bayesian modelling
framework, for minimally supervised morpho-
logical segmentation. We compare three train-
ing methods: unsupervised training, semi-
supervised training, and a novel model selec-
tion method. In the model selection method,
we train unsupervised Adaptor Grammars us-
ing an over-articulated metagrammar, then use
a small labelled data set to select which poten-
tial morph boundaries identified by the meta-
grammar should be returned in the final output.
We evaluate on five languages and show that
semi-supervised training provides a boost over
unsupervised training, while the model selec-
tion method yields the best average results over
all languages and is competitive with state-of-
the-art semi-supervised systems. Moreover,
this method provides the potential to tune per-
formance according to different evaluation met-
rics or downstream tasks.
1 Introduction
Research into unsupervised learning of morphology
has a long history, starting with the work of Harris
(1951). While early research was mostly motivated
by linguistic interests, more recent work in NLP often
aims to reduce data sparsity in morphologically rich
languages for tasks such as automatic speech recogni-
tion, statistical machine translation, or automatic text
generation. For these applications, however, com-
pletely unsupervised systems may not be ideal if
even a small amount of segmented training data is
available. In this paper, we explore the use of Adap-
tor Grammars (Johnson et al, 2007) for minimally
supervised morphological segmentation.
Adaptor Grammars (AGs) are a nonparametric
Bayesian modelling framework that can learn latent
tree structures over an input corpus of strings. For
example, they can be used to define a morpholog-
ical grammar where each word consists of zero or
more prefixes, a stem, and zero or more suffixes; the
actual forms of these morphs (and the segmentation
of words into morphs) are learned from the data. In
this general approach AGs are similar to many other
unsupervised morphological segmentation systems,
such as Linguistica (Goldsmith, 2001) and the Mor-
fessor family (Creutz and Lagus, 2007). A major
difference, however, is that the morphological gram-
mar is specified as an input to the program, rather
than hard-coded, which allows different grammars
to be explored easily. For the task of segmenting
utterances into words, for example, Johnson and col-
leagues have experimented with grammars encoding
different kinds of sub-word and super-word structure
(e.g., syllables and collocations), showing that the
best grammars far outperform other systems on the
same corpora (Johnson, 2008a; Johnson and Goldwa-
ter, 2009; Johnson and Demuth, 2010).
These word segmentation papers demonstrated
both the power of the AG approach and the syner-
gistic behavior that occurs when learning multiple
levels of structure simultaneously. However, the best-
performing grammars were selected using the same
corpus that was used for final testing, and each paper
dealt with only one language. The ideal unsuper-
vised learner would use a single grammar tuned on
255
one or more development languages and still perform
well on other languages where development data is
unavailable. Indeed, this is the basic principle be-
hind Linguistica and Morfessor. However, we know
that different languages can have very different mor-
phological properties, so using a single grammar for
all languages may not be the best approach if there
is a principled way to choose between grammars.
Though AGs make it easy to try many different pos-
sible grammars, the process of proposing and testing
plausible options can still be time-consuming.
In this paper, we propose a novel method for au-
tomatically selecting good morphological grammars
for different languages (English, Finnish, Turkish,
German, and Estonian) using a small amount of
gold-segmented data (1000 word types). We use
the AG framework to specify a very general binary-
branching grammar of depth four with which we
learn a parse tree of each word that contains several
possible segmentation splits for the word. Then, we
use the gold-segmented data to learn, for each lan-
guage, which of the proposed splits from the original
grammar should actually be used in order to best
segment that language.
We evaluate our approach on both a small devel-
opment set and the full Morpho Challenge test set
for each language?up to three million word types.
In doing so, we demonstrate that using the posterior
grammar of an AG model to decode unseen data is
a feasible way to scale these models to large data
sets. We compare to several baselines which use the
annotated data to different degrees: parameter tuning,
grammar tuning, supervised training, or no use of
annotated data. In addition to existing approaches?
unsupervised and semi-supervised Morfessor, unsu-
pervised Morsel (Lignos, 2010), and unsupervised
AGs?we also show how to use the annotated data to
train semi-supervised AGs (using the data to accumu-
late rule statistics rather than for grammar selection).
The grammar selection method yields comparable
results to the best of these other approaches.
To summarize, our contributions in this paper are:
1) scaling AGs to large data sets by using the poste-
rior grammar to define an inductive model; 2) demon-
strating how to train semi-supervised AG models, and
showing that this improves morphological segmenta-
tion over unsupervised training; and 3) introducing
a novel grammar selection method for AG models
whose segmentation results are competitive with the
best existing systems.
Before providing details of our methods and re-
sults, we first briefly review Adaptor Grammars. For
a formal definition, see Johnson et al (2007).
2 Adaptor Grammars
Adaptor Grammars are a framework for specifying
nonparametric Bayesian models that can be used to
learn latent tree structures from a corpus of strings.
There are two components to an AG model: the base
distribution, which is just a PCFG, and the adaptor,
which ?adapts? the probabilities assigned to individ-
ual subtrees under the PCFG model, such that the
probability of a subtree under the complete model
may be considerably higher than the product of the
probabilities of the PCFG rules required to construct
it. Although in principle the adaptor can be any func-
tion that maps one distribution onto another, Johnson
et al (2007) use a Pitman-Yor Process (PYP) (Pit-
man and Yor, 1997) as the adaptor because it acts
as a caching model. Under a PYP AG model, the
posterior probability of a particular subtree will be
roughly proportional to the number of times that sub-
tree occurs in the current analysis of the data (with
the probability of unseen subtrees being computed
under the base PCFG distribution).
An AG model can be defined by specifying the
CFG rules (the support for the base distribution) and
indicating which non-terminals are ?adapted?, i.e.,
can serve as the root of a cached subtree. Given this
definition and an input corpus of strings, Markov
chain Monte Carlo samplers can be used to infer the
posterior distribution over trees (and all hyperparam-
eters of the model, including PCFG probabilities in
the base distribution and PYP hyperparameters). Any
frequently recurring substring (e.g., a common pre-
fix) will tend to be parsed consistently, as this permits
the model to treat the subtree spanning that string as
a cached subtree, assigning it higher probability than
under the PCFG distribution.
Adaptor Grammars have been applied to a wide
variety of tasks, including segmenting utterances
into words (Johnson, 2008a; Johnson and Goldwa-
ter, 2009; Johnson and Demuth, 2010), classifying
documents according to perspective (Hardisty et al,
2010), machine transliteration of names (Huang et
256
al., 2011), native language identification (Wong et
al., 2012), and named entity clustering (Elsner et al,
2009). There have also been AG experiments with
morphological segmentation, but more as a proof of
concept than an attempt to achieve state-of-the-art
results (Johnson et al, 2007; Johnson, 2008b).
3 Using AGs for Learning Morphology
Originally, the AG framework was designed for un-
supervised learning. This section first describes how
AGs can be used for unsupervised morphological
segmentation, and then introduces two ways to use
a small labelled data set to improve performance:
semi-supervised learning and grammar selection.
3.1 Unsupervised Adaptor Grammars
We define three AG models to use as unsupervised
baselines in our segmentation experiments. The first
of these is very simple:
Word? Morph+
Morph? Char+ (1)
The underline notation indicates an adapted non-
terminal, and + abbreviates a set of recursive rules,
e.g., Word? Morph+ is short for
Word? Morphs
Morphs? Morph Morphs
Morphs? Morph
Grammar 1 (MorphSeq) is just a unigram model
over morphs: the Morph symbol is adapted, so the
probability of each Morph will be roughly propor-
tional to its (inferred) frequency in the corpus. The
grammar specifies no further structural relationships
between morphs or inside of morphs (other than a
geometric distribution on their length in characters).
Experiments with AGs for unsupervised word seg-
mentation suggest that adding further latent structure
can help with learning. Here, we add another layer
of structure below the morphs,1 calling the resulting
1Because the nonterminal labels are arbitrary, this grammar
can also be interpreted as adding another layer on top of morphs,
allowing the model to learn morph collocations that encode de-
pendencies between morphs (which themselves have no substruc-
ture). However preliminary experiments showed that the morph-
submorph interpretation scored better than the collocation-morph
interpretation, hence we chose the corresponding nonterminal
names.
grammar SubMorphs:
Word? Morph+
Morph? SubMorph+
SubMorph? Char+
(2)
For capturing the rules of morphotactics, a gram-
mar with linguistically motivated non-terminals can
be created. There are many plausible options and
the best-performing grammar may be somewhat
language-dependent. Rather than experimenting ex-
tensively, we designed our third grammar to replicate
as closely as possible the grammar that is implicitly
implemented in the Morfessor system. This Com-
pounding grammar distinguishes between prefixes,
stems and suffixes, allows compounding, defines the
order in which the morphs can occur and also allows
the morphs to have inner latent structure:
Word? Compound+
Compound? Prefix? Stem Suffix?
Prefix? SubMorph+
Stem? SubMorph+
Suffix? SubMorph+
SubMorph? Char+
(3)
3.2 Semi-Supervised Adaptor Grammars
The first new use of AGs we introduce is the semi-
supervised AG, where we use the labelled data to ex-
tract counts of the different rules and subtrees used in
the gold-standard analyses. We then run the MCMC
sampler as usual over both the unlabelled and la-
belled data, treating the counts from the labelled data
as fixed.
We assume that the labelled data provides a con-
sistent bracketing (no two spans in the bracketing
can partially overlap) and the labels of the spans
must be compatible with the grammar. However,
the bracketing may not specify all levels of structure
in the grammar. In our case, we have morpheme
bracketings but not, e.g., submorphs. Thus, using
the SubMorphs grammar in semi-supervised mode
will constrain the sampler so that Morph spans in the
labelled data will remain fixed, while the SubMorphs
inside those Morphs will be resampled.
257
The main change made to the AG inference pro-
cess2 for implementing the semi-supervised AG was
to prune out from the sampling distribution any non-
terminals that are inconsistent with the spans/labels
in the given labelling.
3.3 AG Select
Both the unsupervised and semi-supervised methods
described above assume the definition of a grammar
that adequately captures the phenomena being mod-
elled. Although the AG framework makes it easy
to experiment with different grammars, these experi-
ments can be time-consuming and require some good
guesses as to what a plausible grammar might be.
These problems can be overcome by automating the
grammar development process to systematically eval-
uate different grammars and find the best one.
We propose a minimally supervised model selec-
tion method AG Select that uses the AG framework to
automatically identify the best grammar for different
languages and data sets. We first define a very gen-
eral binary-branching CFG grammar for AG training
that we call the metagrammar. The metagrammar
learns a parse tree for each word where each branch
contains a different structure in the word. The granu-
larity of these structures is determined by the depth of
this tree. For example, Grammar 4 generates binary
trees of depth two and can learn segmentations of up
to four segments.
Word? M1
Word? M1 M2
M1? M11
M1? M11 M12
M2? M21
M2? M21 M22
M11? Chars+
M12? Chars+
M21? Chars+
M22? Chars+
(4)
Next we introduce the notion of a morphologi-
cal template, which is an ordered sequence of non-
terminals whose concatenated yields constitute the
word and which are used to parse out a specific seg-
mentation of the word. For example, using Gram-
mar 4 the parse tree of the word saltiness is shown in
Figure 1. There are four possible templates with four
2We started with Mark Johnson?s PYAG implementa-
tion, http://web.science.mq.edu.au/?mjohnson/code/py-cfg.tgz,
which we also used for our unsupervised and grammar selection
experiments.
Word
M1
M11
s a l
M12
t
M2
M21
i
M22
n e s s
Figure 1: The parse tree generated by the metagrammar
of depth 2 for the word saltiness.
different segmentations: M1 M2 (salt iness), M11
M12 M2 (sal t iness), M1 M21 M22 (salt i ness),
and M11 M12 M21 M22 (sal t i ness).
The morphological template consisting only of
non-terminals from the lowest cached level of the
parse tree is expected to have high recall, whereas
the template containing the non-terminals just below
the Word is expected to have high precision. Our
goal is to find the optimal template by using a small
labelled data set. The grammar selection process iter-
ates over the set of all templates. For each template,
the segmentations of the words in the labelled data
set are parsed out and the value of the desired evalua-
tion metric is computed. The template that obtained
the highest score is then chosen.
For each language we use a single template to seg-
ment all the words in that language. However, even
using (say) a four-morph template such as M11 M12
M21 M22, some words may contain fewer morphs
because the metagrammar permits either unary or
binary branching rules, so some parses may not con-
tain M12 or M2 (and thus M21 M22) spans. Thus,
we can represent segmentations of different lengths
(from 1 to 2n, where n is the depth of the metagram-
mar) with a single template.3
For our experiments we use a metagrammar of
depth four. This grammar allows words to consist of
up to 16 segments, which we felt would be enough for
any word in the training data. Also, iterating over all
the templates of a grammar with bigger depth would
not be feasible as the number of different templates
increases very rapidly.4
3We also experimented with selecting different templates for
words of different length but observed no improvements over the
single template approach.
4The number of templates of each depth can be expressed
recursively as Ni = (Ni?1 + 1)2, where Ni?1 is the number of
258
3.4 Inductive Learning
Previous work on AGs has used relatively small data
sets and run the sampler on the entire input corpus
(some or all of which is also used for evaluation)?a
transductive learning scenario. However, our larger
data sets contain millions of word types, where sam-
pling over the whole set is not feasible. For example,
1000 training iterations on 50k word types took about
a week on one 2.67 GHz CPU. To solve this problem,
we need an inductive learner that can be trained on a
small set of data and then used to segment a different
larger set.
To create such a learner, we run the sampler on
up to 50k word types, and then extract the posterior
grammar as a PCFG.5 This grammar contains all the
initial CFG rules, plus rules to generate each of the
cached subtrees inferred by the sampler. The sampler
counts of all rules are normalized to obtain a PCFG,
and we can then use a standard CKY parser to decode
the remaining data using this PCFG.
4 Experiments
4.1 Data
We test on languages with a range of morphologi-
cal complexity: English, Finnish, Turkish, German,
and Estonian. For each language we use two small
sets of gold-annotated data?a labelled set for semi-
supervised training or model selection and a dev
set for development results?and one larger gold-
annotated dataset for final tests. We also have a large
unlabelled training set for each language. Table 1
gives statistics.
The data sets for English, Finnish, Turkish and
German are from the Morpho Challenge 2010 com-
petition6 (MC2010). We use the MC2010 training
set of 1000 annotated word types as our labelled data,
and for our dev sets we collate together the devel-
opment data from all years of the MC competition.
Final evaluation is done on the official MC2010 test
sets, which are not public, so we rely on the MC
organizers to perform the evaluation. The words in
templates in the grammar of depth one less and N0 = 0.
5This can be seen as a form of Structure Compilation (Liang
et al, 2008), where the solution found by a more costly model
is used to define a less costly model. However in Liang et al?s
case both models were already inductive.
6http://research.ics.aalto.fi/events/morphochallenge2010/
datasets.shtml
Unlab. Lab. Dev Test
English 0.9M 1000 1212 16K
Finnish 2.9M 1000 1494 225K
Turkish 0.6M 1000 1531 64K
German 2.3M 1000 785 62K
Estonian 2.1M 1000 1500 74K
Table 1: Number of word types in our data sets.
each test set are an unknown subset of the words in
the unlabelled corpus, so to evaluate we segmented
the entire unlabelled corpus and sent the results to
the MC team, who then computed scores on the test
words.
The Estonian wordlist is gathered from the news-
paper texts of a mixed corpus of Estonian.7 Gold
standard segmentations of some of these words are
available from the Estonian morphologically disam-
biguated corpus;8 we used these for the test set, with
small subsets selected randomly for the labelled and
dev sets.
For semi-supervised tests of the AG Compounding
grammar we annotated the morphemes in the English,
Finnish and Estonian labelled sets as prefixes, stems
or suffixes. We could not do so for Turkish because
none of the authors knows Turkish.
4.2 Evaluation
We evaluate our results with two measures: segment
border F1-score (SBF1) and EMMA (Spiegler and
Monson, 2010). SBF1 is one of the simplest and
most popular evaluation metrics for morphological
segmentations. It computes F1-score from the preci-
sion and recall of ambiguous segment boundaries?
i.e., word edges are not counted. It is easy and quick
to compute but has the drawback that it gives no
credit for one-morpheme words that have been seg-
mented correctly (i.e., are assigned no segment bor-
ders). Also it can only be used on systems and gold
standards where the output is just a segmentation of
the surface string (e.g., availabil+ity) rather than a
morpheme analysis (e.g., available+ity). For this
reason we cannot report SBF1 on our German data,
which annotations contain only analyses.
EMMA is a newer measure that addresses both
7http://www.cl.ut.ee/korpused/segakorpus/epl
8http://www.cl.ut.ee/korpused/morfkorpus/
259
of these issues?correctly segmented one-morpheme
words are reflected in the score, and it can evalu-
ate both concatenative and non-concatenative mor-
phology. EMMA works by finding the best one-to-
one mapping between the hypothesized and true seg-
ments. The induced segments are then replaced with
their mappings and based on that, F1-score on match-
ing segments is calculated. Using EMMA we can
evaluate the induced segmentations of German words
against gold standard analyses. EMMA has a freely
available implementation,9 but is slow to compute
because it uses Integer Linear Programming.
For our dev results, we computed both scores us-
ing the entire dev set, but for the large test sets, the
evaluation is done on batches of 1000 word types se-
lected randomly from the test set. This procedure is
repeated 10 times and the average is reported, just as
in the MC2010 competition (Kohonen et al, 2010a).
4.3 Baseline Models
We compare our AG models to several other mor-
phology learning systems. We were able to obtain
implementations of two of the best unsupervised sys-
tems from MC2010, Morfessor (Creutz and Lagus,
2007) and Morsel (Lignos, 2010), and we use these
for comparisons on both the dev and test sets. We
also report test results from MC2010 for the only
semi-supervised system in the competition, semi-
supervised Morfessor (Kohonen et al, 2010a; Ko-
honen et al, 2010b). No dev results are reported on
this system since we were unable to obtain an imple-
mentation. This section briefly reviews the systems.
4.3.1 Morfessor Categories-MAP
Morfessor Categories-MAP (Morfessor) is a state-
of-the-art unsupervised morphology learning system.
Its implementation is freely available10 so it is widely
used both as a preprocessing step in tasks requiring
morphological segmentations, and as a baseline for
evaluating morphology learning systems.
Morfessor uses the Minimum Description Length
(MDL) principle to choose the optimal segment lexi-
con and the corpus segmentation. Each morph in the
segment lexicon is labelled as a stem, prefix, suffix
9http://www.cs.bris.ac.uk/Research/MachineLearning/
Morphology/resources.jsp#eval
10http://www.cis.hut.fi/projects/morpho/
morfessorcatmapdownloadform.shtml
or non-morph. The morphotactic rules are encoded
as an HMM, which specifies the allowed morph se-
quences with respect to the labels (e.g., a suffix can-
not directly follow a prefix).
The morphs in the segment lexicon can have a
hierachical structure, containing submorphs which
themselves can consist of submorphs etc. We hypoth-
esize that this hierarchical structure is one of the key
reasons why Morfessor has been so successful, as the
experiments also in this paper with different gram-
mars show that the ability to learn latent structures is
crucial for learning good segmentations.
One essential difference between Morfessor and
the proposed AG Select is that while we use the la-
belled data to choose which levels of the hierarchy
are to be used as morphs, Morfessor makes this de-
cision based on the labels of the segments, choosing
the most fine-grained morph sequence that does not
contain the non-morph label.
Morfessor includes a free parameter, perplexity
threshold, which we found can affect the SBF1 score
considerably (7 points or more). The best value for
this parameter depends on the size of the training
set, characteristics of the language being learned, and
also the evaluation metric being used, as in some
cases the best SBF1 and EMMA scores are obtained
with completely different values.
Thus, we tuned the value of the perplexity thresh-
old on the labelled set for each language and evalua-
tion metric for different unlabelled training set sizes.
4.3.2 Semi-Supervised Morfessor
Recently, the Morfessor system has been adapted
to allow semi-supervised training. Four versions of
the system were evaluated in MC2010, using differ-
ent degrees of supervision. Results reported here are
from the Morfessor S+W system, which performed
best of those that use the same kind of labelled data
as we do.11 This system uses the Morfessor Base-
line model (not Cat-MAP), which incorporates a
lexicon prior and data likelihood term. The semi-
supervised version maintains separate likelihoods for
the labelled and unlabelled data, and uses the devel-
opment set to tune two parameters that weight these
terms with respect to each other and the prior.
11Morfessor S+W+L performs better, but uses training data
with morpheme analyses rather than surface segmentations.
260
4.3.3 Morsel
Morsel (Lignos, 2010) is an unsupervised mor-
phology learning system introduced in MC2010; we
obtained the implementation from the author. Morsel
learns morphological analyses rather than segmenta-
tions, so it can be evaluated only using EMMA. There
are two options provided for running Morsel: aggres-
sive and conservative. We used the development set
to choose the best in each experimental case.
The MC data sets contain gold standard morpho-
logical analyses (as well as segmentations) so we
could compute Morsel?s EMMA scores using the
analyses. However, we found that Morsel obtains
higher EMMA scores when evaluated against gold
standard segmentations and thus we used this option
in all the experiments. (EMMA scores for other sys-
tems were also computed using the segmentations.)
4.4 Method
The experiments were conducted in two parts. First,
we evaluated different aspects of the AG models and
compared to all baseline models using the dev set
data. Then we evaluated the most competitive models
on the final test data.
For the development experiments, we compiled un-
labelled training sets with sizes ranging from 10k to
50k word types (using the most frequent word types
in each case). For the AG results, we report the aver-
age of five different runs made on the same training
set. We let the sampler run for 1000 iterations. No
annealing was used as it did not seem to help. The
table label resampling option was turned on and the
hyperparameter values were inferred.
We trained all AG and baseline models on each of
these training sets. For AG Select, the words from
the labelled data set were added to the training set to
allow for template selection.12 To compute results in
transductive mode, the words from the dev set were
also added to the training data. In inductive mode,
the dev set was instead parsed with the CKY parser.
Preliminary experiments showed that the perfor-
mance of unsupervised AG and AG Select improved
with larger training sets, though the effect is small
(see Figure 2 for results of AG Select in transductive
12We also experimented with smaller sets of labelled data. In
most cases, the template selected based on only 300 word types
was the same than the one selected with 1000 word types.
mode; the trend in inductive mode is similar). Based
on these and similar results with other baseline sys-
tems, all results reported later for unsupervised mod-
els (AG and baseline) and AG Select were obtained
using training sets of 50k words.
In contrast to the above models, the semi-
supervised AG does not always improve with more
unlabelled data (see Figure 2) and in the limit, it
will match the performance of the same grammar
in the unsupervised setting. Other semi-supervised
approaches often solve this problem by weighting
the labelled data more heavily than the unlabelled
data when estimating model parameters?effectively,
assuming that each labelled item has actually been
observed more than once. However, duplicating the
labelled data does not make sense in the AG frame-
work, because duplicate items will in most cases just
be cached at the root (Word) node, providing no addi-
tional counts of Morphs (which are where the useful
information is). It might be possible to come up with
a different way to weight the labelled data more heav-
ily when larger unlabelled sets are used, however
for this paper we instead kept the labelled data the
same and tuned the amount of unlabelled data. We
used the dev set to choose the amount of unlabelled
data (in the range from 10k to 50k types); results for
semi-supervised AG are reported using the optimal
amount of unlabelled data for each experiment.
For test set experiments with semi-supervised AG,
we evaluated each language using whichever gram-
mar performed best on that language?s dev set. For
test set experiments with AG Select, we chose the
templates with a two-pass procedure. First, we
trained 5 samplers on the 50k training set with la-
belled set added, and used the labelled data to choose
the best template for each inferred grammar. Then,
we decoded the dev set using each of the 5 gram-
mar/template pairs and based on these results, chose
the best of these pairs to decode the test set.
4.5 Results
We present the dev set results in Table 2(a) for trans-
ductive and in Table 2(b) for inductive learning. In
each table, unsupervised models are shown in the
upper section and the semi-supervised models and
AG Select below. Morsel appears only in Table 2(a)
since it only works transductively. Semi-supervised
grammars cannot be trained on German, since we
261
 55
 60
 65
 70
 75
 80
 85
 90
 10000  20000  30000  40000  50000
F-s
cor
e
# of word types
EnglishEstonianFinnishTurkish
 55
 60
 65
 70
 75
 80
 85
 90
 10000  20000  30000  40000  50000
F-s
cor
e
# of word types
EnglishEstonianFinnishTurkish
Figure 2: Effect of training data size on dev set SBF1 for AG Select (left) and semi-supervised SubMorphs grammar
(right) in transductive mode.
only have gold standard analyses, not segmentations.
The SubMorphs grammar performs the best of the
unsupervised AG models, with the Compounding
grammar being only slightly worse. We also tried
the Compounding grammar without the sub-morph
structures but the results were even worse than those
of MorphSeq. This shows that the latent structures
are important for learning good segmentations.
In all cases, the semi-supervised AGs perform bet-
ter (ofen much better) than the corresponding unsu-
pervised grammars. Even though their average scores
are not as high as AG Select?s, they give the best dev
set results in many cases. This shows that although
for semi-supervised AG the grammar must be cho-
sen manually, with a suitable choice of the grammar
and only a small set of labelled data it can improve
considerably over unsupervised AG.
In transductive mode, the AG Select performs the
best in several cases. In both transductive and induc-
tive mode, the results of AG Select are close to the
best results obtained and are consistently good across
all languages?it achieves the best average scores
of all models, suggesting that the model selection
method is robust to different types of morphology
and annotation schemes.
Table 3 presents the test set results. We include
scores for unsupervised Morfessor in both transduc-
tive and inductive mode, where transductive mode
trains on the entire unlabelled corpus and inductive
mode trains on the 50k subset. The semi-supervised
Morfessor scores are taken from the MC results
page13 after verifying that the evaluation method-
13http://research.ics.aalto.fi/events/morphochallenge/
ology and labelled data used is the same as ours.14
There is a good deal of variation between devel-
opment and test results, indicating that the dev sets
may not be a representative sample. The most no-
table differences are in Turkish, where all models
perform far worse on the test than dev set. However,
AG Select performs slightly better on the test set for
the other languages. Thus its average SBF1 score ac-
tually improves on the test set and is not much worse
than semi-supervised Morfessor. While its average
performance drops somewhat on test set EMMA, it
is still as good as any other model on that measure.
Again, these results support the idea that AG Select
is robust to variations in language and data set.
We also note the surprisingly good performance
of Morfessor in transductive mode on Estonian; this
could possibly be due to the larger amount of training
data used for the test set results, but it is not clear
why this would improve performance so much on
Estonian and not on the other languages.
5 Discussion
To give a sense of what the AG Select model is learn-
ing, we provide some examples of both correctly and
incorrectly induced segmentations in Table 4. These
examples suggest that for example in English, M1 is
used to model the stem, M21 is for the suffix or the
second stem in the compound word, and the rest of
the elements in the template are for the remaining
suffixes (if any).
Table 5 presents examples of some of the most
frequently used metagrammar rules and cached rules
14Sami Virpioja, personal communication.
262
(a) Transductive mode Border F1-score EMMA
Eng Est Fin Tur Avg Eng Est Fin Tur Ger Avg
AG MorphSeq 61.5 54.0 56.9 59.5 58.0 74.7 74.1 63.7 53.5 59.4 65.1
AG SubMorphs 66.2 66.9 60.5 59.5 63.3 79.1 83.4 66.8 53.4 57.4 68.0
AG Compounding 63.0 64.8 60.9 60.9 62.4 75.4 81.6 65.5 53.7 62.2 67.7
Morfessor 69.5 55.7 65.0 69.3 64.9 81.3 75.3 67.8 62.2 62.7 69.9
Morsel - - - - - 76.8 74.4 66.1 50.1 55.9 64.7
AG ssv MorphSeq 64.4 57.3 63.0 68.9 63.4 74.4 75.9 65.6 59.6 - -
AG ssv SubMorphs 67.6 69.1 64.4 63.4 66.1 79.5 84.4 69.2 56.1 - -
AG ssv Compounding 70.0 67.5 71.8 - - 79.5 82.8 74.0 - - -
AG Select 71.9 68.5 70.2 72.6 70.8 77.5 81.8 73.2 63.0 62.4 71.6
(b) Inductive mode Border F1-score EMMA
Eng Est Fin Tur Avg Eng Est Fin Tur Ger Avg
AG MorphSeq 57.6 54.0 55.4 59.8 56.7 72.0 73.8 62.6 53.7 58.9 64.2
AG SubMorphs 66.1 67.5 61.6 59.8 63.7 78.6 83.7 67.4 53.4 56.0 67.8
AG Compounding 62.0 64.8 57.4 61.1 61.3 73.5 81.1 61.9 53.2 61.0 66.2
Morfessor 68.9 51.1 63.5 68.2 62.9 80.9 72.0 68.1 60.6 60.8 68.5
AG ssv MorphSeq 64.6 56.9 63.1 70.3 63.8 72.7 73.3 65.9 61.2 - -
AG ssv SubMorphs 70.1 69.7 66.3 67.9 68.4 80.4 83.7 70.5 59.0 - -
AG ssv Compounding 70.5 67.2 70.0 - - 77.3 81.9 70.5 - - -
AG Select 69.8 68.8 67.5 70.1 69.1 77.3 81.9 71.1 59.7 62.6 70.5
Table 2: Dev set results for all models in (a) transductive and (b) inductive mode. Unsupervised AG models and
baselines are shown in the top part of each table; semi-supervised AG models and grammar selection method are below.
Border F1-score EMMA
Eng Est Fin Tur Avg -Est Eng Est Fin Tur Ger Avg -Est/Ger
Morf. trans 67.3 73.9 61.2 57.1 64.9 61.9 78.4 78.8 61.8 49.8 65.2 66.8 63.3
Morf. ind 65.7 57.7 60.8 60.1 61.1 62.2 76.5 70.5 59.6 47.0 64.1 63.5 61.0
Morsel - - - - - - 81.9 77.2 63.3 47.8 59.0 65.8 64.3
Morf. ssv 77.8 - 71.7 68.9 - 72.8 80.6 - 62.1 49.9 - - 64.2
AG ssv best 70.3? 68.6? 64.9? 58.2? 65.5 64.5 75.9? 80.3? 61.3? 46.1? - - 61.1
AG Select 74.4 71.7 70.0 61.4 69.4 68.6 81.3 81.0 64.0 47.5 63.8 67.5 64.3
Table 3: Test set results for unsupervised baselines Morfessor CatMAP (in transductive and inductive mode) and Morsel;
semi-supervised Morfessor; and AG semi-supervised (? marks the Compounding grammar, ? denotes SubMorphs
grammar, and ? is the MorphSeq grammar) and grammar selection methods. Results are shown for each language,
averaged over all languages (when possible: Avg), and averaged over just the languages where scores are available for
all systems (-Est, -Est/Ger).
for English, together with their relative frequencies.
It shows that at the Word level the binary rule is
selected over three times more frequently than the
unary rule. Also, most of the more frequently used
grammar rules expand the first branch (rooted in M1)
into more finegrained structures. The second branch
(M2) is mostly modelled with the unary rule.
Among the frequently cached rules we see the
common English prefixes and suffixes. One of the
most frequent cached rule stores the single letter e at
the end of a word, which often causes oversegmen-
tation of words ending in e (as seen in the incorrect
examples in Table 4). This problem is common in
unsupervised morphological segmentation of English
(Goldwater et al, 2006; Goldsmith, 2001).
We also took a look at the most frequent cached
rules learned by the semi-supervised AG with the
SubMorphs grammar, and observed that Morphs
263
Correct Segmentations Incorrect Segmentations
Word Segmentation Induced Correct
treatable [tr.ea.t]M1 [a.b.le]M21 disagree s dis agree s
disciplined [dis.cip.l.i.n]M1 [e.d]M21 reduc e reduce
monogamous [mon.o.g.a.m]M1 [o.u.s]M21 revalu e re value
streakers [st.r.e.a.k]M1 [e.r]M21 [s]M2211 derid e deride
tollgate [t.o.l.l.]M1 [g.a.t.e]M21 [s]M2211 accompani ed ac compani ed
foxhunting [f.o.x]M1 [h.u.n.t]M21 [ing]M2211 war y wary
muscovites [m.u.sc.o.v]M1 [i.t.e]M21 [s]M2211 indescrib able in describ able
standardizes [st.a.n.d.a.rd]M1 [i.z.e]M21 [s]M2211 orat es orate s
slavers? [sl.a.v]M1 [e.r]M21 [s]M2211 [?]M2212 alger ian s algeri an s
earthiness? [e.ar.th]M1 [i]M2111 [ness]M2211 [?]M2212 disput e s dispute s
instinkt [in.st.in.kt]M1 meister likkust meisterlikkus t
rebis [re.b.i]M1 [s]M2 min a mina
toitsid [to.it]M1 [s.id]M2 teiste teis te
armuavaldus [a.rm.u]M11 [ava.ld.u.s]M12 kuritegu de sse kuri tegu desse
ma?a?givale [ma?a?.g.i]M11 [v.a]M12 [l.e]M2 liharoa ga liha roa ga
keskuskoulussa [kesk.us]M11 [koul.u]M12 [s.sa]M2 polte tti in polte tt i in
perusla?hteille [per.u.s]M11 [l.a?.ht.e]M12 [i]M211 [ll.e]M212 kulttuuri se lt a kin kulttuurise lta kin
perunakaupoista [per.u.n.a]M11 [k.au.p.o]M12 [i]M211 [st.a]M212 tuote palki ntoja tuote palkinto j a
yo?paikkaani [yo?]M11 [p.ai.kk.a]M12 [a]M21 [n.i]M22 veli puo lt a veli puol ta
nimetta?ko?o?n [ni.m.e]M11 [tt.a?]M12 [k.o?]M21 [o?.n]M22 ota ttava otatta va
Table 4: Examples of segmented words in English (top), Estonian (middle) and Finnish (bottom). Correctly segmented
words are in the left part of the table. The identified segments are in brackets indexed by the respective template
nonterminal; dots separate the metagrammar generated parse tree leaves. Examples of incorrectly segmented words
together with the correct segmentation are on the right.
Freq (%) Rule Freq (%) Cached Rule
9.9 Word?M1 M2 1.2 (M2 (M21 (M211 (M2111 s)))))
5.7 M1?M11 M12 0.9 (M2 (M21 (M211 (M2111 e)) (M212 (M2121 d))))
3.1 Word?M1 0.7 (M2 (M21 (M211 (M2111 i)) (M212 (M2121 n g))))
2.5 M11?M111 0.6 (M2 (M21 (M211 (M2111 e)))
1.8 M2?M21 0.4 (M2 (M21 (M211 (M2111 ?))) (M22 (M221 (M2211 s))))
1.4 M12?M121 M122 0.3 (M1112 a)
1.4 M111?M1111 M1112 0.3 (M2 (M21 (M211 (M2111 y))))
0.9 M12?M121 0.3 (M2 (M21 (M211 (M2111 e))) (M212 (M2121 r)))
0.9 M11?M111 M112 0.2 (M2 (M21 (M211 (M2111 a))))
Table 5: Examples from English most frequently used metagrammar rules and cached rules together with their relative
occurrence frequencies (in percentages).
tended to contain only a single SubMorph. This
helps to explain why the SubMorphs grammar in
semi-supervised AG improved less over the unsuper-
vised AG as compared to the MorphSeq grammar?
the rules with only a single SubMorph under the
Morph are essentially the same as they would be in
the MorphSeq grammar.
Finally, we examined the consistency of the tem-
plates chosen for each of the 5 samplers during model
selection for the test set (Section 4.4). We found that
there was some variability in the templates, but in
most experiments the same template was chosen for
the majority of the samplers (see Table 6). While this
majority template is not always the optimal one on
the dev set, we observed that it does produce con-
sistently good results. It is possible that using the
majority template, rather than the optimal template
for the dev set, would actually produce better results
264
Majority template
English M1 M21 M2211 M2212 M222
Finnish M11 M12 M211 M212 M22
Turkish M11 M12 M211 M212 M22
German M11 M121 M122 M21 M221 M222
Estonian M11 M12 M2
Table 6: Majority templates for each language. Note
that the Estonian gold standard contains less fine-grained
segmentations than some of the other languages.
on the test set, especially if (as appears to be the case
here, and may often be the case in real applications)
the dev and test sets are from somewhat different
distributions.
It must be noted that both AG Select and semi-
supervised AG are computationally more demanding
than the comparison systems. Since we do inference
over tree structures, the complexity is cubic in the
input word length, while most segmentation systems
are quadratic or linear. Even compared to the unsu-
pervised AG, AG Select is more expensive, because
of the larger grammar and number of cached symbols.
Nevertheless, our systems can feasibly be run on the
large Morpho Challenge datasets.
Other recent unsupervised systems have reported
state-of-the art results by incorporating additional in-
formation from surrounding words (Lee et al, 2011),
multilingual alignments (Snyder and Barzilay, 2008),
or overlapping context features in a log-linear model
(Poon et al, 2009), but they have only been run on
Semitic languages and English (and in the latter case,
a very small corpus). Since they explicitly enumerate
and sample from all possible segmentations of each
word (often with some heuristic constraints), they
could have trouble with the much longer words of
the agglutinative languages tested here. In any case
the results are not directly comparable to ours.
6 Conclusion
In this paper we have introduced three new meth-
ods for Adaptor Grammars and demonstrated their
usefulness for minimally supervised morphological
segmentation. First, we showed that AG models can
be scaled to large data sets by using the posterior
grammar for defining an inductive model, that on
average results in the same accuracy as compared to
full transductive training.
Second, we implemented semi-supervised AG in-
ference, which uses labelled data to constrain the
sampler, and showed that in all cases it performs
much better than the unsupervised AG on the same
grammar. Semi-supervised AG could benefit from
labelled data reweighting techniques frequently used
in semi-supervised learning, and studying the proper
ways of doing so within the AG framework would be
a potential topic for future research.
Our final contribution is the AG Select method,
where the initial model is trained using a very general
grammar that oversegments the data, and the labelled
data is used to select which granularity of segments to
use. Unlike other morphological segmentation mod-
els, this method can adapt its grammar to languages
with different structures, rather than having to use
the same grammar for every language. Indeed, we
found that AG Select performs well across a range
of languages and also seems to be less sensitive to
differences between data sets (here, dev vs. test). In
addition, it can be trained on either morphological
analyses or segmentations. Although we tuned all
results to optimize the SBF1 metric, in principle the
same method could be used to optimize other mea-
sures, including extrinsic measures on downstream
applications such as machine translation or informa-
tion retrieval. In future we hope to show that this
method can be used to improve performance on such
applications, and also to explore its use for related
segmentation tasks such as stemming or syllabifica-
tion. Also, the method itself could potentially be
improved by designing a classifier to determinine the
best template for each word based on a set of features,
rather than using a single template for all words in
the language.
Acknowledgments
This work was supported by the Tiger University pro-
gram of Estonian Information Technology Founda-
tion for the first author. We thank Constantine Lignos
for releasing his Morsel code to us, Sami Virpioja for
evaluating test set results, and Federico Sangati for
providing useful scripts.
References
Mathias Creutz and Krista Lagus. 2007. Unsupervised
models for morpheme segmentation and morphology
265
learning. ACM Transactions of Speech and Language
Processing, 4(1):1?34, February.
Micha Elsner, Eugene Charniak, and Mark Johnson. 2009.
Structured generative models for unsupervised named-
entity clustering. In Proceedings of NAACL, pages
164?172. Association for Computational Linguistics.
John Goldsmith. 2001. Unsupervised learning of the
morphology of a natural language. Computational Lin-
guistics, 27(2):153?198, June.
Sharon Goldwater, Thomas L. Griffiths, and Mark John-
son. 2006. Interpolating between types and tokens by
estimating power-law generators. In Advances in Neu-
ral Information Processing Systems 18, pages 459?466,
Cambridge, MA. MIT Press.
Eric A. Hardisty, Jordan Boyd-Graber, and Philip Resnik.
2010. Modeling perspective using adaptor grammars.
In Proceedings of EMNLP, pages 284?292. Association
for Computational Linguistics.
Zellig Harris. 1951. Structural Linguistics. University of
Chicago Press.
Yun Huang, Min Zhang, and Chew Lim Tan. 2011. Non-
parametric bayesian machine transliteration with syn-
chronous adaptor grammars. In Proceedings of ACL:
short papers - Volume 2, pages 534?539. Association
for Computational Linguistics.
Mark Johnson and Katherine Demuth. 2010. Unsuper-
vised phonemic chinese word segmentation using adap-
tor grammars. In Proceedings of COLING, pages 528?
536. Association for Computational Linguistics.
Mark Johnson and Sharon Goldwater. 2009. Improving
nonparameteric bayesian inference: experiments on un-
supervised word segmentation with adaptor grammars.
In Proceedings of NAACL, pages 317?325. Association
for Computational Linguistics.
Mark Johnson, Thomas L. Griffiths, and Sharon Gold-
water. 2007. Adaptor grammars: A framework for
specifying compositional nonparametric bayesian mod-
els. In B. Scho?lkopf, J. Platt, and T. Hoffman, editors,
Advances in Neural Information Processing Systems
19, pages 641?648. MIT Press, Cambridge, MA.
Mark Johnson. 2008a. Unsupervised word segmentation
for sesotho using adaptor grammars. In Proceedings
of ACL Special Interest Group on Computational Mor-
phology and Phonology, pages 20?27. Association for
Computational Linguistics.
Mark Johnson. 2008b. Using adaptor grammars to iden-
tify synergies in the unsupervised acquisition of linguis-
tic structure. In Proceedings of ACL, pages 398?406.
Association for Computational Linguistics.
Oskar Kohonen, Sami Virpioja, and Krista Lagus. 2010a.
Semi-supervised learning of concatenative morphology.
In Proceedings of ACL Special Interest Group on Com-
putational Morphology and Phonology, pages 78?86.
Association for Computational Linguistics.
Oskar Kohonen, Sami Virpioja, Laura Leppa?nen, and
Krista Lagus. 2010b. Semi-supervised extensions to
morfessor baseline. In Proceedings of the Morpho
Challenge 2010 Workshop, pages 30?34. Aalto Univer-
sity School of Science and Technology.
Yoong Keok Lee, Aria Haghighi, and Regina Barzilay.
2011. Modeling syntactic context improves morpho-
logical segmentation. In Proceedings of CoNLL, pages
1?9. Association for Computational Linguistics.
Percy Liang, Hal Daume?, III, and Dan Klein. 2008. Struc-
ture compilation: trading structure for features. In
Proceedings of ICML, pages 592?599. Association for
Computing Machinery.
Constantine Lignos. 2010. Learning from Unseen Data.
In Mikko Kurimo, Sami Virpioja, and Ville T. Turunen,
editors, Proceedings of the Morpho Challenge 2010
Workshop, pages 35?38. Aalto University School of
Science and Technology.
Jim Pitman and Marc Yor. 1997. The two-parameter
Poisson-Dirichlet distribution derived from a stable sub-
ordinator. Annals of Probability, 25(2):855?900.
Hoifung Poon, Colin Cherry, and Kristina Toutanova.
2009. Unsupervised morphological segmentation with
log-linear models. In Proceedings of NAACL, pages
209?217. Association for Computational Linguistics.
Benjamin Snyder and Regina Barzilay. 2008. Unsuper-
vised multilingual learning for morphological segmen-
tation. In Proceedings of ACL, pages 737?745. Associ-
ation for Computational Linguistics.
Sebastian Spiegler and Christian Monson. 2010. Emma:
A novel evaluation metric for morphological analysis.
In Proceedings of COLING, pages 1029?1037. Associ-
ation for Computational Linguistics.
Sze-Meng Jojo Wong, Mark Dras, and Mark Johnson.
2012. Exploring adaptor grammars for native language
identification. In Proceedings of EMNLP, pages 699?
709. Association for Computational Linguistics.
266
