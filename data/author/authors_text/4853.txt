Learning Formulation and Transformation Rules for  
Multilingual Named Entities 
Hsin-Hsi Chen Changhua Yang Ying Lin 
Department of Computer Science and Information Engineering 
National Taiwan University 
Taipei, TAIWAN, 106 
{hh_chen, d91013, b88034}@csie.ntu.edu.tw 
Abstract 
This paper investigates three multilingual 
named entity corpora, including named 
people, named locations and named 
organizations.  Frequency-based 
approaches with and without dictionary 
are proposed to extract formulation rules 
of named entities for individual languages, 
and transformation rules for mapping 
among languages.  We consider the issues 
of abbreviation and compound keyword at 
a distance.  Keywords specify not only the 
types of named entities, but also tell out 
which parts of a named entity should be 
meaning-translated and which part should 
be phoneme-transliterated.  An 
application of the results on cross 
language information retrieval is also 
shown. 
1 Introduction 
Named entities are major components of a 
document.  Capturing named entities is a 
fundamental task to understanding documents 
(MUC, 1998).  Several approaches have been 
proposed to recognize these types of terms.  For 
example, corpus-based methods are employed to 
extract Chinese personal names, and rule-based 
methods are used to extract Chinese date/time 
expressions and monetary and percentage 
expressions (Chen and Lee, 1996; Chen, Ding and 
Tsai, 1998).  In the past, named entity extraction 
mainly focuses on general domains and is 
employed to various applications such as 
information retrieval (Chen, Ding and Tsai, 1998), 
question-answering (Lin, et al, 2001), and so on.  
Recently, several attempts have been extended to 
mine knowledge from biomedical documents 
(Hirschman, et al, 2002). 
Most of the previous approaches dealt with 
monolingual named entity extraction.  Chen et al 
(1998) extended it to cross-language information 
retrieval.  A grapheme-based model was proposed 
to compute the similarity between Chinese 
transliteration name and English name.  Lin and 
Chen (2000) further classified the works into two 
directions ? say, forward transliteration (Wan and 
Verspoor, 1998) and backward transliteration 
(Chen et al, 1998; Knight and Graehl, 1998), and 
proposed a phoneme-based model.  Lin and Chen 
(2002) employed a machine learning approach to 
determine phonetic similarity scores for machine 
transliteration.  AI-Onaizan and Knight (2002) 
investigated the translation of Arabic named 
entities to English using monolingual and bilingual 
resources. 
The past works on multilingual named entities 
emphasizes on the transliteration issues.  However, 
the transformation between named entities in 
different languages is not transliteration only.  The 
mapping may be a combination of meaning 
translation and/or phoneme transliteration.  The 
following five English-Chinese examples show 
this issue.  The symbol A ? B denotes a foreign 
name A is translated and/or transliterated into a 
Chinese name B. 
 
(s1) Victoria Fall  
? ?????? (wei duo li ya pu bu) 
(s2) Little Rocky Mountains 
? ????? (xiao luo ji shan mo) 
(s3) Great Salt Lake ? ??? (da yan hu) 
(s4) Kenmare ? ??? (kang mei er) 
(s5) East Chicago ? ???? (dong zhi jia ge) 
 
Example (s1) shows a name part (i.e., Victoria) 
and a keyword part (i.e., Fall) of a named location 
are transliterated and translated into ?????? 
(wei duo li ya) and ???? (pu bu), respectively.  
In Example (s2), the keyword part (i.e., Mountains) 
is still translated, i.e., ???? (shan mo), however, 
some part of name is translated (i.e., Little ? ??? 
(xiao)) and another part is transliterated (i.e., 
Rocky ? ???? (luo ji)).  Example (s3) shows an 
extreme case.  All the three words are translated 
(i.e., Great ? ??? (da)), Salt ? ??? (yan), Lake 
? ??? (hu)).  Examples (s4) and (s5) show two 
location names without keywords.  The former is 
transliterated and the latter is a combination of 
transliteration and translation. 
Which part is translated and which part is 
transliterated depends on the type of named entities.  
For example, personal names tend to be 
transliterated.  For a location name, name part and 
keyword part are usually transliterated and 
translated, respectively.  The organization names 
are totally different.  Most of constituents are 
translated.  Besides the issue of the named entity 
types, different language pairs have different 
transformation rules.  German named entity has 
decompounding problem when it is 
translated/transliterated, e.g., Bundesbahn ? ??
????? (lian bang tie lu ju) and Bundesbank ? 
?????? (lian bang yin hang). 
This paper will study the issues of languages 
and named entity types on the choices of 
translation and transliteration.  We focus on three 
more challenging named entities only, i.e., named 
people, named locations and named organizations.  
Three phrase-aligned corpora will be adopted ? say, 
a multilingual personal name corpus and a 
multilingual organization name corpus compiled 
by Central News Agency (abbreviated CNA 
personal name and organization corpora hereafter), 
and a multilingual location name corpus compiled 
by National Institute for Compilation and 
Translation of Taiwan (abbreviated NICT location 
name corpus hereafter).  We will extract 
transliteration/translation rules from these 
multilingual named corpora.  This paper is 
organized as follows.  Section 2 introduces the 
corpora used.  Section 3 shows how to extract 
formulation rules and the transformation rules.  
Section 4 analyzes the results.  Section 5 
demonstrates the application of the extracted rules 
on cross language information retrieval.  Section 6 
concludes the remarks. 
2 Multilingual Named Entity Corpora 
NICT location name corpus which was developed 
by Ministry of Education of Taiwan in 1995 
collected 19,385 foreign location names.  Each 
entry consists of three parts, including foreign 
location name, Chinese transliteration/translation 
name, and country name, e.g., (Victoria Fall, ??
?????? (wei duo li ya pu bu), South Africa), 
(Little Rocky Mountains, ??????? (xiao luo 
ji shan mo), USA), etc.  The foreign location 
names are in English alphabet.  Some location 
names denoting the same city have more than one 
form like Firenze and Florence for a famous Italian 
city.  The former is an Italian name and the latter is 
its English name.  They correspond to two 
different transliterations in Chinese, respectively, 
i.e., ????? (fei leng cui) and ?????? (fo 
luo lun si).  The pronunciation of the foreign 
names in NICT corpus is based on Webster?s New 
Geographic Dictionary.  The foreign name itself 
may be a transliteration name.  A Japanese city is 
transliterated in English alphabet, but its 
corresponding translation name is in Kanji (Hanzi 
in Japanese).  It is hard to capture their 
relationships except dictionary lookup, so that 
Japanese location name is out of our discussion.  
We employ the country field to select the 
translation/transliteration pairs that we will deal 
with in this paper.  Table 1 summarizes the 
statistics of NICT corpus based on country tags. 
 
Table 1. Statistics of NICT Corpus 
Country Frequency Percentage Country Frequency Percentage
USA 3,012 15.5% Korea 574 3.0%
UK 1,073 5.5% Brazil 433 2.2%
Russia 961 5.0% German 395 2.0%
Japan 796 4.1% Italy 379 2.0%
Canada 692 3.6% Spain 370 1.9%
France 679 3.5% Mexico 324 1.7%
India 679 3.5% Others 8,413 43.5%
Australia 603 3.1% Total 19,385 100%
 
CNA personal name and organization corpora 
are used by news reporters to unify the name 
transliteration/translation in news stories.  There 
are 50,586 pairs of foreign personal names and 
Chinese transliteration/translation in persona name 
corpus.  Different from NICT corpus, there do not 
exist clear cues to identify the nationality of named 
people.  Thus, we could not exclude the Japanese 
names like ?Hayakawa? and the corresponding 
name ??? ? (zao chuan) from our discussion 
automatically.  There are 14,658 named 
organizations in CNA corpus.  Some organization 
names are tagged with the country names to which 
they belong.  For example, ?Aachen Technical 
University? ? ?????? (ya ken ji shu da 
xue) (Germany).  But not all the organization 
names have such country tags.  Comparatively, 
organization names are longer than the other two 
named entities.  Table 2 shows the statistics of 
NICT organization name corpus.  FL denotes the 
length of foreign names in words, CL denotes the 
length of Chinese names in characters, and Count 
denotes the number of foreign names of the 
specified length. 
3 Rule Mining 
3.1 Frequency-Based Approach with a 
Bilingual Dictionary 
We postulate that a transliterated term is usually an 
unknown word, i.e., not listed in a lexicon and a 
translated term often appears in a lexicon.  Under 
this postulation, a translated term occurs more 
often in a corpus, and comparatively, a 
transliterated term only appears very few. 
A simple frequency-based method will 
compute the frequencies of terms and use them to 
tell out the transliteration and translation parts in a 
named entity.  Because Chinese has segmentation 
problem, we start the frequency computation from 
the foreign name part in a multilingual named 
entity corpus.  The method is sketched as follows. 
(1) Compute the word frequencies of each 
word in the foreign name list. 
(2) Keep those words that appear more than a 
threshold and appear in a common foreign 
dictionary (e.g., an English dictionary).  These 
words form candidates of simple keywords. 
(3) Examine the foreign word list again.  
 
Table 2. Statistics of CNA Organization Corpus 
FL Count CL FL Count CL FL Count CL
1 1,773 4.73 7 425 9.94 13 10 14.20 
2 3,622 4.98 8 223 10.50 14 6 12.00 
3 3,751 6.30 9 122 10.98 15 5 17.00 
4 2,406 7.28 10 53 11.57 16 2 14.50 
5 1,434 8.27 11 32 13.41 18 1 9.00 
6 775 8.97 12 17 12.35 20 1 15.00 
 
Those word strings that are composed of simple 
keyword candidates are candidates of compound 
keywords.  We find out the compound keyword set 
by using collocation metric by selecting the most 
frequently occurring compounds through the well-
known elimination of prepositions. 
(4)Because the experimental corpus is aligned, 
we can cluster the Chinese name list based on 
foreign keywords.  For each Chinese name cluster, 
we try to identify the Chinese keyword sets.  Here 
a bilingual dictionary may be consulted. 
The above algorithm extracts foreign/Chinese 
keyword sets from a multilingual named entity 
corpus.  In the meantime, formulation rules for 
foreign names and Chinese counterparts are mined.  
A complete foreign name and a complete Chinese 
name are mapped into name-keyword combination.  
By the way, which method, translation or 
transliteration, is used is also determined. 
Take NICT location name corpus as an 
example.  The terms of frequencies greater than 20 
include River (?, he), Island (?, dao), Lake (?, 
hu), Mountain (?, shan), Bay (?, wan), Mountain 
(?, feng), Peak (?, feng), Islands (??, qun dao), 
Mountains (??, shan mo), Cape (?, jiao), City 
(?, cheng), Range (?, ling), Peninsula (??, ban 
dao), Point (?, jiao), Strait (??, hai xia), River 
(?, chuan), Gulf (?, wan), Cape (?, jia), Pass 
(?? , shan kou), Plateau (?? , gao yuan), 
Headland (?, jia), Harbor (?, gang), Sea (?, hai), 
Promontory (?, jia), and Hills (??, qui ling).  
On the one hand, a foreign location keyword, e.g., 
?Mountain?, may correspond to two Chinese 
location keywords, e.g., ?? ? (shan) and ?? ? 
(feng).  On the other hand, the same Chinese 
location keyword ??? (feng) can be translated into 
two English location keywords ?Mountain? and 
?Peak?. 
Similarly, suffix and prefix for organization 
names can be extracted from CNA organization 
name corpus.  Some high frequent keywords are 
shown as follows. 
(1) Suffix 
Party (?, dang), Association (??, xie 
hui), University (??, da xue), Co. (??, gong 
si), Committee (???, wei yuan hui), Company 
(??, gong si), Bank (??, yia hang), etc. 
(2) Prefix 
International (??, guo ji), World (??, 
shi jie), American (??, mei guo), National (??, 
quan guo), Japan (??, ri ben), National (??, 
guo jia), Asian (??, ya zhou), etc. 
3.2 Keyword Extraction without a Bilingual 
Dictionary 
At the step (4) of the algorithm in Section 3.1, a 
bilingual dictionary is required.  Because 
abbreviation is common adopted in translation, 
dictionary-based approach is hard to capture this 
phenomenon.  A named organization ?World 
Taiwanese Association? which is translated into 
????? (shi tai hui) is a typical example.  The 
term ?World? is translated into an abbreviated term 
??? (shi) rather than a complete term ???? (shi 
jie).  Here another approach without dictionary is 
proposed.  Suppose there are M pairs of (foreign 
name, Chinese name) in a multilingual named 
entity corpus.  The jth pair, 1 ? j ? M, is denoted by 
{Ej, Cj}, where Ej is a foreign named entity, and Cj 
is a Chinese named entity.  Then some Chinese 
segment c ? Cj should be associated with some 
foreign segment e ?  Ej.  Consider the following 
examples. 
 
(s6) Aletschhorn Mountain ? ?????? 
(s7) Catalan Mountain ? ????  
(s8) Cook Strait ? ????  
(s9) Dover, Strait of ?????  
 
We will align ??? (shan) and ???? (hai xia) to 
Mountain and Strait, respectively, from these 
examples. 
We further decompose the named entities.  If 
a named entity Ej comprises m words w1?w2?wm, 
then a candidate segment ep, q is defined as wp ? wq, 
where 1 ? p ? q ? m.  If a Chinese named entity Cj 
has n syllables s1?s2?sn, then a candidate segment 
cx, y is defined as sx ? sy, where 1 ? p ? q ? n.  
Theoretically, we can get 
2
)1(
2
)1( +?+ nnmm pairs of 
{ep, q, cx, y} from {Ej, Cj}.  We then group the pairs 
collected from the multilingual named entity list 
and count the frequency for each occurrence.  
Those pairs with higher frequency denote 
significant segment pairs.  In the above examples, 
both the two pairs {Mountain, ??? (shan)} and 
{Strait, ???? (hai xia)} appear twice, while the 
other pairs appear only once. 
All the pairs {e, c} whose frequency > 2 are 
kept.  Two issues have to be addressed.  The first is: 
redundancy which may exist in the pairs of 
segments should be eliminated carefully.  If a pair 
{e, s1 s2 ? st} occurs k times, then the frequency 
of t?(t+1)/2 substrings (1 ? u ? v ? t) is at least k.  
The second is: e may be translated to more than 
one synonym, which has the same prefix, suffix, or 
infix.  In examples (s10) and (s11), ?Association? 
may be translated into ???? (xie hui) and ???
?? (lian yi hui), where ??? (hui) is a common 
suffix of these two translation equivalents, so that 
its frequency is more than the translation 
equivalents. 
 
(s10) World Trade Association ? ?????? 
(s11) North Europe Chinese Association ?  
??????? 
 
These two issues may be mixed together to make 
this problem more challengeable. 
A metric to deal with the above issues is 
proposed.  The concept is borrowed from tf?idf 
scheme in information retrieval to measure the 
alignment of each foreign segment and the possible 
Chinese translation segments.  Assume there are N 
foreign segments.  Term frequency (tf) of a 
Chinese translation segment ci in e denotes the 
number of occurrences of ci in e.  Document 
frequency (df) of ci is the number of foreign 
segments that ci is translated to.  We prefer to the 
Chinese translation segment that occur frequently 
in a specific foreign segment, but rarely in the 
remainder of foreign segments.  Besides, we also 
prefer the longer Chinese segment, so that the 
length of a Chinese segment, i.e., |ci|, is also 
considered.   
=}),({ icescore  
)1|(|log)(}),({ 2 +?? iii ccidfcef   (1) 
}),{(max
}),({}),({
jj
i
i cetf
cetfcef =   (2) 
)
)(
(log)( 2
i
i cdf
Ncidf = ,   (3) 
For some e, the corresponding Chinese segment c 
is obtained by equation (4). 
}),({maxarg i
c
cescorec
i
=   (4) 
In this way, we can produce a ranking list of pairs 
of (foreign segment, Chinese segment), which 
form multilingual keyword pairs. 
3.3 Extraction of Transformation Rules 
We apply the keyword pairs extracted in the last 
section to the original named entity list.  In (s6)-
(s9), (mountain, ? (shan)) and (strait, ?? (hai 
xia)) are significant keyword pairs.  We replace the 
non-keywords of Ej and Cj with patterns ? and ?, 
respectively, get the following rules. 
 
(s6?) ? mountain ? ? ? 
(s7?) ? mountain ? ? ? 
(s8?) ? Strait ? ??? 
(s9?) ?, Strait of ? ??? 
 
(s6?) and (s7?) can be grouped into a rule.  As a 
result, a set of transformation rules can be 
formulated.  From these examples, Chinese 
location name keyword tends to be located in the 
rightmost and the remaining part is a transliterated 
name.  On the counterpart, foreign location name 
keyword tends to be either located in the rightmost, 
or permuted by some prepositions, comma, and the 
transliterating part. 
3.4 Extraction of Keywords at a Distance 
The algorithm proposed in Section 3.2 can deal 
with single keywords and connected compound 
keywords.  Now we will extend it to keywords at a 
distance.  Consider examples (s12)-(s15) at first. 
 
(s12) American Podiatric medical Association  
? ???????? 
(s13) American Public Health Association 
? ???????? 
(s14) American Society for Industrial Security 
? ???????? 
 (s15) American Society of Newspaper Editors  
? ????????? 
 
(s12) and (s13) show that an English compound 
keyword is separated and so is its corresponding 
Chinese counterpart.  In contrast, the English 
compound keyword is connected in (s14) and (s15), 
but the corresponding Chinese translation is 
separated.  The phenomenon appears quite often in 
the translation of organization names. 
We introduce a symbol ? to cope with the 
distance issue.  The original algorithm is modified 
as follows.  A candidate segment cp, q is defined as 
a string that begins with sp and ends with sq.  Each 
syllable from sp-1 to sq-1 can be replaced by ?.  
Therefore, both ep, q and cx, y are extended to 2(p-q-1), 
and 2(x-y-1) instances, respectively.  For example, 
the following shows some additional instances for 
?American Civil Liberties Union?. 
 
?American ? Liberties Union? 
?American Civil ? Union? 
?American ? Union? 
 
The scoring method, i.e., formulas (1)-(4), is still 
applicable for the new algorithm.  Nevertheless, 
the complexity is different.  The complexity of the 
original algorithm is O(m2n2), but the complexity 
of the algorithm here is O(2m2n), where m is the 
word count for a foreign named entity and n is the 
character count for a Chinese named entity. 
The mining procedure is performed only 
once, and the mined rules are employed in an 
application without being recomputed.  Thus, the 
running time is not the major concern of this paper.  
Besides, the N is bounded in a reasonable small 
number because the length of a named entity is 
always rather shorter than that of a sentence.  Table 
2 shows that 93.88% of foreign names in CNA 
organization name corpus consist of less than 7 
words. 
4 Experimental Results 
The algorithm in Section 3.2 was performed on 
NICT location name corpus, and CNA personal 
name and organization corpora.  With this 
algorithm, we can produce a ranking list of pairs of 
(foreign segment, Chinese segment), which form 
multilingual keyword pairs.  Individual foreign 
segments and Chinese segments are regarded as 
formulation rules for foreign languages and 
Chinese, respectively.  When both the two  
Table 3. Learning Statistics 
 NICT LOC CNA ORG CNA PER
# of records in corpus 18,922 14,658 50,586
# of records for learning 5,714 12,885 100 
Vocabulary size 18,220 11,542 50,315
# of keyword pairs 122 5,229 12 
# of transformation rules 230   
# of successful records 4,262   
 
segments are considered together, they form a 
transformation rule.  Table 3 summarizes the 
results using the frequency-based approach without 
dictionary.  For named locations, there are 18,922 
records, of which, only 5714 records consist of 
more than one foreign word.  In other words, 
13,208 named locations are single words, and they 
are unique, so that we cannot extract keywords 
from these words.  Total 122 keyword pairs are 
identified.  We classify these keyword pairs into 
the following types: 
 
(1) Meaning translation 
Total 69 keywords belong to this type.  It 
occupies 56.56%.  They are further 
classified into three subtypes. 
(a) common location keywords 
 Besides the English location 
keywords mentioned in Section 3.1, 
some location keywords in other 
languages are also captured, including 
Bir ? ? (jing), Ain ? ? (quan), 
Bahr ? ? (he), Cerro ? ? (shan), 
etc. 
(b) direction (e.g., Low  ? ?  (xia), 
Central ? ? (zhong), East  ? ? 
(dong), etc.), size (e.g., Big ? ? 
(da)), length (e.g, Long ? ? 
(zhang)), color (e.g., Black ? ? 
(hei), Blue ? ? (lan), etc.) 
(c) the specificity of place or area such as 
Crystal ? ?? (jie jing), Diamond 
? ?? (zuan shi), etc.  
(2) Phoneme transliteration keywords 
Some morphemes are transliterated such as 
el ? ? (la), Dera ? ?? (de la), Monte  
? ?? (meng te), Los ? ?? (luo si), 
Le ? ? (le), and so on.  Besides, some 
common transliteration names are also 
regarded as keywords, e.g., Elizabeth ? 
???? (yi li sha bai), Edward ? ??? 
(ai de hua), etc.  Total 39 terms belong to 
this type.  It occupies 31.97%. 
(3) Some keywords in type (1) are 
transliterated.  For example, Bay ? ? 
(Bay), Beach ? ?? (bi qi), mountain ? 
?? (meng tan), Little ? ?? (li te), etc.  
Total 14 keywords (11.48%) are extracted. 
Total 230 transformation rules are mined from 
the NICT location corpus.  On the average, a 
keyword pair corresponds to 1.89 transformation 
rules.  Consider a keyword pair mountain ? ? 
(shan) as an example.  Four transformation rules 
shown as follows are learned, where ? and ? 
denote keywords for foreign language and Chinese, 
respectively; ? is a Chinese transliteration of a 
foreign fragment ?; the number enclosed in 
parentheses denotes frequency the rule is applied. 
(1) ?? ? ?? (234) 
(2) ?, ? ? ?? (45) 
(3) ?, ?? ? ?? (1) 
(4) ??? ? ?? (1) 
When we apply the 230 transformation rules back 
to the 5,714 named locations, we can tell out which 
part is transliterated and which part is translated 
from 4,262 named locations.  It confirms our 
postulation that a named location is composed of 
two parts, i.e., one is translated and the other one is 
transliterated. 
Comparatively, there are 50,586 personal 
names in CNA personal names, but only 100 
named people are composed of more than one 
word.  The number of keywords extracted is only a 
few.  They are listed below. 
De ? ? (dai), La ? ? (la), De La ? ?? 
(dai la), Van Der ? ?? (fan de), Du ? ? (du), 
David ? ?? (da wei), Khan ? ? (han), Del ? 
? (dai), Le ? ? (le), Van Den ? ?? (fan 
deng), Di ? ? (di) 
It shows that personal names tend to be 
transliterated and the CNA personal name corpus 
is suitable for training the similarity scores among 
phonetic characters (Lin and Chen, 2002). 
Finally, we consider the named organizations. 
There are 14,658 records in CNA organization 
corpus.  Total 12,885 organization names are 
composed of more than one word.  The percentage, 
87.90%, is the highest among these three corpora.  
Besides that, 5,229 keyword pairs are extracted.  
Most of the keyword pairs are meaning translated.  
This set is also the largest among the three corpora.  
Thus, the keyword pairs are too small and too large 
to find suitable transformation rules for personal 
names and organization names, respectively.  
Although the original idea of our algorithm is 
universal for languages, it should be modified 
slightly for some specific languages.  The 
following takes German as examples.  German 
words have cases and genders.  Most of German 
words are compound.  Consider examples (s16)-
(s19). 
 
(s16) Neue Osnabruecker ? ???????
(s17) Neues Deutschland ? ??? 
(s18) Bundesbahn ? ????? 
(s19) Bundesbank ? ???? 
 
The first two examples show the German adjective 
Neu (New) has different suffixes such as ?-e? and 
?-es? according to the case and gender of the noun.  
The last two examples suggest that morphological 
analysis for decompounding the words into 
meaningful segments is necessary before our 
algorithm. 
 
5 Application on CLIR 
Cross language information retrieval (CLIR) 
facilitates using queries in one language to access 
documents in another.  Because named entities are 
key components of a document, they are usually 
targets that users are interested in.  Figure 1 shows 
an application of the extracted formulation rules 
and transformation rules on Chinese-Foreign CLIR.  
For each document in the Foreign collection, 
named entities are recognized and classified by 
using formulation rules.  They form important 
indices for the related documents.  When a Chinese 
query is issued, the system extracts the possible 
Chinese named entities according to Chinese 
formulation rules.  If keywords are specified in a 
query, we know the structure and the type of the 
named entity.  The lexical structure tells us which 
part is translated and which part is transliterated.   
The backward transliteration method proposed 
by Lin and Chen (2000, 2002) was followed to 
select the most similar English named entity and 
the related documents at the same time.  In Lin and 
Chen?s approach, both Chinese name and English 
candidates will be transformed into a canonical 
form in terms of International Phonetic Alphabets.  
Similarity computation among Chinese query term 
and English candidates are done on phoneme level.  
Figure 1.  A Chinese-Foreign CLIR System 
Foreign 
Document 
Collection 
Query 
Translation/ 
Transliteration 
Information 
Retrieval 
System 
Relevant
Documents
Named Entity
Extractor
Transliteration 
Knowledge 
Bilingual 
Dictionary 
Chinese Query
Chinese-Foreign
Transformation
Rules
Chinese
Formulation
Rules
Foreign
Formulation
Rules
Rule 
Miner 
Multi-Lingual 
Named Entity 
Corpora 
Named Entity
Extractor
That is an expensive operation.  Hopefully, the 
type of Chinese named entity will help to narrow 
down the number of candidate.   
6 Conclusion and Remarks 
This paper proposes corpus-based approaches to 
extract the formulation rules and the translation/ 
transliteration rules among multilingual named 
entities.  Simple frequency-based method identifies 
keywords of named entities for individual 
languages and their correspondence.  The modified 
tf?idf scheme deals with the issues of abbreviation 
and compound keyword at a distance. 
Since the corpora are already phrase-aligned, 
the mined rules cover at least a significant number 
of instances.  That is, they seem to be significant, 
but further evaluation is needed.  Two types of 
evaluation are being conducted, i.e., direct and 
indirect approaches.  In the former, we will 
partition the corpora into two parts, one for 
training and the other one for testing.  In the latter, 
we are integrating our method in a cross language 
information retrieval system.  Given a query 
consisting of Chinese named entity, the Chinese 
formulation rules will tell us its type and lexical 
structures.  The transformation rules show which 
parts should be translated and transliterated.  Our 
previous works on phoneme transliteration is 
integrated.  The transformation result may be 
submitted to an information retrieval system to 
access documents in another language.  In the 
ongoing evaluation, the test bed is supported by 
CLEF (2003).  The result will be reported in 
CLEF2003 after evaluation by CLEF organizer.  
Further applications will be explored in the future 
and the methodology will be extended to other 
types of named entities. 
 
References 
Al-Onaizan, Yaser and Knight, Kevin (2002) 
?Translating Named Entities Using Monolingual and 
Bilingual Resources,? Proceedings of 41st Annual 
Meeting of Association for Computational Linguistics, 
2002, pp. 400-408. 
Chen, Hsin-Hsi and Lee, Jen-Chang (1996) 
?Identification and Classification of Proper Nouns in 
Chinese Texts,? Proceedings of 16th International 
Conference on Computational Linguistics, 1996, pp. 
222-229. 
Chen, Hsin-Hsi; Ding, Yung-Wei and Tsai, Shih-Chung 
(1998) ?Named Entity Extraction for Information 
Retrieval,? Computer Processing of Oriental 
Languages, Special Issue on Information Retrieval 
on Oriental Languages, 12(1), 1998, pp. 75-85. 
Chen, Hsin-Hsi et al (1998) ?Proper Name Translation 
in Cross-Language Information Retrieval,? 
Proceedings of 17th COLING and 36th ACL, pp. 232-
236. 
CLEF (2003) Cross-Language Retrieval in Image 
Collections, Pilot Experiments, 2003. 
Hirschman, L.; Park, J.C.; Tsujii, J.; Wong, L. and Wu, 
C.H. (2002) ?Accomplishments and Challenges in 
Literature Data mining for Biology,? Bioinformatics, 
18(12), pp. 1553-1561. 
Knight, Kevin and Graehl, Jonathan (1998) ?Machine 
Transliteration,? Computational Linguistics, 24(4), 
pp. 599-612. 
Lin, Chuan-Jie; Chen, Hsin-Hsi; et al (2001) ?Open 
Domain Question Answering on Heterogeneous 
Data,? Proceedings of ACL Workshop on Human 
Language Technology and Knowledge Management, 
2001, pp. 79-85. 
Lin, Wei-Hao and Chen, Hsin-Hsi (2000) ?Similarity 
Measure in Backward Transliteration between 
Different Character Sets and Its Application to 
CLIR,? Proceedings of Research on Computational 
Linguistics Conference XIII, pp. 79-113. 
Lin, Wei-Hao and Chen, Hsin-Hsi (2002) ?Backward 
Machine Transliteration by Learning Phonetic 
Similarity,? Proceedings of 6th Conference on 
Natural Language Learning, 2002. 
MUC (1998) Proceedings of 7th Message 
Understanding Conference, 1998, 
http://www.itl.nist.gov/iaui/894.02/related_projects/
muc/index.html. 
Wan, Stephen and Verspoor, Cornelia Maria (1998) 
?Automatic English-Chinese Name Transliteration 
for Development of Multilingual Resources,? 
Proceedings of 17th COLING and 36th ACL, pp. 
1352-1356. 
 
Proceedings of the 43rd Annual Meeting of the ACL, pages 346?353,
Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
Learning Stochastic OT Grammars: A Bayesian approach
using Data Augmentation and Gibbs Sampling
Ying Lin?
Department of Linguistics
University of California, Los Angeles
Los Angeles, CA 90095
yinglin@ucla.edu
Abstract
Stochastic Optimality Theory (Boersma,
1997) is a widely-used model in linguis-
tics that did not have a theoretically sound
learning method previously. In this pa-
per, a Markov chain Monte-Carlo method
is proposed for learning Stochastic OT
Grammars. Following a Bayesian frame-
work, the goal is finding the posterior dis-
tribution of the grammar given the rela-
tive frequencies of input-output pairs. The
Data Augmentation algorithm allows one
to simulate a joint posterior distribution by
iterating two conditional sampling steps.
This Gibbs sampler constructs a Markov
chain that converges to the joint distribu-
tion, and the target posterior can be de-
rived as its marginal distribution.
1 Introduction
Optimality Theory (Prince and Smolensky, 1993)
is a linguistic theory that dominates the field of
phonology, and some areas of morphology and syn-
tax. The standard version of OT contains the follow-
ing assumptions:
? A grammar is a set of ordered constraints ({Ci :
i = 1, ? ? ? , N}, >);
? Each constraint Ci is a function: ?? ?
{0, 1, ? ? ? }, where ?? is the set of strings in the
language;
?The author thanks Bruce Hayes, Ed Stabler, Yingnian Wu,
Colin Wilson, and anonymous reviewers for their comments.
? Each underlying form u corresponds to a set
of candidates GEN(u). To obtain the unique
surface form, the candidate set is successively
filtered according to the order of constraints, so
that only the most harmonic candidates remain
after each filtering. If only 1 candidate is left
in the candidate set, it is chosen as the optimal
output.
The popularity of OT is partly due to learning al-
gorithms that induce constraint ranking from data.
However, most of such algorithms cannot be ap-
plied to noisy learning data. Stochastic Optimality
Theory (Boersma, 1997) is a variant of Optimality
Theory that tries to quantitatively predict linguis-
tic variation. As a popular model among linguists
that are more engaged with empirical data than with
formalisms, Stochastic OT has been used in a large
body of linguistics literature.
In Stochastic OT, constraints are regarded as
independent normal distributions with unknown
means and fixed variance. As a result, the stochastic
constraint hierarchy generates systematic linguistic
variation. For example, consider a grammar with
3 constraints, C1 ? N(?1, ?2), C2 ? N(?2, ?2),
C3 ? N(?3, ?2), and 2 competing candidates for a
given input x:
p(.) C1 C2 C3
x ? y1 .77 0 0 1
x ? y2 .23 1 1 0
Table 1: A Stochastic OT grammar
with 1 input and 2 outputs
346
The probabilities p(.) are obtained by repeatedly
sampling the 3 normal distributions, generating the
winning candidate according to the ordering of con-
straints, and counting the relative frequencies in the
outcome. As a result, the grammar will assign non-
zero probabilities to a given set of outputs, as shown
above.
The learning problem of Stochastic OT involves
fitting a grammar G ? RN to a set of candidates
with frequency counts in a corpus. For example,
if the learning data is the above table, we need to
find an estimate of G = (?1, ?2, ?3)1 so that the
following ordering relations hold with certain prob-
abilities:
max{C1, C2} > C3; with probability .77
max{C1, C2} < C3; with probability .23 (1)
The current method for fitting Stochastic OT mod-
els, used by many linguists, is the Gradual Learn-
ing Algorithm (GLA) (Boersma and Hayes, 2001).
GLA looks for the correct ranking values by using
the following heuristic, which resembles gradient
descent. First, an input-output pair is sampled from
the data; second, an ordering of the constraints is
sampled from the grammar and used to generate an
output; and finally, the means of the constraints are
updated so as to minimize the error. The updating
is done by adding or subtracting a ?plasticity? value
that goes to zero over time. The intuition behind
GLA is that it does ?frequency matching?, i.e. look-
ing for a better match between the output frequen-
cies of the grammar and those in the data.
As it turns out, GLA does not work in all cases2,
and its lack of formal foundations has been ques-
tioned by a number of researchers (Keller and
Asudeh, 2002; Goldwater and Johnson, 2003).
However, considering the broad range of linguistic
data that has been analyzed with Stochastic OT, it
seems unadvisable to reject this model because of
the absence of theoretically sound learning meth-
ods. Rather, a general solution is needed to eval-
uate Stochastic OT as a model for linguistic varia-
tion. In this paper, I introduce an algorithm for learn-
ing Stochastic OT grammars using Markov chain
Monte-Carlo methods. Within a Bayesian frame-
1Up to translation by an additive constant.
2Two examples included in the experiment section. See 6.3.
work, the learning problem is formalized as find-
ing the posterior distribution of ranking values (G)
given the information on constraint interaction based
on input-output pairs (D). The posterior contains all
the information needed for linguists? use: for exam-
ple, if there is a grammar that will generate the exact
frequencies as in the data, such a grammar will ap-
pear as a mode of the posterior.
In computation, the posterior distribution is sim-
ulated with MCMC methods because the likeli-
hood function has a complex form, thus making
a maximum-likelihood approach hard to perform.
Such problems are avoided by using the Data Aug-
mentation algorithm (Tanner and Wong, 1987) to
make computation feasible: to simulate the pos-
terior distribution G ? p(G|D), we augment the
parameter space and simulate a joint distribution
(G, Y ) ? p(G,Y |D). It turns out that by setting
Y as the value of constraints that observe the de-
sired ordering, simulating from p(G,Y |D) can be
achieved with a Gibbs sampler, which constructs a
Markov chain that converges to the joint posterior
distribution (Geman and Geman, 1984; Gelfand and
Smith, 1990). I will also discuss some issues related
to efficiency in implementation.
2 The difficulty of a maximum-likelihood
approach
Naturally, one may consider ?frequency matching?
as estimating the grammar based on the maximum-
likelihood criterion. Given a set of constraints and
candidates, the data may be compiled in the form of
(1), on which the likelihood calculation is based. As
an example, given the grammar and data set in Table
1, the likelihood of d=?max{C1, C2} > C3? can
be written as P (d|?1, ?2, ?3)=
1? ? 0??
? 0
??
1
2pi?2 exp
{
? ~fxy ???~f
Txy
2
}
dx dy
where ~fxy = (x? ?1 + ?3, y ? ?2 + ?3), and ?
is the identity covariance matrix. The integral sign
follows from the fact that both C1 ? C2, C2 ? C3
are normal, since each constraint is independently
normally distributed.
If we treat each data as independently generated
by the grammar, then the likelihood will be a prod-
uct of such integrals (multiple integrals if many con-
straints are interacting). One may attempt to max-
imize such a likelihood function using numerical
347
methods3, yet it appears to be desirable to avoid like-
lihood calculations altogether.
3 The missing data scheme for learning
Stochastic OT grammars
The Bayesian approach tries to explore p(G|D),
the posterior distribution. Notice if we take the
usual approach by using the relationship p(G|D) ?
p(D|G) ? p(G), we will encounter the same prob-
lem as in Section 2. Therefore we need a feasible
way of sampling p(G|D) without having to derive
the closed-form of p(D|G).
The key idea here is the so-called ?missing data?
scheme in Bayesian statistics: in a complex model-
fitting problem, the computation can sometimes be
greatly simplified if we treat part of the unknown
parameters as data and fit the model in successive
stages. To apply this idea, one needs to observe that
Stochastic OT grammars are learned from ordinal
data, as seen in (1). In other words, only one as-
pect of the structure generated by those normal dis-
tributions ? the ordering of constraints ? is used
to generate outputs.
This observation points to the possibility of
treating the sample values of constraints ~y =
(y1, y2, ? ? ? , yN ) that satisfy the ordering relations
as missing data. It is appropriate to refer to them
as ?missing? because a language learner obviously
cannot observe real numbers from the constraints,
which are postulated by linguistic theory. When
the observed data are augmented with missing data
and become a complete data model, computation be-
comes significantly simpler. This type of idea is of-
ficially known as Data Augmentation (Tanner and
Wong, 1987). More specifically, we also make the
following intuitive observations:
? The complete data model consists of 3 random
variables: the observed ordering relations D,
the grammar G, and the missing samples of
constraint values Y that generate the ordering
D.
? G and Y are interdependent:
? For each fixed d, values of Y that respect d
can be obtained easily once G is given: we
just sample from p(Y |G) and only keep
3Notice even computing the gradient is non-trivial.
those that observe d. Then we let d vary
with its frequency in the data, and obtain
a sample of p(Y |G,D);
? Once we have the values of Y that respect
the ranking relations D, G becomes in-
dependent of D. Thus, sampling G from
p(G|Y,D) becomes the same as sampling
from p(G|Y ).
4 Gibbs sampler for the joint posterior ?
p(G, Y |D)
The interdependence of G and Y helps design iter-
ative algorithms for sampling p(G, Y |D). In this
case, since each step samples from a conditional
distribution (p(G|Y,D) or p(Y |G,D)), they can be
combined to form a Gibbs sampler (Geman and Ge-
man, 1984). In the same order as described in Sec-
tion 3, the two conditional sampling steps are imple-
mented as follows:
1. Sample an ordering relation d according to
the prior p(D), which is simply normalized
frequency counts; sample a vector of con-
straint values y = {y1, ? ? ? , yN} from the nor-
mal distributions N(?(t)1 , ?2), ? ? ? , N(?(t)N , ?2)
such that y observes the ordering in d;
2. Repeat Step 1 and obtain M samples of miss-
ing data: y1, ? ? ? , yM ; sample ?(t+1)i from
N(?j yji /M, ?2/M).
The grammar G = (?1, ? ? ? , ?N ), and the su-
perscript (t) represents a sample of G in iteration
t. As explained in 3, Step 1 samples missing data
from p(Y |G,D), and Step 2 is equivalent to sam-
pling from p(G|Y,D), by the conditional indepen-
dence of G and D given Y . The normal posterior
distribution N(?j yji /M, ?2/M) is derived by us-
ing p(G|Y ) ? p(Y |G)p(G), where p(Y |G) is nor-
mal, and p(G) ? N(?0, ?0) is chosen to be an non-
informative prior with ?0 ??.
M (the number of missing data) is not a crucial
parameter. In our experiments, M is set to the total
number of observed forms4. Although it may seem
that ?2/M is small for a large M and does not play
4Other choices of M , e.g. M = 1, lead to more or less the
same running time.
348
a significant role in the sampling of ?(t+1)i , the vari-
ance of the sampling distribution is a necessary in-
gredient of the Gibbs sampler5.
Under fairly general conditions (Geman and Ge-
man, 1984), the Gibbs sampler iterates these two
steps until it converges to a unique stationary dis-
tribution. In practice, convergence can be monitored
by calculating cross-sample statistics from multiple
Markov chains with different starting points (Gel-
man and Rubin, 1992). After the simulation is
stopped at convergence, we will have obtained a
perfect sample of p(G,Y |D). These samples can
be used to derive our target distribution p(G|D) by
simply keeping all the G components, since p(G|D)
is a marginal distribution of p(G,Y |D). Thus, the
sampling-based approach gives us the advantage of
doing inference without performing any integration.
5 Computational issues in implementation
In this section, I will sketch some key steps in the
implementation of the Gibbs sampler. Particular at-
tention is paid to sampling p(Y |G,D), since a direct
implementation may require an unrealistic running
time.
5.1 Computing p(D) from linguistic data
The prior probability p(D) determines the number
of samples (missing data) that are drawn under each
ordering relation. The following example illustrates
how the ordering D and p(D) are calculated from
data collected in a linguistic analysis. Consider a
data set that contains 2 inputs and a few outputs,
each associated with an observed frequency in the
lexicon:
C1 C2 C3 C4 C5 Freq.
x1 y11 0 1 0 1 0 4
y12 1 0 0 0 0 3
y13 0 1 1 0 1 0
y14 0 0 1 0 0 0
x2 y21 1 1 0 0 0 3
y22 0 0 1 1 1 0
Table 2: A Stochastic OT grammar with 2 inputs
The three ordering relations (corresponding to 3
attested outputs) and p(D) are computed as follows:
5As required by the proof in (Geman and Geman, 1984).
Ordering Relation D p(D)?
?
?
C1>max{C2, C4}
max{C3, C5}>C4
C3>max{C2, C4}
.4
?
?
?
max{C2, C4}>C1
max{C2, C3, C5}>C1
C3>C1
.3
max{C3, C4, C5} > max{C1, C2} .3
Table 3: The ordering relations D and p(D)
computed from Table 2.
Here each ordering relation has several conjuncts,
and the number of conjuncts is equal to the number
of competing candidates for each given input. These
conjuncts need to hold simultaneously because each
winning candidate needs to be more harmonic than
all other competing candidates. The probabilities
p(D) are obtained by normalizing the frequencies of
the surface forms in the original data. This will have
the consequence of placing more weight on lexical
items that occur frequently in the corpus.
5.2 Sampling p(Y |G,D) under complex
ordering relations
A direct implementation p(Y |G, d) is straightfor-
ward: 1) first obtain N samples from N Gaussian
distributions; 2) check each conjunct to see if the
ordering relation is satisfied. If so, then keep the
sample; if not, discard the sample and try again.
However, this can be highly inefficient in many
cases. For example, if m constraints appear in the
ordering relation d and the sample is rejected, the
N ?m random numbers for constraints not appear-
ing in d are also discarded. When d has several con-
juncts, the chance of rejecting samples for irrelevant
constraints is even greater.
In order to save the generated random
numbers, the vector Y can be decom-
posed into its 1-dimensional components
(Y1, Y2, ? ? ? , YN ). The problem then becomes
sampling p(Y1, ? ? ? , YN |G,D). Again, we may use
conditional sampling to draw yi one at a time: we
keep yj 6=i and d fixed6, and draw yi so that d holds
for y. There are now two cases: if d holds regardless
of yi, then any sample from N(?(t)i , ?2) will do;
otherwise, we will need to draw yi from a truncated
6Here we use yj 6=i for all components of y except the i-th
dimension.
349
normal distribution.
To illustrate this idea, consider an example used
earlier where d=?max{c1, c2} > c3?, and the ini-
tial sample and parameters are (y(0)1 , y(0)2 , y(0)3 ) =
(?(0)1 , ?(0)2 , ?(0)3 ) = (1,?1, 0).
Sampling dist. Y1 Y2 Y3
p(Y1|?1, Y1 > y3) 2.3799 -1.0000 0
p(Y2|?2) 2.3799 -0.7591 0
p(Y3|?3, Y3 < y1) 2.3799 -0.7591 -1.0328
p(Y1|?1) -1.4823 -0.7591 -1.0328
p(Y2|?2, Y2 > y3) -1.4823 2.1772 -1.0328
p(Y3|?3, Y3 < y2) -1.4823 2.1772 1.0107
Table 4: Conditional sampling steps for
p(Y |G, d) = p(Y1, Y2, Y3|?1, ?2, ?3, d)
Notice that in each step, the sampling density is
either just a normal, or a truncated normal distribu-
tion. This is because we only need to make sure that
d will continue to hold for the next sample y(t+1),
which differs from y(t) by just 1 constraint.
In our experiment, sampling from truncated nor-
mal distributions is realized by using the idea of re-
jection sampling: to sample from a truncated nor-
mal7 pic(x) = 1Z(c) ?N(?, ?) ?I{x>c}, we first find an
envelope density function g(x) that is easy to sam-
ple directly, such that pic(x) is uniformly bounded by
M ? g(x) for some constant M that does not depend
on x. It can be shown that once each sample x from
g(x) is rejected with probability r(x) = 1? pic(x)M ?g(x) ,
the resulting histogram will provide a perfect sample
for pic(x). In the current work, the exponential dis-
tribution g(x) = ? exp {??x} is used as the enve-
lope, with the following choices for ? and the rejec-
tion ratio r(x), which have been optimized to lower
the rejection rate:
? = c+
?c+ 4?2
2?2
r(x) = exp
{(x+ c)2
2 + ?0(x+ c)?
?2?20
2
}
Putting these ideas together, the final version of
Gibbs sampler is constructed by implementing Step
1 in Section 4 as a sequence of conditional sam-
pling steps for p(Yi|Yj 6=i, d), and combining them
7Notice the truncated distribution needs to be re-normalized
in order to be a proper density.
with the sampling of p(G|Y,D). Notice the order in
which Yi is updated is fixed, which makes our imple-
mentation an instance of the systematic-scan Gibbs
sampler (Liu, 2001). This implementation may be
improved even further by utilizing the structure of
the ordering relation d, and optimizing the order in
which Yi is updated.
5.3 Model identifiability
Identifiability is related to the uniqueness of solu-
tion in model fitting. Given N constraints, a gram-
mar G ? RN is not identifiable because G + C
will have the same behavior as G for any constant
C = (c0, ? ? ? , c0). To remove translation invariance,
in Step 2 the average ranking value is subtracted
from G, such that ?i ?i = 0.
Another problem related to identifiability arises
when the data contains the so-called ?categorical
domination?, i.e., there may be data of the follow-
ing form:
c1 > c2 with probability 1.
In theory, the mode of the posterior tends to infin-
ity and the Gibbs sampler will not converge. Since
having categorical dominance relations is a com-
mon practice in linguistics, we avoid this problem
by truncating the posterior distribution8 by I|?|<K ,
where K is chosen to be a positive number large
enough to ensure that the model be identifiable. The
role of truncation/renormalization may be seen as a
strong prior that makes the model identifiable on a
bounded set.
A third problem related to identifiability occurs
when the posterior has multiple modes, which sug-
gests that multiple grammars may generate the same
output frequencies. This situation is common when
the grammar contains interactions between many
constraints, and greedy algorithms like GLA tend to
find one of the many solutions. In this case, one
can either introduce extra ordering relations or use
informative priors to sample p(G|Y ), so that the in-
ference on the posterior can be done with a relatively
small number of samples.
5.4 Posterior inference
Once the Gibbs sampler has converged to its station-
ary distribution, we can use the samples to make var-
8The implementation of sampling from truncated normals is
the same as described in 5.2.
350
ious inferences on the posterior. In the experiments
reported in this paper, we are primarily interested in
the mode of the posterior marginal9 p(?i|D), where
i = 1, ? ? ? , N . In cases where the posterior marginal
is symmetric and uni-modal, its mode can be esti-
mated by the sample median.
In real linguistic applications, the posterior
marginal may be a skewed distribution, and many
modes may appear in the histogram. In these cases,
more sophisticated non-parametric methods, such as
kernel density estimation, can be used to estimate
the modes. To reduce the computation in identifying
multiple modes, a mixture approximation (by EM
algorithm or its relatives) may be necessary.
6 Experiments
6.1 Ilokano reduplication
The following Ilokano grammar and data set, used
in (Boersma and Hayes, 2001), illustrate a complex
type of constraint interaction: the interaction be-
tween the three constraints: ?COMPLEX-ONSET,
ALIGN, and IDENTBR([long]) cannot be factored
into interactions between 2 constraints. For any
given candidate to be optimal, the constraint that
prefers such a candidate must simultaneously dom-
inate the other two constraints. Hence it is not im-
mediately clear whether there is a grammar that will
assign equal probability to the 3 candidates.
/HRED-bwaja/ p(.) ?C-ONS AL IBR
bu:.bwa.ja .33 1 0 1
bwaj.bwa.ja .33 2 0 0
bub.wa.ja .33 0 1 0
Table 5: Data for Ilokano reduplication.
Since it does not address the problem of identifi-
ability, the GLA does not always converge on this
data set, and the returned grammar does not always
fit the input frequencies exactly, depending on the
choice of parameters10.
In comparison, the Gibbs sampler converges
quickly11, regardless of the parameters. The result
suggests the existence of a unique grammar that will
9Note G = (?1, ? ? ? , ?N ), and p(?i|D) is a marginal of
p(G|D).
10B &H reported results of averaging many runs of the algo-
rithm. Yet there appears to be significant randomness in each
run of the algorithm.
11Within 1000 iterations.
assign equal probabilities to the 3 candidates. The
posterior samples and histograms are displayed in
Figure 1. Using the median of the marginal posteri-
ors, the estimated grammar generates an exact fit to
the frequencies in the input data.
0 200 400 600 800 1000?2
?1.5
?1
?0.5
0
0.5
1
1.5
2
2.5
?2 ?1 0 1 20
50
100
150
200
250
300
350
Figure 1: Posterior marginal samples and histograms for
Experiment 2.
6.2 Spanish diminutive suffixation
The second experiment uses linguistic data on Span-
ish diminutives and the analysis proposed in (Arbisi-
Kelm, 2002). There are 3 base forms, each as-
sociated with 2 diminutive suffixes. The gram-
mar consists of 4 constraints: ALIGN(TE,Word,R),
MAX-OO(V), DEP-IO and BaseTooLittle. The data
presents the problem of learning from noise, since
no Stochastic OT grammar can provide an exact fit
to the data: the candidate [ubita] violates an extra
constraint compared to [liri.ito], and [ubasita] vio-
lates the same constraint as [liryosito]. Yet unlike
[lityosito], [ubasita] is not observed.
Input Output Freq. A M D B
/uba/ [ubita] 10 0 1 0 1
[ubasita] 0 1 0 0 0
/mar/ [marEsito] 5 0 0 1 0
[marsito] 5 0 0 0 1
/liryo/ [liri.ito] 9 0 1 0 0
[liryosito] 1 1 0 0 0
Table 6: Data for Spanish diminutive suffixation.
In the results found by GLA, [marEsito] always
has a lower frequency than [marsito] (See Table 7).
This is not accidental. Instead it reveals a problem-
atic use of heuristics in GLA12: since the constraint
B is violated by [ubita], it is always demoted when-
ever the underlying form /uba/ is encountered dur-
ing learning. Therefore, even though the expected
12Thanks to Bruce Hayes for pointing out this problem.
351
model assigns equal values to ?3 and ?4 (corre-
sponding to D and B, respectively), ?3 is always
less than ?4, simply because there is more chance
of penalizing D rather than B. This problem arises
precisely because of the heuristic (i.e. demoting
the constraint that prefers the wrong candidate) that
GLA uses to find the target grammar.
The Gibbs sampler, on the other hand, does not
depend on heuristic rules in its search. Since modes
of the posterior p(?3|D) and p(?4|D) reside in neg-
ative infinity, the posterior is truncated by I?i<K ,
with K = 6, based on the discussion in 5.3. Re-
sults of the Gibbs sampler and two runs of GLA13
are reported in Table 7.
Input Output Obs Gibbs GLA1 GLA2
/uba/ [ubita] 100% 95% 96% 96%
[ubasita] 0% 5% 4% 4%
/mar/ [marEsito] 50% 50% 38% 45%
[marsito] 50% 50% 62% 55%
/liryo/ [liri.ito] 90% 95% 96% 91.4%
[liryosito] 10% 5% 4% 8.6%
Table 7: Comparison of Gibbs sampler and GLA
7 A comparison with Max-Ent models
Previously, problems with the GLA14 have inspired
other OT-like models of linguistic variation. One
such proposal suggests using the more well-known
Maximum Entropy model (Goldwater and Johnson,
2003). In Max-Ent models, a grammar G is also
parameterized by a real vector of weights w =
(w1, ? ? ? , wN ), but the conditional likelihood of an
output y given an input x is given by:
p(y|x) = exp{
?
i wifi(y, x)}?
z exp{
?
i wifi(z, x)}
(2)
where fi(y, x) is the violation each constraint as-
signs to the input-output pair (x, y).
Clearly, Max-Ent is a rather different type of
model from Stochastic OT, not only in the use
of constraint ordering, but also in the objective
function (conditional likelihood rather than likeli-
hood/posterior). However, it may be of interest to
compare these two types of models. Using the same
13The two runs here both use 0.002 and 0.0001 as the final
plasticity. The initial plasticity and the iterations are set to 2
and 1.0e7. Slightly better fits can be found by tuning these pa-
rameters, but the observation remains the same.
14See (Keller and Asudeh, 2002) for a summary.
data as in 6.2, results of fitting Max-Ent (using con-
jugate gradient descent) and Stochastic OT (using
Gibbs sampler) are reported in Table 8:
Input Output Obs SOT ME MEsm
/uba/ [ubita] 100% 95% 100% 97.5%
[ubasita] 0% 5% 0% 2.5%
/mar/ [marEsito] 50% 50% 50% 48.8%
[marsito] 50% 50% 50% 51.2%
/liryo/ [liri.ito] 90% 95% 90% 91.4%
[liryosito] 10% 5% 10% 8.6%
Table 8: Comparison of Max-Ent and Stochastic OT models
It can be seen that the Max-Ent model, in the ab-
sence of a smoothing prior, fits the data perfectly by
assigning positive weights to constraints B and D. A
less exact fit (denoted by MEsm) is obtained when
the smoothing Gaussian prior is used with ?i = 0,
?2i = 1. But as observed in 6.2, an exact fit is im-
possible to obtain using Stochastic OT, due to the
difference in the way variation is generated by the
models. Thus it may be seen that Max-Ent is a more
powerful class of models than Stochastic OT, though
it is not clear how the Max-Ent model?s descriptive
power is related to generative linguistic theories like
phonology.
Although the abundance of well-behaved opti-
mization algorithms has been pointed out in favor
of Max-Ent models, it is the author?s hope that the
MCMC approach also gives Stochastic OT a sim-
ilar underpinning. However, complex Stochastic
OT models often bring worries about identifiability,
whereas the convexity property of Max-Ent may be
viewed as an advantage15.
8 Discussion
From a non-Bayesian perspective, the MCMC-based
approach can be seen as a randomized strategy for
learning a grammar. Computing resources make it
possible to explore the entire space of grammars and
discover where good hypotheses are likely to occur.
In this paper, we have focused on the frequently vis-
ited areas of the hypothesis space.
It is worth pointing out that the Graduate Learning
Algorithm can also be seen from this perspective.
An examination of the GLA shows that when the
plasticity term is fixed, parameters found by GLA
also form a Markov chain G(t) ? RN , t = 1, 2, ? ? ? .
Therefore, assuming the model is identifiable, it
15Concerns about identifiability appear much more fre-
quently in statistics than in linguistics.
352
seems possible to use GLA in the same way as the
MCMC methods: rather than forcing it to stop, we
can run GLA until it reaches stationary distribution,
if it exists.
However, it is difficult to interpret the results
found by this ?random walk-GLA? approach: the
stationary distribution of GLA may not be the target
distribution ? the posterior p(G|D). To construct
a Markov chain that converges to p(G|D), one may
consider turning GLA into a real MCMC algorithm
by designing reversible jumps, or the Metropolis al-
gorithm. But this may not be easy, due to the diffi-
culty in likelihood evaluation (including likelihood
ratio) discussed in Section 2.
In contrast, our algorithm provides a general solu-
tion to the problem of learning Stochastic OT gram-
mars. Instead of looking for a Markov chain in RN ,
we go to a higher dimensional space RN ?RN , us-
ing the idea of data augmentation. By taking advan-
tage of the interdependence of G and Y , the Gibbs
sampler provides a Markov chain that converges to
p(G,Y |D), which allows us to return to the original
subspace and derive p(G|D) ? the target distribu-
tion. Interestingly, by adding more parameters, the
computation becomes simpler.
9 Future work
This work can be extended in two directions. First,
it would be interesting to consider other types of
OT grammars, in connection with the linguistics lit-
erature. For example, the variances of the normal
distribution are fixed in the current paper, but they
may also be treated as unknown parameters (Nagy
and Reynolds, 1997). Moreover, constraints may be
parameterized as mixture distributions, which rep-
resent other approaches to using OT for modeling
linguistic variation (Anttila, 1997).
The second direction is to introduce informative
priors motivated by linguistic theories. It is found
through experimentation that for more sophisticated
grammars, identifiability often becomes an issue:
some constraints may have multiple modes in their
posterior marginal, and it is difficult to extract modes
in high dimensions16. Therefore, use of priors is
needed in order to make more reliable inferences. In
addition, priors also have a linguistic appeal, since
16Notice that posterior marginals do not provide enough in-
formation for modes of the joint distribution.
current research on the ?initial bias? in language ac-
quisition can be formulated as priors (e.g. Faithful-
ness Low (Hayes, 2004)) from a Bayesian perspec-
tive.
Implementing these extensions will merely in-
volve modifying p(G|Y,D), which we leave for fu-
ture work.
References
Anttila, A. (1997). Variation in Finnish Phonology and Mor-
phology. PhD thesis, Stanford University.
Arbisi-Kelm, T. (2002). An analysis of variability in Spanish
diminutive formation. Master?s thesis, UCLA, Los Angeles.
Boersma, P. (1997). How we learn variation, optionality, prob-
ability. In Proceedings of the Institute of Phonetic Sciences
21, pages 43?58, Amsterdam. University of Amsterdam.
Boersma, P. and Hayes, B. P. (2001). Empirical tests of the
Gradual Learning Algorithm. Linguistic Inquiry, 32:45?86.
Gelfand, A. and Smith, A. (1990). Sampling-based approaches
to calculating marginal densities. Journal of the American
Statistical Association, 85(410).
Gelman, A. and Rubin, D. B. (1992). Inference from iterative
simulation using multiple sequences. Statistical Science,
7:457?472.
Geman, S. and Geman, D. (1984). Stochastic relaxation,
Gibbs distributions, and the Bayesian restoration of images.
IEEE Trans. on Pattern Analysis and Machine Intelligence,
6(6):721?741.
Goldwater, S. and Johnson, M. (2003). Learning OT constraint
rankings using a Maximum Entropy model. In Spenader,
J., editor, Proceedings of the Workshop on Variation within
Optimality Theory, Stockholm.
Hayes, B. P. (2004). Phonological acquisition in optimality the-
ory: The early stages. In Kager, R., Pater, J., and Zonneveld,
W., editors, Fixing Priorities: Constraints in Phonological
Acquisition. Cambridge University Press.
Keller, F. and Asudeh, A. (2002). Probabilistic learning
algorithms and Optimality Theory. Linguistic Inquiry,
33(2):225?244.
Liu, J. S. (2001). Monte Carlo Strategies in Scientific Com-
puting. Number 33 in Springer Statistics Series. Springer-
Verlag, Berlin.
Nagy, N. and Reynolds, B. (1997). Optimality theory and vari-
able word-final deletion in Faetar. Language Variation and
Change, 9.
Prince, A. and Smolensky, P. (1993). Optimality Theory: Con-
straint Interaction in Generative Grammar. Forthcoming.
Tanner, M. and Wong, W. H. (1987). The calculation of poste-
rior distributions by data augmentation. Journal of the Amer-
ican Statistical Association, 82(398).
353
