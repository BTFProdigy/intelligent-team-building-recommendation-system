The TELRI tool catalogue: structure and prospects
Tomaz? Erjavec
Dept. of Intelligent Systems
Institute ?Joz?ef Stefan?
Jamova 39
SI-1000 Ljubljana, Slovenia
tomaz.erjavec@ijs.si
Tama?s Va?radi
Linguistics Institute
Hungarian Academy of Sciences
P.O.Box 701/518
Budapest H-1399, Hungary
varadi@nytud.hu
Abstract
In the scope of the TELRI concerted
action a working group is investigat-
ing the formation of a tool catalogue
and repository. The idea is similar to
that of the ACL Natural Language Soft-
ware Registry, but the contents should
be mostly limited to corpus processing
tools available free of cost for research
use. The catalogue should also offer
a help-line for installing and using the
software. The paper reports on the set-
up of this catalogue, and concentrates
on the technical issues involved in its
creation, storage and display. This in-
volves the form interface on the Web,
the XML DocBook encoding, and the
XSL stylesheets used to present the cat-
alogue either on the Web or in print.
The paper lists the current entries in the
catalogue and discusses plans for their
expansion and maintenance.
1 Introduction
The ?Trans-European Language Resources In-
frastructure?, TELRI (http://www.telri.de/), is a
pan-European alliance of focal national language
(technology) institutions with the emphasis on
Central and Eastern European and NIS countries.
Some of the main objectives of TELRI is to col-
lect, promote, and make available monolingual
and multilingual language resources and tools
for the extraction of language data and linguis-
tic knowledge; to provide a forum where experts
from academia and industry share and assess tools
and resources; and to make available the expertise
of its partner institutions to the research commu-
nity, to language industry and to the general pub-
lic.
A number of these goals is being served
by the ?TELRI Research Archive of Com-
putational Tools and Resources?, TRACTOR,
(http://www.tractor.de), which features monolin-
gual, bilingual, and multilingual corpora and lex-
ica in a wide variety of languages as well as
corpus- and lexicon-related software. While the
primary aim is to pool the resources of TELRI
partners, TRACTOR also serves other institutions
by making the resources and tools available to the
wider research and educational community.
While the TRACTOR archives already offer a
number of tools, the longer term objective is to
offer a more substantial catalogue of corpus and
lexicon processing software. Furthermore, the
software itself is not necessarily available directly
from TRACTOR, which would also have a more
formalised structure and a well-defined process
of updating and presenting its entries. A closely
related initiative and model for this effort is the
?The Natural Language Software Registry? of the
ACL hosted at DFKI, a new edition of which was
released in 2000 (Declerck et al, 2000). While
the ACL registry offers a much larger array of
tools, the TELRI catalogue should have the ad-
vantage that each entry also contains a pointer to
the TELRI member who is able to offer advice on
installing and using the tool in question.
Other related catalogues on the Web
are the CTI?s Guide to Digital Resources
(http://info.ox.ac.uk/ctitext/resguide/) which has
a section on Text Analysis Tools and Techniques.
However, it does not seem to be maintained any
longer.
The Summer Institute of Linguistics
(http://www.sil.org/computing/catalog/) also
hosts a repository containing more than 60
pieces of software developed at SIL. Most of the
software is available for free download; the latest
update to the pages comes spring 1999.
A view on sharing resources, very much
based on latest standardisation initiatives, has
been developed by the Open Language Archives
Community, OLAC, (Bird and Simons, 2000),
http://www.language-archives.org/. OLAC is an
international project to construct an infrastructure
aimed at opening the whole array of language re-
sources, including texts, recordings, lexicons, an-
notations, software, protocols, models, and for-
mats. OLAC aims to develop community-specific
metadata to link language archives and establish
centralized catalogs. It builds directly on two
other initiatives, namely the the Open Archives
Initiative (developing and promoting interoper-
ability standards for efficient dissemination of
content) and the Dublin Core Metadata Initia-
tive (development of interoperable online meta-
data standards).
In the scope of the TELRI-II concerted action,
a working group has been set up to design a cata-
logue of corpus processing tools, and this paper
reports on the preliminary results of the work-
ing group. The rest of the paper is structured as
follows: Section 2 gives the overall structure of
the catalogue and its entries; Section 3 explains
the pipeline for updating and displaying the cat-
alogue, i.e. the Web form interface for input, ed-
itorial policy, and the stylesheet mechanism for
display; Section 4 lists the current contents of the
catalogue, while Section 5. gives some conclu-
sions and outlines plans for its expansion and fur-
ther maintenance.
2 Catalogue Format
The overall encoding chosen for the catalogue
was DocBook, an SGML/XML DTD primar-
ily used for encoding computer manuals and
other technical documentation. Choosing an
SGML/XML framework follows a similar strand
of research in annotating linguistic resources, as
exemplified in the XML version of the Corpus
Encoding Standard (Nancy et al, 2000) and in
work on syntactic annotation (Nancy and Romary,
2001). An advantage of XML is the possibility
of further standardisation by the use of related
recommendations, i.e. the XML Stylesheet Lan-
guage.
DocBook has a large user base and is well
documented: a reference book has been pub-
lished and is available on-line (Walsh, 1999)
for browsing or downloading. There is also an
interesting public initiative utilising DocBook,
namely the Linux Documentation Project, LDP
(http://www.linuxdoc.org/), which is working on
developing free, high quality documentation for
the GNU/Linux operating system.
Because DocBook is an application of SGML,
and, more recently, XML, many freely available
tools are available to process it. Most importantly,
this includes XSL processors, which can be used
to render DocBook documents in, say, HTML or
PDF; this issue is further elaborated in Section 4.
The complete catalogue is represented as one
<book> element, with introductory matter in
<bookinfo> giving the name, release informa-
tion and some other general information about
the catalogue. The catalogue is then divided (at
present) into three <chapter> elements, each
giving a a certain type of tools we plan to address:
 morpho-syntactic taggers
 concordancers
 aligners
Each catalogue entry is contained in
<sect1>, the top-level section element.
The section, besides containing a <title>
and being marked with an ID, is composed of
two <sect2> elements. The first gives the
information that is common to all sorts of tools,
while the second is tool-type specific.
The information records are encoded as <for-
malpara>, where each such element has a
<title>, followed by the text of the of the
record as a <para>. Various other DocBook el-
ements are used to annotate pieces of informa-
tion, e.g. <address>, <affiliation> and
similar details. Table 1 gives as an example a
complete dummy catalogue entry, where variable
parts are prefixed by ?this is?.
<sect1 id="this_is_name_971886394">
<title><productname>this is name</productname></title>
<sect2><title>Common part</title>
<formalpara><title>Task</title>
<para>this is task
<indexterm><primary>this is task</primary></indexterm></para></formalpara>
<formalpara><title>Author(s)</title>
<para>this is author</para></formalpara>
<formalpara><title>Institute/Company</title>
<para>
<address>
<affiliation><orgname>this is affil</orgname></affiliation>
<street>this is street</street>
<city>this is city</city>
<country>this is country</country></address></para></formalpara>
<formalpara><title>Version</title>
<para>this is version</para></formalpara>
<formalpara><title>Interface</title>
<para>this is interface</para></formalpara>
<sect3><title>Implementation</title>
<formalpara><title>Platform</title>
<para><hardware>this is platform</hardware></para></formalpara>
<formalpara><title>Operating system</title>
<para><envar>this is os</envar></para></formalpara>
<formalpara><title>Language of implementation</title>
<para>this is impl</para></formalpara></sect3>
<sect3><title>License</title>
<formalpara><title>License conditions for research purposes</title>
<para>this is licres</para></formalpara>
<formalpara><title>License conditions for commercial purposes</title>
<para>this is liccom</para></formalpara>
<formalpara><title>Restrictions</title>
<para>this is restrict</para></formalpara></sect3>
<sect3><title>Distribution</title>
<formalpara><title>Availability of source code</title>
<para>
<ulink url="this is source_url">this is source_url</ulink></para></formalpara>
<formalpara><title>Download possibilities and formats</title>
<para>
<ulink url="this is binary_url">this is binary_url</ulink>
</para></formalpara></sect3>
<sect3><title>References</title>
<formalpara><title>Homepage</title>
<para><ulink url="this is homepage">this is home-
page</ulink></para></formalpara>
<formalpara><title>Language of documentation</title>
<para>this is doc_lang</para></formalpara></sect3>
<sect3><title>TELRI helpline</title>
<para>this is helpline</para></sect3>
</sect2>
<sect2><title>Tool specific part</title>
<formalpara><title>Description</title>
<para>this is description</para></formalpara>
</sect2>
</sect1>
Table 1: Example of entry in DocBook produced via the form interace
3 Catalogue input and output
While the initial catalogue was input di-
rectly with an SGML editor and then vali-
dated, the envisioned additions will be per-
formed via a Web form interface, available at
http://gnu.nytud.hu/telri/. Figure 1 displays the
top part of the screenshot of the HTML form de-
signed to collect the specification of description
of catalogue items.
The definition of the particular information
sought about the software tools required some
consideration. Obviously, we would like to have
as detailed a description of each item as possible.
On the other hand, one has to bear in mind that the
TELRI Catalogue will appeal for free voluntary
contributions. Hence, the form should be maxi-
mally easy to fill in with minimal effort in order
to avoid possibly deterring people from contribut-
ing who might otherwise have done so. The cru-
cial factor to consider was to find the right balance
between the set of required and optional items. In
the end, the required information fields were con-
fined to the bare minimum of name, task, descrip-
tion and TELRI helpline. Table 2 displays the full
list of questions used in the HTML form.
The form interface runs a Perl CGI script,
which mails the output, encoded as the above de-
scribed DocBook <sect1> element, to the ed-
itors of the catalogue. After checking, fresh en-
tries are included in the official release of the cat-
alogue.
The DocBook format is suitable for storage
and interchange, but it is, of course, not appro-
priate for displaying the information. However,
one of the benefits of using standardised solutions
is that conversion tools and specifications are, to
a large extent, already available. For presenta-
tion, we have been so far experimenting with the
XML Stylesheet Language, XSL, or, more pre-
cisely, XSLT, the XSL Transformation Language,
(W3C, 2000). XSLT is a recommendation of the
W3C and is a language for transforming XML
documents into other XML documents. There al-
ready exist several freely available XSLT proces-
sors, e.g., Xalan (http://xml.apache.org/xalan/),
produced by the Apache XML Project.
XSLT is most often used to produce HTML
output for viewing on the Web, and so called
Formatted Objects, which are then further
transformed into print formats, usually PDF.
For DocBook XML there exist ready-made
stylesheets for both kinds of output, made by
Norman Walsh and available at on the Web
(http://nwalsh.com/docbook/xsl/). In the current
version we have used these ?out of the box? tools
to render the catalogue, although some slight
modifications would be in order to produce out-
put better tailored to the catalogue application.
Figure 2 contains a sample HTML output of
one item in the Catalogue.
In summary, Figure 3 gives a graphical
overview of the data processing of the TELRI
Catalogue items.
4 Catalogue Contents
The catalogue currently contains only a few sam-
ple entries, which, nevertheless, exemplify the
kinds of software that are to be most relevant for
inclusion into the catalogue:
 tools that at least one TELRI partner has ex-
perience in using and that the partner is will-
ing to support for new users
 tools that are available free of cost, at least
for academic purposes and, preferably, are
open source
 tools that are language independent or adapt
easily to new languages
 tools that are primarily meant for corpus pro-
cessing
At present, the catalogue lists the following
tools:
 The morpho-syntactic tagger TnT (Brants,
2000)
A robust and very efficient statistical part-
of-speech tagger that is trainable on differ-
ent languages and on virtually any tagset. It
is available by a license agreement which is
free of charge for non-commercial purposes.
Distribution is available, in binaries only, for
Linux and SunOS/Solaris.
Figure 1: The TELRI Catalogue HTML form
*name = Name of product
*task = Task of product
author = Name(s) of author(s)
affiliation = Name of company
street = Address of company
city
country
version = Version number
language = Language(s)
*description
licres = License conditions for research purposes
liccom = License conditions for commercial purposes
restrict = License restrictions
source url = URL of source code
binary url = URL of binary files
platform = Supported hardware
os = Supperted operating system(s)
impl = Language of implementation
interface = User interface
homepage = URL of homepage
doc url = URL of documentation
doc lang = Language of documentation
*helpline = TELRI helpline
Table 2: Full list of fields of the Catalogue HTML form
Figure 2: A sample output page of one Catalogue item
user input User?readableformats:
html, pdf etc.
DocBook
XML
Perl/CGI XSLTHTML?form
Figure 3: Overview of the catalogue data processing
 The IMS Corpus Workbench concordancer
(Christ, 1994)
Comprises a powerful Corpus Query Proces-
sor and a graphical user interface. It is avail-
able by a license agreement which is free of
charge for non-commercial purposes. Distri-
bution, in binary form only, is available for
Linux and SunOS/Solaris.
 The Vanilla sentence aligner (Danielsson
and Ridings, 1997)
A simple but useful program that aligns
a parallel corpus by comparing sentence
lengths in characters by dynamic time-
warping. The program assumes that hard
boundaries are correctly aligned and per-
forms alignment on soft boundaries. It is
freely available with C source code distribu-
tion.
 The Twente Word Aligner (Hiemstra, 1998)
The program constructs a bilingual lexicon
from a parallel sentence aligned corpus. The
translations are ranked according to com-
puted confidence. The system uses statisti-
cal measures and works for single words (to-
kens) only. It is available under the GNU
General Public License and is written in C.
 PLUG Word Aligner (Ahrenberg et al,
1998)
The system integrates a set of modules for
knowledge-lite approaches to word align-
ment, with various possibilities to change
configuration and to adapt the system to
other language pairs and text types. The
system takes a parallel sentence aligned cor-
pus as input and produces a list of word and
phrase correspondences in the text (link in-
stances) and additionally a bilingual lexicon
from these instances (type links). It is avail-
able by a license agreement which is free of
charge for non-commercial purposes. Distri-
bution is available, in binary form only, for
Linux and MS Windows.
5 Conclusions
The paper reported on the set-up of the TELRI
corpus-tool catalogue, concentrating on the tech-
nical issues involved in its creation (form inter-
face), storage (DocBook) and display (XSLT). At
present, the input form is operational and the cata-
logue contains a few sample entries and has a pre-
liminary (default) rendering of its contents. The
current version of the catalogue and templates is
available at http://nl.ijs.si/telri/
In the future, we hope to flesh out the cat-
alogue with more tools, and enlist the services
of TELRI experts in providing user support for
them. The catalogue will, where license permits,
also archive a copy of the software, and will con-
tinue with a proactive adoption of the GNU li-
cense and open standards.
The open (non-profit) nature of the tools we
attempt to identify lends them well for pedago-
cial purposes at the graduate and undergraduate
courses in natural language processing, corpus
linguistics and language engineering.
The tool catalogue, as well as TRACTOR,
could also be made a part of the Open Language
Archives Community mentioned in the introduc-
tion. To join OLAC a number of changes and
mappings would have to be defined, say from the
on-line form onto Dublin Core and the OLAC
Metadata Set. The choices currently listed in the
template could also be changed into a controlled
vocabulary to facilitate searching.
The process of catalogue updates is currently
manual. To automate the production of the on-
line version of the catalogue directly from new
form entries would be relatively easy, given suf-
ficient volume to justify this. More challeng-
ing would be (semi)automatic tracking of new
tools that become available via various (OLAC)
archives and announcements.
Acknowledgements
The authors would like to thank Inguna Greitane
for her exposition of the catalogue structure vo-
cabulary, Laurent Romary for his invaluable assis-
tance with everything XSLT; and Victor Nagy for
his technical assistance in preparing the HTML
form and the CGI script.
Thanks also to the anonymous reviewers for
their valuable comments on the previous version
of the paper; for all remaining errors, only the au-
thors are to blame.
The work report here was supported by the
Copernicus TELRI-II concerted action.
References
Lars Ahrenberg, Mikael Andersson, and Magnus
Merkel. 1998. A simple hybrid aligner for gener-
ating lexical correspondences in parallell texts. In
COLING/ACL.
Steven Bird and Gary Simons. 2000. Open language
archives community. ElsNews, 9(4).
Thorsten Brants. 2000. Tnt - a statistical part-
of-speech tagger. In Proceedings of the Sixth
Applied Natural Language Processing Conference
ANLP-2000, Seattle, WA. http://www.coli.uni-
sb.de/?thorsten/tnt/.
Oliver Christ. 1994. A modular and flexible archi-
tecture for an integrated corpus query system. In
Proceedings of COMPLEX ?94: 3rd Conference
on Computational Lexicography and Text Research,
Budapest, Hungary. CMP-LG archive id 9408005.
Pernilla Danielsson and Daniel Ridings. 1997. Prac-
tical presentation of a ?vanilla? aligner. In Pre-
sented at the TELRI Workshop on Alignment and
Exploitation of Texts. Institute Joz?ef Stefan, Ljubl-
jana. http://nl.ijs.si/telri/Vanilla/doc/ljubljana/.
Thierry Declerck, Alexander Werner Jachmann, and
Hans Uszkoreit. 2000. The new edition of the
natural language software registry (an initiative
of acl hosted at dfki). In Second International
Conference on Language Resources and Evalua-
tion, LREC?00, pages 1129?1132. Paris. ELRA.
http://registry.dfki.de/.
Djoerd Hiemstra. 1998. Multilingual domain mod-
eling in Twenty-One: automatic creation of a bi-
directoral translation lexicon from a parallel cor-
pus. In Proceedings Computational Linguistics in
the Nederlands, pages 41?57. Nijmegen.
Ide Nancy and Laurent Romary. 2001. A Com-
mon Framework for Syntactic Annotation. In ACL,
Toulouse.
Ide Nancy, Laurent Romary, and Patrice Bonhomme.
2000. CES/XML : An XML-based Standard for
Linguistic Corpora. In Second International Con-
ference on Language Resources and Evaluation,
LREC?00, pages 825?830. Paris. ELRA.
W3C. 2000. Extensible stylesheet language (XSL)
version 1.0. URL. http://www.w3.org/TR/xsl.
Norman Walsh. 1999. DocBook: The Defini-
tive Guide. O?Reilly & Associates, Inc.
http://docbook.org/.
Sense Discrimination with Parallel Corpora
Nancy Ide
Dept. of Computer Science
Vassar College
Poughkeepsie,
New York 12604-0520
 USA
ide@cs.vassar.edu
Tomaz Erjavec
Dept. of Intelligent Systems
Institute "Jozef Stefan"
Jamova 39,
SI-1000 Ljubljana
SLOVENIA
tomaz.erjavec@ijs.si
Dan Tufis
RACAI
Romanian Academy
Casa Academiei,
Calea 13 Septembrie 13,
Bucharest 74311, ROMANIA
tufis@racai.ro
Abstract
This paper describes an experiment that
uses translation equivalents derived from
parallel corpora to determine sense
distinctions that can be used for automatic
sense-tagging and other disambiguation
tasks. Our results show that sense
distinctions derived from cross-lingual
information are at least as reliable as those
made by human annotators. Because our
approach is fully automated through all its
steps, it could provide means to obtain
large samples of ?sense-tagged? data
without the high cost of human
annotation.
1 Introduction
It is well known that the most nagging issue for
word sense disambiguation (WSD) is the definition
of just what a word sense is. At its base, the
problem is a philosophical and linguistic one that is
far from being resolved. However, work in
automated language processing has led to efforts to
find practical means to distinguish word senses, at
least to the degree that they are useful for natural
language processing tasks such as summarization,
document retrieval, and machine translation.
Resnik and Yarowsky (1997) suggest that for the
purposes of WSD, the different senses of a word
could be determined by considering only sense
distinctions that are lexicalized cross-linguistically.
In particular, they propose that some set of target
languages be identified, and that the sense
distinctions to be considered for language
processing applications and evaluation be restricted
to those that are realized lexically in some
minimum subset of those languages. This idea
would seem to provide an answer, at least in part,
to the problem of determining different senses of a
word: intuitively, one assumes that if another
language lexicalizes a word in two or more ways,
there must be a conceptual motivation. If we look
at enough languages, we would be likely to find the
significant lexical differences that delimit different
senses of a word.
Several studies have used parallel texts for WSD
(e.g., Gale et al, 1993; Dagan et al, 1991; Dagan
and Itai, 1994) as well as to define semantic
properties of and relations among lexemes (Dyvik,
1998). More recently, two studies have examined
the use of cross-lingual lexicalization as a criterion
for validating sense distinctions: Ide (1999) used
translation equivalents derived from aligned
versions of Orwell?s Nineteen Eighty-Four among
five languages from four different languages
families, while Resnik and Yarowsky (2000) used
translations generated by native speakers presented
with isolated sentences in English. In both of these
studies, translation information was used to
validate sense distinctions provided in lexicons
such as WordNet (Miller et al, 1990). Although
the results are promising, especially for coarse-
grained sense distinctions, they rest on the
acceptance of a previously established set of
senses. Given the substantial divergences among
sense distinctions in dictionaries and lexicons,
together with the ongoing debate within the WSD
community concerning which sense distinctions, if
any, are appropriate for language processing
applications, fitting cross-linguistic information to
pre-established sense inventories may not be the
optimal approach.
                     July 2002, pp. 54-60.  Association for Computational Linguistics.
                 Disambiguation: Recent Successes and Future Directions, Philadelphia,
                             Proceedings of the SIGLEX/SENSEVAL Workshop on Word Sense
This paper builds on previously reported work (Ide
et al, 2001) that uses translation equivalents
derived from a parallel corpus to determine sense
distinctions that can be used to automatically
sense-tag the data. Our results show that sense
distinctions derived from cross-lingual information
are at least as reliable as those made by human
annotators. Our approach therefore provides a
promising means to automatically identify sense
distinctions.
2 Methodology
We conducted a study using parallel, aligned
versions of George Orwell's Nineteen Eighty-Four
(Erjavec and Ide, 1998) in seven languages:
English, Romanian, Slovene, Czech, Bulgarian,
Estonian, and Hungarian. The study involves
languages from four language families (Germanic,
Romance, Slavic, and Finno-Ugric),  three
languages from the same family (Czech, Slovene
and Bulgarian), as well as two  non-Indo-European
languages (Estonian and Hungarian). Although
Nineteen Eighty-Four, (ca. 100,000 words),  is a
work of fiction, Orwell's prose is not highly
stylized and, as such, it provides a reasonable
sample of modern, ordinary language that is not
tied to a given topic or sub-domain (which is the
case for newspapers, technical reports, etc.).
Furthermore, the translations of the text seem to be
relatively faithful to the original: over 95% of the
sentence alignments in the full parallel corpus of
seven languages are one-to-one (Priest-Dorman, et
al., 1997).
2.1 Preliminary Experiment
We constructed a multilingual lexicon based on the
Orwell corpus, using a method outlined in Tufis
and Barbu (2001, 2002). The complete English
Orwell contains 7,069 different lemmas, while the
computed lexicon comprises 1,233 entries, out of
which 845 have (possibly multiple) translation
equivalents in all languages. We then conducted a
preliminary study using a subset of 33 nouns
covering a range of frequencies and degrees of
ambiguity (Ide, et al, 2001).
For each noun in the sample, we extracted all
sentences from the English Nineteen Eighty-Four
containing the lemma in question, together with the
parallel sentences from each of the six translations.
The aligned sentences were automatically scanned
to extract translation equivalents.
1
 A vector was
then created for each occurrence, representing all
possible lexical translations in the six parallel
versions: if a given word is used to translate that
occurrence, the vector contains a 1 in the
corresponding position, 0 otherwise. The vectors
for each ambiguous word were fed to an
agglomerative clustering algorithm (Stolcke,
1996), where the resulting clusters are taken to
represent different senses and sub-senses of the
word in question.
The clusters produced by the algorithm were
compared with sense assignments made by two
human annotators on the basis of WordNet 1.6.
2
 In
order to compare the algorithm results with the
annotators? sense assignments, we normalized the
data as follows: for each annotator and the
algorithm, each of the 33 words was represented as
a vector of length n(n-1)/2, where n is the number
of occurrences of the word in the corpus. The
positions in the vector represent a ?yes-no?
assignment for each pair of occurrences, indicating
whether or not they were judged to have the same
sense (the same WordNet sense for the annotators,
and the same cluster for the algorithm).
Representing the clustering algorithm results in this
form required some means to ?flatten? the cluster
hierarchies, which typically extend to 5 or 6 levels,
to conform more closely to the completely flat
WordNet-based data. Therefore, clusters with a
minimum distance value (as assigned by the
clustering algorithm) at or below 1.7 were
combined, and each leaf of the resulting collapsed
tree was treated as a different sense. This yielded a
set of sense distinctions for each word roughly
similar in number to those assigned by the
annotators.
3
The cluster output for glass  in Figure 1 is an
example of the results obtained from the clustering
algorithm. For clarity, the occurrences have been
manually labeled with WordNet 1.6 senses (Figure
2). The tree shows that the algorithm correctly
                                                           
1
 Sentences in which more than one translation equivalent
appears were eliminated (cca. 5% of the translations).
2
 Originally, the annotators attempted to group occurrences
without reference to an externally defined sense set, but this
proved to be inordinately difficult and produced highly
variable results and was eventually abandoned.
3
 We used the number of senses annotators assigned rather
than the number of WordNet senses as a guide to determine
the minimum distance cutoff, because many WordNet senses
are not represented in the corpus.
grouped occurrences corresponding to WordNet
sense 1 (a solid material) in one of the two main
branches, and those corresponding to sense 2
(drinking vessel) in the other.  The top group is
further divided into two sub-clusters, the lower of
which refer to a looking glass and a magnifying
glass, respectively. While this is a particularly clear
example of good results from the clustering
algorithm, results for other words are, for the most
part, similarly reasonable.
Figure 1 : Output of the clustering algorithm
1. a brittle transparent solid with
irregular atomic structure
2. a glass container for holding liquids
while drinking
3. the quantity a glass will hold
4. a small refracting telescope
5. a mirror; usually a ladies' dressing
mirror
6. glassware collectively; "She collected
old glass"
Figure 2 : WordNet 1.6 senses for glass (noun)
The results of the first experiment are summarized
in Table 1, which shows the percentage of
agreement between the cluster algorithm and each
annotator, between the two annotators, and for the
algorithm and both annotators taken together.
4
 The
percentages are similar to those reported in earlier
work; for example, Ng et al (1999) achieved a raw
percentage score of 58% agreement among
annotators tagging nouns with WordNet 1.6 senses.
Cluster/Annotator 1 66.7%
Cluster/Annotator 2 63.6%
Annotator 1/Annotator 2 76.3%
Cluster/Annotator 1/ Annotator 2 53.4%
Table 1 : Levels of agreement
2.2 Second experiment
Comparison of sense differentiation achieved using
translation equivalents, as determined by the
clustering algorithm, with those assigned by human
annotators suggests that use of translation
equivalents for word sense tagging and
disambiguation is worth pursuing. Agreement
levels are comparable to (and in some cases higher
than) those obtained in earlier studies tagging with
WordNet senses. Furthermore, the pairwise
difference in agreement between the human
annotators and the annotators and the clustering
algorithm is only 10-13%, which is also similar to
scores obtained in other studies.
In the second phase, the experiment was broadened
to include 76 nouns from the multi-lingual lexicon,
including words with varying ambiguity (the range
in number of WordNet senses is 2 to 29, average
7.09) and semantic characteristics (e.g., abstract vs.
concrete: ?thought?, ?stuff?, ?meaning?, ?feeling?
vs. ?hand?, ?boot?, ?glass?, ?girl?, etc.). We chose
nouns that occur a minimum of 10 times in the
corpus, have no undetermined translations and at
least five different translations in the six non-
English languages, and have the log likelihood
score of at least 18; that is:
LL(T
T
, T
S
)  =
? ?
= =
2
1
ij
2
1i
n*2
j
*
j**i
**ij
n*n
n*n
log  
? 18
where n
ij
 stands for the number of times T
T
 and T
S
have been seen together in aligned sentences, n
i*
and n
*j 
stand for the number occurrences of T
T
 and
T
S,
 respectively, and n
**
 represents the total
                                                           
4
 We computed raw percentages only; common measures of
annotator agreement such as the Kappa statistic (Carletta,
1996) proved to be inappropriate for our two-category (?yes-
no?) classification scheme.
                _____|-> (1)
         |-----|     |-> (1)
         |     |_____|---> (1)
         |           |___|-> (1)
         |               |-> (1)
         |         |---> (1)
    |----|         |            _|-> (1)
    |    |         |         |-| |-> (1)
    |    |     |---|       |-| |-> (1)
    |    |     |   |     |-| |-> (1)
    |    |-----|   |   |-| |-> (1)
 |--|          |   |---| |-> (1)
 |  |          |       |-> (1)
 |  |          |___|---> (6)
 |  |              |___|-----> (1)
 |  |                  |-----> (1)
 |  |     _____|-----> (1)
-|  |----|     |-----> (5)
 |       |-----> (4)
 |      |---> (2)
 |  |---|      _|-> (2)
 |  |   |   |-| |-> (2)
 |  |   |---| |-> (2)
 |--|       |-> (2)
    |   |-----> (2)
    |   |           ___|-----> (2)
    |---|     |----|   |-----> (2)
        |     |    |    _|-> (2)
        |     |    |---| |-> (2)
        |-----|        |-> (2)
              |     ____|-> (3)
              |----|    |-> (2)
                   |     _|-> (2)
                   |----| |-> (2)
                               |-> (2)
number of potential translation equivalents in the
parallel corpus. The LL score is set at a maximum
value to ensure high precision for the extracted
translation equivalents, which minimizes sense
clustering errors due to incorrect word alignment.
Table 2 summarizes the data.
No. of words 76
No. of example sentences 2399
Average examples/word 32
No. of senses (annotator 1) 241
No. of senses (annotator 2) 280
No. of senses (annotator 3) 213
No. of senses (annotator 4) 232
No. of senses (all annotators) 345
Average senses per word 4.53
Percentage of annotator agreement:
Full agreement (4/4) 54.27
75% agreement (3/4) 28.13
50% agreement (2/4) 16.92
No agreement 0.66
Table 2 : Summary of the data
In this second experiment, we increased the
number of annotators to four. The results of the
clustering algorithm and the sense assignments
made by the human annotators were normalized
differently than in the earlier experiment, by
ignoring sense numbers and interpreting the
annotators? sense assignments as clusters only. To
see why this was necessary, consider the following
set of sense assignments for the seven occurrences
of ?youth? in Nineteen Eighty-Four:
OCC 1 2 3 4 5 6 7
Ann1
3 1 6 3 6 3 1
Ann2
2 1 4 2 6 2 1
Agreement is 43%; however, both annotators
classify occurrences 1, 4, and 6  as having the same
sense, although each assigned a different sense
number to the group. If we ignore sense numbers
and consider only the annotators? ?clusters?, the
agreement rate is much higher,
5
 and the data is
more comparable to that obtained from the cluster
algorithm.
We also addressed the issue of the appropriate
point at which to cut off the clustering by the
algorithm. Our use of a pre-defined minimum
                                                           
5
 In fact, the only remaining disagreement is that Annotator 1
assigns occurrences 3 and 5 together, whereas Annotator 2
assigns a different sense to occurrence 3?in effect, Annotator
2 makes a finer distinction than Annotator 1 between
occurrences 3 and 5.
distance value to determine the number of clusters
(senses) in the earlier experiment  yielded varying
results for different words (especially words with
significantly different numbers of translation
equivalents) and we sought a more principled
means to determine the cut-off value. The
clustering algorithm was therefore modified to
compute the correct number of clusters
automatically by halting the clustering process
when the number of clusters reached a value
similar to the average number obtained by the
annotators.
6
 As criteria, we used the minimum
distance between existing clusters at each iteration,
which determines the two clusters to be joined,
where minimum distance is computed between two
vectors v
1
, v
2
 length n as:
? 
(v
1
(i) - v
2
(i))
2
i=1
n
?
Best results were obtained when the clustering was
stopped at the point where:
(dist(k)-dist(k+1))/dist(k+1) < 0.12
where dist(k) is the minimal distance between two
clusters at the kth iteration step.
We defined a ?gold standard? annotation by taking
the majority vote of the four annotators (in case of
ties, the annotator closest to the majority vote in
the greatest number of cases was considered to be
right). Using this heuristic, the clustering algorithm
assigned the same number of senses as the gold
standard for 41 words. However, overall agreement
was much worse (67.9%) than when the number of
clusters was pre-specified. The vast majority of
clustering errors occurred when sense distributions
are skewed; we therefore added a post-processing
phase in which the smallest clusters are eliminated
and their members included in the largest cluster
when the number of occurrences in the largest
cluster is at least ten times that of any other
cluster.
7
With this new heuristic, the algorithm produced the
same number of clusters as the gold standard for
only 15 words, but overall agreement reached
74.6%. Mismatching clusters typically included
                                                           
6
 In principle, the upper limit for the number of senses for a
word is the number of senses in WordNet 1.6; however, there
was no case in which all WordNet senses appeared in the text.
7
 The factor of 10 is a conservative threshold; additional
experiments might yield evidence for a lower value.
only one element. There were only five words for
which a difference in the  number of clusters
assigned by the gold standard vs. the algorithm
significantly contributed to the 2.7% depreciation
in agreement.
We also experimented with eliminating the data for
?non-contributing? languages  (i.e., languages for
which there is only one translation for the target
word); this was ultimately abandoned because it
worsened results by amplifying the effect of
synonymous translations in other languages.
Finally, we compared the use of weighted vs.
unweighted clustering algorithms (see, e.g.,
Yarowsky and Florian, 1999) and determined that
results were improved using weighted clustering.
The clusters produced by each pair of classifiers
(human or machine) were mapped for maximum
overlap; differences were considered as
divergences. The agreement between two different
classifications was computed as the number of
common occurrences in the corresponding clusters
of the two classifications divided by the total
number of the occurrences of the target word. For
example, the word movement occurs 40 times in
the corpus; both the ?gold standard? and the
algorithm identified four clusters, but the
distribution of the 40 occurrences was substantially
different, as summarized in Table 3.  Thirty-four of
the 40 occurrences appear in the clusters common
to the two classifications; therefore, the agreement
rate is 85%.
CLUSTER 1 2 3 4
Gold standard 28 6 3 3
Algorithm 25 7 6 2
Intersection 24 6 3 1
Table 3 : Gold standard vs. algorithm clustering for
movement
2.3 Results
The results of our second experiment are
summarized in Table 4, which gives the agreement
rate between baseline clustering (B), in which it is
assumed all occurrences are labeled with the same
sense; each pair of human annotators (1-4); the
gold standard (G); and the clustering algorithm
(A). The table shows that agreement rates among
the human annotators, as compared to those
between the algorithm and all but one annotator,
are not significantly different, and that the
algorithm?s highest level of agreement is with the
baseline. This is not surprising because of the
second heuristic used. However, the second best
agreement rate for the algorithm is with the gold
standard, which suggests that sense distinctions
determined using the algorithm are almost as
reliable as sense distinctions determined manually.
The agreement of the algorithm with the gold
standard falls slightly below that of the human
annotators, but is still well within the range of
acceptability. Also, given that the gold standard
was computed on the basis of the human
annotations, it is understandable that these
annotations do better than the algorithm.
1 2 3 4 G A
B
71.1 65.1 76.3 74.1 75.5 81.5
1
78.1 75.6 83.1 88.6 74.4
2
71.3 75.9 82.5 66.9
3
77.3 82.1 77.1
4
90.4 75.9
G
77.3
Table 4 Agreement rates among baseline, the four
annotators, gold standard, and the algorithm
3 Discussion and Further Work
Our results show that sense distinctions based on
translation variants from parallel corpora are
similar to those obtained from human annotators,
which suggests several potential applications.
Because our approach is fully automated through
all its steps, it could be used to automatically
obtain large samples of ?sense-differentiated? data
without the high cost of human annotation.
Although our method does not choose sense
assignments from a pre-defined list, most language
processing applications (e.g. information retrieval)
do not require this knowledge; they need only the
information that different occurrences of a given
word are used in the same or a different sense.
A by-product of applying our method is that once
words in a text in one language are tagged using
this method, different senses of the corresponding
translations in the parallel texts are also identified,
potentially providing a source of information for
use in other language processing tasks and for
building resources in the parallel languages (e.g.,
WordNets for the Eastern European languages in
our study).  In addition, if different senses of target
words are identified in parallel texts, contextual
information for different senses of a word can be
gathered for use in disambiguating other, unrelated
texts. The greatest obstacle to application of this
approach is, obviously, the lack of parallel corpora:
existing freely available parallel corpora including
several languages are typically small (e.g., the
Orwell), domain dependent (e.g. the MULTEXT
Journal of the Commission (JOC) corpus; Ide and
V?ronis, 1994), and/or represent highly stylized
language (e.g. the Bible; Resnik et al, 1999).
Appropriate parallel data including Asian
languages  is virtually non-existent. Given that our
method applies only to words for which different
senses are lexicalized differently in at least one
other language, its broad application depends on
the future availability of large-scale parallel
corpora including a variety of language types.
Many studies have pointed out that coarser-grained
sense distinctions can be assigned more reliably by
human annotators than finer distinctions such as
those in WordNet. In our study, the granularity of
the sense distinctions was largely ignored, except
insofar as we attempted to cut off the number of
clusters produced by the algorithm at a value
similar to the number identified by the annotators.
The sense distinctions derived from the clustering
algorithm are hierarchical, often identifying four or
five levels of refinement, whereas the WordNet
sense distinctions are organized as a flat list with
no indication of their degree of relatedness. Our
attempt to flatten the cluster data in fact loses much
information about the relatedness of senses.
8
 As a
result, both annotators and the clustering algorithm
are penalized as much for failing to distinguish
fine-grained as coarse-grained distinctions. We are
currently exploring two possible sources of
information about sense relatedness: the output of
the clustering algorithm itself, and WordNet
hypernyms, which may not only improve but also
broaden the applicability of our method.
                                                           
8
 Interestingly, the clustering for ?glass? in Figure 1 reveals
additional sub-groupings that are not distinguished in
WordNet:  the top sub-group of the top cluster includes
occurrences that deal with some physical aspect of the material
(?texture of?, ?surface of?, ?rainwatery?, ?soft?, etc.). In the
lower cluster, the two main sub-groups distinguish a (drinking)
glass as a manipulatable object (by washing, holding, on a
shelf, etc.) from its sense as a vessel (mainly used as the object
of ?pour into?, ?fill?, ?take/pick up?, etc. or modified by
?empty?, ?of gin?, etc.).
We note in our data that although it is not
statistically significant, there is some correlation (-
.51) between the number of WordNet senses for a
word and overall agreement levels. The lowest
overall agreement levels were for ?line? (29
senses), ?step? (10), position (15), ?place? (17),
and ?corner? (11). Perfect agreement was achieved
for several words with under 5 senses, e.g., ?hair?
(5), ?morning? (4), ?sister? (4), ?tree? (2), and
?waist? (2)?all of which were judged by both the
annotators and the algorithm to occur in only one
sense in the text. On the other hand, agreement
levels for some words with under five WordNet
senses had low agreement: e.g., ?rubbish? (2),
?rhyme? (2), ?destruction? (3), and ?belief? (3).
Because both the algorithm (which based
distinctions on translations) and the human
annotators (who used WordNet senses) had low
agreement in these cases, the WordNet sense
distinctions may be overly fine-grained and,
possibly, irrelevant to many language processing
tasks.
We continue to explore the viability of our method
to automatically determine sense distinctions
comparable to those achieved by human
annotators. We are currently exploring methods to
refine the clustering results as well as their
comparison to results obtained from human
annotators (e.g., the Gini Index  [Boley, et al,
1999]).
4 Conclusion
The results reported here represent a first step in
determining the degree to which automated
clustering based on translation equivalents can be
used to differentiate word senses.  Our work so far
indicates that the method is promising and could
provide a significant means to automatically
acquire sense-differentiated data in multiple
languages. Our current results suggest that coarse-
grained agreement is the best that can be expected
from humans, and that our method is capable of
duplicating sense differentiation at this level.
5 Acknowledgements
Our thanks go to Arianna Schlegel, Christine
Perpetua, and Lindsay Schulz who annotated the
data, and to Ion Radu who modified the clustering
algorithm. We would also like to thank the
anonymous reviewers for their comments and
suggestions. All errors, of course, remain our own.
6 References
Boley D., Gini, M, Gross, R., Han, S.,.
Hastings, K and Karypis, G., Kumar, V.,
Mobasher, B, Moore, J. (1999) Partitioning-Based
Clustering for Web Document Categorization.
Decision Support Systems, 27:3, 329-341.
Carletta, J. (1996). Assessing Agreement on
Classification Tasks: The Kappa Statistic.
Computational Linguistics, 22:2, 249-254.
Dagan, I. and Itai, A. (1994). Word sense
disambiguation using a second language
monolingual corpus. Computational Linguistics,
20:4, 563-596.
Dagan, I., Itai, A., and Schwall, U. (1991). Two
languages are more informative than one.
Proceedings of the 29th Annual Meeting of the
ACL, 18-21 Berkeley, California, 130-137.
Dyvik, H. (1998). Translations as Semantic
Mirrors. Proceedings of Workshop Multilinguality
in the Lexicon II, ECAI 98, Brighton, UK, 24-44.
Erjavec, T. and Ide, N. (1998). The
MULTEXT-EAST Corpus. Proceedings of the
First International Conference on Language
Resources and Evaluation, Granada, 971-74.
Gale, W. A., Church, K. W. and Yarowsky, D.
(1993). A method for disambiguating word senses
in a large corpus. Computers and the Humanities,
26, 415-439.
Ide, N. (1999). Cross-lingual sense
determination: Can it work? Computers and the
Humanities, 34:1-2,  223-34.
Ide, N., Erjavec, T., and Tufis, D. (2001).
Automatic sense tagging using parallel corpora.
Proceedings of the Sixth Natural Language
Processing Pacific Rim Symposium, Tokyo,  83-89.
Ide, N., V?ronis, J. (1994). Multext
(Multilingual Tools and Corpora). Proceedings of
the 14th International Conference on
Computational Linguistics, COLING?94, Kyoto,
90-96.
Miller, G. A., Beckwith, R. T. Fellbaum, C. D.,
Gross, D. and Miller, K. J. (1990). WordNet: An
on-line lexical database. International Journal of
Lexicography, 3:4, 235-244.
Ng, H. T., Lim, C. Y., Foo, S. K. (1999). A
Case Study on Inter-Annotator Agreement for
Word Sense Disambiguation. Proceedings of the
ACL SIGLEX Workshop: Standardizing Lexical
Resources, College Park, MD, USA, 9-13.
Priest-Dorman, G.; Erjavec, T.; Ide, N. and
Petkevic, V. (1997). Corpus Markup. COP Project
106 MULTEXT-East D2.3 F.
Resnik, P. and Yarowsky, D. (2000).
Distinguishing systems and distinguishing senses:
New evaluation methods for word sense
disambiguation. Journal of Natural Language
Engineering, 5(2): 113-133.
Resnik, P., Broman Olsen, M., Diab, M. (1999).
Creating a Parallel Corpus from the Book of 2000
Tongues. Computers and the Humanities, 33:1-2.
129-153.
Resnik, Philip and Yarowsky, David (1997). A
perspective on word sense disambiguation methods
and their evaluation. ACL-SIGLEX Workshop
Tagging Text with Lexical Semantics: Why, What,
and How? Washington, D.C., 79-86.
Stolcke, Andreas (1996) Cluster 2.9.
http://www.icsi.berkeley.edu/ftp/global/pub/ai/
stolcke/software/cluster-2.9.tar.Z.
Tufis, D., Barbu, A.-M. (2001) Automatic
Construction of Translation Lexicons. In V.Kluew,
C. D'Attellis N. Mastorakis (eds.) Advances in
Automation, Multimedia and Modern Computer
Science, WSES Press, 156-172
Tufis, D., Barbu, A.-M. (2002), Revealing
translators knowledge: statistical methods in
constructing practical multilingual lexicons for
language and speech processing. International
Journal of Speech Technology (to appear).
Yarowsky, D., Florian. R. (1999). Taking the
load off the conference chairs: towards a digital
paper-routing assistant. Proceedings of the Joint
SIGDAT Conference on Empirical Methods in NLP
and Very Large Corpora, 220-230.
Encoding Biomedical Resources in TEI: the Case of the GENIA Corpus
Tomaz? Erjavec
Dept. of Intelligent Systems
Joz?ef Stefan Institute, Ljubljana
Yuka Tateisi
CREST
Japan Science and
Technology Corporation
Jin-Dong Kim
Dept. of Information Science
University of Tokyo
Tomoko Ohta
CREST
Japan Science and
Technology Corporation
Jun-ichi Tsujii
CREST JST &
Dept. of Information Science
University of Tokyo
Abstract
It is well known that standardising the
annotation of language resources signifi-
cantly raises their potential, as it enables
re-use and spurs the development of com-
mon technologies. Despite the fact that
increasingly complex linguistic informa-
tion is being added to biomedical texts,
no standard solutions have so far been
proposed for their encoding. This pa-
per describes a standardised XML tagset
(DTD) for annotated biomedical corpora
and other resources, which is based on
the Text Encoding Initiative Guidelines
P4, a general and parameterisable stan-
dard for encoding language resources. We
ground the discussion in the encoding of
the GENIA corpus, which currently con-
tains 2,000 abstracts taken from the MED-
LINE database, and has almost 100,000
hand-annotated terms marked for seman-
tic class from the accompanying ontol-
ogy. The paper introduces GENIA and
TEI and implements a TEI parametrisa-
tion and conversion for the GENIA cor-
pus. A number of aspects of biomedi-
cal language are discussed, such as com-
plex tokenisation, prevalence of contrac-
tions and complex terms, and the linkage
and encoding of ontologies.
1 Introduction
With the growing research on processing texts from
the biomedical domain, the number of resources,
esp. corpora, is increasing rapidly. Such corpora can
be heavily annotated, e.g., with meta-data, words
and part-of-speech tags, named entities, phrases,
terms, concepts, translation equivalents, etc. Cor-
pora are invaluable to the further development of
technologies for utilising the information in biomed-
ical texts, as they provide them with training and
testing data. Given the value of such resources, it
is important to ensure their reusability and increase
their interchange potential ? a step in this direc-
tion is developing common encodings for biomedi-
cal corpora.
Standardisation of resource encoding practices
has now, for some time, been in the forefront of at-
tention. Most of these advances are Web-driven, and
include XML and related recommendations, such as
XSLT, XML Schemas, XPointer, SAX, etc. The
higher level standards, of meta-data (RDF) and on-
tologies (OWL) have been especially influential in
encoding biomedical resources. However, there re-
mains the question how to best encode the structure
of the text themselves, how to mark-up added lin-
guistic analyses, and how to implement linkages be-
tween the text and and further resources, such as lex-
ica, thesauri and ontologies. As discussed in (Ide
and Brew, 2000), in order to qualify as a ?good?
annotated corpus, its encoding should provide for
reusabilty and extensibily.
In this paper we build on previous work (Erjavec
et al, 2003) and show how to develop a standard-
ised encoding for biomedical corpora. We base
our discussion on the case of the GENIA corpus
(Ohta et al, 2002), which is originaly encoded in
GPML, the GENIA Project Markup Language, an
XML DTD. We re-encode the corpus into a stan-
dardised annotation scheme, based on the Text En-
coding Initiative Guidelines P4 (Sperberg-McQueen
and Burnard, 2002), and specify a constructive map-
ping from the original DTD to the developed encod-
ing via a XSLT transformation.
One of the motivations for such an re-encoding
is that TEI is well-designed and widely accepted ar-
chitecture, which has been often used for annotating
language corpora, and by porting to it, GENIA, and
other projects, can gain new insights into possible
encoding practices and maybe make the corpus bet-
ter suited for interchange. As the transformation to
TEI is fully automatic, there is also no need to aban-
don the original markup format (in this case GPML),
which, as it has been crafted specially for the corpus,
provides a tighter encoding than can be possible with
the more general TEI.
The paper thus proposes the creation of a prac-
tical annotation scheme for linguistically annotated
(biomedical) corpora, the conversion to which is
automatic and supports consistency checking and
validation. The paper also serves as a guide to
parametrising TEI and draws attention to certain as-
pects of biomedical corpora which are likely to face
all that wish to process such texts.
The paper is structured as follows: Section 2 in-
troduces the GENIA corpus; Section 3 introduces
the TEI, gives some pros and cons of using it,
and the method of parametrising TEI for particular
projects; Section 4 discusses such a parametrisation
for biomedical corpora and explains the conversion
of the GENIA corpus to TEI; Section 5 discusses
some challenging properties of biomedical text an-
notations; finally, Section 6 offers some conclusions
and directions for further work.
2 The GENIA Corpus
The GENIA corpus (Ohta et al, 2002) is be-
ing developed in the scope of the GENIA project,
which seeks to develop information extraction tech-
niques for scientific texts using NLP technol-
ogy. The corpus consists of semantically anno-
tated published abstracts from the biomedical do-
main. The corpus is a collection of articles ex-
tracted from the on-line MEDLINE abstracts (U.S.
National Center for Biotechnology Information,
http://www.ncbi.nlm.nih.gov/, PubMed database).
Since the focus of the corpus is on biological re-
actions concerning transcription factors in human
blood cells, articles were selected that contain the
MeSH terms human, blood cell and transcription
factor.
As usual for the field, the articles are composed
largely of structurally very complex technical terms,
and are almost incomprehensible to a layperson. A
typical heading e.g., reads IL-2 gene expression and
NF-kappa B activation through CD28 requires reac-
tive oxygen production by 5-lipoxygenase.
The main value of the GENIA corpus comes from
its annotation: all the abstracts and their titles have
been marked-up by two domain experts for bio-
logically meaningful terms, and these terms have
been semantically annotated with descriptors from
the GENIA ontology.
The GENIA ontology is a taxonomy of, currently,
47 biologically relevant nominal categories, such as
body part, virus, or RNA domain or region; the tax-
onomy has 35 terminal categories.
The terms of the corpus are semantically de-
fined as those sentence constituents that can be cate-
gorised using the terminal categories from the ontol-
ogy. Syntactically such constituents are quite varied:
they include qualifiers and can be recursive.
The GENIA corpus is encoded in the Genia
Project Markup Language. The GPML is an XML
DTD (Kim et al, 2001) where each article con-
tains its MEDLINE ID, title and abstract. The texts
of the abstracts are segmented into sentences, and
these contain the constituents with their semantic
classification. The GENIA ontology is provided to-
gether with the GENIA corpus and is encoded in
DAML+OIL (http://www.daml.org/ ), the standard
XML-based ontology description language. This
structure and its annotation will be further discussed
below.
A suite of supporting tools has been developed or
tuned for the GENIA corpus and GPML: the term
annotation is performed with the XMLMind editor;
an XPath-based concordancer has been developed
for searching the corpus; and CSS stylesheets are
available for browsing it.
At the time of writing, the latest version of the
GENIA corpus is 3.01, which has been released
in April 2003. It consists of 2,000 abstracts with
over 400,000 words and more than 90,000 marked-
up terms. This version has not yet been marked-
up with tokens or PoS information, although an
earlier version (Genia-V3.0p) has been. The GE-
NIA corpus is available free of charge from the GE-
NIA project homepage, at http://www-tsujii.is.s.u-
tokyo.ac.jp/GENIA/.
3 The Text Encoding Initiative
The Text Encoding Initiative was established in
1987 as a systematised attempt to develop a fully
general text encoding model and set of encoding
conventions based upon it, suitable for processing
and analysis of any type of text, in any language,
and intended to serve the increasing range of ex-
isting (and potential) applications and uses. The
TEI Guidelines for Electronic Text Encoding and
Interchange were first published in April 1994 in
two substantial green volumes, known as TEI P3.
In May 1999, a revised edition of TEI P3 was
produced, correcting several typographic and other
errors. In December 2000 the TEI Consortium
(http://www.tei-c.org/ ) was set up to maintain and
develop the TEI standard. In 2002, the Consortium
announced the availability of a major revision of TEI
P3, the TEI P4 (Sperberg-McQueen and Burnard,
2002) the object of which is to provide equal sup-
port for XML and SGML applications using the TEI
scheme. The revisions needed to make TEI P4 have
been deliberately restricted to error correction only,
with a view to ensuring that documents conforming
to TEI P3 will not become illegal when processed
with TEI P4. For GENIA, we are using the XML-
compatible version of TEI P4.
In producing P4, many possibilities for other,
more fundamental changes have been identified.
With the establishment of the TEI Council, it be-
came possible to agree on a programme of work to
enhance and modify the Guidelines more fundamen-
tally over the coming years. TEI P5 will be the next
full revision of the Guidelines. The work on P5 has
started, and the date of its appearance will likely be
in 2004 and there are currently several TEI Working
Groups addressing various parts of the Guidelines
that need attention.
More than 80 projects spanning over 30 languages
have so far made use of the TEI guidelines, pro-
ducing diverse resources, e.g., text-critical editions
of classical works. TEI has also been influential
in corpus encoding, where the best known exam-
ple is probably the British National Corpus. How-
ever, while the TEI has been extensively used for
annotating PoS tagged corpora, it been less popu-
lar for encoding texts used by the the Information
Retrieval/Extraction community; here, a number of
other initiatives have taken the lead in encoding, say,
ontologies or inter-document linking.
3.1 Pros and cons of using TEI
Why, if a corpus is already encoded in XML using
a home-grown DTD, to re-encoded it in TEI at all?
One reasons is certainly the validation aspect of the
exercise: re-coding a corpus, or any other resource,
reveals hidden (and in practice incorrect) assump-
tions about its structure. Re-coding to a standard
recommendation also forces the corpus designers to
face issues which might have been overlooked in the
original design.
There are also other advantages of using TEI as
the interchange format: (1) it is a wide-coverage,
well-designed (modular and extensible), widely ac-
cepted and well-maintained architecture; (2) it pro-
vides extensive documentation, which comprises not
only the Guidelines but also papers and documen-
tation (best practices) of various projects; (3) it of-
fers community support via the tei-l public discus-
sion list; (4) various TEI-dedicated software already
exists, and more is likely to become available; and
(5) using it contributes to the adoption of open stan-
dards and recommendations.
However, using a very general recommendation
which tries to cater for any possible situation brings
with it also several disadvantages:
Tag abuse TEI might not have elements / attributes
with the exact meaning we require. This re-
sults in a tendency to misuse tags for purposes
they were not meant for; however, it is a case
of individual judgement to decide whether to
(slightly) abuse a tag, or to implement a lo-
cal extension to add the attribute or element re-
quired.
Tag bloat Being a general purpose recommenda-
tion, TEI can ? almost by definition ? never
be optimal for a specific application. Thus a
custom developed DTD will be leaner, have
less (redundant) tags and simpler content mod-
els.
TEI for humanities While the Guidelines cover a
vast range of text types and annotations, they
are maybe the least developed for ?high level?
NLP applications or have failed to keep abreast
of ?cutting-edge? initiatives. As will be seen,
critical areas are the encoding of ontologies, of
lexical databases and of feature structures.
3.2 Building the TEI DTD
The TEI Guidelines (Sperberg-McQueen and
Burnard, 2002) consist of the formal part, which
is a set of SGML/XML DTD fragments, and the
documentation, which explains the rationale behind
the elements available in these fragments, as well as
giving overall information about the structure of the
TEI.
The formal SGML/XML part of TEI comes as a
set of DTD fragments or tagsets. A TEI DTD for a
particular application is then constructed by select-
ing an appropriate combination of such tagsets. TEI
distinguishes the following types of tagsets:
Core tagset : standard components of the TEI main
DTD in all its forms; these are always included
without any special action by the encoder.
Base tagsets : basic building blocks for specific text
types; exactly one base must be selected by the
encoder, unless one of the combined bases is
used.
Additional tagsets : extra tags useful for particular
purposes. All additional tagsets are compatible
with all bases and with each other; an encoder
may therefore add them to the selected base in
any combination desired.
User defined tagsets : these extra tags give the pos-
sibility of extending and overriding the defi-
nitions provided in the TEI tagset. Further-
more, they give the option of explicitly includ-
<!DOCTYPE teiCorpus.2 SYSTEM
"http://www.tei-c.org/P4X/DTD/tei2.dtd"
[<!ENTITY % TEI.XML "INCLUDE">
<!ENTITY % TEI.prose "INCLUDE">
<!ENTITY % TEI.linking "INCLUDE">
<!ENTITY % TEI.analysis "INCLUDE">
<!ENTITY % TEI.corpus "INCLUDE">
<!ENTITY % TEI.extensions.ent SYSTEM
?geniaex.ent?>
<!ENTITY % TEI.extensions.dtd SYSTEM
?geniaex.dtd?>
]>
Figure 1: The XML TEI prolog for GENIA
ing or ignoring (disallowing) each particular el-
ement licensed by the chosen base and addi-
tional tagsets.
While a project-particular XML DTD can be con-
structed by including and ignoring the TEI DTD
fragments directly (as exemplified in Figure 1), it is
also possible to build ? for easier processing ? a
one-file DTD with the help of the on-line TEI Pizza
Chef service, available from the TEI web site.
4 Parametrising TEI for biomedical
corpora
In previous work (Erjavec et al, 2003) we have al-
ready proposed a TEI parametrisation of GENIA
which was quite broad in its scope. Because a num-
ber of tagsets could prove useful in the long term
this parametrisation collected not only those that we
considered necessary for the current version of GE-
NIA, but also some that might prove of service in the
future. Furthermore, we supported the encoding of
both version 2.1 and 3.0 of the corpus. The resulting
DTD was thus very generous in what kinds of data it
caters for. To focus the discussion we, in the current
paper, only address tagset that are immediately rele-
vant to annotating biomedical texts. In Figure 1 we
define the XML DTD that can be used for encoding
biomedical resources, and that we used for GENIA
V3.01. The XML prolog given in this Figure defines
that ?teiCorpus.2? is the root element of the corpus,
that the external DTD resides at the given URL be-
longing to the TEI Consortium, and that a number
of TEI modules, detailed below, are being used to
parametrise the TEI to arrive at our particular DTD.
4.1 TEI.XML
TEI P4 allows both standard SGML and XML en-
codings. Including the TEI.XML option indicates
that the target DTD is to be expressed in XML.
4.2 TEI.prose
The base tagset does not declare many elements but
rather inherits all of the TEI core, which includes the
TEI header, and text elements. A TEI document will
typically have as its root element ?TEI.2? which is
composed of the ?teiHeader?, followed by the ?text?;
c.f. right hand side of Figure 2, but note that the root
element from the TEI.corpus module is used for the
complete corpus.
The TEI header describes an encoded work so that
the text (corpus) itself, its source, its encoding, and
its revisions are all thoroughly documented.
TEI.prose also contains elements and attributes
for describing text structure, e.g. ?div? for text divi-
sion, ?p? for paragraph, ?head? for text header, etc.
The tagset is therefore useful for encoding the gross
structure of the corpus texts; for an illustration again
see Figure 2.
4.3 TEI.linking
This additional tagset provides mechanisms for link-
ing, segmentation, and alignment. The elements
provided here enable links to be made e.g., between
the articles and their source URLs, or between con-
cepts and their hypernyms.
It should be noted that while the TEI treatment
of external pointers had been very influential, it was
overtaken and made obsolete by newer recommen-
dations. However, the TEI does have a Working
Group on Stand-Off Markup, XLink and XPointer,
which should produce new TEI encoding recom-
mendations for this area in 2003.
4.4 TEI.analysis
This additional tagset is used for associating sim-
ple linguistic analyses and interpretations with text
elements. It can be used to annotate words, ?w?,
clauses, ?cl?, and sentences, ?s? with dedicated tags,
as well as arbitrary and possibly nested segments
with the ?seg?. Such elements can be, via at-
tributes, associated with their analyses. This tagset
has proved very popular for PoS-annotated corpora;
for an illustration see Figure 3.
4.5 TEI.corpus
This additional tagset introduces a new root element,
?teiCorpus.2?, which comprises a (corpus) header
and a series of ?TEI.2? elements. The TEI.corpus
tagset alo extends the certain header elements to
provide more detailed descriptions of the corpus ma-
terial.
4.6 TEI.extensions.ent
The file gives, for each element sanctioned by the
chosen modules, whether we include or ignore it in
our parametrisation. While this is not strictly neces-
sary (without any such specification, all the elements
would be included) we thought it wise to constrain
the content models somewhat, to reduce the bewil-
dering variety of choices that the TEI otherwise of-
fers. Also, such an entity extension file gives the
complete list of all the TEI elements that are allowed
(and disallowed) in GENIA, which might prove use-
ful for documentation purposes.
4.7 TEI.extensions.dtd
This file specifies the changes we have made to TEI
elements. We have e.g., added the url attribute to
?xptr? and ?xref ? and tagging attributes to word and
punctuation elements.
4.8 Conversion of GPML to TEI
Because the source format of GENIA will remain
the simpler GPML, it is imperative to have an au-
tomatic procedure for converting to the TEI inter-
change format. The translation process takes advan-
tage of the fact that both the input and output are
encoded in XML, which makes it possible to use the
XSL Transformation Language, XSLT that defines a
standard declarative specification of transformations
between XML documents. There also exist a num-
ber of free XSLT processors; we used Daniel Veil-
lard?s xsltproc.
The transformation is written as a XSLT
stylesheet, which makes reference to two docu-
ments: the GENIA ontology in TEI and the template
for the corpus header. The stylesheet then resolves
the GPML encoded corpus into TEI. The translation
of the corpus is thus fully automatic, except for the
taxonomy, which was translated by hand.
Figure 2 illustrates the top level structure of the
corpus, and how it differs between the GPML and
TEI encodings. The most noticeable difference is,
apart from the renaming of elements, the addition
of headers to the corpus and texts. In the GENIA
?teiHeader? we give e.g., the name, address, avail-
ability, sampling description, and, for each abstract?s
?sourceDesc?, two ?xptr?s: the first gives the URL of
the HTML article in the MEDLINE database, while
the second is the URL of the article in the origi-
nal XML. It should be noted that we use a locally
defined url attribute for specifying the value of the
pointer.
5 Characteristics of biomedical texts
In this section we review some challenges that
biomedical texts present to the processing and en-
coding of linguistic information, and the manner of
their encoding in our DTD.
5.1 Tokens
Tokenisation, i.e., the identification of words and
punctuation marks, is the lowest level of linguistic
analysis, yet is, in spite (or because) of this of con-
siderable importance. As all other levels of linguis-
tic markup make direct or direct reference to the to-
ken stream of the text, so if this is incorrect, errors
will propagate to all other annotations.
It is also interesting to note that current annota-
tion practice is more and more leaning toward stand-
off markup, i.e., annotations that are separated from
the primary data (text) and make reference to it only
via pointers. However, it is beneficial to have some
markup in the primary data to which it is possible to
refer, and this markup is, almost exclusivelly, that of
tokens; see e.g., (Freese et al, 2003).
Version V1.1 of GENIA has been also annotated
with LTG tools (Grover et al, 2002). In short, the
corpus is tokenised, and then part-of-speech tagged
with two taggers, each one using a different tagset,
and the nouns and verbs lemmatised. Additionally,
the deverbal nominalisations are assigned their ver-
bal stems.
The conversion to TEI is also able to handle this
additional markup, by using the TEI.analysis mod-
ule. The word and punctuation tokens are encoded
as ?w? and ?c? elements respectively, which are fur-
ther marked with type and lemma and the locally de-
fined c1, c2 and vstem. An example of such markup
<s>
<w c1="DT" c2="DB">All</w>
<c type="HYPH" c1=":" c2="-">-</c>
<w c1="VBZ" c2="JJ">trans</w>
<w c1="JJ" c2="JJ">retinoic</w>
<w lemma="acid" c1="NN" c2="NN1">acid</w>
<c type="BR" c1="(" c2="(">(</c>
<w lemma="Ra" c1="NN" c2="NP1">RA</w>
<c type="BR" c1=")" c2=")">)</c>
<w lemma="be" c1="VBZ" c2="VBZ">is</w>
<w c1="DT" c2="AT1">an</w>
<w c1="JJ" c2="JJ">important</w>
...
Figure 3: TEI encoding of annotated tokens
is given in Figure 3.
Given the high density of technical terms,
biomedical texts are rife with various types of con-
tractions, such as abbreviations, acronyms, prefixes,
etc. As seen already in Figure 3, one of the
more problematic apects of tokenisaton are paren-
theses. Almost all tokenisers (e.g., the LT one, or
the UPENN tokeniser) take these as separate tokens,
but many are in biomedical texts parts of terms. So,
out of almost 35,000 distinct terms that have been
marked up in the GENIA corpus, over 1,700 con-
tain parentheses. Some examples: (+)-pentazocine,
(3H)-E2 binding, (gamma(c))-like molecule.
Correct tokenisation of the biomedical texts is
thus a challenging tasks, and it is fair to say that,
from a linguistic processing perspective, complex
tokenisation is one of the defining characteristics of
such corpora.
5.2 Terms
Annotation of terms is a prerequisite for meaningful
processing of biomedical texts, yet it is often diffi-
cult to decide what constitutes a term in a text, and
how to abstract away from local variations. Biomed-
ical texts are largerly (one could almost say excu-
sivelly) composed of terms, and, as mentioned, this
brings with it complex abbreviatory mechanisms.
Even though TEI offers a ?term? element, we
chose, in line with the original GPML encoding, to
rather use the TEI.analysis clause (?cl?) element to
encode terms. In GENIA, the terms have been hand-
annotated, and marked up with concepts from the
GENIA ontology; this was also the defining factor
of term-hood, namely that the term could be linked
<!DOCTYPE set SYSTEM "gpml.dtd"> <!DOCTYPE teiCorpus.2 SYSTEM "genia-tei.dtd">
<set> <TEIcorpus.2>
<article> <teiHeader type="corpus">
<articleinfo><bibliomisc> *Corpus_header*</teiHeader>
*MEDLINE_ID* <TEI.2 id="*MEDLINE_ID*">
</bibliomisc></articleinfo> <teiHeader type="text">
<title> *Article_header*</teiHeader>
*Title_of_article* <text><body>
</title> <div type="abstract">
<abstract> <head>*Title_of_article*</head>
*Abstract_of_article* <p>*Abstract_of_article*</p>
</abstract> </div>
</article> </body></text></TEI.2>
*More_articles* *More_articles*
</set> </TEIcorpus.2>
Figure 2: The GPML and TEI structure of the corpus
to a terminal concept of the GENIA ontology.
In spite of the simple semantic definition, the syn-
tactic structure of the terms in the corpus varies
dramatically. Biomedical terms are in some ways
similar to named entities (names of people, orga-
nizations, etc.) but from the linguistic perspective,
they are different in that named entities are mostly
proper nouns, while terms mostly contain common
nouns, and the two differ in their syntactic proper-
ties. Terms in the corpus can also be nested, where
complex terms are composed out of simpler ones,
e.g., ?cl??cl?IL-2 gene?/cl? transcription?/cl?.
This nesting, and the reference to ontology con-
cepts is often far from simple, as (partial) terms can
appear in coordinated clauses involving ellipsis. For
example, ?CD2 and CD 25 receptors? refers to two
terms, CD2 receptors and CD25 receptors, but only
the latter actually appears in the text.
In such cases by parsing the coordination
all the terms can be identified and annotated;
the TEI encoding achieves this by specifyng
the propositional formula involving the par-
ticipating concepts in the function attribute;
for example, ?cl function=?(AND G.tissue
G.tissue)? ana=?G.tissue???cl?normal?/cl? and
?cl?hypopigmented?/cl? ?cl?skin samples?/cl??/cl?.
The ana attribute encodes the IDREF of the con-
cept; currently, only same valued concepts are either
conjoined or disjoined.
The number of ?cl? elements in the GENIA cor-
pus is 96,582, among which 89,682 are simple terms
and 1,583 are nested terms that are contain 3,431
terms. 5,137 terms do not yet have the ana attribute
for concept identification, so the total number of
ontology-linked terms is 93,293.
5.3 Ontologies
One of the more interesting questions in recoding
GENIA in TEI was how to encode the ontology. The
ontology is in GENIA GPML encoded in a separate
document, conforming to the OIL+DAML specifi-
cation. This, inter alia, means that that XML file
heavily relies on XML Namespaces and the RDF
recommendation. An illustrative fragment is given
on the left side of Figure 4.
Currently the GENIA ontology has a simple tree-
like structure, i.e., it corresponds to a taxonomy,
so we translated it to the TEI ?taxonomy? element,
which is contained in the ?classDecl? of the header
?encodingDesc?. The TEI defines this element
as ?[the classification declaration] contains one or
more taxonomies defining any classificatory codes
used elsewhere in the text?, i.e., is exactly suited for
our purposes.
There are quite substantial differences between
the two encodings: the DAML+OIL models class
inclusion with links, while the TEI does it as XML
element inclusion. This is certainly the simpler and
more robust solution, but requires that the ontol-
ogy is a taxonomy, i.e., tree structured. The sec-
ond difference is in the status of the identifiers: in
DAML+OIL they are general #CDATA links, which
need a separate (XLink/XPointer) mechanisms for
their resolution. In TEI they are XML ID attributes,
<daml:Class rdf:ID="source"></daml:Class> <taxonomy id="G.taxonomy">
<daml:Class rdf:ID="natural"> <category id="G.source">
<rdfs:subClassOf rdf:resource="#source"/> <catDesc>biological source</catDesc>
</daml:Class> <category id="G.natural">
<daml:Class rdf:ID="organism"> <catDesc>natural</catDesc>
<rdfs:subClassOf rdf:resource="#natural"/> <category id="G.organism">
</daml:Class> <catDesc>organism</catDesc>
<daml:Class rdf:ID="multi_cell"> <category id="G.multi_cell">
<rdfs:subClassOf rdf:resource="#organism"/> <catDesc>multi-cellular</catDesc>
</daml:Class> </category>
... ...
Figure 4: The GENIA DAML+OIL and TEI ontology
and can rely on the XML parser to resolve them.
While this is a simpler solution, it does support
document-internal reference only.
6 Conclusions
The paper proposed an XML paramterisation of TEI
P4 developed for linguistically annotated biomedi-
cal corpora, and applied it to the GENIA corpus.
The conversion from the Genia Project Markup Lan-
guage to this encoding has been implemented in
XSLT and both the TEI-conformant parametrisation
(TEI extension file and one-file DTD) and the XSLT
stylesheets are, together with a report documenting
them, available at http://nl.ijs.si/et/genia/, while the
GENIA corpus is freely available from http://www-
tsujii.is.s.u-tokyo.ac.jp/GENIA/.
The paper gave a survey of the TEI modules that
can be useful for encoding a wide variety of linguis-
tically annotated corpora. This contribution, it is
hoped, can thus serve as a blueprint for parametris-
ing TEI for diverse corpus resources.
Further work involves the inclusion of other
knowledge sources into the corpus, say of Medi-
cal Subject Headings (MeSH), Unified Medical Lan-
guage System (UMLS), International Classification
of Disease (ICD), etc. The place of these annota-
tions in the corpus will have to be considered, and
their linking to the existing information determined.
References
Tomaz? Erjavec, Jin-Dong Kim, Tomoko Ohta, Yuka
Tateisi, and Jun ichi Tsujii. 2003. Stretching the TEI:
Converting the GENIA corpus. In Proceedings of the
EACL-03 Workshop on Linguistically Interpreted Cor-
pora (LINC-03), pages 117?124, Budapest. ACL.
Marion Freese, Ulrich Heid, and Martin Emele. 2003.
Enhancing XCES to XCOMFORT: An Extensible
Modular Architecture for Manipulation of Text Re-
sources. In Proceedings of the EACL-03 Workshop
on Language Technology and the Semantic Web: 3rd
Workshop on NLP and XML (NLPXML-2003), pages
33?40, Budapest. ACL.
Claire Grover, Ewan Klein, Alex Lascarides, and Maria
Lapata. 2002. XML-based NLP Tools for Analysing
and Annotating Medical Language. In 2nd Workshop
on NLP and XML (CoLing Workshop NLPXML-2002).
http://www.ltg.ed.ac.uk/software/ttt/.
Nancy Ide and Chris Brew. 2000. Requrements, Tools
and Architectures for Annotated Corpora. In Proceed-
ings of Data Architectures and Software Support for
Large Corpora, pages 1?5, Budapest. ELRA.
Jin-Dong Kim, Tomoko Ohta, and Jun-ichi Tsujii. 2001.
XML-based Linguistic Annotation of Corpus. In Pro-
ceedings of the first NLP and XML Workshop, pages
44?53.
Tomoko Ohta, Yuka Tateisi, and Jin-Dong Kim. 2002.
The GENIA Corpus: an Annotated Research Abstract
Corpus in Molecular Biology Domain. In Proceedings
of the Human Language Technology Conference, page
To appear.
C. M. Sperberg-McQueen and Lou Burnard, editors.
2002. Guidelines for Electronic Text Encoding and
Interchange, The XML Version of the TEI Guidelines.
The TEI Consortium. http://www.tei-c.org/.
The MULTEXT-East Morphosyntactic Specifications
for Slavic Languages
Toma? Erjavec
Dept. of Intelligent Systems
Jo?ef Stefan Institute, Ljubljana
tomaz.erjavec@ijs.si
Kiril Simov
Linguistic Modelling Laboratory
Bulgarian Academy of Sciences
kivs@bultreebank.org
Cvetana Krstev
Faculty of Philology
University of Belgrade
cvetana@matf.bg.ac.yu
Marko Tadic?
Department of Linguistics
Zagreb University
marko.tadic@ffzg.hr
Vladim?r Petkevic?
Faculty of Arts
Charles University, Prague
vladimir.petkevic@ff.cuni.cz
Du?ko Vitas
Faculty of Mathematics
University of Belgrade
vitas@matf.bg.ac.yu
Abstract
Word-level morphosyntactic descrip-
tions, such as ?Ncmsn? designating a
common masculine singular noun in
the nominative, have been developed
for all Slavic languages, yet there have
been few attempts to arrive at a pro-
posal that would be harmonised across
the languages. Standardisation adds
to the interchange potential of the re-
sources, making it easier to develop
multilingual applications or to evaluate
language technology tools across sev-
eral languages. The process of the
harmonisation of morphosyntactic cat-
egories, esp. for morphologically rich
Slavic languages is also interesting from
a language-typological perspective. The
EU MULTEXT-East project developed
corpora, lexica and tools for seven
languages, with the focus being on
morphosyntactic data, including formal,
EAGLES-based specifications for lexi-
cal morphosyntactic descriptions. The
specifications were later extended, so
that they currently cover nine languages,
five from the Slavic family: Bulgarian,
Croatian, Czech, Serbian and Slovene.
The paper presents these morphosyn-
tactic specifications, giving their back-
ground and structure, including the en-
coding of the tables as TEI feature struc-
tures. The five Slavic language specifi-
cations are discussed in more depth.
1 Introduction
The mid-nineties saw ? to a large extent via EU
projects ? the rapid development of multilingual
language resources and standards for human lan-
guage technologies. However, while the develop-
ment of resources, tools, and standards was well
on its way for EU languages, there had been no
comparable efforts for the languages of Central
and Eastern Europe.
The MULTEXT-East project (Multilingual Text
Tools and Corpora for Eastern and Central Eu-
ropean Languages) was a spin-off of the EU
MULTEXT project (Ide and V?ronis, 1994); it
developed standardised language resources for
six languages (Dimitrova et al, 1998): Bulgar-
ian, Czech, Estonian, Hungarian, Romanian, and
Slovene, as well as for English, the ?hub? language
of the project. The main results of the project were
an annotated multilingual corpus (Erjavec and Ide,
1998), comprising a speech corpus, a comparable
corpus and a parallel corpus; lexical resources (Ide
et al, 1998); and tool resources for the seven lan-
guages.
One of the objectives of MULTEXT-East has
been to make its resources freely available for re-
search purposes. In the scope of the TELRI con-
certed action the results of MULTEXT-East have
been extended with several new languages. This
edition is now available via the TELRI Research
Archive of Computational Tools and Resources, at
http://www.tractor.de/.
Following the TELRI release, the MULTEXT-
East resources have been used in a number of
studies and experiments, e.g., (Tufis?, 1999; Ha-
jic?, 2000; D?eroski et al, 2000). In the course
of such work, errors and inconsistencies were dis-
covered in the MULTEXT-East specifications and
data, most of which were subsequently corrected.
But because this work was done at different sites
and in different manners, the encodings of the re-
sources had begun to drift apart.
The EU Copernicus project CONCEDE, Consor-
tium for Central European Dictionary Encoding,
which ran from ?98 to ?00 and comprised most of
the same partners as MULTEXT-East, offered the
possibility to bring the versions back on a common
footing. Although CONCEDE was primarily de-
voted to machine readable dictionaries and lexical
databases (Erjavec et al, 2000), one of its work-
packages did consider the integration of the dic-
tionary data with the MULTEXT-East corpus. In
the scope of this workpackage, the corrected mor-
phosyntactically annotated corpus was normalised
and re-encoded. This release of the MULTEXT-
East resources (Erjavec, 2001a; Erjavec, 2001b)
contains the revised and expanded morphosyntac-
tic specifications, the revised lexica, and the sig-
nificantly corrected and re-encoded 1984 corpus.
In Table 1, we give all these connected re-
sources by language, type and release. The ones
marked by T belong to the TELRI edition, and
those with C to the Concede edition. A special
case is the Serbian specification, on which we have
started working recently.
The columns distinguish the resource in ques-
tion: ?Other Res.? are the multilingual tool spec-
ifications and the speech and comparable corpora,
?1984 Doc? refers to the structurally annotated
parallel Orwell corpus, and ?1984 Align? to the
sentence alignments.
By far the most useful part of the MULTEXT-
East project deliverables proved to be the mor-
phosyntactic resources, and these were also taken
forward to Concede. These resources are also in-
cluded in the TELRI edition, but have been since
substantially modified and added to.
Producing this linked set of deliverables was
also by the most labour intensive part of the
project. First, while most MULTEXT-East lan-
guages had pre-existing morphological lexica and
annotations, these had to be 7-way harmonised ac-
cording to the common specifications, a huge task
given not only the diversity of languages but also
of linguistic practices. Furthermore, a morphosyn-
tactically annotated corpus of 100,000 words was,
for most of the languages, the first such resource
to be made. This meant that the annotation had to
be done largely manually, and that the corpus an-
notation process fed back into the lexica and spec-
ifications, through a series of revisions.
The morphosyntactic resources consist of three
layers, listed in order of abstraction:
1. 1984 MSD: the morphosyntactically anno-
tated 1984 corpus, where each word is as-
signed its context-disambiguated MSD and
lemma, e.g.,
<w ana="Pp3ns" lemma="it">It<
<w ana="Vmis3s" lemma="be">wa
<w ana="Di" lemma="a">a</w>
2. MSD Lexicons: the morphosyntactic lex-
icons, which contain the full inflectional
paradigms of a superset of the lemmas that
appear in the 1984 corpus. Each entry gives
the word-form, its lemma and MSD, e.g.,
walk = Ncns
walks walk Ncnp
3. MSD Specs: the morphosyntactic specifica-
tions, which are the topic of this paper. They
set out the grammar of valid morphosyn-
tactic descriptions, MSDs. The specifica-
tions determine what, for each language, is
a valid MSD and what it means, e.g., Ncms
  PoS:Noun, Type:common, Gen-
der:masculine, Number:singular
To obtain the corpus and lexica, it is necessary
to fill out a web-based license agreement, which
limits the use of resources to research pruposes.
The specifications, however, are freely available
on the Web, under http://nl.ijs.si/ME/. At the time
of writing, the latest version is V2.1/msd/
The rest of this paper is structured as follows:
Section 2 discusses the structure of the MULTEXT-
East morphosyntactic specifications and quanti-
fies them; Section 3 explains the specifications for
the Slavic languages; Section 4 turns to the stan-
dardisation of the encoding of the specifications
in XML/TEI, and Section 5 gives the conclusions
and directions for further work.
Other 1984 1984 1984 MSD MSD
Res. Doc Align MSD Lexicon Specs
English T T T/C C C C
Romanian T T T/C C C C
Slovene T T T/C C C C
Czech T T T/C C C C
Bulgarian T T T/C - C C
Estonian T T T/C C C C
Hungarian T T T/C C C C
Latvian - T T - - -
Lithuanian - T T - - -
Serbian - T T - - V2.1
Russian - T - - - -
Croatian - - - - - C
Table 1: The MULTEXT-East Resources: TELRI edition (V1); Concede edition (V2)
2 The Morphosyntactic Specifications
The MULTEXT-East morphosyntactic specifica-
tions give the syntax and semantics of the mor-
phosyntactic descriptions (MSDs) used in the lex-
ica and corpora. The specifications have been de-
veloped in the formalism and on the basis of spec-
ifications for six Western European languages of
the EU MULTEXT project (Ide and V?ronis, 1994)
and in cooperation with EAGLES, the Expert Advi-
sory Group on Language Engineering Standards.
Originally, these specifications were released as
a report of the MULTEXT-East project but have,
in the CONCEDE release (Erjavec (ed.), 2001),
been significantly revised. The format of the re-
port has been unified and structured in a more de-
tailed manner (thus leading to an easily naviga-
ble HTML version), the formal specifications for
some languages have been modified. The specifi-
cations have, in the CONCEDE release also gained
a new language, Croatian, and we have recently
also added Serbian to the Specifications.
Technically, the specifications are a LATEX doc-
ument, with derived Postscript, PDF and HTML
renderings, where the common tables are plain
ASCII in a strictly defined format. As will be seen
in Section 4, we have converted these latter into a
TEI/XML encoding.
The MULTEXT-East morphosyntactic specifica-
tions have the following structure: (1) introduc-
tory matter; (2) the common specification; and (3)
a language particular section for each language.
2.1 The Common Part
The common part of the specifications first defines
the parts of speech and their codes; MULTEXT-
East distinguishes the following, where not all PoS
are used for all languages: Noun (N), Verb (V),
Adjective (A), Pronoun (P), Determiner (D), Arti-
cle (T), Adverb (R), Adposition (S), Conjunction
(C), Numeral (M), Interjection (I), Residual (X),
Abbreviation (Y), and Particle (Q).
The common part of the specifications then
gives, for each category, a table defining the at-
tributes appropriate for the category, the values de-
fined for these attributes, and one-letter codes to
identify the values. They also define which lan-
guages distinguish each attribute-value pair. To il-
lustrate, a part of the verb table is given in Table 2.
The morphosyntactic descriptions, MSDs,
are structured and more detailed than is com-
monly the case for part-of-speech tags; they are
compact string representations of a simplified
kind of feature structures. The first letter of a
MSD encodes the part of speech, e.g., Noun or
Adjective. The letters following the PoS give
the values of the position determined attributes.
The specifications define, for each part of speech,
its appropriate attributes, their values and one-
letter codes. So, for example, the Ncmpi MSD
expands to PoS:Noun, Type:common,
Gender:masculine, Number:plural,
Verb (V)
15 Positions
**** **** **** **** **** **** **** ---- ---- ---- ---- ---- ---- ---- ----
PoS Type VFrm Tens Pers Numb Gend Voic Neg Def Cltc Case Anim Clt2 Aspt
**** **** **** **** **** **** **** ---- ---- ---- ---- ---- ---- ---- ----
= ============== ============== = EN RO SL CS BG ET HU HR SR
P ATT VAL C x x x x x x x x x
= ============== ============== =
1 Type main m x x x x x x x x x
auxiliary a x x x x x x x x x
modal o x x x x x x x
copula c x x x x x
base b x
- -------------- -------------- -
2 VForm indicative i x x x x x x x x x
subjunctive s x
imperative m x x x x x x x x
conditional c x x x x x x x
infinitive n x x x x x x x x
participle p x x x x x x x x
gerund g x x x
supine u x x
transgressive t x
quotative q x
- -------------- -------------- -
...
Table 2: The Verb Common Table from the Specifications
Case:instrumental. It should be noted that
in case a certain attribute is not appropriate (1)
for a language, (2) for the particular combination
of features, or (3) for the word in question, this
is marked by a hyphen in the attribute?s position.
Slovene verbs in the indicative, for example, are
not marked for gender or voice, hence the two
hyphens in Vcip3s--n.
The common part of the specifications further
contains two sections, the first giving the complete
list of values with their codes and the attributes
they belong to, and the second listing all the at-
tributes, which PoS they belong to, and ? with
the less familiar ones ? what their meaning is.
In the context of the common tables, we should
mention the Perl script mtems-expand, which
is ? along with various other useful programs ?
included in the public msd/bin directory. The pro-
gram parses the common tables of the specifica-
tion, and is then able to either check the validity
of any given MSD or expand the MSD into a more
readable format.
In Table 3 we quantify the specifications and
give, for each language and part-of-speech, the
number of attributes and attribute-value pairs de-
fined in the specification. Where a language does
not use a PoS, that is marked by a hyphen, while if
a PoS is used, but defines no attributes, the value
of zero is given.
The numbers in Table 3 give an idea of the
?weight? of the MSDs for each particular language
and PoS. As can be seen in the bottom right-hand
corner, the full number of defined attributes is over
one hundred with almost five hundred attribute-
value pairs; the Slavic languages define the most
categories, and the Pronoun is the most complex
PoS.
2.2 Language Particular Sections
In the specifications, the common part is followed
by dedicated sections for each particular language,
and we turn to these next. The structure of these
sections can ? although need not ? be in itself
quite complex. Maximally they contain, for each
PoS category, the following parts: (1) attribute-
value table with notes; (2) allowed combinations
PoS en ro cs sl hr sr bg et hu  
N 3/7 5/14 5/17 5/16 5/16 5/17 5/14 3/19 7/34 10/54
V 5/15 7/24 10/29 9/28 8/27 8/28 8/24 8/28 6/16 14/52
A 2/4 6/16 7/22 7/23 7/21 7/23 3/9 3/20 8/37 12/61
P 8/23 8/29 12/39 11/40 11/35 10/37 8/30 4/29 7/42 17/88
R 2/7 3/11 2/4 2/5 2/4 2/8 1/2 0 4/13 6/24
S 1/2 4/8 3/8 3/8 3/8 3/8 1/1 1/2 1/1 4/11
C 1/4 5/12 3/7 2/4 2/4 3/8 2/4 1/2 2/6 7/21
M 1/2 6/20 7/29 7/23 6/21 6/20 5/16 4/22 7/39 12/73
I 0 0 0 0 1/2 1/2 1/2 0 1/2 2/4
Y 0 4/15 0 0 4/13 4/14 0 3/21 0 5/35
Q - 2/7 0 0 1/4 1/4 2/8 - - 3/15
D 6/16 8/22 - - - - - - - 10/28
T - 5/13 - - - - - - 1/2 5/13
X 0 0 0 0 0 0 0 - 0 0
 
29/80 63/191 49/155 46/147 50/155 50/169 36/110 27/143 43/192 107/479
Table 3: Attribute and attribute-value cardinalities of MSDs
of features with examples; (3) full lists of lexical
MSDs with examples and cardinality.
The minimal content of a language section is
just (1); these are identical to the common ones,
but containing only the relevant pairs for the lan-
guage. These tables can then be further extended,
say with notes and examples, and can even be lo-
calised to the language in question.
In addition to the tables, the MULTEXT-East
languages also have a section giving the feature
co-occurrence restrictions on attribute-value pairs.
These tables specify the allowed combinations of
attribute-values for each PoS, and give a regular
expression grammar of MSDs.
The Combinations Sections are useful in the be-
ginning stages of developing lexica, as they isolate
malformed MSDs in the resources. However, it is
often easier to operate with simple lists of MSDs,
as not all possibilities allowed by combinations ac-
tually occur in the language.
That is why some languages have, instead of
or in addition to the combinations section an ex-
plicit list of valid MSDs per category; these lists
can then serve as a ?gold standard? MSD set for
the language; it should be noted that due to rich
inflection, the cardinalities of the Slavic language
MSDs can be well over a thousand.
3 The Slavic Languages
In this section we further discuss the specifications
for the Slavic languages; in particular, we give the
historical context in which they were developed
and how they related to other MSD tagsets devel-
oped for the five languages.
3.1 Bulgarian
At the time when the MULTEXT-East project
started there existed two wide coverage morpho-
logical lexica for Bulgarian (Morpho-Assistant,
Slovnik), both of which encoded the morphosyn-
tactic features of word forms as lists of attribute-
value pairs. On the basis of Morpho-Assistant two
tagsets were defined: the Bulgarian part of the
EAGLES tagset and the LML tagset. On the basis
of Slovnik lexicon also two tagsets were defined
? first, the Bulgarian part of the MULTEXT-East
tagset, which was then extended and localised to
Bulgarian (using Cyrillic letters). The two Bulgar-
ian tagsets ? LML and Slovnik ? are richer than
EAGLES and MULTEXT-East tagsets; for a com-
parison with the LML tagset and discussion see
(Slavcheva, 1997).
For the purposes of the BulTreeBank project
(Simov et al, 2002), the Slovnik tagset was
adapted by having been converted into a Latin for-
mat and modified in several ways: there were in-
troduced separate tags for the auxiliary verbs and
a hybrid POS tag referring to family names and
adjectives derived from names; the pronoun ad-
verbials were made more fine-grained etc. This
tagset is being used for the annotation of the Bul-
TreeBank Text Archive. The lexicon is encoded
as a regular grammar within the CLaRK system
(Simov et al, 2001).
3.2 Croatian
The Croatian specifications were compiled soon
after the MULTEXT-East project ended in 1997,
using the project?s Final report as the template.
These specifications are used in the PoS-tagging
and lemmatisation of the Croatian National Cor-
pus (Tadic?, 2002). It was also selected for the for-
mat of MSDs accompanying word-forms in Croa-
tian Morphological Lexicon (Tadic?, 2003) which
is conformant with MULTEXT-East lexica.
3.3 Czech
The morphological specifications for Czech were
developed exclusively for the MULTEXT-East
project but the authors had already had some expe-
rience with the first draft of morphological speci-
fications for Czech which is now thoroughly de-
scribed in (Hajic?, 2002). These specifications and
the resulting tagset developed by Hajic? are nowa-
days used as a standard for morphological and
morphosyntactic annotations of the majority of
Czech corpora, especially the 100 million word
corpus of synchronic Czech developed within the
Czech National Corpus project. From the present
viewpoint, the MULTEXT-East specifications for
Czech can be regarded as a subset of this stan-
dard. The formalism of both annotation schemes
is similar in that both use positional attributes, the
important difference being that in MULTEXT-East
the attribute position is PoS-dependent, whereas in
the standard specifications each attribute is always
identified with a fixed position in the tag string.
Among the Czech morphologically annotated
corpora, only the Czech translation of 1984 is
annotated by the MULTEXT-East specifications.
The MULTEXT-East annotation of this corpus was
mapped to the standard annotation, i.e., both 1984
corpora differing only in the tagsets used can now
be accessed ? both are included in the Czech Na-
tional Corpus.
3.4 Serbian
The Serbian language did not have its represen-
tative either in the MULTEXT-East project nor in
Concede. The researchers from the Faculty of
Mathematics, however, participated in both the
TELRI-I and TELRI-II concerted actions. One
of the results of this participation was the Serbian
1984 Doc corpus, but the morphosyntactic speci-
fication, lexicon and MSD tagged 1984 were not
produced.
Independently of these European projects, the
same team was working on the production of a
Serbian morphological lexicon (Du?ko Vitas and
Cvetana Krstev, 2001) in the format of the INTEX
system, which is based on the technology of finite-
state transducers (Silberztein, 2000).
The team from the Faculty of Belgrade plans to
convert its INTEX lexicon to a MSD-type lexicon.
It is to be expected that Serbian MSDs will not dif-
fer much from the Croatian ones, as Serbian and
Croatian are at the morphological level very sim-
ilar. The combination of features and lexicon it-
self will exhibit more differences. A further plan
is to produce the annotated version of 1984 that
will also be used in the scope of BalkaNet project
for the validation of the Serbian WordNet being
produced, along with the other languages involved
in both MULTEXT-East and BalkaNet, i.e., Czech,
Bulgarian and Romanian.
3.5 Slovene
The first version of the Slovene specifications
was produced in the scope of the MULTEXT-East
project. The second version of the guidelines was
produced for the 100 million word FIDA Slovene
reference corpus, (Krek et al, 1998). Here the
specifications were revised and localised. In par-
ticular, all the PoS, attribute, and value names,
as well as value codes have been translated into
Slovene; the Slovene MSDs are used in the FIDA
corpus. The localisation is achieved by extend-
ing the tables with additional columns, giving the
translation of the symbol(s) and code.
The FIDA MSD specifications were subse-
quently harmonised with the common MULTEXT-
East tables and then released in the context of
CONCEDE; since then they have been used in a
number of other corpus projects.
4 The TEI encoding
As has been mentioned, the complete specifica-
tions are written in LATEX, where the common ta-
bles are plain ASCII in a strictly defined format.
This, over time, has proved to be a good choice,
as the format had to be portable and durable, as
well as useful for further processing. While we
did write several Perl scripts to process or use the
common tables, their structure and that of other
parts of the specifications (e.g., the combinations)
are still quite implicit, and writing a parsing pro-
gram is not trivial.
For re-use it would certainly be beneficial if the
specifications were converted into a standard in-
terchange format, with the obvious choice being
XML. As the MULTEXT-East corpus is already
encoded in TEI (Sperberg-McQueen and Burnard,
2002), we pursued the option of using already ex-
isting TEI tag-sets to encode (parts of) the specifi-
cations.
We have defined the MSD IDs in a TEI feature-
value library. Additionally, we have also taken the
common tables of the specifications and converted
these to a TEI feature library, and provided a de-
composition from the IDs (MSDs) to the attribute-
values and their names.
First, we needed to define the list of all valid
MSDs. This, of course, includes the MSDs used in
the corpus, but also the MSDs culled from the lex-
icons; this list then constitutes the authoritative set
of valid MSDs for each particular language, and is
also included in the language specific sections of
the specification.
The MSDs are then encoded as a feature
structure library,   fsLib  , where each MSD is
expressed as a feature structure specifying its
type (the category, i.e., Part of Speech), the
language(s) the MSD is appropriate for, and its
decomposition into features. The value of   feats 
is of type IDREFs, i.e., it contains pointers to the
definitions of the attribute/value pairs, e.g., <fs
id="Npmpa" type="Noun" select="cs
sl" feats="N1.p N2.m N3.p N4.a"/>
The attribute/value pair definitions are given
in the common tables of the morphosyntac-
tic specifications and are encoded as a TEI
feature library,   fLib  . For each feature we
give, apart from its identifier, the languages
it is appropriate for and the full name of its
attribute, while its value is encoded as the con-
tent of the feature, as a symbol with the full
name of its value, e.g., <f id="N4.a" se-
lect="cs hu sl" name="Case"><sym
value="accusative"/>
In the corpus, both libraries are stored in a
dedicated corpus element, together with the TEI
header. Eventually, the complete morphosyntactic
specifications should be converted from LATEX to
TEI and stored in this element.
5 Conclusions
The paper presented the EAGLES & MULTEXT-
based multilingual morphosyntactic specifica-
tions, which currently include five Slavic lan-
guages. Presented were the MULTEXT-East
project deliverables and their various editions, esp.
those that deal with morphosyntactic resources.
The structure and formats of the specifications
were discussed, and the Slavic languages intro-
duced in more depth.
As mentioned, of the current Slavic languages,
Croatian and Serbian do not yet have the lexical
and corpus resource utilising the MSDs defined in
the specifications; we hope to remedy this short-
coming sometime in the future, as only with such
resources can we validate, quantify and exemplify
the specifications. It should be noted that both lan-
guages already have lexica that need only to be
converted to MULTEXT-East MSDs but producing
the MSD tagged 1984 corpus is more complex;
while both languages already have the text in digi-
tal form, the manual annotation of 100,000 tokens
with MSDs is a labour intensive process.
The format of the specifications makes it quite
easy to add new languages, although choosing
which attributes and values to use, and which
word-forms and lemmas to assign them too is far
from simple, not only because of the difference in
languages, but also due to different linguistic tra-
ditions as well as computational models.
In our further work on the specifications, it
would be of course beneficial to add new lan-
guages, and also to re-evaluate some current
choices in the specifications. On the encoding
side, we would like to move to complete speci-
fications to a full TEI/XML encoding and XSLT
processing.
Acknowledgements
The complete lists of contributors and acknowl-
edgements are given in the MULTEXT-East Mor-
phosyntactic Specifications, also in the language
particular sections. The authors would like to
thank all the people mentioned there. The work on
these specifications was supported by EU projects
MULTEXT-East, CONCEDE and TELRI-II. The
work on the individual languages was further sup-
ported by various partners? grants and contracts.
References
Ludmila Dimitrova, Toma? Erjavec, Nancy Ide, Heiki-
Jan Kaalep, Vladim?r Petkevic?, and Dan Tufis?.
1998. Multext-East: Parallel and Comparable Cor-
pora and Lexicons for Six Central and Eastern Euro-
pean Languages. In COLING-ACL ?98, pages 315?
319, Montr?al, Qu?bec, Canada. http://nl.ijs.si/ME/.
Du?ko Vitas and Cvetana Krstev. 2001. Intex and
Slavonic Morphology. In 4es Journ?es INTEX, Bor-
deaux. In print.
Sa?o D?eroski, Toma? Erjavec, and Jakub Zavrel.
2000. Morphosyntactic Tagging of Slovene: Eval-
uating PoS Taggers and Tagsets. In Second Interna-
tional Conference on Language Resources and Eval-
uation, LREC?00, pages 1099?1104, Paris. ELRA.
Toma? Erjavec and Nancy Ide. 1998. The MULTEXT-
East corpus. In LREC?98, pages 971?974, Granada.
ELRA.
Toma? Erjavec, Roger Evans, Nancy Ide, and Adam
Kilgarriff. 2000. The Concede Model for Lexi-
cal Databases. In LREC?00, pages 355?362, Paris.
ELRA.
Toma? Erjavec (ed.). 2001. Specifications and
Notation for MULTEXT-East Lexicon Encod-
ing. MULTEXT-East Report, Concede Edition
D1.1F/Concede, Jo?ef Stefan Institute, Ljubljana.
http://nl.ijs.si/ME/V2/msd/.
Toma? Erjavec. 2001a. Harmonised Morphosyntactic
Tagging for Seven Languages and Orwell?s 1984. In
6th Natural Language Processing Pacific Rim Sym-
posium, NLPRS?01, pages 487?492, Tokyo.
Toma? Erjavec. 2001b. The MULTEXT-East Re-
sources Revisited. ElsNews, 10(1):3?2.
Jan Hajic?. 2000. Morphological Tagging: Data vs.
Dictionaries. In ANLP/NAACL 2000, pages 94?101,
Seattle.
Jan Hajic?. 2002. Disambiguation of Rich Inflec-
tion (Computational Morphology of Czech), Vol. 1.
Karolinum Charles University Press, Prague.
Nancy Ide and Jean V?ronis. 1994. Multext (multi-
lingual tools and corpora). In COLING?94, pages
90?96, Kyoto.
Nancy Ide, Dan Tufis?, and Toma? Erjavec. 1998.
Development and Assessment of Common Lexical
Specifications for Six Central and Eastern European
Languages. In LREC?98, pages 233?240, Granada.
ELRA.
Simon Krek, Marko Stabej, Vojko Gorjanc, Toma? Er-
javec, Miro Romih, and Peter Holozan. 1998.
FIDA: a Corpus of the Slovene Language.
http://www.fida.net/.
Max Silberztein. 2000. INTEX. Masson.
Kiril Simov, Zdravko Peev, Milen Kouylekov, Alexan-
der Simov, Marin Dimitrov, and Atanas Kiryakov.
2001. CLaRK ? an XML-based System for Corpora
Development. In Corpus Linguistics 2001, pages
558?560, Lancaster, England.
Kiril Simov, Gergana Popova, and Petya Osenova.
2002. HPSG-based syntactic treebank of Bulgarian
(BulTreeBank). In Andrew Wilson, Paul Rayson,
and Tony McEnery, editors, A Rainbow of Corpora:
Corpus Linguistics and the Languages of the World,
pages 135?142. Lincom-Europa, Munich.
Milena Slavcheva. 1997. A Comparative Rep-
resentation of Two Bulgarian Morphosyntactic
Tagsets and the EAGLES Encoding Standard.
http://www.lml.acad.bg/projects/BG-EUstand/.
C. M. Sperberg-McQueen and Lou Burnard, editors.
2002. Guidelines for Electronic Text Encoding and
Interchange, The XML Version of the TEI Guide-
lines. The TEI Consortium. http://www.tei-c.org/.
Marko Tadic?. 2002. Building the Croatian National
Corpus. In LREC?02, pages 441?446, Paris. ELRA.
Marko Tadic?. 2003. Building the Croatian Morpho-
logical Lexicon. In [this volume]. ACL.
Dan Tufis?. 1999. Tiered Tagging and Combined Lan-
guage Model Classifiers. In Jelinek and Noth, ed-
itors, Text, Speech and Dialogue, number 1692 in
LNAI, pages 28?33, Berlin. Springer-Verlag.
Proceedings of the Fifth Law Workshop (LAW V), pages 11?20,
Portland, Oregon, 23-24 June 2011. c?2011 Association for Computational Linguistics
OWL/DL formalization of the MULTEXT-East morphosyntactic
specifications
Christian Chiarcos
University of Potsdam, Germany
chiarcos@uni-potsdam.de
Tomaz? Erjavec
Joz?ef Stefan Institute, Slovenia
tomaz.erjavec@ijs.si
Abstract
This paper describes the modeling of
the morphosyntactic annotations of the
MULTEXT-East corpora and lexicons as
an OWL/DL ontology. Formalizing anno-
tation schemes in OWL/DL has the advan-
tages of enabling formally specifying in-
terrelationships between the various fea-
tures and making logical inferences based
on the relationships between them. We
show that this approach provides us with
a top-down perspective on a large set of
morphosyntactic specifications for multi-
ple languages, and that this perspective
helps to identify and to resolve concep-
tual problems in the original specifications.
Furthermore, the ontological modeling al-
lows us to link the MULTEXT-East spe-
cifications with repositories of annotation
terminology such as the General Ontol-
ogy of Linguistics Descriptions or the ISO
TC37/SC4 Data Category Registry.
1 Introduction
In the last 15 years, the heterogeneity of linguis-
tic annotations has been identified as a key prob-
lem limiting the interoperability and reusabil-
ity of NLP tools and linguistic data collections.
The multitude of linguistic tagsets complicates
the combination of NLP modules within a sin-
gle pipeline; similar problems exist in language
documentation, typology and corpus linguistics,
where researchers are interested to access and
query data collections on a homogeneous termi-
nological basis.
One way to enhance the consistency of lin-
guistic annotations is to provide explicit seman-
tics for tags by grounding annotations in termino-
logy repositories such as the General Ontology
of Linguistics Descriptions (Farrar and Langen-
doen, 2003, GOLD) or the ISO TC37/SC4 Data
Category Registry (Kemps-Snijders et al, 2009,
ISOcat). Reference definitions provide an inter-
lingua that allows the mapping of linguistic an-
notations from annotation scheme A to scheme
B. This application requires linking annotation
schemes with the terminological repository. This
relation can be formalized within the Linked Data
paradigm (Berners-Lee, 2006), which requires
the use of uniform resource identifiers (URIs),
the hypertext transfer protocol (HTTP), standard
representation formats (such as RDF) and links to
other URIs. Here, we propose a formalization of
this linking in OWL/DL, a notational variant of
the Description Logic SHOIN (D) that builds
on RDF and Linked Data.
Another way to enhance the consistency of
linguistic annotations is to make use of cross-
linguistic meta schemes or annotation standards,
such as EAGLES (Leech and Wilson, 1996). The
problem is that these enforce the use of the same
categories across multiple languages, and this
may be inappropriate for historically and geo-
graphically unrelated languages. For specific lin-
guistic and historical regions, the application of
standardization approaches has, however, been
performed with great success, e.g., for Western
(Leech and Wilson, 1996) and Eastern Europe
(Erjavec et al, 2003) or the Indian subcontinent
(Baskaran et al, 2008).
11
In this paper, we illustrate differences and
commonalities of both approaches by creating
an OWL/DL terminology repository from the
MULTEXT-East (MTE) specifications (Erjavec
et al, 2003; Erjavec, 2010), which define features
for the morphosyntactic level of linguistic de-
scription, instantiate them for 16 languages and
provide morphosyntactic tagsets for these lan-
guages. The specifications are a part of the MTE
resources, which also include lexicons and an an-
notated parallel corpus that use these morphosyn-
tactic tagsets.
The encoding of the MTE specifications fol-
lows the Text Encoding Initiative Guidelines, TEI
P5 (TEI Consortium, 2007), and this paper con-
centrates on developing a semi-automatic pro-
cedure for converting them from TEI XML to
OWL. While TEI is more appropriate for author-
ing the specifications and displaying them in a
book-oriented format, the OWL encoding has the
advantages of enabling formally specifying inter-
relationships between the various features (con-
cepts, or classes) and making logical inferences
based on the relationships between them, useful
in mediating between different tagsets and tools
(Chiarcos, 2008).
2 The MULTEXT-East (MTE)
Morphosyntactic Specifications
The MTE morphosyntactic specifications define
attributes and values used for word-level syntac-
tic annotation, i.e., they provide a formal gram-
mar for the morphosyntactic properties of the lan-
guages covered. The specifications also contain
commentary, bibliography, notes, etc. Follow-
ing the original MULTEXT proposal (Ide and
Ve?ronis, 1994), the specifications define 14 cat-
egories (parts of speech), and for each its at-
tributes, their values, and the languages that every
attribute-value pair is appropriate for. The mor-
phosyntactic specifications also define the map-
ping between the feature structures and mor-
phosyntactic descriptions (MSDs). MSDs are
compact strings used as tags for corpus annota-
tion and in the morphosyntactic lexicons. For
example, the MSD Ncmsn is equivalent to the
feature structure consisting of the attribute-value
pairs Noun, Type=common, Gender=masculine,
Number=singular, Case=nominative.
The specifications currently cover 16 lan-
guages, in particular: Bulgarian, Croatian,
Czech, English, Estonian, Hungarian, Macedo-
nian, Persian, Polish, Resian, Romanian, Rus-
sian, Serbian, Slovak, Slovene, and Ukrainian.
For a number of these languages the specifica-
tions have become a de-facto standard and, for
some, the MTE lexicons and corpora are still the
only publicly available datasets for this level of
linguistic description.1
Table 1 lists the defined categories and gives
the number of distinct attributes, attribute-value
pairs and the number of MTE languages which
distinguish the category. The feature-set is quite
large, as many of the languages covered have
very rich inflection, are typologically different
(inflectional, agglutinating), but also have inde-
pendent traditions of linguistic description; this
also leads to similar phenomena sometimes be-
ing expressed by different means (see Sect. 4.3).
Category Code Atts Att-Vals Langs
Noun N 14 68 16
Verb V 17 74 16
Adjective A 17 79 16
Pronoun P 19 97 16
Determiner D 10 32 3
Article T 6 23 3
Adverb R 7 28 16
Adposition S 4 12 16
Conjunction C 7 21 16
Numeral M 13 81 16
Particle Q 3 17 12
Interjection I 2 4 16
Abbreviation Y 5 35 16
Residual X 1 3 16
Table 1: MULTEXT categories with the number
of MULTEXT-East defined attributes, attribute-value
pairs and languages.
The specifications are encoded as a TEI doc-
ument, consisting of an introductory part, the
Common and the Language Specific Specifica-
tions, the latter two organized into tables by the
1The MTE specifications, as well as the other MTE re-
sources, are available from the Web page of the project at
http://nl.ijs.si/ME/.
12
<table n="msd.cat" xml:lang="en">
<head>Common specifications for Noun</head>
<row role="type">
<cell role="position">0</cell>
<cell role="name">CATEGORY</cell>
<cell role="value">Noun</cell>
<cell role="code">N</cell>
<cell role="lang">en</cell>
<cell role="lang">ro</cell>
<cell role="lang">sl</cell>
...
</row>
<row role="attribute">
<cell role="position">1</cell>
<cell role="name">Type</cell>
<cell>
<table>
<row role="value">
<cell role="name">common</cell>
<cell role="code">c</cell>
<cell role="lang">en</cell>
...
Figure 1: Common table for Noun
14 defined categories.
Figure 1 gives the start of the Common table
for Noun. It first gives the category, the lan-
guages that distinguish it, and then its attributes
with their values; the meaning of a particular row
or cell is given by its role attribute. As with the
category, each attribute-value is also qualified by
the languages that make use of the feature. Note
that MTE is a positional tagset that specifies the
position of the attribute in the MSD string, and
the one-letter code of its value, so that Nc would
correspond to Noun, Type=common.
The language-specific sections also contain ta-
bles for each category, which are similar to the
common tables in that they repeat the attributes
and their values, although only those appropri-
ate for the language. The language-specific ta-
bles can also contain localization information,
i.e., the names of the categories, attributes, their
values and codes in the particular language, in
addition to English. This enables expressing the
feature structures and MSDs either in English or
in the language in question. Furthermore, each
language-specific section can also contain an in-
dex listing all valid MSDs. This index is aug-
mented with frequency information and exam-
ples of usage drawn for a corpus.
In addition to the source TEI P5 XML, the
MTE specifications are delivered in various de-
rived formats, in particular HTML for reading
and as tabular files, which map the MSD tagset
into various feature decompositions.
3 Linking annotation schemes with
terminology repositories
3.1 Linguistic terminology initiatives
There have been, by now, several approaches
to develop terminology repositories and data
category registries for language resources, sys-
tems for mapping between diverse (morphosyn-
tactic) vocabularies and for integrating annota-
tions from different tools and tagsets, ranging
from early texts on annotation standards (Bakker
et al, 1993; Leech and Wilson, 1996) over re-
lational models and concept hierarchies (Bickel
and Nichols, 2002; Rosen, 2010) to more formal
specifications in OWL/RDF (or with OWL/RDF
export), e.g., the already mentioned GOLD and
ISOcat, OntoTag (Aguado de Cea et al, 2002)
or the Typological Database System ontology
(Saulwick et al, 2005).
Despite their common level of representation
these efforts have not yet converged into a unified
and generally accepted ontology of linguistic an-
notation terminology and there is still a consider-
able amount of disagreement between their def-
initions. As these repositories nevertheless play
an important role in their respective communi-
ties, it is desirable to link the MTE specifications
with the most representative of them, notably
with GOLD and the morphosyntactic profile of
ISOcat. As we argue below, different design de-
cisions in the terminology repositories make it
necessary to use a linking formalism that is capa-
ble of expressing both disjunctions and conjunc-
tions of concepts. For this reason, we propose the
application of OWL/DL.
By representing the MTE specifications, the
repositories, and the linking between them as
separate OWL/DL models, we follow the archi-
tectural concept of the OLiA architecture (Chiar-
cos, 2008), see Sect. 5.
13
3.2 Annotation mapping
The classic approach to link annotations with ref-
erence concepts is to specify rules that define a
direct mapping (Zeman, 2008). It is, however,
not always possible to find a 1:1 mapping.
One problem is conceptual overlap: A com-
mon noun may occur as a part of a proper name,
e.g., German Palais ?baroque-style palace? in
Neues Palais lit. ?new palace?, a Prussian royal
palace in Potsdam/Germany. Palais is thus both a
proper noun (in its function), and a common noun
(in its form). Such conceptual overlap is some-
times represented with a specialized tag, e.g., in
the TIGER scheme (Brants and Hansen, 2002).
ISOcat (like other terminological repositories)
does currently not provide the corresponding hy-
brid category, so that Palais is to be linked to both
properNoun/DC-1371 and commonNoun/DC-
1256 if the information carried by the original
annotation is to be preserved. Contractions pose
similar problems: English gonna combines going
(PTB tag VBG, Marcus et al, 1994) and to (TO).
If whitespace tokenization is applied, both tags
need to be assigned to the same token.
A related problem is the representation of am-
biguity: The SUSANNE (Sampson, 1995) tag
ICSt applies to English after both as a prepo-
sition and as a subordinating conjunction. The
corresponding ISOcat category is thus either
preposition/DC-1366 or subordinating
Conjunction/DC-1393. Without additional
disambiguation, ICSt needs to be linked to both
data categories.
Technically, such problems can be solved with
a 1:n mapping between annotations and refer-
ence concepts. Yet, overlap/contraction and am-
biguity differ in their meaning: While overlap-
ping/contracted categories are in the intersec-
tion (?) of reference categories, ambiguous cate-
gories are in their join (?). This difference is rel-
evant for subsequent processing, e.g., to decide
whether disambiguation is necessary. A mapping
approach, however, fails to distinguish ? and ?.
The linking between reference categories and
annotations requires a formalism that can distin-
guish intersection and join operators. A less ex-
pressive linking formalism that makes use of a
1:1 (or 1:n) mapping between annotation con-
cepts and reference concepts can lead to inconsis-
tencies when mapping annotation concepts from
an annotation scheme A to an annotation scheme
B if these use the same terms with slightly deviat-
ing definitions, as noted, for example, by Garab??k
et al (2009) for MTE.
3.3 Annotation linking with OWL/DL
OWL/DL is a formalism that supports the nec-
essary operators and flexibility. Reference con-
cepts and annotation concepts are formalized
as OWL classes and the linking between them
can be represented by rdfs:subClassOf (?).
OWL/DL provides owl:intersectionOf (?),
owl:unionOf (?) and owl:complementOf
(?) operators and it allows the definition of prop-
erties and restrictions on the respective concepts.
As an example, the MTE Definiteness=definite
refers to either a clitic determiner or (?) to the
?definite conjunction? of Hungarian verbs. More
precisely, it is in the intersection between these
and (?) a category for ambiguous feature values
(Sect. 4.3).
An OWL/DL-based formalization has the ad-
ditional advantage that it can be linked with exist-
ing terminology repositories that are available in
OWL or RDF, e.g., GOLD or ISOcat (Chiarcos,
2010). The linking to other terminology reposi-
tories will be subject of subsequent research. In
this paper, we focus on the development of an
OWL/DL representation of MTE morphosyntac-
tic specifications that represents a necessary pre-
condition for OWL/DL-based annotation linking.
4 Building the MTE ontology
We built the MTE ontology2 in a three-step sce-
nario: first, a preliminary OWL/DL model of the
common MTE specifications was created (Sect.
4.1); we then built language-specific subontolo-
gies and linked them to the common ontology
(Sect. 4.2); finally, the outcome of this process
2All MTE ontologies are available under
http://nl.ijs.si/ME/owl/ under a Creative
Commons Attribution licence (CC BY 3.0).
14
was discussed with a group of experts and revised
(Sect. 4.3).
4.1 Common specifications
Following the methodology described by Chiar-
cos (2008), the structure of the MTE ontology
was derived from the original documentation.
The initial ontology skeleton was created auto-
matically (the organization of the specifications
was exploited to develop an XSLT script that
mapped TEI XML to OWL), but subsequently
manually augmented with descriptions and ex-
amples found in the individual languages.
1. Two top-level concepts Morphosyn-
tacticCategory and Morphosyntac-
ticFeature represent root elements of
the MTE ontology. An object property
hasFeature maps a Morphosyntac-
ticCategory onto one or multiple
MorphosyntacticFeature values.
2. All MSD categories are subconcepts of
MorphosyntacticCategory, e.g., Noun,
Verb, Adjective, etc.
3. For every category, the MTE attribute
Type was used to infer subcategories, e.g.,
the concept ExclamativePronoun (?
Pronoun) for Pronoun/Type=exclamative.
4. From more specialized type attributes
(e.g., Wh Type, Coord Type, Sub Type,
and Referent Type), additional subcate-
gories were induced at the next deeper
level, e.g., SimpleCoordinatingCon-
junction (? CoordinatingConjunc-
tion) from Conjunction/Type=coordina-
ting, Coord Type=simple.
5. All remaining attributes are subconcepts
of MorphosyntacticFeature, e.g.,
Aspect, Case, etc.
6. For every subconcept of Morphosyntac-
ticFeature (e.g., Aspect) a corres-
ponding hasFeature subproperty (e.g.,
hasAspect) was introduced, with the mor-
phosyntactic feature as its range and the join
of morphosyntactic categories it can cooc-
cur with as its domain. An additional con-
straint restricts its cardinality to at most 1.
7. All attribute values are represented as
subclasses of the corresponding at-
tribute concept, e.g., AbessiveCase (for
Case=abessive) as a subconcept of Case.3
8. Every concept was automatically aug-
mented with a list of up to 10 examples for
every language which were drawn from the
language-specific MSD index.
4.2 Language-specific subontologies
Having represented the common MTE specifica-
tions in OWL, we decided to represent the an-
notation scheme for every language in a separate
OWL model, and to make use of the OWL im-
port mechanism to link it with the common spe-
cifications. The language-specific subontologies
do not specify their own taxonomy, but rather
inherit the concepts and properties of the com-
mon model. Unlike the common model, they in-
clude individuals that provide information about
the tags (MSDs) used for this particular language.
Every individual corresponds to an MSD tag.
We use data properties of the OLiA system on-
tology4 to indicate its string realization (e.g.,
system:hasTag ?Ncmsn?) and the designator
of its annotation layer (e.g., system:hasTier
?pos?). Additionally, rdfs:comment elements
contain all examples of the original MSD speci-
fications.
In accordance to the specified annotation val-
ues, every individual is defined as an instance
of the corresponding MorphosyntacticCate-
gory (e.g., Noun) and MorphosyntacticFea-
ture (e.g., SingularNumber) from the com-
mon specifications. Additionally, for every Mor-
phosyntacticFeature (e.g., Number, the su-
perconcept of SingularNumber), it is assigned
3This ontology does not contain individuals. In our
approach, individuals represent feature bundles in the
language-specific subontologies, corresponding to the indi-
vidual MSD tags. (or, in other application scenarios, the
token that the tag is applied to).
4http://nachhalt.sfb632.uni-potsdam.de/
owl/system.owl, prefix system
15
<mte:Noun rdf:ID="Ncmsn_sl">
<system:hasTag>Ncmsn</system:hasTag>
<system:hasTier>pos</system:hasTier>
<rdf:type
rdf:resource="...#CommonNoun"/>
<rdf:type
rdf:resource="...#MasculineGender"/>
<rdf:type
rdf:resource="...#SingularNumber"/>
<rdf:type
rdf:resource="...#NominativeCase"/>
<mte:hasGender rdf:resource="#Ncmsg_sl"/>
<mte:hasNumber rdf:resource="#Ncmsg_sl"/>
<mte:hasCase rdf:resource="#Ncmsg_sl"/>
<rdfs:comment>e.g., cas, svet, denar, ...
</mte:Noun>
Figure 2: MSD Ncmsn in the Slovene subontology
itself as target of the corresponding object prop-
erty (e.g., hasNumber).
Figure 2 shows the subontology entry for the
tag Ncmsn in the Slovene subontology. The indi-
vidual could thus be retrieved with the following
queries for ?singular noun?:
(1) Noun and hasNumber some
SingularNumber
(2) Noun and SingularNumber
The language-specific subontologies were fully
automatically created from the TEI XML using
XSLT scripts. During the revision of the com-
mon specifications, these scripts were updated
and reapplied.
4.3 Revision of the initial OWL model
After the automatic conversion from XML to
OWL the resulting ontology skeleton of the
common specifications was manually augmented
with descriptions, explanations and selected
examples from the language-specific MTE spe-
cifications. Furthermore, concept names with ab-
breviated or redundant names were adjusted, e.g.,
the concept CorrelatCoordConjunction
(Coord Type=correlat) was expanded to
CorrelativeCoordinatingConjunction,
and DefiniteDefiniteness (Definite-
ness=definite) was simplified to Definite.
Finally, if one attribute value represents a
specialization of another, the former was
recast as a subconcept of the latter (e.g.,
CliticProximalDeterminer ? CliticDe-
finiteDeterminer).
Moreover, a number of potential problems
were identified. Some of them could be ad-
dressed by consulting MTE-related publications
(Qasemizadeh and Rahimi, 2006; Dimitrova et
al., 2009; Derzhanski and Kotsyba, 2009), but
most were solved with the help of the original
authors of the MTE specifications and an open
discussion with these experts over a mailing list.
The problems fall in two general classes:
(a) terminological problems, and (b) conceptual
problems. By terminological problems we mean
that a term required a more precise definition
than provided in the MTE specifications; con-
ceptual problems pertain to design decisions in
a positional tagset (overload: the same annota-
tion refers to two different phenomena in dif-
ferent languages) and to artifacts of the creation
process of the MTE specifications (redundancies:
the same phenomenon is represented in different
ways for different languages). Figure 3 shows
a fragment of the MTE ontology that showed all
types of conceptual problems as described below.
Terminological problems include the use of
non-standard or language-specific terminology
(e.g., Clitic=burkinostka for conventional collo-
cations in Polish, or Case=essive-formal for Hun-
garian), and the need to understand design deci-
sions that were necessary for language-specific
phenomena (e.g., Numeral/Class=definite34 for
Czech and Polish quantifiers with the same pat-
terns of agreement as the numerals 3 and 4).
In the course of the revision, most non-
standard terms were replaced with conven-
tional, language-independent concept names, and
language-specific phenomena were documented
by adding relevant excerpts from discussions or
literature as owl:versionInfo.
For a few concepts, no language-independent
characterization could be found. For exam-
ple, Numeral/Form=m form refers to numer-
als with the suffix -ma in Bulgarian (a special
form of the numerals ?2? to ?7? for persons of
masculine gender). In the ontology, the con-
cept MFormNumeral is preserved, but it is con-
strained so that every instance matches the fol-
16
lowing OWL/DL expression:
(3) CardinalNumber and hasAnimacy some
Animate and hasGender some Masculine
Attribute overload means that one attribute
groups together unrelated phenomena from dif-
ferent languages. In a positional tagset, attribute
overload is a natural strategy to achieve compact
and yet expressive tags. As every attribute re-
quires its own position in the tag, the length of
MSD tags grows with the number of attributes.
Overload thus reduces tag complexity. To an on-
tological model, however, these complexity con-
siderations do not apply, whereas proper concep-
tual differentiations are strongly encouraged.
We thus decided to disentangle the various
senses of overloaded attributes. For example, the
MorphosyntacticFeature Definiteness,
is split up in three subconcepts (cf. Fig. 3).
CliticDeterminerType: presence of a post-
fixed article of Romanian, Bulgarian and
Persian nouns and adjectives.
ReductionFeature: the difference between
full and reduced adjectives in many Slavic
languages.
PersonOfObject: the so-called ?definite con-
jugation? of Hungarian verbs.
Value overload has a similar meaning to at-
tribute overload. Definiteness=definite, for ex-
ample, can refer to a clitic definite determiner
(a CliticDeterminerType in Romanian and
Bulgarian), to a clitic determiner that expresses
specificity (a CliticDeterminerType in Per-
sian), or to a verb with a definite 3rd-person di-
rect object (a PersonOfObject in Hungarian).
In the ontology, this is represented by defin-
ing Definite as a subconcept of the owl:join
(?) of CliticDefiniteDeterminer, Cli-
ticSpecificDeterminer and PersonOfOb-
ject. Additional concepts, e.g., Ambigu-
ousDefinitenessFeature, were created to
anchor ambiguous concepts like Definite in
the taxonomy (see Fig. 3).
Redundancy: For many languages, the MTE
specifications were created in a bottom-up fash-
ion, where existing NLP tools and lexicons were
Figure 3: Definiteness in the MTE ontology
integrated with a pre-existing taxonomy of an-
notation categories. Language-specific features
were introduced when necessary, but sometimes
in different ways for the same phenomenon in
closely related languages. The MTE specifica-
tions thus comprise a certain degree of redun-
dancy.
For example, the distinction between full and
reduced adjectives in Slavic languages is ex-
pressed differently: For Czech, reduced adjec-
tives are marked by Formation=nominal, but for
Polish by Definiteness=short-art.
In the ontology, such redundancies are re-
solved by owl:equivalentClass statements,
marked by ? in Fig. 3.
5 Summary and Discussion
We have described the semi-automatic creation
of an ontological model of the MTE morphosyn-
tactic specifications for 16 different languages.
Such a model may be fruitfully applied in
various ways, e.g., within an NLP pipeline that
uses ontological specifications of annotations
rather than their string representations (Buyko
et al, 2008; Hellmann, 2010). The ontolog-
ical modeling may serve also as a first step
towards an ontology-based documentation of
the annotations within a corpus query system
(Rehm et al, 2007; Chiarcos et al, 2008),
17
or even the ontological modeling of entire
corpora (Burchardt et al, 2008; Hellmann et
al., 2010) and lexicons (Martin et al, 2009).
As an interesting side-effect of the OWL con-
version of the entire body of MTE resources,
they could be easily integrated with existing
lexical-semantic resources as Linked Data, e.g.,
OWL/RDF versions of WordNet (Gangemi et
al., 2003), which are currently being assem-
bled by various initiatives, e.g., in the context
of the LOD2 project (http://lod2.eu)
and by the Open Linguistics Working
Group at the OpenKnowledge Foundation
(http://linguistics.okfn.org).
Another very important element is that the on-
tological modeling of the MTE annotations al-
lows it to be interpreted in terms of existing
repositories of annotation terminology such as
ISOcat and GOLD. A bridge between these ter-
minology repositories and the MTE ontology
may be developed, for example, by integrat-
ing the ontology in an architecture of modular
ontologies such as the Ontologies of Linguis-
tic Annotations (Chiarcos, 2008, OLiA), where
the linking between annotations and terminology
repositories is mediated by a so-called ?Refer-
ence Model? that serves as an interface between
different levels of representation.
The MTE ontology will be integrated in this
model as an annotation model, i.e., its concepts
will be defined as subconcepts of concepts of the
OLiA Reference Model and thereby inherit the
linking with GOLD (Chiarcos et al, 2008) and
ISOcat (Chiarcos, 2010). The linking with these
standard repositories increases the comparability
of MTE annotations and it serves an important
documentation function.
More important than merely potential applica-
tions of the MTE ontology, however, is that its
creation provides us with a new, global perspec-
tive on the MTE specifications. A number of
internal inconsistencies could be identified and
strategies for their resolution (or formalization)
were developed. Redundancies and overload
were documented, and we further added expert
definitions of controversial or non-standard con-
cepts. When used as a documentation, these spe-
cifications may prevent misunderstandings with
respect to the meaning of the actual annotations.
For later versions of the MTE morphosyntactic
specifications, they may even guide the refactor-
ing of the annotation scheme.
The result of the development process de-
scribed above is a prototype, that has to be aug-
mented with definitions for non-controversial and
well-understood concepts, which can be derived
from the linking with OLiA, GOLD and ISOcat.
As for its language type, our strategy to resolve
overload requires OWL/DL (owl:join). With-
out value overload and redundancy, the ontology
would be OWL/Lite, as were the initial ontolo-
gies (Sect. 4.1 and Sect. 4.2). However, the cur-
rent modeling is still sufficiently restricted to al-
low the application of reasoners, thereby open-
ing up the possibility to use SemanticWeb tech-
nologies on MTE data, to connect it with other
sources of information and to draw inferences
from such Linked Data.
We would also like to point out that the conver-
sion of the MTE specifications to OWL required
relatively little effort. The total time required
for conversion (without the revision phase) took
approximately four days of work for a compu-
tational linguist familiar with OWL and part-of-
speech tagsets in general (the most labor-intense
part were discussions and literature consultation
during the revision phase). Given the complexity
of the MTE specifications (a highly elaborate set
of morphosyntactic specifications for 16 typolog-
ically diverse languages and with more than thou-
sand tags for many of the languages), this may be
regarded an upper limit for the time necessary to
create OWL models for annotation schemes.
We have thus not only shown that the ontolog-
ical modeling of annotation schemes is possible
and that it allows us to use our data in novel ways
and to perform consistency control, but also that
this was achievable with relatively low efforts in
time and personnel.
18
Acknowledgements
The authors would like to thank the members of
the mocky-l mailing list for their invaluable in-
put; all errors in the paper remain our own. The
research on linguistic ontologies described in this
paper was partially funded by the German Re-
search Foundation (DFG) in the context of the
Collaborative Research Center (SFB) 632.
References
Guadalupe Aguado de Cea, Inmaculada ?Alvarez de
Mon-Rego, Antonio Pareja-Lora, and Rosario
Plaza-Arteche. 2002. OntoTag: A semantic web
page linguistic annotation model. In Proceedings
of the ECAI 2002 Workshop on Semantic Author-
ing, Annotation and Knowledge Markup, Lyon,
France, July.
Dik Bakker, Osten Dahl, Martin Haspelmath, Maria
Koptjevskaja-Tamm, Christian Lehmann, and
Anna Siewierska. 1993. EUROTYP guidelines.
Technical report, European Science Foundation
Programme in Language Typology.
S. Kalika Bali Baskaran, Tanmoy Bhattacharya,
Pushpak Bhattacharyya, Monojit Choudhury,
Girish Nath Jha, S. Rajendran, K. Saravanan,
L. Sobha, and KVS Subbarao. 2008. Designing
a common POS-tagset framework for Indian
languages. In 6th Workshop on Asian Language
Resources, pages 89?92, Hyderabad, India.
Tim Berners-Lee. 2006. Design issues: Linked data.
http://www.w3.org/DesignIssues/
LinkedData.html (May 11, 2011).
Balthasar Bickel and Johanna Nichols. 2002. Autoty-
pologizing databases and their use in fieldwork. In
Proceedings of the LREC 2002 Workshop on Re-
sources and Tools in Field Linguistics, Las Palmas,
Spain, May.
Sabine Brants and Silvia Hansen. 2002. Develop-
ments in the TIGER annotation scheme and their
realization in the corpus. In Proceedings of the 3rd
International Conference on Language Resources
and Evaluation (LREC 2002), pages 1643?1649,
Las Palmas, Spain, May.
Aljoscha Burchardt, Sebastian Pado?, Dennis Spohr,
Anette Frank, and Ulrich Heid. 2008. Formal-
ising Multi-layer Corpora in OWL/DL ? Lexicon
Modelling, Querying and Consistency Control. In
Proceedings of the 3rd International Joint Confer-
ence on NLP (IJCNLP 2008), Hyderabad, India,
January.
Ekaterina Buyko, Christian Chiarcos, and Antonio
Pareja-Lora. 2008. Ontology-based interface spec-
ifications for a NLP pipeline architecture. In Pro-
ceedings of the 6th International Conference on
Language Resources and Evaluation (LREC 2008),
Marrakech, Morocco, May.
Christian Chiarcos, Stefanie Dipper, Michael Go?tze,
Ulf Leser, Anke Lu?deling, Julia Ritz, and Manfred
Stede. 2008. A flexible framework for integrat-
ing annotations from different tools and tag sets.
Traitement Automatique des Langues (TAL), 49(2).
Christian Chiarcos. 2008. An ontology of linguis-
tic annotations. LDV Forum, 23(1):1?16. Foun-
dations of Ontologies in Text Technology, Part II:
Applications.
Christian Chiarcos. 2010. Grounding an ontology
of linguistic annotations in the Data Category Reg-
istry. In Proceedings of the LREC 2010 Workshop
on Language Resource and Language Technology
Standards (LR&LTS 2010), Valetta, Malta, May.
Ivan Derzhanski and Natalia Kotsyba. 2009. To-
wards a consistent morphological tagset for Slavic
languages: Extending MULTEXT-East for Polish,
Ukrainian and Belarusian. In Mondilex Third Open
Workshop, pages 9?26, Bratislava, Slovakia, April.
Ludmila Dimitrova, Radovan Garab??k, and Daniela
Majchra?kova?. 2009. Comparing Bulgarian
and Slovak Multext-East morphology tagset. In
Mondilex Second Open Workshop: Organization
and Development of Digital Lexical Resources,
pages 38?46, Kyiv, Ukraine, February.
Tomaz? Erjavec, Cvetana Krstev, Vladim??r Petkevic?,
Kiril Simov, Marko Tadic?, and Dus?ko Vitas. 2003.
The MULTEXT-East Morphosyntactic Specifica-
tions for Slavic Languages. In Proceedings of the
EACL 2003 Workshop on Morphological Process-
ing of Slavic Languages, pages 25?32.
Tomaz? Erjavec. 2010. MULTEXT-East Version 4:
Multilingual Morphosyntactic Specifications, Lex-
icons and Corpora. In Proceedings of the 7th Inter-
national Conference on Language Resources and
Evaluation (LREC 2010), Valetta, Malta, May.
Scott Farrar and D. Terence Langendoen. 2003. A
linguistic ontology for the semantic web. Glot In-
ternational, 7(3):97?100.
Aldo Gangemi, Roberto Navigli, and Paola Velardi.
2003. The OntoWordNet project: Extension and
axiomatization of conceptual relations in Word-
Net. In R. Meersman and Z. Tari, editors, Procee-
dings of On the Move to Meaningful Internet Sys-
tems (OTM 2003), pages 820?838, Catania, Italy,
November.
19
Radovan Garab??k, Daniela Majchra?kova?, and Lud-
mila Dimitrova. 2009. Comparing Bulgarian and
Slovak MULTEXT-East morphology tagset. In
Mondilex Second Open Workshop: Organization
and Development of Digital Lexical Resources,
pages 38?46, Kyiv, Ukraine. Dovira Publishing
House.
Sebastian Hellmann, Jo?rg Unbehauen, Christian
Chiarcos, and Axel-Cyrille Ngonga Ngomo. 2010.
The TIGER Corpus Navigator. In Proceedings
of the 9th International Workshop on Treebanks
and Linguistic Theories (TLT 2010), pages 91?102,
Tartu, Estonia, December.
Sebastian Hellmann. 2010. The semantic gap of for-
malized meaning. In Proceedings of the 7th Ex-
tended Semantic Web Conference (ESWC 2010),
Heraklion, Greece, May 30th ? June 3rd.
Nancy Ide and Jean Ve?ronis. 1994. MULTEXT
(Multilingual Tools and Corpora). In Proceedings
of the 15th International Conference on Computa-
tional Linguistics (COLING 1994), pages 90?96,
Kyoto.
Marc Kemps-Snijders, Menzo Windhouwer, Peter
Wittenburg, and Sue Ellen Wright. 2009. ISO-
cat: remodelling metadata for language resources.
International Journal of Metadata, Semantics and
Ontologies, 4(4):261?276.
Geoffrey Leech and Andrew Wilson. 1996.
Recommendations for the Morphosyntac-
tic Annotation of Corpora. EAGLES Re-
port EAG?TCWG?MAC/R, ILC, Pisa.
http://www.ilc.cnr.it/EAGLES96/
annotate/ (May 11, 2011).
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1994. Building a large annotated
corpus of English: The Penn Treebank. Computa-
tional Linguistics, 19(2):313?330.
Fabienne Martin, Dennis Spohr, and Achim Stein.
2009. Representing a resource of formal lexical-
semantic descriptions in the Web Ontology Lan-
guage. Journal for Language Technology and
Computational Linguistics, 21:1?22.
Behrang Qasemizadeh and Saeed Rahimi. 2006.
Persian in MULTEXT-East framework. In Tapio
Salakoski, Filip Ginter, Sampo Pyysalo, and Tapio
Pahikkala, editors, Advances in Natural Language
Processing, Proceedings of the 5th International
Conference on NLP (FinTAL 2006), pages 541?
551, Turku, Finland, August.
Georg Rehm, Richard Eckart, and Christian Chiar-
cos. 2007. An OWL-and XQuery-based mech-
anism for the retrieval of linguistic patterns from
XML-corpora. In Proceedings of Recent Advances
in Natural Language Processing (RANLP 2007),
Borovets, Bulgaria, September.
Alexandr Rosen. 2010. Mediating between incom-
patible tagsets. In Proceedings of the Workshop on
Annotation and Exploitation of Parallel Corpora
(AEPC), pages 53?62, Tartu, Estonia, December.
Geoffrey Sampson. 1995. English for the computer:
The SUSANNE corpus and analytic scheme. Ox-
ford University Press.
Adam Saulwick, Menzo Windhouwer, Alexis Dimi-
triadis, and Rob Goedemans. 2005. Distributed
tasking in ontology mediated integration of typo-
logical databases for linguistic research. In Procee-
dings of the 17th Conference on Advanced Infor-
mation Systems Engineering (CAiSE 2005), Porto,
Portugal, June.
TEI Consortium, editor. 2007. TEI P5: Guidelines
for Electronic Text Encoding and Interchange. TEI
Consortium.
Daniel Zeman. 2008. Reusable tagset conversion us-
ing tagset drivers. In Proceedings of the 6th Inter-
national Conference on Language Resources and
Evaluation (LREC 2008), Marrakech, Morocco,
May.
20
Proceedings of the 5th ACL-HLT Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, pages 33?38,
Portland, OR, USA, 24 June 2011. c?2011 Association for Computational Linguistics
Automatic linguistic annotation of historical language: 
ToTrTaLe and XIX century Slovene 
Toma? Erjavec 
Department of Knowledge Technologies, 
Jo?ef Stefan Institute 
Jamova cesta 39, 1000 Ljubljana 
Slovenia 
tomaz.erjavec@ijs.si 
 
Abstract 
The paper describes a tool developed to 
process historical (Slovene) text, which an-
notates words in a TEI encoded corpus 
with their modern-day equivalents, mor-
phosyntactic tags and lemmas. Such a tool 
is useful for developing historical corpora 
of highly-inflecting languages, enabling 
full text search in digital libraries of histor-
ical texts, for modernising such texts for 
today's readers and making it simpler to 
correct OCR transcriptions. 
1 Introduction 
Basic processing of written language, in particular 
tokenisation, tagging and lemmatisation, is useful 
in a number of applications, such as enabling full-
text search, corpus-linguistic studies, and adding 
further layers of annotation. Support for lemmati-
sation and morphosyntactic tagging is well-
advanced for modern-day languages, however, the 
situation is very different for historical language 
varieties, where much less ? if any ? resources ex-
ist to train high-quality taggers and lemmatisers. 
Historical texts also bring with them a number of 
challenges not present with modern language: 
? due to the low print quality, optical character 
recognition (OCR) produces much worse re-
sults than for modern day texts; currently, such 
texts must be hand-corrected to arrive at ac-
ceptable quality levels; 
? full-text search is difficult, as the texts are not 
lemmatised and use different orthographic 
conventions and archaic spellings, typically 
not familiar to non-specialists; 
? comprehension can also be limited, esp. when 
the text uses an alphabet different from the 
contemporary norm. 
This paper describes a tool to help alleviate the 
above problems. The tool implements a pipeline, 
where it first tokenises the text and then attempts 
to transcribe the archaic words to their modern day 
equivalents. For here on, the text is tagged and 
lemmatised using the models for modern Slovene. 
Such an approach is not new, as it straightforward-
ly follows from a situation where good language 
models are available for contemporary language, 
but not for its historical variants.  
The focus of the research in such cases is on the 
mapping from historical words to modern ones, 
and such approaches have already been attempted 
for other languages, e.g. for English (Rayson et al 
2007), German (Pilz et al 2008), Spanish 
(S?nchez-Marco et al 2010) and Icelandic (R?gn-
valdsson and Helgad?ttir, 2008). These studies 
have mostly concentrated on mapping historical 
variants to modern words or evaluating PoS tag-
ging accuracy and have dealt with Germanic and 
Romance languages. This paper discusses the 
complete annotation process, including lemmatisa-
tion, and treats a Slavic language, which has sub-
stantially different morphology; in Slovene, words 
belong to complex inflectional paradigms, which 
makes tagging and lemmatisation models quite 
complex, esp. for unknown words.  
The paper also discusses structural annotations 
supported by the tool, which takes as input a doc-
ument encoded according to (a subset of) the Text 
Encoding Initiative Guidelines, TEI P5 (Burnard 
and Bauman, 2007) and also produces output in 
this format.  
An example of the tool input fragment and the cor-
responding output is given in Figure 1. 
33
2 The ToTrTaLe tool 
The annotation tool implements a pipeline archi-
tecture and is essentially a wrapper program that 
calls a number of further processing modules. The 
tool is based on the ToTaLe tool (Erjavec et al, 
2005), which performs Tokenisation, Tagging and 
Lemmatisation on modern text; as the present tool 
extends this with Transcription, it is called To-
TrTaLe, and comprises the following modules: 
1. extracting processing chunks from source TEI 
2. tokenisation 
3. extracting text to be annotated 
4. transcription to modern word-forms 
5. part-of-speech tagging 
6. lemmatisation 
7. TEI output 
While the tool and its modules make some lan-
guage specific assumption, they are rather broad, 
such as that text tokens are (typically) separated by 
space; otherwise, the tool relies on external lan-
guage resources, so it could be made to work with 
most European languages, although it is especially 
suited for the highly-inflecting ones. 
The tool is written in Perl and is reasonably fast, 
i.e. it processes about 100k words per minute on a 
Linux server. The greatest speed bottleneck is the 
tool start-up, mostly the result of the lemmatisation 
module, which for Slovene contains thousands of 
rules and exceptions. In the rest of this section we 
present the modules of ToTrTaLe, esp. as they re-
late to processing of historical language. 
2.1 Extracting chunks 
In the first step, the top-level elements of the TEI 
file that contain text to be processed in one chunk 
are identified and passed on for linguistic pro-
cessing. This step serves two purposes. Certain 
TEI elements, in particular the <teiHeader>, which 
contains the meta-data of the document, should not 
be analysed but simply passed on to the output 
(except for recording the fact that the text has been 
linguistically annotated). Second, the processors in 
certain stages keep the text and annotations in 
memory. As a TEI document can be arbitrarily 
large the available physical memory can be ex-
hausted, leading to severe slow-down or even out-
of-memory errors. It is therefore possible to speci-
fy which elements (such as <body> or <div>) 
should be treated as chunks to be processed in one 
annotation run.  
2.2 The tokenisation module 
The multilingual tokenisation module mlToken 1 
is written in Perl and in addition to splitting the 
input string into tokens has also the following fea-
tures: 
? assigns to each token its token type, e.g. XML 
tag, sentence final punctuation, digit, abbrevia-
tion, URL, etc. 
? preserves (subject to a flag) white-space, so 
that the input can be reconstituted from the 
output. 
The tokeniser can be fine-tuned by putting punctu-
ation into various classes (e.g. word-breaking vs. 
non-breaking) and also uses several language-
dependent resource files, in particular a list of ab-
breviations (?words? ending in period, which is a 
part of the token and does not necessarily end a 
sentence), list of multi-word units (tokens consist-
ing of several space-separated ?words?) and a list 
of (right or left) clitics, i.e. cases where one ?word? 
should be treated as several tokens. These resource 
files are esp. important in the context of processing 
historical language, as it often happens that words 
that used to be written apart and now written to-
gether or vice-versa. Such words are put in the ap-
propriate resource file, so that their tokenisation is 
normalised. Examples of multi-word and split to-
kens are given in Figure 1. 
2.3 Text extraction 
A TEI encoded text can contain a fair amount of 
markup, which we, as much as possible, aim to 
preserve in the output. However, most of the 
markup should be ignored by the annotation mod-
ules, or, in certain cases, even the content of an 
element should be ignored; this goes esp. for 
markup found in text-critical editions of historical 
texts. For example, the top and bottom of the page 
can contain a running header, page number and 
catch-words (marked up in <fw> ?forme work? 
elements), which should typically not be annotated 
as they are not linguistically interesting and would 
furthermore break the continuity of the text. The 
text might also contain editorial corrections 
(marked up as <choice> <sic>mistyped text</sic> 
<corr>corrected text</corr> </choice>), where, 
arguably, only the corrected text should be taken 
                                                          
1 mlToken was written in 2005 by Camelia Ignat, then work-
ing at the EU Joint Research Centre  in Ispra, Italy.  
34
into account in the linguistic annotation. This 
module extracts the text that should be passed on 
to the annotation modules, where the elements to 
be ignored are specified in a resource file. 
This solution does take care of most situations en-
countered so far in our corpora2 but is not com-
pletely general. As discussed in Bennet et al 
(2010), there are many cases where adding token 
(and sentence) tags to existing markup breaks 
XML well-formedness or TEI validity, such as 
sentences crossing structural boundaries or word-
internal TEI markup.  
A general ?solution? to the problem is stand-off 
markup, where the annotated text is kept separate 
from the source TEI, but that merely postpones the 
problem of how to treat the two as a unit. And 
while TEI does offer solutions to such problems, 
implementing processing of arbitrary TEI in-place 
markup would, however, require much further re-
search. So ToTrTaLe adds the linguistic mark-up 
in-place, but does so correctly only for a restricted, 
although still useful, set of TEI element configura-
tions. 
2.4 Transcription 
The transcription of archaic word-forms to their 
modern day equivalents is the core module which 
distinguishes our processing of historical language 
as opposed to its contemporary form. The tran-
scription process relies on three resources: 
? a lexicon of modern-day word-forms; 
? a lexicon of historical word-forms, with asso-
ciated modern-day equivalent word-form(s);3 
? a set of transcription patterns. 
In processing historical texts, the word-form to-
kens are first normalised, i.e. de-capitalised and 
diacritic marks over vowels removed; the latter is 
most likely Slovene specific, as modern-day Slo-
vene, unlike the language of the 19th century, does 
not use vowel diacritics. 
                                                          
2 The notable exception is <lb/>, line break, which, giv-
en the large font size and small pages, often occurs in 
the middle of a word in historical texts. We move such 
line breaks in the source documents to the start of the 
word and mark their displacement in lb/@n. 
3 The two lexica have in fact a somewhat more compli-
cated structure. For example, many archaic words do 
not have a proper modern day equivalent; for these, the 
lexicon gives the word in its modern spelling but also its 
modern near synonyms. 
To determine the modern-day word-form, the his-
torical lexicon is checked first. If the normalized 
word-form is an entry of the historical lexicon, the 
equivalent modern-day word-form has also been 
identified; if not, it is checked against the modern-
day lexicon. This order of searching the lexica is 
important, as the modern lexicon can contain 
word-forms which have an incorrect meaning in 
the context of historical texts, so the historical lex-
icon also serves to block such meanings.  
If neither lexicon contains the word, the transcrip-
tion patterns are tried. Many historical spelling 
variants can be traced to a set of rewrite rules or 
?patterns? that locally explain the difference be-
tween the contemporary and the historical spelling. 
For Slovene, a very prominent pattern is e.g. r?er 
as exemplified by the pair br??ber?, where the 
left side represents the modern and the right the 
historical spelling.  
Such patterns are operationalized by the finite-state 
?Variant aware approximate matching? tool Vaam, 
(Gotscharek et al 2009; Reffle, 2011), which takes 
as input a historical word-form, the set of patters, 
and a modern-day lexicon and efficiently returns 
the modern-day word-forms that can be computed 
from the archaic one by applying one or more pat-
terns. The output list is ranked, preferring candi-
dates where a small number of pattern applications 
is needed for the rewrite operation.4  
It should be noted that the above process of tran-
scription is non-deterministic. While this rarely 
happens in practice, the historical word-form can 
have several modern-day equivalents. More im-
portantly, the Vaam module will typically return 
several possible alternative modernisations, of 
which only one is correct for the specific use of the 
word in context. We currently make use of fre-
quency based heuristics to determine the ?best? 
transcription, but more advanced models are possi-
ble, which would postpone the decision of the best 
candidate until the tagging and lemmatization has 
been performed. 
We currently use a set of about 100 transcription 
patterns, which were obtained by corpus inspec-
tion, using a dedicated concordancer. 
                                                          
4 Vaam also supports approximate matching based on 
edit distance, useful for identifying (and correcting) 
OCR errors; we have, however, not yet made use of this 
functionality. 
35
2.5 Tagging 
For tagging words in the text with their context 
disambiguated morphosyntactic annotations we use 
TnT (Brants, 2000), a fast and robust tri-gram tag-
ger. The tagger has been trained on jos1M, the 1 
million word JOS corpus of contemporary Slovene 
(Erjavec and Krek, 2008), and is also given a large 
background lexicon extracted from the 600 million 
word FidaPLUS reference corpus of contemporary 
Slovene (Arhar and Gorjanc, 2007). 
2.6 Lemmatisation 
Automatic lemmatisation is a core application for 
many language processing tasks. In inflectionally 
rich languages assigning the correct lemma (base 
form) to each word in a running text is not trivial, 
as, for instance, Slovene adjectives inflect for gen-
der, number and case (3x3x6) with a complex con-
figuration of endings and stem modifications.  
For our lemmatiser we use CLOG (Manandhar et 
al., 1998, Erjavec and D?eroski, 2004), which im-
plements a machine learning approach to the au-
tomatic lemmatisation of (unknown) words. CLOG 
learns on the basis of input examples (pairs word-
form/lemma, where each morphosyntactic tag is 
learnt separately) a first-order decision list, essen-
tially a sequence of if-then-else clauses, where the 
defined operation is string concatenation. The 
learnt structures are Prolog programs but in order 
to minimise interface issues we made a converter 
from the Prolog program into one in Perl.  
An interesting feature of CLOG is that it does not 
succeed in lemmatising just any word-form. With 
historical texts it almost invariably fails in lemma-
tising truly archaic words, making it a good selec-
tor for new entries in the historical lexicon. 
The lemmatiser was trained on a lexicon extracted 
from the jos1M corpus, and the lemmatisation of 
contemporary language is quite accurate, with 92% 
on unknown words. However, as mentioned, the 
learnt model, given that there are 2,000 separate 
classes, is quite large: the Perl rules have about 
2MB, which makes loading the lemmatiser slow. 
2.7 TEI output 
The final stage of processing is packing the origi-
nal file with the added annotations into a valid TEI 
document. This is achieved by combining Perl pro-
cessing with XSLT scripts. The last step in the 
processing is the validation of the resulting XML 
file against a TEI schema expressed in Relax NG. 
A validation failure indicates that the input docu-
ment breaks some (possibly implicit) mark-up as-
sumptions ? in this case either the input document 
must be fixed, or, if the encoding choices were val-
id, the program should be extended to deal also 
with such cases. 
3 Conclusions 
The paper gave an overview of the ToTrTaLe tool, 
which performs basic linguistic annotation on TEI 
encoded historical texts. Some future work on the 
tool has already been mentioned, in particular ex-
ploring ways of flexibly connecting transcription to 
tagging and lemmatisation, as well as supporting 
more complex TEI encoded structures. 
While the tool itself is largely language independ-
ent, it does need substantial language resources to 
operationalize it for a language. Specific for histor-
ical language processing are a corpus of tran-
scribed historical texts, a lexicon of historical word 
forms and a pattern set. The paper did not discuss 
these language resources, although it is here that 
most work will be invested in the future. 
The corpus we have used so far for Slovene lexi-
con building comes from the AHLib digital library 
(Prun?, 2007; Erjavec 2005), which contains 2 mil-
lion words of 19th century texts; we now plan to 
extend this with older material, predominantly 
from the 18th century. 
The on-going process of creating the Slovene his-
torical lexicon is described in Erjavec et al, 
(2010), while the model of a TEI encoded lexicon 
containing not only historical word-forms, but also 
all the other lexical items needed to feed the tool 
(such as multi-word units) is presented in Erjavec 
et al (2011). As we extend the corpus, we will also 
obtain new words, which will be automatically 
annotated with ToTrTaLe and then manually cor-
rected, feeding into the lexicon building process.  
For the patterns, the extension of the corpus will no 
doubt show the need to extend also the pattern set. 
Most likely this will be done by corpus inspection, 
via a dedicated concordancer, although alternative 
methods of pattern identification are possible. In 
particular, once when a substantial list of pairs his-
torical word-form / contemporary word-form be-
comes available, automatic methods can be used to 
derive a list of patterns, ranked by how productive 
they are (Pilz et al, 2008; Oravecz et al 2010). 
36
Acknowledgements  
The author thanks the anonymous reviewers for their 
useful comments and suggestions. The work presented 
in this paper has been supported by the EU IMPACT 
project ?Improving Access to Text? and the Google 
Digital Humanities Research Award ?Language models 
for historical Slovenian?. 
References  
Paul Bennett, Martin Durrell, Silke Scheible, and Rich-
ard J. Whitt, 2010. Annotating a historical corpus of 
German: A case study. Proceedings of the LREC 
2010 workshop on Language Resources and Lan-
guage Technology Standards. Valletta, Malta, 18 
May 2010. 64-68. 
Lou Burnard and Syd Bauman, 2007. Guidelines for 
Electronic Text Encoding and Interchange (TEI P5). 
Text Encoding Initiative Consortium. Oxford, 2007. 
http://www.tei-c.org/release/doc/tei-p5-doc/  
Toma? Erjavec. 2007. Architecture for Editing Complex 
Digital Documents. Proceedings of the Conference 
on Digital Information and Heritage. Zagreb. pp. 
105-114.  
Toma? Erjavec and Sa?o D?eroski. 2004. Machine 
Learning of Language Structure: Lemmatising Un-
known Slovene Words. Applied Artificial Intelli-
gence, 18(1):17?41. 
Toma? Erjavec, Simon Krek, 2008. The JOS morpho-
syntactically tagged corpus of Slovene. In Proceed-
ings of the Sixth International Conference on 
Language Resources and Evaluation, LREC?08, Par-
is, ELRA. 
Toma? Erjavec, Camelia Ignat, Bruno Pouliquen, and 
Ralf Steinberger. Massive Multi-Lingual Corpus 
Compilation: Acquis Communautaire and ToTaLe. 
In Proceedings of the 2nd Language & Technology 
Conference, April 21-23, 2005, Poznan, Poland. 
2005, pp. 32-36. 
Toma? Erjavec, Christoph Ringlstetter, Maja ?orga, and 
Annette Gotscharek, 2010. Towards a Lexicon of 
XIXth Century Slovene. In Proceedings of the Sev-
enth Language Technologies Conference, October 
14th-15th, 2010, Ljubljana, Slovenia. Jo?ef Stefan 
Institute. 
Toma? Erjavec, Christoph Ringlstetter, Maja ?orga, and 
Annette Gotscharek, (submitted). A lexicon for pro-
cessing archaic language: the case of XIXth century 
Slovene. ESSLLI Workshop on Lexical Resources 
workshop, WoLeR?11. Ljubljana, Slovenia. 
Annette Gotscharek, Andreas Neumann, Ulrich Reffle, 
Christoph Ringlstetter and Klaus U. Schulz. 2009. 
Enabling Information Retrieval on Historical Docu-
ment Collections - the Role of Matching Procedures 
and Special Lexica. Proceedings of the ACM SIGIR 
2009 Workshop on Analytics for Noisy Unstructured 
Text Data (AND09), Barcelona. 
Suresh Manandhar, Sa?o D?eroski and Toma? Erjavec 
1998. Learning Multilingual Morphology with 
CLOG. In Proceedings of Inductive Logic Program-
ming; 8th International Workshop ILP-98 (Lecture 
Notes in Artificial Intelligence 1446) (pp. 135-144). 
Springer-Verlag, Berlin. 
Csaba Oravecz, B?lint Sass and Eszter Simon. 2010. 
Semi-automatic Normalization of Old Hungarian 
Codices. Proceedings of the ECAI 2010 Workshop 
on Language Technology for Cultural Heritage, So-
cial Sciences, and Humanities (LaTeCH 2010), Au-
gust 16, 2010, Lisbon, Portugal. 
Thomas Pilz, Andrea Ernst-Gerlach, Sebastian Kemp-
ken, Paul Rayson and Dawn Archer, 2008. The Iden-
tification of Spelling Variants in English and German 
Historical Texts: Manual or Automatic? Literary and 
Linguistic Computing, 23/1, pp. 65-72. 
Erich Prun?. 2007. Deutsch-slowenische/kroatische 
?bersetzung 1848-1918 [German-Slovene/Croatian 
translation, 1848-1918].  Ein Werkst?ttenbericht.  
Wiener Slavistisches Jahrbuch 53/2007. Austrian 
Academy of Sciences Press, Vienna.  pp. 163-176. 
Paul Rayson, Dawn Archer, Alistair Baron, Jonathan 
Culpeper, and Nicolas Smith, 2007. Tagging the 
Bard: Evaluating the accuracy of a modern POS tag-
ger on Early Modern English corpora. In Proceedings 
of Corpus Linguistics 2007. University of Birming-
ham, UK. 
Ulrich Reffle, Efficiently generating correction sugges-
tions for garbled tokens of historical language, Jour-
nal of Natural Language Engineering, Special Issue 
on Finite State Methods and Models in Natural Lan-
guage  Processing, 2011.  
Eir?kur R?gnvaldsson and Sigr?n Helgad?ttir, 2008. 
Morphological tagging of Old Norse texts and its use 
in studying syntactic variation and change. In Pro-
ceedings of the LREC 2008 Workshop on Language 
Technology for Cultural Heritage Data (LaTeCH 
2008).  ELRA, Paris. 
Cristina S?nchez-Marco, Gemma Boleda, Josep Maria 
Fontana and Judith Domingo. 2010. Annotation and 
Representation of a Diachronic Corpus of Spanish. 
Proceedings of the Seventh conference on Interna-
tional Language Resources and Evaluation 
(LREC'10). ELRA, Paris. 
37
TEI input fragment: 
 
  <p xml:id="p.401">Nekiga bogatiga kneza z nja <lb/> 
    <pb n="93" facs="#FPG00012.097" xml:id="pb.97"/> 
    dru?ino, ki v mes nemore  <lb n="3"/> 
    <gap/> 
  </p>  
 
ToTrTaLe output: 
 
<p xml:id="p.401"> 
   <s> 
     <w subtype="lexicon" nform="nekiga" mform="nekega" lemma="nek" ctag="Pi-msg">Nekiga</w> 
     <c> </c> 
     <w subtype="pattern" pattern="[ega@?iga@]" mform="bogatega" lemma="bogat" 
           ctag="Agpmsg">bogatiga</w> 
     <c> </c> 
     <w lemma="knez" ctag="Npmsg">kneza</w> 
     <c> </c> 
     <w lemma="z" ctag="Si">z</w> 
     <c> </c> 
     <w subtype="lexicon" mform="njegova" lemma="njegov" ctag="Ps3fsnsm">nja</w> 
     <c> </c> 
     <lb/> 
     <pb n="93" facs="#FPG00012.097" xml:id="pb.97"/> 
     <w lemma="dru?ina" ctag="Ncfsa">dru?ino</w> 
     <pc ctag=",">,</pc> 
     <c> </c> 
     <w lemma="ki" ctag="Cs">ki</w> 
     <c> </c> 
     <w type="multiw" subtype="pattern" pattern="[@v?@v_]" mform="vmes" lemma="vmes" ctag="Rgp" 
            n="mw_jeGx2">v</w> 
     <c> </c> 
     <w type="multiw" subtype="pattern" pattern="[@v?@v_]" mform="vmes" lemma="vmes" ctag="Rgp" 
           n="mw_jeGx2">mes</w> 
     <c> </c> 
     <w type="split" mform="ne_more" lemma="ne_mo?i" ctag="Q_Vmpr3s">nemore</w> 
     <c>  </c> 
     <lb n="3"/> 
     <gap/> 
   </s> 
</p> 
 
Figure 1. An example of ToTrTaLe input paragraph and the equivalent output.  
Paragraphs, page and line breaks are preserved, and the program adds elements for words, punctuation symbols and 
white-space. Both punctuation and words are assigned a corpus tag and lemma, and, where different from the de-
fault, the type and subtype of the word, its normalised and modernised form, and possibly the used pattern(s). In 
cases of multi-words, each part is given its own word tag, which have identical analyses and are joined together by 
the unique value of @n; this approach allows also modelling discontinuous multi-word units, such as separable 
verbs in Germanic languages. Split words forms, on the other hand, are modelled by one word token, but with a 
portmanteau analysis. 
38
Proceedings of the 6th EACL Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, pages 1?6,
Avignon, France, 24 April 2012. c?2012 Association for Computational Linguistics
Lexicon construction and corpus annotation of historical language 
with the CoBaLT editor
Tom Kenter1, Toma? Erjavec2, Maja ?orga Dulmin3, Darja Fi?er4
1 Institute for Dutch Lexicology
Matthias de Vrieshof 3, gebouw 1171, 2311 BZ Leiden
tom.kenter@inl.nl
2 Department of Knowledge Technologies, Jo?ef Stefan Institute
Jamova cesta 39, SI-1000 Ljubljana
tomaz.erjavec@ijs.si
3 maja.zorga@gmail.com
4 Department of Translation, Faculty of Arts, University of Ljubljana
A?ker?eva 2, SI-1000 Ljubljana
darja.fiser@ff.uni-lj.si
Abstract
This paper describes a Web-based editor 
called  CoBaLT  (Corpus-Based  Lexicon 
Tool),  developed  to  construct  corpus-
based computational lexica and to correct 
word-level  annotations  and transcription 
errors in corpora. The paper describes the 
tool as well as our experience in using it 
to  annotate  a  reference  corpus  and 
compile  a  large  lexicon  of  historical 
Slovene.  The  annotations  used  in  our 
project  are  modern-day  word  form 
equivalent,  lemma,  part-of-speech  tag 
and optional gloss. The CoBaLT interface 
is  word  form  oriented  and  compact.  It 
enables  wildcard  word  searching  and 
sorting  according  to  several  criteria, 
which makes the editing process flexible 
and  efficient.  The  tool  accepts  pre-
annotated corpora in TEI P5 format and 
is able to export the corpus and lexicon in 
TEI P5 as well. The tool is implemented 
using  the  LAMP  architecture  and  is 
freely available for research purposes.
1 Introduction
Processing tools as well as linguistic studies of 
historical  language  need  language  resources, 
which have to be developed separately for each 
language,  and manually annotated or  validated. 
The two basic resource types are hand-annotated 
corpora and lexica for historical language, which 
should  contain  (at  least)  information  about  the
modern-day equivalent  of  a  word  form and its
lemma  and  part-of-speech  (PoS).  The  first  of 
these  is  useful  for  easier  reading  of  historical 
texts, as well as for enabling already developed 
modern-day  PoS  tagging  and  lemmatisation 
models to be applied to historical texts. PoS tags 
make  for  a  better  environment  for  linguistic 
exploration  and  enable  further  levels  of 
annotation,  such  as  tree-banking.  They  also 
facilitate  lemmatisation,  which  is  especially 
useful  for  highly  inflecting  languages  as  it 
abstracts away from the inflectional variants of 
words, thereby enabling better text searching.
To  develop  such  resources,  a  good  editor  is 
needed that caters to the peculiarities of historical 
texts. Preferably it would combine the production 
of  annotated  corpora  and  corpus-based  lexica. 
This paper presents CoBaLT, a Web-based editor 
which  has  already  been  used  for  developing 
language  resources  for  several  languages.  We 
describe it within the framework of developing a 
gold-standard  annotated  reference  corpus 
(Erjavec, 2012) and a large lexicon of historical 
Slovene. 
This paper is structured as follows: in the next 
section  we  describe  the  implementation  and 
functionality of CoBaLT. In Section 3 we present 
the input and output corpus and lexicon formats, 
in particular from the perspective of our project. 
In Section 4 we compare existing tools serving a 
similar  purpose  to  CoBaLT  and  discuss  the 
advantages  and  disadvantages  of  the  CoBaLT 
environment.  The  last  section  summarizes  and
lists our conclusions.
1
Figure 1. CoBaLT interface
2 The CoBaLT tool
2.1 Implementation
CoBaLT is a Web-based editor using the classic 
LAMP architecture (Linux, Apache, MySQL and 
PHP). Ajax (Asynchronous JavaScript and XML) 
technology  is  used  extensively  as  it  enables 
updating only relevant parts of the screen which 
increases  speed  and  usability.  The  code  is 
optimised to work with large datasets and comes 
with  documentation  on  various  settings  for 
MySQL and  PHP that  enhance  handling  large 
data  collections.  System,  project,  language-
specific details (e.g. the list of valid PoS tags to 
enable their validation during editing) and some 
interface settings are encapsulated in a PHP file, 
making  the  adaptation  of  the  tool  to  other 
environments  very  easy.  However,  some 
knowledge  of  MySQL is  still  required,  e.g.  to 
add new users to the system which is performed 
directly in MySQL.
Apart  from  an  Internet  browser,  no  additional 
software  is  required  at  the  user  side.  The 
interface can be used from various browsers on 
all major operating systems, although it has been 
tested primarily on Mozilla Firefox.
2.2 User interface 
Apart from logging into the tool and selecting the 
corpus  or  file  to  work  on,  the  CoBaLT  user 
interface is always contained on a single screen. 
The  icons  and  fields  on  the  screen  have 
associated tool-tips. 
As shown in Figure 1, the screen is divided in 
four parts:
1. The upper, ?dashboard? part enables ways of 
organizing  the  displayed  information,  i.e. 
how to sort the word forms, which ones to  
select, whether to hide certain less interesting 
word forms (such as numerals), the number 
of word forms shown, and links back to start 
pages.
2. The left  side  of  the  middle  part  shows the 
(selected)  historical  word  forms  with  their 
corpus  frequencies.  This  is  followed by an 
editable window giving the modernised word 
form, lemma, PoS and potential gloss; if the 
corpus contains  distinct  annotations  for the 
word form, they are all shown, separated by 
a  pipe  symbol.  Finally,  on  the  right-hand 
side,  all  the  possible lexical  annotations  of 
the word form are given; those in bold have 
been validated.
3. The separator between the middle and lower 
parts  shows  who  has  worked  last  on  the 
selected  word  form,  and  gives  icons  for 
sorting  the  word  forms  in  context  in  the 
lower part according to a number of criteria: 
word  form,  right  and  left  context,  analysis 
and verification. 
4. The  lower  part  of  the  screen  shows  the 
selected  word  form  tokens  in  context 
together with their  analyses  in  that  context 
and a tick box for validation next  to each. 
Also displayed is the name of the document 
in which they appear. The arrows next to a 
context row allow for expanding the context. 
Clicking on the camera icon at the left side 
of the row opens the facsimile image.
The separator bar in the middle can be dragged 
for relative resizing of the middle and lower part.
2.3 Editing in CoBaLT
There  is  more  than  one  way  of  editing  the 
analyses  assigned  to  a  word  form in  CoBaLT. 
The user can work on a specific word form either 
in the middle screen or in the lower screen, with 
2
keyboard  shortcuts  making  the  process  very 
efficient.  Multiple  rows  of  a  word  form  in 
context can be quickly selected with the mouse. 
The user can assign the analysis to selected word 
form  tokens  a)  in  the  middle  part  either  by 
writing it in the editable window or by clicking 
on a proposed analysis; b) in the lower part by 
clicking on the word token, which opens a drop 
down  menu.  Further  options  are  available, 
explained in the user manual. 
A special feature is the ability to assign analyses 
to  a  group of word tokens,  e.g.  when multiple 
word tokens in the historical text correspond to a 
single modern word. Multiple analyses can also 
be assigned to a single word token,  e.g. if  one 
historical  word  form  corresponds  to  several 
modern ones.
Working  on  historical  language,  the  need 
occasionally  arises  to  correct  the  transcription. 
This can be done by Ctrl-clicking the word form 
in context in the lower screen. An editable box 
will appear in which the user can correct a typo 
or separate merged words.
3 Data import and export
3.1 Corpus import and export
CoBaLT input  corpus  files  can  be  in  arbitrary 
formats, as long as the tokens, and possibly their 
annotations,  are  indicated  in  the  texts,  and 
appropriate import routines are in place. The tool 
currently  accepts  plain  text  and  a 
parameterisation  of  TEI  P5  XML  (TEI 
Consortium,  2007).  The  latter  option  is  more 
interesting for our case, as TEI files can already 
be structurally  and linguistically  annotated. Zip 
files are also supported, which enables uploading 
large datasets with many separate files.
The  Slovene  corpora  are  encoded  in  TEI,  and 
each  corpus  file  contains  the  transcription of  a 
single page, together with the link to its facsimile 
image.  The  page  is  also  annotated  with 
paragraphs, line breaks, etc.  Such annotation is 
imported  into  CoBaLT  but  not  displayed  or 
modified, and appears again only in the export.
The texts in our project were first automatically 
annotated  (Erjavec,  2011):  each  text  was 
sentence  segmented  and  tokenised  into  words. 
Punctuation symbols (periods, commas, etc.) and 
white-spaces were preserved in the annotation so 
the original text and layout can be reconstructed 
from  the  annotated  text.  Each  word  form  was 
assigned its modern-day equivalent,  its PoS tag 
and modern day lemma. 
Such  files,  a  number  of  them  together 
constituting one corpus, were then imported into 
CoBaLT  and  manually  edited,  with  CoBaLT 
supporting the export of the annotated corpus as 
TEI  P5  as  well.  In  the  export,  each  validated 
token  is  additionally  annotated  with  the 
annotator?s username and time of annotation.
One particular  facet of the annotation concerns 
the  word-boundary  mismatch  between  the 
historical  and  modern-day  word  forms.  As 
mentioned, CoBaLT supports joining two words 
in  the  transcription  to  give  them  a  common 
annotation, as well as giving several successive 
annotations  to  a  single  word,  and  this  is  also 
reflected in the exported TEI annotation. 
3.2 Lexicon export
While it is of course possible to produce a direct 
SQL dump of the lexicon, CoBaLT also supports 
lexicon  export  in  TEI  P5  using  the  TEI 
dictionaries  module.  This  lexicon  is  headword 
(lemma) oriented. The lemma entry in the export 
consists  of  a  headword,  part  of  speech  and 
optionally a gloss. The entry also contains all the 
modern word forms of the lemma as annotated in 
the corpus. For each modern word form one or 
more historical word forms are listed, including 
their normalised and cited forms. The difference 
between normalised and cited forms is that cited 
forms are the exact word forms as they appear in 
the corpus, while the normalised ones are lower-
cased, and, in the case of Slovene, have vowel 
diacritics  removed  as  these  are  not  used  in 
contemporary Slovene and are furthermore very 
inconsistently  used  in  historical  texts.  These 
normalised forms are also what  is listed in the 
left  column of  the  middle part  of  the  CoBaLT 
window.  As  illustrated  in  Figure  2,  one  cited 
form with examples of usage is ?gl??nikam?, the 
normalised  form  ?gla?nikam?,  the  modernised 
one ?glasnikom? and the lemma form ?glasnik?, 
which is a common noun of masculine gender. 
This  word  does  not  exist  anymore,  so  it  is 
assigned a gloss, i.e. its contemporary equivalent 
?samoglasnik? (meaning ?vowel?).
The cited forms also contain examples of usage 
together  with  the  file  they  occurred  in.  The 
export  script  can  be  limited  as  to  how  many 
usage examples get exported, as in the case of a 
fully annotated corpus the number of attestations 
for  high-frequency  words  (typically  function 
words)  can  easily  go  into  the  thousands,  and 
there is little point in including all of them in the 
lexicon.
3
<entry>
 <form type="lemma">
  <orth type="hypothetical">glasnik</orth>
  <gramGrp>
   <gram type="msd">Ncm</gram>
   <gram type="PoS">Noun</gram>
   <gram type="Type">common</gram>
   <gram type="Gender">masculine</gram>
  </gramGrp>
  <gloss>samoglasnik</gloss>
  <bibl>kontekst, Pleter?nik</bibl>
  <lbl type="occurrences">1</lbl>
 </form>
 <form type="wordform">
  <orth type="hypothetical">glasnikom</orth>
  <form type="historical">
   <orth type="normalised">gla?nikam</orth>
   <form type="cited">
    <orth type="exact">gl??nikam</orth>
    <cit>
     <quote>kadar be?eda, ktira na?l?duje,
        sazh?nja s' enim <oVar>gl??nikam</oVar>
       al tudi s' enim/quote>
     <bibl>NUK_10220-
        1811.pb.007_Pozhetki_gramatike.xml
     </bibl>
    </cit>
   </form>
  </form>
 </form>
</entry>
Figure 2. Example of a TEI dictionary entry
The  export  script  also  accepts  parameters  that 
determine which word forms should be exported 
? all, or only the attested or verified ones.
As in the corpus, the special case of multiword 
units and split words arises in the lexicon as well. 
Multiword units have the lemma and modern day 
forms composed of multiple words, and multiple 
grammatical  descriptions,  one  for  each  lemma, 
while split words have the historical word forms 
composed of two or more words.
Also included with CoBaLT is a script to merge 
two  TEI  lexica  (e.g.  derived  from  different 
corpora) into a single TEI lexicon and to convert 
the TEI lexicon into HTML for web browsing. 
We extended this script for the case of Slovene to 
also  give  direct  links  to  several  on-line 
dictionaries  and  to  the  concordancer  that  hosts 
our corpora.
4 Discussion
4.1 Strengths and weakness of CoBaLT
First,  it  should  be  noted  that  CoBaLT is  not 
limited  to  working  with  corpora  of  historical 
language ? it could also be used for non-standard 
language  varieties  (e.g.  tweets)  or  for  standard 
contemporary  language,  by  slightly  modifying 
the  import/export  and  the  parsing  of  the  word 
annotation  in  the  editor.  Nevertheless,  it 
incorporates  several  features  that  make  it 
particularly suitable for handling historical texts:
? CoBaLT supports both corpus annotation and 
corpus-based lexicon construction; extensive 
lexica are, at least from the point of view of 
good processing of historical language, much 
more important than annotated corpora. 
? The texts of historical corpora are typically 
first  produced  by  optical  character 
recognition  (OCR)  software  and  then 
manually corrected.  In spite  of  corrections, 
some errors will invariably remain in the text 
and will be, for the most part, noticed during 
the annotation process. While not meant for 
major  editing  of  the  transcription,  CoBaLT 
does  offer  the  possibility  to  correct  the 
transcription of  individual  words.  This  is  a 
rare functionality in other annotation editors, 
which typically  take the base text  as  read-
only. The current version of CoBaLT offers 
support  for  editing,  splitting,  and  joining 
word tokens. Deleting word forms altogether, 
however,  is  not  supported ? an option that 
should be added in the future.
? Related  to  the  previous  point  is  CoBaLT?s 
feature to display the facsimile of a particular 
page,  making  it  possible  to  check  the 
transcription  or  OCR  result  against  the 
original image of the page.
As  regards  the  functioning  of  the  tool,  it  is 
important  to  note  that  almost  all  linguistic 
processing occurs outside of CoBaLT making it 
more  light-weight  as  well  as  more  language 
independent.  In  previous  work  (Erjavec  et  al., 
2010)  a  different  editor  was  used  which  had 
linguistic  processing  built  in  and proved  to  be 
more difficult to adapt to Slovene than CoBaLT.
In this particular project we decided to organise 
the files around the concept of a facsimile page. 
This has a number of advantages, in particular a 
straight-forward  mapping  between  files  and 
facsimile images, a simple unit of sampling for 
the corpus, and small files, which makes it easier 
to manage the work of annotators. However, this 
4
arrangement  causes  some  problems  from  a 
linguistic point of view, namely that the page will 
often start or end in the middle of a paragraph, 
sentence or even word. We decided to start and 
end  each  page  with  a  paragraph  or  sentence 
boundary,  while  split  words  are  marked  by  a 
special  PoS tag.  It  should be noted that  this  is 
used only at  page-breaks ? split  words at line-
breaks are joined before importing the texts into 
CoBaLT.
From  a  user-interface  perspective,  a 
distinguishing feature of CoBaLT is that there is 
a single editor window, with keyboard shortcuts 
making the jumps between the parts of the screen 
faster than moving a mouse, allowing for quick 
and  efficient  editing.  Adding  or  deleting  a 
number of analyses is also just a click away. This 
again  makes  the  tool  very  efficient  but  also 
means that the user has to be quite careful not to 
accidentally destroy already existing annotations 
? this proved to be a problem in the annotation 
round.
From an implementation standpoint,  we should 
note that the level of security offered by CoBaLT 
is limited. Only a user name is needed to log in 
and have access to the data.  While this can be 
easily  circumvented  by  placing  the  entire 
interface behind a secure page, a higher level of 
security, e.g. just adding passwords to the login 
procedure, should be implemented in the future. 
On  the  other  hand,  access  should  not  be  too 
restricted, as simple access does allow for easy 
crowdsourcing. 
4.2 Related work
Historical  corpora  have  been  compiled, 
annotated and made available for searching in a 
number of projects, such as Corpus of Historical 
American English (Davies, 2010), Penn Corpora 
of  Historical  English  (Kroch  et  al.,  2004), 
GermanC historical corpus (Durrell et al, 2007), 
Historical  Corpus  of  the  Welsh  Language 
(Mittendorf  and  Willis,  2004)  and  Icelandic 
Parsed  Historical  Corpus  (Wallenberg  et  al., 
2011), etc.  Surprisingly few of these initiatives 
have  developed  or  discussed  the  need  for  a 
historical text platform that would enable manual 
correction of pre-annotated corpora, facilities for 
lexicon building,  and a standardized annotation 
format.
As  the simplest  solution,  some of  the  projects 
used  general-purpose  XML.  However,  human 
annotators usually have a hard time working in 
XML directly  to  revise  word-level  annotations 
and  transcription  errors.  This  is  one  of  the 
reasons  why  automatic  and  manual  corpus-
development tasks were integrated into the same 
environment in the GermanC project (Scheible et 
al.,  2010),  where  the  GATE  platform 
(Cunningham et al, 2002) was used to produce 
the  initial  annotations  and  to  perform  manual 
corrections.  However,  GATE  does  not  provide 
explicit  support  for texts  encoded according  to 
the  TEI  P5  guidelines,  which  is  why  the 
GermanC team spent  a  lot  of  time  on  writing 
scripts to deal with formatting issues. As GATE 
has automatic processing integrated into it, it is 
also not trivial to adapt it to a new language. 
The  only  special-purpose  tools  for  historical 
corpus development we could find is E-Dictor, a 
specialized tool for encoding, applying levels of 
editions and assigning PoS tags to ancient texts 
for building the Tycho Brahe Parsed Corpus of 
Historical Portuguese (de Faria et al, 2010). It is 
similar  to  CoBaLT  in  that  it  too  has  a 
WYSIWYG interface  and  allows  annotators  to 
check transcriptions and assign several layers of 
annotations  to  the  tokens.  E-Dictor  enables 
export of the encoded text XML and the lexicon 
of  editions  in  HTML  and  CSV.  This  is  an 
interesting  tool  although  it  does  not  seem  to 
support a lexical view of the data or merging and 
splitting word forms, and it is not quite clear how 
it  interacts  with  automatic  processing  of  the 
texts, or if a user manual is available.
As the review of related work shows, there is a 
general lack of tools such as CoBaLT which can 
significantly  simplify  and  speed  up  most 
historical  corpus  and  lexicon  development 
projects.  We believe CoBaLT has  a  number  of 
qualities  that  will  make  it  attractive  for  other 
researchers.
5 Conclusions
The  paper  presented  CoBaLT,  an  editor  for 
constructing corpus-based lexica  and correcting 
word-level annotations and transcription errors in 
corpora. The editor has been extensively tested in 
a  project  in  which  a  historical  corpus  was 
manually  annotated  and  used  to  produce  a 
lexicon, with the lexicon being further extended 
on  the  basis  of  a  much  larger  corpus.  Seven 
annotators have worked on the resources for over 
half a year,  which put  the tool through a good 
stress test. CoBaLT has also been used in several 
similar projects for other languages, in particular 
in producing historical lexica for Czech, Polish, 
Dutch and Spanish (de Does et al, 2012).1
5
With the help of CoBaLT Slovene now has two 
essential  historical  language  resources,  both 
encoded in TEI P5. The resources will be used to 
build  better  models  for  (re)tokenisation, 
transcription, tagging and lemmatisation, and to 
facilitate  corpus-based  diachronic  language 
studies. We also plan to continue using CoBaLT 
to further extend the hand-annotated corpus and 
lexicon.
CoBaLT is freely available for research use from 
the  Web  site  of  the  Impact  Centre  of 
Competence,  http://www.digitisation.eu.  The 
distribution contains the code, user manual, and 
associated scripts mentioned in this paper.
Acknowledgements
The authors would like to thank the anonymous 
reviewers  for  their  helpful  comments  and 
suggestions.  The  work  presented  in  this  paper 
has been supported by the EU IMPACT project 
?Improving Access to Text?,  http://www.impact-
project.eu.
References
Mark  Davies.  2010.  The  Corpus  of  Historical  
American English (COHA): 400+ Million Words,  
1810?2009. http://corpus.byu.edu/coha 
Jesse  de  Does,  Katrien  Depuyd,  Klaus  Schulz, 
Annette Gotscharek, Christoph Ringlstetter, Janusz 
S.  Bie?,  Toma?  Erjavec,  Karel  Ku?era,  Isabel 
Martinez, Stoyan Mihov, and Gilles Souvay. 2012. 
Cross-language  Perspective  on  Lexicon  Building  
and  Deployment  in  IMPACT.  Project  Report. 
IMPACT.
Toma? Erjavec,  Christoph Ringlstetter,  Maja  ?orga, 
and Annette Gotscharek. 2010. Towards a Lexicon 
of XIXth Century Slovene. In Proceedings of the 
Seventh  Language  Technologies  Conference, 
Ljubljana, Slovenia. Jo?ef Stefan Institute.
Toma? Erjavec. 2011. Automatic linguistic annotation 
of historical language: ToTrTaLe and XIX century 
Slovene.  In  Proceedings  of  the  5th  ACL-HLT 
Workshop  on  Language  Technology  for  Cultural  
Heritage, Social Sciences, and Humanities, ACL.
Toma?  Erjavec.  2012.  The  goo300k  corpus  of 
historical  Slovene.  In  Proceedings  of  the  Eight  
International Conference on Language Resources  
and Evaluation, LREC?12, Paris, ELRA.
Anthony Kroch, Beatrice Santorini, and Lauren Delfs. 
2004. The Penn-Helsinki Parsed Corpus of Early  
Modern English (PPCEME). Department of 
Linguistics, University of Pennsylvania. CD-ROM, 
first edition.
http://www.ling.upenn.edu/hist-corpora/ 
Martin  Durrell,  Astrid  Ensslin,  and  Paul  Bennett. 
2007.  The  GerManC  project.  Sprache  und 
Datenverarbeitung, 31:71?80.
Ingo Mittendorf, and David Willis, eds. 2004. Corpws 
hanesyddol  yr  iaith  Gymraeg  1500?1850  /  A  
historical  corpus  of  the  Welsh  language  
1500? 1850. 
http://people.pwf.cam.ac.uk/dwew2/hcwl/menu.ht
m 
Joel C. Wallenberg, Anton Karl Ingason, Einar Freyr 
Sigur?sson, and Eir?kur R?gnvaldsson. 2011. 
Icelandic Parsed Historical Corpus (IcePaHC). 
Version 0.9. 
http://www.linguist.is/icelandic_treebank 
Silke Scheible, Richard J. Whitt, Martin Durrell, and 
Paul Bennett, 2010. Annotating a Historical Corpus 
of  German:  A  Case  Study.  Proceedings  of  the  
LREC 2010 Workshop on Language Resources and  
Language Technology Standards, Valletta, Malta.
Hamish  Cunningham.  2002.  GATE,  a  General 
Architecture for Text Engineering. Computers and 
the Humanities, 36:223?254.
Pablo  Picasso  Feliciano  de  Faria,  Fabio  Natanael 
Kepler, and Maria Clara Paix?o de Sousa. 2010. An 
integrated  tool  for  annotating  historical  corpora. 
Proceedings  of  the  Fourth  Linguistic  Annotation  
Workshop, ACL?10, 217?221.
TEI Consortium, eds. 2007. Guidelines for Electronic  
Text Encoding and Interchange.
http://www.tei-c.org/P5
1 For more information on these projects please see the Impact Centre of Competence:
  http://www.digitisation.eu/
6
Proceedings of the 4th Biennial International Workshop on Balto-Slavic Natural Language Processing, pages 58?62,
Sofia, Bulgaria, 8-9 August 2013. c?2010 Association for Computational Linguistics
Modernizing Historical Slovene Words with Character-Based SMT
Yves Scherrer
ALPAGE
Universit? Paris 7 Diderot & INRIA
5 Rue Thomas Mann, Paris, France
yves.scherrer@inria.fr
Toma? Erjavec
Dept. of Knowledge Technologies
Jo?ef Stefan Institute
Jamova cesta 39, Ljubljana, Slovenia
tomaz.erjavec@ijs.si
Abstract
We propose a language-independent word
normalization method exemplified on
modernizing historical Slovene words.
Our method relies on character-based sta-
tistical machine translation and uses only
shallow knowledge. We present the rel-
evant lexicons and two experiments. In
one, we use a lexicon of historical word?
contemporary word pairs and a list of con-
temporary words; in the other, we only
use a list of historical words and one of
contemporary ones. We show that both
methods produce significantly better re-
sults than the baseline.
1 Introduction
A lot of recent work deals with detecting and
matching cognate words in corpora of closely re-
lated language varieties. This approach is also use-
ful for processing historical language (Piotrowski,
2012), where historical word forms are matched
against contemporary forms, thus normalizing the
varied and changing spelling of words over time.
Such normalization has a number of applications:
it enables better full-text search in cultural heritage
digital libraries, makes old texts more understand-
able to today?s readers and significantly improves
further text processing by allowing PoS tagging,
lemmatization and parsing models trained on con-
temporary language to be used on historical texts.
In this paper, we try to match word pairs of dif-
ferent historical stages of the Slovene language. In
one experiment we use character-based machine
translation to learn the character correspondences
from pairs of words. In the second experiment, we
start by extracting noisy word pairs from monolin-
gual1 lexicons; this experiment simulates a situa-
1For lack of a better term, we use ?monolingual? to refer
to a single diachronic state of the language, and ?bilingual?
to refer to two diachronic states of the language.
tion where bilingual data is not available.
The rest of this paper is structured as follows:
Section 2 presents related work, Section 3 details
the dataset used, Section 4 shows the experiments
and results, and Section 5 concludes.
2 Related Work
The most common approach to modernizing his-
torical words uses (semi-) hand-constructed tran-
scription rules, which are then applied to historical
words, and the results filtered against a contempo-
rary lexicon (Baron and Rayson, 2008; Scheible et
al., 2010; Scheible et al, 2011); such rules are of-
ten encoded and used as (extended) finite state au-
tomata (Reffle, 2011). An alternative to such de-
ductive approaches is the automatic induction of
mappings. For example, Kestemont et al (2010)
use machine learning to convert 12th century Mid-
dle Dutch word forms to contemporary lemmas.
Word modernization can be viewed as a special
case of transforming cognate words from one lan-
guage to a closely related one. This task has tradi-
tionally been performed with stochastic transduc-
ers or HMMs trained on a set of cognate word
pairs (Mann and Yarowsky, 2001). More re-
cently, character-based statistical machine trans-
lation (C-SMT) (Vilar et al, 2007; Tiedemann,
2009) has been proposed as an alternative ap-
proach to translating words between closely re-
lated languages and has been shown to outperform
stochastic transducers on the task of name translit-
eration (Tiedemann and Nabende, 2009).
For the related task of matching cognate pairs in
bilingual non-parallel corpora, various language-
independent similarity measures have been pro-
posed on the basis of string edit distance (Kon-
drak and Dorr, 2004). Cognate word matching has
been shown to facilitate the extraction of trans-
lation lexicons from comparable corpora (Koehn
and Knight, 2002; Kondrak et al, 2003; Fi?er and
Ljube?ic?, 2011).
58
For using SMT for modernizing historical
words, the only work so far is, to the best of our
knowledge, S?nchez-Mart?nez et al (2013).
3 The Dataset
In this section we detail the dataset that was used
in the subsequent experiments, which consists
of a frequency lexicon of contemporary Slovene
and training and testing lexicons of historical
Slovene.2
3.1 The Lexicon of Contemporary Slovene
Sloleks is a large inflectional lexicon of contem-
porary Slovene.3 The lexicon contains lemmas
with their full inflectional paradigms and with
the word forms annotated with frequency of oc-
currence in a large reference corpus of Slovene.
For the purposes of this experiment, we extracted
from Sloleks the list of its lower-cased word forms
(930,000) together with their frequency.
3.2 Corpora of Historical Slovene
The lexicons used in the experiments are con-
structed from two corpora of historical Slovene.4
The texts in the corpora are, inter alia marked up
with the year of publication and their IANA lan-
guage subtag (sl for contemporary Slovene al-
phabet and sl-bohoric for the old, pre-1850
Bohoric? alphabet). The word tokens are anno-
tated with the attributes nform, mform, lemma, tag,
gloss, where only the first two are used in the pre-
sented experiments.
The nform attribute contains the result of a sim-
ple normalization step, consisting of lower-casing,
removal of vowel diacritics (which are not used in
contemporary Slovene), and conversion of the Bo-
horic? alphabet to the contemporary one. Thus, we
do not rely on the C-SMT model presented below
to perform these pervasive, yet deterministic and
fairly trivial transformations.
The modernized form of the word, mform is the
word as it is (or would be, for extinct words) writ-
ten today: the task of the experiments is to predict
the correct mform given an nform.
2The dataset used in this paper is available under the
CC-BY-NC-SA license from http://nl.ijs.si/imp/
experiments/bsnlp-2013/.
3Sloleks is encoded in LMF and available under the CC-
BY-NC-SA license from http://www.slovenscina.
eu/.
4The data for historical Slovene comes from the IMP re-
sources, see http://nl.ijs.si/imp/.
Period Texts Words Verified
18B 8 21,129 21,129
19A 9 83,270 83,270
19B 59 146,100 146,100
? 75 250,499 250,499
Table 1: Size of goo300k corpus.
Period Texts Words Verified
18B 11 139,649 15,466
19A 13 457,291 17,616
19B 270 2,273,959 65,769
? 293 2,870,899 98,851
Table 2: Size of foo3M corpus.
The two corpora were constructed by sampling
individual pages from a collection of books and
editions of one newspaper, where the pages (but
not necessarily the publications) of the two cor-
pora are disjoint:5
? goo300k is the smaller, but fully manually
annotated corpus, in which the annotations of
each word have been verified;6
? foo3M is the larger, and only partially manu-
ally annotated corpus, in which only the more
frequent word forms that do not already ap-
pear in goo300k have verified annotations.
The texts have been marked up with the time
period in which they were published, e.g., 18B
meaning the second half of the 18th century. This
allows us to observe the changes to the vocabulary
in 50-year time slices. The sizes of the corpora are
given in Table 1 and Table 2.
3.3 Lexicons of Historical Slovene
From the two corpora we have extracted the
training and testing lexicons, keeping only words
(e.g., discarding digits) that have been manually
verified. The training lexicon, Lgoo is derived
from the goo300k corpus, while the test lexicon,
Lfoo is derived from the foo3M corpus and, as
5The corpora used in our experiments are slightly smaller
than the originals: the text from two books and one newspa-
per issue has been removed, as the former contain highly id-
iosyncratic ways of spelling words, not seen elsewhere, and
the latter contains a mixture of the Bohoric? and contempo-
rary alphabet, causing problems for word form normaliza-
tion. The texts older than 1750 have also been removed from
goo300k, as such texts do not occur in foo3M, which is used
for testing our approach.
6A previous version of this corpus is described in (Er-
javec, 2012).
59
Period Pairs Ident Diff OOV
18B 6,305 2,635 3,670 703
19A 18,733 12,223 6,510 2,117
19B 30,874 24,597 6,277 4,759
? 45,810 31,160 14,650 7,369
Table 3: Size of Lgoo lexicon.
Period OOV Pairs Ident Diff
18B 660 3,199 493 2,706
19A 886 3,638 1,708 1,930
19B 1,983 10,033 8,281 1,752
? 3,480 16,029 9,834 6,195
Table 4: Size of Lfoo lexicon.
mentioned, contains no ?nform, mform? pairs al-
ready appearing in Lgoo. This setting simulates
the task of an existing system receiving a new text
to modernize.
The lexicons used in the experiment contain en-
tries with nform, mform, and the per-slice frequen-
cies of the pair in the corpus from which the lexi-
con was derived, as illustrated in the example be-
low:
benetkah benetkah 19A:1 19B:1
aposteljnov apostolov 19A:1 19B:1
ar?ati ar?etu* 18B:2
The first example is a word that has not changed
its spelling (and was observed twice in the 19th
century texts), while the second and third have
changed their spelling. The asterisk on the third
example indicates that the mform is not present in
Sloleks. We exclude such pairs from the test lexi-
con (but not from the training lexicon) since they
will most likely not be correctly modernized by
our model, which relies on Sloleks. The sizes of
the two lexicons are given in Table 3 and Table 4.
For Lgoo we give the number of pairs including the
OOV words, while for Lfoo we exclude them; the
tables also show the numbers of pairs with iden-
tical and different words. Note that the summary
row has smaller numbers than the sum of the in-
dividual rows, as different slices can contain the
same pairs.
4 Experiments and Results
We conducted two experiments with the data de-
scribed above. In both cases, the goal is to cre-
ate C-SMT models for automatically modernizing
historical Slovene words. In each experiment, we
create three different models for the three time pe-
riods of old Slovene (18B, 19A, 19B).
The first experiment follows a supervised setup:
we train a C-SMT model on ?historical word,
contemporary word? pairs from Lgoo and test the
model on the word pairs of Lfoo. The second ex-
periment is unsupervised and relies on monolin-
gual data only: we match the old Slovene words
from Lgoo with modern Slovene word candidates
from Sloleks; this noisy list of word pairs then
serves to train the C-SMT model. We test again
on Lfoo.
4.1 Supervised Learning
SMT models consist of two main components: the
translation model, which is trained on bilingual
data, and the language model, which is trained
on monolingual data of the target language. We
use the word pairs from Lgoo to train the transla-
tion model, and the modern Slovene words from
Lgoo to train the language model.7 As said above,
we test the model on the word pairs of Lfoo.
The experiments have been carried out with the
tools of the standard SMT pipeline: GIZA++ (Och
and Ney, 2003) for alignment, Moses (Koehn et
al., 2007) for phrase extraction and decoding, and
IRSTLM (Federico et al, 2008) for language mod-
elling. After preliminary experimentation, we set-
tled on the following parameter settings:
? We have obtained the best results with a 5-
gram language model. The beginning and
the end of each word were marked by special
symbols.
? The alignments produced by GIZA++ are
combined with the grow-diag-final method.
? We chose to disable distortion, which ac-
counts for the possibility of swapping ele-
ments; there is not much evidence of this phe-
nomenon in the evolution of Slovene.
? We use Good Turing discounting to adjust the
weights of rare alignments.
? We set 20% of Lgoo aside for Minimum Error
Rate Training.
The candidates proposed by the C-SMT sys-
tem are not necessarily existing modern Slovene
words. Following Vilar et al (2007), we added a
7It is customary to use a larger dataset for the language
model than for the translation model. However, adding the
Sloleks data to the language model did not improve perfor-
mances.
60
Supervised Unsupervised
Period Total Baseline No lex filter With lex filter No lex filter With lex filter
18B 3199 493 (15.4%) 2024 (63.3%) 2316 (72.4%) 1289 (40.3%) 1563 (48.9%)
19A 3638 1708 (46.9%) 2611 (71.8%) 2941 (80.0%) 2327 (64.0%) 2644 (72.7%)
19B 10033 8281 (82.5%) 8707 (86.8%) 9298 (92.7%) 8384 (83.6%) 8766 (87.4%)
Table 5: Results of the supervised and the unsupervised experiments on Lfoo.
lexicon filter, which selects the first candidate pro-
posed by the C-SMT that also occurs in Sloleks.8
The results of these experiments, with and with-
out lexicon filter, are shown in Table 5. As a base-
line, we consider the words that are identical in
both language varieties. Without lexicon filter, we
obtain significant improvements over the baseline
for the first two time spans, but as the language va-
rieties become closer and the proportion of identi-
cal words increases, the SMT model becomes less
efficient. In contrast to Vilar et al (2007), we have
found the lexicon filter to be very useful: it im-
proves the results by nearly 10% absolute in 18B
and 19A, and by 5% in 19B.
4.2 Unsupervised Learning
The supervised approach requires a bilingual
training lexicon which associates old words with
modern words. Such lexicons may not be available
for a given language variety. In the second exper-
iment we investigate what can be achieved with
purely monolingual data. Concretely, we propose
a bootstrapping step to collect potential cognate
pairs from two monolingual word lists (the histor-
ical words of Lgoo, and Sloleks). We then train the
C-SMT system on these hypothesized pairs.
The bootstrapping step consists of searching,
for each historical word of Lgoo, its most similar
modern words in Sloleks.9 The similarity between
two words is computed with the BI-SIM measure
(Kondrak and Dorr, 2004). BI-SIM is a measure
of graphemic similarity which uses character bi-
grams as basic units. It does not allow crossing
alignments, and it is normalized by the length of
the longer string. As a result, this measure cap-
tures a certain degree of context sensitivity, avoids
8In practice, we generated 50-best candidate lists with
Moses, and applied the lexicon filter on that lists. In case
none of the 50 candidates occurs in Sloleks, the filter returns
the candidate with the best Moses score.
9In order to speed up the process and remove some noise,
we excluded hapaxes from Lgoo and all but the 20,000 most
frequent words from Sloleks. We also excluded words that
contain less than four characters from both corpora, since the
similarity measures proved unreliable on them.
counterintuitive alignments and favours associa-
tions between words of similar lengths. BI-SIM
is a language-independent measure and therefore
well-suited for this bootstrapping step.
For each old Slovene word, we keep the corre-
spondences that maximize the BI-SIM value, but
only if this value is greater than 0.8.10 For the
18B slice, this means that 812 out of 1333 histori-
cal words (60.9%) have been matched with at least
one modern word; 565 of the matches (69.6%, or
42.4% of the total) were correct.
These word correspondences are then used to
train a C-SMT model, analogously to the super-
vised approach. As for the language model, it is
trained on Sloleks, since the modernized forms
of Lgoo are not supposed to be known. Due to
the smaller training set size, MERT yielded un-
satisfactory results; we used the default weights of
Moses instead. The other settings are the same as
reported in Section 4.1. Again, we conducted ex-
periments for the three time slices. We tested the
system on the word pairs of the Lfoo lexicon, as
above. Results are shown in Table 5.
While the unsupervised approach performs sig-
nificantly less well on the 18B period, the differ-
ences gradually diminish for the subsequent time
slices; the model always performs better than the
baseline. Again, the lexicon filter proves useful in
all cases.
5 Conclusion
We have successfully applied the C-SMT ap-
proach to modernize historical words, obtaining
up to 57.0% (absolute) accuracy improvements
with the supervised approach and up to 33.5% (ab-
solute) with the unsupervised approach. In the fu-
ture, we plan to extend our model to modernize
entire texts in order to take into account possible
tokenization changes.
10This threshold has been chosen empirically on the basis
of earlier experiments, and allows us to eliminate correspon-
dences that are likely to be wrong. If several modern words
correspond to the same old word, we keep all of them.
61
Acknowledgements
The authors thank the anonymous reviewers for
their comments ? all errors, of course, remain
our own. This work has been partially funded
by the LabEx EFL (ANR/CGI), operation LR2.2,
by the EU IMPACT project ?Improving Access to
Text? and the Google Digital Humanities Research
Award ?Language models for historical Slove-
nian?.
References
Alistair Baron and Paul Rayson. 2008. VARD 2: A
tool for dealing with spelling variation in historical
corpora. In Proceedings of the Postgraduate Confer-
ence in Corpus Linguistics, Birmingham, UK. Aston
University.
Toma? Erjavec. 2012. The goo300k corpus of his-
torical Slovene. In Proceedings of the Eighth In-
ternational Conference on Language Resources and
Evaluation, LREC?12, Paris. ELRA.
Marcello Federico, Nicola Bertoldi, and Mauro Cet-
tolo. 2008. IRSTLM: an open source toolkit for
handling large scale language models. In Proceed-
ings of Interspeech 2008, Brisbane.
Darja Fi?er and Nikola Ljube?ic?. 2011. Bilingual lexi-
con extraction from comparable corpora for closely
related languages. In Proceedings of the Interna-
tional Conference on Recent Advances in Natural
Language Processing (RANLP?11), pages 125?131.
Mike Kestemont, Walter Daelemans, and Guy De
Pauw. 2010. Weigh your words ? memory-based
lemmatization for Middle Dutch. Literary and Lin-
guistic Computing, 25:287?301.
Philipp Koehn and Kevin Knight. 2002. Learning a
translation lexicon from monolingual corpora. In
Proceedings of the ACL 2002 Workshop on Unsu-
pervised Lexical Acquisition (SIGLEX 2002), pages
9?16, Philadelphia.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
source toolkit for statistical machine translation. In
Proceedings of the 45th Annual Meeting of the As-
sociation for Computational Linguistics (ACL?07),
demonstration session, Prague.
Grzegorz Kondrak and Bonnie Dorr. 2004. Identifi-
cation of confusable drug names: A new approach
and evaluation methodology. In In Proceedings of
COLING 2004, pages 952?958.
Grzegorz Kondrak, Daniel Marcu, and Kevin Knight.
2003. Cognates can improve statistical translation
models. In Proceedings of NAACL-HLT 2003.
Gideon S. Mann and David Yarowsky. 2001. Mul-
tipath translation lexicon induction via bridge lan-
guages. In Proceedings of the Second Meeting
of the North American Chapter of the Association
for Computational Linguistics (NAACL 2001), pages
151?158, Pittsburgh.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29(1):19?51.
Michael Piotrowski. 2012. Natural Language Pro-
cessing for Historical Texts. Synthesis Lectures on
Human Language Technologies. Morgan & Clay-
pool.
Ulrich Reffle. 2011. Efficiently generating correc-
tion suggestions for garbled tokens of historical lan-
guage. Natural Language Engineering, 17:265?
282.
Silke Scheible, Richard J. Whitt, Martin Durrell, and
Paul Bennett. 2010. Annotating a Historical Corpus
of German: A Case Study. In Proceedings of the
LREC 2010 Workshop on Language Resources and
Language Technology Standards, Paris. ELRA.
Silke Scheible, Richard J. Whitt, Martin Durrell, and
Paul Bennett. 2011. A Gold Standard Corpus of
Early Modern German. In Proceedings of the 5th
Linguistic Annotation Workshop, pages 124?128,
Portland, Oregon, USA, June. Association for Com-
putational Linguistics.
Felipe S?nchez-Mart?nez, Isabel Mart?nez-Sempere,
Xavier Ivars-Ribes, and Rafael C. Carrasco. 2013.
An open diachronic corpus of historical Span-
ish: annotation criteria and automatic modernisa-
tion of spelling. Research report, Departament
de Llenguatges i Sistemes Inform?tics, Universi-
tat d?Alacant, Alicante. http://arxiv.org/
abs/1306.3692.
J?rg Tiedemann and Peter Nabende. 2009. Translating
transliterations. International Journal of Computing
and ICT Research, 3(1):33?41. Special Issue of Se-
lected Papers from the fifth international conference
on computing and ICT Research (ICCIR 09), Kam-
pala, Uganda.
J?rg Tiedemann. 2009. Character-based PSMT for
closely related languages. In Proceedings of the
13th Conference of the European Association for
Machine Translation (EAMT 2009), pages 12 ? 19,
Barcelona.
David Vilar, Jan-Thorsten Peter, and Hermann Ney.
2007. Can we translate letters? In Proceedings of
the Second Workshop on Statistical Machine Trans-
lation, pages 33?39, Prague.
62
