Developments in Affect Detection in E-drama
Li Zhang, John A. Barnden, Robert J. Hendley, and Alan M. Wallington
School of Computer Science
University of Birmingham, UK
l.zhang@cs.bham.ac.uk
Abstract
We report work1 in progress on adding
affect-detection to an existing program
for virtual dramatic improvisation, moni-
tored by a human director. To partially
automate the directors? functions, we
have partially implemented the detection
of emotions, etc. in users? text input, by
means of pattern-matching, robust pars-
ing and some semantic analysis. The
work also involves basic research into
how affect is conveyed by metaphor.
1 Introduction
Improvised drama and role-play are widely used
in education, counselling and conflict resolution.
Researchers have explored frameworks for e-
drama, in which virtual characters (avatars) in-
teract under the control of human actors. The
springboard for our research is an existing sys-
tem (edrama) created by Hi8us Midlands Ltd,
used in schools for creative writing and teaching
in various subjects. The experience suggests that
e-drama helps students lose their usual inhibi-
tions, because of anonymity etc. In edrama,
characters are completely human-controlled,
their speeches textual in speech bubbles, and
their visual forms cartoon figures. The actors
(users) are given a loose scenario within which to
improvise, but are at liberty to be creative. There
is also a human director, who constantly moni-
tors the unfolding drama and can intervene by,
1 This work is supported by grant RES-328-25-0009 from
the ESRC under the ESRC/EPSRC/DTI ?PACCIT? pro-
gramme. We are grateful to Hi8us Midlands Ltd, Maverick
Television Ltd, BT, and our colleagues W.H. Edmondson,
S.R. Glasbey, M.G. Lee and Z. Wen. The work is also par-
tially supported by EPSRC grant EP/C538943/1.
for example, sending messages to actors, or by
introducing and controlling a minor ?bit-part?
character to interact with the main characters.
But this places a heavy burden on directors, es-
pecially if they are, for example, teachers and
unpracticed in the directorial role. One research
aim is thus partially to automate the directorial
functions, which importantly involve affect de-
tection. For instance, a director may intervene
when emotions expressed or discussed by char-
acters are not as expected. Hence we have devel-
oped an affect-detection module. It has not yet
actually been used for direction, but instead to
control a simple automated bit-part actor,
EmEliza. The module identifies affect in charac-
ters? speeches, and makes appropriate responses
to help stimulate the improvisation. Within affect
we include: basic and complex emotions such as
anger and embarrassment; meta-emotions such
as desiring to overcome anxiety; moods such as
hostility; and value judgments (of goodness,
etc.). Although merely detecting affect is limited
compared to extracting full meaning, this is often
enough for stimulating improvisation.
Much research has been done on creating affec-
tive virtual characters in interactive systems. Emo-
tion theories, particularly that of Ortony et al
(1988; OCC in the following), have been used
widely. Prendinger & Ishizuka (2001) used OCC
to reason about emotions. Mehdi et al (2004) used
OCC to generate emotional behaviour. Gratch and
Marsella?s (2004) model reasons about emotions.
However, few systems are aimed at detecting af-
fect as broadly as we do and in open-ended utter-
ances. Although Fa?ade (Mateas, 2002) included
processing of open-ended utterances, the broad
detection of emotions, rudeness and value judge-
ments is not covered. Zhe & Boucouvalas (2002)
demonstrated emotion extraction using a tagger
and a chunker to help detect the speaker?s own
emotions. But it focuses only on emotional adjec-
tives, considers only first-person emotions and
203
neglects deep issues such as figurative expression.
Our work is distinctive in several respects. Our
interest is not just in (a) the positive first-person
case: the affective states that a virtual character X
implies that it has (or had or will have, etc.), but
also in (b) affect that X implies it lacks, (c) affect
that X implies that other characters have or lack,
and (d) questions, commands, injunctions, etc.
concerning affect. We aim also for the software to
cope partially with the important case of meta-
phorical conveyance of affect (Fussell & Moss,
1998; K?vecses, 1998).
Our project does not involve using or develop-
ing deep, scientific models of how emotional
states, etc., function in cognition. Instead, the
deep questions investigated are on linguistic mat-
ters such as the metaphorical expression of af-
fect. Also, in studying how people understand
and talk about affect, what is of prime impor-
tance is their common-sense views of how affect
works, irrespective of scientific reality. Metaphor
is strongly involved in such views.
2 A Preliminary Approach
Various characterizations of emotion are used in
emotion theories. The OCC model uses emotion
labels and intensity, while Watson and Tellegen
(1985) use positive and negative affects as the
major dimensions. Currently, we use an evalua-
tion dimension (positive and negative), affect
labels and intensity. Affect labels with intensity
are used when strong text clues signalling affect
are detected, while the evaluation dimension
with intensity is used when only weak text clues
are detected.
2.1 Pre-processing Modules
The language in the speeches created in e-drama
sessions, especially by excited children, severely
challenges existing language-analysis tools if
accurate semantic information is sought. The
language includes misspellings, ungrammatical-
ity, abbreviations (such as in texting), slang, use
of upper case and special punctuation (such as
repeated exclamation marks) for affective em-
phasis, repetition of letters or words for empha-
sis, and open-ended onomatopoeic elements such
as ?grrrr?. The genre is similar to Internet chat.
To deal with the misspellings, abbreviations
and onomatopoeia, several pre-processing mod-
ules are used before the detection of affect starts
using pattern matching, syntactic processing by
means of the Rasp parser (Briscoe & Carroll,
2002), and subsequent semantic processing.
A lookup table has been used to deal with ab-
breviations e.g. ?im (I am)?, ?c u (see you)? and
?l8r (later)?. It includes abbreviations used in
Internet chat rooms and others found in an anly-
sis of previous edrama sessions. We handle am-
biguity (e.g.,?2? (to, too, two) in ?I?m 2 hungry 2
walk?) by considering the POS tags of immedi-
ately surrounding words. Such simple processing
inevitably leads to errors, but in evaluations us-
ing examples in a corpus of 21695 words derived
from previous transcripts we have obtained
85.7% accuracy, which is currently adequate.
The iconic use of word length (corresponding
roughly to imagined sound length) as found both
in ordinary words with repeated letters (e.g.
?seeeee?) and in onomatopoeia and interjections,
(e.g. ?wheee?, ?grr?, ?grrrrrr?, ?agh?, ?aaaggghhh?)
normally implies strong affective states. We have
a small dictionary containing base forms of some
special words (e.g. ?grr?) and some ordinary
words that often have letters repeated in e-drama.
Then the Metaphone spelling-correction algo-
rithm, which is based on pronunciation, works
with the dictionary to locate the base forms of
words with letter repetitions.
Finally, the Levenshtein distance algorithm
with a contemporary English dictionary deals
with misspelling.
2.2 Affect Detection
In the first stage after the pre-processing, our
affect detection is based on textual pattern-
matching rules that look for simple grammatical
patterns or phrasal templates. Thus keywords,
phrases and partial sentence structures are ex-
tracted. The Jess rule-based Java framework is
used to implement the pattern/template-matching
rules. This method has the robustness to deal
with ungrammatical and fragmented sentences
and varied positioning of sought-after phraseol-
ogy, but lacks other types of generality and can
be fooled by suitable syntactic embedding. For
example, if the input is ?I doubt she?s really an-
gry?, rules looking for anger in a simple way will
output incorrect results.
The transcripts analysed to inspire our initial
knowledge base and pattern-matching rules had
independently been produced earlier from edrama
improvisations based on a school bullying sce-
nario. We have also worked on another, distinctly
different scenario concerning a serious disease,
based on a TV programme produced by Maverick
Television Ltd. The rule sets created for one sce-
nario have a useful degree of applicability to an-
other, although some changes in the specific
204
knowledge database will be needed.
As a simple example of our pattern-matching,
when the bully character says ?Lisa, you Pizza
Face! You smell?, the module detects that he is
insulting Lisa. Patterns such as ?you smell? have
been used for rule implementation. The rules work
out the character?s emotions, evaluation dimension
(negative or positive), politeness (rude or polite)
and what response EmEliza might make. Although
the patterns detected are based on English, we
would expect that some of the rules would require
little modification to apply to other languages.
Multiple exclamation marks and capitalisation
of whole words are often used for emphasis in e-
drama. If exclamation marks or capitalisation are
detected, then emotion intensity is deemed to be
comparatively high (and emotion is suggested
even without other clues).
A reasonably good indicator that an inner state
is being described is the use of ?I? (see also Craggs
and Wood (2004)), especially in combination with
the present or future tense. In the school-bullying
scenario, when ?I? is followed by a future-tense
verb, a threat is normally being expressed; and the
utterance is often the shortened version of an im-
plied conditional, e.g., ?I?ll scream [if you stay
here].? When ?I? is followed by a present-tense
verb, other emotional states tend to be expressed,
as in ?I want my mum? and ?I hate you?.
Another useful signal is the imperative mood,
especially when used without softeners such as
?please?: strong emotions and/or rude attitudes are
often being expressed. There are common impera-
tive phrases we deal with explicitly, such as ?shut
up? and ?mind your own business?. But, to go
beyond the limitations of the pattern matching
we have done, we have also used the Rasp parser
and semantic information in the form of the se-
mantic profiles for the 1,000 most frequently
used English words (Heise, 1965).
Although Rasp recognizes many simple im-
peratives directly, it can parse some imperatives
as declaratives or questions. Therefore, further
analysis is applied to Rasp?s syntactic output.
For example, if the subject of an input sen-
tence is ?you? followed by certain special verbs
or verb phrases (e.g. ?shut?, ?calm?, ?get lost?, ?go
away?, etc), and Rasp parses a declarative, then it
will be changed to imperative. If the softener
?please? is followed by a base forms of the verb,
the inputs are also deemed to be imperatives. If a
singular proper noun or ?you? is followed by a
base form of the verb, the sentence is deemed to
be imperative (e.g. ?Dave bring me the menu?).
When ?you? or a singular proper noun is fol-
lowed by a verb whose base form equals its past
tense form, ambiguity arises (e.g. ?Lisa hit me?).
For one special case of this, if the direct object is
?me?, we exploit the evaluation value of the verb
from Heise?s (1965) semantic profiles. Heise
lists values of evaluation (goodness), activation,
potency, distance from neutrality, etc. for each
word covered. If the evaluation value for the
verb is negative, then the sentence is probably
not imperative but a declarative expressing a
complaint (e.g ?Mayid hurt me?). If it has a posi-
tive value, then other factors suggesting impera-
tive are checked in this sentence, such as excla-
mation marks and capitalizations. Previous con-
versation is checked to see if there is any recent
question sentence toward the speaker. If so, then
the sentence is taken to be declarative.
There is another type of sentence: ?don?t you +
(base form of verb)?, which is often a negative
version of an imperative with a ?you? subject (e.g.
?Don?t you call me a dog?). Normally Rasp re-
gards such strings as questions. Further analysis
has also been implemented for such sentence
structure, which implies negative affective state,
to change the sentence type to imperative.
Aside from imperatives, we have also imple-
mented simple types of semantic extraction of
affect using affect dictionaries and WordNet.
3 Metaphorical Expression of Affect
The explicit metaphorical description of emo-
tional states is common and has been extensively
studied (Fussell & Moss, 1998). Examples are
?He nearly exploded?, and ?Joy ran through me.?
Also, affect is often conveyed implicitly via
metaphor, as in ?His room is a cess-pit?, where
affect associated with a source item (cess-pit) is
carried over to the corresponding target item.
Physical size is often metaphorically used to
emphasize evaluations, as in ?you are a big
bully?, ?you?re a big idiot?, and ?you?re just a
little bully?, although the bigness may be literal
as well. ?Big bully? expresses strong disapproval
(Sharoff, 2005) and ?little bully? can express
contempt, although ?little? can also convey sym-
pathy. Such examples are not only practically
important but also theoretically challenging.
We have also encountered quite creative use
of metaphor in e-drama. For example, in a
school-bullying improvisation that occurred,
Mayid had already insulted Lisa by calling her a
?pizza?, developing a previous ?pizza-face? in-
sult. Mayid then said ?I?ll knock your topping
off, Lisa? ? a theoretically intriguing spontane-
205
ous creative elaboration of the ?pizza? metaphor.
Our developing approach to metaphor handling
in the affect detection module is partly to look
for stock metaphorical phraseology and straight-
forward variants of it, and partly to use a simple
version of the more open-ended, reasoning-based
techniques taken from the ATT-Meta project
(Barnden et al, 2002; 2003; 2004). ATT-Meta
includes a general-purpose reasoning engine, and
can potentially be used to reason about emotion
in relation to other factors in a situation. In turn,
the realities of metaphor usage in e-drama ses-
sions are contributing to our basic research on
metaphor processing.
4 Conclusion
We have implemented a limited degree of affect-
detection in an automated actor by means of pat-
tern-matching, robust parsing and some semantic
analysis. Although there is a considerable dis-
tance to go in terms of the practical affect-
detection that we plan to implement, the already
implemented detection is able to cause reasona-
bly appropriate contributions by the automated
character. We have conducted a two-day pilot
user test with 39 secondary school students. We
concealed the involvement of an earlier version
of EmEliza in some sessions, in order to test by
questionnaire whether its involvement affects
user satisfaction, etc. None of the measures re-
vealed a significant effect. Also, judging by the
group debriefing sessions after the e-drama ses-
sions, nobody found out that one bit-part charac-
ter was sometimes computer-controlled. Further
user testing with students at several Birmingham
schools will take place in March 2006.
References
Barnden, J.A., Glasbey, S.R., Lee, M.G. & Walling-
ton, A.M., 2002. Reasoning in metaphor under-
standing: The ATT-Meta approach and system. In
Proceedings of the 19th International Confer-
ence on Computational Linguistics.
Barnden, J.A., Glasbey, S.R., Lee, M.G. & Walling-
ton, A.M., 2003. Domain-transcending mappings
in a system for metaphorical reasoning. In Pro-
ceedings of the Research Note Sessions of the
10th Conference of EACL.
Barnden, J.A., Glasbey, S.R., Lee, M.G. & Walling-
ton, A.M. 2004. Varieties and Directions of Inter-
domain Influence in Metaphor. Metaphor and
Symbol, 19(1), pp.1-30.
Briscoe, E. & J. Carroll. 2002. Robust Accurate Sta-
tistical Annotation of General Text. In Proceed-
ings of the 3rd International Conference on
Language Resources and Evaluation, Las Pal-
mas, Gran Canaria. pp.1499-1504.
Craggs, R. & Wood. M. 2004. A Two Dimensional
Annotation Scheme for Emotion in Dialogue. In
Proceedings of AAAI Spring Symposium: Ex-
ploring Attitude and Affect in Text.
Fussell, S. & Moss, M. 1998. Figurative Language in
Descriptions of Emotional States. In S. R. Fussell
and R. J. Kreuz (Eds.), Social and cognitive ap-
proaches to interpersonal communication.
Lawrence Erlbaum.
Gratch, J. & Marsella, S. 2004. A Domain-
Independent Framework for Modeling Emotion.
Journal of Cognitive Systems Research. Vol 5,
Issue 4, pp.269-306.
Heise, D. R. 1965. Semantic Differential Profiles for
1,000 Most Frequent English Words. Psychologi-
cal Monographs 79, pp.1-31.
K?vecses, Z. 1998. Are There Any Emotion-Specific
Metaphors? In Speaking of Emotions: Concep-
tualization and Expression. Athanasiadou, A.
and Tabakowska, E. (eds.), Berlin and New York:
Mouton de Gruyter, pp.127-151.
Mateas, M. 2002. Ph.D. Thesis. Interactive Drama,
Art and Artificial Intelligence. School of Computer
Science, Carnegie Mellon University.
Mehdi, E.J., Nico P., Julie D. & Bernard P. 2004.
Modeling Character Emotion in an Interactive Vir-
tual Environment. In Proceedings of AISB 2004
Symposium: Motion, Emotion and Cognition.
Leeds, UK.
Ortony, A., Clore, G.L. & Collins, A. 1988. The
Cognitive Structure of Emotions. CUP
Prendinger, H. & Ishizuka, M. 2001. Simulating Af-
fective Communication with Animated Agents. In
Proceedings of Eighth IFIP TC.13 Conference
on Human-Computer Interaction, Tokyo, Japan,
pp.182-189.
Sharoff, S. 2005. How to Handle Lexical Semantics in
SFL: a Corpus Study of Purposes for Using Size
Adjectives. Systemic Linguistics and Corpus.
London: Continuum.
Watson, D. & Tellegen, A. 1985. Toward a Consen-
sual Structure of Mood. Psychological Bulletin,
98, pp.219-235.
Zhe, X. & Boucouvalas, A. C. 2002. Text-to-Emotion
Engine for Real Time Internet Communication. In
Proceedings of International Symposium on
Communication Systems, Networks and DSPs,
Staffordshire University, UK, pp.164-168.
206
Proceedings of the ACL 2007 Demo and Poster Sessions, pages 37?40,
Prague, June 2007. c?2007 Association for Computational Linguistics
Don?t worry about metaphor: affect extraction for conversational agents
Catherine Smith, Tim Rumbell, John Barnden, Bob Hendley, Mark Lee & Alan Wallington
School of Computer Science, University of Birmingham
Birmingham B15 2TT, UK
J.A.Barnden@cs.bham.ac.uk
Abstract
We demonstrate one aspect of an affect-
extraction system for use in intelligent con-
versational agents. This aspect performs a
degree of affective interpretation of some
types of metaphorical utterance.
1 Introduction
Our demonstration is of one aspect of a system
for extracting affective information from individ-
ual utterances, for use in text-based intelligent con-
versational agents (ICAs). Affect includes emo-
tions/moods (such as embarrassment, hostility) and
evaluations (of goodness, importance, etc.). Our
own particular ICA [Zhang et al 2006] is for use
in an e-drama system, where human users behave as
actors engaged in unscripted role-play. Actors type
in utterances for the on-screen characters they con-
trol to utter (via speech bubbles). Our ICA is an-
other actor, controlling a bit-part character. Through
extracting affect from other characters? utterances it
makes responses that can help keep the conversation
flowing. The same algorithms are also used for in-
fluencing the characters? gesturing (when a 3D ani-
mation mode is used).
The system aspect demonstrated handles one im-
portant way in which affect is expressed in most dis-
course genres: namely metaphor. Only a relatively
small amount of work has been done on computa-
tional processing of metaphorical meaning, for any
purpose, let alne in ICA research. Major work
apart from ours on metaphorical-meaning compu-
tation includes (Fass, 1997; Hobbs, 1990; Mar-
tin, 1990; Mason, 2004; Narayanan, 1999; Veale,
1998). The e-drama genre exhibits a variety of types
of metaphor, with a significant degree of linguistic
open-endedness. Also, note that our overarching re-
search aim is to study metaphor as such, not just how
it arises in e-drama. This increases our need for sys-
tematic, open-ended methods.
2 Metaphor and Affect
Conveying affect is one important role for metaphor,
and metaphor is one important way of conveying
affect. Emotional states and behavior often them-
selves described metaphorically (Ko?vecses, 2000;
Fussell & Moss, 1998), as in ?He was boiling
inside? [feelings of anger]. But another impor-
tant phenomenon is describing something X using
metaphorical source terms that are subject to that
affect, as in ?My son?s room [= X] is a bomb site?
or ?smelly attitude? (an e-drama transcript exam-
ple). Such carry-over of affect in metaphor is well-
recognized, e.g. in the political domain (Musolff,
2004). Our transcript analyses indicate that this type
of affect-laden metaphor is a significant issue in e-
drama: at a conservative estimate, in recent user
studies in secondary schools at least one in every
16 speech-turns has contained such metaphor (each
turn is   100 characters, and rarely more than one
sentence; 33K words across all transcripts).
There are other specific, theoretically interesting
metaphorical phenomena arising in e-drama that are
important also for discourse in general, and plausi-
bly could be handled reasonably successfully in an
ICA using current techniques. Some are:
1) Casting someone as an animal. This often con-
veys affect, from insultingly negative to affection-
ately positive. Terms for young animals (?piglet?,
?wolf cub?, etc.) are often used affectionately, even
37
when the adult form is negative. Animal words can
have a conventional metaphorical sense, often with
specific affect, but in non-conventional cases a sys-
tem may still be able to discern a particular affective
connotation; and even if it cannot, it can still plausi-
bly infer that some affect is expressed, of unknown
polarity (positivity/negativity).
2) Rather similarly, casting someone as a monster
or as a mythical or supernatural being, using words
such as ?monster?, ?dragon,? ?angel,? ?devil.?
3) Casting someone as a special type of human, us-
ing words such as ?baby? (to an adult), ?freak,? ?girl?
(to a boy), ?lunatic.?
4) Metaphorical use of size adjectives (cf. Sharoff,
2006). Particularly, using ?a little X? to convey af-
fective qualities of X such as unimportance and con-
temptibility, but sometimes affection towards X, and
?big X? to convey importance of X (?big event?) or
intensity of X-ness (?big bully?)?and X can itself
be metaphorical (?baby?, ?ape?).
Currently, our system partially addresses (1), (2) and
(4).
3 Metaphor Recognition & Analysis
3.1 The Recognition Component
The basis here is a subset of a list of
metaphoricity signals we have compiled
[http://www.cs.bham.ac.uk/?jab/ATT-
Meta/metaphoricity-signals.html], by modify-
ing and expanding a list from Goatly (1997). The
signals include specific syntactic structures, phrase-
ological items and morphological elements. We
currently focus on two special syntactic structures,
X is/are Y and You/you Y, and some lexical strings
such as ?[looks] like?, ?a bit of a? and ?such a?. The
signals are merely uncertain, heuristic indicators.
For instance, in the transcripts mentioned in section
2, we judged X is/are Y as actually indicating the
presence of metaphor in 38% of cases (18 out of
47). Other success rates are: you Y ? 61% (22 out of
36); like (including looks like)? 81% (35 out of 43).
In order to detect signals we use the Grammatical
Relations (GR) output from the RASP robust parser
[Briscoe et al, 2006] This output shows typed word-
pair dependencies between the words in the utter-
ance. E.g., the GR output for ?You are a pig? is:
|ncsubj| |be+_vbr| |you_ppy| |_|
|xcomp| _ |be+_vbr| |pig_nn1|
|det| |pig_nn1| |a_at1|
For an utterance of the type X is/are Y the GRs will
always give a subject relation (ncsubj) between X
and the verb ?to be?, as well as a complement re-
lation (xcomp) between the verb and the noun Y.
The structure is detected by finding these relations.
As for you Y, Rasp also typically delivers an easily
analysable structure, but unfortunately the POS tag-
ger in Rasp seems to favour tagging Y as a verb?
e.g., ?cow? in ?You cow?. In such a case, our system
looks the word up in a list of tagged words that forms
part of the RASP tagger. If the verb can be tagged
as a noun, the tag is changed, and the metaphoricity
signal is deemed detected. Once a signal is detected,
the word(s) in relevant positions (e.g. the Y posi-
tion) position are pulled out to be analysed. This
approach has the advantage that whether or not the
noun in, say, the Y position has adjectival modifiers
the GR between the verb and Y is the same, so the
detection tolerates a large amount of variation. Any
such modifiers are found in modifying relations and
are available for use in the Analysis Component.
3.2 The Analysis Component
We confine attention here to X?is/are?Y and You?Y
cases. The analysis element of the processing takes
the X noun (if any) and Y noun and uses Word-
Net 2.0 to analyse them. First, we try to determine
whether X refers to a person (the only case the sys-
tem currently deals with), partly by using a specified
list of proper names of characters in the drama and
partly by WordNet processing. If so, then the Y and
remaining elements are analysed using WordNet?s
taxonomy. This allows us to see if the Y noun in one
of its senses is a hyponym of animals or supernatural
beings. If this is established, the system sees if an-
other of the senses of the word is a hyponym of the
person synset, as many metaphors are already given
as senses in WordNet. If different senses of the given
word are hyponyms of both animal and person, other
categories in the tree between the noun and the per-
son synset may provide information about the eval-
uative content of the metaphor. For example the
word ?cow? in its metaphorical usage has the ?un-
pleasant person? synset as a lower hypernym, which
heuristically suggests that, when the word is used in
a metaphor, it will be negative about the target.
There is a further complication. Baby animal
names can often be used to give a statement a more
affectionate quality. Some baby animal names such
as ?piglet? do not have a metaphorical sense in Word-
38
Net. In these cases, we check the word?s gloss to see
if it is a young animal and what kind of animal it
is. We then process the adult animal name to seek a
metaphorical meaning but add the quality of affec-
tion to the result. A higher degree of confidence is
attached to the quality of affection than is attached
to the positive/negative result, if any, obtained from
the adult name. Other baby animal names such as
?lamb? do have a metaphorical sense in WordNet in-
dependently of the adult animal, and are therefore
evaluated as in the previous paragraph. They are
also flagged as potentially expressing affection but
with a lesser degree of confidence than that gained
from the metaphorical processing of the word. How-
ever, the youth of an animal is not always encoded
in a single word: e.g., ?cub? may be accompanied
by specification of an animal type, as in ?wolf cub?.
An extension to our processing would be required to
handle this and also cases like ?young wolf? or ?baby
wolf?.
If any adjectival modifiers of the Y noun were rec-
ognized the analyser then goes on to evaluate their
contribution to the metaphor?s affect. If the analyser
finds that ?big? is one of the modifying adjectives
of the noun it has analysed the metaphor is marked
as being more emphatic. If ?little? is found the fol-
lowing is done. If the metaphor has been tagged as
negative and no degree of affection has been added
(from a baby animal name, currently) then ?little? is
taken to be expressing contempt. If the metaphor
has been tagged as positive OR a degree of affection
has been added then ?little? is taken to be expressing
affection.
4 Examples of Course of Processing
?You piglet?:
(1) Detector recognises the you Y signal with Y =
?piglet?.
(2) Analyser finds that ?piglet? is a hyponym of ?an-
imal?.
(3) ?Piglet? does not have ?person? as a WordNet hy-
pernym so analyser retrieves the WordNet gloss.
(4) It finds ?young? in the gloss (?a young pig?) and
retrieves all of the following words (just ?pig? ? the
analysis process is would otherwise be repeated for
each of the words captured from the gloss), and finds
that ?pig? by itself has negative metaphorical affect.
(5) The input is labelled as an animal metaphor
which is negative but affectionate, with the affection
having higher confidence than the negativity.
?Lisa is an angel?:
(1) Detector recognises the X is Y signal with Y =
?angel?, after checking that Lisa is a person.
(2) Analyser finds that ?angel? is a hyponym of ?su-
pernatural being?.
(3) It finds that in another sense ?angel? is a hyponym
of ?person?.
(4) It finds that the tree including the ?person? synset
also passes through ?good person,? expressing posi-
tive affect.
(5) Conclusion: positive supernatural-
being metaphor.
Results from Some Other Examples:
?You cow?, ?they?re such sheep?: negative
metaphor.
?You little rat?: contemptuous metaphor.
?You little piggy?: affectionate metaphor with a neg-
ative base.
?You?re a lamb?: affectionate metaphor.
?You are a monster?: negative metaphor.
?She is such a big fat cow?: negative metaphor, in-
tensified by ?big? (currently ?fat? is not dealt with).
5 Concluding Remarks
The demonstrated processing capabilities make par-
ticular but nevertheless valuable contributions to
metaphor processing and affect-detection for ICAs,
in e-drama at least. Further work is ongoing on the
four specific metaphorical phenomena in section 3
as well as on other phenomena, such as the vari-
ation of conventional metaphorical phraseology by
synonym substitution and addition of modifiers, and
metaphorical descriptions of emotions themselves.
As many extensions are ongoing or envisaged,
it is premature to engage in large-scale evaluation.
Also, there are basic problems facing evaluation.
The language in the e-drama genre is full of mis-
spellings, ?texting? abbreviations, acronyms, gram-
matical errors, etc., so that fully automated evalua-
tion of the metaphorical processing by itself is dif-
ficult; and application of the system to manually
cleaned-up utterances is still dependent on Rasp ex-
tracting structure appropriately. Also, our own ul-
timate concerns are theoretical, to do with the na-
ture of metaphor understanding. We are interested
in covering the qualitative range of possibilities and
complications, with no strong constraint from their
39
frequency in real discourse. Thus, statistical evalua-
tion on corpora is not particularly relevant except for
practical purposes.
However, some proto-evaluative comments that
can be made about animal metaphors are as fol-
lows. The transcripts mentioned in section 2 (33K
words total) contain metaphors with the following
animal words: rhino, bitch, dog, ape, cow, mole,
from 14 metaphorical utterances in all. Seven of
the utterances are recognized by our system, and
these involve rhino, dog, ape, mole. No WordNet-
based metaphorical connotation is found for the
rhino case. Negative affect is concluded for bitch,
dog and cow cases, and affect of undetermined po-
larity is concluded for ape and mole.
The system is currently designed only to do rela-
tively simple, specialized metaphorical processing.
The system currently only deals with a small mi-
nority of our own list of metaphoricity signals (see
section 3.1), and these signals are only present in a
minority of cases of metaphor overall. It does not
do either complex reasoning or analogical structure-
matching as in our own ATT-Meta metaphor sys-
tem (Barnden, 2006) or the cited approaches of Fass,
Hobbs, Martin, Narayanan and Veale. However, we
plan to eventually add simplified versions of ATT-
Meta-style reasoning, and in particular to add the
ATT-Meta view-neutral mapping adjunct feature to
implement the default carry-over of affect (see sec-
tion 2) and certain other information, as well as han-
dling more signals.
Other work on metaphor has exploited WordNet
(see, e.g., Veale, 2003, and panel on Figurative Lan-
guage in WordNets and other Lexical Resources
at GWC?04 (http://www.fi.muni.cz/gwc2004/.
Such work uses WordNet in distinctly different ways
from us and largely for different purposes. Our sys-
tem is also distinctive in, for instance, interpreting
the contribution of size adjectives.
Acknowledgments
The research has been aided by Sheila Glasbey and
Li Zhang, and supported by ESRC/EPSRC/DTI Pac-
cit LINK grant (ESRC RES-328-25-0009) and EP-
SRC grant EP/C538943/1.
References
John Barnden. 2006. Artificial Intelligence, Figurative
Language and Cognitive Linguistics. In G. Kristiansen
et al (Eds), Cognitive Linguistics: Current Applica-
tions and Future Perspectives, 431?459. Berlin: Mou-
ton de Gruyter.
Ted Briscoe, John Carroll and Rebecca Watson. 2006.
The Second Release of the RASP System. In Procs.
COLING/ACL 2006 Interactive Presentation Sessions.
Sydney, Australia.
Dan Fass. 1997. Processing Metaphor and Metonymy.
Greenwich, Connecticut: Ablex.
Susan Fussell & Mallie Moss. 1998. Figurative Lan-
guage in Emotional Communication. Social and Cog-
nitive Approaches to Interpersonal Communication.
Lawrence Erlbaum.
Andrew Goatly. 1997. The Language of Metaphors.
Routledge, London.
Jerry Hobbs. 1990. Literature and Cognition. CSLI Lec-
ture Notes, 21, Stanford University, 1990.
Zolta?n Ko?vecses. 2000. Metaphor and Emotion: Lan-
guage, Culture and Body in Human Feeling. Cam-
bridge University Press, Cambridge.
James Martin. 1990. A Computational Model of
Metaphor Interpretation. Academic Press.
Zachary Mason. 2004. CorMet: A computational,
corpus-based conventional metaphor extraction sys-
tem. Computational Linguistics, 30(1), 23?44.
Andreas Musolff. 2004. Metaphor and political dis-
course: Analogical reasoning in debates about Eu-
rope. Palgrave Macmillan.
Srini Narayanan. 1999. Moving right along: A compu-
tational model of metaphoric reasoning about events.
Procs. National Conference on Art. Int., 121?128.
Serge Sharoff. 2006. How to Handle Lexical Semantics
in SFL: A Corpus Study of Purposes for Using Size
Adjectives. System and Corpus: Exploring Connec-
tions. Equinox, London.
Tony Veale. 1998. ?Just in Time? analogical mapping, an
iterative-deepening approach to structure-mapping. In
Procs. 13th European Conference on Art. Intell.
Tony Veale. 2003. Dynamic Type Creation in Metaphor
Interpretation and Analogical Reasoning: A Case-
Study with WordNet. In Procs. International Confer-
ence on Conceptual Structures (Dresden).
Li Zhang, John Barnden, Bob Hendley & Alan Walling-
ton. 2006. Exploitation in Affect Detection in Impro-
visational E-Drama. In Procs. 6th Int. Conference on
Intelligent Virtual Agents: Lecture Notes in Computer
Science, 4133, 68?79. Springer.
40
Proceedings of the Workshop on Sentiment and Subjectivity in Text, pages 47?54,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Exploitation in Affect Detection in Open-Ended Improvisational Text   
 
 
Li Zhang, John A. Barnden, Robert J. Hendley and Alan M. Wallington 
School of Computer Science 
University of Birmingham 
  Birmingham B15 2TT, UK 
l.zhang@cs.bham.ac.uk 
 
  
 
Abstract 
We report progress on adding affect-
detection to a program for virtual dra-
matic improvisation, monitored by a hu-
man director. We have developed an af-
fect-detection module to control an 
automated virtual actor and to contribute 
to the automation of directorial functions. 
The work also involves basic research 
into how affect is conveyed through 
metaphor. The project contributes to the 
application of sentiment and subjectivity 
analysis to the creation of emotionally 
believable synthetic agents for interactive 
narrative environments. 
1 Introduction 
Improvised drama and role-play are widely used 
in education, counselling and conflict resolution. 
Researchers have explored frameworks for e-
drama, in which virtual characters (avatars) 
interact under the control of human actors. The 
springboard for our research is an existing 
system (edrama) created by one of our industrial 
partners, Hi8us Midlands, used in schools for 
creative writing and teaching in various subjects. 
The experience suggests that e-drama helps 
students lose their usual inhibitions, because of 
anonymity etc. In edrama, characters are 
completely human-controlled, their speeches 
textual in speech bubbles, and their visual forms 
cartoon figures. The actors (users) are given a 
loose scenario within which to improvise, but are 
at liberty to be creative. There is also a human 
director, who constantly monitors the unfolding 
drama and can intervene by, for example, 
sending messages to actors, or by introducing 
and controlling a minor ?bit-part? character to 
interact with the main characters. But this places 
a heavy burden on directors, especially if they 
are, for example, teachers and unpracticed in the 
directorial role. One research aim is thus partially 
to automate the directorial functions, which 
importantly involve affect detection. For 
instance, a director may intervene when 
emotions expressed or discussed by characters 
are not as expected. Hence we have developed an 
affect-detection module. It has not yet actually 
been used for direction, but instead to control an 
automated bit-part actor, EMMA (emotion, 
metaphor and affect). The module identifies 
affect in characters? speeches, and makes 
appropriate responses to help stimulate the 
improvisation. Within affect we include: basic 
and complex emotions such as anger and 
embarrassment; meta-emotions such as desiring 
to overcome anxiety; moods such as hostility; 
and value judgments (of goodness, etc.). 
Although merely detecting affect is limited 
compared to extracting full meaning, this is often 
enough for stimulating improvisation. 
Much research has been done on creating af-
fective virtual characters in interactive systems. 
Indeed, Picard?s work (2000) makes great con-
tributions to building affective virtual characters. 
Also, emotion theories, particularly that of Or-
tony, et al (1988) (OCC), have been used widely 
therein. Egges et al (2003) have provided virtual 
characters with conversational emotional respon-
siveness. However, few systems are aimed at 
detecting affect as broadly as we do and in open-
ended utterances. Although Fa?ade (Mateas, 
2002) included processing of open-ended utter-
ances, the broad detection of emotions, rudeness 
and value judgements is not covered. Zhe & 
Boucouvalas (2002) demonstrated emotion ex-
traction using a tagger and a chunker to help de-
tect the speaker?s own emotions. But it focuses 
only on emotional adjectives, considers only 
47
first-person emotions and neglects deep issues 
such as figurative expression. Our work is dis-
tinctive in several respects. Our interest is not 
just in (a) the positive first-person case: the af-
fective states that a virtual character X implies 
that it has (or had or will have, etc.), but also in 
(b) affect that X implies it lacks, (c) affect that X 
implies that other characters have or lack, and (d) 
questions, commands, injunctions, etc. concern-
ing affect. We aim also for the software to cope 
partially with the important case of metaphorical 
conveyance of affect (Fussell & Moss, 1998; 
K?vecses, 1998). 
Our project does not involve using or develop-
ing deep, scientific models of how emotional 
states, etc., function in cognition. Instead, the 
deep questions investigated are on linguistic mat-
ters such as the metaphorical expression of af-
fect. Also, in studying how people understand 
and talk about affect, what is of prime impor-
tance is their common-sense views of how affect 
works, irrespective of scientific reality. Metaphor 
is strongly involved in such views. 
2 Our Current Affect Detection 
Various characterizations of emotion are used in 
emotion theories. The OCC model uses emotion 
labels (anger, etc.) and intensity, while Watson 
and Tellegen (1985) use positivity and negativity 
of affect as the major dimensions. Currently, we 
use an evaluation dimension (negative-positive), 
affect labels, and intensity. Affect labels plus 
intensity are used when strong text clues signal-
ling affect are detected, while the evaluation di-
mension plus intensity is used for weak text 
clues. Moreover, our analysis reported here is 
based on the transcripts of previous e-drama ses-
sions. Since even a person?s interpretations of 
affect can be very unreliable, our approach com-
bines various weak relevant affect indicators into 
a stronger and more reliable source of informa-
tion for affect detection. Now we summarize our 
affect detection based on multiple streams of in-
formation. 
2.1 Pre-processing Modules 
The language in the speeches created in e-drama 
sessions severely challenges existing language-
analysis tools if accurate semantic information is 
sought even for the purposes of restricted affect-
detection. The language includes misspellings, 
ungrammaticality, abbreviations (often as in text 
messaging), slang, use of upper case and special 
punctuation (such as repeated exclamation 
marks) for affective emphasis, repetition of 
letters or words also for affective emphasis, and 
open-ended interjective and onomatopoeic 
elements such as ?hm? and ?grrrr?. In the 
examples we have studied, which so far involve 
teenage children improvising around topics such 
as school bullying, the genre is similar to Internet 
chat.  
To deal with the misspellings, abbreviations, 
letter repetitions, interjections and onomatopoeia, 
several types of pre-processing occur before ac-
tual detection of affect. 
A lookup table has been used to deal with ab-
breviations e.g. ?im (I am)?, ?c u (see you)? and 
?l8r (later)?. It includes abbreviations used in 
Internet chat rooms and others found in an analy-
sis of previous edrama sessions. We handle am-
biguity (e.g.,?2? (to, too, two) in ?I?m 2 hungry 2 
walk?) by considering the POS tags of immedi-
ately surrounding words. Such simple processing 
inevitably leads to errors, but in evaluations us-
ing examples in a corpus of 21695 words derived 
from previous transcripts we have obtained 
85.7% accuracy, which is currently adequate. We 
are also considering dealing with abbreviations, 
etc. in a more general way by including them as 
special lexical items in the lexicon of the robust 
parser we are using (see below). 
The iconic use of word length (corresponding 
roughly to imagined sound length) as found both 
in ordinary words with repeated letters (e.g. 
?seeeee?) and in onomatopoeia and interjections, 
(e.g. ?wheee?, ?grr?, ?grrrrrr?, ?agh?, ?aaaggghhh?) 
normally implies strong affective states. We have 
a small dictionary containing base forms of some 
special words (e.g. ?grr?) and some ordinary 
words that often have letters repeated in e-drama. 
Then the Metaphone spelling-correction algo-
rithm (http://aspell.net/metaphone/), which is 
based on pronunciation, works with the diction-
ary to locate the base forms of words with letter 
repetitions.  
Finally, the Levenshtein distance algorithm 
(http://www.merriampark.com/ld.htm) with a 
contemporary English dictionary deals with 
spelling mistakes in users? input.  
2.2 Processing of Imperative Moods 
One useful pointer to affect is the use of impera-
tive mood, especially when used without soften-
ers such as ?please? or ?would you?. Strong emo-
tions and/or rude attitudes are often expressed in 
this case. There are special, common imperative 
phrases we deal with explicitly, such as ?shut 
up? and ?mind your own business?. They usually 
48
indicate strong negative emotions. But the phe-
nomenon is more general. 
Detecting imperatives accurately in general is 
by itself an example of the non-trivial problems 
we face. We have used the syntactic output from 
the Rasp parser (Briscoe & Carroll, 2002) and 
semantic information in the form of the semantic 
profiles for the 1,000 most frequently used Eng-
lish words (Heise, 1965) to deal with certain 
types of imperatives. 
Rasp recognises some types of imperatives di-
rectly. Unfortunately, the grammar of the 2002 
version of the Rasp parser that we have used 
does not deal properly with certain imperatives 
(John Carroll, p.c), which means that examples 
like ?you shut up?, ?Dave bring me the menu?, 
?Matt don?t be so blunt? and ?please leave me 
alone?, are not recognized as imperatives, but as 
normal declarative sentences. Therefore, further 
analysis is needed to detect imperatives, by addi-
tional processing applied to the possibly-
incorrect syntactic trees produced by Rasp.  
If Rasp outputs a subject, ?you?, followed by 
certain verbs (e.g. ?shut?, ?calm?, etc) or certain 
verb phrases (e.g. ?get lost?, ?go away? etc), the 
sentence type will be changed to imperative. 
(Note: in ?you get out? the ?you? could be a 
vocative rather than the subject of ?get?, espe-
cially as punctuation such as commas is often 
omitted in our genre; however these cases are not 
worth distinguishing and we assume that the 
?you? is a subject.) If a softener ?please? is fol-
lowed by the base forms of a verb, then the input 
is taken to be imperative. If a singular proper 
noun is followed by a base form of the verb, then 
this sentence is taken to be an imperative as well 
(e.g. ?Dave get lost?). However, when a subject 
is followed by a verb for which there is no dif-
ference at all between the base form and the past 
tense form, then ambiguity arises between im-
perative and declarative (e.g. ?Lisa hit me?).  
There is an important special case of this am-
biguity. If the object of the verb is ?me?, then in 
order to solve the ambiguity, we have adopted 
the evaluation value of the verb from Heise?s 
(1965) compilation of semantic differential pro-
files. In these profiles, Heise listed values of 
evaluation, activation, potency, distance from 
neutrality, etc. for the 1,000 most frequently used 
English words. In the evaluation dimension, 
positive values imply goodness. Because nor-
mally people tend to use ?a negative verb + me? 
to complain about an unfair fact to the others, if 
the evaluation value is negative for such a verb, 
then this sentence is probably not imperative but 
declarative (e.g. ?Mayid hurt me?). Otherwise, 
other factors implying imperative are checked in 
this sentence, such as exclamation marks and 
capitalizations. If these factors occur, then the 
input is probably an imperative. Otherwise, the 
conversation logs are checked to see if there is 
any question sentence directed toward this 
speaker recently. If there is, then the input is con-
jectured to be declarative.  
There is another type of sentence: ?don?t you + 
base form of verb? that we have started to address. 
Though such a sentence is often interrogative, it is 
also often a negative version of an imperative with 
a ?you? subject (e.g. ?Don?t you dare call me a 
dog,? ?Don?t you call me a dog?). Normally Rasp 
regards it as a question sentence. Thus, further 
analysis has also been implemented for such a sen-
tence structure to change its sentence type to im-
perative. Although currently this has limited effect, 
as we only infer a (negative) affective quality 
when the verb is ?dare?, we plan to add semantic 
processing in an attempt to glean affect more gen-
erally from ?Don?t you ?? imperatives. 
2.3 Affect Detection by Pattern Matching 
In an initial stage of our work, affect detection 
was based purely on textual pattern-matching 
rules that looked for simple grammatical patterns 
or templates partially involving lists of specific 
alternative words. This continues to be a core 
aspect of our system but we have now added ro-
bust parsing and some semantic analysis. Jess, a 
rule-based Java framework, is used to implement 
the pattern/template-matching rules in EMMA. 
In the textual pattern-matching, particular 
keywords, phrases and fragmented sentences are 
found, but also certain partial sentence structures 
are extracted. This procedure possesses the ro-
bustness and flexibility to accept many ungram-
matical fragmented sentences and to deal with 
the varied positions of sought-after phraseology 
in speeches. However, it lacks other types of 
generality and can be fooled when the phrases 
are suitably embedded as subcomponents of 
other grammatical structures. For example, if the 
input is ?I doubt she?s really angry?, rules look-
ing for anger in a simple way will fail to provide 
the expected results.  
The transcripts analysed to inspire our initial 
knowledge base and pattern-matching rules were 
derived independently from previous edrama 
improvisations based on a school bullying sce-
nario. We have also worked on another, dis-
tinctly different scenario, Crohn?s disease, based 
on a TV programme by another of our industrial 
49
partners (Maverick TV). The rule sets created for 
one scenario have a useful degree of applicability 
to other scenarios, though there will be a few 
changes in the related knowledge database ac-
cording to the nature of specific scenarios.  
The rules, as we mentioned at the beginning of 
this section, conjecture the character?s emotions, 
evaluation dimension (negative or positive), po-
liteness (rude or polite) and what response 
EMMA should make.  
Multiple exclamation marks and capitalisation 
are frequently employed to express emphasis in 
e-drama sessions. If exclamation marks or capi-
talisation are detected in a character?s utterance, 
then the emotion intensity is deemed to be com-
paratively high (and emotion is suggested even 
in the absence of other indicators).  
A reasonably good indicator that an inner state 
is being described is the use of ?I? (see also 
Craggs & Wood (2004)), especially in combina-
tion with the present or future tense. In the 
school-bullying scenario, when ?I? is followed by 
a future-tense verb the affective state ?threaten-
ing? is normally being expressed; and the utter-
ance is usually the shortened version of an im-
plied conditional, e.g., ?I?ll scream [if you stay 
here].? Note that when ?I? is followed by a pre-
sent-tense verb, a variety of other emotional 
states tend to be expressed, e.g. ?I want my 
mum? (fear) and ?I hate you? (dislike), I like you 
(liking). Further analysis of first-person, present-
tense cases is provided in the following section.  
2.4 Going Beyond Pattern Matching 
In order to go beyond the limitations of simple 
pattern matching, sentence type information ob-
tained from the Rasp parser has also been 
adopted in the pattern-matching rules. The gen-
eral sentence structure information not only helps 
EMMA to detect affective states in the user?s 
input (see the above discussion of imperatives), 
and to decide if the detected affective states 
should be counted, but also helps EMMA to 
make appropriate responses. Rasp will inform 
the pattern-matching rule with sentence type in-
formation. If the current input is a conditional or 
question sentence with affective keywords or 
structures in, then the affective states won?t be 
valued. For example, if the input is ?I like the 
place when it is quiet?, Rasp works out its sen-
tence type: a conditional sentence and the rule 
for structures containing ?like? with a normal 
declarative sentence label won?t be activated. 
Instead, the rule for the keyword ?when? with a 
conditional sentence type label will be fired. Thus 
an appropriate response will be obtained. 
Additionally, as we discussed in section 2.2, we 
use Rasp to indicate imperative sentences, such as 
when Mayid (the bully) said ?Lisa, don?t tell Miss 
about it?. The pseudo-code example rule for such 
input is as follows:  
(defrule example_rule 
?fact <- (any string containing negation and the 
sentence type is ?imperative?)  => 
(obtain affect and response from knowledge da-
tabase) 
Thus the declarative input such as ?I won?t tell 
Miss about it? won?t be able to activate the exam-
ple rule due to different sentence type information. 
Especially, we have assigned a special sentence 
type label (?imp+please?) for imperatives with sof-
tener ?please?. Only using this special sentence 
type label itself in the pattern-matching rule helps 
us effortlessly to obtain the user?s linguistic style 
(?polite?) and probably a polite response from 
EMMA as well according to different roles in spe-
cific scenarios.  
Aside from using the Rasp parser, we have also 
worked on implementing simple types of semantic 
extraction of affect using affect dictionaries and 
electronic thesauri, such as WordNet. The way we 
are currently using WordNet is briefly as follows. 
2.5 Using WordNet for a First Person Case 
As we mentioned earlier, use of the first-person 
with a present-tense verb tends to express an affec-
tive state in the speaker, especially in discourse in 
which affect is salient, as is the case in scenarios 
such as School Bullying and Crohn?s Disease. We 
have used the Rasp parser to detect such a sen-
tence. First of all, such user?s input is sent to the 
pattern-matching rules in order to obtain the 
speaker?s current affective state and EMMA?s re-
sponse to the user. If there is no rule fired (i.e. we 
don?t obtain any information of the speaker?s af-
fective state and EMMA?s response from the pat-
tern-matching rules), further processing is applied. 
We use WordNet to track down the rough syno-
nyms of the verb (possibly from different Word-
Net ?synsets?) in the verb phrase of the input sen-
tence, in order to allow a higher degree of general-
ity than would be achieved just with the use of our 
pattern-matching rules. In order to find the closest 
synonyms to the verb in different synsets, the se-
mantic profiles of the 1,000 most frequently used 
English words (Heise, 1965) have been employed, 
especially to find the evaluation values of every 
synonym of the original verb. We transform posi-
tive and negative evaluation values in Heise?s dic-
50
tionary into binary ?positive? and ?negative? only. 
Thus if any synonym has the same evaluation 
value (?positive? or ?negative?) as that of the origi-
nal verb, then it will be selected as a member of 
the set of closest synonyms. Then, we use one 
closest synonym to replace the original verb in the 
user?s input. This newly built sentence will be sent 
to the pattern-matching rules in order to obtain the 
user?s affective state and EMMA?s response. Such 
processing (using a closest synonym to replace the 
original verb and sending the newly built sentence 
to the pattern-matching rules) continues until we 
obtain the speaker?s affective state and appropriate 
response.  
2.6 Responding Regimes 
EMMA normally responds to, on average, every 
Nth speech by another character in the e-drama 
session, where N is a changeable parameter (cur-
rently set to 3). However, it also responds when 
EMMA?s character?s name is mentioned, and 
makes no response if it cannot detect anything 
useful in the utterance it is responding to. The 
one-in-N average is achieved by sampling a ran-
dom variable every time another character says 
something. As a future development, we plan to 
have N dynamically adjustable according to how 
confident EMMA is about what it has discerned 
in the utterance at hand.  
EMMA sometimes makes a random response 
from several stored response candidates that are 
suitable for the affective quality it has discerned 
in an utterance it is responding to. In addition, 
EMMA sometimes reflects back, in modified 
form, part of the user?s input string as a sub-
component of its response. Notice here that, be-
cause the pre-processing module reported in sec-
tion 2.1 expands abbreviations and corrects mis-
spellings, it helps to obscure the fact that part of 
EMMA?s response is only a reflection. E.g.: 
<Character> I?m ur (your) best m8 (mate). 
<EMMA> Why are you my best mate? 
On the other hand, we also, on a random basis, 
purposely put phenomena such as abbreviations 
and Internet-chat features in EMMA?s responses 
in order to make EMMA express itself more like 
a typical school-student user. E.g.: 
<Character> You get lost!  
<EMMA> Hey, coool it folks. (notice the 
lengthening of ?cool?) 
<Character> He didn?t do it.  
<EMMA> No1 believes you, m8. (where 
?no1? stands for ?no one?) 
It should be borne in mind that EMMA?s re-
sponses are not aimed at engaging with the de-
tailed meaning of the utterance, but simply to 
stimulate the improvisation in a way that is 
somewhat sensitive to affect being expressed. 
Furthermore, in order to make the EMMA char-
acter?s responses push the improvisation for-
ward, the character will not only ask scenario 
related questions to the main characters, but also 
introduce new topics closely related to the sce-
nario in the improvisation. In a recent user-
testing debrief session, secondary school students 
mentioned that the human bit-part character did 
not stay in character and said pointless things, 
while in another session one student, who played 
a main character, believed that the EMMA char-
acter was the only one that stuck to scenario re-
lated topics. The directors reported that, even 
when a main character was silent and the director 
did not intervene very much, the EMMA charac-
ter led the improvisation on the right track by 
raising new topics other characters were con-
cerned about.      
3 Affect via Metaphor 
In the introduction we commented on two func-
tions of metaphor. Metaphor is often used to 
convey affect and it also partly underlies folk 
theories of how affect and emotion work. As an 
example of the latter, folk theories of anger often 
talk about, and appear to conceive of, anger as if 
it were a heated fluid possibly exerting a strong 
pressure on its containing body. This motivates a 
wide range of metaphorical expressions both 
conventional such as ?he was boiling with anger 
and about to blow his top? and more creative 
variants such as ?the temperature in the office 
was getting higher and this had nothing to do 
with where the thermostat was set? (modified, 
slightly from a Google? search). Passion, or 
lack of, is also often described in terms of heat 
and the latter example could in certain contexts 
be used in this manner. So far, examples of ac-
tors reflecting or commenting on the nature of 
their or others emotions, which would require an 
appropriate vocabulary, have been infrequent in 
the e-drama transcripts, although we might ex-
pect to find more examples as more students par-
ticipate in the Crohn?s disease scenario. 
However, such metaphorically motivated folk 
models often directly motivate the terminology 
used to convey affect, as in utterances such as 
?you leave me cold?, which conveys lack of in-
terest or disdain. This use of metaphor to moti-
vate folk models of emotions and, as a conse-
quence, certain forms of direct expression of 
51
emotion has been extensively studied, albeit usu-
ally from a theoretical, linguistic, perspective 
(Fussell & Moss, 1998; K?vecses, 1998).  
Less recognised (although see Barnden et al, 
2004; Wallington et al, 2006) is the fact that 
metaphor is also frequently used to convey emo-
tion more indirectly. Here the metaphor does not 
describe some aspect of an emotional state, but 
something else. Crucially, however, it also con-
veys a negative or positive value judgement 
which is carried over to what is being described 
and this attitude hints at the emotion. For exam-
ple to say of someone?s room that ?it is a cess-
pit? allows the negative evaluation of ?cess-pit? 
to be transferred to ?the room? and we might as-
sume an emotion of disgust. In our transcripts we 
find examples such as ?smelly attitude? and ?you 
buy your clothes at the rag market? (which we 
take to be not literally true). Animal insults such 
as ?you pig? frequently take this form, although 
many are now highly conventionalised. Our 
analysis of e-drama transcripts shows that this 
type of metaphor that conveys affect indirectly is 
much more common than the direct use.  
It should be apparent that even though conven-
tional metaphorical phraseology may well be 
listed in specialised lexicons, approaches to 
metaphor and affect which rely upon a form of 
lexical look-up to determine the meaning of ut-
terances are likely to miss both the creative vari-
ants and extensions of standard metaphors and 
also the quite general carrying over of affectual 
evaluations from the literal meaning of an utter-
ance to the intended metaphorical meaning.  
At the time of writing (early June 2006) little 
in the way of metaphor handling has been incor-
porated into the EMMA affect-detection module. 
However, certain aspects of metaphor handling 
will be incorporated shortly, since they involve 
extensions of existing capabilities. Our intended 
approach is partly to look for stock metaphorical 
phraseology and straightforward variants of it, 
which is the most common form of metaphor in 
most forms of discourse, including e-drama. 
However, we also plan to employ a simple ver-
sion of the more open-ended, reasoning-based 
techniques described in the ATT-Meta project on 
metaphor processing (Barnden et al, 2004; Wal-
lington et al, 2006). 
As a first step, it should be noted that insults 
and swear words are often metaphorical. We are 
currently investigating specialised insult diction-
aries and the machine-readable version of the 
OALD, which indicates slang. 
Calling someone an animal of any sort usually 
conveys affect, but it can be either insulting or 
affectionate. We have noted that calling someone 
the young of an animal is often affectionate, and 
the same is true of diminutive (e.g., ?piglet?) and 
nursery forms (e.g., ?moo cow?), even when the 
adult form of the animal is usually used as an 
insult. Thus calling someone ?a cat? or ?catty? is 
different from describing them as kittenish. 
Likewise, ?you young pup? is different from 
?you dog?. We are constructing a dictionary of 
specific animals used in slang and as insults, but, 
more generally, for animals not listed we can use 
WordNet and electronic dictionaries to determine 
whether or not it is the young or mature form of 
the animal that is being used.  
We have already noted that in metaphor the 
affect associated with a source term will carry 
across to the target by default. EMMA already 
consults Heise?s compilation of semantic differ-
ential profiles for the evaluation value of the 
verb. We will extend the determination of the 
evaluation value to all parts of speech.  
Having the means to determine the emotion 
conveyed by a metaphor is most useful when 
metaphor can be reliably spotted. There are a 
number of means of doing this for some meta-
phors. For example, idioms are often metaphori-
cal (Moon 1988). Thus we can use an existing 
idiom dictionary, adding to it as necessary. This 
will work with fixed idioms, but, as is often 
noted, idioms frequently show some degree of 
variation, either by using synonyms of standard 
lexis, e.g., ?constructing castles in the air? in-
stead of ?building castles in the air?, or by adding 
modifiers, e.g., ?shut your big fat mouth?. This 
variability will pose a challenge if one is looking 
for fixed expressions from an idiom dictionary. 
However, if the idiom dictionary is treated as 
providing base forms, with for example the 
nouns being treated as the head nouns of a noun-
phrase, then the Rasp parser can be used to de-
termine the noun phrase and the modifiers of the 
head noun, and likewise with verbs, verb-
phrases, etc. Indeed, this approach can be ex-
tended beyond highly fixed expressions to other 
cases of metaphor, since as Deignan (2005) has 
noted metaphors tend to display a much greater 
degree of fixedness compared to non-metaphors, 
whilst not being as fixed as what are convention-
ally called idioms. 
There are other ways of detecting metaphors 
which we could utilise. Thus, metaphoricity sig-
nals (as in Goatly, 1997; Wallington et al, 2003) 
signal the use of a metaphor in some cases. Such 
52
signals include phrases such as: so to speak, sort 
of, almost, picture as. Furthermore, semantic 
restriction violations (Wilks, 1978; Fass, 1997; 
Mason, 2004), as in ?my car drinks petrol,? of-
ten indicate metaphor, although not all meta-
phors violate semantic restrictions. To determine 
whether semantic restrictions are being violated, 
domain information from ontologies/thesauri 
such as WordNet could be used and/or statistical 
techniques as used by Mason (2004). 
4 User Testing 
We conducted a two-day pilot user test with 39 
secondary school students in May 2005, in order 
to try out and a refine a testing methodology. The 
aim of the testing was primarily to measure the 
extent to which having EMMA as opposed to a 
person play a character affects users? level of 
enjoyment, sense of engagement, etc. We con-
cealed the fact that EMMA was involved in some 
sessions in order to have a fair test of the differ-
ence that is made. We obtained surprisingly good 
results. Having a minor bit-part character called 
?Dave? played by EMMA as opposed to a person 
made no statistically significant difference to 
measures of user engagement and enjoyment, or 
indeed to user perceptions of the worth of the 
contributions made by the character ?Dave?. Us-
ers did comment in debriefing sessions on some 
utterances of Dave?s, so it was not that there was 
a lack of effect simply because users did not no-
tice Dave at all. Also, the frequencies of human 
?Dave? and EMMA ?Dave? being responded to 
during the improvisation (sentences of Dave?s 
causing a response divided by all sentences said 
by ?Dave?) are both roughly around 30%, again 
suggesting that users notice Dave. Additionally, 
the frequencies of other side-characters being 
responded to are roughly the same as the ?Dave? 
character ? ?Matthew?: around 30% and ?Elise?: 
around 35%.  
Furthermore, it surprised us that no user ap-
peared to realize that sometimes Dave was com-
puter-controlled. We stress, however, that it is 
not an aim of our work to ensure that human ac-
tors do not realize this. More extensive, user test-
ing at several Birmingham secondary schools is 
being conducted at the time of writing this paper, 
now that we have tried out and somewhat modi-
fied the methodology.  
The experimental methodology used in the 
testing is as follows, in outline. Subjects are 14-
16 year old students at local Birmingham 
schools. Forty students are chosen by each 
school for the testing. Four two-hour sessions 
take place at the school, each session involving a 
different set of ten students. In a session, the 
main phases are as follows: an introduction to the 
software; a First Improvisation Phase, where five 
students are involved in a School Bullying im-
provisation and the remaining five in a Crohn?s 
Disease improvisation; a Second Improvisation 
Phase in which this assignment is reversed; fill-
ing out of a questionnaire by the students; and 
finally a group discussion acting as a debrief 
phase. For each improvisation, characters are 
pre-assigned to specific students. Each Improvi-
sation Phase involves some preliminaries fol-
lowed by ten minutes of improvisation proper.  
In half of the SB improvisations and half of 
the CD improvisations, the minor character Dave 
is played by one of the students, and by EMMA 
in the remaining. When EMMA plays Dave, the 
student who would otherwise have played him is 
instructed to sit at another student?s terminal and 
thereby to be an audience member. Students are 
told that we are interested in the experiences of 
audience members as well as of actors. Almost 
without exception students have appeared not to 
have suspected that having an audience member 
results from not having Dave played by another 
student. At the end of one exceptional session 
some students asked whether one of the directors 
from Hi8us was playing Dave.  
Of the two improvisations a given student is 
involved in, exactly one involves EMMA play-
ing Dave. This will be the first session or the sec-
ond. This EMMA-involvement order and the 
order in which the student encounters SB and CD 
are independently counterbalanced across stu-
dents.  
The questionnaire is largely composed of 
questions that are explicitly about students? feel-
ings about the experience (notably enjoyment, 
nervousness, and opinions about the worth of the 
dramatic contributions of the various characters), 
with essentially the same set of questions being 
asked separately about the SB and the CD im-
provisations. The other data collected are: for 
each debrief phase, written minutes and an audio 
and video record; notes taken by two observers 
present during each Improvisation Phase; and 
automatically stored transcripts of the sessions 
themselves, allowing analysis of linguistic forms 
used and types of interactivity. To date only the 
non-narrative questionnaire answers have been 
subjected to statistical analysis, with the sole in-
dependent variable being the involvement or oth-
erwise of EMMA in improvisations. 
53
5 Conclusion and Ongoing Work 
We have implemented a limited degree of affect-
detection in an automated bit-part character in an 
e-drama application, and fielded the actor suc-
cessfully in pilot user-testing. Although there is a 
considerable distance to go in terms of the prac-
tical affect-detection that we plan to implement, 
the already implemented detection is able to 
cause reasonably appropriate contributions by 
the automated character. We also intend to use 
the affect-detection in a module for automatically 
generating director messages to human actors. 
In general, our work contributes to the issue of 
how affect/sentiment detection from language 
can contribute to the development of believable 
responsive AI characters, and thus to a user?s 
feeling of involvement in game playing. More-
over, the development of affect detection and 
sentiment & subjectivity analysis provides a 
good test-bed for the accompanying deeper re-
search into how affect is conveyed linguistically.  
Acknowledgement 
The project is supported by grant RES-328-25-
0009 under the ESRC/EPSRC/DTI ?PACCIT? 
programme, and its metaphor aspects also by 
EPSRC grant EP/C538943/1. We thank our part-
ners?Hi8us, Maverick TV and BT?and col-
leagues W.H. Edmondson, S.R. Glasbey, M.G. 
Lee and Z. Wen.  
References 
Barnden, J.A., Glasbey, S.R., Lee, M.G. & Walling-
ton, A.M. 2004. Varieties and Directions of Inter-
domain Influence in Metaphor. Metaphor and 
Symbol, 19(1), pp.1-30. 
Briscoe, E. & J. Carroll. 2002. Robust Accurate Sta-
tistical Annotation of General Text. In Proceedings 
of the 3rd International Conference on Language 
Resources and Evaluation, Las Palmas, Gran Ca-
naria. pp.1499-1504.  
Craggs, R. & Wood. M. 2004. A Two Dimensional 
Annotation Scheme for Emotion in Dialogue. In 
Proceedings of AAAI Spring Symposium: Explor-
ing Attitude and Affect in Text. 
Deignan , A. 2005. Metaphor and corpus Linguistics. 
John Benjamins. 
Egges, A., Kshirsagar, S. & Magnenat-Thalmann, N. 
2003. A Model for Personality and Emotion Simu-
lation, In Proceedings of Knowledge-Based Intelli-
gent Information & Engineering Systems 
(KES2003), Lecture Notes in AI. Springer-Verlag. 
Fussell, S. & Moss, M. 1998. Figurative Language in 
Descriptions of Emotional States. In S. R. Fussell 
and R. J. Kreuz (Eds.), Social and cognitive ap-
proaches to interpersonal communication. Law-
rence Erlbaum.  
Fass, D. 1997. Processing metaphor and metonymy. 
Greenwich, Connecticut: Ablex 
Goatly, A. 1997. The language of metaphors. 
Routledge London and New York:  
Heise, D. R. 1965. Semantic Differential Profiles for 
1,000 Most Frequent English Words. Psychologi-
cal Monographs 79, pp.1-31. 
K?vecses, Z. 1998. Are There Any Emotion-Specific 
Metaphors? In Speaking of Emotions: Conceptuali-
zation and Expression. Athanasiadou, A. and Ta-
bakowska, E. (eds.), Berlin and New York: Mou-
ton de Gruyter, pp.127-151. 
Mason, Z.J. 2004. CorMet: a computational, corpus-
based conventional metaphor extraction system. 
Computational Linguistics 30:1. pp. 23-44. 
Mateas, M. 2002. Ph.D. Thesis. Interactive Drama, 
Art and Artificial Intelligence. School of Computer 
Science, Carnegie Mellon University. 
Moon, R. 1998. Fixed idioms and expressions in Eng-
lish. Clarendon Press: Oxford, U.K 
Ortony, A., Clore, G.L. & Collins, A. 1988. The Cog-
nitive Structure of Emotions. CUP 
Picard, R.W. 2000. Affective Computing. The MIT 
Press. Cambridge MA. 
Sharoff, S. 2005. How to Handle Lexical Semantics in 
SFL: a Corpus Study of Purposes for Using Size 
Adjectives. Systemic Linguistics and Corpus. Lon-
don: Continuum. 
Watson, D. & Tellegen, A. 1985. Toward a Consen-
sual Structure of Mood. Psychological Bulletin, 98, 
pp.219-235.  
Zhe, X. & Boucouvalas, A. C. 2002. Text-to-Emotion 
Engine for Real Time Internet Communication. In 
Proceedings of International Symposium on Com-
munication Systems, Networks and DSPs, Stafford-
shire University, UK, pp.164-168. 
Wallington, A.M., Barnden, J.A., Barnden, M.A., 
Ferguson, F.J. & Glasbey, S.R. 2003. Metaphoric-
ity Signals: A Corpus-Based Investigation. Techni-
cal Report CSRP-03-5, School of Computer Sci-
ence, The University of Birmingham, U.K. 
Wallington, A.M., Barnden, J.A. Glasbey S.R. and 
Lee M. G. 2006. Metaphorical reasoning with an 
economical set of mappings. Delta, 22:1 
Wilks, Y. (1978). Making preferences more active. 
Artificial Intelligence, 10, pp. 75- 97 
54
