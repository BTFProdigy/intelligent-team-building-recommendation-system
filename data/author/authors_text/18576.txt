Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1574?1583,
Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational Linguistics
A Convex Alternative to IBM Model 2
Andrei Simion
Columbia University
IEOR Department
New York, NY, 10027
aas2148@columbia.edu
Michael Collins
Columbia University
Computer Science
New York, NY, 10027
mc3354@columbia.edu
Clifford Stein
Columbia University
IEOR Department
New York, NY, 10027
cs2035@columbia.edu
Abstract
The IBM translation models have been hugely
influential in statistical machine translation;
they are the basis of the alignment models
used in modern translation systems. Exclud-
ing IBM Model 1, the IBM translation mod-
els, and practically all variants proposed in the
literature, have relied on the optimization of
likelihood functions or similar functions that
are non-convex, and hence have multiple lo-
cal optima. In this paper we introduce a con-
vex relaxation of IBM Model 2, and describe
an optimization algorithm for the relaxation
based on a subgradient method combined
with exponentiated-gradient updates. Our ap-
proach gives the same level of alignment ac-
curacy as IBM Model 2.
1 Introduction
The IBM translation models (Brown et al, 1993)
have been tremendously important in statistical ma-
chine translation (SMT). The IBM models were the
first generation of SMT systems; in recent work,
they play a central role in deriving alignments used
within many modern SMT approaches, for exam-
ple phrase-based translation models (Koehn, 2008)
and syntax-based translation systems (e.g., (Chi-
ang, 2005; Marcu et al, 2006)). Since the origi-
nal IBM paper, there has been a large amount of re-
search exploring the original IBM models and mod-
ern variants (e.g., (Moore, 2004; Liang et al, 2006;
Toutanova and Galley, 2011; Riley and Gildea,
2012; Vogel et al, 1996)).
Excluding IBM Model 1, the IBM translation
models, and practically all variants proposed in the
literature, have relied on the optimization of like-
lihood functions or similar functions that are non-
convex. Unfortunately, non-convex objective func-
tions have multiple local optima, and finding a
global optimum of a non-convex function is typi-
cally a computationally intractible problem. Typi-
cally, an EM algorithm is used, which often runs in
a reasonable amount of time, but with no guarantees
of finding a global optima (or for that matter, even a
near-optimal solution).
In this paper we make the following contributions:
? We introduce a convex relaxation of IBM
Model 2. At a very high level, the relaxation
is derived by replacing the product t(fj |ei) ?
d(i|j) with a relaxation that is commonly used
in the linear programming literature (e.g., see
(Bertsimas, 1997; Bertsimas and Tsitsiklis,
1997; Martins et al, 2010)). (Here t(f |e) are
the translation parameters of the model, and
d(i|j) are the distortion parameters; the prod-
uct is non-linear, effectively introducing non-
convexity into the problem.)
? We describe an optimization algorithm for
the relaxed objective, based on a combina-
tion of stochastic subgradient methods with the
exponentiated-gradient (EG) algorithm (Kivi-
nen and Warmuth, 1997; Beck and Teboulle,
2003).
? We describe experiments with the method on
standard alignment datasets, showing that the
EG algorithm converges in only a few passes
over the data, and that our method achieves ac-
curacies that are very similar to those of IBM
Model 2.
Framing the unsupervised learning of alignment
models as a convex optimization problem, with
guaranteed convergence to a global optimum, has
several clear advantages. First, the method is eas-
ier to analyze, as the objective function is being
truly maximized. Second, there is no need for ini-
tialization heuristics with the approach, given that
the method will always converge to a global op-
timum. Finally, we expect that our convexity-
based approach may facilitate the further develop-
ment of more convex models. There has been a rich
1574
interplay between convex and non-convex meth-
ods in machine learning: as one example consider
the literature on classification problems, with early
work on the perceptron (linear/convex), then work
on neural networks with back-propagation (non-
linear/non-convex), then the introduction of support
vector machines (non-linear/convex), and finally re-
cent work on deep belief networks (non-linear/non-
convex). In view of these developments, the lack
of convex methods in translation alignment models
has been noticeable, and we hope that our work will
open up new directions and lead to further progress
in this area.
Notation. Throughout this paper, for any integer
N , we use [N ] to denote {1 . . . N} and [N ]0 to de-
note {0 . . . N}.
2 Related Work
(Brown et al, 1993) introduced IBM Models 1
through 5, and optimization methods for these mod-
els based on the EM algorithm. While the models
were originally introduced for full translation, they
are now mainly used to derive alignments which are
then used by phrase-based and other modern SMT
systems. Since the original IBM models were in-
troduced, many variants have been introduced in the
literature. (Vogel et al, 1996) introduced a model,
sometimes referred to as IBM 2.5, which uses a pa-
rameterization that is similar to a hidden Markov
model, and which allows the value of each alignment
variable to be conditioned on a previous alignment
variable. (Liang et al, 2006) describe a method that
explicitly incorporates agreement preferences dur-
ing training. (Och and Ney, 2003) give a systematic
comparison of several alignment models in the liter-
ature. (Moore, 2004) gives a detailed study of IBM
Model 1, showing various steps that can be used to
improve its performance. (Ganchev et al, 2010)
describes a method based on posterior regulariza-
tion that incorporates additional constraints within
the EM algorithm for estimation of IBM models.
All of these approaches are unsupervised, in that
they do not require labeled alignment data; however
several authors have considered supervised models
(e.g., see (Lacoste-Julien et al, 2006; Taskar et al,
2005; Haghighi et al, 2009)). The focus of the cur-
rent paper is on unsupervised learning; the unsuper-
vised variants described above all make use of non-
convex objective functions during training, with the
usual problems with multiple local maxima.
3 The IBM Model 1 and Model 2
Optimization Problems
In this section we give a brief review of IBM Models
1 and 2, and the optimization problems arising from
these models. The standard approach for optimiza-
tion within these models is the EM algorithm.
Throughout this section, and the remainder of the
paper, we assume that our set of training examples
is (e(k), f (k)) for k = 1 . . . n, where e(k) is the k?th
English sentence and f (k) is the k?th French sen-
tence. Following standard convention, we assume
the task is to translate from French (the ?source?
language) into English (the ?target? language). We
use E to denote the English vocabulary (set of pos-
sible English words), and F to denote the French
vocabulary. The k?th English sentence is a sequence
of words e(k)1 . . . e
(k)
lk
where lk is the length of the
k?th English sentence, and each e(k)i ? E; similarly
the k?th French sentence is a sequence f (k)1 . . . f
(k)
mk
where each f (k)j ? F . We define e
(k)
0 for k = 1 . . . n
to be a special NULL word (note that E contains the
NULL word). Finally, we define L = maxnk=1 lk
and M = maxnk=1mk.
For each English word e ? E, we will assume
that D(e) is a dictionary specifying the set of possi-
ble French words that can be translations of e. The
set D(e) is a subset of F . In practice, D(e) can be
derived in various ways; in our experiments we sim-
ply define D(e) to include all French words f such
that e and f are seen in a translation pair.
Given these definitions, the IBM model 2 opti-
mization problem is given in Figure 1. The parame-
ters in this problem are t(f |e) and d(i|j). The t(f |e)
parameters are translation parameters specifying the
probability of English word e being translated as
French word f . The distortion parameters d(i|j)
specify the probability of the j?th French word in a
sentence being aligned to the i?th English word. We
use a variant of IBM Model 2 where the distortion
variables are shared across all sentence lengths (sim-
ilar variants have been used in (Liang et al, 2006)
and (Koehn, 2008)). The objective function is then
1575
Input: DefineE, F , L,M , (e(k), f (k), lk,mk) for
k = 1 . . . n, D(e) for e ? E as in Section 3.
Parameters:
? A parameter t(f |e) for each e ? E, f ? D(e).
? A parameter d(i|j) for each i ? [L]0, j ? [M ].
Constraints:
?e ? E, f ? D(e), t(f |e) ? 0 (1)
?e ? E,
?
f?D(e)
t(f |e) = 1 (2)
?i ? [L]0, j ? [M ], d(i|j) ? 0 (3)
?j ? [M ],
?
i?[L]0
d(i|j) = 1 (4)
Objective: Maximize
1
n
n?
k=1
mk?
j=1
log
lk?
i=0
t(f (k)j |e
(k)
i )d(i|j) (5)
with respect to the t(f |e) and d(i|j) parameters.
Figure 1: The IBM Model 2 Optimization Problem.
the log-likelihood of the training data (see Eq. 5):
1
n
n?
k=1
mk?
j=1
log p(f (k)j |e
(k)) ,
where
p(f (k)j |e
(k)) =
lk?
i=0
t(f (k)j |e
(k)
i )d(i|j) .
Crucially, while the constraints in the IBM Model
2 optimization problem are linear, the objective
function in Eq. 5 is non-convex. Therefore, opti-
mization methods for IBM Model 2, in particular
the EM algorithm, are typically only guaranteed to
reach a local maximum of the objective function.
For completeness, Figure 2 shows the optimiza-
tion problem for IBM Model 1. In IBM Model 1
the distortion parameters d(i|j) are all fixed to be
the uniform distribution (i.e., 1/(L + 1)). The ob-
jective function for IBM Model 1 is actually convex,
so the EM algorithm will converge to a global max-
imum. However IBM Model 1 is much weaker than
model 2, and typically gives far worse performance.
Input: DefineE, F , L,M , (e(k), f (k), lk,mk) for
k = 1 . . . n, D(e) for e ? E as in Section 3.
Parameters:
? A parameter t(f |e) for each e ? E, f ? D(e).
Constraints:
?e ? E, f ? D(e), t(f |e) ? 0 (6)
?e ? E,
?
f?D(e)
t(f |e) = 1 (7)
Objective: Maximize
1
n
n?
k=1
mk?
j=1
log
lk?
i=0
t(f (k)j |e
(k)
i )
(L+ 1)
(8)
with respect to the t(f |e) parameters.
Figure 2: The IBM Model 1 Optimization Problem.
A common heuristic is to initialize the t(f |e) param-
eters in EM optimization of IBM Model 2 using the
output from IBM Model 1. The intuition behind this
heuristic is that the IBM Model 1 values for t(f |e)
will be a reasonable starting point, and the EM al-
gorithm will climb to a ?good? local optimum. We
are not aware of any guarantees for this initialization
heuristic, however.
4 A Convex Relaxation of IBM Model 2
We now introduce a convex optimization problem,
the I2CR (IBM 2 Convex Relaxation) problem.
As its name suggests, this optimization problem is
closely related to IBM Model 2, but is convex. Be-
cause of this it will be relatively easy to derive an op-
timization algorithm that is guaranteed to converge
to a global optimum. Our experiments show that
the relaxation gives very similar performance to the
original IBM 2 optimization problem, as described
in the previous section.
We first describe an optimization problem,
I2CR-1, that illustrates the basic idea behind the
convex relaxation. We then describe a refined re-
laxation, I2CR-2, that introduces a couple of modi-
fications, and which performs well in experiments.
1576
Input: DefineE, F , L,M , (e(k), f (k), lk,mk) for
k = 1 . . . n, D(e) for e ? E as in Section 3.
Parameters:
? A parameter t(f |e) for each e ? E, f ? D(e).
? A parameter d(i|j) for each i ? [L]0, j ? [M ].
?A parameter q(i, j, k) for each k ? [n], i ? [lk]0,
j ? [mk].
Constraints:
?e ? E, f ? D(e), t(f |e) ? 0 (9)
?e ? E,
?
f?D(e)
t(f |e) = 1 (10)
?i ? [L]0, j ? [M ], d(i|j) ? 0 (11)
?j ? [M ],
?
i?[L]0
d(i|j) = 1 (12)
?i, j, k, q(i, j, k) ? 0 (13)
?i, j, k, q(i, j, k) ? d(i|j) (14)
?i, j, k, q(i, j, k) ? t(f (k)j |e
(k)
i ) (15)
Objective: Maximize
1
n
n?
k=1
mk?
j=1
log
lk?
i=0
q(i, j, k) (16)
with respect to the q(i, j, k), t(f |e) and d(i|j) pa-
rameters.
Figure 3: The I2CR-1 (IBM 2 Convex Relaxation) Prob-
lem, version 1.
4.1 The I2CR-1 Problem
The I2CR-1 problem is shown in Figure 3. A first
key idea is to introduce a new variable q(i, j, k) for
each k ? [n], i ? [lk]0, j ? [mk]: that is, a new
variable for each triple (i, j, k) specifying a sen-
tence pair, and a specific English and French posi-
tion in that sentence. Each q variable must satisfy
the constraints in Eqs. 13-15, repeated here for con-
venience:
?i, j, k, q(i, j, k) ? 0 ,
?i, j, k, q(i, j, k) ? d(i|j) ,
?i, j, k, q(i, j, k) ? t(f (k)j |e
(k)
i ) .
The objective function is
1
n
n?
k=1
mk?
j=1
log
lk?
i=0
q(i, j, k)
which is similar to the objective function in Figure 1,
but where t(f (k)j |e
(k)
i )?d(i|j) has been replaced by
q(i, j, k). The intuition behind the new problem is as
follows. If, instead of the constraints in Eqs. 13-15,
we had the constraint
q(i, j, k) = t(f (k)j |e
(k)
i )? d(i|j) , (17)
then the I2CR-1 problem would clearly be identi-
cal to the IBM Model 2 optimization problem. We
have used a standard relaxation of the non-linear
constraint x = y ? z where x, y, z are all variables
in the range [0, 1], namely
x ? y ,
x ? z ,
x ? y + z ? 1 .
These inequalites are a relaxation in the sense that
any (x, y, z) triple that satisfies x = y ? z also sat-
isfies these constraints. Applying this relaxation to
Eq. 17 gives
q(i, j, k) ? t(f (k)j |e
(k)
i ) ,
q(i, j, k) ? d(i|j) ,
q(i, j, k) ? t(f (k)j |e
(k)
i ) + d(i|j)? 1 . (18)
The final thing to note is that the constraint in
Eq. 18 can be omitted in the I2CR-1 problem. This
is because the task is to maximize the objective
with respect to the q variables and the objective
is strictly increasing as the q values increase?thus
lower bounds on their values are redundant in the
I2CR-1 problem.
It is easily verified that the constraints in the
I2CR-1 problem are linear, and that the objective
function is convex. In Section 5 of this paper we
describe an optimization method for the problem.
Note that because the objective function is being
maximized, and the objective increases monotoni-
cally as the q values increase, at the global optimum1
1More precisely, at any global optimum: the objective func-
tion may not be strictly convex, in which case there will be mul-
tiple global optima.
1577
Input: Same as in I2CR-1 (Figure 4).
Parameters: Same as in I2CR-1 (Figure 4).
Constraints: Same as in I2CR-1 (Figure 4).
Objective: Maximize
1
2n
n?
k=1
mk?
j=1
log?
lk?
i=0
q(i, j, k)
+
1
2n
n?
k=1
mk?
j=1
log?
lk?
i=0
t(f (k)j |e
(k)
i )
(L+ 1)
with respect to the q(i, j, k), t(f |e) and d(i|j) pa-
rameters.
Figure 4: The I2CR-2 (IBM 2 Convex Relaxation) Prob-
lem, version 2. The problem is identical to the I2CR-1
problem, but it also includes a term in the objective func-
tion that is identical to the IBM Model 1 objective. We
define log?(z) = log(z + ?) where ? is a small positive
constant.
we have
q(i, j, k) = min{t(f (k)j |e
(k)
i ), d(i|j)} ,
where min{x, y} returns the minimum of the two
values x and y. Thus, we could actually eliminate
the q variables and write an optimization problem
that is identical to the IBM Model 2 optimization
problem, but with the objective function
1
n
n?
k=1
mk?
j=1
log
lk?
i=0
min{t(f (k)j |e
(k)
i ), d(i|j)} .
It will turn out that both views of the I2CR-1
problem?with and without the q variables?are
helpful, so we have included both in this paper.
4.2 The I2CR-2 Problem
Figure 4 shows the refined optimization problem,
which we call I2CR-2. The problem incorporates
two modifications. First, we modify the objective
function to be
1
2n
n?
k=1
mk?
j=1
log?
lk?
i=0
q(i, j, k)
+
1
2n
n?
k=1
mk?
j=1
log?
lk?
i=0
t(f (k)j |e
(k)
i )
(L+ 1)
.
Thus the objective function includes a second term
that is identical to the objective function for IBM
Model 1 (see Figure 2). In preliminary experiments
with the I2CR-1 optimization problem, we found
that the I2CR-1 objective was not sufficiently depen-
dent on the t parameters: intuitively, if the d param-
eters achieve the min on many training examples,
the values for the t variables become unimportant.
The addition of the IBM Model 1 objective fixed this
problem by introducing a term that depends on the t
values alone.
Second, we replace log by log?, where log?(z) =
log(z + ?), and ? is a small positive constant (in
our experiments we used ? = 0.001). Under this
definition the derivatives of log? are upper-bounded
by 1/?, in contrast to log, where the derivatives
can diverge to infinity. The optimization methods
we use are gradient-based methods (or more pre-
cisely, subgradient-based methods), and we have
found them to be considerably more stable when the
values for gradients do not diverge to infinity.
The modified objective remains convex.
5 A Stochastic Exponentiated-Gradient
Algorithm for Optimization
We now describe an algorithm for optimizing the
I2CR-2 problem in Figure 4. The algorithm is
closely related to stochastic gradient ascent, but with
two modifications:
? First, because the t(f |e) and d(i|j) parame-
ters have simplex constraints (see Figure 1),
we use exponentiated gradient (EG) updates.
EG algorithms are gradient-based methods that
maintain simplex constraints; see for exam-
ple: (Kivinen and Warmuth, 1997; Beck and
Teboulle, 2003; Collins et al, 2008).
? Second, the objective function in the I2CR-
2 problem is convex, but is not differentiable
(the gradient may not exist at all points). For
this reason we use subgradients in the place of
gradients. In spite of the non-differentiability
of the objective function, subgradient meth-
ods still have strong convergence guarantees
when combined with EG updates (e.g., the con-
vergence proofs in (Beck and Teboulle, 2003)
1578
go through with minor modifications; see also
(Bertsekas, 1999)).
To derive the updates, recall that we are maximiz-
ing the following objective function:
h(t, d)
=
1
2|T |
?
k?T
mk?
j=1
log?
lk?
i=0
min
{
t(f (k)j |e
(k)
i ), d(i|j)
}
+
1
2|T |
?
k?T
mk?
j=1
log?
lk?
i=0
t(f (k)j |e
(k)
i )
(L+ 1)
. (19)
Here we use T to denote the set {1 . . . n}; we will
see shortly why this notation is convenient. We use
t and d to refer to the full set of t and d parameters
respectively; h(t, d) is the function to be maximized.
Recall that log?(z) = log(z + ?) where ? is a small
positive parameter.
Given a concave function f(x) where x ? Rd, a
subgradient of f(x) at x is any vector g(x) ? Rd
such that for any y ? Rd,
f(y) ? f(x) + g(x) ? (y ? x) ,
where u?v is the inner product between vectors u and
v. Subgradients are similar to gradients for differ-
entiable concave functions, in that gradients satisfy
the above property. Subgradients can be used in the
place of gradients in many optimization algorithms
(see for example (Bertsekas, 1999)).
The subgradients for the objective function in
Eq. 19 take a simple form. First, define
R(j, k) = ?+
lk?
i=0
t(f (k)j |e
(k)
i ) ,
Q(j, k) = ?+
lk?
i=0
min{t(f (k)j |e
(k)
i ), d(i|j)} ,
and
I(i, j, k) =
{
1 if t(f (k)j |e
(k)
i ) ? d(i|j)
0 otherwise .
Then the subgradients2 are
?t(f |e) =
1
2|T |
?
i,j,k:
f
(k)
j =f
e(k)i =e
(
1
R(j, k)
+
I(i, j, k)
Q(j, k)
)
2We set ?t(f |e) and ?d(i|j) as the subgradients for the
objective function in Eq. 19 with respect to t(f |e) and d(i|j)
respectively.
and
?d(i|j) =
1
2|T |
?
k:i?lk,j?mk
1? I(i, j, k)
Q(j, k)
.
Exponentiated-gradient updates then take the fol-
lowing form:
t(f |e)?
t(f |e)? exp{? ??t(f |e)}
?
f t(f |e)? exp{? ??t(f |e)}
(20)
and
d(i|j)?
d(i|j)? exp{? ??d(i|j)}
?
i d(i|j)? exp{? ??d(i|j)}
, (21)
where ? > 0 is a constant step size in the algorithm.
Note that the EG updates make use of subgradients,
but maintain the simplex constraints on the t and d
variables.
The method just described is a batch gradient
method, where the entire training set T = {1 . . . n}
is used to derive the subgradients before the updates
in Eqs. 20 and 21 are made. Many results in ma-
chine learning and NLP have shown that stochastic
gradient methods, where a subset of the training ex-
amples is used before each gradient-based update,
can converge much more quickly than batch gradi-
ent methods. In our notation, this simply involves
replacing T by some subset T ? of the training exam-
ples in the above definitions, where |T ?| is typically
much smaller than |T |.
Figure 5 shows our final algorithm, a stochastic
version of the exponentiated-gradient method. The
method takes S passes over the data. For each pass,
it randomly partitions the training set into mini-
batches T1 . . . TK of size B, where B is an integer
specifying the size of each mini-batch (in our exper-
iments we used B = 125 or B = 250). The al-
gorithm then performs EG updates using each mini-
batch T1 . . . TK in turn. As can be seen in Table 3,
our experiments show that the algorithm makes very
significant progress in the first pass over the data,
and takes very few iterations to converge to a good
solution even though we initialized with uniform pa-
rameter values.
6 Experiments
In this section we describe experiments using the
I2CR-2 optimization problem combined with the
1579
1: Input: Define E, F , L, M , (e(k), f (k), lk,mk)
for k = 1 . . . n, D(e) for e ? E as in Section 3.
An integer B specifying the batch size. An inte-
ger S specifying the number of passes over the
data. A step size ? > 0. A parameter ? > 0
used in the definition of log? .
2: Parameters:
?A parameter t(f |e) for each e ? E, f ? D(e).
?A parameter d(i|j) for each i ? [L]0, j ? [M ].
3: Definitions:
R(j, k) = ?+
lk?
i=0
t(f (k)j |e
(k)
i )
Q(j, k) = ?+
lk?
i=0
min{t(f (k)j |e
(k)
i ), d(i|j)}
4: Initialization:
? ?e ? E, f ? D(e), t(f |e) = 1/|D(e)|
? ?j ? [M ], i ? [L]0, d(i|j) = 1/(L+ 1)
5: Algorithm:
6: for all s = 1 to S do
7: Randomly partition [n] into subsets T1 . . . TK of
size B where K = n/B.
8: for all b = 1 to K do
9: ?e ? E, f ? D(e), ?(e, f) = 0
10: ?j ? [M ], i ? [L]0, ?(i, j) = 0
11: for all k ? Tb do
12: for all j = 1 to mk do
13: for all i = 0 to lk do
14: ?(e(k)i , f
(k)
j ) += 1/(2R(j, k))
15: if t(f (k)j |e
(k)
i ) ? d(i|j) then
16: ?(e(k)i , f
(k)
j ) += 1/(2Q(j, k))
17: else
18: ?(i, j) += 1/(2Q(j, k))
19: ?e, f, t(f |e) = t(f |e) exp (? ? ?(e, f)/B)
20: ?i, j, d(i|j) = d(i|j) exp (? ? ?(i, j)/B)
21: Renormalize t and d parameters to satisfy
?
f t(f |e) = 1 and
?
i d(i|j) = 1.
22: Output: t and d parameters.
Figure 5: The stochastic exponentiated-gradient algo-
rithm for optimization of I2CR-2.
stochastic EG algorithm for parameter estimation.
We first describe the data sets we use, and then de-
scribe experiments with the method, comparing our
approach to results from IBM Model 2. We com-
pare the various algorithms in terms of their accu-
racy in recovering alignments, using metrics such as
F-measure and AER.
6.1 Data Sets
We use data from the bilingual word alignment
workshop held at HLT-NAACL 2003 (Michalcea
and Pederson, 2003). As a first dataset, we use the
Canadian Hansards bilingual corpus, with 247,878
English-French sentence pairs as training data, 37
sentences of development data, and 447 sentences
of test data (note that we use a randomly chosen
subset of the original training set of 1.1 million sen-
tences, similar to the setting used in (Moore, 2004)).
The development and test data have been manually
aligned at the word level, annotating alignments be-
tween source and target words in the corpus as ei-
ther ?sure? (S) or ?possible? (P ) alignments, as de-
scribed in (Och and Ney, 2003).
As a second data set, we used the Romanian-
English data from the HLT-NAACL 2003 workshop.
This consisted of a training set of 48,706 Romanian-
English sentence-pairs, a development set of 17 sen-
tence pairs, and a test set of 248 sentence pairs.
6.2 Methodology
For each of the models?IBM Model 1, IBM Model
2, and I2CR-2?we follow convention in applying
the following methodology: first, we estimate the
t and d parameters using models in both source-
target and target-source directions; second, we find
the most likely alignment for each development or
test data sentence in each direction; third, we take
the intersection of the two alignments as the final
output from the model.
For the EG algorithm we use a batch size B =
250 and step size ? = 0.5 on the Hansards data, and
B = 125 and ? = 0.5 for the Romanian-English
data.
We report the performance of the models in terms
of Precision, Recall, AER, and F-Measure as defined
by (Och and Ney, 2003). If A is the set of align-
ments produced by an algorithm, S is the set of sure
alignments as annotated in test data, and P is the
set of possible alignments, then these quantities are
defined as
Recall =
|A ? S|
|S|
,
1580
Precision =
|A ? S|
|A|
,
AER = 1?
|A ? S|+ |A ? P |
|A|+ |S|
,
F-Measure =
1
.5
Recall +
.5
Precision
.
Note that we report results in both AER and
F-measure; however there is evidence (Fraser and
Marcu, 2004) that F-measure is better correlated
with translation quality when the alignments are
used in a full system.
In training IBM Model 1 we follow (Moore,
2004) in running EM for 15 iterations. In training
IBM Model 2 we first train IBM Model 1 for 15
iterations to initialize the t parameters, then train
IBM Model 2 for a further 10 iterations. For the
EG algorithm, we use 10 iterations over the training
data for the Hansards data, and 15 iterations on the
Romanian-English data (on the latter dataset results
on the trial data showed that the method took slightly
longer to converge). We report F-measure and AER
results for each of the iterations under the IBM
Model 2 and I2CR-2 models. See Table 1 for the re-
sults on the Hansards data, and Table 2 for the results
on the English-Romanian dataset. It can be seen that
both I2CR-2 and IBM Model 2 converge to a fairly
stable result after 2-3 iterations. The two models
give very similar levels of performance, for example
after 10 iterations on the Hansard data IBM Model
2 gives 14.22 AER and 0.7516 F-Measure versus
14.60 AER and 0.7506 F-Measure for I2CR-2.
On the right, Table 3 shows the values of the ob-
jective function at each iteration when using the EG
algorithm to optimize the I2CR-2 objective. The
method makes a large amount of progress on the first
iteration and then continues to improve. Finally, we
note that the memory requirements for I2CR-2 and
IBM2 are about the same, but that the time for one
iteration of I2CR-2 on the Hansards data is approxi-
mately one hour, while the time for one iteration of
IBM2 was approximately 10 minutes.
7 Conclusions and Future Work
We have introduced the first convex model for un-
supervised learning of alignments in statistical ma-
chine translation with performance comparable to
Iteration IBM2 I2CR-2 IBM2 I2CR-2
AER AER F-Measure F-Measure
Test Set Statistics
1 0.1491 0.1556 0.7530 0.7369
2 0.1477 0.1489 0.7519 0.7456
3 0.1451 0.1476 0.7527 0.7467
4 0.1426 0.1488 0.7536 0.7449
5 0.1422 0.1495 0.7535 0.7472
6 0.1431 0.1476 0.7511 0.7478
7 0.1434 0.1506 0.7506 0.7456
8 0.1437 0.1495 0.7501 0.7470
9 0.1434 0.1494 0.7501 0.7468
10 0.1422 0.1460 0.7516 0.7506
Development Set Statistics
1 0.1871 0.1971 0.6823 .6676
2 0.1896 0.1760 0.6758 .6827
3 0.1964 0.1860 0.6648 .6739
4 0.1912 0.1835 0.6713 .6775
5 0.1884 0.1813 0.6740 .06773
6 0.1836 0.1851 0.6767 0.6811
7 0.1831 0.1806 0.6749 0.6765
8 0.1842 0.1843 0.6739 0.6775
9 0.1864 0.1928 0.6694 0.6640
10 0.1845 0.1829 0.6703 .6721
Table 1: Results on the Hansards data for IBM Model 2
and the I2CR-2 method.
Iteration IBM2 I2CR-2 IBM2 I2CR-2
AER AER F-Measure F-Measure
Test Set Statistics
1 0.4041 0.5354 0.5959 0.4646
2 0.4010 0.4764 0.5990 0.5256
3 0.4020 0.4543 0.5980 0.5457
4 0.4012 0.4384 0.5988 0.5617
5 0.4003 0.4277 0.5997 0.5723
6 0.3990 0.4266 0.6010 0.5834
7 0.4000 0.4162 0.6000 0.5838
8 0.4023 0.4114 0.5977 0.5886
9 0.4022 0.4081 0.5978 0.5919
10 0.4027 0.4043 0.5973 0.5957
11 0.4031 0.4040 0.5969 0.5960
12 0.4042 0.4027 0.5958 0.5973
13 0.4043 0.4021 0.5957 0.5979
14 0.4062 0.4007 0.5938 0.5993
15 0.4057 0.4014 0.5943 0.5986
Development Set Statistics
1 0.4074 0.5841 0.5926 0.4159
2 0.3911 0.4938 0.6089 0.5062
3 0.3888 0.4673 0.6112 0.5327
4 0.3904 0.4596 0.6096 0.5404
5 0.3881 0.4463 0.6119 0.5537
6 0.3904 0.4306 0.6096 0.5694
7 0.3936 0.4175 0.6094 0.5826
8 0.3897 0.4060 0.6103 0.5940
9 0.3961 0.4014 0.6039 0.5986
10 0.3970 0.4072 0.6030 0.5928
11 0.4018 0.3956 0.5982 0.6044
12 0.4035 0.3931 0.5965 0.6069
13 0.4035 0.3862 0.5965 0.6138
14 0.4014 0.3908 0.5986 0.6092
15 0.4063 0.3858 0.5937 0.6142
Table 2: Results on the English-Romanian data for IBM
Model 2 and the I2CR-2 method.
1581
Iteration EF Objective FE Objective
0 -99.6053 -79.5566
1 -32.4528 -27.4925
2 -31.1641 -26.262
3 -30.6311 -25.7093
4 -30.3367 -25.3714
5 -30.1428 -25.1456
6 -30.0000 -24.992
7 -29.8736 -24.8605
8 -29.8093 -24.7551
9 -29.7326 -24.684
10 -29.6771 -24.6099
Table 3: Objective values for the EG algorithm opti-
mization of I2CR-2 at each iteration. ?EF Objective?
corresponds to training a model with t(e|f) parameters,
?FE Objective? corresponds to the reverse direction, with
t(f |e) parameters. Iteration 0 corresponds to the objec-
tive value under the initial, uniform parameter values.
the commonly-used IBM Model 2. We believe
that introducing convexity without sacrificing per-
formance will open the door to further improve-
ments in this area. Future work will consider ways to
speed up our algorithm and extensions of the method
to more complex alignment models.
Acknowledgments
Michael Collins is partly supported by NSF grant
IIS-1161814. Cliff Stein is partly supported by NSF
grant CCF-0915681. The authors thank Sasha Rush
for his help with implementation questions. We
also thank the anonymous reviewers for many use-
ful comments; we hope to pursue the comments we
were not able to address in a followup paper.
References
Peter L. Bartlett, Ben Taskar, Michael Collins and David
Mcallester. 2004. Exponentiated Gradient Algorithms
for Large-Margin Structured Classification. In Pro-
ceedings of NIPS.
Amir Beck and Marc Teboulle. 2003. Mirror Descent and
Nonlinear Projected Subgradient Methods for Convex
Optimization. Operations Research Letters, 31:167-
175.
Dimitris Bertsimas and John N. Tsitsiklis. 1997. Intro-
duction to Linear Programming. Athena Scientific.
Dimitris Bertsimas. 2005. Optimization Over Integers.
Dynamic Ideas.
Dimitri P. Bertsekas. 1999. Nonlinear Optimization.
Athena Press.
Steven Boyd and Lieven Vandenberghe. 2004. Convex
Optimization. Cambridge University Press.
Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della
Pietra, and Robert. L. Mercer. 1993. The Mathematics
of Statistical Machine Translation: Parameter Estima-
tion. Computational Linguistics, 19:263-311.
David Chiang. 2005. A Hierarchical Phrase-Based Model
for Statistical Machine Translation. In Proceedings of
the ACL.
Michael Collins, Amir Globerson, Terry Koo, Xavier
Carreras and Peter L. Bartlett. 2008. Exponentiated
Gradient Algorithms for Conditional Random Fields
and Max-Margin Markov Networks. Journal Machine
Learning, 9(Aug): 1775-1822.
A. P. Dempster, N. M. Laird, and D. B. Rubin. 1977.
Maximum Likelihood From Incomplete Data via the
EM Algorithm. Journal of the royal statistical society,
series B, 39(1):1-38.
Alexander Fraser and Daniel Marcu. 2007. Measur-
ing Word Alignment Quality for Statistical Ma-
chine Translation. Journal Computational Linguistics,
33(3): 293-303.
Kuzman Ganchev, Joao V. Graca, Jennifer Gillenwater,
Ben Taskar. 2010. Posterior Regularization for Struc-
tured Latent Variable Models. Journal of Machine
Learning, 11(July): 2001-2049.
Joao V. Graca, Kuzman Ganchev and Ben Taskar. 2007.
Expectation Maximization and Posterior Constraints.
In Proceedings of NIPS.
Aria Haghighi, John Blitzer, John DeNero and Dan Klein.
2009. Better Word Alignments with Supervised ITG
Models. In Proceedings of the ACL.
Darcey Riley and Daniel Gildea. 2012. Improving the
IBM Alignment Models Using Variational Bayes. In
Proceedings of the ACL.
Yuhong Guo and Dale Schuurmans. 2007. Convex Relax-
ations of Latent Variable Training. In NIPS.
Simon Lacoste-Julien, Ben Taskar, Dan Klein, and
Michael Jordan. 2008. Word Alignment via Quadratic
Assignment. In Proceedings of the HLT-NAACL.
Phillip Koehn. 2008. Statistical Machine Translation.
Cambridge University Press.
Kivinen, J., Warmuth, M. 1997. Exponentiated Gradient
Versus Gradient Descent for Linear Predictors. Infor-
mation and Computation, 132, 1-63.
Percy Liang, Ben Taskar and Dan Klein. 2006. Alignment
by Agreement. In Proceedings of NAACL.
Daniel Marcu, Wei Wang, Abdessamad Echihabi,
and Kevin Knight. 2006. SPMT: Statistical Ma-
chine Translation with Syntactified Target Language
Phrases. In Proceedings of the EMNLP.
1582
Andre F. T. Martins, Noah A. Smith and Eric P. Xing.
2010. Turbo Parsers: Dependency Parsing by Ap-
proximate Variational Inference. In Proceedings of the
EMNLP.
Rada Michalcea and Ted Pederson. 2003. An Evalua-
tion Exercise in Word Alignment. HLT-NAACL 2003:
Workshop in building and using Parallel Texts: Data
Driven Machine Translation and Beyond.
Robert C. Moore. 2004. Improving IBM Word-
Alignment Model 1. In Proceedings of the ACL.
Stephan Vogel, Hermann Ney and Christoph Tillman.
1996. HMM-Based Word Alignment in Statistical
Translation. In Proceedings of COLING.
Franz Och and Hermann Ney. 2003. A Systematic
Comparison of Various Statistical Alignment Models.
Computational-Linguistics, 29(1): 19-52.
Libin Shen, Jinxi Xu and Ralph Weischedel. 2008. A
New String-to-Dependency Machine Translation Al-
gorithm with a Target Dependency Language Model.
In Proceedings of the ACL-HLT.
Ben Taskar, Simon Lacoste-Julien and Dan Klein. 2005.
A Discriminative Matching Approach to Word Align-
ment. In Proceedings of the EMNLP.
Kristina Toutanova and Michel Galley. 2011. Why Ini-
tialization Matters for IBM Model 1: Multiple Optima
and Non-Strict Convexity. In Proceedings of the ACL.
Kenji Yamada and Kevin Knight. 2001. A Syntax-Based
Statistical Translation Model. In Proceedings of the
ACL.
Kenji Yamada and Kevin Knight. 2002. A Decoder for
Syntax-Based Statistical Machine Translation. In Pro-
ceedings of the ACL.
Ashish Vaswani, Liang Huang and David Chiang. 2012.
Smaller Alignment Models for Better Translations:
Unsupervised Word Alignment with the L0-norm. In
Proceedings of the ACL.
1583
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 180?184,
Gothenburg, Sweden, April 26-30 2014.
c?2014 Association for Computational Linguistics
Some Experiments with a Convex IBM Model 2
Andrei Simion
Columbia University
IEOR Department
New York, NY, 10027
aas2148@columbia.edu
Michael Collins
Columbia University
Computer Science
New York, NY, 10027
mc3354@columbia.edu
Clifford Stein
Columbia University
IEOR Department
New York, NY, 10027
cs2035@columbia.edu
Abstract
Using a recent convex formulation of IBM
Model 2, we propose a new initialization
scheme which has some favorable compar-
isons to the standard method of initializing
IBM Model 2 with IBM Model 1. Addition-
ally, we derive the Viterbi alignment for the
convex relaxation of IBM Model 2 and show
that it leads to better F-Measure scores than
those of IBM Model 2.
1 Introduction
The IBM translation models are widely used in
modern statistical translation systems. Unfortu-
nately, apart from Model 1, the IBM models lead
to non-convex objective functions, leading to meth-
ods (such as EM) which are not guaranteed to reach
the global maximum of the log-likelihood function.
In a recent paper, Simion et al. introduced a con-
vex relaxation of IBM Model 2, I2CR-2, and showed
that it has performance on par with the standard IBM
Model 2 (Simion et al., 2013).
In this paper we make the following contributions:
? We explore some applications of I2CR-2. In
particular, we show how this model can be
used to seed IBM Model 2 and compare the
speed/performance gains of our initialization
under various settings. We show that initializ-
ing IBM Model 2 with a version of I2CR-2 that
uses large batch size yields a method that has
similar run time to IBM Model 1 initialization
and at times has better performance.
? We derive the Viterbi alignment for I2CR-2 and
compare it directly with that of IBM Model
2. Previously, Simion et al. (2013) had com-
pared IBM Model 2 and I2CR-2 by using IBM
Model 2?s Viterbi alignment rule, which is not
necessarily the optimal alignment for I2CR-2.
We show that by comparing I2CR-2 with IBM
Model 2 by using each model?s optimal Viterbi
alignment the convex model consistently has a
higher F-Measure. F-Measure is an important
metric because it has been shown to be corre-
lated with BLEU scores (Marcu et al., 2006).
Notation. We adopt the notation introduced in
(Och and Ney, 2003) of having 1
m
2
n
denote the
training scheme of m IBM Model 1 EM iterations
followed by initializing Model 2 with these parame-
ters and running n IBM Model 2 EM iterations. The
notation EG
m
B
2
n
means that we run m iterations of
I2CR-2?s EG algorithm (Simion et al., 2013) with
batch size of B, initialize IBM Model 2 with I2CR-
2?s parameters, and then run n iterations of Model
2?s EM.
2 The IBM Model 1 and 2 Optimization
Problems
In this section we give a brief review of IBM Mod-
els 1 and 2 and the convex relaxation of Model 2,
I2CR-2 (Simion et al., 2013). The standard ap-
proach in training parameters for Models 1 and 2 is
EM, whereas for I2CR-2 an exponentiated-gradient
(EG) algorithm was developed (Simion et al., 2013).
We assume that our set of training examples is
(e
(k)
, f
(k)
) for k = 1 . . . n, where e
(k)
is the k?th
English sentence and f
(k)
is the k?th French sen-
tence. The k?th English sentence is a sequence of
words e
(k)
1
. . . e
(k)
l
k
where l
k
is the length of the k?th
English sentence, and each e
(k)
i
? E; similarly
the k?th French sentence is a sequence f
(k)
1
. . . f
(k)
m
k
where each f
(k)
j
? F . We define e
(k)
0
for k = 1 . . . n
to be a special NULL word (note that E contains the
NULL word). IBM Model 2 is detailed in several
sources such as (Simion et al., 2013) and (Koehn,
2004).
The convex and non-convex objectives of respec-
tively IBM Model 1 and 2 can be found in (Simion
180
et al., 2013). For I2CR-2, the convex relaxation of
IBM Model 2, the objective is given by
1
2n
n
?
k=1
m
k
?
j=1
log
?
l
k
?
i=0
t(f
(k)
j
|e
(k)
i
)
(L+ 1)
+
1
2n
n
?
k=1
m
k
?
j=1
log
?
l
k
?
i=0
min{t(f
(k)
j
|e
(k)
i
), d(i|j)} .
For smoothness reasons, Simion et al. (2013) de-
fined log
?
(z) = log(z + ?) where ? = .001 is a
small positive constant. The I2CR-2 objective is a
convex combination of the convex IBM Model 1 ob-
jective and a direct (convex) relaxation of the IBM2
Model 2 objective, and hence is itself convex.
3 The Viterbi Alignment for I2CR-2
Alignment models have been compared using meth-
ods other than Viterbi comparisons; for example,
Simion et al. (2013) use IBM Model 2?s optimal
rule given by (see below) Eq. 2 to compare mod-
els while Liang et al. (2006) use posterior de-
coding. Here, we derive and use I2CR-2?s Viterbi
alignment. To get the Viterbi alignment of a pair
(e
(k)
, f
(k)
) using I2CR-2 we need to find a
(k)
=
(a
(k)
1
, . . . , a
(k)
m
k
) which yields the highest probability
p(f
(k)
, a
(k)
|e
(k)
).Referring to the I2CR-2 objective,
this corresponds to finding a
(k)
that maximizes
log
?
m
k
j=1
t(f
(k)
j
|e
(k)
a
(k)
j
)
2
+
log
?
m
k
j=1
min {t(f
(k)
j
|e
(k)
a
(k)
j
), d(a
(k)
j
|j)}
2
.
Putting the above terms together and using the
monotonicity of the logarithm, the above reduces to
finding the vector a
(k)
which maximizes
m
k
?
j=1
t(f
(k)
j
|e
(k)
a
(k)
j
)min {t(f
(k)
j
|e
(k)
a
(k)
j
), d(a
(k)
j
|j)}.
As with IBM Models 1 and 2, we can find the vector
a
(k)
by splitting the maximization over the compo-
nents of a
(k)
and focusing on finding a
(k)
j
given by
argmax
a
(t(f
(k)
j
|e
(k)
a
)min {t(f
(k)
j
|e
(k)
a
), d(a|j)}) . (1)
In previous experiments, Simion et al. (Simion et
al., 2013) were comparing I2CR-2 and IBM Model
2 using the standard alignment formula derived in a
similar fashion from IBM Model 2:
a
(k)
j
= argmax
a
(t(f
(k)
j
|e
(k)
a
)d(a|j)) . (2)
4 Experiments
In this section we describe experiments using the
I2CR-2 optimization problem combined with the
stochastic EG algorithm (Simion et al., 2013) for pa-
rameter estimation. The experiments conducted here
use a similar setup to those in (Simion et al., 2013).
We first describe the data we use, and then describe
the experiments we ran.
4.1 Data Sets
We use data from the bilingual word alignment
workshop held at HLT-NAACL 2003 (Michalcea
and Pederson, 2003). We use the Canadian Hansards
bilingual corpus, with 247,878 English-French sen-
tence pairs as training data, 37 sentences of devel-
opment data, and 447 sentences of test data (note
that we use a randomly chosen subset of the orig-
inal training set of 1.1 million sentences, similar to
the setting used in (Moore, 2004)). The development
and test data have been manually aligned at the word
level, annotating alignments between source and tar-
get words in the corpus as either ?sure? (S) or ?pos-
sible? (P ) alignments, as described in (Och and Ney,
2003).
As a second data set, we used the Romanian-
English data from the HLT-NAACL 2003 workshop
consisting of a training set of 48,706 Romanian-
English sentence-pairs, a development set of 17 sen-
tence pairs, and a test set of 248 sentence pairs.
We carried out our analysis on this data set as
well, but because of space we only report the de-
tails on the Hansards data set. The results on the
Romanian data were similar, but the magnitude of
improvement was smaller.
4.2 Methodology
Our experiments make use of either standard train-
ing or intersection training (Och and Ney, 2003).
For standard training, we run a model in the source-
target direction and then derive the alignments on
the test or development data. For each of the
181
Training 2
10
1
5
2
10
EG
1
125
2
10
EG
1
1250
2
10
Iteration Objective
0 -224.0919 -144.2978 -91.2418 -101.2250
1 -110.6285 -85.6757 -83.3255 -85.5847
2 -91.7091 -82.5312 -81.3845 -82.1499
3 -84.8166 -81.3380 -80.6120 -80.9610
4 -82.0957 -80.7305 -80.2319 -80.4041
5 -80.9103 -80.3798 -80.0173 -80-1009
6 -80.3620 -80.1585 -79.8830 -79.9196
7 -80.0858 -80.0080 -79.7911 -79.8048
8 -79.9294 -79.9015 -79.7247 -79.7284
9 -79.8319 -79.8240 -79.6764 -79.6751
10 -79.7670 -79.7659 -79.6403 -79.6354
Table 1: Objective results for the English? French IBM
Model 2 seeded with either uniform parameters, IBM
Model 1 ran for 5 EM iterations, or I2CR-2 ran for 1 iter-
ation with either B = 125 or 1250. Iteration 0 denotes the
starting IBM 2 objective depending on the initialization.
models?IBM Model 1, IBM Model 2, and I2CR-
2? we apply the conventional methodology to in-
tersect alignments: first, we estimate the t and d
parameters using models in both source-target and
target-source directions; second, we find the most
likely alignment for each development or test data
sentence in each direction; third, we take the in-
tersection of the two alignments as the final output
from the model. For the I2CR-2 EG (Simion et al.,
2013) training, we use batch sizes of eitherB = 125
or B = 1250 and a step size of ? = 0.5 throughout.
We measure the performance of the models in
terms of Precision, Recall, F-Measure, and AER us-
ing only sure alignments in the definitions of the first
three metrics and sure and possible alignments in the
definition of AER, as in (Simion et al., 2013) and
(Marcu et al., 2006). For our experiments, we report
results in both AER (lower is better) and F-Measure
(higher is better).
4.3 Initialization and Timing Experiments
We first report the summary statistics on the test set
using a model trained only in the English-French di-
rection. In these experiments we seeded IBM Model
2?s parameters either with those of IBM Model 1 run
for 5, 10 or 15 EM iterations or I2CR-2 run for 1 it-
eration of EG with a batch size of either B = 125 or
1250. For uniform comparison, all of our implemen-
tations were written in C++ using STL/Boost con-
tainers.
There are several takeaways from our experi-
ments, which are presented in Table 2. We first note
that with B = 1250 we get higher F-Measure and
lower AER even though we use less training time: 5
iterations of IBM Model 1 EM training takes about
3.3 minutes, which is about the time it takes for 1 it-
eration of EG with a batch size of 125 (4.1 minutes);
on the other hand, using B = 1250 takes EG 1.7
minutes and produces the best results across almost
all iterations. Additionally, we note that the initial
solution given to IBM Model 2 by running I2CR-2
for 1 iteration with B = 1250 is fairly strong and
allows for further progress: IBM2 EM training im-
proves upon this solution during the first few iter-
ations. We also note that this behavior is global:
no IBM 1 initialization scheme produced subsequent
solutions for IBM 2 with as low in AER or high in
F-Measure. Finally, comparing Table 1 which lists
objective values with Table 2 which lists alignment
statistics, we see that although the objective progres-
sion is similar throughout, the alignment quality is
different.
To complement the above, we also ran inter-
section experiments. Seeding IBM Model 2 by
Model 1 and intersecting the alignments produced
by the English-French and French-English models
gave both AER and F-Measure which were better
than those that we obtained by any seeding of IBM
Model 2 with I2CR-2. However, there are still rea-
sons why I2CR-2 would be useful in this context. In
particular, we note that I2CR-2 takes roughly half
the time to progress to a better solution than IBM
Model 1 run for 5 EM iterations. Second, a possible
remedy to the above loss in marginal improvement
when taking intersections would be to use a more re-
fined method for obtaining the joint alignment of the
English-French and French-English models, such as
?grow-diagonal? (Och and Ney, 2003).
4.4 Viterbi Comparisons
For the decoding experiments, we used IBM Model
1 as a seed to Model 2. To train IBM Model 1, we
follow (Moore, 2004) and (Och and Ney, 2003) in
running EM for 5, 10 or 15 iterations. For the EG al-
gorithm, we initialize all parameters uniformly and
use 10 iterations of EG with a batch size of 125.
Given the lack of development data for the align-
ment data sets, for both IBM Model 2 and the I2CR-
2 method, we report test set F-Measure and AER re-
sults for each of the 10 iterations, rather than picking
the results from a single iteration.
182
Training 2
10
1
5
2
10
1
10
2
10
1
15
2
10
EG
1
125
2
10
EG
1
1250
2
10
Iteration AER
0 0.8713 0.3175 0.3177 0.3160 0.2329 0.2662
1 0.4491 0.2547 0.2507 0.2475 0.2351 0.2259
2 0.2938 0.2428 0.2399 0.2378 0.2321 0.2180
3 0.2593 0.2351 0.2338 0.2341 0.2309 0.2176
4 0.2464 0.2298 0.2305 0.2310 0.2283 0.2168
5 0.2383 0.2293 0.2299 0.2290 0.2268 0.2188
6 0.2350 0.2273 0.2285 0.2289 0.2274 0.2205
7 0.2320 0.2271 0.2265 0.2286 0.2274 0.2213
8 0.2393 0.2261 0.2251 0.2276 0.2278 0.2223
9 0.2293 0.2253 0.2246 0.2258 0.2284 0.2217
10 0.2288 0.2248 0.2249 0.2246 0.2275 0.2223
Iteration F-Measure
0 0.0427 0.5500 0.5468 0.5471 0.6072 0.5977
1 0.4088 0.5846 0.5876 0.5914 0.6005 0.6220
2 0.5480 0.5892 0.5916 0.5938 0.5981 0.6215
3 0.5750 0.5920 0.5938 0.5947 0.5960 0.6165
4 0.5814 0.5934 0.5839 0.5952 0.5955 0.6129
5 0.5860 0.5930 0.5933 0.5947 0.5945 0.6080
6 0.5873 0.5939 0.5936 0.5940 0.5924 0.6051
7 0.5884 0.5931 0.5955 0.5941 0.5913 0.6024
8 0.5899 0.5932 0.5961 0.5942 0.5906 0.6000
9 0.5899 0.5933 0.5961 0.5958 0.5906 0.5996
10 0.5897 0.5936 0.5954 0.5966 0.5910 0.5986
Table 2: Results on the Hansards data for English ?
French IBM Model 2 seeded using different methods.
The first three columns are for a model seeded with IBM
Model 1 ran for 5, 10 or 15 EM iterations. The fourth
and fifth columns show results when we seed with I2CR-
2 ran for 1 iteration either withB = 125 or 1250. Iteration
0 denotes the starting statistics.
Training 1
5
2
10
1
10
2
10
1
15
2
10
EG
10
125
EG
10
125
Viterbi Rule t? d t? d t? d t? d t?min{t? d}
Iteration AER
0 0.2141 0.2159 0.2146 0.9273 0.9273
1 0.1609 0.1566 0.1513 0.1530 0.1551
2 0.1531 0.1507 0.1493 0.1479 0.1463
3 0.1477 0.1471 0.1470 0.1473 0.1465
4 0.1458 0.1444 0.1449 0.1510 0.1482
5 0.1455 0.1438 0.1435 0.1501 0.1482
6 0.1436 0.1444 0.1429 0.1495 0.1481
7 0.1436 0.1426 0.1435 0.1494 0.1468
8 0.1449 0.1427 0.1437 0.1508 0.1489
9 0.1454 0.1426 0.1430 0.1509 0.1481
10 0.1451 0.1430 0.1423 0.1530 0.1484
Iteration F-Measure
0 0.7043 0.7012 0.7021 0.0482 0.0482
1 0.7424 0.7477 0.7534 0.7395 0.7507
2 0.7468 0.7499 0.7514 0.7448 0.7583
3 0.7489 0.7514 0.7520 0.7455 0.7585
4 0.7501 0.7520 0.7516 0.7418 0.7560
5 0.7495 0.7513 0.7522 0.7444 0.7567
6 0.7501 0.7501 0.7517 0.7452 0.7574
7 0.7493 0.7517 0.7507 0.7452 0.7580
8 0.7480 0.7520 0.7504 0.7452 0.7563
9 0.7473 0.7511 0.7513 0.7450 0.7590
10 0.7474 0.7505 0.7520 0.7430 0.7568
Table 3: Intersected results on the English-French data
for IBM Model 2 and I2CR-2 using either IBM Model 1
trained to 5, 10, or 15 EM iterations to seed IBM2 and us-
ing either the IBM2 or I2CR-2 Viterbi formula for I2CR-
2.
In Table 3 we report F-Measure and AER results
for each of the iterations under IBM Model 2 and
I2CR-2 models using either the Model 2 Viterbi rule
of Eq. 2 or I2CR-2?s Viterbi rule in Eq. 1. We
note that unlike in the previous experiments pre-
sented in (Simion et al., 2013), we are directly test-
ing the quality of the alignments produced by I2CR-
2 and IBM Model 2 since we are getting the Viterbi
alignment for each model (for completeness, we also
have included in the fourth column the Viterbi align-
ments we get by using the IBM Model 2 Viterbi for-
mula with the I2CR-2 parameters as Simion et al.
(2013) had done previously). For these experiments
we report intersection statistics. Under its proper
decoding formula, I2CR-2 model yields a higher F-
Measure than any setting of IBM Model 2. Since
AER and BLEU correlation is arguably known to be
weak while F-Measure is at times strongly related
with BLEU (Marcu et al., 2006), the above results
favor the convex model.
We close this section by pointing out that the main
difference between the IBM Model 2 Viterbi rule of
Eq. 2 and the I2CR-2 Viterbi rule in Eq. 1 is that
the Eq. 1 yield fewer alignments when doing inter-
section training. Even though there are fewer align-
ments produced, the quality in terms of F-Measure
is better.
5 Conclusions and Future Work
In this paper we have explored some of the details of
a convex formulation of IBM Model 2 and showed
it may have an application either as a new initial-
ization technique for IBM Model 2 or as a model
in its own right, especially if the F-Measure is the
target metric. Other possible topics of interest in-
clude performing efficient sensitivity analysis on the
I2CR-2 model, analyzing the balance between the
IBM Model 1 and I2CR-1 (Simion et al., 2013) com-
ponents of the I2CR-2 objective, studying I2CR-
2?s intersection training performance using methods
such as ?grow diagonal? or ?agreement? (Liang et
al., 2006), and integrating it into the GIZA++ open
source library so we can see how much it affects the
downstream system.
Acknowledgments
Michael Collins and Andrei Simion are partly sup-
ported by NSF grant IIS-1161814. Cliff Stein is
183
partly supported by NSF grants CCF-0915681 and
CCF-1349602. We thank Professor Paul Blaer and
Systems Engineer Radu Sadeanu for their help set-
ting up some of the hardware used for these experi-
ments. We also thank the anonymous reviewers for
many useful comments; we hope to pursue the com-
ments we were not able to address in a followup pa-
per.
References
Peter L. Bartlett, Ben Taskar, Michael Collins and David
Mcallester. 2004. Exponentiated Gradient Algorithms
for Large-Margin Structured Classification. In Pro-
ceedings of NIPS.
Steven Boyd and Lieven Vandenberghe. 2004. Convex
Optimization. Cambridge University Press.
Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della
Pietra, and Robert. L. Mercer. 1993. The Mathematics
of Statistical Machine Translation: Parameter Estima-
tion. Computational Linguistics, 19:263-311.
Michael Collins, Amir Globerson, Terry Koo, Xavier
Carreras and Peter L. Bartlett. 2008. Exponentiated
Gradient Algorithms for Conditional Random Fields
and Max-Margin Markov Networks. Journal Machine
Learning, 9(Aug): 1775-1822.
A. P. Dempster, N. M. Laird, and D. B. Rubin. 1977.
Maximum Likelihood From Incomplete Data via the
EM Algorithm. Journal of the royal statistical society,
series B, 39(1):1-38.
Alexander Fraser and Daniel Marcu. 2007. Measur-
ing Word Alignment Quality for Statistical Ma-
chine Translation. Journal Computational Linguistics,
33(3): 293-303.
Joao V. Graca, Kuzman Ganchev and Ben Taskar. 2007.
Expectation Maximization and Posterior Constraints.
In Proceedings of NIPS.
Yuhong Guo and Dale Schuurmans. 2007. Convex Re-
laxations of Latent Variable Training. In Proceedings
of NIPS.
Simon Lacoste-Julien, Ben Taskar, Dan Klein, and
Michael Jordan. 2008. Word Alignment via Quadratic
Assignment. In Proceedings of the HLT-NAACL.
Phillip Koehn. 2004. Statistical Significance Tests for
Machine Translation Evaluation. In Proceedings of the
EMNLP.
Phillip Koehn. 2008. Statistical Machine Translation.
Cambridge University Press.
Kivinen, J., Warmuth, M. 1997. Exponentiated Gradient
Versus Gradient Descent for Linear Predictors. Infor-
mation and Computation, 132, 1-63.
Percy Liang, Ben Taskar and Dan Klein. 2006. Alignment
by Agreement. In Proceedings of NAACL.
Daniel Marcu, Wei Wang, Abdessamad Echihabi,
and Kevin Knight. 2006. SPMT: Statistical Ma-
chine Translation with Syntactified Target Language
Phrases. In Proceedings of the EMNLP.
Rada Michalcea and Ted Pederson. 2003. An Evalua-
tion Exercise in Word Alignment. HLT-NAACL 2003:
Workshop in building and using Parallel Texts: Data
Driven Machine Translation and Beyond.
Robert C. Moore. 2004. Improving IBM Word-
Alignment Model 1. In Proceedings of the ACL.
Stephan Vogel, Hermann Ney and Christoph Tillman.
1996. HMM-Based Word Alignment in Statistical
Translation. In Proceedings of COLING.
Franz Och and Hermann Ney. 2003. A Systematic
Comparison of Various Statistical Alignment Models.
Computational-Linguistics, 29(1): 19-52.
Andrei Simion, Michael Collins and Cliff Stein. 2013. A
Convex Alternative to IBM Model 2. In Proceedings
of the EMNLP.
Kristina Toutanova and Michel Galley. 2011. Why Ini-
tialization Matters for IBM Model 1: Multiple Optima
and Non-Strict Convexity. In Proceedings of the ACL.
Ashish Vaswani, Liang Huang and David Chiang. 2012.
Smaller Alignment Models for Better Translations:
Unsupervised Word Alignment with the L0-norm. In
Proceedings of the ACL.
184
