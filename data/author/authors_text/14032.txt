Proceedings of the Third Workshop on Statistical Machine Translation, pages 111?114,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
The MetaMorpho translation system 
Attila Nov?k, L?szl? Tihanyi and G?bor Pr?sz?ky 
MorphoLogic 
Orb?nhegyi ?t 5, Budapest 1126, Hungary 
{novak,tihanyi,proszeky}@morphologic.hu 
 
 
 
Abstract 
In this article, we present MetaMorpho, a rule 
based machine translation system that was 
used to create MorphoLogic?s submission to 
the WMT08 shared Hungarian to English 
translation task. The architecture of Meta-
Morpho does not fit easily into traditional 
categories of rule based systems: the building 
blocks of its grammar are pairs of rules that 
describe source and target language structures 
in a parallel fashion and translated structures 
are created while parsing the input.  
1 Introduction 
Three rule-based approaches to MT are tradition-
ally distinguished: direct, interlingua and transfer. 
The direct method uses a primitive one-stage proc-
ess in which words in the source language are re-
placed with words in the target language and then 
some rearrangement is done. The main idea behind 
the interlingua method is that the analysis of any 
source language should result in a language-
independent representation. The target language is 
then generated from that language-neutral repre-
sentation. The transfer method first parses the sen-
tence of the source language. It then applies rules 
that map the lexical and grammatical segments of 
the source sentence to a representation in the target 
language. 
The MetaMorpho machine translation system de-
veloped at MorphoLogic (Pr?sz?ky and Tihanyi, 
2002), cannot be directly classified in either of the 
above categories, although it has the most in com-
mon with the transfer type architecture.  
2 Translation via immediate transfer 
In the MetaMorpho system, both productive 
rules of grammar and lexical entries are stored in 
the form of patterns, which are like context-free 
rules enriched with features. Patterns may contain 
more-or-less underspecified slots, ranging from 
general productive rules of grammar through more-
or-less idiomatic phrases to fully lexicalized items. 
The majority of the patterns (a couple of hundreds 
of thousands in the case of our English grammar) 
represent partially lexicalized items. 
The grammar operates with pairs of patterns 
that consist of one source pattern used during bot-
tom-up parsing and one or more target patterns that 
are applied during top-down generation of the 
translation. While traditional transfer and interlin-
gua based systems consist of separate parsing and 
generating rules, in a MetaMorpho grammar, each 
parsing rule has its associated generating counter-
part. The translation of the parsed structures is al-
ready determined during parsing the source 
language input. The actual generation of the target 
language representations does not involve any ad-
ditional transfer operations: target language struc-
tures corresponding to substructures of the source 
language parse tree are combined and the leaves of 
the resulting tree are interpreted by a morphologi-
cal generator. We call this solution ?immediate 
transfer? as it uses no separate transfer steps or 
target transformations. 
The idea behind this architecture has much in 
common with the way semantic compositionality 
was formalized by Bach (1976) in the from of his 
rule-to-rule hypothesis, stating that to every rule of 
syntax that combines constituents into a phrase 
pertains a corresponding rule of semantics that 
111
combines the meanings of the constituents. In the 
case of phrases with compositional meaning, the 
pair of rules of syntax and semantics are of a gen-
eral nature, while in the case of idioms, the pair of 
rules is specific and arbitrary. The architecture im-
plemented in the MetaMorpho system is based on 
essentially the same idea, except that the represen-
tation built during analysis of the input sentence is 
not expressed in a formal language of some seman-
tic representation but directly in the human target 
language of the translation system. 
3 System architecture  
The analysis of the input is performed in three 
stages. First the text to be translated is segmented 
into sentences, and each sentence is broken up into 
a sequence of tokens. This token sequence is the 
actual input of the parser. Morphosyntactic annota-
tion of the input word forms is performed by a 
morphological analyzer: it assigns morphosyntactic 
attribute vectors to word forms. We use the Humor 
morphological system (Pr?sz?ky and Kis, 1999; 
Pr?sz?ky and Nov?k, 2005) that performs an item-
and-arrangement style morphological analysis. 
Morphological synthesis of the target language 
word forms is performed by the same morphologi-
cal engine.  
The system also accepts unknown elements: 
they are treated as strings to be inflected at the tar-
get side. The (potentially ambiguous) output of the 
morphological analyzer is fed into the syntactic 
parser called Moose (Pr?sz?ky, Tihanyi and Ugray, 
2004), which analyzes this input sequence using 
the source language patterns and if it is recognized 
as a correct sentence, comes up with one or more 
root symbols on the source side.  
Every terminal and non-terminal symbol in the 
syntactic tree under construction has a set of fea-
tures. The number of features is normally up to a 
few dozen, depending on the category. These fea-
tures can either take their values from a finite set of 
symbolic items (e.g., values of case can be INS, 
ACC, DAT, etc.), or represent a string (e.g., 
lex="approach", the lexical form of a token). 
The formalism does not contain embedded feature 
structures. It is important to note that no structural 
or semantic information is amassed in the features 
of symbols: the interpretation of the input is con-
tained in the syntactic tree itself, and not in the fea-
tures of the node on the topmost level. Features are 
used to express constraints on the applicability of 
patterns and to store morphosyntactic valence and 
lexical information concerning the parsed input. 
More specific patterns (e.g. approach to) can 
override more general ones (e.g. approach), in that 
case subtrees containing symbols that were created 
by the general pattern are deleted. Every symbol 
that is created and is not eliminated by an overrid-
ing pattern is retained even if it does not form part 
of a correct sentence's syntactic tree. Each pattern 
can explicitly override other rules: if the overriding 
rule covers a specific range of the input, it blocks 
the overridden ones over the same range. This 
method can be used to eliminate spurious ambigui-
ties early during analysis. 
When the whole input is processed and no ap-
plicable patterns remain, translation is generated in 
a top-down fashion by combining the target struc-
tures corresponding to the source patterns consti-
tuting the source language parse tree.  
A source language pattern may have more than 
one associated target pattern. The selection of the 
target structure to apply relies on constraints on the 
actual values of features in the source pattern: the 
first target pattern whose conditions are satisfied is 
used for target structure generation. To handle 
complicated word-order changes, the target struc-
ture may need rearrangement of its elements within 
the scope of a single node and its children. There is 
another technique that can be used to handle word 
order differences between the source and the target 
language. A pointer to a subtree can be stored in a 
feature when applying a rule at parse time, and 
because this feature?s value can percolate up the 
parse-tree and down the target tree, just like any 
other feature, a phrase swallowed somewhere in 
the source side can be expanded at a different loca-
tion in the target tree. This technique can be used 
to handle both systematic word order differences 
(such as the different but fixed order of constitu-
ents in possessive constructions: possession of pos-
sessor in English versus possessor possession + 
possessive suffix in Hungarian) and accidental ones 
(such as the fixed order of subject verb and object 
in English, versus the ?free? order of these con-
stituents in Hungarian1). 
Unlike in classical transfer-based systems, 
however, these rearrangement operations are al-
                                                          
1 In fact the order is determined by various factors other than 
grammatical function. 
112
ready determined during parsing the source lan-
guage input. During generation, the already deter-
mined rearranged structures are simply spelled out. 
The morphosyntactic feature vectors on the termi-
nal level of the generated tree are interpreted by 
the morphological generator that synthesizes the 
corresponding target language word forms.  
The morphological generator is not a simple in-
verse of the corresponding analyzer. It accepts 
many alternative equivalent morphological de-
scriptions of each word form it can generate beside 
the one that the corresponding analyzer outputs.  
4 The rule database 
The rules used by the parser explicitly contain 
all the features of the daughter nodes to check, all 
the features to percolate to the mother node, all the 
features to set in the corresponding target struc-
tures and those to be checked on the source lan-
guage structure to decide on the applicability of a 
target structure. The fact that all this redundant 
information is present in the run-time rule database 
makes the operation of the parser efficient in terms 
of speed. However, it would be very difficult for 
humans to create and maintain the rule database in 
this redundant format.  
There is a high level version of the language: 
although it is not really different in terms of its 
syntax from the low-level one, it does not require 
default values and default correspondences to be 
explicitly listed. The rule database is maintained 
using this high level formalism. There is a rule 
converter for each language pair that extends the 
high-level rules with default information and may 
also create transformed rules (such as the passive 
version of verbal subcategorization frames) creat-
ing the rule database used by the parser.  
Rule conversion is also necessary because in 
order to be able to parse a free word order lan-
guage like Hungarian with a parser that uses con-
text free rules, you need to use run time rules that 
essentially differ in the way they operate from 
what would be suggested by the rules they are de-
rived from in the high level database. In Hungar-
ian, arguments of a predicate may appear in many 
different orders in actual sentences and they also 
freely mix with sentence level adjuncts. This 
means that a verbal argument structure of the high 
level rule database with its normal context free rule 
interpretation would only cover a fraction of its 
real world realizations. Rule conversion effectively 
handles this problem by converting rules describ-
ing lexical items with argument structures ex-
pressed using a context free rule formalism into 
run time rules that do not actually combine con-
stituents, but only check the saturation of valency 
frames. Constituents are combined by other more 
generic rules that take care of saturating the argu-
ment slots. This means that while the high level 
and the run time rules have a similar syntax, the 
semantics of some high level rules may be very 
different from similar rules in the low level rule 
database. 
5 Handling sentences with no full parse 
The system must not break down if the input 
sentence happens not to have a full parse (this in-
evitably happens in the case of real life texts). In 
that case, it reverts to using a heuristic process that 
constructs an output by combining the output of a 
selected set of partial structures covering the whole 
sentence stored during parsing the input. In the 
MetaMorpho terminology, this is called a ?mosaic 
translation?. Mosaic translations are usually subop-
timal, because in the absence of a full parse some 
structural information such as agreement is usually 
lost. There is much to improve on the current algo-
rithm used to create mosaic translations: e.g. it 
does not currently utilize a statistical model of the 
target language, which has a negative effect on the 
fluency of the output. Augmenting the system with 
such a component would probably improve its per-
formance considerably. 
6 Motivation for the MetaMorpho archi-
tecture 
An obvious drawback of the architecture de-
scribed above compared to the interlingua and 
transfer based systems is that the grammar compo-
nents of the system cannot be simply reused to 
build translation systems to new target languages 
without a major revision of the grammar. While in 
a classical transfer based system, the source lan-
guage grammar may cover phenomena that the 
transfer component does not cover, in the Meta-
Morpho architecture, this is not possible. In a 
transfer based system, there is a relatively cheaper 
way to handle coverage issues partially by aug-
menting only the source grammar (and postponing 
113
creation of the corresponding transfer rules). This 
is not an option in the MetaMorpho architecture. 
The main motivation for this system architec-
ture was that it makes it possible to integrate ma-
chine translation and translation memories in a 
natural way and to make the system easily extensi-
ble by the user. There is a grammar writer?s work-
bench component of MetaMorpho called Rule 
Builder. This makes it possible for users to add 
new, lexical or even syntactic patterns to the 
grammar in a controlled manner without the need 
to recompile the rest, using an SQL database for 
user added entries. The technology used in Rule-
Builder can also be applied to create a special 
combination of the MetaMorpho machine transla-
tion tool and translation memories (Hod?sz, 
Gr?bler and Kis 2004).  
Moreover, existing bilingual lexical databases 
(dictionaries of idioms and collocations) are rela-
tively easy to convert to the high level rule format 
of the system. The bulk of the grammar of the sys-
tem was created based on such resources. Another 
rationale for developing language pair specific 
grammars directly is that this way distinctions in 
the grammar of the source language not relevant 
for the translation to the target language at hand 
need not be addressed.  
7 Performance in the translation task 
During development of the system and its grammar 
components, regression testing has been performed 
using a test set unknown to the developers measur-
ing case insensitive BLEU with three human refer-
ence translations. Our usual test set for the system 
translating from Hungarian to English contains 274 
sentences of newswire text. We had never used 
single reference BLEU before, because, although 
creating multiple translations is expensive, single 
reference BLEU is quite unreliable usually produc-
ing very low scores especially if the target lan-
guage is morphologically rich, like Hungarian. 
The current version of the MetaMorpho system 
translating from Hungarian to English has a BLEU 
score of 22.14 on our usual newswire test set with 
three references. Obtaining a BLEU score of 7.8 on 
the WMT08 shared Hungarian to English transla-
tion task test set was rather surprising, so we 
checked single reference BLEU on our usual test 
set: the scores are 13.02, 14.15 and 16.83 with the 
three reference translations respectively.  
In the end, we decided to submit our results to the 
WMT08 shared translation task in spite of the low 
score. But we think, that these figures cast doubts 
on the quality of the texts and reference transla-
tions in the test set, especially in cases where both 
the English and the Hungarian text were translated 
from a third language, so we think that the scores 
on the WMT08 test set should be evaluated only 
relative to other systems? performance on the same 
data and the same language pair. 
References  
Emmon Bach. 1976. An extension of classical transfor-
mational grammar. In Saenz (ed.) Problems of Lin-
guistic Metatheory: Proceedings of the 1976 
Conference, 183?224. East Lansing, MI: Michigan 
State University. 
G?bor Hod?sz, Tam?s Gr?bler and Bal?zs Kis. 2004. 
Translation memory as a robust example-based trans-
lation system. In Hutchins (ed.), 82?89.  
John Hutchins (ed.) Broadening horizons of machine 
translation and its applications. Proceedings of the 
9th EAMT Workshop, 26?27 April 2004. La Val-
letta: Foundation for International Studies. 
G?bor Pr?sz?ky and Bal?zs Kis. 1999. Agglutinative 
and other (highly) inflectional languages. In Robert 
Dale & Kenneth W. Church (eds.) Proceedings of the 
37th Annual Meeting of the Association for Computa-
tional Linguistics, 261?268. Morristown, NJ: Asso-
ciation for Computational Linguistics. 
G?bor Pr?sz?ky and Attila Nov?k. 2005. Computational 
Morphologies for Small Uralic Languages. In: A. 
Arppe, L. Carlson, K. Lind?n, J. Piitulainen, M. 
Suominen, M. Vainio, H. Westerlund, A. Yli-Jyr? 
(eds.): Inquiries into Words, Constraints and Con-
texts Festschrift in the Honour of Kimmo Kosken-
niemi on his 60th Birthday, 116?125. Gummerus 
Printing, Saarij?rvi/CSLI Publications, Stanford. 
G?bor Pr?sz?ky and L?szl? Tihanyi. 2002 MetaMor-
pho: A Pattern-Based Machine Translation System. 
In: Proceedings of the 24th 'Translating and the 
Computer' Conference, 19?24. ASLIB, London, 
United Kingdom. 
G?bor Pr?sz?ky, L?szl? Tihanyi and G?bor Ugray. 
2004. Moose: A robust high-performance parser and 
generator. In Hutchins (ed.), 138?142. 
114
Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 155?159,
Athens, Greece, 30 March ? 31 March 2009. c?2009 Association for Computational Linguistics
MorphoLogic?s submission for the WMT 2009 Shared Task 
Attila Nov?k 
MorphoLogic 
Kardhegy utca 5, Budapest 1116, Hungary 
novak@morphologic.hu 
  
 
Abstract 
In this article, we describe the machine 
translation systems we used to create 
MorphoLogic?s submissions to the 
WMT09 shared Hungarian to English 
and English to Hungarian shared transla-
tion tasks. We used our rule based 
MetaMorpho system to generate our pri-
mary submission. In addition, we created 
a hybrid system where the Moses de-
coder is used to rank translations or as-
semble partial translations created by 
MetaMorpho. Our third system was a 
purely statistical morpheme based system 
for the Hungarian to English task. 
1 Introduction 
This year, MorphoLogic submitted translations 
for the WMT09 shared Hungarian to English and 
English to Hungarian translation tasks. Our pri-
mary submissions were translated by MetaMor-
pho, a purely rule based machine translation sys-
tem (Pr?sz?ky and Tihanyi, 2002). Since last 
year?s workshop we improved the Hungarian to 
English grammar of MetaMorpho by making 
more efficient the handling of certain structural 
ambiguities and making the way the system han-
dles long sentences more robust. 
The way Metamorpho selects the translation to 
output is not optimal whether or not a full parse 
for the source sentence could be obtained by its 
parser.1 Thus we decided to experiment with a 
hybrid system where translations and partial 
translations produced by MetaMorpho are ranked 
or assembled by the Moses decoder (Koehn et 
al., 2007) using a target language model.  
                                                 
1 In the first case, simply the first translation is output 
instead of considering all possible translations and 
selecting the best, while in the second case, the algo-
rithm that combines the partial translations does not 
check how well the target language side of the pieces 
fit together. 
In addition, we created a purely statistical 
morpheme based system (also using Moses) for 
the Hungarian to English task. However, results 
obtained with the latter setup have been clearly 
inferior in quality to those produced by the rule 
based system both in terms of BLEU score and 
subjective human judgment. 
2 The MetaMorpho translation system 
MetaMorpho is a rule based system the architec-
ture of which differs from that of most well-
known rule based systems: it does not contain a 
separate transfer component. Its grammar oper-
ates with pairs of patterns (context-free rules en-
riched with features) that consist of one source 
pattern used during bottom-up parsing and one or 
more target patterns that are applied during top-
down generation of the translation. The architec-
ture of the grammar is completely homogeneous: 
the same formalism is used to represent general 
rules of grammar, more-or-less idiomatic phrases 
and fully lexicalized items, these differ only in 
the degree of underspecification. 
The translation of the parsed structures is al-
ready determined during parsing the source lan-
guage input. The actual generation of the target 
language representations does not involve any 
additional transfer operations: target language 
structures corresponding to substructures of the 
source language parse tree are combined and the 
leaves of the resulting tree are interpreted by a 
morphological generator. 
MetaMorpho processes input by first segmenting 
it into sentences, then tokenizing them and per-
forming morphological analysis on tokens, as-
signing morphosyntactic attribute vectors to 
them. This is followed by parsing the network of 
ambiguous token sequences using the source side 
of the grammar. Features are used in the gram-
mar to express constraints on the applicability of 
rules and to store morphosyntactic, valence and 
lexical information concerning the parsed input.  
When no applicable rules remain, translation 
is generated in a top-down fashion by combining 
the target structures corresponding to the source 
155
patterns constituting the source language parse 
tree. A source language rule may have more than 
one associated target rule. The selection of the 
target structure to apply relies on constraints on 
the actual values of features in the source rule. 
Unlike in classical transfer-based systems, 
word order rearrangement is already determined 
during parsing the source language input by the 
applied rules and the values of the features. Dur-
ing generation, the already determined rear-
ranged structures are simply spelled out. The 
morphosyntactic feature vectors on the terminal 
level of the generated tree are interpreted by a 
morphological generator that synthesizes the cor-
responding target language word forms. 
Handling ambiguity is always a difficult 
problem in a rule based system. MetaMorpho 
gets rid of alternatives either by using high level 
heuristics or by specific rules explicitly overrid-
ing some more general alternatives. Generally 
MetaMorpho only generates the first possible 
translation corresponding to the first parse it pro-
duces. In the case of long sentences however, 
MetaMorpho still may run into the problem of 
generating too many hypotheses. The solution to 
this problem originally was simply to abort the 
parser when it had spent too much time on ana-
lyzing a sentence. This resulted in a sequence of 
words at the end of the sentence remaining un-
translated. We managed to alleviate this problem 
by introducing subsentential segmentation that 
partitions the input sentence into chunks at pre-
sumably safe places (usually clause boundaries).  
3 Using a target language model to com-
bine partial parses 
During parsing, a hierarchy of partial structures 
is built by the parser. If the parser fails to pro-
duce full parse of the sentence, MetaMorpho re-
verts to using a heuristic process that constructs 
an output by combining the output of a selected 
set of these partial structures covering the whole 
sentence. These assembled translations are usu-
ally suboptimal, because in the absence of a full 
parse some structural information such as agree-
ment is often lost.  
3.1 Pronoun dropping 
In the case of Hungarian to English translation, 
pronoun dropping in Hungarian is a further prob-
lem when trying to assemble a translation from 
partial structures. Since the number and person 
of the subject and the definiteness of the object 
(in the case of transitive verbs) is exactly ex-
pressed by Hungarian verbal agreement suffixes, 
explicit subject and object pronouns may be (and 
usually are) dropped (unless they are focused or 
otherwise stressed). The problem is that the same 
verb forms are used when the subject or object is 
a full NP. In these cases, however no pronoun is 
incorporated in the verbal suffix: 
 
Hallja. He/she/it hears him/her/it.  
Fred hallja a doktort. Fred hears the doctor.  
 
For single verb forms the MetaMorpho parser 
only generates English phrases that contain sub-
ject pronouns (and in the case of a transitive 
definite verb like hallja also an object pronoun: 
he hears it), because the verb is only represented 
in the grammar by structures that inherently con-
tain its possible argument structures. This results 
in extra pronouns appearing in the assembled 
output translation if there is in fact an overt sub-
ject and/or object in the sentence. The same thing 
applies to 3rd person singular possessive con-
structions: 
 
h?za his house  
Fred h?za. Fred?s house.  
3.2 Utilizing the Moses decoder 
The original partial structure combination algo-
rithm in MetaMorpho does not utilize a statistical 
model of the target language. In our experiments, 
we replaced the original phrase combination al-
gorithm with a statistical model using the Moses 
decoder hoping that this would improve the 
translations produced in these cases. We created 
an interface to the parser that can output all par-
tial parses generated during parsing the input 
sentence along with their translations.  
We directly constructed a phrase table from 
the partial translations and used the Moses de-
coder to select the best translation using a surface 
target language model. We assumed a uniform 
distribution on the translations in the phrase table 
(for lack of a better estimation of the translation 
probabilities) and assigned a zero weight to the 
phrase model in the Moses configuration. Nei-
ther did we use a lexicalized distortion table. The 
decoder thus selects the best translation based on 
the language model score assigned to it. In our 
experiments we used 5-gram language models 
created from the WMT09 bilingual training data. 
We could not use language models created from 
the larger monolingual corpora: the RAM in-
156
stalled in our test machine was not enough for 
that.2 
We experimented with various parameter set-
tings and ways of building the phrase table. 
While including partial translations in the phrase 
table for sentences that had a full parse definitely 
hurt performance, adding all alternative full 
translations (if the parser managed to parse the 
whole sentence) to the phrase table and letting 
the language model select the best one (instead 
of MetaMorpho defaulting to the first successful 
parse) improved performance as could be ex-
pected. We needed to increase the maximum al-
lowed phrase length parameter from the default 
to allow the decoder to use the full sentence 
translations (failing to do so resulted in a serious 
degradation of performance).  
Adding alternative versions of phrases con-
taining possibly spurious pronouns to the phrase 
table with the pronouns removed or properly 
modified also had a beneficial effect as this re-
duced the frequency of extra inserted pronouns 
in the translations. 
While our original phrase assembly algorithm 
never attempts to reorder the chunks it selects, 
we did experiment with different distortion pa-
rameter settings in the statistical approach since 
reordering comes for free with the Moses de-
coder. (Well, there is in fact a price to pay for 
distortion: a sharp fall in decoding speed.) We 
found that not penalizing word order changes by 
the decoder clearly had a detrimental effect on 
the accuracy of translations. The default distor-
tion limit and penalty (distortion limit was of six 
words (d=6) in this setting; distortion penalty 
weight was identical with the language model 
weight) often resulted in translations with com-
pletely out-of-place chunks at the end of the sen-
tence. We got the best results (also in terms of 
BLEU score) when disallowing distortion alto-
gether even though this results in somewhat dis-
fluent output, especially if the target language is 
English and the original Hungarian sentence was 
verb final. Disallowing distortion also made de-
coding more than ten times faster. 
                                                 
2 Building lower-order LMs, cutting off singletons, 
and/or limiting the LM's vocabulary to the most fre-
quent phrases could be possible solutions to that prob-
lem as the reviewer of the paper pointed out. We are 
going to try to solve the memory problem using a 
combination these techniques in our follow-up ex-
periments. 
3.3 Results 
Unfortunately, even with the best parameter set-
tings that we have found, we managed to achieve 
only a slight improvement in BLEU scores com-
pared to the original heuristics used in MetaMor-
pho. The following table lists the (case insensi-
tive) BLEU scores achieved by the original 
purely rule based system and various versions of 
the hybrid system on the WMT09 test set.3  
 
Hungarian to English  
MetaMorpho 9.96 
d=6, no distortion penalty, reassem-
bling full parses 
9.62 
d=6, distortion penalty, no partial 
analyses for full parse sentences  
9.70 
d=0, no distortion, no partial analyses 
for full parse sentences, pronoun drop-
ping 
10.10 
English to Hungarian  
MetaMorpho 8.13 
d=6, distortion penalty, no partial 
analyses for full parse sentences  
8.22 
d=0, no distortion, no partial analyses 
for full parse sentences 
8.44 
 
Although we got slightly better results using 
the hybrid system, we submitted the output of the 
original fully rule based MetaMorpho system as 
our primary submission. 
4 A morpheme based Hungarian to 
English statistical translation system 
In addition to the hybrid system above, we also 
experimented with a statistical system using the 
Moses toolkit that we used to build a Hungarian 
to English translation system. The model that we 
implemented is based on a morpheme based rep-
resentation of both languages instead of a word 
form based or factored representation. 
4.1 The architecture of the system 
The Hungarian side of the WMT09 parallel 
training corpus was analyzed and stemmed using 
the Humor morphological analyzer (Pr?sz?ky 
and Kis, 1999; Pr?sz?ky and Nov?k, 2005) and 
we used the Hunpos tagger (Hal?csy, Kornai and 
Oravecz, 2007) for disambiguating the morpho-
                                                 
3 We first used a cleaned-up version of the WMT08 
test set (with typos and badly converted characters 
fixed) in our experiments. Then we rerun some of the 
test configurations on the WMT09 test set and got 
similarly improving results, which we report here. 
157
logical tagging. For English tagging, we used 
CRFTagger (Phan, 2006), a Java-based condi-
tional random fields POS tagger, while stemming 
was performed by morpha (Minnen, Carroll and 
Pearce, 2001). We used the corresponding 
morphg word form generator to generate the out-
put surface word forms. Unfortunately, morpha 
neutralizes some present and past forms of the 
copula, we needed to fix this to get the proper 
forms in the output. 
We segmented both sides of the corpus into 
morphemes based on the analyses, so the tokens 
in our system were morphemes instead of word 
forms. The following is a lowercased example 
sentence pair from the training corpus: 
 
a[det] 137[szn] apr?[mn] csillag[fn] [ela] ?ll?[mn] 
spir?l[fn] meg+[ik] dupl?z?dik[ige] [me3] .[punct] 
 
the_dt spiral_nn of_in 137_cd tiny_jj star_nn s_nns 
double_vb ed_vbd itself_prp ._. 
 
The motivation for this approach was that 
Hungarian has a very rich morphology with 
thousands of possible inflected forms for each 
word in the open word classes. In addition, many 
English function words, such as prepositions, 
possessive and other pronouns etc. correspond to 
bound morphemes in Hungarian, which makes 
already the word alignment part of the Moses 
training procedure a difficult task. It is difficult 
capture generalizations like the ones above using 
a word form based representation. There are also 
systematic morpheme order differences between 
these corresponding morphemes: the inflectional 
suffixes (or postpositions) corresponding to Eng-
lish prepositions follow noun phrases rather than 
preceding them and the same applies to posses-
sive pronouns and subject pronouns (the latter 
corresponding to verb agreement suffixes). We 
hoped that these difficulties could be addressed 
by a morpheme based solution adequately. 
The phrase table was built using the default 
grow-diag-final heuristic from Giza++ align-
ments that we acquired from the morpheme 
based representation of the corpus. We used the 
default settings for Giza++. We also used a lexi-
calized reordering table. The distortion parameter 
was left at the default value. We also analyzed 
and tried to use a 5-gram language model built 
from the monolingual English corpus that was 
published as part of the WMT09 shared transla-
tion task training material but the resulting model 
was too big to be loaded into the 3GB RAM of 
the machine that we used in our experiments. We 
tried to use IRSTLM instead of SRILM but we 
did not manage to solve the memory overload 
problem. So in the end we used a 5-gram mor-
pheme based language model that was built from 
the English side of the bilingual training corpus 
only. 
We run the MERT parameter optimization 
procedure using a morpheme based BLEU score 
computed on the morpheme segmented version 
of the WMT09 Hungarian to English tuning set. 
MERT took several days to run. 
4.2 Results 
We used the parameter settings suggested by 
the (morpheme BLEU score based) MERT opti-
mization and generated English surface word 
forms using morphg. We expected that the mor-
pheme based solution would pose a new prob-
lem: that of misplaced morphemes in the output 
that do not correspond to any valid surface word 
form. In such cases we resorted to skipping the 
misplaced morpheme, although this is obviously 
not an optimal solution. 
The BLEU score we obtained on the detoken-
ized output was not very encouraging, to put it 
mildly: 7.82. When we rerun the decoder with 
the parameter settings obtained from a previous 
broken down MERT session, we obtained 
somewhat better results: 7.95. But this is still 
very far from the 9.96/10.10 points achieved by 
MetaMorpho and the hybrid solution. Inspection 
of the translation results confirmed that the trans-
lations generated by the morpheme based setup 
are far inferior to those generated by our rule 
based system. 
Inspecting Giza++ alignments revealed that, 
contrary to our hopes, segmenting the training 
corpus into morphemes did not in itself solve the 
word alignment quality problem: the alignments 
look even worse than those achieved on the plain 
text version of the corpus. On the other hand, all 
the drawbacks of the approach that we predicted: 
reduced span of local dependencies in the lan-
guage models and the phase table due to the in-
creased number of tokens spanning the same 
span of input, misplaced morphemes, etc. seem 
to have hit us. 
5 Conclusion 
In this article, we described the rule based, hy-
brid and statistical systems that we implemented 
and used in the WMT09 shared translation task.  
Although we only managed to slightly im-
prove the performance of our rule based machine 
translation system in our hybrid experiment and 
158
with our first attempt at a morpheme based statis-
tical system we obtained more modest results 
than we hoped, we think that it is still worth to 
make further attempts to build better translation 
systems for the Hungarian English language pair 
along these lines.  
 
Acknowledgments 
This research has been supported by the Euro-
pean Commission in the FP6-IST project Euro-
Matrix. We also would like to thank L?szl? Laki 
and Borb?la Sikl?si for the work they have put 
into the statistical system that we built. 
References 
P?ter Hal?csy, Andr?s Kornai, and Csaba Oravecz. 
2007. HunPos ? an open source trigram tagger In: 
Proceedings of the 45th Annual Meeting of the As-
sociation for Computational Linguistics Compan-
ion Volume Proceedings of the Demo and Poster 
Sessions, Association for Computational Linguis-
tics, Prague, Czech Republic, 209?212. 
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris 
Callison-Burch, Marcello Federico, Nicola Ber-
toldi, Brooke Cowan, Wade Shen, Christine 
Moran, Richard Zens, Chris Dyer, Ondrej Bojar, 
Alexandra Constantin, Evan Herbst. 2007. Moses: 
Open Source Toolkit for Statistical Machine Trans-
lation In: Proceedings of the 45th Annual Meeting 
of the Association for Computational Linguistics 
Companion Volume Proceedings of the Demo and 
Poster Sessions, Association for Computational 
Linguistics, Prague, Czech Republic, 177?180. 
Guido Minnen, John Carroll and Darren Pearce. 2001. 
Applied morphological processing of English, 
Natural Language Engineering, 7(3). 207?223. 
Xuan-Hieu Phan. 2006. CRFTagger: CRF English 
POS Tagger, http://crftagger.sourceforge.net/ 
G?bor Pr?sz?ky and Attila Nov?k. 2005. Computa-
tional Morphologies for Small Uralic Languages. 
In: A. Arppe, L. Carlson, K. Lind?n, J. Piitulainen, 
M. Suominen, M. Vainio, H. Westerlund, A. Yli-
Jyr? (eds.): Inquiries into Words, Constraints and 
Contexts Festschrift in the Honour of Kimmo 
Koskenniemi on his 60th Birthday, 116?125. 
Gummerus Printing, Saarij?rvi/CSLI Publications, 
Stanford. 
G?bor Pr?sz?ky and L?szl? Tihanyi. 2002. MetaMor-
pho: A Pattern-Based Machine Translation System. 
In: Proceedings of the 24th 'Translating and the 
Computer' Conference, 19?24. ASLIB, London, 
United Kingdom. 
159
Proceedings of the 7th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, pages 43?48,
Sofia, Bulgaria, August 8 2013. c?2013 Association for Computational Linguistics
Morphological annotation of Old and Middle Hungarian corpora
Attila Nova?k1,2 Gyo?rgy Orosz2 No?ra Wenszky2
1Research Institute for Linguistics, Hungarian Academy of Sciences
Benczu?r u. 33., Budapest, Hungary
2MTA-PPKE Natural Language Research Group
Faculty of Information Technology, Pa?zma?ny Pe?ter Catholic University
Pra?ter u. 50/a, Budapest, Hungary
{novak.attila,oroszgy}@itk.ppke.hu, wenszkynora@gmail.com
Abstract
In our paper, we present a computational
morphology for Old and Middle Hungar-
ian used in two research projects that aim
at creating morphologically annotated cor-
pora of Old and Middle Hungarian. In ad-
dition, we present the web-based disam-
biguation tool used in the semi-automatic
disambiguation of the annotations and the
structured corpus query tool that has a
unique but very useful feature of making
corrections to the annotation in the query
results possible.
1 Introduction
One of the aims of two parallel OTKA projects of
the Research Institute for Linguistics of the Hun-
garian Academy of Sciences1 is to create mor-
phologically analyzed and searchable corpora of
texts from the Old Hungarian and Middle Hungar-
ian period. In the course of the projects, the Hu-
mor Hungarian morphological analyzer (Nova?k,
2003; Pro?sze?ky and Nova?k, 2005) was extended
to be capable of analyzing words containing mor-
phological constructions, suffix allomorphs, suf-
fix morphemes, paradigms or stems that were used
in Old and Middle Hungarian but no longer exist
in present-day Hungarian. In the sections below,
we describe how the morphological analyzer was
adapted to the task, the problems we encountered
and how they were solved. We also present the
automatic and the manual disambiguation system
used for the morphosyntactic annotation of texts
and the corpus manager with the help of which
the annotated corpora can be searched and main-
tained.
1Hungarian historical generative syntax [OTKA
NK78074], and Morphologically analysed corpus of Old and
Middle Hungarian texts representative of informal language
use [OTKA 81189]
2 Preprocessing
The overwhelming majority of extant texts from
the Old Hungarian period are codices, mainly con-
taining texts translated from Latin. The texts se-
lected for the Corpus of Informal Language Use,
however, are much closer to spoken language:
minutes taken at court trials, such as witch tri-
als, and letters sent by noblemen and serfs. In
the case of the latter corpus, metadata belonging to
the texts are also of primary importance, as these
make the corpus fit for historical-sociolinguistic
research.
2.1 Digitization
All the texts selected for our corpora were orig-
inally hand-written. However, the basis for the
digitized version was always a printed edition of
the texts published earlier. The printed texts were
scanned and converted to a character stream us-
ing OCR. This was not a trivial task, especially
in the case of Old Hungarian texts, owing to the
extensive use of unusual characters and diacrit-
ics. In the lack of an orthographic norm, each
text applied a different set of characters; moreover,
the printed publications used different fonts. Thus
the only way to get acceptable results was to re-
train the OCR program2 for each text from scratch
since the out-of-the-box Hungarian language and
glyph models of the software did not fit any of our
texts. Subsequently, all the automatically recog-
nized documents had to be manually checked and
corrected, but even so, this workflow proved to be
much faster than attempting to type in the texts.
2.2 Normalization
The next step of preprocessing was normalization,
i.e. making the texts uniform regarding their or-
thography and phonology. Normalization, which
2We used FineReader, which makes full customization of
glyph models possible, including the total exclusion of out-
of-the-box models.
43
was done manually, in our case meant modern-
ization to present-day orthography. Note that this
also implies differences in tokenization into indi-
vidual words between the original and the normal-
ized version. During this process, which also in-
cluded segmentation of the texts into clauses, cer-
tain phonological dialectal variations were neu-
tralized.
Morphological variation, however, was left un-
touched: no extinct morphemes were replaced by
their present day counterparts. We also retained
extinct allomorphs unless the variation was purely
phonological. In the case of potential irresolvable
ambiguity, the ambiguity was preserved as well,
even if it was due to the vagueness of the orthog-
raphy of the era.
An example of this is the non-consistent mark-
ing of vowel length. The definite and indefinite
3rd person singular imperfect of the frequently
used word mond ?say? was monda? ? monda re-
spectively, but accents are often missing from the
texts. Furthermore, in many texts in the corpus,
these two forms were used with a clearly differ-
ent distribution from their present day counterparts
mondta?mondott. Therefore, in many cases, nei-
ther the orthography, nor the usage was consistent
enough to decide unambiguously how a certain ap-
pearance of monda should be annotated concern-
ing definiteness.
Another example of inherent ambiguity is a di-
alectal variant of possessive marking, which is
very frequent in these corpora and often neutral-
izes singular and plural possessed forms. For ex-
ample, cselekedetinek could both mean ?of his/her
deed? or ?of his/her deeds?, which in many cases
cannot be disambiguated based on the context
even for human annotators. Such ambiguous cases
were annotated as inherently ambiguous regarding
number/definiteness etc.
2.3 Jakab?s databases
Some of the Old Hungarian codices (Jo?kai (Jakab,
2002), Guary (Jakab and Kiss, 1994), Apor (Jakab
and Kiss, 1997), and Festetics (Jakab and Kiss,
2001)) were not digitized using the OCR tech-
nique described above, as these were available in
the form of historical linguistic databases, created
by Jakab La?szlo? and his colleagues between 1978
and 2002. However, the re-creation of the origi-
nal texts out of these lexical databases was a dif-
ficult task. The first problem was that, in the
databases, the locus of word token occurrences
only identified codex page, column and line num-
ber, but there was no information concerning the
order of words within a line. The databases also
contain morphological analyses, but they were en-
coded in a hard-to-read numerical format, which
occasionally was incorrect and often incomplete.
Furthermore, the categorization was in many re-
spects incompatible with our system. However, fi-
nally we managed to re-create the original texts.
First the order of words was manually restored
and incomplete and erroneous analyses were fixed.
Missing lemmas were added to the lexicon of the
adapted computational morphology, and the nor-
malized version of the texts was generated using
the morphology as a word form generator. Finally,
the normalized texts were reanalyzed to get analy-
ses compatible with the annotation scheme applied
to the other texts in the corpora.
3 The morphological analyzer
The digitized and normalized texts have been an-
alyzed with an extended version of the Humor
analyzer for Hungarian. The lexicon of lemmas
and the affix inventory of the program have been
augmented with items that have disappeared from
the language but are present in the historical cor-
pora. Just the affix inventory had to be supple-
mented with 50 new affixes (not counting their al-
lomorphs).
Certain affixes have not disappeared, but their
productivity has diminished compared to the Old
Hungarian era. Although words with these mor-
phemes are still present in the language, they are
generally lexicalized items, often with a changed
meaning. An example of such a suffix is ?At,
which used to be a fully productive nomen actio-
nis suffix. Today, this function belongs to the suf-
fix ?A?s. The (now lexicalized) words, however,
that end in ?At mark the (tangible) result of an ac-
tion (i.e. nomen acti) in present-day standard Hun-
garian, as in falazat ?wall? vs. falaza?s ?building a
wall?.
One factor that made adaptation of the morpho-
logical model difficult was that there are no reli-
able accounts on the changes of paradigms. Data
concerning which affix allomorphs could be at-
tached to which stem allomorphs had to be ex-
tracted from the texts themselves. Certain mor-
phological constructions that had already disap-
peared by the end of the Old Hungarian era were
44
rather rare (such as some participle forms) and of-
ten some items in these rare subparadigms have al-
ternative analyses. This made the formal descrip-
tion of these paradigms rather difficult.
However, the most time consuming task was the
enlargement of the stem inventory. Beside the ad-
dition of a number of new lemmas, the entries of
several items already listed in the lexicon of the
present-day analyzer had to be modified for our
purposes. The causes were various: some roots
now belong to another part of speech, or in some
constructions they had to be analyzed differently
from their present analysis.
Furthermore, the number of pronouns was con-
siderably higher in the examined period than
today. The description of their extensive and
rather irregular paradigms was really challenging
as some forms were underrepresented in the cor-
pora.
Some enhancements of the morphological an-
alyzer made during the corpus annotation projects
were also applicable to the morphological descrip-
tion of standard modern Hungarian. One such
modification was a new annotation scheme ap-
plied to time adverbials that are lexicalized suf-
fixed (or unsuffixed) forms of nouns, like reggel
?morning/in the morning? or nappal ?daytime/in
daytime?, quite a few of which can be modified by
adjectives when used adverbially, such as fe?nyes
nappal ?in broad daylight?. This latter fact sheds
light on a double nature of these words that could
be captured in an annotation of these forms as spe-
cially suffixed forms of nouns instead of atomic
adverbs, an analysis that is compatible with X-bar
theory (Jackendoff, 1977).
4 Disambiguation
With the exception of already analyzed sources
(i.e. the ones recovered from the Jakab databases),
the morphological annotation had to be disam-
biguated. The ambiguity rate of the output of
the extended morphological analyzer on historical
texts is higher than that for the standard Humor
analyzer for present-day corpora (2.21 vs. 1.923
analyses/word with an identical (high) granularity
of analyses). This is due to several factors: (i) the
historical analyzer is less strict, (ii) there are sev-
eral formally identical members of the enlarged
verbal paradigms including massively ambiguous
subparadigms like that of the passive and the fac-
3measured on newswire text
titive,4 (iii) a lot of inherent ambiguities described
above.
The workflow for disambiguation of mor-
phosyntactic annotation was a semi-automatic
process: an automatically pre-disambiguated ver-
sion of each text was checked and corrected manu-
ally. For a very short time, we considered using the
Jakab databases as a training corpus, but recover-
ing them required so much development and man-
ual labor and the analyses in them lacked so much
distinction we wanted to make that we opted for
creating the training data completely from scratch
instead.
4.1 The manual disambiguation interface
To support the process of manual checking and
the initial manual disambiguation of the training
corpus a web-based interface was created using
JavaScript and Ajax where disambiguation and
normalization errors can be corrected very effec-
tively. The system presents the document to the
user using an interlinear annotation format that is
easy and natural to read. An alternative analysis
can be chosen from a pop-up menu containing a
list of analyses applicable to the word that appears
when the mouse cursor is placed over the problem-
atic word. Note that the list only contains gram-
matically relevant tags and lemmas for the word
returned by the morphological analyzer. This is
very important, since, due to the agglutinating na-
ture of Hungarian, there are thousands of possible
tags (see Figure 1).
Figure 1: The web-based disambiguation interface
The original and the normalized word forms as
well as the analyses can also be edited by clicking
them, and an immediate reanalysis by the morpho-
logical analyzer running on the web server can be
initiated by double clicking the word. We use Ajax
technology to update only the part of the page be-
longing to the given token, so the update is imme-
diate. Afterwards, a new analysis can be selected
from the updated pop-up menu.
4This ambiguity is absent from modern standard Hungar-
ian because the passive is not used any more.
45
As there is an inherent difference between the
original and normalized tokenization, and be-
cause, even after thorough proofreading of the nor-
malized version, there may remain tokenization
errors in the texts, it is important that tokens and
clauses can also be split and joined using the dis-
ambiguation interface.
The automatic annotation system was created in
a way that makes it possible that details of the
annotation scheme be modified in the course of
work. One such modification was e.g. the change
to the annotation of time adverbs mentioned in
Section 3 above. The modified annotation can
be applied to texts analyzed and disambiguated
prior to the modification relatively easily. This
is achieved by the fact that, in the course of re-
analysis, the program chooses the analysis most
similar to the previously selected analysis (based
on a letter trigram similarity measure). Neverthe-
less, the system highlights all tokens the reanaly-
sis of which resulted in a change of annotation, so
that these spots can be easily checked manually.
For changes in the annotation scheme where the
simple similarity-based heuristic could not be ex-
pected to yield an appropriate result (e.g. when
we decided to use a more detailed analysis of de-
rived verb forms as before), a more sophisticated
method was devised to update the annotations: old
analyses were replaced using automatically gener-
ated regular expressions.
4.2 Automatic disambiguation
While the first few documents were disambiguated
completely manually using the web-based tool,
we soon started to train and use a tagger for pre-
disambiguation applying the tagger incrementally,
trained on an increasing number of disambiguated
and checked text. First the HMM-based trigram
tagger HunPos (Hala?csy et al, 2007) was used.
HunPos is not capable of lemmatization, but we
used a straightforward method to get a full anal-
ysis: we applied reanalysis to the text annotated
only by the tags assigned by HunPos using the
automatic similarity-based ranking of the analy-
ses. This approach yielded quite good results, but
one problem with it was that the similarity-based
ranking always prefers shorter lemmas, which was
not appropriate for handling the case of a fre-
quent lemma ambiguity for verbs with one of the
lemma candidates ending in an ?ik suffix and the
other lacking a suffix (such as dolgozik ?work? vs.
(fel)dolgoz ?process?). Always selecting the ?ik-
less variant is not a good bet in the case of many
frequent words in this ambiguity class.
Recently, we replaced HunPos with another
HMM-based trigram tagger, PurePos (Orosz and
Nova?k, 2012), that has many nice extra features. It
can process morphologically analyzed ambiguous
input and/or use an integrated analyzer constrain-
ing possible analyses to those proposed by the an-
alyzer or read from the input. This boosts the pre-
cision of the tagger dramatically in the case of lan-
guages like Hungarian and small training corpora.
The fact that PurePos can be fed analyzed input
makes it easy to combine with constraint-based
tools that can further improve the accuracy of the
tagging by handling long distance agreement phe-
nomena not covered by the trigram model or sim-
ply removing impossible tag sequences from the
search space of the tool.
PurePos can perform lemmatization, even for
words unknown to the morphological analyzer
(and not annotated on the input) learning a suffix-
based lemmatization model from the training cor-
pus along with a similar suffix-based tag guessing
model, thus it assigns a full morphological anal-
ysis to each token. It is also capable of generat-
ing an n-best list of annotations for the input sen-
tence when using beam search instead of the de-
fault Viterbi decoding algorithm.
4.3 Disambiguation performance
We performed an evaluation of the accuracy of
PurePos on an 84000-word manually checked
part of the historical corpus using five-fold cross-
validation with a training corpus of about 67000
words and a test corpus of about 17000 words in
each round. The ratio of words unknown to the
MA in this corpus is rather low: 0.32%.
The average accuracy of tagging, lemmatiza-
tion and full annotation for different versions of
the tagger are shown in Table 1. In addition to
token accuracy, we also present sentence accu-
racy values in the table. Note that, in contrast to
the usual way of evaluating taggers, these values
were calculated excluding the always unambigu-
ous punctuation tokens from the evaluation. The
baseline tagger uses no morphological information
at all. Its current lemmatization implementation
uses suffix guessing in all cases (even for words
seen in the training corpus) and selects the most
frequent lemma, which is obviously not an ideal
46
solution.
The disambiguator using morphology performs
significantly better. Its clause-level accuracy is
81.50%, which means that only every fifth clause
contains a tagging error. The tag set we used in
the corpus differentiates constructions which are
not generally differentiated at the tag level in Hun-
garian corpora, e.g. deictic pronouns (ebben ?in
this?) vs. deictic pre-determiners (ebben a ha?zban
?in this house?). Many of these can only be dis-
ambiguated using long-distance dependencies, i.e.
information often not available to the trigram tag-
ger. Combination of the tagger with a constraint-
based tool (see e.g. Hulden and Francom (2012))
would presumably improve accuracy significantly.
In the rightmost column, we listed a theoreti-
cal upper limit of the performance of the current
trigram tagger implementation using 5-best output
and an ideal oracle that can select the best annota-
tion.
baseline morph 5-best+o
token Tag 90.17% 96.44% 98.97%
Lem. 91.52% 98.19% 99.11%
Full 87.29% 95.90% 98.53%
clause Tag 62.48% 83.81% 93.99%
Full 54.68% 81.50% 91.47%
Table 1: Disambiguation performance of the tag-
ger
5 Searching the corpus
The web-based tool we created as a corpus query
interface does not only make it possible to search
for different grammatical constructions in the
texts, but it is also an effective correction tool. Er-
rors discovered in the annotation or the text ap-
pearing in the ?results? box can immediately be
corrected and the corrected text and annotation
is recorded in the database. Naturally, this latter
functionality of the corpus manager is only avail-
able to expert users having the necessary privi-
leges.
A fast and effective way of correcting errors in
the annotation is to search for presumably incor-
rect structures and to correct the truly problematic
ones at once. The corrected corpus can be ex-
ported after this procedure and the tagger can be
retrained on it.
The database used for the corpus manager is
based on the Emdros corpus manager (Petersen,
2004). In addition to queries formulated using
MQL, the query language of Emdros, either typed
in at the query box or assembled using controls
of the query interface, advanced users can use
a custom-made corpus-specific query language
(MEQL), which makes a much more compact for-
mulation of queries possible than MQL. It is e.g.
extremely simple to locate a specific locus in the
corpus: one simply needs to type in the sequence
of words one is looking for. Queries formulated
in MEQL are automatically converted to MQL
queries by the query processor.
The search engine makes it possible to search
inside sentences, clauses, or texts containing
grammatical constructions and/or tagged with
metadata matching the criteria specified in the
query. Units longer than a sentence can also be
searched for. The context displayed by default for
each hit is the enclosing sentence with focus words
highlighted. Clauses may be non-continuous:
this is often the case for embedded subordinate
clauses, but the corpus also contains many injected
parenthetical coordinate clauses and many exam-
ples where the topic of a subordinate clause pre-
cedes its main clause with the net effect of the
subordinate clause being interrupted by the main
clause. The query example in Figure 2 shows a
sentence containing several clauses with gaps: the
clauses enclosed in angle brackets are wedged be-
tween the topic and comment part of the clauses
which they interrupt. Emdros is capable of repre-
senting these interrupted clauses as single linguis-
tic objects with the interrupting clause not being
considered part of the interrupted one.
6 Conclusion
In our paper, we described the most important
steps of the creation of a morphological annota-
tion framework for the analysis of Old and Mid-
dle Hungarian extant texts consisting of a mor-
phological analyzer, an automatic disambiguation
tool and an intuitive web-based manual disam-
biguation tool. Certain problems arising during
this process were discussed together with their so-
lution. We also presented our corpus manager,
which serves both as a structured corpus query tool
and as a correction tool.
The morphological analyzer is used for the an-
notation of the constantly growing Old and Mid-
dle Hungarian corpora. Part of these corpora are
already searchable by the public. The Old Hun-
47
Figure 2: The query interface
garian Corpus is available at http://rmk.nytud.hu,
while the analyzed part of the Historical Corpus
of Informal Language Use can be searched at
http://tmk.nytud.hu.
Acknowledgments
Research reported in this paper was supported by
the research project grants OTKA NK78074 and
OTKA 81189. In addition, we gratefully acknowl-
edge support by the grants TA?MOP-4.2.1./B-
11/2/KMR-2011-002 and TA?MOP-4.2.2./B-10/1-
2010-0014. We would also like to thank anony-
mous reviewers of the paper for their helpful com-
ments and suggestions.
References
Pe?ter Hala?csy, Andra?s Kornai, and Csaba Oravecz.
2007. HunPos: an open source trigram tagger. In
Proceedings of the 45th Annual Meeting of the ACL
on Interactive Poster and Demonstration Sessions,
ACL ?07, pages 209?212, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Mans Hulden and Jerid Francom. 2012. Boost-
ing statistical tagger accuracy with simple rule-
based grammars. In Nicoletta Calzolari (Confer-
ence Chair), Khalid Choukri, Thierry Declerck,
Mehmet Ug?ur Dog?an, Bente Maegaard, Joseph Mar-
iani, Jan Odijk, and Stelios Piperidis, editors, Pro-
ceedings of the Eighth International Conference on
Language Resources and Evaluation (LREC?12), Is-
tanbul, Turkey. European Language Resources As-
sociation (ELRA).
Ray Jackendoff. 1977. X-bar-Syntax: A Study of
Phrase Structure. Linguistic Inquiry Monograph 2.
MIT Press, Cambridge, MA.
La?szlo? Jakab and Antal Kiss. 1994. A Guary?-ko?dex
a?be?ce?rendes adatta?ra. Sza?m??to?ge?pes nyelvto?rte?neti
adatta?r. Debreceni Egyetem, Debrecen.
La?szlo? Jakab and Antal Kiss. 1997. Az Apor-ko?dex
a?be?ce?rendes adatta?ra. Sza?m??to?ge?pes nyelvto?rte?neti
adatta?r. Debreceni Egyetem, Debrecen.
La?szlo? Jakab and Antal Kiss. 2001. A Festetics-ko?dex
a?be?ce?rendes adatta?ra. Sza?m??to?ge?pes nyelvto?rte?neti
adatta?r. Debreceni Egyetem, Debrecen.
La?szlo? Jakab. 2002. A Jo?kai-ko?dex mint nyelvi
emle?k: szo?ta?rszeru? feldolgoza?sban. Sza?m??to?ge?pes
Nyelvto?rte?neti Adatta?r. Debreceni Egyetem, Debre-
cen.
Attila Nova?k. 2003. Milyen a jo? Humor? [What
is good Humor like?]. In I. Magyar Sza?m??to?ge?pes
Nyelve?szeti Konferencia, pages 138?144, Szeged.
SZTE.
Gyo?rgy Orosz and Attila Nova?k. 2012. PurePos ? an
open source morphological disambiguator. In Pro-
ceedings of the 9th International Workshop on Nat-
ural Language Processing and Cognitive Science.,
Wroclaw, Poland.
Ulrik Petersen. 2004. Emdros ? a text database en-
gine for analyzed or annotated text. In In: Proceed-
ings of COLING 2004. (2004) 1190?1193.
Ga?bor Pro?sze?ky and Bala?zs Kis. 1999. A unification-
based approach to morpho-syntactic parsing of ag-
glutinative and other (highly) inflectional languages.
In Proceedings of the 37th annual meeting of the
Association for Computational Linguistics on Com-
putational Linguistics, ACL ?99, pages 261?268,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Ga?bor Pro?sze?ky and Attila Nova?k. 2005. Compu-
tational Morphologies for Small Uralic Languages.
In Inquiries into Words, Constraints and Contexts.,
pages 150?157, Stanford, California.
48
Proceedings of the Second Workshop on Hybrid Approaches to Translation, pages 42?50,
Sofia, Bulgaria, August 8, 2013. c?2013 Association for Computational Linguistics
An English-to-Hungarian Morpheme-based Statistical Machine
Translation System with Reordering Rules
La?szlo? J. Laki, Attila Nova?k, Borba?la Siklo?si
MTA-PPKE Language Technology Research Group
Pa?zma?ny Pe?ter Catholic University, Faculty of Information Technology
50/a Pra?ter Street, 1083 Budapest, Hungary
{surname.firstname}@itk.ppke.hu
Abstract
Phrase-based statistical machine transla-
tion systems can generate translations of
reasonable quality in the case of language
pairs with similar structure and word or-
der. However, if the languages are more
distant from a grammatical point of view,
the quality of translations is much behind
the expectations, since the baseline trans-
lation system cannot cope with long dis-
tance reordering of words and the mapping
of word internal grammatical structures.
In our paper, we present a method that tries
to overcome these problems in the case of
English-Hungarian translation by apply-
ing reordering rules prior to the translation
process and by creating morpheme-based
and factored models. Although automatic
evaluation scores do not reliably reflect the
improvement in all cases, human evalua-
tion of our systems shows that readabil-
ity and accuracy of the translations were
improved both by reordering and applying
richer models.
1 Introduction
Phrase-based statistical machine translation sys-
tems rely on statistical observations derived from
phrase alignments automatically extracted from
parallel bilingual corpora. The main advantage of
applying SMT is its language-independence. The
phrase-based model works well for language pairs
with similar syntactic structure and word order.
However, phrase-based models fail to handle
great word-order differences adequately. We de-
scribe our attempt to improve performance by
transforming source language (English) sentences
to a structure similar to that of the corresponding
target (Hungarian) sentence. We also describe our
approach for handling data sparseness due to the
inadequate coverage of linguistic structures by the
limited training corpus. It is a common problem in
the case of translation to agglutinating languages
like Hungarian, where a much greater amount of
training data would be necessary to provide ade-
quate statistics than what is necessary for closely
related language pairs involving only morphologi-
cally less complex languages.
2 Machine Translation from English to
Hungarian
English and Hungarian are rather distant regarding
morphological and syntactic structure and word
order. Hungarian, like Finish or Turkish, is an
agglutinating and compounding language, which
morphological processes yield a huge number of
different word forms. This, combined with free
word order of main grammatical constituents and
systematically different word order in NP?s and
PP?s, results in poor performance of traditional
phrase-based SMT systems. In order to have an
SMT system produce correct translations of high
quality, it is required to have a relevant statisti-
cal model acquired from bilingual corpora. Thus,
even if a corpus of a substantial size were available
(which is not the case), both the alignment phase
of constructing a translation model and translation
itself would be compromised by the high number
of seldom or never seen word forms.
3 Related work
For language pairs having very different syntactic
structure and word order, research has shifted to-
wards using hierarchical models or the use of hy-
brid methods, such as augmenting purely statisti-
cal approaches by handmade rules as a preprocess-
ing step. Such extensions have proved to improve
results significantly in systems translating from
English to German, Arabic or Turkish and several
other languages (Yeniterzi and Oflazer, 2010; Go-
42
jun and Fraser, 2012; Collins et al, 2005). The
hybrid models applied to English-Hungarian ma-
chine translation that we present in this paper be-
long to the latter line of research.
We applied both reordering and morphological
segmentation in order to handle both word order
problems and data sparseness caused by agglu-
tination. Luong et al (2010) applied only mor-
phological analysis in the case of translation from
English to Finnish. On the other hand, Yeniterzi
and Oflazer (2010) described an approach for En-
glish to Turkish translation, in which they applied
both syntactic source-side reordering and morpho-
logical segmentation. In their work, morphemes
constructing a single word were joined during the
translation process, but in our experiments, this
method increased data sparseness in the training
set, decreasing the quality of the final translation
rather than improving it. Another difference be-
tween Yeniterzi and Oflazer (2010)?s and our work
is that they applied the morphological generator
integrated in the SMT system, while we used our
computational morphology on SMT output as a
word form generator, generating final word forms
in cases, where the SMT system was not able to
find it.
Relying on recent trends and results of research
in the field of machine translation, we believe that
neither a purely rule-based nor a statistical method
by itself is an optimal way to handle the problem.
Our work reflects this attitude by applying hand-
made language-specific rules. Some works, such
as (Jiang et al, 2010; Holmqvist et al, 2012; Gen-
zel, 2010) have also tried deriving such reordering
rules automatically.
A further method to apply would be using a hi-
erarchical tree-based translation system, also aug-
mented by reordering rules and morphological
segmentation. Such a method is presented in (Gao
et al, 2011), but focusing on a narrower problem
and applying it to Chinese to English translation.
4 Hybrid morpheme-based machine
translation system with reordering
rules
In order to mitigate the aforementioned difficulties
regarding word order and data sparseness, we cre-
ated a hybrid system with different preprocessing
and decoding solutions. First we applied reorder-
ing rules in order to transform the source sentence
to a structure more appropriate for word alignment
Test Train
# of sentences 1000 1,026,836
Words
(AVG per sent.)
en 14.137 14.173
hu 11.672 11.764
Morphemes
(AVG per sent.)
en 16.764 16.768
hu 18.391 18.429
Table 1: Size of training and test datasets mea-
sured in the number of sentences, average number
of words per sentences and the average number of
morphemes per sentences on the English and Hun-
garian sides.
and phrase extraction. The problem of lexical
granularity (i.e. the relatively substantial differ-
ence in the number of words in the corresponding
sentences, see Table 1) was also to be solved. We
explored two approaches: a) increasing the num-
ber of tokens on both sides using morphemes in-
stead of words and b) decreasing the number of
word tokens on the English side to approximate
that of the corresponding Hungarian sentences.
4.1 Reordering rules
In order to augment the phrase-based SMT sys-
tem, we defined reordering rules as a preprocess-
ing step. The goal of these transformations is to
move words in the English source sentence to po-
sitions that correspond to their place in the Hun-
garian translation. Fig. 1 illustrates the trans-
formation process on the phrase the sons of the
many merchants living in the city. E.g., the sub-
phrase living in the city is transformed to the order
the city in living corresponding to the Hungarian
translation ?a va?ros+ban e?lo?? as shown in Fig. 1a.
Our rules apply only to those word order differ-
ences, which are systematically present between
the two grammars (e.g. prepositions vs. case end-
ings/postpositions). We did not intend to handle
free word order variations of Hungarian, where the
same meaning can be expressed with several dif-
ferent orderings, since the actual word order in a
sentence is not only determined by syntactic rules,
but also by pragmatic factors.
Dependency structure: Reordering rules are
guided by dependency relations. After generat-
ing a context-free parse, these relations are ex-
tracted by the Stanford parser (Marneffe et al,
2006) that we used in our experiments. The depen-
dency structure of our example is shown in Fig. 1b.
Thus the example phrase merchants living in
the city is transformed along the relations PART-
43
(a) Word alignment of a sentence pair before and after reorder-
ing
(b) Dependency structure of the sentence: The sons of the many
merchants living in the city
(c) The process of reordering along dependency relations.
Figure 1: Word alignment, dependency relations and reordering
MOD(merchant, living)1, PREP(living, in)1 and
POBJ(in, city)1. First the preposition is attached
to the child of the POBJ relation, then they are
positioned before the noun phrase preceding it as
shown in Fig. 1c. The resulting word order the city
in living merchants corresponds to the Hungarian
structure ?a va?ros+ban e?lo? kereskedo?k?.
Since these levels of analysis depend on each
other, errors arising at each phase propagate and
cumulate through the whole process having a sig-
nificant effect on reordering. Even though we
used the lexicalized version of the Stanford parser,
which is reported to work more accurately, it
still very often generates agrammatical parses with
agreement errors and odd PoS sequences as shown
in Table 2 (showing only the generated PoS tag se-
quences here).
1PARTMOD=participial modifier, PREP=prepositional
modifier, POBJ=object of preposition. The full
list of dependency relations can be found in
http://nlp.stanford.edu/software/
dependencies_manual.pdf
-/: 100/CD million/CD sound/NN good/JJ
to/TO me/PRP ./.
For/IN airline/NN personnel/NNS ,/, we/PRP
cash/NN personal/JJ checks/VBZ up/RP
to/TO $/$ 100/CD ./.
Table 2: Examples of low level errors (verbs
tagged as nouns and vice versa) that affect reorder-
ing and translation
Morpheme-based restructuring: Due to the
agglutinating nature of Hungarian, many func-
tion words in English are expressed as suffixes
in the Hungarian translation. In order to enable
the phrase-based system to have them correspond
to each other, we applied morphological analy-
sis on the Hungarian sentences segmenting each
word to their morphological constituents. To an-
notate the Hungarian side of the corpus, we used
the PurePos automated morphological annotation
system (Orosz and Nova?k, 2012). A simple ex-
ample is a phrase like in my house, which is
44
transformed to the form house my in correspond-
ing to the single word ?ha?zamban? in Hungarian.
The morphological segmentation of this word is
ha?z[N]+am[PxS1]+ban[Ine]1. Defining and ap-
plying the rules for such short phrases is not partic-
ularly difficult. However, related words in longer
sentences can be much further separated from each
other and they may be involved in more than one
relation, which often results in an interaction of
word order constraints. In a similar manner, some
rules insert morphological elements correspond-
ing to those present in the Hungarian sentence,
but not explicitly expressed in English, such as
the accusative case suffix or subject agreement of
verbs. These pieces of implicit structural informa-
tion can be induced from the dependency relations.
For example, in the English phrase giving/VBG
a/DT present/NN, the word present is tagged as
acc (based on its object role) corresponding to the
Hungarian accusative -t suffix resulting in the re-
ordered phrase of giving a present+acc now per-
fectly aligning to the Hungarian structure of ?adni
egy aja?nde?k+ot?
4.2 Lexical granularity
The number of words is often rather different in a
pair of Hungarian and English sentences enforcing
the alignment module of the SMT system to cre-
ate one-to-many or many-to-many alignments, or
simply leave tokens unaligned. Such alignments
often result in missing or ?hallucinated? words in
the translation. Table 1 shows the differences in
the average number of words and morphemes in
our parallel corpus. The average number of words
is smaller in Hungarian than in the English sen-
tences. On the other hand, at least at the granu-
larity of the morphological analysis we applied to
our data, the number of morphemes is higher in
Hungarian than in English. The number of tokens
on both sides can be made more similar by either
decreasing the number of words on the English
side by joining function words corresponding to
Hungarian suffixes or by increasing the number on
both sides using morphemes as tokens.
As the difference is primarily due to the fact
that some English function words are represented
as suffixes in Hungarian, the relative difference
between the number of morphemes in the cor-
responding sentences is lower than that of the
words. So one possible approach to solving the
1PxS1=Possessor:1Sg=?my?, Ine=Inessive=?in?
lexical granularity difference problem is to use
morphemes instead of words. One problem with
morpheme-based translation is that it is often the
case in longer sentences that instances of the same
functional morpheme belong to more than one dif-
ferent word in the sentence. This causes inde-
terminacies in the alignment process (because the
models implemented in the Giza++ word aligner
cannot be forced to assume locally monotone
alignment at the places where we in fact know that
the alignment should be monotone), which often
results in erroneous phrases being extracted from
the training corpus. For example, if there are two
nouns in a sentence and one of them is plural, then
the [PL] tag corresponding to this feature might
land at another noun.
The difficulty of aligning very frequent func-
tional morphemes is illustrated by the fact that
in the Giza++ alignments created from our train-
ing corpus, 39% of the nominal plural ([PL])
morphemes remained unaligned, 13% was not at-
tached to the noun it should have been attached to,
because the alignment was not monotone, while
1% was aligned to several (up to eight) instances
of the corresponding morpheme. Alignment is not
the only problem: some indivisible morpheme se-
quences (like noun+plural) should always stay to-
gether but we had concerns that, unless it is con-
strained to monotone decoding, the baseline dis-
tortion model of the decoder will often scatter suf-
fixes throughout the sentence instead. A lexical-
ized reordering model can be expected to solve
this problem, thus we used lexical reordering in
our models but for comparison we also tested how
each model performs when the decoder is con-
strained to monotone decoding.
Another approach we tested was fusing sepa-
rate words on the English side that correspond to
a single word in the Hungarian sentence (model-
ing English as an agglutinating language) to avoid
the aligner connecting these morphemes to some
other words on the Hungarian side and using a
factored model to try to solve the data sparse-
ness issues this move results in. For example,
possessive determiners are attached to the head
noun as suffixes in this model like the correspond-
ing possessive suffixes in Hungarian : the phrase
my/PRP$ own/JJ mother/NN is transformed to the
form own/JJ mother/NN my/PRP$, which corre-
sponds to the Hungarian phrase saja?t anya? m.
By applying either of the morpheme-token-
45
based or the factored morphosyntactic-feature-
based solution, the translations generated by the
SMT system contain sequences of lemmas and
morphosyntactic tags, thus, in order to get the fi-
nal form of the translated sentence, the surface
form of the words have to be generated from the
morpheme sequence. In our experiments, we ap-
plied the word form generator module of the Hu-
mor morphological analyzer to the output of the
decoder (Nova?k, 2003; Pro?sze?ky and Kis, 1999).
4.3 Factored translation
The Moses SMT toolkit (Koehn et al, 2007),
which we used in our experiments, is suitable for
implementing factored translation models. Instead
of relying on just the surface form of the words,
further annotations such as morphological analy-
sis can be used in the process of a factored trans-
lation. Translation factors might be the surface
form of each word, its lemma, its main PoS tag
and its morphosyntactic features. During factored
translation, there is an opportunity to use multiple
translation models, generation models or contex-
tual language models. Since the system has the
possibility to use any combination of these, in the-
ory it is able to generate better translations using
sparse linguistic data than a word-based baseline
system. This feature is vital in cases where some
abstraction is necessary, because some words in
the sentence to be translated or generated are miss-
ing from the training set.
To see how well a factored model performs in
the case of translation to an agglutinating lan-
guage, we also trained a factored translation sys-
tem combined with our reordering rules. The fac-
tors in our case were of the form: lemma/PoS |
PoS+morphtags, where PoS is the main part-
of-speech tag and morphtags are the rest of the
morphological features and extra morphemes at-
tached to the word as described in Section 4.2.
Training the system with this combination of fac-
tors to handle data sparseness issues seems reason-
able in theory; however, translation of lexical and
grammatical factors is compromised by a serious
weakness of the factored translation implementa-
tion in Moses. If the two factors are treated as con-
nected at training time, then if a certain combina-
tion of a lemma and its morphology is not present
in the translation models, which is very frequent in
the case of an agglutinating language, then it can
not be translated even if both the lemma and the
morphological feature set are represented in the
training corpus separately. In such cases none of
the factors are translated and the source word is
copied to the output untranslated.
Another method of training a factored model is
to translate factors independently. This could in-
deed solve data sparseness problems, but, as we
noted during our experiments, another problem
arises in this case: at translation time, translations
of morphological tags often land at wrong lem-
mas. This is due to the fact when translating a
phrase, the system selects a translation having one
word order, e.g. [Det N V], for one factor (the lem-
mas) and another, e.g. [V Det N] for the other (the
morphosyntactic tags). This results in ill-formed
structures, such as nominal morphosyntactic fea-
tures landing on verbs and verbal morphosyntac-
tic features landing on nouns etc., thus, although
the translation might contain the relevant transla-
tions regarding both lemmas and morphological
features, the final sentence will be an inconsistent
mixture of them, making generation of the right
word forms impossible. Due to word order vari-
ations in Hungarian, this situation turned out to
be rather frequent, affecting 21% of our 1000 test
sentences.
In order to improve translations compromised
by inconsistent mapping of lemmas and morphol-
ogy, we introduced a postprocessing step extract-
ing and restoring the proper positions of the mor-
phological tags in the result of factored transla-
tions. Relying on the alignment information, the
proper position of each morphological tag in the
sequence can be found. At translation time, Moses
can output which source words each target phrase
was translated from. We introduced two auxil-
iary factors to the phrase table that represent align-
ments of our two main factors. If the alignments in
the two factors mismatch, we can realign them us-
ing the auxiliary alignment factors (using the word
order in the lemma factor as pivot). Once having
the factors rematched, the two factors of the target
translation are unified and the morphological gen-
erator can be applied to generate the final word
forms. As it is evident from the evaluation data
presented in Section 5, the realignment of factors
consistently improved the quality of translations
produced by all factored models.
46
5 Experiments and results
We performed experiments on word-based,
morpheme-based and factored translations from
English to Hungarian with and without applying
our reordering rules as a preprocessing step. We
also contrasted the performance of our experi-
mental systems with that of some commercial
systems: the rule-based MetaMorpho (Nova?k
et al, 2008; Nova?k, 2009) and the major com-
mercial translation services, Google Translate
and Bing Translator, which apply their language
independent statistical systems trained on huge
parallel corpora. Low BLEU scores of translations
generated by these systems (compared to those
usually obtained for other languages) indicate
that machine translation to Hungarian is indeed a
difficult task.
In all of our experiments, the Moses (Koehn et
al., 2007) toolkit was used for building the trans-
lation models and performing the translation task
itself, using IRSTLM (Federico et al, 2008) to
build language models. Wherever it was neces-
sary, PurePos (Orosz and Nova?k, 2012) was used
for morphological analysis and generation, and the
Stanford Parser (Marneffe et al, 2006) for con-
stituent and dependency parsing.
5.1 Datasets
As training data, we used the Hunglish (Varga et
al., 2005) corpus, created by BME MOKK2 and
the Research Institute for Linguistics of the Hun-
garian Academy of Sciences. This corpus contains
parallel texts from the following domains: litera-
ture and magazines, legal texts and movie subti-
tles. There is a great degree of variation in the
quality of different parts of the corpus. We auto-
matically eliminated sentence pairs from the cor-
pus that caused technical problems, but overall
translation quality was not checked.
The corpus we used for training the sys-
tem consists of 1,026,836 parallel sentences
with 14,553,765 words on the English side and
12,079,557 on the Hungarian side. For testing pur-
poses, a 1000-sentence-long portion was selected
from the same corpus with one reference transla-
tion. Automatic evaluation was performed on this
set using the BLEU evaluation metric. Results for
each system are listed in Table 3.
2MOKK Centre for Media Research and Education at
the Department of Sociology and Communication, Budapest
University of Technology and Economics
5.2 Baseline systems
We built a word-based, a morpheme-based, and a
factored baseline system (featured as w, m and f in
Table 3), not using the reordering rules described
in Section 4.1, each trained using Moses.
For the word-based baseline model w, the only
preprocessing we applied was standard tokeniza-
tion and lowercasing. A phrase table with a phrase
length limit of 7 was extracted, and a 5-gram lan-
guage model was built. A lexicalized reordering
model with a distortion limit of 6 was used in this
baseline model (and all other models with non-
monotone decoding).
We evaluated this system using two automatic
metrics: the usual word-based BLEU (w-BLEU)
and, in order to have a relevant base of compari-
son to the other systems, a morpheme-based score
(mm-BLEU), which in the case of the word-based
baseline was computed applying morphological
analysis to the translations. mm-BLEU is based on
counts of identical abstract morpheme sequences
in the generated and the reference translations in-
stead of identical word sequences. Note that this
differs from m-BLEU as used in e.g. (Clifton and
Sarkar, 2011), which is BLEU applied to pseudo-
morphs generated by an unsupervised segmenter.
mm-BLEU measures the ability of the system to
generate the correct morphemes in the transla-
tions.
The second baseline system m was trained on
morphologically segmented sentences, thus the
output of the decoder is a sequence of morphemes.
A BLEU score computed on the output of the de-
coder in this case is mm-BLEU. The morpholog-
ical generator was applied to the output of the
Moses decoder in order to acquire the final word
forms. The morpheme-based system m performed
better in terms of mm-BLEU, although it got a
lower w-BLEU score.
The third, factored baseline model f was outper-
formed by the two other models both in terms of
w-BLEU and mm-BLEU, even when the problem
caused by a different word order in the factors was
fixed as described in Section 4.3 (the system fx).
5.3 Reordered models
Based on considerations described in Sections 4.1
and 4.2, we performed reordering as a prepro-
cessing step both at training and translation time.
Models using this configuration were also evalu-
ated applying the same w-BLEU and mm-BLEU
47
ID w-BLEU mm-BLEU
w-based baseline (w) 14.57% 59.32%
m-based baseline mon. (mm) 11.69% 63.18%
m-based baseline (m) 12.19% 63.87%
factored baseline monotone
(fm)
9.70% 56.00%
factored baseline mon. fixed
(fmx)
9.84% 57.09%
w-based reord. (wre) 14.83% 58.06%
w-based reord. joined (wre ) 13.05% 57.21%
m-based reord. mon. (mrem) 12.01% 64.24%
m-based reord. (mre) 12.22% 64.94%
fact. reord. mon. (frem) 10.50% 59.56%
fact. reord. mon. fixed
(fremx)
10.64% 60.28%
fact. reord. (fre) 10.78% 59.97%
fact. reord. fixed (frex) 10.88% 60.83%
Google Translate (goo) 15.68% 55.86%
Bing Translator (bing) 12.16% 53.05%
MetaMorpho (mmo) 6.86% 50.97%
Table 3: Automatic evaluation scores for systems
tested in the experiments.
metrics. We implemented various morpheme-
based, factored and word-based reordered mod-
els. The two word-based setups performed the
same transformations moving function words, the
difference between the two was only whether the
moved words were kept as distinct words (wre) or
joined to the target word as suffixes to form a sin-
gle word form (wre ). The models allowed further
reordering during decoding using a lexicalized re-
ordering model.
The morpheme-based (mre) and the factored
models (fre and frex, the latter with factor mis-
alignment fixed) were contrasted with alterna-
tive setups where the decoder was constrained
to monotone decoding (mrem, frem, fremx). We
had concerns that in the case of the morpheme-
based model the decoder might move suffixes to
incorrect positions. However, using a lexicalized
reordering model prevented these problems and
the systems with reordering during decoding per-
formed consistently better. Monotone decoding
blocked the decoder from fixing word order in the
preverbal field of the comment part of Hungarian
sentences, where strict word order constraints ap-
ply in contrast to the free word order of the topic
and the postverbal part of the comment. While our
reordering rules did not capture these constraints
depending on various subtle features of the actu-
ally selected translation that cannot be reliably in-
ferred from the English original, the lexically con-
strained reordering performed by the decoder did
manage to generate translations that conformed to
them at least to some extent.
The results presented in Table 3 show that the
reordered wre, mre and frex models obtained con-
sistently higher BLEU scores than the correspond-
ing baseline models (the only exception being the
mm-BLEU score of the wre model). Although
the BLEU scores do not show this clearly, the
translations generated by the wre model are far
worse than the output of any other system due to
a high number of untranslated ?agglutinating En-
glish? words with function words attached to con-
tent words as suffixes.
Figure 4 shows the translation results of our dif-
ferent systems. As it can be seen, mre performed
the best, regarding fluency and reflecting the orig-
inal meaning.
6 Human evaluation
It has been shown that system rankings based on
single reference BLEU scores often do not cor-
respond to how humans evaluate the translations.
For this reason, automatic evaluation has for a
long time not been used to officially rank systems
at Workshops on Statistical Machine Translation
(WMT) (Callison-Burch et al, 2007). In our work,
we presented results of automated evaluation us-
ing a single reference BLEU metrics, but we also
investigated translations generated by each sys-
tem using human evaluation, applying the ranking
scheme used at WMT workshops to officially rank
systems.
300 sentences were randomly chosen from the
test set for the purpose of human evaluation.
Five annotators evaluated translations generated
by each of the above described systems plus the
reference translation in the corpus with regard to
translation quality (considering both adequacy and
fluency in a single quality ranking). The order of
translations was randomized for each sentence and
a balanced number of comparisons was performed
for each system pair. The systems were ranked
based on a score that was defined as the number
of times the output of a system was deemed not
worse than that of the other in pairwise compar-
isons divided by the number of pairwise compar-
isons. The aggregate results of human evaluation
are listed in Table 5.
Manual investigation of the translation outputs
revealed that the system incorporating morpholog-
ical and syntactic information are better at captur-
ing grammatical relations in the original text and
rendering them in the translation by generating the
48
original English After you were picked up at sea , our listening post in Malta intercepted that fax .
reordered English after/[IN] you/[PRP] be/[VB] [Past] pick/[VB] [PPart] up/[RP] at/[IN] sea/[NN] ,/[,]
our/[PRP$] listen/[VB] [ING] post/[NN] in/[IN] malta/[NNP] intercept/[VB] [PPart] that/[DT]
fax/[NN] ./[.]
morpheme based
translation
miuta?n/[KOT] felvesz/[IGE] [Past] [t3] [Def] maga/[FN NM] [e3] [ACC] a/[DET] tenger/[FN]
[SUP] ,/[PUNCT] hallgat/[IGE] [Past] [e3] [Def] a/[DET] hely/[FN] [PSt1] ,/[PUNCT]
hogy/[KOT] ma?lta/[FN] [INE] a?ll/[IGE] [Past] [e3] [Def] ez/[FN NM] [ACC] a/[DET] fax/[FN]
[ACC] ./[PUNCT]
final translation Miuta?n felvette?k maga?t a tengeren , hallgatta a helyu?nk , hogy ma?lta a?llta ezt a faxot .
back-translation After you were picked up at sea, our listening post caught the fax in Malta.
baseline translation Azuta?n , hogy felvette a tengeren , a ma?ltai hallgatta az emelkedo? , hogy fax .
back-translation After you, he picked it up at the sea, and that Malta were caught, that it is a fax.
Hungarian reference Miuta?n o?nt kihala?szta?k , ezt fogta?k el egy ma?ltai posta?n .
back-translation After you were fished out, this was caught at a post in Malta.
Table 4: Translation results of our systems with hand made backtranslations for comparison with the
reference.
ref mmo goo bing mre frex m fx w wre wre
88.33 76.30 72.80 61.66 55.60 55.42 54.28 52.03 51.33 50.89 37.57
Table 5: Human evaluation ranking of systems measured as percentage of generating a translation not
worse than the other in pairwise comparisons
appropriate inflected forms. Rule-based reorder-
ing also improved quality when using linguisti-
cally rich models. The only ones that performed
worse than the baseline were the word-based re-
ordered solutions, especially the one based on
?agglutinating English?, the poor performance of
which came as no surprise. BLEU scores do not
correspond well to human judgments. Of our
models, the wre system had the highest BLEU
score, however, human evaluation ranked that
worse than any of the morpheme-based systems.
Moreover, MetaMorpho, the commercial system
having highest rank had by far the lowest BLEU
score.
Considering all the systems in the ranking pro-
cedure, it can be observed that the reference trans-
lation used also for measuring BLEU score does
not always represent the best translation either
according to our evaluators. It is worth not-
ing though that there was a rather significant
variance in the ranking of reference translations
due to some evaluators ranking them much less
favourably than others (75.29% vs. 92.98%).
7 Conclusion
We performed several experiments on English-
Hungarian machine translation. Automatic eval-
uation consistently scored models including rule-
based reordering higher than systems not includ-
ing it. Human evaluation confirmed that applying
reordering and morphological segmentation does
improve translation quality in the case of translat-
ing to an agglutinating language like Hungarian.
Our models are not yet on par with commer-
cial systems. The rather limited amount of train-
ing corpus that also has serious quality problems
is certainly one factor playing a role in this. Our
future plans include enlarging and improving our
training corpus, improving alignment and compo-
nents of the syntactic annotation and reordering
chain as well as experimenting with combination
of morpheme-based and factored models.
Acknowledgement
This work was partially supported by TA?MOP ?
4.2.1.B ? 11/2/KMR-2011-0002 and TA?MOP ?
4.2.2./B ? 10/1-2010-0014.
References
Chris Callison-Burch, Cameron Fordyce, Philipp
Koehn, Christof Monz, and Josh Schroeder. 2007.
(Meta-)evaluation of machine translation. In Pro-
ceedings of the Second Workshop on Statistical
Machine Translation, StatMT ?07, pages 136?158,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Ann Clifton and Anoop Sarkar. 2011. Combin-
ing morpheme-based machine translation with post-
processing morpheme prediction. In Proceedings of
the 49th Annual Meeting of the Association for Com-
putational Linguistics: Human Language Technolo-
gies - Volume 1, HLT ?11, pages 32?42, Stroudsburg,
49
PA, USA. Association for Computational Linguis-
tics.
Michael Collins, Philipp Koehn, and Ivona Kuc?erova?.
2005. Clause restructuring for statistical machine
translation. In Proceedings of the 43rd Annual
Meeting on Association for Computational Linguis-
tics, ACL ?05, pages 531?540, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Marcello Federico, Nicola Bertoldi, and Mauro Cet-
tolo. 2008. Irstlm: an open source toolkit for
handling large scale language models. In INTER-
SPEECH, pages 1618?1621.
Yang Gao, Philipp Koehn, and Alexandra Birch. 2011.
Soft dependency constraints for reordering in hier-
archical Phrase-Based translation. In Proceedings
of the 2011 Conference on Empirical Methods in
Natural Language Processing, pages 857?868, Ed-
inburgh, Scotland, UK., jul. Association for Compu-
tational Linguistics.
Dmitriy Genzel. 2010. Automatically learning source-
side reordering rules for large scale machine transla-
tion. In COLING, pages 376?384.
Anita Gojun and Alexander Fraser. 2012. Determin-
ing the placement of German verbs in English-to-
German SMT. In Walter Daelemans, Mirella La-
pata, and Llus Mrquez, editors, EACL, pages 726?
735. The Association for Computer Linguistics.
Hieu Hoang. 2007. Factored translation models. In
In Proceedings of the 2007 Joint Conference on
Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning
(EMNLP-CoNLL, pages 868?876.
Maria Holmqvist, Sara Stymne, Lars Ahrenberg, and
Magnus Merkel. 2012. Alignment-based reordering
for SMT. In Nicoletta Calzolari (Conference Chair)
et al, editor, Proceedings of the Eight International
Conference on Language Resources and Evaluation
(LREC?12), Istanbul, Turkey, may. European Lan-
guage Resources Association (ELRA).
Jie Jiang, Jinhua Du, and Andy Way. 2010. Source-
side syntactic reordering patterns with functional
words for improved phrase-based SMT. In Pro-
ceedings of SSST-4, Fourth Workshop on Syntax and
Structure in Statistical Translation, pages 19?27,
Beijing.
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,
and E. Herbst. 2007. Moses: Open Source Toolkit
for Statistical Machine Translation. In Proceed-
ings of the ACL 2007 Demo and Poster Sessions,
pages 177?180, Prague. Association for Computa-
tional Linguistics.
Minh-Thang Luong, Preslav Nakov, and Min-Yen Kan.
2010. A hybrid morpheme-word representation for
machine translation of morphologically rich lan-
guages. In Proceedings of the 2010 Conference on
Empirical Methods in Natural Language Process-
ing, EMNLP ?10, pages 148?157, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Marie-Catherine De Marneffe, Bill Maccartney, and
Christopher D. Manning. 2006. Generating typed
dependency parses from phrase structure parses. In
In LREC 2006.
Attila Nova?k, La?szlo? Tihanyi, and Ga?bor Pro?sze?ky.
2008. The MetaMorpho translation system. In
Proceedings of the Third Workshop on Statistical
Machine Translation, StatMT ?08, pages 111?114,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Attila Nova?k. 2003. What is good Humor like?
In I. Magyar Sza?mto?ge?pes Nyelve?szeti Konferencia,
pages 138?144, Szeged. SZTE.
Attila Nova?k. 2009. MorphoLogic?s submission for
the WMT 2009 Shared Task. In Proceedings of the
Fourth Workshop on Statistical Machine Translation
at EACL 2009, Athens, Greece.
Gyo?rgy Orosz and Attila Nova?k. 2012. PurePos ? an
open source morphological disambiguator. In Pro-
ceedings of the 9th International Workshop on Nat-
ural Language Processing and Cognitive Science.,
Wroclaw, Poland.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic
evaluation of machine translation. In Proceedings
of the 40th Annual Meeting on Association for Com-
putational Linguistics, ACL ?02, pages 311?318,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Ga?bor Pro?sze?ky and Bala?zs Kis. 1999. A unification-
based approach to morpho-syntactic parsing of ag-
glutinative and other (highly) inflectional languages.
In Proceedings of the 37th annual meeting of the
Association for Computational Linguistics on Com-
putational Linguistics, ACL ?99, pages 261?268,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
D. Varga, L. Ne?meth, P. Hala?csy, A. Kornai, V. Tro?n,
and V. Nagy. 2005. Parallel corpora for medium
density languages. In Recent Advances in Natural
Language Processing (RANLP 2005), pages 590?
596.
Reyyan Yeniterzi and Kemal Oflazer. 2010. Syntax-to-
morphology mapping in factored phrase-based sta-
tistical machine translation from English to Turkish.
In Proceedings of the 48th Annual Meeting of the As-
sociation for Computational Linguistics, ACL ?10,
pages 454?464, Stroudsburg, PA, USA. Association
for Computational Linguistics.
50
