Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1?6,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Translating Dialectal Arabic to English
Hassan Sajjad, Kareem Darwish
Qatar Computing Research Institute
Qatar Foundation
{hsajjad,kdarwish}@qf.org.qa
Yonatan Belinkov
CSAIL
Massachusetts Institute of Technology
belinkov@mit.edu
Abstract
We present a dialectal Egyptian Arabic
to English statistical machine translation
system that leverages dialectal to Modern
Standard Arabic (MSA) adaptation. In
contrast to previous work, we first nar-
row down the gap between Egyptian and
MSA by applying an automatic character-
level transformational model that changes
Egyptian to EG?, which looks simi-
lar to MSA. The transformations include
morphological, phonological and spelling
changes. The transformation reduces
the out-of-vocabulary (OOV) words from
5.2% to 2.6% and gives a gain of 1.87
BLEU points. Further, adapting large
MSA/English parallel data increases the
lexical coverage, reduces OOVs to 0.7%
and leads to an absolute BLEU improve-
ment of 2.73 points.
1 Introduction
Modern Standard Arabic (MSA) is the lingua
franca for the Arab world. Arabic speakers gen-
erally use dialects in daily interactions. There are
6 dominant dialects, namely Egyptian, Moroccan,
Levantine, Iraqi, Gulf, and Yemeni1. The dialects
may differ in vocabulary, morphology, syntax, and
spelling from MSA and most lack spelling con-
ventions.
Different dialects often make different lexical
choices to express concepts. For example, the con-
cept corresponding to ?Oryd? YK
P

@ (?I want?) is
expressed as ?EAwz? 	P?A? in Egyptian, ?Abgy?
?


	?K. @ in Gulf, ?Aby? ?
G. @ in Iraqi, and ?bdy? ?
 YK.
in Levantine2. Often, words have different or op-
posite meanings in different dialects.
1http://en.wikipedia.org/wiki/
Varieties_of_Arabic
2All transliterations follow the Buckwalter scheme
Arabic dialects may differ morphologically
from MSA. For example, Egyptian Arabic uses a
negation construct similar to the French ?ne pas?
negation construct. The Egyptian word ?mlEbt$?
?

J.??? (or alternatively spelled ?J.??A?) (?I did
not play?) is composed of ?m+lEbt+$?.
The pronunciations of letters often differ from
one dialect to another. For example, the letter ?q?

? is typically pronounced in MSA as an unvoiced
uvular stop (as the ?q? in ?quote?), but as a glot-
tal stop in Egyptian and Levantine (like ?A? in
?Alpine?) and a voiced velar stop in the Gulf (like
?g? in ?gavel?). Differing pronunciations often re-
flect on spelling.
Social media platforms allowed people to ex-
press themselves more freely in writing. Although
MSA is used in formal writing, dialects are in-
creasingly being used on social media sites. Some
notable trends on social platforms include (Dar-
wish et al, 2012):
- Mixed language texts where bilingual (or mul-
tilingual) users code switch between Arabic and
English (or Arabic and French). In the exam-
ple ?wSlny mrsy? ?


??Q? ?


	
???? (?got it thank
you?), ?thank you? is the transliterated French
word ?merci?.
? The use of phonetic transcription to match di-
alectal pronunciation. For example, ?Sdq? ?Y?
(?truth?) is often written as ?Sj? l .? in Gulf di-
alect.
? Creative spellings, spelling mistakes, and word
elongations are ubiquitous in social texts.
? The use of new words like ?lol? ??? (?LOL?).
? The attachment of new meanings to words such
as using ?THn? 	?j? to mean ?very? while it
means ?grinding? in MSA.
The Egyptian dialect has the largest number of
speakers and is the most commonly understood di-
alect in the Arab world. In this work, we focused
on translating dialectal Egyptian to English us-1
ing Egyptian to MSA adaptation. Unlike previous
work, we first narrowed the gap between Egyptian
and MSA using character-level transformations
and word n-gram models that handle spelling mis-
takes, phonological variations, and morphological
transformations. Later, we applied an adaptation
method to incorporate MSA/English parallel data.
The contributions of this paper are as follows:
? We trained an Egyptian/MSA transformation
model to make Egyptian look similar to MSA. We
publicly released the training data.
? We built a phrasal Machine Translation (MT)
system on adapted Egyptian/English parallel data,
which outperformed a non-adapted baseline by
1.87 BLEU points.
? We used phrase-table merging (Nakov and Ng,
2009) to utilize MSA/English parallel data with
the available in-domain parallel data.
2 Previous Work
Our work is related to research on MT from a re-
source poor language (to other languages) by piv-
oting on a closely related resource rich language.
This can be done by either translating between
the related languages using word-level translation,
character level transformations, and language spe-
cific rules (Durrani et al, 2010; Hajic? et al, 2000;
Nakov and Tiedemann, 2012), or by concatenating
the parallel data for both languages (Nakov and
Ng, 2009). These translation methods generally
require parallel data, for which hardly any exists
between dialects and MSA. Instead of translating
between a dialect and MSA, we tried to narrow
down the lexical, morphological and phonetic gap
between them using a character-level conversion
model, which we trained on a small set of parallel
dialect/MSA word pairs.
In the context of Arabic dialects3, most previous
work focused on converting dialects to MSA and
vice versa to improve the processing of dialects
(Sawaf, 2010; Chiang et al, 2006; Mohamed et
al., 2012; Utiyama and Isahara, 2008). Sawaf
(2010) proposed a dialect to MSA normalization
that used character-level rules and morphological
analysis. Salloum and Habash (2011) also used a
rule-based method to generate MSA paraphrases
of dialectal out-of-vocabulary (OOV) and low fre-
quency words. Instead of rules, we automatically
3Due to space limitations, we restrict discussion to work
on dialects only.
learnt character mappings from dialect/MSA word
pairs.
Zbib et al (2012) explored several methods for
dialect/English MT. Their best Egyptian/English
system was trained on dialect/English parallel
data. They used two language models built from
the English GigaWord corpus and from a large
web crawl. Their best system outperformed man-
ually translating Egyptian to MSA then translat-
ing using an MSA/English system. In contrast, we
showed that training on in-domain dialectal data
irrespective of its small size is better than training
on large MSA/English data. Our LM experiments
also affirmed the importance of in-domain English
LMs. We also showed that a conversion does not
imply a straight forward usage of MSA resources
and there is a need for adaptation which we ful-
filled using phrase-table merging (Nakov and Ng,
2009).
2.1 Baseline
We constructed baselines that were based on the
following training data:
- An Egyptian/English parallel corpus consist-
ing of ?38k sentences, which is part of the
LDC2012T09 corpus (Zbib et al, 2012). We ran-
domly divided it into 32k sentences for training,
2k for development and 4k for testing. We hence-
forth refer to this corpus as EG and the English
part of it as EGen. We did not have access to the
training/test splits of Zbib et al (2012) to directly
compare to their results.
- An MSA/English parallel corpus consisting of
200k sentences from LDC4. We refer to this cor-
pus as the AR corpus.
For language modeling, we used either EGen
or the English side of the AR corpus plus the En-
glish side of NIST12 training data and English Gi-
gaWord v5. We refer to this corpus as GW.
We tokenized Egyptian and Arabic accord-
ing to the ATB tokenization scheme using the
MADA+TOKAN morphological analyzer and to-
kenizer v3.1 (Roth et al, 2008). Word elonga-
tions were already fixed in the corpus. We word-
aligned the parallel data using GIZA++ (Och and
Ney, 2003), and symmetrized the alignments using
grow-diag-final-and heuristic (Koehn et al, 2003).
We trained a phrasal MT system (Koehn et al,
2003). We built five-gram LMs using KenLM
4Arabic News (LDC2004T17), eTIRR (LDC2004E72),
and parallel corpora the GALE program2
Train LM BLEU OOV
B1 AR GW 7.48 6.7
B2 EG GW 12.82 5.2
B3 EG EGen 13.94 5.2
B4 EG EGenGW 14.23 5.2
Table 1: Baseline results using the EG and AR
training sets with GW and EGen corpora for LM
training
with modified Kneser-Ney smoothing (Heafield,
2011). In case of more than one LM, we tuned
their weights on a development set using Mini-
mum Error Rate Training (Och and Ney, 2003).
We built several baseline systems as follows:
? B1 used AR for training a translation model and
GW for LM.
? B2-B4 systems used identical training data,
namely EG, with the GW, EGen, or both for B2,
B3, and B4 respectively for language modeling.
Table 1 reports the baseline results. The system
trained on AR (B1) performed poorly compared
to the one trained on EG (B2) with a 6.75 BLEU
points difference. This highlights the difference
between MSA and Egyptian. Using EG data for
training both the translation and language models
was effective. B4 used two LMs and yielded the
best results. For later comparison, we only use the
B4 baseline.
3 Proposed Methods
3.1 Egyptian to EG? Conversion
As mentioned previously, dialects differ from
MSA in vocabulary, morphology, and phonology.
Dialectal spelling often follows dialectal pronun-
ciation, and dialects lack standard spelling con-
ventions. To address the vocabulary problem, we
used the EG corpus for training.
To address the spelling and morphological dif-
ferences, we trained a character-level mapping
model to generate MSA words from dialectal
ones using character transformations. To train the
model, we extracted the most frequent words from
a dialectal Egyptian corpus, which had 12,527
news comments (containing 327k words) from Al-
Youm Al-Sabe news site (Zaidan and Callison-
Burch, 2011) and translated them to their equiv-
alent MSA words. We hired a professional trans-
lator, who generated one or more translations of
the most frequent 5,581 words into MSA. Out of
these word pairs, 4,162 involved character-level
transformations due to phonological, morphologi-
cal, or spelling changes. We aligned the translated
pairs at character level using GIZA++ and Moses
in the manner described in Section 2.1. As in the
baseline of Kahki et al (2011), given a source
word, we produced all of its possible segmenta-
tions along with their associated character-level
mappings. We restricted individual source char-
acter sequences to be 3 characters at most. We
retained all mapping sequences leading to valid
words in a large lexicon. We built the lexicon from
a set of 234,638 Aljazeera articles5 that span a 10
year period and contain 254M tokens. Spelling
mistakes in Aljazeera articles were very infre-
quent. We sorted the candidates by the product of
the constituent mapping probabilities and kept the
top 10 candidates. Then we used a trigram LM that
we built from the aforementioned Aljazeera arti-
cles to pick the most likely candidate in context.
We simply multiplied the character-level transfor-
mation probability with the LM probability ? giv-
ing them equal weight. Since Egyptian has a ?ne
pas? like negation construct that involves putting a
??? and ? ?? at the beginning and end of verbs,
we handled words that had negation by remov-
ing these two letters, then applying our character
transformation, and lastly adding the negation ar-
ticle ?lA? B before the verb. We converted theEG
train, tune, and test parts. We refer to the converted
corpus as EG?.
As an example, our system transformed
Yg ?. j. ?J
? ????jJ
K. ?


?

? @ ?. (?what is hap-
pening to them does not please anyone?) to
Yg I. j. ?K
 B ??? ??m
