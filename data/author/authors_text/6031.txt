Optimising text quality in generation from relational databases 
Michael  O 'Donne l l t  (micko@dai .ed .ac .uk) ,  
A l i s ta i r  Knott:~ (a l i k@hermes .o tago .ac .nz ) ,  
Jon  Ober lander ,  ( jon@cogsc i .ed .ac .uk) ,  
Chr i s  Me l l i sh t (chr i sm@dai .ed .ac .uk)  
, D iv is ion  of  In fo rmat ics ,  Un ivers i ty  of  Ed inburgh .  
. . . . .  ~.:D.eparl~me~t.nf: Compulzer?c ience~ ~Otago Univers ity:  
Abst rac t  
This paper outlines a text generation system suited 
to a large class of information sources, relational 
databases. We focus on one aspect of the problem: 
the additional information which needs to be spe- 
cified to produce reasonable text quality when gen- 
erating from relational databases. We outline how 
databases need to be prepared, and then describe 
various types of domain semantics which can be used 
to improve text qualify. 
1 In t roduct ion  
As the problems of how we generate text are gradu- 
ally solved, a new problem is gaining prominence 
- where do we obtain the information which feeds 
the generation. Many domain models for existing 
generation systems are hand-crafted for the specific 
system. Other systems take advantage of existing 
information sources. 
A good information source for text generation 
resides in the vast number of relational databases 
which are in use around tile world. These resources 
have usually been provided for some reason other 
than text generation, such as inventory manage- 
ment, accounting, etc. However, given that the in- 
formation is on hand, it can be of value to conuect 
these databases to text generation facilities. 
The benefits include natural anguage access to in- 
formation which is usually accessed in tabular form, 
which can be difficult to interpret. Natural Lan- 
guage descriptions are easier to read, can be tailored 
to user types, and can be expressed in different lan- 
guages if properly represented. 
This paper outlines the domain specification lan- 
guage for the ILEX text g~neration system, (for 
Intelligent Labelling Explorer). 1
ILEX is a tool for ?dynamic browsing of database- 
defined information: it allows a user to browse 
through the information in a database using hyper- 
1Earlier ILEX papers have been based on Ilex 2.0, which 
was relatively domain-dependent.  This  paper is based around 
version 3.0 of ILEX, a re-draft to make the system domain- 
independent, and domain acquisition far easier. The ILEX 
project was supported by EPSRC grant GR/K53321.  
text. ILEX generates descriptions of database ob- 
jects on the fly, taking into account he user's con- 
text of browsing. Figure 1 shows the ILEX web in- 
terface, as applied to a museum domain, in this case 
the Twentieth Century Jewellery exhibition at the 
the National Museum of Scotland. 2 The links to 
related database objects are also automatically gen- 
erated. ILEX has been applied to other domains, in- 
cluding personnel (Nowson, 1999), and a sales cata- 
logue for computer systems and peripherals (Ander- 
son and Bradshaw, 1998). 
One of the advantages of using NLG for database 
browsing is that the system can keep track of what 
has already been said about objects, and not repeat 
that information on later pages. Appropriate refer- 
ring expressions can also be selected on the basis 
of the discourse history. The object descriptions can 
be tailored to the informational interests of the user. 
See Knott et al (1997) and Mellish et al (1998) for 
more information on these aspects of ILEX. 
In section 2, we consider some systems related to 
the ILEX system. Section 3 describes the form of 
relational database that ILEX accepts as input. Sec- 
tion 4 outlines what additional information - domain 
semantics - needs to be provided for coherent ext 
production from the database, while section 5 de- 
scribes additional information which can be provided 
to improve the quality of the text produced. 
2 Re la ted  Work  
It should be clear that the task we are discussing is 
very distinct from the task of response generation in 
a natural language interface to a database (e.g., see 
Androutsopoulos et al (1995)). ' In such systtems, 
the role of text planning is quite simple or absent, 
usually dealing with single sentences, or in the most 
? ? complex systems;~ a:single:sentence ,answer ~with an 
additional clause or two of supporting information. 
ILEX is not a query response generation system, 
it is an object description system. It composes a full 
text, at whatever size, with the goal of making that 
text a coherent discourse. 
2The authors thank the museum for making their database 
available: 
133 
Sflver.A~nd Ename . :  
!- S.~.v~ t !~s ,  w i~ blu~-~e~.~i/e.1 . ! 
' ) . :~v{ .  ,EX :~- - : :  . . . . . . . . . . . . . .  )' . . . . . . .  " t ' ': i:: ' :  :!:i 
? lessie-I~-X~g.,l~. Place of,. ; 
? This Jewel !s apel'l.d~mat-neckla~ ililitwaS . . 
I madebZ,aSa~h de:a,S~caUed-Jesae M , 
l<: gin,g:ilt~bnedlhe f~mrRemStn:tht~:case.,::_: , '  
:: ? / lowers reseri~A a~ai~t  i t - I t  is tn ~e Arts :~ud,  
. Crafts:style and was made t1~ :lgfl~ It has an . . . .  
elaborate aesign; specifically It h~ floral mows.  
: :;::anlllustrat~too, In fact., shg did qttite, a' l~ of,-: : 
" differei~tl~rpes of creative Wark;/cwdleiTls ? : i:. 
:. ; :  :i'; ~:t~n Arts. amt Craft#Style . ),.::.:):i:.: 2,} :,i.: 'i:' :" 
:'::' ; :-'? ;~.~,~t,~I,t~,,/~l.a~.~_~': ~" ; : "  : : ; " : " ,  -'; 7.; ...:. 
."  ' .:,L'~n Ai'ts aiid Crafts:s~lgne~iil~e -: :.::'..': " i 
J 
.; ... (; . 
Figure 1: Browsing Object Descriptions 
In this regard, ILEX should be more fruit- 
fully compared with text generation systems such 
as GOSSIP (Carcagno and Iordanskaja, 1993), 
PEBA (Milosavljevie, 1997; Milosavljevic, 1999), or 
POWER (Dale et al, 1998), systems which build an 
extended text fl'om an underlying database. 
ILEX 3.0 has been developed to be domain in- 
dependent, to handle relational databases from any 
domain, as long as the information is provided in the 
required format. The first two of the systems above 
are single domain systems. T:he third, POWER,  is 
an extension of PEBA to handle a new domain. It 
is not clear however whether the resulting system is 
.. itself domain-dependent or not. 
This last system is perhaps the best comparison 
for the ILEX system, since it also generates de- 
scriptions of museum objects from an underlying 
database. In that paper, the main focus is on the 
problem of extracting out usable information from 
badly structured databases (as often provided by 
museulns), and on generating texts using only only 
this information (plus some linguistic knowledge). 
The present paper differs from this approach by as- 
suming that information is already available in a nor- 
malised relational database. We observe, as do Dale 
et al (1998), that texts generated from this inform- 
ation alone are quite poor in quality. We go one 
step further by examining what additional informa- 
tion can be provided to improve the quality of the 
text to a reasonable l vel. 
The ILEX system has been implemented to be 
flexible in regards to the available domain inform- 
ation. With a bare minimum, the system provides 
poor quality texts, but as the domain developer ex- 
.tends-the domain semantics, the quahty of.texts im- 
proves, up to a point where users sometimes nfistake 
ILEX-generated texts for human-authored texts. 
3 The Structure of a Relational 
Database 
Databases vary widely in form, so we have assumed 
a fairly" standard relational database format. 
134 
3.1 Entity Files 
:.The database consists of .a number:.:of ~ntity files, 
each file providing the records for a different entity 
type. Each record (row) in the entity file defines a 
unique entity. The columns define attributes of the 
entities. In a museum domain, we might have an 
entity file for museum artifacts, another for people 
involved with the artifacts (designers, owners, etc.), 
another for locations, etc. See figure 2 for a sample 
entity file for the Jewellery domain. Given the wide 
.range of database formats..a~vailable, !LEX ~sumes 
a tab-delimited format for database files. 
ILEX imposes two requirements on the entity files 
it uses: 
1. Single field key: while relational databases of- 
ten use multiple attributes to form a unique key 
(e.g., name and birthdate), ILEX requires that 
each entity have a unique identifier in a single 
attribute. This identifier must be under a field 
labelled ID. 
2. Typing of entities: ILEX depends trongly on a 
type system. We require that each entity record 
provides a type for the entity in a field labelled 
Class. 
Some other attribute labels are reserved by the 
system, allowing ILEX to deal intelligently with 
them, including Name, Short-Name and Gender. 
3.2 L ink Fi les 
In some cases, an entity will have multiple fillers of 
an attribute, for instance, a jewellery piece may be 
made of any number of materials. Entity files, with 
fixed record structure, cannot handle such eases. 
The standard approach in relational databases i to 
provide a link file for each case where multiple fillers 
are possible. A link file consists of two columns only, 
one identifying the entity, the other identifying the 
filler (the name of the attribute is provided in the 
first line of the file, see figure 3). 
We are aware that the above specification repres- 
ents an impoverished view of relational databases. 
Many relational databases provide far more than 
simple entity and link files. However, by no means 
all relational databases provide more than this, so 
we have adopted the lowest common denominator. 
Most relational databases can be exported in a form 
which meets our requirements. 
3.3 Terminology 
In the following discussion, we will use the following 
terminology: 
* Predicate: each column of an entity file defines 
a predicate. Class, Designer and Date are thus 
predicates introduced in figure 2. Each link file 
also defines a predicate. 
? Record: each row of an entity table provides the 
attributes o f  a: single.,entity.: The row is termed 
a record in database terminology. 
? Fact: each entry in a record defines what we 
call a fact about that entity, a A fact consists o f  
three parts: its predicate name, and two argu- 
ments, being the entity of the record, and the 
filler of the slot. 
? ARC1: the first argument of a fact, the entity 
the  fact is about. 
. ARC2: the second argument of a fact, the filler 
of the attribute for the entity. 
4 Spec i fy ing  the  Semant ics  o f  the  
Database  
A database itself says nothing about the nature of 
the contents of each field in the database. It might 
be a name, a date, a price, etc. Similarly for the 
field label: the field label names a relation between 
the entity represented by the record and the entity 
represented by the filler. However, without further 
specification, we do not know what this relationship 
entails, apart from the label itself, e.g., 'Designer'. 
Before we can begin to process a database intelli- 
gently, we need to define the 'semantics' of the data- 
base. This section will outline how this is done in the 
ILEX case. There has been some work on automatic 
acquisition of database semantics, uch as in the con- 
struction of taxonomies of domain entity types (see 
Dale et al (1998) for instance). However, it is diffi- 
cult to perform this process reliably and in a domain- 
independent manner, so we have not attempted to 
in this case. The specification of domain semantics 
is still a manual process which has to be undertaken 
to link a database to the text generator. 
To use a database for generation, additional in- 
formation of several kinds needs to be provided: 
1. Taxonomic organisation: supplying of types for 
each database ntity, and organisation of these 
types into taxonomies; 
2. Taxonomic lexification: specif~'ing how each do- 
main type is lexified; 
3. Data type off attribute fillers: telling the system 
to expect the filler of a record slot to be an 
entity-id, a string, a date, etc. 
4. Domain type specification:specifying What do- 
main type the slot filler can be assumed to be. 
Each of these aspects of domain specification will 
be briefly described below. 
3Excepting the first column, which provides the entity-id 
for tile record. 
135 
 Class brooch -necklace necklace Designer KingO1 "KingO1 ChanelO1 Style J___190~ A-rt-Deco : ~_~_~ Art-Noveux London Paris 
L_ 
Sponsor 
Liberty01 
Figure 2: A Sample from an Entity file 
\ [ ~ .  Material 
Figure 3: A Sample from a Link file 
(def-basic-type 
:domain jewellery-domain 
:head jewellery 
:mn-link 3D-PHYS-0BJECT) 
(def-taxonomy 
:type jewellery 
:subtypes (neck-jewellery wrist-jewellery 
pin-jewellery pendant buckle 
earring earring-pair finger-ring 
ringset watch button dress-clip 
hat-pin)) 
Figure 4: Defining Taxonomic Knowledge 
4.1 Taxonomic  Organ isat ion  
ILEX requires that the entities of the domain are or- 
ganised under a domain taxonomy. The user defines 
a basic type (e.g., jewellery), and then defines the 
sub-types of the basic-type, and perhaps further sub- 
classification. Figure 4 shows the lisp forms defining 
a basic type in the jewellery domain, and the sub- 
classification of this type. The basic type is also 
mapped onto a type (or set of types) in the concept 
ontology used for sentence generation, a version of 
Penman's Upper Model (Bateman, 1990). This al- 
lows the sentence generator to reason about the ob- 
jects it expresses. 
Taxonomic organisation is important for several 
reasons, including among others: 
1. Expressing Entities: each type can be related to 
lexical i tems'to use,to-express that  type (e.g., 
linking the type brooch to a the lexical item for 
"brooch". If no lexical item is defined for a type, 
a lexical item associated with some super-type 
can be used instead. Other aspects of the ex- 
pression of entities may depend on the concep- 
tual type, for instance pronominalisation, deixis 
(e.g., mass or count entities), etc. 
2. Supporting Inferences and Generalisations: 
ILEX allows the user to assert generalisations 
about types, e.g., that Arts and Crafts jewellery 
tends to be made using enamel (see section 5.4). 
The type hierarchy is used to check whether a 
particular generalisation is appropriate for any 
given instance. 
The earlier version of ILEX, Ilex2.0, allowed the 
full representational power of the Systemic formal- 
ism for representing domain taxonomies, including 
cross-classification, and multiple inheritance (both 
disjunctive and conjunctive). However, our exper- 
iences with non-linguists trying to define domain 
models showed us that the more scope for expres- 
sion, the more direction was needed. We thus sim- 
plified the formalism, by requiring taxonomies to be 
simple, with no cross-classification r multiple inher- 
itance. We felt that the minor loss of expressivity 
was well balanced by the gain in simplicity for do- 
main developers. 
4.2 Type Lexi f icat ion 
To express each database ntity, it is essential to be 
able to map from its defined type, to a noun to use 
in a referring expression, e.g., this brooch. 
Ilex comes with a basic lexicon already provided. 
covering the commonly occurring words. Each entry 
defines the svntactic and morphological information 
required for sentence generation. For these items, 
the domain developer needs to provide a simpl e map- 
ping from domain type to lexical item, for instance, 
the following lisp form specifies that the domain type 
location should be lexified by the lexical item whose 
id is location=noun: 
(lexify location location-noun) 
For those lexical items not already defined, the do- 
main developer needs to provide in addition lexical 
item definitions for the nouns expressing the types 
in their domain. A typical entry has the form shown 
in figure 5. 
136 
(def-lexical-item 
:name professor-noun 
:spelling "professor" 
:grammatical-features (common-noun count-noun) 
) 
Figure 5: A Sample Lexical item Specification 
. . . .  (defobject-structurejewellery- " ..... 
:class :generic-type 
:subclass :generic-type 
:designer :entity-id 
:style :entity-id 
:material :generic-type 
:date :date 
:place :string 
:dimension :dimension) 
Figure 6: Specifying Field Semantics 
(def-predicateClass 
:expression (:verb be-verb) 
) 
Figure 8: Simple Fact Expression 
4.3 Data Type of Slot Fillers 
Each field in a database record contains a string of 
characters. It is not clear whether this string is an 
identifier for another domain entity, a string (e.g., 
someone's urname), a date, a number, a type in 
the type hierarchy, etc. 
ILEX requires, for each entity file, a statement as 
to how the field fillers should be interpreted. See 
figure 6 for an example. 
Some special filler types have been provided to 
facilitate the import of structured ata types. This 
includes both :date and :dimension in the current 
example. Special code has been written to convert 
the fillers of these slots into ILEX objects. Other 
special filler types are being added as needed. 
4.4 Domain  Type  o f  Slot Fi l lers 
The def-predicate form allows the domain developer 
to state what type the fillers of a particular field 
should be. This not only allows for type checking, 
but also allows the type of an entity to be inferred 
if not otherwise provided. For instance, by assert- 
ing that fillers of the Place field should of type city, 
the system can infer that "London" is a city even if 
London itself has no database record. See figure 7. 
(def-predicate Place 
:argl jewellery 
:arg2 city 
) 
Figure 7: Speci~'ing Predicate Fillers 
4.5 Summary  
..... '.:~With:just chisvmuch-semantics~specified,. ILEX e-an 
generate very poor texts, but texts which convey 
the content of the database records. In the next 
section, we will outline the extensions to the domain 
semantics which are needed to improve the quality 
of the text produced by ILEX. 
5 Extending Domain Semantics for 
Improved Text Quality 
So far we have discussed only the simplest level of 
domain semantics, which allows a fairly direct ex- 
pression of domain information. ILEX allows the 
domain developer to provide additional domain se- 
mantics to improve the quality of the text. 
5.1 Expression of Facts 
Unless told otherwise, ILEX will express each fact in 
a simple regular form, such as The designer of this 
brooch is Jessie M. King, using a template form4: 
The <predicate> of <entity-expression> 
is <filler-expression>. 
However, a text consisting solely of clauses of this 
form is unnatural, and depends on the predicate la- 
bel being appropriate to the task (labels like given-by 
will produce nonsense sentences). 
To produce better text, ILEX can be told how 
to express facts. The domain developer can provide 
an optional slot to the &f-predicate form as shown 
in figure 8. The expression specification first of all 
defines which verb to use in the expression. By de- 
fault, the ARG1 element is mapped onto the Sub- 
ject, and the ARG2 onto the Object. Default val- 
ues are assumed for tense, modality, polarity, voice. 
finiteness, quantification, etc., unless otherwise spe- 
cified. So, using the above expression specification, 
the Class fact of a jewel would be expressed by a 
clause like: This item is a brooch. 
To .produce less .standard expressions, we need to 
modify some of the defaults. A more complex ex- 
pression specification is shown in figure 9, which 
would result in the expression such as: For further 
information, see Liberty Style Guide No. 326: 
4ILEX3.0  borrowed this use of a default  express ion tem- 
p late  from the POWER system (Dale et al, 1998). In previ-  
ous vers ions of ILEX,  all facts were expressed by full NLG as 
exp la ined below. 
137 
(def-predicate Bib-Note 
:argl jewellery 
:expression ( 
:adjunctl "for further information" 
:mood imperative 
:verb see-verb 
:voice active) 
Figure 9: More Complex Fact Expression 
The expression form is used to construct a par- 
tial syntactic specification, which is then completed 
using the sentence generation module of the WAG 
sentence generator (O'Donnell, 1996). 
With the level of domain semantics pecified so 
far, ILEX is able to produce texts such as the two be- 
low, which provides an initial page describing data- 
base entity BUNDY01, and then a subsequent page 
when more information was requested (this from the 
Personnel domain (Nowson, 1999)): 
o Page  1: Alan Bundy is located in room F1, 
which is in South Bridge. He lectures a course 
called Advanced Automated Reasoning and is in 
the Institute for Representation and Reasoning. 
He is the Head of Division and is a professor. 
* Page  2: As already mentioned, Alan Bundy lec- 
tures Advanced Automated Reasoning. AAR is 
lectured to MSc and AI4. 
This expression specification form has been de- 
signed to limit the linguistic skills needed for domain 
developers working with the system. Given that the 
domain developers may be museum staff, not com- 
putational linguists, this is necessary. The notation 
however allows for a wide range of linguistic expres- 
sions if the full range of parameters are used. 
5.2 User  Adapt ion  
To enable the system to adapt its content to the 
type of user, the domain developers can associate 
information with each predicate indicating the sys- 
tem's view of the predicate's interest, importance, 
etc., to the user. This information is added to the 
d@predicate form, as shown in figure 10. 
The user annotations allowed by ILEX include: 
1. Interest: how interesting does the system judge 
the information to be to the user; 
2. Importance: how important is it to the system 
that the user reads the information; 
3. Assimilation: to what degree does the system 
judge the user to already know the infornlation: 
.<def~predicate Designer 
. o .  
:importance ((expert lO)(default 6)(child 5)) 
:interest ((expert lO)(default 6)(child 4)) 
:assimilation ((expert O)(default O)(child 0)) 
:assim-rate ((expert l)(default l)(child 0.5)) 
) 
Figure 10: Specifying User Parameters 
4. Assimilation Rate: How quickly does the sys- 
tem believe the user will absorb the information 
when presented (is one presentation enough?). 
This information influences what content will be 
expressed to a particular user, and in what or- 
der (more relevant on earlier pages). Information 
already assimilated will not be delivered, except 
when relevant for other purposes (e.g., when refer- 
ring to the entity). If no annotations are provided, 
no user customisation will occur. 
The values in ILEX's user models have been set 
intuitively by the implementers. While ideally these 
values would be derived through user studies, our 
purpose was purely to test the adaptive mechanism, 
and demonstrate that it works. We .leave the devel- 
opment of real user models for later work. 
ILEX has opted out of using adaptive user model- 
ling, whereby the user model attributes are adapted 
as a result of observed user choices in the web inter- 
face. We leave this for future research. 
5.3 Compar i sons  
When describing an object, it seems sometimes use- 
ful to compare it to similar articles already seen. 
With small addition to the domain specification, 
ILEX can compare items (an extension by Maria Mi- 
losavljevic), as demonstrated in the following text: 
This item is also a brooch. Like the previ- 
ous item, it was designed by King. How- 
ever, it differs from the previous item in 
that it is made of gold and enamel, while 
the previous brooch was made of silver and 
enamel. 
For ILEX to properly compare two entities, it 
needs to Mmw how the various.attributes of the en- 
tity can be compared (nominal, ordinal, scalar, etc.). 
Again, information can be added to the d@predicate 
for each predicate to define its scale of comparabil- 
ity. See Milosavljevic (1997) and (1999) for more de- 
tail. Figure 11 shows the additions for the Designer 
predicate. Comparisons introduce several RST re- 
lations to the text structure, including rst-contrast, 
rst-similarity and rst-whereas. 
138 
(def-predicate Designer 
:variation (string i) 
:scale nominal 
) 
Figure lh Specifying Predicate Comparability 
(def-defeasible-rule 
? :qv ($jewel jewellery) ....... 
:lhs (some ($X (style $jewel $X)) 
(arts-and-crafts SX))) 
:rhs (some ($X (made-of Sjewel SX)) 
(enamel SX))) 
Figure 12: Specifying Generalisations 
5 . 4  G e n e r a l i s a t i o n s  
We found it useful to allow facts about general types 
of entities to be asserted, for instance, that Arts and 
Crafts jewellery tend to be made of enamel. These 
generalisations can then be used to improve the qual- 
ity of text, producing object descriptions as in the 
following: 
This brooch is in the Arts and Crafts style. 
Arts and Crafts jewels tend to be made of 
enamel. However, this one is not. 
These generalisations are defined using defeasible 
implication - similar to the usual implication, but 
working in terms of few, many, or most rather than 
all or none. They are entered in a form derived 
from first order predicate calculus, for instance, see 
figure 12 which specifies that most Arts and Crafts 
jewellery uses enamel. 
ILEX find each instance which matches the gen- 
eral type (in this case, instances of type jewellery 
which have Arts and Crafts in the Style role). If 
the fact about the generic object has a correspond- 
ing fact on the instantial object, an exemplification 
relation is asserted between the facts. Otherwise, 
a ?concession relation is asserted. See Knott et al 
(1997) for more details on this procedure. 
6 Summary  
While observing people trying to convert an earlier 
ILEX system to a new domain, we noted the diffi- 
culty they had. To avoid these problems, we under- 
took to re-implement the domain specification as- 
pects of ILEX to simplify the task. 
Towards this end, we have followed a number of 
steps. Firstly, we reconstructed ILEX to be domain 
- Taxonomies 
- Lexification of Types 
- Filler Domain Type Information 
- Filler Data Type Information 
OBLIGATORY 
- Predicate Expression 
- Comparison Information 
- Generalisations 
- User Annotations 
OPTIONAL 
Figure 13: Obligatory and Optional Steps in Domain 
Specification 
independent, with all domain information defined in 
declarative resource files. This means that domain 
developers do not have to deal with code. 
Secondly, we built into ILEX the ability to import 
entity definitions directly from a relational database 
(although with some restrictions as to its form). 
A database by itself does not provide enough in- 
formation to produce text. Domain semantics is re- 
quired. We have provided a system of incremental 
specification of this semantics which allows a domain 
developer to hook up adynamic hypertext interface 
to a relational database quickly, although producing 
poor quality text. Minimally, the system requires 
a domain taxonomy, information on lexification of 
types, and specification of the data type of each re- 
cord field. 
Additional effort can then improve the quality of 
text up to a quite reasonable l vel. The additional 
information can include: specification of predicate 
expression, and specifications supporting comparis- 
ons, user adaption, and generalisations. 
Figure 13 summarises the obligatory and optional 
steps in domain specification in ILEX. 
Simplifying the domain specification task is a ne- 
cessity as text generation systems move outside of 
research labs and into the real world, where the 
domain developer may not be a computational lin- 
guist, but a museum curator, personnel officer or 
wine salesman. ~ have tried to take a step towards 
making their task easier. 
Re ferences  
Gail Anderson and Tim Bradshaw. 1998. ILEX: 
The intelligent labelling explorer: Experience of 
Building a Demonstrator for the Workstation Do- 
main. Internal Report, Artificial Intelligence Ap- 
plications tnstitute,University of Edinburgh. 
I. Androutsopoulos, G.D. Ritchie, and P. Thanisch. 
1995. Natural language interfaces to databases - 
an introduction. Natural Language Engineering, 1
(1):29-81. 
John Bateman. 1990. Upper modeling: organiz- 
ing knowledge for natural language processing. 
In Proceedings of the Fifth International Work- 
139 
shop on Natural Language Generation, Pitts- 
burgh, June. 
Denis Carcagno and Lidija Iordanskaja. 1993. Con- 
tent determination a d text structuring: two in- 
terrelated processes. In Helmut Horocek and Mi- 
chael Zock, editors, New Concepts in Natural Lan- 
guage Generation, Communication i Artificial 
Intelligence Series, pages 10 - 26. Pinter: London. 
Robert Dale, Stephen J Green, Maria Milosavljevic, 
CEcile Paris, Cornelia Verspoor, and Sandra Wil- 
liams. 1998. The realities of generating natural 
language from databases. In "Proceedings of the 
11th Australian Joint Conference on Artificial In- 
telligence, Brisbane, Australia, 13-17 July. 
Alistair Knott, Michael O'Donnell, Jon Oberlander, 
and Chris Mellish. 1997. Defeasible rules in con- 
tent selection and text structuring. In Proceedings 
of the 6th European Workshop on Natural Lan- 
guage Generation, Gerhard-Mercator University, 
Duisburg, Germany, March 24 - 26. 
Chris Mellish, Mick O'Donnell, Jon Oberlander, and 
Alistair Knott. 1998. An architecture for oppor- 
tunistic text generation. In Proceedings of the 
Ninth International Workshop on Natural Lan- 
guage Generation, Niagara-on-the-Lake, Ontario, 
Canada. 
Maria Milosavljevic. 1997. Augmenting the user's 
knowledge via comparison. In Proceedings of the 
6th International Conference on User Modelling, 
pages 119-130, Sardinia, 2-5 June. 
Maria Milosavljevic. 1999. Maximising the Co- 
herence of Descriptions via Comparison. Ph.D. 
thesis, Macquarie University, Sydney, Australia. 
Scott Nowson. 1999. Acquiring ILEX for a Per- 
sonnel Domain. Honours Thesis, Artificial Intel- 
ligence, University of Edinburgh. 
Michael O'Donnell. 1996. Input specification i the 
wag sentence generation system. In Proceedings of 
the 8th International Workshop on Natural Lan- 
guage Generation, Herstmonceux Castle, UK, 13- 
15 June. 
140 - ' 
RSTToo l  2 .4  - A Markup  Too l  fo r  Rhetor ica l  S t ruc ture  Theory  
Michael O'Donnell (micko@dai.ed.ac.uk) 
Division of Informatics, University of Edinburgh. 
Abst rac t  
RSTTool is a graphical tool for annotating a text in 
terms of its rhetorical structure. The demonstration 
will show the various interfaces of the tool, focusing 
on its ease of use. 
1 In t roduct ion  
This paper describes the RSTTool, a graphical in- 
terface for marking up the structure of text. While 
primarily intended to be used for marking up Rhet- 
orical Structure (cf. Rhetorical Structure Thegry 
(RST): Mann and Thompson (1988)), the tool also 
allows the mark-up of constituency-style analysis, as 
in Hasan's Generic Structure Potential (GSP - cf. 
Hasan (1996)). 
The tool is written in the platform-independent 
scripting language, Tcl/Tk, and thus works under 
Windows, Macintosh, UNIX and LINUX operating 
systems. 
RSTTool is easy to use, one creates an RST dia- 
gram from a text by dragging from segment to seg- 
ment, indicating rhetorical dependency. There is a 
separate interface for text segmentation. The tool 
can automatically segment at sentence boundaries 
(with reasonable accuracy), and the user clicks on 
the text to add boundaries missed by the automatic 
segmenter (or click on superfluous boundaries to re- 
move them). 
The tool was previously described in O'Donnell 
(1997). However, since then tile tool has been sub- 
stantially revised and extended,(the current version 
being 2.4). This version is also far more robust due 
to extensive debugging by one of RST's inventor's, 
Bill Mann. Particular improvements in the tool in- 
clude: 
1. GUI for defining relation: ability to add, re- 
name, delete, etc. tile relations used using a 
graphical user interface. 
2. St.atistical Analysis: a new interface was added. 
which allows users to be presented with statist- 
its regarding the proportional use of relations 
in a text. 
3. Output Options: the new tool allows saving 
of RST analyses in postscript (for inclusion in 
Latex documents), or sending diagrams directly 
to the printer. Files are now saved in an XML 
format, to facilitate importation in other sys- 
tems. 
4. Improved Structuring: the possibilities for 
structuring have improved, allowing the in- 
sertion of spans, multinuclear elements and 
schemas within existing structure. 
The Tool consists of four interfaces, which will be 
described in following sections: 
1. Text Segmentation: for marking the boundaries 
between text segments; 
2. Text Structuring: for marking the structural re- 
lations between these segments; 
3. Relation Editor: for maintaining the set of dis- 
course relations, and schemas; 
4. Statistics: for deriving simple descriptive stat- 
istics based on the analysis. 
2 What  is RSTToo l  For?  
The RSTTool is an analysis tool, but most users of 
the tool are researchers in the text generation field. 
For this reason, we present he tool at this confer- 
ence. 
Several reasons for using the tool are: 
. Corpus Studies: before one can generate text, 
one nmst understand the rhetorical patterns of 
language. By performing analyses of texts sin> 
ilar to which one wishes to generate, one can 
identify the recurrent structures in tile text-type 
and work towards understanding their context 
of use. 
o Results Verification: often, a particular study 
may be challenged by other researchers. If the 
study was performed using RSTTool, the cor- 
pus supporting the study can be released for 
analysis by others. Previously, most RST ana- 
lysis was done bv hand, malting distribution of 
253 
.~.L . . ~ . . ? . ~ ~ ~ . ~ , ~ ~  ~ , .  &~.-.,~15~5~;, ,~.~2~9~:.~., ~$ ..g-= '. , ,.~ * ." ? .:, z~ . . . . .  ? a 
~ _ w i t h  the ~oftware~ 
~ d i v i d u a l f ' ~ e s . \ ]  . . .  
..... he author hereby gra, t permission to use, copy, modify, 
~d is t r ibute ,  and license this software and ?t6  documentation for 
~ a n y  purpose, ~ provided that existing copyright notices are 
~ '~reta ined  in all copies; and that this notice is iscluded verbat im 
~ | i n  any distributions.~ No written agree~aent, license, or royalty 
 fee is required for any of the authorized use~s.i 
~.~,~,~,~,~IModtflcations . to th i s  software may be copyrighted by their 
~|authors< mnd need not follow the licensing terms described here,: 
(~h~9~prov ided  that~ the new terms are clearly indicated on the first 
~N.:'t&~NI~ge of e~h file ~here ~h~y ~pp~y.:! 
Figure h The Segmentation I terface 
corpora difficult. RSTTool thus not only sim- 
plifies the production of the corpus, but also 
allows ease of distribution and verification. 
. Diagram Preparation: the RSTTool can also be 
used for diagram preparation, for inclusion in 
papers. The tool allows diagrams to be expor- 
ted as EPS files, ready for inclusion in LaTeX 
documents (as demonstrated in this paper). For 
PCs and Mac, screen-dumps of diagrams are 
possible (Tcl/Tk does not yet fully support ex- 
port of GIF or JPG formats, and conversion 
from EPS to other formats is primitive). Some 
versions of MS Word allow the inclusion of EPS 
diagrams. 
o A Teaching Tool: by getting students to analyse 
texts with the RSTTool, teachers of discourse 
theory can increase the student's understanding 
of the theory. 
To allow RSTTool analyses to be more generally 
usable, the tool now saves its analyses in an XML 
format, making loading into other systems for pro- 
cessing much simpler. 
3 Segmentat ion  In ter face  
The first step in RST analysis is to deternline seg- 
ment boundaries. RSTTool provides an interface to 
facilitate this task. The user starts by "importing" a
plain text file. The user can then automatically seg- 
ment at sentence boundaries by pressing the "Sen- 
tences" button. This segmentation is not 100% re- 
liable, but is reasonably intelligent. The user carl 
then correct any mistakes made by the automatic 
segnrentation, and also add in segment boundaries 
within sentences. 
To add a segment boundary, the user simply clicks 
at the t)oint of the text where the boundary is de- 
sired. A boundary marker is inserted. To temove 
a boundary, the user simply clicks on the boundary 
marker. Figure 1 shows the Segmentation i terface 
after clausal segmentation. 
The user can also edit the text, correcting mis- 
takes, etc.,.by switching to Edit mode. 
The user then moves to the Structuring interface 
by clicking on the "Structurer" button at the top of 
the window. Note that the user can return at any 
point to the Segmentation i terface, to change seg- 
ment boundaries, or edit text. These changes are 
automatically accounted for in the structuring com- 
ponent. 
4 S t ruc tur ing  In ter face  
The next step involves structuring the text. The 
second interface of the RSTTool allows the user to 
connect he segments into a rhetorical structure tree. 
as shown in figure 2. We have followed the graphical 
style presented in Mann and Thompson (1988). 
The tool supports not only RST structuring, but 
also constituency structuring. I believe that texts 
cannot always be analysed totally in ternrs of rhet- 
orical relations, and that some level of schematic 
analysis complements the rhetorical analysis. For 
instance, a typical conference paper (such as this 
one) can be assigned a top level schematic structure 
of 
T i t le  - Author  ^ Ins t i tu t ion  - Abst rac t  
" Sect ion*  - B ib l iography  
The R.STTool allows intermixing of such schema 
with RST analysis. 
Initially, all segments are unconnected, ordered at 
the top of the window. The user can then drag tile 
mouse from one segment (tile satelite) to another 
(the nucleus) to link them. 
The system allows both plain RST relations and 
also multi-nuclear relations (e.g., Joint, Sequence, 
254 
Figure 2: The Structuring Interface 
1-2 3-4 
When he took it It was as heavy and he was because he 
up, as lead, going to throw it thought a trick 
away, had been played 
on him. 
Figure 3: RST Structuring 
Orie_ = 
TWO old men 2-3 
sitting talking In 
a reUrement ______~-'~e~oenc>.~__ 
home. One asks, The other 
"How's your replies, "No 
memory?" problem at all, 
touch wood", as 
he knocked on 
the oak table. 
Pun; l ine  
Two minutes go 
by, and he says 
"isn't anyone 
going to get that 
door!" 
Figure 4: Schema-based Structuring 
etc.). Scoping is also possible, whereby tile user in- 
dicates that the nucleus of a relation is not a seg- 
ment itself, but rather a segment and all of its satel- 
lites. See figure 3 for an example combining normal 
RST relations (Circumstance, Motivation); nmlti- 
nuclear structure (Conjunction), and scoping (the 
nodes marked 1-2 and 3-4). In addition, schemas 
can be used to represent constituency-type struc- 
tures. See figure 4. 
Because RST-structures can become very elabor- 
ate, the RSTTool allows the user to collapse sub- 
trees - hiding the substructure under a node. This 
makes it easier, for instance, to comtect wo nodes 
which normally would not appear on the same page 
of the editor. 
5 Editing Relations 
The tool provides an interface for editing relation 
sets. The user can add, delete or rename relations. 
If the relation is in use in the current analysis, the 
changes are propagated throughout the analysis. 
6 Statistical Analysis 
Discussions on the RST mail list have demonstrated 
that there is a community concern with frequency 
of different relations in specific text-types. The 
RSTTool, by providing counts of relations within a 
text, supports this research goal. See figure 5. 
The interface shows not only the frequency of re- 
lations, but also the ratio of Nuc Sat orderings to 
Sat lquc orderings for the relation (valuable data for 
both generation and automatic discourse structure 
recognition). 
7 Summary 
RSTTool is a robust tool which facilitates manual 
analysis of a text's rhetorical structure. These ana- 
lyses can be used for a number of purposes, including 
i) to improve understanding of discourse structure, 
to aid in either text generation or analysis; ii) dia- 
gram preparation, and iii) as a teaching tool. 
The main improvement in the latest version of the 
tool is the statistical analysis interface. Later ver- 
sions of the.tool will extend oll this aspect, increas- 
ing the range of analyses which can be performed on 
each text, or collection of texts. 
Future versions will also add code for automatic 
structure recognition, using such work ms Marcu's 
RST recognition tool (Marcu, 1997). While tile au- 
thor believes that automatic recognition is not yet 
reliable, integrating such a tool into an R ST Markup 
255 
Figure 5: The Statistics Interface 
tool allows the recognition software to provide a first 
draft, which the human editor can correct to their 
liking. At present, such a mixture of automatic and 
human-directed mark-up is the best way of achieving 
accurate mark-up of text structure. 
Re ferences  
Ruqaiya Hasan. 1996. The nursery tale as a genre. 
In Carmel Cloran, David Butt, and Geoff Willi- 
ams, editors, Ways of Saying: Ways of Meaning. 
Cassell, London. Previously published in Notting- 
ham Linguistics Circular 13, 1984. 
W.C. Mann and S. Thompson. 1988. Rhetorical 
structure theory: Toward a functional theory of 
text organization. Text, 8(3):243-281. 
Daniel Marcu. 1997. The rhetorical parsing of 
natural language texts. In The Proceedings of 
the 35th Annual Meeting of the Association for 
Computational Linguistics, (A CL '97lEA CL '97), 
pages 96-103, Madrid, Spain, July 7-10. 
Michael O'Donnell. 1997. Rst-tool: An rst analysis 
tool. In Proceedings off the 6th European Work- 
shop on Natural Language Generation, pages 92 - 
96, Gerhard-Mercator University, Duisburg, Ger- 
many, March 24 - 26. 
256 
Demonstrat ion of ILEX 3.0 
Michae l  O 'Donne l l t  (micko@dai .ed.ac .uk) ,  
A l is ta i r  Knott:~ (a l ik@hermes.otago.ac .nz) ,  
Jon  Ober lander t  ( jon@cogsci .ed.ac.uk) ,  
Chr is  Mel l isht (chr ism@dai .ed.ac .uk)  
t Divis ion o f  Informat ics ,  Un ivers i ty  of  Ed inburgh .  
:~ Depar tment  of  Computer  Science ~ Otago  University.  
Abst rac t  
We will demonstrate the ILEX system, a system 
which dynamically generates descriptions of data- 
base objects for the web, adapting the description to 
the discourse context and user type. Among other 
improvements in version 3, the system now gener- 
ates from relational databases, and this demonstra- 
tion will focus on this ability. We will also show how 
incremental extensions to the domain semantics im- 
prove the quality of the text produced. 
1 In t roduct ion  
ILEX is a tool for dynamic browsing of database- 
defined information: it allows a user to browse 
through the information in a database using hyper- 
text. ILEX generates descriptions of a database ob- 
ject on the fly, taking into account he user's con- 
text of browsing. For more information on ILEX, 
see Knott et al (1997) and Mellish et al (1998). 
The demonstration will consist of generating a
series of texts, in each case adding in additional com- 
ponents of the domain semantics. This short paper 
should be read in conjunction with the full paper 
elsewhere in this volume. 
2 Generat ing  f rom Bare  Data  
We start initially with a relational database, as 
defined by a set of tab-delimited database files, plus 
some minimal semantics. As discussed in the paper, 
we use assume a relational database to consist of two 
types of files: 
1. Entity Files: each of which provides data for 
a particular entity type. Each row (or record) 
defines the attributes of a different entity. See 
figure 1. 
2. Link Files: where a particular attribute may 
have multiple fillers, we use link files to define 
the entity-entity relations. See figure 2. 
To generate from these files, the dolnain-editor 
needs to provide two additional resources: 
1. Data-type specification for each entity-file, a 
specification of what data-type the values in the 
~ Material 
silver 
enamel 
gold 
Figure 2: A Sample from a Link file 
. 
3. 
column are, e.g., string, entity-id, domain type, 
etc. 
Domain Taxonomy: detailing the taxonomic or- 
ganisation of the various classes of the entities. 
Mapping Domain taxonomy onto Upper Model: 
ILEX uses an Upper Model (a domain- 
independent semantic taxonomy, see Bateman 
(1990)), which supports the grammatical ex- 
pression of entities, e.g., selection of pronoun, 
differentiation between mass and count entities, 
between things and qualities, etc. We require 
that the basic types in the domain taxonomy 
are mapped onto the upper model, to allow the 
entities to be grammaticalised and lexicalised 
appropriately. 
With just this semantics, we can generate texts, 
although impoverished texts, such as: 
The class of J-997 is necklace. It's de- 
signer is Jessie M. King. It's date is 1905. 
Several tricks are needed to generate without a 
specified omain semantics: 
Use of standard clause templates: lacking any 
knowledge of how different attributes are to be 
expressed, the system-can only generate ach 
attribute using a standard template structures, 
such as the X of Y is Z or It's X is Z. The 
attribute names, e.g., Designer, Style, etc. can 
be assumed to work as the lexical head of the 
Subject. This ploy sometimes goes wrong, but 
in general works. (this approach borrowed from 
Dale et al (1998)). 
257 
ID Class 
J-997 brooch 
J~998: :neddace 
J-999 i necklace 
etc. I 
Designer Date Style Place Sponsor 
King01 11905 Art-Deco London Liberty01 
King01 '19116 - Art-Deco "London 
Chanel01 1910 Art-Noveau Paris 
Figure 1: A Sample from an Entity file 
* Referring to Entities: there are a number of 
strategies open for referring to entities. If the 
Name attribute.is.supplied-(a:defined- attribute 
within the ILEX system), then the system can 
use this for referring. Lacking a name, it is pos- 
sible for the system to form nominal references 
using the Class attr ibute of the entity (all en- 
tities in ILEX databases are required to have 
this attribute provided). We could thus gener- 
ate indefinite references such as a brooch as first 
mentions, and on subsequent mentions, gener- 
ate forms such as the brooch or the brooch whose 
designer is Jessie M. King. Without specifica- 
tion of which entities should be considered part 
of the general knowledge of the reader, we must 
assume all entities are initially unknown. 
* Fact Annotations: ILEX was designed to work 
with various extra information known about 
facts, such as the assumed level of interest to the 
current reader model, the importance of the fact 
to the system's educational agenda, and the as- 
sumed assimilation of the information (how well 
does the system believe the reader to already 
understand it). See the main paper for more 
details. 
Lacking this information, the system assumes 
an average value for interest and importance, 
and a 0 value for assimilation (totally un- 
known). 
With only default values, the system cannot 
customise the text to the particular user. It may 
provide information already well known by the 
user, and thus risking boring them. Also, there 
can be no selection of information to ensure that 
the more interesting and important information 
is provided on earlier pages (the reader may not 
bother to look at later pages). 
Other information (defeasible rules), which allows 
us to organise the material into complex rhetorical 
structure, is also missing. 
So, these tricks allow us to generate simple texts, 
consisting of a list of template-formatted clauses. 
3 Add ing  Express ion  in fo rmat ion  
In the next step, we will add in information about 
how the various attributes hould be expressed. This 
includes three main resources: 
1. Syntactic expression of attributes: for each at- 
tribute, we provide a specification of how the 
......... ~. ~.~ribu:te~should~be~-expressed. syntactically. 
2. Lexicalisation of domain types: by providing 
a lexicon, which maps domain types to lexical 
items, we avoid problems of using the domain 
type itself as the spelling. The lexical inform- 
ation allows correct generation of inflectional 
forms (e.g., of the plural for nouns, comparative 
or superlative forms for adjectives). 
3. Restrictive modifiers for referring expressions: 
In choosing restrictive modifiers for forming re- 
ferring expressions, ome facts work better than 
others. For instance, the brooch designed by 
King is more likely to refer adequately than the 
brooch which was 3 inches long. ILEX allows 
the user to state the preferential order for choos- 
ing restrictive modifiers. 
The addition of these resources will result in im- 
proved expression within the clauses, but not af- 
fect the text structure itself, which are still a list 
of clauses in random order. 
4 Add ing  User  Annotat ions  
In the next step, we add in the user model, which 
provides, for each attribute type, predicted user in- 
terest, importance for the system, and expected user 
assimilation. 
Using these values, ILEX can start to organise 
the text, placing important/interesting i formation 
on earlier pages, and avoiding information already 
known by tile user. 
5 Add ing  Defeas ib le  Ru les ,  S tor ies  
As a final step, we add in various resources which 
improve the texture of the text. 
o Defeasible Rules: ILEX allows the assertion 
of generalisations like most Art Deco jewels 
use enamel. These rules allow the genera- 
tion of complex rhetorical structures which in- 
dude Generalisation, Exemplification and Con- 
cession. The use of these relations improves tim 
quality of the text generated. 
* Stories: much of the information obtainable 
about tile domain is in natural language. Of- 
ten, the information is specific to a particular 
258 
entity, and as such, it would be a waste of time 
to reduce the in.formation i to ILEX's Pred-Arg 
knowledge structure, just to regenerate he text. 
Because of this, ILEX allows the association 
of canned text with a database ntity (e.g., J- 
999), or type of entity (e.g., jewels designed for 
Liberty). The text can then be included in the 
text when the entity or type of entity is men- 
tioned. 
The intermixing of generated and canned text 
improves the qual i ty of generated texts by 
providing more variety of structures, and al- 
lowing anecdotes, which would be difficult to 
model in terms of the knowledge representation 
system. 
6 Conc lus ion  
By showing incremental addition of domain spe- 
cification within the ILEX system, we have demon- 
strated that it is a system which can function with 
varying degrees of information. This allows domain 
developers to rapidly prototype a working system, 
after which they can concentrate on improving the 
quality of text in the directions they favour. 
Re ferences  
John Bateman. 1990. Upper modeling: organiz- 
ing knowledge for natural language processing. 
In Proceedings of the Fifth International Work- 
shop on Natural Language Generation, Pitts- 
burgh, June. 
Robert Dale, Stephen J Green, Maria Milosavljevic, 
CEcile Paris, Cornelia Verspoor, and Sandra Wil- 
liams. 1998. The realities of generating natural 
language from databases. In Proceedings of the 
11th Australian Joint Conference on Artificial In- 
telligence, Brisbane, Australia, 13-17 July. 
Alistair Knott, Michael O'Donnell, Jon Oberlander, 
and Chris Mellish. 1997. Defeasible rules in con- 
tent selection and text structuring. In Proceedings 
of the 6th European Workshop on Natural Lan- 
9uage Generation, Gerhard-Mercator University, 
Duisburg, Germany, March 24 - 26. 
Chris Mellish, Mick O'Donnell, Jon Oberlander, and 
Alistair Knott. 1998. An architecture for oppor- 
tunistic text generation. In Proceedings of the 
Ninth International Workshop on Natural Lan- 
guage Generation, Niagara-on-the-Lake, Ontario, 
Canada. 
259 
Proceedings of the ACL-08: HLT Demo Session (Companion Volume), pages 13?16,
Columbus, June 2008. c?2008 Association for Computational Linguistics
Demonstration of the UAM CorpusTool for text and image annotation 
 
 
Mick O?Donnell 
Escuela Polit?cnica Superior 
Universidad Aut?noma de Madrid 
28049, Cantoblanco, Madrid, Spain 
michael.odonnell@uam.es 
 
 
 
 
 
 
Abstract 
This paper introduced the main features of the 
UAM CorpusTool, software for human and 
semi-automatic annotation of text and images. 
The demonstration will show how to set up an 
annotation project, how to annotate text files 
at multiple annotation levels, how to auto-
matically assign tags to segments matching 
lexical patterns, and how to perform cross-
layer searches of the corpus. 
1 Introduction 
In the last 20 years, a number of tools have been 
developed to facilitate the human annotation of 
text. These have been necessary where software for 
automatic annotation has not been available, e.g., 
for linguistic patterns which are not easily identi-
fied by machine, or for languages without suffi-
cient linguistic resources. 
The vast majority of these annotation tools have 
been developed for particular projects, and have 
thus not been readily adaptable to different annota-
tion problems. Often, the annotation scheme has 
been built into the software, or the software has 
been limited in that they allow only certain types 
of annotation to take place. 
A small number of systems have however been 
developed to be general purpose text annotation 
systems, e.g., MMAX-2 (M?ller and Strube 2006), 
GATE (Cunningham et al2002), WordFreak 
(Morton and LaCivita 2003) and Knowtator 
(Ogren 2006). 
With the exception of the last of these however, 
these systems are generally aimed at technically 
advanced users.  WordFreak, for instance, requires 
writing of Java code to adapt to a different annota-
tion scheme. Users of MMAX-2 need to edit XML 
by hand to provide annotation schemes. Gate al-
lows editing of annotation schemes within the tool, 
but it is a very complex system, and lacks clear 
documentation to help the novice user become 
competent. 
The UAM CorpusTool is a text annotation tool 
primarily aimed at the linguist or computational 
linguist who does not program, and would rather 
spend their time annotating text than learning how 
to use the system. The software is thus designed 
from the ground up to support typical user work-
flow, and everything the user needs to perform an-
notation tasks is included within the software. 
2 The Project Window 
In the majority of cases, the annotator is interested 
in annotating a range of texts, not just single texts. 
Additionally, in most cases annotation at multiple 
linguistic levels is desired (e.g., classifying the text 
as a whole, tagging sections of text by function 
(e.g., abstract, introduction, etc.), tagging sen-
tences/clauses, and tagging participants in clauses. 
To overcome the complexity of dealing with mul-
tiple source files annotated at multiple levels, the 
main window of the CorpusTool is thus a window 
for project management (see Figure 1). 
 
13
 Figure 1: The Project Window of UAM CorpusTool 
 
 
Figure 3: An annotation window for ?Participant? layer. 
 
<?xml version='1.0' encoding='utf-8'?> 
<document> 
  <segments> 
    <segment id='1' start='158' end='176' 
             features='participant;human' state='active'/> 
    <segment id='2' start='207' end='214' 
               features='participant;organisation;company'  
               state='active'/> 
   ... 
  </segments> 
</document> 
Figure 4: Annotation Storage Example 
 
14
This window allows the user to add new annota-
tion layers to the project, and edit/extend the anno-
tation scheme for each layer (by clicking on the 
?edit? button shown with each layer panel). It also 
allows the user to add or delete source files to the 
project, and to open a specific file for annotation at 
a specific layer (each file has a button for each 
layer). 
3 Tag Hierarchy Editing 
Most of the current text annotation tools lack built-
in facilities for creating and editing the coding 
scheme (the tag set). UAM CorpusTool uses a hie-
rarchally organised tag scheme, allowing cross-
classification and multiple inheritance (both dis-
junctive and conjunctive). The scheme is edited 
graphically, adding, renaming, moving or deleting 
features, adding new sub-distinctions, etc. See Fig-
ure 3. 
An important feature of the tool is that any 
change to the coding scheme is automatically 
propagated throughout all files annotated at this 
layer. For instance, if a feature is renamed in the 
scheme editor, it is also renamed in all annotation 
files. 
The user can also associate a gloss with each 
tag, and during annotation, the gloss associated 
with each feature can be viewed to help the coder 
determine which tag to assign. 
participant
PARTICIPANTS-
TYPE
person
country
organisation ORGANISATION-TYPE
company
government
union
other-organisation
political-party
FORM
proper
common
pronominal
 
Figure 2: Graphical Editing of the Tag Hierarchy 
4 Annotation Windows 
When the user clicks on the button for a given text 
file/layer, an annotation window opens (see Figure 
3). This window shows the text in the top panel 
(with previously identified text segments indicated 
with underlining). When the user creates a new 
segment (by swiping text) or selects an existing 
segment, the space below the text window shows 
controls to select the tags to assign to this segment. 
Tags are drawn from the tag scheme for the current 
layer. Since the tag hierarchy allows cross-
classification, multiple tags are assigned to the 
segment. CorpusTool allows for partially overlap-
ping segments, and embedding of segments. 
Annotated texts are stored using stand-off XML, 
one file per source text and layer. See Figure 4 for 
a sample. The software does not currently input 
from or export to any of the various text encoding 
standards, but will be extended to do so as it be-
comes clear which standards users want supported. 
Currently the tool only supports assigning tags 
to text. Annotating structural relations between text 
segments (e.g., co-reference, constituency or rhe-
torical relations) is not currently supported, but is 
planned for later releases. 
5 Corpus Search 
A button on the main window opens a Corpus 
Search interface, which allows users to retrieve 
lists of segments matching a query. Queries can 
involve multiple layers, for instance, subject 
in passive-clause in english would 
retrieve all NPs tagged as subject in clauses tagged 
as passive-clause in texts tagged as ?english? (this 
is thus a search over 3 annotation layers). Searches 
can also retrieve segments ?containing? segments. 
One can also search for segments containing a 
string. 
Where a lexicon is provided (currently only 
English), users can search for segments containing 
lexical patterns, for instance, clause con-
taining ?be% @participle? would return 
all clause segments containing any inflection of 
?be? immediately followed by any participle verb 
(i.e. most of the passive clauses). Since dictionaries 
are used, the text does not need to be pre-tagged 
with a POS tagger, which may be unreliable on 
texts of a different nature to those on which the 
tagger was trained. Results are displayed in a 
KWIK table format. 
6 Automating Annotation 
Currently, automatic segmentation into sentences 
is provided. I am currently working on automatic 
NP segmentation.  
The search facility outlined above can also be 
used for semi-automatic tagging of text. To auto-
code segments as ?passive-clause?, one specifies a 
search pattern (i.e., clause containing 
15
?be% @participle?). The user is presented 
with all matches, with a check-box next to each. 
The user can then uncheck the hits which are false 
matches, and then click on the ?Store? button to 
tag all checked segments with the ?passive-clause? 
feature. A reasonable number of syntactic features 
can be identified in this way. 
7 Statistical processing 
The tool comes with a statistical analysis interface 
which allows for specified sub-sections of the cor-
pora (e.g., ?finite-clause in english? vs. ?finite-
clause in spanish?)  to be described or contrasted. 
Statistics can be of the text itself (e.g., lexical den-
sity, pronominal usage,  word and segment length, 
etc.), or relate to the frequency of annotations. 
These statistics can also be exported in tab-
delimited form for processing in more general sta-
tistical packages. 
8 Intercoder Reliability Testing 
Where several users have annotated files at the 
same layers, a separate tool is provided to compare 
each annotation document, showing only the dif-
ferences between coders, and also indicating total 
coder agreement. The software can also produce a 
?consensus? version of the annotations, taking the 
most popular coding where 3 or more coders have 
coded the document. In this way, each coder can 
be compared to the consensus (n comparisons), 
rather than comparing the n! pairs of documents.  
9 Annotating Images 
The tool can also be used to annotate images in-
stead of text files. In this context, one can swipe 
regions of the image to create a selection, and as-
sign features to the selection. Since stand-off anno-
tation is used for both text and image, much of the 
code-base is common between the two applica-
tions. The major differences are: i) a different an-
notation widget is used for text selection than for 
image selection; ii) segments in text are defined by 
a tuple: (startchar, endchar), while image segments 
are defined by a tuple of points ( (startx,starty), 
(endx,endy)), and iii) search in images is restricted 
to tag searching, while text can be searched for 
strings and lexical patterns. 
10 Conclusions 
UAM CorpusTool is perhaps the most user-
friendly of the annotation tools available, offering 
easy installation, an intuitive interface, yet power-
ful facilities for management of multiple docu-
ments annotated at multiple levels. 
The main limitation of the tool is that it cur-
rently deals only with feature tagging. Future work 
will add structural tagging, including co-reference 
linking, rhetorical structuring and syntactic struc-
turing. 
The use of the tool is rapidly spreading: in the 
first 15 months of availability, the tool has been 
downloaded 1700 times, to 1100 distinct CPUs 
(with only minimal advertisement). It is being used 
for various text annotation projects throughout the 
world, but mostly by individual linguists perform-
ing linguistic studies.   
UAM CorpusTool is free, available currently for 
Macintosh and Windows machines. It is not open 
source at present, delivered as a standalone execu-
table. It is implemented in Python, using TKinter . 
Acknowledgments 
The development of UAM CorpusTool was par-
tially funded by the Spanish Ministry of Education 
and Science (MEC) under grant number 
HUM2005-01728/FILO (the WOSLAC project). 
References  
C. M?ller, and M. Strube. 2006. Multi-Level Annotation 
of Linguistic Data with MMAX2. In S. Braun, K. 
Kohn, J. Mukherjee (eds.) Corpus Technology 
and Language Pedagogy. New Resources, New 
Tools, New Methods (English Corpus Linguis-
tics, Vol.3). Frankfurt: Peter Lang. 197-214. 
H. Cunningham, D. Maynard, K. Bontcheva and V. 
Tablan. 2002. GATE: A Framework and Graphi-
cal Development Environment for Robust NLP 
Tools and Applications. Proceedings of the 40th 
Meeting of the Association for Computational 
Linguistics (ACL'02). Philadelphia, July 2002. 
T.S. Morton and J. LaCivita. 2003. WordFreak: An 
Open Tool for Linguistic Annotation. Proceed-
ings of HLT-NAACL. 17-18. 
P.V. Ogren 2006. Knowtator: a plug-in for creating 
training and evaluation data sets for biomedical 
natural language systems. Proceedings of the 9th 
International Prot?g? Conference. 73?76. 
 
16
