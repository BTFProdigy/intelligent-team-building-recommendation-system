Topic Identification In Natural Language Dialogues Using
Neural Networks
Krista Lagus and Jukka Kuusisto
Neural Networks Research Centre, Helsinki University of Technology
P.O.Box 9800, FIN-02015 HUT, Finland
krista.lagus@hut.fi
Abstract
In human?computer interaction sys-
tems using natural language, the
recognition of the topic from user?s
utterances is an important task. We
examine two different perspectives
to the problem of topic analysis
needed for carrying out a success-
ful dialogue. First, we apply self-
organized document maps for mod-
eling the broader subject of dis-
course based on the occurrence of
content words in the dialogue con-
text. On a Finnish corpus of 57
dialogues the method is shown to
work well for recognizing subjects of
longer dialogue segments, whereas
for individual utterances the sub-
ject recognition history should per-
haps be taken into account. Sec-
ond, we attempt to identify topically
relevant words in the utterances
and thus locate the old information
(?topic words?) and new information
(?focus words?). For this we define a
probabilistic model and compare dif-
ferent methods for model parameter
estimation on a corpus of 189 dia-
logues. Moreover, the utilization of
information regarding the position
of the word in the utterance is found
to improve the results.
1 Introduction
The analysis of the topic of a sentence or a
document is an important task for many nat-
ural language applications. For example, in
interactive dialogue systems that attempt to
carry out and answer requests made by cus-
tomers, the response strategy employed may
depend on the topic of the request (Jokinen et
al., 2002). In large vocabulary speech recog-
nition knowledge of the topic can, in general,
be utilized for adjusting the language model
used (see, e.g., (Iyer and Ostendorf, 1999)).
We describe two approaches to analyzing
the topical information, namely the use of
topically ordered document maps for analyz-
ing the overall topic of dialogue segments, and
identification of topic and focus words in an
utterance for sentence-level analysis and iden-
tification of topically relevant specific infor-
mation in short contexts.
1.1 Document map as a topically
ordered semantic space
The Self-Organizing Map (Kohonen, 1982;
Kohonen, 1995) is an unsupervised neural
network method suitable for ordering and vi-
sualization of complex data sets. It has been
shown that very large document collections
can be meaningfully organized onto maps that
are topically ordered: documents with similar
content are found near each other on the map
(Lin, 1992; Honkela et al, 1996; Lin, 1997;
Kohonen et al, 2000).
The document map can be considered to
form an ordered representation of possible
topics, i.e., a topical semantic space. Each
set of map coordinates specifies a point in the
semantic space, and additionally, corresponds
to a subset of the corpus, forming a kind of
associative topical-semantic memory.
Document maps have been found useful in
text mining and in improving information re-
      Philadelphia, July 2002, pp. 95-102.  Association for Computational Linguistics.
                  Proceedings of the Third SIGdial Workshop on Discourse and Dialogue,
trieval (Lagus, 2000). Recent experiments in-
dicate that the document maps ordered using
the SOM algorithm can be useful in focusing
the language model to the current active vo-
cabulary (Kurimo and Lagus, 2002).
In this article we examine the usefulness
of document maps for analyzing the topics of
transcripts of natural spoken dialogues. The
topic identification from both individual ut-
terances and longer segments is studied.
1.2 Conceptual analysis of individual
utterances
Within a single utterance or sentence the
speaker may provide several details that spec-
ify the request further or provide additional
information that specifies something said ear-
lier. Automatic extraction of the relevant
words and the concepts they relate to may be
useful, e.g., for a system filling out the fields
of a database query intended to answer the
user?s request.
If a small set of relevant semantic concepts
can be defined, and if the sentence structures
allowed are strictly limited, the semantic con-
cept identification problem can be solved, at
least to some degree, by manually designed
rule-based systems (Jokinen et al, 2002).
However, if the goal is the analysis of free-
form dialogues, one cannot count on hearing
full sentences. It is therefore important to try
to formulate the task as a learning problem
into which adaptive, statistical methods can
be applied.
The major challenge in adaptive language
modeling is the complexity of the learning
problem, caused by large vocabularies and
large amount of variation in sentence struc-
tures, compared to the amount of learning
data available. For English there already exist
various tagged and analyzed corpora. In con-
trast, for many smaller languages no tagged
corpora generally exist. Yet the methods that
are developed for English cannot as such be
applied for many other languages, such as
Finnish.
In the analysis of natural language di-
alogues, theories of information structure
(Sgall et al, 1986; Halliday, 1985) concern the
semantic concepts and their structural prop-
erties within an utterance. Such concepts in-
clude the attitudes, prior knowledge, beliefs
and intentions of the speaker, as well as con-
cepts identifying information that is shared
between the speakers. The terms ?topic? and
?focus? may be defined as follows: ?topic? is
the general subject of which the user is talk-
ing about, and ?focus? refers to the specific
additional information that the user now in-
troduces about the topic. An alternative way
of describing these terms is that ?topic? con-
stitutes of the old information shared by both
dialogue participants and ?focus? contains the
new information which is communicated re-
garding the topic.
A traditional way of finding the old and
new information is the ?question test? (see
(Vilkuna, 1989) about using it for Finnish).
For any declarative sentence, a question is
composed so that the sentence would be a nat-
ural answer to that question. Then the items
of the sentence that are repeated in the ques-
tion belong to the topic and the new items to
the focus.
A usual approach for topic?focus identi-
fication is to use parsed data. The sen-
tence, or it?s semantic or syntactic-semantic
representation, is divided into two segments,
usually at the location of the main verb,
and the words or semantical concepts in
the first segment are regarded as ?topic?
words/concepts and those in the second as ?fo-
cus? words/concepts. For example in (Meteer
and Iyer, 1996), the division point is placed
before the first strong verb, or, in the absence
of such a verb, behind the last weak verb of
the sentence. Similar division is also the start-
ing point for the algorithm for topic?focus
identification introduced in (Hajic?ova? et al,
1995). The initial division is then modified
according to the verb?s position and meaning,
the subject?s definiteness or indefiniteness and
the number, type and order of the other sen-
tence constituents.
In language modeling for speech recogni-
tion improvements in perplexity and word er-
ror rate have been observed on English cor-
pora when using language models trained sep-
arately for the topic and the focus part of the
sentence (Meteer and Iyer, 1996; Ma et al,
1998). Identification of these concepts is likely
to be important also for sentence comprehen-
sion and dialogue strategy selection.
In this article we examine the application of
a number of statistical approaches for identifi-
cation of these concepts. In particular, we ap-
ply the notions of topic and focus in informa-
tion structure (Sgall et al, 1986) to tagging a
set of natural dialogues in Finnish. We then
try several approaches for learning to identify
the occurrences of these concepts from new
data based on the statistical properties of the
old instances.
2 Experiments on recognizing the
dialogue topic of a dialogue turn
The ordered document map can be utilized
in the analysis of dialogue topics as follows:
encode a dialogue turn, i.e., an utterance u
(or an utterance combined with its recent his-
tory) as a document vector. Locate the best-
matching map unit, or several such units. Uti-
lize the identities of the best units as a seman-
tic representation of the topic of the u. In ef-
fect, this is a latent semantic representation
of the topical content of the utterance. Eval-
uation of such a latent representation directly
amounts to asking whether the dialogue man-
ager can benefit from the representation, and
must therefore be carried out by the dialogue
manager. This direct evaluation has not yet
been done.
Instead, we have utilized the following ap-
proach for evaluating the ordering of the maps
and the generalization to new, unseen dia-
logues: An intermediate set of named seman-
tic concepts has been defined in an attempt
to approximate what is considered to be inter-
esting for the dialogue manager. The latent
semantic representation of the map is then la-
beled or calibrated to reflect these named con-
cepts. In effect, each dialogue segment is cat-
egorized to a prior topical category. The or-
ganized map is labeled using part of the data
(?training data?), and the remaining part is
used to evaluate the map (?test data?)1.
1Note that even in this case the map is ordered in
Furthermore, a statistical model for docu-
ment classification can be defined on top of
the map. The probability model used for
topic estimation is
P (Ai|S) = P (XN |S)P (Ai|XN ), (1)
where Ai is the topic category, S denotes the
text transcription of the spoken sentence and
XN is the set of N best map vectors used for
the classification. We approximate the proba-
bility P (XN |S) to be equal for each map vec-
tor inXN . We assume thatXN conveys all in-
formation about S. The terms P (Ai|XN ) are
calculated as the relative frequencies of the
topics of the document vectors in the train-
ing data that were mapped to the nodes that
correspond to XN .
2.1 Corpus: transcripts of 57 spoken
dialogues
The data used in the experiments were
Finnish dialogues, recorded from the cus-
tomer service phone line of Helsinki City
Transport. The dialogues, provided by the
Interact project (Jokinen et al, 2002), had
been transcribed into text by a person listen-
ing to the tapes.
The transcribed data is extremely collo-
quial. Both the customers and the customer
service personnel use a lot of expletive words,
such as ?nii? (?so?, ?yea?) and ?tota? (?hum?,
?er?, ?like?), often the words appear in re-
duced or otherwise non-standard forms. The
word order does not always follow grammat-
ical rules and quite frequently there is con-
siderable overlap between the dialogue turns.
For example, the utterance of speaker A may
be interjected by a confirmation from speaker
B. This had currently been transcribed as
three separate utterances: A1 B A2.
2.2 Tagging and segmentation of
dialogues
The data set was split into training and test
data so that the first 33 dialogues were used
for organization and calibration of the map
an unsupervised manner, although it is applied for the
classification of new instances based on old ones.
Table 1: Proportions of customer utterances
in each topic category in the data sets.
Training data Test data
Beginnings 0.08 0.11
Endings 0.12 0.14
Timetables 0.49 0.59
Tickets 0.16 0.11
OOD 0.15 0.06
and the 24 dialogues collected later for test-
ing.
A small number of broad topic categories
were selected so that they comprehensively
encompass the subjects of discussion occur-
ring in the data. The categories were ?timeta-
bles?, ?beginnings?, ?tickets?, ?endings?, and
?out of domain?.
The dialogues were then manually tagged
and segmented, so that each continuous dia-
logue segment of several utterances that be-
longed to one general topic category formed
a single document. This resulted in a total of
196 segments, 115 and 81 in training and test
sets, respectively. Each segment contained
data from both the customer and the assis-
tant.
Of particular interest is the analysis of the
topics of individual customer utterances. The
data was therefore split further into utter-
ances, resulting in 450 and 189 customer ut-
terances in the training and test set, respec-
tively. The relative frequencies of utterances
belonging to each topic category for both
training and test data are shown in Table 1.
Each individual utterance was labeled with
the topic category of the segment it belonged
to.
2.3 Creation of the document map
The documents, whether segments or utter-
ances, were encoded as vectors using the
methods described in detail in (Kohonen et
al., 2000). In short, the encoding was as fol-
lows. Stopwords (function words etc.) and
words that appeared fewer than 2 times in the
training data were removed. The remaining
words were weighted using their entropy over
document classes. The documents were en-
coded using the vector space model by Salton
(Salton et al, 1975) with word weights. Fur-
thermore, sparse random projection of was
applied to reduce the dimensionality of the
document vectors from the original 1738 to
500 (for details of the method, see, e.g., (Ko-
honen et al, 2000)).
In organizing the map each longer dia-
logue segment was considered as a document.
The use of longer segments is likely to make
the organization of the map more robust.
The inclusion of the utterances by the assis-
tant is particularly important given the small
amount of data?all information must be uti-
lized. The document vectors were then orga-
nized on a SOM of 6? 4 = 24 units.
2.4 Experiments and results
We carried out three tests where the length
of dialogue segments was varied. In each
case, different values of N were tried. In
the first case, longer dialogue segments in the
training data were used to estimate the term
P (Ai|XN ) whereas recognition accuracy was
calculated on customer utterances only. Next,
individual customer utterances were used also
in estimating the model term. The best recog-
nition accuracy in both cases were obtained
using the value N = 3, namely 60.3% for
the first case and 65.1% for the second case.
In the third case we used the longer dia-
logue segments both for estimating the model
and for evaluation, to examine the effect of
longer context on the recognition accuracy.
The recognition accuracy was now 87.7%, i.e.,
clearly better for the longer dialogue segments
than for the utterances.
It seems that many utterances taken out of
context are too short or nondescript to pro-
vide reliable cues regarding the topical cat-
egory. An example of such an utterance is
?Onks sinne mita?a? muuta?? (lit. ?Is to there
anything else??, the intended meaning prob-
ably being ?Does any other bus go there??).
In this case it is the surrounding dialogue (or
perhaps the Finnish morpheme corresponding
to ?to?) that would identify the correct cate-
gory, namely ?timetables?.
Moreover, results on comparing a docu-
ment map to Independent Component Analy-
sis on the same corpus are reported in (Bing-
ham et al, 2002). The slightly higher per-
centages in that paper are due to evaluating
longer segments and to reporting the results
on the whole data set instead of a separate
test set.
3 Identification of old and new
information in utterances
We define this task as the identification of
?topic words? and ?focus words? from utter-
ances of natural Finnish dialogues. There
are thus no restrictions regarding the vocabu-
lary or the grammar. By observing previous,
marked instances of these concepts we try to
recognize the instances in new dialogues. It
should be noted that this task definition dif-
fers somewhat from those discussed in Sec-
tion 1.2 in that we do not construct any con-
ceptual representation of the utterances, nor
do we segment them into a ?topic? part and
a ?focus? part. This choice is due to utiliz-
ing natural utterances in which the sentence
borders do not always coincide with the turn-
taking of the speakers?a turn may consist of
several sentences or a partial one (when inter-
rupted by a comment from the other speaker).
In other words, we try to identify the central
words that communicate the topic and focus
in an utterance. We assume that they can ap-
pear in any part of the sentence and between
them there may be other words that are not
relevant to the topic or focus. Whether these
central words form a single topic or focus or
several such concepts is left open.
3.1 Corpus and tagging
The corpus used includes the same data as
in section 2 with additional 133 dialogues
collected from the same source. Basically
each dialogue turn was treated as an utter-
ance, with the exception that long turns were
segmented into sentence-like segments, which
were then considered to be utterances2. Ut-
terances consisting of only one word were re-
2Non-textual cues such as silences within turns
could not be considered for segmenting because they
were not marked in the data.
moved from the data. The training data con-
tained 11464 words in 1704 utterances. Of the
words 17 % were tagged as topic, and 28 % as
focus. The test data consisted of 11750 words
in 1415 utterances, with 14 % tagged as topic
and 25 % as focus.
In tagging the topic and focus words in
the corpus, the following definitions were em-
ployed: In interrogative clauses focus consists
of those words that form the exact entity that
is being asked and all the other words that de-
fine the subject are tagged as belonging to the
topic. In declarative sentences that function
as answers words that form the core of the
answer are tagged as ?focus?, and other words
that merely provide context for the specific
answer are tagged as ?topic?. In other declar-
ative sentences ?topics? are words that define
the subject matter and ?focus? is applied to
words that communicate what is being said
about the topic. Regardless, the tagging task
was in many cases quite difficult, and the re-
sulting choice of tags often debatable.
As is charasteristic of spoken language, the
data contained a noticeable percentage (35 %)
of elliptic utterances, which didn?t contain
any topic words. Multiple topic constructs,
on the other hand, were quite rare: more than
one topic concept occurred in only 1 % of the
utterances. The pronouns were quite evenly
distributed with regard to position in the ut-
terances: 32 % were in medial and 36 % in
final position3.
3.2 The probabilistic model
The probability of a word belonging to the
class topic, focus or other is modeled as
P (Ti|W,S) =
P (Ti|W )P (Ti|S)
P (Ti)
, (2)
where W denotes the word, S its position in
an utterance, and Ti ? {topic, focus, other}
stands for the class. The model thus assumes
that being a topic or a focus word is depen-
dent on the properties of that particular word
as well as its position in the utterance. Due
3We interpreted ?medial? to mean the middle third
of the sentence, and ?final? to be the last third of the
sentence.
to computational reasons we made the sim-
plifying assumption that these two effects are
independent, i.e., P (W,S) = P (W )P (S).
Maximum likelihood estimates are used for
the terms P (Ti|W ) for already seen words.
Moreover, for unseen words we use the aver-
age of the models of words seen only rarely
(once or twice) in the training data.
For the term P (Ti|S) that describes the ef-
fect of the position of a word we use a softmax
model, namely
P (Ti|Sj) =
eqi(xj)
?
i e
qi(xj)
, (3)
where the index j identifies the word and xj
is the position of the word j. The functions
qi are defined as simple linear functions
qi(xj) = aixj + bi (4)
The parameters ai and bi are estimated from
the training data. For the class T3 (other),
these parameters are set to a constant value
of zero.
3.2.1 ML estimation
When evaluating the rest of the model pa-
rameters we use two methods, first Maximum
Likelihood estimation and then Bayesian vari-
ational analysis.
In ML estimation the cost function is the
log likelihood of the training data D given
the model M , i.e,
lnP (D|M) = ln
?
w
P (Ti|Sw) (5)
=
?
w?T1
q1 +
?
w?T2
q2 +
?
w
(? ln(1 + eq1 + eq2)). (6)
The logarithmic term is approximated by a
Taylor series of first degree and the parame-
ters can then be solved as usual, by setting the
partial derivatives of lnP (D|M) to zero with
regard to each parameter. The parameters bi
can be solved analytically and the parameters
ai are solved using Newton iteration.
3.2.2 Bayesian estimation
The ML estimation is known to be prone
to overlearning the properties of the train-
ing data. In contrast, in the Bayesian ap-
proach, also the model cost is included in the
cost function and can be used to avoid over-
learning. For comparison, we thus tried also
the Bayesian approach utilizing the software
and methodology introduced in (Valpola et
al., 2001). The method is based on variational
analysis and uses ensemble learning for esti-
mating the model parameters. The method-
ology and the software allows for the opti-
mization of the model structure with roughly
linear computational complexity without the
risk of over-fitting the model. However, in
these experiments the model structure was
not optimized.
3.2.3 Disregarding position
information
Furthermore, to study the importance of
the position information, we calculated the
probabilities using only ML estimates for
P (T |W ), i.e., disregarding the position of the
word.
3.2.4 Tf?idf
As a comparison, we applied the tf?idf
weighting scheme, which is commonly used
in information retrieval for weighting content
words. This method does not benefit from the
labeling of the training data. For this reason,
it does not differentiate between ?topic? and
?focus? words.
3.3 Experiments and results
The following experiment was performed us-
ing each described method: For each utter-
ance in the test data, n words were tagged
as topic, and likewise for the focus category.
Further, n was varied from 1 to 8 to produce
the results depicted in Figure 1.
As can be seen, the Bayesian variational
analysis and the maximum likelihood estima-
tion produce nearly identical performances.
This is perhaps due to the use of very smooth
model family, namely first-order polynomials,
for taking into account the effect of the posi-
tion of the word. For this reason, overlearn-
0 0.5 10
0.1
0.2
0.3
0.4
0.5
0.6
0.7
Recall
Prec
ision
Topics
ML          Bayes       No pos. inf.Idf         Random      
0 0.5 10
0.1
0.2
0.3
0.4
0.5
0.6
0.7
Recall
Prec
ision
Focuses
Figure 1: The precision?recall curves for
topic?focus estimation. (ML = maximum
likelihood, Bayes = Bayesian variational anal-
ysis, No pos. inf. = without position informa-
tion, Idf = tf?idf weighting, Random = the
average precision with random selection.)
ing is not problem even for the ML estima-
tion. However, since the nearly identical re-
sults were obtained using two completely dif-
ferent implementations of quite similar meth-
ods, this can be considered as a validation
experiment on either implementation and op-
timization method. In total, it seems that the
full statistical model designed works rather
well especially in focus identification.
When compared to the full model, disre-
garding position information altoghether re-
sults in inferior performance. The difference
is statistically significant (p ? 0.05) in focus
identification for all values of n and in topic
identification for small values of n. More-
over, the performance of the tf?idf scheme
is clearly inferior in either task. However, it
seems that the tf?idf definition of word im-
portance corresponds more closely with the
definition of ?focus? than that of ?topic?.
4 Discussion and conclusions
We examined two different viewpoints for the
topic identification problem in natural lan-
guage understanding. In experiments utiliz-
ing document maps it was found that longer
dialogue segments are reliably modeled, but
especially for short segments the history of
the utterance must be consulted. A perhaps
more interesting idea would be to also look at
morphological features, such as cases, and in-
clude them in the encoding of the utterances.
We plan to study this possibility in further
work.
In the second viewpoint, individual utter-
ances were analyzed to automatically iden-
tify ?topics? (what the user is talking about)
and ?focuses? (what is being said about the
topic). Each word in an utterance was labeled
as ?topic?, ?focus? or ?other?.
A statistical model that utilized the iden-
tity of the word and its position in the ut-
terance was found to be rather successful, es-
pecially for identification of words belonging
to the ?focus? category. Without the position
information significantly lower performance
was observed, which indicates that position
information is indeed relevant for the iden-
tification. In this case, the Bayesian mod-
eling paradigm and the maximum likelihood
estimation produced nearly identical perfor-
mance. However, this is not the case in gen-
eral, when less smooth model families and op-
timization of model structure are applied. In
the future we plan to examine other kinds of
model structures for this task, perhaps inte-
grating new types of information sources re-
garding the words, as well. For example, it
would be interesting to see whether the ad-
dition of prosodic information would provide
additional cues to improved solving of this
task.
5 Acknowledgements
We thank Harri Valpola for his valuable ad-
vice concerning the estimation of the topic-
focus identification model and for the possi-
bility to apply the Bayesian software package
developed by his group.
This work is part of the collaborative ?Inter-
act? project on natural language interaction in
Finnish.
References
Ella Bingham, Jukka Kuusisto, and Krista Lagus.
2002. Ica and som in text document analy-
sis. In The 25th ACM SIGIR Conference on
Research and Development in Information Re-
trieval,August 11-15, 2002, Tampere, Finland.
Submitted.
Eva Hajic?ova?, Petr Sgall, and Hana Skoumalova?.
1995. An automatic procedure for topic?
focus identification. Computational Linguis-
tics, 21(1):81?94.
M. A. Halliday. 1985. Introduction to Functional
Grammar. Oxford University Press, Oxford,
UK.
Timo Honkela, Samuel Kaski, Krista Lagus, and
Teuvo Kohonen. 1996. Newsgroup exploration
with WEBSOM method and browsing inter-
face. Technical Report A32, Helsinki University
of Technology, Laboratory of Computer and In-
formation Science, Espoo, Finland.
R.M. Iyer and M. Ostendorf. 1999. Modelling
long distance dependencies in language: Topic
mixtures versus dynamic cache model. IEEE
Trans. Speech and Audio Processing, 7.
Kristiina Jokinen, Antti Kerminen, Mauri
Kaipainen, Tommi Jauhiainen, Markku Tu-
runen, Jaakko Hakulinen, Jukka Kuusisto, and
Krista Lagus. 2002. Adaptive dialogue systems
? interaction with interact. In 3rd SIGdial
Workshop on Discourse and Dialogue, July 11
and 12, 2002. To appear.
Teuvo Kohonen, Samuel Kaski, Krista Lagus,
Jarkko Salojrvi, Vesa Paatero, and Antti
Saarela. 2000. Organization of a massive
document collection. IEEE Transactions on
Neural Networks, Special Issue on Neural Net-
works for Data Mining and Knowledge Discov-
ery, 11(3):574?585.
Teuvo Kohonen. 1982. Analysis of a simple
self-organizing process. Biological Cybernetics,
44(2):135?140.
Teuvo Kohonen. 1995. Self-Organizing Maps.
3rd, extended edition, 2001. Springer, Berlin.
Mikko Kurimo and Krista Lagus. 2002. An
efficiently focusing large vocabulary language
model. In International Conference on Arti-
ficial Neural Networks, ICANN?02. To appear.
Krista Lagus. 2000. Text mining with the WEB-
SOM. Acta Polytechnica Scandinavica, Mathe-
matics and Computing Series No. 110, 54 pp.
December. D.Sc(Tech) Thesis, Helsinki Univer-
sity of Technology, Finland.
Xia Lin. 1992. Visualization for the document
space. In Proceedings of Visualization ?92,
pages 274?81, Los Alamitos, CA, USA. Cen-
ter for Comput. Legal Res., Pace Univ., White
Plains, NY, USA, IEEE Comput. Soc. Press.
Xia Lin. 1997. Map displays for information re-
trieval. Journal of the American Society for
Information Science, 48:40?54.
Kristine Ma, George Zavaliagkos, and Marie
Meteer. 1998. Sub-sentence discourse models
for conversational speech recognition. In Pro-
ceedings of the 1998 IEEE International Con-
ference on Acoustics, Speech and Signal Pro-
cessing, vol. 2, Seattle, Washington, USA.
Marie Meteer and Rukmini Iyer. 1996. Model-
ing conversational speech for speech recogni-
tion. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Process-
ing, Philadelphia, PA, USA.
G. Salton, A. Wong, and C. S. Yang. 1975. A vec-
tor space model for automatic indexing. Com-
munications of the ACM, 18(11):613?620.
Petr Sgall, Eva Hajic?ova?, and Jarmila Panevova?.
1986. The Meaning of the Sentence in Its Se-
mantic and Pragmatic Aspects. D. Reidel Pub-
lishing Company, Dordrecht, Holland.
Harri Valpola, Tapani Raiko, and Juha Karhunen.
2001. Building blocks for hierarchical latent
variable models. In In Proceedings of the 3rd
International Conference on Independent Com-
ponent Analysis and Blind Signal Separation,
San Diego, California, USA.
Maria Vilkuna. 1989. Free Word Order in
Finnish. Its Syntax and discourse functions.
Suomalaisen Kirjallisuuden Seura, Helsinki.
Unsupervised Discovery of Morphemes
Mathias Creutz and Krista Lagus
Neural Networks Research Centre
Helsinki University of Technology
P.O.Box 9800, FIN-02015 HUT, Finland
{Mathias.Creutz, Krista.Lagus}@hut.fi
Abstract
We present two methods for unsupervised
segmentation of words into morpheme-
like units. The model utilized is espe-
cially suited for languages with a rich
morphology, such as Finnish. The first
method is based on the Minimum Descrip-
tion Length (MDL) principle and works
online. In the second method, Max-
imum Likelihood (ML) optimization is
used. The quality of the segmentations is
measured using an evaluation method that
compares the segmentations produced to
an existing morphological analysis. Ex-
periments on both Finnish and English
corpora show that the presented methods
perform well compared to a current state-
of-the-art system.
1 Introduction
According to linguistic theory, morphemes are con-
sidered to be the smallest meaning-bearing ele-
ments of language, and they can be defined in a
language-independent manner. However, no ade-
quate language-independent definition of the word
as a unit has been agreed upon (Karlsson, 1998,
p. 83). If effective methods can be devised for the
unsupervised discovery of morphemes, they could
aid the formulation of a linguistic theory of mor-
phology for a new language.
It seems that even approximative automated mor-
phological analysis would be beneficial for many
natural language applications dealing with large vo-
cabularies. For example, in text retrieval it is cus-
tomary to preprocess texts by returning words to
their base forms, especially for morphologically rich
languages.
Moreover, in large vocabulary speech recognition,
predictive models of language are typically used for
selecting the most plausible words suggested by an
acoustic speech recognizer (see, e.g., Bellegarda,
2000). Consider, for example the estimation of the
standard n-gram model, which entails the estima-
tion of the probabilities of all sequences of n words.
When the vocabulary is very large, say 100 000
words, the basic problems in the estimation of the
language model are: (1) If words are used as ba-
sic representational units in the language model, the
number of basic units is very high and the estimated
word n-grams are poor due to sparse data. (2) Due
to the high number of possible word forms, many
perfectly valid word forms will not be observed at
all in the training data, even in large amounts of text.
These problems are particularly severe for languages
with rich morphology, such as Finnish and Turkish.
For example, in Finnish, a single verb may appear in
thousands of different forms (Karlsson, 1987).
The utilization of morphemes as basic representa-
tional units in a statistical language model instead of
words seems a promising course. Even a rough mor-
phological segmentation could then be sufficient.
On the other hand, the construction of a comprehen-
sive morphological analyzer for a language based
on linguistic theory requires a considerable amount
of work by experts. This is both slow and expen-
sive and therefore not applicable to all languages.
                     July 2002, pp. 21-30.  Association for Computational Linguistics.
        ACL Special Interest Group in Computational Phonology (SIGPHON), Philadelphia,
       Morphological and Phonological Learning: Proceedings of the 6th Workshop of the
Table 1: The morphological structure of the Finnish
word for ?also for [the] coffee drinker?.
Word kahvinjuojallekin
Morphs kahvi n juo ja lle kin
Transl. coffee of drink -er for also
The problem is further compounded as languages
evolve, new words appear and grammatical changes
take place. Consequently, it is important to develop
methods that are able to discover a morphology for
a language based on unsupervised analysis of large
amounts of data.
As the morphology discovery from untagged cor-
pora is a computationally hard problem, in practice
one must make some assumptions about the struc-
ture of words. The appropriate specific assumptions
are somewhat language-dedependent. For example,
for English it may be useful to assume that words
consist of a stem, often followed by a suffix and pos-
sibly preceded by a prefix. By contrast, a Finnish
word typically consists of a stem followed by multi-
ple suffixes. In addition, compound words are com-
mon, containing an alternation of stems and suf-
fixes, e.g., the word kahvinjuojallekin (Engl.
?also for [the] coffee drinker?; cf. Table 1)1. More-
over, one may ask, whether a morphologically com-
plex word exhibits some hierarchical structure, or
whether it is merely a flat concatenation of stems
and suffices.
1.1 Previous Work on Unsupervised
Segmentation
Many existing morphology discovery algorithms
concentrate on identifying prefixes, suffixes and
stems, i.e., assume a rather simple inflectional mor-
phology.
De?jean (1998) concentrates on the problem of
finding the list of frequent affixes for a language
rather than attempting to produce a morphological
analysis of each word. Following the work of Zellig
Harris he identifies possible morpheme boundaries
by looking at the number of possible letters follow-
ing a given sequence of letters, and then utilizes fre-
quency limits for accepting morphemes.
1For a comprehensive view of Finnish morphology, see
(Karlsson, 1987).
Goldsmith (2000) concentrates on stem+suffix-
languages, in particular Indo-European languages,
and tries to produce output that would match as
closely as possible with the analysis given by a hu-
man morphologist. He further assumes that stems
form groups that he calls signatures, and each sig-
nature shares a set of possible affixes. He applies an
MDL criterion for model optimization.
The previously discussed approaches consider
only individual words without regard to their con-
texts, or to their semantic content. In a different ap-
proach, Schone and Jurafsky (2000) utilize the con-
text of each term to obtain a semantic representa-
tion for it using LSA. The division to morphemes
is then accepted only when the stem and stem+affix
are sufficiently similar semantically. Their method
is shown to improve on the performance of Gold-
smith?s Linguistica on CELEX, a morphologically
analyzed English corpus.
In the related field of text segmentation, one can
sometimes obtain morphemes. Some of the ap-
proaches remove spaces from text and try to identify
word boundaries utilizing e.g. entropy-based mea-
sures, as in (Redlich, 1993).
Word induction from natural language text with-
out word boundaries is also studied in (Deligne
and Bimbot, 1997; Hua, 2000), where MDL-based
model optimization measures are used. Viterbi or
the forward-backward algorithm (an EM algorithm)
is used for improving the segmentation of the cor-
pus2.
Also de Marcken (1995; 1996) studies the prob-
lem of learning a lexicon, but instead of optimiz-
ing the cost of the whole corpus, as in (Redlich,
1993; Hua, 2000), de Marcken starts with sentences.
Spaces are included as any other characters.
Utterances are also analyzed in (Kit and Wilks,
1999) where optimal segmentation for an utterance
is sought so that the compression effect over the seg-
ments is maximal. The compression effect is mea-
sured in what the authors call Description Length
Gain, defined as the relative reduction in entropy.
The Viterbi algorithm is used for searching for the
optimal segmentation given a model. The input ut-
2The regular EM procedure only maximizes the likelihood
of the data. To follow the MDL approach where model cost is
also optimized, Hua includes the model cost as a penalty term
on pure ML probabilities.
terances include spaces and punctuation as ordinary
characters. The method is evaluated in terms of pre-
cision and recall on word boundary prediction.
Brent presents a general, modular probabilistic
model structure for word discovery (Brent, 1999).
He uses a minimum representation length criterion
for model optimization and applies an incremental,
greedy search algorithm which is suitable for on-line
learning such that children might employ.
1.2 Our Approach
In this work, we use a model where words may con-
sist of lengthy sequences of segments. This model
is especially suitable for languages with agglutina-
tive morphological structure. We call the segments
morphs and at this point no distinction is made be-
tween stems and affixes.
The practical purpose of the segmentation is
to provide a vocabulary of language units that is
smaller and generalizes better than a vocabulary
consisting of words as they appear in text. Such a
vocabulary could be utilized in statistical language
modeling, e.g., for speech recognition. Moreover,
one could assume that such a discovered morph vo-
cabulary would correspond rather closely to linguis-
tic morphemes of the language.
We examine two methods for unsupervised learn-
ing of the model, presented in Sections 2 and 3. The
cost function for the first method is derived from the
Minimum Description Length principle from classic
information theory (Rissanen, 1989), which simul-
taneously measures the goodness of the representa-
tion and the model complexity. Including a model
complexity term generally improves generalization
by inhibiting overlearning, a problem especially se-
vere for sparse data. An incremental (online) search
algorithm is utilized that applies a hierarchical split-
ting strategy for words. In the second method the
cost function is defined as the maximum likelihood
of the data given the model. Sequential splitting is
applied and a batch learning algorithm is utilized.
In Section 4, we develop a method for evaluat-
ing the quality of the morph segmentations produced
by the unsupervised segmentation methods. Even
though the morph segmentations obtained are not in-
tended to correspond exactly to the morphemes of
linguistic theory, a basis for comparison is provided
by existing, linguistically motivated morphological
analyses of the words.
Both segmentation methods are applied to the
segmentation of both Finnish and English words.
In Section 5, we compare the results obtained from
our methods to results produced by Goldsmith?s Lin-
guistica on the same data.
2 Method 1: Recursive Segmentation and
MDL Cost
The task is to find the optimal segmentation of the
source text into morphs. One can think of this as
constructing a model of the data in which the model
consists of a vocabulary of morphs, i.e. the code-
book and the data is the sequence of text. We try to
find a set of morphs that is concise, and moreover
gives a concise representation for the data. This is
achieved by utilizing an MDL cost function.
2.1 Model Cost Using MDL
The total cost consists of two parts: the cost of the
source text in this model and the cost of the code-
book. Let M be the morph codebook (the vocab-
ulary of morph types) and D = m1m2 . . .mn the
sequence of morph tokens that makes up the string
of words. We then define the total cost C as
C = Cost(Source text) + Cost(Codebook)
=
?
tokens
? log p(mi) +
?
types
k ? l(mj)
The cost of the source text is thus the negative log-
likelihood of the morph, summed over all the morph
tokens that comprise the source text. The cost of the
codebook is simply the length in bits needed to rep-
resent each morph separately as a string of charac-
ters, summed over the morphs in the codebook. The
length in characters of the morph mj is denoted by
l(mj) and k is the number of bits needed to code a
character (we have used a value of 5 since that is suf-
ficient for coding 32 lower-case letters). For p(mi)
we use the ML estimate, i.e., the token count of mi
divided by the total count of morph tokens.
2.2 Search Algorithm
The online search algorithm works by incremen-
tally suggesting changes that could improve the cost
function. Each time a new word token is read
from the input, different ways of segmenting it into
morphs are evaluated, and the one with minimum
cost is selected.
Recursive segmentation. The search for the opti-
mal morph segmentation proceeds recursively. First,
the word as a whole is considered to be a morph and
added to the codebook. Next, every possible split of
the word into two parts is evaluated.
The algorithm selects the split (or no split) that
yields the minimum total cost. In case of no split,
the processing of the word is finished and the next
word is read from input. Otherwise, the search for a
split is performed recursively on the two segments.
The order of splits can be represented as a binary tree
for each word, where the leafs represent the morphs
making up the word, and the tree structure describes
the ordering of the splits.
During model search, an overall hierarchical data
structure is used for keeping track of the current
segmentation of every word type encountered so
far. Let us assume that we have seen seven in-
stances of linja-auton (Engl. ?of [the] bus?)
and two instances of autonkuljettajalla-
kaan (Engl. ?not even by/at/with [the] car driver?).
Figure 1 then shows a possible structure used for
representing the segmentations of the data. Each
chunk is provided with an occurrence count of the
chunk in the data set and the split location in this
chunk. A zero split location denotes a leaf node, i.e.,
a morph. The occurrence counts flow down through
the hierachical structure, so that the count of a child
always equals the sum of the counts of its parents.
The occurrence counts of the leaf nodes are used for
computing the relative frequencies of the morphs.
To find out the morph sequence that a word consists
of, we look up the chunk that is identical to the word,
and trace the split indices recursively until we reach
the leafs, which are the morphs.
Note that the hierarchical structure is used only
during model search: It is not part of the final model,
and accordingly no cost is associated with any other
nodes than the leaf nodes.
Adding and removing morphs. Adding new
morphs to the codebook increases the codebook
cost. Consequently, a new word token will tend to
be split into morphs already listed in the codebook,
which may lead to local optima. To better escape lo-
cal optima, each time a new word token is encoun-
13:2
0:210:2
0:2
5:2
kuljettajallakaan
kuljettajalla
kuljettaja lla
kaan
0:2
6:7
0:7
0:9
linja?
n
4:9
0:9
linja?auton
auton
auto
autonkuljettajallakaan
Figure 1: Hierarchical structure of the segmenta-
tion of the words linja-auton and autonkul-
jettajallakaan. The boxes represent chunks.
Boxes with bold text are morphs, and are part of the
codebook. The numbers above each box are the split
location (to the left of the colon sign) and the occur-
rence count of the chunk (to the right of the colon
sign).
tered, it is resegmented, whether or not this word has
been observed before. If the word has been observed
(i.e. the corresponding chunk is found in the hierar-
chical structure), we first remove the chunk and de-
crease the counts of all its children. Chunks with
zero count are removed (remember that removal of
leaf nodes corresponds to removal of morphs from
the codebook). Next, we increase the count of the
observed word chunk by one and re-insert it as an
unsplit chunk. Finally, we apply the recursive split-
ting to the chunk, which may lead to a new, different
segmentation of the word.
?Dreaming?. Due to the online learning, as the
number of processed words increases, the quality
of the set of morphs in the codebook gradually im-
proves. Consequently, words encountered in the be-
ginning of the input data, and not observed since,
may have a sub-optimal segmentation in the new
model, since at some point more suitable morphs
have emerged in the codebook. We have therefore
introduced a ?dreaming? stage: At regular intervals
the system stops reading words from the input, and
instead iterates over the words already encountered
in random order. These words are resegmented and
thus compressed further, if possible. Dreaming con-
tinues for a limited time or until no considerable de-
crease in the total cost can be observed. Figure 2
shows the development of the average cost per word
as a function of the increasing amount of source text.
0 20 40 60 80 10020
25
30
35
40
45
50Corpus: Finnish newspaper text 100 000 words
Number of words read [x 1000 words]
Ave
rage
 cost
 per 
word
 [bits
]
Figure 2: Development of the average word cost
when processing newspaper text. Dreaming, i.e., the
re-processing of the words encountered so far, takes
place five times, which can be seen as sudden drops
on the curve.
3 Method 2: Sequential Segmentation and
ML Cost
3.1 Model Cost Using ML
In this case, we use as cost function the likelihood
of the data, i.e., P (data|model). Thus, the model
cost is not included. This corresponds to Maximum-
Likelihood (ML) learning. The cost is then
Cost(Source text) =
?
morph tokens
? log p(mi), (1)
where the summation is over all morph tokens in the
source data. As before, for p(mi) we use the ML
estimate, i.e., the token count of mi divided by the
total count of morph tokens.
3.2 Search Algorithm
In this case, we utilize batch learning where an EM-
like (Expectation-Maximization) algorithm is used
for optimizing the model. Moreover, splitting is not
recursive but proceeds linearly.
1. Initialize segmentation by splitting words into
morphs at random intervals, starting from the
beginning of the word. The lengths of intervals
are sampled from the Poisson distribution with
? = 5.5. If the interval is larger than the num-
ber of letters in the remaining word segment,
the splitting ends.
2. Repeat for a number of iterations:
(a) Estimate morph probabilities for the given
splitting.
(b) Given the current set of morphs and their
probabilities, re-segment the text using the
Viterbi algorithm for finding the segmen-
tation with lowest cost for each word.
(c) If not the last iteration: Evaluate the seg-
mentation of a word against rejection cri-
teria. If the proposed segmentation is not
accepted, segment this word randomly (as
in the Initialization step).
Note that the possibility of introducing a random
segmentation at step (c) is the only thing that allows
for the addition of new morphs. (In the cost function
their cost would be infinite, due to ML probability
estimates). In fact, without this step the algorithm
seems to get seriously stuck in suboptimal solutions.
Rejection criteria. (1) Rare morphs. Reject the
segmentation of a word if the segmentation contains
a morph that was used in only one word type in the
previous iteration. This is motivated by the fact that
extremely rare morphs are often incorrect. (2) Se-
quences of one-letter morphs. Reject the segmenta-
tion if it contains two or more one-letter morphs in
a sequence. For instance, accept the segmentation
halua + n (Engl. ?I want?, i.e. present stem of
the verb ?to want? followed by the ending for the first
person singular), but reject the segmentation halu
+ a + n (stem of the noun ?desire? followed by
a strange sequence of endings). Long sequences of
one-letter morphs are usually a sign of a very bad
local optimum that may even get worse in future it-
erations, in case too much probability mass is trans-
ferred onto these short morphs3.
3Nevertheless, for Finnish there do exist some one-letter
morphemes that can occur in a sequence. However, these mor-
phemes can be thought of as a group that belongs together: e.g.,
4 Evaluation Measures
We wish to evaluate the method quantitatively from
the following perspectives: (1) correspondence with
linguistic morphemes, (2) efficiency of compression
of the data, and (3) computational efficiency. The ef-
ficiency of compression can be evaluated as the total
description length of the corpus and the codebook
(the MDL cost function). The computational effi-
ciency of the algorithm can be estimated from the
running time and memory consumption of the pro-
gram. However, the linguistic evaluation is in gen-
eral not so straightforward.
4.1 Linguistic Evaluation Procedure
If a corpus with marked morpheme boundaries is
available, the linguistic evaluation can be computed
as the precision and recall of the segmentation. Un-
fortunately, we did not have such data sets at our dis-
posal, and for Finnish such do not even exist. In ad-
dition, it is not always clear exactly where the mor-
pheme boundary should be placed. Several alterna-
tives may be possible, cf. Engl. hope + d vs. hop
+ ed, (past tense of to hope).
Instead, we utilized an existing tool for providing
a morphological analysis, although not a segmenta-
tion, of words, based on the two-level morphology
of Koskenniemi (1983). The analyzer is a finite-state
transducer that reads a word form as input and out-
puts the base form of the word together with gram-
matical tags. Sample analyses are shown in Figure 3.
The tag set consists of tags corresponding to
morphological affixes and other tags, for example,
part-of-speech tags. We preprocessed the analyses
by removing other tags than those corresponding
to affixes, and further split compound base forms
(marked using the # character by the analyzer) into
their constituents. As a result, we obtained for each
word a sequence of labels that corresponds well to
a linguistic morphemic analysis of the word. A la-
bel can often be considered to correspond to a single
word segment, and the labels appear in the order of
the segments.
The following step consists in retrieving the seg-
mentation produced by one of the unsupervised seg-
mentation algorithms, and trying to align this seg-
the Finnish talo + j + a (plural partitive of ?house?); can
also be thought of as talo + ja.
Input Output
Word Base form Tags
easily EASY <DER:ly> ADV
bigger BIG A CMP
hours? HOUR N PL GEN
auton AUTO N SG GEN
puutaloja PUU#TALO N PL PTV
tehnyt TEHDA? V ACT PCP2 SG
Figure 3: Morphological analyses for some English
and Finnish word forms. The Finnish words are au-
ton (car?s), puutaloja ([some] wooden houses)
and tehnyt ([has] done). The tags are A (adjec-
tive), ACT (active voice), ADV (adverb), CMP (com-
parative), GEN (genitive), N (noun), PCP2 (2nd par-
ticiple), PL (plural), PTV (partitive), SG (singular),
V (verb), and <DER:ly> (-ly derivative).
mentation with the desired morphemic label se-
quence (cf. Figure 4).
A good segmentation algorithm will produce
morphs that align gracefully with the correct mor-
phemic labels, preferably producing a one-to-one
mapping. A one-to-many mapping from morphs
to labels is also acceptable, when a morph forms a
common entity, such as the suffix -ja in puutaloja,
which contains both the plural and partitive element.
By contrast, a many-to-one mapping from morphs
to a label is a sign of excessive splitting, e.g., t +
alo for talo (cf. English h + ouse for house).
Correct labels BIG CMP
Morph sequence bigg er
Correct labels HOUR PL GEN
Morph sequence hour s ?
Correct labels PUU TALO PL PTV
Morph sequence puu t alo ja
Figure 4: Alignment of obtained morph sequences
with their respective correct morphemic analyses.
We assume that the segmentation algorithm has
split the word bigger into the morphs bigg + er,
hours? into hour + s + ? and puutaloja into
puu + t + alo + ja.
Alignment procedure. We align the morph se-
quence with the morphemic label sequence using
dynamic programming, namely Viterbi alignment,
to find the best sequence of mappings between
morphs and morphemic labels. Each possible pair
of morph/morphemic label has a distance associated
with it. For each segmented word, the algorithm
searches for the alignment that minimizes the to-
tal alignment distance for the word. The distance
d(M,L) for a pair of morph M and label L is given
by:
d(M,L) = ? log
cM,L
cM
, (2)
where cM,L is the number of word tokens in which
the morph M has been aligned with the label L; and
cM is the number of word tokens that contain the
morph M in their segmentation. The distance mea-
sure can be thought of as the negative logarithm of a
conditional probability P (L|M). This indicates the
probability that a morph M is a realisation of a mor-
pheme represented by the label L. Put another way,
if the unsupervised segmentation algorithm discov-
ers morphs that are allomorphs of real morphemes, a
particular allomorph will ideally always be aligned
with the same (correct) morphemic label, which
leads to a high probability P (L|M), and a short dis-
tance d(M,L)4. In contrast, if the segmentation al-
gorithm does not discover meaningful morphs, each
of the segments will be aligned with a number of dif-
ferent morphemic labels throughout the corpus, and
as a consequence, the probabilities will be low and
the distances high.
We then utilize the EM algorithm for iteratively
improving the alignment. The initial alignment that
is used for computing initial distance values is ob-
tained through a string matching procedure: String
matching is efficient for aligning the stem of the
word with the base form (e.g., the morph puu with
the label PUU, and the morphs t + alo with the
label TALO). The suffix morphs that do not match
well with the base form labels will end up aligned
somehow with the morphological tags (e.g., the
morph ja with the labels PL + PTV).
4This holds especially for allomorphs of ?stem morphemes?,
e.g., it is possible to identify the English morpheme easy with
a probability of one from both its allomorphs: easy and easi.
However, suffixes, in particular, can have several meanings,
e.g., the English suffix s can mean either the plural of nouns
or the third person singular of the present tense of verbs.
Comparison of methods. In order to compare two
segmentation algorithms, the segmentation of each
is aligned with the linguistic morpheme labels, and
the total distance of the alignment is computed.
Shorter total distance indicates better segmentation.
However, one should note that the distance mea-
sure used favors long morphs. If a particular ?seg-
mentation? algorithm does not split one single word
of the corpus, the total distance can be zero. In such
a situation, the single morph that a word is com-
posed of is aligned with all morphemic labels of the
word. The morph M , i.e., the word, is unique, which
means that all probabilities P (L|M) are equal to
one: e.g., the morph puutaloja is always aligned
with the labels PUU + TALO + PL + PTV and no
other labels, which yields the probabilities P (PUU |
puutaloja) = P (TALO | puutaloja) = P (PL |
puutaloja) = P (PTV | puutaloja) = 1.
Therefore, part of the corpus should be used as
training data, and the rest as test data. Both data sets
are segmented using the unsupervised segmentation
algorithms. The training set is then used for estimat-
ing the distance values d(M,L). These values are
used when the test set is aligned. The better seg-
mentation algorithm is the one that yields a better
alignment distance for the test set.
For morph/label pairs that were never observed in
the training set, a maximum distance value is as-
signed. A good segmentation algorithm will find
segments that are good building blocks of entirely
new word forms, and thus the maximum distance
values will occur only rarely.
5 Experiments and Results
We compared the two proposed methods as well as
Goldsmith?s program Linguistica5 on both Finnish
and English corpora. The Finnish corpus consisted
of newspaper text from CSC6. A morphosyntac-
tic analysis of the text was performed using the
Conexor FDG parser7. All characters were con-
verted to lower case, and words containing other
characters than a through z and the Scandinavian
letters a?, a? and o? were removed. Other than mor-
phemic tags were removed from the morphological
5http://humanities.uchicago.edu/faculty/goldsmith/Linguist-
ica2000/
6http://www.csc.fi/kielipankki/
7http://www.conexor.fi/
analyses of the words. The remaining tags corre-
spond to inflectional affixes (i.e. endings and mark-
ers) and clitics. Unfortunately the parser does not
distinguish derivational affixes. The first 100 000
word tokens were used as training data, and the fol-
lowing 100 000 word tokens were used as test data.
The test data contained 34 821 word types.
The English corpus consisted of mainly newspa-
per text from the Brown corpus8. A morphologi-
cal analysis of the words was performed using the
Lingsoft ENGTWOL analyzer9. In case of multi-
ple alternative morphological analyses, the shortest
analysis was selected. All characters were converted
to lower case, and words containing other characters
than a through z, an apostrophe or a hyphen were
removed. Other than morphemic tags were removed
from the morphological analyses of the words. The
remaining tags correspond to inflectional or deriva-
tional affixes. A set of 100 000 word tokens from the
corpus sections Press Reportage and Press Editorial
were used as training data. A separate set of 100 000
word tokens from the sections Press Editorial, Press
Reviews, Religion, and Skills Hobbies were used as
test data. The test data contained 12 053 word types.
Test results for the three methods and the two lan-
guages are shown in Table 2. We observe different
tendencies for Finnish and English. For Finnish,
there is a correlation between the compression of
the corpus and the linguistic generalization capac-
ity to new word forms. The Recursive splitting with
the MDL cost function is clearly superior to the Se-
quential splitting with ML cost, which in turn is su-
perior to Linguistica. The Recursive MDL method
is best in terms of data compression: it produces the
smallest morph lexicon (codebook), and the code-
book naturally occupies a small part of the total cost.
It is best also in terms of the linguistic measure, the
total alignment distance on test data. Linguistica, on
the other hand, employs a more restricted segmenta-
tion, which leads to a larger codebook and to the fact
that the codebook occupies a large part of the total
MDL cost. This also appears to lead to a poor gen-
eralization ability to new word forms. The linguis-
tic alignment distance is the highest, and so is the
percentage of aligned morph/morphemic label pairs
8The Brown corpus is available at the Linguistic Data Con-
sortium at http://www.ldc.upenn.edu/
9http://www.lingsoft.fi/
that were never observed in the training set. On the
other hand, Linguistica is the fastest program10.
Also for English, the Recursive MDL method
achieves the best alignment, but here Linguistica
achieves nearly the same result. The rate of com-
pression follows the same pattern as for Finnish,
in that Linguistica produces a much larger morph
lexicon than the methods presented in this pa-
per. In spite of this fact, the percentage of unseen
morph/morphemic label pairs is about the same for
all three methods. This suggests that in a morpho-
logically poor language such as English a restrictive
segmentation method, such as Linguistica, can com-
pensate for new word forms ? that it does not rec-
ognize at all ? with old, familiar words, that it ?gets
just right?. In contrast, the methods presented in this
paper produce a morph lexicon that is smaller and
able to generalize better to new word forms but has
somewhat lower accuracy for already observed word
forms.
Visual inspection of a sample of words. In an
attempt to analyze the segmentations more thor-
oughly, we randomly picked 1000 different words
from the Finnish test set. The total number of occur-
rences of these words constitute about 2.5% of the
whole set. We inspected the segmentation of each
word visually and classified it into one of three cat-
egories: (1) correct and complete segmentation (i.e.,
all relevant morpheme boundaries were identified),
(2) correct but incomplete segmentation (i.e., not all
relevant morpheme boundaries were identified, but
no proposed boundary was incorrect), (3) incorrect
segmentation (i.e., some proposed boundary did not
correspond to an actual morpheme boundary).
The results of the inspection for each of the three
segmentation methods are shown in Table 3. The
Recursive MDL method performs best and segments
about half of the words correctly. The Sequential
ML method comes second and Linguistica third with
a share of 43% correctly segmented words. When
considering the incomplete and incorrect segmenta-
tions the methods behave differently. The Recursive
MDL method leaves very common word forms un-
split, and often produces excessive splitting for rare
10Note, however, that the computing time comparison with
Linguistica is only approximate since it was a compiled pro-
gram run on Windows whereas the two other methods were im-
plemented as Perl scripts run on Linux.
Table 2: Test results for the Finnish and English corpus. Method names are abbreviated: Recursive seg-
mentation and MDL cost (Rec. MDL), Sequential segmentation and ML cost (Seq. ML), and Linguistica
(Ling.). The total MDL cost measures the compression of the corpus. However, the cost is computed accord-
ing to Equation (1), which favors the Recursive MDL method. The final number of morphs in the codebook
(#morphs in codebook) is a measure of the size of the morph ?vocabulary?. The relative codebook cost
gives the share of the total MDL cost that goes into coding the codebook. The alignment distance is the total
distance computed over the sequence of morph/morphemic label pairs in the test data. The unseen aligned
pairs is the percentage of all aligned morph/label pairs in the test set that were never observed in the training
set. This gives an indication of the generalization capacity of the method to new word forms.
Language Finnish English
Method Rec. MDL Seq. ML Ling. Rec. MDL Seq. ML Ling.
Total MDL cost [bits] 2.09M 2.27M 2.88M 1.26M 1.34M 1.44M
#morphs in codebook 6302 10 977 22 075 3836 4888 8153
Relative codebook cost 10.16% 15.27% 36.81% 9.42% 10.90% 19.14%
Alignment distance 768k 817k 1111k 313k 444k 332k
Unseen aligned pairs 23.64% 20.20% 37.22% 18.75% 19.67% 20.94%
Time [sec] 620 390 180 130 80 30
Table 3: Estimate of accuracy of morpheme bound-
ary detection based on visual inspection of a sample
of 2500 Finnish word tokens.
Method Correct Incomplete Incorrect
Rec. MDL 49.6% 29.7% 20.6%
Seq. ML 47.3% 15.3% 37.4%
Linguistica 43.1% 24.1% 32.8%
words. The Sequential ML method is more prone to
excessive splitting, even for words that are not rare.
Linguistica, on the other hand, employs a more con-
servative splitting strategy, but makes incorrect seg-
mentations for many common word forms.
The behaviour of the methods is illustrated by ex-
ample segmentations in Table 4. Often the Recur-
sive MDL method produces complete and correct
segmentations. However, both it and the Sequential
ML method can produce excessive splitting, as is
shown for the latter, e.g. affecti + on + at
+ e. In contrast, Linguistica refrains from splitting
words when they should be split, e.g., the Finnish
compound words in the table.
6 Discussion of the Model
Regarding the model, there is always room for im-
provement. In particular, the current model does
not allow representation of contextual dependencies,
i.e., that some morphs appear only in particular con-
texts (allomorphy). Moreover, languages have rules
regarding the ordering of stems and affixes (morpho-
tax). However, the current model has no way of rep-
resenting such contextual dependencies.
7 Conclusions
In the experiments the online method with the MDL
cost function and recursive splitting appeared most
successful especially for Finnish, whereas for En-
glish the compared methods were rather equal in
performance. This is likely to be partially due to
the model structure of the presented methods which
is especially suitable for languages such as Finnish.
However, there is still room for considerable im-
provement in the model structure, especially regard-
ing the representation of contextual dependencies.
Considering the two examined model optimiza-
tion methods, the Recursive MDL method per-
formed consistently somewhat better. Whether this
is due to the cost function or the splitting strategy
cannot be deduced based on these experiments. In
the future, we intend to extend the latter method to
utilize an MDL-like cost function.
Table 4: Some English and Finnish word segmentations produced by the three methods. The Finnish words
are ela?inla?a?ka?ri (veterinarian, lit. animal doctor), ela?inmuseo (zoological museum, lit. animal
museum), ela?inpuisto (zoological park, lit. animal park), and ela?intarha (zoo, lit. animal garden).
The suffixes -lle, -n, -on, and -sta are linguistically correct. (Note that in the Sequential ML method
the rejection criteria mentioned are not applied on the last round of Viterbi segmentation. This is why two
one letter morphs appear in a sequence in the segmentation ela?in + tarh + a + n.)
Recursive MDL Sequential ML Linguistica
affect affect affect
affect + ing affect + ing affect + ing
affect + ing + ly affect + ing + ly affect + ing + ly
affect + ion affecti + on affect + ion
affect + ion + ate affecti + on + at + e affect + ion + ate
affect + ion + s affecti + on + s affect + ion + s
affect + s affect + s affect + s
ela?in + la?a?ka?ri ela?in + la?a?ka?ri ela?inla?a?ka?ri
ela?in + la?a?ka?ri + lle ela?in + la?a?ka?ri + lle ela?inla?a?ka?ri + lle
ela?in + museo + n ela?in + museo + n ela?inmuseo + n
ela?in + museo + on ela?in + museo + on ela?inmuseo + on
ela?in + puisto + n ela?in + puisto + n ela?inpuisto + n
ela?in + puisto + sta ela?in + puisto + sta ela?inpuisto + sta
ela?in + tar + han ela?in + tarh + a + n ela?intarh + an
References
Jerome Bellegarda. 2000. Exploiting latent semantic in-
formation in statistical language modeling. Proceed-
ings of the IEEE, 88(8):1279?1296.
Michael R. Brent. 1999. An efficient, probabilistically
sound algorithm for segmentation and word discovery.
Machine Learning, 34:71?105.
Carl de Marcken. 1995. The unsupervised acquisition
of a lexicon from continuous speech. Technical Re-
port A.I. Memo 1558, MIT Artificial Intelligence Lab.,
Cambridge, Massachusetts.
Carl de Marcken. 1996. Linguistic structure as compo-
sition and perturbation. In Meeting of the Association
for Computational Linguistics.
Herve? De?jean. 1998. Morphemes as necessary con-
cept for structures discovery from untagged corpora.
In Workshop on Paradigms and Grounding in Natural
Language Learning, pages 295?299, Adelaide, Jan.
22.
Sabine Deligne and Fre?de?ric Bimbot. 1997. Inference of
variable-length linguistic and acoustic units by multi-
grams. Speech Communication, 23:223?241.
John Goldsmith. 2001. Unsupervised learning of the
morphology of a natural language. Computational
Linguistics, 27(2):153?198.
Yu Hua. 2000. Unsupervised word induction using MDL
criterion. In Proceedings of ISCSL, Beijing.
Fred Karlsson. 1987. Finnish Grammar. WSOY, Juva,
second edition.
Fred Karlsson. 1998. Yleinen kielitiede.
Yliopistopaino/Helsinki University Press.
Chunyu Kit and Yorick Wilks. 1999. Unsupervised
learning of word boundary with description length
gain. In Proceedings of CoNLL99 ACL Workshop,
Bergen.
Kimmo Koskenniemi. 1983. Two-level morphology:
A general computational model for word-form recog-
nition and production. Ph.D. thesis, University of
Helsinki.
A. Norman Redlich. 1993. Redundancy reduction as a
strategy for unsupervised learning. Neural Computa-
tion, 5:289?304.
Jorma Rissanen. 1989. Stochastic complexity in statis-
tical inquiry. World Scientific Series in Computer Sci-
ence, 15:79?93.
Patrick Schone and Daniel Jurafsky. 2000. Knowledge-
free induction of morphology using latent semantic
analysis. In Proceedings of CoNLL-2000 and LLL-
2000, pages 67?72, Lisbon.
Proceedings of the 11th Meeting of the ACL-SIGMORPHON, ACL 2010, pages 78?86,
Uppsala, Sweden, 15 July 2010. c?2010 Association for Computational Linguistics
Semi-supervised learning of concatenative morphology
Oskar Kohonen and Sami Virpioja and Krista Lagus
Aalto University School of Science and Technology
Adaptive Informatics Research Centre
P.O. Box 15400, FI-00076 AALTO, Finland
{oskar.kohonen,sami.virpioja,krista.lagus}@tkk.fi
Abstract
We consider morphology learning in a
semi-supervised setting, where a small
set of linguistic gold standard analyses is
available. We extend Morfessor Base-
line, which is a method for unsupervised
morphological segmentation, to this task.
We show that known linguistic segmenta-
tions can be exploited by adding them into
the data likelihood function and optimiz-
ing separate weights for unlabeled and la-
beled data. Experiments on English and
Finnish are presented with varying amount
of labeled data. Results of the linguis-
tic evaluation of Morpho Challenge im-
prove rapidly already with small amounts
of labeled data, surpassing the state-of-
the-art unsupervised methods at 1000 la-
beled words for English and at 100 labeled
words for Finnish.
1 Introduction
Morphological analysis is required in many natu-
ral language processing problems. Especially, in
agglutinative and compounding languages, where
each word form consists of a combination of stems
and affixes, the number of unique word forms in
a corpus is very large. This leads to problems in
word-based statistical language modeling: Even
with a large training corpus, many of the words en-
countered when applying the model did not occur
in the training corpus, and thus there is no infor-
mation available on how to process them. Using
morphological units, such as stems and affixes, in-
stead of complete word forms alleviates this prob-
lem. Unfortunately, for many languages morpho-
logical analysis tools either do not exist or they
are not freely available. In many cases, the prob-
lems of availability also apply to morphologically
annotated corpora, making supervised learning in-
feasible.
In consequence, there has been a need for ap-
proaches for morphological processing that would
require little language-dependent resources. Due
to this need, as well as the general interest in
language acquisition and unsupervised language
learning, the research on unsupervised learning
of morphology has been active during the past
ten years. Especially, methods that perform mor-
phological segmentation have been studied exten-
sively (Goldsmith, 2001; Creutz and Lagus, 2002;
Monson et al, 2004; Bernhard, 2006; Dasgupta
and Ng, 2007; Snyder and Barzilay, 2008b; Poon
et al, 2009). These methods have shown to pro-
duce results that improve performance in several
applications, such as speech recognition and in-
formation retrieval (Creutz et al, 2007; Kurimo et
al., 2008).
While unsupervised methods often work quite
well across different languages, it is difficult to
avoid biases toward certain kinds of languages and
analyses. For example, in isolating languages, the
average amount of morphemes per word is low,
whereas in synthetic languages the amount may be
very high. Also, different applications may need
a particular bias, for example, not analyzing fre-
quent compound words as consisting of smaller
parts could be beneficial in information retrieval.
In many cases, even a small amount of labeled data
can be used to adapt a method to a particular lan-
guage and task. Methodologically, this is referred
to as semi-supervised learning.
In semi-supervised learning, the learning sys-
tem has access to both labeled and unlabeled data.
Typically, the labeled data set is too small for su-
pervised methods to be effective, but there is a
large amount of unlabeled data available. There
are many different approaches to this class of
problems, as presented by Zhu (2005). One ap-
proach is to use generative models, which spec-
ify a join distribution over all variables in the
model. They can be utilized both in unsupervised
78
and supervised learning. In contrast, discrimina-
tive models only specify the conditional distribu-
tion between input data and labels, and therefore
require labeled data. Both, however, can be ex-
tended to the semi-supervised case. For generative
models, it is, in principle, very easy to use both la-
beled and unlabeled data. For unsupervised learn-
ing one can consider the labels as missing data and
estimate their values using the Expectation Maxi-
mization (EM) algorithm (Dempster et al, 1977).
In the semi-supervised case, some labels are avail-
able, and the rest are considered missing and esti-
mated with EM.
In this paper, we extend the Morfessor Base-
line method for the semi-supervised case. Morfes-
sor (Creutz and Lagus, 2002; Creutz and Lagus,
2005; Creutz and Lagus, 2007, etc.) is one of the
well-established methods for morphological seg-
mentation. It applies a simple generative model.
The basic idea, inspired by the Minimum Descrip-
tion Length principle (Rissanen, 1989), is to en-
code the words in the training data with a lexicon
of morphs, that are segments of the words. The
number of bits needed to encode both the morph
lexicon and the data using the lexicon should be
minimized. Morfessor does not limit the num-
ber of morphemes per word form, making it suit-
able for modeling a large variety of agglutinative
languages irrespective of them being more isolat-
ing or synthetic. We show that the model can be
trained in a similar fashion in the semi-supervised
case as in the unsupervised case. However, with
a large set of unlabeled data, the effect of the su-
pervision on the results tends to be small. Thus,
we add a discriminative weighting scheme, where
a small set of word forms with gold standard ana-
lyzes are used for tuning the respective weights of
the labeled and unlabeled data.
The paper is organized as follows: First, we
discuss related work on semi-supervised learning.
Then we describe the Morfessor Baseline model
and the unsupervised algorithm, followed by our
semi-supervised extension. Finally, we present ex-
perimental results for English and Finnish using
the Morpho Challenge data sets (Kurimo et al,
2009).
1.1 Related work
There is surprisingly little work that consider im-
proving the unsupervised models of morphology
with small amounts of annotated data. In the
related tasks that deal with sequential labeling
(word segmentation, POS tagging, shallow pars-
ing, named-entity recognition), semi-supervised
learning is more common.
Snyder and Barzilay (2008a; 2008b) consider
learning morphological segmentation with non-
parametric Bayesian model from multilingual
data. For multilingual settings, they extract 6 139
parallel short phrases from the Hebrew, Arabic,
Aramaic and English bible. Using the aligned
phrase pairs, the model can learn the segmen-
tations for two languages at the same time. In
one of the papers (2008a), they consider also
semi-supervised scenarios, where annotated data
is available either in only one language or both of
the languages. However, the amount of annotated
data is fixed to the half of the full data. This differs
from our experimental setting, where the amount
of unlabeled data is very large and the amount of
labeled data relatively small.
Poon et al (2009) apply a log-linear, undi-
rected generative model for learning the morphol-
ogy of Arabic and Hebrew. They report results
for the same small data set as Snyder and Barzilay
(2008a) in both unsupervised and semi-supervised
settings. For the latter, they use somewhat smaller
proportions of annotated data, varying from 25%
to 100% of the total data, but the amount of unla-
beled data is still very small. Results are reported
also for a larger 120 000 word Arabic data set, but
only for unsupervised learning.
A problem similar to morphological segmen-
tation is word segmentation for the languages
where orthography does not specify word bound-
aries. However, the amount of labeled data is
usually large, and unlabeled data is just an addi-
tional source of information. Li and McCallum
(2005) apply a semi-supervised approach to Chi-
nese word segmentation where unlabeled data is
utilized for forming word clusters, which are then
used as features for a supervised classifier. Xu
et al (2008) adapt a Chinese word segmentation
specifically to a machine translation task, by using
the indirect supervision from a parallel corpus.
2 Method
We present an extension of the Morfessor Baseline
method to the semi-supervised setting. Morfes-
sor Baseline is based on a generative probabilis-
tic model. It is a method for modeling concatena-
tive morphology, where the morphs?i.e., the sur-
79
face forms of morphemes?of a word are its non-
overlapping segments. The model parameters ?
encode a morph lexicon, which includes the prop-
erties of the morphs, such as their string represen-
tations. Each morph m in the lexicon has a proba-
bility of occurring in a word, P (M = m |?).1 The
probabilities are assumed to be independent. The
model uses a prior P (?), derived using the Min-
imum Description Length (MDL) principle, that
controls the complexity of the model. Intuitively,
the prior assigns higher probability to models that
store fewer morphs, where a morph is considered
stored if P (M = m |?) > 0. During model learn-
ing, ? is optimized to maximize the posterior prob-
ability:
?
MAP
= argmax
?
P (?|D
W
)
= argmax
?
{
P (?)P (D
W
|?)
}
, (1)
where D
W
includes the words in the training
data. In this section, we first consider sepa-
rately the likelihood P (D
W
|?) and the prior P (?)
used in Morfessor Baseline. Then we describe
the algorithms, first unsupervised and then semi-
supervised, for finding optimal model parameters.
Last, we shortly discuss the algorithm for seg-
menting new words after the model training.
2.1 Likelihood
The latent variable of the model, Z =
(Z
1
, . . . , Z
|D
W
|
), contains the analyses of the
words in the training data D
W
. An instance of
a single analysis for the j:th word is a sequence of
morphs, z
j
= (m
j1
, . . . ,m
j|z
j
|
). During training,
each word w
j
is assumed to have only one possible
analysis. Thus, instead of using the joint distribu-
tion P (D
W
,Z |?), we need to use the likelihood
function only conditioned on the analyses of the
observed words, P (D
W
|Z,?). The conditional
likelihood is
P (D
W
|Z = z,?)
=
|D
W
|
?
j=1
P (W = w
j
|Z = z,?)
=
|D
W
|
?
j=1
|z
j
|
?
i=1
P (M = m
ji
|?), (2)
where m
ij
is the i:th morph in word w
j
.
1We denote variables with uppercase letters and their in-
stances with lowercase letters.
2.2 Priors
Morfessor applies Maximum A Posteriori (MAP)
estimation, so priors for the model parameters
need to be defined. The parameters ? of the model
are:
? Morph type count, or the size of the morph
lexicon, ? ? Z
+
? Morph token count, or the number of morphs
tokens in the observed data, ? ? Z
+
? Morph strings (?
1
, . . . , ?
?
), ?
i
? ?
?
? Morph counts (?
1
, . . . , ?
?
), ?
i
? {1, . . . , ?},
?
i
?
i
= ?. Normalized with ?, these give
the probabilities of the morphs.
MDL-inspired and non-informative priors have
been preferred. When using such priors, morph
type count and morph token counts can be ne-
glected when optimizing the model. The morph
string prior is based on length distribution P (L)
and distribution P (C) of characters over the char-
acter set ?, both assumed to be known:
P (?
i
) = P (L = |?
i
|)
|?
i
|
?
j=1
P (C = ?
ij
) (3)
We use the implicit length prior (Creutz and La-
gus, 2005), which is obtained by removing P (L)
and using end-of-word mark as an additional char-
acter in P (C). For morph counts, the non-
informative prior
P (?
1
, . . . , ?
?
) = 1/
(
? ? 1
?? 1
)
(4)
gives equal probability to each possible combina-
tion of the counts when ? and ? are known, as
there are
(
??1
??1
)
possible ways to choose ? positive
integers that sum up to ?.
2.3 Unsupervised learning
In principle, unsupervised learning can be per-
formed by looking for the MAP estimate with the
EM-algorithm. In the case of Morfessor Baseline,
this is problematic, because the prior only assigns
higher probability to lexicons where fewer morphs
have nonzero probabilities. The EM-algorithm has
the property that it will not assign a zero probabil-
ity to any morph, that has a nonzero likelihood in
the previous step, and this will hold for all morphs
80
that initially have a nonzero probability. In con-
sequence, Morfessor Baseline instead uses a local
search algorithm, which will assign zero probabil-
ity to a large part of the potential morphs. This
is memory-efficient, since only the morphs with
nonzero probabilities need to be stored in mem-
ory. The training algorithm of Morfessor Base-
line, described by Creutz and Lagus (2005), tries
to minimize the cost function
L(?, z,D
W
) = ? lnP (?)? lnP (D
W
| z,?)
(5)
by testing local changes to z, modifying the pa-
rameters according to each change, and selecting
the best one. More specifically, one word is pro-
cessed at a time, and the segmentation that min-
imizes the cost function with the optimal model
parameters is selected:
z
(t+1)
j
= argmin
z
j
{
min
?
L(?, z
(t)
,D
W
)
}
. (6)
Next, the parameters are updated:
?
(t+1)
= argmin
?
{
L(?, z
(t+1)
,D
W
)
}
. (7)
As neither of the steps can increase the cost func-
tion, this will converge to a local optimum. The
initial parameters are obtained by adding all the
words into the morph lexicon. Due to the context
independence of the morphs within a word, the op-
timal analysis for a segment does not depend on
in which context the segment appears. Thus, it is
possible to encode z as a binary tree-like graph,
where the words are the top nodes and morphs the
leaf nodes. For each word, every possible split into
two morphs is tested in addition to no split. If the
word is split, the same test is applied recursively
to its parts. See, e.g., Creutz and Lagus (2005) for
more details and pseudo-code.
2.4 Semi-supervised learning
A straightforward way to do semi-supervised
learning is to fix the analyses z for the labeled ex-
amples. Early experiments indicated that this has
little effect on the results. The Morfessor Baseline
model only contains local parameters for morphs,
and relies on the bias given by its prior to guide
the amount of segmentation. Therefore, it may not
be well suited for semi-supervised learning. The
labeled data affects only the morphs that are found
in the labeled data, and even their analyses can be
overwhelmed by a large amount of unsupervised
data and the bias of the prior.
We suggest a fairly simple solution to this by
introducing extra parameters that guide the more
general behavior of the model. The amount of
segmentation is mostly affected by the balance
between the prior and the model. The Morfes-
sor Baseline model has been developed to ensure
this balance is sensible. However, the labeled
data gives a strong source of information regarding
the amount of segmentation preferred by the gold
standard. We can utilize this information by intro-
ducing the weight ? on the likelihood. To address
the problem of labeled data being overwhelmed by
the large amount of unlabeled data we introduce a
second weight ? on the likelihood for the labeled
data. These weights are optimized on a separate
held-out set. Thus, instead of optimizing the MAP
estimate, we minimize the following function:
L(?, z,D
W
,D
W 7?A
) =
? lnP (?)
? ?? lnP (D
W
| z,?)
? ? ? lnP (D
W 7?A
| z,?) (8)
The labeled training set D
W 7?A
may include al-
ternative analyses for some of the words. Let
A(w
j
) = {a
j1
, . . . , a
jk
} be the set of known anal-
yses for word w
j
. Assuming the training samples
are independent, and giving equal weight for each
analysis, the likelihood of the labeled data would
be
P (D
W 7?A
|?)
=
|D
W 7?A
|
?
j=1
?
a
jk
?A(w
j
)
|a
jk
|
?
i=1
P (M = m
jki
|?). (9)
However, when the analyses of the words are
fixed, the product over alternative analyses in A
is problematic, because the model cannot select
several of them at the same time. A sum over
A(w
j
):s would avoid this problem, but then the
logarithm of the likelihood function becomes non-
trivial (i.e., logarithm of sum of products) and too
slow to calculate during the training. Instead, we
use the hidden variable Z to select only one anal-
ysis also for the labeled samples, but now with the
restriction that Z
j
? A(w
j
). The likelihood func-
tion for D
W 7?A
is then equivalent to Equation 2.
Because the recursive algorithm search assumes
that a string is segmented in the same way irre-
spective of its context, the labeled data can still
81
get zero probabilities. In practice, zero probabil-
ities in the labeled data likelihood are treated as
very large, but not infinite, costs.
2.5 Segmenting new words
After training the model, a Viterbi-like algorithm
can be applied to find the optimal segmentation
of each word. As proposed by Virpioja and Ko-
honen (2009), also new morph types can be al-
lowed by utilizing an approximate cost of adding
them to the lexicon. As this enables reasonable re-
sults also when the training data is small, we use a
similar technique. The cost is calculated from the
decrease in the probabilities given in Equations 3
and 4 when a new morph is assumed to be in the
lexicon.
3 Experiments
In the experiments, we compare six different vari-
ants of the Morfessor Baseline algorithm:
? Unsupervised: The classic, unsupervised
Morfessor baseline.
? Unsupervised + weighting: A held-out set
is used for adjusting the weight of the likeli-
hood ?. When ? = 1 the method is equiva-
lent to the unsupervised baseline. The main
effect of adjusting ? is to control how many
segments per word the algorithm prefers.
Higher ? leads to fewer and lower ? to more
segments per word.
? Supervised: The semi-supervised method
trained with only the labeled data.
? Supervised + weighting: As above, but the
weight of the likelihood ? is optimized on
the held-out set. The weight can only af-
fect which segmentations are selected from
the possible alternative segmentations in the
labeled data.
? Semi-supervised: The semi-supervised
method trained with both labeled and
unlabeled data.
? Semi-supervised + weighting: As above,
but the parameters ? and ? are optimized us-
ing the the held-out set.
All variations are evaluated using the linguistic
gold standard evaluation of Morpho Challenge
2009. For supervised and semi-supervised meth-
ods, the amount of labeled data is varied be-
tween 100 and 10 000 words, whereas the held-
out set has 500 gold standard analyzes. To obtain
precision-recall curves, we calculated weighted
F0.5 and F2 scores in addition to the normal F1
score. The parameters ? and ? were optimized
also for those.
3.1 Data and evaluation
We used the English and Finnish data sets from
Competition 1 of Morpho Challenge 2009 (Ku-
rimo et al, 2009). Both are extracted from a
three million sentence corpora. For English, there
were 62 185 728 word tokens and 384 903 word
types. For Finnish, there were 36 207 308 word
tokens and 2 206 719 word types. The complexity
of Finnish morphology is indicated by the almost
ten times larger number of word types than in En-
glish, while the number of word tokens is smaller.
We applied also the evaluation method of the
Morpho Challenge 2009: The results of the mor-
phological segmentation were compared to a lin-
guistic gold standard analysis. Precision measures
whether the words that share morphemes in the
proposed analysis have common morphemes also
in the gold standard, and recall measures the op-
posite. The final score to optimize was F-measure,
i.e, the harmonic mean of the precision and re-
call.2 In addition to the unweighted F1 score, we
have applied F2 and F0.5 scores, which give more
weight to recall and precision, respectively.
Finnish gold standards are based on FINT-
WOL morphological analyzer from Lingsoft, Inc.,
that applies the two-level model by Koskenniemi
(1983). English gold standards are from the
CELEX English database. The final test sets are
the same as in Morpho Challenge, based on 10 000
English word forms and 200 000 Finnish word
forms. The test sets are divided into ten parts for
calculating deviations and statistical significances.
For parameter tuning, we applied a small held-out
set containing 500 word forms that were not in-
cluded in the test set.
For supervised and semi-supervised training,
we created sets of five different sizes: 100, 300,
1 000, 3 000, and 10 000. They did not contain any
of the word forms in the final test set, but were
otherwise randomly selected from the words for
2Both the data sets and evaluation scripts are available
from the Morpho Challenge 2009 web page: http://www.
cis.hut.fi/morphochallenge2009/
82
Figure 1: The F-measure for English as a function
of the number of labeled training samples.
which the gold standard analyses were available.
In order to use them for training Morfessor, the
morpheme analyses were converted to segmenta-
tions using the Hutmegs package by Creutz and
Linde?n (2004).
3.2 Results
Figure 1 shows a comparison of the unsupervised,
supervised and semi-supervised Morfessor Base-
line for English. It can be seen that optimiz-
ing the likelihood weight ? alone does not im-
prove much over the unsupervised case, imply-
ing that the Morfessor Baseline is well suited for
English morphology. Without weighting of the
likelihood function, semi-supervised training im-
proves the results somewhat, but it outperforms
weighted unsupervised model only barely. With
weighting, however, semi-supervised training im-
proves the results significantly already for only
100 labeled training samples. For comparison,
in Morpho Challenges (Kurimo et al, 2009), the
unsupervised Morfessor Baseline and Morfessor
Categories-MAP by Creutz and Lagus (2007) have
achieved F-measures of 59.84% and 50.50%, re-
spectively, and the all time best unsupervised re-
sult by a method that does not provide alternative
analyses for words is 66.24%, obtained by Bern-
hard (2008).3 This best unsupervised result is sur-
passed by the semi-supervised algorithm at 1000
labeled samples.
As shown in Figure 1, the supervised method
obtains inconsistent scores for English with the
3Better results (68.71%) have been achieved by Monson
et al (2008), but as they were obtained by combining of
two systems as alternative analyses, the comparison is not as
meaningful.
Figure 2: The F-measure for Finnish as a function
of the number of labeled training samples. The
semi-supervised and unsupervised lines overlap.
smallest training data sizes. The supervised al-
gorithm only knows the morphs in the training
set, and therefore is crucially dependent on the
Viterbi segmentation algorithm for analyzing new
data. Thus, overfitting to some small data sets is
not surprising. At 10 000 labeled training samples
it clearly outperforms the unsupervised algorithm.
The improvement obtained from tuning the weight
? in the supervised case is small.
Figure 2 shows the corresponding results for
Finnish. The optimization of the likelihood weight
gives a large improvement to the F-measure al-
ready in the unsupervised case. This is mainly be-
cause the standard unsupervised Morfessor Base-
line method does not, on average, segment words
into as many segments as would be appropriate for
Finnish. Without weighting, the semi-supervised
method does not improve over the unsupervised
one: The unlabeled training data is so much larger
that the labeled data has no real effect.
For Finnish, the unsupervised Morfessor Base-
line and Categories-MAP obtain F-measures of
26.75% and 44.61%, respectively (Kurimo et al,
2009). The all time best for an unsupervised
method is 52.45% by Bernhard (2008). With op-
timized likelihood weights, the semi-supervised
Morfessor Baseline achieves higher F-measures
with only 100 labeled training samples. Fur-
thermore, the largest improvement for the semi-
supervised method is achieved already from 1000
labeled training samples. Unlike English, the su-
pervised method is quite a lot worse than the un-
supervised one for small training data. This is
natural because of the more complex morphology
83
Figure 3: Precision-recall graph for English with
varying amount of labeled training data. Parame-
ters ? and ? have been optimized for three differ-
ent measures: F0.5, F1 and F2 on the held-out set.
Precision and recall values are from the final test
set, error bars indicate one standard deviation.
in Finnish; good results are not achieved just by
knowing the few most common suffixes.
Figures 3 and 4 show precision-recall graphs
of the performance of the semi-supervised method
for English and Finnish. The parameters ? and ?
have been optimized for three differently weighted
F-measures (F0.5, F1, and F2) on the held-out set.
The weight tells how much recall is emphasized;
F1 is the symmetric F-measure that emphasizes
precision and recall alike. The graphs show that
the more there are labeled training data, the more
constrained the model parameters are: With many
labeled examples, the model cannot be forced to
achieve high precision or recall only. The phe-
nomenon is more evident in the Finnish data (Fig-
ure 3), where the same amount of words contains
more information (morphemes) than in the En-
glish data. Table 1 shows the F0.5, F1 and F2
measures numerically.
Table 2 shows the values for the F1-optimal
weights ? and ? that were chosen for different
amounts of labeled data using the held-out set. As
even the largest labeled sets are much smaller than
the unlabeled training set, it is natural that ? ? ?.
The small optimal ? for Finnish explains why the
difference between unsupervised unweighted and
weighted versions in Figure 2 was so large. Gener-
ally, the more there is labeled data, the smaller ? is
needed. A possible increase in overall likelihood
cost is compensated by a smaller ?. Finnish with
100 labeled words is an exception; probably a very
Figure 4: Precision-recall graph for Finnish with
varying amount of labeled training data. Param-
eters ? and ? have been optimized for three dif-
ferent measures: F0.5, F1 and F2 on the held-out
set. Precision and recall values are from the final
test set, error bars indicate one standard deviation,
which here is very small.
high ? would end in overlearning of the small set
words at the cost of overall performance.
4 Discussion
The method developed in this paper is a straight-
forward extension of Morfessor Baseline. In the
semi-supervised setting, it should be possible to
develop a generative model that would not require
any discriminative reweighting, but could learn,
e.g., the amount of segmentation from the labeled
data. Moreover, it would be possible to learn the
morpheme labels instead of just the segmentation
into morphs, either within the current model or as
a separate step after the segmentation. We made
initial experiment with a trivial context-free label-
ing: A mapping between the segments and mor-
pheme labels was extracted from the labeled train-
ing data. If some label did not have a correspond-
ing segment, it was appended to the previous la-
bel. E.g., if the labels for ?found? are ?find V
+PAST?, ?found? was mapped to both labels. Af-
ter segmentation, each segment in the test data was
replaced by the most common label or label se-
quence whenever such was available. The results
using training data with 1 000 and 10 000 labeled
samples are shown in Table 3. Although preci-
sions decrease somewhat, recalls improve consid-
erably, and significant gains in F-measure are ob-
tained. A more advanced, context-sensitive label-
ing should perform much better.
84
English
labeled data F0.5 F1 F2
0 69.16 61.05 62.70
100 73.23 65.18 68.30
300 72.98 65.63 68.81
1000 71.86 68.29 69.68
3000 74.34 69.13 72.01
10000 76.04 72.85 73.89
Finnish
labeled data F0.5 F1 F2
0 56.81 49.07 53.95
100 58.96 52.66 57.01
300 59.33 54.92 57.16
1000 61.75 56.38 58.24
3000 63.72 58.21 58.90
10000 66.58 60.26 57.24
Table 1: The F0.5, F1 and F2 measures for the
semi-supervised + weighting method.
English Finnish
labeled data ? ? ? ?
0 0.75 - 0.01 -
100 0.75 750 0.01 500
300 1 500 0.005 5000
1000 1 500 0.05 2500
3000 1.75 350 0.1 1000
10000 1.75 175 0.1 500
Table 2: The values for the weights ? and ?
that the semisupervised algorithm chose for differ-
ent amounts of labeled data when optimizing F1-
measure.
The semi-supervised extension could easily be
applied to the other versions and extensions of
Morfessor, such as Morfessor Categories-MAP
(Creutz and Lagus, 2007) and Allomorfessor (Vir-
pioja and Kohonen, 2009). Especially the model-
ing of allomorphy might benefit from even small
amounts of labeled data, because those allomorphs
that are hardest to find (affixes, stems with irregu-
lar orthographic changes) are often more common
than the easy cases, and thus likely to be found
even from a small labeled data set.
Even without labeling, it will be interesting
to see how well the semi-supervised morphology
learning works in applications such as information
retrieval. Compared to unsupervised learning, we
obtained much higher recall for reasonably good
levels of precision, which should be beneficial to
most applications.
Segmented Labeled
English, D = 1000
Precision 69.72% 69.30%
Recall 66.92% 72.21%
F-measure 68.29% 70.72%
English, D = 10 000
Precision 77.35% 77.07%
Recall 68.85% 77.78%
F-measure 72.86% 77.42%
Finnish, D = 1000
Precision 61.03% 58.96%
Recall 52.38% 66.55%
F-measure 56.38% 62.53%
Finnish, D = 10 000
Precision 69.14% 66.90%
Recall 53.40% 74.08%
F-measure 60.26% 70.31%
Table 3: Results of a simple morph labeling after
segmentation with semi-supervised Morfessor.
5 Conclusions
We have evaluated an extension of the Morfessor
Baseline method to semi-supervised morphologi-
cal segmentation. Even with our simple method,
the scores improve far beyond the best unsuper-
vised results. Moreover, already one hundred
known segmentations give significant gain over
the unsupervised method even with the optimized
data likelihood weight.
Acknowledgments
This work was funded by Academy of Finland and
Graduate School of Language Technology in Fin-
land. We thank Mikko Kurimo and Tiina Lindh-
Knuutila for comments on the manuscript, and
Nokia foundation for financial support.
References
Delphine Bernhard. 2006. Unsupervised morpholog-
ical segmentation based on segment predictability
and word segments alignment. In Proceedings of the
PASCAL Challenge Workshop on Unsupervised seg-
mentation of words into morphemes, Venice, Italy.
PASCAL European Network of Excellence.
Delphine Bernhard. 2008. Simple morpheme labelling
in unsupervised morpheme analysis. In Advances in
Multilingual and Multimodal Information Retrieval,
8th Workshop of the CLEF, volume 5152 of Lec-
ture Notes in Computer Science, pages 873?880.
Springer Berlin / Heidelberg.
85
Mathias Creutz and Krista Lagus. 2002. Unsuper-
vised discovery of morphemes. In Proceedings of
the Workshop on Morphological and Phonological
Learning of ACL?02, pages 21?30, Philadelphia,
Pennsylvania, USA.
Mathias Creutz and Krista Lagus. 2005. Unsupervised
morpheme segmentation and morphology induction
from text corpora using Morfessor 1.0. Technical
Report A81, Publications in Computer and Informa-
tion Science, Helsinki University of Technology.
Mathias Creutz and Krista Lagus. 2007. Unsuper-
vised models for morpheme segmentation and mor-
phology learning. ACM Transactions on Speech and
Language Processing, 4(1), January.
Mathias Creutz and Krister Linde?n. 2004. Morpheme
segmentation gold standards for Finnish and En-
glish. Technical Report A77, Publications in Com-
puter and Information Science, Helsinki University
of Technology.
Mathias Creutz, Teemu Hirsima?ki, Mikko Kurimo,
Antti Puurula, Janne Pylkko?nen, Vesa Siivola, Matti
Varjokallio, Ebru Arisoy, Murat Sarac?lar, and An-
dreas Stolcke. 2007. Morph-based speech recog-
nition and modeling of out-of-vocabulary words
across languages. ACM Transactions on Speech and
Language Processing, 5(1):1?29.
Sajib Dasgupta and Vincent Ng. 2007. High-
performance, language-independent morphological
segmentation. In the annual conference of the North
American Chapter of the ACL (NAACL-HLT).
Arthur P. Dempster, Nan M. Laird, and Donald B. Ru-
bin. 1977. Maximum likelihood from incomplete
data via the em algorithm. Journal of the Royal Sta-
tistical Society, Series B (Methodological), 39(1):1?
38.
John Goldsmith. 2001. Unsupervised learning of the
morphology of a natural language. Computational
Linguistics, 27(2):153?189.
Kimmo Koskenniemi. 1983. Two-level morphology: A
general computational model for word-form recog-
nition and production. Ph.D. thesis, University of
Helsinki.
Mikko Kurimo, Mathias Creutz, and Matti Varjokallio.
2008. Morpho Challenge evaluation using a linguis-
tic Gold Standard. In Advances in Multilingual and
MultiModal Information Retrieval, 8th Workshop of
the Cross-Language Evaluation Forum, CLEF 2007,
Budapest, Hungary, September 19-21, 2007, Re-
vised Selected Papers, Lecture Notes in Computer
Science , Vol. 5152, pages 864?873. Springer.
Mikko Kurimo, Sami Virpioja, Ville T. Turunen,
Graeme W. Blackwood, and William Byrne. 2009.
Overview and results of Morpho Challenge 2009. In
Working Notes for the CLEF 2009 Workshop, Corfu,
Greece, September.
Wei Li and Andrew McCallum. 2005. Semi-
supervised sequence modeling with syntactic topic
models. In AAAI?05: Proceedings of the 20th na-
tional conference on Artificial intelligence, pages
813?818. AAAI Press.
Christian Monson, Alon Lavie, Jaime Carbonell, and
Lori Levin. 2004. Unsupervised induction of natu-
ral language morphology inflection classes. In Pro-
ceedings of the Workshop of the ACL Special Interest
Group in Computational Phonology (SIGPHON).
Christian Monson, Jaime Carbonell, Alon Lavie, and
Lori Levin. 2008. ParaMor: Finding paradigms
across morphology. In Advances in Multilingual
and MultiModal Information Retrieval, 8th Work-
shop of the Cross-Language Evaluation Forum,
CLEF 2007, Budapest, Hungary, September 19-21,
2007, Revised Selected Papers, Lecture Notes in
Computer Science , Vol. 5152. Springer.
Hoifung Poon, Colin Cherry, and Kristina Toutanova.
2009. Unsupervised morphological segmentation
with log-linear models. In NAACL ?09: Proceed-
ings of Human Language Technologies: The 2009
Annual Conference of the North American Chap-
ter of the Association for Computational Linguistics,
pages 209?217. Association for Computational Lin-
guistics.
Jorma Rissanen. 1989. Stochastic Complexity in Sta-
tistical Inquiry, volume 15. World Scientific Series
in Computer Science, Singapore.
Benjamin Snyder and Regina Barzilay. 2008a. Cross-
lingual propagation for morphological analysis. In
AAAI?08: Proceedings of the 23rd national con-
ference on Artificial intelligence, pages 848?854.
AAAI Press.
Benjamin Snyder and Regina Barzilay. 2008b. Un-
supervised multilingual learning for morphological
segmentation. In Proceedings of ACL-08: HLT,
pages 737?745, Columbus, Ohio, June. Association
for Computational Linguistics.
Sami Virpioja and Oskar Kohonen. 2009. Unsuper-
vised morpheme analysis with Allomorfessor. In
Working notes for the CLEF 2009 Workshop, Corfu,
Greece.
Jia Xu, Jianfeng Gao, Kristina Toutanova, and Her-
mann Ney. 2008. Bayesian semi-supervised chinese
word segmentation for statistical machine transla-
tion. In COLING ?08: Proceedings of the 22nd In-
ternational Conference on Computational Linguis-
tics, pages 1017?1024, Morristown, NJ, USA. As-
sociation for Computational Linguistics.
Xiaojin Zhu. 2005. Semi-supervised Learning with
Graphs. Ph.D. thesis, CMU. Chapter 11, Semi-
supervised learning literature survey (updated online
version).
86
Proceedings of the 11th Meeting of the ACL-SIGMORPHON, ACL 2010, pages 87?95,
Uppsala, Sweden, 15 July 2010. c?2010 Association for Computational Linguistics
Morpho Challenge competition 2005-2010: Evaluations and results
Mikko Kurimo, Sami Virpioja, Ville Turunen, Krista Lagus
Adaptive Informatics Research Centre
Aalto University, Espoo, Finland
Firstname.Lastname@tkk.fi
Abstract
Morpho Challenge is an annual evalu-
ation campaign for unsupervised mor-
pheme analysis. In morpheme analysis,
words are segmented into smaller mean-
ingful units. This is an essential part in
processing complex word forms in many
large-scale natural language processing
applications, such as speech recognition,
information retrieval, and machine trans-
lation. The discovery of morphemes is
particularly important for morphologically
rich languages where inflection, deriva-
tion and composition can produce a huge
amount of different word forms. Morpho
Challenge aims at language-independent
unsupervised learning algorithms that can
discover useful morpheme-like units from
raw text material. In this paper we de-
fine the challenge, review proposed algo-
rithms, evaluations and results so far, and
point out the questions that are still open.
1 Introduction
Many large-scale natural language processing
(NLP) applications, such as speech recognition,
information retrieval and machine translation, re-
quire that complex word forms are analyzed into
smaller, meaningful units. The discovery of these
units called morphemes is particularly important
for morphologically rich languages where the in-
flection, derivation and composition makes it im-
possible to even list all the word forms that are
used. Various tools have been developed for mor-
pheme analysis of word forms, but they are mostly
based on language-specific rules that are not eas-
ily ported to other languages. Recently, the per-
formance of tools based on language-independent
unsupervised learning from raw text material has
improved significantly and rivaled the language-
specific tools in many applications.
The unsupervised algorithms proposed so far in
Morpho Challenge typically first generate various
alternative morphemes for each word and then se-
lect the best ones based on relevant criteria. The
statistical letter successor variation (LSV) analy-
sis (Harris, 1955) and its variations are quite com-
monly used as generation methods. LSV is based
on the observation that the segment borders be-
tween the sub-word units often co-occur with the
peaks of variation for the next letter. One popu-
lar selection approach is to minimize a cost func-
tion that balances between the size of the corpus
when coded by the morphemes and the size of
the morpheme codebook needed. Selection cri-
teria that produce results resembling the linguis-
tic morpheme segmentation include, for example,
the Minimum Description Length (MDL) princi-
ple and maximum a posteriori (MAP) probability
optimization (de Marcken, 1996; Creutz and La-
gus, 2005).
The Morpho Challenge competition was
launched in 2005 to encourage the machine
learning people, linguists and specialists in NLP
applications to study this field and come together
to compare their best algorithms against each
other. The organizers selected evaluation tasks,
data and metric and performed all the evaluations.
Thus, participation was made easy for people
who were not specialists in the chosen NLP
applications. Participation was open to everybody
with no charge. The competition became popular
right from the beginning and has gained new
participants every year.
Although not all the authors of relevant mor-
pheme analysis algorithms have yet submitted
their algorithms for this evaluation campaign,
more than 50 algorithms have already been eval-
uated. After the first five years of Morpho Chal-
lenge, a lot has been learned on the various pos-
sible ways to solve the problem and how the dif-
ferent methods work in various NLP tasks. How-
87
ever, there are still open questions such as: how to
find meaning for the obtained unsupervised mor-
phemes, how to disambiguate among the alterna-
tive analyses of one word, and how to use context
in the analysis. Another recently emerged ques-
tion that is the special topic in 2010 competition
is how to utilize small amounts of labeled data
and semi-supervised learning to further improve
the analysis.
2 Definition of the challenge
2.1 Morphemes and their evaluation
Generally, the morphemes are defined as the
smallest meaningful units of language. Rather
than trying to directly specify which units are
meaningful, the Morpho Challenge aims at find-
ing units that would be useful for various practical
NLP applications. The goal is to find automatic
methods that can discover suitable units using un-
supervised learning directly on raw text data. The
methods should also not be restricted to certain
languages or include many language and applica-
tion dependent parameters that needed to be hand
tuned for each task separately. The following three
goals have been defined as the main scientific ob-
jectives for the challenge: (1) To learn of the phe-
nomena underlying word construction in natural
languages. (2) To discover approaches suitable for
a wide range of languages. (3) To advance ma-
chine learning methodology.
The evaluation tasks, metrics and languages
have been designed based on the scientific objec-
tives of the challenge. It can not be directly ver-
ified how well an obtained analysis reflects the
word construction in natural languages, but intu-
itively, the methods that split everything into let-
ters or pre-specified letter n-grams, or leave the
word forms unanalyzed, would not be very in-
teresting solutions. An interesting thing that can
be evaluated, however, is how close the obtained
analysis is to the linguistic gold standard mor-
phemes that can be obtained from CELEX or
various language-dependent rule-based analyzers.
The exact definition of the morphemes, tags, or
features available in the gold standard to be uti-
lized in the comparison should be decided and
fixed for each language separately.
To verify that a proposed algorithm works in
various languages would, ideally, require running
the evaluations on a large number of languages
that would be somehow representative of various
important language families. However, the re-
sources available for both computing and evalu-
ating the analysis in various applications and lan-
guages are limited. The suggested and applicable
compromise is to select morphologically rich lan-
guages where the morpheme analysis is most use-
ful and those languages where interesting state-of-
the-art evaluation tasks are available. By including
German, Turkish, Finnish and Arabic, many inter-
esting aspects of concatenative morphology have
already been covered.
While the comparison against the linguistic
gold standard morphemes is an interesting sub-
goal, the main interest in running the Morpho
Challenge is to find out how useful the proposed
morpheme analyses are for various practical NLP
applications. Naturally, this is best evaluated
by performing evaluations in several state-of-the-
art application tasks. Due to the limitations of
the resources, the applications have been selected
based on the importance of the morpheme analy-
sis for the application, on the availability of open
state-of-the-art evaluation tasks, and on the effort
needed to run the actual evaluations.
2.2 Unsupervised and semi-supervised
learning
Unsupervised learning is the task of learning with-
out labeled data. In the context of morphology dis-
covery, it means learning without knowing where
morpheme borders are, or which morphemes exist
in which words. Unsupervised learning methods
have many attractive features for morphological
modeling, such as language-independence, inde-
pendence of any particular linguistic theory, and
easy portability to a new language.
Semi-supervised learning can be approached
from two research directions, namely unsuper-
vised and supervised learning. In an essentially
unsupervised learning task there may exist some
labeled (classified) data, or some known links be-
tween data items, which might be utilized by the
(typically generative) learning algorithms. Turned
around, an essentially supervised learning task,
such as classification or prediction, may benefit
also from unlabeled data which is typically more
abundantly available.
In morphology modeling one might consider
the former setup to be the case: the learning task
is essentially that of unsupervised modeling, and
morpheme labels can be thought of as known links
88
between various inflected word forms.
Until 2010 the Morpho Challenge has been de-
fined only as an unsupervised learning task. How-
ever, since small samples of morphologically la-
beled data can be provided already for quite many
languages, also the semi-supervised learning task
has become of interest.
Moreover, while there exists a fair amount of
research and now even books on semi-supervised
learning (Zhu, 2005; Abney, 2007; Zhu, 2010),
it has not been as widely studied for structured
classification problems like sequence segmenta-
tion and labeling (cf. e.g. (Jiao et al, 2006)). The
semi-supervised learning challenge introduced for
Morpho Challenge 2010 can thus be viewed as an
opportunity to strengthen research in both mor-
phology modeling as well as in semi-supervised
learning for sequence segmentation and labeling
in general.
3 Review of Morpho Challenge
competitions so far
3.1 Evaluation tasks, metrics, and languages
The evaluation tasks and languages selected for
Morpho Challenge evaluations are shown in Fig-
ure 1. The languages where evaluations have been
prepared are Finnish (FIN), Turkish (TUR), En-
glish (ENG), German (GER), and Arabic (ARA).
First the morphemes are compared to linguis-
tic gold standards in direct morpheme segmen-
tation (2005) and full morpheme analysis (since
2007). The practical NLP application based eval-
uations are automatic speech recognition (ASR),
information retrieval (IR) and statistical machine
translation (SMT). Morphemes obtained by semi-
supervised learning can be evaluated in parallel
with the unsupervised morphemes. For IR, eval-
uation has also been extended for full sentences,
where the morpheme analysis can based on con-
text. The various suggested and tested evaluations
are defined in this section.
year new languages new tasks
2005 FIN, TUR, ENG segmentation, ASR
2007 GER full analysis, IR
2008 ARA context IR
2009 - SMT
2010 - semi-supervised
Table 1: The evolution of the evaluations. The
acronyms are explained in section 3.1.
3.1.1 Comparisons to linguistic gold standard
The first Morpho Challenge in 2005 (Kurimo et
al., 2006) considered unsupervised segmentation
of words into morphemes. The evaluation was
based on comparing the segmentation boundaries
given by the competitor?s algorithm to the bound-
aries obtained from a gold standard analysis.
From 2007 onwards, the task was changed to
full morpheme analysis, that is, the algorithm
should not only locate the surface forms (i.e., word
segments) of the morphemes, but find also which
surface forms are realizations (allomorphs) of the
same underlying morpheme. This generalizes the
task for finding more meaningful units than just
the realizations of morphemes that may be just in-
dividual letters or even empty strings. In applica-
tions this is useful when it is important to identify
which units carry the same meaning even if they
have different realizations in different words.
As an unsupervised algorithm cannot find the
morpheme labels that would equal to the labels in
the gold standard, the evaluation has to be based
on what word forms share the same morphemes.
The evaluation procedure samples a large num-
ber of word pairs, such that both words in the
pair have at least one morpheme in common, from
both the proposed analysis and the gold standard.
The first version of the method was applied in
2007 (Kurimo et al, 2008) and 2008 (Kurimo et
al., 2009a), and minor modifications were done in
2009 (Kurimo et al, 2009b). However, the orga-
nizers have reported the evaluation results of the
2007 and 2008 submissions also with the new ver-
sion, thus allowing a direct comparison between
them. A summary of these results for English,
Finnish, German and Turkish for the best algo-
rithms is presented in Table 2. The evaluations
in 2008 and 2009 were also performed on Arabic,
but these results and not comparable, because the
database and the gold standard was changed be-
tween the years. The exact annual results for all
participants as well as the details of the evaluation
in each year can be reviewed in the annual evalu-
ation reports (Kurimo et al, 2006; Kurimo et al,
2008; Kurimo et al, 2009a; Kurimo et al, 2009b).
Already the linguistic evaluation of Morpho
Challenge 2005 applied some principles that have
been used thereafter: (1) The evaluation is based
on a subset of the word forms given as training
data. This not only makes the evaluation proce-
dure lighter, but also allows changing the set when
89
English Finnish
Method P R F Method P R F
2009 2009
Allomorfessor 68.98 56.82 62.31 Monson PMU 47.89 50.98 49.39
Monson PMU 55.68 62.33 58.82 Monson PMM 51.75 45.42 48.38
Lignos 83.49 45.00 58.48 Spiegler PROMODES C 41.20 48.22 44.44
2008 2008
Monson P+M 69.59 65.57 67.52 Monson P+M 65.21 50.43 56.87
Monson ParaMor 63.32 51.96 57.08 Monson ParaMor 49.97 37.64 42.93
Zeman 1 67.13 46.67 55.06 Monson Morfessor 79.76 24.95 38.02
2007 2007
Monson P+M 70.09 67.38 68.71 Bernhard 2 63.92 44.48 52.45
Bernhard 2 67.42 65.11 66.24 Bernhard 1 78.11 29.39 42.71
Bernhard 1 75.61 57.87 65.56 Bordag 5a 72.45 27.21 39.56
German Turkish
Method P R F Method P R F
2009 2009
Monson PMU 52.53 60.27 56.14 Monson PMM 48.07 60.39 53.53
Monson PMM 51.07 57.79 54.22 Monson PMU 47.25 60.01 52.88
Monson PM 50.81 47.68 49.20 Monson PM 49.54 54.77 52.02
2008 2008
Monson P+M 64.06 61.52 62.76 Monson P+M 66.78 57.97 62.07
Monson Morfessor 70.73 38.82 50.13 Monson ParaMor 57.35 45.75 50.90
Monson ParaMor 56.98 42.10 48.42 Monson Morfessor 77.36 33.47 46.73
2007 2007
Monson P+M 69.96 55.42 61.85 Bordag 5a 81.06 23.51 36.45
Bernhard 2 54.02 60.77 57.20 Bordag 5 81.19 23.44 36.38
Bernhard 1 66.82 42.48 51.94 Zeman 77.48 22.71 35.13
Table 2: The summary of the best three submitted methods for years 2009, 2008 and 2007 using the
linguistic evaluation of Morpho Challenge 2009. The complete results tables by the organizers are avail-
able from http://www.cis.hut.fi/morphochallenge2009/. The three columns numbers
are precision (P), recall (R), and F-measure (F). The best F-measure for each language is in boldface,
and the best result that is not based on a direct combination of two other methods is underlined.
the old one is considered to be ?overlearned?. (2)
The frequency of the word form plays no role in
evaluation; rare and common forms are equally
likely to be selected, and have equal weight to
the score. (3) The evaluation score is balanced F-
measure, the harmonic mean of precision and re-
call. Precision measures how many of the choices
made by the algorithm are matched in gold stan-
dard; recall measures how many of the choices
in the gold standard are matched in the proposed
analysis. (4) If the linguistic gold standard has
several alternative analysis for one word, for full
precision, it is enough that one of the alternatives
is equivalent to the proposed analysis. The same
holds the other way around for recall.
All of the principles can be also criticized. For
example, evaluation based on the full set would
provide more trustworthy estimates, and common
word forms are more significant in any practical
application. However, the third and the fourth
principle have problems that can be considered to
be more serious.
Balanced F-measure favors methods that are
able to get near-to-equal precision and recall. As
many algorithms can be tuned to give either more
or less morphemes per word than in the default
case, this encourages using developments sets to
optimize the respective parameters. The winning
methods in Challenge 2009?Monson?s ParaMor-
Morfessor Union (PMU) and ParaMor-Morfessor
90
Mimic (PMM) (Monson et al, 2009), and Al-
lomorfessor (Virpioja and Kohonen, 2009)?did
this, more or less explicitly.1 Moreover, it can
be argued that the precision would be more im-
portant than recall in many applications, or, more
generally, that the optimal balance between preci-
sion and recall is application dependent. We see
two solutions for this: Either the optimization for
F-measure should be allowed with a public devel-
opment set, which means moving towards semi-
supervised direction, or precision-recall curves
should be compared, which means more complex
evaluations.
The fourth principle causes problems, if the
evaluated algorithms are allowed to have alterna-
tive analyses for each word. If several alternative
analyses are provided, the obtained precision is
about the average over the individual analyses, but
the recall is based on the best of the alternatives.
This property have been exploited in Challenges
2007 and 2008 by combining the results of two
algorithms as alternative analyses. The method,
Monson?s ParaMor+Morfessor (P+M) holds still
the best position measured in F-measures in all
languages. Combining even better-performing
methods in a similar manner would increase the
scores further. To fix this problem, either the eval-
uation metric should require matching number of
alternative analyses to get the full points, or the
symmetry of the precision and recall measures has
to be removed.
Excluding the methods that combine the anal-
yses of two other methods as alternative ones, we
see that the best F-measure (underlined in Table 2)
is held by Monson?s ParaMor-Morfessor Mimic
from 2009 (Monson et al, 2009) in Turkish and
Bernhard?s method 2 from 2007 (Bernhard, 2006)
in all the other three languages. This means that
except for Turkish, there is no improvement in the
results over the three years. Furthermore, both
of the methods are based purely on segmentation,
and so are all the other top methods presented
in Table 2 except for Bordag?s methods (Bordag,
2006) and Allomorfessor (Virpioja and Kohonen,
2009).
3.1.2 Speech recognition
A key factor in the success of large-vocabulary
continuous speech recognition is the system?s abil-
1Allomorfessor was trained with a pruned data to obtain
a higher recall, whereas ParaMor-Morfessor is explicitly op-
timized for F-measure with a separate Hungarian data set.
ity to limit the search space using a statistical lan-
guage model. The language model provides the
probability of different recognition hypothesis by
using a model of the co-occurence of its words
and morphemes. A properly smoothed n-gram is
the most conventional model. The n-gram should
consist of modeling units that are suitable for the
language, typically words or morphemes.
In Morpho Challenge state-of-the-art large-
vocabulary speech recognizers have been built for
evaluations in Finnish and Turkish (Kurimo et al,
2006). The various morpheme analysis algorithms
have been compared by measuring the recogni-
tion accuracy with different language models each
trained and optimized based on units from one of
the algorithms. The best results were quite near
to each other, but Bernhard (Bernhard, 2006) and
Morfessor Categories MAP were at the top for
both languages.
3.1.3 Information retrieval
In the information retrieval task, the algorithms
were tested by using the morpheme segmentations
for text retrieval. To return all relevant documents,
it is important to match the words in the queries to
the words in the documents irrespective of which
word forms are used. Typically, a stemming al-
gorithm or a morphological analyzer is used to re-
duce the inflected forms to their stem or base form.
The problem with these methods is that specific
rules need to be crafted for each language. How-
ever, these approaches were also tested for com-
parison purposes. The IR experiments were car-
ried out by replacing the words in the corpora and
queries by the suggested morpheme segmenta-
tions. Test corpora, queries and relevance assess-
ments were provided by Cross-Language Evalua-
tion Forum (CLEF) (Agirre et al, 2008).
To test the effect of the morpheme segmen-
tation, the number of other variables will have
to be minimized, which poses some challenges.
For example, the term weighting method will af-
fect the results and different morpheme analyz-
ers may perform optimally with different weight-
ing approaches. TFIDF and Okapi BM25 term
weighting methods have been tested. In the 2007
Challenge, it was noted that Okapi BM25 suffers
greatly if the corpus contains a lot of frequent
terms. These terms are often introduced when the
algorithms segment suffixes from stems. To over-
come this problem, a method for automatically
generating stop lists of frequent terms was intro-
91
duced. Any term that occurs more times in the cor-
pus than a certain threshold is added to the stop list
and excluded from indexing. The method is quite
simple, but it treats all morpheme analysis meth-
ods equally as it does not require the algorithm
to tag which morphemes are stems and which are
suffixes. The generated stoplists are also reason-
able sized and the results are robust with respect
to the stop list cutoff parameter. With a stop list,
Okapi BM25 clearly outperformed TFIDF rank-
ing method for all algorithms. However, the prob-
lem of choosing the term weighting approach that
treats all algorithms in an optimal way remains
open.
Another challenge is analyzing the results as it
is hard to achieve statistically significant results
with the limited number of queries (50-60) that
were available. In fact, in each language 11-17 of
the best algorithms belonged to the ?top group?,
that is, had no statistically different result to the
top performer of the language. To improve the
significance of the results, the number of queries
should be increased. This is a known problem in
the field of IR. However, it is important to test the
methods in a real life application and if an algo-
rithm gives good results across languages, there is
evidence that it is doing something useful.
Some conclusions can be drawn from the re-
sults. The language specific reference methods
(Porter stemming for English, two-layer morpho-
logical analysis for Finnish and German) give the
best results, but the best unsupervised algorithms
are almost at par and the differences are not signif-
icant. For German and Finnish, the best unsuper-
vised methods can also beat in a statistically sig-
nificant way the baseline of not doing any segmen-
tation or stemming. The best algorithms that per-
formed well across languages are ParaMor (Mon-
son et al, 2008), Bernhard (Bernhard, 2006), Mor-
fessor Baseline, andMcNamee (McNamee, 2008).
Comparing the results to the linguistic evalua-
tion (section 3.1.1), it seems that methods that per-
form well at the IR task tend to have good preci-
sion in the linguistic task, with exceptions. Thus,
in the IR task it seems important not to overseg-
ment words. One exception is the method (Mc-
Namee, 2008) which simply splits the words into
equal length letter n-grams. The method gives sur-
prisingly good results in the IR task, given the sim-
plicity, but suffers from low precision in the lin-
guistic task.
3.1.4 Machine translation
In phrase-based statistical machine translation
process there are two stages where morpheme
analysis and segmentation of the words into mean-
ingful sub-word units is needed. The first stage
is the alignment of the parallel sentences in the
source and target language for training the transla-
tion model. The second one is training a statistical
language model for the production of fluent sen-
tences in a morphologically rich target language.
In the machine translation tasks used in the
Morpho Challenge, the focus has so far been in
the alignment problem. In the evaluation tasks in-
troduced in 2009 the language-pairs were Finnish-
English and German-English. To obtain state-of-
the-art results, the evaluation consists of minimum
Bayes risk (MBR) combination of two transla-
tion systems trained on the same data, one us-
ing words and the other morphemes as the ba-
sic modeling units (de Gispert et al, 2009). The
various morpheme analysis algorithms are com-
pared by measuring the translation performance
for different two-model combinations where the
word-based model is always the same, but the
morpheme-based model is trained based on units
from each of the algorithms in turns.
Because the machine translation evaluation has
yet been tried only in 2009, it is difficult to draw
conclusions about the results yet. However, the
Morfessor Baseline algorithm seems to be partic-
ularly difficult to beat both in Finnish-German and
German-English task. The differences between
the best results are small, but the ranking in both
tasks was the same: 1. Morfessor Baseline, 2. Al-
lomorfessor, 3. The linguistic gold standard mor-
phemes (Kurimo et al, 2009b).
3.2 Evaluated algorithms
This section attempts to describe very briefly some
of the individual morpheme analysis algorithms
that have been most successful in the evaluations.
Morfessor Baseline (Creutz and Lagus, 2002):
This is a public baseline algorithm based on jointly
minimizing the size of the morph codebook and
the encoded size of the all the word forms using
the minimum description length MDL cost func-
tion. The performance is above average for all
evaluated tasks in most languages.
Allomorfessor (Kohonen et al, 2009; Virpi-
oja and Kohonen, 2009): The development of
this method was based on the observation that the
92
Finnish German English
0.25
0.3
0.35
0.4
0.45
0.5
0.55
 
 
Morfessor baseline
2007 Bernhard
2008 McNamee 4?gram
2008 Monson P+M
2009 Monson PMU
2009 Lignos
2009 Allomorfessor
Figure 1: Mean Average Precision (MAP) values for some of the best algorithms over the years in the IR
task. The upper horizontal line shows the ?goal level? for each language, i.e. the performance of the best
language specific reference method. The lower line shows the baseline reference of doing no stemming
or analysis.
morph level surface forms of one morpheme are
often very similar and the differences occur close
to the morpheme boundary. Thus, the allomor-
phemes could be modeled by simple mutations.
It has been implemented on top of the Morfessor
Baseline using maximum a posteriori (MAP) opti-
mization. This model slightly improves the perfor-
mance in the linguistic evaluation in all languages
(Kurimo et al, 2009b), but in IR and SMT there is
no improvement yet.
Morfessor Categories MAP (Creutz and La-
gus, 2005): In this method hidden Markov models
are used to incorporate morphotactic categories for
theMorfessor Baseline. The structure is optimized
by MAP and yields slight improvements in the lin-
guistic evaluation for most languages, but not for
IR or SMT tasks.
Bernhard (Bernhard, 2006): This has been one
of the best performing algorithms in Finnish, En-
glish and German linguistic evaluation and in IR
(Kurimo et al, 2008). First a list of the most likely
prefixes and suffixes is extracted and alternative
segmentations are generated for the word forms.
Then the best ones are selected based on cost func-
tions that favour most frequent analysis and some
basic morphotactics.
Bordag (Bordag, 2006): This method applies
iterative LSV and clustering of morphs into mor-
phemes. The performance in the linguistic eval-
uation is quite well for Turkish and decent for
Finnish (Kurimo et al, 2008).
ParaMor (Monson et al, 2008): This method
applies an unsupervised model for inflection rules
and suffixation for the stems by building linguisti-
cally motivated paradigms. It has obtained one of
the top performances for all languages when com-
bined with the Morfessor Baseline (Kurimo et al,
2009a). Various combination methods have been
tested: union, weighted probabilistic average and
proposing both the analyses (Monson et al, 2009).
Lignos (Lignos et al, 2009): This method is
based on the observation that the derivation of
the inflected forms can be modeled as transfor-
mations. The best transformations can be found
by optimizing the simplicity and frequency. This
method performs much better in English than in
the other languages (Kurimo et al, 2009b).
Promodes (Spiegler et al, 2009): This method
presents a probabilistic generative model that ap-
plies LSV and combines multiple analysis using a
committee. It seems to generate a large amount
of short morphemes, which is difficult for many
of the practical applications. However, it obtained
the best performance for the linguistic evaluation
in Arabic 2009 (Kurimo et al, 2009b), but did not
survive as well in other languages, and particularly
not in the IR application.
4 Open questions and challenges
Although more than 50 algorithms have already
been tested in the Morpho Challenge evaluations
and many lessons have been learned from the re-
sults and discussions, many challenges are still
open and untouched. In fact, the attempts to solve
the problem have perhaps produced even more
open questions than there were in the beginning.
93
The main new and open challenges are described
in this section.
What is the best analysis algorithm? Some
of the suggested algorithms have produced good
test results and some even in several tasks and lan-
guages, such as Bernhard (Bernhard, 2006), Mon-
son ParaMor+Morfessor (Monson et al, 2008)
and Allomorfessor (Virpioja and Kohonen, 2009).
However, none of the methods perform really well
in all the evaluation tasks and languages and their
mutual performance differences are often rather
small, even though the morphemes and the al-
gorithmic principles are totally different. Thus,
no dominant morpheme analysis algorithm have
been found. Furthermore, reaching the perfor-
mance level that rivals, or even sometimes domi-
nates, the rule-based and language-dependent ref-
erence methods does not mean that the solutions
are sufficient. Often the limited coverage or un-
suitable level of details in the analysis for the task
in the reference methods just indicates that they
are not sufficient either and better solutions are
needed. Another observation which complicates
the finding and determination of the best algorithm
is that in some tasks, such as statistical language
models for speech recognition, very different al-
gorithms can reach the same performance, because
advanced modelling methods can compensate for
unsuitable morpheme analysis.
What is the meaning of the morphemes? In
some of the fundamental applications of mor-
pheme analysis, such as text understanding, mor-
pheme segmentation alone is only part of the solu-
tion. Even more important is to find the meaning
for the obtained morphemes. The extension of the
segmentation of words into smaller units to iden-
tification of the units that correspond to the same
morpheme is a step taken to this direction, but the
question of the meaning of the morpheme is still
open. However, in the unsupervised way of learn-
ing, solutions to this may be so tightly tied to the
applications that much more complex evaluations
would be needed.
How to evaluate the alternative analyses? It
is clear that when a word form is separated from
the sentence context where it was used, the mor-
pheme analysis easily becomes ambiguous. In the
Morpho Challenge evaluations this has been taken
into account by allowing multiple alternative anal-
yses. However, in some evaluations, for exam-
ple, in the measurement of the recall of the gold
standard morphemes, this leads to unwanted re-
sults and may favour methods that always provide
a large number of alternative analysis.
How to improve the analysis using context?
A natural way to disambiguate the analysis in-
volves taking the sentence context into account.
Some of the Morpho Challenge evaluations, for
example, the information retrieval, allow this op-
tion when the source texts and queries are given.
However, this has not been widely tried yet by
the participants, probably because of the increased
computational complexity of the modelling task.
How to effectively apply semi-supervised
learning? In semi-supervised learning, a small set
of labeled data in the form of gold standard anal-
ysis for the word forms are provided. This data
can be used for improving the unsupervised solu-
tions based on unlabeled data in several ways: (1)
The labeled data is used for tuning some learning
parameters, followed by an unsupervised learning
process for the unlabeled data. (2) The labeled
morphemes are used as an ideal starting point
to bootstrap the learning on the unlabeled words
(self-training). (3) Using the EM algorithm for es-
timating a generative model, the unlabeled cases
can be treated as missing data.
The best and most practical way of using the
partly labeled data will be determined in future
when the semi-supervised task has been evaluated
in the future Morpho Challenge evaluations. For
the first time this task will be evaluated in the on-
going Morpho Challenge 2010.
Acknowledgments
We are grateful to the University of Leipzig,
University of Leeds, Computational Linguistics
Group at University of Haifa, Stefan Bordag,
Ebru Arisoy, Nizar Habash, Majdi Sawalha, Eric
Atwell, and Mathias Creutz for making the data
and gold standards in various languages available
to the Challenge. This work was supported by the
Academy of Finland in the project Adaptive In-
formatics, the graduate schools in Language Tech-
nology and Computational Methods of Informa-
tion Technology, in part by the GALE program of
the Defense Advanced Research Projects Agency,
Contract No. HR0011-06-C-0022, and in part by
the IST Programme of the European Community,
under the FP7 project EMIME (213845) and PAS-
CAL Network of Excellence.
94
References
Steven Abney. 2007. Semisupervised Learning
for Computational Linguistics. Chapman and
Hall/CRC.
Eneko Agirre, Giorgio M. Di Nunzio, Nicola Ferro,
Thomas Mandl, and Carol Peters. 2008. CLEF
2008: Ad hoc track overview. In Working Notes for
the CLEF 2008 Workshop.
Delphine Bernhard. 2006. Unsupervised morpholog-
ical segmentation based on segment predictability
and word segments alignment. In Proc. PASCAL
Challenge Workshop on Unsupervised segmentation
of words into morphemes, Venice, Italy. PASCAL
European Network of Excellence.
Stefan Bordag. 2006. Two-step approach to unsuper-
vised morpheme segmentation. In Proc. of the PAS-
CAL Challenge Workshop on Unsupervised segmen-
tation of words into morphemes, Venice, Italy. PAS-
CAL European Network of Excellence.
Mathias Creutz and Krista Lagus. 2002. Unsu-
pervised discovery of morphemes. In Proc. SIG-
PHON/ACL?02, pages 21?30.
Mathias Creutz and Krista Lagus. 2005. Inducing the
morphological lexicon of a natural language from
unannotated text. In Proc. AKRR?05, pages 106?
113.
Adria de Gispert, Sami Virpioja, Mikko Kurimo, and
William Byrne. 2009. Minimum bayes risk
combination of translation hypothesis from alter-
native morphological decompositions. In Proc.
NAACL?09, pages 73-76.
C. G. de Marcken. 1996. Unsupervised Language Ac-
quisition. Ph.D. thesis, MIT.
Zellig S. Harris. 1955. From phoneme to morpheme.
Language, 31(2):190?222. Reprinted 1970 in Pa-
pers in Structural and Transformational Linguistics,
Reidel Publishing Company, Dordrecht, Holland.
Feng Jiao, Shaojun Wang, Chi-Hoon Lee, Russell
Greiner, and Dale Schuurmans. 2006. Semi-
supervised conditional random fields for improved
sequence segmentation and labeling. In Proc.
ACL?06, pages 209?216.
Oskar Kohonen, Sami Virpioja, and Mikaela Klami.
2009. Allomorfessor: Towards unsupervised mor-
pheme analysis. In Evaluating systems for Mul-
tilingual and MultiModal Information Access, 9th
Workshop of the Cross-Language Evaluation Forum,
CLEF 2008, Revised Selected Papers, Lecture Notes
in Computer Science , Vol. 5706. Springer.
Mikko Kurimo, Mathias Creutz, and Krista Lagus.
2006. Unsupervised segmentation of words into
morphemes - challenge 2005, an introduction and
evaluation report. In Proc. PASCAL Challenge
Workshop on Unsupervised segmentation of words
into morphemes, Venice, Italy. PASCAL European
Network of Excellence.
Mikko Kurimo, Mathias Creutz, and Matti Varjokallio.
2008. Morpho Challenge evaluation using a linguis-
tic Gold Standard. In Advances in Multilingual and
MultiModal Information Retrieval, 8th Workshop of
the Cross-Language Evaluation Forum, CLEF 2007,
Revised Selected Papers, Lecture Notes in Computer
Science , Vol. 5152, pages 864?873. Springer.
Mikko Kurimo, Ville Turunen, and Matti Varjokallio.
2009a. Overview of Morpho Challenge 2008.
In Evaluating systems for Multilingual and Mul-
tiModal Information Access, 9th Workshop of the
Cross-Language Evaluation Forum, CLEF 2008,
Revised Selected Papers, Lecture Notes in Computer
Science , Vol. 5706. Springer.
Mikko Kurimo, Sami Virpioja, Ville T. Turunen,
Graeme W. Blackwood, and William Byrne. 2009b.
Overview and results of Morpho Challenge 2009. In
Working Notes for the CLEF 2009 Workshop, Corfu,
Greece.
Constantine Lignos, Erwin Chan, Mitchell P. Marcus,
and Charles Yang. 2009. A rule-based unsupervised
morphology learning framework. In Working Notes
for the CLEF 2009 Workshop, Corfu, Greece.
Paul McNamee. 2008. Retrieval experiments at mor-
pho challenge 2008. InWorking Notes for the CLEF
2008 Workshop, Aarhus, Denmark, September.
Christian Monson, Jaime Carbonell, Alon Lavie, and
Lori Levin. 2008. ParaMor: Finding paradigms
across morphology. In Advances in Multilingual
and MultiModal Information Retrieval, 8th Work-
shop of the Cross-Language Evaluation Forum,
CLEF 2007, Revised Selected Papers, Lecture Notes
in Computer Science , Vol. 5152. Springer.
Christian Monson, Kristy Hollingshead, and Brian
Roard. 2009. Probabilistic paraMor. In Working
Notes for the CLEF 2009 Workshop, Corfu, Greece,
September.
Sebastian Spiegler, Bruno Golenia, and Peter Flach.
2009. PROMODES: A probabilistic generative
model for word decomposition. In Working Notes
for the CLEF 2009 Workshop, Corfu, Greece,
September.
Sami Virpioja and Oskar Kohonen. 2009. Unsuper-
vised morpheme discovery with Allomorfessor. In
Working Notes for the CLEF 2009 Workshop, Corfu,
Greece, September.
Xiaojin Zhu. 2005. Semi-supervised learning litera-
ture survey. Technical Report 1530, Computer Sci-
ences, University of Wisconsin-Madison.
Xiaojin Zhu. 2010. Semi-supervised learning. In En-
cyclopedia of Machine Learning. To appear.
95
