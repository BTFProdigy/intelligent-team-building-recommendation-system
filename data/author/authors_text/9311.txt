Adapting an Example-Based Translation System to
Chinese
Ying Zhang, Ralf D. Brown, and Robert E. Frederking
Language Technologies Institute, Carnegie Mellon University
5000 Forbes Avenue
Pittsburgh, PA 15213-3890 USA
fjoy,ralf,refg@cs.cmu.edu
ABSTRACT
We describe an Example-Based Machine Translation (EBMT) sys-
tem and the adaptations and enhancementsmade to create a Chinese-
English translation system from the Hong Kong legal code and var-
ious other bilingual resources available from the Linguistic Data
Consortium (LDC).
1. BACKGROUND
We describe an Example-Based Machine Translation (EBMT)
system and the adaptations and enhancements made to create a
Chinese-English translation system from the Hong Kong legal code
and various other bilingual resources available from the Linguistic
Data Consortium (LDC).
The EBMT software [1, 3] used for the experiments described
here is a shallow system which can function using nothing more
than sentence-alignedplaintext and a bilingual dictionary; and given
sufficient parallel text, the dictionary can be extracted statistically
from the corpus [2]. To perform a translation, the program looks up
all matching phrases in the source-language half of the parallel cor-
pus and performs a word-level alignment on the entries containing
matches to determine a (usually partial) translation. Portions of the
input for which there are no matches in the corpus do not generate
a translation.
Because the EBMT system does not generate translations for
100% of the text it is given as input, a bilingual dictionary and
phrasal glossary are used to fill any gaps. Selection of a ?best?
translation is guided by a trigram model of the target language [6].
Supporting Chinese required a number of changes to the program
and training procedures; those changes are discussed in the next
section.
2. ENHANCEMENTS
The first change required of the translation software was sup-
port for the two-byte encoding used for the Chinese text (GB-2312,
?GB? for short). Further, the EBMT (as well as dictionary and glos-
sary) approaches are word-based, but Chinese is ordinarily writ-
ten without breaks between words. Thus, Chinese input must be
.
segmented into individual words. The initial baseline system used
the segmenter made available by the LDC. This segmenter uses a
word-frequency list to make segmentation decisions, but although
the list provided by the LDC is large, it did not completely cover
the vocabulary of the EBMT training corpus (described below). As
a result, many sentences had incorrect segmentations or included
long sequences which were not segmented at all or were broken
into single characters. Almost every Chinese character has at least
one meaning, and its meaning may be entirely different from the
meaning of the word containing it. The mis-segmenting of Chinese
words due to the inadequate dictionary makes it very hard to build
a statistical dictionary and properly index the EBMT corpus.
To improve the performance of the Chinese segmenter, we aug-
mented its word list by finding sequences of characters in the train-
ing corpus that belong together, based on their frequency and high
mutual information. We developed a form of term extraction to
find English phrases which should be treated as atomic units for
translation, thus increasing the average length of ?words? in both
source and target languages. Finally, we also created an augmented
bilingual dictionary for use in word-level alignment for EBMT by
applying statistical dictionary extraction techniques to the training
corpus.
As the improved segmenter and the term finder may be produc-
ing excessively long phrases or phrases which are impossible to
match in the other language, we repeat the procedure of segment-
ing/bracketing/dictionary-building several times. On each succes-
sive iteration, the segmenter and bracketer are limited to words and
phrases for which the statistical dictionary from the previous itera-
tion contains translations. Through this iteration, we increased the
size of the statistical dictionary from each step and guaranteed that
all Chinese words generated by the segmenter have translations in
the dictionary. This helps ensure that the EBMT engine can per-
form word-level alignments.
3. EXPERIMENTAL DESIGN
The primary purpose of this experiment was to determine the
effect of each enhancement by operating with various subsets of
the enhancements. Since it rapidly becomes impractical to test all
possible combinations, we opted for the following test conditions:
1. baseline: parallel corpus segmented with the LDC segmenter
and LDC dictionary/glossary
2. baseline plus improved segmenter
3. baseline plus improved segmenter and term finder
4. baseline plus improved segmenter and statistical dictionary
5. baseline plus improved segmenter, term finder, and statistical
dictionary
For training, we had available two parallel Chinese-English cor-
pora distributed by the LDC: the complete Hong Kong legal code
(after cleaning: 47.86 megabytes, 5.5 million English words, 9 mil-
lion Chinese characters) where 85% of the content (by sentence) is
unique, and a collection of Hong Kong news articles (after clean-
ing: 24.58 megabytes, 2.67 million English words, 4.5 million Chi-
nese characters). In addition, LDC distributes a bilingual dictio-
nary/phrasebook, which we also used.
To determine the effects of varying amounts of training data on
overall performance, we divided the bilingual training corpus into
ten nearly equal slices. Each test condition was then run ten times,
each time increasing the number of slices used for training the sys-
tem. After each training pass, the test sentences were translated and
the system?s performance evaluated automatically; selected points
were then manually evaluated for translation quality.
The automatic performance evaluation measured coverage of the
input and average phrase length. Coverage is the percentage of the
input text for which a translation is produced by a particular trans-
lation method (since the EBMT engine does not generally produce
hypotheses that cover every word of input), while average phrase
length is a crude indication of translation quality ? the longer the
phrase that is translated, the more context is incorporated and the
less likely it is that the wrong sense will be used in the translation or
that (for EBMT) the alignment will be incorrect. Since the dictio-
nary and glossary remain constant for a given test condition, only
the EBMT coverage will be presented.
Manual grading of the output was performed using a web-based
system with which the graders could assign one of three scores
(?Good?, ?OK?, ?Bad?) in each of two dimensions: grammatical
correctness and meaning preservation. This type of quality scoring
is commonly used in assessing translation quality, and is used by
other TIDES participants. Fifty-two test sentences were translated
for each of four points from the automated evaluation and these sets
of four alternatives presented to the graders. The four points chosen
were the baseline system with 100% of the training corpus, the full
system with 20% and 100% training, and the full system trained on
a corpus of Hong Kong news text (cross-domain); only four points
were selected due to the difficulty and expense of obtaining large
numbers of manual quality judgements.
To assess the performance of the system in a different domain,
as well as the effect of the trigram language model on the selec-
tion of translated fragments for the final translation, we obtained
manual judgements for 44 sentences on an additional four test con-
ditions, each trained with the entire available parallel text and tested
on Hong Kong news text rather than legal sentences. These points
were the cross-domain case (trained on the legal corpus) and three
different language models for within-domain training: an English
language model derived from the legal corpus, one derived from
the news corpus, and a pre-existing model generated from two gi-
gabytes of newswire and broadcast news transcriptions.
4. RESULTS
We discovered that there is a certain amount of synergy between
some of the improvements, particularly the term finder and statis-
tical dictionary extraction. Applying the term finder modifies the
parallel corpus in such a way that it becomes more difficult for
the EBMT engine to find matches which it can align, while adding
dictionary entries derived from the modified corpus eliminates that
effect. As a result, we will not present the performance results for
Test Condition 3 (improved segmenter plus term finder); further,
the data for Test Conditions 2 (improved segmenter only) and 4
(improved segmenter plus statistical dictionary) may not accurately
reflect the contribution of those two components to the full system
Translating Legal Code
System Baseline Full Full X-Dom
Training 100% 20% 100% 100%
Syntactic 42.31% 54.81% 61.06% 39.42%
Semantic 43.75% 61.54% 64.42% 34.62%
Translating Hong Kong News
Training News News News Legal
LangModel Legal News Prior Legal
Syntactic 45.67% 44.71% 47.60% 34.62%
Semantic 50.00% 50.96% 51.92% 47.12%
Figure 1: Judgements ? Acceptable Translations
used for Test Condition 5.
Figure 2 shows the proportion of the words in the test sentences
for which the EBMT engine was able to produce a translation,
while Figure 3 shows the average number of source-languagewords
per translated fragment. These curves do not increase monotoni-
cally because, for performance reasons, the EBMT engine does not
attempt to align every occurrence of a phrase, only theN (currently
12) most-recently added ones; as a result, adding more text to the
corpus can cause EBMT to ignore matches that successfully align
in favor of newer occurrences which it is unable to align.
Examining Figure 3, it is clear that the fifth slice (from 40 to
50%) is much more like the test data than other slices, resulting in
longer matches. In general, the closer training and test text are to
each other, the longer the phrases they have in common.
Figure 1 summarizes the results of human quality assessments.
The ?Good? and ?OK? judgements were combined into ?Accept-
able? and the the percentage of ?Acceptable? judgements was aver-
aged across sentences and graders. As hoped and expected, the im-
provements do in fact result not only in better coverage by EBMT,
but also in better quality assessments by the human graders. Fur-
ther, the results on Hong Kong news text show that the choice of
language model does have a definite effect on quality. These results
also confirm the adage that there is no such thing as too much train-
ing text for language modeling, since the model generated from the
EBMT corpus was unable to match the performance of the pre-
existing model generated from two orders of magnitude more text.
5. CONCLUSIONS AND FUTURE WORK
As seen in Figure 2, the enhancements described here cumula-
tively provide a 12% absolute improvement in coverage for EBMT
translations without requiring any additional knowledge resources.
Further, the enhanced coverage does, in fact, result in improved
translations, as verified by human judgements. We can also con-
clude that when we combine words into larger chunks on both sides
of the corpus, the possibility of finding larger matches between the
source language and the target language increases, which leads to
the improvement of the translation quality for EBMT.
We will do further research on the interaction between the im-
proved segmenter, term finder and statistical dictionary builder, uti-
lizing the information provided by the statistical dictionary as feed-
back for the segmenter and term finder to modify their results. We
are also investigating the effects of splitting the EBMT training into
multiple sets of topic-specific sentences, automatically separated
using clustering techniques.
The relatively low slope of the coverage curve also indicates that
the training corpus is sufficiently large. Our prior experience with
Spanish (using the UN Multilingual Corpus [5]) and French (using
00.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
0.55
0.6
0.65
0.7
0.75
0.8
0 10 20 30 40 50 60 70 80 90 100
Co
ve
ra
ge
 o
f E
BM
T
Percentage of corpus used for training (%)
Improved Segmenter, term finder, statDict
Improved Segmenter, statDict
Improved Segmenter
Baseline system
Trained on News tested On Legalcode
Figure 2: EBMT Coverage with Varying Training
the Hansard corpus [7]) was that the curve flattens out at between
two and three million words of training text, which appears also to
be the case for Chinese (each training slice contains approximately
one million words of total text).
We have not yet taken full advantage of the features of the EBMT
software. In particular, it supports equivalence classes that permit
generalization of the training text into templates for improved cov-
erage. We intend to test automatic creation of equivalence classes
from the training corpus [4] in conjunction with the other improve-
ments reported herein.
6. ACKNOWLEDGEMENTS
We would like to thank Alon Lavie and Lori Levin for their com-
ments on drafts of this paper.
7. REFERENCES
[1] R. D. Brown. Example-Based Machine Translation in the
PANGLOSS System. In Proceedings of the Sixteenth
International Conference on Computational Linguistics, pages
169?174, Copenhagen, Denmark, 1996.
http://www.cs.cmu.edu/?ralf/papers.html.
[2] R. D. Brown. Automated Dictionary Extraction for
?Knowledge-Free? Example-Based Translation. In
Proceedings of the Seventh International Conference on
Theoretical and Methodological Issues in Machine
Translation (TMI-97), pages 111?118, Santa Fe, New Mexico,
July 1997.
http://www.cs.cmu.edu/?ralf/papers.html.
[3] R. D. Brown. Adding Linguistic Knowledge to a Lexical
Example-Based Translation System. In Proceedings of the
Eighth International Conference on Theoretical and
Methodological Issues in Machine Translation (TMI-99),
pages 22?32, Chester, England, August 1999.
http://www.cs.cmu.edu/?ralf/papers.html.
[4] R. D. Brown. Automated Generalization of Translation
Examples. In Proceedings of the Eighteenth International
Conference on Computational Linguistics (COLING-2000),
pages 125?131, 2000.
[5] D. Graff and R. Finch. Multilingual Text Resources at the
Linguistic Data Consortium. In Proceedings of the 1994 ARPA
Human Language Technology Workshop. Morgan Kaufmann,
1994.
00.5
1
1.5
2
2.5
3
3.5
4
4.5
5
5.5
6
6.5
7
7.5
0 10 20 30 40 50 60 70 80 90 100
Av
er
ag
e 
ph
ra
se
 le
ng
th
 (w
ord
s)
Percentage of corpus used for training (%)
Improved Segmenter, term finder, statDict
Improved Segmenter, statDict
Improved Segmenter
Baseline system
Trained on News tested On Legalcode
Figure 3: Average EBMT Match Lengths
[6] C. Hogan and R. E. Frederking. An Evaluation of the
Multi-engine MT Architecture. In Machine Translation and
the Information Soup: Proceedings of the Third Conference of
the Association for Machine Translation in the Americas
(AMTA ?98), volume 1529 of Lecture Notes in Artificial
Intelligence, pages 113?123. Springer-Verlag, Berlin, October
1998.
[7] Linguistic Data Consortium. Hansard Corpus of Parallel
English and French. Linguistic Data Consortium, December
1997. http://www.ldc.upenn.edu/.
Towards Automatic Sign Translation
Jie Yang, Jiang Gao, Ying Zhang, Alex Waibel 
Interactive Systems Laboratory 
Carnegie Mellon University 
Pittsburgh, PA 15213 USA 
{yang+,jgao,joy,waibel}@cs.cmu.edu
ABSTRACT 
Signs are everywhere in our lives. They make our lives easier 
when we are familiar with them. But sometimes they also pose 
problems. For example, a tourist might not be able to understand 
signs in a foreign country. In this paper, we present our efforts 
towards automatic sign translation. We discuss methods for 
automatic sign detection. We describe sign translation using 
example based machine translation technology. We use a user-
centered approach in developing an automatic sign translation 
system. The approach takes advantage of human intelligence in 
selecting an area of interest and domain for translation if needed. 
A user can determine which sign is to be translated if multiple 
signs have been detected within the image. The selected part of 
the image is then processed, recognized, and translated. We have 
developed a prototype system that can recognize Chinese signs 
input from a video camera which is a common gadget for a tourist, 
and translate them into English text or voice stream. 
Keywords 
Sign, sign detection, sign recognition, sign translation. 
1. INTRODUCTION 
Languages play an important role in human communication. 
We communicate with people and information systems 
through diverse media in increasingly varied environments. 
One of those media is a sign. A sign is something that 
suggests the presence of a fact, condition, or quality. Signs 
are everywhere in our lives. They make our lives easier 
when we are familiar with them.  But sometimes they also 
pose problems. For example, a tourist might not be able to 
understand signs in a foreign country. Unfamiliar language 
and environment make it difficult for international tourists 
to read signs, take a taxi, order food, and understand the 
comments of passersby.  
At the Interactive Systems Lab of Carnegie Mellon 
University, we are developing technologies for tourist 
applications [12]. The systems are equipped with a unique 
combination of sensors and software. The hardware 
includes computers, GPS receivers, lapel microphones and 
earphones, video cameras and head-mounted displays. This 
combination enables a multimodal interface to take 
advantage of speech and gesture inputs to provide 
assistance for tourists. The software supports natural 
language processing, speech recognition, machine 
translation, handwriting recognition and multimodal fusion. 
A vision module is trained to locate and read written 
language, is able to adapt to new environments, and is able 
to interpret intentions offered by the user, such as a spoken 
clarification or pointing gesture.  
In this paper, we present our efforts towards automatic sign 
translation. A system capable of sign detection and 
translation would benefit three types of individuals: tourists, 
the visually handicapped and military intelligence.  Sign 
translation, in conjunction with spoken language 
translation, can help international tourists to overcome these 
barriers. Automatic sign recognition can help us to increase 
environmental awareness by effectively increasing our field 
of vision. It can also help blind people to extract 
information. A successful sign translation system relies on 
three key technologies: sign extraction, optical character 
recognition (OCR), and language translation. Although 
much research has been directed to automatic speech 
recognition, handwriting recognition, OCR, speech and text 
translation, little attention has been paid to automatic sign 
recognition and translation in the past. Our current research 
is focused on automatic sign detection and translation while 
taking advantage of OCR technology available. We have 
developed robust automatic sign detection algorithms. We 
have applied Example Based Machine Translation (EBMT) 
technology [1] in sign translation.  
Fully automatic extraction of signs from the environment is 
a challenging problem because signs are usually embedded 
in the environment. Sign translation has some special 
problems compared to a traditional language translation 
task. They can be location dependent. The same text on 
different signs can be treated differently. For example, it is 
not necessary to translate the meanings for names, such as 
street names or company names, in most cases. In the 
system development, we use a user-centered approach. The 
 
 
 
approach takes advantage of human intelligence in selecting 
an area of interest and domain for translation if needed. For 
example, a user can determine which sign is to be translated 
if multiple signs have been detected within the image. The 
selected part of the image is then processed, recognized, 
and translated, with the translation displayed on a hand-held 
wearable display, or a head mounted display, or synthesized 
as a voice output message over the earphones. By focusing 
only on the information of interest and providing domain 
knowledge, the approach provides a flexible method for 
sign translation. It can enhance the robustness of sign 
recognition and translation, and speed up the recognition 
and translation process. We have developed a prototype 
system that can recognize Chinese sign input from a video 
camera which is a common gadget for a tourist, and 
translate the signs into English text or voice stream.  
The organization of this paper is as follows: Section 2 
describes challenges in sign recognition and translation. 
Section 3 discusses methods for sign detection. Section 4 
addresses the application of EBMT technology into sign 
translation. Section 5 introduces a prototype system for 
Chinese sign translation. Section 6 gives experimental 
results. Section 7concludes the paper. 
2. PROBLEM DESCRIPTION  
A sign can be a displayed structure bearing letters or 
symbols, used to identify or advertise a place of business. It 
can also be a posted notice bearing a designation, direction, 
or command. Figure 1 and Figure 2 illustrate two examples 
of signs. Figure 1 shows a Russian sign completely 
embedded in the background. Figure 2 is a sign that 
contains German text with no verb and article. In this 
research, we are interested in translating signs that have 
direct influence upon a tourist from a different country or 
culture. These signs, at least, include the following 
categories: 
? Names: street, building, company, etc. 
? Information: designation, direction, safety 
advisory, warning, notice, etc. 
? Commercial: announcement, advertisement, etc. 
? Traffic: warning, limitation, etc. 
? Conventional symbol: especially those are 
confusable to a foreign tourist, e.g., some symbols 
are not international. 
Fully automatic extraction of signs from the environment is 
a challenging problem because signs are usually embedded 
in the environment. The related work includes video OCR 
and automatic text detection. Video OCR is used to capture 
text in the video images and recognize the text.  Many 
video images contain text contents. Such text can come 
from computer-generated text that is overlaid on the 
imagery (e.g., captions in broadcast news programs) or text 
that appears as a part of the video scene itself (e.g., a sign 
outside a place of business, or a post). Location and 
recognition of text in video imagery is challenging due to 
low resolution of characters and complexity of background. 
Research in video OCR has mainly focused on locating the 
text in the image and preprocessing the text area for OCR 
[4][6][7][9][10]. Applications of the research include 
automatically identifying the contents of video imagery for 
video index [7][9], and capturing documents from paper 
source during reading and writing [10]. Compared to other 
video OCR tasks, sign extraction takes place in a more 
dynamic environment. The user?s movement can cause 
unstable input images. Non-professional equipment can 
make the video input poorer than that of other video OCR 
tasks, such as detecting captions in broadcast news 
programs. In addition, sign extraction has to be 
implemented in real time using limited resources. 
 
Figure 1 A sign embedded in the background 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 2 A German sign 
Sign translation requires sign recognition. A straightforward 
idea is to use advanced OCR technology. Although OCR 
technology works well in many applications, it requires 
some improvements before it can be applied to sign 
recognition. At current stage of the research, we will focus 
our research on sign detection and translation while taking 
advantage of state-of-the-art OCR technologies. 
Sign translation has some special problems compared to a 
traditional language translation task. The function of signs 
lead to the characteristic of the text used in the sign: it has 
to be short and concise. The lexical mismatch and structural 
mismatch problems become more severe in sign translation 
because shorter words/phrases are more likely to be 
ambiguous and insufficient information from the text to 
resolve the ambiguities which are related to the 
environment of the sign.  
We assume that a tourist has a video camera to capture 
signs into a wearable or portable computer. The procedure 
of sign translation is as follows: capturing the image with 
signs, detecting signs in the image, recognizing signs, and 
translating results of sign recognition into target language.  
3. AUTOMATIC SIGN DETECTION  
Fully automatic extraction of signs from the environment is 
very difficult, because signs are usually embedded in the 
environment. There are many challenges in sign detection, 
such as variation, motion and occlusion. We have no 
control in font, size, orientation, and position of sign texts. 
Originating in 3-D space, text on signs in scene images can 
be distorted by slant, tilt, and shape of objects on which 
they are found [8]. In addition to the horizontal left-to-right 
orientation, other orientations include vertical, circularly 
wrapped around another object, slanted, sometimes with the 
characters tapering (as in a sign angled away from the 
camera), and even mixed orientations within the same text 
area (as would be found on text on a T-shirt or wrinkled 
sign). Unlike other text detection and video OCR tasks, sign 
extraction is in a more dynamic environment. The user?s 
movement can cause unstable input images. Furthermore, 
the quality of the video input is poorer than that of other 
video OCR tasks, such as detecting captions in broadcast 
news programs, because of low quality of equipment. 
Moreover, sign detection has to be real-time using a limited 
resource. Though automatic sign detection is a difficult 
task, it is crucial for a sign translation system.  
We use a hierarchical approach to address these challenges. 
We detect signs at three different levels. At the first level, 
the system performs coarse detection by extracting features 
from edges, textures, colors/intensities. The system 
emphasizes robust detection at this level and tries to 
effectively deal with the different conditions such as 
lighting, noise, and low resolution. A multi-resolution 
detection algorithm is used to compensate different lighting 
and low contrasts. The algorithm provides hypotheses of 
sign regions for a variety of scenes with large variations in 
both lighting condition and contrast. At the second level, 
the system refines the initial detection by employing various 
adaptive algorithms. The system focuses on each detected 
area and makes elaborate analysis to guarantee reliable and 
complete detection. In most cases, the adaptive algorithms 
can lead to finding the regions without missing any sign 
region. At the third level, the system performs layout 
analysis based on the outcome from the previous levels. 
The design and layout of signs are language and culture 
dependent. For example, many Asia languages, such as 
Chinese and Japanese, have two types of layout: the 
horizontal and the vertical. The system provides 
considerable flexibility to allow the detection of slanted 
signs and signs with non-uniform character sizes.  
4. SIGN TRANSLATION  
Sign translation has some special problems compared to a 
traditional language translation task. Sign translation 
depends not only on domain but also on functionality of the 
sign. The same text on different signs can be treated 
differently. In general, the text used in the sign is short and 
concise. For example, the average length of each sign in our 
Chinese sign database is 6.02 Chinese characters. The 
lexical mismatch and structural mismatch problems become 
more severe for sign translation because shorter 
words/phrases are more likely to be ambiguous and there 
isn?t sufficient information from the text to resolve the 
ambiguities which are related to the environment of the 
sign. For example, in order to make signs short, 
abbreviations are widely used in signs, e.g.,  (/ji 
yan suo/) is the abbreviation for ,(/ji 
sheng chong yan jiu suo/ institute of parasites), such 
abbreviations are difficult, if not impossible, even for a 
human to understand without knowledge of the context of 
the sign. Since designers of signs always assume that 
readers can use the information from other sources to 
understand the meaning of the sign, they tend to use short 
words. e.g.  in sign (/man xing/, drive slowly), the 
word (/xing/, walk, drive) is ambiguous, it can mean 
  (/xing zou/ ?move of human,? walk) or  
?move of a car,? drive). The human reader can understand 
the meaning if he knows it is a traffic sign for cars, but 
without this information, MT system cannot select the 
correct translation for this word. Another problem in sign is 
structural mismatch. Although this is one of the basic 
problems for all MT systems, it is more serious in sign 
translation: some grammatical functions are omitted to 
make signs concise. Examples include: (1) the subject ?we? 
is omitted in (/li mao dai ke/, treat customers 
politely); (2) the sentence is reordered to emphasize the 
topic: rather than saying 
(/qing jiang bao zhuang zhi 
tou ru la ji xiang/, please throw wrapping paper into the 
garbage can), using (/bao 
zhuang zhi qing tou ru la ji xiang/, wrapping paper, please 
throw it into the garbage can) to highlight the ?wrapping 
paper.? With these special features, sign translation is not a 
trivial problem of just using existing MT technologies to 
translate the text recognized by OCR module.  
 
Although a knowledge-based MT system works well with 
grammatical sentences, it requires a great amount of human 
effort to construct its knowledge base, and it is difficult for 
such a system to handle ungrammatical text that appears 
frequently in signs.  
We can use a database search method to deal with names, 
phrases, and symbols related to tourists. Names are usually 
location dependent, but they can be easily obtained from 
many information sources such as maps and phone books. 
Phrases and symbols related to tourists are relative fixed for 
a certain country. The database of phrases and symbols is 
relatively stable once it is built 
We propose to apply Generalized Example Based Machine 
Translation (GEBMT) [1][2] enhanced with domain 
detection to a sign translation task. This is a data-driven 
approach. What EBMT needs are a set of bilingual corpora 
each for one domain and a bilingual dictionary where the 
latter can be constructed statistically from the corpora. 
Matched from the corpus, EBMT can give the same style of 
translations as the corpus. The domain detection can be 
achieved from other sources. For example, shape/color of 
the sign and semantics of the text can be used to choose the 
domain of the sign. 
We will start with the EBMT software [1]. The system will 
be used as a shallow system that can function using nothing 
more than sentence-aligned plain text and a bilingual 
dictionary; and given sufficient parallel text, the dictionary 
can be extracted statistically from the corpus.  In a 
translation process, the system looks up all matching 
phrases in the source-language half of the parallel corpus 
and performs a word-level alignment on the entries 
containing matches to determine a (usually partial) 
translation. Portions of the input for which there are no 
matches in the corpus do not generate a translation. 
Because the EBMT system does not generate translations 
for 100% of its input text, a bilingual dictionary and phrasal 
glossary are used to fill any gaps.  Selection of the ?best? 
translation is guided by a trigram model of the target 
language and a chart table [3]. 
5. A PROTOTYPE SYSTEM  
We have developed a prototype system for Chinese sign 
recognition and translation. Figure 3 shows the architecture 
of the prototype system. A user can interactively involve 
sign recognition and translation process when needed. For 
example, a user can select the area of interest, or indicate 
that the sign is a street name. The system works as follows. 
The system captures the sign in a natural background using 
a video camera. The system then automatically detects or 
interactively selects the sign region. The system performs 
sign recognition and translation within the detected/selected 
region. It first preprocesses the selected region, binarizes 
the image to get text or symbol, and feeds the binary image 
into the sign recognizer. OCR software from a third party is 
used for text recognition. The recognized text is then 
translated into English. The output of the translation is fed 
to the user by display on screen or synthesized speech. 
Festival, a general purpose multi-lingual text-to-speech 
(TTS) system is used for speech synthesis.  
 
 
 
Figure 3 Architecture of the prototype system 
 
 
 
Figure 4  The interface of the prototype system 
An efficient user interface is important to a user-centered 
system. Use of interaction is not only necessary for an 
interactive system, but also useful for an automatic system. 
A user can select a sign from multiple detected signs for 
translation, and get involved when automatic sign detection 
is wrong. Figure 4 is the interface of the system. The 
window of the interface displays the image from a video 
camera. The translation result is overlaid on the location of 
the sign. A user can select the sign text using pen or mouse 
anywhere in the window. 
6. EXPERIMENTAL RESULTS  
We have evaluated the prototype system for automatic sign 
detection and translation. We have built a Chinese sign 
database with about 800 images taken from China and 
Singapore. We have tested the automatic detection module 
using 50 images randomly selected from the database. 
Table 1 shows the test result of automatic sign detection. 
Figure 5 and Figure 6 show examples of automatic sign 
detection with white rectangles indicating the sign regions. 
Figure 5 shows correct detection after layout analysis. 
Figure 6 illustrates a result with a false detection (Note the 
small detection box below and to the left of the larger 
detection).  
 
Table 1 Test Results of Automatic Detection on 50 
Chinese Signs 
Detection 
without missing 
characters 
Detection 
with false 
alarm 
Detection with 
missing characters 
43 12 5 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 5 An example of automatic sign detection 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 6 An example of false detection 
 
Figure 7 illustrates two difficult examples of sign detection. 
The text in Figure 7(a) is easily confused with the reflective 
background. The sign in Figure 7(b) is embedded in the 
background  
 
 
 
 
 
 
 
 
 
                     (a)                                                (b) 
Figure 7 Difficult examples of sign detection 
 
We have also tested the EBMT based method. We assume 
perfect sign recognition in our test. We randomly selected 
50 signs from our database. We first tested the system 
includes a Chinese-English dictionary from the Linguistic 
Data Consortium, and a statistical dictionary built from the 
HKLC (Hong Kong Legal Code) corpus. As a result, we 
only got about 30% reasonable translations. We then 
trained with a small corpus of 670 pairs of bilingual 
sentences [7], The accuracy is improved from 30% to 52% 
on 50 test signs. Some examples of errors are illustrated 
below: 
Mis-segmentaion: 
Chinese with wrong segmentation: 
  
/ge zhong che liang qing rao xing/ 
Translation from MT: 
 All vehicles are please wind profession  
Correct segmentation: 
   
Translation if segmentation is correct: 
 All vehicles please use detour 
Lack-domain information: 
Chinese with segmentation: 
  
 /qing wu dong shou/ 
 Please don?t touch it 
Translation from MT: 
 Please do not get to work 
Domain knowledge needed to translate : 
?start to work? in domain such as work plan and 
?don?t touch? in domains like tourism, exhibition 
etc. 
Proper Name: 
Chinese with segmentation: 
  
 /bei jing tong ren yi yuan/ 
 Beijing Tongren Hospital 
Translation from MT: 
 Beijing similar humane hospital 
is translated to the meaning of each 
character because it is not identified as a proper 
name which then should only be represented by its 
pronunciation. 
Figure 8 illustrates error analysis of the translation module. 
It is interesting to note that 40% of errors come from mis-
segmentation of words. There is a big room for 
improvement in proper word segmentation.  In addition, we 
can take advantage of the contextual information provided 
by the OCR module to further improve the translation 
quality.  
Error source
41.11%
31.11%
10.00%
14.44%
3.33%
Mis-segmentation
Lack domain knowledge
Mis-detection of proper
name
Corpus/dict not large enough
Other
 
Figure 8 Error analysis of the translation module 
7. CONCLUSION 
We have reported progress on automatic sign translation in 
this paper. Sign translation, in conjunction with spoken 
language translation, can help international tourists to 
overcome language barriers. A successful sign translation 
system relies on three key technologies: sign extraction, 
OCR, and language translation. We have developed 
algorithms for robust sign detection. We have applied 
EBMT technology for sign translation. We have employed 
a user-centered approach in developing an automatic sign 
translation system. The approach takes advantage of human 
intelligence in selecting an area of interest and domain for 
translation if needed. We have developed a prototype 
system that can recognize Chinese signs input from a video 
camera which is a common gadget for a tourist, and 
translate them into English text or voice stream. 
ACKNOWLEDGMENTS 
We would like to thank Dr. Ralf Brown and Dr. Robert 
Frederking for providing initial EBMT software and 
William Kunz for developing the interface for the prototype 
system. We would also like to thank other members in the 
Interactive Systems Labs for their inspiring discussions and 
support. This research is partially supported by DARPA 
under TIDES project. 
 
REFERENCES 
[1] R.D. Brown. Example-based machine translation in the 
pangloss system. Proceedings of the 16th International 
Conference on Computational Linguistics, pp. 169-
174, 1996. 
[2] R.D. Brown. Automated generalization of translation 
examples". In Proceedings of the Eighteenth 
International Conference on Computational Linguistics 
(COLING-2000), p. 125-131. Saarbr?cken, Germany, 
August 2000. 
[3] C. Hogan and R.E. Frederking. An evaluation of the 
multi-engine MT architecture. Machine Translation 
and the Information Soup: Proceedings of the Third 
Conference of the Association for Machine Translation 
in the Americas (AMTA ?98), vol. 1529 of Lecture 
Notes in Artificial Intelligence, pp. 113-123. Springer-
Verlag, Berlin, October. 
[4] A.K. Jain and B. Yu. Automatic text location in images 
and video frames. Pattern Recognition, vol. 31, no. 12, 
pp. 2055--2076, 1998. 
[5] C. C. Kubler. "Read Chinese Signs". Published by 
Chheng & Tsui Company, 1993. 
[6] H. Li and D. Doermann, Automatic Identification of 
Text in Digital Video Key Frames, Proceedings of 
IEEE International Conference of Pattern Recognition, 
pp. 129-132, 1998. 
[7] R. Lienhart, Automatic Text Recognition for Video 
Indexing, Proceedings of ACM Multimedia 96, pp. 11-
20, 1996. 
[8] J. Ohya, A. Shio, and S. Akamatsu. Recognition 
characters in scene images. IEEE Transactions on 
Pattern Analysis and Machine Intelligence, vol. 16, no. 
2, pp. 214--220, 1994. 
[9] T. Sato, T. Kanade, E.K. Hughes, and M.A. Smith. 
Video ocr for digital news archives. IEEE Int. 
Workshop on Content-Based Access of Image and 
Video Database, 1998. 
[10] M.J. Taylor, A. Zappala, W.M. Newman, and C.R. 
Dance, Documents through cameras, Image and Vision 
Computing, vol. 17, no. 11, pp. 831-844, 1999. 
[11] V. Wu, R. Manmatha, and E.M. Riseman, Textfinder: 
an automatic system to detect and recognize text in 
images. IEEE Transactions on Pattern Analysis and 
Machine Intelligence, vol. 21, no. 11, pp. 1224-1229, 
1999. 
[12] J. Yang, W. Yang, M. Denecke, and A. Waibel. Smart 
sight: a tourist assistant system.  Proceedings of Third 
International Symposium on Wearable Computers, pp. 
73--78. 1999. 
 
Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language
Processing (HLT/EMNLP), pages 483?490, Vancouver, October 2005. c?2005 Association for Computational Linguistics
Mining Key Phrase Translations from Web Corpora 
 
Fei Huang       Ying Zhang       Stephan Vogel 
 
School of Computer Science 
Carnegie Mellon University, Pittsburgh, PA 15213 
{fhuang, joy, vogel}@cs.cmu.edu 
 
 
Abstract 
Key phrases are usually among the most 
information-bearing linguistic structures. 
Translating them correctly will improve 
many natural language processing appli-
cations. We propose a new framework to 
mine key phrase translations from web 
corpora. We submit a source phrase to a 
search engine as a query, then expand 
queries by adding the translations of 
topic-relevant hint words from the re-
turned snippets. We retrieve mixed-
language web pages based on the ex-
panded queries.  Finally, we extract the 
key phrase translation from the second-
round returned web page snippets with 
phonetic, semantic and frequency-
distance features. We achieve 46% phrase 
translation accuracy when using top 10 re-
turned snippets, and 80% accuracy with 
165 snippets. Both results are signifi-
cantly better than several existing meth-
ods. 
1 Introduction 
Key phrases such as named entities (person, loca-
tion and organization names), book and movie ti-
tles, science, medical or military terms and others 
1, are usually among the most information-bearing 
linguistic structures. Translating them correctly 
will improve the performance of cross-lingual in-
formation retrieval, question answering and ma-
chine translation systems. However, these key 
phrases are often domain-specific, and people con-
                                                                                                                    
1 Some name and terminology is a single word, which could 
be regarded as a one-word phrase. 
stantly create new key phrases which are not cov-
ered by existing bilingual dictionaries or parallel 
corpora, therefore standard data-driven or knowl-
edge-based machine translation systems cannot 
translate them correctly. 
 As an increasing amount of web information be-
comes available, exploiting such a huge informa-
tion resource is becoming more attractive. (Resnik 
1999) searched the web for parallel corpora while 
(Lu et al 2002) extracted translation pairs from 
anchor texts pointing to the same webpage. How-
ever, parallel webpages or anchor texts are quite 
limited, and these approaches greatly suffer from 
the lack of data.  
However, there are many web pages containing 
useful bilingual information where key phrases and 
their translations both occur. See the example in 
Figure 1. This example demonstrates web page 
snippets2 containing both a Chinese key phrase ??
??? and its translation, ?Faust?. 
We thus can transform the translation problem 
into a data mining problem by retrieving these 
mixed-language web pages and extracting their 
translations. We propose a new framework to mine 
key phrase translations from web corpora. Given a 
source key phrase (here a Chinese phrase), we first 
retrieve web page snippets containing this phrase 
using the Google search engine. We then expand 
queries by adding the translations of topic-relevant 
hint words from the returned snippets. We submit 
the source key phrase and expanded queries again 
to Google to retrieve mixed-language web page 
snippets.  Finally, we extract the key phrase trans-
lation from the second-round returned snippets 
with phonetic, semantic and frequency-distance 
features.  
2A snippet is a sentence or paragraph containing the key 
phrase, returned with the web page URLs. 
483
  
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1. Returned mixed-language web page snip-
pets using source query 
 
We achieve 46% phrase translation accuracy 
when using 10 returned snippets, and 80% accu-
racy with 165 snippets. Both results are signifi-
cantly better than several existing methods. 
   The reminder of this paper is organized as fol-
lows: cross-lingual query expansion is discussed in 
section 2; key phrase translation extraction is ad-
dressed in section 3. In section 4 we present ex-
perimental results, which is followed by relevant 
works and conclusions. 
2 Retrieving Web Page Snippets through 
Cross-lingual Query Expansion 
For a Chinese key phrase f, we want to find its 
translation e from the web, more specifically, from 
the mixed-language web pages or web page snip-
pets containing both f and e. As we do not know e, 
we are unable to directly retrieve such mixed-
language web page using (f,e) as the query.   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 2. Returned mixed-language web page snip-
pets using cross-lingual query expansion 
However, we observed that when the author of a 
web page lists both f and e in a page, it is very 
likely that f' and e' are listed in the same page, 
where f? is a Chinese hint word topically relevant 
to f, and e? is f?s translation. Therefore if we know 
a Chinese hint word f?, and we know its reliable 
translation, e?, we can send (f, e?) as a query to re-
trieve mixed language web pages containing (f, e).    
For example, to find web pages which contain 
translations of ?????(Faust), we expand the 
query to ????+goethe? since ???? (Goethe) 
is the author of ?????(Faust). Figure 2 illus-
trates retrieved web page snippets with expanded 
queries. We find that newly returned snippets con-
tain more correct translations with higher ranks. 
   To propose a ?good? English hint e' for f, first we 
need to find a Chinese hint word f' that is relevant 
to f. Because f is often an OOV word, it is unlikely 
that such information can be obtained from exist-
ing Chinese monolingual corpora. Instead, we 
484
query Google for web pages containing f. From the 
returned snippets we select Chinese words f' based 
on the following criteria: 
 
1. f' should be relevant to f based on the co-
occurrence frequency. On average, 300 
Chinese words are returned for each query 
f. We only consider those words that occur 
at least twice to be relevant. 
2. f' can be reliably translated given the cur-
rent bilingual resources (e.g. the LDC 
Chinese-English lexicon 3  with 81,945 
translation entries). 
3. The meaning of f' should not be too am-
biguous. Words with many translations 
are not used. 
4. f' should be translated into noun or noun 
phrases. Given the fact that most OOV 
words are noun or noun phrases, we ig-
nore those source words which are trans-
lated into other part-of-speech words. The 
British National Corpus4 is used to gener-
ate the English noun lists. 
 
For each f, the top Chinese words f' with the 
highest frequency are selected. Their correspond-
ing translations are then used as the cross-lingual 
hint words for f. For example, for OOV word f = 
??? (Faust), the top candidate f's are ???
(Goethe)?, ? ?? (introduction)?, ???
(literature)? and ???(tragedy)?. We expand 
the original query ????? to ???? + 
goethe?, ???? + introduction?, ???? + lit-
erature?, ???? + tragic?, and then query Google 
again for web page snippets containing the correct 
translation ?Faust?. 
3 Extracting Key Phrase Translation 
When the Chinese key phrase and its English hint 
words are sent to Google as the query, returned 
web page snippets contain the source query and 
possibly its translation. We preprocess the snippets 
to remove irrelevant information. The preprocess-
ing steps are: 
1. Filter out HTML tags; 
                                                          
3http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?catalogI
d=LDC2002L27 
4 http://www.natcorp.ox.ac.uk/ 
2. Convert HTML special characters (e.g., 
?&lt?) to corresponding ASCII code (?>?); 
3. Segment Chinese words based on a maxi-
mum string matching algorithm, which is 
used to calculate the translation probability 
between a Chinese key phrase and an Eng-
lish translation candidate. 
4. Replace punctuation marks with phrase sepa-
rator ?|?; 
5. Replace non-query Chinese words with 
placeholder mark ?+?, as they indicate the 
distance between an English phrase and the 
Chinese key phrase. 
For example, the snippet  
? <b>???? </b>? (the bridges of 
madison county)[review]. ????anjing | 
?????2004-01-25 ??? 02:13 | ?
????? 
is converted into 
| <b> ?  ?  ?  ? </b> | 
the_bridges_of_Madison_county | review | 
++ + | anjing | ++ ++  | 2004-01-25 +++ 02 
13 | + + ++ ++, 
where ?<b>? and ?</b>? mark the start and end 
positions of the Chinese key phrase. The candidate 
English phrases, ?the bridges of madison county?, 
?review? and ?anjing?, will be aligned to the 
source key phrase according to a combined feature 
set using a transliteration model which captures the 
pronunciation similarity, a translation model which 
captures the semantic similarity and a frequency-
distance model reflecting their relevancy. These 
models are described below. 
3.1 Transliteration Model 
The transliteration model captures the phonetic 
similarity between a Chinese phrase and an Eng-
lish translation candidate via string alignment. 
Many key phrases are person and location names, 
which are phonetically translated and whose writ-
ten forms resemble their pronunciations. Therefore 
it is possible to discover these translation pairs 
through their surface strings. Surface string trans-
literation does not need a pronunciation lexicon to 
map words into phoneme sequences; thus it is es-
pecially appealing for OOV word translation. For 
non-Latin languages like Chinese, a romanization 
485
script called ?pinyin? maps each Chinese character 
into Latin letter strings. This normalization makes 
the string alignment possible. 
     We adopt the transliteration model proposed in 
(Huang, et al 2003). This model calculates the 
probabilistic Levinstein distance between a roman-
ized source string and a target string. Unlike the 
traditional Levinstein distance calculation, the 
character alignment cost is not binary (0/1); rather 
it is the logarithm of character alignment probabil-
ity, which ensures that characters with similar pro-
nunciations (e.g. `p` and `b`) have higher 
alignment probabilities and lower cost. These 
probabilities are automatically learned from bilin-
gual name lists using EM. 
Assume the Chinese phrase f has J Chinese 
characters, , and the English candidate 
phrase e has L English words, . The 
transliteration cost between a Chinese query and 
an English translation candidate  is calculated as: 
Jfff ,..., 21
Leee ,...,, 21
f
e
 
 
where is the pinyin of Chinese character ,  
is the i th letter in , and and are their 
aligned English letters, respectively.  
is the letter transliteration probability. The translit-
eration costs between a Chinese phrase and an 
English phrase is approximated by the sum of their 
letter transliteration cost along the optimal align-
ment path, which is identified based on dynamic 
programming.   
jy jf
ijy , jy jae ),( ijae
)|( ,),( jiji yep
3.2 Translation Model 
The translation model measures the semantic 
equivalence between a Chinese phrase and an Eng-
lish candidate. One widely used model is the IBM 
model (Brown et al 1993). The phrase translation 
probability is computed using the IBM model-1 as: 
  
 
 
where is the lexical translation probabili-
ties, which can be calculated according to the IBM 
models. This alignment model is asymmetric, as 
one source word can only be aligned to one target 
word, while one target word can be aligned to mul-
tiple source words. We estimate both  
and , and define the NE translation 
cost as: 
)|( lj efp
)|( efPtrans
)|( fePtrans
).|(log)|(log),( efPfePfeC transtranstrans +=
3.3 Frequency-Distance Model 
The more often a bilingual phrase pair co-occurs, 
or the closer a bilingual phrase pair is within a 
snippet, the more likely they are translations of 
each other. The frequency-distance model meas-
ures this correlation.  
   Suppose S is the set of returned snippets for 
query , and a single returned snippet isf Ssi ? . 
The source phrase occurs in si as  ( since f 
may occur several times in a snippet). The fre-
quency-distance weight of an English candidate 
is  
jif , 1?j
e
??=
i jis f ji efd
ew
,
),(
1
)(
,
 
 
.)|(log)|(log),( ,),(??? =?
j i
jia
j
jatrl yepyepfe where is the distance between phrase   
and e, i.e., how many words are there between the 
two phrases (the separator `|` is not counted).  
),( efd jif ,
3.4 Feature Combination 
Define the confidence measure for the translitera-
tion model as: 
 
 
where e and e? are English candidate phrases, and 
m is the weight of the distance model. We empiri-
cally choose m=2 in our experiments. This 
measure indicates how good the English phrase e is 
compared with other candidates based on translit-
eration model. Similarly the translation model con-
fidence measure is defined as: 
 
 
 
 
   The overall feature cost is the linear combination 
of transliteration cost and translation cost, which 
are weighted by their confidence scores respec-
tively: 
 
 
C
jij
,
)'()],'(exp[
)()],(exp[
)|(
'
?=
e
m
trl
m
trl
trl ewfeC
ewfeC
fe?
.
)'()],'(exp[
)()],(exp[
)|(
'
?=
e
m
trans
m
trans
trans ewfeC
ewfeC
fe???
= =
=
J
j
L
l
ljJtrans efpL
efP
1 1
)|(
1
)|(
486
 ???? the Bridges of Madison-
County                                                                                   
where the linear combination weight ?  is chosen 
empirically. While trl? and trans?  represent the rela-
tive rank of the current candidate among all com-
pared candidates, C and  indicate its 
absolute likelihood, which is useful to reject the 
top 1 incorrect candidate if the true translation does 
not occur in any returned snippets.  
trl transC
                                                          
4 Experiments 
We evaluated our approach by translating a set of 
key phrases from different domains. We selected 
310 Chinese key phrases from 12 domains as the 
test set, which were almost equally distributed 
within these domains. We also manually translated 
them as the reference translations. Table 1 shows 
some typical phrases and their translations, where 
one may find that correct key phrase translations 
need both phonetic transliterations and semantic 
translations. We evaluated inclusion rate, defined 
as the percentage of correct key phrase translations 
which can be retrieved in the returned snippets; 
alignment accuracy, defined as the percentage of 
key phrase translations which can be correctly 
aligned given that these translations are included in 
the snippets; and overall translation accuracy, de-
fined as the percentage of key phrases which can 
be translated correctly. We compared our approach 
with the LiveTrans5 (Cheng et.al. 2004) system, an 
unknown word translator using web corpora, and 
we observed better translation performance using 
our approach. 
4.1 Query Translation Inclusion Rate 
In the first round query search, for each Chinese 
key phrase f, on average 13 unique snippets were 
returned to identify relevant Chinese hint words f?, 
and the top 5 f's were selected to generate hint 
words e?s. In the second round f and e?s were sent 
to Google again to retrieve mixed language snip-
pets, which were used to extract e, the correct 
translation of f. 
Figure 3 shows the inclusion rate vs. the number 
of snippets used for three mixed-language web 
page searching strategies: 
                                                          
5 http://livetrans.iis.sinica.edu.tw/lt.html 
 Table 1. Test set key phrases 
? Search any web pages containing f (Zhang 
and Vines 2004); 
? Only search English web pages6 contain-
ing f (Cheng et al 2004); 
? Search any web pages containing f and 
hint words e?, as proposed in this paper.  
 
   The first search strategy resulted in a relatively 
low inclusion rate; the second achieved a much 
higher inclusion rate. However, because such Eng-
lish pages were limited, and on average only 45 
unique snippets could be found for each f, which 
resulted in a maximum inclusion rate of 85.8%. In 
the case of the cross-lingual query expansion, the 
search space was much larger but more focused 
and we achieved a high inclusion rate of 89.7% 
using 32 mixed-language snippets and 95.2% using 
165 snippets, both from the second round retrieval.  
6 These web pages are labeled by Google as ?English? web 
pages, though they may contain non-English characters. 
Movie Title 
????            Forrest Gump 
Book Title 
???   Dream of the Red Mansion 
???    La Dame aux camellias 
Organization 
Name 
????   University of Notre Dame  
??????????? David and 
Lucile Packard Foundation  
Person 
Name 
???          Ludwig Van Beethoven 
????? Audrey Hepburn 
Location 
Name 
????? Kamchatka 
??????? Taklamakan desert 
Company /
Brand 
???? Lufthansa German 
Airlines 
???? Estee Lauder 
Sci&Tech 
Terms 
???? genetic algorithm 
???? speech recognition  
Specie Term 
??               Aegypius monachus 
???              Manispentadactyla 
Military 
Term 
???              Aegis  
???              Phalcon 
Medical 
Term 
?????? SARS 
???? Arteriosclerosis 
Music Term 
????     Bird-call in the Mountain 
???        Bassoon 
Sports Term 
?????? Houston Rockets 
?????? Tour de France 
)]()|()( ff?? exp[1
)],(exp[)|(),(
eCe
feCfefeC
transtrans
trltrl= ?? +
,?
487
Table 2. Alignment accuracies using different features 
 
These search strategies are further discussed in the 
section 5. 
4.2 Translation Alignment Accuracy 
We evaluated our key phrase extraction model by 
testing queries whose correct translations were in-
cluded in the returned snippets. We used different 
feature combinations on differently sized snippets 
to compare their alignment accuracies. Table 2 
shows the result. Here ?Trl? means using the trans-
literation model, ?Trans? means using the transla-
tion model, and ?Fq-dis? means using Frequency-
Distance model. The frequency-distance model 
seemed to be the strongest single model in both 
cases (with and without hint words), while incor-
porating phonetic and semantic features provided 
additional strength to the overall performance. 
Combining all three features together yielded the 
best accuracy. Note that when more candidate 
translations were available through query expan-
sion, the alignment accuracy improved by 30% 
relative due to the frequency-distance model. 
However, using transliteration and/or translation 
models alone decreased performance because of 
more incorrect translation candidates from returned 
snippets. After incorporating the frequency-
distance model, correct translations have the 
maximum frequency-distance weights and are 
more likely to be selected as the top hypothesis. 
Therefore the combined model obtained the high-
est translation accuracy. 
4.3 Overall Translation Quality  
The overall translation qualities are listed in Table 
3, where we showed the translation accuracies of  
 
No Hints 
(Inc = 44.19%) 
With Hints 
(Inc = 95.16%) 
Table 3. Overall translation accuracy 
the top 5 hypotheses using different number of 
snippets. A hypothesized translation was consid-
ered to be correct when it matched one of the ref-
erence translations.  Using more snippets always 
increased the overall translation accuracy, and with 
all the 165 snippets (on average per query), our 
approach achieved 80% top-1 translation accuracy, 
and 90% top-5 accuracy. 
We compared the translations from a research 
statistical machine translation system (CMU-SMT, 
Vogel et al 2003) and a web-based MT engine 
(BabelFish). Due to the lack of topic-relevant con-
texts and many OOV words occurring in the source 
key phrases, their results were not satisfactory. We 
also compare our system with LiveTrans, which 
only searched within English web pages, thus with 
limited search space and more noises (incorrect 
English candidates). Therefore it was more diffi-
cult to select the correct translation. Table 4 lists 
some example key phrase translations mined from 
web corpora, as well as translations from the Ba-
belFish.  
5 Relevant Work 
Both (Cheng et al 2004) and (Zhang and Vines 
2004) exploited web corpora for translating OOV 
terms and queries. Compared with their work, our 
proposed method differs in both webpage search 
                                                          
7 http://babelfish.altavista.com/ 
Features (avg. snippets = 
10) 
(avg. snip-
pets=130) 
Trl 51.45 17.97 
Trans 51.45 40.68 
Fq-dis 53.62 73.22 
Trl+Trans 63.04 51.36 
Trl+Trans+ 
Fq-dis 65.94 86.73 
Accuracy of the Top-N Hyp. (%) Snippets 
Used Top1 Top2 Top3 Top4 Top5 
10 46.1 55.2 59.0 61.3 62.3 
20 57.4 64.2 69.7 72.6 72.9 
50 63.2 74.5 77.7 79.7 80.6 
100 75.2 84.5 85.8 87.4 87.4 
165 80.0 86.5 89.0 90.0 90.0 
Babel-
Fish7 MT 31.3 N/A N/A N/A N/A 
CMU-
SMT 21.9 N/A N/A N/A N/A 
LiveTrans
(Fast) 20.6 30.0 36.8 41.9 45.2 
LiveTrans
(Smart) 30.0 41.9 48.7 51.0 52.9 
488
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
Figure 3. Inclusion rate vs. the number of snippets used 
 
Examples Category 
Chinese Key Phrase Web-Mining Translation BabelFish? Result 
Movie  
Title ???? 
the Bridges of Madison 
County 
*Love has gone and only good 
memory has left in the dream 
Book  
Title ????? Sense and Sensibility *Reason and emotion 
Organization 
Name 
Woodrow Wilson National 
Fellowship Foundation 
*Wood the Wilson nation gets to-
gether the foundation 
??????????
?? 
Person  ???? Seiji Ozawa *Young Ze drafts you Name 
Location 
Name ????? Tsaidam Basin Qaidam Basin 
Company / ?? Clinique *Attractive blue Brand 
Sci&Tech 
Terms ????? Bayesian network *Shell Ye Si network 
Specie  ?? walrus walrus Term 
Military 
Term ????? stratofortress stratofortress 
Medical 
Term ??? glaucoma glaucoma 
Music  ??? bassoon bassoon Term 
Sports  ?????? Km Tour de France *Link law bicycle match Term 
*: Incorrect translations 
 
Table 4. Key phrase translation from web mining and a MT engine 
 
489
space and translation extraction features. Figure 4 
illustrates three different search strategies. Suppose 
we want to translate the Chinese query ?????. 
(Cheng et al 2004) only searched 188 English web 
pages which contained the source query, and 53% 
of them (100 pages) had the correct translations.  
(Zhang and Vines 2004) searched the whole 
55,100 web pages, 10% of them (5490 pages) had 
the correct translation. Our approach used query 
expansion to search any web pages containing ??
??? and English hint words, which was a larger 
search space than (Cheng et al 2004) and more 
focused compared with (Zhang and Vines 2004), 
as illustrated with the shaded region in Figure 4. 
For translation extraction features, we took advan-
tage of machine transliteration and machine trans-
lation models, and combined them with frequency 
and distance information.  
 
 
 
 
 
 
 
 
 
 
 
 
Figure 4. Web search space strategy comparison 
6 Discussion and Future Work 
In this paper we demonstrated the feasibility of 
the proposed approach by searching for the English 
translation for a given Chinese key phrase, where 
we use punctuations and Chinese words as the 
boundary of candidate English translations. In the 
future we plan to try more flexible translation can-
didate selection methods, and apply them to other 
language pairs. We also would like to test our ap-
proach on more standard test sets, and compare the 
performance with other systems.  
Our approach works on short snippets for query 
expansion and translation extraction, and the com-
putation time is short. Therefore the search en-
gine?s response time is the major factor of 
computational efficiency.  
 
 
7 Conclusion 
We proposed a novel approach to mine key phrase 
translations from web corpora. We used cross-
lingual query expansion to retrieve more relevant 
web pages snippets, and extracted target transla-
tions combining transliteration, translation and fre-
quency-distance models. We achieved significantly 
better results compared to the existing methods.  
8 References  
P. F. Brown, S. A. Della Pietra, V. J. Della Pietra and 
R.L. Mercer. The Mathematics of Machine Translation: 
Parameter Estimation. In Computational Linguistics, vol 
19, number 2. pp.263-311, June, 1993. 
 
P.?J. Cheng, J.-W. Teng, R.-C. Chen, J.-H. Wang, W.-H. 
Lu, and L.-F. Chien. Translating unknown queries with 
web corpora for cross-language information retrieval. In 
the Proceedings of 27th ACM SIGIR, pp146-153. ACM 
Press, 2004. 
 
F. Huang, S.Vogel and A. Waibel. Automatic extraction 
of named entity translingual equivalence based on 
multi-feature cost minimization. In the Proceedings of 
the 41st ACL. Workshop on Multilingual and Mixed-
language Named Entity Recognition, pp124-129, Sap-
poro, Japan, July 2003. 
 
W.-H. Lu, L.-F. Chien, H.-J. Lee. Translation of web 
queries using anchor text mining. ACM Trans. Asian 
Language Information Processing  (TALIP) 1(2): 159-
172 (2002) 
 
P. Resnik and N. A. Smith, The Web as a Parallel Cor-
pus, Computational Linguistics 29(3), pp. 349-380, Sep-
tember 2003 
 
S. Vogel, Y. Zhang, F. Huang, A. Tribble, A. Venogu-
pal, B. Zhao and A. Waibel.  The CMU statistical ma-
chine translation system. In Proceedings of the MT 
Summit IX Conference New Orlean, LA, September, 
2003. 
 
Y. Zhang and P. Vines. Detection and Translation of 
OOV Terms Prior to Query Time, In the Proceedings of 
27th ACM SIGIR. pp524-525, Sheffield, England, 2004. 
 
Y. Zhang and P. Vines 2004, Using the Web for Auto-
mated Translation Extraction in Cross-Language Infor-
mation Retrieval, In Proceedings of 27th ACM SIGIR, 
pp.162-169, Sheffield, United Kingdom, 2004. 
 
Y. Zhang, F. Huang and S. Vogel, Mining Translations 
of OOV Terms from the Web through Cross-lingual 
Query Expansion, in the Proceedings of the 28th ACM 
SIGIR, Salvador, Brazil, August 2005. 
490
Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 159?162,
Ann Arbor, June 2005. c?Association for Computational Linguistics, 2005
Competitive Grouping in Integrated Phrase Segmentation
and Alignment Model
Ying Zhang Stephan Vogel
Language Technologies Institute
School of Computer Science
Carnegie Mellon University
Pittsburgh, PA 15213
{joy+,vogel+}@cs.cmu.edu
Abstract
This article describes the competitive
grouping algorithm at the core of our Inte-
grated Segmentation and Alignment (ISA)
model. ISA extracts phrase pairs from a
bilingual corpus without requiring the pre-
calculated word alignment as many other
phrase alignment models do. Experiments
conducted within the WPT-05 shared task
on statistical machine translation demon-
strate the simplicity and effectiveness of
this approach.
1 Introduction
In recent years, various phrase translation ap-
proaches (Marcu and Wong, 2002; Och et al, 1999;
Koehn et al, 2003) have been shown to outper-
form word-to-word translation models (Brown et al,
1993). Many of these phrase alignment strategies
rely on the pre-calculated word alignment and use
different heuristics to extract the phrase pairs from
the Viterbi word alignment path. The Integrated
Segmentation and Alignment (ISA) model (Zhang
et al, 2003) does not require such word alignment.
ISA segments the sentence into phrases and finds
their alignment simultaneously. ISA is simple and
fast. Translation experiments have shown compara-
ble performance to other phrase alignment strategies
which require complicated statistical model training.
In this paper, we describe the key idea behind this
model and connect it with the competitive linking al-
gorithm (Melamed, 1997) which was developed for
word-to-word alignment.
2 Translation Likelihood as a Statistical
Test
Given a bilingual corpus of language pair F (For-
eign, source language) and E (English, target lan-
guage), if we know the word alignment for each sen-
tence pair we can calculate the co-occurrence fre-
quency for each source/target word pair type C(f, e)
and the marginal frequency C(f) = ?e C(f, e) and
C(e) = ?f C(f, e). We can apply various sta-
tistical tests (Manning and Schu?tze, 1999) to mea-
sure how likely is the association between f and
e, in other words how likely they are mutual trans-
lations. In the following sections, we will use ?2
statistics to measure the the mutual translation like-
lihood (Church and Hanks, 1990).
3 The Core of the Integrated Phrase
Segmentation and Alignment
The competitive linking algorithm (CLA)
(Melamed, 1997) is a greedy word alignment
algorithm. It was designed to overcome the problem
of indirect associations using a simple heuristic:
whenever several word tokens fi in one half of the
bilingual corpus co-occur with a particular word to-
ken e in the other half of the corpus, the word that is
most likely to be e?s translation is the one for which
the likelihood L(f, e) of translational equivalence
is highest. The simplicity of this algorithm depends
on a one-to-one alignment assumption. Each word
translates to at most one other word. Thus when
one pair {f, e} is ?linked?, neither f nor e can be
aligned with any other words. This assumption
renders CLA unusable in phrase level alignment.
159
We propose an extension, the competitive grouping,
as the core component in the ISA model.
3.1 Competitive Grouping Algorithm (CGA)
The key modification to the competitive linking al-
gorithm is to make it less greedy. When a word pair
is found to be the winner of the competition, we al-
low it to invite its neighbors to join the ?winner?s
club? and group them together as an aligned phrase
pair. The one-to-one assumption is thus discarded
in CGA. In addition, we introduce the locality as-
sumption for phrase alignment. Locality states that a
source phrase of adjacent words can only be aligned
to a target phrase composed of adjacent words. This
is not true of most language pairs in cases such as
the relative clause, passive tense, and prepositional
clause, etc.; however this assumption renders the
problem tractable. Here is a description of CGA:
For a sentence pair {f , e}, represent the word pair
statistics for each word pair {f, e} in a two dimen-
sional matrix LI?J , where L(i, j) = ?2(fi, ej) in
our implementation. 1
Figure 1: Expanding the current phrase pair
Denote an aligned phrase pair {f? , e?} as
a tuple [istart, iend, jstart, jend] where f? is
fistart , fistart+1 , . . . , fiend and similarly for e?.
1. Find i? and j? such that L(i?, j?) is the highest.
Create a seed phrase pair [i?, i?, j?, j?] which is
simply the word pair {fi? , ej?} itself.
2. Expand the current phrase pair
[istart, iend, jstart, jend] to the neighboring
territory to include adjacent source and target
words in the phrase alignment group. There
1?2 statistics were found to be more discriminative in our
experiments than other symmetric word association measures,
such as the averaged mutual information, ?2 statistics and Dice-
coefficient.
are 8 ways to group new words into the phrase
pair. For example, one can expand to the
north by including an additional source word
fistart?1 to be aligned with all the target words
in the current group; or one can expand to the
northeast by including fistart?1 and ejend+1
(Figure 1).
Two criteria have to be satisfied for each expan-
sion:
(a) If a new source word fi? is to be grouped,
maxjstart?j?jend L(i?, j) should be no
smaller than max1?j?J L(i?, j). Since
CGA is a greedy algorithm as described
below, this is to guarantee that fi? will not
?regret? the decision of joining the phrase
pair because it does not have other ?better?
target words to be aligned with. Similar
constraint is applied if a new target word
ej? is to be grouped.
(b) The highest value in the newly-expanded
area needs to be ?similar? to the seed value
L(i?, j?).
Expand the current phrase pair to the largest ex-
tend possible as long as both criteria are satis-
fied.
3. The locality assumption means that the aligned
phrase cannot be aligned again. Therefore, all
the source and target words in the phrase pair
are marked as ?invalid? and will be skipped in
the following steps.
4. If there is another valid pair {fi, ej}, then re-
peat from Step 1.
Figure 2 and Figure 3 show a simple example
of applying CGA on the sentence pair {je de?clare
reprise la session/i declare resumed the session}.
Figure 2: Seed pair {je / i}, no expansion allowed
160
Figure 3: Seed pair {session/session}, expanded to
{la session/the session}
3.2 Exploring all possible groupings
The similarity criterion 2-(b) described previously
is used to control the granularity of phrase pairs.
In cases where the pairs {f1f2, e1e2}, {f1, e1} and
{f2, e2} are all valid translations pairs, similar-
ity is used to control whether we want to align
{f1f2, e1e2} as one phrase pair or two shorter ones.
The granularity of the phrase pairs is hard to op-
timize especially when the test data is unknown. On
the one hand, we prefer long phrases since inter-
action among the words in the phrase, for example
word sense, morphology and local reordering could
be encapsulated. On the other hand, long phrase
pairs are less likely to occur in the test data than the
shorter ones and may lead to low coverage. To have
both long and short phrases in the alignment, we ap-
ply a range of similarity thresholds for each of the
expansion operations. By applying a low similarity
threshold, the expanded phrase pairs tend to be large,
while a higher similarity threshold results in shorter
phrase pairs. As described above, CGA is a greedy
algorithm and the expansion of the seed pair restricts
the possible alignments for the rest of the sentence.
Figure 4 shows an example as we explore all the pos-
sible grouping choices in a depth-first search. In the
end, all unique phrase pairs along the path traveled
are output as phrase translation candidates for the
current sentence pair.
3.3 Phrase translation probabilities
Each aligned phrase pair {f? , e?} is assigned a likeli-
hood score L(f? , e?), defined as:
?
i maxj logL(fi, ej) +
?
j maxi logL(fi, ej)
|f? |+ |e?|
where i ranges over all words in f? and similarly j in
e?.
Given the collected phrase pairs and their likeli-
hood, we estimate the phrase translation probability
Figure 4: Depth-first itinerary of all possible group-
ing choices.
by their weighted frequency:
P (f? |e?) = count(f? , e?) ? L(f? , e?)?
f? count(f? , e?) ? L(f? , e?)
No smoothing is applied to the probabilities.
4 Learning co-occurrence information
In most cases, word alignment information is not
given and is treated as a hidden parameter in the
training process. We initialize a word pair co-
occurrence frequency by assuming uniform align-
ment for each sentence pair, i.e. for sentence pair
(f , e) where f has I words and e has J words, each
word pair {f, e} is considered to be aligned with fre-
quency 1I?J . These co-occurrence frequencies will
be accumulated over the whole corpus to calculate
the initial L(f, e). Then we iterate the ISA model:
1. Apply the competitive grouping algorithm to
each sentence pair to find all possible phrase
pairs.
2. For each identified phrase pair {f? , e?}, increase
the co-occurrence counts for all word pairs in-
side {f? , e?} with weight 1|f? |?|e?| .
3. Calculate L(f, e) again and goto Step 1 for sev-
eral iterations.
5 Experiments
We participated the shared task in the WPT05 work-
shop2 and applied ISA to all four language pairs
2http://www.statmt.org/wpt05/mt-shared-task/
161
(French-English, Finnish-English, German-English
and Spanish-English). Table 1 shows the n-gram
coverage of the dev-test set. French and Spanish
data are better covered by the training data com-
pared to the German and Finnish sets. Since our
phrase alignment is constrained by the locality as-
sumption and we can only extract phrase pairs of
adjacent words, lower n-gram coverage will result in
lower translation scores. We used the training data
Dev-test DE ES FI FR
N=1 99.2 99.6 98.2 99.8
N=2 88.2 93.3 73.0 94.7
N=3 59.4 71.7 38.2 76.0
N=4 30.0 42.9 17.0 50.6
N=5 13.0 21.7 6.8 29.8
N=16 (8) (65) (1) (101)
N=19 (1) (23) (34)
N=23 (1) (1)
Table 1: Percentage of dev-test n-grams covered by
the training data. Numbers in parenthesis are the
actual counts of n-gram tokens in the dev-test data.
and the language model as provided and manually
tuned the parameters of the Pharaoh decoder3 to op-
timize BLEU scores. Table 2 shows the translation
results on the dev-test and the test set of WPT05.
The BLEU scores appear comparable to those of
other state-of-the-art phrase alignment systems, in
spite of the simplicity of the ISA model and ease of
training.
DE ES FI FR
Dev-test 18.63 26.20 12.88 26.20
Test 18.93 26.14 12.66 26.71
Table 2: BLEU scores of ISA in WPT05
6 Conclusion
In this paper, we introduced the competitive group-
ing algorithm which is at the core of the ISA phrase
alignment model. As an extension to the competitive
linking algorithm which is used for word-to-word
alignment, CGA overcomes the assumption of one-
to-one mapping and makes it possible to align phrase
3http://www.isi.edu/licensed-sw/pharaoh/
pairs. Despite its simplicity, the ISA model has
achieved competitive translation results. We plan to
release ISA toolkit4 to the community in the near
future.
References
Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della
Pietra, and Robert L. Mercer. 1993. The mathemat-
ics of statistical machine translation: parameter esti-
mation. Comput. Linguist., 19(2):263?311.
Kenneth Ward Church and Patrick Hanks. 1990. Word
association norms, mutual information, and lexicogra-
phy. Comput. Linguist., 16(1):22?29.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Proceed-
ings of the Human Language Technology and North
American Association for Computational Linguistics
Conference (HLT/NAACL), Edomonton, Canada, May
27-June 1.
Christopher D. Manning and Hinrich Schu?tze. 1999.
Foundations of statistical natural language process-
ing. MIT Press, Cambridge, MA, USA.
Daniel Marcu and William Wong. 2002. A phrase-based,
joint probability model for statistical machine transla-
tion. In Proc. of the Conference on Empirical Meth-
ods in Natural Language Processing, Philadephia, PA,
July 6-7.
I. Dan Melamed. 1997. A word-to-word model of trans-
lational equivalence. In Proceedings of the 8-th con-
ference on EACL, pages 490?497, Morristown, NJ,
USA. Association for Computational Linguistics.
Franz Josef Och, Christoph Tillmann, and Hermann Ney.
1999. Improved alignment models for statistical ma-
chine translation. In Proc. of the Conference on
Empirical Methods in Natural Language Processing
and Very Large Corpora, pages 20?28, University of
Maryland, College Park, MD, June.
Ying Zhang, Stephan Vogel, and Alex Waibel. 2003. In-
tegrated phrase segmentation and alignment algorithm
for statistical machine translation. In Proceedings of
NLP-KE?03, Beijing, China, October.
4http://projectile.is.cs.cmu.edu/research/public/isa/index.htm
162
Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 216?223,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Distributed Language Modeling for N -best List Re-ranking
Ying Zhang Almut Silja Hildebrand Stephan Vogel
Language Technologies Institute, Carnegie Mellon University
5000 Forbes Ave. Pittsburgh, PA 15213, U.S.A.
{joy+, silja+, vogel+}@cs.cmu.edu
Abstract
In this paper we describe a novel dis-
tributed language model for N -best list
re-ranking. The model is based on the
client/server paradigm where each server
hosts a portion of the data and provides
information to the client. This model al-
lows for using an arbitrarily large corpus
in a very efficient way. It also provides
a natural platform for relevance weighting
and selection. We applied this model on
a 2.97 billion-word corpus and re-ranked
the N -best list from Hiero, a state-of-the-
art phrase-based system. Using BLEU as a
metric, the re-ranked translation achieves
a relative improvement of 4.8%, signifi-
cantly better than the model-best transla-
tion.
1 Introduction
Statistical language modeling has been widely
used in natural language processing applications
such as Automatic Speech Recognition (ASR),
Statistical Machine Translation (SMT) (Brown et
al., 1993) and Information Retrieval (IR) (Ponte
and Croft, 1998).
Conventional n-gram language modeling
counts the frequency of all the n-grams in a
corpus and calculates the conditional probabilities
of a word given its history of n ? 1 words
P (wi|wi?1i?n+1). As the corpus size increases,
building a high order language model offline
becomes very expensive if it is still possible
(Goodman, 2000).
In this paper, we describe a new approach of
language modeling using a distributed comput-
ing paradigm. Distributed language modeling can
make use of arbitrarily large training corpora and
provides a natural way for language model adap-
tation.
We applied the distributed LM to the task of re-
ranking the N -best list in statistical machine trans-
lation and achieved significantly better translation
quality when measured by the BLEU metric (Pap-
ineni et al, 2001).
2 N -best list re-ranking
When translating a source language sentence f
into English, the SMT decoder first builds a trans-
lation lattice over the source words by applying the
translation model and then explores the lattice and
searches for an optimal path as the best translation.
The decoder uses different models, such as the
translation model, n-gram language model, fertil-
ity model, and combines multiple model scores to
calculate the objective function value which favors
one translation hypothesis over the other (Och et
al., 2004).
Instead of outputting the top hypothesis e(1)
based on the decoder model, the decoder can out-
put N (usually N = 1000) alternative hypotheses
{e(r)|r = 1, . . . , N} for one source sentence and
rank them according to their model scores.
Figure 1 shows an example of the output from a
SMT system. In this example, alternative hypoth-
esis e(2) is a better translations than e(1) according
to the reference (Ref) although its model score is
lower.
SMT models are not perfect, it is unavoidable
to have a sub-optimal translation output as the
model-best by the decoder. The objective of N -
best list re-ranking is then to re-rank the trans-
lation hypotheses using features which are not
used during decoding so that better translations
can emerge as ?optimal? translations. Our exper-
216
f : , 2001#?)?I9]??{/G??
Ref: Since the terrorist attacks on the United States in 2001
e(1): since 200 year , the united states after the terrorist
attacks in the incident
e(2): since 2001 after the incident of the terrorist attacks on
the united states
e(3): since the united states 2001 threats of terrorist attacks
after the incident
e(4): since 2001 the terrorist attacks after the incident
e(5): since 200 year , the united states after the terrorist
attacks in the incident
Figure 1: An example of N -best list.
iments (section 5.1) have shown that the oracle-
best translation from a typical N -best list could be
6 to 10 BLEU points better than the model-best
translation.
In this paper we use the distributed language
model on very large data to re-rank the N -best list.
2.1 Sentence likelihood
The goal of a language model is to determine
the probability, or in general the ?likelihood? of
a word sequence w1 . . . wm (wm1 for short) given
some training data. The standard language model-
ing approach breaks the sentence probability down
into:
P (wm1 ) =
?
i
P (wi|wi?11 ) (1)
Under the Markov or higher order Markov process
assumption that only the closest n? 1 words have
real impact on the choice of wi, equation 1 is ap-
proximated to:
P (wm1 ) =
?
i
P (wi|wi?1i?n+1) (2)
The probability of a word given its history can be
approximated with the maximum likelihood esti-
mate (MLE) without any smoothing:
P (wi|wi?1i?n+1) ?
C(wii?n+1)
C(wi?1i?n+1)
(3)
In addition to the standard n-gram probability
estimation, we propose 3 sentence likelihood met-
rics.
? L0: Number of n-grams matched.
The simplest metric for sentence likelihood is
to count how many n-grams in this sentence
can be found in the corpus.
L0(wm1 ) =
?
i,j
i?j
?(wji ) (4)
?(wji ) =
{
1 : C(wji ) > 0
0 : C(wji ) = 0
(5)
For example, L0 for sentence in figure 2 is 52
because 52 n-grams have non-zero counts.
? Ln1 : Average interpolated n-gram conditional
probability.
Ln1 (wm1 ) =
( m?
i=1
n?
k=1
?kP (wi|wi?1i?k+1)
) 1
m
(6)
P (wi|wi?1i?k+1) is approximated from the n-
gram counts (Eq. 3) without any smoothing.
?k is the weight for k-gram conditional prob-
ability,
??k = 1.
Ln1 is similar to the standard n-gram LM
except the probability is averaged over the
words in the sentence to prevent shorter sen-
tences being favored unfairly.
? L2: Sum of n-gram?s non-compositionality
For each matched n-gram, we consider all
the possibilities to cut/decompose it into two
short n-grams, for example ?the terrorist at-
tacks on the united states? could be decom-
posed into (?the?, ?terrorist attacks on the
united states?) or (?the terrorist?, ?attacks
on the united states?), ... , or (?the ter-
rorist attacks on the united?, ?states?). For
each cut, calculate the point-wise mutual in-
formation (PMI) between the two short n-
grams. The one with the minimal PMI
is the most ?natural? cut for this n-gram.
The PMI over the natural cut quantifies the
non-compositionality Inc of an n-gram wji .
The higher the value of Inc(wji ) the more
likely wji is a meaningful constituent, in other
words, it is less likely that wji is composed
from two short n-grams just by chance (Ya-
mamoto and Church, 2001).
Define L2 formally as:
L2(wm1 ) =
?
i,j
i?j
Inc(wji ) (7)
217
Inc(wji ) =
?
?
?
min
k
I(wki ;wjk+1) : C(wji ) > 0
0 : C(wji ) = 0
(8)
I(wki ;wjk+1) = log
P (wji )
P (wki )P (wjk+1)
(9)
3 Distributed language model
The fundamental information required to calculate
the likelihood of a sentence is the frequency of n-
grams in the corpus. In conventional LM train-
ing, all the counts are collected from the corpus D
and saved to disk for probability estimation. When
the size of D becomes large and/or n is increased
to capture more context, the count file can be too
large to be processed.
Instead of collecting n-gram counts offline, we
index D using a suffix array (Manber and Myers,
1993) and count the occurrences of wii?n+1 in D
on the fly.
3.1 Calculate n-gram frequency using suffix
array
For a corpus D with N words, locating all the oc-
currences of wii?n+1 takes O(logN ). Zhang and
Vogel (2005) introduce a search algorithm which
locates all the m(m+ 1)/2 embedded n-grams in
a sentence of m words within O(m ? logN ) time.
Figure 2 shows the frequencies of all the embed-
ded n-grams in sentence ?since 2001 after the in-
cident of the terrorist attacks on the united states?
matched against a 26 million words corpus. For
example, unigram ?after? occurs 4.43?104 times,
trigram ?after the incident? occurs 106 times. The
longest n-gram that can be matched is the 8-gram
?of the terrorist attacks on the united states? which
occurs 7 times in the corpus.
3.2 Client/Server paradigm
To load the corpus and its suffix array index into
the memory, each word token needs 8 bytes. For
example, if the corpus has 50 million words,
400MB memory is required. For the English1 Gi-
gaWord2 corpus which has 2.7 billion words, the
1Though we used English data for our experiments in this
paper, the approach described here is language independent.
2http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?
catalogId=LDC2005T12
total memory required is 22GB. It is practically
impossible to fit such data into the memory of any
single machine.
To make use of the large amount of data, we
developed a distributed client/server architecture
for language modeling. Client/server is the most
common paradigm of distributed computing at
present (Leopold, 2001). The paradigm describes
an asymmetric relationship between two type of
processes, of which one is the client, and the other
is the server. The server process manages some re-
sources and offers a service which can be used by
other processes. The client is a process that needs
the service in order to accomplish its task. It sends
a request to the server and asks for the execution
of a task that is covered by the service.
We split the large corpus D into d non-
overlapping chunks. One can easily verify that for
any n-gram wii?n+1 the count of its occurrences in
D is the sum of its occurrences in all the chunks,
i.e.,
C(wii?n+1)|D =
?
d
C(wii?n+1)|Dd (10)
Each server3 loads one chunk of the corpus with
its suffix array index. The client sends an English
sentence w1 . . . wm to each of the servers and re-
quests for the count information of all the n-grams
in the sentence. The client collects the count infor-
mation from all the servers, sums up the counts for
each n-gram and then calculates the likelihood of
the sentence.
The client communicates with the servers via
TCP/IP sockets. In our experiments, we used
150 servers running on 26 computers to serve one
client. Multiple clients can be served at the same
time if needed. The process of collecting counts
and calculating the sentence probabilities takes
about 1 to 2 ms for each English sentence (average
length 23.5 words). With this architecture, we can
easily make use of larger corpora by adding addi-
tional data servers. In our experiments, we used all
the 2.7 billion word data in the English Gigaword
corpus without any technical difficulties.
3A server is a special program that provides services to
client processes. It runs on a physical computer but the con-
cept of server should not be confused with the actual machine
that runs it. In practice, one computer usually hosts multiple
servers at the same time.
218
n since 2001 after the incident of the terrorist attacks on the united states
1 2.19?104 7559 4.43?104 1.67?106 2989 6.9?105 1.67?106 6160 9278 2.7?105 1.67?106 5.1?104 3.78?104
2 165 105 1.19?104 1892 34 2.07?105 807 1398 1656 5.64?104 3.72?104 3.29?104
3 6 56 106 6 3 162 181 216 545 605 2.58?104
4 0 0 0 1 0 35 67 111 239 424
5 0 0 0 0 0 15 34 77 232
6 0 0 0 0 0 10 23 76
7 0 0 0 0 0 7 23
8 0 0 0 0 0 7
Figure 2: Frequencies of all the embedded n-grams in sentence ?since 2001 after the incident of the
terrorist attacks on the united states.?
4 ?More data is better data? or
?Relevant data is better data?
Although statistical systems usually improve with
more data, performance can decrease if additional
data does not fit the test data. There have been
debates in the data-driven NLP community as to
whether ?more data is better data? or ?relevant
data is better data?. For N -best list re-ranking, the
question becomes: ?should we use all the data to
re-rank the hypotheses for one source sentence, or
select some corpus chunks that are believed to be
relevant to this sentence??
Various relevance measures are proposed in
(Iyer and Ostendorf, 1999) including content-
based relevance criteria and style-based criteria. In
this paper, we use a very simple relevance metric.
Define corporaDd?s relevance to a source sentence
ft as:
R(Dd, ft) =
N?
r=1
L0(e(r)t )|Dd (11)
R(Dd, ft) estimates how well a corpus Dd can
cover the n-grams in the N -best list of a source
sentence. The higher the coverage, the more rele-
vant Dd is.
In the distributed LM architecture, the client
first sends N translations of ft to all the servers.
From the returned n-gram matching information,
client calculates R(Dd, ft) for each server, and
choose the most relevant (e.g., 20) servers for ft.
The n-gram counts returned from these relevant
servers are summed up for calculating the likeli-
hood of ft. One could also assign weights to the n-
gram counts returned from different servers during
the summation so that the relevant data has more
impact than the less-relevant ones.
5 Experiments
We used the N -best list generated by the Hiero
SMT system (Chiang, 2005). Hiero is a statis-
tical phrase-based translation model that uses hi-
erarchical phrases. The decoder uses a trigram
language model trained with modified Kneser-Ney
smoothing (Kneser and Ney, 1995) on a 200 mil-
lion words corpus. The 1000-best list was gen-
erated on 919 sentences from the MT03 Chinese-
English evaluation set.
All the data from the English Gigaword corpus
plus the English side of the Chinese-English bilin-
gual data available from LDC are used. The 2.97
billion words data is split into 150 chunks, each
has about 20 million words. The original order
is kept so that each chunk contains data from the
same news source and a certain period of time.
For example, chunk Xinhua2003 has all the Xin-
hua News data from year 2003 and NYT9499 038
has the last 20 million words from the New York
Times 1994-1999 corpus. One could split the
data into larger(smaller) chunks which will require
less(more) servers. We choose 20 million words as
the size for each chunk because it can be loaded by
our smallest machine and it is a reasonable granu-
larity for selection.
In total, 150 corpus information servers run on
26 machines connected by the standard Ethernet
LAN. One client sends each English hypothesis
translations to all 150 servers and uses the returned
information to re-rank. The whole process takes
about 600 seconds to finish.
We use BLEU scores to measure the transla-
tion accuracy. A bootstrapping method is used to
calculate the 95% confidence intervals for BLEU
(Koehn, 2004; Zhang and Vogel, 2004).
5.1 Oracle score of the N -best list
Because of the spurious ambiguity, there are only
24,612 unique hypotheses in the 1000-best list, on
average 27 per source sentence. This limits the po-
tential of N -best re-ranking. Spurious ambiguity
is created by the decoder where two hypotheses
generated from different decoding path are con-
sidered different even though they have identical
word sequences. For example, ?the terrorist at-
tacks on the united states? could be the output of
decoding path [the terrorist attacks][on the united
219
states] and [the terrorist attacks on] [the united
states].
We first calculate the oracle score from the N -
best list to verify that there are alternative hypothe-
ses better than the model-best translation. The or-
acle best translations are created by selecting the
hypothesis which has the highest sentence BLEU
score for each source sentence. Yet a critical prob-
lem with BLEU score is that it is a function of
the entire test set and does not give meaningful
scores for single sentences. We followed the ap-
proximation described in (Collins et al, 2005) to
get around this problem. Given a test set with T
sentences, N hypotheses are generated for each
source sentence ft. Denote e(r)t as the r-th ranked
hypothesis for ft. e(1)t is the model-best hypoth-
esis for this sentence. The baseline BLEU scores
are calculated based on the model-best translation
set {e(1)t |t = 1, . . . , T}.
Define the BLEU sentence-level gain for e(r)t
as:
GBLEUe(r)t =
BLEU{e(1)1 , e(1)2 , . . . , e(r)t , . . . , e(r)T }
? BLEU{e(1)1 , e(1)2 , . . . , e(1)t , . . . , e(r)T }
GBLEUe(r)t calculates the gain if we switch the
model-best hypothesis e(1)t using e(r)t for sentence
ft and keep the translations for the rest of the test
set untouched.
With the estimated sentence level gain for each
hypothesis, we can construct the oracle best trans-
lation set by selecting the hypotheses with the
highest BLEU gain for each sentence. Oracle best
BLEU translation set is: {e(r?t )t |t = 1, . . . , T}
where r?t = argmaxr GBLEUe(r)t .
Model-best
Score Confidence Interval Oracle
BLEU 31.44 [30.49, 32.33] 37.48
Table 1: BLEU scores for the model-best and
oracle-best translations.
Table 1 shows the BLEU score of the approxi-
mated oracle best translation. The oracle score is
7 points higher than the model-best scores even
though there are only 27 unique hypotheses for
each sentence on average. This confirms our ob-
servation that there are indeed better translations
in the N -best list.
5.2 Training standard n-gram LM on large
data for comparison
Besides comparing the distributed language model
re-ranked translations with the model-best transla-
tions, we also want to compare the distributed LM
with the the standard 3-gram and 4-gram language
models on the N -best list re-ranking task.
Training a standard n-gram model for a 2.9 bil-
lion words corpora is much more complicated and
tedious than setting up the distributed LM. Be-
cause of the huge size of the corpora, we could
only manage to train a test-set specific n-gram LM
for this experiment.
First, we split the corpora into smaller chunks
and generate n-gram count files for each chunk.
Each count file is then sub-sampled to entries
where all the words are listed in the vocabulary
of the N -best list (5,522 word types). We merge
all the sub-sampled count files into one and train
the standard language model based on it.
We manage to train a 3-gram LM using the
2.97 billion-word corpus. Resulting LM requires
2.3GB memory to be loaded for the re-ranking ex-
periment.
A 4-gram LM for this N -best list is of 13 GB
in size and can not be fit into the memory. We
split the N -best list into 9 parts to reduce the vo-
cabulary size of each sub N -best list to be around
1000 words. The 4-gram LM tailored for each sub
N -best list is around 1.5 to 2 GB in size.
Training higher order standard n-gram LMs
with this method requires even more partitions of
the N -best list to get smaller vocabularies. When
the vocabulary becomes too small, the smoothing
could fail and results in unreliable LM probabili-
ties.
Adapting the standard n-gram LM for each in-
dividual source sentence is almost infeasible given
our limited computing resources. Thus we do not
have equivalent n-gram LMs to be compared with
the distributed LM for conditions where the most
relevant data chunks are used to re-rank the N -best
list for a particular source sentence.
5.3 Results
Table 2 lists results of the re-ranking experiments
under different conditions. The re-ranked trans-
lation improved the BLEU score from 31.44 to
220
32.64, significantly better than the model-best
translation.
Different metrics are used under the same data
situation for comparison. L0, though extremely
simple, gives quite nice results on N -best list re-
ranking. With only one corpus chunk (the most
relevant one) for each source sentence, L0 im-
proved the BLEU score to 32.22. We suspect that
L0 works well because it is inline with the nature
of BLEU score. BLEU measures the similarity be-
tween the translation hypothesis and human refer-
ence by counting how many n-grams in MT can
be found in the references.
Instead of assigning weights 1 to all the
matched n-grams in L0, L2 weights each n-gram
by its non-compositionality. For all data condi-
tions, L2 consistently gives the best results.
Metric family L1 is close to the standard n-gram
LM probability estimation. Because no smoothing
is used, L31 performance (32.00) is slightly worse
than the standard 3-gram LM result (32.22). On
the other hand, increasing the length of the history
in L1 generally improves the performance.
Figure 3 shows the BLEU score of the re-ranked
translation when using different numbers of rele-
vant data chunks for each sentence. The selected
data chunks may differ for each sentences. For
example, the 2 most relevant corpora for sentence
1 are Xinhua2002 and Xinhua2003 while for sen-
tence 2 APW2003A and NYT2002D are more rel-
evant. When we use the most relevant data chunk
(about 20 million words) to re-rank the N -best list,
36 chunks of data will be used at least once for
919 different sentences, which accounts for about
720 million words in total. Thus the x-axis in fig-
ure 3 should not be interpreted as the total amount
of data used but the number of the most relevant
corpora used for each sentence.
All three metrics in figure 3 show that using
all data together (150 chunks, 2.97 billion words)
does not give better discriminative powers than us-
ing only some relevant chunks. This supports our
argument in section 4 that relevance selection is
helpful in N -best list re-ranking. In some cases
the re-ranked N -best list has a higher BLEU score
after adding a supposedly ?less-relevant? corpus
chunk and a lower BLEU score after adding a
?more-relevant? chunk. This indicates that the rel-
evance measurement (Eq. 11) is not fully reflect-
ing the real ?relevance? of a data chunk for a sen-
tence. With a better relevance measurement one
 32.15
 32.2
 32.25
 32.3
 32.35
 32.4
 32.45
 32.5
 32.55
 32.6
 32.65
 32.7
 0  20  40  60  80  100  120  140  160
Ble
u S
cor
e
Number of corpus chunks used for each source sentence (*20M=corpus size used)
"L0"
"L1"
"L2"
Figure 3: BLEU score of the re-ranked best hy-
pothesis vs. the number of the most relevant cor-
pus chunks used to re-rank the n-best list for each
sentences. L0: number of n-grams matched; L1:
average interpolated n-gram conditional probabil-
ity; L2: sum of n-grams? non-compositionality.
would expect to see the curves in figure 3 to be
much smoother.
6 Related work and discussion
Yamamoto and Church (2001) used suffix arrays
to compute the frequency and location of an n-
gram in a corpus. The frequencies are used to find
?interesting? substrings which have high mutual
information.
Soricut et al (2002) build a Finite State Ac-
ceptor (FSA) to compactly represent all possible
English translations of a source sentence accord-
ing to the translation model. All sentences in a
big monolingual English corpus are then scanned
by this FSA and those accepted by the FSA are
considered as possible translations for the source
sentence. The corpus is split into hundreds of
chunks for parallel processing. All the sentences
in one chunk are scanned by the FSA on one pro-
cessor. Matched sentences from all chunks are
then used together as possible translations. The
assumption of this work that possible translations
of a source sentence can be found as exact match
in a big monolingual corpus is weak even for very
large corpus. This method can easily fail to find
any possible translation and return zero proposed
translations.
Kirchhoff and Yang (2005) used a factored 3-
gram model and a 4-gram LM (modified KN
smoothing) together with seven system scores to
re-rank an SMT N -best. They improved the
translation quality of their best baseline (Spanish-
221
# of Relevant Chunks per. Sent 1 2 5 10 20 150
3-gram KN 32.22 32.08
4-gram KN 32.22 32.53
L0 32.27 32.38 32.40 32.47 32.51 32.48
L31 32.00 32.14 32.14 32.15 32.16
L41 32.18 32.36 32.28 32.44 32.41
L51 32.21 32.33 32.35 32.41 32.37
L61 32.19 32.22 32.37 32.45 32.40 32.41
L71 32.22 32.29 32.37 32.44 32.40
L2 32.29 32.52 32.61 32.55 32.64 32.56
Table 2: BLEU scores of the re-ranked translations. Baseline score = 31.44
English) from BLEU 30.5 to BLEU 31.0.
Iyer and Ostendorf (1999) select and weight
data to train language modeling for ASR. The data
is selected based on its relevance for a topic or the
similarity to data known to be in the same domain
as the test data. Each additional document is clas-
sified to be in-domain or out-of-domain accord-
ing to cosine distance with TF-IDF term weights,
POS-tag LM and a 3-gram word LM. n-gram
counts from the in-domain and the additionally se-
lected out-of-domain data are then combined with
an weighting factor. The combined counts are
used to estimate a LM with standard smoothing.
Hildebrand et al (2005) use information re-
trieval to select relevant data to train adapted trans-
lation and language models for an SMT system.
Si et al (2002) use unigram distribution simi-
larity to select the document collection which is
most relevant to the query documents. Their work
is mainly focused on information retrieval appli-
cation.
7 Conclusion and future work
In this paper, we presented a novel distributed
language modeling solution. The distributed LM
is capable of using an arbitrarily large corpus
to estimate the n-gram probability for arbitrarily
long histories. We applied the distributed lan-
guage model to N -best re-ranking and improved
the translation quality by 4.8% when evaluated by
the BLEU metric. The distributed LM provides a
flexible architecture for relevance selection, which
makes it possible to select data for each individual
test sentence. Our experiments have shown that
relevant data has better discriminative power than
using all the data.
We will investigate different relevance weight-
ing schemes to better combine n-gram statistics
from different data sources. We are planning to
integrate the distributed LM in the statistical ma-
chine translation decoder in the near future.
8 Acknowledgement
We would like to thank Necip Fazil Ayan and
Philip Resnik for providing Hiero system?s N -best
list and allowing us to use it for this work.
References
Peter F. Brown, Vincent J. Della Pietra, Stephen
A. Della Pietra, and Robert L. Mercer. 1993. The
mathematics of statistical machine translation: pa-
rameter estimation. Comput. Linguist., 19(2):263?
311.
David Chiang. 2005. A hierarchical phrase-based
model for statistical machine translation. In Pro-
ceedings of ACL 2005, pages 263?270, Ann Arbor,
MI, June 2005. ACL.
Michael Collins, Philipp Koehn, and Ivona Kucerova.
2005. Clause restructuring for statistical machine
translation. In Proceedings of ACL 2005, pages
531?540, Ann Arbor, MI, June.
J. Goodman. 2000. A bit of progress in language
modeling. Technical report, Microsoft Research, 56
Fuchun Peng.
Almut Silja Hildebrand, Matthias Eck, Stephan Vogel,
and Alex Waibel. 2005. Adaptation of the transla-
tion model for statistical machine translation based
on information retrieval. In Proceedings of the 10th
EAMT conference ?Practical applications of ma-
chine translation?, pages 133?142, Budapest, May.
R. Iyer and M. Ostendorf. 1999. Relevance weighting
for combining multi-domain data for n-gram lan-
guage modeling. Comptuer Speech and Language,
13(3):267?282.
222
Katrin Kirchhoff and Mei Yang. 2005. Improved lan-
guage modeling for statistical machine translation.
In Proceedings of the ACL Workshop on Building
and Using Parallel Texts, pages 125?128, Ann Ar-
bor, Michigan, June. Association for Computational
Linguistics.
Reinhard Kneser and Hermann Ney. 1995. Improved
backing-off for m-gram language modeling. In Pro-
ceedings of the IEEE International Conference on
Acoustics, Speech and Signal Processing, volume 1,
pages 181?184.
Philipp Koehn. 2004. Statistical significance tests for
machine translation evaluation. In Proceedings of
EMNLP 2004, Barcelona, Spain, July.
Claudia Leopold. 2001. Parallel and Distributed Com-
puting: A Survey of Models, Paradigms and Ap-
proaches. John Wiley & Sons, Inc., New York, NY,
USA.
Udi Manber and Gene Myers. 1993. Suffix arrays:
a new method for on-line string searches. SIAM J.
Comput., 22(5):935?948.
Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur,
Anoop Sarkar, Kenji Yamada, Alex Fraser, Shankar
Kumar, Libin Shen, David Smith, Katherine Eng,
Viren Jain, Zhen Jin, and Dragomir Radev. 2004.
A smorgasbord of features for statistical machine
translation. In Proceedings of the 2004 Meeting of
the North American chapter of the Association for
Computational Linguistics (NAACL-04), Boston.
K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2001.
Bleu: a method for automatic evaluation of machine
translation. Technical Report RC22176(W0109-
022), IBM Research Division, Thomas J. Watson
Research Center.
Jay M. Ponte and W. Bruce Croft. 1998. A language
modeling approach to information retrieval. In Re-
search and Development in Information Retrieval,
pages 275?281.
Luo Si, Rong Jin, Jamie Callan, and Paul Ogilvie.
2002. A language modeling framework for resource
selection and results merging. In CIKM ?02: Pro-
ceedings of the eleventh international conference
on Information and knowledge management, pages
391?397, New York, NY, USA. ACM Press.
Radu Soricut, Kevin Knight, and Daniel Marcu. 2002.
Using a large monolingual corpus to improve trans-
lation accuracy. In AMTA ?02: Proceedings of
the 5th Conference of the Association for Machine
Translation in the Americas on Machine Transla-
tion: From Research to Real Users, pages 155?164,
London, UK. Springer-Verlag.
Mikio Yamamoto and Kenneth W. Church. 2001. Us-
ing suffix arrays to compute term frequency and doc-
ument frequency for all substrings in a corpus. Com-
put. Linguist., 27(1):1?30.
Ying Zhang and Stephan Vogel. 2004. Measuring con-
fidence intervals for the machine translation evalu-
ation metrics. In Proceedings of The 10th Interna-
tional Conference on Theoretical and Methodologi-
cal Issues in Machine Translation, October.
Ying Zhang and Stephan Vogel. 2005. An effi-
cient phrase-to-phrase alignment model for arbitrar-
ily long phrase and large corpora. In Proceedings
of the Tenth Conference of the European Associa-
tion for Machine Translation (EAMT-05), Budapest,
Hungary, May. The European Association for Ma-
chine Translation.
223
Domain-Specific Query Translation for Multilingual Information Access
using Machine Translation Augmented With Dictionaries
Mined from Wikipedia
Gareth J. F. Jones, Fabio Fantino, Eamonn Newman, Ying Zhang
Centre for Digital Video Processing
Dublin City University
Dublin 9, Ireland
{gjones,enewman,yzhang}@computing.dcu.ie
Abstract
Accurate high-coverage translation is a vi-
tal component of reliable cross language in-
formation access (CLIA) systems. While
machine translation (MT) has been shown
to be effective for CLIA tasks in previous
evaluation workshops, it is not well suited
to specialized tasks where domain specific
translations are required. We demonstrate
that effective query translation for CLIA can
be achieved in the domain of cultural her-
itage (CH). This is performed by augment-
ing a standard MT system with domain-
specific phrase dictionaries automatically
mined from the online Wikipedia. Exper-
iments using our hybrid translation system
with sample query logs from users of CH
websites demonstrate a large improvement
in the accuracy of domain specific phrase de-
tection and translation.
1 Introduction
Reliable translation is a key component of effective
Cross Language Information Access (CLIA) sys-
tems. Various approaches to translation have been
explored at evaluation workshops such as TREC1,
CLEF2 and NTCIR3. Experiments at these work-
shops have been based on laboratory collections
consisting of news articles or technical reports with
?TREC? style queries with a minimum length of a
1trec.nist.gov
2http://www.clef-campaign.org/
3http://research.nii.ac.jp/ntcir/
full sentence. Test collection design at these work-
shops often ensures that there are a reasonable num-
ber of relevant documents available for each query.
In such cases general purpose translation resources
based on bilingual dictionaries and standard ma-
chine translation (MT) have been shown to be ef-
fective for translation in CLIA. However, this is less
likely to be the case when translating the very short
queries typically entered by general users of search
engines, particularly when they are seeking informa-
tion in a specific domain.
Online cultural heritage (CH) content is currently
appearing in many countries produced by organisa-
tions such as national libraries, museums, galleries
and audiovisual archives. Additionally, there are in-
creasing amounts of CH relevant content available
more generally on the World Wide Web. While
some of this material concerns national or regional
content only of local interest, much material relates
to items involving multiple nations and languages,
for example concerning events or groups encom-
passing large areas of Europe or Asia. In order to
gain a full understanding of such things, including
details contained in different collections and explor-
ing different cultural perspectives, often requires ef-
fective multilingual search technologies.
CH content encompasses various different media,
including of course text documents, but also im-
ages, videos, and audio recordings which may only
be described by very limited metadata labels. Such
metadata may include simple factual details such as
date of creation, but also descriptive details relat-
ing to the contents of the item and interpretation
and contextualization of the content. Multilingual
searching using metadata content requires that ei-
ther the metadata be translated into a language with
which the user is able to search or that the search
query be translated into the language of the meta-
data. This alternative of document or query trans-
lation is a well rehearsed argument in CLIA, which
has generally concerned itself with full text docu-
ment searching. However, the features of metadata
require a more careful analysis. Metadata is typi-
cally dense in search terms, while lacking the lin-
guistic structure and information redundancy of full
text documents. The absence of linguistic struc-
ture makes precise translation of content problem-
atic, while the lack of redundancy means that accu-
rate translation of individual words and phrases be-
tween the query and document is vital to minimize
mismatch between query and document terms. De-
veloping reliable and robust approaches to transla-
tion for metadata search is thus an important com-
ponent of search for many CH archives.
The EU FP6 MultiMatch4 project is concerned
with information access for multimedia and multi-
lingual content for a range of European languages.
In this paper we report on the MultiMatch query
translation methods we are developing to deal with
domain-specific language in the CH domain. We
demonstrate the effectiveness of these techniques
using example query logs from CH sites in English,
Spanish and Italian. We translate the queries and ex-
amine the quality of these translations using human
annotation. We show how a domain-specific phrase
dictionary can be used to augment traditional gen-
eral MT systems to improve the coverage and relia-
bility of translation of these queries. We also show
how retrieval performance on CH image metadata is
improved with the use of these improved, domain-
specific translations.
The remainder of this paper is organized as fol-
lows: Section 2 introduces the translation resources
used for this study, Section 3 describes our experi-
mental setup and results, Section 4 summarizes our
conclusions, and Section 5 gives details of our on-
going work.
4www.multimatch.org
2 Query Translation Techniques
The MT approach to query translation for CLIA
uses an existing MT system to provide automatic
translation. Using MT systems for query transla-
tion is widely used in CLIA when such a system
is available for the particular language pair under
consideration. Results reported at the standard re-
trieval evaluation workshops have often shown it
to be competitive with other translation methods.
However, while MT systems can provide reasonable
translations for general language expressions, they
are often not sufficient for domain-specific phrases
that contain personal names, place names, techni-
cal terms, titles of artworks, etc. In addition, cer-
tain words and phrases hold special meanings in a
specific domain. For example, the Spanish phrase
?Canto general? is translated into English as ?gen-
eral song?, which is arguably correct. However, in
the CH domain, ?Canto general? refers to a book ti-
tle from Pablo Neruda?s book of poems and should
be translated directly into English as the phrase
?Canto general?. Multiple-word phrases are more
information-bearing and more unambiguously rep-
resented than single words. They are often domain-
specific and typically absent from static lexicons.
Effective translation of such phrases is therefore par-
ticularly critical for short queries that are typically
entered by non-expert users of search engines.
The focus of the research reported in this paper
is a method to improve translation effectiveness of
phrases previously untranslated or inappropriately
translated by a standard MT system. In this work we
combine an MT system with domain-specific phrase
dictionaries mined from the online Wikipedia. The
next sections describe the construction of our dictio-
naries and their combination with the MT system.
2.1 Phrase Dictionary Construction
Our phrase translation system uses domain-specific
phrase dictionaries built by mining the online
Wikipedia5. As a multilingual hypertext medium,
Wikipedia has been shown to be a valuable new
source of translation information (Adafre and de
Rijke, 2005; Adafre and de Rijke, 2006; Bouma
et al, 2006; Declerck et al, 2006). Wikipedia is
structured as an interconnected network of articles,
5http://wikipedia.org
Figure 1: An example of Italian?English query translation.
in particular, wikipedia page titles in one language
are often linked to a multilingual database of cor-
responding terms. Unlike the web, most hyper-
links in wikipedia have a more consistent pattern
and meaningful interpretation. For example, the En-
glish wikipedia page http://en.wikipedia.org/
wiki/Cupid_and_Psyche hyperlinks to its counter-
part written in Italian http://it.wikipedia.org/
wiki/Amore_e_Psiche, where the basenames of
these two URLs (?Cupid and Psyche? and ?Amore e
Psiche?) are an English?Italian translation pair. The
URL basename can be considered to be a term (sin-
gle word or multiple-word phrase) that should be
translated as a unit.
Utilizing the multilingual linkage feature of
Wikipedia, we implement a three-stage automatic
process to mine wikipedia pages as a translation
source and construct phrase dictionaries in the cul-
ture heritage domain.
1. First, we performed a web crawl from the En-
glish wikipedia, Category: Culture. This cate-
gory contains links to articles and subcategories
concerning arts, religions, traditions, entertain-
ment, philosophy, etc. The crawl process is re-
stricted to the category of culture including all
of its recursive subcategories. In total, we col-
lected 458, 929 English pages.
2. For each English page obtained, we extracted
the hyperlinks to each of the query languages
(Italian and Spanish).
3. We then selected the basenames of each
pair of hyperlinks (English?Italian, English?
Spanish) as translations and added them into
our domain-specific dictionaries. The multiple-
word phrases were added into the phrase dictio-
nary for each language. These phrase dictionar-
ies are later used for dictionary-based phrase
identification.
The dictionaries we compiled contain about 90, 000,
70, 000, and 80, 000 distinct multiple-word phrases
in English, Italian, and Spanish respectively. The
majority of the phrases extracted are CH domain-
specific named entities and the rest of them are
general noun-based phrases, such as ?Music of Ire-
land? and ?Philosophy of history?. We did not ap-
ply any classifier to filter out the general noun-based
phrases, since such phrases play an equally impor-
tant role in the query translation process as domain-
specific named entities.
2.2 Improved MT-based Translation
Figure 1 shows our query translation process which
proceeds as follows:
Lexical rule-based phrase identification Given a
query, the first task is to locate phrases. Three meth-
ods of multiple-word phrase identification have been
commonly used: lexical rule-based (Ballesteros and
Croft, 1997; Hull and Grefenstette, 1996), statisti-
cal (Coenen et al, 2007; Gao et al, 2001), and syn-
tactical methods (Sharma and Raman, 2003; Gel-
bukh et al, 2004; Van de Cruys and Villada Moiro?n,
2007). The lexical rule-based approach with max-
imum forward matching was adopted in our query
translation process due to its robust performance and
computational simplicity. The query is sequentially
scanned to match the phrase dictionary. The longest
matched subsequence is taken as a phrase and trans-
lated via a domain-specific dictionary lookup. This
process is recursively invoked on the remaining part
of the query until no matches are found. The per-
formance of this approach depends strongly on the
completeness of the coverage of the adopted dictio-
nary. Our experimental results showed that at least
one phrase is detected in 90% of the testing queries,
for example, personal names, geographic locations,
and titles of various types of artworks. This indicates
that the phrase dictionaries we compiled can be used
to accurately identify phrases in web queries.
WorldLingo machine translation We translate
the original query into the target language using the
WorldLingo6 MT system. WorldLingo was selected
for the MultiMatch project because it generally pro-
vides good translation between English, Spanish,
Italian, and Dutch ? the languages relevant to the
Multimatch project. In addition, it provides a useful
API that can be used to translate queries in real-time
via HTTP transfer protocol.
Phrase translation validation For each of the
phrases previously recognized, we again pass it to
the MT system and the translation Tmt of this phrase
is returned by WorldLingo. Tmt is then replaced in
theWorldLingo translation of the query by the trans-
lations(s) Tdict from our domain-specific dictionary,
if Tmt 6= Tdict. This allows us to correct unreliable
phrase translations generated by the MT system.
3 Experimental Investigation
The goal of our experiments was to evaluate the
usefulness and the accuracy of the domain-specific
translation dictionaries. Instead of using queries
from a standard information retrieval test collection,
we experimented with queries explicitly seeking CH
information from real query log data provided by
CH organisations.
3.1 Query Log
The query log data used in this investigation was
provided by three European CH organisations par-
6http://worldlingo.com
# Detected # Untranslated
Proportionby dictionaries by WorldLingo
EN?IT 14 11 79%
EN?ES 19 11 58%
IT?EN 83 33 40%
ES?EN 74 33 45%
Table 1: Number of detected phrases using the
domain-specific dictionaries.
Total
# Exactly # + Extra # + Minor
correct translations noise
EN?IT 14 13 1 0
EN?ES 19 17 1 1
IT?EN 83 40 43 0
ES?EN 74 37 5 32
Table 2: Correctness of the translations of detected
domain-specific phrases.
ticipating in the MultiMatch project, and is taken
from their archives of real user queries. The data
consists of 100 English, 1048 Italian, and 1088
Spanish distinct web queries and the number of hits
of each query. The top 200 most popular multiple-
word queries in Italian and Spanish were selected as
the queries for testing. Due to the smaller size of
the English query log, we only obtained English 53
phrasal queries.
We used two methods of evaluation: first, the dic-
tionary usefulness and the translation effectiveness
are judged extrinsically by human assessment; and
second, evaluation using a parallel Italian?English
metadata document set explored how translation af-
fects the retrieval performance of an information re-
trieval system.
3.2 Human Judgement Evaluation
The WorldLingo MT system was used to translate
Spanish and Italian queries into English and vice
versa. Our domain-specific dictionaries were used
to translate phrases within the queries into the same
target languages. It should be noted that it is not pos-
sible to directly compare the lexical coverage of our
domain-specific dictionaries and the built-in phrase
dictionaries of WorldLingo since we don?t have ac-
cess to the internal WorldLingo dictionaries.
To evaluate the usefulness of our dictionaries, we
observed the proportion of domain-specific phrases
in the various query sets that can be translated us-
ing our domain-specific dictionaries mined from the
web, but are incorrectly translated by WorldLingo.
Original Query WorldLingo Translation Improved Machine Translation
EN?IT
turner east sussex Turner Sussex orientale Turner East Sussex
still life flowers fiori di vita tranquilla fiori di Natura morta
francis bacon Francis Bacon Francesco Bacone
pop art arte di schiocco Pop art
m c escher escher di m. c Maurits Cornelis Escher
american 60?s americano 60?s americano Anni 1960
EN?ES
vanessa bell campana del vanessa Vanessa Bell
turner east sussex Turner sussex del este Turner East Sussex
henry moore moore del Henrio Henry Moore
still life flowers flores de la vida inmo?vil flores de Bodego?n
guerrilla girls muchachas del guerrilla Guerrilla Girls
IT?EN
leonardo da vinci leonardo from you win Da Vinci, Leonardo da Vinci,
Leonardo daVinci, Leonardo de Vinci
duomo di milano dome of Milan Cathedral of Milan, Duomo di Milan,
Duomo di Milano, Duomo of Milan, Milan Cathedral
beni culturali cultural assets Cultural heritage
arte povera poor art Arte povera
san lorenzo saint lorenzo Lawrence of Rome, Saint Lawrence, St Lawrence,
gentile da fabriano kind from fabriano Gentile da Fabriano
statua della liberta statue of the freedom Statue of Liberty
aldo rossi aldo red Aldo Rossi
arnaldo pomodoro arnaldo tomato Arnaldo Pomodoro
la cattura di cristo di caravaggio the capture of caravaggio Christ The Taking of Christ caravaggio
ES?EN
lope de vega lope of fertile valley Lope de Vega
literatura infantil infantile Literature Children?s book, Children?s books,Children?s literature
cantar de mio cid to sing of mine cid Cantar de mio Cid, Lay of the Cid, The Lay of the Cid
el quijote de la mancha quijote of the spot quijote of La Mancha
dulce maria loynaz candy Maria loynaz Dulce Mar??a Loynaz
andres bello andres beautiful Andre?s Bello
filosofia del derecho philosophy of the right Philosophy of law
elogio de la locura praise of madness In Praise of Folly, Praise of Folly, The Praise of Folly
la regenta it runs it La Regenta
cristobal colon cristobal colon Christopher Colombus, Christopher Columbus,
Cristopher Columbus
Table 3: Some examples of improved translations using the domain-specific dictionaries. (The corrected
phrase translations are in italic.)
Namely, we tested the ability of our system to
detect and correct the presence of unreliable MT
translations for domain-specific phrases. Translated
phrases for these queries can generally be judged
unambiguously as correct or incorrect by a bilin-
gual speaker of the languages involved, and so we
are confident that assessment of translation accuracy
here does not involve significant degrees of subjec-
tivity.
As shown in Table 1, we can see that 79%, 58%,
40%, and 45% of incorrect MT-translated phrases
were able to be corrected using the domain-specific
dictionaries mined from wikipedia, in EN?IT, EN?
ES, IT?EN, and ES?EN translation tasks, respec-
tively. Our system leads to a large improvement in
MT translation for domain-specific phrases. Some
examples of improved query translations are shown
in Table 3.
We also conducted an investigation on the cor-
rectness of the translation mined from wikipedia,
as shown in Table 2. Exact correct translation is
strictly-correct single translation. Extra translation
refers to strictly-correct multiple translations, for
example, ?Cathedral of Milan, Duomo di Milan,
Duomo di Milano, Duomo of Milan, Milan Cathe-
dral? (Italian: Duomo di Milano). It is interesting to
observe that about 50% of Italian phrases are found
to have multiple correct English translations due to
multiple English wikipedia pages being redirected
to the same Italian pages. Some minor noise is ob-
served when the correct translation contains some
related additional words, such as ?Alfonso XII of
Spain? (Spanish: Alfonso XII). When used for in-
formation retrieval, this additional information can
sometimes improve effectiveness.
We are not able to manually evaluate the accuracy
of all translation pairs in our bilingual dictionaries
due to limited resources. However, our results for
sample queries from user logs demonstrate that our
translations are generally highly accurate.
3.3 Intrinsic Evaluation Using IR System
Our information retrieval experiments were per-
formed on a database of metadata associated with a
collection of 5000 CH photographs. The metadata to
describe each artifact in the collection is available in
English and in Italian. Each photograph is described
identically in both languages. We formed a separate
search index for English and Italian. Search was car-
ried out using the Lucene search engine7. We carried
out an evaluation based on this collection which pro-
ceeded as follows:
1. Submit the original queries to the index and
record the ranked list of references returned.
2. Submit the translated queries to the appropriate
index and record the ranked list of references
returned.
3. Find the correlation between the lists returned
for the native language queries and the queries
translated to that language.
4. The better translation will have the stronger
correlation with the native language list.
Due to the fact that the corpus was only complete
in the Italian and English versions, we were unable
to include the Spanish queries in this part of the eval-
uation. Also, while this collection is based in the CH
domain, some of the queries yield no relevant docu-
ments due to their specialist nature. The collection
of queries for which meaningful retrieval results are
7http://lucene.apache.org/
returned is too small to allow for a quantitative anal-
ysis of retrieval effectiveness. Therefore, we present
a qualitative analysis of some of the more interesting
cases.
3.3.1 Italian?English translations
The Italian queries cover a wide range of Italian
interests in CH. We present here a sample of some
of the more interesting results.
Arnaldo Pomodoro This refers to an Italian artist,
but the name ?Pomodoro? is translated to ?Tomato?
in English by WorldLingo. While there were no
references to the artist in the collection, all docu-
ments returned contained the term ?tomato? (refer-
ring to the vegetable) which are irrelevant to the
query. The dictionary-based translation recognized
the name and therefore left it untranslated. It is
preferable to retrieve no documents rather than to
retrieve irrelevant ones.
Amore e Psiche This refers to the sculpture en-
titled ?Cupid and Psyche? in English. This phrase
was matched in our phrase dictionary and translated
correctly. The MT system translated this as ?Love,
Psyche?. The dictionary translation was observed
to retrieve relevant documents with greater precision
since it matched against the more specific term ?Cu-
pid?, as opposed to the more general term ?Love?.
David Michaelangelo This query provided a
counterexample. The phrase dictionary added the
term ?statue? to the translated query. This led to re-
trieval of a large number of non-relevant documents.
3.3.2 English?Italian translations
As with the Italian queries, there was not much
overlap between the query log and the document col-
lection. Some of the interesting translations include:
pop art This phrase was recognized by our
domain-specific dictionary, and so was left in its
original form for searching in Italian. Interestingly,
this led to an improvement in search accuracy for the
query compared to that in the English language col-
lection. For the English index, this phrase matched
many non-relevant documents which contained the
word ?art?. However, when searching in the Italian
index, where ?art? is not a word encountered in the
general vocabulary, the phrase retrieves only 7 doc-
uments, of which 5 were relevant.
Turner East Sussex The place name ?East Sus-
sex? was correctly recognized and translated by our
phrase dictionary. However the MT system again
failed to recognise it and translated the partial term
?East? to ?Orientale?. The presence of the term
?Orientale? in the translated query resulted in many
non-relevant documents being retrieved, reducing
the precision of the query.
The examples given in this section provide anec-
dotal evidence to support the view that the auto-
matically mined domain-specific phrase dictionary
improves the performance of the retrieval system.
Query sets and relevance judgements are being cre-
ated for the MultiMatch document set by domain ex-
perts who compiled the original collections. Thus
we will be able to ensure that the query sets are a
good representative sample of the information needs
of the typical user. These test collections will allow
us to conduct full quantitative analysis of our sys-
tem.
4 Conclusions
We have presented an automatic mining system de-
veloped for construction of domain-specific phrase
dictionaries. Phrases not translated by a general
MT system are shown to be translated effectively
using these dictionaries. The extracted translations
were evaluated by human assessment and shown to
be highly accurate. We have also demonstrated a
way to combine these dictionaries with MT for top-
ical phrases in the culture heritage domain. Our ex-
perimental results show that we were able to detect
and correct a large proportion of domain-specific
phrases unsuccessfully translated by MT, and thus
improve information retrieval effectiveness and fa-
cilitate MLIA.
5 Ongoing Work
In our ongoing work we plan to further extend the
coverage of our dictionaries by exploring the min-
ing of other translations pairs from within the linked
Wikipedia pages. While the method described in this
paper has been shown to be effective for query trans-
lation, we have so far only demonstrated its behav-
ior for a very small number of queries to our CLIA
system. We are currently developing test collections
based on several CH data sets to evaluate the effec-
tiveness of our hybrid query translation method.
Acknowledgement
Work partially supported by European Community
under the Information Society Technologies (IST)
programme of the 6th FP for RTD ? project Mul-
tiMATCH contract IST?033104. The authors are
solely responsible for the content of this paper. It
does not represent the opinion of the European Com-
munity, and the European Community is not respon-
sible for any use that might be made of data appear-
ing therein.
References
Sisay Fissaha Adafre and Maarten de Rijke. 2005. Dis-
covering missing links in Wikipedia. In Proceedings
of the 3rd International Workshop on Link Discovery,
pages 90?97, Chicago, Illinois, United States. ACM
Press.
Sisay Fissaha Adafre and Maarten de Rijke. 2006. Find-
ing similar sentences across multiple languages in
Wikipedia. In Proceedings of the 11th Conference of
the European Chapter of the Association for Compu-
tational Linguistics, pages 62?69, Trento, Italy.
Lisa Ballesteros and W. Bruce Croft. 1997. Phrasal
translation and query expansion techniques for cross-
language information retrieval. In Proceedings of the
20th Annual International ACM SIGIR Conference on
Research and Development in Information Retrieval,
pages 84?91, Philadelphia, PA, USA. ACM Press.
Gosse Bouma, Ismail Fahmi, Jori Mur, Gertjan van No-
ord, Lonneke van der Plas, and Jorg Tiedemann. 2006.
The University of Groningen at QA@CLEF 2006 us-
ing syntactic knowledge for QA. In Working Notes
for the Cross Language Evaluation Forum 2006 Work-
shop, Alicante, Spain.
Frans Coenen, Paul H. Leng, Robert Sanderson, and
Yanbo J. Wang. 2007. Statistical identification of key
phrases for text classification. In Machine Learning
and Data Mining in Pattern Recognition, volume 4571
of Lecture Notes in Computer Science, pages 838?853.
Springer.
Thierry Declerck, Asuncio`n Go`mez Pe`rez, Ovidiu Vela,
Zeno Gantner, and David Manzano-Macho. 2006.
Multilingual lexical semantic resources for ontology
translation. In Proceedings of the 5th International
Conference on Language Resources and Evaluation,
Genoa, Italy. ELDA.
Jianfeng Gao, Jian-Yun Nie, Endong Xun, Jian Zhang,
Ming Zhou, and Changning Huang. 2001. Improv-
ing query translation for cross-language information
retrieval using statistical models. In Proceedings of the
24th Annual International ACM SIGIR conference on
Research and Development in information retrieval,
pages 96?104, New Orleans, Louisiana, United States.
ACM Press.
Alexander F. Gelbukh, Grigori Sidorov, Sang-Yong Han,
and Erika Herna?ndez-Rubio. 2004. Automatic syn-
tactic analysis for detection of word combinations. In
Proceedings of the 5th International Conference on
Computational Linguistics and Intelligent Text Pro-
cessing, volume 2945 of Lecture Notes in Computer
Science, pages 243?247. Springer.
David A. Hull and Gregory Grefenstette. 1996. Query-
ing across languages: a dictionary-based approach to
multilingual information retrieval. In Proceedings of
the 19th Annual International ACM SIGIR Confer-
ence on Research and Development in Information Re-
trieval, pages 49?57, Zurich, Switzerland. ACM Press.
Rupali Sharma and S. Raman. 2003. Phrase-based text
representation for managing the web documents. In
Proceedings of the International Conference on Infor-
mation Technology: Computers and Communications,
page 165, Washington, DC, USA. IEEE Computer So-
ciety.
Tim Van de Cruys and Begon?a Villada Moiro?n. 2007.
Semantics-based multiword expression extraction. In
Proceedings of the Workshop on A Broader Perspec-
tive on Multiword Expressions, pages 25?32, Prague,
Czech Republic, June. Association for Computational
Linguistics.
Proceedings of the Workshop on Language Technology for Cultural Heritage Data (LaTeCH 2007), pages 81?88,
Prague, 28 June 2007. c?2007 Association for Computational Linguistics
Multilingual Search for Cultural Heritage Archives via Combining Multiple
Translation Resources
Gareth J. F. Jones, Ying Zhang, Eamonn Newman, Fabio Fantino
Centre for Digital Video Processing
Dublin City University
Dublin 9, Ireland
{gjones,yzhang,enewman,ffantino}
@computing.dcu.ie
Franca Debole
ISTI-CNR
Pisa
Italy
franca.debole
@isti.cnr.it
Abstract
The linguistic features of material in Cul-
tural Heritage (CH) archives may be in var-
ious languages requiring a facility for ef-
fective multilingual search. The specialised
language often associated with CH content
introduces problems for automatic transla-
tion to support search applications. The
MultiMatch project is focused on enabling
users to interact with CH content across
different media types and languages. We
present results from a MultiMatch study ex-
ploring various translation techniques for
the CH domain. Our experiments ex-
amine translation techniques for the En-
glish language CLEF 2006 Cross-Language
Speech Retrieval (CL-SR) task using Span-
ish, French and German queries. Re-
sults compare effectiveness of our query
translation against a monolingual baseline
and show improvement when combining a
domain-specific translation lexicon with a
standard machine translation system.
1 Introduction
Online Cultural Heritage (CH) content is being pro-
duced in many countries by organisations such as
national libraries, museums, galleries and audiovi-
sual archives. Additionally, there are increasing
amounts of CH relevant content available more gen-
erally on the World Wide Web. While some of this
material concerns national or regional content only
of local interest, much material relates to items in-
volving multiple nations and languages, for exam-
ple concerning events in Europe or Asia. In order to
gain a full understanding of such events, including
details contained in different collections and explor-
ing different cultural perspectives requires effective
multilingual search technologies. Facilitating search
of this type requires translation tools to cross the lan-
guage barrier between users and the available infor-
mation sources.
CH content encompasses various different media,
including of course text documents, images, videos,
and audio recordings. Search of text documents be-
tween languages forms the focus of cross-language
information retrieval (CLIR) research, while search
for images is the concern of content-based image re-
trieval. However, whatever the media of the items
they are accompanied by metadata. Such metadata
may include simple factual details such as date of
creation, but also descriptive details relating to the
contents of the item. Multilingual searching using
metadata content requires that either the metadata
be translated into a language with which the user is
able to search or that the search query be translated
into the language of the metadata. This alternative
of document or query translation is a well rehearsed
argument in CLIR, which has generally concerned
itself with full text document searching. However,
the features of metadata require a more careful anal-
ysis. Metadata is typically dense in search terms,
while lacking the linguistic structure and informa-
tion redundancy of full text documents. The absence
of linguistic structure makes precise translation of
content problematic, while the lack of redundancy
means that accurate translation of individual words
81
and phrases is vital to minimise mismatch between
query and document terms. Furthermore, CH con-
tent is typically in specialised domains requiring do-
main specific resources for accurate translation. De-
veloping reliable and robust approaches to transla-
tion for metadata search is thus an important com-
ponent of search for many CH archives.
The EU FP6 MultiMatch1 project is concerned
with information access for multimedia and multi-
lingual content for a range of European languages.
In the investigation reported in this paper we intro-
duce the first stage multilingual search functional-
ity of the MultiMatch system, and describe its use
in an investigation for multilingual metadata search.
Since at present we do not have a search test collec-
tion specifically developed for MultiMatch we use
data from the CLEF 2006 Cross-Language Speech
Retrieval (CL-SR) task for our experiments (Oard et
al., 2006).
The remainder of this paper is organised as fol-
lows: Section 2 gives an overview of the MultiMatch
search architecture, Section 3 outlines the experi-
mental search task, Section 4 describes the trans-
lation resources used for this study, Section 5 and
6 concern our experimental setup and results, and
finally Section 7 summarises our conclusions and
gives details of our ongoing work.
2 MultiMatch Search System
The MultiMatch search system is centered on the
MILOS Multimedia Repository system (Amato et
al., 2004) which incorporates free-text search using
Lucene (Hatcher and Gospodnetic, 2004) and im-
age search using an open source image retrieval sys-
tem GIFT (Mu?ller et al, 2001). In order to support
multilingual searching a number of translation tools
are being developed based on standard online ma-
chine translation tools and dictionaries augmented
with domain-specific resources gathered from the
WWW and elsewhere. In this section we briefly in-
troduce the relevant details of MILOS and Lucene.
Since this paper focuses on text search within Mul-
tiMatch, we do not describe the multimedia features
of the MultiMatch system.
1www.multimatch.org
2.1 MILOS: Multimedia Repository
MILOS (Multimedia dIgital Library for On-line
Search) is a repository system conceived to support
the distributed storage and retrieval of multimedia
objects. This Multimedia Content Management Sys-
tem (MCMS) is able to manage not only structured
data, as in databases, but also textual data (using
information retrieval technologies), semi-structured
data (typically in XML), mixed-mode data, and mul-
timedia data. In MultiMatch, we use MILOS as a
metadata repository to enable querying on the struc-
ture of the data stored.
MILOS has a three-tier architecture composed of
three main components:
1. the XML Search Engine (XMLSE) component
which manages the metadata;
2. the MultiMedia Server (MMS) component
which manages the documents; and
3. the MultiMedia Digital Library service
(MMDLS) component MMDLS which pro-
vides application developers with a uniform
and integrated way of accessing MMS and
XMLSE.
Each of these components is implemented using
solutions providing flexibility, scalability, and effi-
ciency.
2.1.1 XMLSE
XMLSE is an enhanced native XML
database/repository system with special features
for digital library applications. This is especially
justified by the well known and accepted advantages
of representing metadata as XML documents.
Metadata represented with XML can have arbitrary
complex structures, which allows it to handle with
complex metadata schemas, and can easily be
exported and imported. Our XML database can
store and retrieve any valid XML document. No
metadata schema or XML schema definition is
needed before inserting an XML document, except
optional index definitions for performance boosting.
Once an arbitrary XML document has been inserted
in the database it can be immediately retrieved using
XQuery. This allows digital library applications to
use arbitrary (XML encoded) metadata schemas
82
and to deal with heterogeneous metadata, without
any constraint on schema design and/or overhead
due to metadata translation. Thus, the native XML
database/repository system is simpler than a general
purpose XML database system, but offers signif-
icant improvements in specific areas: it supports
standard XML query languages such as XPath and
XQuery, and offers advanced search and indexing
functionality on arbitrary XML documents. It
supports high performance search and retrieval on
heavily structured XML documents, relying on
specific index structures.
Moreover XMLSE provides the possibility of us-
ing particular indexes. For example, using the con-
figuration file of XMLSE the system administrator
can associate the <abstract> elements of a doc-
ument with a full-text index and to the MPEG-7
<VisualDescriptor> elements can be associated
with a similarity search index. XMLSE uses Apache
Lucene2 to provide partial (or approximate) text
string matching, effectively providing information
retrieval functionality within MILOS. This allows
XMLSE to use the ranked searching and wildcard
queries of Lucene to solve queries like ?find all the
articles whose title contains the word XML? and
so on. This application allows users to interrogate
the dataset combining full text, and exact or partial
match search. For example the user can look for
documents whose <metadata> element contains the
word ?Switzerland?. MILOS generates and submits
to XMLSE the following XQuery query:
for $a in /document where
$a//metadata ? ?Switzerland?
return
<result>
{$a//title}, {$a//author}
</result>
The query will return a list of results which con-
sist of the title and author of all documents whose
metadata contains the term ?Switzerland?.
2.2 Lucene
Full text search in MILOS is provided by using
Lucene as a plugin. Ranked retrieval uses the
standard tf ? idf vector-space method provided in
Lucene (Hatcher and Gospodnetic, 2004). Lucene
also provides additional functionality to improve re-
2http://lucene.apache.org
trieval effectiveness by providing various query ex-
pansion services using techniques such as relevance
feedback, although these are not used in the current
investigation. Documents and search requests are
preprocessed to remove stop words and stemming is
applied using the standard resources supplied with
Lucene.
3 Evaluation Task
The MultiMatch system will enable search from a
number of CH repository sources including formally
published documents, images and video, as well
as material gathered from relevant WWW sources.
However, in order to explore metadata search is-
sues and evaluate our approaches to addressing re-
lated translation problems, a test collection includ-
ing sample user search topics and relevance judge-
ments is required. Since MultiMatch does not yet
have such a collection available, for our current ex-
periments we made use of the data provided for the
CLEF 2006 CL-SR track (Oard et al, 2006).
The document collection comprises 8104 En-
glish documents that are manually-determined
topically-coherent segments taken from 272 in-
terviews with Holocaust survivors, witnesses and
rescuers, totaling 589 hours of speech. Sev-
eral automatic speech recognition transcripts are
available for these interviews. However, for this
study we focus on the metadata fields provided
for each document: two sets of 20 automati-
cally assigned keywords (<AUTOKEYWORD2004A1>
and <AUTOKEYWORD2004A2>) determined using two
different kNN classifiers, denoted by AKW1 and
AKW2 respectively; a set of a varying number of
manually-assigned keywords (<MANUALKEYWORD>),
denoted by MKW; and a manual three-sentence
summary written by an expert in the field
(<SUMMARY>), denoted by SUMMARY.
The CLEF collection includes a set of 33 search
topics in standard TREC format created in English,
and translated into Czech, German, French, and
Spanish by native speakers. Since we wish to in-
vestigate topics with minimal redundancy, for our
experiments we used only the topic Title fields as
our search request. Relevance judgments were gen-
erated using a search guided procedure and standard
pooling methods were also provided with the collec-
83
tion. Full details of the this collection can be found
in (Oard et al, 2006; White et al, 2005).
To explore metadata field search, we used various
methods, described in the next section, to automati-
cally translate the French, German, and Spanish top-
ics into English3.
4 Translation Techniques
The MultiMatch translation resources are based on
the WorldLingo machine translation system aug-
mented with domain-specific dictionary resources
gathered automatically from the WWW. This section
briefly reviews WorldLingo4, and then describes
construction of our augmentation translation lexi-
cons and their application for query translation in
multilingual metadata search.
4.1 Machine translation system
There are a number of commercial machine transla-
tion systems currently available. After evaluation of
several candidate systems, WorldLingo was selected
for the MultiMatch project because it generally gives
good translation well between the English, Spanish,
Italian, and Dutch, languages relevant to the Mul-
timatch project5. In addition, it provides a useful
API that can be used to translate queries on the fly
via HTTP transfer protocol. The usefulness of such
a system is that it can be integrated into any appli-
cation and present translations in real-time. It al-
lows users to select the source/target languages and
specify the text format (e.g. plain text file or html
file) of their input files. The WorldLingo translation
system also provides various domain-specific dictio-
naries that can be integrated with translation system.
A particularly useful feature of WorldLingo with re-
spect to for MultiMatch, and potentially applications
within CH in general, is that to improve the qual-
ity of translations, additional locally developed cus-
tomized dictionaries can be uploaded. This enables
the WorldLingo dictionaries to be extended to con-
tain special terms for a specific domain.
3Due to a lack of translation resources, we did not use the
Czech translations in these experiments
4http://www.worldlingo.com/
5Additionally, it translates well between French and En-
glish, as used in this paper
4.2 Translation lexicon construction
To extend the standard dictionaries provided with
WorldLingo we used the current online wikipedia.
Wikipedia6 is the largest multilingual free-content
encyclopedia on the Internet. As of March 21 2007,
there are approximately 6.8 million articles written
in 250 languages available on the web, according
to Wiki Stats7. Wikipedia is structured as an in-
terconnected network of articles. Each wikipedia
page can hyperlink to several other wikipedia pages.
Wikipedia page titles in one language are also linked
to a multilingual database of corresponding terms.
Unlike the web, most hyperlinks in wikipedia have
a more consistent and semantically meaningful in-
terpretation and purpose. The comprehensive liter-
ature review presented by Adafre and Rijke (2005)
describes the link structure of wikipedia. As a mul-
tilingual hypertext medium, wikipedia presents a
valuable new source of translation information. Re-
cently, researchers have proposed techniques to ex-
ploit this opportunity. Adafre and Rijke (2006) de-
veloped a technique to identify similar text across
multiple languages in wikipedia using page content-
based features. Boumaet et al (2006) utilized
wikipedia for term recognition and translation in
order to enhance multilingual question answering
systems. Declerck et al (2006) showed how the
wikipedia resource can be used to support the su-
pervised translation of ontology labels.
In order to improve the effectiveness of multilin-
gual metadata search, we mine wikipedia pages as
a translation source and construct translation lex-
icons that can be used to reduce the errors intro-
duced by unknown terms (single words and multi-
word phrases) during query translation. The major
difference in our proposal is that the translations are
extracted on the basis of hyperlinks, meta keywords,
and emphasized concepts ? e.g. anchor text, bold-
face text, italics text, and text within special punc-
tuation marks ? appearing in the first paragraph of
wikipedia articles.
Meta keywords Wikipedia pages typically contain
meta keywords assigned by page editors. This
meta keywords can be used to assist in the iden-
6http://www.wikipedia.org/
7http://s23.org/wikistats/wikipedias
html.php?sort=good desc
84
tification of the associated terms on the same
topic.
Emphasized concepts In common with standard
summarization studies, we observed that the
first paragraph of a wikipedia document is usu-
ally a concise introduction to the article. Thus,
concepts emphasized in the introductory sec-
tion are likely to be semantically related to the
title of the page.
In our study we seek to use these features from
multilingual wikipedia pages to compile a domain-
specific word and phrase translation lexicon. Our
method in using this data is to augment the queries
with topically related terms in the document lan-
guage through a process of post-translation query
expansion. This procedure was performed as fol-
lows:
1. An English vocabulary for the domain of the
test collection was constructed by performing a
limited crawl of the English wikipedia8, Cate-
gory:World War II. This category contains links
to pages and subcategories concerning events,
persons, places, and organizations pertaining
to war crimes or crimes against humanity es-
pecially during WWII. It should be noted that
this process was neither an exhaustive crawl
nor a focused crawl. The purpose of our cur-
rent study is to explore the effect of translation
expansion on metadata retrieval effectiveness.
In total, we collected 7431 English web pages.
2. For each English wikipedia page, we extracted
its hyperlinks to German, Spanish, and French.
The basename of each hyperlink is considered
as a term (single word or multi-word phrase
that should be translated as a unit). This pro-
vided a total of 4446 German terms, 3338
Spanish terms, and 4062 French terms. As an
alternative way of collecting terms in German,
Spanish, and French, we are able to crawl the
wikipedia in a specific language. However, a
page with no link pointing to its English coun-
terpart will not provide enough translation in-
formation.
8en.wikipedia.org
RUN ID
Augmented lexicon using all terms
appearing in the following fields
Title Meta Emphasized
terms keywords concepts
RUNmt+t
?
? ?
RUNmt+m ?
?
?
RUNmt+c ? ?
?
RUNmt+m+c ?
? ?
Table 1: Run descriptions.
3. For each of the German, Spanish, and French
terms obtained, we used the title term, the meta
keywords, and the emphasized concepts ob-
tained from the same English wikipedia page
as its potential translations.
For example, consider an English page titled as
?World War II?9. The title term, the meta keywords,
the emphasized concepts in English, and the hyper-
links (to German, Spanish, and French) associated
are shown in Figure 1. We first extract the base-
names ?Zweiter Weltkrieg? (in German), ?Segunda
Guerra Mundial? (in Spanish), and ?Seconde Guerre
mondiale? (in French) using the hyperlink feature.
To translate these terms into English, we replace
them using the English title term, all the English
meta keywords and/or all the English emphasized
concepts occurring in the same English wikipedia
page. This is a straightforward approach to au-
tomatic post-translation query expansion by using
meta keywords and/or emphasized concepts as ex-
panded terms. The effects of the features described
above are investigated in this work, both separately
and in combination, as shown in Table 1,
5 Experimental Setup
In this section we outline the design of our exper-
iments. We established a monolingual reference
(RUNmono) against which we can measure multilin-
gual retrieval effectiveness. To provide a baseline
for our multilingual results, we used the standard
WorldLingo to translate the queries (RUNmt). We
then tested the MT integrated with different lexicons
compiled using wikipedia. Results of these experi-
ments, shown in Table 1, enable us gauge the effect
of each of our additional translation resources gen-
erated using wikipedia.
9http://en.wikipedia.org/wiki/World War
II
85
Title: World War II
Hyperlink to German: http://de.wikipedia.org/wiki/Zweiter_Weltkrieg
Hyperlink to Spanish: http://es.wikipedia.org/wiki/Segunda_Guerra_Mundial
Hyperlink to French: http://fr.wikipedia.org/wiki/Seconde_Guerre_mondiale
Meta keywords:
World War II, WWII history by nation, WWII history by nation, 101st Airborne 
Division, 11th SS Volunteer Panzergrenadier Division Nordland, 15th Army Group,
1937, 1939, 1940
Emphasized concepts:
World War II (abbreviated WWII), or the Second World War, was a worldwide conflict
which lasted from 1939 to 1945. World War II was the amalgamation of two 
conflicts, one starting in Asia as the Second Sino-Japanese War, and the other 
beginning in Europe with the Invasion of Poland. The war was caused by the 
expansionist and hegemonic ambitions of Germany, Italy, and Japan and economic 
tensions between all major powers.
Figure 1: Title, hyperlinks, meta keywords, and emphasized concepts (underlined terms) extracted from the
English wikipedia page http://en.wikipedia.org/wiki/World War II.
The focus of this paper is not on optimising ab-
solute retrieval performance, but rather to explore
the usefulness of our translation resources. Thus
we do not apply retrieval enhancement techniques
such as relevance feedback which would make it
more difficult to observe the impact of differences
in behaviour of the translation resources. The ex-
periments use the SUMMARY field, as an exam-
ple of concise natural language descriptions of CH
objects; and the AKW1 and AKW2 fields as exam-
ples of automatically assigned keyword labels with-
out linguistic structure, with the MKW field provid-
ing similar manually assigned for keyword labels.
Retrieval effectiveness is evaluated using standard
TREC mean average precision (MAP) and the pre-
cision at rank 10 (P@10).
6 Results and Discussion
The results of our query translation experiments are
shown in Table 2, 3, 4, and 5. For search using SUM-
MARY and MKW fields, the lexicon compiled us-
ing title terms provided an improvement of 7? 9%,
7 ? 19%, and 20 ? 30%, in German?English,
Spanish?English, and French?English retrieval task,
respectively. These improvements are statistically
significant at the 95% confidence level, and empha-
size the importance of a good domain-specific trans-
lation lexicon.
The addition of meta keywords or emphasized
concepts also improves results in most cases relative
to the RUNmt results. However, we can see that re-
trieval performance degrades when the query is ex-
panded to contain terms from both meta keywords
and emphasized concepts. This occurs despite the
fact that the additional terms are often closely re-
lated to the original query terms. While the addition
of all these terms generally produces an increase in
the number of retrieved documents, there is little or
no increase in the number of relevant documents re-
trieved, and the combination of the two sets of terms
in the queries leads on average to a slight reduce in
the rank of relevant documents.
The results show that RUNmt+t runs provide the
best results when averaged across a query set. How-
ever, when analysed at the level of individual queries
different combined translation resources are more
effective for different queries, examples of this ef-
fect are shown in Table 6. This suggests that it may
be possible to develop a more sophisticated transla-
tion expansion methods to select the best terms from
different lexicons. At the very least, it should be pos-
sible to use ?context-sensitive filtering? and ?com-
bination of evidence? (Smets, 1990) approaches to
improve the overall translation quality. We plan to
explore this method in further investigations.
7 Conclusion and Future Work
This paper reports experiments with techniques de-
veloped for domain-specific lexicon construction to
facilitate multilingual metadata search for a CH re-
86
RUN ID German?English Spanish?English French?EnglishMAP P@10 MAP P@10 MAP P@10
RUNmt 0.0750 0.1233 0.0756 0.1250 0.0652 0.1152
RUNmt+t 0.0815 0.1516 0.0899 0.1545 0.0783 0.1333
RUNmt+m 0.0775 0.1266 0.0797 0.1364 0.0690 0.1030
RUNmt+c 0.0669 0.1000 0.0793 0.1303 0.0770 0.1152
RUNmt+m+c 0.0668 0.0968 0.0737 0.1212 0.0646 0.0970
RUNmono MAP = 0.1049 P@10 = 0.1818
Table 2: Results for SUMMARY field search. (RUNmt+t run provides the best results in all cases.)
RUN ID German?English French?English Spanish?EnglishMAP P@10 MAP P@10 MAP P@10
RUNmt 0.1158 0.1750 0.1000 0.1677 0.0903 0.1677
RUNmt+t 0.1235 0.2100 0.1071 0.2031 0.1171 0.2194
RUNmt+m 0.1171 0.1393 0.1023 0.2000 0.0983 0.1903
RUNmt+c 0.1084 0.1500 0.0958 0.1636 0.1089 0.1667
RUNmt+m+c 0.1069 0.1600 0.0947 0.1727 0.0940 0.1742
RUNmono MAP = 0.1596 P@10 = 0.2812
Table 3: Results for MKW field search. (RUNmt+t run provides the best results in all cases.)
RUN ID German?English French?English Spanish?EnglishMAP P@10 MAP P@10 MAP P@10
RUNmt 0.0264 0.0731 0.0247 0.0548 0.0316 0.0767
RUNmt+t 0.0273 0.0828 0.0274 0.0656 0.0406 0.0867
RUNmt+m 0.0268 0.0633 0.0258 0.0606 0.0357 0.0613
RUNmt+c 0.0266 0.0667 0.0266 0.0636 0.0383 0.0839
RUNmt+m+c 0.0259 0.0633 0.0260 0.0606 0.0328 0.0677
RUNmono MAP = 0.0388 P@10 = 0.1000
Table 4: Results for AKW1 field search. (RUNmt+t run provides the best results in all cases.)
RUN ID German?English French?English Spanish?EnglishMAP P@10 MAP P@10 MAP P@10
RUNmt 0.0279 0.0375 0.0347 0.0625 0.0205 0.0483
RUNmt+t 0.0279 0.0481 0.0351 0.0680 0.0238 0.0433
RUNmt+m 0.0302 0.0448 0.0361 0.0556 0.0223 0.0484
RUNmt+c 0.0275 0.0414 0.0332 0.0593 0.0268 0.0548
RUNmt+m+c 0.0299 0.0448 0.0351 0.0536 0.0273 0.0581
RUNmono MAP = 0.0420 P@10 = 0.0821
Table 5: Results for AKW2 field search. (The best results are in bold.)
trieval tasks. The results show that our techniques
can provide a statistically significant improvement
in the retrieval effectiveness. Using a tailored trans-
lation lexicon enables us to achieve (77%, 78%),
(86%, 67%) and (75%, 63%) of the monolingual ef-
fectiveness in German?English, Spanish?English,
and French?English multilingual metadata SUM-
MARY, MKW field search tasks. In addition, the
multilingual wikipedia proved to be a rich resource
of translations for domain-specific terms.
Intuitively, document translation is superior to
query translation. Documents provide more context
for resolving ambiguities (Oard, 1998) and the trans-
lation of source documents into all the languages
supported by the retrieval system effectively reduces
CLIR to a monolingual IR task. Furthermore, it has
the added advantage that document content is acces-
sible to users in their native languages. In our future
work, we will compare the effectiveness of these two
approaches to metadata search in a multilingual en-
vironment.
87
Query ID
MT Augmented lexicon using all terms appearing in the following fields
WorldLingo Title terms Meta keyword Emphasized concepts Meta keyword +Emphasized concepts
German?English 1133 0.6000 0.6000 0.6195 0.6092 0.6400
1325 0.0000 0.0003 0.0020 0.0020 0.0018
1623 0.2210 0.2210 0.3203 0.0450 0.0763
3007 0.0000 0.0003 0.0025 0.0047 0.0054
3012 0.0087 0.0087 0.0073 0.0073 0.0097
3025 0.0052 0.0052 0.0060 0.0052 0.0060
Spanish?English 1623 0.0063 0.0063 0.1014 0.0084 0.0334
3007 0.0000 0.0004 0.0028 0.0048 0.0057
French?English 1133 0.6000 0.6000 0.6195 0.6092 0.6400
1345 0.0600 0.0667 0.0809 0.0495 0.0420
1623 0.0750 0.0798 0.1810 0.0228 0.0528
3005 0.0200 0.0232 0.0226 0.2709 0.1063
3007 0.0003 0.0003 0.0024 0.0025 0.0037
3025 0.0173 0.0173 0.0178 0.0173 0.0178
Table 6: Examples of MAP values obtained using different translation combinations for SUMMARY field
search. (The best results are in bold.)
Acknowledgement
Work partially supported by European Community
under the Information Society Technologies (IST)
programme of the 6th FP for RTD - project Mul-
tiMATCH contract IST- 033104. The authors are
solely responsible for the content of this paper. It
does not represent the opinion of the European Com-
munity, and the European Community is not respon-
sible for any use that might be made of data appear-
ing therein.
References
Sisay Fissaha Adafre and Maarten de Rijke. 2005. Discovering
missing links in wikipedia. In Proceedings of the 3rd inter-
national workshop on Link discovery, pages 90?97, Chicago,
Illinois. ACM Press.
Sisay Fissaha Adafre and Maarten de Rijke. 2006. Finding
similar sentences across multiple languages in wikipedia. In
Proceedings of the 11th Conference of the European Chapter
of the Association for Computational Linguistics, pages 62?
69, Trento, Italy.
Giuseppe Amato, Claudio Gennaro, Fausto Rabitti, and
Pasquale Savino. 2004. Milos: A multimedia content man-
agement system for digital library applications. In Proceed-
ings of the 8th European Conference on Research and Ad-
vanced Technology for Digital Libraries, Lecture Notes in
Computer Science, pages 14?25. Springer-Verlag.
Gosse Bouma, Ismail Fahmi, Jori Mur, Gertjan van Noord, Lon-
neke van der Plas, and Jorg Tiedemann. 2006. The univer-
sity of groningen at QA@CLEF 2006 using syntactic knowl-
edge for QA. In Working Notes for the Cross Language
Evaluation Forum 2006 Workshop, Alicante, Spain.
Thierry Declerck, Asuncio`n Go`mez Pe`rez, Ovidiu Vela, Zeno
Gantner, and David Manzano-Macho. 2006. Multilingual
lexical semantic resources for ontology translation. In Pro-
ceedings of the 5th International Conference on Language
Resources and Evaluation, Genoa, Italy.
Erik Hatcher and Otis Gospodnetic. 2004. Lucene in Action (In
Action series). Manning Publications Co., Greenwich, CT,
USA.
Henning Mu?ller, Wolfgang Mu?ller, and David McG. Squire.
2001. Automated benchmarking in content-based image re-
trieval. In Proceedings of the 2001 IEEE International Con-
ference on Multimedia and Expo, Tokyo, Japan. IEEE Com-
puter Society.
Douglas W. Oard, Jianqiang Wang, Gareth J. F. Jones, Ryen W.
White, Pavel Pecina, Dagobert Soergel, Xiaoli Huang, and
Izhak Shafran. 2006. Overview of the CLEF-2006 cross-
language speech retrieval track. In Working Notes for the
Cross Language Evaluation Forum 2006 Workshop, Ali-
cante, Spain.
Douglas W. Oard. 1998. A comparative study of query
and document translation for cross-language information re-
trieval. In Proceedings of the 3rd Conference of the Associ-
ation for Machine Translation in the Americas on Machine
Translation and the Information Soup, pages 472?483, Lon-
don, UK. Springer-Verlag.
Philippe Smets. 1990. The combination of evidence in the
transferable belief model. IEEE Transaction on Pattern
Analysis and Machine Intelligence, 12(5):447?458.
Ryen W. White, Douglas W. Oard, Gareth J. F. Jones, Dagobert
Soergel, and Xiaoli Huang. 2005. Overview of the CLEF-
2005 cross-language speech retrievaltrack. In Carol Pe-
ters, Fredric C. Gey, Julio Gonzalo, Henning Mu?ller, Gareth
J. F. Jones, Michael Kluck, Bernardo Magnini, and Maarten
de Rijke, editors, CLEF, volume 4022 of Lecture Notes in
Computer Science, pages 744?759. Springer.
88
Zock/Rapp/Huang (eds.): Proceedings of the 4th Workshop on Cognitive Aspects of the Lexicon, pages 87?98,
Dublin, Ireland, August 23, 2014.
Jibiki-LINKS: a Tool between Traditional Dictionaries and Lexical Networks for Modelling Lexical Resources  
ZHANG Ying1, 2 Mathieu MANGEOT1 Val?rie BELLYNCK1 Christian BOITET1 1. GETALP-LIG, 41 rue des Math?matiques BP53, 38041 Grenoble Cedex 2. SAS Lingua et Machina, Domaine de Voluceau, Rocquencourt, 78153 Le Chesnay  {ying.zhang, mathieu.mangeot, valerie.bellynck, christian.boitet}@imag.fr  
 Abstract  Between simple electronic dictionaries such as the TLFi (computerized French Language Treasure)1 and lexical networks like WordNet2 (Diller et al., 1990; Vossen, 1998), the lexical databases are growing at high speed. Our work is about the addition of rich links to lexical databases, in the context of the parallel development of lexical networks. Current research on management tools for lexical databases is strongly influenced by the field of massive data ("big data") and by the Web of data ("linked data"). In lexical networks, one can build and use arbitrary links, but possible queries cannot model all the usual interactions with lexicographers-developers and users, that are needed, and derive from the paper world. Our work aims to find a solution that allows for the main advantages of lexical networks, while providing the equivalent of paper dictionaries by doing the lexicographic work in lexical DBs.  1 Introduction  The growing importance of IT in all human activities extends and expands the needs and usages of all key digital resources that include lexical resources. Thus, while applications valuing the linguistic processes rely on increasingly abstract representations, modelled for computer operations, it remains that models coming from the historical construction of resources foster human understanding, and therefore, the building of tools for studies centring on the humanities.  In this this section, we place the emergence of the concept of lexical database between electronic dictionaries and lexical networks. We show that this concept is still valid, that it is still necessary to enrich it, and that our work on improving tools for lexical databases helps solve real problems.  To do this, we analyse in the second section the evolution of lexical resources in 4 main steps (simple electronic dictionaries, simple lexical databases, multilevel and multiversion lexical databases, and lexical networks) and present the associated problems. In the third section, we present Jibiki-LINKS, a platform for building multilingual lexical databases that enriches the Jibiki generic platform by introducing the concept of rich link between the components it manages (dictionary entries and dictionary volumes). Finally, we show that it allows the construction of lexical databases such as Pivax-UNL, which support scaling up.  2 From computerized dictionaries to lexical databases with rich links  The first computerized lexical resources are electronic versions of printed dictionaries, mainly monolingual or bilingual. The use of computers has helped to overcome the constraints of the paper form. The impossibility to inverse bilingual dictionaries led to a model having a "pivot" consisting of axies3. Lexical pivot-based databases are invertible and transitive, but rooted on the form of the 
                                                This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http:// creativecommons.org/licenses/by/4.0/ 1 http://atilf.atilf.fr 2 http://wordnet.princeton.edu 3 "Axie" = "interlingual meaning," by analogy with "lexie". 
87
symbols, while the lexical networks allow a move towards the direct manipulation of semantic tokens, regardless of their surface form, and thus of the language.  In this section, we present the evolution of approaches, distinguishing four main types of lexical resources, the limitations that motivated this evolution, and the remaining hard problems.  2.1 Simple electronic dictionaries  A simple electronic dictionary is an electronic version of a printed dictionary, or the computer representation of a new kind of the same type of dictionary, for example, the TLFi4, the morphological and bilingual dictionaries of Apertium5, etc. A simple electronic dictionary contains either one volume or two volumes. The electronic version of a monolingual paper dictionary is (usually implicitly) based on its microstructure, that is to say, on the organization of its entries in the form of a small tree organizing the information it contains. In a paper dictionary, the presentation of an entry reflects the microstructure, but the microstructure is not always directly retrievable from it (for example, parts in italics can correspond to different types of information units, such as idiom or example of use). In absolute terms, it is always possible to represent the information specified in each entry of a dictionary according to a common structure. In reality, the structures of paper dictionaries are less rigorous than what would be required for automatic processing, so that manual editing is required.  A bilingual paper dictionary is generally based on a structure in two volumes, one for each language pair, each volume conforming to the same microstructure. There are therefore generally one volume from language A (Lg A) to language B (Lg B) and a mirror volume from Lg B to Lg A. We define the macrostructure of a dictionary as the organization of the volumes that make up its structure. These macrostructures constitute the bulk of the printed dictionaries.  2.2 Lexical databases  A lexical database is a tool for unifying any set of dictionaries, where each dictionary can be monolingual, bilingual or multitarget. A multilingual lexical database is composed of volumes that are monolingual, direct multilingual, or indirect multilingual, i.e. connecting the entries of different languages via a pivot structure. It has an overall macrostructure, and a microstructure for each of its volumes. A link between 2 entries is realized by the software tool as a direct link, or as 2 links going through an intermediate language, or as a semantic link, etc.  The lack of symmetry of the correspondence between the entries of bilingual dictionaries (from word senses to words, not word senses) led to the concept of interlingual pivot. In the pivot macrostructure developed and used for the Papillon-NADIA multilingual lexical database (S?rasset and Mangeot, 2001), there is only one monolingual volume for each language. Lexies are word senses (of a lexeme or an idiom) and make up the entries of these volumes. To group the lexies of different languages together, there is a pivot volume of axies (interlingual acceptions). An axie connects synonymous lexies. The links are established only between lexies and axies. This is the simplest macrostructure for a pivot-based multilingual lexical resource that allows for the extraction of usage dictionaries for all pairs in all directions. The concept of axie-based pivot structure has been validated by the Papillon project and then included in the Lexical Markup Framework standard (Francopoulo et al. 2009).  2.3 Multilevel and multiversion databases  In this type of lexical database, several monolingual volumes are allowed for each lexical space6, A volume of axemes (monolingual acceptions) is introduced to link synonymous lexies of the considered lexical space. Also, various levels are introduced to tag entries according to different points of view (sublanguage, version, type of link, reliability, preference). The simple links of previous versions are replaced by rich links that can be established not only between lexies, axemes and axies, but also between entries and subentries, monolingually (lexicosemantic functions) or bilingually (translations).                                                  4 Tr?sor de la Langue Fran?aise informatis?, http://atilf.atilf.fr/ 5 http://wiki.apertium.org/wiki/User:Alessiojr/Easy_dictionary_-_Application-GSOC2010 6 A lexical space of a natural language contains various levels (wordform, lemma, lexie, prolexeme, proaxeme); it can also contain the lexical symbols of an artificial semantic representation language (e.g., the UWs of UNL). 
88
For example, there is a 3-level macrostructure (lexie, axeme, axie) in PIVAX (Nguyen & al., 2007) and a 4-level macrostructure (lexie, prolexeme, proaxie, axie) in ProAxie (Zhang & Mangeot, 2013), described in more detail in section 4.1. Both allow us to manage one or more monolingual volumes for each lexical space. That has been quite useful in the ANR Traouiero GBDLex-UW++ subproject, during which we stored the UNL part of many UNL-Li dictionaries (the UW interlingual lexemes, built with slightly different conventions by different UNL groups for their languages), and tried then to unify them in a new monolingual UNL dictionary (using a set of "UW++" built from WordNet and from the previous UNL dictionaries).  2.4 Lexical network  A lexical network brings together the set of words that denote ideas or realities that refer to the same theme, as well as all the words that, because of the context and certain aspects of their meaning, also evoke this theme7. The theme may possibly be very broad. It is possible to represent the full vocabulary of a language in a lexical network, such as, for French, the JeuxDeMots network (Lafourcade and Joubert, 2010) or RFL (Lexical Network of French (Lux-Pogodalla, Polgu?re 2011)).  Lexical networks are traditionally represented as graphs. Nodes represent the lexemes of one or more languages, and links represent the relationships between these lexemes (translation, synonymy, etc.). A lexical network can be monolingual or multilingual. One can create syntactic, morphological and semantic relations between lexemes.  Although lexical networks have many advantages, they are not suitable for all usages. For example, lexical networks like WordNet (Diller & al., 1990; Vossen, 1998), HowNet (Dong et al., 2010) and MindNet (Dolan and Richardson, 1996) (Richardson et al., 1998) are not browsable in alphabetical order. But we need that possibility to have an idea of the content of a lexical repository, whatever its nature, or to play word games, or to find a word one has on the tip of the tongue8. On the other hand, in a lexical network, the concept of volume is missing, which prevents to create a resource in a simple way when studying a new language.  For example, the lexical network DBNary (S?rasset, 2012), which is based on the Lemon model (McCrae et al., 2011), contains millions of terms, but does not allow labelling the links. To navigate in this system, one must write SPARQL queries, which is not within the reach of everyone.  2.5 Conclusion: features, limitations and hard problems  Research efforts focus today mainly on lexical networks, but much remains to be done on the preceding types (pivot, multilevel). In particular, the import of lexical databases in lexical networks causes a loss of information, especially information born by the attributes of rich links. For example, what concerns the history, the etymology or the evolution of word senses is not systematically imported into lexical networks. They therefore cannot meet the needs of the humanities, nor allow the transition to "digital humanities."  A lexical network is actually the type of structure that enables the greatest freedom of representation. Indeed, we can create entries and links arbitrarily. But the possible queries cannot model all the usual interactions with lexicographers-developers and users, which come from the world of paper, and are felt necessary. They allow us to represent all categories of lexical resources, but the analogy with the real world is lost. Thus, the practical expertise of linguists-lexicographers is lost.  We must continue to equip lexical databases, because that is the right level to transfer the techniques used by lexicographers-linguists. Also, modelling by a volume-based macrostructure allows keeping a link to the original paper world. Moreover, there are already reusable resources of these types. That is why we focus on the management of resources having multiversion and multilevel macrostructures.  3 Reuse of rich links  In this section, we present an improvement that consists in introducing into lexical databases relational                                                 7 http://ddata.over-blog.com/xxxyyy/3/12/82/15/GRAMMAIRE/champs-et-reseaux-lexicaux.pdf 8 For that kind of functionality, multiple sorting on subsets of inflected forms and on arbitray types of information seems to be a necessary first level of computer aid. 
89
information in the form of rich links that will bring them closer to lexical networks. An important point is that these links may bear arbitrary labels.  3.1 Presentation of the Jibiki platform  Jibiki is a generic platform that enables the construction of contributive websites dedicated to the construction of multilingual lexical databases. That platform has been developed mainly by Mathieu Mangeot (Mangeot & Chalvin, 2006) and Gilles S?rasset (S?rasset & Mangeot, 2001). It has been used in various projects (EU LexALP project, Papillon project, GDEF project, etc.). The code is available in open source, and freely downloadable by SVN from ligforge.imag.fr. With this platform, one can perform import, export, edit and search operations in lexical databases. One can also manage the contributions. Jibiki allows handling almost all lexical resources of XML type, by using different microstructures and macrostructures.  In the Jibiki approach, resources are organized in volumes, which makes it easier to achieve the equivalent of paper dictionaries, keeping the mental image of the representation of the dictionary, while offering new interactions allowed in the digital world. Usages of dictionaries in Jibiki are also similar to those of paper dictionaries. For example, one can consult a database in alphabetical order, indicate a source and/or target language, group lexies in vocables, navigate in a volume, etc.  3.2 Classical Common Dictionary Markup  Version 1 of Jibiki uses "CDM pointers" (Common Dictionary Markup (Mangeot, 2002)) to import, view and edit any type of microstructure without modifying it. CDM pointers are also used to index specific parts of the information, and then allow a multi-criteria search.  Each CDM pointer indicates the path (XPath) to the corresponding element in the XML microstructure of the described resource (see Figure 1). Its description is stored in a XML metadata file. When the resource is imported in the Jibiki platform, the pointers are computed, and the result is stored in a table of the (postgresql) database, for each volume. This table is considered as an indexing table.  
 Figure 1: CDM pointers for the French volume of the GDEF9 resource (Mangeot and Chalvin, 2006) 
CDM tags FeM10 (Gut et al., 1996) OHD11  JMdict12 (Breen, 2004) Volume /volume /volume /JMdict Entry /volume/entry /volume/se /JMdict/entry Entry ID /volume/entry/@id  /JMdict/entry/ent_seq/text() Headword /volume/entry/headword/text() /volume/se/hw/text() /JMdict/entry/k_ele/keb/text() Pron /volume/entry/prnc/text() /volume/se/pr/ph/text()  PoS //sense-list/sense/pos-list/text() /volume/se/hg/ps/text() /JMdict/entry/sense/pos/text() Domain  //u/text()  Example //sense1/expl-list/expl/fra //le/text() /JMdict/entry/sense/gloss/text() Table 1: Examples of Common Dictionary Markup                                                  9 GDEF is a large Estonian-French dictionary that is being created by the Franco-Estonian lexicography association (see http://estfra.ee/GDEF.po).  10 FeM is a French-English-Malay dictionary (30000 entries, 50000 lexies, 8000 idioms, 10000 examples of use). 11 OHD is abbreviation of Oxford-Hachette Dictionary, which is a French-English dictionary. 12 JMdict is a Japanese-multilingual dictionary. 
90
The translation links are treated at this stage with conventional CDM pointers, as classical information elements. It is not possible to index other information carried by the links, such as weights or labels.  Hence, multilevel macrostructures cannot be modelled in a generic manner with Jibiki-v1 and traditional CDM pointers. For example, it is not possible to link the same volume to several volumes at different levels. This has forced us initially to use palliatives that did not scale up. It became necessary to modify the conceptual model. We addressed these shortcomings in a new version, Jibiki-LINKS.  Table 1 above is an example of CDM for the different resources.  3.3 New version of Jibiki with CDM LINKS  To manage multilevel macrostructures, we enriched the CDM with a richer description of the links (see Figure 2). For each link, more information can be indexed:  ? the identifier of the source entry.  ? the identifier of the target entry.  ? the identifier of the XML element of the source entry containing the link. For example, the sense number in a polysemous entry having a translation link for each translation direction. That allows us to precisely retrieve the origin of the link.  ? the link name. It is used to distinguish between different types of links in a single entry, such as a translation link and a synonymy link.  ? the target language (three-letter code ISO 639-2 / T).  ? the target volume.  ? the type of link. Some types are predefined, because they are used by the algorithms that compute the rich links (translation, axeme, axie), but it is possible to use other types of links.  ? a label whose text is arbitrary.  ? a weight whose value must be a real number.  These links can be established between two entries of the same volume or between two different volumes. The same volume may group entries connected to several volumes.  To realize the implementation of rich links, we separated the module processing the links from the module processing other CDM pointers. It means we have two CDM tables in the database associated to each volume. The first stores CDM traditional pointers, and the second CDM LINKS. All information of LINKS can be found in this table.  
 Figure 2: CDM-LINKS for the English volume of the CommonUNLDict resource  3.4 Approach by rich links in searching in a complex lexical network  To explain how we create arbitrary links, let us give an example. A free label is available for each link. For example, in a lexical resource including SMS, in French "A+" has a link to "Over" with a "SMS" label, in English "L8R" corresponds to "later" with a "SMS" label, and the label of the link between "Over" and "later" is "translation."  A ProAxie macrostructure (Zhang & Mangeot, 2013) has been implemented on the Jibiki-Links platform. We present another example of rich links for semantic search in section 4.1.  
91
3.5 Algorithms for computing rich links  The computer implementation is based on two algorithms. The first collects the links, and the second builds the result. More precisely, the first looks for all possible links in the set of all rich links of all volumes, for a desired entry. The second recursively performs the following steps: (1) selection of the start entry; (2) search of the links to other entries; (3) treatment of labels; (4) recursive call of the algorithm on the connected entry; (5) integration of the XML code of the entry connected to the start entry; (6) display.  4 Experimentation  4.1 Examples of multilevel macrostructures  We have already installed several multilevel macrostructures on Jibiki-LINKS. Here are 3 examples.  Mot?Mot: trilingual lexical database with a pivot structure (Mangeot & Touche, 2010) This project (2009-2012) has computerized a French-Khmer classical dictionary, initially in Word, into a Jibiki database (see http://jibiki.univ-savoie.fr/motamot/). The macrostructure is composed of a monolingual volume for each language and a central pivot volume. However, in order not to confuse users, the contributing interface shows a classic view of a bilingual dictionary. Each bilingual link language A ? language B added via this interface is actually translated into the background by creating two interlingual links as well as an axie link representing the original translation, to finally get: language A ? pivot axie ? language B (see Figure 3). If a contributor wants to add a translation link between a vocable Va of language A and a vocable Vb of language B, s/he can establish this link at different levels. The ideal solution is to connect a word meaning (lexie) La of the vocable Va to another word meaning Lb of the vocable Vb. In this case, the link is bijective and Lb is also connected to La. If the contributor cannot choose between word meanings, s/he can connect directly the word meaning La to the vocable Vb and the link is tagged for refinement. With the pivot macrostructure, if two links language A ? language B and language B ? language C exist, then it will automatically create a link language A ? language C tagged for refinement. 
 Figure 3: Example of Mot?Mot ProAxie: multilingual extension of ProxlexBase (Tran, 2006) The ProAxie macrostructure aims at solving the problem of linking several terms that refer to one and the same referent, in particular for the management of acronyms (Zhang et Mangeot, 2013). In this macrostructure, there are two different layers. The base layer consists of two types of volume: volumes of lexies and volumes of axies. The axies are used to connect the lexies that match each other exactly. For example, one translates "ONU" by "UN" (see Figure 4) from French into English.  The "Pro" layer allows us to propose to users translations having the same referential meanings. This layer includes the volumes of prolexemes (Tran, 2006) and one volume of proaxies. A prolexeme entry links lexies having the same meaning with a label (aka, acronym, definition, etc.). A proaxie entry connects prolexemes of different languages. If one cannot find the translations directly using the lower layer, one will get the translations proposed by the "Pro" layer.  For example, for "Nations-Unies", translations by "United Nations" and "UN" will be proposed, with the "alias" label.   
92
 Figure 4: Example of ProAxie  For each natural language, there are one or more volumes of lexies, and a single volume of prolexemes. For each dictionary, there is a volume of axies and a volume of proaxies.  This gives three levels of translation, classified according to the precision obtained.  (1) The system finds a lexie directly, using the volume of axies. That is the first and most accurate level of translation.  (2) The system searches a link to the prolexemes volume of the source language with a certain label. When it finds the link in the proaxies volume, it follows the prolexeme link of the target language, and finally arrives at the volume of lexies in the target language, and finds a lexie that has the same label. That is the second, intermediate level.  (3) The system finds the lexies going through prolexemes and proaxies, without a corresponding label. These proposed lexies constitute the third and least accurate level.  Pivax: lexical multilingual multiversion database with 3 levels  The Pivax macrostructure has three levels: lexie, axeme and axie (Nguyen & al., 2007). Axemes are monolingual acceptions, and group monolingual lexies having the same meaning. Axies group synonymous axemes of different languages in a central "hub". In some situations, a lexical database has several volumes for a single language. For example, when there are several editions, or when the lexical resource is created for a machine translation system: one may have one volume coming from Systran, one from Ariane/H?lo?se, one from IATE13, etc. This macrostructure allows us to manage multiple volumes in the same language. Given a language, there are one or more volumes of lexies and a single volume of axemes. For any Pivax database, there is only one volume of axies. The links between the lexies and the axemes and between the axemes and the axies are rich links with attributes such as type, target volume, target language, free label, weight, etc.  4.2 CommonUNLDict: toward scaling up with a resource of Pivax type  In this section, we present the CommonUNLDict resource that uses the Pivax macrostructure. We have implemented this resource on the Pivax-UNL platform, which is an instance of Jibiki-Links. Users can easily use this resource via the link http://getalp.imag.fr/pivax/Home.po.  Resource created by linguists  Thanks to CDM-LINKS, all types of XML formats can be used in an instance of Jibiki-LINKS without modification. One needs only simple knowledge about XML to create a resource for Jibiki-LINKS. In addition, very useful available tools can be used to create an XML file, such as oXygen14 that allows the creation of a DTD using a graphical interface.   
                                                13 "A single database for all EU-related terminology (InterActive Terminology for Europe) in 23 languages opens to the public", 2007) 14 http://www.oxygenxml.com 
93
The CommonUNLDict resource has been created by the Russian lexicographer  and linguist Viacheslav Dikonov (Dikonov & Boguslavsky, 2009).  Figure 5 shows the graph of a monolingual volume structure using oXygen. In this example, each volume contains a large quantity of vocables, and each vocable includes one or more lexie. We will explain this structure in section 3.2.3. 
 Figure 5: Structure of a monolingual volume 
 Figure 6: Macrostructure of CommonUNLDict   
94
Macrostructure of CommonUNLDict  CommonUNLDict contains 8 languages (7 natural languages, French, English, Hindi, Malay, Russian, Spanish, Vietnamese, and the UNL language) and 17 volumes (8 volumes of monolingual data, 8 volumes of monolingual axemes, and 1 volume of axies ("interlingual meanings"). The macrostructure of CommonUNLDict is diagrammed in Figure 6. For each language, there is only one volume of monolingual data (vocables and lexical items) and a single volume of axemes. For the whole CommonUNLDict, there is only one volume of axies.  Microstructure of CommonUNLDict  The microstructure is the structure of the entries (Mangeot, 2001). In the CommonUNLDict resource, there are three types of entries (vocables, axemes and axies) and 720 K entries in total.  See Table 2.  Volume  Language  Entries  CommonUNLDict_axi  axi  82804  CommonUNLDict_eng  English  45471  CommonUNLDict_eng-axemes  English  82069  CommonUNLDict_esp  Spanish  7080  CommonUNLDict_esp-axemes  Spanish  22254  CommonUNLDict_fra  French  27537  CommonUNLDict_fra-axemes  French  48312  CommonUNLDict_hin  Hindi  31255  CommonUNLDict_hin-axemes  Hindi  50380  CommonUNLDict_msa  Malay  37342  CommonUNLDict_msa-axemes  Malay  31699  CommonUNLDict_rus  Russian  28475  CommonUNLDict_rus-axemes  Russian  45020  CommonUNLDict_unl  unl  82804  CommonUNLDict_unl-axemes  unl  82804  CommonUNLDict_vie  Vietnamese  6585  CommonUNLDict_vie-axemes  Vietnamese  8819  Table 2: Number of entries of CommonUNLDict  All volumes of the same type have the same microstructure. The example below (see Figure 7) shows the microstructure of a volume of vocables. Each entry of vocable type allows us to describe all detailed information, such as part of speech (POS), pronunciation, etc. Each vocable includes one or more lexies (word senses). Figure 2 shows an example. Therefore the number of axemes is greater than or equal to the number of vocables. In this microstructure, the "entryref" attribute allows us to manage the links between lexies and the entries of axeme type.  
 Figure 7: Microstructure of a volume of lexies  ? In this example, the value of "type" is the type of link, the value of "volume" is the target volume, the value of "idref" is the identifier of the axeme entry, the value of "lang" is the target language, and the value of "relationship-mono" is the label.  
95
? The microstructure of the entries of axeme type allows us to describe the links with entries of lexie type and the links with entries of axie type. The microstructure of the axies allows us to describe the links with the entries of axeme type.  Response time and use case The tests were performed with an instance of Jibiki-LINKS installed on a machine with an Intel Core i3 processor at 3.3 GHz with 8 GB of RAM.  The tool used to perform queries is wget. The command is run directly on the server to avoid the latency due to the network. We give three examples in Table 3, which show the number of links computed by the system, of entries displayed, of queries, of different languages, and the average response time. The response time, less than 1 second in these cases, is generally satisfactory. For better understanding, there is some details about the example "manger" (see Figure 8). We search "manger" in French, and find one entry with id "fra.manger.v" in the French vocable volume. The search direction is "up". This entry links to another entry of the volume of French axemes, whose id is CommonUNLDict.axeme.fra.eat(icl>consume>do, agt>living_thing, obj>concrete_thing, ins>thing) 15. This axeme entry links with one axie entry and the vocable entry fra.manger.v. Because the search direction is "up", we just go to the axie entry. When we arrive in the volume of axies, the search direction is changed to "down". The axie entry links to 6 different axeme entries. We search each axeme entry and its links. Because the search direction is "down", we only take into account vocable entries links. For each axeme entry, we find at least one vocable entry. In other cases, one vocable entry has more than one lexie, so it links to one or several axeme entries, and there are more links.  Search argument Links  Displayed entries  Number of requests  Different languages  Average time (ms)  French vocable "manger"  14  6  10  6  19.7  French vocable "recherche"  66  27  10  6  73.5  UNL "search(icl>action)"  51  20  10  6  56  Table 3: Response time on three examples  
 Figure 8: Links in the case of "manger"  Figure 9 shows the display of the interface for a classical search in a Web browser.  
                                                15 In order to better display figure, we have simplified the id in figure 8. 
96
 Figure 9: Display of the interface for a classical search  5 Conclusion and perspectives  In this article, we analysed the different types of lexical resource and presented a method of modelling lexical resources using volumes. This method allows us to manage complex resources while providing facilities for manipulation and treatment equivalent to those of a paper dictionary.  Jibiki-LINKS is a new version of the Jibiki platform, which can manage resources based on multilevel macrostructures using rich links, bearing attributes such as target volume, weight, type, language, open label, etc. To realize the implementation of rich links, we separated the module processing the links from the module processing other CDM pointers. Jibiki-LINKS has been used to implement the Mot?Mot, ProAxie and Pivax macrostructures.  On the Pivax-UNL platform, another instance of the Jibiki-LINKS-based Pivax macrostructure, we have installed the volumes corresponding to the CommonUNLDict resource of V. Dikonov, and tested our platform with that resource.  There is also a UW (UNL interlingual lexemes) resource of 8G entries that was created from DBpedia by David Rouquet. In that resource, there are several volumes for the same language. As links were poorly structured, we are currently working on this resource in order to recompute them. We hope to be able to import this resource, and to make tests at that very large scale in the near future.  To sum up, lexical databases equipped with rich links allow for importing XML-based electronic dictionaries without loss of information, whether they have been elaborated from source or printable forms (such as Word, rtf, ps, pdf) or directly produced in XML from a relational database, or using a dedicated editor knowing their microstructures. They also allow us to automatically produce from them a pivot-based macrostructure organised in volumes, and after that to edit and improve them, using a mixed textual and graphical interface to merge or split lexies, axemes or axies, or to enrich the links with appropriate labels. The introduction of rich links to multilevel lexical databases enhances them with a very interesting aspect of the lexical networks while keeping the classical ways of using dictionaries and of performing lexicographic work. References  EU-IATE (2007) A single database for all EU-related terminology (InterActiveTerminology for Europe) in 23 languages opens to the public. Press release. Brussels. 2007-06-28. Breen, J. W., (2004) JMdict : a Japanese-Multilingual Dictionary. In Gilles S?rasset, Susan Armstrong, Christian Boitet, Andrei Pospescu-Belis, and Dan Tufis, editors, post COLING Workshop on Multilingual Linguistic Resources, Geneva, Switzerland, 28th August. International Committee on Computational Linguistics.  
97
Dikonov V., Boguslavsky I., (2009) Semantic Network of the UNL Dictionary of Concepts. Proceedings of the SENSE Workshop on conceptual Structures for Extracting Natural language SEmantics Moscow, Russia, July 2009, 7 p. Diller, G.A., Beckwith, R., Fellbaum, C., Gross, D., and Miller, K.J. (1990) Introduction to WordNet: an on-line lexical database, International Journal of Lexicography 3(4), pp. 235-244. Dolan, W.B. & Richardson, S.D., (1996) Interactive Lexical Priming for Disambiguation. Proc. MIDDIM'96, Post-COLING seminar on Interactive Disambiguation, C. Boitet ed. Le Col de Porte, Is?re, France. 12-14 ao?t 1996. vol. 1/1 : pp. 54-56. Dong, Z.D., Dong, Q., Hao, C.L., (2010). HowNet and Its Computation of Meaning. In Actes de COLING-2010, Beijing, 4 p. Francopoulo, G., Bel, N., George, M., Calzolari, N., Monachini, M., Pet, M. and Soria, C. (2009). Multilingual resources for NLP in the lexical markup framework (LMF). In journal de Language Resources and Evaluation, March 2009, Volume 43, pp. 55-57. Gut, Y., Ramli, P. R. M., Yusoff, Z., Kim, Ch. Ch., Samat, S. A., Boitet, Ch., N?dobejkine, N., Lafourcade, M., Gaschler, J. and Levenbach, D. (1996). Kamus Perancis-Melayu Dewan, dictionnaire fran?ais-malais. Dewan Bahasa Dan Pustaka, Kuala Lumpur, 667 p. Lafourcade, M., Joubert, A. (2010). Computing trees of named word usages from a crowdsourced lexical network. Investigationes Linguisticae, vol. XXI, pp. 39-56  Lux-Pogodalla, V., Polgu?re, A. (2011) Construction of a French Lexical Network: Methodological Issues. Proceedings of the First International Workshop on Lexical Resources, WoLeR 2011. An ESSLLI-2011 Workshop. Ljubljana, 2011, pp. 54-61.  Mangeot, M. (2002). An XML Markup Language Framework for Lexical Databases Environments: the Dictionary Markup Language. In Actes de LREC-2002, pp. 37-44. Mangeot, M & Chalvin, A.  (2006). Dictionary Building with the Jibiki Platform: the GDEF case. In Actes de LREC-2006, Genoa, pp. 1666-1669.  Mangeot, M. & Touch, S., (2010) Mot?Mot project: building a multilingual lexical system via bilingual dictionaries. Proc. SLTU 2010: Second International Workshop on Spoken Languages Technologies for Under-Resourced Languages, Penang, Malaysia, 2010, 6 p. McCrae, J., Spohr, D. and Cimiano, P., (2011)  Linking lexical resources and ontologies on the semantic web with lemon. Proc. ESWC?11, Berlin, pp. 245-259. Nguyen, H.T., Boitet, C. and S?rasset, G. (2007). PIVAX, an online contributive lexical data base for heterogeneous MT systems using a lexical pivot. In Actes de SNLP-2007, Bangkok, 6 p. Richardson, S.D., Dolan, W.B. and Vanderwende, L. (1998) MindNet: acquiring and structuring semantic information from text, no. MSR-TR-98-23. S?rasset, G. (2012) Dbnary: Wiktionary as a LMF-based Multilingual RDF network. In Actes de LREC-2012, Istanbul, 7 p. S?rasset, G. & Mangeot, M. (2001). Papillon Lexical Database Project: Monolingual Dictionaries and Interlingual Links. In Proc. NLPRS-2011, Tokyo, pp. 119-125. Tran, M. (2006). Prolexbase : Un dictionnaire relationnel multilingue de noms propres : conception, impl?mentation et gestion en ligne. Th?se de doctorat, Tours, pp. 54-57. Vossen, P., (1998) EuroWordNet: A Multilingual Database with Lexical Semantic Networks, Computers and the Humanities, 32(2-3). Zhang, Y. & Mangeot, M., (2013).  Gestion des terminologies riches : l'exemple des acronymes. In Actes de TALN-2013, Les Sables d?Olonne, 8 p.  
98
