Multi-View Co-training of Transliteration Model 
 
Jin-Shea Kuo Haizhou Li 
Chung-Hwa Telecomm. 
Laboratories, Taiwan 
d8807302@gmail.com 
Institute for Infocomm Research, 
Singapore 119613 
hli@i2r.a-star.edu.sg 
 
Abstract 
This paper discusses a new approach to 
training of transliteration model from 
unlabeled data for transliteration extraction. 
We start with an inquiry into the 
formulation of transliteration model by 
considering different transliteration 
strategies as a multi-view problem, where 
each view exploits a natural division of 
transliteration features, such as phoneme-
based, grapheme-based or hybrid features. 
Then we introduce a multi-view Co-
training algorithm, which leverages 
compatible and partially uncorrelated 
information across different views to 
effectively boost the model from unlabeled 
data. Applying this algorithm to 
transliteration extraction, the results show 
that it not only circumvents the need of data 
labeling, but also achieves performance 
close to that of supervised learning, where 
manual labeling is required for all training 
samples. 
1 Introduction 
Named entities are important content words in text 
documents. In many applications, such as cross-
language information retrieval (Meng et al, 2001; 
Virga and Khudanpur, 2003) and machine 
translation (Knight and Graehl, 1998; Chen et al, 
2006), one of the fundamental tasks is to identify 
these words. Imported foreign proper names 
constitute a good portion of such words, which are 
newly translated into Chinese by transliteration. 
Transliteration is a process of translating a foreign 
word into the native language by preserving its 
pronunciation in the original language, otherwise 
known as translation-by-sound.  
As new words emerge everyday, no lexicon is 
able to cover all transliterations. It is desirable to 
find ways to harvest transliterations from real 
world corpora. In this paper, we are interested in 
the learning of English to Chinese (E-C) 
transliteration model for transliteration extraction 
from the Web. 
A statistical transliteration model is typically 
trained on a large amount of transliteration pairs, 
also referred to a bilingual corpus. The 
correspondence between a transliteration pair may 
be described by the mapping of different basic 
pronunciation units (BPUs) such as phoneme-
based1, or grapheme-based one, or both. We can 
see each type of BPU mapping as a natural division 
of transliteration features, which represents a view 
to the phonetic mapping problem. By using 
different BPUs, we approach the transliteration 
modeling and extraction problems from different 
views.  
This paper is organized as follows. In Section 2, 
we briefly introduce previous work. In Section 3, 
we conduct an inquiry into the formulation of 
transliteration model or phonetic similarity model 
(PSM) and consider it as a multi-view problem. In 
Section 4, we propose a multi-view Co-training 
strategy for PSM training and transliteration 
extraction. In Section 5, we study the effectiveness 
of proposed algorithms. Finally, we conclude in 
Section 6. 
2 Related Work 
Studies on transliteration have been focused on 
transliteration modeling and transliteration 
extraction. The transliteration modeling approach 
deduces either phoneme-based or grapheme-based 
mapping rules using a generative model that is 
                                                 
1 Both phoneme and syllable based approaches are 
referred to as phoneme-based in this paper. 
373
trained from a large bilingual corpus. Most of the 
works are devoted to phoneme-based transliteration 
modeling (Knight and Graehl, 1998; Lee, 1999). 
Suppose that EW is an English word and CW is its 
Chinese transliteration. EW and CW form an E-C 
transliteration pair. The phoneme-based approach 
first converts EW into an intermediate phonemic 
representation p, and then converts p into its 
Chinese counterpart CW. The idea is to transform 
both source and target words into comparable 
phonemes so that the phonetic similarity between 
two words can be measured easily.  
Recently the grapheme-based approach has 
attracted much attention. It was proposed by Jeong 
et al (1999), Li et al (2004) and many others (Oh 
et al, 2006b), which is also known as direct 
orthography mapping. It treats the transliteration as 
a statistical machine translation problem under 
monotonic constraint. The idea is to obtain the 
bilingual orthographical correspondence directly to 
reduce the possible errors introduced in multiple 
conversions. However, the grapheme-based 
transliteration model has more parameters than 
phoneme-based one does, thus expects a larger 
training corpus. 
Most of the reported works have been focused 
on either phoneme- or grapheme-based approaches. 
Bilac and Tanaka (2004) and Oh et al (2006a; 
2006b) recently proposed using a mix of phoneme 
and grapheme features, where both features are 
fused into a single learning process. The feature 
fusion was shown to be effective. However, their 
methods hinge on the availability of a labeled 
bilingual corpus. 
In transliteration extraction, mining translations 
or transliterations from the ever-growing 
multilingual Web has become an active research 
topic, for example, by exploring query logs (Brill et 
al., 2001) and parallel (Nie et al, 1999) or 
comparable corpora (Sproat et al, 2006). 
Transliterations in such a live corpus are typically 
unlabeled. For model-based transliteration 
extraction, recent progress in machine learning 
offers different options to exploit unlabeled data, 
that include active learning (Lewis and Catlett, 
1994) and Co-training (Nigam and Ghani, 2000; 
T?r et al 2005). 
Taking the prior work a step forward, this paper 
explores a new way of fusing phoneme and 
grapheme features through a multi-view Co-
training algorithm (Blum and Mitchell, 1998), 
which starts with a small number of labeled data to 
bootstrap a transliteration model to automatically 
harvest transliterations from the Web. 
3 Phonetic Similarity Model with 
Multiple Views 
Machine transliteration can be formulated as a 
generative process, which takes a character string 
in source language as input and generates a 
character string in the target language as output. 
Conceptually, this process can be regarded as a 3-
step decoding: segmentation of both source and 
target strings into basic pronunciation units (BPUs), 
relating the source BPUs with target units by 
resolving different combinations of alignments and 
unit mappings in finding the most probable BPU 
pairs. A BPU can be defined as a phoneme 
sequence, a grapheme sequence, or a part of them. 
A transliteration model establishes the phonetic 
relationship between BPUs in two languages to 
measure their similarity, therefore, it is also known 
as the phonetic similarity model (PSM). 
 To introduce the multi-view concept, we 
illustrate the BPU transfers in Figure 1, where each 
transfer is represented by a direct path with 
different line style. There are altogether four 
different paths: the phoneme-based path V1 
(T1?T2?T3), the grapheme-based path V4 (T4), 
and their variants, V2(T1?T5) and V3(T6?T3). The 
last two paths make use of the intermediate BPU 
mappings between phonemes and graphemes. Each 
of the paths represents a view to the mapping 
problem. Given a labeled bilingual corpus, we are 
able to train a transliteration model for each view 
easily.   
 
 
Figure 1. Multiple views for establishing 
transliteration correspondence. 
 
The E-C transliteration has been studied 
extensively in the paradigm of noisy channel model 
Source 
Phoneme 
Target 
Phoneme 
Source 
Word 
Target  
Word 
T1 
T2 
T4 
T3 
T5 T6 
374
(Manning and Scheutze, 1999), with EW as the 
observation and CW as the input to be recovered. 
Applying Bayes rule, the transliteration can be 
described by Eq. (1),  
( | ) ( )( | ) ,
( )
P EW CW P CWP CW EW
P EW
?=               (1) 
where we need to deal with two probability 
distributions: P(EW|CW), the probability of 
transliterating CW to EW, also known as the unit 
mapping rules, and P(CW), the probability 
distribution of CW, known as the target language 
model. 
Representing EW in English BPU 
sequence 1{ ,... ,... }= m MEP ep ep ep  and CW in 
Chinese one, 1{ ,... ,... }= n NCP cp cp cp , a typical 
transliteration probability can be expressed as, 
 
( | ) ( | ) ( | ) ( | ).P EW CW P EW EP P EP CP P CP CW? ? ?   (2) 
 
The language model, P(CW), can be represented by 
Chinese characters n-gram statistics (Manning and 
Scheutze, 1999) and expressed in Eq. (3). In the 
case of bigram, we have, 
1 1
2
( ) ( ) ( | )
N
n n
n
P CW P c P c c ?
=
? ?          (3) 
We next rewrite Eq. (2) for the four different views 
depicted in Figure 1 in a systematic manner. 
3.1 Phoneme-based Approach 
The phoneme-based approach approximates the 
transliteration probability distribution by 
introducing an intermediate phonemic 
representation. In this way, we convert the words in 
the source language, say 1 2, ... KEW e e e= , into 
English syllables ES , then Chinese syllables CS  
and finally the target language, say Chinese 
1 2, ... KCW c c c=  in sequence. Eq. (2) can be 
rewritten by replacing EP and CP with ES and CS, 
respectively, and expressed by Eq. (4). 
 
( | ) ( | ) ( | ) ( | )P EW CW P EW ES P ES CS PCS CW? ? ?       (4) 
 
The three probabilities correspond to the three-step 
mapping in V1 path.  
The phoneme-based approach suffers from 
multiple step mappings. This could compromise 
overall performance because none of the three 
steps guarantees a perfect conversion.  
3.2 Grapheme-based Approach 
The grapheme-based approach is inspired by the 
transfer model (Vauqois, 1988) in machine 
translation that estimates ( | )P EW CW  directly 
without interlingua representation. This method 
aims to alleviate the imprecision introduced by the 
multiple transfers in phoneme-based approach. 
In practice, a grapheme-based approach converts 
the English graphemes to Chinese graphemes in 
one single step. Suppose that we have 
1 2, ... KEW e e e= and 1 2, ... KCW c c c= where ke  and 
kc are aligned grapheme units.  
Under the noisy channel model, we can estimate 
( | )P EW CW  based on the alignment statistics 
which is similar to the lexical mapping in statistical 
machine translation.  
1
( | ) ( | )K k kkP EW CW P e c=??     (5) 
Eq.(5) is a grapheme-based alternative to Eq.(2).  
3.3 Hybrid Approach 
A tradeoff between the phoneme- and grapheme-
based approaches is to take shortcuts to the 
mapping between phonemes and graphemes of two 
languages via V2 or V3, where only two steps of 
mapping are involved. For V3, we rewrite Eq.(2) as 
Eq. (6): 
 
( | ) ( | ) ( | ),= ?P EW CW P EW CS P CS CW         (6) 
 
where ( | )P EW CS  translates Chinese sounds into 
English words. For V2, we rewrite Eq. (2) as Eq. 
(7): 
 
( | ) ( | ) ( | ),= ?P EW CW P EW ES P ES CW         (7) 
 
where ( | )P ES CW translates Chinese words into 
English sounds. 
Eqs. (4) ? (7) describe the four paths of 
transliteration. In a multi-view problem, one 
partitions the domain?s features into subsets, each 
of which is sufficient for learning the target 
concept. Here the target concept is the label of 
transliteration pair. Given a collection of E-C pair 
candidates, the transliteration extraction task can be 
formulated as a hypothesis test, which makes a 
binary decision as to whether a candidate E-C pair 
is a genuine transliteration pair or not. Given an E-
C pair X={EW,CW}, we have 0H , which 
375
hypothesizes that EW  and CW  form a genuine E-
C pair, and 1H , which hypothesizes otherwise. The 
likelihood ratio is given as 0 1( | ) / ( | )P X H P X H? = , 
where 0( | )P X H and 0( | )P X H  are derived from 
P(EW|CW). By comparing ?  with a threshold ? , 
we make the binary decision as that in (Kuo et al, 
2007).  
As discussed, each view takes a distinct path that 
has its own advantages and disadvantages in terms 
of model expressiveness and complexity. Each 
view represents a weak learner achieving 
moderately good performance towards the target 
concept. Next, we study a multi-view Co-training 
process that leverages the data of different views 
from each other in order to boost the accuracy of a 
PSM model.  
4 Multi-View Learning Framework 
The PSM can be trained in a supervised manner 
using a manually labeled corpus. The advantage of 
supervised learning is that we can establish a model 
quickly as long as labeled data are available. 
However, this method suffers from some practical 
constraints. First, the derived model can only be as 
good as the data it sees. Second, the labeling of 
corpus is labor intensive.  
To circumvent the need of manual labeling, here 
we study three adaptive strategies cast in the 
machine learning framework, namely unsupervised 
learning, Co-training and Co-EM. 
4.1 Unsupervised Learning 
Unsupervised learning minimizes human 
supervision by probabilistically labeling data 
through an Expectation and Maximization (EM) 
(Dempster et al, 1977) process. The unsupervised 
learning strategy can be depicted in Figure 2 by 
taking the dotted path, where the extraction process 
accumulates all the acquired transliteration pairs in 
a repository for training a new PSM. A new PSM is 
in turn used to extract new transliteration pairs. The 
unsupervised learning approach only needs a few 
labeled samples to bootstrap the initial model for 
further extraction. Note that the training samples 
are noisy and hence the quality of initial PSM 
therefore has a direct impact on the final 
performance.  
4.2 Co-training and Co-EM  
The multi-view setting (Muslea et al, 2002) 
applies to learning problems that have a natural 
way to divide their features into different views, 
each of which is sufficient to learn the target 
concept. Blum and Mitchell (1998) proved that for 
a problem with two views, the target concept can 
be learned based on a few labeled and many 
unlabeled examples, provided that the views are 
compatible and uncorrelated. Intuitively, the 
transliteration problem has compatible views. If an 
E-C pair forms a transliteration, then this is true 
across all different views. However, it is arguable 
that the four views in Figure 1 are uncorrelated. 
Studies (Nigam and Ghani, 2000; Muslea et al, 
2002) shown that the views do not have to be 
entirely uncorrelated for Co-training to take effect. 
This motivates our attempt to explore multi-view 
Co-training for learning models in transliteration 
extraction. 
 
  
Figure 2. Diagram of unsupervised/multi-view Co-
training for transliteration extraction. 
 
To simplify the discussion, here we take a two-
view (V1 and V2) example to show how Co-
training can potentially help. To start with, one can 
learn a weak hypothesis PSM1 using V1 based on a 
few labeled examples and then apply PSM1 to all 
unlabeled examples. If the views are uncorrelated, 
or at least partially uncorrelated, these newly 
labeled examples seen from V1 augment the 
training set for V2. These newly labeled examples 
Stop Start 
Iterate 
Final 
PSM 
Initial 
PSM 
Search &  
Ranking 
PSM Learner 
Lexicon The Web 
Training 
Repository 
PSM  
Evaluation & Stop 
Criterion 
Unsupervised 
Co-training 
PSM Learner 1 
Training 
Repository 
PSM Learner n 
376
present new information from the V2 point of view, 
from which one can in turn update the PSM2. As 
the views are compatible, both V1 and V2 label the 
samples consistently according to the same 
probabilistic transliteration criteria. In this way, 
PSMs are boosted each other through such an 
iterative process between two different views.  
 
 
Table 1. Co-training with two learners. 
Extending the two-view to multi-view, one can 
develop multiple learners from several subsets of 
features, each of which approaches the problem 
from a unique perspective, called a view when 
taking the Co-training path in Figure 2. Finally, we 
use outputs from multi-view learners to 
approximate the manual labeling. The multi-view 
learning is similar to unsupervised learning in the 
sense that the learning alleviates the need of 
labeling and starts with very few labeled data. 
However, it is also different from the unsupervised 
learning because the latter does not leverage the 
natural split of compatible and uncorrelated 
features. Two variants of two-view learning 
strategy can be summarized in Table 1 and Table 2, 
where the algorithm in Table 1 is referred to as Co-
training and the one in Table 2 as Co-EM (Nigam 
and Ghani. 2000; Muslea et al, 2002). 
In Co-training, Learners A and B are trained on 
the same training data and updated simultaneously. 
In Co-EM, Learners A and B are trained on labeled 
set predicted by each other?s view, with their 
models being updated in sequence. In other words, 
the Co-EM algorithm interchanges the probabilistic 
labels generated in the view of each other before a 
new EM iteration. In both cases, the unsupervised, 
multi-view algorithms use the hypotheses learned 
to probabilistically label the examples.  
 
 
Table 2. Co-EM with two learners. 
The extension of algorithms in Table 1 and 2 to 
the multi-view transliteration problem is 
straightforward. After an ensemble of learners are 
trained, the overall PSM can be expressed as a 
linear combination of the learners,  
1
( | ) ( | ),n i iiP EW CW w P EW CW==?             (8) 
where iw is the weight of ith learner ( | )iP EW CW , 
which can be learnt by using a development corpus.  
5 Experiments 
To validate the effectiveness of the learning 
framework, we conduct a series of experiments in 
transliteration extraction on a development corpus 
described later. First, we repeat the experiment in 
(Kuo et al, 2006) to train a PSM using PSA and 
GSA feature fusion in a supervised manner, which 
serves as the upper bound of Co-training or Co-EM 
system performance. We then train the PSMs with 
single view V1, V2, V3 and V4 alone in an 
unsupervised manner. The performance achieved 
by each view alone can be considered as the 
baseline for multi-view benchmarking. Then, we 
run two-view Co-training for different 
combinations of views on the same development 
corpus. We expect to see positive effects with the 
multi-view training. Finally, we run the 
experiments using two-view Co-training and Co-
EM and compare the results. 
A 500 MB development corpus is constructed by 
crawling pages from the Web for the experiments. 
We first establish a gold standard for performance 
evaluation by manually labeling the corpus based 
on the following criteria: (i) if an EW is partly 
Given  
a). A small set of labeled samples and a set of 
unlabeled samples. 
b). Learner A is trained on a labeled set to 
predict the labels of the unlabeled data. 
 
1) Loop for k iterations 
a). Learner B is trained on data labeled by 
Learner A to predict the labels of the 
unlabeled data; 
b). Learner A is trained on data labeled  by 
Learner B to predict the labels of the 
unlabeled data;   
2) Combine models from Learners A and B. 
Given: 
a). A small set of labeled samples and a set 
of unlabeled samples. 
b). Two learners A and B are trained on the 
labeled set. 
 
1) Loop for k iterations: 
a). Learners A and B predict the labels of 
the unlabeled data to augment the labeled 
set; 
b). Learners A and B are trained on the 
augmented labeled set.    
2) Combine models from Learners A and B. 
377
translated phonetically and partly translated 
semantically, only the phonetic transliteration 
constituent is extracted to form a transliteration 
pair; (ii) multiple E-C pairs can appear in one 
sentence; (iii) an EW can have multiple valid 
Chinese transliterations and vice versa.  
We first derive 80,094 E-C pair candidates from 
the 500 MB corpus by spotting the co-occurrence 
of English and Chinese words in the same 
sentences. This can be done automatically without 
human intervention. Then, the manual labeling 
process results in 8,898 qualified E-C pairs, also 
referred to as Distinct Qualified Transliteration 
Pairs (DQTPs).  
 To establish comparison, we first train a PSM 
using all 8,898 DQTPs in a supervised manner and 
conduct a closed test as reported in Table 3. We 
further implement three PSM learning strategies 
and conduct a systematic series of experiments by 
following the recognition followed by validation 
strategy proposed in (Kuo et al, 2007). 
 
 Precision Recall F-measure 
Closed test 0.834 0.663 0.739 
Table 3. Performance with PSM trained in the 
supervised manner. 
For performance benchmarking, we define the 
precision as the ratio of extracted number of 
DQTPs over that of total extracted pairs, recall as 
the ratio of extracted number of DQTPs over that 
of total DQTPs, and F-measure as in Eq. (9). They 
are collectively referred to as extraction 
performance. 
2 recall precisionF measure
recall precision
? ?? =
+
            (9) 
5.1 Unsupervised Learning 
As formulated in Section 4.1, first, we derive an 
initial PSM using randomly selected 100 seed 
DQTPs for each learner and simulate the Web-
based learning process: (i) extract E-C pairs using 
the PSM; (ii) add all of the extracted E-C pairs to 
the DQTP pool; (iii) re-estimate the PSM for each 
view by using the updated DQTP pool. This 
process is also known as semi-supervised EM 
(Muslea et al, 2002). 
As shown in Figure 3, the unsupervised learning 
algorithm consistently improves the initial PSM 
using in all four views. To appreciate the 
effectiveness of each view, we report the F-
measures on each individual view V1, V2, V3 and 
V4, as 0.680, 0.620, 0.541 and 0.520, respectively at 
the 6th iteration. We observe that V1, the phoneme-
based path, achieves the best result. 
 
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
1 2 3 4 5 6
#Iteration
F-
me
as
ur
e
Supervised
V1
V2
V3
V4
Figure 3. F-measure over iterations using 
unsupervised learning with individual view. 
5.2 Co-training (CT) 
We report three typical combinations of two co-
working learners or two-view Co-training. Like in 
unsupervised learning, we start with the same 100 
seed DQTPs and an initial PSM model by 
following the algorithm in Table 1 over 6 iterations. 
With two-view Co-training, we obtain 0.726, 
0.705, 0.590 and 0.716 in terms of F-measures for 
V1+V2, V2+V3, V3+V4 and V1+V4 at the 6th 
iteration, as shown in Figure 4. Comparing Figure 
3 and 4, we find that Co-training consistently 
outperforms unsupervised learning by exploiting 
compatible information across different views. The 
V1+V2 Co-training outperforms other Co-training 
combinations, and surprisingly achieves close 
performance to that of supervised learning.  
 
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
1 2 3 4 5 6
#Iteration
F-
me
as
ur
e
Supervised
V1
V1+V2
V2+V3
V3+V4
V1+V4
 
Figure 4. F-measure over iterations using Co-
training algorithm 
378
5.3 Co-EM (CE) 
Next we start with the same 100 seed DQTPs by 
initializing the training pool and carry out Co-EM 
on the same corpus. We build PSM1 for Learner A 
and PSM2 for Learner B. To start with, PSM1 is 
learnt from the initial labeled set. We then follow 
the algorithm in Table 2 by looping in the 
following two steps over 6 iterations: (i) estimate 
the PSM2 from the samples labeled by Learner A 
(V1) to extract the high confident E-C pairs and 
augment the DQTP pool with the probabilistically 
labeled E-C pairs; (ii) estimate the PSM1 from the 
samples labeled by Learner B (V2) to extract the 
high confident E-C pairs and augment the DQTP 
pool with the probabilistically labeled E-C pairs. 
We report the results in Figure 5. 
 
0.5
0.6
0.7
0.8
1 2 3 4 5 6
#Iteration
F-
me
as
ur
e
Supervised
CT-V1+V2
CE-V1+V2
 
Figure 5. Comparing F-measure over iterations 
between Co-training (CT) and Co-EM (CE). 
 
To summarize, we compare the performance of 
six learning methods studied in this paper in Table 
4. The Co-training and Co-EM learning approaches 
have alleviated the need of manual labeling, yet 
achieving performance close to supervised learning. 
The multi-view learning effectively leverages 
multiple compatible and partially uncorrelated 
views. It reduces the need of labeled samples from 
80,094 to just 100.  
We also compare the multi-view learning 
algorithm with active learning on the same 
development corpus using same features. We 
include the results from previously reported work 
(Kuo et al, 2006) into Table 4 (see Exp. 2) where 
multiple features are fused in a single active 
learning process. In Exp. 2, PSA feature is the 
equivalent of V1 feature in Exp. 4; GSA feature is 
the equivalent of V4 feature in Exp. 4. In Exp. 4, 
we carry out V1+V4 two-view Co-training. It is 
interesting to find that the multi-view learning in 
this paper achieves better results than active 
learning in terms of F-measure while reducing the 
need of manual labeling from 8,191 samples to just 
100.  
 
Exp. Learning algorithm F-measure 
# of 
samples 
to label 
1 Supervised 0.739 80,094 
2 Active Learning 
(Kuo et al, 2006) 0.710 8,191 
3 Unsupervised (V1) 0.680 100 
4 Co-training (V1+V4) 0.716 100 
5 Co-training (V1+V2) 0.726 100 
6 Co-EM (V1+V2) 0.725 100 
Table 4. Comparison of six learning strategies.  
6 Conclusions 
Fusion of phoneme and grapheme features in 
transliteration modeling was studied in many 
previous works. However, it was done through the 
combination of phoneme and grapheme similarity 
scores (Bilac and Tanaka, 2004), or by pooling 
phoneme and grapheme features together into a 
single-view training process (Oh and Choi, 2006b). 
This paper presents a new approach that leverages 
the information across different views to 
effectively boost the learning from unlabeled data. 
We have shown that both Co-training and Co-
EM not only outperform the unsupervised learning 
of single view, but also alleviate the need of data 
labeling. This reaffirms that multi-view is a viable 
solution to the learning of transliteration model and 
hence transliteration extraction. Moving forward, 
we believe that contextual feature in documents 
presents another compatible, uncorrelated, and 
complementary view to the four views. 
We validate the effectiveness of the proposed 
algorithms by conducting experiments on 
transliteration extraction. We hope to extend the 
work further by investigating the possibility of 
applying the multi-view learning algorithms to 
machine translation.  
References 
S. Bilac and H. Tanaka. 2004. Improving back-
transliteration by combining information sources, In 
Proc. of Int?l Joint Conf. on Natural Language 
Processing, pp. 542-547. 
379
S. Blum and T. Mitchell. 1998. Combining Labeled and 
Unlabeled Data with Co-training, In Proc. of 11th 
Conference on Computational Learning Theory, pp. 
92-100. 
E. Brill, G. Kacmarcik and C. Brockett. 2001. 
Automatically Harvesting Katakana-English Term 
Pairs from Search Engine Query Logs, In Proc. of 
Natural Language Processing Pacific Rim 
Symposium (NLPPRS), pp. 393-399. 
H.-H. Chen, W.-C. Lin, C.-H. Yang and W.-H. Lin. 
2006, Translating-Transliterating Named Entities for 
Multilingual Information Access, Journal of the 
American Society for Information Science and 
Technology, 57(5), pp. 645-659. 
A. P. Dempster, N. M. Laird and D. B. Rubin. 1977. 
Maximum Likelihood from Incomplete Data via the 
EM Algorithm, Journal of the Royal Statistical 
Society, Ser. B. Vol. 39, pp. 1-38. 
K. S. Jeong, S. H. Myaeng, J. S. Lee and K.-S. Choi. 
1999. Automatic Identification and Back-
transliteration of Foreign Words for Information 
Retrieval, Information Processing and Management, 
Vol. 35, pp. 523-540. 
K. Knight and J. Graehl. 1998. Machine Transliteration, 
Computational Linguistics, Vol. 24, No. 4, pp. 599-
612. 
J.-S. Kuo, H. Li and Y.-K. Yang. 2006. Learning 
Transliteration Lexicons from the Web, In Proc. of 
44th ACL, pp. 1129-1136. 
J.-S. Kuo, H. Li and Y.-K. Yang. 2007. A Phonetic 
Similarity Model for Automatic Extraction of 
Transliteration Pairs, ACM Transactions on Asian 
Language Information Processing. 6(2), pp. 1-24. 
J.-S. Lee. 1999. An English-Korean Transliteration and 
Retransliteration Model for Cross-Lingual 
Information Retrieval, PhD Thesis, Department of 
Computer Science, KAIST. 
D. D. Lewis and J. Catlett. 1994. Heterogeneous 
Uncertainty Sampling for Supervised Learning, In 
Proc. of Int?l Conference on Machine Learning 
(ICML), pp. 148-156. 
H. Li, M. Zhang and J. Su. 2004. A Joint Source 
Channel Model for Machine Transliteration, In Proc. 
of 42nd ACL, pp. 159-166. 
C. D. Manning and H. Scheutze. 1999. Fundamentals of 
Statistical Natural Language Processing, The MIT 
Press. 
H. M. Meng, W.-K. Lo, B. Chen and T. Tang. 2001. 
Generate Phonetic Cognates to Handle Name Entities 
in English-Chinese Cross-Language Spoken 
Document Retrieval, In Proceedings of Automatic 
Speech Recognition Understanding (ASRU), pp. 311-
314. 
I. Muslea, S. Minton and C. A. Knoblock. 2002. Active 
+ Semi-supervised learning = Robust Multi-View 
Learning, In Proc. of the 9th Int?l Conference on 
Machine Learning, pp. 435-442. 
J.-Y. Nie, P. Isabelle, M. Simard and R. Durand. 1999. 
Cross-language Information Retrieval based on 
Parallel Texts and Automatic Mining of Parallel Text 
from the Web, In Proc. of 22nd ACM SIGIR, pp 74-81. 
K. Nigam and R. Ghani. 2000. Analyzing the 
Effectiveness and Applicability of Co-training, In 
Proc. of the 9th Conference in Information and 
Knowledge and Management, pp. 86-93. 
J.-H. Oh, K.-S. Choi and H. Isahara. 2006a. A Machine 
Transliteration Model based on Graphemes and 
Phonemes, ACM TALIP, Vol. 5, No. 3, pp. 185-208. 
J.-H. Oh and K.-S. Choi. 2006b. An Ensemble of 
Transliteration Models for Information Retrieval, In 
Information Processing and Management, Vol. 42, pp. 
980-1002. 
R. Sproat, T. Tao and C. Zhai. 2006. Named Entity 
Transliteration with Comparable Corpora, In Proc. of 
44th ACL, pp. 73-80. 
G. T?r, D. Hakkani-T?r and R. E. Schapire. 2005. 
Combining Active and Semi-supervised Learning for 
Spoken Language Understanding, Speech 
Communication, 45, pp. 171-186. 
B. Vauqois. 1988. A Survey of Formal Grammars and 
Algorithms for Recognition and Transformation in 
Machine Translation, IFIP Congress-68, reprinted  
TAO: Vingtcinq Ans de Traduction Automatique - 
Analectes in C. Boitet, Ed., Association Champollin, 
Grenoble, pp.201-213 
P. Virga and S. Khudanpur. 2003. Transliteration of 
Proper Names in Cross-Lingual Information Retrieval, 
In Proceedings of 41st ACL Workshop on 
Multilingual and Mixed Language Named Entity 
Recognition, pp. 57-64. 
380
Mining Transliterations from Web Query Results: 
An Incremental Approach 
Jin-Shea Kuo Haizhou Li Chih-Lung Lin 
Chung-Hwa Telecomm.  
Laboratories, Taiwan 
d8807302 @gmail.com 
Institute for Infocomm  
Research, Singapore 119613 
hzli@ieee.com 
Chung Yuan Christian 
 University, Taiwan 
linclr@gmail.com 
 
Abstract 
We study an adaptive learning framework 
for phonetic similarity modeling (PSM) that 
supports the automatic acquisition of trans-
literations by exploiting minimum prior 
knowledge about machine transliteration to 
mine transliterations incrementally from the 
live Web. We formulate an incremental 
learning strategy for the framework based 
on Bayesian theory for PSM adaptation. 
The idea of incremental learning is to bene-
fit from the continuously developing his-
tory to update a static model towards the in-
tended reality. In this way, the learning 
process refines the PSM incrementally 
while constructing a transliteration lexicon 
at the same time on a development corpus. 
We further demonstrate that the proposed 
learning framework is reliably effective in 
mining live transliterations from Web query 
results. 
1 Introduction 
Transliteration is a process of rewriting a word 
from one language into another by preserving its 
pronunciation in its original language, also known 
as translation-by-sound. It usually takes place be-
tween languages with different scripts, for example, 
from English to Chinese, and words, such as proper 
nouns, that do not have ?easy? or semantic transla-
tions. 
The increasing size of multilingual content on 
the Web has made it a live information source rich 
in transliterations. Research on automatic acquisi-
tion of transliteration pairs in batch mode has 
shown promising results (Kuo et al, 2006). In 
dealing with the dynamic growth of the Web, it is 
almost impossible to collect and store all its con-
tents in local storage. Therefore, there is a need to 
develop an incremental learning algorithm to mine 
transliterations in an on-line manner. In general, an 
incremental learning technique is designed for 
adapting a model towards a changing environment. 
We are interested in deducing the incremental 
learning method for automatically constructing an 
English-Chinese (E-C) transliteration lexicon from 
Web query results.  
In the deduction, we start with a phonetic simi-
larity model (PSM), which measures the phonetic 
similarity between words in two different scripts, 
and study the learning mechanism of PSM in both 
batch and incremental modes. The contributions of 
this paper include: (i) the formulation of a batch 
learning framework and an incremental learning 
framework for PSM learning; (ii) a comparative 
study of the batch and incremental unsupervised 
learning strategies. 
In this paper, Section 2 briefly introduces prior 
work related to machine transliteration. In Section 
3, we formulate the PSM and its batch and incre-
mental learning algorithms while in Section 4, we 
discuss the practical issues in implementation. Sec-
tion 5 provides a report on the experiments con-
ducted and finally, we conclude in Section 6. 
2 Related Work 
Much of research on extraction of transliterations 
has been motivated by information retrieval tech-
niques, where attempts to extracting transliteration 
pairs from large bodies of corpora have been made. 
Some have proposed extracting translations from 
parallel or comparable bitexts using co-occurrence 
analysis or a context-vector approach (Fung and 
Yee, 1998; Nie et al, 1999). These methods com-
pare the semantic similarities between source and 
target words without taking their phonetic similari-
ties into account.  
Another direction of research is focused on es-
16
Sixth SIGHAN Workshop on Chinese Language Processing
tablishing the phonetic relationship between trans-
literation pairs. This typically involves the encod-
ing of phoneme- or grapheme-based mapping rules 
using a generative model trained from a large bi-
lingual lexicon. Suppose that EW and CW form an 
E-C transliteration pair. The phoneme-based ap-
proach (Knight & Graehl, 1998) first converts EW 
into an intermediate phonemic representation and 
then converts the phonemic representation into its 
Chinese counterpart CW. The grapheme-based ap-
proach, also known as direct orthographical map-
ping (Li et al, 2004), which treats transliteration as 
a statistical machine translation problem under 
monotonic constraints, has also achieved promising 
results. 
Many efforts have also been channeled to tap-
ping the wealth of the Web for harvesting translit-
eration/translation pairs. These include studying the 
query logs (Brill et al, 2001), unrelated corpora 
(Rapp, 1999), and comparable corpora (Sproat et al 
2006). To establish cross-lingual correspondence in 
the harvest, these algorithms usually rely on one or 
more statistical clues (Lam et al, 2004), such as 
the correlation between word frequencies, and cog-
nates of similar spelling or pronunciations. In doing 
so, two things are needed: first, a robust mecha-
nism that establishes statistical relationships be-
tween bilingual words, such as a phonetic similar-
ity model which is motivated by transliteration 
modeling research; and second, an effective learn-
ing framework that is able to adaptively discover 
new events from the Web.  
In Chinese/Japanese/Korean (CJK) Web pages, 
translated terms are frequently accompanied by 
their original Latin words, with the Latin words 
serving as the appositives of the CJK words. In 
other words, the E-C pairs are always closely col-
located. Inspired by this observation in CJK texts, 
some algorithms were proposed (Kuo et al, 2006) 
to search over the close context of an English word 
in a Chinese predominant bilingual snippet for 
transliteration.  
Unfortunately, many of the reported works have 
not taken the dynamic nature of the Web into ac-
count. In this paper, we study the learning frame-
work of the phonetic similarity model, which 
adopts a transliteration modeling approach for 
transliteration extraction from the Web in an in-
cremental manner.   
3 Phonetic Similarity Model 
Phonetic similarity model (PSM) is a probabilistic 
model that encodes the syllable mapping between 
E-C pairs. Let 1{ ,... ,... }m MES e e e= be a sequence of 
English syllables derived from EW and 
1{ ,... ,... }n NCS s s s=  be the sequence of Chinese syl-
lables derived from CW, represented by a Chinese 
character string 1,... ,...,n NCW w w w? . If each of the 
English syllables is drawn from a vocabulary of X 
entries, 1{ ,..., }m Ie x x? , and each of the Chinese 
syllable from a vocabulary of Y entries, 
1{ ,..., }n Js y y? , then the E-C transliteration can be 
considered as a generative process formulated by 
the noisy channel model, which recovers the input 
CW from the observed output EW. Applying 
Bayesian rule, we have Eq. (1), where ( | )P EW CW  
is estimated to characterize the noisy channel, 
known as the transliteration probability and 
( )P CW  is a language model to characterize the 
source language.  
( | ) ( | ) ( ) / ( )P CW EW P EW CW P CW P EW= . (1) 
Following the translation-by-sound principle, 
( | )P EW CW can be approximated by the phonetic 
probability ( | )P ES CS , which is given by Eq. (2).  
( | ) max ( , | ),P ES CS P ES CS
???
= ?     (2) 
where ?  is the set of all possible alignment paths 
between ES and CS. To find the best alignment 
path ? , one can resort to a dynamic warping algo-
rithm (Myers and Rabiner, 1981). Assuming condi-
tional independence of syllables in ES and CS, we 
have 
1
( | ) ( | )
k k
K
m nk
P ES CS P e s==?  where k is the 
index of alignment. We rewrite Eq.(1) as, 
( | ) ( | ) ( ) / ( )P CW EW P ES CS P CW P EW? .  (3) 
The language model ( )P CW in Eq.(3) can be repre-
sented by the n-gram statistics of the Chinese char-
acters derived from a monolingual corpus. Using 
bigram to approximate the n-gram model, we have 
1 12
( ) ( ) ( | )
N
n nn
P CW P w P w w ?=? ? .  (4) 
Removing ( )P EW  from Eq.(3) which is not a func-
tion of CW, a PSM ? now consists of both 
( | )P ES CS and ( )P CW  parameters (Kuo et al, 
2007). We now look into the mathematic formula-
tion for the learning of ( | )P ES CS  parameters from 
a bilingual transliteration lexicon.  
3.1 Batch Learning of PSM  
17
Sixth SIGHAN Workshop on Chinese Language Processing
A collection of manually selected or automatically 
extracted E-C pairs can form a transliteration lexi-
con. Given such a lexicon for training, the PSM 
parameters can be estimated in a batch mode. An 
initial PSM is bootstrapped using limited prior 
knowledge such as a small amount of translitera-
tions, which may be obtained by exploiting co-
occurrence information (Sproat et al, 2006). Then 
we align the E-C pairs using the PSM ? and derive 
syllable mapping statistics.  
Suppose that we have the event counts ,i jc =  
( , )m i n jcount e x s y= = , and ( )j n jc count s y= =  for a 
given transliteration lexicon D with alignments ? . 
We would like to find the parameters 
|i jP = ( | )m i n jP e x s y= = , ,m ne s< >?? , that maxi-
mize the probability, 
,
|
( , | ) ( | ) i j
c
m n j i i j
P D P e s P?? ? = =? ? ? ,       (5) 
where |{ , 1,..., , 1,..., }i jP i I j J? = = = , with maximum 
likelihood estimation (MLE) criteria, subject to the 
constraints of | 1,i jiP j= ?? . Rewriting Eq.(5) in 
log-likelihood ( LL )  
, |
( , | )
log ( | ) logm n i j i j
j i
LL D
P e s c P?
? ?
= =? ??                 (6) 
It is described as the cross-entropy of the true data 
distribution ,i jc with regard to the PSM model. 
Given an alignment ??? , the MLE estimate of 
PSM is: 
| , /i j i j jP c c= .              (7) 
With a new PSM, one is able to arrive at a new 
alignment. This is formulated as an expectation-
maximization (EM) process (Dempster, 1977), 
which assumes that there exists a mappingD?? , 
where ?  is introduced as the latent information, 
also known as missing data in the EM literature. 
The EM algorithm maximizes the likelihood prob-
ability ( | )P D ?  over ?  by exploiting 
( | ) ( , | )P D P D?? = ? ?? .  
The EM process guarantees non-decreasing like-
lihood probability ( | )P D ? through multiple EM 
steps until it converges. In the E-step, we derive the 
event counts ,i jc  and jc  by force-aligning all the 
E-C pairs in the training lexicon D  using a PSM. 
In the M-step, we estimate the PSM parameters ?  
by Eq.(7). The EM process also serves as a refining 
process to obtain the best alignment between the E-
C syllables. In each EM cycle, the model is updated 
after observing the whole corpus D . An EM cycle 
is also called an iteration in batch learning. The 
batch learning process is described as follows and 
depicted in Figure 1. 
 
 
Figure 1. Batch learning of PSM   
 
Batch Learning Algorithm: 
Start: Bootstrap PSM parameters |i jP using prior 
phonetic mapping knowledge; 
E-Step: Force-align corpus D  using |i jP  to obtain 
?  and hence the counts of ,i jc  and jc ; 
M-Step: Re-estimate | , /i j i j jP c c=  using the counts 
from E-Step; 
Iterate: Repeat E-Step and M-Step until ( | )P D ?  
converges; 
3.2 Incremental Learning of PSM  
In batch learning all the training samples have to be 
collected in advance. In a dynamically changing 
environment, such as the Web, new samples always 
appear and it is impossible to collect all of them. 
Incremental learning (Zavaliagkos, 1995) is de-
vised to achieve rapid adaptation towards the work-
ing environment by updating the model as learning 
samples arrive in sequence. It is believed that if the 
statistics for the E-step are incrementally collected 
and the parameters are frequently estimated, incre-
mental learning converges quicker because the in-
formation from the new data contributes to the pa-
rameter estimation more effectively than the batch 
algorithm does (Gotoh et al, 1998). In incremental 
learning, the model is typically updated progres-
sively as the training samples become available and 
the number of incremental samples may vary from 
as few as one to as many as they are available. In 
the extreme case where all the learning samples are 
Iterate 
Initial 
PSM 
E-Step 
 
Training 
Corpus 
M-Step Final PSM 
18
Sixth SIGHAN Workshop on Chinese Language Processing
available and the updating is done after observing 
all of them, the incremental learning becomes batch 
learning. Therefore, the batch learning can be con-
sidered as a special case of the incremental learning. 
The incremental learning can be formulated 
through maximum a posteriori (MAP) framework, 
also known as Bayesian learning, where we assume 
that the parameters ?  are random variables subject 
to a prior distribution. A possible candidate for the 
prior distribution of |i jP  is the Dirichlet density 
over each of the parameters |i jP (Bacchiani et al, 
2006). Let |{ , 1,..., }j i jP i I? = = , we introduce, 
| 1
|( ) ,i j
h
j i ji
P P j? ?? ? ?? ,   (8) 
where | 1i ji h =? , and ? , which can be empirically 
set, is a positive scalar. Assuming H is the set of 
hyperparameters, we have as many hyperparame-
ters |i jh H? as the parameters |i jP . The probability 
of generating the aligned transliteration lexicon is 
obtained by integrating over the parameter space, 
( ) ( | ) ( )P D P D P d= ? ? ?? . 
This integration can be easily written down in a 
closed form due to the conjugacy between Dirichlet 
distribution | 1| i j
h
i ji
P ? ??  and the multinomial dis-
tribution ,
|
i jc
i i j
P? . Instead of finding ?  that 
maximizes ( | )P D ? with MLE, we maximize a 
posteriori (MAP) probability as follows: 
argmax ( | ) argmax ( | ) ( ) / ( )
argmax ( | ) ( ) (9)
MAP P D P D P P D
P D P
? ?
?
? = ? = ? ?
= ? ?
The MAP solution uses a distribution to model the 
uncertainty of the parameters ? , while the MLE 
gives a point estimation (Jelinek, 1990; MacKay, 
1994). We rewrite Eq.(9) as Eq.(10) using Eq.(5) 
and Eq.(8).  
, | 1
|argmax i j i j
j
c hmap
j i ji
P ?+ ?
?
? ? ?                        (10) 
Eq.(10) can be seen as a Dirichlet function of ?  
given H , or a multinomial function of H given ? . 
With given prior H , the MAP estimation is there-
fore similar to the MLE problem which is to find 
the mode of the kernel density in Eq.(10).  
| | |(1 )i j i j i jP h f? ?= + ? ,             (11) 
where | , /i j i j jf c c= , ,/( )i ji c? ? ?= +? . 
One can find that ?  serves as a weighting factor 
between the prior and the current observations. The 
difference between MLE and MAP strategy lies in 
the fact that MAP introduces prior knowledge into 
the parameter updating formula. Eq.(11) assumes 
that the prior parameters H  are known and static 
while the training samples are available all at once.  
The idea of incremental learning is to benefit 
from the continuously developing history to update 
the static model towards the intended reality. As is 
often the case, the Web query results in an on-line 
application arrive in sequence. It is of practical use 
to devise such an incremental mechanism that 
adapts both parameters and the prior knowledge 
over time. The quasi-Bayesian (QB) learning 
method offers a solution to it (Bai and Li, 2006). 
Let?s break up a training corpus D into a se-
quence of sample subsets 1 2{ , ,..., }TD D D D=  and 
denote an accumulated sample subset ( )tD =  
1 2{ , ,..., },1tD D D t T? ?  as an incremental corpus. 
Therefore, we have ( )TD D= . The QB method ap-
proximates the posterior probability ( 1)( | )tP D ??  
by the closest tractable prior density ( 1)( | )tP H ??  
with ( 1)tH ? evolved from historical corpus ( 1)tD ? ,  
( 1)
,
( ) ( )
( 1)
1
|1
argmax ( | )
argmax ( | ) ( | )
argmax , .
t
i j i
t t
QB
t
t
I c h
i ji
P D
P D P D
P j?
?
?
?
?
+ ?
=?
? = ?
? ? ?
= ??
          (12) 
QB estimation offers a recursive learning 
mechanism. Starting with a hyperparameter set 
(0)H  and a corpus subset 1D , we estimate (1)H  and 
(1)
QB? , then (2)H  and (2)QB?  and so on until ( )tH  and 
( )t
QB?  as observed samples arrive in sequence. The 
updating of parameters can be iterated between the 
reproducible prior and posterior estimates as in Eq. 
(13) and Eq. (14). Assuming T ?? , we have the 
following: 
 
Incremental Learning Algorithm: 
Start: Bootstrap (0)QB?  and (0)H using prior phonetic 
mapping knowledge and set 1t = ; 
E-Step: Force-align corpus subset tD  using ( 1)tQB?? , 
compute the event counts ( ),ti jc  and reproduce prior 
parameters ( 1) ( )t tH H? ? . 
( ) ( 1) ( )
,| | /
t t t
i ji j i jh h c
?= + ?           (13) 
19
Sixth SIGHAN Workshop on Chinese Language Processing
M-Step: Re-estimate parameters ( )( ) tt QBH ??  and 
|i jP  using the counts from E-Step. 
( ) ( ) ( )
| | |/
t t t
i j i j i ji
P h h= ?           (14) 
EM cycle: Repeat E-Step and M-Step until 
( )( | )tP D?  converges. 
Iterate: Repeat T EM cycles covering the entire 
data set D in an iteration. 
 
The algorithm updates the PSM as training sam-
ples become available. The scalar factor ?  can be 
seen as a forgetting factor. When ?  is big, the up-
date of hyperparameters favors the prior. Otherwise, 
current observation is given more attention. As for 
the sample subset size | |tD , if we set | | 100tD = , 
each EM cycle updates ?  after observing every 
100 samples. To be comparable with batch learning, 
we define an iteration here to be a sequence of EM 
cycles that covers the whole corpus D. If corpus D 
has a fixed size ( )| |TD , an iteration means T EM 
cycles in incremental learning.  
4 Mining Transliterations from the Web 
Since the Web is dynamically changing and new 
transliterations come out all the time, it is better to 
mine transliterations from the Web in an incre-
mental way. Words transliterated by closely ob-
serving common guidelines are referred to as regu-
lar transliterations. However, in Web publishing, 
translators in different regions may not observe the 
same guidelines. Sometimes they skew the translit-
erations in different ways to introduce semantic 
implications, also known as wordplay, resulting in 
casual transliterations. Casual transliteration leads 
to multiple Chinese transliteration variants for the 
same English word. For example, ?Disney? may be 
transliterated into ????/Di-Shi-Ni/1?, ????
/Di-Si-Nai/? and ????/Di-Si-Nai/?.  
Suppose that a sufficiently large, manually vali-
dated transliteration lexicon is available, a PSM 
can be built in a supervised manner. However, this 
method hinges on the availability of such a lexicon.  
Even if a lexicon is available, the derived model 
can only be as good as what the training lexicon 
offers. New transliterations, such as casual ones, 
may not be well handled. It is desirable to adapt the 
PSM as new transliterations become available, also 
                                                 
1 The Chinese words are romanized in Hanyu Pinyin. 
referred to as the learning-at-work mechanism. 
Some solutions have been proposed recently along 
this direction (Kuo et al, 2006). However, the ef-
fort was mainly devoted to mitigating the need of 
manual labeling. A dynamic learning-at-work 
mechanism for mining transliterations has not been 
well studied. 
Here we are interested in an unsupervised learn-
ing process, in which we adapt the PSM as we ex-
tract transliterations. The learning-at-work frame-
work is illustrated in Figure 2. As opposed to a 
manually labeled training corpus in Figure 1, we 
insert into the EM process an automatic translitera-
tion extraction mechanism, search and rank, as 
shown in the left panel of Figure 2. The search and 
rank shortlists a set of transliterations from the 
Web query results or bilingual snippets. 
 
 
Figure 2. Diagram of unsupervised transliteration 
extraction ? learning-at-work. 
4.1 Search and Rank 
We obtain bilingual snippets from the Web by 
iteratively submitting queries to the Web search 
engines (Brin and Page, 1998). Qualified sentences 
are extracted from the results of each query. Each 
qualified sentence has at least one English word.  
Given a qualified sentence, first, the competing 
Chinese transliteration candidates are denoted as a 
set ? , from which we would like to pick the most 
likely one. Second, we would like to know if there 
is indeed a Chinese transliteration CW in the close 
context of the English word EW. 
We propose ranking the candidates using the 
PSM model to find the most likely CW for a given 
EW. The CW candidate that gives the highest poste-
rior probability is considered the most probable 
Final 
PSM 
Initial PSM 
E-Step 
M-Step 
The Web 
 
Transliterations 
Search and 
Rank 
Final  
Lexicon 
Iterate 
20
Sixth SIGHAN Workshop on Chinese Language Processing
candidate CW ? .  
argmax ( | )
argmax ( | ) ( )
CW
CW
CW P CW EW
P ES CS P CW
??
??
? =
?           (15) 
The next step is to examine if CW ?  and EW indeed 
form a genuine E-C pair. We define the confidence 
of the E-C pair as the posterior odds similar to that 
in a hypothesis test under the Bayesian interpreta-
tion. We have 0H , which hypothesizes that 
CW ? and EW  form an E-C pair, and 1H , which 
hypothesizes otherwise, and use posterior odd ?  
(Kuo et al, 2006) for hypothesis tests. 
Our search and rank formulation can be seen as 
an extension to a prior work (Brill et al, 2001). 
The posterior odd ?  is used as the confidence 
score so that E-C pairs extracted from different 
contexts can be directly compared. In practice, we 
set a threshold for ?  to decide on a cutoff point for 
E-C pairs short-listing. In this way, the search and 
rank is able to retrieve a collection of translitera-
tions from the Web given a PSM. 
4.2 Unsupervised Learning Strategy 
Now we can carry out PSM learning as formulated 
in Section 3 using the transliterations as if they 
were manually validated. By unsupervised batch 
learning, we mean to re-estimate the PSM after 
search and rank over the whole database, i.e., in 
each iteration. Just as in supervised learning, one 
can expect the PSM performance to improve over 
multiple iterations. We report the F-measure at 
each iteration. The extracted transliterations also 
form a new training corpus in next iteration. 
In contrast to the batch learning, incremental 
learning updates the PSM parameters as the train-
ing samples arrive in sequence. This is especially 
useful in Web mining. With the QB incremental 
optimization, one can think of an EM process that 
continuously re-estimates PSM parameters as the 
Web crawler discovers new ?territories?. In this 
way, the search and rank process gathers qualified 
training samples tD after crawling a portion of the 
Web. Note that the incremental EM process up-
dates parameters more often than batch learning 
does. To evaluate performance of both learning, we 
define an iteration to be T EM cycles in incre-
mental learning on a training corpus ( )TD D=  as 
discussed in Section 3.2.  
5 Experiments 
To obtain the ground truth for performance evalua-
tion, each possible transliteration pair is manually 
checked based on the following criteria: (i) only the 
phonetic transliteration is extracted to form a trans-
literation pair; (ii) multiple E-C pairs may appear in 
one sentence; (iii) an EW can have multiple valid 
Chinese transliterations and vice versa. The valida-
tion process results in a collection of qualified E-C 
pairs, also referred to as distinct qualified translit-
eration pairs (DQTPs), which form a translitera-
tion lexicon. 
To simulate the dynamic Web, we collected a 
Web corpus, which consists of about 500 MB of 
Web pages, referred to as SET1. From SET1, 
80,094 qualified sentences were automatically ex-
tracted and 8,898 DQTPs were further selected 
with manual validation.  
To establish a reference for performance bench-
marking, we first initialize a PSM, referred to as 
seed PSM hereafter, using randomly selected 100 
seed DQTPs. By exploiting the seed PSM on all 
8,898 DQTPs, we train a PSM in a supervised 
batch mode and improve the PSM on SET1 after 
each iteration. The performance defined below in 
precision, recall and F-measure in the 6th iteration 
is reported in Table 1 and the F-measure is also 
shown in Figure 3.  
# _ /# _ ,
# _ /# _ ,
2 /( )
precision extracted DQTPs extracted pairs
recall extracted DQTPs total DQTPs
F measure recall precision recall precision
=
=
? = ? ? +
  
 
 Precision Recall F-measure 
Closed-test 0.834 0.663 0.739 
Table 1. The performance achieved by supervised 
batch learning on SET1. 
 
We use this closed test (supervised batch learning) 
as the reference point for unsupervised experiments. 
Next we further implement two PSM learning 
strategies, namely unsupervised batch and unsu-
pervised incremental learning. 
5.1 Unsupervised Batch Learning 
We begin with the same seed PSM. However, we 
use transliterations that are extracted automatically 
instead of manually validated DQTPs for training. 
Note that the transliterations are extracted and col-
lected at the end of each iteration. It may differ 
from one iteration to another. After re-estimating 
21
Sixth SIGHAN Workshop on Chinese Language Processing
the PSM in each iteration, we evaluate performance 
on SET1. 
Comparing the two batch mode learning strate-
gies in Figure 3, it is observed that learning sub-
stantially improves the seed PSM after the first it-
eration. Without surprise, the supervised learning 
consistently outperforms the unsupervised one, 
which reaches a plateau at 0.679 F-measure. This 
performance is considered as the baseline for com-
parison in this paper. The unsupervised batch learn-
ing presented here is similar to that in (Kuo et al, 
2006).  
0.45
0.55
0.65
0.75
1 2 3 4 5 6
#Iteration
F-
m
ea
su
re
Supervised Batch
Unsupervised Batch
U-Incremental (100)
U-Incremental (5,000)
 
Figure 3. Comparison of F-measure over iterations 
(U-Incremental: Unsupervised Incremental). 
5.2 Unsupervised Incremental Learning 
We now formulate an on-line2 unsupervised incre-
mental learning algorithm: 
(i) Start with the seed PSM, set 1t = ; 
(ii) Extract | |tD  quasi-transliterations pairs fol-
lowed by E-Step in incremental learning algo-
rithm; 
(iii) Re-estimate PSM using | |tD  (M-Step), 1t t= + ; 
(iv) Repeat (ii) and (iii) to crawl over a corpus. 
 
To simulate the on-line incremental learning just 
described, we train and test on SET1 because of the 
availability of gold standard and comparison with 
performance by batch mode. We empirically set 
0.5? =  and study different | |tD settings. An itera-
tion is defined as multiple cycles of steps (ii)-(iii) 
that screen through the whole SET1 once. We run 
multiple iterations. 
The performance of incremental learning with 
| | 100tD = and | | 5,000tD = are reported in Figure 3. 
It is observed that incremental learning benefits 
from more frequent PSM updating. With | | 100tD = , 
it not only attains good F-measure in the first itera-
                                                 
2 In an actual on-line environment, we are not supposed to 
store documents, thus no iteration can take place. 
tion, but also outperforms that of unsupervised 
batch learning along the EM process. The PSM 
updating becomes less frequent for larger | |tD . 
When | |tD  is set to be the whole corpus, then in-
cremental learning becomes a batch mode learning, 
which is evidenced by | | 5,000tD =  and it performs 
close to the batch mode learning. The experiments 
in Figure 3 are considered closed tests. Next we 
move on to an actual on-line experiment. 
5.3 Learning from the Live Web  
In practice, it is possible to extract bilingual snip-
pets of interest by repeatedly submitting queries to 
the Web. With the learning-at-work mechanism, 
we can mine the query results for up-to-date trans-
literations in an on-line environment. For example, 
by submitting ?Amy? to search engines, we may 
get ?Amy-??/Ai-Mi/? and, as a by-product, ?Jes-
sica-???/Jie-Xi-Ka/? as well. In this way, new 
queries can be generated iteratively, thus new pairs 
are discovered.  
Following the unsupervised incremental learning 
algorithm, we start the crawling with the same seed 
PSM as in Section 5.2. We adapt the PSM as every 
100 quasi-transliterations are extracted, i.e. 
| | 100tD = . The crawling stops after accumulating 
67,944 Web pages, where there are 100 snippets at 
most in a page, with 2,122,026 qualified sentences. 
We obtain 123,215 distinct E-C pairs when the 
crawling stops. For comparison, we also carry out 
unsupervised batch learning over the same 
2,122,026 qualified sentences in a single iteration 
under such an on-line environment. As the gold 
standard for this live corpus is not available, we 
randomly select 500 quasi-transliteration pairs for 
manual checking of precision (see Table 2). It is 
found that incremental learning is more productive 
than batch learning in discovering transliteration 
pairs. This finding is consistent with the test results 
on SET1. 
 
 Unsupervised Batch 
Unsupervised 
Incremental  
#distinct E-C pairs 67,708 123,215 
Estimated Precision 0.758 0.768 
Table 2. Comparison between the unsupervised 
batch and incremental learning from live Web. 
 
The live Web corpus was used in transliteration 
extraction using active learning (Kuo et al, 2006). 
22
Sixth SIGHAN Workshop on Chinese Language Processing
Kuo et al reported slightly better performance by 
annotating some samples manually and adapting 
the learning process in a batch manner. However, it 
is apparent that, in an on-line environment, the un-
supervised learning is more suitable for discovering 
knowledge without resorting to human annotation; 
incremental learning is desirable as it does not re-
quire storing all documents in advance.  
6 Conclusions 
We have proposed a learning framework for min-
ing E-C transliterations using bilingual snippets 
from a live Web corpus. In this learning-at-work 
framework, we formulate the PSM learning method 
and study strategies for PSM learning in both batch 
and incremental manners. The batch mode learning 
benefits from multiple iterations for improving per-
formance, while the unsupervised incremental one, 
which does not require all the training data to be 
available in advance, adapts to the dynamically 
changing environment easily without compromis-
ing the performance. Unsupervised incremental 
learning provides a practical and effective solution 
to transliteration extraction from query results, 
which can be easily extended to other Web mining 
applications.  
References 
S. Bai and H. Li. 2006. Bayesian Learning of N-gram 
Statistical Language Modeling, In Proc. of ICASSP, 
pp. 1045-1048. 
M. Bacchiani, B. Roark, M. Riley and R. Sproat. 2006. 
MAP Adaptation of Stochastic Grammars, Computer 
Speech and Language, 20(1), pp. 41-68. 
E. Brill, G. Kacmarcik, C. Brockett. 2001. Automati-
cally Harvesting Katakana-English Term Pairs from 
Search Engine Query Logs, In Proc. of NLPPRS, pp. 
393-399. 
S. Brin and L. Page. 1998. The Anatomy of a Large-
scale Hypertextual Web Search Engine, In Proc. of 7th 
WWW, pp. 107-117. 
A. P. Dempster, N. M. Laird and D. B. Rubin. 1977. 
Maximum Likelihood from Incomplete Data via the 
EM Algorithm, Journal of the Royal Statistical Soci-
ety, Ser. B. Vol. 39, pp. 1-38. 
P. Fung and L.-Y. Yee. 1998. An IR Approach for 
Translating New Words from Nonparallel, Compara-
ble Texts, In Proc. of 17th COLING and 36th ACL, pp. 
414-420. 
Y. Gotoh, M. M. Hochberg and H. F. Silverman. 1998. 
Efficient Training Algorithms for HMM?s Using In-
cremental Estimation, IEEE Trans. on Speech and 
Audio Processing, 6(6), pp. 539-547. 
F. Jelinek. 1999. Self-organized Language Modeling for 
Speech Recognition, Readings in speech recognition, 
Morgan Kaufmann, pp. 450-506. 
D. Jurafsky and J. H. Martin. 2000. Speech and Lan-
guage Processing, pp. 102-120, Prentice-Hall, New 
Jersey. 
K. Knight and J. Graehl. 1998. Machine Transliteration, 
Computational Linguistics, 24(4), pp. 599-612. 
J.-S. Kuo, H. Li and Y.-K. Yang. 2006. Learning Trans-
literation Lexicons from the Web, In Proc. of 44th 
ACL, pp. 1129-1136. 
J.-S. Kuo, H. Li and Y.-K. Yang. 2007. A Phonetic 
Similarity Model for Automatic Extraction of Trans-
literation Pairs, ACM TALIP, 6(2), pp. 1-24.  
H. Li, M. Zhang and J. Su. 2004. A Joint Source Chan-
nel Model for Machine Transliteration, In Proc. of 
42nd ACL, pp. 159-166. 
W. Lam, R.-Z. Huang and P.-S. Cheung. 2004. Learning 
Phonetic Similarity for Matching Named Entity 
Translations and Mining New Translations, In Proc. 
of 27th ACM SIGIR, pp. 289-296. 
D. MacKay and L. Peto. 1994. A Hierarchical Dirichlet 
Language Model, Natural Language Engineering, 
1(3), pp.1-19.  
C. S. Myers and L. R. Rabiner. 1981. A Comparative 
Study of Several Dynamic Time-warping Algorithms 
for Connected word Recognition, The Bell System 
Technical Journal, 60(7), pp. 1389-1409. 
J.-Y. Nie, P. Isabelle, M. Simard and R. Durand. 1999. 
Cross-language Information Retrieval based on Paral-
lel Texts and Automatic Mining of Parallel Text from 
the Web, In Proc. of 22nd ACM SIGIR, pp. 74-81. 
R. Rapp. 1999. Automatic Identification of Word Trans-
lations from Unrelated English and German Corpora, 
In Proc. of 37th ACL, pp. 519-526. 
R. Sproat, T. Tao and C. Zhai. 2006. Named Entity 
Transliteration with Comparable Corpora, In Proc. of 
44th ACL, pp. 73-80. 
G. Zavaliagkos, R. Schwartz, and J. Makhoul. 1995. 
Batch, Incremental and Instantaneous Adaptation 
Techniques for Speech Recognition, In Proc. of 
ICASSP, pp. 676-679. 
23
Sixth SIGHAN Workshop on Chinese Language Processing
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 1129?1136,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Learning Transliteration Lexicons from the Web 
 
Jin-Shea Kuo1, 2 
1Chung-Hwa Telecom. 
Laboratories, Taiwan 
jskuo@cht.com.tw 
Haizhou Li 
Institute for Infocomm 
Research, Singapore  
hzli@ieee.org 
Ying-Kuei Yang2 
2National Taiwan University of 
Science and Technology, Taiwan  
ykyang@mouse.ee. 
ntust.edu.tw 
 
Abstract 
This paper presents an adaptive learning 
framework for Phonetic Similarity 
Modeling (PSM) that supports the 
automatic construction of transliteration 
lexicons. The learning algorithm starts 
with minimum prior knowledge about 
machine transliteration, and acquires 
knowledge iteratively from the Web. We 
study the active learning and the 
unsupervised learning strategies that 
minimize human supervision in terms of 
data labeling. The learning process 
refines the PSM and constructs a 
transliteration lexicon at the same time. 
We evaluate the proposed PSM and its 
learning algorithm through a series of 
systematic experiments, which show that 
the proposed framework is reliably 
effective on two independent databases. 
1 Introduction 
In applications such as cross-lingual information 
retrieval (CLIR) and machine translation (MT), 
there is an increasing need to translate out-of-
vocabulary (OOV) words, for example from an 
alphabetical language to Chinese. Foreign proper 
names constitute a good portion of OOV words, 
which are translated into Chinese through 
transliteration. Transliteration is a process of 
translating a foreign word into a native language 
by preserving its pronunciation in the original 
language, otherwise known as translation-by-
sound.  
MT and CLIR systems rely heavily on 
bilingual lexicons, which are typically compiled 
manually. However, in view of the current 
information explosion, it is labor intensive, if not 
impossible, to compile a complete proper nouns 
lexicon. The Web is growing at a fast pace and is 
providing a live information source that is rich in 
transliterations. This paper presents a novel 
solution for automatically constructing an 
English-Chinese transliteration lexicon from the 
Web. 
Research on automatic transliteration has 
reported promising results for regular 
transliteration (Wan and Verspoor, 1998; Li et al 
2004), where transliterations follow rigid 
guidelines. However, in Web publishing, 
translators in different countries and regions may 
not observe common guidelines. They often 
skew the transliterations in different ways to 
create special meanings to the sound equivalents, 
resulting in casual transliterations. In this case, 
the common generative models (Li et al 2004) 
fail to predict the transliteration most of the time. 
For example, ?Coca Cola? is transliterated into 
? ? ? ? ?  /Ke-Kou-Ke-Le/? as a sound 
equivalent in Chinese, which literately means 
?happiness in the mouth?. In this paper, we are 
interested in constructing lexicons that cover 
both regular and casual transliterations. 
When a new English word is first introduced, 
many transliterations are invented. Most of them 
are casual transliterations because a regular 
transliteration typically does not have many 
variations. After a while, the transliterations 
converge into one or two popular ones. For 
example, ?Taxi? becomes ???  /Di-Shi/? in 
China and ? ? ?  /De-Shi/? in Singapore. 
Therefore, the adequacy of a transliteration entry 
could be judged by its popularity and its 
conformity with the translation-by-sound 
principle. In any case, the phonetic similarity 
should serve as the primary basis of judgment. 
This paper is organized as follows. In Section 
2, we briefly introduce prior works pertaining to 
machine transliteration. In Section 3, we propose 
a phonetic similarity model (PSM) for 
confidence scoring of transliteration. In Section 4, 
we propose an adaptive learning process for 
PSM modeling and lexicon construction. In 
Section 5, we conduct experiments to evaluate 
different adaptive learning strategies. Finally, we 
conclude in Section 6. 
1129
2 Related Work 
In general, studies of transliteration fall into two 
categories: transliteration modeling (TM) and 
extraction of transliteration pairs (EX) from 
corpora.  
The TM approach models phoneme-based or 
grapheme-based mapping rules using a 
generative model that is trained from a large 
bilingual lexicon, with the objective of 
translating unknown words on the fly. The 
efforts are centered on establishing the phonetic 
relationship between transliteration pairs. Most 
of these works are devoted to phoneme1-based 
transliteration modeling (Wan and Verspoor 
1998, Knight and Graehl, 1998). Suppose that 
EW is an English word and CW is its prospective 
Chinese transliteration. The phoneme-based 
approach first converts EW into an intermediate 
phonemic representation P, and then converts the 
phonemic representation into its Chinese 
counterpart CW. In this way, EW and CW form 
an E-C transliteration pair. 
In this approach, we model the transliteration 
using two conditional probabilities, P(CW|P) and 
P(P|EW), in a generative model P(CW|EW) = 
P(CW|P)P(P|EW). Meng (2001) proposed a rule-
based mapping approach. Virga and Khudanpur 
(2003) and Kuo et al(2005) adopted the noisy-
channel modeling framework. Li et al(2004) 
took a different approach by introducing a joint 
source-channel model for direct orthography 
mapping (DOM), which treats transliteration as a 
statistical machine translation problem under 
monotonic constraints. The DOM approach, 
which is a grapheme-based approach, 
significantly outperforms the phoneme-based 
approaches in regular transliterations. It is noted 
that the state-of-the-art accuracy reported by Li 
et al(2004) for regular transliterations of the 
Xinhua database is about 70.1%, which leaves 
much room for improvement if one expects to 
use a generative model to construct a lexicon for 
casual transliterations. 
EX research is motivated by information 
retrieval techniques, where people attempt to 
extract transliteration pairs from corpora. The 
EX approach aims to construct a large and up-to-
date transliteration lexicon from live corpora. 
Towards this objective, some have proposed 
extracting translation pairs from parallel or 
comparable bitext using co-occurrence analysis 
                                               
1 Both phoneme and syllable based approaches are referred 
to as phoneme-based here. 
or a context-vector approach (Fung and Yee, 
1998; Nie et al 1999). These methods compare 
the semantic similarities between words without 
taking their phonetic similarities into accounts. 
Lee and Chang (2003) proposed using a 
probabilistic model to identify E-C pairs from 
aligned sentences using phonetic clues. Lam et al
(2004) proposed using semantic and phonetic 
clues to extract E-C pairs from comparable 
corpora. However, these approaches are subject 
to the availability of parallel or comparable 
bitext. A method that explores non-aligned text 
was proposed by harvesting katakana-English 
pairs from query logs (Brill et al 2001). It was 
discovered that the unsupervised learning of such 
a transliteration model could be overwhelmed by 
noisy data, resulting in a decrease in model 
accuracy.  
Many efforts have been made in using Web-
based resources for harvesting transliteration/ 
translation pairs. These include exploring query 
logs (Brill et al 2001), unrelated corpus (Rapp, 
1999), and parallel or comparable corpus (Fung 
and Yee, 1998; Nie et al 1999; Huang et al
2005). To establish correspondence, these 
algorithms usually rely on one or more statistical 
clues, such as the correlation between word 
frequencies, cognates of similar spelling or 
pronunciations. They include two aspects. First, 
a robust mechanism that establishes statistical 
relationships between bilingual words, such as a 
phonetic similarity model which is motivated by 
the TM research; and second, an effective 
learning framework that is able to adaptively 
discover new events from the Web. In the prior 
work, most of the phonetic similarity models 
were trained on a static lexicon. In this paper, we 
address the EX problem by exploiting a novel 
Web-based resource. We also propose a phonetic 
similarity model that generates confidence scores 
for the validation of E-C pairs. 
In Chinese webpages, translated or 
transliterated terms are frequently accompanied 
by their original Latin words. The latter serve as 
the appositives of the former. A sample search 
result for the query submission ?Kuro? is the 
bilingual snippet2 ?...?? Kuro?? P2P???
????????3 ??? P2P ???????
???? C2C (Content to Community)...?. The 
co-occurrence statistics in such a snippet was 
shown to be useful in constructing a transitive 
translation model (Lu et al 2002). In the 
                                               
2 A bilingual snippet refers to a Chinese predominant text 
with embedded English appositives. 
1130
example above, ?Content to Community? is not a 
transliteration of C2C, but rather an acronym 
expansion, while ??? /Ku-Luo/?, as underlined, 
presents a transliteration for ?Kuro?. What is 
important is that the E-C pairs are always closely 
collocated. Inspired by this observation, we 
propose an algorithm that searches over the close 
context of an English word in a bilingual snippet 
for the word?s transliteration candidates.  
The contributions of this paper include: (i) an 
approach to harvesting real life E-C 
transliteration pairs from the Web; (ii) a phonetic 
similarity model that evaluates the confidence of 
so extracted E-C pair candidates; (iii) a 
comparative study of several machine learning 
strategies. 
3 Phonetic Similarity Model 
English and Chinese have different syllable 
structures. Chinese is a syllabic language where 
each Chinese character is a syllable in either 
consonant-vowel (CV) or consonant-vowel-nasal 
(CVN) structure. A Chinese word consists of a 
sequence of characters, phonetically a sequence 
of syllables. Thus, in first E-C transliteration, it 
is a natural choice to syllabify an English word 
by converting its phoneme sequence into a 
sequence of Chinese-like syllables, and then 
convert it into a sequence of Chinese characters.  
There have been several effective algorithms 
for the syllabification of English words for 
transliteration. Typical syllabification algorithms 
first convert English graphemes to phonemes, 
referred to as the letter-to-sound transformation, 
then syllabify the phoneme sequence into a 
syllable sequence. For this method, a letter-to-
sound conversion is needed (Pagel, 1998; 
Jurafsky, 2000). The phoneme-based 
syllabification algorithm is referred to as PSA. 
Another syllabification technique attempts to 
map the grapheme of an English word to 
syllables directly (Kuo and Yang, 2004). The 
grapheme-based syllabification algorithm is 
referred to as GSA. In general, the size of a 
phoneme inventory is smaller than that of a 
grapheme inventory. The PSA therefore requires 
less training data for statistical modeling (Knight, 
1998); on the other hand, the grapheme-based 
method gets rid of the letter-to-sound conversion, 
which is one of the main causes of transliteration 
errors (Li et al 2004).   
Assuming that Chinese transliterations always 
co-occur in proximity to their original English 
words, we propose a phonetic similarity 
modeling (PSM) that measures the phonetic 
similarity between candidate transliteration pairs. 
In a bilingual snippet, when an English word EW 
is spotted, the method searches for the word?s 
possible Chinese transliteration CW in its 
neighborhood. EW can be a single word or a 
phrase of multiple English words. Next, we 
formulate the PSM and the estimation of its 
parameters.  
3.1 Generative Model 
Let 1{ ,... ,... }m MES es es es= be a sequence of 
English syllables derived from EW, using the 
PSA or GSA approach, and 1{ ,... ,... }n NCS cs cs cs=  
be the sequence of Chinese syllables derived 
from CW, represented by a Chinese character 
string 1,... ,...,n NCW c c c? . EW and CW is a 
transliteration pair. The E-C transliteration can 
be considered a generative process formulated by 
the noisy channel model, with EW as the input 
and CW as the output. ( / )P EW CW  is estimated 
to characterize the noisy channel, known as the 
transliteration probability. ( )P CW  is a language 
model to characterize the source language. 
Applying Bayes? rule, we have 
( / ) ( / ) ( ) / ( )P CW EW P EW CW P CW P EW=   (1) 
Following the translation-by-sound principle, the 
transliteration probability ( / )P EW CW can be 
approximated by the phonetic confusion 
probability ( / )P ES CS , which is given as 
( / ) max ( , / ),P ES CS P ES CSD?F= D   (2) 
where F  is the set of all possible alignment 
paths between ES and CS. It is not trivial to find 
the best alignment path D . One can resort to a 
dynamic programming algorithm. Assuming 
conditional independence of syllables in ES and 
CS, we have 1( / ) ( / )
M
m mmP ES CS p es cs== ?  in a 
special case where M N= . Note that, typically, 
we have N M?  due to syllable elision. We 
introduce a null syllable j  and a dynamic 
warping strategy to evaluate ( / )P ES CS  when 
M N? (Kuo et al 2005). With the phonetic 
approximation, Eq.(1) can be rewritten as 
( / ) ( / ) ( ) / ( )P CW EW P ES CS P CW P EW?     (3) 
The language model in Eq.(3) can be 
represented by Chinese characters n-gram 
statistics. 
1 2 11( ) ( / , ,..., )
N
n n nnP CW p c c c c- -== ?   (4) 
1131
In adopting bigram, Eq.(4) is rewritten as 
1 12( ) ( ) ( / )
N
n nnP CW p c p c c -=? ? . Note that the 
context of EW usually has a number of 
competing Chinese transliteration candidates in a 
set, denoted as W . We rank the candidates by 
Eq.(1) to find the most likely CW for a given EW. 
In this process, ( )P EW  can be ignored because it 
is the same for all CW candidates. The CW 
candidate that gives the highest posterior 
probability is considered the most probable 
candidate CW ? . 
arg max ( / )
arg max ( / ) ( )
CW
CW
CW P CW EW
P ES CS P CW
?W
?W
? =
?  (5) 
However, the most probable CW ?  isn?t 
necessarily the desired transliteration. The next 
step is to examine if CW ?  and EW indeed form a 
genuine E-C pair. We define the confidence of 
the E-C pair as the posterior odds similar to that 
in a hypothesis test under the Bayesian 
interpretation. We have 0H , which hypothesizes 
that CW ? and EW  form an E-C pair, and 1H , 
which hypothesizes otherwise. The posterior 
odds is given as follows,  
0
1
'
( / ) ( / ') ( ')
( / ) ( / ) ( )CW
CW CW
P H EW P ES CS P CW
P H EW P ES CS P CW
s
?W?
= ? ? (6) 
where 'CS is the syllable sequence of CW ? , 
1( / )p H EW  is approximated by the probability 
mass of the competing candidates of CW ? , 
or
'
( / ) ( )CW
CW CW
P ES CS P CW?W?? . The higher the s  
is, the more probable that hypothesis 
0H overtakes 1H . The PSM formulation can be 
seen as an extension to prior work (Brill et al 
2001) in transliteration modeling. We introduce 
the posterior odds s as the confidence score so 
that E-C pairs that are extracted from different 
contexts can be directly compared. In practice, 
we set a threshold for s  to decide a cutoff point 
for E-C pairs short-listing. 
3.2 PSM Estimation 
The PSM parameters are estimated from the 
statistics of a given transliteration lexicon, which 
is a collection of manually selected E-C pairs in 
supervised learning, or a collection of high 
confidence E-C pairs in unsupervised learning. 
An initial PSM is bootstrapped using prior 
knowledge such as rule-based syllable mapping. 
Then we align the E-C pairs with the PSM and 
derive syllable mapping statistics for PSA and 
GSA syllabifications. A final PSM is a linear 
combination of the PSA-based PSM (PSA-PSM) 
and the GSA-based PSM (GSA-PSM). The PSM 
parameter ( / )m np es cs can be estimated by an 
Expectation-Maximization (EM) process 
(Dempster, 1977). In the Expectation step, we 
compute the counts of events such as 
# ,m nes cs< >  and # ncs< >  by force-aligning the 
E-C pairs in the training lexicon Y . In the 
Maximization step, we estimate the PSM 
parameters ( / )m np es cs by  
( / ) # , /#m n m n np es cs es cs cs= < > < > .  (7) 
As the EM process guarantees non-decreasing 
likelihood probability ( / )P ES CS"Y? , we let 
the EM process iterate until ( / )P ES CS"Y?  
converges. The EM process can be thought of as 
a refining process to obtain the best alignment 
between the E-C syllables and at the same time a 
re-estimating process for PSM parameters. It is 
summarized as follows. 
Start: Bootstrap PSM parameters 
( / )m np es cs using prior phonetic mapping 
knowledge 
E-Step: Force-align corpus Y  using existing 
( / )m np es cs  and compute the counts of 
# ,m nes cs< >  and # ncs< > ; 
M-Step: Re-estimate ( / )m np es cs  using the 
counts from E-Step. 
Iterate: Repeat E-Step and M-Step until 
( / )P ES CS"Y?  converges. 
4 Adaptive Learning Framework 
We propose an adaptive learning framework 
under which we learn PSM and harvest E-C pairs 
from the Web at the same time. Conceptually, 
the adaptive learning is carried out as follows. 
We obtain bilingual snippets from the Web by 
iteratively submitting queries to the Web search 
engines (Brin and Page, 1998). For each batch of 
querying, the query results are all normalized to 
plain text, from which we further extract 
qualified sentences. A qualified sentence has at 
least one English word. Under this criterion, a 
collection of qualified sentences can be extracted 
automatically. To label the E-C pairs, each 
qualified sentence is manually checked based on 
the following transliteration criteria: (i) if an EW 
is partly translated phonetically and partly 
translated semantically, only the phonetic 
transliteration constituent is extracted to form a 
1132
transliteration pair; (ii) elision of English sound 
is accepted; (iii) multiple E-C pairs can appear in 
one sentence; (iv) an EW can have multiple valid 
Chinese transliterations and vice versa. The 
validation process results in a collection of 
qualified E-C pairs, also referred to as Distinct 
Qualified Transliteration Pairs (DQTPs).  
As formulated in Section 3, the PSM is trained 
using a training lexicon in a data driven manner. 
It is therefore very important to ensure that in the 
learning process we have prepared a quality 
training lexicon. We establish a baseline system 
using supervised learning. In this approach, we 
use human labeled data to train a model. The 
advantage is that it is able to establish a model 
quickly as long as labeled data are available. 
However, this method also suffers from some 
practical issues. First, the derived model can only 
be as good as the data that it sees. An adaptive 
mechanism is therefore needed for the model to 
acquire new knowledge from the dynamically 
growing Web. Second, a massive annotation of 
database is labor intensive, if not entirely 
impossible.  
To reduce the annotation needed, we discuss 
three adaptive strategies cast in the machine 
learning framework, namely active learning, 
unsupervised learning and active-unsupervised 
learning. The learning strategies can be depicted 
in Figure 1 with their difference being discussed 
next. We also train a baseline system using 
supervised learning approach as a reference point 
for benchmarking purpose. 
4.1 Active Learning 
Active learning is based on the assumption that a 
small number of labeled samples, which are 
DQTPs here, and a large number of unlabeled 
 
 
Figure 1. An adaptive learning framework for 
automatic construction of transliteration lexicon. 
samples are available. This assumption is valid in 
most NLP tasks. In contrast to supervised 
learning, where the entire corpus is labeled 
manually, active learning selects the most useful 
samples for labeling and adds the labeled 
examples to the training set to retrain the model. 
This procedure is repeated until the model 
achieves a certain level of performance. 
Practically, a batch of samples is selected each 
time. This is called batch-based sample selection 
(Lewis and Catlett, 1994), as shown in the search 
and ranking block in Figure 1.  
For an active learning to be effective, we 
propose using three measures to select candidates 
for human labeling. First, we would like to select 
the most uncertain samples that are potentially 
highly informative for the PSM model. The 
informativeness of a sample can be quantified by 
its confidence score s  as in the PSM 
formulation. Ranking the E-C pairs by s  is 
referred to as C-rank. The samples of low C-rank 
are the interesting samples to be labeled. Second, 
we would like to select candidates that are of low 
frequency. Ranking by frequency is called F-
rank. During Web crawling, most of the search 
engines use various strategies to prevent 
spamming and one of fundamental tasks is to 
remove the duplicated Web pages. Therefore, we 
assume that the bilingual snippets are all unique. 
Intuitively, E-C pairs of low frequency indicate 
uncommon events which are of higher interest to 
the model. Third, we would like to select 
samples upon which the PSA-PSM and GSA-
PSM disagree the most. The disagreed upon 
samples represent new knowledge to the PSM. In 
short, we select low C-rank, low F-rank and 
PSM-disagreed samples for labeling because the 
high C-rank, high F-rank and PSM-agreed 
samples are already well known to the model. 
4.2 Unsupervised Learning 
Unsupervised learning skips the human labeling 
step. It minimizes human supervision by 
automatically labeling the data. This can be 
effective if prior knowledge about a task is 
available, for example, if an initial PSM can be 
built based on human crafted phonetic mapping 
rules. This is entirely possible. Kuo et al(2005) 
proposed using a cross-lingual phonetic 
confusion matrix resulting from automatic 
speech recognition to bootstrap an initial PSM 
model. The task of labeling samples is basically 
to distinguish the qualified transliteration pairs 
from the rest. Unlike the sample selection 
method in active learning, here we would like to 
Iterate Start 
Final 
PSM 
Initial 
PSM 
Search &  
Ranking 
 
PSM  
Learning 
Lexicon 
Stop 
The Web 
 
 
Select & 
 Labeling 
Training 
Samples 
Labeled 
Samples 
PSM  
Evaluation & Stop 
Criterion 
1133
select the samples that are of high C-rank and 
high F-rank because they are more likely to be 
the desired transliteration pairs. 
The difference between the active learning and 
the unsupervised learning strategies lies in that 
the former selects samples for human labeling, 
such as in the select & labeling block in Figure 1 
before passing on for PSM learning, while the 
latter selects the samples automatically and 
assumes they are all correct DQTPs. The 
disadvantage of unsupervised learning is that it 
tends to reinforce its existing knowledge rather 
than to discover new events.  
4.3 Active-Unsupervised Learning 
The active learning and the unsupervised 
learning strategies can be complementary. Active 
learning minimizes the labeling effort by 
intelligently short-listing informative and 
representative samples for labeling. It makes sure 
that the PSM learns new and informative 
knowledge over iterations. Unsupervised 
learning effectively exploits the unlabelled data. 
It reinforces the knowledge that PSM has 
acquired and allows PSM to adapt to changes at 
no cost. However, we do not expect 
unsupervised learning to acquire new knowledge 
like active learning does. Intuitively, a better 
solution is to integrate the two strategies into one, 
referred to as the active-unsupervised learning 
strategy. In this strategy, we use active learning 
to select a small amount of informative and 
representative samples for labeling. At the same 
time, we select samples of high confidence score 
from the rest and consider them correct E-C pairs. 
We then merge the labeled set with the high-
confidence set in the PSM re-training.  
5 Experiments 
We first construct a development corpus by 
crawling of webpages. This corpus consists of 
about 500 MB of webpages, called SET1 (Kuo et 
al, 2005). Out of 80,094 qualified sentences, 
8,898 DQTPs are manually extracted from SET1, 
which serve as the gold standard in testing. To 
establish a baseline system, we first train a PSM 
using all 8,898 DQTPs in supervised manner and 
conduct a closed test on SET1 as in Table 1. We 
further implement three PSM learning strategies 
and conduct a systematic series of experiments. 
 
 Precision Recall F-measure 
closed-test 0.79 0.69 0.74 
     Table 1. Supervised learning test on SET1 
5.1 Unsupervised Learning 
We follow the formulation described in 
Section 4.2. First, we derive an initial PSM using 
randomly selected 100 seed DQTPs and simulate 
the Web-based learning process with the SET1: 
(i) select high F-rank and high C-rank E-C pairs 
using PSM, (ii) add the selected E-C pairs to the 
DQTP pool as if they are true DQTPs, and (iii) 
reestimate PSM by using the updated DQTP pool. 
In Figure 2, we report the F-measure over 
iterations. The U_HF curve reflects the learning 
progress of using E-C pairs that occur more than 
once in the SET1 corpus (high F-rank). The 
U_HF_HR curve reflects the learning progress 
using a subset of E-C pairs from U_HF which 
has high posterior odds as defined in Eq.(6). 
Both selection strategies aim to select E-C pairs, 
which are as genuine as possible. 
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
1 2 3 4 5 6
# Iteration
F-
m
ea
su
re Supervised
U_HF
U_HF_HR
 
Figure 2. F-measure over iterations for 
unsupervised learning on SET1. 
 
We found that both U_HF and U_HF_HR give 
similar results in terms of F-measure. Without 
surprise, more iterations don?t always lead to 
better performance because unsupervised 
learning doesn?t aim to acquiring new knowledge 
over iterations. Nevertheless, unsupervised 
learning improves the initial PSM in the first 
iteration substantially. It can serve as an effective 
PSM adaptation method. 
5.2 Active Learning 
The objective of active learning is to minimize 
human supervision by automatically selecting the 
most informative samples to be labeled. The 
effect of active learning is that it maximizes 
performance improvement with minimum 
annotation effort. Like in unsupervised learning, 
we start with the same 100 seed DQTPs and an 
initial PSM model and carry out experiments on 
SET1: (i) select low F-rank, low C-rank and 
GSA-PSM and PSA-PSM disagreed E-C pairs; 
(ii) label the selected pairs by removing the non-
E-C pairs and add the labeled E-C pairs to the 
DQTP pool, and (iii) reestimate the PSM by 
using the updated DQTP pool.  
1134
To select the samples, we employ 3 different 
strategies: A_LF_LR, where we only select low 
F-rank and low C-rank candidates for labeling. 
A_DIFF, where we only select those that GSA-
PSM and PSA-PSM disagreed upon; and 
A_DIFF_LF_LR, the union of A_LF_LR and 
A_DIFF selections. As shown in Figure 3, the F-
measure of A_DIFF (0.729) and 
A_DIFF_LF_LR (0.731) approximate to that of 
supervised learning 0.735) after four iterations.   
 
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
1 2 3 4 5 6
# Iteration
F-
me
as
ur
e Supervised
A_LF_LR
A_DIFF
A_DIFF_LF_LR
 
Figure 3. F-measure over iterations for active 
learning on SET1. 
 
With almost identical performance as 
supervised learning, the active learning approach 
has greatly reduced the number of samples for 
manual labeling as reported in Table 2. It is 
found that for active learning to reach the 
performance of supervised learning, A_DIFF is 
the most effective strategy. It reduces the 
labeling effort by 89.0%, from 80,094 samples to 
8,750. 
 
 Sample selection #samples labeled 
A_LF_LR 1,671 
A_DIFF 8,750 Active learning A_DIFF_LF_LR 9,683 
Supervised learning 80,094 
Table 2. Number of total samples for manual 
labeling in 6 iterations of Figure 3. 
5.3 Active Unsupervised Learning 
It would be interesting to study the performance 
of combining unsupervised learning and active 
learning. The experiment is similar to that of 
active learning except that, in step (iii) of active 
learning, we take the unlabeled high confidence 
candidates (high F-rank and high C-rank as in 
U_HF_HR of Section 5.1) as the true labeled 
samples and add into the DQTP pool. The result 
is shown in Figure 4. Although active 
unsupervised learning was reported having 
promising results (Riccardi and Hakkani-Tur, 
2003) in some NLP tasks, it has not been as 
effective as active learning alone in this 
experiment probably due to the fact the 
unlabeled high confidence candidates are still too 
noisy to be informative. 
 
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
1 2 3 4 5 6
# Iteration
F-
me
as
ur
e Supervised
AU_LF_LR
AU_DIFF
AU_DIFF_LF_LR
 
Figure 4. F-measure over iterations for active 
unsupervised learning on SET1. 
5.4 Learning Transliteration Lexicons 
The ultimate objective of building a PSM is to 
extract a transliteration lexicon from the Web by 
iteratively submitting queries and harvesting new 
transliteration pairs from the return results until 
no more new pairs. For example, by submitting 
?Robert? to search engines, we may get ?Robert-
????, ?Richard-??? and ?Charles-???? 
in return. In this way, new queries can be 
generated iteratively, thus new pairs are 
discovered. We pick the best performing SET1-
derived PSM trained using A_DIFF_LF_LR 
active learning strategy and test it on a new 
database SET2 which is obtained in the same 
way as SET1. 
 
 Before  adaptation 
After  
adaptation 
#distinct E-C pairs 137,711 130,456  
Precision 0.777 0.846  
#expected DQTPs 107,001 110,365  
Table 3. SET1-derived PSM adapted towards 
SET2. 
 
SET2 contains 67,944 Web pages amounting 
to 3.17 GB. We extracted 2,122,026 qualified 
sentences from SET2. Using the PSM, we extract 
137,711 distinct E-C pairs. As the gold standard 
for SET2 is unavailable, we randomly select 
1,000 pairs for manual checking. A precision of 
0.777 is reported. In this way, 107,001 DQTPs 
can be expected. We further carry out one 
iteration of unsupervised learning using 
U_HF_HR to adapt the SET1-derived PSM 
towards SET2. The results before and after 
adaptation are reported in Table 3. Like the 
experiment in Section 5.1, the unsupervised 
learning improves the PSM in terms of precision 
significantly. 
1135
6 Conclusions 
We have proposed a framework for harvesting E-
C transliteration lexicons from the Web using 
bilingual snippets. In this framework, we 
formulate the PSM learning and E-C pair 
evaluation methods. We have studied three 
strategies for PSM learning aiming at reducing 
the human supervision.  
The experiments show that unsupervised 
learning is an effective way for rapid PSM 
adaptation while active learning is the most 
effective in achieving high performance. We find 
that the Web is a resourceful live corpus for real 
life E-C transliteration lexicon learning, 
especially for casual transliterations. In this 
paper, we use two Web databases SET1 and 
SET2 for simplicity. The proposed framework 
can be easily extended to an incremental learning 
framework for live databases. This paper has 
focused solely on use of phonetic clues for 
lexicon and PSM learning. We have good reason 
to expect the combining semantic and phonetic 
clues to improve the performance further.  
References 
E. Brill, G. Kacmarcik, C. Brockett. 2001. 
Automatically Harvesting Katakana-English Term 
Pairs from Search Engine Query Logs, In Proc. of 
NLPPRS, pp. 393-399. 
S. Brin and L. Page. 1998. The Anatomy of a Large-
scale Hypertextual Web Search Engine, In Proc. of 
7th WWW, pp. 107-117. 
A. P. Dempster, N. M. Laird and D. B. Rubin. 1977. 
Maximum Likelihood from Incomplete Data via 
the EM Algorithm, Journal of the Royal Statistical 
Society, Ser. B. Vol. 39, pp. 1-38. 
P. Fung and L.-Y. Yee. 1998. An IR Approach for 
Translating New Words from Nonparallel, 
Comparable Texts. In Proc. of 17th COLING and 
36th ACL, pp. 414-420. 
F. Huang, Y. Zhang and Stephan Vogel. 2005. Mining 
Key Phrase Translations from Web Corpora. In 
Proc. of HLT-EMNLP, pp. 483-490. 
D. Jurafsky and J. H. Martin. 2000. Speech and 
Language Processing, pp. 102-120, Prentice-Hall, 
New Jersey. 
K. Knight and J. Graehl. 1998. Machine 
Transliteration, Computational Linguistics, Vol. 24, 
No. 4, pp. 599-612. 
J.-S. Kuo and Y.-K. Yang. 2004. Constructing 
Transliterations Lexicons from Web Corpora, In 
the Companion Volume, 42nd ACL, pp. 102-105. 
J.-S. Kuo and Y.-K. Yang. 2005. Incorporating 
Pronunciation Variation into Extraction of 
Transliterated-term Pairs from Web Corpora, In 
Proc. of ICCC, pp. 131-138. 
C.-J. Lee and J.-S. Chang. 2003. Acquisition of 
English-Chinese Transliterated Word Pairs from 
Parallel-Aligned Texts Using a Statistical Machine 
Transliteration Model, In Proc. of HLT-NAACL 
Workshop Data Driven MT and Beyond, pp. 96-
103. 
D. D. Lewis and J. Catlett. 1994. Heterogeneous 
Uncertainty Sampling for Supervised Learning, In 
Proc. of ICML 1994, pp. 148-156. 
H. Li, M. Zhang and J. Su. 2004. A Joint Source 
Channel Model for Machine Transliteration, In 
Proc. of 42nd ACL, pp. 159-166. 
W. Lam, R.-Z. Huang and P.-S. Cheung. 2004. 
Learning Phonetic Similarity for Matching Named 
Entity Translations and Mining New Translations, 
In Proc. of 27th ACM SIGIR, pp. 289-296. 
W.-H. Lu, L.-F. Chien and H.-J Lee. 2002. 
Translation of Web Queries Using Anchor Text 
Mining, TALIP, Vol. 1, Issue 2, pp. 159- 172. 
H. M. Meng, W.-K. Lo, B. Chen and T. Tang. 2001. 
Generate Phonetic Cognates to Handle Name 
Entities in English-Chinese Cross-Language 
Spoken Document Retrieval, In Proc. of ASRU, pp. 
311-314. 
J.-Y. Nie, P. Isabelle, M. Simard, and R. Durand. 
1999. Cross-language Information Retrieval based 
on Parallel Texts and Automatic Mining of Parallel 
Text from the Web?, In Proc. of 22nd ACM SIGIR, 
pp 74-81. 
V. Pagel, K. Lenzo and A. Black. 1998. Letter to 
Sound Rules for Accented Lexicon Compression, 
In Proc. of ICSLP, pp. 2015-2020. 
R. Rapp. 1999. Automatic Identification of Word 
Translations from Unrelated English and German 
Corpora, In Proc. of 37th ACL, pp. 519-526. 
G. Riccardi and D. Hakkani-T?r. 2003. Active and 
Unsupervised Learning for Automatic Speech 
Recognition. In Proc. of 8th Eurospeech. 
P. Virga and S. Khudanpur. 2003. Transliteration of 
Proper Names in Cross-Lingual Information 
Retrieval, In Proc.  of 41st ACL Workshop on 
Multilingual and Mixed Language Named Entity 
Recognition, pp. 57-64. 
S. Wan and C. M. Verspoor. 1998. Automatic 
English-Chinese Name Transliteration for 
Development of Multilingual Resources, In Proc. of 
17th COLING and 36th ACL, pp.1352-1356. 
1136
Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 120?127,
Prague, Czech Republic, June 2007. c?2007 Association for Computational Linguistics
 
 
 
 
 
 
Abstract 
Words of foreign origin are referred to as 
borrowed words or loanwords. A loanword 
is usually imported to Chinese by phonetic 
transliteration if a translation is not easily 
available. Semantic transliteration is seen 
as a good tradition in introducing foreign 
words to Chinese. Not only does it preserve 
how a word sounds in the source language, 
it also carries forward the word?s original 
semantic attributes. This paper attempts to 
automate the semantic transliteration 
process for the first time. We conduct an 
inquiry into the feasibility of semantic 
transliteration and propose a probabilistic 
model for transliterating personal names in 
Latin script into Chinese. The results show 
that semantic transliteration substantially 
and consistently improves accuracy over 
phonetic transliteration in all the 
experiments. 
1 Introduction 
The study of Chinese transliteration dates back to 
the seventh century when Buddhist scriptures were 
translated into Chinese. The earliest bit of Chinese 
translation theory related to transliteration may be 
the principle of ?Names should follow their 
bearers, while things should follow Chinese.? In 
other words, names should be transliterated, while 
things should be translated according to their 
meanings. The same theory still holds today.  
Transliteration has been practiced in several 
ways, including phonetic transliteration and 
phonetic-semantic transliteration. By phonetic 
transliteration, we mean rewriting a foreign word 
in native grapheme such that its original 
pronunciation is preserved. For example, London 
becomes ??  /Lun-Dun/1 which does not carry 
any clear connotations. Phonetic transliteration 
represents the common practice in transliteration. 
Phonetic-semantic transliteration, hereafter 
referred to as semantic transliteration for short, is 
an advanced translation technique that is 
considered as a recommended translation practice 
for centuries. It translates a foreign word by 
preserving both its original pronunciation and 
meaning. For example, Xu Guangqi 2  translated 
geo- in geometry into Chinese as ??  /Ji-He/, 
which carries the pronunciation of geo- and 
expresses the meaning of ?a science concerned 
with measuring the earth?.  
Many of the loanwords exist in today?s Chinese 
through semantic transliteration, which has been 
well received (Hu and Xu, 2003; Hu, 2004) by the 
people because of many advantages. Here we just 
name a few. (1) It brings in not only the sound, but 
also the meaning that fills in the semantic blank 
left by phonetic transliteration. This also reminds 
people that it is a loanword and avoids misleading; 
(2) It provides etymological clues that make it easy 
to trace back to the root of the words. For example, 
a transliterated Japanese name will maintain its 
Japanese identity in its Chinese appearance; (3) It 
evokes desirable associations, for example, an 
English girl?s name is transliterated with Chinese 
characters that have clear feminine association, 
thus maintaining the gender identity. 
                                                 
1 Hereafter, Chinese characters are also denoted in Pinyin ro-
manization system, for ease of reference.  
2 Xu Quangqi (1562?1633) translated The Original Manu-
script of Geometry to Chinese jointly with Matteo Ricci. 
Semantic Transliteration of Personal Names 
Haizhou Li*,  Khe Chai Sim*,  Jin-Shea Kuo?,  Minghui Dong* 
*Institute for Infocomm Research 
Singapore 119613 
{hli,kcsim,mhdong}@i2r.a-star.edu.sg 
?Chung-Hwa Telecom Laboratories 
Taiwan 
jskuo@cht.com.tw 
120
Unfortunately, most of the reported work in the 
area of machine transliteration has not ventured 
into semantic transliteration yet. The Latin-scripted 
personal names are always assumed to 
homogeneously follow the English phonic rules in 
automatic transliteration (Li et al, 2004). 
Therefore, the same transliteration model is 
applied to all the names indiscriminatively. This 
assumption degrades the performance of 
transliteration because each language has its own 
phonic rule and the Chinese characters to be 
adopted depend on the following semantic 
attributes of a foreign name. 
(1) Language of origin: An English word is not 
necessarily of pure English origin. In English news 
reports about Asian happenings, an English 
personal name may have been originated from 
Chinese, Japanese or Korean. The language origin 
affects the phonic rules and the characters to be 
used in transliteration3. For example, a Japanese 
name Matsumoto should be transliterated as ?? 
/Song-Ben/, instead of ???? /Ma-Ci-Mo-Tuo/ 
as if it were an English name. 
(2) Gender association: A given name typically 
implies a clear gender association in both the 
source and target languages. For example, the 
Chinese transliterations of Alice and Alexandra 
are ??? /Ai-Li-Si/ and ???? /Ya-Li-Shan-
Da/ respectively, showing clear feminine and 
masculine characteristics. Transliterating Alice as 
???  /Ai-Li-Si/ is phonetically correct, but 
semantically inadequate due to an improper gender 
association. 
(3) Surname and given name: The Chinese name 
system is the original pattern of names in Eastern 
Asia such as China, Korea and Vietnam, in which 
a limited number of characters 4  are used for 
surnames while those for given names are less 
restrictive. Even for English names, the character 
set for given name transliterations are different 
from that for surnames. 
Here are two examples of semantic 
transliteration for personal names.  George Bush 
                                                 
3 In the literature (Knight  and  Graehl,1998; Qu et al, 2003), 
translating romanized Japanese or Chinese names to Chinese 
characters is also known as back-transliteration. For simplic-
ity, we consider all conversions from Latin-scripted words to 
Chinese as transliteration in this paper. 
4 The 19 most common surnames cover 55.6% percent of the 
Chinese population (Ning and Ning 1995). 
and Yamamoto Akiko are transliterated into ??  
?? and ??  ???  that arouse to the 
following associations: ??  /Qiao-Zhi/ - male 
given name, English origin; ??  /Bu-Shi/ - 
surname, English origin; ? ?  /Shan-Ben/ - 
surname, Japanese origin; ??? /Ya-Xi-Zi/ - 
female given name, Japanese origin. 
 In Section 2, we summarize the related work. In 
Section 3, we discuss the linguistic feasibility of 
semantic transliteration for personal names. 
Section 4 formulates a probabilistic model for 
semantic transliteration.  Section 5 reports the 
experiments. Finally, we conclude in Section 6. 
2 Related Work 
In general, computational studies of transliteration 
fall into two categories: transliteration modeling 
and extraction of transliteration pairs. In 
transliteration modeling, transliteration rules are 
trained from a large, bilingual transliteration 
lexicon (Lin and Chen, 2002; Oh and Choi, 2005), 
with the objective of translating unknown words 
on the fly in an open, general domain. In the 
extraction of transliterations, data-driven methods 
are adopted to extract actual transliteration pairs 
from a corpus, in an effort to construct a large, up-
to-date transliteration lexicon (Kuo et al, 2006; 
Sproat et al, 2006).  
Phonetic transliteration can be considered as an 
extension to the traditional grapheme-to-phoneme 
(G2P) conversion (Galescu and Allen, 2001), 
which has been a much-researched topic in the 
field of speech processing. If we view the 
grapheme and phoneme as two symbolic 
representations of the same word in two different 
languages, then G2P is a transliteration task by 
itself. Although G2P and phonetic transliteration 
are common in many ways, transliteration has its 
unique challenges, especially as far as E-C 
transliteration is concerned. E-C transliteration is 
the conversion between English graphemes, 
phonetically associated English letters, and 
Chinese graphemes, characters which represent 
ideas or meanings. As a Chinese transliteration can 
arouse to certain connotations, the choice of 
Chinese characters becomes a topic of interest (Xu 
et al, 2006). 
Semantic transliteration can be seen as a subtask 
of statistical machine translation (SMT) with 
121
monotonic word ordering. By treating a 
letter/character as a word and a group of 
letters/characters as a phrase or token unit in SMT, 
one can easily apply the traditional SMT models, 
such as the IBM generative model (Brown et al, 
1993) or the phrase-based translation model (Crego 
et al, 2005) to transliteration. In transliteration, we 
face similar issues as in SMT, such as lexical 
mapping and alignment. However, transliteration is 
also different from general SMT in many ways. 
Unlike SMT where we aim at optimizing the 
semantic transfer, semantic transliteration needs to 
maintain the phonetic equivalence as well. 
In computational linguistic literature, much 
effort has been devoted to phonetic transliteration, 
such as English-Arabic, English-Chinese (Li et al, 
2004), English-Japanese (Knight and Graehl, 
1998) and English-Korean. In G2P studies, Font 
Llitjos and Black (2001) showed how knowledge 
of language of origin may improve conversion 
accuracy. Unfortunately semantic transliteration, 
which is considered as a good tradition in 
translation practice (Hu and Xu, 2003; Hu, 2004), 
has not been adequately addressed computationally 
in the literature. Some recent work (Li et al, 2006; 
Xu et al, 2006) has attempted to introduce 
preference into a probabilistic framework for 
selection of Chinese characters in phonetic 
transliteration. However, there is neither analytical 
result nor semantic-motivated transliteration 
solution being reported. 
3 Feasibility of Semantic Transliteration 
A Latin-scripted personal name is written in letters, 
which represent the pronunciations closely, 
whereas each Chinese character represents not only 
the syllables, but also the semantic associations. 
Thus, character rendering is a vital issue in trans-
literation. Good transliteration adequately projects 
semantic association while an inappropriate one 
may lead to undesirable interpretation. 
Is semantic transliteration possible? Let?s first 
conduct an inquiry into the feasibility of semantic 
transliteration on 3 bilingual name corpora, which 
are summarizied in Table 1 and will be used in 
experiments. E-C corpus is an augmented version 
of Xinhua English to Chinese dictionary  for 
English names (Xinhua, 1992). J-C corpus is a 
romanized Japanese to Chinese dictionary for 
Japanese names. The C-C corpus is a Chinese 
Pinyin to character dictionary for Chinese names. 
The entries are classified into surname, male and 
female given name categories. The E-C corpus also 
contains some entries without gender/surname 
labels, referred to as unclassified. 
 
 E-C J-C5 C-C6 
Surname (S) 12,490 36,352 569,403 
Given name (M) 3,201 35,767 345,044 
Given name (F) 4,275 11,817 122,772 
Unclassified 22,562 - - 
All 42,528 83,936 1,972,851 
Table 1: Number of entries in 3 corpora 
 
Phonetic transliteration has not been a problem 
as Chinese has over 400 unique syllables that are 
enough to approximately transcribe all syllables in 
other languages. Different Chinese characters may 
render into the same syllable and form a range of 
homonyms. Among the homonyms, those arousing 
positive meanings can be used for personal names. 
As discussed elsewhere (Sproat et al, 1996), out of 
several thousand common Chinese characters, a 
subset of a few hundred characters tends to be used 
overwhelmingly for transliterating English names 
to Chinese, e.g. only 731 Chinese characters are 
adopted in the E-C corpus. Although the character 
sets are shared across languages and genders, the 
statistics in Table 2 show that each semantic 
attribute is associated with some unique characters. 
In the C-C corpus, out of the total of 4,507 
characters, only 776 of them are for surnames. It is 
interesting to find that female given names are 
represented by a smaller set of characters than that 
for male across 3 corpora.     
 
 E-C J-C C-C All 
S 327 2,129 776 2,612 (19.2%)
M 504 1,399 4,340 4,995 (20.0%)
F 479 1,178 1,318 2,192 (26.3%)
All 731 (44.2%)
2,533 
(46.2%)
4,507 
(30.0%) 5,779 (53.6%)
Table 2: Chinese character usage in 3 corpora. The 
numbers in brackets indicate the percentage of 
characters that are shared by at least 2 corpora. 
 
Note that the overlap of Chinese characters 
usage across genders is higher than that across 
languages. For instance, there is a 44.2% overlap 
                                                 
5 http://www.cjk.org 
6 http://technology.chtsai.org/namelist 
122
across gender for the transcribed English names; 
but only 19.2% overlap across languages for the 
surnames. 
In summary, the semantic attributes of personal 
names are characterized by the choice of characters, 
and therefore their n-gram statistics as well. If the 
attributes are known in advance, then the semantic 
transliteration is absolutely feasible. We may 
obtain the semantic attributes from the context 
through trigger words. For instance, from ?Mr 
Tony Blair?, we realize ?Tony? is a male given 
name while ?Blair? is a surname; from  ?Japanese 
Prime Minister Koizumi?, we resolve that 
?Koizumi? is a Japanese surname. In the case 
where contextual trigger words are not available, 
we study detecting the semantic attributes from the 
personal names themselves in the next section. 
4 Formulation of Transliteration Model  
Let S and T denote the name written in the source 
and target writing systems respectively. Within a 
probabilistic framework, a transliteration system 
produces the optimum target name, T*, which 
yields the highest posterior probability given the 
source name, S, i.e. 
)|(maxarg* STPT
T ST?
=  (1) 
where ST  is the set of all possible transliterations 
for the source name, S. The alignment between S 
and T is assumed implicit in the above formulation.  
In a standard phonetic transliteration system, 
)|( STP , the posterior probability of the hypothe-
sized transliteration, T, given the source name, S, is 
directly modeled without considering any form of 
semantic information. On the other hand, semantic 
transliteration described in this paper incorporates 
language of origin and gender information to cap-
ture the semantic structure. To do so, )|( STP  is 
rewritten as 
( | )P T S  = ??? GL GL SGLTP, )|,,(  (2) 
 = ??? GL GL SGLPGLSTP, )|,(),,|(  (3) 
where ( | , , )P T S L G  is the transliteration probabil-
ity from source S to target T, given the language of 
origin (L) and gender (G) labels. L  and G denote 
the sets of languages and genders respectively. 
)|,( SGLP  is the probability of the language and 
the gender given the source, S. 
Given the alignment between S and T, the 
transliteration probability given L and G may be 
written as  
),,|( GLSTP = 11 1
1
( | , )
I
i i
i
i
P t T S?
=
?  (4)
 ? 1 1
1
( | , , )
I
i i i i
i
P t t s s? ?
=
?  (5)
where is  and it are the i
th token of S and T respec-
tively and I is the total number of tokens in both S 
and T. kjS  and kjT  represent the sequence of tokens 
( )1, , ,j j ks s s+ K  and ( )1, , ,j j kt t t+ K  respectively. Eq. 
(4) is in fact the n-gram likelihood of the token pair 
,i it s? ?  sequence and Eq. (5) approximates this 
probability using a bigram language model. This 
model is conceptually similar to the joint source-
channel model (Li et al, 2004) where the target to-
ken it  depends on not only its source token is but 
also the history 1it ? and 1is ? . Each character in the 
target name forms a token. To obtain the source 
tokens, the source and target names in the training 
data are aligned using the EM algorithm. This 
yields a set of possible source tokens and a map-
ping between the source and target tokens. During 
testing, each source name is first segmented into 
all possible token sequences given the token set. 
These source token sequences are mapped to the 
target sequences to yield an N-best list of translit-
eration candidates. Each candidate is scored using 
an n-gram language model given by Eqs. (4) or (5). 
As in Eq. (3), the transliteration also greatly 
depends on the prior knowledge, )|,( SGLP . 
When no prior knowledge is available, a uniform 
probability distribution is assumed. By expressing 
)|,( SGLP  in the following form, 
)|(),|()|,( SLPSLGPSGLP =  (6) 
prior knowledge about language and gender may 
be incorporated. For example, if the language of S 
is known as sL , we have 
1
( | )
0
s
s
L L
P L S
L L
=?= ? ??
 (7) 
Similarly, if the gender information for S is known 
as sG , then, 
123
1
( | , )
0
s
s
G G
P G L S
G G
=?= ? ??
 (8) 
Note that personal names have clear semantic 
associations. In the case where the semantic 
attribute information is not available, we propose 
learning semantic information from the names 
themselves. Using Bayes? theorem, we have 
)(
),(),|()|,(
SP
GLPGLSPSGLP =  (9) 
( | , )P S L G  can be modeled using an n-gram lan-
guage model for the letter sequence of all the 
Latin-scripted names in the training set. The prior 
probability, ),( GLP , is typically uniform. )(SP  
does not depend on L and G, thus can be omitted. 
Incorporating )|,( SGLP into Eq. (3) can be 
viewed as performing a soft decision of the 
language and gender semantic attributes. By 
contrast, hard decision may also be performed 
based on maximum likelihood approach: 
arg max ( | )s
L
L P S L
?
=
L
 (10) 
arg max ( | , )s
G
G P S L G
?
=
G
 (11) 
where sL  and sG are the detected language and 
gender of S respectively. Therefore, for hard deci-
sion, )|,( SGLP  is obtained by replacing sL  and 
sG  in Eq. (7) and (8) with sL  and sG respec-
tively. Although hard decision eliminates the need 
to compute the likelihood scores for all possible 
pairs of L and G, the decision errors made in the 
early stage will propagate to the transliteration 
stage. This is potentially bad if a poor detector is 
used (see Table 9 in Section 5.3). 
If we are unable to model the prior knowledge 
of semantic attributes )|,( SGLP , then a more 
general model will be used for ( | , , )P T S L G  by 
dropping the dependency on the information that is 
not available. For example, Eq. (3) is reduced 
to ( | , ) ( | )
L
P T S L P L S?? L  if the gender information 
is missing. Note that when both language and 
gender are unknown, the system simplifies to the 
baseline phonetic transliteration system. 
5 Experiments 
This section presents experiments on database of 3 
language origins (Japanese, Chinese and English) 
and gender information (surname7, male and fe-
male). In the experiments of determining the lan-
guage origin, we used the full data set for the 3 lan-
guages as in shown in Table 1. The training and test 
data for semantic transliteration are the subset of 
Table 1 comprising those with surnames, male and 
female given names labels. In this paper, J, C and 
E stand for Japanese, Chinese and English; S, M 
and F represent Surname, Male and Female given 
names, respectively.  
 
# unique entries L Data set S M F All 
Train 21.7k 5.6k 1.7k 27.1k J 
Test 2.6k 518 276 2.9k 
Train 283 29.6k 9.2k 31.5k C 
Test 283 2.9k 1.2k 3.1k 
Train 12.5k 2.8k 3.8k 18.5k E 
Test 1.4k 367 429 2.1k 
Table 3: Number of unique entries in training and 
test sets, categorized by semantic attributes 
 
Table 3 summarizes the number of unique8 name 
entries used in training and testing. The test sets 
were randomly chosen such that the amount of test 
data is approximately 10-20% of the whole corpus. 
There were no overlapping entries between the 
training and test data. Note that the Chinese sur-
names are typically single characters in a small set; 
we assume there is no unseen surname in the test 
set. All the Chinese surname entries are used for 
both training and testing. 
5.1 Language of Origin 
For each language of origin, a 4-gram language 
model was trained for the letter sequence of the 
source names, with a 1-letter shift. 
 
Japanese Chinese English All 
96.46 96.44 89.90 94.81 
Table 4: Language detection accuracies (%) using 
a 4-gram language model for the letter sequence of 
the source name in Latin script. 
                                                 
7 In this paper, surnames are treated as a special class of gen-
der. Unlike given names, they do not have any gender associa-
tion. Therefore, they fall into a third category which is neither 
male nor female.  
8 By contrast, Table 1 shows the total number of name exam-
ples available. For each unique entry, there may be multiple 
examples. 
124
 
Table 4 shows the language detection accuracies 
for all the 3 languages using Eq. (10). The overall 
detection accuracy is 94.81%. The corresponding 
Equal Error Rate (EER)9 is 4.52%. The detection 
results may be used directly to infer the semantic 
information for transliteration. Alternatively, the 
language model likelihood scores may be 
incorporated into the Bayesian framework to 
improve the transliteration performance, as 
described in Section 4. 
5.2 Gender Association 
Similarly, gender detection 10  was performed by 
training a 4-gram language model for the letter se-
quence of the source names for each language and 
gender pair.  
 
Language Male Female All 
Japanese 90.54 80.43 87.03 
Chinese 64.34 71.66 66.52 
English 75.20 72.26 73.62 
Table 5: Gender detection accuracies (%) using a 
4-gram language model for the letter sequence of 
the source name in Latin script. 
 
Table 5 summarizes the gender detection accura-
cies using Eq. (11) assuming language of origin is 
known, arg max ( | , )s s
G
G P S L L G
?
= =
G
. The overall 
detection accuracies are 87.03%, 66.52% and 
73.62% for Japanese, Chinese and English respec-
tively. The corresponding EER are 13.1%, 21.8% 
and 19.3% respectively. Note that gender detection 
is generally harder than language detection. This is 
because the tokens (syllables) are shared very 
much across gender categories, while they are 
quite different from one language to another.  
5.3 Semantic Transliteration 
The performance was measured using the Mean 
Reciprocal Rank (MRR) metric (Kantor and Voor-
hees, 2000), a measure that is commonly used in 
information retrieval, assuming there is precisely 
one correct answer. Each transliteration system 
generated at most 50-best hypotheses for each 
                                                 
9 EER is defined as the error of false acceptance and false re-
jection when they are equal. 
10 In most writing systems, the ordering of surname and 
given name is known. Therefore, gender detection is 
only performed for male and female classes. 
word when computing MRR. The word and char-
acter accuracies of the top best hypotheses are also 
reported.  
We used the phonetic transliteration system as 
the baseline to study the effects of semantic 
transliteration. The phonetic transliteration system 
was trained by pooling all the available training 
data from all the languages and genders to estimate 
a language model for the source-target token pairs. 
Table 6 compares the MRR performance of the 
baseline system using unigram and bigram 
language models for the source-target token pairs. 
 
 J C E All 
Unigram 0.5109 0.4869 0.2598 0.4443 
Bigram 0.5412 0.5261 0.3395 0.4895 
Table 6:  MRR performance of phonetic translit-
eration for 3 corpora using unigram and bigram 
language models. 
 
The MRR performance for Japanese and Chinese 
is in the range of 0.48-0.55. However, due to the 
small amount of training and test data, the MRR 
performance of the English name transliteration is 
slightly poor (approximately 0.26-0.34). In general, 
a bigram language model gave an overall relative 
improvement of 10.2% over a unigram model.  
 
L G Set J C E 
S 0.5366 0.7426 0.4009 
M 0.5992 0.5184 0.2875 
F 0.4750 0.4945 0.1779 2 2 
All 0.5412 0.5261 0.3395 
S 0.6500 0.7971 0.7178 
M 0.6733 0.5245 0.4978 
F 0.5956 0.5191 0.4115 2 
All 0.6491 0.5404 0.6228 
S 0.6822 0.9969 0.7382 
M 0.7267 0.6466 0.4319 
F 0.5856 0.7844 0.4340 
3 
3 
All 0.6811 0.7075 0.6294 
S 0.6541 0.6733 0.7129 
M 0.6974 0.5362 0.4821 
F 0.5743 0.6574 0.4138 
c c 
All 0.6477 0.5764 0.6168 
Table 7: The effect of language and gender in-
formation on the overall MRR performance of 
transliteration (L=Language, G=Gender, 
2=unknown, 3=known, c=soft decision). 
 
Next, the scenarios with perfect language and/or 
gender information were considered. This com-
125
parison is summarized in Table 7. All the MRR re-
sults are based on transliteration systems using bi-
gram language models. The table clearly shows 
that having perfect knowledge, denoted by ?3?, of 
language and gender helps improve the MRR per-
formance; detecting semantic attributes using soft 
decision, denoted by ?c?, has a clear win over the 
baseline, denoted by ?2?, where semantic informa-
tion is not used. The results strongly recommend 
the use of semantic transliteration for personal 
names in practice. 
Next let?s look into the effects of automatic 
language and gender detection on the performance. 
 
 J C E All 
2 0.5412 0.5261 0.3395 0.4895 
? 0.6292 0.5290 0.5780 0.5734 
c 0.6162 0.5301 0.6088 0.5765 
3 0.6491 0.5404 0.6228 0.5952 
Table 8: The effect of language detection 
schemes on MRR using bigram language models 
and unknown gender information (hereafter, 
2=unknown, 3=known, ?=hard decision, c=soft 
decision). 
 
Table 8 compares the MRR performance of the 
semantic transliteration systems with different 
prior information, using bigram language models. 
Soft decision refers to the incorporation of the lan-
guage model scores into the transliteration process 
to improve the prior knowledge in Bayesian infer-
ence. Overall, both hard and soft decision methods 
gave similar MRR performance of approximately 
0.5750, which was about 17.5% relatively im-
provement compared to the phonetic transliteration 
system with 0.4895 MRR. The hard decision 
scheme owes its surprisingly good performance to 
the high detection accuracies (see Table 4). 
 
 S M F All 
2 0.6825 0.5422 0.5062 0.5952 
? 0.7216 0.4674 0.5162 0.5855 
c 0.7216 0.5473 0.5878 0.6267 
3 0.7216 0.6368 0.6786 0.6812 
Table 9: The effect of gender detection schemes 
on MRR using bigram language  
models with perfect language information. 
 
Similarly, the effect of various gender detection 
methods used to obtain the prior information is 
shown in Table 9. The language information was 
assumed known a-priori. Due to the poorer 
detection accuracy for the Chinese male given 
names (see Table 5), hard decision of gender had 
led to deterioration in MRR performance of the 
male names compared to the case where no prior 
information was assumed. Soft decision of gender 
yielded further gains of 17.1% and 13.9% relative 
improvements for male and female given names 
respectively, over the hard decision method. 
 
Overall Accuracy (%) L G MRR Word Character 
2 2 0.4895 36.87 58.39 
2 0.5952 46.92 65.18 3 3 0.6812 58.16 70.76 
? ? 0.5824 47.09 66.84 
c c 0.6122 49.38 69.21 
Table 10: Overall transliteration performance 
using bigram language model with various lan-
guage and gender information. 
 
Finally, Table 10 compares the performance of 
various semantic transliteration systems using bi-
gram language models. The baseline phonetic 
transliteration system yielded 36.87% and 58.39% 
accuracies at word and character levels respec-
tively; and 0.4895 MRR. It can be conjectured 
from the results that semantic transliteration is sub-
stantially superior to phonetic transliteration. In 
particular, knowing the language information im-
proved the overall MRR performance to 0.5952; 
and with additional gender information, the best 
performance of 0.6812 was obtained. Furthermore, 
both hard and soft decision of semantic informa-
tion improved the performance, with the latter be-
ing substantially better. Both the word and charac-
ter accuracies improvements were consistent and 
have similar trend to that observed for MRR.  
The performance of the semantic transliteration 
using soft decisions (last row of Table 10) 
achieved 25.1%, 33.9%, 18.5% relative improve-
ment in MRR, word and character accuracies 
respectively over that of the phonetic 
transliteration (first row of Table 10). In addition, 
soft decision also presented 5.1%, 4.9% and 3.5% 
relative improvement over hard decision in MRR, 
word and character accuracies respectively. 
5.4 Discussions 
It was found that the performance of the baseline 
phonetic transliteration may be greatly improved 
by incorporating semantic information such as the 
language of origin and gender. Furthermore, it was 
found that the soft decision of language and gender 
126
outperforms the hard decision approach. The soft 
decision method incorporates the semantic scores 
( , | )P L G S with transliteration scores ( | , , )P T S L G , 
involving all possible semantic specific models in 
the decoding process.  
In this paper, there are 9 such models (3 
languages? 3 genders). The hard decision relies on 
Eqs. (10) and (11) to decide language and gender, 
which only involves one semantic specific model 
in the decoding. Neither soft nor hard decision 
requires any prior information about the names. It 
provides substantial performance improvement 
over phonetic transliteration at a reasonable 
computational cost. If the prior semantic 
information is known, e.g. via trigger words, then 
semantic transliteration attains its best performance. 
6 Conclusion 
Transliteration is a difficult, artistic human en-
deavor, as rich as any other creative pursuit. Re-
search on automatic transliteration has reported 
promising results for regular transliteration, where 
transliterations follow certain rules. The generative 
model works well as it is designed to capture regu-
larities in terms of rules or patterns. This paper ex-
tends the research by showing that semantic trans-
literation of personal names is feasible and pro-
vides substantial performance gains over phonetic 
transliteration.  This paper has presented a success-
ful attempt towards semantic transliteration using 
personal name transliteration as a case study. It 
formulates a mathematical framework that incor-
porates explicit semantic information (prior 
knowledge), or implicit one (through soft or hard 
decision) into the transliteration model. Extending 
the framework to machine transliteration of named 
entities in general is a topic for further research. 
References 
Peter F. Brown and Stephen Della Pietra and Vincent J. 
Della Pietra and Robert L. Mercer. 1993, The Mathe-
matics of Statistical Machine Translation: Parameter 
Estimation, Computational Linguistics, 19(2), pp. 
263-311. 
J. M. Crego, M. R. Costa-jussa and J. B. Mario and J. A. 
R. Fonollosa. 2005, N-gram-based versus Phrase-
based Statistical Machine Translation, In Proc. of 
IWSLT, pp. 177-184. 
Ariadna Font Llitjos, Alan W. Black. 2001. Knowledge 
of language origin improves pronunciation accuracy 
of proper names. In Proc. of Eurospeech, Denmark, 
pp 1919-1922. 
Lucian Galescu and James F. Allen. 2001, Bi-
directional Conversion between Graphemes and Pho-
nemes using a Joint N-gram Model, In Proc. 4th ISCA 
Tutorial and Research Workshop on Speech Synthesis, 
Scotland, pp. 103-108. 
Peter Hu, 2004, Adapting English to Chinese, English 
Today, 20(2), pp. 34-39. 
Qingping Hu and Jun Xu, 2003, Semantic Translitera-
tion: A Good Tradition in Translating Foreign Words 
into Chinese Babel: International Journal of Transla-
tion, Babel, 49(4), pp. 310-326. 
Paul B. Kantor and Ellen M. Voorhees, 2000, The 
TREC-5 Confusion Track: Comparing Retrieval 
Methods for Scanned Text. Informational Retrieval, 2, 
pp. 165-176. 
K. Knight and J. Graehl. 1998. Machine Transliteration, 
Computational Linguistics 24(4), pp. 599-612. 
J.-S. Kuo, H. Li and Y.-K. Yang. 2006. Learning Trans-
literation Lexicons from the Web, In Proc. of 44th 
ACL, pp. 1129-1136. 
Haizhou Li, Min Zhang and Jian Su. 2004. A Joint 
Source Channel Model for Machine Transliteration, In 
Proc. of 42nd ACL, pp. 159-166. 
Haizhou Li, Shuanhu Bai, and Jin-Shea Kuo, 2006, 
Transliteration, In Advances in Chinese Spoken Lan-
guage Processing, C.-H. Lee, et al (eds), World Sci-
entific, pp. 341-364. 
Wei-Hao Lin and Hsin-Hsi Chen, 2002, Backward ma-
chine transliteration by learning phonetic similarity, In 
Proc. of CoNLL , pp.139-145. 
Yegao Ning and Yun Ning, 1995, Chinese Personal 
Names, Federal Publications, Singapore. 
Jong-Hoon Oh and Key-Sun Choi. 2005, An Ensemble 
of Grapheme and Phoneme for Machine Translitera-
tion, In Proc. of IJCNLP, pp.450-461. 
Y. Qu, G. Grefenstette and D. A. Evans, 2003, Auto-
matic Transliteration for Japanese-to-English Text Re-
trieval. In Proc. of 26th ACM SIGIR, pp. 353-360. 
Richard Sproat, C. Chih, W. Gale, and N. Chang. 1996. 
A stochastic Finite-state Word-segmentation Algo-
rithm for Chinese, Computational Linguistics, 22(3), 
pp. 377-404. 
Richard Sproat, Tao Tao and ChengXiang Zhai. 2006. 
Named Entity Transliteration with Comparable Cor-
pora, In Proc. of 44th ACL, pp. 73-80. 
Xinhua News Agency, 1992, Chinese Transliteration of 
Foreign Personal Names, The Commercial Press. 
L. Xu, A. Fujii, T. Ishikawa, 2006 Modeling Impression 
in Probabilistic Transliteration into Chinese, In Proc. 
of EMNLP 2006, Sydney,  pp. 242?249. 
127
 Constructing Transliteration Lexicons from Web Corpora  
 
Jin-Shea Kuo1, 2 Ying-Kuei Yang2 
1Chung-Hwa Telecommunication 
Laboratories, Taiwan, R. O. C., 326 
2E. E. Dept., National Taiwan University of Science 
and Technology, Taiwan, R.O.C., 106 
jskuo@cht.com.tw ykyang@mouse.ee.ntust.edu.tw 
 
Abstract 
This paper proposes a novel approach to automating 
the construction of transliterated-term lexicons. A 
simple syllable alignment algorithm is used to 
construct confusion matrices for cross-language 
syllable-phoneme conversion. Each row in the 
confusion matrix consists of a set of syllables in the 
source language that are (correctly or erroneously) 
matched phonetically and statistically to a syllable in 
the target language. Two conversions using 
phoneme-to-phoneme and text-to-phoneme 
syllabification algorithms are automatically deduced 
from a training corpus of paired terms and are used 
to calculate the degree of similarity between 
phonemes for transliterated-term extraction. In a 
large-scale experiment using this automated learning 
process for conversions, more than 200,000 
transliterated-term pairs were successfully extracted 
by analyzing query results from Internet search 
engines. Experimental results indicate the proposed 
approach shows promise in transliterated-term 
extraction. 
 
1 Introduction 
Machine transliteration plays an important role in 
machine translation. The importance of term 
transliteration can be realized from our analysis of 
the terms used in 200 qualifying sentences that were 
randomly selected from English-Chinese mixed news 
pages. Each qualifying sentence contained at least 
one English word. Analysis showed that 17.43% of 
the English terms were transliterated, and that most 
of them were content words (words that carry 
essential meaning, as opposed to grammatical 
function words such as conjunctions, prepositions, 
and auxiliary verbs). 
In general, a transliteration process starts by first 
examining a pre-compiled lexicon which contains 
many transliterated-term pairs collected manually or 
automatically. If a term is not found in the lexicon, 
the transliteration system then deals with this out-of-
vocabulary (OOV) term to try to generate a 
transliterated-term via a sequence of pipelined 
conversions (Knight, 1998). Before this issue can be 
dealt with, a large quantity of transliterated-term 
pairs are required to train conversion models. 
Preparing a lexicon composed of transliterated term 
pairs is time- and labor-intensive. Constructing such 
a lexicon automatically is the most important goal of 
this paper. The problem is how to collect 
transliterated-term pairs from text resources. 
Query logs recorded by Internet search engines 
reveal users' intentions and contain much information 
about users' behaviors. (Brill, 2001) proposed an 
interactive process that used query logs for extracting 
English-Japanese transliterated-terms. Under this 
method, a large initial number of term pairs were 
compiled manually. It is time-consuming to prepare 
such an initial training set, and the resource used is 
not publicly accessible. 
The Internet is one of the largest distributed 
databases in the world. It comprises various kinds of 
data and at the same time is growing rapidly. Though 
the World Wide Web is not systematically organized, 
much invaluable information can be obtained from 
this large text corpus. Many researchers dealing with 
natural language processing, machine translation, 
and information retrieval have focused on exploiting 
such non-parallel Web data (Al-Onaizan, 2002; Fung, 
1998;). Also, online texts contain the latest terms that 
may not be found in existing dictionaries. Regularly 
exploring Web corpora is a good way to update 
dictionaries. 
Transliterated-term extraction using non-parallel 
corpora has also been conducted (Kuo, 2003). 
Automated speech recognition-generated confusion 
matrices (AGCM) have been used successfully to 
bootstrap term extraction from Web pages collected 
by a software spider.  
AGCM were used successfully not only to alleviate 
pronunciation variation, especially the sociolinguistic 
causes, but also to construct a method for cross-
language syllable-phoneme conversion (CLSPC). 
This is a mapping from a source-language syllable 
into its target-language counterpart. The problem is 
how to produce such conversions if AGCM are not 
available for the targeted language pair. To generate 
confusion matrices from automated speech 
recognition requires the effort of collecting many 
speech corpora for model training, costing time and 
labor. Automatically constructing a CLSPC without 
AGCM is the other main focus of this paper. 
 Web pages, which are dynamically updated and 
publicly accessible, are important to many 
researchers. However, if many personally guided 
spiders were simultaneously collecting Web pages, 
they might cause a network traffic jam. Internet 
search engines, which update their data periodically, 
provide search services that are also publicly 
accessible. A user can select only the pages of 
interest from Internet search engines; this mitigates 
the possibility that a network traffic jam will be 
caused by many personally guided spiders. 
Possibly aligned candidate strings in two languages, 
which may belong to two completely different 
language families, are selected using local context 
analysis from non-parallel corpora (Kuo, 2003). In 
order to determine the degree of similarity between 
possible candidate strings, a method for converting 
such aligned terms cross-linguistically into the same 
representation in syllables is needed. A syllable is the 
basic pronunciation unit used in this paper. The tasks 
discussed in this paper are first to align syllables 
cross-linguistically, then to construct a cross-
linguistic relation, and third to use the trained 
relation to extract transliterated-term pairs. 
The remainder of the paper is organized as follows: 
Section 2 describes how English-Chinese 
transliterated-term pairs can be extracted 
automatically. Experimental results are presented in 
Section 3. Section 4 analyzes on the performance 
achieved by the extraction. Conclusions are drawn in 
Section 5. 
 
2. The Proposed Approach 
An algorithm based on minimizing the edit distance 
between words with the same representation has 
been proposed (Brill, 2001). However, the mapping 
between cross-linguistic phonemes is obtained only 
after the cross-linguistic relation is constructed. Such 
a relation is not available at the very beginning.  
A simple and fast approach is proposed here to 
overcome this problem. Initially, 200 verified correct 
English-Chinese transliterated-term pairs are 
collected manually. One of the most important 
attributes of these term pairs is that the numbers of 
syllables in the source-language term and the target-
language term are equal. The syllables of both 
languages can also be decomposed further into 
phonemes. The algorithm that adopts equal syllable 
numbers to align syllables and phonemes cross-
linguistically is called the simple syllable alignment 
algorithm (SSAA). This algorithm generates syllable 
and phoneme mapping tables between the source and 
target languages. These two mapping tables can be 
used to calculate similarity between candidate strings 
in transliterated-term extraction. With the mapping, 
the transliterated-term pairs can be extracted. The 
obtained term pairs can be selected according to the 
criterion of equal syllable segments. These qualified 
term pairs can then be merged with the previous set 
to form a larger set of qualified term pairs. The new 
set of qualified term pairs can be used again to 
construct a new cross-linguistic mapping for the next 
term extraction. This process iterates until no more 
new term pairs are produced or until other criteria are 
met. The conversions used in the last round of the 
training phase are then used to extract large-scale 
transliterated-term pairs from query results. 
Two types of cross-linguistic relations, phoneme-
to-phoneme (PP) and text-to-phoneme (TP), can be 
used depending on whether a source-language letter-
to-sound system is available or not. 
 
2.1 Construction of a Relation Using Phoneme-to-
Phoneme Mapping 
If a letter-to-phoneme system is available, a 
phoneme-based syllabification algorithm (PSA) is 
used for constructing a cross-linguistic relation, then 
a phoneme-to-phoneme (PP) mapping is selected. 
Each word in the located English string is converted 
into phonemes using MBRDICO (Pagel, 1998). In 
order to compare English terms with Chinese terms 
in syllables, the generated English phonemes are 
syllabified into consonant-vowel pairs. Each 
consonant-vowel pair is then converted into a 
Chinese syllable. The PSA used here is basically the 
same as the classical one (Jurafsky, 2000), but has 
some minor modifications. Traditionally, an English 
syllable is composed of an initial consonant cluster 
followed by a vowel and then a final consonant 
cluster. However, in order to convert English 
syllables to Chinese ones, the final consonant cluster 
is appended only when it is a nasal. The other 
consonants in the final consonant cluster are then 
segmented into isolated consonants. Such a syllable 
may be viewed as the basic pronunciation unit in 
transliterated-term extraction. 
After English phonemes are grouped into syllables, 
the English syllables can be converted into Chinese 
ones according to the results produced by using 
SSAA. The accuracy of the conversion can improve 
progressively if the cross-linguistic relation is 
deduced from a large quantity of transliterated-term 
pairs. 
Take the word ?polder? as an example. First, it is 
converted into /pold?/ using the letter-to-phoneme 
system, and then according to the phoneme-based 
syllabification algorithm (PSA), it is divided into /po/, 
/l/, and /d?/, where /l/ is an isolated consonant. 
Second, these English syllables are then converted 
into Chinese syllables using the trained cross-
 linguistic relation; for example, /po/, /l/, and /d?/ are 
converted into /po/, /er/, and /de/ (in Pin-yin), 
respectively. /l/ is a syllable with only an isolated 
consonant. A final is appended to its converted 
Chinese syllable in order to make it complete 
because not all Chinese initials are legal syllables. 
The other point worth noting is that /l/, a consonant 
in English, is converted into its Chinese equivalent, 
/er/, but, /er/ is a final (a kind of complex vowel) in 
Chinese. 
 
2.2 Construction of a Relation Using Text-to-
Phoneme Mapping 
If a source language letter-to-phoneme system is 
not available, a simple text-based syllabification 
algorithm (TSA) is used and a text-to-phoneme (TP) 
mapping is selected. An English word is frequently 
composed of multiple syllables; whereas, every 
Chinese character is a monosyllable. First, each 
English character in an English term is identified as a 
consonant, a vowel or a nasal. For example, the 
characters ?a?, ?b? and ?n? are viewed as a vowel, a 
consonant and a nasal, respectively. Second, 
consecutive characters of the same attribute form a 
cluster. However, some characters, such as ?ch?, 
?ng? and ?ph?, always combine together to form 
complex consonants. Such complex consonants are 
also taken into account in the syllabification process. 
A Chinese syllable is composed of an initial and a 
final. An initial is similar to a consonant in English, 
and a final is analogous to a vowel or a combination 
of a vowel and a nasal. Using the proposed simple 
syllable alignment algorithm, a conversion using TP 
mapping can be produced. The conversion can also 
be used in transliterated-term extraction from non-
parallel web corpora. 
The automated construction of a cross-linguistic 
mapping eliminates the dependency on AGCM 
reported in (Kuo, 2003) and makes transliterated-
term extraction for other language pairs possible. The 
cross-linguistic relation constructed using TSA and 
TP is called CTP; on the other hand, the cross-
linguistic relation using PSA and PP is called CPP. 
 
3 The Experimental Results 
3.1 Training Cross-language Syllable-phoneme 
Conversions 
An English-Chinese text corpus of 500MB in 
15,822,984 pages, which was collected from the 
Internet using a web spider and was converted to 
plain text, was used as a training set. This corpus is 
called SET1. From SET1, 80,094 qualifying 
sentences that occupied 5MB were extracted. A 
qualifying sentence was a sentence composed of at 
least one English string.  
Two experiments were conducted using either CPP 
or CTP on SET1. Figure 1 shows the progress of 
extracting transliterated-term pairs achieved using 
CPP mapping. A noteworthy phenomenon was that 
phoneme conversion produced more term pairs than 
syllable conversion did at the very beginning of 
training. This is because, initially, the quality of the 
syllable combinations is not good enough. The 
phonemes exerted finer-grained control than 
syllables did. However, when the generated syllable 
combinations improved in quality, the situation 
changed. Finally, extraction performed using syllable 
conversion outperformed that achieved using 
phoneme conversion. Note also that the results 
produced by using phonemes quickly approached the 
saturation state. This is because the English phoneme 
set is small. When phonemes were used 
independently to perform term extraction, fewer 
extracted term pairs were produced than were 
produced using syllables or a combination of 
syllables and phonemes.  
0
500
1000
1500
2000
2500
3000
3500
4000
4500
5000
5500
6000
6500
7000
Iter #1 Iter #2 Iter #3 Iter #4 Iter #5 Iter #6
Syllable (S)
Phoneme (P)
S+P
 
Figure 1. The progress of extracting transliterated-
term pairs using CPP conversion 
Figure 2 shows the progress of extracting 
transliterated-term pairs using CTP. The same 
situation also occurred at the very beginning of 
training. Comparing the results generated using CPP 
and CTP, CPP outperformed CTP in terms of the 
quantity of extracted term pairs because the 
combinations obtained using TSA are larger than 
those obtained using PSA. This is also revealed by 
the results generated at iteration 1 and shown in 
Figures 1 and 2. 
0
500
1000
1500
2000
2500
3000
3500
4000
4500
5000
5500
6000
Iter #1 Iter #2 Iter #3 Iter #4 Iter #5 Iter #6
Syllable (S)
Phoneme (P)
S+P
 Figure 2. The progress of extracting transliterated-
term pairs using CTP conversion. 
 3.2 Transliterated-term Extraction 
The Web is growing rapidly. It is a rich information 
source for many researchers. Internet search engines 
have collected a huge number of Web pages for 
public searching (Brin, 1998). Submitting queries to 
these search engines and analyzing the results can 
help researchers to understand the usages of 
transliterated-term pairs. 
Query results are text snippets shown in a page 
returned from an Internet search engine in response 
to a query. These text snippets may be composed of 
texts that are extracted from the beginning of pages 
or from the texts around the keywords matched in the 
pages. Though a snippet presents only a portion of 
the full text, it provides an alternative way to 
summarize the pages matched. 
Initially, 200 personal names were randomly 
selected from the names in the 1990 census 
conducted by the US Census Bureau1 as queries to 
be submitted to Internet search engines. CPP and 
CTP were obtained in the last round of the training 
phase. The estimated numbers of distinct qualifying 
term pairs (EDQTP) obtained by analyzing query 
results and by using CPP and CTP mappings for 7 
days are shown in Table 1. A qualifying term pair 
means a term pair that is verified manually to be 
correct. EDQTP are term pairs that are not verified 
manually but are estimated according to the precision 
achieved during the training phase. 
Finally, a text corpus called SET2 was obtained by 
iteratively submitting queries to search engines. 
SET2 occupies 3.17GB and is composed of 67,944 
pages in total. The term pairs extracted using CTP 
were much fewer in number than those extracted 
using CPP. This is because the TSA used in this 
study, though effective, is very simple and 
rudimentary. A finer-grained syllabification 
algorithm would improve performance. 
 CPP CTP 
EDQTP 201,732 110,295 
Table 1. The term pairs extracted from Internet 
search engines using PP and TP mappings. 
 
4 Discussion 
Comparing the performances achieved by CPP and 
CTP, the results obtained by using CPP were better 
than those with CTP. The reason is that TSA is very 
simple. A better TSA would produce better results. 
Though TSA is simple, it is still effective in 
automatically extracting a large quantity of term 
                                               
1http://www.census.gov/genealogy/names/ 
pairs. Also, TSA has an advantage over PSA is that 
no letter-to-phoneme system is required. It could be 
helpful when applying the proposed approach to 
other language pairs, where such a mapping may not 
be available. 
 
5 Conclusions 
An approach to constructing transliterated-term 
lexicons has been presented in this paper. A simple 
alignment algorithm has been used to automatically 
construct confusion matrices for cross-language 
syllable-phoneme conversion using phoneme-to-
phoneme (PP) and text-to-phoneme (TP) 
syllabification algorithms. The proposed approach 
not only reduces the need for using automated 
speech recognition-generated confusion matrices, but 
also eliminates the need for a letter-to-phoneme 
system for source-language terms if TP is used to 
construct a cross-language syllable-phoneme 
conversion and to successfully extract transliterated-
term pairs from query results returned by Internet 
search engines. The performance achieved using PP 
and TP has been compared and discussed. The 
overall experimental results show that this approach 
is very promising for transliterated-term extraction. 
 
References 
Al-Onaizan Y. and Knight K. 2002. Machine 
Transliteration of Names in Arabic Text, In Proceedings 
of ACL Workshop on Computational Approaches to 
Semitic Languages, pp. 34-46. 
Brill E., Kacmarcik G., Brockett C. 2001. Automatically 
Harvesting Katakana-English Term Pairs from Search 
Engine Query Logs, In Proceedings of Natural 
Language Processing Pacific Rim Symposium, pp. 393-
399. 
Brin S. and Page L. 1998. The Anatomy of a Large-scale 
Hypertextual Web Search Engine, In Proceedings of 7th 
International World Wide Web Conference, pp. 107-117. 
Fung P. and Yee L.-Y. 1998. An IR Approach for 
Translating New Words from Nonparallel, Comparable 
Texts. In Proceedings of the 36th Annual Meeting of the 
Association for Computational Linguistics and 7th 
International Conference on Computational Linguistics, 
pp. 414-420. 
Jurafsky D. and Martin J. H. 2000. Speech and Language 
Processing, pp. 102-120, Prentice-Hall, New Jersey. 
Knight K. and Graehl J. 1998. Machine Transliteration, 
Computational Linguistics, Vol. 24, No. 4, pp.599-612. 
Kuo J. S. and Yang Y. K. 2003. Automatic Transliterated-
term Extraction Using Confusion Matrix from Non-
parallel Corpora, In Proceedings of ROCLING XV 
Computational Linguistics Conference, pp.17-32. 
Pagel V., Lenzo K., and Black A. 1998. Letter to Sound 
Rules for Accented Lexicon Compression, In 
Proceedings of ICSLP, pp. 2015-2020. 
