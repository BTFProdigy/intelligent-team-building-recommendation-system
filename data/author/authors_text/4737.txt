Modeling sentence processing in ACT-R
Shravan Vasishth
Department of Computational Linguistics
Saarland University, PO Box 15 11 05
66041 Saarbru?cken, Germany
vasishth@acm.org
Richard L. Lewis
Department of Psychology
University of Michigan
Ann Arbor, MI, USA
rickl@umich.edu
Abstract
We present a series of simulations of behavioral data
by casting a simple parsing model in the cognitive
architecture ACT-R. We show that constraints de-
fined in ACT-R, specifically those relating to acti-
vation, can account for a range of facts about hu-
man sentence processing. In doing so, we argue
that resource limitation in working memory is bet-
ter defined as an artefact of very general and in-
dependently motivated principles of cognitive pro-
cessing.
1 Introduction
Although language processing may be a specialized
cognitive faculty, it is possible that it is nevertheless
shaped by general constraints on the human cog-
nitive architecture. This point has been addressed
extensively in the connectionist literature, but we
present a somewhat different approach to this prob-
lem by casting parsing within the cognitive architec-
ture ACT-R (Anderson et al, 2002) and directly us-
ing the constraints provided in ACT-R to account for
several interesting cross-linguistic facts: the well-
known sentential complement/relative clause asym-
metry (Gibson, 2000; Grodner and Gibson, 2003)
and the subject/object relative clause asymmetry in
English (Homes and O?Regan, 1981); and some re-
cent results (Vasishth, 2003) involving Hindi center
embeddings, including a principled account of indi-
vidual variation in subject behavior.
In developing this approach, we argue that re-
source limitation in working memory is better de-
fined as an artefact of very general constraints on
information processing ? specifically, rehearsal and
activation ? rather than as an inherent numerical
bound on memory capacity (cf. (Gibson, 2000;
Hawkins, 1994); also see Section 3.5).
In the rest of this paper, we first introduce the
ACT-R architecture. Then we present the results
of several simulations of experiments available in
the psycholinguistic literature. The paper concludes
with a discussion of the potential advantages and
shortcomings of this approach, and of the broader
consequences of modeling parsing within a cogni-
tive architecture.
2 A brief introduction to the cognitive
architecture ACT-R
ACT-R is a theory of the human cognitive archi-
tecture. It allows the development of computa-
tional models that can closely simulate experimental
methodologies such as eye-tracking and self-paced
reading, and has been used to model a wide array of
behavioral data from learning and memory, problem
solving and decision making, language and commu-
nication, perception and attention, cognitive devel-
opment, and individual differences (Anderson et al,
2002).
The ACT-R architecture is attractive as a model-
ing tool for three reasons. First, it is based on a wide
array of empirical results in various domains of cog-
nitive psychology. Second, it is flexible enough to
permit the modeler to add their own assumptions
and theories about the specific task to be modeled.
Finally, ACT-R models yield dependent measures
such as reading time in much the same way as hu-
mans performing the experiment; e.g., the system
can easily be programmed to simulate key presses
after it processes material presented on the screen.
As shown in Figure 1, the architecture consists of
several MODULES such as Declarative, Visual, and
Manual. Each module is associated with a BUFFER
which temporarily stores information for a given ac-
tion. For example, the visual buffer is used to store
an item ?seen? by the system in the environment be-
fore it is used in the service of some task.
The module that is especially important for the
present paper is the Declarative (henceforth, DM).
DM represents permanent memory: every fact that
is assumed to be known is encoded as a CHUNK in
declarative memory. A chunk is an attribute-value
list structure with a special attribute, ISA, which de-
fines its type. The attributes are also referred to as
slots. The value of a chunk?s slot is also (by defi-
nition) a chunk, unless it is double-quoted or is the
Intentional Module Declarative module
Environment
Visual module Manual module
Visual buffer Manual buffer
Matching
Selection
Execution
Retrieval bufferGoal buffer
Pr
od
uc
tio
ns
Figure 1: This is a schematic view of the ACT-R
system. ?Environment? is the outside world that
ACT-R is programmed to interact with. The arrows
show the possible flows of information. Productions
and the central box with the boxes labeled ?Match-
ing?, ?Selection?, and ?Execution? are intended to
represent a set of central executive mechanisms and
processes.
lisp primitive ?nil?.
Each DM chunk has an activation that determines
its speed of retrieval, and the probability that it will
be retrieved; the initial activation for a given chunk
can be set manually.
There is a GOAL BUFFER that holds a current goal
under consideration (there can be only one goal at
one time); this goal is a chunk with a given type and
possibly instantiated slots.
The control structure for modeling a sequence of
events is a set of PRODUCTIONS; a production is
simply an if-then statement of the following general
form: for a given state of one or more buffers and/or
DM, execute some actions. Examples of executing
actions are retrieving something from DM; chang-
ing a value in one of the goal?s slots; repositioning
the hand over a keyboard; a visual shift of attention;
changing the goal to a new one, etc. If the goal is
changed, then this new goal now occupies the goal
buffer.
Building an ACT-R model is essentially a defi-
nition of possible sequences of actions for a given
state of affairs. Events like retrievals from DM are
triggered by looking at the contents of one or more
buffers. For example, the ACT-R system ?sees? an
item/object on the screen and then encodes it as a vi-
sual chunk. This chunk can then be harvested from
the visual buffer; it includes (as slot-value specifi-
cations) information about the content of the item
seen, its x-y coordinates, etc. One can define an ac-
tion based on this information, such as retrieving a
chunk from DM.
3 Modeling sentence parsing in ACT-R
Previous research suggests that humans employ
some variant of left-corner parsing (see, e.g.,
(Resnik, 1992)), which in essence involves a
bottom-up and a top-down (predictive) step. We
adopt this parsing strategy in the simulations. In
order to model the prediction of syntactic struc-
ture based on incrementally appearing input, we as-
sume that sentence structure templates are available
in declarative memory as underspecified chunks.
These chunks are retrieved every time a new word is
integrated into the structure, as are prior arguments
necessary for semantic integration.
We illustrate the parsing process with a simple
example (Figure 2). Suppose that the sentence to be
parsed is The girl ran, and suppose that we are sim-
ulating self-paced reading (Just et al, 1982). When
the word the is seen, a bottom-up and top-down
structure building step results in a sentence with an
intransitive verb being predicted. This structure be-
comes the current goal. Then the word girl is seen
and processed, i.e., its lexical entry is retrieved from
declarative memory. The noun slot in the goal is
then instantiated with that lexical entry. In the next
step, if the word ran is seen the relevant lexical item
for the verb is retrieved and instantiated with the
verb slot of the goal; here, the verb?s argument is
also retrieved and integrated with the subcategoriza-
tion frame of the verb. If, instead of ran the word
that appears, a new goal is created, with any pre-
viously instantiated slots of the preceding goal be-
ing passed on to the new goal, and parsing proceeds
from there.
Each retrieval of a goal from memory results in
a surge in its activation, so that repeated retrievals
result in increased activation; and the higher the ac-
tivation of an item the faster it is processed. At the
same time, activation decays according to the power
law of forgetting (Anderson et al, 2002). In the
same way that the goals undergo decay and reacti-
vation, so do the previously seen words. This means
that the speed of retrieval of a previously seen argu-
ment at a verb will be determined by the activation
level of that argument. Thus, the activation of both
the goals (predicted structures) and the arguments
affect processing.
In our simulations, for simplicity we code in the
exact steps that ACT-R takes for particular sen-
tences. Although it is feasible to build a very gen-
Det N V1
the
S
ran
Det N
girl
S
that
t V2
V1
the
NP NP
NP
NP
Det N V1
girlthe
S
Det N V1
girlthe
S
S?
S
Figure 2: A simple illustration of parsing steps in
the ACT-R simulations presented.
eral parser in pure ACT-R, before doing this we
wanted to first establish whether ACT-R?s reacti-
vation mechanisms can account for a reasonable
array of facts from the sentence processing litera-
ture. In (Lewis and Vasishth, An activation-based
model of sentence processing as skilled memory re-
trieval, (tentative title; in preparation)) we provide
a detailed description of a model employing mech-
anisms similar to those described here, but one that
behaves more like a standard parser.
3.1 English subject versus object relative
clauses
It is well known (Homes and O?Regan, 1981) that
English subject relatives are easier to process that
object relatives (1). In the parsing model outlined
above, we can model this result without changing
any ACT-R parameters at all (i.e., we use the default
settings for the parameters).
(1) a. The reporter who sent the photographer
to the editor hoped for a good story.
b. The reporter who the photographer sent
to the editor hoped for a good story.
The explanation comes from the decay of the ar-
guments of the verb sent: in object relatives the
argument reporter decays much more than in the
subject relative by the time it is integrated with the
verb?s subcategorization frame (Figure 3). This is
because more time elapses between the argument
being first seen and its retrieval at the verb.1
1A reviewer points out that several head-final languages
such as German and Dutch also have a subject relative pref-
erence and in these languages the activation level cannot be the
explanation. We do not claim that decay is the only constraint
operating in parsing; frequency effects (greater preference for
30
0
40
0
50
0
60
0
70
0
80
0
90
0
10
00
Position
M
ea
n 
R
ea
di
ng
 T
im
e 
(m
se
c)
1 2 3 4 5 6 7 8 9 10 11 12 13
Object Relative
Subject Relative
The reporter
who
sent
The reporter
who
the
photographer
sent
Figure 3: The reading times provided by the model.
Retrieval of reporter at sent is harder in the object
relative because of increased argument decay.
3.2 The SC/RC asymmetry in English
It is also well-known (Gibson, 2000) that a senten-
tial complement (SC) followed by a relative clause
(RC) is easier to process than an RC followed by an
SC:
(2) a. The fact that the employee who the
manager hired stole office supplies wor-
ried the executive.
b. #The executive who the fact that the
employee stole office supplies worried
hired the manager.
As in the previous discussion about relative
clauses, in the harder case the decay of the argument
executive at the verb worried is greater compared
to the decay of the argument employee at hired in
the easier-to-process sentence. In addition, the to-
tal reading time for the harder sentence is about 120
msec longer.2
3.3 Hindi center embeddings
Previous work (Hakes, 1972), (Konieczny, 2000)
has shown that if argument-verb distance is in-
creased, processing is easier at the verb. (Vasishth,
more frequently occurring subject relatives) etc. could certainly
dominate where the amount of decay is constant in subject and
object relatives. It is an open empirical question whether fre-
quency alone can account for the subject/object asymmetry in
English, but given that we have independent empirical justi-
fication for decay (see Section 3.5), the above is a plausible
explanation.
2As a reviewer points out, ?the account in terms of acti-
vation decay suggests that the SC/RC asymmetry can be an-
nihilated or even reversed by inserting longer or shorter NPs
between the critical verbs (worried, hired) and their arguments
(executive, employee). This seems unrealistic.? This is surely
an empirical question that needs to be verified experimentally;
we intend to pursue this very interesting issue in future work.
400
500
600
700
800
900
the fac
t
tha
t
the
em
plo
ye
e
w
ho the
m
an
ag
er
hir
ed
sto
le
off
ice
 su
pp
lie
s
w
or
rie
d
the
ex
ec
uti
ve
SC/RC (easy); total RT = 7482 msec
the
ex
ec
uti
ve
w
ho the fac
t
tha
t
the
em
plo
ye
e
sto
le
off
ice
sup
pli
es
w
or
rie
d
hir
ed the
m
an
ag
er
RC/SC (hard); total RT = 7605 msec
R
ea
di
ng
 T
im
e 
(m
se
c)
RC/SC
SC/RC
Figure 4: Model?s behavior in the complement-
clause/relative-clause contrast.
2003) presented similar results in Hindi. The Hindi
experiment manipulated distance by comparing the
baseline condition (3a) with the case where an ad-
verb intervened (3b), a verb-modifying PP inter-
vened (3c), and relative clause intervened that mod-
ified the preceding NP (3d).
(3) a. Siitaa-ne
Sita-erg
Hari-ko
Hari-dat
Ravi-ko
Ravi-dat
[kitaab-ko
book-acc
khariid-neko]
buy-inf
bol-neko
tell-inf
kahaa
told
?Sita told Hari to tell Ravi to buy the
book.?
b. Siitaa-ne
Sita-erg
Hari-ko
Hari-dat
Ravi-ko
Ravi-dat
[kitaab-ko
book-acc
jitnii-jaldii-ho-sake
as-soon-as-possible
khariid-neko]
buy-inf
bol-neko
tell-inf
kahaa
told
?Sita told Hari to tell Ravi to buy the
book as soon as possible.?
c. Siitaa-ne
Sita-erg
Hari-ko
Hari-dat
Ravi-ko
Ravi-dat
[kitaab-ko
book-acc
ek bar
.
hiya dukaan se
from-a-good-shop
khariid-neko]
buy-inf
bol-neko
tell-inf
kahaa
told
?Sita told Hari to tell Ravi to buy the
book from a good shop.?
d. Siitaa-ne
Sita-erg
Hari-ko
Hari-dat
Ravi-ko
Ravi-dat
[kitaab-ko
book-acc
jo-mez-par-thii
that-was-on-a-table
khariid-neko]
buy-inf
bol-neko
tell-inf
kahaa
told
?Sita told Hari to tell Ravi to buy the
book that was lying on a/the table.?
In all the ?insertion? cases a statistically signifi-
cant speedup was observed at the verb, compared to
the baseline condition.
This experiment?s results were replicated in the
ACT-R system; the replication is based on the as-
sumption that the goal (predicted syntactic struc-
ture) is reactivated each time it (i.e., the entire pre-
dicted structure) is modified. The intervening items
result in an extra retrieval compared to the base-
line, resulting in faster processing at the verb. In
this model, one parameter was changed: the rate of
decay of items. We justify this change in the next
sub-section.
The modeling results are shown in Figure 5.
? Adv PP RC
Data
R
ea
di
ng
 ti
m
es
 (m
se
c)
0
20
0
40
0
60
0
80
0
10
00
? Adv PP RC
Model
R
ea
di
ng
 ti
m
es
 (m
se
c)
0
20
0
40
0
60
0
80
0
10
00
Figure 5: Reading times from data versus model, at
the first verb.
3.4 Individual variation in Hindi center
embedding data
In the Hindi experiment, there was a further varia-
tion in the data when individual subjects? data were
considered: only about 48% of subjects showed a
speedup at the verb. About 21% showed a slow-
down and there was only a few milliseconds differ-
ence (essentially no difference) in the reading times
for about 31% of the subjects. The observed varia-
tion was a systematic trend in the sense that the 47%
of the subjects who showed a speedup or slowdown
in adverb-insertion case also showed the same trend
in the PP- and RC-inserted cases ? the probability of
this happening is considerably below chance level.
The rate of decay defined in ACT-R?s rehearsal
equation can systematically explain this variation.
Consider the situation where a chunk   with an ini-
tial activation of  is retrieved. The activation is
0
20
0
40
0
60
0
80
0
10
00
12
00
14
00
d=0.01
R
ea
di
ng
 T
im
e 
at
 fi
rs
t v
er
b 
(m
se
c)
Data Model
No Adverb
Adverb
Figure 6: Modeling speedup.
0
20
0
40
0
60
0
80
0
10
00
12
00
14
00
d=0.5
R
ea
di
ng
 T
im
e 
at
 fi
rs
t v
er
b 
(m
se
c)
Data Model
No Adverb
Adverb
Figure 7: Modeling slowdown.
0
20
0
40
0
60
0
80
0
10
00
12
00
14
00
d=0.16
R
ea
di
ng
 T
im
e 
at
 fi
rs
t v
er
b 
(m
se
c)
Data Model
No Adverb
Adverb
Figure 8: Modeling no difference in reading time.
recalculated each time a retrieval occurs, according
to the following equation.
(4)    	




Here,  is the number of times the chunk   was
successfully retrieved,


 is the time elapsed since
the  -th retrieval, and  is a decay rate that defaults
to Proceedings of the 2014 ACL Workshop on Cognitive Modeling and Computational Linguistics, pages 1?9,
Baltimore, Maryland USA, June 26 2014.
c
?2014 Association for Computational Linguistics
Computationally Rational Saccadic Control: An Explanation of Spillover
Effects Based on Sampling from Noisy Perception and Memory
Michael Shvartsman
Department of Psychology
University of Michigan
mshvarts@umich.edu
Richard L. Lewis
Department of Psychology
University of Michigan
rickl@umich.edu
Satinder Singh
Computer Science & Eng.
University of Michigan
baveja@umich.edu
Abstract
Eye-movements in reading exhibit frequency
spillover effects: fixation durations on a word are
affected by the frequency of the previous word. We
explore the idea that this effect may be an emer-
gent property of a computationally rational eye-
movement strategy that is navigating a tradeoff be-
tween processing immediate perceptual input, and
continued processing of past input based on mem-
ory. We present an adaptive eye-movement con-
trol model with a minimal capacity for such pro-
cessing, based on a composition of thresholded se-
quential samplers that integrate information from
noisy perception and noisy memory. The model
is applied to the List Lexical Decision Task and
shown to yield frequency spillover?a robust prop-
erty of human eye-movements in this task, even
with parafoveal masking. We show that spillover in
the model emerges in approximately optimal con-
trol policies that sometimes process memory rather
than perception. We compare this model with one
that is able to give priority to perception over mem-
ory, and show that the perception-priority policies
in such a model do not perform as well in a range
of plausible noise settings. We explain how the
frequency spillover arises from a counter-intuitive
but fundamental property of sequenced thresholded
samplers.
1 Introduction and overview
Our interest is in understanding how eye-
movements are controlled in service of linguis-
tic tasks involving reading?more specifically,
how saccadic decisions are conditioned on the
moment-by-moment state of incremental percep-
tual and cognitive processing. The phenomena
we are concerned with here are spillover effects,
where fixation durations on a word are affected by
linguistic properties of the prior word or words.
The specific idea we explore is that spillover ef-
fects may be emergent properties of a computa-
tionally rational control strategy that is navigating
a tradeoff between processing immediate percep-
tual input, and continued processing of past input
based on a memory of recent stimuli.
The paper is organized as follows. We first
review evidence that eye-movement control in
reading is strategically adaptive, and describe our
theoretical approach. We then review evidence
from gaze-contingent eye-tracking paradigms?
some existing and some new?that suggests that
frequency spillover is not driven exclusively by
parafoveal preview of upcoming words. We take
this as evidence that frequency spillover may be
driven in part by processing of words that con-
tinues after the eyes have moved away. We then
extend an existing adaptive control model of eye-
movements with a minimal capacity for such con-
tinued processing, by allowing it to process a
memory of past input. The model is based on
a simple composition of thresholded sequential
samplers that integrate information from noisy
perception and noisy memory. Threshold parame-
ters define the control policy and their values de-
termine how processing resources are allocated
to perception and memory. We provide a com-
putational rationality analysis of the model?s pol-
icy space: First, we show that frequency spillover
emerges in top-performing policies, where perfor-
mance is evaluated on the same task and payoff
given to human participants. Second, we show
that a model capable of spillover does no worse
than an otherwise identical model that can elim-
inate spillover by always attending to perception
when it can, and that the spillover-capable poli-
cies in such a model do no worse than spillover-
incapable ones across the speed-accuracy tradeoff
curve, and in fact do better in some portions of
the noise parameter space. Finally, we trace the
origin of the effect to a counter-intuitive but fun-
damental property of the dynamics of sequenced
thresholded samplers.
2 Adaptive control of eye-movements:
Evidence and theoretical approach
A growing body of evidence suggests that eye-
movements in reading are strategic adaptations
that manifest at the level of individual fixations.
For example, Rayner and Fischer (1996) showed
1
that when participants are searching for a partic-
ular word in a text rather than reading for full
comprehension, saccade durations are shortened
and the magnitude of frequency effects is reduced.
Wotschack (2009) showed that readers assigned
the task of proofreading read more slowly and per-
formed more second-pass reading with fewer skips
than in a control reading-for-comprehension task.
People also adapt reading behavior to within-
task manipulations of difficulty and payoff.
Wotschack (2009) showed that people change
their reading behavior in response to manipula-
tions of the difficulty of comprehension questions.
Lewis et al. (2013) showed that people adapt their
eye movements in response to changes in quanti-
tative task payoffs. Payoffs emphasizing speed at
the expense of accuracy result in shorter fixation
durations and lower accuracies.
We seek to develop a model that can explain
such variation in eye-movement behavior as a ra-
tional adaptation to the task (including utility) and
the internal oculomotor and cognitive architecture
(Lewis et al., 2013). Such a model would permit a
computational rationality analysis (Lewis et al., to
appear) because the problem of rational behavior
is defined in part by the bounded mechanisms of
the posited computational architecture.
We constrain our architectural assumptions by
building on existing theories of oculomotor archi-
tecture, such as E-Z Reader (Reichle et al., 2009).
But we enrich these architectures with explicit as-
sumptions about the policy space of saccadic con-
trol, and with assumptions about the processing of
noisy perception and memory. This enriched ar-
chitecture is then embedded in a minimal cogni-
tive system that is capable of performing a com-
plete experimental task. The complete model af-
fords computational rationality analyses because it
can be used to derive the implications of saccadic
control policies for task performance.
3 The nature of spillover effects
Our aim in this section is to establish a link be-
tween spillover and the continued processing of
past input based on memory. Consider a pair of
words in sequence: word
n?1
and word
n
. There
are three natural explanations for how the fre-
quency of word
n?1
could affect the duration of
fixations on word
n
. (1) During fixation of word
n
,
perceptual information from word
n?1
is available
in the parafovea and continues to be processed.
masked unmasked
?
??
?
?
??
?
230
250
270
290
310
high low high low
Fixated Word Frequency
Si
ng
le
 F
ixa
tio
n 
Du
ra
tio
n Prev. Word Frequency
?
?
high
low
Figure 1: Frequency spillover in the List Lexical
Decision Task. Single fixation durations (fixations
when the word was fixated only once) on words
as a function of the fixated and previous word?s
frequency. Frequencies are binned by a median
split; error bars are bootstrapped standard errors.
We call this the parafoveal review explanation.
(2) During fixation on word
n?1
, perceptual infor-
mation from word
n
is available in the parafovea;
the frequency of word
n?1
affects the degree to
which this information is processed, and this in
turns affects the subsequent fixation duration on
word
n
. We call this the parafoveal preview expla-
nation. (3) During fixation of word
n
, processing
of word
n?1
continues based on some memory of
the perception of word
n?1
, and this processing is
affected by the frequency of word
n?1
. We call this
the memory explanation.
It is unlikely that spillover is driven by
parafoveal review because the effective visual field
in reading does not extend to the left of the current
word (Rayner et al., 1980).
The standard paradigm for investigating the re-
lationship between spillover effects and parafoveal
preview is some form of parafoveal masking
(Rayner, 1975): a nonveridical preview of word
n
is shown until the eye crosses an invisible bound-
ary just before word
n
, at which point word
n
is
shown. When participants are not informed of
the manipulation or do not notice it, they do not
exhibit frequency spillover (Henderson and Fer-
reira, 1990; Kennison and Clifton, 1995; White et
al., 2005). However, when participants are aware
of preview being unavailable or not veridical, the
spillover frequency effect remains (White et al.,
2005; Schroyens et al., 1999). These results sug-
gest that parafoveal preview (or review) cannot be
the only explanation of spillover and therefore the
2
Figure 2: Example dynamics of a decision to saccade from word
n?1
to word
n
. The memory-driven
attention shift decision can delay the start of perceptual sampling on the next word, potentially creating
spillover. A detailed description of the dynamics depicted in this figure is in ?4.
memory explanation warrants consideration. We
now summarize unpublished data consistent with
these findings in a simple linguistic task that we
also use to test the new model reported below.
Spillover in the List Lexical Decision Task
(LLDT). We use the List Lexical Decision Task
(LLDT) (Lewis et al., 2013), an extension of a task
introduced by Meyer and Schvaneveldt (1971). In
the LLDT participants must determine whether
a list of six strings contains all words, or con-
tains a single nonword. All strings are four char-
acters in length and separated by six character
spaces. The task was designed to require sequen-
tial eye-movements and contact with the mental
lexicon (but not higher-level linguistic process-
ing), to minimize parafoveal processing (via the
wide spacing), and to yield a high proportion of
single-fixation durations (via short strings).
Two versions of the task were performed by
separate participant groups. In the masked con-
dition, we used a gaze-contingent moving window
paradigm wherein all strings but the fixated string
were replaced with hashmarks (####). In the un-
masked condition, all six strings remained visible.
Figure 1 shows the effects of word frequency on
single fixation durations. The main result of cur-
rent interest is that frequency spillover is evident
in both conditions, despite the wide spacing in the
unmasked condition, and the complete denial of
parafoveal preview in the masked condition.
The work reviewed above and our new data
are consistent with an account of spillover in
which both parafoveal preview (if available) and
memory-based processing are operative. Our con-
cern here is with the latter: understanding how a
noisy memory of recently seen stimuli might be
incorporated into an adaptive oculomotor architec-
ture, and exploring whether rational exploitation
of that memory might lead to spillover.
4 A model of saccadic control with noisy
memory for recent perception
Our new model extends the one presented in Lewis
et al. (2013) to include a noisy memory that
buffers perceptual input. We develop it in the con-
text of the LLDT, but its essential elements are not
tied to this task. It is most easily understood by
first considering the dynamics of a single decision
to saccade from one word to the next, as presented
in Figure 2. After describing these dynamics we
summarize the model?s key assumptions and asso-
ciated mathematical specification.
The dynamics of a decision to saccade from
word
n?1
to word
n
. The eye first fixates
word
n?1
. Some time passes before information
from the retina becomes available for perceptual
processing (the eye-brain lag, EBL in Figure 2). A
sequence of noisy perceptual samples then arrive
and are integrated via an incremental and noisy
Bayesian update of a probability distribution over
lexical hypotheses in a manner described below.
The perceptual samples are also buffered by stor-
ing them in a memory that contains samples from
only one word. When the probability of one of the
hypotheses reaches the saccade threshold, saccade
planning is initiated. Perceptual sampling (marked
as free sampling in Figure 2 because its length is
not under adaptive control) continues in parallel
with saccade planning until the fixation ends, and
then for another EBL amount longer (these are
samples received at the retina during the fixation
and only now arriving at the lexical processor).
The model then switches to sampling from its
memory, continuing to update the distribution over
lexical hypotheses until one of the hypotheses
reaches an attention shift threshold. If this thresh-
old had already been reached during the earlier
perceptual sampling stages, attention shifts in-
stantly. Otherwise attention remains on word
n?1
even if the eye has saccaded to word
n
, and the eye-
3
brain lag on word
n
is completed. Perceptual sam-
ples from word
n
will not be processed until atten-
tion is shifted away from the memory-based pro-
cessing of word
n?1
. Thus the memory processing
on word
n?1
may delay processing of perceptual
samples from word
n
; perceptual samples arriving
during this time are buffered in the memory. In
this way the posterior update is a limited compu-
tational resource and its relative allocation to per-
ception or memory is determined by the saccade
and attention shift thresholds. To the extent that
the time to reach the attention shift threshold is
sensitive to the frequency of word
n?1
, the model
may exhibit a spillover frequency effect.
Lexical processing as rise-to-threshold deci-
sionmaking. The decisions to plan a saccade,
shift attention, and make a motor response are re-
alized as Multi-hypothesis Sequential Probability
Ratio Tests (Baum and Veeravalli, 1994; Dragalin
et al., 2000). At each timestep, the model per-
forms a Bayes update based on a noisy sample
drawn from perception or memory, with the pos-
terior at each timestep becoming the prior for the
next timestep. Our choice of word representation
follows Norris (2006) in representing a letter as a
unit-basis vector encoding and a word as a con-
catenation of such vectors.
To generate a perceptual sample, mean-zero
Gaussian perception noise with standard devia-
tion (SD) ?
p
is added to each component of the
word representation vector. Each perceptual sam-
ple is also stored in a memory buffer, and mem-
ory samples are generated by uniformly draw-
ing a stored sample from memory (with replace-
ment), and adding an additional mean-zero Gaus-
sian memory noise with SD ?
m
to each posi-
tion. Before each Bayesian update, whether us-
ing a sample from perception or memory, mean-
zero Gaussian update noise with SD ?
u
is added to
each component of the word representation vector.
Thus a Bayes update from a perceptual sample in-
cludes two noise terms, while a Bayes update from
a memory sample includes three noise terms. All
noises are drawn independently. The three SD?s,
?
p
, ?
m
and ?
u
, are free parameters in the model,
and we explore their implications below.
The model uses the update specified in the ap-
pendix in Lewis et al. (2013) except for the noise
generation specified above and the consequent
change in the likelihood computation. The lexical
hypotheses are updated as follows:
Pr
new
(S
k
|s
k
, T ) =
Pr(s
k
|S
k
, T )Pr
old
(S
k
, T )
?
S
Pr(s
k
|S
k
, T )Pr
old
(S
k
, T )
(1)
where s
k
is a sample generated as above from the
letterstring (word or nonword) in the current posi-
tion k, S
k
is the hypothesis that the string at posi-
tion k is S, and T is a multinomial distribution re-
flecting the current belief of (a) whether this is an
all-words trial and (b) otherwise, where the non-
word is located. The eye movement planning and
attention shift decisions are conditioned on the dis-
tribution of probabilities Pr(S
k
) for all strings in
the current position. When the maximum of these
probabilities crosses a saccade planning threshold
?
s
, saccade planning begins. When the maximum
crosses the attention shift threshold ?
a
, attention
shifts to the next word
1
. Each sample takes 10ms,
a fixed discretization parameter.
The likelihood of drawing perceptual or mem-
ory sample s for a string S is computed from the
unit-basis word representation as follows:
Pr(s|S) =
?
i
f(s
i
;?
i
, ?) (2)
where i indexes the unit-basis vector representa-
tion of sample s and some true letterstring S (and
so ?
i
is either 0 or 1), ? is the sampling noise
(dependent on whether the samples are memory
or perceptual samples as specified below), and
f(x;?, ?) is the probability density function of the
normal distribution with mean ? and standard de-
viation ?.
We simplify the likelihood computation for
memory samples by treating the perception and
memory samples as independent. For present
purposes this assumption may be treated as a
bound on the architecture. The ? in Equa-
tion 2 is
?
(?
2
p
+ ?
2
u
) for perceptual samples and
?
(?
2
p
+ ?
2
m
+ ?
2
u
) for memory samples. At each
sample the string-level probabilities in each posi-
tion are aggregated to the multinomial trial-level
decision variable T as described above. Given T
the model computes the probability of a word trial
Pr(W) or nonword trial Pr(N ) = 1 ? Pr(W).
When either of these probabilities exceeds the mo-
tor response threshold ?
r
, motor response plan-
ning commences.
1
Because there is a fixed set of memory samples available,
the attention shift decision is not guaranteed to converge, un-
like the saccade threshold. It nearly always converges, but we
use a 30-sample deadline to prevent infinite sequences.
4
0.5 1.5 2.5
?
??
?
?
?
??
?
???
?
?
?
?
??
?
??
???
?
??
?
?
?
?
?
?
?
?
?
???
??
?
?
?
??
?
0
20
40
60
0
20
40
60
0
20
40
60
0.5
1.5
2.5
0.5 1.5 2.5 0.5 1.5 2.5 0.5 1.5 2.5
Update Noise
Sp
illo
ve
r E
ffe
ct
Perceptual Noise
Memory Noise
Figure 3: Spillover effects generated by the top 5% of policies across different settings of memory, per-
ception, and update noise. On each distinct machine defined by a combination of noise settings, policies
(settings of ?
s
, ?
m
, ?
r
) were evaluated by the same task payoff given to human participants in the exper-
iment described in ?3. Boxplots show spillover effects of the top-performing 5% of policies. Spillover
effects are the difference in mean single fixation durations on word
n
when word
n?1
is low frequency
and when word
n?1
is high frequency (low/high determined by median split). The highest noise settings
in the bottom row are not shown because performance was near-chance even for the best policies.
The prior probability of an all-words trial is 0.5,
so the prior probability of a word in each position
k is 1?
0.5
6
. Therefore, we set the prior probabili-
ties of words in each position to corpus frequency
counts (Ku?cera and Francis, 1967), normalized to
sum to this value, 1 ?
0.5
6
. Nonword probabilities
are uniformly distributed over the remainder,
0.5
6
.
Oculomotor and Manual Architecture. The
remainder of the architectural parameters are stage
durations that are simulated as gamma deviates
with means based on previous work or indepen-
dently estimated from data. The key parameters
for present purposes are the 50ms mean eye-brain
lag and 125ms saccade planning time, following
Reichle et al. (2009), and the 40ms mean sac-
cade execution time, based on estimates from our
own human participants. The standard deviation
of each distribution is 0.3 times the mean. We
transform the means and standard deviations into
scale and shape parameters for a Gamma distri-
bution and then draw duration values from these
Gammas independently for every word and trial.
5 A computational rationality analysis
We explore whether spillover effects might be a
signature of computationally rational behavior in
two ways. First, we evaluate a space of policies
(parameterized by ?
s
, ?
m
, ?
r
) against the task pay-
off given to our human participants, and show that
top-performing policies yield frequency spillover
consistent with human data, and poor-performing
policies do not. Second, we extend the model?s
policy space to allow it to prioritize perception
over memory samples when both are available
(eliminating spillover in those policies), and show
that the spillover portions of the policy space per-
form better than non-spillover ones under any im-
posed speed-accuracy tradeoff in plausible noise
settings, and never perform worse.
In computational rationality analyses, we dis-
tinguish between policy parameters, fixed archi-
tecture parameters, and free architecture parame-
ters. Policy parameters are determined by select-
ing those policies that maximize a given task pay-
off, given the hypothesized architectural bounds.
Fixed architecture parameters are based on pre-
vious empirical or theoretical work. Free archi-
tecture parameters can be fit to data or explored
to show the range of predictions with which the
model is compatible. We focus here on the lat-
ter, showing not only that the model is compatible
with human data, but that it is incompatible with
results significantly different from the human data.
Our first evaluation of the model asks the ques-
tion of whether we see spillover effects emerging
in approximately optimal policies under our as-
sumptions about mechanism and task. We eval-
uated our model in the LLDT, under the balanced
payoff presented in Lewis et al. (2013), the same
5
??
?
?
?
?
?
?
?
?2
0
2
4
6
0.5 1.0 1.5 2.0 2.5
Memory Noise
M
ea
n 
Ra
tio
 o
f N
?1
 to
 
 N
 F
re
qu
en
cy
 E
ffe
ct Best 5% of policies
Best 5% of policies with 
 memory threshold = 0
Bottom 50% of policies
Model
?
?
?
masked unmasked
Humans
Figure 4: Normalized spillover effect in model (vs. memory noise) and human participants. We define
normalized spillover as the ratio of the spillover (word
n?1
) frequency effect size to the foveal (word
n
)
frequency effect size; this normalizes against scale differences between high and low noise architectures.
Left: Mean normalized spillover effect at different memory noises for best performing 5% of policies
with and without memory sampling, and worst 50% performing policies. Right: Mean human spillover
effect sizes in masked and unmasked versions of LLDT.
payoff given to our participants in the unpublished
masking experiment described above. We ex-
plored a discretized policy space as follows: we let
?
s
range between 0.199 and 0.999 in steps of 0.05;
?
m
between 0.19999 and 0.99999 in steps of 0.05,
and also include ?
m
= 0 which prevents memory
sampling; and ?
r
between 0.599 and 0.999 in steps
of 0.1. We explored all 1530 permutations.
Figure 3 shows the distribution of spillover ef-
fect sizes in the top 5% of policies (evaluated by
task payoff, not fit to human data), for a range
of noise parameter settings (at higher noise set-
tings, even the best policies are close to chance
performance). The top 5% of policies average 7.78
points per trial across the noise and policy range,
and the bottom 50% average 1.32 points. The fig-
ure shows that top-performing policies show lit-
tle to no spillover when update noise is low, posi-
tive but small spillover effects when update noise
is moderate, and sizable positive spillover effects
when update noise is relatively high. These results
are consistent with spillover as a rational adapta-
tion to belief update noise.
Figure 4 (left panel) shows normalized spillover
effects (the ratio of the word
n?1
frequency effect
to the word
n
frequency effect) for the best poli-
cies, the bottom 50% of policies, and the best
policies constrained with a memory threshold of
zero (?
m
= 0). When ?
m
= 0, the spillover ef-
fect is zero as expected. The top performing poli-
cies in the unconstrained space generate nonzero
spillover effects that are consistent with the human
data, but the poor performing policies do not (Fig-
ure 4, right panel). We know that the top perform-
ing policies exploit memory because they do yield
nonzero spillover effects, and the values of ?
m
are
nonzero for these policies.
Our second evaluation asks whether a model
that is constrained to always give priority to pro-
cessing perceptual samples over memory samples
will perform better than the present model, which
has the flexibility to give priority to memory over
perception. To explore this, we added a single bi-
nary policy parameter, the perceptual priority bit.
If this bit is set, then the model has the choice be-
tween memory sampling from word
n?1
and per-
ceptual sampling from word
n
, it always chooses
the latter. Such an option is not available in the
previous model?there is no setting of the saccade
and memory thresholds that will always use mem-
ory samples when only they are available, but also
never choose to use memory samples when per-
ceptual samples can be used. With the perceptual
priority bit set, the model is capable of exploiting
the least noisy samples available to it, but is inca-
pable of exhibiting spillover effects.
Figure 5 shows speed-accuracy tradeoffs for
the model, with the perceptual-priority bit not set
(spillover-capable) and set (spillover-incapable),
in three representative noise settings. Individual
points are policies and the lines mark the best ac-
curacy available at a particular reaction time for
the two classes of policies; i.e. these lines repre-
sent the best speed-accuracy tradeoff possible for
6
0.5, 0.5, 0.5 0.5, 0.5, 2.5 1.5, 1.5, 1.5
0.5
0.6
0.7
0.8
0.9
1.0
1000 2000 3000 1000 2000 3000 1000 2000 3000
RT
Ac
cu
ra
cy
spillover <= 5ms
spillover > 5ms
Spillover?capable
spillover?incapable
Figure 5: Speed-accuracy tradeoff curves for some representative noise settings. Each individual point
corresponds to one policy (i.e. setting of the three decision thresholds). Plotted are mean trial RT and
accuracy (computed from 5000 simulated trials), color-coded by whether the policies yielded spillover
frequency effects. Lines mark the best speed-accuracy tradeoff available to spillover-capable and inca-
pable policies. Each plot is labeled at the top with the noise setting (perceptual, memory, update).
both spillover-capable and -incapable policies. In
the left plot of the figure, noise is low enough over-
all such that responses are very fast and spillover-
capable policies do no worse and no better than
spillover-incapable policies. In the middle plot,
update noise is higher, and the optimal speed-
accuracy tradeoff is better for the model that can
yield spillover, consistent with the exploitation of
memory sampling to mitigate update noise. In the
right plot, perception and memory noise are high
enough that it is not useful to sample from mem-
ory at the expense of perception. All the noise
settings we explored (see Figure 3 for the range)
yield one of these three patterns, or the uninter-
esting case of near-chance performance. In no
setting does the spillover-capable model perform
worse than the spillover-incapable one. The noise
settings cover a range from implausibly-high ac-
curacy to chance performance, and so we con-
clude that spillover-capable policies dominate, in
that they do no worse, and occasionally do better,
than those constrained to give priority to percep-
tion over memory.
6 Why spillover arises from sequenced
thresholded samplers
We have demonstrated through simulations that
the model yields frequency spillover through a
composed sequence of perception and memory
sampling. We have not yet addressed the ques-
tion of how or why this happens. Indeed, it is ini-
tially somewhat puzzling that an effect of priors
(set by lexical frequency) would persist after the
initial perceptual sampling threshold ?
p
is passed,
because this fixed threshold must be exceeded no
matter the starting prior.
The crucial insight is that it is not always the
case that the true word hypothesis reaches the
threshold first; i.e., the decision to initiate saccade
planning may be based on (partial) recognition of
a different word than the true word. In such cases,
at the start of memory sampling, the hypothesis for
the true word is farther from the memory threshold
?
m
than if the true word had been (partially) recog-
nized. Incorrect decisions are more likely for low
frequency words, so in expectation the memory-
driven attention shift mechanism will start farther
from its threshold for low-frequency words, and
therefore take longer to reach threshold, delaying
the following word more.
We constructed a minimal two-sampler exam-
ple to clearly illustrate this phenomenon. The left-
most panel of Figure 6 illustrates the dynamics of
such a trial. In this panel, the threshold is crossed
for the incorrect hypothesis (green line) in the first
sampler, triggering the start of the second sampler.
The second sampler recovers from the mistake, al-
lowing the correct (red) hypothesis to cross the
threshold, but at the cost of additional time. The
middle panel shows that incorrect (and thus eligi-
ble for recovery) trials are more frequent for low
priors. The rightmost panel shows that the finish-
ing time of the second sampler is proportional to
the prior probability of the correct hypothesis for
the first sampler. It is also inversely proportional
to accuracy (middle plot), consistent with inaccu-
rate trials driving the relationship between the first
sampler prior and second sampler finishing times.
7
0 50 100 150 2000
.0
0.2
0.4
0.6
0.8
1.0
sample
pro
bab
ility
Sampler 1 Sampler 2 ll
l
l
l
l
lllllll
l
l
l
l
l
l
l
l
l
l
llllll
lllllllllllll
l
l
l
l
l
l
l
l
l
llllllllllll
l
l
l
l
0.00
0.25
0.50
0.75
1.00
1e?05 1e?04 1e?03 1e?02 1e?01Starting prior of correct
 hypothesis (Sampler 1)
Acc
ura
cy
(Sam
pler 
1)
Number of Hypotheses
l
l
l
l
2
5
100
1000
ll
l
l
l
l
lllll
ll
l
l
l
l
l
l
l
l
l
llllll
l
lllll
llllll
ll
ll
l
l
l
l
l
l
l
l
ll
ll
lllll
llllllll
ll
l
l
l
l
0
25
50
75
1e?05 1e?04 1e?03 1e?02 1e?01Starting prior of correct
 hypothesis (Sampler 1)
Num
. sa
mp
les 
to t
hre
sho
ld
(Sam
pler 
2, co
rrec
t cas
es)
Number of Hypotheses
l
l
l
l
2
5
100
1000
Figure 6: A simple example illustrating how the prior for a thresholded sampler affects its final posterior,
and therefore the prior for a subsequent coupled sampler, despite the fixed threshold. Left: An example
?recovery? trial for 500 hypotheses (words). Middle: Accuracy for the first sampler as a function of the
prior of the true hypothesis. Right: Second sampler finishing times as a function of to the true-hypothesis
prior in the first sampler.
7 Discussion and Conclusion
We briefly highlight the key properties of the
model that yield our result and how they may gen-
eralize beyond our particular implementation.
Post-perceptual processing. Although we
adopted a second MSPRT sampler, spillover may
arise from other processes with access to the pos-
terior of the perceptual sampling, such that it can
recover from perceptually misidentified words. In
the present model we investigated the possibil-
ity that post-perceptual memory-based processing
could be partially motivated by mitigating noise
in the update process itself. But it is almost cer-
tainly the case that post-perceptual processing is
required in the course of reading for indepen-
dent reasons, and such processing could also yield
spillover frequency effects in a way that the mem-
ory sampling process does. (A challenge for such
an alternate process is that spillover effects per-
sist in the LLDT in the absence of required higher
level syntactic or semantic processing).
A tradeoff between processing perception and
memory. The serial queuing model is a simple re-
alization (inspired by EZ-Reader (Reichle et al.,
1998)) of a limited resource that can be allocated
to perceptual and memory processing, but an alter-
native parallel attention machine might recover the
results, as long as it suffers from the same tradeoff
that processing the previous word from memory
will slow down processing of the fixated word.
Direct oculomotor control. In the present model
saccade planning is triggered directly by the per-
ceptual evidence accumulation process, and as
such is not obviously compatible with autonomous
saccade generation models like SWIFT (Engbert
et al., 2005). It may be possible to layer SWIFT?s
time-delayed foveal inhibition over a sequential
sampling process, but we note that spillover ef-
fects were part of the empirical motivation for
such delayed control.
The present model and results open several av-
enues for future work. These include the interac-
tions of memory-based or post-perceptual process-
ing with models of saccade planning that include
saccade targeting, re-targeting, and cancellation,
as well as buttonpress behavior (e.g. in the self-
paced moving window paradigm). The role that
parafoveal preview plays in spillover effects can
also be explored, including how the model (and
thus human participants) might navigate the trade-
off between using parafoveal preview information
(noisy due to eccentricity) and using memory of
past input in the service of a reading task. Fi-
nally, it is possible to explore the spillover expla-
nation in an architecture capable of higher-level
sentence processing in service of different reading
task goals.
Acknowledgments
This material is based upon work supported by the
National Science Foundation under Grant BCS-
1152819 to RL and SB. We thank MindMod-
eling@Home for invaluable computational re-
sources.
8
References
C.W. Baum and V.V. Veeravalli. 1994. A sequential
procedure for multihypothesis testing. IEEE Trans-
actions on Information Theory, 40(6):1994?2007.
Vladimir P Dragalin, Alexander G Tartakovsky, Venu-
gopal V Veeravalli, and Senior Member. 2000. Mul-
tihypothesis Sequential Probability Ratio Tests Part
II : Accurate Asymptotic Expansions for the Ex-
pected Sample Size. IEEE Transactions on Infor-
mation Theory, 46(4):1366?1383.
Ralf Engbert, Antje Nuthmann, Eike M. Richter, and
Reinhold Kliegl. 2005. SWIFT: a dynamical model
of saccade generation during reading. Psychological
review, 112(4):777?813, October.
John M. Henderson and Fernanda Ferreira. 1990.
Effects of foveal processing difficulty on the per-
ceptual span in reading: Implications for attention
and eye movement control. Journal of Experimen-
tal Psychology: Learning, Memory, and Cognition,
16(3):417?429.
Sheila M. Kennison and Charles Clifton. 1995. De-
terminants of parafoveal preview benefit in high and
low working memory capacity readers: implications
for eye movement control. Journal of experimen-
tal psychology. Learning, memory, and cognition,
21(1):68?81, January.
Henry Ku?cera and W. Nelson Francis. 1967. Compu-
tational analysis of present-day American English.
Brown University Press, Providence, RI.
Richard L. Lewis, Michael Shvartsman, and Satinder
Singh. 2013. The Adaptive Nature of Eye Move-
ments in Linguistic Tasks: How Payoff and Archi-
tecture Shape Speed-Accuracy Trade-Offs. Topics
in cognitive science, pages 1?30, June.
Richard L. Lewis, Andrew Howes, and Satinder Singh.
to appear. Computational rationality: Linking
mechanism and behavior through utility maximiza-
tion. Topics in Cognitive Science.
David E. Meyer and Roger Schvaneveldt. 1971. Fa-
cilitation in recognizing pairs of words: Evidence of
a dependence between retrieval operations. Journal
of Experimental Psychology, 90:22?34.
Dennis Norris. 2006. The Bayesian reader: explain-
ing word recognition as an optimal Bayesian de-
cision process. Psychological review, 113(2):327?
357, April.
Keith Rayner and Martin H. Fischer. 1996. Mind-
less reading revisited: eye movements during read-
ing and scanning are different. Perception & psy-
chophysics, 58(5):734?47, July.
Keith Rayner, Arnold D. Well, and Alexander Pollat-
sek. 1980. Asymmetry of the effective visual field
in reading. Perception & psychophysics, 27(6):537?
44, June.
Keith Rayner. 1975. The perceptual span and periph-
eral cues in reading. Cognitive Psychology, 7(1):65?
81, January.
E D Reichle, a Pollatsek, D L Fisher, and K Rayner.
1998. Toward a model of eye movement control in
reading. Psychological review, 105(1):125?57, Jan-
uary.
Erik D. Reichle, Tessa Warren, and Kerry McConnell.
2009. Using E-Z Reader to model the effects of
higher level language processing on eye movements
during reading. Psychonomic bulletin & review,
16(1):1?21, February.
Walter Schroyens, Franc?oise Vitu, Marc Brysbaert, and
G?ery D?Ydewalle. 1999. Eye movement control
during reading: foveal load and parafoveal process-
ing. The Quarterly journal of experimental psychol-
ogy, 52(4):1021?46, November.
Sarah J. White, Keith Rayner, and Simon P. Liv-
ersedge. 2005. Eye movements and the modulation
of parafoveal processing by foveal processing dif-
ficulty: A reexamination. Psychonomic bulletin &
review, 12(5):891?6, October.
Christiane Wotschack. 2009. Eye Movements in Read-
ing Strategies. Ph.D. thesis.
9
