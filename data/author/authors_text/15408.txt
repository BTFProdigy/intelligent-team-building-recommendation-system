Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: System Demonstrations,
pages 124?128, Dublin, Ireland, August 23-29 2014.
OpenSoNaR: user-driven development of the SoNaR corpus interfaces
Martin Reynaert
TiCC / Tilburg University
CLST / Radboud
Universiteit Nijmegen
reynaert@uvt.nl
Matje van de Camp
De Taalmonsters
matje@taalmonsters.nl
Menno van Zaanen
TiCC / Tilburg University
mvzaanen@uvt.nl
Abstract
OpenSoNaR is an online system that allows for analyzing and searching the large scale Dutch
reference corpus SoNaR. Due to the size of the corpus, accessing the information contained in
the dataset has proven to be difficult for less technically inclined researchers. The OpenSoNaR
project aims to facilitate the use of the SoNaR corpus by providing a user-friendly online inter-
face. To make sure that the resulting system is practically useful, several user groups have been
identified, who drive the interface development process by providing practical use cases. The
current system is already used in educational and research settings.
1 Introduction
Concerted efforts over the past years
1
in the Dutch language area in Europe, the Netherlands and the
northern half of Belgium, Flanders, have yielded a corpus of over 500 million words of richly linguis-
tically annotated contemporary written Dutch, called SoNaR (Oostdijk et al., 2013). After the SoNaR
project finished, it became clear that the corpus is difficult to handle for most potential users because
of its size and technical formats. The OpenSoNaR project
2
aims to resolve the practical problems of
dealing with the SoNaR dataset. On the basis of an available corpus back-end system, BlackLab, that
allows for searching through all the information contained in the SoNaR dataset, user interfaces, called
WhiteLab, are developed that allow for user-desired types of corpus searches and investigations. We will
first briefly describe the SoNaR dataset. Next, we discuss the OpenSoNaR project, treating the ideas
behind the project as well as the description of the system, focusing mainly on WhiteLab.
2 SoNaR
The SoNaR project developed a large scale reference corpus for contemporary, written Dutch. This
balanced corpus consists of about 540 million tokens of Dutch across a wide range of text types, such
as books, magazine articles, reports, subtitles, but also data from the ?new? media, such as chat texts,
SMS and tweets. A unique aspect of this corpus is that for all texts, IPR regulations are explicitly
known, in most cases settled by contract with the copyright holders. All texts are linguistically annotated
on several layers. Documents, paragraphs, sentences and tokens are uniquely identified and lemmata,
part-of-speech (POS), named entity information and morphological analyses have been automatically
annotated in the data. All information, from tokenization, linguistic annotation to metadata, is marked in
XML structures. The Folia XML format (van Gompel and Reynaert, 2013) is used to hold all the textual
information and linguistic annotations. Metadata, which includes, for example, origin, author, text genre
(as far as known), is stored in a separate document that is linked to the text document. Metadata is stored
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are
added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/
1
Funded in large part by the Dutch Language Union in the STEVIN programme described in the Open Access book
?Essential Speech and Language Technology for Dutch? http://www.springer.com/education+%26+language/
linguistics/book/978-3-642-30909-0
2
Homepage: http://opensonar.uvt.nl
124
in CMDI files (Broeder et al., 2011). The metadata files duplicate the number of documents in the corpus.
SoNaR consists of approximately 2.4 million files.
3 OpenSoNaR
The aim of the OpenSoNaR project is to develop and implement a practically useful system that allows
easy access to the SoNaR corpus. The project has been set up to make sure that the functionality of the
system serves a wide range of users. As is implied by the name of the project, our wish is to make the
system we build as open as possible to all users. We will provide a fully open online service to all, from
schoolchildren onwards, based on the IPR-settlements negotiated during the SoNaR corpus building
project. The SoNaR corpus has subsections which were obtained on the basis of Creative Common
licenses, e.g. Wikipedia, which will be open. The system will further under CLARIN login be fully open
and free to all non-commercial researchers. Restrictions on commercial research and/or use apply to
some important subsections, e.g. the newspapers and periodicals incorporated in the corpus. For these,
interested commercial parties need to negotiate access separately with the copyright owners.
3.1 Project
Technical issues stand in the way of most potential users actively conducting research on the SoNaR cor-
pus. The OpenSoNaR project is to resolve these. The SoNaR-500 corpus
3
requires information retrieval
tools for efficient searching, as trivial solutions are simply too slow or cumbersome to use. The XML
format requires the search system to know about the XML structure that describes the linguistic infor-
mation in somewhat more complex searches, for example, using a combination of token and linguistic
information. Metadata selections are required just as well.
The aim of the OpenSoNaR system is to solve all these practical problems. Two components are
developed: BlackLab that enables searching in the data, and WhiteLab providing the user-interface. In
order to provide the most useful search interface, four main user groups have been identified. These con-
sist of researchers in the areas of (corpus and cognitive) linguistics, communication and media studies,
literary sciences, and cultural sciences. Each of these groups are asked to provide typical use cases, i.e.
search operations that they would like to be able to ask the SoNaR corpus. To test practical usability,
the system is also incorporated in education. Currently, OpenSoNaR has been successfully tested by
students in courses on linguistics and research methodology. The results of these test provide feedback
on what further developments the interfaces require to be practically of best possible use to all.
3.2 Related work
Throughout Europe, most national corpora available online are based on BlackLab?s predecessor and
source of inspiration, the notable Corpus Workbench system
4
(Christ, 1994). In the Netherlands, there
is another concurrent project in which a corpus exploration and exploitation environment is being de-
veloped. This is the much larger and far more ambitious project Nederlab
5
. Nederlab aims to create a
research portal to all digital corpora available for Dutch from its earliest days. There is cross-fertilization
between both projects.
3.3 System
The OpenSoNaR system consists of two components that interact with each other. The BlackLab com-
ponent is the back-end of the system and provides the actual search functionality. On top of BlackLab,
the WhiteLab component provides the front-end, user interface.
3
Available free for research from the Dutch HLT Agency TST-Centrale http://tst-centrale.org/nl/
producten/corpora/sonar-corpus/6-85. The documentation link on the page offers access to the user manual.
4
Homepage: http://cwb.sourceforge.net/
5
http://www.nederlab.nl/docs/Nederlab_NWO_Groot_English_aanvraagformulier.pdf
125
3.3.1 BlackLab
As explained on its official GitHub site
6
, BlackLab is a Java-based corpus retrieval engine built on top
of Apache Lucene. It allows fast, complex searches with accurate hit highlighting on large, annotated,
bodies of text, in our case text in FoLiA XML. This back-end system is further being developed at the
Dutch Institute for Lexicology (INL) by Jan Niestadt. OpenSoNaR had a head start in its further interface
development efforts in that BlackLab comes equipped with a fine basic user interface as is evidenced by
the online INL corpora ?Letters as Loot?
7
and the corpus of Medieval Dutch ?Corpus Gysseling?
8
.
3.3.2 WhiteLab
The Whitelab user interface
9
is currently available in two languages, Dutch and English. We hope to
be able to extend the languages available. The Whitelab user by default lands on the Search page of
OpenSoNaR when logging in. Next to this page we have the Explore page and the Home page.
Home The Home page provides information about the system. It provides a first-user manual which
gives an overview of the main possibilities OpenSoNaR offers. It also provides the actual user manual of
the SoNaR corpus which offers in-depth information on the composition of this corpus of contemporary
written Dutch. Next, short films are available that provide tutorials of how to use the system.
Explore The Explore page gives statistical information about the corpus contents, providing insight
into the distribution of the texts available per genre and according to their provenance, basically whether
they were collected in the Netherlands or in Flanders. A third category contains texts with uncertain
provenance, e.g. the texts from various European Union organizations or from Wikipedia. This page also
affords access to n-gram (where n is 1 to 5) frequency lists derived from the whole corpus and its genre
subsections for word forms, lemmata and the combination of lemmata with POS-tags.
Search The Search environment is the most elaborate. It provides four levels of access to the contents:
Simple, Extended, Advanced and Expert.
The Simple search option provides Google-style, single query box access. Entering a search term
here will instantiate a search over the full contents of the corpus. The search is for word forms, which
may be phrases (n-grams), in which case exact matches are sought, i.e. respecting the actual sequence of
words. This functionality is also provided by the next two search environments.
The Extended search environment allows one to impose selection filters on the search effected. These
filters are of two kinds. First, there are filters on the metadata. Second, there are filters on the lexical
level, allowing one to search for either word forms, lemmata or by POS-tags.
The metadata filters are at first hidden behind a bar visible above the actual lexical query fields. When
the user wants to impose metadata filters the bar is expanded by a simple mouse click and the user is
presented with a row consisting of three drop-down boxes. The middle box has just two options: ?is? or
?is not?. The left box gives access to all the metadata fields available in the corpus CMDI metadata files.
The right box, upon selection of a particular metadata field in the left box, dynamically expands with the
list of available metadata contents, where applicable. Metadata filters can be stacked. Through a ?plus?
button to the right of the query row, one may obtain further rows in each of which further restrictions
on the query may be imposed. The metadata selection interface further provides the option of grouping
the query results obtained by a range of features. E.g, if one here selects the option of having the results
presented by country of origin of the hit texts, one is not presented directly with the KWIC list of results,
but rather with a bar representation of the number of hits per country. One may then click on one of these
bars and be presented with the KWIC list. Alternatively, having made a selection of texts, one may opt
to be presented with a word cloud of its most salient terms, for exploratory purposes.
The lexical filters allow one to perform optionally case-sensitive searches for either word forms, for
lemmata and for POS-tags. When the search is for lemmata, all the word forms sharing the same lemma
6
https://github.com/INL/BlackLab
7
URL: http://brievenalsbuit.inl.nl/zeebrieven/page/search
8
http://gysseling.corpus.taalbanknederlands.inl.nl/gysseling/page/search
9
We provide screenshots of the interfaces at http://opensonar.uvt.nl
126
will be retrieved. For POS-tag searches the user is presented with a drop-down list which presents a
layman?s translation in plain language for the actual POS-tags involved. Combinations of, for instance,
word forms and POS searches are possible to direct the search for the word ?drink? (ibidem in English)
towards the first person singular of the present tense verb form, rather than its use as a noun.
For the Advanced search option we fully acknowledge to emulate the elegant interface to CQL-
query building as provided by the Swedish Spr?akbanken
10
. Users are first presented with a single box
containing three query fields. By horizontally or vertically adding further boxes as in Figure 1 they may
build quite complex queries without the need to know the query language behind them. Users get to see
the query they have built and have the option of further extending it, manually. Results are subsequently
presented graphically, cf. Figure 2.
Figure 1: An advanced CQL-query having been built with Advanced Search query boxes
The Expert search requires knowledge of the query language incorporated in the system. It is CQL,
the Corpus Query Language
11
. In its essence, this search option?s limitations are defined mainly by the
user?s CQL proficiency.
Regardless of the search option one has chosen, by default, eventually a KWIC list of results is pre-
sented. One may then choose to ?Toggle titles? and by clicking on a title, move to full text view. There,
moving the cursor over any of the words in the text, one gets to see a small window with the word form?s
unique ID, lemma and POS-tag.
A feature of the Extended and Advanced search options we have not seen in other corpus exploration
environments is that multiple queries can be performed in one operation. This is facilitated by the fact
that by clicking on the ?list? button to the right of the query boxes the user may effortlessly upload a pre-
prepared list of query terms. After uploading, these query terms are converted by the system into actual,
separate CQL queries which are accessible via a drop-down list above the query boxes. The user then has
the option of having the output presented separately, per query, or mixed. As soon as the queries have
run, the user has the further option of downloading the results. If in the Advanced search environment a
user uploads more than one query list, the system makes a combination of all the query terms in the lists.
Given x terms in list A and y terms in list B, this results in x times y queries. If this is not what the user
intended, then he has the option of uploading a list of, for instance, word bigrams to be searched for in
10
See ?Korp? at http://spraakbanken.gu.se/eng/start
11
A nice tutorial is at: http://cwb.sourceforge.net/files/CQP_Tutorial/
127
Figure 2: Grouped results of the advanced CQL-query having been built with Advanced Search query
boxes. After grouping, results are first presented graphically after which the user may further explore the
text snippets retrieved.
the Extended search environment.
The query results are in a tab-separated format suitable for loading in a spreadsheet. The format should
be easily convertible to the specific formats required by statistical packages such as R or SPSS.
4 Conclusion
In this OpenSoNaR system demonstration paper we have given an overview of ongoing work in the
Netherlands to provide to all online access to the new richly annotated reference corpus for contemporary
written Dutch called SoNaR.
Acknowledgements
The authors, TiCC senior scientific programmer Ko van der Sloot as Software Quality Control Offi-
cer, and Max Louwerse as Project Coordinator gratefully acknowledge support from CLARIN-NL in
project OpenSoNaR (CLARIN-NL-12-013). The first author further acknowledges support from NWO
in project Nederlab. We would like to specifically thank our colleagues at INL: Katrien Depuydt, Jesse
de Does and Jan Niestadt.
References
Daan Broeder, Oliver Schonefeld, Thorsten Trippel, Dieter Van Uytvanck, and Andreas Witt. 2011. A pragmatic
approach to XML interoperability ? the Component Metadata Infrastructure (CMDI). In Balisage: The Markup
Conference 2011, volume 7.
Oliver Christ. 1994. A Modular and Flexible Architecture for an Integrated Corpus Query System.
Nelleke Oostdijk, Martin Reynaert, V?eronique Hoste, and Ineke Schuurman. 2013. The construction of a 500-
million-word reference corpus of contemporary written Dutch. In Essential Speech and Language Technology
for Dutch: Results by the STEVIN-programme, chapter 13. Springer Verlag.
Maarten van Gompel and Martin Reynaert. 2013. FoLiA: A practical XML Format for Linguistic Annotation - a
descriptive and comparative study. Computational Linguistics in the Netherlands Journal, 3.
128
Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, ACL-HLT 2011, pages 61?69,
24 June, 2011, Portland, Oregon, USA c?2011 Association for Computational Linguistics
A Link to the Past: Constructing Historical Social Networks
Matje van de Camp
Tilburg Centre for Cognition
and Communication
Tilburg University, The Netherlands
M.M.v.d.Camp@uvt.nl
Antal van den Bosch
Tilburg Centre for Cognition
and Communication
Tilburg University, The Netherlands
Antal.vdnBosch@uvt.nl
Abstract
To assist in the research of social networks in
history, we develop machine-learning-based
tools for the identification and classification
of personal relationships. Our case study fo-
cuses on the Dutch social movement between
1870 and 1940, and is based on biographical
texts describing the lives of notable people in
this movement. We treat the identification and
the labeling of relations between two persons
into positive, neutral, and negative both as a
sequence of two tasks and as a single task. We
observe that our machine-learning classifiers,
support vector machines, produce better gen-
eralization performance on the single task. We
show how a complete social network can be
built from these classifications, and provide a
qualitative analysis of the induced network us-
ing expert judgements on samples of the net-
work.
1 Introduction
The rapid growth of Social Networking Services
such as Facebook, Myspace and Twitter over the
last few years has made it possible to gather data on
human interactions on a large scale, causing an in-
creased interest in the field of Social Network Anal-
ysis and Extraction. Although we are now more in-
terconnected than ever before due to technological
advances, social networks have always been a vital
part of human existence. They are prerequisite to the
distribution of knowledge and beliefs among people
and to the formation of larger entities such as orga-
nizations and communities. By applying the tech-
nology of today to the heritage of our past, it may be
possible to uncover yet unknown patterns and pro-
vide a better insight into our society?s development.
In this paper we present a case study based on
historical biographical information, so-called sec-
ondary historical sources, describing people in a
particular domain, region and time frame: the
Dutch social movement between the mid-19th and
mid-20th century. ?Social movement? refers to
the social-political-economical complex of ideolo-
gies, worker?s unions, political organizations, and
art movements that arose from the ideas of Karl
Marx (1818?1883) and followers. In the Nether-
lands, a network of persons unfolded over time with
leader figures such as Ferdinand Domela Nieuwen-
huis (1846?1919) and Pieter Jelles Troelstra (1860?
1930). Although this network is implicit in all
the primary and secondary historical writings doc-
umenting the period, and partly explicit in the minds
of experts studying the domain, there is no explic-
itly modeled social network of this group of persons.
Yet, it would potentially benefit further research in
social history to have this in the form of a computa-
tional model.
In our study we focus on detecting and labeling
relations between two persons, where one of the per-
sons, A, is the topic of a biographical article, and
the other person, B, is mentioned in that article. The
genre of biographical articles allows us to assume
that person A is topical throughout the text. What
remains is to determine whether the mention of per-
son B signifies a relation between A and B, and if so,
whether the relation in the direction of A to B can be
labeled as positive, neutral, or negative. Many more
fine-grained labels are possible (as discussed later in
61
the paper), but the primary aim of our case study is
to build a basic network out of robustly recognized
person-to-person relations at the highest possible ac-
curacy. As our data only consists of several hun-
dreds of articles describing an amount of people of
roughly the same order of magnitude, we are facing
data sparsity, and thus are limited in the granularity
of the labels we wish to predict.
This paper is structured as follows. After a brief
survey of related research in Section 2, we describe
our method of research, our data, and our annota-
tion scheme in Section 3. In Section 4 we describe
how we implement relation detection and classifica-
tion as supervised machine learning tasks. The out-
comes of the experiments on our data are provided in
Section 5. We discuss our findings, formulate con-
clusions, and identify points for future research in
Section 6.
2 Related Research
Our research combines Social Network Extraction
and Sentiment Analysis. We briefly review related
research in both areas.
2.1 Social Network Extraction
A widely used method for determining the related-
ness of two entities was first introduced by Kautz et
al (1997). They compute the relatedness between
two entities by normalizing their co-occurrence
count on the Web with their individual hit counts us-
ing the Jaccard coefficient. If the coefficient reaches
a certain threshold, the entities are considered to be
related. For disambiguation purposes, keywords are
added to the queries when obtaining the hit counts.
Matsuo et al(2004) apply the same method to find
connections between members of a closed commu-
nity of researchers. They gather person names from
conference attendance lists to create the nodes of the
network. The affiliations of each person are added
to the queries as a crude form of named entity dis-
ambiguation. When a connection is found, the re-
lation is labeled by applying minimal rules, based
on the occurrence of manually selected keywords,
to the contents of websites where both entities are
mentioned.
A more elaborate approach to network min-
ing is taken by Mika (2005) in his presentation
of the Flink system. In addition to Web co-
occurrence counts of person names, the system uses
data mined from other?highly structured?sources
such as email headers, publication archives and so-
called Friend-Of-A-Friend (FOAF) profiles. Co-
occurrence counts of a name and different interests
taken from a predefined set are used to determine a
person?s expertise and to enrich their profile. These
profiles are then used to resolve named entity co-
reference and to find new connections.
Elson et al(2010) use quoted speech attribution to
reconstruct the social networks of the characters in
a novel. Though this work is most related regarding
the type of data used, their method can be consid-
ered complementary to ours: where they relate enti-
ties based on their conversational interaction without
further analysis of the content, we try to find connec-
tions based solely on the words that occur in the text.
Efforts in more general relation extraction from
text have focused on finding recurring patterns and
transforming them into triples (RDF). Relation types
and labels are then deduced from the most common
patterns (Ravichandran and Hovy, 2002; Culotta et
al, 2006). These approaches work well for the in-
duction and verification of straightforwardly verbal-
ized factoids, but they are too restricted to capture
the multitude of aspects that surround human inter-
action; a case in point is the kind of relationship be-
tween two persons, which people can usually infer
from the text, but is rarely explicitly described in a
single triple.
2.2 Sentiment Analysis
Sentiment analysis is concerned with locating and
classifying the subjective information contained in a
source. Subjectivity is inherently dependent on hu-
man interpretation and emotion. A machine can be
taught to mimic these aspects, given enough exam-
ples, but the interaction of the two is what makes
humans able to understand, for instance, that a sar-
castic comment is not meant to be taken literally.
Although the general distinction between negative
and positive is intuitive for humans to make, sub-
jectivity and sentiment are very much domain and
context dependent. Depending on the domain and
context, a single sentence can have opposite mean-
ings (Pang and Lee, 2008).
Many of the approaches to automatically solv-
62
ing tasks like these involve using lists of positively
and negatively polarized words or phrases to calcu-
late the overall sentiment of a clause, sentence or
document (Pang et al 2002). As shown by Kim
and Hovy (2006), the order of the words poten-
tially influences the interpretation of a text. Pang
et al(2002) also found that the simple presence of a
word is more important than the number of times it
appears.
Word sense disambiguation can be a useful tool in
determining polarity. Turney (2002) proposed a sim-
ple, but seemingly effective way to determine polar-
ity at the word level. He calculates the difference
between the mutual information gain of a phrase and
the word ?excellent? and of the same phrase and the
word ?poor?.
3 Method, Data, and Annotation
3.1 Method
In contrast to most previous work regarding social
network extraction, we do not possess any explicit
record of the network we are after. Although the
documents we work with are available online, the
number of hyperlinks between them is minimal and
all personal relations are expressed only in running
text. We aim to train a system able to extract these
relations and classify their polarity automatically us-
ing as little information as possible that is not explic-
itly included in the text, thus keeping the reliance on
external resources as limited as possible.
We take the same approach with regards to the
sentiment analysis part of the task: no predefined
lists are supplied to the system and no word sense
disambiguation is performed.
We take a supervised machine learning approach
to solving the problem, by training support vector
machines on a limited number of preclassified exam-
ples. We chose to use SVMs as a baseline method
that has been shown to be effective in text catego-
rization tasks (Joachims, 1998). We compare perfor-
mance between joint learning, using one multi-class
classifier, and a pipeline, using a single class clas-
sifier to judge whether an instance describes a rela-
tion, and a second classifier to classify the relations
according to their polarity.
3.2 Data
We use the Biographical Dictionary of Socialism
and the Workers? Movement in the Netherlands
(BWSA) as input for our system.1 This digital
resource consists of 574 biographical articles, in
Dutch, relating to the most notable actors within the
domain. The texts are accompanied by a database
that holds such metadata as a person?s full name
and known aliases, dates of birth and death, and a
short description of the role they played within the
Workers? Movement. The articles were written by
over 200 different authors, thus the use of vocabu-
lary varies greatly across the texts. The length of the
biographies also varies: the shortest text has 308 to-
kens, the longest has 7,188 tokens. The mean length
is 1,546 tokens with a standard deviation of 784.
A biography can be seen as a summary of the most
important events in a person?s life. Therefore, this
type of data suits our purpose well: any person that
the main character was closely related to, can be ex-
pected to appear in his or her biography.
In training our relation extraction system we look
only at the relation from A to B and its associated
polarity. The assumption that we make here is that
by processing the BWSA in its entirety, making each
of the 574 main characters person A once and har-
vesting all of their relations, we will get a full view
of the existing relations, including the relation from
B to A if A and B have a relation and B also has a
biography in the BWSA.
We create one data set focused on a particular per-
son who is prevalent throughout the data, namely
Ferdinand Domela Nieuwenhuis (FDN). He started
his career as a Lutheran priest, but lost his faith and
pursued a career in socialist politics. After a series
of disappointments, however, he turned to anarchism
and eventually withdrew himself from the political
stage completely, though his ideas continued to in-
spire others. We expect that the turmoil of his life
will be reflected in his social network and the vari-
ety of relationships surrounding him.
As a first step in recreating Domela Nieuwenhuis?
network, we extract all sentences from the BWSA
that mention the name ?Domela?, by which he is
generally known. We exclude Domela?s own bi-
ography from the search. All but one of the ex-
1http://www.iisg.nl/bwsa/
63
tracted sentences, 447 in total, actually refer to Fer-
dinand Domela Nieuwenhuis. This sentence is re-
moved, resulting in a total of 446 sentences spread
over 153 biographies. Each sentence with a men-
tion is expanded with additional context, to capture
more clues than the sentence with the mention might
hold. Preliminary tests showed that two sentences
of context before the mention, and two sentences of
context after the mention is sufficient. Often there
is an introduction before a person is mentioned, and
an elaboration on the relation after the mention. Fig-
ure 1 shows an example fragment.
However, since Domela was a rather controver-
sial and a-typical figure, his network might not be
a good representation of the actual relations in the
data. Therefore, we create a second data set by ran-
domly extracting another 534 sentences with their
surrounding context from the BWSA that contain a
named entity which is not the main entity of the bi-
ography. We aim to test which data set leads to bet-
ter performance in finding and classifying relations
across the entire community.
3.3 Annotation
All fragments in the Domela set were annotated by
two human annotators, native speakers of Dutch, but
unfamiliar with the domain of social history. They
were asked to judge whether the fragment does in
fact describe a relation between the two entities and,
if so, whether the polarity of the relation from A to B
is negative, neutral, or positive; i.e. whether person
A has a negative, neutral or positive attitude towards
person B.
With regards to the existence of a relation, the an-
notators reached an agreement of 74.9%. For the
negative, neutral and positive classes they agreed on
60.8%, 24.2%, and 66.5%, respectively. All dis-
agreements were resolved in discussion. The class
distribution over the three polarities after resolution
is shown in Table 1.
The generic set was annotated by only one of the
annotators. The class distribution of this set is also
shown in Table 1. It is roughly the same as the dis-
tribution for the A to B polarities from the Domela
set.
Class Generic set FDN set
No. % No. %
negative 86 16.1 74 16.6
neutral 134 25.1 87 19.5
positive 238 44.6 215 48.2
not related 76 14.2 70 15.7
total 534 100 446 100
Table 1: Class distribution
4 Relation Extraction and Classification
We train our system using LibSVM (Chang and
Lin, 2001), an implementation of support vector ma-
chines. In training, the cost factor is set to 0.01 with
a polynomial kernel type.
4.1 Preprocessing
First, all fragments and biographies are lemmatized
and POS-tagged using Frog, a morpho-syntactic
analyzer for Dutch (Van den Bosch et al 2007).
In a next step, Named Entity Recognition is per-
formed with a classifier-based sequence processing
tool trained on biographical data.
To identify the person to which a named entity
refers, the name is split up into chunks representing
first name, initials, infix and surname. These chunks,
as far as they are included in the string, are then
matched against the BWSA database. If no match
is found, the name is added to the database as a new
person. For now, however, we treat the network as
a closed community by only extracting those frag-
ments in which person B is one that already has a bi-
ography in the BWSA. At a later stage, biographies
of people from outside the BWSA can be gathered
and used to determine their position within the net-
work.
4.2 Features
Co-occurrence counts: We calculate an initial mea-
sure of the relatedness of A to B using a method that
is similar to Kautz et al(1997). The main difference
is that we do not get our co-occurrence counts only
from the Web, but also from the data itself. Since the
domain of the data is so specific, Web counts do not
accurately represent the actual distribution of people
in the data. More famous people are likely to receive
more attention on the Web than less famous people.
64
AnsingPER?A and Domela NieuwenhuisPER?B were in written contact with each other since August 1878.
Domela Nieuwenhuis probably wrote uplifting words in his letter to Ansing, which was not preserved, after
reading Pekelharing?s report of the program convention of the ANWV in Vragen des Tijds, which was all
but flattering for Ansing.
In this letter, Domela also offered his services to Ansing and his friends.
Domela Nieuwenhuis used this opportunity to ask Ansing several questions about the conditions of the
workers, the same that he had already asked in a letter to the ANWV in 1877, which had been left unan-
swered.
Ansing answered the questions extensively.
Figure 1: English translation of an example fragment from the FDN set.
This is illustrated by Figure 2, where the number of
times each person?s name is mentioned within the
BWSA is compared to the number of times he or
she is mentioned on the Web.
We collect all possible combinations of each per-
son?s first names, initials and surnames (some are
known by multiple surnames) and their aliases from
the database and get the number of hits, i.e. the num-
ber of articles or webpages that contain the name, by
querying the BWSA and Yahoo!. For each we derive
6 scores:
? A-B: the maximum hit count of all combina-
tions of A ? B divided by the maximum hit
count of A;
? A-B(25): the maximum hit count of all combi-
nations of A ? B within 25 words divided by
the maximum hit count of A;
? B-A: the maximum hit count of all combina-
tions of A ? B divided by the maximum hit
count of B;
? B-A(25): the maximum hit count of all combi-
nations of A ? B within 25 words divided by
the maximum hit count of B;
? AB: the maximum hit count of all combinations
of A ? B divided by the maximum hit count of
A plus the maximum hit count of B;
? AB(25): the maximum hit count of all combina-
tions of A ? B within 25 words divided by the
maximum hit count of A plus the maximum hit
count of B.
0 100 200 300 400 500 600
0
0.2
0.4
0.6
0.8
1
Persons
O
cc
ur
re
nc
e
BWSA
Yahoo!
Figure 2: Fraction of maximum occurrence count
for all 574 persons in the BWSA and on Yahoo!.
Set mention count: As an indication of the re-
latedness more specific to the text fragment under
consideration, we add the number of times A or B
is mentioned in the 5-sentence-context of the frag-
ment, and the number of sentences in which both A
and B are mentioned to the feature vector.
Lexical features: Preliminary tests revealed that
keeping lemmatized verbs and nouns provided the
best results, with mildly positive effects for prepo-
sitions and person names. All tokens outside these
categories were not incorporated in the feature vec-
tor.
Person names are further processed in two ways:
all mentions of person A and person B are replaced
with labels ?PER-A? and ?PER-B?; all names of other
persons mentioned in the fragment are replaced with
label ?PER-X?, where X is either the next available
65
letter in the alphabet (anonymous) or the person?s
unique ID in the database (identified).
We create four variants of both the generic data
set and the FDN data set: one that represents only
verbs and nouns (VN), one that also includes prepo-
sitions (VNPr), one that includes anonymous person
names (VNP-a) and a last one that includes identi-
fied person names (VNP-i). Each set is split into a
training and a test set of respectively 90% and 10%
of the total size. We test our system both with binary
features and with tf.idf weighted features.
5 Results and Evaluation
5.1 Binary versus Tf.idf
Figure 3 shows the 10-fold cross-validation accu-
racy scores on the joint learning task for each of the
training vector sets using binary and tf.idf weighted
features. We take the majority class of the training
set as our baseline. In all cases we observe that un-
weighted binary features outperform weighted fea-
tures. These results are in line with the findings of
Pang et al(2002), who found that the occurrence of
a word is more important than its frequency in de-
termining the sentiment of a text.
Regarding the different feature sets, the addition
of prepositions or person names, either anonymous
or identified, does not have a significant effect on the
results. Only for the VNP-a set the score is raised
from 47.86 % to 48.53 % by the inclusion of anony-
mous person names.
5.2 Co-occurrence
We perform a second experiment to assess the influ-
ence of adding any of the co-occurrence measures
to the feature vectors. Figure 4 displays the results
for the VN set on its own and with inclusion of the
set mention counts (M), the BWSA co-occurrence
scores (B) and the Yahoo! co-occurrence scores (Y).
For the generic set, we observe in all cases that
the co-occurrence measures have a negative effect
on the overall score. For the FDN set this is not al-
ways the case. The set mention counts slightly im-
prove the score, though this is not significant. The
remainder of the experiments is performed on the
vectors without any co-occurrence scores.
5.3 Joint Learning versus Pipeline
Table 2 lists the accuracy scores on the training sets
on both the joint learning task and the pipeline. Only
for the FDN set does the system perform better on
the two-step task than on the single task. In fact, the
FDN set reaches an accuracy of 53.08 % in the two-
step task, which is 6.55 % higher than the majority
class baseline and the highest score so far.
The system consistently performs better on the
joint learning task for the generic set. Further in-
vestigation into why the pipeline does not do well
on the generic set reveals that in the first step of the
task, where instances are classified on whether they
describe a relation or not, all instances always get
classified as ?related?. This immediately results in an
error rate of approximately 15%. In the second step,
when classifying relations into negative, neutral or
positive, we observe that in most cases the system
again resorts to majority class voting and thus does
not exceed the baseline.
Even for the FDN set, where the pipeline does
outperform the joint learning task, the difference in
accuracy between both tasks is minor (0.22-0.96 %).
We conclude that it is preferable to approach our
classification problem as a single, rather than a two-
step task. If the system already resorts to majority
class voting in the first step, every occurrence of a
name in a biography will be flagged as a relation,
which is detrimental to the precision of the system.
5.4 Generic versus FDN
Although the classifiers trained on both sets do not
perform particularly well, the FDN set provides a
greater gain in accuracy over the baseline. The same
is shown when we train the system on the training
sets for both data sets and test them on the held out
test sets. For the generic set, the VNP-a feature set
provides the best results. It results in an accuracy of
50% on the test set, with a baseline of 48.2%.
For the FDN data set, none of the different fea-
ture sets performs better than the others on the joint
learning task. In testing, however, the VNP-a set
proves to be most successful. It results in an ac-
curacy of 66.7%, which is a gain of 4.5% over the
baseline of 62.2%.
To test how well each of the sets generalizes over
the entire community, we test both sets on each
66
baseline
Ac
cu
ra
cy
Generic set
10
20
30
40
50
60
70
44.17
binary
V
N
V
N
P
r
V
N
P
-a
V
N
P
-i
tf.idf
V
N
V
N
P
r
V
N
P
-a
V
N
P
-i
baseline
FDN set
10
20
30
40
50
60
70
46.63
binary
V
N
V
N
P
r
V
N
P
-a
V
N
P
-i
tf.idf
V
N
V
N
P
r
V
N
P
-a
V
N
P
-i
Figure 3: Binary versus weighted features.
Generic set FDN set
joint pipeline baseline joint pipeline baseline
VN 47.92 45.83 44.17 52.12 52.83 46.63
VNPr 48.33 46.88 44.17 52.12 53.08 46.63
VNP-a 48.54 46.88 44.17 52.12 52.34 46.63
VNP-i 47.71 45.83 44.17 52.12 52.59 46.63
Table 2: Accuracy scores on training sets (10-fold cross-validation) for both the joint learning task and the
pipeline.
other. Training on the generic set and testing on
the FDN set results in an accuracy of 45.3% with a
baseline of 48.2%. Doing the same experiment vice
versa results in an accuracy of 44.8% with a baseline
of 44.6%. Examining the output reveals that both
systems resort to selecting the majority class (?posi-
tive?) in most cases. The system that was trained on
the FDN set correctly selects the ?negative? class in a
few cases, but never classifies a fragment as ?neutral?
or ?not related?. The distribution of classes in the
output of the generic system shows a bit more vari-
ety: 0.2% is classified as ?negative?, 10.1% is classi-
fied as ?neutral? and 89.7% is classified as ?positive?.
None of the fragments are classified as ?not related?.
A possible explanation for this is the fact that the
?not related? fragments in the FDN set specifically
describe situations where the main entity is not re-
lated to Ferdinand Domela Nieuwenhuis; these frag-
ments could still describe a relation from the main
entity to another person mentioned in the fragment
and therefore be miss-classified.
5.5 Evaluation
To evaluate our system, we process the entire
BWSA, extracting from each biography all frag-
ments that mention a person from any of the other
biographies. We train the system on the best per-
forming feature set of the generic data set, VNP-a.
In order to filter out some of the errors, we remove
all relations of which only one instance is found in
the BWSA.
The resulting network is evaluated qualitatively
by a domain expert on a sample of the network. For
this we extracted the top-five friends and foes for
five persons. Both rankings are based on the fre-
quency of the relation in the system?s output. The
lists of friends are judged to be mostly correct. This
is probably due to the fact that the positive relation
is the majority class, to which the classifiers easily
revert.
The generated lists of foes are more controversial.
Some of the lists contain names which are also in-
cluded in the list of friends. Of course, this is not
67
Ac
cu
ra
cy
10
20
30
40
50
60
70
10
20
30
40
50
60
70
46.6344.17
Generic set
V
N
V
N
-M
V
N
-B
V
N
-Y
FDN set
V
N
V
N
-M
V
N
-B
V
N
-Y
Figure 4: Comparison of co-occurrence features: M
= set mention counts, B = BWSA co-occurrence, Y
= Yahoo! co-occurrence.
necessarily a sign of bad system performance: we
do not count time as a factor in this experiment and
relationships are subject to change. 25% of the listed
foes are judged to be completely wrong by the expert
judge. 10% are not so much enemies of the main
entity, but did have known political disagreements
with them. The remaining 65% are considered to be
plausible as foes, though the expert would not have
placed them in the top five.
6 Discussion and Future Research
Our case study has demonstrated that relations be-
tween persons can be identified and labeled by their
polarity at an above-baseline level, though the im-
provements are minor. Yet, the utility of the clas-
sifications is visible in the higher-level task of con-
structing a complete social network from all the clas-
sified pairwise relations. After filtering out relations
with only one attestation, a qualitative analysis by a
domain expert on frequency-ranked top-five lists of
friends and foes yielded mostly correct results on the
majority class, ?positive?, and approximately 65%
correct on the harder ?negative? class. If we would
not have used the classifier and guessed only the ma-
jority ?positive? class, we would not have been able
to build ranked lists of foes.
In discussions with domain experts, several ex-
tensions to our current annotation scheme have been
proposed, some of which may be learnable to some
usable extent (i.e. leading to qualitatively good la-
belings in the overall social network) with machine
learning tools given sufficient annotated material.
First, we plan to include more elaborate annotations
by domain experts that discriminate between types
of relationships, such as between family members,
co-workers, or friends. Second, relationships are ob-
viously not static throughout time; their polarity and
type can change, and they have a beginning and an
end.
We aim at working with other machine learn-
ing methods in future expansions of our experi-
mental matrix, including the use of rule learning
methods because of their interpretable output. An-
other direction of research, related to the idea of
the improved annotation levels, is the identifica-
tion of sub-networks in the total social network.
Arguably, certain sub-networks identify ideologi-
cally like-minded people, and may correspond to
what eventually developed into organizations such
as workers unions or political organizations. When
we are able to link automatically detected temporal
expressions to initializations, changes, and endings
of relationships, we may be able to have enough in-
gredients for the automatic identification of large-
scale events such as the emergence of a political
movement.
References
Antal van den Bosch, Bertjan Busser, Sander Canisius
and Walter Daelemans. 2007. An efficient memory-
based morphosyntactic tagger and parser for Dutch.
Selected Papers of the 17th Computational Linguis-
tics in the Netherlands Meeting, Leuven, Belgium, 99?
114.
Chih-Chung Chang and Chih-Jen Lin. 2001. LIB-
SVM: a library for support vector machines. Soft-
ware available at http://www.csie.ntu.edu.
tw/
?
cjlin/libsvm.
Aron Culotta, Andrew McCallum and Jonathan Betz.
2006. Integrating probabilistic extraction models and
data mining to discover relations and patterns in text.
Proceedings of the main conference on Human Lan-
guage Technology Conference of the North American
Chapter of the Association of Computational Linguis-
tics (HLT-NAACL) 2006, 296?303.
Walter Daelemans, Jakub Zavrel, Ko van der Sloot and
Antal van den Bosch. 2010. TiMBL: Tilburg Memory
68
Based Learner, version 6.3, Reference Guide. ILK
Research Group Technical Report Series no. 10-01.
David K. Elson, Nicholas Dames, Kathleen R. McKe-
own. 2010. Extracting social networks from literary
fiction. Proceedings of the 48th Annual Meeting of the
Association for Computational Linguistics 2010, 138?
147.
Thorsten Joachims. 1998. Text categorization with sup-
port vector machines: Learning with many relevant
features. Proceedings of ECML-98, 10th European
Conference on Machine Learning 1998, 137-142.
Henry Kautz, Bart Selman and Mehul Shah. 1997. The
hidden web. AI Magazine, volume 18, number 2, 27?
36.
Soo-Min Kim and Eduard Hovy. 2006. Automatic iden-
tification of pro and con reasons in online reviews.
Proceedings of the COLING/ACL Main Conference
Poster Sessions, 483?490.
Yutaka Matsuo, Hironori Tomobe, Koiti Hasida and Mit-
suru Ishizuka. 2004. Finding social network for trust
calculation. European Conference on Artificial Intel-
ligence - ECAI 2004.
Peter Mika. 2005. Flink: Semantic web technology for
the extraction and analysis of social networks. Web
Semantics: Science, Services and Agents on the World
Wide Web, volume 3, number 2-3, 211?223.
Bo Pang, Lillian Lee and Shivakumar Vaithyanathan.
2002. Thumbs up? Sentiment classification using ma-
chine learning techniques. Proceedings of the Confer-
ence on Empirical Methods in Natural Language Pro-
cessing (EMNLP), 79?86.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Foundations and Trends in Infor-
mation Retrieval, vol. 2, number 1-2, 1?135.
Deepak Ravichandran and Eduard Hovy. 2002. Learning
Surface Text Patterns for a Question Answering Sys-
tem. Proceedings of the 40th Annual Meeting on As-
sociation for Computational Linguistics (ACL) 2002.
Peter D. Turney. 2002. Thumbs up or thumbs down?
Semantic orientation applied to unsupervised classifi-
cation of reviews. Proceedings of the Association for
Computational Linguistics (ACL), 417-424.
69
