Proceedings of the ACL 2007 Demo and Poster Sessions, pages 21?24,
Prague, June 2007. c?2007 Association for Computational Linguistics
Multilingual Ontological Analysis of European Directives
Gianmaria Ajani
Dipartimento di Scienze Giuridiche
Universita` di Torino - Italy
gianmaria.ajani@unito.it
Guido Boella
Leonardo Lesmo
Alessandro Mazzei
Dipartimento di Informatica
Universita` di Torino - Italy
[guido|lesmo|mazzei]@di.unito.it
Piercarlo Rossi
Dipartimento di Studi per l?Impresa e il Territorio
Universita` del Piemonte Orientale - Italy
piercarlo.rossi@eco.unipmn.it
Abstract
This paper describes the main features of our
tool called ?Legal Taxonomy Syllabus?. The
system is an ontology based tool designed to
annotate and recover multi-lingua legal in-
formation and build conceptual dictionaries
on European Directives.
1 Introduction
The European union each year produces a large
number of Union Directives (EUD), which are trans-
lated into each of the communitary languages. The
EUD are sets of norms that have to be implemented
by the national legislations. The problem of multi-
linguism in European legislation has recently been
addressed by using linguistic and ontological tools,
e.g. (Boer et al, 2003; Giguet and P.S., 2006; De-
spre?s and Szulman, 2006). The management of
EUD is particularly complex since the implementa-
tion of a EUD however not correspond to the straight
transposition into a national law. An EUD is subject
to further interpretation, and this process can lead to
unexpected results. Comparative Law has studied in
details the problematics concerning EUD and their
complexities. On the other hand managing with ap-
propriate tools this kind of complexity can facilitate
the comparison and harmonization of national legis-
lation (Boer et al, 2003). Based on this research, in
this paper, we describe the tool for building multilin-
gual conceptual dictionaries we developed for repre-
senting an analysing the terminology and concepts
used in EUD.
The main assumptions of our methodology, mo-
tivated by studies in comparative law (Rossi and
Vogel, 2004) and ontologies engineering (Klein,
2001), are the following ones: 1) Terms and con-
cepts must be distinguished; for this purpose, we
use lightweight ontologies, i.e. simple taxonomic
structures of primitive or composite terms together
with associated definitions. They are hardly axiom-
atized as the intended meaning of the terms used by
the community is more or less known in advance
by all members, and the ontology can be limited to
those structural relationships among terms that are
considered as relevant (Oberle, 2005)1. 2) We dis-
tinguish the ontology implicitly defined by EUD,
the EU level, from the various national ontologies,
the national level. Furthermore, each national leg-
islation refers to a distinct national legal ontology.
We do not assume that the transposition of an EUD
introduces automatically in a national ontology the
same concepts present at the EU level. 3) Corre-
sponding concepts at the EU level and at the national
level can be denoted by different terms in the same
national language.
In this paper, we show how the Legal Taxon-
omy Syllabus (LTS) is used to build a dictionary
of consumer law, to support the Uniform Terminol-
ogy Project2 (Rossi and Vogel, 2004). The struc-
ture of this paper is the following one. In Section 2
we stress two main problems which comparative law
has raised concerning EUD and their transpositions.
In Section 3 we describe how the methodology of
the LTS allows to cope with these problems and fi-
nally in Section 4we give some conclusions.
1See http://cos.ontoware.org/
2http://www.uniformterminology.unito.it
21
2 Terminological and conceptual
misalignment
Comparative law has identified two key points in
dealing with EUD, which makes more difficult deal-
ing with the polysemy of legal terms: we call them
the terminological and conceptual misalignments.
In the case of EUD (usually adopted for harmon-
ising the laws of the Member States), the termino-
logical matter is complicated by their necessity to
be implemented by the national legislations. In or-
der to have a precise transposition in a national law,
a Directive may be subject to further interpretation.
Thus, a same legal concept can be expressed in dif-
ferent ways in a Directive and in its implementing
national law. The same legal concept in some lan-
guage can be expressed in a different way in a EUD
and in the national law implementing it. As a con-
sequence we have a terminological misalignment.
For example, the concept corresponding to the word
reasonably in English, is translated into Italian as
ragionevolmente in the EUD, and as con ordinaria
diligenza into the transposition law.
In the EUD transposition laws a further problem
arises from the different national legal doctrines.
A legal concept expressed in an EUD may not be
present in a national legal system. In this case we
can talk about a conceptual misalignment. To make
sense for the national lawyers? expectancies, the Eu-
ropean legal terms have not only to be translated
into a sound national terminology, but they need to
be correctly detected when their meanings are to re-
fer to EU legal concepts or when their meanings are
similar to concepts which are known in the Member
states. Consequently, the transposition of European
law in the parochial legal framework of each Mem-
ber state can lead to a set of distinct national legal
doctrines, that are all different from the European
one. In case of consumer contracts (like those con-
cluded by the means of distance communication as
in Directive 97/7/EC, Art. 4.2), the notion to pro-
vide in a clear and comprehensible manner some el-
ements of the contract by the professionals to the
consumers represents a specification of the informa-
tion duties which are a pivotal principle of EU law.
Despite the pairs of translation in the language ver-
sions of EU Directives (i.e., klar und versta?ndlich
in German - clear and comprehensible in English -
chiaro e comprensibile in Italian), each legal term,
when transposed in the national legal orders, is in-
fluenced by the conceptual filters of the lawyers?
domestic legal thinking. So, klar und versta?ndlich
in the German system is considered by the German
commentators referring to three different legal con-
cepts: 1) the print or the writing of the informa-
tion must be clear and legible (gestaltung der infor-
mation), 2) the information must be intelligible by
the consumer (formulierung der information), 3) the
language of the information must be the national of
consumer (sprache der information). In Italy, the
judiciary tend to control more the formal features of
the concepts 1 and 3, and less concept 2, while in
England the main role has been played by the con-
cept 2, though considered as plain style of language
(not legal technical jargon) thanks to the historical
influences of plain English movement in that coun-
try.
Note that this kind of problems identified in com-
parative law has a direct correspondence in the on-
tology theory. In particular Klein (Klein, 2001) has
remarked that two particular forms of ontology mis-
match are terminological and conceptualization on-
tological mismatch which straightforwardly corre-
spond to our definitions of misalignments.
3 The methodology of the Legal Taxonomy
Syllabus
A standard way to properly manage large multilin-
gual lexical databases is to do a clear distinction
among terms and their interlingual acceptions (or
axies) (Se?rasset, 1994; Lyding et al, 2006). In
our system to properly manage terminological and
conceptual misalignment we distinguish in the LTS
project the notion of legal term from the notion of
legal concept and we build a systematic classifica-
tion based on this distinction. The basic idea in
our system is that the conceptual backbone consists
in a taxonomy of concepts (ontology) to which the
terms can refer to express their meaning. One of
the main points to keep in mind is that we do not
assume the existence of a single taxonomy cover-
ing all languages. In fact, it has been convincingly
argued that the different national systems may orga-
nize the concepts in different ways. For instance,
the term contract corresponds to different concepts
22
EU ontology Italian ontology German ontology 
Term-Ita-A Term-Ger-A 
EU-1 
Ita-2 
Ger-3 
Ger-5 
Ita-4 
Figure 1: Relationship between ontologies and
terms. The thick arcs represent the inter-ontology
?association? link.
in common law and civil law, where it has the mean-
ing of bargain and agreement, respectively (Sacco,
1999). In most complex instances, there are no
homologous between terms-concepts such as frutto
civile (legal fruit) and income, but respectively civil
law and common law systems can achieve function-
ally same operational rules thanks to the function-
ing of the entire taxonomy of national legal concepts
(Graziadei, 2004). Consequently, the LTS includes
different ontologies, one for each involved national
language plus one for the language of EU docu-
ments. Each language-specific ontology is related
via a set of association links to the EU concepts, as
shown in Fig. 1.
Although this picture is conform to intuition, in
LTS it had to be enhanced in two directions. First,
it must be observed that the various national ontolo-
gies have a reference language. This is not the case
for the EU ontology. For instance, a given term in
English could refer either to a concept in the UK on-
tology or to a concept in the EU ontology. In the
first case, the term is used for referring to a concept
in the national UK legal system, whilst in the second
one, it is used to refer to a concept used in the Euro-
pean directives. This is one of the main advantages
of LTS. For example klar und versta?ndlich could re-
fer both to concept Ger-379 (a concept in the Ger-
man Ontology) and to concept EU-882 (a concept
in the European ontology). This is the LTS solution
for facing the possibility of a correspondence only
partial between the meaning of a term has in the na-
tional system and the meaning of the same term in
the translation of a EU directive. This feature en-
ables the LTS to be more precise about what ?trans-
lation? means. It puts at disposal a way for asserting
that two terms are the translation of each other, but
just in case those terms have been used in the trans-
lation of an EU directive: within LTS, we can talk
about direct EU-translations of terms, but only about
indirect national-system translations of terms. The
situation enforced in LTS is depicted in Fig. 1, where
it is represented that: The Italian term Term-Ita-A
and the German term Term-Ger-A have been used as
corresponding terms in the translation of an EU di-
rective, as shown by the fact that both of them refer
to the same EU-concept EU-1. In the Italian legal
system, Term-Ita-A has the meaning Ita-2. In the
German legal system, Term-Ger-A has the meaning
Ger-3. The EU translations of the directive is cor-
rect insofar no terms exist in Italian and German that
characterize precisely the concept EU-1 in the two
languages (i.e., the ?associated? concepts Ita-4
and Ger-5 have no corresponding legal terms). A
practical example of such a situation is reported in
Fig. 2, where we can see that the ontologies include
different types of arcs. Beyond the usual is-a (link-
ing a category to its supercategory), there are also
a purpose arc, which relates a concept to the legal
principle motivating it, and concerns, which refers
to a general relatedness. The dotted arcs represent
the reference from terms to concepts. Some terms
have links both to a National ontology and to the EU
Ontology (in particular, withdrawal vs. recesso and
difesa del consumatore vs. consumer protection).
The last item above is especially relevant: note
that this configuration of arcs specifies that: 1) with-
drawal and recesso have been used as equivalent
terms (concept EU-2) in some European Directives
(e.g., Directive 90/314/EEC). 2) In that context, the
term involved an act having as purpose the some
kind of protection of the consumer. 3) The terms
used for referring to the latter are consumer protec-
tion in English and difesa del consumatore in Ital-
ian. 4) In the British legal system, however, not
all withdrawals have this goal, but only a subtype
of them, to which the code refers to as cancellation
(concept Eng-3). 5) In the Italian legal system, the
term diritto di recesso is ambiguous, since it can be
used with reference either to something concerning
23
Figure 2: An example of interconnections among
terms.
the risoluzione (concept Ita-4), or to something
concerning the recesso proper (concept Ita-3).
Finally, it is possible to use the LTS to translate
terms into different national systems via the con-
cepts which they are transposition of at the European
level. For instance suppose that we want to trans-
late the legal term credito al consumo from Italian
to German. In the LTS credito al consumo is asso-
ciated to the national umeaning Ita-175. We find
that Ita-175 is the transposition of the European
umeaning EU-26 (contratto di credito). EU-26 is
associated to the German legal term Kreditvertrag
at European level. Again, we find that the national
German transposition of EU-26 corresponds to the
national umeaning Ger-32 that is associated with
the national legal term Darlehensvertrag. Then, by
using the European ontology, we can translate the
Italian legal term credito al consumo into the Ger-
man legal term Darlehensvertrag.
4 Conclusions
In this paper we discuss some features of the LTS, a
tool for building multilingual conceptual dictionar-
ies for the EU law. The tool is based on lightweight
ontologies to allow a distinction of concepts from
terms. Distinct ontologies are built at the EU level
and for each national language, to deal with poly-
semy and terminological and conceptual misalign-
ment.
Many attempts have been done to use ontology
in legal field, e.g. (Casanovas et al, 2005; De-
spre?s and Szulman, 2006) and LOIS project (that is
based on EuroWordNet project (Vossen et al, 1999),
http://www.loisproject.org), but to our
knowledge the LTS is the first attempt which starts
from fine grained legal expertise on the EUD do-
main.
Future work is to study how the LTS can be used
as a thesaurus for general EUD, even if the current
domain is limited to consumer law.
References
A. Boer, T.M. van Engers, and R. Winkels. 2003. Using
ontologies for comparing and harmonizing legislation.
In ICAIL, pages 60?69.
P. Casanovas, N. Casellas, C. Tempich, D. Vrandecic, and
R. Benjamins. 2005. OPJK modeling methodology.
In Proceedings of the ICAIL Workshop: LOAIT 2005.
S. Despre?s and S. Szulman. 2006. Merging of legal
micro-ontologies from european directives. Artificial
Intelligence and Law, ??:????? In press.
E. Giguet and P.S. 2006. Multilingual lexical database
generation from parallel texts in 20 european lan-
guages with endogenous resources. In Proceedings of
the COLING/ACL 2006 Main Conference Poster Ses-
sions, pages 271?278, July.
M. Graziadei. 2004. Tuttifrutti. In P. Birks and A. Pretto,
editors, Themes in Comparative Law, pages ?. Oxford
University Press.
M. Klein. 2001. Combining and relating ontologies: an
analysis of problems and solutions. In Workshop on
Ontologies and Information Sharing, IJCAI?01, Seat-
tle, USA.
V. Lyding, Elena Chiocchetti, G. Se?rasset, and F. Brunet-
Manquat. 2006. The LexALP information system:
Term bank and corpus for multilingual legal termi-
nology consolidated. In Proc. of the Wokshop on
Multilingual Language Resources and Interoperabil-
ity, ACL06, pages 25?31.
D. Oberle, editor. 2005. Semantic Management of Mid-
dleware. Springer Science+Business and Media.
P. Rossi and C. Vogel. 2004. Terms and concepts; to-
wards a syllabus for european private law. European
Review of Private Law (ERPL), 12(2):293?300.
R. Sacco. 1999. Contract. European Review of Private
Law, 2:237?240.
G. Se?rasset. 1994. Interlingual lexical organization for
multilingual lexical databases in NADIA. In Proc.
COLING94, pages 278?282.
P. Vossen, W. Peters, and J. Gonzalo. 1999. Towards a
universal index of meaning. In Proc. ACL-99 Siglex
Workshop.
24
Competence and Performance Grammar
in Incremental Processing
Vincenzo Lombardo
Dipartimento di Informatica
Universita` di Torino
c.so Svizzera, 185
10149, Torino, Italy
vincenzo@di.unito.it
Alessandro Mazzei
Dipartimento di Informatica
Universita` di Torino
c.so Svizzera, 185
10149, Torino, Italy
mazzei@di.unito.it
Patrick Sturt
Department of Psychology
University of Glasgow
58 Hillhead Street
Glasgow, G12 8QB, UK
patrick@psy.gla.ac.uk
Abstract
The goal of this paper is to explore some conse-
quences of the dichotomy between competence
and performance from the point of view of in-
crementality. We introduce a TAG?based for-
malism that encodes a strong notion of incre-
mentality directly into the operations of the
formal system. A left-associative operation is
used to build a lexicon of extended elementary
trees. Extended elementary trees allow deriva-
tions in which a single fully connected struc-
ture is mantained through the course of a left-
to-right word-by-word derivation. In the paper,
we describe the consequences of this view for
semantic interpretation, and we also evaluate
some of the computational consequences of en-
larging the lexicon in this way.
1 Introduction
Incremental processing can be achieved with a
combination of grammar formalism and deriva-
tion/parsing strategy. In this paper we explore
some of the computational consequences of de-
riving the incremental character of the human
language processor from the competence gram-
mar. In the following paragraphs, we assume
that incremental processing proceeds through a
sequence of processing steps. Each step consists
of a configuration of partial syntactic structures
(possibly connected into only one structure) and
a configuration of semantic structures (again,
possibly connected into one single expression).
These semantic structures result from the ap-
plication of the semantic interpreter to the syn-
tactic structures in the same processing step.
Depending on the semantic rules, some syntac-
tic structures may not be interpretable?that
is, some processing steps do not involve an up-
dating of the semantic representation. In the
view we present here, competence grammar is
responsible for the definition of both the set of
well-formed sentences of the language and the
set of possible partial structures that are yielded
by the derivation process. According to this
view, the performance component is responsible
for other aspects of language processing, includ-
ing ambiguity handling and error handling. The
latter issues are not addressed in this paper.
In the psycholinguistic and computational lit-
erature, many models for incremental process-
ing have been discussed. These models can be
characterized in terms of the location of the bor-
der between competence and performance. In
particular, we discuss the relative responsibility
of the competence and performance components
on three key areas of syntactic processing: a)
the space of well-formed partial syntactic struc-
tures; b) the space of the possible configurations
of partial syntactic structures at each process-
ing step; c) the sub-space of partial structures
that can actually be interpreted.
The definition of well-formedness is almost
universally assigned to the competence compo-
nent, whether in a direct implementation of the
grammar formalism (cf. the Type Transparency
hypothesis (Berwick and Weinberg, 1984)) or a
compiled version of the competence grammar
(e.g. LR parsing (Shieber and Johnson, 1993)).
The space of the possible configurations of
partial structures refers to those partial syntac-
tic structures that are built and stored during
parsing or derivation. Different algorithms re-
sult in different possibilities for the configura-
tions of partial structures that the parser builds.
For example, a bottom?up algorithm will never
build a partial structure with non?terminal leaf
nodes. The standard approach is to assign this
responsibility to the parsing algorithm, whether
the grammar is based on standard context-free
formalisms (Roark, 2001), on generative syntac-
tic theories based on a context-free backbone
(Crocker, 1992), or on categorial approaches,
like e.g. Combinatory Categorial Grammar
(CCG ? (Steedman, 2000)). A different method
is to assign this responsibility to the compe-
tence component. In this case the space of
possible configurations of partial structures is
constrained by the grammatical derivation pro-
cess itself, and the parsing algorithm needs to
be aligned with these requirements. This ap-
proach is exemplified by the works of Kempson
et al (2000) and Phillips (2003), who argue
that many problems in theoretical syntax, like
the definition of constituency, can be solved by
extending this responsability to the competence
grammar.
This issue of constituency is also relevant in
the third key area, which is the definition of the
space of interpretable structures. The assign-
ment of responsibility with respect to current
approaches usually depends on the implementa-
tion of the incremental technique. Approaches
based on a coupling of syntactic and seman-
tic rules in the competence grammar (Steed-
man, 2000; Kempson et al, 2000) adhere to the
so-called Strict Competence Hypothesis (Steed-
man, 2000), which constrains the interpreter to
deal only with grammatical constituents, so the
responsibility for deciding the interpretable par-
tial structures is assigned to competence1. In
contrast, approaches that are based on com-
petence grammars that do not include seman-
tic rules, like CFG, implement semantic inter-
preters that mimic such semantic rules (Stabler,
1991), and so they assign the responsibility for
deciding the interpretable partial structures to
performance.
In this paper we explore the empirical con-
sequences of building a realistic grammar when
the formalism constrains all these three areas,
as is the case with Kempson et al (2000)
and Phillips (2003). The work relies upon the
Dynamic Version of Lexicalized Tree Adjoin-
ing Grammar (DV?TAG), introduced in (Lom-
bardo and Sturt, 2002b), a formalism that en-
codes a dynamic grammar (cf. (Milward, 1994))
in LTAG terms (Joshi and Schabes, 1997). The
consequence of encoding a dynamic grammar
is that the configurations of partial structures
discussed above are limited to fully connected
structures, that is no disconnected structures
are allowed in a configuration. In particular,
the paper focuses on the problem of building a
realistic DV?TAG grammar through a conver-
sion from an LTAG, in order to maintain the
1Notice that these approaches may, however, differ in
the time-course with which semantic rules are applied
in the interpreter, and this issue depends directly on
the space of configurations of partial structures discussed
above
linguistic significance of elementary trees while
extending them to allow the full connectivity.
2 Dynamic Version of Tree
Adjoining Grammar
This section reviews the major aspects of the
Dynamic Version of Tree Adjoining Grammar
(DV?TAG), with special reference to similari-
ties and differences with respect to LTAG.
Dynamic grammars define well-formedness in
terms of states and transitions between states.
They allow a natural formulation of incremental
processing, where each word wi defines a tran-
sition from Statei?1, also called the left context,
to Statei (Milward, 1994). The states can be
defined as partial syntactic or semantic struc-
tures that are ?updated? as each word is recog-
nized; roughly speaking, two adjacent states can
be thought of as two parse trees before and af-
ter the attachment of a word, respectively. The
derivation process proceeds from left to right
by extending a fully connected left context to
include the next input word.
Like an LTAG (Joshi and Schabes, 1997), a
Dynamic Version of Tree Adjoining Grammar
(DV?TAG) consists of a set of elementary trees,
divided into initial trees and auxiliary trees,
and attachment operations for combining them.
Lexicalization is expressed through the associ-
ation of a lexical anchor with each elementary
tree. The anchor defines the semantic content of
the elementary tree: the whole elementary tree
can be seen as an extended projection of the an-
chor (Frank, 2000). LTAG is said to define an
extended domain of locality ?unlike context-free
grammars, which use rules that describe one?
branch deep fragments of trees, TAG elemen-
tary trees can describe larger structures (e.g. a
verb, its maximal S node and subject NP node).
In figures 1(a) and 2(a) we can see the ele-
mentary trees for a derivation of the sentence
Bill often pleases Sue for LTAG and DV?TAG
respectively. Auxiliary trees in DV?TAG are
split into left auxiliary trees, where the lexical
anchor is on the left of the foot node, and right
auxiliary trees, where the lexical anchor is on
the right of the foot node. The tree anchored
by often in fig. 2(a) is a left auxiliary tree.
Non-terminal nodes have a distinguished
head daughter, which provides the lexical head
of the mother node: unlike in LTAG, each node
in the elementary trees is augmented with a fea-
ture indicating the lexical head that projects
the node. This feature is needed for the no-
Bill often pleases Sue. 
NNP 
Sue 
NP 
ADV
often
ADVP 
VP 
VP* 
NP 
NNP 
Sue 
S
V
pleases
NP 
VP NNP 
Bill 
ADV
often
ADVP 
VP 
V
pleases 
NP$ 
NP$ 
S
VP 
adjunction
Bill
pleases
Sueoften
(a)
(b)
(c)
substitutionNNP 
Bill 
NP 
substitution
 
Bill
 
pleases

often
 
Sue
Figure 1: The LTAG derivation of the sentence
Bill often pleases Sue.
NNP 
Sue 
NP(Sue)
ADV
often
ADVP(often)
VP(_j)
VP*(_j)
NP(Sue)
NNP 
Sue 
S(pleases)
V
pleases
NP(Bill)
VP(pleases)NNP 
Bill 
ADV
often
ADVP(often)
VP(pleases)
V(_i) NP$(_k)NNP 
Bill 
NP(Bill)
S(_i)
VP( i)
pleases 
likes 
eats 
plays 
?
1. adjunction 
from the left 
2. shift 
Bill
pleases
Sueoften
(a)
(b)
(c)
3. substitution 
Figure 2: The DVTAG derivation of the sen-
tence Bill often pleases Sue.
tion of derivation?dependency tree (see below).
If several unheaded nodes share the same lexical
head, they are all co-indexed with a head vari-
able (e.g. i in the elementary tree anchored by
Bill in figure 2(a)); the head variable is a vari-
able in logic terms: i will be unified with the
constant (?lexical head?) pleases.
In both LTAG and DV?TAG the lexical an-
chor does not necessarily provide the head fea-
ture of the root of the elementary tree. This is
trivially true for auxiliary trees (e.g. the tree
anchored often in figure 1(a) and figure 2(a)).
However, in DV?TAG this can also occur with
initial trees (e.g. the tree anchored by Bill in
figure 2(a)), because initial trees can include
not only the head projection of the anchor, but
also other higher projections that are required
to account for the full connectedness of the par-
tial parse tree. The elementary tree anchored
by Bill is linguistically motivated up to the NP
projection; the rest of the structure depends on
connectivity. These extra nodes are called pre-
dicted nodes. A predicted preterminal node is
referred by a set of lexical items. In the sec-
tion 3 we illustrate a method for building such
extended elementary trees.
The derivation process in LTAG and DV?
TAG builds a derived tree by combining the ele-
mentary trees via some operations that are illus-
trated below. DV?TAG implements the incre-
mental process by constraining the derivation
process to be a series of steps in which an ele-
mentary tree is combined with the partial tree
spanning the left fragment of the sentence. The
result of a step is an updated partial structure.
Specifically, at the processing step i, the ele-
mentary tree anchored by the i-th word in the
sentence is combined with the partial structure
spanning the words from 1 to i ? 1 positions;
the result is a partial structure spanning the
words from 1 to i. In contrast, LTAG does
not pose any order constraint on the deriva-
tion process, and the combinatorial operations
are defined over pairs of elementary trees. In
DV?TAG the derivation process starts from an
elementary tree anchored by the first word in
the sentence and that does not require any at-
tachment that would introduce lexical material
on the left of the anchor (such as in the case
that a Substitution node is on the left of the
anchor). This elementary tree becomes the first
left context that has to be combined with some
elementary tree on the right.
Since in DV?TAG we always combine a left
context with an elementary tree, the number
of attachment operations increases from two
in LTAG to six in DV?TAG. Three operations
(substitution, adjunction from the left and ad-
junction from the right) are called forward op-
erations because they insert the current elemen-
tary tree into the left context; two other oper-
ations (inverse substitution and inverse adjunc-
tion) are called inverse operations because they
insert the left context into the current elemen-
tary tree; the sixth operation (shift) does not
involve any insertion of new structural material.
The first operation in DV?TAG is the stan-
dard LTAG substitution, where some elemen-
tary tree replaces a substitution node in another
tree structure (see fig. 2(a)).
Standard LTAG adjunction is split into two
operations: adjunction from the left and ad-
junction from the right. The type of adjunction
depends on the position of the lexical material
introduced by the auxiliary tree with respect
to the material currently dominated by the ad-
joined node (which is in the left context). In
figure 2(a) we have an adjunction from the left
in the case of the left auxiliary tree anchored by
often.
Inverse operations account for the insertion
of the left context into the elementary tree. In
the case of inverse substitution the left context
replaces a substitution node in the elementary
tree; in the case of inverse adjunction, the left
context acts like an auxiliary tree, and the el-
ementary tree is split because of the adjoining
of the left context at some node. In (Lombardo
and Sturt, 2002b) there is shown the importance
of the latter operation to obtain the correct de-
pendencies for cross-serial Dutch dependencies
in DV?TAG.
Finally, the shift operation either scans a lex-
ical item which has been already introduced in
the structure or derives a lexical item from some
predicted preterminal node.
It is important to notice that, during the
derivation process, not all the nodes in the left
context and the elementary tree are accessible
for performing some operation: given the i? 1-
th word in the sentence we can compute a set
of accessible nodes in the left context (the right
fringe); also, given the lexical anchor of the el-
ementary tree, that in the derivation process
matches the i-th word in the sentence, we can
compute a set of accessible nodes in the elemen-
tary tree (the left fringe).
At the end of the derivation process the left
context structure spans the whole sentence, and
is called the derived tree: in the figures 1(c) and
2(c) there are the derived trees for Bill often
pleases Sue in LTAG and DV?TAG respectively.
A key device in LTAG is the derivation tree
(fig. 1(b)). The derivation tree represents the
history of the derivation of the sentence: it de-
scribes the substitutions and the adjoinings that
occur in a sentence derivation through a tree
structure. The nodes of the derivation tree are
identifiers of the elementary trees, and one edge
represents the operation that combines two ele-
mentary trees. Given an edge, the mother node
identifies the elementary tree where the elemen-
tary tree identified by the daughter node is sub-
stituted in or adjoined to, respectively. The
derivation tree provides a factorized representa-
tion of the derived tree. Since each elementary
is anchored by a lexical item, the derivation tree
also describes the syntactic dependencies in the
sentence in the terms of a dependency?style rep-
resentation (Rambow and Joshi, 1999) (Dras et
al., 2003).
The notion of derivation tree is not ade-
quate for DV?TAG, since the elementary trees
contain unheaded predicted nodes. For exam-
ple, the elementary tree anchored by Bill ac-
tually involves two anchors, Bill and pleases,
even if the latter anchor remains unspecified
until it is scanned/derived in the linear or-
der. We introduce a new word?based structure
that represents syntactic dependencies, namely
a derivation-dependency tree.
A derivation-dependency tree is a head-based
version of the derivation tree. Each node in an
elementary tree is augmented with the lexical
head that projects that node. The derivation-
dependency tree contains one node per lexi-
cal head, and a lexical head dominates another
when the corresponding projections in the de-
rived tree stand in a dominance relation. Each
elementary tree can contain only one overtly
marked lexical head, that represents the seman-
tic unit, but the presence of predicted nodes
in the partial derived tree corresponds to pre-
dicted heads in the derivation-dependency tree.
In figure 3 is depicted the evolution of the
derivation?dependency tree for the sentence Bill
often pleases Sue.
The DV?TAG derivation process requires the
full connectivity of the left context at all times.
The extended domain of locality provided by
LTAG elementary trees appears to be a desir-
able feature for implementing full connectivity.
However, each new word in a string has to be
connected with the preceding left context, and
there is no a priori limit on the amount of struc-
ture that may intervene between that word and
the preceding context. For example, in a DV?
TAG derivation of John said that tasty apples
     	


    	
 An Ontology Based Architecture for Translation
Leonardo Lesmo, Alessandro Mazzei and Daniele P. Radicioni
Dipartimento di Informatica, Universita` degli Studi di Torino
{lesmo,mazzei,radicion}@di.unito.it
Abstract
In this paper we present some features of an architecture for the translation (Italian ? Italian Sign
Language) that performs syntactic analysis, semantic interpretation and generation. Such architec-
ture relies on an ontology that has been used to encode the domain of weather forecasts as well as
information on language as part of the world knowledge. We present some general issues of the
ontological semantic interpretation and discuss the analysis of ordinal numbers.
1 Introduction
In this paper we describe some features of a system designed to translate from Italian into Italian Sign
Language (henceforth LIS). The system is being developed within the ATLAS project.1 This architec-
ture applies a hard computational linguistic approach: knowledge-based restricted interlingua (Hutchins
and Somer, 1992). We perform a deep linguistic processing in each phase of the translation, i.e (1)
syntactic analysis of the Italian input sentence, (2) semantic interpretation and (3) LIS generation.2 The
main motivation to adopt this ambitious architecture is that Italian and LIS are very different languages.
Moreover, LIS is a poorly studied language, so no large corpus is available and statistical techniques are
hardly conceivable. We reduce our ambitions by restricting ourselves to the weather forecasts application
domain.
In this paper we describe some major issues of the semantic interpretation and illustrate a case study
on ordinal numbers. Our semantic interpretation is based on a syntactic analysis that is a dependency tree
(Hudson, 1984; Lesmo, 2007). Each word in the sentence is associated with a node of the syntactic tree.
Nodes are linked via labeled arcs that specify the syntactic role of the dependents with respect to their
head (the parent node). A key point in semantic interpretation is that the syntax-semantics interface used
in the analysis is based on an ontology. The knowledge in the ontology concerns an application domain,
i.e. weather forecasts, as well as more general information about the world: the latter information is used
to compute the sentence meaning. Indeed, the sentence meaning consists of a complex fragment of the
ontology: predicate-argument structures and semantic roles are contained in this fragment and could be
extracted by translating this fragment into usual First Order Logic predicates.3
The idea to use the ontological paradigm to represent world knowledge as well as sentence meaning
is similar to the work by Nirenburg and Raskin (2004) and Buitelaar et al (2009), but in contrast to these
approaches (1) we use a syntactic parser to account for syntactic analysis; and (2) we use a recursive
semantic interpretation function similar to Cimiano (2009).
2 The Ontology
The ontological knowledge base is a formal (partial) description of the domain of application. It is for-
mal, since its primitives are formally defined, and it is partial, since it does not include all axioms that
provide details about the relationships between the involved concepts. The top level of the domain ontol-
ogy is illustrated in Fig. 1.4 The classes most relevant to weather forecasts are ??meteo-status-situation ,
1http://www.atlas.polito.it/
2LIS, as all the signed languages do not have a natural writing form. In order to apply linguistic tools designed for written
languages, in our project we developed ?AEW-LIS?, an artificial written form for LIS.
3However, similar to other approach (among others Bunt et al (2007); White (2006)), our ontological meaning representa-
tion is totally unscoped.
4Some conventions have been adopted for ontology names: concepts (classes) have a ??prefix; instances have a ?prefix; and
relations and relation instances have a & prefix.
345
!
99$-.0.:
99.0,$"0-.$;<"1!
=0#+;$!>!
99?$5*;0@.0%-!
99#$%#;"@";."
5$1$*.0%-"
*;0.$;0+,!
99,$.$%"5.".+5"
50.+".0%-!
99?":! 99$<$-0-#
99@%50.0<$"?":!
99@%50.0<$"
$<$-0-#
99@%50.0<$"$<"1"
$-.0.:!
99$<"1+"A1$"!
$-.0.:!
990.";$#0%-
990."*";?0-"1";$#0%-!
990."B$5.$;-";$#0%-!
990."$"5.$;-";$#0%-
990."5%+.C$;-";$#0%-!
990."-%;.C$;-";$#0%-!
990."*$-.;"1";$#0%-
990.""?;0".0*"
;$#0%-
990."051"-?";$#0%-
990.""?;0".0*";$#0%-
995$"990.";$#0%-"#;%+@
99#$%#;"@C0*"
";$"
990."#$%#;"";$"
!
!
!
!
=0#+;$!D!
!
!
!
!
!
!
!
!
!
!
!
!
!
Figure 1: The top ontology used for the weather forecast domain. Dashed triangles represent collapsed regions of
the hierarchy.
??geographic-area , ??description , ??geographic-part-selection-criterium .
??meteo-status-situation It is the most relevant class in the present setting, since it refers to the possi-
ble weather situations, thus providing a starting point ?in principle? to every weather forecast. It may
concern the sea status, a generic weather status (either stable or not) or possible atmospheric events such
as snow, rain or clouds.
??geographic-area and ??time-interval Any weather situation holds in a specific place; in particular,
the relevant places are geographic areas. A ??geographic-area can be an Italian region, a group of re-
gions, a sea, or may be identified by specifying a cardinal direction (North, South, . . . ). Yet, any weather
situation holds in a specific temporal interval. Such time interval could last one or more days or a part of
a day. Expression as ?in the evening? are interpreted anaphorically, i.e. on the basis of current context: if
the context is referring to ?today?, then it is interpreted as ?today evening?, for ?tomorrow? as ?tomorrow
evening?, etc..
??description The actual situation and its description are kept separated. For instance, if today is Octo-
ber 28, then ?today? is a ??deictic-description of a particular instance (or occurrence) of a ??day . ?April
28, 2010? is another description (absolute) of the same instance. Particular relevance have the deictic de-
scriptions since most temporal descriptions (today, tomorrow, but also the weekday names, as Monday,
Tuesday, . . . ) are deictic in nature.
??geogr-part-selection-criterium In descriptions, a particular instance (or group of instances) can be
identified by a general class term (e.g. area) and a descriptor (e.g. northern). This concept refers to the
parts of the reality that can act as descriptors. For instance, the cardinal direction can be such a criterium
for geographic parts, while a date is not.
The last relevant portion of the ontology concerns relations. Although the ontology has no axioms,
class concepts are connected through relevant relations. In turn, relations constitute the basic steps to
form paths (more later on). All relations in the ontology are binary, so that the representation of relations
of arity greater than 2 requires that they be reified.
3 Semantic Interpretation
One chief assumption in our work is that words meaning can be expressed in terms of ontology nodes,
and the meaning of the sentence is a complex path on the ontology that we call ontological restriction.
We define the meaning interpretation function MO, that computes the the ontological restriction of a
sentence starting from the its dependency analysis and on the basis of an ontology O.
Given a sentence S and the corresponding syntactic analysis expressed as a dependency tree depTree(S),
the meaning of S is computed by applying the meaning interpretation function to the root of the tree, that
is MO(root(depTree(S))). In procedural terms, the meaning for a sentence is computed in two steps:
(i) we annotate each word of the input sentence with the corresponding lexical meaning; (ii) we build the
346
giorno [??day]
ultimo [??last] mese [??month]
adjc+ordin-rmod rmod
Figure 2: The dependency analysis of ultimo giorno del mese (last day of the month) enriched with lexical meaning.
actual ontological representation in a quasi-compositional way, by merging paths found in the ontology
in a single representation which is a subgraph of the ontology itself. These two steps can be formalized
as a meaning interpretation function M defined as:
MO(n) :=
{
LMO(n) if n is a leaf
??ki=1(CPO(LMO(n),MO(di))) otherwise
where n is the node of a dependency tree and d1, d2, . . . , dk are its dependents. LMO(w) is a function
that extracts the lexical meaning of a word w accessing the dictionary: that is, a class or an individual
on the ontology O. CPO(y, z) is a function that returns the shortest path on O that connects y to z.
The search for connections relies on the rationale that the shortest path between any two ontology nodes
represents the stronger semantic connection between them. In most cases the distance between two
concepts is the number of the nodes among them, but in some cases a number of constraints needs to
be satisfied too (see the example on ordinal construction). Finally, the operator ?? is used to denote a
particular merge operator, similar to Cimiano (2009). As a general strategy, shortest paths are composed
with the union operation, but each CPO(y, z) conveys a peculiar set of ontological constraints: the merge
operator takes all such constraints to build the overall complex ontological representation. In particular, a
number of semantic clashes can arise from the union operation: we use a number of heuristics to resolve
these clashes. For sake of simplicity (and space) in this definition we do not describe the heuristics
used in the ambiguity resolution. However, three distinct types of ambiguity exist: (1) lexical ambiguity,
i.e. a word can have more than one lexical meaning; (2) shortest path ambiguity, i.e. two nodes can
be connected by two equal-length paths; (3) merge ambiguity, i.e. two fragments of ontology can be
merged in different manners. Whilst lexical ambiguity has not a great impact due to the limited domain
(and could be addressed by standard word sense disambiguation techniques), handling shortest path and
merge ambiguities needs heuristics expressed as constraints that rely on general world knowledge.
A particular case of ontological constraints in merge ambiguity is present in the interpretation of
ordinal numbers, so further details on the merge operator can be found in Section 4.
4 A case study: the ordinal numbers
In order to translate from Italian into LIS, we need to cope with a number of semantic phenomena
appearing in the particular domain chosen as pilot study, i.e. weather forecast. One of the most frequent
constructions are ordinal numbers. Consider the simple phrase l?ultimo giorno del mese (the last day
of the month). The (simplified) dependency structure corresponding to this phrase is depicted in Fig. 2:
the head word giorno (day) has two modifying dependents, ultimo (last) and mese (month). Since the
interpretation relies heavily on the access to the ontology, we first describe the portion of the ontology
used for the interpretation and then we illustrate the application of the function M to the given example.
The relevant fragment of the ontology is organized as shown in Fig. 3, that has been split in two parts.
The upper part ?labeled TEMPORAL PARTS? describes the reified ??part-of relation and its temporally
specialized subclasses. The lower part ?labeled ORDINALS? is constituted by some classes that account
just for ordinal numbers. In the TEMPORAL PARTS region of the Fig. we find the ??temporal-part-of
(reified) sub-relation, which, in turn, subsumes ??day-month-part-of . This specifies that days are parts of
months, so that day of the month can be interpreted as the day which is part of the month. The ??part-of
relation has two roles: we use the term role to refer to the binary relation associated with a participant
in a reified relation. These roles are ?value-restricted? as &day-in-daymonth and &month-in-daymonth
respectively, for what concerns ??day-month-part-of . The most relevant class in the ORDINALS part
of Fig. 3 is the class ??ordinal-description . It is the domain of three roles, 1) &ord-described-item , 2)
&references-sequence and 3) &ordinal-desc-selector . The range of the first relation &ord-described-item
is the item whose position in the sequence is specified by the ordinal, that is a ??sequenceable-entity.
The range of the second relation &reference-sequence is the sequence inside which the position makes
347
??physical-entity ??part-of
&part-smaller &part-bigger
??time-interval ??temporal-part-of
&temporal-
  part-smaller &temporal-
  part-bigger
??day-month-part-of??day ??month
&day-in-
daymonth
&month-in-
daymonth
??ordinal-
description
??sequenceable-
          entity
??entity-sequence
&ord-described-item &reference-sequence
&ordinal-
   desc-selector ??ordinal-selector
??last
??day-sequence
TEMPORAL PARTS
ORDINALS
Figure 3: The fragment of the ontology accounting for ordinals.
sense, that is an ??entity-sequence . The range of the third relation &ordinal-desc-selector is item that
specifies the position, that is a ??ordinal-selector . In the example, ?last is an instance of ??ordinal-
selector . Of course, any (true) ordinal (first, second, thirtythird) can fill that role. The two portions of
the ontology are connected by two arcs. The first arc specifies that a ??time-interval is a subclass of
??sequenceable-entity (so that one can say the fourth minute, the first year, and so on). The second arc
specifies that ??month is subclass of ??day-sequence , which in turn is subclass of ??entity-sequence .
As a consequence it can play the role (can be the range) of the &reference-sequence .
We now describe how the meaning interpretation function is applied on the considered example. It
consists of three steps: 1. we compute the connection path between the concepts ??day and ?last ; 2. we
compute the connection path between ??day and ??month ; 3. we merge the connection paths previously
computed. In details:
1. By computing CP(??day, ?last) we obtain the connection path in Fig 4-a. Note that this ontological
restriction contains the concept ??ordinal-selector .
2. By computing CP(??day, ??month) we obtain the connection path in Fig 4-b. In this case the shortest
path is not actually the ?shortest? one, i.e. the presence of the preposition del (of ) constraints the value
returned by CP . Moreover, this ontological restriction contains the concept ??day-month-part-of , which
is a sub-concept of ??part-of .
3. The last step consists of the application of the meaning composition function to CP(??day, ?last) and
CP(??day, ??month). The ??ordinal-description concept is detected in the first ontological restriction;
moreover ??day is recognized as (subclass of) a possible filler for ??ordinal-description . At this point
we need establishing how ??day fits as the smaller part of a &part-of relation. We scan the remain-
ing ontological restriction(s) looking for a bigger part involved in a &part-of relation or in any of its
sub-relations. The resulting representation (Fig. 4-c) is built by assuming that the larger entity (here
??month , since &month-in-daymonth restricts &part-bigger) is the reference sequence for the ordering.
So, the direct ??day-month-part-of of the second ontological restriction is replaced by a path passing
through ??ordinal-description . In such final ontological restriction ??day is the &ord-described-item
and ??month is the &reference-sequence .
5 Conclusions and future work
In this paper we illustrated the analysis component of a knowledge-based restricted interlingua architec-
ture for the translation from Italian into LIS. The structure produced by the semantic interpretation of the
348
??physical-entity ??part-of
&part-smaller &part-bigger
??time-interval ??temporal-part-of
&temporal-
  part-smaller &temporal-
  part-bigger
??day-month-part-of??day ??month
&day-in-
daymonth
&month-in-
daymonth
??ordinal-
description
??sequenceable-
          entity
??entity-sequence
&ord-described-item &reference-sequence
&ordinal-
   desc-selector ??ordinal-selector
??last
??day-sequence
TEMPORAL PARTS
ORDINALS
1
2
3
4 5
6
7
8
9
??physical-entity ??part-of
&part-smaller &part-bigger
??time-interval ??temporal-part-of
&temporal-
  part-smaller &temporal-
  part-bigger
??day-month-part-of??day ??month
&day-in-
daymonth
&month-in-
daymonth
??ordinal-
description
??sequenceable-
          entity
??entity-sequence
&ord-described-item &reference-sequence
&ordinal-
   desc-selector ??ordinal-selector
??last
??day-sequence
TEMPORAL PARTS
ORDINALS
1 2 3
b)
c)
??physical-entity ??part-of
&part-smaller &part-bigger
??time-interval ??temporal-part-of
&temporal-
  part-smaller &temporal-
  part-bigger
??day-month-part-of??day ??month
&day-in-
daymonth
&month-in-
daymonth
??ordinal-
description
??sequenceable-
          entity
??entity-sequence
&ord-described-item &reference-sequence
&ordinal-
   desc-selector ??ordinal-selector
??last
??day-sequence
TEMPORAL PARTS
ORDINALS
2
1
3
4 5
6
a)
Figure 4: The ontology fragment computed by the semantic interpretation function.
source sentence is a complex ontology fragment obtained by the application of the function MO. As case
study we showed how this function uses the ontology O to interpret the ordinal numbers. The decision
to use an ontology fragment as semantic representation is motivated by theoretical assumptions and has
some practical appeals. From a theoretical point of view, we represent language semantics as part of the
world knowledge in ontologies (Buitelaar et al, 2009; Galanis and Androutsopoulos, 2007; Nirenburg
and Raskin, 2004). From an applicative point of view the ontology restriction produced by the semantic
interpretation is used (in logical form) as input of the OpenCCG tool, in the generation component of the
translation architecture (White, 2006). As a consequence, similar to Nirenburg and Raskin (2004), we
use ontologies in all components of our architecture (cf. Galanis and Androutsopoulos (2007); Sun and
Mellish (2007)).
We have currently implemented the main features of the MO and the ontology is being developed.
Our working hypothesis is that the weather forecast sub-language is characterized by plain and short
sentences and this guarantees scalability of our approach. In the next future we plan to broaden the
coverage of linguistic phenomena, so to unify ordinals, superlative and comparative adjective analyses.5
References
Buitelaar, P., P. Cimiano, P. Haase, and M. Sintek (2009). Towards linguistically grounded ontologies. In Proceed-
ings of the 6th Annual European Semantic Web Conference (ESWC).
Bunt, H., R. M. M. Dzikovska, M. Swift, and J. Allen (2007). Customizing Meaning: Building Domain-Specific
Semantic Representations From A Generic Lexicon, Volume 83. Springer.
Cimiano, P. (2009). Flexible semantic composition with DUDES. In Proceedings of the 8th International Confer-
ence on Computational Semantics (IWCS?09).
Galanis, D. and I. Androutsopoulos (2007). Generating multilingual descriptions from linguistically annotated
OWL ontologies: the naturalOWL system. In In Proceedings of the 11th European Workshop on Natural
Language Generation, Schloss Dagstuhl.
Hudson, R. (1984). Word Grammar. Oxford and New York: Basil Blackwell.
Hutchins, W. and H. L. Somer (1992). An Introduction to Machine Translation. London: Academic Press.
Lesmo, L. (2007, June). The Rule-Based Parser of the NLP Group of the University of Torino. Intelligenza
Artificiale 2(4), 46?47.
Nirenburg, S. and V. Raskin (2004). Ontological Semantics. The MIT Press.
Sun, X. and C. Mellish (2007). An experiment on ?free generation? from single RDF triples. In Proceedings of
ENLG ?07, pp. 105?108. Association for Computational Linguistics.
White, M. (2006). Efficient realization of coordinate structures in combinatory categorial grammar. Research on
Language and Computation 2006(4(1)), 39?75.
5Acknowledgement: This work is partly supported from the ATLAS project, that is co-funded by Regione Piemonte within
the ?Converging Technologies - CIPE 2007? framework (Research Sector: Cognitive Science and ICT).
349
INLG 2012 Proceedings of the 7th International Natural Language Generation Conference, pages 105?109,
Utica, May 2012. c?2012 Association for Computational Linguistics
Sign Language Generation with Expert Systems and CCG
Alessandro Mazzei
Dipartimento di Informatica
Universita` degli Studi di Torino
Corso Svizzera 185, 10185 Torino Italy
mazzei@di.unito.it
Abstract
This paper concerns the architecture of a gen-
erator for Italian Sign Language. In particu-
lar we describe a microplanner based on an
expert-system and a combinatory categorial
grammar used in realization.
1 Introduction
In this paper we present the main features of the
generator used into a translation architecture from
Italian to Italian Sign Language (Lingua Italiana
dei Segni, henceforth LIS), that is the sign lan-
guage used by the Italian deaf (signing) community
(Volterra, 2004). Our generator consists of two mod-
ules: (i) SentenceDesigner, that is a rule-based mi-
croplanner; (ii) OpenCCG, that is a chart realizer
(White, 2006). There are two main issues in this
work. The first issue concerns the use of an expert
system for microplanning. Most of our knowledge
about LIS linguistics derives from discussions with
linguists: expert systems allow for sharp modular-
ization of this human knowledge. Moreover, expert-
system allow us for easily updateable knowledge or-
ganization in cases of conflict or contradiction. The
second issue in our work concerns the design of
a combinatory categorial grammar (CCG) used by
the realizer. This CCG accounts for a number of
specific LIS phenomena as spatial verb-arguments
agreement and NP coordination.1
1In this paper we present a grammatical account for spatial
verb-arguments agreement. A different approach, that we are
exploring too, is to consider space allocation as separate process
that takes as input the syntactic structure, similar to prosody in
vocal languages.
! !
!""#$%&'#()$"#)*+)$,-&$(-.-$,#$"#%"+)/$0)+$12&)*#$,#$'-(3-*2'%*2$.%3-*#)*#$2&&2$(-,#2
!""# %&'#() "#)*+) ,-& (-.- ,# "#%"+) / 0)+ 12&)*# ,#
(-,#22&&2
.%3-*#)*#'-(3-*2'%*2
42&)*# ,# (-,#22&&2.%3-*#)*#'-(3-*2'%*2
!"#$ %!&
!"#$
%!& %!&
Figure 1: The (simplified) syntactic structure of the sen-
tence ?Valori di temperatura superiori alla media? (Tem-
perature values exceed the average) produced by the TUP
parser.
In order to reduce the difficulties of our project we
concentrated on a specific application domain, i.e.
weather forecasts: a group of linguists produced a
small parallel corpus (300 sentences) of Italian-LIS
sentences extracted from TV news and concerning
weather forecasts. Building vocal-SL parallel cor-
pora is a hard task: there are theoretical difficulties
concerning the extra-video annotation. In particu-
lar, while there are standards for the representation
of the phonological information of the signs, there
are no standard ways to represent their morpho-
syntactic inflections. The corpus has been used pri-
marily to produce an electronic dictionary for the
virtual interpreter consisting of about 1500 signs,
that provides a lexicon for the realizer too. In con-
trast, most of the knowledge about LIS syntax comes
from discussions with some linguists.
2 Parsing and Interpretation
Our interlingua translation system is a chain com-
posed of four distinct modules, that are: (1) a de-
pendency parser for Italian; (2) an ontology based
semantic interpreter; (3) a generator; (4) a virtual
actor that performs the synthesis of the final LIS sen-
tence. In this Section we give some details about the
105
parser and the semantic interpreter, in Sections 3 and
4 we describe the generator.
In the first step, the syntactic structure of the
source language is produced by the TUP, a rule-
based parser (Lesmo, 2007). The TUP is based on
a morphological dictionary of Italian (about 25, 000
lemmata) and a rule-based grammar, and it produces
a dependency tree, that makes clear the structural
syntactic relationships occurring between the words
of the sentence. Each word in the source sentence is
associated with a node of the tree, and the nodes are
linked via labeled arcs that specify the syntactic role
of the dependents with respect to their head (the par-
ent node). In Figure 1 we show the syntactic analy-
sis for the sentence ?Valori di temperatura superiori
alla media? (rough translation: Temperature values
exceed the average). The edge label ?ARG? indi-
cates an ARGument relation, i.e. an obligatory rela-
tion between the head and its argument. The edge
label ?RMOD? indicates a Restricting MODifier re-
lation, i.e. a non obligatory relation from the head
and its dependent (Bosco and Lombardo, 2004).
! !
!!"##$%&'()*+,-%.+/!"#!!,.0#"1%2.+(1&$"-%.+/!"$
!"3&1"4&/%"#!!0"-5(3"$*&/!"&!41&"-&1(-5"+/%"$!!0&"2*1&'(3"$*&/!"'
()*+,-./,0 ()*+,-./,"()*+,*1 (-11,234,5-6 (234)7*.
Figure 2: The fragment of the semantic network resulting
from the interpretation of the sentence ?Valori di temper-
atura superiori alla media?.
The second step of the translation is the seman-
tic interpretation: the syntax-semantics interface is
based on ontologies (Lesmo et al, 2011). The
knowledge in the ontology, which has been designed
for this specific application, concerns the application
domain, i.e. weather forecasts, as well as more gen-
eral common knowledge about the world. Note that
the ontology used by the semantic interpreter is not
the same ontology used by the generator (microplan-
ner and realizer): indeed, whilst the semantic inter-
preter ontology describes the linguistic knowledge
of the Italian language, the generator describes the
linguistic knowledge of the LIS. Starting from the
lexical semantics of the words and on the basis of the
dependency structure, a recursive function searches
in the ontology providing a number of ?connection
paths? that represent the meaning. In fact, the final
sentence meaning consists of a complex fragment of
the ontology, i.e. a single connected semantic net-
work (Lesmo et al, 2011). In Figure 2 we show a
fragment of the semantic network resulting from the
interpretation of the sentence ?Valori di temperatura
superiori alla media?. The nodes of the network con-
tain instances (prefix name ?), concepts (prefix name
??) relations (prefix name &) from the ontology. In
Figure 2 the nodes AVERAGE, GRATER-THAN are in-
stances, the other nodes are concepts. Informally
speaking, we can say that the semantic interpreter
organizes the information of the semantic network
as a number of ?information chunks? that are weakly
connected to the other parts of the network. In the
network of Figure 2 we can distinguish two chunks.
The paraphrase of these chuncks meanings is: there
is a (temperature) value involved in a comparison
(chunk 1) with a mathematical value that is the aver-
age (chunk 2). In the next section we describe how
the microplanner manages this organization of the
information.
3 The SentenceDesigner microplanner
In a previous version of our system we assumed
that the semantic network encoded a single chunk of
meaning expressing the semantics of the event only
in terms of predicate-arguments. The working hy-
pothesis was to assume a one-to-one sentence align-
ment between source and target sentences. This sim-
plification assumption allowed for a trivial genera-
tion architecture that did not have a microplanning
phase at all, and just delegated a simple form of lex-
icalization to the realizer. However, newer version
of the semantic interpreter produced more complex
semantic networks. Therefore, in our project we re-
move the previous assumption and in this Section we
describe SentenceDesigner, a rule-based microplan-
ner. SentenceDesigner basically performs the fol-
lowing three-steps algorithm:
1. Segmentation
a. Split the semantic network
into atomic messages
2. Lexicalization
For each message:
a. Introduce prelexical nodes
b. Introduce syntactic relations
between prelexical nodes
3. Simplification
106
For each message:
a. Extend syntactic relations
among messages
b. Remove non-necessary
prelexical nodes
c. Remove repetitions
among messages
d. Remove semantic relations
and reorder messages
In the first step SentenceDesigner split the seman-
tic networks into a number of subgraphs: the idea
is to recognize which parts of the network con-
tain an atomic message, i.e. a complete information
chunk, that can potentially be generated as a sin-
gular sentence. SentenceDesigner uses a very sim-
ple heuristic for this step: a message is a subtree
of the network, i.e. a root-node together with all of
its descendants in the network. We call root-node a
node that does not have any parent: in Figure 2 the
nodes COMPARISON-RELATION, APPLIED-FUNCTION
are root-nodes. Note that some nodes belong to sev-
eral distinct messages: for example the MATH-VALUE
belongs to the messages rooted by COMPARISON-
RELATION and APPLIED-FUNCTION respectively.
! !
!"#$%&'#(%&'#)*+,-./01+2)/34.50+2(!6((!7#89:;<=)7;9;#(((((!:98#(>>*+,-./01+2)/34.50+26(!9%?)@(AB@66((!7#89:;<=)%#'9;<C:(!:98#(D*+,-./)./E@6(!9%?)@(AB@6(!9%?)F(ABF66((!7#89:;<=)%#'9;<C:(!:98#(D*+,-./)./EF6(!9%?)@(AB@6(!9%?)F(ABG66((!7#89:;<=)%#'9;<C:(!:98#(D*+,-./)+-6((((((!9%?)@(AB@6(!9%?)F(ABH66(((((IJ((!977#%;(!7K:;9=;<=)%#'9;<C:(!:98#(1L2)1MNO6(!9%?)@(ABH6(!9%?)F(ABF666((((!977#%;(!7K:;9=;<=)%#'9;<C:(!:98#(1L2)+NO6(((!9%?)@(ABH6(!9%?)F(ABG6666
!"#$%&'#(%&'#).--403P)QM2*50+2(!6((!7#89:;<=)7;9;#(((((!:98#(>>.--403P)QM2*50+26(!9%?)@(AB@66((!7#89:;<=)%#'9;<C:(!:98#(DQM2*5+/6(!9%?)@(AB@6(!9%?)F(ABF66((!7#89:;<=)%#'9;<C:(!:98#(D.--403P)QM2*50+2)R.4M36(!9%?)@(AB@6(((!9%?)F(ABG66((((((IJ((!977#%;(!7K:;9=;<=)%#'9;<C:(!:98#(1L2)/,+P6((!9%?)@(ABG6(!9%?)F(ABF6666
Figure 3: Two rules of the knowledge-base used by the
expert system for lexicalization.
In the second step, that corresponds to ?lexical-
ization? (Reiter and Dale, 2000), SentenceDesigner
performs two distinct procedures for each message.
The procedure 2-a. introduces new prelexical nodes
in the message that will be treated as lexical items
in the realization phase. Also in this case we have
a very simple heuristic that associates one-to-one
prelexical nodes to concepts and instances. The
prelexical nodes are organized into a lexical ontol-
ogy that is shared with the realizer: in this way
the microplanner informs the realizer of the selec-
tional restrictions that the semantics imposes on the
syntactic behaviour of lexical nodes (e.g. colloca-
tions). For example, the prelexical node value be-
longing to the class evaluable-entity is in-
troduced in place to the concept MATH-VALUE. Note
that currently we are not yet able to deal with re-
ferring expressions generation for instances, i.e. we
uniformly treat concepts and instances: in future we
plan to integrate into the system a specific module
for this task. The procedure 2-b. concerns the in-
troduction of syntactic relations between prelexical
nodes. This is a very complex and critical task: on
the one hand we need to encode the linguistic knowl-
edge produced by the corpus analysis (see below)
and by many discussions with linguists; on the other
hand we need to account for the behaviour of these
relations in the CCG used by the realizer. In order
to manage this complexity we decided to use an ex-
pert system (Stefik et al, 1982).2 Indeed, expert sys-
tems allow for a sharp modularization of the knowl-
edge and allow for a clear resolution of conflicts:
we needed several revisions of our formalization and
expert systems speed-up this process. In Figure 3 we
show two rules that are ?fired? by SentenceDesigner
during the microplanning of the semantic network in
Figure 2: the first rule encodes the comparison se-
mantic relation into one subject (SYN-SUBJ) and one
object (SYN-OBJ) syntactic relations; the second rule
encodes the semantic relation concerning a math-
ematical value as a modifier (SYN-RMOD) relation.
The actual implementation of the system consists of
about 50 rules and very complex rules are necessary
for particular syntactic constructions as coordination
or subordinate clauses, i.e. to manage aggregation.
The third step of the algorithm concerns the sim-
plification of the messages built in the previous step.
In 3-a. we ?propagate? the syntactic relations among
the various messages: if a prelexical node belongs
to various messages, then all the syntactic relations
starting from that node will be replicated in all the
messages. For example, the prelexical node aver-
age is replicated in the message rooted by the node
COMPARISON-RELATION, since value is connected
to the prelexical node average by the syntactic re-
2In particular, since SentenceDesigner is written in lisp, we
used the LISA expert system. This is an implementation of the
RETE algorithm compliant with Common lisp Specifications
(Young, 2007).
107
lation modifier in the message rooted by the node
APPLIED-FUNCTION. In 3-b., we remove non neces-
sary prelexical nodes: corpus analysis showed that
LIS often is ?lexically simpler? with respect to the
corresponding Italian sentence, and in order to pro-
duce fluent LIS sentences we need to remove some
prelexical nodes. For example, the Italian phrase
?valori di temperatura? (values of temperature) is
translated by omitting the sign for ?valore?. In 3-c.,
we remove messages that are properly included in
other messages: this can happen as a consequence
of the procedure 3-a. For example, at this stage
the syntactic information of the message rooted by
the node APPLIED-FUNCTION is properly contained
in the message rooted by the node COMPARISON-
RELATION. In 3-d., we remove the semantic relations
and reorder the remaining messages on the basis of
a simple heuristics: for example, temporal informa-
tion will be passed first to the realizer. The final
! !
!"#$%&'&()*'+',*!"#$%"#&""'
-".$&/+0,+10&)&2'3'4!"#$%(")*"+,(-+" -"5$&/+0,+10&)&2'3'4!"#$%.,!-"
!"6$&/+0,+10&)&2'3'4!"#$,."+,/"
01230-45 0123645
0123+)6'
Figure 4: A fragment of the output of SentenceDesigner
on the by the semantic network of Figure 2.
result of SentenceDesigner consists of a number of
syntactic messages, i.e. a number of abstract syntax
trees: each tree will be realized as single sentence
(Reiter and Dale, 2000). In Figure 4 there are the
abstract syntax tree produced by SentenceDesigner
on the input given by the semantic network of Fig-
ure 2.
4 A CCG for LIS
In our architecture we use the OpenCCG realizer
(White, 2006), an open source tool that is based
on categorial grammars (CCG) (Steedman, 2000).
Some previous works on translation to SL accounted
for typical syntactic phenomena by using lexical-
ized grammars and feature unification too (Veale
and Conway, 1994; Zhao et al, 2000; Huener-
fauth, 2006). However we use the OpenCCG since
it allows us to encode the LIS inflectional system
by using features in the syntactic categories. The
! !
!"!"#$% #$%$!"!"&$%!%$!"!"#$% !
#$%$!"!"&$%$
#
!"$"#$%
!
#$'()*+&,-&+'&$.+/,0'#$1+.*+&01)&0'&$ 20#-&+'#$
!"!"#$%
!"!"#$%!%$!"!"#$% "#!
!"$"&$%
Figure 5: The realization of the LIS sentence
?TEMPERATURA R2 VALORE L2 MEDIA L2
L2 SUPERIORE R2?.
integration in one single elementary structure of
morphology-syntax-semantics is appealing for SLs,
where the absence of function words increases the
importance of morpho-syntactic features to express
the correct meaning of the sentence.
A challenging requirement of our project is that
the SLs do not have a natural written form. As
a consequence we developed an artificial written
form for LIS. Our electronic lexicon is stored into
a database, such that an entry consists of a unique
alphanumeric ID. However, for the sake of clarity
here we write a LIS sentence just as a sequence of
glosses. We use names (in uppercase) for the glosses
that are related to their rough translation into Ital-
ian. The only feature that we explicitly represent in
glosses is the spatial position of the sign (cf. (Zhao
et al, 2000)). We assume a discrete horizontal di-
mension consisting of seven positions L1 (the left-
most position), L2, L3, N (the neutral position), R3,
R2, R1 (the rightmost position).
Similarly to American SL, in LIS we can tell a
number of verb classes on the basis of spatial ac-
cord (Volterra, 2004; Wright, 2008; Brentani, 2010).
For instance the verb Li SUPERIORE Rj (exceed)
belongs to the class II-A, i.e. it is a transitive verb
such that the starting position of the sign (Li) co-
incides with the position of the subject, as well as
the ending position of the sign (Rj) coincides with
the position of the object (Volterra, 2004). Sim-
ilarly to (Wright, 2008), we model LIS linguistic
phenomenon in CCG by using a morphological fea-
ture. This feature encodes the position of the noun in
the atomic category NP , as well as the starting and
ending position of a verb in the complex category
S\NP\NP (in accord with (Geraci, 2004) and in
contrast to (Volterra, 2004) we assume that LIS re-
spects the SOV order). In Fig. 5 we show the re-
108
alization of the LIS sentence ?TEMPERATURA R2
VALORE L2 MEDIA L2 L2 SUPERIORE R2? by
using the abstract syntactic tree in Figure 4. The
feature unification mechanism constraints the NP ar-
guments to agree with the starting and ending po-
sition of the verb: the subject TEMPERATURA is
signed in the position R2, i.e. the starting position
of the verb SUPERIORE, while the object MEDIA
is signed in the position L2, i.e. the ending position
of the verb. More details about our formalization of
verb-arguments and NP-coordination in LIS can be
found in (Mazzei, 2011).
5 Conclusions
In this paper we have presented a generator for
LIS adopted into a symbolic translation architecture.
The generator is composed by a expert-system based
microplanner and a CCG based realizer. The expert-
system allows us to manage and update the knowl-
edge provided by linguists and derived from corpus
analysis. CCG allowed for a clear formalization of
LIS syntax.
While the design of a quantitative evaluation of
the system is still in progress, a preliminary quali-
tative evaluation provided us some information. In
particular, two native LIS signers give a positive
evaluation about the space allocation of the signs but
give a negative feedback on modifiers word order.
Acknowledgments
This work has been partially supported by the AT-
LAS project, that is co-funded by Regione Piemonte
within the ?Converging Technologies - CIPE 2007?
framework (Research Sector: Cognitive Science and
ICT).
References
Cristina Bosco and Vincenzo Lombardo. 2004. De-
pendency and relational structure in treebank annota-
tion. In Proc. of the COLING?04 workshop on Recent
Advances in Dependency Grammar, Geneve, Switzer-
land.
Dana Brentani, editor. 2010. Sign Languages. Cam-
bridge University Press.
Carlo Geraci. 2004. L?ordine delle parole nella LIS (lin-
gua dei segni italiana). In Convegno nazionale della
Societa` di Linguistica Italiana.
Matt Huenerfauth. 2006. Generating American Sign
Language classifier predicates for english-to-asl ma-
chine translation. Ph.D. thesis, University of Pennsyl-
vania.
Leonardo Lesmo, Alessandro Mazzei, and Daniele P.
Radicioni. 2011. An ontology based architecture
for translation. In Proceedings of the Ninth Interna-
tional Conference on Computational Semantics (IWCS
2011), The University of Oxford.
Leonardo Lesmo. 2007. The Rule-Based Parser of the
NLP Group of the University of Torino. Intelligenza
Artificiale, 2(4):46?47, June.
Alessandro Mazzei. 2011. Building a generator for ital-
ian sign language. In Proceedings of the 13th Eu-
ropean Workshop on Natural Language Generation,
pages 170?175, Nancy, France, September. Associa-
tion for Computational Linguistics.
Ehud Reiter and Robert Dale. 2000. Building natural
language generation systems. Cambridge University
Press, New York, NY, USA.
Mark Steedman. 2000. The syntactic process. MIT
Press, Cambridge, MA, USA.
Mark Stefik, Jan Aikins, Robert Balzer, John Benoit,
Lawrence Birnbaum, Frederick Hayes-Roth, and
Earl D. Sacerdoti. 1982. The organization of expert
systems, a tutorial. Artif. Intell., 18(2):135?173.
Tony Veale and Alan Conway. 1994. Cross modal com-
prehension in zardoz an english to sign-language trans-
lation system. In Proceedings of the Seventh Inter-
national Workshop on Natural Language Generation,
INLG ?94, pages 249?252, Stroudsburg, PA, USA. As-
sociation for Computational Linguistics.
Virginia Volterra, editor. 2004. La lingua dei segni ital-
iana. Il Mulino.
Michael White. 2006. Efficient realization of co-
ordinate structures in combinatory categorial gram-
mar. Research on Language and Computation,
2006(4(1)):39?75.
Tony Wright. 2008. A combinatory categorial grammar
of a fragment of american sign language. In Proc. of
the Texas Linguistics Society X Conference. CSLI Pub-
lications.
David E. Young. 2007. The Lisa Project.
http://lisa.sourceforge.net/.
Liwei Zhao, Karin Kipper, William Schuler, Christian
Vogler, Norman I. Badler, and Martha Palmer. 2000.
A machine translation system from english to ameri-
can sign language. In Proceedings of the 4th Confer-
ence of the Association for Machine Translation in the
Americas on Envisioning Machine Translation in the
Information Future, AMTA ?00, pages 54?67, Lon-
don, UK, UK. Springer-Verlag.
109
