Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational
Natural Language Learning, pp. 847?857, Prague, June 2007. c?2007 Association for Computational Linguistics
Multiple Alignment of Citation Sentences with
Conditional Random Fields and Posterior Decoding
Ariel S. Schwartz?
EECS, Computer Science Division
UC Berkeley
Berkeley, CA 94720-1776
sariel@cs.berkeley.edu
Anna Divoli, Marti A. Hearst
School of Information
UC Berkeley
Berkeley, CA 94720-4600
{hearst,divoli}@ischool.berkeley.edu
Abstract
In scientific literature, sentences that cite re-
lated work can be a valuable resource for
applications such as summarization, syn-
onym identification, and entity extraction.
In order to determine which equivalent en-
tities are discussed in the various citation
sentences, we propose aligning the words
within these sentences according to semantic
similarity. This problem is partly analogous
to the problem of multiple sequence align-
ment in the biosciences, and is also closely
related to the word alignment problem in sta-
tistical machine translation. In this paper
we address the problem of multiple citation
concept alignment by combining and mod-
ifying the CRF based pairwise word align-
ment system of Blunsom & Cohn (2006)
and a posterior decoding based multiple se-
quence alignment algorithm of Schwartz &
Pachter (2007). We evaluate the algorithm
on hand-labeled data, achieving results that
improve on a baseline.
1 Introduction
The scientific literature of biomedicine, genomics,
and other biosciences is a rich, complex, and con-
tinually growing resource. With appropriate infor-
mation extraction and retrieval tools, bioscience re-
searchers can use the contents of the literature to
further their research goals. With online full text
?Current address: Department of Bioengineering, Univer-
sity of California, San Diego, La Jolla, CA 92093-0412. Email:
sariel@ucsd.edu.
of journal articles finally becoming the norm, new
forms of citation analysis become possible.
Nearly every statement in biology articles is
backed up by at least one citation, and, conversely,
it is quite common for papers in the bioscience do-
main to be cited by 30?100 other papers. The cited
facts are typically stated in a more concise way in the
citing papers than in the original papers. Since the
same facts are repeatedly stated in different ways in
different papers, statistical models can be trained on
existing citation sentences to identify similar facts in
unseen text. Citation sentences also have the poten-
tial to be useful for text summarization and database
curation. Figure 1 shows an example of three differ-
ent citation sentences to the same target paper.
Most citation analysis work focuses on the cita-
tion network structure, to determine which papers
are most central, or uses co-citation analysis to de-
termine which papers are similar to one another in
content (White, 2004; Liu, 1993; Garfield, 1955;
Lipetz, 1965; Giles et al, 1998). In this paper we
focus instead on analyzing the sentences that sur-
round the citations to related work, which we termed
citances in Nakov et al (2004). In that paper we
note that one subproblem for using citances for au-
tomated analysis is to identify the different concepts
mentioned; a given paper may be cited for more than
one fact or relation.
Citances often state similar information using
varying words and phrases. In order to build con-
cise summaries, those entities and relations that are
expressed in different ways should be matched up,
or aligned, so that subsequent processing steps will
know what the core concepts are. In this paper we
847
Exam
ple o
f una
ligne
d cit
ance
s
?In r
espo
nse t
o ge
noto
xics
tress
, Ch
k1 a
nd C
hk2 
phos
phor
ylate
Cdc
25A
 on N
-term
inal 
sites
 and
 targ
et it 
rapid
ly fo
r ubi
quiti
n-de
pend
ent d
egra
datio
n (M
ailan
det 
al, 2
000,
 200
2; 
Mol
inari
et al
, 200
0 ; Fa
lcke
t al, 
2001
; Shi
muta
et al
, 200
2; B
usin
oet 
al, 2
003)
, wh
ich i
s 
thou
ght t
o be
 cen
tral t
o the
 S an
d G2
 cell
 cyc
le ch
eckp
oints
 (Ba
rtek
and 
Luk
as, 2
003;
 
Don
zelli
and 
Drae
tta, 2
003 )
.?
?Giv
en th
at C
hk1 
prom
otes
 Cdc
25A
 turn
over
 in r
espo
nse t
o DN
Ada
mag
e in 
vivo
 
(Fal
cke
t al. 
2001
; Sor
ense
n et 
al. 2
003)
 and
that 
Chk
1 is 
requ
ired 
for C
dc25
A 
ubiq
uitin
ation
by S
CF?-T
RCP
 in v
itro,
 we 
expl
ored
 the 
role 
of C
dc25
A 
phos
phor
ylati
onin
the u
biqu
itina
tion
proc
ess.?
?Sin
ce ac
tivat
ed p
hosp
hory
lated
Chk
2-T68
is in
volv
ed in
 pho
spho
rylat
iona
nd 
degr
adat
ion o
f Cd
c25A
 (Fal
cke
t al.,
 200
1 , Fa
lcke
t al.,
2002
; Ba
rtek
and 
Luk
as, 
2003
), we
 also
 exa
mine
d the
 leve
ls of
Cdc
25A
 in 2
fTG
H an
d U3
A ce
lls e
xpos
ed to
 
?-IR.?
Figure 1: Example of three unaligned citances.
Alig
nme
nt af
ter n
orm
aliza
tion
resp
onse
geno
toxi
cstr
essC
hk1
 Chk
2ph
osph
oryl
ateC
dc25
AN
 term
inal
 site
s tar
get 
rapi
dly u
biqu
itin
depe
nden
tdeg
rada
tion
thou
ght 
cent
ral S
 G2 
cell 
cycl
e ch
eckp
oint
s
Give
n Ch
k1p
rom
otes
 Cdc
25A
turn
over
resp
onse
DNA
 dam
age
vivo
 Chk
1re
quir
ed
Cdc
25A
ubiq
uitin
atio
nSC
F be
ta T
RCP
 vitr
o ex
plor
edr
ole C
dc25
Aph
osph
oryl
atio
n
ubiq
uitin
atio
npr
oces
s
activ
ated
 pho
spho
ryla
tedC
hk2
T68
invo
lved
 pho
spho
ryla
tion
degr
adat
ionC
dc25
A
exam
ined
leve
ls C
dc25
A2f
TGH
 U3A
 cell
s exp
osed
 gam
ma I
R
Figure 2: Example of three normalized aligned ci-
tances. Homologous entities are colored the same.
Unaligned entities are black.
build on the work of Nakov et al (2004) by tackling
the entity normalization step.
The citance alignment problem is partially anal-
ogous to the problem of multiple alignment of bi-
ological sequences (Durbin et al, 1998). In both
cases the goal is to align homologous entities that
are derived from the same ancestral entity. While in
biology homology is well-defined in the molecular
level, in the citances case it is defined in the seman-
tic level, which is much more subjective. Given a
group of citances that cite the same target paper, we
loosely define semantic homology as a symmetric,
transitive, and reflexive relation between two enti-
ties (words or phrases) in the same or different ci-
tance that have similar semantics in the context of
the cited paper.
Figure 1 shows an example of three citances that
cite the same target paper (Falck et al, 2001). A
multiple alignment of the entities in the same ci-
tances (after removal of stopwords) is shown in Fig-
ure 2. Homologous entities are colored the same.
This small example illustrates some of the main
challenges of multiple citance alignment (MCA).
While orthographic similarity can help to identify
semantic homology (e.g., phosphorylate and phos-
phorylation), it can also be misleading (e.g., cell cy-
cle and U3A cells). In addition, semantic homology
might not include any orthographic clues (e.g., geno-
toxic stress and DNA damage).
Unlike global multiple sequence alignment
(MSA) in genomics, where each character can be
aligned to at most one character in every other se-
quence, in multiple citance alignment, each word
can be aligned to any number of words in other sen-
tences. Another major difference between the two
problems is the fact that while the sequential order-
ing of characters must be maintained in multiple se-
quence alignment, this is not the case for multiple
citance alignment.
MCA is also related to the problem of word align-
ment in statistical machine translation (SMT) (Och
and Ney, 2003). However, unlike SMT alignment,
MCA aligns multiple citances in the same language
rather than a pair of sentences in different languages.
In this paper we present an MCA algorithm that
is based on an extension to the posterior decoding
algorithm for MSA called AMAP (Schwartz et al,
2006; Schwartz and Pachter, 2007), with an under-
lying pairwise alignment model based on the CRF
SMT alignment of Blunsom & Cohn (2006).
2 Multiple citance alignments
Let G , {C1, C2, . . . , CK} be a group of K ci-
tances that cite the same target paper, where the ith
citance is a sequence of words Ci , Ci1C
i
2 ? ? ?C
i
ni ,
and ci , {ci1, c
i
2, . . . , c
i
ni} is the set of word indices
of Ci. A pairwise citance alignment of Ci and Cj
is an equivalence (symmetric, reflexive, and transi-
tive) relation ?ij on the set ci ? cj . The expres-
sion cik ?ij c
j
l means that according to the pairwise
alignment?ij word k in citance Ci and word l in ci-
tance Cj are aligned. A multiple citance alignment
(MCA) is an equivalence relation ?,
(?
ij ?ij
)+
on the set
?
i c
i, which is the transitive closure of
the union of all pairwise alignments of citance pairs
in G. Taking the transitive closure and not only
the union of all pairwise alignments ensures that the
MCA is an equivalence relation.
An MCA ? defines a partition of the set of all
word indices c ,
?
ik {c
i
k}, which is of size n ,
848
|c| =
?
i n
i. Therefore, the number of distinct
MCAs of G is the number of partitions of a set of
size n. This number is called the nth Bell number
(Rota, 1964)
Bn ,
1
e
??
k=0
kn
k!
. (1)
Asymptotically,Bn grows faster than an exponential
but slower than a factorial. For example B100 ?
10116. Obviously, enumerating all possible MCAs
is impractical even for small problems.
3 Probabilistic model for MCA
Unlike biological sequences, for which pair-HMMs
are a natural choice for modeling evolutionary pro-
cesses between two sequences, there is no simple
generative model that can be used for modeling
pairwise citance alignment. Most of the work on
pairwise alignment of sentences at the word level
has been done in the statistical machine translation
(SMT) community.
Och & Ney (2003) present an overview and com-
parison of the most common models used for SMT
word alignments. Out of the models they describe,
the HMM models are the most expressive mod-
els that can compute posterior probabilities using
the forward-backward algorithm. However, unlike
sequence alignments, there are no ordering con-
straints in word alignments, and the alignments are
many-to-many as opposed to one-to-one. Therefore,
the SMT HMM models cannot be based on pair-
HMMs, which generate two sentences simultane-
ously. Rather, they are directional models that model
the probability of generating a target sentence given
a source sentence. In other words they only model
many-to-one alignments, recovering the many-to-
many alignments in a preprocessing step. Therefore,
SMT HMMs can only compute the posterior proba-
bilities P (cik ; c
j
l |C
i, Cj) and P (cjl ; c
i
k|C
i, Cj),
where the relation ; represents the (directional)
event that a source word is translated into a target
word. Nevertheless, recently such posterior proba-
bilities have been used in SMT word alignment sys-
tem as an alternative to Viterbi decoding, and helped
to improve the performance of such systems (Ma-
tusov et al, 2004; Liang et al, 2006).
Generative models like HMMs have several lim-
itations. First, they require relatively large train-
ing data, which is difficult to attain in case of SMT
word alignment, and even more so in the case of
MCA. Second, generative models explicitly model
the inter-dependence of different features, which re-
duces the ability to incorporate multiple arbitrary
features into the model. Since orthographic similar-
ity is not a strong enough indication for semantic ho-
mology in MCA, we would like to be able to incor-
porate multiple inter-dependent features into a single
model, including orthographic, contextual, ontolog-
ical, and lexical features.
Recently, several authors have described dis-
criminative SMT alignment models (Moore, 2005;
Lacoste-Julien et al, 2006; Blunsom and Cohn,
2006). However, to the best of our knowledge only
the model of Blunsom & Cohn (2006), which is
based on a Conditional Random Field (CRF) (Laf-
ferty et al, 2001), can compute word indices pairs?
directional posterior probabilities, like those com-
puted by the HMM models. Therefore, we decided
to adopt the CRF-based model to the MCA problem.
3.1 Conditional random fields for word
alignment
The model of Blunsom & Cohn (2006) is based on
a linear chain CRF, which can be viewed as the
undirected version of an HMM. The CRF models
a many-to-one pairwise alignment, in which every
source word can get algned to zero or one target
words, but every word in the target sentence can be
the target of multiple source words. CRFs define
a conditional distribution over a latent labeling se-
quence given observation sequence(s). In the case
of CRF for word alignment, the observed sequences
are the source and target sentences (citances), and
the latent labeling sequence is the mapping of source
words to target word-indices. Given a source citance
Ci of length ni, and a target citance Cj of length nj ,
the many-to-one alignment of Ci to Cj is the rela-
tion ;. Since this is a many-to-one alignment, ;
can be represented by a vector a of length ni. The
CRF models the probability of the alignment a con-
ditioned on Ci and Cj as follows:
P?(a|C
i, Cj) =
exp
(?
t
?
k ?kfk(t, at?1, at, C
i, Cj)
)
Z?(Ci, Cj)
, (2)
849
where f , {fk} are the model?s features, ? , {?k}
are the features? weights, and Z?(Ci, Cj) is the par-
tition (normalization) function which is defined as:
Z?(C
i, Cj) ,
?
a
exp
(
?
t
?
k
?kfk(t, at?1, at, C
i, Cj)
)
.
(3)
Parameters are estimated from fully observed data
(manually aligned citances) using a maximum a pos-
teriori estimate. The parameter estimation proce-
dure is described in more details in the original pa-
per. Blunsom & Cohn (2006) use Viterbi decoding
to find an alignment of two sentences given a trained
CRF model, a? , argmaxa P?(a|C
i, Cj). How-
ever, the posterior probabilities of the labels at each
position can be calculated as well using the forward-
backward algorithm:
P?(c
i
l ; c
j
k|C
i, Cj) = P?(al = c
j
k|C
i, Cj) =
?l(c
j
k|C
i, Cj)?l(c
j
k|C
i, Cj)
Z?(Ci, Cj)
(4)
where ?l and ?l are the forward and backward vec-
tors that are computed with the forward-backward
algorithm (Lafferty et al, 2001).
3.2 The posterior decoding algorithm for MCA
Ultimately, the success of an MCA algorithm should
be judged by its effect on the success of the citance
analysis systems that use MCAs as their input. How-
ever, measuring this effect directly is difficult, since
high-level tasks such as summarization are difficult
to evaluate objectively. More to the point, it is dif-
ficult to quantify the contribution of the MCA ac-
curacy to the accuracy of the high-level system that
uses it. A more practical alternative is to measure the
accuracy of MCAs directly using a meaningful ac-
curacy measure, under the simplifying assumption
that there is a strong correlation between the mea-
sured MCA accuracy and the performance of the
high-level application.
We argue that a useful utility function should be
correlated (or even identical) to the accuracy mea-
sure used to evaluate the performance of an algo-
rithm. In addition, the utility function should be
easily decomposable, to enable direct optimization
using posterior-decoding. Although any accuracy
measure that is acceptable as a single performance
measure can be used to guide the design of the util-
ity function, metric-based accuracy measures have
several noticeable advantages. First, a metric for-
malizes the intuitive notion of distance. Hence, an
accuracy measure which is based on a metric fol-
lows the intuition that reducing the distance to the
correct answer should increase the accuracy of the
predicted answer. Therefore, defining a metric space
for the objects of a given problem leads to a nat-
ural definition of accuracy. Another advantage of
using a metric-based accuracy measure is the abil-
ity to provide bounds in the search space using the
triangle inequality. For example, while searching for
the answer with the optimal (metric-based) expected
utility, a step of length x can only change the ex-
pected utility as well as the actual utility by at most
?x units. Examples of more complex bounds us-
ing metric loss functions are described in (Schlu?ter
et al, 2005) and (Domingos, 2000).
Schwartz et al (2006) define the alignment met-
ric accuracy (AMA), which is a utility function for
one-to-one MSA. Intuitively, AMA measures the
fraction of characters that are aligned correctly ac-
cording to the reference alignment, either to another
character or to a gap (null). We extend the definition
of AMA to the case of many-to-many MCA.
A good utility function for MCA should give par-
tial credit to word positions that align to some of the
correct word positions while penalizing for aligning
to wrong word positions. To help define such a util-
ity function we define the following. Let mij?(c
j
l ) ,
{cik ? c
i|cik ? c
j
l } be the set of all word positions
in citance Ci that align to word position l in citance
Cj according to MCA ?. We can then define the
following utility function for the MCA ?p of the ci-
tance group G given a reference MCA ?r:
UAMA(?
r,?p) ,
?
ijl|i6=j Uset agreement
(
mij?r(c
j
l ),m
ij
?p(c
j
l )
)
n(K ? 1)
, (5)
where n is the number of word indices in G, K ,
|G| is the number of citances in the group, and
Uset agreement is any utility function for agreement
between sets that assigns values in the range [0, 1].
850
Uset agreement can be viewed as a ?score? assigned
to each word position based on the agreement be-
tween the two alignments with regards to the other
word positions that align to it. Using a 0?1 loss as
the set agreement score is equivalent to the original
AMA. Other utility functions, such as Dice, Jaccard
and Hamming can be used as Uset agreement. How-
ever, only metric-based utility functions will result
in a metric-based UAMA utility function. It is easy
to see that 1 ? UAMA satisfies all the requirements
of a metric, i.e., it is non-negative, equals zero if
and only if ?r=?p, symmetric, and obeys the trian-
gle inequality, since if the triangle inequality holds
for 1 ? Uset agreement, it must hold for a sum of
1 ? Uset agreement values. (We refer the reader to
Schwartz (2007) for a longer discussion of the prop-
erties of the different utility functions.) We define
the AMA for MCA by setting the Uset agreement to
be the Braun-Blanquet coefficient (Braun-Blanquet,
1932), which is defined as:
UBraun?Blanquet
(
mij?r(c
j
l ),m
ij
?p(c
j
l )
)
,
?
???
???
1 if mij?r(c
j
l ) = ?
and mij?p(c
j
l ) = ?
|mij?r (c
j
l )?m
ij
?p (c
j
l )|
max{|mij?r (c
j
l )|,|m
ij
?p (c
j
l )|}
otherwise
.
(6)
Caillez & Kuntz (1996) show that the Braun-
Blanquet coefficient is based on a metric.
As with the MSA case, a family of utility func-
tions can be defined to enable control of the re-
call/precision trade-off. Unlike MSA, in the case of
MCA two free parameters are needed, in order to
have better control of the trade-off using posterior-
decoding. In addition to a gap-factor that controls
the threshold at which unaligned words start to get
aligned, a match-factor is added to enable control of
the number of word-positions each word aligns to.
The result is the following utility function:
U?,?(?
r,?p) ,
1
n(K ? 1)
?
ijl|i6=j
(
?|m
ij
?p (c
j
l )|
|mij?r(c
j
l ) ?m
ij
?p(c
j
l )|
max
{
|mij?r(c
j
l )|, |m
ij
?p(c
j
l )|, 1
}+
?1{mij?r(c
j
l ) = m
ij
?p(c
j
l ) = ?}
)
, (7)
where ? ? [0,?) is a gap-factor, and ? ? (0,?) is
a match factor. The neutral value for both parame-
ters is 1. Increasing ? results in increased utility to
sparser MCAs, while reducing ? increases the util-
ity of denser alignments. However, in the case of
MCA, the gap-factor only affects the first aligned
word position, but it cannot affect the number of
word positions each word is aligned to. The match-
factor adds this functionality by rewarding MCAs
that align words to multiple word positions when
? > 1, and penalizing such MCAs when ? < 1.
Given a group of K citances G and a trained
CRF model, the goal of the MCA algorithm is to
find the MCA ??, argmax?p E?tU?,?(?
t,?p)
that maximizes the expected utility. Since search-
ing the space of possible MCAs exhaustively is in-
feasible, we resort to a simple heuristic for predict-
ing an MCA. Instead of searching for a global opti-
mum, the predicted MCA is defined as the equiva-
lence (symmetric transitive) closure of the union of
multiple local optima. For each target word posi-
tion cjl and every source citance C
i the combina-
tion of source word positions ci? that maximize the
expected set-agreement score of cjl is added to the
predicted MCA. Formally, let P(ci) be the power-
set of ci, then we define the predicted MCA as
?p,
(
;p ?(;p)?1
)+
, where;p is defined as:
;p,
?
ijl|i6=j
{cjl } ? argmax
ci??P(ci)
Emij
?t
(cjl )
?
??|c
i
?|
|mij?t(c
j
l ) ? c
i
?|
max
{
|mij?t(c
j
l )|, |c
i
?|, 1
}+
?1{mij?t(c
j
l ) = c
i
? = ?}
)
. (8)
The value of ;p can be computed from the CRF
directional posterior probabilities as follows:
;p=
?
ijl|i6=j
{cjl } ? argmax
ci??P(ci)
?
ci??P(ci)
P
(
mij?t(c
j
l ) = c
i
?
)
(
?|c
i
?|
|ci? ? c
i
?|
max {|ci?|, |ci?|, 1}
+ ?1{ci? = c
i
? = ?}
)
,
(9)
851
and using an independence assumption we get:
;p?
?
ijl|i6=j
{cjl } ? argmax
ci??P(ci)
?
ci??P(ci)
?
?
?
cik
(
P?(c
i
k ; c
j
l |C
i, Cj)1{cik ? c
i
?}+
(1? P?(c
i
k ; c
j
l |C
i, Cj))1{cik /? c
i
?}
)
)
(
?|c
i
?|
|ci? ? c
i
?|
max {|ci?|, |ci?|, 1}
+ ?1{ci? = c
i
? = ?}
)
.
(10)
Note that although the directional posterior prob-
abilities are used to generate the predicted MCA,
the result is a many-to-many alignment, since the
union is done over all pairs of sequences in both
directions. The calculation in Equation (10) can
be computationally intensive in practice, as it re-
quires |P(ci)|2 = 22n
i
operations for each word
position cjl and citance C
i. This can be over-
come by restricting the combinations of source word
positions (ci? and c
i
?) to include only the the top
MAX SOURCES source words with a minimum
posterior probability of MIN PROB to align to cjl
(P?(cik ; c
j
l |C
i, Cj) ? MIN PROB). In our im-
plementation we set MAX SOURCES to 8 and
MIN PROB to 0.01. Additionally, the probabilities
of each combination ci? can be calculated only once,
since it is independent of ci?. This reduces the to-
tal computational complexity of calculating ?p to
O
(
216(K2 ?K)maxni
{
ni
})
.
4 Data sets
Since citance alignment is a new task, we had to
create our own evaluation and training sets. We re-
stricted the domain of the target papers to molec-
ular interactions, a domain which is actively re-
searched in the biosciences text mining community
(Hirschman et al, 2002). The biologist in our group
annotated citances to 6 target papers. The training
set consisted of 40 citances to 4 different target pa-
pers (10 citances each; we wanted to have variety in
the training set). The development set consisted of
51 citances to the fifth target paper, and the test set
contained 45 citances to the sixth target paper.
For each target paper we downloaded the full text
of those papers citing it that were available in HTML
format. The link structure of the cited references in
the HTML documents allowed us to automatically
extract citances to a given target paper. We defined a
citance to be the full sentence that contains a citation
to the target paper. Each citance was then tokenized,
and normalized by removing all stopwords from a
predefined list.
One goal of the annotation was to cover as much
of the content of the citances as possible. Another
goal was consistency; our biologist manually fol-
lowed a small number of rules to determine seman-
tic similarity. Distinct semantic units (words or
phrases) were identified and given an annotation ID.
Within each group of citances, words or phrases that
share semantic similarity were annotated with the
same ID.
Using the manually annotated citance groups,
pairwise word alignments were generated for every
source-target pair of citances from every group. That
resulted in a training, development, and test sets
of 180, 1275, and 990 pairwise alignments respec-
tively.
Alignments that were used for development and
testing were generated as many-to-many alignments.
However, many-to-many alignments are not suit-
able for the training the many-to-one CRF align-
ment model. When a given source word cik aligns
to multiple words in the target citance, the CRF
model chooses only one target word as a true pos-
itive, while incorrectly treating the other true posi-
tive target words as true negatives. To alleviate this
problem, in such cases we replaced all true-positive
target words other than the first with ?*?, thus forcing
them to act as real true negatives for the purpose of
training. This adjustment does not solve the inher-
ent limitation of the CRF?s many-to-one modeling of
a many-to-many alignment, but it prevents learning
incorrect weights for good features.
5 Feature engineering
The CRF alignment model can combine multiple
overlapping features. We evaluated the effectiveness
of different features by training models on the train-
ing set and evaluating their performance on the de-
velopment set. We considered variations of features
852
that were part of the original system of Blunsom &
Cohn (2006), and also designed new features that are
specific to the problem of MCA.
Orthographic features
We used the following orthographic features from
the original system of Blunsom & Cohn (2006) (be-
low all features are either Boolean indicator func-
tions (b) or real valued (r)):
(b) exact string similarity of source-target words;
(b) every possible source-target pair of length 3 prefixes;
(b) exact string match of length 3 prefixes;
(b) exact string match of length 3 suffixes;
(r) absolute difference in word lengths;
(b) both words are shorter than 4 characters.
In addition, the following orthographic features
were added: indicator that both words include capi-
tal letters, and normalized edit-similarity of the two
words (1?
edit distance(cik,c
j
l )
max{|cik|,|c
j
l |}
).
Markov features
We used the following Markov features from the
original system:
(r) absolute jump width (abs(at?at?1?1), which measures
the distance between the target words of adjacent source
words;
(r) positive jump width (max{at ? at?1 ? 1, 0});
(r) negative jump width (max{at?1 + 1? at, 0});
(b) transition from null aligned source-word to non-null
aligned source-word;
(b) transition from non-null aligned source-word to null
aligned source-word;
(b) transition from null aligned source-word to null aligned
source-word.
In addition we added the following Markov fea-
tures in order to model the tendency of certain words
to be part of longer phrases:
(b) source-word aligns to the same target-word as the previ-
ous source-word;
(b) source-word aligns to the same target-word as the next
source-word;
(b) transition from non-null aligned source-word to non-null
aligned source-word.
Sentence position: We included the relative sen-
tence position feature from the original system,
which is defined as abs( at|cj | ?
t
ci ). Although it was
not expected to be relevant for MCA, since the ci-
tances are not expected to align along the diagonal,
this feature slightly improved the performance of the
development set.
Null: An indicator function for leaving a source-
word unaligned was retained from the original sys-
tem. This is an essential feature since without it the
CRF tends to over-align words, and produces mean-
ingless posterior probabilities.
Ontological features: Orthographic and posi-
tional features alone do not cover all cases of se-
mantic homology. We therefore included features
that are based on domain specific ontologies.
Using an automated script we mapped specific
words and phrases in every citance to MeSH1 terms,
Gene identifiers from Entrez Gene,2 UniProt,3 and
OMIM.4 We then added features indicating when
the source and target words are annotated with the
same MeSH term or the same gene identifier. We
tried numerous features that compare MeSH terms
based on their distance in the ontology, and other
features that indicate whether a word is part of a
longer term. However, none of these feature were
selected for the final system.
In addition to biological ontologies we added a
feature for semantic word similarity between the
source and target words, based on the Lin (1998)
WordNet similarity measure.
6 Results
We modified the CRF alignment system of Blun-
som & Cohn (2006) to support MCA by incorpo-
rating the posterior decoding algorithm from Sec-
tion 3.2 into the existing system. The CRF model
was trained using the features that were selected us-
ing the development set, on a dataset that included
the training and development MCAs. All the perfor-
mance results in this section are reported on the test
set, which includes 990 pairs of citances (45?44/2),
with a total of 34188 words (8547 ? 44). On aver-
age, 20% of the source words are aligned to at least
one other target word in a given reference pairwise
alignment. Since the union of all the pairwise align-
ments results in only a single test MCA, it is hard
to make strong arguments about the performance
1http://www.nlm.nih.gov/mesh/
2http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=gene
3http://www.pir.uniprot.org/
4http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?db=OMIM
853
00.10.20.30.40.50.60.70.80.91 0.
3
0.4
0.5
0.6
0.7
0.8
Reca
ll
Precision
Viterb
i_Inte
rsect
ion
Viterb
i_Uni
on
Poste
rior d
ecod
ing
Figure 3: Recall/Precision curve of pairwise ci-
tance alignments comparing Viterbi to posterior
decoding.
of the system in general. Therefore, we concen-
trate our discussion on general trends, and do not
claim that the specific performance numbers we re-
port here are statistically significant. As a point of
comparison, the SMT community has been evalu-
ating performance of word-alignment systems on an
even smaller dataset of 447 pairs of non-overlapping
sentences (Mihalcea and Pedersen, 2003).
We first analyze the performance of the system
on pairwise citance alignments. Instead of tak-
ing the equivalence closure of ;p we take only
the symmetric closure. The result is 990 many-
to-many pairwise alignments. In order to evalu-
ate the effectiveness of the posterior-decoding al-
gorithm, we generate the Viterbi alignments using
the same CRF model. The Viterbi many-to-many
pairwise alignments are then generated by combin-
ing equivalent pairs of many-to-one alignments us-
ing three different standard symmetrization methods
for word-alignment?union, intersection, and the re-
fined method of Och & Ney (2003).
Figure 3 shows the recall/precision trade-off of
the pairwise posterior-decoding and Viterbi align-
ments. The curve for the posterior-decoding align-
ments was produced by varying the gap and match
factors. For the Viterbi alignments, only three re-
sults could be generated (one for each symmetriza-
tion method). However, since the refined method
produced a very similar result to the union, only
the union is displayed in the figure. The impor-
tant observation is that while posterior-decoding en-
ables refined control over the recall/precision trade-
off, the Viterbi decoding generates only three align-
ments, which cover only a small fraction of the curve
at its high precision range. The union of Viterbi
alignments achieves 0.531 recall at 0.913 preci-
sion, which is similar result to the 0.540 recall at
0.909 precision achieved using posterior-decoding
with gap-factor and match-factor set to 1. However,
unlike Viterbi, posterior-decoding produces align-
ments with much higher recall levels, by increas-
ing the match-factor and decreasing the gap-factor.
For example setting the gap-factor to 0.1 and match-
factor to 1.2 results in alignments with 0.636 recall
at 0.517 precision, and setting them to 0.05 and 1.5
results in 0.742 recall at 0.198 precision. Generally,
the gap and match factor affect the accuracy of the
alignments as expected. In particular, the alignments
with the best AMA (0.889) and the best F1-measure
(0.678) are generated when the gap match factor are
set to their natural values (1,1), which theoretically
should maximize the expected AMA.
The performance of the pairwise alignments
validates the underlying probabilistic model,
showing it behaves as theoretically expected.
However, the union of all pairwise alignments
is not a valid MCA. To evaluate the MCA
posterior decoding algorithm, we compared it
to baseline MCAs. The baseline MCAs are
constructed by using only the normalized-edit-
distance
edit distance(cik,c
j
l )
max{|cik|,|c
j
l |}
, and defining cik ;
?
cjl if and only if normalized edit distance(c
i
k, c
j
l ) ?
?, where ? is a distance threshold. The fi-
nal baseline MCA is constructed by taking the
equivalence closure of all pairwise alignments,
??,
(
;? ?(;?)?1)
)+
. The ? parameter can
be used to control the recall/precision trade-off,
since increasing it adds more position-pairs to the
alignment, thus increasing recall, while decreasing
it increases precision.
Figures 4 compares the performance of the CRF
posterior-decoding MCAs with the baseline MCAs.
The different MCAs were produced by varying the
gap and match factors in the case of the posterior-
decoding, and ? for the baseline MCAs. The CRF
curve clearly dominates the baseline curve. How-
ever, they do overlap in range between 0.52 and
0.55 recall (0.84 and 0.90 precision). This is prob-
854
00.10.20.30.40.50.60.70.80.91 0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Reca
ll
Precision
CRF
Base
line
Figure 4: Recall/Precision curve of MCAs
comparing CRF with posterior decoding to
normalized-edit-distance baseline.
ably a range in which for this particular MCA the
orthographic similarity is the most dominant fea-
ture. While the baseline curve drops sharply after
that range, the posterior-decoding curve keeps im-
proving recall up to 0.636 at 0.748 precision, be-
fore a major drop in precision. The additional recall
is due to the ability of the CRF model to incorpo-
rate multiple overlapping features. In particular, the
domain-specific features are important for aligning
words and phrases that have little or no orthographic
similarity. At the other end of the overlap range, the
posterior-decoding achieves better precision than the
baseline for the same recall levels. For example, the
posterior decoding gets 0.381 recall at 0.982 preci-
sion compared with 0.346 at 0.937 for the baseline.
Unlike the pairwise alignment case, the neutral
settings of the gap and match factors did not result in
the best AMA score. This is due to the equivalence
closure heuristic that results in MCAs that are too
dense, since a single link between two equivalence
classes causes them to merge. The best AMA score
(0.886) is obtained by reducing the gap-factor to 0.5
and match-factor to 0.45, in order to compensate for
the effect of the equivalence closure heuristic. For
comparison, the best F1-measure (0.690) is achieved
by setting the gap and match factors to 0.75.
An error analysis on the latter MCA shows that
out of 1400 unique errors, 1194 (85.3%) are false
negatives (FN) and 206 (14.7%) false positives (FP).
Most errors (more than 600) are due to misalign-
ment of subtypes (e.g., cdc, cdc6, cdc25A), oppo-
sites (e.g., phosphorylated and unphosphorylated)
and complex entities (e.g., cell cycle v.s. cell line).
In addition, a large portion of FN errors are due to
not aligning entities that belong to just four equiva-
lence classes (e.g., 97 FN errors caused by terms in
the class of motif, site and domain). Other types of
errors include not aligning plural and singular forms
of the same entities, aligning only part of multi-
word entities, and incorrectly aligning orthographi-
cally similar entities that belong to different classes.
7 Conclusions
We have shown how to derive a posterior-decoding
algorithm that aims at maximizing the expected util-
ity for the MCA problem, as a substitute for the
sequence-annealing algorithm for MSA. Adding a
gap and match factor to the utility function allows
control over the recall/precision trade-off when us-
ing posterior-decoding. Another advantage of opti-
mizing the expected utility with posterior-decoding
methods is the decoupling from the probabilistic
model that generated the posterior probabilities.
This allows the use of CRFs instead of HMMs with
a similar posterior decoding algorithm.
Our experiments were limited by the size of the
labeled data. However, the results support the the-
oretical predictions, and demonstrate the advantage
of posterior-decoding over Viterbi decoding.
Since citances are still a relatively unexplored re-
source, it is still unclear whether the formulation we
presented here for citance alignment is the most use-
ful for applications that use citances for compara-
tive analysis of bioscience text. Unlike biological
sequence alignment, citance alignments are much
more subjective, as they depend on a loose defini-
tion of semantic homology between entities. Even
the definition of the basic entities can vary, since in
many cases noun-compounds and other multi-word
entities seem to be a more natural choice for basic el-
ements of semantic homology and alignment. How-
ever, automatic segmentation and entity recognition
are still difficult tasks in the bioscience text domain
and so new methods are worth investigating.
Acknowledgements: We thank Phil Blunsom and
Trevor Cohn for sharing their CRF-based word
alignment code. This research was supported in part
by NSF DBI 0317510.
855
References
Phil Blunsom and Trevor Cohn. 2006. Discrimina-
tive word alignment with conditional random fields.
In Proceedings of the 21st International Conference
on Computational Linguistics and 44th Annual Meet-
ing of the Association for Computational Linguistics,
pages 65?72, Sydney, Australia, July. Association for
Computational Linguistics.
Josias Braun-Blanquet. 1932. Plant sociology: the study
of plant communities. McGraw-Hill, New York.
Francis Caillez and Pascale Kuntz. 1996. A contribution
to the study of the metric and euclidean structures of
dissimilarities. Psychometrika, 61(2):241?253.
Pedros Domingos. 2000. A unified bias-variance de-
composition and its applications. In Proceedings
of the Seventeenth International Conference on Ma-
chine Learning, pages 231?238, Stanford, CA. Mor-
gan Kaufmann.
Richard Durbin, Sean R. Eddy, Anders Krogh, and
Graeme Mitchison. 1998. Biological sequence analy-
sis. Probablistic models of proteins and nucleic acids.
Cambridge University Press.
Jacob Falck, Niels Mailand, Randi G. Syljuasen, Jiri
Bartek, and Jiri Lukas. 2001. The ATM-Chk2-
Cdc25A checkpoint pathway guards against radiore-
sistant DNA synthesis. Nature, 410(6830):842?847.
Eugene Garfield. 1955. Citation indexes for science: A
new dimension in documentation through association
of ideas. Science, 122(3159):108?111.
C. Lee Giles, Kurt D. Bollacker, and Steve Lawrence.
1998. Citeseer: an automatic citation indexing sys-
tem. In Proceedings of the third ACM conference on
Digital libraries, pages 89?98. ACM Press.
Lynette Hirschman, Jong C. Park, Junichi Tsujii, Lim-
soon Wong, and Cathy H. Wu. 2002. Accomplish-
ments and challenges in literature data mining for bi-
ology. Bioinformatics, 18(12):1553?1561.
Simon Lacoste-Julien, Ben Taskar, Dan Klein, and
Michael I. Jordan. 2006. Word alignment via
quadratic assignment. In Proceedings of the Human
Language Technology Conference of the NAACL, Main
Conference, pages 112?119, New York City, USA,
June. Association for Computational Linguistics.
John Lafferty, Andrew McCallum, and Fernando Pereira.
2001. Conditional random fields: Probabilistic models
for segmenting and labeling sequence data. In Proc.
18th International Conf. on Machine Learning, pages
282?289. Morgan Kaufmann, San Francisco, CA.
Percy Liang, Ben Taskar, and Dan Klein. 2006. Align-
ment by agreement. In Proceedings of the Human
Language Technology Conference of the NAACL, Main
Conference, pages 104?111, New York City, USA,
June. Association for Computational Linguistics.
Dekang Lin. 1998. An information-theoretic definition
of similarity. In Proc. 15th International Conf. on Ma-
chine Learning, pages 296?304. Morgan Kaufmann,
San Francisco, CA.
Ben-Ami Lipetz. 1965. Improvements of the selectiv-
ity of citation indexes to science literature through in-
clusion of citation relationship indicators. American
Documentation, 16:81?90.
Mengxiong Liu. 1993. Progress in documentation. the
complexities of citation practice: A review of citation
studies. Journal of Documentation, 49(4):370?408.
Evgeny Matusov, Richard Zens, and Hermann Ney.
2004. Symmetric word alignments for statistical ma-
chine translation. In COLING ?04: Proceedings of the
20th international conference on Computational Lin-
guistics, page 219, Morristown, NJ, USA. Association
for Computational Linguistics.
Rada Mihalcea and Ted Pedersen. 2003. An evaluation
exercise for word alignment. In Rada Mihalcea and
Ted Pedersen, editors, HLT-NAACL 2003 Workshop:
Building and Using Parallel Texts: Data Driven Ma-
chine Translation and Beyond, pages 1?10, Edmonton,
Alberta, Canada, May 31. Association for Computa-
tional Linguistics.
Robert C. Moore. 2005. A discriminative framework for
bilingual word alignment. In HLT/EMNLP, pages 81?
88.
Preslav I. Nakov, Ariel S. Schwartz, and Marti A. Hearst.
2004. Citances: Citation sentences for semantic anal-
ysis of bioscience text. In SIGIR?04 Workshop on
Search and Discovery in Bioinformatics.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, 29(1):19?51.
Gian-Carlo Rota. 1964. The number of partitions of a
set. The American Mathematical Monthly, 71(5):498?
504, may.
Ralf Schlu?ter, Thomas Scharrenbach, Volker Steinbiss,
and Hermann Ney. 2005. Bayes risk minimization
using metric loss functions. In Proceedings of the
European Conference on Speech Communication and
Technology, Interspeech, pages 1449?1452, Portugal,
September.
Ariel S. Schwartz and Lior Pachter. 2007. Multiple
alignment by sequence annealing. Bioinformatics,
23(2):e24?29.
856
Ariel S. Schwartz, Eugene W. Myers, and Lior Pachter.
2006. Alignment metric accuracy. arXiv:q-
bio.QM/0510052.
Ariel S. Schwartz. 2007. Posterior Decoding Meth-
ods for Optimization and Accuracy Control of Multiple
Alignments. Ph.D. thesis, EECS Department, Univer-
sity of California, Berkeley.
Howard D. White. 2004. Citation analysis and discourse
analysis revisited. Applied Linguistics, 25(1):89?116.
857
BioNLP 2007: Biological, translational, and clinical language processing, pages 73?80,
Prague, June 2007. c?2007 Association for Computational Linguistics
Exploring the Efficacy of
Caption Search for Bioscience Journal Search Interfaces
Marti A. Hearst, Anna Divoli, Jerry Ye
School of Information, UC Berkeley
Berkeley, CA 94720
{hearst,divoli,jerryye}@ischool.berkeley.edu
Michael A. Wooldridge
California Digital Library
Oakland, CA 94612
mikew@ucop.edu
Abstract
This paper presents the results of a pilot us-
ability study of a novel approach to search
user interfaces for bioscience journal arti-
cles. The main idea is to support search over
figure captions explicitly, and show the cor-
responding figures directly within the search
results. Participants in a pilot study ex-
pressed surprise at the idea, noting that they
had never thought of search in this way.
They also reported strong positive reactions
to the idea: 7 out of 8 said they would use a
search system with this kind of feature, sug-
gesting that this is a promising idea for jour-
nal article search.
1 Introduction
For at least two decades, the standard way to search
for bioscience journal articles has been to use the
National Library of Medicine?s PubMed system to
search the MEDLINE collection of journal articles.
PubMed has innovated search in many ways, but to
date search in PubMed is restricted to the title, ab-
stract, and several kinds of metadata about the doc-
ument, including authors, Medical Subject Heading
(MeSH) labels, publication year, and so on.
On the Web, searching within the full text of doc-
uments has been standard for more than a decade,
and much progress has been made on how to do
this well. However, until recently, full text search
of bioscience journal articles was not possible due
to two major constraints: (1) the full text was not
widely available online, and (2) publishers restrict
researchers from downloading these articles in bulk.
Recently, online full text of bioscience journal ar-
ticles has become ubiquitous, eliminating one bar-
rier. The intellectual property restriction is under
attack, and we are optimistic that it will be nearly
entirely diffused in a few years. In the meantime,
the PubMedCentral Open Access collection of jour-
nals provides an unrestricted resource for scientists
to experiment with for providing full text search.1
Full text availability requires a re-thinking of how
search should be done on bioscience journal arti-
cles. One opportunity is to do information extrac-
tion (text mining) to extract facts and relations from
the body of the text, as well as from the title and
abstract as done by much of the early text mining
work. (The Biocreative competition includes tasks
that allow for extraction within full text (Yeh et al,
2003; Hirschman et al, 2005).) The results of text
extraction can then be exposed in search interfaces,
as done in systems like iHOP (Hoffmann and Va-
lencia, 2004) and ChiliBot (Chen and Sharp, 2004)
(although both of these search only over abstracts).
Another issue is how to adjust search ranking al-
gorithms when using full text journal articles. For
example, there is evidence that ranking algorithms
should consider which section of an article the query
terms are found in, and assign different weights to
different sections for different query types (Shah et
al., 2003), as seen in the TREC 2006 Genomics
Track (Hersh et al, 2006).
Recently Google Scholar has provided search
1The license terms for use for BioMed Central can be
found at: http://www.biomedcentral.com/info/authors/license
and the license for PubMedCentral can be found at:
http://www.pubmedcentral.gov/about/openftlist.html
73
over the full text of journal articles from a wide
range of fields, but with no special consideration
for the needs of bioscience researchers2. Google
Scholar?s distinguishing characteristic is its ability
to show the number of papers that cite a given arti-
cle, and rank papers by this citation count. We be-
lieve this is an excellent starting point for full text
search, and any future journal article search system
should use citation count as a metric. Unfortunately,
citation count requires access to the entire collection
of articles; something that is currently only avail-
able to a search system that has entered into con-
tracts with all of the journal publishers.
In this article, we focus on another new opportu-
nity: the ability to search over figure captions and
display the associated figures. This idea is based
on the observation, noted by our own group as well
as many others, that when reading bioscience arti-
cles, researchers tend to start by looking at the title,
abstract, figures, and captions. Figure captions can
be especially useful for locating information about
experimental results. A prominent example of this
was seen in the 2002 KDD competition, the goal
of which was to find articles that contained exper-
imental evidence for gene products, where the top-
performing team focused its analysis on the figure
captions (Yeh et al, 2003).
In the Biotext project, we are exploring how to
incorporate figures and captions into journal article
search explicitly, as part of a larger effort to provide
high-quality article search interfaces. This paper re-
ports on the results of a pilot study of the caption
search idea. Participants found the idea novel, stim-
ulating, and most expressed a desire to use a search
interface that supports caption search and figure dis-
play.3
2 Related Work
2.1 Automated Caption Analysis
Several research projects have examined the auto-
mated analysis of text from captions. Srihari (1991;
1995) did early work on linking information be-
tween photographs and their captions, to determine,
for example, which person?s face in a newspaper
2http://scholar.google.com
3The current version of the interface can be seen at
http://biosearch.berkeley.edu
photograph corresponded to which name in the cap-
tion. Shatkay et al (2006) combined information
from images as well as captions to enhance a text
categorization algorithm.
Cohen, Murphy, et al have explored several dif-
ferent aspects of biological text caption analysis. In
one piece of work (Cohen et al, 2003) they devised
and tested algorithms for parsing the structure of im-
age captions, which are often quite complex, espe-
cially when referring to a figure that has multiple
images within it. In another effort, they developed
tools to extract information relating to subcellular
localization by automatically analyzing fluorescence
microscope images of cells (Murphy et al, 2003).
They later developed methods to extract facts from
the captions referring to these images (Cohen et al,
2003).
Liu et al (2004) collected a set of figures and
classified them according to whether or not they de-
picted schematic representations of protein interac-
tions. They then allowed users to search for a gene
name within the figure caption, returning only those
figures that fit within the one class (protein interac-
tion schematics) and contained the gene name.
Yu et al (2006) created a bioscience image tax-
onomy (consisting of Gel-Image, Graph, Image-of-
Thing, Mix, Model, and Table) and used Support
Vector Machines to classify the figures, using prop-
erties of both the textual captions and the images.
2.2 Figures in Bioscience Article Search
Some bioscience journal publishers provide a ser-
vice called ?SummaryPlus? that allows for display
of figures and captions in the description of a partic-
ular article, but the interface does not apply to search
results listings.4
A medical image retrieval and image annotation
task have been part of the ImageCLEF competition
since 2005 (Muller et al, 2006).5 The datasets for
this competition are clinical images, and the task is
to retrieve images relevant to a query such as ?Show
blood smears that include polymorphonuclear neu-
4Recently a commercial offering by a company called CSA
Illustrata was brought to our attention; it claims to use figures
and tables in search in some manner, but detailed information is
not freely available.
5CLEF stands for Cross-language Evaluation Forum; it orig-
inally evaluated multi-lingual information retrieval, but has
since broadened its mission.
74
trophils.? Thus, the emphasis is on identifying the
content of the images themselves.
Yu and Lee (2006) hypothesized that the infor-
mation found in the figures of a bioscience article
are summarized by sentences from that article?s ab-
stract. They succeeded in having 119 scientists mark
up the abstract of one of their own articles, indicat-
ing which sentence corresponded to each figure in
the article. They then developed algorithms to link
sentences from the abstract to the figure caption con-
tent. They also developed and assessed a user inter-
face called BioEx that makes use of this linking in-
formation. The interface shows a set of very small
image thumbnails beneath each abstract. When the
searcher?s mouse hovers over the thumbnail, the cor-
responding sentence from the abstract is highlighted
dynamically.
To evaluate BioEx, Yu and Lee (2006) sent a ques-
tionnaire to the 119 biologists who had done the
hand-labeling linking abstract sentences to images,
asking them to assess three different article display
designs. The first design looked like the PubMed
abstract view. The second augmented the first view
with very small thumbnails of figures extracted from
the article. The third was the second view aug-
mented with color highlighting of the abstract?s sen-
tences. It is unclear if the biologists were asked to
do searches over a collection or were just shown a
sample of each view and asked to rate it. 35% of the
biologists responded to the survey, and of these, 36
out of 41 (88%) preferred the linked abstract view
over the other views. (It should be noted that the
effort invested in annotating the abstracts may have
affected the scientists? view of the design.)
It is not clear, however, whether biologists would
prefer to see the caption text itself rather than the
associated information from the abstract. The sys-
tem described did not allow for searching over text
corresponding to the figure caption. The system also
did not focus on how to design a full text and caption
search system in general.
3 Interface Design and Implementation
The Biotext search engine indexes all Open Access
articles available at PubMedCentral. This collection
consists of more than 150 journals, 20,000 articles
and 80,000 figures. The figures are stored locally,
and at different scales, in order to be able to present
thumbnails quickly. The Lucene search engine6 is
used to index, retrieve, and rank the text (default sta-
tistical ranking). The interface is web-based and is
implemented in Python and PHP. Logs and other in-
formation are stored and queried using MySQL.
Figure 1a shows the results of searching over the
caption text in the Caption Figure view. Figure
1b shows the same search in the Caption Figure
with additional Thumbnails (CFT) view. Figure 2a-
b shows two examples of the Grid view, in which
the query terms are searched for in the captions, and
the resulting figures are shown in a grid, along with
metadata information.7 The Grid view may be espe-
cially useful for seeing commonalities among topics,
such as all the phylogenetic trees that include a given
gene, or seeing all images of embryo development of
some species.
The next section describes the study participants?
reaction to these designs.
4 Pilot Usability Study
The design of search user interfaces is difficult; the
evidence suggests that most searchers are reluctant
to switch away from something that is familiar. A
search interface needs to offer something qualita-
tively better than what is currently available in order
to be acceptable to a large user base (Hearst, 2006).
Because text search requires the display of text,
results listings can quickly obtain an undesirably
cluttered look, and so careful attention to detail is
required in the elements of layout and graphic de-
sign. Small details that users find objectionable can
render an interface objectionable, or too difficult to
use. Thus, when introducing a new search interface
idea, great care must be taken to get the details right.
The practice of user-centered design teaches how to
achieve this goal: first prototype, then test the results
with potential users, then refine the design based on
their responses, and repeat (Hix and Hartson, 1993;
Shneiderman and Plaisant, 2004).
Before embarking on a major usability study to
determine if a new search interface idea is a good
one, it is advantageous to run a series of pilot stud-
ies to determine which aspects of the design work,
6http://lucene.apache.org
7These screenshots represent the system as it was evaluated.
The design has subsequently evolved and changed.
75
(a)
(b)
Figure 1: Search results on a query of zebrafish over the captions within the articles with (a) CF view, and
(b) CFT view. The thumbnail is shown to the left of a blue box containing the bibliographic information
above a yellow box containing the caption text. The full-size view of the figure can be overlaid over the
current page or in a new browser window. In (b) the first few figures are shown as mini-thumbnails in a row
below the caption text with a link to view all the figures and captions.
76
(a)
(b)
Figure 2: Grid views of the first sets of figures returned as the result of queries for (a) mutagenesis and for
(b) pathways over captions in the Open Access collection.
77
ID status sex lit search area(s) of specialization
1 undergrad F monthly organic chemistry
2 graduate F weekly genetics / molecular bio.
3 other F rarely medical diagnostics
4 postdoc M weekly neurobiology, evolution
5 graduate F daily evolutionary bio., entomology
6 undergrad F weekly molecular bio., biochemistry
7 undergrad F monthly cell developmental bio.
8 postdoc M daily molecular / developmental bio.
Table 1: Participant Demographics. Participant 3 is
an unemployed former lab worker.
which do not, make adjustments, and test some
more. Once the design has stabilized and is re-
ceiving nearly uniform positive feedback from pilot
study participants, then a formal study can be run
that compares the novel idea to the state-of-the-art,
and evaluates hypotheses about which features work
well for which kinds of tasks.
The primary goal of this pilot study was to deter-
mine if biological researchers would find the idea of
caption search and figure display to be useful or not.
The secondary goal was to determine, should cap-
tion search and figure display be useful, how best
to support these features in the interface. We want
to retain those aspects of search interfaces that are
both familiar and useful, and to introduce new ele-
ments in such a way as to further enhance the search
experience without degrading it.
4.1 Method
We recruited participants who work in our campus?
main biology buildings to participate in the study.
None of the participants were known to us in ad-
vance. To help avoid positive bias, we told partici-
pants that we were evaluating a search system, but
did not mention that our group was the one who
was designing the system. The participants all had
strong interests in biosciences; their demographics
are shown in Table 1.
Each participant?s session lasted approximately
one hour. First, they were told the purpose of the
study, and then filled out an informed consent form
and a background questionnaire. Next, they used the
search interfaces (the order of presentation was var-
ied). Before the use of each search interface, we
explained the idea behind the design. The partici-
pant then used the interface to search on their own
Figure 3: Likert scores on the CF view. X-axis:
participant ID, y-axis: Likert scores: 1 = strongly
disagree, 7 = strongly agree. (Scale reversed for
questionnaire-posed cluttered and overwhelming.)
queries for about 10 minutes, and then filled out a
questionnaire describing their reaction to that de-
sign. After viewing all of the designs, they filled
out a post-study questionnaire where they indicated
whether or not they would like to use any of the
designs in their work, and compared the design to
PubMed-type search.
Along with these standardized questions, we had
open discussions with participants about their reac-
tions to each view in terms of design and content.
Throughout the study, we asked participants to as-
sume that the new designs would eventually search
over the entire contents of PubMed and not just the
Open Access collection.
We showed all 8 participants the Caption with
Figure (CF) view (see Figure 1a), and Caption with
Figure and additional Thumbnails (CFT) (see Figure
1b), as we didn?t know if participants would want to
see additional figures from the caption?s paper.8 We
did not show the first few participants the Grid view,
as we did not know how the figure/caption search
would be received, and were worried about over-
whelming participants with new ideas. (Usability
study participants can become frustrated if exposed
to too many options that they find distasteful or con-
fusing.) Because the figure search did receive pos-
8We also experimented with showing full text search to the
first five participants, but as that view was problematic, we dis-
continued it and substituted a title/abstract search for the re-
maining three participants. These are not the focus of this study
and are not discussed further here.
78
itive reactions from 3 of the first 4 participants, we
decided to show the Grid view to the next 4.
4.2 Results
The idea of caption search and figure display was
very positively perceived by all but one participant.
7 out of 8 said they would want to use either CF
or CFT in their bioscience journal article searches.
Figure 3 shows Likert scores for CF view.
The one participant (number 2) who did not like
CF nor CFT thought that the captions/figures would
not be useful for their tasks, and preferred seeing
the articles? abstracts. Many participants noted that
caption search would be better for some tasks than
others, where a more standard title & abstract or full-
text search would be preferable. Some participants
said that different views serve different roles, and
they would use more than one view depending on
the goal of their search. Several suggested combin-
ing abstract and figure captions in the search and/or
the display. (Because this could lead to search re-
sults that require a lot of scrolling, it would probably
be best to use modern Web interface technologies
to dynamically expand long abstracts and captions.)
When asked for their preference versus PubMed, 5
out of 8 rated at least one of the figure searches
above PubMed?s interface. (In some cases this may
be due to a preference for the layout in our design as
opposed to entirely a preference for caption search.)
Two of the participants preferred CFT to CF; the
rest thought CFT was too busy. It became clear
through the course of this study that it would be
best to show all the thumbnails that correspond to a
given article as the result of a full-text or abstract-
text search interface, and to show only the figure
that corresponds to the caption in the caption search
view, with a link to view all figures from this article
in a new page.
All four participants who saw the Grid view liked
it, but noted that the metadata shown was insuffi-
cient; if it were changed to include title and other
bibliographic data, 2 of the 4 who saw Grid said they
would prefer that view over the CF view. Several
participants commented that they have used Google
Images to search for images but they rarely find what
they are looking for. They reacted very positively
to the idea of a Google Image-type system special-
ized to biomedical images. One participant went so
far as to open up Google Image search and compare
the results directly, finding the caption search to be
preferable.
All participants favored the ability to browse all
figures from a paper once they find the abstract or
one of the figures relevant to their query. Two partic-
ipants commented that if they were looking for gen-
eral concepts, abstract search would be more suit-
able but for a specific method, caption view would
be better.
4.3 Suggestions for Redesign
All participants found the design of the new views
to be simple and clear. They told us that they gen-
erally want information displayed in a simple man-
ner, with as few clicks needed as possible, and with
as few distracting links as possible. Only a few ad-
ditional types of information were suggested from
some participants: display, or show links to, related
papers and provide a link to the full text PDF directly
in the search results, as opposed to having to access
the paper via PubMed.
Participants also made clear that they would of-
ten want to start from search results based on title
and abstract, and then move to figures and captions,
and from there to the full article, unless they are do-
ing figure search explicitly. In that case, they want
to start with CF or Grid view, depending on how
much information they want about the figure at first
glance.
They also wished to have the ability to sort the re-
sults along different criteria, including year of pub-
lication, alphabetically by either journal or author
name, and by relevance ranking. This result has
been seen in studies of other kinds of search inter-
faces as well (Reiterer et al, 2005; Dumais et al,
2003). We have also received several requests for ta-
ble caption search along with figure caption search.
5 Conclusions and Future Work
The results of this pilot study suggest that caption
search and figure display is a very promising direc-
tion for bioscience journal article search, especially
paired with title/abstract search and potentially with
other forms of full-text search. A much larger-scale
study must be performed to firmly establish this re-
sult, but this pilot study provides insight about how
79
to design a search interface that will be positively re-
ceived in such a study. Our results also suggest that
web search systems like Google Scholar and Google
Images could be improved by showing images from
the articles along lines of specialization.
The Grid view should be able to show images
grouped by category type that is of interest to biolo-
gists, such as heat maps and phylogenetic trees. One
participant searched on pancreas and was surprised
when the top-ranked figure was an image of a ma-
chine. This idea underscores the need for BioNLP
research in the study of automated caption classifi-
cation. NLP is needed both to classify images and
perhaps also to automatically determine which im-
ages are most ?interesting? for a given article.
To this end, we are in the process of building a
classifier for the figure captions, in order to allow
for grouping by type. We have developed an im-
age annotation interface and are soliciting help with
hand-labeling from the research community, to build
a training set for an automated caption classifier.
In future, we plan to integrate table caption
search, to index the text that refers to the cap-
tion, along with the caption, and to provide inter-
face features that allow searchers to organize and
filter search results according to metadata such as
year published, and topical information such as
genes/proteins mentioned. We also plan to conduct
formal interface evaluation studies, including com-
paring to PubMed-style presentations.
Acknowledgements: This work was supported in
part by NSF DBI-0317510. We thank the study par-
ticipants for their invaluable help.
References
H. Chen and B.M. Sharp. 2004. Content-rich biological net-
work constructed by mining PubMed abstracts. BMC Bioin-
formatics, 5(147).
W.W. Cohen, R. Wang, and R.F. Murphy. 2003. Understand-
ing captions in biomedical publications. Proceedings of the
ninth ACM SIGKDD international conference on Knowledge
discovery and data mining, pages 499?504.
S. Dumais, E. Cutrell, J.J. Cadiz, G. Jancke, R. Sarin, and D.C.
Robbins. 2003. Stuff I?ve seen: a system for personal in-
formation retrieval and re-use. Proceedings of SIGIR 2003,
pages 72?79.
M. Hearst. 2006. Design recommendations for hierarchi-
cal faceted search interfaces. In ACM SIGIR Workshop on
Faceted Search, Seattle, WA.
W. Hersh, A. Cohen, P. Roberts, and Rekapalli H. K. 2006.
TREC 2006 genomics track overview. The Fifteenth Text
Retrieval Conference.
L. Hirschman, A. Yeh, C. Blaschke, and A. Valencia. 2005.
Overview of BioCreAtIvE: critical assessment of informa-
tion extraction for biology. BMC Bioinformatics, 6:1.
D. Hix and H.R. Hartson. 1993. Developing user interfaces:
ensuring usability through product & process. John Wiley
& Sons, Inc. New York, NY, USA.
R. Hoffmann and A. Valencia. 2004. A gene network for navi-
gating the literature. Nature Genetics, 36(664).
F. Liu, T-K. Jenssen, V. Nygaard, J. Sack, and E. Hovig. 2004.
FigSearch: a figure legend indexing and classification sys-
tem. Bioinformatics, 20(16):2880?2882.
H. Muller, T. Deselaers, T. Lehmann, P. Clough, E. Kim, and
W. Hersh. 2006. Overview of the ImageCLEF 2006 Medical
Image Retrieval Tasks. In Working Notes for the CLEF 2006
Workshop.
R.F. Murphy, M. Velliste, and G. Porreca. 2003. Robust Nu-
merical Features for Description and Classification of Sub-
cellular Location Patterns in Fluorescence Microscope Im-
ages. The Journal of VLSI Signal Processing, 35(3):311?
321.
B. Rafkind, M. Lee, S.F. Chang, and H. Yu. 2006. Exploring
text and image features to classify images in bioscience lit-
erature. Proceedings of the BioNLP Workshop on Linking
Natural Language Processing and Biology at HLT-NAACL,
6:73?80.
H. Reiterer, G. Tullius, and T. M. Mann. 2005. Insyder:
a content-based visual-information-seeking system for the
web. International Journal on Digital Libraries, 5(1):25?
41, Mar.
P.K. Shah, C. Perez-Iratxeta, P. Bork, and M.A. Andrade.
2003. Information extraction from full text scientific arti-
cles: where are the keywords? BMC Bioinformatics, 4(20).
H. Shatkay, N. Chen, and D. Blostein. 2006. Integrating im-
age data into biomedical text categorization. Bioinformatics,
22(14):e446.
B. Shneiderman and C. Plaisant. 2004. Designing the user in-
terface: strategies for effective human-computer interaction,
4/E. Addison Wesley.
R.K. Srihari. 1991. PICTION: A System that Uses Captions
to Label Human Faces in Newspaper Photographs. Proceed-
ings AAAI-91, pages 80?85.
RK Srihari. 1995. Automatic indexing and content-based re-
trieval of captioned images. Computer, 28(9):49?56.
A.S. Yeh, L. Hirschman, and A.A. Morgan. 2003. Evaluation
of text data mining for database curation: lessons learned
from the KDD Challenge Cup. Bioinformatics, 19(1):i331?
i339.
H. Yu and M. Lee. 2006. Accessing bioscience images from
abstract sentences. Bioinformatics, 22(14):e547.
80
