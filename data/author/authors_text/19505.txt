Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 89?98, Dublin, Ireland, August 23-29 2014.
Group Non-negative Matrix Factorization with Natural Categories for
Question Retrieval in Community Question Answer Archives
Guangyou Zhou, Yubo Chen, Daojian Zeng, and Jun Zhao
National Laboratory of Pattern Recognition
Institute of Automation, Chinese Academy of Sciences
95 Zhongguancun East Road, Beijing 100190, China
{gyzhou,yubo.chen,djzeng,jzhao}@nlpr.ia.ac.cn
Abstract
Community question answering (CQA) has become an important service due to the popularity of
CQA archives on the web. A distinctive feature is that CQA services usually organize questions
into a hierarchy of natural categories. In this paper, we focus on the problem of question re-
trieval and propose a novel approach, called group non-negative matrix factorization with natural
categories (GNMFNC). This is achieved by learning the category-specific topics for each cate-
gory as well as shared topics across all categories via a group non-negative matrix factorization
framework. We derive an efficient algorithm for learning the factorization, analyze its complex-
ity, and provide proof of convergence. Experiments are carried out on a real world CQA data set
from Yahoo! Answers. The results show that our proposed approach significantly outperforms
various baseline methods and achieves the state-of-the-art performance for question retrieval.
1 Introduction
Community question answering (CQA) such as Yahoo! Answers
1
and Quora
2
, has become an important
service due to the popularity of CQA archives on the web. To make use of the large-scale questions and
their answers, it is critical to have functionality of helping users to retrieve previous answers (Duan et
al., 2008). Typically, such functionality is achieved by first retrieving the historical questions that best
match a user?s queried question, and then using answers of these returned questions to answer the queried
question. This is what we called question retrieval in this paper.
The major challenge for question retrieval, as for most information retrieval tasks, is the lexical gap
between the queried questions and the historical questions in the archives. For example, if a queried ques-
tion contains the word ?company? but a relevant historical question instead contains the word ?firm?, then
there is a mismatch and the historical question may not be easily distinguished from an irrelevant one.
To solve the lexical gap problem, most researchers focused on translation-based approaches since the
relationships between words (or phrases) can be explicitly modeled through word-to-word (or phrases)
translation probabilities (Jeon et al., 2005; Riezler et al., 2007; Xue et al., 2008; Lee et al., 2008; Bern-
hard and Gurevych, 2009; Zhou et al., 2011; Singh, 2012). However, these existing methods model the
relevance ranking without considering the category-specific and shared topics with natural categories, it
is not clear whether this information is useful for question retrieval.
A distinctive feature of question-answer pairs in CQA is that CQA services usually organize questions
into a hierarchy of natural categories. For example, Yahoo! Answers contains a hierarchy of 26 categories
at the first level and more than 1262 subcategories at the leaf level. When a user asks a question, the user
is typically required to choose a category label for the question from a predefined hierarchy. Questions in
the predefined hierarchy usually share certain generic topics while questions in different categories have
their specific topics. For example, questions in categories ?Arts & Humanities? and ?Beauty & Style?
may share the generic topic of ?dance? but they also have the category-specific topics of ?poem? and
?wearing?, respectively.
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer
are added by the organisers. Licence details: http:// creativecommons.org/licenses/by/4.0/
1
http://answers.yahoo.com/
2
http://www.quora.com/
89
Inspired by the above observation, we propose a novel approach, called group non-negative matrix
factorization with natural categories (GNMFNC). GNMFNC assumes that there exists a set of category-
specific topics for each of the category, and there also exists a set of shared topics for all of the categories.
Each question in CQA is specified by its category label, category-specific topics, as well as shared topics.
In this way, the large-scale question retrieval problem can be decomposed into small-scale subproblems.
In GNMFNC, questions in each category are represented as a term-question matrix. The term-question
matrix is then approximated as the product of two matrices: one matrix represents the category-specific
topics as well as the shared topics, and the other matrix denotes the question representation based on
topics. An objective function is defined to measure the goodness of prediction of the data with the
model. Optimization of the objective function leads to the automatic discovery of topics as well as
the topic representation of questions. Finally, we calculate the relevance ranking between the queried
questions and the historical questions in the latent topic space.
Past studies by (Cao et al., 2009; Cao et al., 2010; Ming et al., 2010; Cai et al., 2011; Ji et al., 2012;
Zhou et al., 2013) confirmed a significant retrieval improvement by adding the natural categories into
various existing retrieval models. However, all these previous work regarded natural categories indi-
vidually without considering the relationships among them. On the contrary, this paper can effectively
capture the relationships between the shared aspects and the category-specific individual aspects with
natural categories via a group non-negative matrix factorization framework. Also, our work models the
relevance ranking in the latent topic space rather than using the existing retrieval models. To date, no at-
tempts have been made regarding group non-negative matrix factorization in studies of question retrieval,
which remains an under-explored area.
The remainder of this paper is organized as follows. Section 2 describes our proposed group non-
negative matrix factorization with natural categories for question retrieval. Section 3 presents the exper-
imental results. In Section 4, we conclude with ideas for future research.
2 Group Non-negative Matrix Factorization with Natural Categories
2.1 Problem Formulation
In CQA, all questions are usually organized into a hierarchy of categories. When a user asks a question,
the user is typically required to choose a category label for the question from a predefined hierarchy of
categories. Hence, each question in CQA has a category label. Suppose that we are given a question col-
lection D in CQA archive with size N , containing terms from a vocabulary V with size M . A question
d is represented as a vector d ? R
M
where each entry denotes the weight of the corresponding term,
for example tf-idf is used in this paper. Let C = {c
1
, c
2
, ? ? ? , c
P
} denote the set of categories (subcat-
egories) of question collection D, where P is the number of categories (subcategories). The question
collection D is organized into P groups according to their category labels and can be represented as
D = {D
1
,D
2
, ? ? ? ,D
P
}. D
p
= {d
(p)
1
, ? ? ? ,d
(p)
N
p
} ? R
M?N
p
is the term-question matrix corresponding
to category c
p
, in which each row stands for a term and each column stands for a question. N
p
is the
number of questions in category c
p
such that
?
P
p=1
N
p
= N .
LetU
?
p
= [U
s
,U
p
] ? R
M?(K
s
+K
p
)
be the term-topic matrix corresponding to category c
p
, where K
s
is the number of shared topics, K
p
is the number of category-specific topics corresponding to category
c
p
, and p ? [1, P ]. Term-topic matrix U
s
can be represented as U
s
= [u
(s)
1
, ? ? ? ,u
(s)
K
s
] ? R
M?K
s
, in
which each column corresponds to a shared topic. While the term-topic matrix U
p
can be represented
as U
p
= [u
(p)
1
, ? ? ? ,u
(p)
K
p
] ? R
M?K
p
. The total number of topics in the question collection D is K =
K
s
+ PK
p
. Let V
p
= [v
(p)
1
, ? ? ? ,v
(p)
N
p
] ? R
(K
s
+K
p
)?N
p
be the topic-question matrix corresponding to
category c
p
, in which each column denotes the question representation in the topic space. We also denote
V
T
p
= [H
T
p
,W
T
p
], where H
p
? R
K
s
?N
p
and W
p
? R
K
p
?N
p
correspond to the coefficients of shared
topicsU
s
and category-specific topicsU
p
, respectively.
Thus, given a question collection D = {D
1
,D
2
, ? ? ? ,D
P
} together with the category labels C =
{c
1
, c
2
, ? ? ? , c
P
}, our proposed GNMFNC amounts to modeling the question collection D with P group
90
simultaneously, arriving at the following objective function:
O =
P
?
p=1
{
?
p
?
?
D
p
? [U
s
,U
p
]V
p
?
?
2
F
+ R(U
s
,U
p
)
}
(1)
where ?
p
, ?D
p
?
?2
F
. R(U
s
,U
p
) is a regularization term used to penalize the ?similarity? between the
shared topics and category-specific topics throughU
s
andU
p
.
In this paper, we aim to ensure that matrix U
s
captures only shared topics and matrix U
p
captures
only the category-specific topics. For example, if matricesU
s
andU
p
are mutually orthogonal, we have
U
T
s
U
p
= 0. To impose this constraint, we attempt to minimize the sum-of-squares of entries of the
matrix U
T
s
U
p
(e.g., ?U
T
s
U
p
?
2
F
which uniformly optimizes each entry of U
T
s
U
p
). With this choice, the
regularization term of R(U
s
,U
p
) is given by
R(U
s
,U
p
) =
P
?
p=1
?
p
?
?
U
T
s
U
p
?
?
2
F
+
P
?
l=1,l?=p
?
l
?
?
U
T
p
U
l
?
?
2
F
(2)
where ?
p
and ?
l
are the regularization parameters, ?p ? [1, P ], ?l ? [1, P ].
Learning the objective function in equation (1) involves the following optimization problem:
min
U
s
,U
p
,V
p
?0
L = O + ?
1
?
?
U
T
s
1
M
? 1
K
s
?
?
2
F
+ ?
2
?
?
U
T
p
1
M
? 1
K
p
?
?
2
F
+ ?
3
?
?
V
p
1
N
p
? 1
K
s
+K
p
?
?
2
F
(3)
where ?
1
, ?
2
and ?
3
are the shrinkage regularization parameters. Based on the shrinkage methodology,
we can approximately satisfy the normalization constraints for each column of [U
s
,U
p
] and V
T
p
by
guaranteeing the optimization converges to a stationary point.
2.2 Learning Algorithm
We present the solution to the GNMFNC optimization problem in equation (3) as the following theorem.
The theoretical aspects of the optimization are presented in the next subsection.
Theorem 2.1. UpdatingU
s
,U
p
andV
p
using equations (4)?(6) corresponds to category c
p
will mono-
tonically decrease the objective function in equation (3) until convergence.
U
s
? U
s
?
[
?
P
p=1
?
p
D
p
H
T
p
]
[
?
P
p=1
?
p
[U
s
,U
p
]V
p
H
T
p
+ ?
p
U
p
U
T
p
U
s
]
(4)
U
p
? U
p
?
[
?
p
D
p
W
T
p
]
[
?
p
[U
s
,U
p
]V
p
W
T
p
+ ?
p
U
s
U
T
s
U
p
+
?
P
l=1,l?=p
?
l
U
l
U
T
l
U
p
]
(5)
V
p
? V
p
?
[
?
p
D
T
p
[U
s
,U
p
]
]
[
?
p
V
T
p
[U
s
,U
p
]
T
[U
s
,U
p
]
]
(6)
where operator ? is element-wise product and
[?]
[?]
is element-wise division.
Based on Theorem 2.1, we note that multiplicative update rules given by equations (4)?(6) are ob-
tained by extending the updates of standard NMF (Lee and Seung, 2001). A number of techniques can
be used here to optimize the objective function in equation (3), such as alternating least squares (Kim
and Park, 2008), the active set method (Kim and Park, 2008), and the projected gradients approach (Lin,
2007). Nonetheless, the multiplicative updates derived in this paper have reasonably fast convergence
behavior as shown empirically in the experiments.
2.3 Theoretical Analysis
In this subsection, we give the theoretical analysis of the optimization, convergence and computational
complexity.
91
Without loss of generality, we only show the optimization ofU
s
and formulate the Lagrange function
with constraints as follows:
L(U
s
) = O + ?
1
?
?
U
T
s
1
M
? 1
K
s
?
?
2
F
+ Tr(?
s
U
T
s
)
(7)
where Tr(?) denotes the trace of a matrix, ?
s
? R
K
s
?K
s
is the Lagrange multiplier for the nonnegative
constraintU
s
? 0.
The partial derivative of L(U
s
) w.r.t. U
s
is
?
U
s
L(U
s
) = ?2
P
?
p=1
?
p
D
p
H
T
p
+ 2
P
?
p=1
?
p
[U
s
,U
p
]V
p
H
T
p
+ 2
P
?
p=1
?
p
U
p
U
T
p
U
s
+ 2?
1
U
s
? 2?
1
+ ?
s
(8)
Using the Karush-Kuhn-Tucker (KKT) (Boyd and Vandenberghe, 2004) condition ?
s
?U
s
= 0, we
obtain
?
U
s
L(U
s
) ?U
s
=
{
?
?
P
p=1
?
p
D
p
H
T
p
+
?
P
p=1
?
p
[U
s
,U
p
]V
p
H
T
p
+
?
P
p=1
?
p
U
p
U
T
p
U
s
+ ?
1
U
s
? ?
1
}
?U
s
= 0 (9)
After normalization ofU
s
, the terms ?
1
U
s
and ?
1
are in fact equal. They can be safely ignored from
the above formula without influencing convergence. This leads to the updating rule for U
s
in equation
(4). Following the similar derivations as shown above, we can obtain the updating rules for the rest
variablesU
p
andV
p
in GNMFNC optimization, as shown in equations (5) and (6).
2.3.1 Convergence Analysis
In this subsection, we prove the convergence of multiplicative updates given by equations (4)?(6). We
first introduce the definition of auxiliary function as follows.
Definition 2.1. F(X,X
?
) is an auxiliary function for L(X) if L(X) ? F(X,X
?
) and equality holds if
and only if L(X) = F(X,X).
Lemma 2.1. (Lee and Seung, 2001) If F is an auxiliary function for L, L is non-increasing under the
update
X
(t+1)
= argmin
X
F(X,X
(t)
)
Proof. By Definition 2.1, L(X
(t+1)
) ? F(X
(t+1)
,X
(t)
) ? F(X
(t)
,X
(t)
) = L(X
(t)
)
Theorem 2.2. Let L(U
(t+1)
s
) denote the sum of all terms in L that containU
(t+1)
s
, the following function
is an auxiliary function for L(U
(t+1)
s
)
F(U
(t+1)
s
,U
(t)
s
) = L(U
(t)
s
) + (U
(t+1)
s
?U
(t)
s
)?
U
(t)
s
L(U
(t)
s
) +
1
2
(U
(t+1)
s
?U
(t)
s
)
2
P(U
(t)
s
)
(10)
P(U
(t)
s
) =
?
ij
[
?
P
p=1
?
p
[U
(t)
s
,U
p
]V
p
W
T
p
+ ?
p
U
p
U
T
p
U
(t)
s
+ ?
1
U
(t)
s
]
ij
?
ij
[U
(t)
s
]
ij
where ?
U
(t)
s
L(U
(t)
s
) is the first-order derivative of L(U
(t)
s
) with respect toU
(t)
s
. Theorem 2.2 can be
proved similarly to (Lee and Seung, 2001) by validating L(U
(t+1)
s
) ? F(U
(t+1)
s
,U
(t)
s
), L(U
(t+1)
s
) =
F(U
(t+1)
s
,U
(t+1)
s
), and the Hessian matrix ??
U
(t+1)
s
F(U
(t+1)
s
,U
(t)
s
) ? 0. Due to limited space, we
omit the details of the validation.
92
addition multiplication division overall
GNMFNC:U
s
P (3MN
p
K
s
+MN
p
K
p
+MK
2
s
) P (3MN
p
K
s
+MN
p
K
p
+MK
2
s
) MK
s
O(PMN
p
K
max
)
GNMFNC:U
p
3MN
p
K
p
+MN
p
K
s
+ PM
2
K
?
3MN
p
K
p
+MN
p
K
s
+ PM
2
K
?
MK
p
O(PMRK
?
)
GNMFNC:V
p
3MN
p
K
?
3MN
p
K
?
N
p
K
?
O(MN
p
K
?
)
Table 1: Computational operation counts for each iteration in GNMFNC.
Based on Theorem 2.2, we can fixU
(t)
s
and minimize F(U
(t+1)
s
,U
(t)
s
) with respect toU
(t+1)
s
. When
setting ?
U
(t+1)
s
F(U
(t+1)
s
,U
(t)
s
) = 0, we get the following updating rule
U
(t+1)
s
? U
(t)
s
?
[
?
P
p=1
?
p
D
p
H
T
p
+ ?
1
]
[
?
P
p=1
?
p
[U
(t)
s
,U
p
]V
p
W
T
p
+ ?
p
U
p
U
T
p
U
(t)
s
+ ?
1
U
(t)
s
]
(11)
which is consistent with the updating rule derived from the KKT conditions aforementioned.
By Lemma 2.1 and Theorem 2.2, we have L(U
(0)
s
) = F(U
(0)
s
,U
(0)
s
) ? F(U
(1)
s
,U
(0)
s
) ?
F(U
(1)
s
,U
(1)
s
) = L(U
(1)
s
) ? ? ? ? ? L(U
(Iter)
s
), where Iter is the number of iterations. Therefore,
U
s
is monotonically decreasing. Since the objective function L is lower bounded by 0, the correctness
and convergence of Theorem 2.1 is validated.
2.3.2 Computational Complexity
In this subsection, we discuss the time computational complexity of the proposed algorithm GNMFNC.
Besides expressing the complexity of the algorithm using big O notation, we also count the number of
arithmetic operations to provide more details about running time. We show the results in Table 1, where
K
max
= max{K
s
,K
p
}, K
?
= K
s
+ K
p
and R = max{M,N
p
}.
Suppose the multiplicative updates stop after Iter iterations, the time cost of multiplicative updates
then becomes O(Iter ? PMRK
?
). We set Iter = 100 empirically in rest of the paper. Therefore, the
overall running time of GNMFNC is linear with respect to the size of word vocabulary, the number of
questions and categories.
2.4 Relevance Ranking
The motivation of incorporating matrix factorization into relevance ranking is to learn the word rela-
tionships and reduce the ?lexical gap? (Zhou et al., 2013a). To do so, given a queried question q with
category label c
p
from Yahoo! Answers, we first represent it in the latent topic space as v
q
,
v
q
= argmin
v?0
?q? [U
s
,U
p
]v?
2
2
(12)
where vector q is the tf-idf representation of queried question q in the term space.
For each historical question d (indexed by r) in question collection D, with representation v
d
= r-th
column ofV, we compute its similarity with queried question v
q
as following
s
topic
(q, d) =
< v
q
,v
d
>
?v
q
?
2
? ?v
d
?
2
(13)
The latent topic space score s
topic
(q, d) is combined with the conventional term matching score
s
term
(q, d) for final relevance ranking. There are several ways to conduct the combination. Linear
combination is a simple and effective way. The final relevance ranking score s(q, d) is:
s(q, d) = ?s
topic
(q, d) + (1? ?)s
term
(q, d) (14)
where ? ? [0, 1] is the parameter which controls the relative importance of the latent topic space score
and term matching score. s
term
(q, d) can be calculated with any of the conventional relevance models
such as BM25 (Robertson et al., 1994) and LM (Zhai and Lafferty, 2001).
93
3 Experiments
3.1 Data Set and Evaluation Metrics
We collect the data set from Yahoo! Answers and use the getByCategory function provided in Yahoo!
Answers API
3
to obtain CQA threads from the Yahoo! site. More specifically, we utilize the resolved
questions and the resulting question repository that we use for question retrieval contains 2,288,607 ques-
tions. Each resolved question consists of four parts: ?question title?, ?question description?, ?question
answers? and ?question category?. We only use the ?question title? and ?question category? parts, which
have been widely used in the literature for question retrieval (Cao et al., 2009; Cao et al., 2010). There
are 26 first-level categories in the predefined natural hierarchy, i.e., each historical question is categorized
into one of the 26 categories. The categories include ?Arts & Humanities?, ?Beauty & Style?, ?Business
& Finance?, etc.
In order to evaluate our approach, we randomly select 2,000 questions as queried questions from the
above data collection to construct the validation/test sets, and the remaining data collection as training
set. Note that we select the queried questions in proportion to the number of questions and categories
against the whole distribution to have a better control over a possible imbalance. To obtain the ground-
truth, we employ the Vector Space Model (VSM) (Salton et al., 1975) to retrieve the top 10 results and
obtain manual judgements. The top 10 results don?t include the queried question itself. Given a returned
result by VSM, an annotator is asked to label it with ?relevant? or ?irrelevant?. If a returned result
is considered semantically equivalent to the queried question, the annotator will label it as ?relevant?;
otherwise, the annotator will label it as ?irrelevant?. Two annotators are involved in the annotation
process. If a conflict happens, a third person will make judgement for the final result. In the process
of manually judging questions, the annotators are presented only the questions. As a result, there are in
total 20,000 judged question pairs. We randomly split the 2,000 queried questions into validation/test
sets, each has 1,000/1,000 queried questions. We use the validation set for parameter tuning and the test
set for evaluation.
Evaluation Metrics: We evaluate the performance of question retrieval using the following metrics:
Mean Average Precision (MAP) and Precision@N (P@N). MAP rewards methods that return relevant
questions early and also rewards correct ranking of the results. P@N reports the fraction of the top-N
questions retrieved that are relevant. We perform a significant test, i.e., a t-test with a default significant
level of 0.05.
There are several parameters used in the paper, we tune these parameters on the validation set.
Specifically, we set the number of category-specific topics per category and the number of shared
topics in GNMFNC as (K
s
,K
p
) = {(5, 2), (10, 4), (20, 8), (40, 16), (80, 32)}, resulting in K =
{57, 114, 228, 456, 912} total number of topics. (Note that the total number of topics in GNMFNC
is K
s
+ 26 ?K
p
, where 26 is the number of categories in the first-level predefined natural hierarchy
4
).
Finally, we set (K
s
,K
p
) = (20, 8) and K = 228 empirically as this setting yields the best performance.
For regularization parameters ?
p
and ?
l
, it is difficult to directly tune on the validation set, we present
an alternative way by adding a common factor a to look at the objective function of optimization problem
in equation (3) on the training data. In other words, we set ?
p
=
a
K
s
?K
p
and ?
l
=
a
K
p
?K
l
. Therefore, we
tune the parameters ?
p
and ?
l
by alternatively adjusting the common factor a via grid search. As a result,
we set a = 100, resulting in ?
p
= ?
l
= 0.625 in the following experiments. The trade-off parameter ?
in the linear combination is set from 0 to 1 in steps of 0.1 for all methods. We set ? = 0.6 empirically.
For shrinkage regularization parameters, we empirically set ?
1
= ?
2
= ?
3
= 1.
3.2 Question Retrieval Results
In this experiment, we present the experimental results for question retrieval on the test data set. Specif-
ically, for our proposed GNMFNC, we combine the latent topic matching scores with the term matching
scores given by BM25 and LM, denoted as ?BM25+GNMFNC? and ?LM+GNMFNC?. Table 2 shows
3
http://developer.yahoo.com/answers
4
Here we do not use the leaf categories because we find that it is not possible to run GNMFNC with such large number of
topics on the current machines, and we will leave it for future work.
94
Table 2: Comparison with different methods
for question retrieval.
# Methods MAP P@10
1 BM25 0.243 0.225
2 LM 0.286 0.232
3 (Jeon et al., 2005) 0.327 0.235
4 (Xue et al., 2008) 0.341 0.238
5 (Zhou et al., 2011) 0.365 0.243
6 (Singh, 2012) 0.354 0.240
7 (Cao et al., 2010) 0.358 0.242
8 (Cai et al., 2011) 0.331 0.236
9 BM25+GNMFNC 0.369 0.248
10 LM+GNMFNC 0.374 0.251
Table 3: Comparison of matrix factoriza-
tions for question retrieval.
# Methods MAP P@10
1 BM25 0.243 0.225
2 BM25+NMF 0.325 0.235
3 BM25+CNMF 0.344 0.239
4 BM25+GNMF 0.361 0.242
5 BM25+GNMFNC 0.369 0.248
6 LM 0.286 0.232
7 LM+NMF 0.337 0.237
8 LM+CNMF 0.352 0.240
9 LM+GNMF 0.365 0.243
10 LM+GNMFNC 0.374 0.251
the main retrieval performances under the evaluation metrics MAP, P@1 and P@10. Row 1 and row
2 are the baseline systems, which model the relevance ranking using BM25 (Robertson et al., 1994)
and language model (LM) (Zhai and Lafferty, 2001) in the term space. Row 3 is word-based transla-
tion model (Jeon et al., 2005), and row 4 is word-based translation language model (TRLM) (Xue et
al., 2008). Row 5 is phrase-based translation model (Zhou et al., 2011), and row 6 is the entity-based
translation model (Singh, 2012). Row 7 to row 11 explore the natural categories for question retrieval.
In row 7, Cao et al. (2010) employed the natural categories to compute the local and global relevance
with different model combination, here we use the combination VSM + TRLM for comparison because
this combination obtains the superior performance than others. In row 8, Cai et al. (2011) proposed a
category-enhanced TRLM for question retrieval. There are some clear trends in the results of Table 2:
(1) BM25+GNMFNC and LM+GNMFNC perform significantly better than BM25 and LM respec-
tively (t-test, p-value < 0.05, row 1 vs. row 9; row 2 vs. row 10), indicating the effective of GNMFNC.
(2) BM25+GNMFNC and LM+GNMFNC perform better than translation methods, some improve-
ments are statistical significant (t-test, p-value < 0.05, row 3 and row 4 vs. row 9 and row 10). The
reason may be that GNMFNC models the relevance ranking in the latent topic space, which can also
effectively solve the the lexical gap problem.
(3) Capturing the shared aspects and the category-specific individual aspects with natural categories
in the group modeling framework can significantly improve the performance of question retrieval (t-test,
p-value < 0.05, row 7 and row 8 vs. row 9 and row 10).
(4) Natural categories are useful and effectiveness for question retrieval, no matter in the group mod-
eling framework or existing retrieval models (row 3? row 6 vs. row 7?row 10).
3.3 Comparison of Matrix Factorizations
We note that our proposed GNMFNC is related to non-negative matrix factorization (NMF) (Lee and
Seung, 2001) and its variants, we introduce three baselines. The first baseline is NMF, which is trained
on the whole training data. The second baseline is CNMF, which is trained on each category without
considering the shared topics. The third baseline is GNMF (Lee and Choi, 2009; Wang et al., 2012),
which is similar to our GNMFNC but there are no constraints on the category-specific topics to prevent
them from capturing the information from the shared topics.
NMF and GNMF are trained on the training data with the same parameter settings in section 4.1 for
fair comparison. For CNMF, we also train the model on the training data with the same parameter settings
in section 4.1, except parameter K
s
, as there exists no shared topics in CNMF.
Table 3 shows the question retrieval performance of NMF families on the test set, obtained with the
best parameter settings determined by the validation set. From the results, we draw the following obser-
vations:
(1) All of these methods can significantly improve the performance in comparison to the baseline
BM25 and LM (t-test, p-value < 0.05).
(2) GNMF and GNMFNC perform significantly better than NMF and CNMF respectively (t-test, p-
value < 0.05), indicating the effectiveness of group matrix factorization framework, especially the use
of shared topics.
95
0 20 40 60 80 1000.41
0.42
0.43
0.44
0.45
0.46
0.47
0.48
0.49
0.5
Iteration number
Obje
ctive 
funct
ion v
alue
Figure 1: Convergence curve of GNMFNC.
-4 -3 -2 -1 0 1 2 3 40.414
0.416
0.418
0.42
0.422
0.424
0.426
0.428
0.43
Log10a
Conv
erged
 obje
ctive 
funct
ion v
alue
Figure 2: Objective function value vs. factor a.
(3) GNMFNC performs significantly better than GNMF (t-test, p-value < 0.05, row 4 vs. row 5; row
9 vs. row 10), indicating the effectiveness of the regularization term on the category-specific topics to
prevent them from capturing the information from the shared topics.
From the experimental results reported above, we can conclude that our proposed GNMFNC is useful
for question retrieval with high accuracies. To the best of our knowledge, it is the first time to investigate
the group matrix factorization for question retrieval.
3.4 Convergence Behavior
In subsection 2.3.1, we have shown that the multiplicative updates given by equations (4)?(6) are con-
vergent. Here, we empirically show the convergence behavior of GNMFNC.
Figure 1 shows the convergence curve of GNMFNC on the training data set. From the figure, y-axis is
the value of objective function and x-axis denotes the iteration number. We can see that the multiplicative
updates for GNMFNC converge very fast, usually within 80 iterations.
3.5 Regularization Parameters Selection
One success of this paper is to use regularized constrains on the category-specific topics to prevent them
from capturing the information from the shared topics. It is necessary to give an in-depth analysis of
the regularization parameters used in the paper. Consider the regularization term used in equation (2),
each element in U
T
s
U
p
and U
T
p
U
l
has a value between 0 and 1 as each column of U
s
, U
p
and U
l
is
normalized. Therefore, it is appropriate to normalize the term having ?U
T
s
U
p
?
2
F
by K
s
K
p
since there
are K
s
?K
p
elements inU
T
s
U
p
. Similarly, ?U
T
p
U
l
?
2
F
is normalized by K
l
K
p
. Note that K
l
= K
p
and
l ?= p. As discussed in subsection 4.1, we present an alternative way by adding a common factor a and
set ?
p
=
a
K
s
?K
p
and ?
l
=
a
K
p
?K
l
. The common factor a is used to adjust a trade-off between the matrix
factorization errors and the mutual orthogonality, which cannot directly tune on the validation set. Thus,
we look at the objective function of optimization problem in equation (3) on the training data and find
the optimum value for a.
Figure 2 shows the objective function value vs. common factor a, where y-axis denotes the converged
objective function value, and x-axis denotes Log
10
a . We can see that the optimum value of a is 100.
Therefore, the common factor a can be fixed at 100 for our data set used in the paper, resulting in
?
p
= ?
l
= 0.625. Note that the optimum value of (K
s
,K
p
) are set as (20, 8) in subsection 4.1. Due to
limited space, we do not give an in-depth analysis for other parameters.
4 Conclusion and Future Work
In this paper, we propose a novel approach, called group non-negative matrix factorization with natural
categories (GNMFNC). The proposed method is achieved by learning the category-specific topics for
each category as well as shared topics across all categories via a group non-negative matrix factorization
framework. We derive an efficient algorithm for learning the factorization, analyze its complexity, and
96
provide proof of convergence. Experiments show that our proposed approach significantly outperforms
various baseline methods and achieves state-of-the-art performance for question retrieval.
There are some ways in which this research could be continued. First, the optimization of GNMFNC
can be decomposed into many sub-optimization problems, a natural avenue for future research is to
reduce the running time by executing the optimization in a distributed computing environment (e.g.,
MapReduce (Dean et al., 2004)). Second, another combination approach will be used to incorporate the
latent topic match score as a feature in a learning to rank model, e.g., LambdaRank (Burges et al., 2007).
Third, we will try to investigate the use of the proposed approach for other kinds of data sets with larger
categories, such as categorized documents from ODP project.
5
Acknowledgments
This work was supported by the National Natural Science Foundation of China (No. 61333018 and
No. 61303180), the Beijing Natural Science Foundation (No. 4144087), CCF Opening Project of Chi-
nese Information Processing, and also Sponsored by CCF-Tencent Open Research Fund. We thank the
anonymous reviewers for their insightful comments.
References
D. Bernhard and I. Gurevych. 2009. Combining lexical semantic resources with question & answer archives for
translation-based answer finding. In Proceedings of ACL, pages 728-736.
S. Boyd and L. Vandenberghe. 2004. Convex Optimization. Cambridge university press.
C. Boutsidis and E. Gallopoulos. 2008. SVD based initialization: a head start for nonnegative matrix factorization.
Pattern Recognition, 41(4):1350-1362.
C. Burges, R. Ragno, and Q. Le. 2007. Learning to rank with nonsmooth cost function. In Proceedings of NIPS.
L. Cai, G. Zhou, K. Liu, and J. Zhao. 2011. Learning the latent topics for question retrieval in community QA. In
Proceedings of IJCNLP.
X. Cao, G. Cong, B. Cui, C. Jensen, and C. Zhang. 2009. The use of categorization information in language
models for question retrieval. In Proceedings of CIKM, pages 265-274.
X. Cao, G. Cong, B. Cui, and C. Jensen. 2010. A generalized framework of exploring category information for
question retrieval in community question answer archives. In Proceedings of WWW.
J. Dean, S. Ghemanwat, and G. Inc. 2004. Mapreduce: simplified data processing on large clusters. In Proceed-
ings of OSDI.
H. Duan, Y. Cao, C. Lin, and Y. Yu. 2008. Searching questions by identifying questions topics and question focus.
In Proceedings of ACL, pages 156-164.
J. Jeon, W. Croft, and J. Lee. 2005. Finding similar questions in large question and answer archives. In Proceed-
ings of CIKM, pages 84-90.
Z. Ji, F. Xu, and B. Wang. 2012. A category-integrated language model for question retrieval in community
question answering. In Proceedings of AIRS, pages 14-25.
H. Kim and H. Park. 2008. Non-negative matrix factorization based on alternating non-negativity constrained
least squares and active set method. SIAM J Matrix Anal Appl, 30(2):713-730.
A. Langville, C. Meyer, R. Albright, J. Cox, and D. Duling. 2006. Initializations for the nonnegative matrix
factorization. In Proceedings of KDD.
J. Lee, S. Kim, Y. Song, and H. Rim. 2008. Bridging lexical gaps between queries and questions on large online
Q&A collections with compact translation models. In Proceedings of EMNLP, pages 410-418.
D. Lee and H. Seung. 2001. Algorithms for non-negative matrix factorization. In Proceedings of NIPS.
5
http://www.dmoz.org/
97
H. Lee and S. Choi. 2009. Group nonnegative matrix factorization for eeg classification. In Proceedings of
AISTATS, pages 320-327.
C. Lin. 2007. Projected gradient methods for nonnegative matrix factorization. Neural Comput, 19(10):2756-
2779.
Z. Ming, T. Chua, and G. Cong. 2010. Exploring domain-specific term weight in archived question search. In
Proceedings of CIKM, pages 1605-1608.
S. Riezler, A. Vasserman, I. Tsochantaridis, V. Mittal, and Y. Liu. 2007. Statistical machine translation for query
expansion in answer retrieval. In Proceedings of ACL, pages 464-471.
S. Robertson, S. Walker, S. Jones, M. Hancock-Beaulieu, and M. Gatford. 1994. Okapi at trec-3. In Proceedings
of TREC, pages 109-126.
G. Salton, A. Wong, and C. Yang. 1975. A vector space model for automatic indexing. Communications of the
ACM, 18(11):613-620.
A. Singh. 2012. Entity based q&a retrieval. In Proceedings of EMNLP-CoNLL, pages 1266-1277.
Q. Wang, Z. Cao, J. Xun, and H. Li. 2012. Group matrix factorizaiton for scalable topic modeling. In Proceedings
of SIGIR.
X. Xue, J. Jeon, and W. Croft. 2008. Retrieval models for question and answer archives. In Proceedings of SIGIR,
pages 475-482.
C. Zhai and J. Lafferty. 2001. A study of smooth methods for language models applied to ad hoc information
retrieval. In Proceedings of SIGIR, pages 334-342.
G. Zhou, L. Cai, J. Zhao, and K. Liu. 2011. Phrase-based translation model for question retrieval in community
question answer archives. In Proceedings of ACL, pages 653-662.
G. Zhou, F. Liu, Y. Liu, S. He, and J. Zhao. 2013. Statistical machine translation improves question retrieval in
community question answering via matrix factorization. In Proceedings of ACL, pages 852-861.
G. Zhou, Y. Chen, D. Zeng, and J. Zhao. 2013. Toward faster and better retrieval models for question search. In
Proceedings of CIKM, pages 2139-2148.
98
Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 1331?1340, Dublin, Ireland, August 23-29 2014.
Sentiment Classification with Graph Co-Regularization
Guangyou Zhou, Jun Zhao, and Daojian Zeng
National Laboratory of Pattern Recognition
Institute of Automation, Chinese Academy of Sciences
95 Zhongguancun East Road, Beijing 100190, China
{gyzhou,jzhao,djzeng}@nlpr.ia.ac.cn
Abstract
Sentiment classification aims to automatically predict sentiment polarity (e.g., positive or neg-
ative) of user-generated sentiment data (e.g., reviews, blogs). To obtain sentiment classifica-
tion with high accuracy, supervised techniques require a large amount of manually labeled data.
The labeling work can be time-consuming and expensive, which makes unsupervised (or semi-
supervised) sentiment analysis essential for this application. In this paper, we propose a novel
algorithm, called graph co-regularized non-negative matrix tri-factorization (GNMTF), from the
geometric perspective. GNMTF assumes that if two words (or documents) are sufficiently close
to each other, they tend to share the same sentiment polarity. To achieve this, we encode the
geometric information by constructing the nearest neighbor graphs, in conjunction with a non-
negative matrix tri-factorization framework. We derive an efficient algorithm for learning the
factorization, analyze its complexity, and provide proof of convergence. Our empirical study on
two open data sets validates that GNMTF can consistently improve the sentiment classification
accuracy in comparison to the state-of-the-art methods.
1 Introduction
Recently, sentiment classification has gained a wide interest in natural language processing (NLP) com-
munity. Methods for automatically classifying sentiments expressed in products and movie reviews can
roughly be divided into supervised and unsupervised (or semi-supervised) sentiment analysis. Super-
vised techniques have been proved promising and widely used in sentiment classification (Pang et al.,
2002; Pang and Lee, 2008; Liu, 2012). However, the performance of these methods relies on manually
labeled training data. In some cases, the labeling work may be time-consuming and expensive. This
motivates the problem of learning robust sentiment classification via unsupervised (or semi-supervised)
paradigm.
A traditional way to perform unsupervised sentiment analysis is the lexicon-based method (Turney,
2002; Taboada et al., 2011). Lexicon-based methods employ a sentiment lexicon to determine overall
sentiment orientation of a document. However, it is difficult to define a universally optimal sentiment
lexicon to cover all words from different domains (Lu et al., 2011a). Besides, most semi-automated
lexicon-based methods yield unsatisfactory lexicons, with either high coverage and low precision or
vice versa (Ng et al., 2006). Thus it is challenging for lexicon-based methods to accurately identify
the overall sentiment polarity of users generated sentiment data. Recently, Li et al. (2009) proposed a
constrained non-negative matrix tri-factorization (CNMTF) approach to sentiment classification, with
a domain-independent sentiment lexicon as prior knowledge. Experimental results show that CNMTF
achieves state-of-the-art performance.
From the geometric perspective, the data points (words or documents) may be sampled from a distribu-
tion supported by a low-dimensional manifold embedded in a high-dimensional space (Cai et al., 2011).
This geometric structure, meaning that two words (or documents) sufficiently close to each other tend to
share the same sentiment polarity, should be preserved during the matrix factorization. Research studies
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer
are added by the organisers. Licence details: http:// creativecommons.org/licenses/by/4.0/
1331
have shown that learning performance can be significantly enhanced in many real applications (e.g., text
mining, computer vision, etc.) if the geometric structure is exploited (Roweis and Saul, 2000; Tenen-
baum et al., 2000). However, CNMTF fails to exploit the geometric structure, it is not clear whether this
geometric information is useful for sentiment classification, which remains an under-explored area. This
paper is thus designed to fill the gap.
In this paper, we propose a novel algorithm, called graph co-regularized non-negative matrix tri-
factorization (GNMTF). We construct two affinity graphs to encode the geometric information under-
lying the word space and the document space, respectively. Intuitively, if two words or documents are
sufficiently close to each other, they tend to share the same sentiment polarity. Taking these two graphs
as co-regularization for the non-negative matrix tri-factorization, leading to the better sentiment polarity
prediction which respects to the geometric structures of the word space and document space. We also de-
rive an efficient algorithm for learning the tri-factorization, analyze its complexity, and provide proof of
convergence. Empirical study on two open data sets shows encouraging results of the proposed method
in comparison to state-of-the-art methods.
The remainder of this paper is organized as follows. Section 2 introduces the basic concept of matrix
tri-factorization. Section 3 describes our graph co-regularized non-negative matrix tri-factorization (GN-
MTF) for sentiment classification. Section 4 presents the experimental results. Section 5 introduces the
related work. In section 6, we conclude the paper and discuss future research directions.
2 Preliminaries
2.1 Non-negative Matrix Tri-factorization
Li et al. (2009) proposed a matrix factorization based framework for unsupervised (or semi-supervised)
sentiment analysis. The proposed framework is built on the orthogonal non-negative matrix tri-
factorization (NMTF) (Ding et al., 2006). In these models, a term-document matrixX = [x
1
, ? ? ? ,x
n
] ?
R
m?n
is approximated by three factor matrices that specify cluster labels for words and documents by
solving the following optimization problem:
min
U,H,V?0
O =
?
?
X?UHV
T
?
?
2
F
+ ?
1
?
?
U
T
U? I
?
?
2
F
+ ?
2
?
?
V
T
V ? I
?
?
2
F
(1)
where ?
1
and ?
2
are the shrinkage regularization parameters, U = [u
1
, ? ? ? ,u
k
] ? R
m?k
+
is the word-
sentiment matrix, V = [v
1
, ? ? ? ,v
n
] ? R
n?k
+
is the document-sentiment matrix, and k is the number of
sentiment classes for documents. Our task is polarity sentiment classification (positive or negative), i.e.,
k = 2. For example,V
i1
= 1 (orU
i1
= 1) represents that the sentiment polarity of document i (or word
i) is positive, andV
i2
= 1 (orU
i2
= 1) represents that the sentiment polarity of document i (or word i)
is negative. V
i?
= 0 (orU
i?
= 0) represents unknown, i.e., the document i (or word i) is neither positive
or negative. H ? R
k?k
+
provides a condensed view of X; ? ? ?
F
is the Frobenius norm and I is a k ? k
identity matrix with all entries equal to 1. Based on the shrinkage methodology, we can approximately
satisfy the orthogonality constraints forU andV by preventing the second and third terms from getting
too large.
2.2 Constrained NMTF
Lexical knowledge in the form of the polarity of words in the lexicon can be introduced in matrix tri-
factorization. By partially specifying word polarity viaU, the lexicon influences the sentiment prediction
V over documents. Following the literature (Li et al., 2009), let U
0
represent lexical prior knowledge
about sentiment words in the lexicon, e.g., if word i is positive (U
0
)
i1
= 1 while if it is negative
(U
0
)
i2
= 1, and if it does not exist in the lexicon (U
0
)
i?
= 0. Li et al. (2009) also investigated that we
had a few documents manually labeled for the purpose of capturing some domain-specific connotations.
LetV
0
denote the manually labeled documents, if the document expresses positive sentiment (V
0
)
ii
= 1,
and (V
0
)
i2
= 1 for negative sentiment. Therefore, the semi-supervised learning with lexical knowledge
can be written as:
min
U,H,V?0
O + ?Tr
[
(U?U
0
)
T
C
u
(U?U
0
)
]
+ ?Tr
[
(V ?V
0
)
T
C
v
(V ?V
0
)
]
(2)
1332
where Tr(?) denotes the trace of a matrix, ? > 0 and ? > 0 are the parameters which control the
contribution of lexical prior knowledge and manually labeled documents. C
u
? {0, 1}
m?m
is a diagonal
matrix whose entry C
u
ii
= 1 if the category of the i-th word is known and C
u
ii
= 0 otherwise. C
v
?
{0, 1}
n?n
is a diagonal matrix whose entry C
v
ii
= 1 if the category of the i-th document is labeled and
C
v
ii
= 0 otherwise.
3 Graph Co-regularized Non-negative Matrix Tri-factorization
In this section, we introduce our proposed graph co-regularized non-negative matrix tri-factorization
(GNMTF) algorithm which avoids this limitation by incorporating the geometrically based co-
regularization.
3.1 Model Formulation
Based on the manifold assumption (Belkin and Niyogi, 2001), if two documents x
i
and x
j
are sufficiently
close to each other in the intrinsic geometric of the documents distribution, then their sentiment polarity
v
i
and v
j
should be close. In order to model the geometric structure, we construct a document-document
graphG
v
. In the graph, nodes represent documents in the corpus and edges represent the affinity between
the documents. The affinity matrixW
v
? R
n?n
of the graph G
v
is defined as
W
v
ij
=
{
cos(x
i
,x
j
) if x
i
? N
p
(x
j
) or x
j
? N
p
(x
i
)
0 otherwise
(3)
where N
p
(x
i
) represents the p-nearest neighbors of document x
i
. Many matrices, e.g., 0-1 weighting,
textual similarity and heat kernel weighting (Belkin and Niyogi, 2001), can be used to obtain nearest
neighbors of a document, and further define the affinity matrix. Since W
v
ij
in our paper is only for
measuring the closeness, we only use the simple textual similarity and do not treat the different weighting
schemes separately due to the limited space. For further information, please refer to (Cai et al., 2011).
Preserving the geometric structure in the document space is reduced to minimizing the following loss
function:
R
v
=
1
2
n
?
i,j=1
?
?
v
i
? v
j
?
?
2
2
W
v
ij
=
n
?
i=1
v
T
i
v
i
D
v
ii
?
n
?
i,j=1
v
T
i
v
j
W
v
ij
= Tr(V
T
D
v
V)? Tr(V
T
W
v
V) = Tr(V
T
L
v
V)
(4)
whereD
v
? R
n?n
is a diagonal matrix whose entries are column (or row, sinceD
v
is symmetric) sums
ofW
v
,D
v
ii
=
?
n
j=1
W
v
ij
, and L
v
= D
v
?W
v
is the Laplacian matrix (Chung, 1997) of the constructed
graph G
v
.
Similarly to document-document geometric structure, if two words w
i
= [x
i1
, ? ? ? ,x
in
] and w
j
=
[x
j1
, ? ? ? ,x
jn
] are sufficiently close to each other in the intrinsic geometric of the words distribution,
then their sentiment polarity u
i
and u
j
should be close. In order to model the geometric structure in the
word space, we construct a word-word graph G
u
. In the graph, nodes represent distinct words and edges
represent the affinity between words. The affinity matrixW
u
? R
m?m
of the graph G
u
is defined as
W
u
ij
=
{
cos(w
i
,w
j
) ifw
i
? N
p
(w
j
) orw
j
? N
p
(w
i
)
0 otherwise
(5)
where N
p
(w
j
) represents the p-nearest neighbor of word w
j
. Here, we represent a term w
j
as a docu-
ment vector [x
j1
, ? ? ? ,x
jn
]. To measure the closeness of two words, a common way is to calculate the
similarity of their vector representations. Although there are several ways (e.g., co-occurrence infor-
mation, semantic similarity computed by WordNet, Wikipedia, or search engine have been empirically
studied in NLP literature (Hu et al., 2009)) to define the affinity matrixW
u
, we do not treat the different
ways separately and leave this investigation for future work.
Preserving the geometric structure in the word space is reduced to minimizing the following loss
function:
R
u
=
1
2
m
?
i,j=1
?
?
u
i
? u
j
?
?
2
2
W
u
ij
= Tr(U
T
L
u
U) (6)
1333
where L
u
= D
u
?W
u
is the Laplacian matrix of the constructed graph G
u
, and D
u
? R
m?m
is a
diagonal matrix whose entries areD
u
ii
=
?
m
j=1
W
u
ij
.
Finally, we treat unsupervised (or semi-supervised) sentiment classification as a clustering problem,
employing lexical prior knowledge and partial manually labeled data to guide the learning process. More-
over, we introduce the geometric structures from both document and word sides as co-regularization.
Therefore, our proposed unsupervised (or semi-supervised) sentiment classification framework can be
mathematically formulated as solving the following optimization problem:
min
U,H,V?0
L =
?
?
X?UHV
T
?
?
2
F
+ ?
1
?
?
U
T
U? I
?
?
2
F
+ ?
2
?
?
V
T
V ? I
?
?
2
F
+ ?Tr
[
(U?U
0
)
T
C
u
(U?U
0
)
]
+ ?Tr(U
T
L
u
U)
+ ?Tr
[
(V ?V
0
)
T
C
v
(V ?V
0
)
]
+ ?Tr(V
T
L
v
V)
(7)
where ? > 0 and ? > 0 are parameters which control the contributions of document space and word
space geometric information, respectively. With the optimization results, the sentiment polarity of a new
document x
i
can be easily inferred by f(x
i
) = argmax
j?{p, n}
V
ij
.
3.2 Learning Algorithm
We present the solution to the GNMTF optimization problem in equation (7) as the following theorem.
The theoretical aspects of the optimization are presented in the next subsection.
Theorem 3.1. Updating U, H and V using equations (8)?(10) will monotonically decrease the objec-
tive function in equation (7) until convergence.
U? U ?
[
XVH
T
+ ?
1
U+ ?C
u
U
0
+ ?W
u
U
]
[
UHV
T
VH
T
+ ?
1
UU
T
U+ ?C
u
U+ ?D
u
U
]
(8)
H? H ?
[
U
T
XV
]
[
U
T
UHV
T
V
]
(9)
V? V ?
[
X
T
UH+ ?
2
V + ?C
v
V
0
+ ?W
v
V
]
[
VH
T
U
T
UH+ ?
2
VV
T
V + ?C
v
V + ?D
v
V
]
(10)
where operator ? is element-wise product and
[?]
[?]
is element-wise division.
Based on Theorem 3.1, we note that the multiplicative update rules given by equations (8)?(10) are
obtained by extending the updates of standard NMTF (Ding et al., 2006). A number of techniques can
be used here to optimize the objective function in equation (7), such as alternating least squares (Kim
and Park, 2008), the active set method (Kim and Park, 2008), and the projected gradients approach (Lin,
2007). Nonetheless, the multiplicative updates derived in this paper has reasonably fast convergence
behavior as shown empirically in the experiments.
3.3 Theoretical Analysis
In this subsection, we give the theoretical analysis of the optimization, convergence and computational
complexity. Without loss of generality, we only show the optimization ofU and formulate the Lagrange
function with constraints as follows:
L(U) =
?
?
X?UHV
T
?
?
2
F
+ ?
1
?
?
U
T
U? I
?
?
2
F
+ ?Tr
[
(U?U
0
)
T
C
u
(U?U
0
)
]
+ Tr(?U
T
)
(11)
where ? is the Lagrange multiplier for the nonnegative constraintU ? 0.
The partial derivative of L(U) w.r.t. U is
?
U
L(U) = ?2XVH
T
+ 2UHV
T
VH
T
+ 2?
1
UU
T
U? 2?
1
U
+ 2?C
u
U? 2?C
u
U
0
+ 2?D
u
U? 2?W
u
U+?
1334
Using the Karush-Kuhn-Tucker (KKT) (Boyd and Vandenberghe, 2004) condition ??U = 0, we can
obtain
?
U
L(U) ?U =
[
UHV
T
VH
T
+ ?
1
UU
T
U+ ?C
u
U+ ?D
u
U
]
?U
?
[
XVH
T
+ ?
1
U+ ?C
u
U
0
+ ?W
u
U
]
?U = 0
This leads to the update rule in equation (8). Following the similar derivations as shown above, we
can obtain the updating rules for all the other variables H and V in GNMTF optimization, as shown in
equations (9) and (10).
3.3.1 Convergence Analysis
In this subsection, we prove the convergence of multiplicative updates given by equations (8)?(10). We
first introduce the definition of auxiliary function as follows.
Definition 3.1. F(Y,Y
?
) is an auxiliary function for L(Y) if L(Y) ? F(Y,Y
?
) and equality holds if
and only if L(Y) = F(Y,Y).
Lemma 3.1. (Lee and Seung, 2001) If F is an auxiliary function for L, L is non-increasing under the
updateY
(t+1)
= argmin
Y
F(Y,Y
(t)
)
Proof. By Definition 3.1, L(Y
(t+1)
) ? F(Y
(t+1)
,Y
(t)
) ? F(Y
(t)
,Y
(t)
) = L(Y
(t)
)
Theorem 3.2. Let function
F(U
ij
,U
(t)
ij
) = L(U
(t)
ij
) + L
?
(U
(t)
ij
)(U
ij
?U
(t)
ij
)
+
[
UHV
T
VH
T
+ ?
1
UU
T
U+ ?C
u
U+ ?D
u
U
]
ij
U
ij
(
U
ij
?U
(t)
ij
)
(12)
be a proper auxiliary function for L(U
ij
), where L
?
(U
ij
) = [?
U
L(U)]
ij
is the first-order derivatives
of L(U
ij
) with respect toU
ij
.
Theorem 3.2 can be proved similarly to (Ding et al., 2006). Due to limited space, we omit the details
of the validation. Based on Lemmas 3.1 and Theorem 3.2, the update rule for U can be obtained by
minimizing F(U
(t+1)
ij
,U
(t)
ij
). When setting ?
U
(t+1)
ij
F(U
(t+1)
ij
,U
(t)
ij
), we can obtain
U
(t+1)
ij
= U
(t)
ij
[
XVH
T
+ ?
1
U+ ?C
u
U
0
+ ?W
u
U
]
ij
[
UHV
T
VH
T
+ ?
1
UU
T
U+ ?C
u
U+ ?D
u
U
]
ij
By Lemma 3.1 and Theorem 3.2, we have L(U
(0)
) = F(U
(0)
,U
(0)
) ? F(U
(1)
,U
(0)
) ?
F(U
(1)
,U
(1)
) = L(U
(1)
) ? ? ? ? ? L(U
(Iter)
), where Iter denotes the number of iteration number.
Therefore, U is monotonically decreasing. Since the objective function L is lower bounded by 0, the
correctness and convergence of Theorem 3.1 is validated.
3.3.2 Time Complexity Analysis
In this subsection, we discuss the time computational complexity of the proposed algorithm GNMTF.
Besides expressing the complexity of the algorithm using big O notation, we also count the number of
arithmetic operations to provide more details about running time. We show the results in Table 1, where
m ? k and n ? k.
Based on the updating rules summarized in Theorem 3.1, it it not hard to count the arithmetic operators
of each iteration in GNMTF. It is important to note thatC
u
is a diagonal matrix, the nonzero elements on
each row of C
u
is 1. Thus, we only need zero addition and mk multiplications to compute C
u
U. Simi-
larly, forC
u
U
0
,C
v
V,C
v
V
0
,D
u
U andD
v
V, we also only need zero addition and mk multiplications
for each of them. Besides, we also note thatW
u
is a sparse matrix, if we use a p-nearest neighbor graph,
the average nonzero elements on each row of W
u
is p. Thus, we only need mpk additions and mpk
multiplications to compute W
u
U. Similarly, for W
v
V, we need the same operation counts as W
u
U.
Suppose the multiplicative updates stop after Iter iterations, the time cost of multiplicative updates then
becomes O(Iter ? mnk). Therefore, the overall running time of GNMTF is similar to the standard
NMTF and CNMTF.
1335
addition multiplication division overall
GNMTF:U 2k
3
+ (2m+ n)k
2
+m(n+ p)k 2k
3
+ (2m+ n)k
2
+m(n+ p+ 7)k mk O(mnk)
GNMTF:H 2k
3
+ (m+ n+ 2)k
2
+mnk 2k
3
+ (m+ n+ 1)k
2
+mnk k
2
O(mnk)
GNMTF:V 2k
3
+ (2n+m)k
2
+ n(m+ p)k 2k
3
+ (2n+m)k
2
+ n(m+ p+ 7)k nk O(mnk)
Table 1: Computational operation counts for each iteration in GNMTF.
4 Experiments
4.1 Data Sets
Sentiment classification has been extensively studied in the literature. Among these, a large majority
proposed experiments performed on the benchmarks made of Movies Reviews (Pang et al., 2002) and
Amazon products (Blitzer et al., 2007).
Movies data This data set has been widely used for sentiment analysis in the literature (Pang et
al., 2002), which consists of 1000 positive and 1000 negative reviews drawn from the IMDB archive of
rec.arts.movies.reviews.newsgroups.
Amazon data This data set is heterogeneous, heavily unbalanced and large-scale, a smaller ver-
sion has been released. The reduced data set contains 4 product types: Kitchen, Books, DVDs, and
Electronics (Blitzer et al., 2007). There are 4000 positive and 4000 negative reviews.
1
For these two data sets, we select 8000 words with highest document-frequency to generate the vo-
cabulary. Stopwords
2
are removed and a normalized term-frequency representation is used. In order to
construct the lexical prior knowledge matrixU
0
, we use the sentiment lexicon generated by (Hu and Liu,
2004). It contains 2,006 positive words (e.g., ?beautiful?) and 4,783 negative words (e.g., ?upset?).
4.2 Unsupervised Sentiment Classification
Our first experiment is to explore the benefits of incorporating the geometric information in the unsu-
pervised paradigm (that is C
v
= 0). Therefore, the third part in equation (7) will be ignored. For this
unsupervised paradigm of GNMTF, we empirically set ? = ? = ? = 1, ?
1
= ?
2
= 1, Iter = 100 and
run GNMTF 10 repeated times to remove any randomness caused by the random initialization. Due to
limited space, we do not present the impacts of the parameters on the learning model. Now we compare
our proposed GNMTF with the following four categories of methods:
(1) Lexicon-Based Methods (LBM in short): Taboada et al. (2011) proposed to incorporate intensifi-
cation and negation to refine the sentiment score for each document. This is the state-of-the-art lexicon-
based method for unsupervised sentiment classification.
(2) Document Clustering Methods: We choose the most representative cluster methods, K-means,
NMTF, Information-Theoretic Co-clustering (ITCC) (Dhillon et al., 2003), and Euclidean Co-clustering
method (ECC) (Cho et al., 2004). We set the number of clusters as two in these methods. Note that all
these methods do not make use of the sentiment lexicon.
(3) Constrained NMTF (CNMTF in short): Li et al. (2009) incorporated the sentiment lexicon into
NMTF as a domain-independent prior constraint.
(4) Graph co-regularized Non-negative Matrix Tri-factorization (GNMTF in short): It is a new algo-
rithm proposed in this paper. We use cosine similarity for constructing the p-nearest neighbor graph for
its simplicity. The number of nearest neighbor p is set to 10 empirically both on document and word
spaces.
4.2.1 Sentiment Classification Results
The experimental results are reported in Table 2. We perform a significant test, i.e., a t-test with a default
significant level of 0.05. From Table 2, we can see that (1) Both CNMTF and GNMTF consider the
lexical prior knowledge from off-the-shelf sentiment lexicon and achieve better performance than NMTF.
This suggests the importance of the lexical prior knowledge in learning the sentiment classification (row
1
The data set can be freely downloaded from http://www.cs.jhu.edu/ mdredze/datasets/sentiment/.
2
http://truereader.com/manuals/onix/stopwords1.html
1336
# Methods Movies Amazon
1 LBM 0.632 0.580
2 K-means 0.543 (-8.9%) 0.535 (-4.5%)
3 NMTF 0.561 (-7.1%) 0.547 (-3.3%)
4 ECC 0.678 (+4.6%) 0.642 (+6.2%)
5 ITCC 0.714 (+8.2%) 0.655 (+7.5%)
6 CNMTF 0.695 (+6.3%) 0.658 (+7.8%)
7 GNMTF 0.736 (+10.4%) 0.705 (+12.5%)
Table 2: Sentiment classification accuracy of unsupervised paradigm on the data sets. Improvements of
K-means, NMTF, ITCC, ECC, CNMTF and GNMTF over baseline LBM are shown in parentheses.
0 20 40 60 80 1000.2
0.25
0.3
0.35
0.4
0.45
0.5
(a) Movies data
Objec
tive fu
nction
 value
0 20 40 60 80 1000.46
0.48
0.5
0.52
0.54
0.56
0.58
0.6
0.62
0.64
0.66
(b) Amazon data
Objec
tive fu
nction
 value
Figure 1: Convergence curves of GNMTF on both data sets.
3 vs. row 6 and row 7); (2) Regardless of the data sets, our GNMTF significantly outperforms state-of-
the-art CNMTF and achieves the best performance. This shows the superiority of geometric information
and graph co-regularization framework (row 4 vs. row 5, the improvements are statistically significant at
p < 0.05).
4.2.2 Convergence Behavior
In subsection 3.3.1, we have shown that the multiplicative updates given by equations (8)?(10) are
convergent. Here, we empirically show the convergence behavior of GNMTF.
Figure 1 shows the convergence curves of GNMTF on Movies and Amazon data sets. From the figure,
y-axis is the value of objective function and x-axis denotes the iteration number. We can see that the
multiplicative updates for GNMTF converge very fast, usually within 50 iterations.
4.3 Semi-supervised Sentiment Classification
In this subsection, we describe our proposed GNMTF with a few labeled documents. For this semi-
supervised paradigm of GNMTF, we empirically set Iter = 100, ?
1
= ?
2
= 2, ? = ? = ? = ? = 1 and
p = 10 on document and word spaces and also run 10 repeated times to remove any randomness caused
by the random initialization. Due to limited space, we do not give an in-depth parameter analysis. For
CNMTF, we set ? = ? = 1 for fair comparison. We also compare our proposed GNMTF with some
representative semi-supervised approaches described in (Li et al., 2009): (1) Semi-supervised learning
with local and global consistency (Consistency Method in short) (Zhou et al., 2004); (2) Semi-supervised
learning using gaussian fields and harmonic functions (GFHF in short) (Zhu et al., 2003). Besides,
we also compare the results of our proposed GNMTF with the representative supervised classification
method: support vector machine (SVM), which has been widely used in sentiment classification (Pang
et al., 2002).
The results are presented in Figure 2. From the figure, we can see that GNMTF outperforms other
methods over the entire range of number of labeled documents on both data sets. By this observation,
we can conclude that taking the geometric information can still improve the sentiment classification
accuracy in semi-supervised paradigm.
1337
0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.50.45
0.5
0.55
0.6
0.65
0.7
0.75
0.8
(a) Movies data
Senti
ment
 class
ificati
on ac
curac
y
SVMConsistency MethodGFHFCNMTFGNMTF 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.50.55
0.6
0.65
0.7
0.75
0.8
0.85
(b) Amazon data
Senti
ment
 class
ificati
on ac
curac
y
SVMConsistency MethodGFHFCNMTFGNMTF
Figure 2: Sentiment classification accuracy vs. different percentage of labeled documents, where x-axis
denotes the number of documents labeled as a fraction of the original labeled documents.
5 Related Work
Sentiment classification has gained widely interest in NLP community, we point the readers to recent
books (Pang and Lee, 2008; Liu, 2012) for an in-depth survey of literature on sentiment analysis.
Methods for automatically classifying sentiments expressed in products and movie reviews can
roughly be divided into supervised and unsupervised (or semi-supervised) sentiment analysis. Super-
vised techniques have been proved promising and widely used in sentiment classification (Pang et al.,
2002; Pang and Lee, 2008; Liu, 2012). However, the performance of these methods relies on manually
labeled training data. In some cases, the labeling work may be time-consuming and expensive. This
motivates the problem of learning robust sentiment classification via unsupervised (or semi-supervised)
paradigm.
The most representative way to perform semi-supervised paradigm is to employ partial labeled data to
guide the sentiment classification (Goldberg and Zhu, 2006; Sindhwani and Melville, 2008; Wan, 2009;
Li et al., 2011). However, we do not have any labeled data at hand in many situations, which makes
the unsupervised paradigm possible. The most representative way to perform unsupervised paradigm
is to use a sentiment lexicon to guide the sentiment classification (Turney, 2002; Taboada et al., 2011)
or learn sentiment orientation via a matrix factorization clustering framework (Li et al., 2009; ?; Hu
et al., 2013). In contrast, we perform sentiment classification with the different model formulation and
learning algorithm, which considers both word-level and document-level sentiment-related contextual
information (e.g., the neighboring words or documents tend to share the same sentiment polarity) into
a unified framework. The proposed framework makes use of the valuable geometric information to
compensate the problem of lack of labeled data for sentiment classification. In addition, some researchers
also explored the matrix factorization techniques for other NLP tasks, such as relation extraction (Peng
and Park, 2013) and question answering (Zhou et al., 2013)
Besides, many studies address some other aspects of sentiment analysis, such as cross-domain senti-
ment classification (Blitzer et al., 2007; Pan et al., 2010; Hu et al., 2011; Bollegala et al., 2011; Glorot
et al., 2011), cross-lingual sentiment classification (Wan, 2009; Lu et al., 2011b; Meng et al., 2012) and
imbalanced sentiment classification (Li et al., 2011), which are out of scope of this paper.
6 Conclusion and Future Work
In this paper, we propose a novel algorithm, called graph co-regularized non-negative matrix tri-
factorization (GNMTF), from a geometric perspective. GNMTF assumes that if two words (or docu-
ments) are sufficiently close to each other, they tend to share the same sentiment polarity. To achieve
this, we encode the geometric information by constructing the nearest neighbor graphs, in conjunction
with a non-negative matrix tri-factorization framework. We derive an efficient algorithm for learning
the factorization, analyze its complexity, and provide proof of convergence. Our empirical study on two
open data sets validates that GNMTF can consistently improve the sentiment classification accuracy in
comparison to state-of-the-art methods.
1338
There are some ways in which this research could be continued. First, some other ways should be
considered to construct the graphs (e.g., hyperlinks between documents, synonyms or co-occurrences
between words). Second, we will try to extend the proposed framework for other aspects of sentiment
analysis, such as cross-domain or cross-lingual settings.
Acknowledgments
This work was supported by the National Natural Science Foundation of China (No. 61303180 and
No. 61272332), the Beijing Natural Science Foundation (No. 4144087), CCF Opening Project of Chi-
nese Information Processing, and also Sponsored by CCF-Tencent Open Research Fund. We thank the
anonymous reviewers for their insightful comments.
References
M. Belkin and P. Niyogi. 2001. Laplacian eigenmaps and spectral techniques for embedding and clustering. In
Proceedings of NIPS, pages 585-591.
J. Blitzer, M. Dredze and F. Pereira. 2007. Biographies, bollywood, boom-boxes and blenders: domain adaptation
for sentiment classification. In Proceedings of ACL, pages 440-447.
D. Bollegala, D. Weir, and J. Carroll. 2011. Using multiples sources to construct a sentiment sensitive thesaurus.
In Proceedings of ACL, pages 132-141.
S. Boyd and L. Vandenberghe. 2004. Convex Optimization. Cambridge university press.
D. Cai, X. He, J. Han, and T. Huang. 2011. Graph regularized non-negative matrix factorization for data represen-
tation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 33(8): 1548-1560.
H. Cho, I. Dhillon, Y. Guan, and S. Sra. 2004. Minimum sum squared residue co-clutering of gene expression
data. In Proceedings of SDM, pages 22-24.
F. Chung. 1997. Spectral graph theory. Regional Conference Series in Mathematics, Volume 92.
I. Dhillon, S. Mallela, and D. Modha. 2003. Information-theoretic Co-clustering. In Proceedings of KDD, pages
89-98.
C. Ding, T. Li, W. Peng, and H. Park. 2006. Orthogonal non-negative matrix tri-factorization for clustering. In
Proceedings of KDD, pages 126-135.
X. Glorot, A. Bordes, and Y. Bengio. 2011. Domain adaptation for larage-scale sentiment classification: a deep
learning approach. In Proceedings of ICML.
A. Goldberg and X. Zhu. 2006. Seeing stars when there aren?t many stars: graph-based semi-supervised learning
for sentiment categorization. In Proceedings of NAACL Workshop.
Y. He, C. Lin and H. Alani. 2011. Automatically extracting polarity-bearing topics for cross-domain sentiment
classification. In Proceedings of ACL, pages 123-131.
M. Hu and B. Liu. 2004. Mining and summarizing customer reviews. In Proceedings of KDD.
X. Hu, J. Tang, H. Gao, and H. Liu. 2013. Unsupervised sentiment analysis with emotional signals. In Proceedings
of WSDM.
X. Hu, N. Sun, C. Zhang, and T. Chua. 2009. Exploiting internal and external semantics for the clustering of short
texts using world knowldge. In Proceedings of CIKM, pages 919-928.
H. Kim and H. Park. 2008. Non-negative matrix factorization based on alternating non-negativity constrained
least squares and active set method. SIAM J Matrix Anal Appl, 30(2):713-730.
D. Lee and H. Seung. 2001. Algorithms for non-negative matrix factorization. In Proceedings of NIPS.
S. Li, Z. Wang, G. Zhou, and S. Lee. 2011. Semi-supervised learning for imbalanced sentiment classification. In
Proceedings of IJCAI, pages 1826-1831.
1339
T. Li, Y. Zhang, and V. Singhwani. 2009. A non-negative matrix tri-factorization approach to sentiment classifica-
tion with lexical prior knowledge. In Proceedings of ACL, pages 244-252.
C. Lin. 2007. Projected gradient methods for nonnegative matrix factorization. Neural Comput, 19(10):2756-
2779.
B. Liu. 2012. Sentiment analysis and opinion mining. Morgan & Claypool Publishers.
B. Lu, C. Tan, C. Cardie, and B. Tsou. 2011. Joint bilingual sentiment classification with unlabeled parallel
corpora. In Proceedings of ACL, pages 320-330.
Y. Lu, M. Castellanos, U. Dayal, and C. Zhai. 2011. Automatic construction of a context-aware sentiment lexicon:
an optimization approach. In Proceedings of WWW, pages 347-356.
X. Meng, F. Wei, X. Liu, M. Zhou, G. Xu, and H. Wang. 2012. Cross-lingual mixture model for sentiment
classification. In Proceedings of ACL, pages 572-581.
V. Ng, S. Dasgupta, and S. Arifin. 2006. Examing the role of linguistic knowlege sources in the automatic
identification and classificaton of reviews. In Proceedings of ACL.
S. Pan, X. Ni, J. Sun, Q. Yang, and Z. Chen. 2010. Cross-domain sentiment classification via spectral feature
alignment. In Proceedings of WWW.
B. Pang and L. Lee. 2008. Opinion mining and sentiment analysis. Foundations and Trends in Informaiton
Retrieval, pages 1-135.
B. Pang, L. Lee, S. Vaithyanathan. 2002. Thumbs up? sentiment classification using machine learning techniques.
In Proceedings of EMNLP, pages 79-86.
S. Riedel, L. Yao, A. McCallum, and B. Marlin. 2013. Relation extraction with matrix factorization and universal
schemas. In Proceedings of NAACL.
W. Peng and D. Park. 2011. Generative adjective sentiment dictionary for social media sentiment analysis using
constrained nonnegative matrix factorization. In Proceedings of ICWSM.
S. Roweis and L. Saul. 2000. Nonlinear dimensionality reduction by locally linear embedding. Science,
290(5500):2323-2326.
V. Sindhwani and P. Melville. 2008. Document-word co-regulariztion for semi-supervised sentiment analysis. In
Proceedings of ICDM, pages 1025-1030.
J. Tenenbaum, V. Silva, and J. Langford. 2000. A global geometric framework for nonlinear dimensionality
reduction. Science, 290(5500):2319-2323.
M. Taboada, J. Brooke, M. Tofiloski, K. Voll, and M. Stede. 2011. Lexicon-based methods for sentiment analysis.
Computational Linguistics.
P. Turney. 2002. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of
reviews. In Proceedings of ACL, pages 417-424.
X. Wan. 2009. Co-training for cross-lingual sentiment classification. In Proceedings of ACL, pages 235-243.
D. Zhou, Q. Bousquet, T. Lal, J. Weston, and B. Scholkopf. 2004. Learning with local and global consistency. In
Proceedings of NIPS.
G. Zhou, F. Liu, Y. Liu, S. He, and J. Zhao. 2013. Statistical machine translation improves question retrieval in
community question answering via matrix factorization. In Proceedings of ACL, pages 852-861.
X. Zhu, Z. Ghahramani, and J. Lafferty. 2003. Semi-supervised learning using gaussian fields and harmonic
functions. In Proceedings of ICML.
1340
Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 2335?2344, Dublin, Ireland, August 23-29 2014.
Relation Classification via Convolutional Deep Neural Network
Daojian Zeng, Kang Liu, Siwei Lai, Guangyou Zhou and Jun Zhao
National Laboratory of Pattern Recognition
Institute of Automation, Chinese Academy of Sciences
95 Zhongguancun East Road, Beijing 100190, China
{djzeng,kliu,swlai,gyzhou,jzhao}@nlpr.ia.ac.cn
Abstract
The state-of-the-art methods used for relation classification are primarily based on statistical ma-
chine learning, and their performance strongly depends on the quality of the extracted features.
The extracted features are often derived from the output of pre-existing natural language process-
ing (NLP) systems, which leads to the propagation of the errors in the existing tools and hinders
the performance of these systems. In this paper, we exploit a convolutional deep neural network
(DNN) to extract lexical and sentence level features. Our method takes all of the word tokens as
input without complicated pre-processing. First, the word tokens are transformed to vectors by
looking up word embeddings
1
. Then, lexical level features are extracted according to the given
nouns. Meanwhile, sentence level features are learned using a convolutional approach. These
two level features are concatenated to form the final extracted feature vector. Finally, the fea-
tures are fed into a softmax classifier to predict the relationship between two marked nouns. The
experimental results demonstrate that our approach significantly outperforms the state-of-the-art
methods.
1 Introduction
The task of relation classification is to predict semantic relations between pairs of nominals and can
be defined as follows: given a sentence S with the annotated pairs of nominals e
1
and e
2
, we aim
to identify the relations between e
1
and e
2
(Hendrickx et al., 2010). There is considerable interest in
automatic relation classification, both as an end in itself and as an intermediate step in a variety of NLP
applications.
The most representative methods for relation classification use supervised paradigm; such methods
have been shown to be effective and yield relatively high performance (Zelenko et al., 2003; Bunescu
and Mooney, 2005; Zhou et al., 2005; Mintz et al., 2009). Supervised approaches are further divided
into feature-based methods and kernel-based methods. Feature-based methods use a set of features that
are selected after performing textual analysis. They convert these features into symbolic IDs, which are
then transformed into a vector using a paradigm that is similar to the bag-of-words model
2
. Conversely,
kernel-based methods require pre-processed input data in the form of parse trees (such as dependency
parse trees). These approaches are effective because they leverage a large body of linguistic knowledge.
However, the extracted features or elaborately designed kernels are often derived from the output of pre-
existing NLP systems, which leads to the propagation of the errors in the existing tools and hinders the
performance of such systems (Bach and Badaskar, 2007). It is attractive to consider extracting features
that are as independent from existing NLP tools as possible.
To identify the relations between pairs of nominals, it is necessary to a skillfully combine lexical and
sentence level clues from diverse syntactic and semantic structures in a sentence. For example, in the
sentence ?The [fire]
e
1
inside WTC was caused by exploding [fuel]
e
2
?, to identify that fire and fuel are in a
This work is licenced under a Creative Commons Attribution 4.0 International License.Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
1
A word embedding is a distributed representation for a word. For example, Collobert et al. (2011) use a 50-dimensional
vector to represent a word.
2
http://en.wikipedia.org/wiki/Bag-of-words model
2335
Cause-Effect relationship, we usually leverage the marked nouns and the meanings of the entire sentence.
In this paper, we exploit a convolutional DNN to extract lexical and sentence level features for relation
classification. Our method takes all of the word tokens as input without complicated pre-processing,
such as Part-of-Speech (POS) tagging and syntactic parsing. First, all the word tokens are transformed
into vectors by looking up word embeddings. Then, lexical level features are extracted according to the
given nouns. Meanwhile, sentence level features are learned using a convolutional approach. These two
level features are concatenated to form the final extracted feature vector. Finally, the features are feed
into a softmax classifier to predict the relationship between two marked nouns.
The idea of extracting features for NLP using convolutional DNN was previously explored by Col-
lobert et al. (2011), in the context of POS tagging, chunking (CHUNK), Named Entity Recogni-
tion (NER) and Semantic Role Labeling (SRL). Our work shares similar intuition with that of Collobert
et al. (2011). In (Collobert et al., 2011), all of the tasks are considered as the sequential labeling prob-
lems in which each word in the input sentence is given a tag. However, our task, ?relation classification?,
can be considered a multi-class classification problem, which results in a different objective function.
Moreover, relation classification is defined as assigning relation labels to pairs of words. It is thus nec-
essary to specify which pairs of words to which we expect to assign relation labels. For that purpose, the
position features (PF) are exploited to encode the relative distances to the target noun pairs. To the best
of our knowledge, this work is the first example of using a convolutional DNN for relation classification.
The contributions of this paper can be summarized as follows.
? We explore the feasibility of performing relation classification without complicated NLP pre-
processing. A convolutional DNN is employed to extract lexical and sentence level features.
? To specify pairs of words to which relation labels should be assigned, position features are proposed
to encode the relative distances to the target noun pairs in the convolutional DNN.
? We conduct experiments using the SemEval-2010 Task 8 dataset. The experimental results demon-
strate that the proposed position features are critical for relation classification. The extracted lexical
and sentence level features are effective for relation classification. Our approach outperforms the
state-of-the-art methods.
2 Related Work
Relation classification is one of the most important topics in NLP. Many approaches have been explored
for relation classification, including unsupervised relation discovery and supervised classification. Re-
searchers have proposed various features to identify the relations between nominals using different meth-
ods.
In the unsupervised paradigms, contextual features are used. Distributional hypothesis theory (Harris,
1954) indicates that words that occur in the same context tend to have similar meanings. Accordingly, it is
assumed that the pairs of nominals that occur in similar contexts tend to have similar relations. Hasegawa
et al. (2004) adopted a hierarchical clustering method to cluster the contexts of nominals and simply
selected the most frequent words in the contexts to represent the relation between the nominals. Chen
et al. (2005) proposed a novel unsupervised method based on model order selection and discriminative
label identification to address this problem.
In the supervised paradigm, relation classification is considered a multi-classification problem, and re-
searchers concentrate on extracting more complex features. Generally, these methods can be categorized
into two types: feature-based and kernel-based. In feature-based methods, a diverse set of strategies
have been exploited to convert the classification clues (such as sequences and parse trees) into feature
vectors (Kambhatla, 2004; Suchanek et al., 2006). Feature-based methods suffer from the problem
of selecting a suitable feature set when converting the structured representation into feature vectors.
Kernel-based methods provide a natural alternative to exploit rich representations of the input classifica-
tion clues, such as syntactic parse trees. Kernel-based methods allow the use of a large set of features
without explicitly extracting the features. Various kernels, such as the convolution tree kernel (Qian et
2336
WordRepresentation
FeatureExtraction
Output W3x
Figure 1: Architecture of the neural network used
for relation classification.
WindowProcessing
max over timesConvolution
tanh W2x
W1
WF
PF
Sentence levelFeatures
Figure 2: The framework used for extracting sen-
tence level features.
al., 2008), subsequence kernel (Mooney and Bunescu, 2005) and dependency tree kernel (Bunescu and
Mooney, 2005), have been proposed to solve the relation classification problem. However, the methods
mentioned above suffer from a lack of sufficient labeled data for training. Mintz et al. (2009) proposed
distant supervision (DS) to address this problem. The DS method selects sentences that match the facts
in a knowledge base as positive examples. The DS algorithm sometimes faces the problem of wrong
labels, which results in noisy labeled data. To address the shortcoming of DS, Riedel et al. (2010) and
Hoffmann et al. (2011) cast the relaxed DS assumption as multi-instance learning. Furthermore, Taka-
matsu et al. (2012) noted that the relaxed DS assumption would fail and proposed a novel generative
model to model the heuristic labeling process in order to reduce the wrong labels.
The supervised method has been demonstrated to be effective for relation detection and yields rela-
tively high performance. However, the performance of this method strongly depends on the quality of the
designed features. With the recent revival of interest in DNN, many researchers have concentrated on us-
ing Deep Learning to learn features. In NLP, such methods are primarily based on learning a distributed
representation for each word, which is also called a word embeddings (Turian et al., 2010). Socher et al.
(2012) present a novel recursive neural network (RNN) for relation classification that learns vectors in
the syntactic tree path that connects two nominals to determine their semantic relationship. Hashimoto
et al. (2013) also use an RNN for relation classification; their method allows for the explicit weighting
of important phrases for the target task. As mentioned in Section 1, it is difficult to design high quality
features using the existing NLP tools. In this paper, we propose a convolutional DNN to extract lexical
and sentence level features for relation classification; our method effectively alleviates the shortcomings
of traditional features.
3 Methodology
3.1 The Neural Network Architecture
Figure 1 describes the architecture of the neural network that we use for relation classification. The
network takes an input sentence and discovers multiple levels of feature extraction, where higher levels
represent more abstract aspects of the inputs. It primarily includes the following three components: Word
Representation, Feature Extraction and Output. The system does not need any complicated syntactic or
semantic preprocessing, and the input of the system is a sentence with two marked nouns. Then, the
word tokens are transformed into vectors by looking up word embeddings. In succession, the lexical and
sentence level features are respectively extracted and then directly concatenated to form the final feature
vector. Finally, to compute the confidence of each relation, the feature vector is fed into a softmax
classifier. The output of the classifier is a vector, the dimension of which is equal to the number of
predefined relation types. The value of each dimension is the confidence score of the corresponding
relation.
2337
Features Remark
L1 Noun 1
L2 Noun 2
L3 Left and right tokens of noun 1
L4 Left and right tokens of noun 2
L5 WordNet hypernyms of nouns
Table 1: Lexical level features.
3.2 Word Representation
In the word representation component, each input word token is transformed into a vector by looking
up word embeddings. Collobert et al. (2011) reported that word embeddings learned from significant
amounts of unlabeled data are far more satisfactory than the randomly initialized embeddings. In relation
classification, we should first concentrate on learning discriminative word embeddings, which carry more
syntactic and semantic information, using significant amounts of unlabeled data. Unfortunately, it usually
takes a long time to train the word embeddings
3
. However, there are many trained word embeddings that
are freely available (Turian et al., 2010). A comparison of the available word embeddings is beyond
the scope of this paper. Our experiments directly utilize the trained embeddings provided by Turian et
al.(2010).
3.3 Lexical Level Features
Lexical level features serve as important cues for deciding relations. The traditional lexical level features
primarily include the nouns themselves, the types of the pairs of nominals and word sequences between
the entities, the quality of which strongly depends on the results of existing NLP tools. Alternatively,
this paper uses generic word embeddings as the source of base features. We select the word embeddings
of marked nouns and the context tokens. Moreover, the WordNet hypernyms
4
are adopted as MVRNN
(Socher et al., 2012). All of these features are concatenated into our lexical level features vector l. Table
1 presents the selected word embeddings that are related to the marked nouns in the sentence.
3.4 Sentence Level Features
As mentioned in section 3.2, all of the tokens are represented as word vectors, which have been demon-
strated to correlate well with human judgments of word similarity. Despite their success, single word
vector models are severely limited because they do not capture long distance features and semantic com-
positionality, the important quality of natural language that allows humans to understand the meanings
of a longer expression. In this section, we propose a max-pooled convolutional neural network to offer
sentence level representation and automatically extract sentence level features. Figure 2 shows the frame-
work for sentence level feature extraction. In the Window Processing component, each token is further
represented as Word Features (WF) and Position Features (PF) (see section 3.4.1 and 3.4.2). Then, the
vector goes through a convolutional component. Finally, we obtain the sentence level features through a
non-linear transformation.
3.4.1 Word Features
Distributional hypothesis theory (Harris, 1954) indicates that words that occur in the same context tend
to have similar meanings. To capture this characteristic, the WF combines a word?s vector representation
and the vector representations of the words in its context. Assume that we have the following sequence
of words.
S : [People]
0
have
1
been
2
moving
3
back
4
into
5
[downtown]
6
The marked nouns are associated with a label y that defines the relation type that the marked pair contains.
Each word is also associated with an index into the word embeddings. All of the word tokens of the
sentence S are then represented as a list of vectors (x
0
,x
1
, ? ? ? ,x
6
), where x
i
corresponds to the word
3
Collobert et al. (2011) proposed a pairwise ranking approach to train the word embeddings, and the total training time for
an English corpus (Wikipedia) was approximately four weeks.
4
http://sourceforge.net/projects/supersensetag/
2338
embedding of the i-th word in the sentence. To use a context size of w, we combine the size w windows
of vectors into a richer feature. For example, when we take w = 3, the WF of the third word ?moving?
in the sentence S is expressed as [x
2
,x
3
,x
4
]. Similarly, considering the whole sentence, the WF can be
represented as follows:
{[x
s
,x
0
,x
1
], [x
0
,x
1
,x
2
], ? ? ? , [x
5
,x
6
,x
e
]}
5
3.4.2 Position Features
Relation classification is a very complex task. Traditionally, structure features (e.g., the shortest depen-
dency path between nominals) are used to solve this problem (Bunescu and Mooney, 2005). Apparently,
it is not possible to capture such structure information only through WF. It is necessary to specify which
input tokens are the target nouns in the sentence. For this purpose, PF are proposed for relation classi-
fication. In this paper, the PF is the combination of the relative distances of the current word to w
1
and
w
2
. For example, the relative distances of ?moving? in sentence S to ?people? and ?downtown? are 3
and -3, respectively. In our method, the relative distances also are mapped to a vector of dimension d
e
(a
hyperparameter); this vector is randomly initialized. Then, we obtain the distance vectors d
1
and d
2
with
respect to the relative distances of the current word to w
1
and w
2
, and PF = [d
1
,d
2
]. Combining the WF
and PF, the word is represented as [WF,PF]
T
, which is subsequently fed into the convolution component
of the algorithm.
3.4.3 Convolution
We will see that the word representation approach can capture contextual information through combina-
tions of vectors in a window. However, it only produces local features around each word of the sentence.
In relation classification, an input sentence that is marked with target nouns only corresponds to a re-
lation type rather than predicting label for each word. Thus, it might be necessary to utilize all of the
local features and predict a relation globally. When using neural network, the convolution approach is a
natural method to merge all of the features. Similar to Collobert et al. (2011), we first process the output
of Window Processing using a linear transformation.
Z = W
1
X (1)
X ? R
n
0
?t
is the output of the Window Processing task, where n
0
= w? n, n (a hyperparameter) is the
dimension of feature vector, and t is the token number of the input sentence. W
1
? R
n
1
?n
0
, where n
1
(a
hyperparameter) is the size of hidden layer 1, is the linear transformation matrix. We can see that the
features share the same weights across all times, which greatly reduces the number of free parameters to
learn. After the linear transformation is applied, the output Z ? R
n
1
?t
is dependent on t. To determine
the most useful feature in the each dimension of the feature vectors, we perform a max operation over
time on Z.
m
i
= maxZ(i, ?) 0 ? i ? n
1
(2)
where Z(i, ?) denote the i-th row of matrix Z. Finally, we obtain the feature vector m =
{m
1
,m
2
, ? ? ? ,m
n
1
}, the dimension of which is no longer related to the sentence length.
3.4.4 Sentence Level Feature Vector
To learn more complex features, we designed a non-linear layer and selected hyperbolic tanh as the
activation function. One useful property of tanh is that its derivative can be expressed in terms of the
function value itself:
d
dx
tanhx = 1? tanh
2
x (3)
It has the advantage of making it easy to compute the gradient in the backpropagation training procedure.
Formally, the non-linear transformation can be written as
g = tanh(W
2
m) (4)
5
x
s
and x
e
are special word embeddings that correspond to the beginning and end of the sentence, respectively.
2339
W2
? R
n
2
?n
1
is the linear transformation matrix, where n
2
(a hyperparameter) is the size of hidden
layer 2. Compared with m ? R
n
1
?1
, g ? R
n
2
?1
can be considered higher level features (sentence level
features).
3.5 Output
The automatically learned lexical and sentence level features mentioned above are concatenated into a
single vector f = [l, g]. To compute the confidence of each relation, the feature vector f ? R
n
3
?1
(n
3
equals n
2
plus the dimension of the lexical level features) is fed into a softmax classifier.
o = W
3
f (5)
W
3
? R
n
4
?n
3
is the transformation matrix and o ? R
n
4
?1
is the final output of the network, where n
4
is equal to the number of possible relation types for the relation classification system. Each output can
be then interpreted as the confidence score of the corresponding relation. This score can be interpreted
as a conditional probability by applying a softmax operation (see Section 3.6).
3.6 Backpropagation Training
The DNN based relation classification method proposed here could be stated as a quintuple ? =
(X,N,W
1
,W
2
,W
3
)
6
. In this paper, each input sentence is considered independently. Given an in-
put example s, the network with parameter ? outputs the vector o, where the i-th component o
i
contains
the score for relation i. To obtain the conditional probability p(i|x, ?), we apply a softmax operation over
all relation types:
p(i|x, ?) =
e
o
i
n
4
?
k=1
e
o
k
(6)
Given all our (suppose T ) training examples (x
(i)
; y
(i)
), we can then write down the log likelihood of the
parameters as follows:
J (?) =
T
?
i=1
log p(y
(i)
|x
(i)
, ?) (7)
To compute the network parameter ?, we maximize the log likelihood J(?) using a simple optimization
technique called stochastic gradient descent (SGD). N,W
1
,W
2
and W
3
are randomly initialized and
X is initialized using the word embeddings. Because the parameters are in different layers of the neural
network, we implement the backpropagation algorithm: the differentiation chain rule is applied through
the network until the word embedding layer is reached by iteratively selecting an example (x, y) and
applying the following update rule.
? ? ? + ?
? log p(y|x, ?)
??
(8)
4 Dataset and Evaluation Metrics
To evaluate the performance of our proposed method, we use the SemEval-2010 Task 8 dataset (Hen-
drickx et al., 2010). The dataset is freely available
7
and contains 10,717 annotated examples, including
8,000 training instances and 2,717 test instances. There are 9 relationships (with two directions) and
an undirected Other class. The following are examples of the included relationships: Cause-Effect,
Component-Whole and Entity-Origin. In the official evaluation framework, directionality is taken into
account. A pair is counted as correct if the order of the words in the relationship is correct. For example,
both of the following instances S
1
and S
2
have the relationship Component-Whole.
S
1
: The [haft]
e
1
of the [axe]
e
2
is make ? ? ? ? Component-Whole(e
1
,e
2
)
S
2
: This [machine]
e
1
has two [units]
e
2
? ? ? ? Component-Whole(e
2
,e
1
)
6
N represents the word embeddings of WordNet hypernyms.
7
http://docs.google.com/View?id=dfvxd49s 36c28v9pmw
2340
?# Window size
1 2 3 4 5 6 7
F1
72
74
76
78
80
82
# Hidden layer 1
0 100 200 300 400 500 600
F1
72
74
76
78
80
82
# Hidden layer 2
0 100 200 300 400 500 600
F1
72
74
76
78
80
82
Figure 3: Effect of hyperparameters.
However, these two instances cannot be classified into the same category because Component-
Whole(e
1
,e
2
) and Component-Whole(e
2
,e
1
) are different relationships. Furthermore, the official rank-
ing of the participating systems is based on the macro-averaged F1-scores for the nine proper relations
(excluding Other). To compare our results with those obtained in previous studies, we adopt the macro-
averaged F1-score and also account for directionality into account in our following experiments
8
.
5 Experiments
In this section, we conduct three sets of experiments. The first is to test several variants via cross-
validation to gain some understanding of how the choice of hyperparameters impacts upon the perfor-
mance. In the second set of experiments, we make comparison of the performance among the convolu-
tional DNN learned features and various traditional features. The goal of the third set of experiments is
to evaluate the effectiveness of each extracted feature.
5.1 Parameter Settings
In this section, we experimentally study the effects of the three parameters in our proposed method:
the window size in the convolutional component w, the number of hidden layer 1, and the number of
hidden layer 2. Because there is no official development dataset, we tuned the hyperparameters by trying
different architectures via 5-fold cross-validation.
In Figure 3, we respectively vary the number of hyper parameters w, n
1
and n
2
and compute the F1.
We can see that it does not improve the performance when the window size is greater than 3. Moreover,
because the size of our training dataset is limited, the network is prone to overfitting, especially when
using large hidden layers. From Figure 3, we can see that the parameters have a limited impact on the
results when increasing the numbers of both hidden layers 1 and 2. Because the distance dimension has
little effect on the result (this is not illustrated in Figure 3), we heuristically choose d
e
= 5. Finally,
the word dimension and learning rate are the same as in Collobert et al. (2011). Table 2 reports all the
hyperparameters used in the following experiments.
Hyperparameter Window size Word dim. Distance dim. Hidden layer 1 Hidden layer 2 Learning rate
Value w = 3 n = 50 d
e
= 5 n
1
= 200 n
2
= 100 ? = 0.01
Table 2: Hyperparameters used in our experiments.
5.2 Results of Comparison Experiments
To obtain the final performance of our automatically learned features, we select seven approaches as com-
petitors to be compared with our method in Table 3. The first five competitors are described in Hendrickx
et al. (2010), all of which use traditional features and employ SVM or MaxEnt as the classifier. These
systems design a series of features and take advantage of a variety of resources (WordNet, ProBank,
and FrameNet, for example). RNN represents recursive neural networks for relation classification, as
8
The corpus contains a Perl-based automatic evaluation tool.
2341
Classifier Feature Sets F1
SVM POS, stemming, syntactic patterns 60.1
SVM word pair, words in between 72.5
SVM POS, stemming, syntactic patterns, WordNet 74.8
MaxEnt POS, morphological, noun compound, thesauri, Google n-grams, WordNet 77.6
SVM POS, prefixes, morphological, WordNet, dependency parse, Levin classed, ProBank,
FrameNet, NomLex-Plus, Google n-gram, paraphrases, TextRunner
82.2
RNN - 74.8
POS, NER, WordNet 77.6
MVRNN - 79.1
POS, NER, WordNet 82.4
Proposed word pair, words around word pair, WordNet 82.7
Table 3: Classifier, their feature sets and the F1-score for relation classification.
proposed by Socher et al. (2012). This method learns vectors in the syntactic tree path that connect two
nominals to determine their semantic relationship. The MVRNN model builds a single compositional
semantics for the minimal constituent, including both nominals as RNN (Socher et al., 2012). It is almost
certainly too much to expect a single fixed transformation to be able to capture the meaning combination
effects of all natural language operators. Thus, MVRNN assigns a matrix to every word and modifies the
meanings of other words instead of only considering word embeddings in the recursive procedure.
Table 3 illustrates the macro-averaged F1 measure results for these competing methods along with the
resources, features and classifier used by each method. Based on these results, we make the following
observations:
(1) Richer feature sets lead to better performance when using traditional features. This improvement
can be explained by the need for semantic generalization from training to test data. The quality of
traditional features relies on human ingenuity and prior NLP knowledge. It is almost impossible to
manually choose the best feature sets.
(2) RNN and MVRNN contain feature learning procedures; thus, they depend on the syntactic tree used
in the recursive procedures. Errors in syntactic parsing inhibit the ability of these methods to learn
high quality features. RNN cannot achieve a higher performance than the best method that uses
traditional features, even when POS, NER and WordNet are added to the training dataset. Compared
with RNN, the MVRNN model can capture the meaning combination effectively and achieve a higher
performance.
(3) Our method achieves the best performance among all of the compared methods. We also perform
a t-test (p 6 0.05), which indicates that our method significantly outperforms all of the compared
methods.
5.3 The Effect of Learned Features
Feature Sets F1
Lexical L1 34.7
+L2 53.1
+L3 59.4
+L4 65.9
+L5 73.3
Sentence WF 69.7
+PF 78.9
Combination all 82.7
Table 4: Score obtained for various sets of features on for the test set. The bottom portion of the table
shows the best combination of lexical and sentence level features.
In our method, the network extract lexical and sentence level features. The lexical level features pri-
marily contain five sets of features (L1 to L5). We performed ablation tests on the five sets of features
from the lexical part of Table 4 to determine which type of features contributed the most. The results are
2342
presented in Table 4, from which we can observe that our learned lexical level features are effective for
relation classification. The F1-score is improved remarkably when new features are added. Similarly, we
perform experiment on the sentence level features. The system achieves approximately 9.2% improve-
ments when adding PF. When all of the lexical and sentence level features are combined, we achieve the
best result.
6 Conclusion
In this paper, we exploit a convolutional deep neural network (DNN) to extract lexical and sentence
level features for relation classification. In the network, position features (PF) are successfully proposed
to specify the pairs of nominals to which we expect to assign relation labels. The system obtains a
significant improvement when PF are added. The automatically learned features yield excellent results
and can replace the elaborately designed features that are based on the outputs of existing NLP tools.
Acknowledgments
This work was sponsored by the National Basic Research Program of China (No. 2014CB340503) and
the National Natural Science Foundation of China (No. 61272332, 61333018, 61202329, 61303180).
This work was supported in part by Noah?s Ark Lab of Huawei Tech. Co. Ltd. We thank the anonymous
reviewers for their insightful comments.
References
Nguyen Bach and Sameer Badaskar. 2007. A review of relation extraction. Literature review for Language and
Statistics II.
Razvan C. Bunescu and Raymond J. Mooney. 2005. A shortest path dependency kernel for relation extraction. In
Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language
Processing, pages 724?731.
Jinxiu Chen, Donghong Ji, Chew Lim Tan, and Zhengyu Niu. 2005. Unsupervised feature selection for relation
extraction. In Proceedings of the International Joint Conference on Natural Language Processing, pages 262?
267.
Ronan Collobert, Jason Weston, L?eon Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel Kuksa. 2011.
Natural language processing (almost) from scratch. The Journal of Machine Learning Research, 12:2493?2537.
Zellig Harris. 1954. Distributional structure. Word, 10(23):146?162.
Takaaki Hasegawa, Satoshi Sekine, and Ralph Grishman. 2004. Discovering relations among named entities from
large corpora. In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, pages
415?422.
Kazuma Hashimoto, Makoto Miwa, Yoshimasa Tsuruoka, and Takashi Chikayama. 2013. Simple customization
of recursive neural networks for semantic relation classification. In Proceedings of the 2013 Conference on
Empirical Methods in Natural Language Processing, pages 1372?1376.
Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva, Preslav Nakov, Diarmuid
?
O. S?eaghdha, Sebastian Pad?o, Marco
Pennacchiotti, Lorenza Romano, and Stan Szpakowicz. 2010. Semeval-2010 task 8: Multi-way classification
of semantic relations between pairs of nominals. In Proceedings of the 5th International Workshop on Semantic
Evaluation, SemEval ?10, pages 33?38.
Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke Zettlemoyer, and Daniel S. Weld. 2011. Knowledge-based
weak supervision for information extraction of overlapping relations. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguistics: Human Language Technologies - Volume 1, pages 541?
550.
Nanda Kambhatla. 2004. Combining lexical, syntactic, and semantic features with maximum entropy models for
extracting relations. In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics
on Interactive poster and demonstration sessions.
2343
Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky. 2009. Distant supervision for relation extraction without
labeled data. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th
International Joint Conference on Natural Language Processing of the AFNLP: Volume 2, pages 1003?1011.
Raymond J Mooney and Razvan C Bunescu. 2005. Subsequence kernels for relation extraction. In Advances in
neural information processing systems, pages 171?178.
Longhua Qian, Guodong Zhou, Fang Kong, Qiaoming Zhu, and Peide Qian. 2008. Exploiting constituent depen-
dencies for tree kernel-based semantic relation extraction. In Proceedings of the 22nd International Conference
on Computational Linguistics, pages 697?704.
Sebastian Riedel, Limin Yao, and Andrew McCallum. 2010. Modeling relations and their mentions without
labeled text. In Proceedings of the 2010 European conference on Machine learning and knowledge discovery
in databases: Part III, pages 148?163.
Richard Socher, Brody Huval, Christopher D. Manning, and Andrew Y. Ng. 2012. Semantic compositionality
through recursive matrix-vector spaces. In Proceedings of the 2012 Joint Conference on Empirical Methods in
Natural Language Processing and Computational Natural Language Learning, pages 1201?1211.
Fabian M. Suchanek, Georgiana Ifrim, and Gerhard Weikum. 2006. Combining linguistic and statistical analysis
to extract relations from web documents. In Proceedings of the 12th ACM SIGKDD international conference
on Knowledge discovery and data mining, pages 712?717.
Shingo Takamatsu, Issei Sato, and Hiroshi Nakagawa. 2012. Reducing wrong labels in distant supervision for
relation extraction. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics:
Long Papers - Volume 1, pages 721?729.
Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010. Word representations: a simple and general method for
semi-supervised learning. In Proceedings of the 48th Annual Meeting of the Association for Computational
Linguistics, pages 384?394.
Dmitry Zelenko, Chinatsu Aone, and Anthony Richardella. 2003. Kernel methods for relation extraction. The
Journal of Machine Learning Research, 3:1083?1106.
GuoDong Zhou, Su Jian, Zhang Jie, and Zhang Min. 2005. Exploring various knowledge in relation extraction.
In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 427?434.
2344
