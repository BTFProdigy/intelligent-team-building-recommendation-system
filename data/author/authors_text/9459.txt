Lexicalized Tree Automata-based Grammars for 
Translating Conversational Texts 
Kiyoshi YAMABANA Shinichi ANDO Kiyomi MIMURA 
Computer & Communication Media Research, NEC Corporation 
4-1-1, Miyazaki, Miyamae-ku, Kawasaki 216-8555, JAPAN 
k-yamabana@ct.jp.nec.com s-ando@cw.jp.nec.com k-lnimura@dad p.nec.com 
Abstract 
We propose a new lexicalizcd grammar 
formalism called Lexicalized Tree 
Automata-based Grammar, which lcxicalizes 
tree acccptors instead of trees themselves. We 
discuss the properties of the grammar and 
present a chart parsing algorithm. Wc have 
implemented a translation module for 
conversational texts using this formalism, and 
applied it to an experimental automatic 
interpretation system (speech translation 
system). 
1 Introduction 
Achieving both broad coverage for general texts 
and better quality for texts from a restricted omain 
has been an important issue in practical natural 
language processing. Conversational language is a 
typical domain this problem has been notable, since 
they often include idioms, colloquial expressions 
and/or extra-grammatical expressions while a 
majority of utterances still obey a standard 
grammar. 
Furusc and Iida (1994) proposed an approach to 
spoken-language translation based on pattern 
matching on the surface form, combined with an 
cxalnple-based disambiguation method. Since the 
grammar rules are simple patterns containing 
surface expressions or constituent boundaries, they 
are easy to write, and domain-specific knowledge 
can be easily accumulated in the grammar. On the 
other hand, relationships between two trees arc not 
easy to describe, especially when they are separated 
apart on a larger tree. This might become an 
obstacle in expanding a domain-specific grammar 
into a general gralnlnar with a wide coverage. 
Brown (1996) approached to this problem 
employing a nmlti-engine architecture, where 
outputs from Transfer Machine Translation (MT), 
Knowledge-based MT and Example-based MT are 
combined on the chart during parsing. Ruland et al 
(1998) employs a multi-parser multi-strategy 
architecture for robust parsing of the spoken 
language, where the results fi'om different engines 
are combined on the chart using probability-based 
scores. A difficult part with these hybrid 
architectures is that it is not easy to properly 
compare and combine the results fi'om differcnt 
engines designed on different principles. In addition, 
these methods will require much computational 
power, since multiple parsers have to be run 
simultaneously. 
A third approach, such as Takeda (1996), is 
grammar-based. In this approach, a method is 
provided to associate a grammar ule to a word or a 
set of words in order to encode their idiosyncratic 
syntactic behaviour. An associated grammar rule 
can be sccn as a kind of example if it is described 
mostly by the surface level information. As is 
apparent fl'om this description, this approach is an 
application of strong lexicalization of a grammar 
(Schabes, Abeill6 and Joshi, 1988). 
This approach allows coexistence of general 
rules and surface-level patterns in a uniform 
framework. Combination of both types of rules is 
naturally defined. These advantages arc a good 
reason to employ strongly lexicalized grammars as 
the basic grammar formalism. However, wc feel 
there are some points to be improved in the current 
strongly lcxicalized grammar formalislns. 
The first point is the existence of globally 
defined special tree operation, which requires a 
special parsing algorithm. In a strongly lexicalized 
grammar formalism, each word is associated with a 
finite set of trees anchored by that word. The tree 
operations usually include substitution of a leaf 
node by another tree, corresponding to expansion of 
a nonterminal symbol by a rewriting rule in CFG. 
However, if the tree operation is limited to 
substitution, the resulting grammar, namely 
Lexicalized Tree Substitution Grammar (LTSG), 
cannot even reproduce the trees obtained fi'om 
non-lexicalized context free grammars. This will be 
obvious from the fact that for any LTSG, there is a 
926 
constant such that, in any trees built by the 
grammar, the distance of the root node and the 
nearest lexical item is less than that constant, while 
this property does not always hold for CFG. Tree 
Insertion Grammar (TIG), introduced by Schabes et 
al. (1995), had to be equipped with the insertion 
operation in addition to substitution, so that it can 
be strongly equivalent to an arbitrary CFG. The 
insertion operation is a restricted form of the 
adjoining operation in the Lexicalized Tree 
Adjoining Grammar (LTAG) (Joshi and Schabes, 
1992). 
Thus, a special tree operation other than 
substitution is inevitable to strongly lexicatized 
grammars. It is needed to grow an infinite number 
of trees from a finitely ambiguous set of initial trees 
representing the extended domain of locality 
(EDOL) of the word. 
However, such special tree operation requires a 
specially devised parsing algorithm. In addition, the 
algorithm will be operation-specific and we have to 
devise a new algorithm if we want to add or modify 
the operation at all. Our first motivation was to 
eliminate the need for globally defined special tree 
operations other than substitution whenever 
possible, without losing the existence of EDOL. 
Another point is the fact that lexicalization is 
applied only to trees, not to the tree operations. For 
example, in LTAG, initial tree sets anchored to a 
word is not enough to describe the whole set of 
trees anchored by that word, since initial trees are 
grown by adjunction of auxiliary trees. Since an 
auxiliary tree is in the EDOL of another word, the 
former word has limited direct control over which 
auxiliary tree can be adjoined to certain node. For 
detailed control, the grammar writer has to give 
additional adjoining restrictions to the node, and/or 
detailed attribute-values to the nodes that can 
control adjunction through node operations uch as 
unification. 
In short, we would like to define a lexicalized 
grammar such that 1) tree operation is substitution 
only, 2) it has extended omain of locality, and 3) 
tree operations as well as trees are lexicalized 
whenever possible. In the next section, we propose 
a grammar formalism that has these properties. 
2 Lexicalized Tree Automata-based 
Grammars 
In this section we introduce Lexicalized Tree 
Automata-based Grammar (LTA-based Grammar) 
and present i s parsing algorithm. 
First, we define some basic terminologies. A 
grammar is strongly lexicalized if it consists of 1) a 
finite set of structures each associated with a lexical 
item; each lexical item will be called the anchor of 
the corresponding structure, and 2) an operation or 
operations for composing the structures (Sehabes, 
Abeilld and Joshi, 1988). 
In the following, the word "tree automaton" 
(TA) will be used as a generic term for an 
automaton that accepts trees as input. It can be a 
finite tree automaton, a pushdown tree automaton, 
or any tree-accepting automaton having a state set? 
state transitions, initial and final states, and optional 
memories associated with states. Although our 
argument below does not necessarily require 
understanding of these general TAs, definitions and 
properties of finite and pushdown TAs can be found 
in G6eseg and Steinby (1997) for example~ 
2.1 Definition of LTA-based Grammars 
The basic idea of an LTA-based grammar is to 
associate a tree automaton toeach word that defines 
the set of local trees anchored to the word, instead 
of associating the trees themselves. The lexicalized 
tree automaton (LTA) provides a finite 
representation f a possibly non-finite set of local 
trees. This differs from other lexicalized grammars 
as LTAG, where non-finiteness of local trees is 
introduced through a global tree operation such as 
adjunction of auxiliary trees. 
We define a lexicalized tree automata-based 
grammar as follows. LEt X be a set of terminal 
symbols (words), and NT be the set of nonterminal 
symbols disjoint fi'om 27. Let Tw be a set of trees 
(elementary trees) associated with a word w in 2:.. A 
tree in Tw has nodes either from 27 or from N1, and 
its root )and one of its leaves are marked by a 
distinguished symbol self in NT. Let A,v be the tree 
automaton lcxicalized to the word w, which accepts 
a subset of trees obtained by repeatedly joining two 
trees in Tw at the special nodes labelled selfi one at 
the root of a tree and the other at a foot of another 
tree. From this definition~ A1, can be identified with 
a string automaton; its alphabets are the trees in Tw, 
and a string of the elementary trees are identified 
with the tree obtained by joining the elementary 
trees in a bottom-up manner. Sw is a set of 
nonterminal symbols associated with the word Wo 
They are assigned to the root of a tree when the tree 
is accepted by A,~ 
f For each word w, the set A,, l T,,, A,v, Sw} is the 
set of local trees associated with w. The structure is 
described by Aw and 1'w~ the symbol at the root node 
927 
is fl-om Sw, and se./fin the loot is identified with w. 
We denote the family of Aw as A = {A,,,} for w in Z. 
A lexicalized tree automata-based grammar G is 
defined to be the tree algebra whose trees are the 
set union of Aw for all w in Z', and the basic tree 
operation being the substitution, that is, joining two 
trees at the root node and a foot node when they 
have the same nonterminal in NT other than self. 
2,2 Some Remarks 
1 Strictly speaking, the definition above does 
not satisfy the definition of strongly lexicalized 
grammars that the structures associated to a word 
must form a finite set, since the tree set accepted by 
the automaton may be an infinite set. However, 
since a finite device, namely an automaton, 
describes this possibly infinite set, we will classify 
the proposed formalism as a strongly lexicalized 
grallllTlar. 
2 We defined the lexicalized tree automata 
using string automata where the alphabets are trees. 
The latter is obtained by linearizing the constituent 
trees along the spine of the tree. Because the I/I'A 
can be any tree automaton as long as it accepts all 
and only the (possibly infinite) tree set beaded by a 
word, LTA are essentially tree automata. These 
equivalent wo pictures (the tree automata picture 
of a tree grammar and the string automata picture 
employed in the definition) will be used 
interchangeably in this paper. 
3 The grarnmar G can also be defined by a tree 
automaton T that accepts all and only the trees of 
the grammar as follows: First we regard NT as the 
set of states of T. Its initial states are .Z', and the 
final states are also NT. Sw is regarded as the set of 
final states of A .... The set of initial states ofAw are 
the set of nonterminal symbols that appear in T,,. 
and w. The LTAs are combined into T through the 
common state set NT. The recognition era  tree t 
proceeds in a bottom-up manner, beginning at the 
leaf nodes that are initial states for G and for some 
Aw. When a subtree of T has been recognized by an 
LTA Aw, its root node is in a state s fl'om S,,. I fs  is 
XP 
- / \ Adjunction tO X' can 
Specifier X" / \occur  arbitrary times 
\ X' 
/ ~ adjunct 
X complenletlt 
Figure I. General fOllll o1" X-bar theory 
an initial state of another LTA A,., the recognition 
can proceed. The tree t has been successfully 
recognized if the recognition step arrives at the root 
node. 
2.3 Examples 
Adjunetion in the X-bar Theory 
We demonstrate how the proposed formalism 
handles the simplest case of an infinite set of the 
local trees. The example is repeated adjunction at 
the bar level 1 of the X-bar theory. Figure I shows 
a general scheme of the X-bar theory. X' at the bar 
level 1 can be paired with some adjunct arbitrary 
times betbre it grows to the phrase level, XP. 
Figure 2 shows how this scheme is realized in the 
LTA-based grammar tbrmalism. Figure 2 (a) shows 
the tree set associated with the word. It consists of 
three trees, corresponding to the bar levels. r3 is for 
the complement, "r2 for adjunction, and T3 for the 
specifier. (b) shows the tree automaton associated 
with this word in the (tree-alphabet) string 
automaton representation. It first accepts "I'~, then 
"I'2 arbitrary times, finally T3 to arrive at the final 
state. This sequence is identified with the trees in 
(d), obtained by concatenating "Fi through T3 in a 
bottom-ut) manner. When the ETA arrives at the 
final state, the root node is given a nonternlhml 
symbol lYom the set in (c), which is XP. 
Tree Adjoining Language 
Figure 3 shows a I~I'AG that generates a strictly 
context sensitive language anb"ec'~d n. The unique 
initial tree 7" in (a) is adjoined repeatedly by the 
unique auxiliary tree A in (b) at the root node 
labeled S. The root and foot of A is labeled S, but 
adjunction to them is inhibited by the index NA. (c) 
shows a tree obtained by adjoinhlg A once to T. 
Generally a string a"b"ec"d" is obtained as the yield 
Tz 
sell" 
T i I \  
sell" colnplement 
sell" sell" 
sell" adjunct spccil\]cr self 
sell `=. XP 
/ \  
specifier sell" re/waled 
sell" 
\\ a4iuncI 
self ~ complcn~enl 
(a) Tree set T,,, (d) accepted trees 
(b) -rree {ltitoln\[ll()n a,,, in Jls TI . T.,n . .r3 
tree sequence r presentation 
(c) set of start s) mbol S,,, {Xl': 
Figure 2. I/fA?representation f the tree in Figure 1. 
928 
S S,,A S 'x  
e a S c 
b S,',:\ c 
a) initial tree a 
b) auxil iaD' tree e 
c) "1" adjoined once 
Figure 3: LTAG tbr a"b'~ecIkt '' 
Ca) '.voi'd 
(b) tree set 
sell" 
a sell" d 
F I 
self" / ? \  
h self c 
? I 2 
(C) tree autonlaton(Te).(Ti). 
(d) slari symbols ~,<,j 
se l l -  F, 
a ~ d  
b set f c 
b se l f  c 
I 
sell ":~ e 
(c) trec til l  i! :: 2 
Figure 4: l,TA-based grallllllar lilt a'%"ec"d" 
era tree produced by adjoining :I n-times to T. 
The same language can be expressed by an 
IM'A-based grammar shown in l:igure 4. "lhe word 
is e Ca). The tree set associated \rich e consists of 
two trees TI and 'I', as shown in (b). The local 
automaton is a pushdown automaton that accepts 
tree sequence (Tx)n(Tl)n, and accepted trees are 
given the nonterminal symbol S as in (d). (e) shows 
a Wee with n = 2. From this setting, it is apparent 
that ibis l,l 'A-based grallllnar generates the same 
language as the TAI, in the figure 3. 
By extending this construction, it will be obvious 
that for any I/FAG, all equivalent 171'A-based 
grammar can be constructed within the class of 
pushdown LTA. 
2.,4 Pars ing ,  LTA-based  Gramnlars  
Parsing algorithm lbr the I/l'A-based granlnlar is 
a <;traiglltforward extension of the CFG case. In the 
CFG case, an active edge is represented by a 
rewriting rule with a dot in the right hand side. The 
dot shows that the terminals and ilOll-termillals up 
to that location have been ah'eady t'(')tllld, and the 
rule application becomes a success when the (lot 
reaches the end of the rule. If we regafd  the 
right-haild side of a rule as an automaton accepting 
a sequence of terminals and non-terminals, with the 
clot representing the current state, this picture can 
be easily generalized to the LTA-based grammar 
case .  
Figure 7 shows an example parse for the sentence 
"'He eats dinner". Figure 5 shows the dictionary 
content of the verb "'eats", which is basically the 
same as llgure 2. Figure 6 shows the dictionary of 
"he" and "dinner". We suppose here that these 
words have no associated trees for simplicity. The 
basic strategy is left to right bottom-up chart 
pall s ing .  
First, edges el, e, and e3 are loaded into the chart 
and set to the initial state. They correspond to "'he", 
"'eats" and "'dinner" respectively. The parsing 
proceeds from left to right, and the parser triggers 
the I,TA of el first. Since its only possible 
transition is a null transition, it arrives at the llnal 
state immediately and creates an edge e4 labelled 
,~,'111)/. 
Then the focus moves one step to the right on the 
chart and the I,TA of e, is activated. It tries to find 
Hie tree T,I, and finds that an edge labelled d(;D is 
necessary to its right. Since there is no such edge, 
the I/I'A creates an active edge t with a hole Uoh, as 
in the case of'CFG, and the I/I'A goes into a pause 
waiting tBr the hole to be filled. 
Creation of e5 from e3 is simihu" to the creation of 
% t'rorn el. Then e5 starts the completion step as in 
the CI:(I case. At this step, the active edge created 
above is fouild, and es is found to match the hole. 
Then the I/FA of e, is reactivated, arrives at the 
stale Sl, then creates an edge ca. 
Next the I/I'A of e(, is actiwited. It tries to find 
"t'a, or Ta3 In searching for Ta;, an active edge with 
a hole t)o.vlmcJd is created. While searching for Ta,, 
the I.TA finds that an edge labelled mutT/to the left 
r,, __ i- _ 
(--~df_) ( dob ) 
C~dC> <i, > 
Ta3 ~ "~ 2 
final state : sen le / i ce  
Ca) tree set (b) tree automaton 
Figure 5:1 ,TA of"eats"  
I .,\miv? edges are not shm~n hi the lT~tm: 
929 
final state su\]Tj final state :
s'ubj Idob t prepol!j 
he dinner 
Figure 6: LTAs o f "he"  and "'dirmer'" 
is what is necessary, and finds that e4 satisfies this 
condition. By accepting Ta2, tile LTA creates the 
edge ev, label it as senlence and advances to tile 
final state. There is no more possible action on the 
Chart, and the parsing is completed successlhlly. 
Please note that the algorithm exemplified above 
does not depend on the concrete form of LTA. The 
satne algorithm can be applied to pushdown 
atttomata and other class of automata having 
internal memories. 
3 Translation Module 
We buih a bi-directional translation system between 
the ,lapanese and English languages usitlg the 
proposed method. It translates conversational texts 
as will appear in a dialogue between two people, to 
help them communicate in a foreign travel situation. 
Figttre 8 shows an overview of the system. 
3.1 Translation Engine 
Since each word in tile dictionary has its own tree 
set and tree automaton, a simple implementation 
will lead to inefficiency. To cope with this problem, 
we provided two mechanisms to share tile UI'A. A 
"rule template" mechanism is provided to share the 
triplet, tmrnely Aw it1 tile definition of I+TA, while a 
"'shared tree" mechanism is provided to sllare the 
elementary trees among different A+. 
The rule template is applied just after dictionary 
loading, and assigns an LTA to a word that matches 
the condition in tile template. It is mainly used for 
words such as cotnmon nouns. A shared tree is 
represented by a pointer to an elementary tree in the 
pool, and is loaded into the systetn when it is tised 
lbr tile first time. 
The language conversion method is based on 
synchronous deriwttion of analysis and generation 
trees, basically the same as the syntax directed 
translation by Aho and Ulhnan (1969) and the 
synchronous LTAG by Shieber and Schabes (1990). 
In this method, elementary analysis tree of each 
word is paired with another tree (elementary 
generation tree). Starting from the root, at each 
(?- 
A ~4 
AL?I 
".. C-c,,-s~b 
I I +3 / '~_  
_ I +, 
r~777- -~ suh l  - I I ~- 85 ,)1% "+ 
T . e: ! I ,  e.; * . .  
he i - ' eats dinner i 
Figure 7: ExamlJle Parse 
node of the analysis tree+ the direct descendant 
nodes are reordered in the generation tree, 
according to tile correspondence of elementary 
analysis and generation trees. Tiffs translation 
mechanisna is basically independent of how the 
analysis tree is constructed, hence the grammar 
l'ornmlistri. In our implerrientation, the gerleration 
tree is a call graph of target language generating 
ftirmtioils, which enables detailed procedural 
control over the syntactic generation process. 
3.2 Grammars and Dictionaries for 
English to Japanese Transh l t ion  
The English to Japanese translation grammar and 
dictionary has been developed. In order to achieve 
wide coverage for general input and high quality 
for tile target dolnain, we developed general 
gramrrlar l't.iles and donlain-specific rules 
sinltlltaneot, isly. (\]eneral rules are based on a 
standard X-bar theory. Nodes of a tree are 
associated with attribute-value structure in a 
standaM way. As nonterminals, we employed a 
grammatical function-centered approach as lank 
Grammar (Sleator and Temperley, 1991). A phrase 
Input 
i,,+ ++ 
I__ I /~c  Tcn'i +>tatcsj 
~ Grammar R,tos ~ i,al A~na++ ~ ~  _ _  
t ,Z,L,,<,,,Cy x,<,,,,,,<,,<,<+_,, 
<<+ 
i _  ~Jt. d ...... 
\[ ()12,/C,'\[}t ll.ll\]\] 
1 J} 
Output t % 
K( I I '~2-~( I  }' I '+~}'okl - l l>O I\[I\])UI'-H ,~J<J " m 
/h'-~ub\] l/llillt'l'-d++ti C+H 
Figut'e 8: Trai~slatior~ Modttle 
930 
level node is assigned attribute-values that express 
their syntactic ftlnction Stlch as subject, direct 
object, etc, instead of a single part-of-speech 
symbol such as NP. This approach is suitable to 
capture idiosyncratic behaviour of words. 
Domain-specific rules are mostly pattern-like 
rules with special attention to aspects that are 
important for carrying conversations, such as 
modality and the degree of politeness. The English 
to Japanese translation dictionary contains about 
seventy thousand words. The number of words that 
required individual I,TA was a few thousand at tile 
time of this report. 
3?3 Current Status of Implementation 
The system has been iml~lemented using C++, 
and runs on Windows 98 and NT. The requirelnent 
is Pentium I\] 400MItz or above for tile CPU~ about 
61) MB of memory, and 200 MB of  disk space. 
Most of the disk space is used for statistical data for 
disambiguation. 
We performed a preliminary evaluation of the 
translation quality of l';nglish to Japanese 
translation. A widely used COlnmercial systeln was 
chosen as a reference system, of which the 
dictionaries were expanded for the target domain, 
t:ive hundred sentellces were randomly chosen from 
a large (about 40K) pool of conversatiolml texts of 
the target domain. '\['hen the output of our system 
and the reference system were mixed, and then 
presented to a single evahmtor at a random order. 
The evaluator classified them into (Bur levels 
(natural, good, understandable and bad). The result 
showed that tile number of sentences classified to 
"'natural" increased about 45% compared to that of 
tlle reference system, i.e. tile ratio of the ntlmber of 
sentences was arotllld 1.45. The ntllllber o|" 
sentences classified as "bad" decreased about 40% 
in the same measure. 
We applied this module to an experimental 
speech translation system (Watanabe t al., 2000). 
4 l)iscussions 
The proposed granllnar fornlalism is a kind of 
lexicalized granll'nar fcnTnalisnl and shares its 
advantages. The largest difference frolll other 
strongly lexicalized granunar tbrnlalisms is that it 
employs lexicalized tree automata (I,TA) to 
describe the tree set associated with a word, which 
allows a finite description of a non-finite set of 
local trees. These automata's role is equivalent o 
additional tree operations in other formalisms. In 
addition, an LTA provide an extended domain of 
locality (EDOL) of the word. 
I f  all the LTAs are finite automata in the string 
automaton representation, then the tree language 
recognized by this grammar is regular and its yield 
is a context-free language. The grammar can accept 
general Tree Adjoining Language (TAL) if" the 
LTAs belong to the class of pushdown atttomata in 
the string autonlaton representation. This is a 
reflection of tile thct that pushdown tree automata 
can accept the indexed languages (Gdcseg and 
Steinby, 1997), of which the TAL is a subclass. 
As shown in the section 2.4, the control strategy 
of bottom-up chart parsing does not rely ell the 
concrete content of the I,TA, which is an adwmtage 
of the proposed formalism. This implies that we can 
alter even tile grammar class without affecting the 
parsing. Suppose the current L'I'As are finite 
automata, hence the yield language is context-free. 
If we want to introduce a word e that induces a 
non-context-fi'eeness, such as e in a"b"ec"d", then 
what we have to do is to write a pushdown 
automaton in tile figure 4 li)r the word e. We 
change neither tile grammar formalism nor the 
parsing algorithm, and the change is localized to the 
LTA of e. 
Writing automata by hand may seem much more 
complex than writing trees, but our experience 
shows that it is not nlucll different fronl 
convelltional granHllar development. As long as 
appropriate notations are used, writing automata for 
a word anlounts to detornlining possible t'olnl of 
trees headed by that word, a task ahvays required in 
gramil-iar development. In fact, thei'e is tess alllOtllli 
of work since tile gralllnlar writer does not need to 
pay attention to assigning proper nontcrminals 
and/or proper attributes to internal nodes of trees in 
order to control their growth. 
It is another advantage of the proposed 
formalisnl that it can utilize various autorriata 
operations, such as conlposition and intersection. 
For exanlple, a word can append an atltOlllatoll to 
thai of the headword when it becomes a child, 
which enables to specify a constraint fi'onl a 
h)wer-positioned word to a higherq)ositioned v~oi'd 
in tile tree. Another example is cootdination. Two 
edges are conjoined when tile unapplied parts of 
I,TAs have nonempty intersection as automata, and 
tile conjoined edge is given with this intersection as 
the lTfA. Verb phrase conjunction such as ",lohn 
eats cookies and drinks beer" is handled in this 
manner, by conjoining "'eats cookies" and "'drinks 
beer. The intersected automaton will accept the 
subject ree and other sentence-level trees. 
931 
In the proposed method, elementary trees are 
always anchored by the syntactic headword. For 
example, a verb iit a relative clause is in the EDOL 
of the antecedent. Then, if the embedded verb puts 
a constraint on the antecedent, hat constraint is not 
expressed in a straightforward manner, which may 
seem a weakness of the method. We just poiltt out 
that this type of problem occurs when the syntactic 
head and the semantic head are different, and is 
common to lexicalized grammars as long as a tree 
is anchored to one word, because constraints are 
often reciprocal. In our current implementation, the 
constraint written in the verb's dictionary is found 
and checked by the relative-clause-tree accepting 
automaton of the antecedent noun. 
There have been many work on syntactic analysis 
based on automata ttached to the headword. Evans 
and Weir (1998) used finite state automata as 
representation of  trees that can be merged and 
minimized to improve parsing efficiency, lit their 
method, the granlnlar is fixed to be I,TAG or seine 
lexicalized grammar and the automata re obtained 
by automatic conversion from the trees. Our 
nlethod differs frol11 theirs ilt the poiltt that ours 
employs trees as the basic object of automata, 
which enables to handle general recursive 
adjunction in LTAG,  whi le  their automata work Oll 
tile nonter i l l inal  and ternl inal synlbols, lit the center 
O\[" Ot.lr method is the notion of" the local orallllllal of 
a word. "\['he whole grammar is divided into the 
global part and the set of h)cal gralltntars specific to 
the words, which is represented by tile LTAs. 
Alshawi (1996) introduced ttead Atitornata, a 
weighted finite machine that accepts a pair o\[" 
sequences of relation symbols. The difference is 
similar as above. Since the tree automata in our 
method are used to define the set of the local trees, 
their role will be equivalent o building the head 
automata themselves, but not to combining the trees 
that are already built, like the I lead Automata. 
5 Conchlsion 
We proposed a new lexicalized grammar formalism, 
called Lexicalized Tree Automata-based Grammar. 
In this formalism, the trees anchored to a word are 
described by a tree automaton associated with it. 
We showed a chart parsing algo,ithm that does not 
depend on the concrete content of the automata. We 
have imt)lemented a bi-directional translation 
module between Japanese and English liar 
conversational texts using this formalism. A 
preliminary evaluation of English to Japanese 
translation quality revealed a promising result. 
Acknowledgement 
We would like to thank Shinichiro Kamei tia" useful 
discussions and Yoshinori Ishihara for his help in 
the implelnentation work. 
References 
Abeilld, A., Schabes, Y. and .loshi, A.K. (1990). t.'si,z<.,, 
l.exicalized 771(;s fin" Machine 77"an.dalion. tn 
f~roceedin<<.,,s oi ( 'OI, LVG- 90. p p. 1-6. 
Aho. A.V.. and Ulhn:.ul..I.1). (1969). I'roFe#'lie.v qf,Slvntax 
Directed 7)'anslations..Iotlrllal of C(Hllrltlicr {tlld g}stelll 
Sciences. vol.3, pp.319-334. 
AIshawi. II. (19961. Ilead ..haomam and Bilini,,ual Tilin<<,c 
7)'aHs/alioll with Minima/ Rel)re.ventalion.v. In 
Proceedin.Ts of 34 If' .4#lnlla\[ .lleetlll?, (g {'onl/)lttattolla/ 
Linguistics, pp. 167-176. 
P, rown. P,.D. (1996). ICvamlJle-Based ,l/achine 7)'all.v/all'oil 
ill the Pan gloss ,71'.s'lenl. hi Proceedinw of ('Ol.l,VG-96. 
pp. 169-174. 
\]'vans, R. and Weir, I).,I. (1998). ,4 .S'tructure-,S'harink, 
Parser jo t  Lexicalized (;rantmars. In tb'oc'eedi, g.s" of  
COLING-,.ICL "98. pp.372-378. 
Furuse, O. and lida. It. (1994). ('onstituenl Boundary 
Parsing .for 1Crample-Ba,sed .Wachine 77"culs/ation. In 
l'roceedin?,s o/( 'Ol ,  lNG-94, pp. 105- I I I. 
Gdcsc,, F. and Stcinby, M. (1997). Tree lA.ulguagcs. In 
t/andbook of Formal l.anguages. G. P, osenberg and it. 
Salomaa. trillers. Springer Vcrlag. Vol.3. pp. 1-68. 
Joshi. A.K. and Schabcs. Y. (1992). Tree-..tcOoinin?4 
(Trammars and l, exicali_-ed Grammars. II1 "\['I'CC i\tltOlllala 
and lxmguages. M. NiXal and A. l>odelski, cd,, Elsevier 
Science l~ublishcrs B.V., pp.409-43 I. 
ltuland. T., ltupp. C_I., Spilkcr. J.. \Vcbcr, It. itlld \VorilL K. 
(1998). Jlakin<t~ The Most qf :WulttTUiciO'.- t Multi-I'ar.~er 
.llu/ti-.S'lrategy .-Irc/H'tecture for Hie l?olm.vt /~r,'.>c'e,v.vin~ of 
.q'poken l.ang ta?,e In IJroceedin,v.v oJ I('.S'/,/~ '98. 
pp. 1163-. I 166. 
Schabes, Y.. Abcill6. A. and Joshi. A. (1988). /~ar.viu?, 
,~'t#'ategiex with "l, exicali=ed' (h'ammars. In />roceedin?,.s" 
o/(  OI, I.\G 8<S. pp.>78-_ 8.~. 
Schabcs. Y. and \Vatcrs. R.C. (1995). Tree ht.~'ertion 
(;#'CIIIIIII\[ll': .l ('u/Uc-JTme. Par.valUe /.'ormali.vm l/lat 
Lexicah-e.~" ('onte:~t-I;)'ee Oralllnlglr without ('han,,,,in<,.,, the 
Trees Prod\teed. Computational ,inguisiics. Vol. 21, 
pp.479-513. 
Shicbcr. S.N,1. and Schabcs, Y. (1990)..S'vnchronou.s Tree 
..le(ioinin?, Grammars. In Prlweedinr~4s ?)/" (.'()I.I.V(;'90. 
pp.253-258. 
Slcaim. I).I).K. and Tempcrley. \[). (199t). Par\in,, IGz,c, li.dl 
Wl'lJt el l.l'tgk (;#'anlnlar. CM\[J lechnical P, eport 
('N'llJ-C'.q-91- 196. 
Takcda. K. (19961. I~altermBa.seU .~lachine 77"an.v/alien. In 
l'roceedmgs qICOI.IN(; '96. pp. I 155- I 158. 
\Valai~abe. T.. ()kunltlra, A...'qakai. S.. Yail/abal'la. K. alld 
l)oi..'4. (2000)..IIIlOIIIHIIL' \]IIlL'ITJI'L'ILIII'OII. "\['O apl:,ear in 
NI!(_' Technical Jourrial. Vol.53. No.6. (in .lapancseL 
932 
 	
 ffProceedings of the ACL 2007 Demo and Poster Sessions, pages 9?12,
Prague, June 2007. c?2007 Association for Computational Linguistics
Multimedia Blog Creation System using Dialogue  
with Intelligent Robot 
Akitoshi Okumura, Takahiro Ikeda, Toshihiro Nishizawa, Shin-ichi Ando, 
and Fumihiro Adachi 
Common Platform Software Research Laboratries,  
NEC Corporation 
1753 Shimonumabe Nakahara-ku, Kawasaki-city, Kanagawa 211-8666 JAPAN 
{a-okumura@bx,nishizawa@bk,s-ando@cw,f-adachi@aj}.jp.nec.com 
 
Abstract 
A multimedia blog creation system is de-
scribed that uses Japanese dialogue with an 
intelligent robot. Although multimedia 
blogs are increasing in popularity, creating 
blogs is not easy for users who lack high-
level information literacy skills. Even 
skilled users have to waste time creating 
and assigning text descriptions to their 
blogs and searching related multimedia 
such as images, music, and illustrations. To 
enable effortless and enjoyable creation of 
multimedia blogs, we developed the system 
on a prototype robot called PaPeRo. Video 
messages are recorded and converted into 
text descriptions by PaPeRo using continu-
ous speech recognition. PaPeRo then 
searches for suitable multimedia contents 
on the internet and databases, and then, 
based on the search results, chooses appro-
priate sympathetic comments by using 
natural language text retrieval. The re-
trieved contents, PaPeRo's comments, and 
the video recording on the user's blog is 
automatically uploaded and edited. The 
system was evaluated by 10 users for creat-
ing travel blogs and proved to be helpful 
for both inexperienced and experienced us-
ers. The system enabled easy multimedia-
rich blog creation and even provided users 
the pleasure of chatting with PaPeRo. 
1 Introduction 
Blogs have become popular and are used in a vari-
ety of settings not only for personal use, but are 
also used in the internal communications of or-
ganizations. A multimedia blog, which contains 
videos, music, and illustrations, is increasing in 
popularity because it enables users to express their 
thoughts creatively. However, users are unsatisfied 
with the current multimedia blog creation methods. 
Users have three requirements. First, they need 
easier methods to create blogs. Most multimedia 
blogs are created in one of two ways: 1) A user 
creates audio-visual contents by cameras and or 
some other recording devices, and then assigns a 
text description to the contents as indexes. 2) A 
user creates a text blog, and then searches for mul-
timedia contents on the internet and databases to 
attach them to his blog. Both methods require 
high-level information literacy skills. Second, they 
would like to reduce their blog-creation time. Even 
skilled users have to waste time assigning text de-
scription and searching related multimedia con-
tents. Third, they like to be encouraged by other 
peoples? comments on their blogs. Although some 
users utilize pet-type agents making automatic 
comments to their blogs, the agents do not always 
satisfy them because the comments do not consider 
users' moods. To meet the three requirements, we 
developed a multimedia blog creation system using 
Japanese dialogue with an intelligent robot. The 
system was developed on a prototype robot called 
PaPeRo (Fujita, 2002), which has the same CPU 
and memory as a mobile PC. In this paper, we de-
scribe the multimedia blog creation method and 
the evaluation results in a practical setting. 
2 Multimedia Blog Creation 
2.1 Outline of system processes 
The system has four sequential processes: video 
message recording, continuous speech recognition, 
natural language text retrieval, and blog coordina-
9
tion. The first process is activated when a user be-
gins a conversation with PaPeRo. The process 
stores a video message recorded on PaPeRo's mi-
crophones and CCD cameras, and the second 
process converts the speech contents of the video 
message into a text description to extract important 
keywords. Then, the third process searches for 
suitable multimedia contents on pre-specified web 
sites and databases based on the text description. 
The first three processes can simplify multimedia 
blog creation and reduce creation costs. The last 
process detects a user?s mood, such as delight, an-
ger, sorrow, and pleasure, by extracting typical 
expressions from the text description, and then 
chooses appropriate sympathetic comments to en-
courage the user. Finally, the last process coordi-
nates uploading the recorded video message, the 
text description, the extracted keywords, the 
searched contents, and the sympathetic comments 
on the user's blog. 
2.2 Continuous Speech Recognition 
The system converts the speech content of the 
video message into text descriptions and extracts 
important keywords based on their lexical infor-
mation. The system should, therefore, be equipped 
with a large-vocabulary continuous speech recog-
nition engine capable of dealing with spontaneous 
speech. This is because blog messages usually con-
tain various kinds of words and expressions. As 
this kind of engine needs a large amount of mem-
ory and computational resources, it is generally 
difficult to install the engine on small intelligent 
robots because the robot requires its own computa-
tional resources for their own intelligent operations, 
such as image recognition and movement control. 
To solve this problem, we used a compact and 
scalable large-vocabulary continuous speech rec-
ognition framework, which has been shown to 
work on low-power devices, such as PDAs (Isotani 
et al,2005). The framework achieves compact and 
high-speed processing by the following techniques: 
 - Efficient reduction of Gaussian components us-
ing MDL criterion (Shinoda, et al, 2002) 
- High-speed likelihood calculation using tree-
structured probability density functions (Wata-
nabe, et al, 1995) 
- Compaction of search algorithm using lexical 
prefix tree and shared usage of calculated lan-
guage model scores (Isotani et al, 2005) 
The framework we developed contained a Japanese 
lexicon of 50,000 words typically used in travel 
conversations based on a speech translation system 
(Isotani, et al, 2002). We were able to evaluate the 
developed system by making a travel blog using 
Japanese dialogue with PaPeRo.  
2.3 Natural Language Text Retrieval 
The system generates a query sentence from a 
text description converted using the above-
mentioned framework. As few multimedia contents 
contain retrieval keywords, the system matches the 
query to text in web pages and documents contain-
ing multimedia contents. The system then chooses 
multimedia contents located adjacent to the highly-
matched text as retrieval results. To achieve high 
precision for avoiding user interaction with the 
retrieved results, the system is enhanced using the 
Okapi BM25 model (Robertson, et al, 1995) by 
the following techniques (Ikeda, et al, 2005): 
(1) Utilization of syntactic relationships 
The system needs to distinguish illustrations 
based on the context. For example, an illustration 
of fish to be eaten in a restaurant should be differ-
ent from that of fish to be seen in an aquarium. To 
achieve this, the system utilizes the syntactic rela-
tionships between a pair of words. The system 
produces a higher score for text containing the 
same syntactic relationship as that of a pair of 
words in a query sentence when calculating the 
matching score.  
(2) Distinction of negation and affirmation 
The system needs to distinguish negative and af-
firmative expressions because their meanings are 
clearly opposite. To achieve this, the system 
checks adjuncts attached to the expressions when 
matching a query sentence and text. 
(3) Identification of synonyms  
As different expressions have the same meaning, 
the system normalizes expressions by using a 
synonym dictionary containing 500 words before 
matching a query sentence and text. 
2.4 Blog Coordination 
The system detects users? mood to choose en-
couraging comments. Users? moods are sometimes 
detected by the expressions used and the manner in 
which the utterances are spoken. Although speak-
ing manner can clearly detect emotions, such as 
laughing or crying, some emotions are not always 
indicated. Expressions that clearly identify a per-
10
son?s mood can be indicated (Nakamura, 1993). 
By studying moods that are easily detectable from 
expressions, including modality, we developed a 
database of 10 moods (delight, anger, sorrow, 
pleasure, desire, fear, shame, relief, surprise, and 
normal) individually linked with 100 kinds of spe-
cific expressions. The database is searched based 
on the above-mentioned natural language text re-
trieval, which considers syntactic relationships, 
negative and affirmative responses, and synonyms. 
The database is also linked to PaPeRo?s response 
to convey the most appropriate sympathy for each 
mood. The response includes verbal comments, 
such as ?I'm happy for you? and ?It's really too 
bad?, and gestures, such as dancing and crying de-
picted using GIF animation files. Responses are 
chosen based on the mood detected. Finally, the 
system coordinates uploading a recorded video 
message, the text description, the extracted impor-
tant keywords, the searched multimedia contents, 
and PaPeRo?s responses on the user's blog. 
3 Example Use in Practical Setting 
We developed a prototype system for creating a 
travel blog on PaPeRo, which can retrieve 2000 
web pages containing 1500 illustrations and 550 
songs. PaPeRo is activated by hearing the phrase, 
?can you help me make my blog please??, as listed 
in Table. 1, and creates a blog, as shown in Figure 
1. Figure 1 shows a screen shot of a video message 
attached to the blog, a text description converted 
by the speech recognition and a button for playing 
the video message (A). Keywords, in this case Yo-
semite, Las Vegas, and Roulette, extracted from 
the text description are displayed (B). Three illus-
trations searched based on a query using the text 
description are displayed (C). A button for playing 
a searched song is available (D). PaPeRo?s com-
ments, such as ?I hope that happens?, are displayed 
(E). The user?s mood is detected as desire from her 
saying ?I would like to go there again.? The com-
ment is displayed together with the appropriate 
PaPeRo?s response.  
Table 1. Dialogue example (Excerpt) 
A user  : Can you help me make my blog please? 
PaPeRo: Yes, please push the button on my head. 
A user  : I went to Yosemite for my winter vacation. 
 I played the roulette for the first time in Las 
Vegas. I would like to go there again. 
PaPeRo: Ok, now your blog is ready for viewing. 
B
C
E
A
D
?????
????
 
Figure 1. Example of Created Blog  
4 Evaluation and Discussion 
4.1  Evaluation 
The system needs to be evaluated from two per-
spectives. The first is to individually evaluate the 
performance of each process mentioned in section 
2. The second is to evaluate total performance, in-
cluding the users? subjective opinions. As per-
formance has been evaluated using different appli-
cation systems, such as an automatic speech trans-
lation system (Isotani, et al, 2002) and a speech-
activated text retrieval system (Ikeda, et al, 2005), 
we concentrated on evaluating the total perform-
ance based on surveying users? opinions about the 
blogs they created using the developed system. The 
survey results were analyzed in terms of speech 
recognition accuracy and users? blog making ex-
perience to improve the system.  
4.2 Results and Discussion 
The system was evaluated by 10 users. Half had 
blog making experiences, and the other half had 
no experience at all. All users input 20 sentences, 
and half of the sentences input were on travel is-
sues, but the other half were unrelated because we 
needed opinions based on the results from low 
speech recognition accuracy. Users were inter-
viewed on their automatically created blogs. 
Their opinions are listed in Table 2. The first row 
contains opinions about blogs created based on 
speech recognition results that had high word ac-
curacy (85-95%). The second row contains opin-
ions that had low accuracy (50-84%). The third 
row shows opinions regardless of the accuracy. 
11
The left column contains opinions of users with 
blog-making experience. The middle column con-
tains opinions of inexperienced users. The right 
column shows opinions regardless of the experi-
ence. The table leads to the following discussion: 
(1) Expectations for multimedia blog creation 
Users were satisfied with the system when high 
speech recognition accuracy was used regardless 
of their blog-making experience. Some users ex-
pected that the system could promote spread of 
multimedia contents with index keywords, even 
though few multimedia contents currently have 
indexes for retrieval. 
(2) Robustness and tolerability for low accuracy 
Users understood the results when low speech 
recognition accuracy was used because the mul-
timedia content search is still fairly successful 
when keywords are accurately recognized, even 
though the total accuracy is not high. Users can 
appreciate the funny side of speech recognition 
errors and unexpected multimedia contents from 
PaPeRo?s mistakes. However, as the errors do not 
always lead to amusing results, an edit interface 
should be equipped to improve keywords, illus-
trations and the total blog page layout. 
(3) More expectations of dialogue with PaPeRo 
Users would like to more enjoy themselves with 
PaPeRo, regardless of the speech recognition ac-
curacy. They expect PaPeRo to give them more 
information, such as track-back and comments, 
based on dialogue history. As PaPeRo stores all 
the messages in himself, he has the ability to gen-
erate more sophisticated comments and track-
back messages with users. Also, when the dia-
logue scenario is improved, he can ask the users 
some encouraging questions to make their blog 
more interesting and attractive while recording 
their video messages. 
5 Conclusion  
We developed a multimedia blog creation system 
using Japanese dialogue with an intelligent robot. 
The system was developed on PaPeRo for creating 
travel blogs and was evaluated by 10 users. Results 
showed that the system was effective for inexperi-
enced and experienced users. The system enabled 
easy and simple creation of multimedia-rich blogs, 
while enabling users the pleasure of chatting with 
PaPeRo. We plan to improve the system by sup-
porting the edit interface and enhancing the dia-
logue scenario so that users can enjoy themselves 
with more sophisticated and complex interaction 
with PaPeRo.  
Table 2. Survey of Users? Opinions 
References 
Yoshihiro Fujita. 2002. Personal Robot PaPeRo. Jour-
nal of Robotics and Mechatronics, 14(1): 60?63. 
Takahiro Ikeda, at al. 2005. Speech-Activated Text Re-
trieval System for Cellular Phones with Web Brows-
ing Capability. In Proceedings of PACLIC19, 265?
272. 
Ryosuke Isotani, et al 2002. An Automatic Speech 
Translation System on PDAs for Travel Conversation. 
In Proceedings of ICMI2002, 211?216. 
Ryosuke Isotani, et al 2005. Basic Technologies for 
Spontaneous Speech Recognition and Its Applica-
tions. In IPSJ-SIGNL, 2005-NL-169, 209?116 (in 
Japanese). 
Akira Nakamura (ed.). 1993. Kanjo hyogen jiten (Emo-
tional Expressions Dictionary). Tokyodo Shuppan, 
Tokyo (in Japanese). 
Stephen E. Robertson, et al 1995. Okapi at TREC-3. In 
Proceedings of TREC-3, 109?126. 
Koichi Shinoda and et al 2002. Efficient Reduction of 
Gaussian Components Using MDL Criterion for 
HMM-based Speech Recognition, In Proceedings of 
ICASSP-2002, 869?872. 
Takao Watanabe, et al 1995. High Speed Speech Rec-
ognition Using Tree-Structured Probability Density 
Function. In Proceedings of ICASSP-1995, 556?559. 
Blog-making experience  
Experienced Inexperienced Either 
Hi
gh
 
-This system 
makes multi-
media con-
tents more 
searchable on 
the internet. 
-I would like to 
create blogs with 
PaPeRo. 
-Easy to create 
blog only by 
chatting. 
-PaPeRo?s 
comments are 
nice. 
Lo
w 
-Keywords, 
searched con-
tents, and the 
total lay-out of 
blogs should 
be edited. 
-Searched con-
tents are good. 
-Even unexpect-
edly searched 
contents because 
of recognition 
errors are funny. 
-PaPeRo could 
be allowed for 
his mistake. 
- Unexpected 
texts tempt users 
to play the 
video.  
Sp
ee
ch
 re
co
gn
itio
n a
cc
ura
cy
 
Ei
the
r 
-PaPeRo?s 
track-back is 
wanted as well 
as more dia-
logue varia-
tion. 
-PaPeRo should 
talk on reasons 
of his choosing a 
song. 
-PaPeRo should 
consider a his-
tory of recorded 
messages and his 
comments. 
12
 Topic Detection Based on Dialogue History 
 
Takayuki NAKATA, Takahiro IKEDA, Shinichi ANDO, Akitoshi OKUMURA 
Multimedia Research Laboratories, NEC Corporation 
4-1-1, Miyazaki, Miyamae-ku, Kawasaki, KANAGAWA, 216-8555, JAPAN 
t-nakata@bk.jp.nec.com, t-ikeda@di.jp.nec.co.jp, s-ando@cw.jp.nec.com, a-okumura@bx.jp.nec.com
 
 
 
Abstract 
In this paper, we propose a topic detection 
method using a dialogue history for 
selecting a scene in the automatic 
interpretation system (Ikeda et al, 2002).  
The method uses a k-nearest neighbor 
method for the algorithm, automatically 
clusters target topics into smaller topics 
grouped by similarity, and incorporates 
dialogue history weighted in terms of time 
to detect and track topics on spoken 
phrases.  From the evaluation of 
detection performance using test corpus 
comprised of realistic spoken dialogue, 
the method has shown to perform better 
with clustering incorporated, and 
combined with time-weighted dialogue 
history of three sentences, gives detection 
accuracy of 77.0%. 
1 Introduction 
In recent years, speech-to-speech translation 
systems have been developed that integrate three 
components: speech recognition, machine 
translation, and speech synthesis (Watanabe et 
al., 2000).  However, these systems cannot 
guarantee accurate translation because the 
individual components do not always provide 
correct results.  To overcome this restriction, 
we proposed a method to use parallel text based 
translation for supporting free-style sentence 
translation.  In addition, we built a prototype 
automatic interpretation system for Japanese 
overseas travelers (Ikeda et al, 2002).  With 
this system, the user searches for an appropriate 
sentence in source language from the registered 
parallel text by using the criteria of an utterance, 
a scene, and a situation, and then uses the target 
language sentence for a translation. 
Although parallel text based translation 
provides guaranteed translation results, it has 
two problems as the user searches for the 
sentence.  One is difficulty in searching an 
appropriate sentence from user?s short utterance, 
which is often heard in travel conversation.  
Short phrases provide only a few keywords and 
make the search result too broad.  Specifying 
the exact scene and action helps narrow down 
the result, but the task may cause user frustration 
in having to select the right option from the vast 
categories of scenes and actions. 
The other problem is existence of nonadaptive 
sentences that may be inappropriate in some of 
the scenes.  Users usually select sentences 
according to the scenes so they can exclude 
those inapplicable sentences, but some new 
users may accidentally select those nonadaptive 
sentences by failing to specify a scene. 
 Here, we propose a method to detect a topic 
for each utterance.  We define a topic as 
corresponding to a scene that is a place or a 
situation in which the user converses.  The 
proposed method is based on the k-nearest 
neighbor method, which is improved for 
dialogue utterances by clustering training data 
and using dialogue history.  We use the 
detected topic for specifying a scene condition in 
parallel text based translation, and thereby solve 
the two problems described above. 
Detecting topics also helps improve accuracy 
of the automatic interpretation system by 
disambiguating polysemy.  Some words should 
be translated into different words according to 
the scene and context selection.  Topic 
detection can enhance speech recognition 
accuracy by selecting the correct word 
                                            Association for Computational Linguistics.
                            Algorithms and Systems, Philadelphia, July 2002, pp. 9-14.
                          Proceedings of the Workshop on Speech-to-Speech Translation:
 dictionary and resources, which are organized 
according to the topic. 
The remainder of this paper is organized as 
follows.  Section 2 describes the constraints in 
detecting a topic from dialogue utterances.  
Section 3 describes our topic detection algorithm 
to overcome these constraints.  Section 4 
explains the evaluation of our method by using a 
travel conversation corpus and Section 5 
presents the evaluation result.  Section 6 
discusses the effect of our method from a 
comparison of the results on typical dialogue 
data and on real situation dialogue data.  We 
conclude in Section 7 with some final remarks 
and mention of future work. 
2 Topic detection 
Among conventional topic detection methods, 
one uses compound words that features certain 
topic as trigger information for detecting a topic 
(Hatori et al, 2000), and another uses 
domain-dependant dictionaries and thesauruses 
to construct knowledge applicable to a certain 
topic (Tsunoda et al, 1996).  In the former 
method, a scene-dependant dictionary provides 
the knowledge relevant to the scene and 
compound words in the dictionary are used for 
detecting a topic.  In the latter method, words 
appearing in a scene are defined as the 
knowledge relevant to the scene and 
superordinate/subordinate relation and 
synonyms provided by thesauruses are used to 
enhance the robustness. 
These conventional methods are suitable for 
written texts but not for dialogue utterances in a 
speech translation system.  The following two 
major constraints make the topic detection for 
dialogue utterances more difficult. 
 
(1) Constraint due to single sentence process 
- Sentences in a dialogue are usually 
short with few keywords. 
- In a dialogue, the frequency values of 
the word in a sentence are mostly one, 
making it difficult to apply a statistical 
method. 
 
(2) Constraint due to the nature of spoken 
dialogue 
- In a dialogue, one topic is sometimes 
expressed with two or more sentences. 
- The words appearing in a sentence are 
sometimes replaced by anaphora or 
omitted by ellipsis in the next sentence. 
- Topics frequently change in a dialogue. 
 
On the other hand, a speech translation system 
requires the following: 
- Topic detection for each utterance in a 
dialogue; 
- Prompt topic detection in real time 
processing; 
- Dynamic tracking of topic transition. 
 
To make topic detection adaptive to the 
speech translation system, we propose a method 
applicable to one utterance in a dialogue as an 
input, which can be used for tracking the topic 
transitions dynamically and outputting most 
appropriate topic for the latest utterance.  The 
k-nearest neighbor method (Yang, 1994) is used 
with the clustering method linked with the 
dialogue history as a topic detection algorithm 
for dialogue utterance.  The k-nearest neighbor 
method is known to have high precision 
performance with less restriction in the field of 
document categorization.  This method is 
frequently used as a baseline in the field and also 
applied to topic detection for story but not for a 
single sentence (Yang et al, 1999).  This paper 
incorporates two new methods to the k-nearest 
neighbor method to overcome two constraints 
mentioned above. 
To overcome the first constraint, we cluster a 
set of sentences in training data into subsets 
(called subtopics) based on similarity between 
the sentences.  A topic is detected by 
calculating the relevance between the input 
sentence and these subtopics.  Clustering 
sentences on the same subtopic increases 
number of characteristic words to be compared 
with input sentence in calculation. 
To overcome the second constraint, we group 
an input sentence with other sentences in the 
dialogue history.  A topic is detected by 
calculating the relevance between this group and 
each possible topic.  Grouping the input 
sentence with the preceding sentences increases 
number of characteristic words to be compared 
with topics in calculation.  We consider the 
 order of the sentences in the dialogue in 
calculating the relevance to avoid the influence 
of topic change in the dialogue. 
3 Topic detection algorithm 
This section explains three methods used in 
the proposed topic detection algorithm: 1) 
k-nearest neighbor method, 2) the clustering 
method using TF-IDF, and 3) the application of 
the dialogue history. 
3.1 k-nearest neighbor method 
We denote the character vector for a given 
sentence in the training data as Dj, and that for a 
given input sentence as X.  Each vector has a 
TF-IDF value of the word in the sentence as its 
element value (Salton 1989). 
The similarity between the input sentence X 
and the training data Dj is calculated by taking 
the inner product of the character vectors. 
 
 
 
The conditional probability of topic Cl being 
related to the training data Dj is calculated as: 
 
?
?
j
l
jl D
C
DCPr
  the torelated being 
  topicsofnumber  The
1)|( =  
 
The relevance score between the input sentence 
X and each topic Cl is calculated as the sum of 
similarity for k sentences taken from the training 
data in descending order of similarity. 
 
?
?
?=
}sentence  ranking  k  top{
)|(),()|(
jD
jljl DCPrDXSimXCRel  
3.2 Topics clustering method 
This method clusters topics into smaller 
subtopics.  The word ?topic? used in this 
method consists of several subtopics 
representing detailed situations.  The topic 
?Hotel? consists of subtopics such as ?Checking 
In? and ?Room Service?.  Sentences in training 
data categorized under the same topic are further 
grouped into subtopics based on their similarity.  
Calculating the relevance between the test data 
input and these subsets of training data provides 
more keywords in detecting topics.  Our 
method to create the subtopics identifies a 
keyword in a sentence set, and then recursively 
divides the set into two smaller subsets, one that 
includes the keyword and one that does not. 
 
TF-IDF Clustering Method 
(1) Find the word that has the highest TF-IDF 
value among the words in the sentence 
set; 
(2) Divide the sentence set into two subsets; 
one that contains the word obtained in 
step (1) and one that does not; 
(3) Repeat steps (1) and (2) recursively until 
TF-IDF value reaches the threshold. 
 
Subtopics created by this method consist of 
keywords featuring each subtopic and their 
related words. 
3.3 Application of the dialogue history 
The proposed method applies the dialog 
history in topic detection.  The method 
interprets a current input sentence and the 
sentences prior to the current input as a dialogue 
history subset, and detects topics by calculating 
the relevance score between the dialogue history 
subset and the each topic.  The method 
increases number of keywords in the input for 
calculation.  We assign a weight to each 
sentence in the dialogue history subset to control 
the effect of time-sequence in sentences. 
The relevance score combined with the dialog 
history is calculated as: 
 
)Xr|C(lRer...)Xr|C(lRer
)X|C(lRe)Xr,...,Xr,X|C(lRe
nlnl
lnl
??
?
+++
=
11
1  
 
Here the similarity is calculated with the input 
sentence X and the sentence in the dialog history 
subset Xri, taking ? and ?ri as the weights for the 
input sentences and the sentences in the dialogue 
history, respectively. 
4 Evaluation 
To evaluate the proposed method, we 
prepared training data and test data from a travel 
conversation corpus.  We also prepared three 
22 || || || || 
) , ( 
j 
i ij i 
j D X
d x 
D X Sim 
? 
? 
= 
? 
 types of clusters with different thresholds and 
two types of dialogue history with different 
weight values. 
4.1 Training data 
In the evaluation, we used approximately 
25,000 sentences from our original travel 
conversation corpus as our training data.  The 
sentences are manually classified into four 
topics: 1) Hotel, 2) Restaurant, 3) Shopping, and 
4) Others.  The topic ?Others? consists of 
sentences not categorized into the remaining 
three. Topics such as ?Transportation? or 
?Illnesses and injuries? are placed into this 
?Others? in this evaluation. 
4.2 Test data 
We prepared two sets of test data.  One set 
consists of 62 typical travel dialogues 
comprising 896 sentences (hereafter called 
?typical dialogue data?).  The other set consists 
of 45 dialogues comprising 498 sentences, 
which may include irregular expressions but 
closely representing daily spoken language 
(hereafter called ?real situation dialogue data?). 
Sentences in ?typical dialogue data? are often 
heard in travel planning and travelling situations, 
and form a variety of initiating dialogues as the 
travel conversation unfolds.  The data includes 
words and phrases often used in the topics listed 
above, and each sentence is short with little 
redundancy.  On the other hand, ?real situation 
dialogue data? consists of spoken dialogue 
phrases which are likely to appear in 
user-specific situations in the travel domain.  
Some phrases may be typically used, while 
others may consist of colloquial expressions and 
words and phrases that are redundant.  Some of 
the words may not appear in the training data. 
4.3 Clustering the topics 
We applied the clustering with the 
aforementioned method to 8,457 sentences from 
training data which are categorized into one or 
more of the three topics: 1) Hotel, 2) Restaurant, 
and 3) Shopping.  Clusters are created on three 
different thresholds: 8,409 clusters (small-sized 
cluster), 3,845 clusters (medium-sized cluster) 
and 2,203 clusters (large-sized cluster).  In 
carrying out clustering, we set one sentence as 
one cluster if the sentence does not contain a 
word whose TF-IDF value is not equal to or 
greater than the threshold.  We excluded data 
that falls only under the topic ?Others? and data 
that falls under all four topics, which are 
considered to be general conversation.  
Variations of these topics produce 13 probable 
combinations. 
The number of clusters is smallest (13) when 
we set one topic as one cluster and largest 
(8,457) when we set one sentence as one cluster. 
4.4 Use of the dialogue history 
To evaluate the effect of the dialogue history, 
we use an input sentence, the most preceding 
and the next preceding sentence (hereafter 
?sentence 0?, ?sentence -1?, and ?sentence -2?) 
as a dialogue history.  Two types of sentence 
weights are applied to these three sentences, one 
of equal weights and one of weights based on a 
time series.  These sets are: 
 
0.33) 0.33, (0.33,  
2)- sentence 1,- sentence 0, (sentence
=
0.2) 0.3, (0.5, 
 2)- sentence 1,- sentence 0, (sentence
=
 
 
5 Results 
We performed the detection test described in 
4.3 on 13 types of topic combinations using 
typical dialogue data and real situation dialogue 
data. 
5.1 Test results on typical dialogue data 
Figure 1 shows the results of topic detection 
on typical dialogue data for a varying number of 
clusters.  The figure shows that the accuracy is 
highest when one sentence is set as one cluster 
(one sentence per cluster) in each topic, and 
lowest when one whole topic is set as one 
cluster. 
  
5.2 Test result on real situation dialogue 
data 
Figure 2 shows the results of topic detection 
on real situation dialogue data for a varying 
number of clusters.  The figure shows that the 
accuracy of the medium cluster is slightly better 
than that for one sentence per cluster.  This 
indicates that sentences grouped in terms of 
similarity heighten the accuracy of similarity 
calculation between input sentences and the 
training data. 
 
5.3 Results of dialogue history 
application 
We evaluated the effect of the dialogue 
history for typical dialogue test data, and 
compared the case of one sentence per cluster 
with the case of medium cluster.  Using only 
the input sentence, the topic detection accuracy 
was 59.2% for the former and 56.0% for the 
latter.  Using three sentences from the dialogue 
history, the respective figures were 72.0% and 
70.0% with equal weights, 76.7% and 77.0% 
with time series weights.  
 
6 Discussion 
Looking at the results on the typical dialogue 
data, it can be argued that the 
one-sentence-per-cluster case shows the highest 
accuracy because the data is a typical dialogue 
and each sentence is short, so that feature words 
in the input sentences and those of the learning 
data are likely to match.  On the other hand, it 
can be argued that the one-topic-per-cluster case 
shows the lowest accuracy because feature 
words become less effective when so many 
subtopics are in one cluster. 
For example, let us look at the sentence in the 
learning data, ?Is it all right to pick it up with 
my hand??  This sentence can be used when 
deciding what to buy, and so is categorized 
under the topic ?Shopping?.  When a cluster is 
one sentence, the result will likely be 
satisfactory if you input the sentence, ?Is it all 
right to pick it up with my hand?? because the 
input sentence is similar to the cluster.  
However, when a cluster is one topic, this 
sentence might be categorized under the topic 
?Others?, along with sentences used to express 
physical conditions such as ?My hand hurts? or 
?I am all right?.  Therefore, it can be concluded 
that it is better to divide a large topic into 
smaller groups or even into single sentences. 
Looking at the results on real situation 
dialogue data, we find the ratio of correct 
answers is almost the same for the 
one-sentence-per-cluster and the medium-cluster 
cases, but the actual sentences correctly detected 
topics differed significantly between them.  In 
the former case, topics are identified correctly 
when there are strong feature words, while in the 
latter case, it works well when there is no strong 
feature word but the topics can be determined by 
sets of words.  From this fact, we can conclude 
that typical input sentences can be compared 
easily with the one-sentence-per-cluster case, 
and real situation input sentences can be 
Figure 2: The result on real situation test data 
Figure 1: The result on typical test data 
0
10
20
30
40
50
60
one t
opic 
per c
luste
r
large
 clus
ter
medi
um c
luste
r
small
 clus
ter
one s
enten
ce pe
r clus
ter
number of cluster
ac
cu
ra
cy
 ra
te
42
44
46
48
50
52
54
56
58
one t
opic 
per c
luste
r
large
 clus
ter
medi
um c
luste
r
small
 clus
ter
one s
enten
ce pe
r clus
ter
number of cluster
ac
cu
ra
cy
 ra
te
 compared with the medium-cluster case even 
though the sentences are different from those in 
typical dialogue in terms of content and 
expressions.  We find that with typical dialogue 
data, the accuracy level is almost the same for 
the one-sentence-per-cluster and the 
medium-cluster cases, but with the real situation 
dialogue data, the accuracy level is slightly 
improved.  Therefore, it might be possible to 
improve the practicality of topic detection by 
collecting a large amount of data, dividing the 
data into typical and real situation dialogues, and 
setting the appropriate clusters to each type. 
7 Conclusions 
In this paper, we proposed a topic detection 
method using a dialogue history to select a scene 
for the automatic interpretation system.  We 
investigated its limitation in dialogue utterances 
and provided solutions by clustering training 
data and utilizing dialogue history.  Our 
method showed topic detection accuracy of at 
least 50% for both typical and real situation 
dialogues in 13 topic combinations.  For typical 
dialogues, we found that the best results were 
obtained when one sentence is used for one 
cluster, and for real situation dialogues, we 
found slightly better results were obtained when 
clustering was introduced.  Therefore, it can be 
argued that the topic detection accuracy is 
improved for both typical and real situation 
sentences if an appropriate size cluster is 
introduced. 
We plan to use our topic detection technique 
for specifying a scene condition of parallel text 
based translation in our automatic interpretation 
system.  Detecting topics also helps improve 
accuracy of the automatic interpretation system 
by disambiguating polysemy. Topic detection 
can enhance speech recognition accuracy by 
selecting the correct word dictionary and 
resources, which are organized according to the 
topic. 
Our method is also applicable in determining 
time series behavior such as topic transition.  
Our future studies will focus on linking the 
dialogue history and clustering more closely to 
improve the topic detection accuracy. 
References  
H. Hatori, Y. Kamiyama (2000) Web translation 
by feeding back information for judging 
category, Information Processing Society of 
Japan 63rd. Annual Meeting, Vol. 2, pp. 
253-254. 
 
T. Ikeda, S. Ando, K. Satoh, A. Okumura, T. 
Watanabe (2002) Automatic Interpretation 
System Integrating Free-style  Sentence 
Translation and Parallel Text Based Translation, 
ACL-02 Workshop on Speech-to-speech 
Translation (to appear). 
 
G. Salton (1989) The vector space model, 
automatic text processing ? the   
transformation, analysis, and retrieval of 
information by computer, Addison-Wesley 
Publishing Company Inc., pp.312-325. 
 
T. Tsunoda and H. Tanaka (1996) Evaluation of 
Scene Information as Context for English Noun 
Disambiguation, Natural Language Processing, 
Vol.3 No.1, pp. 3-27. 
 
T. Watanabe, A. Okumura, S. Sakai, K. 
Yamabana, S. Doi, K. Hanazawa (2000) An 
Automatic Interpretation System for Travel 
Conversation, The Proceeding of the 6th 
International Conference on Spoken Language 
Processing Vol. 4, pp. 444-447. 
 
Y. Yang (1994) Expert Network, Effective and 
Efficient Learning from Human Decisions in 
Text Categorization and Retrieval, Proceedings 
of the 17th Annual International ACM SIGIR 
Conference on Research and Development in 
Information Retrieval (SIGIR?94) 1994:11-21. 
 
Y. Yang, J.G. Carbonell, R. Brown, T. Pierce, B. 
T. Archibald, and X. Liu (1999) Learning 
approaches for detecting and tracking news 
events, IEEE Intelligent Systems, 14(4), pp. 
32-43. 
Automatic Interpretation System Integrating
Free-style Sentence Translation and Parallel Text Based Translation
Takahiro Ikeda Shinichi Ando Kenji Satoh Akitoshi Okumura Takao Watanabe
Multimedia Res. Labs. NEC Labs.
4-1-1 Miyazaki, Miyamae-ku, Kawasaki, Kanagawa 216
t-ikeda@di.jp.nec.com, s-ando@cw.jp.nec.com, k-satoh@da.jp.nec.com,
a-okumura@bx.jp.nec.com, t-watanabe@ay.jp.nec.com
Abstract
This paper proposes an automatic in-
terpretation system that integrates free-
style sentence translation and parallel text
based translation. Free-style sentence
translation accepts natural language sen-
tences and translates them by machine
translation. Parallel text based translation
provides a proper translation for a sen-
tence in the parallel text by referring to a
corresponding translation of the sentence
and supplements free-style sentence trans-
lation. We developed a prototype of an au-
tomatic interpretation system for Japanese
overseas travelers with parallel text based
translation using 9206 parallel bilingual
sentences prepared in task-oriented man-
ner. Evaluation results show that the par-
allel text based translation covers 72% of
typical utterances for overseas travel and
the user can easily find an appropriate sen-
tence from a natural utterance for 64% of
typical traveler?s tasks. This indicates that
the user can benefit from reliable transla-
tion based on parallel text for fundamental
utterances necessary for overseas travel.
1 Introduction
A speech-to-speech translation system must inte-
grate at least three components ? speech recogni-
tion, machine translation, and speech synthesis. In
practice, each component does not always output
the correct result for various inputs, and an error
in one component often leads to an incorrect result
being produced by the total system even for a lim-
ited domain. Clearly, we need ways to complement
speech-to-speech translation systems that cannot re-
liably produce a correct result.
Although some robust methods that make the er-
roneous results of other components acceptable have
been proposed (Yumi et al, 1997; Furuse et al,
1998), there is no guarantee that the final output
from a system will be appropriate even with these
methods. To deal with this problem, we have taken a
more practical approach to developing an automatic
interpretation system where the user can obtain a
correct result instead of having to apply additional
operations and judgment.
In actual use of a speech-to-speech translation
system, an error in the speech-recognition or speech-
synthesis components is not a large problem if the
system has a screen that displays each result. The
user of the system can correct errors in the recogni-
tion result on the screen, and can communicate by
showing the other person the translated sentence on
the screen.
On the other hand, an error in the machine-
translation component is critical because a user who
is not familiar with the target language is unlikely
to notice the error in some cases. When a nonsensi-
cal sentence is generated by machine translation, the
user may realize that the listener does not understand
the translated sentence. However, when a plausible
sentence that means something different from the in-
tended meaning is generated by the machine trans-
lation, the user may incorrectly assume that the ut-
terance was properly communicated. Consequently,
the user can seldom be sure that the listener cor-
rectly understood the intended meaning when using
a speech-to-speech translation system. A conversa-
                                            Association for Computational Linguistics.
                           Algorithms and Systems, Philadelphia, July 2002, pp. 85-92.
                          Proceedings of the Workshop on Speech-to-Speech Translation:
tion could continue for some time before it became
apparent that the two sides misunderstood what the
other was saying.
Moreover, if the user realizes that there is an er-
ror in the machine translation, correcting it will be
difficult. Without knowing the source of the error,
the user cannot modify the input to obtain a correct
result.
These error problems severely limit the usability
of speech-to-speech translation.
In this paper, we propose an automatic interpreta-
tion system that integrates free-style sentence trans-
lation and parallel text based translation. In this sys-
tem, free-style sentence translation accepts natural
language sentences and translates them by machine
translation without guaranteeing the quality of the
translation. On the other hand, parallel text based
translation uses parallel bilingual sentences regis-
tered in the system and translates a registered sen-
tence by referring to the corresponding translation.
Although this translation process limits the input to
registered sentences, it is a robust means of han-
dling input with recognition errors and consistently
provides a correct translation. We integrated these
two types of translation to realize a robust transla-
tion system where the two types of translation com-
pensate for the shortcomings of each other.
For appropriate integration of free-style sentence
translation and parallel text based translation, we
had to consider three main points.
1. User interface: how best to present the two
functions to the user?
2. Content of registered sentences: How many ut-
terances should be covered by registered sen-
tences?
3. Retrieval system: What methods of searching
among the registered sentences should be pro-
vided to the user?
In this paper, we discuss these three points with
respect to a translation system for Japanese travelers
in the overseas travel domain. We construct a model
of the integration of free-style sentence translation
and parallel text based translation in Section 2. We
describe a prototype system based on the model in
Section 3 and evaluate it in Section 4. Related work
on translation systems utilizing parallel text are dis-
cussed in Section 5, and we conclude in Section 6.
2 The Integration Model
2.1 User Interface
Although parallel text based translation provides a
correct result, the registered parallel bilingual sen-
tences cannot cover all possible utterances by the
user in the target domain. Free-style sentence trans-
lation, on the contrary, accepts free-style input sen-
tences but provides no guarantee as to the quality of
results.
For many routine situations, users will clearly
benefit from using parallel text based translation.
In such cases, the system will probably include a
sentence that totally or partially fits what they want
to say. To ensure high translation reliability, users
should use free-style sentence translation only for
utterances not covered by the registered sentences.
However, users usually will not know what sen-
tences are registered in the system and will have to
search for an appropriate sentence before they can
use parallel text based translation. In some cases, the
user will be forced to use free-style sentence trans-
lation if unable to find an appropriate sentence.
A seamless user interface that allows the user to
easily switch between free-style sentence transla-
tion and parallel text based translation is therefore
needed in a system integrating these two forms of
translation. Two conditions in particular had to be
met to make the system easy to use.
1. The user should be able to use an input sen-
tence seamlessly as both a source sentence for
free-style sentence translation and a key sen-
tence for registered sentence retrieval.
2. The user should be able to use each sentence in-
cluded in the results of the registered sentence
retrieval and the input sentence as a source
sentence for translation. (The former would
be used for parallel text based translation, and
the latter would be used for free-style sentence
translation.)
2.2 Content of Registered Sentences
Registered sentences must cover the utterances nec-
essary for accomplishing typical tasks in the target
domain to provide correct translation for minimal
communication. In a translation system for overseas
travelers, some typical tasks are changing money,
checking in at a hotel, and ordering at a restaurant.
We adopted a three-tier model that consists of
scenes, tasks, and subtasks to prepare a sufficient set
Table 1: Examples of scenes, tasks, subtasks, and templates of sentences
Scene Task Subtask Template of sentence
Hotel Check-in Checking in I?d like to check in, please.
Hotel Check-in Requesting a type of room I?d like a room with the ocean view.
Restaurant Order Requesting cooking time for your steak Medium, please.
Restaurant Order Asking what they recommend What do you recommend for appetizers?
of necessary sentences to be registered in the sys-
tem. A scene comprised a place or situation that
corresponds to where a traveler is likely to be (e.g., a
hotel) and a problem that could arise. We made a list
of typical travelers? tasks that would be necessary in
various travel scenes, divided each task into smaller
primitive tasks (subtasks), and assigned a sentence
template to each subtask based on the model.
In general, more than one round of conversation
is necessary to accomplish each task. We assumed
that a task would consist of smaller subtasks, each
of which would correspond to one round of conver-
sation that consisted simply of an utterance from a
traveler to a respondent and a response from the re-
spondent to the traveler. For example, the task of
checking in to a hotel consists of subtasks such as
giving your name, confirming your departure date,
and so on. Each subtask should be the smallest unit
of a task because users cannot use a registered sen-
tence effectively if it includes more than what they
want to say.
In this way, only one sentence template is needed
for each subtask with regard to an utterance from a
traveler to a respondent. For example, we can assign
a sentence template of ?I?d like to have ....? to the
subtask of ordering a dish in a restaurant. We can
provide a sufficient number of sentences by enabling
the user to fill in the part denoted as ?...? (referred to
as a slot) with words applicable to the situation.
Table 1 shows examples of scenes, tasks, sub-
tasks, and sentence templates. An underlined part
represents a slot. We define a list of words individu-
ally for each slot.
For each task, both the utterances from a traveler
to a respondent and the responses from a respon-
dent to a traveler are significant. Responses should
also be supported by parallel text based translation to
ensure reliable communication. However, inputting
the response and retrieving a registered sentence that
matches it will be difficult and time consuming for
the respondent who is unlikely to be familiar with
the translation system.
We use a system that presents a menu of responses
for the respondent to choose from. The system keeps
typical responses in parallel bilingual form for each
registered sentence that the traveler can use and dis-
plays these as candidate responses when the traveler
uses the sentence. The system then shows the trav-
eler the translation of the response selected by the
respondent.
This approach enables travelers to obtain a reli-
able response and also enables respondents to easily
select an appropriate response.
2.3 Retrieval System
The retrieval system to search for a registered sen-
tence that we use is based on a combination of three
conditions ? the natural language sentence, scene,
and action.
Registered sentence retrieval based on a natural
language sentence is essential for seamless integra-
tion of free-style sentence translation and parallel
text based translation. We used a simple keyword-
based retrieval system for registered sentence re-
trieval. This system extracts keywords from an in-
putted natural language sentence, searches for sen-
tences including the keywords, and presents the re-
sults ranked mainly by the number of keywords in-
cluded in each sentence.
The system retrieves all sentences including more
than one keyword to reduce the chance of an appro-
priate sentence not being retrieved. We overcame
the increased retrieval noise in the result by applying
an additional retrieval system to search for registered
sentences in terms of the scene and action.
Each registered sentence to be retrieved for trans-
lation corresponds to a set of a scene, a task, and
a subtask as described in the previous section. A
scene represents a place or a situation where the user
wishes to accomplish the task and the subtask. A
task and a subtask represent a user?s actions. This
means that the user?s utterance is related to the user?s
intention regarding where (scene) the user wants to
do something (action).
We use the additional retrieval system in situa-
tions where the user has to search for sentences from
	
		


	

	

	


	
	
	


		




		
	
	

		


	
	


	
