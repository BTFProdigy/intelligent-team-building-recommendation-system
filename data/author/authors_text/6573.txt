Authoring Multimedia Documents using WYSIWYM Editing 
Kees  van  Deemter  and  R ichard  Power  
Infbrmat ion Technology Research Inst i tute 
UIfiversity of Brighton, Brighton, UK, 
{Kees. van. Deemter, Richard. Power}@itri. brighton, ac. uk 
Abst ract  
(1) This paper outlines a future 'ideal' nmlti- 
media document authoring system that allows 
authors to speci\[y content and form of the docu- 
ment independently of each other and at a h igt~ 
level of abstraction; 
(2) It describes a working system that imple- 
ments a small but significant part of the flmc- 
tionality of such an ideal system, based on se- 
mantic modeling of tile pictures as well as the 
text of the docunmnt; and 
(3) It explains what needs to be done to bridge 
the gap between the implemented system and 
the ideal one. 
1 A Future  ~Ideal' Mu l t imed ia  
Document  Author ing  System 
A Document Authoring System is a tool that 
helps an author to writ(; docmnents. If the sys- 
tem supports tile authoring of documents that 
combine 'presentations' in diflb.rent media (text 
and images, for example), we will speak of a 
multimedia document authoring system. Ide- 
ally, a multimedia document authoring system 
would allow authors to speci(y the content and 
fbrm of a high-quality document in ways that 
are both simple and etiicient. More specifically, 
an ideal system would aftbrd the tbllowing op- 
tions to the author: 
1. Easy determination of content. ~Content' 
is taken to mean the factual (i.e., proposi- 
tional) content of the docmnent - in other 
words, the content of the Knowledge Base 
(KB) that forms the input to tilt document 
authoring system. 
2. Easy determination of style and layout. In 
the absence of specific instructions from the 
author, style and layout should be deter- 
mined using intelligent defimlts. (For ex- 
ample, tile standard settings may require 
tilt document o be infi)rmal, with avoid- 
ancc of technical terms, lists and footnotes, 
without nlaximum paragraph length, and 
with numbered sections.) Defaults can be 
overridden by the author, whereupon other 
defaults mw become relevant. 
3. Easy allocation oJ' media. As in the case 
of style and layout, the system has to use 
judiciously chosen de.faults: perhaps using 
illustrative pictures wherever suitable pic- 
turks are available, and graphs or tables 
wherever large amomlts of homogeneously 
structured quantitative information are in- 
volved. As above, defaults may be over- 
ruled by specific requests from the author; 
if a request is impossible to fifllfil, an appro- 
priate error message should tm generatc(t. 
4. Easy annotation of non-generated presen- 
tations. In some cases, it will be possible 
tbr the system to generate presentations. In
other cases, this mw be impossible: Liter- 
ally quoted texts, for example, or historic 
photogral)hs , m~y predate the use of the 
system, in which case it may be necessary 
to treat them as 'canned' and to annotate 
thenl to allow the system to make intelli- 
gent use of them. 
5. Easy post-editin.q. Once tile system has 
produced a document according to the 
specifications of the author, the ideal sys- 
tem would oiler tools to address remaining 
ilmdequacies using post-editing. 
'Easy' means efficient, protected against incon- 
sistencies, and not requiring specialist skills or 
knowledge. A domain specialist, - who may not 
know anything about knowledge representation, 
logic, or linguistics - could use such a system to 
222 
build KBS that l;he sysl;elll call turn into docu- 
menl;s in any desired bmguage using any desired 
(:olnbination of media. The 1)reduction and ut)- 
(b~ting of (;omplex documents would l)e greatly 
simplitied as a result. 
In present-day practice, these requirements end 
to be far from realized: authoring docuxnents by 
means of such l;oots as MS WORD or POWER,- 
POINT requires much low-level int;eraction, such 
as the typing of (:haracters (m a keyl)o;trd anti 
the dragging of figures from one plwsic~d lo- 
cal;ion t;o m~other. In SOllle cases, all h~telli- 
gent Mult, inledia l)resentation Systc, ln (IMMPS 
e.g., Bordegoni et al 1.997) can be used (see 
AIR 1995, Maybury and Wahlster 1998 for some 
surveys), which (nnploys techniques from Arti- 
ficial Intelligence to allow higher-lew~l intera('- 
l;ion. Present IMMI'S, howev(,r, meel; few of the 
\]'e(luirenmnl;s nenl;ioned al)ove. Most ()f l;hem, 
fi)r exmnl)le ~ require intmt ()t' a highly Sl)e(:ial- 
ize.d 11al;llre (e.g., the (;omt)lex logical fornm- 
las ent;ere(t in the wIP sysl;em, An(trd and II.isI; 
1995) 1 and l;hey allow an author little (:ontrol 
over the tbnn (e.g., layout, textual style, me(lia 
allocation) of the (loellnlenl;. The issue of easy 
amlol.ation (d) is never even ad(lress(',(t, to tim 
be, st of our knowledge. 
The, next section descril)es an iml)hnnented sys- 
tem tbr l;he authoring of teztual (lo(:uinents l,hal. 
can |)e ~rgue(l to fltllill requirements (1) and 
(2) and which tbrms n suitnbh: st~rtin g point 
for working towards the 'ideal' multimedia sys- 
l;e111 outlined above,. Section 3 des(:ril)es ~tll ex- 
tension of this system in which signiticallt as- 
1)ect;s of re(luireln('nt;s 3-5 h~we also been ilnl)le- 
menl;ed. Key features of l;his new sysl;em nre its 
ability to use .semantic 'repre.s'entatio'n.s l;hat are. 
common to the different media, and the abil- 
ity to construct natural language feedback texts 
to help the author understand the contenl; and 
the form of |;lie document while it is still raider 
eonsl;ruction. The concluding section exl)lains 
what needs to be done to till the gap |)el, ween 
the iml)lemenl;ed sysl;eln and |,tie ideal one. 
1An exception is AIA,Tes(:o whit:h takes natural lan- 
guage input~ requiring the system to interpret uncon- 
strained natural language (Stock 1991). Avoiding the 
need for doing this is an important design motivation 
for WYSlWYM-based syst;enis. 
2 A WYSIWYM-based  System tbr 
the  Author ing  o f  Textua l  
Documents  
Elsewhere (Power mid Scott 1998, Scott el; al. 
1998, Scott 1999), a new knowledge-editing 
1net;hod called ~WYSIWYM editing' has been in- 
troduced and motivated. WYSIWYM editing 
allows a domain expert to edit a knowledge 
base (KB) by inl;er~wl;ing with a .\[~edbaek ic.:rt,, 
generated by the system, which pl'esents both 
the knowledge, already defined and the options 
for exl;ending and modit~ying it. Knowledge is 
added or modified by return-based choices which 
directly Mti;et the knowledge base; the result is 
displayed to the author by means of an auto- 
matic~lly generated feedback text: thus ~What 
You See ls What You Meant'. WYSIWYM in- 
stant|ares a general recent trend in dialogue sys- 
l;ems |;owards moving some of the initiative from 
the user to the sysl;em, ~dlowing such systenls to 
avoid the (titli(;ulties of t)ro(;essing %t)cn ~ (i.e., 
tureens|rained) input. 
Of parti(:ular importance, here, m:e at)plieations 
of WYSIWYM to the generation of documents 
(:ont~dning text mid 1)ietures; the t)resent sec- 
tion tbcuses on (multilingual) tezt generation: 
l;he KB (:re~Lted with the help of WYSIWYM is 
used as input to a natural language generation 
(NLG) l)rogrmn, pro(hu:ing as output a docu- 
ment of some sort, for I;he benelit of ~m end 
user. Present apt)lications of WYSIWYM \[;o i;exl; 
generation use a KL-ONE-I,yl)e knowledge rep- 
resentation language as input to two NLG sys- 
\[;elliS. ()lie NLG sys|;elll generates tb.edback texts 
(for l;he raft;her) ml(t I;h(' other gener~d;es on|trot 
l;exi;s (for all ell(t l lser). Ol le at)plication cur-  
rent ly  under develotmmnl; has 1;11(; creation of 
Patient Informal;ion Leaflets (PILLS) aS its do- 
main. The present vt;rsion of this PILLs system 
allows authors to enter information about pos- 
sible side eft'cots ( ' i f  you are either pre.qnant o1" 
allergic to penicillin, then tell your doctor') and 
how to handle lnedical devices such as inhalers, 
inoculators, etc. By interacting with the feed- 
back texts generated by the system, the author 
can detine a procedure for perfornfing a task, 
e.g. preparing an inhaler for use. A llew KB 
leads to the creation of a procedure instance, 
e.g. p. The permanent part of the KB (i.e., 
the T-Box) spt, eifies l;haI; procedures ma, y be 
223 
complex or atomic, and lists a number of op- 
tions in both cases. In the atomic case, the op- 
tions include Clean, S tore ,  Remove, etc., and 
these are made visible by means of a metal from 
which tile author can select, say, Remove. Tile 
program responds by adding a new instance, of 
type Remove, to the KB: 
Remove(p) 
('There is a procedure p whose type is Remove.') 
th'om the updated knowledge base, the genera- 
for produces a feedback text 
Remove this device or device-part 
from this device or device-part,  
making use of the infbrmation, in the T-Box of 
the system, that Remove procedures require an 
Actee and a Source. Such not yet defined at- 
tributes are shown through mouse-sensitive an- 
chors. By clicking on all anchor, the author 
obtains a pop-up metal listing the pernfissible 
values of the attrilmte; by selecting one of these 
options, the author updates the knowledge base. 
Clicking on this device or device part yields 
a pop-up menu that lists all the types of devices 
and their parts that the systenl knows about, in- 
eluding a Cover (which, according to the T-Box 
must have a Device as Owner). By continuing 
to make choices at anchors, the author might 
expand the knowledge base in the tbllowing se- 
quence: 
? Remove a device's  cover from a device 
or device-part  
? Remove a device's  cover from an inhaler 
of a person 
? Remove a device's  cover from your inhaler 
? Remove your inhaler's cover from your in- 
haler 
At this point the knowledge base is potentially 
complete, so a (less stilted) outp'ut tczt can be 
generated and incorporated into the leaflet, e.g. 
Please remove the cover of your ill- 
haler. 
Longer output texts can be obtained by expand- 
ing the feedback text fitrther. A numl)er of 
proi)erties of the PILLS system are worth stress- 
ing. First, the system sut)ports a high-level di- 
alogue, allowing the author to disregard low- 
level details, such as the exact words used in the 
output text. This makes it possible to interact 
with the system using, say, French (provided a 
generator tbr French feedback texts is available), 
for the i)roduction of leatlets in Japanese (pro- 
vided a generator for Japanese output texts is 
available). The semantic model in the T-Box 
guarantees that many types of inconsistencies 
(e.g., a medicine that has to be taken both once 
and twice a day) are prevented. Second, a sire- 
ple version of WYSIWYM has also been applied 
to the tbrm of the text, allowing the author to 
specit) it separately from its content. This is 
done by allowing the author to use WYSIWYM 
tbr building a second, form-related KB which 
describes the st~.tlc and layo'ut of the docmnent. 
Th is  KB, for example, may state that the maxi- 
mum paragraph length is 10 sentences and that 
there are no tbotnotes. (A second, form-related 
T-Box deternfines what the options determining 
layout are.) This form-related KB constrains the 
texts that are generated. By interacting with 
feedback texts describing the tbrm-related KB, 
the author changes the stylistic/layout proper- 
ties of the document. 
A WYSIWYM-based  System for 
the  Author ing  o f  Mu l t imed ia  
Documents  
ILLUSTrl, ATE is ai1 extension of PILLS produc- 
ing documents that contain pictures as well as 
words. Consider a toy exalnl)le, adapted from 
ABPI (1997). Suppose the document says Re- 
move the cover of your inhaler. An instruction 
of this kind may be illustrated by the picture 
below. How can a document authoring system 
produce a document in which appropriate pic- 
tnres illustrate the text when this is desired? 
ILLUSTRATE does this by allowing an author to 
ask tbr pictorial il lustration of the intbrmation 
in the document by interacting with the feed- 
back texts. The author can indicate, fbr a given 
mouse-sensitive stretch s of the feedback text, 
whether she would like to see the part of the 
document hat corresponds to s illustrated. If 
so, the system searches its library to find a pic- 
ture that matches the meaning of s. In Fig.2, 
the author has requested illustration of the in- 
224 
i . . . . . . .  1_/ 
I 
Figure 1: One of the picture.s ill the lit)rary of 
the a, uthoring system 
struction (:orresl)onding with tim text 'Remove 
your inhaler's cov(,r fi'om your inhaler'. (The 
otlmr four options are irrelevant for t)resent pur-  
poses . )  In domains where all the pictures are 
, i  
\[:Jle ;%.'.ture f,.',oda!~t? C,srltr0l 
\ ]{en lova  your  inha le r '  s cover  h ' ,  . . . . . .  , . , , , .  ; , .h  . I . . , .  
ti i i l i  i:. ' .t 2c . . fvs , : l : t ;  
C,:,I>'~ 
CLR 
(gel)ell : t~,  a 
,%i.: !!,,,,d,, di, r ~ 
Figur(' 2: Screen(hunt): Author makes a re-. 
quests for illustration 
variations on a common theme, suitnble pic- 
tures can be generated. Ill the case. of l)atient; 
Information LeMtets, however, this was not a 
practical option because of the many ditDrent 
kinds of things depicted in the leaflets: medicine 
packages, body parts, medical at)l)licmmes, var-. 
ious t;yl)eS of actions, etc. Pictures, moreover, 
are he,wily reused in the diit'erent leatlets writ- 
tell \])y the S&lilO company. For these reasons, 
IIAAJSTRATt?, llses ~tii alternative al)proaeh, se- 
lecting pictures from a library, each of which is 
;tnnol;at,ed with ~t formal rel)r(;sentation of its 
meaning. We will explain the workings of IL- 
LUSTRATE by answering three questions: (\]) 
What kinds of rei)resent~tions are used ill the li- 
brary to annotate the pictures with relevant as- 
l)ects of their meaning'? (2) How is the .~;emanti- 
(:ally annotated library of t)i(:tures created'? and 
(3) What selection algorithm is employed to re- 
trieve all optimally approt)riate illustration for a 
given part of the, KB frolll the library? We shall 
assmne that the information whose illustration 
is requested con'esponds with the following for- 
mul~t in the KB, which tel)resents the metaling 
of the feedback text ill Fig. 2. 
R,'~,,,,o~,,'.(t,) ,V Acto,'(p) = .',: 
I~,.a~.,'(.~:) g So,,,,.,:c~(;,) = v a~ 
Inhalcr(y) ~ Actce(p) = z 
g = v. 
('There exists a 'Remove.' action whose Sere'co 
is an Inhah'.r and who.~e Ad, ee is a Cover of the 
same inhaler.') 
1. What  k inds  of  representat ions  are  
used?  Representations say what information 
each pictm'e intends to convey. Irrelewmt de- 
tails shouht be omitted. It has been observed 
that photographic pictures express 'vivid' in- 
formation and that this intbrmation can be 
expressed by a conjmmtion of positive, literals 
(Levesque 1!)86}. In line with this obserwttion, 
ILLUSTI/ATE rei)resents the lllea, nillg of the pic- 
ture in Fig. 1, for example, as follows: 
;~+.',,,.o~,+.'(p) *+ So',,.r',:+.'(p) = :\] 
H-I*",'(V) ,V A,tc~;(~,) = 
a C,,',.',,'(~) a O',,,,,. ', '(~) = :,j. 
(The leattet.~; (le,~mril)e Inhalers, Autohale.rs, and 
Aerohalers.) If any of the wtriables c, :r, y, z has 
&Ii oc('urrelice ill the llle;tlling rel)resentation of
mlother 1)i(:ture thei~ these occurrences coref'er. 
This ~:dlows the systmn to know wh(.'n two pi(:- 
tm'es depict the same. i)erson, for examt)le (Vail 
Demrd:er and Power 1999). 
2. How is the  l ib rary  c reated?  This is a 
question of great imi)ortmlce because the library 
contains emantic representations that m'e lIlltCh 
more detailed than those in current picture re- 
t r ieval  systems (e.g. Van de ~vVaal \]995) nml this 
couht potentially nmke the &llllOtat;iOll t;ask ex- 
tremely })ur(lensome (Enser 1995). The an,~wer 
to this t)rol)lem may be unext)e(:t;e(l: ILLUS- 
TI1ATE u.qi'.s WYSIWYM it;self to emtl)le authors 
t.t) associate ;t given t)icture with a novel rep- 
resenl;;tl;ion. The class of representations tlmt 
225 
are suitable for expressing the meaning of a pic- 
ture is, alter all, a ('vivid') subset of tile class 
of representations allowed by the T-Box tbr tim 
text of the document, and consequently, tim 
same WYSIWYM interlhce can be used to create 
snch representations. Fig. 3 contains a screen- 
dump of the annotation process, wtmre the cnr- 
rent annotation corresponds with the formula 
Cover(z) & Owner(z) = y. Note that this 
formula is still incomplete because the nature 
of the Source is undefined. (When it is finished, 
the feedback text will be eqniwtlent o that in 
Figure 2.) The top of the screendump shows the 
accompanying feedback text containing anchors 
tbr flsrther additions. 
Figure 3: Screendump: A stage during tile an- 
notation of a picture 
3. What  is the select ion algorithm? A pic- 
ture can illustrate ass item of information with- 
out expressing everything in it. For example, 
Fig. 1 does not show that the Actor is the 
Reader and it leaves the type of 'Haler' unspec- 
ified. (They all look alike.) So, a selection rule 
must allow pictures to omit intbrmation: 
Select ion Rule: Use the logically 
s t rongest  picture whose representa- 
tion is logically impl ied  by  the infor- 
mation to be illustrated. (Van Deemter 
1999) 
Logical strength is determined on the basis of 
the two semantic representations alone. Deter- 
mining whether one representation logically ira- 
lilies tim other, where one is an instance in the 
KB and tim other a representation of a picture, 
is easy, given that both are conjunctions of pos- 
itive literals. 
This brief description should suffice to highlight 
the following advantages of ILLUSTRATE: 
? One unifbrm interface is employed for all 
actions that involve the editing of semantic 
representations, regardless of the type of 
presentation i volved (i.e., its media). 
? When used for the construction of anno- 
tations of pictures, the T-Box of the sys- 
tem snakes sure that only those properties 
can enter an annotation that are relevant in 
connection with it. In the present domain, 
for example, the height of the patient is ir- 
relevant, and consequently the T-Box does 
not make height all attribnte of a person. 
,, Pictures are retrieved by a reasoning pro- 
cess involving classical ogic; since a match 
between a picture and a piece of the KB 
can never be inexact, there is no need tbr 
the retriewfl process to be probabilistic, as 
has to be done when the system has less 
control over the form of annotations (Van 
Rijsl)ergen 1985, Van Deesnter 1999). 
Specific aspects of ILLUSTRATE have been de- 
scribed elsewhere, but the assumptions belfind 
the system as a whole have not beess tated be- 
fore. (For tlm representation scheme and the 
selection scheme see Van Deemter 1999; tbr 
the treatment of sequences of pictures see Van 
Deemter and Power 1999.) We have so t'nr sin> 
plified by assuming there to be only one au- 
thor. In fact, however, an intelligent authoring 
system is most useflfl when there are several au- 
thors (each of which can be allowed to work in a 
different langnage). More specifically, it is plan- 
sible that the person anthoring the annotations 
in the library is not the santo as the person(s) 
who author(s) the document itself. 
4 Future  Work  Towards  the  I dea l  
The PILLS system (section 2) makes a first 
stab at fnlfilling text-related requirements 1 and 
2 nmntioned in section 1. The ILLUSTRATE 
demonstrator goes beyond this, fulfilling impor- 
tant aspects of requirements 3 and 4 as well. 
226 
Yet, there is a considerable ga t) l)etween the im- 
i)hmlented system and the ideal one of section 
1. Possit)le improvements do not only concern 
the (:overage of the sysl;em, but matters of sys- 
tem arehitectm:e as well. Three (titti;rent sets of 
improvements may l)e dis(:erned. Firstly, there 
is rcquirelnent 5 of section 1, whi(:h requires 
easy postediting. It is easy to allow at%hers to 
make h)w-levcl corrections in the document a.f- 
let the interaction with WYSIWYM, HIlL unless 
the system 'understands' the, meaning of the 
editing actions, i)ostediting destroys tlm con- 
ne(:tion t)etween the edited document an(l the 
(:ontent of l;he various knowledge l)nses. Conse- 
quenl;ly, l)OSt-editing is not a t)ractieal t)ossit)il- 
ity yet, giv(;n the state of the, m:t in text- and 
picture understanding. 
Other imt)rovements would 1)e less t)rol)lem- 
atic. On the one hand, there are issues that 
have been t~mkled by other research groups and 
whose sohltions we inten(t to (:arty over to a 
WYSlWYM-l)ased setl;ing. These (:on(:ern the 
generation ot' gral)hies Kern underlying rel)re- 
sentations (Wahlster et; al. 1993) and the 1)rot)- 
lem of ot)timizing tim layout of text & \])i(:ture 
do(:uments (e.g. Grat)h et al 1996), l'or in- 
stall(;e. Three remaining imt)rovements , (m the 
Ot\]ler \]lall(t~ ~LFe lllal;t(~rs for fill;tire l;('.s(?~l;(;ll: 
? Media alloc,,tio'n,. \]LLUSTRATF eml)o(li(',s 
one way in whi(:h media may be allocated. 
Other mechanisms (:ould give the system 
more autonomy. For example, l;he system 
may use rules (e.g. I/.oth and Hettey 1.!)93) 
to decide alltOllOnlOllsly what illforlllation 
is in need of illustration. Simih~rly, authors 
may 1)e enabled to 1)oint at thmnlmail 1)ie- 
tures, whereul)On the system tries to fin(t a 
suitable place in the document o include 
them, based on the ret)resentation of their 
meaning and making use, of the Se lect ion  
Ru le  of section 3. By thus allowing the au- 
thor and the system to coot)crate on media 
allocation, this ditiicult task will t)e lnade 
more tractable (see the recent discussions 
ill ETAI 1997-8). 
? Other media. Little in ILLUSTRATE hinges 
on the fact that the ol)jects in the lil)rary 
are t)ictures. The Salll(. ~ system, for exam- 
t)le, can be used tbr ammtating somul or 
canned tez t  (for examl)le, a complex t)it of 
btw {:ode, which needs to be rendered liter- 
ally). Of great practical interest, finally, is 
the 1)ossil)ility of including docunlents au- 
thored previously (and possibly by a dif- 
ferent author), leading to iterative applica- 
tions of WYSIWYM. 
? bttcract ion bctwc.cn media. Ide~flly, the 
words in a text should be Ml'ected by the 
inclusion of a picture: First, and most obvi- 
ously, texts im~y be cnlauicd by retbrences 
to 1)ictures (e.g., references like ~See Fig. 
3' may l}e.adde{t, {:f Paraboni an{t Van 
l)eemter 1999). Secondly, texts may 1)e 
red,uccd because information expressed in 
the 1)ictme can l)e shortened (or left out 
all;ogether). One type of situation where 
this h~q)l)ens i  cxempliiied by t;he text '12,o- 
move the ('al)sule frolll the foil as shown 
in the \])i(:ture' (ABPI 1997), a(:(:omt)anie(t 
1)y a t)i(:ture showing how this may be 
done. Oth(;r tyt)es of situation in(:lude the 
case where quantil;ative inforln~ttion is ex- 
1)resse(t through a vague textual descril)l;ion 
('a blol) of (:ream', ~a tingertip of ointmead:') 
that is made more l)re(:ise by means of a 
picture showing t\]w, required amount. 
It should 1)e noted that each of these extensions 
del)ends ('ru('ially on ILLUSTRA'I'E:s at)ility to 
ma.nil)ulate the semanti(: rel)resentations ass()- 
('iated with multimedia objc(:ts, whoxc' one mid 
the same rel)resental;ion language is used fbr 
the difl'erent media: a lmfltimedia qnterlingua' 
(e.g. Barkcr-Plummer and Greeves 1995). 
In the ('ase of an author selecting a t)icturc 
using tlmmbnails, tbr exami)le , the semantic 
rel)resentation cnal)les the author to (a) t inda  
suitabh; local;ion for the t)ieture and (1)) adat)t 
the, (;ext l)y omitting fl'om i(; information that 
is now expressed by the picture. 
A final extension of the ideas outlined in this 
t)aper would involve completing the symmetry 
between feedl)ack and outl)ut: all t)resent 
WYSIWYM systems IlSe Imrely textual feedback. 
In prin(:it)le, however, feedt)ack can l)e as 
multimodal as the target document. We are 
currently exploring the 1)ossibility of allowing 
an author to express some of her choices by 
clicking on a mouse-sensitive part of a picture; 
the system could generate an ui)dated feedback 
text (possibly along with an updated t)icture) 
227 
as a result. Iu some technologically complex 
domains, for example, where a brief description 
of an object may be difficult to obtain, this 
might lead to a fllrther improvement of the 
WYSIWYM technique. 
References  
ABPI (1997). The Association of the British 
Pharmaceutical Industry, 1996-1997 ABPI 
Compendium of Patient Information Leaflets. 
Am (1995). Special Issue, edited by P. Mc 
Kevitt, on Integration of Natural Language 
and Vision Processing: Intelligent Multimedia. 
Artificial Intelligence Review 9, Nos.2-3. 
E. Andr6 and Th. Rist (1995). Generating 
Coherent Presentations Employing Textual and 
Visual Material. Art{ficial Intelligence Review 
9:147-165. 
D. Barker-Hummer and M. Greeves (1995). 
Architectures for Heterogeneous Reasoning. 
In J.Lee (Ed.) Prec. of First International 
Workshop on Intelligence and Multimodality in 
Mnltimedia Inte1:faces: Research and Applica- 
lions (IMMI- 1), Edinburgh. 
M. Bordegoni, G. Faconti, S. Feiner, M.T. 
Maybury, T. I{ist, S. Ruggieri, P. Trahanias, 
and M. Wilson (1997). A Standard Reference 
Model for Intelligent Multimedia Presentation 
Systems. Computer Standards & Interfaces 18, 
pp. 477-496. 
P. Enser (1995). Progress in Docmnentation; 
Pictorial hffbrmation II,etrieval. Journal of 
Documentation, Vol.51, No.2, pp.126-170. 
ETM (1997, 1998). ETAI News Journal on 
Intelligent User Interfaces, Vol 1, No's 1 and 2. 
W.H. Graf, S. Neurohr, and R. Goebel (1996). 
A Constraint-Based Tool for the Pagination of 
Yellow-Page Directories. In U. Geske and H. 
Simonis (Eds.) Procs. of KI96 workshop on 
declarative constraint programnfing. GMD- 
Studien 297, St. Augustin. 
H.J. Levesque (1986). Ma~king Believers out of 
Computers. Artificial Intelligence 30, pp.81-108 
M. Maybury and W. Wahlster (1998). Read- 
ings in Intelligent User Interthces. Morgan 
Kaufmmm Publ., San Francisco. 
I. Paraboni and K. van Deemter (1999). Issues 
for Generation of Document Deixis. Ill E. 
Andrd c ta l .  (Eds) Procs. of workshop on 
Deixis, Demonstration and Deictic Belief in 
Multimedia Contexts, ill association with tile 
l l th  European Smnmers School in Logic, 
Language and Information (ESSLLI99). 
R. Power and D. Scott (1998). Multilingual 
Authoring using Feedback Texts. In Prec. of 
COLING/A CL co#:ference, Montreal. 
S. Roth and W. Hefley (1993). Intelligent 
Multimedia Presentation Systems: Research 
and Principles. In M.Maybury (Ed.) Intelligent 
Multimedia Interlaces, AAAI Press, pp.13-58. 
D. Scott, R. Power, and R. Evans (1998). 
"Generation as a Solution to its own Problem", 
Accepted for Prec. of 9th International Work- 
shop on Natural Language Generation. 
D. Scott (1999). The Multilingual Generation 
Game: authoring fluent texts in unfamiliar lan- 
guages. Proceedings of the 16th International 
Joint Conference on Artificial Intelligence 
(IJCAI'99). 
O. Stock (1991). Natural Language and Explo- 
ration of an Information Space: the aLFfl'esco 
Interactive Systein. In M. Maytmry and W. 
Wahlster (1998). 
K. van Deemter (1999). Docunlent Geueration 
and Picture Retrieval. In Prec. of Third 
Int. Conf. on Visual hfformation Systems, 
Amsterdam, Springer Lecture Notes. 
K. van Deemter and R. Power (1999). Inclusion 
of Picture Sequences in Generated Docmnents. 
In Prec. of iburth Portuguese Conf. on 
Artificial Intelligence, Evora, Springer Lecture 
Notes. 
H. van de Waal (1995). ICONGLASS; An leone- 
graphic classification system. Amsterdam 1973- 
1985 (17 vols). ISBN 0-7204-8264-X. See also 
<http : / / i cone lass .  leg .  ruu. n l /home, html>. 
C.J. van Rijsbergen (1989). Towards an inibr- 
mation logic. In: Prec. ACM SIGIR. 
W. Wahlster, E. Andrd, W. Finkler, H.-J. 
Profitlich, and Th.Rist (1993). Plan-based 
Integration of Natural Language and Graph- 
ics Generation. Artificial Intelligence 63, 
p.387-427. 
228 
Planning texts by constraint satisfaction 
Richard  Power  
I n fo rmat ion  Techno logy  Research  Ins t i tu te  
Un ivers i ty  of Br ighton  
Lewes Road 
Br ighton  BN2 4G J, UI,: 
Rich ard.  Power:~_}itri. b ton.  ac. uk 
Abst ract  
A method is de.scribed by which a rhetorical- 
structure tree can be realized by a text structure 
made up of sections, paragraphs, sentences, verti- 
cal lists, mid other textual patterns, with discourse 
connectives added (in the correct positions) to mark 
rhetorical relations. We show that text-structuring 
can be formulated as a Constraint Satisfaction Prob- 
lem, so that all solutions rest)ecting constraints on 
text-structure formation and structu,'al compatibil- 
ity can be efficiently generated. Of the many sohl- 
tions generated by this method, some are stylisti- 
cally preferable to others; we show how further con- 
straints can be applied in order to select the best 
versions. Finally, we discuss some extensions uch 
as the generation of indented text structures. 
1 In t roduct ion  
Much recent work on language generation (I-tosner 
and Stede, 1992; Hovy, 1993; Mellish et al, 1998) 
has made use of discourse representations based 
on Rhetorical Structure Theory (RST) (Mann and 
Thompson, 1988). Interest has focussed in particu- 
lar on the problem of buihting a rhetorical str'uct~tre 
(RS) which organizes elementary propositions him'- 
archically by means of RST relations (.NIarcu, 1996). 
There has been less attention to a second problem 
in text plmming, that of realizing the RS by a te:rt 
struct.uT'e (TS), in which the material in the RS is dis- 
tributed among I)aragraphs, entences, vertical ists, 
etc., perhaps linked up by discourse connectives such 
as 'since' and 'however'. This task, which we will 
call text structuring, is typically addressed through 
a micro-planning phase that determines the content 
of successive sentences. However, docmnents of re- 
alistic complexity require richer TSs including, for 
example, vertical ists, sub-sections, and clauses ep- 
arated by semi-colons. 
We describe in this pat)or a text-structuring sys- 
tem that has been developed within ICONOCLAST 1 , a 
project which investigates applications of constraint- 
based reasoning in Natural Language Generatiou 
I ICONOCI.AST is supt)orted by the UI<. l~ngineering and 
Phys ica l  Sciences t/.esearch Counci l  { EPSI{(':) G rant 1,77102. 
concession 
approve(fda, elixir-plus) cause 
banlfda, elixir) contain(elixir, gestodene) 
Fignre 1: Rhetorical structure 
using as subject-nlatter the domain of medical in- 
formation leaflets. Following Scott and de Souza 
(1990), we represent rhetorical structure by graphs 
like figure 1, in which non-ternfinal nodes rel)re- 
sent RST relations, terminal nodes represent propo- 
sitions, and linear order is unspecified (for regularity, 
the nucleus is arbitrarily presented on the left of the 
satellite). One of many possible TSs realizing this 
I{S is shown in figure 2, au ordered tree in which 
nodes are labelled with %ext-categories' (Nunberg, 
1990); the terminal nodes hold either discourse con- 
nectives (which owing to their interaction with text 
structure have already been selected) or l)ropositions 
(to be realized in their turn during tactical genera- 
tion). After passing this TS to the tactical genera- 
tor, we might obtain the. following OUtlmt2: 
The FDA bans Elixir since it contains gesto.- 
dene; however, the FDA approves ElixirPlus. 
Part of the interest of the prol)lem is that RS and 
TS are not always isomorphic; this will be illustrated 
later by an alternative TS realizing figure 1 (figure 
6b). 
Our goal in ICONOCLAST has  been to explore the 
huge variety of ways in which an RS can be con- 
veyed, noting stylistic reasons why one version might 
be preferred to another, with the eventual aim of 
providing a system in which the user enjoys fine- 
grained control over style as well as content. These 
requirements ('anllot be met by a text structurer 
~q'he content of  the examples i  of course fictional. 
642 
senlcnce 
text-clause text-clause 
Icxl-phrase lexl-phrast~ lexl-phl as? tcxl -phnlse 
I,aa(i~la. elixir) / ~ "1 ........ '?1" el,Ill o ve(lila, elixil-llhls) 
Iexl-phrase texl-phlase 
"since" conlain(elixir, geslodene) 
Figure 2: Text structure 
that  merely returns one or two sat isfactory solu- 
tions, relying I)erhaps on a l ibrary of schemas. We 
need a method for enulnerat ing all the candidate so- 
lutions that  (:an be coinl)osed f ro ln  a given set of 
text-categories.  By a 'candi( late'  we mean a solu- 
tion that  correct ly realizes the RS without violat ing 
text -st ructure format ion rules; it may nevertheless 
be styl ist ical ly inel)t. Having generated a set of can- 
d idate text; structures,  the ICONO(ILAST system eval- 
uates them through rules that detect styl ist ic tlaws, 
and on this basis re:ranges them in an order of prefer- 
en(:e. We will discuss styl istic evaluation brMly, but 
the focus of the paper  is the 1)roblem of enum(;rating 
solutions. 
2 Format ion  rules 
A text structur( '  is defined in ICONOCI,AST as all or- 
dered tree ill which each node has a text-t 'ategory 
('O:ml)rising two t~atur(,s named TI,;X'I'-I,I,;VEI, and IN- 
I)ENTATION. Vahtes  of  TEXT-I,EVI,;I~ are  tel)resented 
by inl;egers in the range 0..LMo:,,; these~ may lie in- 
terl)rete.d in various ways, l int w(! will assttllle here 
that  LMa, = 4 aim that integers are t)aired with 
descriptive labels as follows: 
0 t(;xt-i)hrase 
1 text-c lause 
2 text-sentence 
3 t laragraph 
4 section 
The meanings of 'section' and :paragral)h'  are the 
usual ones, excellt that  section tit les are ignored: a 
section is simt)ly a sequence of one or more I)ara- 
graphs. Fol lowing Nunberg (1990), : text-sentenee'  
denotes a unit normal ly  Imnetuated with a capital  
letter and a flfll stop; this is dist inguished froin the 
syntact ic concept of 'senten('e', which depends on 
syntact ic format ion rules. Thus the following para-  
graph consists of three text-sentences which contain, 
respectively, one, zero, and two syntact ic  sentences: 
He entered the room. l)isaster. The safe was 
ol)en and the money had gone. 
A (;ext-clause is a unit that  would nornmlly be Imne- 
tuated with a semicolon; the text-sentence you are 
now reading contains two text-clauses, but  tile see- 
end semicolon does not appear  because it has been 
'absorbed'  into the flfl l-stop that  marks the whole 
text-sentence. Wil;hin a text-clause, hierarchy is de- 
termined by syntax rather  than text-structm'e,  so all 
units within a text-c lause are assigned the minimal  
TI~XT-LF, VEI~ of  zero.  
The tmrt)ose of INDENTATION is to allow indented 
text structures like lmlteted lists; the feature takes 
values in the range 0, 1, 2 . . . ,  where unindented 
text has  INDI,~NTATION ~ ()~ 
? a list i tem has INI)ENTATION = l 
? a list i tem within a list i tem has 1NI)ENTA- 
TION ---~ 2 
and so forth. To siml)lit~y the presentat ion,  we will 
assume for now that  all nodes have INI)ENTAT1ON = 
0, so that  text-categories are dist inguished only by 
TI~XT-I,EVEI,. 
intormally,  a text structure is well-formed if it re- 
sl)ects the hierarchy of textual  evels, so that  sections 
are coml/osed of paragraphs,  i )aragraphs of text- 
sentences ,  atl(l so forth. An examt)le of all i l l -formed 
stru(:ture would be one in which a text-sentence, con- 
tained a paragrat)h; such a structure can occur only 
when the. paragrat)h is indented - - a possibi l i ty we 
are excluding here. Formally, the text -structure tbr- 
mat ion rules are as follows: 
1. A text structure is an ordered tree in which 
each node i has a TEX'F-LENq~,I, Li iIl the range 
O..LMox. 
2. If a node p has a ( laughter node d, then p must 
have  a 'I'EXT-IA,;Xfl.;L Olle ral lk higher than d, un- 
less t)oth no(les have the minimal  level 0. In 
other words, either 
(a) L v=L , ;+ l ,o r  
(b) L v = Ld = 0 
(From this it follows that  any nodes that  are 
sisters must have the stone level.) 
3. All terminal  nodes must have tilt: minimal  
TIqXT-LEVEI, o f  0. 
In most al)l)l ications it would also inake sense to set 
a lower l imit on the root node. For instance, we 
might at)I)ly the constraint  L,?.oot _> 2 to ensure that  
the whole text is at least a text-sentence. 
3 Compat ib i l i ty  
As well as being a welM'ormed text  structure,  a can- 
d idate solution must realize a rhetorical  structure 
'correct ly ' ,  in a sense that  we need to mak(: precise. 
Roughly, a correct solution should satist~y three coil- 
ditions: 
643 
1. The terminal nodes of the TS should express 
all tim elementary propositions in tile RS; they 
may also contain discourse connectives express- 
ing rhetorical relations in tile RS, although for 
some relations discourse commctives are op- 
tional. 
2. The TS must respect rules of syntax when it 
combines propositions and discourse connec- 
tives within a text-clause; tbr instance, a con- 
junction such as 'but'  linking two text-phrases 
must be coordinated with tile second one. 
3. Tile TS must be structurally compatible with 
the RS. 
The first two conditions are straightforward, but 
what is meant by 'structural compatibil ity'? We 
suggest the crucial criterion should be as follows: 
any grouping of the elementary propositions 
in the  TS must also occur in the RS. In other 
words, the text-strncturer is allowed to eliminate 
groupings, but not to add any. More formally: 
? If a node in tile TS dominates terminal nodes 
expressing a set of elementary propositions, 
there nmst be a corresponding node in the RS 
dominating the same set of propositions. 
? Tile converse does not hold: for instance, an RS 
of the form R1(R2(pi,p2),p3) can be realized 
by a paragraph of three sentences, one for each 
proposition, even though this TS contains no 
node dominatillg the propositions (Pl and P2) 
that are grouped by R2. However, when this 
happens, the propositions grouped togettmr in 
the I7(S nmst remain consecutive in the TS; so- 
lutions in which Pa comes inbetween Pl and P2 
are protfibited. 
4 Generat ing  so lu t ions  
Our procedure for generating candidate solutions is 
based on a technique for formulating text structuring 
as a constTvdnt satisfaction pTvblem (CSP) (Henten- 
ryck, 1989). In general, a CSP is characterized by 
tim following elements: 
? A set of variables V1..I/'N. 
? For each variable l/i, a finite domain Di of pos- 
sible values. 
? A set of constraints on the wflues of the vari- 
ables. (For integer domains these often use 
'greater than' and 'less than'; other domains 
usually rely on 'equal' or 'unequal'.) 
A solution assigns to each variable 17/ a value fl'om 
its domain Di while respecting all constraints. De- 
pending on tile constraints, there may be multiple 
solutions, or there may be no solution at all. 
The difficulty in formulating a configuration task 
as a CSP is that we usually do not know in ad- 
vance how many variables the solution will contain. 
Problems of this kind are sometimes called dynamic 
(Deehter and Dechter, 1988), because the set of rel- 
evant variables changes as the search for a solution 
progresses. The solution in figure 2, for examl)le, 
has nine TS nodes, each bearing a TEXT-LEVEL vari- 
able; different realizations of the same RS might 
have more nodes, or fewer. However, we have found 
that all candidate solutions can be generated by as- 
signing four variables (TEXT-LEVEL, INI)ENTATION~ 
ORDER and CONNECTIVE)  to  each node of rhetori- 
cal structure, so obtaining a partial description that 
determines a unique TS. Intuitively, the idea is that 
this description should specify a subset of the nodes 
in the target TS; further nodes are then added, by a 
deterministic procedure, in order to satisfy the for- 
nlation rules and accommodate any discourse con-- 
nectives. 
cause 
ban(fda, elixir) contain(elixir, gestodene) 
(b) 
TEXT-LEVI~L = {0..4} 
ORDER = {t,2} 
cause 
TEXT-LEVEL = 3 
ban(fda, elixir) contain(elixir, gestodene) 
TEXT-LEVEL = {0..4\] 
ORDER = { 1,2 } 
Figure 3: Adding solution variables 
As an introduction to this nmthod, we will begin 
by working through a very simple example. Suppose 
that our aim is to find all TSs that realize the I{S 
in figure 3a in a paragraph, without using discourse 
connectives or indentation. 
Create solution variables 
The first step is to add TEXT-LEVEL and Oa- 
DER variables to each RS node. Since ORDER 
represents tile linear position of a text span in 
relation to its sisters, it can be omitted fi-om the 
root .  
Assign domains 
Each variable is assigned a finite domain of pos- 
sine values (figure 3b). For TEXT-LEVEI. vari- 
ables, tile donlain is O..LMax; for ORI)Ell vari- 
ables it is 1..N, where N is the number of sis- 
ters. Since we have decided that the whole text 
644 
should be a paragrat)h, we can fix the TEXT- 
I,I.~VEL Oll the root directly (assigning it the 
wflue 3). 
Apply const ra in ts  
Constraints over the solution variables are now 
applied. Informally, these are as follows: the 
root node should have a higher TEXT-LF.VEI. 
than its daughters; sister nodes should have the 
same vahms for TEXT-LIgVEL but  different val- 
ues {-'or ORDER; and since the 'cause' relation is 
not marked by a discourse connective, its argu- 
ments (the two prot)ositions) cannot be realized 
by text-t)hrases (the result would be syntacti- 
cally ill-formed) --- in otlmr words, they must 
have TI~XT-LEVEL ? 0. Collectively, these con- 
straints reduce the TEXT-LEVEL domains for tim 
terminal nodes to {1,2}. 
Enumerate  so lut ions 
The solutions can IIOW be enmnerated by com- 
puting all combinations of values that respect 
tile constraints. One example of a solution is 
shown ill figure 4a. 
Compute  eomplete  text  s t ruc tures  
For each solution, a complete TS can tie corn- 
tinted by adding any nodes that are required by 
the text-structure formation rules (figure 4b). 
cause 
TEXT-LEVEL = 3 
(a) NUCL " /~S S~'ELL ITE  
/ \ 
ban(fda, elixir) contain(elixir, gestodene) 
TEXT-LEVEL = 1 TEXT-LEVEI~ = 1 
ORI)ER = 2 ORDI{R = I 
paragraph (3) 
sentence (2) 
text-clause (1) text-clause (1) 
text-phrase (0) text-phrase (0) 
contain(elixir, gestodene) ban(fda, elixir) 
Figure 4: Completing a solution 
In this simple case there are just four solutions, 
since tile TEXT-LEVI.3I, and ORI)EI/. variables oil the 
nucleus both have the domains {1,2}, and any set- 
ting of these variables fixes the corresponding vari- 
ables on tile satellite. Here are texts that might 
result from the four solutions (L and O represent 
'FEXT-LI,3VEL and ORDER; N and S represent nucleus 
and satellite): 
LN = 1, ON = 1, Ls  = 1, Os = 2 
Elixir is banned by the FDA; it contains gesto- 
(lelle. 
LN = 1, ON = 2, Ls = 1, Os = 1 (figure 4) 
Elixir contains gestodene; it is banned by the 
FDA. 
LN = 2, ON = 1, Ls  = 2, Os  = 2 
Elixir is banned by tile FDA. It contains gesto- 
(telle. 
LN =2,  ON = 2, Ls  = 2 ,0s  = l 
Elixir contains gestodene. It is banned by the 
FDA. 
The method for including discourse connectives 
has been described elsewhere (Power et al, 1999). 
Briefly, the lexical entry for a discourse connective 
must specify its syntactic category (at present we 
cover subordinating conjunctions, coordinating con- 
junctions and conjuuctivc adverbs) and whether it is 
realized Oil the nucleus or the satellite. For example, 
the relation cause can be marked by the subordinat- 
ing conjunction 'since' (realized on tim satellite) or 
the coi\imlctive adverb 'consequently' (realized on 
the nucleus) - -  among others. The choice of dis- 
course connective strongly coustrains tile values of 
q'EXT-I~EVEL gi ld ORDI,~,R for tile arguments of tile 
relation. If cause is expressed by 'since', the argu- 
merits may occur in any order, but they must be 
text-ptlrases: 
Since Elixir contains gestodene, it is banned 
by the FDA. 
Elixir is 1)armed by the FDA since it contains 
gestodene. 
#Elixir is banne.d by the FDA; since it con- 
tains gestodene. 
#Elixir is banned by the FI)A. Since i~ con- 
tains gestodene. 
If instead cause is expressed by :cousequently', the 
satellite nulst be placed before tile nucleus, and uu- 
less tim style is very informal tile arguments hould 
have TEXT-I,I~VEI, values above texl;-t)hrase: 
Elixir contains gestodene; consequently, it is 
brained by the FDA. 
Elixir is banned by the FDA. Consequently, it 
contains gestodene. 
~Elixir is banned by the FDA, consequently 
it contains gestodene. 
5 Const ra in ts  
We now state the text-structuring constraints pre- 
cisely, including the feature CONNECTIVE but still 
onlitting INI)ENTATION. Before applying ttlese con- 
straints, finite domains are assigned to each tlS node 
i: 
TEXT-LEVEl, L i  ----- {0..LMa:~} 
OI{1)EI{ 0 i ~- {I...N} (for N sisters) 
645 
COllCeSsion 
TEXT-LEVE I~ = 4 
CONNECTIVE  = { 0, al lhough, however} 
J \ 
approve( i l ia ,  e l ix i rqf lus)  cause  
TI~XT- I~EVEL = {0..4} TEXT-LEVEL  = {0..4} 
ORDER = {1,2} ORDER = {1,2} 
CONNECTIVE  = 0 CONNECTIVE  = {0, since, consequent ly  }
NUCL)~J  ~ELL ITE  
/ \ 
ban(fda,  el ixir)  contain(el ix ir ,  gestodene)  
TEXT-LEVEL  = {0..4} TEXT-LEVEL  = {O..4} 
ORDER = {1,2} ORDER = {1,2} 
CONNECTIVE  = 0 CONNECTIVE  = 0 
Figure 5: Domain assigmnents 
CONNECTIVE Oil the node cause (figure 3a) Ci = 
{~, since, consequently}; on a proposition ode, 
Ci = 0. The value ~1 represents the option of 
using no discourse connective. 
As an example, possible domain assigmnents for fig- 
ure 1 are shown in figure 5. The constraints are as 
follows: 
Root Domination 
The TEXT-LEVEL of the root node r must exceed 
that of any daughter d. 
L v > Ld 
Parental Domination 
Tile TEXT-LEVEl, of" a parent node p Inust be 
equal to or greater than tile TIgXT-I,EVEL of any 
daughter d. 
Lp >_ Ld 
Sister  Equa l i ty  
If nodes a and b are descended from the same 
parent, they must have the same TEXT-LEVEL. 
La =- Lb 
Sister  Order 
If nodes a and b are descended fi'om the same 
parent, they must have different values of OR- 
DER. 
O~ ? O~, 
Argument Order 
If C v is a coordinating conjmlction or conjunc- 
tive adverb, the argument d (nucleus or satel- 
lite) on which the connective will be realised 
(according to its lexical entry) nmst have Od = 
2. 
Subordinating Conjunction Level 
If C v is a subordinating conjunction, any daugh- 
ter node (t (expressing an argument of the rela- 
tion) must have Ld = O. 
Conjunctive Adverb Level  
If Up is a conjunctive adverb, ally daughter node 
d (expressing an argument of the relation) must 
have Ld > 0. 
Umnarked  Level 
If a relation is unmarked (Cp = 0) any daughter 
node d (expressing an argument of the relation) 
must have Ld > 0. 
6 Complet ing  the  text  s t ruc ture  
conccssioll 
TEXT-I,EVEI, = 4 
CONNI!CTIVl i  = howovtw 
NUCI, '~S  S~A tI~,I,ITE 
J \ 
ilpprtwc( fda, elixir-plus) cause 
Tl iXT-I , l iVl ' l ,  = 2 'l'l!X'l'-I,liVlil, = 2 
OH)F,R = 2 ORIJER = 1 
CONNE(YI'IVI! = (1 CONNI!CTIVli  = consequently 
NUCI,E JSU~ ~ N~qSA (a) / ~1,11 ,I'I'E 
banIfda, elixir) contaill(?lixil, gcslodClle) 
TI~XT-I,EVI~I, = 2 Tl iXTd, l iVl i l ,  = 2 
ORDER = 2 ORI)ER = 1 
CONNliCTIVE = 0 CONNliCTIVE = 0 
(b) 
Icxt-scntcncc (2) 
I 
Icxt-chuisc ( 1 ) 
I 
lexl-phrasc ((1) 
coiliaill(clixh, gcstodollO) 
section (4) 
I paragraph (3) 
ICxt-sclltell?0 (2) t't.'xl-SCll\[Oilct~ 12) 
I I 
tcxl-clause (I) text-clause (I) 
text-phrase (0) text-phrase (0) 
"c OI}~k'q tlelll Iy . . . .  hOWCVCI" 
text-phrase (0) text-phrase (0) 
ban(fda, elixir) allprov?( fda, elixir-phls) 
Figure 6: Conlpleting the TS 
The algorit:hm for completing the TS cannot be de- 
scribed fully here, trot as an exnmple we connnent Oll 
how the solution in figure 6a yields the TS ill figure 
fib. 
? If a parent is more than one level above its 
daughters (Lp - Ld > 1), extra nodes are added 
beneath tim parent to bridge tile gap - -  hence 
the paragraph node in figure 6b. 
? If a parent has the same level as its daughters 
(Lp = Ld), the daughters are raised to replace 
tim t)arent. Thus in figure 6b, the paragraph 
has three sentences, and a rhetorical grouping 
has been left unrealized iu the TS. Of course the 
reader might infer the intended RS from other 
evidence (e.g. semantic plausibility). 
? If a terminal node i has a level above text-phrase 
(Li > 0), a chain of nodes is added to bring it 
'down to earth' (e.g. the chain below the first 
text-sentence in figure 6b). 
646 
? Discourse connectives are t)assed down to the 
text>clause ill which they should be realized. 
This is decide(l (i) by l)assing the connective to 
the aI)l)ropriate argument (nucleus or satellite), 
according to its lexical entry, and (it) by there- 
after 1)assing it; down to tile first constituent if 
the argument is complex (Power et al, 1999). 
After tactical generation, we might obtain tile fol- 
lowing (rather poor) result: 
Elixir contains gestodene. Consequently, it; is 
banned by the FDA. Itowever, the FDA ap- 
proves ElixirPhls. 
7 Style 
Having designed a procedure tha.t will generate all 
text structures meeting mininml standards of co l  
rectness, we need to at)l)ly fllrther constraints ill or- 
der to eliminate solutions that are stylistically eccen- 
tric or at least ill-suited to the l)Url)ose at hand. 
In ICONOCI,AS'I', this call be done in two ways: 
? If a stylistic (lefect is regarded as fatal, it is 
exchlded 1)y a hard constraint on the sohltion 
variables, so that TSs with tiffs defect are never 
generated. 
? If a stylistic defect is regar(ted as non-fatal (i.e. 
unwelcome trot sometimes necessary), it is 1)e- 
nalize(1, by a sot;(; constraint, during a subse- 
quent evaluation t)hase iil which the enunmrated 
solutions m'e ordered from best to worst. 
The user can iml)ose stylistic 1)retL'r(',n(:es by switch- 
ing hard constraints on/off, and also by weigllting 
soft constraints (i.e. determining the imt)ortanc(~ of 
non-fat;al (lefects). 
We cannot discuss stylistic control in detail here, 
trot we will give onb. or two examples for each type 
of constraint. 
IIARI) CONSTI{AINTS 
Mult i l ) le  text -c lauses :  r\[k) obtain an infornml 
style without semicolons, senten('es c(mtaining 
more than one text-clause (:all l)e avoided by 
ilnt)osing the constraint Li ? 1 on all nodes i. 
Nuelens-satellite order :  For some rhetorical re- 
lations it in W l)e al)l)ropriate to fix the linear 
order of nucleus and satellite; for instmme, the 
satellite of a background relation shoul(1 pre- 
cede the nucleus. This Call 1)C ensured by a 
constraint Os = 1. on the satellite node S. 
SOFT CONSTRAINTS 
Rhetor iea l  g roup ing :  Failure to exl)ress a rhetor- 
ical grout)tag can be treated as a defect. (This 
is one reason why the TS ill figure 6b is poor.) 
Oversimple paragraph: A paragraph c(mtaining 
only one text-sentence can lxe treated as a tie- 
feet. 
8 Extens ions  
Our method allows an exhaustive mnneration of so- 
lutions, but only within an elenmntary ti'a.nmwork tbr 
representing rhetorical and textual structure. We 
hot)e to gradually extend this frmnework to cover 
many phenonmna that are currently excluded: 
? Since its inlmt takes the form of a rhetorical 
structure tree, the text; strueturer inherits ally 
limitations of RST as a description of rhetorical 
organization. 
? We cover only three types of discourse commc- 
tive (subordillating conjmmtion, coordinating 
conjunction, conjuctive adverb). 
? At present here is no treatment of titles. 
? There is no treatment of relative clauses, which 
(:all be elnt)loyed for exami)le to realize the 
e laborat ion  relation (Scott; and de Souza, 
1990): 
Zovirax, which contains the antiviral 
agent aciclovir, is a smooth white cretan. 
? There is no treatinent of propositions that are 
expressed parenthetically. 
Zovirax, since it; is for you only, should 
never be given to other l)atients. 
Zovirax should never be given to other 
pall(mrs (the medicine is for you only). 
? We have omitted the colou-expansion pat- 
tern (Nunl)erg, 1.990) and some other features 
inthleneing i)unctuation (emi)hasis , quotation 
marks, parentheses). 
? We have not covered the integration of text with 
tloating items like diagrams, tal)les, or boxes. 
Two extensions that have already been iml)lemented 
are indentation and centering. We have exl)lained 
here how indentation is represented in text struc- 
ture; the relevant constraints will be described else- 
where. Centering has been incorporated by assign- 
ing backward and forward centers to all 1)rot)ositions 
ill a comt)leted TS bcforc generating the wording; 
in this way, centering transitions can be evahlated 
before tactical generation begins, and TSs yielding 
good c(mtimlity of reference can be i)referred (Kibble 
aud Power, 1999). 
To use our approach ill 1)ractical applications, one 
must address the 1)roblem that the number of eandi- 
(late solutions increases exi)onentially with the con> 
plexity of the rhetorical structure --- measured, for 
exanll)le , by the mmfl)er of elementary propositions. 
lil informal trials we find that the numl)er of solu- 
tions is roughly 5 g -1  for all input with N proposi- 
tions; this means that even for a short passage con- 
taining n dozen propositions, the text t)lanner would 
lind about 50 million solutions satisfying the hard  
647 
constraints. For texts of non-trivial ength, there 
steins no alternative to sacrificing lobal ot)timality 
in the interests of efficiency. One option is to use 
a statistical optimization method such as a genetic 
algorithm (Mellish et al, 1998). In ICONOCLAST we 
have preferred a method of partial optimization i  
which the the text-structuring problem is split into 
parts, so that at each stage only a manageable part 
of the total solution is constructed. For instance, 
when planning a patient information leaflet, the se- 
mantic material could first be distributed among sec- 
tions, then perhaps among t)aragraphs, thus spawn- 
ing many small-scale text-structuring problems for 
which the search spaces would be measured in hun- 
dreds rather than billions. 
References  
A. Dechter and R. Dechter. 1988. Belief mainte- 
nance in dynamic constraint networks. In Pro- 
ceedings of NCAI-AAAI. American Association 
for Artificial Intelligence. 
P. Van Hentenryck. 1989. Constraint Satisfaction 
in Logic Programming. MIT Press, Cambridge, 
Mass. 
E. Hovy. 1993. Automatic discourse generation us- 
ing discourse structure relations. Artificial Intel- 
ligence, 63:341-386. 
R. Kibble and R. Power. 1999. Using centering the- 
ory to plan coherent exts. In Proceedings of the 
12th Amsterdam Colloquium. Institute for Logic, 
Language and Computation, University of Ams- 
terdam. 
W. Mann and S. Thompson. 1988. Rhetorical struc- 
ture theory: towards a functional theory of text 
organization. Text, 8(3):243-281. 
D. Marcu. 1996. Building up rhetorical structure 
trees. In Proceedings of AAAI-96. American As- 
sociation for Artificial Inmlligence. 
C. Mellish, A. Knott, J. Oberlander, and 
M. O'Donnell. 1998. Experiments using stochas- 
tic search for text planning. In Prvcecdings of 
IWNLG-98, Niagara-on-the-Lake, Canada. Asso- 
ciation for Comtmtational Linguistics. 
G. Nunberg. 1990. The Linguistics of Punctuation. 
CSLI, Stanford, USA. 
R. Power, C. Doran, and D. Scott. 1999. Generat- 
ing embedded iscourse markers from rhetorical 
structure. In Proceedings of the European Work- 
shop on Natural Languagc Generation, pages 30- 
38, Toulouse, France. 
D. Rosner and M. Stede. 1992. Customizing RST 
for the automatic production of technical manu- 
als. In R. Dale, C. Mellish, and M. Zock, editors, 
Aspects of Automatic Natural Language Genera- 
tion, Levico, Italy. 
D. Scott and C. de Souza. 1990. Getting the mes- 
sage across in RST-based text generation. In 
R. Dale, C. Mellish, and M. Zock, editors, Current 
Research in Natural Language Generation. Cogni- 
tive Science Series, Academic Press. 
648 
203
204
205
206
c? 2003 Association for Computational Linguistics
Document Structure
Richard Power? Donia Scott?
University of Brighton University of Brighton
Nadjet Bouayad-Agha?
University Pompeu Fabra
We argue the case for abstract document structure as a separate descriptive level in the anal-
ysis and generation of written texts. The purpose of this representation is to mediate between the
message of a text (i.e., its discourse structure) and its physical presentation (i.e., its organization
into graphical constituents like sections, paragraphs, sentences, bulleted lists, figures, and foot-
notes). Abstract document structure can be seen as an extension of Nunberg?s ?text-grammar?;
it is also closely related to ?logical? markup in languages like HTML and LaTEX. We show that
by using this intermediate representation, several subtasks in language generation and language
understanding can be defined more cleanly.
1. Introduction
When language is written, it appears as a collection of words set out on one or more
(actual or virtual) pages. In fact, much of what we tend to call ?text? has a strong
graphical component (Schriver 1997; Scott and Power 2001). Not only are the words
often accompanied by conventional graphics such as pictures or diagrams, but they
themselves form graphical elements such as titles, headings, chapters, sections, cap-
tions, paragraphs, and bulleted lists.
The overlay of graphics on text is in many ways equivalent to the overlay of
prosody on speech. Just as all speech has prosody (even if it is a monotone), so too do
all texts have layout (even if it is simple wrapped format, in a single face and font, and
makes rudimentary use of white space). And just as prosody undoubtedly contributes
to the meaning of utterances, so too does a text?s graphical presentation contribute to its
meaning. However, although there is a long tradition and rich linguistic framework for
describing and representing speech prosody (e.g., Halliday 1967; Chomsky and Halle
1968; Crystal 1969; Bolinger 1972; Pierrehumbert 1980; ?t Hart, Collier, and Cohen 1990;
Ladd 1996), the same is not true for text layout. Perhaps not surprisingly, therefore, few
natural language understanding (NLU) systems use graphical presentational features
to aid interpretation, and few natural language generation (NLG) systems attempt to
render the output texts in a principled way.
Of course, since all texts have a graphical dimension, all NLG systems will, by
definition, produce laid-out texts. In all but a few recent cases (the ICONOCLAST sys-
tem (Power 2000; Bouayad-Agha, Power, and Scott 2000; Bouayad-Agha, Scott, and
Power 2001; Bouayad-Agha 2001) and the DArtbio system (Bateman et al 2001)), this
is achieved by mapping directly from the underlying discourse structure (Arens and
? Information Technology Research Institute, University of Brighton, Lewes Road, Brighton BN2 4GJ,
UK. Email: {firstname.lastname}@itri.bton.ac.uk.
? Departament de Tecnologia, University Pompeu Fabra, Barcelona, Spain. Email: Nadjet.Bouayad@
tecm.upf.es.
212
Computational Linguistics Volume 29, Number 2
Hovy 1990; DiMarco et al 1995; Paris et al 1995; Power and Cavallotto 1996; Lavoie
and Rambow 1997; Mittal et al 1998). In other cases, the text is mapped onto pre-
determined genre-specific layout patterns?for example, for verbalizing mathematical
proofs (Huang and Fiedler 1997) or producing letters for customers (Coch 1996). If we
take, as most do, the level of discourse structure as representative of the underlying
message of a text, such systems are subject to a fundamental limitation. Simply put, for
each message there will be but one possible form of presentation.
As an illustration let us briefly consider the well-known consensus architecture
for NLG systems proposed by Reiter (1994). This architecture, based on a survey
of NLG systems from the 1980s and early 1990s, takes the form of a ?pipeline? in
which five modules are applied in sequence: content determination, sentence planning,
surface generation, morphology, and formatting. Sentence planning maps ?conceptual
structures into linguistic ones . . . grouping information into clauses and sentences?
(Reiter 1994, page 164), but formatting (specified, for example, by LaTEX markup) occurs
only in the final formatting stage. In consequence, the organization of material into
paragraphs, bulleted lists, etc., is considered only after the wording has been fixed.
Graphical presentation, however, clearly interacts with wording. For example, the
section of a message that, at the level of discourse, is composed of a list relation,
will be expressed differently depending on whether, at the presentational level, it is
mapped onto a vertical or horizontal list. Consider a simple example like the following,
taken from a patient information leaflet (PIL):
(1) Are you taking any of the following:
? Anticoagulants?
? Lithium?
? Methotrexate?
? Any other medicines which your doctor does not know about?
(Voltarol leaflet, Geigy; from APBI 1997)
If the very same content were presented instead as a horizontal list, we would expect
to get something like:
(2) Are you taking anticoagulants, lithium, methotrexate, or any other medicines which
your doctor does not know about?
Now all the information is packed into one sentence, with some missing and addi-
tional words, wildly different punctuation, and less generous use of upper-case letters.1
Mapping directly from discourse structure to graphical presentation during generation
therefore limits not only the choice of possible layout, but also the choice of possible
wording.
There have been some recent attempts to develop NLG systems that generate doc-
uments rather than just texts. Instead of producing text plans, they produce document
plans. Typically these are the text plans of old (i.e., structures of ordered content ele-
ments represented in terms of rhetorical structure theory (Mann and Thompson 1986,
1987)), but extended to include pictures or diagrams as content elements, and with
additional annotations for metalevel elements such as paragraph or sentence bound-
aries. Figure 1 shows the type of document plan proposed by Reiter and Dale (2000).
1 Indeed, it appears to be the case that the more graphical the presentation is, the greater the difference
in wording is likely to be over the unmarked case of plain text (Bouayad-Agha, Scott, and Power 2000).
213
Power, Scott, and Bouayad-Agha Document Structure
still very depleted.  Heavy rain fell on the 27th and 28th.
The month was slightly warmer than average with almost exactly the average rainfall, but rainfall for the year is 
Weather Summary for July 1996
DocumentPlan 
Relation = Sequence
Document Plan
Relation = NarrativeSequence
RainEventMsg
     [28th]
DocumentPlan
Relation = Contrast
DPDocument
Title = "Weather Summary for July 1996"
Relation = Sequence
RainEventMsg
     [27th]
MonthlyTemperatureMsg
MonthlyRainfallMsg TotalRainSoFarMsg
Nucleus Satellite
Figure 1
A document plan and associated text (Reiter and Dale 2000).
Although this approach allows for a more reasoned presentational format, by conflat-
ing discourse and presentational features into one structure, the possible generated
expressions of any given message are once again strongly limited relative to the set of
all possible valid expressions.
We wish to argue the case for a separate descriptive level in the analysis and gen-
eration of written texts, which we will call document structure. Informally, document
structure describes the organization of a document into graphical constituents like
sections, paragraphs, sentences, bulleted lists, and figures; it also covers some features
within sentences, including quotation and emphasis. Although document structure
applies equally to NLU and NLG, we will focus our attention here on its role in the
generation of appropriate presentations (both wording and layout) of texts. As we will
try to show, texts (unless they are fairly simple) cannot be produced to a satisfactory
standard unless document structure is specified earlier in the process than suggested
in previous works (e.g., Reiter 1994; Reiter and Dale 2000), so that interactions with
meaning and wording are taken into account.
The plan of the article is as follows. In section 2 we explain more fully what we
mean by document structure, acknowledging its origins in Nunberg?s (1990) work and
text markup languages such as LaTEX and HTML. Section 3 discusses the relationship
of document structure to rhetorical organization and syntax. Section 4 presents the
formal theory of document structure, and Section 5 shows how it is applied in the
ICONOCLAST system. Finally, Section 6 summarizes the argument and discusses some
other approaches to the representation and generation of layout.
214
Computational Linguistics Volume 29, Number 2
2. Defining Document Structure
2.1 Nunberg?s Text Grammar
Our point of departure has been the theory of text structure proposed by Nunberg
(1990) in The Linguistics of Punctuation. This book introduces two crucial clarifications.
First, it distinguishes text structure,2 which is realized by punctuation and layout, from
syntactic structure. Second, it distinguishes abstract features of text structure from the
concrete (or graphical) features through which they are expressed.
The distinction between text structure and syntax can best be explained by consid-
ering two interpretations of the word sentence. In linguistics, sentence is used mainly as
a syntactic category, defined by phrase structure rules such as S ? NP+VP. However,
a sentence can also be viewed orthographically as a portion of text starting with a
capital letter and ending in a period; to distinguish this from the syntactic category,
Nunberg calls it a text-sentence. Sometimes the two categories of sentence coincide,
but often they do not. Thus in the following passage:
(3) He entered the office. Disaster. The safe was open and the money had gone.
the first text-sentence is also a syntactic sentence, but the second is merely a noun,
and the third comprises two syntactic sentences (or three, if we count the whole as
well as its parts). Nunberg argues that if we have two kinds of category, then we need
two kinds of grammar: he calls them the lexical grammar (we prefer syntactic gram-
mar) and the text-grammar. In addition to text-sentence, the text-categories include
text-clause, paragraph, and section, and the text-grammar allows us to formulate con-
stituent structure rules such as
St ? Ct+
meaning that a text-sentence comprises one or more text-clauses.
In introducing the concepts text-sentence, text-clause, etc., it is convenient to explain
them in terms of their realization in punctuation and layout: thus a text-sentence
starts with a capital letter and ends in a period; a text-clause ends in a semicolon;
a paragraph begins on a new line with a tab. However, this is not strictly correct.
In Nunberg?s theory, these concepts represent abstract structural properties of the text
that may be realized differently according to context or convention. In the case of
paragraph this distinction is obvious, since we are all familiar with several devices for
expressing paragraph boundaries: instead of a new line with a tab, for example, an
editor might prefer two new lines (or some other vertical space) with no tab. However,
the abstract/concrete distinction also applies to the other text-categories. For example,
the passage:
(4) The safe was open; the money had gone.
contains two text-clauses, but the second has no semicolon because its ending coincides
with the closure of a larger unit, a text-sentence, which is marked by a period. Similarly,
the stop at the end of a text-sentence is often dropped when the sentence is an item
2 This should not be confused with the use of this term within the NLG literature to refer to the
discourse structure of a text.
215
Power, Scott, and Bouayad-Agha Document Structure
in a vertical list, for instance, in a sequence of instructions:
(5) To save the file:
1. Open the Save dialogue-box
2. Enter the filename
3. Click on the Save button
Thus text structure is realized by punctuation (and layout), but the two are not equiv-
alent.
2.2 Markup Languages
Nunberg?s notion of text structure, or our wider notion of document structure, has an
obvious connection to the markup languages (e.g., LaTEX, SGML) now in common use
as a method for specifying layout in an ASCII source file. The common philosophy
of these languages is that markup should abstract from the visual appearance of the
document, using concepts like paragraph that might be realized graphically in different
ways, depending on a separate style definition.
This approach has several advantages, of which the most obvious is flexibility.
An exact specification of the desired spatial layout can yield only one printed form
of the document; by employing abstract categories, definitions using LaTEX or SGML
can produce a range of printed forms, depending on which style file is used. Less
obviously, the markup language can be tailored to the genre of the document, so that,
for example, a poem may have a constituent marked stanza, whereas a letter may have
one marked address.
In practice, this separation of abstract structure from visual realization is not car-
ried through consistently; for reasons of convenience, authors sometimes prefer to
have direct control over appearance. Thus LaTEX, for example, allows both the abstract
tag em, meaning emphasis, and the visual tag it, meaning italic face. Vertical separation
is usually achieved through abstract tags like section and itemize but may also be
imposed directly using vspace. All these devices have counterparts in HTML: thus
a typical reference guide to HTML (Ford and Dixon 1996) explicitly distinguishes
?logical? tags such as <EM> from ?visual? tags such as <I>.
More subtly, the markup languages in common use do not attempt to cover struc-
tural units that are realized through punctuation rather than layout. Paragraphs may
be marked (albeit implicitly in LaTEX), but lower units such as text-sentence and text-
clause are not. No doubt there are good practical reasons for this approach, but some
opportunities for stylistic variation are thereby lost. Consider, for example, the simple
case of reported speech in example (6a). If this were marked up as a sentence contain-
ing a quotation, it could be punctuated differently, with the period outside the closing
quotation mark (6b), perhaps, or using double quote (6c), or even using a dash with
no quotation marks at all (6d) (as in James Joyce?s Ulysses):
(6)
(a) She said ?Come up and see me sometime.?
(b) She said ?Come up and see me sometime?.
(c) She said ?Come up and see me sometime.?
(d) She said?Come up and see me sometime.
Thus although markup languages provide some guidance toward a formal treat-
ment of document structure, they often deviate, for practical reasons, from the philo-
sophical ideal of separating abstract structure from visual presentation. On the one
216
Computational Linguistics Volume 29, Number 2
hand, some tags (e.g., italic face) are clearly visual and should not be included in
abstract document structure at all. On the other hand, some abstract categories (e.g.,
text-sentence, quoted speech) are omitted from the tag set and thus cannot be realized
in a range of different graphical styles.
Despite these compromises, markup languages are based on a key insight that is
highly relevant to natural language analysis and generation: layout can be matched to
wording through the mediation of abstract document structure. Consider the following three
versions of a passage adapted from a patient information leaflet:
(7)
(a) Elixir is a white cream.
It is used in the treatment of cold sores.
It contains aliprosan. This is effective against a range of viral skin disorders.
It should be used only on your lips and face.
(b) Elixir is a white cream.
It is used in the treatment of cold sores.
It contains aliprosan. This is effective against a range of viral skin disorders.
It should be used only on your lips and face.
(c) Elixir is a white cream. It is used in the treatment of cold sores. It contains aliprosan.
This is effective against a range of viral skin disorders. N.B. Elixir should be used only
on your lips and face.
Suppose that example (7a) has been produced by author A, a novice in document
design, and passed to a more experienced designer B for revision. The passage looks
odd because it has four very short paragraphs, but short paragraphs are common
in this genre, and B decides that the ugly appearance can be corrected simply by
realizing paragraphs through a vertical space with no tab. In addition, B notices that
boldface has been used for two different purposes: highlighting the product name
and emphasizing only; this ambiguity is removed by changing emphatic boldface to
small caps. Both these revisions, shown in version (7b), concern realization rather than
abstract structure, and consequently they do not affect the validity of the wording.
For final checking the passage is then passed to a senior expert C, whose prefer-
ences are more traditional: in particular, C dislikes short paragraphs and variations
in typeface. Glaring at the waste of space in version (7b), C takes out the paragraph
boundaries and removes the emphasis on only. These are not merely changes in graph-
ical realization: they also affect the abstract document structure. In general, such changes
endanger the validity of the wording. Reading through the new version, C notices that the
pronoun it in the final sentence now seems to refer to aliprosan, not Elixir, so it has
to be replaced by the product name. To reinstate the emphasis in this sentence, C also
inserts the expression N.B. These changes lead to version (7c).
In summary, abstract document structure interacts with wording, whereas visual
realization does not. This principle explains why abstract markup is useful; it also
shows where the boundary should be drawn. By applying this principle, we might
discover that a category previously treated as visual should be reclassified as abstract.
If, for example, the change in the realization of paragraph boundaries in examples
like version (7b) required a rewording of the text, we would have to extend our set
of abstract document categories so that there were two types of paragraph instead of
one.
217
Power, Scott, and Bouayad-Agha Document Structure
3. Document Structure and Rhetorical Structure
3.1 Form and Meaning
Logically there are four possible relationships between document structure (DS) and
rhetorical structure (RS): either DS is part of RS, or RS is part of DS, or they partially
overlap, or they are distinct from one another. Our view is that they should be distinct,
just as syntax is distinct from semantics. Document structure, like syntax, describes
the form of a (mainly) linguistic product. Rhetorical structure, like semantics, describes
meaning, interpreting meaning in a broad sense that includes pragmatic features.
As an example, suppose that approve(fda, elixir) is a semantic formula meaning that
the Food and Drug Administration (FDA) approves the medicine Elixir. This semantic
formula can be realized (in English) through a range of syntactic forms, including
[S [NP [DET the][N FDA]][VP [V approves][NP Elixir]]]
which would yield ?the FDA approves Elixir?; alternative syntactic forms could be
obtained by replacing descriptions with pronouns, or by putting the whole sentence
into the passive (e.g., ?it is approved by the FDA?). Now, suppose that we add a
second semantic formula contain(elixir, gestodene), and suppose that the author knows
that gestodene is a controversial ingredient. On this basis, a rhetorical relation of
concession might be applied to the two formulas:
concession(contain(elixir, gestodone), approve(fda, elixir))
where the second argument of concession is the central one and is supported by the
first argument.3 To realize this more complex message, we may need a linguistic form
that cannot be described only by a syntactic phrase marker. In other words, we need
to consider document structure as well as syntax. Ignoring possibilities for variations
in the wording of the constituent propositions and assuming that concession may be
marked with the discourse connectives although and however, we can choose among
the following realizations of the whole message:
(8)
(a) Although Elixir contains gestodene, it is approved by the FDA.
(b) The FDA approves Elixir although it contains gestodene.
(c) Elixir contains gestodene; however, it is approved by the FDA.
(d) Elixir contains gestodene. However, it is approved by the FDA.
(e) Elixir contains gestodene.
However, it is approved by the FDA.
In versions (8a) and (8b), the rhetorical relationship is realized within a single
syntactic sentence, although before adding punctuation we need to know that this
syntactic sentence is also a text-sentence. In versions (8c)?(8e), the arguments of the
concession relation are expressed in separate syntactic sentences, so that the rela-
tionship is realized through document structure as well as syntax. In each case, the
3 These are termed nucleus and satellite in RST (Mann and Thompson 1987).
218
Computational Linguistics Volume 29, Number 2
units realizing the arguments are coordinated in document structure, satellite precedes
nucleus, and the discourse connective however is placed within the nucleus.
Our claim, then, is that document structure combines with syntax in the real-
ization of the meaning of a document, and that rhetorical structure should be re-
garded as part of meaning, not part of document structure. However, as we will now
show, this principle of clear separation of meaning and form has not always been
observed.
3.2 Rhetorical Structure Theory
Rhetorical structure theory (Mann and Thompson 1986, 1987) was developed as a
method of analyzing the rhetorical organization of texts. Formally, the theory is re-
markably simple. It proposes that a text can be analyzed, by rhetorical function, into
a set of nested spans, each span being represented by a node on an ordered tree. Each
nonterminal node on this tree is labeled with a single term describing the relationship
that holds among its constituents. These constituents may have equal importance, in
which case the relation is said to be multinuclear, or one may be rhetorically subor-
dinated to the other, in which case they are said to fulfill the roles of satellite and
nucleus. Although this scheme is obviously intended as a first approximation, it has
been widely adopted, not only by literary analysts, but also by computational linguists,
especially in the NLG community.
One aspect of RST, perhaps more presentational than substantial, has led, in our
view, to confusion: both in the text of their article and the accompanying diagrams,
Mann and Thompson seem to assert that rhetorical relations hold between spans of
text, rather than between the meanings of these texts. In other words, they treat rhetor-
ical structure as part of document structure. Mann and Thompson assert this explicitly
(1987, page 4):
Relations are defined to hold between two non-overlapping text spans,
here called the nucleus and the satellite, denoted by N and S.
where
A text span is an uninterrupted linear sequence of text.
However, it is unclear whether their claim is intentional or simply the result of an
informal style of presentation.
Would it make any sense to treat rhetorical relations as holding literally between
text spans? For clearly pragmatic relations, such as restatement, this seems a possible
position. A text span, after all, is an instrument of the writer, so it makes sense to make
a statement about the function that the instrument is supposed to serve. For clearly
semantic relations, such as nonvolitional-cause, the position is harder to maintain.
In a text like ?Mary was sad because she lost her doll?, the causal relation plainly holds
between two events, not between two spans of text.
Leaving aside intuitive plausibility, the crucial question, we think, is whether the
argument in a document can be formalized without reference to the particular text
spans through which it is realized. Could the same argument be realized by two
English texts with a different structure, or by an English text and a French text? Could
someone forget a text but remember its argument? If so, it must be possible to treat
relations like concession and nonvolitional-cause as holding between ideas rather
than units of text. Rather than creating two kinds of rhetorical relation, it seems more
parsimonious to treat the relation between ideas as primary, so that the argument of
219
Power, Scott, and Bouayad-Agha Document Structure
concession
NUCLEUSSATELLITE
however, it is approved by the FDA.Elixir contains gestodene; 
concession
The FDA approves Elixir although it contains gestodene.
NUCLEUS SATELLITE
(8c)
(8b)
Figure 2
RST analysis.
a document can be planned before the writer (or NLG system) has considered issues
of wording or linear order.4
To illustrate this point, let us go back to example (8). Suppose that we want to
show that versions (8b) and (8c) express the same argument.
(8b) The FDA approves Elixir although it contains gestodene.
(8c) Elixir contains gestodene; however, it is approved by the FDA.
Figure 2 shows RST annotations for these texts, on the assumption that rhetorical
relations hold between text spans; note, incidentally, that since related spans must
be consecutive, the discourse connectives although and however have to be included
somewhat arbitrarily in one span or the other. These annotations fail to bring out that
the two texts express the same argument, since at a textual level the spans in (8b) and
(8c) are simply different, both in wording and position.
In Figure 3, instead, different document structures are specified for versions (8b)
and (8c) and linked to a common rhetorical structure; the dotted arrows express the
relation realizes, so that, for example, each text-sentence realizes the whole rhetori-
cal structure governed by the concession relation. Note that rhetorical structures are
always unordered, whereas document structures are ordered trees. Thus the two un-
ordered propositions in the rhetorical structure of Figure 3 are realized in different
orders in the two document structures.
This distinction between rhetorical structure and document structure accounts for
some of the difficulties encountered when RST is applied as an analytic tool. The
core of the problem is that when faced with a text to analyze, the analyst applies the
principles of RST analysis to the text itself rather than to the message underlying the
text. What the analyst really needs to do is, in some way, to ?get behind the text?
to its constituent propositions and the rhetorical relations that hold between them
(Scott and Paris 1995). But instead, by applying relations to text-spans, he or she is
heavily constrained by the evident document structure of the text, and the result is a
rhetorical structure that is isomorphic to the document structure. However, as we have
4 This proposal was first made by Scott and Souza (1990).
220
Computational Linguistics Volume 29, Number 2
TEXT?SENTENCE
TEXT?PHRASE TEXT?PHRASE
TEXT?PHRASE
although
Elixir is approved by the FDA
it contains gestodene
TEXT?PHRASE
TEXT?SENTENCE
TEXT?CLAUSE TEXT?CLAUSE
Elixir contains gestodene
TEXT?PHRASE TEXT?PHRASE
however it is approved by the FDA
approve(fda, elixir) contain(elixir, gestodene)
SATELLITE
concession
NUCLEUS
RHETORICAL STRUCTURE DOCUMENT STRUCTURE (8c)DOCUMENT STRUCTURE (8b)
Figure 3
Document structure realizes rhetorical structure.
seen from the above example, the underlying rhetorical structure is not necessarily
isomorphic to the document structure;5 this means that the analysis obtained in this
way is not necessarily an accurate representation of the actual discourse structure
of the text. Consider, for example, the following excerpt from a patient information
leaflet:
(9) IF you find your condition gets worse during treatmentA you may be allergic to the
creamD or have a skin infectionE.
STOP USING THE CREAMB AND TELL YOUR DOCTOR AS SOON AS POSSIBLEC
(Betnovate leaflet, Glaxo; from APBI 1997)
Careful reading of the text, combined with world knowledge, suggests that the
following logical condition holds between the propositional content of A and the pair
B and C:
IF <condition of patient worsens during treatment>
THEN <patient must stop taking cream>
AND <patient must tell patient?s doctor>
ENDIF
In other words, the rhetorical relation of condition holds between A as satellite and
the complex of B and C (joined by a list relation) as nucleus. We learn additionally
that the reason why the patient must carry out the imperative actions of B and C is
that he or she may be either allergic to the cream (D) or have a skin infection (E). In
other words, there is a causal relation between the complex of B and C (the effect) and
complex of D and E (the cause). Representing all this in RST would yield the structure
in Figure 4.
Most people would probably agree that what is depicted in the RST structure
shown in Figure 4 captures the intended meaning of the text in the example, and that
the text itself is of reasonable quality. However, a traditional RST analysis (i.e., of the
text itself, as opposed to its underlying meaning) would not be able to produce the
structure shown here. To explicate, let us go through what the typical RST analyst
would do with this text.
The analyst would probably start by segmenting the text into elementary ?text
spans? (i.e., clauses); this would lead to the same assignment of A?E given above. The
next step would focus on the first sentence: the discourse marker if clearly suggests
the condition relation; similarly, the marker or suggests the alternative relation.
So far so good. However, the next step would be to find a relation that holds among
5 This is discussed in more detail in Bouayad-Agha, Power, and Scott (2000) and Bouayad-Agha (2001)
and in section 5.3.
221
Power, Scott, and Bouayad-Agha Document Structure
PARAGRAPH
TEXT?SENTENCE
TEXT?PHRASETEXT?PHRASE TEXT?PHRASE TEXT?PHRASE
TEXT?PHRASE
TEXT?SENTENCE
D E
B
CA
D EC
list alternative
cause
condition
A
B
SN
N S
RHETORICAL STRUCTURE DOCUMENT STRUCTURE
Figure 4
Document structure is not always isomorphic with rhetorical structure.
SN
list
N
N N NN
C D E
A
B
alternative
condition
S
result
Figure 5
Analysis when RST is applied directly to text.
the text spans in the sentence; if this cannot be done, then according to the tenets of
RST, the text is not coherent. Following this rule, the analyst is likely to make D and E
the components of the identified (multinuclear) alternative relation. Next he would
attempt to assign the satellite and nucleus of the identified condition relation; the
choice would be between A and the complex of D and E. Since the marker if must
attach to the satellite of condition, the answer seems clear:
condition(alternative(D,E),A)
(corresponding to the RST structure shown in Figure 5). But it is also clearly wrong,
since we know from our semantic analysis that what really holds is that shown in
Figure 4:
condition(list(B,C),A)
Indeed, even the layout of the text reinforces, through the use of capital letters, the
strong relationship between A and the pair B and C.
In principle, an RST structure that is derived from the analysis of a given text
should, when used as the input to an NLG system, produce the very same text and
other semantically equivalent versions of it. By separating rhetorical structure from doc-
ument structure, we can now provide a coherent framework for achieving this result.
222
Computational Linguistics Volume 29, Number 2
For instance, we can now produce not only the original text of example (9) (shown
here with neutral layout):
(9b) If you find your condition gets worse during treatment, you may be
allergic to the cream or have a skin infection. Stop using the cream and
tell your doctor as soon as possible.
but also the following (in some contexts perhaps better) variant
(9c) If you find your condition gets worse during treatment, stop using the
cream and tell your doctor as soon as possible; you may be allergic to
the cream or have a skin infection.
Of course, NLG systems that ignore the level of document structure would still be able
to produce the text in version (9b) from the RST structure in Figure 5, but they would
not be able to produce version (9c). Moreover, they could also end up producing the
following incorrect text:6
(9c) # Stop using the cream and tell your doctor as soon as possible because
you may be allergic to the cream or have a skin infection if your
condition gets worse during treatment.
A number of other researchers have identified cases in which ?orthodox? RST
analysis of a text is problematic (e.g., Moore and Pollack 1992; Moser and Moore 1996;
Knott et al 2001). For example, Knott et al (2001) report on texts from a corpus of
museum labels that violate the RST principle of continuous constituency (i.e., adjacent
units must be linked by a relation) but are nonetheless coherent. These are cases in
which the satellite of a relation is not adjacent to its own nucleus in the text. In
all the texts that Knott et al discuss, the ?dislocated? relation is elaboration, and
they attribute the source of the problem to the relation itself: elaboration is not, they
claim, a proper relation; it is a very weak relation that commands a different treatment
from the other stronger ones.
Although there may well be a strong case to be made for the ?demotion? of
elaboration and for a special treatment of it in NLG systems, the phenomenon
of dislocated satellites that Knott et al (2001) describe is not, in fact, confined to
elaboration. Indeed, it corresponds precisely to the problem we have just seen with
example (9), which involves not elaboration, but condition. We have also reported
elsewhere other similar examples of nonisomorphic rhetorical and document structures
(Bouayad-Agha, Power, and Scott 2000). In all cases that we have seen, the principles of
RST (e.g., compositionality, nuclearity, continuous constituency) appear to be violated
only because they are being applied (in the orthodox manner) to the surface text
(i.e., at the level of document structure) rather than more properly to the underlying
propositional structure of the text (i.e., at the level of rhetorical structure).
But why would one want to produce a text whose document structure is not iso-
morphic with its rhetorical structure? One rather practical reason is that as a rhetorical
structure becomes more complex, it becomes increasingly difficult for the writer to pro-
duce a text that satisfies both the demands of coherence (as defined by theories such
6 This text would result from systems that treat the leaves of a rhetorical or text plan as ordered.
223
Power, Scott, and Bouayad-Agha Document Structure
as RST) and those of syntax. This happens quite frequently, for example, with condi-
tionals: syntax dictates that expressions using the subordinating discourse marker if
must have the antecedent and consequent in the same sentence. For example:
(10) If you eat too many sweets, you will become ill.
but not
(11) # If you eat too many sweets. You will become ill.
As the consequent or its antecedent becomes more complex, the chances of satis-
fying the syntactic constraints are reduced. Here is a typical example from a PIL:
(12) If you get any of the following:
Stomach pain, indigestion, heartburn or feeling sick for the first time.
Any sign of bleeding in the stomach or intestine, for example, passing black
stools.
. . .
An unexpected change in the amount of urine produced and/or its
appearance.
STOP taking the tablets and tell your doctor.
(Voltarol leaflet, Geigy; from APBI 1997)
Here the conditional is expressed within one big sentence that itself contains several
other sentences?indeed, paragraphs?each describing a set of symptoms organized
around areas of the body. In writing this text, the author has clearly chosen to remain
faithful to the rhetorical structure at the expense of syntax.
At other times, such as the example in Figure 6, taken from Knott et al (2001), it
is the rhetorical structure that loses out. In this case, the author has decided that the
content of the satellite associated with (9) warrants its own paragraph (perhaps for
reasons to do with its size).
4. Formal Theory of Document Structure
We will describe here the formal theory of document structure that we have developed
as part of the ICONOCLAST system (Power 2000; Bouayad-Agha, Power, and Scott
2000; Bouayad-Agha 2000; Bouayad-Agha, Scott, and Power 2001), which generates
multiple versions of the same message in different styles (i.e., with different wording
and layout). In describing the theory, we will concentrate on units above the level
of text-sentence; our treatment of the lower levels varies only slightly from that in
Nunberg?s theory, which is described in great detail in Nunberg (1990).
4.1 Basic Hierarchy of Document Units
Informally it seems clear that units of document structure are ranked: sentences are
grouped into paragraphs, paragraphs into sections, sections into chapters, and so forth.
The hierarchy of categories differs from one document type to another, but there is
always some hierarchy;7 there might for instance be subsubsections and subsections
7 Exceptionally, some elements?in particular, footnotes and pictures?will be ?floating.?
224
Computational Linguistics Volume 29, Number 2
2 3 . . .
. . .
. . .< >
. . .< >
(1) In the women?s quarters the business of running the household took place.
(2) Much of the furniture was made up of chests (3) arranged vertically in matching
pairs. ... (4) Female guests were entertained in these rooms, (5) which often had
beautifully carved wooden toilet boxes (6) with fold?away mirrors and sewing
boxes, (7) and folding screens, (8) painted with birds and flowers.
(9) Chests were used for storage of clothes. ...
1
N S
DOCUMENT STRUCTURE
4 8
TEXT
PARAGRAPH
TEXT?SENTENCETEXT?SENTENCETEXT?SENTENCE
PARAGRAPH
1
N S
N N
4 8
TEXT?SENTENCE
9
3
RHETORICAL STRUCTURE
2
N S
N S
9
Figure 6
Another example of nonisomorphic rhetorical and document structures.
between paragraphs and sections. As a basis for discussion, let us assume a hierarchy
of six levels, which we will number from 0 (assumed to be the lowest possible level
of document structure) to 5:8
0 text-phrase
1 text-clause
2 text-sentence
3 paragraph
4 section
5 chapter
The fundamental organizing principle of document structure is that a unit of a
given level is composed of one or more units of the next level down. This observation
could be expressed by a set of constituent structure rules, one for each level:
chapter ? section+
section ? paragraph+ (etc.)
Alternatively, we could generalize over this set of rules by introducing the symbol LN
to denote a unit of level N (so that L0 means text-phrase, L1 means text-clause, etc.).
A single rule will now cover units of all levels:
LN ? LN?1+ (N > 0)
8 We use text-sentence and text-clause in Nunberg?s sense, as units typically marked by a period and a
semicolon. However, unlike Nunberg, we use text-phrase for any constituent of a text-clause, whether it
is marked by a comma or not.
225
Power, Scott, and Bouayad-Agha Document Structure
(a)
(b)
SECTION
PARAGRAPH PARAGRAPHTEXT?SENTENCE
PARAGRAPH PARAGRAPH
SECTION
TEXT?SENTENCE
PARAGRAPH
Figure 7
Ill-formed (a) and well-formed (b) document structures.
Two consequences of this rule should be noted. First, it disallows document struc-
tures in which a unit contains a subunit of higher level?for instance, a text-sentence
may not contain a paragraph. Second, it disallows document structures in which
coordinated units have different levels. A section, for example, may not be formed
by coordinating two paragraphs and a text-sentence, as in Figure 7(a); the sentence
should be the only constituent of a further paragraph unit, as in Figure 7(b), so
that when the abstract document structure is realized graphically, the sentence will
be formatted with a paragraph break as well as with a capital letter and a
period.
This deals with the basic organization of text into hierarchical document units;
however, a full description should take account of many other patterns including
headings, bulleted lists, footnotes, and figures. We cannot deal with all these pat-
terns here, so we focus on what is probably the most complex problem: the treat-
ment of indented structures such as quotations, bulleted lists, and enumerated
lists.
4.2 Indented Document Units
At first sight it might seem that indentation is a feature of graphical realization
rather than underlying structure: in other words, that it belongs to concrete rather
than abstract document structure. We have several reasons for rejecting this view.
First, it is at least suggestive that both LaTEX and HTML include tags for indented
structures:
Pattern HTML tag LATEX tag
Quotation <QUOTE> \begin{quote}
Bulleted list <UL> \begin{itemize}
Enumerated list <OL> \begin{enumerate}
Description list <DL> \begin{description}
Second, one can find examples of vertical lists that seem structurally equivalent to
(say) a bulleted list but are presented without item markers and without the use of
horizontal indentation. Here is a case in point, taken from a PIL with formatting exactly
226
Computational Linguistics Volume 29, Number 2
preserved:
(13) If you experience any of the following or any other unusual effects,
tell your doctor:
Poor appetite or a slight sick feeling
Mild abdominal pains or fullness
Alterations in your sense of taste
Diarrhoea
Itching or rash
Pain in your muscles or joints
If you notice yellowing of the skin or eyes, tell your doctor
straight away.
(Lamisil, Sandoz; from APBI 1997)
Third, and most important of all, indented structures may introduce apparent viola-
tions of the hierarchical ranking described in the last section: for instance, a sentence
may contain a paragraph, provided that the paragraph is indented. We have already seen
this in the case of complex conditionals in example (12). However, the phenomenon
is much more widespread:
(14) In rare cases the treatment can be prolonged for another week; however, this is risky
since
? The side-effects are likely to get worse. Some patients have reported severe
headache and nausea.
? Permanent damage to the liver might result.
(15) The opening of Pride and Prejudice
It is a truth universally acknowledged, that a single man in possession of a
good fortune, must be in want of a wife. However little known the feelings
or views of such a man may be on his first entering a neighbourhood, this
truth is so well fixed in the minds of the surrounding families, that he is
considered as the rightful property of some one or other of their daughters.
is one of the most famous paragraphs in English literature.
In these examples, too, note that the important issue is not graphical indentation, but
what we might call logical indentation. Thus in the case of the quotation, the logical
indentation of the quoted paragraph might be shown without graphical indentation
(e.g., by using a distinctive font or character size):
(16) The opening of ?Pride and Prejudice?
It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a
wife. However little known the feelings or views of such a man may be on his first entering a neighbourhood,
this truth is so well fixed in the minds of the surrounding families, that he is considered as the rightful property
of some one or other of their daughters.
is one of the most famous paragraphs in English literature.
How can the formation rules for document structure be extended so as to ac-
commodate these patterns? Our main proposal, implemented in the ICONOCLAST
document planner, is that a document unit should be defined by (at least) two fea-
tures: its level and its indentation. The level is the usual ranking from L0 (text-phrase)
227
Power, Scott, and Bouayad-Agha Document Structure
"however, this is risky since"
"In rare cases ... for another week;"
"Permanent damage ... might result.""The side effects ... and nausea."
TEXT?CLAUSE (0)
TEXT?SENTENCE (0)
TEXT?PHRASE (0) TEXT?PHRASE (0)
PARAGRAPH (1) PARAGRAPH (1)
TEXT?CLAUSE (0)
Figure 8
Indented document structure (example (14)).
to L5 (chapter) or whatever hierarchy of units the author decides to employ; the inden-
tation is a value in the range I0 . . . IMax, where I0 means that the unit is not indented at
all, I1 means it is indented one place, and so forth, with IMax representing the deepest
embedding that the author is prepared to contemplate. The passages in examples 14?16
can then be described formally as unindented text-sentences (i.e., units with the cat-
egory [L2, I0]), which have among their constituents indented paragraphs (units with
the category [L3, I1]). Such structures can be permitted if we change the basic rule of
the last section so that a unit of indentation IN always outranks a unit of indentation
IN+1, no matter what their respective levels may be. Instead of one general rule, we
now need two: the first for unindented constituents, the second for indented ones.
Unindented constituents [LN, IM] ? [LN?1, IM]+
Indented constituents [LA, IM] ? [LB, IM+1]+
In the second rule, LA and LB are unrelated, so LB could represent a higher level than
LA (e.g., a paragraph inside a text-sentence). For most document types one would
presumably prefer to set an upper limit on the level of an indented constituent (e.g.,
an indented chapter seems ridiculous); this could be done for instance by adding the
constraint B < 4.
Figures 8 and 9 give document structures for examples (14) and (15), respectively;
the latter also describes example (16), which differs from (15) only in the graphical
realization of the indented paragraph. One feature of these analyses might at first
sight appear strange: they assign the minimal text level L0 to the node representing
the quotation or the bulleted list. How, one might ask, can a paragraph, or indeed a
list of paragraphs, be regarded as a text-phrase? Should it not be a unit higher than the
paragraph, perhaps some kind of section, or better, a new text category vertical list?
On first tackling indented structures, we followed precisely this reasoning, in-
troducing vertical list as a text category. However, despite its initial plausibility, this
decision has several irritating consequences. First, the concept vertical list has no re-
lationship to the text-level hierarchy. Does it belong between text-sentence and para-
graph, or perhaps between paragraph and section? Any placement seems arbitrary.
Second, since the vertical list in a document structure like that in Figure 8 is clearly
coordinated with a text-phrase, such an analysis would violate the rule that coordi-
nated constituents have the same level. Third, and perhaps most persuasively of all,
228
Computational Linguistics Volume 29, Number 2
"is one of ... English literature.""The opening of Pride and Prejudice"
"It is a truth universally ... daughters."
TEXT?SENTENCE (0)
TEXT?CLAUSE (0)
TEXT?PHRASE (0) TEXT?PHRASE (0)
PARAGRAPH (1)
TEXT?PHRASE (0)
Figure 9
Indented document structure (examples (15) and (16)).
it turns out that in their interactions with discourse connectives, vertical lists behave
like text-phrases, not like sentences, paragraphs, or higher units. Thus the vertical list in
Figure 8 is coordinated with the discourse connective since, which would not normally
link constituents higher than text-phrases (we will discuss this constraint more fully
in the next section).9
All these difficulties are removed by denying appearances and assigning the
vertical-list node a text-level of L0. With this treatment, no new arbitrary level in the
hierarchy of units is needed, the basic rule of document structure holds (i.e., coordi-
nated constituents have the same level), and the interaction of the unit with discourse
connectives can be described using the same rules that hold for nonindented struc-
tures. Note also that the difference in indentation between the node and its daughters
is sufficient to identify it as a vertical list; any extra feature (such as a new value in
the text-level hierarchy) would be redundant.
5. Methods of Document Structuring
5.1 Defining the Task
The aim of document structuring within NLG is to create a document structure that
satisfactorily realizes a particular rhetorical structure. This can be achieved through a
variety of architectures, as reflected in the RAGS framework.10 For example, systems
aimed at generating technical abstracts or captions for graphics would probably need
to specify a ?one paragraph only? limit quite early on in the process; in such cases,
document structuring would start before any rhetorical or syntactic decisions were
made (e.g., the RAGS reimplementation of the Caption Generation System [Mellish
et al 2000]). Alternatively, systems that need to generate texts with rich layout might
prefer to interleave document structuring with rhetorical structuring (e.g., Cahill et al
2001).
9 Note that a vertical list can also be coordinated with units larger than text-phrases, such as
text-sentences or paragraphs. The formal rules allow this because a text-phrase can be the only
constituent of a text-clause, which can in turn be the only constituent of a text-sentence, and so forth.
10 See The RAGS Reference Manual, http://www.itri.bton.ac.uk/projects/rags/RefMan/refman.ps.
229
Power, Scott, and Bouayad-Agha Document Structure
For simplicity of presentation, we will assume here an NLG architecture in which a
preliminary module selects simple propositions from a knowledge base and organizes
them into some kind of argument; the document structurer distributes the various
parts of this argument among units like paragraphs and text-sentences; a syntactic
realizer takes over in order to determine the wording of the propositions; finally, a
formatter decides how the abstract categories and features of document structure will
be realized graphically (e.g., whether paragraphs will be marked by a tab on a new
line, or by a vertical space). In the context of such an architecture, two issues are crucial:
what input does the document structurer receive from the earlier planning module,
and how does the output of the document structurer guide syntactic realization?
In ICONOCLAST, our initial assumption, following Scott and Souza (1990), was
that the rhetorical structure would take the form of a graph in which terminal nodes
represent simple propositions and nonterminal nodes represent rhetorical relation-
ships. By organizing all propositions into a single hierarchy, such an input simplifies
the task of the document structuring module; indeed, it could be argued that part
of the work has been done already. An alternative assumption is that the rhetorical
structure takes the form of a set of assertions, each describing a rhetorical relationship
between two propositions (Marcu 1997). With this flat representation, the document
structurer must take more responsibility for grouping the propositions. In this article,
we will focus on the first of these methods (i.e, starting from a hierarchical rhetori-
cal input). The second method (starting from a flat rhetorical input) is described in
Bouayad-Agha (2001).
Regarding the interface between document structuring and syntax, the difficult
issue is where the boundary should be drawn. Above the level of text-clause, it seems
clear that syntax plays little part; however, at the level in which text-phrases combine
to form text-clauses, there is an interplay between the ?syntactic? grammar and the
?text? grammar, as Nunberg (1990) has shown. As an example, consider the simple
rhetorical structure discussed earlier (example (8) and Figure 2):
concession(contain(elixir, gestodene), approve(fda, elixir))
As mentioned earlier, this rhetorical-semantic input could be realized through a text-
sentence comprising two text-clauses:
(8c) Elixir contains gestodene; however, it is approved by the FDA.
In this case it seems clear where the boundary should lie: the document structurer
decides that approve(fda, elixir) should be expressed in the first text-clause, and that
contain(elixir, gestodene) should be expressed in the second, along with the connec-
tive however. It might also impose constraints on the clauses that will realize these
propositions, for instance, by requiring declarative clauses rather than imperative or
interrogative ones. The rest is left to the syntactic realizer, which must decide how the
two propositions should be worded, and how the second clause should be combined
with the connective. Several alternative versions might result, each having exactly the
same document structure:
(8?) Elixir contains gestodene; the FDA, however, approves it.
(8?) Elixir contains gestodene; however, the FDA approves it.
230
Computational Linguistics Volume 29, Number 2
(8??) Gestodene is an ingredient of Elixir; Elixir is approved, however, by the
FDA.
Suppose, however, that the document structurer decides to realize the two propo-
sitions within the same text-clause, as in the following version:
(8??) Elixir is approved by the FDA although it contains gestodene.
Where now does the boundary lie? Should the document structurer create a text-
sentence containing a single text-clause, leave instructions that this text-clause should
express the whole concession relationship, and then wash its hands of the affair, leaving
everything else to the syntactic realizer? Or should it trespass into the domain of
syntactic realization by constructing a syntactic clause of the form S1 although S2, with
instructions that a subclause realizing approve(fda, elixir) should be inserted in position
S1 and a second subclause realizing contain(elixir, gestodene) in position S2?
In ICONOCLAST we have found it more convenient to adopt the latter policy. The
linguistic structure of a document is represented using a single tree in which nodes
may be labeled both with document structure features and with syntactic features.
The document structurer?s task is to build the upper part of this tree, extending from
the root all the way down to the nodes that express simple propositions. In the upper
reaches of the tree, nodes will be labeled with units like section and paragraph, and
syntactic features will be irrelevant; lower down, the document structure may have to
assign some syntactic features when constructing compound clauses. To simplify, we
assume that conjunctive adverbs like however will always be placed at the beginning
of a clause; this means that discourse connectives can be placed into the tree by the
document structurer, thereby limiting the task of the syntactic realizer to the wording
of the simple clauses that realize propositions.
Having clarified the document structurer?s task, we posed the following question:
given a well-formed rhetorical structure, together with a set of formation rules for
document structure and a set of discourse connectives for realizing rhetorical rela-
tions, can we enumerate all document structures that correctly realize the rhetorical
structure?and further, can we evaluate these document structures by some metric so
that we can choose the best? The generation of many alternative solutions was es-
sential to the project, which focused on the problem of controlling style in an NLG
system: by varying a set of stylistic parameters, the user of the system can influence
the evaluation metric that is applied to the set of potential solutions and so influence
the type of solution that will be preferred.
As mentioned above, we have explored two methods of enumerating and evaluat-
ing document structures, one (the focus of this article) assuming a hierarchical input,
the other (described in Bouayad-Agha [2001]) assuming a nonhierarchical input. The
two methods have much in common: they share the same formation rules for doc-
ument structure, the same discourse connectives, and (mainly) the same constraints
on the correct realization of rhetorical relationships. Before describing the hierarchical
method in detail, it will be useful to review the constraints that they share; these con-
straints will be needed, in some form or other, in any system that performs document
structuring.
5.2 Constraints on Realizing Rhetorical Structure
In order to realize a rhetorical structure R(A1, A2) as a document structure, several
decisions must be made:
231
Power, Scott, and Bouayad-Agha Document Structure
? What should be the level (e.g., section, paragraph, text-sentence) of the
document unit that realizes the whole relationship R(A1, A2)?
? What should be the levels of the units realizing the arguments A1 and
A2?
? Should the units realizing A1 and A2 be indented items, or should they
have the same indentation as the unit realizing R(A1, A2)?
? In what linear order should the units realizing A1 and A2 occur?
? Should the rhetorical relation R be expressed using a discourse
connective or left implicit?
? If a discourse connective is used, should it be linked to the span
realizing A1 or the span realizing A2?
These decisions are closely related, as the following examples show:
? If R(A1, A2) is realized through a text-sentence, then the arguments A1
and A2 cannot be realized through a higher unit, such as a paragraph,
unless they are indented one place further than R(A1, A2). (This follows
from the formation rules for document structure.)
? If R is a nucleus-satellite relation rather than a multinuclear one, the
arguments A1 and A2 should not be realized through indented items.11
? If a subordinating conjunction like although is used to express the
relation R, the arguments A1 and A2 should be realized within the same
syntactic clause; hence they should be text-phrases, rather than
text-clauses or some higher unit. Moreover, although should be attached
to the clause expressing A1 (assuming this is the satellite).
Constraints arising from the formation rules for document structure have already
been covered; we will therefore focus here on constraints that concern the realization
of rhetorical relations.
Leaving aside quotations for the time being, our first suggestion is that indentation
should be employed only for the arguments of a multinuclear relation. Vertical lists are
typically used when the items in the list play the same role in the discourse?for
instance, they might be symptoms of a disease or potential side effects of a medicine.
By definition, the arguments of a nucleus-satellite relation have different purposes; the
nucleus makes the main point, whereas the satellite?s role is supportive. Consider, for
example, the following rhetorical structure:
justify(list(tested(elixir), approve(fda, elixir)), safe(elixir))
which gives two reasons why Elixir is safe to use. The LIST relation is multinuclear,
whereas JUSTIFY is nucleus-satellite; according to our rule, then, the document struc-
tures in (17) and (18) should be avoided, whereas those in (19) and (20) should be
11 This constraint is based on the intuition that the items in a vertical list should have parallel roles in the
argument, a condition that clearly fails to hold for a nucleus-satellite relation.
232
Computational Linguistics Volume 29, Number 2
acceptable:
(17) ? Elixir is safe to use
? because it has been carefully tested and is approved by the FDA.
(18) ? Elixir has been carefully tested and is approved by the FDA,
? therefore, it is safe to use.
(19) Elixir is safe to use because
? it has been carefully tested
? it is approved by the FDA
(20) ? Elixir has been carefully tested
? Elixir is approved by the FDA
Therefore, it is safe to use.
Note that when the arguments of a multinuclear relation are presented within a
text-clause, syntax requires a connective like and or or. When they are presented as
indented items, the connective is instead often omitted, leaving the relation implicit;
the reader has to use common sense to divine whether the list represents a conjunction
or a disjunction.
5.2.1 Discourse Connectives. A comprehensive treatment of discourse connectives
will not be attempted here, but we will cover the three main categories identified by
Knott (1996): subordinating conjunctions, coordinating conjunctions, and conjunctive
adverbs.
The properties of a discourse connective can be fully specified by four features:
MEANING, SYNTAX, LOCUS, and SPELLING. As examples, here are three definitions for
the CONCESSION relation:
MEANING concession
SYNTAX subordinating conjunction
LOCUS satellite
spelling ?although?
meaning concession
syntax coordinating conjunction
locus nucleus
spelling ?but?
meaning concession
syntax conjunctive adverb
locus nucleus
spelling ?however?
The locus specifies which argument of the relation carries the discourse connec-
tive. For a nucleus-satellite relation, the argument is identified either by nucleus or
satellite; for a multinuclear relation it is identified by an ordinal specification such
as initial or final.
For each type of discourse connective, it is possible to state specific constraints on
the order of arguments, and on the document units that express them.12
12 Some of these are also mentioned by Scott and Souza (1990) and Rosner and Stede (1992).
233
Power, Scott, and Bouayad-Agha Document Structure
5.2.1.1 Subordinating Conjunction. The spans linked by a subordinating conjunction
can be arranged in either order (nucleus first or satellite first) but must be expressed
within the same text-clause. For example:
(21) Although it has no significant side effects, never give Elixir to other patients.
(22) Never give Elixir to other patients, although it has no significant side effects.
(23) # Although it has no significant side effects; never give Elixir to other patients.
(24) # Although it has no significant side effects. Never give Elixir to other patients.
(25) # Never give Elixir to other patients; although it has no significant side effects.
(26) # Never give Elixir to other patients. Although it has no significant side effects.
5.2.1.2 Coordinating Conjunction. Spans linked by a coordinating conjunction can oc-
cur in the same text-clause or in different text-clauses (or higher units) but must be
ordered so that the discourse connective is located in the final span (i.e., the second
span in the case of a nucleus-satellite relation):
(27) Elixir has no significant side effects, but never give it to other patients.
(28) # But never give Elixir to other patients, it has no significant side effects.
(29) Elixir has no significant side effects; but never give it to other patients.
(30) # But never give Elixir to other patients; it has no significant side effects.
(31) Elixir has no significant side effects. But never give it to other patients.
(32) # But never give Elixir to other patients. It has no significant side effects.
Of course examples (28), (30), and (32) are prohibited only as a means of realizing
a concession relation between the two propositions. They might be acceptable in a
text realizing a different rhetorical structure in which the satellite had already been
expressed.
5.2.1.3 Conjunctive Adverb. Spans linked by a conjunctive adverb can occur in differ-
ent text-clauses (or higher units), but not in the same text-clause. For a nucleus-satellite
relation they must be ordered so that the discourse connective is located in the second
span:
(33) # Elixir has no significant side-effects, however, never give it to other patients.
(34) # However, never give Elixir to other patients, it has no significant side-effects.
(35) Elixir has no significant side-effects; however, never give it to other patients.
(36) # However, never give Elixir to other patients; it has no significant side-effects.
(37) Elixir has no significant side-effects. However, never give it to other patients.
(38) # However, never give Elixir to other patients. It has no significant side-effects.
Again, examples (33), (34), (36), and (38) would be acceptable in realizations of different
rhetorical structures in which the satellite had already been presented.
5.3 Planning Document Structure Using Hierarchical Input
Using the hierarchical method, the input rhetorical structure is a tree in which the
terminal nodes are formulas representing elementary propositions (i.e., propositions
having no internal rhetorical complexity), whereas the nonterminal nodes are labeled
with rhetorical relations (see, for example, Figure 10). This tree is unordered: the roles
234
Computational Linguistics Volume 29, Number 2
concession
justifyapprove(fda, elixirplus)
ban(fda, elixir) contain(elixir, gestodene)
SATELLITE
NUCLEUS SATELLITE
NUCLEUS
Figure 10
Example of rhetorical structure.
of daughter nodes are shown by labels on the arcs (nucleus or satellite in the
case of a nucleus-satellite relation, or an integer greater than zero in the case of a
multinuclear relation).
The output is a linguistic structure, represented formally by an ordered tree in
which each node corresponds to a span of the document. Nodes are labeled with
document structure features (e.g., the level and indentation of the unit) and also with
syntactic features, which usually become relevant only at the level of text-clause or
below. Discourse connectives are already selected and positioned correctly in the tree;
the only task left to the syntactic realizer is to elaborate the tree further by generating
clauses that express the elementary propositions.
Our aim in ICONOCLAST has been to find a document-structuring method that
will generate all document structures that correctly realize an input rhetorical struc-
ture, given certain simplifying assumptions about the composition of the document
structure and the discourse connectives available in the lexicon. During this initial
enumeration of potential solutions, we are not concerned with good style: the pro-
cedure should generate clumsy realizations as well as elegant ones. But we do re-
quire a minimal standard of correctness. There is no point in considering solutions
that leave propositions in the rhetorical structure unexpressed in the document struc-
ture or group them wrongly. The strategy is first to define a procedure that gen-
erates all solutions that are worth considering at all; using this minimally correct
set as a basis, we can then posit further constraints that impose particular stylistic
preferences.
We assume that a minimally correct solution must satisfy three conditions:
1. The terminal nodes of the document structure must express all the
propositions in the rhetorical structure.
2. In addition to satisfying the document structure formation rules, the
solution must conform to correct syntax within text-clauses. For example,
two elementary propositions within a text clause must be linked by a
conjunction placed in the right position.
3. The document structure must be structurally compatible with the
rhetorical structure.
The first two of these conditions are obvious, but the third needs clarification. What
exactly is meant by ?structurally compatible??
We have explored two definitions of structural compatibility that are closely re-
lated to the mathematical notions of isomorphism and homomorphism (Landman
235
Power, Scott, and Bouayad-Agha Document Structure
(a)
approve(fda, elixirplus)
ban(fda, elixir) approve(fda, elixirplus)contain(elixir, gestodene)
ban(fda, elixir)
(b)
contain(elixir, gestodene)
PARAGRAPH
TEXT?SENTENCETEXT?SENTENCE
TEXT?CLAUSETEXT?CLAUSE TEXT?CLAUSE
TEXT?SENTENCETEXT?SENTENCE
PARAGRAPH
TEXT?SENTENCE
Figure 11
Isomorphic (a) and homomorphic (b) document structures.
1991; Bouayad-Agha, Power, and Scott 2000). Each notion can be conveniently ex-
pressed in terms of groupings of propositions in the rhetorical structure and the dis-
course structure. For an isomorphism (the strongest definition of compatibility), two
conditions must hold:
1. If a node in the document structure represents a span in which the set of
propositions expressed is P, there must be a corresponding node in the
rhetorical structure that dominates exactly the same set P of propositions.
2. If a node in the rhetorical structure dominates a set P of propositions,
there must be a node in the document structure representing a span in
which exactly this set P is expressed.
Informally, for an isomorphism, all groupings of propositions in the rhetorical struc-
ture must be transmitted faithfully to the document structure, and no new groupings
should be introduced. For a homomorphism from rhetorical structure to document
structure, only the first condition is required to be fulfilled. Any grouping found in
the document structure must correspond to a grouping in the rhetorical structure, but
the document structure may ?flatten out? the rhetorical structure by leaving some
groupings unexpressed.
These two kinds of compatibility, isomorphism and homomorphism, are illustrated
by document structures (a) and (b), respectively, in Figure 11, which are alternative
realizations of the rhetorical structure in Figure 10; to simplify, discourse connectives
have been left out. Solution (a) is isomorphic with the rhetorical structure, since the
propositions dominated by the justify relation are grouped together in a separate
text-sentence. Solution (b) is homomorphic only with the rhetorical structure, since
the propositions are expressed in three separate text-sentences, the internal grouping
236
Computational Linguistics Volume 29, Number 2
remaining implicit. Here are two texts that might result:
(39)
(a) Elixir contains gestodene; therefore, it is banned by the FDA. However, the FDA ap-
proves ElixirPlus.
(b) Elixir contains gestodene. Therefore, it is banned by the FDA. However, the FDA ap-
proves ElixirPlus.
Note that by losing a grouping from the rhetorical structure, (39b) introduces an
ambiguity: its form would also be consistent with an alternative rhetorical structure in
which the relation justify dominated concession. From the point of view of express-
ing the rhetorical input precisely, the isomorphic solution is always better. However,
when the resulting document structure is complex, or when the correct interpretation
can be inferred easily from the content, there might be stylistic reasons for preferring
a looser homomorphic solution. As a criterion for generating all minimally correct
solutions, therefore, we believe the homomorphic definition of compatibility is more
appropriate.13
Having decided what counts as a correct solution, our next task is to find an
efficient algorithm that will generate all and only these solutions. In ICONOCLAST,
this is accomplished through a constraint-solving method that formalizes the options
for realizing each part of the rhetorical structure, then eliminates those combined
choices that violate constraints. The technique has been explained fully elsewhere
(Power 2000), so we will confine ourselves here to a sketch of the main points.
For each node NR on the rhetorical structure, we can lay out some options on
how the rhetorical fragment dominated by this node will be realized in the document
structure. The crucial choices are as follows:
? What should be the level and indentation of the document structure
node that realizes the proposition or relationship NR?
? If NR is a nonterminal node, labeled with a rhetorical relation, what
discourse connective (if any) should express this relation in the
document structure?
? If NR is nonterminal, in what linear order should its daughter nodes be
realized in the document structure?
These decisions can be formalized by associating with each node four variables that
we will call level, indentation, connective, and position. The potential values
of these variables represent options for realizing the relevant part of the rhetorical
structure, and these options will be reduced by considering constraints on which com-
binations of values are allowed. Initially, the possibilities are as follows:
level: The level of the document structure unit realizing NR will be a document
unit along the hierarchy from text-phrase to chapter. In the program, it
13 We actually believe that even the less strict requirement of a homomorphism from RS to DS is too
strong, because one occasionally finds natural texts that violate it. For example, in Figure 4, RS and DS
are not only nonisomorphic, but nonhomomorphic, because there is a grouping in the DS (propositions
A, D, E) that is not found in the RS (no node in the RS dominates just these three propositions). This
raises the question of how one can distinguish nonhomomorphic solutions that are acceptable (like that
in Figure 4) from ones that are unacceptable (probably the great majority). To defer this difficult issue,
we have preferred in this article to confine our attention to homomorphic solutions. For further
discussion see Bouayad-Agha, Power, and Scott (2000).
237
Power, Scott, and Bouayad-Agha Document Structure
is convenient to represent this with an integer, so that constraints on a
higher or lower level can be implemented using the operations > and <;
we will here continue the notation introduced in Section 4.1, in which L0
means text-phrase, L1 means text-clause, and so forth.
indentation: The indentation of the document structure unit will be a value in
the range I0 to IMax, as explained in Section 4.2. Again, in the implemen-
tation, it is convenient to use an integer.
connective: The value of this variable is either ?, meaning that no connective
should be used, or a word from the lexicon. Thus if the node NR has
the label concession, the potential values might be ?, although, but, and
however.
position: This variable represents the order in which NR will be realized in the
document structure, in comparison with its sisters. The value must lie in
the range 1 . . .S, where S is the total number of sisters (including NR).
Thus if NR is an argument in a nucleus-satellite relation, the range will be
1 . . . 2; if it is an argument in a multinuclear relation, the range may be
larger.
The solution process consists in determining the set of options for each variable (these
are known in constraint logic programming as the domain of the variable), then im-
posing constraints on combinations of values, then enumerating all combinations that
satisfy the constraints. Each admissible combination of values can then be used as a
blueprint for building one of the document structures that may realize the input rhetor-
ical structure. The constraints imposed during the second phase of this algorithm are
essentially those described in the last section.
6. Examples of Document Structuring
We now give two examples of the document-structuring method outlined in the last
section. First, we look in detail at a very simple task, to make it clear how the method
works. Then we show some output for a more complex task, for which the program
will generate dozens of solutions even if the wording of individual propositions is
held constant.
6.1 Simple Example
To view the document-structuring method from close up, we will use a simplified
version of the task discussed in the last section. The rhetorical structure will comprise
just two propositions linked by a concession relation:
concession(ban(fda, elixir), approve(fda, elixirplus))
The method works by computing the options for realizing each constituent of the
rhetorical structure, where a constituent is any node in the rhetorical structure tree
along with its descendents. Thus in the present example there are three constituents?
the two propositions and the whole relationship?and for convenience we will label
them as follows:
A: approve(fda, elixirplus)
B: ban(fda, elixir)
C: concession(ban(fda, elixir), approve(fda, elixirplus))
238
Computational Linguistics Volume 29, Number 2
We can now begin to characterize the units in the document structure that will
realize the rhetorical constituents A, B, and C. For each unit, four choices must be
made: its level, its indentation, its position in relation to its sisters, and its connective.
We therefore have a total of twelve variables. Any combination of values that satis-
fies the constraints (as discussed in the last section) will serve as the blueprint for a
solution.
Following the usual technique for solving constraint satisfaction problems (Hen-
tenryck 1989), we assign to each variable a domain of potential values:
Constituent Level Indentation Position Connective
A (approve) {L0 . . . L3} {I0, I1} {P1, P2} C0
B (ban) {L0 . . . L3} {I0, I1} {P1, P2} C0
C (concession) {L0 . . . L3} {I0, I1} P1 {C0, Calt, Cbut, Chow}
Some of these assignments require some explanation:
? We make the simplifying assumption that the highest unit required will
be the paragraph (formalized as level L3), and that the maximum
indentation will be one place (formalized as I1).
? Since constituents A and B are sisters in the rhetorical structure, their
relative order is formalized by a choice between two positions, P1 and
P2. Constituent C, in contrast, has no sister in the rhetorical structure, so
as an ?only child,? it can have only one position value.
? Constituents A and B are not associated with a discourse connective,
because they are elementary propositions, so their value for the
connective variable is C? (meaning no connective). Constituent C is instead
associated with the concession relation, for which we assume that the
lexicon offers three connectives: although (Calt), but (Cbut), and however
(Chow). The initial domain for the variable connective(C) therefore
comprises these three possibilities along with C?, the option of leaving
the relation implicit.
Having assigned the initial domains, we next proceed to apply some constraints;
these will have the effect of reducing some of the domains. First of all, there are some
constraints applicable to the unit that will serve as the root of the whole document
structure:
Root Level: In a document generation task, we usually have some preconception
about the size of the whole document (e.g., it might be a chapter, or a
section). Since this is a small rhetorical structure, we might decree that the
whole text should consist of a paragraph, so that level(C) = L3.
Root Indentation: It makes no sense for a whole document to be an indented item,
so to realize the root constituent C we may stipulate that indentation(C) =
I0.
Having applied these constraints to the variables realizing C, we can impose some
further constraints that arise from the relationship between C and its direct constituents
A and B:
239
Power, Scott, and Bouayad-Agha Document Structure
Argument Indentation: As pointed out in the last section, it is permissible to
indent the arguments of a multinuclear relation, but not a nucleus-satellite
relation. Therefore, given that the indentation of C has been fixed as I0,
the indentations of A and B must also be I0.
Parental Domination: Since A and B are constituents of C in the rhetorical struc-
ture, the units realizing A and B in the document structure will occur
within the constituent realizing C. Given that all indentations have been
set to I0, this means that level(C) should outrank both level(A) and level(B),
and that consequently the option L3 should be removed from the domains
of the last two variables.
Sister Equality: Because A and B are sisters in the rhetorical structure (i.e., argu-
ments of the same relation), it is appropriate that they should be realized
in the document structure by units of the same level. We can therefore im-
pose the constraint level(A) = level(B). This does not immediately affect
the domains of these variables, but it does mean that as soon as one is
fixed, so is the other.
Sister Position: The units realizing the sisters A and B must occur in one of two
linear orders in the document structure?they cannot both come first, or
both second. We may therefore set the constraint position(A) = position(B).
Again this has no immediate effect on the domains, but as soon as one
value is fixed, so is the other.
Obligatory Connective: As Scott and Souza (1990) point out, an NLG system is
ill-equipped to judge when a rhetorical relation may be left implicit, so it
makes sense to play safe by always realizing the relation using a discourse
connective. Following this policy, we can remove C0 from the domain of
connective(C).
Through applying these constraints, the domains of the variables have been reduced
as follows:
Constituent Level Indentation Position Connective
A (approve) {L0 . . . L2} I0 {P1, P2} C0
B (ban) {L0 . . . L2} I0 {P1, P2} C0
C (concession) L3 I0 P1 {Calt, Cbut, Chow}
Before enumerating solutions, we need to impose a final set of constraints that are
conditional on the choice of discourse connective for C. These constraints have been
explained fully above, so here we only point out how they are stated in terms of our
variables.
Subordinating Conjunction: The units connected by although may occur in any
order, but they must be text-phrases. Therefore, if connective(C) = Calt,
then level(A) = level(B) = L0.
Coordinating Conjunction: We will assume that a coordinating conjunction like
but may link spans within a text-clause, or across text-clauses and text-
sentences, so that no constraint on the levels of A and B results. However,
the satellite must precede the nucleus, so we have position(B) = P1 (and
hence, by Sister Position, position(A) = P2).
240
Computational Linguistics Volume 29, Number 2
Conjunctive Adverb: A conjunctive adverb like however should link spans in units
of text-clause or higher,14 so we can impose the constraints level(A) > L0
and level(B) > L0. (Note that in the implementation, only one of these need
be applied, since the other results from Sister Equality.) For however, the
satellite must precede the nucleus, so again we have position(B) = P1 and
position(A) = P2.
With all potential interactions among decisions taken care of, enumeration can
proceed. In an implementation in constraint logic programming, this is accomplished
through a method called labeling, in which the remaining possible values for each
variable are tried one by one, with backtracking, until all permitted combinations
have been produced. For this example, this process can be understood most easily if
we explore in turn the possible values for connective(C).
Suppose first that connective(C) = Calt (i.e., that we try although). Through the
constraint Subordinating Conjunction, this choice immediately fixes all values of level,
yielding the following domains:
Constituent Level Indentation Position Connective
A (approve) L0 I0 {P1, P2} C0
B (ban) L0 I0 {P1, P2} C0
C (concession) L3 I0 P1 Calt
The only remaining issue is the relative orders of the spans realizing A and B. Enu-
merating arbitrarily on position(A), we first try the value P1; by Sister Position this
immediately yields position(B) = P2, whereupon all values in the table are fixed. We
therefore have our first complete solution:
Constituent Level Indentation Position Connective
A (approve) L0 I0 P1 C0
B (ban) L0 I0 P2 C0
C (concession) L3 I0 P1 Calt
This is still only a blueprint for a document structure, but with these specifications
the rest can be inferred. First, since the units realizing A and B are text-phrases, whereas
the root unit realizing C is a paragraph, the program can interpolate the units needed
to make a well-formed document structure: the paragraph has a single text-sentence,
which has a single text-clause, which comprises the two text-phrases. Next, since
although attaches to the satellite, the program coordinates it with the clause that will
syntactically realize B. The document structure is now complete, and after syntactic
realization of the two propositions we might obtain the following paragraph:
Solution 1: The FDA approves ElixirPlus, although it bans Elixir.
Backing up, the program can now try the alternative order in which position(A) = P2.
After inferring the complete document structure in the same way, we thereby obtain
a second solution:
Solution 2: Although the FDA bans Elixir, it approves ElixirPlus.
14 As Oates (2001) has shown, this is not true if multiple discourse connectives are allowed: For instance,
one might say ?The FDA bans Elixir but, however, it approves ElixirPlus.? But in the present example,
we assume, for simplicity, that only single discourse connectives are used.
241
Power, Scott, and Bouayad-Agha Document Structure
Having fully explored the possibilities with connective(C) = Calt, we back up and
try the next value, namely, Cbut. This time the constraint Coordinating Conjunction
applies, fixing the position values but leaving several possiblities for level:
Constituent Level Indentation Position Connective
A (approve) {L0 . . . L2} I0 P2 C0
B (ban) {L0 . . . L2} I0 P1 C0
C (concession) L3 I0 P1 Cbut
Enumerating on one of the level variables, for instance, level(A), we can now try in
turn the values L0, L1, and L2 (text-phrase, text-clause, and text-sentence); by Sister
Equality, any choice will be copied across to level(B), so that we obtain only three
further solutions rather than nine:
Solution 3: The FDA bans Elixir, but it approves ElixirPlus.
Solution 4: The FDA bans Elixir; but it approves ElixirPlus.
Solution 5: The FDA bans Elixir. But it approves ElixirPlus.
Finally, we try the remaining option, for which connective(C) = Chow. The constraint
Conjunctive Adverb now applies, fixing the order of A and B and ruling out solutions
for which these propositions are realized by text-phrases:
Constituent Level Indentation Position Connective
A (approve) {L1, L2} I0 P2 C0
B (ban) {L1, L2} I0 P1 C0
C (concession) L3 I0 P1 Chow
It remains to enumerate (as before) on level(A), trying in turn the values L1 and L2
(text-clause and text-sentence). Sister Equality again copies any selected value across
to level(B), so that we obtain just two more solutions:
Solution 6: The FDA bans Elixir; however, it approves ElixirPlus.
Solution 7: The FDA bans Elixir. However, it approves ElixirPlus.
Obviously further texts could be obtained by different wordings of the propo-
sitions or different placements of however (e.g., ?The FDA bans Elixir; the FDA ap-
proves ElixirPlus, however?). But these variations do not concern us here, since we
assume they are introduced during syntactic realization, not during document
structuring.
6.2 Complex Example
To examine a more complex example, it is convenient to use a version of ICONOCLAST
in which the wording of individual propositions is prespecified, so that the program?s
only task is to explore the set of possible document structures. The input to this
program is provided in the form of an XML file using the tags RhetRep (for rhetorical
relationships) and SemRep (for propositions) (Cahill et al 1999). The roles of satellite
and nucleus are distinguished implicitly by the order of the elements (satellite precedes
nucleus). Thus the example discussed in the last section
concession(ban(fda, elixir), approve(fda, elixirplus))
242
Computational Linguistics Volume 29, Number 2
Figure 12
Running the document planner.
could be encoded as follows:
<RhetRep relation=concession>
<SemRep prop="the FDA bans Elixir"/>
<SemRep prop="the FDA approves ElixirPlus"/>
</RhetRep>
Obviously this will sometimes lead to some clumsy wording (e.g., through inappro-
priate decisions on whether to use pronouns), but we can try to ignore this when
evaluating the generated document structures.
As a more complicated example we will consider a rhetorical structure with
two nucleus-satellite relations (evidence, concession) and one multinuclear relation
(list):
<RhetRep relation=concession>
<SemRep prop="Elixir contains gestodene"/>
<RhetRep relation=evidence>
<RhetRep relation=list>
<SemRep prop="the medicine has been thoroughly tested"/>
<SemRep prop="it has no significant side effects"/>
</RhetRep>
<SemRep prop="Elixir is safe to use"/>
</RhetRep>
</RhetRep>
The main idea here is that Elixir is safe to use although it contains gestodene; the
claim that Elixir is safe is supported by evidence comprising two conjoined facts: It
has been thoroughly tested, and it has no significant side effects.
Figure 12 shows a snapshot of the program running on this example. Through the
control panel on the left, the user can decide which XML model to use as input; in
the figure, this is set to ?Concession-Evidence-Conjunction,? the name given to this
243
Power, Scott, and Bouayad-Agha Document Structure
input model. Using the button labeled ?Number of versions,? the user can determine
the maximum number of versions that will be generated; since this has been set to
500, the program will return the first 500 solutions that it finds.15 The other buttons
control hard constraints and have been set deliberately to rather restrictive values (e.g.,
indented items have been allowed only to one level of indentation and may consist
only of text-phrases, not larger units like text-sentences or paragraphs). Even with
these restrictive settings, 58 solutions have been generated; they are presented in the
pane on the right, ordered (partially) from best to worst. The scores in parentheses
after the version number report the number of defects that the program detected for
that particular version: thus for each of the solutions that appear in the snapshot,
no defects were found.16 As a comparison, here is version 58, which came up at the
bottom of the class with six defects:
Version 58 (6)
Elixir contains gestodene.
However, the medicine has been thoroughly tested.
It has no significant side effects.
Consequently, Elixir is safe to use.
The specific defects cited here were ?Single-sentence paragraph? (occurring four times)
and ?Lost rhetorical grouping? (occurring twice). (The defects are explained below, and
the full set of solutions is given in the Appendix.)
At present the program looks for six stylistic defects, which are formulated mainly
by looking at generated solutions and making an intuitive judgment as to why they
are bad. We have not tried to give the stylistic assessment a sound theoretical or
empirical basis; the aim at this stage is to confirm that by applying some simple
intuitive principles, we can separate reasonably good solutions from obviously horrible
ones. The six defects are as follows (and we stress again that they are only provisional):
Nucleus precedes satellite: It is generally the case for English that the more im-
portant information is placed at the end of the sentence (i.e., end focus
[Quirk et al 1985]). For example, the rheme of a sentence comes after its
theme, and new information is typically placed after given information
(Halliday 1985; Givo?n 1988). There is also psycholinguistic evidence to
suggest that sentences that conform to this general pattern are processed
more easily (Yekovich, Walker, and Blackman 1979). Since by definition the
nucleus is more important than the satellite (Mann and Thompson 1986,
page 6), it thus makes sense to place the nucleus second. Obviously this
principle is debatable, and the best order might differ from one relation
to another, but we have noticed that for the very common relations such
as concession and evidence, the order satellite-nucleus seems to work
better. The program therefore scores a defect every time that a nucleus is
placed before its satellite.
Left-branching structure: Fodor, Bever, and Garrett (1974) report that left-branching
structures take more time to process and remember than right-branching
15 Obviously, if there are fewer than 500 solutions, it will return all the solutions it finds.
16 When it finds a defect in a version, the system also reports on the type of defect that it finds.
244
Computational Linguistics Volume 29, Number 2
ones. We have also noticed that when a document structure coordinates
two units of different sizes, it reads best when the smaller unit is placed
first. We believe that this may be related to the more general organizational
principle of end weight (Quirk et al 1985). Thus in the program, when
an elementary proposition is coordinated with a unit containing several
propositions, a defect is scored whenever the elementary proposition is
placed second.
Lost rhetorical grouping: As discussed, our method of document structuring does
not demand an isomorphism between rhetorical structure and document
structure; consequently, a grouping that is present in rhetorical structure
may be left implicit in the document structure. Although we allow a group-
ing to be lost in this way, a defect is scored every time it is found to have
occurred.
Single-sentence paragraph: Paragraphs containing a single text-sentence usually
look strange, so they are scored as a defect.
Oversimple text-clauses: We noticed this subtle defect only as a result of experi-
ence with the program. In most cases it looks odd to compose a sentence
from two text-clauses, each expressing a single proposition:
Elixir contains gestodene; therefore, it is banned by the FDA.
The FDA bans Elixir; however, it approves ElixirPlus.
Assuming it is agreed that these sentences are a little strange, why should
this be so? We would suggest the following reason. The semicolon is a
somewhat unusual device, more sophisticated than the comma, and one
therefore expects it to be used only when ordinary methods are unsatis-
factory. In these examples, containing only two propositions, a single text-
clause using conjunctions (e.g., since, although) instead of adverbs would
express the meaning equally clearly, so the semicolon seems unnecessary,
and therefore distracting. A defect is therefore scored every time this is
found to have happened.
Repeated discourse connective: If a rhetorical structure contains two relations of
the same type, one dominating the other, a defect is scored if they are
expressed using the same discourse connective. Here is a simple example
of this defect (repetition of although), followed by an alternative solution
that avoids the defect:
The FDA approves ElixirPlus although it bans Elixir although Elixir has
been thoroughly tested.
The FDA approves ElixirPlus but it bans Elixir although Elixir has been
thoroughly tested.
7. Discussion and Conclusion
Our main aim has been to introduce and motivate abstract document structure as an
important representational level in natural language processing. This proposal rests
on two separate claims: first, that it is useful to distinguish abstract document structure
from concrete graphical realization; second, that abstract document structure should
also be distinguished from rhetorical structure.
245
Power, Scott, and Bouayad-Agha Document Structure
7.1 Abstract versus Concrete
We argue that the transition from a rhetorical-semantic message to a fully specified
document can usefully be divided into two stages. During the first stage, the author
puts the message into words and organizes the words into higher linguistic units like
sentences, paragraphs, and bulleted lists. All decisions pertaining to the realization of
literal content take place during this stage. During the second stage, detailed format-
ting takes place: quotations are realized either by single or double quotes (or some
other method); emphasis is realized through italics, boldface, small capitals, or under-
lining; paragraphs are realized through an introductory tab or double line spacing;
and so forth. Decisions about format do not affect the factual or logical content of the
document, although they might convey ?meanings? of a subtler sort, communicated
through the typographical preferences of the authors (e.g., traditional versus trendy,
ornamental versus puritanical, compact versus expansive).
It is worth noting that similar distinctions are made in other branches of linguistics.
Thus in phonology, a distinction is made between a phonemic level and a phonetic
level. The word grass has a single phonemic representation but will be pronounced
differently by people from different regions or different social classes; these distinctions
are phonetic, not phonemic. To refer to an area in the garden as grass rather than lawn
is one kind of decision; to pronounce grass with a short or long vowel is another. A
theory that mapped directly from the semantic concept to the phonetic form would
miss a generalization that is not only obvious theoretically, but useful practically. The
invention of writing provides additional support for an intermediate phonemic level,
because the different pronunciations of grass are all written down in the same way;
similarly, we would argue, the representational level of abstract document structure
has received more recent support from the invention of markup languages like HTML
and LaTEX.
The concept of abstract document structure is not linked to any particular architec-
ture for natural language generation or understanding. In the RAGS ?reference archi-
tecture? for NLG (Mellish et al 2000; Cahill et al 2001), document structure is distin-
guished from rhetorical structure as a data type, with no commitment as to when these
two data structures are created during the generation process. The ICONOCLAST sys-
tem, described in this article, assumes that rhetorical planning fully precedes document
structuring: in other words, the RST tree has to be complete before the process of cre-
ating a document structure can begin. Such an architecture could be thought of as a
refinement of the standard pipeline (Reiter 1994), with the document-planning phase
divided into two parts (rhetorical planning and document structuring). However, the
ICONOCLAST method would work equally well if a partial assignment of document
structure was part of its input: This would be treated merely as a more specific set of
constraints on possible solutions, which is precisely the arrangement that is used in
the RAGS reimplementation of the Caption Generation System (Mellish et al 2000).
7.2 Document Structure versus Rhetorical Structure
In the terminology of HTML and other mark-up languages, tags like section and
description list are sometimes called logical, suggesting that they are rhetorical
rather than linguistic categories. We have argued that this is a mistake, comparable to
a confusion of syntax with semantics. In our view, the term rhetorical structure should
properly be applied to the higher-level pragmatic and semantic organization of the
message, with no commitment to the means by which this message will be expressed?
whether by speech, or gesture, or diagram, or written document. By contrast, the
categories section and description list are specific to a particular medium, the
written document; hence the term document structure. The two levels are easily confused
246
Computational Linguistics Volume 29, Number 2
because we often refer to spans of a document using a noun that describes their
rhetorical role (e.g., summary in an academic paper).
Some of the distinctions made in this article have parallels in work on document
analysis. Various representations for document structure have been proposed in the
document analysis community, of which the most developed is the Document Attribute
Format Specification (DAFS) (Dori et al 1997). In DAFS, the physical structure of a
document is distinguished from its logical structure; typical physical units are block,
frame, page, and page set, and typical logical units are sentence, paragraph, section,
and header. More formally, the units of logical structure, called textons, are organized
into levels from character (level 0), word (level 1), and sentence or phrase (level 2) up
to sections and whole documents; the lower levels (up to paragraph) are called sim-
ple textons, and the higher levels are called compound textons. Simple textons are
realized through blocks of text, whereas compound textons additionally have a head-
ing and (optionally) a trailer. There is considerable overlap here with our distinction
between concrete and abstract document structure; differences arise because the anal-
ysis community is concerned mainly with the relationship between logical structure
and physical structure (to use that community?s terminology), whereas the generation
community, coming from the opposite direction, is concerned mainly with the rela-
tionship between logical structure (i.e., abstract document structure) and rhetorical
structure.
Having drawn these distinctions, we have sketched a formal theory of abstract
document structure and shown through an implemented NLG system that this theory
allows us to enumerate systematically the high-level linguistic structures that can real-
ize a given rhetorical-semantic input. The formal description of document structure is
based on Nunberg?s (1990) text-grammar, which we have extended in two ways. First,
we introduce larger units such as sections and chapters; Nunberg instead focuses on
the levels relevant for punctuation (i.e., text-sentence and below). Secondly, we intro-
duce a second feature, abstract indentation. Whereas Nunberg categorizes units only
according to the feature we have called level (the hierarchy from text-phrase, text-
clause, etc., up to section and chapter), we categorize units according to two features,
level and indentation. This allows the generation of such patterns as bulleted lists,
including more complex cases in which one list is embedded within another. Using
this descriptive scheme, it has proved relatively easy to state constraints on the inter-
action between content, layout, and wording, especially as regards the use of discourse
connectives.
By introducing a formal scheme for representing document structure, we have
been able to define the task of document structuring in a simple and clear way. Fol-
lowing Scott and Souza (1990) and many other researchers on NLG, it is assumed
that the rhetorical input takes the form of an RST tree; the output is a tree rep-
resenting high-level linguistic structure, each node being labeled with a document
structure category defined by the features level and indentation. Our scheme is by
no means complete (e.g., it has no treatment of tables, or figures, or text presented
in boxes); however, it is sufficient to generate hundreds of alternative solutions even
for a rhetorical structure containing only four or five elementary propositions. By
clarifying the task of document structuring in this way, we have been able to de-
fine it as a constraint satisfaction problem and thus to implement a system in which
the relevant constraints are defined declaratively; this means that constraints can be
added or removed without changing the rest of the program. Such a system is use-
ful not only as a module in an NLG architecture, but also as a tool for theoretical
investigation: the results of any proposed combination of constraints can be quickly
tested.
247
Power, Scott, and Bouayad-Agha Document Structure
In pursuing this investigation, our methodology has been essentially the same as
Nunberg?s, relying largely on intuition as a means of separating the wheat from the
chaff. Moreover, by implementing the theory in a system that can enumerate solutions
systematically, we are able to test more thoroughly any proposed rule or constraint, at
least for simple examples. This methodology assumes, first, that intuition is a reliable
guide, and second, that constraints derived from small examples will apply also to
full-scale examples. In the initial stages of an investigation, these assumptions seem
reasonably safe. Many of the solutions generated by the program are so obviously
good or bad that there is no point in submitting them to the judgment of literary
experts or subjecting them to some other kind of empirical test. No doubt large-scale
examples will require additional constraints, but much can still be learned from simple
ones: an intrinsically bad paragraph will usually remain bad when placed into a larger
context.
As a contrast, it is interesting to consider the investigation into layout by Bateman
et al (2001). Their approach could not be more different from ours. Instead of sim-
ple examples, they analyze (and regenerate) an exceedingly complicated page from a
magazine. This page, which describes the game of hockey, includes several drawings,
a photograph, diagrams of the pitch, boxes of text, two headers, and a glossary, all laid
out in five different grids, each having a different division into columns. Their RST
analysis of this page is correspondingly complex, with 45 elementary propositions
and the same number of rhetorical relationships (the whole RST tree therefore has
nearly 100 nodes). To analyze such an example informally may be a useful source of
insights, but to attempt a complete formal analysis (and generation) of the page seems
bold in the extreme. However, despite this difference in approach, the framework
that emerges from Bateman et al?s work is broadly similar to ours. First, a distinc-
tion is made between ?layout structure? and ?physical layout? (Bateman et al 2001,
section 3.1); although the discussion concerns boxes in a grid rather than more con-
ventional linguistic units like section and paragraph, this distinction reflects the need
for an abstract level of representation that can be related more easily to the rhetor-
ical structure of the message. Secondly, in sections 4 and 5 of their article, Bateman
et al distinguish clearly between layout structure and rhetorical structure, pointing
out that the two are not necessarily isomorphic and that constraints on the mapping
must therefore be considered:
Mapping is generally achieved by placing parts of the RST-structure
in correspondence with particular nodes in layout structure. [. . .] As
we have now seen, however, this correspondence is complicated by
the fact that the layout structure and the RST tree need not remain
congruent.
(Bateman et al 2001, page 430)
However, Bateman and his colleagues do not provide a detailed account of the forma-
tion rules for layout structure, or of the constraints on the mapping between the RST
tree and the layout structure. We are unsure, for example, whether ?layout structure?
would include such patterns as sections, paragraphs, and bulleted lists. Nevertheless,
the role played by these two abstract representations seems similar?they mediate be-
tween rhetorical structure and physical layout?so there is some reason to think that
the two approaches are yielding results that are compatible.
Both in the Bateman et al study and in our own work, a problem arises as to how
the proposed representations and constraints should be validated. Our own approach,
at least provisionally, has been that the theory should be embodied in a program
248
Computational Linguistics Volume 29, Number 2
that can generate many alternative solutions and rank them using some kind of cost
function; at this point, we rely on intuition to judge whether the system has generated
a plausible set of solutions and ranked them in an appropriate order. For the very
complex examples considered by Bateman et al, the set of solutions could only be
sampled: Even keeping the wording of individual propositions constant, they would
number billions. Evaluation in this field has to take account of style as well as quality;
in other words, it has a subjective side as well as an objective one. The problem
is not just to generate a good solution, but to generate one that satisfies a set of
subjective preferences, so that, for example, different documents produced for the
same company will exhibit the desired consistency of style. Eventually, some kind
of empirical investigation will be needed (e.g., an expert evaluation, or a study of
the impression made on the intended readers). At the present state of knowledge,
however, such refinements seem exaggerated: If we can separate the satisfactory from
the barbaric, we will be more than content.
Acknowledgments
The research presented in this article was
carried out as part of the ICONOCLAST
project
(http://www.itri.bton.ac.uk/projects/iconoclast),
with funding from Engineering and
Physical Sciences Research Council grant
number L77102. We are extremely grateful
to Kees van Deemter and three anonymous
reviewers for their critical feedback on an
earlier draft of this article.
References
Arens, Yigal and Eduard Hovy. 1990. Text
layout as a problem of modality selection.
In Proceedings of the Fifth Conference on
Knowledge-Based Specification, RADC
Workshop, pages 87?94, Syracuse, New
York.
Association of British Pharmaceutical
Industry (ABPI). 1997. Compendium of
Patient Information Leaflets. Association of
British Pharmaceutical Industry, London.
Bateman, John, Thomas Kamps, Jorge
Kleinz, and Klaus Reichenberger. 2001.
Towards constructive text, diagram, and
layout generation for information
presentation. Computational Linguistics,
27(3):409?449.
Bolinger, Dwight, editor. 1972. Intonation.
Penguin, Harmonsworth, England.
Bouayad-Agha, Nadjet. 2000. Using an
abstract rhetorical representation to
generate a variety of pragmatically
congruent texts. In Proceedings of the 38th
Annual Meeting of the Association for
Computational Linguistics (ACL), Student
Workshop, pages 16?22, Hong Kong,
October.
Bouayad-Agha, Nadjet. 2001. The role of
document structure in text generation.
Ph.D. thesis, University of Brighton,
Brighton, U.K. Also available as Technical
Report ITRI-01-24, Information
Technology Research Institute, University
of Brighton, Brighton, U.K.
Bouayad-Agha, Nadjet, Richard Power, and
Donia Scott. 2000. Can text structure be
incompatible with rhetorical structure? In
Proceedings of the International Natural
Language Generation Conference, pages
194?200, Mitzpe Ramon, Israel, June
12?16.
Bouayad-Agha, Nadjet, Donia Scott, and
Richard Power. 2000. Integrating content
and style in documents: A case study of
patient information leaflets. Information
Design, 9(2):161?176.
Bouayad-Agha, Nadjet, Donia Scott, and
Richard Power. 2001. The influence of
layout on the interpretation of referring
expressions. In L. Degand, Y. Bestgen,
W. Spooren, and L. van Waes, editors,
Multidisciplinary Approaches to Discourse.
Amsterdam, Nodus, pages 133?141. Also
presented as a paper at the
Multidisciplinary Approaches to
Discourse (MAD) workshop, Ittre,
Belgium, August 2001. A slightly
modified version is also available as
Technical Report ITRI-01-23, Information
Technology Research Institute, University
of Brighton, Brighton, U.K.
Cahill, Lynne, John Carroll, Roger Evans,
Daniel Paiva, Richard Power, Donia Scott,
and Kees van Deemter. 2001. From rags to
riches: Exploiting the potential of a
flexible generation architecture. In
Proceedings of the 39th Annual Meeting of the
Association for Computational Linguistics
(ACL?01), Toulouse, France, pages 98?105.
Also available as Technical Report
ITRI-01-07, Information Technology
Research Institute, University of Brighton,
Brighton, U.K.
249
Power, Scott, and Bouayad-Agha Document Structure
Cahill, Lynne, Christine Doran, Roger
Evans, Chris Mellish, Daniel Paiva, Mike
Reape, Donia Scott, and Neil Tipper. 1999.
Towards a reference architecture for
natural language generation systems.
Technical Report ITRI-99-14, Information
Technology Research Institute, University
of Brighton, Brighton, U.K.
Chomsky, Noam and Morris Halle. 1968.
The Sound Pattern of English. Harper and
Row, New York.
Coch, Jose. 1996. Overview of AlethGen. In
Demonstrations and Posters of the Eighth
International Natural Language Generation
Workshop (INLG?96), Herstmonceux Castle,
Sussex, U.K., pages 25?28.
Crystal, David. 1969. Prosodic Systems and
Intonation in English. Cambridge
University Press, Cambridge.
DiMarco, Chrysanne, Graeme Hirst, Leo
Wanner, and John Wilkinson. 1995.
Healthdoc: Customizing patient
information and health education by
medical condition and personal
characteristics. In First International
Workshop on Artificial Intelligence in Patient
Education, Glasgow, August.
Dori, Dov, David Doermann, Christian Shin,
Robert Haralick, Ihsin Phillips, Mitchell
Buckman, and David Ross. 1997. The
representation of document structure: A
generic object-process analysis. In
P. Wang and H. Bunke, editors, Handbook
on Optical Character Recognition and
Document Image Analysis. World Scientific,
Singapore, pages 421?456.
Fodor, Janet, Thomas Bever, and Merril
Garrett. 1974. The Psychology of Language.
McGraw-Hill, New York.
Ford, Andrew and Tim Dixon. 1996.
Spinning the Web. International Thompson
Computer, London.
Givo?n, Talmy. 1988. The pragmatics of word
order: Predictability, importance and
attention. In M. Hammond, E. Moravcsik,
and J. Werth, editors, Studies in Syntactic
Typology. John Benjamins, Amsterdam,
pages 243?284.
Halliday, Michael. 1967. Intonation and
Grammar in British English. Mouton, the
Hague.
Halliday, Michael. 1985. An Introduction to
Functional Grammar. Edward Arnold,
Baltimore.
Hentenryck, Pascal Van. 1989. Constraint
Satisfaction in Logic Programming. MIT
Press, Cambridge.
Huang, Xiaorong and Armin Fiedler. 1997.
Proof verbalization as an application of
NLG. In Proceedings of the 16th International
Joint Conference on Artificial Intelligence
(IJCAI?97), Nagoya, Japan, pages 965?970.
Knott, Alistair. 1996. A Data-Driven
Methodology for Motivating a Set of Coherence
Relations. Ph.D. thesis, University of
Edinburgh, Edinburgh, U.K.
Knott, Alistair, John Oberlander, Mick
O?Donnell, and Chris Mellish. 2001.
Beyond elaboration: The interaction of
relations and focus in coherent text. In
T. Sanders, J. Schilperoord, and
W. Spooren, editors, Text Representation:
Linguistic and Psycholinguistics Aspects.
Benjamins, Amsterdam, pages 181?196.
Ladd, Robert. 1996. Intonational Phonology.
Cambridge University Press, Cambridge.
Landman, Fred. 1991. Structures for
Semantics, volume 45 in Studies in
Linguistics and Philosophy. Kluwer
Academic.
Lavoie, Benoit and Owen Rambow. 1997. A
fast and portable realizer for text
generation systems. In Proceedings of the
Fifth Conference on Applied Natural Language
Processing (ANLP?97), Washington, D.C.,
pages 265?68.
Mann, William and Sandra Thompson.
1986. Rhetorical structure theory:
Description and construction of text
structures. In Proceedings of the Third
International Workshop on Text Generation,
Nijmegen, the Netherlands, August.
Mann, William and Sandra Thompson.
1987. Rhetorical structure theory: A
theory of text organization. Technical
Report ISI/RS-87-190, Information
Sciences Institute, University of Southern
California, Marina del Rey.
Marcu, Daniel. 1997. From local to global
coherence: A bottom-up approach to text
planning. In Proceedings of the 14th National
Conference on Artificial Intelligence,
Providence, Rhode Island, July. AAAI,
Menlo Park, California, pages 629?635.
Mellish, Chris, Roger Evans, Lynne Cahill,
Christine Doran, Daniel Paiva, Mike
Reape, Donia Scott, and Neil Tipper. 2000.
A representation for complex and
evolving data dependencies in generation.
In Proceedings of the Sixth Applied Natural
Language Processing Conference (ANLP?00),
Seattle.
Mittal, Vibhu, Johanna Moore, Guiseppe
Carenini, and Steven Roth. 1998.
Describing complex charts in natural
language: A caption generation system.
Computational Linguistics, 24(3):431?468.
Moore, Johanna and Martha Pollack. 1992.
A problem for RST: The need for
multi-level discourse analysis.
Computational Linguistics, 18(4):537?544.
Moser, Megan and Johanna Moore. 1996.
250
Computational Linguistics Volume 29, Number 2
Towards a synthesis of two accounts of
discourse structure. Computational
Linguistics, 22(3):409?419.
Nunberg, Geoff. 1990. The Linguistics of
Punctuation, volume 18 in CSLI Lecture
Notes. CSLI, Stanford, California.
Oates, Sarah. 2001. Generating multiple
discourse markers in text. Master?s thesis,
University of Brighton, Brighton, U.K.
Also available as Technical Report
ITRI-01-25, Information Technology
Research Institute, University of Brighton,
Brighton, U.K.
Paris, Cecile, Keith Vander Linden, Marcus
Fischer, Anthony Hartley, Lynne
Pemberton, Richard Power, and Donia
Scott. 1995. A support tool for writing
multilingual instructions. In Proceedings of
the Fourteenth International Joint Conference
in Artificial Intelligence (IJCAI-95), pages
1398?1404. Also available as Technical
Report ITRI-95-11, Information
Technology Research Institute, University
of Brighton, Brighton, U.K.,
http://www.itri.bton.ac.uk/techreports/.
Pierrehumbert, Janet. 1980. The Phonology
and Phonetics of English Intonation. Ph.D.
thesis, Massachusetts Institute of
Technology, Cambridge.
Power, Richard. 2000. Planning texts by
constraint satisfaction. In Proceedings of the
18th International Conference in
Computational Linguistics (COLING),
Saarbru?cken, Germany, pages 642?648.
Power, Richard and Nico Cavallotto. 1996.
Multilingual generation of administrative
forms. In Proceedings of the Eighth
International Workshop on Natural Language
Generation, Herstmonceux Castle, Sussex,
U.K., pages 17?19.
Quirk, Randolph, Sidney Greenbaum,
Geoffrey Leech, and Jan Svartvik. 1985. A
Comprehensive Grammar of the English
Language. Longman, London.
Reiter, Ehud. 1994. Has a consensus NL
generation architecture appeared, and is it
psycholinguistically plausible? In
Proceedings of the Seventh International
Workshop on Natural Language Generation
(INLGW-1994), Kennebunkport, Maine,
pages 163?170.
Reiter, Ehud and Robert Dale. 2000. Building
Natural Language Generation Systems.
Cambridge University Press, Cambridge.
Rosner, Dietmar and Manfred Stede. 1992.
Customizing RST for the automatic
production of technical manuals. In
R. Dale, D. Roesner, E. H. Hovy, and
O. Stock, editors, Aspects of Automated
Natural Language Generation.
Springer-Verlag, Heidelberg, pages
199?214.
Schriver, Karen. 1997. Dynamics in Document
Design: Creating Text for Readers. Wiley
Computer, New York.
Scott, Donia and Clarisse de Souza. 1990.
Getting the message across in RST-based
text generation. In R. Dale, C. Mellish,
and M. Zock, editors, Current Research in
Natural Language Generation, volume 4 in
Cognitive Science Series. Academic Press,
New York, pages 47?73.
Scott, Donia and Cecile Paris. 1995.
Identifying the mapping of semantics
onto language: Going beyond the text. In
Working Papers of the AAAI Symposium on
Empirical Methods in Discourse Interpretation
and Generation, Stanford University,
Stanford, California, March.
Scott, Donia and Richard Power. 2001.
Generating textual diagrams and
diagrammatic texts. In H. Bunt and R-J.
Beun, editors, Cooperative Multimodal
Communication, volume 2155 in Lecture
Notes in Artificial Intelligence.
Springer-Verlag, Berlin, pages 13?29. Also
available as Technical Report ITRI-01-02,
Information Technology Research
Institute, University of Brighton,
Brighton, U.K.
?t Hart, Johan, Rene? Collier, and Antonie
Cohen. 1990. A Perceptual Study of
Intonation, in series Cambridge Studies in
Speech Science and Communication.
Cambridge University Press, Cambridge.
Yekovich, Frank, Carol Walker, and Harold
Blackman. 1979. The role of presupposed
and focal information in integrating
sentences. Journal of Verbal Learning and
Verbal Behavior, 18:535?548.
251
Power, Scott, and Bouayad-Agha Document Structure
Appendix. Solutions Found for the Example in Section 6.1
Number of versions = 58
Version 1 (0)
Elixir contains gestodene. However, the medicine has been thoroughly tested and it
has no significant side effects; consequently, Elixir is safe to use.
Version 2 (0)
Elixir contains gestodene; however, since
? the medicine has been thoroughly tested
? it has no significant side effects
Elixir is safe to use.
Version 3 (0)
Elixir contains gestodene. However, since
? the medicine has been thoroughly tested
? it has no significant side effects
Elixir is safe to use.
Version 4 (0)
Elixir contains gestodene; however,
? the medicine has been thoroughly tested
? it has no significant side effects
so Elixir is safe to use.
Version 5 (0)
Elixir contains gestodene. However,
? the medicine has been thoroughly tested
? it has no significant side effects
so Elixir is safe to use.
Version 6 (0)
Elixir contains gestodene. However,
? the medicine has been thoroughly tested
? it has no significant side effects;
consequently, Elixir is safe to use.
Version 7 (1)
Elixir contains gestodene. However, the medicine has been thoroughly tested and it
has no significant side effects. Consequently, Elixir is safe to use.
Lost rhetorical grouping
252
Computational Linguistics Volume 29, Number 2
Version 8 (1)
Elixir contains gestodene. However, the medicine has been thoroughly tested and it
has no significant side effects. Consequently, Elixir is safe to use.
Single-sentence paragraph
Version 9 (1)
Although Elixir contains gestodene since
? the medicine has been thoroughly tested
? it has no significant side effects
Elixir is safe to use.
Lost rhetorical grouping
Version 10 (1)
Although Elixir contains gestodene
? the medicine has been thoroughly tested
? it has no significant side effects
so Elixir is safe to use.
Lost rhetorical grouping
Version 11 (1)
Elixir contains gestodene but since
? the medicine has been thoroughly tested
? it has no significant side effects
Elixir is safe to use.
Lost rhetorical grouping
Version 12 (1)
Elixir contains gestodene but
? the medicine has been thoroughly tested
? it has no significant side effects
so Elixir is safe to use.
Lost rhetorical grouping
Version 13 (1)
Elixir contains gestodene; however, Elixir is safe to use since
? the medicine has been thoroughly tested
? it has no significant side effects.
Nucleus precedes satellite
253
Power, Scott, and Bouayad-Agha Document Structure
Version 14 (1)
Elixir contains gestodene. However, since the medicine has been thoroughly tested
and it has no significant side effects Elixir is safe to use.
Lost rhetorical grouping
Version 15 (1)
Elixir contains gestodene. However, Elixir is safe to use since
? the medicine has been thoroughly tested
? it has no significant side effects.
Nucleus precedes satellite
Version 16 (1)
Elixir contains gestodene; however, the medicine has been thoroughly tested and it
has no significant side effects so Elixir is safe to use.
Lost rhetorical grouping
Version 17 (1)
Elixir contains gestodene. However, the medicine has been thoroughly tested and it
has no significant side effects so Elixir is safe to use.
Lost rhetorical grouping
Version 18 (1)
Elixir contains gestodene; however, the medicine has been thoroughly tested and it
has no significant side effects; consequently, Elixir is safe to use.
Lost rhetorical grouping
Version 19 (1)
Elixir contains gestodene; however,
? the medicine has been thoroughly tested
? it has no significant side effects;
consequently, Elixir is safe to use.
Lost rhetorical grouping
Version 20 (1)
Elixir contains gestodene; however, since the medicine has been thoroughly tested and
it has no significant side effects Elixir is safe to use.
Lost rhetorical grouping
Version 21 (1)
Elixir contains gestodene. However,
? the medicine has been thoroughly tested
? it has no significant side effects.
Consequently, Elixir is safe to use.
Lost rhetorical grouping
254
Computational Linguistics Volume 29, Number 2
Version 22 (1)
Elixir contains gestodene.
However,
? the medicine has been thoroughly tested
? it has no significant side effects.
Consequently, Elixir is safe to use.
Single-sentence paragraph
Version 23 (2)
Elixir contains gestodene but since the medicine has been thoroughly tested and it has
no significant side effects Elixir is safe to use.
Lost rhetorical grouping
Lost rhetorical grouping
Version 24 (2)
? The medicine has been thoroughly tested
? it has no significant side effects
so Elixir is safe to use although Elixir contains gestodene.
Nucleus precedes satellite
Lost rhetorical grouping
Version 25 (2)
Elixir contains gestodene but the medicine has been thoroughly tested and it has no
significant side effects so Elixir is safe to use.
Lost rhetorical grouping
Lost rhetorical grouping
Version 26 (2)
Elixir contains gestodene but Elixir is safe to use since
? the medicine has been thoroughly tested
? it has no significant side effects.
Nucleus precedes satellite
Lost rhetorical grouping
Version 27 (2)
Elixir contains gestodene; however, Elixir is safe to use since the medicine has been
thoroughly tested and it has no significant side effects.
Nucleus precedes satellite
Lost rhetorical grouping
Version 28 (2)
Although Elixir contains gestodene since the medicine has been thoroughly tested and
it has no significant side effects Elixir is safe to use.
Lost rhetorical grouping
Lost rhetorical grouping
255
Power, Scott, and Bouayad-Agha Document Structure
Version 29 (2)
Elixir contains gestodene. However, Elixir is safe to use since the medicine has been
thoroughly tested and it has no significant side effects.
Nucleus precedes satellite
Lost rhetorical grouping
Version 30 (2)
Elixir contains gestodene.
However, the medicine has been thoroughly tested and it has no significant side
effects; consequently, Elixir is safe to use.
Single-sentence paragraph
Single-sentence paragraph
Version 31 (2)
Although Elixir contains gestodene the medicine has been thoroughly tested and it
has no significant side effects so Elixir is safe to use.
Lost rhetorical grouping
Lost rhetorical grouping
Version 32 (2)
Elixir contains gestodene. However, the medicine has been thoroughly tested; it has
no significant side effects; consequently, Elixir is safe to use.
Lost rhetorical grouping
Oversimple text-clauses
Version 33 (2)
Elixir contains gestodene.
However, since
? the medicine has been thoroughly tested
? it has no significant side effects
Elixir is safe to use.
Single-sentence paragraph
Single-sentence paragraph
Version 34 (2)
Elixir contains gestodene. However, the medicine has been thoroughly tested; it has
no significant side effects. Consequently, Elixir is safe to use.
Lost rhetorical grouping
Oversimple text-clauses
Version 35 (2)
Elixir contains gestodene. However, the medicine has been thoroughly tested. It has
no significant side effects. Consequently, Elixir is safe to use.
Lost rhetorical grouping
Lost rhetorical grouping
256
Computational Linguistics Volume 29, Number 2
Version 36 (2)
Elixir contains gestodene.
However,
? the medicine has been thoroughly tested
? it has no significant side effects
so Elixir is safe to use.
Single-sentence paragraph
Single-sentence paragraph
Version 37 (2)
Elixir contains gestodene.
However, the medicine has been thoroughly tested; it has no significant side effects.
Consequently, Elixir is safe to use.
Single-sentence paragraph
Oversimple text-clauses
Version 38 (2)
Elixir contains gestodene.
However, the medicine has been thoroughly tested. It has no significant side ef-
fects. Consequently, Elixir is safe to use.
Single-sentence paragraph
Lost rhetorical grouping
Version 39 (2)
Since
? the medicine has been thoroughly tested
? it has no significant side effects
Elixir is safe to use although Elixir contains gestodene.
Nucleus precedes satellite
Lost rhetorical grouping
Version 40 (2)
Elixir contains gestodene.
However,
? the medicine has been thoroughly tested
? it has no significant side effects;
consequently, Elixir is safe to use.
Single-sentence paragraph
Single-sentence paragraph
257
Power, Scott, and Bouayad-Agha Document Structure
Version 41 (2)
Although Elixir contains gestodene Elixir is safe to use since
? the medicine has been thoroughly tested
? it has no significant side effects.
Nucleus precedes satellite
Lost rhetorical grouping
Version 42 (3)
Elixir contains gestodene.
However, Elixir is safe to use since
? the medicine has been thoroughly tested
? it has no significant side effects.
Single-sentence paragraph
Nucleus precedes satellite
Single-sentence paragraph
Version 43 (3)
Since the medicine has been thoroughly tested and it has no significant side effects
Elixir is safe to use although Elixir contains gestodene.
Nucleus precedes satellite
Lost rhetorical grouping
Lost rhetorical grouping
Version 44 (3)
The medicine has been thoroughly tested and it has no significant side effects so Elixir
is safe to use although Elixir contains gestodene.
Nucleus precedes satellite
Lost rhetorical grouping
Lost rhetorical grouping
Version 45 (3)
Elixir contains gestodene.
However, since the medicine has been thoroughly tested and it has no significant
side effects Elixir is safe to use.
Single-sentence paragraph
Single-sentence paragraph
Lost rhetorical grouping
Version 46 (3)
Although Elixir contains gestodene Elixir is safe to use since the medicine has been
thoroughly tested and it has no significant side effects.
Nucleus precedes satellite
Lost rhetorical grouping
Lost rhetorical grouping
258
Computational Linguistics Volume 29, Number 2
Version 47 (3)
Elixir contains gestodene.
However, the medicine has been thoroughly tested. It has no significant side ef-
fects.
Consequently, Elixir is safe to use.
Single-sentence paragraph
Lost rhetorical grouping
Single-sentence paragraph
Version 48 (3)
Elixir is safe to use since
? the medicine has been thoroughly tested
? it has no significant side effects
although Elixir contains gestodene.
Nucleus precedes satellite
Nucleus precedes satellite
Lost rhetorical grouping
Version 49 (3)
Elixir contains gestodene but Elixir is safe to use since the medicine has been thor-
oughly tested and it has no significant side effects.
Nucleus precedes satellite
Lost rhetorical grouping
Lost rhetorical grouping
Version 50 (3)
Elixir contains gestodene; however, the medicine has been thoroughly tested; it has
no significant side effects; consequently, Elixir is safe to use.
Lost rhetorical grouping
Lost rhetorical grouping
Oversimple text-clauses
Version 51 (3)
Elixir contains gestodene.
However, the medicine has been thoroughly tested and it has no significant side
effects so Elixir is safe to use.
Single-sentence paragraph
Single-sentence paragraph
Lost rhetorical grouping
Version 52 (3)
Elixir contains gestodene.
However,
? the medicine has been thoroughly tested
? it has no significant side effects.
259
Power, Scott, and Bouayad-Agha Document Structure
Consequently, Elixir is safe to use.
Single-sentence paragraph
Lost rhetorical grouping
Single-sentence paragraph
Version 53 (4)
Elixir contains gestodene.
However, the medicine has been thoroughly tested; it has no significant side effects;
consequently, Elixir is safe to use.
Single-sentence paragraph
Single-sentence paragraph
Lost rhetorical grouping
Oversimple text-clauses
Version 54 (4)
Elixir is safe to use since the medicine has been thoroughly tested and it has no
significant side effects although Elixir contains gestodene.
Nucleus precedes satellite
Nucleus precedes satellite
Lost rhetorical grouping
Lost rhetorical grouping
Version 55 (4)
Elixir contains gestodene.
However, the medicine has been thoroughly tested and it has no significant side
effects.
Consequently, Elixir is safe to use.
Single-sentence paragraph
Lost rhetorical grouping
Single-sentence paragraph
Single-sentence paragraph
Version 56 (4)
Elixir contains gestodene.
However, Elixir is safe to use since the medicine has been thoroughly tested and
it has no significant side effects.
Single-sentence paragraph
Nucleus precedes satellite
Single-sentence paragraph
Lost rhetorical grouping
Version 57 (5)
Elixir contains gestodene.
However, the medicine has been thoroughly tested; it has no significant side effects.
Consequently, Elixir is safe to use.
260
Computational Linguistics Volume 29, Number 2
Single-sentence paragraph
Lost rhetorical grouping
Single-sentence paragraph
Oversimple text-clauses
Single-sentence paragraph
Version 58 (6)
Elixir contains gestodene.
However, the medicine has been thoroughly tested.
It has no significant side effects.
Consequently, Elixir is safe to use.
Single-sentence paragraph
Lost rhetorical grouping
Lost rhetorical grouping
Single-sentence paragraph
Single-sentence paragraph
Single-sentence paragraph
c? 2004 Association for Computational Linguistics
Optimizing Referential Coherence
in Text Generation
Rodger Kibble? Richard Power?
University of London University of Brighton
This article describes an implemented system which uses centering theory for planning of coherent
texts and choice of referring expressions. We argue that text and sentence planning need to be
driven in part by the goal of maintaining referential continuity and thereby facilitating pronoun
resolution: Obtaining a favorable ordering of clauses, and of arguments within clauses, is likely
to increase opportunities for nonambiguous pronoun use. Centering theory provides the basis for
such an integrated approach. Generating coherent texts according to centering theory is treated
as a constraint satisfaction problem. The well-known Rule 2 of centering theory is reformulated in
terms of a set of constraints?cohesion, salience, cheapness, and continuity?and we show sample
outputs obtained under a particular weighting of these constraints. This framework facilitates
detailed research into evaluation metrics and will therefore provide a productive research tool in
addition to the immediate practical benefit of improving the fluency and readability of generated
texts. The technique is generally applicable to natural language generation systems, which perform
hierarchical text structuring based on a theory of coherence relations with certain additional
assumptions.
1. Overview
A central task for natural language generation (NLG) systems is to produce text that
is coherent, in the sense in which (1a) is noticeably more coherent than (1b):
1. a. Elixir is a white cream.
It is used in the treatment of cold sores.
It contains aliprosan.
Aliprosan relieves viral skin disorders.
b. Elixir contains aliprosan.
Viral skin disorders are relieved by aliprosan.
Elixir is used in the treatment of cold sores.
It is a white cream.
We can observe various ways in which text organization influences coherence: the
sequence in which certain facts are presented, the order in which entities are mentioned
in a clause, and the possibilities available for identifying the intended reference of
pronouns. Generally, (1a) seems to conform better to a reader?s expectations of what
will be referred to next and of how to resolve underspecified referring expressions,
? Department of Computing, Goldsmiths College, University of London, London SE14 6NW, U. K.
E-mail: r.kibble@gold.ac.uk
? Information Technology Research Institute, University of Brighton, Brighton BN2 4GJ, U. K. E-mail:
Richard.Power@itri.brighton.ac.uk
Submission received: 17 October 2002; Revised submission received: 22 May 2004; Accepted for
publication: 6 August 2004
402
Computational Linguistics Volume 30, Number 4
in particular pronouns. These are issues which the well-known centering theory (CT)
of Grosz, Joshi, and Weinstein (1995; henceforth GJW) is concerned with. Previous
algorithms for pronominalization such as those of McCoy and Strube (1999), Henschel,
Cheng, and Poesio (2000), and Callaway and Lester (2002) have addressed the task of
deciding whether to realize an entity as a pronoun on the basis of given factors such as
its syntactic role and discourse history within a given text structure; what is essentially
novel in our approach is that we treat referential coherence as a planning problem, on
the assumption that obtaining a favorable ordering of clauses, and of arguments within
clauses, is likely to increase opportunities for nonambiguous pronoun use. Centering
theory provides the basis for such an integrated approach.1
Of course coherence of a text depends on the realization of rhetorical relations
(Mann and Thompson 1987) as well as referential continuity, and the latter is to an
extent a byproduct of the former, as clauses that are rhetorically related also tend
to mention the same entities. However, even when a set of facts is arranged in a
hierarchical RST structure, there are still many possible linear orderings with notice-
able differences in referential coherence. This article concentrates on the influence of
referential continuity on overall coherence and describes a method for applying CT
to problems in text planning and pronominalization in order to improve the fluency
and readability of generated texts. This method is applicable in principle to any sys-
tem which produces hierarchically structured text plans using a theory of coherence
relations, with the following additional assumptions:
? There is a one-to-one correspondence between predicates and verbs, so
that the options for syntactic realization can be predicted from the
argument structure of predicates. Such ?shallow? lexicalization appears
to be standard in applied NLG systems (Cahill 1999).
? Pronominalization is deferred until grammatical relations and word
order have been determined.
Our exposition will refer to an implemented document generation system, Icon-
oclast, which uses the technique of constraint satisfaction (van Hentenryck 1989;
Power 2000; Power, Scott, and Bouayad-Agha 2003) with CT principles implemented
among a set of soft constraints. The Iconoclast system allows the user to specify
content and rhetorical structure through an interactive knowledge-base editor and
supports fine-grained control over stylistic and layout features. The user-determined
rhetorical structure is transformed into a text structure or a set of candidate text struc-
tures which respect various text formation rules encoded as hard constraints. Not all
of the resulting text structures will give rise to stylistically acceptable documents, and
of those which may be judged acceptable, some will be noticeably preferable to others.
The text-structuring phase is followed by an evaluation of the candidate structures in
which they are ranked according to a set of preferences encoded as soft constraints.
Centering preferences are weighted along with other stylistic constraints to fix the
preferred final ordering both of propositions in the text and of arguments within a
clause.
It is not our primary aim in this short article to provide an empirical assessment
of the claims of CT, for which we refer the reader to the relevant papers, such as
1 Callaway and Lester (2002) note that CT-based pronominalization algorithms ?assume that the
discourse tree was constructed with Centering theory in mind? (page 91); in our case this assumption
is justified.
403
Kibble and Power Optimizing Referential Coherence
those collected in Walker, Joshi, and Prince (1998a) as well as Poesio et al (2002)
and other works cited there. We report elsewhere (Kibble and Power 2004) on two
ongoing empirical studies: A paired-comparison study of judgments by naive subjects
indicates that centering constraints make an appreciable difference to the acceptability
of texts, and a corpus study using what we believe to be a novel technique involving
perturbations provides clear evidence of preferences between the different constraints.
One of the strengths of our framework is that it can be used as a research tool for
the evaluation of variants of CT, as different realizations of an input sequence can be
generated by varying control parameters, and one can very quickly see the results of
alternative choices.
1.1 Related Work
Other researchers have applied CT to generation, though to our knowledge none have
applied it to text planning, sentence planning, and pronominalization in the integrated
way that we present in this article. This general approach is anticipated by McKeown?s
(1985) text-planning system, in which referential coherence is taken to be one of the
factors determining fluency, though McKeown?s work predates RST and centering.
Mittal et al (1998) apply what we term salience to sentence planning, with the goal of
realizing the Cb as subject, though the text planner does not have a goal of attempting
to maintain the same Cb. We regard Cheng?s (2000) work on the interaction of centering
preferences and aggregation in text planning as complementary to our enterprise.
Karamanis (2001), Kibble (2001), and Beaver (2004), have argued for a ranking of the
centering principles as opposed to weighting, and indeed Beaver provides a unified
formulation of the centering rules and constraints as a ranked set of OT constraints.
However, we believe that such a ranking stands in need of empirical justification,
and Beaver?s data actually provide little evidence for strict ranking as opposed to
weighting of constraints (see Kibble 2003). Constraint satisfaction search was applied
by Marcu (1996, 1997) to the far harder task of constructing RST trees given a set
of facts and a repertoire of rhetorical relations; Mellish et al (1998) argue that this
approach may not scale up to the generation of larger texts and propose an alternative
using stochastic search. We address the issue of computational complexity in section
4; however we do not face the same problems as Marcu, since the task for our text
planner is to convert a given RST tree into a (possibly singleton) set of text structures
rather than to build the RST tree from scratch.
2. Centering Parameters
We assume some familiarity with the basic concepts of CT. In this section we briefly
and informally summarize the main assumptions of the theory and explain how we
have interpreted and applied these assumptions:
1. For each utterance in a discourse there is said to be at most one entity that is the
center of attention or center (Constraint 1). The center in an utterance Un is the most
highly ranked entity realized in Un?1, which is also realized in Un (Constraint 3). This
is also referred to as the backward-looking center or Cb. (The set of entities mentioned
in an utterance Un is defined by Constraint 2 as the set of forward-looking centers
or Cfs.) It is not entirely clear whether Constraint 1 is to be taken as an empirical
claim or as a stipulation that some entity must be designated as Cb, if necessary by
constructing an indirect anaphoric link.
2. There is a preference for consecutive utterances within a discourse segment to
keep the same entity as the center and for the center to be realized as the highest-
ranked entity or preferred center (Cp). Kibble (1999) dubbed these principles cohe-
404
Computational Linguistics Volume 30, Number 4
Table 1
Centering transitions.
Continue Cohesion and Salience both hold; same center (or Cb(Un) undefined),
realized as Cp in Un+1
Retain Cohesion only; that is, center remains the same but is not realized
as Cp in Un+1
Smooth Shift Salience only; center of Un+1 realized as Cp but not equal to Cb(Un)
Rough Shift Neither cohesion nor salience holds
sion and salience, respectively. Combinations of these preferences provide the familiar
canonical set of transitions shown in Table 1, ranked in the stipulated order of pref-
erence first set out as Rule 2 by Brennan, Friedman, and Pollard (1987) and adopted
by Walker, Joshi, and Prince (1998b).
3. The center is the entity which is most likely to be pronominalized: GJW?s Rule 1
in its weakest form states that if any entity is referred to by a pronoun, the Cb must be.
As Poesio et al (2002) point out, CT can be viewed as a ?parametric? theory in
that key notions such as utterance and previous utterance, realization of entities, and
ranking are not given precise definitions by GJW, and subsequent applied studies
have had to begin by fixing particular instantiations of these notions.
2.1 Ranking
Since Brennan, Friedman, and Pollard (1987), a ranking in terms of grammatical roles
(or obliqueness) has become standard; for example: subject > direct object >
indirect object > others.
We have simplified matters somewhat for the purposes of this implementation. First,
we assume that syntactic realization serves only to distinguish the Cp from all other
referents, which are ranked on the same level: Thus effectively subject > others.
Secondly, we assume that the system already knows, from the argument structure
of the proposition, which entities can occur in subject position: Thus in realizing a
proposition ban(fda, elixir), both arguments are potential Cps because active and pas-
sive realizations are both allowed; for contain(elixir, gestodene), only elixir is a potential
Cp because we disallow Gestodene is contained by Elixir.
2.2 Realization
GJW?s original formulation distinguished between ?direct? realization, or coreference,
and ?indirect? realization, which corresponds to bridging reference. As an example,
in (1a) the terms cold sores and viral skin disorders are not strictly coreferential and so do
not count as direct realizations of the same entity, but if we allow indirect realization,
then there is the potential for one of these to be identified as Cb, in a sequence such
as Elixir is used to treat cold sores. Viral skin disorders are relieved by aliprosan. Again, we
keep things simple at this stage by treating nominal expressions as realizations of the
same entity only if they strictly corefer. As Poesio et al (2002) observe, under this
interpretation of realization, a number of utterances will lack an identifiable Cb, so we
have to allow for a ?no-Cb? transition in addition to the canonical transitions listed
in Table 1.2
2 Of course, even with indirect realization we would still have to allow for the possibility of no-Cb
transitions.
405
Kibble and Power Optimizing Referential Coherence
2.3 Utterance and Previous Utterance
Two different approaches to the realization of ?utterance? have become associated with
the work of Kameyama (1998) and Suri, McCoy, and DeCristoforo (1999). To simplify
somewhat: Kameyama argued that the local focus is updated in a linear manner by
tensed clauses rather than by sentences, while Suri, McCoy, and DeCristoforo present
evidence that the subject of the main clause in a complex sentence is likely to be
the preferred antecedent for a subject pronoun in an immediately following sentence,
winning out over candidates in an intervening subordinate clause, as in example (2):
2. Dodgei was robbed by an ex-convict j the other night.
The ex-convictj tied himi up because hei wasn?t cooperating.
Then hej took all the money and ran / #he i started screaming for help.
In fact we would argue that Suri, McCoy, and DeCristoforo?s analysis does not estab-
lish whether the accessibility effects are due to the syntactic or the rhetorical structure
of utterances. The examples they present all involve sentences of the form Sx because
Sy corresponding to the rhetorical pattern nucleus?connective?satellite. Their results
are therefore consistent with the hypothesis that the nucleus of a preceding segment
is more accessible than the satellite. We allow the user of our system to choose be-
tween two strategies: a linear, Kameyama-style approach or a hierarchical approach
in which the utterance is effectively identified with a rhetorical span. Our approach is
more general than that of Suri, McCoy, and DeCristoforo as it covers cases in which
the components of a complex rhetorical span are realized in different sentences. Veins
theory (Cristea, Ide, and Romary 1998) provides a possible formalization of the intu-
ition that some earlier propositions become inaccessible as a rhetorical boundary is
crossed. The theory could be applied to centering in various ways; we have imple-
mented perhaps the simplest approach, in which centering transitions are assessed in
relation to the nearest accessible predecessor. In many cases the linear and hierarchi-
cal definitions give the same result, but sometimes they diverge, as in the following
schematic example:
3. ban(fda, elixir) since contain(elixir, gestodene).
However, approve(fda, elixirplus).
Following Veins Theory, the predecessor of approve(fda, elixirplus) is ban(fda, elixir); its
linear predecessor contain(elixir, gestodene) (an embedded satellite) is inaccessible. This
makes a considerable difference: Under a hierarchical approach, fda can be the Cb of
the final proposition; under a linear approach, this proposition has no Cb.
2.4 Transitions versus Constraints
Kibble (1999, 2001) argued for a decomposition of the canonical transition types into
the principles of cohesion and salience, partly on the architectural grounds that this
makes it easier to apply CT to the generation task, and partly on the empirical grounds
that the preference ordering assumed by GJW is not strongly supported by corpus
evidence and that transitions are better seen as epiphenomenal, emerging in a partial
ordering from the interaction of more fundamental constraints. We follow this general
approach, including among the constraints the principle of continuity: Each utterance
should have at least one referent in common with the preceding utterance, which
is effectively a restatement of GJW?s Constraint 1. If we assign a weight of 1 each
to cohesion and salience and 2 to continuity, we obtain a partial ordering over the
406
Computational Linguistics Volume 30, Number 4
canonical transitions as follows:
0 : Continue > 1 : {Retain | Smooth Shift} > 2 : {Rough Shift | No Cb}
Any relative weighting or ranking of coherence over salience would need to be mo-
tivated by evidence that Retain is preferred over Smooth Shift, and we are not aware
of any conclusive evidence of this in the literature (see Kipple [1999] for further dis-
cussion).
This approach also means that Strube and Hahn?s (1999) principle of cheapness
can be naturally incorporated as an additional constraint: This is a requirement that
Cp(Un?1) = Cb(Un). The principle of cheapness effectively cashes out the informal
definition of the Cp as ?represent[ing] a prediction about the Cb of the following
utterance? (Walker, Joshi, and Prince, 1998b, page 3). In classic variants of centering
theory, this happens only indirectly as a result of transition preferences, and only
following a Continue or Smooth Shift, since the Cp is also the Cb and Rule 2 predicts
that the preferred transition will maintain the same Cb. However, the prediction is
not entailed by the theory following a Retain, Rough Shift, or no-Cb transition or
indeed for the first sentence in a discourse, when there is effectively no prediction
concerning the Cp. Strube and Hahn claim that the cheapness principle is motivated
by the existence of Retain-Shift patterns, which are evidently a common means of
introducing a new topic (see also Brennan, Friedman, and Pollard 1987 [henceforth
BFP]). To summarize, our system incorporates the following constraints:
cohesion: Cb(Un?1) = Cb(Un)
salience: Cp(Un) = Cb(Un)
cheapness: Cp(Un?1) = Cb(Un)
continuity: Cfs(Un?1) ? Cfs(Un) = ?
2.5 Preferences: Transitions, Pairs, or Sequences?
The original version of GJW?s Rule 2 specified that sequences of Continue transitions
are preferred over sequences of Retains, and so on; in BFP?s implementation, how-
ever, transitions are evaluated incrementally and the preference applies to individ-
ual transitions such as Continue versus Retain rather than to sequences. Strube and
Hahn (1999) take an intermediate position: In their formulation, pairs of transitions
??Ui, Uj?, ?Uj, Uk?? are preferred that are cheap, that is, Cp(Uj) = Cb(Uk). Strube and
Hahn intended the preference for cheap transition pairs to replace GJW?s Rule 2 in
toto, which seems a rather weak requirement. On the other hand the original GJW
formulation is difficult to verify, since as Poesio et al (2002, page 66) found, sequences
of multiple occurrences of the same transition type turn out to be relatively rare.
Our position is a little more complex, as we do not directly aim to generate particular
transitions or sequences of transitions but to minimize violations of the constraints con-
tinuity, cohesion, salience, and cheapness. Violations are computed on individual nodes
and summed for each candidate text structure, so we may expect that the candidate
with the fewest violations will have a preponderance of the preferred transitions. The
system is certainly more slanted toward global optimization than BFP?s incremental
model but may be said to achieve this in a more natural way than a strategy of trying
to produce uniform sequences of transitions.
2.6 Pronominalization
GJW?s Rule 1 is rather weak as a guide to pronominalization decisions in general, as
it only mentions the Cb and gives little guidance on when or whether to pronomi-
407
Kibble and Power Optimizing Referential Coherence
nalize non-Cbs. An important consideration for NLG is to minimize the possibility of
ambiguity, and so we adopt a cautious strategy: The user can choose between invari-
ably pronominalizing the Cb or using a fairly simple algorithm based on parallelism
of grammatical roles. A possible future development is to supplement our CT-based
text planner with a more sophisticated pronominalization algorithm as proposed by
Henschel, Cheng, and Poesio (2000) or Callaway and Lester (2002).
3. Generation Issues
CT has developed primarily in the context of natural language interpretation, focussing
on anaphora resolution (see, e.g., Brennan, Friedman, and Pollard 1987). As stated
above, the novel contribution of this article is an integrated treatment of pronomi-
nalization and planning, aiming to determine whether the principles underlying the
constraints and rules of the theory can be ?turned round? and used as planning oper-
ators for generating coherent text. We have assumed some familiarity in the foregoing
with terms such as text planning and sentence planning. These are among the distinct
tasks identified in Reiter?s ?consensus architecture? for natural language generation
(Reiter 1994):
Text planning/content determination: deciding the content of a message and or-
ganizing the component propositions into a text structure (typically a tree)
Sentence planning: aggregating propositions into clausal units and choosing lex-
ical items corresponding to concepts in the knowledge base; this is the
level at which the order of arguments and choice of referring expressions
will be determined
Linguistic realization: surface details such as agreement and orthography
Reiter observed that these functions can often be identified with discrete modules
in applied NLG systems and that a de facto standard had emerged in which these
modules are organized in a pipeline such that data flows only in one direction and
only between consecutive modules.
Breaking down the generation task in this way makes it evident that there are var-
ious ways the distinct principles of CT can be incorporated. Continuity and cohesion
naturally come under text planning: respectively, ordering a sequence of utterances to
ensure that each has a backward-looking center and maintaining the same entity as
the center within constraints on ordering determined by discourse relations. Salience
and cheapness, on the other hand, would come under sentence planning, since in each
case a particular entity is to be realized as subject. However, we encounter an appar-
ent paradox in that identifying the center itself depends on grammatical salience as
determined by the sentence planner: for example, choice of active or passive voice.
Consequently, the text planner appears to rely on decisions made at the sentence-
planning level, which is incompatible with the fact that ?pipelined systems cannot
perform general search over a decision space which includes decisions made in more
than one module? (Reiter 2000, page 252).
We can envisage three possibilities for incorporating CT into a generation archi-
tecture:
1. ?Incremental? sentence-by-sentence generation, in which the syntactic structure
of Un is determined before the semantic content of Un+1 is planned. That is, the text
planner would plan the content of Un+1 by aiming to realize a proposition in the
knowledge base which mentions an entity which is salient in Un. We are not aware
408
Computational Linguistics Volume 30, Number 4
Figure 1
Rhetorical structure.
of any system which performs all stages of generation in a sentence-by-sentence way,
and in any case this type of architecture would not allow for global planning over
multisentence sequences, which we take to be essential for a faithful implementation
of centering.
2. A pipelined system in which the ?topic? or ?theme? of a sentence is desig-
nated independently as part of the semantic input and centering rules reflect the
information structure of a discourse. Prince (1999) notes that definitions of topic in
the literature do not provide objective tests for topichood and proposes that the
topic should be identified with the center of attention as defined by CT; however,
what would be needed here would be a more fundamental definition that would ac-
count for a particular entity?s being chosen to be the center of attention in the first
place.
3. The solution we adopt is to treat the task of identifying Cbs and Cps as an
optimization problem. We assume that certain options for syntactic realization can be
predicted on the basis of the argument structure of predicates, which means that cen-
tering constructs can be calculated as part of text planning before syntactic realization
takes place, so that the paradox noted above is resolved. Pronominalization decisions
are deferred until a point at which grammatical relations and word order have been
fixed.
4. Generation as Constraint Satisfaction
In this section we give an overview of our text-planning component in order to set the
implementation of CT in context. The methodology is more fully described by Power,
Scott, and Bouayad-Agha (2003).
The text planner was developed within Iconoclast, a project that investigated
applications of constraint-based reasoning in natural language generation using as sub-
ject matter the domain of medical information leaflets. Following Scott and de Souza
(1990), we represent rhetorical structure by graphs like Figure 1, in which nontermi-
nal nodes represent RST relations, terminal nodes represent propositions, and linear
order is unspecified. The task of the text planner is to realize the rhetorical structure
as a text structure in which propositions are ordered, assigned to textual units (e.g.,
sentences, paragraphs, vertical lists), and linked where appropriate by discourse con-
nectives (e.g., since, however). The boundary between text and sentence planning is
drawn at the realization of elementary propositions rather than at the generation of
individual sentences. If a rhetorical subtree is realized as a complex sentence, the effect
409
Kibble and Power Optimizing Referential Coherence
is that ?text planning? trespasses into the higher-level syntax of the sentence, leaving
only the elementary propositions to be realized by ?sentence planning.?3
Even for a simple rhetorical input like figure 1, many reasonable text structures
can be generated. Since there are two nucleus-satellite relations, the elementary propo-
sitions can be ordered in four ways. Several discourse connectives can be employed
to realize each rhetorical relation (e.g., concession can be realized by although, but, and
however). At one extreme, the text can be spread out over several paragraphs, while at
the other extreme, it can be squeezed into a single sentence. With fairly restrictive con-
straint settings, the system generates 24 text structure patterns for figure 1, including
the following (shown schematically):
A. Since contain(elixir, gestodene), ban(fda, elixir).
However, approve(fda, elixirplus).
B. approve(fda, elixirplus), although since contain(elixir, gestodene),
ban(fda, elixir).
The final output texts will depend on how the propositions are realized syntactically;
among other things, this will depend on centering choices within each proposition.
In outline, the procedure that we propose is as follows:
1. Enumerate all text structures that are acceptable realizations of the
rhetorical structure.
2. For each text structure, enumerate all permissible choices for the Cb and
Cp of each proposition.
3. Evaluate the solutions, taking account of referential coherence among
other considerations, and choose the best.
For the example in figure 1, centers can be assigned in four ways for each text structure
pattern, making a total of 96 solutions.
As will probably be obvious, such a procedure could not be applied for rhetorical
structures with many propositions. For examples of this kind, based on the relations
cause and concession (each of which can be marked by several different connectives), we
find that the total number of text structures is approximately 5N?1 for N propositions.
Hence with N = 5, we would expect around 600 text structures; with perhaps five
to ten ways of assigning centers to each text structure, the total number of solutions
would approximate to 5,000. Global optimization of the solution therefore becomes
impracticable for texts longer than about five propositions; we address this problem
by a technique of partial optimization in which a high-level planner fixes the large-
scale structure of the text, thus defining a set of local planning problems, each small
enough to be tackled by the methods described here.
Stage 1 of the planning procedure is described in more detail by Power, Scott,
and Bouayad-Agha (2003). A brief summary follows, after which we focus on stages 2
and 3, in which the text planner enumerates the possible assignments of centers and
evaluates which is the best.
3 See Power, Scott, and Bouayad-Agha (2003) for detailed motivation of this concept of text structure as a
level of representation distinct from both rhetorical structure and syntactic structure.
410
Computational Linguistics Volume 30, Number 4
4.1 Generating and Evaluating Text Structures
A text structure is defined in Iconoclast as an ordered tree in which each node has a
feature named text?level. Values of text?level are represented by integers in the
range 0 . . .Lmax; these may be interpreted in various ways, but we will assume here
that Lmax = 4 and that integers are paired with descriptive labels as follows:
0 text phrase
1 text clause
2 text sentence
3 paragraph
4 section
Informally, a text structure (TS) is well-formed if it respects the hierarchy of textual
levels, so that sections are composed of paragraphs, paragraphs of text sentences,
and so forth. An example of an ill-formed structure would be one in which a text
sentence contained a paragraph; such a structure can occur only when the paragraph
is indented?a possibility we are excluding here. As well as being a well-formed text
structure, a candidate solution must realize a rhetorical structure (RS) ?correctly,? in
a sense that we need to make precise. Roughly, a correct solution should satisfy three
conditions:
1. The terminal nodes of the TS should express all the elementary
propositions in the RS; they may also contain discourse connectives
expressing rhetorical relations in the RS, although for some relations
discourse connectives are optional.
2. The TS must respect rules of syntax when it combines propositions and
discourse connectives within a text clause; for instance, a conjunction
such as but linking two text phrases must be coordinated with the
second one.
3. The TS must be structurally compatible with the RS.
The first two conditions are straightforward, but what is meant by ?structural compat-
ibility?? We suggest the crucial criterion for such compatibility should be as follows:
Any grouping of the elementary propositions in the TS must also occur in the RS. In
other words, the text structurer is allowed to eliminate groupings, but not to add any.
More formally:
? If a node in the TS dominates terminal nodes expressing a set of
elementary propositions, there must be a corresponding node in the RS
dominating the same set of propositions.
? The converse does not hold: For instance, an RS of the form
R1(R2(p1, p2), p3) can be realized by a paragraph of three sentences, one
for each proposition, even though this TS contains no node dominating
the propositions p1 and p2 that are grouped by R2. However, when this
happens, the propositions grouped together in the RS must remain
consecutive in the TS; solutions in which p3 comes in between p1 and p2
are prohibited.
411
Kibble and Power Optimizing Referential Coherence
Table 2
Examples of text-structuring constraints.
Name Type Description
Root domination Hard The text?level of the root node r must exceed
Lp > Ld that of any daughter d.
Parental domination Hard The text?level of a parent node p must be equal to
Lp ? Ld or greater than the text?level of any daughter d.
Sister equality Hard If nodes a and b are descended from the same
La = Lb parent, they must have the same text?level.
Sister order Hard If nodes a and b are descended from the same
Oa = Ob parent, they must have different values of order.
Connective Hard Governs choice of discourse connective.
Rhetorical grouping Soft Failure to express a rhetorical grouping can be
treated as a defect.
Oversimple paragraph Soft A paragraph containing only one text sentence can
be treated as a defect.
Centering Soft Constraints derived from centering theory.
Our procedure for generating candidate solutions is based on a technique for for-
mulating text structuring as a constraint satisfaction problem (CSP) (van Hentenryck,
1989), using the Eclipse logic programming environment.4 In general, a CSP is char-
acterized by the following elements:
? a set of variables V1 . . .VN
? For each variable Vi, a finite domain Di of possible values
? a set of constraints on the values of the variables (for integer domains
these often use ?greater than? and ?less than?; other domains usually
rely on ?equal? or ?unequal?.)
A solution assigns to each variable Vi a value from its domain Di while respecting
all constraints. For instance each node of the rhetorical structure is annotated with
a text?level variable with the domain 0 . . .Lmax and an order variable with the
domain 1 . . .N, where N is the number of sisters. Depending on the constraints, there
may be multiple solutions, or there may be no solution at all. We distinguish between
hard constraints, which are applied during the enumeration phase, determining which
candidate structures will be considered, and soft constraints, which apply during an
evaluation phase in which the enumerated solutions are ordered from best to worst.
Some examples of hard and soft constraints are shown in Table 2.
4.2 Choosing Centers
Given a text structure, we enumerate all permissible centering assignments as follows:
1. Determine the predecessor Un?1 (if any) of each proposition Un.
2. List the potential Cbs and Cps of each proposition (henceforth denoted
by ?Cb and ?Cp).
4 See http://www-icparc.doc.ic.ac.uk/eclipse/.
412
Computational Linguistics Volume 30, Number 4
Table 3
Cbs and Cps for solution A.
U Proposition ?Cb(U) ?Cp(U)
U1 contain(elixir, gestodene) [ ] [elixir]
U2 ban(fda, elixir) [elixir] [fda, elixir]
U3 approve(fda, elixir-plus) [fda] [fda, elixir-plus]
3. Compute all combinations from ?Cb and ?Cp that respect the
fundamental centering constraint that Cb(Un) should be the most salient
candidate in Un?1.
As stated earlier, two criteria for determining the predecessor have been implemented;
the user can select one or the other criterion, thus using the NLG system to test different
approaches. Following a linear criterion, the predecessor is simply the proposition that
precedes the current proposition in the text, regardless of structural considerations.
Following a hierarchical criterion, the predecessor is the most accessible previous
proposition, in the sense defined by Veins Theory (Cristea, Ide, and Romary, 1998).
For now we assume the criterion is linear.
?Cb(Un) (potential Cbs of proposition Un) is given by the intersection between
Cf (Un) and Cf (Un?1)?that is, all the referents they have in common. The potential
Cps are those referents in the current proposition that can be realized as most salient.
Obviously this should depend on the linguistic resources available to the generator; the
system actually uses a simpler rule based on argument types within the proposition.
Table 3 shows the potential Cbs and Cps for the proposition sequence in solution A pre-
sented at the beginning of this section. As stated earlier, our treatment of salience here
simplifies in two ways: We assume that syntactic realization serves only to distinguish
the Cp from all other referents and that the system already knows, from the argument
structure of the proposition, which entities can occur in subject position. With these
simplifications, the enumeration of centering assignments is straightforward; in the
above example, four combinations are possible, since there are two choices each for
Cp(U2) and Cp(U3).
4.3 Evaluating Solutions
The system evaluates candidate solutions by applying a battery of tests to each node of
the text plan. Each test identifies whether the node suffers from a particular defect. For
instance, one stylistic defect (at least for the rhetorical relations occurring in figure 1)
is that of placing nucleus before satellite; in general, the text reads better if important
material is placed at the end. For each type of defect, we specify a weight indicating
its importance: In evaluating continuity of reference, for example, the defect ?no Cb?
is regarded as more significant than other defects. Other violations are recorded only
in the case in which a Cb is present, so if all violations were weighted equally, this
could result in a ?no-Cb? transition?s being treated as less serious than an ?expensive?
Smooth Shift, for example (violating cheapness and cohesion). Summing the weighted
costs for all defects, we obtain a total cost for the solution; our aim is to find the
solution with the lowest total cost.
Regarding centering, the tests currently applied are as follows:
Salience violation: A proposition Un violates salience if Cb(Un) = Cp(Un). This
defect is assessed only on propositions that have a backward-looking cen-
ter.
413
Kibble and Power Optimizing Referential Coherence
Cohesion violation: A transition ?Un?1, Un? violates cohesion if Cb(Un) =
Cb(Un?1). This defect is not recorded when either Un or Un?1 has no Cb.
Cheapness violation: A transition ?Un?1, Un? violates cheapness if Cb(Un) =
Cp(Un?1). This defect is assessed only on propositions that have a
backward-looking center.
Continuity violation: This defect is recorded for any proposition with no Cb,
except the first proposition in the sequence (which by definition cannot
have a Cb).
Relative weightings for these defects can be chosen by the user; for the current exam-
ples we have chosen a neutral scheme with a weight of 3 for continuity violations and
1 each for the others, so that a no-Cb transition is ranked equally bad as an ?expen-
sive? Rough Shift.5 Applied to the four solutions to text structures A and B presented
in this section, these definitions yield costs shown in Table 4. According to our metric,
solutions A1 and A2 should be preferred because they incur less cost than any others,
with B3 and B4 the least preferred.
Although this article focuses on centering issues, it is important to remember that
other aspects of text quality are evaluated at the same time: The aim is to compute a
global measure so that disadvantages in one factor can be weighed against advantages
in another. For instance, text pattern B is bound to yield poor continuity of reference
because it orders the propositions so that U1 and U2 have no referents in common.
Text pattern A avoids this defect, but this does not automatically mean that A is better
than B; there may be other reasons, unconnected with centering, for preferring B to
A. The constraints which have an effect on clause ordering include:
Satellite before nucleus: For nucleus-satellite relations, place the satellite before
the nucleus.
Right-branching structure: If an elementary proposition is coordinated with a
complex rhetorical structure, place the elementary proposition first.
Centering constraints: Penalize orderings which violate centering preferences.
Text pattern B is favored by ?right-branching structure,? but in this case the centering
constraints will ?conspire? with ?satellite before nucleus? to favor pattern A overall.
5. Conclusion
We have described a technique for generating texts which will be coherent according
to a reasonably faithful interpretation of centering theory. NLG systems need some
principled means of deciding on the preferred orderings of clauses and of arguments
within clauses, and CT appears a good candidate to provide a basis for these decisions,
in tandem with other stylistic considerations. We have reported on a particular imple-
mentation in the Iconoclast document generation system, but the technique can be
applied to other NLG systems that perform hierarchical text structuring based on a
theory of coherence relations (with additional assumptions as detailed in Section 1):
? For systems which generate a single text plan, CT can determine the
most coherent ordering of arguments within clauses.
5 See Kibble and Power (2004) for initial results of empirical research on constraint weightings.
414
Computational Linguistics Volume 30, Number 4
Table 4
Realizations of text patterns A and B, with weights: cohesion | salience | cheapness = 1,
continuity = 3.
Version Text Cb Cp Defects Sum
Since Elixir contains gestodene ? elixir none
A1 the FDA bans Elixir. elixir fda sal 2
However, it approves Elixir+. fda fda coh
Since Elixir contains gestodene ? elixir none
A2 it is banned by the FDA. elixir elixir none 2
However, the FDA approves Elixir+. fda fda coh, ch
Since Elixir contains gestodene ? elixir none
A3 the FDA bans Elixir. However, elixir fda sal 3
Elixir+ is approved by the FDA. fda elixir+ sal, coh
Since Elixir contains gestodene ? elixir none
A4 it is banned by the FDA. However, elixir elixir none 3
Elixir+ is approved by the FDA. fda elixir+ sal, coh, ch
The FDA approves Elixir+ although ? fda none
B1 since Elixir contains gestodene ? elixir cont 3
it is banned by the FDA. elixir elixir none
Elixir+ is approved by the FDA ? elixir+ none
B2 although since Elixir contains gestodene ? elixir cont 3
it is banned by the FDA. elixir elixir none
The FDA approves Elixir+ although ? fda none
B3 since Elixir contains gestodene ? elixir cont 4
the FDA bans Elixir. elixir fda sal
Elixir+ is approved by the FDA ? elixir+ none
B4 although since Elixir contains gestodene ? elixir cont 4
the FDA bans Elixir. fda elixir sal
Note: ch = cohesion, coh=cohesion, cont=continuity, sal=salience.
? For systems which generate multiple text plans, CT can be used to
evaluate the different plans as well as to determine the optimal
realization of any particular plan.
We have carried out empirical studies that provide clear evidence that centering fea-
tures make a difference to the acceptability of texts and demonstrate one way to
determine weightings (Kibble and Power 2004). It may turn out that different weight-
415
Kibble and Power Optimizing Referential Coherence
ings are appropriate for different text genres or for speech as opposed to ?written?
text. Our framework will facilitate detailed research into evaluation metrics and will
therefore provide a productive research tool in addition to the immediate practical
benefit of improving the fluency and readability of generated texts.
Acknowledgments
The essential ideas of this work were
originally presented at the ACL Workshop
on Discourse Structure and Reference (1999),
the 12th Amsterdam Colloquium (1999),
and COLING 2000. An earlier version of
this article was presented at INLG 2000. We
are grateful to the audiences on those
occasions for useful feedback and also to
colleagues on the GNOME project as well
as Nikiforos Karamanis and the anonymous
reviewers for Computational Linguistics. This
work was supported in part by the U.K.
EPSRC under grant references L51126,
L77102, and M36960.
References
Beaver, David. 2004. The optimization of
discourse anaphora. Linguistics and
Philosophy, 27(1):3?56.
Brennan, Susan, Marilyn Walker Friedman,
and Carl Pollard. 1987. A centering
approach to pronouns. In Proceedings of
25th ACL, pages 155?162, Stanford, CA.
Cahill, Lynne. 1999. Lexicalisation in
applied NLG systems. Technical Report
ITRI-99-04, Information Technology
Research Institute, University of Brighton.
Callaway, Charles B. and James C. Lester.
2002. Pronominalization in generated
discourse and dialogue. In Proceedings of
the 40th Annual Meeting of the Association for
Computational Linguistics (ACL), pages
88?95, Philadelphia.
Cheng, Hua. 2000. Experimenting with the
interaction between aggregation and text
planning. In Proceedings of ANLP-NAACL,
pages 1?6, Seattle.
Cristea, Dan, Nancy Ide, and Laurent
Romary. 1998. Veins theory: A model of
global discourse cohesion and coherence.
In Proceedings of COLING/ACL?98, pages
281?285, Montreal.
Grosz, Barbara, Aravind Joshi, and Scott
Weinstein. 1995. Centering: A framework
for modelling the local coherence of
discourse. Computational Linguistics,
21(2):203?225.
Henschel, Renate, Hua Cheng, and
Massimo Poesio. 2000. Pronominalisation
revisited. In Proceedings of 18th COLING,
pages 306?312, Saarbru?cken, Germany.
Kameyama, Megumi. 1998. Intrasentential
centering: A case study. In Marilyn
Walker, Aravind Joshi, and Ellen Prince,
editors, Centering Theory in Discourse,
pages 89?112. Clarendon, Oxford.
Karamanis, Nikiforos. 2001. Exploring
entity-based coherence. In Proceedings of
Fourth CLUK, pages 18?26, University of
Sheffield, Sheffield, England.
Kibble, Rodger. 1999. Cb or not Cb?
Centering theory applied to NLG. In
Proceedings of ACL Workshop on Discourse
and Reference Structure, pages 72?81,
University of Maryland, College Park.
Kibble, Rodger. 2001. A reformulation of
rule 2 of centering theory. Computational
Linguistics, 27(4):579?587.
Kibble, Rodger. 2003. Towards the
elimination of centering theory. In Ivana
Kruijff-Korbayova? and Claudia Kosny,
editors, DiaBruck 2003: Proceedings of the
Seventh Workshop on the Semantics and
Pragmatics of Dialogue, Universita?t des
Saarlandes, Saarbru?cken, Germany.
Kibble, Rodger and Richard Power. 2004.
Optimising referential coherence as a
constraint satisfaction problem. Technical
Report RK/2004/1, Department of
Computing, Goldsmiths College, and
ITRI-04-07, Information Technology
Research Institute, University of Brighton.
Mann, William and Sandra Thompson.
1987. Rhetorical structure theory: A
theory of text organisation. Technical
Report ISI/RS-87-190, Information
Sciences Institute, Los Angeles.
Marcu, Daniel. 1996. Building up rhetorical
structure trees. In Proceedings of AAAI-96,
pages 1069?1074, Portland, OR.
Marcu, Daniel. 1997. From local to global
coherence: A bottom-up approach to text
planning. In Proceedings of AAAI-97, pages
629?635, Providence, RI.
McCoy, Kathleen and Michael Strube. 1999.
Generating anaphoric expressions:
Pronoun or definite description? In
Proceedings of ACL Workshop on Discourse
and Reference Structure, pages 63?71,
University of Maryland, College Park.
McKeown, Kathleen R. 1985. Text Generation.
Cambridge University Press, Cambridge.
Mellish, Chris, Alistair Knott, Jon
Oberlander, and Mick O?Donnell. 1998.
Experiments using stochastic search for
text planning. In Proceedings of the Ninth
International Workshop on Natural Language
416
Computational Linguistics Volume 30, Number 4
Generation, pages 97?108,
Niagara-on-the-Lake, Ontario.
Mittal, Vibhu, Johanna Moore, Giuseppe
Carenini, and Steven Roth. 1998.
Describing complex charts in natural
language: A caption generation system.
Computational Linguistics, 24(3):431?467.
Poesio, Massimo, Rosemary Stevenson, Hua
Cheng, Barbara di Eugenio, and Janet
Hitzeman. 2002. A corpus-based
evaluation of centering theory. Technical
Report TN-02-01/CSM-369, Natural
Language Engineering Group, University
of Essex.
Power, Richard. 2000. Planning texts by
constraint satisfaction. In Proceedings of
COLING 2000, pages 642?648,
Saarbru?cken, Germany.
Power, Richard, Donia Scott, and Nadjet
Bouayad-Agha. 2003. Document structure.
Computational Linguistics, 29(2):211?260.
Prince, Ellen. 1999. How not to mark topics:
?Topicalization? in English and Yiddish.
Unpublished manuscript, Linguistics
Department, University of Pennsylvania.
Reiter, Ehud. 1994. Has a consensus NL
generation architecture appeared, and is it
psycholinguistically plausible? In
Proceedings of the Seventh International
Natural Language Generation Workshop,
pages 163?170, Kennebunkport, ME.
Reiter, Ehud. 2000. Pipelines and size
constraints. Computational Linguistics,
26(2):251?259.
Scott, Donia and Clarisse de Souza. 1990.
Getting the message across in RST-based
text generation. In Robert Dale, Chris
Mellish, and Michael Zock, editors,
Current Research in Natural Language
Generation, pages 47?73. Academic Press,
London.
Strube, Michael and Udo Hahn. 1999.
Functional centering?Grounding
referential coherence in information
structure. Computational Linguistics,
25(3):309?344.
Suri, Linda, Kathleen McCoy, and Jonathan
DeCristofaro. 1999. A methodology for
extending focussing franeworks.
Computational Linguistics, 25(2):173?194.
van Hentenryck, P. 1989. Constraint
Satisfaction in Logic Programming. MIT
Press, Cambridge, MA.
Walker, Marilyn, Aravind Joshi, and Ellen
Prince, editors. 1998a. Centering Theory in
Discourse. Clarendon, Oxford.
Walker, Marilyn, Aravind Joshi, and Ellen
Prince. 1998b. Centering in naturally
occurring discourse. In Marilyn Walker,
Aravind Joshi, and Ellen Prince, editors,
Centering Theory in Discourse, pages 1?28.
Clarendon, Oxford.
From RAGS to RICHES: exploiting the potential of a flexible generation
architecture  
Lynne Cahill  , John Carroll  , Roger Evans  , Daniel Paiva  ,
Richard Power

, Donia Scott  and Kees van Deemter 

ITRI, University of Brighton
Brighton, BN2 4GJ, UK
Firstname.Lastname@itri.bton.ac.uk
 School of Cognitive and Computing Sciences, University of Sussex
Brighton, BN1 9QH, UK
johnca@cogs.susx.ac.uk
Abstract
The RAGS proposals for generic speci-
fication of NLG systems includes a de-
tailed account of data representation,
but only an outline view of processing
aspects. In this paper we introduce a
modular processing architecture with a
concrete implementation which aims to
meet the RAGS goals of transparency
and reusability. We illustrate the model
with the RICHES system ? a generation
system built from simple linguistically-
motivated modules.
1 Introduction
As part of the RAGS (Reference Architecture for
Generation Systems) project, Mellish et al(2000)
introduces a framework for the representation of
data in NLG systems, the RAGS ?data model?.
This model offers a formally well-defined declar-
ative representation language, which supports the
complex and dynamic data requirements of gen-
eration systems, e.g. different levels of repre-
sentation (conceptual to syntax), mixed represen-
tations that cut across levels, partial and shared
structures and ?canned? representations. However

We would like to acknowledge the financial support of
the EPSRC (RAGS ? Reference Architecture for Generation
Systems: grant GR/L77102 to Donia Scott), as well as the
intellectual contribution of our partners at Edinburgh (Chris
Mellish and Mike Reape: grant GR/L77041 to Mellish) and
other colleagues at the ITRI, especially Nedjet Bouayad-
Agha. We would also like to acknowledge the contribution
of colleagues who worked on the RICHES system previ-
ously: Neil Tipper and Rodger Kibble. We are grateful to
our anonymous referees for their helpful comments.
RAGS, as described in that paper, says very little
about the functional structure of an NLG system,
or the issues arising from more complex process-
ing regimes (see for example Robin (1994), Inuie
et al, (1992) for further discussion).
NLG systems, especially end-to-end, applied
NLG systems, have many functionalities in com-
mon. Reiter (1994) proposed an analysis of such
systems in terms of a simple three stage pipeline.
More recently Cahill et al(1999) attempted to re-
peat the analysis, but found that while most sys-
tems did implement a pipeline, they did not im-
plement the same pipeline ? different functional-
ities occurred in different ways and different or-
ders in different systems. But this survey did
identify a number of core functionalities which
seem to occur during the execution of most sys-
tems. In order to accommodate this result, a ?pro-
cess model? was sketched which aimed to support
both pipelines and more complex control regimes
in a flexible but structured way (see (Cahill et al,
1999),(RAGS, 2000)). In this paper, we describe
our attempts to test these ideas in a simple NLG
application that is based on a concrete realisation
of such an architecture1 .
The RAGS data model aims to promote com-
parability and re-usability in the NLG research
community, as well as insight into the organisa-
tion and processing of linguistic data in NLG. The
present work has similar goals for the processing
aspects: to propose a general approach to organis-
ing whole NLG systems in a way which promotes
1More details about the RAGS project, the
RICHES implementation and the OASYS subsys-
tem can be found at the RAGS project web site:
http://www.itri.bton.ac.uk/projects/rags.
the same ideals. In addition, we aim to test the
claims that the RAGS data model approach sup-
ports the flexible processing of information in an
NLG setting.
2 The RAGS data model
The starting point for our work here is the RAGS
data model as presented in Mellish et al(2000).
This model distinguishes the following five levels
of data representation that underpin the genera-
tion process:
Rhetorical representations (RhetReps) define how propo-
sitions within a text are related. For example, the sen-
tence ?Blow your nose, so that it is clear? can be con-
sidered to consist of two propositions: BLOW YOUR
NOSE and YOUR NOSE IS CLEAR, connected by a re-
lation like MOTIVATION.
Document representations (DocReps) encode information
about the physical layout of a document, such as tex-
tual level (paragraph, orthographic sentence, etc.),
layout (indentation, bullet lists etc.) and their relative
positions.
Semantic representations (SemReps) specify information
about the meaning of individual propositions. For
each proposition, this includes the predicate and its
arguments, as well as links to underlying domain ob-
jects and scoping information.
Syntactic representations (SynReps) define ?abstract?
syntactic information such as lexical features (FORM,
ROOT etc.) and syntactic arguments and adjuncts
(SUBJECT, OBJECT etc.).
Quote representations These are used to represent literal
unanalysed content used by a generator, such as
canned text, pictures or tables.
The representations aim to cover the core com-
mon requirements of NLG systems, while avoid-
ing over-commitment on less clearly agreed is-
sues relating to conceptual representation on the
one hand and concrete syntax and document ren-
dering on the other. When one considers process-
ing aspects, however, the picture tends to be a lot
less tidy: typical modules in real NLG systems
often manipulate data at several levels at once,
building structures incrementally, and often work-
ing with ?mixed? structures, which include infor-
mation from more than one level. Furthermore
this characteristic remains even when one consid-
ers more purely functionally-motivated ?abstract?
NLG modules. For example, Referring Expres-
sion Generation, commonly viewed as a single
task, needs to have access to at least rhetorical and
document information as well as referencing and
adding to the syntactic information.
To accommodate this, the RAGS data model in-
cludes a more concrete representational proposal,
called the ?whiteboard? (Calder et al, 1999), in
which all the data levels can be represented in
a common framework consisting of networks of
typed ?objects? connected by typed ?arrows?. This
lingua franca allows NLG modules to manipulate
data flexibly and consistently. It also facilitates
modular design of NLG systems, and reusability
of modules and data sets. However, it does not in
itself say anything about how modules in such a
system might interact.
This paper describes a concrete realisation of
the RAGS object and arrows model, OASYS,
as applied to a simple but flexible NLG system
called RICHES. This is not the first such re-
alisation: Cahill et al, (2000) describes a par-
tial re-implementation of the ?Caption Generation
System? (Mittal et al, 1999) which includes an
objects and arrows ?whiteboard?. The OASYS
system includes more specific proposals for pro-
cessing and inter-module communication, and
RICHES demonstrates how this can be used to
support a modular architecture based on small
scale functionally-motivated units.
3 OASYS
OASYS (Objects and Arrows SYStem) is a soft-
ware library which provides:
  an implementation of the RAGS Object and
Arrows (O/A) data representation,
  support for representing the five-layer RAGS
data model in O/A terms,
  an event-driven active database server for
O/A representations.
Together these components provide a central core
for RAGS-style NLG applications, allowing sepa-
rate parts of NLG functionality to be specified in
independent modules, which communicate exclu-
sively via the OASYS server.
The O/A data representation is a simple
typed network representation language. An O/A
database consists of a collection of objects, each
of which has a unique identifier and a type, and
arrows, each of which has a unique identifier,
a type, and source and target objects. Such a
database can be viewed as a (possibly discon-
nected) directed network representation: the fig-
ures in section 5 give examples of such networks.
OASYS pre-defines object and arrow types re-
quired to support the RAGS data model. Two ar-
row types, el (element) and el(<integer>),
are used to build up basic network structures ?
el identifies its target as a member of the set rep-
resented by its source, el(3), identifies its tar-
get as the third element of the tuple represented
by its source. Arrow type realised by re-
lates structures at different levels of representa-
tion. for example, indicating that this SemRep
object is realised by this SynRep object. Arrow
type revised to provides for support for non-
destructive modification of a structure, mapping
from an object to another of the same type that
can be viewed as a revision of it. Arrow type
refers to allows an object at one level to indi-
rectly refer to an object at a different level. Object
types correspond to the types of the RAGS data
model, and are either atomic, tuples, sets or se-
quences. For example, document structures are
built out of DocRep (a 2-tuple), DocAttr (a set
of DocFeatAtoms ? feature-value pairs), DocRe-
pSeq (a sequence of DocReps or DocLeafs) and
DocLeafs.
The active database server supports multiple
independent O/A databases. Individual modules
of an application publish and retrieve objects and
arrows on databases, incrementally building the
?higher level?, data structures. Modules com-
municate by accessing a shared database. Flow
of control in the application is event-based: the
OASYS module has the central thread of execu-
tion, calls to OASYS generate ?events?, and mod-
ules are implemented as event handlers. A mod-
ule registers interest in particular kinds of events,
and when those events occur, the module?s hander
is called to deal with them, which typically will
involve inspecting the database and adding more
structure (which generates further events).
OASYS supports three kinds of events: pub-
lish events occur whenever an object or arrow is
published in a database, module lifecycle events
occur whenever a new module starts up or termi-
nates, and synthetic events ? arbitrary messages
passed between the modules, but not interpreted
by OASYS itself ? may be generated by mod-
ules at any time. An application starts up by ini-
tialising all its modules. This generates initialise
events, which at least one module must respond
to, generating further events which other modules
may respond to, and so on, until no new events
are generated, at which point OASYS generates
finalise events for all the modules and terminates
them.
This framework supports a wide range of archi-
tectural possibilities. Publish events can be used
to make a module wake up whenever data of a
particular sort becomes available for processing.
Lifecycle events provide, among other things, an
easy way to do pipelining: the second module in a
pipeline waits for the finalise event of the first and
then starts processing, the third waits similarly
for the second to finalise etc. Synthetic events
allow modules to tell each other more explicitly
that some data is ready for processing, in situa-
tion where simple publication of an object is not
enough.
RICHES includes examples of all three
regimes: the first three modules are pipelined us-
ing lifecycle events; LC and RE, FLO and REND
interact using synthetic events; while SF watches
the database specifically for publication events.
4 RICHES
The RICHES system is a simple generation sys-
tem that takes as input rhetorical plans and pro-
duces patient advice texts. The texts are intended
to resemble those found at the PharmWeb site
(http://www.pharmweb.net). These are
simple instructional texts telling patients how to
use certain types of medicines, such as nosedrops,
eye drops, suppositories etc.. An example text
from PharmWeb is shown in figure 1, alongside
the corresponding text produced by RICHES.
The main aim of RICHES is to demonstrate
the feasibility of a system based on both the RAGS
data model and the OASYS server model. The
modules collectively construct and access the data
representations in a shared blackboard space and
this allows the modules to be defined in terms of
their functional role, rather than say, the kind of
data they manipulate or their position in a pro-
cessing pipeline. Each of the modules in the sys-
 How to Use Nose Drops
1. Blow your nose gently, so that it is clear. 
  
2. Wash your hands. 
  
3. Unscrew the top of the bottle and draw some liquid into the dropper. 
  
4. Tilt your head back. 
  
5. Hold the dropper just above your nose and put the correct number of drops into your nostril. 
  
6. DO NOT let the dropper touch the inside of your nose. 
  
7. Keep your head tilted back for two to three minutes to help the drops run to the back of your nose. 
  
8. Replace the top on the bottle. 
 
KEEP ALL MEDICINES OUT OF THE REACH OF CHILDREN 
PharmWeb - Copyright?1994-2001. All rights reserved
  
  
Blow your nose so that it is clear. 
Wash your hands
Unscrew the top. Then draw the liquid into the dropper. 
Tilt your head back
Hold the dropper above your nose. Then put the drops into your nostril.
The dropper must not touch the inside.
Keep your head tilted back for two to three minutes so that the drops run to the back.
Replace the top on the bottle
Generated by RICHES version 1.0 (9/5/2001) on 9/5/2001 
?2001, ITRI, University of Brighton 
Figure 1: An example text from PharmWeb, together with the corresponding text generated by RICHES
tem is in itself very simple ? our primary interest
here is in the way they interact.
Figure 2 shows the structure of the system2.
The functionality of the individual modules is
briefly described below.
Rhetorical Oracle (RO) The input to the sys-
tem is a RhetRep of the document to be gen-
erated: a tree with internal nodes labelled with
(RST-style) rhetorical relations and RhetLeaves
referring to semantic proposition representations
(SemReps). RO simply accesses such a represen-
tation from a data file and initialises the OASYS
database.
Media Selection (MS) RICHES produces doc-
uments that may include pictures as well as text.
As soon as the RhetRep becomes available, this
module examines it and decides what can be il-
lustrated and what picture should illustrate it. Pic-
2The dashed lines indicate flow of information, solid ar-
rows indicate approximately flow of control between mod-
ules, double boxes indicate a completely reused module
(from another system), while a double box with a dashed
outer indicates a module partially reused. Ellipses indicate
information sources, as opposed to processing modules.
tures, annotated with their SemReps, are part of
the picture library, and Media Selection builds
small pieces of DocRep referencing the pictures.
Document Planner (DP) The Document Plan-
ner, based on the ICONOCLAST text planner
(Power, 2000) takes the input RhetRep and pro-
duces a document structure (DocRep). This
specifies aspects such as the text-level (e.g.,
paragraph, sentence) and the relative or-
dering of propositions in the DocRep. Its
leaves refer to SynReps corresponding to syntac-
tic phrases. This module is pipelined after MS,
to make sure that it takes account of any pictures
that have been included in the document.
Lexical Choice (LC) Lexical choice happens in
two stages. In the first stage, LC chooses the lex-
ical items for the predicate of each SynRep. This
fixes the basic syntactic structure of the proposi-
tion, and the valency mapping between semantic
and syntactic arguments. At this point the ba-
sic document structure is complete, and the LC
advises REND and SF that they can start pro-
cessing. LC then goes into a second phase, in-
TEXT
SENTENCE
RHETORICAL 
ORACLE
LEXICAL
FINALISER
RENDERER
LINGO
PICTURE
LIBRARY
SELECTION
MEDIUM FLO
LEXICON
CHOICE
OASYS
REFERRING
EXPRESSIONS
DOCUMENT
PLANNER
Figure 2: The structure of the RICHES system
terleaved with RE and FLO: for each sentence,
RE determines the referring expressions for each
noun phrase, LC then lexicalises them, and when
the sentence is complete FLO invokes LinGO to
realise them.
Referring Expressions (RE) The Referring
Expression module adapts the SynReps to add in-
formation about the form of a noun phrase. It de-
cides whether it should be a pronoun, a definite
noun phrase or an indefinite noun phrase.
Sentence Finaliser (SF) The Sentence Fi-
naliser carries out high level sentential organisa-
tion. LC and RE together build individual syntac-
tic phrases, but do not combine them into whole
sentences. SF uses rhetorical and document struc-
ture information to decide how to complete the
syntactic representations, for example, combin-
ing main and subordinate clauses. In addition, SF
decides whether a sentence should be imperative,
depending on who the reader of the document is
(an input parameter to the system).
Finalise Lexical Output (FLO) RICHES uses
an external sentence realiser component with its
own non-RAGS input specification. FLO provides
the interface to this realiser, extracting (mostly
syntactic) information from OASYS and convert-
ing it to the appropriate form for the realiser. Cur-
rently, FLO supports the LinGO realiser (Carroll
et al, 1999), but we are also looking at FLO mod-
ules for RealPro (Lavoie and Rambow, 1997) and
FUF/SURGE (Elhadad et al, 1997).
Renderer (REND) The Renderer is the module
that puts the concrete document together. Guided
by the document structure, it produces HTML for-
matting for the text and positions and references
the pictures. Individual sentences are produced
for it by LinGO, via the FLO interface. FLO actu-
ally processes sentences independently of REND,
so when REND makes a request, either the sen-
tence is there already, or the request is queued,
and serviced when it becomes available.
LinGO The LinGO realiser uses a wide-
coverage grammar of English in the LKB HPSG
framework, (Copestake and Flickinger, 2000).
The tactical generation component accepts in-
put in the Minimal Recursion Semantics formal-
ism and produces the target text using a chart-
driven algorithm with an optimised treatment of
modification (Carroll et al, 1999). No domain-
specific tuning of the grammar was required for
the RICHES system, only a few additions to the
lexicon were necessary.
5 An example: generation in RICHES
In this section we show how RICHES generates
the first sentence of the example text, Blow your
nose so that it is clear and the picture that accom-
panies the text.
The system starts with a rhetorical represen-
tation (RhetRep) provided by the RO (see Fig-
ure 3)3. The first active module to run is MS
3In the figures, labels indicate object types and the sub-
script numbers are identifiers provided by OASYS for each
which traverses the RhetRep looking at the se-
mantic propositions labelling the RhetRep leaves,
to see if any can be illustrated by pictures in the
picture library. Each picture in the library is en-
coded with a semantic representation. Matching
between propositions and pictures is based on the
algorithm presented in Van Deemter (1999) which
selects the most informative picture whose repre-
sentation contains nothing that is not contained in
the proposition. For each picture that will be in-
cluded, a leaf node of document representation is
created and a realised by arrow is added to it
from the semantic proposition object (see Figure
4).
  	


  



el(1) el(2)
  		
(motivation)
  	ffWysiwym with wider coverage
Richard Power and Roger Evans
Information Technology Research Institute
University of Brighton
Lewes Road
Brighton BN2 4AT, UK
Firstname.Lastname@itri.bton.ac.uk
Abstract
We describe an extension of the Wysiwym
technology for knowledge editing through nat-
ural language feedback. Previous applications
have addressed relatively simple tasks requiring
a very limited range of nominal and clause pat-
terns. We show that by adding a further editing
operation called reconfiguration, the technology
can achieve a far wider coverage more in line
with other general-purpose generators. The ex-
tension will be included in a Java-based library
package for producing Wysiwym applications.
1 Introduction
Wysiwym (What You See Is What You Meant)
is a user-interface technology through which a
domain expert can formally encode knowledge
by structured editing of an automatically gener-
ated feedback text (Power and Scott, 1998). The
technology has hitherto addressed two practical
contexts: the automatic production of multilin-
gual technical documentation, and the formula-
tion of queries to a database or expert system.
In the first case, Wysiwym editing encodes the
desired content of the document in an interlin-
gua, from which versions can be generated in
mutliple languages; in the second case, it yields
a query encoded in a formal query language such
as SQL. The benefit is the same in either con-
text: since editing is mediated through a presen-
tation in natural language, there is no need for
the user to be acquainted with the formal details
of knowledge representation or query languages.
Elsewhere (Evans and Power, 2003) we have
described a library package for developing
Wysiwym applications. This package was a
consolidation of work carried out in a series of
early applications (Power and Scott, 1998; Pi-
wek et al, 2000; Bouayad-Agha et al, 2002),
requiring a very restricted linguistic coverage,
especially as regards the range of clausal and
nominal patterns. We present here an exten-
sion to this library which allows a coverage
more in line with general-purpose generators
like FUF/SURGE (Elhadad and Robin, 1992),
KPML/PENMAN (Bateman, 1996) and Real-
Pro (Lavoie and Rambow, 1997). The exten-
sion is based on two new ideas: first, a change
to the underlying semantic model, replacing
atomic entity types with feature structures; sec-
ondly, a corresponding change in the user inter-
face, which now offers an extra editing operation
(called reconfiguration) through which complex
entity types may be modified. The purpose of
this paper (and the accompanying demonstra-
tion) is to describe these novelties.
2 Editing with simple types
take
patient
aspirin
ARG?1
ARG?2
Figure 1: A-box with simple types
In early Wysiwym applications, the editing
process served to build an A-box like that shown
in figure 1, comprising a set of entities (repre-
sented by rectangles), each entity having a sim-
ple type (represented by labels within rectan-
gles) and a set of relationships (represented by
labelled arcs). The graph in this figure is rooted
in a take entity, denoting a taking event, the
participants being a patient entity (the taker)
and an an aspirin entity (the takee). The in-
tended meaning of the graph is expressed by the
English sentence ?the patient takes an aspirin?.
The construction of the graph through Wysi-
wym editing proceeds as follows. The starting
point is an empty A-box, which consists only
in a constraint on the root entity ? for in-
stance, the requirement that it should be some
kind of event. This unpromising A-box is sup-
plied as input to a natural language generator
with two special features: (a) it can generate
texts from an A-box in any state of completion
(even empty); (b) it can generate menus open-
ing on anchors within the text, in addition to
the text itself. The resulting feedback text is
presented to the user through a special interface
in which some spans are mouse-sensitive an-
chors, marking points where a new entity may
be added to the A-box. Anchors are normally
shown through a colour code; here we will em-
ploy square brackets:
[Some event].
When the user mouse-clicks on an anchor, a
menu pops up listing all entity types allowed
in the relevant context ? in this case, all event
types.
arrive
breathe
. . .
take
. . .
After the user chooses one of these options, such
as ?take?, a new entity of the specified type is
created, and added to the A-box at the current
location (in this case, the root of the graph). As-
suming the ontology decrees that a take event
has two participants, a person and an object,
the new A-box will include two anchors allow-
ing these entities to be defined:
[Some person] takes [some object].
Opening the anchor ?some person? will yield a
list of options including ?patient?; opening ?some
object? will yield options including ?an aspirin?;
in this way two more entities can be introduced,
so obtaining the complete graph in figure 1.
3 Limitations in coverage
For some applications, the above procedure
works well, but it allows far too few variations to
cope with real documents or queries of normal
linguistic complexity. A single choice of event
type (?take?) is assumed by default to imply just
one out of the thousands of possible clause pat-
terns that could be obtained by varying mood,
tense, polarity, modality, etc., or by adding ad-
verbial modifiers:
force
does the patient take an aspirin?
take an aspirin
time
the patient took an aspirin
the patient will take an aspirin
polarity
the patient does not take an aspirin
modality
the patient may take an aspirin
the patient must take an aspirin
the patient might take an aspirin
the patient should take an aspirin
modifier
the patient takes an aspirin [at some time]
the patient takes an aspirin [somewhere]
the patient takes an aspirin [in some manner]
the patient takes an aspirin [with some frequency]
By combining just the above features, we ob-
tain over 300 combinations; these would mul-
tiply further if we included the semantic fea-
tures controlling perfective, progressive, voice,
and wh-questions. Such a large set of options
challenges the feasibility of Wysiwym, or in-
deed any other approach to knowledge editing
by domain experts.
4 Editing with complex types
Our favoured (indeed, only) proposal for em-
bracing these variations is based on an analogy
with a drawing tool. In Wysiwym, choosing
take from a menu of event types introduces
an event entity, implicitly defaulted to present
time, positive polarity, and so forth. In a draw-
ing tool, choosing the rectangle icon from a
palette of shapes introduces a rectangle entity,
implicitly defaulted to a certain size, colour, and
border (to name just three features). Having
introduced a rectangle entity, however, the user
can reconfigure it by changing these features one
at a time. Why should an equivalent operation
not be provided for the semantic features un-
derlying a clause?
take
TIME  present
POLARITY  positive
MODALITY  undef
ARG?1
ARG?2
MULTIPLICITY  single
IDENTIFIABILITY  unidentifiable
aspirin
patient
MULTIPLICITY  single
IDENTIFIABILITY  identifiable
Figure 2: A-box with complex types
To add this extra editing operation we must
replace the simple entity types employed in
early Wysiwym systems by complex types, as
illustrated in figure 2 (to simplify, just a few of
the possible features are shown). To reconfig-
ure an entity, the user selects the corresponding
span in the feedback text (all such spans will be
mouse-sensitive), and chooses from a menu of
options, each corresponding to a change in just
one feature.
With this potentially huge increase in the
number of editing operations for a given feed-
back text, the idea of precomputing all possi-
ble menus and popping one up on demand be-
comes less attractive, both computationally and
to the user. Instead, when the user selects a
span of text, the menu of reconfigurations for
that span is computed on the fly, and displayed
in a static menu pane adjacent to the main text
pane, which can be browsed and searched - see
figure 3. At every stage during the interaction,
the user sees a feedback text (right pane), with
one span highlighted through a colour code, and
a list of options for reconfiguring the currently
selected unit (left pane). If the selected unit
happens to be an anchor (square brackets), the
operation will be one of choosing an initial en-
tity type rather than reconfiguring an existing
one, but the appearance of the interface will be
the same. The user can continue the interaction
in two ways: either by choosing an option from
the menu pane, or by selecting a different cur-
rent unit by mouse-clicking within the feedback
text pane.
To illustrate, we will suppose that the current
A-box is as depicted in figure 2, and that the
?patient? entity is currently selected. Highlight-
ing the selected span in bold face rather than a
colour code, the feedback text and the menu of
reconfiguration options might be as follows:
The patient takes an aspirin.
identifiability
A patient
multiplicity
The patients
The labels (identifiability etc.) could of
course be replaced by more familiar words (e.g.,
article, number). Assuming that the user is
happy with the subject of the sentence, he/she
will ignore the reconfiguration options and in-
stead click around the word ?takes? in the feed-
back text, so selecting the whole event entity:
The patient takes an aspirin.
polarity
The patient does not take an aspirin.
time
The patient took an aspirin.
The patient will take an aspirin.
modality
The patient must take an aspirin.
The patient may take an aspirin.
The patient might take an aspirin.
If the first reconfiguration option is chosen, set-
ting polarity to negative, the revised options
will conserve this new value throughout, except
for the new polarity option, which will now be
to change the value back to positive:
The patient does not take an aspirin.
polarity
The patient takes an aspirin.
time
The patient did not take an aspirin.
The patient will not take an aspirin.
modality
The patient must not take an aspirin.
The patient may not take an aspirin.
The patient might not take an aspirin.
Figure 3 also shows the use of tags in the feed-
back text, such as Leaflet, Section, Paragraph.
These provide anchor points to select and re-
configure linguistic units which have no exclu-
sive text of their own. Such tags would not form
part of the final output text in a document au-
thoring scenario.
5 Benefits of the approach
These techniques make it possible to construct
complex, fluent and expressive texts using a
point-and-click interface, with no typing of text.
The benefits of previous Wysiwym systems are
also retained here: the text is guaranteed to
have a coherent internal representation which
can be constrained to conform to a controlled
language or house style specification, or gener-
ated (and edited) in a different language. The
internal representation can be used to monitor
the document content, for example to provide
authoring support, or it can be transformed into
an alternative representation for further pro-
cessing.
Although the motivation for this extension
was to provide effective support for document
authoring, the underlying model offers addi-
tional functionality in other knowledge creation
scenarios as well. The examples in this paper
use the complex types of the knowledge objects
to represent linguistic variation, but might just
Figure 3: Snapshot of application
as easily represent other kinds of semantic de-
tail, for example in an object-oriented program
specifciation scenario.
6 Conclusion
In this paper we have described an extension to
our earlier Wysiwym approach which supports
more sophisticated interactions with the under-
lying knowledge base, allowing a far wider range
of linguistic expressions to be constructed. This
makes the system more suitable for real author-
ing tasks, particularly in controlled language
or multilingual contexts, while also enhancing
its potential for constructing and editing other
kinds of complex knowledge.
The system has been implemented as an ex-
tension to our Wysiwym library (Evans and
Power, 2003), using a wide-coverage grammar
based on the subcategorisation frames found in
the XTAG (Doran et al, 1994) categories, and
deployed in the domain of medical informatics.
The demonstration requires a PC with Java and
Sicstus Prolog.
References
John A. Bateman. 1996. KPML: The komet-
Penman (Multilingual) Development Envi-
ronment. Technical report, Institut fu?r In-
tegrierte Publikations- und Informationssys-
teme (IPSI), GMD, Darmstadt, March. Re-
lease 0.9.
Nadjet Bouayad-Agha, Richard Power, Donia
Scott, and Anja Belz. 2002. PILLS: Multilin-
gual generation of medical information docu-
ments with overlapping content. In Proceed-
ings of the Third International Conference on
Language Resoures and Evaluation (LREC
2002), pages 2111?2114, Las Palmas.
Christy Doran, Dania Egedi, Beth Ann Hockey,
B. Srinivas, and Martin Zaidel. 1994. XTAG
system - a wide coverage grammar for english.
In Proceedings of the 15th International Con-
ference on Computational Linguistics (COL-
ING 94), pages 922?928, Kyoto, Japan.
Michael Elhadad and Jacques Robin. 1992.
Controlling content realization with func-
tional unification grammars. In Aspects
of Automated Natural Language Generation,
pages 89?104. Springer Verlag.
Roger Evans and Richard Power. 2003. Wysi-
wym: Building user interfaces with natu-
ral language feedback. In Research notes
and demonstration papers at EACL-03, pages
203?206, Budapest, Hungary.
B. Lavoie and O. Rambow. 1997. RealPro: A
fast, portable sentence realizer. In Proceed-
ings of the Conference on Applied Natural
Language Processing (ANLP?97), Washing-
ton, DC.
Paul Piwek, Roger Evans, Lynne Cahill, and
Neil Tipper. 2000. Natural language genera-
tion in the mile system. In Proceedings of the
IMPACTS in NLG Workshop, pages 33?42,
Schloss Dagstuhl, Germany.
R. Power and D. Scott. 1998. Multilingual au-
thoring using feedback texts. In Proceedings
of the 17th International Conference on Com-
putational Linguistics and 36th Annual Meet-
ing of the Association for Computational Lin-
guistics, pages 1053?1059, Montreal, Canada.
An integrated framework for text planning and pronominalisation 
R0dger - 'K ibb le  and  R ichard  Power  
ITRI 
University of Brighton 
Brighton BN2 4GJ 
UK. 
Email: {Rodger.Kibble I Richard.Power}@itri.brighton.ac.uk 
Abst ract  
This paper describes an implemented system 
which uses centering theory for planning of co- 
herent exts and choice of referring expressions. 
We argue that text and sentence planning need 
to be driven in part by the goal of maintain- 
ing referential continuity and thereby facilitat- 
ing pronoun resolution: obtaining a favourable 
ordering of clauses, and of arguments within 
clauses, is likely to increase opportunities for 
non-ambiguous pronoun use. Centering theory 
provides the basis for such an integrated ap- 
proach. Generating coherent texts according to 
centering theory is treated as a constraint sat- 
isfaction problem. 
1 In t roduct ion  
1.1 Issues in pronoun generat ion 
The appropriate r alisation of anaphoric expres- 
sions is a long-standing problem in NLG re- 
search. However, as McCoy and Strube (1999) 
observe, few researchers have developed sophis- 
ticated algorithms for pronoun generation. A 
typical approach, exemplified by Dale (1993), 
Reiter and Dale (1997) is to pronominalise ome 
distinguished referent which was mentioned in 
the previous sentence according to a domain- 
dependent criterion of prominence or salience. 
McCoy and Strube (op cir.) offer a more com- 
plex algorithm based on the notion of "dis- 
course threads", for which they report an ac- 
curacy of 85% when tested against a corpus 
of naturally-occurring texts. Their approach 
makes some fundamental assumptions about 
discourse structure which appear to be beyond 
the capabilities of current text and sentence 
planners and are incompatible with the widely- 
accepted notion of discourse structure as a tree 
with non-crossing branches (e.g., Mann and 
Thompson 1987). 
We argue for an approach which integrates 
the tasks of text planning and choice of referring 
expression on the following grounds: 
o portabi l i ty:  this approach should be com- 
patible with any system that employs hi- 
erarchical text planning and certain basic 
grammatical categories; 
o coherence:  we claim that text planning 
needs to be driven in part by the goal of 
maintaining referential continuity: obtain- 
ing a favourable ordering of clauses, and 
of arguments within clauses, is likely to 
increase opportunities for non-ambiguous 
pronoun use. 
The latter claim is not new, but underlies the 
Centering Theory (CT) of Grosz, Joshi and We- 
instein (1995, hereafter "GJW"). 
1.2 Issues in Text Planning 
Text Planning is one of the distinct tasks iden- 
tified in Reiter's "consensus" architecture for 
Natural Language Generation (Reiter 1994, Re- 
iter and Dale 1997): 
Text P lann ing-  deciding the content of a 
message, and organising the component 
propositions into a text tree; 
Sentence P lanning - aggregating proposi- 
tions into clausal units and choosing lex- 
ical items corresponding to concepts in the 
knowledge base; 
Linguistic real isation - surface details Such 
as agreement, orthography etc. 
Following Scott and de Souza (1990), we as- 
sume that the component propositions to be re- 
alised in a text are organised in a tree structure 
77 
in which ternfinal nodes are elementary propo- 
sitions and non-terminal nodes represent dis- 
course relations as .detined by  e~g:,. Rhetorical 
Structure Theory (RST, Mann and Thompson 
1987). This structure only partially constrains 
the linear order in which the propositions will 
be realised - -  in other words, any RST struc- 
ture specifies a range of possible text plans. We 
propose as an additional constraint that the 
generator should seek to maximise continuity 
of reference as determined by centering theory, 
and we argue that- this enables us to select the 
most cohesive variants from a set of text plans. 
The RST tree itself is produced by an interac- 
tive knowledge base editor which allows a user 
to control both semantic ontent and rhetorical 
structure via a sequence of choices guided by a 
natural language interface. 
2 Reconst ruct ing  Center ing  for  NLG 
2.1 Center ing  in a nutshe l l  
The main assumptions of Centering theory are: 
1. For each utterance in a discourse there is 
precisely one entity which is the centre of atten- 
tion or center. The center in an utterance Un is 
the most grammatically salient entity realised 
in U~_i which is also realised in Un. This is 
also referred to as the backward-looking center 
or Cb. The notion of "salience" for the purposes 
of centering theory is most commonly defined 
according to a hierarchy of grammatical roles: 
SUBJECT > DIRECT OBJECT  > INDIRECT OB- 
JECT  ~> OTHERS (see e.g., Brennan et al1987)? 
For alternative approaches see e.g., (Strube and 
Hahn 1999), (Walker et al1994). 
2. There is a preference for consecutive ut- 
terances within a discourse segment o keep the 
same entity as the center, and for the center to 
be realised as Subject or preferred center (Cp). 
Kibble (1999) dubbed these principles cohe- 
sion and sal ience respectively. Pairs of suc- 
cessive utterances (U,~, U~+i} are classified into 
the transition types shown in Fig. 1, in the or- 
.der of preference specified by Grosz et als "Rule 
, ,  ? 
3. The center is the entity which is most likely 
to be pronominalised: Grosz et als "Rule 1" 
in its weakest form states that if any entity is 
referred to by a pronoun, the Cb must be. 
CONTINUE." cohes ion and sa l ience 
. . . .  both hold; same center (o  r 
Cb(Un) undefined), realised as 
Subject in Un+l; 
RETAIN." cohes ion only; i.e. center 
remains the same but is not re- 
alised as Subject in Un+l; 
SMOOTH SHIFT." sa l ience only; cen- 
ter of Un+l realised as Subject but 
: , not  equal .to,Cb(U~); 
ROUGH SHIFT." neither cohes ion  nor 
sa l ience holds. 
NO CB: this transition is used by 
some researchers but is not dis- 
cussed by GJW. 
Figure 1: Centering Transitions 
2.2 P ronomina l i sa t ion  
Text genres are known to vary in the extent 
to which pronouns are used. The CT-based 
framework allows us to experiment with differ- 
ent strategies for choosing when to use a pro- 
noun, including: 
1. Never use anaphoric pronouns - -  for in- 
stance, in certain legal documents or tech- 
nical manuals where there must be no pos- 
sibility of ambiguity. 
2. Always pronominalise the Cb. 
3. Use a pronoun for non-Cbs only if the Cb 
is pronominalised. 
4. Pronominalise the Cb only after a Continue 
transition. 
Strategy 3 is favoured by (GJW) who cite psy- 
chological evidence that "the Cb is preferen- 
tially realised by a pronoun in English and by 
equivalent forms (i.e., ,.zero pronouns) in other 
languages" (op cit., p. 214). However, in the 
implementation reported in section 3 we opt for 
the more restrictive strategy 4. The generation 
approach outlined below enables us to experi- 
ment with different strategies and compare the 
resulting texts. 
78 
2.3 Center ing  and d iscourse  s t ruc ture  center after a sequence of CONTINUE. How- 
The canonical formulation of CT is concerned ever, in a sequence CONTINUE-RETAIN-SHIFT 
.' with local? cohesion;--'specifying .aqment-,. ~rarisi~':"::':the:sHng'~:is:p redicted:Am:its:A?cal':c?ntext~ but  
tions between consecutive sentences in a dis- the RETAIN is not; whenever RETAIN is a cheap 
course segment and favouring sequences which 
maintain the same center. Our implementation 
incorporates two extensions which have impli- 
cations for more structured iscourse: Strube 
and Hahn's (1999) "cheapness" principle, which 
favours transitions that introduce a new topic 
? in. a sal ient  position, and .Cristea's Veins The- 
ory (Cristea et al1998) which redefines tran- 
sitions in terms of rhetorical hierarchy rather 
than linear sequence of clauses (see section 3.3 
for discussion). 
"Cheapness" is satisfied by a transition pair 
( (Un-1 ,  Un), (Un, Un+l)) if the preferred center 
of Un is the Cb of Un+l. For example, this test 
is satisfied by a RETAIN-SHIFT sequence but not 
by CONTINUE-SHIFT, so it is predicted that the 
former pattern will be used to introduce a new 
center. (This claim is consistent with the find- 
ings of Brennan 1998, Brennan et al1987.) If we 
consider examples la-e below, the sequence c- 
d'-e ~, including a RETAIN-SHIFT sequence, reads 
more fluently than c-d-e even though the latter 
scores better according to the canonical rank- 
ing. 
. a. John has had trouble arranging his va- 
cation. 
b. He cannot find anyone to take over his 
responsibilities. 
c. He called up Mike yesterday to work 
out a plan. CONTINUE 
d. He has been pretty annoyed with Mike 
recently. CONTINUE 
e. Mike cancelled last week's project 
meeting at short notice. 
EXP-SMOOTH SHIFT 
d'. Mike has mmoyed him a lot recently. 
RETAIN 
e I. He cancelled last week's project meet- 
ing at short notice. SMOOTH SHIFT 
The "cheapness" principle illustrates the need 
for global opfimisation. We noted above that 
there is evidence that a RETAIN-SHIFT sequence 
is the preferred way of introducing a new 
transition following CONTINUE, another CON- 
TINUE would be cheap as well. The RETAIN 
is motivated as it enables a "cheap" SMOOTH 
SHIFT, and so we need a way of evaluating the 
whole sequence CONTINUE-RETAIN-SHIFT ver- 
SUS CONTINUE-CONTINUE-SHIFT. 
? : :2~4_~._,:Ceaatering.in :NLG 
CT has developed primarily in the context of 
natural language interpretation, focussing on 
anaphora resolution (see e.g., Brennan et al
1987). Curiously, NLG researchers have tended 
to overlook GJW's proposal that 
Rule 2 provides a constraint on speak- 
ers, and on natural-language gener- 
ation systems . . .To  empirically test 
the claim made by Rule 2 requires ex- 
amination of differences in inference 
load of alternative multi-utterance s - 
quences that differentially realize the 
same content. 
GJW, p. 215. 
With a few exceptions (e.g., Mittal et al1998, 
Kibble 1999, Kibble and Power 1999, Cheng 
2000) NLG researchers have interpreted CT as 
a theory of pronominalisation only (e.g., Dale 
1992). In this paper we concentrate on plan- 
ning, aiming to determine whether the prim 
ciples underlying the constraints and rules of 
the theory can be "turned round" and used as 
planning operators for generating coherent ext. 
Text planning in conformity with CT will need 
to follow the following set of heuristics: 
1. Plan tile order of clauses so that adjacent 
clauses have at least one referent in corn- 
I l ion. 
2. Cohes ion :  Prefer orderings which main- 
tain the same Cb in successive clauses. 
,3..- Sal ience: .Realise as=SubjeCt- of U;~ tile 
most grammatically salient entity in U,~-i 
which is mentioned in Un (the Cb). 
4. Cheapness :  Realise as Subject of Un an 
entity which is mentioned in U,~+l (and will 
therefore be Cb of U,,+i). 
79 
Breaking down the problem like this reveals ferent transitions. We assume that certain 
that there are various ways the distinct tasks options for syntactic realisation can be pre- 
...... can. be slotted, into.-an.NLG,system~Cohesion. . ... .... _~dicted.,ma::t~he,~basis~,of:,the~axgu~ment  ~str:uc- 
naturally comes under Text Planning: ordering 
a sequence of utterances to maintain the same 
entity as the center, within constraints on order- 
ing determined by discourse relations. However, 
identifying the center depends on grammatical 
salience, which is normally determined by the 
Sentence Planner- for example, choice of active 
or passive voice. Three possibilities are: 
? "Incremental" sentence-by-sentence gener- 
ation, where the syntactic structure of Un 
is determined before the semantic ontent 
of Un+l is planned. That is, the Text Plan- 
ner would plan the content of Un+l by aim- 
ing to realise a proposition in the knowl- 
edge base which mentions an entity which 
is salient in Un. We axe not aware of any 
system which performs all stages of gener- 
ation in a sentence-by-sentence way, and in 
any case this type of architecture would not 
allow the cheapness principle to be imple- 
mented as it would not support the neces- 
sary forward planning. 
* A pipelined system where the "topic" or 
"theme" of a sentence is designated inde- 
pendently as part of the semantic input, 
and centering rules reflect the information 
structure of a discourse. This approach 
was suggested by Kibble (1999), proposing 
that text and sentence planning should be 
driven by the goal of realising the desig- 
nated topic in positions where it will be 
interpreted as the Cb. However, this is not 
really a solution so much as a refinement of 
the problem, since it simply shifts the prob- 
lem of identifying the topic. Prince (1999) 
notes that definitions of "topic" in the liter- 
ature do not provide objective tests for top- 
ichood and proposes that the topic should 
be identified with the centre of attention 
as defined by CT; however, what would be 
needed here would be a more fimdamental 
definition which would, account for a par- 
ticular entity being chosen to be tile centre 
of attention. 
o The solution we adopt is to treat tile task 
of identifying Cbs as an optimisation prob- 
lem, giving different weightings to t, he dif- 
ture of predicates, which means that cen- 
tering transitions can be calculated as part 
of Text Planning. 
3 Imp lemented  prototype  
concession 
approve(fda, elixir-plus) cause NUCL~ S~LITE 
ban(fda, elixir) contain(elixir, gestodene) 
Figure 2: Rhetorical structure 
The text planner has been developed within 
ICONOCLAST, a project which investigates ap- 
plications of constraint-based reasoning in Nat- 
ural Language Generation using as  subject- 
matter the domain of medical information 
leaflets. Following (Scott and de Souza 1990), 
we represent rhetorical structure by graphs like 
figure 2, in which non-terminal nodes represent 
RST relations, terminal nodes represent propo- 
sitions, and linear order is unspecified. The task 
of the text planner is to realize the rhetorical 
structure as a text structure in which propo- 
sitions are ordered, assigned to textual units 
(e.g., sentences, paragraphs, vertical lists), and 
linked where appropriate by discourse connec- 
tives (e.g., 'since', 'however'). 
Even for a simple rhetorical input like figure 2 
many reasonable text structures call be gener- 
ated. Since there are two nucleus-satellite r la- 
tions, tile elementary propositions can be or- 
dered in four ways; several discourse connec- 
tives can be employed to realize each rhetor- 
ical relation (e.g. concession can be realized 
by 'although', 'but' and '.however'); at one ex- 
treme, the text can be spread out over several 
paragraphs, while at the other extreme it can 
be squeezed into a single sentence. With fairly 
restrictive constraint settings, the system gen- 
erates 24 text-structure patterns for figure 2, 
including the following (shown schematically): 
80 
A. Since contain(elixir, gestodene), ban(fda, 3.1 Choos ing  centers  
elixir). However, approve(fda, elixirplus). Given a text structure, we enumerate all per- 
B. approve(fda, elixirplus), although since 
contain(elixir, gestodene ) , ban (f da, elixir). 
The final output texts will depend on how the 
propositions are realized syntactically; among 
other things this will depend on centering 
choices within each proposition. 
In outline, the procedure that we propose is 
as follows: ~ . 
. Enumerate all text structures that are ac- 
ceptable realizations of the rhetorical struc- 
ture. 
. 
. 
For each text structure, enumerate all per- 
missible choices for the Cb and Cp of each 
proposition. 
Evaluate the solutions, taking account of 
referential coherence among other consid- 
erations, and choose the best. 
For the example in figure 2, centers can be as- 
signed in four ways for each text-structure pat- 
tern, making a total of 96 solutions. 
As will probably be obvious, such a procedure 
could not be applied for rhetorical structures 
with many propositions. For examples of this 
kind, based on the relations 'cause' and 'con- 
cession' (each of which can be marked by sev- 
eral different connectives), we find that the to- 
tal number of text-structures i  approximately 
5 N-~ for N propositions. Hence with N = 4 we 
would expect around 600 text structures; with 
perhaps 5-10 ways of assigning centers to each 
text structure, the total number of solutions 
would approximate to 5000. Global optimiza- 
tion of the solution therefore becomes imprac- 
ticable for texts longer than about five propo- 
sitions; we address this problem by a technique 
of partial optimization i which a macro-planner 
fixes the large-scale structure of the text, thus 
defining a set of micro-planning problems each 
small enough to be tack led by the methods de- 
scribed here. 
Stage 1 of the planning procedure is described 
elsewhere (Power, 2000); we focus here on stages 
2 and 3, in which the text planner enumerates 
the possible assignments of centers and evalu- 
ates which is the best. 
missible centering assignments as foil0ws: " . . . . .  
1. Determine the predecessor Yn-1 (if any) of 
each proposition Un. 
2. List the potential Cbs and Cps of each 
proposition, henceforth denoted by ECb 
and ECp. 
3. Compute ~li combinations from ECb and 
ECp that respect the fundamental center- 
ing constraint hat Cb(Un) should be the 
most salient candidate in Un-1. 
Two criteria for determining the predecessor 
have been implemented; the user can select one 
or other criterion, thus using the NLG system 
to test different approaches. Following a linear 
criterion, the predecessor is simply the propo- 
sition that precedes the current proposition in 
the text, regardless of structural considerations. 
Following a hierarchical criterion, the predeces- 
sor is the most accessible previous proposition, 
in the sense defined by Veins Theory (Cristea et 
al 1998). We will return to this issue later; for 
now we assume the criterion is linear. 
ECb(Un) (potential Cbs of proposition Un) is 
given by the intersection between Cf(U,~) and 
Cf(Un-1) -- i.e., all the referents they have in 
common. The potential Cps are those referents 
in the current proposition that can be realized 
as most salient. Obviously this should depend 
on the linguistic resources available to the gen- 
erator; the system actually uses a simpler rule 
based oil case roles within the proposition. Fig- 
ure 3 shows the potential Cbs and Cps for the 
proposition sequence in solution A. 
Our treatment of salience here simplifies ill 
tWO ways. First, we assume that syntactic real- 
ization serves only to distinguish the Cp from 
all other referents, which are ranked on the 
same level: thus effectively SUBJECT > OTHERS. 
Secondly, we assume that the system already 
.knows, from the event.class,of the proposition, 
which of its case roles can occur in subject po- 
sition: thus for ban, both arguments are poten- 
tim Cps because active and passive realizations 
are both allowed; for contain, only elixir is a 
potential Cp because we disallow 'Gestodene is
contained by Elixir'. 
81 
U Proposit ion 
U1 cont ain(elixir, gestodene) 
U2 ban(fda, elixir) 
U3 approve(fda, elixir-plus) 
ECb(U) 
\[\] 
\[elixir\] 
\[fda\] 
2Cp(U) 
.......... -{elixir\] 
\[fda, elixir\] 
\[fda, elixir-plus\] 
Figure 3: Cbs and Cps for solution A. 
With these simplifications, the enumeration 
of centering assignments i straightforward; in
the above example, four combinations are pos- 
sible, since there are two choices each for Cp(U2) 
and Cp(U3), none of which leads to any viola- 
tion of the basic centering constraint. This con- 
straint only comes into play if there are several 
choices for Cb(Un), one of which coincides with 
Cp(Un-1). 
3.2 Evaluat ing solutions 
Various metrics could be used in order to eval- 
uate centering choices. One possibility, for ex- 
ample, would be to associate a cost with each 
transition, so that perhaps 'Continue' (the best 
transition) has zero cost, while 'No Cb' (the 
worst transtion) has the highest cost. However, 
we have preferred the approach mentioned ear- 
lier in which cohesion and salience are evaluated 
separately; this allows us to include the further 
criterion of cheapness. 
Although this paper focusses on centering is- 
sues, it is important o remember that other as- 
pects of text quality are evaluated at the same 
time: the aim is to compute a global measure so 
that disadvantages in one factor can be weighed 
against advantages in another. For instance, 
text pattern B is bound to yield poor continuity 
of reference because it orders the propositions 
so that U1 and U2 have no referents in coin- 
mon. Text pattern A avoids this defect, but 
this does not necessarily mean that A is bet- 
ter than B overall; there may be other reasons, 
unconnected with centering, for preferring B to 
A. 
The system evaluates candidate solutions by 
applying a battery of tests to each.node of the 
text plan. Each test identifies whether the node 
suffers from a particular defect. For instance, 
one stylistic defect (at least for the rhetorical 
relations occurring in figure 2) is that of plac- 
ing nucleus before satellite; in general, the text 
reads better if important material is placed at 
the end. For each type of defect, we specify a 
weight indicating its importance: in evaluating 
continuity of reference, for example, the defect 
'No Cb' might be regarded as more significant 
than other defects. Summing the weighted costs 
for all defects, we obtain a total cost for the so- 
lution; our aim is to find the solution with the 
lowest total cost. 
Regarding centering, the tests currently ap- 
plied are as follows. 
Salience violation 
A proposition Un violates salience if 
Cb(Un) 7 ~ Cp(Un). This defect is assessed 
only on propositions that have a backward- 
looking center. 
Coherence violation 
A proposition Un violates cohesion if 
Cb(Un) 7 ~ Cb(Un-1). Again, this defect is 
not recorded when either Un or Un-1 has 
no Cb. 
Cheapness violation 
A proposition Us violates cheapness if 
Cb(Un) 7 ~ Cp(Un-1). 
No backward- look ing  center  
This defect is recorded for any proposition 
with no Cb, except the first proposition in 
the sequence (which by definition cannot 
have a Cb). 
Applied to the four solutions to text structure 
A, with all weights equal to 1, these definitions 
yield costs, shown in Figure 4.-According to our 
metric, solutions A1 and A2 should be preferred 
to A3 and A4 because they incur less cost. This 
resutt=cml be  assessed, by comparing -the follow- 
ing output texts, in which the generator has fol- 
lowed the policy of pronominalizing the Cb only 
after a 'Continue' transition: 
A1. Since Elixir contains gestodene, the FDA bans 
Elixir. However, it approves ElixirPlus. 
82 
Solut ion 
A1 
A2 
A3 
A4 
U Cb(U) Cp(U) Defects  
U1 0 .elixir none 
U2 elixir fda salience 
U3 fda fda cohesion 
TOTAL 2 
U1 ~ elixir 
U2 elixir elixir 
Ua fda fda 
TOTAL 
Vl 
U2 
U3 
U1 
U2 
U3 
none 
none 
cohesion, cheapness 
2 
I~ elixir none 
elixir fda salience 
fda elixir-plus salience, cohesion 
TOTAL 3 
elixir none 
elixir elixir none 
fda elixir-plus salience, cohesion, cheapness 
TOTAL 3 
Figure 4: Costs of solutions A1 - A4. 
A2. Since Elixir contains gestodene, it is banned by 
the FDA. However, the FDA approves Elixir- 
Plus. 
A3. Since Elixir contains gestodene, the FDA bans 
Elixir. However, ElixirPlus is approved by the 
FDA. 
A4. Since Elixir contains gestodene, it is banned by 
the FDA. However, ElixirPlus is approved by 
the FDA. 
Of course we are not satisfied that this metric 
is the best; an advantage of the generation ap- 
proach is that different evaluation methods can 
easily be compared. 
3.3 H ierarch ica l  center ing  
The linear approach, illustrated above, assigns 
centers on the basis of a proposition sequence, 
flattening the original hierarchy and ignoring 
nucleus-satellite r lations. This means, for ex- 
ample, that in a text of two paragraphs, propo- 
sition U2.1 (the first proposition in the second 
paragraph) has to be treated as the successor 
to Ui.N (the final proposition of the first para- 
graph): even if Ui.:\, is relatively insignificant 
(the satellite of a satellite, perhaps). One's in- 
tuition in such cases is that some more signif- 
icant proposition in the first paragraph should 
become the focus against which continuity of 
reference in the second paragraph is judged. 
Veins Theory (Cristea et al1998) provides a 
possible formalization of this intuition, in which 
some earlier propositions become inaccessible as 
a rhetorical boundary is crossed. The theory 
could be applied to centering in various ways; 
we have implemented perhaps the simplest ap- 
proach, in which centering transitions are as- 
sessed in relation to the nearest accessible prede- 
cessor. In many cases the linear and hierarchical 
definitions give tile same result, but sometimes 
they diverge, as in the following alternative to 
solutions A and B: 
C. ban(fda, elixir) since contain(elixir, 
gestodene). 
However, approve(f tin, elixirplus). 
Following Veins Theory, the predecessor of 
approve(f da, elixirplus) is ban(f da, elixir); its 
linear predecessor contain( elixir, ge.stodene ) 
(an embedded satellite) is inaccessible. This 
makes a considerable difference: under a hier- 
archical approach, fda can be the Cb of the 
83 
final proposition; under a linear approach, this Proceedings of ANLP-NAACL 2000. 
proposition has no Cb. D Cristea, N Ide and L Romary, 1998. Veins 
~ '. Iheory:  ~ A :model of,:gtobat: discourse :cohesion 
4 Conc lus ion  
This paper has highlighted some implications 
of Centering Theory for planning coherent text. 
We show that by making some assumptions 
about which entities are potential Cps, we can 
determine Cbs, Cps, and hence transitions, in 
the text planning stage. This allows the text 
planner to select he proposition sequence that 
yields the best continuity of reference, or to bal- 
ance the goal of referential continuity against 
other factors. For instance, there may be a 
preference for Satellite to follow Nucleus for 
some discourse relations, even if this results in a 
greater number of defects according to centering 
considerations. There are difficulties in evaluat- 
ing algorithms for specific tasks which are em- 
bedded in a generation system, since the quality 
of the output is limited by the functionalities of
the system as a whole. In particular, the task 
of generating appropriate referring expressions 
cannot be tackled in isolation from other tasks 
which contribute to the coherence of a text. 
The implementation of Centering reported 
here is a special case of text planning by con- 
straint satisfaction, where the user has control 
over the different constraints, and this approach 
means that different strategies for e.g. clause or- 
dering and pronominalisation can easily be com- 
pared by inspecting the resulting texts. The 
evaluation metrics we have presented here are 
provisional and are a matter for further detailed 
research, which our approach to text generation 
will facilitate. 
Acknowledgements  
This work was supported by the UK EPSRC 
under grant references L51126, L77102 (Kibble) 
and M36960 (Power). 
References 
S Brennan 1998. Centering as a Psychological 
Resource for Achieving Joint Reference in Spon- 
taneous Discourse. In Walker, Joshi and Prince 
(eds), Centering Theory in Discourse, Oxford. 
S Brennan. M Walker Friedman and C Pollard 
1987. A Centering Approach to Pronouns. In 
Proe. 25th A CL . 
H Cheng 2000. Experimenting with the Inter- 
action between Aggregation and Text Planning~ 
and coherence. In Proc COLING/ACL'98, pp 
281-285, Montreal. 
R Dale 1992, Generating Referring Expressions, 
MIT Press. 
B Grosz, A Joshi and S Weinstein 1995, Center- 
ing: a framework for modelling the local coher- 
ence of discourse. Computational Linguistics. 
? R Kibble 1999, Cb or not Cb? Centering theory 
applied to NLG. A CL workshop on Discourse 
and Reference Structure. 
R Kibble and R Power,1999. Using centering 
theory to plan coherent exts, Proceedings of 
the 12th Amsterdam Colloquium. 
W Mann and S Thompson 1987, Rhetorical 
Structure Theory: A Theory of Text Organ- 
isation. In L Polanyi (ed.), The Structure of 
Discourse. 
K McCoy and M Strube, 1999. Generating 
Anaphoric Expressions: Pronoun or Definite 
Description? A CL workshop on Discourse and 
Reference Structure. 
V Mittal, J Moore, G Carenini and S Roth 1998, 
Describing Complex Charts in Natural Lan- 
guage: A Caption Generation System. Com- 
putational Linguistics. 
R Power 2000. Planning Texts by Constraint 
Satisfaction, to appear in Proceedings of COL- 
ING 2000. 
E Prince 1999. How not to mark topics: "Top- 
icalization" in English and Yiddish. Ms, Lin- 
guistics Department, University of Pennsylva- 
nia. 
E Reiter 1994. Has a consensus NL generation 
architecture appeared, and is it psycholinguisti- 
cally plausible? In Proc. INLG 7. 
E Reiter and R Dale 1997, Building Applied 
Natural-Language Generation Systems. Jour- 
nal of Natural-Language Engineering 
D Scott and C de Souza, 1990. Getting the 
message across in RST-based text generation. 
In Dale, Mellish and Zock (eds), Current Re- 
search in Natural Language Generation, Aca- 
demic Press. 
M Strube and U Hahn 1999, Functional Center- 
ing - Grounding Referential Coherence in Infor- 
mation Structure. Computational Linguistics. 
84 
Can text structure be incompat ib le  with rhetorical structure? 
Nadjet Bouayad-Agha,  Richard Power and Donia  Scott 
Information Technology Research Institute 
University of Brighton 
Lewes Road 
Brighton BN2 4G J, UK 
first name. lastname@it ri.bton.ac.uk 
Abstract  
Scott and Souza (1990) have posed the problem 
of how a rhetorical structure (in which proposi- 
tions are linked by rhetorical relations, but not 
yet arranged in a linear order) can be realized 
by a text structure (in which propositions are 
ordered and linked up by appropriate discourse 
connectives). Almost all work on this problem 
assumes, implicitly or explicitly, that this map- 
ping is governed by a constraint on compatibil- 
ity of structure. We show how this constraint 
can be stated precisely, and present some coun- 
terexamples which seem acceptable ven though 
they violate compatibility. The examples are 
based on a phenomenon we call extraposition, 
in which complex embedded constituents of a 
rhetorical structure are extracted and realized 
separately. 
1 Introduct ion 
Text planning (or more broadly, document plan- 
ning) can be divided into two stages. In the 
first stage, material is selected, perhaps from a 
knowledge base, and organized rhetorically. In 
the second stage, the rhetorical structure is re- 
alized by a text structure (or document struc- 
ture), through which the material is distributed 
among sentences, paragraphs, vertical lists, and 
perhaps even diagrams. The RAtS (1999) pro- 
posal for a standard NLG architecture distin- 
guishes tile outputs of these two phases by the 
data types l:l.hetRep (rhetorical representation) 
and DocRep (document representation). 
We focus in this paper on the  second stage 
of text planning - -  the passage from RhetRep 
to DocRep. NLG researchers have addressed 
this issue in various ways, but everyone as- 
sumes some kind of structural compatibility be- 
tween rhetorical structure and text structure. 
The most popular discourse framework in NLG 
is R ST (Mann a.nd Thompson. 1988). which 
makes the crucial distinction between nucleus, 
which is the most important part of a message, 
and satellite, which is the peripheral part of the 
message. Scott and Souza (1990) provide guide- 
lines for the realisation of RST trees into a co- 
herent text. One of them is to avoid dangling 
sentences, that is, to avoid putting "information 
that is only weakly relevant o the message" in 
a separate sentence because it will feel as if it 
has been introduced as an afterthought or as 
introducing a new topic which is then abruptly 
abandoned, disrupting the comprehensibility of
the text. As an example, the authors provide 
the attributive satellite of an elaboration rela- 
tion. 
Marcu (1996), in order to build a valid text 
plan from a set of rhetorical assertions, uses 
the "nuclearity principle", that is the observa- 
tion in Mann and Thompson's framework that 
"whenever two large text spans are connected 
through a rhetorical relation, that rhetorical re- 
lation holds also between the most important 
parts of the constituent spans". Therefore, the 
resulting text plans are valid in the sense that 
they are isomorphic with one of the rhetorical 
structures that can be built from the rhetorical 
assertions using this nuclearity principle. 
Our aim in this paper is to formulate more 
precisely a notion of structural compatibility 
which is necessary in order to describe the real- 
isation of a RhetRep into various DocReps, and 
then .to discuss some examples (mostly taken 
from the domain of patient information leaflets) 
of apparently acceptable texts in which this no- 
.tion of compatibility is violated..:To discuss 
this issue clearly, an assmnption must be made 
about the kinds of information represented by 
rhetorical and text structure; we outline in sec- 
tion 2 the common assumption that these rep- 
resentations are trees, labelled respectively with 
rhetorical and textual categories, the rhetorical 
structure being unordered and the text struc- 
194 
ture ordered. Section 3 then defines a notion 
of .structural  compatibility that:is weaker than 
isomorphism; section 4 shows that we can find 
plausible counterexamples ven to this weaker 
formulation, and discusses why these passages 
occur. Section 5 discusses ome implications for 
NLG, and finally, section 6 raises further impor- 
tant issues. 
2 Rhetor ica l  s t ruc ture  and 
text  s t ruc ture  
To distinguish clearly between FthetRep and 
DocRep, we need to define the kinds of infor- 
mation that should be included in the two rep- 
resentations. Bateman and Rondhius (1997) 
compare several approaches to rhetorical rep- 
resentation, citing in particular RST (Mann 
and Thompson, 1988) and Segmented Discourse 
Representation Theory (Asher, 1993). These 
approaches share the idea that rhetorical repre- 
sentations are composed of propositions linked 
by rhetorical relations; SDRT includes as well 
the logical apparatus of DRT, thus covering 
notions like necessity and logical scope which 
are missing from RST. For the most part, 
NLG applications have used the RST frame- 
work, adapted in various ways; the most com- 
mon representation, proposed also as the RAGS 
standard, is that of a tree in which terminal 
nodes represent elementary propositions, while 
non-terminal nodes represent rhetorical rela- 
tionships. This representation, proposed for ex- 
ample by Scott and Souza (1990), is illustrated 
by figure 1, which might be realized by the fol- 
lowing passage: 
(1) Elixir occasionally provokes a mild allergic 
reaction B, because it contains gestodene C. 
However, Elixir has no serious side- 
effects A. 
Assuming an RST-based framework, an im- 
portant issue is whether the rhetorical represen- 
. tation should already.imply a linear order. Most 
researchers have followed Scott and Souza in as- 
suming that linear order should be left unspeci- 
fied; i t  is during the transition to the document 
representation that the material is distributed 
among linguistic units (or perhaps diagrams, in 
a multimedia document) arranged in a specific 
order. Thus the cause relation in figure 1. for 
example, could be realized with nucleus first, or 
satellite first, or satellite embedded within nu- 
cleus: 
not(serious-side -e ff ~ts(elixir)) 
NU~EUS S,~LLITE 
B C 
possible(allergic-reaction(elixir)) contain(elixir, gestodene) 
Figure 1: Rhetorical representation 
(2a) Elixir occasionally provokes a mild allergic 
reaction B, because it contains gestodene c. 
(2b) Because it contains gestodene C, Elixir 
occasionally provokes a mild allergic 
reaction B. 
(2c) Elixir, because it contains gestodene C, 
occasionally provokes a mild allergic 
reaction B . 
In the RAGS proposal, which aims to extract 
a useful common approach from current work 
in NLG, the DocRep comprises an ordered tree 
corresponding roughly to the 'logical markup' 
in notations like HTML and LaTeX. More pre- 
cisely, a distinction is made between abstract 
and concrete levels of representation, where the 
abstract representation corresponds to logical 
markup (e.g., concepts like 'paragraph' and :em- 
phasis'), while the concrete representation also 
covers graphical markup (concepts like ~vertical 
space' and 'bold face'). In terms of this dis- 
tinction, it is the AbsDocRep that is specified 
during text planning; graphical markup can be 
deferred to a later formatting stage. 
Figure 2 shows two alternative document rep- 
resentations expressing the rhetorical content in 
figure 1. Following Power (2000), the nodes of 
the tree are labelled with 'text-categories' us- 
ing a system that extends the 'text grammar' 
proposed by Nunberg (1990). 1 These document 
1Nunberg's terms 'text-phrase', 'text-clatise',and 
'text-sentence' refer to textual categories, which 
should not be confused with their syntactic oun- 
terparts. They are defined not by syntactic forma- 
tion rules but by their role in text-structure, which 
is typically marked as follows: tezt-sentences begin 
with a capital letter and end in a full stop; text- 
clauses are separated by semicolons; tezt-phrases are 
195 
PARAGRAPH 
TEXT-SENTENCE 
TEXT-PHRASE " TEXT-PHRASE 
B 
possible(allergic-reaction(elixir)) / 
TEXT-SENTENCE 
TEXT-PHRASE TEXT-PHRASE 
concession A 
"however" not(serious-side-effects(elixir)) 
TEXT-PHRASE TEXT-PHRASE 
cause C 
"because" contain(elixir, gestodene) 
TEXT-SENTENCE 
(b) ~ ~  / 
TEXT-CLAUSE TEXT-CLAUSE TEXT-CLAUSE 
C 
TEXT-PHRASE TEXT-PHRASE TEXT-PHRASE TEXT-PHRASE 
cause B concession A 
"consequently"possible(allergic-reaction(elixir)) "however" not(serious-side-effects(elixir)) 
Figure 2: Document  representations 
representations can now be passed to the tac- 
tical generator for the syntactic realization of 
the elementary propositions; the resulting texts 
might be as follows: 
(3a) Elixir occasionally provokes a mild allergic 
reaction B, because i t  contains gestodene C.
However, Elixir has no serious side- 
effects A. 
(3b) Elixir contains gestodeneC; consequently, 
it occasionally provokes a mild allergic 
reactionS; however, Elixir has no serious 
side-effects A .
3 Structural compatibi l i ty 
Summarising the argument so far. we have made 
three main points: 
o Rhetorical structure has typically been 
represented by unordered RST trees such 
as figure 1. 
o Document structure, which conveys in- 
formation similar to logical markup in 
HTML~ can be represented by ordered 
trees in which nodes are labelled with text- 
categories (figure 2). 
const i tuents  of text-clauses, ometimes eparated by 
commas, although within text-clauses the hierarchi- 
cal- structture is expressed mainly through syntax. 
A given rhetorical representation can be 
expressed by a variety of different docu- 
ment representations, in which the propo- 
sitions occur in different orders, and in 
different text-category configurations, and 
the rhetorical relations are expressed by 
different connectives. 
This formulation of the problem raises an obvi- 
ous question: how can we characterize the set of 
document representations that adequately real- 
ize a given rhetorical representation? Elsewhere 
(Power, 2000), we have argued that an adequate 
realization must meet three conditions: 
Cor rect  content :  
All propositions and 
nmst be expressed. 
rhetorical relations 
Wel l - fo rmed s t ructure :  
General formation rules for document 
structure must be respected (e.g. a text- 
sentence cannot  contain a paragraph, un- 
less tile paragraph is indented). 
S t ruc tura l  compat ib i l i ty :  
The docmnent representation mst orga- 
nize the propositions in a way that is com- 
patible with their organization in rhetori- 
cal structure. 
196 
The first two conditions are relatively straight- 
forward, but what is meant,exactly .by 'struc- 
tural compatibility'? 
Assuming that we are comparing two trees, 
the strongest notion of compatibility is isomor- 
phism, which can be defined for our purposes as 
follows: 
DocRep is isomorphic with RhetRep 
if they group the elementary propo- 
sitions in exactly the same way. 
More formally, every set of proposi- 
tions that is dominated by a node in 
DocRep should be dominated by a node 
in RhetRep, and vice-versa. 
Under this definition, the rhetorical representa- 
tion in figure 1 is isomorphic with the document 
representation i  figure 2a, but not with that in 
figure 2b: 
* Proceeding top-down and left-to-right, the 
five nodes in figure 1 dominate the proposi- 
tion sets {A,B, C}, {A}, {S,C},  {B}, and 
{c}. 
o Ignoring nodes that express discourse con- 
nectives, the nodes in figure 2a dominate 
the proposition sets {A,B,C},  {B,C},  
{B}, {C} (twice), and {A} (twice). These 
are exactly the same sets that were ob- 
tained for figure 1. 
* Tile corresponding sets for figure 2b are 
{A,B,C},  {C}, {B} (twice), and {A} 
(twice). Since the set {B,C} is missing 
from this list, there is a grouping in figure 
1 that is not realized in figure 2b, so these 
representations are not isomorphic. 
Since structures like figure 2b are common, iso- 
tnorphism seems too strong a constraint; we 
have therefore proposed (Power, 2000) the fol- 
lowing weaker notion of compatibility: 
DocRep is compatible with RhetRep 
if every grouping of the elementary 
propositions in Docgep is also found 
in R.hetRep. 
Formally, every set of propositionS 
that is dominated by a node in DocRep 
sh.ould be dominated by a node in 
RhetRep -- bat the converse is not re- 
quired. 
Under this constraint, we allow tim document 
representation t.oomit rhetorical groupings, but 
"you forfA~ T~ITE to take C ~  
your tablet" S U S _  1 NUC~USD 2 
"Go on as before" 
~,~J~ L EU S _ I N U C~.E~ S _2 
B C 
"take another assoon "wait until it is time 
as you remember" to take your next dose" 
Figure 3: Rhetorical representation of in- 
struct ion 
not to introduce new ones. The resulting struc- 
tures may be ambiguous, but this will not mat- 
ter if the unexpressed rhetorical relationships 
can .be inferred from the content. 
4 Extraposition 
The compatibility rule may be a useful text- 
planning heuristic, but as a constraint on ade- 
quacy it still seems too strong. Looking through 
our corpus of patient information leaflets, we 
have noticed some exceptions, especially in pas- 
sages giving conditional instructions: 
(4) If you forget to take your tablet A, take an- 
other as soon as you remember B or wait 
until it is time to take your next dose C. 
Then go on as before D. 
From the point of view of document structure, 
this passage is a paragraph comprising two text- 
sentences: thns the proposition D is separated 
from the other three propositions, which are 
grouped in tile .first sentence. However, rhetor- 
ically speaking, D belongs to the consequent of 
the conditional: it is the final step of the plan 
that should be activated .if_the patient forgets 
to take a dose (figure 3). Compatibility is vio- 
lated because tile DocRep contains a node (the 
first text-sentence) dominating the proposition 
set {A, B, C}. which is not dominated by any 
node in figure 3. 
Such examples might be explained as the re- 
sult of loose punctuation or layout, perhal)S 
197 
through imitation of the patterns of conversa- 
tion, in which extra:.materi~! is_often ~tagged. on- 
as an afterthought. Thus proposition D remains 
grouped with B and C - -  they occur consecu- 
tively - -  but through a minor relaxation of nor- 
mal punctuation it has been separated by a full- 
stop rather than a comma. However, this expla- 
nation fails to cover variations of the example 
in which the propositions in the consequent are 
not realized consecutively in the DocRep: 
(5) Consult your doctor immediately A if a 
rash develops B. It might become seriously 
infected C. 
In this example, A must be grouped rhetori- 
cally with C rather than with B, unless we take 
the radical step of allowing rhetorical structure 
to contradict logical structure. The proposition 
C cannot be logically conjoined with the con- 
ditional because it contains a hypothetical dis- 
course referent (the rash) that is bound to the 
antecedent, and is therefore inaccessible outside 
the conditional. 
If passages of this kind are not artifacts of 
loose punctuation, why do they occur? A plau- 
sible reason, we suggest, is that some com- 
plex rhetorical patterns cannot easily be real- 
ized in a way that maintains structural com- 
patibility, usually because text-clauses are over- 
loaded. Conditionals are especially prone to this 
problem because the only common discourse 
connective ('if') is a subordinating conjunction 
which can only link spans within a syntactic 
sentence (and thus within a text-clause). If ei- 
ther the antecedent or the consequent is com- 
plex, the author is faced with a tricky problem. 
We have found examples in patient informa- 
tion leaflets of conditional sentences so long that 
they are ahnost incomprehensible. More skilled 
authors, however, succeed in presenting the ma- 
terial clearly either by using layout (e.g., a com- 
plex antecedent is presented as an indented list), 
or by a trick of rhetorical reorganization that we 
will call eztraposition. It is this trick that intro- 
duces an incompatibility between RhetRep and 
DocRep. 
Extraposition typically occurs when a rhetor- 
ical representation R contains a complex em- 
bedded constituent C. To respect structural 
compatibility, R should be realized by a doc- 
ument unit that contains the realization of C: 
instead, in extraposition, a document unit real- 
ising/?. - C is coordinated with one realizing C. 
so that the extraposed material C is raised in 
the DocRep to the same level as R. To recon- 
...... struct ~:the:.: meanings.of .the:-.whole:. passage, .the 
reader has to plug C back into R. In most 
cases, the author facilitates this task through 
an explicit deictic reference to the extraposed 
material (Bouayad-Agha et al, 2000): 
(6) If you have any of the following, tell your 
doctor: 
difficulty in breathing 
. . . . . . . . . . .  al)dominal..Dains 
nausea or vomiting 
Occasionally, however, the author leaves the 
extraposition implicit, assuming that the reader 
can infer the correct location of C within R from 
the propositional content. In such cases, the ex- 
traposition looks like an afterthought, because 
the unit realizing R - C contains no signal that 
a gap in its content will be filled in later. 
We have also come across rare examples 
of another kind of incompatibil ity in which 
Marcu's (1996) principle of nuclearity is vio- 
lated by grouping together two satellites which 
have the same nucleus. Suppose that the rhetor- 
ical representation i figure 1 is realized by the 
following passage, in a context in which the 
reader knows nothing about gestodene: 
(7) Although Elixir has no serious side- 
effects A, it contains gestodene c. Conse- 
quently, it occasionally provokes a mild al- 
lergic reaction 8. 
The apparent concession relation between A 
and C here is paradoxical, since in rhetorical 
structure they are unrelated. Of course a con- 
trast between A and C nfight be perceived by 
a medical expert; however, one can construct 
similar examples in which the apparent relation 
is even less plausible: 
(8a) Although we usually work fl'om nine' to 
five A, today is Friday C. Consequently, we 
can go home early B. 
This may be rather loose, but many people find 
it acceptable. It could be explained as a rhetor- 
ical trick in which the sheer paradox of the con- 
cession serves as a signal that it is incomplete. 
The device might be spelled out as follows: 
Although Elixir has no serious side- 
effects A, there exists a contrasting 
state of a~hirs resulting fl'om the flzct 
that it contains gestodene c. This 
state of affairs is that it occasionally 
provokes a nfild allergic reaction t3. 
198 
Unlike the conditional examples above, this de- 
vice works only.when the-.rhetorically grouped 
propositions B and C are consecutive in the 
DocRep. Thus whatever view is taken of exam- 
ple (Sa) , everyone finds its variant (Sb) much 
worse: 
(Sb) # Today is Friday C although we usually 
work from nine to five A. Consequently, we 
can go home early s. 
5 Implications for NLG 
For many NLG applications, the notion of com- 
patibility defined above is a useful hard con- 
straint; even if violations of this constraint are 
sometimes acceptable, they are not essential. 
However, for some kinds of material (e.g., com- 
plex instructions), extraposition is a convenient 
rhetorical device which might improve the read- 
ability of the generated texts, so it is worth con- 
sidering how a text planner might be configured 
so as to allow solutions that violate compatibil- 
ity. 
In terms of the RAGS framework, there 
are broadly two possible approaches. First, 
we could introduce incompatibility by defin- 
ing transformations on the RhetRep; alterna- 
tively, we could relax the constraints govern- 
ing the transition from RhetRep to DocRep. 
The RAGS proposal (1999) allows for rhetorical 
transformations through a distinction between 
abstract and concrete rhetorical representa- 
tions. The abstract representation AbsRhetRep 
expresses the rhetorical content of the under- 
lying message, while the concrete RhetRep ex- 
presses the rhetorical structure directly realized 
in the text and corresponds to the representa- 
tion used by Scott and Souza (1990) to discuss 
textual realisation. If KhetRep is incompati- 
ble with AbsRhetRep, the text structure DocRep 
will also be incompatible with AbsRhetRep, 
even though the rules for realizing rhetorical 
structure by document structure are themselves 
compatibility-preserving, qYaalsformation oper- 
ations are also used by Marcu (2000) to map 
Japanese rhetorical structures onto English-like 
rhetorical structures, but these are mappings 
between two PdaetReps rather than from an 
AbsRhetRep to a RhetRep. 
If transformations are allowed, there are obvi- 
ous dangers that the message will be expressed 
in such a distorted way that the reader cannot 
recover the original intention. For this reason, 
rhetori(:al transformations must be defined with 
care. A fairly safe option would appear to be 
.... -the ..extraposition-iof.:a ,proposition. ~lab6rai~ing 
the antecedent of a conditional - - .even though 
such a transformation would violate Marcu's 
(1996) 'nuclearity principle' (assuming that the 
antecedent is regarded as the satellite). The fop - 
lowing examples how that this transformation 
leads to acceptable texts regardless of the order 
of nucleus and satellite within the conditional: 
(9a)~ Dcr.uot" use :Elixirif you :have had' an al: " 
lergic reaction to Elixir. An allergic reac- 
tion may be recognised as a rash, itching 
or shortness of breath. 
(9b) If you have had an allergic reaction to 
Elixir, do not use Elixir. An allergic re- 
action may be recognised as a rash, itching 
or shortness of'breath. 
However, the approach based on rhetorical 
transformations leads to difficulties when the 
acceptability of the resulting text depends on 
linear order as well as grouping. For instance, 
suppose that we try extraposing the elabora- 
tion of a satellite when the main relation is not 
a conditional, but a concession. The following 
passages how two texts that might result, but 
in this case the second version sounds anoma- 
lous: even if they are not grouped together in 
the DocRep, the satellite and its elaboration at 
least need to be consecutive. 
(10a) You should not stop taking Elixir, even 
though you might experience some mild 
effects. For example, feelings of dizziness 
and nausea are very common at the begin- 
ning of treatment. 
(lOb) # Even though you might experience some 
mild effects at tile beginning of tile treat- 
ment, you should not stop taking Elixir. 
For example, feelings of dizziness and nau- 
sea are very common at the beginning of 
treatment. 
A transformation from AbsKhetRep to 
RhetRep cannot distinguish these cases, so that 
10a is,allowed while 10b is protfibited; unless the 
l:l.hetRep is at least partially specified for linear 
order. Adhering strictly to the RAGS frame- 
work, where linear order is specified only in 
tbsDocRep, one would have to adopt the alter- 
native of building an incompatible /~bsDocRep 
from RhetRep. constraining the linear order at, 
this stage. 
199 
6 Conclusion 
We have discussed various examples Of extra- 
position. This phenomenon is due to various 
factors: the complexity of the material (exam- 
ple 4), the presence of logical information (5), 
the use of referring expressions to access infor- 
mation at various degrees of accessibility in the 
text structure (5,6,9), and the use of particular 
rhetorical strategies (7,8). This last group of ex- 
amples concerns.a concession constr.uction sim- 
ilar to the one discussed by Grote et al (1997), 
namely the substitution concession. This type 
of concession groups together the conceded part 
A and the explanation C but leaves the conclu- 
sion B unverbalised. The difference in the case 
of examples 7 and 8 is that A and C are grouped 
together but B is required to follow them be- 
cause there is not enough information for the 
reader to infer B from A and C. 
The extraposition phenomenon shows that 
the nucleus-satellite distinction is not the only 
factor influencing the segmentation f the mes- 
sage. In example 10, the injunction you should 
not stop taking Elixir obviously expresses the 
main intention of the author. However, the 
fact that the subordinated concession is placed 
after its main clause makes it available for 
further expansion. The sometimes compet- 
ing informational nd intentional roles of dis- 
course segments have been at the centre of 
the debate over the nucleus-satellite distinction 
(Moore and Pollack, 1992; Moser and Moore, 
1996; Bateman and Rondhius, 1997); the acces- 
sibility of discourse segments on the right fron- 
tier of a discourse structure is a phenomenon 
that has already been discussed by several re- 
searchers (Webber, 1991; Asher, 1993). Extra- 
position provides a useful and sometimes im- 
portant means of rearranging complex material 
in an abstract discourse representation in order 
to satisfy the constraints posed by linearisation 
into text. 
References 
N. Asher. 1993. Reference to Abstract Objects 
in Discourse. Kluwer Academic Publishers, 
Netherlands. 
J. Bateman and K. Rondhius. 1997. Coher- 
ence relations: Towards a general specifica- 
tion. Discourse Processes, 24(1):3-50. 
N. Bouayad-Agha, D. Scott, and R. Power. 
2000. Integrating content and style in doc- 
mnents: a case study of patient informa- 
tion leaflets. Information Design Journal, 
-9(2):161~176. - -  ? : - ' . : : -  
B. Grote, N. Lenke, and Stede M. 1997. 
Ma(r)king concessions in english and german. 
Discourse Processes, 24( 1):87-117. 
W. Mann and S. Thompson. 1988. Rhetorical 
structure theory: towards a functional theory 
of text organization. Text, 8(3):243-281. 
D. Marcu, L. Carlson, and M. Watanabe. 2000. 
The automatic translation of discourse struc- 
tures. In Proceedings of the North Ameri- 
can Chapter of the Association for Comptu- 
ational Linguistics (NAACL'2000), Seattle, 
Washington. 
D. Marcu. 1996. Building up rhetorical struc- 
ture trees. In Proceedings of AAAI-96. Amer- 
ican Association for Artificial Intelligence. 
D.J Moore and M.E. Pollack. 1992. A prob- 
lem for rst: The need for multi-level dis- 
course analysis. Computational Linguistics, 
18(4):537-544. 
M. Moser and J.D. Moore. 1996. Towards a 
synthesis of two accounts of discourse struc- 
ture. Computational Linguistics, 22(3):409- 
419. 
G. Nunberg. 1990. The Linguistics of Punctu- 
ation. CSLI, Stanford, USA. 
R. Power. 2000. Mapping rhetorical struc- 
tures to text structures by constraint satis- 
faction. Technical report, ITRI, University of 
Brighton. 
RAGS. 1999. The RAGS project: towards 
a reference architecture for natural lan- 
guage generation systems. Technical report, 
Information Technology Research Institute, 
Brighton, UK. 
D. Scott and C. de Souza. 1990. Getting the 
message across in RST-based text generation. 
In R. Dale, C. Mellish, and M. Zock, editors, 
Current Research in Natural Language Gen- 
eration. Cognitive Science Series, Academic 
Press. 
B.L Webber. 1991. Structure and ostension in 
the interpretation of discourse deixis. Lan- 
guage and Cognitive Processes, 6(2):107-135. 
200 
Automatic generation of large-scale paraphrases
Richard Power and Donia Scott
Centre for Research in Computing
The Open University
Walton Hall
Milton Keynes MK7 6AA
{r.power,d.scott}@open.ac.uk
Abstract
Research on paraphrase has mostly fo-
cussed on lexical or syntactic variation
within individual sentences. Our con-
cern is with larger-scale paraphrases,
from multiple sentences or paragraphs
to entire documents. In this paper
we address the problem of generating
paraphrases of large chunks of texts.
We ground our discussion through a
worked example of extending an exist-
ing NLG system to accept as input a
source text, and to generate a range of
fluent semantically-equivalent alterna-
tives, varying not only at the lexical and
syntactic levels, but also in document
structure and layout.
1 Introduction
Much work on paraphrase generation has fo-
cussed on lexical variation and syntactic trans-
formation within individual sentences (Barzilay
and McKeown, 2001; Carroll et al, 1999; Dras,
1999; Inui and Nogami, 2001; Kozlowski et al,
2003; Langkilde and Knight, 1998; Takahashi
et al, 2001; Stede, 1999). Our interest in this
paper lies instead with variations at the level of
text structuring ? the way in which propositions
are grouped into units like paragraphs, sections,
and bulletted lists, and linked rhetorically by dis-
course connectives such as ?since?, ?nevertheless?,
and ?however?. Elsewhere, we have described a
text-structuring method in which the options for
organising propositions in a text are laid out as a
set of constraints, so that acceptable solutions can
be enumerated using constraint satisfaction and
evaluated using a cost metric (Power et al, 2003).
In this paper we show how this method, when
harnessed to a system for recognising rhetorical
structure in an input text, can be employed in or-
der to produce large-scale paraphrases fulfilling
purposes like improving coherence and achieving
a desired style of layout.
2 Text structure
The input to our text-structuring system (ICONO-
CLAST) is a rhetorical structure tree (Mann and
Thompson, 1983) in which the leaves are elemen-
tary propositions, specified either as semantic for-
mulas or as canned text. The following is a simple
example, containing one nucleus-satellite relation
(REASON) and one multinuclear relation (CON-
JUNCTION1):
reason
NUCLEUS: recommend(doctors, elixir)
SATELLITE: conjunction
1: quick-results(elixir)
2: few-side-effects(elixir)
Ignoring variations in the wording of proposi-
tions, ICONOCLAST generates over 20 texts re-
alising this input (or many more if a larger reper-
toire of discourse connectives is allowed). They
include the following two solutions, which lie at
stylistic extremes, the first compressing the mes-
sage into a sentence (suitable if space is at a pre-
mium), the second laying it out more expansively
in a list:
1This is the RST relation, LIST, which we have renamed
here to avoid possible confusion with the layout style of ver-
tical lists.
73
Solution 1
Doctors recommend Elixir since it gives quick
results and it has few side effects.
Solution 2
? Elixir gives quick results.
? Elixir has few side effects.
Therefore, it is recommended by doctors.
Comparing these solutions illustrates some of the
text-structuring options, and some ways in which
they interact.
? Propositions, or groups of propositions, can
be realised by different text categories. Thus
quick-results(elixir) is realised
by a text-phrase (in Nunberg?s sense (Nun-
berg, 1990)) in Solution 1, and by a text-
sentence (also a list item) in Solution 2.
? Rhetorical relations can be expressed by dif-
ferent discourse connectives or layout op-
tions. In Solution 1, REASON is realised by
?since? and CONJUNCTION by ?and?; in So-
lution 2 REASON is realised by ?therefore?
and CONJUNCTION (more implicitly) by a
bulletted list.
? Propositions may be realised in different or-
ders: for instance, the nucleus of the REA-
SON relation comes first in Solution 1, while
the satellite comes first in Solution 2. Note
that order is constrained by the choice of
discourse connective: ?therefore? requires
satellite-first; ?since? allows both orders.
These text-structuring decisions strongly influ-
ence the options for wording the individual propo-
sitions, mostly because they determine the order
in which propositions are presented. In Solution
1, the nucleus of the REASON relation is presented
first, so ?Elixir? has to be referenced by name, and
there is no particular reason for preferring passive
to active. In Solution 2, the same proposition oc-
curs at the end, when Elixir has been introduced
and established as the topic focus; it is therefore
appropriate to refer to Elixir by a pronoun, and to
promote this reference to the most salient position
in the clause by passivization.
Text structuring is controlled by hard con-
straints, which determine the set of solutions that
can be generated, and by preferences (or soft con-
straints), which allow a ranking of solutions from
best to worst. The purpose of hard constraints
is to avoid solutions that are clearly anomalous,
such as the following text in which the arguments
of the CONJUNCTION relation are separated, thus
altering the rhetorical interpretation:
Since Elixir gives quick results doctors recom-
mend it, and it has few side effects.
A more marginal case is the following solution,
in which the arguments of a nucleus-satellite re-
lation are expressed as items in a bulletted list.
In the default settings this is also considered an
anomaly, since a bulletted list usually implies a
parallelism among the items that is violated when
one argument dominates the other.
? Elixir gives quick results and has
few side-effects.
? Therefore, it is recommended by doctors.
The purpose of soft constraints is to represent
stylistic preferences. These include general prin-
ciples of prose quality that are likely to apply to
any context, as well as preferences specifically
linked to the purpose of the text and the nature
of the intended reader. Here are four examples
of preferences supported in ICONOCLAST: we
would assume that the first two are general, the
second two specific.
? Avoid single-sentence paragraphs This
would penalise a solution in which our ex-
ample was laid out in two paragraphs, one
for satellite and one for nucleus.
? Avoid discontinuity of reference As Kibble
and Power (2004) have shown, centering cri-
teria can be used to penalize solutions with
relatively many topic shifts.
? Avoid passivization In contexts requiring
an informal, popular style, there might be a
stronger tendency to favour active over pas-
sive.
? Avoid complex sentences For some con-
texts we might prefer to penalize solutions
in which many propositions are presented
within the same sentence (e.g., Solution 1).
All these preferences are implemented through a
cost metric. To calculate the cost of a solution,
74
the program first recognizes all violations, then
multiplies each by a weight representing its im-
portance before summing to obtain a total score.
During execution, the program can either enumer-
ate all solutions, ranking them from low cost to
high, or it can simply search for the best solution
using branch-and-bound optimization.
3 Controlling constraints and
preferences
ICONOCLAST was originally developed as a
component of a Natural Language Generation
system. It assumes that the propositional content
of the desired text is already formally encoded,
along with a rhetorical-structure tree represent-
ing the role of each proposition in the argument.
The program can also be run on a simplified in-
put in which propositions are replaced by canned
phrases; however, the quality in this case will
obviously suffer, since referring expressions and
clause structure cannot be adapted to context. By
itself, then, ICONOCLAST cannot be used in or-
der to paraphrase an independently provided text.
However, once a semantic model is available, the
system allows an unusual degree of flexibility and
precision in controlling paraphrases. The source
of this power lies in the use of explicitly encoded
constraints and preferences, which can be edited
through a direct-manipulation user interface in or-
der to guide the generator in the desired direc-
tions.
For hard constraints, the control interface
works mostly by buttons for switching constraints
on and off, or occasionally by menus for fixing
the value of a parameter. Examples of switches
are the following (also mentioned above):
Allow indented list for arguments of a
multinuclear relation (Yes/No)
Allow indented list for arguments of a
nucleus-satellite relation (No/Yes)
Allow discourse connective introducing
a list item (Yes/No)
The default in each case is the option given first,
which would allow (but not require) a solution
to our example in which the conjunction was re-
alised by a list including the discourse connective
?and?:
Doctors recommend Elixir because
? Elixir gives quick results
? And it has few side effects
An example of a parameter setting would be a
constraint fixing the textual unit governing the
whole text, or the maximum text level allowed for
an indented list item:
Root textual unit
(document/section/paragraph/text-sentence)
Maximum level for list item
(paragraph/text-sentence/text-clause)
By constraining the whole text to fit in a para-
graph, we could eliminate any solution requiring
multiple paragraphs (e.g., nucleus in one para-
graph and satellite in another). Under this set-
ting, both solutions 1 and 2 could be generated
(although solution 1 would have to be a single-
sentence paragraph). Further constraining the
root level to sentence would preserve solution
1 but eliminate solution 2.
For soft constraints, the user interface works
through sliders representing both the direction of
a preference and its intensity. In most cases, the
sliders are calibrated to an 11-point scale from
-5 to +5. A straightforward example is the di-
chotomy between active and passive voice, where
negative values penalize use of the passive, while
positive values penalize use of the active; the
central value (zero) represents neutrality. A cost
value is computed every time a proposition is re-
alised by a clause for which the grammar allows
passivization. Depending on the setting of the
11-point scale, a cost is incurred either for use
of the passive (negative values on the scale), or
for failure to use it (positive values on the scale);
the amount of cost varies from 1 to 5, again de-
pending on the setting. Thus if the user sets the
passivization slider to a value of -4, a cost of 4
accrues every time a proposition is realised by a
passive clause; or for a value of +2, a cost of 2
accrues every time a proposition that could have
been realised by a passive clause is realised by an
active one.
In practice, this method of evaluating solu-
tions typically means that every solution is flawed,
given a non-trivial semantic input and a suffi-
cient range of preferences. The reason is that
many decisions are trade-offs: avoiding cost on
75
one preference often means incurring cost else-
where. For instance, a preference to avoid the pas-
sive conflicts with the preference to preserve top-
ical coherence, which is expressed by penalizing
a ?salience violation? ? that is, a failure to equate
the backward-looking center in a clause with the
most salient forward-looking center (i.e., Cb with
Cp) (Kibble and Power, 2004). If salience re-
quires passivization, and passivization is penal-
ized, then a cost must be incurred somewhere: the
issue is which is the lesser evil.
We have considered two ways of control-
ling a paraphrase in a constraint-based gener-
ator: imposing/relaxing a hard constraint, and
changing a preference. A possibility that
we have not yet implemented is a hard con-
straint defined only on the current problem,
as opposed to the general settings illustrated
above. The constraint might state, for example,
that the proposition recommend(doctors,
elixir) should appear at the beginning of the
text, thus eliminating Solution 2. Or it might
state that the conjunction relation between the
other propositions should be realised by a bullet-
ted list, thus eliminating Solution 1. To support
constraints of this kind one would need a user in-
terface in which the user can select part of the
semantic input, perhaps by clicking on the cor-
responding part of the text, as in a WYSIWYM
interface (Power and Scott, 1998); a dialogue
box would then appear allowing a range of con-
straints specifically directed to the selected frag-
ment. Such an interface would mimic the typical
interaction between a human writer and human
critic ? e.g., the critic might highlight a para-
graph and advise the writer to reformat it as a list.
4 Deriving the rhetorical-semantic input
We have shown that by defining text-structuring
as a Constraint Satisfaction Problem, our method
allows considerable flexibility and precision in
controlling the generation of paraphrases (Power
et al, 2003). The question now is whether the
system can be extended so that it accepts a text as
input, rather than a formally encoded rhetorical-
semantic representation. Obviously the extended
system will require an extra component perform-
ing interpretation of the input text ? but how
much interpretation is needed in order to pro-
vide an encoding that the current ICONOCLAST
text-structurer can use? Can we extract suffi-
cient rhetorical and referential information to al-
low reasonable paraphrases, without depending
on a full semantic analysis of the original text?
In this section we consider three stages of inter-
pretation, which could be applied incrementally:
1. Rhetorical mark-up: The program marks
up the EDUs (Elementary Discourse Units)
(Marcu, 2000) in the input text ? what we
have been calling the elementary proposi-
tions ? and also identifies the rhetorical
relations among them, expressed through a
Rhetorical Structure Tree. Within EDUs
there is no mark-up: at this stage they are
treated as canned strings.
2. Coreference mark-up: The program identi-
fies noun-phrases referring to discourse en-
tities, and recognises chains referring to
the same entity. For each discourse entity,
enough semantic information is recovered to
allow a correct choice of pronoun (i.e., val-
ues are assigned to features like NUMBER,
GENDER, HUMAN), but no further semantic
analysis is assumed.
3. Clause transformations: The syntactic struc-
ture of each EDU is analysed sufficiently to
allow a reformulation that promotes a differ-
ent discourse entity as the most salient of the
clause (i.e., the Cp). Typically this would
mean a change of voice from active to pas-
sive, or vice-versa, although there might be
other variations like fronting that could be
explored.
We now discuss these stages in turn.
4.1 Recognising rhetorical structure
Maintaining the same example, suppose that the
input text is the following (a slight variation of
Solution 1):
Doctors recommend Elixir since it gives quick
results and has few side effects.
The goal at this stage is to interpret this text as
a set of elementary propositions, represented by
canned phrases, organised into a tree by rhetorical
relations. An example of the desired encoding, in
76
the format actually used as input to the current
system, is the following XML fragment:
<RhetRep relation=reason>
<SemRep prop="doctors recommend Elixir"/>
<RhetRep relation=conjunction>
<SemRep prop="it gives quick results"/>
<SemRep prop="it has few side-effects"/>
</RhetRep>
</RhetRep>
As can be seen, even though this representation
provides no analysis within propositions (EDUs),
the task of deriving the rhetorical structure and the
canned phrases is not trivial. First, the rhetorical
relations REASON and CONJUNCTION must be in-
ferred. Second, the correct tree structure must be
assigned, with REASON dominating CONJUNC-
TION. Third, the discourse connectives ?since?
and ?and? must be separated from the phrases
in which they occur ? the aim is that these
phrases should represent only the propositions.
Finally, where parts of a phrase have been elided
through aggregation (e.g., ?has few side-effects?),
the missing part (?it?) should be found and re-
placed.
If this level of interpretation is achieved, the
program will be able to generate several dozen
paraphrases, but referential continuity will be
poor unless we pose the additional constraint that
the order of propositions should remain the same
as in the original. Thus a successful paraphrase,
including some reformatting, would be the fol-
lowing:
Doctors recommend Elixir since:
? it gives quick results.
? it has few side effects.
However, with satellite preceding nucleus, as in
Solution 2, the text becomes incoherent because
the first mentions of Elixir are through a pronoun.
? It gives quick results.
? It has few side effects.
Therefore, doctors recommend Elixir.
4.2 Recognising coreference
Incoherence resulting from canned propositions
can be partly remedied if the analysis of the in-
put text is taken a stage further, by recognising
some simple semantic features on noun phrases,
and marking them up for coreference. The ele-
mentary propositions in our example could for in-
stance be marked up as follows:
<edu>
<np id=1 phrase="doctors"
class="human" number="plural"/>
recommend
<np id=2 phrase="Elixir"
class="thing" number="singular"/>
</edu>
<edu>
<pronoun id=2 phrase="it"/>
gives
<np id=3 phrase="quick results"
class="thing" number="plural"/>
</edu>
<edu>
<pronoun id=2 phrase="it"/>
has
<np id=4 phrase="few side-effects"
class="thing" number="plural"/>
</edu>
This further mark-up facilitates text-structuring in
two ways. First, since centering information is
now available (the Cb and Cp of each proposi-
tion can be computed), the evaluation of solu-
tions can take account of the centering prefer-
ences proposed by Kibble and Power (2004). Sec-
ondly, when realising individual propositions, the
referring expressions can be adapted to context,
perhaps by replacing a name/description with a
pronoun, or even eliding it altogether when two
propositions are aggregated. This means that the
program will be able to generate solutions such as
the following, in which the wordings of the propo-
sitions has been revised:
Since Elixir gives quick results and has few side-
effects, doctors recommend it.
This solution illustrates three ways in of revising
a proposition:
? Pronoun ? Name ?it gives quick results?
becomes ?Elixir gives quick results?.
? Elision ?it has few side-effects? becomes
?has few side-effects?.
? Name ? Pronoun ?doctors recommend
Elixir? becomes ?doctors recommend it?.
The generated paraphrases should now be more
fluent, but the program is still limited by its inabil-
ity to control the most salient referent in a propo-
sition (i.e., to modify the Cp). To add this op-
tion, we need the third level of interpretation men-
tioned above, in which the structure of a clause
can be transformed (e.g., from active to passive).
77
4.3 Clause transformations
Assuming that the analysis program can com-
pletely parse a clause identified as an EDU, it may
be able to apply a syntactic transformation which
expresses the same proposition with changed in-
formation focus. An obviously useful transforma-
tion is passivization ? or its opposite if the orig-
inal sentence is in the passive. Assuming that the
parser has correctly identified the main verb, and
that the program has access to a lexical database
including irregular morphology, it could derive
alternative formulations for the original proposi-
tions by a rule such as the following:
[NP1] recommends [NP2]?
[NP2] is recommended by [NP1]
Of course the program should not allow such
transformations for special verbs like ?be? and
?have?, so as to avoid clumsy renderings like ?few
side effects are had by Elixir?. However, when
used on an appropriate verb, passivization can im-
prove the fluency of the solution by promoting
the Cb of the proposition to the subject position,
so that it becomes the Cp; revisions of this kind
also provide more opportunities for favourable
pronominalization and elision. With this extra
resource, the solution just proposed can be im-
proved as follows:
Since Elixir gives quick results and has few side-
effects, it is recommended by doctors.
A more ambitious aim would be to transform be-
tween finite and reduced forms of a subordinate
clause. For instance, if the original text is ?De-
spite having few side-effects, Elixir is banned
by the FDA?, we could allow the transformation
of ?having few side-effects? into the finite clause
?Elixir has few side-effects, borrowing the subject
and tense from the main clause. This transforma-
tion would enable the system to generate a solu-
tion using a connective such as ?however? which
requires that full clauses are employed both for
the nucleus and the satellite. Alternatively, a fi-
nite clause could be transformed into the reduced
form, so allowing the connective ?despite?.
Conclusion
It is hard to conceive of an NLG system that
cannot produce alternative realisations, and thus
paraphrases. Most systems, however, are only
capable of producing variations at the lexical or
syntactic levels (or both). As such, they operate
very much like traditional Machine Translation
systems ? except that the source and target texts
are now in the same language ? and have similar
limitations. Additionally, most of them work with
input that is a representation of the meaning of a
(source) text, rather than the text itself.
The system described in this paper develops an
existing NLG system into a full-blown paraphase
generator capable of producing a wide range of
alternative renditions of the source text, with vari-
ations at three linguistic levels: lexical choice,
syntactic structure, and document structure. This
is in contrast to most existing paraphrase gener-
ators, which are constrained to vary only the first
or second of these levels (Barzilay and McKeown,
2001; Carroll et al, 1999; Dras, 1999; Inui and
Nogami, 2001; Kozlowski et al, 2003; Langkilde
and Knight, 1998; Takahashi et al, 2001; Stede,
1999). The range of lexical and syntactic varia-
tion in a paraphrase generator obviously depends
on how deeply the input text is interpreted, but
even with the relatively superficial analysis pro-
posed here, we can introduce variations for dis-
course connectives, referring expressions (in par-
ticular, when to use pronouns), and some clause
patterns (e.g., whether to use active or passive).
However, the innovation in our work lies in its
controlled variation in the third level, document
structure: just as the other paraphrase generators
provide multiple lexical-syntactic structures for
the same semantic structure, so our system pro-
vides multiple document structures for the same
discourse structure (i.e., for the same rhetori-
cal structure). The document structure solutions
serve not only to realise the rhetorical input, but
also to create a context that determines which of
the alternative syntactic realisations is most suit-
able for the elementary propositions.
Our paraphrase generator links an exist-
ing general-purpose discourse parser ? DAS
(Le Thanh et al, 2004)2 ? which builds a dis-
course tree automatically from an input text, to an
existing NLG system ?ICONOCLAST (Power
et al, 2003) ? which generates a wide range of
2Similar parsers have been developed by Marcu (2000)
and Corston-Oliver (1998)
78
formulations for a given discourse structure. We
have described here the issues that need to be
taken into account when turning any NLG sys-
tem into a fully-fledged paraphraser. We believe
that our approach to text-structuring, whereby op-
tions for organising propositions in a text are laid
out as a set of constraints, and acceptable solu-
tions are enumerated using constraint satisfaction
and evaluated using a cost metric, provides a par-
ticularly useful method for achieving large-scale
paraphrases. Although we are agnostic with re-
spect to the issue of psychological validity, it is
worth noting that our method reflects many of
the processes facing any writer or editor trying to
achieve their ideal text, but constrained by the lin-
guistic resources at hand (e.g., wording, syntax,
discourse and layout) which interact with each
other such that the final text is invariably a flawed
version of the ideal.
For evaluation of our system, two points need
to be addressed. The first concerns fidelity: are the
generated solutions equivalent in meaning to the
original input text? The second concerns qual-
ity: are the generated solutions ranked, by the
cost metric, in a way that corresponds to the pref-
erences of good judges? More practically, we
would like to explore the issue of usability: the
main question here is whether human users can
successfully manipulate the system?s constraints
and preferences in order to guide solutions in the
desired direction.
References
Regina Barzilay and Kathleen McKeown. 2001. Ex-
tracting paraphrases from a parallel corpus. In Pro-
ceedings of the 39th Annual Meeting of the Associ-
ation for Computational Linguistics, pages 50?57,
Toulouse.
J. Carroll, G. G. Minnen, D. Pearce, Y. Canning,
S. Devlin, and J. Tait. 1999. Simplifying text
for language-impaired readers. In Proceedings of
the 9th Conference of the European Chapter of the
Association for Computational Linguistics (EACL-
99), pages 269?270, Bergen, Norway.
S. Corston-Oliver. 1998. Computing Representations
of the Structure of Written Discourse. Ph.D. thesis,
University of California, Santa Barbara, CA, USA.
Mark Dras. 1999. Tree Adjoining Grammar and the
Reluctant Paraphrasing of Text. Ph.D. thesis, Mac-
quarie University, Australia.
Kentaro Inui and Masaru Nogami. 2001. A
paraphrase-based exploration of cohesiveness crite-
ria. In Proceedings of the 8th European Workshop
on Natural Language Generation (EWNLG-01).
Rodger Kibble and Richard Power. 2004. Optimising
referential coherence in text generation. Computa-
tional Linguistics, 30(4).
Raymond Kozlowski, Kathleen F. McCoy, and
K. Vijay-Shanker. 2003. Generation of single-
sentence paraphrases from predicate/argument
structure using lexico-grammatical resources. In
Proceedings of the Second International Workshop
on Paraphrasing, pages 1?8.
Irene Langkilde and Kevin Knight. 1998. Generation
that exploits corpus-based statistical knowledge. In
Proceedings of the 17th International Conference
on Computational Linguistics and the 36th Annual
Meeting of the Association for Computational Lin-
guistics (COLING-ACL98), pages 704?710, Mon-
treal.
H. Le Thanh, G. Abeysinghe, and C. Huyck. 2004.
Generating discourse structures for written texts.
In Proceedings of the 20th International Con-
ference on Computational Linguistics (COLING-
2004), pages 329?335.
W.C Mann and S.A. Thompson. 1983. Relational
propositions in discourse. Technical Report RR-83-
115, Information Sciences Institute.
D. Marcu. 2000. The theory and practice of dis-
course parsing and summarisation. MIT Press,
Cambridge, Massachusetts, USA.
Geoffrey Nunberg. 1990. The Linguistics of Punctu-
ation. CSLI Lecture Notes, No. 18. Center for the
Study of Language and Information, Stanford.
Richard Power and Donia Scott. 1998. Multilingual
authoring using feedback texts. In Proceedings of
17th International Conference on Computational
Linguistics and 36th Annual Meeting of the Associ-
ation for Computational Linguistics (COLING-ACL
98), pages 1053?1059, Montreal, Canada.
Richard Power, Donia Scott, and Nadjet Bouayad-
Agha. 2003. Document structure. Computational
Linguistics, 29(2):211?260.
Manfred Stede. 1999. Lexical semantics and knowl-
edge representation in multilingual text genera-
tion. Kluwer Academic Publishers, Boston.
Tetsuro Takahashi, Tomoyam Iwakura, Ryu Iida, At-
sushi Fujita, and Kentaro Inui. 2001. Kura: A
transfer- based lexico-structural paraphrasing en-
gine. In Proceedings of the Workshop on Automatic
Paraphrasing. (NLPRS 2001), Tokyo.
79
Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 699?706,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Implementing a Characterization of Genre for                              
Automatic Genre Identification of Web Pages 
 
Marina Santini 
NLTG 
University of Brighton 
UK 
M.Santini@brighton.ac.uk 
Richard Power 
Computing Department 
Open University 
UK 
r.power@open.ac.uk  
Roger Evans 
NLTG 
University of Brighton 
UK 
R.P.Evans@brighton.ac.uk 
 
 
Abstract 
In this paper, we propose an 
implementable characterization of genre 
suitable for automatic genre 
identification of web pages. This 
characterization is implemented as an 
inferential model based on a modified 
version of Bayes? theorem. Such a model 
can deal with genre hybridism and 
individualization, two important forces 
behind genre evolution. Results show 
that this approach is effective and is 
worth further research. 
1 Introduction 
The term ?genre? is employed in virtually all 
cultural fields: literature, music, art, architecture, 
dance, pedagogy, hypermedia studies, computer-
mediated communication, and so forth. As has 
often been pointed out, it is hard to pin down the 
concept of genre from a unified perspective (cf. 
Kwasnik and Crowston, 2004). This lack is also 
experienced in the more restricted world of non-
literary or non-fictional document genres, such 
as professional or instrumental genres, where 
variation due to personal style is less pronounced 
than in literary genres. In particular, scholars 
working with practical genres focus upon a 
specific environment. For instance Swales (1990) 
develops his notion of genre in academic and 
research settings, Bathia (1993) in professional 
settings, and so on. In automatic genre 
classification studies, genres have often been 
seen as non-topical categories that could help 
reduce information overload (e.g. Mayer zu 
Eissen and Stein, 2004; Lim et al, 2005).  
Despite the lack of an agreed theoretical 
notion, genre is a well-established term, 
intuitively understood in its vagueness. What 
humans intuitively perceive is that there are 
categories created within a culture, a society or a 
community which are used to group documents 
that share some conventions. Each of these 
groups is a genre, i.e. a cultural object or artefact, 
purposely made to meet and streamline 
communicative needs. Genres show sets of 
standardized or conventional characteristics that 
make them recognizable, and this identity raises 
specific expectations.   
Together with conventions and expectations, 
genres have many other traits. We would like to 
focus on three traits, namely hybridism, 
individualization and evolution. Genres are not 
mutually exclusive and different genres can be 
merged into a single document, generating 
hybrid forms. Also, genres allow a certain 
freedom of variation and consequently can be 
individualized. Finally, genre repertoires are 
dynamic, i.e. they change over time, thus 
triggering genre change and evolution. It is also 
important to notice that before genre conventions 
become fully standardized, a genre does not have 
an official name. A genre name becomes 
acknowledged when the genre itself has an active 
role and a communicative function in a 
community or society (Swales, 1990). Before 
this acknowledgement, a genre shows hybrid or 
individualized forms, and indistinct functions. 
Putting all these traits together, we suggest the 
following broad theoretical characterization of 
genre of written texts: genres are named 
communication artefacts characterized by 
conventions, raising expectations, showing 
hybridism and individualization, and undergoing 
evolution. 
This characterization is flexible enough to 
encompass not only paper genres (both literary 
and practical genres), but also digital genres, and 
more specifically web genres. Web genres or 
cybergenres (Shepherd and Watters 1998) are 
those genres created by the combination of the 
use of the computer and the Internet.   
699
Genre hybridism and individualization are very 
evident on the web. In fact, web pages are often 
very hybrid because of the wider intra-genre 
variation and the smaller inter-genre 
differentiation. They can also be highly 
individualized because of the creative freedom 
provided by HTML tags (the building blocks of 
web pages) or programming languages such as 
Javascript. We suggest that genre hybridism and 
individualization can be seen as forces acting 
behind genre evolution. They allow the upgrade 
of existing genres and the creation of novel 
genres.  
The change of genre repertoire and the 
creation of new genres were well illustrated by 
Crowston and Williams (2000) and Shepherd and 
Watters (1998). Both these studies describe a 
similar process. Web genres can start either as 
reproductions or as unprecedented types of 
documents. In the first case, existing genres are 
gradually upgraded and modified to adapt to 
potentials offered by the web. These variants 
might become very different from the original 
genres with time passing by. In the second case, 
novel genres can be generated from specific 
needs and requirements of the web. Crowston 
and Williams (2000) have traced this evolution 
through a manual qualitative survey of 1000 web 
pages. Shepherd and Watters (1998) have 
proposed a fuzzy taxonomy for web genres. 
We would like to add a new force in this 
scenario, namely emerging genres. Emerging 
genre are those genres still in formation, not fully 
standardized and without any name or fixed 
function. For example, before 1998 web logs (or 
blogs) were already present on the web, but they 
were not yet identified as a genre. They were just 
?web pages?, with similar characteristics and 
functions. In 1999, suddenly a community sprang 
up using this new genre (Blood, 2000). Only at 
this point, the genre ?web log? or ?blog? started 
being spread and being recognized. 
Emerging genres may account for all those 
web pages, which remain unclassified or 
unclassifiable (cf. Crowston and Williams, 2000) 
because they show genre mixture or no genre at 
all. Authors often point out that assigning a genre 
to a web page might be difficult and 
controversial (e.g. Roussinov et al, 2001; Meyer 
zu Eissen and Stein, 2004; Shepherd et al, 2004) 
because web pages can appear hybrid or peculiar. 
Genre-mixed web pages or web pages without 
any evident genre can represent the antecedent of 
a future genre, but currently they might be 
considered as belonging to a genre still in 
formation. It is also important to highlight, 
however, that since the acknowledgement of 
genre relies on social acceptance, it is impossible 
to define the exact point at which a new genre 
emerges (Crowston and Williams 2000). The 
multi-facetted model capable of hosting new 
genres wished for by Kwasnik and Crowston 
(2004), and the adaptive learning system that can 
identify genre as they emerge announced by 
Shepherd et al (2004) are hard to implement.  
For this reason, the focus of the method proposed 
below is not to detect emerging genres, but to 
show a flexible approach capable of giving 
account of genre hybridism and 
individualization.  
Flexible genre classification systems are 
uncommon in automatic genre classification 
studies. Apart from two notable exceptions, 
namely Kessler et al (1997) and Rehm (2006) 
whose implementations require extensive manual 
annotation (Kessler et al, 1997) or analysis 
(Rehm, 2006), genres are usually classified as 
single-label discrete entities, relying on the 
simplified assumption that a document can be 
assigned to only one genre. 
In this paper, we propose a tuple 
representation that maps onto the theoretical 
characterization of genre suggested above and 
that can be implemented without much overhead. 
The implementable tuple includes the following 
attributes: 
(genre(s)) of web pages=<linguistic features, HTML, text types, [...]> 
This tuple means that web pages can have zero, 
one or more genres ((genre(s)) of web pages) 
and that this situation can be captured by a 
number of attributes. For the time being these 
attributes are limited to linguistic features, 
HTML tags, text types, but in future other 
attributes can be added ([...]). The attributes of 
the tuple can capture the presence of textual 
conventions or their absence. The presence of 
conventions brings about expectations, and can 
be used to identify acknowledged genres. The 
absence of conventions brings about hybridism 
and individualisation and can be interpreted in 
terms of emerging genres and genre evolution.  
In this paper we present a simple model that 
implement the tuple and can deal with this 
complex situation. This model is based on 
statistical inference, performs automatic text 
analysis and has a classification scheme that 
includes zero labels, one label or multiple labels. 
More specifically, in addition to the traditional 
single-label classification, a zero-label 
700
classification is useful when, for example, a web 
page is so peculiar from a textual point of view 
that it does not show any similarity with the 
genres included in the model. Conversely, a 
multi-label classification is useful when web 
pages show several genres at the same time. As 
there is no standard evaluation metrics for a 
comprehensive evaluation of such a model, we 
defer to further research the assessment of the 
model as a whole. In this paper, we report a 
partial evaluation based on single-label 
classification accuracy and predictions.  
From a theoretical point of view, the 
inferential model makes a clear-cut separation 
between the concepts of ?text types? and 
?genres?. Text types are rhetorical/discourse 
patterns dictated by the purposes of a text. For 
example, when the purpose of a text producer is 
to narrate, the narration text type is used. On the 
contrary, genres are cultural objects created by a 
society or a community, characterized by a set of 
linguistic and non-linguistic conventions, which 
can be fulfilled, personalized, transgressed, 
colonized, etc., but that are nonetheless 
recognized by the members of the society and 
community that have created them, raising 
predictable expectations. For example, what we 
expect from a personal blog is diary-form 
narration of the self, where opinions and 
comments are freely expressed.  
The model presented here is capable of 
inferring text types from web pages using a 
modified form of Bayes? theorem, and derive 
genres through if-then rules.  
With this model, emerging genres can be 
hypothesized through the analysis of unexpected 
combinations of text types and/or other traits in a 
large number of web pages. However, this 
potential will be investigated in future work. The 
results presented here are just a first step towards 
a more dynamic view of a genre classification 
system. 
Automatic identification of text types and 
genres represents a great advantage in many 
fields because manual annotation is expensive 
and time-consuming. Apart from the benefits that 
it could bring to information retrieval, 
information extraction, digital libraries and so 
forth, automatic identification of text types and 
genres could be particularly useful for problems 
that natural language processing (NLP) is 
concerned with. For example, parsing accuracy 
could be increased if parsers were tested on 
different text types or genres, as certain 
constructions may occur only in certain types of 
texts. The same is true for Part-of-Speech (POS) 
tagging and word sense disambiguation. More 
accurate NLP tools could in turn be beneficial for 
automatic genre identification, because many 
features used for this task are extracted from the 
output of taggers and parsers, such as POS 
frequencies and syntactic constructions. 
The paper is organized as follows: Section 2 
reports previous characterization that have been 
implemented as statistical or computational 
models; Section 3 illustrates the attributes of the 
tuple; Section 4 describes the inferential model 
and reports evaluation; finally in Section 5 we 
draw some conclusions and outline points for 
future work. 
2 Background 
Although both Crowston and Williams (2000) 
and Shepherd and Watters (1998) have well 
described the evolution of genres on the web, 
when it comes to the actual genre identification 
of web pages (Roussinov et al, 2001; and 
Shepherd et al, 2004, respectively), they set 
aside the evolutionary aspect and consider genre 
from a static point of view. For Crowston and 
Williams (2000) and the follow-up Roussinov et 
al. (2001) most genres imply a combination of 
<purpose/function, form, content>, and, as they 
are complex entities, a multi-facetted 
classification seems appropriate (Kwasnik and 
Crowston, 2004). For Shepherd and Watters 
(1998) and the practical implementation 
Shepherd et al (2004), cybergenres or web 
genres are characterized by the triple <content, 
form, functionality>, where functionality is a key 
evolutionary aspect afforded by the web. 
Crowston and co-workers have not yet 
implemented the combination of 
<purpose/function, form, content> together with 
the facetted classification in any automatic 
classification model, but the tuple <content, 
form, function> has been employed by Rehm 
(2006) for an original approach to single-web 
genre analysis, the personal home pages in the 
domain of academia. Rehm (2006) describes the 
relationship between HTML and web genres and 
depicts the evolutionary processes that shape and 
form web genres. In the practical 
implementation, however, he focuses only on a 
single web genre, the academic?s personal home 
page, that is seen from a static point of view. As 
far as we know, Boese and Howe (2005) is the 
only study that tries to implement a diachronic 
view on genre of web pages using the triple 
701
<style, form, content>. This study has the 
practical aim of finding out whether feature sets 
for genre identification need to be changed or 
updated because of genre evolution. They tried to 
detect the change through the use of a classifier 
on two parallel corpora separated by a six-year 
gap. Although this study does not focus on how 
to detect newly created web genres or how to 
deal with difficult web pages, it is an interesting 
starting point for traditional diachronic analysis 
applied to automatic genre classification.  
In contrast, the model described in this paper 
aims at pointing out genre hybridism and 
individualisation in web pages. These two 
phenomena can be interpreted in terms of genre 
evolution in future investigations. 
3 Attributes of the Tuple 
The attributes <linguistic features, HTML tags, 
text types> of the tuple represent the 
computationally tractable version of the 
combination <purpose, form> often used to 
define the concept of genre (e.g. cf. Roussinov et 
al. 2001).  
In our view, the purpose corresponds to text 
types, i.e. the rhetorical patterns that indicate 
what a text has been written for. For example, a 
text can be produced to narrate, instruct, argue, 
etc. Narration, instruction, and argumentation are 
examples of text types. As stressed earlier, text 
types are usually considered separate entities 
from genres (cf. Biber, 1988; Lee, 2001). 
Form is a more heterogeneous attribute. Form 
can refer to linguistic form and to the shape 
(layout etc.). From an automatic point of view, 
linguistic form is represented by linguistic 
features, while shape is represented by HTML 
tags. Also the functionality attribute introduced 
by Shepherd and Watters (1998) can be seen in 
terms of HTML tags (e.g. tags for links and 
scripts). While content words or terms show 
some drawbacks for automatic genre 
identification (cf. Boese and Howe, 2005), there 
are several types of linguistic features that return 
good results, for instance, Biberian features 
(Biber, 1988). In the model presented here we 
use a mixture of Biberian features and additional 
syntactic traits. The total number of features used 
in this implementation of the model is 100. 
These features are available online at: 
http://www.nltg.brighton.ac.uk/home/Marina.Santini/ 
4 Inferential Model 
The inferential model presented here (partially 
discussed in Santini (2006a) combines the 
advantages of deductive and inductive 
approaches. It is deductive because the co-
occurrence and the combination of features in 
text types is decided a priori by the linguist on 
the basis on previous studies, and not derived by 
a statistical procedure, which is too biased 
towards high frequencies (some linguistic 
phenomena can be rare, but they are nonetheless 
discriminating). It is also inductive because the 
inference process is corpus-based, which means 
that it is based on a pool of data used to predict 
some text types. A few handcrafted if-then rules 
combine the inferred text types with other traits 
(mainly layout and functionality tags) in order to 
suggest genres. These rules are worked out either 
on the basis of previous genre studies or of a 
cursory qualitative analysis. For example, rules 
for personal home pages are based on the 
observations by Roberts (1998), Dillon and 
Gushrowski (2000). When previous studies were 
not available, as in the cases of eshops or search 
pages, the author of this paper has briefly 
analysed these genres to extract generalizations 
useful to write few rules.  
It is important to stress that there is no hand-
coding in the model. Web pages were randomly 
downloaded from genre-specific portals or 
archives without any further annotation. Web 
pages were parsed, linguistic features were 
automatically extracted and counted from the 
parsed outputs, while frequencies of HTML tags 
were automatically counted from the raw web 
pages. All feature frequencies were normalized 
by the length of web pages (in tokens) and then 
submitted to the model. 
As stated earlier, the inferential model makes 
a clear-cut separation between text types and 
genres. The four text types included in this 
implementation are: descriptive_narrative, 
expository_informational, argumentative_persuasive, 
and instructional. The linguistic features for these 
text types come from previous (corpus-)linguistic 
studies (Werlich 1976; Biber, 1988; etc.), and are 
not extracted from the corpus using statistical 
methods. For each web page the model returns 
the probability of belonging to the four text 
types. For example, a web page can have 0.9 
probabilities of being argumentative_persuasive, 
0.7 of being instructional and so on. Probabilities 
are interpreted in terms of degree or gradation. 
For example, a web page with 0.9 probabilities 
702
of being argumentative_persuasive shows a high 
gradation of argumentation. Gradations/ 
probabilities are ranked for each web page.  
The computation of text types as intermediate 
step between linguistic and non-linguistic 
features and genres is useful if we see genres as 
conventionalised and standardized cultural 
objects raising expectations. For example, what 
we expect from an editorial is an ?opinion? or a 
?comment? by the editor, which represents, 
broadly speaking, the view of the newspaper or 
magazine. Opinions are a form of 
?argumentation?. Argumentation is a rhetorical 
pattern, or text type, expressed by a combination 
of linguistic features. If a document shows a high 
probability of being argumentative, i.e. it has a 
high gradation of argumentation, this document 
has a good chance of belonging to argumentative 
genres, such as editorials, sermons, pleadings, 
academic papers, etc. It has less chances of being 
a story, a biography, etc. We suggest that the 
exploitation of this knowledge about the 
textuality of a web page can add flexibility to the 
model and this flexibility can capture hybridism 
and individualization, the key forces behind 
genre evolution. 
4.1 The Web Corpus  
The inferential model is based on a corpus 
representative of the web. In this implementation 
of the model we approximated one of the 
possible compositions of a random slice of the 
web, statistically supported by reliable standard 
error measures. We built a web corpus with four 
BBC web genres (editorial, Do-It-Yourself 
(DIY) mini-guide, short biography, and feature), 
seven novel web genres (blog, eshop, FAQs, 
front page, listing, personal home page, search 
page), and 1,000 unclassified web pages from 
SPIRIT collection (Joho and Sanderson, 2004). 
The total number of web pages is 2,480. The four 
BBC genres represent traditional genres adapted 
to the functionalities of the web, while the seven 
genres are novel web genres, either 
unprecedented or showing a loose kinship with 
paper genres. Proportions are purely arbitrary 
and based on the assumption that at least half of 
web users tend to use recognized genre patterns 
in order to achieve felicitous communication. We 
consider the sampling distribution of the sample 
mean as approximately normal, following the 
Central Limit Theorem. This allows us to make 
inferences even if the population distribution is 
irregular or if variables are very skewed or 
highly discrete. The web corpus is available at: 
http://www.nltg.brighton.ac.uk/home/Marina.Santini/ 
4.2 Bayesian Inference: Inferring with 
Odds-Likelihood 
The inferential model is based on a modified 
version of Bayes? theorem. This modified 
version uses a form of Bayes? theorem called 
odds-likelihood or subjective Bayesian method 
(Duda and Reboh, 1984) and is capable of 
solving more complex reasoning problems than 
the basic version.  Odds is a number that tells us 
how much more likely one hypothesis is than the 
other. Odds and probabilities contain exactly the 
same information and are interconvertible. The 
main difference with original Bayes? theorem is 
that in the modified version much of the effort is 
devoted to weighing the contributions of 
different pieces of evidence in establishing the 
match with a hypothesis. These weights are 
confidence measures: Logical Sufficiency (LS) 
and Logical Necessity (LN). LS is used when the 
evidence is known to exist (larger value means 
greater sufficiency), while LN is used when 
evidence is known NOT to exist (a smaller value 
means greater necessity). LS is typically a 
number > 1, and LN is typically a number < 1. 
Usually LS*LN=1. In this implementation of the 
model, LS and LN were set to 1.25 and 0.8 
respectively, on the basis of previous studies and 
empirical adjustments. Future work will include 
more investigation on the tuning of these two 
parameters.  
The steps included in the model are the 
following: 
1) Representation of the web in a corpus that is 
approximately normal. 
2) Extraction, count and normalization of genre-
revealing features. 
3) Conversion of normalized counts into z-scores, 
which represent the deviation from the ?norm? 
coming out from the web corpus. The concept of 
?gradation? is based on these deviations from the 
norm. 
4) Conversion of z-scores into probabilities, which 
means that feature frequencies are seen in terms 
of probabilities distribution. 
5) Calculation of prior odds from prior probabilities 
of a text type. The prior probability for each of 
the four text types was set to 0.25 (all text types 
were given an equal chance to appear in a web 
page). Prior odds are calculated with the formula:   
 
prOdds(H)=prProb(H)/1-prProb(H)  
 
6) Calculation of weighted features, or multipliers 
(Mn). If a feature or piece of evidence (E) has a 
703
probability >=0.5, LS is applied, otherwise LN is 
applied. Multipliers are calculated with the 
following formulae: 
 
if  Prob (E)>=0.5 then  
M(E)=1+(LS-1)(Prob(E)-0.5)/0.25 
if Prob (E)<0.5 then 
M(E)=1-(1-LN)(0.5-Prob(E))/0.25 
 
7) Multiplication of weighted probabilities together, 
according to the co-occurrence decided by the 
analyst on the basis of previous studies in order to 
infer text types. In this implementation the 
feature co-occurrence was decided following 
Werlich (1976) and Biber (1988). 
8) Posterior odds for the text type is then calculated 
by multiplying prior odds (step 5) with co-
occurrence of weighted features (step 7).  
9) Finally, posterior odds is re-converted into a 
probability value with the following formula: 
 
Prob(H)=Odds(H)/1+Odds(H) 
 
Although odds contains exactly the same 
information as probability values, they are not 
constrained in 0-1 range, like probabilities.  
Once text types have been inferred, if-then 
rules are applied for determining genres. In 
particular, for each of the seven web genre 
included in this implementation, few hand-
crafted rules combine the two predominant text 
types per web genre with additional traits. For 
example, the actual rules for deriving a blog are 
as simple as the following ones: 
 
if (text_type_1=descr_narrat_1|argum_pers_1) 
if (text_type_2=descr_narrat_2|argum_pers_2) 
if (page_length=LONG) 
if (blog_words >= 0.5 probabilities) 
then good blog candidate. 
 
That is, if a web page has description_narration 
and argumentation_persuasion as the two 
predominant text types, and the page length is > 
500 words (LONG), and the probability value for 
blog words is >=0.5 (blog words are terms such 
as web log, weblog, blog, journal, diary, posted 
by, comments, archive plus names of the days 
and months), then this web page is a good blog 
candidate.  
For other web genres, the number of rules is 
higher, but it is worth saying that in the current 
implementation, rules are useful to understand 
how features interact and correlate.  
One important thing to highlight is that each 
genre is computed independently for each web 
page. Therefore a web page can be assigned to 
different genres (Table 1) or to none (Table 2).  
Multi-label and no-label classification cannot be 
evaluated with standard metrics and their 
evaluation requires further research. In the next 
subsection we present the evaluation of the 
single label classification returned by the 
inferential model.  
4.3 Evaluation of the Results 
Single-label classification. For the seven web 
genres we compared the classification accuracy 
of the inferential model with the accuracy of 
classifiers. Two standard classifiers ? SVM and 
Naive Bayes from Weka Machine Learning 
Workbench (Witten, Frank, 2005) ? were run on 
the seven web genres. The stratified cross-
validated accuracy returned by these classifiers 
for one seed is ca. 89% for SVM and ca. 67% for 
Na?ve Bayes. The accuracy achieved by the 
inferential model is ca. 86%. 
An accuracy of 86% is a good achievement for 
a first implementation, especially if we consider 
that the standard Na?ve Bayes classifier returns 
an accuracy of about 67%.  Although slightly 
lower than SVM, an accuracy of 86% looks 
promising because this evaluation is only on a 
single label. Ideally the inferential model could 
be more accurate than SVM if more labels could 
be taken into account. For example, the actual 
classification returned by the inferential model is 
shown in Table 1. The web pages in Table 1 are 
blogs but they also contain either sequences of 
questions and answers or are organized like a 
how-to document, like in the snippet in Figure 1 
 
blog 
augustine 
0000024 
GOOD 
blog 
BAD 
eshop 
GOOD 
faq 
BAD 
frontpage 
BAD 
listing 
BAD 
php 
BAD 
spage 
blog 
britblog 
00000107 
GOOD 
blog 
BAD 
eshop 
GOOD 
faq 
BAD 
frontpage 
BAD 
listing 
BAD 
php 
BAD 
spage 
Table 1. Examples of multi-label classification 
 
Figure 1. Snippet blog_augustine_0000024 
 
704
The snippet shows an example of genre 
colonization, where the vocabulary and text 
forms of one genre (FAQs/How to in this case) 
are inserted in another (cf. Beghtol, 2001). These 
strategies are frequent on the web and might give 
rise to new web genres. The model also captures 
a situation where the genre labels available in the 
system are not suitable for the web page under 
analysis, like in the example in Table 2. 
 
SPRT_010_049 
_112_0055685 
BAD 
blog 
BAD 
eshop 
BAD 
faq 
BAD 
frontpage 
BAD 
listing 
BAD 
php 
BAD 
spage 
Table 2. Example of zero label classification 
This web page (shown in Figure 2) from the 
unannotated SPIRIT collection (see Section 4.1) 
does not receive any of the genre labels currently 
available in the system. 
 
Figure 2. SPRT_010_049_112_0055685 
If the pattern shown in Figure 2 keeps on 
recurring even when more web genres are added 
to the system, a possible interpretation could be 
that this pattern might develop into a stable web 
genre in future. If this happens, the system will 
be ready to host such a novelty. In the current 
implementation, only a few rules need to be 
added. In future implementations hand-crafted 
rules can be replaced by other methods. For 
example, an interesting adaptive solution has 
been explored by Segal and Kephart (2000). 
Predictions. Precision of predictions on one web 
genre is used as an additional evaluation metric. 
The predictions on the eshop genre issued by the 
inferential model are compared with the 
predictions returned by two SVM models built 
with two different web page collections, Meyer-
zu-Eissen collection and the 7-web-genre 
collection (Santini, 2006).  Only the predictions 
on eshops are evaluated, because eshop is the 
only web genre shared by the three models. The 
number of predictions is shown in Table 3. 
 
Models Total 
Predictions 
Correct 
Predictions 
Incorrect 
Predictions and 
Uncertain 
Meyer-zu-Eissen 
and SVM 
6 3 3 
7-web-genre and 
SVM 
11 3 8 
Web corpus and 
inferential model 
17 6 11 
Table 3. Predictions on eshops 
The number of retrieved web pages (Total 
Predictions) is higher when the inferential model 
is used. Also the value of precision (Correct 
Predictions) is higher. The manual evaluation of 
the predictions is available online at: 
http://www.nltg.brighton.ac.uk/home/Marina.Santini/ 
5 Conclusions and Future Work 
From a technical point of view, the inferential 
model presented in this paper is a simple starting 
point for reflection on a number of issues in 
automatic identification of genres in web pages. 
Although parameters need a better tuning and 
text type and genre palettes need to be enlarged, 
it seems that the inferential approach is effective, 
as shown by the preliminary evaluation reported 
in Section 4.3.  
More importantly, this model instantiates a 
theoretical characterization of genre that includes 
hybridism and individualization, and interprets 
these two elements as the forces behind genre 
evolution. It is also worth noticing that the 
inclusion of the attribute ?text types? in the tuple 
gives flexibility to the model. In fact, the model 
can assign not only a single genre label, as in 
previous approaches to genre, but also multiple 
labels or no label at all. Ideally other 
computationally tractable attributes can be added 
to the tuple to increase flexibility and provide a 
multi-facetted classification, for example register 
or layout analysis. 
However, other issues remain open. First, the 
possibility of a comprehensive evaluation of the 
model is to be explored. So far, only tentative 
evaluation schemes exist for multi-label 
classification (e.g. McCallum, 1999). Further 
research is still needed.  
Second, in this model the detection of emerging 
genres can be done indirectly through the 
analysis of an unexpected combination of text 
types and/or genres. Other possibilities can be 
explored in future. Also the objective evaluation 
705
of emerging genres requires further research and 
discussion. 
More feasible in the short term is an 
investigation of the scalability of the model, 
when additional web pages, classified or not 
classified by genre, are added to the web corpus.  
Also the possibility of replacing hand-crafted 
rules with some learning methodology can be 
explored in the near future. Apart from the 
approach suggested by Segal and Kephart (2000) 
mentioned above, many other pieces of 
experience are now available on adaptive 
learning (for example those reported in the 
EACL 2006 on Workshop on Adaptive Text 
Extraction and Mining).  
References 
Bathia V. 1993. Analysing Genre. Language Use in 
Professional Settings. Longman, London-NY. 
Beghtol C. 2001. The Concept of Genre and Its 
Characteristics. Bulletin of The American Society 
for Inform. Science and Technology, Vol. 27 (2). 
Biber D. 1988. Variations across speech and writing. 
Cambridge University Press, Cambridge. 
Blood, R. 2000. Weblogs: A History and Perspective, 
Rebecca's Pocket.  
Boese E. and Howe A. 2005. Effects of Web 
Document Evolution on Genre Classification. 
CIKM 2005, Germany. 
Crowston K. and Williams M. 2000. Reproduced and 
Emergent Genres of Communication on the World-
Wide Web, The Information Society, 16(3), 201-
216. 
Dillon, A. and Gushrowski, B. 2000. Genres and the 
Web: is the personal home page the first uniquely 
digital genre?, JASIS, 51(2). 
Duda R. and Reboh R. 1984. AI and decision making: 
The PROSPECTOR experience. In Reitman, W. 
(Ed.), Artificial Intelligence Applications for 
Business, Norwood, NJ. 
Joho H. and Sanderson M. 2004. The SPIRIT 
collection: an overview of a large web collection, 
SIGIR Forum, December 2004, Vol. 38(2). 
Kessler B., Numberg G. and Sh?tze H. (1997), 
Automatic Detection of Text Genre, Proc. 35 ACL 
and 8  EACL. 
Kwasnik B and Crowston K. 2004. A Framework for 
Creating a Facetted Classification for Genres: 
Addressing Issues of Multidimensionality. Proc. 
37 Hawaii Intern. Conference on System Science. 
Lee D. 2001. Genres, Registers, Text types, Domains, 
and Styles: Clarifying the concepts and navigating 
a path through the BNC Jungle. Language 
Learning and Technology, 5, 37-72. 
Lim, C., Lee, K. and Kim G. 2005. Automatic Genre 
Detection of Web Documents, in Su K., Tsujii J., 
Lee J., Kwong O. Y. (eds.) Natural Language 
Processing, Springer, Berlin. 
Meyer zu Eissen S. and Stein B. 2004. Genre 
Classification of Web Pages: User Study and 
Feasibility Analysis, in Biundo S., Fruhwirth T., 
Palm G. (eds.), Advances in Artificial Intelligence, 
Springer, Berlin, 256-269. 
McCallum A. 1999. Multi-Label Text Classification 
with a Mixture Model Trained by EM, AAAI'99 
Workshop on Text Learning. 
Rehm G. 2006. Hypertext Types and Markup 
Languages. In Metzing D. and Witt A. (eds.), 
Linguistic Modelling of Information and Markup 
Languages. Springer, 2006 (in preparation). 
Roberts, G. 1998. The Home Page as Genre: A 
Narrative Approach, Proc. 31 Hawaii Intern. 
Conference on System Sciences. 
Roussinov D., Crowston K., Nilan M., Kwasnik B., 
Cai J., Liu X. 2001. Genre Based Navigation on 
the Web, Proc. 34 Hawaii Intern. Conference on 
System Sciences. 
Santini M. 2006a. Identifying Genres of Web Pages, 
TALN 06 - Actes de la 13 Conference sur le 
Traitement Automatique des Langues Naturelles, 
Vol. 1, 307-316. 
Santini M. 2006b. Some issues in Automatic Genre 
Classification of Web Pages,  JADT 06 ? Actes des 
8 Journ?es internationales d?analyse statistiques 
des donn?s textuelles, Vol 2, 865-876. 
Segal R. and Kephart J. 2000. Incremental Learning 
in SwiftFile. Proc.  17 Intern. Conf. on Machine 
Learning. 
Shepherd M. and Watters C. 1998. The Evolution of 
Cybergenre,  Proc. 31 Hawaii Intern. Conference 
on System Sciences. 
Shepherd M.,  Watters C., Kennedy A. 2004. 
Cybergenre: Automatic Identification of Home 
Pages on the Web. Journal of Web Engineering, 
Vol. 3(3-4), 236-251. 
Swales, J. Genre Analysis. English in academic and 
research settings, Cambridge University Press, 
Cambridge, 1990. 
Werlich E. (1976). A Text Grammar of English. 
Quelle & Meyer, Heidelberg. 
706
Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 40?48,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
Fast, Scalable and Reliable Generation of Controlled Natural Language
David Hardcastle
Faculty of Maths, Computing
and Technology
The Open University
Milton Keynes, UK
d.w.hardcastle@open.ac.uk
Richard Power
Faculty of Maths, Computing
and Technology
The Open University
Milton Keynes, UK
r.power@open.ac.uk
Abstract
In this paper we describe a natural language
generation system which takes as its input a
set of assertions encoded as a semantic graph
and outputs a data structure connecting the se-
mantic graph to a text which expresses those
assertions, encoded as a TAG syntactic tree.
The scope of the system is restricted to con-
trolled natural language, and this allows the
generator to work within a tightly restricted
domain of locality. We can exploit this fea-
ture of the system to ensure fast and efficient
generation, and also to make the generator re-
liable by providing a rapid algorithm which
can exhaustively test at compile time the com-
pleteness of the linguistic resources with re-
spect to the range of potential meanings. The
system can be exported for deployment with
a minimal build of the semantic and linguistic
resources that is verified to ensure that no run-
time errors will result from missing resources.
The framework is targeted at using natural lan-
guage generation technology to build semantic
web applications where machine-readable in-
formation can be automatically expressed in
natural language on demand.
1 Introduction
This paper describes a fast, reliable and scalable
framework for developing applications supporting
tactical generation ? by which we mean applications
which take as their input some semantic structure
that has already been organised at a high level, and
choose the syntactic structures and words required to
express it. The framework takes as input a semantic
graph representing a set of assertions in Description
Logic (DL) (Baader et al, 2003) and transforms it
into a tree which encodes the grammar rules, syn-
tactic subcategorisations, orderings and lexical an-
chors required to construct a textual representation
of the input data. The resulting text is conceptu-
ally aligned, by which we mean that each compo-
nent of the text structure (such as words, clauses or
sentences, for example) is linked back to the medi-
ating structure from which the text was generated,
and from there back to vertices and edges in the
semantic graph received as input. The target con-
text for the framework is the construction of se-
mantic web (Berners-Lee et al, 2001) resources us-
ing Natural Language Generation (NLG) technology
which extends the notion of semantic alignment de-
veloped in the WYSIWYM system (Power and Scott,
1998; Power et al, 2003). In this context the text is
ephemeral and is generated on demand, while the
document content is fully machine-readable, sup-
porting tasks such as automated consistency check-
ing, inferencing and semantic search/query. Since
the text is fully linked to the underlying semantic
representation it supports a rich user interface en-
compassing fast and reliable semantic search, inline
syntax or anaphora highlighting, knowledge editing,
and so on. Finally, the text could be generated in
many different natural languages making the infor-
mation content more widely available. We envisage
the technology supporting a range of different use
cases such as information feeds, technical instruc-
tions, medical orders or short, factual reports.
For such a system to be of practical value in an
enterprise system the NLG component must sup-
40
port standard aspects of software engineering qual-
ity such as modularity, reliability, speed and scala-
bility. The design of the framework relies on two key
simplifying assumptions and these limit the range of
information which can be represented and the flu-
ency of the text used to express it. Specifically, the
information is limited by the expressivity of DL ?
for example only limited quantification is possible ?
and the surface text is restricted to controlled natu-
ral language (Hartley and Paris, 2001). The upside
of this trade-off is that the domain of locality is very
restricted. This means that there is minimal search
during generation and so the algorithm is fast and
scalable. It also enables us to design the generator
so that it is predictable and can therefore be statically
tested for completeness, a notion which we define in
Section 3.
Our aim in this paper is to show how the simpli-
fying assumptions behind the design bring consider-
able engineering benefits. We discuss the theoreti-
cal background to our approach (Sections 2 and 3)
and then present the implementation details, focus-
ing on the features of the design that support speed
and scalability (Section 4) and reliability (Section
5), followed by an overview of the architectural con-
siderations (Section 6). Finally we present the re-
sults of tests evaluating the system?s performance
(Section 7).
2 Implementation Theory
The generation algorithm has its roots in the WYSI-
WYM system, which was originally developed as a
way of defining the input for multilingual NLG in
DRAFTER (Paris et al, 1995), one of a series of
projects in the KPML/Penman tradition (Bateman
et al, 1989). The system uses the standard seman-
tic representation employed in DL and the Semantic
Web: a Terminology Box, or Tbox, defining the con-
cepts and their interrelations and an Assertion Box,
or Abox, representing the information content that
forms the input (Baader et al, 2003). An Abox is a
set of assertions defining relations between instances
of the types defined in the Tbox. It can be depicted
by a connected graph (Figure 1) in which vertices
represent entities and edges represent relations, and
is represented in the input to the system by a set
of RDF subject-predicate-argument triples (Lassila
Figure 1: Sample Abox
and Swick, 1998), with one-place predications as-
signing types and two-place predications asserting
relationships. Assuming that the entities are being
mentioned for the first time, we might express this
Abox fragment in English by the sentence ?a woman
lost her bag?1. This sentence can be aligned with the
Abox by associating spans of the text with the enti-
ties expressed by the Abox, as follows:
Span Entity Context
a woman lost her bag e1 ROOT
a woman e2 AGENT
her bag e3 PATIENT
her e2 OWNER
Note that the same entity may be expressed in
multiple contexts (denoted by the incoming arcs
in the semantic graph). The relationships between
the entities are represented by syntactic dependen-
cies between the spans of the text. For instance,
AGENT(e1,e2) is realised by the clause-subject rela-
tion between ?a woman lost her bag? and its subspan
?a woman?. This direct linking of semantic and syn-
tactic dependencies has of course been noted many
times, for instance in Meaning-Text Theory (Can-
dito and Kahane, 1998).
The structure of the spans of text can be repre-
sented by a reconfiguration of the original Abox as
an ordered tree, which we will henceforth call an
Atree. Figure 2 shows an Atree that fits the exam-
ple Abox. Note that since this is a tree, the vertex
with two incoming edges (e2) has to be repeated,
and there are two spans referring to the woman.
1The system is able to generate a referring expression, ?her?,
for the second reference to the woman since it knows that the
entity has already been mentioned in the text. This informa-
tion is available because the Atree, see Figure 2, is an ordered
structure.
41
Figure 2: Sample Atree
This Atree is constructed using a set of bindings
which map instances of concepts from the Tbox in a
given context onto a subcategorisation frame, gram-
mar rule call and list of lexical anchors. As each ver-
tex of the Atree is constructed it is labelled with the
grammar rule and lexical anchors and linked back to
the vertex of the Abox which it expresses. Our cur-
rent model uses the Tree Adjoining Grammar (TAG)
formalism, see Joshi (1987), and the Atree acts as a
stand-in derivation tree from which the derived syn-
tactic tree can be computed. Each vertex of the de-
rived tree is linked back to the vertex of the Atree
from which it was generated, and so the output from
the system is a composite data structure compris-
ing the Tbox, Abox, Atree and derived tree with a
chain of references connecting each span of the sur-
face text via the Atree to the underlying semantic
representation. A detailed exposition of the process
through which the Atree and derivation tree are con-
structed is presented in a separate Technical Report
(Hardcastle and Power, 2008).
2.1 Simplifying assumptions
The design of the generator relies on two simplify-
ing assumptions. The key assumption for this paper
is that the text should adhere strictly to a controlled
language, so that a given local semantic configura-
tion is always realised by the same linguistic pattern.
The cost is that the text is likely to be repetitive and
may be awkward at times; however the trade-off is
that the domain of locality is tightly restricted and
this yields important benefits in speed, scalability,
reliability and verifiability that make the system suit-
able for deployment in an enterprise environment.
We also assume that the strategic element of the
NLG process, comprising content selection and doc-
ument structuring, has occurred prior to our system
receiving its input. Our framework is focused specif-
ically on tactical generation ? rendering the semantic
representation of the selected content as text.
3 Completeness
We can verify that the generator is complete, in the
sense that we can guarantee that it will produce a
derivation tree for any Abox valid under the Tbox.
We present the details of the verification algorithm
below, in Section 5. Note that we assume that the
system is equipped with the requisite morpholog-
ical and orthographic rules to realise the resulting
derivation tree. We also note that we cannot verify
that the generator is consistent, by which we mean
that it should produce different texts for different
Aboxes, nor that the syntactic frames and lexical an-
chors mapped to the concepts in the Tbox are appro-
priate. Checking the system for consistency remains
an open research question.
4 Speed and Scalability
In many NLG systems the choice of syntactic struc-
ture and lexical arguments depends on a large num-
ber of interdependent variables. This means that the
process of realizing the semantic input involves ex-
ploring a large search space, often with some back-
tracking. In contrast, the algorithm described in this
paper is monotonic and involves minimal search.
The system begins at the root of the Abox and uses
a set of mappings to construct the Atree one node
at a time. Because the same local semantic context
is always expressed in the same way the choice of
syntactic structure and lexical arguments can always
be made on the basis of a single mapping. Over
the course of this section we demonstrate this with a
simple example using resources that were automati-
cally inferred to construct the test harness described
in Section 8, which could be used to construct the
following simple sentence:
The nurse reminded the doctor that the pa-
tient was allergic to aspirin.
The Abox representing this sentence is rooted in
an instance of a Tbox concept representing an event
42
in which one person reminds another of a fact. Fig-
ure 3 shows the attributes defined for this Tbox con-
cept, 938B, namely an actor, actee and target. The
range of actor and actee is any concept in the Tbox
subsumed by the person concept, the range of tar-
get is any fact. There will therefore be three out-
going arcs from the root Abox node, labelled with
attributes actor, actee and target, pointing respec-
tively to nodes representing the nurse, doctor and
the fact about the patient?s allergy described in the
sample sentence above. Some of these nodes will
themselves have out-going arcs expressing their own
attributes, such as the subsidiary details of the fact
about the allergy.
938B
actor(person)
actee(person)
target(fact)
Figure 3: A Sample Tbox Node
To realize the first node in the Abox the system
searches for mappings for concept 938B. The con-
trolled language assumption allows the system to
search with a restricted domain of locality, and so
the only variables affecting the choice of frame will
be: the Tbox concept represented by the Abox node
to be realized (938B in this case), the syntactic con-
text (there is none at this stage since we are process-
ing the root node, so the system will default to clause
context), the incoming arc (there is none at this stage
so no constraint is applied), the out-going arcs (the
three attributes specified), and whether or not the in-
stance has already been expressed (in this case it has
not)2. The search parameters are used to locate a
2The last of these variables is used to determine whether or
not a referring expression (an anaphoric reference to an entity
which has already been mentioned) is required. Because the
Atree is ordered and is constructed in order, the system always
knows whether an instance is being mentioned for the first time.
We currently render subsequent mentions by pruning all of the
out-going arcs from the Abox node, which also allows us to
manage cycles in the semantic graph. Since the system knows
which nodes in the semantic graph have already been mentioned
it would also be possible to configure an external call to a GRE
system (Dale, 1989) - an application which infers the content of
a referring expression given the current semantic context.
mapping such as the one depicted in Figure 4 below.
<frame concept=?938B?
role=?any?
subcat=?CatClause-33?
bindings=?SUB,D OB,CL COM?>
<gr key=?TnxOVnx1s2?>
<anchor lemma=?remind? pos=?verb?/>
</gr>
</frame>
Figure 4: A Sample Mapping
This mapping tells the system which subcategori-
sation frame to use, which grammar rule to asso-
ciate with it, which lexical anchors to pass as argu-
ments to the grammar rule and also how to order the
subsidiary arguments of the subcategorisation frame
(the bindings attribute in the frame element). The
subcategorisation frame itself (shown in Figure 5) is
highly reusable as it only defines a coarse-grained
syntactic type and a list of arguments, each of which
consists of a free text label (such as SUB indicat-
ing the subject syntactic dependency) and a coarse-
grained syntactic constraint such as clause, nomi-
nal or modifier. In this example the first attribute
CatClause-33
type= CLAUSE
args= SUB/NOMINAL,
D OB/NOMINAL,
CL COM/CLAUSE
Figure 5: Sample Subcategorisation Frame
of the 938B node, namely the actor, is mapped to
the SUB (subject) argument, so it will become the
first child of the Atree node representing the remind
event. The nominal syntactic constraint will be car-
ried forward as the syntactic context for the nurse
node of the Abox, constraining the choice of map-
ping that the system can make to realise it. So, each
mapping enforces an ordering on the out-going arcs
of the Abox which is used to order the Atree and pro-
vides a syntactic context which is used to constrain
43
the mapping search for each child. The process of
locating and imposing mappings cascades through
the Abox from the root with minimal search and no
backtracking. If multiple mappings are defined for
a given context the first one is always chosen. If no
mapping is located then the system fails.
While the Atree is constructed, it is annotated
with the grammar rules and lexical anchors listed
in each mapping, allowing it to serve as a stand-in
TAG derivation tree from which a derived syntactic
tree can be constructed by instantiating and connect-
ing the elementary trees specified by each grammar
rule. Further details of this process are given in a
Technical Report (Hardcastle and Power, 2008).
So while the controlled language assumption that
we should always express the same local semantic
context in the same way limits expressivity, it also
limits algorithmic choice and prevents backtracking,
which means that the system can generate rapidly
and scale linearly. In the following section we show
how we can prove at compile time that no Abox can
be constructed which will result in a local semantic
context not accounted for in the mappings.
5 Reliability
In a real-world context the Tbox will evolve as the
underlying domain model is extended and enhanced.
As a result, some of the mappings described above
will become defunct and in some instances a re-
quired mapping will not be present. If the system
encounters an Abox which requires a mapping that
is not present it will not backtrack but will fail, mak-
ing the system fragile. To address this problem we
need to be able to run a static test in a short period
of time to determine if any mappings are unused or
missing.
Although the set of possible Abox graphs is an
infinite set, the tight domain of locality means that
there is a finite set of parameters which could be
passed to the generator for any given Tbox. As de-
scribed in the previous section the choice of map-
ping is based only on the following information:
the concept being realised, the syntactic context, the
number of attributes expressed by the concept, the
attribute used to select it, and whether or not this
Abox instance is being mentioned for the first time.
Given a starting TBox node and syntactic context
the system can crawl the TBox recursively using the
subcategorisation frames returned from each param-
eter set to derive a new list of parameter sets to be
tested. Each of these must be tested both as a first
and as a subsequent mention. The result is an algo-
rithm which proves the application?s completeness
(as defined in Section 3) with respect to a particular
domain (represented by the Tbox); if the test suc-
ceeds then it guarantees that the mappings defined
by the system can transform any Abox that is valid
under the given domain into an Atree annotated with
the information required to produce a derived syn-
tactic tree.
As above, the proving algorithm starts with a root
concept in the Tbox and an initial syntactic context
and uses these as the starting parameter set to find
the first mapping. Once a mapping is located it ex-
plores each of the attributes of the root concept using
the syntactic context to which the attribute is bound
by the mapping. Since there is no Abox it constructs
a list of parameter sets to check using every concept
in the range of the attribute.
For example, during the verification process the
prover will encounter the mapping shown above in
Figure 4 for the remind concept 938B in a clausal
context. The concept has three attributes: an actor,
an actee and a target. The first of these has as its
range all of the subconcepts of person defined in the
Tbox, and this introduces a new sub-problem. The
first attribute is bound to the SUB argument of the
subcategorisation frame used in the mapping, in Fig-
ure 4, by the bindings element, and this argument of
the subcategorisation frame imposes a nominal con-
straint. So the fact that concept 938B might need
to be expressed using this mapping means that any
subconcept of person might need to be expressed in
a nominal syntactic context with semantic role ac-
tor, and so the prover now checks each subconcept
with these parameters. If none of the subconcepts of
person define any attributes and a mapping is found
for each then no new sub-problems are introduced
and so this branch of the search bottoms out.
The prover then returns to 938B and processes the
actee and target attributes. The target attribute is
bound to the CL COM argument of the subcategori-
sation frame, and so the new sub-problem involves
checking that every subconcept of fact can be ex-
pressed as a clause with semantic role target. In
44
the ontology the subconcepts of fact include events,
each of which define a number of attributes, and so
this sub-problem branches out into many new sub-
problems before it bottoms out. One such event will
be the concept 938B, but since the mapping that we
have already encountered (Figure 4) is encoded for
any semantic role and the system has already pro-
cessed it the prover can break out and does not fall
into an infinite loop. This checking process contin-
ues recursively until the search space is exhausted,
with each parameter set tested being cached to re-
duce the size of the search space.
6 Relaxing the Simplifying Constraints
The simplifying assumptions described in Sec-
tion 2.1 deliver benefits in terms of performance
and reliability; however, they limit the expressiv-
ity of the language and reduce the scope of what
can be expressed. We can relax some of the con-
straints imposed by the simplifying assumptions and
still have a performant and reliable system, although
proving completeness becomes more complex and
some localised exponential complexity is introduced
into the generation algorithm. In this section we ex-
plore the ways in which relaxing the constraints to
allow quantification or underspecification impact on
the system.
The simplest scenario, which adheres to our sim-
plifying constraints, is that each node in the Abox
expresses exactly one of each of the attributes de-
fined by the Tbox concept which it instantiates. So,
using the remind example above, every instance of
remind must express an actor, an actee and a fact.
In practice the Tbox may allow an attribute not to be
expressed, to be expressed many times or to be ex-
pressed but not specified. We handle the first case by
allowing arguments in the subcategorisation frames
to be marked as optional; for example, a verb frame
may include an optional adverb slot. These optional
arguments increase the number of tests that must be
performed; if a frame has n optional slots then the
system will need to perform 2n checks to verify it,
and will have to consider 2n mapping combinations
during generation. This introduces localised expo-
nentiation into both the generation and the verifica-
tion algorithm, although it will only lead to tractabil-
ity problems if the number of optional slots on any
single frame is too high, since the exponent is only
applied to each frame and not across the whole
search space.
Where an attribute may remain unspecified the
system can be configured to respond in two different
ways. First, unspecified attributes can be included
in the text using the concept that represents the root
of the range. For example, if an event occurs at a
time which is not specified then the system can use
the concept that represents the root of the range (e.g.
timePeriod perhaps) and render it accordingly (?at
some time?). Alternatively the system can prune
all underspecified instances from the Abox before
the Atree is generated. Attributes which may not be
expressed (for either reason) must be flagged in the
TBox so that the proving algorithm knows to match
them to optional arguments in the subcategorisation
frames. This is implemented with a flag on each at-
tribute definition indicating whether its presence in
the Abox is optional.
Relaxing the constraints also impacts on our abil-
ity to verify the grammar rules which are associated
with each mapping. If we use TAG, then we can
easily verify that the syntactic type of the root of the
elementary tree defined by each mapping matches
the syntactic type of the subcategorisation frame to
which it is bound. However, if a mapping can be
accessed via an optional slot in another subcategori-
sation frame, then it must be bound to an auxiliary
tree, that is to an elementary tree which can be added
to the derived tree through adjunction, since any de-
rived tree with open substitution sites will be gram-
matically incomplete. For the system to support this
behaviour each mapping must declare not just the
concept which it realises but also the role (Tbox at-
tribute) which it fulfils, so that both the prover can
determine whether it may be left out, and this in-
creases the combinatorial complexity of the algo-
rithm.
7 Architecture
The design of the generator ensures that it can gen-
erate rapidly and that it can be verified at compile
time. A further feature is that it is implemented
with a component-based modular architecture. For
NLP applications it is particularly important that in-
dividual components can be independently verified
45
and reused, because linguistic resources are time-
consuming and expensive to build and curate. Fur-
thermore, because the mappings from concepts to
subcategorisation frames, grammar rules and lexi-
cal anchors are defined in a single file, the task of
building and maintaining the mappings is easier to
learn and easier to manage. It is also easier to boot-
strap the mappings through resource mining, as we
did ourselves in the construction of the test data set
discussed in Section 8.
The framework manages the graph and tree struc-
tures and the transformations between them, and it
defines the API for the domain and language specific
resources that will be required by the application. It
also defines the API of the linguistic resource man-
ager, leaving it to the application layer to provide
an appropriate implementer using dependency injec-
tion (Fowler, 2004). Rather than define a core ?in-
terlingual? feature structure that attempts to capture
all of the lexical features used by the grammar, the
framework provides a genericised interface to the
linguistic resource manager. This means that gram-
mars for different natural languages can use different
feature structures to define the lexical anchors used
by the application and to support tasks that are the
responsibility of the grammar, such as unification or
morphological inflection. For example, all verbs in
French should have a flag indicating whether avoir
or e?tre is used as a modal auxiliary for the passe?
compose?, but this flag need not be present for other
languages. The Tbox, the subcategorisation frames
and the mappings between them are all defined as
data sources and can be reused across applications
as appropriate. Although they are not defined in
code they can still be verified at compile time by
the prover discussed in the previous section, and this
allows the system to be flexible and modular with-
out introducing the risk of runtime failures caused
by faulty mapping data.
7.1 Export
A further feature of the system which arises from
the proving algorithm is that it supports export be-
haviour. In an enterprise context we want to be
able to reuse linguistic resource components, such
as a lexicon, a grammar, a morphological genera-
tor and so on, across many different applications.
These resources are large and complex and for a
given application much of the data may not be re-
quired. Because the proving algorithm is able to
compile a comprehensive list of the concepts, gram-
matical relations, subcategorisation frames and lexi-
cal anchors that will be required to realise any Abox,
given a starting concept and syntactic context, the
system can cut the Tbox, lexicon, grammar, subcat-
egorisation frame store and related resources to ex-
port a build for deployment, while guaranteeing that
the deployed application will never fail because of
a missing resource. This is of particular value if we
want to reuse large-scale, generic, curated resources
for a small domain and deploy where bandwidth is
an issue ? for example where language generation is
required in a client-heavy internet-based or mobile
application.
8 Testing and Results
We unit-tested the mechanics of the framework,
such as the graph and tree managers. We then built a
proof-of-concept application with a small ontology
representing the domain of patient treatment narra-
tives and handcrafted the subcategorisation frames,
lexical resources and TAG grammars for English,
French, Spanish and Italian. We used this applica-
tion to verify the independence of the framework,
domain and linguistic resources and verified that we
could develop linguistic resources offline and plug
them into the application effectively. The applica-
tion also served as a test harness to test the adaptibil-
ity of the framework to render the same semantic
context in different syntactic structures depending
on the target natural language. For example, we
included the examination of a body part belonging
to a person in the domain, and this was expressed
through a Saxon genitive in English but a preposi-
tional phrase (with the subsidiary NPs in the reverse
order) in the other languages.
To test our assumptions about efficiency and scal-
ability we inferred a larger Tbox, subcategorisation
frames and mappings using a pre-existing data set
of verb frames for English encoded using the COM-
LEX subcategorisation frame inventory (Grishman
et al, 1994). The linguistic resources for the appli-
cation comprised a generative TAG grammar based
on X-TAG (Doran et al, 1994) which we wrote our-
46
selves, the CUV+ lexicon3, and a pre-existing mor-
phological generator for English (Hardcastle, 2007).
To test the performance of the generation process
we used a set of randomly-generated Aboxes derived
from the Tbox to produce texts of increasing size.
For the purposes of testing we defined the size of an
Abox as the total number of nodes and edges in the
graph, which is the number of RDF triples required
to represent it. Table 1 shows the size of the out-
put text in sentences, the time taken to generate it in
milliseconds, averaged over 5 runs, and the ratio of
the time taken to the size of the output which shows
linear scaling4.
Size Timing Timing/Size
31 2 0.065
280 10 0.036
2,800 59 0.021
28,000 479 0.017
Table 1: The time, in milliseconds, taken to generate
Aboxes of increasing size and the ratio of time taken to
the size of the output.
To test the performance of the proving algorithm
we ran the algorithm on a set of Tboxes of differ-
ing sizes. The smallest Tbox in Table 2 is the hand-
crafted proof-of-concept Tbox, the largest is the in-
ferred Tbox described above, and the intermediate
ones were pruned from the large, inferred Tbox at
random cut points. The size of each Tbox is the
total number of attribute-concept pairs which it de-
fines. The table shows the time taken to run the
prover from the root node of the Tbox with no start-
ing syntactic context and the ratio of time taken to
size, which shows linear scaling.
We tested the mechanics of the implementation
of the prover through unit testing, and we tested
the the design with a test suite of sample data. We
performed white box tests by removing individual
bindings from a set of mappings which we judged
to be complete for the small handcrafted Tbox, and
checked to ensure that each was highlighted by the
prover. We performed black box tests by using a
3A publicly available lexicon for English available from the
Oxford Text Archive
4In fact scaling is slightly sub-linear for this test and the
test of the proving algorithm. In both cases that is because of
caching within the framework to improve performance.
Size Timing Timing/Size
125 10 0.08
86,766 432 0.005
2,054,020 8,217 0.004
9,267,444 21,526 0.002
Table 2: The time, in milliseconds, taken to prove relia-
bility for Tboxes of increasing size and the ratio of time
taken to size.
set of inferred mappings, judged by the prover to be
complete, to generate from a large number of ran-
domly structured Aboxes, drawn from our large in-
ferred Tbox, and checked that the generation process
never failed.
We chose not to undertake a formal evaluation
over and above the unit and sampling tests, because
the accuracy of the prover is a function of the re-
stricted domain of locality imposed by the system
and of the recursive algorithm which depends on it.
Instead we show that the prover is accurate by de-
scribing the parameters that guide search in gener-
ation and explaining why they can be exhaustively
tested (see Section 5).
9 Conclusion
In this paper we presented a tactical generator which
exploits a simplifying assumption that the output
text will be restricted to controlled natural language
to enforce a restricted domain of locality on search
in generation. As a result, the generation process is
fast and scales linearly, and furthermore the system
is reliable, since we are able to perform a compile-
time check of the data sources which drive the as-
signment of syntactic subcategorisations to the ex-
pression of each node in the input semantic graph.
The generator is most appropriate for applications
which need to present small chunks of structured
data as text on demand and in high volume. For ex-
ample, information feeds such as local weather fore-
casts, traffic information, and tourist information or
technical information that must be both machine-
readable (for example because it is safety critical
and requires consistency checking) and also human-
readable (for example for an operator to make use of
it) such as machine operator instructions, business
process/protocol descriptions and medical orders.
47
References
F. Baader, D. Calvanese, D. L. Mcguinness, D. Nardi, and
P. F. Patel-Schneider, editors. 2003. The Description
Logic Handbook : Theory, Implementation and Appli-
cations. Cambridge University Press.
J. Bateman, R. Kasper, J. Moore, and R. Whitney. 1989.
A general organization of knowledge for natural lan-
guage processing: The Penman Upper Model. Techni-
cal report, Information Sciences Institute, Marina del
Rey, California.
T. Berners-Lee, J. Hendler, and O. Lassila. 2001. The
Semantic Web. Scientific American, 284(5):34?43.
M. Candito and S. Kahane. 1998. Can the TAG deriva-
tion tree represent a semantic graph? An answer in
the light of the Meaning-Text Theory. In Proceedings
of the Fourth Workshop on Tree-Adjoining Grammars
and Related Frameworks, Philadephia, USA.
R. Dale. 1989. Cooking up referring expressions. In
Proceedings of the 27th Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 68 ? 75,
Vancouver, Canada.
C. Doran, D. Egedia, B. Hockey, B. Srinivas, and
M. Zaidel. 1994. XTAG system - a wide coverage
grammar for English. In Proceedings of the 15th In-
ternational Conference on Computational Linguistics,
pages 922?928, Kyoto, Japan.
M. Fowler. 2004. Inversion of control containers and the
dependency injection pattern
http://www.martinfowler.com/
articles/injection.html.
R. Grishman, C. McLeod, and A. Myers. 1994. Com-
lex Syntax: Building a Computational Lexicon. In
Proceedings of the The 15th International Conference
on Computational Linguistics, pages 268?272, Kyoto,
Japan.
D. Hardcastle and R. Power. 2008. Generating Concep-
tually Aligned Texts. Technical Report 2008/06, The
Open University, Milton Keynes, UK.
D. Hardcastle. 2007. Riddle posed by computer (6): The
Computer Generation of Cryptic Crossword Clues.
PhD thesis, University of London.
A. Hartley and C. Paris. 2001. Translation, controlled
languages, generation. In E. Steiner and C. Yallop,
editors, Exploring Translation and Multilingual Text
production, pages 307?325. Mouton de Gruyter.
A. Joshi. 1987. The relevance of tree adjoining gram-
mar to generation. In G. Kempen, editor, Natural Lan-
guage Generation: New Directions in Artificial Intel-
ligence, Psychology, and Linguistics. Kluwer.
O. Lassila and R. Swick. 1998. Resource Descrip-
tion Framework (RDF) model and syntax specifica-
tion. W3C Working Draft WD-rdf-syntax-19981008.
C. Paris, K. Vander Linden, M. Fischer, A. Hartley,
L. Pemberton, R. Power, and D. Scott. 1995. A sup-
port tool for writing multilingual instructions. In Pro-
ceedings of the 14th International Joint Conference
on Artificial Intelligence, pages 1398?1404, Montreal,
Canada.
R. Power and D. Scott. 1998. Multilingual authoring
using feedback texts. In Proceedings of the 17th In-
ternational Conference on Computational Linguistics
and 36th Annual Meeting of the Association for Com-
putational Linguistics, pages 1053?1059, Montreal,
Canada.
R. Power, D. Scott, and N. Bouayad-Agha. 2003.
Document structure. Computational Linguistics,
29(4):211?260.
48
Proceedings of the 12th European Workshop on Natural Language Generation, pages 9?15,
Athens, Greece, 30 ? 31 March 2009. c?2009 Association for Computational Linguistics
Towards a Generation-Based Semantic Web Authoring Tool
Richard Power
Department of Computing
Open University
Milton Keynes, UK
r.power@open.ac.uk
Abstract
Widespread use of Semantic Web tech-
nologies requires interfaces through which
knowledge can be viewed and edited with-
out deep understanding of Description
Logic and formalisms like OWL and RDF.
Several groups are pursuing approaches
based on Controlled Natural Languages
(CNLs), so that editing can be performed
by typing in sentences which are automat-
ically interpreted as statements in OWL.
We suggest here a variant of this approach
which relies entirely on Natural Language
Generation (NLG), and propose require-
ments for a system that can reliably gen-
erate transparent realisations of statements
in Description Logic.
1 Introduction
We describe here a simple prototype of an edit-
ing tool that allows a user to create an ontology
through an open-ended Natural Language inter-
face. By ?open-ended? we mean that when intro-
ducing class or property names into the ontology,
the user also decides how they should be expressed
linguistically: thus the lexicon of the Natural Lan-
guage interface is not predetermined. The purpose
of such a tool is to support knowledge editing on
the Semantic Web, which at present requires train-
ing in graphical user interfaces like Prote?ge? (Rec-
tor et al, 2004), or direct coding in OWL and RDF.
Linking OWL to Controlled Natural Language is
currently the topic of an OWL1-1 task force, and
several groups are already working in this area
(Schwitter and Tilbrook, 2004; Thompson et al,
2005; Bernstein and Kaufmann, 2006; Pool, 2006;
Dongilli, 2007); the novelty in our approach is that
we rely entirely on Natural Language Generation
(NLG), extending the WYSIWYM (or Conceptual
Authoring) method (Power and Scott, 1998; Hal-
lett et al, 2007) so that it supports knowledge edit-
ing for ontologies as well as for assertions about
individuals.
The idea of linking formal and natural lan-
guages can be traced back to Frege (1879), who
observed that mathematical proofs were made up
of formulae interspersed with passages in natu-
ral language, and invented formal logic as a way
of rendering these passages in a precise notation.
With the arrival of Artificial Intelligence in the
1950s, formal logic became the foundation for
knowledge representation and automatic reason-
ing ? a trend leading to the recent concept of a
?semantic web? that would open up knowledge en-
coding and utilisation to a world-wide community
(Berners-Lee et al, 2001). However, accessible
knowledge management requires accessible pre-
sentation: hence the current interest in methods of
?sugaring? formal logic into natural language text
(Ranta, 1994; Horacek, 1999), thus in a sense turn-
ing Frege upside-down.
1.1 Description Logic
The theoretical underpinning of OWL (and hence
of the semantic web) is a discipline that evolved
under various names in the 1980s and 1990s and
is now called Description Logic (Baader et al,
2003). This refers not to a single logical language,
but to a family of languages. All of these lan-
guages allow statements to be built from individu-
als, classes and properties, but they differ in the re-
sources provided in order to construct classes and
properties, thus allowing different balances to be
drawn between the conflicting demands of expres-
siveness and tractability (i.e., decidability and ef-
ficiency of reasoning).
Figure 1 shows some common class construc-
tors, using mathematical notation rather than
OWL syntax (which is equivalent, but much
lengthier). There are in fact three versions of
OWL (Lite, DL and Full) which provide pro-
9
Description Syntax
atomic class A (etc.)
universal class >
negation ?C
intersection C uD
union C unionsqD
value restriction ?R.C
exists restriction ?R.C
enumeration {a}
Table 1: Class constructors
gressively more constructors, not only for classes
but also for properties and axioms. Having cho-
sen the desired logic, the ontology builder is
free to introduce new atomic classes (and also
properties and individuals), which can be given
any name consistent with the RDF naming con-
ventions (i.e., names must be Unique Resource
Identifiers). Thus a new class might be named
http://myontology.net/parent and a new
property http://myontology.net/hasChild, al-
though for brevity we will henceforth omit names-
paces (i.e., parent, hasChild). Statements about
classes can then be expressed by axioms, the most
important of which are C v D (C is subsumed by
D) and C ? D (C is equivalent to D). For instance:
(1) parent ? person u ?hasChild.>
(2) person v ?hasChild.person
The meanings are probably obvious: (1) a parent is
defined as a person with one or more children; (2)
every person only has persons as children. Note
that expressing these axioms in clear English is not
trivial ? for instance, in (2) we must take care not
to imply that every person has children.
A collection of such axioms is called a TBox:
intuitively, a TBox expresses concept defini-
tions and generalisations. Description Logics
also contain names for individual instances (e.g.,
Abraham, Isaac) and formulas expressing facts
about individuals: thus father(Abraham) would
express class membership (?Abraham is a father?),
and hasChild(Abraham, Isaac) a relationship
between individuals (?Isaac is Abraham?s child?).
A collection of such assertions is called an ABox,
and TBox and ABox together make up a Knowl-
edge Base (KB).
1.2 Reasoning services
The reason for proposing Description Logic as the
foundation for the Semantic Web is that it allows
for efficient reasoning services. Much effort is still
going into the mathematical task of proving decid-
ability and efficiency results for increasingly ex-
pressive dialects. Informally, the standard reason-
ing services are as follows:
1. Class Satisfiability: Checking whether in a
given KB it is possible for a class to have at
least one member.
2. Subsumption: Checking whether a given
KB implies a specified subsumption relation-
ship between two classes.
3. Consistency: Checking whether a given KB
is consistent.
4. Instance Checking: Checking whether a
given KB implies a specified ABox assertion
that an individual a belongs to a class C.
Consider for instance the following miniature KB:
man unionsq woman ? person
man v ?woman
man(Abraham)
In respect to this KB, a reasoning engine should be
able to show (1) that the class man u woman is
unsatisfiable, (2) that man is subsumed by person
(man v person), (3) that the KB is consis-
tent, and (4) that the assertion person(Abraham)
holds.
The ability to perform these reasoning tasks ef-
ficiently can be exploited not only in applications
that utilize knowledge in problem-solving, but in
knowledge editing and natural language genera-
tion. For instance, when an ontology builder adds
a new axiom to a KB, the editor can run the sub-
sumption and consistency checks and give feed-
back on whether the axiom is informative, redun-
dant, or inconsistent. Or when producing a natural
language gloss for the class ?hasChild.female,
the generator could choose between ?something
with at least one female child? and ?someone
with at least one female child? by checking the
subsumption relationship ?hasChild.female v
person.
2 Aligning DL to CNL
We have explained informally the technical fea-
tures of description logics. Briefly, they include
rules for constructing classes, axioms, and asser-
tions about individuals; the resulting expressions
10
are interpreted through a relatively simple model-
theoretic semantics (Baader et al, 2005). They
also include efficient algorithms for performing
reasoning tasks. We now turn to issues in the
design of Controlled Natural Languages (CNLs)
which can be aligned with specific DLs, and thus
serve as useful interfaces for working with com-
plex formalisms like OWL and RDF.
As a provisional list of requirements, we would
suggest the following:
1. Completeness: A sentence (or text) can be
generated for any axiom permitted by the DL.
2. Uniqueness: Different sentences are gener-
ated for different axioms.
3. Transparency: Sentences in the CNL are ac-
curately interpreted by human readers.
4. Fluency: Sentences in the CNL are inter-
preted easily by human readers and judged
natural.
5. Interpretability: Sentences conforming to
the CNL can be automatically interpreted to
recover the corresponding DL axiom.
6. Editability: Interactive texts in the CNL can
be manipulated by domain experts in order to
extend and revise the KB.
7. Extensibility: Domain experts can extend
the CNL by linking lexical entries to new in-
dividuals, classes or properties in the KB.
Note that these are essentially practical require-
ments, which concern the CNL?s role as an inter-
face for a particular DL. We see no reason to insist
that the alignment between DL and CNL should
conform to general theories of natural language se-
mantics.
2.1 Completeness
If we propose to use generated CNL as an inter-
face to a knowledge base, it is important that gen-
eration should be reliable. A minimal test of re-
liability is that the grammar and lexicon are com-
plete, in the sense that they produce a text for any
well-formed semantic input. Elsewhere, we have
described a generation method that allows com-
pleteness to be checked by a computer program
(Hardcastle and Power, 2008). For any non-trivial
DL the set of classes is infinite (e.g., through recur-
sion on C uD or ?R.C); however, completeness
can be proved through an enumeration of all local
contexts for which a linguistic realisation rule is
needed. As well as guaranteeing reliability, com-
pleteness checking is obviously useful as an aid to
grammar development.
2.2 Uniqueness
Although necessary, completeness is not a suffi-
cient condition on the grammar of a CNL, since
it could be trivially met by generating the same
string (perhaps ?Hallo World?) for any semantic in-
put. It would also be useful to have an automatic
check that the same sentence is not generated for
two different semantic inputs ? i.e., that every
sentence in the CNL has a unique meaning. This
seems a harder problem than completeness, and
we have not seen any proposals on how it could be
done.
To pose this problem precisely we would need
to define what is meant by ?different? semantic in-
puts. Complex class descriptions can be manipu-
lated by well-known logical equivalences like De
Morgan?s laws: for instance, ?(C u D) is equiv-
alent to (?C) unionsq (?D). Should these be treated as
different inputs or the same input? We think users
would probably prefer them to be treated as differ-
ent, but the issue needs to be investigated further.
2.3 Transparency
Transparency is obviously at the heart of the en-
terprise: completeness and uniqueness proofs are
no help if the generated texts are unclear to human
readers. Unlike the preceding requirements, trans-
parency is a matter of degree: we cannot expect,
far less prove, that every sentence in the CNL will
be accurately understood by all target users on all
occasions. Transparency can only be assessed, and
gradually improved, through experiments and user
feedback.
2.4 Fluency
Fluency is another aspect of readability: whereas
transparency concerns accuracy of interpretation,
fluency concerns ease. These requirements poten-
tially conflict. For instance, to express the axiom
parent v ?hasChild.> fluently we could say
?every parent has a child?, while for transparency
we might prefer the pedantic ?every parent has one
or more children?. In a CNL designed for editing
a KB, transparency will have priority, but one can
imagine other purposes (e.g., an informal report)
for which fluency would matter more.
11
2.5 Interpretability
This is an essential requirement for knowledge ed-
itors that rely on automatic parsing and interpreta-
tion of texts typed in by human authors (Schwit-
ter and Tilbrook, 2004; Bernstein and Kaufmann,
2006). A recent innovation has been to pursue the
goal of ?roundtripping? (Davis et al, 2008), so that
a CNL text can be generated from an existing on-
tology, revised in a text editor, and then interpreted
automatically to obtain an updated ontology in the
original format. For our approach, which relies en-
tirely on generation, automatic interpretability is
not essential (although one can imagine contexts
in which it would be useful, for instance to allow
knowledge encoding outside the NLG-based edit-
ing environment).
2.6 Editability
The key feature of Conceptual Authoring (WYSI-
WYM) is that editing operations are defined on the
semantic input, not the text. This means that au-
thors cannot produce a text in the normal way by
typing in words from left to right. Some kind of
non-specific initial configuration has to be grad-
ually refined through semantic distinctions made
by choices from menus (an example will be given
later). To validate the approach, it has to be
shown that this editing process is efficient and eas-
ily learned. Usability results from ABox editing
applications have been encouraging (Hallett et al,
2007), but whether similar results can be achieved
for KB editing (TBox as well as ABox) remains
unproven.
2.7 Extensibility
Ontology development requires that authors
should be able to introduce new terms for indi-
viduals, classes and properties. The designer of a
CNL-based editor cannot foresee what these terms
will be, and therefore cannot provide a mapping to
suitable lexical entries. This must be done by the
ontology developer, and take-up accordingly de-
pends on making this task not only feasible but
easy (Hielkema et al, 2007). We will explore two
ideas on how this might be done: (a) providing a
wide-coverage lexicon from which users can se-
lect words to extend the CNL, and (b) using con-
ventions for controlling the naming of classes and
properties, so that the two decisions (term name,
CNL lexical entry) become essentially a single de-
cision.
3 Editing process
As a first experiment we have written a Prolog
program which allows a KB to be built up from
scratch for a very simple DL with only one kind
of statement (C v D), four class constructors
(A, >, ?R.C, {a}), and one property construc-
tor (property inversion, which will be explained
shortly). Using just these resources we can formu-
late ABox assertions as well as TBox axioms by
the trick of representing individuals through enu-
merated classes. For instance, man(Abraham)
can be asserted through the axiom {Abraham} v
man (the class containing only Abraham is a sub-
class of the class of men).
A generic grammar is provided for realising
axioms and complex class descriptions (a hand-
ful of rules suffices); the grammar assumes that
the words for realising individuals, atomic classes
and properties will conform to the following (very
strict) regulations:
1. Individuals are realised by proper names
2. Atomic classes are realised by count nouns
3. Properties are realised either by transitive
verbs or by count nouns
We also simplify by assuming that the name of ev-
ery atomic term in the DL is identical to the root
form of the word realising the term ? for instance,
the count noun realising the class person will be
?person?.
When the editor is launched there are no indi-
viduals, atomic classes or properties, and the only
word in the lexicon is ?thing?, which denotes the
class > (i.e., the class containing all individuals).
The KB is construed as a sequence of axioms, and
to start the ball rolling it is seeded with a single
vacuous axiom > v >. The program generates a
sentence expressing this axiom and adds a list of
editing options as follows:
1: Every thing/1 is a thing/2.
t Add a new term
a Add a new axiom
A/C Edit class C in axiom A
A/d Delete axiom A
Note that in every sentence expressing an axiom,
the head word of every span denoting a class is
given a numerical label; in a simple Prolog inter-
face this allows the class to be selected for edit-
ing. There is no point in attempting any edit-
ing yet, since no terms have been introduced.
12
Word Syntax Type
Mary name individual
pet noun class
animal noun class
own verb property
Table 2: Lexical entries for terms
The user should therefore choose option t to add
a new term. This is done by specifying three
things: a word (any string), a syntactic category
(either name, noun, or verb), and a logical type
(individual, class, or property). In this way
the user might define the set of terms in figure 2
from the people+pets domain, which will be fa-
miliar to students of Description Logic.
Editing of the axiom > v > can now begin.
Assuming that the target is pet v animal, the
user first selects the first class in the first axiom
by typing 1/1 (in a GUI this would be done sim-
ply by clicking on the word). The program re-
turns a menu of substitutions computed from the
current ontology and expressed in English phrases
adapted to the context of the selected class:
1 Mary
2 Every pet
3 Every animal
4 Everything that owns one or more things
5 Everything owned by one or more things
These phrases express respectively the classes
{Mary}, pet, animal, ?own.> and ?own?1.>
which can be formed from the terms in figure 2.
Note that the last class results from the inversion of
the property own: if own(a, b) means that a owns
b, the inverse own?1(a, b) means that b owns a ?
a relationship that can conveniently be expressed
by passivisation (a is owned by b).
When the user chooses option 2 (in a GUI this
would of course be done by clicking on the menu
item), the program updates the knowledge base
and regenerates:
1: Every pet/1 is a thing/2
Selecting the second class by typing 1/2 now
yields the same menu of options, differently
phrased to suit the different context of the class
in the axiom:
1 Mary
2 a pet
3 an animal
4 owns one or more things
5 is owned by one or more things
Choosing option 3 completes the first axiom, after
which the user can use the option a (see above) to
obtain a second default axiom for editing:
1: Every pet/1 is an animal/2
2: Every thing/1 is a thing/2
A similar series of operations on the second ax-
iom (starting by selecting 2/1) might then yield
the following:
1: Every pet/1 is an animal/2
2: Mary/1 owns/2 one or more pets/3
Even in such a simple example, we can see how
editing could be supported by the reasoning ser-
vices. For instance, if the user added a third ax-
iom ?Mary owns one or more animals?, the pro-
gram could point out that this is redundant, since
{Mary} v ?own.animal can be deduced from
pet v animal and {Mary} v ?own.pet.
4 Discussion
We have shown through a small prototype how a
KB could be built up from scratch using an NLG-
based authoring tool, with the lexicon almost en-
tirely specified by the ontology developer. Al-
though modest in scope, the prototype extends
previous work on Conceptual Authoring (WYSI-
WYM) in several ways:
? It allows editing of the TBox as well as
the ABox, by defining editing operations on
classes rather than individuals (with individ-
uals treated as singleton enumerated classes).
? It allows users to extend the CNL through the
constrained choice of words/phrases to ex-
press new individuals, classes and properties.
? It allows feedback based on reasoning ser-
vices (e.g, on whether a new axiom is incon-
sistent, informative or redundant).
An obvious objection to our approach is that
we are increasing the load on users by requiring
them to build not only a KB but also a CNL lexi-
con. Much will therefore depend on the tools that
support users in the latter task. Ideally, the con-
struction of a lexical entry would depend on mak-
ing a single selection from a wide-coverage lexi-
con that has already been built by computational
linguists. However, although this ideal is feasible
for classes and properties like pet and own which
can be mapped to single words, any encounter
with real ontologies is likely to reveal terms like
hasDietaryPreference that would have to be
13
expressed by a phrase. Probably there are solu-
tions to this problem ? one could imagine for
instance an algorithm that builds new entries in a
phrasal lexicon from examples ? but they remain
to be demonstrated and tested.
More generally, an important question is
whether such a method will scale up. It seems to
work reasonably well in the above example with
a handful of class constructors, terms and axioms,
but what happens when we tackle an expressive
DL like OWL Full, and support the editing of a
KB with thousands of terms and axioms?
As regards more expressive DLs, we have al-
ready cited promising work on developing CNLs
for OWL. As one might expect, the Boolean class
constructors (CuD, CunionsqD, ?C) can lead to prob-
lems of structural ambiguity, e.g. in a description
like old u (man unionsq woman). Here an NLG-based
editor should have the advantage over one that re-
quires human authoring of texts, since it can apply
the best available aids of punctuation and format-
ting (Hallett et al, 2007), a task that would require
great care and skill from human authors.
Increasing the number of terms would mean that
during editing, classes had to be selected from
thousands of alternatives; some kind of search
mechanism would therefore be needed. A simple
solution already used in WYSIWYM applications
(Bouayad-Agha et al, 2002; Hallett et al, 2007;
Evans et al, 2008) is a menu equipped with a text
field allowing users to narrow the focus by typ-
ing in some characters from the desired word or
phrase. In an ontology editor this search mech-
anism could be enhanced by using the ontology
itself in order to pick options that are concep-
tual rather than orthographic neighbours ? for in-
stance on typing in ?dog? the user would obtain a
focussed list containing ?poodle? and ?pekingese?
as well as ?doggerel?.
Increasing the number of axioms has no ef-
fect on the editing process, since we are assum-
ing that axioms will be realised by separate sen-
tences, each generated without regard to context.
However, a text comprising a long list of unor-
ganised axioms hardly makes for easy reading or
navigation. There is therefore potential here for
a more interesting application of NLG technology
that would draw on topics like generation of refer-
ring expressions, pronominalisation, aggregation,
discourse planning, and summarisation. Present-
ing a KB through a fluent and well-organised re-
port would give users a valuable return on their ef-
forts in linking terms to lexical entries, and would
address a pressing problem in ontology building
? how to maintain trasparency in an ontology
as it expands, possibly through contributions from
multiple users.
In a word, the advantage of applying NLG in
this area is flexibility. Once we have a mapping
from logical terms to lexical entries in English
or another natural language, we can tailor gener-
ated texts to different tasks in knowledge manage-
ment, using fluent organised reports for purposes
of overview and navigation, and short pedantically
precise sentences for editing ? backed up if nec-
essary with footnotes explaining unintuitive log-
ical implications in detail, or painstakingly for-
matted Boolean constructions that avoid potential
structural ambiguities.
References
Franz Baader, Diego Calvanese, Deborah L. McGuin-
ness, Daniele Nardi, and Peter F. Patel-Schneider,
editors. 2003. The Description Logic Handbook:
Theory, Implementation, and Applications. Cam-
bridge University Press.
F. Baader, I. R. Horrocks, and U. Sattler. 2005. De-
scription logics as ontology languages for the se-
mantic web. Lecture Notes in Artificial Intelligence,
2605:228?248.
T. Berners-Lee, J. Hendler, and O. Lassila. 2001. The
semantic web. Scientific American, 284(5):34?43.
A. Bernstein and E. Kaufmann. 2006. GINO ? a
guided input natural language ontology editor. In
Proceedings of the 5th International Semantic Web
Conference, Athens, Georgia.
Nadjet Bouayad-Agha, Richard Power, Donia Scott,
and Anja Belz. 2002. PILLS: Multilingual gener-
ation of medical information documents with over-
lapping content. In Proceedings of the Third In-
ternational Conference on Language Resoures and
Evaluation (LREC 2002), pages 2111?2114, Las
Palmas.
Brian Davis, Ahmad Ali Iqbal, Adam Funk, Valentin
Tablan, Kalina Bontcheva, Hamish Cunningham,
and Siegfried Handschuh. 2008. Roundtrip ontol-
ogy authoring. In International Semantic Web Con-
ference, volume 5318 of Lecture Notes in Computer
Science, pages 50?65. Springer.
Paolo Dongilli. 2007. Discourse Planning Strategies
for Complex Concept Descriptions. In Proceedings
of the 7th International Symposium on Natural Lan-
guage Processing, Pattaya, Chonburi, Thailand.
14
R. Evans, P. Piwek, L. Cahill, and N. Tipper. 2008.
Natural Language Processing in CLIME, a Multi-
lingual Legal Advisory System. Journal of Natural
Language Engineering, 14(1):101?132.
Gottlob Frege. 1879. Begriffsschrift. Halle.
Catalina Hallett, Donia Scott, and Richard Power.
2007. Composing queries through conceptual au-
thoring. Computational Linguistics, 33(1):105?133.
D. Hardcastle and R. Power. 2008. Fast, Scalable
and Reliable Generation of Controlled Natural Lan-
guage. In Proceedings of SETQA-NLP Workshop at
the 46th Annual Meeting of the Association for Com-
putational Linguistics, Ohio, US.
F. Hielkema, C. Mellish, and P. Edwards. 2007. Using
WYSIWYM to create an open-ended interface for
the semantic grid. In Proceedings of the 11th Eu-
ropean Workshop on Natural Language Generation,
Schloss Dagstuhl.
Helmut Horacek. 1999. Presenting Proofs in a
Human-Oriented Way. In Proceedings of the 16th
International Conference on Automated Deduction,
pages 142?156, London, UK. Springer-Verlag.
J. Pool. 2006. Can controlled languages scale to the
web? In 5th International Workshop on Controlled
Language Applications (CLAW?06), Boston, USA.
R. Power and D. Scott. 1998. Multilingual authoring
using feedback texts. In Proceedings of the 17th In-
ternational Conference on Computational Linguis-
tics and 36th Annual Meeting of the Association for
Computational Linguistics, pages 1053?1059, Mon-
treal, Canada.
Aarne Ranta. 1994. Type theory and the informal lan-
guage of mathematics. In Proceedings of the 1993
Types Worshop, Nijmegen, LNCS 806, pages 352?
365. Spinger Verlag.
Alan Rector, Nick Drummond, Matthew Horridge,
Jeremy Rogers, Holger Knublauch, Robert Stevens,
Hai Wang, and Chris Wroe. 2004. OWL Pizzas:
Practical Experience of Teaching OWL-DL: Com-
mon Errors and Common Patterns. In 14th Interna-
tional Conference on Knowledge Engineering and
Knowledge Management, pages 63?81.
R. Schwitter and M. Tilbrook. 2004. Controlled nat-
ural language meets the semantic web. In Pro-
ceedings of the Australasian Language Technology
Workshop, pages 55?62, Macquarie University.
C. Thompson, P. Pazandak, and H. Tennant. 2005.
Talk to your semantic web. IEEE Internet Comput-
ing, 9(6):75?78.
15
Proceedings of the 12th European Workshop on Natural Language Generation, pages 118?121,
Athens, Greece, 30 ? 31 March 2009. c?2009 Association for Computational Linguistics
Precision and mathematical form in first and subsequent mentions of
numerical facts and their relation to document structure
Sandra Williams and Richard Power
The Open University
Walton Hall, Milton Keynes MK7 6AA, U.K.
s.h.williams@open.ac.uk; r.power@open.ac.uk
Abstract
In a corpus study we found that authors
vary both mathematical form and preci-
sion1 when expressing numerical quanti-
ties. Indeed, within the same document,
a quantity is often described vaguely in
some places and more accurately in others.
Vague descriptions tend to occur early in a
document and to be expressed in simpler
mathematical forms (e.g., fractions or ra-
tios), whereas more accurate descriptions
of the same proportions tend to occur later,
often expressed in more complex forms
(e.g., decimal percentages). Our results
can be used in Natural Language Gener-
ation (1) to generate repeat descriptions
within the same document, and (2) to gen-
erate descriptions of numerical quantities
for different audiences according to math-
ematical ability.
1 Introduction
This study is part of the NUMGEN project2, which
aims (a) to investigate how numerical quantity de-
scriptions vary in English, (b) to specify a gram-
mar that covers these variations, and (c) to develop
an algorithm that selects appropriate descriptions
for people with different levels of mathematical
ability. We collected, from newspapers, popular
science magazines and scientific journals, exam-
ples of numerical facts that were mentioned more
than once, so that first mentions could be com-
pared with subsequent mentions. For example in
the following text, two mentions of the same nu-
merical fact ? the proportion of A grades in UK
A-level examinations in 2008 ? are underlined:
1Our use of the term precision has nothing to do with pre-
cision in information retrieval (i.e., the percentage of docu-
ments retrieved that are relevant).
2http://mcs.open.ac.uk/sw6629/numgen
A-level results show record number of
A grades
Record numbers of teenagers have re-
ceived top A-level grades
By Graeme Paton, Education Editor
More than a quarter of papers were
marked A as results in the so-called gold
standard examination reach a new high.
. . .
According to figures released today by
the Joint Council for Qualifications,
25.9 per cent of A-level papers were
awarded an A grade this summer . . .
(Daily Telegraph, 14 August 2008)
Comparing the two, (a) the first (More than a
quarter) is less precise than the second (25.9 per
cent), (b) its mathematical form, a common frac-
tion, is less complex than the decimal percentage
form of the second, and (c) its string has more
characters (i.e., it is not shorter in length as might
be expected if it were a summary). Also, the two
mentions occur in different parts of the document
? the first paragraph, and the fifth paragraph.
1.1 What do we mean by precision?
To compare the precision of numerical expres-
sions we needed a more exact definition of the
concept. We derived the following rules to deter-
mine precision:
? Precision increases with the number of sig-
nificant figures
? Round numbers imply vagueness (implicit
approximation)
? Modifiers increase the precision of round
numbers when they indicate the direction of
approximation (> or <)
? Common proportional quantities imply
vagueness (implicit approximation similar to
round numbers)
118
Our first rule concerns arithmetical precision ?
i.e., the number of significant figures. Thus 344
with three significant figures is more precise than
340 with only two and 56% with two significant
figures is more precise than 50% with one.
Second, we adhere to Krifka?s RNRI (round
number round interpretation) theory that when
speakers or writers mention a round figure such as
sixty, they mean that the actual figure is slightly
less than or more than the round number un-
less they explicitly modify it with (say) exactly,
and similarly, hearers or readers interpret it as
rounded (Krifka, 2007). As a consequence, sixty
and around sixty have the same level of precision,
while exactly sixty is more precise than sixty.
Third, we take into account modifiers (or nu-
merical hedges) such as under, over, more than,
and verbs such as topped. So we say that over
sixty and topped sixty are more precise than sixty
since they give more information.
Finally, we extend Krifka?s ideas (2007) to
cover common proportional quantities. Krifka
confined his ideas to scalar and numerical quan-
tities, but we propose that they can also be applied
to common proportions such as half, two thirds
and three quarters and their ratio, decimal, per-
centage and multiple equivalents. We hypothesise
that when speakers or writers use a common pro-
portion, they implicitly round up or down just the
same as with round whole numbers, so we would
argue that around a half is the same level of preci-
sion as a half, whereas more than half is more pre-
cise than half. When comparing different types,
we take the implied vagueness of common propor-
tions into account, so that we consider 25% to be
more precise than one quarter.
1.2 Maths form and conceptual complexity
Numerical proportions may be expressed by dif-
ferent mathematical forms, e.g., fractions, ratios,
percentages. Complexity of mathematical form
denotes the amount of effort and numerical skill
required by readers to interpret a numerical quan-
tity; as complexity of mathematical concepts in-
creases, the amount of effort required for compre-
hension also increases.
As a convenient measure of the complexity of
mathematical forms, we employ a scale corre-
sponding to the levels at which they are intro-
duced in the Mathematics Curriculum for Schools
(1999); that is, we assume that simple concepts are
Maths Form Level or
Complexity
Whole numbers 1?10 Level 1
Whole numbers 1?100 Level 2
Whole numbers 1?1000 Level 3
1-place decimals Level 3
Common fractions Level 3
Money and temperature Level 3
Whole numbers > 1000 Level 4
3-place decimals Level 4
Multiples Level 4
Percentages Level 4
Fractions Level 5
Ratios Level 5
Decimal Percentages Level 6
Standard index form Level 8
Table 1: Scale of Level/Complexity extracted
from the Maths Curriculum for Schools (1999)
taught before difficult ones, so that a child learns
whole numbers up to ten at Level 1, then much
later learns standard index form (e.g., 4.12x106)
at Level 8 (table 1).
2 Hypotheses
Our hypotheses about repeated mentions of nu-
merical facts are as follows:
? Precision will increase from first to subse-
quent mentions.
? Level of complexity of mathematical forms
will increase from first to subsequent men-
tions.
? Changes in precision and mathematical form
are related to document structure.
3 Empirical Study
3.1 The NUMGEN Corpus
The corpus has 97 articles on ten topics, where
each topic describes the same underlying numer-
ical quantities, e.g., 19 articles on the discovery of
a new planet al published in the first week of May
2007 (from Astronomy and Astrophysics, Nature,
Scientific American, New Scientist, Science, 11
newspapers and three Internet news sites). In total,
the corpus has 2,648 sentences and 54,684 words.
119
3.2 Corpus analysis and annotation
The articles were split into sentences automati-
cally, then checked and corrected manually. We
annotated 1,887 numerical quantity expressions
(788 integers, 319 dates, 140 decimals, 87 frac-
tions, 107 multiples, 66 ordinals, 336 percentages
and 44 ratios).
In this study, we looked for coreferring phrases
containing numerical quantities, such as the sen-
tences . . . of papers were marked A and . . . of A-
level papers were awarded an A grade in the above
text, and compared the numerical expressions as-
sociated with them.3 Then, for each fact, we noted
the linguistic form of first and subsequent men-
tions in each text and their document positions.
3.3 Judgements on precision and
mathematical level
Two readers (the authors) judged whether preci-
sion had changed from first to subsequent men-
tions of a numerical fact in a text, and if so,
whether it had increased or decreased, according
to the rules set out in the list in section 1.1. We
also judged the conceptual complexity of mathe-
matical forms, ranging from 1 to 8 (as defined in
table 1). For precision, the judges agreed on 94%
of cases (Cohen?s kappa is 0.88). Differences were
resolved by discussion.
3.4 Results
Table 2 shows results for binomial tests on 88
cases of repeated numerical facts. They show
a clear trend towards unequal precision between
first and subsequent mentions and, in the 62 cases
where it is unequal, an overwhelming trend for
precision to increase. Regarding mathematical
level (i.e., the complexity scale for mathematical
form), the trend is for subsequent mentions to have
a level equal to that of first mentions, but in the 31
cases where it is unequal, they show a significant
trend towards an increase in level ? i.e., subse-
quent mentions are conceptually more difficult.
Our first hypothesis (precision increases from
first to subsequent mentions) is thus clearly sup-
ported. Our second hypothesis (level of concep-
tual complexity increases from first to subsequent
mentions) is supported by significant increases in
level only where the level changed. Note that by
3Note that the numerical facts themselves do not corefer,
since they are merely properties of coreferring sets or scales
(Deemter and Kibble, 2000).
Observation n Prop. Sig.
Precision: Equal 26 .30 .0002
Unequal 62 .70
Precision: Increase 56 .90
Decrease 6 .10 .00001
Maths Level: Equal 57 .65
Unequal 31 .35 .007
Maths Level: Increase 25 .81
Decrease 6 .19 .0009
Table 2: Binomial tests on repeated mentions,
based on .5 probability, 2-tailed, Z approximation.
our definition, complexity of mathematical con-
cepts is distinct from precision: for example, 59
is more precise than 60 but equally complex (both
are taught at Level 2 ? whole numbers up to 100).
Further investigation revealed that mathematical
level tended to remain the same where both men-
tions were at the beginning of a document (n=14,
p < 0.005, in a 2-tailed binomial test, as above).
Hypothesis three (changes in precision and
mathematical form are related to document struc-
ture) is partially validated in that precision and
mathematical level both increase from early to
later positions in the document structure.
4 Discussion
Are these results surprising? We believe they show
that appropriate presentation of numerical infor-
mation requires surprising sophistication. It is
usual to summarise information early in an arti-
cle, but with numerical facts, summarisation can-
not be equated with lower precision or with sim-
pler mathematical form. If summarisation means
identifying important facts and presenting them
in a condensed form, then why are early men-
tions of numerical facts not condensed? A sur-
prisingly large proportion of first mentions (45%)
had longer (or equally long) strings than subse-
quent mentions (see the text in the introduction,
where More than a quarter is longer than 25.9 per
cent). Also, why change the mathematical form?
It is not obvious that 25.9% should be converted
to a common fraction. Intuitively we might reason
that 25.9% is close to 25% which can be expressed
by the simpler mathematical form a quarter, but it
is far from obvious how this reasoning should be
generalised so that it applies to all cases.
A side-effect of our analysis is that it pro-
vides some empirical evidence in support of
120
Krifka?s RNRI theory (2007); however, the data
is sparse. Ten repeated mentions of numerical
facts had round, whole number first mentions
and subsequent mentions that were more precise,
e.g., 200,000. . . 207,000. Thus demonstrating that
authors do indeed write round numbers which
they intend readers to interpret as being approxi-
mate. There is similar evidence from 22 examples
demonstrating that RNRI can be extended to com-
mon proportions.
5 Related work
Communicating numerical information is impor-
tant in Natural Language Generation (NLG) be-
cause input data is wholly or partially numerical
in nearly every NLG system, but the problem has
received little attention. For example, SUMTIME
summarises weather prediction data for oil rig per-
sonnel e.g., 1.0-1.5 mainly SW swell falling 1.0
or less mainly SSW swell by afternoon (Reiter et
al., 2005) but would require much greater flexi-
bility to present the same numerical facts to non-
professionals.
The difficulty of communicating numerical in-
formation has been highlighted in educational and
psychological research. Hansen et al?s book
(2005) provides ample evidence of confusions that
many children have about e.g., decimal places; in-
deed, they demonstrate that many believe 68.95%
is larger than 70.1% -- misconceptions that often
persist into adulthood. Even professionals misun-
derstand the mathematics of risk. Gingerenzer and
Edwards (2003) found doctors calculate more re-
liably with reference sets than with proportions.
We are not aware of any research on linguistic
variation in proportions; in fact, a recent special is-
sue on numerical expressions contained no papers
on proportions (Corver et al, 2007).
6 Conclusions and Future Work
In this paper we presented:
? A set of rules for determining precision in nu-
merical quantities that is sufficient to cover
the examples in our corpus
? A scale for conceptual complexity in numer-
ical expressions derived from the Mathemat-
ics Curriculum for Schools.
? A corpus of sets of articles whose main mes-
sage is to present numerical facts
? Empirical results demonstrating trends to-
wards increasing precision and complexity in
repeat mentions of numerical facts with posi-
tion in document structure.
Our results identify an interesting and well-
defined problem that will be addressed in the fi-
nal stage of NUMGEN: how to derive appropriate
simplified expressions (less precise, simpler math-
ematical form) for use in contexts like the open-
ings of articles, or communications intended for
readers with lower levels of mathematical ability.
Acknowledgements
Our thanks to members of The Open University
NLG Group. NUMGEN is supported by ESRC4
Small Grant RES-000-22-2760.
References
N. Corver, J. Doetjes, and J. Zwarts. 2007. Linguis-
tic perspectives on numerical expressions: Introduc-
tion. Lingua, Special issue on Linguistic perspec-
tives on numerical expressions, 117(5):751?775.
K. Van Deemter and R. Kibble. 2000. On Corefer-
ring: coreference in MUC and related annotation
schemes. Computational Linguistics, 26:629?637.
G. Gigerenza and A. Edwards. 2003. Simple tools
for understanding risks: from innumeracy to insight.
British Medical Journal, 327:714?744.
A. Hansen, D. Drews, J. Dudgeon, F. Lawton, and
L. Surtees. 2005. Children?s Errors in Maths:
Understanding Common Misconceptions in Primary
Schools. Learning Matters Ltd, Exeter, UK.
M. Krifka. 2007. Approximate interpretation of num-
ber words: A case for strategic communication. In
G. Bouma, I. Kraer, and J. Zwarts, editors, Cognitive
foundations of interpretation, pages 111?126, Am-
sterdam. Koninklijke Nederlandse Akademie van
Wetenschapen.
Qualification and Curriculum Authority. 1999. Math-
ematics: the National Curriculum for England. De-
partment for Education and Employment, London.
E. Reiter, S. Sripada, J. Hunter, J. Yu, and I. Davy.
2005. Choosing words in computer-generated
weather forecasts. Artificial Intelligence, 167(1-
2):137?169.
4Economic and Social Research Council
121
Coling 2010: Poster Volume, pages 1006?1013,
Beijing, August 2010
Expressing OWL axioms by English sentences: dubious in theory,
feasible in practice
Richard Power
Department of Computing
Open University
r.power@open.ac.uk
Allan Third
Department of Computing
Open University
a.third@open.ac.uk
Abstract
With OWL (Web Ontology Language) es-
tablished as a standard for encoding on-
tologies on the Semantic Web, interest
has begun to focus on the task of ver-
balising OWL code in controlled English
(or other natural language). Current ap-
proaches to this task assume that axioms
in OWL can be mapped to sentences in
English. We examine three potential prob-
lems with this approach (concerning log-
ical sophistication, information structure,
and size), and show that although these
could in theory lead to insuperable diffi-
culties, in practice they seldom arise, be-
cause ontology developers use OWL in
ways that favour a transparent mapping.
This result is evidenced by an analysis of
patterns from a corpus of over 600,000 ax-
ioms in about 200 ontologies.
1 Introduction
Since the adoption of OWL (Web Ontology Lan-
guage) as a standard in 2004, several research
groups have explored ways of mapping between
OWL and controlled English, with the aim of
presenting ontologies (both for viewing and edit-
ing) in natural language (Schwitter and Tilbrook,
2004; Kaljurand and Fuchs, 2007; Funk et al,
2007; Hart et al, 2008); this task has been called
ontology ?verbalisation? (Smart, 2008). To de-
velop generic methods for ontology verbalisation,
some kind of structural mapping is needed be-
tween the formal and natural languages, and the
assumption generally adopted has been a three-
tier model in which identifiers for atomic terms
(e.g., individuals, classes, properties) map to lexi-
cal entries, single axioms map to sentences, and
groups of related axioms map to higher textual
units such as paragraphs and sections. The pur-
pose of this paper is to look in detail at one level of
this model, the realisation of axioms by sentences,
and to check its feasibility through an analysis of
a large corpus of ontologies.
The input to a verbaliser is a file in one
of the standard formats such as OWL/RDF or
OWL/XML, containing axioms along with sup-
porting statements such as annotations. As ex-
amples of the nature of the input, table 1 shows
three axioms in OWL/XML format; without any
attempt at aggregation or pronominalisation, they
could be realised by the following sentences1:
Horatio Nelson is an admiral.
Horatio Nelson is the victor of the Battle of
Trafalgar.
Every admiral is commander of a fleet.
Without attempting anything like a full descrip-
tion of OWL, it will be useful to look more closely
at the structure of these expressions. Note first that
they are essentially in functor-argument form2. In
the first axiom, for example, there is a functor
called ClassAssertion with two arguments, one
a class and the other an individual; the mean-
ing of the axiom is that the individual belongs
to the class. The second functor (ObjectProp-
ertyAssertion) requires instead three arguments,
1Note that one limitation of OWL is that at present it con-
tains no treatment of time; we therefore have to fall back on
the historical present.
2In fact, there is an alternative format called OWL
Functional Syntax in which, for example, the first ax-
iom would be represented by a predication of the form
ClassAssertion(X,Y).
1006
<ClassAssertion>
<Class IRI="http://www.example.org#admiral"/>
<NamedIndividual IRI="www.example.org#HoratioNelson"/>
</ClassAssertion>
<ObjectPropertyAssertion>
<ObjectProperty IRI="http://www.example.org#victorOf"/>
<NamedIndividual IRI="http://www.example.org#HoratioNelson"/>
<NamedIndividual IRI="http://www.example.org#BattleOfTrafalgar"/>
</ObjectPropertyAssertion>
<SubClassOf>
<Class IRI="http://www.example.org#admiral"/>
<ObjectSomeValuesFrom>
<ObjectProperty IRI="http://www.example.org#commanderOf"/>
<Class IRI="http://www.example.org#fleet"/>
</ObjectSomeValuesFrom>
</SubClassOf>
Table 1: Examples of axioms in OWL/XML
and describes a relation (in OWL these are called
?properties?) holding between two individuals; the
third (SubClassOf) requires two arguments, both
classes, and asserts that the first class is a subclass
of the second.
Turning to the structure of the arguments, there
are two possibilities: either the argument is
atomic, in which case it will be represented by
an identifier (or a literal if it is a data value), or
it is complex, in which case it will be represented
by an OWL functor with arguments of its own.
Most of the arguments in table 1 are atomic, the
sole exception being the second argument of Sub-
ClassOf, which denotes a complex class meaning
?someone that is commander of a fleet?3. In gen-
eral, then, the OWL functors denote logical con-
cepts such as class membership and class inclu-
sion, while atomic terms denote domain-specific
concepts such as Nelson and admiral. A funda-
mental design decision of the Semantic Web is
that logical concepts are standardised, while do-
main concepts are left open: ontology developers
are free to name the class admiral in any way they
please, provided that the identifier takes the form
of an IRI (Internationalized Resource Identifier).
Given this distinction, the obvious strategy to
follow in developing a verbaliser is to divide lin-
guistic resources into two parts: (a) a generic set
3To be more precise we should say ?someone that is com-
mander of one or more fleets?; this kind of trade-off between
elegance and precision often arises in systems that verbalise
formal languages.
of rules for realising logical expressions (based
on standardised OWL functors); (b) a domain-
specific lexicon for realising atomic individuals,
classes and properties. This obviously raises the
problem of how to acquire the specialised lexicons
needed for each ontology. All else failing, these
would have to be crafted by hand, but provided
that we are not too concerned about text quality, a
provisional lexicon can often be derived automat-
ically from internal evidence within the ontology
(i.e., either from identifier names or annotation la-
bels)4.
Assuming that a lexicon for atomic terms can
be obtained (by fair means or foul), there remains
a question of whether we can find sentence pat-
terns which provide understandable realisations
of the logical patterns determined by (possibly
nested) OWL functors. In section 2 we show that
this is not guaranteed, for three reasons. First,
there may be OWL functors that represent logi-
cally sophisticated concepts which cannot be ex-
pressed in non-technical English. Secondly, an
OWL axiom may be hard to verbalise because
it lacks the right kind of information structure
(i.e., because it fails to make a statement about a
recognisable topic such as an individual or atomic
class). Finally, since arguments can be nested in-
definitely, an axiom might contain so much se-
4We have discussed elsewhere whether phrases derived in
this way provide suitable lexicalisations (Power, 2010), but
this topic lies outside the scope of the present paper.
1007
mantic complexity that it cannot be compressed
clearly into a single sentence. We then describe
(section 3) an empirical analysis of axiom pat-
terns from about 200 ontologies, which investi-
gates whether these potential problems are com-
mon in practice. Section 4 discusses the results,
and section 5 concludes.
2 Potential problems in verbalising
axioms
2.1 Logical sophistication
We show in table 2 the 16 most commonly used
OWL functors for expressing axioms, each ac-
companied by a simple English sentence illustrat-
ing what the functor means. As will be seen, the
functors divide into two groups. For those in the
upper segment, it is relatively easy to find En-
glish constructions that realise the logical content
of the axiom ? assuming we have suitable lexi-
calisations of the atomic terms. For those in the
lower segment, finding a good English realisation
is harder, since statements describing properties
are normally found only in the rarified worlds of
mathematics and logic, not in everyday discourse.
Our attempts to verbalise these axioms are accord-
ingly clumsy (e.g., through resorting to variables
like X and Y), and not even entirely precise (e.g.,
the sentence for FunctionalObjectProperty should
really specify ?For any X. . . ?); perhaps the reader
can do better.
Does this mean that our aim of realising OWL
axioms in non-technical English is doomed? We
would argue that this depends on how the axioms
describing properties are used in practice. First,
for any difficult axiom functor, it is important to
consider its frequency. If it turns out that a func-
tor accounts for (say) only one axiom in every
thousand, then it will give rise only to the occa-
sional clumsy sentence, not a text that is clumsy
through and through. Second, it is important to
take account of argument complexity. If a func-
tor is used invariably with atomic terms as argu-
ments, then the sentence expressing it will contain
only one source of complexity ? logical sophisti-
cation; if instead the functor has non-atomic argu-
ments, this additional strain might push it over a
threshold from difficult to incomprehensible. For-
tunately, OWL syntax requires that all property ar-
guments for the difficult functors are atomic ? for
FunctionalObjectProperty, for instance, the argu-
ment cannot be a complex property expression.
For statements about domains and ranges, how-
ever, class arguments can be non-atomic, so here
a complexity issue might arise.
2.2 Information structure
We learn at school that sentences have a sub-
ject (preferably simple) and predicate (relatively
complex), the purpose of the predicate being to
say something about the subject. This rather
simplified idea is developed technically in work
on information structure (Kruijff-Korbayova? and
Steedman, 2003) and centering theory (Walker et
al., 1998). Is there any equivalent to this topic-
comment distinction in OWL? Formally speak-
ing, one would have to answer in the negative.
The two-argument functor SubClassOf, for exam-
ple, can have class expressions of any complex-
ity in either argument position, and there is no
logical reason to claim that it is ?about? one of
these classes rather than the other. This is still
clearer in the case of EquivalentClasses, where
the functor is commutative (so that switching the
arguments leaves the meaning unchanged). Again
there seems to be a difficulty here ? and again
we argue that this difficulty might disappear, or at
least diminish, if we consider how OWL is used
in practice.
Suppose, for instance, that although OWL syn-
tax allows indefinitely complex arguments in ei-
ther position for the SubClassOf functor, in prac-
tice users invariably construct axioms in which the
first argument is an atomic term, with complex
expressions occurring (if at all) only in second-
argument position. This would strongly suggest,
in our view, that developers are assigning a topic-
comment structure to the two arguments, with the
first expressing the topic and the second express-
ing the comment. As we will show later in the
paper, this pattern is found overwhelmingly ? so
much so that in a sample of nearly half a million
SubClassOf axioms, fewer than 1000 instances
(0.2%) were found of non-atomic first arguments.
1008
Functor Example
SubClassOf Every admiral is a sailor
EquivalentClasses An admiral is defined as a person that commands a fleet
DisjointClasses No sailor is a landlubber
ClassAssertion Nelson is an admiral
ObjectPropertyAssertion Nelson is victor of the Battle of Trafalgar
DataPropertyAssertion The Battle of Trafalgar is dated 1805
ObjectPropertyDomain If X commands Y, X must be a person
ObjectPropertyRange If X commands Y, Y must be a fleet
SubObjectPropertyOf If X is a child of Y, X must be related to Y
InverseObjectProperties If X is a child of Y, Y must be a parent of X
TransitiveObjectProperty If X contains Y and Y contains Z, X must contain Z
FunctionalObjectProperty There can be only one Y such that X has as father Y
DataPropertyDomain If X is dated Y, X must be an event
DataPropertyRange If X is dated Y, Y must be an integer
SubDataPropertyOf If X occurs during Y, X must be dated Y
FunctionalDataProperty There can be only one Y such that X is dated Y
Table 2: Meanings of OWL functors
2.3 Semantic complexity
When encoding knowledge in description logic,
developers have considerable freedom in dis-
tributing content among axioms, so that axiom
size is partly a matter of style ? rather like sen-
tence length in composing a text. Development
tools like Prote?ge? (Rector et al, 2004) support
refactoring of axioms, so that for example any ax-
iom of the form CA v CS u CL (e.g., ?Every ad-
miral is a sailor and a leader?) can be split into
two axioms CA v CS and CA v CL (?Every
admiral is a sailor. Every admiral is a leader.?),
or vice-versa5. Indeed, it can be shown that any
set of SubClassOf axioms can be amalgamated
into a single axiom (Horrocks, 1997) of the form
> v M , where > is the class containing all indi-
viduals in the domain, and M is a class to which
any individual respecting the axiom set must be-
long6. Applying this transformation to just two
axioms already yields an amalgam that will per-
plex most readers:
Every admiral is a sailor
Every admiral commands a fleet.
Everything is (a) either a non-admiral or a sailor,
and (b) either a non-admiral or something that
commands a fleet.
There is thus no guarantee that an axiom in OWL
can be verbalised transparently by a single sen-
5The symbols v and u in logical notation correspond to
the OWL functors SubClassOf and ObjectIntersectionOf.
6This all-embracing axiom or ?meta-constraint? is com-
puted by the standard description logic reasoning algorithms
when determining the consistency of a knowledge base.
tence; in theory it could contain as much knowl-
edge as a textbook. As before, we have to appeal
to practice. Do ontology developers distribute
content among knowledge units (axioms) equiv-
alent in size to sentences? If they (almost always)
do, then our approach is worth pursuing; if not,
we have to reconsider.
3 Method
To investigate the issues of usage just described,
we have analysed axiom patterns in a large cor-
pus of ontologies of varying subject-matter and
provenance. The corpus was based on the TONES
Ontology Repository (TONES, 2010), which is
a searchable database of RDF/XML ontologies
from a range of sources. The repository is in-
tended to be useful to developers of tools to work
with ontologies, and as such represents a wide
range of ontology kinds and features. It also clas-
sifies ontologies by ?expressivity? ? the weak-
est description logic necessary to express every
axiom. While the TONES site itself acknowl-
edges that the expressivity categorisation is only
a guideline, it can serve as a rough guide for com-
parison with the pattern frequency analysis carried
out here.
The whole repository was downloaded, com-
prising 214 files each containing between 0 and
100726 logical axioms7. (Note that an OWL
7A few of the ontologies in the TONES repository were
excluded, either because of syntax errors in the original files
(2-3 files), or because they exceeded our processing limits ?
1009
file may contain no logical axioms and still
be non-empty.) To develop quickly a program
that could cope with the larger ontologies with-
out memory problems, we used the Java-based
OWL API (Horridge and Bechhofer, 2010) as
much as possible, in conjunction with standard
Unix text-processing tools (?grep?, ?sed? and
?awk? (Dougherty and Robbins, 1997)) for pattern
recognition8.
Each ontology was converted into OWL Func-
tional Syntax (Motik et al, 2010) and lists were
automatically generated of the identifiers it con-
tains ? classes, named individuals, properties,
and so on. The Unix tools were scripted to re-
place every occurrence of such an identifier with
a string representing its type. This process gen-
erated a new file in which every axiom of the
original ontology had been replaced with a string
representing its logical structure: thus SubClas-
sOf(Admiral, Sailor) and SubClassOf(Sailor, Per-
son) would each have been replaced with Sub-
ClassOf(Class, Class). The number of occur-
rences of each unique pattern was then counted
and the results converted into a set of Prolog
facts for further analysis. Some manual tidying-
up of the data was necessary in order to correct
some complex cases such as quoted string liter-
als which themselves contained (escaped) quoted
strings; however, these cases were so rare that any
remaining errors should not adversely affect out-
put quality.
4 Results
To address the issue of logical sophistication, we
first calculated frequencies for each axiom func-
tor, using two measures: (a) the number of ontolo-
gies in which the functor was used at least once,
and (b) the number of axioms using the functor
overall. The former measure (which we will call
?ontology frequency?) is a useful corrective since
a simple axiom count can be misleading when a
e.g., the Foundational Model of Anatomy (Rosse and Mejino,
2003).
8A pure Java solution was not practical in the time avail-
able since the OWL API was designed to support reasoning
and evaluation of OWL ontologies rather than syntactic anal-
ysis of their axioms. We hope to produce an extension of the
OWL API to support straightforward and portable analysis
of ontologies in the future.
functor is used profusely in a few very large on-
tologies, but rarely elsewhere. The results are pre-
sented in table 3, ordered by ontology frequency
rather than overall axiom frequency9. As can be
seen, the ten functors classified as logically so-
phisticated in table 2 are relatively rare, by both
measures, accounting overall for just 2.2% of the
axioms in the corpus, with none of them having a
frequency reaching even 5 in 1000.
Next, to address information structure, we
looked at the argument patterns for each ax-
iom functor, distinguishing three cases: (a) all
arguments simple (i.e., atomic); (b) all argu-
ments complex (non-atomic); (c) mixed argu-
ments (some atomic, some non-atomic). This
comparison is relevant only for the functors Sub-
ClassOf, EquivalentClasses and DisjointClasses,
for which OWL syntax allows multiple non-
atomic arguments. The results (table 4) show a
clear preference for patterns in which at least one
argument is simple. Thus for SubClassOf, given
the overall frequencies of simple and complex ar-
guments for this functor, the expected frequency
for the combination Complex-Complex would be
12606 (2.7%), whereas the observed frequency
was only 978 (0.2%) (?2 = 16296 with df=2,
p < 0.0001)10. The corresponding result for
EquivalentClasses is even clearer, with not a sin-
gle instance of an axiom in which all arguments
are complex, against an expected frequency of 973
(16.0%) (?2 = 2692 with df=2, p < 0.0001)11.
For DisjointClasses no complex arguments were
obtained, so the only possible combination was
?All Simple?. Overall, 99.8% of axioms for these
three functors contained at least one atomic term,
suggesting that the arguments were interpreted ac-
cording to intuitions of information structure, with
one atomic argument serving as the topic. This
point is reinforced by our next analysis, which
considers detailed argument patterns.
9Note that the total in the first column of table 3 is sim-
ple the number of ontologies in our sample; the sum of the
frequencies in the column is of no interest at all.
10The data for this test, with expected values in brack-
ets, are SS = 297293 (312138), CC = 978 (12606), and SC
= 170541 (144068), where S means ?Simple? and C means
?Complex?.
11The data for this test, with expected values in brackets,
are SS = 1222 (2190), CC = 0 (973), and SC = 4860 (2919),
where again S means ?Simple? and C means ?Complex?.
1010
Functor Ontology Frequency Percent Axiom Frequency Percent
SubClassOf 190 94% 468812 74.0%
EquivalentClasses 94 46% 6082 1.0%
ObjectPropertyRange 92 45% 2275 0.4%
ObjectPropertyDomain 91 45% 2176 0.3%
DisjointClasses 88 43% 94390 14.9%
SubObjectPropertyOf 75 37% 2511 0.4%
InverseObjectProperties 63 31% 1330 0.2%
TransitiveObjectProperty 59 29% 221 0.0%
FunctionalObjectProperty 56 28% 1129 0.2%
DataPropertyRange 52 26% 2067 0.3%
ClassAssertion 49 24% 12798 2.0%
DataPropertyDomain 47 23% 2019 0.3%
FunctionalDataProperty 37 18% 931 0.1%
ObjectPropertyAssertion 22 11% 19524 3.1%
DataPropertyAssertion 14 7% 17488 2.8%
SubDataPropertyOf 6 3% 12 0.0%
TOTAL 203 100% 633791 100%
Table 3: Frequencies for OWL functors
Functor All Simple Percent All Complex Mixed Percent
SubClassOf 297293 63% 978 (0.2%) 170541 37%
EquivalentClasses 1222 20% 0 4860 80%
DisjointClasses 94390 100% 0 0 0%
TOTAL 392905 69% 978 (0.2%) 175401 31%
Table 4: Simple and complex arguments of OWL functors
OWL Pattern Frequency Percent
SubClassOf(Class,Class) 297293 46.9%
SubClassOf(Class,ObjectSomeValuesFrom(ObjectProperty,Class)) 158519 25.0%
DisjointClasses(Class,Class) 94358 14.9%
ObjectPropertyAssertion(ObjectProperty,NamedIndividual,NamedIndividual) 18552 3.0%
DataPropertyAssertion(DataProperty,NamedIndividual,Literal) 17433 2.7%
ClassAssertion(Class,NamedIndividual) 12767 2.0%
SubClassOf(Class,ObjectAllValuesFrom(ObjectProperty,Class)) 4990 0.8%
SubObjectPropertyOf(ObjectProperty,ObjectProperty) 2453 0.4%
EquivalentClasses(Class,ObjectIntersectionOf(Class,ObjectSomeValuesFrom(ObjectProperty,Class))) 2217 0.3%
ObjectPropertyRange(ObjectProperty,Class) 2025 0.3%
ObjectPropertyDomain(ObjectProperty,Class) 1835 0.3%
DataPropertyDomain(DataProperty,Class) 1703 0.3%
SubClassOf(Class,ObjectHasValue(ObjectProperty,NamedIndividual)) 1525 0.2%
SubClassOf(Class,DataHasValue(DataProperty,Literal)) 1473 0.2%
InverseObjectProperties(ObjectProperty,ObjectProperty) 1318 0.2%
DataPropertyRange(DataProperty,Datatype) 1308 0.2%
EquivalentClasses(Class,Class) 1222 0.2%
FunctionalObjectProperty(ObjectProperty) 1121 0.2%
Other pattern. . . 11469 1.8%
TOTAL 633791 100%
Table 5: Frequencies for OWL Functor-Argument patterns
1011
Finally, to address semantic complexity (i.e.,
axiom size), we counted the frequencies of de-
tailed argument patterns, abstracting from atomic
terms as explained in section 3. The results (or-
dered by pattern frequency) are presented in table
5, which reveals several clear trends:
? A small number of patterns covers most of
the axioms in the corpus. Thus the top five
patterns cover 91.9% of the axioms, the top
10 cover 95.8%, and the top 20 cover 97.2%.
? All of the frequent patterns (i.e., the top 20)
can be expressed by a single sentence with-
out problems of semantic complexity arising
from size. The most complex is the Equiv-
alentClasses pattern (number 10 in the list),
but this can be realised comfortably by a sen-
tence following the classical Aristotelian pat-
tern for a definition ? e.g., ?An admiral is
defined as a person that commands a fleet?.
? None of the first ten patterns employs the
axiom functors previously classified as log-
ically sophisticated (bottom half of table 2).
? In the patterns where one argument is sim-
ple and the other is complex (i.e., SubClas-
sOf and EquivalentClasses), the simple ar-
gument invariably comes first, supporting the
intuition that developers conceptualise these
statements in subject-predicate form, with
(simple) topic preceding (possibly complex)
comment.
? Among the frequent patterns, different func-
tors have distinctive argument preferences.
For instance, for SubClassOf most axioms
have atomic arguments, presumably because
it is through this functor that the class hierar-
chy is specified. For EquivalentClasses, in-
stead, the Aristotelean definition pattern is by
far the most frequent, although all-atomic ar-
guments are occasionally employed (0.2% of
axioms) to show that two class terms are syn-
onymous.
5 Conclusion
Our analysis of over 600,000 axioms from 203
ontologies provides empirical support for the as-
sumption that in practice OWL axioms can be
transparently expressed by English sentences. In
principle, as we have seen, OWL syntax grants
users the freedom to construct axioms that would
defeat this assumption entirely, either by concen-
trating too much semantic content into a single ax-
iom, or by filling all argument positions by com-
plex expressions that are unsuited to fulfilling the
role of topic; it also allows logically sophisticated
statements about properties, which would lead to
impossibly clumsy texts if they occurred too of-
ten, or were exacerbated by complex arguments.
In practice, if our sample is typical, none of these
problems seems to arise, and we think it would
be a fair summary of our results to say that on-
tology developers treat OWL axioms by analogy
with sentences, by assigning a clear information
structure (so that one atomic argument is identi-
fied with the topic) and including only an appro-
priate amount of content.
Having identified a relatively small set of com-
mon axiom patterns, it is obviously interesting to
consider how each pattern can best be expressed
in a given natural language. Considering the pat-
tern SubClassOf(Class,Class) for instance (47%
of all axioms), one could weigh the relative mer-
its of ?Every admiral is a sailor?, ?All admirals are
sailors?, ?Admirals are sailors?, ?If X is an admiral,
then X must be a sailor?, and so forth. To address
this issue we are planning a quite different kind of
empirical study on how various sentence patterns
are interpreted by human readers; by highlighting
the logical patterns that occur most often in prac-
tice, the results reported here will help set the pa-
rameters for such an investigation.
Acknowledgments
The research described in this paper was un-
dertaken as part of the SWAT project (Seman-
tic Web Authoring Tool), which is supported by
the UK Engineering and Physical Sciences Re-
search Council (EPSRC) grants G033579/1 (Open
University) and G032459/1 (University of Manch-
ester). We thank the anonymous reviewers and
our colleagues on the SWAT project for their com-
ments.
1012
References
Dougherty, Dale and Arnold Robbins. 1997. sed and
awk. UNIX Power Tools. O?Reilly Media, 2nd edi-
tion.
Funk, Adam, Valentin Tablan, Kalina Bontcheva,
Hamish Cunningham, Brian Davis, and Siegfried
Handschuh. 2007. CLOnE: Controlled Lan-
guage for Ontology Editing. In 6th Interna-
tional and 2nd Asian Semantic Web Conference
(ISWC2007+ASWC2007), pages 141?154, Novem-
ber.
Hart, Glen, Martina Johnson, and Catherine Dolbear.
2008. Rabbit: Developing a control natural lan-
guage for authoring ontologies. In ESWC, pages
348?360.
Horridge, Matthew and Sean Bechhofer. 2010. The
OWL API. http://owlapi.sourceforge.net. Last ac-
cessed: 21st April 2010.
Horrocks, Ian. 1997. Optimising Tableaux Decision
Procedures for Description Logics. Ph.D. thesis,
University of Manchester.
Kaljurand, K. and N. Fuchs. 2007. Verbalizing OWL
in Attempto Controlled English. In Proceedings of
OWL: Experiences and Directions, Innsbruck, Aus-
tria.
Kruijff-Korbayova?, Ivana and Mark Steedman. 2003.
Discourse and information structure. Journal of
Logic, Language and Information, 12(3):249?259.
Motik, Boris, Peter F. Patel-Schneider, and Bijan
Parsia. 2010. OWL 2 web ontology language:
Structural specification and functional-style syn-
tax. http://www.w3.org/TR/owl2-syntax/. 21st
April 2010.
Power, Richard. 2010. Complexity assumptions in on-
tology verbalisation. In 48th Annual Meeting of the
Association for Computational Linguistics.
Rector, Alan, Nick Drummond, Matthew Horridge,
Jeremy Rogers, Holger Knublauch, Robert Stevens,
Hai Wang, and Chris Wroe. 2004. OWL Pizzas:
Practical Experience of Teaching OWL-DL: Com-
mon Errors and Common Patterns. In 14th Interna-
tional Conference on Knowledge Engineering and
Knowledge Management, pages 63?81.
Rosse, Cornelius and Jose? L. V. Mejino. 2003.
A reference ontology for biomedical informatics:
the Foundational Model of Anatomy. Journal of
Biomedical Informatics, 36(6):478?500.
Schwitter, R. and M. Tilbrook. 2004. Controlled
natural language meets the semantic web. In Pro-
ceedings of the Australasian Language Technology
Workshop, pages 55?62, Macquarie University.
Smart, Paul. 2008. Controlled Natural Languages and
the Semantic Web. Technical Report Technical Re-
port ITA/P12/SemWebCNL, School of Electronics
and Computer Science, University of Southampton.
TONES. 2010. The TONES ontology repository.
http://owl.cs.manchester.ac.uk/repository/browser.
Last accessed: 21st April 2010.
Walker, M., A. Joshi, and E. Prince. 1998. Centering
theory in discourse. Clarendon Press, Oxford.
1013
Composing Questions through
Conceptual Authoring
Catalina Hallett?
The Open University
Richard Power?
The Open University
Donia Scott?
The Open University
This article describes a method for composing fluent and complex natural language ques-
tions, while avoiding the standard pitfalls of free text queries. The method, based on Conceptual
Authoring, is targeted at question-answering systems where reliability and transparency
are critical, and where users cannot be expected to undergo extensive training in question
composition. This scenario is found in most corporate domains, especially in applications that
are risk-averse. We present a proof-of-concept system we have developed: a question-answering
interface to a large repository of medical histories in the area of cancer. We show that the method
allows users to successfully and reliably compose complex queries with minimal training.
1. Introduction
Where early attempts to build natural language question-answering systems focused on
accessing and presenting information held in (closed domain) databases (e.g., Hendrix
et al 1978; Templeton and Burger 1983; Kaplan 1984; Hafner and Godden 1985), the
advent of the World Wide Web has led to a shift towards (open domain) collections
of texts. However, despite significant advances in open domain question answering
since the simple pattern-matching systems of the first TREC competition in 1999,
current systems are still largely restricted to simple questions. They can, for example,
successfully find answers to questions like Which is the highest peak in Africa? or Who first
climbed Kilimanjaro? but they cannot correctly answer more complex questions like:
What is the median height of the top twelve highest peaks in Africa?
Which explorer who climbed Kilimanjaro but not Everest between 1960 and 1995 died in the last
three years before the age of 55?
How many of the explorers who climbed Kilimanjaro but not Everest between 1960 and 1995
did so more than three times during that period?
? Department of Computing, The Open University, Walton Hall, Milton Keynes, Buckinghamshire,
MK7 6AA, UK. E-mail: D.Scott@open.ac.uk; C.Hallett@open.ac.uk; R.Power@open.ac.uk.
The research presented here was supported in part by Medical Research Council grant G0100852
under the e-Science GRID Initiative. Special thanks are due our colleagues on CLEF (Alan Rector,
Jeremy Rogers, and James McKay) and to the CLEF clinical collaborators at the Royal Marsden and
Royal Free hospitals?see www.clinical-escience.org.
Submission received: 17 July 2005; revised submission received: 3 May 2006; accepted for publication:
28 July 2006.
? 2007 Association for Computational Linguistics
Computational Linguistics Volume 33, Number 1
There are many reasons why such queries are unlikely to be successful. For example,
although the first question is very simple to interpret, a correct answer is unlikely to be
available (in a retrievable form) in any individual document in the target collection.
A question-answering system would thus have to first retrieve the heights of each
of the top twelve highest peaks, probably from different documents, and apply some
calculations to obtain their median height, and then generate a response that aggregates
answers from multiple documents. The answer to the second question, on the other
hand, is very simple and likely to be found in a small number of documents, but
the question itself is not trivial to interpret and would require (among other things)
resolving the temporal information, correctly assuming that 55 refers to age at the time
of death, and interpreting the negation but not as referring to the climbing of Everest
only within the specified time span. For the third question, the difficulty comes from
a combination of complex question and complex answer. Retrieving aggregated results
from the World Wide Web also introduces issues of reliability because the sources may
not all be trusted, and there is no guarantee that a different selection of sources would
not yield a contrary result.
For many applications of question answering, the need for complex questions
and trusted answers is paramount?for example, in the medical, legal, and financial
domains, or indeed in any research area?and it is to this scenario that the work we
present here applies. Our goal is to develop a general and intuitive method by which
users can pose complex queries to data repositories; we are particularly concerned
with scenarios where the users are domain experts (i.e., clinicians, lawyers, financiers,
etc.) rather than database experts, where reliability of the answer is critical, where
the method of posing questions should be easy to learn, and where the questions
themselves should be transparent (i.e., clear and unambiguous) to both user and
system.
Current methods for querying databases typically make use of formal query
languages such as SQL. These languages are highly technical and require a great deal
of training to achieve the level of proficiency required to pose the kinds of complex
queries shown in the previous example. Successful query composition requires the user
to be proficient in the query language and have detailed knowledge of the structure
of the database to which the queries are being addressed. Users also need to be
fluent in any formal codes employed to refer to entities in the domain (e.g., disease
classifications, laws, bank codes). For example, in the medical domain alone there are a
large number of clinical terminologies and classifications, used for different purposes:
Some classifications, such as ICD-9, ICD-10, and OPCS-4, are employed in summarizing
the incidence of diseases and operations on a national or worldwide level; others,
such as CPT4 or ICD-9CM, manage the process of billing patients. Each covers a large
number of terms and associated codes: SNOMED-CT alone, to name the most widely
used medical terminology, currently contains some 365,000 individual concepts, and is
being updated continuously (College of American Pathologists 2004). Finally, because
database languages are not transparent, mistakes in query formulation can be difficult
to spot; so even where the system itself may be highly reliable, there is a reasonable
chance that?except for very highly experienced database programmers?the returned
answer may not be an accurate response to the intended question.
A well-known alternative to formal database languages is available in visual query
systems, which make use of graphical devices such as forms, diagrams, menus, and
pointers to communicate the content of a database to the user. They are also widely
used in commercial applications, and research shows that they are much preferred over
textual query languages like SQL, especially by casual and non-expert users (Capindale
106
Hallett, Scott, and Power Composing Questions through Conceptual Authoring
and Crawford 1990; Bell and Rowe 1992; Catarci and Santucci 1995). However, visual
interfaces are also problematic: empirical studies report high error rates by domain
experts using visual object-oriented modeling tools (Kim 1990), and a clear advantage
of text over graphics for understanding nested conditional structures (Petre 1995).
Natural language clearly provides a more intuitive means for users to pose their
questions, but this is also highly problematic because queries expressed in free natural
language are obviously very sensitive to errors of composition (e.g., misspellings,
ungrammaticalities) or processing (at the lexical, syntactic, or semantic level).
2. Natural Language Interfaces
In a typical natural language interface to a database (henceforth NLIDB), the user
requests database records through a query expressed in natural language. The ques-
tion is first parsed and analyzed semantically by a linguistic front-end, which trans-
lates it into an intermediate meaning representation language (typically, some form
of logic). The intermediate language expression is then translated into a database
language (usually SQL) that is supported by the underlying database management
system.
A large number of NLIDBs have been developed in the past 30 years, featuring a
wide range of techniques. The general drawback of these systems1 is that they normally
understand only a subset of natural language. Casual users cannot always discern
which constructions are valid or whether the lack of response from the system is due to
the unavailability of an answer or to an unaccepted input construction. On the positive
side, natural language is far more expressive than formal database query languages
such as SQL, so it is generally easier to ask complex questions using natural language
(NL) than a database language (a single natural language query will have to be trans-
lated into multiple SQL statements). Natural language queries are not only more user-
friendly for the non-expert user, but they also allow easier manipulation of temporal
constructions.
Broadly, research in NLIDBs has addressed the following issues:2
 domain knowledge acquisition (Frank et al 2005)
 interpretation of the NL input query, including parsing and semantic
disambiguation, semantic interpretation, and transformation of the query
to an intermediate logical form (Hendrix et al 1978; Zhang et al 1999;
Tang and Mooney 2001; Popescu, Etzioni, and Kautz 2003; Kate, Wong,
and Mooney 2005)
 translation to a database query language (Lowden et al 1991;
Androutsopoulos 1992)
 portability (Templeton and Burger 1983; Kaplan 1984; Hafner and Godden
1985; Androutsopoulos, Ritchie, and Thanitsch 1993; Popescu, Etzioni, and
Kautz 2003)
1 Leaving aside here the possibility of errors in parsing and interpretation.
2 The extent of NLIDBs research is such that it is beyond the scope of this article to reference a
comprehensive list of projects in this area. For a critical review of various NLIDBs, the reader is
referred to Androutsopoulos, Ritchie, and Thanisch (1995).
107
Computational Linguistics Volume 33, Number 1
In order to recover from errors in any of these steps, most advanced NLIDB systems also
incorporate some sort of cooperative user feedback module that will inform users when
the system cannot construct their query, and ask for clarification.
2.1 Our Solution: A Quasi-NL Interface
The solution that we propose partially overlaps with previous research in NLIDBs, in
that a logical representation is constructed using a NL interface, and then mapped
into the database query language. The difference lies in the nature of the NL interface,
which in our case uses a method that we call Conceptual Authoring; this replaces the
traditional method of free text entry followed by automatic interpretation.
There are two key ideas to Conceptual Authoring. The first (captured by ?Con-
ceptual?) is that all editing operations are defined directly on an underlying logical
representation, governed by a predefined ontology. Instead of typing in text, the user
builds the logical representation directly, so no problem of interpretation arises. The
second key idea (captured by ?Authoring?) is that the user interface presents the
developing logical representation, and the options for editing it, in a way that is
transparent to users?namely, natural language text, possibly supplemented by other
familiar media; users therefore feel that they are performing a familiar activity, a kind
of guided writing, rather than an unfamiliar activity akin to programming.
In general, then, Conceptual Authoring requires that some kind of formal knowl-
edge encoding is edited by direct manipulation of a familiar presentation, the presen-
tation being generated automatically from the underlying knowledge encoding, and
updated every time knowledge is added (or removed) through an editing operation.
The user need not be aware of the underlying formalism any more than a person using
a text editor need be aware of ASCII codes. Conceptual Authoring therefore depends
entirely on language generation technology; it does not use language interpretation
at all.
Various applications of Conceptual Authoring are possible, depending on the
nature of the underlying knowledge and the presentational medium. In the query
editor described in this article, the underlying knowledge is a set of assertions (i.e., an
A-box), and the presentational medium is natural language text. Elsewhere, we have
used the term WYSIWYM (What You See Is What You Meant) for various systems of this
kind that we have developed (Power and Scott 1998): as well as query interfaces they
include programs that generate technical documentation in multiple languages. We use
?Conceptual Authoring? as a more general term that would also cover applications in
which the underlying knowledge included conceptual definitions and rules as well as
assertions, and the presentation medium included diagrams as well as text?provided,
of course, that the diagrams were familiar to the relevant subject-matter experts (e.g., a
molecular structure diagram if the user were an organic chemist).
The basic idea of Conceptual Authoring is that a special kind of natural language
text is generated in order to present successive states of the underlying logical
representation. This text includes generic phrases, called ?place-holders?, which mark
attributes that currently have no value. Place-holders serve as the locations where new
objects may be added. By opening a pop-up menu on a place-holder, the user obtains
a list of short (generated) phrases describing the types of objects that are permissible
values of the attribute; when one of these options is selected, a new object of the
specified type is added. New text is then generated to present the modified logical
representation, including the attributes of the new object. As more information is added
108
Hallett, Scott, and Power Composing Questions through Conceptual Authoring
about an object, it will be presented by longer spans of text, comprising sentences or
perhaps even paragraphs. These spans of text are also mouse-sensitive, so that the
associated semantic material can be cut or copied. The cutting operation removes the
logical fragment that was previously the value of an attribute, and stores it in a buffer,
where it remains available for pasting into another suitable location. The text associated
with the fragment may or may not remain the same, depending on the context of the
new location.
As an illustration, suppose that the user wishes to define an event that might
naturally be expressed by the sentence The doctor examined the patient with a stethoscope.
The underlying logical structure could be an event object of type examined, with
attributes for actor, actee, and instrument; this will of course be only one among
many events allowed by the ontology. To define this content using a Conceptual
Authoring interface, the user begins from a text containing a place-holder for any kind
of event. By clicking on this place-holder, the user obtains a list of event patterns, each
shown as a short phrase corresponding to a specific event type from the ontology:
FEEDBACK TEXT
[Some event]
MENU OF OPTIONS
.....
consulted
examined
treated
visited
.....
When the user selects examined from this list, an event object of type examined is added
to the underlying semantic model, and the feedback text is regenerated to express the
new event and its attributes (as yet unspecified), which are shown by short phrases in
square brackets (the place-holders). A color code on place-holders indicates whether
an attribute is obligatory (it must be specified) or optional (it can be left unspecified);
here for convenience we use boldface for obligatory, and italics for optional. By clicking
on a place-holder, say the first, the user can now obtain options for specifying the
corresponding attribute (in this case the actor).
FEEDBACK TEXT
[Some person] examined [some person] [in some way]
MENU OF OPTIONS
.....
doctor
nurse
patient
.....
109
Computational Linguistics Volume 33, Number 1
By making successive choices in this way, the user will complete the desired proposi-
tion, perhaps through the following sequence:
[Some event].
[Some person] examined [some person] [in some way].
The doctor examined [some person] [in some way].
The doctor examined the patient [in some way].
The doctor examined the patient by using a stethoscope.
Note that because the feedback text is always generated by the system, we can try to
design feedback texts in a way that minimizes ambiguity. We might, for instance, prefer
to avoid the more natural phrase ?with a stethoscope?, which introduces the well-known
PP-attachment ambiguity, in favor of the slightly clumsy but unambiguous alternative
employed herein.
As well as introducing new objects on place-holders, the user can select a span
representing a filled slot and perform Cut or Copy. For instance, from the feedback
sentence reached in the last example, the user could select the span ?the patient? and
choose Cut, thus emptying the slot and reinstalling the place-holder:
The doctor examined [some person] by using a stethoscope.
Having freed up the slot in this way, the user might next select ?The doctor?, choose
Copy, select the place-holder ?[some person]?, and choose Paste. The Copy operation
here applies to the actual instance selected: It does not create a new instance of the same
type. Therefore, after the Paste operation, the doctor instance fills two slots, both the
actor and the actee of the event. The resulting coreference is shown by the wording of
the feedback text:
The doctor examined himself by using a stethoscope.
Conceptual Authoring (or WYSIWYM) has been applied as a tool for creating
knowledge content for multilingual generation of instruction manuals (Power and Scott
1998; Power, Scott, and Evans 1998; Scott, Power, and Evans 1998) and pharmaceutical
leaflets (Bouayad-Agha et al 2002). It has also been applied in a tool for posing queries
to a knowledge base of legal and regulatory information about maritime shipping
(Piwek et al 2000; Piwek 2002; Evans et al in press). In some ways the interface
resembles early menu-based techniques like Tennant, Ross, and Thompson (1983) and
Mueckstein (1985); however, this resemblance is only superficial, because in these
techniques the user edits a linguistic structure, whereas in Conceptual Authoring all
editing operations are defined on an underlying logical structure.
3. A Test Application: Electronic Health Records
Typically, an individual?s medical record is a collection of documents held in his or her
doctor?s office; most people will also have other records held at other sites, such as
110
Hallett, Scott, and Power Composing Questions through Conceptual Authoring
hospitals or clinics they have attended, or specialists they have seen. These records are
primarily textual, and the record of the average hospital patient will consist of a large
number of documents?around 100 narratives, plus hundreds of items of structured
data derived from laboratory, pharmacy, or other hospital subsystems. There is a
significant move?not just by medical providers, but by governments (e.g., the National
Programme for Information Technology in Medicine [NPfIT] in the UK, and various
e-Health initiatives in other countries)?to replace or supplement the current form of
patient records with electronic records; these are intended to be not simply electronic
text files of the existing records, but collections of ?messages? held in databases and
accessible at the point of care. One of the disadvantages of text-only health records is
that the information contained within them, because it is ?locked into? the text, is not
available for statistical manipulation and cannot be easily interrogated.
Previous studies (Gorman and Helfand 1995; Ely et al 2000; Jerome et al 2001;
Estrella et al 2004; Koonce, Giuse, and Todd 2004), as well as our own preliminary
analysis, show that free text queries written by medical professionals are mostly
complex and often highly ambiguous. From this we conclude that when querying
medical databases, such users need to be able to construct queries that are complex,
both in volume of material and in the organization of this material (e.g., into temporal
or conditional constructions). Traditionally, user interfaces to medical databases have
been complex visual interfaces that are unsuitable for use by a casual user (Nadkarni
and Brandt 1998; Shahar and Cheng 1999).
Electronic health records provide a good example of the kind of application
for which question-answering systems are required for accessing large collections of
trusted closed-domain data. Not only is there a requirement for complex queries of
the sort that are extremely difficult to achieve in current natural language question-
answering systems but, for obvious reasons, the veracity of the results of any query is
critical, making it doubly important that queries put to the system, and their resulting
responses, are unambiguous and clearly understandable to the user. Because the users
will be medical professionals, with great demands on their time, the ease of use
of the question-answering system is also extremely important. We have applied our
Conceptual Authoring question-answering method to one such application: the Clinical
E-Science Framework (CLEF).
3.1 The Clinical E-Science Framework
The Clinical E-Science Framework (CLEF) aims at providing a repository of well-
organized clinical histories that can be queried and summarized both for biomedical
research and clinical care (Rector et al 2003). In this context, the purpose of the query
interface is to provide efficient access to aggregated data for performing a variety of
tasks: assisting in diagnosis or treatment, identifying patterns in treatment, selecting
subjects for clinical trials, and monitoring the participants in clinical trials. Although
the CLEF architecture is largely independent of any particular area of medicine, it is
currently being applied to cancer, in collaboration with the Royal Marsden Hospital in
London, one of the primary centers for the treatment of cancer in Britain.
The current CLEF database repository contains 22,500 patient records,3 containing
a total of more than 400,000 database entries, some 3.5 million record components
3 At present, the repository contains records of deceased patients only. In the near future, it will grow
significantly with the addition of live patient records.
111
Computational Linguistics Volume 33, Number 1
and more than 5 gigabytes of data, implemented as a relational database that stores
patient records modeled on an archetype for cancer developed by Kalra et al (2001).
The information on each patient comes from hundreds of documents, and a single care
episode or clinical problem is likely to be mentioned repeatedly in several documents.
Within CLEF, a patient record is organized as a collection of individual entries, each
entry representing an instance of the cancer archetype.
3.2 Users and Extent
The CLEF query system is designed to answer questions relating to patterns in medical
histories over sets of patients in the repository. At this point, the system supports
attribute-centric queries asking for aggregated results, such as:
{Absolute count/percentage/statistical measure} of patients with certain characteristics.
The answers to such queries can be produced by simple interrogation of the
database, because they do not require inferences over the repository of patient records.
However, the query interface is also coupled with a data-mining module to provide
answers to more complex queries, such as
Given certain conditions, what is the treatment with the highest chance of success for a patient
with certain characteristics?
The query interface can also be used for accessing information about individual
patients.
The interface is designed for casual and moderate users who are familiar with the
semantic domain of the repository (but not with its actual structure or encoding) and
who require queries of little variance but with relatively high structural complexity.
Under this description come three primary types of users, each having a different goal
in interrogating the repository:
 clinicians, who use it for assisting in diagnosis or treatment
 medical researchers, who use it for identifying patterns in treatment,
selecting subjects for clinical trials, or monitoring the participants in
clinical trials
 hospital administrators, who use it for collecting information about
patterns of treatment, frequency of tests, hospital admissions, and so on
Among these, we expect those users with little or no knowledge of formal database
languages (e.g., SQL) to be the main beneficiaries of the query interface, although in the
Evaluation (Section 6) we will show that even for SQL-aware users, the query interface
represents an improved alternative to standard SQL. We also target the interface at users
who are unfamiliar with medical encoding schemes, such as SNOMED or ICD, or who
prefer to use natural language expressions instead of medical codes.
3.3 Previous Work on Querying Clinical Databases
There are a number of query systems for clinical databases, mostly designed for
formulating patient-centric queries and typically using visual interfaces. For example:
112
Hallett, Scott, and Power Composing Questions through Conceptual Authoring
Figure 1
Architecture of the CLEF query interface.
The Columbia-Presbyterian Medical Center Query Builder works off the medical
center?s data repository and generates both HL7 and Arden Syntax4 for several
categories of data; for example, patient demographics, laboratory values, medi-
cations, and diagnoses (Wilcox, Hripcsak, and Chen 1997). The user interface is a
simple HTML-based application that allows users to select the type of data they
want to query and to specify constraints on it.
TrialDB (formerly ACT/DB) is a clinical study data management system that provides
a complex visual interface for formulating attribute-centric temporal queries
(Nadkarni and Brandt 1998; Deshpande, Brandt, and Nadkarni 2001, 2003). The
interface allows for attributes to be searched and selected by specifying key words
or part of the attribute name/caption. Once an attribute is selected, the user may
optionally specify that an aggregate value for that attribute be returned. Searching
criteria can be combined using boolean operators.
KNAVE is a visualization and navigation model that enables clinicians to query a specific
patient record for time-oriented raw data, external interventions, abstractions, and
temporal patterns, and to visualize the results of the temporal query (Shahar and
Cheng 1999).
Natural language query interfaces have been used far less extensively and for more
restricted tasks. For example, the HERMES system (Rivera and Cercone 1998) allows
the formulation and interpretation of ad hoc queries relating to doctor and patient
demographic information, patients? personal details, visit information, and insurance
coverage information. It is designed as an aid to hospital administration, and not to
clinical care.
4. The CLEF Query Interface
The CLEF Query Tool has four components which are invoked in sequence whenever a
query is posed by the user (Figure 1). The first is the Query Editor, a natural language
interface which guides the user in building a clear and valid query. The output of
4 HL7 is an internationally adopted communication language used for healthcare data. It covers the whole
scope of healthcare communication (http://www.hl7.org). Arden Syntax is a standard specification of
defining and sharing modular health knowledge bases, providing procedural representations of medical
knowledge and explicit definitions.
113
Computational Linguistics Volume 33, Number 1
this component is a logical representation underlying the query text that the user has
created. The second component, the Query Transcoder, converts this logical represen-
tation to a Java encoding accepted by the CLEF database management system (DBMS).
In this form, the query is sent to the DBMS, which recodes it again into SQL and
submits it to the database. The result of the query, usually a list of records for relevant
patients, returns to the third component of the Query Tool, the Result Processor, which
transforms the raw data into an aggregated representation defining the content of the
answer. This representation then passes to the fourth and final component, the Answer
Renderer, which configures a convenient display for the user by combining fluent text
with diagrams (tables and charts).
We now describe these components in more detail.
4.1 Query Editor
The Query Editor allows the user to create a logical representation of the query by means
of Conceptual Authoring. When beginning a new query, the user is shown a minimally
specified feedback text based on a model of query structure in this domain; this model
is described in Section 5. By inserting content in the initial place-holders, the user can
build up the full text of a query in a few dozen choices, a process that takes a few
minutes once the user has become accustomed to the editing process (for details, see
Section 6). A query is potentially complete when all obligatory slots have been filled.
This is easy for the user to verify because obligatory place-holders are shown in red:
When no red text remains, the query is complete. At this point, the user can hit the
Submit button, whereupon the current A-box is passed to the Query Transcoder.
4.2 Query Transcoder
The Query Transcoder takes as input an A-box from the Query Editor, and recodes it
in the format expected by the DBMS. This conversion depends on a mapping between
the ontology (or T-box) employed by the Query Editor, and the concepts of the database
archetype. The T-box cannot be exactly the same as the archetype, because it has to serve
a different purpose?that of providing logical representations suitable for generating
linguistic structures like clauses and nominals.
4.3 Result Processor
The Result Processor receives the data returned by the DBMS, normally a set of records
for relevant patients, and constructs the logical representation of an answer for the user.
A typical result set received from the DBMS would list the patients that fulfilled the
requirements of the query, and specify, for each patient, the features AGE and GENDER
along with values for each of the query elements. For example, the query
How many patients between 30 and 70 years of age, who had a clinical diagnosis of malignant
neoplasm of breast and underwent surgery, had a haematoma after surgery?
may yield the result set shown in Figure 2.
From such data, the Result Processor plans aggregate presentations in which
patients are grouped according to the age/gender breakdown and the individual query
terms. For each query term, the data are split into a dynamically determined number of
age groups, and for each age group the patients are further subdivided by gender.
114
Hallett, Scott, and Power Composing Questions through Conceptual Authoring
Figure 2
Example of a result set.
4.4 Answer Renderer
The data thus organized are presented to the user in three types of formats: tables, charts
and text. Each individual chart is accompanied by an automatically generated caption
that explains its content.
Captions are generated using template-based techniques, where fillers are provided
by the same data that were used for generating the chart. For example, the results we
saw in Figure 2 are presented as an answer that includes the bar chart in Figure 3.
This is accompanied by a textual explanation in the form of a caption, a fragment of
which reads:
Your query has returned 965 patients between 30 and 70 years of age who had a clinical
diagnosis of malignant neoplasm of breast and underwent surgery. This chart displays
the distribution of patients in five age groups according to their gender and time of
haematoma after surgery.
? In the 30?39 years age group there were 163 patients (2 men and 161 women):
151 patients did not have haematoma after surgery, 12 patients had haematoma
after surgery.
? In the 40?49 years age group there were 326 patients (no men and 326 women):
304 patients did not have haematoma after surgery, 22 patients had haematoma
after surgery.
? In the 50?59 years age group there were 363 patients (8 men and 355 women):
337 patients did not have haematoma after surgery, 26 patients had haematoma
after surgery.
? In the 60?69 years age group there were 110 patients (2 men and 108 women):
97 patients did not have haematoma after surgery, 13 patients had haematoma
after surgery.
? In the 70?79 years age group there were 3 patients (one man and two women):
two patients did not have haematoma after surgery, one patient had haematoma
after surgery.
5. Query Model
A controlled editing environment is most effective when based on a model of the kinds
of queries that users will wish to make. There is a trade-off here between flexibility and
ease of use. If we have no preconceptions about the general nature of queries, we have
to provide users with a wide set of possible patterns, leaving them to search for the
particular pattern they happen to want. If instead we can assume that the query will
belong to a known set of patterns, the editor can help the user to get started by offering
a manageable list of alternatives, so avoiding the ?blank page? problem.
Investigations on a taxonomy of queries posed by general practitioners in an
outpatient setting has shown that in primary care, queries are relatively simple and
115
Computational Linguistics Volume 33, Number 1
Figure 3
Chart generated as part of a response displaying the distribution of patients who developed and
did not develop haematoma according to their age and gender.
generally ask for evidence-based advice for treatment decisions (Ely et al 2000). For
example, of 64 generic question types, the three most common are:
What is the drug of choice for condition X?
What is the cause of symptom X?
What test is indicated in situation X?
In contrast to these findings, our consultation with cancer clinicians revealed that
questions posed in a clinical research setting tend to have a more complex nature
and to be directed at groups of patients, searching for relationships rather than simple
values:
What is the average time of relapse in Acute Myeloid Leukaemia for patients with a complete
response after two cycles of treatment?
Can this time be linked to the cytogenetic findings in the original blood sample?
What is the median time between first drug treatment for metastatic breast cancer and death?
116
Hallett, Scott, and Power Composing Questions through Conceptual Authoring
Our policy in CLEF has been to aim first at a relatively specific model, under the
guidance of the relevant experts?clinicians and medical researchers in the area of
cancer.
5.1 Elements of a Basic Query
The structure of a typical query (according to our experts) is shown by the following
relatively simple example:
For all patients with cancer of the pancreas, what is the percentage alive at five years for those
who had a course of gemcitabine?
As can be seen, this query breaks down into three elements: the set of relevant patients,
defined by a problem; the partition of this set according to treatment; and the further
partition according to outcome, from which the percentage can be calculated. For
maximum clarity, the Query Editor can format the query so that these three elements
are marked explicitly and presented separately:
Relevant subjects: Patients with cancer of the pancreas.
Treatment profile: Patients who received a course of gemcitabine.
Outcome measure: Percentage of patients alive after five years.
Generalizing from this example, we can identify the following basic query pattern:
Relevant subjects: Patients with [some diagnosis].
Treatment profile: Patients who received [some treatment].
Outcome measure: [Measure] of patients [with some status] [at some point in time].
An important requirement on this formulation of the query is that it should
be unambiguous?namely, that users should understand correctly how the outcome
measure will be calculated. We assume that the calculation will proceed through the
following steps. First, retrieve all the patients in the database who satisfy the conditions
in the first two paragraphs (Relevant subjects and Treatment profile)?in this example,
all patients with cancer of the pancreas who received a course of gemcitabine. Call this
set S and let its cardinality (i.e., the number of patients in the set) be C(S). Next, find
the subset of S also satisfying the outcome condition?in this example, the patients still
alive after five years. Call this set M and its cardinality C(M). Finally, divide C(M) by
C(S) and express the result as a percentage.
With a slight elaboration of this basic pattern, we can obtain a second kind of query,
which requests a comparison rather than a single value:
For all patients with cancer of the pancreas, compare the percentage alive at five years for those
who had a course of gemcitabine with those who didn?t.
Again this can be presented to the user using a separate paragraph for each element:
Relevant subjects: Patients with cancer of the pancreas.
Treatment profile: Patients who received a course of gemcitabine, compared with
patients who did not.
Outcome measure: Percentage of patients alive after five years.
117
Computational Linguistics Volume 33, Number 1
For a comparison question we need to compute two outcome measures, so the steps in
the calculation have to be elaborated as follows. First, retrieve two sets of patients, S1
and S2, satisfying the conditions that we want to compare. In the example, S1 will be
the set of patients with cancer of the pancreas who had a course of gemcitabine; S2 will
be the set of patients with the same type of cancer but no gemcitabine treatment.5 Next,
for each set, find the subset of patients still alive after five years: Call these subsets M1
and M2. Finally, compute the measures to be compared by dividing C(M1) by C(S1), and
C(M2) by C(S2), and expressing the resulting ratios as percentages.
5.2 Complex Queries
Each element of a query can be made more complex in two ways. First, it can be replaced
by a conjunction or disjunction, so that the query in a sense becomes several queries
requiring several answers. Second, the content of the description can be elaborated, for
example by adding more qualifications. Here is an example of the first kind:
For all patients with a brain glioma, what percentages are still alive at 1, 2, and 5 years if they
take Imatinib Mesylate every day?
This can be analyzed as a single relevance group, single treatment, and multiple
outcome measures (survival at 1, 2, and 5 years). Separate answers for these measures
will be needed. An example of the second kind is the following:
For all patients with cancer of the vulva that is locally advanced and/or metastatic or recurrent,
and where this cannot be treated with either surgery or radiotherapy of any kind, what is the
survival rate for those given Taxol only?
We assume this is a single rather than a multiple query, and that separate answers are
not needed for the various conjunctions and disjunctions. The treatment profile (Taxol)
and the outcome measure (survival rate) have a content that can be easily specified?a
single choice from a menu would suffice. However, the set of relevant patients requires
a very elaborate description because there are so many qualifications.
5.3 Multiple Relevance Sets
When the phrase describing a relevance set includes a conjunction or disjunction, there
may be ambiguity over whether the intended query is single or multiple. Compare these
three patterns:
(1) For all patients with lung cancer, and for all patients with breast cancer . . .
(2) For all patients with lung cancer and breast cancer . . .
(3) For all patients with lung cancer or breast cancer . . .
Here (1) seems a clear case of a multiple query, whereas the others are ambiguous
but tending to a single-query interpetation. It is hard to eliminate such ambiguities
altogether while wording the query in a way that is reasonably natural, but at least we
can impose consistency by using different realization devices for the two cases?for
5 These sets are obviously disjoint.
118
Hallett, Scott, and Power Composing Questions through Conceptual Authoring
example, bulleted lists for conjunctions (or disjunctions) that imply multiple queries,
and discourse connectives (and, or) for ones that imply single queries. For example:
Relevant subjects:
? Patients younger than 60 years of age who have had bad prognosis
myelodysplastic syndrome only for at least six months
? Patients younger than 60 years of age who have had acute
myelogenous leukaemia caused by bad prognosis myelodysplastic
syndrome for at least six months
versus
Relevant subjects:
? Patients younger than 60 years of age who have either had bad
prognosis myelodysplastic syndrome only for at least six months or
acute myelogenous leukaemia caused by bad prognosis myelodysplastic
syndrome for at least six months
In the first we have two relevance sets; in the second we have only one.
5.4 Multiple Treatment Profiles
A similar ambiguity is found when several treatment profiles are mentioned. Either
there are several queries, or there is a single query concerning a logical combination of
the treatments. The following query text (written as an example by a medical researcher)
could be interpreted either way:
For all patients younger than 60 years of age who have either had bad prognosis myelodysplastic
syndrome only for at least six months or acute myelogenous leukaemia caused by bad prognosis
myelodysplastic syndrome for at least six months, what is the survival rate if you give them
intensified remission induction chemotherapy followed by either an autologous or allogeneic
bone marrow transplant?
Perhaps the researcher?s aim is to compare autologous bone marrow transplants
with allogeneic ones. Alternatively, it might not matter whether the transplant is
autologous or allogeneic provided that it is one or the other, as suggested by the singular
verb (?what is the survival?). In the query interface, the ambiguity can be avoided in the
same way as before, by using bullets to mark separate queries. For example:
Treatment profiles:
? Intensified remission induction chemotherapy followed by an
autologous bone marrow transplant
? Intensified remission induction chemotherapy followed by an
allogeneic bone marrow transplant
versus
Treatment profiles:
? Intensified remission induction chemotherapy followed by an
autologous or allogeneic bone marrow transplant
In the first we have two treatment profiles and hence separate queries; in the second we
have only one.
119
Computational Linguistics Volume 33, Number 1
5.5 Multiple Outcome Measures
There are several examples in which survival rates are requested at, say, one year,
two years, and five years. It makes no sense to combine these into a single query, so
they are always interpreted as separate queries.
5.6 Comparison Queries
Comparison queries are those that ask for certain outcomes of separate groups of
patients that do not share common diagnosis or treatment profiles.
Compare survival rates at 5 years after diagnosis for patients with adenocarcinoma who received
chemotherapy and patients with invasive ductal carcinoma who received radiotherapy.
We represent such queries as two independent queries, with separate profiles.
5.7 Elaborate Descriptions
Descriptions are boolean combinations of properties. A description can be elaborate
either because it contains many boolean operators, or because the properties are
themselves complicated. The following description of a reference set is elaborate in
both ways:
For all patients younger than 60 years of age who have either had bad prognosis myelodysplastic
syndrome only for at least six months or acute myelogenous leukaemia caused by bad prognosis
myelodysplastic syndrome for at least six months, what is the survival rate. . . ?
Complex boolean combinations of this kind often cannot be presented in running
prose without the scopes of the boolean operators becoming unclear. To avoid this
problem, the feedback text generator formats complex boolean combinations using
hierarchical layout:
Relevant subjects:
? Patients with the following properties:
a. They are younger than 60 years of age
AND
b. They have one of these properties:
b1. They have had bad prognosis myelodysplastic syndrome only
for at least six months
OR
b2. They have had acute myelogenous leukaemia caused by
bad prognosis myelodysplastic syndrome for at least six
months
Descriptions of treatment profiles can be elaborate in the same ways. The following
excerpt has two treatment profiles, the first using a combination of AND and NOT, the
second using AND combined with temporal sequence (marked by THEN).
. . . compare the survival rates over time for those who had no surgery but did have mitomycin C
injected into the bladder once a month, with those who had transurethral resection of the tumor
and then a single one-time injection of mitomycin C into the bladder.
120
Hallett, Scott, and Power Composing Questions through Conceptual Authoring
The corresponding part of the feedback text is laid out as follows:
Treatment profiles:
? a. NO surgery
AND
b. Mitomycin C injected into the bladder once a month
? a. Transurethral resection of the tumor
THEN
b. A single one-time injection of mitomycin C into the bladder
5.8 Representing Time
Queries about patient records contain many references to events occurring at particular
times: diagnoses, tests, treatments, deaths, and so forth. These time specifications are
crucial. To deal with them effectively, the query tool must meet two requirements.
First, the feedback text should express temporal relations naturally and unambiguously,
using familiar devices like tenses and adverbials. Second, the resulting conceptual
representation (in the A-box) must be aligned with the fields through which time is
represented in the database.
Like most databases, the CLEF medical records employ several types of time stamp.
First of all, an event has a valid time, the moment when it actually took place. For
example, if a mastectomy was performed on 29th January 2000, the valid time would be
some representation of this day, perhaps ?29-01-2000?, assuming a granularity calibrated
in days (rather than hours, weeks, etc.). Next, an event has a recording time, the
moment when it was written down. Obviously this might differ from the valid time,
although they would be the same if the doctor kept prompt records. We also use a
concept of query time, the moment when a query was formulated by the CLEF user:
this is needed in order to interpret deictic time references in the feedback text, based
for example on tenses or on phrases like ?after 1995?, which can be interpreted to mean
?from 1995 until now?.
For some events the valid time can be a single moment, specified for example by a
date. For events that last for longer intervals, like a whole course of treatment, two valid
time stamps have to be given, one for the start time and one for the end time. Of course
this distinction is related to granularity. With a granularity based on days, a week has
to be treated as an interval with a start date and an end date; with a granularity based
on weeks, the same week could be identified by a single time stamp (e.g., ?W40-2000?,
meaning the 40th week of the year 2000).
To model time effectively in queries, we need to provide a range of natural and
clear options, and map them to the time stamps used in the database. At present, the
temporal modifiers offered during query editing are as follows:
 between [date 1] and [date 2]: interpreted as a closed interval [date 1, date 2]
 after [some date]:interpreted as a closed interval [this date, query time]
 before [some date]
 in [this year]: interpreted as [01/01/this year, 31/12/this year]
 any of the above, where instead of a specific date the user enters an index
event after the surgery; in this case, the implied time will be computed by
the DBMS instead of explicitly entered by the user
121
Computational Linguistics Volume 33, Number 1
 event1 {while/at the same time as/during event2} : will be interpreted as two
overlapping time intervals corresponding to the two events
For example, such time expressions cover queries like: patients diagnosed with cancer
before 1999, or patients who received chemotherapy within 5 months of surgery. The interface
allows Allen?s 13 basic interval relationships to be expressed in natural language (Allen
1984).
In principle we could require users to associate a time stamp with every event
mentioned in a query; however, by imposing this further requirement on users we
would pay a high price in usability, virtually doubling the number of operations needed
in order to complete the query, and damaging the transparency of the resulting text.
In the CLEF query interface we have decided instead to associate default values to
time descriptions and to make the time stamp anchors visible only on demand in the
feedback text. The output text will contain all the time stamps, with the values either
entered by the user or defaulted, so allowing the user to review the query and amend it
where necessary.
6. Evaluation
The best evaluation of any question-answering system is one which looks at real users
making information-seeking requests in real-life contexts. Because the complete CLEF
system is not yet ready for deployment, this is impractical at this stage. However, we
have been able to perform usability tests on the query interface in isolation from the
full system, and this is what we report on here. Our current study does not cover
the Query to SQL Translation and the Answer Retrieval components, which are part of
the server components side of the query interface. This separation is not always possible
in practice. For example, we cannot at this stage test the full range of queries that can
be constructed in the interface, because some are not yet supported by the back-end.
Similarly, we can only assess the time necessary for editing queries, not for retrieving
answers, because this is almost entirely dependent on the communication procedure
and on the speed of the SQL translator.
We have thus far conducted two formal experiments, to address the following
questions:
 Are users able to successfully compose complex queries using the system?
 Can the system be used with minimal training?
 Are the queries, as presented in the interface, easily understandable?
6.1 Experiment 1: Query Composition
As mentioned earlier (Section 1), one of the main desiderata behind the design of our
querying method is that it should be intuitive. With respect to the system we have
implemented for CLEF, what this means is that medics and bio-informaticians should
be able to pose the kind of complex queries that they require, without the need for
extensive training, or for knowledge of the structure or language of the underlying
repository. This experiment tests the extent to which our querying method fulfills these
requirements.
122
Hallett, Scott, and Power Composing Questions through Conceptual Authoring
Subjects. Fifteen medics and bio-informaticians participated in the experiment. All had
previously been granted clearance6 to see the information in the confidential repository
of patient records. All subjects were knowledgeable in the domain of cancer, and all
but two had no knowledge of the representation language of the repository (SQL), or
of how the data contained therein were structured; none had any prior experience with
the query-formulation interface.
Methodology. Each subject was given a short (5?10 minute) introduction to the interface,
which included a demonstration of the construction of a fairly simple query. Subjects
were then given a set of four queries, which they were asked to compose using the
interface. To increase the difficulty of the task, the questions presented to the subjects
avoided, where possible, the wording required by the user interface, so that users were
obliged to think about the meaning rather than to aim for particular target phrases. To
avoid effects of practice, we varied randomly the order in which the questions in the
set were presented to subjects. Subjects were allowed as much time as they needed to
compose each query.
For each subject, we measured the time taken to build each query, and recorded the
number of operations used for constructing it.
Materials. The materials for the experiment consisted of the following set of four queries:
How many patients who received surgical treatment for malignant neoplasm of the central
portion of the breast had no curative radiotherapy?
How many patients between the ages of 40 and 60 when they were first diagnosed with lung
cancer (malignant neoplasm of bronchus or lung, unspec) received radiotherapy and had
a platelet count higher than 300 and a leukocytes count lower than 3?
What percentage of patients under the age of 60 treated for breast cancer (malignant neoplasm
of breast, unspec) died within 5 years of a mastectomy?
How many patients with acute lymphoid leukaemia have been given chemotherapy?
These are representative of the query types that emerged from an earlier requirements
analysis with oncologists and cancer bio-informaticians. They also vary in their levels of
structural complexity and in the number of interface operations required to successfully
complete them.
As can be seen, these questions are far more complex than the queries standardly
posed to search engines or to most other interactive query engines (as described,
for example in [Hovy, Hermjakob, and Ravichandran 2002]; [Soricut and Brill 2004];
[TREC 2005]).
Results. The main finding of this experiment is the achievement of 100% success in
subjects? ability to use the interface for the purpose for which it was intended: All
subjects successfully composed all queries. The mean completion time per query was
3.9 minutes (noting that subjects were under no time pressure to complete the individual
6 By the UK Medical Research Ethics Committee (MREC).
123
Computational Linguistics Volume 33, Number 1
Figure 4
Mean completion time for queries in order of occurrence.
queries).7 Figure 4, which gives the average time to completion across all subjects, shows
that subjects learned to use the interface quickly: they take much longer on their first
query, and their performance asymptotes by the time they get to the second query.
This effect is confirmed by an analysis of variance (ANOVA)8, which shows a highly
significant effect of order of presentation (F = 9.8427; p< .0001). Furthermore, significant
differences were found between subjects? performance on the first query they composed
compared to the second, third, and the fourth (each at p < .01 on the Tukey HSD
test). However, application of the same test showed no significant difference in subjects?
performance on the second versus third, second versus fourth, or the third versus fourth
composed query.
Because the queries vary in structural complexity, some will require the user to
perform more interface actions than others, and so one would predict a difference in
subjects? performance (i.e., time to completion) on the individual queries; this was borne
out by the analysis (ANOVA, F = 5.5015; p < .0028).
If the method is easy to learn, one would predict that subjects? proficiency with the
interface will increase fairly quickly as they move from the first query they encounter
to the last, irrespective of complexity. This can be tested by measuring subjects?
performance on the interface in terms of the number of interface operations (mouse
clicks and selections) they perform, normalized for complexity: a value of 1 would
mean that subjects perform twice as many operations as are required; a value of 0 would
mean that subjects perform the minimal number of required operations (i.e., perfect
performance). The result of such an analysis is shown in Figure 5. The picture that
emerges from this is one where, overall, subjects are very efficient, achieving an average
score of 0.19 over their first four encounters with the method. They make a fair number
of false starts when composing their first query, but become extremely proficient by
the time they get to their second query, and near perfect by the time they get to the
fourth. Analysis of variance9 shows a highly significant effect of order of presentation
(F = 7.4993; p < .0004). Once again, the Tukey HSD Test shows a significant difference
between the first query encountered and each of the subsequent ones (p <. 01), and that
the differences between the second and third, the second and fourth, and the third and
fourth, were nonsignificant.
7 For the last 5 subjects, all of whom used a version of the interface that had been improved to respond
faster to interface actions, this average went down to 2.7 minutes.
8 One-way ANOVA for correlated samples.
9 One-way ANOVA for correlated samples.
124
Hallett, Scott, and Power Composing Questions through Conceptual Authoring
Figure 5
Proficiency with the interface as a function of experience.
6.2 Experiment 2: Clarity of the Queries
Interfaces to databases based on natural language interpretation inevitably suffer from
the ambiguity and imprecision of the input texts, unless users can be trained in a
controlled language. Our method of composing queries avoids this problem altogether:
because the natural language feedback text is generated by the system rather than the
user, there is no need for the system to choose among alternative interpretations. Of
course, this does not guarantee that the query text is equally transparent to the user: this
will depend on the efficacy of our feedback text design?the point we wish to evaluate
in the present experiment, which explores the extent to which composed queries, as
presented in the feedback texts, can be clearly understood.
Subjects. Fifteen subjects participated in the experiment. Of these, ten had previously
participated in Experiment 1; the new subjects had the same profile as those previously
seen.
Methodology. Subjects were given a paper-based questionnaire containing 24 trials, each
showing a completed complex query as presented in the interface (i.e., as a ?feedback
text?). Each query was associated with three alternative interpretations, presented as full
natural language questions: only one of these represented the correct meaning; the other
two represented plausible but incorrect meanings. Subjects were given a forced-choice
task to identify which of the three alternatives corresponded to the meaning of the given
feedback text.
The queries were presented to all subjects in the same (random) order. We devised
five presentation sets, each containing a different ordering of the options for each query,
and these were randomly assigned to subjects. We suggested to subjects that a useful
strategy might be to read the alternatives before looking at the associated feedback text.
There was no time limit.
Materials. The materials comprised four examples, each of six patterns of ambiguity:
Type 1: Attachment of temporal expression. Most events can have a temporal expression
associated. When there is more than one event that could be subsumed by a temporal
expression, the text may become ambiguous. For example:
Relevant subjects: patients with a clinical diagnosis of breast cancer
Treatment: patients who did not receive adjuvant chemotherapy in the past year
Tests: [ ]
Outcome: absolute number of patients
125
Computational Linguistics Volume 33, Number 1
Options:10
 How many patients diagnosed with breast cancer had no adjuvant chemotherapy
in the past year?
 How many patients treated for breast cancer in the past year had no
adjuvant chemotherapy?
 How many patients diagnosed with breast cancer in the past year had no
adjuvant chemotherapy?
Type 2: Scope of conjunctions. Whenever a complex expression contains a combination
of conjunctions and disjunctions, potential ambiguities may occur, especially when
combined with negations or prepositional phrases. For example:
Relevant subjects: patients with a clinical diagnosis of invasive ductal carcinoma
Treatment: patients who received breast conservation surgery, no auxillary surgery,
and radiotherapy
Tests:[ ]
Outcome: absolute number of patients
Options:
 How many patients diagnosed with invasive ductal carcinoma underwent breast
conservation surgery, did not undergo auxillary surgery, and received
radiotherapy?
 How many patients diagnosed with invasive ductal carcinoma underwent
breast conservation surgery, did not undergo auxillary surgery, and did
not receive radiotherapy?
 How many patients diagnosed with invasive ductal carcinoma did not
undergo breast conservation surgery, did not undergo auxillary surgery,
and received radiotherapy?
Type 3: Scope of conjunctions plus attachment of temporal expression. This is an extension of
the first two cases, where a temporal expression post-modifies an expression that is part
of a conjunction of events. For example:
Relevant subjects: patients with a clinical diagnosis of malignant neoplasm,
unspecified
Treatment: patients who received radiotherapy and chemotherapy within 1 year
of the diagnosis
Tests:[ ]
Outcome:absolute number of patients
Options:
 How many patients diagnosed with cancer had radiotherapy and chemotherapy
both within 1 year of diagnosis?
 How many patients diagnosed with cancer had radiotherapy within
1 year of diagnosis and also had chemotherapy at any time?
10 In the examples that follow, the correct interpretations are indicated with italics.
126
Hallett, Scott, and Power Composing Questions through Conceptual Authoring
 How many patients diagnosed with cancer had radiotherapy and
chemotherapy and received any kind of treatment within 1 year of
diagnosis?
Type 4: Combination of various query components. Events in a query can be linked to each
other by various means, including temporal expressions, conjunctions, and disjunc-
tions. Complex combinations may render the feedback text ambiguous. For example:
Relevant subjects: patients with a clinical diagnosis of breast cancer and who had
nausea within 1 year of the chemotherapy
Treatment: patients who received [some surgical procedure] [at some point in time]
and chemotherapy but no radiotherapy within 1 year of the diagnosis
Tests:[ ]
Outcome: percentage of patients who were alive after 5 years of the diagnosis
Options:
 What percentage of patients diagnosed with breast cancer who underwent a
surgical procedure at any time, received chemotherapy within 1 year of the
diagnosis, had nausea within 1 year of the chemotherapy, and received no
radiotherapy within 1 year of the diagnosis, survived more than 5 years
after diagnosis?
 What percentage of patients diagnosed with breast cancer who underwent
a surgical procedure at any time, received chemotherapy at any time, had
nausea at any time after chemotherapy, and received no radiotherapy
within 1 year of the diagnosis, survived more than 5 years after diagnosis?
 What percentage of patients diagnosed with breast cancer who underwent
a surgical procedure at any time, received chemotherapy within 1 year of
the diagnosis, had nausea after chemotherapy but within 1 year of the
diagnosis, and received no radiotherapy within 1 year of the diagnosis,
survived more than 5 years after diagnosis?
Type 5: Complex queries, non-ambiguous components. We introduced this category in order
to test the readability of complex queries that do not necessarily contain ambiguous
components. Because most queries in the medical domain are likely to be very complex,
can the sheer number of query components render the query ambiguous to the users?
For example:
Relevant subjects: patients under the age of 50 at the time of diagnosis, with a
clinical diagnosis of breast cancer
Treatment: patients who received [some surgical procedure] [at some point in time]
and no chemotherapy within 1 year of the diagnosis
Tests: [ ]
Outcome: absolute number of patients
Options
 How many patients with breast cancer, under the age of 50, had a surgical
procedure at any time and did not have chemotherapy within 1 year of the
diagnosis?
127
Computational Linguistics Volume 33, Number 1
 How many patients with breast cancer, under the age of 50, had a surgical
procedure within one year of the diagnosis and did not have
chemotherapy within one year of the diagnosis?
 How many patients with breast cancer, below the age of 50, had a surgical
procedure within one year of the diagnosis and had chemotherapy after
one year of the diagnosis?
Type 6: Attachment/interpretation of outcome. The outcome section generally describes a
condition holding between a reference and a target set of patients. If the query contains
multiple features describing the patient set, it may be difficult to differentiate between
features that contribute to the reference set and features that contribute to the target set.
For example:
Relevant subjects: patients with a clinical diagnosis of breast cancer and who had
anaemia after chemotherapy
Treatment: patients who received chemotherapy
Tests:[ ]
Outcome: percentage of patients who were alive after 5 years from the diagnosis
Options:
 Of the patients diagnosed with breast cancer who developed anaemia after
chemotherapy, what percentage survived 5 years after diagnosis?
 Of the patients in the database, what percentage were diagnosed with
breast cancer, developed anaemia after chemotherapy, and survived
5 years after diagnosis?
 Of the patients diagnosed with breast cancer, what percentage developed
anaemia after chemotherapy and survived 5 years after diagnosis?
Results. If the presented feedback text is incomprehensible, the probability that subjects
will select the correct interpretation will be 0.33 (i.e., they will get the right answer only
a third of the time). Our results show that subjects? precision is 0.84; that is, on average,
they select the intended interpretation 84% of the time, rather than 33% as would be predicted if
their selections were random. Statistical analysis of these results, using a one-sample t-test,
shows this effect to be highly significant (mean = 0.8361, d = 0.5028, t = 16.76, p < .0001).
The breakdown by type of ambiguity is shown in Table 1.
Table 1
Interpretation of feedback texts.
Ambiguity Total correct Percent
Type 1 51 85
Type 2 54 90
Type 3 50 83
Type 4 48 80
Type 5 47 78
Type 6 51 85
128
Hallett, Scott, and Power Composing Questions through Conceptual Authoring
6.3 Summarizing the Evaluation
The true test of any system comes with its use in situ by the users for which it was
designed. Normally, this would be preceded by a bank of formal empirical studies
under more controlled conditions. For a question-answering system like the one we are
addressing in this article (which is but a small part of a much larger system), a formal
controlled evaluation would ideally cover a large number of exemplars of each type of
query supported by the system, and a large number of subjects. Given our constraints
on the number of available subjects (and the concomitant effect this has on the possible
design of any experiments), the evaluation reported here is necessarily more limited in
scope. This is not an unusual situation in system development, where evaluation must
proceed by gradual refinement through the application of rigor, wherever possible,
but also applying along the way intuition, common sense, and past experience. The
evaluation we have presented here shows what can be done during the early phases
of the development of a large and complex system whose components are in different
stages of completion, and where access to representative users is limited.
Given these caveats, the picture that emerges from this study is nonetheless very
encouraging. Our results suggest that our target users (medical researchers) can quickly
learn to construct queries of the type and complexity that they have identified as
relevant. Specifically:
 They are able to use the Conceptual Authoring method successfully to
compose complex queries, with no prior exposure to the method and
with the benefit of only minimal training.
 They become quickly proficient with the system, achieving near perfect
performance by their fourth attempt at query composition.
The study also indicates that the feedback texts employed to construct queries of a
high degree of structural complexity are not difficult to understand. This is extremely
important, as it means that users can be confident that they are obtaining an answer
that pertains to the question that they think they are asking, as opposed to an answer to
some other similar question.
Additionally, in a separate, informal study, we have found suggestive evidence
that the Conceptual Authoring method of query composition may be much more
user-friendly than the traditional method of direct SQL editing, even for extremely
skilled SQL coders with a high level of familiarity with the database and the domain
(Hallett, Scott, and Power 2006). Our tests showed that (an albeit small sample of) such
experts, even in a situation that is heavily biased towards optimal performance of
SQL codes, found it much easier to compose queries with the Conceptual Authoring
interface than in SQL. Not only did it take them more than three times longer, on
average, to compose the query in SQL, but they were not able to produce the complete
SQL in that time.
7. Conclusion
Most question-answering systems make use of natural language understanding and
allow users to pose simple questions to textual repositories. We have presented
here a generic method for composing natural language questions within a question-
answering system that avoids the well-know pitfalls of natural language understanding
129
Computational Linguistics Volume 33, Number 1
while allowing users to pose complex questions to data repositories. The method,
Conceptual Authoring, involves no natural language interpretation?only generation?
and is particularly well-suited to query interfaces to closed-domain systems. We have
elucidated the method through its use in the CLEF query tool, which has been designed
to meet the requirements of a particular context: the querying of large repositories
of electronic health records by doctors and medical researchers. Similar requirements
almost certainly apply in other fields of expertise (e.g., engineering, genomics, law,
finance), as data are increasingly available in machine-usable electronic form; they can
be summarized as follows:
 Users: The query tool must be usable by the relevant domain
experts?doctors, lawyers, or whomever?with no training in database
query languages.
 Training: The users must be able to use the query tool after minimal
learning time (minutes rather than hours).
 Time: After training, users must be able to construct complex queries in
a time comparable to writing the query down on paper?that is, a few
minutes.
 Reliability: The query tool must be close to 100% reliable, in the sense that
any query correctly formed by the user will be correctly transcoded into
the database query language and therefore answered by the system.
 Transparency: Queries must be presented to users in a form that is clear
and unambiguous, so that they know exactly what question they have
asked.
Although not exactly a requirement, a practical consideration is that the queries should
be frequent and important enough to justify the effort needed to meet the very stringent
requirements on usability and transparency. There is no point investing in a natural
language interface like the CLEF query tool except in contexts where the query results
are highly valuable.
In our view, transparent communication with expert users depends first and
foremost on using a familiar medium?the medium the experts use in their
normal work, which in this case means natural language. However, as argued in
Section 2, traditional natural language interfaces to database systems cannot meet the
requirements on reliability and training, because reliable interpretation of an input
text can be achieved only if the text conforms strictly to a controlled language (which
our users would not have time to learn). We therefore proposed a modification of
the traditional approach, in which the semantic representation of the query is edited
directly, through an interactive feedback text generated by the system. Otherwise the
approaches are the same: once obtained, the semantic representation is transcoded to
the database query language and passed to the database management system; when
the answer is returned, it is organized to suit the purposes of users, and presented in a
familiar display such as a text or diagram.
Ultimately, the value of such a tool must be proved in everyday use, but our
evaluation study provides some evidence that our approach can meet the requirements.
First, our studies were performed with the relevant users, in this case medical experts.
The training required for reaching a reliable level of performance was a matter of
minutes?usually a single demonstration followed by a single trial. Thereafter, most
130
Hallett, Scott, and Power Composing Questions through Conceptual Authoring
users could formulate fairly complex queries in a reasonably short time (3?4 minutes); in
contrast, we have found in informal tests that expert SQL coders take at least three times
as long, while often failing to achieve a complete query (Hallett, Scott, and Power 2006).
The reliability achieved over 60 queries was 100%, in the sense that all users managed to
formulate all their targets. Finally, a further experiment showed that the formulations
of the queries in the feedback texts were transparent, with accuracy rates of 80?90% on a
multiple-choice comprehension task with a random baseline of 33%.
These evaluation results offer strong support for Conceptual Authoring as an
approach to this class of problems: we know of no alternative approach that can
achieve similar success in meeting these requirements. However, there are several areas
where improvement should be possible. First, we need to find ways of facilitating
the development process: building and maintaining a system like the CLEF query tool
requires, at present, the hand-coding of linguistic and conceptual resources; as a step in
this direction, we have developed a method of automatically inferring relevant types
of queries for any database, and automatically constructing resources that inform a
Conceptual Authoring interface (Hallett 2006). Second, we cannot be sure yet that the
wording of feedback texts is optimal?perhaps with more research the comprehension
rates can be pushed higher. Finally, we have only begun to explore the possibilities for
improving the GUI for Conceptual Authoring.
References
Allen, James. 1984. Towards a general theory
of action and time. Artificial Intelligence,
23(2):123?154.
Androutsopoulos, I. 1992. Interfacing a
natural language front end to a relational
database. Masters thesis, Department of
Artificial Intelligence, University of
Edinburgh.
Androutsopoulos, I., G. Ritchie, and P.
Thanitsch. 1993. An efficient and portable
natural language query interface for
relational databases. In Proceedings of the
6th International Conference on Industrial
Engineering Applications of Artificial
Intelligence and Expert Systems Edinburgh,
pages 327?330, Edinburgh.
Androutsopoulos, I., G. D. Ritchie, and
P. Thanisch. 1995. Natural language
interfaces to databases?an introduction.
Natural Language Engineering, 2(1):29?81.
Bell, J. E. and L. A. Rowe. 1992. An
exploratory study of ad hoc query
languages to databases. In Proceedings of
the 8th International Conference on Data
Engineering, pages 606?613, Tempe, AZ.
Bouayad-Agha, Nadjet, Richard Power,
Donia Scott, and Anja Belz. 2002.
PILLS: Multilingual generation of
medical information documents with
overlapping content. In Proceedings
of the Third International Conference on
Language Resources and Evaluation,
pages 2111?2114, Las Palmas, Spain.
Capindale, R. A. and R. G. Crawford. 1990.
Using a natural language interface with
casual users. International Journal of
Man?Machine Studies, 32(3):341?361.
Catarci, T. and G. Santucci. 1995. Are visual
query languages easier to use than
traditional ones? An experimental proof.
In Proceedings of the International Conference
on Human-Computer Interaction (HCI95).
College of American Pathologists, 2004.
SNOMED Clinical Terms User Guide.
July 2004 release.
Deshpande, A., C. Brandt, and P. Nadkarni.
2001. Ad hoc query of patient data:
Meeting the needs of clinical studies.
Journal of the American Medical Informatics
Association, 9(4):369?382.
Deshpande, A., C. Brandt, and P. Nadkarni.
2003. Temporal query of attribute-value
patient data: Utilizing the constraints of
clinical studies. International Journal of
Medical Informatics, 70:59?77.
Ely, John W., Jerome A. Osheroff, Paul N.
Gorman, Mark H. Ebell, M. Lee Chambliss,
Eric A. Pifer, and P. Zoe Stavri. 2000. A
taxonomy of generic clinical questions:
Classification study. British Medical Journal,
321:429?432.
Estrella, Florida, Chiara del Frate, Tamas
Hauer, Richard McClatchey, Mohammed
Odeh, Dmitry Rogulin, Salvator Roberto
Amendolia, David Schottlander,
Tony Solomonides, and Ruth Warren.
2004. Resolving clinicians queries
131
Computational Linguistics Volume 33, Number 1
across a grids infrastructure. In
Proceedings of the 2nd International
HealthGRID Conference.
Evans, Roger, Paul Piwek, Lynne Cahill, and
Neil Tipper. In press. Natural language
processing in CLIME, a multilingual legal
advisory system. Natural Language
Engineering.
Frank, Annette, Hans-Ulrich Krieger, Feiyu
Xu, Hans Uszkoreit, Berthold Crysmann,
Brigitte Jorg, and Ulrich Schafer. 2005.
Querying structured knowledge sources.
In AAAI-05 Workshop on Question
Answering in Restricted Domains, pages
10?19, Pittsburgh, Pennsylvania.
Gorman, P. N. and M. Helfand. 1995.
Information seeking in primary care:
How physicians choose which clinical
questions to pursue and which to leave
unanswered. Medical Decision Making,
(15):113?119.
Hafner, Carole D. and Kurt Godden. 1985.
Portability of syntax and semantics in
datalog. ACM Transactions on Information
Systems, 3(2):141?164.
Hallett, Catalina. 2006. Generic querying of
relational databases using natural
language generation techniques. In
Proceedings of the 4th International Natural
Language Generation Conference (INLG?06),
pages 95?102, Sydney, Australia.
Hallett, Catalina, Donia Scott, and Richard
Power. 2006. Evaluation of the CLEF
query interface. Technical Report 2006/01,
Centre for Research in Computing, The
Open University.
Hendrix, Gary G., Earl D. Sacerdoti, Daniel
Sagalowicz, and Jonathan Slocum. 1978.
Developing a natural language interface to
complex data. ACM Transactions on
Database Systems, 3(2):105?147.
Hovy, E. H., U. Hermjakob, and
D. Ravichandran. 2002. A question/
answer typology with surface text
patterns. In Proceedings of the DARPA
Human Language Technology Conference,
pages 247?250, San Diego, CA.
Jerome, R. N., N. B. Giuse, K. W. Gish,
N. A. Sathe, and M. S. Dietrich. 2001.
Information needs of clinical teams:
Analysis of questions received by the
clinical informatics consult service.
Bulletin of the Medical Library Association,
89(2):177?184.
Kalra, Dipak, Anthony Austin, A. O?Connor,
D. Patterson, David Lloyd, and David
Ingram. 2001. Design and Implementation
of a Federated Health Record Server,
pages 1?13. Medical Records Institute
for the Centre for Advancement of
Electronic Records Ltd.
Kaplan, S. Jerrold. 1984. Designing a portable
natural language database query system.
ACM Transactions on Database Systems,
9(1):1?19.
Kate, R. J., Y. W. Wong, and R. J. Mooney.
2005. Learning to transform natural to
formal languages. In Proceedings of the
Twentieth National Conference on Artificial
Intelligence (AAAI-05), pages 1062?1068,
Pittsburgh, PA.
Kim, Y. 1990. Effects of conceptual data
modelling formalisms on user validation and
analyst modelling of information requirements.
Ph.D. thesis, University of Minnesota.
Koonce, Taneya Y., Nunzia Bettinsoli Giuse,
and Pauline Todd. 2004. Evidence-based
databases versus primary medical
literature: An in-house investigation on
their optimal use. Bulletin of the Medical
Library Association, 92(4):407?411.
Lowden, B. G. T., B. R. Walls, A. De Roeck,
C. J. Fox, and R. Turner. 1991. A formal
approach to translating English into SQL.
In Proceedings of the 9th British National
Conference on Databases, pages 110?127,
Wolverhampton, UK.
Mueckstein, Eva-Martin. 1985. Controlled
natural language interfaces (extended
abstract): The best of three worlds. In CSC
?85: Proceedings of the 1985 ACM thirteenth
annual conference on Computer Science,
pages 176?178, New York, NY.
Nadkarni, P. and C. Brandt. 1998. Data
extraction and ad hoc query of an
entity-attribute-value database. Journal
of the American Medical Informatics
Association, 5(6):511?527.
Petre, Marian. 1995. Why looking isn?t
always seeing: Readership skills and
graphical programming. Communications
of the ACM, 38(6):33?44.
Piwek, Paul. 2002. Requirements definition,
validation, verification and evaluation
of the clime interface and language
processing technology. Technical Report
ITRI-02-03, ITRI, University of Brighton.
Piwek, Paul, Roger Evans, Lynne Cahill,
and Neil Tipper. 2000. Natural language
generation in the MILE system. In
Proceedings of the IMPACTS in NLG
Workshop, pages 33?42, Schloss Dagstuhl,
Germany.
Popescu, Ana-Maria, Oren Etzioni, and
Henry Kautz. 2003. Towards a theory
of natural language interfaces to
databases. In IUI ?03: Proceedings of
the 8th international conference on
132
Hallett, Scott, and Power Composing Questions through Conceptual Authoring
Intelligent user interfaces, pages 149?157,
New York, NY.
Power, Richard and Donia Scott. 1998.
Multilingual authoring using feedback
texts. In Proceedings of 17th International
Conference on Computational Linguistics
and 36th Annual Meeting of the
Association for Computational Linguistics
(COLING-ACL 98), pages 1053?1059,
Montreal, Canada.
Power, Richard, Donia Scott, and Roger
Evans. 1998. What you see is what you
meant: direct knowledge editing with
natural language feedback. In Proceedings
of the 13th Biennial European Conference on
Artificial Intelligence, pages 675?681,
Brighton, UK.
Rector, Alan, Jeremy Rogers, Adel Taweel,
David Ingram, Dipak Kalra, Jo Milan,
Robert Gaizauskas, Mark Hepple,
Donia Scott, and Richard Power. 2003.
CLEF?joining up healthcare with
clinical and post-genomic research. In
Second UK E-Science ?All Hands Meeting?,
Nottingham, UK.
Rivera, Carlos and Nick Cercone. 1998.
Hermes: Natural language access to a
medical database. Technical report
CS-98-03, University of Regina, Canada.
Scott, Donia, Richard Power, and Roger
Evans. 1998. Generation as a solution
to its own problem. In Proceedings
of the 9th International Workshop on
Natural Language Generation,
pages 256?265, Niagara-on-the-Lake,
Canada.
Shahar, Yuval and Cleve Cheng. 1999.
Intelligent visualization and exploration of
time-oriented clinical data. In Proceedings
of HICSS, pages 4019?4030, Maui, HI.
Soricut, R. and E. Brill. 2004. Automatic
question answering: Beyond the factoid.
In Proceedings of the HLT/NAACL 2004,
pages 57?64, Boston, MA.
Tang, Lappoon R. and Raymond J. Mooney.
2001. Using multiple clause constructors
in inductive logic programming
for semantic parsing. In EMCL ?01:
Proceedings of the 12th European Conference
on Machine Learning, pages 466?477,
London, UK.
Templeton, Marjorie and John Burger. 1983.
Problems in natural-language interface to
DBMs with examples from EUFID. In
Proceedings of the First Conference on Applied
Natural Language Processing, pages 3?16,
Morristown, NJ.
Tennant, Harry R., Kenneth M. Ross, and
Craig W. Thompson. 1983. Usable natural
language interfaces through menu-based
natural language understanding. In CHI
?83: Proceedings of the SIGCHI Conference
on Human Factors in Computing Systems,
pages 154?160, New York, NY.
TREC. 2005. Question answering data.
http://trec.nist.gov/data/qa/t2005
qadata.html.
Wilcox, Adam, George Hripcsak, and
Cynthia Chen. 1997. Creating an
environment for linking knowledge-based
systems to a clinical database: A suite of
tools. In Proceedings of AMIA Annual Fall
Symposium, pages 303?307, Nashville, TN.
Zhang, Guogen, Wesley W. Chu, Frank
Meng, and Gladys Kong. 1999. Query
formulation from high-level concepts
for relational databases. In UIDIS ?99:
Proceedings of the 1999 User Interfaces
to Data Intensive Systems, page 64,
Washington, DC.
133

Generating Numerical Approximations
Richard Power?
Open University
Sandra Williams??
Open University
We describe a computational model for planning phrases like ?more than a quarter? and ?25.9
per cent? which describe proportions at different levels of precision. The model lays out the key
choices in planning a numerical description, using formal definitions of mathematical form
(e.g., the distinction between fractions and percentages) and roundness adapted from earlier
studies. The task is modeled as a constraint satisfaction problem, with solutions subsequently
ranked by preferences (e.g., for roundness). Detailed constraints are based on a corpus of numer-
ical expressions collected in the NUMGEN project,1 and evaluated through empirical studies in
which subjects were asked to produce (or complete) numerical expressions in specified contexts.
1. Introduction
We describe in this article a computational model for planning phrases that express
proportions (e.g., ?more than a quarter? and ?25.9 percent,? among others, as alternative
descriptions of the proportion 0.259). This task is of interest for several reasons. First,
such expressions are very common in factual discourse?they will be found on almost
any page in a newspaper or scientific journal. Second, any numerical value can be
expressed in a variety of ways, differing along such dimensions as precision, formality,
and mathematical sophistication; generating the range of suitable phrases is therefore
non-trivial. Third, the matter has been largely ignored in the literature on Natural
Language Generation (NLG), even though many NLG systems are designed to produce
text from numerical data in domains like weather forecasting (Reiter et al 2005), stock
market trends,2 and medical records (Hallett, Scott, and Power 2007). Finally, and more
subtly, the task provides a convenient microcosm of the general pragmatic problem
of determining optimal information content?for instance, of balancing preferences for
precision and brevity (Krifka 2002).
The work reported here was carried out in the NUMGEN project, and exploits the
NUMGEN corpus of numerical expressions drawn from families of texts describing the
? Department of Computing, Open University, Milton Keynes MK7 6AA, UK.
E-mail: r.power@open.ac.uk.
?? Department of Computing, Open University, Milton Keynes MK7 6AA, UK.
E-mail: s.h.williams@open.ac.uk.
Submission received: 1 August 2009; revised submission received: 31 March 2011; accepted for publication:
25 May 2011.
1 NUMGEN: Generating intelligent descriptions of numerical quantities for people with different levels of
numeracy (http://mcs.open.ac.uk/sw6629/numgen). NUMGEN was funded by the Economic and Social
Research Council under Grant Ref. RES-000-22-2760.
2 http://www.ics.mq.edu.au/lt-gdemo/StockReporter/.
? 2012 Association for Computational Linguistics
Computational Linguistics Volume 38, Number 1
same facts. Because the same quantitative fact is mentioned within and across multiple
texts, the corpus provides many examples of linguistic expressions that describe exactly
the same quantity. For instance, the following excerpt from an article in the UK news-
paper The Daily Telegraph contains several expressions representing proportions, includ-
ing the two phrases given as examples in the opening sentence of this article (and shown
here in italics), both of which describe the proportion of A-level papers3 that received
the top grade (A) in 2008:
A-level results show record number of A grades
Record numbers of teenagers have received top A-levels grades. More than a quarter of
papers were marked A as results in the so-called gold standard examination reach a
new high.
The overall pass rate also rose beyond 97 per cent for the first time ? the 28th straight
increase ? fuelling claims that A-levels are now almost impossible to fail. [. . . ] Today?s
results for 300,000 students in England, Wales and Northern Ireland were expected to
trigger a scramble to get into university, with experts predicting a record rise in the
number of applicants going through the clearing system. Applications to university
have already increased by nine per cent this year.
According to figures released today by the Joint Council for Qualifications, 25.9 per cent
of A-level papers were awarded an A grade this summer, compared to 25.3 per cent
12 months earlier ? and just 12 per cent in 1990.
(Daily Telegraph, 14th August 2008)
The NUMGEN corpus contains 14 articles reporting this story, mostly from UK news-
papers; in total, it has nearly 100 articles covering ten stories. The numerical facts found
in the corpus include cardinalities (e.g., ?300,000 students?) and measures (?28 years?)
as well as proportions, but the project focused on proportions as a convenient subset.
Elsewhere we have shown that proportions tend to be expressed differently at dif-
ferent locations within a document (Williams and Power 2009). The phrases ?more than
a quarter? and ?25.9 percent? in the example extract provide a convenient illustration
of the nature of these differences. First, there is an obvious disparity in precision. Next,
the phrases differ in mathematical form (fraction vs. percentage); we have argued that this
distinction is conceptual as well as notational, because fractions are accessible to a wider
readership than percentages?as testified by the levels at which they are introduced
in the UK mathematics curriculum (Qualification and Curriculum Authority 1999).
Finally, one of the phrases contains not only a quantity (?a quarter?) but a modifier
(?more than?); such modifiers have been called hedges (Lakoff 1973; Crystal 1988), and
they serve (among other things) to indicate the arithmetical relationship between the
quantity that follows and the actual value (0.259 > 1/4). Our corpus study showed that
fractions and round numbers tend to occur in the opening of a document, whereas
subsequent references to the same fact are more likely to use precise percentages.
These differences in precision and formality raise two questions, one concerning
motivation (why do speakers/writers approximate?), the other concerning technique
(how do they approximate?). On the first point, various motives have been proposed.
Speakers might aim at conceptual simplicity (Krifka 2007)?for example, because round
numbers are easier to remember and calculate with; or they might wish for various rea-
sons to avoid commitment (van Deemter 2009). Also, as implied by Grice?s (1975) qual-
ity and quantity maxims, the benefits of precision need to be balanced against the costs;
this trade-off has been discussed within the framework of optimality theory (Dekker
3 The A-level examination is taken by British 18-year-olds in their final year of school; university places are
usually conditional on the grades obtained in this examination.
114
Power and Williams Generating Numerical Approximations
and van Rooy 2000; Krifka 2002; Blutner and Zeevat 2011). Little attention has been paid,
however, to the second question?regarding the technique of approximation?despite its
intrinsic interest and its practical importance in applications of NLG.
Our aim in this article is to explain formally how speakers/writers are able to
produce numerical expressions with varying degrees of precision and formality. We
propose a two-stage generation process, the first stage producing a language-neutral
semantic form such as > 1/4, the second stage realizing this semantic form in English
or some other natural language (e.g., ?over a quarter?, ?more than 1/4?). Our model
considers the first stage only, and aims to generate the set of alternative semantic
forms underlying acceptable numerical expressions. Choosing the most appropriate
alternative from this set would depend on the pragmatic context; here, for generality,
the model identifies a number of criteria (roundness, accuracy, etc.) but leaves open
how they should be weighted (or otherwise combined).4
The structure of the article is as follows. In the next section we review previ-
ous linguistic and philosophical work on numerical expressions and approximation.
Section 3 adapts some important insights from this literature to propose a new formal
model for planning the semantic forms of proportion expressions; we then describe
an implementation of this model in Section 4, followed by an empirical evaluation in
Section 5. Section 6 discusses the outcome of the evaluation, and concludes.
2. Previous Work
2.1 Linguistic Background
Mathematically, a proportion is the cardinality of a set divided by the cardinality of
a superset. If S is a set, its cardinality CS is defined as the number of elements that S
contains; thus if SS is a superset of S (meaning that every element in S is also in SS), then
CS/CSS is a proportion. From this it follows that a proportion must lie between 0.0 and
1.0, because it will have its minimum value when S is empty, and its maximum value
when S is identical to SS. Typically, S and SS can be identified by descriptions, with S
distinguished by an extra attribute. Thus in our A-level example, SS is the set of A-level
papers marked in 2008, and S is the subset of these papers that received an A grade. To
calculate the proportion 25.9%, somebody or something (probably a computer program)
must have counted the total number of papers, then counted those distinguished by an
A-grade, then divided the latter number by the former.
Syntactically, proportion expressions usually occur as pre-modifiers in noun
phrases, in constructions of the form P of Ns where N is a noun. Both mentions of the
A-grade proportion in our sample text fit this pattern:
More than a quarter of papers were marked A
25.9 per cent of A-level papers were awarded an A grade this summer
In general, such expressions comprise a numerical value, optionally preceded by a
hedge. It is important to note that the numerical value in the expression may differ from
the actual value of the proportion, just as a place can be described with reference to
a convenient (but different) landmark (e.g., ?beyond the church?). For this reason we
4 The program actually prints out solutions in order of accuracy, so that precise descriptions occur towards
the beginning and round ones towards the end.
115
Computational Linguistics Volume 38, Number 1
will introduce the term given value for the numerical value found in the quantifying
expression. To understand the expression, a reader must infer the relationship between
the given value (call it VG) and the actual value (VA). One important clue is provided by
the hedge; thus in ?more than a quarter? the hedge ?more than? indicates that VA > VG
where VG = 1/4. Another clue, it has been argued, is provided by the given value itself,
because round numbers are likely to be interpreted as approximations (Krifka 2002).
Thus in ?a quarter of papers were marked A? the given value is a simple fraction,
suggesting that VG has been selected by the writer as a round number conveniently
near VA, and that the relationship is accordingly VA ? VG.
The term hedge was introduced by Lakoff (1973) and subsequently applied to nu-
merical descriptions by Dubois (1987), who studied imprecision in oral scientific presen-
tations and listed some common numerical hedges (e.g., ?about?, ?almost?, ?nearly?,
?of the order of?, ?a little over?); Crystal (1988) added a few more. Because Crystal
applied the term to any expression indicating imprecision or uncertainty, he included
some terms like ?maybe?, ?usually?, ?probably?, which are not relevant here. However,
restricting the field to numerical hedges, all Dubois?s examples concern the relationship
between given value and actual value, and in particular VA ? VG. In the NUMGEN
corpus, the most common hedge was ?more than? (expressing VA > VG), followed by
?about? (VA ? VG), ?under? (VA < VG), ?almost?, and ?nearly?.5 In marking up the
corpus, the modifier ?exactly? was also counted as a hedge, even though its purpose
is to confirm rather than to disclaim a precise commitment, since in common with the
other hedges it indicates a relationship between a given and an actual value (VA = VG).
We have discussed informally the possible forms and meanings of hedges; what
of the given value itself? From preliminary analysis of the NUMGEN corpus, three
basic forms for proportion values were identified, and used subsequently for mark-up:
fractions, percentages, and ratios. Fractions almost invariably had simple denominators
(2, 3 or 4) and were expressed in words rather than digits (e.g., ?two-thirds? rather than
?2/3?). Percentages were by contrast expressed almost always in digits??25 percent?
(or ?25%?) rather than ?twenty-five percent?; the numerical part was often a decimal,
usually with just one digit after the point. Ratios were sometimes used as an alternative
to fractions (e.g., ?one in four students obtained an A grade?), but with more freedom in
choosing denominators, which were sometimes large or non-round numbers (?roughly
one in 17 Britons?); because they were relatively rare, they are not included in the model
presented here.6
Stepping back, one could ask whether these are merely distinctions in surface
form, because the underlying quantities are always expressible as rational numbers
(i.e., Num/Den where numerator Num and denominator Den are both integers). We
have several reasons for treating mathematical form as a deeper conceptual distinc-
tion, however.7 Firstly, as we will show later, fractions and percentages typically have
denominators from different sets?low integers for fractions, powers of ten and related
5 Note that the hedges ?almost? and ?nearly? do not mean the same as ?less than?, because they can
also be used when VA > VG (e.g., ?the temperature fell to nearly zero?). However, it has been pointed
out to us that they do not mean the same as ?about? (i.e., VA ? VG) either; rather, they imply that VA
approaches VG from a direction indicated by the context, which might be either from above or below
(e.g., ?fell?, ?rose?)?a more subtle relation that we have not attempted to cover in the present article.
6 Note that by ratio here we refer not to the abstract mathematical operator, but to linguistic realizations
like ?N in M?, ?N out of M?, ?N of any M?, where N and M are integers.
7 In terms of the standard NLG pipeline architecture (Reiter 1994), this would mean that mathematical
form is already decided in the phase of content determination, so that the distinction between fractions,
ratios, and percentages is an input to the subsequent phases (sentence planning, surface realization, etc.).
116
Power and Williams Generating Numerical Approximations
integers for percentages. They also represent distinguishable levels of numerical compe-
tence, as evidenced by the UK mathematics curriculum (Qualification and Curriculum
Authority 1999) in which percentages are introduced later than fractions and depend
conceptually upon them. Finally, judgments of roundness can only be made relative
to a given mathematical form: thus in fractions 1/3 is rounder than 3/10, whereas in
percentages 33.33% is less round than 30%. This means that any program planning to
describe a proportion VA by relating it to a round number VG will have to take account
of mathematical form in selecting VG.
2.2 Roundness
It is a matter of common observation that some numbers are perceived as rounder
than others, and hence more likely to be employed in approximations. You might
approximate 0.259 by saying ?about a quarter?, but you would never approximate 0.25
by saying ?about 25.9 percent.? But what exactly is meant by roundness? Linguists and
psychologists have approached this question in various ways.
In Hurford?s book The Linguistic Theory of Numerals (Hurford 1975), numbers are
distinguished according to the roles they can play in verbal numerals. A few privileged
numbers can serve as multiplicands: In English and most European numeral systems
these would include 100, 1000, 1000000, and also perhaps 10 if we take account of word
morphology (i.e., if we think of ?forty? as meaning 4 ? 10). An important (although less
exalted) set can be named by forming a product with one of the multiplicands (e.g.,
?twenty?, ?two hundred?). Finally, at the bottom of the heap, we find the numbers
typically named as the sum of a product and another (smaller) number: thus ?sixty
five? is the sum of 60 and 5, or ?three hundred sixty five? is 300 + 65.
An alternative three-tier classification has been proposed by Pollmann and Jansen
(1996), on the basis of empirical evidence including number frequencies, currency sys-
tems, and approximations of the form ?30 or 35 people.? At the top level of roundness
are ?favorite numbers,? defined thus:
In any numeration system in base N, there is a set of favourite numbers comprising
(a) any integer power of the base, and (b) half, double, and half of half of any integer
power of the base.
(Pollmann and Jansen 1996, page 225)
With a numerical system based on 10, this definition yields the set F(10) defined as
follows:
F(10) = { f |f = 10n ? K} where K is 1, 2, 1/2 or 1/4, and n is any integer.
Note that this definition allows n to take negative values, or zero; hence 0.05 is also
classified as a favorite number because it can be formed by f = 10?1 ? 1/2.
The special status of F(10) numbers is attested by currency systems: For instance,
in pounds sterling there are coins for ?0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1.0, and 2.0, as well
as notes for ?5, 10, 20, 50, 100, and so forth. In a survey of currencies from 84 countries
(Pollmann and Jansen 1996), only 13 out of about 1,000 coins/notes lay outside F(10)
(e.g., a three-dollar banknote in the Cook Islands). Frequency data also support the
principle: Using a corpus of Dutch newspaper articles, Jansen and Pollmann (2001)
found spikes (local maxima) in the frequency plot for numbers belonging to F(10) (thus
10 was more common than 9 or 11). From experiments on phrases like ?30 or 35 people,?
117
Computational Linguistics Volume 38, Number 1
they also arrived at a wider group of round numbers (termed ?sequences?), formed
by multiplying any favorite number F by a low integer M with values in the range
M = 1 . . . 20: This set would include for example 5, 10, 15, . . . 95, 100, which are multiples
M*F of the favorite number 5.
Another approach to roundness is to think of measurements as taken from scales
of different granularity, as suggested for example by Krifka (2007). A scale is defined
as a set of evenly spaced points, so that consecutive points are always separated by a
unit distance d?it is equivalent, in other words, to Pollmann and Jansen?s concept of
?sequence.? However, scales can be organized into systems of varying granularity, so
that for example in the metric system for measuring length we have meters, decimeters,
centimeters, millimeters, and so forth, with granularity increasing tenfold from each
scale to the next. Less obviously, we can think of the minutes in an hour as belonging
to the following four scales, in which the units are respectively one hour, half an hour, a
quarter of an hour, and five minutes (example from Krifka 2007):
0---------------------------------60----------------------...--120
0---------------30----------------60----------------90----...--120
0------15-------30-------45-------60-------75-------90----...--120
0-5-10-15-20-25-30-35-40-45-50-55-60-65-70-75-80-85-90-95-...--120
The roundness of a number, relative to a scale system, can then be equated with the
coarsest-grained scale to which it belongs (i.e., the earliest scale, if they are arranged
in order of increasing granularity). Thus in this scale system 45 is rounder than 40,
although in most systems (e.g., metric distance) 40 would be rounder than 45.
3. Formal Model for Proportions
We have reviewed some insights from the literature on hedging, mathematical form,
and roundness; we now aim to draw these together into a formal model that can be
implemented and evaluated.
The first crucial insight from linguistic work on hedging is that proportions (and
indeed other quantities) are expressed by relating them to another, typically different
quantity that we have called the given value VG, with the hedge (if present) indicating
the nature of this relationship. Thus in expressing the proportion 0.259 by ?over a
quarter,? we have an actual value VA (0.259), a given value VG (1/4), and a relationship
VA > VG. This leads to the idea that underlying any numerical expression there will
be some kind of arithmetical relationship between VA and VG. The task of producing
the expression can therefore be divided into two stages: (a) choosing an appropriate
semantic relationship such as VA > 1/4 or VA ? 26/100; (b) choosing an appropriate
linguistic realization of this relationship, such as ?over a quarter? or ?about 26 percent.?
The second crucial insight, from the work on favorite numbers and roundness, is
that given numbers can be conceptualized as points along scales, of varying granularity,
organized into systems. This is obvious in Krifka?s (2007) example of time measures,
and also for distance measures where we are familiar with different systems such as
imperial units (inches, feet, yards, etc.) and metric units (centimeters, meters), but it
can be applied also to representing proportions. Adopting the simplest and most direct
approach, we can measure proportions on scales that divide the interval from 0.0 to 1.0
into N equal segments, where N is an integer greater than 1. A scale system can then
be defined as a set of scales ordered by increasing granularity (and hence increasing
N). Thus if we denote a scale with N segments by SN, an example of a scale system
would be the set [S10,S100,S1000], for which the units correspond to 10%, 1%, and 0.1%.
118
Power and Williams Generating Numerical Approximations
To specify a given value VG we must choose (a) a system, (b) a scale from the system,
and (c) a point from the scale?the points on a scale SN being represented by integers
from 0 to N.
This formalization of the given value has the advantage of distinguishing not only
degrees of roundness, but also different mathematical forms, which can be equated with
scale systems. Thus the system including [S10,S100,S1000] corresponds to the mathemati-
cal form percentages, whereas simple fractions use instead a system with very low values
of N, including [S2,S3,S4]. Equating roundness with the N value of the scale, it follows
that simple fractions are rounder than percentages, and that within any scale system,
earlier scales are rounder than later ones. For instance, within the percentage system,
40% would be considered rounder than 45%, because it first appears on the S10 scale
whereas 45% first appears on S100.
Conceptualized in this way, the semantic form of a proportion expression is the
result of four choices, each from a finite domain of options.8
 Choose an arithmetical relation between VA and VG (e.g., from the
set {=,?,>,<}).
 Choose a scale system for expressing VG (e.g., either fractions or
percentages).
 Choose a scale from this system.
 Choose a point from this scale.
Thus to obtain the semantic form for ?over a quarter,? starting from VA = 0.259, we
would choose (1) the relation >, (2) the scale system [S2,S3,S4, . . .] (fractions), (3) the
scale S4, and (4) the point 1. Alternatively, to obtain the semantic form for ?about 26 per-
cent,? the choices would be (1) the relation ?, (2) the scale system [S10,S100,S1000, . . .]
(percentages), (3) the scale S100, and (4) the point 26.
3.1 Scale Systems
We have described the outline of a model for planning proportion expressions; to im-
plement this model in an actual generator, we need to make specific assumptions about
the scale systems to be employed. We have suggested earlier that there are two major
scale systems for proportions, corresponding to fractions and percentages, the former
based on very low values of N (e.g., [S2,S3,S4]), the latter based on powers of ten. As a
preliminary test of this idea, we have taken all VG values for fractions and percentages in
the NUMGEN corpus, and re-expressed them as rational numbers of the form Num/Den,
reduced to their minimal terms so that numerator Num and denominator Den have no
common factor, and counted the frequencies of all denominators.9 The results (Table 1)
show a clear difference in the two distributions, with fractions having denominators in
the range 2?4 (apart from a couple of outliers), and percentages spread more widely,
with peaks in powers of 10 or their multiples.
8 Note that in a constraint-based model these choices are not sequentially ordered, so we are not, for
instance, implying that the arithmetical relation should be chosen first.
9 Thus, for example, 50% would be expressed as 1/2, which is 50/100 reduced to minimal terms; similarly,
7.5% would be expressed as 3/40 after reducing 75/1000.
119
Computational Linguistics Volume 38, Number 1
Table 1
Denominators for fractions and percentages in NUMGEN corpus.
Frequencies
Denominator Fractions Percentages
1 0 13
2 33 16
3 29 0
4 18 11
5 0 12
10 0 24
14 2 0
20 0 13
25 0 35
40 0 4
50 0 21
100 0 54
Other 0 139
Total 82 324
These data support an initial calibration of the model with separate scale systems
for fractions and percentages, the system for fractions being simply [S2,S3,S4]. For
percentages, we need to decide (a) how far to extend the granularity (e.g., whether to
include S10000, S100000, etc.), and (b) which intermediate scales to include (e.g., whether
to include S20, which would cover percentages divisible by 5, such as 5% and 15%).
For practical convenience in presenting and testing the model, we have decided to limit
granularity to S1000, so that we cover, for instance, 25.9% but not 25.95%. Regarding
intermediate scales, Table 1 provides support for S20 but even stronger support for S25,
which would yield percentages like 16% divisible by 4 rather than 5. This result could
also be due to bias in our (fairly small) corpus, however; searching for phrases of the
form ?X percent? in the Google Labs Ngram Viewer10 showed a clear preponderance
of percentages divisible by 5 compared with neighbors divisible by 4 (Table 2). We
therefore begin by limiting the scale system for percentages to [S10,S20,S100,S1000]11?
that is, powers of ten up to 1,000 with a single intermediate scale for percentages
divisible by 5.
3.2 Imposing Constraints
Having specified two scale systems and a set of arithmetical relations (=,?,>,<), we
can generate a large (but finite) set of semantic forms, most of which will of course be
unsuitable for describing any particular input proportion such as 0.259. To narrow these
down, we need to impose constraints which can be separated into three categories: (1) Is
the description true? (2) Is the description competent? (3) Is the description appropriate,
given the context and the speaker?s goals?
10 The search was performed in July 2011 at http://ngrams.googlelabs.com/.
11 These initial settings of the scale systems are motivated by a trade-off between keeping the model simple
while covering the most likely solutions; they could and should be modified if, for example, a domain
has special requirements or conventions (such as the use of eighths in U.S. stock prices).
120
Power and Williams Generating Numerical Approximations
Table 2
Hits on Google Labs Ngram Viewer (millions) for percentages divisible by 5, and close neighbors
divisible by 4. The data were obtained by searching for bigrams such as ?15 percent? in the
Google English Books corpus for the years 1800?2000.
Divisible by 5 Divisible by 4
Percentages Frequencies Percentages Frequencies
15 2.1 16 0.7
25 2.4 24 0.5
35 1.3 36 0.4
45 0.9 44 0.4
55 0.6 56 0.3
65 0.7 64 0.2
75 1.5 76 0.2
85 1.0 84 0.2
95 1.2 96 0.2
Total 11.7 Total 3.1
To obtain a true description, the generator must obviously ensure that the relation-
ship asserted between VA and VG actually holds. Thus for VA = 0.259, the solution
VA > 26/100 (choosing the 26th point along the S100 scale from the percentage scale
system, with the relation >) should be rejected as untrue, because the actual value 0.259
is less than the given value 26/100, not greater.
Having overcome the hurdle of truth, a candidate solution can be checked for what
we have called ?competence.? By this we mean that a solution should be excluded if
another solution is superior in all contexts. Consider, for example, the solution VA < 4/10
(again for the input VA = 0.259), in which VG is represented by the fourth point along
the S10 percentage scale. As a method for approximating 0.259 we would argue that this
is incompetent, because using the same arithmetical relation < and the same scale S10,
a closer approximation could have been obtained by choosing the third point instead
of the fourth. Of course the generator could get even closer by choosing, for instance,
VA < 26/100, but VA < 3/10 has the potential benefit of using a rounder scale, so both
are competent.
Finally, from the set of true and competent solutions, the generator needs to select
the semantic form that is most appropriate pragmatically. Here many factors come into
play, some of which have been mentioned previously (e.g., technical sophistication of
the reader/hearer, ease of comprehension, utilities of different levels of precision, eval-
uation of the proportion as higher or lower than expected). We have not included such
factors in the model described and evaluated in this article, but it is worth commenting
briefly on how this could be done, through optimization methods typical of constraint-
based applications.
In broad terms, what is required is a function that associates a contextually based
cost with each solution, so that the set of true and competent solutions can be ranked
from most to least appropriate. Plausibly, this function would measure various features
of the solution, including mathematical difficulty, emphasis, roundness, and accuracy,
and combine them through a weighted sum, with weights reflecting the contextual
revelance of the features. Thus, for contexts in which readers lack mathematical so-
phistication, solutions using the percentage scale system should incur extra cost; if the
writer?s aim is to emphasize that the actual value is higher than expected, solutions
121
Computational Linguistics Volume 38, Number 1
using the arithmetical relation < should be penalized; where small differences in the
actual value have important practical consequences, accuracy should receive a higher
weighting than roundness; and so forth.
4. Implementation of the Generator
The input to the generator is a proportion, specified as a real number between 0.0
and 1.0 correct to three places of decimals; the output is a set of alternative semantic
forms describing the proportion, where each semantic form is constructed by making
four choices from finite domains: (1) a scale system, (2) a scale from this system, (3) a
point from this scale, and (4) an arithmetical relation. To implement a generator of this
kind, it is convenient to formulate the task as a constraint satisfaction problem, which is
characterized by the following components (van Hentenryck 1989):
 A set of variables V1. . .Vn
 For each variable Vi a finite domain Di of possible values
 A set of constraints on the values of the variables
A solution assigns to each variable Vi a specific value from its domain Di, while
respecting all constraints. In implementations using Constraint Logic Programming
(CLP), programs typically have a three-part structure: first, the domains of the variables
are initialized; secondly, constraints over the variables are imposed; finally, values for
the variables are chosen?a process sometimes called ?labeling.? The labeling stage
introduces backtracking points whenever a variable can take one of several values,
so that multiple solutions can be generated if desired (and if they exist). However,
by using the constraints before labeling in order to reduce the domains of the vari-
ables, CLP can achieve substantial efficiency gains over algorithms that rely on
generate-and-test, and has been used successfully for a variety of NLP tasks (Koller
and Niehren 2000).
4.1 Assigning Domains to Solution Variables
Any solution is defined by four variables which we will call System, Scale, Point, and Re-
lation. For two of these variables, domains can be assigned during initialization: System
must belong to {Fraction, Percentage} and Relation to {=,?,>,<}. For the other vari-
ables, the domain can be assigned only during the search phase, because it depends on
the values of other variables. For instance, the domain of Scale can be set to {S2,S3,S4}
as soon as System receives the value Fraction, or alternatively to {S10,S20,S100,S1000} if
System receives instead the value Percentage. Similarly, the domain of Point can be set
only when a value of Scale has been chosen?in general, if Scale has the value SN, Point
should have the domain 0. . .N.
4.2 Constraints
Having initialized the domains of the variables (where possible), the program next
applies five constraints which rule out solutions that are ill-formed (i.e., outside our
scale systems), untrue, or incompetent; for convenience these will be given names (see
122
Power and Williams Generating Numerical Approximations
subsequent list). The first two (Scale Domain, Point Domain) perform the conditional
domain assignments just described, thus ensuring that solutions lie on the scales that
we have prescribed. The third (Correct Description) is concerned with correctness, and
the final two (Minimal Distance, Extreme Point) with competence.
1. Scale Domain: The scale must belong to the selected scale system. For
instance, if System = Fraction, the domain of Scale is {S2,S3,S4}.
2. Point Domain: The point chosen as given value must belong to the
selected scale. For instance, if Scale is S4, the domain of Point is 0..4.
3. Correct Description: The relation must be adapted to the given value so
that the proportion is described correctly. For instance, if VA is 0.259 and
VG (i.e., Point/Scale) is 1/4, then Relation must be one of {?,>}.
4. Minimal Distance: For a given relation and scale, the point selected as
given value should be as close as possible to the actual value of the
proportion. For instance, if VA is 0.259, Relation is >, and Scale is S4, Point
must be 1, not 0.
5. Extreme Point: If extreme points (equivalent to 0.0 and 1.0) are used
as given values, the relation should not be either > or < (i.e., when
approximating one should avoid expressions like ?more than 0%?
and ?less than 100%?).
Whereas the first three constraints are straightforward and obviously necessary, Mini-
mal Distance and Extreme Point make more interesting claims that require discussion
and empirical testing.
4.2.1 Minimal Distance. The assumption here is that when making an approximation, the
generator should make the best possible use of the chosen scale, by considering only
points that are adjacent to the actual value.12 This means, for instance, that if VA = 0.259
and Scale = S10, the only points that should be considered are 2 and 3. Which of these is
chosen will depend on the relation: for ? it will be 3 (which is closer); for < and > the
choice will depend on correct description. Note that we have not excluded > 2 on the
grounds that < 3 is closer, because there might be pragmatic reasons for preferring one
relation to the other.13
4.2.2 Extreme Point. This constraint prohibits the use of the relations > and < in associa-
tion with given values at the extreme points of the scale (e.g., 0/10 and 10/10 if Scale =
10); such combinations are not found in the NUMGEN corpus and it is hard to imagine
contexts when they would be appropriate as approximations.14
12 Note that we are assuming that the purpose of the given value is to approximate the actual value. The
minimal distance constraint would not apply when the given value had a special practical significance:
For instance, in a country where a referendum was valid only with turnout exceeding 55%, a journalist
might report ?Turnout was more than 55%? when the actual value was 93%.
13 Intuitively, ?more than 20%? seems to emphasize how high the proportion is compared with what was
desired or expected, and ?less than 30%? how low.
14 One sometimes hears pronouncements like ?I will not accept less than 100% effort? (e.g., in a team talk),
but this seems more a rhetorical flourish than an attempt to approximate an actual value.
123
Computational Linguistics Volume 38, Number 1
4.3 Preferences
The constraints just described yield multiple solutions for any given input value; to
complete the model, we need to consider contextual reasons why speakers/writers
might prefer some solutions to others. Regarding for example the System variable,
we have already pointed out some reasons why writers might prefer fractions to per-
centages (or vice versa), including location within the document, and the educational
level of the reader. Similarly, with regard to Relation, considerations of emphasis might
favor > over < (or vice versa), as in the sentence ?More than a quarter of papers
were marked A. . . ? in our initial example, which focuses attention on how easy the
A-level examinations have become. For present purposes, nothing can be said about
these choices except that they depend on contextual features outside the scope of our
current model. However, regarding the choice of Scale, we can filter out some solutions
on the assumption that speakers/writers apply a trade-off between roundness and
accuracy. That is, we can show that however these two factors are weighted (provided
that they are not judged irrelevant or even undesirable), some solutions will be inferior
to others and can therefore be discarded. This is done by the following rule:
Roundness Preference
If two solutions have the same values for System and Relation, and different values for
Scale, then the solution with the larger Scale value should be discarded unless it has
higher accuracy.
A similar rule could be formulated for solutions along the same scale with different
accuracies, but in our implementation this case is already covered by the Minimal
Distance constraint.
One advantage of the Roundness Preference rule is that it avoids duplicate solutions
in which the values for Point/Scale are arithmetically equivalent, such as 5/10 and 10/20
(values for System and Relation being the same). According to Krifka?s Round Number
Round Interpretation principle, readers of a phrase like ?about 50%? will apply an
interpretation bias favoring coarse-grained representations (i.e., scales with a relatively
low N-value), and writers will take this bias into account. We can therefore prefer 5/10
to 10/20, 50/100, and any other equivalent given value with Scale exceeding 10, and
filter out these dispreferred duplicates.15
In our implementation, filtering through the Roundness Preference is applied after
labeling, because it relies on comparing each candidate solution with the other can-
didates. In general this kind of procedure can lead to computational inefficiency; in
planning descriptions of proportions, however, the number of candidates should not be
large enough for this to be a problem, given that most combinations will already have
been eliminated by the constraints applied before labeling.16
15 Note incidentally that this principle has empirical consequences, because different Scale values imply
different degrees of approximation. Thus if ?more than 50 percent? means ?> 5/10,? the implied range
of the proportion (applying the Minimal Distance Constraint) is from 50.1% to 59.9%, whereas if it
means ?> 10/20? the implied range is from 50.1% to 54.9%.
16 If efficiency became an issue, owing for instance to very complex scale systems, it could be increased by
using branch-and-bound search, which discards any solution (even if incomplete) as soon as its cost
exceeds the best alternative found so far, thus avoiding the need to generate all solutions before filtering.
Some simple efficiency tests using the Sicstus Prolog statistics operator showed that with our current scale
systems (two systems each with four scales), runtimes averaged over 100 trials were 3.5 milliseconds;
extending each system first to 8 then to 12 scales increased average runtimes to 6.0 and 11.9 milliseconds;
extending the number of systems first to three then four increased them to 5.5 and 11.4 milliseconds.
124
Power and Williams Generating Numerical Approximations
Table 3
Solutions generated for VA = 0.259.
System Point/Scale Relation Realization
Perc 259/1000 = exactly 25.9 percent
Perc 26/100 ? about 26 percent
Perc 26/100 < less than 26 percent
Frac 1/4 ? about a quarter
Frac 1/4 > more than a quarter
Perc 5/20 ? about 25 percent
Perc 5/20 > more than 25 percent
Perc 3/10 ? about 30 percent
Perc 3/10 < less than 30 percent
Frac 1/3 ? about a third
Frac 1/3 < less than a third
Frac 1/2 ? about a half
Frac 1/2 < less than a half
4.4 Example of Output
Table 3 gives a full listing of output for our original A-level example (VA = 0.259),
with solutions ordered by accuracy.17 For convenience, the table includes a possible
verbalization of each semantic form.
5. Evaluation
Overall, we would like the generator to satisfy two requirements: First, it should allow
all the good solutions; second, it should exclude the bad ones. This assumes (a) that
we can measure ?goodness,? and (b) that we can draw a line separating wheat from
chaff. Theoretically these are difficult tasks to achieve, because we are dealing with
dimensions of judgment that are continuous and partly subjective, but this should
not stop us from looking for practical evaluation criteria which can support rough
assessments and comparisons of different algorithms.
To evaluate a proposed linguistic solution, the two criteria in common use are the
judgments of native speakers, and frequency in a corpus. Using the former method, we
could ask people to judge whether the 13 plans proposed previously for describing 0.259
are all appropriate (to some context), and whether there are other acceptable solutions
that have been omitted. Using the latter method, we could collect from a corpus all
phrases describing a given proportion (say 0.259), identify the plans behind them, and
find out whether (i) the solutions actually found in the corpus are all generated by our
model, and (ii) solutions absent from the corpus are not generated.
We would argue, however, that the overall performance of the program is actually
not the most instructive aspect to evaluate. Any reasonably complex system is based
on a number of methods and assumptions, some of which might be correct and some
17 We have preferred to include some very inaccurate solutions such as ?about a half?, in order to cater
for all positions along the roundness/accuracy trade-off. For instance, ?half of the birds flew away?
seems acceptable in a context in which the exact proportion is unimportant, whereas the more accurate
?a quarter? or ?a third? might sound fussy.
125
Computational Linguistics Volume 38, Number 1
incorrect; separate evaluations of these components should provide more useful evi-
dence on how the model can be improved. We have therefore designed the empirical
study so that as well as assessing overall coverage and quality, it allows us to evaluate
the Minimal Distance and Extreme Point Constraints, the Roundness Preference, and
the suggested scale systems for fractions and percentages.
5.1 Method
The model was evaluated through two surveys in which participants were asked to
fill in gaps in sentences describing proportions, with reference to data from which the
actual value VA could be easily computed. The surveys were presented on-line using
SurveyMonkey18 through a link sent to two computational linguistics mailing lists
(SIGGEN and SIGDIAL). Survey 1, completed by 50 participants, tested the predictions
of the model concerning given (VG) values for percentages. Survey 2, completed by
62 participants,19 investigated given (VG) values for fractions, and their relationship to
the decision whether to use a fraction or a percentage; it also included four questions
testing the Extreme Point constraint. The content of all questions was adapted from
newspaper articles in the NUMGEN corpus. In detail, the composition of the surveys
was as follows:
A. Eight questions where subjects were asked to provide the given number
(VG) in a sentence that already contained a hedge, with reference to data
determining an actual value (VA). The context of the VG response was
varied systematically to cover the three approximation relations (?,<,>)
with actual values at different distances from a convenient round number.
[Survey 1]
B. Ten questions where subjects were asked to complete a sentence by
providing a fraction/percentage (possibly including a hedge). The data
were varied so that the actual value was sometimes close to a convenient
VG value from the fraction scale system [S2,S3,S4] (i.e., halves, thirds,
quarters), and sometimes close to VG values on other scales (e.g., fifths,
sixths, tenths). [Survey 2]
C. Four questions where subjects were asked to choose a hedge for a sentence
that already contained a given (VG) number, in each case either 0% or
100%. Their purpose was to test the Extreme Point constraint on the choice
of relation. [Survey 2]
Examples of each kind of question are shown in Figure 1. The instructions in both
surveys were as follows, with the italicized paragraph occurring only in Survey 2.
This survey will take about 5 minutes to complete. Its purpose is to investigate how
people choose numerical descriptions. It is not a test where answers are either right
or wrong.
18 http://www.surveymonkey.com/.
19 In fact, 65 people completed Survey 2, but three were eliminated, one for responding at random, and two
for giving responses that were not proportions. Our policy was to eliminate participants only when all
their responses were nonsensical, therefore as can be seen, a few obviously mistaken responses remain.
126
Power and Williams Generating Numerical Approximations
Figure 1
Snapshots of questions from the surveys, illustrating the three question types.
Imagine that you are the subeditor of a newspaper. You have been asked to
complete an article which has some gaps where data were not yet available to the
original author.
You are given the incomplete sentence, and the data which it should describe. Your
task is to choose a suitable expression to complete the sentence, leaving the rest of the
wording unchanged (even if you disagree with it).
Each expression should use either a fraction or a percentage, and may also include
modifying words like ?over?, ?about? (e.g., ?55 percent?, ?over a half?).
The data are fictional, but assume they are correct. We are interested in your choice
of numerical expression, not in the validity of the data.
Schematically, each question presented the raw data of a proportion in the form CS/CSS
(cardinality of set divided by cardinality of superset)?for instance, 712 out of 1,000 UK
teenagers?so that the actual value VA could be calculated. The values of CSS were chosen
so that this calculation would be relatively simple (1,000).20
The whole design is shown in Table 4, where the questions are numbered in order
of presentation, and the gaps to be filled by the subjects are shown by question marks.
In Survey 1, all participants viewed questions A1?A8 in the same order on separate
20 There is a possible bias here in that the denominator used in presenting the data (1,000) might lead
participants to favor scales that easily divide this number (e.g., 10 in preference to 3). Without a control
we cannot rule out this possibility, but the results for fractions, where 3 was actually the most common
denominator (46.8% of responses), show no evidence that non-decimal scales were handicapped.
127
Computational Linguistics Volume 38, Number 1
Table 4
Design of the surveys. Questions A1?A8 were presented in Survey 1, and questions B1?B10 and
C1?C4 in Survey 2. VA is the actual value, derived from data supplied in the question; VG is the
given value; the Relation holds between VA and VG. Responses required from subjects are
shown by ???.
Q VA Relation VG
A1 0.712 ? ?%
A2 0.437 > ?%
A3 0.625 ? ?%
A4 0.336 < ?%
A5 0.475 ? ?%
A6 0.561 < ?%
A7 0.286 ? ?%
A8 0.619 > ?%
B1 0.372 ? ?
B2 0.493 ? ?
B3 0.894 ? ?
B4 0.744 ? ?
B5 0.661 ? ?
B6 0.056 ? ?
B7 0.257 ? ?
B8 0.170 ? ?
B9 0.605 ? ?
B10 0.339 ? ?
C1 0.983 ? 100%
C2 0.028 ? 0%
C3 0.962 ? 100%
C4 0.021 ? 0%
pages.21 In Survey 2, similarly, questions B1?B10 were presented on separate pages,
followed by questions C1?C4 presented on a single page (see Figure 1).22
5.2 Results
Before presenting the results schematically, we will look in detail at the responses
actually typed for the question A1 (top of Figure 1). Subjects were asked to complete
the sentence About [. . . ] percent of UK teenagers under 16 have used sunbeds during the
last year given the data 712/1,000, equivalent to VA = 0.712. Reproduced as strings, the
following responses were received (some more than once):
70, 71, 71.2, 70%, seventy, 75, 20, 15, 2
As can be seen, the same answer was sometimes given in different forms (70, sev-
enty, 70%); in collating the results, these were all normalized to 70. Occasional bizarre
21 Questions A1?A8 were ordered so that Relation values varied from one question to the next and were
evenly distributed.
22 To check that there were no effects of question order, questions B1?B10 were presented to half the
subjects in one order, and to the other half in the reverse order. Because no differences were
apparent?the preferred response was the same for every question?the data were then amalgamated.
For questions C1?C4, the order was randomized.
128
Power and Williams Generating Numerical Approximations
Table 5
Results for questions A1?A8 (50 participants). VA is the actual value indicated by the question
data; R is the arithmetical relation implied by the hedge in the question text. Response
frequencies for VG (given value) are shown in parentheses, or unspecified if the response
occurred only once.
Q R VA Responses (frequencies)
A1 ? 0.712 70 (33), 71 (8), 71.2 (5), 75, 20, 15, 2
A2 > 0.437 40 (26), 43 (21), 30 (2), 45
A3 ? 0.625 60 (19), 62 (17), 63 (10), 62.5 (2), 30, 20
A4 < 0.336 35 (30), 34 (17), 50, 40, 1
A5 ? 0.475 50 (17), 48 (12), 47 (12), 45 (5), 47.5 (2), 46, 25
A6 < 0.561 60 (27), 57 (17), 56 (3), 55 (2), 30
A7 ? 0.286 30 (28), 29 (15), 28 (4), 25, 28.6, 1
A8 > 0.619 60 (38), 61 (9), 62 (2), 50
Table 6
Results for questions B1?B10 (62 participants). Questions marked with an asterisk were
predicted to favor fractions because their actual values are close to fractions from scales 2?4;
nearest fractions are shown in column F. Response frequencies are shown in parentheses, or
unspecified if the response occurred only once.
Q VA F Fraction responses Percentage responses
B1 0.372 3/8 1/3 (28) 37 (13), 40 (9), 37.2 (6), 33, 30, 38
B2* 0.493 1/2 1/2 (45) 50 (9), 49.3 (5), 49 (3)
B3 0.894 9/10 90 (46), 89.4 (5), 89 (4)
B4* 0.744 3/4 3/4 (28), 2/3 75 (17), 74.4 (5), 74 (4), 70 (2), 80
B5* 0.661 2/3 2/3 (34), 1/2 (4) 66 (13), 66.1 (5), 60 (2), 70
B6 0.056 1/20 1/2 5 (25), 5.6 (10), 6 (10), 56 (2), 10, 60, 1.2, 1
B7* 0.257 1/4 1/4 (34) 25 (15), 25.7 (6), 26 (5)
B8 0.170 1/6 1/6 (3), 1/5, 1/4 17 (48), 20 (6), 1.7 (2)
B9 0.605 3/5 1/2 (8), 2/3 (8) 60 (37), 60.5 (6), 61
B10* 0.339 1/3 1/3 (39) 34 (10), 33.9 (6), 30 (2), 35 (2), 40
responses (20, 15, 2) were not excluded. Collating in this way, and ordering by frequency,
the results for the first eight questions were as shown in Table 5.
For questions B1?B10, we were interested in whether subjects would choose a
fraction or a percentage, and whether fractions would conform to the proposed scale
system (favoring denominators in the range 2?4). Responses such as ?a quarter?, ?two
thirds?, ?1/4?, ?2/3?, were classified as fractions; responses like ?one out of four?, ?2
of every 3? were instead classified as ratios. For each actual value, a convenient fraction
was located within a distance of 0.01 on the proportion scale: for instance, 0.257 is just
0.007 above 1/4, and 0.372 just 0.003 below 3/8. Five of these fractions lay within the
proposed scale system (denominators 2?4) and five lay outside (denominators 5, 6, 8,
10, 20); questions in the former category are marked by an asterisk in Table 6.
For questions C1?C4, subjects had to choose from the four hedging options about,
less than, more than, and approximately.23 The purpose of these questions was to test the
23 The plausible option ?almost? was omitted because, as pointed out earlier, this denotes a subtler relation
of approaching the given value either from above or below. We hope in future work to extend the model
so that it includes this relation as well as the four treated here.
129
Computational Linguistics Volume 38, Number 1
Table 7
Results for questions C1?C4 (62 participants). Response frequencies are shown in parentheses.
For these questions, actual and given values (VA, VG) were specified in the question, and
participants were asked to choose the hedge?and thus, implicitly, the arithmetical relation.
Q VA VG Responses (frequencies)
C1 0.983 100% about (25), approximately (31), less than (6)
C2 0.028 0% about (30), approximately (19), more than (13)
C3 0.962 100% about (29) approximately (23), less than (10)
C4 0.021 0% about (28), approximately (27), more than (8)
Table 8
Predictions for questions A1?A8. Coverage reports the number of responses conforming to the
predictions. Quality reports the number of predicted solutions that were produced by at least
one subject.
Q R Actual Predictions Coverage Quality
A1 ? 0.712 70, 71 41 (82%) 2/2
A2 > 0.437 40, 43 47 (94%) 2/2
A3 ? 0.625 60, 62, 63 46 (92%) 3/3
A4 < 0.336 35, 34, 40 48 (96%) 3/3
A5 ? 0.475 50, 48, 47 41 (82%) 3/3
A6 < 0.561 60, 57 44 (88%) 2/2
A7 ? 0.286 30, 29 43 (86%) 2/2
A8 > 0.619 60, 61 47 (94%) 2/2
Extreme Point constraint?our hypothesis was that when constrained to use the extreme
points 0% or 100% as given values, people would avoid the relations< and>. Two other
hedges were employed so that on a random response the frequencies would be equally
divided, with half favoring either < or >. Results for these questions are presented in
Table 7, which shows that the hedges ?less than? and ?more than? (corresponding to <
and >) were strongly dispreferred for extreme given values.24
5.3 Analysis of Issues
5.3.1 Overall Performance. Comparing the solutions generated by the program with those
produced by human authors (including participants in our survey), we can ask (a) how
many solutions produced by humans were generated by the program, and (b) how
many solutions generated by the program were produced by humans?thus addressing
the competing criteria of coverage and quality. A model that generates many solutions
will increase coverage at the expense of quality, because it accepts some solutions that
competent authors would never produce.
Considering coverage first, the results predicted for questions A1?A8 are shown in
Table 8; comparing these with the actual results in Table 5, we observe that participants
chose one of the predicted given values in 357 out of 400 responses, giving an overall
24 Collating the results for VG = 100% we obtain the frequency distribution 54-54-16 for the three choices
?about,? ?approximately,? ?less than? (?2 = 23.3, df = 2, p < 0.00001). For VG = 0% the corresponding
distribution is 58-45-21 for the three choices ?about,? ?approximately,? ?more than? (?2 = 17.1, df = 2,
p < 0.0002).
130
Power and Williams Generating Numerical Approximations
coverage rate of about 90%. Turning to quality, the final column of Table 8 shows that
all of the predicted solutions occurred at least once in a sample of 50 responses, giving
a quality rate of 100%. This confirms that the fairly high coverage rate was not achieved
by the artifice of generating an overlarge set of predicted solutions.
For questions B1?B10 (Survey 2), considering only responses that were fractions or
percentages, we obtained 576/588 responses conforming to the predicted given values
(98% coverage), and 49 out of 76 predicted given values used at least once (64% quality).
Here the quality rate is lower because our model generates some very rough approxima-
tions using fractions (e.g., < 1/2 for actual values like 0.257 and 0.170)?responses that
would only occur in contexts where roundness overwhelmingly dominates precision.
5.3.2 Fraction and Percentage Scales. Responses to questions B1?B10 supported our as-
sumption that fractions are normally drawn from a scale system with denominators in
the range 2?4. This is shown (a) by the preponderance of fractions using these scales,
and (b) by the tendency of subjects to prefer percentages when the closest fraction used
another scale (e.g., fifths or tenths).
Out of 235 fraction responses overall, only 5 denominators were used, covering the
range 2?6, with frequencies as follows: halves 58 (24.7%), thirds 110 (46.8%), quarters
63 (26.8%), fifths 1 (0.4%), and sixths 3 (1.3%). Thus overall, 98.3% of fraction responses
used the proposed scales. Strikingly, none of the subjects chose three-fifths as a given
number for 0.605 (question B9), where the 16 fraction responses divided equally be-
tween half and two-thirds. Similarly, no subjects chose nine-tenths for VA = 0.894 (ques-
tion B3), for which the overwhelming preference was 90%, and there were no fraction
responses at all. The data thus supported a clear division into fraction and percentage
scale systems, with most subjects staying within a fraction system with scales limited to
the range 2?4.
Regarding the decision whether to use a fraction or a percentage, the actual values
were chosen so that five were close to convenient fractions in the range 2?4, and five
were not (see Table 6). For the former group, fractions outnumbered percentages by
185 to 114; for the latter group, percentages outnumbered fractions by 237 to 50?a
clear crossover (on a 2 ? 2 association test, ?2 = 120.5, df = 2, p < 0.00001). Another
way of showing this result is to correlate fraction frequencies with the distance between
the actual value and the nearest fraction with a denominator in the range 2?4: As this
difference increases, fraction frequencies decline, so that we obtain a strong negative
correlation (product-moment correlation r = ?0.9, df = 8, p < 0.01).
5.3.3 Minimal Distance. The Minimal Distance constraint relates the choice of the given
value VG to the choices made for the relation and the scale. It states that VG should
be chosen from the scale so as to minimize the distance from the actual value VA,
while obtaining a true description. Applied for example to question A1, for which the
relation is ? and VA = 0.712, the only point along the S10 scale satisfying the constraint
will be VG = 7/10, yielding a distance from VA of 0.012 (compared with a distance
of 0.088 when VG = 8/10, the nearest rival). For the other scales, the nearest points
are respectively, 14/20, 71/100, and 712/1,000, with the result that there are only two
predicted VG values, 7/10 and 71/100 (realized as 70% and 71%): 14/20 is a duplicate
of 7/10 removed by the Roundness Preference, and 712/1,000 is inconsistent with the
relation ? because it is exactly equal to VA.
Excluding non-serious responses such as ?about 15 percent? as an approximation
of 0.712, we can find in Table 5 (questions A1?A8) only seven violations of minimal
distance (2%), compared with 357 responses respecting the constraint (98%). The only
131
Computational Linguistics Volume 38, Number 1
violation that occurred more than once was ?about 28 percent? as an approximation
of 0.286. For questions B1?B10 we counted only five violations (1%) compared with
583 respecting the constraint (99%). Four of these violations were obvious arithmetical
mistakes (e.g., 56% as a realization of 0.056); the other was the response 33% as an
approximation for 0.372, suggesting an attempt to realize the underlying form 1/3 as
a percentage.25
5.3.4 Extreme Point. The Extreme Point constraint states that the relations < and > will
be avoided with given values at the extremes of the scale (VG = 0%, 100%). To test this
claim, the survey contained four questions (C1?C4) in which subjects had to choose a
hedge to accompany an extreme value of VG. For instance in question C1, with VA =
0.983, the sentence presented was A survey has found that [. . . ] 100 percent of people believe
they are smarter than average, and subjects had to choose from the hedges about, less than,
more than, approximately in order to fill the gap. The arithmetically correct answers to
this question are < 100 (represented by ?less than?) and ? 100 (represented by ?about?
and ?approximately?); most subjects, however, respected the Extreme Point constraint
by opting for the latter, with only 6/62 choosing ?less than.? Overall, 211/248 responses
to questions C1?C4 respected the constraint (85%), with 37 violations (15%).
5.3.5 Roundness Preference. Two questions in Survey 1 were included specifically to test
the Roundness Preference; both employed the relation ? in combination with an actual
value exactly midway between two round numbers, one on the scale S10 and the other
on the scale S20. The prediction was that subjects would favor the VG value taken from
the coarser-grained scale (S10). Results were as follows:
 For question A3 (?, VA = 0.625), 19 subjects chose ?about 60 percent? and
no subjects chose ?about 65 percent.?
 For question A5 (?, VA = 0.475), 17 subjects chose ?about 50 percent? and
5 chose ?about 45 percent.?
The overall count was therefore 36 to 5 in favor of the Roundness Preference (p <
0.00001, binomial test), but there was at least a hint of some other factor intruding, with
over 10% of responses going the other way.
6. Conclusion
We have proposed and tested a theoretical model for planning expressions that describe
proportions, with varying degrees of formality and precision. Our central idea is that
such expressions describe an arithmetical relationship between an actual value VA and
a given value VG, where the relation belongs to the set {=,?,>,<} and the given
value is a point from a scale belonging to a scale system. We use the concept of scale
system in order to distinguish the two commonest mathematical forms for representing
proportions?fractions and percentages. In everyday usage, fractions are conceptually
25 The use of 33% as an approximation suggests an alternative way of setting up the model using a single
scale system [S2,S3,S4,S10,S20,S100,S1000], and treating the choice between fraction and percentage
as a subsequent step influenced but not determined by the scale value. This approach receives some
support from the peaks in Table 2 for 25% and 75%, which would correspond to points along the S4 scale.
However, overall we obtained 67 responses of 1/3 as a fraction compared with only one as a percentage,
confirming a strong association of the scales [S2,S3,S4] with a particular mathematical form.
132
Power and Williams Generating Numerical Approximations
simpler because they have low-valued scales (usually in the region 2?4), whereas per-
centages use higher-valued scales based on powers of ten; both scales, however, could
be extended to finer granularities, for instance, to meet the requirements of specialized
domains. Scales for proportions are characterized by their SN numbers: lower SN values
represent coarser granularities and are associated intuitively with rounder given values.
The model provides a convenient formalization of the notions of mathematical form and
roundness, and a framework for investigating the detailed structure of scale systems
and the constraints and preferences that inform the planning process.
In evaluating the model, we found that most given values produced by partici-
pants in our survey were predicted by the model, with an overall coverage over 90%;
quality was also high (i.e., most generated solutions were employed at least once by
participants). These results support our assumptions about the composition of the scale
systems for fractions ([S2, S3, S4]) and percentages ([S10, S20, S100, S1000, . . . ]), which
determine the range of generated given values. Regarding the other assumptions of
the model, we found overwhelming evidence for a Minimal Distance constraint, which
requires speakers/writers to choose (for a specified scale and relation) the nearest point
to the actual value that yields a true description, and strong evidence for an Extreme
Point constraint, which disallows approximations in which the relations> or< are used
in combination with extreme points of a scale (e.g., with the percentages 0% or 100%).
We also found clear evidence for a Roundness Preference which, all other things being
equal, favors solutions using coarser-grained scales within the selected system.
We hope that with some calibration of the details, our model can provide a reliable
set of plans for describing any proportion, although when incorporated into an NLG
application it would obviously have to be complemented by a module for selecting
the best solution for a given pragmatic context. Despite not covering this problem
in the model, we have given examples of how pragmatic considerations might affect
each component of a solution (scale system, given value, arithmetical relation), thus
providing a framework for investigating such questions systematically.
Acknowledgments
NUMGEN was funded by the Economic
and Social Research Council under Grant
Ref. RES-000-22-2760. We are grateful to
our colleagues and reviewers for helpful
comments and suggestions.
References
Blutner, Reinhard and Henk Zeevat. 2004.
Optimality Theory and Pragmatics. Palgrave
MacMillan, Houndmills, Basingstoke,
Hampshire. Mouton de Gruyter, Berlin.
Crystal, David. 1988. On keeping one?s
hedges in order. English Today, 15:46?47.
Dekker, P. and R. van Rooy. 2000.
Bi-directional optimality theory: An
application of game theory. Journal of
Semantics, 17:217?242.
Dubois, B. L. 1987. Something of the order
of around forty to forty-four. Language
in Society, 16(4):527?541.
Grice, H. P. 1975. Logic and conversation.
In P. Cole and J. L. Morgan, editors, Syntax
and Semantics: Vol. 3: Speech Acts. Academic
Press, San Diego, CA, pages 41?58.
Hallett, Catalina, Donia Scott, and Richard
Power. 2007. Composing queries through
conceptual authoring. Computational
Linguistics, 33(1):105?133.
Hurford, J. R. 1975. The Linguistic Theory of
Numerals. Cambridge University Press,
Cambridge.
Jansen, C. J. M. and M. M. W. Pollmann.
2001. On round numbers: Pragmatic
aspects of numerical expressions. Journal
of Quantitative Linguistics, 8(3):187?201.
Koller, Alexander and Joachim Niehren.
2000. Constraint programming in
computational linguistics. In Proceedings
of 8th CSLI Workshop on Logic, Language
and Communication, pages 95?122, Stanford
University.
Krifka, Manfred. 2002. Be brief and vague!
and how bidirectional optimality theory
allows for verbosity and precision. In
133
Computational Linguistics Volume 38, Number 1
D. Restle and D. Zaefferer, editors,
Sounds and Systems: Studies in Structure
and Change: A Festschrift for Theo
Vennemann (Trends in Linguistics 141).
Mouton de Gruyter, Berlin, pages 439?458.
Krifka, Manfred. 2007. Approximate
interpretation of number words:
A case for strategic communication.
In G. Bouma, I. Kra?mer, and J. Zwarts,
editors, Cognitive Foundations of
Interpretation. Koninklijke Nederlandse
Akademie van Wetenschapen,
Amsterdam, pages 111?126.
Lakoff, George. 1973. Hedges: A study in
meaning criteria and the logic of fuzzy
concepts. Journal of Philosophical Logic,
2(4):458?508.
Pollmann, M. M. W. and C. J. M. Jansen.
1996. The language user as an
arithmetician. Cognition, 59:219?237.
Qualification and Curriculum Authority.
1999. Mathematics: the National
Curriculum for England. Department for
Education and Employment, London.
Reiter, Ehud. 1994. Has a consensus NL
architecture appeared, and is it
psychologically plausible? In Proceedings
of the 7th International Workshop on Natural
Language Generation, pages 163?170,
Kennebunkport, ME.
Reiter, Ehud, Somayajulu Sripada, Jim
Hunter, Jin Yu, and Ian Davy. 2005.
Choosing words in computer-generated
weather forecasts. Artificial Intelligence,
167(1-2):137?169.
van Deemter, Kees. 2009. What game
theory can do for NLG: the case of
vague language. In Proceedings of the
12th European Workshop on Natural
Language Generation, pages 154?161,
Athens.
van Hentenryck, P. 1989. Constraint
Satisfaction in Logic Programming.
MIT Press, Cambridge, MA.
Williams, Sandra and Richard Power.
2009. Precision and mathematical form
in first and subsequent mentions of
numerical facts and their relation to
document structure. In Proceedings of
the 12th European Workshop on Natural
Language Generation, pages 118?121,
Athens.
134
Proceedings of the ACL 2010 Conference Short Papers, pages 132?136,
Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational Linguistics
Complexity assumptions in ontology verbalisation
Richard Power
Department of Computing
Open University, UK
r.power@open.ac.uk
Abstract
We describe the strategy currently pur-
sued for verbalising OWL ontologies by
sentences in Controlled Natural Language
(i.e., combining generic rules for realising
logical patterns with ontology-specific lex-
icons for realising atomic terms for indi-
viduals, classes, and properties) and argue
that its success depends on assumptions
about the complexity of terms and axioms
in the ontology. We then show, through
analysis of a corpus of ontologies, that al-
though these assumptions could in princi-
ple be violated, they are overwhelmingly
respected in practice by ontology develop-
ers.
1 Introduction
Since OWL (Web Ontology Language) was
adopted as a standard in 2004, researchers have
sought ways of mediating between the (decidedly
cumbersome) raw code and the human users who
aspire to view or edit it. Among the solutions
that have been proposed are more readable coding
formats such as Manchester OWL Syntax (Hor-
ridge et al, 2006), and graphical interfaces such
as Prote?ge? (Knublauch et al, 2004); more specula-
tively, several research groups have explored ways
of mapping between OWL and controlled English,
with the aim of presenting ontologies (both for
viewing and editing) in natural language (Schwit-
ter and Tilbrook, 2004; Sun and Mellish, 2006;
Kaljurand and Fuchs, 2007; Hart et al, 2008). In
this paper we uncover and test some assumptions
on which this latter approach is based.
Historically, ontology verbalisation evolved
from a more general tradition (predating OWL
and the Semantic Web) that aimed to support
knowledge formation by automatic interpretation
of texts authored in Controlled Natural Languages
(Fuchs and Schwitter, 1995). The idea is to es-
tablish a mapping from a formal language to a
natural subset of English, so that any sentence
conforming to the Controlled Natural Language
(CNL) can be assigned a single interpretation in
the formal language ? and conversely, any well-
formed statement in the formal language can be
realised in the CNL. With the advent of OWL,
some of these CNLs were rapidly adapted to the
new opportunity: part of Attempto Controlled En-
glish (ACE) was mapped to OWL (Kaljurand and
Fuchs, 2007), and Processable English (PENG)
evolved to Sydney OWL Syntax (SOS) (Cregan et
al., 2007). In addition, new CNLs were developed
specifically for editing OWL ontologies, such as
Rabbit (Hart et al, 2008) and Controlled Lan-
guage for Ontology Editing (CLOnE) (Funk et al,
2007).
In detail, these CNLs display some variations:
thus an inclusion relationship between the classes
Admiral and Sailor would be expressed by the
pattern ?Admirals are a type of sailor? in CLOnE,
?Every admiral is a kind of sailor? in Rabbit, and
?Every admiral is a sailor? in ACE and SOS. How-
ever, at the level of general strategy, all the CNLs
rely on the same set of assumptions concerning the
mapping from natural to formal language; for con-
venience we will refer to these assumptions as the
consensus model. In brief, the consensus model
assumes that when an ontology is verbalised in
natural language, axioms are expressed by sen-
tences, and atomic terms are expressed by en-
tries from the lexicon. Such a model may fail in
two ways: (1) an ontology might contain axioms
that cannot be described transparently by a sen-
tence (for instance, because they contain complex
Boolean expressions that lead to structural ambi-
guity); (2) it might contain atomic terms for which
no suitable lexical entry can be found. In the re-
mainder of this paper we first describe the consen-
sus model in more detail, then show that although
132
Logic OWL
C uD IntersectionOf(C D)
?P.C SomeValuesFrom(P C)
C v D SubClassOf(C D)
a ? C ClassAssertion(C a)
[a, b] ? P PropertyAssertion(P a b)
Table 1: Common OWL expressions
in principle it is vulnerable to both the problems
just mentioned, in practice these problems almost
never arise.
2 Consensus model
Atomic terms in OWL (or any other language im-
plementing description logic) are principally of
three kinds, denoting either individuals, classes
or properties1. Individuals denote entities in the
domain, such as Horatio Nelson or the Battle of
Trafalgar; classes denote sets of entities, such as
people or battles; and properties denote relations
between individuals, such as the relation victor of
between a person and a battle.
From these basic terms, a wide range of com-
plex expressions may be constructed for classes,
properties and axioms, of which some common
examples are shown in table 1. The upper part of
the table presents two class constructors (C and
D denote any classes; P denotes any property);
by combining them we could build the following
expression denoting the class of persons that com-
mand fleets2:
Person u ? CommanderOf.F leet
The lower half of the table presents three axiom
patterns for making statements about classes and
individuals (a, b denote individuals); examples of
their usage are as follows:
1. Admiral v ? CommanderOf.F leet
2. Nelson ? Admiral
3. [Nelson, Trafalgar] ? VictorOf
Note that since class expressions contain classes
as constituents, they can become indefinitely com-
plex. For instance, given the intersection A u B
1If data properties are used, there will also be terms for
data types and literals (e.g., numbers and strings), but for sim-
plicity these are not considered here.
2In description logic notation, the constructor C u D
forms the intersection of two classes and corresponds to
Boolean conjunction, while the existential restriction ?P.C
forms the class of individuals having the relation P to
one or more members of class C. Thus Person u ?
CommanderOf.F leet denotes the set of individuals x such
that x is a person and x commands one or more fleets.
we could replace atomic class A by a constructed
class, thus obtaining perhaps (A1 u A2) u B, and
so on ad infinitum. Moreover, since most axiom
patterns contain classes as constituents, they too
can become indefinitely complex.
This sketch of knowledge representation in
OWL illustrates the central distinction be-
tween logical functors (e.g., IntersectionOf,
SubClassOf), which belong to the W3C standard
(Motik et al, 2010), and atomic terms for in-
dividuals, classes and properties (e.g., Nelson,
Admiral, VictorOf). Perhaps the fundamental de-
sign decision of the Semantic Web is that all do-
main terms remain unstandardised, leaving ontol-
ogy developers free to conceptualise the domain
in any way they see fit. In the consensus verbali-
sation model, this distinction is reflected by divid-
ing linguistic resources into a generic grammar for
realising logical patterns, and an ontology-specific
lexicon for realising atomic terms.
Consider for instance C v D, the axiom pat-
tern for class inclusion. This purely logical pattern
can often be mapped (following ACE and SOS) to
the sentence pattern ?Every [C] is a [D]?, where C
and D will be realised by count nouns from the
lexicon if they are atomic, or further grammatical
rules if they are complex. The more specific pat-
tern C v ?P.D can be expressed better by a sen-
tence pattern based on a verb frame (?Every [C]
[P]s a [D]?). All these mappings depend entirely
on the OWL logical functors, and will work with
any lexicalisation of atomic terms that respects the
syntactic constraints of the grammar, to yield ver-
balisations such as the following (for axioms 1-3
above):
1. Every admiral commands a fleet.
2. Nelson is an admiral.
3. Nelson is the victor of Trafalgar.
The CNLs we have cited are more sophisticated
than this, allowing a wider range of linguistic pat-
terns (e.g., adjectives for classes), but the basic
assumptions are the same. The model provides
satisfactory verbalisations for the simple examples
considered so far, but what happens when the ax-
ioms and atomic terms become more complex?
3 Complex terms and axioms
The distribution of content among axioms depends
to some extent on stylistic decisions by ontol-
ogy developers, in particular with regard to ax-
133
iom size. This freedom is possible because de-
scription logics (including OWL) allow equiva-
lent formulations using a large number of short
axioms at one extreme, and a small number of
long ones at the other. For many logical patterns,
rules can be stated for amalgamating or splitting
axioms while leaving overall content unchanged
(thus ensuring that exactly the same inferences are
drawn by a reasoning engine); such rules are often
used in reasoning algorithms. For instance, any set
of SubClassOf axioms can be amalgamated into
a single ?metaconstraint? (Horrocks, 1997) of the
form > v M , where > is the class containing
all individuals in the domain, and M is a class
to which any individual respecting the axiom set
must belong3. Applying this transformation even
to only two axioms (verbalised by 1 and 2 below)
will yield an outcome (verbalised by 3) that strains
human comprehension:
1. Every admiral is a sailor.
2. Every admiral commands a fleet.
3. Everything is (a) either a non-admiral or a sailor, and
(b) either a non-admiral or something that commands a
fleet.
An example of axiom-splitting rules is found in
a computational complexity proof for the descrip-
tion logic EL+ (Baader et al, 2005), which re-
quires class inclusion axioms to be rewritten to a
maximally simple ?normal form? permitting only
four patterns: A1 v A2, A1 u A2 v A3, A1 v
?P.A2, and ?P.A1 v A2, where P and all AN
are atomic terms. However, this simplification of
axiom structure can be achieved only by introduc-
ing new atomic terms. For example, to simplify
an axiom of the form A1 v ?P.(A2 u A3), the
rewriting rules must introduce a new term A23 ?
A2 uA3, through which the axiom may be rewrit-
ten as A1 v ?P.A23 (along with some further ax-
ioms expressing the definition of A23); depending
on the expressions that they replace, the content of
such terms may become indefinitely complex.
A trade-off therefore results. We can often find
rules for refactoring an overcomplex axiom by a
number of simpler ones, but only at the cost of in-
troducing atomic terms for which no satisfactory
lexical realisation may exist. In principle, there-
fore, there is no guarantee that OWL ontologies
3For an axiom set C1 v D1, C2 v D2 . . ., M will be
(?C1 unionsq D1) u (?C2 unionsq D2) . . ., where the class construc-
tors ?C (complement of C) and C unionsqD (union of C and D)
correspond to Boolean negation and disjunction.
Figure 1: Identifier content
can be verbalised transparently within the assump-
tions of the consensus model.
4 Empirical studies of usage
We have shown that OWL syntax will permit
atomic terms that cannot be lexicalised, and ax-
ioms that cannot be expressed clearly in a sen-
tence. However, it remains possible that in prac-
tice, ontology developers use OWL in a con-
strained manner that favours verbalisation by the
consensus model. This could happen either be-
cause the relevant constraints are psychologically
intuitive to developers, or because they are some-
how built into the editing tools that they use
(e.g., Prote?ge?). To investigate this possibility,
we have carried out an exploratory study using a
corpus of 48 ontologies mostly downloaded from
the University of Manchester TONES repository
(TONES, 2010). The corpus covers ontologies of
varying expressivity and subject-matter, including
some well-known tutorial examples (pets, pizzas)
and topics of general interest (photography, travel,
heraldry, wine), as well as some highly technical
scientific material (mosquito anatomy, worm on-
togeny, periodic table). Overall, our sample con-
tains around 45,000 axioms and 25,000 atomic
terms.
Our first analysis concerns identifier length,
which we measure simply by counting the num-
ber of words in the identifying phrase. The pro-
gram recovers the phrase by the following steps:
(1) read an identifier (or label if one is provided4);
(2) strip off the namespace prefix; (3) segment the
resulting string into words. For the third step we
4Some ontology developers use ?non-semantic? identifiers
such as #000123, in which case the meaning of the identifier
is indicated in an annotation assertion linking the identifier to
a label.
134
Pattern Frequency Percentage
CA v CA 18961 42.3%
CA u CA v ? 8225 18.3%
CA v ?PA.CA 6211 13.9%
[I, I] ? PA 4383 9.8%
[I, L] ? DA 1851 4.1%
I ? CA 1786 4.0%
CA ? CA u ?PA.CA 500 1.1%
Other 2869 6.4%
Total 44786 100%
Table 2: Axiom pattern frequencies
assume that word boundaries are marked either
by underline characters or by capital letters (e.g.,
battle of trafalgar, BattleOfTrafalgar), a
rule that holds (in our corpus) almost without ex-
ception. The analysis (figure 1) reveals that phrase
lengths are typically between one and four words
(this was true of over 95% of individuals, over
90% of classes, and over 98% of properties), as
in the following random selections:
Individuals: beaujolais region, beringer, blue
mountains, bondi beach
Classes: abi graph plot, amps block format, abat-
toir, abbey church
Properties: has activity, has address, has amino
acid, has aunt in law
Our second analysis concerns axiom patterns,
which we obtain by replacing all atomic terms
with a symbol meaning either individual, class,
property, datatype or literal. Thus for example the
axioms Admiral v Sailor and Dog v Animal
are both reduced to the form CA v CA, where
the symbol CA means ?any atomic class term?. In
this way we can count the frequencies of all the
logical patterns in the corpus, abstracting from the
domain-specific identifier names. The results (ta-
ble 2) show an overwhelming focus on a small
number of simple logical patterns5. Concern-
ing class constructors, the most common by far
were intersection (C u C) and existential restric-
tion (?P.C); universal restriction (?P.C) was rel-
atively rare, so that for example the pattern CA v
?PA.CA occurred only 54 times (0.1%)6.
5Most of these patterns have been explained already; the
others are disjoint classes (CAuCA v ?), equivalent classes
(CA ? CA u ?PA.CA) and data property assertion ([I, L] ?
DA). In the latter pattern, DA denotes a data property, which
differs from an object property (PA) in that it ranges over
literals (L) rather than individuals (I).
6If C v ?P.D means ?Every admiral commands a fleet?,
C v ?P.D will mean ?Every admiral commands only fleets?
(this will remain true if some admirals do not command any-
thing at all).
The preference for simple patterns was con-
firmed by an analysis of argument struc-
ture for the OWL functors (e.g., SubClassOf,
IntersectionOf) that take classes as arguments.
Overall, 85% of arguments were atomic terms
rather than complex class expressions. Interest-
ingly, there was also a clear effect of argument po-
sition, with the first argument of a functor being
atomic rather than complex in as many as 99.4%
of cases7.
5 Discussion
Our results indicate that although in principle the
consensus model cannot guarantee transparent re-
alisations, in practice these are almost always at-
tainable, since ontology developers overwhelm-
ingly favour terms and axioms with relatively sim-
ple content. In an analysis of around 50 ontologies
we have found that over 90% of axioms fit a mere
seven patterns (table 2); the following examples
show that each of these patterns can be verbalised
by a clear unambiguous sentence ? provided, of
course, that no problems arise in lexicalising the
atomic terms:
1. Every admiral is a sailor
2. No sailor is a landlubber
3. Every admiral commands a fleet
4. Nelson is the victor of Trafalgar
5. Trafalgar is dated 1805
6. Nelson is an admiral
7. An admiral is defined as a person that com-
mands a fleet
However, since identifiers containing 3-4 words
are fairly common (figure 1), we need to consider
whether these formulations will remain transpar-
ent when combined with more complex lexical en-
tries. For instance, a travel ontology in our cor-
pus contains an axiom (fitting pattern 4) which our
prototype verbalises as follows:
4?. West Yorkshire has as boundary the West
Yorkshire Greater Manchester Boundary Frag-
ment
The lexical entries here are far from ideal: ?has
as boundary? is clumsy, and ?the West Yorkshire
Greater Manchester Boundary Fragment? has as
7One explanation for this result could be that develop-
ers (or development tools) treat axioms as having a topic-
comment structure, where the topic is usually the first ar-
gument; we intend to investigate this possibility in a further
study.
135
many as six content words (and would benefit
from hyphens). We assess the sentence as ugly but
understandable, but to draw more definite conclu-
sions one would need to perform a different kind
of empirical study using human readers.
6 Conclusion
We conclude (a) that existing ontologies can be
mostly verbalised using the consensus model, and
(b) that an editing tool based on relatively simple
linguistic patterns would not inconvenience on-
tology developers, but merely enforce constraints
that they almost always respect anyway. These
conclusions are based on analysis of identifier and
axiom patterns in a corpus of ontologies; they need
to be complemented by studies showing that the
resulting verbalisations are understood by ontol-
ogy developers and other users.
Acknowledgments
The research described in this paper was un-
dertaken as part of the SWAT project (Seman-
tic Web Authoring Tool), which is supported by
the UK Engineering and Physical Sciences Re-
search Council (EPSRC) grants G033579/1 (Open
University) and G032459/1 (University of Manch-
ester). Thanks are due to the anonymous ACL re-
viewers and to colleagues on the SWAT project for
their comments and suggestions.
References
F. Baader, I. R. Horrocks, and U. Sattler. 2005. De-
scription logics as ontology languages for the se-
mantic web. Lecture Notes in Artificial Intelligence,
2605:228?248.
Anne Cregan, Rolf Schwitter, and Thomas Meyer.
2007. Sydney OWL Syntax - towards a Controlled
Natural Language Syntax for OWL 1.1. In OWLED.
Norbert Fuchs and Rolf Schwitter. 1995. Specifying
logic programs in controlled natural language. In
CLNLP-95.
Adam Funk, Valentin Tablan, Kalina Bontcheva,
Hamish Cunningham, Brian Davis, and Siegfried
Handschuh. 2007. CLOnE: Controlled Lan-
guage for Ontology Editing. In 6th Interna-
tional and 2nd Asian Semantic Web Conference
(ISWC2007+ASWC2007), pages 141?154, Novem-
ber.
Glen Hart, Martina Johnson, and Catherine Dolbear.
2008. Rabbit: Developing a control natural lan-
guage for authoring ontologies. In ESWC, pages
348?360.
Matthew Horridge, Nicholas Drummond, John Good-
win, Alan Rector, Robert Stevens, and Hai Wang.
2006. The Manchester OWL syntax. In OWL:
Experiences and Directions (OWLED?06), Athens,
Georgia. CEUR.
Ian Horrocks. 1997. Optimising Tableaux Decision
Procedures for Description Logics. Ph.D. thesis,
University of Manchester.
K. Kaljurand and N. Fuchs. 2007. Verbalizing OWL
in Attempto Controlled English. In Proceedings of
OWL: Experiences and Directions, Innsbruck, Aus-
tria.
Holger Knublauch, Ray W. Fergerson, Natalya Frid-
man Noy, and Mark A. Musen. 2004. The Prote?ge?
OWL Plugin: An Open Development Environment
for Semantic Web Applications. In International Se-
mantic Web Conference, pages 229?243.
Boris Motik, Peter F. Patel-Schneider, and Bijan Par-
sia. 2010. OWL 2 web ontology language:
Structural specification and functional-style syn-
tax. http://www.w3.org/TR/owl2-syntax/. 21st
April 2010.
R. Schwitter and M. Tilbrook. 2004. Controlled nat-
ural language meets the semantic web. In Pro-
ceedings of the Australasian Language Technology
Workshop, pages 55?62, Macquarie University.
X. Sun and C. Mellish. 2006. Domain Independent
Sentence Generation from RDF Representations for
the Semantic Web. In Proceedings of the Combined
Workshop on Language-Enabled Educational Tech-
nology and Development and Evaluation of Robust
Spoken Dialogue Systems (ECAI06), Riva del Garda,
Italy.
TONES. 2010. The TONES ontology repository.
http://owl.cs.manchester.ac.uk/repository/browser.
Last accessed: 21st April 2010.
136
Grouping axioms for more coherent ontology descriptions
Sandra Williams
The Open University
Milton Keynes, United Kingdom
s.h.williams@open.ac.uk
Richard Power
The Open University
Milton Keynes, United Kingdom
r.power@open.ac.uk
Abstract
Ontologies and datasets for the Semantic
Web are encoded in OWL formalisms that
are not easily comprehended by people.
To make ontologies accessible to human
domain experts, several research groups
have developed ontology verbalisers using
Natural Language Generation. In practice
ontologies are usually composed of simple
axioms, so that realising them separately
is relatively easy; there remains however
the problem of producing texts that are co-
herent and efficient. We describe in this
paper some methods for producing sen-
tences that aggregate over sets of axioms
that share the same logical structure. Be-
cause these methods are based on logical
structure rather than domain-specific con-
cepts or language-specific syntax, they are
generic both as regards domain and lan-
guage.
1 Introduction
When the Semantic Web becomes established,
people will want to build their own knowledge
bases (i.e., ontologies, or TBox axioms, and data,
or ABox axioms1). Building these requires a high
level of expertise and is time-consuming, even
with the help of graphical interface tools such as
Prote?ge? (Knublauch et al, 2004). Fortunately, nat-
ural language engineers have provided a solution
to at least part of the problem: verbalisers, e.g.,
the OWL ACE verbaliser (Kaljurand and Fuchs,
2007).
Ontology verbalisers are NLG systems that gen-
erate controlled natural language from Semantic
1Description Logic (DL) underlies the Web Ontology
Language OWL. DL distinguishes statements about classes
(TBox) from those about individuals (ABox). OWL cov-
ers both kinds of statements, which in OWL terminology are
called ?axioms?.
Web languages, see Smart (2008). Typically they
generate one sentence per axiom: for example,
from the axiom2 Cat v Animal the OWL ACE
verbaliser (Kaljurand and Fuchs, 2007) generates
?Every cat is an animal?. The result is not a co-
herent text, however, but a disorganised list, often
including inefficient repetitions such as:
Every cat is an animal.
Every dog is an animal.
Every horse is an animal.
Every rabbit is an animal.
An obvious first step towards improved efficiency
and coherence would be to replace such lists with
a single aggregated sentence:
The following are kinds of animals: cats, dogs,
horses and rabbits.
In this paper, we show how all axiom patterns
in EL++, a DL commonly used in the Semantic
Web, can be aggregated without further domain
knowledge, and describe a prototype system that
performs such aggregations. Our method aggre-
gates axioms while they are still in logical form,
i.e., as part of sentence planning but before con-
verting to a linguistic representation and realising
as English sentences. This approach is somewhat
different from that proposed by other researchers
who convert ontology axioms to linguistic struc-
tures before aggregating (Hielkema, 2009; Galanis
et al, 2009; Dongilli, 2008). We present results
from testing our algorithm on over fifty ontologies
from the Tones repository3.
2 Analysis of axiom groupings
In this section we analyse which kinds of axioms
might be grouped together. Power (2010) anal-
2For brevity we use logic notation rather than e.g., OWL
Functional Syntax: subClassOf(class(ns:cat)
class(ns:animal)) where ns is any valid namespace.
The operatorv denotes the subclass relation, u denotes class
intersection, and ?P.C the class of individuals bearing the
relation P to one or more members of class C.
3http://owl.cs.manchester.ac.uk/
No. Logic OWL %
1 A v B subClassOf(A B) 51
2 A v ?P.B subClassOf(A
someValuesFrom(P B)) 33
3 [a, b] ? P propertyAssertion(P a b) 8
4 a ? A classAssertion(A a) 4
Table 1: The four most common axiom patterns.
ysed axiom patterns present in the same fifty on-
tologies. In spite of the richness of OWL, the sur-
prising result was that only four relatively simple
patterns dominated, accounting for 96% of all pat-
terns found in more than 35,000 axioms. Overall
there were few unique patterns, typically only 10
to 20, and up to 34 in an unusually complex ontol-
ogy. Table 1 lists the common patterns in logic no-
tation and OWL Functional Syntax, and also gives
the frequencies across the fifty knowledge bases.
Examples of English paraphrases for them are:
1. Every Siamese is a cat.
2. Every cat has as body part a tail.
3. Mary owns Kitty.
4. Kitty is a Siamese.
When two or more axioms conform to a pattern:
A v B
A v C
B v C
C v D
there are two techniques with which to aggregate
them: merging and chaining. If the right-hand
sides are identical we can merge the left-hand
sides, and vice versa:4
[A,B] v C
A v [B,C]
Alternatively, where the right-hand side of an ax-
iom is identical to the left-hand side of another ax-
iom, we can ?chain? them:
A v B v C v D
Merging compresses the information into a more
efficient text, as shown in the introduction, while
chaining orders the information to facilitate infer-
ence ? for example, ?Every A is a B and every
B is a C? makes it easier for readers to draw the
inference that every A is a C.
4We regard expressions like A v [B,C] and A v B v C
as shorthand forms allowing us to compress several axioms
into one formula. For merges one could also refactor the set
of axioms into a new axiom: thus for example A v [B,C]
could be expressed as A v (B u C), or [A,B] v C as
(A unionsq B) v C. This formulation would have the advantage
of staying within the normal notation and semantics of DL;
however, it is applicable only to merges, not to chains.
1. 2. 3. 4.
1. L,R,C ?,R?,? ?,?,? L?,?,C
2. L,R,? ?,?,? ?,?,C
3. L,R,? ?,R?,?
4. L,R,?
Table 2: Aggregating common axioms: 1. A v B,
2. A v ?P.B, 3. [a, b] ? P , 4. a ? A
Table 2 summarises our conclusions on whether
each pair of the four common patterns can be
merged or chained. Each cell contains three en-
tries, indicating the possibility of left-hand-side
merge (L), right-hand-side merge (R), and chain-
ing (C). As can be seen, some merges or chains
are possible across different patterns, but the safest
aggregations are those grouping axioms with the
same pattern (down the diagonal), and it is these
on which we focus here.
3 Merging similar patterns
Function Merge Patterns
f1(A) f1([A1, A2, A3, . . . ])
f2(A,B) f2([A1, A2, A3, . . . ], B)
f2(A, [B1, B2, B3, . . . ])
f3(A,B,C) f3([A1, A2, A3, . . . ], B,C)
f3(A, [B1, B2, B3, . . . ], C)
f3(A,B, [C1, C2, C3, . . . ])
Table 3: Generic merging rules.
If we represent ABox and TBox axioms as
Prolog terms (or equivalently in OWL Func-
tional Syntax), they take the form of functions
with a number of arguments ? for example
subClassOf(A,B), where subClassOf is the func-
tor, A is the first argument and B is the second argu-
ment. We can then formulate generic aggregation
rules for merging one-, two- and three-argument
axioms, as shown in table 3.
In general, we combine axioms for which the
functor is the same and only one argument differs.
We do not aggregate axiom functions with more
than three arguments. The merged constituents
must be different expressions with the same log-
ical form.
4 Implemention
This section describes a Prolog application which
performs a simple verbalisation including aggre-
gation. It combines a generic grammar for real-
ising logical forms with a domain-specific lexicon
derived from identifiers and labels within the input
ontology.
Input to the application is an OWL/XML file.5
Axioms that conform to EL++ DL are selected
and converted into Prolog format. A draft lex-
icon is then built automatically from the iden-
tifier names and labels, on the assumption that
classes are lexicalised by noun groups, properties
by verb groups with valency two, and individuals
by proper nouns.
Our aggregation rules are applied to axioms
with the same logical form. The first step picks
out all the logical patterns present in the input
ontology by abstracting from atomic terms. The
next step searches for all axioms matching each
of the patterns present. Then within each pattern-
set, the algorithm searches for axioms that differ
by only one argument, grouping axioms together
in the ways suggested in table 3. It exhaustively
lists every possible grouping and builds a new, ag-
gregated axiom placing the values for the merged
argument in a list, e.g., consider the axioms:
subClassOf(class(cat), class(feline)).
subClassOf(class(cat), class(mammal)).
subClassOf(class(dog), class(mammal)).
subClassOf(class(mouse), class(mammal)).
Identical first arguments =?
subClassOf(class(cat),
[class(feline),
class(mammal)]).
?Every cat is a feline and a mammal.?
Identical second arguments =?
subClassOf([class(cat), class(dog),
class(mouse)], class(mammal)).
?The following are kinds of mammal:
cats, dogs and mice.?
For all axioms with an identical first argu-
ment, class(cat), the algorithm places the
second arguments in a list, [class(feline),
class(mammal)], and builds a new axiom with the
first argument and the merged second argument.
From this, our realiser generates the sentence ?Ev-
ery cat is a feline and a mammal.? A similar pro-
cess is performed on first arguments when the sec-
ond arguments are identical.
To construct the grammar, we first formulated
rules for realising single axioms, and then added
rules for the aggregated patterns, incorporating
aggregation cues such as ?both? and ?the follow-
ing:? (Dalianis and Hovy, 1996). For the word-
ing of single axioms we relied mainly on proposals
5We convert OWL to OWL/XML with
the Manchester OWL Syntax Converter
http://owl.cs.manchester.ac.uk/converter/
from the OWL Controlled Natural Language task
force (Schwitter et al, 2008), so obtaining rea-
sonably natural sentences for common axiom pat-
terns, even though some less common axioms such
as those describing attributes of properties (e.g.,
domain, range, functionality, reflexivity, transitiv-
ity) are hard to express without falling back on
technical concepts from the logic of relations; for
these we have (for now) allowed short technical
formulations (e.g., ?The property ?has as part?
is transitive?). With these limitations, the gram-
mar currently realises any single axiom conform-
ing to EL++, or any aggregation of EL++ axioms
through the merge rules described above. Table 4
lists example aggregated axiom patterns and En-
glish realisations generated with our grammar.
5 Testing the ?merging? algorithm
Unit Original Aggregated Reduction
Sentences 35,542 11,948 66%
Words 320,603 264,461 18%
Table 5: Reduction achieved by aggregating
We have tested our generic merging rules on ax-
ioms conforming to EL++ in a sample of around
50 ontologies. Table 5 shows the reduction in the
number of generated sentence after aggregation.
Remember that previously, the system generated
one sentence for every axiom (35,542 sentences),
but with aggregation this is reduced to 11,948 sen-
tences, an overall reduction of 66%. However, ag-
gregation increases sentence length so the saving
in words is only 18%.
The effect of merging is to replace a large num-
ber of short sentences with a smaller number of
longer ones. Sometimes the aggregated sentences
were very long indeed, e.g., when a travel ontol-
ogy cited 800 instances of the class island ?
perhaps such cases would be expressed better by
a table than by prose6.
The algorithm computes all possible merges, so
we get, for instance, Fred described as a person
in both ?The following are people: Fred, . . . ? and
?Fred is all of the following: a person, . . . ?. This
means that the greater efficiency achieved through
aggregation may be counterbalanced by the extra
text required when the same axiom participates in
several merges ? for a few of our ontologies, in
6In a summary one might instead simply give a count and
an example: ?There are 800 islands, e.g., The Isle of Skye?.
Aggregated Axiom Pattern Example of Generated Text
subClassOf([C1,C2,. . . ], C3). The following are kinds of vehicles: a bicycle, a car, a truck and a van.
subClassOf(C1, [C2,C3,. . . ]). Every old lady is all of the following: a cat owner, an elderly and a woman.
subClassOf([C1,C2,. . . ], The following are kinds of something that has as topping a tomato: a fungi,
objectSomeValuesFrom(P1, C3)). a fiorella and a margherita.
subClassOf(C1, [ objectSomeValuesFrom(P1, C2) Every fiorella is something that has as topping a mozzarella and is
objectSomeValuesFrom(P2, C3)]). something that has as topping an olive.
classAssertion(C1, [I1, I2, . . . ]). The following are people: Fred, Joe, Kevin and Walt.
classAssertion([C1,C2,. . . ], I). Fred is all of the following: an animal, a cat owner and a person.
objectPropertyAssertion(P1, [I1, I2, I3], I4). The following are pet of Walt: Dewey, Huey and Louie.
objectPropertyAssertion(P1, I4, [I1, I2, I3]). Walt has as pet Dewey, Huey and Louie.
disjointClasses([C1,C2,. . . ], C3). None of the following are mad cows: an adult, . . . a lorry or a lorry driver.
disjointClasses(C1, [C2,C3,. . . ]). No grownup is any of the following: a kid, a mad cow, a plant, or a tree.
dataPropertyDomain([P1, P2, . . . ], C1). If any of the following relationships hold between X and Y then X
must be a contact: ?has as city?, ?has as street? and ?has as zip code?.
dataPropertyRange([P1, P2, . . . ], C1). If any of the following relationships hold between X and Y then Y
must be a string: ?has as city?, ?has as e mail? and ?has as street?.
differentIndividuals(I1, [I2, I3, . . . ]). The One Star Rating is a different individual from any of the following:
differentIndividuals([I1, I2, . . . ], I3). the Three Star Rating or the Two Star Rating.
equivalentDataProperties(P1, [P2,P3,. . . ]). The following properties are equivalent to the property ?has as zip code?:
equivalentDataProperties([P1,P2,. . . ], P3). ?has as post code?, ?has as zip? and ?has as postcode?.
equivalentObjectProperties([P1,P2,. . . ], P3). The following properties are equivalent to the property ?has as father?: . . . .
negativeobjectPropertyAssertion(P1, [I1, I2, . . . ], I3). None of the following are pet of Walt: Fluffy, Mog or Rex.
negativeobjectPropertyAssertion(P1, I1, [I2, I3, . . . ]). It is not true that Walt has as pet Fluffy or Rex.
Table 4: Example realisations of common aggregated EL++ axiom patterns.
fact, the word count for the aggregated version was
greater. This is an interesting problem that we
have not seen treated elsewhere. Merely pursu-
ing brevity, one might argue that an axiom already
included in a merge should be removed from any
other merges in which it participates; on the other
hand, the arbitrary exclusion of an axiom from a
list might be regarded as misleading. For now we
have allowed repetition, leaving the problem to fu-
ture work.
6 Related work
Reape and Mellish?s (1999) survey of aggrega-
tion in NLG proposed a continuum of definitions
ranging from narrow to wide. Our technique fits
into the narrow definition, i.e., it is language-
independent, operating on non-linguistic concep-
tual representations with the aim of minimising re-
dundancy and repetition. It implements the subject
and predicate grouping rules and aggregation cues
suggested by Dalianis and Hovy (1996).
Recent NLG systems that aggregate data from
ontologies (Hielkema, 2009; Galanis and An-
droutsopoulos, 2007; Dongilli, 2008) do not per-
form aggregation directly on axioms, but only af-
ter converting them to linguistic representations.
Moreover, their systems generate only from ABox
axioms in restricted domains while ours generates
English for both ABox and TBox in any domain.
The approach most similar to ours is that
of Bontcheva and Wilks (2004), who aggre-
gate a subset of RDF triples after domain-
dependent discourse structuring ? a task equiv-
alent to merging axioms that conform to the
objectPropertyAssertion pattern in table 4.
7 Conclusion
We have demonstrated that for the EL++ DL that
underlies many Semantic Web ontologies we can
define generic aggregation rules based on logical
structure, each linked to a syntactic rule for ex-
pressing the aggregated axioms in English. The
work described here is a first step in tackling a
potentially complex area, and relies at present on
several intuitive assumptions that need to be con-
firmed empirically. First, from an examination
of all combinations of the four commonest axiom
patterns, we concluded that axioms sharing the
same pattern could be combined more effectively
than axioms with different patterns, and there-
fore focussed first on same-pattern merges with
variations in only one constituent. Secondly, af-
ter systematically enumerating all such merges for
EL++, we have implemented a grammar that ex-
presses each aggregated pattern in English, relying
on an intuitive choice of the best form of words: at
a later stage we need to confirm that the resulting
sentences are clearly understood, and to consider
whether different formulations might be better.
Acknowledgments
This work is supported by the UK Engineering
and Physical Sciences Research Council (EPSRC)
grant EP/G033579/1 (SWAT: Semantic Web Au-
thoring Tool). We thank our colleagues and the
anonymous reviewers.
References
K. Bontcheva and Y. Wilks. 2004. Automatic re-
port generation from ontologies: the MIAKT ap-
proach. In Nineth International Conference on Ap-
plications of Natural Language to Information Sys-
tems (NLDB?2004), pages 214?225, Manchester,
UK.
Hercules Dalianis and Eduard H. Hovy. 1996. Aggre-
gation in natural language generation. In EWNLG
?93: Selected papers from the Fourth European
Workshop on Trends in Natural Language Gener-
ation, An Artificial Intelligence Perspective, pages
88?105, London, UK. Springer-Verlag.
Paolo Dongilli. 2008. Natural language rendering of
a conjunctive query. Technical Report Knowledge
Representation Meets Databases (KRDB) Research
Centre Technical Report: KRDB08-3, Free Univer-
sity of Bozen-Bolzano.
Dimitrios Galanis and Ion Androutsopoulos. 2007.
Generating multilingual descriptions from linguisti-
cally annotated OWL ontologies: the NaturalOWL
system. In Proceedings of the 11th European Work-
shop on Natural Language Generation, pages 143?
146, Morristown, NJ, USA. Association for Compu-
tational Linguistics.
Dimitrios Galanis, George Karakatsiotis, Gerasimos
Lampouras, and Ion Androutsopoulos. 2009. An
open-source natural language generator for OWL
ontologies and its use in prote?ge?, and second life.
In Proceedings of the 12th Conference of the Euro-
pean Chapter of the Association for Computational
Linguistics: Demonstrations Session, pages 17?20,
Morristown, NJ, USA. Association for Computa-
tional Linguistics.
Feikje Hielkema. 2009. Using Natural Language Gen-
eration to Provide Access to Semantic Metadata.
Ph.D. thesis, University of Aberdeen.
Kaarel Kaljurand and Norbert Fuchs. 2007. Ver-
balizing OWL in Attempto Controlled English. In
Proceedings of the Third International Workshop on
OWL: Experiences and Directions OWLED 2007.
Holger Knublauch, Ray W. Fergerson, Natalya Frid-
man Noy, and Mark A. Musen. 2004. The Prote?ge?
OWL Plugin: An Open Development Environment
for Semantic Web Applications. In International Se-
mantic Web Conference, pages 229?243.
Richard Power. 2010. Complexity assumptions in on-
tology verbalisation. In 48th Annual Meeting of the
Association for Computational Linguistics.
Michael Reape and Chris Mellish. 1999. Just what is
aggregation anyway? In Proceedings of the 7th Eu-
ropean Workshop on Natural Language Generation,
pages 20?29, Toulouse, France.
Rolf Schwitter, Kaarel Kaljur, Anne Cregan, Cather-
ine Dolbear, and Glen Hart. 2008. A comparison
of three controlled natural languages for owl 1.1.
In 4th OWL Experiences and Directions Workshop
(OWLED 2008).
Paul Smart. 2008. Controlled Natural Languages
and the Semantic Web. Technical Report Technical
Report ITA/P12/SemWebCNL, School of Electron-
ics and Computer Science, University of Southamp-
ton),.
Proceedings of the 2nd Workshop on Speech and Language Processing for Assistive Technologies, pages 128?136,
Edinburgh, Scotland, UK, July 30, 2011. c?2011 Association for Computational Linguistics
Experimental Identification of the Use of Hedges in the Simplification of
Numerical Expressions
Susana Bautista and Raquel Herva?s and Pablo Gerva?s
Universidad Complutense de Madrid, Spain
{raquelhb,subautis}@fdi.ucm.es, pgervas@sip.ucm.es
Richard Power and Sandra Williams
Department of Computing, The Open University, Milton Keynes MK76AA, UK
{r.power,s.h.williams}@open.ac.uk
Abstract
Numerical information is very common in
all kinds of documents from newspapers and
magazines to household bills and wage slips.
However, many people find it difficult to un-
derstand, particularly people with poor educa-
tion and disabilities. Sometimes numerical in-
formation is presented with hedges that mod-
ify the meaning. A numerical hedge is a word
or phrase employed to indicate explicitly that
some loss of precision has taken place (e.g.,
?around?) and it may also indicate the di-
rection of approximation (e.g., ?more than?).
This paper presents a study of the use of nu-
merical hedges that is part of research inves-
tigating the process of rewriting difficult nu-
merical expressions in simpler ways. We car-
ried out a survey in which experts in numer-
acy were asked to simplify a range of pro-
portion expressions and analysed the results to
obtain guidelines for automating the simplifi-
cation task.
1 Introduction
All public information services and documents
should be accessible in such a way that makes them
easily understood by everybody, according to the
United Nations (1994). Nowadays, a large percent-
age of information expressed in daily news comes
in the form of numerical expressions (statistics of
economy, demography data, etc). But many people
have problems with understanding such expressions
-e.g., people with limited education or some kind of
mental disability.
Lack of ability to understand numerical informa-
tion is an even greater problem than poor literacy.
A U.K. Government Survey in 2003 estimated that
6.8 million adults had insufficient numeracy skills
to perform simple everyday tasks such as paying
house-hold bills and understanding wage slips, and
23.8 million adults would be unable to achieve grade
C in the GCSE maths examination for 16 year-old
school children (Williams et al, 2003).
A first possible approach to solve this impor-
tant social problem is making numerical informa-
tion accessible by rewriting difficult numerical ex-
pressions using alternative wordings that are easier
to understand. Some loss of precision could have
positive advantages for numerate people as well as
less numerate. Such an approach would require a
set of rewriting strategies yielding expressions that
are linguistically correct, easier to understand than
the original, and as close as possible to the original
meaning.
In rewriting, hedges play an important role. For
example,?50.9%? could be rewritten as ?just over
half? using the hedge ?just over?. In this kind of
simplification, hedges indicate that the original num-
ber has been approximated and, in some cases, also
the direction of approximation.
This paper presents a preliminary study of the use
of hedges when numerical expressions are simplified
to make them more accessible. We have carried out
a survey in which experts in numeracy were asked to
simplify a range of proportion expressions to obtain
guidelines for developing the numerical expressions
simplification task automatically. As a first step to-
wards more complex simplification strategies, we
128
are trying to simplify numerical expressions without
losing substantial information. Our study does not
have a particular kind of disability in mind. Rather,
we aim to simplify according to levels of difficulty
defined in the Mathematics Curriculum of the Quali-
fications and Curriculum Authority (1999). Adapta-
tion to particular types of users is beyond the scope
of this paper.
2 Background
Text simplification, a relative new task in Natu-
ral Language Processing, has been directed mainly
at syntactic constructions and lexical choices that
some readers find difficult, such as long sentences,
passives, coordinate and subordinate clauses, ab-
stract words, low frequency words, and abbrevia-
tions. Chandrasekar et al (1996) introduced a two-
stage process, first transforming from sentence to
syntactic tree, then from syntactic tree to new sen-
tence; Siddharthan (2002) instead proposed a three-
stage process comprising analysis, transformation
and generation. In 1998, the project PSET (Car-
roll et al, 1998) employed lexical as well as syn-
tactic simplifications. Other researchers have fo-
cused on the generation of readable texts for readers
with low basic skills (Williams and Reiter, 2005),
and for teaching foreign languages (Petersen and
Ostendorf, 2007). There has been some previous
work on numerical expressions but more for experts
than for people who have difficulties with numer-
acy (Ellen Peters and Dieckmann, 2007), (Nathan
F. Dieckmann and Peters, 2009), (Ann M. Bisantz
and Munch, 2005), (Mishra H, 2011). However,
to our knowledge, there have been no previous at-
tempts to automatically simplify numerical informa-
tion in texts.
A corpus of numerical expressions was collected
for the NUMGEN project (Williams and Power,
2009). The corpus contains 10 sets of newspaper ar-
ticles and scientific papers (110 texts in total). Each
set is a collection of articles on the same topic ?
e.g., the increased risk of breast cancer in red meat
eaters, and the decline in the puffin population on
the Isle of May. Within each set, identical numeri-
cal facts are presented in a variety of linguistic and
mathematical forms.
3 Experiment
Our survey took the form of a questionnaire in
which participants were shown a sentence contain-
ing one or more numerical expressions which they
were asked to simplify using hedges if necessary.
3.1 Materials
Our simplification strategies are focused at two lev-
els: decimal percentages and whole-number per-
centages. For the survey we chose three sets of can-
didate sentences from the NUMGEN corpus: eight
sentences containing only decimal percentages and
two sets of eight sentences containing mixed whole-
number and decimal percentages. The number of
numerical expressions are more than eight because
some sentences contained more than one proportion
expression.
A wide spread of proportion values was present in
each set, including the two end points at nearly 0.0
and almost 1.0. We also included some numerical
expressions with hedges and sentences from differ-
ent topics in the corpus. In short, we included as
many variations in context, precision and different
wordings as possible.
3.2 Participants
We carried out the survey with primary or secondary
school mathematics teachers or adult basic numer-
acy tutors, all native English speakers. We found
them through personal contacts and posts to Inter-
net forums. The task of simplifying numerical ex-
pressions is difficult, but it is a task that this group
seemed well qualified to tackle since they are highly
numerate and accustomed to talking to people who
do not understand mathematical concepts very well.
Our experimental evaluation involved 34 partici-
pants who answered at least one question in our sur-
vey (some participants did not complete it).
3.3 Survey Design and Implementation
The survey was divided into three parts as follows:
1. Simplification of numerical expressions for a
person who can not understand percentages
2. Simplification of numerical expressions for a
person who can not understand decimals
129
3. Free simplification of numerical expressions
for a person with poor numeracy
Each part of the survey is considered as a differ-
ent kind of simplification: (1) simplification with no
percentages, (2) simplification with no decimals and
(3) free simplification.
For part (2), the set of sentences containing only
decimal percentages was used. One of the two
mixed sets of sentences with whole-number and
decimal percentages was used for part (1) and the
other for part (3). The experiment was presented on
SurveyMonkey1, a commonly-used provider of web
surveys. The survey was configured so that partic-
ipants could leave the questionnaire and later con-
tinue with it.
We asked participants to provide simplifications
for numerical expressions that were marked by
square brackets in each sentence. Below the sen-
tence, each bracketed number was shown beside a
text box in which the participant was asked to type
the simplified version. Our instructions said that nu-
merical expressions could be simplified using any
format: number words, digits, fractions, ratios, etc.
and that hedges such as ?more than?, ?almost? and
so on could be introduced if necessary. Participants
were also told that the meaning of the simplified ex-
pression should be as close to the original expres-
sion as possible and that, if necessary, they could
rewrite part of the original sentence. Figure 1 shows
a screenshot of part of the questionnaire.
3.4 Underlying assumptions
A numerical expression (NE) is considered to be a
phrase that represents a quantity, sometimes modi-
fied by a numerical hedge as in ?less than a quarter?
or ?about 20%?. We have restricted coverage to pro-
portions -i.e., fractions, ratios and percentages. We
had five hypotheses:
? H1: The use of hedges to accompany the sim-
plified numerical expression is influenced by
the simplification strategy selected. We con-
sider the use of fractions, ratios and percent-
ages like simplification strategies.
? H2: The use of hedges to simplify the numeri-
cal expression is influenced by the value of the
1www.surveymonkey.com
proportion, with values in the central range (say
0.2 to 0.8) and values at the extreme ranges (say
0.0-0.2 and 0.8-1.0) having a different use of
hedges.
? H3: The loss of precision allowed for the sim-
plified numerical expression is influenced by
the simplification strategy selected.
? H4: There is some kind of correlation between
the loss of precision and the use of hedges, in
such a way that the increase or decrease in the
former influences changes in the latter.
? H5: As an specific case of H4, when writers
choose numerical expressions for readers with
low numeracy, they do not tend to use hedges if
they are not losing precision.
4 Results
The results of the survey were carefully analyzed as
follows. First, within each block of questions, a set
of simplification strategies was identified for each
specific numerical expression. These strategies were
then grouped together according to the mathematical
forms and/or linguistic expressions employed (frac-
tions, ratios, percentages).
With a view to using these data to design an au-
tomated simplification system, these data have to be
analyzed in terms of pairs of a given input numeri-
cal expression and the simplified expression result-
ing from applying a specific simplification strategy.
For such pairings, three important features must be
considered as relevant to choosing a realization:
? Whether any numbers in the expression are re-
alized as one of the different types of available
expressions (fractions, ratios, percentages).
? The loss of precision involved in the simplifi-
cation.
? The possible use of a hedge to cover this loss
of precision explicitly in the simplified expres-
sion.
To calculate the loss of precision, we defined
Equation 1.
error =
(simplifiedNE ? originalNE)
originalNE
(1)
130
Figure 1: Screenshot of part of the questionnaire.
The set of pairings of input expression and ob-
served simplification strategies, loss of precision and
use of hedges as found in the results of the survey is
given in Tables 1, 2 and 3. For each input numer-
ical expression, the set of available simplification
strategies is represented as three lines in the table.
For each pairing, three columns are shown in the
table. Empty cells represent that the strategy was
not used. The first column presents the relative fre-
quency of usage with respect to the total set of possi-
ble simplification strategies used for that expression.
The second column captures the loss of precision in-
volved, represented in terms of the ratio between the
value of the difference between the original numer-
ical value in the input expression and the numerical
value that is conveyed by the corresponding simpli-
fied expression (using Equation 1). This ratio is also
expressed as a percentage. The third column indi-
cates the percentage of simplified numerical expres-
sions that contained a hedge. All of them are mean
values.
Each line represents one kind of simplification
strategy used to simplify the original numerical ex-
pression. Another point to explain is that frequen-
cies that belong to the same expression do not al-
ways add up to 100%. This is because a small num-
ber of others kinds of simplification strategies, like
deletions or rewriting of the whole sentence, are not
shown in the table. Moreover, we must keep in mind
that not all participants answered each question of
the survey.
Table 1 presents the relationships identified be-
tween the original numerical expressions and the
simplification strategies (presented as lines) for the
results of the first part of the survey (simplification
of numerical expressions for a person who can not
understand percentages). All the values are repre-
sented in percentages. Table 2 represents the same
data for the second part of the survey (simplification
of numerical expressions for a person who can not
understand decimals) and Table 3 for the third part
(free simplification of numerical expressions for a
person with poor numeracy).
In the three parts of the survey, the percentage of
simplifications that use hedges is slightly higher than
that of those not using hedges especially in the sec-
ond and third part of the survey. Adapting original
numerical expressions by inserting hedges accounts
for more than the 50% of cases. This reinforces
our assumption that simplifications involving loss of
precision may be better understood if an appropriate
hedge is used.
4.1 Analysis of the Use of Hedges in the
Simplified Numerical Expressions
In order to test hypothesis H1 (the use of hedges
in the simplified numerical expression is influenced
by the simplification strategy selected), we carried
out a series of two sample t-tests where statistical
significance was adjusted for multiple comparisons
by using the Bonferroni correction. Results are pre-
sented in Table 4. When considering the entire sur-
vey (Whole column), there is no significant differ-
ence in the use of hedges in fractions and percent-
ages. When analyzing the survey by parts we find
similar results. There is no significant difference in
the use of hedges in any strategy in the second (no
decimals) and the third (free simplification) parts of
131
Num. Exp. Frequency (%) Error (%) Hedge (%)
Fractions 18 0 67
more than 1% Ratios 6 0 100
Percentages 18 17 50
Fractions 6 0 50
2% Ratios 18 -1 17
Percentages 12 0 0
Fractions 26 1 67
16.8% Ratios 65 5 45
Percentages 9 -3 0
Fractions 82 -4 86
27% Ratios 12 8 75
Percentages 6 6 50
Fractions 41 0 93
at least 30% Ratios 35 13 67
Percentages 3 0 100
Fractions 53 12 50
40% Ratios 29 0 10
Percentages 6 0 0
Fractions 82 -13 82
56% Ratios
Percentages 6 -5 50
Fractions 74 -3 84
63% Ratios 24 0 75
Percentages 3 0 0
Fractions 32 0 0
75% Ratios 29 0 0
Percentages
Fractions 3 0 0
97.2% Ratios 38 -8 23
Percentages 18 1 50
Fractions 6 0 0
98% Ratios 12 0 0
Percentages 3 0 0
Fractions 39 -1 53
Average Ratios 24 2 41
Percentages 7 1 30
Table 1: Analysis of the data for 34 participants from the
first part of the survey (simplifications intended for peo-
ple who do not understand percentages). All values are
percentages. The first column represents the frequencies
of use for each simplification strategy. The second col-
umn shows the error as the loss of precision involved in
the simplification. And the last column displays the use
of hedges in the simplifications.
the survey, but in the first part (no percentages) we
find significant difference between fractions and ra-
tios (p<0.0006). These results do not support the
hypothesis, as there is not a direct relation between
the use of hedges and the selected strategy.
We performed another t-test adjusted by using the
Bonferroni correction on the simplification strate-
gies and central and peripheral values to test hypoth-
esis H2 (the use of hedges to simplify the numerical
expression is influenced by the value of the propor-
tion, with values in the central range (say 0.2 to 0.8)
and values at the extreme ranges (say 0.0-0.2 and
0.8-1.0) having a different use of hedges). In this
case there is also no significant difference. The re-
sults show that the use of hedges is not influenced by
central and peripheral values, rejecting our hypoth-
esis H2 with a p-value p=0.77 in the worst case for
the percentages strategy.
A new t-test adjusted by using the Bonferroni cor-
Num. Exp. Frequency (%) Error (%) Hedge (%)
Fractions 6 25 50
0.6% Ratios 9 22 33
Percentages 47 21 100
Fractions 3 -29 0
2.8% Ratios 24 6 63
Percentages 47 7 63
Fractions
6.1% Ratios 18 -4 50
Percentages 50 -3 82
Fractions 12 9 75
7.5% Ratios 12 -10 0
Percentages 50 7 41
Fractions 15 -1 80
15.5% Ratios 12 6 50
Percentages 44 2 33
Fractions 15 -3 100
25.9% Ratios 12 -3 75
Percentages 38 5 62
Fractions 3 0 0
29.1% Ratios 15 3 60
Percentages 50 2 71
Fractions 12 -5 100
35.4% Ratios 15 -4 60
Percentages 41 -1 71
Fractions 44 -2 93
50.8% Ratios 3 0 0
Percentages 21 0 43
Fractions 44 1 93
73.9% Ratios 6 1 50
Percentages 18 0 50
Fractions 3 0 0
87.8% Ratios 15 -1 60
Percentages 47 1 88
Fractions 3 0 0
96.9% Ratios 12 -2 75
Percentages 29 0 80
Fractions 6 0 50
96.9% Ratios 18 -1 67
Percentages 21 0 86
Fractions 3 0 0
97.2% Ratios 18 -1 67
Percentages 41 0 93
Fractions 3 0 0
97.2% Ratios 18 -1 83
Percentages 32 0 91
Fractions 3 0 0
98.2% Ratios 15 -2 40
Percentages 44 0 67
Fractions 11 0 43
Average Ratios 14 1 52
Percentages 39 2 70
Table 2: Analysis of the data for 34 participants from
the second part of the survey (simplifications intended for
people who do not understand decimals). All values are
percentages. The first column represents the frequencies
of use for each simplification strategy. The second col-
umn shows the error as the loss of precision involved in
the simplification. And the last column displays the use
of hedges in the simplifications.
rection was done to test hypothesis H3 (the loss of
precision allowed for the simplified numerical ex-
pression is influenced by the simplification strategy
selected). Table 5 shows significant differences be-
tween each simplification strategy and each kind of
simplification. In the Whole column we can observe
that the loss of precision in fractions is significantly
different to the one in ratios and percentages. In the
first part (no percentages) there is a significant dif-
ference between ratios and the rest of simplification
strategies. In the second part (no decimals) there is
132
Num. Exp. Frequency (%) Error (%) Hedge (%)
Fractions
0.7% Ratios 6 43 100
Percentages 9 43 100
Fractions 6 -17 100
12% Ratios 21 -8 71
Percentages 21 -17 100
Fractions 41 -4 57
26% Ratios 12 -4 50
Percentages
Fractions 41 -8 86
36% Ratios 9 -2 67
Percentages
Fractions 41 -6 50
53% Ratios
Percentages 6 -6 50
Fractions 21 -5 100
65% Ratios 18 -1 33
Percentages 3 0 0
Fractions 15 0 20
75% Ratios 9 0 33
Percentages 3 0 0
Fractions
91% Ratios 29 -1 50
Percentages 6 -1 50
Fractions
above 97% Ratios 32 0 64
Percentages 6 2 100
Fractions 18 -7 69
Average Ratios 15 3 59
Percentages 6 3 57
Table 3: Analysis of the data for 34 participants from the
third part of the survey (free simplification intended for
people with poor literacy). All values are percentages.
The first column represents the frequencies of use for
each simplification strategy. The second column shows
the error as the loss of precision involved in the simplifi-
cation. And the last column displays the use of hedges in
the simplifications.
no significant difference between any strategy. And
in the last part (free simplification) there is only a
significant difference between fractions and ratios.
These results seem not to support the hypothesis,
as there is not a direct relation between the use of
hedges and the loss of precision in the simplified nu-
merical expression.
For hypothesis H4 (there is some kind of corre-
lation between the loss of precision and the use of
hedges), we looked for correlations between each
part of the survey and each kind of simplification
strategy. We carried out a non-parametric measure
of statistical dependence between the two variables
(loss of precision and use of hedges) calculated by
the Spearman?s rank correlation coefficient.
In general, the results show no correlation, so
there is no linear dependence between the loss of
precision in the strategy and use of hedges, rejecting
our hypothesis. For example, there are cases with
a weak correlation (e.g. in the second part of the
survey for fractions with r=0.49, N=17 and p=0.03),
and cases where there is a strong correlation (e.g.
in the third part of the survey, with r=1, N=18 and
p<.0001).
Finally, when we analyzed hypothesis H5 (when
writers choose numerical expressions for readers
with low numeracy, they do not tend to use hedges if
they are not losing precision), we worked with each
part of the survey to study the cases where the loss
of precision is zero and what is the tendency of use
of hedges.
? In the first part of the survey (simplification
of numerical expressions for a person who can
not understand percentages), considering our
34 participants, in a 46% of responses the loss
of precision is zero, and for these cases only
11% used hedges.
? For the second part (simplification of numeri-
cal expressions for a person who can not un-
derstand decimals), considering our 34 partici-
pants, in a 16% of responses the loss of preci-
sion is zero and for these cases only 7% used
hedges.
? And finally, in the last part (simplification of
numerical expressions for a person with poor
numeracy), considering the same participants,
in a 23% of cases the loss of precision is zero
in the simplification and for these cases only
6% used hedges.
With this data, it seems that we can accept hypoth-
esis H5, that is, we found evidence for our assump-
tion that when writers choose numerical expressions
for readers with poor numeracy, they tend to use
hedges when they round the original numerical ex-
pression, i.e when the loss of precision is not zero.
4.2 Original Numerical Expressions with
Hedges
In our survey there were a few cases where the orig-
inal numerical expression had a hedge. We have
observed that if the original numerical expression
has hedge almost always the simplified numerical
expression contained a hedge. There is a special
case, ?above 97%? where we do not count the use
of hedges because in this case the participants chose
non-numeric options mostly and they rewrote the
numerical expression with phrases like ?around all?.
133
Strategy No Pct. No Dec. Free Simp. Whole
Fractions A A A A
Percentages A B A A A
Ratios B A A B
Table 4: Results of t-test adjusted by Bonferroni correction for H1 (the use of hedges in simplified numerical ex-
pressions is influenced by the simplification strategy selected). Strategies which do not share a letter are significantly
different.
Strategy No Pct. No Dec. Free Simp. Whole
Fractions A A A A
Percentages A A A B B
Ratios B A B B
Table 5: Results of t-test adjusted by Bonferroni correction for H3 (the loss of precision allowed for the simplified
numerical expression is influenced by the simplification strategy selected). Strategies which do not share a letter are
significantly different.
In the remaining cases, the same hedge is nearly al-
way chosen to simplify the numerical expression.
4.3 Kinds of Hedges
With respect to the actual hedges used, we have
identified two different possible roles of hedge in-
gredients in a numerical expression. In some cases,
hedges are used to indicate that the actual numeri-
cal value given is an approximation to the intended
value. Uses of about or around are instances of this.
This kind of hedge is employed to indicate explic-
itly that some loss of precision has taken place dur-
ing simplification. In other cases, hedges are used to
indicate the direction in which the simplified value
diverges from the original value. Uses of under or
over are instances of this. In some cases more than
one hedge may be added to an expression to indi-
cate both approximation and direction, or to some-
how specify the precision involved in the simplifica-
tion, as in just under or a little less than.
In our analysis we studied which hedges were
the most frequent in each part of the survey. Only
hedges with more than ten appearances in total (in-
cluding simplification strategies not present in the
table) have been considered in Table 6. We observed
that the three parts of the survey have three hedges
in common: about, just over and over. They are
used in different strategies for each kind of simpli-
fication. In the second part of the survey, where
simplifications of numerical expressions for a per-
son who can not understand decimals are done, is
where more hedges are used, in special for percent-
ages strategy. In the last part of the survey, where
there is more freedom to decide how simplify the
original numerical expression, participants used less
hedges compare to the others parts.
No Percentages
Hedge Fractions Ratios Percent.
about 15 9 0
at least 8 5 1
just over 21 1 0
more than 9 3 0
over 6 3 2
Total 59 21 3
No Decimals
Hedges Fractions Ratios Percent.
about 8 12 6
almost 4 1 8
just over 13 3 39
just under 3 2 27
nearly 7 5 24
over 7 5 9
Total 42 28 113
Free Simplification
Hedges Fractions Ratios Percent.
about 6 5 1
just over 6 0 5
more than 4 5 0
nearly 4 0 2
over 11 2 3
Total 31 12 11
Table 6: Use of the most frequent hedges in each part of
the survey
134
5 Discussion
As can be seen in the results, the use of hedges to
simplify numerical expressions can be influenced by
three parameters. The first is the kind of simplifica-
tion. Our survey was divided in three parts depend-
ing on the mathematical knowledge of the final user.
The second is the simplification strategy for choos-
ing mathematical form (fractions, ratios, or percent-
ages). In our data we observed some differences in
the usage of hedges with ratios and their usage with
fractions and percentages (see Table 4). The last pa-
rameter is the loss of precision that occurs when the
numerical expression is rounded. We investigated
the use of hedges vs. loss of precision with different
tests hoping to define some dependencies, but there
was no clear correlation between them, and it was
only when we tried a deeper analysis of strategies
and kind of simplifications that we found some cor-
relations such as those we presented in Section 4.1.
When asked to simplify for people who do not
understand percentages, or for people with poor nu-
meracy, the participants use different simplification
strategies and sometimes they use hedges to simplify
the original numerical expression. As some partic-
ipants commented, not only are percentages mathe-
matically sophisticated forms, but they may be used
in sophisticated ways in the text, often for example
describing rising and falling values, for which in-
creases or decreases can themselves be described in
percentages terms. Such complex relationships are
likely to pose problems for people with poor numer-
acy even if a suitable strategy can be found for sim-
plifying the individual percentages. In some of the
examples with more than one numerical expression
being compared, some of the evaluators reported a
tendency to phrase them both according to a com-
parable base. Thus we should consider the role of
context (the set of numerical expressions in a given
sentence as a whole, and the meaning of the text) in
establishing what simplifications must be used.
6 Conclusions and Future Work
Through a survey administered to experts on nu-
meracy, we have collected a wide range of exam-
ples of appropriate simplifications of percentage ex-
pressions. These examples of simplified expressions
give us information about the use of hedges that our
participants carry out to adapt the original numer-
ical expression to be understood by the final user.
We investigated the loss of precision that occurs with
each hedge and the relation between the simplifica-
tion strategy and the use of hedges.
Our aim is to use this data to guide the develop-
ment of a system for automatically simplifying per-
centages in texts. With the knowledge acquired from
our study we will improve our algorithm to simplify
numerical expressions. We could determinate from
the simplification strategy, kind of simplification and
the loss of precision allowed, which will be the best
option to adapt the original numerical expression to
the final user and if that option uses hedges to under-
stand better the original numerical expression. As a
part of our algorithm, we will have to look at inter-
rater agreements for identifying appropriate hedges.
As future work, we plan to carry out another study
to determine a ranking of simplification strategies
from collecting a repertoire of rewriting strategies
used to simplify. This data should allow us to deter-
mine whether common values are considered sim-
pler and whether the value of the original expression
influences the chosen simplification strategy. So,
given a numerical expression, we could choose what
simplification strategy to apply and whether to insert
a hedge. We could investigate whether the value of
the original proportion also influences choices, de-
pending on its correspondence with central or pe-
ripheral values.
We have also collected a parallel corpus of numer-
ical expressions (original vs. simplified version).
This corpus will be shared with other researches so
it can be used in different applications to improve
the readability of text. This could be a very use-
ful resource because simplification of percentages
remains an interesting and non-trivial problem.
Acknowledgments
This research is funded by the Spanish Ministry
of Education and Science (TIN2009-14659-C03-01
Project), Universidad Complutense de Madrid and
Banco Santander Central Hispano (GR58/08 Re-
search Group Grant), and the FPI grant program.
135
References
Stephanie Schinzing Marsiglio Ann M. Bisantz and Jes-
sica Munch. 2005. Displaying uncertainty: Inves-
tigating the effects of display format and specificity.
Human Factors: The Journal of the Human Factors
and Ergonomics Society, 47(4):777.
J. Carroll, G. Minnen, Y. Canning, S. Devlin, and J. Tait.
1998. Practical simplification of English newspaper
text to assist aphasic readers. In AAAI-98 Workshop on
Integrating Artificial Intelligence and Assistive Tech-
nology, Madison, Wisconsin.
Raman Chandrasekar, Christine Doran, and Bangalore
Srinivas. 1996. Motivations and Methods for Text
Simplification. In COLING, pages 1041?1044.
Paul Slovic Ellen Peters, Judith Hibbard and Nathan
Dieckmann. 2007. Numeracy skill and the commu-
nication, comprehension, and use of risk-benefit infor-
mation. Health Affairs, 26(3):741?748.
Shiv B. Mishra H, Mishra A. 2011. In praise of vague-
ness: malleability of vague information as a perfor-
mance booster. Psychological Science, 22(6):733?8,
April.
Paul Slovic Nathan F. Dieckmann and Ellen M. Peters.
2009. The use of narrative evidence and explicit like-
lihood by decisionmakers varying in numeracy. Risk
Analysis, 29(10).
The United Nations. 1994. Normas uniformes sobre la
igualdad de oportunidades para las personas con dis-
capacidad. Technical report.
Sarah E. Petersen and Mari Ostendorf. 2007. Text Sim-
plification for Language Learners: A Corpus Analy-
sis. Speech and Language Technology for Education
(SLaTE).
Qualification and Curriculum Authority. 1999. Mathe-
matics: the national curriculum for england. Depart-
ment for Education and Employment, London.
Advaith Siddharthan. 2002. Resolving Attachment and
Clause Boundary Amgiguities for Simplifying Rela-
tive Clause Constructs. In Proceedings of the Student
Research Workshop, 40th Meeting of the Association
for Computacional Linguistics.
Sandra Williams and Richard Power. 2009. Precision
and mathematical form in first and subsequent men-
tions of numerical facts and their relation to document
structure. In Proceedings of the 12th European Work-
shop on Natural Language Generation, Athens.
Sandra Williams and Ehud Reiter. 2005. Generating
readable texts for readers with low basic skills. In
Proceeding of the 10th European Workshop on Natu-
ral Language Generation, pages 140?147, Aberdeen,
Scotland.
Joel Williams, Sam Clemens, Karin Oleinikova, and
Karen Tarvin. 2003. The Skills for Life survey: A
national needs and impact survey of literacy, numer-
acy and ICT skills. Technical Report Research Report
490, Department for Education and Skills.
136
INLG 2012 Proceedings of the 7th International Natural Language Generation Conference, pages 110?114,
Utica, May 2012. c?2012 Association for Computational Linguistics
Planning Accessible Explanations for Entailments in OWL Ontologies
Tu Anh T. Nguyen, Richard Power, Paul Piwek, Sandra Williams
The Open University
Milton Keynes, United Kingdom
{t.nguyen,r.power,p.piwek,s.h.williams}@open.ac.uk
Abstract
A useful enhancement of an NLG system for
verbalising ontologies would be a module ca-
pable of explaining undesired entailments of
the axioms encoded by the developer. This
task raises interesting issues of content plan-
ning. One approach, useful as a baseline, is
simply to list the subset of axioms relevant
to inferring the entailment; however, in many
cases it will still not be obvious, even to OWL
experts, why the entailment follows. We sug-
gest an approach in which further statements
are added in order to construct a proof tree,
with every step based on a relatively simple
deduction rule of known difficulty; we also de-
scribe an empirical study through which the
difficulty of these simple deduction patterns
has been measured.
1 Introduction
A practical problem in developing ontologies for
the semantic web is that mistakes are hard to spot.
One reason for this lies in the opacity of the stan-
dard OWL formalisms, such as OWL/RDF, which
are designed for efficient processing by computer
programs and not for fast comprehension by peo-
ple. Various tools have been proposed to address
this problem, including not only graphical interfaces
such as Prote?ge?, but NLG (Natural Language Gener-
ation) programs that verbalise the axioms of an on-
tology as text (Kaljurand and Fuchs, 2007; Schwit-
ter and Meyer, 2007; Hart et al, 2008). Using such a
tool, a mistaken axiom presented through a sentence
like ?Every person is a movie? immediately leaps to
the eye.
Although there is evidence that verbalisation
helps developers to check individual axioms
(Stevens et al, 2011), there remains a more subtle
problem of undesired entailments, often based on in-
teractions among axioms. The difference between
axioms and entailments is that whereas axioms are
statements encoded by the developer, entailments
are statements inferred from axioms by automated
reasoners such as FaCT++ (Tsarkov and Horrocks,
2006). Because reasoning systems interpret state-
ments absolutely literally, it is quite common for ap-
parently innocuous axioms to lead to absurd conclu-
sions such as ?Everything is a person?, ?Nothing is
a person?, or indeed ?Every person is a movie?. The
standard reasoning algorithms, based on tableau al-
gorithms, will compute these entailments efficiently,
but they provide no information that helps explain
why an undesired conclusion was drawn, and hence
which axiom or axioms need to be corrected.
To provide an explanation of an entailment, the
first step is obviously to determine which axioms are
relevant to the inference. A set of relevant axioms
is known technically as a justification of the entail-
ment, defined as any minimal subset of the ontology
from which the entailment can be drawn (Kalyan-
pur, 2006). The minimality requirement here means
that if any axiom is removed from a justification, the
entailment will no longer be inferable.
Drawing on Kalyanpur?s work, the most direct
strategy for planning an explanation is simply to
verbalise the axioms in the justification, followed
by the entailment, with no additional content. This
strategy serves as a useful baseline for comparison,
and might even be effective for some simple justi-
110
Entailment Person v Movie Every person is a movie.
1. GoodMovie ? ?hasRating.FourStars 1. A good movie is anything that only has ratings of four stars.
Justification 2. Domain(hasRating) = Movie 2. Anything that has a rating is a movie.
3. GoodMovie v StarRatedMovie 3. Every good movie is a star-rated movie.
4. StarRatedMovie v Movie 4. Every star-rated movie is a movie.
Table 1: An example justification that requires further explanation
fications; however, user studies have shown that in
many cases even OWL experts are unable to work
out how the conclusion follows from the premises
without further explanation (Horridge et al, 2009).
This raises two problems of content planning that
we now address: (a) how we can ascertain that fur-
ther explanation is needed, and (b) what form such
explanation should take.
2 Explaining complex justifications
An example of a justification requiring further ex-
planation is shown in Table 1. Statements are pre-
sented in mathematical notation in the middle col-
umn (rather than in OWL, which would take up a
lot more space), with a natural language gloss in the
right column. Since these sentences are handcrafted
they should be more fluent than the output of a ver-
baliser, but even with this benefit, it is extremely
hard to see why the entailment follows.
The key to understanding this inference lies in the
first axiom, which asserts an equivalence between
two classes: good movies, and things that only have
ratings of four stars. The precise condition for an in-
dividual to belong to the second class is that all of its
ratings should be four star, and this condition would
be trivially satisfied if the individual had no ratings
at all. From this it follows that people, parrots,
parsnips, or in general things that cannot have a rat-
ing, all belong to the second class, which is asserted
to be equivalent to the class of good movies. If in-
dividuals with no rating are good movies, then by
axioms 3 and 4 they are also movies, so we are left
with two paradoxical statements: individuals with a
rating are movies (axiom 2), and individuals without
a rating are movies (the intermediate conclusion just
derived). Since everything that exists must either
have some rating or no rating, we are driven to the
conclusion that everything is a movie, from which it
follows that any person (or parrot, etc.) must also be
a movie: hence the entailment. Our target explana-
tion for this case is as follows:
Every person is a movie because the ontology
implies that everything is a movie.
Everything is a movie because (a) anything that
has a rating is a movie, and (b) anything that has
no rating at all is a movie.
Statement (a) is stated in axiom 2 in the justifica-
tion. Statement (b) is inferred because the ontology
implies that (c) anything that has no rating at all
is a good movie, and (d) every good movie is a
movie.
Statement (d) is inferred from axioms 3 and 4 in
the justification. Statement (c) is inferred from
axiom 1, which asserts an equivalence between
two classes: ?good movie? and ?anything that has
as rating only four stars?. Since the second class
trivially accepts anything that has no rating at all,
we conclude that anything that has no rating at all
is a good movie.
Note that in this or any other intelligible explana-
tion, a path is traced from premises to conclusion by
introducing a number of intermediate statements, or
lemmas. Sometimes a lemma merely unpacks part
of the meaning of an axiom ? the part that actually
contributes to the entailment. This is clearly what
we are doing when we draw from axiom 1 the im-
plication that all individuals with no ratings are good
movies. Alternatively a lemma could be obtained by
combining two axioms, or perhaps even more. By
introducing appropriate lemmas of either type, we
can construct a proof tree in which the root node is
the entailment, the terminal nodes are the axioms in
the justification, and the other nodes are lemmas. An
explanation based on a proof tree should be easier to
understand because it replaces a single complex in-
ference step with a number of simpler ones.
Assuming that some kind of proof tree is needed,
the next question is how to construct proof trees that
provide effective explanations. Here two conditions
need to be met: (1) the proof tree should be correct,
in the sense that all steps are valid; (2) it should be
111
accessible, in the sense that all steps are understand-
able. As can be seen, one of these conditions is logi-
cal, the other psychological. Several research groups
have proposed methods for producing logically cor-
rect proof trees for description logic (McGuinness,
1996; Borgida et al, 1999; Horridge et al, 2010),
but explanations planned in this way will not nec-
essarily meet our second requirement. In fact they
could fail in two ways: either they might employ a
single reasoning step that most people cannot fol-
low, or they might unduly complicate the text by
including multiple steps where a single step would
have been understood equally well. We believe this
problem can be addressed by constructing the proof
tree from deduction rules for which the intuitive dif-
ficulty has been measured in an empirical study.1
3 Collecting Deduction Rules
For our purposes, a deduction rule consists of a
conclusion (i.e., an entailment) and up to three
premises from which the conclusion logically fol-
lows. Both conclusion and premises are generalised
by using variables that abstract over class and prop-
erty names, as shown in Table 2, where for example
the second rule corresponds to the well-known syl-
logism that from ?Every A is a B? and ?Every B is a
C?, we may infer ?Every A is a C?.
Our deduction rules were derived through a cor-
pus study of around 500 OWL ontologies. First
we computed entailment-justification pairs using the
method described in Nguyen et al (2010), and
collated them to obtain a list of deduction patterns
ranked by frequency. From this list, we selected pat-
terns that were simple (in a sense that will be ex-
plained shortly) and frequent, subsequently adding
some further rules that occurred often as parts of
more complex deduction patterns, but were not com-
puted as separate patterns because of certain limi-
tations of the reasoning algorithm.2 The deduction
rules required for the previous example are shown
1Deduction rules were previously used by Huang for re-
constructing machine-generated mathematical proofs; however,
these rules were not for description logic based proofs and
assumed to be intuitive to people (Huang, 1994). The out-
put proofs were then enhanced (Horacek, 1999) and verbalised
(Huang, 1994).
2Reasoning services for OWL typically compute only some
kinds of entailment, such as subclass and class membership
statements, and ignore others.
in Table 2. So far, 41 deduction rules have been ob-
tained in this way; these are sufficient to generate
proof trees for 48% of the justifications of subsump-
tion entailments in the corpus (i.e., over 30,000 jus-
tifications).
As a criterion of simplicity we considered the
number of premises (we stipulated not more than
three) and also what is called the ?laconic? property
(Horridge et al, 2008) ? that an axiom should not
contain information that is not required for the en-
tailment to hold. We have assumed that deduction
rules that are simple in this sense are more likely to
be understandable by people; we return to this issue
in section 5, which describes an empirical test of the
understandability of the rules.
4 Constructing Proof Trees
A proof tree can be defined as any tree linking the
axioms of a justification (terminal nodes) to an en-
tailment (root node), in such a way that every local
tree (i.e., every node and its children) corresponds
to a deduction rule. This means that if the entail-
ment and justification already correspond to a de-
duction rule, no further nodes (i.e., lemmas) need
to be added. Otherwise, a proof can be sought by
applying the deduction rules, where possible, to the
terminal nodes, so introducing lemmas and grow-
ing the tree bottom-up towards the root. Exhaus-
tive search using this method may yield zero, one or
multiple solutions ? e.g., for our example two proof
trees were generated, as depicted in Figure 1.3
5 Measuring understandability
To investigate the difficulty of deduction rules em-
pirically, we have conducted a survey in which 43
participants (mostly university staff and students un-
familiar with OWL) were shown the premises of the
rule, expressed as English sentences concerning fic-
titious entities, and asked to choose the correct con-
clusion from four alternatives. They were also asked
to rate the difficulty of this choice on a five-point
scale. For instance, in one problem the premises
3In the current implementation, the proof tree can also be de-
veloped by adding lemmas that unpack part of the meaning of
an axiom, using the method proposed by Horridge et al(2008).
These steps in the proof are not always obvious, so their under-
standability should also be measured.
112
ID Deduction Rule Example Success Rate
1 ?r.? v C Anything that has no ratings at all is a movie. 65%
?r.> v C Anything that has a rating is a movie.
? > v C ? Everything is a movie.
2 C v D Anything that has no ratings at all is a good movie. 88%
D v E Every good movie is a movie.
? C v E ? Anything that has no ratings at all is a movie.
3 C ? ?r.D A good movie is anything that only has ratings of four stars. ?
? ?r.? v C ? Anything that has no ratings at all is a good movie.
Table 2: Deduction rules for the example in Table 1
Figure 1: Proof trees generated by our current system
Figure 2: Results of the empirical study. In our difficulty
scale, 1 means ?very easy? and 5 means ?very difficult?
were ?Every verbeeg is a giantkin; no giantkin is
a verbeeg.?; to answer correctly, participants had to
tick ?Nothing is a verbeeg? and not ?Nothing is a gi-
antkin?.
So far 9/41 deduction rules have been measured
in this way. Figure 2 shows the success rates and the
means of difficulty of those rules. For most prob-
lems the success rates were around 80%, confirm-
ing that the rules were understandable, although in
a few cases performance fell to around 50%, sug-
gesting that further explanation would be needed.
The study also indicates a statistically significant re-
lationship between the accuracy of the participants?
performance and their perceptions of difficulty (r =
0.82, p < 0.01). Two of the three rules in Table 2
were measured in this way. The third rule has not
been tested yet; however, its success rate is expected
to be very low as it was proved to be a very difficult
inference (Horridge et al, 2009).
6 Conclusion
This paper has reported our work in progress on con-
tent planning for explanations of entailments. The
main steps involved in the planning process are sum-
113
Figure 3: Our approach for the content planning. E, J, Pn
are entailments, justifications and proofs respectively; d1
and d2 are difficulty scores and d2 ? d1
marised in Figure 3. We have focused on one as-
pect: the introduction of lemmas that mediate be-
tween premises and conclusion, so organising the
proof into manageable steps. Lemmas are derived
by applying deduction rules collected through a cor-
pus study on entailments and their justifications.
Through a survey we have measured the difficulty of
some of these rules, as evidenced by performance on
the task of choosing the correct conclusion for given
premises. These measures should indicate which
steps in a proof are relatively hard, and thus perhaps
in need of further elucidation, through special strate-
gies that can be devised for each problematic rule.
Our hypothesis is that these measures will also allow
an accurate assessment of the difficulty of a candi-
date proof tree, so providing a criterion for choos-
ing among alternatives ? e.g., by using the success
rates as an index of difficulty, we can sum the in-
dex over a proof tree to obtain a simple measure
of its difficulty. Our verbaliser currently translates
OWL statements literally, and needs to be improved
to make sure any verbalisations do not give rise to
unwanted presuppositions and Gricean implicatures.
Acknowledgments
This research was undertaken as part of the ongo-
ing SWAT project (Semantic Web Authoring Tool),
which is supported by the UK Engineering and
Physical Sciences Research Council (EPSRC). We
thank our colleagues and the anonymous viewers.
References
Alexander Borgida, Enrico Franconi, Ian Horrocks, Deb-
orah L. McGuinness, and Peter F. Patel-Schneider.
1999. Explaining ALC Subsumption. In DL 1999,
International Workshop on Description Logics.
Glen Hart, Martina Johnson, and Catherine Dolbear.
2008. Rabbit: developing a control natural language
for authoring ontologies. In ESWC 2008, European
Semantic Web Conference, pages 348?360.
Helmut Horacek. 1999. Presenting Proofs in a Human-
Oriented Way. In CADE 1999, International Confer-
ence on Automated Deduction, pages 142?156.
Matthew Horridge, Bijan Parsia, and Ulrike Sattler.
2008. Laconic and Precise Justifications in OWL. In
ISWC 2008, International Semantic Web Conference,
pages 323?338.
Matthew Horridge, Bijan Parsia, and Ulrike Sattler.
2009. Lemmas for Justifications in OWL. In DL 2009,
International Workshop on Description Logics.
Matthew Horridge, Bijan Parsia, and Ulrike Sattler.
2010. Justification Oriented Proofs in OWL. In ISWC
2010, International Semantic Web Conference, pages
354?369.
Xiaorong Huang. 1994. Human Oriented Proof Presen-
tation: A Reconstructive Approach. Ph.D. thesis, The
University of Saarbru?cken, Germany.
Kaarel Kaljurand and Norbert Fuchs. 2007. Verbaliz-
ing OWL in Attempto Controlled English. In OWLED
2007, International Workshop on OWL: Experiences
and Directions.
Aditya Kalyanpur. 2006. Debugging and repair of OWL
ontologies. Ph.D. thesis, The University of Maryland,
US.
Deborah Louise McGuinness. 1996. Explaining reason-
ing in description logics. Ph.D. thesis, The State Uni-
versity of New Jersey, US.
Tu Anh T. Nguyen, Paul Piwek, Richard Power, and San-
dra Williams. 2010. Justification Patterns for OWL
DL Ontologies. Technical Report TR2011/05, The
Open University, UK.
Rolf Schwitter and Thomas Meyer. 2007. Sydney OWL
Syntax - towards a Controlled Natural Language Syn-
tax for OWL 1.1. In OWLED 2007, International
Workshop on OWL: Experiences and Directions.
Robert Stevens, James Malone, Sandra Williams,
Richard Power, and Allan Third. 2011. Automating
generation of textual class definitions from OWL to
English. Journal of Biomedical Semantics, 2(S 2:S5).
Dmitry Tsarkov and Ian Horrocks. 2006. FaCT++ De-
scription Logic Reasoner: System Description. In IJ-
CAR 2006, International Joint Conference on Auto-
mated Reasoning, pages 292?297.
114
Proceedings of the 2th Workshop of Natural Language Processing for Improving Textual Accessibility (NLP4ITA), pages 39?48,
Atlanta, Georgia, 14 June 2013. c?2013 Association for Computational Linguistics
A System for the Simplification of Numerical Expressions at Different Levels
of Understandability
Susana Bautista, Raquel Herva?s,
Pablo Gerva?s
Universidad Complutense de Madrid
Prof. Jose? Garc??a Santesmases
Madrid, Spain
{subautis,raquelhb}@fdi.ucm.es
pgervas@sip.ucm.es
Richard Power, Sandra Williams
Department of Computing,
The Open University
Milton Keynes,
MK76AA, UK
r.power@open.ac.uk
s.h.williams@open.ac.uk
Abstract
The purpose of this paper is to motivate and
describe a system that simplifies numerical
expression in texts, along with an evaluation
study in which experts in numeracy and liter-
acy assessed the outputs of this system. We
have worked with a collection of newspaper
articles with a significant number of numerical
expressions. The results are discussed in com-
parison to conclusions obtained from a prior
empirical survey.
1 Introduction
A surprisingly large number of people have limited
access to information because of poor literacy. The
most recent surveys of literacy in the United King-
dom reveal that 7 million adults in England can-
not locate the reference page for plumbers if given
the Yellow Pages alphabetical index. This means
that one in five adults has less literacy than the ex-
pected literacy in an 11-year-old child (Jama and
Dugdale, 2010; Williams et al, 2003a; Christina and
Jonathan, 2010). Additionally, almost 24 million
adults in the U.K. have insufficient numeracy skills
to perform simple everyday tasks such as paying
household bills and understanding wage slips. They
would be unable to achieve grade C in the GCSE
maths examination for 16-year-old school children
(Williams et al, 2003a).
?The Standard Rules on the Equalization of Op-
portunities for Persons with Disabilities? by United
Nations (1994) state that all public information ser-
vices and documents should be accessible in such
a way that they could be easily understood. If we
focus on numerical information, nowadays, a large
percentage of information expressed in daily news
or reports comes in the form of numerical expres-
sions (economic statistics, demography data, etc)
but many people have problems understanding the
more complex expressions. In the text simplification
process, different tasks are carried out: replacing
difficult words, splitting sentences, etc., and the sim-
plification of numerical expressions is one of them.
A possible approach to solve this important social
problem of making numerical information accessi-
ble is to rewrite difficult numerical expressions using
alternative wordings that are easier to understand.
For example, the original sentence, ?25.9% scored A
grades? could be rewritten by ?Around 26% scored
A grades?. In our study we define a ?numerical ex-
pression? as a phrase that presents a quantity, some-
times modified by a numerical hedge as in these ex-
amples: ?less than a quarter? or ?about 98%?. Such
an approach would require a set of rewriting strate-
gies yielding expressions that are linguistically cor-
rect, easier to understand than the original, and as
close as possible to the original meaning. Some loss
of precision could have positive advantages for nu-
merate people as well as less numerate. In rewrit-
ing, hedges play also an important role. For exam-
ple, ?50.9%? could be rewritten as ?about a half? us-
ing the hedge ?about?. In this kind of simplification,
hedges indicate that the original number has been
approximated and, in some cases, also the direction
of the approximation.
This paper presents a system developed for auto-
mated simplification of numerical expressions. Ex-
perts in simplification tasks are asked to validate the
39
simplifications done automatically. The system is
evaluated and the results are discussed against con-
clusions obtained from previous empirical survey.
2 Previous work
Text simplification, a relative new task in Natural
Language Processing, has been directed mainly at
syntactic constructions and lexical choices that some
readers find difficult, such as long sentences, pas-
sives, coordinate and subordinate clauses, abstract
words, low frequency words, and abbreviations.
The rule-based paradigm has been used in the
implementation of some systems for text simpli-
fication, each one focusing on a variety of read-
ers (with poor literacy, aphasia, etc) (Chandrasekar
et al, 1996; Siddharthan, 2003; Jr. et al, 2009;
Bautista et al, 2009).
The transformation of texts into easy-to-read ver-
sions can also be phrased as a translation problem
between two different subsets of language: the orig-
inal and the easy-to-read version. Corpus-based sys-
tems can learn from corpora the simplification oper-
ations and also the required degree of simplification
for a given task (Daelemans et al, 2004; Petersen
and Ostendorf, 2007; Gasperin et al, 2009).
A variety of simplification techniques have been
used, substituting common words for uncommon
words (Devlin and Tait, 1998), activating passive
sentences and resolving references (Canning, 2000),
reducing multiple-clause sentences to single-clause
sentences (Chandrasekar and Srinivas, 1997; Can-
ning, 2000; Siddharthan, 2002) and making appro-
priate choices at the discourse level (Williams et al,
2003b). Khan et at. (2008) studied the tradeoff be-
tween brevity and clarity in the context of generat-
ing referring expressions. Other researchers have fo-
cused on the generation of readable texts for readers
with low basic skills (Williams and Reiter, 2005),
and for teaching foreign languages (Petersen and
Ostendorf, 2007).
Previous work on numerical expressions has stud-
ied the treatment of numerical information in differ-
ent areas like health (Peters et al, 2007), forecast
(Dieckmann et al, 2009), representation of proba-
bilistic information (Bisantz et al, 2005) or vague
information (Mishra et al, 2011). In the NUM-
GEN project (Williams and Power, 2009), a corpus
of numerical expressions was collected and a for-
mal model for planning specifications for propor-
tions (numbers between 0 and 1) was developed.
The underlying theory and the design of the work-
ing program are described in (Power and Williams,
2012).
3 Experimental identification of
simplification strategies for numerical
information
In order to analyze different simplification strategies
for numerical expressions, first we have to study the
mathematical complexity of the expressions. Ex-
pressions can be classified and a level of difficulty
can be assigned. A study about the simplification
strategies selected by experts to simplify numerical
expressions expressed as decimal percentages in a
corpus was carried out in Bautista et al (2011b).
Other important aspect of the simplification task is
the use of hedges to simplify numerical expressions
in the text. A study was performed in Bautista et
al. (2011a) to analyze the use of hedges in the sim-
plification process. This study was done with ex-
perts in simplification tasks. A set of sentences with
numerical expressions were presented and they had
to rewrite the numerical expressions following some
rules. Several hypotheses were expressed and an-
alyzed to understand experts? preferences on sim-
plification strategies and use of hedges to simplify
numerical expressions in the text. The main conclu-
sions from the study were:
Conclusion 1: When experts choose expressions
for readers with low numeracy, they tend to prefer
round or common values to precise values. For ex-
ample, halves, thirds and quarters are usually pre-
ferred to eighths or similar, and expressions like N
in 10 or N in 100 are chosen instead of N in 36.
Conclusion 2: The value of the original propor-
tion influences the choice of simplification strategies
(fractions, ratios, percentages). With values in the
central range (say 0.2 to 0.8 in a 0.0 to 1.0 scale)
and values at the extreme ranges (say 0.0-0.2 and
0.8-1.0) favoring different strategies.
Conclusion 3: When writers choose numerical
expressions for readers with low numeracy, they
only use hedges if they are losing precision.
40
4 A system for adapting numerical
expressions
In this first prototype, only numerical expressions
defined as percentages are adapted. From an in-
put text, the percentage numerical expressions are
detected, a target level of difficulty is chosen and
the simplified version of the text is generated by re-
placing the original numerical expression with the
adapted expression.
4.1 Numerical expression
A numerical expression consists of: (1) a numerical
value, a quantity which may be expressed with dig-
its or with words; (2) an optional unit accompanying
the quantity (euro, miles, . . . ); and (3) an optional
numerical hedge modifier (around, less than, . . . ).
Some examples of numerical expressions used in
our experiments are: ?more than a quarter?, ?around
98.2%?, ?just over 25 per cent? or ?less than 100 kilo-
metres?.
4.2 Levels of difficulty
The Mathematics Curriculum of the Qualifications
and Curriculum Authority (1999) describes a num-
ber of teaching levels and we assume that concepts
to be taught at lower levels will be simpler than ones
taught at higher levels. Following this idea a Scale of
Mathematic Concepts is defined to identify the dif-
ferent levels of difficulty to understand mathematic
concepts. The scale defined from less to greater dif-
ficulty is: numerical expression in numbers (600),
words (six), fractions (1/4), ratios (1 in 4), percent-
ages (25%) and decimal percentages (33.8%).
From the Scale of Mathematic Concepts defined,
different levels of difficulty are considered in our
system. There are three different levels (from eas-
iest to hardest):
1. Fractions Level: each percentage in the text is
adapted using fractions as mathematical form
for the quantity, and sometimes a hedge is used.
2. Percentages without decimals Level (PWD):
the system rounds the original percentage with
decimals and uses hedges if they are needed.
3. Percentages with decimals Level: This is the
most difficult level where no adaptation is per-
formed.
The system operates only on numerical expres-
sions at the highest levels of the scale (the most dif-
ficult levels), that is, numerical expression given in
percentages or decimal percentages, adapting them
to other levels of less difficulty. So, the user can
select the level to which adapt the original numeri-
cal expression from the text. Using the interface of
the system, the level of difficulty is chosen by the fi-
nal user and the numerical expressions from the text
with higher level of difficulty than the level chosen
are adapted following the rules defined.
4.3 Set of strategies
A set of strategies is defined so they can be applied to
adapt the original numerical expression. The quan-
tity of the expression is replaced with another ex-
pression and sometimes numerical hedges are added
to create the simplified numerical expression.
The use of hedges to simplify numerical expres-
sion can be influenced by three parameters. The first
is the type of simplification depending on the math-
ematical knowledge of the final user. The second is
the simplification strategy for the choice of the final
mathematical form. And the last is the loss of preci-
sion that occurs when the expression is simplified.
Out of the European Guidelines for the Produc-
tion of Easy-to-Read Information for People with
Learning Disability (Freyhoff et al, 1998), only one
involves the treatment of numbers: ?Be careful with
numbers. If you use small numbers, always use the
number and not the word?. For example, if the texts
says ?four?, the system adapts it by ?4? following this
European Guideline. This strategy is applied by the
system at all levels.
There are other strategies to adapt numerical ex-
pressions in the form of percentage to other levels of
difficulty: (1) replace decimal percentages with per-
centages without decimals; (2) replace decimal per-
centages with ratios; (3) replace percentages with ra-
tios; (4) replace decimal percentages with fractions;
(5) replace percentages with fractions; (6) replace
ratios with fractions; (7) replace numerical expres-
sions in words with numerical expressions in digits.
At each level of difficulty, a subset of the strate-
gies is applied to simplify the numerical expression.
For the Fractions Level the strategies 4, 5 and 7
are used. For the Percentages with decimals Level
the strategies 1 and 7 are applied. And for the last
41
level, Percentages without decimals Level only the
last strategy, number 7, is used.
4.4 System operation
The system takes as input the original text. The user
of the system has to choose the level of difficulty. A
set of numerical expressions are selected and a set
of transformations is applied to adapt them, generat-
ing as output of the system a text with the numerical
expressions simplified at the chosen level.
The system works through several phases to adapt
the numerical expressions in the input text. Some of
them are internal working phases (2, 4 and 5). The
rest of them (1, 3 and 6) are phases where the user
of the system plays a role. The phases considered in
the system are:
1. Input text: an original text is selected to adapt
its numerical expressions.
2. Mark Numerical Expressions: the numerical
expressions that can be adapted are marked.
3. Choose the level of difficulty: the user chooses
the desired level of difficulty for the numerical
expressions in the text.
4. Adapt the numerical expression from the
text: each numerical expression is adapted if
the level of the numerical expression is higher
than the level of difficulty chosen.
5. Replace numerical expression in the text:
adapted numerical expressions replace the orig-
inals in the text.
6. Output text: the final adapted version of the
text is presented to the user.
The next subsections presents how the system acts
in each phase and what kind of tools are used to
achieve the final text.
4.4.1 Phase 1: Input text
In this first phase, a plain text is chosen as input to
the system to adapt its numerical expressions. Using
a Graphical User Interface (GUI) in Java, the user
can upload an original text.
4.4.2 Phase 2: Mark numerical expressions
For the text chosen, the system executes the Nu-
merical Expression Parser1. Using this parser the
numerical quantities are annotated with their type
(cardinal, fraction, percentage, decimal percentage,
etc.), their format (words, digits), their value (Vg),
their units, and hedging phrases, such as ?more
than?. The input to the program is the plain text file
and the output is the text with sentences and numer-
ical expressions annotated in XML format. In the
following code we can see how a numerical quantity
is annotated in the parser.
Overall figures showed the national pass
rate soared
<numex hedge=?above? hedge-
sem=?greaterthan? type=?percentage?
format=?digits? Vg=?0.97?>
above 97% </numex>
The XML file is treated by the system and numer-
ical expressions are marked in the original text. So,
the user can see which numerical expressions are go-
ing to be adapted by the system (in the next phase)
depending on the level of difficulty chosen.
4.4.3 Phase 3: Choose the level of difficulty
The user of the system chooses the level of dif-
ficulty to adapt the original numerical expressions.
There are three levels: fractions, percentages with-
out decimals and percentages with decimals.
4.4.4 Phase 4: Adapt the Numerical
Expressions
After deciding the level of difficulty, the system
has to adapt each numerical expression to generate
the final version. The process of simplification has
two stages: obtaining the candidate and applying the
adaptation and hedge choice rules.
From the XML file produced by the parser the fol-
lowing information for a numerical expression is ob-
tained: (1) if there is or not hedge and the kind of
hedge; (2) the type (cardinal, fraction, percentage,
decimal percentage) and format (digits or words)
of the original numerical expression; (3) the given
value (Vg) translated from the original numerical ex-
pression value of the text; and (4) the units from the
1For more details see (Williams, 2010)
42
O
rig
in
al
 
Ex
pr
es
sio
n
Pa
rs
er
Vm
g
Pr
op
or
tio
n
Ap
pr
ox
.
Pr
og
ra
m
Vr
M
or
e 
th
an
 2
8%
0.
28
0.
28
1/
3
0.
33
Vg
Vc
[0
...
1]
[0
...
1]
1/
3
30
%
28
%
Figure 1: Obtaining the candidate for simplification. The original expression is annotated by the parser (Vg), and this
value is normalized (Vmg). A candidate substitute value (Vc) is chosen from the proportion approximation program
and normalized (Vr).
original expression (M, ins, grams). For example,
if in the text the original numerical expression is a
percentage like ?25.9%?, there is no hedge, the type
is ?decimal percentage?, the format is ?digits?, Vg is
0.259 and there are no units. In the expression, ?20
grams?, there is no hedge, the type is ?cardinal?, the
format is ?digits?, Vg is 20 and the parser annotates
the units with ?g?.
The given value Vg annotated by the parser is
transformed into a value between 0 to 1, referred
to as mapping given value (Vmg), which represents
the proportion under consideration. This value is
given as input to the proportion approximation pro-
gram (Power and Williams, 2012), which returns a
list of candidates for substitution. From this list,
the first option is taken as candidate substitute value
(Vc), because the program returns them in decreas-
ing order of precision. This means that the most
precise candidate at the required level of difficulty
is chosen. The program also might return the val-
ues ?none? and ?all? if the input value is close to
0 or 1, respectively. From the Vc we calculate the
rounded value (Vr) corresponding to the normaliza-
tion of the candidate value between 0 to 1. For ex-
ample, if Fraction level is chosen, for the original
expression ?more than 28%? with Vmg=0.28, the
system chooses Vc=1/3 with Vr=0.33. The whole
process can be seen in Figure 1.
An additional level of adaptation is required be-
yond simple replacement with the candidate substi-
tute value. If the original numerical expressions in
the text are difficult to understand, the system must
adapt them to the desired level of difficulty. For each
numerical expression, the system only applies the
adaptation rules if the difficulty level of the numer-
ical expression is higher than the level of difficulty
chosen by the user. This is captured by a set of three
adaptation rules:
? If the type of the numerical expression is ?car-
dinal? and the format is ?words? then the candi-
date to be used in the simplification is Vg. For
example, if the original numerical expression is
?six?, it will be replaced by ?6?.
? In a similar way, if the type is ?fraction? (the
lowest possible level of difficulty) and the for-
mat is also ?words? then the candidate is ob-
tained by applying the proportion approxima-
tion program. For example, if the original nu-
merical expression is ?a quarter?, it would be
replaced by ?1/4?.
? If the type is ?percentages? or ?decimal percent-
ages? and the format is ?digits? then the can-
didate is calculated by the proportion approxi-
mation program provided that the level of dif-
ficulty chosen in the GUI was lower than the
level of the calculated numerical expression.
In order to complete the simplification, the system
has to decide if a hedge should be used to achieve
the final version of the adapted numerical expres-
sion. This decision is taken based on the difference
in value between the value of the original expression
in the text (Vg) and the value of the candidate substi-
tute (Vc) (as given by the relative difference between
the normalized values Vr and Vmg calculated in the
first stage). The actual hedge used in the original
expression (if any) is also considered. The various
possible combinations of these values, and the corre-
sponding choice of final hedge, are described in Ta-
ble 1, which presents all possible options to decide
in each case, the hedge and the value corresponding
to the final numerical expression. For example, if
the original expression is ?more than 28%?, we have
Vc=1/3, Vmg=0.28 and Vr=0.33. Then Vr>Vmg so
the corresponding choice of the final hedge is in the
43
OriginalNumExp if Vr>Vmg if Vr=Vmg if Vr<Vmg
more than OrigValue around Vc more than Vc more than Vc
exactly OrigValue less than Vc exactly Vc more than Vc
less than OrigValue less than Vc less than Vc around Vc
OrigValue around Vc Vc around Vc
Table 1: Hedge Choice Rules. For each original expression (OrigValue), the normalized values (Vmg, Vr) are used to
determinate the hedge chosen for the simplified expression. The final version is composed by the hedge chosen and
the candidate value (Vc)
first column of Table 1 (?around?) and the simplified
expression is ?around 1/3?.
When the user chooses the Fraction Level in the
system, every numerical expression with difficulty
level greater than fraction level will be replaced by
a numerical expression expressed in fraction form.
Depending on the values Vr and Vmg, the appropri-
ate hedge will be chosen.
4.4.5 Phase 5: Replace numerical expressions
Once the system has applied its rules, an adapted
version is available for each original numerical ex-
pression which was more difficult than the target dif-
ficulty level. The output text is obtained by replac-
ing these difficult expressions with the correspond-
ing simplified version.
5 Evaluation of the system
This section presents the evaluation of the system,
describing the materials, experiment, participants
and results of the evaluation.
5.1 Materials
We selected for the experiment a set of eight can-
didate sentences from the NUMGEN corpus, but the
number of numerical expressions was larger as some
sentences contained more than one proportion ex-
pression. In total we had 13 numerical expressions.
We selected sentences with as many variations in
context, precision and different wordings as possi-
ble. The range of proportions values was from points
nearly 0.0 to almost 1.0, to give coverage to a wide
spread of proportion values. We considered values
in the central range (say 0.2 to 0.8) and values at the
extreme ranges (say 0.0-0.2 and 0.8-1.0). We also
classified as common values the well-known per-
centages and fractions like 25%, 50%, 1/4 and 1/2,
and as uncommon values the rest like 15% or 6/7.
5.2 Experiment
To evaluate the system a questionnaire was pre-
sented to a set of human evaluators. The experi-
ment was created and presented on SurveyMonkey2,
a commonly-used provider of web surveys. For each
original sentence, we presented two possible simpli-
fications generated by the system. Participants were
asked to use their judgement to decide whether they
agreed that the simplified sentences were acceptable
for the original sentence. A Likert scale of four val-
ues (Strongly Disagree, Disagree, Agree, Strongly
Agree) was used to collect the answers.
In the survey only two levels of adaptation from
the original sentence were presented. The first op-
tion generated by the system was for the Fractions
level. The second option generated by the system
was for the Percentages without decimals (PWD).
5.3 Participants
The task of simplifying numerical expressions is dif-
ficult, so we selected a group of 34 experts made up
of primary or secondary school mathematics teach-
ers or adult basic numeracy tutors, all native English
speakers. This group is well qualified to tackle the
task since they are highly numerate and accustomed
to talking to people who do not understand mathe-
matical concepts very well. We found participants
through personal contacts and posts to Internet fo-
rums for mathematics teachers and numeracy tutors.
5.4 Results
The answers from the participants were evaluated.
In total we collected 377 responses, 191 responses
for the Fraction level and 186 responses for the Per-
centage without decimals (PWD). Table 2 shows the
average from the collected responses, considering 1
2http://www.surveymonkey.com/s/WJ69L86
44
Level Total average Values Average Values Average
Fraction 2,44
Central 2,87 Common 2,59
Extreme 2,14 Uncommon 1,21
PWD 2,96
Central 3,00 Common 2,80
Extreme 2,96 Uncommon 3,22
Table 2: System Evaluation: Fraction Level and Percentages Without Decimals (PWD)
Opinion Fraction PWD
Level Level
Strongly Disagree 19% 6%
Disagree 27% 15%
Agree 43% 56%
Strongly Agree 11% 23%
Table 3: Opinion of the experts in percentages
to 4 for strongly disagree to strongly agree. In ad-
dition, Table 3 shows the distribution in percentages
of the opinion of the experts. At the Fraction level,
there is not too much difference between the average
of the answers of the experts that agree with the sys-
tem and those that disagree. Most experts are neu-
tral. But for the PWD level the average shows that
most experts agree with the simplification done.
We have also analyzed the answers considering
two different criteria from the original numerical ex-
pressions: when they are central (20% to 80%) or
extreme values (0% to 20% and 80% to 100%), and
when the original numerical expressions are com-
mon or uncommon values. In general terms, the ex-
perts think that the simplification done by the sys-
tem in the PWD level is better than the simplification
done in the Fraction level. They disagree specially
with the simplification using fractions in two cases.
One is the treatment of the extreme values where the
system obtains as possible candidates ?none? and
?all?3. Another case is when uncommon fractions
are used to simplify the numerical expression, like
for example 9/10. In these two cases the average is
lower than the rest of the average achieved.
5.5 Discussion
The system combines syntactic transformations (via
the introduction of hedges) and lexical substitu-
3See (Power and Williams, 2012) for a discussion of appro-
priate hedges for values near the extreme points of 0 and 1.
tions (by replacing actual values with substitution
candidates and transforming quantities expressed as
words into digits) to simplify the original numerical
expression. These kinds of transformations are dif-
ferent from those used by other systems, which rely
only on syntactic transformations or only on lexi-
cal substitutions. Rules are purpose-specific and fo-
cused on numerical expressions. With this kind of
transformations the readability of the text improves
in spite of the fact that the resulting syntactic struc-
ture of the numerical expression is more compli-
cated, due to the possible presence of hedges. For
example, for a original numerical expression like
?25.9%? the system generates the simplified ?more
than a quarter? which is easier to understand even
though longer and syntactically more complex.
With respect to coverage of different types of nu-
merical expressions, this system does not consider
ratios as a possible simplification strategy because
the proportion approximation program does not use
them as candidates to simplify a proportion. This
possibility should be explored in the future.
Another observation is that the system does not
consider the context of the sentence in which the
numerical expression occurs. For example, if the
sentence makes a comparison between two numer-
ical expressions that the system rounded to the same
value, the original meaning is lost. One example
of this case is the following sentence from the cor-
pus: ?One in four children were awarded A grades
(25.9%, up from 25.3% last year)?. Both percent-
ages ?25.9%? and ?25.3%? are simplified by the sys-
tem using ?around 1/4? and the meaning of the sen-
tence is lost. Thus we should consider the role of
context (the set of numerical expressions in a given
sentence as a whole and the meaning of the text) in
establishing what simplifications must be used.
45
6 Conforming with conclusions of prior
surveys
The results presented for the system are evaluated
in this section for conformance with the conclusions
resulting from the empirical studies described in
(Bautista et al, 2011b) and (Bautista et al, 2011a).
With respect to the preference for round or com-
mon values in simplification (Conclusion 1), the sys-
tem presented conforms to this preference by virtue
of the way in which the list of candidate substitu-
tions is produced by the program. The candidates re-
turned by the program are already restricted to com-
mon values of percentages (rounded up) and frac-
tions, so the decision to consider as preferred candi-
date the one listed first implicitly applies the criteria
that leads to this behavior.
With respect to the need to treat differently values
in the extreme or central ranges of proportion (Con-
clusion 2), the system addresses this need by virtue
of the actual set of candidates produced by the pro-
gram in each case. For example, if the original ex-
pression is a extreme value like ?0.972?, the program
produces a different candidate substitution (?almost
all?) that in the central ranges is not considered.
With respect to restricting the use of hedges to
situations where loss of precision is incurred (Con-
clusion 3), the hedge choice rules applied by the
system (see Table 1) satisfy this restriction. When
Vr=Vmg hedges are included in the simplified ex-
pression only if they were already present in the
original expression.
In addition, the system rounds up any quantities
with decimal positions to the nearest whole num-
ber whenever the decimal positions are lost during
simplification. This functionality is provided im-
plicitly by the program, which presents the rounded
up version as the next option immediately follow-
ing the alternative which includes the decimal posi-
tions. For example, if the input proportion is ?0.198?,
some rounded candidate substitutions are calculated
as ?almost 20%? or ?less than 20%?.
Finally, the system follows the European guide-
lines for the production of easy to read information
in that it automatically replaces numerical quantities
expressed in words with the corresponding quantity
expressed in digits.
7 Conclusions and future work
The system described in this paper constitutes a first
approximation to the task of simplifying numerical
expressions in a text to varying degrees of difficulty.
The definition of an scale of difficulty of numeri-
cal expressions, the identification of rules governing
the selection of candidate substitution and the appli-
cation of hedges constitute important contributions.
The empirical evaluation of the system with human
experts results in acceptable rates of agreement. The
behavior of the system conforms to the conclusions
on simplification strategies as applied by humans re-
sulting from previous empirical surveys.
There are different aspects to improve the actual
system from the data collected, with a special atten-
tion to cases in which the experts disagree. As future
work, the syntactic context should be considered to
simplify numerical expression, extending the kind
of proportion to simplify and treating special cases
analyzed in this first version. At the syntactic level,
some transformation rules can be implemented from
a syntactic analysis. It is important that the meaning
of the sentences be preserved regardless of whether
part of the sentence is deleted or rewritten by the
adaptation rules. In addition, the numerical expres-
sion parser and the proportion approximation pro-
gram could also be studied in order to evaluate the
impact of their errors in the final performance.
Our final aim is to develop an automatic simplifi-
cation system in a broader sense, possibly including
more complex operations like syntactic transforma-
tions of the structure of the input text, or lexical sub-
stitution to reduce the complexity of the vocabulary
employed in the text. Additionally we hope to de-
velop versions of the simplification system for other
languages, starting with Spanish. Probably the sim-
plification strategies for numbers would be the same
but the use of hedge modifiers may be different.
Acknowledgments
This research is funded by the Spanish Ministry
of Education and Science (TIN2009-14659-C03-01
Project), Universidad Complutense de Madrid and
Banco Santander Central Hispano (GR58/08 Re-
search Group Grant), and the FPI grant program.
46
References
Susana Bautista, Pablo Gerva?s, and Ignacio Madrid.
2009. Feasibility Analysis for SemiAutomatic Con-
version of Text to Improve Readability. In Proceed-
ings of The Second International Conference on Infor-
mation and Communication Technologies and Acces-
sibility, Hammamet, Tunusia, May.
Susana Bautista, Raquel Herva?s, Pablo Gerva?s, Richard
Power, and Sandra Williams. 2011a. Experimental
identification of the use of hedges in the simplifica-
tion of numerical expressions. In Proceedings of the
Second Workshop on Speech and Language Process-
ing for Assistive Technologies, pages 128?136, Edin-
burgh, Scotland, UK, July. Association for Computa-
tional Linguistics.
Susana Bautista, Raquel Herva?s, Pablo Gerva?s, Richard
Power, and Sandra Williams. 2011b. How to
Make Numerical Information Accessible: Experimen-
tal Identification of Simplification Strategies. In Cam-
pos, Pedro and Graham, Nicholas and Jorge, Joaquim
and Nunes, Nuno and Palanque, Philippe and Winck-
ler, Marco, editor, Human-Computer Interaction IN-
TERACT 2011, volume 6946 of Lecture Notes in Com-
puter Science, pages 57?64. Springer Berlin / Heidel-
berg.
Ann M. Bisantz, Stephanie Schinzing, and Jessica
Munch. 2005. Displaying uncertainty: Investigating
the effects of display format and specificity. Human
Factors: The Journal of the Human Factors and Er-
gonomics Society, 47(4):777.
Yvonne Canning. 2000. Cohesive simplification of
newspaper text for aphasic readers. In 3rd annual
CLUK Doctoral Research Colloquium.
Raman Chandrasekar and Bangalore Srinivas. 1997.
Automatic induction of rules for text simplification.
Knowledge-Based Systems, 10.
Raman Chandrasekar, Christine Doran, and Bangalore
Srinivas. 1996. Motivations and methods for text
simplification. In In Proceedings of the Sixteenth In-
ternational Conference on Computational Linguistics
(COLING ?96), pages 1041?1044.
Clark Christina and Douglas Jonathan. 2010. Young
people reading and writing today: Whether, what and
why. Technical report, London: National Literacy
Trust.
Walter Daelemans, Anja Hothker, and Erik Tjong Kim
Sang. 2004. Automatic Sentence Simplification for
Subtitling in Dutch and English. In Proceedings of the
4th Conference on Language Resources and Evalua-
tion, pages 1045?1048, Lisbon, Portugal.
Siobhan Devlin and John Tait. 1998. The use of a
Psycholinguistic database in the Simplification of Text
for Aphasic Readers. Lecture Notes. Stanford, USA:
CSLI.
Nathan Dieckmann, Paul Slovic, and Ellen Peters. 2009.
The use of narrative evidence and explicit likelihood
by decision makers varying in numeracy. Risk Analy-
sis, 29(10).
Geert Freyhoff, Gerhard Hess, Linda Kerr, Elizabeth
Menzel, Bror Tronbacke, and Kathy Van Der Veken.
1998. European guidelines for the production of easy-
to-read information.
Caroline Gasperin, Lucia Specia, Tiago F. Pereira, and
Sandra M. Aluisio. 2009. Learning when to simplify
sentences for natural text simplification. In Proceed-
ings of the Encontro Nacional de Inteligencia Artificial
(ENIA), pages 809?818, Bento Gonalves, Brazil.
Deeqa Jama and George Dugdale. 2010. Literacy: State
of the nation. Technical report, National Literacy
Trust.
Arnaldo Candido Jr., Erick Maziero, Caroline Gasperin,
Thiago A. S. Pardo, Lucia Specia, and Sandra M.
Aluisio. 2009. Supporting the Adaptation of Texts
for Poor Literacy Readers: a Text Simplification Ed-
itor for Brazilian Portuguese. In Proceedings of the
NAACL/HLT Workshop on Innovative Use of NLP
for Building Educational Applications, pages 34?42,
Boulder, Colorado.
Imtiaz Hussain Khan, Kees Deemter, and Graeme
Ritchie. 2008. Generation of refering expressions:
managing structural ambiguities. In Proceedings of
the 22nd International Conference on Computational
Linguistics(COLING), pages 433?440, Manchester.
Himanshu Mishra, Arul Mishra, and Baba Shiv. 2011.
In praise of vagueness: malleability of vague informa-
tion as a performance booster. Psychological Science,
22(6):733?8, April.
Ellen Peters, Judith Hibbard, Paul Slovic, and Nathan
Dieckmann. 2007. Numeracy skill and the commu-
nication, comprehension, and use of risk-benefit infor-
mation. Health Affairs, 26(3):741?748.
Sarah E. Petersen and Mari Ostendorf. 2007. Text Sim-
plification for Language Learners: A Corpus Analysis.
In Proceedings of Workshop on Speech and Language
Technology for Education (SLaTE).
Richard Power and Sandra Williams. 2012. Generating
numerical approximations. Computational Linguis-
tics, 38(1).
Qualification and Curriculum Authority. 1999. Mathe-
matics: the National Curriculum for England. Depart-
ment for Education and Employment, London.
Advaith Siddharthan. 2002. Resolving attachment and
clause boundary amgiguities for simplifying relative
clause constructs. In Proceedings of the Student Re-
search Workshop, 40th Meeting of the Association for
Computacional Linguistics.
47
Advaith Siddharthan. 2003. Syntactic Simplification and
Text Cohesion. Ph.D. thesis, University of Cambridge.
United Nations. 1994. Standard Rules on the Equal-
ization of Opportunities for Persons with Disabilities.
Technical report.
Sandra Williams and Richard Power. 2009. Precision
and mathematical form in first and subsequent men-
tions of numerical facts and their relation to document
structure. In Proc. of the 12th European Workshop on
Natural Language Generation, Athens.
Sandra Williams and Ehud Reiter. 2005. Generating
readable texts for readers with low basic skills. In
Proceeding of the 10th European Workshop on Natu-
ral Language Generation, pages 140?147, Aberdeen,
Scotland.
Joel Williams, Sam Clemens, Karin Oleinikova, and
Karen Tarvin. 2003a. The Skills for Life survey: A
national needs and impact survey of literacy, numer-
acy and ICT skills. Technical Report Research Report
490, Department for Education and Skills.
Sandra Williams, Ehud Reiter, and Liesl Osman. 2003b.
Experiments with discourse-level choices and read-
ability. In In Proceedings of the European Natu-
ral Language Generation Workshop (ENLG) and 11th
Conference of the European Chapter of the Associa-
tion for Computational Linguistics (EACL03), pages
127?134.
Sandra Williams. 2010. A Parser and Information
Extraction System for English Numerical Expres-
sions. Technical report, The Open University, Milton
Keynes, MK7 6AA, U.K.
48
