Proceedings of ACL-08: HLT, pages 843?851,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
An Entity-Mention Model for Coreference Resolution
with Inductive Logic Programming
Xiaofeng Yang1 Jian Su1 Jun Lang2
Chew Lim Tan3 Ting Liu2 Sheng Li2
1Institute for Infocomm Research
{xiaofengy,sujian}@i2r.a-star.edu.sg
2Harbin Institute of Technology
{bill lang,tliu}@ir.hit.edu.cn
lisheng@hit.edu.cn
3National University of Singapore,
tancl@comp.nus.edu.sg
Abstract
The traditional mention-pair model for coref-
erence resolution cannot capture information
beyond mention pairs for both learning and
testing. To deal with this problem, we present
an expressive entity-mention model that per-
forms coreference resolution at an entity level.
The model adopts the Inductive Logic Pro-
gramming (ILP) algorithm, which provides a
relational way to organize different knowledge
of entities and mentions. The solution can
explicitly express relations between an entity
and the contained mentions, and automatically
learn first-order rules important for corefer-
ence decision. The evaluation on the ACE data
set shows that the ILP based entity-mention
model is effective for the coreference resolu-
tion task.
1 Introduction
Coreference resolution is the process of linking mul-
tiple mentions that refer to the same entity. Most
of previous work adopts the mention-pair model,
which recasts coreference resolution to a binary
classification problem of determining whether or not
two mentions in a document are co-referring (e.g.
Aone and Bennett (1995); McCarthy and Lehnert
(1995); Soon et al (2001); Ng and Cardie (2002)).
Although having achieved reasonable success, the
mention-pair model has a limitation that informa-
tion beyond mention pairs is ignored for training and
testing. As an individual mention usually lacks ad-
equate descriptive information of the referred entity,
it is often difficult to judge whether or not two men-
tions are talking about the same entity simply from
the pair alone.
An alternative learning model that can overcome
this problem performs coreference resolution based
on entity-mention pairs (Luo et al, 2004; Yang et
al., 2004b). Compared with the traditional mention-
pair counterpart, the entity-mention model aims to
make coreference decision at an entity level. Classi-
fication is done to determine whether a mention is a
referent of a partially found entity. A mention to be
resolved (called active mention henceforth) is linked
to an appropriate entity chain (if any), based on clas-
sification results.
One problem that arises with the entity-mention
model is how to represent the knowledge related to
an entity. In a document, an entity may have more
than one mention. It is impractical to enumerate all
the mentions in an entity and record their informa-
tion in a single feature vector, as it would make the
feature space too large. Even worse, the number of
mentions in an entity is not fixed, which would re-
sult in variant-length feature vectors and make trou-
ble for normal machine learning algorithms. A solu-
tion seen in previous work (Luo et al, 2004; Culotta
et al, 2007) is to design a set of first-order features
summarizing the information of the mentions in an
entity, for example, ?whether the entity has any men-
tion that is a name alias of the active mention?? or
?whether most of the mentions in the entity have the
same head word as the active mention?? These fea-
tures, nevertheless, are designed in an ad-hoc man-
ner and lack the capability of describing each indi-
vidual mention in an entity.
In this paper, we present a more expressive entity-
843
mention model for coreference resolution. The
model employs Inductive Logic Programming (ILP)
to represent the relational knowledge of an active
mention, an entity, and the mentions in the entity. On
top of this, a set of first-order rules is automatically
learned, which can capture the information of each
individual mention in an entity, as well as the global
information of the entity, to make coreference deci-
sion. Hence, our model has a more powerful repre-
sentation capability than the traditional mention-pair
or entity-mention model. And our experimental re-
sults on the ACE data set shows the model is effec-
tive for coreference resolution.
2 Related Work
There are plenty of learning-based coreference reso-
lution systems that employ the mention-pair model.
A typical one of them is presented by Soon et al
(2001). In the system, a training or testing instance
is formed for two mentions in question, with a fea-
ture vector describing their properties and relation-
ships. At a testing time, an active mention is checked
against all its preceding mentions, and is linked with
the closest one that is classified as positive. The
work is further enhanced by Ng and Cardie (2002)
by expanding the feature set and adopting a ?best-
first? linking strategy.
Recent years have seen some work on the entity-
mention model. Luo et al (2004) propose a system
that performs coreference resolution by doing search
in a large space of entities. They train a classifier that
can determine the likelihood that an active mention
should belong to an entity. The entity-level features
are calculated with an ?Any-X? strategy: an entity-
mention pair would be assigned a feature X, if any
mention in the entity has the feature X with the ac-
tive mention.
Culotta et al (2007) present a system which uses
an online learning approach to train a classifier to
judge whether two entities are coreferential or not.
The features describing the relationships between
two entities are obtained based on the information
of every possible pair of mentions from the two en-
tities. Different from (Luo et al, 2004), the entity-
level features are computed using a ?Most-X? strat-
egy, that is, two given entities would have a feature
X, if most of the mention pairs from the two entities
have the feature X.
Yang et al (2004b) suggest an entity-based coref-
erence resolution system. The model adopted in the
system is similar to the mention-pair model, except
that the entity information (e.g., the global num-
ber/gender agreement) is considered as additional
features of a mention in the entity.
McCallum and Wellner (2003) propose several
graphical models for coreference analysis. These
models aim to overcome the limitation that pair-
wise coreference decisions are made independently
of each other. The simplest model conditions coref-
erence on mention pairs, but enforces dependency
by calculating the distance of a node to a partition
(i.e., the probability that an active mention belongs
to an entity) based on the sum of its distances to all
the nodes in the partition (i.e., the sum of the prob-
ability of the active mention co-referring with the
mentions in the entity).
Inductive Logic Programming (ILP) has been ap-
plied to some natural language processing tasks, in-
cluding parsing (Mooney, 1997), POS disambigua-
tion (Cussens, 1996), lexicon construction (Claveau
et al, 2003), WSD (Specia et al, 2007), and so on.
However, to our knowledge, our work is the first ef-
fort to adopt this technique for the coreference reso-
lution task.
3 Modelling Coreference Resolution
Suppose we have a document containing n mentions
{mj : 1 < j < n}, in which mj is the jth mention
occurring in the document. Let ei be the ith entity in
the document. We define
P (L|ei,mj), (1)
the probability that a mention belongs to an entity.
Here the random variable L takes a binary value and
is 1 if mj is a mention of ei.
By assuming that mentions occurring after mj
have no influence on the decision of linking mj to
an entity, we can approximate (1) as:
P (L|ei,mj)
? P (L|{mk ? ei, 1 ? k ? j ? 1},mj) (2)
? max
mk?ei,1?k?j?1
P (L|mk,mj) (3)
(3) further assumes that an entity-mention score
can be computed by using the maximum mention-
844
[ Microsoft Corp. ]11 announced [ [ its ]12 new CEO ]23
[ yesterday ]34. [ The company ]15 said [ he ]26 will . . .
Table 1: A sample text
pair score. Both (2) and (1) can be approximated
with a machine learning method, leading to the tra-
ditional mention-pair model and the entity-mention
model for coreference resolution, respectively.
The two models will be described in the next sub-
sections, with the sample text in Table 1 used for
demonstration. In the table, a mention m is high-
lighted as [ m ]eidmid, where mid and eid are the IDs
for the mention and the entity to which it belongs,
respectively. Three entity chains can be found in the
text, that is,
e1 : Microsoft Corp. - its - The company
e2 : its new CEO - he
e3 : yesterday
3.1 Mention-Pair Model
As a baseline, we first describe a learning framework
with the mention-pair model as adopted in the work
by Soon et al (2001) and Ng and Cardie (2002).
In the learning framework, a training or testing
instance has the form of i{mk, mj}, in which mj is
an active mention and mk is a preceding mention.
An instance is associated with a vector of features,
which is used to describe the properties of the two
mentions as well as their relationships. Table 2 sum-
marizes the features used in our study.
For training, given each encountered anaphoric
mention mj in a document, one single positive train-
ing instance is created for mj and its closest an-
tecedent. And a group of negative training in-
stances is created for every intervening mentions
between mj and the antecedent. Consider the ex-
ample text in Table 1, for the pronoun ?he?, three
instances are generated: i(?The company?,?he?),
i(?yesterday?,?he?), and i(?its new CEO?,?he?).
Among them, the first two are labelled as negative
while the last one is labelled as positive.
Based on the training instances, a binary classifier
can be generated using any discriminative learning
algorithm. During resolution, an input document is
processed from the first mention to the last. For each
encountered mention mj , a test instance is formed
for each preceding mention, mk. This instance is
presented to the classifier to determine the corefer-
ence relationship. mj is linked with the mention that
is classified as positive (if any) with the highest con-
fidence value.
3.2 Entity-Mention Model
The mention-based solution has a limitation that in-
formation beyond a mention pair cannot be captured.
As an individual mention usually lacks complete de-
scription about the referred entity, the coreference
relationship between two mentions may be not clear,
which would affect classifier learning. Consider
a document with three coreferential mentions ?Mr.
Powell?, ?he?, and ?Powell?, appearing in that or-
der. The positive training instance i(?he?, ?Powell?)
is not informative, as the pronoun ?he? itself dis-
closes nothing but the gender. However, if the whole
entity is considered instead of only one mention, we
can know that ?he? refers to a male person named
?Powell?. And consequently, the coreference rela-
tionships between the mentions would become more
obvious.
The mention-pair model would also cause errors
at a testing time. Suppose we have three mentions
?Mr. Powell?, ?Powell?, and ?she? in a document.
The model tends to link ?she? with ?Powell? be-
cause of their proximity. This error can be avoided,
if we know ?Powell? belongs to the entity starting
with ?Mr. Powell?, and therefore refers to a male
person and cannot co-refer with ?she?.
The entity-mention model based on Eq. (2) per-
forms coreference resolution at an entity-level. For
simplicity, the framework considered for the entity-
mention model adopts similar training and testing
procedures as for the mention-pair model. Specif-
ically, a training or testing instance has the form of
i{ei, mj}, in which mj is an active mention and ei
is a partial entity found before mj . During train-
ing, given each anaphoric mention mj , one single
positive training instance is created for the entity to
which mj belongs. And a group of negative train-
ing instances is created for every partial entity whose
last mention occurs between mj and the closest an-
tecedent of mj .
See the sample in Table 1 again. For the pronoun
?he?, the following three instances are generated for
845
Features describing an active mention, mj
defNP mj 1 if mj is a definite description; else 0
indefNP mj 1 if mj is an indefinite NP; else 0
nameNP mj 1 if mj is a named-entity; else 0
pron mj 1 if mj is a pronoun; else 0
bareNP mj 1 if mj is a bare NP (i.e., NP without determiners) ; else 0
Features describing a previous mention, mk
defNP mk 1 if mk is a definite description; else 0
indefNP mk 1 if mk is an indefinite NP; else 0
nameNP mk 1 if mk is a named-entity; else 0
pron mk 1 if mk is a pronoun; else 0
bareNP mk 1 if mk is a bare NP; else 0
subject mk 1 if mk is an NP in a subject position; else 0
Features describing the relationships between mk and mj
sentDist sentence distance between two mentions
numAgree 1 if two mentions match in the number agreement; else 0
genderAgree 1 if two mentions match in the gender agreement; else 0
parallelStruct 1 if two mentions have an identical collocation pattern; else 0
semAgree 1 if two mentions have the same semantic category; else 0
nameAlias 1 if two mentions are an alias of the other; else 0
apposition 1 if two mentions are in an appositive structure; else 0
predicative 1 if two mentions are in a predicative structure; else 0
strMatch Head 1 if two mentions have the same head string; else 0
strMatch Full 1 if two mentions contain the same strings, excluding the determiners; else 0
strMatch Contain 1 if the string of mj is fully contained in that of mk ; else 0
Table 2: Feature set for coreference resolution
entity e1, e3 and e2:
i({?Microsoft Corp.?, ?its?, ?The company?},?he?),
i({?yesterday?},?he?),
i({?its new CEO?},?he?).
Among them, the first two are labelled as negative,
while the last one is positive.
The resolution is done using a greedy clustering
strategy. Given a test document, the mentions are
processed one by one. For each encountered men-
tion mj , a test instance is formed for each partial en-
tity found so far, ei. This instance is presented to the
classifier. mj is appended to the entity that is classi-
fied as positive (if any) with the highest confidence
value. If no positive entity exists, the active mention
is deemed as non-anaphoric and forms a new entity.
The process continues until the last mention of the
document is reached.
One potential problem with the entity-mention
model is how to represent the entity-level knowl-
edge. As an entity may contain more than one candi-
date and the number is not fixed, it is impractical to
enumerate all the mentions in an entity and put their
properties into a single feature vector. As a base-
line, we follow the solution proposed in (Luo et al,
2004) to design a set of first-order features. The fea-
tures are similar to those for the mention-pair model
as shown in Table 2, but their values are calculated
at an entity level. Specifically, the lexical and gram-
matical features are computed by testing any men-
tion1 in the entity against the active mention, for ex-
1Linguistically, pronouns usually have the most direct coref-
ample, the feature nameAlias is assigned value 1 if
at least one mention in the entity is a name alias of
the active mention. The distance feature (i.e., sent-
Dist) is the minimum distance between the mentions
in the entity and the active mention.
The above entity-level features are designed in an
ad-hoc way. They cannot capture the detailed infor-
mation of each individual mention in an entity. In
the next section, we will present a more expressive
entity-mention model by using ILP.
4 Entity-mention Model with ILP
4.1 Motivation
The entity-mention model based on Eq. (2) re-
quires relational knowledge that involves informa-
tion of an active mention (mj), an entity (ei), and
the mentions in the entity ({mk ? ei}). How-
ever, normal machine learning algorithms work on
attribute-value vectors, which only allows the repre-
sentation of atomic proposition. To learn from rela-
tional knowledge, we need an algorithm that can ex-
press first-order logic. This requirement motivates
our use of Inductive Logic Programming (ILP), a
learning algorithm capable of inferring logic pro-
grams. The relational nature of ILP makes it pos-
sible to explicitly represent relations between an en-
tity and its mentions, and thus provides a powerful
expressiveness for the coreference resolution task.
erence relationship with antecedents in a local discourse.
Hence, if an active mention is a pronoun, we only consider the
mentions in its previous two sentences for feature computation.
846
ILP uses logic programming as a uniform repre-
sentation for examples, background knowledge and
hypotheses. Given a set of positive and negative ex-
ample E = E+ ? E?, and a set of background
knowledge K of the domain, ILP tries to induce a
set of hypotheses h that covers most of E+ with no
E?, i.e., K ? h |= E+ and K ? h 6|= E?.
In our study, we choose ALEPH2, an ILP imple-
mentation by Srinivasan (2000) that has been proven
well suited to deal with a large amount of data in
multiple domains. For its routine use, ALEPH fol-
lows a simple procedure to induce rules. It first se-
lects an example and builds the most specific clause
that entertains the example. Next, it tries to search
for a clause more general than the bottom one. The
best clause is added to the current theory and all the
examples made redundant are removed. The proce-
dure repeats until all examples are processed.
4.2 Apply ILP to coreference resolution
Given a document, we encode a mention or a par-
tial entity with a unique constant. Specifically, mj
represents the jth mention (e.g., m6 for the pronoun
?he?). ei j represents the partial entity i before the
jth mention. For example, e1 6 denotes the part of
e1 before m6, i.e., {?Microsoft Corp.?, ?its?, ?the
company?}, while e1 5 denotes the part of e1 be-
fore m5 (?The company?), i.e., {?Microsoft Corp.?,
?its?}.
Training instances are created as described in Sec-
tion 3.2 for the entity-mention model. Each instance
is recorded with a predicate link(ei j , mj), where mj
is an active mention and ei j is a partial entity. For
example, the three training instances formed by the
pronoun ?he? are represented as follows:
link(e1 6,m6).
link(e3 6,m6).
link(e2 6,m6).
The first two predicates are put into E?, while the
last one is put to E+.
The background knowledge for an instance
link(ei j , mj) is also represented with predicates,
which are divided into the following types:
1. Predicates describing the information related to
ei j and mj . The properties of mj are pre-
2http://web.comlab.ox.ac.uk/oucl/
research/areas/machlearn/Aleph/aleph toc.html
sented with predicates like f (m, v), where f
corresponds to a feature in the first part of Ta-
ble 2 (removing the suffix mj), and v is its
value. For example, the pronoun ?he? can be
described by the following predicates:
defNP(m6, 0). indefNP(m6, 0).
nameNP(m6, 0). pron(m6, 1).
bareNP(m6, 0).
The predicates for the relationships between
ei j and mj take a form of f (e, m, v). In our
study, we consider the number agreement (ent-
NumAgree) and the gender agreement (entGen-
derAgree) between ei j and mj . v is 1 if all
of the mentions in ei j have consistent num-
ber/gender agreement with mj , e.g,
entNumAgree(e1 6,m6, 1).
2. Predicates describing the belonging relations
between ei j and its mentions. A predicate
has mention(e, m) is used for each mention in
e 3. For example, the partial entity e1 6 has
three mentions, m1, m2 and m5, which can be
described as follows:
has mention(e1 6,m1).
has mention(e1 6,m2).
has mention(e1 6,m5).
3. Predicates describing the information related to
mj and each mention mk in ei j . The predi-
cates for the properties of mk correspond to the
features in the second part of Table 2 (removing
the suffix mk), while the predicates for the re-
lationships between mj and mk correspond to
the features in the third part of Table 2. For ex-
ample, given the two mentions m1 (?Microsoft
Corp.) and m6 (?he), the following predicates
can be applied:
nameNP(m1, 1).
pron(m1, 0).
. . .
nameAlias(m1,m6, 0).
sentDist(m1,m6, 1).
. . .
the last two predicates represent that m1 and
3If an active mention mj is a pronoun, only the previous
mentions in two sentences apart are recorded by has mention,
while the farther ones are ignored as they have less impact on
the resolution of the pronoun.
847
m6 are not name alias, and are one sentence
apart.
By using the three types of predicates, the dif-
ferent knowledge related to entities and mentions
are integrated. The predicate has mention acts as
a bridge connecting the entity-mention knowledge
and the mention-pair knowledge. As a result, when
evaluating the coreference relationship between an
active mention and an entity, we can make use of
the ?global? information about the entity, as well as
the ?local? information of each individual mention
in the entity.
From the training instances and the associated
background knowledge, a set of hypotheses can be
automatically learned by ILP. Each hypothesis is
output as a rule that may look like:
link(A,B):-
predi1, predi2, . . . , has mention(A,C), . . . , prediN.
which corresponds to first-order logic
?A,B(predi1 ? predi2 ? . . .?
?C(has mention(A,C) ? . . . ? prediN)
? link(A,B))
Consider an example rule produced in our system:
link(A,B) :-
has mention(A,C), numAgree(B,C,1),
strMatch Head(B,C,1), bareNP(C,1).
Here, variables A and B stand for an entity and an
active mention in question. The first-order logic is
implemented by using non-instantiated arguments C
in the predicate has mention. This rule states that a
mention B should belong to an entity A, if there ex-
ists a mention C in A such that C is a bare noun
phrase with the same head string as B, and matches
in number with B. In this way, the detailed informa-
tion of each individual mention in an entity can be
captured for resolution.
A rule is applicable to an instance link(e, m), if
the background knowledge for the instance can be
described by the predicates in the body of the rule.
Each rule is associated with a score, which is the
accuracy that the rule can produce for the training
instances.
The learned rules are applied to resolution in a
similar way as described in Section 3.2. Given an
active mention m and a partial entity e, a test in-
stance link(e, m) is formed and tested against every
rule in the rule set. The confidence that m should
Train Test
#entity #mention #entity #mention
NWire 1678 9861 411 2304
NPaper 1528 10277 365 2290
BNews 1695 8986 468 2493
Table 3: statistics of entities (length > 1) and contained
mentions
belong to e is the maximal score of the applicable
rules. An active mention is linked to the entity with
the highest confidence value (above 0.5), if any.
5 Experiments and Results
5.1 Experimental Setup
In our study, we did evaluation on the ACE-2003
corpus, which contains two data sets, training and
devtest, used for training and testing respectively.
Each of these sets is further divided into three do-
mains: newswire (NWire), newspaper (NPaper), and
broadcast news (BNews). The number of entities
with more than one mention, as well as the number
of the contained mentions, is summarized in Table 3.
For both training and resolution, an input raw
document was processed by a pipeline of NLP
modules including Tokenizer, Part-of-Speech tag-
ger, NP Chunker and Named-Entity (NE) Recog-
nizer. Trained and tested on Penn WSJ TreeBank,
the POS tagger could obtain an accuracy of 97% and
the NP chunker could produce an F-measure above
94% (Zhou and Su, 2000). Evaluated for the MUC-
6 and MUC-7 Named-Entity task, the NER mod-
ule (Zhou and Su, 2002) could provide an F-measure
of 96.6% (MUC-6) and 94.1%(MUC-7). For evalu-
ation, Vilain et al (1995)?s scoring algorithm was
adopted to compute recall and precision rates.
By default, the ALEPH algorithm only generates
rules that have 100% accuracy for the training data.
And each rule contains at most three predicates. To
accommodate for coreference resolution, we loos-
ened the restrictions to allow rules that have above
50% accuracy and contain up to ten predicates. De-
fault parameters were applied for all the other set-
tings in ALEPH as well as other learning algorithms
used in the experiments.
5.2 Results and Discussions
Table 4 lists the performance of different corefer-
ence resolution systems. For comparison, we first
848
NWire NPaper BNews
R P F R P F R P F
C4.5
- Mention-Pair 68.2 54.3 60.4 67.3 50.8 57.9 66.5 59.5 62.9
- Entity-Mention 66.8 55.0 60.3 64.2 53.4 58.3 64.6 60.6 62.5
- Mention-Pair (all mentions in entity) 66.7 49.3 56.7 65.8 48.9 56.1 66.5 47.6 55.4
ILP
- Mention-Pair 66.1 54.8 59.5 65.6 54.8 59.7 63.5 60.8 62.1
- Entity-Mention 65.0 58.9 61.8 63.4 57.1 60.1 61.7 65.4 63.5
Table 4: Results of different systems for coreference resolution
examined the C4.5 algorithm4 which is widely used
for the coreference resolution task. The first line of
the table shows the baseline system that employs the
traditional mention-pair model (MP) as described in
Section 3.1. From the table, our baseline system
achieves a recall of around 66%-68% and a preci-
sion of around 50%-60%. The overall F-measure
for NWire, NPaper and BNews is 60.4%, 57.9% and
62.9% respectively. The results are comparable to
those reported in (Ng, 2005) which uses similar fea-
tures and gets an F-measure ranging in 50-60% for
the same data set. As our system relies only on sim-
ple and knowledge-poor features, the achieved F-
measure is around 2-4% lower than the state-of-the-
art systems do, like (Ng, 2007) and (Yang and Su,
2007) which utilized sophisticated semantic or real-
world knowledge. Since ILP has a strong capability
in knowledge management, our system could be fur-
ther improved if such helpful knowledge is incorpo-
rated, which will be explored in our future work.
The second line of Table 4 is for the system
that employs the entity-mention model (EM) with
?Any-X? based entity features, as described in Sec-
tion 3.2. We can find that the EM model does not
show superiority over the baseline MP model. It
achieves a higher precision (up to 2.6%), but a lower
recall (2.9%), than MP. As a result, we only see
?0.4% difference between the F-measure. The re-
sults are consistent with the reports by Luo et al
(2004) that the entity-mention model with the ?Any-
X? first-order features performs worse than the nor-
mal mention-pair model. In our study, we also tested
the ?Most-X? strategy for the first-order features as
in (Culotta et al, 2007), but got similar results with-
out much difference (?0.5% F-measure) in perfor-
4http://www.rulequest.com/see5-info.html
mance. Besides, as with our entity-mention predi-
cates described in Section 4.2, we also tried the ?All-
X? strategy for the entity-level agreement features,
that is, whether all mentions in a partial entity agree
in number and gender with an active mention. How-
ever, we found this bring no improvement against
the ?Any-X? strategy.
As described, given an active mention mj , the MP
model only considers the mentions between mj and
its closest antecedent. By contrast, the EM model
considers not only these mentions, but also their an-
tecedents in the same entity link. We were interested
in examining what if the MP model utilizes all the
mentions in an entity as the EM model does. As
shown in the third line of Table 4, such a solution
damages the performance; while the recall is at the
same level, the precision drops significantly (up to
12%) and as a result, the F-measure is even lower
than the original MP model. This should be because
a mention does not necessarily have direct corefer-
ence relationships with all of its antecedents. As the
MP model treats each mention-pair as an indepen-
dent instance, including all the antecedents would
produce many less-confident positive instances, and
thus adversely affect training.
The second block of the table summarizes the per-
formance of the systems with ILP. We were first con-
cerned with how well ILP works for the mention-
pair model, compared with the normally used algo-
rithm C4.5. From the results shown in the fourth
line of Table 4, ILP exhibits the same capability in
the resolution; it tends to produce a slightly higher
precision but a lower recall than C4.5 does. Overall,
it performs better in F-measure (1.8%) for Npaper,
while slightly worse (<1%) for Nwire and BNews.
These results demonstrate that ILP could be used as
849
link(A,B) :-
bareNP(B,0), has mention(A,C), appositive(C,1).
link(A,B) :-
has mention(A,C), numAgree(B,C,1), strMatch Head(B,C,1), bareNP(C,1).
link(A,B) :-
nameNP(B,0), has mention(A,C), predicative(C,1).
link(A,B) :-
has mention(A,C), strMatch Contain(B,C,1), strMatch Head(B,C,1), bareNP(C,0).
link(A,B) :-
nameNP(B,0), has mention(A,C), nameAlias(C,1), bareNP(C,0).
link(A,B) :-
pron(B,1), has mention(A,C), nameNP(C,1), has mention(A,D), indefNP(D,1),
subject(D, 1).
...
Figure 1: Examples of rules produced by ILP (entity-
mention model)
a good classifier learner for the mention-pair model.
The fifth line of Table 4 is for the ILP based entity-
mention model (described in Section 4.2). We can
observe that the model leads to a better performance
than all the other models. Compared with the sys-
tem with the MP model (under ILP), the EM version
is able to achieve a higher precision (up to 4.6% for
BNews). Although the recall drops slightly (up to
1.8% for BNews), the gain in the precision could
compensate it well; it beats the MP model in the
overall F-measure for all three domains (2.3% for
Nwire, 0.4% for Npaper, 1.4% for BNews). Es-
pecially, the improvement in NWire and BNews is
statistically significant under a 2-tailed t test (p <
0.05). Compared with the EM model with the man-
ually designed first-order feature (the second line),
the ILP-based EM solution also yields better perfor-
mance in precision (with a slightly lower recall) as
well as the overall F-measure (1.0% - 1.8%).
The improvement in precision against the
mention-pair model confirms that the global infor-
mation beyond a single mention pair, when being
considered for training, can make coreference rela-
tions clearer and help classifier learning. The bet-
ter performance against the EM model with heuristi-
cally designed features also suggests that ILP is able
to learn effective first-order rules for the coreference
resolution task.
In Figure 1, we illustrate part of the rules pro-
duced by ILP for the entity-mention model (NWire
domain), which shows how the relational knowledge
of entities and mentions is represented for decision
making. An interesting finding, as shown in the last
rule of the table, is that multiple non-instantiated ar-
guments (i.e. C and D) could possibly appear in
the same rule. According to this rule, a pronominal
mention should be linked with a partial entity which
contains a named-entity and contains an indefinite
NP in a subject position. This supports the claims
in (Yang et al, 2004a) that coreferential informa-
tion is an important factor to evaluate a candidate an-
tecedent in pronoun resolution. Such complex logic
makes it possible to capture information of multi-
ple mentions in an entity at the same time, which is
difficult to implemented in the mention-pair model
and the ordinary entity-mention model with heuris-
tic first-order features.
6 Conclusions
This paper presented an expressive entity-mention
model for coreference resolution by using Inductive
Logic Programming. In contrast to the traditional
mention-pair model, our model can capture infor-
mation beyond single mention pairs for both training
and testing. The relational nature of ILP enables our
model to explicitly express the relations between an
entity and its mentions, and to automatically learn
the first-order rules effective for the coreference res-
olution task. The evaluation on ACE data set shows
that the ILP based entity-model performs better than
the mention-pair model (with up to 2.3% increase in
F-measure), and also beats the entity-mention model
with heuristically designed first-order features.
Our current work focuses on the learning model
that calculates the probability of a mention be-
longing to an entity. For simplicity, we just use a
greedy clustering strategy for resolution, that is, a
mention is linked to the current best partial entity.
In our future work, we would like to investigate
more sophisticated clustering methods that would
lead to global optimization, e.g., by keeping a large
search space (Luo et al, 2004) or using integer
programming (Denis and Baldridge, 2007).
Acknowledgements This research is supported
by a Specific Targeted Research Project (STREP)
of the European Union?s 6th Framework Programme
within IST call 4, Bootstrapping Of Ontologies and
Terminologies STrategic REsearch Project (BOOT-
Strep).
850
References
C. Aone and S. W. Bennett. 1995. Evaluating automated
and manual acquisition of anaphora resolution strate-
gies. In Proceedings of the 33rd Annual Meeting of
the Association for Computational Linguistics (ACL),
pages 122?129.
V. Claveau, P. Sebillot, C. Fabre, and P. Bouillon. 2003.
Learning semantic lexicons from a part-of-speech and
semantically tagged corpus using inductive logic pro-
gramming. Journal of Machine Learning Research,
4:493?525.
A. Culotta, M. Wick, and A. McCallum. 2007. First-
order probabilistic models for coreference resolution.
In Proceedings of the Annual Meeting of the North
America Chapter of the Association for Computational
Linguistics (NAACL), pages 81?88.
J. Cussens. 1996. Part-of-speech disambiguation using
ilp. Technical report, Oxford University Computing
Laboratory.
P. Denis and J. Baldridge. 2007. Joint determination of
anaphoricity and coreference resolution using integer
programming. In Proceedings of the Annual Meeting
of the North America Chapter of the Association for
Computational Linguistics (NAACL), pages 236?243.
X. Luo, A. Ittycheriah, H. Jing, N. Kambhatla, and
S. Roukos. 2004. A mention-synchronous corefer-
ence resolution algorithm based on the bell tree. In
Proceedings of the 42nd Annual Meeting of the As-
sociation for Computational Linguistics (ACL), pages
135?142.
A. McCallum and B. Wellner. 2003. Toward condi-
tional models of identity uncertainty with application
to proper noun coreference. In Proceedings of IJCAI-
03 Workshop on Information Integration on the Web,
pages 79?86.
J. McCarthy and W. Lehnert. 1995. Using decision
trees for coreference resolution. In Proceedings of
the 14th International Conference on Artificial Intel-
ligences (IJCAI), pages 1050?1055.
R. Mooney. 1997. Inductive logic programming for nat-
ural language processing. In Proceedings of the sixth
International Inductive Logic Programming Work-
shop, pages 3?24.
V. Ng and C. Cardie. 2002. Improving machine learn-
ing approaches to coreference resolution. In Proceed-
ings of the 40th Annual Meeting of the Association
for Computational Linguistics (ACL), pages 104?111,
Philadelphia.
V. Ng. 2005. Machine learning for coreference resolu-
tion: From local classification to global ranking. In
Proceedings of the 43rd Annual Meeting of the As-
sociation for Computational Linguistics (ACL), pages
157?164.
V. Ng. 2007. Semantic class induction and coreference
resolution. In Proceedings of the 45th Annual Meet-
ing of the Association for Computational Linguistics
(ACL), pages 536?543.
W. Soon, H. Ng, and D. Lim. 2001. A machine learning
approach to coreference resolution of noun phrases.
Computational Linguistics, 27(4):521?544.
L. Specia, M. Stevenson, and M. V. Nunes. 2007. Learn-
ing expressive models for words sense disambiguation.
In Proceedings of the 45th Annual Meeting of the As-
sociation for Computational Linguistics (ACL), pages
41?48.
A. Srinivasan. 2000. The aleph manual. Technical re-
port, Oxford University Computing Laboratory.
M. Vilain, J. Burger, J. Aberdeen, D. Connolly, and
L. Hirschman. 1995. A model-theoretic coreference
scoring scheme. In Proceedings of the Sixth Mes-
sage understanding Conference (MUC-6), pages 45?
52, San Francisco, CA. Morgan Kaufmann Publishers.
X. Yang and J. Su. 2007. Coreference resolution us-
ing semantic relatedness information from automati-
cally discovered patterns. In Proceedings of the 45th
Annual Meeting of the Association for Computational
Linguistics (ACL), pages 528?535.
X. Yang, J. Su, G. Zhou, and C. Tan. 2004a. Improv-
ing pronoun resolution by incorporating coreferential
information of candidates. In Proceedings of the 42nd
Annual Meeting of the Association for Computational
Linguistics (ACL), pages 127?134, Barcelona.
X. Yang, J. Su, G. Zhou, and C. Tan. 2004b. An
NP-cluster approach to coreference resolution. In
Proceedings of the 20th International Conference on
Computational Linguistics, pages 219?225, Geneva.
G. Zhou and J. Su. 2000. Error-driven HMM-based
chunk tagger with context-dependent lexicon. In Pro-
ceedings of the Joint Conference on Empirical Meth-
ods in Natural Language Processing and Very Large
Corpora, pages 71?79, Hong Kong.
G. Zhou and J. Su. 2002. Named Entity recognition us-
ing a HMM-based chunk tagger. In Proceedings of the
40th Annual Meeting of the Association for Compu-
tational Linguistics (ACL), pages 473?480, Philadel-
phia.
851
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1216?1224,
October 25-29, 2014, Doha, Qatar. c?2014 Association for Computational Linguistics
An Iterative Link-based Method for Parallel Web Page Mining 
Le Liu1, Yu Hong1, Jun Lu2, Jun Lang2, Heng Ji3, Jianmin Yao1 
1School of Computer Science & Technology, Soochow University, Suzhou, 215006, China 
2Institute for Infocomm Research, Singapore, 138632 
3Computer Science Department, Rensselaer Polytechnic Institute, Troy, NY 12180, USA 
giden@sina.cn,{tianxianer,lujun59,billlangjun}@gmail.com 
jih@rpi.edu,jyao@suda.edu.cn 
 
Abstracts 
Identifying parallel web pages from bi-
lingual web sites is a crucial step of bi-
lingual resource construction for cross-
lingual information processing. In this 
paper, we propose a link-based approach 
to distinguish parallel web pages from bi-
lingual web sites. Compared with the ex-
isting methods, which only employ the 
internal translation similarity (such as 
content-based similarity and page struc-
tural similarity), we hypothesize that the 
external translation similarity is an effec-
tive feature to identify parallel web pages. 
Within a bilingual web site, web pages 
are interconnected by hyperlinks. The 
basic idea of our method is that the trans-
lation similarity of two pages can be in-
ferred from their neighbor pages, which 
can be adopted as an important source of 
external similarity. Thus, the translation 
similarity of page pairs will influence 
each other. An iterative algorithm is de-
veloped to estimate the external transla-
tion similarity and the final translation 
similarity. Both internal and external 
similarity measures are combined in the 
iterative algorithm. Experiments on six 
bilingual websites demonstrate that our 
method is effective and obtains signifi-
cant improvement (6.2% F-Score) over 
the baseline which only utilizes internal 
translation similarity. 
1 Introduction 
Parallel corpora have played an important role in 
multilingual Natural Language Processing, espe-
cially in Machine Translation (MT) and Cross-
lingual Information Retrieval(CLIR). However, 
it?s time-consuming to build parallel corpora 
manually. Some existing parallel corpora are 
subject to subscription or license fee and thus not 
freely available, while others are domain-specific. 
Therefore, a lot of previous research has focused 
on automatically mining parallel corpora from 
the web. 
In the past decade, there have been extensive 
studies on parallel resource extraction from the 
web (e.g., Chen and Nie, 2000; Resnik 2003; 
Jiang et al., 2009) and many effective Web min-
ing systems have been developed such as 
STRAND, PTMiner, BITS and WPDE. For most 
of these mining systems, there is a typical paral-
lel resource mining strategy which involves three 
steps: (1) locate the bilingual websites (2) identi-
fy  parallel web pages from these bilingual web-
sites and (3) extract bilingual resources from the 
parallel web pages.  
In this paper, we focus on the step (2) which is 
regarded as the core of the mining system 
(Chunyu, 2007). Estimating the translation simi-
larity of two pages is the most basic and key 
problem in this step. Previous approaches have 
tried to tackle this problem by using the infor-
mation within the pages. For example, in the 
STRAND and PTMiner system, a structural fil-
tering process that relies on the analysis of the 
underlying HTML structure of pages is used to 
determine a set of pair-specific structural values, 
and then the values are used to decide whether 
the pages are translations of one another. The 
BITS system filters out bad pairs by using a large 
bilingual dictionary to compute a content-based 
similarity score and comparing the score with a 
threshold. The WPDE system combines URL 
similarity, structure similarity with content-based 
similarity to discover and verify candidate paral-
lel page pairs. Some other features or rules such 
as page size ratio, predefined hypertexts which 
link to different language versions of a web page 
are also used in most of these systems. Here, all 
of the mining systems are simply using the in-
formation within the page in the process of find-
1216
ing parallel web pages. In this paper, we attempt 
to explore other information to identify parallel 
web pages. 
On the Internet, most web pages are linked by 
hyperlinks. We argue that the translation similar-
ity of two pages depends on not only their inter-
nal information but also their neighbors. The 
neighbors of a web page are a set of pages, 
which link to the page. We find that the similari-
ty of neighbors can provide more reliable evi-
dence in estimating the translation similarity of 
two pages.  
The main issues are discussed in this paper as 
follows:  
? Can the neighbors of candidate page pairs 
really contribute to estimating the translation 
similarity?  
? How to estimate the translation similarity of 
candidate page pairs by using their neighbors? 
Our method has the following advantages: 
High performance 
The external and internal information is com-
bined to verify parallel page pairs in our method, 
while in previous mining systems, only internal 
information was used. Experimental results show 
that compared with existing parallel page pair 
identification technologies, our method obtains 
both higher precision and recall (6.2% and 6.3% 
improvement than the baseline, respectively). In 
addition, the external information used in our 
method is a more effective feature than internal 
features alone such as structural similarity and 
content-based similarity. 
Language independent 
In principle, our method is language inde-
pendent and can be easily ported to new lan-
guage pairs, except for the language-specific bi-
lingual lexicons. Our method takes full ad-
vantage of the link information that is language-
independent. For the bilingual lexicons in our 
experiments, compared to previous methods, our 
method does not need a big bilingual lexicon, 
which is good news to less-resource language 
pairs. 
Unsupervised and fewer parameters 
In previous work, some parameters need to be 
optimized. Due to the diversity of web page 
styles, it is not trivial to obtain the best parame-
ters. Some previous researches(Resnik, 2003; 
Zhang et al., 2006) attempt to optimize parame-
ters by employing machine learning method. In 
contrast, in our method, only two parameters 
need to be estimated. One parameter remains 
stable for different style websites. Another pa-
rameter can be easily adjusted to achieve the best 
performance. Therefore, our method can be used 
in other websites with different styles, without 
much effort to optimize these parameters.  
2 Related Work 
A large amount of literature has been published 
on parallel resource mining from the web. Ac-
cording to the existing form of the parallel re-
source on the Internet, related work can be cate-
gorized as follows: 
Mining from bilingual websites 
Most existing web mining systems aimed at 
mining bilingual resource from the bilingual 
websites, such as PTMiner (Nie et al., 1999), 
STRAND (Resnik and Smith, 2003), BITS (Ma 
and Liberman, 1999), PTI (Chen et al., 2004). 
PTMiner uses search engines to pinpoint the 
candidate sites that are likely to contain parallel 
pages, and then uses the collected URLs as seeds 
to further crawl each web site for more URLs. 
Web page pairs are extracted based on manually 
defined URL pattern matching, and further fil-
tered according to several criteria. STRAND us-
es a search engine to search for multilingual 
websites and generated candidate page pairs 
based on manually created substitution rules. 
Then, it filters some candidate pairs by analyzing 
the HTML pages. PTI crawls the web to fetch 
(potentially parallel) candidate multilingual web 
documents by using a web spider. To determine 
the parallelism between potential document pairs, 
a filename comparison module is used to check 
filename resemblance, and a content analysis 
module is used to measure the semantic similari-
ty. BITS was the first to obtain bilingual web-
sites by employing a language identification 
module, and then for each bilingual website, it 
extracts parallel pages based on their content.  
Mining from bilingual web pages 
Parallel/bilingual resources may exist not only 
in two parallel monolingual web pages, but also 
in single bilingual web pages. Jiang et al. (2009) 
used an adaptive pattern-based method to mine 
interesting bilingual data based on the observa-
tion that bilingual data usually appears collec-
tively following similar patterns. They found that 
bilingual web pages are a promising source of 
up-to-date bilingual terms/sentences which cover 
many domains and application scenarios. In ad-
dition, Feng et al. (2010) proposed a new method 
1217
to automatically acquire bilingual web pages 
from the result pages of a search engine.  
Mining from comparable corpus 
Several attempts have been made to extract 
parallel resources from comparable corpora. 
Zhao et al. (2002) proposed a robust, adaptive 
approach for mining parallel sentences from a 
bilingual comparable news collection. In their 
method, sentence length models and lexicon-
based models were combined under a maximum 
likelihood criterion. Smith et al. (2010) found 
that Wikipedia contains a lot of comparable doc-
uments, and adopted a ranking model to select 
parallel sentence pairs from comparable docu-
ments. Bharadwaj et al. (2011) used a SVM clas-
sifier with some new features to identify parallel 
sentences from Wikipedia.  
3 Iterative Link-based Parallel Web 
Pages Mining 
As mentioned, the basic idea of our method is 
that the similarity of two pages can be inferred 
from their neighbors. This idea is illustrated in 
Figure 1.  
A D
E
C
B
A?
D?
E?
C?
B?
?
 
Figure 1 Illustration of the link-based method 
In Figure 1, A, B, C, D and E are some pages 
in the same language; while A?, B?, C?, D? and E? 
are some pages in another language. The solid 
black arrows indicate the links between these 
pages. For example, page A points to C, page B? 
points to C? and so on. Then the page set {A, B, 
D, E} is called the neighbors of page C. Similar-
ly, the page set {A?, B?, D?, E?} contains the 
neighbors of page C?. If the page pairs : <A, A?>, 
<B, B?>, <D, D?> and <E, E?> have high transla-
tion similarities, then it can be inferred that page 
C and C? have a high probability to be a pair of 
parallel pages. Every page has its own neighbors. 
For each web page, our method views link-in and 
link-out hyperlinks as the same. Thus, the linked 
pages will influence each other in estimating the 
translation similarity. For example, the similari-
ties of two pairs <A, A?> and <C, C?> will influ-
ence each other. It is an iterative process. We 
will elaborate the process in the following sec-
tions.  
Since our goal is to find parallel pages in a 
specific website, the key task is to evaluate the 
translation similarity of two pages (which are in 
different languages) as accurately as possible. 
The final similarity of two pages should depend 
both on their internal similarity and external sim-
ilarity. The internal similarity means the similari-
ty estimated by using the information in the page 
itself, such as the structure similarity and the 
content-based similarity of the two pages. On the 
other hand, the external similarity of two pages is 
the similarity depending on their neighbors. The 
final translation similarity is called the En-
hanced Translation Similarity (ETS). The ETS 
of two pages can be calculated as follows:  
   (   )        (   )  (   )  
                                      (   )   [   ]              (1) 
Where,    (   ) is the internal translation simi-
larity of two pages: e and c;     (   ) represents 
the external translation similarity of pages e and 
c.    (   ) indicates the final similarity of two 
pages, which combines the internal with external 
translation similarity. 
In this paper, we conduct the experiments on 
English-Chinese parallel page pair mining. How-
ever, our method is language-independent. Thus, 
it can be applied to other language pairs by only 
replacing a bilingual lexicon. The symbol e and c 
always indicate an English page and a Chinese 
page respectively in this paper. In the following 
sections, we will describe how to calculate the 
   (   ) and     (   ) step by step. 
3.1 Preprocessing 
The input of our method is a bilingual website. 
This paper aims to find English/Chinese parallel 
pages. So a 3-gram language model is used to 
identify (or classify) the language of a certain 
document. The performance of the language 
identification module achieves 99.5% accuracy 
through in-house testing. As a result, a set of 
English pages and a set of Chinese pages are ob-
tained. In order to get the neighbors of a page, 
for each bilingual website, two networks are con-
structed based on the hyperlinks, one for English 
pages and another for Chinese pages. 
3.2 The Internal Translation Similarity 
Following Resnik and Smith (2003), three fea-
tures are used to evaluate the internal translation 
similarity of two pages: 
1218
The size ratio of two pages 
The length ratio of two documents is the sim-
plest criterion for determining whether two doc-
uments are parallel or not. Parallel documents 
tend to be similar in length. And it is reasonable 
to assume that for text E in one language and text 
F in another language, length(E) ? C?length(F), 
where C is a constant that depends on the lan-
guage pair. Here, the content length of a web 
page is regarded as its length. 
The structure similarity of two pages 
The HTML tags describe and control a web 
page?s structure. Therefore, the structure similar-
ity of two pages can be calculated by their 
HTML tags. Here, the HTML tags of each page 
are extracted (except the visual tags such as ?B?, 
?FONT?.) as a linear sequence. Then the struc-
ture similarity of two pages is computed by com-
paring their linearized sequences. In this paper, 
the LCS algorithm (Dan, 1997) is adopted to find 
the longest common sequences of the two HTML 
tag sequences. The ratio of LCS length and the 
average length of two HTML tag sequences are 
used as the structure similarity of the two pages.  
The content-based translation similarity of 
two pages 
The basic idea is that if two documents are 
parallel, they will contain word pairs that are mu-
tual translations (Ma, 1999). So the percentage of 
translation word pairs in the two pages can be 
considered as the content-based similarity. The 
translation words of two documents can be ex-
tracted by using a bilingual lexicon. Here, for 
each word in English document, we will try to 
find a corresponding word in Chinese document.  
Finally, the internal translation similarity of 
two pages is calculated as follows: 
   (   )       (   )  (   )  
                                          (   )   [   ]        (2) 
Where,     (   )  and        (   )  are the con-
tent-based and structural similarity of page   and 
  respectively. In addition, the size ratio of two 
pages is used to filter invalid page pairs.  
3.3 The External and Enhanced Transla-
tion Similarity 
As described above, the external translation 
similarity of two pages depends on their neigh-
bors:  
    (   )     (  ( )   ( )) (3) 
Where, PG(x), a set of pages, is the neighbors of 
page x. Obviously, the similarity of two sets re-
lies on the similarity of the elements in the two 
sets. Here, the elements are namely web pages. 
So,     (   ) equals to    (  ( )   ( )), and 
   (  ( )   ( ))  depends on    (     ) 
(       belongs to    ( )   ( ) , respectively) 
and    (   ) . According to Equation (1), 
   (   )  depends on    (   )  and     (   ) . 
Therefore, it is a process of iteration.    (   ) 
will converge after a certain number of iterations. 
Thus,     (   )  is defined as the enhanced 
similarity of page   and   after the i-th iteration, 
and the same is for     
 (   ) and     (  ( ) 
  ( )) .     (  ( )   ( ))  is computed by 
the following algorithm: 
Algorithm 1: Estimating the external transla-
tion similarity 
Input:      ( )   ( ) 
Output:     
 (   ) 
Procedure:  
   ? 0 
     ?   ( ) 
      ?   ( ) 
While        and       are both not empty: 
             
?                          (   
   (   ))  
    ?     +        (   ) 
Remove   from        
Remove   from       
    
 (   )       ( ( )  ( )) 
                             (   ( )     ( ) ) 
Algorithm 2 Estimating the enhanced transla-
tion similarity 
Input:      , (the English and Chinese page set) 
Output:    (   )           
Initialization: Set ETS(e, c) random value or 
small value 
Procedure:  
LOOP: 
For each   in    : 
For each   in   : 
     (   )         
 (   ) 
                                          (   )     (   ) 
Parameters normalization 
UNTIL    (   ) is stable  
Algorithm 1 tries to find the real parallel pairs 
from   ( ) and   ( ). The similarity of   ( ) 
and   ( ) is calculated based on the similarity 
1219
values of these pairs. Finally,    (   ) is calcu-
lated by the following algorithm 2. 
In Algorithm 2, the input    and    are English 
and Chinese page sets in a certain bilingual web-
site. We use algorithm 2 to estimate the en-
hanced translation similarity. 
3.4 Find the Parallel Page Pairs 
At last, the enhanced translation similarity of 
every pair is obtained, and the parallel page pairs 
can be extracted in terms of these similarities: 
Algorithm 3 Finding parallel page pairs 
Input:       
    (   )              
       (or       ) 
Output:  Parallel Page Pairs List :     
Procedure:  
LOOP: 
                       (   (   )) 
Add       to     
Remove   from     
Remove   from     
UNTIL size of     >       (or    (   )  < 
       ) 
This algorithm is similar to Algorithm 1 in 
each bilingual website. The input      is an 
integer threshold which means that only top 
      page pairs will be extracted in a certain 
website. It needs to be noted that      is al-
ways less than      and     . While the input 
        is another kind of threshold that is 
used for extracting page pairs with high transla-
tion similarity.  
4 Experiments and Analysis 
4.1 Experimental setup 
Our experiments focus on six bilingual websites. 
Most of them are selected from HK government 
websites. All the web pages were retrieved by 
using a web site download tool: HTTrack1. We 
notice that a small amount of pages doesn?t al-
ways contain valuable contents. So, we put a 
threshold (100 bytes in our experiment) on the 
web pages' content to filter meaningless pages. In 
order to evaluate our method, the bilingual page 
pairs of each website are annotated by a human 
annotator. Finally, we got 23109 pages and 
11684 bilingual page pairs in total for testing. 
                                                 
1 http://www.httrack.com/ 
The basic information of these websites is listed 
in Table 1. 
It?s time-consuming to annotate whether two 
pages is parallel or not. Note that if a website 
contains N English pages and M Chinese pages, 
an annotator has to label N*M page pairs. To the 
best of our knowledge, there is no large scale and 
public parallel page pair dataset with human an-
notation. So we try to build a reliable and large-
scale dataset. 
In our experiments, URL similarity is used to 
reduce the workload for annotation. For a certain 
website, firstly, we obtain its URL pattern be-
tween English and Chinese pages manually. For 
example, in the website ?www.gov.hk?, the URL 
pairs like: 
http://www.gov.hk/en/about/govdirectory/   (English) 
http://www.gov.hk/sc/about/govdirectory/   (Chinese) 
The URL pairs always point to a pair of paral-
lel pages. So <?/en/?,?/sc/?> is considered as a 
URL pattern that was used to find parallel pages. 
For the other URLs that can?t match the pattern, 
we have to label them by hand. The column ?No 
pattern pairs? in Table 1 shows that the number 
of parallel page pairs which mismatch any pat-
terns. 
Table 1 Number of pages and bilingual page pairs of 
each websites 
Site ID En/Ch pages 
Total 
pairs 
No pat-
tern pairs 
URL 
S1 1101/1098 1092 20 www.gov.hk 
S2 501/497 487 7 www.customs.gov.hk 
S3 995/775 768 12 www.sbc.edu.sg 
S4 4085/3838 3648 4 www.swd.gov.hk 
S5 660/637 637 0 www.landsd.gov.hk 
S6 4733/4626 4615 8 www.td.gov.hk 
 total 12075/11471 11684 51  
Each website listed in Table 1 has a URL pat-
tern for most parallel web pages. Some previous 
researches used the URL similarity or patterns to 
find parallel page pairs. However, due to the di-
versity of web page styles and website mainte-
nance mechanisms, bilingual websites adopt var-
ied naming schemes for parallel documents (Shi, 
et al, 2006). The effect of URL pattern-based 
mining always depends on the style of website. 
In order to build a large dataset, the URL pattern 
is not used in our method. Our method is able to 
handle bilingual websites without URL pattern 
rules. 
In addition, an English-Chinese dictionary 
with 64K words pairs is used in our experiments. 
Algorithm 3 needs a threshold       or 
1220
       . It is very hard to tune the        
because it varies a lot in different websites and 
language pairs. However, Table 1 shows that the 
number of parallel pages is smaller than that of 
English and Chinese pages. Here, for each web-
site, the      is set to the number of Chinese 
pages (which is always smaller than that of Eng-
lish pages). In this way, the precision will never 
reach 100%, but it is more practical in a real ap-
plication. As a result, in some experiments, we 
only report the F-score, and the precision and 
recall can be calculated as follows:  
          
       (            )
      
                 (4) 
       
       (            )
        
                      (5) 
Where,        for each website is listed in the 
?Total  pairs? column of Table 1. 
4.2 Results and Analysis 
Performance of the Baseline 
Let?s start by presenting the performance of a 
baseline method as follows. The baseline only 
employs the internal translation similarity for 
parallel web pages mining. Algorithm 3 is also 
used to get the page pairs in baseline system. 
Here, the input    (   )  is replaced by 
   (   ) . The parameter   in Equation 2 is a 
discount factor. For different   values, the per-
formance of baseline system on six websites is 
shown in Figure 2. In the Figure 2, it shows that 
when   is set to 0.6, the baseline system achieves 
the best performance. The precision, recall and 
F-score are 85.84%, 87.55% and 86.69% respec-
tively. So in the following experiments, we al-
ways set ? to 0.6.  
 
Figure 2 Performances of baseline system with differ-
ent   value 
Performance of Our Method 
As described in Section 3, our method com-
bines the internal with external translation simi-
larity in estimating the final translation similarity 
(i.e., ETS) of two pages. So, the discount factor 
  in Equation (1) is important in our method. 
Besides, as shown in Algorithm 2, the iterative 
algorithm is used to calculate the similarity. Then, 
one question is that how many iterations are re-
quired in our algorithm. Figure 3 shows the per-
formance of our method on each website. Its hor-
izontal axis represents the number of iterations 
and the vertical axis represents the F-score. And 
for each website, the F-scores with different   
(range from 0.2 to 0.8) are also reported in this 
figure. From Figure 3, it is very easy to find that 
the best iteration number is 3. For almost all the 
websites, the performance of our method 
achieves the maximal values and converges after 
the third iteration. In addition, Figure 3 also indi-
cates that our method is robust for different web-
sites. In the following experiments, the iteration 
number is set to 3. 
Next, let?s turn to the discount factor  . Figure 
4 reports the experimental results on the whole 
dataset. Here, the horizontal axis represents the 
discount factor   and the vertical axis represents 
the F-score.     means that only the internal 
similarity is used in the algorithm, so the F-score 
equals to that in Figure 2 when      . On the 
contrary,     means that only the external 
similarity is used in the method, and the F-score 
is 80.20%. The performance is lower than the 
baseline system when only the external link in-
formation is used, but it is much better than the 
performance of the content-based method and 
structure-based method whose F-scores are 64.82% 
and 64.0% respectively. Besides, it is shown 
from Figure 4, the performance is improved sig-
nificantly when the internal and external similari-
ty measures are combined together. Furthermore, 
it is somewhat surprising that the discount factor 
  is not important as we previously expected. In 
fact, if we discard the cases that   equals to 0 or 
1, the difference between the maximum and min-
imum F-score will be 0.76% which is very small. 
This finding indicates that the internal and exter-
nal similarity can easily be combined and we 
don?t need to make many efforts to tune this pa-
rameter when our method is applied to other 
websites. The reason of this phenomenon is that, 
no matter how much weight (i.e., 1-  ) was as-
signed  to the internal similarity, the internal sim-
ilarity always provides a relatively good initial 
60
65
70
75
80
85
90
95
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
P
er
fo
rm
a
n
ce
(%
) 
? 
F-score Precision Recall
1221
 
Figure 3 Experiment results of our method on each website
iterative direction. In the following experiments, 
the parameter ? is set to 0.6. 
 
Figure 4 The F-scores of our method with different 
the value of ? 
The weight of pages 
The weight of the neighbor pages should also 
be considered. For example, in the most websites, 
it is very common that most of the web pages 
contain a hyperlink which points to the homep-
age of the website. While in most of the Eng-
lish/Chinese websites, almost every English page 
will link to the English homepage and each Chi-
nese page will point to Chinese homepage. The 
English and Chinese homepages are probably 
parallel, but they will be helpless to find parallel 
web pages, because they are neighbors of almost 
every page in the site. On the contrary, some-
times the parallel homepages have negative ef-
fects on finding parallel pages They will increase 
the translation similarity of two pages which are 
not indeed mutual translations. So it is necessary 
to amend the Algorithm 1.  
The weight of each page is calculated accord-
ing to its popularity: 
 ( )     
    
    ( )   
  (6) 
where ( ) indicates the weight of page  ,   is 
the number of all pages,     ( ) is the number 
of pages pointing to page   and   is a constant 
for smoothing.  
In this paper, the weights of pages are used in 
two ways: 
Weight 1: The 9th line of Algorithm 1 is 
amended by the page weight as follows: 
     ?           (   )  ( ( )   ( ))    
Weight 2: The pages with low weight are re-
moved from the input of Algorithm 1. 
The experiment results are shown in Table 2.  
Table 2 The effect of page weight 
Type No Weight Weight 1 Weight 2 
F-score (%) 92.91 92.78 92.75 
Surprisingly, no big differences are found after 
the introduction of the page weight. The side ef-
fect of popular pages is not so large in our meth-
od. In the neighbor pages of a certain page, the 
popular pages are the minority. Besides, the iter-
ative process makes our method more stable and 
robust. 
The impact of the size of bilingual lexicon 
The baseline system mainly combines the con-
tent-based similarity with structure similarity. 
86.69  
92.15  
92.42  
92.67  
92.78  
92.83  
92.91  
92.83  
92.61  
92.40  
80.20  
79
81
83
85
87
89
91
93
95
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
F
-s
co
re
(%
) 
? 
1222
And two kinds of similarity measures are also 
used in our method. As Ma and Liberman (1999) 
pointed out, not all translators create translated 
pages that look like the original page which 
means that the structure similarity does not al-
ways work well. Compared to the structure simi-
larity, the content-based is more reliable and has 
wider applicability. Furthermore, the bilingual 
lexicon is the only information that relates to the 
language pairs, and other features (such as struc-
ture and link information) are all language inde-
pendent. So, it?s important to investigate the ef-
fect of lexicon size in our method. We test the 
performance of our method with different size of 
the bilingual dictionary. The experiment results 
are shown in Figure 5. In this figure, the horizon-
tal axis represents the bilingual lexicon size and 
the vertical axis represents the F-score. With the 
decline of the lexicon size, the performances of 
both the baseline method and our method are 
decreased. However, we can find that the descent 
rate of our method is smaller than that of the 
baseline. It indicates that our method does not 
need a big bilingual lexicon which is good news 
for the low-resource language pairs. 
 
Figure 5 The impact of the size of bilingual lexicon 
Error analysis  
Errors occur when the two pages are similar in 
terms of structure, content and their neighbors. 
For example, Figure 6 illustrates a typical web 
page structure. There are 5 parts in the web page: 
 ,  ,  ,   and  . Part   always contains the 
main content of this page. While part  ,  ,   and 
  always contain some hyperlinks such as ?home? 
in part   and ?About us? in part  . Links in   
and   sometimes relate to the content of the page. 
For such a kind of non-parallel page pairs, let?s 
assume that the two pages have the same struc-
ture (as shown in Figure 6). In addition, their 
content part   is very short and contains the 
same or related topics. As a result, the links in 
other 4 parts are likely to be similar. In this case, 
our method is likely to regard the two pages as 
parallel.  
M
U
B
L R
 
Figure 6 A typical web page structure 
There are about 920 errors when our system 
obtains its best performance. By carefully inves-
tigating the error page pairs, we find that more 
than 90% errors fall into the category discussed 
above. The websites used in our experiments 
mainly come from Hong Kong government web-
sites. Some government departments regularly 
publish quarterly or monthly work reports on one 
issue through their websites. These reports look 
very similar except the publish date and some 
data in them. The other 10% errors happen be-
cause of the particularity of the web pages, e.g. 
very short pages, broken pages and so on. 
5 Conclusions and Future Work 
Parallel corpora are valuable resources for a lot 
of NLP research problems and applications, such 
as MT and CLIR. This paper introduces an effi-
cient and effective solution to bilingual language 
processing. We first explore how to extract paral-
lel page pairs in bilingual websites with link in-
formation between web pages. Firstly, we hy-
pothesize that the translation similarity of pages 
should be based on both internal and external 
translation similarity. Secondly, a novel iterative 
method is proposed to verify parallel page pairs. 
Experimental results show that our method is 
much more effective than the baseline system 
with 6.2% improvement on F-Score. Further-
more, our method has some significant contribu-
tions. For example, compared to previous work, 
our method does not depend on bilingual lexi-
cons, and the parameters in our method have lit-
tle effect on the final performance. These fea-
tures improve the applicability of our method. 
In the future work, we will study some method 
on extracting parallel resource from existing par-
allel page pairs, which are challenging tasks due 
to the diversity of page structures and styles. Be-
sides, we will evaluate the effectiveness of our 
mined data on MT or other applications. 
78
80
82
84
86
88
90
92
94
64K 32K 16K 8K 4K 2K 1K
F
-s
co
re
 (
%
) 
Lexicon Size 
Baseline Our Method
1223
Acknowledgments 
This research work has been sponsored by Na-
tional Natural Science Foundation of China 
(Grants No.61373097 and No.61272259), one 
National Natural Science Foundation of Jiangsu 
Province (Grants No.BK2011282), one Major 
Project of College Natural Science Foundation of 
Jiangsu Province (Grants No.11KJA520003) and 
one National Science Foundation of Suzhou City 
(Grants No.SH201212).  
The corresponding author of this paper, ac-
cording to the meaning given to this role by 
School of computer science and technology at 
Soochow University, is Yu Hong 
Reference 
Chen, Jiang and Jianyun Nie. 2000. Automatic con-
struction of parallel English-Chinese corpus for 
cross-language information retrieval. Proceedings 
of the sixth conference on Applied Natural Lan-
guage Processing, 21?28. 
Resnik, Philip and Noah A. Smith. 2003. The Web as 
a Parallel Corpus. Meeting of the Association for 
Computational Linguistics 29(3). 349?380. 
Kit, Chunyu and Jessica Yee Ha Ng. 2007. An Intelli-
gent Web Agent to Mine Bilingual Parallel Pages 
via Automatic Discovery of URL Pairing Patterns. 
Web Intelligence and Intelligent Agent Technology 
Workshops, 526?529. 
Zhang, Ying, Ke Wu, Jianfeng Gao and Phil Vines. 
2006. Automatic Acquisition of Chinese-English 
Parallel Corpus from the Web. Joint Proceedings of 
the Association for Computational Linguistics and 
the International Conference on Computational 
Linguistics, 420?431. 
Nie, Jianyun, Michel Simard, Pierre Isabelle and 
Richard Durand. 1999. Cross-language information 
retrieval based on parallel texts and automatic min-
ing of parallel texts from the Web. Proceedings of 
the 22nd annual international ACM SIGIR confer-
ence on Research and development in information 
retrieval, 74?81. 
Ma, Xiaoyi and Mark Y. Liberman. 1999. BITS: A 
Method for Bilingual Text Search over the Web. 
Machine Translation Summit VII. 
Chen, Jisong, Rowena Chau and Chung-Hsing Yeh. 
2004. Discovering Parallel Text from the World 
Wide Web. The Australasian Workshop on Data 
Mining and Web Intelligence, vol. 32, 157?161. 
Dunedin, New Zealand. 
Jiang, Long, Shiquan Yang, Ming Zhou, Xiaohua Liu 
and Qingsheng Zhu. 2009. Mining Bilingual Data 
from the Web with Adaptively Learnt Patterns. 
Proceedings of the Joint Conference of the 47th 
Annual Meeting of the ACL and the 4th Interna-
tional Joint Conference on Natural Language Pro-
cessing of the AFNLP, vol. 2, 870?878. 
Yanhui Feng, Yu Hong, Zhenxiang Yan, Jianmin  
Yao and Qiaoming Zhu. 2010. A novel method for 
bilingual web page acquisition from search engine 
web records. Proceedings of the 23rd International 
Conference on Computational Linguistics: Posters, 
294?302.  
Zhao, Bing and Stephan Vogel. 2002. Adaptive Paral-
lel Sentences Mining from Web Bilingual News 
Collection. IEEE International Conference on Data 
Mining, 745?748. 
Smith, Jason R., Chris Quirk and Kristina Toutanova. 
2010. Extracting parallel sentences from compara-
ble corpora using document level alignment. Hu-
man Language Technologies: The 2010 Annual 
Conference of the North American Chapter of the 
Association for Computational Linguistics, 403?
411. 
Bharadwaj, Rohit G. and Vasudeva Varma. 2011. 
Language independent identification of parallel 
sentences using wikipedia. Proceedings of the 20th 
International Conference Companion on World 
Wide Web, 11?12. Hyderabad, India. 
Gusfield, Dan. 1997. Algorithms on Strings, Trees 
and Sequences: Computerss Science and Computa-
tional Biology. Cambridge University Press  
Shi, Lei, Cheng Niu, Ming Zhou and Jianfeng Gao. 
2006. A DOM Tree Alignment Model for Mining 
Parallel Data from the Web. Proceedings of the 
21st International Conference on Computational 
Linguistics and the 44th annual meeting of the As-
sociation for Computational Linguistics, 489?496. 
 
 
1224
