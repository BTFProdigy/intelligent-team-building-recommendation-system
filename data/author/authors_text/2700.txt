Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 170?179,
Singapore, 6-7 August 2009.
c
?2009 ACL and AFNLP
Supervised and Unsupervised Methods in Employing Discourse Relations
for Improving Opinion Polarity Classification
Swapna Somasundaran
Univ. of Pittsburgh
Pittsburgh, PA 15260
swapna@cs.pitt.edu
Galileo Namata
Univ. of Maryland
College Park, MD 20742
namatag@cs.umd.edu
Janyce Wiebe
Univ. of Pittsburgh
Pittsburgh, PA 15260
wiebe@cs.pitt.edu
Lise Getoor
Univ. of Maryland
College Park, MD 20742
getoor@cs.umd.edu
Abstract
This work investigates design choices in
modeling a discourse scheme for im-
proving opinion polarity classification.
For this, two diverse global inference
paradigms are used: a supervised collec-
tive classification framework and an un-
supervised optimization framework. Both
approaches perform substantially better
than baseline approaches, establishing the
efficacy of the methods and the underlying
discourse scheme. We also present quan-
titative and qualitative analyses showing
how the improvements are achieved.
1 Introduction
The importance of discourse in opinion analy-
sis is being increasingly recognized (Polanyi and
Zaenen, 2006). Motivated by the need to en-
able discourse-based opinion analysis, previous
research (Asher et al, 2008; Somasundaran et al,
2008) developed discourse schemes and created
manually annotated corpora. However, it was not
known whether and how well these linguistic ideas
and schemes can be translated into effective com-
putational implementations.
In this paper, we first investigate ways in which
an opinion discourse scheme can be computation-
ally modeled, and then how it can be utilized to
improve polarity classification. Specifically, the
discourse scheme we use is from Somasundaran
et al (2008), which was developed to support a
global, interdependent polarity interpretation. To
achieve discourse-based global inference, we ex-
plore two different frameworks. The first is a
supervised framework that learns interdependent
opinion interpretations from training data. The
second is an unsupervised optimization frame-
work which uses constraints to express the ideas
of coherent opinion interpretation embodied in the
scheme. For the supervised framework, we use It-
erative Collective Classification (ICA), which fa-
cilitates machine learning using relational infor-
mation. The unsupervised optimization is imple-
mented as an Integer Linear Programming (ILP)
problem. Via our implementations, we aim to
empirically test if discourse-based approaches to
opinion analysis are useful.
Our results show that both of our implemen-
tations achieve significantly better accuracies in
polarity classification than classifiers using local
information alone. This confirms the hypothesis
that the discourse-based scheme is useful, and also
shows that both of our design choices are effective.
We also find that there is a difference in the way
ICA and ILP achieve improvements, and a simple
hybrid approach, which incorporates the strengths
of both, is able to achieve significant overall im-
provements over both. Our analyses show that
even when our discourse-based methods bootstrap
from noisy classifications, they can achieve good
improvements.
The rest of this paper is organized as follows:
we discuss related work in Section 2 and the
discourse scheme in Section 3. We present our
discourse-based implementations in Section 4, ex-
periments in Section 5, discussions in Section 6
and conclusions in Section 7.
2 Related Work
Previous work on polarity disambiguation has
used contextual clues and reversal words (Wil-
son et al, 2005; Kennedy and Inkpen, 2006;
Kanayama and Nasukawa, 2006; Devitt and Ah-
mad, 2007; Sadamitsu et al, 2008). However,
these do not capture discourse-level relations.
Researchers, such as (Polanyi and Zaenen,
2006), have discussed how the discourse struc-
ture can influence opinion interpretation; and pre-
vious work, such as (Asher et al, 2008; Soma-
sundaran et al, 2008), have developed annota-
170
tion schemes for interpreting opinions with dis-
course relations. However, they do not empiri-
cally demonstrate how automatic methods can use
their ideas to improve polarity classification. In
this work, we demonstrate concrete ways in which
a discourse-based scheme can be modeled using
global inference paradigms.
Joint models have been previously explored for
other NLP problems (Haghighi et al, 2005; Mos-
chitti et al, 2006; Moschitti, 2009). Our global in-
ference model focuses on opinion polarity recog-
nition task.
The biggest difference between this work and
previous work in opinion analysis that use global
inference methods is in the type of linguistic
relations used to achieve the global inference.
Some of the work is not related to discourse
at all (e.g., lexical similarities (Takamura et al,
2007), morphosyntactic similarities (Popescu and
Etzioni, 2005) and word-based measures like TF-
IDF (Goldberg and Zhu, 2006)). Others use
sentence cohesion (Pang and Lee, 2004), agree-
ment/disagreement between speakers (Thomas et
al., 2006; Bansal et al, 2008), or structural adja-
cency. In contrast, our work focuses on discourse-
based relations for global inference. Another dif-
ference from the above work is that our work is
over multi-party conversations.
Previous work on emotion and subjectivity
detection in multi-party conversations has ex-
plored using prosodic information (Neiberg et al,
2006), combining linguistic and acoustic infor-
mation (Raaijmakers et al, 2008) and combining
lexical and dialog information (Somasundaran et
al., 2007). Our work is focused on harnessing
discourse-based knowledge and on interdependent
inference.
There are several collective classification
frameworks, including (Neville and Jensen, 2000;
Lu and Getoor, 2003; Taskar et al, 2004; Richard-
son and Domingos, 2006; Bilgic et al, 2007). In
this paper, we use an approach by (Lu and Getoor,
2003) which iteratively predicts class values using
local and relational features. ILP has been used
on other NLP tasks, e.g., (Denis and Baldridge,
2007; Choi et al, 2006; Roth and Yih, 2004). In
this work, we employ ILP for modeling discourse
constraints for polarity classification.
3 Discourse Scheme and Data
The scheme in Somasundaran et al (2008) has
been developed and annotated over the AMI meet-
ing corpus (Carletta et al, 2005).
1
This scheme
annotates opinions, their polarities (positive, neg-
ative, neutral) and their targets (a target is what
the opinion is about). The targets of opinions are
related via two types of relations: the same rela-
tion, which relates targets referring to the same
entity or proposition, and the alternative relation,
which relates targets referring to mutually exclu-
sive options in the context of the discourse. Ad-
ditionally, the scheme relates opinions via two
types of frame relations: the reinforcing and non-
reinforcing relations. The frame relations repre-
sent discourse scenarios: reinforcing relations ex-
ist between opinions when they contribute to the
same overall stance, while non-reinforcing rela-
tions exist between opinions that show ambiva-
lence.
The opinion annotations are text-span based,
while in this work, we use Dialog Act (DA) based
segmentation of meetings.
2
As the DAs are our
units of classification, we map opinion annotations
to the DA units as follows. If a DA unit contains
an opinion annotation, the label is transferred up-
wards to the containing DA. When a DA contains
multiple opinion annotations, each with a differ-
ent polarity, one of them is randomly chosen as
the label for the DA. The discourse relations exist-
ing between opinions are also transferred upwards,
between the DAs containing each of these anno-
tations. We recreate an example from Somasun-
daran et al (2008) using DA segmentation in Ex-
ample 1. Here, the speaker has a positive opinion
towards the rubbery material for the TV remote.
(1) DA-1: ... this kind of rubbery material,
DA-2: it?s a bit more bouncy,
DA-3: like you said they get chucked around a lot.
DA-4: A bit more durable and that can also be er-
gonomic and
DA-5: it kind of feels a bit different from all the
other remote controls.
In the example, the individual opinion expressions
(shown in bold) are essentially regarding the same
thing ? the rubbery material. Thus, the explicit
targets (shown in italics), it?s, that, and it, and the
implicit target of a bit more durable are all linked
1
The AMI corpus contains a set of scenario-based meet-
ings where participants have to design a new TV remote pro-
totype.
2
DA segmentation is provided with the AMI corpus.
171
Figure 1: Discourse Relations between DA seg-
ments for Example 1.
with same target relations. Also, notice that the
opinions reinforce a particular stance, i.e., a pro-
rubbery-material stance. Thus, the scheme links
the opinions via reinforcing relations. Figure 1 il-
lustrates the corresponding discourse relations be-
tween the containing DA units.
4 Implementing the Discourse Model
The hypothesis in using discourse information for
polarity classification is that the global discourse
view will improve upon a classification with only
a local view. Thus, we implement a local clas-
sifier to bootstrap the classification process, and
then implement classifiers that use discourse in-
formation from the scheme annotations, over it.
We explore two approaches for implementing our
discourse-based classifier. The first is ICA, where
discourse relations and the neighborhood informa-
tion brought in by these relations are incorporated
as features into the learner. The second approach
is ILP optimization, which tries to maximize the
class distributions predicted by the local classifier,
subject to constraints imposed by discourse rela-
tions. Both classifiers thus accommodate prefer-
ences of the local classifier and for coherence with
discourse neighbors.
4.1 Local Classifier
A supervised local classifier, Local, is used to pro-
vide the classifications to bootstrap the discourse-
based classifiers.
3
It is important to make Local as
reliable as possible; otherwise, the discourse rela-
tions will propagate misclassifications. Thus, we
build Local using a variety of knowledge sources
that have been shown to be useful for opinion anal-
ysis in previous work. Specifically, we construct
features using polarity lexicons (used by (Wilson
et al, 2005)), DA tags (used by (Somasundaran
3
Local is supervised, as previous work has shown that
supervised methods are effective in opinion analysis. Even
though this makes the final end-to-end system with the ILP
implementation semi-supervised, note that the discourse-
based ILP part is itself unsupervised.
et al, 2007)) and unigrams (used by many re-
searchers, e.g., (Pang and Lee, 2004)).
Note that, as our discourse-based classifiers at-
tempt to improve upon the local classifications,
Local is also a baseline for our experiments.
4.2 Iterative Collective Classification
We use a variant of ICA (Lu and Getoor, 2003;
Neville and Jensen, 2000), which is a collective
classification algorithm shown to perform consis-
tently well over a wide variety of relational data.
Algorithm 1 ICA Algorithm
for each instance i do {bootstrapping}
Compute polarity for i using local attributes
end for
repeat {iterative}
Generate ordering I over all instances
for each i in I do
Compute polarity for i using local and re-
lational attributes
end for
until Stopping criterion is met
ICA uses two classifiers: a local classifier and a
relational classifier. The local classifier is trained
to predict the DA labels using only the local fea-
tures. We use Local, described in Section 4.1, for
this purpose. The relational classifier is trained us-
ing the local features, and an additional set of fea-
tures commonly referred to as relational features.
The value of a relational feature, for a given DA,
depends on the polarity of the discourse neighbors
of that DA. Thus, the relational features incorpo-
rate discourse and neighbor information; that is,
they incorporate the information about the frame
and target relations in conjunction with the polar-
ity of the discourse neighbors. Intuitively, our mo-
tivation for this approach can be explained using
Example 1. Here, in interpreting the ambiguous
opinion a bit different as being positive, we use
the knowledge that it participates in a reinforc-
ing discourse, and that all its neighbors (e.g., er-
gonomic, durable) are positive opinions regard-
ing the same thing. On the other hand, if it had
been a non-reinforcing discourse, then the polar-
ity of a bit different, when viewed with respect to
the other opinions, could have been interpreted as
negative.
Table 1 lists the relational features we defined
for our experiments where each row represents a
172
Percent of neighbors with polarity type a related via frame relation f
?
Percent of neighbors with polarity type a related via target relation t
?
Percent of neighbors with polarity type a related via frame relation f and target relation t
Percent of neighbors with polarity type a and same speaker related via frame relation f
?
Percent of neighbors with polarity type a and same speaker related via target relation t
?
Percent of neighbors with polarity type a related via a frame relation or target relation
Percent of neighbors with polarity type a related via a reinforcing frame relation or same target relation
Percent of neighbors with polarity type a related via a non-reinforcing frame relation or alt target relation
Most common polarity type of neighbors related via a same target relation
Most common polarity type of neighbors related via a reinforcing frame relation and same target relation
Table 1: Relational features: a ? {non-neutral (i.e., positive or negative), positive, negative}, t ? {same, alt},
f ? {reinforcing, non-reinforcing}, t
?
? {same or alt, same, alt}, f
?
? {reinforcing or non-reinforcing, reinforcing, non-
reinforcing}
set of features. Features are generated for all com-
binations of a, t, t
?
, f and f
?
for each row. For
example, one of the features in the first row is Per-
cent of neighbors with polarity type positive, that
are related via a reinforcing frame relation. Thus,
each feature for the relational classifier identifies
neighbors for a given instance via a specific rela-
tion (f , t, f
?
or t
?
, obtained from the scheme an-
notations) and factors in their polarity values (a,
obtained from the classifier predictions from the
previous round). This adds a total of 59 relational
features to the already existing local features.
ICA has two main phases: the bootstrapping
and iterative phases. In the bootstrapping phase,
the polarity of each instance is initialized to the
most likely value given only the local classifier
and its features. In the iterative phase, we cre-
ate a random ordering of all the instances and,
in turn, apply the relational classifier to each in-
stance where the relational features, for a given
instance, are computed using the most recent po-
larity assignments of its neighbors. We repeat this
until some stopping criterion is met. For our ex-
periments, we use a fixed number of 30 iterations,
which has been found to be sufficient in most data
sets for ICA to converge to a solution.
The pseudocode for the algorithm is shown in
Algorithm 1.
4.3 Integer Linear Programming
First, we explain the intuition behind viewing dis-
course relations as enforcing constraints on polar-
ity interpretation. Then, we explain how the con-
straints are encoded in the optimization problem.
4.3.1 Discourse Constraints on Polarity
The discourse relations between opinions can pro-
vide coherence constraints on the way their polar-
ity is interpreted. Consider a discourse scenario
in which a speaker expresses multiple opinions
regarding the same thing, and is reinforcing his
stance in the process (as in Example 1). The set
of individual polarity assignments that is most co-
herent with this global scenario is the one where
all the opinions have the same (equal) polarity. On
the other hand, a pair of individual polarity assign-
ments most consistent with a discourse scenario
where a speaker reinforces his stance via opinions
towards alternative options, is one with opinions
having mutually opposite polarity. For instance,
in the utterance ?Shapes should be curved, noth-
ing square-like?, the speaker reinforces his pro-
curved stance via his opinions about the alternative
shapes: curved and square-like. And, we see that
the first opinion is positive and the second is neg-
ative. Table 2 lists the discourse relations (target
and frame relation combinations) found in the cor-
pus, and the likely polarity interpretation for the
related instances.
Target relation + Frame relation Polarity
same+reinforcing equal (e)
same+non-reinforcing opposite (o)
alternative+reinforcing opposite (o)
alternative+non-reinforcing equal (e)
Table 2: Discourse relations and their polarity con-
straints on the related instances.
4.3.2 Optimization Problem
For each DA instance i in a dataset, the local
classifier provides a class distribution [p
i
, q
i
, r
i
],
where p
i
, q
i
and r
i
correspond to the probabilities
that i belongs to positive, negative and neutral cat-
egories, respectively. The optimization problem is
formulated as an ILP minimization of the objec-
tive function in Equation 1.
?1?
?
i
(p
i
x
i
+q
i
y
i
+r
i
z
i
)+
?
i,j

ij
+
?
i,j
?
ij
(1)
173
where the x
i
, y
i
and z
i
are binary class vari-
ables corresponding to positive, negative and neu-
tral classes, respectively. When a class variable
is 1, the corresponding class is chosen. Variables

ij
and ?
ij
are binary slack variables that corre-
spond to the discourse constraints between two
distinct DA instances i and j. When a given slack
variable is 1, the corresponding discourse con-
straint is violated. Note that the objective func-
tion tries to achieve two goals. The first part
(
?
i
p
i
x
i
+ q
i
y
i
+ r
i
z
i
) is a maximization that tries
to choose a classification for the instances that
maximizes the probabilities provided by the local
classifier. The second part (
?
i,j

ij
+
?
i,j
?
ij
) is a
minimization that tries to minimize the number of
slack variables used, that is, minimize the number
of discourse constraints violated.
Constraints in Equations 2 and 3 listed below
impose binary constraints on the variables. The
constraint in Equation 4 ensures that, for each in-
stance i, only one class variable is set to 1.
x
i
? {0, 1}, y
i
? {0, 1}, z
i
? {0, 1} , ?i (2)

ij
? {0, 1}, ?
ij
? {0, 1} , ?i 6= j (3)
x
i
+ y
i
+ z
i
= 1 , ?i (4)
We pair distinct DA instances i and j as ij,
and if there exists a discourse relation between
them, they can be subject to the corresponding po-
larity constraints listed in Table 2. For this, we
define two binary discourse-constraint constants:
the equal-polarity constant, e
ij
and the opposite-
polarity constant, o
ij
. If a given DA pair ij is
related by either a same+reinforcing relation or
an alternative+non-reinforcing relation (rows 1, 4
of Table 2), then e
ij
= 1; otherwise it is zero.
Similarly, if it is related by either a same+non-
reinforcing relation or an alternative+reinforcing
relation (rows 2, 3 of Table 2), then o
ij
= 1. Both
e
ij
and o
ij
are zero if the instance pair is unrelated
in the discourse.
For each DA instance pair ij, equal-polarity
constraints are applied to the polarity variables of i
(x
i
, y
i
) and j (x
j
, y
j
) via the following equations:
|x
i
? x
j
| ? 1? e
ij
+ 
ij
, ?i 6= j (5)
|y
i
? y
j
| ? 1? e
ij
+ 
ij
, ?i 6= j (6)
?(x
i
+ y
i
) ? ?l
i
, ?i (7)
When e
ij
= 1, the Equation 5 constrains x
i
and
x
j
to be of the same value (both zero or both one).
Similarly, Equation 6 constrains y
i
and y
j
to be
of the same value. Via these equations, we ensure
that the instances i and j do not have the oppo-
site polarity when e
ij
= 1. However, notice that,
if we use just Equations 5 and 6, the optimization
can converge to the same, non-polar (neutral) cat-
egory. To guide the convergence to the same polar
(positive or negative) category, we use Equation 7.
Here l
i
= 1 if the instance i participates in one or
more discourse relations. When e
ij
= 0, x
i
and x
j
(and y
i
and y
j
), can take on assignments indepen-
dently of one another. Notice that both constraints
5 and 6 are relaxed when 
ij
= 1; thus, x
i
and x
j
(or y
i
and y
j
) can take on values independently of
one another, even if e
ij
= 1.
Next, the opposite-polarity constraints are ap-
plied via the following equations:
|x
i
+ x
j
? 1| ? 1? o
ij
+ ?
ij
, ?i 6= j (8)
|y
i
+ y
j
? 1| ? 1? o
ij
+ ?
ij
, ?i 6= j (9)
In the above equations, when o
ij
= 1, x
i
and x
j
(and y
i
and y
j
) take on opposite values; for exam-
ple, if x
i
= 1 then x
j
= 0 and vice versa. When
o
ij
= 0, the variable assignments are independent
of one another. This set of constraints is relaxed
when ?
ij
= 1.
In general, in our ILP formulation, notice that
if an instance does not have a discourse relation to
any other instance in the data, its classification is
unaffected by the optimization. Also, as the un-
derlying discourse scheme poses constraints only
on the interpretation of the polarity of the related
instances, discourse constraints are applied only to
the polarity variables x and y, and not to the neu-
tral class variable, z. Finally, even though slack
variables are used, we discourage the ILP system
from indiscriminately setting the slack variables to
1 by making them a part of the objective function
that is minimized.
5 Experiments
In this work, we are particularly interested in
improvements due to discourse-based methods.
Thus, we report performance under three con-
ditions: over only those instances that are re-
lated via discourse relations (Connected), over in-
stances not related via discourse relations (Single-
tons), and over all instances (All).
The annotated data consists of 7 scenario-based,
multi-party meetings from the AMI meeting cor-
pus. We filter out very small DAs (DAs with fewer
than 3 tokens, punctuation included). This gives
174
us a total of 4606 DA instances, of which 1935
(42%) have opinion annotations. For our exper-
iments, the DAs with no opinion annotations as
well as those with neutral opinions are considered
as neutral. Table 3 shows the class distributions in
the data for the three conditions.
Pos Neg Neutral Total
Connected 643 343 81 1067
Singleton 553 233 2753 3539
All 1196 576 2834 4606
Table 3: Class distribution over connected, single
and all instances.
5.1 Classifiers
Our first baseline, Base, is a simple distribution-
based classifier that classifies the test data based
on the overall distribution of the classes in the
training data. However, in Table 3, the class distri-
bution is different for the Connected and Single-
ton conditions. We incorporate this in a smarter
baseline, Base-2, which constructs separate dis-
tributions for connected instances and singletons.
Thus, given a test instance, depending on whether
it is connected, Base-2 uses the corresponding dis-
tribution to make its prediction.
The third baseline is the supervised classifier,
Local, described in Section 4.1. It is imple-
mented using the SVM classifiers from the Weka
toolkit (Witten and Frank, 2002).
4
Our super-
vised discourse-based classifier, ICA from Sec-
tion 4.2, also uses a similar SVM implemen-
tation for its relational classifier. We imple-
ment our ILP approach from Section 4.3 us-
ing the optimization toolbox from Mathworks
(http://www.mathworks.com) and GNU Linear
Programming Kit.
We observed that the ILP system performs bet-
ter than the ICA system on instances that are con-
nected, while ICA performs better on singletons.
Thus, we also implemented a simple hybrid clas-
sifier (HYB), which selects the ICA prediction for
classification of singletons and the ILP prediction
for classification of connected instances.
5.2 Results
We performed 7-fold cross validation experi-
ments, where six meetings are used for training
4
We use the SMO implementation, which, when used
with the logistic regression, has an output that can be viewed
as a posterior probability distribution.
and the seventh is used for testing the supervised
classifiers (Base, Base-2, Local and ICA). In the
case of ILP, the optimization is applied to the out-
put of Local for each test fold. Table 4 reports the
accuracies of the classifiers, averaged over 7 folds.
First, we observe that Base performs poorly
over connected instances, but performs consider-
ably better over singletons. This is expected as the
overall majority class is neutral and the singletons
are more likely to be neutral. Base-2, which incor-
porates the differentiated distributions, performs
substantially better than Base. Local achieves an
overall performance improvement over Base and
Base-2 by 23 percentage points and 9 percent-
age points, respectively. In general, Local outper-
forms Base for all three conditions (p < 0.001),
and Base-2 for the Singleton and All conditions
(p < 0.001). This overall improvement in Local?s
accuracy corroborates the utility of the lexical, un-
igram and DA based features for polarity detection
in this corpus.
Turning to the discourse-based classifiers, ICA,
ILP and HYB, all of these perform better than
Base and Base-2 for all conditions. ICA improves
over Local by 9 percentage points for Connected,
3 points for Singleton and 4 points for All. ILP?s
improvement over Local for Connected and All is
even more substantial: 28 percentage points and
6 points, respectively. Notice that ILP has the
same performance as Local for Singletons, as the
discourse constraints are not applied over uncon-
nected instances. Finally, HYB significantly out-
performs Local under all conditions. The signif-
icance levels of the improvements over Local are
highlighted in Table 4. These improvements also
signify that the underlying discourse scheme is
effective, and adaptable to different implementa-
tions.
Interestingly, ICA and ILP improve over Local
in different ways. While ILP sharply improves the
performance over the connected instances, ICA
shows relatively modest improvements over both
connected and singletons. ICA?s improvement
over singletons is interesting because it indicates
that, even though the features in Table 1 are fo-
cused on discourse relations, ICA utilizes them to
learn the classification of singletons too.
Comparing our discourse-based approaches,
ILP does significantly better than ICA over con-
nected instances (p < 0.001), while ICA does
significantly better than ILP over singletons (p <
175
Base Base-2 Local ICA ILP HYB
Connected 24.4 47.56 46.66 55.64 75.07 75.07
Singleton 51.72 63.23 75.73 78.72 75.73 78.72
All 45.34 59.46 68.72 73.31 75.35 77.72
Table 4: Accuracies of the classifiers measured over Connected, Singleton and All instances. Perfor-
mance significantly better than Local are indicated in bold for p < 0.001 and underline for p < 0.01.
0.01). However, there is no significant difference
between ICA and ILP for the All condition. The
HYB classifier outperforms ILP for the Singleton
condition (p < 0.01) and ICA for the Connected
condition (p < 0.001). Interestingly, over all in-
stances (the All condition), HYB also performs
significantly better than both ICA (p < 0.001) and
ILP (p < 0.01).
5.3 Analysis
Amongst our two approaches, ILP performs bet-
ter, and hence we further analyze its behavior to
understand how the improvements are achieved.
Table 5 reports the performance of ILP and Local
for the precision, recall and f-measure metrics (av-
eraged over 7 test folds), measured separately for
each of the opinion categories. The most promi-
nent improvement by ILP is observed for the re-
call of the polar categories under the Connected
condition: 40 percentage points for the positive
class, and 29 percentage points for the negative
class. The gain in recall is not accompanied by
a significant loss in precision. This results in an
improvement in f-measure for the polar categories
(24 points for positive and 16 points for negative).
Also note that, by virtue of the constraint in Equa-
tion 7, ILP does not classify any connected in-
stance as neutral; thus the precision is NaN, recall
is 0 and the f-meaure is NaN. This is indicated as
* in the Table.
The improvement of ILP for the All condition,
for the polar classes, follows a similar trend for re-
call (18 to 21 point improvement) and f-measure
(9 to 13 point improvement). In addition to this,
the ILP has an overall improvement in precision
over Local. This may seem counterintuitive, as
in Table 5, ILP?s precision for connected nodes is
similar to, or lower than, that of Local. This is
explained by the fact that, while going from con-
nected to overall conditions, Local?s polar predic-
tions increase by threefold (565 to 1482), but its
correct polar predictions increase by only twofold
(430 to 801). Thus, the ratio of change in the total
Gold Local
Pos Neg Neut Total
Pos 551 113 532 1196
Neg 121 250 205 576
Neut 312 135 2387 2834
Total 984 498 3124 4606
Gold ILP
Pos Neg Neut Total
Pos 817 157 222 1196
Neg 147 358 71 576
Neut 358 147 2329 2834
Total 1322 662 2622 4606
Table 6: Contingency table over all instances.
polar predictions to the correct polar predictions is
3 : 2. On the other hand, while polar predictions
by ILP increase by only twofold (1067 to 1984),
its correct polar predictions increase by 1.5 times
(804 to 1175). Here, the ratio of change in the total
polar predictions to the correct polar predictions is
4 : 3, a smaller ratio.
The contingency table (Table 6) shows how Lo-
cal and ILP compare against the gold standard
annotations. Notice here, that even though ILP
makes more polar guesses as compared to Local, a
greater proportion of the ILP guesses are correct.
The number of non-diagonal elements are much
smaller for ILP, resulting in the accuracy improve-
ments seen in Table 4.
6 Examples and Discussion
The results in Table 4 show that Local, which pro-
vides the classifications for bootstrapping ICA and
ILP, predicts an incorrect class for more than 50%
of the connected instances. Methods starting with
noisy starting points are in danger of propagating
the errors and hence worsening the performance.
Interestingly, in spite of starting with so many bad
classifications, ILP is able to achieve a large per-
formance improvement. We discovered that, given
a set of connected instances, even when Local has
only one correct guess, ILP is able to use this to
rectify the related instances. We illustrate this situ-
ation in Figure 2, which reproduces the connected
DAs for Example 1. It shows the classifications
176
Positive Negative Neutral
Local ILP Local ILP Local ILP
Connected-Prec 78.1 78.2 71.9 69.8 12.1
Connected-Recall 45.3 86.3 44.1 73.4 62.8 *
Connected-F1 56.8 81.5 54.0 70.7 18.5
All-Prec 56.2 61.3 52.3 54.6 76.3 88.3
All-Recall 46.6 67.7 44.3 62.5 83.9 81.5
All-F1 50.4 64.0 46.0 57.1 79.6 84.6
Table 5: Precision, Recall, Fmeasure for each Polarity category. Performance significantly better than
Local are indicated in bold (p < 0.001), underline (p < 0.01) and italics (p < 0.05). The * denotes that
ILP does not retrieve any connected node as neutral.
Figure 2: Discourse Relations and Classifications
for Example 1.
for each DA from the gold standard (G), the Local
classifier (L) and the ILP classifier (ILP). Observe
that Local predicts the correct positive class (+) for
only DA-4 (the DA containing bit more durable
and ergonomic). Notice that these are clear cases
of positive evaluation. It incorrectly predicts the
polarity of DA-2 (containing bit more bouncy)
as neutral (*), and DA-5 (containing a bit dif-
ferent from all the other remote controls) as
negative (-). DA-2 and DA-5 exemplify the fact
that polarity classification is a complex and diffi-
cult problem: being bouncy is a positive evalua-
tion in this particular discourse context, and may
not be so elsewhere. Thus, naturally, lexicons and
unigram-based learning would fail to capture this
positive evaluation. Similarly, ?being different?
could be deemed negative in other discourse con-
texts. However, ILP is able to arrive at the correct
predictions for all the instances. As the DA-4 is
connected to both DA-2 and DA-5 via a discourse
relation that enforces an equal-polarity constraint
(same+reinforcing relation of row 1, Table 2), both
of the misclassifications are rectified. Presumably,
the incorrect predictions made by Local are low
confidence estimates, while the predictions of the
correct cases have high confidence, which makes
it possible for ILP to make the corrections.
We also observed the propagation of the correct
classification for other types of discourse relations,
for more complex types of connectivity, and also
for conditions where an instance is not directly
connected to the correctly predicted instance. The
meeting snippet below (Example 2) and its cor-
responding DA relations (Figure 3) illustrate this.
This example is a reinforcing discourse where the
speaker is arguing for the number keypad, which is
an alternative to the scrolling option. Thus, he ar-
gues against the scrolling, and argues for entering
the number (which is a capability of the number
keypad).
(2) D-1: I reckon you?re gonna have to have a num-
ber keypad anyway for the amount of channels these
days,
D-2: You wouldn?t want to just have to scroll
through all the channels to get to the one you want
D-3: You wanna enter just the number of it , if you
know it
D-4: I reckon we?re gonna have to have a number
keypad anyway
In Figure 3, we see that, DA-2 is connected via an
alternative+reinforcing discourse relation to each
of its neighbors DA-1 and DA-3, which encour-
ages the optimization to choose a class for it that
is opposite to DA-1 and DA-3. Notice also, that
even though Local predicts only DA-4 correctly,
this correct classification finally influences the cor-
rect choice for all the instances, including the re-
motely connected DA-2.
7 Conclusions and Future Work
This work focuses on the first step to ascertain
whether discourse relations are useful for improv-
ing opinion polarity classification, whether they
can be modeled and what modeling choices can
be used. To this end, we explored two distinct
paradigms: the supervised ICA and the unsuper-
vised ILP. We showed that both of our approaches
are effective in exploiting discourse relations to
177
Figure 3: Discourse Relations and Classifications for Example 2.
significantly improve polarity classification. We
found that there is a difference in how ICA and
ILP achieve improvements, and that combining
the two in a hybrid approach can lead to further
overall improvement. Quantitatively, we showed
that our approach is able to achieve a large in-
crease in recall of the polar categories without
harming the precision, which results in the perfor-
mance improvements. Qualitatively, we illustrated
how, even if the bootstrapping process is noisy,
the optimization and discourse constraints effec-
tively rectify the misclassifications. The improve-
ments of our diverse global inference approaches
indicate that discourse information can be adapted
in different ways to augment and improve existing
opinion analysis techniques.
The automation of the discourse-relation recog-
nition is the next step in this research. The be-
havior of ICA and ILP can change, depending on
the automation of discourse level recognition. The
implementation and comparison of the two meth-
ods under full automation is the focus of our future
work.
Acknowledgments
This research was supported in part by the
Department of Homeland Security under grant
N000140710152 and NSF Grant No. 0746930.
We would also like to thank the anonymous re-
viewers for their helpful comments.
References
N. Asher, F. Benamara, and Y. Mathieu. 2008. Dis-
tilling opinion in discourse: A preliminary study.
COLING-2008.
M. Bansal, C. Cardie, and L. Lee. 2008. The power of
negative thinking: Exploiting label disagreement in
the min-cut classification framework. In COLING-
2008.
M. Bilgic, G. M. Namata, and L. Getoor. 2007. Com-
bining collective classification and link prediction.
In Workshop on Mining Graphs and Complex Struc-
tures at the IEEE International Conference on Data
Mining.
J. Carletta, S. Ashby, S. Bourban, M. Flynn,
M. Guillemot, T. Hain, J. Kadlec, V. Karaiskos,
W. Kraaij, M. Kronenthal, G. Lathoud, M. Lincoln,
A. Lisowska, I. McCowan, W. Post, D. Reidsma, and
P. Wellner. 2005. The ami meetings corpus. In Pro-
ceedings of the Measuring Behavior Symposium on
?Annotating and measuring Meeting Behavior?.
Y. Choi, E. Breck, and C. Cardie. 2006. Joint extrac-
tion of entities and relations for opinion recognition.
In EMNLP 2006.
P. Denis and J. Baldridge. 2007. Joint determination
of anaphoricity and coreference resolution using in-
teger programming. In HLT-NAACL 2007.
A. Devitt and K. Ahmad. 2007. Sentiment polarity
identification in financial news: A cohesion-based
approach. In ACL 2007.
A. B. Goldberg and X. Zhu. 2006. Seeing stars
when there aren?t many stars: Graph-based semi-
supervised learning for sentiment categorization. In
HLT-NAACL 2006 Workshop on Textgraphs: Graph-
based Algorithms for Natural Language Processing.
A. Haghighi, K. Toutanova, and C. Manning. 2005. A
joint model for semantic role labeling. In CoNLL.
H. Kanayama and T. Nasukawa. 2006. Fully auto-
matic lexicon expansion for domain-oriented sen-
timent analysis. In EMNLP-2006, pages 355?363,
Sydney, Australia.
A. Kennedy and D. Inkpen. 2006. Sentiment classi-
fication of movie reviews using contextual valence
shifters. Computational Intelligence, 22(2):110?
125.
Q. Lu and L. Getoor. 2003. Link-based classification.
In Proceedings of the International Conference on
Machine Learning (ICML).
A. Moschitti, D. Pighin, and R. Basili. 2006. Seman-
tic role labeling via tree kernel joint inference. In
CoNLL.
A. Moschitti. 2009. Syntactic and semantic kernels for
short text pair categorization. In EACL.
178
D. Neiberg, K. Elenius, and K. Laskowski. 2006.
Emotion recognition in spontaneous speech using
gmms. In INTERSPEECH 2006 ICSLP.
J. Neville and D. Jensen. 2000. Iterative classifica-
tion in relational data. In In Proc. AAAI-2000 Work-
shop on Learning Statistical Models from Relational
Data, pages 13?20. AAAI Press.
B. Pang and L. Lee. 2004. A sentimental education:
Sentiment analysis using subjectivity summarization
based on minimum cuts. In ACl 2004.
L. Polanyi and A. Zaenen, 2006. Contextual Valence
Shifters. Computing Attitude and Affect in Text:
Theory and Applications.
A.-M. Popescu and O. Etzioni. 2005. Extracting prod-
uct features and opinions from reviews. In HLT-
EMNLP 2005.
S. Raaijmakers, K. Truong, and T. Wilson. 2008. Mul-
timodal subjectivity analysis of multiparty conversa-
tion. In EMNLP.
M. Richardson and P. Domingos. 2006. Markov logic
networks. Mach. Learn., 62(1-2):107?136.
D. Roth and W. Yih. 2004. A linear programming
formulation for global inference in natural language
tasks. In Proceedings of CoNLL-2004, pages 1?8.
Boston, MA, USA.
K. Sadamitsu, S. Sekine, and M. Yamamoto. 2008.
Sentiment analysis based on probabilistic models us-
ing inter-sentence information. In LREC?08.
S. Somasundaran, J. Ruppenhofer, and J. Wiebe. 2007.
Detecting arguing and sentiment in meetings. In
SIGdial Workshop on Discourse and Dialogue 2007.
S. Somasundaran, J. Wiebe, and J. Ruppenhofer. 2008.
Discourse level opinion interpretation. In Coling
2008.
H. Takamura, T. Inui, and M. Okumura. 2007. Extract-
ing semantic orientations of phrases from dictionary.
In HLT-NAACL 2007.
B. Taskar, M. Wong, P. Abbeel, and D. Koller. 2004.
Link prediction in relational data. In Neural Infor-
mation Processing Systems.
M. Thomas, B. Pang, and L. Lee. 2006. Get out the
vote: Determining support or opposition from con-
gressional floor-debate transcripts. In EMNLP 2006.
T. Wilson, J. Wiebe, and P. Hoffmann. 2005. Recog-
nizing contextual polarity in phrase-level sentiment
analysis. In HLT-EMNLP 2005.
I. H. Witten and E. Frank. 2002. Data mining: practi-
cal machine learning tools and techniques with java
implementations. SIGMOD Rec., 31(1):76?77.
179
Unsupervised Sense Disambiguation Using Bilingual Probabilistic Models
Indrajit Bhattacharya
Dept. of Computer Science
University of Maryland
College Park, MD,
USA
indrajit@cs.umd.edu
Lise Getoor
Dept. of Computer Science
University of Maryland
College Park, MD,
USA
getoor@cs.umd.edu
Yoshua Bengio
Dept. IRO
Universit?e de Montr?eal
Montr?eal, Qu?ebec,
Canada
bengioy@IRO.UMontreal.CA
Abstract
We describe two probabilistic models for unsuper-
vised word-sense disambiguation using parallel cor-
pora. The first model, which we call the Sense
model, builds on the work of Diab and Resnik
(2002) that uses both parallel text and a sense in-
ventory for the target language, and recasts their ap-
proach in a probabilistic framework. The second
model, which we call the Concept model, is a hier-
archical model that uses a concept latent variable to
relate different language specific sense labels. We
show that both models improve performance on the
word sense disambiguation task over previous unsu-
pervised approaches, with the Concept model show-
ing the largest improvement. Furthermore, in learn-
ing the Concept model, as a by-product, we learn a
sense inventory for the parallel language.
1 Introduction
Word sense disambiguation (WSD) has been a cen-
tral question in the computational linguistics com-
munity since its inception. WSD is fundamental to
natural language understanding and is a useful in-
termediate step for many other language process-
ing tasks (Ide and Veronis, 1998). Many recent
approaches make use of ideas from statistical ma-
chine learning; the availability of shared sense defi-
nitions (e.g. WordNet (Fellbaum, 1998)) and recent
international competitions (Kilgarrif and Rosen-
zweig, 2000) have enabled researchers to compare
their results. Supervised approaches which make
use of a small hand-labeled training set (Bruce
and Wiebe, 1994; Yarowsky, 1993) typically out-
perform unsupervised approaches (Agirre et al,
2000; Litkowski, 2000; Lin, 2000; Resnik, 1997;
Yarowsky, 1992; Yarowsky, 1995), but tend to be
tuned to a specific corpus and are constrained by
scarcity of labeled data.
In an effort to overcome the difficulty of find-
ing sense-labeled training data, researchers have be-
gun investigating unsupervised approaches to word-
sense disambiguation. For example, the use of par-
allel corpora for sense tagging can help with word
sense disambiguation (Brown et al, 1991; Dagan,
1991; Dagan and Itai, 1994; Ide, 2000; Resnik and
Yarowsky, 1999). As an illustration of sense disam-
biguation from translation data, when the English
word bank is translated to Spanish as orilla, it is
clear that we are referring to the shore sense of bank,
rather than the nancial institution sense.
The main inspiration for our work is Diab and
Resnik (2002), who use translations and linguistic
knowledge for disambiguation and automatic sense
tagging. Bengio and Kermorvant (2003) present
a graphical model that is an attempt to formalize
probabilistically the main ideas in Diab and Resnik
(2002). They assume the same semantic hierarchy
(in particular, WordNet) for both the languages and
assign English words as well as their translations
to WordNet synsets. Here we present two variants
of the graphical model in Bengio and Kermorvant
(2003), along with a method to discover a cluster
structure for the Spanish senses. We also present
empirical word sense disambiguation results which
demonstrate the gain brought by this probabilistic
approach, even while only using the translated word
to provide disambiguation information.
Our first generative model, the Sense Model,
groups semantically related words from the two
languages into senses, and translations are gener-
ated by probabilistically choosing a sense and then
words from the sense. We show that this improves
on the results of Diab and Resnik (2002).
Our next model, which we call the Concept
Model, aims to improve on the above sense struc-
ture by modeling the senses of the two languages
separately and relating senses from both languages
through a higher-level, semantically less precise
concept. The intuition here is that not all of the
senses that are possible for a word will be relevant
for a concept. In other words, the distribution over
the senses of a word given a concept can be expected
to have a lower entropy than the distribution over
the senses of the word in the language as a whole.
In this paper, we look at translation data as a re-
source for identification of semantic concepts. Note
that actual translated word pairs are not always good
matches semantically, because the translation pro-
cess is not on a word by word basis. This intro-
duces a kind of noise in the translation, and an addi-
tional hidden variable to represent the shared mean-
ing helps to take it into account. Improved perfor-
mance over the Sense Model validates the use of
concepts in modeling translations.
An interesting by-product of the Concept Model
is a semantic structure for the secondary language.
This is automatically constructed using background
knowledge of the structure for the primary language
and the observed translation pairs. In the model,
words sharing the same sense are synonyms while
senses under the same concept are semantically re-
lated in the corpus. An investigation of the model
trained over real data reveals that it can indeed
group related words together.
It may be noted that predicting senses from trans-
lations need not necessarily be an end result in it-
self. As we have already mentioned, lack of labeled
data is a severe hindrance for supervised approaches
to word sense disambiguation. At the same time,
there is an abundance of bilingual documents and
many more can potentially be mined from the web.
It should be possible using our approach to (noisily)
assign sense tags to words in such documents, thus
providing huge resources of labeled data for super-
vised approaches to make use of.
For the rest of this paper, for simplicity we will
refer to the primary language of the parallel docu-
ment as English and to the secondary as Spanish.
The paper is organized as follows. We begin by for-
mally describing the models in Section 2. We de-
scribe our approach for constructing the senses and
concepts in Section 3. Our algorithm for learning
the model parameters is described in Section 4. We
present experimental results in Section 5 and our
analysis in Section 6. We conclude in Section 7.
2 Probabilistic Models for Parallel
Corpora
We motivate the use of a probabilistic model by il-
lustrating that disambiguation using translations is
possible even when a word has a unique transla-
tion. For example, according to WordNet, the word
prevention has two senses in English, which may
be abbreviated as hindrance (the act of hindering
or obstruction) and control (by prevention, e.g. the
control of a disease). It has a single translation in
our corpus, that being prevenci ?on. The first En-
glish sense, hindrance, also has other words like
bar that occur in the corpus and all of these other
words are observed to be translated in Spanish as
the word obstrucci?on. In addition, none of these
other words translate to prevenci ?on. So it is not
unreasonable to suppose that the intended sense for
prevention when translated as prevenci ?on is differ-
ent from that of bar. Therefore, the intended sense
is most likely to be control. At the very heart of
the reasoning is probabilistic analysis and indepen-
dence assumptions. We are assuming that senses
and words have certain occurrence probabilities and
that the choice of the word can be made indepen-
dently once the sense has been decided. This is the
flavor that we look to add to modeling parallel doc-
uments for sense disambiguation. We formally de-
scribe the two generative models that use these ideas
in Subsections 2.2 and 2.3.
T
We Ws
Te Ts
C
WsWeword
concept
sense
b) Concept Modela) Sense Model
Figure 1: Graphical Representations of the a) Sense
Model and the b) Concept Model
2.1 Notation
Throughout, we use uppercase letters to denote ran-
dom variables and lowercase letters to denote spe-
cific instances of the random variables. A transla-
tion pair is (   ,   ) where the subscript  and 
indicate the primary language (English) and the sec-
ondary language (Spanish).   	


and   
  
 Proceedings of the 2009 Workshop on Graph-based Methods for Natural Language Processing, ACL-IJCNLP 2009, pages 66?74,
Suntec, Singapore, 7 August 2009.
c
?2009 ACL and AFNLP
Opinion Graphs for Polarity and Discourse Classification
?
Swapna Somasundaran
Univ. of Pittsburgh
Pittsburgh, PA 15260
swapna@cs.pitt.edu
Galileo Namata
Univ. of Maryland
College Park, MD 20742
namatag@cs.umd.edu
Lise Getoor
Univ. of Maryland
College Park, MD 20742
getoor@cs.umd.edu
Janyce Wiebe
Univ. of Pittsburgh
Pittsburgh, PA 15260
wiebe@cs.pitt.edu
Abstract
This work shows how to construct
discourse-level opinion graphs to perform
a joint interpretation of opinions and dis-
course relations. Specifically, our opinion
graphs enable us to factor in discourse in-
formation for polarity classification, and
polarity information for discourse-link
classification. This inter-dependent frame-
work can be used to augment and im-
prove the performance of local polarity
and discourse-link classifiers.
1 Introduction
Much research in opinion analysis has focused on
information from words, phrases and semantic ori-
entation lexicons to perform sentiment classifica-
tion. While these are vital for opinion analysis,
they do not capture discourse-level associations
that arise from relations between opinions. To cap-
ture this information, we propose discourse-level
opinion graphs for classifying opinion polarity.
In order to build our computational model, we
combine a linguistic scheme opinion frames (So-
masundaran et al, 2008) with a collective classifi-
cation framework (Bilgic et al, 2007). According
to this scheme, two opinions are related in the dis-
course when their targets (what they are about) are
related. Further, these pair-wise discourse-level
relations between opinions are either reinforcing
or non-reinforcing frames. Reinforcing frames
capture reinforcing discourse scenarios where the
individual opinions reinforce one another, con-
tributing to the same opinion polarity or stance.
Non-reinforcing frames, on the other hand, cap-
ture discourse scenarios where the individual opin-
ions do not support the same stance. The indi-
vidual opinion polarities and the type of relation
?
This research was supported in part by the Department
of Homeland Security under grant N000140710152.
between their targets determine whether the dis-
course frame is reinforcing or non-reinforcing.
Our polarity classifier begins with information
from opinion lexicons to perform polarity classifi-
cation locally at each node. It then uses discourse-
level links, provided by the opinion frames, to
transmit the polarity information between nodes.
Thus the opinion classification of a node is not
just dependent on its local features, but also on the
class labels of related opinions and the nature of
these links. We design two discourse-level link
classifiers: the target-link classifier, which deter-
mines if a given node pair has unrelated targets (no
link), or if their targets have a same or alternative
relation, and the frame-link classifier, which deter-
mines if a given node pair has no link, reinforcing
or non-reinforcing link relation. Both these classi-
fiers too first start with local classifiers that use lo-
cal information. The opinion graph then provides
a means to factor in the related opinion informa-
tion into the link classifiers. Our approach enables
using the information in the nodes (and links) to
establish or remove links in the graph. Thus in-
formation flows to and fro between all the opinion
nodes and discourse-level links to achieve a joint
inference.
The paper is organized as follows: We first de-
scribe opinion graphs, a structure that can capture
discourse-level opinion relationships in Section 2,
and then describe our joint interpretation approach
to opinion analysis in Section 3. Next, we describe
our algorithm for joint interpretation in Section 4.
Our experimental results are reported in Section 5.
We discuss related work in Section 6 and conclude
in Section 7.
2 Discourse-Level Opinion Graphs
The pairwise relationships that compose opinion
frames can be used to construct a graph over opin-
ion expressions in a discourse, which we refer
to as the discourse-level opinion graph (DLOG).
66
Figure 1 Opinion Frame Annotations.
In this section, we describe these graphs and il-
lustrate their applicability to goal-oriented multi-
party conversations.
The nodes in the DLOG represent opinions, and
there are two kinds of links: target links and frame
links. Each opinion node has a polarity (positive,
negative or neutral) and type (sentiment or argu-
ing). Sentiment opinions are evaluations, feelings
or judgments about the target. Arguing opinions
argue for or against something. Target links are
labeled as either same or alternatives. Same links
hold between targets that refer to the same en-
tity or proposition, while alternative links hold be-
tween targets that are related by virtue of being op-
posing (mutually exclusive) options in the context
of the discourse. The frame links correspond to
the opinion frame relation between opinions.
We illustrate the construction of the opinion
graph with an example (Example 1, from Soma-
sundaran et al (2008)) from a multi-party meet-
ing corpus where participants discuss and design a
new TV remote control. The opinion expressions
are in bold and their targets are in italics. Notice
here that speaker D has a positive sentiment to-
wards the rubbery material for the TV remote.
(1) D:: ... this kind of rubbery material, it?s a bit more
bouncy, like you said they get chucked around a lot.
A bit more durable and that can also be ergonomic
and it kind of feels a bit different from all the other
remote controls.
All the individual opinions in this example are
essentially regarding the same thing ? the rub-
bery material. The speaker?s positive sentiment is
apparent from the text spans bit more bouncy,
bit more durable, ergonomic and a bit different
from all the other remote controls. The explicit
targets of these opinions (it?s, that, and it) and the
implicit target of ?a bit more durable? are thus all
linked with same relations.
Figure 1 illustrates the individual opinion anno-
tations, target annotations (shown in italics) and
the relations between the targets (shown in dotted
lines). Note that the target of a bit more durable
is a zero span ellipsis that refers back to the rub-
bery material. The opinion frames resulting from
the individual annotations make pairwise connec-
tions between opinion instances, as shown in bold
lines in the figure. For example, the two opinions
bit more bouncy and ergonomic, and the same
link between their targets (it?s and that), make up
an opinion frame. An opinion frame type is de-
rived from the details (type and polarity) of the
opinions it relates and the target relation involved.
Even though the different combinations of opin-
ion type (sentiment and arguing), polarity (posi-
tive and negative) and target links (same and al-
ternative) result in many distinct frames types (32
in total), they can be grouped, according to their
discourse-level characteristics, into the two cat-
egories reinforcing and non-reinforcing. In this
work, we only make this category distinction for
opinion frames and the corresponding frame links.
The next example (Example 2, also from So-
masundaran et al (2008)) illustrates an alterna-
tive target relation. In the domain of TV remote
controls, the set of all shapes are alternatives to
one another, since a remote control may have only
one shape at a time. In such scenarios, a positive
opinion regarding one choice may imply a nega-
tive opinion toward competing choices, and vice
versa. In this passage, speaker C?s positive stance
towards the curved shape is brought out even more
strongly with his negative opinions toward the al-
ternative, square-like, shapes.
(2) C:: . . . shapes should be curved, so round shapes.
Nothing square-like.
.
.
.
C:: . . . So we shouldn?t have too square corners
and that kind of thing.
The reinforcing frames characteristically show
a reinforcement of an opinion or stance in the dis-
course. Both the examples presented above depict
a reinforcing scenario. In the first example, the
opinion towards the rubbery material is reinforced
by repeated positive sentiments towards it, while
in the second example the positive stance towards
the curved shapes is further reinforced by nega-
tive opinions toward the alternative option. Ex-
amples of non-reinforcing scenarios are ambiva-
lence between alternative options (for e.g., ?I like
the rubbery material but the plastic will be much
67
cheaper?) or mixed opinions about the same tar-
get (for e.g., weighing pros and cons ?The rubbery
material is good but it will be just so expensive?).
3 Interdependent Interpretation
Our interdependent interpretation in DLOGs is
motivated by the observation that, when two opin-
ions are related, a clear knowledge of the polarity
of one of them makes interpreting the other much
easier. For instance, suppose an opinion classi-
fier wants to find the polarity of all the opinion
expressions in Example 1. As a first step, it can
look up opinion lexicons to infer that words like
?bouncy?, ?durable? and ? ergonomic? are pos-
itive. However, ?a bit different ? cannot be re-
solved via this method, as its polarity can be dif-
ferent in different scenarios.
Suppose now we relate the targets of opinions.
There are clues in the passage that the targets are
related via the same relation; for instance they
are all third person pronouns occurring in adja-
cent clauses and sentences. Once we relate the
targets, the opinions of the passage are related via
target links in the discourse opinion graph. We
are also able to establish frames using the opinion
information and target link information wherever
they are available, i.e., a reinforcing link between
bit more bouncy and ergonomic. For the places
where all the information is not available (between
ergonomic and a bit different) there are multiple
possibilities. Depending on the polarity, either a
reinforcing frame (if a bit different has positive
polarity) or a non-reinforcing frame (if a bit dif-
ferent has negative polarity) can exist. There are
clues in the discourse that this passage represents
a reinforcing scenario. For instance there are rein-
forcing frames between the first few opinions, the
repeated use of ?and? indicates a list, conjunction
or expansion relation between clauses (according
to the Penn Discourse TreeBank (PDTB) (Prasad
et al, 2008)), and there is a lack of contrastive
clues that would indicate a change in the opin-
ion. Thus the reinforcing frame link emerges as
being the most likely candidate. This in turn dis-
ambiguates the polarity of a bit different. Thus,
by establishing target links and frame links be-
tween the opinion instances, we are able to per-
form a joint interpretation of the opinions.
The interdependent framework of this example
is iterative and dynamic ? the information in the
nodes can be used to change the structure (i.e.,
establish new links), and the structure provides a
framework to change node polarity. We build our
classification framework and feature sets with re-
spect to this general framework, where the node
labels as well as the structure of the graph are pre-
dicted in a joint manner.
Thus our interdependent interpretation frame-
work has three main units: an instance polarity
classifier (IPC), a target-link classifier (TLC), and
a frame-link classifier (FLC). IPC classifies each
node (instance), which may be a sentence, utter-
ance or an other text span, as positive, negative
or neutral. The TLC determines if a given node
pair has related targets and whether they are linked
by a same or alternative relation. The FLC deter-
mines if a given node pair is related via frames,
and whether it is a reinforcing or non-reinforcing
link. As we saw in the example, there are local
clues available for each unit to arrive at its classi-
fication. The discourse augments this information
to aid in further disambiguation.
4 Collective Classification Framework
For our collective classification framework, we
use a variant of the iterative classification al-
gorithm (ICA) proposed by Bilgic et al(2007).
It combines several common prediction tasks in
graphs: object classification (predicting the label
of an object) and link prediction (predicting the
existence and class of a link between objects).
For our tasks, object classification directly corre-
sponds to predicting opinion polarity and the link
prediction corresponds to predicting the existence
of a same or alternative target link or a reinforc-
ing or non-reinforcing frame link between opin-
ions. We note that given the nature of our problem
formulation and approach, we use the terms link
prediction and link classification interchangeably.
In the collective classification framework, there
are two sets of features to use. The first are local
features which can be generated for each object or
link, independent of the links in which they par-
ticipate, or the objects they connect. For example,
the opinion instance may contain words that oc-
cur in sentiment lexicons. The local features are
described in Section 4.2. The second set of fea-
tures, the relational features, reflect neighborhood
information in the graph. For frame link classifi-
cation, for example, there is a feature indicating
whether the connected nodes are predicted to have
the same polarity. The relational features are de-
68
scribed in Section 4.3.
4.1 DLOG-ICA Algorithm
Our variant of the ICA algorithm begins by pre-
dicting the opinion polarity, and link type using
only the local features. We then randomly order
the set of all opinions and links and, in turn, pre-
dict the polarity or class using the local features
and the values of the currently predicted relational
features based on previous predictions. We repeat
this until some stopping criterion is met. For our
experiments, we use a fixed number of 30 itera-
tions which was sufficient, in most of our datasets,
for ICA to converge to a solution. The pseudocode
for the algorithm is shown in Algorithm 4.1.
Algorithm 1 DLOG-ICA Algorithm
for each opinion o do {bootstrapping}
Compute polarity for o using local attributes
end for
for each target link t do {bootstrapping}
Compute label for t using local attributes
end for
for each frame link f do {bootstrapping}
Compute label for f using local attributes
end for
repeat {iterative classification}
Generate ordering I over all nodes and links
for each i in I do
if i is an opinion instance then
Compute polarity for i using local and
relational attributes
else if i is a target link then
Compute class for i using local and re-
lational attributes
else if i is a frame link then
Compute class for i using local and re-
lational attributes
end if
end for
until Stopping criterion is met
The algorithm is one very simple way of making
classifications that are interdependent. Once the
local and relational features are defined, a variety
of classifiers can be used. For our experiments, we
use SVMs. Additional details are provided in the
experiments section.
4.2 Local Features
For the local polarity classifier, we employ opin-
ion lexicons, dialog information, and unigram fea-
Feature Task
Time difference between the node pair TLC, FLC
Number of intervening instances TLC, FLC
Content word overlap between the node pair TLC,FLC
Focus space overlap between the node pair TLC, FLC
Bigram overlap between the node pair * TLC, FLC
Are both nodes from same speaker * TLC, FLC
Bag of words for each node TLC, FLC
Anaphoric indicator in the second node TLC
Adjacency pair between the node pair FLC
Discourse relation between node pair * FLC
Table 1: Features and the classification task it is used for;
TLC = target-link classification, FLC = Frame-link classifi-
cation
tures. We use lexicons that have been success-
fully used in previous work (the polarity lexicon
from (Wilson et al, 2005) and the arguing lexi-
con (Somasundaran et al, 2007)). Previous work
used features based on parse trees, e.g., (Wilson et
al., 2005; Kanayama and Nasukawa, 2006), but
our data has very different characteristics from
monologic texts ? the utterances and sentences are
much shorter, and there are frequent disfluencies,
restarts, hedging and repetitions. Because of this,
we cannot rely on parsing features. On the other
hand, in this data, we have dialog act information
1
(Dialog Acts), which we can exploit. Note that the
IPC uses only the Dialog Act tags (instance level
tags like Inform, Suggest) and not the dialog struc-
ture information.
Opinion frame detection between sentences has
been previously attempted (Somasundaran et al,
2008) by using features that capture discourse
and dialog continuity. Even though our link
classification tasks are not directly comparable
(the previous work performs binary classifica-
tion of frame-present/frame-absent between opin-
ion bearing sentences, while this work performs
three-way classification: no-link/reinforcing/non-
reinforcing between DA pairs), we adapt the fea-
tures for the link classification tasks addressed
here. These features depend on properties of the
nodes that the link connects. We also create some
new features that capture discourse relations and
lexical overlap.
Table 1 lists the link classification features.
New features are indicated with a ?*?. Continu-
ous discourse indicators, like time difference be-
tween the node pair and number of intervening
instances are useful for determining if the two
nodes can be related. The content word over-
1
Manual annotations for Dialog act tags and adjacency
pairs are available for the AMI corpus.
69
lap, and focus space overlap features (the focus
space for an instance is a list of the most recently
used NP chunks; i.e., NP chunks in that instance
and a few previous instances) capture the overlap
in topicality within the node pair; while the bi-
gram overlap feature captures the alignment be-
tween instances in terms of function words as well
as content words. The entity-level relations are
captured by the anaphoric indicator feature that
checks for the presence of pronouns such as it and
that in the second node in the node pair. The adja-
cency pair and discourse relation are actually fea-
ture sets that indicate specific dialog-structure and
discourse-level relations. We group the list of dis-
course relations from the PDTB into the following
sets: expansion, contingency, alternative, tempo-
ral, comparison. Each discourse relation in PDTB
is associated with a list of discourse connective
words.
2
Given a node pair, if the first word of the
later instance (or the last word first instance) is a
discourse connective word, then we assume that
this node is connecting back (or forward) in the
discourse and the feature set to which the connec-
tive belongs is set to true (e.g., if a latter instance
is ?because we should ...?, it starts with the con-
nective ?because?, and connects backwards via a
contingency relation). The adjacency pair feature
indicates the presence of a particular dialog struc-
ture (e.g., support, positive-assessment) between
the nodes.
4.3 Relational Features
In addition to the local features, we introduce re-
lational features (Table 2) that incorporate related
class information as well as transfer label informa-
tion between classifiers. As we saw in our example
in Figure 1, we need to know not only the polar-
ity of the related opinions, but also the type of the
relation between them. For example, if the frame
relation between ergonomic and a bit different is
non-reinforcing, then the polarity of a bit differ-
ent is likely to be negative. Thus link labels play
an important role in disambiguating the polarity.
Accordingly, our relational features transfer infor-
mation of class labels from other instances of the
same classifier as well as between different clas-
sifiers. Table 2 lists our relational features. Each
row represents a set of features. Features are gen-
erated for all combinations of x, y and z for each
2
The PDTB provides a list of discourse connectives and
the list of discourse relations each connective signifies.
row. For example, one of the features in the first
row is Number of neighbors with polarity type pos-
itive, that are related via a reinforcing frame link.
Thus each feature for the polarity classifier iden-
tifies neighbors for a given node via a specific re-
lation (z or y) and factors in their polarity values.
Similarly, both link classifiers use polarity infor-
mation of the node pair, and other link relations
involving the nodes of the pair.
5 Evaluation
We experimentally test our hypothesis that
discourse-level information is useful and non-
redundant with local information. We also wanted
to test how the DLOG performs for varying
amounts of available annotations: from full neigh-
borhood information to absolutely no neighbor-
hood information.
Accordingly, for polarity classification, we im-
plemented three scenarios: ICA-LinkNeigh, ICA-
LinkOnly and ICA-noInfo. The ICA-LinkNeigh
scenario measures the performance of the DLOG
under ideal conditions (full neighborhood infor-
mation) ? the structure of the graph (link infor-
mation) as well as the neighbors? class are pro-
vided (by an oracle). Here we do not need the
TLC, or the FLC to predict links and the Instance
Polarity Classifier (IPC) is not dependent on its
predictions from the previous iteration. On the
other hand, the ICA-noInfo scenario is the other
extreme, and has absolutely no neighborhood in-
formation. Each node does not know which nodes
in the network it is connected to apriori, and also
has no information about the polarity of any other
node in the network. Here, the structure of the
graph, as well as the node classes, have to be in-
ferred via the collective classification framework
described in Sections 3 and 4. The ICA-LinkOnly
is an intermediate condition, and is representative
of scenarios where the discourse relationships be-
tween nodes is known. Here we start with the link
information (from an oracle) and the IPC uses the
collective classification framework to infer neigh-
bor polarity information.
Similarly, we vary the amounts of neighbor-
hood information for the TLC and FLC classifiers.
In the ICA-LinkNeigh condition, TLC and FLC
have full neighborhood information. In the ICA-
noInfo condition, TLC and FLC are fully depen-
dent on the classifications of the previous rounds.
In the ICA-Partial condition, the TLC classifier
70
Feature
Opinion Polarity Classification
Number of neighbors with polarity type x linked via frame link z
Number of neighbors with polarity type x linked via target link y
Number of neighbors with polarity type x and same speaker linked via frame link z
Number of neighbors with polarity type x and same speaker linked via target link y
Target Link Classification
Polarity of the DA nodes
Number of other target links y involving the given DA nodes
Number of other target links y involving the given DA nodes and other same-speaker nodes
Presence of a frame link z between the nodes
Frame Link Classification
Polarity of the DA nodes
Number of other frame links z involving the given DA nodes
Number of other frame links z involving the given DA nodes and other same-speaker nodes
Presence of a target link y between the nodes
Table 2: Relational features: x ? {non-neutral (i.e., positive or negative), positive, negative}, y ? {same, alt}, z ?
{reinforcing, non-reinforcing}
uses true frame-links and polarity information,
and previous-stage classifications for information
about neighborhood target links; the FLC classi-
fier uses true target-links and polarity information,
and previous-stage classifications for information
about neighborhood frame-links.
5.1 Data
For our experiments, we use the opinion frame
annotations from previous work (Somasundaran
et al, 2008). These annotations consist of the
opinion spans that reveal opinions, their targets,
the polarity information for opinions, the labeled
links between the targets and the frame links be-
tween the opinions. The annotated data consists
of 7 scenario-based, multi-party meetings from the
AMI meeting corpus (Carletta et al, 2005). The
manual Dialog Act (DA) annotations, provided by
AMI, segment the meeting transcription into sep-
arate dialog acts. We use these DAs as nodes or
instances in our opinion graph.
A DA is assigned the opinion orientation of the
words it contains (for example, if a DA contains a
positive opinion expression, then the DA assigned
the positive opinion category). We filter out very
small DAs (DAs with fewer than 3 tokens, punctu-
ation included) in order to alleviate data skewness
problem in the link classifiers. This gives us a to-
tal of 4606 DA instances, of which 1935 (42%)
have opinions. Out of these 1935, 61.7% are posi-
tive, 30% are negative and the rest are neutral. The
DAs that do not have opinions are considered neu-
tral, and have no links in the DLOG. We create
DA pairs by first ordering the DAs by their start
time, and then pairing a DA with five DAs before
it, and five DAs after it. The classes for target-
link classification are no-link, same, alt. The gold
standard target-link class is decided for a DA pair
based on the target link between the targets of the
opinions contained in that pair. Similarly, the la-
bels for the frame-link labeling task are no-link,
reinforcing, non-reinforcing. The gold standard
frame link class is decided for a DA pair based on
the frame between opinions contained by that pair.
In our data, of the 4606 DAs, 1118 (24.27%) par-
ticipate in target links with other DAs, and 1056
(22.9%) form frame links. The gold standard data
for links, which has pair-wise information, has a
total of 22,925 DA pairs, of which 1371 (6%) pairs
have target links and 1264 (5.5%) pairs have frame
links.
We perform 7-fold cross-validation experi-
ments, using the 7 meetings. In each fold, 6 meet-
ings are used for training and one meeting is used
for testing.
5.2 Classifiers
Our baseline (Base) classifies the test data based
on the distribution of the classes in the training
data. Note that due to the heavily skewed nature of
our link data, this classifier performs very poorly
for minority class prediction, even though it may
achieve good overall accuracy.
For our local classifiers, we used the classifiers
from the Weka toolkit (Witten and Frank, 2002).
For opinion polarity, we used the Weka?s SVM
implementation. For the target link and frame link
classes, the huge class skew caused SVM to learn a
trivial model and always predict the majority class.
To address this, we used a cost sensitive classifier
in Weka where we set the cost of misclassifying a
less frequent class, A, to a more frequent class, B,
71
Base Local ICA
LinkNeigh LinkOnly noInfo
Acc 45.9 68.7 78.8 72.9 68.4
Class: neutral (majority class)
Prec 61.2 76.3 83.9 78.2 73.5
Rec 61.5 83.9 89.6 89.1 86.6
F1 61.1 79.6 86.6 83.2 79.3
Class: positive polarity
Prec 26.3 56.2 70.9 63.3 57.6
Rec 26.1 46.6 62.0 47.0 42.8
F1 25.8 50.4 65.9 53.5 48.5
Class: negative polarity
Prec 12.4 52.3 64.6 56.3 55.2
Rec 12.2 44.3 60.2 48.2 38.2
F1 12.2 46.0 61.9 51.2 43.9
Table 3: Performance of Polarity Classifiers
as |B|/|A| where |class| is the size of the class in
the training set. All other misclassification costs
are set to 1.
For our collective classification, we use the
above classifiers for local features (l) and use sim-
ilar, separate classifiers for relational features (r).
For example, we learned an SVM for predicting
opinion polarity using only the local features and
learned another SVM using only relational fea-
tures. For the ICA-noInfo condition, where we
use TLC and FLC classifiers, we combine the
predictions using a weighted combination where
P (class|l, r) = ? ? P (class|l) + (1 ? ?) ?
P (class|r). This allows us to vary the influence
each feature set has to the overall prediction. The
results for ICA-noInfo are reported on the best per-
forming ? (0.7).
5.3 Results
Our polarity classification results are presented
in Table 3, specifically accuracy (Acc), precision
(Prec), recall (Rec) and F-measure (F1). As we
can see, the results are mixed. First, we no-
tice that the Local classifier shows substantial im-
provement over the baseline classifier. This shows
that the lexical and dialog features we use are in-
formative of opinion polarity in multi-party meet-
ings.
Next, notice that the ICA-LinkNeigh classifier
performs substantially better than the Local clas-
sifier for all metrics and all classes. The accuracy
improves by 10 percentage points, while the F-
measure improves by about 15 percentage points
for the minority (positive and negative) classes.
This result confirms that our discourse-level opin-
ion graphs are useful and discourse-level informa-
tion is non-redundant with lexical and dialog-act
Base Local ICA
LinkNeigh Partial noInfo
TLC
Acc 88.5 85.8 98.1 98.2 86.3
P-M 33.3 35.9 76.1 76.1 36.3
R-M 33.3 38.1 78.1 78.1 38.1
F1-M 33.1 36.0 74.6 74.6 36.5
FLC
Acc 89.3 86.2 98.9 98.9 87.6
P-M 33.3 36.9 81.3 82.8 38.0
R-M 33.4 41.2 82.2 84.4 41.7
F1-M 33.1 37.2 80.7 82.3 38.1
Table 4: Performance of Link Classifiers
information.
The results for ICA-LinkOnly follow the same
trend as for ICA-LinkNeigh, with a 3 to 5 percent-
age point improvement. These results show that
even when the neighbors? classes are not known
a priori, joint inference using discourse-level rela-
tions helps reduce errors from local classification.
However, the performance of the ICA-noInfo
system, which is given absolutely no starting in-
formation, is comparable to the Local classifier for
the overall accuracy and F-measure metrics for the
neutral class. There is slight improvement in pre-
cision for both the positive and negative classes,
but there is a drop in their recall. The reason this
classifier does no better than the Local classifier is
because the link classifiers TLC and FLC predict
?none? predominantly due to the heavy class skew.
The performance of the link classifiers are re-
ported in Table 4, specifically the accuracy (Acc)
and macro averages over all classes for preci-
sion (P-M), recall (R-M) and F-measure (F1-M).
Due to the heavy skew in the data, accuracy
of all classifiers is high; however, the macro F-
measure, which depends on the F1 of the minor-
ity classes, is poor for the ICA-noInfo. Note,
however, that when we provide some (Partial) or
full (LinkNeigh) neighborhood information for the
Link classifiers, the performance of these classi-
fiers improve considerably. This overall observed
trend is similar to that observed with the polarity
classifiers.
6 Related Work
Previous work on polarity disambiguation has
used contextual clues and reversal words (Wil-
son et al, 2005; Kennedy and Inkpen, 2006;
Kanayama and Nasukawa, 2006; Devitt and Ah-
mad, 2007; Sadamitsu et al, 2008). However,
these do not capture discourse-level relations.
72
Polanyi and Zaenen (2006) observe that a cen-
tral topic may be divided into subtopics in or-
der to perform evaluations. Similar to Somasun-
daran et al (2008), Asher et al (2008) advo-
cate a discourse-level analysis in order to get a
deeper understanding of contextual polarity and
the strength of opinions. However, these works do
not provide an implementation for their insights.
In this work we demonstrate a concrete way that
discourse-level interpretation can improve recog-
nition of individual opinions and their polarities.
Graph-based approaches for joint inference in
sentiment analysis have been explored previously
by many researchers. The biggest difference be-
tween this work and theirs is in what the links
represent linguistically. Some of these are not
related to discourse at all (e.g., lexical similari-
ties (Takamura et al, 2007), morphosyntactic sim-
ilarities (Popescu and Etzioni, 2005) and word
based measures like TF-IDF (Goldberg and Zhu,
2006)). Some of these work on sentence cohesion
(Pang and Lee, 2004) or agreement/disagreement
between speakers (Thomas et al, 2006; Bansal
et al, 2008). Our model is not based on sen-
tence cohesion or structural adjacency. The re-
lations due to the opinion frames are based on
relationships between targets and discourse-level
functions of opinions being mutually reinforcing
or non-reinforcing. Adjacent instances need not be
related via opinion frames, while long distant rela-
tions can be present if opinion targets are same or
alternatives. Also, previous efforts in graph-based
joint inference in opinion analysis has been text-
based, while our work is over multi-party conver-
sations.
McDonald et al (2007) propose a joint model
for sentiment classification based on relations de-
fined by granularity (sentence and document).
Snyder and Barzilay (2007) combine an agree-
ment model based on contrastive RST relations
with a local aspect (topic) model. Their aspects
would be related as same and their high contrast
relations would correspond to (a subset of) the
non-reinforcing frames.
In the field of product review mining, senti-
ments and features (aspects or targets) have been
mined (for example, Yi et al (2003), Popescu and
Etzioni (2005), and Hu and Liu (2006)). More re-
cently there has been work on creating joint mod-
els of topic and sentiments (Mei et al, 2007; Titov
and McDonald, 2008) to improve topic-sentiment
summaries. We do not model topics; instead we
directly model the relations between targets. The
focus of our work is to jointly model opinion po-
larities via target relations. The task of finding co-
referent opinion topics by (Stoyanov and Cardie,
2008) is similar to our target link classification
task, and we use somewhat similar features. Even
though their genre is different, we plan to experi-
ment with their full feature set for improving our
TLC system.
Turning to collective classification, there have
been various collective classification frameworks
proposed (for example, Neville and Jensen (2000),
Lu and Getoor (2003), Taskar et al (2004),
Richardson and Domingos (2006)). In this pa-
per, we use an approach proposed by (Bilgic et
al., 2007) which iteratively predicts class and link
existence using local classifiers. Other joint mod-
els used in sentiment classification include the spin
model (Takamura et al, 2007), relaxation labeling
(Popescu and Etzioni, 2005), and label propaga-
tion (Goldberg and Zhu, 2006).
7 Conclusion
This work uses an opinion graph framework,
DLOG, to create an interdependent classifica-
tion of polarity and discourse relations. We em-
ployed this graph to augment lexicon-based meth-
ods to improve polarity classification. We found
that polarity classification in multi-party conver-
sations benefits from opinion lexicons, unigram
and dialog-act information. We found that the
DLOGs are valuable for further improving polar-
ity classification, even with partial neighborhood
information. Our experiments showed three to
five percentage points improvement in F-measure
with link information, and 15 percentage point
improvement with full neighborhood information.
These results show that lexical and discourse in-
formation are non-redundant for polarity classi-
fication, and our DLOG, that employs both, im-
proves performance.
We discovered that link classification is a dif-
ficult problem. Here again, we found that by us-
ing the DLOG framework, and using even partial
neighborhood information, improvements can be
achieved.
References
N. Asher, F. Benamara, and Y. Mathieu. 2008. Dis-
tilling opinion in discourse: A preliminary study.
73
COLING-2008.
M. Bansal, C. Cardie, and L. Lee. 2008. The power of
negative thinking: Exploiting label disagreement in
the min-cut classification framework. In COLING-
2008.
M. Bilgic, G. M. Namata, and L. Getoor. 2007. Com-
bining collective classification and link prediction.
In Workshop on Mining Graphs and Complex Struc-
tures at the IEEE International Conference on Data
Mining.
J. Carletta, S. Ashby, S. Bourban, M. Flynn,
M. Guillemot, T. Hain, J. Kadlec, V. Karaiskos,
W. Kraaij, M. Kronenthal, G. Lathoud, M. Lincoln,
A. Lisowska, I. McCowan, W. Post, D. Reidsma, and
P. Wellner. 2005. The AMI Meetings Corpus. In
Proceedings of the Measuring Behavior Symposium
on ?Annotating and measuring Meeting Behavior?.
A. Devitt and K. Ahmad. 2007. Sentiment polarity
identification in financial news: A cohesion-based
approach. In ACL 2007.
A. B. Goldberg and X. Zhu. 2006. Seeing stars
when there aren?t many stars: Graph-based semi-
supervised learning for sentiment categorization. In
HLT-NAACL 2006 Workshop on Textgraphs: Graph-
based Algorithms for Natural Language Processing.
M. Hu and B. Liu. 2006. Opinion extraction and sum-
marization on the Web. In 21st National Conference
on Artificial Intelligence (AAAI-2006).
H. Kanayama and T. Nasukawa. 2006. Fully auto-
matic lexicon expansion for domain-oriented sen-
timent analysis. In EMNLP-2006, pages 355?363,
Sydney, Australia.
A. Kennedy and D. Inkpen. 2006. Sentiment classi-
fication of movie reviews using contextual valence
shifters. Computational Intelligence, 22(2):110?
125.
Q. Lu and L. Getoor. 2003. Link-based classification.
In Proceedings of the International Conference on
Machine Learning (ICML).
R. McDonald, K. Hannan, T. Neylon, M. Wells, and
J. Reynar. 2007. Structured models for fine-to-
coarse sentiment analysis. In ACL 2007.
Q. Mei, X. Ling, M. Wondra, H. Su, and C Zhai. 2007.
Topic sentiment mixture: modeling facets and opin-
ions in weblogs. In WWW ?07. ACM.
J. Neville and D. Jensen. 2000. Iterative classifica-
tion in relational data. In In Proc. AAAI-2000 Work-
shop on Learning Statistical Models from Relational
Data, pages 13?20. AAAI Press.
B. Pang and L. Lee. 2004. A sentimental education:
Sentiment analysis using subjectivity summarization
based on minimum cuts. In ACl 2004.
L. Polanyi and A. Zaenen, 2006. Contextual Valence
Shifters. Computing Attitude and Affect in Text:
Theory and Applications.
A.-M. Popescu and O. Etzioni. 2005. Extracting prod-
uct features and opinions from reviews. In HLT-
EMNLP 2005.
R. Prasad, A. Lee, N. Dinesh, E. Miltsakaki, G. Cam-
pion, A. Joshi, and B. Webber. 2008. Penn dis-
course treebank version 2.0. Linguistic Data Con-
sortium.
M. Richardson and P. Domingos. 2006. Markov logic
networks. Mach. Learn., 62(1-2):107?136.
K. Sadamitsu, S. Sekine, and M. Yamamoto. 2008.
Sentiment analysis based on probabilistic models us-
ing inter-sentence information. In LREC?08.
B. Snyder and R. Barzilay. 2007. Multiple aspect rank-
ing using the good grief algorithm. In HLT 2007:
NAACL.
S. Somasundaran, J. Ruppenhofer, and J. Wiebe. 2007.
Detecting arguing and sentiment in meetings. In
SIGdial Workshop on Discourse and Dialogue 2007.
S. Somasundaran, J. Wiebe, and J. Ruppenhofer. 2008.
Discourse level opinion interpretation. In Coling
2008.
V. Stoyanov and C. Cardie. 2008. Topic identification
for fine-grained opinion analysis. In Coling 2008.
H. Takamura, T. Inui, and M. Okumura. 2007. Extract-
ing semantic orientations of phrases from dictionary.
In HLT-NAACL 2007.
B. Taskar, M. Wong, P. Abbeel, and D. Koller. 2004.
Link prediction in relational data. In Neural Infor-
mation Processing Systems.
M. Thomas, B. Pang, and L. Lee. 2006. Get out the
vote: Determining support or opposition from con-
gressional floor-debate transcripts. In EMNLP 2006.
I. Titov and R. McDonald. 2008. A joint model of text
and aspect ratings for sentiment summarization. In
ACL 2008.
T. Wilson, J. Wiebe, and P. Hoffmann. 2005. Recog-
nizing contextual polarity in phrase-level sentiment
analysis. In HLT-EMNLP 2005.
I. H. Witten and E. Frank. 2002. Data mining: practi-
cal machine learning tools and techniques with java
implementations. SIGMOD Rec., 31(1):76?77.
J. Yi, T. Nasukawa, R. Bunescu, and W. Niblack. 2003.
Sentiment analyzer: Extracting sentiments about a
given topic using natural language processing tech-
niques. In ICDM-2003.
74
Proceedings of the Ninth Workshop on Innovative Use of NLP for Building Educational Applications , pages 28?33,
Baltimore, Maryland USA, June 26, 2014.
c
?2014 Association for Computational Linguistics
Understanding MOOC Discussion Forums using Seeded LDA
1
Arti Ramesh,
1
Dan Goldwasser,
1
Bert Huang,
1
Hal Daum
?
e III,
2
Lise Getoor
1
University of Maryland, College Park
2
University of California, Santa Cruz
{artir, bert, hal}@cs.umd.edu, goldwas1@umiacs.umd.edu, getoor@soe.ucsc.edu
Abstract
Discussion forums serve as a platform for
student discussions in massive open online
courses (MOOCs). Analyzing content in
these forums can uncover useful informa-
tion for improving student retention and
help in initiating instructor intervention.
In this work, we explore the use of topic
models, particularly seeded topic models
toward this goal. We demonstrate that fea-
tures derived from topic analysis help in
predicting student survival.
1 Introduction
This paper highlights the importance of under-
standing MOOC discussion forum content, and
shows that capturing discussion forum content
can help uncover students? intentions and motiva-
tion and provide useful information in predicting
course completion.
MOOC discussion forums provide a platform
for exchange of ideas, course administration and
logistics questions, reporting errors in lectures,
and discussion about course material. Unlike
classroom settings, where there is face-to-face in-
teraction between the instructor and the students
and among the students, MOOC forums are the
primary means of interaction in MOOCs. How-
ever, due to the large number of students and the
large volume of posts generated by them, MOOC
forums are not monitored completely. Forums
can include student posts expressing difficulties in
course-work, grading errors, dissatisfaction in the
course, which are possible precursors to students
dropping out.
Previous work analyzing discussion forum con-
tent tried manually labeling posts by categories of
interest (Stump et al., 2013). Unfortunately, the
effort involved in manually annotating the large
amounts of posts prevents using such solutions on
a large scale. Instead, we suggest using natural
language processing tools for identifying relevant
aspects of forum content automatically. Specifi-
cally, we explore SeededLDA (Jagarlamudi et al.,
2012), a recent extension of topic models which
can utilize a lexical seed set to bias the topics ac-
cording to relevant domain knowledge.
Exploring data from three MOOCs, we find
that forum posts usually belong to these three
categories?a) course content, which include dis-
cussions about course material (COURSE), b)
meta-level discussions about the course, including
feedback and course logistics (LOGISTICS), and c)
other general discussions, which include student
introductions, discussions about online courses
(GENERAL). In order to capture these categories
automatically we provide seed words for each cat-
egory. For example, we extract seed words for
the COURSE topic from each course?s syllabus.
In addition to the automatic topic assignment, we
capture the sentiment polarity using Opinionfinder
(Wilson et al., 2005). We use features derived
from topic assignments and sentiment to predict
student course completion (student survival). We
measure course completion by examining if the
student attempted the final exam/ last few assign-
ments in the course. We follow the observation
that LOGISTICS posts contain feedback about the
course. Finding high-confidence LOGISTICS posts
can give a better understanding of student opinion
about the course. Similarly, posting in COURSE
topic and receiving good feedback (i.e., votes) is
an indicator of student success and might con-
tribute to survival. We show that modeling these
intuitions using topic assignments together with
sentiment scores, helps in predicting student sur-
vival. In addition, we examine the topic assign-
ment and sentiment patterns of some users and
show that topic assignments help in understanding
student concerns better.
28
2 Modeling Student Survival
Our work builds on work by Ramesh et al. (2013)
and (2014) on modeling student survival using
Probabilistic Soft Logic (PSL). The authors in-
cluded behavioral features, such as lecture views,
posting/voting/viewing discussion forum content,
linguistic features, such as sentiment and subjec-
tivity of posts, and social interaction features de-
rived from forum interaction. The authors looked
at indication of sentiment without modeling the
context in which the sentiment was expressed:
positive sentiment implying survival and negative
sentiment implying drop-out. In this work, we
tackle this problem by adding topics, enabling rea-
soning about specific types of posts. While senti-
ment of posts can indicate general dissatisfaction,
we expect this to be more pronounced in LOGIS-
TICS posts as posts in this category correspond to
issues and feedback about the course. In contrast,
sentiment in posts about course material may sig-
nal a particular topic of discussion in a course and
may not indicate attitude of the student toward the
course. In Section 4.3, we show some examples of
course-related posts and their sentiment, and we
illustrate that they are not suggestive of student
survival. For example, in Women and the Civil
Rights Movement course, the post??I think our
values are shaped by past generations in our fam-
ily as well, sometimes negatively.??indicates an
attitude towards an issue discussed as part of the
course. Hence, identifying posts that fall under
LOGISTICS can improve the value of sentiment in
posts. In Section 3, we show how these are trans-
lated into rules in our model.
2.1 Probabilistic Soft Logic
We briefly overview the some technical details be-
hind Probabilistic Soft Logic (PSL). For brevity,
we omit many specifics, and we refer the reader
to (Broecheler et al., 2010; Bach et al., 2013)
for more details. PSL is a framework for collec-
tive, probabilistic reasoning in relational domains.
Like other statistical relational learning methods
(Getoor and Taskar, 2007), PSL uses weighted
rules to model dependencies in a domain. How-
ever, one distinguishing aspect is that PSL uses
continuous variables to represent truth values, re-
laxing Boolean truth values to the interval [0,1].
Table 1 lists some PSL rules from our model.
The predicate posts captures the relationship be-
tween a post and the user who posted it. Predicate
polarity(P) represents sentiment via its truth value
in [0, 1], where 1.0 signifies positive sentiment,
and 0.0 signifies negative sentiment. upvote(P) is
1.0 if the post has positive feedback and 0.0 if the
post had negative or no feedback. U and P refer to
user and post respectively. These features can be
combined to produce rules in Table 1. For exam-
ple, the first rule captures the idea that posts with
positive sentiment imply student survival.
? posts(U,P ) ? polarity(P ) ? survival(U)
? posts(U,P ) ? ?polarity(P ) ? ?survival(U)
? posts(U,P ) ? upvote(P ) ? survival(U)
Table 1: Example rules in PSL
3 Enhancing Student Survival Models
with Topic Modeling
Discussion forums in online courses are organized
into threads to facilitate grouping of posts into top-
ics. For example, a thread titled errata, grading
issues is likely a place for discussing course logis-
tics and a thread titled week 1, lecture 1 is likely a
place for discussing course content. But a more
precise examination of such threads reveals that
these heuristics do not always hold. We have ob-
served that course content threads often house lo-
gistic content and vice-versa. This demands the
necessity of using computational linguistics meth-
ods to classify the content in discussion forums.
In this work, we?1) use topic models to map
posts to topics in an unsupervised way, and 2)
employ background knowledge from the course
syllabus and manual inspection of discussion fo-
rum posts to seed topic models to get better sep-
arated topics. We use data from three Cours-
era MOOCs: Surviving Disruptive Technologies,
Women and the Civil Rights Movement, and Gene
and the Human Condition for our analysis. In dis-
cussion below, we refer to these courses as DISR-
TECH, WOMEN, and GENE, respectively.
3.1 Latent Dirichlet Allocation
Table 2 gives the topics given by latent Dirichlet
allocation (LDA) on discussion forum posts. The
words that are likely to fall under LOGISTICS are
underlined in the table. It can be observed that
these words are spread across more than one topic.
Since we are especially interested in posts that are
on LOGISTICS, we use SeededLDA (Jagarlamudi
et al., 2012), which allows one to specify seed
words that can influence the discovered topics to-
ward our desired three categories.
29
topic 1: kodak, management, great, innovation, post, agree, film, understand, something, problem, businesses, changes, needs
topic 2: good, change, publishing, brand, companies, publishers, history, marketing, traditional, believe, authors
topic 3: think, work, technologies, newspaper, content, paper, model, business, disruptive, information, survive, print, media, course, assignment
topic 4: digital, kodak, company, camera, market, quality, phone, development, future, failed, high, right, old,
topic 5: amazon, books, netflix, blockbuster, stores, online, experience, products, apple, nook, strategy, video, service
topic 6: time, grading, different, class, course, major, focus, product, like, years
topic 7: companies, interesting, class, thanks, going, printing, far, wonder, article, sure
Table 2: Topics identified by LDA
topic 1: thank, professor, lectures, assignments, concept, love, thanks, learned, enjoyed, forums, subject, question, hard, time, grading, peer, lower, low
topic 2: learning, education, moocs, courses, students, online, university, classroom, teaching, coursera
Table 3: Seed words in LOGISTICS and GENERAL for DISR-TECH, WOMEN and GENE courses
topic 3a: disruptive, technology, innovation, survival, digital, disruption, survivor
topic 3b: women, civil, rights, movement, american, black, struggle, political, protests, organizations, events, historians, african, status, citizenship
topic 3c: genomics, genome, egg, living, processes, ancestors, genes, nature, epigenitics, behavior, genetic, engineering, biotechnology
Table 4: Seed words for COURSE topic for DISR-TECH, WOMEN and GENE courses
topic 1: time, thanks, one, low, hard, question, course, love, professor, lectures, lower, another, concept, agree, peer, point, never
topic 2: online, education, coursera, students, university, courses, classroom, moocs, teaching, video
topic 3: digital, survival, management, disruption, technology, development, market, business, innovation
topic 4: publishing, publisher, traditional, companies, money, history, brand
topic 5: companies, social, internet, work, example
topic 6: business, company, products, services, post, consumer, market, phone, changes, apple
topic 7: amazon, book, nook, readers, strategy, print, noble, barnes
Table 5: Topics identified by SeededLDA for DISR-TECH
topic 1: time, thanks, one, hard, question, course, love, professor, lectures, forums, help, essays, problem, thread, concept, subject
topic 2: online, education, coursera, students, university, courses, classroom, moocs, teaching, video, work, english, interested, everyone
topic 3: women, rights, black, civil, movement, african, struggle, social, citizenship, community, lynching, class, freedom, racial, segregation
topic 4: violence, public, people, one, justice, school,s state, vote, make, system, laws
topic 5: idea, believe, women, world, today, family, group, rights
topic 6: one, years, family, school, history, person, men, children, king, church, mother, story, young
topic 7: lynching, books, mississippi, march, media, youtube, death, google, woman, watch, mrs, south, article, film
Table 6: Topics identified by SeededLDA for WOMEN
topic 1: time, thanks, one, answer, hard, question, course, love, professor, lectures, brian, lever, another, concept, agree, peer, material, interesting
topic 2: online, education, coursera, students, university, courses, classroom, moocs, teaching, video, knowledge, school
topic 3: genes, genome, nature, dna, gene, living, behavior, chromosomes, mutation, processes
topic 4: genetic, biotechnology, engineering, cancer, science, research, function, rna
topic 5: reproduce, animals, vitamin, correct, term, summary, read, steps
topic 6: food, body, cells, alleles blood, less, area, present, gmo, crops, population, stop
topic 7: something, group, dna, certain, type, early, large, cause, less, cells
Table 7: Topics identified by SeededLDA for GENE
3.2 Seeded LDA
We experiment by providing seed words for top-
ics that fall into the three categories. The seed
words for the three courses are listed in tables 3
and 4. The seed words for LOGISTICS and GEN-
ERAL are common across all the three courses.
The seed words for the COURSE topic are chosen
from the course-syllabus of the courses. This con-
struction of seed words enables the model to be
applied to new courses easily. Topics 3a, 3b, and
3c denote the course specific seed words for DISR-
TECH, WOMEN, and GENE courses respectively.
Since the syllabus is only an outline of the class,
it does not contain all the terms that will be used
in class discussions. To capture other finer course
content discussions as separate topics, we include
k more topics when we run the SeededLDA. We
notice that not including more topics here, only
including the seeded topics (i.e., run SeededLDA
with exactly three topics) results in some words
from course content discussions, which were not
specified in the course-seed words, appearing in
the LOGISTICS or GENERAL topics. Thus, the k
extra topics help represent COURSE topics that do
not directly correspond to the course seeds. Note
that these extra topics are not seeded. We exper-
imented with different values of k on our exper-
iments and found by manual inspection that the
topic-terms produced by our model were well sep-
arated for k = 3. Thus, we run SeededLDA with
7 total topics. Tables 5, 6, and 7 give the top-
ics identified for DISR-TECH, WOMEN and GENE
by SeededLDA. The topic assignments so obtained
are used as input features to the PSL model?the
predicate for the first topic is LOGISTICS, the sec-
ond one is GENERAL and the rest are summed up
to get the topic assignment for COURSE.
3.3 Using topic assignments in PSL
We construct two models?a) DIRECT model, in-
cluding all features except features from topic
30
survival = 0.0 polarity = 0.25 logistics = 0.657
general = 0.028
course = 0.314
JSTOR allowed 3 items (texts/writings) on my ?shelf? for 14 days. But, I read the items and wish to return them, but
cannot, until 14 days has expired. It is difficult then, to do the extra readings in the ?Exploring Further? section of Week
1 reading list in a timely manner. Does anyone have any ideas for surmounting this issue?
survival = 0.0 polarity = 0.0 logistics = 0.643
general = 0.071
course = 0.285
There are some mistakes on quiz 2. Questions 3, 5, and 15 mark you wrong for answers that are correct.
survival = 0.0 polarity = 0.25 logistics = 0.652
general = 0.043
course = 0.304
I see week 5 quiz is due April 1( by midnight 3/31/13).I am concerned about this due date being on Easter, some of us
will be traveling, such as myself. Can the due date be later in the week? Thank you
Table 8: Logistics posts containing negative sentiment for dropped-out students
survival = 1.0 polarity = 0.0 logistics = 0.67
general = 0.067
course = 0.267
I was just looking at the topics for the second essay assignments. The thing is I dont see what the question choices are.
I have the option of Weeks and I have no idea what that even means. Can someone help me out here and tell me what
the questions for the second essay assignment are I think my computer isnt allowing me to see the whole assignment!
Someone please help me out and let me know that the options are.
survival = 1.0 polarity = 0.25 logistics = 0.769
general = 0.051
course = 0.179
I?d appreciate someone looks into the following: Lecture slides for the videos (week 5) don?t open (at all) (irrespective
of the used browser). Some required reading material for week 5 won?t open either (error message). I also have a sense
that there should be more material posted for the week (optional readings, more videos, etc). Thanks. ? I am not
seeing a quiz posted for Week 5.
survival = 1.0 polarity = 0.78 logistics = 0.67
general = 0.067
course = 0.267
Hopefully the Terrell reading and the Lecture PowerPoints now open for you. Thanks for reporting this.
Table 9: Example of change in sentiment in a course logistic thread
survival = 1.0 polarity = 0.25 logistics = 0.372
general = 0.163
course = 0.465
I?ve got very interested in the dynamic of segregation in terms of space and body pointed by Professor Brown and
found a document written by GerShun Avilez called ?Housing the Black Body: Value, Domestic Space,and Segregation
Narratives?.
survival = 1.0 polarity = 0.9 logistics = 0.202
general = 0.025
course = 0.772
I think that you hit it on the head, the whole idea of Emancipation came as a result not so much of rights but of the need
to get the Transcontinental Railroad through the mid-west and the north did not want the wealth of the southern slave
owners to overshadow the available shares. There are many brilliant people ?good will hunting?, and their brilliance
either dies with them or dies while they are alive due to intolerance. Many things have happened in my life to cause me
to be tolerant to others and see what their debate is, Many very evil social ills and stereotypes are a result of ignorance.
It would be awesome if the brilliant minds could all come together for reform and change.
survival = 1.0 polarity = 0.167 logistics = 0.052
general = 0.104
course = 0.844
I think our values are shaped by past generations in our family as well ? sometimes negatively. In Bliss, Michigan
where I come from, 5 families settled when the government kicked out the residents ? Ottowa Tribe Native Americans.
I am descended from the 5 families. All of the cultural influences in Bliss were white Christian ? the Native American
population had never been welcomed back or invited to stay as they had in Cross Village just down the beach. My
family moved to the city for 4 years during my childhood, and I had African American, Asian, and Hispanic classmates
and friends. When we moved back to the country I was confronted with the racism and generational wrong-doings of
my ancestors. At the tender age of 10 my awareness had been raised! Was I ever pissed off when the full awareness of
the situation hit me! I still am.
Table 10: Posts talking about COURSE content
DIRECT DIRECT+TOPIC
posts(U,P ) ? polarity(P ) ? survival(U) posts(U,P ) ? topic(P, LOGISTICS) ? ?polarity(P ) ? survival(U)
posts(U,P ) ? ?polarity(P ) ? ?survival(U) posts(U,P ) ? topic(P, LOGISTICS) ? ?polarity(P ) ? survival(U)
posts(U,P ) ? survival(U) posts(U,P ) ? topic(P, GENERAL) ? ?survival(U)
posts(U,P ) ? upvote(P ) ? survival(U) posts(U,P ) ? topic(P, COURSE) ? upvote(P ) ? survival(U)
posts(U
1
, P ) ? posts(U
2
, P ) ? topic(P, COURSE) ? survival(U
1
) ?
survival(U
2
)
Table 11: Rules modified to include topic features
modeling, and b) DIRECT+TOPIC model, includ-
ing the topic assignments as features in the model.
Our DIRECT model is borrowed from Ramesh
(2014). We refer the reader to (Ramesh et al.,
2013) and (Ramesh et al., 2014) for a complete
list of features and rules in this model.
Table 11 contains examples of rules in the DI-
RECT model and the corresponding rules includ-
ing topic assignments in DIRECT+TOPIC model.
The first and second rules containing polarity are
changed to include LOGISTICS topic feature, fol-
lowing our observation that polarity matters in
meta-course posts. While the DIRECT model re-
gards posting in forums as an indication of sur-
vival, in the DIRECT+TOPIC model, this rule is
changed to capture that students that post a lot of
general stuff only on the forums do not necessar-
ily participate in course-related discussions. The
fourth rule containing upvote predicate, which sig-
nifies posts that received positive feedback in the
form of votes, is changed to include the topic-
feature COURSE. This captures the significance
of posting course-related content that gets posi-
tive feedback as opposed to logistics or general
content in the forums. This rule helps us discern
posts in general/logistic category that can get a lot
31
of positive votes (upvote), but do not necessarily
indicate student survival. For example, some in-
troduction threads have a lot of positive votes, but
do not necessarily signify student survival.
4 Empirical Evaluation
We conducted experiments to answer the follow-
ing question?how much do the topic assignments
from SeededLDA help in predicting student sur-
vival? We also perform a qualitative analysis
of topic assignments, the sentiment of posts, and
their correspondence with student survival.
COURSE MODEL AUC-PR
POS.
AUC-PR
NEG.
AUC-
ROC
DISR-TECH
DIRECT 0.764 0.628 0.688
DIRECT+TOPIC 0.794 0.638 0.708
WOMEN
DIRECT 0.654 0.899 0.820
DIRECT+TOPIC 0.674 0.900 0.834
GENE
DIRECT 0.874 0.780 0.860
DIRECT+TOPIC 0.894 0.791 0.873
Table 12: Performance of DIRECT and DI-
RECT+TOPIC models in predicting student sur-
vival. Statistically significant scores typed in bold.
4.1 Datasets and Experimental Setup
We evaluate our models on three Coursera
MOOCs: DISR-TECH, WOMEN-CIVIL, and GENE,
respectively. Our data consists of anonymized stu-
dent records, grades, and online behavior recorded
during the seven week duration of each course. We
label students as survival = 1.0 if they take the fi-
nal exam/quiz and survival = 0.0 otherwise. In
our experiments, we only consider students that
completed at least one quiz/assignment. We eval-
uate our models using area under precision-recall
curve for positive and negative survival labels and
area under ROC curve. We use ten-fold cross-
validation on each of the courses, leaving out 10%
of users for testing and revealing the rest of the
users for training the model weights. We evaluate
statistical significance using a paired t-test with a
rejection threshold of 0.05.
4.2 Survival Prediction using topic features
Table 12 shows the prediction performance of the
DIRECT and DIRECT+TOPIC model. The inclu-
sion of the topic-features improves student sur-
vival prediction in all the three courses.
4.3 Discussion topic analysis using topic
features
Table 8 shows some posts by users that did not
survive the class. All these posts have negative
sentiment scores by Opinionfinder and belong to
LOGISTICS. Also, in the forum, all these posts
were not answered. This suggests that students
might drop out if their course-logistics questions
are not answered. Table 9 gives examples of stu-
dent posts that also have a negative sentiment. But
the sentiment of the thread changes when the issue
is resolved (last row in the table). We observe that
these two students survive the course and a timely
answer to their posts might have been a reason in-
fluencing these students to complete the course.
Tables 8 and 9 show how student survival may
depend on forum interaction and responses they
receive. Our approach can help discover potential
points of contention in the forums, identifying po-
tential drop outs that can be avoided by interven-
tion.
Table 10 shows posts flagged as COURSE by the
SeededLDA. The polarity scores in the COURSE
posts indicate opinions and attitude toward course
specific material. For example, post #3 in Table 10
indicates opinion towards human rights. While the
post?s polarity is negative, it is clear that this po-
larity value is not directed at the course and should
not be used to predict student survival. In fact, all
these users survive the course. We find that par-
ticipation in course related discussion is a sign of
survival. These examples demonstrate that analy-
sis on COURSE posts can mislead survival and jus-
tify our using topic predictions to focus sentiment
analysis on LOGISTICS posts.
5 Discussion
In this paper, we have taken a step toward un-
derstanding discussion content in massive open
online courses. Our topic analysis is coarse-
grained, grouping posts into three categories. In
our analysis, all the meta-content?course logis-
tics and course feedback?were grouped under the
same topic category. Instead, a finer-grained topic
model could be seeded with different components
of meta-content as separate topics. The same ap-
plies for course-related posts too, where a finer-
grained analysis could help identify difficult topics
that may cause student frustration and dropout.
Acknowledgements We thank the instructors for letting us
use data from their course. This work is supported by Na-
tional Science Foundation under Grant No. CCF0937094.
Any opinions, findings, and conclusions or recommendations
expressed in this material are those of the author(s) and do not
necessarily reflect the views of the National Science Founda-
tion.
32
References
Stephen H. Bach, Bert Huang, Ben London, and Lise Getoor.
2013. Hinge-loss Markov random fields: Convex infer-
ence for structured prediction. In Uncertainty in Artificial
Intelligence.
Matthias Broecheler, Lilyana Mihalkova, and Lise Getoor.
2010. Probabilistic similarity logic. In Uncertainty in Ar-
tificial Intelligence (UAI).
Lise Getoor and Ben Taskar. 2007. Introduction to Statistical
Relational Learning (Adaptive Computation and Machine
Learning). The MIT Press.
Jagadeesh Jagarlamudi, Hal Daum?e, III, and Raghavendra
Udupa. 2012. Incorporating lexical priors into topic
models. In Proceedings of the 13th Conference of the
European Chapter of the Association for Computational
Linguistics, EACL ?12, pages 204?213, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Angelika Kimmig, Stephen H. Bach, Matthias Broecheler,
Bert Huang, and Lise Getoor. 2012. A short introduction
to probabilistic soft logic. In NIPS Workshop on Proba-
bilistic Programming: Foundations and Applications.
Arti Ramesh, Dan Goldwasser, Bert Huang, Hal Daume III,
and Lise Getoor. 2013. Modeling learner engagement in
MOOCs using probabilistic soft logic. In NIPS Workshop
on Data Driven Education.
Arti Ramesh, Dan Goldwasser, Bert Huang, Hal Daume III,
and Lise Getoor. 2014. Learning latent engagement pat-
terns of students in online courses. In Proceedings of the
Twenty-Eighth AAAI Conference on Artificial Intelligence.
Glenda S. Stump, Jennifer DeBoer, Jonathan Whittinghill,
and Lori Breslow. 2013. Development of a framework to
classify mooc discussion forum posts: Methodology and
challenges. In NIPS Workshop on Data Driven Education.
Theresa Wilson, Paul Hoffmann, Swapna Somasundaran, Ja-
son Kessler, Janyce Wiebe, Yejin Choi, Claire Cardie,
Ellen Riloff, and Siddharth Patwardhan. 2005. Opinion-
Finder: A system for subjectivity analysis. In Proceedings
of HLT/EMNLP on Interactive Demonstrations.
33
Proceedings of the Joint Workshop on Social Dynamics and Personal Attributes in Social Media, pages 109?117,
Baltimore, Maryland USA, 27 June 2014.
c?2014 Association for Computational Linguistics
Collective Stance Classification of Posts in Online Debate Forums
Dhanya Sridhar
Computer Science Dept.
UC Santa Cruz
dsridhar@soe.ucsc.edu
Lise Getoor
Computer Science Dept.
UC Santa Cruz
getoor@soe.ucsc.edu
Marilyn Walker
Computer Science Dept.
UC Santa Cruz
maw@soe.ucsc.edu
Abstract
Online debate sites are a large source of
informal and opinion-sharing dialogue on
current socio-political issues. Inferring
users? stance (PRO or CON) towards dis-
cussion topics in domains such as politics
or news is an important problem, and is
of utility to researchers, government or-
ganizations, and companies. Predicting
users? stance supports identification of so-
cial and political groups, building of better
recommender systems, and personaliza-
tion of users? information preferences to
their ideological beliefs. In this paper, we
develop a novel collective classification
approach to stance classification, which
makes use of both structural and linguis-
tic features, and which collectively labels
the posts? stance across a network of the
users? posts. We identify both linguistic
features of the posts and features that cap-
ture the underlying relationships between
posts and users. We use probabilistic soft
logic (PSL) (Bach et al., 2013) to model
post stance by leveraging both these local
linguistic features as well as the observed
network structure of the posts to reason
over the dataset. We evaluate our approach
on 4FORUMS (Walker et al., 2012b), a col-
lection of discussions from an online de-
bate site on issues ranging from gun con-
trol to gay marriage. We show that our col-
lective classification model is able to eas-
ily incorporate rich, relational information
and outperforms a local model which uses
only linguistic information.
1 Introduction
Modeling user stance (PRO, CON) in discussion
topics in online social media debate is of inter-
est to researchers, corporations and governmental
organizations alike. Predicting a user?s stance to-
wards a given issue can support the identification
of social or political groups (Gawron et al., 2012;
Abu-Jbara et al., 2012; Anand et al., 2011; Qiu et
al., 2013; Hasan and Ng, 2013), help develop bet-
ter recommendation systems, or tailor users? infor-
mation preferences to their ideologies and beliefs.
Stance classification problems consist of a collec-
tion of debate-style discussions by authors on dif-
ferent controversial, political topics.
While these may be spoken as in the Congres-
sional Debates corpus (Thomas et al., 2006; Bur-
foot, 2008), we focus on forum posts on social
media debate sites. Users on debate sites share
their opinions freely, using informal and social
language, providing a rich and much more chal-
lenging domain for stance prediction.
Social media debate sites contain online discus-
sions with posts from various authors, where each
post is either a response to another post or the root
of the discussion (Anand et al., 2011; Walker et
al., 2012a). Posts are linked to one another by ei-
ther rebuttal or agreement links and are labelled
for stance, either PRO or CON, depending on the
framing of the issue under discussion. Each post
reflects the stance and sentiment of its author. Au-
thors may participate in multiple discussions in the
same topic, and may discuss multiple topics. For
example consider the sample posts from the online
discussion forum 4forums.com shown in Fig.
1. Here, we see discussion topics, together with
sample quotes and responses, where the response
is a direct reply to the quote text. The annotations
for stance were gathered using Amazon?s Mechan-
ical Turk service with an interface that allowed an-
notators to see complete discussions. Quotes pro-
vide additional context that were used by human
annotators in a separate task for annotating agree-
ment and disagreement (Misra and Walker, 2013).
Responses can be labeled as either PRO or CON to-
ward the topic. For the example shown in Fig. 1,
109
Quote Q, Response R Stance Topic
Q: I thought I?d start a new thread for those newcomers who don?t want to be shocked by sick
minded nazi XXXX. Anyway... When are fetuses really alive, and how many fetuses are actually
aborted (murdered) before that time?
R: The heart starts beating 3 weeks after conception, and you can?t live without a beating heart,
but me personally, I think that as soon as the miracle starts, (egg and sperm combine) that is
when life begins. I know it?s more of a spiritual thing for me instead of a fact. :)
CON Abortion
Q2: Most americans support a Federal Marriage Amendment. Defining Marriage as a union
between a man and a woman. Federal Marriage Amendment. This is the text of the Amend:
Marriage in the United States shall consist only of the union of a man and a woman. Neither
this constitution or the constitution of any state, nor state or federal law, shall be construed to
require that marital status or the legal incidents thereof be conferred upon unmarried couples or
groups.
R2: Debator, why does it bother you so much that some people are gay? Its a sexual prefference.
People like certain things when they have sex. Example: A man likes a women with small boobs.
Or, a man likes a women with nice legs. People like the way certain things feel (I?m not giving
te example for that one;) ). So why does it bother people that someone?s sexual prefference is
just a little kinkier than thiers?
PRO Gay
Mar-
riage
Figure 1: Sample Quote/Response Pair from 4forums.com with Mechanical Turk annotations for stance.
Both response posts are from the same author.
both response posts are from the same author. We
describe the dataset further in Section 4.1.
We believe that models of post stance in on-
line debate should capture both the content and the
context of author posts. By jointly reasoning over
both the content of the post and its relationships
with other posts in the discussion, we perform col-
lective classification, as we further define in Sec-
tion 3 (Sen et al., 2008). Previous work has shown
that collective classification models often perform
better than content-only approaches. (Burfoot et
al., 2011; Hasan and Ng, 2013; Thomas et al.,
2006; Bansal et al., 2008; Walker et al., 2012c).
Here, we develop a collective classification ap-
proach for stance prediction which leverages the
sentiment conveyed in a post through its language,
and the reply links consisting of agreements or re-
buttals between posts in a discussion. We imple-
ment our approach using Probabilistic Soft Logic
(PSL) (Bach et al., 2013), a recently introduced
tool for collective inference in relational data. We
evaluate our model on data from the 4FORUMS
online debate site (Walker et al., 2012b).
Section 2 first presents an overview of our ap-
proach and then in Section 3.1 we describe the
PSL framework in more detail. Section 4 de-
scribes the evaluation data and our results show-
ing that the PSL model improves prediction of post
stance in the 4Forums dataset. In Section 5 we
describe related work, and compare with our pro-
posed approach. Section 6 summarizes our ap-
proach and results.
2 Overview of Approach
Given a set of topics {t
1
. . . t
n
}, where each topic
t
i
consists of a set of discussions {d
i1
. . . d
ij
}, we
model each discussion d
k
as a collection of posts
{p
k0
, . . . , p
km
}, where each post p
ki
is mapped to
its author a
i
.
A discussion d
i
? D is a tree of posts, starting
with the initial post p
i0
. We distinguish between
posts that start a new thread (root) and others (non-
root). Each non-root post p
ij
is the response to
some previous post p
ik
, where k < j, and we refer
to p
ik
as the parent of p
ij
. For a subset of the posts,
p
ij
has been annotated with a real valued number
in the interval [?5, 5] that denotes whether the post
disagrees or agrees with its parent. Values ? 0 are
considered disagreement and values? 1, as agree-
ment. We discard the posts where the annotations
are in the interval (0, 1) since those indicate high
annotator uncertainty about agreement.
Fig. 2 illustrates an example of three discussion
trees for two topics where author a
2
participates
in multiple discussions of the same topic and a
3
and a
4
participate in multiple topics. An author
directly replies with a post to another author?s post
and either disagrees or agrees.
Each post p
ij
in discussion d
i
is also mapped to
{x
ij
1
, . . . , x
ij
N
} linguistic features as described in
Section 3.2.1 as well as y
ij
, the stance label (PRO,
CON) towards the discussion topic t
i
.
We say that a
j
participates in topic t
i
if there
exist any posts p
j
? d
i
with author a
j
.
Using the tree structure and posts that have an-
notations for agreement or disagreement, we con-
110
Figure 2: Example of 3 discussions in (a), (b) and (c). Dotted lines denote the ?writes? relation between
authors and posts and dashed lines denote the ?disagrees? relation between posts and between authors.
Authors can participate in multiple discussions of the same topic, shown by a
2
in both (a) and (b).
Moreover, authors may post in multiple topics, as shown by a
3
and a
4
in both (b) and (c), and may
interact with the same authors multiple times, as shown again in (b) and (c).
sider the network graph G of disagreement and
agreement between posts and between authors,
where the vertices are posts {p
0
, . . . , p
m
} and au-
thors {a
0
, . . . , a
n
}. A disagreement edge exists
from post p
u
to p
v
if p
u
disagrees with p
v
.
A disagreement edge exists from a
w
to a
y
if any
of the posts {p
w
, . . . , p
x
} mapped to a
w
disagree
with any posts {p
y
, . . . p
z
}mapped to a
y
. We sim-
ilarly define agreement edges for both posts and
authors.
3 Collective Classification of Stance
Given the discussion structure defined in the pre-
vious section, our task is to infer the stance of each
post. We make use of both linguistic features and
the relational structure in order to collectively or
jointly infer the stance labels. This corresponds to
a collective classification setting (Sen et al., 2008),
in which we are given a multi-relational network
and some partially observed labels, and we wish
to infer all of the unobserved labels, conditioned
on observed attributes and links. Collective clas-
sification refers to the combined classification of
a set of interdependent objects (posts, in our do-
main) using information given by both the local
features of the objects and the properties of the
objects? neighbors in a network. For the stance
classification problem, we infer stance labels for
posts using both the correlation between a post and
its linguistic attributes {x
ij
1
, . . . , x
ij
N
}, and the
labels and attributes of its neighbors in observed
network graph G. We use PSL, described below,
to perform collective classification.
3.1 Probabilistic Soft Logic
Probabilistic soft logic (PSL) is a framework for
probabilistic modeling and collective reasoning in
relational domains (Kimmig et al., 2012; Bach et
al., 2013). PSL provides a declarative syntax and
uses first-order logic to define a templated undi-
rected graphical model over continuous random
variables. Like other statistical relational learn-
ing methods, dependencies in the domain are cap-
tured by constructing rules with weights that can
be learned from data.
But unlike other statistical relational learning
methods, PSL relaxes boolean truth values for
atoms in the domain to soft truth values in the in-
terval [0,1]. In this setting, finding the most proba-
ble explanation (MPE), a joint assignment of truth
values to all random variable ground atoms, can be
done efficiently.
For example, a typical PSL rule looks like the
following:
P (A,B) ?Q(B,C)? R(A,C)
where P, Q and R are predicates that represent
observed or unobserved attributes in the domain,
and A, B, and C are variables. For example, in
our 4FORUMS domain, we consider an observed
attribute such as writesPost(A, P) and infer an un-
observed attribute (or label) such as isProPost(P,
T). Instantiation of predicates with data is called
grounding (e.g. writesPost(A2, P7)), and each
ground predicate, often called ground atom, has a
soft truth value in the interval [0,1]. To build a PSL
model for stance classification, we represent posts
111
isProPost(P, T) ? writesPost(A, P) ? isProAuth(A, T)
? isProPost(P, T) ? writesPost(A, P) ? ? isProAuth(A, T)
agreesPost(P, P2) ? isProPost(P, T) ? isProPost(P2, T)
agreesPost(P, P2) ?? isProPost(P, T) ? ? isProPost(P2, T)
disagreesPost(P, P2) ? isProPost(P, T) ? ? isProPost(P2, T)
disagreesPost(P, P2) ?? isProPost(P, T) ? isProPost(P2, T)
agreesAuth(A, A2) ? isProAuth(A, T) ? isProAuth(A, T)
agreesAuth(A, A2) ?? isProAuth(A, T) ? ? isProAuth(A2, T)
disagreesAuth(A, A2) ? isProAuth(A, T) ? ? isProAuth(A2, T)
disagreesAuth(A, A2) ?? isProAuth(A, T) ? isProAuth(A2, T)
hasLabelPro(P, T) ? isProPost(P, T)
? hasLabelPro(P, T) ? ? isProPost(P, T)
Table 1: Rules for PSL model, where P = post, T = Topic, and A = Author.
and authors as variables and specify predicates to
encode different interactions, such as writes, be-
tween them. Domain knowledge is captured by
writing rules with weights that govern the rela-
tive importance of the dependencies between pred-
icates. The groundings of all the rules result in
an undirected graphical model that represents the
joint probability distribution of assignments for all
unobserved atoms, conditioned on the observed
atoms.
Triangular norms, which are continuous relax-
ations of logical AND and OR, are used to com-
bine the atoms in the first-order clauses. As a
result of the soft truth values and the triangu-
lar norms, the underlying probabilistic model is
a hinge-loss Markov Random Field (HL-MRF).
Inference in HL-MRFs is a convex optimization,
which leads to a significant improvement in effi-
ciency over discrete probabilistic graphical mod-
els. Thus, PSL offers a very natural interface to
compactly represent stance classification as a col-
lective classification problem, along with methods
to reason about our domain.
3.2 Features
We extract both linguistic features that capture the
content of a post and features that capture multiple
relations from our dataset.
3.2.1 Linguistic Features
To capture the content of a post, on top of a bag-of-
words representation with unigrams and bigrams,
we also consider basic lengths, discourse cues,
repeated punctuation counts and counts of lex-
ical categories based on the Linguistic Inquiry
and Word Count tool (LIWC) (Pennebaker et al.,
2001). Basic length features capture the number
of sentences, words, and characters, along with
the average word and sentence lengths for each
post. The discourse cues feature captures fre-
quency counts for the first few words of the post,
which often contain discourse cues. To capture
the information in repeated punctuation like ?!!?,
???? or ??!? we include the frequency count of the
given punctuation patterns as a feature of each post
(Anand et al., 2011). LIWC counts capture senti-
ment by giving the degree to which the post uses
certain categories of subjective language.
3.2.2 Relational Information
As our problem domain contains relations be-
tween both authors and posts, for our PSL model,
we consider the relations between authors, be-
tween posts and between authors and posts. As de-
scribed above, in PSL, we model these relations as
first-order predicates. In Section 3.3, we describe
how we populate the predicates with observations
from our data.
Author Information We observe that authors
participate in discussions by writing posts. For
a subset of authors, we have annotations for their
interactions with other authors as either disagree-
ment or agreement, as given by network graph
G. We encode this with the following predi-
cates: writesPost(A, P), disagreesAuth(A1, A2),
agreesAuth(A1, A2).
Post Information Posts are linked to the topic
of their given discussion, and to other posts in
their discussion through disagreement or agree-
ment. Additionally, we include a predicate for post
stance towards its topic as predicted by a classifier
112
that only uses linguistic features, as described in
Section 3.3, as prior information. We capture these
relations with the following predicates: hasLabel-
Pro(P, T), hasTopic(P, T), disagreesPost(P1, P2),
agreesPost(P1, P2).
3.2.3 Target attributes
Our goal is to 1) predict the stance relation be-
tween a post and its topic, namely, PRO or CON and
2) predict the stance relation between an author
and a topic. In our PSL model, our target predi-
cates are isProPost(P, T) and isProAuth(A, T).
3.3 PSL Model
We construct our collective stance classification
model in PSL using the predicates listed above.
For disagreement/agreement annotations in the in-
terval [-5, 5], we consider values [-5,0] as evidence
for the disagreesAuth relation and values [1, 5] as
evidence for the agreesAuth relation. We discard
observations with annotations in the interval [0,1]
because it indicates a very weak signal of agree-
ment, which is already rare on debate sites. We
populate disagreesPost and agreesPost in the same
way as described above.
For each relation, we populate the correspond-
ing predicate with all the instances that we observe
in data and we fix the truth value of each observa-
tion as 1. For all such predicates where we observe
instances in the data, we say that the predicate is
closed. For the relations isPostPro and isAuthPro
that we predict through inference, a truth value of
1 denotes a PRO stance and a truth value of 0 de-
notes a CON stance. We say that those predicates
are open, and the goal of inference is to jointly as-
sign truth values to groundings of those predicates.
We use our domain knowledge to describe rules
that relate these predicates to one another. We fol-
low our intuition that agreement between nodes
implies that they have the same stance, and dis-
agreement between nodes implies that they have
opposite stances. We relate post and author nodes
to each other by supposing that if a post is PRO
towards its topic, then its author will also be PRO
towards that topic.
We construct a classifier that takes as input the
linguistic features of the posts and outputs predic-
tions for stance label of each post. We then con-
sider the labels predicted by the local classifier as
a prior for the inference of the target attributes in
our PSL model. Table 1 shows the rules in our
PSL model.
Topic Authors Posts
Abortion 385 8114
Evolution 325 6186
Gun Control 319 3899
Gay Marriage 316 7025
Death Penalty 170 572
Table 2: Overview of topics in 4FORUMSdataset.
4 Experimental Evaluation
We first describe the dataset we use for evaluation
and then describe our evaluation method and re-
sults.
4.1 Dataset
We evaluate our proposed approach on discus-
sions from https://www.4forums.com, an
online debate site on social and political issues.
The dataset is publicly available as part of the
Internet Argument Corpus, an annotated collec-
tion of 109,533 forum posts (Walker et al., 2012b;
Walker et al., 2012c). On 4FORUMS, a user ini-
tiates a discussion by posting a new question or
comment under a topic, or participate in an ongo-
ing discussion by replying to any of the posts in
the thread. The discussions were given to English
speaking Mechanical Turk annotators for a num-
ber of annotation tasks to get labels for the stances
of discussion participants towards the topic, and
scores for each post in a discussion indicating
whether it is in agreement or disagreement with
the preceding post.
The scores for agreement and disagreement
were on a 11 point scale [-5, 5] implemented using
a slider, and annotators were given quote/response
pairs to determine if the response text agreed
or disagreed with the quote text. We use the
mean score across the 5-7 annotators used in the
task. A more negative value indicates higher
inter-annotator confidence of disagreement, and a
more positive value indicates higher confidence of
agreement. The gold-standard annotation used for
the stance label of each post is given by the ma-
jority annotation among 3-8 Mechanical Turk an-
notators performed as a separate task, using en-
tire discussions to determine the stance of the au-
thors in the discussion towards the topic. We use
the stance of each post?s author to determine the
post?s stance. For our experiments, we use all
posts with annotations for stance, and about 90%
of these posts also have annotations for agree-
113
ment/disagreement.
The discussions span many topics, and Table 2
gives a summary of the topics we consider in our
experiments and the distribution of posts across
these topics. Each post in a discussion comes as
a quote-response pair, where the quote is the text
that the post is in response to, and the response is
the post text. We refer to (Walker et al., 2012b) for
a full description of the corpus and the annotation
process.
4.2 Evaluation
In order to evaluate our methods, we split the
dataset into training and testing sets by randomly
selecting half the authors from each topic and their
posts for the training set and using the remaining
authors and their posts for the test set. This way,
we ensure that no two authors appear in both train-
ing and test sets for the same topic, since stance
is topic-dependent. We create 10 randomly sam-
pled train/test splits for evaluation. Each split con-
tains about 18,000 posts. For each train/test split,
we train a linear SVM for each topic, with the
L2-regularized-L1-loss SVM implemented in the
LibLINEAR package (Fan et al., 2008). We use
only the linguistic features from the posts, for each
topic in the training set. We refer to the baseline
model which only uses the the output of the SVM
as the LOCAL model. We output the predictions
from LOCAL model and get stance labels for posts
in both the training and test sets. We use the pre-
dictions as prior information for the true stance la-
bel in our PSL model, with the hasLabel predicate.
We use the gold standard stance annotation
(PRO, CON) for each post as ground truth for
weight learning and inference. A truth value of 1
for isPostPro and isAuthPro denotes a PRO stance
and a truth value of 0 denotes a CON stance. We
learn the weights of our PSL model (initially set to
1) for each of our training sets and perform infer-
ence on each of the test sets.
Table 3 shows averages for F1 score for the pos-
itive class (PRO), area under the precision-recall
curve (AUC-PR) for the negative class (CON) and
area under the ROC curve (AUROC) over the 10
train/test splits. For the PSL model, the measures
are computed for joint inference over all topics
in the test sets. For the per-topic linear SVMs
(LOCAL model), we compute the measures indi-
vidually for the predictions of each topic in the
test sets and take a weighted average over the
topics. Our PSL model outperforms the LOCAL
model, with statistically significant improvements
in the F1 score and AUC-PR for the negative class.
Moreover, our model completes weight learning
and inference on the order of seconds, boasting an
advantage in computational efficiency, while also
maintaining model interpretability.
Table 4 shows the weights learned by the PSL
model for the rules in one of the train/test splits
of the experiment. The first two rules relating
post stance and author stance are weighted more
heavily, in part because the writesPost predicate
has a grounding for each author-post pair and con-
tributes to lots of groundings of the rule. The rules
that capture the alternating disagreement stance
also have significant weight, while the rules denot-
ing agreement both between posts and between au-
thors are weighted least heavily since there are far
fewer instances of agreement than disagreement.
This matches our intuition of political debates.
We also explored variations of the PSL model
by removing the first two rules relating post stance
and author stance and found that the weight learn-
ing algorithm drove the weights of the other
rules close to 0, worsening the performance.
We also removed rules 3-10 that capture agree-
ment/disagreement from the model, and found that
the model performs poorly when disregarding the
links between nodes entirely. The PSL model
learns to weight the first and second rule very
highly, and does worse than when considering the
prior alone. Thus, the combination of the rules
gives the model its advantage, allowing the PSL
model to make use of a richer structure that has
multiple types of relations and more information.
5 Related Work
Over the last ten years, there has been significant
progress on modeling stance. Previous work cov-
ers three different debate settings: (1) congres-
sional debates (Thomas et al., 2006; Bansal et
al., 2008; Yessenalina et al., 2010; Balahur et al.,
2009); (2) company-internal discussion sites (Mu-
rakami and Raymond, 2010; Agrawal et al., 2003);
and (3) online social and political public forums
(Somasundaran and Wiebe, 2009; Somasundaran
and Wiebe, 2010; Wang and Ros?e, 2010; Biran
and Rambow, 2011; Walker et al., 2012c; Anand
et al., 2011). Debates in online public forums
(e.g. Fig. 1) differ from debates in congress and
on company discussion sites because the posts are
114
Classifier F1 Score AUC-PR negative class AUROC
LOCAL 0.66 ? 0.015 0.44 ? 0.04 0.54 ? 0.02
PSL 0.74 ? 0.04 0.511 ? 0.04 0.59 ? 0.05
Table 3: Averages and standard deviations for F1 score for the positive class, area under PR curve for the
negative class, and area under ROC curve for post stance over 10 train/test splits.
isProPost(P, T) ? writesPost(A, P) ? isProAuth(A, T) : 10.2
? isProPost(P, T) ? writesPost(A, P) ? ? isProAuth(A, T) : 8.5
agreesPost(P, P2) ? isProPost(P, T) ? isProPost(P2, T) : 0.003
agreesPost(P, P2) ?? isProPost(P, T) ? ? isProPost(P2, T) : 0.003
disagreesPost(P, P2) ? isProPost(P, T) ? ? isProPost(P2, T) : 0.06
disagreesPost(P, P2) ?? isProPost(P, T) ? isProPost(P2, T) : 0.11
agreesAuth(A, A2) ? isProAuth(A, T) ? isProAuth(A, T) : 0.001
agreesAuth(A, A2) ?? isProAuth(A, T) ? ? isProAuth(A2, T) : 0.0
disagreesAuth(A, A2) ? isProAuth(A, T) ? ? isProAuth(A2, T) : 0.23
disagreesAuth(A, A2) ?? isProAuth(A, T) ? isProAuth(A2, T) : 0.6
hasLabelPro(P, T) ? isProPost(P, T) : 2.2
? hasLabelPro(P, T) ? ? isProPost(P, T) : 4.8
Table 4: Weights learned by the model for the PSL rules in train/test split 2 of experiments
shorter and the language is more informal and so-
cial. We predict that this difference makes it more
difficult to achieve accuracies as high for 4FO-
RUMS discussions as can be achieved for the con-
gressional debates corpus.
Work by (Somasundaran and Wiebe, 2009) on
idealogical debates very similar to our own show
that identifying argumentation structure improves
performance; their best performance is approxi-
mately 64% accuracy over all topics. Research by
(Thomas et al., 2006; Bansal et al., 2008; Yesse-
nalina et al., 2010; Balahur et al., 2009) classifies
the speaker?s stance in a corpus of congressional
floor debates. This work combines graph-based
and text-classification approaches to achieve 75%
accuracy on Congressional debate siding over all
topics. Other work applies MaxCut to the re-
ply structure of company discussion forums (Mal-
ouf and Mullen, 2008; Murakami and Raymond,
2010; Agrawal et al., 2003). Murakami & Ray-
mond (2010) show that rules for identifying agree-
ment, defined on the textual content of the post
improve performance.
More recent work has explicitly focused on the
benefits of collective classification in these set-
tings (Burfoot et al., 2011; Hasan and Ng, 2013;
Walker et al., 2012c), and has shown in each
case that collective classification improves perfor-
mance. The results reported here are the first to
apply the PSL collective classification framework
to the forums conversations from the IAC corpus
(Anand et al., 2011; Walker et al., 2012c).
6 Discussion and Future Work
Here, we introduce a novel approach to classify
stance of posts from online debate forums with a
collective classification framework. We formally
construct a model, using PSL, to capture relational
information in the network of authors and posts
and our intuition that agreement or disagreement
between users correlates to their stance towards a
topic. Our initial results are promising, showing
that by incorporating more complex interactions
between authors and posts, we gain improvements
over a content-only approach. Our approach is
ideally suited to collective inference in social me-
dia. It easily extendable to use additional rela-
tional information, and richer behavioral and lin-
guistic information.
Acknowledgments
Thanks to Pranav Anand for providing us with the
stance annotations for the 4forums dataset. This
work is supported by National Science Foundation
under Grant Nos. IIS1218488, CCF0937094 and
CISE-RI 1302668.
115
References
Amjad Abu-Jbara, Mona Diab, Pradeep Dasigi, and
Dragomir Radev. 2012. Subgroup detection in ide-
ological discussions. In Association for Computa-
tional Linguistics (ACL), pages 399?409.
R. Agrawal, S. Rajagopalan, R. Srikant, and Y. Xu.
2003. Mining newsgroups using networks arising
from social behavior. In International Conference
on World Wide Web (WWW), pages 529?535. ACM.
Pranav Anand, Marilyn Walker, Rob Abbott, Jean E.
Fox Tree, Robeson Bowmani, and Michael Minor.
2011. Cats Rule and Dogs Drool: Classifying
Stance in Online Debate. In ACL Workshop on Sen-
timent and Subjectivity.
Stephen H. Bach, Bert Huang, Ben London, and Lise
Getoor. 2013. Hinge-loss markov random fields:
Convex inference for structured prediction. In Un-
certainty in Artificial Intelligence (UAI).
A. Balahur, Z. Kozareva, and A. Montoyo. 2009. De-
termining the polarity and source of opinions ex-
pressed in political debates. Computational Linguis-
tics and Intelligent Text Processing, pages 468?480.
M. Bansal, C. Cardie, and L. Lee. 2008. The power
of negative thinking: Exploiting label disagreement
in the min-cut classification framework. COLING,
pages 13?16.
O. Biran and O. Rambow. 2011. Identifying justifi-
cations in written dialogs. In IEEE International
Conference on Semantic Computing (ICSC), pages
162?168.
Clinton Burfoot, Steven Bird, and Timothy Baldwin.
2011. Collective classification of congressional
floor-debate transcripts. In Association for Compu-
tational Linguistics (ACL), pages 1506?1515.
C. Burfoot. 2008. Using multiple sources of agree-
ment information for sentiment classification of po-
litical transcripts. In Australasian Language Tech-
nology Association Workshop, volume 6, pages 11?
18.
Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-
Rui Wang, and Chih-Jen Lin. 2008. LIBLINEAR:
A library for large linear classification. Journal of
Machine Learning Research, 9:1871?1874.
J.M. Gawron, D. Gupta, K. Stephens, M.H. Tsou,
B. Spitzberg, and L. An. 2012. Using group mem-
bership markers for group identification in web logs.
In AAAI Conference on Weblogs and Social Media
(ICWSM).
Kazi Saidul Hasan and Vincent Ng. 2013. Stance clas-
sification of ideological debates: Data, models, fea-
tures, and constraints. International Joint Confer-
ence on Natural Language Processing.
Angelika Kimmig, Stephen H. Bach, Matthias
Broecheler, Bert Huang, and Lise Getoor. 2012.
A short introduction to probabilistic soft logic.
In NIPS Workshop on Probabilistic Programming:
Foundations and Applications.
R. Malouf and T. Mullen. 2008. Taking sides: User
classification for informal online political discourse.
Internet Research, 18(2):177?190.
Amita Misra and Marilyn A Walker. 2013. Topic in-
dependent identification of agreement and disagree-
ment in social media dialogue. In Conference of the
Special Interest Group on Discourse and Dialogue,
page 920.
A. Murakami and R. Raymond. 2010. Support or Op-
pose? Classifying Positions in Online Debates from
Reply Activities and Opinion Expressions. In Inter-
national Conference on Computational Linguistics
(ACL), pages 869?875.
J. W. Pennebaker, L. E. Francis, and R. J. Booth, 2001.
LIWC: Linguistic Inquiry and Word Count.
Minghui Qiu, Liu Yang, and Jing Jiang. 2013. Mod-
eling interaction features for debate side clustering.
In ACM International Conference on Information &
Knowledge Management (CIKM), pages 873?878.
Prithviraj Sen, Galileo Mark Namata, Mustafa Bilgic,
Lise Getoor, Brian Gallagher, and Tina Eliassi-Rad.
2008. Collective classification in network data. AI
Magazine, 29(3):93?106.
S. Somasundaran and J. Wiebe. 2009. Recogniz-
ing stances in online debates. In ACL and AFNLP,
pages 226?234.
S. Somasundaran and J. Wiebe. 2010. Recognizing
stances in ideological on-line debates. In NAACL
HLT 2010 Workshop on Computational Approaches
to Analysis and Generation of Emotion in Text,
pages 116?124.
M. Thomas, B. Pang, and L. Lee. 2006. Get out the
vote: Determining support or opposition from Con-
gressional floor-debate transcripts. In Conference
on Empirical Methods in Natural Language Pro-
cessing (EMNLP), pages 327?335.
Marilyn Walker, Pranav Anand, Rob Abbott, Jean E.
Fox Tree, Craig Martell, and Joseph King. 2012a.
That?s your evidence?: Classifying stance in online
political debate. Decision Support Sciences.
Marilyn Walker, Pranav Anand, Robert Abbott, and
Jean E. Fox Tree. 2012b. A corpus for research
on deliberation and debate. In Language Resources
and Evaluation Conference, LREC2012.
Marilyn Walker, Pranav Anand, Robert Abbott, and
Richard Grant. 2012c. Stance classification using
dialogic properties of persuasion. In Meeting of the
North American Association for Computational Lin-
guistics. NAACL-HLT12.
116
Y.C. Wang and C.P. Ros?e. 2010. Making conversa-
tional structure explicit: identification of initiation-
response pairs within online discussions. In Human
Language Technologies: The 2010 Annual Confer-
ence of the North American Chapter of the Associa-
tion for Computational Linguistics, pages 673?676.
A. Yessenalina, Y. Yue, and C. Cardie. 2010.
Multi-level structured models for document-level
sentiment classification. In Conference on Em-
pirical Methods in Natural Language Processing
(EMNLP), pages 1046?1056.
117
