Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 929?936,
Sydney, July 2006. c?2006 Association for Computational Linguistics
Word Sense Disambiguation using lexical cohesion in the context 
Dongqiang Yang | David M.W. Powers 
School of Informatics and Engineering 
Flinders University of South Australia  
PO Box 2100, Adelaide 
Dongqiang.Yang|David.Powers@flinders.edu.au 
  
  
 
Abstract 
This paper designs a novel lexical hub to 
disambiguate word sense, using both syn-
tagmatic and paradigmatic relations of 
words. It only employs the semantic net-
work of WordNet to calculate word simi-
larity, and the Edinburgh Association 
Thesaurus (EAT) to transform contextual 
space for computing syntagmatic and 
other domain relations with the target 
word. Without any back-off policy the 
result on the English lexical sample of 
SENSEVAL-21 shows that lexical cohe-
sion based on edge-counting techniques 
is a good way of unsupervisedly disam-
biguating senses.  
1 Introduction 
Word Sense Disambiguation (WSD) is generally 
taken as an intermediate task like part-of-speech 
(POS) tagging in natural language processing, 
but it has not so far achieved the sufficient preci-
sion for application as POS tagging (for the his-
tory of WSD, cf. Ide and V?ronis (1998)). It is 
partly due to the nature of its complexity and 
difficulty, and to the widespread disagreement 
and controversy on its necessity in language en-
gineering, and to the representation of the senses 
of words, as well as to the validity of its evalua-
tion (Kilgarriff and Palmer, 2000). However the 
endeavour to automatically achieve WSD has 
been continuous since the earliest work of the 
1950?s. 
In this paper we specifically investigate the 
role of semantic hierarchies of lexical knowledge 
on WSD, using datasets and evaluation methods 
from SENSEVAL (Kilgarriff and Rosenzweig, 
                                                 
1 http://www.senseval.org/ 
2000) as these are well known and accepted in 
the community of computational linguistics.  
With respect to whether or not they employ 
the training materials provided, SENSEVAL 
roughly categorizes the participating systems 
into ?unsupervised systems? and ?supervised 
systems?. Those that don?t use the training data 
are not usually truly unsupervised, being based 
on lexical knowledge bases such as dictionaries, 
thesauri or semantic nets to discriminate word 
senses; conversely the ?supervised? systems 
learn from corpora marked up with word senses.  
The fundamental assumption, in our ?unsu-
pervised? technique for WSD in this paper, is 
that the similarity of contextual features of the 
target with the pre-defined features of its sense in 
the lexical knowledge base provides a quantita-
tive cue for identifying the true sense of the tar-
get. 
The lexical ambiguity of polysemy and ho-
monymy, whose distinction is however not abso-
lute as sometimes the senses of word may be in-
termediate, is the main object of WSD. Verbs, 
with their more flexible roles in a sentence, tend 
to be more polysemous than nouns, so worsening 
the computational feasibility. In this paper we 
disambiguated the sense of a word after its POS 
tagging has assigned them either a noun or a verb 
tag. Furthermore, we deal with nouns and verbs 
separately.  
2 Some previous work on WSD using 
semantic similarity 
Sussna (1993) utilized the semantic network of 
nouns in WordNet to disambiguate term senses 
to improve the precision of SMART information 
retrieval at the stage of indexing, in which he 
assigned two different weights for both direc-
tions of edges in the network to compute the 
similarity of two nodes. He then exploited the 
moving fixed size window to minimize the sum 
929
of all combinations of the shortest distances 
among target and context words.  
Pedersen et al (2003) extended Lesk?s defini-
tion method (1986) to discriminate word sense 
through the definitions of both target and its IS-A 
relatives, and achieved a better result in the Eng-
lish lexical sample task of SENSEVAL-2, com-
pared with other edge-counting or statistical es-
timation metrics on WordNet. 
Humans carefully select words in a sentence to 
express harmony or cohesion in order to ease the 
ambiguity of the sentence. Halliday and Hasan 
(1976) argued that cohesive chains unite text 
structure together through reiteration of reference 
and lexical semantic relations (superordinate and 
subordinate). Morris and Hirst (1991) suggested 
building lexical chains is important in the resolu-
tion of lexical ambiguity and the determination 
of coherence and discourse structure. They ar-
gued that lexical chains, which cover the multi-
ple semantic relations (systematic and non-
systematic), can transform the context setting 
into the computational one to narrow down the 
specific meaning of the target, manually realiz-
ing this with the help of Roget?s Thesaurus. They 
defined a lexical chain within Roget?s very gen-
eral hierarchy, in which lexical relationships are 
traced through a common category.  
Hirst and St-Onge (1997) define a lexical 
chain using the syn/antonym and hyper/hyponym 
links of WordNet to detect and correct malaprop-
isms in context, in which they specified three 
different weights from extra-strong to medium 
strong to score word similarity to decide the in-
serting sequence in the lexical chain. They first 
computationally employed WordNet to form a 
?greedy? lexical chain as a substitute of the con-
text to solve the matter of malapropism, where 
the word sense is decided by its preceding words.  
 Around the same time, Barzilay and Elhadad 
(1997) realized a ?non-greedy? lexical chain, 
which determined the word sense after process-
ing of all words, in the context of text summari-
zation.   
In this paper we propose an improved lexical 
chain, the lexical hub, that holds the target to be 
disambiguated as the centre, replacing the usual 
chain topology used in text summarization and 
cohesion analysis. In contrast with previous 
methods we only record the lexical hub of each 
sense of the target, and we don?t keep track of 
other context words. In other words, after the 
computation of lexical hub of the target, we can 
immediately produce the right sense of the target 
even though the senses of the context words are 
still in question. We also transform the context 
surroundings through a word association thesau-
rus to explore the effect of other semantic rela-
tionships such as syntagmatic relation against 
WSD.  
3 Selection of knowledge bases 
WordNet (Fellbaum, 1998) provides a fine-
grained enumerative semantic net that is com-
monly used to tag the instances of English target 
words in the tasks of SENSEVAL with different 
senses (WordNet synset numbers). WordNet 
groups related concepts into synsets and links 
them through IS-A and PART-OF links, empha-
sizing the vertical interaction between the con-
cepts that is much paradigmatic.  
Although WordNet can capture the fine-
grained paradigmatic relations of words, another 
typical word relationship, syntagmatic connect-
edness, is neglected. The syntagmatic relation-
ship, which is often characterized with different 
POS tag, and frequently occurs in corpora or 
human brains, plays a critical part in cross-
connecting words from different domains or POS 
tags.  
It should be noted that WordNet 2.0 makes 
some efforts to interrelate nouns and verbs using 
their derived lexical forms, placing associated 
words under the same domain. Although some 
verbs have derived noun forms that can be 
mapped onto the noun taxonomy, this mapping 
only relates the morphological forms of verbs, 
and still lacks syntagmatic links between words.  
The interrelationship of noun and verb hierar-
chies is far from complete and only a supplement 
to the primary IS-A and PART-OF taxonomies 
in WordNet. Moreover as WordNet generally 
concerns the paradigmatic relations (Fellbaum, 
1998), we have to seek for other lexical knowl-
edge sources to compensate for the shortcomings 
of WordNet in WSD.   
The Edinburgh Association Thesaurus2 (EAT) 
provides an associative network to account for 
word relationship in human cognition after col-
lecting the first response words for the stimulus 
words list (Kiss et al, 1973).  Take the words eat 
and food for example. There is no direct path 
between the concepts of these two words in the 
taxonomy of WordNet (both as noun and verb), 
except in the gloss of the first and third sense of 
eat to explain ?take in solid food?, or ?take in 
food?, which glosses are not regularly or care-
                                                 
2 http://www.eat.rl.ac.uk/ 
930
fully organized in WordNet. However in EAT 
eat is strongly associated with food, and when 
taking eat as a stimulus word, 45 out of 100 sub-
jects regarded food as the first response.  
Yarowsky (1993) indicated that the objects of 
verbs play a more dominant role than their sub-
jects in WSD and nouns acquire more stable dis-
ambiguating information from their noun or ad-
jective modifiers.  
In the case of verbs association tests, it is also 
reported that more than half the response words 
of verbs (the stimuli) are syntagmatically related 
(Fellbaum, 1998). In experiments of examining 
the psychological plausibility of WordNet 
relationships, Chaffin et al (1994) stated that 
only 30.4% of the responses of 75 verb stimuli 
belongs to verbs, and more than half of the re-
sponses are nouns, of which nearly 90% are 
categorized as the arguments of the verbs.  
Sinopalnikova (2004) also reported that there 
are multiple relationships found in word associa-
tion thesaurus, such as syntagmatic, paradigmatic 
relations, domain information etc.  
In this paper we only use the straightforward 
forms of context words separating the effect of 
syntactic dependence on the WSD. As a supple-
ment of enriching word linkage in the WSD, we 
retrieve the lexical knowledge from both Word-
Net and EAT. We first explore the function of 
semantic hierarchies of WordNet on WSD, and 
then we transform the context word with EAT to 
investigate whether other relationships can im-
prove WSD. 
4 System design 
In order to find semantically related words to 
cohesively form lexical hubs, we first employ the 
two word similarity algorithms of Yang and 
Powers (2005; 2006) that use WordNet to com-
pute noun similarity and verb similarity respec-
tively. We next construct the lexical hub for each 
target sense to assemble the similarity score be-
tween the target and its context words together. 
The maximum score of these lexical hubs spe-
cifically predicts the real sense of the target, also 
implicitly captures the cohesion and real mean-
ing of the word in its context.  
4.1 Similarity metrics on nouns  
Yang and Powers (2005) designed a metric, 
??? *)2,1( tccSim =  
utilizing both IS-A and PART-OF taxonomies of 
WordNet to measure noun similarity, and they 
argued that the similarity of nouns is the maxi-
mum of all their concept similarities. They de-
fined the similarity (Sim) of two concepts (c1 and 
c2) with a link type factor (?t) to specify the 
weights of different link types (t) (syn/antonym, 
hyper/ hyponym, and holo/meronym) in the 
WordNet, and a path type factor (?t) to reduce 
the uniform distance of the single link, along 
with a depth factor (?) to restrict the maximum 
searching distance between concepts. Since their 
metric on noun similarity is significantly better 
than some popular measures and even outper-
forms some subjects on a standard data set, we 
selected it as a measure on noun similarity in our 
WSD task. 
4.2 Similarity metrics on verbs  
Yang and Powers (2006) also redesigned their 
noun model, 
it
ccDist
i
tstrccSim ???
)2,1(
1
**)2,1(
=
?=  
to accommodate verb case, which is harder to 
deal with in the shallow and incomplete taxon-
omy of verbs in WordNet. As an enhancement to 
the uniqueness of verb similarity they also con-
sider three fall-back factors, where if ?str is 1 
normally but successively falls back to: 
? ?stm: the verb stem polysemy ignoring sense 
and form 
? ?der: the cognate noun hierarchy of the verb  
? ?gls: the definition of the verb 
They also defined two alternate search proto-
cols: rich hierarchy exploration (RHE) with no 
more than six links and shallow hierarchy explo-
ration (SHE) with no more than two links.  
One minor improvement to the verb model in 
their system comes from comparing the similar-
ity of verbs and nouns using the noun model 
metric for the derived noun form of verb. It thus 
allows us to compare nouns and verbs and avoids 
the limitation of having to have the same POS 
tag. 
4.3 Depth in WordNet 
Yang and Powers fine-tuned the parameters of 
the noun and verb similarity models, finding 
them relatively insensitive to the precise values, 
and we have elected to use their recommended 
values for the WSD task. But it is worth 
mentioning that their optimal models are 
achieved in purely verbal data sets, i.e. the 
similarity score is context-free.  
931
In their models, the depth in the WordNet, i.e. 
the distance between the synsets of words (?), is 
indeed an outside factor which confines the 
searching scope to the cost of computation and 
depends on the different applications. If we tuned 
it using the training data set of SENSEVAL-2 we 
probably would assign different values and might 
achieve better results. Note that for both nouns 
and verbs we employ RHE (rich hierarchy explo-
ration) with ? = 2 making full use of the taxon-
omy of WordNet and making no use of glosses. 
4.4 How to setup the selection standard for 
the senses 
Other than making the most of WSD results, our 
main motive for this paper is to explore to what 
extent the semantic relationships will reach accu-
racy, and to fully acknowledge the contribution 
of this single attribute working on WSD, which 
is encouraged by SENSEVAL in order to gain 
further benefits in this field (Kilgarriff and 
Palmer, 2000). Without any definition, which is 
previously surveyed by Lesk (1986) and Peder-
sen et al (2003), we screen off the definition fac-
tor in the metric of verb similarity, with the in-
tention of focusing on the taxonomies of Word-
Net. 
Assuming that the lexical hub for the right 
sense would maximize the cohesion with other 
words in the discourse, we design six different 
strategies to calculate the lexical hub in its unor-
dered contextual surroundings.  
We first put forward three metrics to measure 
up the similarity of the senses of the target and 
the context word: 
? The maximized sense similarity 
( )),(max),( , jikjikmax CTSimCTSim =  
where T denotes the target, Tk is the kth 
sense of the target; Ci is the ith context word 
in a fixed window size around the target, Ci,j 
the jth sense of Ci. Note that T and C can be 
any noun and verb, along with Sim the met-
rics of Yang and Powers. 
? The average of sense similarity 
? ?
= =
=
m
j
m
j
jikjikikave CTLinksCTSimCTSim
1 1
,, ),(),(),(
where Links(Tk,Ci,j)=1, if Sim(Tk,Ci,j)>0, oth-
erwise 0. 
? The sum of sense similarity 
?
=
=
m
j
jikiksum CTSimCTSim
1
, ),(),(  
where m is the total sense number of Ci. 
Subsequently we can define six distinctive 
heuristics to score the lexical hub in the follow-
ing parts: 
? Heuristic 1 ? Sense Norm  (HSN) 
???
?
???
?= ? ?
= =
l
i
l
i
ikikmax
k
CTLinkwCTSimTSense
1 1
),(),(maxarg)(
where Linkw(Ti)=1 if Simmax(Tk,Ci)>0, oth-
erwise 0 
? Heuristic 2 ? Sense Max (HSM) 
An unnormalized version of HSN is: 
???
?
???
?= ?
=
l
i
ikmax
k
CTSimTSense
1
),(maxarg)(  
? Heuristic 3 ? Sense Ave (HSA) 
Taking into account all of the links between 
the target and its context word, the correct 
sense of the target is: 
???
?
???
?= ?
=
l
i
ikave
k
CTSimTSense
1
),(maxarg)(  
? Heuristic 4 ? Sense Sum (HSS) 
The unnormalized version of HSA is: 
???
?
???
?= ?
=
l
i
iksum
k
CTSimTSense
1
),(maxarg)(  
? Heuristic 5 ? Word Linkage (HWL) 
The straightforward output of the correct 
sense of the target in the discourse is to count 
the maximum number of context words 
whose similarity scores with the target are 
larger than zero:  
???
?
???
?= ?
=
l
i
ik
k
CTLinkwTSense
1
),(maxarg)(  
? Heuristic 6 ? Sense Linkage (HSL) 
No matter what kind of relations between the 
target and its context are, the sense of the 
target, which is related to the maximum 
counts of senses of all its context words, is 
scored as the right meaning:  
???
?
???
?= ??
= =
l
i
m
j
jik
k
CTLinksTSense
1 1
, ),(maxarg)(  
Therefore the lexical hub of each sense of the 
target only relies on the interaction of the target 
and its each context word, rather than of the con-
text words. The implication is that the lexical 
hub only disambiguates the real sense of the tar-
932
get other than the real meaning of the context 
word; the maximum scores or link numbers (on 
the level of words or senses) in the six heuristics 
suggest that the correct sense of the target should 
cohere with as many words or their senses as 
practicable in the discourse.  
When similarity scores are ties we directly 
produce all of the word senses to prevent us from 
guessing results. Some WSD systems in SEN-
SEVAL handle tied scores simply using the first 
sense (in WordNet) of the target as the real 
sense. It is no doubt that the skewed distribution 
of word senses in the corpora (the first sense of-
ten captures the dominant sense) can benefit the 
performance of the systems, but at the same time 
it mixes up the contribution of the semantic hier-
archy on WSD in our system.  
5 Results 
We evaluate the six heuristics on the English 
lexical sample of SENSEVAL-2, in which each 
target word has been POS-tagged in the training 
part. With the absence of taxonomy of adjectives 
in WordNet we only extract all 29 nouns and all 
29 verbs from a total of 73 lexical targets, and 
then we subcategorize the test dataset into 1754 
noun instances and 1806 verb instances. Since 
the sample of SENSEVAL-2 is manually sense-
tagged with the sense number of WordNet 1.7 
and our metrics are based on its version 2.0, we 
translate the sample and answer format into 2.0 
in accordance with the system output format.  
Finally, we find that each noun target has 5.3 
senses on average and each verb target 16.4 
senses. Hence the baseline of random selection 
of senses is the reciprocal of each average sense 
number, i.e. separately 18.9 percent for nouns 
and 6 percent for verbs. 
In addition, SENSEVAL-2 provides a scoring 
software with 3 levels of schemes, i.e. fine-
grained, coarse-grained and mixed-grained to 
produce precision and recall rates to evaluate the 
participating systems. According to the SEN-
SEVAL scoring system, as we always give at 
least one answer, the precision is identical to the 
recall under the separate noun and verb datasets. 
So we just evaluate our systems in light of accu-
racy. We tested the heuristics with fine-grained 
precision, which required the exact match of the 
key to each instance. 
5.1 Context 
Without any knowledge of domain, frequency 
and pragmatics to guess, word context is the only 
way of labeling the real meaning of word. Basi-
cally a bag of context words (after morphological 
analyzing and filtering stop-words) or the fine-
grained ones (syntactic role, selection preference 
etc.) can provide cues for the target. We propose 
to merely use a bag of words to feed into each 
heuristic in case of losing any valuable informa-
tion in the disambiguation, and preventing from 
any interference of other clues except the seman-
tic hierarchy of WordNet. 
The size of the context is not a definitive fac-
tor in WSD, Yarowsky (1993) suggested the size 
of 3 or 4 words for the local ambiguity and 20/50 
words for topic ambiguity. He also employed 
Roget?s Thesaurus in 100 words of window to 
implement WSD (Yarowsky, 1992). To investi-
gate the role of local context and topic context 
we vary the size of window from one word dis-
tance away to the target (left and right) until 100 
words away in nouns or 60 in verbs, until there 
are no increases in the context of each instance.  
0.25
0.27
0.29
0.31
0.33
0.35
0.37
0.39
0.41
0.43
0.45
2 5 10 20 30 40 50 60 70 80 90 100
context
ac
cu
ra
cy
HSN
HSM
HSA
HSS
HWL
HSL
 
Figure 1: the result of noun disambiguation with 
different size of context in SENSEVAL 2 
0.05
0.07
0.09
0.11
0.13
0.15
0.17
0.19
0.21
0.23
0.25
0.27
0.29
0.31
0.33
0.35
0.37
1 2 3 4 5 10 20 30 40 50 60
context
a
c
c
u
ra
c
y
HSN
HSM
HSA
HSS
HWL
HSL
 
Figure 2: the result of verb disambiguation with 
different size of context in SENSEVAL 2 
Noun and verb disambiguation results are re-
spectively displayed in Figure 1 and 2. Since the 
performance curves of the heuristics turned into 
flat and stable (the average standard deviations 
of the six curves of nouns and verbs is around 
0.02 level before 60 and 20, after that approxi-
933
mately 0.001 level), optimal performance is 
reached at 60 context words for nouns and 20 
words for verbs. These values are used as pa-
rameters in subsequent experiments. 
5.2 Transformed context (EAT) 
0.25
0.27
0.29
0.31
0.33
0.35
0.37
0.39
0.41
0.43
0.45
0.47
context srandrs sr rs srorrs
different contexts
a
c
c
u
ra
c
y
HSN
HSM
HSA
HSS
HWL
HSL
 
Figure 3: the results of nouns disambiguation of 
SENSEVAL-2 in the transformed context spaces 
0.05
0.07
0.09
0.11
0.13
0.15
0.17
0.19
0.21
0.23
0.25
0.27
0.29
0.31
0.33
0.35
0.37
0.39
context srandrs sr rs srorrs
different contexts
a
c
c
u
ra
c
y
HSN
HSM
HSA
HSS
HWL
HSL
 
Figure 4: the results of verbs disambiguation 
of SENSEVAL-2 in the transformed context 
spaces 
Although our metrics can measure the similarity 
of nouns and verbs through the derived related 
form of verbs (not from the derived verbs of 
nouns as a consequence of the shallowness of 
verb taxonomy of WordNet), we still can?t com-
pletely rely on WordNet, which focuses on the 
paradigmatic relations of words, to fully cover 
the complexity of contextual happenings of 
words.  
Since the word association norm captures both 
syntagmatic and pragmatic relations in words, 
we transform the context words of the target into 
its associated words, which can be retrieved in 
the EAT, to augment the performance of the 
lexical hub. 
There are two word lists in the EAT: one list 
takes each head word as a stimulus word, and 
then collects and ranks all response words ac-
cording to their frequency of subject consensus; 
the other list is in the reverse order with the re-
sponse as a head word and followed by the elicit-
ing stimuli. We denote the stimulus/response set 
of word as SR, respond/stimulus as RS. Apart 
from that we symbolize SRANDRS as the 
intersection of SR and RS, along with SRORRS 
as the union set of SR and RS. Then for each 
context word we retrieve its corresponding words 
in each word list and calculate the similarity be-
tween the target and these words including the 
context words.  
As a result we transform the original context 
space of each target into an enriched context 
space under the function of SR, RS, SRANDRS 
or SRORRS.  
We take the respective 60 context words of 
nouns and 20 words of verbs as the reference 
points for the transferred context experiment, 
since after that the performance curves of the 
heuristics turned into flat and stable (the average 
standard deviations of the six curves of nouns 
and verbs is around 0.02 level before 60, after 
that approximately 0.001 level).  
After the transformations, the noun and verb 
results are respectively demonstrated in Figure 3 
and 4. 
6 Comparison with other techniques. 
0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5
Baseline Random
Baseline Lesk
Baseline Lesk Def
J&C
P&L_vector
P&L_extend
HWL_Context
HSL_Context
UNED-LS-U
DIMAP
IIT 1
IIT 2
HWL_SRORRS
HSL_SRORRS
accuracy
noun
verb
 
Figure 5: comparisons of HWL and HSL with 
other unsupervised systems and similarity met-
rics 
 
Pedersen et al (2003) in the work of evaluating 
different similarity techniques based on Word-
Net, realized two variants of Lesk?s methods: 
extended gloss overlaps (P&L_extend) and gloss 
vector (P&L_vector), as well as evaluating them 
in the English lexical sample of SENSEVAL-2. 
The best edge-counting-based metric that they 
measured are from Jiang and Conrath (1997) 
(J&C). 
934
Accordingly, without the transformation of 
EAT, we compare our results of HWL and HSL 
(denoted as HWL_Context and HSL_Context) 
with the above methods (picking up their optimal 
values). The results are illustrated in Figure 5. At 
the same time we also list three baselines for un-
supervised systems (Kilgarriff and Rosenzweig, 
2000), which are Baseline Random (randomly 
selecting one sense of the target), Baseline Lesk 
(overlapping between the examples and defini-
tions of and unsupervised systems in SEN-
SEVAL-2 each sense of the target and context 
words), and its reduced version, i.e. Baseline 
Lesk Def (only definition). 
We further compare HWL and HSL with the 
intervention of SRORRS of EAT (denoted as 
HWL_SRORRS and HSL_ SRORRS) with other 
unsupervised systems that employ no training 
materials of SENSEVAL-2, which are respec-
tively:  
? IIT 1 and IIT 2: extended the WordNet gloss 
of each sense of the target, along with its su-
perordinate and subordinate node?s glosses, 
without back-off policies. 
? DIMAP: employed both WordNet and the 
New Oxford Dictionary of English. With the 
first sense as a back-off when tied scores oc-
curred. 
? UNED-LS-U: for each sense of the target, 
they enriched the sense describer through the 
first five hyponyms of it and a dictionary 
built from 3200 books from Project Guten-
berg. They adopted a back-off policy to the 
first sense and discarded the senses account-
ing for less than 10 percent of files in Sem-
Cor). 
7 Conclusion and discussion 
7.1 Local context and topic context  
On the analysis of standard deviation of preci-
sion on different stage in Figure 1 and 2 we can 
conclude that the optimum size for HSN to HSS 
was ?10 words for nouns, reflecting a sensitivity 
to only local context, whilst HWL and HSL re-
flected significant improvement up to ?60 re-
flecting a sensitivity to topical context. In the 
case of verbs HSA showed little significant con-
text sensitivity, HSN showed some positive sen-
sitivity to local context but increasing beyond ?5 
had a negative effect, HSM and HSS to HSL 
showed some sensitivity to broader topical con-
text but this plateaued around ?20 to 30.  
7.2 The analysis of different heuristics. 
HWL and HSL were clearly superior for both 
noun and verb tasks, with the superiority of HSL 
being significantly greater and more comparable 
between noun and verb tasks with the difference 
scarcely reaching significance. These observa-
tions remain true with the addition of the EAT 
information. After transformations with EAT for 
nouns, HSL and HWL no longer differ signifi-
cantly in performance, forming a single group 
with relatively higher precision, whilst the other 
heuristics clump together into another group with 
lower precision, reflecting a negative effect from 
EAT. In the verb case, HWL and HSL, HSM and 
HSS, and HSN and HSA form three significantly 
different groups with reference to their precision, 
reflecting poor performance of both normalized 
heuristics (HSN and HSA) and a significantly 
improved result of HWL from the EAT data.  
All of this implies that in the lexical hub for 
WSD, the correct meaning of a word should hold 
as many links as possible with a relatively large 
number of context words. These links can be in 
the level of word form (HWL) or word sense 
(HSL). HSL achieved the highest precision in 
both nouns and verbs.  
7.3 The interaction of EAT in WSD 
For the noun sense disambiguation, the paired 
two sample for mean of the t-Test showed us that 
RS and SRORRS transformations can signifi-
cantly improve the precision of disambiguation 
of HWL and HSL (P<0.05, at the confidence 
level of 95 percent). All four transformations 
using EAT for verb disambiguation are signifi-
cantly better than its straightforward context case 
on HWL and HSL (P<0.05, at the confidence 
level of 95 percent). 
It demonstrated that both the syntagmatic rela-
tion and other domain information in the EAT 
can help discriminate word sense. With the trans-
formation of context surroundings of the target, 
the similarity metrics can compare the likeness 
of nouns and verbs, although we can exploit the 
derived form of word in WordNet to facilitate the 
comparison. 
7.4 Comparison with other methods 
The lexical hub reached comparatively higher 
precision in both nouns (45.8%) and verbs 
(35.6%). This contrasted with other similarity 
based methods and the unsupervised systems in 
SENSEVAL-2. Note that we don?t adopt any 
935
back-off policy such as the commonest sense of 
word used by UNED-LS-U and DIMAP. 
Although the noun and verb similarity metrics 
in this paper are based on edge-counting without 
any aid of frequency information from corpora, 
they performed very well in the task of WSD in 
relation to other information based metrics and 
definition matching methods. Especially in the 
verb case, the metric significantly outperformed 
other metrics. 
8 Conclusion and future work 
In this paper we defined the lexical hub and pro-
posed its use for processing word sense disam-
biguation, achieving results that are compara-
tively better than most unsupervised systems of 
SENSEVAL-2 in the literature. Since WordNet 
only organizes the paradigmatic relations of 
words, unlike previous methods, which are only 
based on WordNet, we fed the syntagmatic rela-
tions of words from the EAT into the noun and 
verb similarity metrics, and significantly im-
proved the results of WSD, given that no back-
off was applied. Moreover, we only utilized the 
unordered raw context information without any 
pragmatic knowledge and syntactic information; 
there is still a lot of work to fuse them in the fu-
ture research. In terms of the heuristics evaluated, 
richness of sense or word connectivity is much 
more important than the strength of individual 
word or sense linkages. An interesting question 
is whether these results will be borne out in other 
datasets. In the forthcoming work we will inves-
tigate their validity in the lexical task of SEN-
SEVAL-3. 
References 
Barzilay, R. and M. Elhadad (1997). Using Lexical 
Chains for Text Summarization. In the Intelligent 
Scalable Text Summarization  Workshop (ISTS'97), 
ACL, Madrid, Spain. 
Chaffin, R., et al (1994). The Paradigmatic Organiza-
tion of Verbs in the Mental Lexicon. Trenton State 
College. 
Fellbaum, C. (1998). Wordnet: An Electronic Lexical 
Database. Cambridge MA, USA, The MIT Press. 
Halliday, M. A. K. and R. Hasan (1976). Cohesion in 
English. London, London:Longman. 
Hirst, G. and D. St-Onge (1997). Lexical Chains as 
Representations of Context for the Detection and 
Correction of Malapropisms. Wordnet. C. Fell-
baum. Cambridge, MA, The Mit Press. 
Ide, N. and J. V?ronis (1998). Word Sense Disam-
biguation: The State of the Art. Computational lin-
guistics 24(1). 
Jiang, J. and D. Conrath (1997). Semantic Similarity 
Based on Corpus Statistics and Lexical Taxonomy. 
In the 10th International Conference on Research 
in Computational Linguistics (ROCLING), Taiwan. 
Kilgarriff, A. and M. Palmer (2000). Introduction, 
Special Issue on Senseval: Evaluating Word Sense 
Disambiguation Programs. Computers and the 
Humanities 34(1-2): 1-13. 
Kilgarriff, A. and J. Rosenzweig (2000). Framework 
and Results for English Senseval. Computers and 
the Humanities 34(1-2): 15-48. 
Kiss, G. R., et al (1973). The Associative Thesaurus 
of English and Its Computer Analysis. Edinburgh, 
University Press. 
Lesk, M. (1986). Automatic Sense Disambiguation 
Using Machine Readable Dictionaries: How to Tell 
a Pine Code from an Ice Cream Cone. In the 5th 
annual international conference on systems docu-
mentation, ACM Press. 
Morris, J. and G. Hirst (1991). Lexical Cohesion 
Computed by Thesaural Relations as an Indicator 
of the Structure of Text. Computational linguistics 
17(1). 
Pedersen, T., et al (2003). Maximizing Semantic Re-
latedness to Perform Word Sense Disambiguation. 
Sinopalnikova, A. (2004). Word Association Thesau-
rus as a Resource for Building Wordnet. In GWC 
2004. 
Sussna, M. (1993). Word Sense Disambiguation for 
Free-Text Indexing Using a Massive Semantic 
Network. In CKIM'93. 
Yang, D. and D. M. W. Powers (2005). Measuring 
Semantic Similarity in the Taxonomy of Wordnet. 
In the Twenty-Eighth Australasian Computer Sci-
ence Conference (ACSC2005), Newcastle, Austra-
lia, ACS. 
Yang, D. and D. M. W. Powers (2006). Verb Similar-
ity on the Taxonomy of Wordnet. In the 3rd Inter-
national WordNet Conference (GWC-06), Jeju Is-
land, Korea. 
Yarowsky, D. (1992). Word Sense Disambiguation 
Using Statistical Models of Roget's Categories 
Trained on Large Corpora. In the 14th International 
Conference on Computational Linguistics, Nates, 
France. 
Yarowsky, D. (1993). One Sense Per Collocation. In 
ARPA Human Language Technology Workshop, 
Princeton, New Jersey. 
  
936
Adaptive Compression-based Approach for Chinese Pinyin Input
Jin Hu Huang and David Powers
School of Informatics and Engineering
Flinders University of South Australia
GPO Box 2100, SA 5001
Australia
{jin.huang,powers}@infoeng.flinders.edu.au
Abstract
This article presents a compression-based adap-
tive algorithm for Chinese Pinyin input. There
are many different input methods for Chinese
character text and the phonetic Pinyin in-
put method is the one most commonly used.
Compression by Partial Match (PPM) is an
adaptive statistical modelling technique that
is widely used in the field of text compres-
sion. Compression-based approaches are able to
build models very efficiently and incrementally.
Experiments show that adaptive compression-
based approach for Pinyin input outperforms
modified Kneser-Ney smoothing method im-
plemented by SRILM language tools (Stolcke,
2002).
1 Introduction
Chinese words comprise ideographic and picto-
graphic characters. Unlike English, these char-
acters can?t be entered by keyboard directly.
They have to be transliterated from keyboard
input based on different input methods. There
are two main approaches: phonetic-based input
methods such as Pinyin input and structure-
based input methods such as WBZX. Pinyin
input is the easiest to learn and most widely
used. WBZX is more difficult as the user has to
remember all the radical parts of each character,
but it is faster.
Early products using Pinyin input methods
are very slow because of the large number of
homonyms in the Chinese language. The user
has to choose the correct character after each
Pinyin has been entered. The situation in cur-
rent products such as Microsoft IME for Chi-
nese and Chinese Star has been improved with
the progress in language modelling (Goodman,
2001) but users are still not satisfied.
2 Statistical Language Modelling
Statistical language modelling has been success-
fully applied to Chinese Pinyin input (Gao et
al., 2002). The task of statistical language mod-
elling is to determine the probability of a se-
quence of words.
P (w1 . . . wi) = P (w1)?P (w2|w1)?? ? ??P (wi|w1 . . . wi?1)
(1)
Given the previous i-1 words, it is difficult to
compute the conditional probability if i is very
large. An n-gram Markov model approximates
this probability by assuming that only words
relevant to predict are previous n-1 words. The
most commonly used is trigram.
P (wi|w1 . . . wi?1) ? P (wi|wi?2wi?1) (2)
The key difficulty with using n-gram language
models is that of data sparsity. One can never
have enough training data to cover all the n-
grams. Therefore some mechanism for assigning
non-zero probability to novel n-grams is a key
issue in statistical language modelling. Smooth-
ing is used to adjust the probabilities and
make distributions more uniform. Chen and
Goodman (Chen and Goodman, 1999) made a
complete comparison of most smoothing tech-
niques and found that the modified Kneser-Ney
smoothing(equation 3) outperformed others.
pKN (wi|w
i?1
i?n+1) =
c(wi?1i?n+1)?D(c(w
i?1
i?n+1))
?
wi c(w
i?1
i?n+1)
+?(wi?1i?n+1)pKN (wi|w
i?1
i?n+2) (3)
where
D(c) =
?
???
???
0 if c = 0
D1 if c = 1
D2 if c = 2
D3+ if c ? 3
?(wi?1i?n+1) =
D1N1(w
i?1
i?n+1?)+D2N2(w
i?1
i?n+1?)+D3+N3+(w
i?1
i?n+1?)?
wi
c(wi?1i?n+1)
(4)
N1(w
i?1
i?n+1?) = | {wi : c(w
i?1
i?n+1wi) = 1} |(5)
Y =
n1
n1 + 2n2
D1 = 1? 2Y
n2
n1
D2 = 1? 3Y
n3
n2
D3+ = 1? 4Y
n4
n3
(6)
The process of Pinyin input can be formu-
lated as follows.
W = argmax
W
Pr(W |A) (7)
W = argmax
W
Pr(A|W ) Pr(W ) (8)
We assume each Chinese character has only
one pronunciation in our experiments.
Thus we can use the Viterbi algorithm to find
the word sequences to maximize the language
model according to Pinyin input.
3 Prediction by Partial Matching
Prediction by Partial Matching (PPM)(Cleary
and Witten, 1984; Bell et al, 1990) is a symbol-
wise compression scheme for adaptive text com-
pression. PPM generates a prediction for each
input character based on its preceding char-
acters. The prediction is encoded in form of
conditional probability, conditioned on previous
context. PPM maintains predictions, computed
from the training data, for larger context as well
as all shorter con-texts. If PPM cannot pre-
dict the character from current context, it uses
an escape probability to ?escape? another con-
text model, usually of length one shorter than
the current context. For novel characters that
have never seen before in any length model, the
algorithm escapes down to a default ?order-1?
context model where all possible characters are
present.
PPM escape method can be considered as an
instance of Jelinek-Mercer smoothing. It is de-
fined recursively as a linear interpolation be-
tween the nth-order maximum likelihood and
the (n-1)th-order smoothed model. Various
methods have been proposed for estimating the
escape probability. In the following description
of each method, e is the escape probability and
p(?) is the conditional probability for symbol ?
, given a context. c(?) is the number of times
the context was followed by the symbol ? . n
is the number of tokens that have followed. t is
the number of types.
Method A works by allocating a count of one
to the escape symbol.
e =
1
n+ 1
(9)
p(?) =
c(?)
n+ 1
(10)
Method B makes assumption that the first
occurrence of a particular symbol in a particu-
lar context may be taken as evidence of a novel
symbol appearing in the context, and therefore
does not contribute towards the estimate of the
probability of the symbol which it occurred.
e =
t
n
(11)
p(?) =
c(?)? 1
n
(12)
Method C (Moffat, 1990) is similar to Method
B, with the distinction that the first observation
of a particular symbol in a particular symbol
in a particular context also contributes to the
probability estimate of the symbol itself. Es-
cape method C is called Witten-Bell smooth-
ing in statistical language modelling. Chen and
Goodman (Chen and Goodman, 1999) reported
it is competitive on very large training data sets
comparing with other smoothing techniques.
e =
t
n+ t
(13)
p(?) =
c(?)
n+ t
(14)
Method D (Howard, 1993) is minor modifi-
cation to method B. Whenever a novel event
occurs, rather than adding one to the symbol,
half is added instead.
e =
t
2n
(15)
p(?) =
2c(?)? 1
2n
(16)
To illustrate the PPM compression modelling
technique, Table 1 shows the model after string
dealornodeal has been processed. In this illus-
tration the maximum order is 2 and each pre-
diction has a count c and a prediction prob-
ability p. The probability is determined from
Order 2
Prediction c p
al ? o 1 1/2
? Esc 1 1/2
de ? a 2 3/4
? Esc 1 1/4
ea ? l 2 3/4
? Esc 1 1/2
lo ? r 1 1/2
? Esc 1 1/2
no ? d 1 1/2
? Esc 1 1/2
od ? e 1 1/2
? Esc 1 1/2
or ? n 1 1/2
? Esc 1 1/2
rn ? o 1 1/2
? Esc 1 1/2
Order 1
Prediction c p
a ? l 2 3/4
? Esc 1 1/4
d ? e 2 3/4
? Esc 1 1/4
e ? a 2 3/4
? Esc 1 1/4
l ? o 1 1/2
? Esc 1 1/2
n ? o 1 1/2
? Esc 1 1/2
o ? d 1 1/4
? r 1 1/4
? Esc 2 1/2
r ? n 1 1/2
? Esc 1 1/2
Order 0
Prediction c p
? a 2 3/24
? d 2 3/24
? e 2 3/24
? l 2 3/24
? n 1 1/24
? o 2 3/24
? r 1 1/24
? Esc 7 7/24
Order ?1
Prediction c p
? A 1 1/|A|
Table 1: PPM model after processing the string
dealornodeal
counts associated with the prediction using es-
cape method D(equation 16). |A| is the size the
alphabet which determines the probability for
each unseen character.
Suppose the character following dealornodeal
is o. Since the order-2 context is al and the up-
coming symbol o has already seen in this con-
text, the order-2 model is used to encode the
symbol. The encoding probability is 1/2. If the
next character were i instead of o, it has not
been seen in the current order-2 context (al).
Then an order-2 escape event is emitted with a
probability of 1/2 and the context truncated to
l. Checking the order-1 model, the upcoming
character i has not been seen in this context,
so an order-1 escape event is emitted with a
probability of 1/2 and the context is truncated
to the null context, corresponding to the order-
0 model. As i has not appeared in the string
dealornodeal, a final level of escape is emitted
with a probability of 7/24 and the i will be pre-
dicted with a probability of 1/256 in the order-
?1, assuming that the alphabet size is 256 for
ASCII. Thus i is encoded with a total probabil-
ity of 12 ?
1
2 ?
7
24 ?
1
256 .
In reality, the alphabet size in the order- ?1
model may be reduced by the number of char-
acters in the order-0 model as these characters
will never be predicted in the order- ?1 context.
Thus it can be reduced to 249 in this case. Simi-
larly a character that occurs in the higher-order
model will never be encoded in the lower-order
models. So it is not necessary to reserve the
probability space for the character in the lower-
order models. This is called ?exclusion?, which
can greatly improve compression.
Compression Method Size Compression Rate
Escape A(order 2) 434228 54.8%
Escape B(order 2) 332278 41.9%
Escape C(order 2) 333791 42.1%
Escape D(order 2) 332829 42.0%
Escape D(order 1) 345841 43.6%
Escape D(order 3) 332932 42.0%
gzip 434220 54.8%
compress 514045 64.8%
Table 2: Compression results for different com-
pression methods
Table 2 shows the compression result for file
People Daily (9101) with 792964 Bytes using
different compression methods. PPM compres-
sion methods are significantly better than prac-
tical compression utilities like Unix gzip and
compress except escape method A but they are
slower during compression. The compression
rates for escape method B and D are both higher
than escape method C. Order-2 model (trigram)
is slightly better that order-1 and order-3 mod-
els for escape method D.
In our experiment we use escape method D
to calculate the escape probability as escape
method D is slightly better than other escape
methods in compressing text although Method
B is the best here. Teahan (Teahan et al, 2000)
has successfully applied escape method D to
segment Chinese text.
4 Experiment and Result
We use 220MB People Daily (91-95) as the
training corpus and 58M People Daily (96) and
stories download from Internet (400K) as the
test corpus.
We used SRILM language tools (Stolcke,
2002) to collect trigram counts and applied
modified Kneser-Ney smoothing method to
build the language model. Then we used disam-
big to translate Pinyin to Chinese characters.
In PPM model we used the same count data
collected by SRILM tools. We chose a trie struc-
ture to store the symbol and count. Adaptive
PPM model updates the counts during Pinyin
input. It is similar to a cache model (Kuhn
and De Mori, 1990). We tested both static and
adaptive PPM models on test corpus. PPM
models run twice faster than SRILM tool dis-
ambig. It took 20 hours to translate Pinyin
(People Daily 96) to character on a Sparc with
two CPUs(900Mhz) using SRILM tools. The
following Table 3 shows the results in terms of
character error rate. People Daily(96) is the
same domain as the training corpus. Results ob-
tained testing on People Daily are consistently
much better than Stories. Static PPM is a lit-
tle worse than modified Kneser-Ney smoothing
method. Adaptive PPM model testing on large
corpus is better than small corpus as it takes
time to adapt to the new model.
People Daily(96) Stories
modified Kneser-Ney 5.82% 14.48%
Static PPM 6.00% 16.55%
Adaptive PPM 4.98% 14.24%
Table 3: Character Error Rates for Kneser-Ney,
Static and Adaptive PPM
5 Conclusion
We have introduced a method for Pinyin input
based on an adaptive PPM model. Adaptive
PPM model outperforms both static PPM and
modified Kneser-Ney smoothing.
References
T.C. Bell, J.G. Cleary, and I.H. Witten. 1990.
Text Compression. Prentice Hall.
Stanly Chen and Joshua Goodman. 1999. An
empirical study of smoothing techniques for
language modeling. Computer Speech and
Language, 13, 10.
J.G. Cleary and I.H. Witten. 1984. Data com-
pression using adaptive coding and partial
string matching. IEEE transactions on Com-
munications, 32(4).
Jianfeng Gao, Juashua Goodman, Mingjing Li,
and Kai Fu Lee. 2002. Toward a unified ap-
proach to statistical language modeling for
chinese. ACM transaction on Asian Lan-
guage information processing, 1(1), March.
Joshua Goodman. 2001. A bit of progress in
language modeling. Technical Report MSR-
TR-2001-72, Microsoft Research.
P.G. Howard. 1993. The design and analysis
of efficient lossless data compression systems.
Ph.D. thesis, Brown University, Providence,
Rhode Island.
R. Kuhn and R. De Mori. 1990. A cache-based
natural language model for speech reproduc-
tion. IEEE Transac-tion on Pattern Analysis
and Machine Intelligence, 6.
Alistair Moffat. 1990. Implement the ppm data
com-pression scheme. IEEE Transaction on
Communications, 38(11):1917?1921.
A. Stolcke. 2002. Srilm ? an extensible lan-
guage modeling toolkit. In Proc. Intl. Conf.
on Spoken Lan-guage Processing, volume 2,
pages 901?904, Denver.
W.J. Teahan, Yingying Wen, and I.H. Wit-
ten R. McNab. 2000. A compression-
based algorithm for chinese word segmenta-
tion. Computational Linguistics, 26(3):375?
394, September.
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 345?355,
Avignon, France, April 23 - 27 2012. c?2012 Association for Computational Linguistics
 
 
The Problem with Kappa   David M W Powers Centre for Knowledge & Interaction Technology, CSEM Flinders University David.Powers@flinders.edu.au       Abstract It is becoming clear that traditional evaluation measures used in Computational Linguistics (including Error Rates, Accuracy, Recall, Precision and F-measure) are of limited value for unbiased evaluation of systems, and are not meaningful for comparison of algorithms unless both the dataset and algorithm parameters are strictly controlled for skew (Prevalence and Bias). The use of techniques originally designed for other purposes, in particular Receiver Operating Characteristics Area Under Curve, plus variants of Kappa, have been proposed to fill the void.  This paper aims to clear up some of the confusion relating to evaluation, by demonstrating that the usefulness of each evaluation method is highly dependent on the assumptions made about the distributions of the dataset and the underlying populations. The behaviour of a number of evaluation measures is compared under common assumptions. Deploying a system in a context which has the opposite skew from its validation set can be expected to approximately negate Fleiss Kappa and halve Cohen Kappa but leave Powers Kappa unchanged. For most performance evaluation purposes, the latter is thus most appropriate, whilst for comparison of behaviour, Matthews Correlation is recommended.  
Introduction Research in Computational Linguistics usually requires some form of quantitative evaluation. A number of traditional measures borrowed from Information Retrieval (Manning & Sch?tze, 1999) are in common use but there has been considerable critical evaluation of these measures themselves over the last decade or so (Entwisle & Powers, 1998, Flach, 2003, Ben-David. 2008). Receiver Operating Analysis (ROC) has been advocated as an alternative by many,  and in particular has been used by F?rnkranz and Flach (2005), Ben-David (2008) and Powers (2008) to better understand both learning algorithms relationship and the between the various measures, and the inherent biases that make many of them suspect. One of the key advantages of ROC is that it provides a clear indication of chance level performance as well as a less well known indication of the relative cost weighting of positive and negative cases for each possible system or parameterization represented. ROC Area Under the Curve (Fig. 1) has been also used as a performance measure but averages over the false positive rate (Fallout) and is thus a function of cost that is dependent on the classifier rather than the application. For this reason it has come into considerable criticism and a number of variants and alternatives have been proposed (e.g. AUK, Kaymak et. Al, 2010 and H-measure, Hand, 2009). An AUC curve that is at least as good as a second curve at all points, is said to dominate it and indicates that the first classifier is equal or better than the second for all plotted values of the parameters, and all cost ratios. However AUC being greater for one classifier than another does not have such a property ? indeed deconvexities within or 
345
  
intersections of ROC curves are both prima facie evidence that fusion of the parameterized classifiers will be useful (cf. Provost and Facett, 2001; Flach and Wu, 2005). AUK stands for Area under Kappa, and represents a step in the advocacy of Kappa (Ben-David, 2008ab) as an alternative to the traditional measures and ROC AUC. Powers (2003,2007) has also proposed a Kappa-like measure (Informedness) and analysed it in terms of ROC, and there are many more, Warrens (2010) analyzing the relationships between some of the others. Systems like RapidMiner (2011) and Weka (Witten and Frank, 2005) provide almost all of the measures we have considered, and many more besides.  This encourages the use of multiple measures, and indeed it is now becoming routine to display tables  of multiple results for each system, and this is in particular true for the frameworks of some of the challenges and competitions brought to the communities (e.g. 2nd i2b2 Challenge in NLP for Clinical Data, 2011; 2nd Pascal Challenge on HTC, 2011)).  This use of multiple statistics is no doubt in response to the criticism levelled at the evaluation mechanisms used in earlier generations of competitions and the above mentioned critiques, but the proliferation of alternate measures in some ways merely compounds the problem. Researchers have the temptation of choosing those that favour their system as they face the dilemma of what to do about competing (and often disagreeing) evaluation measures that they do not completely understand. These systems and competitions also exhibit another issue, the tendency to macro-averages over multiple classes, even of measures that are not denominated in class (e.g. that are proportions of predicted labels rather than real classes, as with Precision). This paper is directed at better understanding some of these new and old measures as well as  providing recommendations as to which measures are appropriate in which circumstances. What?s in a Kappa? In this paper we focus on the Kappa family of measures, as well as some closely related statistics named for other letters of the Greek alphabet, and some measures that we will show behave as Kappa measures although they were not originally defined as such.  These include Informedness, Gini Coefficient and single point 
ROC AUC, which are in fact all equivalent to DeltaP? in the dichotomous case, which we deal with first, and to the other Kappas when the marginal prevalences (or biases) match. 1.1 Two classes and non-negative Kappa. Kappa was originally proposed (Cohen, 1960) to compare human ratings in a binary, or dichotomous, classification task. Cohen (1960) recognized that Rand Accuracy did not take chance into account and therefore proposed to subtract off the chance level of Accuracy and then renormalize to the form of a probability: K(Acc) = [Acc ? E(Acc)] / [1 ? E(Acc)] (1) This leaves the question of how to estimate the expected Accuracy, E(Acc). Cohen (1960) made the assumption that raters would have different distributions that could be estimated as  the products of the corresponding marginal coefficients of the contingency table:   +ve Class ?ve Class  +ve Prediction A=TP B=FP PP ?ve Prediction C=FN D=TN PN Notation RP RN N Table 1. Statistical and IR Contingency Notation In order to discuss this further it is important to discuss our notational conventions, and it is noted that in statistics, the letters A-D (upper case or lower case) are conventionally used to label the cells, and their sums may be used to label the marginal cells.  However in the literature on ROC analysis, which we follow here, it is usual to talk about true and false positives (that is positive predictions that are correct or incorrect), and conversely true and false negatives.  Often upper case is used to indicate counts in the contingency table, which sum to the number of instances, N. In this case lower case letters are used to indicate probabilities, which means that the corresponding upper case values in the contingency table are all divided by N, and n=1.  Statistics relative to (the total numbers of items in) the real classes are called Rates and have the number (or proportion) of Real Positives (RP) or Real Negatives (RN) in the denominator. In this notation, we have Recall = TPR = TP/RP. Conversely statistics relative to the (number of) predictions are called Accuracies, so relative to the predictions that label instances positively, Predicted Positives (PP), we have Precision = TPA = TP/PP.   
346
  
The accuracy of all our predictions, positive or negative, is given by Rand Accuracy = (TF+TN)/N = tf+tn, and this is what is meant in general by the unadorned term Accuracy, or the abbreviation Acc. Rand Accuracy is the weighted average of Precision and Inverse Precision (probability that negative predictions are correctly labeled), where 
the weighting is made according to the number of predictions made for the corresponding labels. Rand Accuracy is also the weighted average of Recall and Inverse Recall (probability that negative instances are correctly predicted), where the weighting is made according to the number of instances in the corresponding classes. The marginal probabilities rp and pp are also known as Prevalence (the class prevalence of positive instances) and Bias (the label bias to positive predictions), and the corresponding probabilities of negative classes and labels are the Inverse Prevalence and Inverse Bias respectively. In the ROC literature, the ratios of negative to positive classes is often referred to as the class ratio or skew.  We can similarly also refer to a label ratio, prediction ratio or prediction skew.  Note that optimal performance can only be achieved if class skew = label skew. The Expected True Positives and Expected True Negatives for Cohen Kappa, as well as Chi-squared significance, are estimated as the product of Bias and Prevalence, and the product of Inverse Bias and Inverse Prevalence, resp., where traditional uses of Kappa for agreement of human raters, the contingency table represents one rater as providing the classification to be predicted by the other rater. Cohen assumes that their distribution of ratings are independent, as reflected both by the margins and the contingencies: ETP = RP*PP; ETN = RN*NN. This gives us E(Acc) = (ETP+ETN)/N=etp+etn. By contrast the two rater two class form of Fleiss (1981) Kappa, also known as Scott Pi, assumes that both raters are labeling independently using the same distribution, and that the margins reflect this potential variation. The expected number of positives is thus effectively estimated as the average of the two raters? counts, so that EP = (RP+PP)/2, and EN = (RN+PN)/2, ETP = EP2 and ETN = EN2. 1.2 Inverting Kappa The definition of Kappa in Eqn (1) can be seen to be applicable to arbitrary definitions of Expected Accuracy, and in order to discover how other measures relate to the family of Kappa measures it is useful to invert Kappa to discover the implicit definition of Expected Accuracy that allows a measure to be interpreted as a form of Kappa. We simply make E(Acc) the subject by multiplying out Eqn (1) to a common denominator and associating factors of E(Acc):  
  Figure 1. Illustration of ROC Analysis. The solid diagonal represents chance performance for different rates of guessing positive or negative labels.  The dotted line represent the convex hull enclosing the results of different systems, thresholds or parameters tested. The (0,0) and (1,1) points represent guessing always negative and always positive and are always nominal systems in a ROC curve.  The points along any straight line segment of a convex hull are achievable by probabilistic interpolation of the systems at each end, the gradient represents the cost ratio and all points along the segment, including the endpoints have the same effective cost benefit. AUC is the area under the curve joining the systems with straight edges and AUCH is the area under the convex hull where points within it are ignored. The height above the chance line of any point represents DeltaP?,  the Gini Coefficient and also the Dichotomous Informedness of the corresponding system, and also corresponds to  twice the area of the triangle between it and the chance line, and thus 2AUC-1 where AUC is calculated on this single point curve (not shown) joining it to (0,0) and (1,1).  The (1,0) point represents perfect performance with 100% True Positive Rate and 0% False Negative Rate.   
!
347
  
K(Acc) = [Acc ? E(Acc)] / [1 ? E(Acc)] (1) E(Acc) = [Acc ? K(Acc)] / [1 ? K(Acc)] (2) Note that for a given value of Acc the function connecting E(Acc) and K(Acc) is its own inverse: E(Acc) = fAcc(K(Acc)) (3) K(Acc) = fAcc(E(Acc)) (4) For the future we will tend to drop the Acc argument or subscript when it is clear, and we will also subscript E and K with the name or initial of the corresponding definition of Expectation and thus Kappa (viz. Fleiss and Cohen so far). Note that given Acc and E(Acc) are in the range of 0..1 as probabilities, Kappa is also restricted to this range, and takes the form of a probability. 1.3 Multiclass multirater Kappa Fleiss (1981) and others sought to generalize the Cohen (1960) definition of Kappa to handle both multiple class (not just positive/negative) and multiple raters (not just two ? one of which we have called real and the other prediction).  Fleiss in fact generalized Scott?s (1955) Pi in both senses, not Cohen Kappa. The Fleiss Kappa is not formulated as we have done here for exposition, but in terms of pairings (agreements) amongst the raters, who are each assumed to have rated the same number of items, N, but not necessarily all.  Krippendorf?s (1970, 1978) effectively generalizes further by dealing with arbitrary numbers of raters assessing different numbers of items. Light (1971) and Hubert (1977) successfully generalized Cohen Kappa. Another approach to estimating E(Acc) was taken by Bennett et al1955) which basically assumed all classes were equilikely (effectively what use of Accuracy, F-Measure etc. do, although they don?t subtract off the chance component).  The Bennett Kappa was generalized by Randolph (2005), but as our starting point is that we need to take the actual margins into account, we do not pursue these further.  However, Warrens (2010a) shows that, under certain conditions, Fleiss Kappa is a lower bound of both the Hubert generalization of Cohen Kappa and the Randolph generalization of Bennet Kappa, which is itself correspondingly an upper bound of both the Hubert and the Light generalizations of Cohen Kappa. Unfortunately the conditions are that there is some agreement between the class and label skews (viz. the 
prevalence and bias of each class/label). Our focus in this paper is the behaviour of the various Kappa measures as we move from strongly matched to strongly mismatched biases. Cohen (1968) also introduced a weighted variant of Kappa. We have also discussed cost weighting in the context of ROC, and Hand (2009) seeks to improve on ROC AUC by introducing a beta distribution as an estimated cost profile, but we will not discuss them further here as we are more interested in the effectiveness of the classifer overall rather than matching a particular cost profile, and are skeptical about any generic cost distribution.  In particular the beta distribution gives priority to central tendency rather than boundary conditions, but boundary conditions are frequently encountered in optimization.  Similarly Kaymak et als (2010) proposal to replace AUC by AUK corresponds to a Cohen Kappa reweighting of ROC that eliminates many of its useful properties, without any expectation that the measure, as an integration across a surrogate cost distribution, has any validity for system selection.  Introducing alternative weights is also allowed in the definition of F-Measure, although in practice this is almost invariably employed as the equally weighted harmonic mean of Recall and Precision. Introducing additional weight or distribution parameters, just multiplies the confusion as to which measure to believe. Powers (2003) derived a further multiclass Kappa-like measure from first principles, dubbing it Informedness, based on an analogy of Bookmaker associating costs/payoffs based on the odds. This is then proven to measure the proportion of time (or probability) a decision is informed versus random, based on the same assumptions re expectation as Cohen Kappa, and we will thus call it Powers Kappa, and derive an formulation of the corresponding expectation. Powers (2007) further identifies that the dichotomous form of Powers Kappa is equivalent to the Gini cooefficient as a deskewed version of the weighted Relative Accuracy proposed by Flach (2003) based on his analysis and deskewing of common evaluation measures in the ROC paradigm. Powers (2007) also identifies that Dichotomous Informedness is equivalent to an empirically derived psychological measure called DeltaP? (Perruchet et al2004). DeltaP? (and its dual DeltaP) were derived based on analysis of human word association data ? the combination of this empirical observation with the place of DeltaP? as the dichotomous case of 
348
  
Powers? ?Informedness? suggests that human association is in some sense optimal. Powers (2007) also introduces a dual of Informedness that he names Markedness, and shows that the geometric mean of Informedness and Markedness is Matthews Correlation, the nominal analog of Pearson Correlation. Powers? Informedness is in fact a variant of Kappa with some similarities to Cohen Kappa, but also some advantages over both Cohen and Fleiss Kappa due to its asymmetric relation with Recall, in the dichotomous form of Powers (2007), Informedness =  Recall + InverseRecall ? 1                        = (Recall ? Bias) / (1 ? Prevalence). If we think of Kappa as assessing the relationship between two raters, Powers? statistic is not evenhanded and the Informedness and Markedness duals measure the two directions of prediction, normalizing Recall and Precision.  In fact, the relationship with Correlation allows these to be interpreted as regression coefficients for the prediction function and its inverse. 1.4 Kappa vs Correlation It is often asked why we don?t just use Correlation to measure.  In fact, Castellan (1996) uses Tetrachoric Correlation, another generalization of Pearson Correlation that assumes that the two class variables are given by underlying normal distributions.  Uebersax (1987), Hutchison (1993) and Bonnet and Price (2005) each compare Kappa and Correlation and conclude that there does not seem to be any situation where Kappa would be preferable to Correlation. However all the Kappa and Correlation variants considered were symmetric, and it is thus interesting to consider the separate regression coefficients underlying it that represent the Powers Kappa duals of Informedness and Markedness, which have the advantage of separating out the influences of Prevalence and Bias (which then allows macro-averaging, which is not admissable for any symmetric form of Correlation or Kappa, as we will discuss shortly).  Powers (2007) regards Matthews Correlation as an appropriate measure for symmetric situations (like rater agreement) and generalizes the relationships between Correlation and Significance to the Markedness and Informedness Measures. The differences between Informedness and Markedness, which relate to mismatches in Prevalence and Bias, mean that the pair of numbers provides further information about the nature of the relationship between the two classifications or raters, whilst 
the ability to take the geometric mean (of macro-averaged) Informedness and Markedness means that a single Correlation can be provided when appropriate. Our aim now is therefore to characterize Informedness (and hence as its dual Markedness) as a Kappa measure in relation to the families of Kappa measures represented by Cohen and Fleiss Kappa in the dichotomous case.  Note that Warrens (2011) shows that a linearly weighted versions of Cohen?s (1968) Kappa is in fact a weighted average of dichotomous Kappas.  Similarly Powers (2003) shows that his Kappa (Informedness) has this property.  Thus it is appropriate to consider the dichotomous case, and from this we can generalize as required. 1.5 Kappa vs Determinant Warrens (2010c) discusses another commonly used measure, the Odds Ratio ad/bc (in Epidemiology rather than Computer Science or Computational Linguistics). Closely related to this is the Determinant of the Contingency Matrix dtp = ad-bc = etp-etn (in the Chi-Sqr, Cohen and Powers sense based on independent marginal probabilities).  Both show whether the odds favour positives over negatives more for the first rater (real) than the second (predicted) ? for the ratio it is if it is greater than one, for the difference it is if it is greater than 0. Note that taking logs of all coefficients would maintain the same relationship and that the difference of the logs corresponds to the log of the ratio, mapping into the information domain. Warrens (2010c) further shows (in cost-weighted form) that Cohen Kappa is given by the following (in the notation of this paper, but preferring the notations Prevalence and Inverse Prevalence to rp and rn for clarity): KC = dtp/[(Prev*IBias+Bias*IPrev)/2]. (5) Based on the previous characterization of Fleiss Kappa, we can further characterize it by KF = dtp/[(Prev+Bias)*(IBias+IPrev)/4]. (6) Powers (2007) also showed corresponding formulations for Bookmaker Informedness (B, or Powers Kappa = KP), Markedness and Matthews Correlation: B  = dtp/[(Prev*IPrev)]. (7) M = dtp/[(Bias*IBias)]. (8) C  = dtp/[?(Prev*IPrev*Bias*IBias)]. (9) These elegant dichotomous forms are straightforward, with the independence assumptions on Bias and Prevalence clear in 
349
  
Cohen Kappa, the arithmetic means of Bias and Prevalence clear in Fleiss Kappa, and the  geometric means of Bias and Prevalence in the Matthews Correlation.  Further the independence of Bias is apparent for Powers Kappa in the Informedness form, and independence of Prevalence is clear in the Markedness direction. Note that the names Powers uses suggest that we are measuring something about the information conveyed by the prediction about the class in the case of Informedness, and the information conveyed to the predictor by the class state in the case of Markedness. To the extent that Prevalence and Bias can be controlled independently, Informedness and Markedness are independent and Correlation represents the joint probability of information being passed in both directions! Powers (2007) further proposes using log formulations of these measures to take them into the information domain, as well as relating them to mutual information, G-squared and chi-squared significance. 1.6 Kappa vs Concordance The pairwise approach used by Fleiss Kappa and its relatives does not assume raters use a common distribution, but does assume they are using the same set, and number of categories.  When undertaking comparison of unconstrained ratings or unsupervised learning, this constraint is removed and we need to use a measure of concordance to compare clusterings against each other or against a Gold Standard.  Some of the concordance measures use operators in probability space and relate closely to the techniques here, whilst others operate in information space. See Pfitzner et al(2009) for reviews of clustering comparison/concordance. A complete coverage of evaluation would also cover significance and the multiple testing problem, but we will confine our focus in this paper to the issue of choice of Kappa or Correlation statistic, as well as addressing some issues relating to the use of macro-averaging. In this paper we are regarding the choice of Bias as under the control of the experimenter, as we have a focus on learned or hand crafted computational linguistics systems.  In fact, when we are using bootstrapping techniques or dealing with multiple real samples or different subjects or ecosystems, Prevalence may also vary. Thus the simple marginal assumptions of Cohen or Powers statistics are the appropriate ones. 
1.7 Averaging We now consider the issue of dealing with multiple measures and results of multiple classifiers by averaging.  We first consider averages of some of the individual measures we have seen. The averages need not be arithmetic means, or may represent means over the Prevalences and Biases. We will be punctuating our theoretical discussions and explanations with empirical demonstrations where we use 1:1 and 4:1 prevalence versus matching and mismatching bias to generate the chance level contingency based on marginal independence.  We then mix in a proportion of informed decisions, with the remaining decisions made by chance.   Table 2 compares Accuracy and F-Measure for an informed decision percentage of 0, 100, 15 and -15. Note that Powers Kappa or ?Informedness? purports to recover this proportion or probability. F-Measure is one of the most common measures in Computational Linguistics and Information Retrieval, being a Harmonic Mean of Recall and Precision, which in the common unweighted form also is interpretable with respect to a mean of Prevalence and Bias: F = tp / [(Prev+Bias)/2] (10) Note that like Recall and Precision, F-Measure ignores totally cell D corresponding to tn.  This is an issue when Prevalence and Bias are uneven or mismatched. In Information Retrieval, it is often justified on the basis that the number of irrelevant documents is large and not precisely known, but in fact this is due to lack of knowledge of the number of relevant documents, which affects Recall. In fact if tn is large with respect to both rp and pp, and thus with respect to components tp, fp and fn, then both tn/pn and tn/rn approach 0 as tn increases without bound. As discussed earlier, Rand Accuracy is a prevalence (real class) weighted average of Precision and Inverse Precision, as well as a bias (prediction label) weighted average of Recall and Inverse Precision. It reflects the D (tn) cell unlike F, and while it does not remove the effect of chance it does not have the positive bias of F. Acc = tp + fp (11) We also point out that the differences between the various Kappas shown in Determinant normalized form in Eqns (5-9) vary only in the way prevalences and biases are averaged together in the normalizing denominator. 
350
  
Informed   1:1/1:1 4:1/4:1 4:1/1:4 Acc 50% 68% 32% 0% F 50% 80% 32% Acc 100% 100% 100% 100% F 100% 100% 100% Acc 57.5% 72.8% 42.2% 15% F 57.5% 83% 46.97% Acc 42.5% 57.8% 27.2% -15% F 42.5% 72% 27.2% Table 2. Accuracy and F-Measure for different mixes of prevalence and bias skew (odds ratio shown) as well as different proportions of correct (informed) answers versus guessing ? negative proportions imply that the informed decisions are deliberately made incorrectly (oracle tells me what to do and I do the opposite). From Table 2 we note that the first set of statistics notes the chance level varies from the 50% expected for Bias=Prevalence=50%. This is in fact the E(Acc) used in calculating Cohen Kappa.  Where Prevalences and Biases are equal and balanced, all common statistics agree ? Recall = Precision = Accuracy = F, and they are interpretable with respect to this 50% chance level. All the Kappas will also agree, as the  different averages of the identical prevalences and biases all come down to 50% as well.  So subtracting 50% from 57.5% and normalizing (dividing) by the average effective prevalence of 50%, we return 15% informed decisions in all cases (as seen in detail in Table 3). However, F-measure gives an inflated estimate when it focus on the more prevalent positive class, with corresponding bias in the chance component. Worse still is the strength of the Acc and F scores under conditions of matched bias and prevalence when the deviation from chance is -15% - that is making the wrong decision 15% of the time and guessing the rest of the time.  In academic terms, if we bump these rates up to  ?25% F-factor gives a High Distinction for guessing 75% of the time and putting the right answer for the other 25%, a Distinction for 100% guessing, and a Credit for guessing 75% of the time and putting a wrong answer for the other 25%!  In fact, the Powers Kappa corresponds to the methodology of multiple choice marking, where for questions with k+1 choices, a right answer gets 1 mark, and a wrong answer gets -1/k so that guessing achieves an expected mark of 0. Cohen Kappa achieves a very similar result for unbiased guessing strategies. 
We now turn to macro-averaging across multiple classifiers or raters.  The Area Under the Curve measures are all of this form, whether we are talking about ROC, Kappa, Recall-Precision curves or whatever. The controversy over these averages, and macro-averaging in general, relates to one of two issues: 1. The averages are not in general over the appropriate units or denominators of the individual statistics; or 2. The averages are over a classifier determined cost function rather than an externally or standardly defined cost function.  AUK and H-Measure seek to address these issues as discussed earlier.  In fact they both boil down to averaging with an inappropriate distribution of weights. Commonly macro-averaging averages across classes as average statistics derived for each class weighted by the cardinality of the class (viz. prevalence). In our review above, we cited four examples, but we will refer only to WEKA (Witten et al 2005) here as a commonly used system and associated text book that employs and advocates macro-averaging. WEKA averages over tpr, fpr, Recall (yes redundantly), Precision, F-Factor and ROC AUC.  Only the average over tpr=Recall is actually meaningful, because only it has the number of members of the class, or its prevalence, as its denominator. Precision needs to be macro-averaged over the number of predictions for each class, in which case it is equivalent to micro-averaging. Other micro-averaged statistics are also shown, including Kappa (with the expectation determined from ZeroR ? predicting the majority class, leading to a Cohen-like Kappa).  AUC will be pointwise for classifiers that don?t provide any probabilistic information associated with label prediction, and thus don?t allow varying a threshold for additional points on the ROC or other threshold curves. In the case where multiple threshold points are available, ROC AUC cannot be interpreted as having any relevance to any particular classifier, but is an average over a range of classifiers. Even then it is not so meaningful as AUCH, which should be used as classifiers on the convex hull are usually available. The AUCH measure will then dominate any individual classifiers, as if the convex hull is not the same as the single classifier it must include points that are above the classifier curve and thus its enclosed area totally includes the area that is enclosed by the individual classifier. Macroaveraging of the curve based on each class in turn as the Positive Class, and weighted 
351
  
by the size of the positive class, is not meaningful as effectively shown by Powers (2003) for the special case of the single point curve given its equivalence to Powers Kappa. In fact Markedness does admit averaging over classes, whilst Informedness requires averaging over predicted labels, as does Precision.  The other Kappa and Correlations are more complex (note the demoninators in Eqns 5-9) and how they might be meaningfully macro-averaged is an open question.  However, microaveraging can always be done quickly and easily by simply summing all the contingency tables (the true contingency tables are tables of counts, not probabilities, as shown in Table 1). Macroaveraging should never be done except for the special cases of Recall and Markedness when it is equivalent to micro-average, which is only slightly more expensive/complicated to do. Comparison of Kappas We now turn to explore the different definitions of Kappas, using the same approach employed with Accuracy and F-Factor in Table 1: We will consider 0%, 100%, 15% and -15% informed decisions, with random decisions modelled on the basis of independent Bias and Prevalence.   This clearly biases against the Fleiss family of Kappas, which is entirely appropriate.  As pointed out by Entwisle & Powers (1998) the practice of deliberately skewing bias to achieve better statistics is to be deprecated ? they used the real-life example of a CL researcher choosing to say water was always a noun because it was a noun more often than not. With Cohen or Powers? measures, any actual power of the system to determine PoS, however weak, would be reflected in an improvement in the scores versus any random choice, whatever the distribution.  Recall that choosing one answer all the time corresponds to the extreme points of the chance line in the ROC curve. Studies like Fitzgibbon et al2007) and Leibbrandt and Powers (2012) show divergences amongst the conventional and debiased measures, but it is tricky to prove which is better. Kappa in the Limit It is however straightforward to derive limits for the various Kappas and Expectations under extreme and central conditions of bias and prevalence, including both match and mismatch. The 36 theoretical results match the mixture model results in Table 3, however, due to space constraints, formal treatment will be limited to 
two of the more complex cases that both relate to Fleiss Kappa with its mismatch to the marginal independence assumptions we prefer. These will provide informedness of probability B plus a remaining proportion 1-B of random responses exhibiting extreme bias versus both neutral and contrary prevalence. Note that we consider only |B|<1 as all Kappas give Acc=1 and thus K=1 for B=1, and only Powers Kappa is designed to work for B<1, giving K= -1 for B= -1. Recall that the general calculation of Expected Accuracy is E(Acc) = etp+etn (11) For Fleiss Kappa we must calculate the expected values of the correct contingencies as discussed previously with expected probabilities ep = (rp+pp)/2      &      en = (rn+pn)/2 (12) etp = ep2               &      etn = en2 (13) We first consider cases where prevalence is extreme and the chance component exhibits inverse bias. We thus consider limits as  rp?0, rn?1, pp?1-B, pn?B. This gives us (assuming |B|<1) EF(Acc)  = (1/4+B2/4+B/2)2+(1/4+B2/4-B/2)2                = (1+B2)/2 (14) KF(Acc) = (1-B)2/[B2-2] (15) We second consider cases where the prevalence is balanced and chance extreme, with rp?0.5, rn?0.5, pp?1-B, pn?B, giving EF(Acc) = 1/2 + (B-1/2)2/2               = 5/8 + B(B-1)/2 (16) KF(Acc)=[(B-1/2)-(B-1/2)2/2]/[1/2-(B-1/2)2/2] (17)              =[B-5/8+B(B-1)/2]/[1-(5/8+B(B-1)/2) Conclusions The asymmetric Powers Informedness gives the clearest measure of the predictive value of a system, while the Matthews Correlation (as geometric mean with the Powers Markedness dual) is appropriate for comparing equally valid classifications or ratings into an agreed number of classes. Concordance measures should be used if number of classes is not agreed or specified. For mismatch cases (15) Fleiss is always negative for |B|<1) and thus fails to adequately reward good performance under these marginal conditions. For the chance case (17), the first form we provide shows that the deviation from matching Prevalence is a driver in a Kappa-like function. Cohen on the other hand (Table 3) tends to apply multiply the weight given to error in even mild prevalence-bias mismatch conditions. None of the symmetric Kappas designed for raters are suitable for classifiers. 
352
  
   1:1 1:1 4:1 4:1 4:1 1:4 1:1 1:1 4:1 4:1 4:1 1:4 1:1 1:1 4:1 4:1 4:1 1:4 Informedness 0% 0% 0% 0% 0% 0% 0% 0% 0% Prevalence 50% 80% 80% 50% 80% 80% 50% 20% 20% Iprevalence 50% 20% 20% 50% 20% 20% 50% 80% 80% Bias 50% 80% 20% 50% 80% 20% 50% 20% 80% Ibias 50% 20% 80% 50% 20% 80% 50% 80% 20%              SkewR 100% 25% 25% 100% 25% 25% 100% 400% 400% SkewP 100% 25% 400% 100% 25% 400% 100% 400% 25% OddsRatio 100% 100% 6% 100% 100% 6% 100% 100% 1600% ePowers 50% 68% 32% 50% 68% 32% 50% 68% 32% eCohen 50% 68% 32% 50% 68% 32% 50% 68% 32% eFleiss 50% 68% 50% 50% 68% 50% 50% 68% 50% kPowers 0% 0% 0% 0% 0% 0% 0% 0% 0% kCohen 0% 0% 0% 0% 0% 0% 0% 0% 0% kFleiss 0% 0% -36% 0% 0% -36% 0% 0% -36% Informedness 100% 100% 100% 100% 100% 100% 100% 100% 100% Prevalence 50% 80% 80% 50% 80% 80% 50% 20% 20% Iprevalence 50% 20% 20% 50% 20% 20% 50% 80% 80% Bias 50% 80% 80% 50% 80% 80% 50% 20% 20% Ibias 50% 20% 20% 50% 20% 20% 50% 80% 80%              SkewR 100% 25% 25% 100% 25% 25% 100% 400% 400% SkewP 100% 25% 25% 100% 25% 25% 100% 400% 400% OddsRatio 100% 100% 100% 100% 100% 100% 100% 100% 100% ePowers 50% 68% 68% 50% 68% 68% 50% 68% 68% aCohen 50% 68% 68% 50% 68% 68% 50% 68% 68% aFleiss 50% 68% 68% 50% 68% 68% 50% 68% 68% kPowers 100% 100% 100% 100% 100% 100% 100% 100% 100% kCohen 100% 100% 100% 100% 100% 100% 100% 100% 100% kFleiss 100% 100% 100% 100% 100% 100% 100% 100% 100% Informedness 15% 15% 15% 99% 99% 99% 99% 99% 99% Prevalence 50% 80% 80% 50% 80% 80% 50% 20% 20% Iprevalence 50% 20% 20% 50% 20% 20% 50% 80% 80% Bias 50% 80% 29% 50% 80% 79% 50% 20% 79% Ibias 50% 20% 71% 50% 20% 21% 50% 80% 21%              SkewR 100% 25% 25% 100% 25% 25% 100% 400% 400% SkewP 100% 25% 245% 100% 25% 26% 100% 400% 26% OddsRatio 100% 100% 6% 100% 100% 6% 100% 100% 1600% ePowers 50% 68% 32% 50% 68% 32% 50% 68% 32% eCohen 50% 68% 37% 50% 68% 68% 50% 68% 32% eFleiss 50% 68% 50% 50% 68% 68% 50% 68% 50% kPowers 15% 15% 15% 99% 99% 99% 1% 1% 1% kCohen 15% 15% 8% 99% 99% 98% 1% 1% 0% kFleiss 15% 15% -17% 99% 99% 98% 1% 1% -35% Informedness -15% -15% -15% -99% -99% -99% -99% -99% -99% Prevalence 50% 80% 20% 50% 80% 80% 50% 20% 20% Iprevalence 50% 20% 80% 50% 20% 20% 50% 80% 80% Bias 50% 71% 80% 50% 21% 20% 50% 21% 80% Ibias 50% 29% 20% 50% 79% 80% 50% 79% 20%              SkewR 100% 25% 400% 100% 25% 25% 100% 400% 400% SkewP 100% 41% 25% 100% 385% 400% 100% 385% 25% OddsRatio 100% 65% 1038% 100% 25% 25% 100% 104% 1542% ePowers 50% 63% 37% 50% 50% 50% 50% 68% 32% eCohen 50% 63% 32% 50% 32% 32% 50% 68% 32% eFleiss 50% 63% 50% 50% 50% 50% 50% 68% 50% kPowers -15% -15% -15% -99% -99% -99% -1% -1% -1% kCohen -15% -13% -7% -99% -47% -47% -1% -1% 0% kFleiss -15% -14% -46% -99% -99% -99% -1% -1% -37%  Table 3. Empirical Results for Accuracy and Kappa for Fleiss/Scott, Cohen and Powers. Shaded cells indicate misleading results, which occur for both Cohen and Fleiss Kappas.  
353
  
References  2nd i2b2 Workshop on Challenges in Natural Language Processing for Clinical Data (2008). http://gnode1.mib.man.ac.uk/awards.html (accessed 4 November 2011) 2nd Pascal Challenge on Hierarchical Text Classification http://lshtc.iit.demokritos.gr/node/48 (accessed 4 November 2011) N. Ailon. and M. Mohri (2010)  Preference-based learning to rank. Machine Learning 80:189-211. A. Ben-David. (2008a). About the relationship between ROC curves and Cohen?s kappa. Engineering Applications of AI, 21:874?882, 2008.  A. Ben-David (2008b). Comparison of classification accuracy using Cohen?s Weighted Kappa, Expert Systems with Applications 34 (2008) 825?832 Y. Benjamini and Y. Hochberg (1995). "Controlling the false discovery rate: a practical and powerful approach to multiple testing". Journal of the Royal Statistical Society. Series B (Methodological) 57 (1), 289?300.  D. G. Bonett & R.M. Price, (2005). Inferential Methods for the Tetrachoric Correlation Coefficient, Journal of Educational and Behavioral Statistics 30:2, 213-225  J. Carletta (1996). Assessing agreement on classification tasks: the kappa statistic. Computational Linguistics 22(2):249-254  N. J. Castellan, (1966). On the estimation of the tetrachoric correlation coefficient. Psychometrika, 31(1), 67-73. J. Cohen (1960). A coefficient of agreement for nominal scales. Educational and Psychological Measurement, 1960:37-46.  J. Cohen (1968). Weighted kappa: Nominal scale agreement with provision for scaled disagreement or partial credit. Psychological Bulletin 70:213-20. B. Di Eugenio and M. Glass (2004), The Kappa Statistic: A Second Look., Computational Linguistics 30:1 95-101. J. Entwisle and D. M. W. Powers (1998). "The Present Use of Statistics in the Evaluation of NLP Parsers", pp215-224, NeMLaP3/CoNLL98 Joint Conference, Sydney, January 1998 Sean Fitzgibbon, David M. W. Powers, Kenneth Pope, and C. Richard Clark (2007). Removal of EEG noise and artefact using blind source separation. Journal of Clinical Neurophysiology 24(3):232-243, June 2007 
P. A. Flach (2003). The Geometry of ROC Space: Understanding Machine Learning Metrics through ROC Isometrics, Proceedings of the Twentieth International Conference on Machine Learning (ICML-2003), Washington DC, 2003, pp. 226-233. J. L. Fleiss (1981). Statistical methods for rates and proportions (2nd ed.). New York: Wiley. A. Fraser & D. Marcu (2007). Measuring Word Alignment Quality for Statistical Machine Translation, Computational Linguistics 33(3):293-303. J. F?rnkranz & P. A. Flach (2005). ROC ?n? Rule Learning ? Towards a Better Understanding of Covering Algorithms, Machine Learning 58(1):39-77.  D. J. Hand (2009). Measuring classifier performance: a coherent alternative to the area under the ROC curve. Machine Learning 77:103-123. T. P. Hutchinson (1993). Focus on Psychometrics. Kappa muddles together two sources of disagreement: tetrachoric correlation is preferable. Research in Nursing & Health 16(4):313-6, 1993 Aug.  U. Kaymak, A. Ben-David and R. Potharst (2010), AUK: a sinple alternative to the AUC, Technical Report, Erasmus Research Institute of Management, Erasmus School of Economics, Rotterdam NL. K. Krippendorff (1970). Estimating the reliability, systematic error, and random error of interval data. Educational and Psychological Measurement, 30 (1),61-70. K. Krippendorff (1978). Reliability of binary attribute data. Biometrics, 34 (1), 142-144. J. Lafferty, A. McCallum. & F. Pereira. (2001). Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data. Proceedings of the 18th International Conference on Machine Learning (ICML-2001), San Francisco, CA: Morgan Kaufmann, pp. 282-289.  R. Leibbrandt & D. M. W. Powers, Robust Induction of Parts-of-Speech in Child-Directed Language by Co-Clustering of Words and Contexts. (2012). EACL Joint Workshop of ROBUS (Robust Unsupervised and Semi-supervised Methods in NLP) and UNSUP (Unsupervised Learning in NLP). P. J. G. Lisboa, A. Vellido & H. Wong (2000). Bias reduction in skewed binary classfication with Bayesian neural networks. Neural Networks 13:407-410. 
354
  
R. Lowry (1999). Concepts and Applications of Inferential Statistics. (Published on the web as http:// faculty.vassar.edu/lowry/webtext.html.) C. D.  Manning, and H. Sch?tze (1999). Foundations of Statistical Natural Language Processing. MIT Press, Cambridge, MA. J. H McDonald, (2007). The Handbook of Biological Statistics. (Course handbook web published as  http: //udel.edu/~mcdonald/statpermissions.html) J.C. Nunnally and Bernstein, I.H. (1994). Psychometric Theory (Third ed.). McGraw-Hill. K. Pearson and D. Heron (1912). On Theories of Association. J. Royal Stat. Soc. LXXV:579-652 P. Perruchet and R. Peereman (2004). The exploitation of distributional information in syllable processing, J. Neurolinguistics 17:97?119. D. Pfitzner, R. E. Leibbrandt and D. M. W. Powers (2009). Characterization and evaluation of similarity measures for pairs of clusterings, Knowledge and Information Systems, 19:3, 361-394 D. M. W. Powers (2003), Recall and Precision versus the Bookmaker, Proceedings of the International Conference on Cognitive Science (ICSC-2003), Sydney Australia, 2003, pp. 529-534. (See http:// david.wardpowers.info/BM/index.htm.) D. M. W. Powers (2008), Evaluation Evaluation, The 18th European Conference on Artificial Intelligence (ECAI?08) D. M W Powers, (2007/2011) Evaluation: From Precision, Recall and F-Factor to ROC, Informedness, Markedness & Correlation,  School of Informatics and Engineering, Flinders University, Adelaide, Australia, TR SIE-07-001, Journal of Machine Learning Technologies 2:1 37-63. https://dl-web.dropbox.com/get/Public/201101-Evaluation_JMLT_Postprint-Colour.pdf?w=abcda988 D. M. W. Powers, 2012. The Problem of Area Under the Curve. International Conference on Information Science and Technology, ICIST2012, in press. D. M. W. Powers and A. Atyabi, 2012. The Problem of Cross-Validation: Averaging and Bias, Repetition and Significance, SCET2012, in press. F. Provost and T. Fawcett. Robust classification for imprecise environments. Machine Learning, 44:203?231, 2001. RapidMiner (2011). http://rapid-i.com (accessed 4 November 2011). 
L. H. Reeker, (2000), Theoretic Constructs and Measurement of Performance and Intelligence in Intelligent Systems, PerMIS 2000. (See  http://www.isd.mel.nist.gov/research_areas/ research_engineering/PerMIS_Workshop/ accessed 22 December 2007.)  W. A. Scott (1955). Reliability of content analysis: The case of nominal scale coding. Public Opinion Quarterly, 19, 321-325. D. R. Shanks (1995). Is human learning rational? Quarterly Journal of Experimental Psychology, 48A, 257-279.  T. Sellke, Bayarri, M.J. and Berger, J. (2001), Calibration of P-values for testing precise null hypotheses, American Statistician 55, 62-71. (See http:// www.stat.duke.edu/%7Eberger/papers.html#p-value accessed 22 December 2007.) P. J. Smith, Rae, DS, Manderscheid, RW and Silbergeld, S. (1981). Approximating the moments and distribution of the likelihood ratio statistic for multinomial goodness of fit. Journal of the American Statistical Association 76:375,737-740. R. R. Sokal, Rohlf FJ (1995) Biometry: The principles and practice of statistics in biological research, 3rd ed New York: WH Freeman and Company. J. Uebersax (1987). Diversity of decision-making models and the measurement of interrater agreement. Psychological Bulletin 101, 140?146.  J. Uebersax (2009) http://ourworld.compuserve.com/ homepages/jsuebersax/agree.htm accessed 24 February 2011. M. J. Warrens (2010a), Inequalities between multi-rater kappas. Advances in Data Analysis and Classification 4:271-286. M. J. Warrens (2010b). A formal proof of a paradox associated with Cohen?s kappa. Journal of Classificaiton 27:322-332. M. J. Warrens (2010c). A Kraemer-type rescaling that transforms the Odds Ratio into the Weighted Kappa Coefficient. Psychometrika 75:2 328-330. M. J. Warrens (2011). Cohen?s linearly wieghted Kappa is a weighted average of 2x2 Kappas. Psychometrika 76:3, 471-486. D. A. Williams (1976). Improved Likelihood Ratio Tests for Complete Contingency Tables, Biometrika 63:33-37. I. H. Witten & E. Frank, (2005). Data mining (2nd ed.). London: Academic Press.  
355
Proceedings of the 2010 Workshop on Companionable Dialogue Systems, ACL 2010, pages 7?12,
Uppsala, Sweden, 15 July 2010. c?2010 Association for Computational Linguistics
MANA for the Ageing 
  David M W Powers, Martin H Luerssen, Trent W Lewis, Richard E Leibbrandt,  Marissa Milne,  John Pashalis and Kenneth Treharne AI Lab, School of Computer Science, Engineering and Mathematics, Flinders University, South Australia David.Powers@flinders.edu.au 
    Abstract 
We present a family of Embodied Conversa-tional Agents (ECAs) using Talking Head technology, along with a program of associ-ated research and user trials. Whilst antece-dents of our current ECAs include ?chatbots? desgined to pass the Turing Test (TT) or win a Loebner Prize (LP), our current agents are task-oriented Teaching Agents and Social Companions. The current focus for our re-search includes the role of emotion, expres-sion and gesture in our agents/companions, the explicit teaching of such social skills as recognizing and displaying appropriate ex-pressions/gestures, and the integration of template/database-based dialogue managers with more conversational TT/LP systems as well as with audio-visual speech/gesture rec-ognition/synthesis technologies. 1 Introduction Embodied Conversational Agents (ECAs) are animated or robotic agents that engage users in real-time dialogue. As a development of the Chatterbot TT/LP system, they address a funda-mental criticism of the Turing Test (TT) as  incarnated in the Loebner Prize (LP), viz. the lack of understanding of the world, the lack of understanding people, the lack of personality (Harnad,1992; Shapiro,1992). This has in fact been acknowledge by Loebner who has insisted that more than ?pen pal? conversation is neces-sary to win his $100K prize and Gold medal, and arranged design of a multimodal test [3]. At a technological level ECAs are a showcase for a large variety of language and human interface technologies including speech and face recogni-tion and synthesis, speech understanding and generation, and dialogue management.  How-ever, at a deeper level they are a platform for exploring affect ? the effect of multimodal fea-
tures, including in particular expression and ges-ture on the human user. Our aim is not to pass the Turing Test, al-though perhaps some descendant of our system will eventually do so.  Rather our focus is to pro-vide an effective agent for specific tasks where the limitations of current conversational compan-ions, or dialog technologies, serve to match rather than conflict with the application con-straints.  Whereas limiting the topic was seen as a trick and a cheat in the Loebner Prize, our aim is to demonstrate and develop useful technolo-gies and we are not interested in philosophical debates about intelligence. For these naturally constrained applications human level grammati-cal and syntactic understanding is not required, and the simple ELIZA-like approach of template matching is perfectly adequate as a first step (Weizenbaum, 1966). Our initial Talking Head was based around the Stelarc Prosthetic Head1 which combines multi-ple off-the-shelf components: keyboard input to a chatbot (AliceBot2) is linked to speech synthesis (IBM ViaVoice3) and 3D face rendering (Eye-matic4). More recently we have adopted Head X5 which is capable of generating a continuous, synchronized, optionally subtitled audiovisual speech stream in many different languages, with the ability to switch and modify voices and morph different faces at the same time as inter-acting with the user. The system is designed to be able to use different speech and face tech-nologies, and we in general use Microsoft?s SAPI6 for speech recognition and generation plus the FaceGen face generation technology7.                                                  1 http://www.stelarc.va.com.au/prosthetichead/ 2 http://www.alicebot.org/about.html 3 http://www.ibm.com/software/pervasive/viavoice.html 4 http://google.about.com/od/n/g/nevenvisiondef.htm 5 http://csem.flinders.edu.au/research/programs/th/ 6 http://msdn.microsoft.com/speech 7 http://www.facegen.com 
7
2 Teaching ECA Applications We have been predominantly exploring the ap-plication of our Talking Head as a virtual tutor of various subject areas. Initially our focus was lan-guage teaching/learning, but more recently de-mand for assistance with social teaching and as-sistant/companion applications has redirected our efforts. The Talking Head has been extended for teaching and environmental/social interaction purposes with intelligent software that integrates inputs from various input sources such as cam-eras, microphones, touch sensors, and the like. A situational model is constructed that represents the physical environment in which encounters with the user take place. A teaching application can monitor a student?s spoken utterances using both audio and video, can try to identify the stu-dent?s facial expressions, and can make reference to physical objects in the surroundings (including specially-devised teaching ?props?).  In addition to spoken utterances (the principal mode of output used in these applications), the Head may make use of audiovisual content pre-sented on additional computer monitors and pro-vide non-linguistic output that involves other sensory modalities, e.g. by making use of haptic devices. The multimodal capabilities of our ECA Teaching Agent are particularly valuable as they allow tutor and student to ground their interac-tion in a shared physical and social environment. Another invaluable aspect of our ECA for lan-guage teaching is the ability to model a student speaking the target language with a correct ac-cent and authentic facial expression and gestures, with their own face and voice.   It is important in teaching, and in particular in language teaching, not to give the student any examples of incorrect or poor grammar, accent, etc.  In a classroom context, students are held back and given poor example by other students, as well as by teachers who are not native speak-ers.  Seeing or hearing their own incorrect writ-ten or spoken examples is immensely counter-productive.  A good language teacher will reflect back, with appropriate degree of inflectional and gestural approbation, what they have said in cor-rected form.  Having a close-up face as well as a voice to emulate allows unconscious recognition of the cultural and linguistic characteristics that 
are part of language, including the way of hold-ing the mouth that affects even the way a person pauses or pronounces a neutral vowel sound, as well as the whole vowel system.  With languages that have new consonants or vowels, or different variants that are treated as allophonic in their first language, seeing how those sounds are made can be very important to achieving an authentic accent. Body language, hand gesture, volume and tone, are all parts of this that are beyond the competence of current speech recognition and synthesis. This ability for our ECA to control vocal and gestural ?accent? is thus a primary fo-cus of our research. One specific application of the Language Teaching Agent is for teaching children with a partial or complete hearing impairment to speak and lipread, where the face rather than the voice is their primary cue. A related one is for teaching corresponding speaking and signing skills to their families. A third is for teaching literacy to indigenous children who have reasonable verbal competence in English (in our case) as a national language, as well as their tribal language and often a trade language as a first and second lan-guage. Preliminary trials with comprehension testing found that appropriate facial expressions could enhance performance by a full grade point (Re-lated-reference, 2008). However, it also identi-fied that inappropriate expressions could negate this advantage ? in particular it seemed that in one case the ECA was seen as laughing at rather than laughing with the subject matter.  This has required us to modify our emotion model to in-clude humour with both positive and negative affect.  Moreover the emotional markup was per-formed by hand by one of the authors.  We are currently engaged in a complex sequence of staged trials to develop appropriate ways of elic-iting the desired AV expressions, getting multi-ple people to markup the texts, getting multiple subjects to classify and evaluate both real and head expressions, prior to undertaking a more comprehensive range of evaluations with the newly developed texts and markups, as well as a human head baseline.  Currently there is very little in the way of audiovisual (as opposed to single image only) corpora of spontaneous or acted emotions and expressions. 
8
2.1 Social Tutors for Children  Once we started working with organizations that provided assistance to those with various dis-abilities and disadvantages, a major common factor emerged: the social problems that go with the disability or with looking different, or even just being from a different social or cultural background. Social skills tutoring of children with autism, hearing impairment and other disor-ders looks to be a promising application of our ECA Teaching Agent, which can accurately model facial expressions, and whose appearance and interactions can be customized to meet learners? needs. Initially we have focused on children with Autism Spectrum Disorders and our initial trials are in this  ASD community. Individuals with autism typically lack the skills needed to participate successfully in every-day social interactions, particularly reading non-verbal cues. Additionally, sufferers often feel more comfortable learning through technology than with other people, who may be judgmental or unpredictable.  Two lesson sequences reflecting common dif-ficulties for children with autism were devel-oped, the first on basic conversation skills and the second on managing bullying. There was a 54% average improvement from pre- to post-testing for the managing bullying module and a 32% average improvement for the conversation skills module, showing clearly that learning can take place through this method (Related-Reference, 2009). 3 Independent Living for the Ageing The Memory, Appointment and Navigation As-sistant (MANA) system is a broad project to as-sist elderly people, and those suffering from de-mentia or other ailments, with independent living in the privacy of their own home and the dignity of an ongoing personal life style. 
3.1 MANA Calendar The initial MANA Calendar application util-izes Head X to provide a talking head companion with an interface to Google Calendar, allowing doctors/carers to enter appointments/events that are provided to patients by the Head on a flexible reminder schedule. Eventually, it will provide localized assistance on how to get to the ap-pointment based on public timetables, trip-planners and previous visits, but currently this information is supplied by carers. The initial Calendar application of the MANA system was developed in 2009 based on prelimi-nary input from an Alzheimer?s Association for deployment in the homes of Alzheimer?s suffer-ers. A preliminary exploration of potential faces and voices was conducted using a focus group approach organized through the NGO. For this preliminary stage we developed a dozen repre-sentative face/voice/script combinations and had representatives of the community select (indi-vidually and anonymously) their preferred face and voice. In associated discussion, it was appar-ent that a major influence was how authoritative the ECA appeared, and this was influenced by both face and voice (as well as the accent as their were only a couple of high quality voices avail-able for each of the different accents). Some comments indicated that the person was too young or not serious enough, while positive comments were along the lines of that?s matron, or an orderly, or that?s someone authoritative ? I?d do what they told me. At a later stage, if we have funds for a comprehensive study, it would be interesting to examine this formally, but for now we believe our ?experts? and have devel-oped our trial around the two most popular and authoritative male and female faces and voices.  As a final stage, we dynamically combined and altered their preferred faces to achieve those characteristics preferred by the group. 
Figure 1. Example of FaceGen morphing: female to male. Morphing is also used to provide speech gestures/visemes, emotion gestures/expressions, as well as explicit gestures like winks. 
9
  Figure 2. Four MANA faces selected by focus group.  These top four faces (Fig. 2) and the top four voices are those from which subjects are allowed to select the ECA for their trial.  As our aim is to show the ECA in the best possible light, we aim to please and give the subject control over who it is they are inviting into their home ? and they do seem to treat it as a person they are inviting. The system comprises the following major components (Self-Reference,2010): Web Calendar Appointment Interface: Essen-tially this interface works virtually identical to a standard Google calendar, where a doctor/carer can enter an appointment/event. The MANA Calendar then extracts the key aspects of the event (i.e: time, date, name, etc) and relays the information to the Calendar Manager. Calendar Manager and Synapse Module: The central Calendar Manager converts the informa-tion into a coherent human-like message to be delivered by the Thinking Head, upon either a set reminder time or upon a person-event. As  Synapse is used by system modules, intermodule communications ensure concurrent productions, e.g. the timing of voice audio and visemes (visual phonemes), appear as human-like as possible. Thinking Head and SAPI/Mary Integration: This new Thinking Head was designed using Face-Gen? software and incorporates Mary and Nuance voices, giving greater flexibility than using the original Stelarc face and voice. Face Detection and Motion Analysis Module: The system uses a camera which monitors the space the subject moves around in (or a part of it), and triggers upon detecting sufficient motion energy for a human body and a human face (us-
ing the algorithm of Viola & Jones (2004)). On detecting such a ?person-event?, the appointment message is then delivered to the subject. Speech Recognition Trigger Module: At any time the subject can query the MANA Calendar sys-tem by uttering ?MANA? and one of 3 key words ?appointment? (for upcoming appoint-ments), ?date? (current date) or ?time? (current time) subject to sufficiently low noise conditions. After making a timed announcement, the system enters a state in which the speech system is set to recognize several acknowledgements (like ?OK?).  MANA Calendar is being trialed in the homes of people with Alzheimer?s disease during the first half of 2010. We require that there is at least one carer or health worker who is able to enter calen-dar information into Google Calendar for the primary subject.  If we have a live in carer, or a spouse or relative in the carer role, we are also allowing them to enter their own appointments. Currently we are using a multiuser Microsoft Speech Recognition system that is not trained to the specific user.  For our (younger) voices tested pre-trial these gave pretty good results, but the system is sensitive to age and accent.  We have therefore adapted the study to provide training opportunities (human and system) for those who cannot initially use the speech recognition sys-tem successfully.   In addition, we do have a back up mouse or switch arrangement that allows such a user to use the system, but we are not permitting use of this option at present.  MANA Calendar is designed not to require use of either keyboard or mouse, and this is the condition that we are insisting on for our initial evaluation.  MANA is meant to appear as a companion, not as a computer. Another problem that we encountered is that the price point requested by the NGO was $1000-$1500, and for these experiments we are using a DELL Studio One which is really not quite fast enough for continuous speech.  Thus if it is left on trying to follow a conversation, it ends up filling up its buffer which gives unac-ceptable response times.  For this reason we not only require the user to say a specific keyword or name to get the attention of the system (by de-fault, MANA), we also require the user to be looking at the ECA (Viola and Jones, 2004) be-fore we try to interpret what they say as a com-mand.  This dramatically reduces the delays, al-though there is still a hiatus that is slightly longer than is comfortable (about two seconds rather than the desired one second). This problem does not appear when run on a more powerful  machine. 
10
3.2 Mobile Living A straightforward extension to MANA Calendar is to implement it on a mobile phone. We are currently exploring a couple of options for both technologies and platforms, the latter possibili-ties include the iPhone, Windows Mobile and Google Android, each of which has its pro?s and con?s. Already MANA Calendar has options to allow the carer/healthworker to enter directions, and eventually a library of directions will be built up so that commonly visited places/recurring events, will not need reentry of directions. With the Mo-bile extension, MANA can also popup with re-minders, make use of GPS, and let people know when to get off the bus, etc. This naturally com-bines in with current directions in GPS naviga-tion systems and aids, as well as systems for keeping track of the elderly. 3.3 Teaching/Training There are also several extensions of MANA en-visaged that make use of our Teaching ECA technology, including teaching social skills, pro-viding personalized family oriented reminders, and bridges to other technologies. We also aim to keep the client occupied and interested in current events, interacting with fam-ily and friends, and actively stimulated and men-tally engaged.  The selection and implementation of these specific task-oriented activities, as well as playing games or doing exercises, is not unique but is beyond the scope of this paper and will not be reviewed.  Our focus here is the natu-ralness and appropriateness of interaction, and exemplifying the kind of task-directed interac-tion which is not beyond the scope of current ECA technology. 3.4 Companion Robots One of the first news items on our technology described it as ?Companion Robots?, picking up very quickly on this potential, notwithstanding the crude Eliza-like interactions. Interestingly this comes round full circle to the kind of ethical questions about the use of computers that were raised in the mind of her creator by those who wanted to put her to work immediately (Weizen-baum, 1976). Weizenbaum argued that we shouldn?t have computerized psychiatrists who didn?t really understand their patients, even if they were using the same techniques the human experts employed. And the world agreed with him!  What has changed? 
In terms of ECA vs Eliza technology, not much ? the dialogue for HeadX is based on Al-ice, who whilst not much different in many ways from Eliza, at least had origins that sought to provide her with  visual connection to the world. The current versions of Alice, reflect AIML code that is very similar in principle to Eliza code, and don?t reflect anything of the real world except through the medium of canned dialogue. The issue of computer control is not limited to dialogue and the issue of competence ? computer controlled trains and buses and planes have been shown to be more reliable than humans under specified conditions, but still tend to be under direct supervision.  Computer-guided missiles are for better or worse under an even more re-moved level of control.  Our homes are full of gadgets, and most of us spend more time inter-acting with a computer and/or watching televi-sion than interacting directly with a person. So WE will leave the ethics to society to de-termine what it wants.  In an age where more people will be retired than working within the next twenty to forty years in most western coun-tries, a MANA-type companion looks to be more of a necessity than a desired outcome. Anecdotally, from our discussions with the NGOs and their staff, those who have had a dis-trict nurse or social worker visiting on a regular basis, tend to be happier with a human visitor than some technological solution.  But those who do not have someone visiting regularly are more apprehensive about having a stranger in the homes telling then what to do and sapping their independence, than they are having a technology that purports to do the same things, or mediates between them and a remote visitor who does not invade the privacy of their own home. 4 Conclusion: A Competent Companion In summary, WE see the key issue as compe-tence, and so will conclude by outlining our ap-proach to building the competence of MANA as a companion, rather than a calendar. Emotion, Affect and Attitude: As discussed, one of our main lines of research at present is exploring and expanding the range of expressions and emo-tions, developing an AV corpus of carefully elic-ited spontaneous natural emotions, and cross-evaluating versus acted/programmed expressions. AV Speech Recognition/Synthesis: Currently we can control the expression of our avatar through markup that is based on human judgements about what particular morphs of the face appear to show, and which are hand tuned to someone?s 
11
idiosyncratic idea of what a particular emotion or expression looks like ? it is already reasonably effective, but as an initial step has not been prop-erly evaluated, although our initial evaluation re-sults have shown that at least some of the markup is effective, and that some is not (without sepa-rating out at this stage the influence of the text and the mark up). The flip side of displaying an ECA face is recognizing human faces and ex-pressions. Similarly there is a much neglected auditory synthesis and recognition side that goes beyond phoneme and word. Our motto is ?one person?s noise is another person?s signal? and our aim is for both speech and noise to simultane-ously analyze and account for all individual dif-ferences, gender and age characteristics, emo-tion/affect/attitude and related human attributes, as well as explicit social and linguistic gestures and expressions, including rhythmic and tonal prosody. Dialogue Management and Understanding: Dia-logue management is a term WE don?t like in the context of companiable systems ? it derives from use as a database front end for ordering pizzas or taxis.  It has a very limited concept of under-standing related to the specific application, and Eliza or Alice type systems are perfectly capable of giving arbitrarily good results just by learning a greater range of template-response patterns.  Our companionable MANA system is grounded in the home environment and is being trained to talk about and monitor and react to what is going on in the home.  At the moment it is focused on body language and facial expression, and shares with the ASD system an aim to understand and react appropriately.  The Alice substrate already has a reasonably comprehensive dictionary built in, but all it can do with that is define things ? it can?t actually productively use the knowledge.  The Stelarc-Alice substrate also has at least three distinguishable personae built in ? one who is male and a performance artist, one who is female and pretending to be human, and one who is neu-ter and surprised that you thought it should have that human characteristic. The latter two are an amalgam of hundreds of different program-mer/user enhancements, whilst the Stelarc per-sona is the work of a single person and reflects his wry humour so that at times it does feel like you are talking to him.  We are building in access to a full encyclopedia, and the ability to answer a wide variety of questions from each entry.  But this also is superficial without the ability to learn and reason. Learning and Reasoning: From a technological Artificial Intelligence perspective, our primary focus is learning. Children learn from the time 
they are born (actually probably more like from about three months before they are born) and their learning and play are very similar to the re-search and experimentation of a scientist. Piagetian Psycholinguistics, and Piaget?s 20 plus books on specific aspects of child learning, de-velopment and reasoning, views learning and reasoning as developing hand in hand, with the little scientists developing new insights and deeper reasoning models, and thus enabling learning more about their world, society, culture and language. Learning to speak and understand language involves making noises and making the connection between the vocal tract/facial articu-lations/gestures and the heard sounds.  Unsuper-vised learning using supervised techniques is possible using cross-modal training. Approaches from Computational Intelligence based on simple models from genetics, ant colonies and bee swarms, also provide mechanisms and analogies that help see how a system can continuously adapt and improve. Generalization and reasoning are part of this.  Our ability to learn language is not independent of our ability to understand the world but an extension of it, and the constraints and nature of language are strongly influenced by the constraints and nature of the world.  This also includes meta-reasoning: our reasoning about the consequences of our logic, decisions and behaviour. References Stevan Harnad (1992) The Turing test is not a trick: Turing indistinguishability is a scientific criterion. SIGART Bulletin 3(4) pp. 9 - 10. David M W Powers (1998) The total Turing test and the Loebner prize, Proceedings of the Joint Confer-ences on New Methods in Language Processing and Computational Natural Language Learning, ACL, pp.279-280. M. Schr?der & J. Trouvain (2003). The German Text-to-Speech Synthesis System MARY: A Tool for Research, Development and Teaching. Interna-tional Journal of Speech Technology, 6, pp. 365-377. Stuart C Shapiro (1992) The Turing test and the economist. SIGART Bulletin 3(4) pp. 10-11. Paul A. Viola and Michael J. Jones, 2004. Robust real-time face detection, International Journal of Computer Vision, vol. 57, pp. 137?154. Joseph Weizenbaum (1966), ELIZA - a computer pro-gram for the study of natural language communica-tion between man and machine, CACM 9 (1): 36?45 Joseph Weizenbaum (1976), Computer Power and Human Reason: From Judgment To Calculation, San Francisco: W. H. Freeman 
12
