Proceedings of BioNLP Shared Task 2011 Workshop, pages 56?64,
Portland, Oregon, USA, 24 June, 2011. c?2011 Association for Computational Linguistics
BioNLP shared Task 2011 - Bacteria Biotope 
Robert Bossy1, Julien Jourde1, Philippe Bessi?res1, Maarten van de Guchte2,  
Claire N?dellec1 
 
1MIG UR1077 2Micalis UMR 1319  
INRA, Domaine de Vilvert 
78352 Jouy-en-Josas, France 
forename.name@jouy.inra.fr 
 
 
Abstract 
This paper presents the Bacteria Biotope 
task as part of the BioNLP Shared Tasks 
2011. The Bacteria Biotope task aims at 
extracting the location of bacteria from 
scientific Web pages. Bacteria location is a 
crucial knowledge in biology for phenotype 
studies. The paper details the corpus 
specification, the evaluation metrics, 
summarizes and discusses the participant 
results.  
1 Introduction 
The Bacteria Biotope (BB) task is one of the five 
main tasks of the BioNLP Shared Tasks 2011. The 
BB task consists of extracting bacteria location 
events from Web pages, in other words, citations 
of places where a given species lives. Bacteria 
locations range from plant or animal hosts for 
pathogenic or symbiotic bacteria, to natural 
environments like soil or water. Challenges for 
Information Extraction (IE) of relations in Biology 
are mostly devoted to the identification of bio-
molecular events in scientific papers where the 
events are described by relations between named 
entities, e.g. genic interactions (N?dellec, 2005), 
protein-protein interactions (Pyysalo et al, 2008), 
and more complex molecular events (Kim et al, 
2011). However, this far from reflects the diversity 
of the potential applications of text mining to 
biology. The objective of previous challenges has 
mostly been focused on modeling biological 
functions and processes using the information on 
elementary molecular events extracted from text. 
The BB task is the first step towards linking 
information on bacteria at the molecular level to 
ecological information. The information on 
bacterial habitats and properties of these habitats is 
very abundant in literature, in particular in 
Systematics literature (e.g. International Journal of 
Systematic and Evolutionary Microbiology), 
however it is rarely available in a structured way 
(Hirschman et al, 2008; Tamames and de Lorenzo, 
2009). The NCBI GenBank nucleotide isolation 
source field (GenBank) and the JGI Genome 
OnLine Database (GOLD) isolation site field are 
incomplete with respect to the microbial diversity 
and are expressed in natural language. The two 
critical missing steps in terms of biotope 
knowledge modeling are (1) the automatic 
population of databases with organism/location 
pairs that are extracted from text, and (2) the 
normalization of the habitat name with respect to 
biotope ontologies. The BB task mainly aims at 
solving the first information extraction issue. The 
second classification issue is handled through the 
categorization of locations into eight types. 
2 Context 
According to NCBI statistics there are nearly 900 
bacteria with complete genomes, which account 
for more than 87% of total complete genomes. 
Consequently, molecular studies in bacteriology 
are shifting from species-centered to full diversity 
investigation. The current trend in high-throughput 
experiments targets diversity related fields, 
typically phylogeny or ecology. In this context, 
adaptation properties, biotopes and biotope 
properties become critical information. Illustrative 
questions are: 
56
? Is there a phylogenetic correlation between 
species that share the same biotope? 
? What are common metabolic pathways of 
species that live in given conditions, especially 
species that survive in extreme conditions? 
? What are the molecular signaling patterns in 
host relationships or population relationships 
(e.g. in biofilms)? 
Recent metagenomic experiments produce 
molecular data associated with a habitat rather than 
a single species. This raises new challenges in 
computational biology and data integration, such 
as identifying known and new species that belong 
to a metagenome. 
Not only will these studies require 
comprehensive databases that associate bacterial 
species to their habitat, but they also require a 
formal description of habitats for property 
inference. The bacteria biotope description is 
potentially very rich since any physical object, 
from a cell to a continent, can be a bacterial 
habitat. However these relations are much simpler 
to model than with general formal spatial 
ontologies. A given place is a bacterial habitat if 
the bacteria and the habitat are physically in 
contact, while the relative position of the bacteria 
and its dissemination are not part of the BB task 
model.  
The BB Task requires the locations to be 
assigned different types (e.g. soil, water). We view 
location typing as a preliminary step of more fine-
grained modeling in location ontologies. Some 
classifications for bacteria biotopes have been 
proposed by some groups (Floyd et al, 2005; 
Hirschman et al, 2008; Field et al, 2008; 
Pignatelli et al, 2009). The Environment Ontology 
project (EnvO) is developing an ambitious detailed 
environment ontology for supporting standard 
manual annotation of environments of all types of 
organisms and biological samples (Field et al, 
2008). In a similar way, the GOLD group at JGI 
defined a standard classification for bacteria 
population metagenome projects. Developing 
methods for the association of such biotope classes 
to organisms remains an open question. EnvDB 
(Pignatelli et al, 2009) is an attempt to inventory 
isolation sources of bacteria as recorded in 
GenBank and to map them to a three level 
hierarchy of 71 biotope classes. The assignment of 
bacterial samples in one of the EnvDB classes is 
supported by a text-mining tool based on a Na?ve 
Bayes (NB) classifier applied to a bag of words 
representing the associated reference title and 
abstract. Unfortunately, the low number of paper 
references associated with the isolation source field 
(46 %) limits the scope of the method. 
The BB task has a similar goal, but directly 
applies to natural language texts thus avoiding the 
issue of database incompleteness. As opposed to 
database-based approaches, biotope information 
density is higher but the task has to include 
bacteria and location identification, as well as 
information extraction to relate them.  
The eight types of locations in the BB task 
capture high-level information for further ontology 
mappings.  The location types are Host, HostPart, 
Geographical and Environmental. Environmental 
is broadly defined to qualify locations that are not 
associated to hosts, in a similar way to what was 
described by Floyd et al (Floyd et al, 2005). In 
addition, the BB task types exclude artificially 
constructed biotopes (e.g. bacteria growing in labs 
on a specific medium) and laboratory mutant 
bacteria. The Environmental class is divided into 
Food, Medical, Soil and Water. Locations that are 
none of these subtypes are classified as 
Environmental. 
The exact geographical location (e.g. latitude 
and longitude coordinates) has less importance 
here than in eukaryote ecology because most of the 
biotope properties vary along distances smaller 
than the precision of the current positioning 
technologies. Geographical names are only useful 
in bacteria biotope studies when the physico-
chemical properties of the location can be inferred. 
For the sake of simplicity, the locations of bacteria 
host (e.g. the stall of the infected cow) are not 
taken into account despite their richness (Floyd et 
al., 2005). 
The important information conveyed by the 
locations, especially of Environment type, is the 
function of the bacterium in its ecosystem rather 
than the substance of the habitat. Indeed the final 
goal is to extract habitat properties and bacteria 
phenotypes. Beyond the identification of locations, 
their properties (e.g. temperature, pH, salinity, 
oxygen) are of high interest for phenotypes (e.g. 
thermophily, acidophily, halophily) and trophism 
studies. This information is difficult to extract, and 
is often incomplete or even not available in papers 
(Tamames and de Lorenzo., 2009). Hopefully, 
some properties can be automatically retrieved 
57
with the help of specialized databases, which give 
the physico-chemical properties of locations, such 
as hosts (plant, animal, human organs), soils (see 
WebSoilSurvey, Corine Land Cover), water, or 
chemical pollutants. 
From a linguistic point of view, the BB task 
differs from other IE molecular biology tasks while 
it raises some issues common to biomedicine and 
more general IE tasks. The documents are 
scientific Web pages intended for non-experts such 
as encyclopedia notices. The information is dense 
compared to scientific papers. Documents are 
structured as encyclopedia pages, with the main 
focus on a single species or a few species of the 
same genus or family. The frequency of anaphora 
and coreferences is unusually high. The location 
entities are denoted by complex expressions with 
semantic boundaries instead of rigid designators.  
3 Task description 
The goal of the BB task is illustrated in Figure 1.  
 
Bifidobacterium longum . This organism is found in 
adult humans  and formula fed infants  as a normal 
component of gut  flora. 
Figure 1. Example of information to be extracted 
in the BB Task. 
 
The entities to be extracted are of two main 
types: bacteria and locations. They are text-bound 
and their position has to be predicted. Relations are 
of type Localization between bacteria and 
locations, and PartOf between hosts and host parts. 
In the example in Figure 1, Bifidobacterium 
longum is a bacterium. adult humans and formula 
fed infants denote host locations for the bacteria. 
gut is also a bacteria location, part of the two hosts 
and thus of type host part.  
Coreference relations between entities denoting 
the same information represent valid alternatives 
for the relation arguments. For example, the three 
taxon names in Figure 2 are equivalent. 
 
 
 
The green sulfur bacteria  (GSB ; Phylum Chlorobi ) 
are commonly found in aquatic environments . 
Figure 2. Coreference example. 
 
The coreference relation between pairs of 
entities is binary, symmetric and transitive. 
Coreference sets are equivalence sets defined as 
the transitive closure of the binary coreference 
relation. Their annotation is provided in the 
training and development sets, but it does not have 
to be predicted in the test set. 
4 Corpus description 
The corpus sources are the following bacteria 
sequencing project Web pages: 
? Genome Projects referenced at NCBI; 
? Microbial Genomics Program at JGI; 
? Bacteria Genomes at EBI; 
? Microorganisms sequenced at Genoscope; 
? Encyclopedia pages from MicrobeWiki. 
The documents are publicly available and quite 
easy to understand by non-experts compared to 
scientific papers on similar topics. From the 2,086 
downloaded documents, 105 were randomly 
selected for the BB task. A quarter of the corpus 
was retained for test evaluation. The rest was split 
into train and development sets. Table 1 gives the 
distribution of the entities and relations per corpus. 
The distribution of the five document sources in 
the test corpus reflects the distribution of the 
training set and no other criteria. Food is therefore 
underrepresented.  
 
 Training+Dev Test 
Document 78 (65 + 13) 27 (26 %) 
Bacteria 538 121 (18 %) 
Environment 62 16 (21 %) 
Host 486 101 (17 %) 
HostPart 217 84 (28 %) 
Geographical 111 25 (18 %) 
Water 70 21 (23 %) 
Food 46 0 (0 %) 
Medical 24 2 (8 %) 
Soil 26 20 (43 %) 
Coreference 484 100 (17 %) 
Total entities 1,580 390 
58
 Training+Dev Test 
Localization 998 250 (20 %) 
Part of Host 204 78 (28 %) 
Total relations 1,202 328 
Table 1. Corpus Figures. 
5 Annotation methodology 
HTML tags and irrelevant metadata were stripped 
from the corpus. The Alvis pipeline (N?dellec et 
al., 2009) pre-annotated the species names that are 
potential bacteria and host names. A team of 7 
scientists manually annotated the entities, 
coreferences and relations using the Cadixe XML 
editor (Cadixe). Each document was processed by 
two independent annotators in a double-blind 
manner. Conflicts were automatically detected, 
resolved by annotator negotiation and irrelevant 
documents (e.g. without bacterial location) were 
removed. The remaining inconsistencies among 
documents were resolved by the two annotators 
assisted by a third person acting as an arbitrator. 
The annotator group designed the detailed 
annotation guidelines in two phases. First, they 
annotated a set of 10 documents, discussed the 
options and wrote detailed guidelines with 
representative and illustrative examples. During 
the annotation of the rest of the documents, new 
cases were discussed by email and the guidelines 
amended accordingly. 
Location types. The main issues under debate 
were the definition of location types, boundaries of 
annotations and coreferences. Additional 
annotation specifications concerned the exclusion 
of overly general locations (e.g. environment, 
zone), artificially constructed biotopes and indirect 
effects of bacteria on distant places. For instance, a 
disease symptom occurring in a given host part 
does not imply the presence of the bacteria in this 
place, whereas infection does. Boundaries of types 
were also an important point of discussion since 
the definite formalization of habitat categories was 
at stake. For instance we decided to exclude land 
environment citations (fields, deserts, savannah, 
etc.) from the type Soil, and thus enforced a strict 
definition of soil bacteria. The most controversial 
type was host parts. We decided to include fluids, 
secretions and excretions (which are not strictly 
organs). Therefore, the host parts category required 
specifications to determine at which point of 
dissociation from the original host is a habitat not a 
host part anymore (e.g. mother?s milk vs. industrial 
milk, rhizosphere as host part instead of soil). 
Boundaries. The bacteria name boundaries do 
not include any external modifiers (e.g. two A. 
baumannii strains). Irrelevant modifiers of 
locations are considered outside the annotation 
boundaries (e.g. responsible for a hospital 
epidemic). All annotations are contiguous and span 
on a single fragment in the same way as the other 
BioNLP Shared Tasks. This constraint led us to 
consider cases where several annotations occur 
side by side. The preferred approach was to have 
one distinct annotation for each different location 
(e.g. contact with infected animal products or 
through the air). In the case of head or modifier 
factorization, the annotation depends on the 
information conveyed by the factorized part. If the 
head is not relevant to determine the location type, 
then each term is annotated separately (e.g. 
tropical and temperate zones). Conversely, if the 
head is the most informative with regards to the 
location type, a single annotation spans the whole 
fragment (fresh and salt water). 
Coreferences. Two expressions are considered 
as coreferential and thus valid solution alternatives, 
if they convey the same information. For instance, 
complete taxon names and non-ambiguous 
abbreviations are valid alternatives (e.g. Borrelia 
garinii vs. B. garinii), while ambiguous anaphora 
ellipses are not (e.g. as in ?[..] infected with 
Borrelia duttonii. Borrelia then multiplies [..]?). 
The ellipsis of the omitted specific name 
(dutotonii) leaves the ambiguous generic name 
(Borrelia). 
The full guidelines document is available for 
download on the BioNLP Shared Task Bacteria 
Biotope page1. 
6 Evaluation procedure 
6.1 Campaign organization 
The training and development corpora with the 
reference annotations were made available to the 
participants by December 1st 2010 on the BioNLP 
Shared Tasks pages together with the evaluation 
software. The test corpus, which does not contain 
                                                   
1 https://sites.google.com/site/bionlpst/home/bacteria-biotopes/ 
BioNLP-ST_2011_Bacteria_Biotopes_Guidelines.pdf 
59
any annotation, was made available by March, 1st 
2011. The participants sent the predicted 
annotations to the BioNLP Shared Task organizers 
by March 10th. Each participant submitted a single 
final prediction set. The detailed evaluation results 
were computed, provided to the participants and 
published on the BioNLP website by March, 11th.  
6.2 Evaluation metrics 
The evaluation metrics are based on precision, 
recall and the F-measure. In the following section, 
the PartOf and Localization relations will both be 
referred to as events. The metrics measure the 
accuracy of the participant prediction of events 
with respect to the reference annotation of the test 
corpus. Predicted entities that are not event 
arguments are ignored and they do not penalize the 
score. Each event Er in the reference set is matched 
to the predicted event Ep that maximizes the event 
similarity function S. The recall is the sum of the S 
results divided by the number of events in the 
reference set. Each event Ep in the predicted set is 
matched to the reference event Er that maximizes 
S. The precision is the sum of the S results divided 
by the number of events in the predicted set. 
Participants were ranked by the F-score defined as 
the harmonic mean between precision and recall. 
Eab, the event similarity between a reference 
Localization event a and a predicted Localization 
event b, is defined as: 
Eab = Bab . Tab . Jab 
? Bab is the bacteria boundary component defined 
as: if the Bacterium arguments of both the 
predicted and reference events have exactly the 
same boundaries, then Bab = 1, otherwise Bab = 
0. Bacteria name boundary matching is strict 
since boundary mistakes usually yield a 
different taxon. 
? Tab is the location type prediction component 
defined as: if the Location arguments of both 
the predicted and reference events are of the 
same type, then Tab = 1, otherwise Tab = 0.5. 
Thus type errors divide the score by two. 
? Jab is the location boundary component defined 
as: if the Location arguments of the predicted 
and reference events overlap, then 
1?+=
ab
ba
ab OV
LENLENJ  
where LENa and LENb are the length of the 
Localization arguments of predicted and 
reference events, and OVab is the length of the 
overlapping segment between the Localization 
arguments of the predicted and reference 
events. If the arguments do not overlap, then Jab 
is 0. This formula is a Jaccard index applied to 
overlapping segments. Location boundary 
matching is relaxed, though the Jaccard index 
rewards predictions that approach the reference. 
For PartOf events between Hosts and HostParts, 
the matching score Pab is defined as: if the Host 
arguments of the reference and predicted events 
overlap and the Part arguments of the reference 
and predicted events overlap, then Pab = 1, 
otherwise Pab = 0. Boundary matching of PartOf 
arguments is relaxed, since boundary mistakes are 
already penalized in Eab. 
Arguments belonging to the same coreference 
set are strictly equivalent. In other words, the 
argument in the predicted event is correct if it is 
equal to the reference entity or to any item in the 
reference entity coreference set. 
7 Results  
7.1 Participating systems 
Three teams submitted predictions to the BB task. 
The first team is from the University of Turku 
(UTurku); their system is generic and produced 
predictions for every BioNLP Shared Task. This 
system uses ML intensely, especially SVMs, for 
entity recognition, entity typing and event 
extraction. UTurku adapted their system for the BB 
task by using specific NER patterns and external 
resources (Bj?rne and Salakoski, 2011). 
The second team is from the Japan Advanced 
Institute of Science and Technology (JAIST); their 
system was specifically designed for this task. 
They used CRF for entity recognition and typing, 
and classifiers for coreference resolution and event 
extraction (Nguyen and Tsuruoka, 2011). 
The third team is from Bibliome INRA; their 
system was specifically designed for this task 
(Ratkovik et al, 2011). This team has the same 
affiliation as the BB Task authors, however great 
care was taken to prevent communication on the 
subject between task participants and the test set 
annotators. 
60
The results of the three submissions according to 
the official metrics are shown in Table 2. The 
scores are micro-averaged: Localization and 
PartOf relations have the same weight. Given the 
novelty and the complexity of the task, these first 
results are quite encouraging. Almost half of the 
relations are correctly predicted. The Bibliome 
team achieved the highest F-measure with a 
balanced recall and precision (45%). 
 
 Recall Precision F-score 
Bibliome 45 45 45 
JAIST 27 42 33 
UTurku 17 52 26 
 
Table 2. Bacteria Biotope Task results. 
7.2 Systems description and result analysis 
All three systems perform the same distinct sub-
tasks: bacteria name detection, detection and 
typing of locations, coreference resolution and 
event extraction. The following description of the 
approaches used by the three systems in each 
subtask will be supported by intermediate results. 
Bacteria name detection. Interestingly the three 
participants used three different resources for the 
detection of bacteria names: the List of Prokaryotic 
Names with Standing in Nomenclature (LPNSN) 
by UTurku, names in the genomic BLAST page of 
NCBI by JAIST and the NCBI Taxonomy by 
Bibliome. 
 
Bibliome 84 
JAIST 55 
UTurku 16 
Table 3. Bacteria entity recall. 
 
Table 3 shows a disparity in the bacteria entity 
recall of participants. The merits of each resource 
cannot be deduced directly from these figures since 
they have been exploited in different manners. 
UTurku and JAIST systems injected the resource 
as features in a ML algorithm, whereas Bibliome 
directly projected the resource on the corpus with 
additional rule-based abbreviation detection. 
However there is some evidence that the 
resources have a major impact on the result. 
According to Sneath and Brenner (1992) LPNSN 
is necessarily incomplete. NCBI BLAST only 
contains names of species for which a complete 
genome has been published. The NCBI Taxonomy 
used by INRA only contains names of taxa for 
which some sequence was published. It appears 
that all the lists are incomplete. However, the 
bacteria referenced by the sequencing projects, 
which are mentioned in the corpus should all be 
recorded by the NCBI Taxonomy. 
Location detection and typing. As stated before, 
locations are not necessarily denoted by rigid 
designators. This was an interesting challenge that 
called for the use of external resources and 
linguistic analysis with a broad scope. 
UTurku and JAIST both used WordNet, a 
sensible choice since it encompasses a wide 
vocabulary and  is also structured with synsets and 
hyperonymy relations. The WordNet entries were 
injected as features in the participant ML-based 
entity recognition and typing subsystems. 
It is worth noting that JAIST also used word 
clustering based on MEMM for entity detection. 
This method has things in common with 
distributional semantics. JAIST experiments 
demonstrated a slight improvement using word 
clustering, but further exploration of this idea may 
prove to be valuable. 
Alternatively, the Bibliome system extracted 
terms from the corpus using linguistic criteria 
classified them as locations and predicted their 
type, by comparing them to classes in a habitat-
specific ontology. This prediction uses both 
linguistic analysis of terms and the hierarchical 
structure of the ontology. Bibliome also used 
additional resources for specific types: the NCBI 
Taxonomy for type Host and Agrovoc countries 
for type Geographical. 
 Bibliome JAIST UTurku 
Host 82 49 28 
Host part 72 36 28 
Geo. 29 60 53 
Environment 53 10 11 
Water 83 32 2 
Soil 86 37 34 
Table 4. Location entity recall by type. The 
number of entities of type Food and Medical in the 
test set is too low to be significant. The scores are 
computed using Tab and Jab. 
61
 
The location entity recall in Table 4 shows that 
Bibliome consistently outperformed the other 
groups for all types except for Geographical. This 
demonstrates the strength of exploiting a resource 
with strong semantics (ontology vs. lexicon) and 
with mixed semantic and linguistic rules. 
In order to evaluate the impact of Location entity 
boundaries and types, we computed the final score 
by relaxing Tab and Jab measures. We re-defined Tab 
as always equal to 1, in other words the type of the 
localization was not evaluated. We also re-defined 
Jab as: if the Location arguments overlap, then Jab = 
1, otherwise Jab = 0. This means that boundaries 
were relaxed. The relaxed scores are shown in 
Table 5. While the difference is not significant for 
JAIST and UTurku, the Bibliome results exhibit a 
9 point increase. This demonstrates that the 
Bibliome system is efficient at predicting which 
entities are locations, while the other participants 
predict more accurately the boundaries and types. 
 Recall Prec. F-score Diff. 
Bibliome 54 54 54 +9 
JAIST 29 45 35 +2 
UTurku 19 56 28 +2 
Table 5. Participants score using relaxed location 
boundaries and types. 
Coreference resolution. The corpus exhibits an 
unusual number of anaphora, especially bacteria 
coreferences since a single bacterium species is 
generally the central topic of a document. The 
Bibliome submission is the only one that 
performed bacteria coreference resolution. Their 
system is rule-based and dealt with referential ?it?, 
bi-antecedent anaphora and more importantly 
sortal anaphora. The JAIST system has a bacteria 
coreference module based on ML. However the 
submission was done without coreference 
resolution since their experiments did not show 
any performance improvement. 
 
Event extraction. Both UTurku and JAIST 
approached the event extraction as a classification 
task using ML (SVM). Bibliome exploited the co-
occurrence of arguments and the presence of 
trigger words from a predefined list. Both UTurku 
and Bibliome generate events in the scope of a 
sentence, whereas JAIST generates events in the 
scope of a paragraph. 
As shown in Table 6, UTurku achieved the best 
score for PartOf events. For all participants, the 
prediction is often correct (between 60 and 80%) 
while the recall is rather low (20 to 32%). 
 
  Recall Precis. F-score 
 Host 61 48 53 
 Host part 53 42 47 
 Geo. 13 38 19 
B. Env. 29 24 26 
 Water 60 55 57 
 Soil 69 59 63 
 Part-of 23 79 36 
 Host 30 43 36 
 Host part 18 68 28 
 Geo. 52 35 42 
J. Env. 5 0 0 
 Water 19 27 23 
 Soil 21 42 28 
 Part-of 31 61 41 
 Host 15 51 23 
 Host part 9 40 15 
 Geo. 32 40 36 
U. Env. 6 50 11 
 Water 1 7 2 
 Soil 12 21 15 
 Part-of 32 83 46 
Table 6. Event extraction results per type. 
 
Conversely, the score of the Localization relation 
by UTurku has been penalized by its low 
recognition of bacteria names (16%). This strongly 
affects the score of Localizations since the 
bacterium is the only expected agent argument. 
The good results of Bibliome are partly explained 
by its high bacteria name recall of 84%. 
The lack of coreference resolution might penalize 
the event extraction recall. To test this hypothesis, 
we computed the recall by taking only into account 
events where both arguments occur in the same 
sentence. The goal of this selection is to remove 
most events denoted through a coreference. The 
recall difference was not significant for Bibliome 
and JAIST, however UTurku recall raised by 12 
points (29%). That experiment confirms that 
UTurku low recall is explained by coreferences 
62
rather than the quality of event extraction. The 
paragraph scope chosen by JAIST probably 
compensates the lack of coreference resolution. 
As opposed to Bibliome, the precision of the 
Localization relation prediction by JAIST and 
UTurku, is high compared to the recall, with a 
noticeable exception of geographical locations. 
The difference between participants seems to be 
caused by the geographical entity recognition step 
more than the relation itself. This is shown by the 
difference between the entity and the event recall 
(Table 4 and 6 respectively).. The worst predicted 
type is Environment, which includes diverse 
locations, such as agricultural, natural and 
industrial sites and residues. This reveals 
significant room for improvement for Water, Soil 
and Environment entity recognition. 
8 Discussion 
The participant papers describe complementary 
methods for tackling BB Task?s new goals. The 
novelty of the task prevents participants from 
deeply investing in all of the issues together. 
Depending on the participants, the effort was 
focused on different issues with various 
approaches: entity recognition and anaphora 
resolution based on extensive use of background 
knowledge, and relation prediction based on 
linguistic analysis of syntactic dependencies. 
Moreover, these different approaches revealed to 
be complementary with distinct strengths and 
limitations. In the future, one may expect that the 
integration of these promising approaches will 
improve the current score. 
The corpus of BioNLP BB Task 2011 consists 
of a set of Web pages that were selected for their 
readability. However, some corpus traits make the 
IE task more difficult compared to scientific 
papers. For example, the relaxed style of some 
pages tolerates some typographic errors (e.g. 
morrow instead of marrow) and ambiguous 
anaphora. The genome sequencing project 
documents aim at justifying the sequencing of 
bacteria. This results in abundant descriptions of 
potential uses and locations that should not be 
predicted as actual locations. Their correct 
prediction requires complex analysis of modalities 
(possibility, probability, negation). Some pages 
describe the action of hosted bacteria at the 
molecular level, such as cellular infection. Terms 
related to the cell are ambiguous locations because 
they may refer to either bacteria or host cells. 
Scientific papers form a much richer source of 
bacterial location information that is exempt from 
such flaws. However, as opposed to Web pages, 
most of them are not publicly available and they 
are in PDF format. 
The typology of locations was designed 
according to the BB Task corpus with a strong bias 
towards natural environments since bioremediation 
and plant growth factor are important motivations 
for bacteria sequencing. It could be necessary to 
revise it according to a broader view of bacterial 
studies where pathogenicity and more generally 
human and animal health are central issues. 
9 Conclusion 
The Bacteria Biotope Task corpus and objectives 
differ from molecular biology text-mining of 
scientific papers. The annotation strategy and the 
analysis of the participant results contributed to the 
construction of a preliminary review of the nature 
and the richness of its linguistic specificities. The 
participant results are encouraging for the future of 
the Bacteria Biotope issue. The degree of 
sophistication of participating systems shows that 
the community has technologies, which are mature 
enough to address this crucial biology question. 
However, the results leave a large room for 
improvement. 
The Bacteria Biotope Task was an opportunity 
to extend molecular biology text-mining goals 
towards the support of bacteria biodiversity studies 
such as metagenomics, ecology and phylogeny. 
The prediction of bacterial location information is 
the very first step in this direction. The abundance 
of scientific papers dealing with this issue and 
describing location properties form a potentially 
rich source for further extensions. 
Acknowledgments 
The authors thank Valentin Loux for his valuable 
contribution to the definition of the Bacteria 
Biotope task. This work was partially supported by 
the French Quaero project. 
63
References 
Jari Bj?rne and Taio Salakoski. 2011. Generalizing 
Biomedical Event Extraction. Proceedings of the 
BioNLP 2011 Workshop Companion Volume for 
Shared Task. 
Cadixe. http://caderige.imag.fr/Articles/CADIXE-XML-
Annotation.pdf 
Corine Land Cover. 
http://www.eea.europa.eu/themes/landuse/interactive/
clc-download 
EnvDB database. http://metagenomics.uv.es/envDB/ 
EnvO Project. 
http://gensc.org/gc_wiki/index.php/EnvO_Project  
Dawn Field [et al. 2008. Towards a richer description 
of our complete collection of genomes and 
metagenomes: the ?Minimum Information about a 
Genome Sequence? (MIGS) specification. Nature 
Biotechnology. 26: 541-547. 
Melissa M. Floyd, Jane Tang, Matthew Kane and David 
Emerson. 2005. Captured Diversity in a Culture 
Collection: Case Study of the Geographic and 
Habitat Distributions of Environmental Isolates Held 
at the American Type Culture Collection. Applied 
and Environmental Microbiology. 71(6):2813-23. 
GenBank. http://www.ncbi.nlm.nih.gov/  
GOLD. http://www.genomesonline.org/cgi-
bin/GOLD/bin/gold.cgi 
Lynette Hirschman, Cheryl Clark, K. Bretonnel Cohen, 
Scott Mardis, Joanne Luciano, Renzo Kottmann, 
James Cole, Victor Markowitz, Nikos Kyrpides, 
Norman Morrison, Lynn M. Schriml, Dawn Field. 
2008. Habitat-Lite: a GSC case study based on free 
text terms for environmental metadata. Omics. 
12(2):129-136. 
Jin-Dong Kim, Tomoko Ohta, Sampo Pyysalo, 
Yoshinobu Kano, Jun?ichi Tsujii. 2010. Extracting 
bio-molecular events from literature - the BioNLP?09 
shared task. Special issue of the International 
Journal of Computational Intelligence. 
MicrobeWiki. 
http://microbewiki.kenyon.edu/index.php/MicrobeWi
ki  
Microbial Genomics Program at JGI. http://genome.jgi-
psf.org/programs/bacteria-archaea/index.jsf 
Microorganisms sequenced at Genoscope. 
http://www.genoscope.cns.fr/spip/Microorganisms-
sequenced-at.html 
Claire N?dellec. 2005. Learning Language in Logic - 
Genic Interaction Extraction Challenge" in 
Proceedings of the Learning Language in Logic 
(LLL05) workshop joint to ICML'05. Cussens J. and 
N?dellec C. (eds). Bonn. 
Claire N?dellec, Adeline Nazarenko, Robert Bossy. 
2008..Information Extraction. Ontology Handbook. 
S. Staab, R. Studer (eds.), Springer Verlag, 2008. 
Nhung T. H. Nguyen and Yoshimasa Tsuruoka. 2011. 
Extracting Bacteria Biotopes with Semi-supervised 
Named Entity Recognition and Coreference 
Resolution. Proceedings of the BioNLP 2011 
Workshop Companion Volume for Shared Task. 
Miguel Pignatelli, Andr?s Moya, Javier Tamames.  
(2009). EnvDB, a database for describing the 
environmental distribution of prokaryotic taxa. 
Environmental Microbiology Reports. 1:198-207. 
Prokaryote Genome Projects at NCBI. 
http://www.ncbi.nlm.nih.gov/genomes/lproks.cgi  
Sampo Pyysalo, Antti Airola, Juho Heimonen, Jari 
Bj?rne, Filip Ginter and Tapio Salakoski. 2008. 
Comparative analysis of five protein-protein 
interaction corpora. BMC Bioinformatics. vol 9. 
Suppl 3. S6. 
Zorana Ratkovic, Wiktoria Golik, Pierre Warnier, 
Philippe Veber, Claire N?dellec. 2011. BioNLP 2011 
Task Bacteria Biotope ? The Alvis System. 
Proceedings of the BioNLP 2011 Workshop 
Companion Volume for Shared Task. 
Peter H. A. Sneath and Don J. Brenner. 1992. ?Official? 
Nomenclature Lists. American Society for 
Microbioloy News. 58, 175. 
Javier Tamames and Victor de Lorenzo. 2010. 
EnvMine: A text-mining system for the automatic 
extraction of contextual information. BMC 
Bioinformatics. 11:294. 
Web Soil Survey. http://websoilsurvey.nrcs.usda.gov/ 
64
Proceedings of BioNLP Shared Task 2011 Workshop, pages 65?73,
Portland, Oregon, USA, 24 June, 2011. c?2011 Association for Computational Linguistics
BioNLP Shared Task 2011 ? Bacteria Gene Interactions and Renaming
Julien Jourde1, Alain-Pierre Manine2, Philippe Veber1, Kare?n Fort3, Robert Bossy1,
Erick Alphonse2, Philippe Bessie`res1
1Mathe?matique, Informatique et 2PredictiveDB 3LIPN ? Universite? Paris-Nord/
Ge?nome ? Institut National de la 16, rue Alexandre Parodi CNRS UMR7030 and
Recherche Agronomique F75010 Paris, France INIST CNRS UPS76 ? F54514
MIG INRA UR1077 {apmanine,alphonse} Vand?uvre-le`s-Nancy, France
F78352 Jouy-en-Josas, France @predictivedb.com karen.fort@inist.fr
forename.lastname@jouy.inra.fr
Abstract
We present two related tasks of the BioNLP
Shared Tasks 2011: Bacteria Gene Renam-
ing (Rename) and Bacteria Gene Interactions
(GI). We detail the objectives, the corpus spec-
ification, the evaluation metrics, and we sum-
marize the participants? results. Both issued
from PubMed scientific literature abstracts,
the Rename task aims at extracting gene name
synonyms, and the GI task aims at extracting
genic interaction events, mainly about gene
transcriptional regulations in bacteria.
1 Introduction
The extraction of biological events from scientific
literature is the most popular task in Information Ex-
traction (IE) challenges applied to molecular biol-
ogy, such as in LLL (Ne?dellec, 2005), BioCreative
Protein-Protein Interaction Task (Krallinger et al,
2008), or BioNLP (Demner-Fushman et al, 2008).
Since the BioNLP 2009 shared task (Kim et al,
2009), this field has evolved from the extraction of a
unique binary interaction relation between proteins
and/or genes towards a broader acceptation of bio-
logical events including localization and transforma-
tion (Kim et al, 2008). In the same way, the tasks
Bacteria Gene Interactions and Bacteria Gene Re-
naming deal with the extraction of various molecu-
lar events capturing the mechanisms relevant to gene
regulation in prokaryotes. The study of bacteria has
numerous applications for health, food and indus-
try, and overall, they are considered as organisms
of choice for the recent integrative approaches in
systems biology, because of their relative simplicity.
Compared to eukaryotes, they allow easier and more
in-depth analysis of biological functions and of their
related molecular mechanisms.
Processing literature on bacteria raises linguis-
tic and semantic specificities that impact text anal-
ysis. First of all, gene renaming is a frequent phe-
nomenon, especially for model bacteria. Hence, the
abundance of gene synonyms that are not morpho-
logical variants is high compared to eukaryotes. The
history of bacterial gene naming has led to drastic
amounts of homonyms and synonyms which are of-
ten missing (or worse, erroneous) in gene databases.
In particular, they often omit old gene names that
are no longer used in new publications, but that are
critical for exhaustive bibliography search. Poly-
semy makes the situation even worse, as old names
frequently happen to be reused to denote different
genes. A correct and complete gene synonym table
is crucial to biology studies, for instance when inte-
grating large scale experimental data using distinct
nomenclatures. Indeed this information can save a
lot of bibliographic research time. The Rename Task
is a new task in text-mining for biology that aims at
extracting explicit mentions of renaming relations.
It is a critical step in gene name normalization that
is needed for further extraction of biological events
such as genic interactions.
Regarding stylistics, gene and protein interactions
are not formulated in the same way for eukary-
otes and prokaryotes. Descriptions of interactions
and regulations in bacteria include more knowledge
about their molecular actors and mechanisms, com-
pared to the literature on eukaryotes. Typically in
bacteria literature, the genic regulations are more
65
likely expressed by direct binding of the protein,
while in eukaryote literature, non-genic agents re-
lated to environmental conditions are much more
frequent. The bacteria GI Task is based on (Manine
et al, 2010) which is a semantic re-annotation of the
LLL challenge corpus (Ne?dellec, 2005), where the
description of the GI events in a fine-grained rep-
resentation includes the distinction between expres-
sion, transcription and other action events, as well as
different transcription controls (e.g. regulon mem-
bership, promoter binding). The entities are not only
protein agent and gene target but extend to families,
complexes and DNA sites (binding sites, promoters)
in order to better capture the complexity of the reg-
ulation at a molecular level. The task consists in re-
lating the entities with the relevant relations.
2 Rename Task Description
The goal of the Rename task is illustrated by Figure
1. It consists in predicting renaming relations be-
tween text-bound gene names given as input. The
only type of event is Renaming where both argu-
ments are of type Gene. The event is directed, the
former and the new names are distinguished. Genes
and proteins were not distinguished because of the
high frequency of metonymy in renaming events.
The relation to predict between genes is a Renam-
ing of a former gene name into a new one. In the
example of Figure 1, YtaA, YvdP and YnzH are the
former names of three proteins renamed CotI, CotQ
and CotU, respectively.
Figure 1: Examples of relations to be extracted.
2.1 Rename Task corpus
The Rename Task corpus is a set of 1,836 PubMed
references of bacterial genetic and genomic studies,
including title and abstract. A first set of 23,000 doc-
uments was retrieved, identifying the presence of the
bacterium Bacillus subtilis in the text and/or in the
MeSH terms. B. subtilis documents are particularly
rich in renaming mentions. Many genes were re-
named in the middle of the nineties, so that the new
names matched those of the Escherichia coli homo-
logues. The 1,843 documents the most susceptible
to mention renaming were automatically filtered ac-
cording to two non exclusive criteria:
1. Either the document mentions at least two gene
synonyms as recorded in the fusion of seven B.
subtilis gene nomenclatures. This led to a set
of 703 documents.
2. Or the document contains a renaming expres-
sion from a list that we manually designed and
tested (e.g. rename, also known as). It is an ex-
tension of a previous work by (Weissenbacher,
2004). A total of 1,140 new documents not in-
cluded in the first set match this criteria.
About 70% of the documents (1,146) were kept in
the training data set. The rest was split into the de-
velopment and test sets, containing 246 and 252 doc-
uments respectively. Table 1 gives the distribution
of genes and renaming relations per corpus. Gene
names were automatically annotated in the docu-
ments with the nomenclature of B. subtilis. Gene
names involved in renaming acts were manually cu-
rated. Among the 21,878 gene mentions in the three
corpus, 680 unique names are involved in renaming
relations which represents 891 occurrences of genes.
Training + Dev. Test
Documents (1,146 + 246) 1,392 252 (15%)
Gene names 18,503 3,375 (15%)
Renamings 373 88 (24%)
Table 1: Rename Task corpus content.
2.2 Rename Task annotation and guidelines
Annotation procedure The corpus was annotated
in a joint effort of MIG/INRA and INIST/CNRS.
The reference annotation of the Rename Task cor-
pus was done in two steps, a first annotation step
by science information professionals of INIST with
MIG initial specifications, a second checking step by
people at MIG. Two annotators and a project man-
ager were in charge of the task at INIST. The docu-
ments were annotated using the Cadixe editor1. We
1http://caderige.imag.fr/Articles/
CADIXEXML-Annotation.pdf
66
provided to them detailed annotation guidelines that
were largely modified in the process. A subset of
100 documents from the first set of 703 was anno-
tated as a training session. This step was used to re-
fine the guidelines according to the methodology de-
scribed in (Bonneau-Maynard et al, 2005). Several
inter-annotator agreements coefficients were com-
puted to measure the discrepancy between annota-
tors (Fort et al, 2009). With a kappa and pi scores
(for more details on those, see (Artstein and Poesio,
2008)), the results can be considered satisfactory.
The manual analysis of the 18 discrepancies led to
enrich the annotation guidelines. The first hundreds
of documents of the second set did not mention any
renaming, leading to concentrate the annotation ef-
forts on the first set. These documents actually con-
tained renamings, but nearly exclusively concerning
other kinds of biological entities (protein domains,
molecules, cellular ultrastructures, etc.).
Guidelines In order to simplify the task, only
short names of gene/protein/groups in B. subtilis
were considered. Naming conventions set short
names of four letters long with an upper case let-
ter at the end for all genes (e.g. gerE) and the same
names with the upper case of the initial letter (e.g.
GerE) and long names for the proteins (e.g. Spore
germination protein gerE). But many irregular gene
names exist (e.g. tuf), which are considered as well.
It also happens that gene or protein name lists are
abbreviated by factorization to form a sequence. For
instance queCDEF is the abbreviation of the list of
gene names queC, queD, queE and queF. Such ag-
gregations are acceptable gene names as well. In any
case, these details were not needed by the task par-
ticipants since the corpus was provided with tagged
gene names.
Most renaming relations involve couples of the
same type, genes, proteins or aggregations. Only
18 relations link mixed couples of genes and pro-
teins. In case of ambiguity, annotators would consult
international gene databases and an internal INRA
database to help them determine whether a given
couple of names were actually synonyms.
Multiple occurrences of the same renaming rela-
tion were annotated independently, and had to be
predicted. The renaming pairs are directed, the for-
mer and the new forms have to be distinguished.
When the renaming order was not explicit in the
document, the rule was to annotate by default the
first member of the couple as the new form, and the
second one as the former form. Figure 2 presents the
most common forms of renaming.
Figure 2: Common types of relations to be extracted.
Revised annotations INIST annotations were
systematically checked by two experts in Bioinfor-
matics from INRA. Mainly, encoding relations (e.g.
the gene encoding sigma K (sigK)) that are not re-
naming cases were purged. Given the number of
ambiguous annotations, we designed a detailed ty-
pology in order to justify acceptance or rejection
decisions in seven different sub-cases hereafter pre-
sented. Three positive relations figure in Table 2,
where the underlined names are the former names
and the framed names are the new ones. Explicit re-
naming relations occur in 261 sentences, synonymy-
like relations in 349 sentences, biological proof-
based relations in 76 sentences.
Explicit renaming relation is the easiest positive
case to identify. In the example, the aggregation of
gene names ykvJKLM is clearly renamed by the au-
thors as queCDEF. Although the four genes are con-
Explicit renaming
PMID 15767583 : Genetic analysis of ykvJKLM mu-
tants in Acinetobacter confirmed that each was essen-
tial for queuosine biosynthesis, and the genes were re-
named queCDEF .
Implicit renaming
PMID 8002615 : Analysis of a suppressor mutation
ssb ( kinC ) of sur0B20 (spo0A) mutation in Bacil-
lus subtilis reveals that kinC encodes a histidine pro-
tein kinase.
Biological proof
PMID 1744050 : DNA sequencing established that
spoIIIF and spoVB are a single monocistronic locus
encoding a 518-amino-acid polypeptide with features
of an integral membrane protein.
Table 2: Positive examples of the Rename Task.
67
catenated, there is no evidence mentioned of them
acting as an operon. Furthermore, despite the con-
text involving mutants of Acinetobacter, the aggre-
gation belongs correctly to B. subtilis.
Implicit renaming is an asymmetric relation
since one of the synonyms is intended to replace the
other one in future uses. The example presents two
renaming relations between former names ssb and
spo0A, and new names kinC and sur0B20, respec-
tively. The renaming relation between ssb and kinC
has a different orientation due to additional informa-
tion in the reference. Like in the preceding example,
the renaming is a consequence of a genetic mutation
experiment. Mutation names represent an important
transversal issue that is discussed below.
Biological proof is a renaming relation induced
by an explicit scientific conclusion while the renam-
ing is not, as in the example where experiments re-
veal that two loci spoIIIF and spoVB are in fact the
same one and then become synonyms. Terms such
as ?allelic to? or ?identical to? usually qualify such
conclusions. Predicting biological proof-based rela-
tions requires some biological modeling.
The next three cases are negative (Table 3). Un-
derlined gene and protein names are involved in a
relation which is not a renaming relation.
Protein encoding relation occurs between a gene
and the protein it codes for. Some mentions may
look like renaming relations. The example presents
the gene yeaC coding for MoxR. No member of the
couple is expected to replace the other one.
Homology measures the similarity between gene
or protein sequences. Most of the homology men-
tions involve genes or proteins from different species
Protein encoding
PMID 8969499: The putative products of ORFs yeaB
(Czd protein), yeaC (MoxR), yebA (CNG-channel and
cGMP-channel proteins from eukaryotes),
Genetic homology
PMID 10619015 : Dynamic movement of the ParA-
like Soj protein of B. subtilis and its dual role in nu-
cleoid organization and developmental regulation.
Operon | Regulon | Family
PMID 3127379 : Three promoters direct transcription
of the sigA (rpoD) operon in Bacillus subtilis.
Table 3: Negative examples of the Rename Task.
(orthologues). The others compare known gene or
protein sequences of the same species (paralogues).
This may be misleading since the similarity men-
tion may look like biological proof-based relations,
as between ParA and Soj in Table 3.
Operon, regulon or family renaming involves
objects that may look like genes, proteins or sim-
ple aggregations of gene or protein names but that
are perceptibly different. The objects represent more
than one gene or protein and the renaming does not
necessarily affect all of them. More problematic,
their name may be the same as one of the genes or
proteins they contain, as in the example where sigA
and rpoD are operons but are also known as gene
names. Here, sigA (and so rpoD) represents at least
two different genes. For the sake of clarity, oper-
ons, regulons and families are rejected, even if all
the genes are clearly named, as in an aggregation.
The last point concerns mutation which are fre-
quent in Microbiology for revealing gene pheno-
types. They carry information about the original
gene names (e.g., rvtA11 is a mutant name created
by adding 11 to rvtA). But partial names cannot be
partially annotated, that is to say, the original part
(rvtA) should not be annotated in the mutation name
(rvtA11). Most of these names are local names, and
should not be annotated because of their restricted
scope. It may happen so that the mutation name
is registered as a synonym in several international
databases. To avoid inconsistencies, all renamings
involving a mutation referenced in a database were
accepted, and only biological proof-based and ex-
plicit renamings involving a strict non-null unrefer-
enced mutation (a null mutation corresponds to a to-
tal suppression of a gene) were accepted.
2.3 Rename Task evaluation procedure
The evaluation of the Rename task is given in terms
of recall, precision and F-score of renaming rela-
tions. Two set of scores are given: the first set is
computed by enforcing strict direction of renaming
relations, the second set is computed with relaxed
direction. Since the relaxed score takes into ac-
count renaming relations even if the arguments are
inverted, it will necessarily be greater or equal than
the strict score. The participant score is the relaxed
score, the strict score is given for information. Re-
laxed scores are informative with respect to the ap-
68
plication goal. The motivation of the Rename task
is to keep bacteria gene synonyms tables up to date.
The choice of the canonical name among synonyms
for denoting a gene is done by the bacteriology com-
munity, and it may be independent of the anteriority
or novelty of the name. The annotation of the ref-
erence corpus showed that the direction was not al-
ways decidable, even for a human reader. Thus, it
would have been unfair to evaluate systems on the
basis of unsure information.
2.4 Results of the Rename Task participants
Final submissions were received from three teams,
the University of Turku (Uturku), the University of
Concordia (Concordia) and the Bibliome team from
MIG/INRA. Their results are summarized in Table
4. The ranking order is given by the overall F-score
for relations with relaxed argument order.
Team Prec. Recall F-score
Univ. of Turku 95.9 79.6 87.0
Concordia Univ. 74.4 65.9 69.9
INRA 57.0 73.9 64.4
Table 4: Participant scores at the Rename Task.
Uturku achieved the best F-score with a very high
precision and a high recall. Concordia achieved the
second F-score with balanced precisions and recalls.
Bibliome is five points behind with a better recall
but much lower precision. Both UTurku and Con-
cordia predictions rely on dependencies (Charniak-
Johnson and Stanford respectively, using McClosky
model), whereas Bibliome predictions rely on bag of
words. This demonstrates the high value of depen-
dency parsing for this task, in particular for the pre-
cision of predictions. We notice that UTurku system
uses machine learning (SVM) and Concordia uses
rules based on trigger words. The good results of
UTurku confirms the hypothesis that gene renam-
ing citations are highly regular in scientific litera-
ture. The most frequently missed renamings belong
to the Biological Proof category (see Table 2). This
is expected because the renaming is formulated as a
reasoning where the conclusion is only implicit.
2.5 Discussion
The very high score of Uturku method leads us to
conclude that the task can be considered as solved
by a linguistic-based approach. Whereas Bib-
liome used an extensive nomenclature considered
as exhaustive and sentence filtering using a SVM,
Uturku used only two nomenclatures in synergy but
with more sophisticated linguistic-based methods,
in particular syntactic analyses. Bibliome methods
showed that a too high dependence to nomenclatures
may decrease scores if they contain compromised
data. However, the use of an extensive nomencla-
ture as done by Bibliome may complement Uturku
approach and improve recall. It is also interesting
that both systems do not manage renamings cross-
ing sentence boundaries.
The good results of the renaming task will be ex-
ploited to keep synonym gene lists up to date with
extensive bibliography mining. In particular this
will contribute to enriching SubtiWiki, a collabora-
tive annotation effort on B. subtilis (Flo?rez et al,
2009; Lammers et al, 2010).
3 Gene Interactions Task description
The goal of the Bacteria GI Task is illustrated by
Figure 3. The genes cotB and cotC are related to
their two promoters, not named here, by the rela-
tion PromoterOf. The protein GerE is related to
these promoters by the relation BindTo. As a con-
sequence, GerE is related to cotB and cotC by an In-
teraction relation. According to (Kim et al, 2008),
the need to define specialized relations replacing one
unique and general interaction relation was raised in
(Manine et al, 2009) for extracting genic interac-
tions from text. An ontology describes relations and
entities (Manine et al, 2008) catching a model of
gene transcription to which biologists implicitly re-
fer in their publications. Therefore, the ontology is
mainly oriented towards the description of a struc-
tural model of genes, with molecular mechanisms
of their transcription and associated regulations.
The corpus roughly contains three kinds of genic
Figure 3: Examples of relations to be extracted.
69
interaction mentions, namely regulations, regulon
membership and binding. The first case corresponds
to interactions the mechanism of which is not explic-
itly given in the text. The mention only tells that the
transcription of a given gene is influenced by a given
protein, either positively (activation), negatively (in-
hibition) or in an unspecified way. The second kind
of genic interaction mention (regulon membership)
basically conveys the same information, using the
regulon term/concept. The regulon of a gene is the
set of genes that it controls. In that case, the interac-
tion is expressed by saying that a gene is a member
of some regulon. The third and last kind of mention
provides with more mechanistic details on a regula-
tion, since it describes the binding of a protein near
the promoter of a target gene. This motivates the in-
troduction of Promoter and Site entities, which cor-
respond to DNA regions. It is thus possible to extract
the architecture of a regulatory DNA region, linking
a protein agent to its gene target (see Figure 3).
The set of entity types is divided into two main
groups, namely 10 genic entities and 3 kinds of ac-
tion (Table 5). Genic entities represent biological
objects like a gene, a group of genes or a gene prod-
uct. In particular, a GeneComplex annotation corre-
sponds to an operon, which is a group of genes that
are contiguous in the genome and under the control
of the same promoter. The annotation GeneFamily
is used to denote either genes involved in the same
biological function or genes with sequence homolo-
gies. More importantly, PolymeraseComplex anno-
tations correspond to the protein complex that is re-
sponsible for the transcription of genes. This com-
plex includes several subunits (components), com-
bined with a sigma factor, that recognizes specific
promoters on the DNA sequence.
The second group of entities are phrases express-
ing either molecular processes (e.g. sequestration,
dephosphorylation, etc.) or the molecular state of
the bacteria (e.g. presence, activity or level of a pro-
tein). They represent some kind of action that can
be performed on a genic entity. Note that transcrip-
tion and expression events were tagged as specific
actions, because they play a specific part in certain
relations (see below).
The annotation of entities and actions was pro-
vided to the participants, and the task consisted in
extracting the relations listed in Table 6.
Name Example
Gene cotA
GeneComplex sigX-ypuN
GeneFamily class III heat shock genes
GeneProduct yvyD gene product
Protein CotA
PolymeraseComplex SigK RNA polymerase
ProteinFamily DNA-binding protein
Site upstream site
Promoter promoter regions
Regulon regulon
Action activity | level | presence
Expression expression
Transcription transcription
Table 5: List of molecular entities and actions in GI.
Name Example
ActionTarget expression of yvyD
Interaction ComK negatively regulates
degR expression
RegulonDependence sigmaB regulon
RegulonMember yvyD is member of sigmaB
regulon
BindTo GerE adheres to the pro-
moter
SiteOf -35 sequence of the pro-
moter
PromoterOf the araE promoter
PromoterDependence GerE-controlled promoter
TranscriptionFrom transcription from the up-
stream site
TranscriptionBy transcription of cotD by
sigmaK RNA polymerase
Table 6: List of relations in GI.
The relations are binary and directed, and rely the
entities defined above. The three kinds of interac-
tions are represented with an Interaction annotation,
linking an agent to its target. The other relations
provide additional details on the regulation, like ele-
mentary components involved in the reaction (sites,
promoters) and contextual information (mainly pro-
vided by the ActionTarget relations). A formal def-
inition of relations and relation argument types can
be found on the Bacteria GI Task Web page.
3.1 Bacteria Gene Interactions corpus
The source of the Bacteria GI Task corpus is a set
of PubMed abstracts mainly dealing with the tran-
70
scription of genes in Bacillus subtilis. The semantic
annotation, derived from the ontology of (Manine et
al., 2008), contains 10 molecular entities, 3 different
actions, and 10 specialized relations. This is applied
to 162 sentences from the LLL set (Ne?dellec, 2005),
which are provided with manually checked linguis-
tic annotations (segmentation, lemmatization, syn-
tactic dependencies). The corpus was split into 105
sentences for training, 15 for development and 42
for test. Table 7 gives the distribution of the entities
and actions per corpus and Table 8 gives the distri-
bution of the relations per corpus.
3.2 Annotation procedures and guidelines
The semantic annotation scheme was developed by
two annotators through a series of independent an-
notations of the corpus, followed by reconciliation
steps, which could involve concerted modifications
(Manine et al, 2010). As a third and final stage, the
Entity or action Train. + Dev. Test
Documents (105+15) 120 42
Protein 219 85
Gene 173 56
Transcription 53 21
Promoter 49 10
Action 45 22
PolymeraseComplex 43 14
Expression 29 6
Site 22 8
GeneComplex 19 4
ProteinFamily 12 3
Regulon 11 2
GeneProduct 10 3
GeneFamily 6 5
Table 7: Distribution of entities and actions in GI.
Relation Train. + Dev. Test
Interaction 208 64
ActionTarget 173 47
PromoterOf 44 8
BindTo 39 4
PromoterDependence 36 4
TranscriptionBy 36 8
SiteOf 23 6
RegulonMember 17 2
TranscriptionFrom 14 2
RegulonDependence 12 1
Table 8: Distribution of relations in GI.
corpus was reviewed and the annotation simplified
to make it more appropriate to the contest. The final
annotation contains 748 relations distributed in nine
categories, 146 of them belonging to the test set.
The annotation scheme was generally well suited
to accurately represent the meaning of the sentences
in the corpus, with one notable exception. In the cor-
pus, there is a common phrasing telling that a pro-
tein P regulates the transcription of a gene G by a
given sigma factor S. In that case, the only anno-
tated interactions are between the couples (P, G) and
(S, G). This representation is not completely satis-
factory, and a ternary relation involving P, S and G
would have been more adequate.
Additional specific rules were needed to cope
with linguistic issues. First, when the argument of a
relation had coreferences, the relation was repeated
for each maximally precise coreference of the argu-
ment. Second, in case of a conjunction like ?sig-
maA and sigmaX holoenzymes?, there should ide-
ally be two entities (namely ?sigmaA holoenzyme?
and ?sigmaX holoenzyme?); however, this is not
easy to represent using the BioNLP format. In this
situation, we grouped the two entities into a single
one. These cases were rare and unlikely affected the
feasibility of the task, since entities were provided
in the test set.
3.3 Gene Interactions evaluation procedure
The training and development corpora with the ref-
erence annotations were made available to partici-
pants by December, 1st on the BioNLP shared Task
pages together with evaluation software. The test
corpus with the entity annotations has been made
available by March, 1st. The participants sent the
predicted annotations to the BioNLP shared Task
organizers by March, 10th. The evaluation results
were computed and provided to the participants and
on the Web site the same day. The participants are
evaluated and ranked according to two scores: F-
score for all event types together, and F-score for
the Interaction event type. In order for a predicted
event to count as a hit, both arguments must be the
same as in the reference in the right order and the
event type must be the same as in the reference.
71
3.4 Results of GI Task participants
There was only one participant, whose results are
shown in Tables 9 and 10. Some relations were
not significantly represented in the test set and thus
the corresponding results should be considered with
caution. This is the case for RegulonMember and
TranscriptionFrom, only represented two times each
in the test. The lowest recall, 17%, obtained for the
SiteOf relation is explained by its low representa-
tion in the corpus: most of the test errors come from
a difficult sentence with coreferences.
The recall of 56% for the Interaction relation cer-
tainly illustrates the heterogeneity of this category,
gathering mentions of interactions at large, as well
as precise descriptions of gene regulations. For in-
stance, Figure 4 shows a complex instance where all
of the interactions were missed. Surprisingly, we
also found false negatives in rather trivial examples
(?ykuD was transcribed by SigK RNA polymerase
from T4 of sporulation.?). Uturku used an SVM-
based approach for extraction, and it is thus delicate
to account for the false negatives in a simple and
concise way.
Event U. Turku scores
Global Precision 85
Global Recall 71
Global F-score 77
Interaction Precision 75
Interaction Recall 56
Interaction F-score 64
Table 9: University of Turku global scores.
Event Prec. Rec. F-score
Global 85 71 77
ActionTarget 94 92 93
BindTo 75 75 75
Interaction 75 56 64
PromoterDependence 100 100 100
PromoterOf 100 100 100
RegulonDependence 100 100 100
RegulonMember 100 50 67
SiteOf 100 17 29
TranscriptionBy 67 50 57
TranscriptionFrom 100 100 100
Table 10: University of Turku scores for each relation.
Figure 4: Examples of three missed interactions.
3.5 Discussion
The GI corpus was previously used in a relation
extraction work (Manine et al 2009) based on In-
ductive Logic Programming (Muggleton and Raedt,
1994). However a direct comparison of the results
is not appropriate here since the annotations were
partially revised, and the evaluation setting was dif-
ferent (leave-one-out in Manine?s work, test set in
the challenge).
Nevertheless, we note similar tendencies if we
compare relative results between relations. In partic-
ular, it was also found in Manine?s paper that SiteOf,
TranscriptionBy and Interaction are the most diffi-
cult relations to extract. It is also worth to mention
that both approaches rely on syntactic dependencies,
and use the curated dependencies provided in the
corpus. Interestingly, the approach by the University
of Turku reports a slightly lower F-measure with de-
pendencies calculated by the Charniak parser (about
1%, personal communication). This information is
especially important in order to consider a produc-
tion setting.
4 Conclusion
The quality of results for both challenges suggests
that current methods are mature enough to be used
in semi-automatic strategies for genome annotation,
where they could efficiently assist biological experts
involved in collaborative annotation efforts (Lam-
mers et al, 2010). However, the false positive rate,
notably for the Interaction relation, is still too high
for the extraction results to be used as a reliable
source of information without a curation step.
Acknowlegments
We thank Franc?oise Tisserand and Bernard Talercio
(INIST) for their work on the Rename corpus, and
the QUAERO Programme funded by OSEO (French
agency for innovation) for its support.
72
References
Artstein R., Poesio M. (2008). Inter-coder agreement
for Computational Linguistics. Computational Lin-
guistics, 34(4):555-96.
Bjo?rne J., Heimonen J., Ginter F., Airola A., Pahikkala
T., Salakoski T. (2009). Extracting complex biological
events with rich graph-based feature sets. BioNLP?09
Proc. Workshop Current Trends in Biomedical Natural
Language Processing: Shared Task, pp. 10-18.
Bonneau-Maynard H., Rosset S., Ayache C., Kuhn A.,
Mostefa D. (2005). Semantic annotation of the French
Media Dialog Corpus. Interspeech-2005, pp. 3457-60.
Demner-Fushman D., Ananiadou S., Cohen K.B., Pestian
J., Tsujii J., Webber B. (2008). Themes in biomedical
natural language processing: BioNLP08. BMC Bioin-
formatics, 9(Suppl. 11):S1.
Flo?rez L.A., Roppel S.F., Schmeisky A.G., Lammers
C.R., Stu?lke J. (2009). A community-curated con-
sensual annotation that is continuously updated: The
Bacillus subtilis centred wiki SubtiWiki. Database,
2009:bap012.
Fort K., Franc?ois C., Ghribi M. (2010). ?Evaluer des an-
notations manuelles disperse?es : les coefficients sont-
ils suffisants pour estimer l?accord inter-annotateurs ?
17e Conf. Traitement Automatique des Langues Na-
turelles (TALN 2010).
Kim J.D., Ohta T., Tsujii J. (2008) Corpus annotation for
mining biomedical events from literature. BMC Bioin-
formatics, 9:10.
Kim J.D., Ohta T., Pyysalo S., Kano Y., Tsujii J. (2009).
Overview of BioNLP?09 shared task on event ex-
traction. BioNLP?09 Proc. Workshop Current Trends
in Biomedical Natural Language Processing: Shared
Task, pp. 1-9.
Krallinger M., Leitner F., Rodriguez-Penagos C., Va-
lencia A. (2008). Overview of the protein-protein in-
teraction annotation extraction task of BioCreative II.
Genome Biology, 9(Suppl. 2):S4.
Lammers C.R., Flo?rez L.A., Schmeisky A.G., Roppel
S.F., Ma?der U., Hamoen L., Stu?lke J. (2010). Con-
necting parts with processes: SubtiWiki and Subti-
Pathways integrate gene and pathway annotation for
Bacillus subtilis. Microbiology, 156(3):849-59.
Manine A.P., Alphonse E., Bessie`res P. (2008). Informa-
tion extraction as an ontology population task and its
application to genic interactions. 20th IEEE Int. Conf.
Tools with Artificial Intelligence (ICTAI?08), pp. 74-
81.
Manine A.P., Alphonse E., Bessie`res P. (2009). Learn-
ing ontological rules to extract multiple relations of
genic interactions from text. Int. J. Medical Informat-
ics, 78(12):e31-8.
Manine A.P., Alphonse E., Bessie`res P. (2010). Extrac-
tion of genic interactions with the recursive logical the-
ory of an ontology. Lecture Notes in Computer Sci-
ences, 6008:549-63.
Muggleton S., Raedt L.D. (1994) Inductive Logic Pro-
gramming: Theory and methods. J. Logic Program-
ming, 19-20:629-79.
Ne?dellec C. (2005). Learning Language in Logic ? Genic
Interaction Extraction Challenge. Proc. 4th Learning
Language in Logic Workshop (LLL?05), pp. 31-7.
Weissenbacher, D. (2004). La relation de synonymie en
Ge?nomique. RECITAL 2004 Conference.
73
