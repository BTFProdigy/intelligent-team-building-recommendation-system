Document  Transformations and Informat ion States 
Sta f fan  Larsson  
Dept. of linguistics 
GSteborg University 
Sweden 
sibling. ~L. se 
Ann ie  Zaenen 
Xerox Research Centre Europe 
Grenoble Laboratory 
France 
Annie. Zaenen~xrce. xerox, com 
Abst rac t  
We discuss ways to explore how 
instructional material needs to be 
structured to be presented with var- 
ious degrees of interactivity. We 
use the TRINDI 1 information state 
approach to model three different 
degrees of interactivity and present 
IMDiS, a small experimental imple- 
mentation based on the GoDiS dia- 
logue system. 
1 In t roduct ion  
Document transformations is becoming a hot 
topic in industrial research on document cre- 
ation. The reason is practical: with the new 
presentation possibilities, the advantages of 
being able to adapt he 'same' document con- 
tent to different uses - where the difference 
can lie in the support devices, audiences, lan- 
guages or modes of interaction - becomes very 
attractive. It not only becomes attractive, it
also becomes necessary: one needs to present 
material in various contexts (oral presenta- 
tious, internet portals, etc.) and it is very 
costly to develop presentations from scratch 
for these various contexts. 
This situation raises an old question and 
opens a new area of research: can one sep- 
arate content from presentation? The philo- 
sophical answer might be 'no', but in practice 
one doesn't need an absolute answer. As this 
area of research arises more out of practical 
necessity than pure intellectual curiosity, the 
1TRINDI (Task Oriented Instruc- 
tional Dialogue), EC Project LE4-8314, 
www. ling. gu. se/research/proj ec~s/trindi/ 
engineering is preceding the science and it will 
take some time before it rest on explicit solid 
foundations. 
Here we look only at one small aspect of the 
problem: how can we model small changes 
in presentation that are due to various de- 
grees of interactivity between participants in 
instructional exchanges. We start from a tra- 
ditional manual and make some assumptions 
about minimal interactivity which are mod- 
eled through dialogue moves. We conclude 
that in this way we can make the presenta- 
tion of the material more flexible. An impor- 
tant limit on the flexibility is, however, the 
detail with which the discourse structure of 
the manual encodes the task plan underlying 
the activity. 
2 Degrees  o f  In teract iv i ty  and  the  
d i f ference between mono logue  
and  d ia logue  
We take here the position that the main differ- 
ence between dialogue and monologue is that 
the former implies interactivity. With interac- 
tivity we mean here that the participants can 
influence ach other's moves. With respect 
to the area that interests us here, giving in- 
structions to repair devices, a traditional writ- 
ten manual influences the user but not vice 
versa (except hrough notes to the author). 
The user can, however, influence the order in 
which she accesses the material: it is easy to 
stop, to go back or to consult an other section 
(traditional printed material might be argued 
to be better in that respect than presentation 
on a screen, we ignore that difference here). 
We can consider this as a limit case of inter- 
activity. 
112 
Note that interactivity does not necessarily 
imply shared initiative. The literature makes 
a distinction between task and dialogue ini- 
tiative (e.g. (Chu-Carroll and Brown, 1998)) 
but one can have dialogue with both types of 
initiative staying with one side. In the cases 
we discuss below the task initiative stays com- 
pletely with the manual and the dialogue ini- 
tiative only switches to the instructee in the 
case where she can indicate that information 
about some subprocedures can be skipped. 
There is another dimension that often inter- 
venes in discussions about the difference be- 
tween dialogue and written discourse: the for- 
mer is spoken, the latter is written. Given the 
way things are in a natural setting, the writ- 
ten medium tends not to allow interactivity, 
whereas the spoken medium is used mainly in 
interactive settings. Technical changes, how- 
ever, allow us to separate the written/spoken 
opposition from that between interactive and 
non, or minimally, interactive discourse. In- 
structional material can be presented in the 
aural mode without becoming more interac- 
tive e.g. when a recording is played. This can 
be considered as a plus for instructional ma- 
terial because it allows the instructee to use 
her hands and eyes for the task itself but it is 
not an unqualified advantage given that read- 
ing gives much more flexibility than listening 
to a tape. To cash in on the advantages ofthe 
aural presentation, we need to recapture the 
flexibility of access that the written medium 
allows. 
3 Ins t ruc t ions  and  In teract iv i ty  
It is obvious that instructional situations 
profit from an interactive setting. Instruc- 
tional situations are typically situations in 
which some participants (the instructors) 
know a lot that the other participants (the 
instructees) need to know to achieve the com- 
mon goals. In these kinds of situations it is 
important hat all the required and, prefer- 
ably only the required, knowledge gets trans- 
ferred at the moment he instructees need it. 
To achieve this, it is not enough that the 
instructor have all the necessary knowledge, 
she needs also to know which state the in- 
structee is in and how that state changes to 
adapt the transfer of knowledge, hence the 
instructee needs to be able to inform the in- 
structor about his state and influence in this 
way the course of the interaction. 
Currently we have manuals, whose con- 
tent can be presented aurally or in a writ- 
ten form but where both the content and the 
presentation are uniquely determined a pri- 
ori (modulo, the speed and order of read- 
ing mentioned above). Or we have interac- 
tions that can be at a distance but where 
a human instructor needs to be available at 
the time of the action. Making humans with 
the required competence available is expen- 
sive and one would want to achieve some in- 
teractivity without his. But computers tend 
to be frustrating participants in interactive 
settings when one compares them to human 
beings and the study of dialogue concentrates 
mainly on making them as human as possible. 
When one considers the possibility of trans- 
ferring the interactivity from humans to ma- 
chines, there are, however, many intermedi- 
ate possibilities between o interactivity and 
full blown interactivity in free-wheeling di- 
alogue where the participants can ask each 
other questions about anything and nothing 
(for a more thorough discussion about dia- 
logues between humans and computers ee 
(Clark, 1999)). In this paper we consider how 
minimal interactions can be modeled on the 
basis of information which is available in tra- 
ditional instructional manuals. 
In looking at the problem this way one 
has to keep in mind that instructional man- 
uals, although not interactive, are coopera- 
tive constructs: they assume that they par- 
ticipate with the user in a rational cooper- 
ative task and they are built on an implicit 
reader model, specifically they make assump- 
tions about what the user knows and what 
she doesn't know and the granularity of the 
task descriptions that they have to provide. 
They obey in their own way Grice's Maxim 
of Quantity but they need to leave open a 
range of possibilities so they need to provide 
more detail than is necessary in all circum- 
stances. In what follows we can only consider 
113 
cases of over-informedness a  the information 
needed to remedy under-informedness is not 
available. 
4 The  TR INDI  mode l  
The TRINDI project has developed both a 
framework and a toolkit to model various 
types of interactions in terms of information 
state updates. The framework, whose main 
ingredients are information states, dialogue 
moves and updates, is described in (Traum 
et al, 1999). We use the term information 
state to mean, roughly, the information stored 
internally by an agent, in this case a dia- 
logue system. A dialogue move engine up- 
dates the information state on the basis of 
observed ialogue moves and selects appropri- 
ate moves to be performed. In:formation state 
updates are formalised as in~brmation state 
update rules. The importance of the frame- 
work is that new interactive :hypotheses can 
be modeled with minor extensions. The infor- 
mation state approach is implemented in the 
TRINDIKIT (Larsson et al, 2000); (Larsson 
and Traum, To appear), a toolkit for experi- 
menting with the implementation f informa- 
tion states and dialogue move engines and for 
building dialogue systems. It is used in the 
experimental implementation described here. 
Various instantiations of the framework 
articulate further what information states, 
moves, and update rules contain. In this pa- 
per we use one formal representation f in- 
formation states that has been developed in 
the TRINDI, SDS 2 and INDI 3 projects, and 
implemented in the GoDiS dialogue system 
(Bohlin et al, 1999). The central parts of the 
information state in GoDiS are dialogue plans 
and Questions Under Discussion (QUD), a 
notion borrowed from Ginzburg (Ginzburg, 
1998). 
2SDS (Swedish Dial%me Systems), 
NUTEK/HSFR Language Technology Project 
F1472/1997, http://~rm~, ida.liu, se/ nlplab/sds/ 
3INDI (Information Exchange in Dialogue), Riks- 
bankens Jubileumsfond 1997-0134. 
5 Mode l ing  var ious  degrees  of  
in teract iv i ty  in  TR INDI  
We envision the following cases: 
? 1. Traditional manual: no overt inter- 
action, we will consider this as the limit 
case  
? 2. Manual can ask yes/no questions and 
understand two types of user responses: 
- yes/no 
- done/don't understand 
- how? 
? 3. User can indicate whether she already 
knows certain (sub)procedures 
5.1 GoDiS / IMDiS  in format ion  states 
To model the types of interactions above, we 
started from the GoDiS system which is de- 
signed to deal with information-seeking dia- 
logue. The IMDiS information state type is 
shown in Figure 1. 
PRIVATE 
SHARED 
PLAN : StackSet (Action) 
: AGENDA : Stack(Action) 
TMP : (sa,ID.e as SHARED) 
| BEL : Set(Prop) 
\[ QUD : StackSet(Question) 
: | ACTIONS : Stack(Action) 
L LU : Ut te rance  
Figure i: IMDiS information state type 
The main division in the information state 
is between information which is private to the 
agent and that which is shared between the 
dialogue participants. The private part of the 
information state contains a PLAN field hold- 
ing a dialogue plan, i.e. is a list of dialogue 
actions that the agent wishes to carry out. 
The plan can be changed uring the course 
of the conversation. The AGENDA field, on 
the other hand, contains the short term goals 
or obligations that the agent has, i.e. what 
the agent is going to do next. We have in- 
cluded a field TMP that mirrors the shared 
fields. This field keeps track of shared infor- 
mation that has not yet been grounded, i.e. 
confirmed as having been understood by the 
114 
? i 
other dialogue participant. The SHARED field 
is divided into four subfields. One subfield is 
a set of proposit ions which the agent assumes 
for the sake of the conversation. The second 
subfield is for a stack of questions under dis- 
cussion (QUD). These are questions that have 
been raised and are currently under discus- 
sion in the dialogue. The ACTIONS field is a 
stack of (domain) actions which the user has 
been instructed to perform but has not yet 
performed.The LU field contains information 
about the latest utterance. 
To adapt GoDiS to instructional dialogue, 
we added a subfield of SHARED.ACTIONS to 
(the shared part  of) the information state. 
The value of this field is a stack of actions 
which the system has instructed the user to 
perform, but whose performance has not yet 
been confirmed by the user. 
In building the experimental IMDiS, we 
have made several simplifications. We have 
ignored all the natural  language generation 
problems and all the problems related to mak- 
ing text or dialogue natural, e.g. problems re- 
lated to the use of pronouns and other refer- 
ential expressions. To handle these we would 
not only have to discuss basic interactivity 
but also the medium in which the interaction 
takes place: speech or written text. 
The monologue mode (case 1) uses only 2 
moves ( Ins t ruct ,  and In fo rm) .  Since there 
is no user to confirm that actions have been 
performed, all actions are automatical ly con- 
firmed using the update rule autoConf i rm.  
RULE: autoConf i rm 
CLASS: in tegrate  
PRE: { fst( SHARED.ACTIONS, A ) 
pop( SHARED.ACTIONS ) 
EFF: add( SHARED.BEL, done(A) ) 
The dialogue version (cases 2 and 3) 
uses 9 move types, basically the 7 used in 
GoDiS (Ask,  Answer ,  In fo rm,  Repeat ,  
RequestRepeat ,  Greet ,  Qu i t )p lus  in- 
structions ( Ins t ruc t )  and confirmations 
(Conf i rm) .  Confirmations are integrated by 
assuming that the current topmost action 
in SHARED.ACTIONS has been performed, as 
seen in the update rule below. 
RULE: in tegrateUsrConf i rm 
CLASS: in tegrate  
val( SHARED.LU.SPEAKER, nsr ) 
PRE: assoc( SHARED.LU.MOVES, confirm, false ) 
fst( SHARED.ACTIONS, A ) 
set_assoc( SHARED.LU.MOVES, confirm, true ) 
EFF: pop( SHARED.ACTIONS ) 
add( SHARED.BEL, clozte( A ) ) 
This rule says that if the user performed a
Conf i rm move, which has not yet been in- 
tegrated, and A is the "most salient" action, 
then integrate the move by putt ing the propo- 
s i t ion done (A) in the shared beliefs, and tak- 
ing A off the action stack. 
Elliptical "how"-questions from the user 
are interpreted as applying to the currently 
topmost action in the SHARED.ACTIONS stack. 
5.2 Domain  task ,  manua ls  and  
d ia logues  
Let's now see how a monologue and a dialogue 
version of the same task are related. Below we 
have an example from the user manual for the 
HomeCentre, a Xerox MFD. 
? Reinstalling the print head 
? Caution: Make sure that the green carriage lock 
lever is STILL moved all the way forward before 
you reinstall the print head. 
? 1. Line up the hole in the print head with the 
green post on the printer carriage. 
? Lower the print head down gently into position. 
? 2. Gently push the green cartridge lock lever up 
until it snaps into place. 
? This secures the print head. 
? 3. Close the top cover and reattach the scanner. 
? 4. Press and release the yellow LED button. 
? The printer will prepare the cartridge for print- 
ing. 
? Note: If the carriage does not move from the cen- 
ter position after you press the cartridge change 
button, remove and reinstall the print head. 
From this text, one can (re)construct a task 
plan for reinstalling the print head. Such a 
plan may be represented as in figure 2. Note 
115 
NAME rein.stall(prim head) 
PRE movcd_forward(carriage2od0 
DEC 
EFF minstalled(prinL head) 
Figure 2: Task plan 
- -1  action 
complcx action / plan 
final state 
that this is a conditional plan, i.e. it contains 
branching conditions. 
From this task plan, IMDiS generates two 
plans: a monologue plan and a dialogue plan. 
This is done using the "translation schema" 
in Figure 3. 
The difference between the text plan and 
the dialogue plan is in the way that condi- 
tionals in the task plan are interpreted. In 
the monologue plan, they correspond to sim- 
ply informing the user of the conditional. In 
dialogue mode, however, the system raises the 
question whether the condition holds. When 
the system finds out if the condition holds, it 
will instruct he user to execute the appropri- 
ate guarded action. 
Here we can clearly see how dialogue differs 
from monologue as viewed by Carlson or Van 
Kuppevelt ((Carlson, 1983), (~an Kuppevelt, 
1995)). Under these views the writer antici- 
pates the questions the user might have asked 
but given the user is not present he writer 
has to make up for the lack of interactivity. 
The questions that can be reconstructed (or 
accommodated) are different in that case. For 
instance in the example given here, the ques- 
tion could something like "What should the 
user/I make sure of?". These questions are 
valuable to help figure out the discourse struc- 
ture of a monologue. They can also be valu- 
able tools to illustrate the differences between 
dialogue and monologue but they do not give 
much insight in the effects of various degrees 
of interactivity. 
Conditionals are treated as follows by the 
system in dialogue mode: When the system 
has found out what the user's task is, it will 
load the appropriate dialogue plan into the 
PRIVATE.PLAN field of the information state. 
It will then execute the actions in the appro- 
priate order by moving them to the agenda 
and generating appropriate utterances. When 
a conditional statement is topmost on the 
plan, IMDiS will check whether it has been es- 
tablished that the condition holds (by check- 
ing the SHARED.BEL field). Since the system 
has previously asked the user and the user has 
answered, either the condition or its negation 
will be in the set of established propositions. 
If the condition or its negation holds, the con- 
ditional will be popped off the plan and re- 
placed by the first or second guarded action 
(respectively). 
116 
DOMAIN 
l~recondition P 
action A 
if_then (C,A) 
effect E 
MONOLOGUE 
Instruct (check (P)) 
Instruct(A) 
Inform(if_then (C, A) ) 
Inform(E) 
DIALOGUE 
findout(P); 
if_then ( not (P),  
Instruct (achieve (P)) ) 
Instruct(A) 
findout (C) ; 
if-then(C, 
Instruct(A)) 
Inform(E) 
Figure 3: Plan conversion table 
5.3 Monologue and Dialogue 
Behav iour  
In the monologue mode in IMDiS, the 
control module does not call the input and 
interpretation modules. The text is output 
"move by move" as a sequence of utterances 
from the system. 
S: Reinstalling the print head. 
S: Make sure that the green carriage lock 
lever is STILL moved all the way forward 
before you install the print head. 
S: Line up the hole in the print head with 
the green post on the printer carriage 
Compared to the monologue mode, even a 
very restricted ialogue mode offers several 
advantages: 
User a t tent ion  and control The user 
can direct her attention to the machine and 
does not have to look at the manual. As 
we noted in when one goes from written to 
aural presentation, one gains the advantage 
that the user has free hands and eyes but if 
nothing more is done this advantage has to 
be weighted against the disadvantage that 
the user looses all control over the order 
and the speed with which the information 
is presented. We can avoid these draw- 
backs by allowing some limited grounding 
behaviour. Very simple interactions like 
'done' (Confirm) or 'don't understand' 
(RequestRepeat)  give back to the user a 
limited control over the speed and the order 
of the presentation (at least up to allowing 
repetition): the user decides when to move 
on to the next action, by confirming that the 
previous action is done, and by 'don't under- 
stand' she can indicate that she would want 
a repetition of what was said immediately 
before. Here we see how to take advantage 
of the advantages of a different mode of 
presentation (written versus aural) we also 
have to change the type of interactivity. 
S: Has the carriage moved from the center 
position? 
U: I didn't understand 
S: Has the carriage moved from the center 
position? 
Avoid irrelevant informat ion When the 
action to be taken depends on a condition, 
the system does not give irrelevant informa- 
tion. 
S: Has the carriage moved from the center 
position? 
U: yes 
S: The print head is now installed 
Because there is no feedback from the user, 
a manual has always to give all the possibili- 
ties regardless of which one actually pertains. 
The possibility to ask yes/no questions allows 
us to do away with this redundancy. 
5.4 More complex task plans 
In the example above we illustrated how a 
simple task plan can give rise to a dialogue 
and a monologue rendering. We can get some 
added flexibility by giving more structure to 
the task plan. For instance in the example 
above, one can argue that the reiustallation 
proper of the print head is described in point 
1 to 2 and that 3 and 4 describe termination 
117 
NAME reinstall(print head) 
PRE movcxLforward(cartiage lock) 
DEC 
\[ secu. ?(prkR._h(~d~ \[ 
cl t ? cv-- t o e op= 
I press_and_release(yellow_button 1 
yes ? no 
V'Y--~-(moved_from_cent e_____r(prin~head)__/~ 
! I I 
/ " >~? ' J 
EFF reinstallcxl(prim head) 
NAME secure(print:head) 
PRE 
DEC 
I line_up(hole, post) 
I push(leveO I 
6 
EFF secured(printhead) 
I \[ action 
~ \ ]  complex action / plan 
final state 
Figure 4: Revised Task Plan 
conditions. To reflect this we can revise the 
task plan as follows: 
With this structure the user can control 
the level of detail of the instructions given. 
If the user does not know how to perform 
a substep, she can ask the system for more 
detailed instructions. 
U: done, aud now? 
S: Close the top cover 
If the user manages to complete the whole 
action sequence without instructions, he can 
tell the system this and the system proceeds 
to the next relevant action. 
S: put the print head in place 
U: how? 
S: Line up the hole in the print head with 
the green post on the printer carriage 
U: r ight ,  ok 
S: Lower the print head down gently into 
position 
U: ok 
S: Gently push the green car t r idge  lock lever  
up unt i l  i t  snaps into p lace 
U: ok 
S: The pr in t  head is  now secure ly  in p lace 
On the other hand, if the user already 
knows how to perform a substep, the system 
moves on to the next step. 
S: put the print head in place 
S: put the print head in place 
U: how? 
S: Line up the hole in the print head with 
the green post on the printer carriage 
U: r ight ,  done 
S: Lower the pr in t  head down gent ly  in to  
position 
U: done, I remember now (pause) the print 
head is put in place 
S: Ok. Close the top cover 
Here, however, we see the importance of 
the task structure. It is only if we have in- 
formation that gives the structure of the task 
with subtasks that we can model this. Very 
often instructional manuals will give this sub- 
structure, e.g. in the form of subdivisions of 
instructions, but they tend not to be corn- 
118 
pletely consistent in this. It is only when this 
information is given in a consistent way that 
we can exploit it in a transformation from a 
written manual presentation to a more inter- 
active presentation. 
6 D iscuss ion  and  Research  I ssues  
In this experiment we have looked at a few 
differences that occur in the rendering of the 
same information under different conditions 
of interactivity. Our little experiment brought 
out several differences in the 'rendering' of the 
same task plan as a written text and as a min- 
imally interactive dialogue. 
? Conditionals and preconditions are han- 
dled differently if limited confirmations 
are possible. 
? The flexibility of access that written text 
allows needs to be modeled more explic- 
itly in case of aural presentation. This 
can be done minimally by allowing the 
machine to interpret 'done' or 'don't un- 
derstand' as moves that lead to the pre- 
sentation of the next instruction or to a 
repetition of the latest instruction. 
Moreover the granularity with which the 
task plan is represented corresponds to the 
granularity of the control the user has over 
the presentations of the instructions. In this 
example we started from an existing manual 
text. Starting from a written manual helped 
us understand the importance of the informa- 
tion about the task structure. This comes of 
course not as a surprise: when the presenta- 
tion mode is fixed as non-interactive, the the 
discourse structure can be very 'fiat': things 
need to be done in a certain order whether 
they are parts of subtasks or not is not rel- 
evant. It can be argued that giving more 
structure will help a user understand better 
what the instructions achieve but it will not 
influence the execution directly. Material that 
helps the user understand why she is doing 
something is typically given in introductory 
sections and not in the procedures themselves 
in this type of manual. But to make doc- 
ument transformations possible in the sense 
described in the beginning, it is important o 
clearly separate task plans and assumptions 
about interactions, i.e. about how the infor- 
mation states get updated. 4 
Once the task plan is distinguished from the 
dialogue plan, assumptions about the type of 
interactions between participants can change 
the dialogue plan even when the task plan 
remains constant. 
In practice a completely automatic trans- 
formation of a written manual into even lim- 
ited dialogue is most likely not possible, al- 
though one can isolate several inguistic flags 
for some of the aspects we have been dis- 
cussing (e.g. expressions like "make sure 
that..." flag preconditions). A more realistic 
approach would be to create a blueprint doc- 
ument that is marked up to allow the deriva- 
tion of several different types of discourse 
from the beginning on. Such an enterprise 
would need tools such as the TRINDIKIT to 
model the various cases 5 
So far, we have only explored one extreme 
of the monologue-dialogue opposition where 
the interactivity stays very low. Obvious ex- 
tensions are to allow the user to ask informa- 
tion that goes beyond the current procedure, 
e.g. 'where can i find the piece you mention' 
or 'how long does this take: i have only 1/2 
hour here'. Further inquiry into the possible 
interactions will help us to define which infor- 
mation is needed and how it needs to be struc- 
tured to fulfill these various needs. And of 
course we will never reach a system in which 
every user need can be anticipated but then 
even human beings are not that type of sys- 
tem. 
4See (Grosz and Sidner, 1986) for a discussion of 
the importance oftask plans in more explanatory di- 
alogue. 
5It would also need tools that make it easy to model 
the relation between the linguistic expressions used in 
the various renderings of the base document. One can 
see this task as akin to that of multilingual genera- 
tion or even simple document rendering. Formal ap- 
proaches used for those tasks could be adapted to such 
an enterprise. XML supplemented with stylesheets 
and schemata could be another possibility. 
119 
References  
P. Bohlin, R. Cooper, E. Engdahl, and S. Larsson. 
1999. Information states and dialogue move 
engines. In J. Alexandersson, editor, IJCAI- 
99 Workshop on Knowled9e and Reasonin 9 in 
Practical Dialogue Systems. 
L. Carlson. 1983. Dialogue Games. D. Reidel, 
Dordrecht. 
Jennifer Chu-Carroll and Michael K. Brown. 
1998. An evidential model for tracking initia- 
tive in collaborative dialogue interactions. User 
Modeling and User-Adapted Interaction, special 
issue on Computational Models of Mized Initia- 
tive Interaction, 8(3+4):215-253. 
H. Clark. 1999. How do real people communicate 
with virtual partners? Proceedings of AAAI- 
99 Fall Symposium, Pshychological Models of 
Communication i  Collaborative Systems. 
J. Ginzburg. 1998. Clarifying utterances. In 
J. Hulstijn and A. Niholt, editors, Proc. of 
the Twente Workshop on the .Formal Seman- 
tics and Pragmatics of Dialogues, pages 11-30, 
Enschede. Universiteit Twente, Faculteit Infor- 
matica. 
B. J. Grosz and C. L. Sidner. 1986. Atten- 
tion, intention, and the structure of discourse. 
12(3):175-204. 
Staffan Larsson and David Traum. To appear. 
Information state and dialogue management in 
the trindi dialogue move engine toolkit. NLE 
Special Issue on Best Practice in Spoken Lan- 
guage Dialogue Systems Engineering. 
Staffan Larsson, Alexander Berman, Johan Bos, 
Leif GrSnqvist, Peter Ljunglbf, and David 
Traum. 2000. Trindikit 2.0 manual. Techni- 
cal Report Deliverable D5.3 - Manual, Trindi. 
D. Traum, J. Bos, R. Cooper, S. Larsson, I.Lewin, 
C. Matheson, and M. Poesio. 1999. A model of 
dialogue moves and irfformation state revision. 
deliverable D2.1, TRINDI. 
Jan van Kuppevelt. 1995. Discourse structure, 
topicality and questioning. Journal of Linguis- 
tics, 31:109-147. 
120 
Statistical Sentence Condensation using Ambiguity Packing and Stochastic
Disambiguation Methods for Lexical-Functional Grammar
Stefan Riezler and Tracy H. King and Richard Crouch and Annie Zaenen
Palo Alto Research Center, 3333 Coyote Hill Rd., Palo Alto, CA 94304
{riezler|thking|crouch|zaenen}@parc.com
Abstract
We present an application of ambiguity pack-
ing and stochastic disambiguation techniques
for Lexical-Functional Grammars (LFG) to the
domain of sentence condensation. Our system
incorporates a linguistic parser/generator for
LFG, a transfer component for parse reduc-
tion operating on packed parse forests, and a
maximum-entropy model for stochastic output
selection. Furthermore, we propose the use of
standard parser evaluation methods for auto-
matically evaluating the summarization qual-
ity of sentence condensation systems. An ex-
perimental evaluation of summarization qual-
ity shows a close correlation between the au-
tomatic parse-based evaluation and a manual
evaluation of generated strings. Overall sum-
marization quality of the proposed system is
state-of-the-art, with guaranteed grammatical-
ity of the system output due to the use of a
constraint-based parser/generator.
1 Introduction
Recent work in statistical text summarization has put for-
ward systems that do not merely extract and concate-
nate sentences, but learn how to generate new sentences
from ?Summary, Text? tuples. Depending on the cho-
sen task, such systems either generate single-sentence
?headlines? for multi-sentence text (Witbrock and Mittal,
1999), or they provide a sentence condensation module
designed for combination with sentence extraction sys-
tems (Knight and Marcu, 2000; Jing, 2000). The chal-
lenge for such systems is to guarantee the grammatical-
ity and summarization quality of the system output, i.e.
the generated sentences need to be syntactically well-
formed and need to retain the most salient information of
the original document. For example a sentence extraction
system might choose a sentence like:
The UNIX operating system, with implementations
from Apples to Crays, appears to have the advan-
tage.
from a document, which could be condensed as:
UNIX appears to have the advantage.
In the approach of Witbrock and Mittal (1999), selec-
tion and ordering of summary terms is based on bag-
of-words models and n-grams. Such models may well
produce summaries that are indicative of the original?s
content; however, n-gram models seem to be insufficient
to guarantee grammatical well-formedness of the system
output. To overcome this problem, linguistic parsing and
generation systems are used in the sentence condensation
approaches of Knight and Marcu (2000) and Jing (2000).
In these approaches, decisions about which material to in-
clude/delete in the sentence summaries do not rely on rel-
ative frequency information on words, but rather on prob-
ability models of subtree deletions that are learned from
a corpus of parses for sentences and their summaries.
A related area where linguistic parsing systems
have been applied successfully is sentence simplifica-
tion. Grefenstette (1998) presented a sentence reduction
method that is based on finite-state technology for lin-
guistic markup and selection, and Carroll et al (1998)
present a sentence simplification system based on linguis-
tic parsing. However, these approaches do not employ
statistical learning techniques to disambiguate simplifi-
cation decisions, but iteratively apply symbolic reduction
rules, producing a single output for each sentence.
The goal of our approach is to apply the fine-grained
tools for stochastic Lexical-Functional Grammar (LFG)
parsing to the task of sentence condensation. The system
presented in this paper is conceptualized as a tool that can
be used as a standalone system for sentence condensation
                                                               Edmonton, May-June 2003
                                                             Main Papers , pp. 118-125
                                                         Proceedings of HLT-NAACL 2003
or simplification, or in combination with sentence extrac-
tion for text-summarization beyond the sentence-level. In
our system, to produce a condensed version of a sen-
tence, the sentence is first parsed using a broad-coverage
LFG grammar for English. The parser produces a set of
functional (f )-structures for an ambiguous sentence in a
packed format. It presents these to the transfer compo-
nent in a single packed data structure that represents in
one place the substructures shared by several different in-
terpretations. The transfer component operates on these
packed representations and modifies the parser output to
produce reduced f -structures. The reduced f -structures
are then filtered by the generator to determine syntac-
tic well-formedness. A stochastic disambiguator using a
maximum entropy model is trained on parsed and manu-
ally disambiguated f -structures for pairs of sentences and
their condensations. Using the disambiguator, the string
generated from the most probable reduced f -structure
produced by the transfer system is chosen. In contrast
to the approaches mentioned above, our system guaran-
tees the grammaticality of generated strings through the
use of a constraint-based generator for LFG which uses
a slightly tighter version of the grammar than is used by
the parser. As shown in an experimental evaluation, sum-
marization quality of our system is high, due to the com-
bination of linguistically fine-grained analysis tools and
expressive stochastic disambiguation models.
A second goal of our approach is to apply the standard
evaluation methods for parsing to an automatic evaluation
of summarization quality for sentence condensation sys-
tems. Instead of deploying costly and non-reusable hu-
man evaluation, or using automatic evaluation methods
based on word error rate or n-gram match, summariza-
tion quality can be evaluated directly and automatically
by matching the reduced f -structures that were produced
by the system against manually selected f -structures that
were produced by parsing a set of manually created con-
densations. Such an evaluation only requires human labor
for the construction and manual structural disambigua-
tion of a reusable gold standard test set. Matching against
the test set can be done automatically and rapidly, and
is repeatable for development purposes and system com-
parison. As shown in an experimental evaluation, a close
correspondence can be established for rankings produced
by the f -structure based automatic evaluation and a man-
ual evaluation of generated strings.
2 Statistical Sentence Condensation in the
LFG Framework
In this section, each of the system components will be
described in more detail.
2.1 Parsing and Transfer
In this project, a broad-coverage LFG gram-
mar and parser for English was employed (see
Riezler et al (2002)). The parser produces a set of
context-free constituent (c-)structures and associated
functional (f -)structures for each input sentence, repre-
sented in packed form (see Maxwell and Kaplan (1989)).
For sentence condensation we are only interested in the
predicate-argument structures encoded in f -structures.
For example, Fig. 1 shows an f -structure manually
selected out of the 40 f -structures for the sentence:
A prototype is ready for testing, and Leary hopes to
set requirements for a full system by the end of the
year.
The transfer component for the sentence condensation
system is based on a component previously used in a ma-
chine translation system (see Frank (1999)). It consists
of an ordered set of rules that rewrite one f -structure
into another. Structures are broken down into flat lists
of facts, and rules may add, delete, or change individ-
ual facts. Rules may be optional or obligatory. In the case
of optional rules, transfer of a single input structure may
lead to multiple alternate output structures. The transfer
component is designed to operate on packed input from
the parser and can also produce packed representations
of the condensation alternatives, using methods adapted
from parse packing.1
An example rule that (optionally) removes an adjunct
is shown below:
+adjunct(X,Y), in-set(Z,Y) ?=>
delete-node(Z,r1), rule-trace(r1,del(Z,X)).
This rule eliminates an adjunct, Z, by deleting the fact that
Z is contained within the set of adjuncts, Y, associated
with the expression X. The + before the adjunct(X,Y)
fact marks this fact as one that needs to be present for the
rule to be applied, but which is left unaltered by the rule
application. The in-set(Z,Y) fact is deleted. Two
new facts are added. delete-node(Z,r1) indicates
that the structure rooted at node Z is to be deleted, and
rule-trace(r1,del(Z,X)) adds a trace of this
rule to an accumulating history of rule applications. This
history records the relation of transferred f -structures to
the original f -structure and is available for stochastic dis-
ambiguation.
Rules used in the sentence condensation transfer sys-
tem include the optional deletion of all intersective ad-
juncts (e.g., He slept in the bed. can become He slept.,
but He did not sleep. cannot become He did sleep. or He
1The packing feature of the transfer component could not
be employed in these experiments since the current interface
to the generator and stochastic disambiguation component still
requires unpacked representations.
"A prototype is ready for testing , and Leary hopes to set requirements for a full system by the end of the year."
?be<[93:ready]>[30:prototype]?PRED
?prototype?PRED
countGRAINNTYPE
?a?PREDDET?FORM a, DET?TYPE indefDETSPEC
CASE nom, NUM sg, PERS 330
SUBJ
?ready<[30:prototype]>?PRED [30:prototype]SUBJADEGREE positive, ATYPE predicative93XCOMP
?for<[141:test]>?PRED
?test?PRED
gerundGRAINNTYPE
CASE acc, NUM sg, PERS 3, PFORM for, VTYPE main141
OBJ
ADV?TYPE vpadv, PSEM unspecified, PTYPE sem125
ADJUNCT
MOOD indicative, PERF ?_, PROG ?_, TENSE presTNS?ASP
PASSIVE ?, STMT?TYPE decl, VTYPE copular[252:hope]>s73
?hope<[235:Leary], [280:set]>?PRED
?Leary?PRED
properGRAIN
namePROPERNSEMNTYPE
ANIM +, CASE nom, NUM sg, PERS 3235
SUBJ
?set<[235:Leary], [336:requirement], [355:for]>?PRED [235:Leary]SUBJ
?requirement?PRED
unspecifiedGRAINNTYPE
CASE acc, NUM pl, PERS 3336
OBJ
?for<[391:system]>?PRED
?system?PRED
?full?PREDADEGREE positive, ADJUNCT?TYPE nominal, ATYPE attributive398ADJUNCT
unspecifiedGRAINNTYPE
?a?PREDDET?FORM a, DET?TYPE indefDETSPEC
CASE acc, NUM sg, PERS 3, PFORM for391
OBJ
PSEM unspecified, PTYPE sem355
OBL
?by<[469:end]>?PRED
?end?PRED
?of<[519:year]>?PRED
?year?PRED
countGRAINNTYPE
?the?PREDDET?FORM the, DET?TYPE defDETSPEC
CASE acc, NUM sg, PERS 3, PFORM of519
OBJ
ADJUNCT?TYPE nominal, PSEM unspecified, PTYPE sem512
ADJUNCT
countGRAINNTYPE
?the?PREDDET?FORM the, DET?TYPE defDETSPEC
CASE acc, NUM sg, PERS 3, PFORM by469
OBJ
ADV?TYPE vpadv, PSEM unspecified, PTYPE sem451
ADJUNCT
PERF ?_, PROG ?_TNS?ASP
INF?FORM to, PASSIVE ?, VTYPE main280
XCOMP
MOOD indicative, PERF ?_, PROG ?_, TENSE presTNS?ASP
PASSIVE ?, STMT?TYPE decl, VTYPE main252
COORD +_, COORD?FORM and, COORD?LEVEL ROOT197
Figure 1: F -structure for non-condensed sentence.
slept.), the optional deletion of parts of coordinate struc-
tures (e.g., They laughed and giggled. can become They
giggled.), and certain simplifications (e.g. It is clear that
the earth is round. can become The earth is round. but
It seems that he is asleep. cannot become He is asleep.).
For example, one possible post-transfer output of the sen-
tence in Fig. 1 is shown in Fig. 2.
2.2 Stochastic Selection and Generation
The transfer rules are independent of the grammar and are
not constrained to preserve the grammaticality or well-
formedness of the reduced f-structures. Some of the re-
duced structures therefore may not correspond to any En-
glish sentence, and these are eliminated from future con-
sideration by using the generator as a filter. The filter-
ing is done by running each transferred structure through
the generator to see whether it produces an output string.
If it does not, the structure is rejected. For example, for
the f -structure in Fig. 1, the transfer system proposed
32 possible reductions. After filtering these structures by
generation, 16 reduced f -structures comprising possible
"A prototype is ready for testing."
?be  <[93:ready]>[30:prototype]?PRED
?prototype ?PRED
countGRAINNTYPE
?a?PREDDET?FORM  a, DET?TYPE  indefDETSPEC
CASE nom, NUM sg, PERS 330
SUBJ
?ready<[30:prototype]>?PRED [30:prototype]SUBJADEGREE  positive , ATYPE  predicative93XCOMP
?for<[141:test]>?PRED
?test ?PRED
gerundGRAINNTYPE
CASE acc, NUM sg, PERS 3, PFORM for, VTYPE main141
OBJ
ADV?TYPE  vpadv , PSEM  unspecified , PTYPE  sem125
ADJUNCT
MOOD	  indicative, PERF  ?_, PROG  ?_, TENSE presTNS?ASP
PASSIVE ?, STMT?TYPE decl, VTYPE copular73
Figure 2: Gold standard f -structure reduction.
condensations of the input sentence survive. The 16 well-
formed structures correspond to the following strings that
were outputted by the generator (note that a single struc-
ture may correspond to more than one string and a given
string may correspond to more than one structure):
A prototype is ready.
A prototype is ready for testing.
Leary hopes to set requirements for a full system.
A prototype is ready and Leary hopes to set require-
ments for a full system.
A prototype is ready for testing and Leary hopes to
set requirements for a full system.
Leary hopes to set requirements for a full system by
the end of the year.
A prototype is ready and Leary hopes to set require-
ments for a full system by the end of the year.
A prototype is ready for testing and Leary hopes to
set requirements for a full system by the end of the
year.
In order to guarantee non-empty output for the over-
all condensation system, the generation component has
to be fault-tolerant in cases where the transfer system op-
erates on a fragmentary parse, or produces non-valid f -
structures from valid input f -structures. Robustness tech-
niques currently applied to the generator include insertion
and deletion of features in order to match invalid transfer-
output to the grammar rules and lexicon. Furthermore,
repair mechanisms such as repairing subject-verb agree-
ment from the subject?s number value are employed. As
a last resort, a fall-back mechanism to the original un-
condensed f -structure is used. These techniques guaran-
tee that a non-empty set of reduced f -structures yielding
grammatical strings in generation is passed on to the next
system component. In case of fragmentary input to the
transfer component, grammaticaliy of the output is guar-
anteed for the separate fragments. In other words, strings
generated from a reduced fragmentary f -structure will be
as grammatical as the string that was fed into the parsing
component.
After filtering by the generator, the remaining f -
structures were weighted by the stochastic disambigua-
tion component. Similar to stochastic disambiguation for
constraint-based parsing (Johnson et al, 1999; Riezler et
al., 2002), an exponential (a.k.a. log-linear or maximum-
entropy) probability model on transferred structures is es-
timated from a set of training data. The data for estima-
tion consists of pairs of original sentences y and gold-
standard summarized f -structures s which were manu-
ally selected from the transfer output for each sentence.
For training data {(sj , yj)}mj=1 and a set of possible sum-
marized structures S(y) for each sentence y, the objective
was to maximize a discriminative criterion, namely the
conditional likelihood L(?) of a summarized f -structure
given the sentence. Optimization of the function shown
below was performed using a conjugate gradient opti-
mization routine:
L(?) = log
m?
j=1
e??f(sj)
?
s?S(yj)
e??f(s)
.
At the core of the exponential probability model is a vec-
tor of property-functions f to be weighted by parameters
?. For the application of sentence condensation, 13,000
property-functions of roughly three categories were used:
? Property-functions indicating attributes, attribute-
combinations, or attribute-value pairs for f -structure
attributes (? 1,000 properties)
? Property-functions indicating co-occurences of verb
stems and subcategorization frames (? 12,000 prop-
erties)
? Property-functions indicating transfer rules used to
arrive at the reduced f - structures (? 60 properties).
A trained probability model is applied to unseen data
by selecting the most probable transferred f -structure,
yielding the string generated from the selected struc-
ture as the target condensation. The transfered f -structure
chosen for our current example is shown in Fig. 3.
"A prototype is ready."
?be  <[93:ready]>[30:prototype]?PRED
?prototype ?PRED
countGRAINNTYPE
?a?PRED
DET?FORM a, DET?TYPE indefDETSPEC
CASE nom, NUM  sg, PERS  330
SUBJ
?ready<[30:prototype]>?PRED [30:prototype]SUBJ
ADEGREE positive , ATYPE predicative93XCOMP

MOOD indicative, PERF ?_, PROG ?_, TENSE presTNS?ASP
PASSIVE ?, STMT?TYPE decl, VTYPE copular73
Figure 3: Transferred f -structure chosen by system.
This structure was produced by the following set of
transfer rules, where var refers to the indices in the rep-
resentation of the f -structure:
rtrace(r13,keep(var(98),of)),
rtrace(r161,keep(system,var(85))),
rtrace(r1,del(var(91),set,by)),
rtrace(r1,del(var(53),be,for)),
rtrace(r20,equal(var(1),and)),
rtrace(r20,equal(var(2),and)),
rtrace(r2,del(var(1),hope,and)),
rtrace(r22,delb(var(0),and)).
These rules delete the adjunct of the first conjunct (for
testing), the adjunct of the second conjunct (by the end
of the year), the rest of the second conjunct (Leary hopes
to set requirements for a full system), and the conjunction
itself (and).
3 A Method for Automatic Evaluation of
Sentence Summarization
Evaluation of quality of sentence condensation systems,
and of text summarization and simplification systems in
general, has mostly been conducted as intrinsic evalua-
tion by human experts. Recently, Papineni et al?s (2001)
proposal for an automatic evaluation of translation sys-
tems by measuring n-gram matches of the system out-
put against reference examples has become popular for
evaluation of summarization systems. In addition, an au-
tomatic evaluation method based on context-free deletion
decisions has been proposed by Jing (2000). However, for
summarization systems that employ a linguistic parser as
an integral system component, it is possible to employ
the standard evaluation techniques for parsing directly
to an evaluation of summarization quality. A parsing-
based evaluation allows us to measure the semantic as-
pects of summarization quality in terms of grammatical-
functional information provided by deep parsers. Further-
more, human expertise was necessary only for the cre-
ation of condensed versions of sentences, and for the
manual disambiguation of parses assigned to those sen-
tences. Given such a gold standard, summarization qual-
ity of a system can be evaluated automatically and re-
peatedly by matching the structures of the system out-
put against the gold standard structures. The standard
metrics of precision, recall, and F-score from statisti-
cal parsing can be used as evaluation metrics for mea-
suring matching quality: Precision measures the number
of matching structural items in the parses of the sys-
tem output and the gold standard, out of all structural
items in the system output?s parse; recall measures the
number of matches, out of all items in the gold stan-
dard?s parse. F-score balances precision and recall as
(2 ? precision ? recall)/(precision + recall).
For the sentence condensation system presented above,
the structural items to be matched consist of rela-
tion(predicate, argument) triples. For example, the gold-
standard f -structure of Fig. 2 corresponds to 23 depen-
dency relations, the first 14 of which are shared with the
reduced f -structure chosen by the stochastic disambigua-
tion system:
tense(be:0, pres),
mood(be:0, indicative),
subj(be:0, prototype:2),
xcomp(be:0, ready:1),
stmt_type(be:0, declarative),
vtype(be:0, copular),
subj(ready:1, prototype:2),
adegree(ready:1, positive),
atype(ready:1, predicative),
det(prototype:2, a:7),
num(prototype:2, sg),
pers(prototype:2, 3),
det_form(a:7, a),
det_type(a:7, indef),
adjunct(be:0, for:12),
obj(for:12, test:14),
adv_type(for:12, vpadv),
psem(for:12, unspecified),
ptype(for:12, semantic),
num(test:14, sg),
pers(test:14, 3),
pform(test:14, for),
vtype(test:14, main).
Matching these f -structures against each other corre-
sponds to a precision of 1, recall of .61, and F-score of
.76.
The fact that our method does not rely on a compar-
ison of the characteristics of surface strings is a clear
advantage. Such comparisons are bad at handling exam-
ples which are similar in meaning but differ in word or-
der or vary structurally, such as in passivization or nom-
inalization. Our method handles such examples straight-
forwardly. Fig. 4 shows two serialization variants of the
condensed sentence of Fig. 2. The f -structures for these
examples are similar to the f -structure assigned to the
gold standard condensation shown in Fig. 2 (except for
the relations ADJUNT-TYPE:parenthetical ver-
sus ADV-TYPE:vpadv versus ADV-TYPE:sadv). An
evaluation of summarization quality that is based on
matching f -structures will treat these examples equally,
whereas an evaluation based on string matching will yield
different quality scores for different serializations.
"A prototype, for testing, is ready."
?be  <[221:ready]>[30:prototype]?PRED
?prototype ?PRED
countGRAINNTYPE
?a?PREDDET?FORM  a, DET?TYPE  indefDETSPEC
CASE nom, NUM sg, PERS 330
SUBJ
?ready<[30:prototype]>?PRED [30:prototype]SUBJADEGREE  positive , ATYPE  predicative221XCOMP
?for<[117:test]>?PRED
?test ?PRED
gerundGRAINNTYPECASE acc, NUM sg, PERS 3, PFORM for, VTYPE main117OBJADJUNCT?TYPE  parenthetical , PSEM  unspecified , PTYPE  sem73
ADJUNCT
MOOD  indicative, PERF  ?_, PROG  ?_, TENSE presTNS?ASP
PASSIVE ?, STMT?TYPE decl, VTYPE copular201
"For testing, a prototype is ready."
?be  <[177:ready]>[131:prototype]?PRED
?prototype ?PRED
countGRAINNTYPE
?a?PREDDET?FORM  a, DET?TYPE  indefDETSPEC
CASE nom, NUM sg, PERS 3131
SUBJ
?ready<[131:prototype]>?PRED [131:prototype]SUBJADEGREE  positive , ATYPE  predicative177XCOMP
?for<[27:test]>?PRED
?test ?PRED
gerundGRAINNTYPECASE acc, NUM sg, PERS 3, PFORM for, VTYPE main27OBJADV?TYPE  sadv, PSEM  unspecified , PTYPE  sem11
ADJUNCT
MOOD  indicative, PERF  ?_, PROG  ?_, TENSE presTNS?ASP
PASSIVE ?, STMT?TYPE decl, VTYPE copular83
Figure 4: F -structure for word-order variants of gold
standard condensation.
In the next section, we present experimental results
of an automatic evaluation of the sentence condensation
system described above. These results show a close cor-
respondence between automatically produced evaluation
results and human judgments on the quality of generated
condensed strings.
4 Experimental Evaluation
The sentences and condensations we used are taken from
data for the experiments of Knight and Marcu (2000),
which were provided to us by Daniel Marcu. These data
consist of pairs of sentences and their condensed versions
that have been extracted from computer-news articles and
abstracts of the Ziff-Davis corpus. Out of these data, we
parsed and manually disambiguated 500 sentence pairs.
These included a set of 32 sentence pairs that were used
for testing purposes in Knight and Marcu (2000). In or-
der to control for the small corpus size of this test set, we
randomly extracted an additional 32 sentence pairs from
the 500 parsed and disambiguated examples as a second
test set. The rest of the 436 randomly selected sentence
pairs were used to create training data. For the purpose
of discriminative training, a gold-standard of transferred
f -structures was created from the transfer output and the
manually selected f -structures for the condensed strings.
This was done automatically by selecting for each exam-
ple the transferred f -structure that best matched the f -
structure annotated for the condensed string.
In the automatic evaluation of f -structure match, three
different system variants were compared. Firstly, ran-
domly chosen transferred f -structures were matched
against the manually selected f -structures for the man-
ually created condensations. This evaluation constitutes
a lower bound on the F-score against the given gold
standard. Secondly, matching results for transferred f -
structures yielding the maximal F-score against the gold
standard were recorded, giving an upper bound for the
system. Thirdly, the performance of the stochastic model
within the range of the lower bound and upper bound was
measured by recording the F-score for the f -structure that
received highest probability according to the learned dis-
tribution on transferred structures.
In order to make our results comparable to the re-
sults of Knight and Marcu (2000) and also to investigate
the correspondence between the automatic evaluation and
human judgments, a manual evaluation of the strings gen-
erated by these system variants was conducted. Two hu-
man judges were presented with the uncondensed sur-
face string and five condensed strings that were displayed
in random order for each test example. The five con-
densed strings presented to the human judges contained
(1) strings generated from three randomly selected f -
structures, (2) the strings generated from the f -structures
which were selected by the stochastic model, and (3) the
manually created gold-standard condensations extracted
from the Ziff-Davis abstracts. The judges were asked
to judge summarization quality on a scale of increasing
quality from 1 to 5 by assessing how well the generated
strings retained the most salient information of the orig-
inal uncondensed sentences. Grammaticality of the sys-
tem output is optimal and not reported separately. Results
for both evaluations are reported for two test corpora of
32 examples each. Testset I contains the sentences and
condensations used to evaluate the system described in
Knight and Marcu (2000). Testset II consists of another
randomly extracted 32 sentence pairs from the same do-
main, prepared in the same way.
Fig. 5 shows evaluation results for a sentence conden-
sation run that uses manually selected f -structures for
the original sentences as input to the transfer component.
These results demonstrate how the condenstation system
performs under the optimal circumstances when the parse
chosen as input is the best available. Fig. 6 applies the
same evaluation data and metrics to a sentence conden-
sation experiment that performs transfer from packed f -
structures, i.e. transfer is performed on all parses for an
ambiguous sentence instead of on a single manually se-
lected parse. Alternatively, a single input parse could be
selected by stochastic models such as the one described
in Riezler et al (2002). A separate phase of parse disam-
biguation, and perhaps the effects of any errors that this
might introduce, can be avoided by transferring from all
parses for an ambiguous sentence. This approach is com-
putationally feasible, however, only if condensation can
be carried all the way through without unpacking. Our
technology is not yet able to do this (in particular, as men-
tioned earlier, we have not yet implemented a method for
stochastic disambiguation on packed f -structures). How-
ever, we conducted a preliminary assessment of this pos-
sibility by unpacking and enumerating the transferred f -
structures. For many sentences this resulted in more can-
didates than we could operate on in the available time
and space, and in those cases we arbitrarily set a cut-off
on the number of transferred f -structures we considered.
Since transferred f -structures are produced according to
the number of rules applied to transfer them, in this setup
the transfer system produces smaller f -structures first,
and cuts off less condensed output. The result of this ex-
periment, shown in Fig. 6, thus provides a conservative
estimate on the quality of the condensations we might
achieve with a full-packing implementation.
In Figs. 5 and 6, the first row shows F-scores for a
random selection, the system selection, and the best pos-
sible selection from the transfer output against the gold
standard. The second rows show summarization quality
scores for generations from a random selection and the
system selection, and for the human-written condensa-
tion. The third rows report compression ratios. As can
testset I lowerbound
system
selection
upper
bound
F-score 58% 67.3% 77.2 %
sum-quality 2.0 3.5 4.4
compr. 50.2% 60.4% 54.9%
testset II lowerbound
system
selection
upper
bound
F-score 59% 65.4% 83.3%
sum-quality 2.1 3.4 4.6
compr. 52.7% 65.9% 56.8%
Figure 5: Sentence condensation from manually selected
f -structure for original uncondensed sentences.
be seen from these tables, the ranking of system variants
produced by the automatic and manual evaluation con-
firm a close correlation between the automatic evaluation
and human judgments. A comparison of evaluation re-
sults across colums, i.e. across selection variants, shows
that a stochastic selection of transferred f -structures is
indeed important. Even if all f -structures are transferred
from the same linguistically rich source, and all gener-
ated strings are grammatical, a reduction in error rate of
around 50% relative to the upper bound can be achieved
by stochastic selection. In contrast, a comparison be-
tween transfer runs with and without perfect disambigua-
tion of the original string shows a decrease of about 5% in
F-score, and of only .1 points for summarization quality
when transferring from packed parses instead of from the
manually selected parse. This shows that it is more im-
portant to learn what a good transferred f -structure looks
like than to have a perfect f -structure to transfer from.
The compression rates associated with the systems that
used stochastic selection is around 60%, which is accept-
able, but not as aggressive as human-written condensa-
tions. Note that in our current implementation, in some
cases the transfer component was unable to operate on
the packed representation. In those cases a parse was cho-
sen at random as a conservative estimate of transfer from
all parses. This fall-back mechanism explains the drop in
F-score for the upper bound in comparing Figs. 5 and 6.
5 Conclusion
We presented an approach to sentence condensation
that employs linguistically rich LFG grammars in a
parsing/generation-based stochastic sentence condensa-
tion system. Fine-grained dependency structures are out-
put by the parser, then modified by a highly expressive
transfer system, and filtered by a constraint-based gener-
ator. Stochastic selection of generation-filtered reduced
structures uses a powerful Maximum-Entropy model.
As shown in an experimental evaluation, summarization
testset I lowerbound
system
selection
upper
bound
F-score 55.2% 63.0% 72.0%
sum-quality 2.1 3.4 4.4
compres. 46.5% 61.6% 54.9%
testset II lowerbound
system
selection
upper
bound
F-score 54% 59.7% 76.0 %
sum-quality 1.9 3.3 4.6
compres. 50.9% 60.0% 56.8%
Figure 6: Sentence condensation from packed f -
structures for original uncondensed sentences.
quality of the system output is state-of-the-art, and gram-
maticality of condensed strings is guaranteed. Robustness
techniques for parsing and generation guarantee that the
system produces non-empty output for unseen input.
Overall, the summarization quality achieved by
our system is similar to the results reported in
Knight and Marcu (2000). This might seem disappoint-
ing considering the more complex machinery employed
in our approach. It has to be noted that these re-
sults are partially due to the somewhat artificial na-
ture of the data that were used in the experiments of
Knight and Marcu (2000) and therefore in our experi-
ments: The human-written condensations in the data set
extracted from the Ziff-Davis corpus show the same
word order as the original sentences and do not exhibit
any structural modification that are common in human-
written summaries. For example, humans tend to make
use of structural modifications such as nominalization
and verb alternations such as active/passive or transi-
tive/intransitive alternations in condensation. Such alter-
nations can easily be expressed in our transfer-based
approach, whereas they impose severe problems to ap-
proaches that operate only on phrase structure trees. In
the given test set, however, the condensation task re-
stricted to the operation of deletion. A creation of addi-
tional condensations for the original sentences other than
the condensed versions extracted from the human-written
abstracts would provide a more diverse test set, and fur-
thermore make it possible to match each system output
against any number of independent human-written con-
densations of the same original sentence. This idea of
computing matching scores to multiple reference exam-
ples was proposed by Alshawi et al (1998), and later by
Papineni et al (2001) for evaluation of machine transla-
tion systems. Similar to these proposals, an evaluation
of condensation quality could consider multiple reference
condensations and record the matching score against the
most similar example.
Another desideratum for future work is to carry
condensation all the way through without unpacking
at any stage. Work on employing packing techniques
not only for parsing and transfer, but also for genera-
tion and stochastic selection is currently underway (see
Geman and Johnson (2002)). This will eventually lead to
a system whose components work on packed represen-
tations of all or n-best solutions, but completely avoid
costly unpacking of representations.
References
Hiyan Alshawi, Srinivas Bangalore, and Shona Douglas.
1998. Automatic acquisition of hierarchical trans-
duction models for machine translation. In Proceed-
ings of the 36th Annual Meeting of the Association for
Computational Linguistics (ACL?98), Montreal, Que-
bec, Canada.
John Carroll, Guido Minnen, Yvonne Canning, Siobhan
Devlin, and John Tait. 1998. Practical simplification
of english newspaper text to assist aphasic readers. In
Proceedings of the AAAI Workshop on Integrating Arti-
ficial Intelligence and Assistive Technology, Madison,
WI.
Anette Frank. 1999. From parallel grammar develop-
ment towards machine translation. In Proceedings of
the MT Summit VII. MT in the Great Translation Era,
pages 134?142. Kent Ridge Digital Labs, Singapore.
Stuart Geman and Mark Johnson. 2002. Dynamic
programming for parsing and estimation of stochas-
tic unification-based grammars. In Proceedings of the
40th Annual Meeting of the Association for Computa-
tional Linguistics (ACL?02), Philadelphia, PA.
Gregory Grefenstette. 1998. Producing intelligent tele-
graphic text reduction to provide an audio scanning
service for the blind. In Proceedings of the AAAI
Spring Workshop on Intelligent Text Summarization,
Stanford, CA.
Hongyan Jing. 2000. Sentence reduction for automatic
text summarization. In Proceedings of the 6th Applied
Natural Language Processing Conference (ANLP?00),
Seattle, WA.
Mark Johnson, Stuart Geman, Stephen Canon, Zhiyi Chi,
and Stefan Riezler. 1999. Estimators for stochastic
?unification-based? grammars. In Proceedings of the
37th Annual Meeting of the Association for Computa-
tional Linguistics (ACL?99), College Park, MD.
Kevin Knight and Daniel Marcu. 2000. Statistics-based
summarization?step one: Sentence compression. In
Proceedings of the 17th National Conference on Arti-
ficial Intelligence (AAAI-2000), Austin, TX.
John Maxwell and Ronald M. Kaplan. 1989. An
overview of disjunctive constraint satisfaction. In Pro-
ceedings of the International Workshop on Parsing
Technologies, Pittsburgh, PA.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2001. Bleu: a method for automatic evalua-
tion of machine translation. Technical Report IBM Re-
search Division Technical Report, RC22176 (W0190-
022), Yorktown Heights, N.Y.
Stefan Riezler, Tracy H. King, Ronald M. Kaplan,
Richard Crouch, John T. Maxwell, and Mark John-
son. 2002. Parsing the Wall Street Journal using a
Lexical-Functional Grammar and discriminative esti-
mation techniques. In Proceedings of the 40th Annual
Meeting of the Association for Computational Linguis-
tics (ACL?02), Philadelphia, PA.
Michael J. Witbrock and Vibhu O. Mittal. 1999. Ultra-
summarization: A statistical approach to generating
highly condensed non-extractive summaries. In Pro-
ceedings of the 22nd ACM SIGIR Conference on Re-
search and Development in Information Retrieval,
Berkeley, CA.
Proceedings of the ACL Workshop on Empirical Modeling of Semantic Equivalence and Entailment, pages 31?36,
Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
Local Textual Inference: can it be defined or circumscribed?
Annie Zaenen
Palo Alto Research Center
3333, Coyote Hill Road
Palo Alto, CA 94304
zaenen@parc.com
Lauri Karttunen
Palo Alto Research Center
3333, Coyote Hill Road
Palo Alto, CA 94304
karttunen@parc.com
Richard Crouch
Palo Alto Research Center
3333, Coyote Hill Road
Palo Alto, CA 94304
crouch@parc.com
Abstract
This paper argues that local textual in-
ferences come in three well-defined vari-
eties (entailments, conventional implica-
tures/presuppositions, and conversational
implicatures) and one less clearly defined
one, generally available world knowledge.
Based on this taxonomy, it discusses some
of the examples in the PASCAL text suite
and shows that these examples do not fall
into any of them. It proposes to enlarge the
test suite with examples that are more di-
rectly related to the inference patterns dis-
cussed.
1 Introduction
The PASCAL initiative on ?textual entailment? had
the excellent idea of proposing a competition testing
NLP systems on their ability to understand language
separate from the ability to cope with world knowl-
edge. This is obviously a welcome endeavor: NLP
systems cannot be held responsible for knowledge
of what goes on in the world but no NLP system can
claim to ?understand? language if it can?t cope with
textual inferences. The task also shies away from
creative metaphorical or metonymic use of language
and makes the assumption that referential assign-
ments remain constant for entities that are described
in the same way. These all seem good features of the
proposal as it stands.
Looking at the challenge as it was put before the
community, however, we feel that it might be useful
to try to circumscribe more precisely what exactly
should count as linguistic knowledge. In this paper
we make a stab at this in the hope of getting a discus-
sion going. For reasons that will become clear, we
prefer to talk about TEXTUAL INFERENCES rather
than about textual entailments when referring to the
general enterprise. We first explicitate what we think
should be covered by the term textual inferences, we
then look at the PASCAL development suite in the
light of our discussion and we conclude with a short
proposal for extensions to the test suite.
Before even starting at this, a point of clarification
needs to be made: the correspondence of a linguis-
tic object to an object in the real world goes beyond
what can be learned from the text itself. When some-
body says or writes The earth is flat or The king of
France is bald because (s)he is a liar or ill-informed,
nothing in these linguistic expressions in themselves
alerts us to the fact that they do not correspond to sit-
uations in the real world (we leave texts in which the
author signals consciously or unconsiously that he is
lying or fibbing out of consideration here.) What the
text does is give us information about the stance its
author takes vis-a`-vis the events or states described.
It is thus useful to distinguish between two ingre-
dients that go into determining the truth value of an
utterance, one is the trustworthiness of the utterer
and the other is the stance of the utterer vis-a`-vis
the truth of the content. The latter we will call the
veridicity of the content. When we talk about tex-
tual inferences we are only interested in veridicity
not in the truth which lies beyond what can be in-
ferred from texts. Or, maybe more realistically, we
assume a trustworthy author so that veridical state-
ments are also true.
31
2 Varieties of local textual inferences
Under this assumption of trustworthiness, semantics
and pragmatics as practiced by philosophers and lin-
guists can give us some insights that are of practical
relevance. Work done in the last century has led re-
searchers to distinguish between entailments, con-
ventional implicatures and conversational implica-
tures. We describe these three classes of inferences
and illustrate why the distinctions are important for
NLP.
2.1 Entailments
The most uncontroversional textual inferences are
those that can be made on the basis of what is as-
serted in a text. If the author makes the statement
that Tony Hall arrived in Baghdad on Sunday night,
then we can conclude that Tony Hall was in Bagh-
dad on Sunday night (keeping referring expressions
constant, as proposed in the PASCAL task). The sec-
ond sentence is true when the first is true (assum-
ing we are talking about the same Tony Hall, the
same Baghdad and the same Sunday) just by virtue
of what the words mean.
In simple examples such as that in (1)
(1) Bill murdered John.
Bill killed John.
one can go to a resource such as WordNet, look up
murder, discover that it means kill with some fur-
ther conditions. ?Ontologies? or thesauruses typi-
cally order terms in a hierarchy that encodes a re-
lation from less specific at the top of the hierarchy
to more specific at the bottom. In simple clauses
the replacement of a more specific term with a less
specific one, ensures an upward monotonic relation
between these sentences. As is well known this re-
lation is inversed when the sentences are negated.1
(2) Bill didn?t murder John.
does not entail Bill didn?t kill John.
but
(3) Bill didn?t kill John.
does entail Bill didn?t murder John.
Monotonicity relations also hold when adjectival
modification is introduced as in (4)
1A sentence is downward monotonic iff it remains true when
it is narrowed. A sentence is upward monotonic when it remains
true when it is broadened.
(4) Ames was a clever spy.
entails Ames was a spy.
Again negation reverses the entailment:
(5) Ames wasn?t a spy.
entails Ames wasn?t a clever spy.
Quantifiers, easily among the most intensively
studied lexical items, also exhibit upward or down-
ward monotonicity.2 To give just one example:
(6) All companies have to file annual reports.
entails All Fortune 500 companies have to file
annual reports.
but
(7) All companies have to file annual reports.
does not entail All companies have to file an-
nual reports to the SEC.
The fact that there are both upwards monotonic
and downwards monotonic expressions means that
simple matching on an inclusion of relevant mate-
rial cannot work as a technique to detect entailments.
Upward monotone expressions preserve truth by
leaving out material whereas downward monotone
expressions don?t: adding material to them can be
truth preserving.3
Apart from a more specific/less specific relation,
lexical items can establish a part-subpart relation be-
tween the events they describe. If we followed the
first sentence in (1) by
(8) John died.
we would still have a lexical inference. In this case
one in which the event described in the second sen-
tence is a subpart of the event described in the first.
The investigation of entailments leads one to dis-
tinguish several types of lexical items that have pre-
dictable effects on meaning that can be exploited to
discover sentences that are inferentially related (by
real entailments in this case). Other examples are
scope bearing elements (an aspect of meaning that
often leads to ambiguities which are not always eas-
ily perceived) and perception reports.
2A quantifier Q is downward monotonic with respect to its
restrictor ? iff ((Q ?) ?) remains true when the ? is narrowed,
e.g. from companies to Fortune 500 companies. A quantifier Q
is upward monotonic with respect to its scope ? iff ((Q ?) ?)
remains true when ? is broadened, e.g. from have to file reports
to the SCE to just have to file reports.
3Dagan and Glickman (2004) explore inferencing by syn-
tactic pattern matching techniques but consider only upward
monotonic expressions. Their proposal ensures loss of recall
on downward monotonic expressions.
32
Two types of relations deserve special mention
here because they are pervasive and they are at the
borderline between linguistic and world knowledge:
temporal relations and spatial relations. Whether
knowing that Tuesday follows Monday or that there
are leap years and non-leap years is linguistic knowl-
edge or world knowledge might not be totally clear
but it is clear that one wants this information to be
part of what textual entailment can draw upon. The
consequences in a Eucledian space of the place and
movement of objects are similar. There is a rich set
of entailment relations that builds on these temporal
and spatial notions.
2.2 Conventional Implicatures4
Apart from making assertions, however, an author
will often ?conventionally implicate? certain things.
We use here the term conventional implicature for
what has been called by that name or labeled as (se-
mantic) presupposition. Some of us have argued
elsewhere there is no need for a distinction between
these two notions (Karttunen and Peters, 1979) and
that presupposition is a less felicitous term because
it tends to be confused with ?old information?.
Traditionally these implications are not consid-
ered to be part of what makes the sentence true, but
the author is COMMITTED to them and we consider
them part of what textual inferences should be based
on. We take this position because we think it is rea-
sonable, for IE tasks, to assume that material that is
conventionally implicated can be used in the same
way as assertions, for instance, to provide answers
to questions. When somebody says Bill acknowl-
edges that the earth is round, we know something
about the author?s as well as Bill?s beliefs in the mat-
ter, namely that the author is committed to the belief
that the earth is round.
If all conventionally implied material were also
discourse old information, this might not matter very
much as the same information would be available
elsewhere in the text, but often conventionally im-
plied material is new information that is presented
as not being under discussion. Conventional impli-
catures are a rich source of information for IE tasks
because the material presented in them is supposed
4For more on conventional implicatures, see e.g. Karttunen
and Peters (1979) and Potts (2005)
to be non-controversial. In newspapers and other in-
formation sources they are a favorite way to distin-
guish background knowledge, that the reader might
have or not, without confusing it with what is news-
worthy in the report at hand. A very common ex-
ample of this, exploited in the PASCAL test suite, is
the use of appositives. illustrated in the following
example:
(9) The New York Times reported that Hanssen,
who sold FBI secrets to the Russians, could face
the death penalty.
Did Hanssen sell FBI reports to the Russians?
YES
From the perspective of IE tasks, the way conven-
tional implicatures behave under negation is one rea-
son to pay close attention to them. The following
examples illustrate this:
(10) Kerry realized that Bush was right.
Bush was right.
(11) Kerry didn?t realize that Bush was right.
Bush was right.
Other types of embedded clauses that are conven-
tionally implicated are temporal adverbials (except
those introduced by before or until. Other types of
material that can introduce a conventional implica-
ture are adverbial expressions such as evidently and
simple adverbs such as again or still.
It is important to point out that the syntactic struc-
ture doesn?t guide the interpretation here. Consider
the following contrast:
(12) As the press reported, Ames was a successful
spy.
conventionally implicates that Ames was a success-
ful spy, but
(13) According to the press, Ames was a successful
spy.
does not.
2.3 Conversational Implicatures5
Authors can be held responsible for more than just
assertions and conventional implicatures. Conversa-
tional implicatures are another type of author com-
mitment. A conversational implicature rests on the
assumption that, in absence of evidence to the con-
trary, a collaborative author will say as much as she
5For more on conversational implicatures, see e.g. Grice
(1989) and Horn (2003)
33
knows. So if Sue says that she has four children,
we tend to conclude that she has no more than four.
This type of implicature can be destroyed without
any contradiction arising: He not only ate some of
the cake, he ate all of it. Within the context of a tex-
tual inference task such as that defined in the PAS-
CAL initiative, it is clear that inferences based on
conversational implicatures might be wrong: PAS-
CAL doesn?t give the context. In a more developed
type of inference task, a distinction should be made
between this type of inference and the ones we dis-
cussed earlier, but when inferencing is reduced to
one sentence it seems more reasonable to take gen-
eralized conversational implicatures into account as
bona fide cases of inferences (except of course if
they are cancelled in the sentence itself, as in the
example above).
(14) I had the time to read your paper.
conversationally implies that I read your paper. But
it could be followed by but I decided to go play ten-
nis instead.
(15) Some soldiers were killed.
conversationally implies Not all soldiers were killed.
But it could be cancelled by In fact we fear that all
of them are dead.
(16) He certainly has three children.
conversationally implies He doesn?t have more than
three children but it could be followed by In fact he
has five, three daughters and two sons.
Apart from the general conversational implica-
tures, implicatures can also arise by virtue of some-
thing being said or not said in a particular context. If
in a letter of recommendation, one praises the can-
didate?s handwriting without saying anything about
his intellectual abilities, this allows the reader to
draw some conclusions. We assume here that this
type of inference is not part of the PASCAL task, as
too little context is given for it to be reliably calcu-
lated.
One might agree with the analysis of various
sources of author commitment given above but be
of the opinion that it doesn?t matter because, given
enough data, it will come out in the statistical wash.
We doubt, however, that this will happen any time
soon without some help: the semantic distinctions
are rather subtle and knowing about them will help
develop adequate features for statistical training.
It might also be thought that the generalizations
that we need here can be reduced to syntactic dis-
tinctions. We don?t have the space to show in great
detail that this is not the case but some reflection
on and experimentation with the examples given
throughout this paper will convince the reader that
this is not the cases. For instance, if one replaces the
adjective clever with the equally good adjective al-
leged in (4) above, the entailment relation between
the sentences doesn?t hold anymore. Substituting
show for realize in (11) has the same effect.
2.4 Some world knowledge?
In our mind this exhausts the ways in which an au-
thor can be held responsible for her writings on the
basis of text internal elements. Textual inferences
are based on textual material that is either an en-
tailment of what is explicitly asserted, or material
that conventionally or conversationally implied by
the author. These inferences can be made solely on
the basis of the way the meaning of the words and
construction she uses are related to other words and
constructions in the language. But even in a task that
tries to separate out linguistic knowledge from world
knowledge, it is not possible to avoid the latter com-
pletely. There is world knowledge that underlies just
about everything we say or write: the societies we
live in use a common view of time to describe events
and rely on the assumptions of Euclidean geometry,
leading to shared calendars and measurement sys-
tems. It would be impossible to separate these from
linguistic knowledge. Then there is knowledge that
is commonly available and static, e.g. that Baghdad
is in Iraq. It seems pointless to us to exclude the
appeal to such knowledge from the test suite but it
would be good to define it more explicitly.
3 The PASCAL development suite.
We now discuss some of the PASCAL development
set examples in the light of the discussion above and
explain why we think some of them do not belong
in a textual inference task. First a number of PAS-
CAL examples are based on spelling variants or even
spelling mistakes. While it is clear that coping with
this type of situation is important for NLP applica-
tions we think they do not belong in a textual infer-
ence test bed. We first discuss a couple of examples
34
that we think should not have been in the test suite
and then some that do not confirm to our view on
inferencing but which might belong in a textual in-
ference test suite.
3.1 Errors?
A problem arises with an example like the follow-
ing:
(17) A farmer who was in contact with cows suffer-
ing from BSE ? the so-called mad cow disease
? has died from what is regarded as the human
form of the disease.
Bovine spongiform encephalopathy is another
name for the ?mad cow disease?.
TRUE
If one googles BSE, one finds that it is an abbre-
viation that can stand for many things, including
the Bombay, Bulgarian, Baku or Bahrain Stock Ex-
change, Breast Self-Examination, and Brain Sur-
face Extractor. To select the right alternative, one
needs the knowledge that ?bovine spongiform en-
cephalopathy? is a name of a disease and the other
competing BSE expansions are not.
The authors of the PASCAL test suite don?t seem
to allow for as much world knowledge when they
mark the following relation as FALSE.
(18) ?I just hope I don?t become so blissful I be-
come boring? ? Nirvana leader Kurt Cobain
said, giving meaning to his ?Teen Spirit? coda,
a denial.
?Smells Like Teen Spirit? is a song by Nirvana.
FALSE
Apparently, it is NOT OK to know that the Nirvana
song ?Smells like Teen Spirit? is often referred to as
?Teen Spirit?. But why should we then know that
bovine spongiform encephalopathy is a disease?
The test suite also contains examples that can only
be classified as plain errors. A couple of examples
are the following:
(19) Green cards are becoming more difficult to ob-
tain.
Green card is now difficult to receive.
TRUE
Something that is becoming more difficult can still
be easy, if it starts out that way.
(20) Hippos do come into conflict with people quite
often.
Hippopotamus attacks human.
TRUE
For somebody who knows a lot about hippos it might
be reasonable to assume that a conflict is necessarily
an attack but in general there is no inference: conflict
is the less general term and attack the more specific
one.
(21) A statement said to be from al Qaida claimed
the terror group had killed one American and
kidnapped another in Riyadh.
A U.S. citizen working in Riyadh has been kid-
napped.
TRUE
This seems betray a rather implausible belief in the
claims of al Qaida and while we are assuming that
the author of the text is trustworthy, this assumption
does not extend to the sources he invokes. In this
case especially, the use of claim can be construed as
indication the doubt of the author about the veracity
of what the source says.
(22) Wal-Mart is being sued by a number of its
female employees who claim they were kept
out of jobs in management because they were
women.
Wal-Mart is sued for sexual discrimination.
TRUE
A minute of reflection will make clear that here the
relation between the two sentences involves quite a
bit of specialized legal knowledge and goes beyond
textual inferencing. How is sexual discrimination
different from sexual harassment?
(23) South Korean?s deputy foreign minister says
his country won?t change its plan to send 3000
soldiers to Iraq.
South Korea continues to send troops.
TRUE
We assume that in context the second sentence
means that South Korea continues to plan to send
troops but normally continue does not mean con-
tinue to plan and the first sentence certainly doesn?t
imply that South Korea has already sent troops. Here
the way the test suite has been put together leads
to odd results. A headline is paired up with a full
sentence. Headlines are not meant to be understood
completely out of context and it would be prudent to
use them sparingly in inference tasks of the sort pro-
posed here. We discuss other consequences of the
way the test suite was constructed in the next sub-
section with examples that to our mind need some
kind of accommodation.
35
3.2 Not a textual inference as such but . . .
There are a couple of examples such as the following
in the test suite:
(24) The White House failed to act on the domes-
tic threat from al Qaida prior to September 11,
2001.
White House ignored the threat of attack.
TRUE
Here there is no entailment either way and surely
fail to act is not a synonym of ignore. The examples
are due to the way the PASCAL test suite was put to-
gether. It was evidently at least in part developed by
finding snippets of text that refer to the same event
in different news sources; this is a fertile method for
finding inferences but it will lead to the inclusion of
some material that mixes factual description and var-
ious APPRECIATIONS of the described facts. For in-
stance in (24) above, two different authors described
what the White house did, putting a different spin
on it. While the fact described in both cases was
the same, the appreciations that the two renderings
give, while both negative, are not equivalent. But
although there is no legitimate inference for the sen-
tences as a whole, they both entail that the White
House did not act. Here the test suite is the victim of
its self imposed constraints, namely that the relation
has to be established between two sentences found
in ?real? text. We propose to give up this constraint.
Another maybe simpler illustration of the same
problem is (25):
(25) The report catalogues 10 missed opportunities.
The report lists 10 missed opportunities.
Although catalogue and list do not have the same
meaning, they may in some cases be used inter-
changeably because, again, there is a common en-
tailment:
(26) According to the report, there were 10 missed
opportunities.
One can conceive of a thesaurus where catalogue
and list would have a low level common hypernym
(in WordNet they don?t) or a statistically inferred
word class that would make the common entailment
explicit, but that relation should not be confused
with an inference between the two sentences in (25).
4 A proposal for some refinements
As the discussion above has shown, the way the test
suite was put together leads sometimes to the in-
clusion of material that should not be there given
the definition of the task. Most of the data that
form the basis of PASCAL are extracted from differ-
ent newspaper articles about the same event, often
from the same newswire. This means that the infor-
mation packaging is very similar, reducing the con-
structional and lexical range that can be used to ex-
press a same idea. This situation will not pertain in
the more general setting of question answering and
many types of paraphrases or inferences that would
be useful for question answering in general will not
be found or will be very rare in PASCAL-like suites.
We would propose to augment the types of pairs
that one can get through the PASCAL extraction tech-
niques with some that take the type of relations that
we have discussed explicitly into account. It can be
objected that this introduces a new level of artificial-
ity by allowing made-up sentences but the separa-
tion of world knowledge from linguistic knowledge
is in any case artificial. But it is necessary because
we will not be able to solve the inferencing problem
without slicing the task into manageable pieces.
Acknowledgments
This article was supported in part by the Advanced
Research and Development Agency (ARDA) within
the program for Advanced Question Answering for
Intelligence (AQUAINT). Thanks to all the members
of PARC?s AQUAINT team.
References
Ido Dagan and Oren Glickman. 2004. Probabilistic tex-
tual entailment: Generic applied modeling of language
variablity. In Learning Methods for Text Understand-
ing and Mining, Grenoble, January.
Paul H. Grice. 1989. Studies in the Way of Words. Har-
vard University, Cambridge, MA.
Larry Horn. 2003. Implicature. In Horn and Ward, edi-
tors, Handbook of Pragmatics. Blackwell, Oxford.
Lauri Karttunen and Stanley Peters. 1979. Conventional
implicature. In Choon-Kyu Oh and David A. Dinneen,
editors, Syntax and Semantics, Volume 11: Presuppo-
sition, pages 1?56. Academic Press, New York.
Christopher Potts. 2005. The Logic of Conventional Im-
plicatures. Oxford Studies in Theoretical Linguistics.
Oxford University Press, Oxford.
36
Proceedings of the Workshop on Textual Entailment and Paraphrasing, pages 16?21,
Prague, June 2007. c?2007 Association for Computational Linguistics
Precision-focused Textual Inference
D. G. Bobrow, C. Condoravdi, R. Crouch, V. de Paiva, L. Karttunen, T. H. King, R. Nairn, L. Price, A. Zaenen
Palo Alto Research Center
Abstract
This paper describes our system as used in
the RTE3 task. The system maps premise and
hypothesis pairs into an abstract knowledge
representation (AKR) and then performs en-
tailment and contradiction detection (ECD)
on the resulting AKRs. Two versions of ECD
were used in RTE3, one with strict ECD and
one with looser ECD.
1 Introduction
In the RTE textual entailment challenge, one is given
a source text T and a hypothesis H, and the task is to
decide whether H can be inferred from T. Our sys-
tem interprets inference in a strict way. Given the
knowledge of the language embedded in the system,
does the hypothesis logically follow from the infor-
mation embedded in the text? Thus we are empha-
sizing precision, particularly in question-answering.
This was reflected in our results in the RTE3 chal-
lenge. We responded correctly with YES to relatively
few of the examples, but on the QA-type examples,
we achieved 90-95% average precision.
The methodology employed is to use the linguis-
tic information to map T and H onto a logical form in
AKR, our Abstract Knowledge Representation. The
AKR is designed to capture the propositions the au-
thor of a statement is committed to. For the sake of
ECD, the representation of T may include elements
that are not directly expressed in the text. For ex-
ample, in the AKR of John bought a car includes the
fact that the car was sold. The AKR of John forgot to
buy milk includes the fact that John did not buy milk.
Our reasoning algorithm tries to determine whether
the AKR of H is subsumed by the AKR of T and detect
cases when they are in conflict.
The Entailment and Contradiction Detection
(ECD) algorithm makes a distinction that is not part
of the basic RTE challenge. If T entails the negation
of H, we answer NO (Contradiction). On the other
Process Output
Text-Breaking Delimited sentences
Named-entity recognition Type-marked Entities
Morphological Analysis Word stems plus features
LFG Parsing Functional Structure
Semantic processing Scope, Predicate-
argument structure
AKR rules Conceptual, Contextual,
Temporal Structure
Figure 1: The processing pipeline: processes with
their ambiguity-enabled packed outputs
hand, if there is no direct entailment we answer UN-
KNOWN. We do not try to construct a likely scenario
that would link T and H. Nor have we tried to col-
lect data on phrases that would tend to indicate such
likely associations between T and H. That approach
is clearly very useful (e.g. (Hickl et al, 2006)), and
could be used as a backup strategy with our more
formal entailment approach. We have chosen to fo-
cus on strict structural and lexical entailments.
This paper describes the processing pipeline for
mapping to AKR, the ECD algorithm, the challenges
we faced in processing the RTE data and a summary
of our results on RTE3.
2 Process Pipeline
Figure 1 shows the processing pipeline for mapping
texts to AKR. The input is a text of one or more
sentences.
All components of the system are ?ambiguity en-
abled? (Maxwell and Kaplan, 1991). This allows
each component to accept ambiguous input in a
?packed? format, process it without unpacking the
ambiguities, and then pass packed input to the next
stage. The syntactic component, LFG Parsing, also
has a stochastic disambiguation system which al-
lows us to pass the n-best on to the semantics (Rie-
zler et al, 2002); for the RTE3 challenge, we used
16
n=50.
The parser takes the output of the morphology
(i.e. a series of lemmata with their tags) and pro-
duces a tree (constituent-structure) and a depen-
dency structure (functional-structure) represented as
an attribute-value matrix. The functional-structure
is of primary importance for the semantics and
AKR. In particular, it encodes predicate-argument
relations, including long-distance dependencies, and
provides other syntactic features (e.g. number, tense,
noun type).
The output of the syntax is input for the seman-
tics that is produced by an ambiguity enabled packed
rewriting system. The semantics is described in de-
tail in (Crouch and King, 2006). Semantic process-
ing assigns scope to scope-bearing elements such as
negation and normalizes the output of the syntax.
This normalization includes reformulating syntactic
passives as actives (e.g. The cake was eaten by Mary.
/ Mary ate the cake.), resolving many null pronouns
(e.g. Laughing, John entered the room / Johni laugh-
ing, Johni entered the room.), and canonicalizing
measure phrases, comparatives, and dates. More
complex normalizations involve converting nominal
deverbals into the equivalent verbal form, identify-
ing arguments of the verb from the arguments of
the nominal (Gurevich et al, 2006). For example,
the semantic representation of Iraq?s destruction of
its WMD is similar to the representation of Iraq de-
stroyed its WMD.
The final main task of the semantics rules is to
convert words into concepts and syntactic grammat-
ical functions into roles. The mapping onto concepts
uses WordNet (Fellbaum, 1998) to map words into
lists of synsets. The named entity types provided by
the morphology and syntax are used to create more
accurate mapping of proper nouns since these are
not systematically represented in WordNet. The se-
mantic rules use the grammatical function subcat-
egorization information from the verb and the role
information found in extended VerbNet (Kipper et
al., 2000) to map syntactic subjects, objects, and
obliques into more abstract thematic roles such as
Agent, Theme, and Goal (Crouch and King, 2005).
This mapping into thematic-style roles allows the
system to correctly align the arguments in pairs like
(1) and (2), something which is impossible using just
syntactic functions. In the first, the object and sub-
ject have a common thematic role in the alternation
between transitive and intransitive; while in the sec-
ond, the common role is shared by the subjects.
(1) John broke the vasesyn:object,sem:patient.
The vasesyn:subject,sem:patient broke.
(2) Johnsyn:subject,sem:agent ate the cake.
Johnsyn:subject,sem:agent ate.
The goal of these semantic normalizations is to
abstract away from the syntactic representation so
that sentences with similar meaning have similar se-
mantic representations. However, the semantics is
still fundamentally a linguistic level of representa-
tion; further abstraction towards the meaning is done
in the mapping from semantics to AKR. The AKR
is the level of representation that is used to deter-
mine entailment and contradiction in our RTE3 sys-
tem. A preliminary description of its logic was pro-
vided in (Bobrow et al, 2005). The AKR mapping
converts grammatical tense and temporal modifiers
into temporal relations, identifies anaphoric refer-
ents and makes explicit the implied relation between
complement clauses and the main verb (e.g. for
manage, fail) (Nairn et al, 2006). AKR also deals
with standard phrases that are equivalent to simple
vocabulary terms. For example, take a flight to New
York is equivalent to fly to New York. These uses
of ?light? verbs (e.g. take, give) are not included
in synonyms found in WordNet. Another class of
phrasal synonyms involve inchoatives (e.g. take a
turn for the worse/worsen). We included a special
set of transformation rules for phrasal synonyms:
some of the rules are part of the mapping from se-
mantics to AKR while others are part of the ECD
module. The mapping to AKR is done using the same
ambiguity-enabled ordered rewriting system that the
semantics uses, allowing the AKR mapping system
to efficiently process the packed output of the se-
mantics.
The AKR for a sentence like Bush claimed that
Iraq possessed WMDs in Figure 2 introduces two
contexts: a top level context t, representing the com-
mitments of the speaker of sentence, and an embed-
ded context claim cx:37 representing the state of af-
fairs according to Bush?s claim. The two contexts
are related via the Topic role of the claim event.
The representation contains terms like claim:37 or
17
Conceptual Structure
subconcept(claim:37,[claim-1,. . .,claim-5])
role(Topic,claim:37,claim cx:37)
role(Agent,claim:37,Bush:1)
subconcept(Bush:1,[person-1])
alias(Bush:1,[Bush])
role(cardinality restriction,Bush:1,sg)
subconcept(possess:24,[possess-1,own-1,possess-3])
role(Destination,possess:24,wmd:34)
role(Agent,possess:24,Iraq:19)
subconcept(Iraq:19,[location-1,location-4])
alias(Iraq:19,[Iraq])
role(cardinality restriction,Iraq:19,sg)
subconcept(wmd:34,
[weapon of mass destruction-1])
role(cardinality restriction,wmd:34,pl)
Contextual Structure
context(t)
context(claim cx:37)
context relation(t,claim cx:37,crel(Topic,claim:37))
instantiable(Bush:1,t)
instantiable(Iraq:19,t)
instantiable(claim:37,t)
instantiable(Iraq:19,claim cx:37)
instantiable(possess:24,claim cx:37)
instantiable(wmd:34,claim cx:37)
Temporal Structure
temporalRel(After,Now,claim:37)
temporalRel(After,claim:37,possess:24)
Figure 2: AKR for Bush claimed that Iraq possessed
WMDs.
Bush:1 which refer to the kinds of object that the
sentence is talking about. The subconcept facts ex-
plicitly link these terms to their concepts in Word-
Net. Thus claim:37 is stated to be some subkind
of the type claim-1, etc., and wmd:34 to be some
subkind of the type weapon of mass destruction-
1. Terms like claim:37 and wmd:34 do not refer
to individuals, but to concepts (or types or kinds).
Saying that there is some subconcept of the kind
weapon of mass destruction-1, where this subcon-
cept is further restricted to be a kind of WMD pos-
sessed by Iraq, does not commit you to saying that
there are any instances of this subconcept.
The instantiable assertions capture the commit-
ments about the existence of the kinds of object de-
scribed. In the top-level context t, there is a com-
mitment to an instance of Bush and of a claim:37
event made by him. However, there is no top-level
commitment to any instances of wmd:34 possessed
by Iraq:19. These commitments are only made in
the embedded claim cx:37 context. It is left open
whether these embedded commitments correspond,
or not, to the beliefs of the speaker. Two distinct
levels of structure can thus be discerned in AKR: a
conceptual structure and a contextual structure. The
conceptual structure, through use of subconcept and
role assertions, indicates the subject matter. The
contextual structure indicates commitments as to the
existence of the subject matter via instantiability as-
sertions linking concepts to contexts, and via context
relations linking contexts to contexts. In addition,
there is a temporal structure that situates the events
described with respect to the time of utterance and
temporally relates them to one another.
3 Entailment and Contradiction Detection
ECD is implemented as another set of rewrite rules,
running on the same packed rewrite system used to
generate the AKR representations. The rules (i) align
concept and context terms in text (T) and hypoth-
esis (H) AKRs, (ii) calculate concept subsumption
orderings between aligned T and H terms, and (iii)
check instantiability and uninstantiability claims in
the light of subsumption orderings to determine
whether T entails H, T contradicts H, or T neither
entails not contradicts H. For the purposes of RTE3,
both contradiction and neither contradiction nor en-
tailment are collapsed into a NO (does not follow)
judgment.
One of the novel features of this approach is that
T and H representations do not need to be disam-
biguated before checking for entailment or contra-
diction. The approach is able to detect if there is one
reading of T that entails (or contradicts) one reading
of H. The T and H passages can in effect mutually
disambiguate one another through the ECD. For ex-
ample, although plane and level both have multiple
readings, they can both refer to a horizontal surface,
and in that sense The plane is dry entails The level is
dry, and vice versa.
The first phase of ECD aligns concepts and con-
text terms in the T and H AKRs. Concepts are repre-
18
sented as lists of WordNet hypernym lists, in Word-
Net sense order. Two concept terms can be aligned
if a sense synset of one term (i.e. the first element
of one of the term?s hypernym lists) is contained in
a hypernym list of the other term. The alignment
can be weighted according to word sense; so a con-
cept overlap on the first senses of a T and H term
counts for more than a concept overlap on the n and
mth senses. However, no weightings were used in
RTE3. For named entities, alignment demands not
only a concept overlap, but also an intersection in
the ?alias? forms of the proper nouns. For exam-
ple,?George Bush? may be aligned with ?George?
or with ?Bush?. Context alignment relies on associ-
ating each context with an indexing concept, usually
the concept for the main verb in the clause heading
the context. Contexts are then aligned on the basis
of these concept indices.
Typically, an H term can align with more than one
T term. In such cases all possible alignments are
proposed, but the alignment rules put the alternative
alignments in different parts of the choice space.
Having aligned T and H terms, rules are applied to
determine concept specificity and subsumption rela-
tions between aligned terms. Preliminary judgments
of specificity are made by looking for hypernym in-
clusion. For example, an H term denoting the con-
cept ?person? is less specific than a T term denot-
ing ?woman?. These preliminary judgments need to
be revised in the light of role restrictions modifying
the terms: a ?tall person? is neither more nor less
specific than a ?woman?. Revisions to specificity
judgments also take into account cardinality modi-
fiers: while ?person? is less specific than ?woman?,
?all persons? is judged to be more specific than ?all
women?.
With judgments of concept specificity in place,
it is possible to determine entailment relations on
the basis of (un)instantiability claims in the T and
H AKRs. For example, suppose the T and H AKRs
contain the facts in (3).
(3) T: instantiable(C T, Ctx T)
H: instantiable(C H, Ctx H)
where concept C T is aligned with C H, C T is
judged to be more specific than C H, and context
Ctx T is aligned with context Ctx H. In this case,
the hypothesis instantiability claim is entailed by
the text instantiability claim (existence of something
more specific entails existence of something more
general). This being so, the H instantiability claim
can be deleted without loss of information.
If instead we had the (un)instantiability claims in
(4) for the same alignments and specificity relations,
(4) T: instantiable(C T, Ctx T)
H: uninstantiable(C H, Ctx H)
we would have a contradiction: the text says that
there is something of the more specific type C T,
whereas the hypothesis says there are no things of
the more general type C H. In this case, the rules
explicitly flag a contradiction.
Once all (un)instantiability claims have been
compared, it is possible to judge whether the text en-
tails or contradicts the hypothesis. Entailed hypothe-
sis (un)instantiability assertions are deleted from the
representation. Consequently, if there is one T and H
AKR readings and one set of alignments under which
all the H (un)instantiability assertions have been re-
moved, then there is an entailment of H by T. If
there is a pair of readings and a set of alignments
under which a contradiction is flagged, then there
is a contradiction. If there is no pair of readings or
set of alignments under which there is either an en-
tailment or a contradiction, then T and H are merely
consistent with one another. There are exceptional
cases such as (5) where one reading of T entails H
and another reading contradicts it.
(5) T: John did not wait to call for help.
H: John called for help.
Our ECD rules detect such cases.
WordNet often misses synonyms needed for the
alignment in the ECD. In particular, the hierarchy
and synsets for verbs are one of WordNet?s least de-
veloped parts. To test the impact of the missing syn-
onyms, we developed a variation on the ECD algo-
rithm that allows loose matching.
First, in concept alignment, if a verb concept in H
does not align with any verb concept in T, then we
permit it to (separately) align with all the text verb
concepts. We do not permit the same loose align-
ment for noun concepts, since we judge WordNet
information to be more reliable for nouns. This free
alignment of verbs might sound risky, but in gen-
eral these alignments will not lead to useful concept
19
specificity judgments unless the T and H verbs have
very similar arguments / role restrictions.
When such a loose verb alignment is made, we
explicitly record this fact in a justification term in-
cluded in the alignment fact. Similarly, when judg-
ing concept specificity, each rule that applies adds a
term to a list of justifications recorded as part of the
fact indicating the specificity relation. This means
that when the final specificity judgments are deter-
mined, each judgment has a record of the sequence
of decisions made to reach it.
(Un)instantiability comparisons are made as in
strict matching. However, the criteria for detect-
ing an entailment are selectively loosened. If no
contradiction is flagged, and there is a pairing of
readings and alignments under which just a single
H instantiability assertion is left standing, then this
is allowed through as a loose entailment. However,
further rules are applied to block those loose entail-
ments that are deemed inappropriate. These block-
ing rules look at the form of the justification terms
gathered based on specificity judgments.
These blocking rules are manually selected. First,
a loose matching run is made without any block-
ing rules. Results are dumped for each T-H pair,
recording the expected logical relation and the jus-
tifications collected. Blocking rules are created by
detecting patterns of justification that are associated
with labeled non-entailments. One such blocking
rule says that if you have just a single H instantia-
bility left, but the specificity justifications leading to
this have been shown to be reliable on training data,
then the instantiability should not be eliminated as a
loose entailment.
4 Challenges in Processing the RTE Data
The RTE3 data set contains inconsistencies in
spelling and punctuation between the text and the
hypothesis. To handle these, we did an automatic
prepass where we compared the strings in the pas-
sage text to those in the hypothesis. Some of the
special cases that we handled include:
? Normalize capitalization and spacing
? Identify acronyms and shorten names
? Title identification
? Spelling correction
Role names in VerbNet are in part intended to cap-
ture the relation of the argument to the event be-
ing described by the verb. For example, an object
playing an Agent role is causally involved in the
event, while an object playing a Theme or Patient
role is only supposed to be affected. This allows
participants in an action to be identified regardless
of the syntactic frame chosen to represent the verb;
this was seen in (1) and (2). Sometimes the roles
from VerbNet are not assigned in such a way as to
allow such transparent identification across frames
or related verbs. Consider an example. In Ed trav-
els/goes to Boston VerbNet identifies Ed as playing a
Theme role. However, in Ed flies to Boston VerbNet
assigns Ed an Agent role; this difference can make
determining contradiction and entailment between T
and H difficult. We have tried to compensate in our
ECD, by using a backoff strategy where fewer role
names are used (by projecting down role names to
the smaller set). As we develop the system further,
we continue to experiment with which set of roles
works best for which tasks.
Another open issue involves identifying alterna-
tive ways vague relations among objects appear in
text. We do not match the expression the Boston
team with the team from Boston. To improve our re-
call, we are considering loose matching techniques.
5 Summary of our results on RTE3
We participated in the RTE challenge as a way to
understand what our particular techniques could do
with respect to a more general version of textual en-
tailment. The overall experiment was quite enlight-
ening. Tables 1 and 2 summarize how we did on the
RTE3 challenge. System 1 is our standard system
with strict ECD. System 2 used the looser set of ECD
rules.
Gold Sys Cor- R P F
YES YES rect
IE 105 6 5 0.048 0.83 0.20
IR 87 4 4 0.046 1.00 0.21
QA 106 10 9 0.085 0.90 0.28
SUM 112 11 7 0.063 0.64 0.20
Total 410 31 25 0.060 0.84 0.22
Table 1: System 1 with Strict ECD
20
Gold Sys Cor- R P F
YES YES rect
IE 105 15 10 0.095 0.67 0.25
IR 87 6 4 0.046 0.67 0.18
QA 106 14 13 0.12 0.93 0.34
SUM 112 17 10 0.089 0.59 0.23
Total 410 52 37 0.088 0.71 0.25
Table 2: System 2 with Loose ECD
As can be seen, we answered very few of the ques-
tions; only 31 of the possible 410 with a YES answer.
However, for those we did answer (requiring only
linguistic, and not world knowledge), we achieved
high precision: up to 90% on QA. However, we were
not perfect even from this perspective. Here are sim-
plified versions of the errors where our system an-
swered YES, and the answer should be NO with an
analysis of what is needed in the system to correct
the error.
The wrong result in (6) is due to our incomplete
coverage of intensional verbs (seek, want, look for,
need, etc.).
(6) T: The US sought the release of hostages.
H: Hostages were released.
The object of an intensional verb cannot be assumed
to exist or to occur. Intensional verbs need to be
marked systematically in our lexicon.
The problem with (7) lies in the lack of treatment
for generic sentences.
(7) T: Girls and boys are segregated in high school
during sex education class.
H: Girls and boys are segregated in high school.
The natural interpretation of H is that girls and boys
are segregated in high school ALL THE TIME. Be-
cause we do not yet handle generic sentences prop-
erly, our algorithm for calculating specificity pro-
duces the wrong result here. It judges segregation in
H to be less specific than in T whereas the opposite
is in fact the case. Adding the word ?sometimes? to
H would make our YES the correct answer.
The distinction between generic and episodic
readings is difficult to make but crucial for the in-
terpretation of bare plural noun phrases such as girls
and boys. For example, the most likely interpreta-
tion of Counselors are available is episodic: SOME
counselors are available. But Experts are highly
paid is weighted towards a generic reading: MOST
IF NOT ALL experts get a good salary.
These examples are indicative of the subtlety of
analysis necessary for high precision textual infer-
ence.
References
Danny Bobrow, Cleo Condoravdi, Richard Crouch,
Ronald Kaplan, Lauri Karttunen, Tracy Holloway
King, Valeria de Paiva, and Annie Zaenen. 2005. A
basic logic for textual inference. In Proceedings of the
AAAI Workshop on Inference for Textual Question An-
swering.
Dick Crouch and Tracy Holloway King. 2005. Unify-
ing lexical resources. In Proceedings of the Interdisci-
plinary Workshop on the Identification and Represen-
tation of Verb Features and Verb Classes.
Dick Crouch and Tracy Holloway King. 2006. Se-
mantics via F-structure rewriting. In Proceedings of
LFG06. CSLI On-line Publications.
Dick Crouch, Mary Dalrymple, Ron Kaplan, Tracy King,
John Maxwell, and Paula Newman. 2007. XLE docu-
mentation. Available on-line.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. The MIT Press.
Olga Gurevich, Richard Crouch, Tracy Holloway King,
and Valeria de Paiva. 2006. Deverbal nouns in knowl-
edge representation. In Proceedings of FLAIRS 2006.
Andres Hickl, John Williams, Jeremy Bensley, Kirk
Roberts, Bryan Rink, and Ying Shi. 2006. Recog-
nizing textual entailment with LCC?s GROUNDHOG
system. In The Second PASCAL Recognising Textual
Entailment Challenge.
Karin Kipper, Hoa Trang Dang, and Martha Palmer.
2000. Class-based construction of a verb lexicon. In
AAAI-2000 17th National Conference on Artificial In-
telligence.
John Maxwell and Ron Kaplan. 1991. A method for
disjunctive constraint satisfaction. Current Issues in
Parsing Technologies.
Rowan Nairn, Cleo Condoravdi, and Lauri Karttunen.
2006. Computing relative polarity for textual infer-
ence. In Proceedings of ICoS-5.
Stefan Riezler, Tracy Holloway King, Ron Kaplan, Dick
Crouch, John Maxwell, and Mark Johnson. 2002.
Parsing the Wall Street Journal using a Lexical-
Functional Grammar and discriminative estimation
techniques. In Proceedings of the Annual Meeting of
the Association for Computational Linguistics.
21
Animacy Encoding in English: why and how
Annie Zaenen
PARC & Stanford University
3333 Coyote Hill Road
Palo Alto, CA 94304]
zaenen@parc.com
Jean Carletta
HCRC-University of Edinburgh
2, Buccleuch Place
Edinburgh EH8LW, UK
J.Carletta@Edinburgh.ac.uk
Gregory Garretson
Boston University
Program in Applied Linguistics
96 Cummington St.,
Boston, MA 02215
gregory@bu.edu
Joan Bresnan
CSLI-Stanford University
220, Panama Street
Stanford CA 94305
bresnan@stanford.edu
Andrew Koontz-Garboden
CSLI-Stanford University
220, Panama Street
Stanford CA 94305
andrewkg@csli.stanford.edu
Tatiana Nikitina
CSLI-Stanford University
220, Panama Street
Stanford CA 94305
tann@Stanford.edu
M. Catherine O?Connor
Boston University
Program in Applied Linguistics
96 Cummington St.,
Boston, MA 02215
mco@bu.edu
Tom Wasow
CSLI-Stanford University
220, Panama Street
Stanford CA 94305
wasow@csli.stanford.edu
Abstract
We report on two recent medium-scale initiatives
annotating present day English corpora for animacy
distinctions.  We discuss the relevance of animacy for
computational linguistics, specifically generation, the
annotation categories used in the two studies and the
interannotator reliability for one of the studies.
1 Introduction
It has long been known that animacy is an
important category in syntactic and morphological
natural language analysis.  It is less evident that
this dimension should play an important role in
practical natural language processing.  After
reviewing some linguistic facts, we argue that it
does play a role in natural language generation and
translation, describe a schema for the annotation of
animacy distinctions, evaluate the reliability of the
scheme and discuss some results obtained.  We
conclude with some remarks on the importance of
animacy and other accessibility dimensions for the
architecture of generation schemes
2 The animacy dimension in natural
language
The animacy hierarchy is one of the accessibility
scales that are hypothesized to influence the
grammatical prominence that is given to the
realization of entities within a discourse. Three
important scales (sometimes conflated into one,
also called animacy hierarchy in Silverstein, 1976),
are the definiteness, the person and the animacy
hierarchy proper.  We assume these are three
different hierarchies that refer to different aspects
of entity representation within language: the
definiteness dimension is linked to the status of the
entity at a particular point in the discourse, the
person hierarchy depends on the participants
within the discourse, and the animacy status is an
inherent characteristic of the entities referred to.
Each of these aspects, however, orders entities on a
scale that makes them more or less salient or
?accessible? when humans use their language.
The importance of accessibility scales is not
widely recognized in computational treatments of
natural language.  This contrasts with the situation
in linguistics where such scales have been
recognized as playing an important role in the
organization of sentence syntax and discourse.
Even in natural language studies, however, their
importance has been underestimated because the
role of these scales is not always to distinguish
between grammatical and ungrammatical
utterances but often that of distinguishing mainly
between felicitous and infelicitous ones, especially
in languages such as English.
Grammaticality and acceptability
As long as one?s attention is limited to the
dist inct ion between grammatical  and
ungrammatical sentences, the importance of the
animacy hierarchy in particular is mainly relevant
for languages with a richer morphology than
English.   In such languages animacy distinctions
can influence grammaticality of e.g. case-marking
and voice selection.  To give just one example, in
Navaho, a bi-form is used rather than an yi-form
whenever the patient is animate and the agent is
inanimate, whereas the yi-form is used when the
agent is animate and the patient is inanimate as
illustrated in (1) (from Comrie 1989 p. 193).
(1) (a) At???d n?masi yi-d??l?d
      girl      potato burnt
      The girl burnt the potato.
(b) At???d n?masi bi-d??l?d
      girl      potato burnt
      The potato burnt the girl.
Other phenomena discussed in the literature are
agreement limited to animate noun phrases
(Comrie, 1989), overt case-marking of subject
limited to inanimates or overt case-marking of
objects limited to animates (Aissen, 2003, see also
Bossong 1985 and 1991), object agreement in
Bantu languages (see e.g. Woolford, 1999), choice
between direct and inverse voice in Menominee
(Bloomfield, 1962, see also, Trommer, n.d.).
Recent linguistic studies have highlighted the
importance of the category in languages such as
English. For instance the choice between the Saxon
genitive and the of-genitive (Rosenbach, 2002,
2003, O?Connor et al 2004, Leech et al 1994),
between the double NP and the prepositional
dative (Cueni et al work in progress) and between
active and passive (Rosenbach et al 2002, Bock et
al. 1992, McDonald et al 1993) and between
pronominal and full noun reference (Dahl and
Fraurud, 1996, based on Swedish data) have all
been shown to be sensitive to the difference
between animate and inanimate referents for the
arguments with variable realization.  In these cases
the difference between animate and inanimate does
not lead to a difference between a grammatical or
an ungrammatical sentence as in the cases cited in
the previous paragraph but to a difference in
acceptability.
Interaction between animacy and other scales
As mentioned above, the term ?animacy hierarchy?
is used in two ways, one to refer to an ordering
imposed on definiteness, animacy and person and
the other where it refers to animacy proper.  The
reason for this lies in the interaction between the
different factors that determine accessibility.
It is conceptually desirable to distinguish between
animacy and definiteness but in practice it is
frequently the case that a linguistic phenomenon is
conditioned by more than one of these
conceptually independent factors (see e.g. Comrie,
1989 for discussion).  The projects in the context
of which the annotation tasks described here were
performed (see description below, section 5) also
encode some of these interacting factors.  The
LINK-project encodes information status (see
Nissim et al 2004) and the Boston project encodes
definiteness and expression type (i.e., NP form) as
proxies for information status.
3 Animacy as a factor in generation and
translation
As long as animacy was discussed as a relevant
grammatical category in languages that had not
been studied from a computational point of view,
its importance for computational linguistics was
perceived as rather limited.  The fact that it
permeates the choice between constructions in
languages such as English changes this perception.
The category is of obvious importance for high
quality generation and translation.
For instance, if one is faced with the task of
generating a sentence from a three place predicate,
P (a,b,c), and one has the choice of rendering either
b or c as the direct object, knowing that c is human
and b is abstract would lead one to choose c ceteris
paribus.  However, everything else is rarely equal
and the challenge for generation will be to assign
the exact relative weights to factors such as
animacy, person distinction and recency.
Moreover, the importance of these factors needs to
be combined with that of heterogeneous
considerations such as the length of the resulting
expression.
In the context of translation we need also to keep
in mind the possibility that the details of the
animacy ranking might be different from language
to language and that the relative impact of animacy
and other accessibility scale factors might be
different from construction to construction.
4 The Animacy Hierarchy
Given the pervasive importance of animacy
information in human languages one might expect
it to be a well-understood linguistic category.
Nothing could be farther from the truth.  Linguistic
descriptions appeal to a hierarchy that in its
minimal form distinguishes between human, non-
human animate and inanimate but can contain
more distinctions, such as distinctions between
higher and lower animals (see Yamamoto, 1999 for
a particularly elaborated scheme).
What makes it difficult to develop clear categories
of animacy is that the linguistically relevant
distinctions between animate and non-animate and
between human and non-human are not the same
as the biological distinctions.  Part of this research
is devoted to discovering the principles that
underlie the distinctions; and the type of
distinctions proposed depend on the assumptions
that a researcher makes about the underlying
motivation for them, e.g. as a reflection of the
language user?s empathy with living beings (e.g.
Yamamoto, 1999).  What is of particular interest
for natural language processing is the observation
that the distinctions are most likely not the same
across languages (cf. Comrie, 1989) and can even
change over time in a given language. They are
similar to other scalar phenomena such as voicing
onset times that play a role in different languages
but where the categorization into voiced and
unvoiced does not correspond to the same physical
boundary in each language. But whereas voicing
onset times can be physically measured, we do not
have an objective measure of animacy. The
categories involved correspond to the degree to
which various entities are construed as human-like
by a given group of speakers and at this point we
have no language independent measure for this.
Moreover, languages make ample use of metaphor
and metonomy.  The intent of an animacy coding is
to encode the animacy status of the referent of the
linguistic expression. But sometimes in figurative
language it is not clear what the referent it.
Especially prevalent cases of metonomy are the
use of names to refer both to organizations (e.g.
IBM) and to characteristic members of them, and
the use of place names (e.g. Russia) to refer both to
organizational entities and geographical places or
inhabitants of them. Terms belonging to these
semantic classes are systematically ambiguous.
Whereas it is true that animacy can be determined
by looking at the entity an expression refers to, in
practice it is not always clear what the referent of
an expression is.
The notions that the animacy hierarchy appeals to,
then, are not a priori well defined. And work is
necessary on two levels: to better define which
distinctions play a role in English and to determine
where they play a role.  Conceptually, it might be
desirable to replace the idea of a hierarchy with
discrete classes by a partial ordering of entities.
This is, however, not the place to pursue this idea.
Fortunately, one doesn?t need to wait until the first
problem is solved completely to tackle the second.
The results obtained in certain linguistic contexts
are robust for the top and the bottom of the
hierarchy.  Uncertainty about the middle does not
prevent us from establishing the importance of the
dimension as such.  Refining the definition of
animacy will, however, be important for more
detailed studies of the interaction between the
various accessibility hierarchies. This more precise
notion will be needed for cross-linguistic studies,
and, in the context of natural language processing,
for high quality generation and translation.
5 Animacy Annotation
As we have discussed above, the animacy scale is
an important factor in the choice of certain
construction in English. But it is only a soft
constraint and as such outside of the realm of
things that native speakers have clear judgments
about.  The best ways to study such phenomena are
psychological experiments and corpus analysis.
The annotation exercise we engaged in is meant to
facilitate the latter.
Given the situation described with respect to
animacy categories, a natural way to proceed is to
start with a commonsensical approach and see
where it leads.  In 2000-2002, two rather similar
initiatives led to the need for animacy annotations:
one, the paraphrase-project, a collaboration
between Stanford and Edinburgh, concentrating on
the factors that influence the choice between
different sentence level syntactic paraphrases
(Bresnan et al 2002) and another concentrating on
the possessive alternation (O?Connor, 2000).  The
two projects used a very similar animacy
annotation scheme, developed in the context of the
O?Connor project.
The scheme was used in two different ways. The
Boston team coded 20,000 noun phrases in
?possessive? constructions from the Brown Corpus.
The first round of coding was automated, with the
animacy annotation based primarily on word lists
and morphological information. The second round
was performed manually by pairs of coders using a
decision tree. The two coders were required to
agree on each code; every case in which there was
not complete agreement was discussed by the rest
of the team, until a choice of code was made. This
way of annotating does not lend itself to a study of
reliability, except between the automated coder
and the human coders as a group. For more
information on this use of the coding system, see
Garretson & O?Connor (2004).
In what follows we concentrate on the use of the
coding scheme in the Stanford-Edinburgh
paraphrase project.
The overall aim of the paraphrase project is to
provide the community of linguists and
computational linguists with a corpus that can be
used to calculate the impact of the various factors
on different constructions.  The annotation scheme
assumes that the main distinction is three-way:
human, other animates and inanimates, but the two
latter categories are subdivided further as follows:
- Other animates: organizations, animals,
intelligent machines and vehicles.
- Inanimates: concrete inanimate, non-concrete
inanimate, place and time.
The category ?organization? is important because
organizations are often presented as groups of
humans engaging in actions that are typically
associated with humans ( they make
pronouncements, decisions, etc.).  The categories
place and time are especially important for the
possessive encoding as it has often been observed
that some spatial and temporal expressions are
realized as Saxon genitives (see e.g. Rosenbach
(2002)).
For the cases in which no clear decision could be
made, a category ?variable animacy? was invented,
and the coders were also given the option to defer
the decision by marking an item with ?oanim?.
The overall coding scheme, with a summary of the
instructions given to the coders, looks as follows
1
HUMAN
Refers to one or more humans; this includes
imaginary entities that are presented as human,
gods, elves, ghosts, etc.: things that look human
and act like humans.
ORG
This tag was proposed for collectivities of humans
when displaying some degree of group identity.
The properties that are deemed relevant can be
represented by the following implicational
hierarchy:
+/- chartered/official
+/- temporally stable
+/- collective voice/purpose
+/- collective action
+/- collective
The cut-off point between HUMAN and ORG was
put at ?having a collective voice/purpose?: so a
group with collective voice and purpose is deemed
to be an ORG, a group with collective action, such
as a mob, is not an ORG.
                                                       
1
 For a more extensive description of the annotation
scheme see Garretson et al 2004.
ANIMAL
Non-human animates, including viruses and
bacteria.
PLACE
The tag is used for nominals that ?refer to a place
as a place?. There are two different problems with
the delimitation of place. On the one hand, any
location can be a place, e.g. a table, a drawer, a
pinhead, ? The coding scheme takes the view that
only potential locations for humans are thought of
as ?places?.  On the other hand some places can be
thought of as ORGs.  The tag was applied in a
rather restricted way, for instance in a sentence
such as ?my house was built in 1960?, ?my house?
is coded as CONC (see below), whereas in ?I was
at my house?, it would be a PLACE.
TIME
This tag is meant to be applied to expressions
referring to periods of time.  It was applied rather
liberally.
CONCRETE
This tag is restricted to ?prototypical? concrete
objects or substances.  Excluded are things like air,
voice, wind and other intangibles. Body parts are
concrete.
NONCONC
This is the default category.  It is used for events,
and anything else that is not prototypically
concrete but clearly inanimate.
MAC
A minor tag used for intelligent machines, such as
computers or robots.
VEH
Another minor category used for vehicles as it
has been observed that these are treated as living
beings in some linguistic contexts (e.g. pronoun
selection in languages such as English where
normal gender distinctions only apply to animates).
OANIM
This tag is used when the coder is completely
unsure and wants to come back to the example
later.
VANIM
This tag can be used in conjunction with another
one to indicate that the coder is not entirely sure of
the code and thinks there are reasons to give
another code too.
Finally, NOT-UNDERSTOOD was supposed to
be used when the text as a whole was not clear.
Three coders coded the parsed part of the
Switchboard corpus (Godfrey et al 1992) over the
summer of 2003.  The corpus consists of around
600 transcribed dialogues on various
predetermined topics among speakers of American
English.  Before the annotation exercise began, the
dialogues were converted into XML (Carletta et al
2004).  The entities that needed to be annotated
(the NPs and possessives determiners) were
automatically selected and filtered for the coders.
The three coders were undergraduate students at
Stanford University who were paid for the work.
The schema presented above was discussed with
them and presented in the form of a decision tree.
Difficult cases were discussed but eventually each
coder worked independently.  599 dialogues were
annotated.
6 Coding reliability
The reliability of the annotation was evaluated
using the kappa statistic (Carletta, 1996).
Although there are no hard and fast rules about
what makes an acceptable kappa coefficient?it
depends on the use to which the data will be
put?many researchers in the computational
linguistics community have adopted the rule of
thumb that discourse annotation should have a
kappa of at least .8.
For the reliability study, we had three
individuals work separately to code the same four
dialogues with the animacy scheme.  Markables (in
this case NPs and possessives) had been extracted
automatically from the data, leading the coders to
mark around 10% of the overall set with a category
that indicated that they were not proper markables
and therefore not to be coded.  Omitting these
(non-) markables, for the data set overall, K=.92
(k=3, N=1081).
In general, coders did not agree about which cases
were problematic enough to mark as VANIM, and
omitting the markables that any coder marked as
problematic using the VANIM code leads to a
slight improvement (K=.96, k=3,N=1135).
It is important to note that these kappa coefficients
are so high primarily because two categories which
are easy to differentiate from each other, HUMAN
and NONCONC, swamp the rest of the categories.
The cross-coder reliability for them is satisfactory
but the intermediate categories were not defined
well enough to allow reliable coding.
Figure 1 shows the confusion matrix for the data
including markables that any coder marker
additionally as problematic using the VANIM
notation.  Considering the coders one pair at a
time, the matrix records the frequency with which
one coder of the pair chose the category named in
the row header whilst the other chose the category
named in the column header for the same
markable.
Although we were aware of the less than formal
definitions given for the categories, we had hoped
that the coders would share the intuitive
understanding of the developers of the categories.
This is obviously not the case for all categories.
What was also surprising was that allowing coders
to mark cases as problematic using the VANIM
code was not worthwhile, since the coders did not
often take advantage of this option and taking the
VANIM codes into account during analysis has
little effect.
Analysis of the four annotated dialogues points to
several sources for the intercoder disagreement.
? The categories TIME and PLACE were
defined in a way that did not coincide with the
coders? intuitive understanding of them.  The
tag TIME was supposed to refer to ?periods of
time?. This led to some wavering
interpretations for temporal expressions that do
not designate a once-occurring period of time.
For instance ?this time? and ?next time? were
coded as TIME by two coders but as
?NONCONC? by the third one.  Clearer
training on what was meant could have helped
here.
? As mentioned above, the choice
between HUMAN, ORG and NONCONC
depended on how the coders interpreted the
referent of the expression.  Although
guidelines were given about the difference
between HUMAN and ORG (see above), the
cut-off point wasn?t always clear
2
. The
distinction between ORGs as proposed in our
schema and less organized human groups
seems too fluctuating to be useful.
                                                       
2 All coders agreed that Vulcans are HUMAN.
Figure 1
? The vagueness of pronominal
reference: for instance a school as an
organization can be marked as ORG by the
coders but later in the dialogue there is
discussion about the what is done with napping
children in the school and one speaker says ?if
they (the children) fall asleep they kind of let
them sleep?, one coder interpreted that the
second ?they? as simply referring to the school
organization and marked it as ORG, whereas
another interpreted it as referring to a rather
vague group of humans, presumably some
teachers, and marked it as HUMAN.  This
vagueness of reference is quite prevalent in
spoken language, especially with the pronoun
?they?.
? Attention errors, e.g. vehicles were
supposed to get a special code but, presumably
because there were so few, this was sometimes
forgotten.  One coder coded ?a couple of
weeks? as HUMAN.  These kinds of mistakes
are unavoidable and the very tools that make
the encoding easier (e.g. the automatic
advancing from one markable to another)
might make them more frequent.
While the problems with ORG and HUMAN don?t
come as a surprise, the difficulties with PLACE,
TIME and CONCRETE are more surprising.  The
two minor classes, MAC and VEH and the
ANIMAL class occurred so seldom that no
significant results were obtained in this sample.
They were equally rare in the corpus as a whole.
7 Conclusion
We are not aware of any other medium-scale
attempts to annotate corpora of contemporary
English for animacy information apart from the
two mentioned here.  There are smaller efforts
concentrating on the genitive alternation (e.g.
Leech et al, 1994, Anschutz, 1997, Stefanowitsch,
2000)
3
.  The resources that have been created give
robust results for the opposition ?human? versus
?nonconcrete? entities in the large sense (as the
category was used as a catch-all).  This should
suffice for further inquiries about linguistic
processes that are sensitive to a binary opposition
in this dimension.  Moreover the Stanford-
Edinburgh effort is integrated in a corpus that has
already been marked up for syntactic information,
so correlations between syntactic constructions and
animacy (and information status) should be easy to
calculate.  It is also the first effort that studies
inter-annotator reliability.
Some studies based on the annotations are
currently being conducted.  The study by Cueni,
Bresnan, Nikitina and Baayen (2004) supplements
partial data from the work described here with
further annotations.  The work reported by
O?Connor et al (2004) derives from the Boston
use of the encoding described here. Within the
paraphrase project we are currently investigation
                                                       
3 Some related work is done in the context of entity
tracking sponsored by various US government programs
(ACE, TIDES, etc.).  The proposed annotation schemes
have problems in distinguishing between persons and
organizations or geo-political entities that are similar to
ours, but the basic categories and the aims of these
enterprises are different.  We have not reviewed them
here.
concr
ete
hum
an
non-
conc
not-
understood
oan
im
o
rg
pl
ace
ti
me
v
eh
concrete 31 9 19 10 0 0 5 0 1
human 148
9
27 11 0 3
3
0 4 0
nonconc 1256 3 3 3
3
23 5
3
1
notundersto
od
0 0 0 0 0 0
oanim 2 2 0 1 0
org 9
1
0 0 0
place 66 0 2
time 7
0
0
veh 3
the possible effect of animacy on constructions
such as Left-Dislocation and Topicalization.
Further work remains to be done, however, to
determine the exact nature of the distinctions in the
animacy dimension that are important for English
and for other languages. The annotations we
provide do not settle this issue. In that sense they
are insufficient to guide generation and translation
precisely. To investigate this further we will need
to devise more careful annotation schemes and
approach the problem via experiments where the
hypothesized relative animacy of various entities
can be carefully controlled. As mentioned above, it
might be better not to think in terms of robust large
categories but rather try to rank specific entities or
small categories relative to each other and to
gradually build up a more precise picture.  This is
most likely better done through controlled
experiments than through corpus annotation.
The annotated corpus, however, will be helpful to
determine where animacy plays a role and which
other factors it interacts with. This knowledge will
help devise more adequate generation and
translation architectures.
The Boston University noun Phrase Corpus is
publicly available at http://np.corpus.bu.edu.  The
paraphrase corpus will be made available to
subscribers to the Switchboard Corpus.
8 Acknowledgements
This work was in part supported by a Scottish
Enterprise Edinburgh-Stanford Link Grant
(265000-3102-R36766) and by NSF grant BCS-
0080377.  Thanks to Toni Jeanine Harris, Rebecca
Regos and Anna Cueni for the encoding work and
to Richard Crouch and Neal Snider for comments
and help. The usual disclaimers obtain.
References
Aissen, Judith, 2002. Differential object marking:
Iconicity vs. economy. NLLT, 21 435-483.
Anschutz, A. 1997. "How to Choose a Possessive
Noun Phrase Construction in Four Easy
Steps." Studies in Language 21, 1, 1-35.
Bock, J. K., Loebell, H. and Morey, R. (1992)
From conceptual roles to structural relations:
Bridging the syntactic cleft.  Psychological
Review 99: 150--171.
Bossong, Georg. 1985. D i f f e r e n t i e l l e
Objektmarkierung in den Neuiranischen
Sprachen,Gunter Narr Verlag, T?bingen.
Bossong, Georg. 1991. 'Differential Object
Marking in Romance and Beyond', in D.
Wanner and D.Kibbee (eds.), New Analyses in
Romance Linguistics: Selected Papers from
theXVIII Linguistic Symposium on Romance
Languages, John Benjamins, Amsterdam, pp.
143-170.
Bresnan, Joan, Dingare, Shipra, and Manning,
Christopher D. 2001.   Soft Constraints Mirror
Hard Constraints: Voice and Person in English
and Lummi.  Proceedings of the LFG '01
Conference. CSLI Online. 20 pages.
Bresnan, Joan, Carletta, Jean, Crouch, Richard,
Nissim, Malvina, Steedman, Mark, Wasow,
Tom and  Zaenen, Annie. 2002. Paraphrase
analysis for improved generation, LINK
project, HCRC Edinburgh-CLSI Stanford.
Carletta, Jean. 1996. Assessing agreement on
classification task: the kappa statstic.
Computational linguistics, 22 (2): 249-254
Carletta, Jean, Shipra Dingare, Malvina Nissim,
and Tatiana Nikitina. 2004. Using the NITE
XML Toolkit on the Switchboard Corpus to
study syntactic choice: a case study. In
Proceedings of the 4th International
Conference on Language Resources and
Evaluation (LREC2004), Lisbon, May 2004.
Comrie, Bernard, 1989, Language Universals and
Linguistic Typology, The University of Chicago
Press
Cueni, Anna, Joan Bresnan, Tatiana Nikitina and Harald
Baayen. 2004. Predicting the Dative Alteration,
Stanford University, ms. in preparation.
Dahl, ?sten and  Fraurud, Kari. 1996 Animacy in
Grammar and Discourse. In Thorstein
Fretheim & Jeanette K. Gundel (eds.),
Reference and Referent Accessibility, 47-64.
Amsterdam/Philadelphia: John Benjamins.
Garretson, Gregory, O'Connor, M. Catherine;
Skarabela, Barbora; & Hogan, Marjorie.
March 2004. Coding practices used in the
project Optimal Typology of Determiner
Phrases.
http://npcorpus.bu.edu/documentation/index.ht
ml
Garretson, Gregory, and O?Connor, M. Catherine.
2004. A combined automatic-and-manual
method for studying discourse features in
corpora. Paper to be presented at the Fifth
North American Symposium on Corpus
Linguistics,  May 21-23, Montclair State
University, NJ.
Godfrey, J. Holliman, E. & McDaniel J. 1992
SWITCHBOARD: Telephone speech corpus
for research and development. Proceedings of
ICASSP-92, 517-520.
Leech, G., B. Francis, et al (1994). The Use of
Computer Corpora in the Textual
Demonstrability of Gradience in Linguistic
Categories. Continuity In Linguistic Semantics.
C. Fuchs and B. Victorri. Amsterdam, John
Benjamins Publishing Company: 57-76.
McDonald, J.L., Bock, K. and M. Kelly. 1993.
Word and world order: semantic, phonological,
and metrical determinants of serial position.
Cognitive Psychology 25: 188-230.
Nissum, Malvina, Shipra Dingare, Jean Carletta
and Mark Steedman. 2004. An annotation
scheme for information status in dialogue.
Submitted to LREC 2004
O?Connor, M. Catherine. 2000. Optimality
typology of the DP: Markedness within the
nominal. NSP-grant. BCS-0080377.
O?Connor, M. Catherine., Anttila, Arto, Fong,
Vivienne and   Maling, Joan (2004).
Differential possessor expression in English:
Re-evaluating animacy and topicality effects.
Paper presented at the Annual Meeting of the
Linguistic Society of America, January 9-11,
Boston, MA.
Rosenbach, Anette (2002) Genitive Variation in
English. Conceptual Factors in Synchronic
and Diachronic Studies. Berlin/New York:
Walter de Gruyter.)
Rosenbach, Anette. 2003. Aspects of iconicity and
economy in the choice between the s-genitive
and the of-genitive in English. In: G?nter
Rohdenburg & Britta Mondorf (eds.).
Determinants of Grammatical Variation in
English Berlin/New York: de Gruyter.
Rosenbach, A., J. Aissen, and J. Bresnan. 2002.
Pilot study of the influence of animacy on
subject choice in a reading task.  (Heinrich
Heine University, UCSC, and Stanford)
Silverstein, Michael. 1976. Hierarchy of features
and ergativity. In Richard Dixon, editor,
Grammatical Categories in Australian
Languages. Australian Institute of Aboriginal
Studies.
Stefanowitsch, Anatol. 2000. Constructional
semantics as a limit to grammatical alternation:
The two genitives of English. in CLEAR
(Cognit ive Linguistics: Explorations,
Applications, Research), 3.
Trommer, Jochen. s.d. Direction Marking and Case
in Menominee,  http:/ /www.ling.uni-
osnabrueck.de/trommer/nim.pdf
Woolford, Ellen. 1999. Animacy hierarchy effects
on object agreement, in Paul Kotey ed. New
Dimensions in African Linguistics and
Languages (Trends in African Linguistics 3),
203-216.
Yamamoto, Mutsumi, 1999, Animacy and
Reference: a cognitive approach to corpus
linguistics , John Benjamins.
Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading, pages 114?121,
Los Angeles, California, June 2010. c?2010 Association for Computational Linguistics
Supporting rule-based representations with corpus-derived lexical
information.
Annie Zaenen
Cleo Condoravdi
Daniel G. Bobrow
PARC
3333, Coyote Hill Road
Palo Alto, CA, 94304, USA
{zaenen,condorav,bobrow}@parc.com
Raphael Hoffmann
University of Washington
Box 352350
Seattle, WA, 98195, USA
raphaelh@cs.washington.edu
Abstract
The pervasive ambiguity of language al-
lows sentences that differ in just one lexi-
cal item to have rather different inference
patterns. This would be no problem if the
different lexical items fell into clearly de-
finable and easy to represent classes. But
this is not the case. To draw the correct
inferences we need to look how the refer-
ents of the lexical items in the sentence (or
broader context) interact in the described
situation. Given that the knowledge our
systems have of the represented situation
will typically be incomplete, the classifica-
tions we come up with can only be prob-
abilistic. We illustrate this problem with
an investigation of various inference pat-
terns associated with predications of the
form ?Verb from X to Y?, especially ?go
from X to Y?. We characterize the vari-
ous readings and make an initial proposal
about how to create the lexical classes that
will allow us to draw the correct inferences
in the different cases.
1 Introduction
Machine Reading requires a level of Natural
Language Processing that allows direct infer-
ences to be drawn from the processed texts.
Most heavy duty inferencing will be done by a
reasoning engine working on the output of the
linguistic analysis (with possible loops between
the two) but for this to be possible, the linguistic
analysis should deliver representations where a
certain level of disambiguation and content spec-
ification has been done. For instance, a human
will draw different conclusions from the follow-
ing two sentences about the position of the ref-
erent of the subject: ?Eric went from Paris to
Lyon? and ?The road went from Paris to Lyon?.
The first sentence implies that a person named
Eric was in Paris at some time and in Lyon at
a later time, whereas the second sentence im-
plies that a part of the road was in Paris and a
part of it was in Lyon at the same time. For the
reasoner to draw such conclusions, the linguis-
tic analysis should assign appropriate roles to
the subject argument and the from-to adjunct
or argument phrases of the verbal predicate go
so as to convey that the first sentence involves
movement, while the second involves spatial ex-
tent.
In this paper we look at a range of such in-
ferences associated with from-to phrases. We
limit ourselves to rather simple cases of the
use of from-to phrases: those that describe no
change or gradual changes in the physical world.
We show that beyond inferences about time-
dependent locations and spatial extent of partic-
ular entities, from-to phrases give rise to infer-
ences about change of an entity in some dimen-
sion (e.g. temperature or width) either through
time or through space. We first discuss the in-
ferences we would like to be able to draw, and
describe features of a representation that cap-
tures enough distinctions to enable these infer-
ences to be drawn. This allows us to isolate the
factors leading to such inferences. Finally, we
give a preliminary sketch of a corpus analysis
that would help make the required distinctions
114
and characterize appropriate lexical classes.
2 Some simple inferences
Consider the following sentences:
1. Eric went from Paris to Lyon.
2. The road went from Paris to Lyon.
3. The meeting went from 3 p.m. to 5 p.m.
4. The temperature in the room went from 20
degrees to 30 degrees from 10 to 11 a.m.
5. The temperature went from 20 to 30 de-
grees from the front to the back of the room
6. The temperature went from 20 degrees to
30 degrees.
7. The room went from 20 to 30 degrees.
As indicated above, we would like the system to
be able to conclude from (1) that Eric was in
Paris before being in Lyon, and from (2) that
one part of the road is in Paris whereas another
part is in Lyon at the same time. From (3) the
system should infer that the mentioned event,
the meeting, started at 3 p.m. (or no later than
3 p.m.) and ended at 5 p.m. (or no earlier than
5 p.m.). From (4) the system should infer that
the value of the function temperature as it ap-
plies to the room increases over the given tem-
poral span. It is worth noting at this point that
the two sets of from-to phrases in (4) play differ-
ent roles. The temporal from-to phrases specify
the relevant domain of the temporal argument of
the function, while the measure from-to phrases
specify the range of the function on the given
domain. (5) has a similar implication to that
of (4), that the temperature changes, but this
time over a spatial dimension: the temperature
is implied to vary in different parts of the room,
being 20 degrees in the front of the room and 30
degrees in the back. Again the two sets of from-
to phrases in (5) play different roles. The spa-
tial from-to phrases specify the relevant domain
of the spatial argument of the function and the
measure from-to phrases specify the range of the
function on the given domain. (6) and (7) have
similar implications to those of (4) and, in the
right context, to those of (5) but they present
challenges of their own. In (6) the temporal (or
spatial) dimension is implicit and needs to be in-
ferred. (7) requires the inference that a change
of the values of the function temperature is in-
volved.1
These examples show that sentences that have
substantially the same syntax and even use the
same main verb can exhibit very different rela-
tions between their parts. The first question we
want to address is how to explicate these dif-
ferences and the second question is how to get
from the words used in these sentences to the
information needed about their type of referent
to ensure the right interpretation in each case.
The verb ?to go? is, of course, not the only
one that exhibits this behavior. The difference
in interpretation between examples (1) and (2)
can also be found with manner-of-motion verbs
such as ?run? and ?zigzag?. Some verbs do lexi-
cally encode a particular functional dimension,
such as temperature or width. These are known
as degree achievements (Dowty, 1979; Abusch,
1986).2 Examples of degree achievements in-
clude ?widen?, ?lengthen?, ?shorten?, ?cool?, ?age?.
They exhibit similar patterns of modification
with from-to phrases as we saw above:
8. The road widens from Palo Alto to Menlo
Park.
9. The road widens from 12 to 24 feet.
Here ?widen? is interpreted statively, like ?go? in
(2), and the two sentences imply spatial change
in width, over subparts of the road. The two
from-to phrases, however, have a different func-
tion giving rise to different implications. (8) im-
plies that the road is wider in Menlo Park than it
is in Palo Alto. (9) specifies the relation between
the measures of width at two different subparts
of the road. The from-to phrases in (8) specify
1It is not clear that the change has to be in one direc-
tional in all cases:
This summer, the temperature went from 20 de-
grees to 30 degrees.
In this example, it seems that the temperature varied
from 20 to 30 degrees, not necessarily that 20 degrees
was a starting point or 30 degrees an end point. See
section 4.1 for some further discussion.
2In English most degree achievements are derived
from gradable adjectives. When this is the case, the
meaning of degree achievements and underlying adjec-
tives is systematically related, as argued in (Hay et al,
1999).
115
the domain of the spatial argument of the func-
tion width as it applies to the referent of ?the
road?. Those in (9) specify the range of the val-
ues of the function width as it applies to different
parts of the referent of ?the road?.
In what follows we will distinguish between
extent readings and change readings. Extent
readings specify, in full or in part, the tempo-
ral or spatial extent of a temporal or spatial en-
tity, as seen in (3) and (2). Change readings
specify the values of a function as applied to a
given entity through a temporal or spatial span.
The function is either determined directly by the
verb, as in (8) and (9), or by the verb in com-
bination with one of its arguments, as in (4) ?
(6), or it has to be inferred, as in (1) and (7).
3 Representing the different readings
For the sake of concreteness, in this section we
show how the distinctions discussed above are
represented and implemented in AKR, an ab-
stract knowledge representation language into
which sentences are mapped after they are
parsed in the NL system developed at PARC
(Bobrow et al, 2007). The idea behind AKR is
to canonicalize many variations of an input text
with the same underlying meaning into a more
uniform representation. This ought to make the
task of interfacing with reasoners easier.
The AKR of a sentence consists of a list of
assertions. Terms are generated for each of the
content words of a sentence, such as verbs and
nouns, and are associated with assertions about
the types of events and objects their correspond-
ing words refer to. Predicates and their argu-
ments or modifiers are related via role relations.
The inventory of roles we use extends the set
of semantic or thematic roles often assumed in
linguistic analyses and found in resources such
VerbNet or FrameNet. It includes among other
things temporal or spatial relations of inclusion,
precedence, etc.
We assume that sentences with from-to
phrases imply the existence of a path and that
the further information about the path specified
is about the ?location? of its initial and final
points. In representing such sentences a term is
created to represent a path and the path term
is linked by a role initial to the term for the
complement of from, and by a role final to the
term for the complement of to. On our analysis
then the from-to phrases are used to specify re-
strictions on the path term and do not translate
into thematic roles relating the verbal predicate
and the complement NP, such source or goal.
The path term is related to the verbal term via
different roles, depending on the type of inter-
pretation. Below is an example that shows the
role relations in AKR for sentence (1).
role(theme, go:13, Eric:7)
role(mpath, go:13, path:23)
role(initial,path:23,loc(-at-,Paris:4))
role(final,path:23,loc(-at-,Lyon:6))
role(dimension,path:23,loc)
3.1 Extent interpretations
In extent readings the subject argument denotes
an entity extended in space, as seen in (2), or a
non-punctual event, as seen in (3). The verb
itself does little work other than to signal that
the from-to phrases give information about the
spatial or temporal extent of its subject argu-
ment. The way they do that is by saying that
the given path is a spatial or temporal part of
the entity that is the referent of the subject ar-
gument. Let us start with the representation of
(3), as the representation of its meaning in our
terms is quite intuitive. Temporal paths, such
as from-to-span:11, correspond to time periods.
role(initial,time-span:11,timepoint(-at-,3pm))
role(final,time-span:11,timepoint(-at-,5pm))
role(temporalWithin,time-span:11,meeting:1)
It should now be clear that the representation
for the spatial extent reading would differ min-
imally from that of the temporal extent read-
ing: the relation between the path and the road
terms would be that of spatial inclusion and the
dimension of the path is locational.
role(initial,path:23,loc(-at-,Paris:4))
role(final,path:23,loc(-at-,Lyon:6))
role(spatialWithin,path:23,road:10)
116
3.2 Change interpretations
As discussed in section 2, change interpretations
establish a dependency between two paths which
should be represented explicitly. The paths
themselves may be specified overtly by from-to
phrases or they may be implicit. Functionally
relating two paths of this type was first dis-
cussed, to our knowledge, in (Jackendoff, 1996)
and further developed in (Gawron, 2005) and
(Gawron, 2009).
Let us consider first example (4), where the
two paths are given explicitly. (4) implies a
change in the temperature of the room over time
so the function temperature should be construed
as time-dependent. The temporal path speci-
fies the time period over which the given change
in temperature takes place; the scalar path par-
tially specifies the range of the function over the
given temporal domain. What we can conclude
for certain from (4) is that the temperature in
the room was 20 degrees at 10 a.m. and 30 de-
grees at 11 a.m. The sentence gives no specific
information about the temperature of the room
in between 10 and 11 a.m. though in this case,
given that change in temperature is continuous,
we can conclude that every degree between 20
and 30 was the temperature of the room at some
point within the relevant time period.
In order to represent the dependency between
the two paths we use a higher order predicate
path-map that specifies a function, that varies
over a range (in this case the scalar path from
20 degrees to 30 degrees) with a domain (in
this case the temporal path from 10 a.m. to 11
a.m.). More generally: the higher-order predi-
cate, path-map(F,D,R), relates a function F
and two posets D and R. The path-map relation
expresses that the image of D under F is equal
to R.3 For (4) we end up with the following rep-
resentation.
role(scale,go:5,path:4)
role(dimension, path:4,temperature)
role(initial,path:4,temperature(-at-,20 deg))
role(final,path:4,temperature(-at-,30 deg))
3Depending on what F, D and R are, this mapping
may also be order preserving, i.e. for all elements x, y in
D, if x precedes y then F(x) precedes F(y).
role(initial,time-span:11,timepoint(-at-,10am))
role(final,time-span:11,timepoint(-at-,11am))
path-map(function(temperature,room:2),
time-span:11,path:4)
The fact that path:4 is a scalar path is marked
by relating it to the verbal term via the role
scale.
The other examples discussed in section 2 re-
ceive representations based on this model. (5)
implies a change in the temperature of the room
over its spatial extent oriented from the front to
the back, so the function temperature should be
construed as location-dependent. Below we give
the assertions for the representation of (5) that
differ from those of (4). Note the additional
assertion relating the spatial path term to the
room term.
role(initial,path:11,loc(-at-,front:10))
role(final,path:11,loc(-at-,back:12))
role(spatialWithin,,path:11,room:2)
path-map(function(temperature,room:2),
path:11,path:4)
The representation of sentences with degree
achievements, such as The road widens from 12
to 24 feet from Palo Alto to Menlo Park, would
the same in all relevant respects except that the
dimension of the scalar path would be deter-
mined by the verb, in this case being width.
To derive full representations for (6) and (7)
we need to be able to infer the second and the
first argument of function, respectively. More-
over, we need to fix the dimension of the implicit
path. Generally, when only one path is specified
overtly, as in (6), (7) and (8) and (9) the exis-
tence of the other type of path is understood.
When only the range path is given, the under-
stood domain path can be either temporal or
locational.
We come now to the prototypical use of a
from-to phrase with verbs like ?go? to describe
movement whose origin is specified by the from
phrase and whose destination is specified by the
to phrase. We gave a preliminary representation
for (1) at the beginning of section 3. Missing
from that representation is the explicit link be-
tween the location of the theme argument during
117
the time of the movement. This link, of course,
can now be given in terms of the following path-
map assertion:
path-map(function(location,Eric:7),
time(go:13),path:23)
4 Which elements in the sentence
guide interpretation?
In our system roles and dimensions are intro-
duced by rules that take the output of the syn-
tactic parse of the sentence as input. The exact
form of these rules need not to concern us here.
But an important question for nlp is where the
information comes from that allows us to deter-
mine which role and dimension a path has. As
the examples show, the verb is not necessarily
the place to look: most of the examples use the
verb ?to go?.
In fact, the information can come from various
places in the sentence (or the broader textual
context: ellipsis and anaphoric relations play
their usual roles here). Moreover in some cases
information about, say, the dimension can come
from the arguments of from and to whereas in
other cases this information can come from the
verb. ?Widen? for instance imposes the width-
dimension but if we use the verb ?to go? to de-
scribe a widening event, the information about
the dimension has to come from the arguments
of from and to and the subject.
Similar problems arise with respect to the de-
termination of the roles. Example 1 and 2 seem
to have straightforward interpretations where
the path role in the first case is clearly a move-
ment path whereas in the second case we have to
do with a stative interpretation. At first blush,
it seems that this information could be straight-
forwardly lexically encoded: people move and
roads don?t. But further reflection shows that
this will not do. Take the following example:
10. The train went from one end of the station
to the other.
In this case we can have two interpretations: ei-
ther the length of the train is such that it covers
that of the whole station or the train moved from
one end of the station to the other. What is im-
portant is not an intrinsic characteristic of the
lexical item but whether it is appropriate for the
extent (length) of its referent to be measured by
the from-to phrase.
Some more or less stable relations between
syntax and semantics can help us determine
which analysis to give. For instance, the starting
and end points of movement paths and stative
locational paths are referential (in contradistinc-
tion to those of scalar paths). As such, they tend
to be expressed by proper names or by a noun
phrase with a determiner.4
Manner of motion verbs are surprisingly un-
informative: many of them can have a moving
object or a stationary object or a function such
as the temperature as their subject. The combi-
nations summarized in the following are all pos-
sible:
11. Liz/the road/the temperature
went/crawled/moved/meandered
from X to Y.
With verbs of inherent directed motion, the verb
contributes a polarity for the direction but very
little else, as example 12 illustrates:
12. Liz/the road/the temperature
descended/climbed/ascended/fell/tumbled
from X to Y.
Again whatever information there is about the
type of path or the dimension it has to come
from the subject or from the from-to arguments.
From-to arguments can give the necessary infor-
mation about the dimension (locations, money,
time, degrees) but when they are scalar or tem-
poral, the measurement units will often be omit-
ted and the theme will indicate the dimension.
Degree achievements tend to be more special-
ized. They indicate the dimension (width, tem-
perature). Lexicons can contain many of the
function names but will not help with the cases
of metonymy (where an argument is given in-
stead of the name of the function itself).
4There are, however, exceptions:
He ran from where Bill was to where the field ends.
His tattoo goes from head to toe.
The path meanders from mountain to mountain.
118
4.1 Characterizing components of the
representations
In the previous subsection we have discussed dif-
ferent types of from-to phrases, and the roles
that link the elements of the representations of
these types. The question we address now is how
we can provide our system with the necessary in-
formation to make these distinctions. This is a
preliminary investigation as yet without imple-
mentation.
Ideally, we would have ontologies to give us
the right characteristics of the entities underly-
ing our lexical items and we would have ade-
quate mappings from the lexical items to these
ontologies. These ontologies and these mappings
are currently not available. Natural language
processing applications, however, have taught us
that even if humans can do surprising things and
language can express surprising thoughts, most
of the time, the reality that human language ex-
presses is rather predictable, so that the map-
ping to ontologies can up to a certain point be
mimicked by probabilistic feature assignments
to lexical items. For ?Eric? we can assume that
with a high probability it will be the theme of
a movement path and whereas for ?the road? a
high probability assigns it as the theme of a sta-
tive path. In other cases, however, we need con-
crete co-occurrence statistics to assign the right
representations. Next, we sketch a preliminary
investigation of some Wikipedia data that can
be brought to bear on this issue. We indicate
how the data might help and point out some of
the new problems it brings up.
A first question that arises is of how much
practical relevance the different types that we
have discussed are. We looked at the first 100
?went from X to Y? sentences pulled out of
Wikipedia parsed with the Stanford dependency
parser, that had the required syntactic pattern
and found that 61 fell into the categories de-
scribed in the previous sections (gradual change
or no change in the physical domain) whereas
about 39 are clearly transformational from-to?s
(for instance ?The SU-152 went from design con-
cept to field trials in a record twenty-five days?).
Of these 61, 4 had temporal from-to modifiers,
19 had various scales or numeric from-to mod-
ifiers and 38 were locational. Of the locational
ones, 11 had a stationary reading and 17 had a
movement reading. So all the cases under dis-
cussion are well represented in naturally occur-
ring text.
A second question is how we can obtain
the relevant features from the data. We
see four potential methods: (1) the charac-
terization of words within existing ontologies
like WordNet (Miller, 1995), (2) the combina-
tion of stated facts through reasoning, (3) co-
occurrence statistics of words in text, and (4)
solicitation of novel features from human anno-
tators. We illustrate these methods based on
Wikipedia examples.
A first idea might be that there is at least a
straightforward ontological characterization for
difference between the movement and the sta-
tive reading: for the movement reading we re-
quire living beings and for the stative reading
we require long stationary entities. These im-
pressions are, of course, not completely wrong
but in the first case, we have to include in the
living beings not only groups such as brigades
but also ships (as in ?She went from the Red Sea
to the Mediterranean to relieve USS Coral Sea
...?), flights (as in ?This flight went from Spits-
bergen (Svalbard) to Alaska nonstop, so there
is little doubt that they went over the North
Pole.?) and messages (as in ?The message went
from the Palace in Stockholm to the King at
Drottningholm.?). And in the second categories
we have not only roads and various transporta-
tion lines but also borders (as in ?The bound-
ary of Manila province went from northeast to
southwest, ...?) and trade routes and things such
as (rifle) suppressors as in ?The suppressor, 2
inches in diameter, went all the way from the
back of the barrel to well beyond the muzzle
...?). A quick inspection of WordNet shows that
there is no interesting ancestor node that covers
all the movement cases but it also suggests that
a great number of the cases can be covered with
?conveyance, transport? together with ?motion,
movement, move? as well as ?organism, being?.
But ?organism, being? also covers ?plants? and
?sitter? and ?stander? and other subclasses that
119
don?t seem to be plausible candidates for the
movement analysis. There is no interesting hy-
pernym for both ?road? and ?border? before we
get to the useless level of ?object, physical ob-
ject? and no already existing ontology will help
with the suppressor case. Thus we might get
some data by using the first method but most
likely not everything we want.
As far as the arguments of the from-to phrases
themselves, locations can be indicated by place
names, institution names, nouns referring to lo-
cations, but also nouns referring to spatial lo-
cated entities that we do not think of as loca-
tions, such as parts of pieces of equipment. The
very limited inspection of data we have done up
to now does not lead us to expect that the na-
ture of the from-to arguments occurring with
movement readings is very different from that
found with stationary readings. In the current
state of affairs, many of the arguments of the
from-to phrases can be found either in gazetteers
or through the analysis of a reasonably well-
circumscribed spatial vocabulary.5
Some cases, however, fall outside of these re-
sources. The most interesting problem is pre-
sented by the reference to spatial entities that
are not clearly flagged as locations in ontologies,
such as those found in the suppressor-sentence
(?The suppressor, 2 inches in diameter, went all
the way from the back of the barrel to well be-
yond the muzzle ...?) above. We admit that
his type of sentence seems to be rather rare
in the Wikipedia corpus but it is problematic
because detailed ontological representations of
even common objects are not readily available.
Wikipedia, however, has some information that
might help one to formulate reasonable hypothe-
ses about parts. For instance, the article that
contains the suppressor-sentence, also contains
a structured specification of the carbine under
description mentioning the barrel and the muz-
zle. Here we need to use the second method,
reasoning. The question then becomes whether
we can find reasoning patterns that are general
enough to give interesting results.
5Whereas it is possible to enumerate an extensive part
of the relevant vocabulary, there is no extensive descrip-
tion of meaning contribution of these elements.
The third method, already demonstrated in
the context of semantic parsing (Poon and
Domingos, 2009), seems also to be promising.
For instance, even staying within the class of
movement verbs, different verbs have different
signatures that might help us with the classifi-
cation of their subjects and their from-to argu-
ments. While ?go? has indeed the wide range of
meanings that we expected, ?run? is rather dif-
ferent: apart from three examples where ?run?
refers to the movement of living beings and three
referring to vehicles moving, the other exam-
ples of the combination of ?run? with from-to fall
in two classes: indications of the spatial extent
of roads, railways and the like (27) and tempo-
ral extensions of shows, games or strips running
(16). The nature of the corpus has certainly an
influence here (Wikipedia does not contain nar-
rative texts) but this type of information might
be valuable to disambiguate parses: if we can
distinguish the cases where ?run? occurs with
spatial extent readings and the cases where it
occurs with temporal extent meanings, we can
harvest a set of possible subjects that are also
possible subjects for the spatial extent meaning
of ?go?. The distinction between the two read-
ings of ?run? is not very difficult to make as most
of the temporal extent readings of ?run? have a
temporal from-to phrase.6
A different way in which the characteristics
of specific verbs or verb argument combinations
might at least probabilistically disambiguate
possible readings is illustrated with a difference
between ?go? and ?range? with scalars. In sec-
tion 3.2, we observed that scalar ?go? does not
always imply that there is a steady increase or
decrease over time or space. However in all the
numerical or scalar examples except for one in
our first sample, the interpretation implies such
6But those readings themselves bring up a new clas-
sificatory problem: most of the time the subject is an
event, a show, or a game. However, in most cases the
meaning is not that one performance of the show ran for
several months or year but that several successive perfor-
mances ran. Moreover, the construction cannot only be
used with event-referring expressions but also with enti-
ties such as ?strips?. Here we get into problems of regular
polysemy. The treatment we have given above needs to
be complicated to take these into account.
120
a steady increase or decrease. We also exam-
ined the sentences with ?price ranged? and ?price
went? in the whole of Wikipedia. Unfortunately
there are very few examples but for these, the
difference in interpretation for ?range? and ?go?
seems to hold up: all 4 examples with ?go? had
the interpretation of steady increase or decrease.
So ?the price ranged ...? and ?the price went ...?
statistically might get a different interpretation
even if in some cases ?go? can be synonymous
with ?range?.
Finally, there is a possibility that due to
sparseness some required features can neither be
derived from existing ontologies nor from natu-
ral language text itself. For example, in ?The
2006 Trek the Trail event was organised on the
Railway Reserve Heritage Trail and went from
Mundaring to Darlington? we assume an extent
interpretation, and may thus be inclined to clas-
sify all events that way. However, in ?The case
Arklow vs MacLean went all the way from the
New Zealand High Court to the Privy Council
in London.? we assume a change interpretation
(movement), although WordNet sees ?event? as
a hypernym of ?case?. Interestingly, it is not the
arguments that determine the right interpreta-
tion here, but rather our distinction between dif-
ferent kinds of events: those for which spatial ex-
tent is important (street festivals) and those for
which not (lawsuits). More generally, in cases
where we are unable to make such fine distinc-
tions based on features derived from available
corpora, we can use our fourth method, solicit-
ing additional features from human annotators,
to group concepts in novel ways.
5 Conclusion
In this paper we first described the distinctions
that need to be made to allow a correct in-
terpretation of a subclass of from-to sentences.
We then looked at the resources that are avail-
able to help us guide to the correct interpreta-
tion. We distinguished four different ways to
obtain the information needed: features in an
existing ontology, features statistically derived
for the relations used with a concept, features
computed through reasoning and features ob-
tained through human annotation. We saw that
a small, very preliminary examination of the
data suggests that the three first methods will
allow us to make the right distinctions in an im-
portant number of cases but that there will be
cases in which the fourth method, human anno-
tation, will be necessary.
Acknowledgments
This material is based in part upon work sup-
ported by the Air Force Research Laboratory
(AFRL) under prime contract no. FA8750-09-
C-0181. Any opinions, findings, and conclusion
or recommendations expressed in this material
are those of the author(s) and do not necessar-
ily reflect the view of the Air Force Research
Laboratory (AFRL).
References
Dorit Abusch. 1986. Verbs of Change, Causation,
and Time. Report CSLI, Stanford University.
Daniel Bobrow, Robert Cheslow, Cleo Condoravdi,
Lauri Karttunen, Tracy, Rowan Nairn, Valeria
de Paiva, Lotti Price, and Annie Zaenen. 2007.
PARC?s Bridge question answering system. In
Proceedings of the GEAF (Grammar Engineer-
ing Across Frameworks) 2007 Workshop. Stan-
ford, CA.
David Dowty. 1979. Word Meaning and Montague
Grammar: The Semantics of Verbs and Times in
Generative Semantics and in Montague?s PTQ.
Springer.
Jean Mark Gawron. 2005. Generalized Paths. SALT
17.
Jean Mark Gawron. 2009. The Lexical Semantics of
Extent Verbs.
Jennifer Hay, Christopher Kennedy, and Beth Levin.
1999. Scale structure underlies telicity in ?degree
achievements?. pages 127?144.
Ray Jackendoff. 1996. The Proper Treatment of
Measuring Out, Telicity, and Perhaps Even Quan-
tification in English. Natural Language and Lin-
guistic Theory 14, pages 305?354.
George A. Miller. 1995. Wordnet: A lexical
database for english. Communications of the
ACM, 38(11):39?41.
Hoifung Poon and Pedro Domingos. 2009. Unsuper-
vised semantic parsing. In EMNLP.
121
