Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 697?704
Manchester, August 2008
Exploiting Constituent Dependencies for Tree Kernel-based Semantic 
Relation Extraction 
Longhua Qian   Guodong Zhou   Fang Kong   Qiaoming Zhu   Peide Qian 
Jiangsu Provincial Key Lab for Computer Information Processing Technology 
School of Computer Science and Technology, Soochow University 
1 Shizi Street, Suzhou, China 215006 
{qianlonghua,gdzhou,kongfang,qmzhu,pdqian}@suda.edu.cn
Abstract
This paper proposes a new approach to 
dynamically determine the tree span for 
tree kernel-based semantic relation ex-
traction. It exploits constituent dependen-
cies to keep the nodes and their head 
children along the path connecting the 
two entities, while removing the noisy in-
formation from the syntactic parse tree, 
eventually leading to a dynamic syntactic 
parse tree. This paper also explores entity 
features and their combined features in a 
unified parse and semantic tree, which in-
tegrates both structured syntactic parse 
information and entity-related semantic 
information. Evaluation on the ACE 
RDC 2004 corpus shows that our dy-
namic syntactic parse tree outperforms all 
previous tree spans, and the composite 
kernel combining this tree kernel with a 
linear state-of-the-art feature-based ker-
nel, achieves the so far best performance. 
1 Introduction 
Information extraction is one of the key tasks in 
natural language processing. It attempts to iden-
tify relevant information from a large amount of 
natural language text documents. Of three sub-
tasks defined by the ACE program1, this paper 
focuses exclusively on Relation Detection and 
Characterization (RDC) task, which detects and 
classifies semantic relationships between prede-
fined types of entities in the ACE corpus. For 
? 2008. Licensed under the Creative Commons Attribution-
Noncommercial-Share Alike 3.0 Unported license 
(http://creativecommons.org/licenses/by-nc-sa/3.0/). Some 
rights reserved. 
1 http://www.ldc.upenn.edu/Projects/ACE/ 
example, the sentence ?Microsoft Corp. is based 
in Redmond, WA? conveys the relation ?GPE-
AFF.Based? between ?Microsoft Corp.? [ORG] 
and ?Redmond? [GPE]. Due to limited accuracy 
in state-of-the-art syntactic and semantic parsing, 
reliably extracting semantic relationships be-
tween named entities in natural language docu-
ments is still a difficult, unresolved problem. 
In the literature, feature-based methods have 
dominated the research in semantic relation ex-
traction. Featured-based methods achieve prom-
ising performance and competitive efficiency by 
transforming a relation example into a set of syn-
tactic and semantic features, such as lexical 
knowledge, entity-related information, syntactic 
parse trees and deep semantic information. How-
ever, detailed research (Zhou et al, 2005) shows 
that it?s difficult to extract new effective features 
to further improve the extraction accuracy. 
Therefore, researchers turn to kernel-based 
methods, which avoids the burden of feature en-
gineering through computing the similarity of 
two discrete objects (e.g. parse trees) directly. 
From prior work (Zelenko et al, 2003; Culotta 
and Sorensen, 2004; Bunescu and Mooney, 2005) 
to current research (Zhang et al, 2006; Zhou et 
al., 2007), kernel methods have been showing 
more and more potential in relation extraction. 
The key problem for kernel methods on rela-
tion extraction is how to represent and capture 
the structured syntactic information inherent in 
relation instances. While kernel methods using 
the dependency tree (Culotta and Sorensen, 2004) 
and the shortest dependency path (Bunescu and 
Mooney, 2005) suffer from low recall perform-
ance, convolution tree kernels (Zhang et al, 2006; 
Zhou et al, 2007) over syntactic parse trees 
achieve comparable or even better performance 
than feature-based methods. 
However, there still exist two problems re-
garding currently widely used tree spans. Zhang 
et al (2006) discover that the Shortest Path-
697
enclosed Tree (SPT) achieves the best perform-
ance. Zhou et al (2007) further extend it to Con-
text-Sensitive Shortest Path-enclosed Tree (CS-
SPT), which dynamically includes necessary 
predicate-linked path information. One problem 
with both SPT and CS-SPT is that they may still 
contain unnecessary information. The other prob-
lem is that a considerable number of useful con-
text-sensitive information is also missing from 
SPT/CS-SPT, although CS-SPT includes some 
contextual information relating to predicate-
linked path. 
This paper proposes a new approach to dy-
namically determine the tree span for relation 
extraction by exploiting constituent dependencies 
to remove the noisy information, as well as keep 
the necessary information in the parse tree. Our 
motivation is to integrate dependency informa-
tion, which has been proven very useful to rela-
tion extraction, with the structured syntactic in-
formation to construct a concise and effective 
tree span specifically targeted for relation extrac-
tion. Moreover, we also explore interesting com-
bined entity features for relation extraction via a 
unified parse and semantic tree. 
The other sections in this paper are organized 
as follows. Previous work is first reviewed in 
Section 2. Then, Section 3 proposes a dynamic 
syntactic parse tree while the entity-related se-
mantic tree is described in Section 4. Evaluation 
on the ACE RDC corpus is given in Section 5. 
Finally, we conclude our work in Section 6. 
2 Related Work 
Due to space limitation, here we only review 
kernel-based methods used in relation extraction. 
For those interested in feature-based methods, 
please refer to Zhou et al (2005) for more details. 
Zelenko et al (2003) described a kernel be-
tween shallow parse trees to extract semantic 
relations, where a relation instance is trans-
formed into the least common sub-tree connect-
ing the two entity nodes. The kernel matches the 
nodes of two corresponding sub-trees from roots 
to leaf nodes recursively layer by layer in a top-
down manner. Their method shows successful 
results on two simple extraction tasks. Culotta 
and Sorensen (2004) proposed a slightly general-
ized version of this kernel between dependency 
trees, in which a successful match of two relation 
instances requires the nodes to be at the same 
layer and in the identical path starting from the 
roots to the current nodes. These strong con-
straints make their kernel yield high precision but 
very low recall on the ACE RDC 2003 corpus. 
Bunescu and Mooney (2005) develop a shortest 
path dependency tree kernel, which simply 
counts the number of common word classes at 
each node in the shortest paths between two enti-
ties in dependency trees. Similar to Culotta and 
Sorensen (2004), this method also suffers from 
high precision but low recall.
Zhang et al (2006) describe a convolution tree 
kernel (CTK, Collins and Duffy, 2001) to inves-
tigate various structured information for relation 
extraction and find that the Shortest Path-
enclosed Tree (SPT) achieves the F-measure of 
67.7 on the 7 relation types of the ACE RDC 
2004 corpus. One problem with SPT is that it 
loses the contextual information outside SPT, 
which is usually critical for relation extraction. 
Zhou et al (2007) point out that both SPT and 
the convolution tree kernel are context-free. They 
expand SPT to CS-SPT by dynamically includ-
ing necessary predicate-linked path information 
and extending the standard CTK to context-
sensitive CTK, obtaining the F-measure of 73.2 
on the 7 relation types of the ACE RDC 2004 
corpus. However, the CS-SPT only recovers part 
of contextual information and may contain noisy 
information as much as SPT. 
In order to fully utilize the advantages of fea-
ture-based methods and kernel-based methods, 
researchers turn to composite kernel methods. 
Zhao and Grishman (2005) define several fea-
ture-based composite kernels to capture diverse 
linguistic knowledge and achieve the F-measure 
of 70.4 on the 7 relation types in the ACE RDC 
2004 corpus. Zhang et al (2006) design a com-
posite kernel consisting of an entity linear kernel 
and a standard CTK, obtaining the F-measure of 
72.1 on the 7 relation types in the ACE RDC 
2004 corpus. Zhou et al (2007) describe a com-
posite kernel to integrate a context-sensitive 
CTK and a state-of-the-art linear kernel. It 
achieves the so far best F-measure of 75.8 on the 
7 relation types in the ACE RDC 2004 corpus. 
In this paper, we will further study how to dy-
namically determine a concise and effective tree 
span for a relation instance by exploiting con-
stituent dependencies inherent in the parse tree 
derivation. We also attempt to fully capture both 
the structured syntactic parse information and 
entity-related semantic information, especially 
combined entity features, via a unified parse and 
semantic tree. Finally, we validate the effective-
ness of a composite kernel for relation extraction, 
which combines a tree kernel and a linear kernel. 
698
3 Dynamic Syntactic Parse Tree 
This section discusses how to generate dynamic 
syntactic parse tree by employing constituent 
dependencies to overcome the problems existing 
in currently used tree spans. 
3.1 Constituent Dependencies in Parse Tree 
Zhang et al (2006) explore five kinds of tree 
spans and find that the Shortest Path-enclosed 
Tree (SPT) achieves the best performance. Zhou 
et al (2007) further propose Context-Sensitive 
SPT (CS-SPT), which can dynamically deter-
mine the tree span by extending the necessary 
predicate-linked path information outside SPT. 
However, the key problem of how to represent 
the structured syntactic parse tree is still partially 
resolved. As we indicate as follows, current tree 
spans suffer from two problems: 
(1) Both SPT and CS-SPT still contain unnec-
essary information. For example, in the sentence 
??bought one of town?s two meat-packing
plants?, the condensed information ?one of 
plants? is sufficient to determine ?DISC? rela-
tionship between the entities ?one? [FAC] and 
?plants? [FAC], while SPT/CS-SPT include the 
redundant underlined part. Therefore more un-
necessary information can be safely removed 
from SPT/CS-SPT. 
(2) CS-SPT only captures part of context-
sensitive information relating to predicate-linked 
structure (Zhou et al, 2007) and still loses much 
context-sensitive information. Let?s take the 
same example sentence ??bought one of town?s
two meat-packing plants?, where indeed there is 
no relationship between the entities ?one? [FAC] 
and ?town? [GPE]. Nevertheless, the information 
contained in SPT/CS-SPT (?one of town?) may 
easily lead to their relationship being misclassi-
fied as ?DISC?, which is beyond our expectation. 
Therefore the underlined part outside SPT/CS-
SPT should be recovered so as to differentiate it 
from positive instances. 
Since dependency plays a key role in many 
NLP problems such as syntactic parsing, seman-
tic role labeling as well as semantic relation ex-
traction, our motivation is to exploit dependency 
knowledge to distinguish the necessary evidence 
from the unnecessary information in the struc-
tured syntactic parse tree.  
On one hand, lexical or word-word depend-
ency indicates the relationship among words 
occurring in the same sentence, e.g. predicate-
argument dependency means that arguments are 
dependent on their target predicates, modifier-
head dependency means that modifiers are de-
pendent on their head words. This dependency 
relationship offers a very condensed representa-
tion of the information needed to assess the rela-
tionship in the forms of the dependency tree (Cu-
lotta and Sorensen, 2004) or the shortest depend-
ency path (Bunescu and Mooney, 2005) that in-
cludes both entities.
On the other hand, when the parse tree corre-
sponding to the sentence is derived using deriva-
tion rules from the bottom to the top, the word-
word dependencies extend upward, making a 
unique head child containing the head word for 
every non-terminal constituent. As indicated as 
follows, each CFG rule has the form: 
P? Ln?L1H R1?Rm
Here, P is the parent node, H is the head child of 
the rule, Ln?L1 and R1?Rm are left and right 
modifiers of H respectively, and both n and m
may be zero. In other words, the parent node P
depends on the head child H, this is what we call 
constituent dependency. Vice versa, we can also 
determine the head child of a constituent in terms 
of constituent dependency. Our hypothesis stipu-
lates that the contribution of the parse tree to es-
tablishing a relationship is almost exclusively 
concentrated in the path connecting the two enti-
ties, as well as the head children of constituent 
nodes along this path. 
3.2 Generation of Dynamic Syntactic Parse 
Tree
Starting from the Minimum Complete Tree 
(MCT, the complete sub-tree rooted by the near-
est common ancestor of the two entities under 
consideration) as the representation of each rela-
tion instance, along the path connecting two enti-
ties, the head child of every node is found ac-
cording to various constituent dependencies. 
Then the path nodes and their head children are 
kept while any other nodes are removed from the 
tree. Eventually we arrive at a tree called Dy-
namic Syntactic Parse Tree (DSPT), which is 
dynamically determined by constituent depend-
encies and only contains necessary information 
as expected. 
There exist a considerable number of constitu-
ent dependencies in CFG as described by Collins 
(2003). However, since our task is to extract the 
relationship between two named entities, our fo-
cus is on how to condense Noun-Phrases (NPs) 
and other useful constituents for relation extrac-
tion. Therefore constituent dependencies can be 
classified according to constituent types of the 
CFG rules: 
699
(1) Modification within base-NPs: base-NPs 
mean that they do not directly dominate an NP
themselves, unless the dominated NP is a posses-
sive NP. The noun phrase right above the entity
headword, whose mention type is nominal or 
name, can be categorized into this type. In this 
case, the entity headword is also the headword of 
the noun phrase, thus all the constituents before 
the headword are dependent on the headword,
and may be removed from the parse tree, while 
the headword and the constituents right after the 
headword remain unchanged. For example, in the 
sentence ??bought one of town?s two meat-
packing plants? as illustrated in Figure 1(a), the
constituents before the headword  ?plants? can 
be removed from the parse tree. In this way the
parse tree ?one of plants? could capture the
?DISC? relationship more concisely and pre-
cisely. Another interesting example is shown in 
Figure 1(b), where the base-NP of the second
entity ?town? is a possessive NP and there is no 
relationship between the entities ?one? and
?town? defined in the ACE corpus. For both SPT
and CS-SPT, this example would be condensed 
to ?one of town? and therefore easily misclassi-
fied as the ?DISC? relationship between the two 
entities. In the contrast, our DSPT can avoid this 
problem by keeping the constituent ??s? and the 
headword ?plants?.
(2) Modification to NPs: except base-NPs,
other modification to NPs can be classified into 
this type. Usually these NPs are recursive, mean-
ing that they contain another NP as their child. 
The CFG rules corresponding to these modifica-
tions may have the following forms:
NP? NP SBAR [relative clause]
NP? NP VP [reduced relative]
NP? NP PP [PP attachment]
Here, the NPs in bold mean that the path con-
necting the two entities passes through them. For
every right hand side, the NP in bold is modified
by the constituent following them. That is, the 
latter is dependent on the former, and may be 
reduced to a single NP. In Figure 1(c) we show a
sentence ?one of about 500 people nominated
for ??, where there exists a ?DISC? relationship
between the entities ?one? and ?people?. Since 
the reduced relative ?nominated for ?? modifies
and is therefore dependent on the ?people?, they 
can be removed from the parse tree, that is, the 
right side (?NP VP?) can be reduced to the left 
hand side, which is exactly a single NP. 
(a) Removal of constituents before the headword in base-NP
(b) Keeping of constituents after the headword in base-NP
NN
one
IN
of
DT
the
NN
town
POS
's
E-FAC
NN
plantstwo
CD NN
one
IN
of
NN
town
POS
's
E-FAC
NN
plantsmeat-packing
JJ
NN
one
PP
IN
of
NP
DT
the
NN
town
POS
's
NN
plantstwo
CD NN
one
IN
of
NN
plantsmeat-packing
JJ NN
one
IN
of
RB
about
QP
CD
500
NNS
people
...
nominated
VBN
for
IN
VP
PP
...
E2-PER
NN
one
IN
of
NNS
people
NN
property
PRP
he
VP
VBZ IN
in
NP
PP
state
NNS
the
NP
JJ
rental
S
owns
DT NN
property
PRP
he
VP
VBZ
owns
governors from connecticut
NNS IN
NP
E-GPE
NNP
,
,
south
NP
E-GPE
NNP
dakota
NNP
,
,
and
CC
montana
NNP
governors from
NNS IN
montana
NNP
(c) Reduction of modification to NP
(d) Removal of arguments to verb
(e) Reduction of conjuncts for NP coordination
E-GPE
NPPP
E1-FAC
NP
E2-FAC
NP
E1-FAC
NP
NP
NP
NP
E2-FAC E1-PER
NP
NP
PP
NP
NP
NP
E1-PER
PP
NP
E2-PER
NP
SBAR
E2-PER
S
NPNP
E1-FAC
PP
NP
NP
E1-PER
NP
E2-GPE
NP
E1-PER
PP
NP
NP
NP
E2-GPE
NP
E1-FAC E2-PER
NP
NP
SBAR
NP
NP
E1-FAC
PP
NP
NP
E2-GPE
NP
NP
E1-PER
PP
NP
NP
E2-GPE
Figure 1. Removal and reduction of constituents using dependencies 
700
(3) Arguments/adjuncts to verbs: this type 
includes the CFG rules in which the left side in-
cludes S, SBAR or VP. An argument represents
the subject or object of a verb, while an adjunct
indicates the location, date/time or way of the
action corresponding to the verb. They depend
on the verb and can be removed if they are not
included in the path connecting the two entities.
However, when the parent tag is S or SBAR, and
its child VP is not included in the path, this VP
should be recovered to indicate the predicate
verb. Figure 1(d) shows a sentence ?? maintain
rental property he owns in the state?, where the
?ART.User-or-Owner? relation holds between 
the entities ?property? and ?he?. While PP can be
removed from the rule  (?VP? VBZ PP?), the 
VP should be kept in the rule (?S? NP VP?).
Consequently, the tree span looks more concise 
and precise for relation extraction. 
(4) Coordination conjunctions: In coordina-
tion constructions, several peer conjuncts may be 
reduced into a single constituent. Although the
first conjunct is always considered as the head-
word (Collins, 2003), actually all the conjuncts
play an equal role in relation extraction. As illus-
trated in Figure 1(e), the NP coordination in the 
sentence (?governors from connecticut, south
dakota, and montana?) can be reduced to a single 
NP (?governors from montana?) by keeping the
conjunct in the path while removing the other 
conjuncts.
(5) Modification to other constituents: ex-
cept for the above four types, other CFG rules 
fall into this type, such as modification to PP,
ADVP and PRN etc. These cases are similar to 
arguments/adjuncts to verbs, but less frequent 
than them, so we will not detail this scenario. 
In fact, SPT (Zhang et al, 2006) can be ar-
rived at by carrying out part of the above re-
moval operations using a single rule (i.e. all the 
constituents outside the linking path should be
removed) and CS-CSPT (Zhou et al, 2007) fur-
ther recovers part of necessary context-sensitive 
information outside SPT, this justifies that SPT
performs well, while CS-SPT outperforms SPT. 
4 Entity-related Semantic Tree 
Entity semantic features, such as entity headword, 
entity type and subtype etc., impose a strong
constraint on relation types in terms of relation
definition by the ACE RDC task. Experiments by
Zhang et al (2006) show that linear kernel using 
only entity features contributes much when com-
bined with the convolution parse tree kernel. 
Qian et al (2007) further indicates that among
these entity features, entity type, subtype, and 
mention type, as well as the base form of predi-
cate verb, contribute most while the contribution
of other features, such as entity class, headword 
and GPE role, can be ignored. 
In order to effectively capture entity-related
semantic features, and their combined features as
well, especially bi-gram or tri-gram features, we 
build an Entity-related Semantic Tree (EST) in 
three ways as illustrated in Figure 2. In the ex-
ample sentence ?they ?re here?, which is ex-
cerpted from the ACE RDC 2004 corpus, there 
exists a relationship ?Physical.Located? between
the entities ?they? [PER] and ?here?
[GPE.Population-Center]. The features are en-
coded as ?TP?, ?ST?, ?MT? and ?PVB?, which
denote type, subtype, mention-type of the two 
entities, and the base form of predicate verb if 
existing (nearest to the 2nd entity along the path 
connecting the two entities) respectively. For 
example, the tag ?TP1? represents the type of the 
1st entity, and the tag ?ST2? represents the sub-
type of the 2nd entity. The three entity-related
semantic tree setups are depicted as follows: 
TP2TP1
(a) Bag Of Features(BOF)
ENT
ST2ST1 MT2MT1 PVB
(c) Entity-Paired Tree(EPT)
ENT
E1 E2
(b) Feature Paired Tree(FPT)
ENT
TP ST MT
ST1TP1 MT1 TP2 ST2 MT2
PVB
TP1 TP2 ST1 ST2 MT1 MT2
PVB
PER null PRO GPE Pop. PRO be
PER null PRO GPE Pop. PRO
be
PER GPE null Pop. PRO PRO
be
Figure 2. Different setups for entity-related se-
mantic tree (EST) 
(a) Bag of Features (BOF, e.g. Fig. 2(a)): all 
feature nodes uniformly hang under the root node,
so the tree kernel simply counts the number of 
common features between two relation instances.
This tree setup is similar to linear entity kernel
explored by Zhang et al (2006). 
(b) Feature-Paired Tree (FPT, e.g. Fig. 2(b)): 
the features of two entities are grouped into dif-
ferent types according to their feature names, e.g.
?TP1? and ?TP2? are grouped to ?TP?. This tree 
setup is aimed to capture the additional similarity
701
of the single feature combined from different 
entities, i.e., the first and the second entities. 
(c) Entity-Paired Tree (EPT, e.g. Fig. 2(c)): all 
the features relating to an entity are grouped to 
nodes ?E1? or ?E2?, thus this tree kernel can fur-
ther explore the equivalence of combined entity 
features only relating to one of the entities be-
tween two relation instances. 
In fact, the BOF only captures the individual 
entity features, while the FPT/EPT can addition-
ally capture the bi-gram/tri-gram features respec-
tively. 
Rather than constructing a composite kernel, 
we incorporate the EST into the DSPT to pro-
duce a Unified Parse and Semantic Tree (UPST) 
to investigate the contribution of the EST to rela-
tion extraction. The entity features can be at-
tached under the top node, the entity nodes, or 
directly combined with the entity nodes as in 
Figure 1. However, detailed evaluation (Qian et 
al., 2007) indicates that the UPST achieves the 
best performance when the feature nodes are at-
tached under the top node. Hence, we also attach 
three kinds of entity-related semantic trees (i.e. 
BOF, FPT and EPT) under the top node of the 
DSPT right after its original children. Thereafter, 
we employ the standard CTK (Collins and Duffy, 
2001) to compute the similarity between two 
UPSTs, since this CTK and its variations are 
successfully applied in syntactic parsing, seman-
tic role labeling (Moschitti, 2004) and relation 
extraction (Zhang et al, 2006; Zhou et al, 2007) 
as well. 
5 Experimentation 
This section will evaluate the effectiveness of the 
DSPT and the contribution of entity-related se-
mantic information through experiments. 
5.1 Experimental Setting  
For evaluation, we use the ACE RDC 2004 cor-
pus as the benchmark data. This data set contains 
451 documents and 5702 relation instances. It 
defines 7 entity types, 7 major relation types and 
23 subtypes. For comparison with previous work, 
evaluation is done on 347 (nwire/bnews) docu-
ments and 4307 relation instances using 5-fold 
cross-validation. Here, the corpus is parsed using 
Charniak?s parser (Charniak, 2001) and relation 
instances are generated by iterating over all pairs 
of entity mentions occurring in the same sentence 
with given ?true? mentions and coreferential in-
formation. In our experimentations, SVMlight
(Joachims, 1998) with the tree kernel function
(Moschitti, 2004) 2  is selected as our classifier. 
For efficiency, we apply the one vs. others
strategy, which builds K classifiers so as to 
separate one class from all others. For 
comparison purposes, the training parameters C 
(SVM) and ? (tree kernel) are also set to 2.4 and 
0.4 respectively. 
5.2 Experimental Results 
Table 1 evaluates the contributions of different 
kinds of constituent dependencies to extraction 
performance on the 7 relation types of the ACE 
RDC 2004 corpus using the convolution parse 
tree kernel as depicted in Figure 1. The MCT 
with only entity-type information is first used as 
the baseline, and various constituent dependen-
cies are then applied sequentially to dynamically 
reshaping the tree in two different modes: 
--[M1] Respective:  every constituent depend-
ency is individually applied on MCT. 
--[M2] Accumulative: every constituent de-
pendency is incrementally applied on the previ-
ously derived tree span, which begins with the 
MCT and eventually gives rise to a Dynamic 
Syntactic Parse Tree (DSPT).  
Dependency types P(%) R(%) F
MCT (baseline) 75.1 53.8 62.7
Modification within 
base-NPs
76.5
(59.8)
59.8
(59.8)
67.1
(67.1)
Modification to NPs 
77.0
(76.2)
63.2
(56.9)
69.4
(65.1)
Arguments/adjuncts to verb 
77.1
(76.1)
63.9
(57.5)
69.9
(65.5)
Coordination conjunctions 
77.3
(77.3)
65.2
(55.1)
70.8
(63.8)
Other modifications 
77.4
(75.0)
65.4
(53.7)
70.9
(62.6)
Table 1. Contribution of constituent dependen-
cies in respective mode (inside parentheses) and 
accumulative mode (outside parentheses) 
The table shows that the final DSPT achieves 
the best performance of 77.4%/65.4%/70.9 in
precision/recall/F-measure respectively after ap-
plying all the dependencies, with the increase of 
F-measure by 8.2 units compared to the baseline 
MCT. This indicates that reshaping the tree by 
exploiting constituent dependencies may signifi-
cantly improve extraction accuracy largely due to 
the increase in recall. It further suggests that con-
stituent dependencies knowledge is very effec-
2 http://ai-nlp.info.uniroma2.it/moschitti/ 
702
tive and can be fully utilized in tree kernel-based 
relation extraction. This table also shows that: 
(1) Both modification within base-NPs and 
modification to NPs contribute much to perform-
ance improvement, acquiring the increase of F-
measure by 4.4/2.4 units in mode M1 and 4.4/2.3 
units in mode M2 respectively. This indicates the 
local characteristic of semantic relations, which 
can be effectively captured by NPs near the two 
involved entities in the DSPT. 
(2) All the other three dependencies show mi-
nor contribution to performance enhancement, 
they improve the F-measure only by 2.8/0.9/-0.1 
units in mode M1 and 0.5/0.9/0.1 units in mode 
M2. This may be due to the reason that these de-
pendencies only remove the nodes far from the 
two entities. 
We compare in Table 2 the performance of 
Unified Parse and Semantic Trees with different 
kinds of Entity Semantic Tree setups using stan-
dard convolution tree kernel, while the SPT and 
DSPT with only entity-type information are 
listed for reference. It shows that: 
(1) All the three unified parse and semantic 
tree kernels significantly outperform the DSPT 
kernel, obtaining an average increase of ~4 units 
in F-measure. This means that they can effec-
tively capture both the structured syntactic in-
formation and the entity-related semantic fea-
tures.
(2) The Unified Parse and Semantic Tree with 
Feature-Paired Tree achieves the best perform-
ance of 80.1/70.7/75.1 in P/R/F respectively, 
with an increase of F-measure by 0.4/0.3 units 
over BOF and EPT respectively. This suggests 
that additional bi-gram entity features captured 
by FPT are more useful than tri-gram entity fea-
tures captured by EPT. 
Tree setups P(%) R(%) F
SPT 76.3 59.8 67.1
DSPT 77.4 65.4 70.9
UPST (BOF) 80.4 69.7 74.7
UPST (FPT) 80.1 70.7 75.1
UPST (EPT) 79.9 70.2 74.8
Table 2. Performance of Unified Parse and 
Semantic Trees (UPSTs) on the 7 relation types 
of the ACE RDC 2004 corpus 
In Table 3 we summarize the improvements of 
different tree setups over SPT. It shows that in a 
similar setting, our DSPT outperforms SPT by 
3.8 units in F-measure, while CS-SPT outper-
forms SPT by 1.3 units in F-measure. This sug-
gests that the DSPT performs best among these 
tree spans. It also shows that the Unified Parse 
and Semantic Tree with Feature-Paired Tree per-
form significantly better than the other two tree 
setups (i.e., CS-SPT and DSPT) by 6.7/4.2 units 
in F-measure respectively. This implies that the 
entity-related semantic information is very useful 
and contributes much when they are incorporated 
into the parse tree for relation extraction. 
Tree setups P(%) R(%) F
CS-SPT over SPT3 1.5   1.1 1.3
DSPT over SPT 1.1   5.6 3.8
UPST (FPT) over SPT 3.8 10.9 8.0
Table 3. Improvements of different tree setups 
over SPT on the ACE RDC 2004 corpus 
Finally, Table 4 compares our system with 
other state-of-the-art kernel-based systems on the 
7 relation types of the ACE RDC 2004 corpus. It 
shows that our UPST outperforms all previous 
tree setups using one single kernel, and even bet-
ter than two previous composite kernels (Zhang 
et al, 2006; Zhao and Grishman, 2005). Fur-
thermore, when the UPST (FPT) kernel is com-
bined with a linear state-of-the-state feature-
based kernel (Zhou et al, 2005) into a composite 
one via polynomial interpolation in a setting 
similar to Zhou et al (2007) (i.e. polynomial de-
gree d=2 and coefficient ?=0.3), we get the so far 
best performance of 77.1 in F-measure for 7 rela-
tion types on the ACE RDC 2004 data set. 
Systems P(%) R(%) F
Ours:
composite kernel 
83.0 72.0 77.1
Zhou et al, (2007):
composite kernel 
82.2 70.2 75.8
Zhang et al, (2006):
composite kernel 
76.1 68.4 72.1
Zhao and Grishman, (2005):4
composite kernel 
69.2 70.5 70.4
Ours:
CTK with UPST 
80.1 70.7 75.1
Zhou et al, (2007): context-
sensitive CTK with CS-SPT 
81.1 66.7 73.2
Zhang et al, (2006):
CTK with SPT 
74.1 62.4 67.7
Table 4. Comparison of different systems on 
the ACE RDC 2004 corpus 
3  We arrive at these values by subtracting P/R/F 
(79.6/5.6/71.9) of Shortest-enclosed Path Tree from P/R/F  
(81.1/6.7/73.2) of Dynamic Context-Sensitive Shortest-
enclosed Path Tree according to Table 2 (Zhou et al, 2007) 
4 There might be some typing errors for the performance 
reported in Zhao and Grishman (2005) since P, R and F do 
not match. 
703
6 Conclusion
This paper further explores the potential of struc-
tured syntactic information for tree kernel-based 
relation extraction, and proposes a new approach 
to dynamically determine the tree span (DSPT) 
for relation instances by exploiting constituent 
dependencies. We also investigate different ways 
of how entity-related semantic features and their 
combined features can be effectively captured in 
a Unified Parse and Semantic Tree (UPST). 
Evaluation on the ACE RDC 2004 corpus shows 
that our DSPT is appropriate for structured repre-
sentation of relation instances. We also find that, 
in addition to individual entity features, com-
bined entity features (especially bi-gram) con-
tribute much when they are combined with a 
DPST into a UPST. And the composite kernel, 
combining the UPST kernel and a linear state-of-
the-art kernel, yields the so far best performance. 
For the future work, we will focus on improv-
ing performance of complex structured parse 
trees, where the path connecting the two entities 
involved in a relationship is too long for current 
kernel methods to take effect. Our preliminary 
experiment of applying certain discourse theory 
exhibits certain positive results.
Acknowledgements 
This research is supported by Project 60673041 
under the National Natural Science Foundation 
of China, Project 2006AA01Z147 under the 
?863? National High-Tech Research and Devel-
opment of China, and the National Research 
Foundation for the Doctoral Program of Higher 
Education of China under Grant No. 
20060285008. We would also like to thank the 
excellent and insightful comments from the three 
anonymous reviewers. 
References
Bunescu, Razvan C. and Raymond J. Mooney. 2005. 
A Shortest Path Dependency Kernel for Relation 
Extraction. In Proceedings of the Human Language 
Technology Conference and Conference on Em-
pirical Methods in Natural Language Processing 
(EMNLP-2005), pages 724-731. Vancover, B.C. 
Charniak, Eugene. 2001. Intermediate-head Parsing 
for Language Models. In Proceedings of the 39th 
Annual Meeting of the Association of Computa-
tional Linguistics (ACL-2001), pages 116-123. 
Collins, Michael. 2003. Head-Driven Statistics Mod-
els for Natural Language Parsing. Computational 
linguistics, 29(4): 589-617. 
Collins, Michael and Nigel Duffy. 2001. Convolution 
Kernels for Natural Language. In Proceedings of 
Neural Information Processing Systems (NIPS-
2001), pages 625-632. Cambridge, MA. 
Culotta, Aron and Jeffrey Sorensen. 2004. Depend-
ency tree kernels for relation extraction. In Pro-
ceedings of the 42nd Annual Meeting of the Asso-
ciation of Computational Linguistics (ACL-2004),
pages 423-439. Barcelona, Spain. 
Joachims, Thorsten. 1998. Text Categorization with 
Support Vector Machine: learning with many rele-
vant features. In Proceedings of the 10th European 
Conference on Machine Learning (ECML-1998),
pages 137-142. Chemnitz, Germany. 
Moschitti, Alessandro. 2004. A Study on Convolution 
Kernels for Shallow Semantic Parsing. In Proceed-
ings of the 42nd Annual Meeting of the Association 
of Computational Linguistics (ACL-2004). Barce-
lona, Spain. 
Qian, Longhua, Guodong Zhou, Qiaoming Zhu and 
Peide Qian. 2007. Relation Extraction using Con-
volution Tree Kernel Expanded with Entity Fea-
tures. In Proceedings of the 21st Pacific Asian 
Conference on Language, Information and Compu-
tation (PACLIC-21), pages 415-421. Seoul, Korea. 
Zelenko, Dmitry, Chinatsu Aone and Anthony Rich-
ardella. 2003. Kernel Methods for Relation Extrac-
tion. Journal of Machine Learning Research, 
3(2003): 1083-1106. 
Zhang, Min, Jie Zhang, Jian Su and Guodong Zhou. 
2006. A Composite Kernel to Extract Relations be-
tween Entities with both Flat and Structured Fea-
tures. In Proceedings of the 21st International 
Conference on Computational Linguistics and the 
44th Annual Meeting of the Association of Compu-
tational Linguistics (COLING/ACL-2006), pages 
825-832. Sydney, Australia. 
Zhao, Shubin and Ralph Grishman. 2005. Extracting 
relations with integrated information using kernel 
methods. In Proceedings of the 43rd Annual Meet-
ing of the Association of Computational Linguistics 
(ACL-2005), pages 419-426. Ann Arbor, USA. 
Zhou, Guodong, Jian Su, Jie Zhang and Min Zhang. 
2005. Exploring various knowledge in relation ex-
traction. In Proceedings of the 43rd Annual Meet-
ing of the Association of Computational Linguistics 
(ACL-2005), pages 427-434. Ann Arbor, USA. 
Zhou, Guodong, Min Zhang, Donghong Ji and 
Qiaoming Zhu. 2007. Tree Kernel-based Relation 
Extraction with Context-Sensitive Structured Parse 
Tree Information. In Proceedings of the 2007 Joint 
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural 
Language Learning (EMNLP/CoNLL-2007), pages 
728-736. Prague, Czech. 
704
Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1280?1288,
Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
 
Improving Nominal SRL in Chinese Language with Verbal SRL In-
formation and Automatic Predicate Recognition 
 
Junhui Li?   Guodong Zhou??   Hai Zhao??  Qiaoming Zhu?  Peide Qian? 
? Jiangsu Provincial Key Lab for Computer Information Processing Technologies
School of Computer Science and Technology 
Soochow University, Suzhou, China 215006 
? Department of Chinese, Translation and Linguistics 
City University of HongKong, China 
Email: {lijunhui,gdzhou,hzhao,qmzhu,pdqian}@suda.edu.cn
 
                                                          
? Corresponding author 
Abstract 
This paper explores Chinese semantic role la-
beling (SRL) for nominal predicates. Besides 
those widely used features in verbal SRL, 
various nominal SRL-specific features are 
first included. Then, we improve the perform-
ance of nominal SRL by integrating useful 
features derived from a state-of-the-art verbal 
SRL system. Finally, we address the issue of 
automatic predicate recognition, which is es-
sential for a nominal SRL system. Evaluation 
on Chinese NomBank shows that our research 
in integrating various features derived from 
verbal SRL significantly improves the per-
formance. It also shows that our nominal SRL 
system much outperforms the state-of-the-art 
ones. 
1. Introduction 
Semantic parsing maps a natural language sen-
tence into a formal representation of its meaning. 
Due to the difficulty in deep semantic parsing, 
most of previous work focuses on shallow se-
mantic parsing, which assigns a simple structure 
(such as WHO did WHAT to WHOM, WHEN, 
WHERE, WHY, HOW) to each predicate in a 
sentence. In particular, the well-defined seman-
tic role labeling (SRL) task has been drawing 
more and more attention in recent years due to 
its importance in deep NLP applications, such as 
question answering (Narayanan and Harabagiu, 
2004), information extraction (Surdeanu et al, 
2003), and co-reference resolution (Ponzetto and 
Strube, 2006). Given a sentence and a predicate 
(either a verb or a noun) in it, SRL recognizes 
and maps all the constituents in the sentence into 
their corresponding semantic arguments (roles) 
of the predicate. According to the predicate 
types, SRL could be divided into SRL for verbal 
predicates (verbal SRL, in short) and SRL for 
nominal predicates (nominal SRL, in short). 
During the past few years, verbal SRL has 
dominated the research on SRL with the avail-
ability of FrameNet (Baker et al, 1998), Prop-
Bank (Palmer et al, 2005), and the consecutive 
CoNLL shared tasks (Carreras and M?rquez, 
2004 & 2005) in English language. As a com-
plement to PropBank on verbal predicates, 
NomBank (Meyers et al, 2004) annotates nomi-
nal predicates and their corresponding semantic 
roles using similar semantic framework as 
PropBank. As a representative, Jiang and Ng 
(2006) pioneered the exploration of various 
nominal SRL-specific features besides the tradi-
tional verbal SRL-related features on NomBank. 
They achieved the performance of 72.73 and 
69.14 in F1-measure on golden and automatic 
syntactic parse trees, respectively, given golden 
nominal predicates. 
For SRL in Chinese, Sun and Jurafsky (2004) 
and Pradhan et al (2004) pioneered the research 
on Chinese verbal and nominal SRLs, respec-
tively, on small private datasets. Taking the ad-
vantage of recent release of Chinese PropBank 
(Xue and Palmer, 2003) and Chinese NomBank 
(Xue, 2006a), Xue and his colleagues (Xue and 
Palmer 2005; Xue 2006b; Xue, 2008) pioneered 
the exploration of Chinese verbal and nominal 
SRLs, given golden predicates. Among them, 
Xue and Palmer (2005) studied Chinese verbal 
SRL using Chinese PropBank and achieved the 
performance of 91.3 and 61.3 in F1-measure on 
golden and automatic syntactic parse trees, re-
spectively. Xue (2006b) extended their study on 
Chinese nominal SRL and attempted to improve 
the performance of nominal SRL by simply in-
1280
 cluding the Chinese PropBank training instances 
into the training data for nominal SRL on Chi-
nese NomBank. However, such integration was 
empirically proven unsuccessful due to the dif-
ferent nature of certain features for verbal and 
nominal SRLs. Xue (2008) further improved the 
performance on both verbal and nominal SRLs 
with a better syntactic parser and new features. 
Ding and Chang (2008) focused on argument 
classification for Chinese verbal predicates with 
hierarchical feature selection strategy. They 
achieved the classification precision of 94.68% 
on golden parse trees on Chinese PropBank. 
This paper focuses on Chinese nominal SRL. 
This is done by adopting a traditional verbal 
SRL architecture to handle Chinese nominal 
predicates with additional nominal SRL-specific 
features. Moreover, we significantly enhance the 
performance of nominal SRL by properly inte-
grating various features derived from verbal 
SRL. Finally, this paper investigates the effect of 
automatic nominal predicate recognition on the 
performance of Chinese nominal SRL. Although 
previous research (e.g. CoNLL?2008) in English 
nominal SRL reveals the importance of auto-
matic predicate recognition, there has no re-
ported research on automatic predicate 
recognition in Chinese nominal SRL. 
The rest of this paper is organized as follows: 
Section 2 introduces Chinese NomBank while 
the baseline nominal SRL system is described in 
Section 3 with traditional and nominal SRL-
specific features. Then, the baseline nominal 
SRL system is improved by integrating useful 
features derived from verbal SRL (Section 4) 
and extended with automatic recognition of 
nominal predicates (Section 5). Section 6 gives 
experimental results and discussion. Finally, 
Section 7 concludes the paper.    
2. Chinese NomBank 
Chinese NomBank (Xue, 2006a) adopts similar 
semantic framework as NomBank, and focuses 
on Chinese nominal predicates with their argu-
ments in Chinese TreeBank. The semantic ar-
guments include:  
1) Core arguments: Arg0 to Arg5. Generally, 
Arg0 and Arg1 denotes the agent and the 
patient, respectively, while arguments from 
Arg2 to Arg5 are predicate-specific.  
2) Adjunct arguments, which are universal to 
all predicates, e.g. ArgM-LOC for locative, 
and ArgM-TMP for temporal. 
 
All the arguments are annotated on parse tree 
nodes with their boundaries aligning with the 
spans of tree nodes. Figure 1 gives an example 
with two nominal predicates and their respective 
arguments, while the nominal predicate ???
/investment? has two core arguments, ?NN(??
/foreign businessman)? as Arg0 and ?NN(??
/bank)? as Arg1, and the other nominal predicate 
??? /loan? also has two core arguments, 
?NP(???? /Bank of China)? as Arg1 and 
Figure 1: Two nominal predicates and their arguments in the style of NomBank. 
? 
?? ?? ??
??
???
P 
NN NN NN
VV
NN NN 
Arg0/Rel1 Rel1 Arg1/Rel1
NP 
PP 
Arg0/Rel2 
ArgM-MNR/Rel2 Rel2 
NP 
CD
QP
NP
VP
VP
??? ?? 
? 
NN NN 
PU 
NP 
Arg1/Rel2 
IP
?? ?? 
Sup/Rel2
Bank of China 
to 
Foreign  Investment  Bank 
provide
4 billion
RMB loan 
. 
Bank of China provides 4 billion RMB loan to Foreign Investment Bank. 
1281
 ?PP(??????? /to Foreign Investment 
Bank)? as Arg0,  and 1 adjunct argument, 
?NN(???/RMB)? as ArgM-MNR, denoting 
the manner of loan. It is worth noticing that 
there is a (Chinese) NomBank-specific label in 
Figure 1, Sup (support verb) (Xue, 2006a), in 
helping introduce the arguments, which occur 
outside the nominal predicate-headed noun 
phrase. This is illustrated by the nominal predi-
cate ???/loan?, whose Arg0 and Arg1 are both 
realized outside the nominal predicate-headed 
noun phrase, NP(????????/4 billion 
RMB loan). Normally, a verb is marked as a 
support verb only when it shares some argu-
ments with the nominal predicate. 
3. Baseline: Chinese Nominal SRL 
Popular SRL systems usually formulate SRL as 
a classification problem, which annotates each 
constituent in a parse tree with a semantic role 
label or with the non-argument label NULL. Be-
sides, we divide the system into three consecu-
tive phases so as to overcome the imbalance 
between the training instances of the NULL 
class and those of any other argument classes.  
Argument pruning. Here, several heuristic 
rules are adopted to filter out constituents, which 
are most likely non-arguments. According to the 
argument structures of nominal predicates, we 
categorize arguments into two types: arguments 
inside NP (called inside arguments) and argu-
ments introduced via a support verb (called out-
side arguments), and handle them separately. 
For the inside arguments, the following three 
heuristic rules are applied to find inside argu-
ment candidates: 
z All the sisters of the predicate are candi-
dates. 
z If a CP or DNP node is a candidate, its chil-
dren are candidates too. 
z For any node X, if its parent is an ancestral 
node of the predicate, and the internal 
nodes along the path between X and the 
predicate are all NPs, then X is a candidate. 
For outside arguments, we look for the sup-
port verb of the focus nominal predicate, and 
then adopt the rules as proposed in Xue and 
Palmer (2005) to find the candidates for the sup-
port verb, since outside argument candidates are 
introduced via this support verb. That to say, the 
argument candidates of the support verb are re-
garded as outside argument candidates of the 
nominal predicate. However, as support verbs 
are not annotated explicitly in the testing phase, 
we identify intervening verbs as alternatives to 
support verbs in both training and testing phases 
with the path between the nominal predicate and 
intervening verb in the form of 
?VV<VP>[NP>]+NN?, where ?[NP>]+? denotes 
one or more NPs.  Our statistics on Chinese 
NomBank shows that 51.96% of nominal predi-
cates have no intervening verb while 48.04% of 
nominal predicates have only one intervening 
verb. 
Taken the nominal predicate ???/loan? in 
Figure 1 as an example, NN(???/RMB) and 
QP(??? /4 billion) are identified as inside 
argument candidates, while PP(??????
?/to Foreign Investment Bank) and NP(???
?/Bank of China) are identified as outside ar-
gument candidates via the support verb VV(?
?/provide). 
Argument identification. A binary classifier 
is applied to determine the candidates as either 
valid arguments or non-arguments. It is worth 
pointing out that we only mark those candidates 
that are most likely to be NULL (with probabil-
ity > 0.90) as non-arguments. Our empirical 
study shows that this little trick much benefits 
nominal SRL, since argument identification for 
nominal predicates is much more difficult than 
that for verbal predicates and thus many argu-
ments would have been falsely marked as non-
arguments if the threshold is set as 0.5. 
Argument classification. A multi-class classi-
fier is employed to label identified arguments 
with specific argument labels (including the 
NULL class for non-argument). 
In the following, we first adapt some tradi-
tional features, which have been proven effec-
tive in verbal SRL, to nominal SRL, and then 
introduce several nominal SRL-specific features. 
3.1. Traditional Features 
Using the feature naming convention as adopted 
in Jiang and Ng (2006), Table 1 lists the tradi-
tional features, where ?I? and ?C? indicate the 
features for argument identification and classifi-
cation, respectively. Among them, the predicate 
class (b2) feature was first introduced in Xue 
and Palmer (2005) to overcome the imbalance of 
the predicate distribution in that some predicates 
can be only found in the training data while 
some predicates in the testing data are absent 
from the training data. In particular, the verb 
class is classified along three dimensions: the 
number of arguments, the number of framesets 
and selected syntactic alternations. For example, 
1282
 the verb class of ?C1C2a? means that it has two 
framesets, with the first frameset having one 
argument and the second having two arguments. 
The symbol ?a? in the second frameset repre-
sents a type of syntactic alternation. 
 
Feature Remarks: b1-b5(C, I), b6-b7(C) 
b1 Predicate: the nominal predicate itself. (??
/loan) 
b2 Predicate class: the verb class that the predi-
cate belongs to. (C4a) 
b3 Head word (b3H) and its POS (b3P).  (??
/bank, NN) 
b4 Phrase type: the syntactic category of the 
constituent. (NP) 
b5 Path: the path from the constituent to the 
nominal predicate. 
 (NP<IP>VP>VP>NP>NP>NN) 
b6 Position: the positional relationship of the 
constituent with the predicate. ?left? or 
?right?. (left) 
b7 First word (b7F) and last word (b7L) of the 
focus constituent. (??/China, ??/bank) 
Combined features: b11-b14(C, I), b15(C) 
b11: b1&b4;       b12: b1&b3H;       b13: b2&b4;  
b14: b2&b3H;    b15: b5&b6 
Table 1: Traditional features and their instantiations 
for argument identification and classification, with 
NP(????/Bank of China)  as the focus constitu-
ent and NN(??/loan) as the nominal predicate, re-
garding Figure 1. 
3.2. Nominal SRL-specific Features 
To capture more useful information in the predi-
cate-argument structure, we also study addi-
tional features which provide extra information. 
Statistics on Chinese NomBank show that about 
40% of pruned inside candidates are arguments. 
Since inside arguments usually locate near to the 
nominal predicate, its surroundings are expected 
to be helpful in SRL. Table 2 shows the features 
in better capturing the details between inside 
arguments and nominal predicates. Specially, 
features ai6 and ai7 are sister-related features, 
inspired by the features related with the 
neighboring arguments in Jiang and Ng (2006). 
Statistics on NomBank and Chinese Nom-
Bank show that about 20% and 22% of argu-
ments are introduced via a support verb, 
respectively. Since a support verb pivots outside 
arguments and the nominal predicate on its two 
sides, support verbs play an important role in 
labeling these arguments. Here, we also identify 
intervening verbs as alternatives to support verbs 
since support verbs are not explicitly in the test-
ing phase. Table 3 lists the intervening verb-
related features (ao1-ao4, ao11-ao14) employed 
in this paper. 
 
Feature Remarks 
ai1 Whether the focus constituent is adjacent to 
the predicate. Yes or No. (Yes) 
ai2 The headword (ai2H) and pos (ai2P) of the 
predicate?s nearest right sister. (??/bank, 
NN) 
ai3 Whether the predicate has right sisters. Yes 
or No. (Yes) 
ai4 Compressed path of b5: compressing se-
quences of identical labels into one. 
(NN<NP>NN) 
ai5 Whether the predicate has sisters. Yes or 
No. (Yes) 
ai6 For each sister of the focus constituent, 
combine b3H&b4&b5&b6. ( ? ?
/bank&NN & NN<NP>NN&right) 
ai7 Coarse version of ai6, b4&b6. (NN&right) 
Table 2: Additional features and their instantiations  
for inside argument candidates, with ?NN(??
/foreign businessman)? as the focus constituent and 
?NN(?? /investment)? as the nominal predicate, 
regarding Figure1. 
 
Feature Remarks 
ao1 Intervening verb itself. (??/provide) 
ao2 The verb class that the intervening verb 
belongs to. (C3b) 
ao3 The path from the focus constituent to the 
intervening verb. (NP<IP>VP>VP>VV) 
ao4 The compressed path of ao3: compressing 
sequences of identical labels into one. 
(NP<IP>VP>VV) 
Combined features: ao11-ao14 
ao11: ao1&ao3;      ao12: ao1&ao4;    
ao13: ao2&ao3;      ao14: ao2&ao4. 
Table 3: Additional features and their instantiations 
for outside argument candidates, with ?NP(????
/Bank of China)? as the focus constituent and ???
/loan? as the nominal predicate, regarding Figure1. 
Feature selection. Some Features proposed 
above may not be effective in tasks of identifica-
tion and classification. We adopt the greedy fea-
ture selection algorithm as described in Jiang 
and Ng (2006) to pick up positive features em-
pirically and incrementally according to their 
contributions on the development data. The al-
gorithm repeatedly selects one feature each time 
which contributes most, and stops when adding 
any of the remaining features fails to improve 
the performance. As far as the SRL task con-
cerned, the whole feature selection process could 
be done as follows: 1). Feature selection for ar-
gument identification: run the selection algo-
1283
 rithm with the basic set of features (b1-b5, b11-
b14) to pick up effective features from (ai1-ai7, 
ao1-ao4, ao11-ao14); 2). Feature selection for 
argument classification: fix the output returned 
in step1 as the feature set of argument identifica-
tion, and run the selection algorithm with the 
basic set of features (b1-b7, b11-b15) to select 
positive features from (ai1-ai7, ao1-ao4, ao11-
ao14) for argument classification. 
4. Integrating Features derived from 
Verbal SRL 
Since Chinese PropBank and NomBank are an-
notated on the same data set with the same lexi-
cal guidelines (e.g. frame files), it may be 
interesting to investigate the contribution of 
Chinese verbal SRL on the performance of Chi-
nese nominal SRL. In the frame files, argument 
labels are defined with regard to their semantic 
roles to the predicate, either a verbal or nominal 
predicate. For example, in the frame file of 
predicate ???/loan?, the borrower is always 
labeled with Arg0 and the lender labeled with 
Arg1. This can be demonstrated by the follow-
ing two sentences: ???/loan? is annotated as a 
nominal and a verbal predicate in S1 and S2, 
respectively. 
S1 [Arg1 ????/Bank of China] [Arg0 ???
????/to Foreign Investment Bank] ??
/provide [Rel??/loan] 
S2  [Arg0 ????/Bank of China] [Arg1 ???
????/from Foreign Investment Bank] [Rel 
??/loan] 
Therefore, it is straightforward to augment 
nominal training instances with verbal ones. 
However, Xue (2006b) found that simply adding 
the training instances for verbal SRL to the 
training data for nominal SRL and indiscrimi-
nately extracting the same features in both ver-
bal and nominal SRLs hurt the performance. 
This may be due to that certain features (e.g. the 
path feature) are much different for verbal and 
nominal SRLs. This can be illustrated in sen-
tences S1 and S2: the verbal instances in S2 are 
negative for semantic role labeling of the nomi-
nal predicate ???/loan? in S1, since ????
?/Bank of China? takes opposite roles in S1 
and S2. So does ????????/(from/to) 
Foreign Investment Bank?. 
Although several support verb-related features 
(ao1-ao4, ao11-ao14) have been proposed, one 
may still ask how large the role support verbs 
can play in nominal SRL. It is interesting to note 
that outside arguments and the highest NP 
phrase headed by the nominal predicate are also 
annotated as arguments of the support verb in 
Chinese PropBank. For example, Chinese Prop-
Bank marks ?????/Bank of China? as Arg0 
and ?????????/4 billion RMB loan? 
as Arg1 for verb ???/provide? in Figure1. Let 
OA be the outside argument, VV be the support 
verb, and NP be the highest NP phrase headed 
by the nominal predicate NN, then there exists a 
pattern ?OA VV NN? in the sentence, where the 
support verb VV plays a certain role in trans-
ferring roles between OA and NN. For example, 
if OA is the agent of VV, then OA is also the 
agent of phrase VP(VV NN). Like the example 
in Figure1, supposing a NP is the agent of sup-
port verb ???/provide? as well as VP phrase 
(??????????? /provide 4 billion 
RMB loan?), we can infer that the NP is the 
lender of the nominal predicate ???/loan? in-
dependently on any other information, such as 
the NP content and the path from the NP to the 
nominal predicate ???/loan?.  
Let C be the focus constituent, V be the inter-
vening verb, and NP be the highest NP headed 
by the nominal predicate. Table 4 shows the fea-
tures (ao5-ao8, p1-p7) derived from verbal SRL. 
In this paper, we develop a state-of-the-art Chi-
nese verbal SRL system, similar to the one as 
shown in Xue (2008), to achieve the goal. Based 
on golden parse trees on Chinese PropBank, our 
Chinese verbal SRL system achieves the per-
formance of 92.38 in F1-measure, comparable to 
Xue (2008) which achieved the performance of 
92.0 in F1-measure. 
 
Feature Remarks 
ao5 Whether C is an argument for V. Yes or No
ao6 The semantic role of C for V. 
ao7 Whether NP is an argument for V. Yes or No
ao8 The semantic role of NP for V. 
Combined features: p1-p7 
p1: ao1&ao5;         p2: ao1&ao6;    p3: ao1&ao5&b1; 
p4: ao1&ao6&b1;  p5: ao1&apo7;  p6: ao1&ao8;  
p7: ao5&ao7. 
Table 4: Features derived from verbal SRL. 
5. Automatic Predicate Recognition 
Unlike Chinese PropBank where almost all the 
verbs are annotated as predicates, Chinese Nom-
Bank only marks those nouns having arguments 
as predicates. Statistics on Chinese NomBank 
show that only 17.5% of nouns are marked as 
predicates. It is possible that a noun is a predi-
1284
 cate in some cases but not in others. Previous 
Chinese nominal SRL systems (Xue, 2006b; 
Xue, 2008) assume that nominal predicates have 
already been manually annotated and thus are 
available. To our best knowledge, there is no 
report on addressing automatic recognition of 
nominal predicates on Chinese nominal SRL. 
Automatic recognition of nominal predicates 
can be cast as a binary classification (e.g., Predi-
cate vs. Non-Predicate) problem. This paper 
employs the convolution tree kernel, as proposed 
in Collins and Duffy (2001), on automatic rec-
ognition of nominal predicates. 
Given the convolution tree kernel, the key 
problem is how to extract a parse tree structure 
from the parse tree for a nominal predicate can-
didate. In this paper, the parse tree structure is 
constructed as follows: 1) starting from the 
predicate candidate?s POS node, collect all of its 
sister nodes (with their headwords); 2). recur-
sively move one level up and collect all of its 
sister nodes (with their headwords) till reaching 
a non-NP node. Specially, in order to explicitly 
mark the positional relation between a node and 
the predicate candidate, all nodes on the left side 
of the candidate are augmented with tags 1 and 2 
for nodes on the right side. Figure 2 shows an 
example of the parse tree structure with regard 
to the predicate candidate ???/loan? as shown 
in Figure 1. 
In our extra experiments we found global sta-
tistic features (e.g. g1-g5) about the predicate 
candidate are helpful in a feature vector-based 
method for predicate recognition. Figure 2 
makes an attempt to utilize those features in ker-
nel-based method. We have explored other ways 
to include those global features. However, the 
way in Figure 2 works best.  
 
 
Let the predicate candidate be w0, and its left 
and right neighbor words be w-1 and w1, respec-
tively. The five global features are defined as 
follows. 
g1 Whether w0 is ever tagged as a verb in the 
training data? Yes or No. 
g2 Whether w0 is ever annotated as a nominal 
predicate in the training data? Yes or No. 
g3 The most likely label for w0 when it occurs 
together with w-1 and w1. 
g4 The most likely label for w0 when it occurs 
together with w-1. 
g5 The most likely label for w0 when it occurs 
together with w1. 
6. Experiment Results and Discussion 
We have evaluated our Chinese nominal SRL 
system on Chinese NomBank with Chinese 
PropBank 2.0 as its counterpart. 
6.1. Experimental Settings 
This version of Chinese NomBank consists of 
standoff annotations on the files (chtb_001 to 
1151.fid) of Chinese Penn TreeBank 5.1. Fol-
lowing the experimental setting in Xue (2008), 
648 files (chtb_081 to 899.fid) are selected as 
the training data, 72 files (chtb_001 to 040.fid 
and chtb_900 to 931.fid) are held out as the test 
data, and 40 files (chtb_041 to 080.fid) as the 
development data, with 8642, 1124, and 731 
propositions, respectively. 
As Chinese words are not naturally segmented 
in raw sentences, two Chinese automatic parsers 
are constructed: word-based parser (assuming 
golden word segmentation) and character-based 
parser (with automatic word segmentation). 
Here, Berkeley parser (Petrov and Klein, 2007)1 
is chosen as the Chinese automatic parser. With 
regard to character-based parsing, we employ a 
Chinese word segmenter, similar to Ng and Low 
(2004), to obtain the best automatic segmenta-
tion result for a given sentence, which is then 
fed into Berkeley parser for further syntactic 
parsing. Both the word segmenter and Berkeley 
parser are developed with the same training and 
development datasets as our SRL experiments. 
The word segmenter achieves the performance 
of 96.1 in F1-measure while the Berkeley parser 
gives a performance of 82.5 and 85.5 in F1-
measure on golden and automatic word segmen-
tation, respectively2.  
??? 1 In addition, SVMLight with the tree kernel 
function (Moschitti, 2004) 3  is selected as our 
classifier. In order to handle multi-classification 
                                                          
1 Berkeley Parser. http://code.google.com/p/berkeleyparser/ 
2 POSs are not counted in evaluating the performance of 
word-based syntactic parser, but they are counted in evalu-
ating the performance of character-based parser. Therefore 
the F1-measure for the later is higher than that for the for-
mer. 
3 SVM-LIGHT-TK. http://dit.unitn.it/~moschitt/ 
Figure 2: Semantic sub-tree for nominal predicate
RMB 
?? 
loan 
?? 1 
provide 
??? 1 
4 billion 
VV1 
NN1 NN 
NPQP1 
NP
VP 
g1 ?. g5
1285
 problem in argument classification, we apply the 
one vs. others strategy, which builds K classifi-
ers so as to separate one class from all others. 
For argument identification and classification, 
we adopt the linear kernel and the training pa-
rameter C is fine-tuned to 0.220. For automatic 
recognition of nominal predicates, the training 
parameter C and the decay factor ?  in the con-
volution tree kernel are fine-tuned to 2.0 and 0.2, 
respectively. 
6.2. Results with Golden Parse Trees and 
Golden Nominal Predicates 
Effect of nominal SRL-specific features 
 
 Rec.(%) Pre.(%) F1 
traditional features 62.83 73.58 67.78 
+nominal SRL-specific  
features 
69.90 75.11 72.55 
Table 5: The performance of nominal SRL on the 
development data with golden parse trees and golden 
nominal predicates 
After performing the greedy feature selection 
algorithm on the development data, features 
{ao1, ai6, ai2P, ai5, ao2, ao12, ao14}, as pro-
posed in Section 3.2, are selected consecutively 
for argument identification, while features {ai7, 
ao1, ai1, ao2, ai5, ao4} are selected for argument 
classification. Table 5 presents the SRL results 
on the development data. It shows that nominal 
SRL-specific features significantly improve the 
performance from 67.78 to 72.55 ( ) 
in F1-measure. 
05.0;2 <p?
Effect of features derived from verbal SRL 
 
Features Rec.(%) Pre.(%) F1 
baseline 67.86 73.63 70.63  
+ao5 68.15 73.60 70.77 (+0.14)
+ao6 67.66 72.80 70.14 (-0.49)
+ao7 68.20 75.41 71.62 (+0.99)
+ao8 68.30 75.39 71.67 (+1.04)
+p1 67.91 74.40 71.00 (+0.37)
+p2 67.76 74.20 70.83 (+0.20)
+p3 67.96 74.69 71.16 (+0.53)
+p4 68.01 74.18 70.96 (+0.33)
+p5 68.01 75.01 71.39 (+0.76)
+p6 68.20 75.12 71.49 (+0.86)
+p7 68.40 75.70 71.87 (+1.24)
Table 6: Effect of features derived from verbal SRL 
on the performance of nominal SRL on the test data 
with golden parse trees and golden nominal predi-
cates. The first row presents the performance using 
traditional and nominal SRL-specific features. 
 
 
 Rec.(%) Pre.(%) F1 
baseline  67.86 73.63 70.63 
+features derived 
from verbal SRL
68.40 77.51 72.67 
Xue (2008) 66.1 73.4 69.6 
Table 7: The performance of nominal SRL on the test 
data with golden parse trees and golden nominal 
predicates 
 
Table 6 shows the effect of features derived 
from verbal SRL in an incremental way. It 
shows that only the feature ao6 has negative ef-
fect due to its strong relevance with intervening 
verbs and thus not included thereafter. Table 7 
shows the performance on the test data with or 
without using the features derived from the ver-
bal SRL system. It shows these features signifi-
cantly improve the performance ( ) 
on nominal SRL. Table 7 also shows our system 
outperforms Xue (2008) by 3.1 in F1-measure. 
05.0;2 <p?
6.3. Results with Automatic Parse Trees 
and Golden Nominal Predicates 
In previous section we have assumed the avail-
ability of golden parse trees during the testing 
process. Here we conduct experiments on auto-
matic parse trees, using the Berkeley parser. 
Since arguments come from constituents in 
parse trees, those arguments, which do not align 
with any syntactic constituents, are simply dis-
carded. Moreover, for any nominal predicate 
segmented incorrectly by the word segmenter, 
all its arguments are unable to be labeled neither. 
Table 8 presents the SRL performance on the 
test data by using automatic parse trees. It shows 
that the performance drops from 72.67 to 60.87 
in F1-measure when replacing golden parse trees 
with word-based automatic ones, partly due to 
the absence of 6.9% arguments in automatic 
trees, and wrong POS tagging of nominal predi-
cates. Table 8 also compares our system with 
Xue (2008). It shows that our system also out-
performs Xue (2008) on Chinese NomBank. 
 Rec. (%) Pre. (%) F1 
This paper 56.95(53.55) 66.74(66.69) 60.87(59.40)
Xue (2008) 53.1 (52.9) 62.9 (62.3) 57.6 (57.3) 
Table 8: The performance of nominal SRL on the test 
data with automatic parse trees and golden predicates. 
Here, the numbers outside the parentheses indicate 
the performance using a word-based parser, while the 
numbers inside indicate the performance using a 
character-based parser4. 
                                                          
4 About 1.6% nominal predicates are mistakenly segmented 
by the character-based parser, thus their arguments are 
missed directly. 
1286
 6.4. Results with Automatic Nominal Predi-
cates 
So far nominal predicates are assumed to be 
manually annotated and available. Here we turn 
to a more realistic scenario in which both the 
parse tree and nominal predicates are automati-
cally obtained. In the following, we first report 
the results of automatic nominal predicate rec-
ognition and then the results of nominal SRL on 
automatic recognition of nominal predicates. 
Results of nominal predicate recognition 
Parses g1-g5 Rec.(%) Pre.(%) F1 
no 91.46 88.93 90.18 golden 
yes 92.62 89.36 90.96 
word-based yes 86.39 81.80 84.03 
character-based yes 84.79 81.94 83.34 
Table 9: The performance of automatic nominal 
predicate recognition on the test data 
 
Table 9 lists the predicate recognition results, 
using the parse tree structure, as shown in Sec-
tion 5, and the convolution tree kernel, as pro-
posed in Collins and Duffy (2001). The second 
column (g1-g5) indicates whether the global fea-
tures (g1-g5) are included in the parse tree struc-
ture. We have also defined a simple rule that 
treats a noun which is ever a verb or a nominal 
predicate in the training data as a nominal predi-
cate. Based on golden parse trees, the rule re-
ceives the performance of 81.40 in F1-measure. 
This suggests that our method significantly out-
performs the simple rule-based one. Table 9 also 
shows that: 
z As a complement to local structural informa-
tion, global features improve the performance 
of automatic nominal predicate recognition 
by 0.78 in F1-measure. 
z The word-based syntactic parser decreases 
the F1-measure from 90.96 to 84.03, mostly 
due to the POSTagging errors between NN 
and VV, while the character-based syntactic 
parser further drops the F1-measure by 0.69, 
due to automatic word segmentation. 
Results with automatic predicates 
 
Parses Predicates Rec.(%) Pre.(%) F1 
golden 68.40 77.51 72.67 golden 
automatic 65.07 74.65 69.53 
golden 55.95 66.74 60.87 word-
based automatic 52.67 59.56 55.90 
golden 53.55 66.69 59.40 character-
based automatic 50.66 59.60 54.77 
Table 10: The performance of nominal SRL on the 
test data with the choices of golden/automatic parse 
trees and golden/automatic predicates 
In order to have a clear performance comparison 
among nominal SRL on golden/automatic parse 
trees and golden/automatic predicates, Table 10 
lists all the results in those scenarios. 
6.5. Comparison 
Chinese nominal SRL vs. Chinese verbal SRL 
Comparison with Xue (2008) shows that the per-
formance of Chinese nominal SRL is about 20 
lower (e.g. 72.67 vs. 92.38 in F1-measure) than 
that of Chinese verbal SRL, partly due to the 
smaller amount of annotated data (about 1/5) in 
Chinese NomBank than that in Chinese Prop-
Bank. Moreover, according to Chinese Nom-
Bank annotation criteria (Xue 2006a), even 
when a noun is a true deverbal noun, not all of 
its modifiers are legitimate arguments or ad-
juncts of this predicate. Only arguments that can 
co-occur with both the nominal and verbal forms 
of the predicate are considered in the NomBank 
annotation. This means that the judgment of ar-
guments is semantic rather than syntactic. These 
facts may also partly explain the lower nominal 
SRL performance, especially the performance of 
argument identification. This can be illustrated 
by the statistics on the development data that 
96% (40%) of verbal (nominal) predicates? sis-
ters are annotated as arguments. Finally, the 
predicate-argument structure of nominal predi-
cates is more flexible and complicated than that 
of verbal predicates as illustrated in Xue (2006a). 
Chinese nominal SRL vs. English nominal 
SRL 
Liu and Ng (2007) reported the performance of 
77.04 and 72.83 in F1-measure on English Nom-
Bank when golden and automatic parse trees are 
used, respectively. Taking into account that Chi-
nese verbal SRL achieves comparable perform-
ance with English verbal SRL on golden parse 
trees, the performance gap between Chinese and 
English nominal SRL (e.g. 72.67 vs. 77.04 in 
F1-measure) presents great challenge for Chi-
nese nominal SRL. Moreover, while automatic 
parse trees only decrease the performance of 
English nominal SRL by about 4.2 in F1-
measure, automatic parse trees significantly de-
crease the performance of Chinese nominal SRL 
by more than 12 in F1-measure due to the much 
lower performance of Chinese syntactic parsing. 
7. Conclusion 
In this paper we investigate nominal SRL in 
Chinese language. In particular, some nominal 
SRL-specific features are included to improve 
1287
 the performance. Moreover, various features 
derived from verbal SRL are properly integrated 
into nominal SRL. Finally, a convolution tree 
kernel is adopted to address the issue of auto-
matic nominal predicates recognition, which is 
essential in a nominal SRL system.  
To our best knowledge, this is the first re-
search on 
1) Exploring Chinese nominal SRL on auto-
matic parse trees with automatic predicate 
recognition; 
2) Successfully integrating features derived 
from Chinese verbal SRL into Chinese nomi-
nal SRL with much performance improve-
ment. 
Acknowledgement  
This research was supported by Project 
60673041 and 60873150 under the National 
Natural Science Foundation of  China, Project 
2006AA01Z147 under the  ?863? National 
High-Tech Research and Development of China, 
and Project BK2008160 under the Natural Sci-
ence Foundation of the Jiangsu province of 
China. We also want to thank Dr. Nianwen Xue 
for share of the verb class file. We also want to 
thank the reviewers for insightful comments. 
References  
Collin F. Baker, Charles J. Fillmore, and John B. 
Lowe. 1998. The Berkeley FrameNet Project. In 
Proceedings of COLING-ACL 1998. 
Xavier Carreras and Lluis M?rquez. 2004. Introduc-
tion to the CoNLL-2004 Shared Task: Semantic 
Role Labeling. In Proceedings of CoNLL 2004.  
Xavier Carreras and Lluis M?rquez. 2005. Introduc-
tion to the CoNLL-2005 Shared Task: Semantic 
Role Labeling. In Proceedings of CoNLL 2005.  
Michael Collins and Nigel Duffy. 2001. Convolution 
Kernels for Natural Language. In Proceedings of 
NIPS 2001.  
Weiwei Ding and Baobao Chang. 2008. Improving 
Chinese Semantic Role Classification with Hierar-
chical Feature Selection Strategy. In Proceedings 
of EMNLP 2008. 
Zheng Ping Jiang and Hwee Tou Ng. 2006. Semantic 
role Labeling of NomBank: a Maximum Entropy 
Approach. In Proceedings of EMNLP 2006.  
Chang Liu and Hwee Tou Ng. 2007. Learning Predic-
tive Structures for Semantic Role Labeling of 
NomBank. In Proceedings of ACL 2007. 
A. Meyers, R. Reeves, C. Macleod, R. Szekely, V. 
Zielinska, B. Yong, and R. Grishman. 2004. Anno-
tating Noun Argument Structure for NomBank. In 
Proceedings of LREC 2004.  
Alessandro Moschitti. 2004. A Study on Convolution 
Kernels for Shallow Semantic Parsing. In Pro-
ceedings of ACL 2004. 
Srini Narayanan and Sanda Harabagiu. 2004. Ques-
tion Answering based on Semantic Structures. In 
Proceedings of COLING 2004.  
Hwee Tou Ng and Jin Kiat Low. 2004. Chinese Part-
of-speech Tagging: One-at-a-time or All-at-once? 
Word-based or Character-based? In Proceedings 
of EMNLP 2004. 
Martha Palmer, Daniel Gildea, and Paul Kingsbury. 
2005. The Proposition Bank: An Annotated Cor-
pus of Semantic Roles. Computational Linguistics. 
Slav Petrov. and Dan Klein. 2007. Improved Infer-
ence for Unlexicalized Parsing. In Proceesings of 
NAACL 2007.  
Simone Paolo Ponzetto and Michael Strube. 2006. 
Semantic Role Labeling for Coreference Resolu-
tion. In Proceedings of EACL 2006. 
Sameer Pradhan, Honglin Sun, Wayne Ward, James 
H. Martin, and Dan Jurafsky. 2004. Parsing Ar-
guments of Nominalizations in English and Chi-
nese. In Proceedings of NAACL-HLT 2004.  
Honglin Sun and Daniel Jurafsky. 2004. Shallow 
Semantic Parsing of Chinese. In Proceedings of 
NAACL 2004.  
Mihai Surdeanu, Sanda Harabagiu, John Williams 
and Paul Aarseth. 2003. Using Predicate-argument 
Structures for Information Extraction. In Proceed-
ings of ACL 2003. 
Mihai Surdeanu, Richard Johansson, Adam Meyers, 
Lluis M?rquez, and Joakim Nivre. 2008. The 
CoNLL-2008 Shared Task on Joint Parsing of 
Syntactic and Semantic Dependencies. In Pro-
ceedings of CoNLL 2008. 
Nianwen Xue and Martha Palmer. 2003. Annotating 
the Propositions in the Penn Chinese TreeBank. In 
Proceedings of 2nd SIGHAN Workshop on Chinese 
Language Processing.  
Nianwen Xue and Martha Palmer. 2005. Automatic 
Semantic Role Labeling for Chinese verbs. In 
Proceedings of IJCAI 2005.  
Nianwen Xue. 2006a. Annotating the Predicate-
Argument Structure of Chinese Nominalizations. 
In Proceedings of the LREC 2006. 
Nianwen Xue. 2006b. Semantic Role Labeling of 
Nominalized Predicates in Chinese. In Proceed-
ings of HLT-NAACL 2006. 
Nianwen Xue. 2008. Labeling Chinese Predicates 
with Semantic Roles. Computational Linguistics, 
34(2):225-255. 
1288
