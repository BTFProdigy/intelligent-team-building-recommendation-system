Proceedings of the 7th Workshop on Asian Language Resources, ACL-IJCNLP 2009, pages 96?102,
Suntec, Singapore, 6-7 August 2009. c?2009 ACL and AFNLP
A Syntactic Resource for Thai: CG Treebank
Taneth Ruangrajitpakorn      Kanokorn Trakultaweekoon      Thepchai Supnithi
Human Language Technology Laboratory
National Electronics and Computer Technology Center
112 Thailand Science Park, Phahonyothin Road, Klong 1, 
Klong Luang Pathumthani, 12120, Thailand
 +66-2-564-6900 Ext.2547, Fax.: +66-2-564-6772
{taneth.ruangrajitpakorn, kanokorn.trakultaweekoon, thep-
chai.supnithi}@nectec.or.th
Abstract
This  paper  presents  Thai  syntactic  re-
source:  Thai  CG treebank,  a  categorial 
approach  of  language  resources.  Since 
there  are  very  few  Thai  syntactic  re-
sources,  we designed to create treebank 
based on CG formalism. Thai corpus was 
parsed  with  existing  CG  syntactic  dic-
tionary  and  LALR  parser.  The  correct 
parsed trees were collected as prelimin-
ary  CG  treebank.  It  consists  of  50,346 
trees  from 27,239 utterances.  Trees  can 
be  split  into  three  grammatical  types. 
There are 12,876 sentential trees, 13,728 
noun  phrasal  trees,  and  18,342  verb 
phrasal trees. There are 17,847 utterances 
that obtain one tree, and an average tree 
per an utterance is 1.85.
1 Introduction
Syntactic lexical resources such as POS tagged 
corpus and treebank play one of  the  important 
roles in NLP tools for instance machine transla-
tion (MT), automatic POS tagger, and statistical 
parser. Because of a load burden and lacking lin-
guistic expertise to manually assign syntactic an-
notation to sentence, we are currently limited to a 
few  syntactical  resources.  There  are  few  re-
searches  (Satayamas  and  Kawtrakul,  2004)  fo-
cused  on  developing  system to  build  treebank. 
Unfortunately,  there is  no further report on the 
existing treebank in Thai  so far.  Especially for 
Thai,  Thai  belongs  to  analytic  language  which 
means  grammatical  information  relying  in  a 
word  rather  than  inflection  (Richard,  1964). 
Function words represent grammatical  informa-
tion such as tense, aspect, modal, etc. Therefore, 
to recognise word order is a key to syntactic ana-
lysis  for  Thai.  Categorial  Grammar  (CG)  is  a 
formalism which focuses on principle of syntact-
ic behaviour. It can be applied to solve word or-
der  issues  in  Thai.  To  apply  CG  for  machine 
learning and statistical based approach,  CG tree-
bank, is initially required.
CG is a based concept that can be applied to 
advance  grammar  such  as  Combinatory  Cat-
egorial  Grammar  (CCG)  (Steedman,  2000). 
Moreover,  CCG is  proved  to  be  superior  than 
POS for CCG tag consisting of fine grained lex-
ical  categories and its  accuracy rate (Curran et 
al., 2006; Clark and Curran, 2007). 
Nowadays,  CG and CCG become popular in 
NLP researches. There are several researches us-
ing them as a main theoretical approach in Asia. 
For example, there is a research in China using 
CG with Type Lifting (Dowty, 1988) to find fea-
tures interpretations of undefined words as syn-
tactic-semantic  analysis  (Jiangsheng,  2000).  In 
Japan,  researchers  also works  on Japanese cat-
egorial grammar (JCG) which gives a foundation 
of  semantic  parsing  of  Japanese  (Komatsu, 
1999). Moreover, there is a research in Japan to 
improve CG for solving Japanese particle shift-
ing phenomenon and using CG to focus on Ja-
panese particle (Nishiguchi, 2008).
This paper is organised as follows. Section 2 
reviews  categorial  grammar  and  its  function. 
Section  3  explains  resources  for  building  Thai 
CG treebank. Section 4 describes experiment res-
ult. Section 5 discusses issues of Thai CG tree-
bank. Last, Section 6 summarises paper and lists 
up future work.
96
2 Categorial Grammar
Categorial  grammar  (Aka.  CG or  classical  cat-
egorial  grammar)  (Ajdukiewicz,  1935;  Car-
penter,  1992;  Buszkowski,  1998;  Steedman, 
2000) is a formalism in natural language syntax 
motivated  by  the  principle  of  constitutionality 
and  organised  according  to  the  syntactic  ele-
ments. The syntactic elements are categorised in 
terms of their ability to combine with one anoth-
er to form larger constituents as functions or ac-
cording to a function-argument relationship. All 
syntactic categories in CG are distinguished by a 
syntactic category identifying them as one of the 
following two types: 
1. Argument: this type is a basic category, 
such  as  s  (sentence)  and  np  (noun 
phrase).
2. Functor  (or  functor  category):  this  cat-
egory type is a combination of argument 
and  operator(s)  '/'  and  '\'.  Functor  is 
marked to a complex lexicon to assist ar-
gument   to  complete  sentence  such  as 
s\np  (intransitive  verb)  requires  noun 
phrase from the left  side to complete a 
sentence.
CG captures the same information by associat-
ing a functional type or category with all gram-
matical entities. The notation ?/? is a rightward-
combining  functor  over  a  domain  of  ?  into  a 
range of ?. The notation ?\? is a leftward-com-
bining functor over ? into ?. ? and ? are both ar-
gument  syntactic  categories  (Hockenmaier  and 
Steedman,  2002;  Baldridge  and  Kruijff,  2003). 
The basic concept is to find the core of the com-
bination  and  replace  the  grammatical  modifier 
and complement with set of categories based on 
the same concept with fractions. For example, in-
transitive verb is needed to combine with a sub-
ject to complete a sentence therefore intransitive 
verb is written as s\np which means it  needs a 
noun phrase from the left side to complete a sen-
tence. If there is a noun phrase exists on the left 
side, the rule of fraction cancellation is applied 
as np*s\np = s. With CG, each lexicon can be an-
notated  with  its  own  syntactic  category. 
However,  a  lexicon could have more  than one 
syntactic category if it is able to be used in dif-
ferent appearances.
Furthermore,  CG  does  not  only  construct  a 
purely  syntactic  structure  but  also  delivers  a 
compositional  interpretation.  The  identification 
of derivation with interpretation becomes an ad-
vantage over others.
Example of CG derivation of Thai sentence is 
illustrated in Figure 1.
Recently,  there are many researches on com-
binatory categorial grammar (CCG) which is an 
improved  version  of  CG.  With  the  CG  based 
concept and notation, it is possible to easily up-
grade  it  to  advance  formalism.  However,  Thai 
syntax still remains unclear since there are sever-
al points on Thai grammar that are yet not com-
pletely  researched  and  found  absolute  solvent 
(Ruangrajitpakorn et al, 2007). Therefore, CG is 
currently set for Thai to significantly reduce over 
generation rate of complex composition or am-
biguate usage.
Figure 1. CG derivation tree of Thai sentence
3 Resources
To collect CG treebank, CG dictionary and pars-
er  are  essentially required.  Firstly,  Thai  corpus 
was parsed with the parser using CG dictionary 
as a syntactic resource. Then, the correct trees of 
each sentence were manually determined by lin-
guists and collected together as treebank.
3.1 Thai CG Dictionary
Recently, we developed Thai CG dictionary to be 
a syntactic dictionary for several purposes since 
CG is new to Thai NLP. CG was adopted to our 
syntactic  dictionary because  of  its  focusing  on 
lexicon's behaviour and its fine grained lexical-
ised  grammar.  CG is  proper  to  nature  of  Thai 
language since Thai belongs to analytic language 
typology; that is, its syntax and meaning depend 
on  the  use  of  particles  and word orders  rather 
than inflection (Boonkwan, and Supnithi, 2008). 
Moreover,  pronouns  and other  grammatical  in-
formation, such as tenses, aspects, numbers, and 
voices, are expressed by function words such as 
97
determiners, auxiliary verbs, adverbs and adject-
ives, which are in fix word order. With CG, it is 
possible  to  well  capture  Thai  grammatical  in-
formation. Currently we only aim to improve an 
accuracy of Thai syntax parsing since it still re-
mains unresearched ambiguities in Thai syntax. 
A list of grammatical Thai word orders which are 
handled with CG is shown in Table 1.
Thai 
utilisation Word-order 
Sentence - Subject + Verb + (Object)1 [rigid order]
Compound 
noun - Core noun + Attachment
Adjective 
modification - Noun + Adjective2
Predicate Ad-
jective - Noun + Adjective3
Determiner - Noun + (Classifier) + Determiner
Numeral ex-
pression
- Noun + (Modifier) + Number + Classifier + 
(Modifier)
Adverb 
modification
- Sentence + Adverb
- Adverb + Sentence 
Several aux-
iliary verbs  - Subject + (Aux verbs) + VP + (Aux verbs)
Negation
- Subject + Negator + VP
- Subject + (Aux verb) + Negator + (Aux verb) + 
VP
- Subject + VP + (Aux verb) + Negator + (Aux 
verb) 
Passive - Actee + Passive marker + (Actor) + Verb
Ditransitive  - Subject + Ditransitive verb + Direct object + In-direct  object
Relative 
clause - Noun + Relative marker + Clause
Compound 
sentence
- Sentence + Conjunction + Sentence
- Conjunction + Sentence +  Sentence
Complex 
sentence
- Sentence + Conjunction + Sentence
- Conjunction + Sentence +  Sentence
Subordinate 
clause that 
begins with 
word ? ????
- Subject + Verb + ? ?  ??? + Sentence
Table 1. Thai word orders that CG can solve
1 Information in parentheses is able to be omitted.
2 Adjective modification is a form of an adjective per-
forms as a modifier to a  noun, and they combine as a 
noun phrase.
3 Predicate adjective is a form of an adjective acts as a 
predicate of a sentence.
In addition, there are many multi-sense words 
in Thai. These words have the same surface form 
but  they have different  meanings  and  different 
usages. This issue can be solved with CG formal-
ism. The different usages are separated because 
the annotation of syntactic information. For ex-
ample,  Thai  word  ? ? ???? /k???/  can  be  used  to 
refer to noun as an 'island' and it is marked as 
np, and this word can also be denoted an action 
which  means  'to  clink'  or  'to  attach'  and  it  is 
marked as s\np/np.
After observation Thai word usage, the list of 
CG  was  created  according  to  CG  theory  ex-
plained in Section 2.
Thai  argument  syntactic  categories  were  ini-
tially created.  For Thai  language,  six argument 
syntactic  categories  were  determined.  Thai  CG 
arguments  are  listed  with  definition  and  ex-
amples in Table 2. Additionally,  np,  num, and 
spnum are a Thai  CG arguments  that  can dir-
ectly tag to a word, but  other can not and they 
can only be used as a combination for other argu-
ment.
With  the  arguments,  other  type  of  word  are 
created as functor by combining the arguments 
together  following  its  behaviour  and  environ-
mental  requirements.  The  first  argument  in  a 
functor is a result of combination. There are only 
two main operators in CG which are slash '/' and 
backslash '\' before an argument. A slash '/' refers 
to  argument  requirement  from the  right,  and  a 
backslash '\' refers to argument requirement from 
the left.  For instance,  a transitive verb requires 
one np from the left and one np from the right to 
complete a sentence. Therefore, it can be written 
as  s\np/np in CG form. However, several Thai 
words have many functions even it has the same 
word sense. For example, Thai word ? ?   ???? /c??? ?/
(to believe) is capable to use as intransitive verb, 
transitive  verb,  and  verb  that  can  be  followed 
with subordinate clause. This word therefore has 
three  different  syntactic  categories.  Currently, 
there are 72 functors for Thai.
With an argument and a functor, each word in 
the word list is annotated with CG. This informa-
tion is  sufficient  for  parser  to analyse  an input 
sentence into a grammatical tree. In conclusion, 
CG dictionary presently contains 42,564 lexical 
entries with 75 CG syntactic categories. All Thai 
CG categories are shown in Appendix A.
98
Thai ar-
gument 
category
definition example
np a noun phrase ? ??? (elephant), ?? (I, me) 
num A both digit and word cardinal number
???? (one), 
2  (two)
spnum
a number which is suc-
ceeding to classifier in-
stead of proceeding clas-
sifier like ordinary num-
ber 
???  (one),  
?????  (one)4
pp a prepositional phrase ????   (in car),??????   (on table)
s a sentence
? ???????? ??? 
(elephant eats ba-
nana) 
ws
a specific category for 
Thai which is assigned 
to a sentence that begins 
with Thai word ??? (that : 
sub-ordinate clause 
marker).
* ????????????? 5
'that he will come 
late' 
Table 2. List of Thai CG arguments
3.2 Parser
Our implemented lookahead LR parser (LALR)
(Aho and Johnson, 1974; Knuth, 1965) was used 
as a tool to syntactically parse input from corpus. 
For  our  LALR  parser,  a  grammar  rule  is  not 
manually determined, but it is automatically pro-
duced by a any given syntactic notations aligned 
with lexicons in a dictionary therefore this LALR 
parser has a coverage including a CG formalism 
parsing. Furthermore, our LALR parser has po-
tential to parse a tree from sentence, noun phrase 
and verb phrase.  However,  the parser  does not 
only return the best first tree, but also all parsable 
trees  to  gather  all  ambiguous  trees  since  Thai 
language tends to be ambiguous because of lack-
ing explicit sentence and word boundary.
3.3 Tree Visualiser
To reduce load burden of linguist to seek for the 
correct tree among all  outputs,  we developed a 
tree visualiser. This tool was developed by using 
an open source library provided by  NLTK: The 
4 This spnum category has a different usage from other 
numerical use, e.g. ? ??[noun,'horse'] ?? [classifier] 
?????[spnum,'one'] 'lit: one horse'. This case is different 
from normal numerical usage, e.g. ? ??[noun,'horse'] ???? 
[num,'one'] ?? [classifier] 'lit: one horse'
5 This example is a part of a sentence ?????????????????
??? 'lit: I believe that he will come late'
Natural  Language Toolkit  (http://www.nltk.org/
Home; Bird and Loper, 2004).
A tree visualiser is a tool to transform a textual 
tree structure to graphic tree.  This tool reads a 
tree  marking  with  parentheses  form and  trans-
mutes it into graphic. This tool can transform all 
output types of tree including sentence tree, noun 
phrase tree, and verb phrase tree. For example, 
Thai  sentence   "|???|???|????|??? ?|???|??????|" 
/ka:n l?: s?? ? p?n ka:n p?a? con p?ai/  'lit: Tiger 
hunting  is  an  adventure'  was  parsed  to  a  tree 
shown in Figure 2. With a tree visualiser, the tree 
in Figure 2 was transformed to a graphic tree il-
lustrated in Figure 3.
4 Experiment Result
In the preliminary experiment, 27,239 Thai utter-
ances with a mix of sentences and phrases from a 
general domain corpus are tested. The input was 
word-segmented  by  JwordSeg  (http://www.su-
parsit.com/nlp-tools) and approved by  linguists. 
In the test corpus, the longest utterance contains 
seventeen words, and the shortest utterance con-
tains two words. 
    s
      (np
        (np/(s\np)[???] 
          s\np(
            (s\np)/np[???] 
            np[????]
          )
        ) 
        s\np(
          (s\np)/np[??? ?] 
          np(
            np/(s\np)[???] 
           s\np[????? ]
          )
        )
      ) 
Figure 2. An example of CG tree output
Figure 3.  An example of graphic tree
99
All trees are manually observed by linguists to 
evaluate accuracy of the parser.  The criteria of 
accuracy are:
? A tree is correct if sentence is success-
fully parsed and syntactically correct ac-
cording to Thai grammar.
? In case of syntactic ambiguity such as a 
usage of preposition or phrase and sen-
tence  ambiguity,  any  tree  following 
those ambiguity is acceptable and coun-
ted as correct.
The parser returns 50,346 trees from  27,239 
utterances  as  1.85  trees  per  input  in  average. 
There are 17,874 utterances that returns one tree. 
The outputs can be divided into three different 
output  types:   12,876  sentential  trees,  13,728 
noun phrasal trees, and 18,342 verb phrasal trees. 
From the parser output, tree amount collecting 
in the CG tree bank in details is shown in Table 
3.
Tree type Utterance 
amount
Tree 
amount
Average
Only S 8,184 12,798 1.56
Only NP 7,211 12,407 1.72
Only VP 8,006 11,339 1.42
Both NP 
and S
1,583 5,188 3.28
Both VP 
and S
1,725 6,816 3.95
Both NP 
and VP
397 1,140 2.87
S, NP, VP 133 658 4.95
Total 27,239 50,346 1.85
Table 3. Amount of tree categorised by a dif-
ferent kind of grammatical tree
5 Discussion
After  observation  of  our  result,  we  found  two 
main issues.
First, some Thai inputs were parsed into sever-
al correct outputs due to ambiguity of an input. 
The use  of  an adjective  can be parsed to  both 
noun phrase  and  sentence  since  Thai  adjective 
can be used either a noun modifier or predicate. 
For example, Thai input ?|?????|????|??|????|? /
d??k d??k sod sai bon sa? na:m/  can be literally 
translated as follows:
1. Children is cheerful on a playground.
2. Cheerful children on a playground 
For  this  problem,  we  decided  to  keep  both 
trees in our treebank since they are both gram-
matically correct.
Second, the next issue is a variety of syntactic 
usages of Thai word.  It is the fact that Thai has a 
narrow range of word's surface but a lot of poly-
symy words. The more the word in Thai is gener-
ally used, the more utilisation of word becomes 
varieties. With the several combination, there are 
more chances to generate trees in a wrong con-
ceptual meaning even they form a correct  syn-
tactic word order. For example, Thai noun phrase 
???????| ? ?????? /kam la? ma? ha: sa:n/ 'lit: great 
power' can automatically be parsed to three trees 
for a sentence, a noun phrase, and a verb phrase 
because of polysymy of the first word. The first 
word "?? ? ??" has two syntactic usages as a noun 
which  conceptually refers  to  power and a  pre-
auxiliary verb to imply progressive aspect.  The 
word "??????" is an adjective which can per-
form two options in Thai as noun modifier and 
predicate. These affect parser to result three trees 
as follows:
np: np(np[??????] np\np[??????])
s: s(np[????? ] s\np[??????])
vp: s\np((s\np)/(s\np)[??????] s\np[??????])
Even though all trees are syntactically correct, 
only  noun  phrasal  tree  is  fully  acceptable  in 
terms of semantic sense as great power. The oth-
er trees are awkward and out of certain meaning 
in Thai. Therefore, the only noun phrase tree is 
collected into our CG treebank for such case.
6 Conclusion and Future Work
This paper presents Thai CG treebank which is a 
language resource for developing Thai NLP ap-
plication. This treebank consists of  50,346 syn-
tactic trees  from 27,239 utterances  with CG tag 
and  composition. Trees  can  be  split  into  three 
grammatical  types.  There  are  12,876 sentential 
trees, 13,728 noun phrasal trees, and 18,342 verb 
phrasal  trees.  There  are  17,847  utterances  that 
obtain one tree, and an average tree per an utter-
ance is 1.85.
In  the  future,  we  plan  to  improve  Thai  CG 
treebank to Thai CCG treebank. We also plan to 
reduce a variety of trees by extending semantic 
feature  into  CG.  We  will  improve  our  LALR 
parser to be GLR and PGLR parser respectively 
to reduce a missing word and named entity prob-
lem.  Moreover,  we  will  develop  parallel  Thai-
English  treebank  by  adding  a  parallel  English 
treebank  aligned  with  Thai  since  parallel  tree-
bank is useful resource for learning to statistical 
100
machine translation. Furthermore, we will apply 
obtained CG treebank for automatic CG tagging 
development.
Reference
Alfred  V.  Aho,  and  Stephen  C.  Johnson.  1974  LR 
Parsing,  In  Proceedings  of  Computing  Surveys, 
Vol. 6, No. 2.
Bob Carpenter. 1992. ?Categorial Grammars, Lexical 
Rules,and the English Predicative?,  In  R. Levine, 
ed., Formal Grammar: Theory and Implementation. 
OUP.
David Dowty,  Type raising,  functional  composition, 
and non-constituent conjunction, In Richard Oehrle 
et al, ed., Categorial Grammars and Natural Lan-
guage Structures. D. Reidel, 1988.
Donald  E.  Knuth.  1965.  On the  translation  of  lan-
guages from left to right, Information and Control 
86.
Hisashi Komatsu. 1999. ?Japanese Categorial Gram-
mar Based on Term and Sentence?.  In Proceeding  
of The 13th Pacific Asia Conference on Language,  
Information and Computation, Taiwan.
James R.  Curran,  Stephen Clark,  and David Vadas. 
2006.  Multi-Tagging  for  Lexicalized-Grammar 
Parsing. In Proceedings of the Joint Conference of  
the  International  Committee  on  Computational  
Linguistics and the Association for Computational  
Linguistics (ACL), Paris, France.
Jason  Baldridge,  and  Geert-Jan.  M.  Kruijff.  2003. 
?Multimodal combinatory categorial grammar?. In 
Proceeding  of  10th  Conference  of  the  European  
Chapter of the ACL-2003, Budapest, Hungary.
Julia Hockenmaier, and Mark Steedman. 2002. ?Ac-
quiring  Compact  Lexicalized  Grammars  from  a 
Cleaner Treebank?.  In Proceeding of 3rd Interna-
tional  Conference  on  Language  Resources  and  
Evaluation (LREC-2002), Las Palmas, Spain.
JWordSeg,  word-segmentation  toolkit.  Available 
from: http://www.suparsit.com/nlp-tools), 2007.
Kazimierz Ajdukiewicz. 1935. Die Syntaktische Kon-
nexitat, Polish Logic.
Mark  Steedman.  2000.  The  Syntactic  Process,  The 
MIT Press, Cambridge Mass.
NLTK:  The  Natural  Language  Toolkit.  Available 
from: http://www.nltk.org/Home
Noss B. Richard. 1964. Thai Reference Grammar, U. 
S. Government Printing Office, Washington DC.
Prachya  Boonkwan,  and  Thepchai  Supnithi.  2008. 
Memory-inductive  categorial  grammar:  An  ap-
proach to gap resolution in analytic-language trans-
lation.  In  Proceeding  of  3rd  International  Joint  
Conference  on  Natural  Language  Processing  
(IJCNLP-2008), Hyderabad, India.
Stephen Clark and James R.  Curran.  2007. Formal-
ism-Independent Parser Evaluation with CCG and 
DepBank.  In  Proceedings  of  the  45th  Annual  
Meeting of the Association for Computational Lin-
guistics (ACL),  Prague, Czech Republic.
Steven G. Bird, and Edward Loper. 2004. NLTK: The 
Natural Language Toolkit, In Proceedings of 42nd 
Meeting of the Association for Computational Lin-
guistics (Demonstration Track), Barcelona, Spain.
Sumiyo  Nishiguchi.  2008.  Continuation-based  CCG 
of  Japanese  Quantifiers.  In  Proceeding  of  6th 
ICCS,  The Korean  Society of  Cognitive Science, 
Seoul, South Korea.
Taneth  Ruangrajitpakorn, Wasan.  na  Chai, Prachya 
Boonkwan,  Montika  Boriboon,  and  Thepchai. 
Supnithi. 2007. The Design of Lexical Information 
for Thai  to English MT,  In  Proceeding of  SNLP 
2007, Pattaya, Thailand.
Vee Satayamas, and Asanee Kawtrakul. 2004. Wide-
Coverage  Grammar  Extraction  from  Thai  Tree-
bank. In Proceedings of Papillon 2004 Workshops  
on  Multilingual  Lexical  Databases,  Grenoble, 
France.
Wojciech  Buszkowski, Witold Marciszewski, and Jo-
han van Benthem, ed.,  Categorial Grammar, John 
Benjamin, Amsterdam, 1998.
Yu Jiangsheng. 2000. Categorial Grammar based on 
Feature Structures, dissersion in In-stitute of Com-
putational Linguistics, Peking University.
101
Appendix A
Type CG Category Type CG Category Type CG Category
Conjoiner ws/s Verb (s\np)/ws Function word ((s\np)\(s\np))/(np\np)
Conjoiner ws/(s/np) Verb, Adjective (s\np)/pp Function word ((s\np)\(s\np))/((s\np)\(s\np))
Function word spnum Determiner (s\np)/num Verb ((s\np)/ws)/pp
Particle, Adverb s\s Verb, Adjective (s\np)/np Verb ((s\np)/ws)/np
Verb s\np/(s\np)/np
Function word, Verb, 
Adverb, Auxiliary verb (s\np)/(s\np)
Adverb, Auxiliary 
verb ((s\np)/pp)\((s\np)/pp)
Verb s\np Function word (s\np)/(np\np) Verb ((s\np)/pp)/np
Function word, Particle s/s Auxiliary verb (s\np)/((s\np)/np)
Function word, 
Adverb ((s\np)/pp)/((s\np)/pp)
Function word s/np Conjunction (s/s)/s Auxiliary verb ((s\np)/np)\((s\np)/np)
Auxiliary verb s/(s/np) Function word (s/s)/np Verb ((s\np)/np)/np
Sentence s Function word (s/s)/(s/np) Verb ((s\np)/np)/(s\np)
Conjoiner pp/s Classifier (np\np)\num Adverberb ((s\np)/(s\np))\((s\np)/(s\np))
Conjoiner pp/np
Function word, Adverb, 
Auxiliary verb (np\np)\(np\np) Function word ((np\np)\(np\np))/np
Conjoiner pp/(s\np) Classifier (np\np)/spnum Conjoiner ((np\np)\(np\np))/(np\np)
Function word num Function word (np\np)/s
Adverb, Auxiliary 
verb ((np\np)/pp)\((np\np)/pp)
Classifier np\num Determiner (np\np)/num
Adverb, Function 
word ((np\np)/pp)/((np\np)/pp)
Adjective np\np Adjective, Conjoiner (np\np)/np Auxiliary verb ((np\np)/np)\((np\np)/np)
Noun, Pronoun np/pp Function word (np\np)/(s\np) Conjoiner ((np/pp)\(np/pp))/(np/pp)
Adjective, Determiner np/np
Classifier, Function word, 
Adverb, Auxiliary verb (np\np)/(np\np) Verb (((s\np)\np)
Function word np/(s\np) Auxiliary verb (np\np)/((np\np)/np) Verb (((s\np)/ws)/pp)/np
Auxiliary verb np/(np/np) Adjective, Determiner (np/pp)\(np/pp) Conjoiner (((s\np)/pp)\((s\np)/pp))/((s\np)/pp)
Function word np/((s\np)/np) Determiner (np/pp)/(np/pp) Function word (((s\np)/pp)\((s\np)/pp))/(((s\np)/pp)\((s\np)/pp))
Noun, Pronoun np Classifier ((s\np)\(s\np))\num Verb (((s\np)/pp)/np)/np
Conjunction (s\s)/s Classifier ((s\np)\(s\np))/spnum Function word (((s\np)/pp)/np)/(((s\np)/pp)/np)
Adverb, Auxiliary verb (s\np)\(s\np)
Function word ((s\np)\(s\np))/np Verb (((s\np)/np)/(s\np))/pp
Conjoiner ((s\np)\(s\np))/(s\np) Conjoiner (((np\np)/pp)\((np\np)/pp))/((np\np)/pp)
102
Proceedings of the 8th Workshop on Asian Language Resources, pages 129?136,
Beijing, China, 21-22 August 2010. c?2010 Asian Federation for Natural Language Processing
A Supervised Learning based Chunking in Thai  
using Categorial Grammar 
Thepchai Supnithi, Peerachet Porkaew, 
Taneth Ruangrajitpakorn, Kanokorn 
Trakultaweekool 
Human Language Technology, 
National Electronics and Computer  
Technology Center 
{thepchai.sup, peera-
chet.por, taneth.rua, ka-
nokorn.tra}@nectec.or.th 
 
Chanon Onman, Asanee Kaw-
trakul  
Department of Computer Engineer-
ing, Kasetsart University and  
National Electronics and Computer  
Technology Center 
 
chanon.onman@gmail.com, 
asanee.kaw@nectec.or.th 
Abstract 
One of the challenging problems in Thai 
NLP is to manage a problem on a syn-
tactical analysis of a long sentence.  
This paper applies conditional random 
field and categorical grammar to devel-
op a chunking method, which can group 
words into larger unit. Based on the ex-
periment, we found the impressive re-
sults. We gain around 74.17% on sen-
tence level chunking. Furthermore we 
got a more correct parsed tree based on 
our technique. Around 50% of tree can 
be added. Finally, we solved the prob-
lem on implicit sentential NP which is 
one of the difficult Thai language pro-
cessing.  58.65% of sentential NP is cor-
rectly detected. 
1 Introduction 
Recently, many languages applied chunking, or 
shallow parsing, using supervised learning ap-
proaches. Basili (1999) utilized clause boundary 
recognition for shallow parsing. Osborne (2000) 
and McCallum et al (2000) applied Maximum 
Entropy tagger for chunking. Lafferty (2001) 
proposed Conditional Random Fields for se-
quence labeling. CRF can be recognized as a 
generative model that is able to reach global 
optimum while other sequential classifiers focus 
on making the best local decision. Sha and Pe-
reira (2003) compared CRF to other supervised 
learning in CoNLL task. They achieved results 
better than other approaches. Molina et al 
(2002) improved the accuracy of HMM-based 
shallow parser by introducing the specialized 
HMMs. 
In Thai language processing, many research-
es focus on fundamental level of NLP, such as 
word segmentation, POS tagging. For example, 
Kruengkrai et al (2006) introduced CRF for 
word segmentation and POS tagging trained 
over Orchid corpus (Sornlertlamvanich et al, 
1998.). However, the number of tagged texts in 
Orchid is specific on a technical report, which is 
difficult to be applied to other domains such as 
news, document, etc. Furthermore, very little 
researches on other fundamental tools, such as 
chunking, unknown word detection and parser, 
have been done. Pengphon et al (2002) ana-
lyzed chunks of noun phrase in Thai for infor-
mation retrieval task. All researches assume that 
sentence segmentation has been primarily done 
in corpus. Since Thai has no explicit sentence 
boundary, defining a concrete concept of sen-
tence break is extremely difficult. 
Most sentence segmentation researches con-
centrate on "space" and apply to Orchid corpus 
(Meknavin 1987, Pradit 2002). Because of am-
biguities on using space, the accuracy is not im-
pressive when we apply into a real application. 
Let consider the following paragraph which 
is a practical usage from news: 
129
"??????????????????????????????? ????????????????????????????????????
??????????????? | ?????????????????  | ??????????????????????????"  
lit: ?The red shirts have put bunkers around 
the assembly area and put oil and tires. The 
traffic is opened normally.? 
We found that three events are described in 
this paragraph. We found that both the first and 
second event do not contain a subject. The third 
event does not semantically relate to the previ-
ous two events. With a literal translation to Eng-
lish, the first and second can be combined into 
one sentence; however, the third events should 
be separated. 
As we survey in BEST corpus (Kosawat 
2009), a ten-million word Thai segmented cor-
pus. It contains twelve genres. The number of 
word in sentence is varied from one word to 
2,633 words and the average word per line is 
40.07 words. Considering to a News domain, 
which is the most practical usage in BEST, we 
found that the number of words are ranged from 
one to 415 words, and the average word length 
in sentence is 53.20. It is obvious that there is a 
heavy burden load for parser when these long 
texts are applied. 
Example 1:  
   ??                  ???                 ????????               ??                ???????????? ?
man(n) drive(v)   taxi(n)  find(v)   wallet(n) 
 
lit1: A man drove a taxi and found a wallet. 
lit2: A taxi chauffeur found a wallet. 
Example 2: 
   ???            ??          ????      ??????              ?????               ?????? 
should will must    can    develop(v) country(n) 
 
lit: possibly have to develop country. 
 
Figure 1. Examples of compounds in Thai 
Two issues are raised in this paper. The first 
question is "How to separate a long paragraph 
into a larger unit than word effectively?" We are 
looking at the possibility of combining words 
into a larger grain size. It enables the system to 
understand the complicate structure in Thai as 
explained in the example. Chunking approach in 
this paper is closely similar to the work of Sha 
and Pereira (2003). Second question is "How to 
analyze the compound noun structure in Thai?" 
Thai allows a compound construction for a noun 
and its structures can be either a sequence of 
nouns or a combination of nouns and verbs. The 
second structure is unique since the word order 
is as same as a word order of a sentence. We 
call this compound noun structure as a ?senten-
tial NP?. 
Let us exemplify some Thai examples related to 
compound word and serial construction problem 
in Figure 1. The example 1 shows a sentence 
which contains a combination of nouns and 
verbs. It can be ambiguously represented into 
two structures. The first alternative is that this 
sentence shows an evidence of a serial verb 
construction. The first word serves as a subject 
of the two following predicates. Another alter-
native is that the first three word can be formed 
together as a compound noun and they refer to 
?a taxi driver? which serve as a subject of the 
following verb and noun. The second alternative 
is more commonly used in practical language. 
However, to set the ?N V N? pattern as a noun 
can be very ambiguous since in the example 1 
can be formed a sentential NP from either the 
first three words or the last three words. 
From the Example 2, an auxiliary verb serial-
ization is represented. It is a combination of 
auxiliary verbs and verb. The word order is 
shown in Aux Aux Aux Aux V N sequence. 
The given examples show complex cases that 
require chunking to reduce an ambiguity while 
Thai text is applied into a syntactical analysis 
such as parsing. Moreover, there is more chance 
to get a syntactically incorrect result from either 
rule-based parser or statistical parser with a high 
amount of word per input. 
This paper is organized as follows. Section 2 
explains Thai categorial grammar. Section 3 
130
illustrates CRF, which is supervised method 
applied in this work.  Section 4 explains the 
methodology and experiment framework. Sec-
tion 5 shows experiments setting and result. 
Section 6 shows discussion. Conclusion and 
future work are illustrated in section 7. 
2 Linguistic Knowledge 
2.1 Categorial Grammar 
Categorial grammar (Aka. CG or classical cate-
gorial grammar) (Ajdukiewicz, 1935; Bar-
Hillel, 1953; Carpenter, 1992; Buszkowski, 
1998; Steedman, 2000) is formalism in natural 
language syntax motivated by the principle of 
constitutionality and organized according to the 
syntactic elements. The syntactic elements are 
categorised in terms of their ability to combine 
with one another to form larger constituents as 
functions or according to a function-argument 
relationship. All syntactic categories in CG are 
distinguished by a syntactic category identifying 
them as one of the following two types: 
1. Argument: this type is a basic category, 
such as s (sentence) and np (noun 
phrase).  
2. Functor (or function category): this cat-
egory type is a combination of argu-
ment and operator(s) '/' and '\'. Functor 
is marked to a complex constituent to 
assist argument to complete sentence 
such as s\np (intransitive verb) requires 
noun phrase from the left side to com-
plete a sentence. 
CG captures the same information by associ-
ating a functional type or category with all 
grammatical entities. The notation ?/? is a 
rightward-combining functor over a domain of ? 
into a range of ?. The notation ?\? is a leftward-
combining functor over ? into ?. ? and ? are 
both argument syntactic categories 
(Hockenmaier and Steedman, 2002; Baldridge 
and Kruijff, 2003). 
The basic concept is to find the core of the 
combination and replace the grammatical modi-
fier and complement with set of categories 
based on the same concept with fractions. For 
example, intransitive verb is needed to combine 
with a subject to complete a sentence therefore 
intransitive verb is written as s\np which means  
Figure 2 Example of Thai CG-parsed Tree. 
it needs a noun phrase from the left side to  
complete a sentence. If there is a noun phrase 
exists on the left side, the rule of fraction can-
cellation is applied as np*s\np = s. With CG, 
each constituent is annotated with its own syn-
tactic category as its function in text. Currently 
there are 79 categories in Thai. An example of 
CG derivation from Thai is shown in Figure 2.  
2.2 CG-Set 
CG-Set are used as a feature when no CG are 
tagged to the input. We aim to apply our chunk-
er to a real world application. Therefore, in case 
that we have only sentence without CG tags, we 
will use CG-Set instead.           
Cat-
Set 
Index 
Cat-Set Member 
0 np ????????? 
2 s\np/pp,s\np/np,s\np/pp/np,s\np ????, ???? 
3 
(np\np)/(np\np), 
((s\np)\(s\np))/spnum, 
np, 
(np\np)\num,np\num, 
(np\np)/spnum, 
((s\np)\(s\np))\num 
????, 
?????? 
62 (s\np)\(s\np),s\s ??'?, ??'?, ??? 
134 np/(s\np), 
np/((s\np)/np) ???, ???? 
Table 1 Example of CG-Set  
131
The concept of CG-Set is to group words that 
their all possible CGs are equivalent to the 
other. Therefore every word will be assigned to 
only one CG-Set. By using CG-Set we use the 
lookup table for tagging the input. Table 1 
shows examples of CG-set. Currently, there are 
183 CG set. 
3 Conditional Random Field (CRF) 
CRF is an undirected graph model in which 
each vertex represents a random variable whose 
distribution is to be inferred, and edge 
represents a dependency between two random 
variables. It is a supervised framework for 
labeling a sequence data such as POS tagging 
and chunking. Let X  is a random variable of 
observed input sequence, such as sequence of 
words, and Y is a random variable of label 
sequence corresponding to X , such as sequence 
of POS or CG. The most probable label 
sequence ( y? ) can be obtain by 
                     )|(maxarg? xypy =  
 Where nxxxx ,...,, 21= and nyyyy ,...,, 21=  
)|( xyp  is the conditional probability 
distribution of a label sequence given by an 
input sequence. CRF defines )|( xyp as 
                  ?
?
??
?
?= ?
=
n
i
ixyF
Z
xyP
1
),,(exp1)|(  
where ( )? ? == y ni ixyFZ 1 ),,(exp  is a 
normalization factor over all state sequences. 
),,( ixyF  is the global feature vector of CRF 
for sequence x and y at position i . ),,( ixyF  
can be calculated by using summation of local 
features. 
?? += ?
j
jj
i
iiii tyxgtyyfixyF ),,(),,(),,( 1 ??
Each local feature consists of transition feature 
function ),,( 1 tyyf iii ?  and per-state feature 
function ),,( tyxg j . Where i? and j? are 
weight vectors of transition feature function and 
per-state feature function respectively.  
The parameter of CRF can be calculated by 
maximizing the likelihood function on the 
training data. Viterbi algorithm is normally 
applied for searching the most suitable output. 
4 Methodology 
Figure 3 shows the methodology of our 
experiments. To prepare the training set, we 
start with our corpus annotated with CG tag. 
Then, each sentence in the corpus was parsed by 
Figure 3 Experimental Framework 
132
our Thai CG parser, developed by GLR tech-
technique. However, not all sentences can be 
parsed successfully due to the complexity of the 
sentence. We kept parsable sentences and 
unparsable sentences separately. The parsable 
sentences were selected to be the training set.  
There are four features ? surface, CG, CG-set 
and chunk marker ? in our experiments. CRF is 
applied using 5-fold cross validation over 
combination of these features. Accuracy in term 
of averaged precision and recall are reported. 
We select the best model from the experiment 
to implement the chunker. To investigate 
performance of the chunker, we feed the 
unparsable sentences to the chunker and 
evaluate them manually.  
After that, the sentences which are correctly 
chunked will be sent to our Thai CG parser. We 
calculate the number of successfully-parsed 
sentences and the number of correct chunks. 
5 Experiment Settings and Results 
5.1 Experiment on chunking 
5.1.1 Experiment setting 
To develop chunker, we apply CG Dictionary 
and CG tagged corpus as input. Four features 
are provided to CRF. Surface is a word surface. 
CG is a categorial grammar of the word. CG-set 
is a combination of CG of the word. IOB 
represents a method to mark chunk in a 
sentence. "I" means "inner" which represents 
the word within the chunk. "O" means "outside" 
which represents the word outside the chunk. 
"B" means "boundary" which represents the 
word as a boundary position. It accompanied 
with five chunk types. "NP" stands for noun 
phrase, "VP" stands for verb phrase, "PP" stands 
for preposition phrase, "ADVP" stands for 
adverb phrase and S-BAR stands for 
complementizer that link two phrases.  
Surface and CG-set are developed from CG 
dictionary. CG is retrieved from CG tagged 
corpus. IOB is developed by parsing tree. We 
apply Thai CG parser to obtain the parsed tree. 
Figure 4 shows an example of our prepared 
data. We provide 4,201 sentences as a training 
data in CRF to obtain a chunked model. In this 
experiment, we use 5-fold cross validation to 
evaluation the model in term of F-measure.  
surface cg_set cg chunk_label 
?? 74 s/s/np B-ADVP 
??? 3 np I-ADVP 
?? 180 (np\np)/(s\np) I-ADVP 
?? ? 54 (s\np)/(s\np) I-ADVP 
???? 7 s\np I-ADVP 
???? 130 ((s/s)\(s/s))/(s/s) I-ADVP 
?? 74 s/s/np I-ADVP 
??????? 0 np I-ADVP 
??? 0 np B-NP 
??? 8 s\np/np B-VP 
???'? 0 np B-NP 
?? 148 (s\np)/(s\np) B-VP 
???????? 2 s\np I-VP 
Figure 4 An example of prepared data 
 
Table 2 Chunking accuracy of each chunk 
133
  
5.1.2 Experiment result 
From Table 2, considering on chunk based lev-
el, we found that CG gives the best result 
among surface, CG-set, CG and their combina-
tion. The average on three types in terms of F-
measure is 86.20.  When we analyze infor-
mation in detail, we found that NP, VP and PP 
show the same results. Using CG shows the F-
measure for each of them, 81.15, 90.96 and 
99.56 respectively.   
From Table 3, considering in both word level 
and sentence level, we got the similar results, 
CG gives the best results. F-measure is 93.24 in 
word level and 74.17 in sentence level. This 
shows the evidence that CG plays an important 
role to improve the accuracy on chunking. 
5.2 Experiment on parsing 
5.2.1 Experiment setting 
We investigate the improvement of parsing con-
sidering unparsable sentences.  There are 14,885 
unparsable sentences from our CG parser. These 
sentences are inputted in chunked model to ob-
tain a chunked corpus. We manually evaluate 
the results by linguist. Linguists evaluate the 
chunked output in three types. 0 means incorrect 
chunk. 1 means correct chunk and 2 represents a 
special case for Thai NP, a sentential NP. 
5.2.2 Experiment result 
From the experiment, we got an impressive re-
sult. We found that 11,698 sentences (78.59%) 
are changed from unparsable to parsable sen-
tence. Only 3,187 (21.41%) are unparsable.  We 
manually evaluate the parsable sentence by ran-
domly select 7,369 sentences. Linguists found 
3,689 correct sentences (50.06%). In addition, 
we investigate the number of parsable chunk 
calculated from the parsable result and found 
37,743 correct chunks from 47,718 chunks 
(78.47%).  We also classified chunk into three 
types NN VP and PP and gain the accuracy in 
each type 79.14% ,74.66% and 92.57% respec-
tively. 
6 Discussion 
6.1 Error analysis 
From the experiment results, we found the fol-
lowing errors. 
6.1.1 Chunking Type missing 
Some chunk missing types are found in experi-
ment results. For example, [PP ?????? (rec-
ord)][NP ????????????????? (character about)]. [PP 
Table 3 Chunking accuracy based on  
word and sentence. 
Figure 4 An Example of sentential NP 
134
?????? (record)] should be defined as VP instead 
of PP. 
6.1.2 Over-grouping 
In the sentence ?[VP ?? ? (Using)][NP 
(medicine)][VP ????? (treat) ][NP ???????????' ?????
?????? (each disease have to)][PP ??? (follow) ]
[NP ???????????????? ?(doctor?s instruction)] ?, we 
found that ?NP ???????????' ??????????? (each disease 
have to) ? has over-grouping. IT is necessary to 
breakdown to NP ???????????' ?(each disease)  and  
VP ??????????(have to). The reason of this error is 
due to allow the sentential structure NP VP NP, 
and then NP and VP are combined. 
6.1.3 Sentential NP 
We investigated the number of sentential NP. If 
the number of chunk equal to 1, sentence should 
not be recognized as NP. Other cases are de-
fined as NP. We found that 929 from 1,584 sen-
tences (58.65 % of sentences) are correct sen-
tential NP. This evidence shows the impressive 
results to solve implicit NP in Thai. Figure 4 
shows an example of sentential NP.  
6.1.4 CG-set  
Since CG-set is another representation of word 
and can only detect from CG dictionary. It is 
very easy to develop a tag sequence using CG-
set. We found that CG-set is more powerful than 
surface. It might be another alternative for less 
language resource situation. 
6.2 The Effect of Linguistic Knowledge on 
chunking 
Since CG is formalism in natural language syn-
tax motivated by the principle of constitutionali-
ty and organised according to the syntactic ele-
ments, we would like to find out whether lin-
guistic knowledge effects to the model. We 
grouped 89 categorial grammars into 17 groups, 
called CG-17.  
It is categorized into Noun, Prep, Noun 
Modifier, Number modifier for noun, Number 
modifier for verb, Number, Clause Marker, 
Verb with no argument, Verb with 1 argument, 
Verb with 2 or more arguments, Prefix noun, 
Prefix predicate, Prefix predicate modifier, 
Noun linker, Predicate Modification, Predicate 
linker, and Sentence Modifier.  
We found that F-measure is slightly improved 
from 74.17% to 75.06%. This shows the evi-
dence that if we carefully categorized data based 
on linguistics viewpoint, it may improve more 
accuracy.  
7 Conclusions and Future Work 
In this paper, we stated Thai language problems 
on the long sentence pattern and find the novel 
method to chunk sentence into smaller unit, 
which larger than word. We concluded that us-
ing CRF accompanied with categorical grammar 
show the impressive results. The accuracy of 
chunking in sentence level is 74.17%. We are 
possible to collect 50% more on correct tree. 
This technique enables us to solve the implicit 
sentential NP problem. With our technique, we 
found 58% of implicit sentential NP. In the fu-
ture work, there are several issues to be im-
proved. First, we have to trade-off between 
over-grouping problem and implicit sentential 
problem. Second, we plan to consider ADVP, 
SBAR, which has a very small size of data. It is 
not adequate to train for a good result. Finally, 
we plan to apply more linguistics knowledge to 
assist more accuracy. 
References 
Abney S., and Tenny C., editors, 1991. Parsing 
by chunks, Priciple-based Parsing. Kluwer 
Academic Publishers. 
Awasthi P., Rao D., Ravindram B., 2006. Part 
of Speech Tagging and Chunking with HMM 
and CRF, Proceeding of the NLPAI Machine 
Learning Competition. 
Basili R., Pazienza T., and Massio F., 1999. 
Lexicalizing a shallow parser, Proceedings of 
135
Traitement Automatique du Langage Naturel 
1999. Corgese, Corsica. 
Charoenporn Thatsanee, Sornlertlamvanich Vi-
rach,  and Isahara Hitoshi. 1997. Building A 
Large Thai Text Corpus - Part-Of-Speech 
Tagged Corpus: ORCHID. Proceedings of 
Natural Language Processing Pacific Rim 
Symposium. 
Kosawat Krit, Boriboon Monthika, Chootrakool 
Patcharika, Chotimongkol Ananlada, Klaithin 
Supon, Kongyoung Sarawoot, Kriengket 
Kanyanut, Phaholphinyo Sitthaa, Puroda-
kananda Sumonmas,Thanakulwarapas 
Tipraporn, and Wutiwiwatchai Chai. 2009. 
BEST 2009: Thai Word Segmentation Soft-
ware Contest. The Eigth International Sym-
posium on Natural Language Processing  : 
83-88. 
Kruengkrai C., Sornlertlumvanich V., Isahara H, 
2006. A Conditional Random Field Frame-
work for Thai Morphological Analysis, Pro-
ceedings of 5th International Conference on 
Language Resources and Evaluation (LREC-
2006). 
Kudo T., and Matsumoto Y., 2001. Chunking 
with support vector machines, Proceeding of 
NAACL. 
Lafferty J., McCallum A., and Pereira F., 2001. 
Conditional Random Fields : Probabilistic 
models for segmenting and labeling sequence 
data. In Proceeding of ICML-01, 282-289. 
McCallum A., Freitag D., and Pereira F. 2000. 
Maximum entropy markov model for infor-
mation extraction and segmentation. Pro-
ceedings of ICML. 
Molina A., and Pla F., 2002. Shallow Parsing 
using Specialized HMMs, Journal of Machine 
Learning Research 2,595-613 
Nguyen L. Minh, Nguyen H. Thao, and Nguyen 
P., Thai. 2009. An Empirical Study of Viet-
namese Noun Phrase Chunking with Discrim-
inative Sequence Models, Proceedings of the 
7th Workshop on Asian Language Resources, 
ACL-IJCNLP 2009,9-16 
Osborne M. 2000. Shallow Parsing as Part-of-
Speech Tagging. Proceedings of CoNLL-
2000 and LLL-2000, Lisbon, Portugal. 
Pengphon N., Kawtrakul A., Suktarachan M., 
2002. Word Formation Approach to Noun 
Phrase Analysis for Thai,  Proceedings of 
SNLP2002. 
Sha F. and Pereira F., 2003. Shallow Parsing 
with Conditional Random Fields, Proceeding 
of HLT-NAACL. 
 
136
