Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 800?809, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational Linguistics
SSHLDA: A Semi-Supervised Hierarchical Topic Model
Xian-Ling Mao??, Zhao-Yan Ming?, Tat-Seng Chua?, Si Li?, Hongfei Yan??, Xiaoming Li?
?Department of Computer Science and Technology, Peking University, China
?School of Computing, National University of Singapore, Singapore
?School of ICE, Beijing University of Posts and Telecommunications, China
{xianlingmao,lxm}@pku.edu.cn, yhf@net.pku.edu.cn
{chuats,mingzhaoyan}@nus.edu.sg, lisi@bupt.edu.cn
Abstract
Supervised hierarchical topic modeling and
unsupervised hierarchical topic modeling are
usually used to obtain hierarchical topics, such
as hLLDA and hLDA. Supervised hierarchi-
cal topic modeling makes heavy use of the in-
formation from observed hierarchical labels,
but cannot explore new topics; while unsu-
pervised hierarchical topic modeling is able
to detect automatically new topics in the data
space, but does not make use of any informa-
tion from hierarchical labels. In this paper, we
propose a semi-supervised hierarchical topic
model which aims to explore new topics auto-
matically in the data space while incorporating
the information from observed hierarchical la-
bels into the modeling process, called Semi-
Supervised Hierarchical Latent Dirichlet Al-
location (SSHLDA). We also prove that hLDA
and hLLDA are special cases of SSHLDA.We
conduct experiments on Yahoo! Answers and
ODP datasets, and assess the performance in
terms of perplexity and clustering. The ex-
perimental results show that predictive ability
of SSHLDA is better than that of baselines,
and SSHLDA can also achieve significant im-
provement over baselines for clustering on the
FScore measure.
1 Introduction
Topic models, such as latent Dirichlet alation
(LDA), are useful NLP tools for the statistical anal-
ysis of document collections and other discrete data.
?This work was done in National University of Singapore.
?Corresponding author.
Furthermore, hierarchical topic modeling is able to
obtain the relations between topics ? parent-child
and sibling relations. Unsupervised hierarchical
topic modeling is able to detect automatically new
topics in the data space, such as hierarchical La-
tent Dirichlet Allocation (hLDA) (Blei et al2004).
hLDAmakes use of nested Dirichlet Process to auto-
matically obtain a L-level hierarchy of topics. Mod-
ern Web documents, however, are not merely col-
lections of words. They are usually documents with
hierarchical labels ? such as Web pages and their
placement in hierarchical directories (Ming et al
2010). Unsupervised hierarchical topic modeling
cannot make use of any information from hierarchi-
cal labels, thus supervised hierarchical topic models,
such as hierarchical Labeled Latent Dirichlet Allo-
cation (hLLDA) (Petinot et al2011), are proposed
to tackle this problem. hLLDA uses hierarchical la-
bels to automatically build corresponding topic for
each label, but it cannot find new latent topics in the
data space, only depending on hierarchy of labels.
As we know that only about 10% of an iceberg?s
mass is seen outside while about 90% of it is unseen,
deep down in water. We think that a corpus with hi-
erarchical labels should include not only observed
topics of labels, but also there are more latent top-
ics, just like icebergs. hLLDA can make use of the
information from labels; while hLDA can explore
latent topics. How can we combine the merits of the
two types of models into one model?
An intuitive and simple combinational method is
like this: first, we use hierarchy of labels as basic hi-
erarchy, called Base Tree (BT); then we use hLDA
to build automatically topic hierarchy for each leaf
800
node in BT, called Leaf Topic Hierarchy (LTH); fi-
nally, we add each LTH to corresponding leaf in the
BT and obtain a hierarchy for the entire dataset. We
refer the method as Simp-hLDA. The performance
of the Simp-hLDA is not so good, as can be seen
from the example in Figure 3 (b). The drawbacks
are: (i) the leaves in BT do not obtain reasonable
and right words distribution, such as ?Computers &
Internet? node in Figure 3 (b), its topical words, ?the
to you and a?, is not about ?Computers & Internet?;
(ii) the non-leaf nodes in BT cannot obtain words
distribution, such as ?Health? node in Figure 3 (b);
(iii) it is a heuristic method, and thus Simp-hLDA
has no solid theoretical basis.
To tackle the above drawbacks, we explore the
use of probabilistic models for such a task where
the hierarchical labels are merely viewed as a part
of a hierarchy of topics, and the topics of a path in
the whole hierarchy generate a corresponding doc-
ument. Our proposed generative model learns both
the latent topics of the underlying data and the la-
beling strategies in a joint model, by leveraging on
the hierarchical structure of labels and Hierarchical
Dirichlet Process.
We demonstrate the effectiveness of the proposed
model on large, real-world datasets in the question
answering and website category domains on two
tasks: the topic modeling of documents, and the use
of the generated topics for document clustering. Our
results show that our joint, semi-hierarchical model
outperforms the state-of-the-art supervised and un-
supervised hierarchical algorithms. The contribu-
tions of this paper are threefold: (1) We propose a
joint, generative semi-supervised hierarchical topic
model, i.e. Semi-Supervised Hierarchical Latent
Dirichlet Allocation (SSHLDA), to overcome the
defects of hLDA and hLLDA while combining the
their merits. SSHLDA is able to not only explore
new latent topics in the data space, but also makes
use of the information from the hierarchy of ob-
served labels; (2) We prove that hLDA and hLLDA
are special cases of SSHLDA; (3) We develop a
gibbs sampling inference algorithm for the proposed
model.
The remainder of this paper is organized as fol-
lows. We review related work in Section 2. In Sec-
tion 3, we introduce some preliminaries; while we
introduce SSHLDA in Section 4. Section 5 details
a gibbs sampling inference algorithm for SSHLDA;
while Section 6 presents the experimental results.
Finally, we conclude the paper and suggest direc-
tions for future research in Section 7.
2 Related Work
There have been many variations of topic mod-
els. The existing topic models can be divided
into four categories: Unsupervised non-hierarchical
topic models, Unsupervised hierarchical topic mod-
els, and their corresponding supervised counter-
parts.
Unsupervised non-hierarchical topic models are
widely studied, such as LSA (Deerwester et al
1990), pLSA (Hofmann, 1999), LDA (Blei et al
2003), Hierarchical-concept TM (Chemudugunta et
al., 2008c; Chemudugunta et al2008b), Corre-
lated TM (Blei and Lafferty, 2006) and Concept TM
(Chemudugunta et al2008a; Chemudugunta et al
2008b) etc. The most famous one is Latent Dirichlet
Allocation (LDA). LDA is similar to pLSA, except
that in LDA the topic distribution is assumed to have
a Dirichlet prior. LDA is a completely unsupervised
algorithm that models each document as a mixture
of topics. Another famous model that not only rep-
resents topic correlations, but also learns them, is
the Correlated Topic Model (CTM). Topics in CTM
are not independent; however it is noted that only
pairwise correlations are modeled, and the number
of parameters in the covariance matrix grows as the
square of the number of topics.
However, the above models cannot capture the
relation between super and sub topics. To address
this problem, many models have been proposed
to model the relations, such as Hierarchical LDA
(HLDA) (Blei et al2004), Hierarchical Dirichlet
processes (HDP) (Teh et al2006), Pachinko Allo-
cation Model (PAM) (Li and McCallum, 2006) and
Hierarchical PAM (HPAM) (Mimno et al2007)
etc. The relations are usually in the form of a hi-
erarchy, such as the tree or Directed Acyclic Graph
(DAG). Blei et al2004) proposed the hLDA model
that simultaneously learns the structure of a topic
hierarchy and the topics that are contained within
that hierarchy. This algorithm can be used to extract
topic hierarchies from large document collections.
Although unsupervised topic models are suffi-
801
ciently expressive to model multiple topics per doc-
ument, they are inappropriate for labeled corpora be-
cause they are unable to incorporate the observed la-
bels into their learning procedure. Several modifica-
tions of LDA to incorporate supervision have been
proposed in the literature. Two such models, Su-
pervised LDA (Blei and McAuliffe, 2007; Blei and
McAuliffe, 2010) and DiscLDA (Lacoste-Julien et
al., 2008) are first proposed to model documents as-
sociated only with a single label. Another category
of models, such as the MM-LDA (Ramage et al
2009b), Author TM (Rosen-Zvi et al2004), Flat-
LDA (Rubin et al2011), Prior-LDA (Rubin et al
2011), Dependency-LDA (Rubin et al2011) and
Partially LDA (PLDA) (Ramage et al2011) etc.,
are not constrained to one label per document be-
cause they model each document as a bag of words
with a bag of labels. However, these models obtain
topics that do not correspond directly with the la-
bels. Labeled LDA (LLDA) (Ramage et al2009a)
can be used to solve this problem.
None of these non-hierarchical supervised mod-
els, however, leverage on dependency structure,
such as parent-child relation, in the label space. For
hierarchical labeled data, there are also few models
that are able to handle the label relations in data.
To the best of our knowledge, only hLLDA (Petinot
et al2011) and HSLDA (Perotte et al2011) are
proposed for this kind of data. HSLDA cannot ob-
tain a probability distribution for a label. Although
hLLDA can obtain a distribution over words for each
label, hLLDA is unable to capture the relations be-
tween parent and child node using parameters, and it
also cannot detect automatically latent topics in the
data space. In this paper, we will propose a genera-
tive topic model to tackle these problems of hLLDA.
3 Preliminaries
The nested Chinese restaurant process (nCRP) is a
distribution over hierarchical partitions (Blei et al
2004). It generalizes the Chinese restaurant process
(CRP), which is a distribution over partitions. The
CRP can be described by the following metaphor.
Imagine a restaurant with an infinite number of ta-
bles, and imagine customers entering the restaurant
in sequence. The dth customer sits at a table accord-
Table 1: Notations used in the paper.
Sym Description
V Vocabulary (word set), w is a word in V
D Document collection
Tj
The set of paths in the sub-tree whose root is the
jth leaf node in the hierarchy of observed topics
m A document m that consists of words and labels
wm The text of document m, wi is ith words in w
cm The topic set of document m
com The set of topics with observed labels for document m
cem The set of topics without labels for document m
ce?m The set of latent topics for all documents other than m
zem
The assignment of the words in the mth document
to one of the latent topics
wem
The set of the words belonging to one of the latent
topics in the the mth document
zm,n
The assignment of the nth word in the mth document
to one of the L available topics
z The set of zm,n for all words in all documents
ci A topic in the ith level in the hierarchy
? The word distribution set for Z, i.e., {?}z?c
? Dirichlet prior of ?
?ci The multinomial distribution over the sub-topics of ci?1
?ci Dirichlet prior of ?ci
? Dirichlet prior of ?
? The multinomial distribution of words
?m The distributions over topics for document m
? The set for ?m, m ? {1, ..., D}
ing to the following distribution,
p(cd = k|c1:(d?1)) ?
{ mk if k is previous occupied
? if k is a new tabel, (1)
where mk is the number of previous customers sit-
ting at table k and ? is a positive scalar. AfterD cus-
tomers have sat down, their seating plan describes a
partition of D items.
In the nested CRP, imagine now that tables are or-
ganized in a hierarchy: there is one table at the first
level; it is associated with an infinite number of ta-
bles at the second level; each second-level table is
associated with an infinite number of tables at the
third level; and so on until the Lth level. Each cus-
tomer enters at the first level and comes out at the
Lth level, generating a path with L tables as she sits
in each restaurant. Moving from a table at level l to
one of its subtables at level l+1, the customer draws
following the CRP using Formula (1). In this paper,
we will make use of nested CRP to explore latent
topics in data space.
To elaborate our model, we first define two con-
cepts. If a model can learn a distribution over words
for a label, we refer the topic with a corresponding
label as a labeled topic. If a model can learn an un-
seen and latent topic without a label, we refer the
802
Figure 1: The graphical model of SSHLDA.
topic as a latent topic.
4 The Semi-Supervised Hierarchical Topic
Model
In this section, we will introduce a semi-
supervised hierarchical topic model, i.e., the Semi-
Supervised Hierarchical Latent Dirichlet Allocation
(SSHLDA). SSHLDA is a probabilistic graphical
model that describes a process for generating a hi-
erarchical labeled document collection. Like hi-
erarchical Labeled LDA (hLLDA) (Petinot et al
2011), SSHLDA can incorporate labeled topics into
the generative process of documents. On the other
hand, like hierarchical Latent Dirichlet Allocation
(hLDA) (Blei et al2004), SSHLDA can automat-
ically explore latent topic in data space, and extend
the existing hierarchy of observed topics. SSHLDA
makes use of not only observed topics, but also la-
tent topics.
The graphical model of SSHLDA is illustrated in
Figure 1. In the model, N is the number of words in
a document, D is the total number of documents in
a collection, M is the number of leaf nodes in hier-
archical observed nodes, ci is a node in the ith level
in the hierarchical tree, ?, ? and ?ci are dirichlet
prior parameters, ?k is a distribution over words, ?
is a document-specific distribution over topics, ?ci is
a multinomial distribution over observed sub-topics
of topic ci, w is an observed word, z is the topic
assigned to w, Dirk(.) is a k-dimensional Dirichlet
distribution, Tj is a set of paths in the hierarchy of
latent topics for jth leaf node in the hierarchy of ob-
Figure 2: One illustration of SSHLDA. The tree has 5
levels. The shaded nodes are observed topics, and circled
nodes are latent topics. The latent topics are generated
automatically by SSHLDA model. After learning, each
node in this tree will obtain a corresponding probability
distribution over words, i.e. a topic.
served topics, ? is a Multi-nomial distribution over
paths in the tree. All notations used in this paper are
listed in Table 1.
SSHLDA, as shown in Figure 1, assumes the fol-
lowing generative process:
(1) For each table k ? T in the infinite tree,
(a) Draw a topic ?k ? Dir(?).
(2) For each document, m ? {1, 2, ..., D}
(a) Let c1 be the root node.
(b) For each level l ? {2, ..., L}:
(i) If nodes in this level have been observed,
draw a node cl from Mult(?cl?1 |?cl?1).
(ii) Otherwise, draw a table cl from restaurant
cl?1 using Formula (1).
(c) Draw an L-dimensional topic proportion vec-
tor ?m from Dir(?).
(d) For each word n ? {1, ..., N}:
(i) Draw z ? {1, ..., L} from Mult(?).
(ii) Draw wn from the topic associated with
restaurant cz .
As the example showed in Figure 2, we assume
that we have known a hierarchy of observed top-
ics: {A1,A2,A17,A3,A4}, and assume the height
of the desired topical tree is L = 5. All circled
nodes are latent topics, and shaded nodes are ob-
served topics. A possible generative process for a
document m can be: It starts from A1, and chooses
node A17 at level 2, and then chooses A18, A20 and
A25 in the following levels. Thus we obtain a path:
cm = {A1, A17, A18, A20, A25}. After getting the
path for m, SSHLDA generates each word from one
of topics in this set of topics cm.
803
5 Probabilistic Inference
In this section, we describe a Gibbs sampling al-
gorithm for sampling from the posterior and corre-
sponding topics in the SSHLDA model. The Gibbs
sampler provides a method for simultaneously ex-
ploring the model parameter space (the latent topics
of the whole corpus) and the model structure space
(L-level trees).
In SSHLDA, we sample the paths cm for docu-
ment m and the per-word level allocations to topics
in those paths zm,n. Thus, we approximate the pos-
terior p(cm, zm|?, ?,w,?). The hyper-parameter ?
reflects the tendency of the customers in each restau-
rant to share tables, ? denotes the expected variance
of the underlying topics (e.g., ?  1 will tend to
choose topics with fewer high-probability words),
?ci is the dirichlet prior of ?ci , and ? is the set of
?ci . wm,n denotes the nth word in the mth docu-
ment; and cm,l represents the restaurant correspond-
ing to the lth-level topic in document m; and zm,n,
the assignment of the nth word in the mth document
to one of the L available topics. All other variables
in the model, ? and ?, are integrated out. The Gibbs
sampler thus assesses the values of zm,n and cm,l.
The Gibbs sampler can be divided into two main
steps: the sampling of level allocations and the sam-
pling of path assignments.
First, given the values of the SSHLDA hidden
variables, we sample the cm,l variables which are as-
sociated with the CRP prior. Noting that cm is com-
posed of com and cem , com is the set of observed
topics for document m, and cem is the set of latent
topics for document m. The conditional distribution
for cm, the L topics associated with documentm, is:
p(cm|z,w, c?m,?)
=p(com |?)p(cem |zem ,wem , ce?m)
?p(com |?)p(wem |cem ,we?m , zem)
p(cem |ce?m) (2)
where
p(com |?) =
|com |?1
?
i=0
p(ci,m|?ci) (3)
and
p(wem |cem ,we?m , zem)
=
|cem |
?
l=1
(
?(n.cem,l,?m + |V |?)
?
w ?(nwcem,l,?m + ?)
?
?
w ?(nwcem,l,?m + n
w
cem,l,m + ?)
?(n.cem,l,?m + n
?
cem,l,m + |V |?)
)
(4)
ce?m is the set of latent topics for all documents
other than m, zem is the assignment of the words
in the mth document to one of the latent topics, and
wem is the set of the words belonging to one of the
latent topics in the the mth document. nwcem,l,?m is
the number of instances of word w that have been
assigned to the topic indexed by cem,l, not including
those in the document m.
Second, given the current state of the SSHLDA,
we sample the zm,n variables of the underlying
SSHLDA model as follows:
p(zm,n = j|z?(m,n),w, cm,?)
?
nm?n,j + ?
nm?n,. + |cm|
?
nwm,n?n,j + ?wm,n
n.?(m,n) + |V |
(5)
Having obtained the full conditional distribution,
the Gibbs sampling algorithm is then straightfor-
ward. The zm,n variables are initialized to determine
the initial state of the Markov chain. The chain is
then run for a number of iterations, each time find-
ing a new state by sampling each zm,n from the dis-
tribution specified by Equation (5). After obtain-
ing individual word assignments z, we can estimate
the topic multinomials and the per-document mixing
proportions. Specifically, the topic multinomials are
estimated as:
?cm,j,i = p(wi|zcm,j) =
? + nzwicm,j
|V |? +
?
n.zcm,j
(6)
while the per-document mixing proportions fixed
can be estimated as:
?m,j =
?+ nm.,j
|cm|?+ nm.,.
, j ? 1, ..., |cm| (7)
5.1 Relation to Existing Models
In this section, we draw comparisons with the cur-
rent state-of-the-art models for hierarchical topic
804
modeling (Blei et al2004; Petinot et al2011) and
show that at certain choices of the parameters of our
model, these methods fall out as special cases.
Our method generalises not only hierarchi-
cal Latent Dirichlet Allocation (hLDA), but also
Hierarchical Labeled Latent Dirichlet Allocation
(hLLDA). Our proposed model provides a unified
framework allowing us to model hierarchical labels
while to explore new latent topics.
Equivalence to hLDA As introduced in Section 2,
hLDA is a unsupervised hierarchical topic model. In
this case, there are no observed nodes, that is, the
corpus has no hierarchical labels. This means cm is
equal to cem,m; meanwhile the factor p(com,m|?) is
always equal to one because each document has root
node, and this allows us to rewrite Formula (2) as:
p(cm|z,w, c?m,?)
?p(wcm |c,w?m, z)p(cm|c?m) (8)
which is exactly the same as the conditional distribu-
tion for cm, the L topics associated with document
m in hLDA model. In this case, our model becomes
equivalent to the hLDA model.
Equivalence to hLLDA hLLDA is a supervised hi-
erarchical topic model, which means all nodes in hi-
erarchy are observed. In this case, cm is equal to
com,m, and this allows us to rewrite Formula (2) as:
p(cm|z,w, c?m,?) = p(cm|?) ? p(com |?) (9)
which is exactly the same as the step ? Draw a
random path assignment cm? in the generative pro-
cess for hLLDA. Consequentially, in this sense our
model is equivalent to hLLDA.
6 Experiments
We demonstrate the effectiveness of the proposed
model on large, real-world datasets in the question
answering and website category domains on two
tasks: the topic modeling of documents, and the use
of the generated topics for document clustering.
6.1 Datasets
To construct comprehensive datasets for our ex-
periments, we crawled data from two websites.
First, we crawled nearly all the questions and as-
sociated answer pairs (QA pairs) of two top cat-
Table 2: The statistics of the datasets.
Datasets #labels #paths Max level #docs
Y Ans 46 35 4 6,345,786
O Hlth 6695 6505 10 54939
O Home 2432 2364 9 24254
egories of Yahoo! Answers: Computers & Inter-
net and Health. This produced forty-three sub-
categories from 2005.11 to 2008.11, and an archive
of 6,345,786 QA documents. We refer the Yahoo!
Answer data as Y Ans.
In addition, we first crawled two categories of
Open Directory Project (ODP)?: Home and Health.
Then, we removed all categories whose number of
Web sites is less than 3. Finally, for each of Web
sites in categories, we submited the url of each Web
site to Google and used the words in the snippet and
title of the first returned result to extend the sum-
mary of the Web site. We denote the data from the
category Home as O Home, and the data from the
category Health as O Hlth.
The statistics of all datasets are summarized in Ta-
ble 2. From this table, we can see that these datasets
are very diverse: Y Ans has much fewer labels than
O Hlth and O Home, but have much more docu-
ments for each label; meanwhile the depth of hierar-
chical tree for O Hlth and O Home can reach level
9 or above.
All experiments are based on the results of models
with a burn-in of 10000 Gibbs sampling iterations,
symmetric priors ? = 0.1 and free parameter ? = 1.0;
and for ?, we can obtain the estimation of ?ci by
fixed-point iteration (Minka, 2003).
6.2 Case Study
With topic modeling, the top associated words of
topics can be used as good descriptors for topics in
a hierarchy (Blei et al2003; Blei and McAuliffe,
2010). We show in Figure 3 a pair of compara-
tive example of the proposed model and a baseline
model over Y Ans dataset. The tree-based topic vi-
sualizations of Figure 3 (a) and (b) are the results of
SSHLDA and Simp-hLDA.
We have three major observations from the exam-
ple: (i) SSHLDA is a unified and generative model,
after learning, it can obtain a hierarchy of topics;
?http://dmoz.org/
805
Figure 3: (a) A sub network discovered on Y Ans dataset using SSHLDA, and the whole tree has 74 nodes; (b) A sub
network discovered on Y Ans dataset using Simp-hLDA algorithm, and the whole tree has 89 nodes. In both figures,
the shaded and squared nodes are observed labels, not topics; the shaded and round nodes are topics with observed
labels; blue nodes are topics but without labels and the yellow node is one of leaves in hierarchy of labels. Each topic
represented by top 5 terms.
while Simp-hLDA is a heuristic method, and its re-
sult is a mixture of label nodes and topical nodes.
For example, Figure 3 (b) shows that the hierarchy
includes label nodes and topic nodes, and each of la-
beled nodes just has a label, but label nodes in Fig-
ure 3 (a) have their corresponding topics. (ii) Dur-
ing obtaining a hierarchy, SSHLDAmakes use of the
information from observed labels, thus it can gener-
ate a logical, structual hierarchy with parent-child
relations; while Simp-hLDA does not incorporate
prior information of labels into its generation pro-
cess, thus although it can obtain a hierarchy, many
parent-child pairs have not parent-child relation. For
example, in Figure 3 (b), although label ?root? is
a parent of label ?Computers & Internet?, the topi-
cal words of label ?Computers & Internet? show the
topical node is not a child of label ?root?. How-
ever, in Figure 3 (a), label ?root? and ?Computers
& Internet? has corresponding parent-child relation
between their topical words. (iii) In a hierarchy of
topics, if a topical node has correspending label, the
label can help people understand descendant topi-
cal nodes. For example, when we know node ?er-
ror files click screen virus? in Figure 3 (a) has its
label ?Computers & Internet?, we can understand
the child topic ?hard screen usb power dell? is about
?computer hardware?. However, in Figure 3 (b), the
labels in parent nodes cannot provide much informa-
tion to understand descendant topical nodes because
many label nodes have not corresponding right topi-
cal words, such as label ?Computers & Internet?, its
topical words, ?the to you and a?, do not reflect the
connotation of the label.
These observations further confirm that SSHLDA
is better than the baseline model.
6.3 Perplexity Comparison
A good topic model should be able to generalize to
unseen data. To measure the prediction ability of
our model and baselines, we compute the perplex-
ity for each document d in the test sets. Perplex-
ity, which is widely used in the language modeling
and topic modeling community, is equivalent alge-
braically to the inverse of the geometric mean per-
word likelihood (Blei et al2003). Lower perplexity
scores mean better. Our model, SSHLDA, will com-
pare with three state-of-the-art models, i.e. Simp-
hLDA, hLDA and hLLDA. Simp-hLDA has been
introduced in Section 1, and hLDA and hLLDA has
been reviewed in Section 2. We keep 80% of the data
collection as the training set and use the remaining
collection as the held-out test set. We build the mod-
806
els based on the train set and compute the preplexity
of the test set to evaluate the models. Thus, our goal
is to achieve lower perplexity score on a held-out test
set. The perplexity of M test documents is calculated
as:
perplexity(Dtest) = exp
{
?
?M
d=1
?Nd
m=1 log p(wdm)
?M
d=1 Nd
}
(10)
where Dtest is the test collection of M documents,
Nd is document length of document d and wdm is
mth word in document d.
We present the results over the O Hlth dataset in
Figure 4. We choose top 3-level labels as observed,
and assume other labels are not observed, i.e. l = 3.
From the figure, we can see that the perplexities of
SSHLDA, are lower than that of Simp-hLDA, hLDA
and hLLDA at different value of the tree height pa-
rameter, i.e. L ? {5, 6, 7, 8}. It shows that the
performance of SSHLDA is always better than the
state-of-the-art baselines, and means that our pro-
posed model can model the hierarchical labeled data
better than the state-of-the-art models. We can also
obtain similar experimental results over Y Ans and
O Home datasets, and their detailed description is
not included in this paper due to the limitation of
space.
6.4 Clustering performance
To evaluate indirectly the performance of the pro-
posed model, we compare the clustering perfor-
mance of following systems: 1) the proposed model;
2) Simp-hLDA; 3) hLDA; 4) agglomerative cluster-
ing algorithm. There are many agglomerative clus-
tering algorithms, and in this paper, we make use
of the single-linkage method in a software package
called CLUTO (Karypis, 2005) to obtain hierarchies
of clusters over our datasets, with words as features.
We refer the method as h-clustering.
Given a document collectionDSwith aH-level hi-
erarchy of labels, each label in the hierarchy and cor-
responding documents will be taken as the ground
truth of clustering algorithms. The hierarchy of la-
bels denoted as GT-tree. The process of evaluation
is as follows. First, we choose top l-level labels
in GT-tree as an observed hierarchy, i.e. Base Tree
(BT), and we need to construct a L-level hierarchy
(l < L <= H) over the documents DS using a
Figure 4: Perplexities of hLLDA, hLDA, Simp-hLDA
and SSHLDA. The results are run over the O Hlth
dataset, with the height of the hierarchy of observed la-
bels l = 3. The X-axis is the height of the whole topical
tree (L), and Y-axis is the perplexity.
model. The remaining labels in GT-tree and cor-
responding documents are the ground truth classes,
each class denoted as Ci. Then, (i) for h-clustering,
we run single-linkage method over the documents
DS. (ii) for Simp-hLDA, hLDA runs on the doc-
uments in each leaf-node in BT, and the height pa-
rameter is (L ? l) for each hLDA. After training,
each document is assigned to top-1 topic accord-
ing to the distribution over topics for the document.
Each topic and corresponding documents forms a
new cluster. (iii) for hLDA, hLDA runs on all docu-
ments in DS, and the height parameter is L. Similar
to Simp-hLDA, each document is assigned to top-
1 topic. Each topic and corresponding documents
forms a new cluster. (iv) for SSHLDA, we set height
parameter as L. After training, each document is
also assigned to top-1 topic. Topics and their cor-
responding documents form a hierarchy of clusters.
6.4.1 Evaluation Metrics
For each dataset we obtain corresponding clusters
using the various models described in previous sec-
tions. Thus we can use clustering metrics to measure
the quality of various algorithms by using a measure
that takes into account the overall set of clusters that
are represented in the new generated part of a hier-
archical tree.
One such measure is the FScore measure, intro-
807
duced by (Manning et al2008). Given a particular
class Cr of size nr and a particular cluster Si of size
ni, suppose nri documents in the cluster Si belong
to Cr, then the FScore of this class and cluster is
defined to be
F (Cr, Si) =
2?R(Cr, Si)? P (Cr, Si)
R(Cr, Si) + P (Cr, Si)
(11)
where R(Cr, Si) is the recall value defined as
nri/nr, and P (Cr, Si) is the precision value defined
as nri/ni for the classCr and the cluster Si. The FS-
core of the class Cr, is the maximum FScore value
attained at any node in the hierarchical clustering
tree T . That is,
F (Cr) = max
Si?T
F (Cr, Si). (12)
The FScore of the entire clustering solution is then
defined to be the sum of the individual class FScore
weighted according to the class size.
FScore =
c
?
r=1
nr
n
F (Cr), (13)
where c is the total number of classes. In general, the
higher the FScore values, the better the clustering
solution is.
6.4.2 Experimental Results
Each of hLDA, Simp-hLDA and SSHLDA needs
a parameter?the height of the topical tree, i.e. L;
and for Simp-hLDA and SSHLDA, they need an-
other parameter?the height of the hierarchical ob-
served labels, i.e l. The h-clustering does not have
any height parameters, thus its FScore will keep the
same values at different height of the topical tree.
With choosing the height of hierarchical labels for
O Home as 4, i.e. l = 4, the results of our model
and baselines with respect to the height of a hierar-
chy are shown in Figure 5.
From the figure, we can see that our proposed
model can achieve consistent improvement over
the baseline models at different height, i.e. L ?
{5, 6, 7, 8}. For example, the performance of
SSHLDA can reach 0.396 at height 5 while the h-
clustering, hLDA and hLLDA only achieve 0.295,
0.328 and 0.349 at the same height. The result shows
that our model can achieve about 34.2%, 20.7% and
13.5% improvements over h-clustering, hLDA and
Figure 5: FScore measures of h-clustering, hLDA,
Simp-hLDA and SSHLDA. The results are run over the
O Home dataset, with the height of the hierarchy of ob-
served labels l = 3. The X-axis is the height of the whole
topical tree (L), and Y-axis is the FScore measure.
hLLDA at height 5. The improvements are signifi-
cant by t-test at the 95% significance level. We can
also obtain similar experimental results over Y Ans
and O Hlth. However, for the same reason of limita-
tion of space, their detailed descriptions are skipped
in this paper.
7 Conclusion and Future work
In this paper, we have proposed a semi-supervised
hierarchical topic models, i.e. SSHLDA, which aims
to solve the drawbacks of hLDA and hLLDA while
combine their merits. Specially, SSHLDA incorpo-
rates the information of labels into generative pro-
cess of topic modeling while exploring latent topics
in data space. In addition, we have also proved that
hLDA and hLLDA are special cases of SSHLDA.
We have conducted experiments on the Yahoo! An-
swers and ODP datasets, and assessed the perfor-
mance in terms of Perplexity and FScore measure.
The experimental results show that the prediction
ability of SSHLDA is the best, and SSHLDA can
also achieve significant improvement over the base-
lines on Fscore measure.
In the future, we will continue to explore novel
topic models for hierarchical labeled data to further
improve the effectiveness; meanwhile we will also
apply SSHLDA to other media forms, such as im-
age, to solve related problems in these areas.
808
Acknowledgments
This work was partially supported by NSFC with Grant
No.61073082, 60933004, 70903008 and NExT Search
Centre, which is supported by the Singapore National Re-
search Foundation & Interactive Digital Media R&D Pro-
gram Office, MDA under research grant (WBS:R-252-
300-001-490).
References
D. Blei and J. Lafferty. 2006. Correlated topic mod-
els. Advances in neural information processing sys-
tems, 18:147.
D.M. Blei and J.D. McAuliffe. 2007. Supervised topic
models. In Proceeding of the Neural Information Pro-
cessing Systems(nips).
D.M. Blei and J.D. McAuliffe. 2010. Supervised topic
models. Arxiv preprint arXiv:1003.0783.
D.M. Blei, A.Y. Ng, and M.I. Jordan. 2003. Latent
dirichlet alation. The Journal of Machine Learning
Research, 3:993?1022.
D. Blei, T.L. Griffiths, M.I. Jordan, and J.B. Tenenbaum.
2004. Hierarchical topic models and the nested chi-
nese restaurant process. Advances in neural informa-
tion processing systems, 16:106.
C. Chemudugunta, A. Holloway, P. Smyth, and
M. Steyvers. 2008a. Modeling documents by com-
bining semantic concepts with unsupervised statistical
learning. The Semantic Web-ISWC 2008, pages 229?
244.
C. Chemudugunta, P. Smyth, and M. Steyvers. 2008b.
Combining concept hierarchies and statistical topic
models. In Proceeding of the 17th ACM conference on
Information and knowledge management, pages 1469?
1470. ACM.
C. Chemudugunta, P. Smyth, and M. Steyvers. 2008c.
Text modeling using unsupervised topic models and
concept hierarchies. Arxiv preprint arXiv:0808.0973.
S. Deerwester, S.T. Dumais, G.W. Furnas, T.K. Landauer,
and R. Harshman. 1990. Indexing by latent semantic
analysis. Journal of the American society for informa-
tion science, 41(6):391?407.
T. Hofmann. 1999. Probabilistic latent semantic analy-
sis. In Proc. of Uncertainty in Artificial Intelligence,
UAI?99, page 21. Citeseer.
G. Karypis. 2005. Cluto: Software for
clustering high dimensional datasets. In-
ternet Website (last accessed, June 2008),
http://glaros.dtc.umn.edu/gkhome/cluto/cluto/overview.
S. Lacoste-Julien, F. Sha, and M.I. Jordan. 2008. ndis-
clda: Discriminative learning for dimensionality re-
duction and classification. Advances in Neural Infor-
mation Processing Systems, 21.
W. Li and A. McCallum. 2006. Pachinko allocation:
Dag-structured mixture models of topic correlations.
In Proceedings of the 23rd international conference on
Machine learning, pages 577?584. ACM.
C.D. Manning, P. Raghavan, and H. Schutze. 2008. In-
troduction to information retrieval, volume 1. Cam-
bridge University Press Cambridge.
D. Mimno, W. Li, and A. McCallum. 2007. Mixtures of
hierarchical topics with pachinko allocation. In Pro-
ceedings of the 24th international conference on Ma-
chine learning, pages 633?640. ACM.
Z.Y. Ming, K. Wang, and T.S. Chua. 2010. Prototype
hierarchy based clustering for the categorization and
navigation of web collections. In Proceeding of the
33rd international ACM SIGIR, pages 2?9. ACM.
T.P. Minka. 2003. Estimating a dirichlet distribution.
Annals of Physics, 2000(8):1?13.
A. Perotte, N. Bartlett, N. Elhadad, and F. Wood. 2011.
Hierarchically supervised latent dirichlet alation.
Neural Information Processing Systems (to appear).
Y. Petinot, K. McKeown, and K. Thadani. 2011. A
hierarchical model of web summaries. In Proceed-
ings of the 49th Annual Meeting of the ACL: Human
Language Technologies: short papers-Volume 2, pages
670?675. ACL.
D. Ramage, D. Hall, R. Nallapati, and C.D. Manning.
2009a. Labeled lda: A supervised topic model for
credit attribution in multi-labeled corpora. In Proceed-
ings of the 2009 Conference on Empirical Methods in
Natural Language Processing: Volume 1-Volume 1,
pages 248?256. Association for Computational Lin-
guistics.
D. Ramage, P. Heymann, C.D. Manning, and H. Garcia-
Molina. 2009b. Clustering the tagged web. In Pro-
ceedings of the Second ACM International Conference
on Web Search and Data Mining, pages 54?63. ACM.
D. Ramage, C.D. Manning, and S. Dumais. 2011. Par-
tially labeled topic models for interpretable text min-
ing. In Proceedings of the 17th ACM SIGKDD inter-
national conference on Knowledge discovery and data
mining, pages 457?465. ACM.
M. Rosen-Zvi, T. Griffiths, M. Steyvers, and P. Smyth.
2004. The author-topic model for authors and doc-
uments. In Proceedings of the 20th conference on
Uncertainty in artificial intelligence, pages 487?494.
AUAI Press.
T.N. Rubin, A. Chambers, P. Smyth, and M. Steyvers.
2011. Statistical topic models for multi-label docu-
ment classification. Arxiv preprint arXiv:1107.2462.
Y.W. Teh, M.I. Jordan, M.J. Beal, and D.M. Blei. 2006.
Hierarchical dirichlet processes. Journal of the Amer-
ican Statistical Association, 101(476):1566?1581.
809
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 199?205,
Baltimore, Maryland, USA, June 23-25 2014.
c?2014 Association for Computational Linguistics
Effective Document-Level Features for Chinese Patent Word
Segmentation
Si Li
Chinese Language Processing Group
Brandeis University
Waltham, MA 02453, USA
lisi@brandeis.edu
Nianwen Xue
Chinese Language Processing Group
Brandeis University
Waltham, MA 02453, USA
xuen@brandeis.edu
Abstract
A patent is a property right for an inven-
tion granted by the government to the in-
ventor. Patents often have a high con-
centration of scientific and technical terms
that are rare in everyday language. How-
ever, some scientific and technical terms
usually appear with high frequency only
in one specific patent. In this paper, we
propose a pragmatic approach to Chinese
word segmentation on patents where we
train a sequence labeling model based on
a group of novel document-level features.
Experiments show that the accuracy of our
model reached 96.3% (F
1
score) on the de-
velopment set and 95.0% on a held-out test
set.
1 Introduction
It is well known that Chinese text does not come
with natural word delimiters, and the first step
for many Chinese language processing tasks is
word segmentation, the automatic determination
of word boundaries in Chinese text. Tremendous
progress was made in this area in the last decade
or so due to the availability of large-scale human
segmented corpora coupled with better statistical
modeling techniques. On the data side, there exist
a few large-scale human annotated corpora based
on established word segmentation standards, and
these include the Chinese TreeBank (Xue et al,
2005), the Sinica Balanced Corpus (Chen et al,
1996), the PKU Peoples? Daily Corpus (Duan et
al., 2003), and the LIVAC balanced corpus (T?sou
et al, 1997). Another driver for the improvemen-
t in Chinese word segmentation accuracy comes
from the evolution of statistical modeling tech-
niques. Dictionaries used to play a central role
in early heuristics-based word segmentation tech-
niques (Chen and Liu, 1996; Sproat et al, 1996).
Modern word segmentation systems have moved
away from dictionary-based approaches in favor
of character tagging approaches. This allows the
word segmentation problem to be modeled as a
sequence labeling problem, and lends itself to dis-
criminative sequence modeling techniques (Xue,
2003; Peng et al, 2004). With these better model-
ing techniques, state-of-the-art systems routinely
report accuracy in the high 90%, and a few recen-
t systems report accuracies of over 98% in F
1
s-
core (Sun, 2011; Zeng et al, 2013b).
Chinese word segmentation is not a solved
problem however and significant challenges re-
main. Advanced word segmentation systems per-
form very well in domains such as newswire
where everyday language is used and there is a
large amount of human annotated training data.
There is often a rapid degradation in performance
when systems trained on one domain (let us call it
the source domain) are used to segment data in a
different domain (let us call it the target domain).
This problem is especially severe when the target
domain is distant from the source domain. This is
the problem we are facing when we perform word
segmentation on Chinese patent data. The word
segmentation accuracy on Chinese patents is very
poor if the word segmentation model is trained on
the Chinese TreeBank data, which consists of data
sources from a variety of genres but no patents.
To address this issue, we annotated a corpus of
142 patents which contain about 440K words ac-
cording to the Chinese TreeBank standards. We
trained a character-tagging based CRF model for
word segmentation, and based on the writing style
of patents, we propose a group of document-level
features as well as a novel character part-of-speech
feature (C_POS). Our results show these new fea-
tures are effective and we are able to achieve an
accuracy of 96.3% (F
1
score) on the development
set and 95% (F
1
score) on the test set.
199
2 Method
We adopt the character-based sequence labeling
approach, first proposed in (Xue, 2003), as our
modeling technique for its simplicity and effec-
tiveness. This approach treats each sentence as a
sequence of characters and assigns to each charac-
ter a label that indicates its position in the word. In
this paper, we use the BMES tag set to indicate the
character positions. The tag set has four labels that
represent for possible positions a character can oc-
cupy within a word: B for beginning, M for mid-
dle, E for ending, and S for a single character as a
word. After each character in a sentence is tagged
with a BMES label, a sequence of words can be
derived from this labeled character sequence.
We train a Conditional Random Field (CRF)
(Lafferty et al, 2001) model for this sequence
labeling. When extracting features to train a
CRF model from a sequence of n characters
C
1
C
2
...C
i?1
C
i
C
i+1
...C
n
, we extract features for
each character C
i
from a fixed window. We start
with a set of core features extracted from the anno-
tated corpus that have been shown to be effective
in previous works and propose some new features
for patent word segmentation. We describe each
group of features in detail below.
2.1 Character features (CF)
When predicting the position of a character with-
in a word, features based on its surrounding char-
acters and their types have shown to be the most
effective features for this task (Xue, 2003). There
are some variations of these features depending on
the window size in terms of the number of char-
acters to examine, and here we adopt the feature
templates used in (Ng and Low, 2004).
Character N-gram features The N-gram fea-
tures are various combinations of the surrounding
characters of the candidate character C
i
. The 10
features we used are listed below:
? Character unigrams: C
k
(i? 3 < k < i+ 3)
? Character bigrams: C
k
C
k+1
(i ? 3 < k <
i+ 2) and C
k?1
C
k+1
(k = i)
Character type N-gram features We classify
the characters in Chinese text into 4 types: Chi-
nese characters or hanzi, English letters, numbers
and others. T
i
is the character type of C
i
. The
character type has been used in the previous work-
s in various forms (Ng and Low, 2004; Jiang et al,
2009), and the 4 features we use are as follows:
? Character type unigrams: T
k
(k = i)
? Character type bigrams: T
k
T
k+1
(i?2 < k <
i+ 1) and T
k?1
T
k+1
(k = i)
Starting with this baseline, we extract some new
features to improve Chinese patent word segmen-
tation accuracy.
2.2 POS of single-character words (C_POS)
Chinese words are composed of Chinese hanzi,
and an overwhelming majority of these Chinese
characters can be single-character words them-
selves in some context. In fact, most of the multi-
character words are compounds that are 2-4 char-
acters in length. The formation of these compound
words is not random and abide by word formation
rules that are similar to the formation of phras-
es (Xue, 2000; Packard, 2000). In fact, the Chi-
nese TreeBank word segmentation guidelines (X-
ia, 2000) specify how words are segmented based
on the part-of-speech (POS) of their componen-
t characters. We hypothesize that the POS tags
of the single-character words would be useful in-
formation to help predict how they form the com-
pound words, and these POS tags are more fine-
grained information than the character type infor-
mation described in the previous section, but are
more robust and more generalizable than the char-
acters themselves.
Since we do not have POS-tagged patent da-
ta, we extract this information from the Chinese
TreeBank (CTB) 7.0, a 1.2-million-word out-of-
domain dataset. We extract the POS tags for al-
l the single-character words in the CTB. Some of
the single-character words will have more than one
POS tag. In this case, we select the POS tag with
the highest frequency as the C_POS tag for this
character. The result of this extraction process is
a list of single-character Chinese words, each of
which is assigned a single POS tag.
When extracting features for the target character
C
i
, if C
i
is in this list, the POS tag of C
i
is used as
a feature for this target character.
2.3 Document-level features
A patent is a property right for an invention grant-
ed by the government to the inventor, and many of
the patents have a high concentration of scientif-
ic and technical terms. From a machine learning
perspective, these terms are hard to detect and seg-
ment because they are often "new words" that are
not seen in everyday language. These technical
200
Algorithm 1 Longest n-gram sequence extraction.
Input:
Sentences {s
i
} in patent P
i
;
Output:
Longest n-gram sequence list for P
i
;
1: For each sentence s
i
in P
i
do:
n-gram sequence extraction
(2?n?length(s
i
));
2: Count the frequency of each n-gram sequence;
3: Delete the sequence if its frequency<2;
4: Delete sequence i if it is contained in a longer
sequence j;
5: All the remaining sequences form a longest n-
gram sequence list for P
i
;
6: return Longest n-gram sequences list.
terminologies also tend to be very sparse, either
because they are related to the latest invention that
has not made into everyday language, or because
our limited patent dataset cannot possibly cover all
possible technical topics. However, these techni-
cal terms are also topical and they tend to have
high relative frequency within a patent document
even though they are sparse in the entire patent da-
ta set. We attempt to exploit this distribution prop-
erty with some document-level features which are
extracted based on each patent document.
Longest n-gram features (LNG) We propose a
longest n-gram (LNG) feature as a document-level
feature. Each patent document is treated as an in-
dependent unit and the candidate longest n-gram
sequence lists for each patent are obtained as de-
scribed in Algorithm 1.
For a given patent, the LNG feature value for the
target character C
i
?s LNG is set to 'S' if the bigram
(C
i
,C
i+1
) are the first two characters of an n-gram
sequence in this patent?s longest n-gram sequence
list. If (C
i?1
, C
i
) are the last two characters of an
n-gram sequence in this patent?s longest n-gram
sequence list, the target character C
i
?s LNG is set
to 'F'. It is set to 'O' otherwise. If C
i
can be labeled
as both 'S' and 'F' at the same time, label 'T' will be
given as the final label. For example, if '?' is the
target character C
i
in patent A and the sequence
'??Z6?' is in patent A?s longest n-gram se-
quence list. If the character next to '?' is '?', the
value of the LNG feature is set to 'S'. If the next
character is not '?', the value of the LNG feature
is set to 'O'.
Algorithm 2 Pseudo KL divergence.
Input:
Sentences {s
i
} in patent P
i
;
Output:
Pseudo KL divergence values between differ-
ent characters in P
i
;
1: For each sentence s
i
in P
i
do:
trigram sequences extraction;
2: Count the frequency of each trigram;
3: Delete the trigram if its frequency<2;
4: For C
i
in trigram C
i
C
i+1
C
i+2
do :
PKL(C
i
, C
i+1
) = p(C
i
1
)log
p(C
i
1
)
p(C
i+1
2
)
(1)
PKL(C
i
, C
i+2
) = p(C
i
1
)log
p(C
i
1
)
p(C
i+2
3
)
(2)
The superscripts {1,2,3} indicate the character
position in trigram sequences;
5: return PKL(C
i
, C
i+1
) and PKL(C
i
, C
i+2
)
for the first character C
i
in each trigram.
Pseudo Kullback-Leibler divergence (PKL)
The second document-level feature we propose
is the Pseudo Kullback-Leibler divergence fea-
ture which is calculated following the form of
the Kullback-Leibler divergence. The relative
position information is very important for Chi-
nese word segmentation as a sequence labeling
task. Characters XY may constitute a meaningful
word, but characters Y X may not be. Therefore,
if we want to determine whether character X and
character Y can form a word, the relative position
of these two characters should be considered. We
adopt a pseudo KL divergence with the relative po-
sition information as a measure of the association
strength between two adjacent characters X and
Y . The pseudo KL divergence is an asymmetric
measure. The PKL value between character X
and character Y is described in Algorithm 2.
The PKL values are real numbers and are s-
parse. A common solution to sparsity reduction
is binning. We rank the PKL values between t-
wo adjacent characters in each patent from low to
high, and then divide all values into five bins. Each
bin is assigned a unique ID and all PKL values in
the same bin are replaced by this ID. This ID is
then used as the PKL feature value for the target
character C
i
.
201
Pointwise Mutual information (PMI) Point-
wise Mutual information has been widely used
in previous work on Chinese word segmentation
(Sun and Xu, 2011; Zhang et al, 2013b) and it is a
measure of the mutual dependence of two strings
and reflects the tendency of two strings appearing
in one word. In previous work, PMI statistics are
gathered on the entire data set, and here we gather
PMI statistics for each patent in an attempt to cap-
ture character strings with high PMI in a particu-
lar patent. The procedure for calculating PMI is
the same as that for computing pseudo KL diver-
gence, but the functions (1) and (2) are replaced
with the following functions:
PMI(C
i
, C
i+1
) = log
p(C
i
1
, C
i+1
2
)
p(C
i
1
)p(C
i+1
2
)
(3)
PMI(C
i
, C
i+2
) = log
p(C
i
1
, C
i+2
3
)
p(C
i
1
)p(C
i+2
3
)
(4)
For the target character C
i
, we obtain the values
for PMI(C
i
, C
i+1
) and PMI(C
i
, C
i+2
). In each
patent document, we rank these values from high
to low and divided them into five bins. Then the
PMI feature values are represented by the bin IDs.
3 Experiments
3.1 Data preparation
We annotated 142 Chinese patents following the
CTB word segmentation guidelines (Xia, 2000).
Since the original guidelines are mainly designed
to cover non-technical everyday language, many
scientific and technical terms found in patents are
not covered in the guidelines. We had to extend
the CTB word segmentation guidelines to han-
dle these new words. Deciding on how to seg-
ment these scientific and technical terms is a big
challenge since these patents cover many differ-
ent technical fields and without proper technical
background, even a native speaker has difficulty
in segmenting them properly. For difficult scien-
tific and technical terms, we consult BaiduBaike
("Baidu Encyclopedia")
1
, which we use as a scien-
tific and technical terminology dictionary during
our annotation. There are still many words that
do not appear in BaiduBaiKe, and these include
chemical names and formulas. These chemical
names and formulas (e.g., /??????Z
/1-bromo-3-chloropropane0) are usually very
1
http://baike.baidu.com/
Table 1: Training, development and test data on
Patent data
Data set # of words # of patent
Training 345336 113
Devel. 46196 14
Test 48351 15
long, and unlike everyday words, they often have
numbers and punctuation marks in them. We de-
cided not to try segmenting the internal structures
of such chemical terms and treat them as single
words, because without a technical background in
chemistry, it is very hard to segment their internal
structures consistently.
The annotated patent dataset covers many topics
and they include chemistry, mechanics, medicine,
etc. If we consider the words in our annotated
dataset but not in CTB 7.0 data as new words (or
out-of-vocabulary, OOV), the new words account
for 18.3% of the patent corpus by token and 68.1%
by type. This shows that there is a large number of
words in the patent corpus that are not in the ev-
eryday language vocabulary. Table 1 presents the
data split used in our experiments.
3.2 Main results
We use CRF++ (Kudo, 2013) to train our sequence
labeling model. Precision, recall, F
1
score and
R
OOV
are used to evaluate our word segmentation
methods, whereR
OOV
for our purposes means the
recall of new words which do not appear in CTB
7.0 but in patent data.
Table 2 shows the segmentation results on the
development and test sets with different feature
templates and different training sets. The CTB
training set includes the entire CTB 7.0, which has
1.2 million words. The model with the CF fea-
ture template is considered to be the baseline sys-
tem. We conducted 4 groups of experiments based
on the different datasets: (1) patent training set +
patent development set; (2) patent training set +
patent test set; (3) CTB training set + patent de-
velopment set; (4) CTB training set + patent test
set.
The results in Table 2 show that the model-
s trained on the patent data outperform the mod-
els trained on the CTB data by a big margin on
both the development and test set, even if the CTB
training set is much bigger. That proves the im-
portance of having a training set in the same do-
202
Table 2: Segmentation performance with different feature sets on different datasets.
Train set Test set Features P R F
1
R
OOV
Patent train Patent dev.
CF 95.34 95.28 95.32 90.02
CF+C_POS 95.58 95.40 95.49 90.40
CF+C_POS+LNG 96.32 96.00 96.15 91.22
CF+C_POS+PKL 95.62 95.41 95.51 90.40
CF+C_POS+PMI 95.65 95.40 95.53 89.94
CF+C_POS+PMI+PKL 95.72 95.53 95.62 90.37
CF+C_POS+LNG+PMI 96.42 96.09 96.26 91.66
CF+C_POS+LNG+PMI+PKL 96.48 96.12 96.30 91.69
Patent train Patent test
CF 93.98 94.49 94.23 85.19
CF+C_POS+LNG+PKL+PMI 94.89 95.10 95.00 87.89
CTB train Patent dev. CF+C_POS+LNG+PKL+PMI 89.04 90.75 89.89 72.80
CTB train Patent test CF+C_POS+LNG+PKL+PMI 87.88 89.03 88.45 70.89
main. The results also show that adding the new
features we proposed leads to consistent improve-
ment across all experimental conditions, and that
the LNG features are the most effective and bring
about the largest improvement in accuracy.
4 Related work
Most of the previous work on Chinese word seg-
mentation focused on newswire, and one wide-
ly adopted technique is character-based represen-
tation combined with sequential learning models
(Xue, 2003; Low et al, 2005; Zhao et al, 2006;
Sun and Xu, 2011; Zeng et al, 2013b; Zhang
et al, 2013b; Wang and Kan, 2013). More re-
cently, word-based models using perceptron learn-
ing techniques (Zhang and Clark, 2007) also pro-
duce very competitive results. There are also some
recent successful attempts to combine character-
based and word-based techniques (Sun, 2010;
Zeng et al, 2013a).
As Chinese word segmentation has reached a
very high accuracy in the newswire domain, the
attention of the field has started to shift to other
domains where there are few annotated resources
and the problem is more challenging, such as work
on the word segmentation of literature data (Li-
u and Zhang, 2012) and informal language gen-
res (Wang and Kan, 2013; Zhang et al, 2013a).
Patents are distinctly different from the above gen-
res as they contain scientific and technical terms
that require some special training to understand.
There has been very little work in this area, and
the only work that is devoted to Chinese word
segmentation is (Guo et al, 2012), which reports
work on Chinese patent word segmentation with
a fairly small test set without any annotated train-
ing data in the target domain. They reported an
accuracy of 86.42% (F
1
score), but the results are
incomparable with ours as their evaluation data is
not available to us. We differ from their work in
that we manually segmented a significant amount
of data, and trained a model with document-level
features designed to capture the characteristics of
patent data.
5 Conclusion
In this paper, we presented an accurate character-
based word segmentation model for Chinese
patents. Our contributions are two-fold. Our first
contribution is that we have annotated a signifi-
cant amount of Chinese patent data and we plan
to release this data once the copyright issues have
been cleared. Our second contribution is that we
designed document-level features to capture the
distributional characteristics of the scientific and
technical terms in patents. Experimental results
showed that the document-level features we pro-
posed are effective for patent word segmentation.
Acknowledgments
This paper is supported by the Intelligence Ad-
vanced Research Projects Activity (IARPA) vi-
a contract NO. D11PC20154. All views ex-
pressed in this paper are those of the authors and
do not necessarily represent the view of IARPA,
DoI/NBC, or the U.S. Government.
203
References
Keh-Jiann Chen and Shing-Huan Liu. 1996. Word
Identification for Mandarin Chinese Sentences. In
Proceedings of COLING?92, pages 101?107.
Keh-Jiann Chen, Chu-Ren Huang, Li-Ping Chang, and
Hui-Li Hsu. 1996. Sinica Corpus: Design Method-
ology for Balanced Corpora. In Proceedings of the
11 th Pacific Asia Conference on Language, Infor-
mation and Computation, pages 167?176.
Huiming Duan, Xiaojing Bai, Baobao Chang, and Shi-
wen Yu. 2003. Chinese word segmentation at
Peking University. In Proceedings of the second
SIGHAN workshop on Chinese language process-
ing, pages 152?155.
Zhen Guo, Yujie Zhang, Chen Su, and Jinan Xu. 2012.
Exploration of N-gram Features for the Domain
Adaptation of Chinese Word Segmentation. In Pro-
ceedings of Natural Language Processing and Chi-
nese Computing Natural Language Processing and
Chinese Computing, pages 121?131.
Wenbin Jiang, Liang Huang, and Qun Liu. 2009. Au-
tomatic Adaptation of Annotation Standards: Chi-
nese Word Segmentation and POS Tagging - A Case
Study. In Proceedings of ACL?09, pages 522?530.
Taku Kudo. 2013. CRF++: Yet Another CRF toolkit.
John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data. In Proceedings of ICML?01, pages
282?289.
Yang Liu and Yue Zhang. 2012. Unsupervised Do-
main Adaptation for Joint Segmentation and POS-
Tagging. In Proceedings of COLING?12, pages
745?754.
Jin Kiat Low, Hwee Tou Ng, and Wenyuan Guo. 2005.
A Maximum Entropy Approach to Chinese Word
Segmentation. In Proceedings of the 4th SIGHAN
Workshop on Chinese Language Processing, pages
970?979.
Hwee Tou Ng and Jin Kiat Low. 2004. Chinese Part-
of-Speech Tagging: One-at-a-Time or All-at-Once?
Word-Based or Character-Based? In Proceedings of
EMNLP?04, pages 277?284.
Jerome Packard. 2000. The Morphology of Chinese: a
cognitive and linguistic approach. Cambridge Uni-
versity Press.
Fuchun Peng, Fangfang Feng, and Andrew McCallum.
2004. Chinese Segmentation and New Word Detec-
tion using Conditional Random Fields. In Proceed-
ings of COLING?04.
Richard Sproat, Chilin Shih, William Gale, and Nan-
cy Chang. 1996. A Stochastic Finite-State Word-
Segmentation Algorithm for Chinese. Computation-
al Linguistics, 22(3):377?404.
Weiwei Sun and Jia Xu. 2011. Enhancing Chinese
Word Segmentation Using Unlabeled Data. In Pro-
ceedings of EMNLP?11, pages 970?979.
Weiwei Sun. 2010. Word-based and character-based
word segmentation models: Comparison and com-
bination. In Proceedings of ACL?10, pages 1211?
1219.
Weiwei Sun. 2011. A Stacked Sub-Word Model
for Joint Chinese Word Segmentation and Part-of-
Speech Tagging. In Proceedings of ACL?11, pages
1385?1394.
Benjamin K. T?sou, Hing-Lung Lin, Godfrey Liu,
Terence Chan, Jerome Hu, Ching hai Chew, and
John K.P. Tse. 1997. A Synchronous Chinese Lan-
guage Corpus from Different Speech Communities:
Construction and Application. International Jour-
nal of Computational Linguistics and Chinese Lan-
guage Processing, 2(1):91?104.
Aobo Wang and Min-Yen Kan. 2013. Mining Infor-
mal Language from Chinese Microtext: Joint Word
Recognition and Segmentation. In Proceedings of
ACL?13, pages 731?741.
Fei Xia. 2000. The segmentation guidelines for the
Penn Chinese Treebank (3.0).
Nianwen Xue, Fei Xia, Fu-Dong Chiou, and Martha
Palmer. 2005. The Penn Chinese TreeBank: Phrase
Structure Annotation of a Large Corpus. Natural
Language Engineering, 11(2):207?238.
Nianwen Xue. 2000. Defining and identifying words
in Chinese. Ph.D. thesis, University of Delaware.
Nianwen Xue. 2003. Chinese Word Segmentation as
Character Tagging. International Journal of Com-
putational Linguistics and Chinese Language Pro-
cessing, 8(1):29?48.
Xiaodong Zeng, Derek F. Wong, Lidia S. Chao, and
Isabel Trancoso. 2013a. Co-regularizing character-
based and word-based models for semi-supervised
Chinese word segmentation. In Proceedings of A-
CL?13, pages 171?176.
Xiaodong Zeng, Derek F. Wong, Lidia S. Chao, and
Isabel Trancoso. 2013b. Graph-based Semi-
Supervised Model for Joint Chinese Word Segmen-
tation and Part-of-Speech Tagging. In Proceedings
of ACL?13, pages 770?779.
Yue Zhang and Stephen Clark. 2007. Chinese Seg-
mentation Using a Word-based Perceptron Algorith-
m. In Proceedings of ACL?07, pages 840?847.
Longkai Zhang, Li Li, Zhengyan He, Houfeng Wang,
and Ni Sun. 2013a. Improving Chinese Word Seg-
mentation on Micro-blog Using Rich Punctuations.
In Proceedings of ACL?13, pages 177?182.
204
Longkai Zhang, Houfeng Wang, Xu Sun, and Mairgup
Mansur. 2013b. Exploring Representations from
Unlabeled Data with Co-training for Chinese Word
Segmentation. In Proceedings of EMNLP?13, pages
311?321.
Hai Zhao, Chang-Ning Huang, and Mu Li. 2006. An
improved Chinese word segmentation system with
conditional random field. In Proceedings of the 5th
SIGHAN Workshop on Chinese Language Process-
ing, pages 162?165.
205
PRIS at Chinese Language Processing  
--Chinese Personal Name Disambiguation 
 
Jiayue Zhang, Yichao Cai, Si Li, Weiran Xu, Jun Guo  
School of Information and Communication Engineering 
Beijing Universit of Posts and Telecommunications 
jyz0706@gmail.com 
 
 
Abstract 
The more Chinese language materials come 
out, the more we have to focus on the ?same 
personal name? problem. In our personal 
name disambiguation system, the hierarchical 
agglomerative clustering is applied, and 
named entity is used as feature for document 
similarity calculation. We propose a two-stage 
strategy in which the first stage involves word 
segmentation and named entity recognition 
(NER) for feature extraction, and the second 
stage focuses on clustering.  
1 Introduction 
World Wide Web (WWW) search engines have 
become widely used in recent years to retrieve 
information about real-world entities such as 
people. Web person search is one of the most 
frequent search types on the web search engine. 
As the sheer amount of web information ex-
pands at an ever more rapid pace, the named-
entity ambiguity problem becomes more and 
more serious in many fields, such as information 
integration, cross-document co-reference, and 
question answering. It is crucial to develop me-
thodologies that can efficiently disambiguate the 
ambiguous names form any given set of data. 
There have been two recent Web People Search 
(WePS) evaluation campaigns [1] on personal 
name disambiguation using data from English 
language web pages. Previous researches on 
name disambiguation mainly employ clustering 
algorithms which disambiguates ambiguous 
names in a given document collection through 
clustering them into different reference entities. 
However, Chinese personal name disambigua-
tion is potentially more challenging due to the 
need for word segmentation, which could intro-
duce errors that can in large part be avoided in 
the English task. 
There are four tasks in Chinese Language 
Processing of the CIPS-SIGHAN Joint Confe-
rence, and we participate in the Chinese Personal 
Name Disambiguation task. To accomplish this 
task, we focused on solving two main problems 
which are word segmentation and duplicate 
names distinguishment. To distinguish duplicate 
names, the system adopts named entity recogni-
tion and clustering strategy. For word segmenta-
tion and NER, we applied a sharing platform 
named LTP designed by Harbin Institute of 
Technology [2].This tagger identifies and labels 
names of locations, organizations, people, time, 
date, numbers and proper nouns in the input text.  
The paper is organized as follows. Section 2 in-
troduces our feature extractions along with their 
corresponding similarity matrix learning. In Sec-
tion 3, we analyze the performance of our sys-
tem. Finally, we draw some conclusions.  
2 Methodology  
Our approach follows a common architecture for 
named-entity disambiguation: the detection of 
ambiguous objects, feature extractions and their 
corresponding similarity matrix learning, and 
clustering. The framework of overall processing 
is shown in Figure 1.  
 
Word Segmentation
Named Entity Recognition
 Building VSM 
HAC
Submitted Results
Corpus
LTP
TF-IDF
K-L 
divergence
weight
similarity
 
 
Figure 1. System Framework 
 
2.1 The detection of ambiguous objects 
 
Since it is common for a single document to 
contain one or more mentions of the ambiguous 
personal name, that is to say, the personal name 
may appear several times in one document, there 
is a need to define the object to be disambi-
guated. Here, we adopt the policy of ?one person 
per document? (all mentions of the ambiguous 
personal name in one document are assumed to 
refer to the same personal entity in reality) as in 
[3] [4] [5]. Therefore, an object is defined as a 
single entity with the ambiguous personal name 
in a given document. This definition of the ob-
ject (document-level object) might be not com-
prehensive, because the mentions of the ambi-
guous personal name in a document may refer to 
multiple entities, but we found that this is a rare 
case (most of those cases occur in genealogy 
web pages). On the other hand, the document-
level object can include much information de-
rived from that document, so that it can be 
represented by features [6]. 
For a given ambiguous personal name, word 
segmentation is applied first. Then we try to ex-
tract all mentions of the ambiguous personal 
name. Take the given personal name ???? for 
example, first, the exact match of the name is 
extracted. Secondly, mentions that are super-
strings of the given name like ?????is also 
extracted . Finally , mentions that contain cha-
racter sequences but not a personal name like 
???????? is ignored.  
Given this definition of an object, we define a 
target entity as an entity that includes a mention 
of the ambiguous personal name. 
 
2.2 Feature extraction and similarity ma-
trix learning 
 
Most of the previous work ([3] [4] [5]) used to-
ken information in the given documents. In this 
paper, we follow and extend their work especial-
ly for a web corpus. Furthermore, compared to a 
token, a phrase contains more information for 
named-entity disambiguation. Therefore, we ex-
plore both token and phrase-based information 
in this paper. Finally, there are two kinds of fea-
ture vectors developed in our system, token-
based and phrase-based. The token-based feature 
vector is composed of tokens, and the phrase-
based feature is composed of phrases. The two 
feature vectors are combined into a unified fea-
ture vector in which tf-idf strategy is used for 
similarity calculation.  
 
2.2.1 Named Entity Features 
 
From the results and papers of various teams 
participating WePS, NEs have been shown to be 
effective features in person name disambigua-
tion, so we used NEs as features in this study. 
Through observation, we found that two differ-
ent individuals can be identified by their corres-
ponding NEs, especially by location, organiza-
tion name and some proper nouns. Hence, in our 
study, we only extracted person, location, organ-
ization name and proper noun as feature from 
the output of LTP, while time, date and numbers 
are discarded. However, location and organiza-
tion name have many proper nouns related 
weakly to a certain person. Therefore, terms 
having high-document-frequency in training data 
sets are removed from test data. 
 
2.2.2 Similarity matrix learning 
 
After NE extraction, we applied the vector space 
model to the calculation of similarities between 
features. In the model, tf-idf is used as the 
weight of the feature, which is defined in Eq. (1).  
iij
ij
ij n
N
MaxFreq
freqwIDFTF log)(: ???
     (1) 
Here, wij is the weight of term (or phrase) ti in 
document dj, freqij is the frequency of ti in dj, 
MaxFreqij is the frequency of the term (or phrase) 
whose frequency is the most in dj, N is the num-
ber of documents under one given name, and ni 
is the number of documents which has term (or 
phrase) ti. 
In this study, the similarities based 
on features described above were calculated us-
ing K-L divergence defined as Eq. (2). 
??
i
KL iQ
iPiPQPD )(
)(log)()||(
        (2) 
P and Q denote the vector of a document respec-
tively. K-L divergence between two vectors 
shows the distance of two related documents. 
The smaller the value of K-L divergence of two 
vectors becomes, the closer the two documents 
are. In order to prevent the zero denominator, we 
applied Dirichlet smoothing, i.e. , the zero ele-
ment in the vector will be replaced by 0.00001.  
 
2.3 Clustering 
 
Clustering is the key part for our personal name 
disambiguation system. This task is viewed as an 
unsupervised hard clustering problem. First, we 
view the problem as unsupervised, using the dis-
tributed training data for parameter validation, to 
optimally tune the parameters in the clustering 
algorithm. Secondly, we observed that the ma-
jority of the input documents reference a single 
individual. Hence, we view the problem as hard 
clustering, assigning input document to exactly 
one individual, so that the produced clusters do 
not overlap. 
In our system, hierarchical agglomerative clus-
tering (HAC) is used as a clustering method. It 
builds up a hierarchy of groups by continuously 
merging the two most similar groups. Each of 
these groups starts as a single item, in this case 
an individual document. In each iteration this 
method calculates the distances between every 
pair of groups, and the closest ones are merged 
together to form a new group. The vector of the 
new group is the average of the original pair.  
This is repeated until there is only one group. 
This process is shown in Fig. 2.  
We used a threshold for selecting cluster. So it is 
not necessary to determine the number of clus-
ters beforehand. W  view the whole group as a 
binary tree, every node which is not a leaf has 
two children, left child and right child, and has a 
record of the distance between the two children. 
We traverse the tree from the root, if the distance 
between the pair of children which form the 
cluster is larger than the threshold, then move 
down to check the distance of its left child, then 
right child. The process will continue until the 
distance between two children is less than the 
threshold. When the process comes to an end, all 
the leaves under the node will be considered to 
be in the same cluster. The selecting process will 
continue until all the leaves are assigned to a 
cluster. The threshold is tuned using the distr i-
buted training data. 
The whole process mainly consists of two 
phases, the first phase is clustering all the single 
items into one group, and the second is selecting 
cluster down along the tree from the root. This 
strategy has a major disadvantage which is the 
new node is the average of its children. Hence, 
with the merger of nodes going on, the distance 
between different groups becomes smaller and 
smaller, which makes the boundaries between 
different clusters blur. This is probably the main 
reason that leads to the unsatisfactory results. 
 
 
Figure 2 visualization of hierarchical clustering  
3 Performance 
Since there is no correct answer of test data 
received, we present the performance of our sys-
tem of training data. There are two results gotten 
from the distributed evaluation in Table 1: one is 
evaluated with B-Cubed, and the other with P_IP. 
Both scores indicate that personal name disam-
biguation needs more effort. 
 
Table 1 The performance of training data 
 prici-
sion 
recall F_sco
re 
B-
Cubed 
71.83 62.88 56.98 
 purity In-
verse 
purity 
F_sco
re 
P_IP 76.43 67.71 62.76 
 
4 Conclusion 
In this report, we describe a system for the Chi-
nese Personal Name Disambiguation task, apply-
ing a two-stage clustering model. Because this is 
our first time attending this kind of task, there 
are many aspects not having been taken into ac-
count. Therefore, improving system performance 
becomes motivation for us to work on it conti-
nuously. In future work, we?ll focus on improv-
ing the clustering algorithm and proper feature 
extraction. 
  
References 
J. Artiles, J. Gonzalo and S. Sekine. WePS 2 Evalua-
tion Campaign: overview of the Web People 
Search Clustering Task. In 2nd Web People Search  
Evaluation Workshop (WePS 2009). In18th  
WWW Conference, 2009.  
http://ir.hit.edu.cn/ 
A. Bagga and B. Baldwin. 1998. Ent ity?based Cross?
document Co?referencing Using the Vector Space 
Model. In 17th COLING. 
C. H. Gooi and J. Allan. 2004.  Cross -Document Co-
reference on a Large Scale Corpus.NAACL 
T. Pedersen, A. Purandare and A. Kulkarn i. 2005. 
Name Discrimination by Clustering Similar Con-
texts. In  Proc. of the Sixth International Confe-
rence on Intelligent Text  Processing and Computa-
tional Linguistics, page 226-237. Mexico City, 
Mexico. 
Y. Chen and J. H. Martin. CU-COMSEM: Exploring  
Rich Features for Unsupervised Web Personal 
Name Disambiguation. In WWW Conference, 
2007. 
M. Ikeda, S. Ono, I. Sato, M. Yoshida and H. Naka-
gawa. Person Name Disambiguation on the Web 
by TwoStage Clustering. In 18th WWW Confe-
rence, 2009. 
E. Elmacioglu, Y. F. Tan, S.Yan, M. Y. Kan and D. 
W. Lee. Web People Name Disambiguation by 
Simple Clustering with Rich Features. In WWW 
Conference, 2007. 
 
