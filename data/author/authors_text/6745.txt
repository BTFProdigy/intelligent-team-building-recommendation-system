Proceedings of the Linguistic Annotation Workshop, pages 148?155,
Prague, June 2007. c?2007 Association for Computational Linguistics
Standoff Coordination for Multi-Tool Annotation in a Dialogue Corpus
Kepa Joseba Rodr??guez?, Stefanie Dipper?, Michael Go?tze?, Massimo Poesio?,
Giuseppe Riccardi?, Christian Raymond?, Joanna Wisniewska?
?Piedmont Consortium for Information Systems (CSI-Piemonte)
KepaJoseba.Rodriguez@csi.it
?Department of Linguistics. University of Potsdam.
{dipper|goetze}@ling.uni-potsdam.de
?Center for Mind/Brain Sciences. University of Trento.
massimo.poesio@unitn.it
?Department of Information and Communication Technology. University of Trento.
{christian.raymond|riccardi}@dit.unitn.it
?Institute of Computer Science. Polish Academy of Science.
jwisniewska@poczta.uw.edu.pl
Abstract
The LUNA corpus is a multi-lingual, multi-
domain spoken dialogue corpus currently
under development that will be used to de-
velop a robust natural spoken language un-
derstanding toolkit for multilingual dialogue
services. The LUNA corpus will be an-
notated at multiple levels to include an-
notations of syntactic, semantic, and dis-
course information; specialized annotation
tools will be used for the annotation at each
of these levels. In order to synchronize these
multiple layers of annotation, the PAULA
standoff exchange format will be used. In
this paper, we present the corpus and its
PAULA-based architecture.1
1 Introduction
XML standoff markup (Thompson and McKelvie,
1997; Dybkj?r et al, 1998) is emerging as the clean-
est way to organize multi-level annotations of cor-
pora. In many of the current annotation efforts based
on standoff a single multi-purpose tool such as the
NITE XML Toolkit (Carletta et al, 2003) or Word-
Freak (Morton and LaCivita, 2003) is used to anno-
1The members of the LUNA project consortium are: Pied-
mont Consortium for Information Systems (IT), University of
Trento (IT), Loquendo SpA (IT), RWTH-Aachen (DE), Uni-
versity of Avignon (FR), France Telecom R&D Division S.A.
(FR), Polish-Japanese Institute of Information Technology (PL)
and the Institute for Computer Science of the Polish Academy
of Sciences (PL), http://www.ist-luna.eu.
This research was performed in the LUNA project funded by the
EC, DG Infso, Unit E1 and in the Collaborative Research Cen-
ter 632 ?Information Structure?, funded by the German Science
Foundation, http://www.sfb632.uni-potsdam.de.
tate as well as maintain all annotation levels (cf. the
SAMMIE annotation effort (Kruijff-Korbayova? et al,
2006b)).
However, it is often the case that specialized tools
are developed to facilitate the annotation of particu-
lar levels: examples include tools for segmentation
and transcription of the speech signal like PRAAT
(Boersma and Weenink, 2005) and TRANSCRIBER
(Barras et al, 1998), the SALSA tools for FrameNet-
style annotation (Burchardt et al, 2006), and MMAX
(Mu?ller and Strube, 2003) for coreference annota-
tion. Even in these cases, however, it may still be
useful, or even necessary, to be able to visualize
more than one level at once, or to ?knit? together2
multiple levels to create a file that can be used to
train a model for a particular type of annotation.
The Linguistic Annotation Framework by (Ide et al,
2003) was proposed as a unifying markup format to
be used to synchronize heterogeneous markup for-
mats for such purposes.
In this paper, we discuss how the PAULA represen-
tation format, a standoff format inspired by the Lin-
guistic Annotation Framework, is being used to syn-
chronize multiple levels of annotation in the LUNA
corpus, a corpus of spoken dialogues in multiple lan-
guages and multiple domains that is being created to
support the development of robust spoken language
understanding models for multilingual dialogue ser-
vices. The corpus is richly annotated with linguistic
information that is considered relevant for research
on dialogue, including chunks, named entities, argu-
ment structure, coreference, and dialogue acts. We
chose to adopt specialized tools for each level: e.g.,
2In the sense of the knit tool of the LT-XML suite.
148
transcription using TRANSCRIBER, coreference us-
ing MMAX, attributes using SEMANTIZER, etc. To
synchronize the annotation and allow cross-layer op-
erations, the annotations are mapped to a common
representation format, PAULA.
The structure of the paper is as follows. In Sec-
tion 2, we present the LUNA project and the LUNA
corpus with its main annotation levels. In Section 3,
we introduce the PAULA exchange format, focusing
on the representation of time alignment and dialogue
phenomena. Finally we show how PAULA is used in
the LUNA corpus and discuss alternative formats.
2 The LUNA project
The aim of the LUNA project is to advance the state
of the art in understanding conversational speech
in Spoken Dialogue Systems (Gupta et al, 2005),
(Bimbot et al, 2006).
Three aspects of Spoken Language Understand-
ing (SLU) are of particular concern in LUNA: gen-
eration of semantic concept tags, semantic compo-
sition into conceptual structures and context sensi-
tive validation using information provided by the di-
alogue manager. In order to train and evaluate SLU
models, we will create an annotated corpus of spo-
ken dialogues in multiple domains and multiple lan-
guages: French, Italian, and Polish.
2.1 The LUNA corpus
The LUNA corpus is currently being collected, with
a target to collect 8100 human-machine dialogues
and 1000 human-human dialogues in Polish, Italian
and French. The dialogues are collected in the fol-
lowing application domains: stock exchange, hotel
reservation and tourism inquiries, customer support
service/help-desk and public transportation.
2.2 Multilevel annotation
Semantic interpretation involves a number of sub-
tasks, ranging from identifying the meaning of indi-
vidual words to understanding which objects are be-
ing referred to up to recovering the relation between
different semantic objects in the utterance and dis-
course level to, finally, understanding the commu-
nicative force of an utterance.
In some annotation efforts?e.g., in the annotation
of the French MEDIA Corpus (Bonneau-Maynard
and Rosset, 2003)? information about the meaning
of semantic chunks, contextual information about
coreference, and information about dialogue acts are
all kept in a single file. This approach however suf-
fers from a number of problems, including the fact
that errors introduced during the annotation at one
level may make other levels of annotation unusable
as well, and that it is not possible for two anno-
tators to work on different types of annotation for
the same file at the same time. Most current an-
notation efforts, therefore, tend to adopt the ?multi-
level? approach pioneered during the development
of the MAPTASK corpus and then developed as part
of work on the EU-funded MATE project (McKelvie
et al, 2001), in which each aspect of interpreta-
tion is annotated in a separate level, independently
maintained. This approach is being followed, for
instance, in the ONTONOTES project (Hovy et al,
2006) and the SAMMIE project (Kruijff-Korbayova
et al, 2006a).
For the annotation of the LUNA corpus, we de-
cided to follow the multilevel approach as well. That
allows us to achieve more granularity in the anno-
tation of each of the levels and to investigate more
easily dependencies between features that belong to
different levels. Furthermore, we can use different
specialized off-the-shelf annotation tools, splitting
up the annotation task and thus facilitating consis-
tent annotation.
2.3 Annotation levels
The LUNA corpus will contain different types of in-
formation. The first levels are necessary to prepare
the corpus for subsequent semantic annotation, and
include segmentation of the corpus in dialogue turns,
transcription of the speech signal, and syntactic pre-
processing with POS-tagging and shallow parsing.
The next level consists of the annotation of do-
main information using attribute-value pairs. This
annotation will be performed on all dialogues in the
corpus.
The other levels of the annotation scheme are not
mandatory, but at least a part of the dialogues will
be annotated in order to investigate contextual as-
pects of the semantic interpretation. These levels in-
clude the predicate structure, the relations between
referring expressions, and the annotation of dialogue
acts.
149
2.3.1 Segmentation and transcription of the
speech signal
Before transcription and annotation can begin, it
is necessary to segment the speech signal into dia-
logue turns and annotate them with speaker identity
and mark where speaker overlap occurs. The goal
of this segmentation is to be able to perform a tran-
scription and annotation of the dialogue turns with
or without dialogue context. While dialogue context
is preferable for semantic annotation, it slows down
the annotation process.
The tool we will use for the segmentation and
transcription of the speech signal is the open source
tool TRANSCRIBER3 (Barras et al, 1998).
The next step is the transcription of the speech
signal, using conventions for the orthographic tran-
scription and for the annotation of non-linguistic
acoustic events.
2.3.2 Part Of Speech Tagging and Chunking
The transcribed material will be annotated with
POS-tags, morphosyntactic information like agree-
ment features, and segmented based on syntactic
constituency.
For the POS-tags and morphosyntactic features,
we will follow the recommendations made in EA-
GLES (EAGLES, 1996), which allows us to have a
unified representation format for the corpus, inde-
pendently of the tools used for each language.
2.3.3 Domain Attribute Annotation
At this level, semantic segments will be anno-
tated following an approach used for the annotation
for the French MEDIA dialogue corpus (Bonneau-
Maynard and Rosset, 2003).
We specify the domain knowledge in domain on-
tologies. These are used to build domain-specific
dictionaries. Each dictionary contains:
? Concepts corresponding to classes of the ontol-
ogy and attributes of the annotation.
? Values corresponding to the individuals of the
domain.
? Constraints on the admissible values for each
concept.
3http://trans.sourceforge.net
The concept dictionaries are used to annotate se-
mantic segments with attribute-value pairs. The se-
mantic segments are produced by concatenation of
the chunks produced by the shallow parser. A se-
mantic segment is a unit that corresponds unambigu-
ously to a concept of the dictionary.
(1) buongiorno lei [puo` iscriversi]concept1 [agli
esami]concept2 [oppure]concept3 [ottenere
delle informazioni]concept4 come la posso
aiutare4
<concept1 action:inscription>
<concept2 objectDB:examen>
<concept3 conjunctor:alternative>
<concept4 action:obtain info>
2.3.4 Predicate structure
The annotation of predicate structure facilitates
the interpretation of the relation between entities and
events occurring in the dialogue.
There are different approaches to annotate predi-
cate structure. Some of them are based upon syntac-
tic structure, with PropBank (Kingsbury and Palmer,
2003) being one of the most relevant, building the
annotation upon the syntactic representation of the
TreeBank corpus (Marcus et al, 1993). An alter-
native to syntax-driven approaches is the annotation
using semantic roles as in FrameNet (Baker et al,
1998).
For the annotation of predicate structure in the
LUNA corpus, we decided to use a FrameNet-like
approach, rather than a syntax-based approach:
1. Annotation of dialogue interaction has to deal
with disfluencies, non-complete sentences, un-
grammaticality, etc., which complicates the use
of deep syntactic representations.
2. If we start from a syntactic representation, we
have to follow a long way to achieve the seman-
tic interpretation. Syntactic constituents must
be mapped to ?-roles, and then to semantic
roles. FrameNet offers the possibility of anno-
tating using directly semantic criteria.
4Good morning, you can register for the exam or obtain in-
formation. How can I help you?
150
For each domain, we define a set of frames. These
frames are defined based on the domain ontology,
with the named entities providing the frame ele-
ments. For all the frames we introduce the negation
as a default frame element.
For the annotation, first of all we annotate the en-
tities with a frame and a frame element.
Then if the target is overtly realized we make a
pointer from the frame elements to the target. The
next step is putting the frame elements and the target
(if overtly realized) in a set.
(2) buongiorno [lei]fe1 [puo` iscriversi]fe2
[agli esami]fe3 oppure [ottenere delle
informazioni]fe4 come la posso aiutare
set1 = {id1, id2, id3}
frame: inscription
frame-elements:{student, examen, date}
set2 = {id4}
frame = info-request
frame-elements:{student, addressee, topic}
<fe1 frame="inscription"
FE="student" member="set1"
pointer="fe2">
<fe2 frame="inscription"
FE="target" member="set1">
<fe3 frame="inscription"
FE="examen" member="set1"
pointer="fe2">
<fe4 frame="information"
FE="target" member="set2">
2.3.5 Coreference / Anaphoric relations
To annotate anaphoric relations we will use an an-
notation scheme close to the one used in the ARRAU
project (Artstein and Poesio, 2006). This scheme
has been extensively tested with dialogue corpora
and includes instructions for annotating a variety of
anaphoric relations, including bridging relations. A
further reason is the robustness of the scheme that
doesn?t require one single interpretation in the an-
notation.
The first step is the annotation of the information
status of the markables with the tags given and
new. If the markables are annotated with given,
the annotator will select the most recent occurrence
of the object and add a pointer to it. If the mark-
able is annotated with new, we distinguish between
markables that are related to a previously mentioned
object (associative reference) or don?t have such a
relation.
If there are alternative interpretations, which of a
list of candidates can be the antecedent, the annota-
tor can annotate the markable as ambiguous and
add a pointer to each of the possible antecedents.
(3) Wizard: buongiorno [lei]cr1 [puo`
iscriversi]cr2 [agli esami]cr3 oppure ot-
tenere [delle informazioni]cr4 come la posso
aiutare
<cr1 inf status="new" related="no">
<cr2 inf status="new" related="no">
<cr3 inf status="new" related="no">
<cr4 inf status="new" related="no">
Caller: [iscrizione]cr5 [esami]cr65
<cr5 inf status="given"
single phrase antecedent="cr2"
ambiguity="unambiguous">
<cr6 inf status="given"
single phrase antecedent="cr3"
ambiguity="unambiguous">
2.3.6 Dialogue acts
In order to associate the intentions of the speaker
with the propositional content of the utterances, the
segmentation of the dialogue turns in utterances is
based on the annotation of predicate structure. Each
set of frame elements will correspond to an utter-
ance.
Each utterance will be annotated using a multi-
dimensional annotation scheme partially based on
the DAMSL scheme (Allen and Core, 1997) and on
the proposals of ICSI-MRDA (Dhillon et al, 2004).
We have selected nine dialogue acts from the
DAMSL scheme as initial tagset, that can be extended
for the different application domains. Each utter-
ance will be annotated with as many tags as applica-
ble.
(4) Wizard: [buongiorno]utt1 [lei puo` iscriversi
agli esami]utt2 oppure [ottenere delle
5Register for the exam.
151
informzaioni]utt3 [come la posso aiutare]utt4
<utt1 d-act="opening/closing">
<utt2 d-act="statement"
link-frame="set1">
<utt3 d-act="statement"
link-frame="set2">
<utt4 d-act="info-request">
Caller: [iscrizione esami]utt5
<utt5 d-act="answer;statement"
link-frame="set3">
3 PAULA - a Linguistic Standoff Exchange
Format
PAULA stands for Potsdamer Austauschformat fu?r
linguistische Annotation (?Potsdam Interchange
Format for Linguistic Annotation?) and has been de-
veloped for the representation of data annotated at
multiple layers. The application scenario is sketched
in Fig 1: researchers use multiple, specialized off-
the-shelf annotation tools, such as EXMARALDA or
MMAX, to enrich data with linguistic information.
The tools store the data in tool-specific formats and,
hence, it is not straightforward to combine informa-
tion from different sources and, e.g., to search for
correlations across multiple annotation layers.
This is where PAULA comes in: PAULA maps
the tool-specific formats to a common format and
serves as an interchange format between these
tools.6 Moreover, the annotations from the different
sources are merged into one single representation.
PAULA makes this data available for further appli-
cations, such as searching the data by means of the
tool ANNIS7, or to feed statistical applications like
WEKA8.
PAULA is an XML-based standoff format for lin-
guistic annotations, inspired by the ?dump format?
6Currently, we provide PAULA import filters for the follow-
ing tools and formats: Exmaralda, MMAX, RST Tool/URML,
annotate/TIGER XML. Export from PAULA to the tool formats
is at present supported for the original source format only. We
plan to support the export of selected annotations to other tools.
This is, however, not a trivial task since it may involve loss of
information.
7ANNIS: http://www.sfb632.uni-potsdam.de/
annis
8WEKA: http://www.cs.waikato.ac.nz/ml/
weka
Figure 1: PAULA annotation scenario
of the Linguistic Annotation Framework (Ide et al,
2003).9 With PAULA, not only is the primary data
separated from its annotations, but individual anno-
tation layers (such as parts of speech and dialogue
acts) are separated from each other as well. The
standoff approach allows us to mark overlapping
segments in a straightforward way: by distributing
annotations over different files (XML as such does
not easily account for overlapping segments, since
its object model is a hierarchical, tree-like structure).
Moreover, new annotation layers can be added eas-
ily.
PAULA assumes that a representation of the pri-
mary data is stored in a file that optionally spec-
ifies a header with meta information, followed by
a tag <body>, which contains a representation of
the primary data. In Fig. 2, the first box displays
the transcription, with all contributions from the first
speaker coming first, and the contributions from the
other speaker(s) following (put in italics in the Fig-
ure).
The basic type of ?annotation? are markables, en-
coded by the XML element <mark>. Markables
specify ?anchors?, i.e., locations or ranges that can
be annotated by linguistic information. The loca-
tions and ranges are positions or spans in the source
text or timeline, which are referenced by means of
XLinks and XPointer expressions. For instance, the
?Token? markables in Fig. 2 define spans that cor-
9The term ?standoff? describes the situation where primary
data (e.g., the transcription) and annotations of this data are
stored in separate files (Thompson and McKelvie, 1997).
152
 

	
	

On the use of confidence for statistical decision in dialogue strategies
Christian Raymond1 Fre?de?ric Be?chet1 Renato de Mori1 Ge?raldine Damnati2
1 LIA/CNRS, University of Avignon France 2 France Telecom R&D, Lannion, France
christian.raymond,frederic.bechet,renato.demori@lia.univ-avignon.fr
geraldine.damnati@rd.francetelecom.com
Abstract
This paper describes an interpretation and deci-
sion strategy that minimizes interpretation er-
rors and perform dialogue actions which may
not depend on the hypothesized concepts only,
but also on confidence of what has been rec-
ognized. The concepts introduced here are ap-
plied in a system which integrates language
and interpretation models into Stochastic Finite
State Transducers (SFST). Furthermore, acous-
tic, linguistic and semantic confidence mea-
sures on the hypothesized word sequences are
made available to the dialogue strategy. By
evaluating predicates related to these confi-
dence measures, a decision tree automatically
learn a decision strategy for rescoring a n-best
list of candidates representing a user?s utter-
ance. The different actions that can be then per-
formed are chosen according to the confidence
scores given by the tree.
1 Introduction
There is a wide consensus in the scientific community
that human-computer dialogue systems based on spoken
natural language make mistakes because the Automatic
Speech Recognition (ASR) component may not hypothe-
size some of the pronounced words and the various levels
of knowledge used for recognizing and reasoning about
conceptual entities are imprecise and incomplete. In spite
of these problems, it is possible to make useful applica-
tions with dialogue systems using spoken input if suit-
able interpretation and decision strategies are conceived
that minimize interpretation errors and perform dialogue
actions which may not depend on the hypothesized con-
cepts only, but also on confidence of what has been rec-
ognized.
This paper introduces some concepts developed for
telephone applications in the framework of stochastic
models for interpretation and dialogue strategies, a good
overview of which can be found in (Young, 2002).
The concepts introduced here are applied in a system
which integrates language and interpretation models into
Stochastic Finite State Transducers (SFST). Furthermore,
acoustic, linguistic and semantic confidence measures on
the hypothesized word sequences are made available to
the dialogue strategy. A new way of using them in the
dialogue decision process is proposed in this paper.
Most of the Spoken language Understanding Systems
(SLU) use semantic grammars with semantic tags as non-
terminals (He and Young, 2003) with rules for rewriting
them into strings of words.
The SFSTs of the system used for the experiments de-
scribed here, represent knowledge for the basic building
blocks of a frame-based semantic grammar. Each block
represents a property/value relation. Different SFSTs
may share words in the same sentence. Property/value
hypotheses are generated with an approach described in
(Raymond et al, 2003) and are combined into a sentence
interpretation hypothesis in which the same word may
contribute to more than one property/value pair. The di-
alogue strategy has to evaluate the probability that each
component of each pair has been correctly hypothesized
in order to decide to perform an action that minimizes the
risk of user dissatisfaction.
2 Overview of the decoding process
The starting point for decoding is a lattice of word
hypotheses generated with an n-gram language model
(LM). Decoding is a search process which detects com-
binations of specialized SFSTs and the n-gram LM. The
output of the decoding process consists of a n-best list
of conceptual interpretations ?. An interpretation ? is
a set of property/value pairs sj = (cj, vj) called con-
cepts. cj is the concept tag and vj is the concept value
of sj . Each concept tag cj is represented by a SFST and
can be related either to the dialogue application (phone
number, date, location expression, etc.) or to the dia-
logue management (confirmation, contestation, etc.). To
each string of words recognized by a given SFST cj is
associated a value vj representing a normalized value
for the concept detected. For example, to the word
phrase: on July the fourteenth, detected by a
SFST dedicated to process dates, is associated the value:
????/07/14.
The n-best list of interpretations output by the decod-
ing process is structured according to the different con-
cept tag strings that can be found in the word lattice. To
each concept tag string is attached another n-best list on
the concept values. This whole n-best is called a struc-
tured n-best. After presenting the statistical model used
in this study, we will describe the implementation of this
decoding process.
3 Statistical model
The contribution of a sequence of words W to a concep-
tual structure ? is evaluated by the posterior probability
P (? | Y ), where Y is the description of acoustic features.
Such a probability is computed as follows:
P (? | Y ) =
?
W?SW P (Y | W )P (? | W )
?P (W )?
?
W?SW P (Y | W )P (W )?
(1)
where P (Y | W ) is provided by the acoustic models,
P (W ) is computed with the LM. Exponents ? and ? are
respectively a semantic and a syntactic fudge factor. SW
corresponds to the set of word strings that can be found in
the word lattice. P (? | W ) is computed by considering
that thus:
P (? | W ) = P (s1 | W ).
J
?
j=2
P (sj | sj?11 W ) (2)
P (sj | sj?11 W ) ? P (sj | W )
If the conceptual component sj is hypothesized with
a sentence pattern pij(W ) recognized in W and pik(W )
triggers a pair sk and there is a training set with which
the probabilities P (pik(W ) | sk) ?k, can be estimated,
then the posterior probability can be obtained as follows:
P (sj | W ) =
P (pij(W ) | sj)P (sj)
?K
k=1 P (pik(W ) | sk)P (sk)
(3)
where P (sk) is a unigram probability of conceptual
components.
4 Structured N-best list
N-best lists are generally produced by simply enumerat-
ing the n best paths in the word graphs produced by Au-
tomatic Speech Recognition (ASR) engines. The scores
used in such graphs are usually only a combination of
acoustic and language model scores, and no other linguis-
tic levels are involved. When an n-best word hypothesis
list is generated, the differences between the hypothesis
i and the hypothesis i+1 are often very small, made of
only one or a few words. This phenomenon is aggravated
when the ASR word graph contains a low confidence
area, due for example to an Out-Of-Vocabulary word, to
a noisy input or to a speech disfluency.
This is the main weakness of this approach in a Spoken
Dialogue context: not all words are important to the Di-
alogue Manager, and all the n-best word hypotheses that
differ only between each other because of some speech
disfluency effects can be considered as equals. That?s
why it is important to generate not only a n-best list of
word hypotheses but rather a n-best list of interpretations,
each of them corresponding to a different meaning from
the Dialogue Manager point of view.
We propose here a method for directly extracting such
a structured n-best from a word lattice output by an ASR
engine. This method relies on operations between Finite
State Machines and is implemented thanks to the AT&T
FSM toolkit (see (Mohri et al, 2002) for more details).
4.1 Word-to-Concept transducer
Each concept ck of the dialogue application is associated
with an FSM. These FMSs are called acceptors (Ak for
the concept ck). In order to process strings of words that
don?t belong to any concept, a filler model, called AF
is used. Because the same string of words can?t belong
to both a concept model and the background text, all the
paths contained in the acceptors Ak are removed from the
filler model AF in the following way:
AF = ? ? ?
m
?
k=1
Ak
where ? is the word lexicon of the application and m
is the number of concepts used.
All these acceptors are now turned into transducers
that take words as input symbols and start or end con-
cept tags as output symbols. Indeed, all acceptors Ak be-
come transducers Tk where the first transition emits the
symbol <Ck> and the last transition the symbol </Ck>.
Similarly the filler model becomes the transducer Tbk
which emits the symbols <BCK> and </BCK>. Except
these start and end tags, no other symbols are emitted: all
words in the concept or background transducers emit an
empty symbol.
Finally all these transducers are linked together in a
single model called Tconcept as presented in figure 1.
FILLER
out=<BCK>
in=<start>
out=<>
in=<> in=<>
out=</BCK>
in=<end>
out=<>
out=<>
in=<start>
out=<>
in=w1
in=w2
out=<>
in=<end>
out=<>
in=<>
out=</C1>out=<C1>
in=<>
out=<C2>
in=<>
out=</C2>
in=<>
in=<>
out=<Cn>
in=<>
out=</Cn>
in=<>
out=<>
in=<>
out=<>in=<>
out=<>
SFST C1
SFST Cn
SFST C2
Figure 1: Word-to-Concept Transducer
4.2 Processing the ASR word lattice
The ASR word lattice is coded by an FSM: an acceptor L
where each transition emits a word. The cost function for
a transition corresponds to the acoustic score of the word
emitted.
The first step in the word lattice processing consists
of rescoring each transition of L by means of a 3-gram
Language Model (LM) in order to obtain the probabili-
ties P (W ) of equation 1. This is done by composing the
word lattice with a 3-gram LM also coded as an FSM (see
(Allauzen et al, 2003) for more details about statistical
LMs and FSMs).
The resulting FSM is then composed with the trans-
ducer TConcept in order to obtain the word-to-concept
transducer L?. A path in L? corresponds to a word string
if only the input symbols of the transducer are considered
and its score is the one expressed by equation 1; simi-
larly by considering only the output symbols, a path in L?
corresponds to a concept tag string.
The structured n-best list is directly obtained from L?:
by extracting the n-best concept tag strings (output label
paths) we obtain an n-best list on the conceptual interpre-
tations. The score of each conceptual interpretation is the
sum of all the word strings (input label paths) in the word
lattice producing the same interpretation.
Finally, for every conceptual interpretations C kept at
the previous step, a local n-best list on the word strings is
calculated by selecting in L? the best paths outputting the
string C .
The resulting structured n-best is illustrated by the fol-
lowing example. If we keep the 2 best conceptual in-
terpretations C1, C2 of a transducer L? and, for each of
these, the 2 best word strings, we obtain:
1 : C1 = <c1_1,c1_2,..,c1_x>
1.1 : W1.1 = <v1.1_1,v1.1_2,..,v1.1_x>
1.2 : W1.2 = <v1.2_1,v1.2_2,..,v1.2_x>
2 : C2 = <c2_1,c2_2,..,c2_y>
2.1 : W2.1 = <v2.1_1,v2.1_2,..,v2.1_y>
2.2 : W2.2 = <v2.2_1,v2.2_2,..,v2.2_y>
where <ci_1,ci_2,..,ci_y> is the conceptual
interpretation at the rank i in the n-best list; Wi.j is the
word string ranked j of interpretation i; and vi.j_k
is the concept value of the kth concept ci_k of the jth
word string of interpretation i.
5 Use of correctness probabilities
In order to select a particular interpretation ? (concep-
tual interpretation + concept values) from the structured
n-best list, we are now interested in computing the proba-
bility that ? is correct, given a set of confidence measures
M : P (? | M ). The choice of the confidence measures
determines the quality of the decision strategy. Those
used in this study are briefly presented in the next sec-
tions.
5.1 Confidence measures
5.1.1 Acoustic confidence measure (AC)
This confidence measure relies on the comparison of
the acoustic likelihood provided by the speech recogni-
tion model for a given hypothesis to the one that would
be provided by a totally unconstrained phoneme loop
model. In order to be consistent with the general model,
the acoustic units are kept identical and the loop is over
context dependent phonemes. This confidence measure
is used at the utterance level and at the concept level (see
(Raymond et al, 2003) for more details).
5.1.2 Linguistic confidence measure (LC)
In order to assess the impact of the absence of ob-
served trigrams as a potential cause of recognition errors,
a Language Model consistency measure is introduced.
This measure is simply, for a given word string candi-
date, the ratio between the number of trigrams observed
in the training corpus of the Language Model vs. the total
number of trigrams in the same word string. Its computa-
tion is very fast and the confidence scores obtained from
it give interesting results as presented in (Este`ve et al,
2003).
5.1.3 Semantic confidence measure (SC)
Several studies have shown that text classification tools
(like Support Vector Machines or Boosting algorithms)
can be an efficient way of labeling an utterance transcrip-
tion with a semantic label such as a call-type (Haffner et
al., 2003) in a Spoken Dialogue context. In our case, the
semantic labels attached to an utterance are the different
concepts handled by the Dialogue Manager. One classi-
fier is trained for each concept tag in the following way:
Each utterance of a training corpus is labeled with a
tag, manually checked, indicating if a given concept oc-
curs or not in the utterance. In order to let the classi-
fier model the context of occurrence of a concept rather
than its value we removed most of the concept headwords
from the list of criterion used by the classifier.
During the decision process, if the interpretation eval-
uated contains 2 concepts c1 and c2, then the classifiers
corresponding to c1 and c2 are used to give to the utter-
ance a confidence score of containing these two concepts.
The text classifier used in the experimental section
is a decision-tree classifier based on the Semantic-
Classification-Trees introduced for the ATIS task
by (Kuhn and Mori, 1995) and used for semantic disam-
biguation in (Be?chet et al, 2000).
5.1.4 Rank confidence measure (R)
To the previous confidence measures we added the
rank of each candidate in its n-best. This rank contains
two numbers: the rank of the interpretation of the utter-
ance and the rank of the utterance among those having
the same interpretation.
5.2 Decision Tree based strategy
As the dependencies of these measures are difficult to es-
tablish, their values are transformed into symbols by vec-
tor quantization (VQ) and conjunctions of these symbols
expressing relevant statistical dependencies are obtained
by a decision tree which is trained with a development
set of examples. At the leaves probabilities P (M |?) are
obtained when ? represents any correct hypothesis, the
case in which only the properties have been correctly rec-
ognized or both properties and values have errors. With
these probabilities we are now able to estimate P (? | M )
in the following way:
P (? | M) = 1
1 + P (M |??)P (??)P (M |?)P (?)
(4)
where ?? indicates that the interpretation in question is
incorrect and P (M |??) = 1 ? P (M |?).
6 From hypotheses to actions
Once concepts have been hypothesized, a dialog system
has to decide what action to perform. Let A = aj be
the set of actions a system can perform. Some of them
can be requests for clarification or repetition. In partic-
ular, the system may request the repetition of the entire
utterance. Performing an action has a certain risk and the
decision about the action to perform has to be the one that
minimizes the risk of user dissatisfaction.
It is thus possible that some or all the hypothesized
components of a conceptual structure ? do not corre-
spond to the user intention because the word sequence
W based on which the conceptual hypothesis has been
generated contains some errors. In particular, there are
requests for clarification or repetition which should be
performed right after the interpretation of an utterance in
order to reduce the stress of the user. It is important to
notice that actions consisting in requests for clarification
or repetition mostly depend on the probability that the in-
terpretation of an utterance is correct, rather than on the
utterance interpretation.
The decoding process described in section 2 provides
a number of hypotheses containing a variable number of
pairs sj = (cj, vj) based on the score expressed by equa-
tion 1.
P (? | M ) is then computed for these hypotheses. The
results can be used to decide to accept an interpretation
or to formulate a clarification question which may imply
more hypotheses.
For simplification purpose, we are going to consider
here only two actions: accepting the hypothesis with the
higher P (? | M ) or rejecting it. The risk associated to the
acceptation decision is called ?fa and corresponds to the
cost of a false acceptation of an incorrect interpretation.
Similarly the risk associated to the rejection decision is
called ?fr and corresponds to the cost of a false rejection
of a correct interpretation. In a spoken dialogue context,
?fa is supposed to be higher than ?fr .
The choice of the action to perform is determined by
a threshold ? on P (? | M ). This threshold is tuned on
a development corpus by minimizing the total risk R ex-
pressed as follows:
R = ?fa ?
Nfa
Ntotal
+ ?fr ?
Nfr
Ntotal
(5)
Nfa and Nfr are the numbers of false acceptation and
false rejection decisions on the development corpus for a
given value of ?. Ntotal is the total number of examples
available for tuning the strategy.
The final goal of the strategy is to make negligible Nfa
and the best set of confidence measures is the one that
minimizes Nfr . In fact, the cost of these cases is lower
because the corresponding action has to be a request for
repetition.
Instead of simply discarding an utterance if P (? | M )
is below ?, another strategy we are investigating consists
of estimating the probability that the conceptual interpre-
tation alone (without the concept values) is correct. This
probability can be estimated the same way as P (? | M )
and can be used to choose a third kind of actions: accept-
ing the conceptual meaning of an utterance but asking for
clarifications about the values of the concepts.
A final decision about the strategy to be adopted should
be based on statistics on system performance to be col-
lected and updated after deploying the system on the tele-
phone network.
7 Experiments
7.1 Application domain
The application domain considered in this study is a
restaurant booking application developed at France Tele-
com R&D. At the moment, we only consider in our strat-
egy the most frequent concepts related to the application
domain: PLACE, PRICE and FOOD TYPE. They can be
described as follows:
? PLACE: an expression related to a restaurant loca-
tion (eg. a restaurant near Bastille);
? PRICE: the price range of a restaurant (eg. less than
a hundred euros);
? FOOD TYPE: the kind of food requested by the
caller (eg. an Indian restaurant).
These entities are expressed in the training corpus by
short sequences of words containing three kinds of to-
ken: head-words like Bastille, concept related words like
restaurant and modifier tokens like near.
A single value is associated to each concept entity
simply be adding together the head-words and some
modifier tokens. For example, the values associated to
the three contexts presented above are: Bastille ,
less+hundred+euros and indian.
In the results section a concept detected is considered a
success only if the tag exists in the reference corpus and if
both values are identical. It?s a binary decision process:
a concept can be considered as a false detection even if
the concept tag is correct and if the value is partially cor-
rect. The measure on the errors (insertion, substitution,
deletion) of these concept/value tokens is called in this
paper the Understanding Error Rate, by opposition to the
standard Word Error Rate measure where all words are
considered equals.
7.2 Experimental setup
Experiments were carried out on a dialogue corpus pro-
vided by France Telecom R&D. The task has a vocabu-
lary of 2200 words. The language model used is made
of 44K words. For this study we selected utterances cor-
responding to answers to a prompt asking for the kind
of restaurant the users were looking for. This corpus has
been cut in two: a development corpus containing 511
utterances and a test corpus containing 419 utterances.
This development corpus has been used to train the deci-
sion tree presented in section 5.2. The Word Error Rate
on the test corpus is 22.7%.
7.3 Evaluation of the rescoring strategy
Table 1 shows the results obtained with a rescoring strat-
egy that selects, from the structured n-best list, the hy-
pothesis with the highest P (? | M ). The baseline re-
sults are obtained with a standard maximum-likelihood
approach choosing the hypothesis maximizing the proba-
bility P (? | Y ) of equation 1. No rejection is performed
in this experiment.
The size of the n-best lists was set to 12 items: the first
4 candidates of the first 3 interpretations in the structured
n-best list. The gain obtained after rescoring is very sig-
nificant and justify our 2-step approach that first extract
an n-best list of interpretations thanks to P (? | Y ) and
then choose the one with the highest confidence accord-
ing to a large set of confidence measures M . This gain
can be compared to the one obtained on the Word Error
Rate measure: the WER drops from 21.6% to 20.7% af-
ter rescoring on the development corpus and from 22.7%
to 22.5% on the test corpus. It is clear here that the
WER measure is not an adequate measure in a Spoken
Dialogue context as a big reduction in the Understanding
Error Rate might have very little effect on the Word Error
Rate.
Corpus baseline rescoring UER reduction %
Devt. 15.0 12.4 17.3%
Test 17.7 14.5 18%
Table 1: Understanding Error Rate results with and with-
out rescoring on structured n-best lists (n=12) (no rejec-
tion)
7.4 Evaluation of the decision strategy
In this experiment we evaluate the decision strategy con-
sisting of accepting or rejecting an hypothesis ? thanks to
a threshold on the probability P (? | M ). Figure 2 shows
the curve UER vs. utterance rejection on the development
and test corpora. As we can see very significant improve-
ments can be achieved with very little utterance rejection.
For example, at a 5% utterance rejection operating point,
the UER on the development corpus drops from 15.0% to
8.6% (42.6% relative improvement) and from 17.7% to
11.4% (35.6% relative improvement).
By using equation 5 for finding the operating point
minimizing the risk fonction (with a cost ?fa = 1.5 ?
?fr) on the development corpus we obtain:
? on the development corpus: UER=6.5 utterance re-
jection=13.1
? on the test corpus: UER=9.6 utterance rejec-
tion=15.9
46
8
10
12
14
16
18
0 5 10 15 20
un
de
rst
an
din
g e
rro
r r
ate
utterance rejection (%)
devt
test
Figure 2: Understanding Error Rate vs. utterance rejec-
tion on the development and test corpora
8 Conclusion
This paper describes an interpretation and decision strat-
egy that minimizes interpretation errors and perform dia-
logue actions which may not depend on the hypothesized
concepts only, but also on confidence of what has been
recognized. The first step in the process consists of gen-
erating a structured n-best list of conceptual interpreta-
tions of an utterance. A set of confidence measures is
then used in order to rescore the n-best list thanks to a de-
cision tree approach. Significant gains in Understanding
Error Rate are achieved with this rescoring method (18%
relative improvement). The confidence score given by the
tree can also be used in a decision strategy about the ac-
tion to perform. By using this score, significant improve-
ments in UER can be achieved with very little utterance
rejection. For example, at a 5% utterance rejection op-
erating point, the UER on the development corpus drops
from 15.0% to 8.6% (42.6% relative improvement) and
from 17.7% to 11.4% (35.6% relative improvement). Fi-
nally the operating point for a deployed dialogue system
can be chosen by explicitly minimizing a risk function on
a development corpus.
References
Cyril Allauzen, Mehryar Mohri, and Brian Roark. 2003.
Generalized algorithms for constructing statistical lan-
guage models. In 41st Annual Meeting of the Associa-
tion for Computational Linguistics (ACL?03), Sapporo,
Japan.
Fre?de?ric Be?chet, Alexis Nasr, and Franck Genet. 2000.
Tagging unknown proper names using decision trees.
In 38th Annual Meeting of the Association for Compu-
tational Linguistics, Hong-Kong, China, pages 77?84.
Yannick Este`ve, Christian Raymond, Renato De Mori,
and David Janiszek. 2003. On the use of linguistic
consistency in systems for human-computer dialogs.
IEEE Transactions on Speech and Audio Processing,
(Accepted for publication, in press).
Patrick Haffner, Gokhan Tur, and Jerry Wright. 2003.
Optimizing SVMs for complex call classification. In
IEEE International Conference on Acoustics, Speech
and Signal Processing, ICASSP?03, Hong-Kong.
Y. He and S. Young. 2003. A data-driven spoken lan-
guage understanding system. In Automatic Speech
Recognition and Understanding workshop - ASRU?03,
St. Thomas, US-Virgin Islands.
R. Kuhn and R. De Mori. 1995. The application of se-
mantic classification trees to natural language under-
standing. IEEE Trans. on Pattern Analysis and Ma-
chine Intelligence, 17(449-460).
Mehryar Mohri, Fernando Pereira, and Michael Ri-
ley. 2002. Weighted finite-state transducers in
speech recognition. Computer, Speech and Language,
16(1):69?88.
Christian Raymond, Yannick Este`ve, Fre?de?ric Be?chet,
Renato De Mori, and Ge?raldine Damnati. 2003. Belief
confirmation in spoken dialogue systems using confi-
dence measures. In Automatic Speech Recognition and
Understanding workshop - ASRU?03, St. Thomas, US-
Virgin Islands.
Steve Young. 2002. Talking to machines (statisti-
cally speaking). In International Conference on Spo-
ken Language Processing, ICSLP?02, pages 113?120,
Denver, CO.
