Listen-Communicate-Show (LCS): Spoken Language
Command of Agent-based Remote Information Access
Jody J. Daniels and Benjamin Bell
Lockheed Martin Advanced Technology Laboratories
1 Federal Street, A&E 3W
Camden, NJ 08102
{jdaniels, bbell@atl.lmco.com}
ABSTRACT
Listen-Communicate-Show (LCS) is a new paradigm for human
interaction with data sources. We integrate a spoken language
understanding system with intelligent mobile agents that
mediate between users and information sources. We have built
and will demonstrate an application of this approach called
LCS-Marine. Using LCS-Marine, tactical personnel can
converse with their logistics system to place a supply or
information request. The request is passed to a mobile,
intelligent agent for execution at the appropriate database.
Requestors can also instruct the system to notify them when
the status of a request changes or when a request is complete.
We have demonstrated this capability in several field exercises
with the Marines and are currently developing applications of
this technology in new domains.
Keywords
Spoken language understanding, agents, dialogue
management.
1. INTRODUCTION
An LCS system listens for information requests, communicates
both with the user and networked information resources, and
shows a tailored visualization to the individual user. The
LCS-Marine system employs a spoken language understanding
system (SLS) for assisting the user in placing a request and
mobile, intelligent agents for information access to implement
the LCS paradigm. The SLS converses with the user to generate
a request or to check status, amend, or cancel an existing
request. Once sufficient information is obtained from the user,
the SLS launches an agent to accomplish the requested task.
The agent accesses the appropriate databases via whatever
network services are available (including existing tactical
communications networks). Once the agent's tasks are
complete, it returns to the SLS, which generates an appropriate
response to the user. The response may be visual, verbal, or a
combination, depending on the available devices.
2. SYSTEM OVERVIEW
The LCS-Marine system consists of four major components: an
SLS, a collection of agents for information access, real-world
operational databases, and communications networks to
connect the user to the SLS and the agents to the databases.
The underlying architecture for the system is the MIT Galaxy II
conversational architecture [3]. It is a distributed, component-
based middleware product designed to be ?plug and play?.
Specialized servers handle specific tasks, such as translating
audio data to text. All Galaxy II-compliant servers com-
municate with each other through a central server known as the
Hub. The Hub manages flow control, handles traffic among
distributed servers, and provides state maintenance.
In the SLS, speech is sent from the Audio I/O server to the
Recognizer. The top n recognitions are then parsed, prior
context added, and processed using the Natural Language
(NL) servers (Frame Construction and Context Tracking) to
verify the new input's validity and context. The Turn Manager
(TM) determines how to proceed with the conversations and
generates a response. NL (Language Generation) converts it to
text and the Synthesis server generates the verbal response.
The audio server then speaks the waveform file to the user. We
customize the various servers to work with domain specific
issues and application-specific information and training.
Figure 1 shows our LCS architecture.
TINA
Info-
Server
GENESIS
Text-to-Speech
Conversion
Text-to-Speech
Conversion
HUB
SUMMIT
SAPI
Audio
Server
Audio
Server
Context
Tracking
Context
Tracking
Speech
Recognition
Speech
Recognition
Frame
Construction
Fra e
Construction
Language
Generation
Language
Generation
Turn
Manager
Turn
anager
Agent
Server
Agent
Server
Figure 1.  The LCS-Marine architecture.
We have integrated an additional server into the architecture
to support information access?an Agent server. The Agent
server manages a collection of agents that can be tasked to
accomplish a variety of missions, including migration to
distant machines with possibly different operating systems to
gather information or to monitor and report events [2].  
Typically, the Agent server receives its tasking from the TM
and supplies the TM with information from the data source(s).
For persistent tasks, the Agent server becomes the initiator of a
dialogue to inform the user of specific events by passing agent
reports to the TM. When a visual display is present, the Agent
server will dispatch an agent to pass the updated information
to the display machine.
For the LCS-Marine application our agents had to interact
with a logistics database that could be between one to one
hundred miles away. We later describe how our agents were
able to reach this live database over the tactical communication
links available.
Users interact with the LCS-Marine system using the voice
capture device appropriate to their organization (telephone,
cell phone, tactical radios, computer headsets, etc.).
3. MARINE COMBAT SERVICE SUPPORT
PROBLEM
Marines work in a dynamic, fluid environment where
requirements and priorities are constantly subject to change.
Under current operations, it might take up to 72 hours before a
Marine in a Combat Service Support Operations Center
(CSSOC) can confirm with a requesting unit that their order i s
in the logistics system. This is due to a lack of resources
available to the tactical units as well as a difficulty in turning
logistics data into information to enable timely analysis and
decision making. For Marines conducting tactical operations,
these restrictions and limited visibility into the supply chain
hamper logistics planning, decision, execution, and assess-
ment. Figure 2 shows the various echelons involved in tactical
Marine logistics operations. It is noteworthy that tactical
units have no organic means of accessing the logistical
databases other than via radio contact with personnel at the
CSSOC.
The focus of the LCS-Marine project is to provide Marines in
the field with this missing visibility into the supply chain.  By
using standard radio protocols and a common form, Marines
can now converse with a system that understands their task
and end goal and can assist them in getting both the
information and supplies they need. Figure 3 shows a sample of
the Rapid Request form, used when placing an order.
Supporting the LCS-Marine domain required understanding
and using proper radio protocols to communicate. It required
the system to understand call signs, military times, grid
coordinates, and special ordinance nomenclature. Additional-
ly, to fully support the dynamic environment, LCS-Marine
needed the ability to understand and translate usages of the
military phonetic alphabet. This alphabet is used to spell
difficult or unusual words. For example, to give the point of
contact for the request as Sergeant Frew, the user could say: ? P
O C is Sergeant I spell Foxtrot Romeo Echo Whiskey over.?
LCS-Marine would convert the phonetic words to the proper
letter combination. This way the vocabulary is potentially
much larger than that used for system training.
Supporting the dynamic aspects of the Marine environment, the
system is speaker independent. This is critical in applications
where the user may change and there is no additional time for
training the system for a new operator.
The recognizer is trained on the domain vocabulary, but not on
individual operator voices. The system also fully supports
natural, conversational dialogue, i.e., the recognizer expects
utterances at a normal rate of speech and the speaker does not
need to enunciate each syllable.
It is important to note that the amount of time spent training
personnel to use the LCS-Marine system is generally less than
10 minutes. After a short introduction, the user is shown a
sample dialogue for familiarization. The user is also given
information about meta-instructions ? how to start over or to
clear their previous statement ? before they begin operation.
4. OPERATIONAL EVALUATION
To measure the effectiveness of the LCS paradigm under
operational conditions?real users placing real requests,
accessing a live database, and using existing communications
links?we conducted a series of Integrated Feasibility
Experiments (IFE). The IFEs ranged from a pilot study that
featured scripted dialogue, replicated databases, and testing in
the lab with prior military personnel, to field experiments
where active duty Marines used the system operationally over
a series of days as their sole means of interaction with the
logistics system for rapid requests. We tested the system?s
support of placing and checking on requests for ammunition
(Class V), fuels (Class III), and subsistence (Class I) supplies.
More on the experimentation protocols can be found in [1] and
[4].
RF LAN
VOICE AND DATA
Rover?s
Sustainment
and
 Distribution
Teams (SDT)
AMMO
PEOPLE
FSSG
CSSOC
(MAIN)
BSSG/CSSD
CSSOC
(MEDIUM)
V
IX
III
I
IV VIII
II
BE01567N10234E TKS ON ROADBE01567N10234E TRPS IN OPENBE01567N10234E 4xTEL?S 12 MTI MOV NE
BE01567N10234E ADA SITE
BE01567N10234E UNK MOV SEBE01567N10234E 4xTEL?SBE01567N10234E 12 MTI MOV NE
UNK MOV SE
BE01567N10234E TKS ON ROAD
CIS
ECS NT
Server(s)
MSSG/MCSSD
CSSOC
(SMALL)
V III
VIII
I
WAN 1-5MBS
Replicated DBMS
Of CSS Data/Status
CIS
BE01567N10234E TKS ON ROADBE01567N10234E TRPS IN OPENBE01567N10234E 4xTEL?SBE01567N10234E 12 MTI MOV NEBE01567N10234E ADA SITEBE01567N10234E UNK MOV SEBE01567N10234E 4xTEL?SBE01567N10234E 12 MTI MOV NE
UNK MOV SEBE01567N10234E TKS ON ROAD
ECS NT
Server(s)
Figure 2.  The Marine logistics ordering chain.
Figure 3.  Partially Complete Rapid Request Form along with a portion of the database.
Over the course of the IFE process we were able to experiment
with differing server configurations as well as varying com-
munications linkages between servers. The most recent IFE
(December 2000) used the server layout shown in Figure 4.  
Win NT/95/98 Linux
Agent
Server
Agent
Dock
Synthesis
Audio-In/Out .wav
Text
Display info*
DB request*
Turn MgmtRecog NL
User?s PCS
Phone/Laptop/Handheld
SLS Server
Laptop/Handheld
*Compressed to
reduce bandwidth
HUB
Agent
Dock
GPS LCS Apps
Display
Dbms
Figure 4.  The physical LCS-Marine server layout.
The ideal configuration of the system would have a Marine
using their organic communications system calling in to a
remote location and communicating with the SLS there. This
would not add any additional cost or hardware to the existing
Marine infrastructure. This operational layout is depicted in
Figure 5. Unfortunately, the current tactical radio, the Single
Channel Ground and Airborne Radio System (SINCGARS),
can create a large amount of channel noise, which alters or
distorts the acoustic signal. Current recognizers can not yet
compensate for this distortion, although there is active
research into solving this problem.
We used a second operational layout to test the system and get
operator feedback on using a spoken language understanding
interface. This layout is depicted in Figure 6. In this layout, we
required the user to beat the same location as the entire SLS
system  and  the agents migrated over the SINCGARS data link
User CSSOC
DB
Database,
Agents
V
I
III
Spoken Language
System, Agents
SINCGARS
(voice)
User Request
SINCGARS
(data)
Mobile Agent
HMMWV
Figure 5.  The ideal LCS-Marine operational layout.
CSSOCUser/HMMWV
Database,
Agents
Spoken Language
System, Agents
SINCGARS
(data)
V I
III
Mobile Agent
DB
Figure 6.  The LCS-Marine actual operational layout.
to reach the logistics database. The recognizer still had to
contend with the issue of a noisy and dynamic background,
but the acoustic distortion was eliminated.
5. CONCLUSION
We have built a system that integrates a spoken language
understanding system with a mobile, intelligent agent system
that allows users in a hostile acoustic environment to place
and access data requests via a conversational interface. LCS-
Marine is speaker independent and requires little training. The
time to accomplish a task is significantly lower than the
manual input method it seeks to enhance, but it can still be
improved. Being able to rapidly access, insert, modify, and
delete requests gives the users greater visibility into the
supply system.
6. ACKNOWLEDGMENTS
Thanks to members of the LCS team: James Denny, Jerry Franke,
Ray Hill, Bob Jones, Steve Knott, Dan Miksch, Kathy Stiller
and Mike Thomas. This research was supported by DARPA
contract N66001-98-D-8507 and Naval contract N47406-99-
C-7033.
7. REFERENCES
[1] Daniels, J. Integrating a Spoken Language System with
Agents for Operational Information Access. In Proc.. o f
Innovative Applications of Artificial Intelligence (IAAI-
2000), August, 2000, Austin, TX.
[2] McGrath, S., Chac?n, D., and Whitebread, K. Intelligent
Mobile Agents in the Military Domain. In Proc.. Of
Autonomous Agents 2000 Workshop on Agents in
Industry. Barcelona, Spain.
[3] Seneff, S., Lau, R., and Polifroni, J. 1999. Organization,
Communication, and Control in the GALAXY-II Conver-
sational System. In Proc.. of Eurospeech ?98. Budapest,
Hungary.
[4] Stibler, K., and Denny, J. A Three-tiered Evaluation Ap-
proach for Interactive Spoken Dialogue Systems. In Proc..
of the Human Language Technology Conference HLT-
2001, Mar, 2001, San Diego, CA.
The Pragmatics of Taking a Spoken Language System Out of the Laboratory
Jody J. Daniels and Helen Wright Hastie
Lockheed Martin Advanced Technology Laboratories
1 Federal Street A&E 3-W
Camden, NJ 08102
 jdaniels, hhastie@atl.lmco.com
Abstract
Lockheed Martin?s Advanced Technology Lab-
oratories has been designing, developing, test-
ing, and evaluating spoken language under-
standing systems in several unique operational
environments over the past five years. Through
these experiences we have encountered numer-
ous challenges in making each system become
an integral part of a user?s operations. In this
paper, we discuss these challenges and report
how we overcame them with respect to a num-
ber of domains.
1 Introduction
Lockheed Martin?s Advanced Technology Laboratories
(LMATL) has been designing, developing, testing, and
evaluating spoken language understanding systems (SLS)
in several unique operational environments over the past
five years. This model of human interaction is referred to
as Listen, Communicate, Show (LCS). In an LCS system,
the computer listens for information requests, communi-
cates with the user and networked information resources
to compute user-centered solutions, and shows tailored
visualizations to individual users. Through developing
these systems, we have encountered numerous challenges
in making each system become an integral part of a user?s
operations. For example, Figure 1 shows the deployment
of a dialogue system for placing Marine supply requests,
which is being used in a tactical vehicle, a HMMWV.
Some of the challenges of creating such spoken lan-
guage systems include giving appropriate responses. This
involves managing the tension between utterance brevity
and giving enough context in a response to build the
user?s trust. Similarly, the length of user utterances must
be succinct enough to convey the correct information
without adding to the signature of the soldier. The system
must be robust when handling out of vocabulary terms
and concepts. It must also be able to adapt to noisy en-
vironments whose parameters change frequently and be
able use input devices and power access unique to each
situation.
Figure 1: LCS Marine on the move
2 Architecture
The LCS Spoken Language systems use the Galaxy ar-
chitecture (Seneff et al, 1999). This Galaxy architecture
consists of a central hub and servers. Each of the servers
performs a specific function, such as converting audio
speech into a text translation of that speech or combin-
ing the user?s past statements with what was said most
recently. The individual servers exchange information by
sending messages through the hub. These messages con-
tain information to be sent to other servers as well as in-
formation used to determine what server or servers should
be contacted next.
Various Galaxy Servers work together to develop a se-
mantic understanding of the user?s statements and ques-
tions. The sound spoken into the microphone, telephone,
or radio is collected by an Audio Server and sent on to
the recognizer. The recognizer translates this wave file
into text, which is sent to a natural language parser. The
parser converts the text into a semantic frame, a repre-
sentation of the statement?s meaning. This meaning rep-
resentation is passed on to another server, the Dialogue
Manager. This server monitors the current context of a
conversation and, based on this context, can prompt the
user for any necessary clarification and present intelligent
responses to the user. Since the Dialogue Manager is
aware of what information has been discussed thus far,
it is able to determine what information is still needed. A
semantic frame is created by the Dialogue Manager and
this is sent through the Language Generation Server to
generate a text response. The text response is then spo-
ken to the user through a speech synthesis server.
To solve the problem of retrieving or placing data
from/in remote and local sources, we gave the sys-
tems below the use of mobile software agents. If user-
requested information is not immediately available, an
agent can monitor the data sources until it is possible to
respond. Users may request a notification or alert when
a particular activity occurs, which may happen at an in-
determinate time in the future. Because of the potentially
significant time lag, it is important to manage dialogue
activity so that the user is only interrupted when the need
for information is more important than the current task
that the user is currently undertaking. This active man-
agement of interruptions aids task management and light-
ens cognitive load (Daniels et al, 2002).
3 Domains
3.1 LCS Marine
One of the first LCS systems to be tested out in the
field was our Marine Logistics spoken dialogue system.
This application sought to connect the Marine in the
field to the Small Unit Logistics (SUL) database, which
maintains current information about supply requisitions.
Warfighters wanted to be able to place requests as well
as check on the status of existing requests without the
need of additional hardware or communicating with a
third party. It was also highly desirable to use existing
communications procedures, so that the training time to
use the system was minimized. The system needed to
be speaker-independent and mixed initiative enabling the
warfighters to develop a sense of trust in the technology.
Marines using the system were able to perform several
tasks. They could create new requests for supplies, with
the system prompting them for information needed to fill
in a request form. They could also modify and delete
previously placed requests and could check on the status
of requests in one of two ways. They could directly ask
about the current status, or they could delegate an agent
to monitor the status of a particular request. It was an
easy addition to the system to add a constraint that the
agent return after a specified time period if no activity oc-
curs on the request, which is also valuable information for
the Marine. These delegated agents travel across a low-
bandwidth SINCGARS radio network from the Marine to
the database and access that database to place, alter, and
monitor supply requisitions.
The challenges in deploying this system to the field
were twofold - building trust in the system so that it
would become part of normal operations and in dealing
with the unique environmental factors. The former pre-
sented the conflicting goals of brevity versus confirming
user inputs. Marines want to restrict their time on the ra-
dio net as much as possible. At the same time they want
to ensure that what they requested is what they were go-
ing to receive. Much time went into defining and refining
system responses that met both needs as best possible.
This involved several sessions with a numerous Marines
evaluating possible dialogue responses. We also spent
much time ensuring that LCS Marine could handle both
proper and malformed radio protocols. Broad coverage of
potential expressions, especially those when under stress,
such as recognition of the liberal use of curse words, led
to greater user ability to successfully interact through the
system.
The second set of challenges, unique environmental
factors, included access while on the move, battlefield
noise, and coping with adverse conditions such as sand
storms. Accessing LCS Marine while on the move meant
using a SINCGARS radio as the input device. Attempts
to use the system by directly collecting speech from a
SINCGARS radio were dropped due to the technological
challenges presented by the distortion introduced by the
radio on the signal. Instead, we installed the majority of
the system on laptops and put these into the HMMWV.
We sent mobile agents over the SINCGARS data link
back to the data sources. This meant securing hardware
in a HMMWV and powering it off of the vehicle?s battery
as illustrated in Figure 1. (Only one laptop was damaged
during testing.) The mobile agents were able to easily
traverse a retransmission link and reach the remote data
source.
Dealing with hugely varying background noise sources
was less of a problem than originally predicted. Fortu-
nately, most of the time that one of these loud events
would occur, users would simply stop talking. Their hear-
ing was impaired and so they would wait for the noise to
abate and then continue the dialogue. On the other hand,
we did encounter several users who, because of the Lom-
bard effect, insisted upon always yelling at the system.
While we did not measure decibel levels, there were a
few times when the system was not able to understand
the user because of background noise.
3.2 Shipboard Information
An LCS system has also been developed to monitor ship-
board system information aboard the Sea Shadow (IX
529), a Naval test platform for stealth, automation, and
control technologies. From anywhere on the ship, per-
sonnel use the on-board intercom to contact this system,
SUSIE (Shipboard Ubiquitous Speech Interface Environ-
ment), to ask about the status of equipment that is located
throughout the ship. Crew members do not have to be
anywhere near the equipment being monitored in order
to receive data. Figure 2 illustrates a sailor using SUSIE
through the ship?s intercom.
Personnel can ask about pressures, temperatures, and
voltages of various pieces of equipment or can delegate
Figure 2: Sailor interacting with SUSIE through the
ship?s intercom
monitoring those measurements (sensor readings) to the
system. A user can request notification of an abnormal
reading by a sensor. This causes the LCS system to dele-
gate a persistent agent to monitor the sensor and to report
the requested data. Should an abnormal reading occur,
the user is contacted by the system, again using the inter-
com.
This domain presented several challenges and oppor-
tunities. Through numerous discussions with users and
presentation of possible dialogues, we learned that the
users would benefit from a system ability to remember,
between sessions, the most recent activity of each user.
This would permit a user to simply log in and request:
?What about now??. SUSIE would determine what had
been this user?s most recent monitoring activity, would
then seek out the current status, and then report it. While
this seems quite simple, there is significant behind-the-
scenes work to store context and make the interaction ap-
pear seamless.
It was necessary to use the organic intercom system in-
stalled in the Sea Shadow for communication with crew
members. Collecting speech data through the intercom
system to pass to SUSIE required linking two DSPs (and
adjusting them) to the hardware for the SLS. Once con-
nected in, the next significant challenge was that of the
varying noise levels. Background noise varied from one
room to the next and even within a single space. We were
not able to use a push-to-talk or hold-to-talk paradigm
because of the inconvenience to the crew members; they
leave the intercom open for the duration of the conversa-
tion. Fortunately, the recognizer (built on MIT?s SUM-
MIT) is able to handle a great deal of a noise and still
hypothesize accurately. To improve the system accuracy,
we will incorporate automatic retraining of the recognizer
on noise each time that a new session begins.
3.3 Battlefield Casualty Reporting System
We are currently developing a new LCS system known
as the Battlefield Casualty Reporting System or BCRS.
The goal of this system is to assist military personnel
in reporting battlefield casualties directly into a main
database. This involves intelligent dialogue to reduce am-
biguity, resolve constraints, and refine searches on indi-
vidual names and the circumstances surrounding the ca-
sualty. Prior knowledge of every individual?s name will
not be possible. The deployment of this system will be
again present many challenges such as noise effects on a
battlefield, effects of stress on the voice, and the ability
to integrate into existing military hardware.
4 Future Work
The areas of research needed to address needs for more
dynamic and robust systems include better, more robust
or partial parsing mechanisms. In addition, systems must
be able to cope with multi-sentence inputs, including the
system?s ability to insert back channel activity. Ease of
domain expansion is important as systems evolve. Vary-
ing environmental factors mean that the systems require
additional noise adaptation or mitigation techniques, in
addition, the ability to switch modes of communication if
one is not appropriate at a given time.
5 Conclusions
We have discussed the pragmatics involved with taking
an SLS system out of the laboratory or away from tele-
phony and placing it in a volatile environment. These sys-
tems have to be robust and be able to cope with varying
input styles and modes as well as be able to modify their
output to the appropriate situation. In addition, the sys-
tems must be an integral part of the technology that is in
current use and be able to withstand adverse conditions.
Satisfying all of these constraints involves active partici-
pation in the development process with the end-users as
well as creative solutions and technological advances.
6 Acknowledgments
This work was supported by DARPA contract N66001-
01-D-6011.
References
Jody Daniels, Susan Regli, and Jerry Franke. 2002. Sup-
port for intelligent interruption and augmented con-
text recovery. In Proceedings of 7th IEEE Conference
on Human Factors and Power Plants, Scottsdate, AZ,
September.
Stephanie Seneff, Ray Lau, and Joe Polifroni. 1999. Or-
ganization, communication, and control in the galaxy-
ii conversational system. In Proceedings for Eu-
rospeech ?98, Budapest, Hungary.
