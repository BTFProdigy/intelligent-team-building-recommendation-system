Proceedings of NAACL HLT 2007, Companion Volume, pages 173?176,
Rochester, NY, April 2007. c?2007 Association for Computational Linguistics
The Effects of Word Prediction on Communication Rate for AAC
Keith Trnka, Debra Yarrington, John McCaw,
and Kathleen F. McCoy
Department of Computer and Information Sciences
University of Delaware Newark, DE 19716
trnka,yarringt,mccaw,mccoy@cis.udel.edu
Christopher Pennington
AgoraNet, Inc.
314 East Main Street, Suite 1
Newark, DE 19711
penningt@agora-net.com
Abstract
Individuals using an Augmentative and
Alternative Communication (AAC) de-
vice communicate at less than 10% of
the speed of ?traditional? speech, creat-
ing a large communication gap. In this
user study, we compare the communica-
tion rate of pseudo-impaired individuals
using two different word prediction algo-
rithms and a system without word pre-
diction. Our results show that word pre-
diction can increase AAC communication
rate and that more accurate predictions
significantly improve communication rate.
1 Introduction
Communication is a significant quality-of-life issue
for individuals with severe speech impairments. The
field of Augmentative and Alternative Communica-
tion (AAC) is concerned with mitigating commu-
nication barriers that would otherwise isolate indi-
viduals from society. Most high-tech AAC devices
provide the user with an electronic letter and word
board to input messages which are output via speech
synthesis. However, even with substantial user inter-
face optimization, communication rate is often less
than 10 words per minute (Newell et al, 1998) as
compared to about 150-200 words per minute for
unimpaired speech.
One way to improve communication rate is to de-
crease the number of keys entered to form a mes-
sage. Word prediction is an application of language
modeling to allowing the user to access words they
may be spelling at a cost of one keystroke. Many
commercial AAC devices use word prediction, such
as PRC?s PathfinderTM, Dynavox Technology?s Dy-
navox 4TM, and Saltillo?s ChatPCTM.
Although word prediction is used in AAC de-
vices, researchers have questioned whether it ac-
tually increases communication rate (Venkatagiri,
1993; Koester and Levine, 1997; Anson et al,
2004). These works note the additional cognitive
demands and cost of using word prediction in con-
junction with a letter-by-letter interface, such as the
need to shift the focus of attention to the prediction
list, the time to scan the prediction list, and the cog-
nitive effort required for making decisions about the
predicted words. Obviously the design of the par-
ticular interface (e.g., the ease of using word pre-
diction) will affect these results. In addition, these
studies used a single, simplistic method of generat-
ing predictions, and this may also be responsible for
some of their results.
In contrast, other researchers (Lesher and Hig-
ginbotham, 2005; Li and Hirst, 2005; Trnka et
al., 2006) have continued to investigate various im-
provements to language modeling for word pre-
diction in order to save the user more keystrokes.
Newer methods such as topic modeling yield sta-
tistically significant keystroke savings over previ-
ous methods. However, the question remains as to
whether improvements in prediction methods trans-
late to an enhanced communication rate. We hypoth-
esize that it will.
In this paper we study (1) whether a word pre-
diction interface increases communication rate over
173
letter-by-letter typing when a reasonable prediction
method is employed and (2) whether an advanced
word prediction method increases communication
rate over a basic word prediction method to a degree
greater than that afforded by the difference in theo-
retical keystroke savings between the two methods.
We expect that the communication rate gain due to
the better word prediction method will exceed the
gains from the poorer system. Our reasons for this
expectation has to do with not only users wasting
time scanning lists that do not contain the desired
word, but also the tendency for a user to give up on
such a system (i.e., choosing to ignore the predic-
tions) and thus missing the predicted word even if it
does appear in the list. Validating these hypotheses
will motivate continued improvements in word pre-
diction methods for increased communication rate.
The target population of our research is adult
AAC users without significant cognitive impair-
ments. Including actual AAC users in the study
poses several significant complications, perhaps the
largest of which concerns the user interface. AAC
devices vary significantly in the physical interfaces
available, in accordance with the variety of physi-
cal abilities of AAC users. This diversity has caused
different word prediction interfaces to be developed
for each physical interface. Moreover, it would be
impossible to mimic our word prediction layout in a
consistent fashion on all of the major AAC devices
used. Because of this, we conducted this pilot study
using subjects that are pseudo-impaired: the subjects
have no motor impairments but we have simulated
a motor impairment by providing an interface that
emulates the communication rate of a typical AAC
user. Future work includes the verification of the re-
sults using a smaller number of actual AAC users.
2 Approach
The purpose of the study was to measure the effects
of word prediction methods on communication rate.
To this end, the interface used for text entry was opti-
mized for ease-of-use and kept constant across trials.
Subjects were asked to enter text on a touchscreen
monitor using WivikTM, an on-screen keyboard. Be-
cause we wanted to simulate AAC users with mo-
tor impairments, we programmed a 1.5 second de-
lay between a key press and its registration in the
system. The artificial impairment gave the subjects
the same incentive to use word prediction that AAC
users face every day, whereas users with fine motor
control tend to ignore word prediction (e.g., in com-
mon word processing software). The delay slows the
input rate of our subjects down to a rate more typical
of AAC users (about 8-10 words per minute).
Seventeen adult, native speakers of English with
no visual, cognitive, or motor impairments partic-
ipated in the study. These subjects were asked to
type in three different excerpts from held-out data of
the Switchboard corpus on three different days.1 In
each of these sessions, a different prediction method
was used and the order of prediction methods was
randomized across subjects. Keystrokes and pre-
dictions were logged and then post-processed to
compute the words produced per minute, seconds
per keystroke, and keystroke savings, among other
statistics.
2.1 Independent variable: prediction methods
The independent variable in our study is the method
of text entry used: (1) letter-by-letter typing using
the Wivik keyboard with no word prediction, (2)
letter-by-letter typing augmented with word predic-
tions produced by a basic prediction method, (3)
letter-by-letter typing augmented with word predic-
tions produced by an advanced prediction method.
Basic prediction generates predictions from the
combination of a recency model of the text entered
so far in conjunction with a large word list. The
recency model is given priority in generating pre-
dictions. This model is similar to language models
used in AAC devices with the exception that many
devices use a unigram model in lieu of a word list.
Advanced prediction generates predictions on
the basis of a trigram model with backoff. A spe-
cial unigram model is used for the first word in
each sentence. This language model is constructed
from the transcribed telephone conversations of the
Switchboard corpus. If the prediction list isn?t filled
from this model?s predictions, then predictions are
selected from a recency model and then a word list,
as in the basic prediction method.
1Switchboard was chosen because our prediction models
were trained using another portion of the corpus. A copy task
was chosen for more controlled experimental conditions.
174
Adv. prediction Basic prediction No prediction
Words per minute (wpm) 8.09 5.50 5.06
Time (seconds) 1316s 1808s 2030s
Seconds per keystroke (spk) 2.92s 2.58s 2.28s
Keystroke savings (ks) 50.3% 18.2% -
Potential keystroke savings (pks) 55.2% 25.0% -
Prediction utilization (pru) 90.9% 73.3% -
Figure 1: Average statistics for each method.
3 Results
Once the data was collected, we post-processed the
logs and accumulated statistics. Average values for
each method are shown in Figure 1 and comparative
values are shown in Figure 2.
3.1 Communication rate (output rate)
The overall average words per minute and task com-
pletion time for each method is shown in Figure 1,
and Figure 2 shows comparative data for the three
methods. As hypothesized, advanced prediction was
found to be significantly faster than basic prediction
and basic prediction was found to be significantly
faster than no prediction (? = 0.01). For example,
users produced 59.9% more words per minute using
advanced prediction compared to no prediction. Ad-
vanced prediction was 44.4% faster than basic pre-
diction but basic prediction was only 10.1% faster
than no prediction.
Additionally, the relative task completion time is
shown in Figure 2. The copy tasks with advanced
prediction were completed in 64.5% of the time it
took to complete without word prediction. The trend
shown with relative task completion time reinforces
the trends shown with words per minute ? advanced
prediction offers a large speedup over no prediction
and basic prediction, but basic prediction offers a
much smaller increase over no prediction.
Our results show that basic word prediction sig-
nificantly boosts communication rate and that ad-
vanced word prediction substantially increases com-
munication rate beyond basic prediction.
3.2 Input rate (seconds per keystroke)
Figures 1 and 2 indicate that there were significant
differences (at ? = 0.01) in the methods in terms
of the rate at which keys were pressed. In partic-
ular, while overall communication rate was signif-
icantly faster with advanced prediction, users took
0.641 seconds longer for each key press from us-
ing advanced prediction compared to entry without
prediction. Similarly, users spent 0.345s longer to
enter each key using advanced as opposed to basic
prediction and basic prediction required more time
per keystroke than no prediction. The slower input
rate can be attributed to the additional demands of
searching through a prediction list and making a de-
cision about selecting a word from that list over con-
tinuing to type letters.
3.3 Keystroke savings / prediction utilization
The difference between the potential keystroke sav-
ings offered by advanced and basic prediction is sub-
stantial: 55.2% vs. 25.0%, as shown in Figure 1.
Accordingly, the actual keystroke savings that users
realized under each prediction method shows a wide
separation: 50.3% for advanced and 18.2% for ba-
sic. The keystroke savings that users of basic predic-
tion achieved seems quite a bit lower than the poten-
tial keystroke savings offered by the predictions. In
other words, the prediction utilization of basic pre-
diction was much lower than that of advanced pre-
diction. Comparative analysis shows a 17.1% im-
provement in prediction utilization from advanced
over basic prediction.
4 Discussion
The results show that communication rate increased
despite the decreased input rate due to a large reduc-
tion in the amount of input required (high keystroke
savings). In the past, researchers have noted that the
cognitive load of using word prediction was consid-
erable, so that the keystroke savings of word pre-
175
Adv. over None Adv. over Basic Basic over None
Relative task completion time 0.6451 0.7011 0.9191
Words per minute (wpm) 59.9% faster2 44.4% faster2 10.1% faster2
Seconds per keystroke (spk) 0.641s2 0.345s2 0.286s2
Prediction utilization (pru) 17.1%2
Figure 2: Average per-subject improvements. (1 Significance not tested. 2 Significant at ? = 0.01.)
diction was outweighed by the overhead of using
it. However, we have shown that despite significant
cognitive load, the reduction in keystroke savings
dominates the effect on output rate.
In contrast to earlier studies, our basic method
showed a significantly improved communication
rate over no prediction. One reason for this could
be the intuitiveness of our user interface. A second
reason could be related to the consistency of the ba-
sic prediction method. In particular, at least some
subjects using the basic prediction method learned
to scan the prediction list when the desired word was
recently used and mentioned it in the exit survey. At
other times they simply ignored the prediction list
and proceeded with letter-by-letter typing. This be-
havior would also explain why the input was sig-
nificantly slower with the advanced method over the
basic method ? users found that scanning the predic-
tion list more often was worth the added effort. This
also explains the significant difference in prediction
utilization between the methods.
The relationship between keystroke savings and
communication rate is a trend of increasing rate
enhancement with increasingly accurate prediction
methods. Improved prediction methods offer greater
potential keystroke savings to users and users see
increased keystroke savings in practice. Addition-
ally, users rely on better predictions more and thus
lose less of the potential keystroke savings offered
by the method. We expect that keystroke savings
will see substantial increases from improved poten-
tial keystroke savings until prediction utilization is
closer to 100%.
5 Conclusions
Word prediction in an experimental AAC device
with simulated AAC users significantly enhances
communication rate. The difference between an ad-
vanced and basic prediction method demonstrates
that further improvements in language modeling for
word prediction are likely to appreciably increase
communication rate. Therefore, further research in
improving word prediction is likely to have an im-
portant impact on quality-of-life for AAC users. We
plan to improve word prediction and validate these
results using AAC users as future work.
Acknowledgments
This work was supported by US Department of Ed-
ucation grant H113G040051.
References
Denis Anson, Penni Moist, Mary Przywars, Heather
Wells, Heather Saylor, and Hantz Maxime. 2004.
The effects of word completion and word prediction
on typing rates using on-screen keyboards. Assistive
Technology, 18.
Heidi Horstmann Koester and Simon P. Levine. 1997.
Keystroke-level models for user performance with
word prediction. Augmentative and Alternative Com-
munication, 13:239?257, December.
Gregory W. Lesher and D. Jeffery Higginbotham. 2005.
Using web content to enhance augmentative commu-
nication. In Proceedings of CSUN 2005.
Jianhua Li and Graeme Hirst. 2005. Semantic knowl-
edge in word completion. In ASSETS ?05, pages 121?
128.
Alan Newell, Stefan Langer, andMarianne Hickey. 1998.
The ro?le of natural language processing in alternative
and augmentative communication. Natural Language
Engineering, 4(1):1?16.
Keith Trnka, Debra Yarrington, Kathleen F. McCoy, and
Christopher A. Pennington. 2006. Topic modeling in
fringe word prediction for aac. In IUI ?06, pages 276?
278.
Horabail S. Venkatagiri. 1993. Efficiency of lexical
prediction as a communication acceleration technique.
Augmentative and Alternative Communication, 9:161?
167, September.
176
Proceedings of the ACL-08: HLT Demo Session (Companion Volume), pages 28?31,
Columbus, June 2008. c?2008 Association for Computational Linguistics
ModelTalker Voice Recorder ? An Interface System for Recording a 
Corpus of Speech for Synthesis 
 
 
Debra Yarrington, John Gray,  
Chris Pennington  
 
H. Timothy Bunnell, Allegra Cornaglia, 
Jason Lilley, Kyoko Nagao,  
James Polikoff,  
AgoraNet, Inc. Speech Research Laboratory 
Newark, DE  19711 A.I. DuPont Hospital for Children 
USA Wilmington, DE  19803, USA 
{yarringt, gray, penningt} 
@agora-net.com 
{bunnell, cornagli, lilley,  
nagao, polikoff}@asel.udel.edu 
 
 
 
 
Abstract 
We will demonstrate the ModelTalker Voice 
Recorder (MT Voice Recorder) ? an interface 
system that lets individuals record and bank a 
speech database for the creation of a synthetic 
voice. The system guides users through an au-
tomatic calibration process that sets pitch, 
amplitude, and silence. The system then 
prompts users with both visual (text-based) 
and auditory prompts. Each recording is 
screened for pitch, amplitude and pronuncia-
tion and users are given immediate feedback 
on the acceptability of each recording. Users 
can then rerecord an unacceptable utterance. 
Recordings are automatically labeled and 
saved and a speech database is created from 
these recordings. The system?s intention is to 
make the process of recording a corpus of ut-
terances relatively easy for those inexpe-
rienced in linguistic analysis. Ultimately, the 
recorded corpus and the resulting speech da-
tabase is used for concatenative synthetic 
speech, thus allowing individuals at home or 
in clinics to create a synthetic voice in their 
own voice. The interface may prove useful  
for other purposes as well. The system facili-
tates the recording and labeling of large cor-
pora of speech, making it useful for speech 
and linguistic research, and it provides imme-
diate feedback on pronunciation, thus making 
it useful as a clinical learning tool.  
 
1 Demonstration 
1.1 MT Voice Recorder Background 
While most of us are familiar with the highly intel-
ligible but somewhat robotic sound of synthetic 
speech, for the approximately 2 million people in 
the United States with a limited ability to commu-
nicate vocally (Matas et al, 1985), these synthetic 
voices are inadequate. The restricted number of 
available voices lack the personalization they de-
sire. While intelligibility is a priority for these in-
dividuals, almost equally important is the 
naturalness and individuality one associates with 
one?s own voice. Individuals with difficulty speak-
ing can be any age, gender, and from any part of 
the country, with regional dialects and idiosyncrat-
ic variations. Each individual deserves to speak 
with a voice that is not only intelligible, but uni-
quely his or her own. For those with degenerative 
diseases such as Amyotrophic Lateral Sclerosis 
(ALS), knowing they will be losing the voice that 
has become intricately associated with their identi-
ty is not only traumatic to the individual but to 
family and friends as well.  
A form of synthesis that incorporates the quali-
ties of individual voices is concatenative synthesis. 
In this type of synthesis, units of recorded speech 
are appended. By using recorded speech, many of 
the voice qualities of the person recording the 
speech remain in the resulting synthetic voice. Dif-
ferent synthesis systems append different sized 
28
segments of speech. Appending larger the units of 
speech results in smoother, more natural sounding 
synthesis, but requires many hours of recording, 
often by a trained professional. The recording 
process is usually supervised, and the recordings 
are often hand-polished. Because appending small-
er units requires less recording on the part of the 
speaker, this is the approach the ModelTalker Syn-
thesizer has taken. However using smaller units 
may result in noticeable auditory glitches at conca-
tenative junctures that are a result of variations (in 
pitch, amplitude, pronunciation, etc.) between the 
speech units being appended. Thus the speech rec-
orded must be more uniform in pitch and ampli-
tude. In addition, the units cannot be 
mispronounced because each unit is crucial to the 
resulting synthetic speech. In a smaller database 
there may not be a second example of a specific 
phoneme sequence.  
MT Voice Recorder expects that the individuals 
recording will be untrained and unsupervised, and 
may lack strength and endurance because of the 
presence of a degenerative disease. Thus the sys-
tem is user-friendly enough for untrained, unsu-
pervised individuals to record a corpus of speech. 
The system provides the user with feedback on the 
quality of each utterance they record in terms of 
pronunciation accuracy, relative uniformity of 
pitch, and relative uniformity of amplitude. Confe-
rence attendees will be able to experience this in-
terface system and test all its different features. 
1.2 Feature Demonstration 
At the conference, attendees will be able to try out 
the different features of ModelTalker Voice Re-
corder. These features include automatic micro-
phone calibration, pitch, amplitude, and 
pronunciation detection and feedback, and auto-
matic phoneme labeling of speech recordings. 
 
1.2.1 Microphone calibration 
One important new feature of the MT Voice Re-
corder is the automatic microphone calibration 
procedure. In InvTool, a predecessor software of 
MT Voice Recorder, users had to set the micro-
phone?s amplitude. The system now calibrates the 
signal to noise ratio automatically through a step-
by-step process (see Figure 1, below). 
 
 
Using the automatic calibration procedure, the 
optimal signal to noise ratio is set for the recording 
session. These measurements are retained for fu-
ture recording sessions in cases in which an indi-
29
vidual is unable to record the entire corpus in one 
sitting. 
Once the user has completed the automatic cali-
bration procedure, he will be able to start recording 
a corpus of speech. The interface has been de-
signed with the assumption that individuals will be 
recording without supervision. Thus the interface 
incorporates a number of feedback mechanisms to 
aid individuals in making a high quality corpus for 
synthesis (see Figure 2, below). 
 
1.2.2 Recording Utterances 
The corpus was carefully chosen so that all fre-
quently used phoneme combinations are included 
at least once. Thus it is critical that users pro-
nounce prompted sentences in the manner in which 
the system expects. Alterations in pronunciation as 
small as saying /i/ versus /?/ for ?the,? for example, 
can negatively affect the resulting synthetic voice. 
To reduce the incidence of alternate pronunciation, 
the user is prompted with both a text and an audito-
ry version of the utterance.  
 
1.2.3 Recording Feedback 
Once an utterance has been recorded, the user rece-
ives feedback on the overall quality of the utter-
ance. Specifically, the user receives feedback on 
the pitch, the overall amplitude, and the pronuncia-
tion of the recording. 
Pitch: The user receives feedback on whether 
the utterance?s average pitch is within range of the 
user?s base pitch determined during the calibration 
process. Collecting all recordings within a relative-
ly small pitch range minimizes concatenation costs 
during the synthesis process. MT Voice Recorder 
determines the average pitch of each utterance and 
gives the user feedback on whether the pitch is 
within an acceptable range. This feedback mechan-
ism also helps to eliminate cases in which the sys-
tem is unable to accurately track the pitch of an 
utterance. In these cases, the utterance will be 
marked unacceptable and the user should rerecord, 
hopefully yielding an utterance with more accurate 
pitch tracking. 
 
 
Figure 2: MT Voice Recorder User Interface 
30
Amplitude: The user is also given feedback on 
the overall amplitude of an utterance. If the ampli-
tude is either too low or too high, the user must 
rerecord the utterance. 
Pronunciation: Each recorded utterance is eva-
luated for pronunciation. Each utterance within the 
corpus is associated with a string of phonemes 
representing its transcription. When an utterance is 
recorded, the phoneme string associated with the 
utterance is force-aligned with the recorded 
speech. If the alignment does not fall within an 
acceptable range, the user is given feedback that 
the recording?s pronunciation may not be accepta-
ble and the user is given the option of rerecording 
the utterance. 
 
1.2.4 Automatic Phoneme Labeling  
During the process of pronunciation evaluation, an 
associated phoneme transcription is aligned with 
the utterance. This alignment is retained so that 
each utterance is automatically labeled. Once the 
entire corpus has been recorded, alignments are 
automatically refined based on specific individual 
voice characteristics. 
 
1.2.5 Other Features 
The MT Voice Recorder also allows users to add 
utterances of their choice to the corpus of speech 
for the synthetic voice. These utterances are those 
the user wants to be synthesized clearly and will 
automatically be included in their entirety in the 
speech database. These utterances are also auto-
matically labeled before being stored. 
In addition, for those with more speech and lin-
guistic experience, the system has a number of 
other features that can be explored. For example, 
the MT Voice Recorder also allows one to change 
settings so that the phoneme string, peak ampli-
tude, RMS range, average F0, F0 range, and pro-
nunciation score can be viewed. Users may use this 
information to more precisely adjust their utter-
ances. 
1.3 Synthetic Voice Demonstration 
Those attending the demonstration will also be 
able to listen to a sampling of synthetic voices 
created using the ModelTalker system. While one 
of the synthetic voices was created by a profes-
sional speaker and manually polished, all other 
voices were created by untrained individuals, most 
of whom have ALS, in an untrained setting, with 
the recordings having no manual polishing. 
2 Other Applications 
Although the MTVR was designed specifically to 
record speech for the creation of a database that 
will be used in speech synthesis, it can also be used 
as a digital audio recording tool for speech re-
search. For example, the MT Voice Recorder of-
fers useful features for language documentation. 
An immediate warning about a poor quality re-
cording will alert a researcher to rerecord the utter-
ance. MT Voice Recorder employs file formats 
that are recommended for digital language docu-
mentation (e.g., XML, WAV, and TXT) (Bird & 
Simons, 2003). The recorded files are automatical-
ly stored with broad phonetic labels. The automatic 
saving function will reduce the time of recordings 
and the potential risk for miscataloging the files. 
Currently, the automatic phonetic labeling feature 
is only available for English, but it could be appli-
cable to different languages in the future.  
For more information about the ModelTalker 
System and to experience an interactive demo as 
well as listen to sample synthetic voices,  
visit http://www.modeltalker.com.  
Acknowledgments 
This work was supported by STTR grants 
R41/R42-DC006193 from NIH/NIDCD and from 
Nemours Biomedical Research. We are especially 
indebted to the many people with ALS, the AAC 
specialists in clinics, and other interested individu-
als who have invested a great deal of time and ef-
fort into this project and have provided valuable 
feedback. 
References  
Bird, S. and Simons, G.F. (2003). Seven dimensions of 
portability for language documentation and descrip-
tion. Language, 79(3): 557-582. 
Matas, J., Mathy-Laikko, P., Beaukelman, D. and Le-
gresley. K. (1985). Identifying the nonspeaking 
population: a demographic study, Augmentative & 
Alternative Communication, 1: 17-31. 
  
31
