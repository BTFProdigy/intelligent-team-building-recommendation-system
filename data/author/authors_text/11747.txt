Proceedings of the 8th International Conference on Computational Semantics, pages 128?139,
Tilburg, January 2009. c?2009 International Conference on Computational Semantics
Dialogue Modelling and the Remit
of Core Grammar
Eleni Gregoromichelaki
?
, Yo Sato
?
, Ruth Kempson
?
Andrew Gargett
?
, Christine Howes
?
?
King?s College London,
?
Queen Mary University of London
1 Introduction
In confronting the challenge of providing formal models of dialogue, with
its plethora of fragments and rich variation in modes of context-dependent
construal, it might seem that linguists face two types of methodological
choice: either (a) conversation employs dialogue-specific mechanisms, for
which a grammar specific to such activity must be constructed; or (b) vari-
ation arises due to independent parsing/production systems which invoke
a process-neutral grammar. However, as dialogue research continues to de-
velop, there are intermediate possibilities, and in this paper we discuss the
approach developed within Dynamic Syntax (DS, Kempson et al 2001,
Cann et al 2005), a grammar framework within which, not only the parser,
but indeed ?syntax? itself are just a single mechanism allowing the pro-
gressive construction of semantic representations in context. Here we take
as a case study the set of phenomena classifiable as clarifications, reformu-
lations, fragment requests and corrections accompanied by extensions, and
argue that though these may seem to be uniquely constitutive of dialogue,
they are grounded in the mechanisms of apposition equivalently usable in
monologue for presenting reformulations, extensions, self-corrections etc.
2 Background
The data we focus on are non-repetitive fragment forms of acknowledge-
ments, clarifications and corrections (henceforth, A female, B male):
(1) A: Bob left.
B: (Yeah,) the accounts guy.
(2)
A: They X-rayed me, and took a urine sample, took a blood sample.
Er, the doctor
B: Chorlton?
A: Chorlton, mhm, he examined me, erm, he, he said now they
were on about a slight [shadow] on my heart.
128
(3) A: Bob left.
B: Rob?
A: (No,) (Bob,) the accounts guy.
Even though in the literature the fragments in (2)-(3) might be characterised
as illustrating distinct construction-types, in our view, they all illustrate how
speakers and hearers may contribute, in some sense to be made precise, to
the joint enterprise of establishing some shared communicative content, in
what might be loosely called split utterances. Even (1), an acknowledgement,
can be seen this way upon analysis: B?s addition is similar in structure to
an afterthought extension that might have been added by A herself to A?s
fully sentential utterance. It can be seen in (2) that such joint construction
of content can proceed incrementally: the clarification request in the form of
a reformulation is provided by B and resolved by A within the construction
of a single proposition. In (3) the fragment reply can be taken to involve
correction, in the sense that, according to the DS analysis of B?s fragment
question, he has provided content construable as equivalent to that derived
by processing Rob left? (see Kempson et al (2007)). Nevertheless such
corrections can also incorporate extensions in the above sense, enabling a
single conjoined propositional content to be derived in a single step.
It might seem that such illustration of diversity of fragment usage is am-
ple evidence of the need for conversation-specific rules. Indeed, Ferna?ndez
(2006) presents a thorough taxonomy, as well as detailed formal modelling
of Non-Sentential Utterances (NSUs), referring to contributions such as (1)
as repeated acknowledgements involving reformulation. Ferna?ndez models
such constructions via type-specific ?accommodation rules? which make a
constituent of the antecedent utterance ?topical?. The semantic effect of
acknowledgement is then derived by applying an appropriately defined ut-
terance type for such fragments to the newly constructed context. A distinct
form of contextual accommodation is employed to model so-called helpful
rejection fragments, as in (3) (without the reformulation), whereby a wh-
question is accommodated in the context by abstracting over the content
of one of the sub-constituents of the previous utterance. The content of
the correction is derived by applying this wh-question in the context to the
content of the fragment (see also Schlangen (2003) for another classification
and analysis).
In contrast, the alternative explored here is whether phenomena such
as (1)-(2), both of which are non-repetitive next-speaker contributions, can
be handled uniformly using the mechanisms for structure-building made
available in the core grammar, without recourse to construction-specific ex-
tensions of that grammar and contextual accommodation rules. This is
because, in our view, the range of interpretations these fragments receive
in actual dialogue seem to form continua with no well-defined boundaries
and mixing of functions (see also comments in Schlangen (2003)). Thus we
129
propose that the grammar itself simply provides mechanisms for process-
ing/integrating such fragments in the current structure while their precise
contribution to the interaction can be calculated by pragmatic inferencing
if needed (as in e.g. Schlangen (2003)) or, as seems most often to be the
case, be left underspecified without disruption to the dialogue.
One bonus of the stance taken here is the promise it offers for elucidating
the grammar-parser contribution to the disambiguation task. Part of the
challenge of modelling dialogue is the apparent multiplicity of interpretive
and structural options opened up during processing by the recurrent, of-
ten overlapping fragments as seen in (2) above. Thus, it might seem that
the rich array of elliptical fragments available in dialogue adds to its com-
plexity. However, an alternative point of view is to see such phenomena as
providing a window on how interlocutors exploit the incrementality afforded
by the grammar. The reliance of fragments on context for interpretation,
when employed incrementally, enables the hearer to immediately respond to
a previous utterance at any relevant point, in a constrained manner, with-
out ?recovering? a propositional unit. Three features of the Dynamic Syntax
model of dialogue (Purver et al (2006)), presented below, provide the flex-
ible control required for such processing: (a) word-by-word incrementality
(b) interaction with contextually provided information at every step of the
construction process (c) tight coordination of parsing and production.
3 Dynamic Syntax: A Sketch
Dynamic Syntax (DS ) is a parsing-based framework, involving strictly se-
quential interpretation of linguistic strings. The model is implemented via
goal-directed growth of tree structures and their annotations formalised us-
ing LOFT (Blackburn and Meyer-Viol (1994)), with modal operators ???, ???
to define concepts of mother and daughter, and their iterated counterparts,
??
?
?, ??
?
?, to define the notions be dominated by and dominate. Under-
specification and update are core aspects of the grammar itself and involve
strictly monotonic information growth for any dimension of tree structures
and annotations. Underspecification is employed at all levels of tree rela-
tions (mother, daughter etc.), as well as formulae and type values, each
having an associated requirement that drives the goal-directed process of
update. For example, an underspecified subject node of a tree may have a
requirement expressed in DS with the node annotation ?Ty(e), for which
the only legitimate updates are logical expressions of type entity (Ty(e));
but requirements may also take a modal form, e.g. ????Ty(e ? t), a con-
straint that the mother node be annotated with a formula of predicate type.
Requirements are essential to the dynamics informing the DS account: all
requirements must be satisfied if the construction process is to lead to a
successful outcome.
130
Semantic structure is built from lexical and general computational ac-
tions. Computational actions govern general tree-constructional processes,
such as introducing and updating nodes, as well as compiling interpretation
for all non-terminal nodes in the tree. Construction of only weakly spec-
ified tree relations (unfixed nodes) can also be induced, characterised only
as dominance by some current node, with subsequent update required. In-
dividual lexical items also provide procedures for building structure in the
form of lexical actions, inducing both nodes and annotations. Thus partial
trees grow incrementally, driven by procedures associated with particular
words as they are encountered, with a pointer, ?, recording the parser?s
progress (unlike van Leusen and Muskens (2003), partial trees are part of
the model and, unlike in other frameworks, incrementality is word-by-word
rather than sentence-by-sentence).
Complete individual trees are taken to correspond to predicate-argument
structures (with an event term associated with tense, suppressed in this
paper). The epsilon calculus (see e.g. Meyer-Viol (1995)) provides the se-
mantic representation language. Complex structures are obtained via a gen-
eral tree-adjunction operation licensing the construction of so-called linked
trees, hosting information that is eventually transferred onto the tree from
which the link is made (Kempson et al2001). Structures projected as such
paired trees range over restrictive relatives, nonrestrictive relatives, condi-
tionals, topic structures and appositions as here. As the semantic represen-
tations employ the epsilon calculus, eventual compound epsilon terms (e.g.
?, x, P (x)) are constructed incrementally through link-adjunction:
(4) A consultant, a friend of Jo?s, is retiring
Ty(t),Retire
?
((?, x, Consultant
?
(x) ? Friend
?
(Jo
?
)(x)))
Ty(e), (?, x, Consultant
?
(x) ? Friend
?
(Jo
?
)(x)) Ty(e? t), Retire
?
Ty(e), (?, x, Friend
?
(Jo
?
)(x))
Ty(cn), (x,Friend
?
(Jo
?
)(x))
x Friend
?
(Jo
?
)
Jo
?
Friend
?
Ty(cn? e), ?P.?, P
Underspecification of content as well as structure are central to facilitat-
ing successful linguistic interaction, our primary concern here. Pronouns,
the prototypical case, contribute a place-holding metavariable, noted as e.g.
U, plus an associated requirement for update by an appropriate term value:
??x.Fo(x). Equally, definite NPs contribute place-holders plus a constraint
providing a restriction/?presupposition? on the kind of entity picked out,
e.g., the man contributes the annotation U
Man
?
(U)
, T y(e). The subscript
specification is shorthand for a transition to a linked tree whose root node is
131
annotated with a formula Man
?
(U)
1
. The update of metavariables can be
accomplished if the context contains an appropriate term for substitution:
context involves storage of parse states, i.e., storing of partial tree, word se-
quence to date, plus the actions used in building up the partial tree (Purver
et al2006).
Scope dependencies between constructed terms or the index of evalua-
tion (e.g. S) are defined on completed propositional formulae, relative to
incrementally collected scope constraints (of the form x < y for constructed
terms containing variables x and y respectively). Constraints reflect on-line
processing considerations modulo over-riding lexical stipulations. For ex-
ample, proper names contribute as iota terms, i.e, epsilon terms reflecting
uniqueness in the context, ?, x,Bob
?
(x), and these project a scope depen-
dency solely on the index of evaluation reflecting their widest scope property
(cf Kamp and Reyle 1994). The structure projected from A?s utterance in
(1) is thus (5) (note that trees are the result of processing words but do
not encode the structure of strings, word order etc., only semantic content
derived in interaction with context, thus are the equivalents of DRSs):
(5)
S < x Ty(t),Leave
?
((?, x,Bob
?
(x)))
Ty(e), (?, x,Bob
?
(x)) Ty(e? t), Leave
?
The scope evaluation rule reflects the predicate-logic/epsilon-calculus equiv-
alence ?xF (x) ? F (?, x, F (x)) so evaluated terms eventually reflect their
containing structure. Hence, evaluation of (5) yields:
(6) Ty(t), Leave
?
(?, x,Bob
?
(x) ? Leave
?
(x))
A major aspect of the DS dialogue model is that both generation and
parsing are goal-directed and incremental, and hence are governed by es-
sentially the same mechanism. Under this model, a human hearer-parser
builds a succession of partial parse trees based on what (s)he has heard
thus far. Importantly, however, unlike the conventional bottom-up parsing,
the DS model assumes a strong predictive element in parsing: a hearer is
assumed to entertain some goal to be reached eventually at any stage of
parsing. In (1), for example, as soon as the hearer encounters Bob, an un-
derspecified propositional tree is constructed, as in the first simplified and
schematised tree in Figure 1. Then the tree ?grows? monotonically, i.e. such
that at each word input, it is ?updated? to an ?incremented? tree that is
subsumed by the original tree, as depicted in the same Figure. This can be
described as a process of specifying the relevant nodes towards a complete
tree. This predictive element in DS allows a speaker-generator to be mod-
elled as doing exactly the same, i.e. going through monotonically updated
partial trees, the only difference being that (s)he also has available a more
1
These linked structures are suppressed in all diagrams.
132
fully specified goal tree representing what (s)he wishes to say, corresponding
to the rightmost tree in the Figure (with ?0? in the ?generation? row at the
bottom indicating it is entertained before utterance). Each licensed step in
generation, i.e. the utterance of a word, is governed by whatever step is
licensed by the parsing formalism, constrained via a required subsumption
relation of the goal tree. By updating their growing ?parse? tree relative
to the goal tree, speakers are licensed to produce the associated natural
language string.
Parsing: 1 2 3
?Ty(t)
q
q
q
q
q
q
q
M
M
M
M
M
M
M
Ty(e),
Bob
?
,?
?Ty(e ? t)
7?
?Ty(t)
q
q
q
q
q
q
q
M
M
M
M
M
M
M
Ty(e),
Bob?
Ty(e ? t),
Leave
?
,?
7?
Ty(t),
Leave?(Bob?),?
q
q
q
q
q
q
q
M
M
M
M
M
M
M
Ty(e),
Bob?
Ty(e ? t),
Leave?
Generation: 1 2 0,3
Figure 1: Parallel parsing and generation in DS
This architecture allows for a dialogue model in which generation (what
a speaker does) and parsing (what a hearer does) function in parallel. The
speaker goes through partial trees subsuming a specified goal tree, while
the hearer attempts to ?mirror? the same series of partial trees, albeit not
knowing what the content of the unspecified nodes will be. For the dialogues
in (1)-(3), therefore, B as the hearer will have the partial representation of
what he has successfully parsed, required also for generation. This provides
him with the ability at any stage to become the speaker, interrupting to
ask for clarification, reformulating, or providing a correction, as and when
necessary. As we shall see, B?s parse tree reveals where need of clarifica-
tion or miscommunication occurs, as it will be at that node from which a
sub-routine extending it takes place
2
. According to our model of dialogue,
repeating or extending a constituent of A?s utterance by B is licensed only
if B, the hearer of A turned now a speaker, entertains currently a goal tree
that matches or extends the parse tree of what he has heard in a monotonic
fashion, although he only utters the relevant subpart of A?s utterance. In-
deed, this update is what B is seeking to clarify, correct or acknowledge. In
DS, B can reuse the already constructed (partial) parse tree in his context,
rather than having to rebuild an entire propositional tree or subtree
3
.
2
The account extends the implementation reported in Purver et al (2006)
3
Given the DS concept of linked trees projecting propositional content, we anticipate
that this mechanism will be extendable to fragment construal involving inference (see e.g.
Schlangen (2003), Schlangen and Lascarides (2003))
133
4 NSU fragments in Dynamic Syntax
4.1 Non-repetitive Acknowledgement
From a DS perspective, phenomena like reformulations as in (1), or exten-
sions to what one understands of the other speaker?s utterance, (2), can
be handled with exactly the same mechanisms as the sentence-internal phe-
nomenon independently identifiable as apposition, as in (4), and equally
usable by a single individual as a means of incrementally reformulating, cor-
recting or extending what they have just uttered. The update rule for such
structures, applicable to all terms, takes the two type e terms so formed and
yields a new term whose compound content is a combination of both.
We now have the basis for analysing extensions potentially functioning
as acknowledgements which build on what has been previously said as a way
of confirming the previous utterance. Recall (1), (2). There are two ways for
fragments which reformulate an interlocutor A?s utterance to occur: (a) as
interruptions of A?s utterance with immediate confirmation of identification
of the individual concerned, see (2); (b) as confirmations/extensions of A?s
utterance after the whole of her utterance has been integrated, see (1). Both
are modelled by DS as incremental additions.
Turning to (1), B?s response (Yeah,) the accounts guy constitutes a re-
formulation of A?s utterance and an extension of A?s referring expression,
yielding a similar content as that of an appositive expression Bob, the ac-
counts guy in this case jointly constructed. B?s reformulation/extension
counts in effect as an acknowledgement in virtue of signalling successful
processing of A?s utterance without objection raised. Thus there is no need
for a separate grammatical mechanism to process these structures. In DS
terms, after processing A?s utterance, B?s context consists of the following
tree:
(7) B?s Context for producing ?Yeah?
Ty(t), Leave
?
(?, x,Bob
?
(x) ? Leave
?
(x)),?
(?, x,Bob
?
(x)) Leave
?
B, as a speaker, can now re-use this representation as point of departure
for generating the expression the accounts guy. In this case his goal tree,
the message to be expressed, will now be annotated with a composite term
made up from both the term recovered from parsing A?s utterance and the
new addition. This requires attaching a linked tree to the correct node
and an appropriate update of the context tree (for reasons of space, the
exact structure of the linked tree is condensed below, with subscripting as
shorthand):
134
(8) B?s goal tree:
Ty(t), Leave
?
((?, x,Bob
?
(x) ?Acc.guy
?
(x))) ? Leave
?
(x))
(?, x,Bob
?
(x) ?Acc.guy
?
(x))
Leave
?
(?, x,Bob
?
(x))
Acc.guy
?
(x)
In order to license generation of the expression the accounts guy, B now
needs to verify that processing these words in the context provided by the
tree in (7) will produce a tree that matches this goal tree in (8). To achieve
this, starting from (7), a series of simulated ?parse? trees are generated
which indeed result in the requisite matching. Steps include shifting the
pointer to the appropriate node, projection of a linked tree from that node
and test-processing the words the accounts guy, each step checking against
the goal tree that a subsumption relation between the current ?parse? tree
and the goal tree is always maintained:
(9) B?s parse tree licensing production of the accounts guy: link adjunction
Ty(t), Leave
?
(?, x,Bob
?
(x) ? Leave
?
(x))
(?, x,Bob
?
(x)) Leave
?
U
Acc.guy
?
(U)
,?
The only way to update this representation relative to both the restriction
on the metavariable and monotonicity of growth on any one node in a tree
involves replacing the metavariable with (?, x,Bob
?
(x)), as this is commen-
surate with an extension of the term annotating the node from which the
link transition was constructed:
(10) Updating B?s parse tree licensing production of the accounts guy
Ty(t), Leave
?
(?, x,Bob
?
(x) ?Acc.guy
?
(x) ? Leave
?
(x)),?
(?, x,Bob
?
(x) ?Acc.guy
?
(x)) Leave
?
(?, x,Bob
?
(x))
Acc.guy
?
(x)
Finally, the information is passed up to the top node of the main tree,
completing the parse tree to match B?s goal tree, (8), thus licensing the
utterance of the expression the accounts guy.
4.2 Non-repetitive Clarification
In the acknowledgement case above, the proposition relative to which the
linked structure is built is completed (with an already extended epsilon
term); but the same mechanism can be used when the interlocutor needs
clarification, prior to any such completion of the tree. In (2), B again, as
the speaker, takes as his goal tree a tree annotated with an expansion of the
term constructed from parsing A?s utterance but nevertheless picking out
the same individual. Using the very same mechanism as in (1) of building a
linked structure, B, interrupting A, provides a distinct expression, the name
Chorlton, this time before he has completed the parse tree for A?s utterance.
All that has been achieved at this point is the definite?s contribution of a
meta-variable with the restriction that the individual picked out must be a
doctor:
135
(11) A/B?s parse tree for Chorlton:
?Ty(t)
U
Doctor
?
(U)
,?
?Ty(e ? t)
(?, x, Chorlton
?
(x))
As in the acknowledgement case, but this time at the node initiating the
link transition, the only possible value to provide for the metavariable U
compatible both with its restriction and the monotoniticity constraint is
the composite term (?, x,Doctor
?
(x) ? Chorlton
?
(x)). The mechanism of
constructing paired structures involving type e terms across linked trees
is identical to that employed in B?s utterance in (1), though to a rather
different effect at this intermediate stage in the interpretation process. This
extension of the term is confirmed by A, this time replicating the composite
term which processing B?s utterance has led to. The eventual effect of the
process of inducing linked structures to be annotated by coreferential type e
terms may thus vary across monologue and different dialogue applications,
yielding different interpretations, but the mechanism is the same.
4.3 Correction
It might be argued nonetheless that correction is intrinsically a dialogue
phenomenon. Consider (3), for example. One of the possible interpretations
of (3), according to the DS analysis, is that B has offered the equivalent of the
content derived by processing Rob left?. That is, let?s assume here that B has
misheard and requests confirmation of what he has perceived A as saying.
A in turn rejects B?s understanding of her utterance and provides more
information. Presuming rejection as simple disagreement (i.e. the utterance
has been understood, but judged as incorrect), in DS terms, this means that
A has in mind a goal tree that licensed what she had produced, which is
distinct from the one derived by processing B?s clarification. As shown in
Kempson et al (2007), this means that A has been unable to process B?s
clarification request as an extension of her own context. Instead, she has to
parse the clarification by exploiting the potential for introducing an initially
structurally underspecified tree-node to accommodate the contribution of
the word Rob. Subsequently, by re-running the actions stored in context
previously by processing her own utterance of the word left, she is able to
complete the integration of the fragment in a new propositional structure.
Now, in order for A to produce the following correction, what is required
is for A to establish as the current most recent representation in context her
original goal tree. This can be monotonically achieved by recovering and
copying this original goal tree to serve as the current most immediate con-
text
4
. An option available to A at this point is to introduce, in addition
or exclusively, a reformulation of her original utterance in order to facilitate
4
Mistaken representations must be maintained in the context as they can provide an-
tecedents for subsequent anaphoric expressions.
136
identification of the named individual which proved problematic for B previ-
ously. She can answer B?s utterance of Rob? with (No,) Bob, the accounts
guy, as in (3) or simply with (No,) the accounts guy. Both are licensed
by the DS parsing mechanism without more ado. For both, the goal tree
will be as follows and it will always be the point of reference for checking
the subsumption relation relative to the simulated parsing steps described
further below:
(12) A?s goal tree
Ty(t), Leave
?
((?, x,Bob
?
(x) ?Acc.guy
?
(x)))
(?, x,Bob
?
(x) ?Acc.guy
?
(x)) Leave
?
(?, x,Bob
?
(x))
Acc.guy
?
(x)
Under these circumstances, given the DS grammar-as-parser perspective,
several strategies are now available for the licensing of generation of the
fragment. A is licensed to repeat the name Bob by locally extending the
node in the context tree where the representation of the individual referred to
is located by using the rule of late*adjunction, a process which involves
building a node of type e from a dominating node of that type (illustrated in
Kempson et al 2007). An alternative way of licensing repetition of the word
Bob is to employ one of the strategies generally available for the parsing of
long distance dependencies i.e. constructing initial tree nodes as unfixed
(*adjunction). We show here how the latter strategy can be exploited to
license the production of the fragment by A.
(13) Parsing simulation licensing generation of Bob, the accounts guy
Step 1: *Adjunction Step 2: LINK-Adjuction + testing the accounts guy
?Ty(t)
(?, x,Bob
?
(x)),?
?Ty(t)
(?, x,Bob
?
(x)),?
U
Acc.guy
?
(U)
The only way to develop the constructed tree at Step 2 commensurate with
the goal tree (12) is to identify the value of U as (?, x,Bob
?
(x)), so this
is what is entered at the newly constructed linked tree, duly leading to
extension of the term originally given as annotating the unfixed node as
(?, x,Bob
?
(x) ? Acc.guy
?
(x)). The structure
5
derived by processing such an
extension is exactly that of (1) above (compare goal tree in (12) above
and tree in (8)). Now, as mentioned before, context, as defined in DS,
keeps track not only of tree representations and words but also of actions
contributed by the words and utilised in building up the tree representations.
Here, according to DS, production of the correction in (3) is licensed to be
5
Again note that DS trees represent derived content rather than structure over natural
language strings.
137
fragmental only because the original actions for parsing/producing the word
left are available in the context and can be recalled to complete the structure
initiated by processing/producing the name Bob. Now these stored actions
can be retrieved to develop the tree further:
(14) Parsing simulation licensing generation of Bob, the accounts guy
Step 3: test-processing stored actions for left
?Ty(t)
(?, x,Bob
?
(x) ?Acc.guy
?
(x)) ?Ty(e),? Leave?
(?, x,Bob
?
(x))
Acc.guy
?
(?,x,Bob
?
(x))
With this partial tree being commensurate with the goal tree, all actions that
follow are general computational processes for completing the tree: unifying
the unfixed node to determine the subject argument, applying the subject
to the predicate, evaluating the quantified terms. Nothing specific to this
structure is needed. Indeed, all these mechanisms are equally applicable by
an individual speaker, perhaps more familiar as right dislocation phenomena,
but equally available incrementally:
(15) Bob left, (Bob) the accounts guy.
5 Conclusion
As these fragments and their construal have demonstrated, despite serving
distinct functions in dialogue, the mechanisms which make such diversity
possible are general strategies for tree growth. In all cases, the advantage
which use of fragments provides is a ?least effort? means of re-employing
previous content/structure/actions which constitute the minimal local con-
text. As modelled in DS, it is more economical to reuse information from
this local context rather than constructing representations afresh (via costly
processes of lexical retrieval, choice of alternative parsing strategies, etc.).
A further quandary in dialogue construal is that, despite such avenues
for economising their efforts, interlocutors are nevertheless faced with an
increasing set of interpretive options at any point during the construction
of representations. One strategy available to hearers is to delay a disam-
biguating move until further input potentially resolves the uncertainty. How-
ever, as further input is processed and parsing/interpretive options increase
rapidly, the human processor struggles. The incremental definition of the
DS formalism allows for the modelling of an alternative strategy available
to hearers: at any (sub-sentential) point they could opt to intervene imme-
diately, and make a direct appeal to the speaker for more information as
illustrated by the clause-medial fragment interruption (2). It seems clear
that the grammar should allow the resources for modelling this behaviour
without any complications.
138
The phenomena examined here are also cases where speakers? and hear-
ers? representations, despite attempts at coordination, may nevertheless sep-
arate sufficiently for them to have to seek ?repair? (see especially (3)). In
the model presented here, the dynamics of interaction allow fully incremen-
tal generation and integration of fragmental utterances so that interlocutors
can be taken to constantly provide optimal evidence of each other?s represen-
tations with necessary adjuncts being able to be incrementally introduced.
But such mechanisms apply equally within an individual utterance, with self-
correction, extension, elaboration, repetition etc. The effect is that all the de-
vices which seem so characteristic of dialogue involve mechanisms invariably
available within an individual?s core grammar. This suggests a new inverse
methodology: it is the challenge of modelling dialogue that can be used as
a point of departure for modelling grammars for individual speakers, rather
than the other, more familiar, way round (see also Ginzburg (forthcmg)).
This reversibility is, notably, straightforwardly available to grammar for-
malisms in which the incremental dynamics of information growth is the
core structural concept because emergent dialogue structure crucially ex-
hibits and interpretively relies on such incrementality.
Acknowledgements
This work was supported by grants ESRC RES-062-23-0962 and Leverhulme F07-
04OU. We are grateful for comments to: Robin Cooper, Alex Davies, Arash Eshghi,
Jonathan Ginzburg, Pat Healey, Greg Mills. Normal disclaimers apply.
References
Patrick Blackburn and Wilfried Meyer-Viol. Linguistics, logic and finite trees.
Bulletin of the IGPL, 2:3?31, 1994.
Raquel Ferna?ndez. Non-Sentential Utterances in Dialogue: Classification, Resolu-
tion and Use. PhD thesis, King?s College London, University of London, 2006.
Jonathan Ginzburg. Semantics for Conversation. CSLI, forthcmg.
Ruth Kempson, Andrew Gargett, and Eleni Gregoromichelaki. Clarification re-
quests: An incremental account. In Proceedings of the 11th Workshop on the
Semantics and Pragmatics of Dialogue (DECALOG), 2007.
Wilfried Meyer-Viol. Instantial Logic. PhD thesis, University of Utrecht, 1995.
Matthew Purver, Ronnie Cann, and Ruth Kempson. Grammars as parsers: Meeting
the dialogue challenge. Research on Language and Computation, 4(2-3):289?326,
2006.
David Schlangen. A Coherence-Based Approach to the Interpretation of Non-
Sentential Utterances in Dialogue. PhD thesis, University of Edinburgh, 2003.
David Schlangen and Alex Lascarides. The interpretation of non-sentential utter-
ances in dialogue. In Proceedings of the 4th SIGdial Workshop on Discourse and
Dialogue, pages 62?71, Sapporo, Japan, July 2003. Association for Computa-
tional Linguistics.
Noor van Leusen and Reinhard Muskens. Construction by description in discourse
representation. In J. Peregrin, editor, Meaning: The Dynamic Turn, chapter 12,
pages 33?65. 2003.
139
Proceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 79?86,
Queen Mary University of London, September 2009. c?2009 Association for Computational Linguistics
A: An Experimental Investigation into. . .
B: . . . Split Utterances
Christine Howes, Patrick G.T. Healey and Gregory J. Mills
Queen Mary University of London
Interaction, Media and Communication Research Group, London, E1 4NS
{chrizba, ph, gj}@dcs.qmul.ac.uk
Abstract
A distinguishing feature of dialogue is that
more that one person can contribute to the
production of an utterance. However, un-
til recently these ?split? utterances have re-
ceived relatively little attention in mod-
els of dialogue processing or of dialogue
structure. Here we report an experiment
that tests the effects of artificially intro-
duced speaker switches on groups of peo-
ple engaged in a task-oriented dialogue.
The results show that splits have reliable
effects on response time and on the num-
ber of edits involved in formulating sub-
sequent turns. In particular we show that
if the second half of an utterance is ?mis-
attributed? people take longer to respond
to it. We also show that responses to ut-
terances that are split across speakers in-
volve fewer deletes. We argue that these
effects provide evidence that: a) speaker
switches affect processing where they in-
terfere with expectations about who will
speak next and b) that the pragmatic effect
of a split is to suggest to other participants
the formation of a coalition or sub-?party?.
1 Introduction
Split utterances, defined simply as utterances
which are split between speakers1, are known
to occur in dialogue, as evidenced by Conversa-
1What we call split utterances have been variously re-
ferred to as collaborative turn sequences (Lerner, 1996;
Lerner, 2004), collaborative completions (Clark, 1996) co-
constructions (Helasvuo, 2004), co-participant completions
(Hayashi, 1999; Lerner and Takagi, 1999) collaborative pro-
ductions (Szczepek, 2000) and anticipatory completions (Fox
and others, 2007) amongst others.
tional Analysis (CA) studies, based on the anal-
ysis of naturally occuring dialogues. In addi-
tion to numerous analyses of split utterances in
generic English dialogues, there are cross lin-
guistic studies, and observations of conversations
with aphasics. In Finnish, split utterances within
a single clause conform to the strict syntactic
constraints of the language (which has a rich
inflectional morphology), despite the change in
speaker (Helasvuo, 2004). Similarly, in Japanese,
a verb-final language, speakers also engage in ?co-
participant completions? (Hayashi, 1999; Lerner
and Takagi, 1999). There is also evidence of
split utterances in conversations with aphasics
(Oelschlaeger and Damico, 1998), demonstrat-
ing that the phenomenon is pervasive in dia-
logue. However, with the possible exception of
Szczepek (2000) who analysed some 200 splits
from 40 hours of recorded English conversation,
these studies tend to be unconcerned with frequen-
cies of occurrence; that split utterances occur at all
renders them worthy of study.
Split utterances are a clear and canonical exam-
ple of coordination in dialogue. In order for one
person to continue an utterance which has been be-
gun by another person requires the hearer to have
coordinated with the initial speaker up to the point
at which they take over the role of producer2.
Analysis of split utterances, when they can or
cannot occur and what effects they have on the co-
ordination of agents in dialogue, is therefore an
area of interest not only for conversational an-
alysts wishing to characterise sytematic interac-
tions in dialogue, but also linguists trying to for-
mulate grammars of dialogue, and psychologists
interested in alignment mechanisms in dialogue.
2Note that this says nothing about whether such a continu-
ation is the same as the initial speakers intended continuation.
79
In this regard, studies of split utterances, in both
spontaneous dialogues and experimentally, as be-
low, provide a complementary way of studying
structural alignment to the traditional experimen-
tal set up exemplified by Branigan and colleagues
(Branigan et al, 2000; Branigan et al, 2003;
Branigan et al, 2006). Indeed, Poesio and Rieser
(In preparation) claim that ?[c]ollaborative com-
pletions . . . are among the strongest evidence yet
for the argument that dialogue requires coordina-
tion even at the sub-sentential level? (italics origi-
nal).
Broadly speaking, there have been two types,
or levels, of explanations of split utterances of-
fered; pragmatic accounts and processing ac-
counts. Pragmatic accounts are favoured by Con-
versational Analysts, with various aspects of split
utterances analysed. However, in line with CA as-
sumptions, these analyses are almost exclusively
concerned with the conditions under which split
utterances can occur. Lerner (1991), for ex-
ample, identifies a number of ?compound? turn-
constructional units, such as the IF-THEN con-
struction (whereby the second participant is in
some sense licensed to provide the THEN part of
the structure). However, Lerner?s insistence on
identifying the circumstances in which split utter-
ances usually occur misses the important general-
isation that, syntactically, they can be anywhere in
a string (his opportunistic completions). His claim
that an anticipatory completion is ordinarily ?de-
signed as a syntactic continuation of the utterance
part it follows at the point of onset?, seems to hold
for all split utterances.
The occurrence of split utterances also has im-
plications for the organisation of turn-taking, as
outlined in Sacks et al (1974). According to Sche-
gloff (1995), turn-taking operates, not on individ-
ual conversational participants, but on ?parties?.
For example, if a couple are talking to a third per-
son, they may organise their turns as if they are
one ?party?, rather than two separate individuals.
Lerner (1991) suggests that split utterances can
clarify the formation of such parties; ?collabora-
tively produced sentences reveal a relationship be-
tween syntax and social organisation. It provides
evidence of how syntax can be mobilised to organ-
ise participants into ?groups?.?
The processing approach towards split utter-
ances is exemplified by the interactive alignment
model of Pickering and Garrod (2004). They
claim that;
. . . it should be more-or-less as easy
to complete someone else?s sentence as
one?s own, and this does appear to be the
case.
(Pickering and Garrod, 2004, p186)
According to this model, speaker and listener
ought to be interchangeable at any point, and this
is also the stance taken by the grammatical frame-
work of Dynamic Syntax (Cann et al, 2005). In
Dynamic Syntax (DS), parsing and production are
taken to use exactly the same mechanisms, lead-
ing to a prediction that split utterances ought to be
strikingly natural (Purver et al, 2006). Addition-
ally, for a third person to process an utterance that
appears to come from two separate speakers ought
not be more difficult than processing the same ut-
terance from a single speaker, regardless of where
in a string the changeover occurs.
According to Poesio and Rieser (In prepara-
tion), ?the study of sentence completions can shed
light on a number of central issues. . . this type of
data may be used to compare competing claims
about coordination ? i.e. whether it is best ex-
plained with an intentional model like Clark?s. . . or
with a model based on simpler alignment models
like Pickering and Garrod?s.? As they see inten-
tions as crucial to dialogue management, they con-
clude that a model which accounts for intentions
(such as their PTT account) better captures their
task specific split utterance data (See Poncin and
Rieser (2006) for details of the German data they
are modelling).
If this is the case, it ought to be more difficult
to process an utterance that appears to be split
between speakers, as opposed to one that comes
from one source, because the intentions of the two
different agents have to be considered in arriving
at an interpretation, and they may appear to have
formed a ?party? with respect to the subject of the
utterance. Additionally it ought to be more dis-
ruptive to the conversation if the utterance is at-
tributed to someone other than the person who
genuinely contributed it, because the hearer would
falsely attribute intentions to the wrong interlocu-
tor. This ought to be especially clear in cases
where the ?conversational momentum? appears to
be with the ?wrong? interlocutor. Contrarily, if a
processing model such as the interactive alignment
model is correct, then no such differences should
80
be observed3.
To test these predictions, an experiment was set
up to alter genuine single-turn utterances into split
utterances at an arbitrary point in the string. Dif-
ferent types of intervention were introduced, in a 2
x 2 factorial design, in order to separate out the ef-
fects of an utterance appearing to come from two
different participants from effects caused by an ap-
parent change of floor.
2 Method
The effects of seeing an utterance split between
speakers or not were tested using the Dialogue
Experimentation Toolkit (DiET) chat tool, as de-
scribed in Healey et al (2003), which enables dia-
logues to be experimentally manipulated.
The DiET chat tool allows interventions to be
introduced into a dialogue in real time, thus caus-
ing a minimum of disruption to the natural ?flow?
of the conversation. In this case, a number of gen-
uine turns in a three way conversation were artifi-
cially split into two sections, with both parts either
appearing to originate from the genuine source, or
one or both parts being falsely attributed to another
participant.
2.1 Materials
2.1.1 The Balloon Task
The balloon task is an ethical dilemma re-
quiring agreement on which of three passengers
should be thrown out of a hot air balloon that will
crash, killing all the passengers, if one is not sac-
rificed. The choice is between a scientist, who be-
lieves he is on the brink of discovering a cure for
cancer, a 7 months pregnant woman, and her hus-
band, the pilot. This task was chosen on the basis
that it should stimulate discussion, leading to dia-
logues of a sufficient length to enable an adequate
number of interventions.
2.1.2 The DiET Chat Tool
The DiET chat tool itself is a custom built java
application consisting of two main components,
which will be outlined in turn; the user interface,
and the server console.
3This is, of course, an oversimplification, and note that in
contrast to pragmatic accounts, no claims are made regard-
ing higher level discourse effects of the split utterance, as the
focus is on the mechanisms which allow split utterances to
occur. Additional mechanisms could of course be posited in
processing models to account for any such differences.
2.1.3 User interface
The user interface is designed to look and feel
like instant messaging applications e.g. Microsoft
Messenger. It consists of a display split into two
windows, with a status bar, indicating whether any
other participant(s) are actively typing, between
them (see figure 1). The ongoing dialogue, con-
sisting of both the nickname of the contributor and
their transmitted text, is shown in the upper win-
dow. In the lower window, participants type and
revise their contributions, before sending them to
their co-participants. All key presses are time-
stamped and stored by the server.
Figure 1: The user interface chat window (as
viewed by participant ?sam?)
2.1.4 Server Console
All text entered is passed to the server, from
where it is relayed to the other participants, not
relayed directly between participants. Prior to be-
ing relayed, some turns are altered by the server to
create fake split utterances.
This is carried out automatically such that a
genuine single-person turn is split around a space
character near the centre of the string. The part
of the turn before the space is relayed first, fol-
lowed by a short delay during which no other turns
may be sent. This is followed by the part of the
turn after the space, as if they were in fact two
quite separate, consecutive turns. In every case,
the server produces two variants of the split utter-
ance, relaying different information to both recip-
ients. Each time an intervention is triggered, one
of the two recipients receives both parts from the
actual source of the utterance (henceforth referred
to as an AA-split). The other recipient receives
one of three, more substantial, manipulations; the
first half could appear to be from the actual ori-
gin with the second part of the split appearing to
originate from the other recipient (an AB-split), or
81
the inverse could be the case (a BA-split), or both
parts could be wrongly attributed to the other par-
ticipant (a BB-split). This design was in order to
separate the effects of a change in conversational
momentum (floor change) from the effects of split-
ting per se, hence the inclusion of the BB condi-
tion where who apparently has the floor is altered
without the utterance being attributable to differ-
ent participants. This contrast is shown in table 1.
Table 1: Comparison of split types
A types:
Should we start now
B sees (AA intervention):
A: Should we
A: start now
C sees (one of):
AB intervention: BA intervention: BB intervention:
A: Should we B: Should we B: Should we
B: start now A: start now B: start now
The intervention is triggered every 10 turns, and
restricted such that the participant who receives
the non AA-split is rotated (to ensure that each
participant only sees any of the more substantially
manipulated interventions every 30 turns). Which
of the three non AA-splits they see (AB, BA or
BB) is, however, generated randomly.
2.2 Subjects
41 male and 19 female native English speaking un-
dergraduate students were recruited for the exper-
iment, in groups of three to ensure that they were
familiar with each other. All had previous expe-
rience of internet chat software such as Microsoft
Messenger and each was paid ?7.00 for their par-
ticipation.
2.3 Procedure
Each of the triad of subjects was sat in front of a
desktop computer in separate rooms, so that they
were unable to see or hear each other. Subjects
were asked to follow the on screen instructions,
and input their e-mail address and their username
(the nickname that would identify their contribu-
tions in the chat window). When they had en-
tered these, a blank chat window appeared, and
they were given a sheet of paper with the task de-
scription on. Participants were instructed to read
this carefully, and begin discussing the task with
their colleagues via the chat window once they
had done so. They were told that the experi-
ment was investigating the differences in commu-
nication when conducted using a text only inter-
face as opposed to face-to-face. Additionally, sub-
jects were informed that the experiment would last
approximately 20-30 minutes, and that all turns
would be recorded anonymously for later analy-
sis. Once all three participants had been logged
on, the experimenter went to sit at the server ma-
chine, a fourth desktop PC out of sight of all three
subjects, and made no further contact with them
until at least 20 minutes of dialogue had been car-
ried out.
3 Results
A post experimental questionnaire and debrief-
ing showed that participants felt the conversations
went as smoothly as face-to-face dialogue. With
the exception of one subject, who had taken part
in a previous chat tool experiment and was there-
fore aware that interventions may occur, none of
the participants reported awareness of any inter-
ventions.
As production and receipt of turns sometimes
occurs in overlap in text chat, it is not possible
to say definitively when one turn is made in di-
rect response to another4. We therefore chose two
separate measures; next turn ? the first turn, by
the first recipient to start and complete a response,
after receipt of the intervention, and global ? all
the turns produced by both recipients between the
most recent intervention and the next intervention,
averaged to produce one data point per recipient
per intervention. This means that in the next turn
condition, only one datapoint is analysed for each
intervention, despite two different people seeing
an intervention (and both usually producing a re-
sponse). This was to try and isolate the initial re-
sponse to an intervention; for the other person who
saw a split but did not respond first, it is not clear
if they are responding to the split utterance, or to
4In online chat, participants can compose their next turns
simultaneously, and turns under construction when another is
received can be subsequently revised, prior to transmission.
This means that a genuine response to a split utterance might
have a negative start time. However, the inclusion of cases
where the whole turn was constructed after receiving the split
(an arbitrary cut-off point, which would catch some turns that
were responses to earlier turns in the dialogue, and miss some
which were begun before the intervention was received and
subsequently revised) should impose the same level of noise
in all cases.
82
the person who already responded to the split ut-
terance. In the global condition, in contrast, there
are two datapoints for each intervention (one for
each of the participants who saw a split utterance).
Of the 253 interventions to which at least one
recipient responded, 89 were AA/AB splits, 99
were AA/BA splits and 65 AA/BB splits. Table 2
shows the n values in each case.
Both next turn and global measures were anal-
ysed according to two factors in a 2 x 2 factorial
design; split ? whether both parts of the utterance
had appeared to come from the same person, or
from different sources ([AA and BB] vs [AB and
BA]), and floor change ? who appeared to have
produced the second part of the split, the genuine
source, or the other participant ([AA and BA] vs
[AB and BB]).
Measures selected for analysis were typing time
of turn (The time, in milliseconds, between the
first key press in a turn and sending the turn to
the other participants by hitting the return key) and
length of turn in characters as measures of produc-
tion; deletes per character (The number of keyed
deletes plus one (to prevent null values) divided
by the total number of characters) as a measure
of revisions; and typing time per character as a
measure of speed. Data in tables are displayed in
the original scale of measurement. However, as
inspection of the data showed that they were not
normally distributed, logarithmic transformations
(using loge) were applied to the data prior to all
formal analyses.
2 x 2 ANOVAs show a main effect of floor
change on the typing time of turn (see table 2).
This holds for next turns (F(3,249) = 7.13, p <
0.05) and globally (F(3,486) = 3.78, p < 0.05),
with participants taking longer over their turns in
the AB and BB conditions. There was no main
effect of split, and no effect of interaction. This
effect is greater locally than globally, with partici-
pants who respond first after seeing a floor change
condition taking more than 40% longer over their
turns than those who saw a non-floor change con-
dition. Globally the difference is in the order of
10%.
There was a main effect of split on the number
of deletes per character , which also held both in
the next turn condition (F(3,249) = 6.26, p < 0.05)
and globally (F(3,486) = 9.23, p < 0.05), with
subjects seeing a split condition (AB or BA) us-
ing fewer deletes per character than those seeing
a non-split condition (see table 3). There was no
main effect of floor change or interaction effect.
This effect is also stronger in the next turn con-
dition, with those not seeing a cross-person split
using over 50% more deletes. In the global condi-
tion, this difference is still 40%, though the overall
proportion of deletes is approximately 25% lower,
from 0.334 per character in the next turn condition
to 0.244 globally.
Table 2: Typing time of turn by type of interven-
tion
Condition Mean (s.d.) N (poss N)
Next Turn
AA 9475.54 (12258.5) 136 (253)
AB 14560.70 (18863.9) 37 (89)
BA 6968.24 (6437.0) 51 (99)
BB 14812.59 (20367.8) 29 (65)
Global
AA 11122.27 (14413.5) 246 (253)
AB 12500.98 (10944.6) 89 (89)
BA 9800.77 (8810.3) 92 (99)
BB 11561.67 (10138.4) 63 (65)
Table 3: Deletes per character by type of interven-
tion
Condition Mean (s.d.)
Next Turn
AA 0.435 (1.63)
AB 0.152 (0.30)
BA 0.202 (0.25)
BB 0.324 (0.61)
Global
AA 0.288 (0.83)
AB 0.192 (0.28)
BA 0.145 (0.18)
BB 0.287 (0.37)
Additional analyses showed an effect of floor
change on length of turn in characters (table 4)
in the next turn condition (F(3,249) = 5.57, p <
0.05) such that turns are longer in the AB and BB
conditions (note that though this might be thought
to be confounded by the typing time of turn, as you
would expect longer turns to take longer to type,
there are no significant effects when ANOVAs are
performed on typing time per character). There is
no main effect of split, or interaction effect. In the
global condition, however, there is a main effect
of split (F(3,486) = 4.08, p < 0.05) such that turns
are longer after seeing an utterance that appears
to be split between two different people (AB and
BA conditions). There is no main effect of floor
change, and no effect of interaction.
83
As the experiment was looking for generic ef-
fects of splitting on coordination, the location of
the splits was random. A post-hoc analysis was
therefore carried out to ascertain whether the stan-
dalone coherence (as judged by the authors) of the
two separate parts of the utterance was a possible
confounding factor. Examples of coherence judge-
ments are shown in table 5.
Table 4: Length of turn in characters by type of
intervention
Condition Mean (s.d.)
Next Turn
AA 23.95 (22.0)
AB 37.76 (34.9)
BA 23.92 (18.4)
BB 26.52 (21.5)
Global
AA 26.41 (20.4)
AB 32.12 (23.9)
BA 28.27 (18.4)
BB 25.78 (13.6)
Table 5: Examples of standalone coherence judge-
ment examples
Part of Split Coherent
First Second 1st 2nd
what the hell is that Y N
the woman is pregnant she should stay Y Y
these people said you did something N Y
I think this is also the wish of the doctor N N
2 x 2 ANOVAs showed that in the next turn con-
dition, there are no main effects of first or sec-
ond part coherence, but there was an interaction
effect of first part coherence by second part co-
herence on deletes (F(3,249) = 4.05, p < 0.05),
such that if both parts are independently coherent,
or if neither part is independently coherent, there
are fewer deletes used in the turn immediately fol-
lowing the intervention (see table 6). There are no
significant global effects.
Table 6: Deletes per character by first and second
part standalone coherence (next turn condition)
Coherence Mean (s.d.)1st 2nd
Y Y 0.198 (0.38)N 0.651 (2.26)
N Y 0.304 (0.66)N 0.206 (0.30)
Running a 2 x 2 x 2 x 2 ANOVA with these ad-
ditional factors does not alter the main effects ob-
served for floor change or split, as detailed above.
There are no additional interaction effects on any
of the measures.
4 Discussion
As this is the first experimental study into split ut-
terances using the DiET chat tool, what follows is
necessarily exploratory. This discussion presents
our current hypotheses as to how best to interpret
the data, as summarised in table 7, below.
Table 7: Summary of significant effects
Effect of Condition on and direction
Floor Next Turn Typing Time
Change and Global (AB ?BB) > (AA ?BA)
Floor Next Turn Number of Chars
Change (AB ?BB) > (AA ?BA)
Split Next Turn Deletes
and Global (AA ?BB) > (AB ?BA)
Split Global Number of Chars
(AB ?BA) > (AA ?BB)
Taking longer over the production of a turn (in-
dependently of typing speed) indicates a lack of
confidence in the conversation (misattributing the
second part of the utterance thus reducing confi-
dence), and is also indicative of local organisation
of turn-taking. If a participant who has seen a floor
change intervention (Participant C) responds first,
then they may be taking longer over their turns be-
cause there is less pressure on them to take a turn.
This is because of the C?s expectations. They will
falsely believe that the fake source (Participant B)
has just completed a turn, and will therefore not
expect them to take the floor, and the genuine
source (Participant A) will not be taking the floor
because they have just completed a turn (though C
does not know this). It is probable that in the turn
immediately following a floor change intervention
both these factors are at play, whereas globally it
is the weaker effect of generic confidence loss that
is observed. This compounding of effects in the
next turn condition would also help explain the di-
vergent effects on the length of turn in characters
in next turn and global conditions.
Regardless of the precise reasons for it, this ef-
fect of floor change on typing time clearly demon-
strates that changing the apparent speaker is dis-
ruptive, perhaps because it alters the forward mo-
84
mentum of the conversation.
More interestingly, independently of a change
of floor, seeing an utterance that appears to be split
between speakers also has an impact on the con-
versation, seen in the amount of revision under-
taken in formulating a response (deletes). One rea-
son why participants might worry less about pre-
cisely formulating their turns following a cross-
person split is that the production of a cross-person
split could have the effect on the recipient of sug-
gesting that the two other participants have formed
a ?party? (Schegloff, 1995) with respect to the de-
cision of who to throw out of the balloon. This
might be understood as signalling the formation
of a strong coalition between the other two partic-
ipants, therefore making the recipient behave as
though they are resigned to the decision of this
coalition. This is not the same as the effect on the
typing time of turn, whereby participants are less
rushed when seeing a change of floor. Deletes, on
the other hand, demonstrate how carefully partici-
pants are constructing their turns. Excerpt 1, taken
from the transcripts shows an example where this
appears to be the case.
Excerpt 1 AB-Split showing apparent coalition
between ?Bhups? and ?Dan? (?fake? part of split
shown in bold)
Bhups: and he can tell his formula
Dan: to tom and susie
If we take split utterances as an indicator of co-
ordination then it is likely that if we believe our
two conversational partners to be in coordination,
we will worry less about precisely formulating our
own contributions. This also backs up the idea that
people are not interchangeable.
The interaction of first and second part coher-
ence also underlines the effect of split on revi-
sions as outlined above. In the case were both
parts of the split could potentially stand as inde-
pendent utterances, they are treated as such and
the number of deletes per character is in line with
the global average (i.e. they are treated as nor-
mal dialogue). In the other non ambiguous case,
where neither part could be interpreted as an ut-
terance on its own, there are also fewer deletes,
in line with the result that there are fewer deletes
in strong split cases. Interestingly, the most dis-
ruptive case is that where the first part could have
been a standalone utterance, but the second part
could not. This could be seen as analogous to a
garden path effect, and provides some indication
that that the building up of interpretations is incre-
mental, and not concerned with who supplies the
input.
These results do not, of course, prejudice the
claim that, at a purely mechanistic level, people
could anticipate the structures needed to complete
a turn, as the interactive alignment model sug-
gests, because they are not concerned with the ac-
tual production of a split utterance, rather on the
effect it has on the conversation. They do indicate
that in terms of the effects of seeing split utter-
ances, the pragmatic approach offers a more fea-
sible level of analysis. For example, if we wish
to treat a jointly produced split utterance as sig-
nalling especially strong alignment, then we need
to account for more than simply syntax.
There is an issue with the design of the exper-
iment which means that the floor change effects
might be caused by a confounding variable; in
essence, because one of the recipients always re-
ceived an AA-split, in the cases which have been
labelled as cases of floor change, the two recipi-
ents will have been left with the impression that a
different person made the final contribution. This
means that there may well be a an effect of con-
founded listener expectation (though see Schober
and Brennan (2003) for discussion), although it
should be noted that this does not have any bear-
ing on the observed differences after an utterance
split between speakers. It is also possible that
split utterances might be particularly marked in a
chat environment, though preliminary results of a
corpus study show that, perhaps surprisingly, split
utterances also occur naturally and as frequently
in text-based chat (Eshghi, in prep) as they do in
face-to-face dialogue (Purver et al, 2009). Be-
cause of these issues, and the already noted po-
tential problems of linearity in text-based chat,
a follow-up study using a character-by-character
chat tool interface is underway. This more directly
enforces turn-taking, as it does not allow partici-
pants to formulate their turn before communicat-
ing it; each character is transmitted as and when it
is entered.
5 Conclusions
The experiment reported here offers clues towards
an understanding of split utterances as an exam-
ple of dialogue phenomena, and provides evidence
85
that speaker switches affect processing where they
interfere with expectations about who will speak
next and that the pragmatic effect of a split is to
suggest to other participants the formation of a
coalition or sub-?party?. It also clearly demon-
strates that this type of experiment provides a fruit-
ful line of future research in the ongoing attempt to
adequately characterise dialogue, though further
developments are needed.
References
H. Branigan, M. Pickering, and A. Cleland. 2000.
Syntactic co-ordination in dialogue. Cognition,
75(2):13?25.
H. Branigan, M. Pickering, J. Pearson, J. McLean, and
C. Nass. 2003. Syntactic alignment between com-
puters and people: The role of belief about mental
states. In Proceedings of the Twenty-fifth Annual
Conference of the Cognitive Science Society.
H. Branigan, M. Pickering, J. McLean, and A. Stewart.
2006. The role of local and global syntactic struc-
ture in language production: Evidence from syn-
tactic priming. Language and cognitive processes,
21(7-8):974?1010.
R. Cann, R. Kempson, and L. Marten. 2005. The Dy-
namics of Language. Elsevier, Oxford.
H. Clark. 1996. Using Language. Cambridge Univer-
sity Press.
A. Eshghi. in prep. Uncommon ground: the distri-
bution of dialogue contexts. Ph.D. thesis, Depart-
ment of Computer Science, Queen Mary University
of London.
A. Fox et al 2007. Principles shaping grammati-
cal practices: an exploration. Discourse Studies,
9(3):299.
M. Hayashi. 1999. Where Grammar and Interac-
tion Meet: A Study of Co-Participant Completion in
Japanese Conversation. Human Studies, 22(2):475?
499.
P. G. T. Healey, M. Purver, J. King, J. Ginzburg, and
G. J. Mills. 2003. Experimenting with clarifica-
tion in dialogue. In Proceedings of the 25th Annual
Meeting of the Cognitive Science Society.
M. Helasvuo. 2004. Shared syntax: the gram-
mar of co-constructions. Journal of Pragmatics,
36(8):1315?1336.
G. Lerner and T. Takagi. 1999. On the place
of linguistic resources in the organization of talk-
in-interaction: A co-investigation of English and
Japanese grammatical practices. Journal of Prag-
matics, 31(1):49?75.
G. Lerner. 1991. On the syntax of sentences-in-
progress. Language in Society, pages 441?458.
G. Lerner. 1996. On the semi-permeable character
of grammatical units in conversation: Conditional
entry into the turn space of another speaker. In
E. Ochs, E. A. Schegloff, and S. A. Thompson,
editors, Interaction and grammar, pages 238?276.
Cambridge University Press.
G. Lerner. 2004. Collaborative turn sequences. In
Conversation analysis: Studies from the first gener-
ation, pages 225?256. John Benjamins.
M. Oelschlaeger and J. Damico. 1998. Joint produc-
tions as a conversational strategy in aphasia. Clini-
cal linguistics & phonetics, 12(6):459?480.
M. Pickering and S. Garrod. 2004. Toward a mech-
anistic psychology of dialogue. Behavioral and
Brain Sciences, 27:169?226.
M. Poesio and H. Rieser. In preparation. Completions,
coordination, and alignment in dialogue. to appear.
K. Poncin and H. Rieser. 2006. Multi-speaker utter-
ances and co-ordination in task-oriented dialogue.
Journal of Pragmatics, 38(5):718?744.
M. Purver, R. Cann, and R. Kempson. 2006.
Grammars as parsers: Meeting the dialogue chal-
lenge. Research on Language and Computation,
4(2-3):289?326.
M. Purver, C. Howes, P. G. Healey, and E. Gre-
goromichelaki. 2009. Split utterances in dialogue:
a corpus study. In SigDial 2009 workshop proceed-
ings.
H. Sacks, E. Schegloff, and G. Jefferson. 1974. A sim-
plest systematics for the organization of turn-taking
for conversation. Language, pages 696?735.
E. Schegloff. 1995. Parties and talking together: Two
ways in which numbers are significant for talk-in-
interaction. Situated order: Studies in the social
organization of talk and embodied activities, pages
31?42.
M. Schober and S. Brennan. 2003. Processes of in-
teractive spoken discourse: The role of the partner.
Handbook of discourse processes, pages 123?64.
B. Szczepek. 2000. Formal Aspects of Col-
laborative Productions in English Conversa-
tion. Interaction and Linguistic Structures
(InLiSt), http://www.uni-potsdam.de/u/
inlist/issues/17/index.htm.
86
Proceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 262?271,
Queen Mary University of London, September 2009. c?2009 Association for Computational Linguistics
Split Utterances in Dialogue: a Corpus Study
Matthew Purver, Christine Howes,
and Patrick G. T. Healey
Department of Computer Science
Queen Mary University of London
Mile End Road, London E1 4NS, UK
{mpurver,chrizba,ph}@dcs.qmul.ac.uk
Eleni Gregoromichelaki
Department of Philosophy
King?s College London
Strand, London WC2R 2LS, UK
eleni.gregor@kcl.ac.uk
Abstract
This paper presents a preliminary English
corpus study of split utterances (SUs), sin-
gle utterances split between two or more
dialogue turns or speakers. It has been
suggested that SUs are a key phenomenon
of dialogue, which this study confirms: al-
most 20% of utterances were found to fit
this general definition, with nearly 3% be-
ing the between-speaker case most often
studied. Other claims/assumptions in the
literature about SUs? form and distribu-
tion are investigated, with preliminary re-
sults showing: splits can occur within syn-
tactic constituents, apparently at any point
in the string; it is unusual for the sepa-
rate parts to be complete units in their own
right; explicit repair of the antecedent does
not occur very often. The theoretical con-
sequences of these results for claims in
the literature are pointed out. The prac-
tical implications for dialogue systems are
mentioned too.
1 Introduction
Split utterances (SUs) ? single utterances split be-
tween two or more dialogue turns/speakers ? have
been claimed to occur regularly in dialogue, espe-
cially according to the observations reported in the
Conversational Analysis (CA) literature, which is
based on the analysis of naturally occurring di-
alogues. SUs are of interest to dialogue theo-
rists as they are a clear sign of how turns cohere
with each other at all levels ? syntactic, seman-
tic and pragmatic. They also indicate the radi-
cal context-dependency of conversational contri-
butions. Turns can, in general, be highly ellip-
tical and nevertheless not disrupt the flow of the
dialogue. SUs are the most dramatic illustration
of this: contributions spread across turns/speakers
rely crucially on the dynamics of the unfolding
context, linguistic and extra-linguistic, in order to
guarantee successful processing and production.
Utterances that are split across speakers also
present a canonical example of participant coor-
dination in dialogue. The ability of one partic-
ipant to continue another interlocutor?s utterance
coherently, both at the syntactic and the seman-
tic level, suggests that both speaker and hearer are
highly coordinated in terms of processing and pro-
duction. The initial speaker must be able to switch
to the role of hearer, processing and integrating the
continuation of their utterance, whereas the ini-
tial hearer must be closely monitoring the gram-
mar and content of what they are being offered
so that they can take over and continue in a way
that respects the constraints set up by the first part
of the utterance. In fact there is (anecdotal) ev-
idence that such constraints are fully respected
across speaker and hearer in such utterances (see
e.g. Gregoromichelaki et al (2009)). A large pro-
portion of the CA literature on SUs tries to iden-
tify the conditions under which SUs usually oc-
cur (see section 2). However, this emphasis seems
to miss the important generalisation, confirmed
by the present study, that, syntactically, a speaker
switch may be able to occur anywhere in a string.
From a theoretical point of view, the implica-
tions of the above are that, if such observations
have an empirical foundation, the grammar em-
ployed by the interlocutors must be able to license
and the semantics interpret chunks much smaller
than the usual sentence/proposition units. More-
over, these observations have implications for the
nature of the grammar itself: dynamic, incremen-
tal formalisms seem more amenable to the mod-
262
elling of this phenomenon as the switch of roles
while syntactic/semantic dependencies are pend-
ing can be taken as evidence for direct involve-
ment of the grammar in the successful process-
ing/production of such utterances. Indeed, Poesio
and Rieser (to appear) claim that ?[c]ollaborative
completions . . . are among the strongest evidence
yet for the argument that dialogue requires coor-
dination even at the sub-sentential level? (italics
original).
From a psycholinguistic point of view, the phe-
nomenon of SUs is compatible with mechanis-
tic approaches as exemplified by the Interactive
Alignment model of Pickering and Garrod (2004)
where it is claimed that it should be as easy to
complete someone else?s sentence as one?s own
(Pickering and Garrod, 2004, p186). According
to this model, speaker and listener ought to be in-
terchangeable at any point. This is also the stance
taken by the grammatical framework of Dynamic
Syntax (DS) (Kempson et al, 2001; Cann et al,
2005). In DS, parsing and production are taken
to employ the same mechanisms, leading to a pre-
diction that split utterances ought to be strikingly
natural (Purver et al, 2006). However, from a
pragmatic point of view, utterance continuation
by another speaker might involve some kind of
guessing1 or preempting the other interlocutor?s
intended content. It has therefore been claimed
that a full account of this phenomenon requires
a complete model of pragmatics that can handle
intention recognition and formation. Indeed, Poe-
sio and Rieser (to appear) claim that ?the study
of sentence completions . . . may be used to com-
pare competing claims about coordination ? i.e.
whether it is best explained with an intentional
model like Clark (1996)?s . . . or with a model
based on simpler alignment models like Pickering
and Garrod (2004)?s.? They conclude that a model
which includes modelling of intentions better cap-
tures the data.
For computational models of dialogue, how-
ever, SUs pose a challenge. While Poesio and
Rieser (to appear) and Purver et al (2006) pro-
vide general foundational models for various parts
of the phenomenon, there are many questions that
remain if we are to begin automatic processing.
A computational dialogue system must be able
to identify SUs, match up their two (or more)
1Note that this says nothing about whether such a contin-
uation is the same as the initial speaker?s intended continua-
tion.
parts (which may not necessarily be adjacent), in-
tegrate them into some suitable syntactic and/or
semantic representation, and determine the over-
all pragmatic contribution to the dialogue context.
SUs also have implications for the organisation of
turn-taking in such models (see e.g. Sacks et al
(1974)), as regards what conditions (if any) allow
or prevent successful turn transfer. Additionally,
from a socio-linguistic point of view, turn-taking
operates (according to Schegloff (1995)) not on
individual conversational participants, but on ?par-
ties?. Lerner (1991) suggests that split utterances
can clarify the formation of such parties in that
they reveal evidence of how syntax can be em-
ployed to organise participants into ?groups?.
Analysis of SUs, when they can or cannot oc-
cur, and what effects they have on the coordina-
tion of agents in dialogue, is therefore an area of
interest not only for conversational analysts wish-
ing to characterise systematic interactions in di-
alogue, but also for linguists trying to formulate
grammars of dialogue, psychologists and sociolin-
guists interested in alignment mechanisms and so-
cial interaction, and those interested in building
automatic dialogue processing systems. In this pa-
per we present and examine empirical corpus data
in order to shed light on some of the questions and
controversies around this phenomenon.
2 Related Work
Most previous work on what we call SUs has ex-
amined specific sub-cases, generally of the cross-
speaker type, and have referred to these vari-
ously as collaborative turn sequences (Lerner,
1996; Lerner, 2004), collaborative completions
(Clark, 1996; Poesio and Rieser, to appear),
co-constructions (Sacks, 1992), joint produc-
tions (Helasvuo, 2004), co-participant comple-
tions (Hayashi, 1999; Lerner and Takagi, 1999),
collaborative productions (Szczepek, 2000) and
anticipatory completions (Fox and others, 2007)
(amongst others). Here we discuss some of these
views.
Conversation Analysis Lerner (1991) identifies
various structures typical of SUs which contain
characteristic split points. Firstly he gives a
number of ?compound? turn-constructional units
(TCUs), i.e., structures that include an initial con-
stituent that hearers can identify as introducing
some later final component. Examples include the
IF X-THEN Y, WHEN X-THEN Y and INSTEAD
263
OF X-Y constructions:
(1) A: Before that then if they were ill
G: They get nothing. [BNC H5H 110-111]
Other cues for potential anticipatory completions
include quotation markers (e.g. SHE SAID), paren-
thetical inserts and lists, as well as non-syntactic
cues such as contrast stress or prefaced disagree-
ments. Ru?hlemann (2007) uses corpus analysis to
examine sentence relatives as typical expansions
of another interlocutor?s turn (see also (16)):
(2) A: profit for the group is a hundred and
ninety thousand pounds.
B: Which is superb. [BNC FUK 2460-2461 ]
Opportunistic Cases Although Lerner focuses
on these projectable turn completions, he also
mentions that splits can occur at other points such
as ?intra-turn silence?, hesitations etc. which he
terms opportunistic completions:
(3) A: Well I do know last week thet=uh Al was
certainly very ? pause 0.5?
B: pissed off [(Lerner, 1996, p260)]
As he makes no claims regarding the frequency
of such devices for SUs, it would be interesting to
know how common these are (insomuch as they
occur at all and can be accordingly classified), es-
pecially as studies on SUs in Japanese (Hayashi,
1999) show that although SUs do occur, they do
not rely on compound TCUs.
Expansions vs. Completions Other classifica-
tions of SUs often distinguish between expansions
and completions (Ono and Thompson, 1993). Ex-
pansions are continuations which add, e.g., an ad-
junct, to an already complete syntactic element:
(4) T: It?ll be an E sharp.
G: Which will of course just be played as an
F. [BNC G3V 262-263]
whilst completions involve the addition of syntac-
tic material which is required to make the whole
utterance complete:
(5) A: . . . and then we looked along one deck, we
were high up, and down below there were
rows of, rows of lifeboats in case you see
B: There was an accident.
A: of an accident [BNC HDK 63-65]
In terms of frequency, the only estimate we
know of is Szczepek (2000), where there are ap-
parently 200 cross-person SUs in 40 hours of En-
glish conversation (there is no mention of the num-
ber of sentences or turns this equates to), of which
75% are completions.2 As briefly outlined above,
CA analyses of SUs tend to be broadly descriptive
of what they reveal for conversational practices.
Because such analyses present real examples they
establish that the phenomenon is a genuine one;
however, there is no discussion of its scale (with
the exception of Szczepek (2000), which offers ex-
tremely limited figures). Even though as a gen-
uine phenomenon it is of theoretical interest, the
lack of frequency statistics prevents generalisabil-
ity. Therefore, any claims that SUs are pervasive
in dialogue need empirical backing.
Linguistic Models Purver et al (2006) present
a grammatical model for split utterances, using an
inherently incremental grammar formalism, Dy-
namic Syntax (Kempson et al, 2001; Cann et al,
2005). This model shows how syntactic and se-
mantic processing can be accounted for no mat-
ter where the split occurs in a sentence; how-
ever, as their interest is in grammatical process-
ing, they give no account of any higher-level in-
ferences which may be required. Poesio and
Rieser (to appear) present a general model for col-
laborative completions based in the PTT frame-
work, using an incremental LTAG-based gram-
mar and an information-state-based approach to
context modelling. While many parts of their
model are compatible with a simple alignment-
based communication model like Pickering and
Garrod (2004)?s, they see intention recognition as
crucial to dialogue management. They conclude
that an intention-based model, more like Clark
(1996)?s, is more suitable. Their primary concern
is to show how such a model can account for the
hearer?s ability to infer a suitable continuation, but
their use of an incremental interpretation method
also allows an explanation of the low-level utter-
ance processing required. Nevertheless, the use
of an essentially head-driven grammar formalism
suggests that some syntactic splits that appear in
our corpus might be more problematic than oth-
ers.
Corpus Studies Skuplik (1999), as reported by
Poesio and Rieser (to appear), collected data from
German two-party task-oriented dialogue, and an-
notated for split utterance phenomena. She found
that expansions (cases where the part before the
split can be considered already complete) were
2However, this could be affected by her decision not to
include what she calls appendor questions in her data which
could also be argued to be expansion SUs.
264
more common than completions (where the first
part is incomplete as it stands). Given that this
study focuses on task-oriented dialogue, it needs
to be shown that its results can be replicated in nat-
urally occurring dialogue. In addition, de Ruiter
and van Dienst (in preparation) are also in the pro-
cess of studying other-initiated completions, in the
above sense, and their effect on the progressivity
of dialogue turns; however no results are available
to us at this point in time.
Dialogue Models We are not aware of any
system/model which treats other-person splits,
but same-person ones are now being looked at.
Skantze and Schlangen (2009) present an incre-
mental system design (for a limited domain) which
can react to user feedback, e.g., backchannels, and
resume with utterance completion if interrupted.
Some related empirical work regarding the issue
of turn-switch addressed here is also presented in
Schlangen (2006) but the emphasis there centered
mostly on prosodic rather than grammar/theory-
based factors.
3 Method
3.1 Terminology
In this paper, as our interest is general, we use the
term split utterances (SUs) to cover all instances
where an utterance is spread across more than one
dialogue contribution ? whether the contributions
are by the same or different speakers. We there-
fore use the term split point to refer to the point at
which the utterance is split (rather than e.g. tran-
sition point which is associated with a speaker
change). Cases where speaker does change across
the split will be called other-person splits; oth-
erwise same-person splits. One of the reasons
for including same-person splits is that there are
claims in the literature that the initial speaker may
strategically continue completing their own utter-
ance, after another person?s intervention, as an al-
ternative to acceptance or rejection of this inter-
vention (delayed completion, (Lerner, 1996)). In
addition, both grammatical formalisms (Purver et
al., 2006) and psycholinguistic models (Picker-
ing and Garrod, 2004) predict that SUs should be
equally natural in both the same- and other- person
conditions.
As not all cases will lead to complete contri-
butions, and not all will be split over exactly two
contributions, we also avoid terms like first-half,
second-half and completion: instead the contri-
butions on either side of a split point will be re-
ferred to as the antecedent and the continuation.
In cases where an utterance has more than one split
point, some portions may therefore act as the con-
tinuation for one split point, and the antecedent for
the next.
3.2 Questions
General Our first interest is in the general statis-
tics regarding SUs: how often do they occur, and
what is the balance between same- and other-
person splits? Do they usually fall into the specific
categories (with specific preferred split points) ex-
amined by e.g. Lerner (1991), or can the split
point be anywhere?
Completeness For a grammatical treatment
of SUs, as well as for implementing pars-
ing/production mechanisms for their processing,
we need to know about the likely completeness
of antecedent and continuation (if they are al-
ways complete in their own right, a standard head-
driven grammar may be suitable; if not, some-
thing more fundamentally incremental may be re-
quired). In addition, CA and other strategic anal-
yses of dialogue phenomena predict that split ut-
terances should occur at turn-transfer points that
are foreseeable by the participants. Complete syn-
tactic units serve this purpose from this point of
view and lack of such completeness will seem
to weaken this general claim. We therefore ask
how often antecedents and continuations are them-
selves complete,3 and look at the syntactic and lex-
ical categories which occur either side of the split.
Repair and Overlap Thirdly, we look at how
often splits involve explicit repair of antecedent
material, and how this depends on antecedent
completeness. Although, sometimes, repair might
be attributed to overlap or speaker uncertainty, it
also might indicate issues regarding preemptive
tactics on the part of the current speaker who needs
to reformulate the original contribution in order
to accommodate their novel offering or take into
account feedback offered while constructing their
utterance. Amount of repair also indicates the de-
gree of attempt the current speaker is making to
3For antecedents, we are more interested in whether they
end in a way that seems complete (they may have started ir-
regularly due to overlap or another split); for continuations,
whether they start in such a way (they may not get finished
for some other reason, but we want to know if they would be
complete if they do get finished).
265
Tag Value Explanation
end-complete y/n For all sentences: does this sentence end in such a way as to
yield a complete proposition or speech act?
continues sentence ID For all sentences: does this sentence continue the proposition
or speech act of a previous sentence? If so, which one?
repairs number of words For continuations: does this continuation explicitly repair
words in the antecedent? If so, how many?
start-complete y/n For continuations: does this continuation start in such a way as
to be able to stand alone as a complete proposition or speech
act?
Table 1: Annotation Tags
integrate syntactically their contribution with the
antecedent. However, we also examine how often
continuations involve overlap, which also has im-
plications for turn-taking management, and how
this depends on antecedent completeness.
3.3 Corpus
For this exercise we used the portion of the
BNC (Burnard, 2000) annotated by Ferna?ndez and
Ginzburg (2002), chosen to maintain a balance be-
tween context-governed dialogue (tutorials, meet-
ings, doctor?s appointments etc.) and general con-
versation. This portion comprises 11,469 sen-
tences taken from 200-turn sections of 53 separate
dialogues.
The BNC transcripts are already annotated for
overlapping speech, for non-verbal noises (laugh-
ter, coughing etc.) and for significant pauses.
Punctuation is included, based on the original au-
dio and the transcribers? judgements; as the au-
dio is not available, we allowed annotators to use
punctuation where it aided interpretation. The
BNC transcription protocol provides a sentence-
level annotation as well as an utterance (turn)-level
one, where turns may be made of several sentences
by the same speaker. We annotated at a sentence-
level, to allow self-continuations within a turn to
be examined. The BNC also forces turns to be
presented in linear order, which is vital if we are
to accurately assess whether turns are continua-
tions of one another; however, this has a side-
effect of forcing long turns to appear split into sev-
eral shorter turns when interrupted by intervening
backchannels. We will discuss this further below.
Annotation Scheme The initial stage of manual
annotation involved 4 tags: start-complete,
end-complete, continues and repairs ?
these are explained in Table 1 above. Sentences
which somehow require continuation (whether
they receive it or not) are therefore those marked
end-complete=n; sentences which act as
continuations are those marked with non-empty
continues tags; and their antecedents are the
values of those continues tags. Further specific
information about the syntactic or lexical nature of
antecedent or continuation components could then
be extracted (semi-)automatically, using the BNC
transcript and part-of-speech annotations.
Inter-Annotator Agreement Three annotators
were used, all linguistically knowledgeable. First,
all three annotators annotated one dialogue inde-
pendently, then compared results and discussed
differences. They then annotated 3 further di-
alogues independently to assess inter-annotator
agreement; kappa statistics (Carletta, 1996) are
shown in Table 2 below.
Tag KND KBG KB0
end-complete .86-.92 .80-1.0 .73-.90
continues (y/n) .89-.81 .76-.85 .77-.89
continues (ant) .90-.82 .74-.85 .76-.86
repairs 1.0-1.0 .55-.81 1.0-1.0
Table 2: Inter-Annotator ? statistic (min-max)
With the exception of the repairs tag for one
annotator pair for one dialogue, all are above 0.7;
the low figure results from a few disagreements
in a dialogue with only a very small number of
repairs instances. The remaining dialogues
were divided evenly between the three annotators.
4 Results and Discussion
The 11,469 sentences annotated yielded 2,228
SUs, of which 1,902 were same-person and 326
other-person splits; 111 examples involved an ex-
plicit repair by the continuation of some part of the
antecedent.
266
person: same other
overlapping 0 17
adjacent 840 260
sep. by overlap 320 10
sep. by backchnl 460 17
sep. by 1 sent 239 16
sep. by 2 sents 31 4
sep. by 3 sents 5 1
sep. by 4 sents 4 0
sep. by 5 sents 1 0
sep. by 6 sents 2 1
Total 1902 326
Table 3: Antecedent/continuation separation
General Same-person splits are much more
common than other-person; however, this is partly
an artefact of the BNC transcription protocol
(which forces contributions to be linearly ordered)
and our choice to annotate at the sentence level.
Around 44% of same-person cases are splits be-
tween sentences within the same-speaker turn;
and a further 17% are separated only by other-
speaker material which entirely overlaps with the
antecedent and therefore does not necessarily ac-
tually interrupt the turn. Both of these might be
considered as single utterances under some views.
However, we believe that splits between same-
turn sentences must be investigated in that the
transcription into separate sentences does indicate
some pause or other separating prosody and, from
a processing/psycholinguistic point of view, it
should be determined whether other-person splits
occur in the same places as same-person split
boundaries. Even in cases of overlap, one can-
not exclude the fact that the shape of the current
speaker?s utterance is influenced by receipt of the
feedback. Nevertheless, we will examine these
issues in further research and hence we exclude
within-turn splits of this type from here on.
Many splits are non-adjacent (see Table 3), with
the antecedent and continuation separated by at
least one intervening sentence. In same-person
cases, once we have excluded the within-turn
splits described above, this must in fact always
be the case; the intervening material is usually a
backchannel (62% of remaning cases) or a sin-
gle other sentence (32%, often e.g. a clarification
question), but two intervening sentences are possi-
ble (4%) with up to six being seen. In other-person
cases, 88% are adjacent or separated only by over-
lapping material, but again up to six intervening
person: same other
and/but/or 748 116
so/whereas 257 39
because 77 3
(pause) 56 5
which/who/etc 26 4
instead of 4 1
said/thought/etc 14 0
if then 1 0
when then 1 1
(other) 783 161
Table 4: Continuation categories
sentences were seen, with a single sentence most
common (10%, in half of which the intervening
sentence was a backchannel).
Many utterances have more than one split. In
same-person cases, a single utterance can be split
over as many as thirteen individual sentence con-
tributions; although such extreme cases occur gen-
erally within one-sided dialogues such as tutori-
als, many multi-split cases are also seen in general
conversation. Only 63% of cases consisted of only
two contributions. Antecedents can also receive
more than one competing continuation, although
this is rare: two continuations are seen in 2% of
cases.
CA Categories We searched for examples
which match CA categories (Lerner, 1991;
Ru?hlemann, 2007) by looking for particular lex-
ical items on either side of the split. Matching was
done loosely, to allow for the ungrammatical na-
ture of dialogue ? for example, an instance was
taken to match the IF X-THEN Y pattern if the con-
tinuation began with ?then? (modulo filled pauses
and non-verbal material) and the antecedent con-
tained ?if? at any point) ? so the counts may be
over-estimates. For Lerner (1996)?s opportunistic
cases, we looked for filled pauses (?er/erm? etc.)
or pauses explicitly annotated in the transcript, so
counts in this case may be underestimates.4 We
also chose some other broad categories based on
our observations of the most common cases. Re-
sults are shown in Table 4.5
The most common of the CA categories can be
4In further research we will examine other features as spe-
cialised laugh tokens, repetitions etc. as well as their particu-
lar positioning
5Note that the categories in Table 4 are not all mutually
exclusive (e.g. an example may have both an ?and?-initial
continuation and an antecedent ending in a pause), so column
sums will not match Table 3.
267
seen to be Lerner (1996)?s hesitation-related op-
portunistic cases, which make up at least 2-3% of
both same- and other-person splits. Ru?hlemann
(2007)?s sentence relative clause cases are next,
with over 1%; the others make up only small pro-
portions.
In contrast, by far the most common pattern (for
both same- and other-) is the addition of an ex-
tending clause, either a conjunction introduced by
?and/but/or/nor? (35-40%), or other clause types
with ?so/whereas/nevertheless/because?. Other
less obviously categorisable cases make up 40-
50% of continuations, with the most common first
words being ?you?, ?it?, ?I?, ?the?, ?in? and ?that?.
Completeness and repair Examination of the
end-complete annotations shows that about
8% of sentences in general are incomplete, but
that (perhaps surprisingly) only 63% of these get
continued. For both same- and other-person con-
tinuations, the vast majority (72% and 74%) con-
tinue an already complete antecedent, with only
26-28% therefore being completions in the sense
of e.g. de Ruiter and van Dienst (in preparation).
This does, however, mean that continuations are
significantly more likely than other sentences to
follow an incomplete antecedent (p < 0.001 us-
ing ?2(1)). Interestingly, though, continuations are
no more likely than other sentences to be complete
themselves.
The frequent clausal categories from Table 4 are
all more likely to continue complete antecedents
than incomplete ones, with the exception of the
(other) category; this suggests that split points
often occur at random points in a sentence, without
regard to particular clausal constructions (see also
A.1 for more examples and context):
(6) D: you know what the actual variations
U: entails
D: entails. you know what the actual quality
of the variations are.
[BNC G4V 114-117]
For the less frequent (e.g. ?if/then?, ?instead of?)
categories, the counts are too low to be sure.
Excluding all the clausal constructions (i.e.
looking only at the general (other) category),
and looking only at other-person cases, we see that
antecedents often end in a complete way (53%) but
that continuations do not often start in a complete
way (24%). Continuations are more than twice
as likely to start in a non-complete as opposed
to complete way, even after complete antecedents.
Explicit repair of some portion of the antecedent
is not common, only occurring in just under 5%
of splits. As might be expected, incomplete an-
tecedents are more likely to be repaired (13% vs.
2%, p < 0.001 using ?2(1)). Other-continuations
are also significantly more likely to repair their an-
tecedents than same-person cases (10% vs. 4%,
p < 0.001 using ?2(1)).
Problematic cases Examination of the data
shows that SUs is not necessarily an autonomous
well-defined category independent of other frag-
ment classifications in the literature. Besides cases
where it is not easy to identify whether a fragment
is a continuation or not or what the antecedent
is (see A.2), there are also cases where, as has
already been pointed out in the literature (Gre-
goromichelaki et al, 2009; Bunt, 2009), fragments
exhibit multifunctionality. This can be illustrated
by the following where the continuation could be
taken also as request for confirmation/question (7)
or a reply to a clarification request (8):
(7) M: It?s generated with a handle and
J: Wound round?
M: Yes [BNC K69 109-112]
(8) S: Quite a good word processor.
J: A word processor?
S: Which is vag- it?s basically a subset of
Word. [BNC H61 37-39]
In this respect, an interesting category is Lerner?s
delayed completions where often the continuation
also serves as some kind of repair or reformulation
(see e.g. (6) and A.3 (26)).
5 Conclusions
Although most of Lerner (1991)?s categories ap-
pear, they are not necessarily the most frequent.
On the other hand, the general results seem to in-
dicate that splits can occur anywhere in a string,
both in the same- or other- conditions. Both these
are consistent with models that advocate highly
coordinated resources between interlocutors and,
moreover, the need for highly incremental means
of processing (Purver et al, 2006; Skantze and
Schlangen, 2009). From a computational mod-
elling point of view, the results also indicate that
start-completeness of continuations is rare, which
means that a dialogue system has a chance of spot-
ting continuations from surface characteristics of
268
the input. This is hampered though by the fact
that the split can occur within any type of syn-
tactic constituent, hence no reliable grammatical
features can be employed securely. On the other
hand, end-incompleteness of antecedents is not as
common as would be expected and long distances
between antecedent and continuation are possible.
In this respect, locating the antecedent is not a
straightforward task for automated systems, espe-
cially again as this can be any type of constituent.
References
H. Bunt. 2009. Multifunctionality and multidimen-
sional dialogue semantics. In Proceedings of Dia-
Holmia, 13th SEMDIAL Workshop.
L. Burnard. 2000. Reference Guide for the British Na-
tional Corpus (World Edition). Oxford University
Computing Services http://www.natcorp.
ox.ac.uk/docs/userManual/.
R. Cann, R. Kempson, and L. Marten. 2005. The Dy-
namics of Language. Elsevier, Oxford.
J. Carletta. 1996. Assessing agreement on classifica-
tion tasks: The kappa statistic. Computational Lin-
guistics, 22(2):249?255.
H. Clark. 1996. Using Language. Cambridge Univer-
sity Press.
J. de Ruiter and M. van Dienst. in preparation. Com-
pleting other people?s utterances: evidence for for-
ward modeling in conversation. ms.
R. Ferna?ndez and J. Ginzburg. 2002. Non-sentential
utterances: A corpus-based study. Traitement Au-
tomatique des Langues, 43(2).
A. Fox et al 2007. Principles shaping grammati-
cal practices: an exploration. Discourse Studies,
9(3):299.
E. Gregoromichelaki, Y. Sato, R. Kempson, A. Gargett,
and C. Howes. 2009. Dialogue modelling and the
remit of core grammar. In Proceedings of IWCS.
M. Hayashi. 1999. Where Grammar and Interac-
tion Meet: A Study of Co-Participant Completion in
Japanese Conversation. Human Studies, 22(2):475?
499.
M. Helasvuo. 2004. Shared syntax: the gram-
mar of co-constructions. Journal of Pragmatics,
36(8):1315?1336.
R. Kempson, W. Meyer-Viol, and D. Gabbay. 2001.
Dynamic Syntax: The Flow of Language Under-
standing. Blackwell.
G. Lerner and T. Takagi. 1999. On the place
of linguistic resources in the organization of talk-
in-interaction: A co-investigation of English and
Japanese grammatical practices. Journal of Prag-
matics, 31(1):49?75.
G. Lerner. 1991. On the syntax of sentences-in-
progress. Language in Society, pages 441?458.
G. Lerner. 1996. On the semi-permeable character
of grammatical units in conversation: Conditional
entry into the turn space of another speaker. In
E. Ochs, E. A. Schegloff, and S. A. Thompson,
editors, Interaction and grammar, pages 238?276.
Cambridge University Press.
G. Lerner. 2004. Collaborative turn sequences. In
Conversation analysis: Studies from the first gener-
ation, pages 225?256. John Benjamins.
T. Ono and S. Thompson. 1993. What can conversa-
tion tell us about syntax. In P. Davis, editor, Alterna-
tive Linguistics: Descriptive and Theoretical Modes.
Benjamin.
M. Pickering and S. Garrod. 2004. Toward a mech-
anistic psychology of dialogue. Behavioral and
Brain Sciences, 27:169?226.
M. Poesio and H. Rieser. to appear. Completions, co-
ordination, and alignment in dialogue. Ms.
M. Purver, R. Cann, and R. Kempson. 2006.
Grammars as parsers: Meeting the dialogue chal-
lenge. Research on Language and Computation,
4(2-3):289?326.
C. Ru?hlemann. 2007. Conversation in context: a
corpus-driven approach. Continuum.
H. Sacks, E. A. Schegloff, and G. Jefferson. 1974.
A simplest systematics for the organization of turn-
taking for conversation. Language, 50(4):696?735.
H. Sacks. 1992. Lectures on Conversation. Blackwell.
E. Schegloff. 1995. Parties and talking together: Two
ways in which numbers are significant for talk-in-
interaction. Situated order: Studies in the social
organization of talk and embodied activities, pages
31?42.
D. Schlangen. 2006. From reaction to prediction: Ex-
periments with computational models of turn-taking.
In Proceedings of the 9th International Conference
on Spoken Language Processing (INTERSPEECH -
ICSLP).
G. Skantze and D. Schlangen. 2009. Incremental dia-
logue processing in a micro-domain. In Proceedings
of the 12th Conference of the European Chapter of
the ACL (EACL 2009).
K. Skuplik. 1999. Satzkooperationen. definition und
empirische untersuchung. SFB 360 1999/03, Biele-
feld University.
B. Szczepek. 2000. Formal Aspects of Collaborative
Productions in English Conversation. Interaction
and Linguistic Structures (InLiSt), http://www.
uni-potsdam.de/u/inlist/issues/17/.
269
A Examples
A.1 Split points
(6) D: Yeah I mean if you?re looking at quan-
titative things it?s really you know how
much actual- How much variation hap-
pens whereas qualitative is ?pause? you
know what the actual variations
U: entails
D: entails. you know what the actual quality
of the variations are.
[BNC G4V 114-117]
(9) A: All the machinery was
G: [[All steam.]]6
A: [[operated]] by steam
[BNC H5G 177-179]
(10) K: I?ve got a scribble behind it, oh annual re-
port I?d get that from.
S: Right.
K: And the total number of [[sixth form stu-
dents in a division.]]
S: [[Sixth form stu-
dents in a division.]] Right.
[BNC H5D 123-127]
(11) M: 292 And another sixteen percent is the
other Ne- Nestle coffee ?pause? erm
Blend Thirty Seven which I used to drink
a long time ago and others ?laugh? and
twenty two percent is er ?pause?
U: Maxwell.
M: Maxwell House, which has become the
other local brand now seeing as how
Maxwell House is owned by Kraft, and
Kraft now own Terry?s.
[BNC G3U 292-294]
(12) A: Erm because as Moira said that Kraft is
erm ?pause? now what was she saying,
what was she saying Kraft is the same as
?pause?
M: Craft? [BNC G3U 412-413]
(13) J: And I couldn?t remember whether she
said at the end of the three months or
A: End of the month. [BNC H4P 17-18]
6Overlapping material is shown in double square brackets,
aligned with the material with which it co-occurs.
(14) G: Had their own men
A: unload the boats?
G: unload the boats, yes. [BNC H5H 91-93]
(15) G: That?s right they had to go on a rota.
A: Run by the Dock Commission?
G: Run by the Dock Commission.
[BNC H5H 100-102]
(16) A: So I thought, oh, I think I?ll put lace over
it, it?ll tone the lilac [[down.]]
B: [[down.]] Yes.
Which it is has done
[BNC KBC 3195-3198]
A.2 Uncertain antecedents
(17) C: Look you?re cleaning this ?pause?
[[with erm]]
G: [[That box.]]
C: [[This.]]
G: [[With]] this. [[And this.]]
C: [[And this.]] [[And this.]]
G: [[And this.]]
Whoops! [BNC KSR 9-17]
(18) S: You?re trying to be everything ?pause?
and they?re pushing it away cos it?s not
what they really want ?pause? and they, I
mean, all, all you can get from him is how
marvellous, you?re right, how marvellous
his brothers are ?pause? and yet, what I?ve
heard of the brothers they?re not
C: Not much, [[yeah.]]
S: [[they?re]] not all that marvel-
lous, they?re not really that much to look
[[up]]
C: [[Ah]].
S: to.
C: No [BNC KBG 76-81]
(19) S: Well this is why I think he?d be better
off, hi- his needs ?pause? are not met by a
class teacher. And I don?t think they have
been for this last
C: Mm, we need a support teacher [[to go
there.]]
S: [[for the
last]] year. But yo-, you need somebody
who?s gonna work with him every day
?pause? and ?pause? with an individual
programme and you just can?t offer that
?pause? in a class. [BNC KBG 56-60]
270
(20) M: I might be a bit biased, I think they still
do that but I think erm ?pause?
J: The television has ?pause?
M: the television has made a difference. I
think not only just at fire stations, I think
in the whole of life, hasn?t it?
[BNC K69 51-54]
(21)A5: I?ll definitely use that
U: ?reading?:[ Get a headache ]?
A5: [[in getting to know ]]
A2: [[Year seven ]]
A5: new [[year seven]]
A2: [[Oh yeah]] for year seven
[BNC J8D 190-195]
(22) G: Well a chain locker is where all the spare
chain used to like coil up
A: So it ?unclear? came in and it went round
G: round the barrel about three times round
the barrel then right down into the chain
locker but if you kept, let it ride what we
used to call let it ride well ?unclear? well
now it get so big then you have to run it
all off cos you had one lever, that?s what
you had and the steam valve could have
all steamed. [BNC H5G 174:176]
A.3 Multifunctionality of fragments
(7) Completion and confirmation request:
J: How does it generate?
M: It?s generated with a handle and
J: Wound round?
M: Yes, wind them round and this should,
should generate a charge which rang bells
and sounded bells and then er you lift up a
telephone and plug in a jack and, and take
a message in that way.
[BNC K69 109-112]
(23) Completion and confirmation request:
G: Had their own men
A: unload the boats?
G: unload the boats, yes. [BNC H5H 91-93]
(24) Late completion and (repetitive) confir-
mation:
N: Alistair [last or full name] erm he?s, he?s
made himself er he has made himself co-
ordinator.
U: And section engineer.
N: And section engineer.
N: I didn?t sign it as coordinator.
[BNC H48 141-144]
(25) Completion and clarification reply:
John: If you press N
Sarah: N?
John: N for name, it?ll let you type in the docu
document name. [BNC G4K 84-86]
(26) Expansion and reformulation/repair:
S: Secondly er
J: We guarantee P five.
S: We we are we?re guaranteeing P five plus
a noise level.
J: Yeah. [BNC JP3 167-170]
(27) Expansion and question:
I: I can?t remember exactly who lived on
the right hand side, I?ve forgotten but th
I know the Chief Clerk lived just a little
way down [address], you see, er
A: In one of those little red brick cottages?
[BNC HDK 124-125]
(28) Answer and expansion:
A: We could hear it from outside ?unclear?.
R: Oh you could hear it?
A: Occasionally yeah. [BNC J8D 13-15]
(29) Answer/reformulation and expansion:
G: [address], that was in the middle, more or
less in the middle of the town.
A: And you called that the manual?
G: The manual school, yes.
[BNC H5G 96-98]
271
Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 79?83,
Seoul, South Korea, 5-6 July 2012. c?2012 Association for Computational Linguistics
Predicting Adherence to Treatment for Schizophrenia from Dialogue
Transcripts
Christine Howes, Matthew Purver, Rose McCabe, Patrick G. T. Healey, Mary Lavelle
Queen Mary University of London
Mile End Road, London E1 4NS
c.howes@qmul.ac.uk
Abstract
Recent work on consultations between out-
patients with schizophrenia and psychiatrists
has shown that adherence to treatment can
be predicted by patterns of repair ? specifi-
cally, the pro-activity of the patient in check-
ing their understanding, i.e. patient clarifi-
cation. Using machine learning techniques,
we investigate whether this tendency can be
predicted from high-level dialogue features,
such as backchannels, overlap and each partic-
ipant?s proportion of talk. The results indicate
that these features are not predictive of a pa-
tient?s adherence to treatment or satisfaction
with the communication, although they do
have some association with symptoms. How-
ever, all these can be predicted if we allow
features at the word level. These preliminary
experiments indicate that patient adherence is
predictable from dialogue transcripts, but fur-
ther work is necessary to develop a meaning-
ful, general and reliable feature set.
1 Introduction
How conversational partners achieve and maintain
shared understanding is of crucial importance in
the understanding of dialogue. One such mecha-
nism, other initiated repair (Schegloff, 1992), where
one conversational participant queries or corrects
the talk of another, has been well documented in
both general and task-based dialogues (Colman and
Healey, 2011). However, how such shared under-
standing impacts beyond the level of the conversa-
tion has not typically been examined. Exceptions to
this have highlighted the role of shared understand-
ing in schizophrenia (McCabe et al, 2002; Themis-
tocleous et al, 2009) and the association between
psychiatrist-patient communication and adherence.
McCabe et al (in preparation) found that more pa-
tient clarification (i.e. other initiated repair) of the
psychiatrist?s talk was associated with better treat-
ment adherence six months later. Clarification con-
sists mainly of asking questions to clarify the mean-
ing of the psychiatrist?s utterance (checking under-
standing) and correcting something that the psychi-
atrist has said (getting the facts straight). Example 1,
taken from a consultation, shows the patient request-
ing clarification of something the psychiatrist has
just said about a possible side effect.
(1) Dr: Yep, well that is a possible side effect
Pat: Side effect?
Dr: Of the er haloperidol
The patient?s request leads to additional explana-
tion by the psychiatrist about the medication which
can cause the possible side effect. More patient clar-
ification reflects greater effort to reach a shared un-
derstanding. McCabe et al (in preparation) found
that for each unit increase in the patient clarification
factor,1 the odds of good (versus poor) adherence
were increased by 5.8 (95% CI 1.3 to 25.8, p=0.02).
Explaining the link between communicative pat-
terns of patients and adherence may create the pos-
sibility for new interventions to improve adherence,
and has both clinical and theoretical implications.
1A regression factor weighted heavily towards patient clar-
ifcations (as in e.g. 1).
79
However, there is no evidence regarding what fac-
tors influence patient clarification and may explain
the link with adherence. If patient clarification is
a measure of greater communicational effort, or en-
gagement, then wemight expect other dialogue mea-
sures, such as the amount of acknowledgements or
other grounding cues (Traum and Allen, 1992), or
the proportion of talk per person, to be correlated
with other initiated repair and therefore similarly
predictive of subsequent adherence behaviour. This
is of particular importance if we wish to build a sys-
tem to automatically predict possible (lack of) ad-
herence from dialogue transcripts, especially given
that the types of patient clarification which carry
the highest weight in the patient clarification factor
(next-turn repair initiators, Schegloff, 1992) are rare,
occurring on average only 1.2 times per dialogue.
Further, although certain types of repair were
shown to affect how patients reported they felt the
conversation went, self-reports of symptoms and
communicational factors are not predictive of adher-
ence. Although micro-communicational behaviour
(in the form of other initiated repair) does have a
bearing on subsequent adherence behaviour, patients
are unaware of this. Additional questions therefore
concern whether we can predict patient?s symptom
levels and subjective analyses of the communication
based only on overview dialogue factors.
2 Hypotheses
Factors which we would expect to index patient en-
gagement, and thus be predictive of adherence to
treatment are the amount of backchannel responses
patients make, and the proportion of questions pa-
tients ask, both of which ought to be higher for the
more engaged patients. We might also expect that
such patients have a greater proportion of the talk
overall, and/or longer turns on average, though note
that this conversational pattern might also be one in
which the patient is not engaged, as they might not
be responding to the feedback from their consultant.
For the symptom scores (see below for details),
we should expect that patients with high levels
of negative symptoms (which includes loss of af-
fect and poverty of speech) would produce less
talk overall, and in general produce shorter turns.
There should also be more noticeable gaps in the
dialogues (defined as greater than approximately
200ms, (Heldner and Edlund, 2010)). Contrarily,
for positive symptoms, (including hallucinations and
delusions) patients ought to produce longer turns
and have a greater proportion of the talk.
We also expect to see effects on how patients felt
the conversation went from the amount of overlap,
though as overlap can be both intended and inter-
preted as either interruptive or collaborative (as with
e.g. overlapping backchannels) it is unclear which
direction such a prediction should take.
3 Method
131 dialogues from outpatient consultations be-
tween patients and psychiatrists were analysed ac-
cording to a number of factors. Each of these fac-
tors, detailed in table 1, below, is calculated for each
dialogue participant (with the exception of pauses).
Each patient featured in only one of the dialogues
however, there were only 29 doctors in the study,
so the same clinician may have featured in several
of the dialogues with different patients. The con-
sultations varied in length, with the shortest con-
sisting of 61 turns (438 words) and the longest
881 turns (13178 words), with an average of 320.5
turns (2706.4 words). In addition, a third party was
present in 47 of the consultations.
Following the consultation, each patient was
asked questions from standard questionnaires to as-
certain their level of symptoms, and their evalua-
tion of aspects of the consultation. The positive
and negative syndrome scale (PANSS) (Kay et al,
1987) assesses positive, negative and general symp-
toms on a 7-point scale of severity (1=absent ? 7=ex-
treme). Positive symptoms represent a change in
the patients? behaviour or thoughts and include sen-
sory hallucinations and delusional beliefs. Negative
symptoms represent a withdrawal or reduction in
functioning, including blunted affect, and emotional
withdrawal and alogia (poverty of speech). Positive
and negative subscale scores ranged from 7 (absent)
? 49 (extreme), general symptoms (such as anxiety)
scores ranged from 16 (absent) ? 112 (extreme).
Patient satisfaction with the communication was
assessed using the Patient Experience Questionnaire
(PEQ) (Steine et al, 2001). Three of the five sub-
scales (12 questions) were used as the others were
80
not relevant, having been developed for primary
care. The three subscales were ?communication ex-
periences?, ?communication barriers? and ?emotions
immediately after the visit?. For the communication
subscales, items were measured on a 5-point Lik-
ert scale, with 1=disagree completely and 5=agree
completely. The four items for the emotion scale
were measured on a 7-point visual analogue scale,
with opposing emotions were at either end. A higher
score indicates a better experience.
Adherence to treatment was rated by the clini-
cians as good (> 75%), average (25  75%) or poor
(< 25%) six months after the consultation. Due to
the low incidence of poor ratings (only 8 dialogues),
this was converted to a binary score of 1 for good ad-
herence (91 patients), and 0 otherwise (37). Ratings
were not available for the remaining dialogues.
Measure Description
Turns Total number of turns
Words Total number of words spoken
Proportion Proportion of total talk in words
(by each participant)
WordsPerTurn Average length of turn in words
WhPerWord Proportion of wh-words (e.g.
what? who?) per word
OCRPerWord Proportion of open class repair ini-
tiators (e.g. pardon? huh?) per
word
BackchannelPerWord Proportion of backchannels (e.g.
uh-huh, yeah) per word
RepeatPerWord Proportion of words repeated from
preceding turn by other person
OverlapAny Proportion of turns containing any
overlapping talk
OverlapAll Proportion of turns entirely over-
lapping another turn
QMark Proportion of turns containing a
question mark
TimedPause Pause of more than approx 200ms,
as marked on the transcripts
Table 1: Measures from outpatient consultations
3.1 Classification Experiments
We performed a series of classification experiments
using the Weka machine learning toolkit (Hall et
al., 2009) to predict each of the outcome mea-
sures outlined above (symptom measures, satisfac-
tion measures, and adherence to treatment). In each
case, outcome measures were converted to binary
high/low scores on an equal frequency basis (i.e.
providing approximately equal numbers of high and
low instances). Features used were the high-level
measures given in Table 1, and/or all unigrams ex-
tracted from the transcript; in both cases, features
from doctor and patient were treated separately. Un-
igrams were produced by tokenising the lower-cased
transcripts on white space; no stemming or stop-
word removal was performed, and feature values
were binary i.e. indicating only presence or ab-
sence of the word spoken by the given speaker in
the given dialogue.2 Given the small size of our
dataset (131 instances) and the large feature space
resulting (> 6500 features), we selected features
based on their predictive ability across the entire
dataset (using Weka?s CfsSubsetEval selector), re-
ducing the number of features to 50-100. In order
to avoid biasing towards doctor-specific features, we
used only words spoken by patients in these exper-
iments ? each patient only features in one dialogue,
so patient-specific vocabulary cannot help perfor-
mance across dialogues. All unigram features thus
selected were used in at least 3 dialogues.3
4 Results
Experiments including unigram features used Lib-
SVM?s support vector machine implementation
(Chang and Lin, 2001) with a radial basis func-
tion kernel; experiments with only high-level fea-
tures used J48 decision trees. In each case, experi-
ments used 5-fold cross-validation.4 In experiments
predicting adherence, the distribution between pos-
itive and negative (i.e. good and bad adherence)
made it impossible to balance the dataset - as this
can be problematic for decision tree classifiers, we
also present results for a downsampled dataset with
only 71 instances but which provides balance. Per-
formance is shown in Table 2 as overall percentage
accuracy, and is compared to a majority-class base-
line throughout; results which are significantly dif-
ferent at the 5% level according to a  2 test from a
2Experiments with frequency counts did not affect the re-
sults as reported.
3Bi- and tri-gram features were not extracted from this data
because of the small amount of data available which we felt
would result in models that suffered from overfitting (note that
the same concern holds for the unigram features).
4Classifiers were trained on 80% and tested on 20% of the
sample, with this was repeated 5 times over each possible 80/20
combination so as to test the whole dataset.
81
random distribution and the majority class distribu-
tion are shown marked with *.
Baseline Words High-level
PANSS positive 51.1 87.0* 56.5*
PANSS negative 49.6 87.8* 56.5*
PANSS general 48.4 91.1* 54.0
PEQ emotions 51.9 89.1* 53.5
PEQ communication 50.8 79.8* 52.4
PEQ comm. barriers 51.6 90.6* 51.6
PEQ overall 50.8 90.6* 53.9
Adherence 73.2 91.1* 63.4
Adherence (balanced) 53.5 93.0* 52.1
Table 2: Percentage accuracies vs feature set
Results show good performance for all experi-
ments when including lexical features, with all fac-
tors being predictable with around 90% accuracy
with the exception of PEQ communication at just be-
low 80%. However, using high-level features alone
gives negligible performance, except for a small
benefit on the PANSS negative and positive symp-
tom measures, though contrary to our hypotheses
the most important high-level features were OCR-
PerWord by the doctor (negative) and WhWords by
an other participant (positive).
Examination of the most predictive unigrams
shows that sets selected for different outcome mea-
sures are different: for example, the 54 fea-
tures selected for adherence and the 73 selected
for PEQ overall have only 1 word in com-
mon (?mates?). Adherence-related words in-
clude words related to conditions, treatment and
medication (?schizophrenic?, ?sickness?, ?symp-
toms?, ?worse?, ?pains?, ?flashbacks?, ?sodium?,
?chemical?, ?monthly?); PEQ-related words in-
clude those related to personal life (?sundays?,
?thursdays?, ?television?, ?sofa?, ?wine?, ?per-
sonally?, ?played?), and filled pauses (?eerrmm?,
?uhhm?) ? although more investigation is required
to draw any firm conclusions from these. Table 3
shows the full lists for adherence and PEQ overall.
5 Discussion and Conclusions
The results show that although we can weakly pre-
dict symptoms at levels above chance using only
high-level dialogue factors, we cannot do so for ad-
herence, or satisfaction measures. Despite the link
between patient other initiated repair and adherence,
this is also not an effective predictor for our machine
learning approach because of the scarcity of the phe-
nomenon, and the fact that many of the consulta-
tions for which the patients subsequently exhibited
good adherence behaviour do not feature a single
patient clarification, which may be linked to psychi-
atrist clarity rather than lack of effort or engagement
on the patient?s part.
The high accuracies with lexical features show
that some aspects of the consultations do enable ac-
curate prediction of adherence, PEQ measures and
symptoms. However, as the features which allow us
to achieve such good results rely on specific words
used, it is unclear how generalisable or interpretable
such results are. The lexical features chosen do gen-
eralise over our dataset (in which individual patients
appear only once), and exclude doctor talk, so can-
not be simply picking out unique unigram signatures
relating to individual patients or doctors; however,
given the small size of the dataset used for this ini-
tial investigation with its constrained domain, genre
and topics, and the use of the whole dataset to select
predictive words, it is unclear whether these results
will scale up to a larger dataset.
We therefore suspect that more general, higher-
level dialogue features such as specific interac-
tion phenomena (repair, question-answering) and/or
more general models of topic may be required.
While unigrams are too low-level to be explanatory
and may not generalise, the dialogue features dis-
cussed are too high-level to be useful; we are there-
fore examining mid-level phenomena and models
to capture the predictability while remaining gen-
eral and providing more interpretable features and
results. Although the word lists offer clues as to
the relevance of specific words for the overall pre-
dictability, we would not like to leave it at that.
Further experiments are therefore underway to in-
vestigate whether we can find a level of appropri-
ate explanatory power and maximal predictivity us-
ing an interim level of analysis, for example with n-
gram and part-of-speech-based models, topic mod-
els based on word distributions, and turn-taking phe-
nomena. Additional experiments also look at the
turn-level data to see if the patient led clarification
factor can be directly extracted from the transcripts.
82
Adherence PEQ overall
air grass schizophrenic 20th electric onto sometime
anyone grave sensation ages energy overweight son
balanced guitar sickness angry environment oxygen standing
bleach h simply anxiety experiencing packed stomach
build hahaha sodium background facilities percent suddenly
building lager stable bladder friendly personally sundays
busy laying stock booked helps picture suppose
challenge lifting symptoms boy ignore played table
chemical lucky talks broken immediately programs team
complaining mates teach bus increased progress television
cup monthly terminology certificate irritated provide thursdays
dates mouse throat dead kick public troubles
en nowhere virtually deep later quid uhhm
fill pains was drunk lee radio upsetting
finished possibly wave earn loose realised walks
fish pr weve eeerrrr low reply watchers
flashbacks recent worse eerrmm march sat wine
removed writing eerrrmm mates shaky
ri moments sofa
Table 3: Most predictive unigram features
References
Chih-Chung Chang and Chih-Jen Lin, 2001. LIB-
SVM: a library for Support Vector Machines. Soft-
ware available at http://www.csie.ntu.edu.
tw/?cjlin/libsvm.
M. Colman and P. G. T. Healey. 2011. The distribution of
repair in dialogue. In Proceedings of the 33rd Annual
Meeting of the Cognitive Science Society, pages 1563?
1568, Boston, MA.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten.
2009. The WEKA data mining software: An update.
SIGDKDD Explorations, 11(1):10?18.
M. Heldner and J. Edlund. 2010. Pauses, gaps and
overlaps in conversations. Journal of Phonetics,
38(4):555?568.
S.R. Kay, A. Fiszbein, and L.A. Opfer. 1987. The
positive and negative syndrome scale (PANSS) for
schizophrenia. Schizophrenia bulletin, 13(2):261.
R. McCabe, C. Heath, T. Burns, S. Priebe, and J. Skel-
ton. 2002. Engagement of patients with psychosis in
the consultation: conversation analytic study. British
Medical Journal, 325(7373):1148?1151.
R. McCabe, M. Lavelle, S. Bremner, D. Dodwell, P. G. T.
Healey, R. Laugharne, S. Priebe, and A. Snell. in
preparation. Shared understanding in psychiatrist-
patient communication: Association with treatment
adherence in schizophrenia.
E.A. Schegloff. 1992. Repair after next turn: The last
structurally provided defense of intersubjectivity in
conversation. American Journal of Sociology, pages
1295?1345.
S. Steine, A. Finset, and E. Laerum. 2001. A new,
brief questionnaire (PEQ) developed in primary health
care for measuring patients? experience of interaction,
emotion and consultation outcome. Family practice,
18(4):410?418.
M. Themistocleous, R. McCabe, N. Rees, I. Hassan,
P. G. T. Healey, and S. Priebe. 2009. Establishing mu-
tual understanding in interaction: An analysis of con-
versational repair in psychiatric consultations. Com-
munication & Medicine, 6(2):165?176.
D.R. Traum and J.F. Allen. 1992. A speech acts ap-
proach to grounding in conversation. In Second Inter-
national Conference on Spoken Language Processing.
83
Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality, pages 7?16,
Baltimore, Maryland USA, June 27, 2014.
c?2014 Association for Computational Linguistics
Linguistic Indicators of Severity and Progress in Online Text-based
Therapy for Depression
?
Christine Howes, Matthew Purver
Cognitive Science Research Group
School of Electronic Engineering and Computer Science
Queen Mary University of London
London, UK
{c.howes,m.purver}@qmul.ac.uk
Rose McCabe
University of Exeter Medical School
Exeter, UK
r.mccabe@exeter.ac.uk
Abstract
Mental illnesses such as depression and
anxiety are highly prevalent, and therapy
is increasingly being offered online. This
new setting is a departure from face-to-
face therapy, and offers both a challenge
and an opportunity ? it is not yet known
what features or approaches are likely to
lead to successful outcomes in such a dif-
ferent medium, but online text-based ther-
apy provides large amounts of data for lin-
guistic analysis. We present an initial in-
vestigation into the application of compu-
tational linguistic techniques, such as topic
and sentiment modelling, to online ther-
apy for depression and anxiety. We find
that important measures such as symptom
severity can be predicted with compara-
ble accuracy to face-to-face data, using
general features such as discussion topic
and sentiment; however, measures of pa-
tient progress are captured only by finer-
grained lexical features, suggesting that
aspects of style or dialogue structure may
also be important.
1 Introduction
Mental illnesses such as depression and anxiety
have been called ?the biggest causes of misery
in Britain today? (Layard, 2012). The main av-
enue of treatment for such conditions is talking
therapies, such as Cognitive Behavioural Therapy
(CBT); however, there is far greater demand than
can currently be met, and currently only 25% of
sufferers in the UK receive treatment. Therapy is
therefore increasingly being delivered online: this
?
This work was partly supported by the ConCreTe project.
The project ConCreTe acknowledges the financial support
of the Future and Emerging Technologies (FET) programme
within the Seventh Framework Programme for Research of
the European Commission, under FET grant number 611733.
helps to improve access and reduce waiting times,
and is just as effective as standard therapy (Kessler
et al., 2009). However, this new online setting
provides a challenge of evaluation and optimisa-
tion (Hanley and Reynolds, 2009; Beattie et al.,
2009). Online therapy is a significant departure
from face-to-face therapy, and it is not yet known
exactly what features or approaches are likely to
lead to successful outcomes, or help identify neg-
ative outcomes such as risk to the patient or oth-
ers. Current methods (e.g. controlled studies) are
expensive and time-consuming; we need fast, ac-
curate methods to ensure treatment can be made
effective and efficient in this new context.
Professional communication varies widely
(McCabe et al., 2013b) and aspects of doctor-
patient interaction and language are known to
influence outcomes such as patient satisfaction,
treatment adherence and health status (Ong et
al., 1995; McCabe et al., 2013a). For therapists,
automated methods to analyse therapist-client
communication are of interest as there is little
known about how the quality of communication
influences patient outcome. Identifying patterns
of effective communication ? both in terms
of what is spoken about and how it is spoken
about ? would help guide training of therapists.
Moreover, it may assist in identifying successful
therapy and perhaps, more importantly, where
communication is not therapeutic and patients are
failing to improve. This may warrant a different or
more intensive therapeutic intervention. Applying
computational linguistic techniques to therapy
data could therefore offer potential to produce
tools which can aid clinicians in predicting out-
comes, diagnosing severity of symptoms and/or
evaluating progress. Recent work on spoken
therapy dialogue has shown promising results in a
range of mental health tasks, including diagnosis
of post-traumatic stress disorder (PTSD) and
depression (DeVault et al., 2013; Yu et al., 2013),
7
and prediction of outcomes in schizophrenia
treatment (Howes et al., 2013).
Online therapy data provides a new challenge
? language and interaction styles differ to face-
to-face ? but also an opportunity in the availabil-
ity of large amounts of text data without the need
for automatic speech recognition or manual tran-
scription. Here, we present an initial investiga-
tion into the application of computational linguis-
tic techniques to online therapy for depression and
anxiety. We find that important measures such as
symptom severity can be predicted with compara-
ble accuracy to face-to-face data, and that general
aspects such as discussion topic and sentiment are
useful predictors; and suggest some ways in which
techniques can be adapted for improved perfor-
mance in future.
2 Background
2.1 Computational analysis & mental health
Research into computer-based diagnosis in mental
health goes back at least to the 1960s ? see (Over-
all and Hollister, 1964; Hirschfeld et al., 1974)
amongst others ? but most systems rely on doctor-
or patient-reported data rather than naturally oc-
curring language. Much recent work similarly
uses self-reported clinical and socio-demographic
data, e.g. to predict treatment resistance in depres-
sion (Perlis, 2013). Some recent natural language
processing (NLP) research examines features of
the language used by patients when discussing
conditions or treatment, e.g. discovering topics
and opinions from online doctor ratings (Paul et
al., 2013) or social media (Paul and Drezde, 2011).
However, aspects of the communication dur-
ing treatment itself are also associated with pa-
tient outcomes (Ong et al., 1995). In the mental
health domain, recent work suggests that, for pa-
tients with schizophrenia both conversation struc-
ture (how communication proceeds in therapy),
and content (what is talked about), can affect out-
comes (McCabe et al., 2013a; John et al., under
review). NLP research has now begun to examine
both. Wallace et al. (2013) model speech acts to
characterise doctor-patient consultations on medi-
cation adherence; Angus et al. (2012) use unsuper-
vised topic models to visualise shared content in
clinical dialogue; Cretchley et al. (2010) use a sim-
ilar approach for a qualititative analysis of topic
and communication style between patients with
schizophrenia and carers. DeVault et al. (2013)
use features of speech, and Yu et al. (2013) mul-
timodal features, from video-mediated dialogue to
detect depression and PTSD with promising accu-
racies (0.66 to 0.74 depending on condition and
task). In face-to-face therapy for schizophrenia,
Howes et al. (2012; 2013) use a combination of
supervised and unsupervised approaches to pre-
dict a range of diagnostic and outcome measures,
including future adherence to treatment (accuracy
0.70); fine-grained lexical features gave reason-
able accuracy, with more general topic features
giving weaker prediction of some outcomes.
2.2 Topic modelling
One focus of research for mental health is there-
fore on methods for analysing content (what is
talked about). Traditional methods, while ef-
fective, involve time-consuming hand-coding of
data (Beattie et al., 2009; John et al., under re-
view); NLP techniques can reduce this require-
ment. Unsupervised probabilistic models (e.g. La-
tent Dirichlet Allocation (LDA) Blei et al. (2003)
and variants) have been widely applied to learn
topics (word distributions) from the data itself,
connecting words with similar meanings and even
distinguishing between uses of words with mul-
tiple meanings (Steyvers and Griffiths, 2007).
Such techniques have been applied successfully
to structured dialogue e.g. meetings and tuto-
rials (Purver et al., 2006; Eisenstein and Barzi-
lay, 2008), and more recently to dialogues in the
clinical domain (Cretchley et al., 2010; Howes et
al., 2013), with topics found to identify important
themes within therapy conversation such as medi-
cation, symptoms, family and social issues, and to
correlate with outcomes.
2.3 Sentiment and emotion analysis
One aspect of conversation process and style is
the affect or emotion present. NLP research has
generally approached this via the task of senti-
ment detection, distinguishing positive from neg-
ative (and sometimes neutral) stance (Pang and
Lee, 2008). Methods generally take either a
knowledge-rich approach (relying on e.g. dictio-
naries of sentiment-carrying words (Pennebaker
et al., 2007)), or a data-rich approach via (usu-
ally supervised) machine learning over datasets of
sentiment-carrying text (e.g. Socher et al. (2013)).
The former can provide deeper insights, but are
less robust in the face of unexpected vocabulary,
unusual or errorful spelling; the latter are more ro-
8
bust but require training from large datasets. Re-
cent research has attempted finer-grained distinc-
tions, e.g. detecting specific emotions such as
anger, surprise, fear etc; again, approaches can
be characterised as dictionary-based or machine-
learning-based (Chuang and Wu, 2004; Seol et al.,
2008; Purver and Battersby, 2012; De Choudhury
et al., 2012). The resulting sentiment or emotion
ratings have been widely used to determine as-
pects of personality and mental state in various do-
mains. In social media text, Quercia et al. (2011;
2012) found correlations between sentiment and
levels of popularity, influence and general well-
being; O?Connor et al. (2010) with measures of
public opinion. Closer to our application, Liakata
et al. (2012) show that these methods can be ap-
plied to analyse emotion in suicide notes.
2.4 Research questions
Here, similar to (DeVault et al., 2013; Howes et
al., 2013), our primary question is whether these
approaches can be usefully applied to diagnose
conditions and predict outcomes, but in a new
modality ? online text-based therapy ? which may
require different and/or more robust methods. In
addition, we would like to gain some insight into
which features of language and interaction might
be predictive, in order to help clinicians improve
therapeutic methods, and to assess how general
and transferable any model might be. Our main
questions here are therefore:
? What features of text-based online therapy di-
alogue might help predict symptoms and/or
outcomes? Specifically, how predictive are
conversation topic and emotional content?
? Can we detect them accurately and reli-
ably, using approaches generalisable to large
datasets, across different subjects and condi-
tions?
? Can the features provide any insights into the
treatment process and/or the online modality?
3 Method
3.1 Data
The data used in this study consisted of the tran-
scripts from 882 Cognitive Behavioural Ther-
apy (CBT) treatment dialogues between patients
with depression and/or anxiety and their ther-
apists using an online text-based chat system.
The transcripts are from online CBT provided
by Psychology Online, who deliver ?live? therapy
from a qualified psychologist accessed via the in-
ternet (http://www.psychologyonline.
co.uk). Of the 882 transcripts, 837 are between
therapists and patients who were in an ongoing
treatment program or had completed their treat-
ment by the time our sample was collected. There
are 167 patients in this sample (125 females and
42 males), with 35 different therapists (for 2 pa-
tients the identity of the therapist is unknown).
The number of transcripts per patient ranges from
1 to 14, with a mean of 5.011 (s.d. 2.73). For all
of the measures based on the transcripts, as out-
lined below, we included all text typed by both the
therapist and the patient. In addition to the tran-
scripts themselves, each patient normally filled out
two questionnaires prior to each session with their
therapist. These are described below.
3.2 Outcomes
Patient Health Questionnaire (PHQ-9) This
is a self-administered diagnostic instrument for
common mental disorders (Kroenke and Spitzer,
2002). The PHQ-9 is the depression module,
which scores each of the 9 DSM-IV criteria as ?0?
(not at all) to ?3? (nearly every day). A higher
score indicates higher levels of depression, with
scores ranging from 0-27. It has been validated
for use (Martin et al., 2006).
Generalised Anxiety Disorder scale (GAD-7)
Similarly, the GAD-7 (Spitzer et al., 2006) is a
brief self-report scale of generalised anxiety disor-
der. This is a 7-item scale which scores each of the
items as ?0? (not at all) to ?3? (nearly every day).
A higher score indicates higher levels of anxiety.
Outcome measures For the data in our sam-
ple, PHQ-9 and GAD-7 were highly correlated
(r = 0.811, p < 0.001) so for the results re-
ported below we focus on PHQ-9. As each patient
filled in the PHQ-9 before each consultation, we
used two different outcome measures: PHQ now
? the PHQ-9 score of the patient for the question-
naire completed immediately prior to the consulta-
tion; and PHQ start-now ? the difference between
the PHQ-9 score prior to any treatment and PHQ
now, i.e. a measure of progress (how much bet-
ter or worse the patient is since the start of their
treatment). Although these two measures are nu-
merical, one of the general aims of our research
is to identify patients at risk. We therefore bina-
rised the outcome measures and treated our task
9
as a categorisation problem to identify the group
of interest. For PHQ now, these were patients with
moderate to severe symptoms; for PHQ start-now,
patients whose PHQ score had not improved.
3.3 Topics
The transcripts from the 882 treatment consulta-
tions were analysed using an unsupervised proba-
bilistic topic model, using MALLET (McCallum,
2002) to apply standard Latent Dirichlet Alloca-
tion (Blei et al., 2003), with the notion of docu-
ment corresponding to a single consultation ses-
sion, represented as the sequence of words typed
by any speaker. Stop words (common words
which do not contribute to the content, e.g. ?the?,
?to?) were removed as usual (Salton and McGill,
1986), but the word list had to be augmented for
text chat conventions and spellings (e.g. unpunc-
tuated ?ive?). Additionally, common mispellings
were mapped to their correctly spelled equivalents
using Microsoft Excel?s in-built spellchecker. This
was due to the nature of text chat, in contrast to
transcribed speech or formal text ? the word ?ques-
tionnaire?, for example, was found to have been
typed in 21 different ways. Following (Howes et
al., 2013) we set the number of topics to 20,
1
used
the default setting of 1000 Gibbs sampling itera-
tions, and enabled automatic hyperparameter opti-
misation to allow an uneven distribution of topics
via an asymmetric prior over the document-topic
distributions (Wallach et al., 2009).
As Howes et al. (2013) did in face-to-face ther-
apy, we found most topics were composed of co-
herent word lists, with many corresponding to
common themes in therapy e.g. family (Topic 12),
symptoms (16), treatment process (2, 14), and is-
sues in work and social life (19, 5) ? see Table 5.
3.4 Sentiment and emotion analysis
Each turn in the transcripts was then annotated for
strength of positive and negative sentiment, and
level of anger. We compared three approaches: the
dictionary-based LIWC (Pennebaker et al., 2007)
and two machine learning approaches, the Stan-
ford classifier based on deep neural nets and parse
structure trained on standard text (Socher et al.,
2013), and one based on distant supervision over
social media text, Sentimental (Purver and Bat-
1
An arbitrary decision, but Howes et al. (2013) chose it
to match the number defined by manual coders in a therapy
domain.
tersby, 2012).
2
None are specifically designed for
therapy dialogue data; however, given the unortho-
dox spelling and vocabulary used in text chat, we
expect machine-learning based approaches, and
training on ?noisy? social media text, to provide
more robustness.
We used each to provide a posi-
tive/negative/neutral sentiment value; for LIWC,
we took this from the relative magnitudes of the
posemo and negemo categories. Two human
judges then rated the 85 utterances in one tran-
script independently. Inter-annotator agreement
was good, with Cohen?s kappa = 0.66. Agreement
with LIWC was poor (0.43-0.45); with Stanford
better (0.51-0.54); but best with Sentimental
(0.63-0.80). For anger, LIWC gave only one
utterance a non-zero rating, while Sentimental
provided a range of values. We therefore used
Sentimental in our experiments. Raw values
per turn were scaled to [-1,+1] for sentiment
(-1 representing strong negative sentiment, +1
strong positive), and [0,1] for anger; we then
derived minimum, maximum, mean and standard
deviation values per transcript.
3.5 Classification experiments
We performed a series of experiments, to inves-
tigate whether various features of the transcripts
could enable automatic detection of patient re-
sponses to the PHQ-9. The full range of possible
features were calculated for each transcript ? see
Table 1. As well as topic, sentiment and emotion
features as detailed above, we include raw lexi-
cal features to characterise details of content, and
some high-level features (amount of talk; patient
demographics; and therapist identity, known to af-
fect outcomes).
In each case, we used the Weka machine learn-
ing toolkit (Hall et al., 2009) to pre-process
data, and a decision tree classifier (J48), a logis-
tic regression model and the support vector ma-
chine implementation LibLINEAR (Chang and
Lin, 2001) as classifiers. PHQ now was bina-
rised based on the classification in Kroenke and
Spitzer (2002), whereby scores of 10 or over are
moderate to severe and scores of less than 10 are
mild. PHQ start-now was binarised according to
whether there was an improvement (reduction) in
the PHQ score or not. Positive scores indicate
2
Available from liwc.net, nlp.stanford.edu
and sentimental.co respectively.
10
Feature set Description
AgentID Identity of the therapist
High level Client gender; client age group; session
number; client/agent number of words and
turns used; proportion of all words per par-
ticipant
Topic Probability distribution of topics per tran-
script (one value per topic per transcript)
Sentiment Overall sentiment mean, standard devi-
ation, minimum and maximum; overall
anger mean, standard deviation, minimum
and maximum
Word Unigrams, for all words that appeared in
at least 20 of the transcripts, regardless of
speaker; the features were the normalised
counts of each word
N-gram As word, but including unigrams, bigrams
and trigrams
Table 1: Feature sets for classification experiments
an improvement; scores of 0 or lower indicate no
change or a worsening of PHQ score. Each out-
come indicator was tested with different feature
sets using 10-fold cross-validation.
3
4 Results
4.1 Correlations
First, we examined statistical associations be-
tween our four outcome measures and our avail-
able features (see Section 3). R-values are shown
for all significant correlations (at the p < 0.05
level) in Tables 2-4. For the PHQ now measure,
a positive correlation means a greater value of the
feature is associated with a greater value of the
PHQ score (i.e. a higher level of symptoms). For
the PHQ start-now measures, a positive correla-
tion means that a greater value of the feature is as-
sociated with a greater improvement in the PHQ
score since the start of treatment. Correlations
greater than ?0.2 are shown in bold.
High-level With patients with a worse (higher)
PHQ score (PHQ now), more words and turns are
typed by both participants. Better overall progress
scores are also weakly associated with the amount
of talk, with fewer turns typed by both participants
if patients? PHQ score has improved by a greater
3
We partition the data into 10 equal subsamples, and use
each subsample as the test data for a model trained on the
remaining 90%. This is repeated for each subsample (the 10
folds), and the test predictions collated to give the overall re-
sults. This partitioning is done by transcript: different tran-
scripts from the same patient may therefore appear in training
and test data within the same fold; our use of low-dimensional
topic/sentiment features should minimise over-fitting, but fu-
ture work will investigate the extent of this effect.
amount since the start of their treatment program
(see Table 2).
Sentiment As shown in Table 3, more negative
sentiment expressed in the transcripts (mean and
minimum), a higher variability of sentiment be-
tween negative and positive (s.d.), and greater lev-
els of anger (mean and maximum) are associated
with worse PHQ scores. More positive sentiments
(mean and maximum) are also associated with bet-
ter progress.
Topic Topics 2, 6, 9, 10, 16 and 17 are neg-
atively correlated with PHQ scores, i.e. higher
levels of these topics are associated with better
PHQ (see Table 4). Some of these topics involve
words related to assessing the patient?s progress
and feedback, e.g. topic 2 includes session, goals
and questionnaires, and topic 17 includes good,
work and positive. Others relate to specific con-
cerns of the patient, e.g. topic 6 (worry, worrying
and problem) and topic 16 (anxiety, fear and sick).
The top twenty words assigned to each topic by
LDA, and the direction of significant correlations
are shown in Table 5.
Conversely, topics 4, 5, 7, 8, 11 and 18 are
positively correlated with PHQ scores, meaning
more talk assigned to these topics is associated
with worse PHQ. Several of these topics relate to
specific issues, such as topic 5 (sleep, bed, night)
and topic 18 (eating, food, weight). Some of these
topics display overlap with the previous group
(e.g. topics 2 and 4 both contain words reviewing
progress such as session, week, next and last); this
suggests that some topics (e.g. progress or particu-
lar issues) are discussed in importantly (and recog-
nisably) different ways or contexts (possibly dif-
ferent emotional valences ? see below), and these
differences are being identified by the automatic
topic modelling.
Similarly, greater amounts of talk in topics 2, 15
and 17 are weakly associated with better progress.
These are the topics identified above as involving
words related to assessing progress, and feedback.
Greater amounts of talk in topic 8 (checking, OCD,
anxiety, rituals) is associated with worse progress.
Cross-correlations between topic and senti-
ment features Previous work has hypothesised
that automatically derived topics may differ from
hand-coded topics in picking up additional factors
of the communication such as valence (Howes et
al., 2013). To explore this on a global level (i.e.
11
Measure PHQ now PHQ start-now
Agent number of words 0.231
Client number of words 0.195
Agent number of turns 0.149 -0.080
Client number of turns 0.193 -0.071
Table 2: Significant correlations of high-level features and outcomes
Measure PHQ now PHQ start-now
Sentiment mean -0.237 0.119
Sentiment s.d. 0.161
Sentiment minimum -0.167
Sentiment maximum 0.074
Anger mean 0.185
Anger s.d. 0.074
Anger minimum
Anger maximum 0.192
Table 3: Significant correlations of sentiment features and outcomes
at the level of the transcript, rather than at the
finer-grained level of the turn) we examined cross-
correlations between sentiment and topic. This
initial exploration offers support for this hypoth-
esis, as can be seen in Table 6. For example, top-
ics 3 and 4 both contain words relating to feel-
ings and thoughts, but topic 3 is positively corre-
lated with sentiment, while topic 4 is negatively
correlated. These correlations indicate a complex
relationship between topic and sentiment which
should be explored further in future research; a
joint topic-sentiment model might be appropriate
e.g. (Paul et al., 2013). Although some topics
pattern consistently with sentiment (e.g. topic 12,
with words about relatives and relationships, is as-
sociated with negative sentiments and higher lev-
els of anger) some do not (e.g. topic 19 is asso-
ciated with more positive sentiment, but greater
anger). Examination suggests that this topic in-
volves discussions about feelings of anger, but not
necessarily expressing anger, and also may include
talk on how to deal with such feelings (with words
like assertive). These observations may indicate
that in this domain, in which people explicitly talk
about their feelings, fully accurate sentiment and
emotion analysis may require a different approach
than in domains such as social media analysis.
4.2 Classification experiments
Results of classification experiments on different
feature sets are shown in Tables 7-9. For each ex-
periment, the weighted average f-score is shown,
with the f-score for the class of interest shown
in brackets. For PHQ now the class of interest
is patients with high (moderate to severe) PHQ-9
scores; for PHQ start-now we are concerned with
patients who are not getting better. As a baseline,
the proportion of the data in the class of interest in
each case is shown in the first column in Table 7 ?
note that these are not exactly 50%, but reflect the
actual proportions in the data (see Section 3.5).
High-level As can be seen in Table 7, if we use
a feature set consisting of high-level features and
AgentID, we are able to predict PHQ now and
PHQ start-now reasonably well (> 0.7). How-
ever, given the nature of the data, it is uncommon
for a therapist to have many clients of the same
age group and gender; these features can therefore
act as a reasonable proxy for identifying individ-
ual patients, meaning that this result is somewhat
spurious. Also, although identity of therapist is an
important factor in therapeutic outcomes (McCabe
et al., 2013a; McCabe et al., 2013b), we would
like to identify aspects of the communication that
explain why particular therapists are more success-
ful than others, and generalise our findings to new
therapists. AgentID was therefore removed in all
subsequent experiments.
Sentiment and topic As shown in Table 8, us-
ing the proportions of derived topics by transcript
as features does allow us to predict whether a pa-
tient has a high PHQ now score reasonably well;
but sentiment alone performs poorly. Combining
sentiment and topic features, however, allows us
to predict PHQ now with scores of around 0.7 (i.e.
approaching the accuracy achieved using high-
level and AgentID features above). Prediction of
the progress measure is less effective.
Words and n-grams For the symptom mea-
sure, using words and n-grams gives f-scores in
12
Measure PHQ now PHQ start-now
Topic 2 -0.157 0.112
Topic 4 0.124
Topic 5 0.176
Topic 6 -0.117
Topic 7 0.217
Topic 8 0.093 -0.126
Topic 9 -0.077
Topic 10 -0.149
Topic 11 0.140
Topic 12 0.080
Topic 15 0.072
Topic 16 -0.112
Topic 17 -0.211 0.079
Topic 18 0.121
Table 4: Significant correlations of topic features and outcomes
Topic P
H
Q
+
/
-
S
e
n
t
i
m
e
n
t
+
/
-
A
n
g
e
r
+
/
-
keywords
Topic 0 - + good thought re well also mindfulness hw thoughts now vc maybe prob message neg just wk one self bit
Topic 1 people good others self evidence thought enough wrong negative esteem thinking say confidence beliefs person true someone belief situation
Topic 2 - + - session send goals next week last sent read great think questionnaires also homework goal appointment set time cbt able
Topic 3 + thoughts thinking unhelpful helpful look thought behaviours go feelings may think anxiety negative try aware behaviour agenda start self
Topic 4 + - feel think like just good really week now know last session next say felt people thoughts going feeling bit
Topic 5 + - + sleep bed day week work get night mood time diary see better much sleeping activity house routine done activities
Topic 6 - worry worrying worries bit stop train worried problem go example idea control hierarchy driving exposure home happen worst car
Topic 7 + - help feel gp depression thank understand therapy now feeling life today think problems able little message medication sorry make
Topic 8 + check checking ocd thoughts anxiety try something difficult danger brain week sense threat helpful away rituals anxious elephant images
Topic 9 - - think time like much way sure see though know look lot sounds well also right thing sorry sense different
Topic 10 - + thought thoughts anxiety really situation situations one week next example social experience record great emotions thanks notice see make
Topic 11 + + things get time go need like want now just something feel know one work good day going give next
Topic 12 + - + mum relationship husband life family dad parents never love feelings children said years mother much hard way told sister
Topic 13 really week think appointment homework however lets teeth questions great just ready start may dentist set end sure therapy
Topic 14 + - great right sure appointment just thank well tonight loo lol good say really cool get going sorry transcript absolutely
Topic 15 + - things like get bit good sounds feeling also something really great today think idea send week useful anything make
Topic 16 - - anxiety panic breathing get anxious feeling going go attack fear physical control try happen sick symptoms times cope distraction
Topic 17 - + - good work well positive back help really time still last much weeks use thanks session better keep done things
Topic 18 + eating eat food weight day week meal lunch dinner pie energy good mum put table public walk believe ate
Topic 19 + + work job anger angry school stress thanks wife team stuff issues also boss year assertiveness assertive meeting kids times
Table 5: Top 20 words per topic
line with those using only the reduced dimen-
sionality of sentiment and topic. This is surpris-
ing; one might expect finer-grained lexical fea-
tures (which provide more information via a much
higher-dimensional feature space) to increase pre-
dictivity, as per Howes et al. (2013); on the other
hand, it is also promising as it suggests that mean-
ingful generalisations can be drawn out of this data
using NLP techniques.
For the progress measure, on the other hand, n-
gram features perform better than topic/sentiment
(though not as well as on the symptom measures);
this suggests that there are aspects of the com-
munication that can assist in predicting patient
progress, but that they are not captured by the topic
and sentiment information as currently defined.
This suggests that dialogue structure or style may
play a role; one possibility for exploration is to
look at topic and/or sentiment at a finer-grained
level and examine their dynamics (e.g. are posi-
tive sentiments expressed near the start or end of a
consultation linked to better progress)?
5 Discussion
Standard topic, sentiment and emotion modelling
can be usefully applied to online text therapy dia-
logue, although care is needed choosing and ap-
plying a technique suitable for the idiosyncratic
language and spelling. The resulting information
allows us to predict aspects of symptom sever-
ity and patient progress with reasonable degrees
of accuracy (similar to those achieved with face-
to-face data (DeVault et al., 2013; Howes et al.,
2012)), without requiring knowledge of thera-
pist identity. However, some measures of patient
progress are predicted better with fine-grained,
high-dimensional lexical features, suggesting that
insight into style and/or dialogue structure is re-
quired, beyond simple topic or sentiment analysis.
13
Sentiment Anger
Measure mean s.d. min max mean s.d. min max
Topic 0 -0.083 0.189 -0.234 0.206 0.329 0.343 -0.144 0.267
Topic 1 0.087 0.083
Topic 2 0.245 -0.180 0.202 -0.135 -0.175 -0.109 0.076 -0.176
Topic 3 0.113 -0.213 0.159 -0.135 -0.123 0.110 0.095
Topic 4 -0.350 0.324 -0.201 0.099 0.074
Topic 5 -0.079 0.119
Topic 6 0.068
Topic 7 -0.083 -0.167 -0.109 0.110
Topic 8 0.078 0.123 -0.104
Topic 9 -0.072 -0.071 -0.075
Topic 10 0.100 -0.167 0.133 -0.073
Topic 11 0.086 0.161 0.132 0.121
Topic 12 -0.338 0.182 -0.156 0.233 0.092 -0.087 0.146
Topic 13 -0.111 -0.112 -0.243 0.077 -0.089
Topic 14 0.112 0.156 -0.183 0.186 -0.087 0.225 -0.116 0.204
Topic 15 0.140 -0.179 0.072 -0.064 -0.161 -0.156 -0.070
Topic 16 -0.090 -0.089 0.073 -0.115
Topic 17 0.385 -0.156 0.267 -0.116 -0.408 -0.139 0.078 -0.288
Topic 18 -0.071
Topic 19 0.177 0.209
Table 6: Significant correlations between topic and sentiment features
Baseline Agent High-level (H/L)
Measure Proportion OneR (Worse) inc Agent J48 exc Agent J48
PHQ Now 40.5% 0.584 (0.360) 0.738 (0.637) 0.640 (0.561)
PHQ Start-now 38.1% 0.639 (0.446) 0.707 (0.611) 0.545 (0.299)
Table 7: Weighted average f-scores of outcomes using different high-level feature groups (figures in
brackets are the f-scores for the class of interest; i.e. PHQ Now ? patients with higher/more symptomatic
PHQ; PHQ Start-now ? patients showing no change or a worsening in PHQ)
Sentiment Topic Sentiment + Topic
inc H/L exc H/L inc H/L exc H/L inc H/L exc H/L
J48
PHQ Now 0.625 (0.528) 0.610 (0.437) 0.642 (0.548) 0.650 (0.512) 0.641 (0.544) 0.638 (0.522)
PHQ Start-now 0.630 (0.412) 0.508 (0.094) 0.628 (0.479) 0.477 (0.024) 0.619 (0.474) 0.526 (0.147)
Logistic PHQ Now 0.626 (0.497) 0.610 (0.432) 0.689 (0.585) 0.658 (0.537) 0.707 (0.613) 0.674 (0.559)
Regr. PHQ Start-now 0.532 (0.218) 0.605 (0.025) 0.593 (0.369) 0.569 (0.283) 0.591 (0.377) 0.557 (0.295)
Table 8: Weighted average f-scores using sentiment/topic features (figures in brackets are the f-scores
for the class of interest)
Words N-grams
Measure inc H/L exc H/L inc H/L exc H/L
PHQ NOW 0.655 (0.575) 0.676 (0.614) 0.696 (0.615) 0.686 (0.616)
PHQ Start-now 0.616 (0.528) 0.623 (0.506) 0.626 (0.459) 0.645 (0.532)
Table 9: Weighted average f-scores using raw lexical features (words/ngrams) using LibLINEAR (figures
in brackets are the f-scores for the class of interest)
14
References
D. Angus, B. Watson, A. Smith, C. Gallois, and
J. Wiles. 2012. Visualising conversation structure
across time: Insights into effective doctor-patient
consultations. PLoS ONE, 7(6):1?12.
A. Beattie, A. Shaw, S. Kaur, and D. Kessler. 2009.
Primary-care patients? expectations and experiences
of online cognitive behavioural therapy for depres-
sion: a qualitative study. Health Expectations,
12(1):45?59.
D. Blei, A. Ng, and M. Jordan. 2003. Latent Dirichlet
allocation. Journal of Machine Learning Research,
3:993?1022.
C.-C. Chang and C.-J. Lin, 2001. LIBSVM: a
library for Support Vector Machines. Soft-
ware available at http://www.csie.ntu.
edu.tw/
?
cjlin/libsvm.
Z.-J. Chuang and C.-H. Wu. 2004. Multi-modal emo-
tion recognition from speech and text. Computa-
tional Linguistics and Chinese Language Process-
ing, 9(2):45?62, August.
J. Cretchley, C. Gallois, H. Chenery, and A. Smith.
2010. Conversations between carers and peo-
ple with schizophrenia: a qualitative analysis us-
ing Leximancer. Qualitative Health Research,
20(12):1611?1628.
M. De Choudhury, M. Gamon, and S. Counts. 2012.
Happy, nervous or surprised? Classification of hu-
man affective states in social media. In Proceed-
ings of the Sixth International Conference on We-
blogs and Social Media (ICWSM).
D. DeVault, K. Georgila, R. Artstein, F. Morbini,
D. Traum, S. Scherer, A. S. Rizzo, and L.-P.
Morency. 2013. Verbal indicators of psychologi-
cal distress in interactive dialogue with a virtual hu-
man. In Proceedings of the SIGDIAL 2013 Confer-
ence, pages 193?202.
J. Eisenstein and R. Barzilay. 2008. Bayesian unsu-
pervised topic segmentation. In Proceedings of the
2008 Conference on Empirical Methods in Natural
Language Processing, pages 334?343.
M. Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reute-
mann, and I. H. Witten. 2009. The WEKA data
mining software: An update. SIGDKDD Explo-
rations, 11(1):10?18.
T. Hanley and D. Reynolds. 2009. Counselling psy-
chology and the internet: A review of the quanti-
tative research into online outcomes and alliances
within text-based therapy. Counselling Psychology
Review, 24(2):4?13.
R. Hirschfeld, R. L. Spitzer, and M. R.G. 1974. Com-
puter diagnosis in psychiatry: A Bayes approach.
Journal of Nervous and Mental Disease, 158:399?
407.
C. Howes, M. Purver, R. McCabe, P. G. T. Healey, and
M. Lavelle. 2012. Helping the medicine go down:
Repair and adherence in patient-clinician dialogues.
In Proceedings of the 16th Workshop on the Seman-
tics and Pragmatics of Dialogue (SemDial 2012).
C. Howes, M. Purver, and R. McCabe. 2013. Using
conversation topics for predicting therapy outcomes
in schizophrenia. Biomedical Informatics Insights,
6(Suppl. 1):39?50, July.
P. John, M. Lavelle, S. Mehnaz, and R. McCabe. un-
der review. What do psychiatrists and patients with
schizophrenia talk about and does it matter? Psy-
chiatric Bulletin.
D. Kessler, G. Lewis, S. Kaur, N. Wiles, M. King,
S. Weich, D. Sharp, R. Araya, S. Hollinghurst, and
T. Peters. 2009. Therapist-delivered internet psy-
chotherapy for depression: a randomised controlled
trial in primary care. Lancet, 374:628?634.
K. Kroenke and R. L. Spitzer. 2002. The PHQ-9:
a new depression diagnostic and severity measure.
Psychiatr Ann, 32(9):1?7.
R. e. a. Layard. 2012. How mental illness loses out
in the NHS. Technical report, Mental Health Policy
Group, Centre for Economic Performance, London
School of Economics, June.
M. Liakata, J.-H. Kim, S. Saha, J. Hastings, and
D. Rebholz-Schuhmann. 2012. Three hybrid classi-
fiers for the detection of emotions in suicide notes.
Biomedical Informatics Insights, 5(1):175?184.
A. Martin, W. Rief, A. Klaiberg, and E. Braehler.
2006. Validity of the brief patient health question-
naire mood scale (PHQ-9) in the general population.
General hospital psychiatry, 28(1):71?77.
R. McCabe, P. G. T. Healey, S. Priebe, M. Lavelle,
D. Dodwell, R. Laugharne, A. Snell, and S. Brem-
ner. 2013a. Shared understanding in psychiatrist-
patient communication: Association with treatment
adherence in schizophrenia. Patient Education and
Counselling.
R. McCabe, H. Khanom, P. Bailey, and S. Priebe.
2013b. Shared decision-making in ongoing outpa-
tient psychiatric treatment. Patient education and
counseling, 91(3):326?328.
A. K. McCallum. 2002. MALLET: A machine learn-
ing for language toolkit. http://mallet.cs.umass.edu.
B. O?Connor, R. Balasubramanyan, B. R. Routledge,
and N. A. Smith. 2010. From tweets to polls: Link-
ing text sentiment to public opinion time series. In
Proceedings of the 4th AAAI International Confer-
ence on Weblogs and Social Media, pages 122?129.
L. Ong, J. De Haes, A. Hoos, and F. Lammes. 1995.
Doctor-patient communication: a review of the liter-
ature. Social science & medicine, 40(7):903?918.
15
J. Overall and L. Hollister. 1964. Computer proce-
dures for psychiatric classification. Journal of the
American Medical Association, 187:583?585.
B. Pang and L. Lee. 2008. Opinion mining and senti-
ment analysis. Foundations and Trends in Informa-
tion Retrieval, 2(1?2):1?135.
M. Paul and M. Drezde. 2011. You are what you
tweet: Analyzing twitter for public health. In Pro-
ceedings of the 5th International AAAI Conference
on Weblogs and Social Media (ICWSM).
M. Paul, B. Wallace, and M. Dredze. 2013. What
affects patient (dis)satisfaction? Analyzing online
doctor ratings with a joint topic-sentiment model.
In Proceedings of the AAAI Workshop on Expand-
ing the Boundaries of Health Informatics Using AI
(HIAI).
J. W. Pennebaker, R. J. Booth, and M. E. Francis.
2007. Linguistic inquiry and word count (LIWC):
A computerized text analysis program. Austin, TX:
LIWC.net.
R. H. Perlis. 2013. A clinical risk stratification tool
for predicting treatment resistance in major depres-
sive disorder. Biological Psychiatry, 74(1):7?14.
Sources of Treatment Resistance in Depression: In-
flammation and Functional Connectivity.
M. Purver and S. Battersby. 2012. Experimenting
with distant supervision for emotion classification.
In Proceedings of the 13th Conference of the Euro-
pean Chapter of the Association for Computational
Linguistics (EACL), pages 482?491.
M. Purver, K. K?ording, T. Griffiths, and J. Tenenbaum.
2006. Unsupervised topic modelling for multi-party
spoken discourse. In Proceedings of the 21st In-
ternational Conference on Computational Linguis-
tics and 44th Annual Meeting of the Association for
Computational Linguistics (COLING-ACL), pages
17?24.
D. Quercia, J. Ellis, L. Capra, and J. Crowcroft. 2011.
In the Mood for Being Influential on Twitter. In
Proceedings of the 3
rd
IEEE Conference on Social
Computing (SocialCom).
D. Quercia, J. Crowcroft, J. Ellis, and L. Capra. 2012.
Tracking ?gross community happiness? from tweets.
In Proceedings of the ACMConference on Computer
Supported Cooperative Work (CSCW), pages 965?
968.
G. Salton and M. McGill. 1986. Introduction to mod-
ern information retrieval. McGraw-Hill, Inc.
Y.-S. Seol, D.-J. Kim, and H.-W. Kim. 2008. Emotion
recognition from text using knowledge based ANN.
In Proceedings of ITC-CSCC.
R. Socher, A. Perelygin, J. Wu, J. Chuang, C. D. Man-
ning, A. Ng, and C. Potts. 2013. Recursive deep
models for semantic compositionality over a senti-
ment treebank. In Proceedings of the 2013 Con-
ference on Empirical Methods in Natural Language
Processing, pages 1631?1642.
R. L. Spitzer, K. Kroenke, J. B. Williams, and B. L?owe.
2006. A brief measure for assessing generalized
anxiety disorder: the GAD-7. Archives of internal
medicine, 166(10):1092?1097.
M. Steyvers and T. Griffiths. 2007. Probabilistic
topic models. Handbook of latent semantic analy-
sis, 427(7):424?440.
B. C. Wallace, T. A. Trikalinos, M. B. Laws, I. B. Wil-
son, and E. Charniak. 2013. A generative joint, ad-
ditive, sequential model of topics and speech acts
in patient-doctor communication. In Proceedings of
the 2013 Conference on Empirical Methods in Nat-
ural Language Processing, pages 1765?1775.
H. M. Wallach, D. M. Mimno, and A. McCallum.
2009. Rethinking LDA: Why priors matter. In
NIPS, volume 22, pages 1973?1981.
Z. Yu, S. Scherer, D. Devault, J. Gratch, G. Stratou, L.-
P. Morency, and J. Cassell. 2013. Multimodal pre-
diction of psychological disorder: Learning nonver-
bal commonality in adjacency pairs. In Proceedings
of the SemDial 2013 Workshop, pages 193?202.
16
