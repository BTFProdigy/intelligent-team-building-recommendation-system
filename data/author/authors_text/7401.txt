Tagging of very large corpora: Tol)ic-Focus Articulation 
Eva  Burf i f iovf i  and Eva  Ha j i~ovf i  and Pet r  Sga l l  
\]nsl;il;ul; of Formal  and App l ied  Linguist ics,  
Facu l ty  (If' Math( ' .matics an(t Phys ics  
Char les  University,  P rague,  Cze(;h \]2,etml)li(: 
Abst rac t  
A\['ter a. bri(;f chara(:teriz:~tion f the th(;ory of the 
tot)i('-fo('us a rticulatioi~ (if the s('.nt('al(:(,. ('I'FA), 
rules 3A'c formulated that (letermin(; I:he a,~sign- 
menI; of al)t)rol)riate values (If |;hi'. "J'\]'\~\ attril)u?;(~ 
ill I;he l)ro(:(',qs of synl;a(:i;i(:o-s('manti(: tagging of 
i~ very large ('orlms lit' Cz(;(:h. 
1 I n t roduct ion :  The  Prague 
Dependency  Treebank  (PDT)  
PDT is a corpus (a part fl'om the Czech Na.tional 
Cortms), tagged on th(; following h'x('.l>: 
1. mort)hemi(: (POS and a illlOl;al;ions using a, 
v(n'y large nmnl)('.r of i;ag G :is r/'quired 1)y 
the language, with rich intl(~(:ti(/n; (:1". (\]lajiC: 
and llladk(~, \] 997)); 
2. 'mmlyl;ic' (del)en(lelwy syntax, with node,q 
for all word o(:cm'r(,.n(:(>, also for p l ln ( ; t l l a -  
tion ma,rks etc., aim wit\]~ the tags for roo f  
t)hemic units and for 1)asic kin(t,q of surfa(:e 
syntactic rch~tion.q (Slfl).je(:t, O1).j('.(:t, Adver- 
t)ial, A(ljun('t), (:f. (Ila.ji~,) 
3. tcctogrammatical  (und('.l'lying) syntax, 
with a iIluch lllOr(; detailed classifit:ation 
of synl;actic relal;ions and with nodes tbr 
aul;o,q0.manl;ic lexical oc(-urren('es only 
(ra.|;her tha.n flln(:l;ion words), with indices 
corresponding to the syntactic relations, 
such as Actor, Addressee, Object ive (Pa- 
tient), Locative, Mmmer, Means, etc., and 
to mort)hologieal values sudl  as Preterite 
(Anterior), Conditional, Plural, etc., and 
also as the prototyl)ical values of 'in', 'into', 
%n', ~from', etc.; ('ol'r(!lates of flmctional 
words (a.nd morph(;m('~s) on this leve, l ha v('~ 
the form of indices of lexi('al nod(', labels.l 
1An except ion  concerns  coord inat ing  con junct ions ,  
which,  in PDT,  are. t reated  as head nodes  of the  (:o- 
2 Represent ing  Top ic -Focus  
Ar t i cu la t ion  (TFA)  in TGTSs  
2.1 A I )r ief  character i za t ion  of TFA 
'l'h(; te(:togranunatical tr(,.e struct;ures (TGTSs)  
should (:alIi;Ul'('. nol, only the syntactic ((l(,.1)(;n- 
/Mmy) relations, lint also the. TFA of the ut- 
t(;ran(:es in the corpus, sin(:('. TFA is cx1)resscd 
l/y grammal;i(:al me,ms and is releva.nt for the 
meaning of (;he sentenc(; (even for its trut\]t (:on- 
ditions), i.e. it; constitutes one of the basic as- 
1)e(:ts of un(l('rlying structures. Tlm scmanli(: 
reh',van/:c. (hi' TFA can be illustra.t('d 1)y (~xaml)lcs 
such as (1), wlfi(:h is a translal:i(m of the Czech 
(.'x. (1') (the capitals (l('amt(*. the. 1)la(:(;m(mt of 
th/'. int()naCion /:c.ntr(', i.e. I;tm focus t)rol)er): 2
(1) 0,) 1;.,..d.i.4,. i.,..~.vo/..c.,, i.,. t/,.,; S t l J ;7 'LANI )S .  
(b) i',, l.h,e ,%cl, hm, ds, lz,'NGLI,2H is ,~'pol,:e',,. 
(~') (,~) A,..d.id..:,j .~, .,,,.l.,,..,,~ ,,.,. Shctl,.',,.a.~t,::,j4,. 
0,~ Tll, 0 VI~ CH. 
ordinl;('d groul)S. Th is  makes  it; l)ossibl(, to ret)resent 
l;he I;(}(;I;og~rantlllai;i(:al st;rll(:l;llres of all s('dlt('.ilt;es a.q I;lee.q 
(rath(,., than using more-dimensional net:works); in this 
point, PDT ditlers fl:om the theoretical assumt)tions of 
th('. l)ragnian lqmctional Gen('xativ('. Descril)t, ion (now 
discussed in (Haji~':ov(~ ? al., 1998)). 
~In the  1)rol, otyt)i(:at case the in tonat ion  (:e.ntre is char-  
acter ized 1)y fal l ing (or r is ing-fal l ing) stress, but  there  are 
also cases in which (similarly as in questions, to a cer- 
tain degree) the centre has a rising stress. This concerns 
utterances displaying a featm'e of hesitation or incom- 
pleteness, of. (M.,); ofte.n also with greet, ings (such as 
Czech Dobrd j ihv \[Good morning\]) a difference of this 
kind marks the 'starting' token, connected with the ex- 
pectation of an answering token, which exhibits a riffling 
sl;ress. Although in it S(~ll|;(*dlCC containing occurrences of 
l)oth a rising aild & falling sLress the former exl)resses a
contrastive (part; of) topic, we l)retier to analyze it its the 
fOCIlS ill ~ SC'II|;CI\].C( '. wiLhoul, all ()c(;urrellCe of the  lal;l;er; 
in such a l)osit ion, the  r is ing stress regular ly  is carr ied  
1)3' an i tem referr ing to 'new'  in format ion .  In wr i t ten  
t;ext;s, some occurrences  of |;he r is ing stress are marked  
1) 3, a semico lon or by ' . . .  '. 
139 
(b) Na Shetlandsk~jch ostvovech se mluv( 
ANGLICKY.  
The conmmnicative function of the sentence 
can basically be rendered by understanding its 
topic (T) as 'what is the sentence about', and 
its focus (F) as the information that is asserted 
about the topic, i.e., schematically, the interpre- 
tation of the sentence S can be understood as 
s - F(T) 
Thus, (1)(a) asserts, on its preferred reading 
(with just the locative modification constituting 
its focus) about where English is spoken that 
it is in the Shetlandt, which hardly can be ac- 
cepted as true w.r.t, what we know of the actual 
world, if no specific context is present. (1)(b) is 
understood as true, stating about E. that it is 
spoken in the S. 
In the TGTSs the order of nodes is such that 
all parts of T precede all parts of F. Moreover, 
the order of nodes corresponds to the scale of 
communicative dynamism (CD, see Section 3 
below); a less dynamic node prototypically has 
the broader scope than a more dynamic one (if 
the nodes correspond to operators). F proper is 
then the most dynamic (the rightmost) node. 
TFA is relevant also tbr the semantics of nega- 
tion: 
(2) John 
(a) 
(b) 
didn't come because he was ILL. 
The reason for Jolm's not-coming was 
his illness. 
The reason for John's coming (e.g. to 
the doctor) was not his illness but 
something else (e.g. he wanted to in- 
vite the doctor for a party). 
With the paraphrase (a), the negated verb 
'come' is included in T, i.e. the fact that John's 
being ill is the cause of an event is asserted about 
the event that he did not come. With (b), the 
main verb 'come' alto belongs to T, but what it 
negated, is the relation between T and F: John 
came, but what is asserted about his coming is 
that the cause of this event was not his illness 
(he might have been ill, though). 
Every node in a TGTS is either contextually 
bound (CB) or non-bound (NB); this opposi- 
tion is a linguistic couterpart of the cognitive 
dichotomy of 'given' vs. hmw', where also an 
item, if corresponding to a 'given' referent pre- 
sented as occupying a newly characterized spe- 
cific position (often in relation to one or more 
'given' items), has the feature NB, cf.: 
(3) Give th, is to YOUR mother. (My parents 
don't like s~tch gifts.) 
kno',,,s  oth ete," ,lane.) Ho,. 
ever, th.is time she only invited IIER. 
The indexical pronoun 'your' in (3) and the 
anaphoric pronoun 'her' in (4) can only rethr to 
items that in a sense are 'known' in the given 
situation. However, in these examples, both of 
them occur as NB; their stress indicates their 
flmction as F proper of the respective sentence. 
Prototypically, an NB node belongs to F and a 
CB node is in T; however, a node not dependent 
immediately on a finite verb (esp. an adjunct) 
need not meet this condition. Thus, in (5), 'my' 
as a shifter, directly determined by the condi- 
tions of the discourse, is CB, although belong- 
ing to F, since it; depends on a part of F (see 
(HajiSovi~ et al, 1998) fbr a definition of T and 
F on the basis of contextual boundness and of 
syntactic dependency, aswell as for other details 
of the given descriptive frmnework). 
2.2 The  a t t r ibute  TFA in PDT 
Three values of the attribute TFA are distin- 
guished with every node in a TGTS: 
1. T a non-contrastive CB node, which always 
has a lower degree of CD than its governor, 
if any; 
2. F an NB node (if different from the main 
verb, then following after its head word in 
the TGTS) 
3. C a contrastive CB node 
Examples: 
(5) (VoIby v Izracli.) Po volbdeh.(T) si 
IzvaeIci(T) zvykaji(F) na novdho(F) pre- 
mid,'a(F). 
(Headline in tile newspapers: Elections ill 
Israel.) After the elections(T), the It- 
raelis(T) get used(F) to a new(F) Prime 
Minister(F). 
140 
(c,) &o,.~,o,,,(,(:(c) o,,,(T).#(P) (lol,,.:,;(F), (,,~(., 
.j(,ko politik(C) v.evynikd(F). 
(As a) St)ortsman(C ) he(T) is(F) g(,od(F), 
but as a politician(C) he does not ex(:el(l?). 
The instructions for the assigmnent of the 
values of TFA can be briefly sl)e('itied as fol- 
lows, if the surface word order and the 1)osi- 
tion of the intonation center (IC, see fl)otnote 
2 above) is taken illtO account, as well as /;he 
%ysi:(;mie' (canonical) ordering of the kinds of 
dependents (wtfich, in fact, (:ml difl'er with dif- 
fer(mr hc.ad words; SO is Sl)e(:itie(t either in the 
valen(:y f lames i1: the in(livi(hml lexi(:al entries, 
or, if i)ossibh.', fl)r whole lexical (:lasses and sub- 
(:lasses): 
1. 
2. 
3. 
4. 
( " ? ,. ,, : the bearer )\] \] C ~ I i' t;vt)i(:allv the right- 
most del)endent of the verl) 
if the IC is placed (m a nod(~ other than 
the rightmost one, th(', (:Oml)lem(',ntai;ions 
1)laced after IC ~> T 
a left side (lepend(mt; of the verl) ~ T o1' C, 
except for cases in which it (:learly ('arri(> 
1C 
th(: verb and lhose of its d(:l)endents tlmt 
stan(l \])el;weell l;he ver\]) all(l the F-llotl(: (se(: 
1) and thai; re'e. or(h'.red (without all inter- 
v(ufing sisW.r node) a(:(:or(lil~g to SO ~ F; 
among sisi;(:r nodes, all those carrying ~.\[" %l- 
low afl, er all those with C, and all those ('at- 
tying F follow after all those with T; there 
a.rc two sets of (':(:eptions: 
(a,) a. fo(;llS sensitive i)m'tiele can (:arry 
F even when i)l"e(:edillg its governing 
node that carries C, of. Se(:ti(m :3.2 be- 
\ ]O \V  
(b) ~ node M ca,rrying T or C can tbl- 
h)w after its nlol;her node if a node 
with F is 1)resent alnong the nodes 
subordilmte to M, })ut is M)sent both 
mnong the sisters of M mM among 
its superot'dinate nodes (here the re- 
h~tion of 'superor(linate' and %ubor(li- 
nat(;' is the tra nsil:ive (:losm(: of 'gov- 
erning' mid Mq)(;ndent'); (:f. the :lO- 
tion of 'l)roxy fo(:us', (:hara(:terized in 
(ilaji~ovit el; al., 1998), and extort- 
ples such as (Kierdh, o u(7-it, ele j.si tam 
vidS.lQ l/idS1 j scm tam u~.ite.Ic ch.emie 
\[lit. (Which t;eacher.A(:cus have-you 
the,e ,~ee.?) I s~w the,'e (the) te.cl~e," 
of-chemisl;ry\], with which the Patieltt 
'ltrTitch', follows after the verl) in the ui:- 
derlying tle(}, although it carries 3.' 
Note: For Cze('h, the SO of the main tyl)eS 
of dependency has 1)een found (on the 1)asis 
of eml)irical mmlysis of texts and of exper- 
iments with groups of speakers, see (Sgall 
eL al., 1995)) to h~vc (with most verbs and 
other heads) the tbllowing form, as for the 
main kinds of dependents: 
A(:tor- i rl'(~mt)oral ,:: Lo(:atiolt -:; 
lnstrmnent ,: Addressee-;  1)aticnt 
1,2Ithet a 
5. eml)(~(hh',d a.t;tril)utes =~> F (unless they are 
on\]y re, l)eat(',(l or restored) 
6. il:dexic, al expre, ssiolm (jd lIl, l,v \[youl, l,(,d' 
I,:,)wl, t(.z:,j Ihei'e.l, we~,k for,.s of p~'o- 
nouns, pronomina.1 expressions with a gen- 
e,.',~l .,(;~:.i,,g (,.;Z~do I,~o,nebodyl, :i~d,~o',~ 
\[once upon a timel...) ~ T (except ill 
cases of (:ontrast or as bearers of IC) 
7. si;rong forms of pronouns - -> F (after 
t)rel)osil:ions an(l in coordinated (:OllStru(:- 
t;ions: l;he, assignment of T or F in @zc(:h is 
gui(lcd by (;it(', g(mcral rules l through 4) 
8. restored lmdes, deleted in the surf:we forms 
of s(~,ll{,(~llces ~ T; we devote Section 2.3 
below to l;he 1)lacelllOllt of the, restored 
nodes Note: There are special cases of (:o- 
ordination, both in Cech and in English, 
which do not mee, t this eolMition: e.g. in 
"l 'hey drank white a.nd red win('? the firsl; 
occurr(m('e of %vine', which m~y be NB, is 
delet;ed in the surface (and restored in the 
TGTS).  
9. a node N dei)endent o the left in a way 
not meeting the conditiol: of 1)rojectivity: 
C (this node is then placed lllore to 
the right, to meet that condition; these and 
;~Let us not(: that Dirc(:tional.3 ('where to') tbllows 
aft, er Patient in Czc(:h as well as in Fmglish and also in 
Gc, rman, a(:cording to the Cml)irical research discussed in 
(M.,); t:lms i( is not exact o characot;riz(; the canonical 
order of German as a "mirror image" of that of English. 
141 
other movements are discussed in Section 
2.4: below) 
10. the nodes subor(linate to such an N move 
together with it and get T or F (according 
to the rules above) 
Note: The resulting TGTSs are projective, 
i.e. t br every pair of nodes x, y in a TGTS it 
holds that if x depends on y and x follows (pre- 
cedes) 37, then every node z following (preceding) 
y and preceding (following) x is subordinate to 
y. Thus, 'not to meet the condition of projec- 
tivity' concerns tim 'analytic' trees; this means, 
in other words, that this condition would not be 
met if the positions of x and y in the left-to-right 
order of the nodes in the TOTS (in the 'under- 
lying word order') always corresponded to their 
positions in the surface (morphemic and %na- 
lytic') word order. 
Example (with a very simplified linearized no- 
tation of the TGTS, in which every dependent 
is closed in its pair of parentheses): 
(7) K jdsotu(C) neni(F) nejmen.~:f(F) 
For triumphing is-not the-least 
&~vod(F). 
reasoll 
(r') (neg.F) bTjt.F ((jdsot.C) d,fi, vod.F 
(neg.F) be.F ((triumlflfing.C) reason.F 
(least.F)) 
A sentence with a non-prototypic~fi placement 
of the IC: 
(8) (Vdtgina m, inistr'gt St@aginovy novd vlddy 
patti k v&'n~m dr,uh,~irn cjzndmgj,~'\[h,o 
ruskdho intrikdna Berezovskdh, o. ) 
(The majority of the miifisters of St6pa~i- 
ney's new government belongs to faithfifl 
fi'iends of the best known Russian intriguer 
Berezovskij.) 
I(F) AKSJONENKO(F) u(h'2ujc(T) 
Even(F) AKSJONENKO(F) keeps(T) 
s Bcrezovsk~rn(T) blfzkd(F) 
with Bere ovskij(T) dose(F) 
styky(T). 
contacts(T). 
2.3 The  pos i t ion  of  a restored node  
The degree of CD of a node that is being re- 
stored (i.e. supposed to have been deleted in 
the surface form of the sentence), and thus also 
its position in the underlying word order, is de- 
termined on the basis of its relationship to its 
governing node. Since such a node ahnost al- 
ways is contextually bound (with the exception 
of the specific case of coordinated structures, see 
the Note after point 8 in Section 2.2 above), it 
is placed to the left of its governing word; more 
specifically: 
(a) if the restored node RN depends on a verb, 
then: 
(b) 
(c) 
(aa) if RN is not the single item depending 
on the given verb token, then RN is 
to be added in the 'Wackernagel posi- 
tion'; 
(ab) if RN has no sister nodes, then it is 
placed at the beginning of the clause; 
if RN is restored as depending on a noun 
(or adjective), I{N is placed as the least dy- 
namic dependent of this governing word; 
if more than one node are inserted as de- 
pending on one and the same item, then 
their order should confornl to tile systemic 
(%anonical') ordering of the valency slots 
(see the remark on SO in Section 2.2 above, 
point 4). 
Point (a) appears to be substantiated by the 
fact that e.g. the subject )ronolln appears ill the 
zero form in Czech under similar conditions as 
the weak, clitic pronouns, for which the position 
imlnediately to the left of the verb is typical, cf. 
sentences such as VSera (on) p~'igel pozd5 \]Yes- 
terday (he) canto here late\], Janu (oni) nevidSli 
\[lit.: .Jane-Accus they have-not-seen\], o1"(On) 
spal \[He was-sleeping\]. This concerns also such 
deletable items as e.g. the Directional with pfi- 
jet \[arrive\], cf. Jan dnes (sere/tam) ncp~'~;jcl \[ it. 
.John to-day (he,'e/there) has-not-arrived\]. 
The appropriateness of these preliminary 
rules is being checked uring the tagging proce- 
dure, the results of which will be of importance 
for a more exact (and more complete) formula- 
tion of the relevant parts of the description of 
the sentence structure of Czech. This aspect 
142 
of the useflflness of the corpus tagging concerns 
also many ol;h(;r 1)oinl;s of grammar. 
2.4 Under ly ing  and  sur face word  order  
Within the tagging procedure, tim differences 
between the two levels of the left-to-right order 
can be described 1)y movelnent rules, a prelimi- 
nary tbrm of which can be brietly characterized 
as follows: 
1. if a node 1111 carries C and a node M2 de- 
l)ending on M1 is 1)laced to the right of a 
node M3 superordinate o M1 in the surtkce 
word order, then M1 is placed immediately 
to the left of M2 in the resulting tree; cf. 
e.g. &o,'tov~',c (M1) o,, .# (M3) dob,",'j (M2) 
Ilit. (As a) sportsman he is goodl, see ex. 
(6) in Section 2.2 
2. if the 1)ositions of the nodes MI, M2 and 
M3 differ front l)oint \] only in t;hat M1 (h> 
pends on M2, then again M1 is placed im- 
mediately to the left of M2 ill the resul/:ing 
tree; of. exanll)le (7) ill Se(:i;ion 2.2 a\])ove, 
in which jdsot  occut)ies the position of M\], 
d,ivod that of M2, and nen i  that of M3, or: 
(9) ,lirku (M1)j.sme pld 'novd i (M3)  
po,~'la, l, (M2) do F'r~n(:i('. 
IliL George.Ac(:us (M1) we-1)la\],ned 
(M3) 1;o-send (M2)to \]Clan(:e\] 
3. ~ compar~tive of an ~Mje(:tive thai; \])rece(les 
its governing 1).OUll in t;he surface is moved 
to the right of this noun in (,,xamt)les such as 
vdt.?i re&to nc~ 13o,s'to',, \[a. hn'ger town than 
Boston\]; I his surface order probably should 
be limited (by a rule of grammar) to cases 
in which the two nouns 1)elong to a single 
semantic sul)class. 
4. in sentences exhibiting a secondary place- 
ment of IC, the bearer of IC occupies the 
rightmost 1)osition in the resulting l:ree; cf. 
example (\])(b) in Section 2.1 al)ove, in 
whi('h 'English' is tile t bt:us prol)er; the as- 
suinl)gion underlying the. t)lacemenl; of IC 
in a written text is that g~ written form of ~ 
sentence may correspond to dit\[erent (silo- 
ken) sentences, according to the differences 
of the 1)lacement of IC in the al)l)ropriate 
way of 1)renouncing t;he sentence. 
3 The  spec ia l  case of  focus  sens i t i ve  
par t ic les  
Since the focus sensitive particles are idengified 
(1)y the flmctor value RHEM for 'rhematizer' or 
'focalizer'), it is possitfle to use PDT also for 
a sl)ecitication of their occurrences in different 
positions 1)oth in the det)endency structure of 
the sentence and in its TFA. Tile starting hy- 
l)otheses, which might be checked on the basis of 
PDT, are. as tbllows (of. (Hajieov5 ctal., 1998)): 
3.1 Focus sensit ive particles in 
i )rototypical pos i t ions 
The 1)rotol;yl)ical syntactic position of a foc, al- 
izer ca.ll t)e understood as that of a dependent 
of a verb node; thus, in examples like (10) or 
(11), it is 1)ossible to specit:y lhe scope of the 
foealizer as the whole subtree subordinated to 
lhe verl) (where "sul)ordilml;ed' is undersl;ood as 
t\]le transitive closure of klel)en(lent' in the re- 
flexive s('.nsc, so I:hat the, verl) itself is in('luded); 
the st'Ol)e is divided into 1)a(:kground and focus 
of the fl)calizer (ti:'), as will 1)e specified in 3.2. 
Thus, in the interl)retation of (10) on the read- 
ing ret)rcsented (with many siml)lifications) by 
(10') it is included that (according to what P. 
knows) among l;hose whom % saw there was 
noone else t;han M (i.e. while 'T. saw' consti- 
l;lll;es l;he 1)ackground of 'only', its fl" is 'Mary'). 
Similarly, if in (11) the negation (all;hough ex- 
\]n'css('d l)y ~t prefix in Czech) is handled as a 
det)cn(lelfl: of the \,er\]), its bad{ground is the 
subject and tt' includes 1)oth the vcrl) an(l t;he 
oh.iect. 
(10) Pavcl v'\[, ~'. Tomd.# 
'Paul knows that Thomas 
vidH .je'n MAIUL  
saw only MAI~Y.' 
(Paul) knows ((Tholnas) sa.w (only) 
(Mary)) 
Mart in  ne(~te NOVINK 
~Marl;in nol;-rea(ts NEWSPAPERS.' 
(10') 
(11) 
\]n (12) only the adjective constitutes the ff of 
'only', its background consisting of 'car' (among 
all cars, P. only wants a blue one); thus, the fo- 
calizer can best })e described here as dq)ending 
el l  ~car'. 
(12) Pct, r ch, ce .jc.n MODIU2 auto. 
'Petr wants o1:1.5, (a) 13\],UE car.' 
143 
3.2 Focus sensitive particles in the 
hierarchy of comnmnicat ive 
dynamism 
The primary position of a focalizer ill a TR is at 
the boundary between tile topic and the focus 
of the verb clause and the tbcus of tile clause is 
then identical to tile focus of tile focalizer. If a 
fbcalizer is included in the topic, then its focus 
contains those items which in the TR are placed 
between this focalizer mid the next item ularked 
as C to tile right and are nlore dynamic than the 
tbcalizer). 
It should be noted that CD is understood here 
as a partial ordering defined so that: 
(i) in every set of a head and its daughter 
nodes, every daughter node placed to the 
right of its head is more dynamic than ev- 
cry daughter node placed to the left of its 
head; 
(ii) the relation 'more dynanfic' is deternlined 
by the irrettexive trausil;ive closure of (i). 
~i'hus, e.g. in the TI{ (10'), 'knows' is more dy- 
nalnic than 'Paul' and less dynmnic than 'saw' 
according to tile point (i), and both 'only' and 
'Mary', being more dynanlic titan 'saw', are 
more dynmnie than ~knows' according to the 
point (ii); however, ~Thomas' is neither more 
nor less dynamic than 'knows'. If (10) is cut- 
bedded into a more conlplex sentence as (a part 
of) its topic, titan 'Mary' is more dynanfic thml 
%nly' and has the f~atm'e C; thus, e.g. with 
'Since Paul knows that Thomas saw only Mary, 
he is not afraid', 'Mary' constitutes the whole fl 
of 'only', similarly as in (10'). 
Tile underlying word order W (a linear order- 
ing) is then defined on the basis of CD, with (iii) 
and (iv) holding tbr every two nodes x and y in 
a tree: 
(iii) if node x is nlore dynamic than node y, then 
x tbllows y under W; 
(iv) if node x follows node y under W, node u is 
subordinated to x and node z is subordinate 
to y, then u tbllows both y and z, and x 
follows z under W. 
Among tile non-prototyt)ical , secondary posi- 
tions of tbcalizers, there are also the cases of 
their clustering (e.g. 'not only'), as well as the 
sentences in which a focalizer itself constitutes 
the whole locus of tile sentence ('He DID realize 
this'). 
4 Summary  
After a brief characterization f the Prague De- 
pendency Treebank and of tile Praguian theory 
of Topic-Focus Articulation we have presented 
a proposal how the main aspects of tile intbr- 
nlation structure of the sentence (i.e. of its 
topic-focus articulation) cml be integrated into 
the tagging system that captures the underly- 
ing structures. The present form of the system 
nmkes it possible to check our hypotheses on a 
large text corpus, and thus perhaps to achieve 
a higher degree of automation (and reliability) 
of the proposed procedure. The last section ex- 
emplifies how the t)roposed approach makes it 
possible to analyze structures with the so-called 
focus sensitive operators. 
References  
.Jan Ha.ji(?. Building a syntactically anno- 
tated corpus: Tile prague dependency tree- 
bank. In E. Hajif:ov{~, editor, Ls's'ues of Va- 
lency and Meaning, Studies in Honour of 
Jarnlila Panevov5, pages 106 132. Karolinum, 
Prague. 
Jml Haji5 mid Barbora Hladkfi. 1997. Proba- 
bilistic and rule-based tagger of all inflective 
language - a comparison. In P'~vceedinfls of
the F@h Uo'n:/'ercrzce on Applied Natural Lan- 
.quagc Processing, pages 111-118, Washing- 
ton, D.C. 
Eva Ha.iiSovi~, B. Partee, and Petr Sgall. 1998. 
Topic-focus articulation, tripartite structures, 
and semantic ontent. Kluwer, Amsterdam. 
Steedlnml M. hlformation structure and 
the syntax-phonology interface, unpublished 
ntanuscript. 
Petr Sgall, O. Pfeiffer, W. U. Dressier, and 
M. Pfieek. 1995. Experimental research on 
systemic ordering. Theoretical Linguistics. 
144 
7KH VLPSOH FRUH DQG WKH FRPSOH[ SHULSKHU\ RI QDWXUDO ODQJXDJH
$ IRUPDO DQG D FRPSXWDWLRQDO YLHZ
3HWU 6*$//
&./ &KDUOHV 8QLYHUVLW\ 3UDJXH
0DORVWUDQVNp QiP 
  3UDKD  &]HFK 5HS
VJDOO#FNOPIIFXQLF]
$OHQD %g+029?
&./ &KDUOHV 8QLYHUVLW\ 3UDJXH
0DORVWUDQVNp QiP 
  3UDKD  &]HFK 5HS
ERKPRYD#FNOPIIFXQLF]
$EVWUDFW
$ FRPSOH[ SURFHGXUH RI V\QWDFWLF
DQQRWDWLRQ RI D ODUJH WH[W FRUSXV PD\ EH
KHOSIXO LQ FKHFNLQJ D ULFK GHVFULSWLYH
IUDPHZRUN WKH 3UDJXLDQ )XQFWLRQDO
*HQHUDWLYH 'HVFULSWLRQ WKDW PDNHV LW
SRVVLEOH WR GLVWLQJXLVK EHWZHHQ WKH FRUH
RI QDWXUDO ODQJXDJH VWUXFWXUHG LQ D
UHODWLYHO\ VLPSOH ZD\ DQG LWV ODUJH
SHULSKHU\ ZLWK LQGLVWLQFW ERUGHUOLQHV
6XFK D SURFHGXUH XQGHUOLHV WKH 3UDJXH
'HSHQGHQF\ 7UHHEDQN ZLWKLQ ZKLFK
DERXW   &]HFK VHQWHQFHV IURP
UXQQLQJ WH[WV KDYH EHHQ DQDO\]HG LQ WKHLU
XQGHUO\LQJ VWUXFWXUH IRU  VHQWHQFHV
DOVR WKHLU 7RSLF)RFXV VWUXFWXUHV KDYH
EHHQ VSHFLILHG :H LOOXVWUDWH WKH ZLGH
UDQJH RI WKH SKHQRPHQD KDQGOHG LH WKH
V\QWDFWLF UHODWLRQV SURSHU DUJXPHQWV DQG
DGMXQFWV FRRUGLQDWLRQ WRSLFIRFXV
DUWLFXODWLRQ ZRUG RUGHU GHOHWLRQ
SRVLWLRQV RI IRFXVLQJ SDUWLFOHV
PRUSKRORJLFDO FDWHJRULHV VXFK DV
QXPEHU WHQVH PRGDOLW\ WKHLU PRUSKHPLF
DQG DQDO\WLFDO PHDQV RI H[SUHVVLRQ DQG
VR RQ
 ,QWURGXFWRU\ UHPDUNV
 7KH DLP
:H ZDQW WR SRLQW RXW KRZ D FRPSOH[
SURFHGXUH RI V\QWDFWLF DQQRWDWLRQ RI D ODUJH WH[W
FRUSXV PD\ EH KHOSIXO LQ FKHFNLQJ D ULFK
GHVFULSWLYH IUDPHZRUN ZKLFK PDNHV LW SRVVLEOH
WR VSHFLI\ WKH IUHTXHQWO\ UHTXLUHG GLVWLQFWLRQ
EHWZHHQ WKH FRUH RI QDWXUDO ODQJXDJH
VWUXFWXUHG LQ D UHODWLYHO\ VLPSOH ZD\ DQG LWV
ODUJH SHULSKHU\ ZLWK LQGLVWLQFW ERUGHUOLQHV 2Q
WKH EDFNJURXQG RI WKH 3UDJXLDQ )XQFWLRQDO
*HQHUDWLYH 'HVFULSWLRQ VHH 6JDOO HW DO 
+DML?RYi HW DO  WKLV SURFHGXUH XQGHUOLHV
WKH 3UDJXH 'HSHQGHQF\ 7UHHEDQN 3'7
ZLWKLQ ZKLFK VHQWHQFHV IURP WKH &]HFK
1DWLRQDO &RUSXV LH IURP UXQQLQJ WH[WV DUH
DQDO\]HG 8S WR QRZ DERXW   VHQWHQFHV
KDYH EHHQ DQQRWDWHG DW WKH OHYHO RI XQGHUO\LQJ
V\QWD[ RXW RI ZKLFK  KDYH EHHQ DQDO\]HG
DOVR LQ WKHLU 7RSLF)RFXV VWUXFWXUHV 2XU
LOOXVWUDWLRQV VKRXOG FKDUDFWHUL]H WKH ZLGH UDQJH
RI WKH SKHQRPHQD KDQGOHG LH WKH V\QWDFWLF
UHODWLRQV SURSHU DUJXPHQWV DQG DGMXQFWV
FRRUGLQDWLRQ WRSLFIRFXV DUWLFXODWLRQ ZRUG
RUGHU GHOHWLRQ SRVLWLRQV RI IRFXVLQJ SDUWLFOHV
RSHUDWRUV PRUSKRORJLFDO FDWHJRULHV VXFK DV
QXPEHU WHQVH PRGDOLW\ WKHLU PRUSKHPLF DQG
DQDO\WLFDO PHDQV RI H[SUHVVLRQ DQG VR RQ
 )RUPDOL]DWLRQ DQG OLQJXLVWLFV DV D
FXPXODWLYH VFLHQFH
7KH JHQHUDO DSSURDFK ZH DSSO\ LQ ORRNLQJ IRU D
IRUPDO GHVFULSWLRQ RI QDWXUDO ODQJXDJH LV EDVHG
RQ RXU FRQYLFWLRQ WKDW OLQJXLVWLFV VKRXOG QRW
ORVH LWV FKDUDFWHU RI D FXPXODWLYH VFLHQFH
LQWHUUXSWLRQV RI LWV GHYHORSPHQW PD\ EH UHGXFHG
E\ V\VWHPDWLF GLVFXVVLRQV EHWZHHQ GLIIHUHQW
WKHRUHWLFDO DSSURDFKHV (VSHFLDOO\ WKH WUDGLWLRQ
RI WKH 3UDJXH VFKRRO RI IXQFWLRQDO DQG
VWUXFWXUDO OLQJXLVWLFV LV QRW WR EH IRUJRWWHQ
VLQFH LW H[KLELWV FHUWDLQ DGYDQWDJHV VRPH RI
WKHP DUH EDVHG RQ WKH IXQGDPHQWDO GLVWLQFWLRQ
EHWZHHQ XQPDUNHG SULPDU\ LH SURWRW\SLFDO
DQG PDUNHG VHFRQGDU\ SKHQRPHQD 7KLV
GLVWLQFWLRQ PDNHV LW SRVVLEOH WR KDQGOH WKH FRUH
RI ODQJXDJH VWUXFWXUH DV EDVHG RQ VLPSOH
JHQHUDO SULQFLSOHV ZKLOH LWV SHULSKHU\ FRQVLVWV
RI PRUH RU OHVV PDUJLQDO OD\HUV OLPLWHG E\
FRQWH[WXDO DQG RWKHU UHVWULFWLRQV KLJKO\
GLIIHUHQW IURP RQH ODQJXDJH WR WKH RWKHU DQG
WKXV FDQ EH GHVFULEHG RQO\ E\ VSHFLILF UXOHV
6WUXFWXUDO V\QWD[ LQ (XURSH KDV EHHQ EDVHG RQ
GHSHQGHQF\ WKH UHODWLRQ EHWZHHQ KHDG DQG
PRGLILHU VLQFH LWV EHJLQQLQJV WKXV GLIIHULQJ
IURP GHVFULSWLYLVW DQG &KRPVN\DQ WUHQGV
ZKLFK ZRUN ZLWK FRQVWLWXHQF\ 7KH WUDGLWLRQ RI
GHSHQGHQF\EDVHG V\QWD[ LV PXFK ROGHU
VWDUWLQJ LQ WKH V LQ *HUPDQ\ DQG
HODERUDWHG WKHQ DOVR LQ )UDQFH DQG WKH 6ODYLF
FRXQWULHV VHH WKH ZULWLQJV RI / 7HVQL?UH 9
?PLODXHU DQG RWKHUV 7KLV DSSURDFK LV ZHOO
VXLWHG IRU D KLJK GHJUHH RI PRGXODULW\ RI
ODQJXDJH GHVFULSWLRQ ZKLFK SHUKDSV XQGHUOLHV
LWV IUHTXHQW XVH LQ QDWXUDO ODQJXDJH SURFHVVLQJ
7KH WKHRUHWLFDO SRWHQWLDO RI VXFK D GHVFULSWLRQ
PD\ EH FOHDUO\ VHHQ LI RQH GRHV QRW ZRUN RQO\
ZLWK VRPH NLQG RI VXUIDFH V\QWD[ EXW
LQYHVWLJDWHV WKH XQGHUO\LQJ VWUXFWXUH
DSSURSULDWH WR VHUYH DV WKH LQSXW WR VHPDQWLF
SUDJPDWLF LQWHUSUHWDWLRQ )URP WKH YLHZSRLQW
RI OLQJXLVWLF W\SRORJ\ ZKLFK SULPDULO\ VWXGLHV
WKH UHODWLRQVKLSV EHWZHHQ XQGHUO\LQJ V\QWDFWLF
DQG VXUIDFH PRUSKHPLF UHSUHVHQWDWLRQV FI
5DPDW  WKH GLIIHUHQFH EHWZHHQ DQ HQGLQJ
DQG D IXQFWLRQ ZRUG LV GLUHFWO\ UHOHYDQW RQO\
IRU PRUSKHPLFV FI 6NDOL?ND Topic-focus and salience*
Eva Haji?ov?
Faculty of Mathematics and Physics
Charles University
Malostransk? n?m. 25
118 00 Praha, Czech Republic
hajicova@ufal.mff.cuni.cz
Petr Sgall
Faculty of Mathematics and Physics
Charles University
Malostransk? n?m. 25
118 00 Praha, Czech Republic
sgall@ufal.mff.cuni.cz
                                                          
*Acknowledgement: The work reported on in this paper has been carried out under the projects GACR 405/96/K214 and
MSMT LN00A063.
1 Objectives and Motivation
Most of the current work on corpus annotation is
concentrated on morphemics, lexical semantics
and sentence structure. However, it becomes
more and more obvious that attention should and
can be also paid to phenomena that reflect the
links between a sentence and its context, i.e. the
discourse anchoring of utterances. If conceived
in this way, an annotated corpus can be used as a
resource for linguistic research not only within
the limits of the sentence, but also with regard to
discourse patterns. Thus, the applications of the
research to issues of information retrieval and
extraction may be made more effective; also
applications in new domains become feasible, be
it to serve for inner linguistic (and literary) aims,
such as text segmentation, specification of topics
of parts of a discourse, or for other disciplines.
These considerations have been a motivation
for the tectogrammatical (i.e. underlying, see
below) tagging done within the Prague
Dependency Treebank (PDT) to contain also
attributes concerning certain contextual features,
i.e. the contextual anchoring of word tokens and
their relationships to their coreferential
antecedents.
Along with this enrichment in the
intersentential aspect, we do not neglect to pay
attention to intrasentential issues, i.e. to sentence
structure, which displays its own features
oriented towards the contextual potential of the
sentence, namely its topic-focus articulation
(TFA).
In the present paper, we give first an outline
of the annotation scenario of the PDT (Section
2), concentrating then on the use of one of the
PDT attributes for the specification of the Topic
and the Focus (the 'information structure') of the
sentence (Section 3). In Section 4. we present
certain heuristics that partly are based on TFA
and that allow for the specification of the
degrees of salience in a discourse. The
application of these heuristics is illustrated in
Section 5.
2 Outline of the Prague Dependency
Treebank
The Prague Dependency Treebank (PDT) is
being built on the basis of the Czech National
Corpus (CNC), which grows rapidly in the range
of hundreds of millions of word occurrences in
journalistic and fiction texts. The PDT scenario
comprises three layers of annotation:
(i) the morphemic (POS) layer with about
2000 tags for the highly inflectional Czech
language; the whole CNC has been tagged by a
stochastic tagger (Haji? and Hladk? 1997;1998,
B?hmov? and Haji?ov? 1999, Hladk? 2000)
with a success rate of 95%; the tagger is based
on a fully automatic morphemic analysis of
Czech (Haji? in press);
(ii) a layer of 'analytic' ("surface") syntax
(see Haji? 1998): cca 100 000 Czech sentences,
i.e. samples of texts (each randomly chosen
sample consisting of 50 sentences of a coherent
text), taken from CNC, have been assigned
dependency tree structures; every word (as well
as every punctuation mark) has a node of its
own, the label of which specifies its analytic
function, i.e. Subj, Pred, Obj, Adv, different
kinds of function words, etc. (total of 40 values);
no nodes are added that are not in the surface
shape of the sentence (except for the root of the
tree, carrying the identification number of the
sentence); the sentences from CNC are
preprocessed by a dependency-based
modification of Collins et al's (1999) automatic
parser (with a success rate of about 80%),
followed by a manual tagging procedure that is
supported by a special user-friendly software
tool that enables the annotators to work with
(i.e. modify) the automatically derived graphic
representations of the trees;
(iii) the tectogrammatical (underlying)
syntactic layer: tectogrammatical tree structures
(TGTSs) are being assigned to a subset of the set
tagged according to (ii); by now, the
experimental phase has resulted in 20 samples of
50 sentences each; the TGTSs, based on
dependency syntax, are much simpler than
structural trees based on constituency
(minimalist or other), displaying a much lower
number of nodes and a more perspicuous
patterning; their basic characteristics are as
follows (a more detailed characterization of
tectogrammatics and motivating discussion,
which cannot be reproduced here, can be found
in Sgall et al 1986; Haji?ov? et al 1998):
(a) only autosemantic (lexical) words have
nodes of their own; function words, as far as
semantically relevant, are reflected by parts of
complex node labels (with the exception of
coordinating conjunctions);
(b) nodes are added in case of deletions on
the surface level;
(c) the condition of projectivity is met (i.e. no
crossing of edges is allowed);
(d) tectogrammatical functions ('functors')
such as Actor/Bearer, Patient, Addressee,
Origin, Effect, different kinds of Circumstantials
are assigned;
(e) basic features of TFA are introduced;
(f) elementary coreference links (both
grammatical and textual) are indicated.
Thus, a TGTS node label consists of the
lexical value of the word, of its '(morphological)
grammatemes' (i.e. the values of morphological
categories), its 'functors' (with a more subtle
differentiation of syntactic relations by means of
'syntactic grammatemes' (e.g. 'in', 'at', 'on',
'under'), of the attribute of Contextual
Boundness (see below), and of values
concerning intersentential links (see below).
3 From Contextual Boundness to the
Topic and the Focus of the Sentence
The dependency based TGTSs in PDT allow for
a highly perspicuous notation of sentence
structure, including an economical
representation of TFA, understood as one of the
main aspects of (underlying) sentence structure
along with all other kinds of semantically
relevant information expressed by grammatical
means. TFA is accounted for by one of the
following three values of a specific TFA
attribute assigned to every lexical
(autosemantic) occurrence: t for 'contextually
bound' (prototypically in Topic), c for
'contrastive (part of) Topic', or f (?non-bound?,
typically in Focus). The opposition of contextual
boundness is understood as the linguistically
structured counterpart of the distinction between
"given" and "new" information, rather than in a
straightforward etymological way (see Sgall,
Haji?ov? and Panevov? 1986, Ch. 3). Our
approach to TFA, which uses such operational
criteria of empirical adequateness as the
question test (with the item corresponding to a
question word prototypically constituting the
focus of the answer), represents an elaboration
of older ideas, discussed especially in Czech
linguistics since V. Mathesius and J. Firbas, in
the sense of an explicit treatment meeting the
methodological requirements of formal syntax.
The following rules determine the
appurtenance of a lexical occurrence to the
Topic (T) or to the Focus (F) of the sentence:
(a) the main verb (V) and any of its direct
dependents belong to F iff they carry index f;
(b) every item i that does not depend directly
on V and is subordinated to an element of F
different from V, belongs to F (where
"subordinated to" is defined as the irreflexive
transitive closure of "depend on");
(c) iff V and all items kj directly depending on it
carry index t, then those items kj to which some
items lm carrying f are subordinated are called
'proxy foci' and the items lm together with all
items subordinated to one of them belong to F,
where 1 ? j,m;
(d) every item not belonging to F according
to (a) - (c) belongs to T.
To illustrate how this approach makes it
possible to analyze also complex sentences as
for their TFA patterns, with neither T nor F
corresponding to a single constitutent, let us
present the following example, in which (1') is a
highly simplified linearized TGTS of (1); every
dependent item is enclosed in a pair of
parentheses; for the sake of transparency,
syntactic subscripts of the parentheses are left
out here, as well as subscripts indicating
morphological values, with the exception of the
two which correspond to function words, i.e.
Temp and Necess(ity); Fig. 1. presents the
respective tree structure, in which three parts of
each node label are specified, namely the lexical
value, the syntactic function (with ACT for
Actor/Bearer, RSTR for Restrictive,  MANN for
Manner, and OBJ for Objective), and the TFA
value:
(1) ?esk? radiokomunikace mus? v tomto
roce rychle splatit dluh televizn?m div?k?m.
This year, Czech Radiocommunications have
quickly to pay their debt to the TV viewers.
(1') ((?esk?.f) radiokomunikace.t)    ((tomto.t)
         Czech    Radiocommunications      this
roce.Temp.t) splatit.Necess.f  (rychle.f)
in-year          must-pay             quickly
(dluh.f ((televizn?m.f) div?k?m.f))
 debt TV                  viewers
Figure 1.
4 Degrees of Salience in a Discourse
During the development of a discourse, in the
prototypical case, a new discourse referent
emerges as corresponding to a lexical
occurrence that carries the index f; its further
occurrences in the discourse carry t and are
primarily guided by the scale of their degrees of
salience. This scale, which was discussed by
Haji?ov? and Vrbov? (1982), has to be reflected
in a description of the semantico-pragmatic
layer of the discourse. In this sense our approach
can be viewed as pointing to a useful enrichment
of the existing theories of discourse
representation (cf. also Kruijffov? 1998,
Krahmer 1998; Krahmer and Theune 1999).
In the annotation system of PDT, not only
values of attributes concerning sentence
structure are assigned, but also values of
attributes for coreferential links in the discourse,
which capture certain features typical for the
linking of sentences to each other and to the
context of situation and allow for a tentative
characterization of the discourse pattern in what
concerns the development of salience degrees
during the discourse.
The following attributes of this kind are
applied within a selected part of PDT, called
'model collection' (for the time being, essentially
only pronouns such as 'on' (he), including its
zero form, or 'ten' (this) are handled in this way):
COREF: the lexical value of the antecedent,
CORNUM: the serial number of the antecedent,
CORSNT: if the antecedent in the same
sentence: NIL, if not: PREVi for the i-th
preceding sentence.
An additional attribute, ANTEC, with its
value equal to the functor of the antecedent, is
used with the so-called grammatical coreference
(relative clauses, pronouns such as 'se' (-self),
the relation of control).
On the basis of these attributes (and of further
judgments, concerning especially associative
links between word occurrences), it is possible
to study the referential identity of different word
tokens in the flow of the discourse, and thus also
the development of salience degrees.
The following basic rules determining the
degrees of salience (in a preliminary
formulation) have been designed, with x(r)
indicating that the referent r has the salience
degree x, and 1 ? m,n:
(i) if r is expressed by a weak pronoun (or
zero) in a sentence, it retains its salience degree
after this sentence is uttered: n(r) --> n(r);
(ii) if r is expressed by a noun (group)
carrying f, then n(r) --> 0(r);
(iii) if r is expressed by a noun (group)
carrying t or c, then n(r) --> 1(r);
(iv) if n(r) --> m(r) in sentence S, then
m+2(q) obtains for every referent q that is not
itself referred to in S, but is immediately
associated with the item r present here1;
(v) if r neither is included in S, nor refers to
an associated object, then n(r) --> n+2(r).
These rules, which have been checked with
several pieces of English and Czech texts,
capture such points as e.g. the fact that in the
third utterance of Jim met Martin. He
immediately started to speak of the old school in
Sussex. Jim invited him for lunch the weak
pronoun in object can only refer to Martin,
whose image has become the most salient
referent by being mentioned in the second
utterance; on the other hand, the use of such a
pronoun also in the subject (in He invited him
for lunch) would make the reference unclear.
Since the only fixed point is that of maximal
salience, our rules technically determine the
degree of salience reduction (indicating 0 as the
maximal salience). Whenever an entity has a
salience distinctly higher than all competing
entities which can be referred to by the given
expression, this expression may be used as
giving the addressee a sufficiently clear
indication of the reference specification.2
5 Illustrations
The development of salience degrees during a
discourse, as far as determined by these rules,
may be illustrated on the basis of five sentence
tokens (utterances) from PDT, starting from (1),
which constitute a segment of a newspaper text
(we indicate the numerical values of salience
reduction for every noun token that is a referring
expression). We present here - similarly as with
(1') in Section 3 above - highly simplified
representations of these sentences, with
parentheses for every dependent member and
the symbols t, c, and f for contextual boundness;
                                                          
1 Only immediate associative links are taken into account
for the time being, such as those between (Czech) crown
and money,  or between TV or (its) signal and (its) viewer.
2 These tentative rules, which have been presented at
several occasions (starting with Haji?ov?  and Vrbov?
1982) for the aims of a further discussion, still wait for a
systematic testing and evaluation, as well as for
enrichments and more precise formulations. These issues
may find new opportunities now, when e.g. a comparison
with the centering theory gets possible and when a large set
of annotated examples from continuous texts in PDT is
available. An automatic derivation of such features can
only be looked for after the lexical units included get a very
complex and subtle semantic classification.
numbers of the degrees of salience (more
precisely, of salince reduction) for every
referring expression are inserted in the sentences
themselves. This example should enable the
reader to check (at least in certain aspects) the
general function of the procedure we use, as
well as the degree of its empirical adequacy in
the points it covers, and also our consistence in
assigning the indices. We are aware of the
preliminary character of our analysis, which
may and should be enriched in several respects
(not to cover only noun groups, to account for
possible episodic text segments, for oral speech
with the sentence prosody, for cases of
deictically, rather than anaphorically
conditioned salience, etc.).
We do not reflect several peripheral points,
such as the differences between surface word
order and the scale of CD (underlying WO),
mainly caused by the fact that a dependent often
precedes its head word on the surface (in
morphemics), although if the dependent has f
(as e.g. rychle (quickly) has in (1)), then it
follows its head under CD (with the exceptions
of focus sensitive particles, cf. Haji?ov?, Partee
and Sgall 1998); our translations are literal.
(1) ?esk? radiokomunikace.1 mus? v tomto
roce.1 rychle splatit dluh.0 televizn?m
div?k?m.0
In this year, Czech Radiocommunications
have quickly to pay their debt to the TV viewers.
(1') ((?esk?.f) radiokomunikace.t)   ((tomto.t)
        Czech    Radiocommunications      this
roce.Temp.t) splatit.Necess.f  (rychle.f)
in-year          must-pay             quickly
(dluh.f ((televizn?m.f) div?k?m.f))
 debt TV                viewers
(2) Jejich.1 vys?la?e.1 dosud pokr?vaj?
sign?lem.0 programu.0 ?T.1 2.0 m?n? ne?-
polovinu.0 ?zem?.0 republiky.0.
Their transmitters hitherto cover by-signal
of-the-program ?T2 less than a-half of-the-
territory of-the-Republic.
(2') ((jejich.t) vys?la?e.t) (dosud.t) pokr?vaj?.f
(sign?lem.f (programu.f (?T.t (2.f)))) ((m?n?.f
(ne?-polovinu.f)) ?zem?.f (republiky.t))
(3) Na moravsko-slovensk?m pomez?.1 je
?ada m?st.0, kde nezachyt? ani prvn? program.0
?esk? televize.1.
On the-Moravian-Slovakian borderline
there-is a-number of-places where (they) do-not-
get even the-first program of-Czech Television.
(3') ((na-moravsko-slovensk?m.t) pomez?.t)
je.f (?ada.f (m?st.f ((kde.t) (oni.t) (ne.f) zachyt?.f
((ani.f) (prvn?.f) program.t ((?esk?.t)
televize.t)))))
(4) Do rozd?len?.1 federace.1 toti? sign?l.1
zaji??ovaly vys?la?e.0 v SR.0.
Until the-division of-the-federation as-a-
matter-of-fact the-signal.Accusative provided
transmitters.Nominative in S(lovac)R(epublic).
(4') (do-rozd?len?.t (federace.t)) (toti?.t)
(sign?l.t) zaji??ovaly.t (vys?la?e.f (v-SR.f)).
(5) ?esk? televize ??d? urychlenou v?stavbu
nov?ch vys?la??.
Czech Television requires quick construction
of-new transmitters.
(5') ((?esk?.t) televize.t) ??d?.f
((urychlenou.f) v?stavbu.f ((nov?ch.f)
vys?la??.t))
The development of salience reduction of the
referents most frequently mentioned in (1) - (5)
is characterized in Tab. 1, which includes
numbers of salience reduction degrees and of
those rules from Section 3 that are the main
sources of the degrees. Two further remarks
may be added, concerning details of our analysis
that have not been discussed above and may not
be directly found in the previous publications we
refer to: (a) a noun group consisting of a head
with t or c and of one or more adjuncts with f
constitutes a referring expression as a whole, in
the prototypical case, and gets degree 0, if it
occurs in F; this concerns e.g. the group vys?la?e
v SR  (?transmitters in  the Slovac Republic?) in
sentence (4), or ?T 2 (CTV 2) in (2); here 2 is
treated as an adjunct of CT; (b) the difference
between the degrees 0 and 1 is not sufficient for
a safe choice of reference, so that, e.g., the
reference of the pronoun jejich (their) after (1)
by itself is indistinct, and only inferencing helps
to establish that ?esk? radiokomunikace (Czech
Radiocommunications) are referred to (viewers
normally do not have transmitters at their
diposal).
after (1) (2) (3) (4) (5)
CRC 1 1 3 5 7
(iii) (iii) (iv) (v) (v)
CTV 3 1 1 2 1
(iv) (iii) (iii) (iv) (iii)
CTV1 2 2 0 2 3
(iv) (iv) (ii) (iv) (iv)
CTV2 2 0 2 2 3
(iv) (ii) (iv) (iv) (iv)
viewer 0 2 2 3 3
(ii) (iv) (i) (iv) (iv)
sig. 3 0 2 1 3
(iv) (ii) (iv) (iii) (iv)
CR 3 1 3 3 3
(iv) (iii) (iv) (iv) (iv)
CSF - - 3 1 3
(iv) (iii) (v)
terr. 3 0 2 2 4
(iv) (ii) (iv) (iv) (v)
tr. - 1 2 0 0
(iii) (iv) (ii) (ii)
Table 1.
Abbreviations:
CRC - Czech Radio(tele)communications
CTV - Czech TV
CR - Czech Republic
CSF - (CS) Federation
CTV1(2) - 1st (2nd) program of CTV
tr. - transmitter
terr. - territory of CR
sig. - signal of CTV
Even with this short piece of discourse, its
segmentation is reflected, if its first subsegment,
discussed up to now (sentences (1) - (5)), is
compared with its continuation, i.e. sentences
(6) - (9), given below. While the first segment
deals primarily with CTV and its signal (cf. the
relatively high salience of CTV, CTV1, CTV2,
RC, signal and viewer  in most parts of the
segment), sentences (6) ? (9) are devoted to
financial issues, as can be seen from the
following facts: (a) money gets degree 0 after
(6), in which it functions as its focus proper (the
most dynamic item), (b) Czech crown gets
degree 1 after (7), in which it is an embedded
part of the focus, and (c) the group financial
coverage gets degree 1 in sentence (8).
The continuation is presented here without
the TGTSs:
(6) Na?e spole?nost m??e ?kol splnit, ale
chyb?j? n?m pen?ze.
Our company can the-task.Accusative fulfil, but
is-lacking us.Dative the-money.Nominative.
(7) Letos by v?stavba technick?ho za??zen? v
sedmi lokalit?ch st?la 120 mili?n? korun, ale
m??eme uvolnit jen 80 mili?n?.
This-year, would the-construction of-technical
equipment in seven localities cost 120 million
crowns, but we-can spend only 80 million.
 (8) Proto o finan?n?m zabezpe?en? jedn?me
s ?eskou televiz?, uv?d? ekonomick? ?editel
?esk?ch radiotelekomunikac? Miroslav Cu??n.
Therefore about (its) financial coverage we-
discuss with Czech Television, states the-
economic director of-Czech
Radiotelcommunications M. C.
(9) Dal??ch 62 mili?n? korun si vy??d?
v?stavba vys?la?? a p?evad??? sign?lu v
pohrani??.
Further 62 million crowns.Accusative Refl. will-
require the-construction.Nominative of-
transmitters and transferrers of-the-signal in the-
border-area.
6 Conclusions
We are aware that, along with the rules
characterized above, there are other factors that
have to be investigated, which are important for
different kinds of discourses. This concerns
various aspects of the discourse situation, of
domain knowledge, of specific textual patterns
(with episodes, poetic effects, and so on).
Factors of these and further kinds can be studied
on the basis of the salience degrees, which are
typical for basic discourse situations.
In any case, we may conclude that it is useful
for a theory of discourse semantics to reflect the
degrees of salience. This makes it possible to
distinguish the reference potential of referring
expressions and thus the connectedness of the
discourse. Discourse analysis of this kind may
also be useful for application domains such as
text segmentation (in accordance with topics of
individual segments), or data mining (specifying
texts in which a given topic is actually treated,
rather than being just occasionally mentioned).
References
B?hmov? A. and E. Haji?ov? (1999). The Prague
Dependency Tree Bank I: How much of the
underlying syntactic structure can be tagged
automatically? The Prague Bulletin of
Mathematical Linguistics 71, 5-12.
Collins M., Haji? J., Brill E., Ramshaw L. and C.
Tillmann (1999). A statistical parser for Czech. In:
Proceedings of 37th Annual Meeting of ACL,
Cambridge, Mass.: M.I.T. Press, 505-512.
Haji? J. (1998). Building a syntactically annotated
corpus: The Prague Dependency Treebank. In:
Issues of Valency and Meaning. Studies in Honour
of Jarmila Panevov?, ed. by E. Haji?ov?, 106-132.
Prague: Karolinum.
Haji? J. (in press). Disambiguation of rich inflection
(Computational morphology of Czech).
Prague:Karolinum.
Haji? J. and Hladk? B. (1997). Probabilistic and rule-
based tagger of an inflective language - a
comparison. In Proceedings of the Fifth
Conference on Applied Natural Language
Processing, Washington, D.C., 111-118.
Haji? J. and Hladk? B. (1998). Czech language
processing - POS tagging. In: Proceedings of the
First International Conference on Language
Resources & Evaluation, Granada.
Haji?ov? E., Partee B. and P. Sgall (1998): Topic-
focus articulation, tripartite structures, and
semantic content. Amsterdam:Kluwer
Haji?ov? E. and J. Vrbov? (1982). On the role of the
hierarchy of activation in the process of natural
language understanding. In: COLING 82. Ed. by J.
Horeck?. Amsterdam: North Holland, 107-113.
Krahmer E. (1998), Presupposition and anaphora.
CSLI Lecture Notes 89. CSLI, Stanford, CA.
Krahmer E. and M. Theune (1999), Efficient
generation of descriptions in context. In: R. Kibble
and K. van Deemter (eds.), Proceedings of the
workshop The Generation of Nominal Expression,
associated with the 11th European Summer School
in Logic, Language and Information.
Kruijff-Korbayov? I. (1998): The dynamic potential
of topic and focus: A Praguian approach to
Discourse Representation Theory. Prague: Charles
University, Faculty of Mathematics and Physics,
Ph.D. dissertation.
Sgall P., Haji?ov? E. and J. Panevov? (1986): The
Meaning of the Sentence in Its Semantic and
Pragmatic Aspects, ed. by J. L. Mey,
Dordrecht:Reidel - Prague: Academia.
Deep Syntactic Annotation: Tectogrammatical Representation and Beyond
Petr Sgall
Center for
Computational Linguistics
sgall@ufal.mff.cuni.cz
Jarmila Panevova?
Institute of Formal
and Applied Linguistics
panevova@ufal.mff.cuni.cz
Eva Hajic?ova?
Center for
Computational Linguistics
hajicova@ufal.mff.cuni.cz
Abstract
The requirements of the depth and precision
of annotation vary for different intended uses
of the corpus but it has been commonly ac-
cepted nowadays that the standard annotations
of surface structure are only the first steps in
a more ambitious research program, aiming at
a creation of advanced resources for most dif-
ferent systems of natural language processing
and for testing and further enrichment of lin-
guistic and computational theories. Among
the several possible directions in which we be-
lieve the standard annotation systems should
go (and in some cases already attempt to go)
beyond the POS tagging or shallow syntactic
annotations, the following four are character-
ized in the present contribution: (i) predicate-
argument representation of the underlying syn-
tactic relations as basically corresponding to a
rooted tree that can be univocally linearized,
(ii) the inclusion of the information structure
using very simple means (the left-to-right or-
der of the nodes and three attribute values),
(iii) relating this underlying structure (render-
ing the ?linguistic meaning,? i.e. the semanti-
cally relevant counterparts of the grammatical
means of expression) to certain central aspects
of referential semantics (reference assignment
and coreferential relations), and (iv) handling
of word sense disambiguation. The first three
issues are documented in the present paper on
the basis of our experience with the devel-
opment of the structure and scenario of the
Prague Dependency Treebank which provides
for syntactico-semantic annotation of large text
segments from the Czech National Corpus and
which is based on a solid theoretical frame-
work.
1 Introduction1
It has been commonly accepted within the computational
linguistics community involved in corpus annotation that
part-of-speech tagging and shallow syntactic annotation
though very progressive, important and useful tasks at
their time, are only the first steps in a more ambitious
research program, aiming at a creation of advanced re-
sources for most different systems of natural language
processing and for testing and further enrichment of lin-
guistic and computational theories. On the basis of our
experience with the development and implementation of
the annotation scheme of the Prague Dependency Tree-
bank (PDT, (Hajic? et al, 2001a), (Bo?hmova?, 2004)), we
would like to indicate four directions, in which we be-
lieve the standard annotation systems should be (and in
some cases already attempt to be) extended to fulfill the
present expectations. We believe that we can offer useful
insights in three of these, namely
(i) an adequate and perspicuous way to represent the
underlying syntactic relations as basically corre-
sponding to a rooted tree that can be equivocally lin-
earized,
(ii) with the inclusion of the information structure us-
ing very simple means (the left-to-right order of the
nodes and two indexes), and
(iii) in relating this underlying structure (rendering the
?linguistic meaning,? i.e. the semantically relevant
counterparts of the grammatical means of expres-
sion) to certain central issues of referential seman-
tics (reference assignment and coreferential rela-
tions).
1The research reported on in this paper has been supported
by the project of the Czech Ministry of Education LN00A063,
and by the grants of the Grant Agency of the Czech Republic
No. 405/03/0913 and No. 405/03/0377.
These insights have been elaborated into annotation
guidelines which now are being used (and checked) on
the basis of PDT, i.e. of syntactico-semantic annotations
of large text segments from the Czech National Corpus,
which allows for a reliable confirmation of the adequacy
of the chosen theoretical framework and for its enrich-
ment in individual details. The fourth dimension we have
in mind is that of handling word-sense disambiguation,
for which the material of our annotated texts, the PDT,
serves as a starting point.
2 The Extensions
2.1 The Structure: Deep Dependency and Valency
The development of formal theories of grammar has doc-
umented that when going beyond the shallow grammat-
ical structure toward some kind of functional or seman-
tic structure, two notions become of fundamental impor-
tance: the notion of the head of the structure and the no-
tion of valency (i.e. of the requirements that the heads
impose on the structure they are heads of). To adduce
just some reflections of this tendency from American
linguistic scene, Fillmore?s ?case grammar? (with verb
frames) and his FrameNet ((Fillmore et al, 2003)), Bres-
nan?s and Kaplans?s lexical functional grammar (with
the distinction between the constituent and the functional
structure and with an interesting classification of func-
tions) and Starosta?s ?lexicase grammar? can serve as
the earliest examples. To put it in terms of formal syn-
tactic frameworks, the phrase structure models take on
at least some traits of the dependency models of lan-
guage; Robinson has shown that even though Fillmore
leaves the issue of formal representation open, the phrase-
structure based sentence structure he proposes can be eas-
ily and adequately transposed in terms of dependency
grammar. Dependency account of sentence structure is
deeply rooted in European linguistic tradition and it is no
wonder then that formal descriptions originating in Eu-
rope are dependency-based (see Sgall, Kunze, Hellwig,
Hudson, Mel?chuk). We understand it as crucial to use
sentence representations ?deep? enough to be adequate as
an input to a procedure of semantic(-pragmatic) interpre-
tation (i.e. representing function words and endings by
indexes of node labels, restoring items which are deleted
in the morphemic or phonemic forms of sentences and
distinguishing tens of kinds of syntactic relations), rather
than to be satisfied with some kind of ?surface? syntax.
The above-mentioned development of formal frame-
works toward an inclusion of valency in some way or an-
other has found its reflection in the annotation scenarios
that aimed at going beyond the shallow structure of sen-
tences. An important support for annotation conceived in
this way can be found in schemes that are based on an
investigation of the subcategorization of lexical units that
function as heads of complex structures, see. Fillmore?s
FRAMENET, the PropBank as a further stage of the de-
velopment of the Penn Treebank (Palmer et al, 2001)
and Levin?s verb classes (Levin, 1993) on which the LCS
Database (Dorr, 2001) is based. There are other systems
working with some kind of ?deep syntactic? annotation,
e.g. the broadly conceived Italian project carried out in
Pisa (N. Calzolari, A. Zampolli) or the Taiwanese project
MARVS; another related framework is presented by the
German project NEGRA, basically surface oriented, with
which the newly produced subcorpus TIGER contains
more information on lexical semantics. Most work that
has already been carried out concerns subcategorization
frames (valency) of verbs but this restriction is not nec-
essary: not only verbs but also nouns or adjectives and
adverbs may have their ?frames? or ?grids?.
One of the first complex projects aimed at a deep (un-
derlying) syntactic annotation of a large corpus is the al-
ready mentioned Prague Dependency Treebank (Hajic?,
1998); it is designed as a complex annotation of Czech
texts (taken from the Czech National Corpus); the under-
lying syntactic dependency relations (called functors) are
captured in the tectogrammatical tree structures (TGTS);
see (Hajic?ova?, 2000). The set of functors comprises
53 valency types subclassified into (inner) participants
(arguments) and (free) modifications (adjuncts). Some
of the free modifications are further subcategorized into
more subtle classes (constituting mainly the underlying
counterparts, or meanings, of prepositions).
Each verb entry in the lexicon is assigned a valency
frame specifying which type of participant or modifi-
cation can be associated with the given verb; the va-
lency frame also specifies which participant/modification
is obligatory and which is optional with the given verb
entry (in the underlying representations of sentences),
which of them is deletable on the surface, which may or
must function as a controller, and so on. Also nouns and
adjectives have their valency frames.
The shape of TGTSs as well as the repertory and clas-
sification of the types of modifications of the verbs is
based on the theoretical framework of the Functional
Generative Description, developed by the Prague re-
search team of theoretical and computational linguis-
tics as an alternative to Chomskyan transformational
grammar (Sgall et al, 1986). The first two arguments,
though labeled by ?semantically descriptive? tags ACT
and PAT (Actor and Patient, respectively) correspond
to the first and the second argument of a verb (cf.
Tesnie`re?s (Tesnie`re, 1959) first and second actant), the
other three arguments of the verb being then differen-
tiated (in accordance with semantic considerations) as
ADDR(essee), ORIG(in) or EFF(ect); these five func-
tors belong to the set of participants (arguments) and
are distinguished from (free) modifications (adjuncts)
such as LOC(ative), several types of directional and tem-
poral (e.g. TWHEN) modifications, APP(urtenance),
R(e)STR(ictive attribute), DIFF(erence), PREC(eding
cotext referred to), etc. on the basis of two basic oper-
ational criteria (Panevova?, 1974), (Panevova?, 1994):
(i) can the given type of modification modify in princi-
ple every verb?
(ii) can the given type of modification occur in the
clause more than once?
If the answers to (i) and (ii) are yes, then the modifica-
tion is an adjunct, if not, then we face an argument.
We assume that the cognitive roles can be determined
on the basis of combinations of the functors with the lex-
ical meanings of individual verbs (or other words), e.g.
the Actor of buy is the buyer, that of sell is the seller, the
Addressee and the Patient of tell are the experiencer and
the object of the message, respectively.The valency dic-
tionary created for and used during the annotation of the
Prague Dependency Treebank, called PDT-VALLEX, is
described in (Hajic? et al, 2003). The relation between
function and (morphological) form as used in the valency
lexicon is described in (Hajic? and Ures?ova?, 2003).
An illustration of this framework is presented in Fig. 1.
#48
SENT
&Gen;
ADDR
jen?e
PREC
tuzemsk?
RSTR
v?robce
ACT
dodat
PRED
hlava
PAT
 
ty i
RSTR
den
DIFF
pozd
TWHEN
Figure 1: A simplified TGTS of the Czech sentence Jenz?e
tuzemsky? vy?robce dostal hlavy o c?tyr?i dny pozde?ji. ?How-
ever, the domestic producer got the heads four days later.?
Let us adduce further two examples in which the func-
tors are written in capitals in the otherwise strongly sim-
plified representations, where most of the adjuncts are un-
derstood as depending on nouns, whereas the other func-
tors concern the syntactic relations to the verb. Let us
note that with the verb arrive the above mentioned test
determines the Directional as a (semantically) obligatory
item that can be specified by the hearer according to the
given context (basically, as here or there):
(1) Jane changed her house from a shabby cottage into
a comfortable home.
(1?) Jane.ACT changed her.APP house.PAT
from-a-shabby.RSTR cottage.ORIG
into-a-comfortable.RSTR home.EFF.
(2) Yesterday Jim arrived by car.
(2?) Yesterday.TWHEN Jim.ACT arrived here.DIR3 by-
car.MEANS.
A formulation of an annotation scenario based on well-
specified subcategorization criteria helps to compare dif-
ferent schemes and to draw some conclusions from such
a comparison. In (Hajic?ova? and Kuc?erova?, 2002) the au-
thors attempt to investigate how different frameworks an-
notating some kind of deep (underlying) syntactic level
(the LCS Data, PropBank and PDT) compare with each
other (having in mind also a more practical applica-
tion, namely a machine translation project the modules
of which would be ?machine-learned?, using a procedure
based on syntactically annotated parallel corpora). We
are convinced that such a pilot study may also contribute
to the discussions on a possibility/impossibility of for-
mulating a ?theory neutral? syntactic annotation scheme.
The idea of a theory neutral annotation scenario seems
to be an unrealistic goal: it is hardly possible to imag-
ine a classification of such a complex subsystem of lan-
guage as the syntactic relations are, without a well mo-
tivated theoretical background; moreover, the languages
of the annotated texts are of different types, and the the-
oretical frameworks the authors of the schemes are used
to work with differ in the ?depth? or abstractness of the
classification of the syntactic relations. However, the dif-
ferent annotation schemes seem to be translatable if the
distinctions made in them are stated as explicitly as pos-
sible, with the use of operational criteria, and supported
by larger sentential contexts. The third condition is made
realistic by very large text corpora being available elec-
tronically; making the first two conditions a realistic goal
is fully in the hands of the designers of the schemes.
2.2 Topic/Focus Articulation
Another aspect of the sentence structure that has to be
taken into account when going beyond the shallow struc-
ture of sentences is the communicative function of the
sentence, reflected in its information structure. As has
been convincingly argued for during decades of linguistic
discussions (see studies by Rooth, Steedman, and several
others, and esp. the argumentation in (Hajic?ova? et al,
1998)), the information structure of the sentence (topic-
focus articulation, TFA in the sequel) is semantically rel-
evant and as such belongs to the semantic structure of the
sentence. A typical declarative sentence expresses that
its focus holds about its topic, and this articulation has
its consequences for the truth conditions, especially for
the differences between meaning proper, presuppositiona
and allegations (see (Hajic?ova?, 1993); (Hajic?ova? et al,
1998)).
TFA often is understood to constitute a level of its own,
but this is not necessary, and it would not be simple to de-
termine the relationships between this level and the other
layers of language structure. In the Functional Generative
Description (Sgall et al, 1986), TFA is captured as one of
the basic aspects of the underlying structure, namely as
the left-to-right dimension of the dependency tree, work-
ing with the basic opposition of contextual boundness;
the contextually bound (CB) nodes stand to the left of the
non-bound (NB) nodes, with the verb as the root of the
tree being either contextually bound or non-bound.
It should be noted that the opposition of NB/CB is the
linguistically patterned counterpart of the cognitive (and
pre-systemic) opposition of ?given? and ?new? informa-
tion. Thus, e.g. in (3) the pronoun him (being NB), in
fact constitutes the focus of the sentence.
(3) (We met a young pair.) My older companion recog-
nized only HIM.
In the prototypical case, NB items belong to the focus
of the sentence, and CB ones constitute its topic; sec-
ondary cases concern items which are embedded more
deeply than to depend on the main verb of the sentence,
cf. the position of older in (3), which may be understood
as NB, although it belongs to the topic (being an adjunct
of the CB noun companion).
In the tectogrammatical structures of the PDT anno-
tation scenario, we work with three values of the TFA
attribute, namely t (contextually bound node), c (contex-
tually bound contrastive node) and f (contextually non-
bound node). 20,000 sentences of the PDT have al-
ready been annotated in this way, and the consistency and
agreement of the annotators is being evaluated. It seems
to be a doable task to annotate and check the whole set of
TGTSs (i.e. 55,000 sentences) by the end of 2004. This
means that by that time the whole set of 55,000 sentences
will be annotated (and checked for consistency) on both
aspects of deep syntactic structure. An algorithm the in-
put of which are the TGTSs with their TFA values and
the output of which is the division of the whole sentence
structure into the (global) topic and the (global) focus is
being formulated.
2.3 Coreference
The inclusion into the annotation scheme of the two as-
pects mentioned above in Sect. 2.1 and 2.2, namely the
deep syntactic relations and topic-focus articulation, con-
siderably extends the scenario in a desirable way, toward
a more complex representation of the meaning of the sen-
tence. The third aspect, the account of coreferential rela-
tions, goes beyond linguistic meaning proper toward what
can be called the sense of the utterance (Sgall, 1994).
Two kinds of coreferential relations have to be distin-
guished: grammatical coreference (i.e. with verbs of con-
trol, with reflexive pronouns, with verbal complements
and with relative pronouns) and textual (which may cross
sentence boundaries), both endophoric and exophoric.
Several annotation schemes have been reported at re-
cent conferences (ACL, LREC) that attempt at a rep-
resentation of coreference relations in continuous texts.
As an example of an attempt to integrate the treatment
of anaphora into a complex deep syntactic scenario, we
would like to present here a brief sketch of the scheme
realized in the Prague Dependency Treebank. For the
time being, we are concerned with coreference relations
in their narrower sense, i.e. not covering the so-called
bridging anaphora (for a possibility to cover also the lat-
ter phenomenon, see (Bo?hmova?, 2004)).
In the Prague Dependency Treebank, coreference is
understood as an asymmetrical binary relation between
nodes of a TGTS (not necessarily the same TGTS), or,
as the case may be, as a relation between a node and
an entity that has no corresponding counterpart in the
TGTS(s). The node from which the coreferential link
leads, is called an anaphor, and the node, to which the
link leads, is called an antecedent.
The present scenario of the PDT provides three coref-
erential attributes: coref, cortype and corlemma. The at-
tribute coref contains the identifier of the antecedent; if
there are more than one antecedents of one anaphor, the
attribute coref includes a sequence of identifiers of the
relevant antecedents; since every node of a TGTS has an
identifier of its own it is a simple programming task to
select the specific information on the antecedent. The at-
tribute cortype includes the information on the type of
coreference (the possible values are gram for grammat-
ical and text for textual coreference), or a sequence of
the types of coreference, where each element of cortype
corresponds to an element of coref. The attribute cor-
lemma is used for cases of a coreference between a node
and an entity that has no corresponding counterpart in the
TGTS(s): for the time being, there are two possible val-
ues of this attribute, namely segm in the case of a coref-
erential link to a whole segment of the preceding text (not
just a sentence), and exoph in the case of an exophoric
relation. Cases of reference difficult to be identified even
if the situation is taken into account are marked by the
assignment of unsp as the lemma of the anaphor. This
does not mean that a decision is to be made between two
or more referents but that the reference cannot be fully
specified even within a broader context.
In order to facilitate the task of the annotators and
to make the resulting structures more transparent and
telling, the coreference relations are captured by arrows
leading from the anaphor to the antecedent and the types
of coreference are distinguished by different colors of the
arrows. There are certain notational devices used in cases
when the antecedent is not within the co-text (exophoric
coreference) or when the link should lead to a whole seg-
ment rather than to a particular node. If the anaphor
corefers to more than a single node or to a subtree, the
link leads to the closest preceding coreferring node (sub-
tree). If there is a possibility to choose between a link to
an antecedent or to a postcedent, the link always leads to
the antecedent.
#51
SENT
&Gen;
ACT
n jak?
RSTR
zem
ACT
usn?st_se
COND
?stavn?
RSTR
z?kon
PAT
pak
TWHEN
ten
PAT
t ?ko
MANN
m nit
PRED
Figure 2: A TGTS of the sentence Pokud se ne?jaka? zeme?
usnese na u?stavn??m za?konu, pak se to te?z?ko me?n??. ?If a
country accepts a constitution law, then this is difficult to
change.?
The manual annotation is made user-friendly by a spe-
cial module within the TRED editor (Hajic? et al, 2001b)
which is being used for all three subareas of annotation.
In the case of coreference, an automatic pre-selection of
nodes relevant for annotation is used, making the process
faster.
Until now, about 30,000 sentences have been annotated
as for the above types of coreference relations. One of the
advantages of a corpus-based study of a language phe-
nomenon is that the researchers become aware of sub-
tleties and nuances that are not apparent. For those who
attempt at a corpus annotation, of course, it is necessary
to collect a list of open questions which have a temporary
solution but which should be studied more intensively
and to a greater detail in the future.
Another issue the study of which is significant and
can be facilitated by an availability of a semantically an-
notated corpus, is the question of a (finite) mechanism
the listener (reader) can use to identify the referents. If
the backbone of such a mechanism is seen in the hierar-
chy (partial ordering) of salience, then it can be under-
stood that this hierarchy typically is modified by the flow
of discourse in a way that was specified and illustrated
by (Hajic?ova?, 1993), (Hajic?ova? et al, in prep). In the
flow of a discourse, prototypically, a new discourse ref-
erent emerges as corresponding to a lexical occurrence
that carries f; further occurrences carry t or c, their ref-
erents being primarily determined by their degrees of
salience, although the difference between the lowest de-
grees of salience reduction, is not decisive. It appears to
be possible to capture at least certain aspects of this hi-
erarchy by some (still tentative) heuristic rules, which tie
up the increase/decrease of salience with the position of
the given item in the topic or in the focus of the given ut-
terance. It should also be remarked that there are certain
permanently salient referents, which may be referred to
by items in topic (as ?given? information) without having
a referentially identical antecedent in the discourse. We
denote them as carrying t or c, but perhaps it would be
more adequate to consider them as being always able to
be accommodated
(i) by the utterance itself, as especially the indexicals
(I, you, here, now, yesterday,. . . ),
(ii) by the given culture (democracy, Paris, Shake-
speare, don Quijote,. . . ), by universal human expe-
rience (sun, sky), or
(iii) by the general domain concerned (history, biol-
ogy,...).
Since every node in the PDT carries one of the TFA
values (t, c or f) from which the appurtenance of the
given item to the topic or focus of the whole sentence
can be determined, it will be possible to use the PDT
data and the above heuristics to start experiments with
an automatic assignment of coreferential relations and
check them against the data with the manual annotation
of coreference.
2.4 Lexical Semantics
The design of the tectogrammatical representation is such
that the nodes in the tectogrammatical tree structure rep-
resent (almost) only the autosemantic words found in the
written or spoken utterance they represent. We believe
that it is thus natural to start distinguishing word senses
only at this level (and not on a lower level, such as surface
syntax or linearized text).
Moreover, there is a close relation between valency
and word senses. We hypothesize that with a suitable
set of dependency relations (both inner participants and
free modifications, see Sect. 2.1), there is only one va-
lency frame per word sense (even though synonyms or
near synonyms might have different valency frames). The
opposite is not true: there can be several word senses with
an identical valency frame.
Although in the detailed valency lexicon VALLEX
(Lopatkova?, 2003), (Lopatkova? et al, 2003) an attempt
has originally been made to link the valency frames to
(Czech) EuroWordNet (Pala and ?Sevec?ek, 1999) senses
to prove this point, this has been abandoned for the time
being because of the idiosyncrasies in WordNet design,
which does not allow to do so properly.
We thus proceed independently with word sense an-
notation based on the Czech version of WordNet. Cur-
rently, we have annotated 10,000 sentences with word
senses, both nouns and verbs. We are assessing now fur-
ther directions in annotation; due to low inter-annotator
agreement, we will probably tend to annotate only over a
preselected subset of the WordNet synsets. An approach
to building semantic lexicons that is more related to our
concept of meaning representation is being prepared in
the meantime (Holub and Stran?a?k, 2003).
3 Conclusions
Up to now, the framework has been checked on a large
amount of running text segments from the Czech Na-
tional Corpus (as for the valency classification 55,000 ut-
terances, as for the topic-focus structure 20,000 ones). In
several cases, it was found that a more detailed classifi-
cation is needed (e.g. with the differentiation of the Gen-
eral Actor vs. Unspecified, cf. the difference between
One can cook well with this oven and At this pub they
cook well). However, it has been confirmed that good
results can be achieved with the chosen classification of
about 40 valency types and of 15 other grammatical at-
tribute types (such as (Semantic) Number, Tense, Modal-
ities, etc., but also different values of Location, such as
those corresponding to the preferred functions of in, at,
on, under, over, etc., or of Benefactive (positive vs. neg-
ative), and so on). It can be supposed that the core of
language corresponds to underlying sentence structures
and to their unmarked morphemic and phonemic coun-
terparts. The marked layers have to be described by spe-
cific sets of rules, most of which concern irregularities
of morphemics, including differences between the under-
lying order of nodes and the surface (morphemic) word
order, especially in cases in which the latter does not di-
rectly meet the condition of projectivity (with no cross-
ing of edges, cf. the discontinuous constituents of other
frameworks).
The prototypical varieties of sentence structure can
thus be characterized by projective rooted trees, which
points to the possibility to describe the core of language
structure on the basis of a maximally perspicuous pat-
tern that comes close to patterns present in other domains
(primitive logic, arithmetics, and so on) which are nor-
mally mastered by children. Structures of this kind are
not only appropriate for computer implementation, but
they also help understand the relative easiness of mas-
tering the mother tongue, without a necessity to assume
complex innate mechanisms specific for the language fac-
ulty.
References
Alena Bo?hmova?. 2004. Automatized Procedures in
the Process of Annotation of PDT. Ph.D. the-
sis, Charles University, Faculty of Mathemartics and
Physics, Prague.
Bonnie Dorr. 2001. The LCS Database.
http://www.umiacs.umd.edu/ ?bonnie/
LCS Database Documentation.html.
Charles J. Fillmore, Christopher R. Robinson, and
Miriam R. L. Petruck. 2003. Background to
FrameNet. International Journal of Lexicography,
16:235?250.
Eva Hajic?ova? and Ivona Kuc?erova?. 2002. Argu-
ment/valency structure in PropBank, LCS database and
Prague Dependency Treebank: A comparative study.
In Proceedings of LREC.
Jan Hajic? and Zden?ka Ures?ova?. 2003. Linguistic Anno-
tation: from Links to Cross-Layer Lexicons. In Pro-
ceedings of The Second Workshop on Treebanks and
Linguistic Theories, volume 9 of Mathematical Mod-
eling in Physics, Engineering and Cognitive Sciences,
pages 69?80. Va?xjo? University Press, November 14?
15, 2003.
Jan Hajic?, Eva Hajic?ova?, Petr Pajas, Jarmila Panevova?,
Petr Sgall, and Barbora Vidova?-Hladka?. 2001a.
Prague Dependency Treebank 1.0 (Final Production
Label). CDROM CAT: LDC2001T10, ISBN 1-58563-
212-0.
Jan Hajic?, Petr Pajas, and Barbora Hladka?. 2001b.
The Prague Dependency Treebank: Annotation Struc-
ture and Support. In IRCS Workshop on Linguistic
Databases, pages 105?114, Philadelphia, PA, Dec. 11?
13.
Jan Hajic?, Alevtina Be?mova?, Petr Pajas, Jarmila
Panevova?, Veronika ?Rezn??c?kova?, and Zden?ka Ures?ova?.
2003. PDT-VALLEX: Creating a Large-coverage Va-
lency Lexicon for Treebank Annotation. In Joakim
Nivre and Erhard Hinrichs, editors, 2nd International
Workshop on Treebanks and Linguistic Theories, vol-
ume 9 of Mathematical Modeling in Physics, Engi-
neering and Cognitive Sciences, pages 57?68. Va?xjo?
University Press, Va?xjo?, Sweden, Nov. 14?15, 2003.
Jan Hajic?. 1998. Building a Syntactically Anno-
tated Corpus: The Prague Dependency Treebank. In
Eva Hajic?ova?, editor, Issues of Valency and Meaning.
Studies in Honor of Jarmila Panevova?, pages 12?19.
Prague Karolinum, Charles University Press.
Eva Hajic?ova?, Barbara Partee, and Petr Sgall. 1998.
Topic-focus articulation, tripartite structures, and se-
mantic content. Kluwer Academic Publishers, Ams-
terdam, Netherlands.
Eva Hajic?ova?, Jir??? Havelka, and Petr Sgall. in prep.
Topic and Focus, Anaphoric Relations and Degrees of
Salience. In Prague Linguistic Circle Papers 5. Ams-
terdam/Philadelphia: John Benjamins.
Eva Hajic?ova?. 1993. Issues of Sentence Structure and
Discourse. Charles University, Prague, Czech Repub-
lic.
Eva Hajic?ova?. 2000. Dependency-Based Underlying-
Structure Tagging of a Very Large Czech Corpus.
In Special issue of TAL journal, Grammaires de
De?pendence / Dependency Grammars (ed. Sylvian Ka-
hane), pages 57?78. Hermes.
Martin Holub and Pavel Stran?a?k. 2003. Approaches to
building semantic lexicons. In WDS?03 Proceedings
of Contributed Papers, Part I, pages 173?178, Prague.
MATFYZPRESS, Charles University.
Beth Levin. 1993. English Verb Classes and Alterna-
tions: A Preliminary Investigation. The University of
Chicago Press.
Marke?ta Lopatkova?, Zdene?k ?Zabokrtsky?, Karol??na
Skwarska, and Va?clava Benes?ova?. 2003. VALLEX
1.0. http://ckl.mff.cuni.cz/zabokrtsky/
vallex/1.0.
Marke?ta Lopatkova?. 2003. Valency in the Prague De-
pendency Treebank: Building the Valency Lexicon.
Prague Bulletin of Mathematical Linguistics, 79?80:in
print.
Karel Pala and Pavel ?Sevec?ek. 1999. Czech
wordnet. http://www.fi.muni.cz/nlp/grants/
ewn cz.ps.en.
Martha Palmer, J Rosenzweig, and S Cotton. 2001.
Automatic Predicate Argument Analysis of the Penn
TreeBank. In J Allan, editor, Processdings of HLT
2001, First Int. Conference on Human Technology Re-
search. Morgan Kaufmann, San Francisco.
Jarmila Panevova?. 1974. On verbal Frames in Functional
Generative Description. Prague Bulletin of Mathemat-
ical Linguistics, 22:3?40.
Jarmila Panevova?. 1994. Valency Frames and the Mean-
ing of the Sentence. In Philip Luelsdorff, editor, The
Prague School of Structural and Functional Linguis-
tics, pages 223?243. John Benjamins, Amsterdam-
Philadephia.
Petr Sgall, Eva Hajic?ova?, and Jarmila Panevova?. 1986.
The meaning of the sentence and its semantic and
pragmatic aspects. Reidel, Dordrecht.
Petr Sgall. 1994. Meaning, Reference and Discourse Pat-
terns. In Philip Luelsdorff, editor, The Prague School
of Structural and Functional Linguistics, pages 277?
309. John Benjamins, Amsterdam-Philadephia.
Lucien Tesnie`re. 1959. ?Elements de Syntaxe Structurale.
Klincksieck, Paris.
