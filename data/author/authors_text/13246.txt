Coling 2010: Demonstration Volume, pages 53?56,
Beijing, August 2010
HowNet and Its Computation of Meaning 
Zhendong Dong 
Research Center of Computer 
& Language Engineering, CAS 
dzd@keenage.com 
Qiang Dong 
Canada Keentime Inc. 
dongqiang@keenage.com 
Changling Hao 
Canada Keentime Inc. 
support@keenage.com 
 
Abstract 
The presentation will mainly cover (1) 
What is HowNet? HowNet is an on-line 
common-sense knowledgebase unveiling 
inter-conceptual relationships and inter-
attribute relationships of concepts as 
connoting in lexicons of the Chinese and 
their English equivalents. (2) How it 
functions in the computation of meaning 
and as a NLP platform? The presentation 
will show 9 HowNet-based application 
tools. All of them are not merely demon-
stration of some methodology or algo-
rithm, but are real application tools that 
can be tested by users themselves. Apart 
from the tools that are specially designed 
to deal with Chinese, most of the tools 
are bilingual, even the WSD tool. 
1  What is HowNet 
HowNet is an on-line common-sense knowled-
gebase unveiling inter-conceptual relationships 
and inter-attribute relationships of concepts as 
connoting in lexicons of the Chinese and their 
English equivalents. To put it simply, relation-
ship is the soul of HowNet, as well as the world 
knowledge. The relationships that represent 
knowledge can be divided into two categories: 
Concept Relationship (CR) and Attribute Rela-
tionship (AR). 
It is believed that concept relationships fall in-
to a net, which is called Concept Relation Net 
(CRN) and attribute relationships fall into a net 
too, called Attribute Relation Net (ARN). Dif-
ferent individual has different CRN, even of the 
same concept. This reflects different levels of 
knowledge among people. CRN is elastic or ex-
tendable as it varies with individual persons. The 
more knowledge one has, the more concepts he 
will master, and what is more, the larger or more 
complicated CRN of the concepts he will know. 
It can be imagined that a 6-year child may know 
?doctor? but his CRN of ?doctor? would be far 
from that as shown in Fig. 1, which is believed 
to be mastered by an ordinary adult. The same 
case goes with mankind as a whole. Mankind 
increases his knowledge with each passing year 
when he enlarges his volume of concepts and at 
the same time, the CRN of the concepts. 
Careful observations find that the meaning of 
concepts is displayed not only by its CRN but 
also by the relationships among attributes of the 
concepts, as called Attribute Relation Net. In 
many cases it is the attributes of a concept that 
act in the role of meaning representation. Fig. 2 
reveals that it is not ?paper? as a whole that is 
related to ?write?, but only one of its attributes, 
say ?color?, is related to ?write? with ?contrast? 
as the condition. Therefore in a strict sense, ?pa-
per? is not necessarily related to ?write?. We can 
sometimes even write on the sand with a twig or 
on the table with our wet finger. On the contrary, 
we cannot write on a piece of white paper with a 
chalk or on the blackboard in black ink. There-
fore, for writing, what affects may not be the 
whole lot of the concept like ?paper?, but some 
attributes of the concept. Besides, we can use 
?paper? to wrap up something because of its 
attributes of the material, which are almost the 
same as cloth or plastic. HowNet is unique in its 
four peculiarities: (1) Use of sememes: HowNet 
uses sememes to interpret concepts. Sememes 
are regarded as the basic unit of the meaning. (2) 
Definition in a structuralized language: Each 
concept in HowNet lexicon is defined in a lan-
guage, called Knowledge Database Markup 
Language (KDML). The KDML is mainly com-
posed of sememes and semantic roles. The  
53
 Figure 1 Concept Relation Net (CRN) of ?doctor? 
 
 
Figure 2 Attribute Relation Net (ARN) of ?paper? 
 
Knowledge Database Mark-up Language uses 
2089 sememes, 128 secondary features and 94 
semantic roles as its vocabulary and adopts an 
extended BNF as its syntax. The concept of 
?doctor (medical)? is defined in HowNet as:   
DEF={human|?:HostOf={Occupation|??}, 
condition 
value value value value 
material material instrument 
patient 
instrument 
attribute attribute attribute attribute 
paper 
color thickness hardness 
white thin flammable soft 
write 
contrast 
shopping bag 
make burn 
flammableness 
54
domain={medical|?},{doctor|??:agent={~}}} 
All the computation of meaning in HowNet 
is based on the definitions of the concepts.  
(3) Self-sufficiency: Systematic integration 
of hierarchical taxonomies, axiomatic inference, 
KDML-defined concepts. 
(4) Language independence: In the final 
analysis, HowNet is not word-oriented as 
WordNet, but concept-oriented. Only with the 
HowNet?s shared definitions can we achieve a 
shared ontology for all languages. 
Table 1 shows the latest statistics of the basic 
data of HowNet. 
 
Chinese Character 7182 
Chinese Word & Expression 100385 
English Word & Expression 96565 
Chinese Meaning 115278 
English Meaning 121262 
Definition 30014 
Record 192191 
Semantics Chinese English 
Event 14554 12881 
Attribute 4351 4879 
AttributeValue 10160 10140 
Things 72016 72016 
Time 2683 2683 
Space 1244 1244 
Component 8577 8577 
Table 1 statistics of the basic data of HowNet 
2 HowNet functions as a NLP platform 
HowNet is developing toward a NLP platform. 
HowNet is a powerful tool for the computation 
of meaning. To date, 9 HowNet-based applica-
tion tools have been developed. They are: 
1. HowNet_Browser (E/C bilingual) 
2. HowNet_Relevance (E/C bilingual) 
3. HowNet_Similarity (E/C bilingual) 
4. HowNet_Inference_Pool (E/C bilingual) 
5. HowNet_SenseColonyTester (E/C bilin-
gual) 
6. HowNet_Translate (E-to-C) 
7.HowNet_Morpho_Processor (Chinese mo-
nolingual) 
8. HowNet_VN ? disambiguator for Chinese 
V-N structure (Chinese monolingual) 
9. HowNet_VXY -- disambiguator for Chi-
nese V-N-?-N structure  (Chinese monolingual) 
The purpose for developing these tools is (1) 
to check the HowNet?s data and framework for 
its accuracy and coverage so as to test the 
soundness of its philosophy and design; (2) to 
push HowNet near to end applications so as to 
provide evidence of its value as knowledge re-
sources; 
Of all these tools, HowNet Browser is the 
key. The Browser contains all HowNet basic 
data and provides various kinds of elementary 
or shallow computation of meanings. The basic 
data in HowNet can be divided into two parts: 
firstly, the basic lexical data and secondly tax-
onomies. In the lexical database, each concept 
is described in a fixed structure, for example, 
 
NO.=046048 
W_C=? 
G_C=adj [fu4] 
S_C=PlusSentiment|???? 
E_C=~??~??~??~????~????
???~?~??~????~?????~? 
W_E=rich 
G_E=adj  
S_E=PlusSentiment|???? 
E_E= 
DEF={rich|?} 
RMK= 
 
With the browser the user can retrieve all 
kinds of basic relations between concepts, such 
as synonym, hypernym, hyponym, etc. It should 
be noticed that these kinds of relations in How-
Net are not coded manually as the way as done 
in WordNet, but are computed on the basis of 
concept definitions. The browser can give all 
sorts of semantic roles for a given verb concept. 
To take ?treat? as a given event, we retrieve all 
its ?agents?, ?locations?, ?patients?, ?instru-
ments?. This is regarded as the shallow rela-
tions between verb concepts and their relevant 
noun concepts. 
Particular attention should be given to our 
newly developed tool, HowNet Inference Pool 
(E/C bilingual). With the help of an activator of 
the tool we can build a senses pool for any con-
cept in HowNet. The pool covers all sorts of 
relationships under the key concept, for instance, 
when the concept of ?money? as the key, it has 
a pool with 2600 concepts, including ?bank?, 
?deposit?, ?borrow?, ?buy?, ?steal?, etc. Hence 
55
suppose a question like ?can we borrow money 
from a bank?? is raised to an inference machine, 
we are sure that the machine can give a correct 
answer with correct selection of meanings, like 
?bank? as ?financial bank?. Moreover based on 
the inference machine we have developed a 
word sense disambiguation tool called HowNet 
SenseColony Tester (E/C bilingual). The tool is 
designed to be skilled in tackling the ambiguity 
of discourse type both in Chinese and English. 
The words ?governor?, ?state? in the following 
paragraph are so-called those of discourse-
ambiguity type: 
?We provided $250 in relief to more than 5 
million California seniors -- many whose life 
savings had taken a big hit in the financial crisis. 
And we provided emergency assistance to our 
governors to prevent teachers and police 
officers and firefighters from being laid off as a 
result of state budget shortfalls. At a time when 
California is facing a fiscal crisis, we know that 
this has saved the jobs of tens of thousands of 
educators and other needed public servants just 
in this state. And what was true in California 
was true all across the country.? 
The tool is language independent; it employs 
the data resources and the algorithm of the same 
type. 
HowNet English-Chinese MT system is a 
rule-based system. It uses HowNet basic data as 
its English-Chinese bilingual dictionary. It is 
powerful in its strongly semantic basis. The sys-
tem will surely have a bright future in its appli-
cation to PDA products and Chinese language 
learning aids. 
All the HowNet tools are not merely a demo 
of certain methodology, but are real applica-
tions that can be tested by users themselves. 
References 
Keh-Jiann Chen, Shu-Ling Huang, Yueh-Yin Shih, 
Yi-Jun Chen, 2005, Extended-HowNet: A Repre-
sentational Framework for concepts, Proceedings 
of Second International Joint Conference 2005 
Keh-Jiann Chen, 2009, E-HowNet- a Lexical Se-
mantic Representation System and its Relation to 
Morphology, Syntax and Semantics, (keynote talk, 
at ROCLING XXI 2009) 
Zhendong Dong and Qiang Dong, 2006. HowNet 
and the Computation of Meaning, World Scientif-
ic Publishing Co. Pte. Ltd., Singapore 
Fellbaum, 1998, WordNet: An Electronic Lexical 
Datbase. Ed. Cristiane Fellbaum, The MIT Press, 
Cambridge, London, England, 1998. 
Nagao, Makoto, 1997 Machine Translation Through 
Language Understanding, MT Summit VI Pro-
ceedings 
Yarowsky, D. (1993) One sense per collocation. In 
Proceedings, ARPA Human Language Technolo-
gy Workshop, pp. 266-271. 
???, ??, 2001, ???????, ?????, 
???, ?1?, pp.33-44 
???, 2001, ???????, ??, ?????. 
56
Word Segmentation needs change 
? From a linguist?s view 
Zhendong Dong 
Research Center of Computer 
& Language Engineering, CAS 
dzd@keenage.com 
Qiang Dong 
Canada Keentime Inc. 
dongqiang@keenage.com
Changling Hao 
Canada Keentime Inc. 
support@keenage.com
 
Abstract 
The authors propose that we need some 
change for the current technology in 
Chinese word segmentation. We should 
have separate and different phases in the 
so-called segmentation. First of all, we 
need to limit segmentation only to the 
segmentation of Chinese characters in-
stead of the so-called Chinese words. In 
character segmentation, we will extract 
all the information of each character. 
Then we start a phase called Chinese 
morphological processing (CMP). The 
first step of CMP is to do a combination 
of the separate characters and is then fol-
lowed by post-segmentation processing, 
including all sorts of repetitive structures, 
Chinese-style abbreviations, recognition 
of pseudo-OOVs and their processing, 
etc. The most part of post-segmentation 
processing may have to be done by some 
rule-based sub-routines, thus we need 
change the current corpus-based meth-
odology by merging with rule-based 
technique. 
1 Introduction 
Chinese word segmentation seems to be an old 
grandma?s story. We very often hear some con-
tradictory remarks about its advance. Most of 
reports from the evaluation tasks always gave us 
positive, or even impressive results, such as over 
96% accuracy, but some reports were rather 
negative and expressed their deep concern. They 
claimed that word segmentation was still entan-
gled in a difficult situation and no breakthrough 
in real applications. By careful and longtime ob-
servation, the incompetence is usually caused by 
the coarseness in the currently prevalent tech-
nology. 
We carefully observed some Chinese-English 
MT systems and found some errors were caused 
even in the very early stage of the processing, 
that is, in the stage of word segmentation. No 
matter the MT is statistics-based or rule-based, 
they have their Achilles' heel in the segmenta-
tion stage. Can today?s prevalent technology 
effectively cope with the problem? Or do we 
need some change? The present technology is 
characterized by its ?trilogy?, that is, ?corpora + 
statistics (ML) + evaluation?. We regret to say 
that many researchers today may be indulged in 
methodology itself rather than the language they 
have to target. They are enchanted by the scores 
and ranks, but they forget the object they are 
processing. 
Therefore we propose that a Chinese morpho-
logical processing (CMP) should be taken to 
replace the current Chinese word segmentation. 
CMP includes the following components: 
? Chinese character processing (CCP) 
? Initial combination of Chinese multi-
character expressions (CMEs) 
? Morphological structure processing 
(MSP) 
2 Chinese character processing 
2.1 ?Word? in Chinese 
?Word or no word? may be an even older story 
in Chinese linguistic circle. One assertion about 
Chinese words may be quite popular, even to 
most of western researchers in the NLP circle, 
that is, different from English or other western 
languages, there is no space between Chinese 
words and thus segmentation of a running text 
into words is necessary for Chinese processing. 
However, do words really exist in Chinese? It is 
still a vexing and controversial issue. Some 
Chinese grammarians argue that in Chinese there 
are no words at all, but there are only characters 
instead and some express their strong objection. 
What is a Chinese ?word?? It was reported 
that the concept of ?word? had not been intro-
duced into China until the very beginning of the 
last century. In fact word is alien to Chinese. At 
least the concept of word in Chinese is rather 
vague. In Chinese there are no clear-cut distinc-
tion between characters and so-called word, ei-
ther between multi-character words and those 
that are similar to English MWE. Ordinary Eng-
lish people may be surprised if they are told that 
even in popular Chinese dictionaries there are no 
entries equivalent to English ?pork (??)?, 
?beef ??)?, ?egg (??)?, ?rain (verb ??)?, 
?snow (verb ??)?, but there are entries equiva-
lent to English ?lower limbs(??)?, ?give or-
ders (??)?, ?appendicitis (???)?. There is 
somewhat arbitrariness in recognition of Chinese 
?words?, so the vocabulary in different Chinese 
dictionaries may vary very greatly. Does a dic-
tionary take usage frequency into account when 
it decides on its entries? Let?s compare their oc-
currence with the following entries in the dic-
tionary as shown in Table 1. Let?s compare the 
occurrence with the following entries in different 
dictionaries and in reference to Google?s results. 
In Table 1, ?-? indicates that the entry does not 
occur and ?+? indicates the entry occurs. 
 
Entries 3 Popular dictionaries Results in 
Google 
?? -  ??1 
- ??  2
- ?????  3
32,500,000 
?? -  ?? 
+ ??   
- ?????   
24,300,000 
?? -  ?? 
+??  
- ?????   
16,600,000 
                                                 
1 Modern Chinese Dictionary 
2 Modern Chinese Standard Dictionary 
3 New Age Chinese-English Dictionary 
?? +  ?? 
- ??   
+ ?????   
6,760,000 
??   +  ?? 
+ ??   
+ ?????   
497,000 
?? -  ?? 
+ ??   
+ ?????   
409,000 
??   +  ?? 
+ ??   
+ ?????   
900,000 
Table 1. Comparison of entry occurrence in 
dictionaries 
 
In a word, since ?word? in Chinese is rather 
vague, what is a better tactics we should take 
then? The present word segmentation is bur-
dened too heavily. In comparison with English 
tokenization, it goes too far. Does English to-
kenization deal with MWEs, such as ?United 
nations?, ?free of charge?, ?first lady?? Why 
does Chinese word segmentation have to deal 
with Chinese multi-character ?word?? 
2.2 Chinese character processing (CCP) 
We propose that the real task of so-called Chi-
nese word segmentation is to segment a running 
text into single characters with spaces between. 
We call this processing Chinese character proc-
essing (CCP). CCP is in parallel with English 
tokenization. In most cases CCP can achieve 
100% accuracy. The most important task for 
CCP is not only to segment a text, but also to 
obtain various kinds of information (syntactic, 
semantic) of every character. What will be fol-
lowed depends on the tasks to be designated. 
Usually a demand-led morphological processing 
will be taken. 
3 Initial combination 
In most cases, what we called initial combina-
tion of Chinese multi-character expressions 
(CMEs) should be followed indispensably. It 
may be either shallow or deep, and may be done 
either with the help of a lexical database or a 
corpus, and the longest matching may be the 
frequently-used technique.   
4 Morphological structure processing 
(MSP) 
4.1 Pseudo-OOVs 
The first task of MSP is to recognize and process 
Chinese OOVs. What are OOVs in English? 
Normally if a string between two spaces in a 
running text does not exist in the lexical 
database or the corpus the processing system is 
using, this string is taken as an OOV. However, 
what is an OOV in Chinese then? It is really not 
so easy to define an OOV in Chinese as in 
English. The recognition of English OOVs may 
be done in the phase of tokenization, but the 
recognition of Chinese OOVs should, in a strict 
sense, not be done in so-called word 
segmentation. It should be regarded as a special 
phase of the morphological processing. It is 
commonly acknowledged that OOV recognition 
is the most serious factor that impairs the 
performance of current Chinese word 
segmentation.  
We may first look at some instances of ma-
chine translation results and find the actual prob-
lems. The reason why we use MT systems to test 
and evaluate segmentation is because this will 
make it explicit and easy for human to assess. 
One error in segmentation makes a 100% failure 
in translation. In our examples, the translation (a) 
is done by a statistical MT system and the trans-
lation (b) by a rule-based MT system. (C) is hu-
man translation, which may help make compari-
son and find the errors made by MT. 
 
1. ?????????? 2020????? 
(a) Americans even behind the bid to host 
the 2020 Olympic Games in Nanjing. 
(b) American people's strength holds out 
in Nanjing and bids for the 2020 Olympic 
Games. 
(c) Americans fully backed up Nanjing?s 
bid to host the 2020 Olympic Games. 
 
Chinese OOVs can be roughly categorized 
into two classes, one is true OOVs and the other 
is pseudo-OOVs. The recognition and process-
ing of true OOVs can be done as English OOVs 
are treated in English.  However, the recognition 
and processing of Chinese pseudo-OOVs should 
be done by a special processing module. Chinese 
pseudo-OOVs includes two types: plain pseudo-
OOVs, such as ????, ????, ????, ????, 
????, ????, and abbreviated pseudo-OOVs, 
such as ????, ????, ????, ????, ???
???, ?????, ?????, ?????, ???
??, ?????, ??????. 
? Plain pseudo-OOVs 
A pseudo-OOV is a combinatory string of 
Chinese characters in which each character car-
ries one of its original meanings and the way of 
combination conforms to Chinese grammatical 
pattern. In the above Chinese sentence the word 
???? is a typical pseudo-OOV. ???? is a 
combination of two characters, ??? and ???. 
??? has four meanings, one of which is ?do 
one?s best?. ??? has six meanings, one of which 
is ?back up?. Originally in Chinese dictionaries 
we can find the following expressions similar to 
the pattern of ????, such as ????, ????, 
????, ????, ????, ????, ????, ??
??, ????, ????, ????, ????. In all 
these expressions the character ??? carries the 
same meaning as that in ????, and the second 
characters in the combinations are all actions. 
Therefore the expression ???? is a grammati-
cal and meaningful pseudo-OOV. It should be 
noticed that this kind of pseudo-OOV is highly 
productive in Chinese. In addition to all the dic-
tionary entries that we listed above, we found 
???(to strongly state)?and ???(to strongly 
resist)? are already used in the web. Its highly 
occurrence in real texts calls our special atten-
tion. Let?s see how MT will tackle them poorly. 
 
2. ?????????? 
(a) Chen multiple defense of human 
doubt. 
(b) Many old doubtful points of the man-
power of pleading. 
(c) The pleader argued and showed many 
doubtful points. 
We wonder how the current technique of 
segmentation tackles the problem. We are not 
sure how one error in a segmentation effect the 
score in Bakeoff.  
Let?s look at two more examples and have a 
brief discussion of them. 
 
3.?????????????????
??????????? 
(a) According to neighbors reflected the 
incident that day at noon there is a fast food 
take-Lang came to the victim's home.  
(b) According to the information of 
neighbour's, a fast food takes out the my 
darling to been to victim's home at noon on 
the day when the case happened. 
(c) According to the neighbors, at noon on 
the same day a fast food takeout boy came 
to the victim?s house. 
 
4. ???????????? 
(a) One officer was stabbed to death the 
women pedicure. 
(b) An officer is trimmed the foot daughter 
and assassinated.  
(c) An official was stabbed to death by the 
girl pedicurist. 
 
All the four erroneous MT translations above 
originate from the so-called recognition of 
OOVs ????? and ????? in the segmenta-
tion. The MT systems might make out ??
??and ??? or ???? and ??? separately, but 
fail to recognize their combinations. The combi-
nation pattern of these two plain pseudo-OOVs 
is a very typical and popular one in Chinese, just 
similar to the suffix ?-er? or ?-or? in English to 
derive a noun of a doer. ????? is a combina-
tion of ????(takeout) and ???(boy). When a 
MT failed to tackle it, the translation would be 
so poor. 
? Abbreviated pseudo-OOVs 
Different from English abbreviations or acro-
nyms, Chinese abbreviations in essence are con-
tracted forms of words and expressions. The 
contraction is mainly related to three factors: (1) 
maximal preservation of the original meaning; (2) 
possible maintenance of Chinese grammatical 
structural pattern; (3) consideration of accept-
ableness of rhythm. Let?s take ????? for ex-
ample. ????? is the contraction of 
?????????. The literal translation of the 
expression is ?maintain stability office?. Thus 
the first part of the expression ?????? is 
contracted to ????, and the second part is con-
tracted to ???. ?????? grammatically is a 
?verb + object? structure while ???? can be 
regarded as the same grammatical structure. 
Grammatically ????? is modified by 
??????, and in the contraction the word 
??? is also modified by the contraction ????. 
As for acceptableness of rhythm, ????? is a 
three-character expression, in which the first two 
are a ?verb + object structure and the last is sin-
gle. The structure of ?2-character verb + 1-
character noun? is a highly-productive pattern of 
noun expression in Chinese. So it is desirable to 
process this type of structures before syntactic 
processing. As the structure can usually be pat-
ternized, it is possible to have them well-
processed. We propose that we should deal with 
it in the morphological processing stage. 
4.2 Repetitive structures 
First let?s look at a MT translation and see what 
has happened when a Chinese repetitive struc-
ture is ill-processed. 
 
5. ?????????? 
(a) Come see Chuan Chuan, too small. 
(b) You come to wear looking, it is too 
small. 
(c) Come and try on, it is too small. 
 
The above two erroneous MT translations (a) 
and (b) originate from the failure in dealing with 
a typical verb structural pattern for expression to 
urge someone to have a try. This pattern is: 
??VV ?, its actual meaning is ?have a try? and 
?to see if ??. The literal translation of the above 
???instance ? ? may be ?put on, put on and 
let?s have a look?. Similarly we can have 
???? ? (which can be literally translated as 
?taste, taste, and let?s see?). 
Chinese is unique with its various types of re-
petitive structures. They are by no means rare 
phenomena in real texts. Any negligence or fail-
ure in the processing of repetitive structures will 
surely spoil the succedent tasks. Unfortunately 
this problem has not caught enough attention of 
researchers and developers of word segmenta-
tion tools. Most of neglecters usually leave the 
problem to the vocabulary that they collect. 
Let?s compare the following two groups of 
translations: 
Group A 
????????????????? 
???????????? 
Group B 
???????????????? 
????????????? 
Group A1 
You listen carefully, is not where the leak 
was. 
He looked at the stop next to the train. 
Group B1 
Carefully you chew a chewing is not a 
mint flavor. 
He sat down, then back by the by. 
 
The English translations of the repetitive 
structures in Group A1 are acceptable for the 
??? ???structures ? ? and ? ? are no doubt 
in the vocabulary. And the translations of Group 
B are messy enough to show that the repetitive 
structures become OOVs and are not well-
processed.  
Generally most of Chinese repetitive struc-
tures originate from three word classes: 
? Verb repetitive patterns: 
AA   ??, ?? ??,  
ABAB  ???? ????,  
? ?A / A  ??? ??? ,  
?AA   ??? ???,  
A??/?A  ???? ????????, ,  
 
? Adjective repetitive patterns: 
AA   ?? ?? ?? ??, , ,  
AABB  ???? ???? , ,???? 
ABAB  ???? ????,  
 
? Classifier repetitive patterns: 
AA  ??????? ,  
????????? 
?AA ??? ??? ??? , , ,  
??? 
?A?A ???? ???????? , ,  
?A??A  ????? ?????, ,  
????? 
 
All these patterns are highly productive in 
Chinese. It will be impracticable for any Chinese 
parsing or MT systems to leave all the resolu-
tions of them to the vocabulary rather than spe-
cial processing module. 
4.3 Plain classifier and unit structures 
Chinese is featured by its plenty of classifiers. In 
many cases a concrete noun occurs idiomatically 
with its particular classifier especially when 
modified a numeral, for example, ?????(a 
person), ?????(two cars), ???????(3 
kilos of apples). The processing of this type of 
structures will surely benefit the succeeding 
parsing and even word sense disambiguation. 
Besides the processing is comparatively easy 
even in the early stage. 
4.4 Chinese verb aspect processing 
The verb aspect in Chinese is different from that 
in English. In general, by using Chinese aspects, 
we add some procedural tune to a verb rather 
than relating to time. In other words Chinese 
verb aspects give hints of the developmental 
phases or results, or the capability or possibility 
of the events. Chinese verb aspects are expressed 
by the aspect markers, such as simple markers 
???, ???, ???, ???, ???, ???, ???, ???, 
??? and compound markers ????, ????, 
etc.  
Again let?s look at two pair of Chinese-to-
English MT translations. 
(6) ?????????????????
???? 
(a) To dry too much work, a person in-
deed dry However come. 
(b) The ones that should do have too 
much work, one can not really be dry. 
(c) I have too much work to do, I can 
hardly cope with it. 
 
(7) ??????????? 
(a) Said the girl spoke to cry. 
(b) The girl has cried saying. 
(c) The girl began to weep while talking. 
 
The messy translations tell us how serious the 
impairment of the translation will be if we fail to 
process the Chinese verb aspects. 
Table 2 shows the meanings conveyed by 
most Chinese aspect and its corresponding ?as-
pect markers? and examples. Finally, when 
speaking about Chinese aspect, one point we 
would like to invite readers? attention that dif-
ferent from the aspect of English. It is known 
that English aspect is usually closely related to 
tenses, for example, English verbs can be used in 
progressive aspect with various tenses, such as 
present progressive, progressive and future pro-
gressive tenses. However, Chinese aspects are 
related to the development of the event itself, but 
not related to the time when the event happens. 
5 Conclusion 
Is it time for Chinese NLP circle to rethink what 
we have actually achieved in the word segmen-
tation and consider some radical change? How 
much room left is there for the current trilogy to 
improve? We propose that we should have mor-
phological processing to replace the so-called 
word segmentation. We have designated new 
tasks for the processing. In addition, we hope 
that we should design and use a new evaluation 
method. The general idea of new evaluation is to 
use a post-segmentation, or post-morphological-
processing task, say, chunking, to evaluate, 
rather than the present method of isochronous 
self-testing.  
 
sememe in 
HowNet meaning marker examples 
{Vsuppose|
??} presupposing 
?? ?~?? 
?? ????~ {Vstart| ?
?} inceptive ? ????~?
? ~??? 
? ~??? 
?? ~?? {Vgoingon|??} progressive ? ?~?~??
? 
{Vcontinue|
??} protractive 
?? ?~????
{Vend|??} terminative ? ?~????
? ?~??? 
?? ?~?? 
? ?~??? 
? ??~? 
?? ?????~
?? ???~? 
? ???~? 
? ?~????
~ 
? ?~????
? ?~????
{Vachieve|
??} perfective 
? ?~????
?? ?~ 
?? ?~ 
??? ?~ 
?? ????~ 
?? ?~ 
?? ?~ 
? ?~??~ 
{Vable| ?
?} capable 
? ???~3 ?
? 
?? ???~ 
?? ?~? 
??? ????~ 
?? ?????~
?? ??~ 
{Vincapable|
???} incapable 
?? ?~ 
{Vpossible|
??} possible 
? ???~??
~ 
{Vtry|??} Trying ? ??~ 
Table 2.  Chinese aspect markers and their 
meanings 
References 
Hai Zhao and Chunyu Kit, 2008. Unsupervised 
Segmentation Helps Supervised Learning of Chi-
nese Tagging for Word Segmentation and Named 
Entity Recognition. In Prceedings of the Sixth 
SIGHAN Workshop on Chinese Language Proc-
essing, 2008, Hyderbad, India. 
Hwee Tou Ng and Jin Kiat Low, 2004. Chinese Part-
of-speech Tagging: One-at-a-Time or All-at-once? 
Word-Based or Character-Based? In Proceedings 
EMNLP. 
Nianwen Xue, 2003. Chinese Word Segmentation as 
Character Tagging. International Journal of Com-
putational Lnguistics and Chinese Language Proc-
essing, 8(1):29-48 
Wenbin Jiang and Haitao Mi and Liang Huang and 
Qun Liu, 2008b. Wird Lattice Reranking for Chi-
nese Word Segmentation and Part-of-speech Tag-
ging. In Proceedings of COLING 
Xinnian Mao, Yuan Dong and Saike He, Sencheng 
Bao and Haila Wang, Chinese Word Segmentation 
and Name Entity Recognition Based on Condition 
Random Fields, In Prceedings of the Sixth 
SIGHAN Workshop on Chinese Language Proc-
essing, 2008, Hyderbad, India. 
Zhendong Dong and Qiang Dong, 2006. HowNet and 
the Computation of Meaning, World Scientific 
Publishing Co. Pte. Ltd., Singapore 
??? ??, , 2007, ????????. 
??????, 2007, 21(3):8-20. 
???, 2009, ?? ?? ??? , , : 
??????????. In Proceedings of  
CNCCL-2009, Yantai 
Overview of the Chinese Word Sense Induction Task at CLP2010 
Le Sun 
Institute of Software 
Chinese Academy of 
Sciences 
sunle@iscas.ac.cn 
Zhenzhong Zhang 
Institute of Software, Graduate 
University Chinese Academy of 
Sciences 
zhenzhong@nfs.iscas.ac.cn
Qiang Dong 
Canada Keentime Inc. 
dongqiang@keenage.
com 
 
Abstract 
In this paper, we describe the Chinese 
word sense induction task at CLP2010. 
Seventeen teams participated in this task 
and nineteen system results were 
submitted. All participant systems are 
evaluated on a dataset containing 100 
target words and 5000 instances using 
the standard cluster evaluation. We will 
describe the participating systems and 
the evaluation results, and then find the 
most suitable method by comparing the 
different Chinese word sense induction 
systems. 
1 Introduction 
Word Sense Disambiguation (WSD) is an 
important task in natural language proceeding 
research and is critical to many applications 
which require language understanding. In 
traditional evaluations, the supervised methods 
usually can achieve a better WSD performance 
than the unsupervised methods. But the 
supervised WSD methods have some drawbacks: 
Firstly, they need large annotated dataset which 
is expensive to manually annotate (Agirre and 
Aitor, 2007). Secondly, the supervised WSD 
methods   are based on the ?fixed-list of 
senses? paradigm, i.e., the senses of a target 
word are represented as a closed list coming 
from a manually constructed dictionary (Agirre 
et al, 2006). Such a ?Fixed-list of senses? 
paradigm suffers from the lack of explicit and 
topic relations between word senses, are usually 
cannot reflect the exact context of the target 
word (Veronis, 2004). Furthermore, because the 
?fixed-list of senses? paradigm make the fix 
granularity assumption of the senses distinction, 
it may not be suitable in different situations 
(Samuel and Mirella, 2009). Thirdly, since most 
supervised WSD methods assign senses based 
on dictionaries or other lexical resources, it will 
be difficult to adapt them to new domains or 
languages when such resources are scare 
(Samuel and Mirella, 2009).  
To overcome the deficiencies of the 
supervised WSD methods, many unsupervised 
WSD methods have been developed in recent 
years, which can induce word senses directly 
from the unannotated dataset, i.e., Word Sense 
Induction (WSI). In this sense, WSI could be 
treat as a clustering task, which groups the 
instances of the target word according to their 
contextual similarity, with each resulting cluster 
corresponding to a specific ?word sense? or 
?word use? of the target word (in the task of 
WSI, the term ?word use? is more suitable than 
?word sense?(Agirre and Aitor, 2007)).  
Although traditional clustering techniques can 
be directly employed in WSI, in recent years 
some new methods have been proposed to 
enhance the WSI performance, such as the 
Bayesian approach (Samuel and Mirella, 2009) 
and the collocation graph approach (Ioannis and 
Suresh, 2008). Both the traditional and the new 
methods can achieve a good performance in the 
task of English word sense induction. However, 
the methods work well in English may not be 
suitable for Chinese due to the difference 
between Chinese and English.  So it is both 
important and critical to provide a standard 
testbed for the task of Chinese word sense 
induction (CWSI), in order to compare the 
performance of different Chinese WSI methods 
and find the methods which are suitable for the 
Chinese word sense induction task.  
In this paper, we describe the Chinese word 
sense induction task at CLP2010. The goal of 
this task is to provide a standard testbed for 
Chinese WSI task. By comparing the different 
Chinese WSI methods, we can find the suitable 
methods for the Chinese word sense induction 
task.  
This paper is organized as follow. Section 2 
describes the evaluation dataset in detail. Section 
3 demonstrates the evaluation criteria. Section 3 
describes the participated systems and their 
results. The conclusions are drawn in section 4. 
2 Dataset 
Two datasets are provided to the participants: 
the trial dataset and the test dataset. 
The trial dataset contains 50 Chinese words, 
and for each Chinese word, a set of 50 word 
instances are provided. All word instances are 
extracted from the Web and the newspapers like 
the Xinhua newspaper and the Renmin 
newspaper, and the HowNet senses of target 
words were manually annotated (Dong). Figure 
1 shows an example of the trial data without 
hand-annotated tag. Figure 2 shows an example 
of the trial data with hand-annotated tag. In 
Figure 1, the tag ?snum=2? indicates that the 
target word ???? has two different senses in 
this dataset. In each instance, the target word is 
marked between the tag ?<head>? and the tag 
?</head>?. In Figure 2, all instances between the 
tag ?<sense s=S0>? and the tag ?</sense>? are 
belong to the same sense class.  
 
 
Figure 1: Example of the trial data without 
hand-annotated tag. 
 
The case of the test dataset is similar to the 
trial dataset, but with little different in the 
number of target words. The test dataset contains 
100 target words (22 Chinese words containing 
one Chinese character and 78 Chinese words  
containing two or more Chinese ideographs). 
Figure 3 shows an example of a system?s output. 
In Figure 3, the first column represents the 
identifiers of target word, the second column 
represents the identifiers of instances, and the 
third column represents the identifiers of the 
resulting clusters and their weight (1.0 by default) 
generated by Chinese WSI systems. 
 
 
Figure 2: Example of the trial data with 
hand-annotated tag. 
 
 
Figure 3: Example of the output format. 
3 Evaluation Metric 
As described in Section 1, WSI could be 
conceptualized as a clustering problem. So we 
can measure the performance of WSI systems 
using the standard cluster evaluation metrics. As 
the same as Zhao and Karypis(2005), we use the 
FScore measure as the primary measure for 
assessing different WSI methods. The FScore is 
used in a similar way as at Information Retrieval 
field.  
In this case, the results of the WSI systems are 
treated as clusters of instances and the gold 
standard senses are classes. Then the precision 
of a class with respect to a cluster is defined as 
the number of their mutual instances divided by 
the total cluster size, and the recall of a class 
with respect to a cluster is defined as the number 
of their mutual instances divided by the total 
class size. The detailed definition is as bellows.  
Let the size of a particular class sr is nr, the 
size of a particular cluster hj is nj and the size of 
their common instances set is nr,j.,then the 
precision can be defined as: 
,( , ) r jr j
j
n
P s h
n
=  
The recall can be defined as: 
,( , ) r jr j
r
n
R s h
n
=  
Then FScore of this class and cluster is defined 
to be: 
2 ( , ) ( , )
( , )
( , ) ( , )
r j r j
r j
r j r j
P s h R s h
F s h
P s h R s h
? ?= +  
The FScore of a class sr, F(sr), is the maximum 
F(sr, hj) value attained by any cluster, and it is 
defined as: 
 ( ) max( ( , ))
j
r r jh
F s F s h=  
Finally, the FScore of the entire clustering 
solution is defined as the weighted average 
FScore of all class: 
1
( )q r r
r
n F s
FScore
n=
?=?  
where q is the number of classes and n is the size 
of the instance set for particular target word. 
Table 1 shows an example of a contingency 
table of classes and clusters, which can be used 
to calculate FScore. 
 
 Cluster 1 Cluster 2 
Class 1 100 500 
Class 2 400 200 
Table 1: A contingency table of classes and 
clusters 
 
Using this contingency table, we can calculate 
the FScore of this example is 0.7483. It is easy 
to know the FScore of a perfect clustering 
solution will be equal to one, where each cluster 
has exactly the same instances as one of the 
classes, and vice versa. This means that the 
higher the FScore, the better the clustering 
performance. 
Purity and entropy (Zhao and Karypis, 2005) 
are also used to measure the performance of the 
clustering solution. Compared to FScore, they 
have some disadvantages. FScore uses two 
complementary concepts, precision and recall, to 
assess the quality of a clustering solution. 
Precision indicates the degree of the instances 
that make up a cluster, which belong to a single 
class. On the other hand, recall indicates the 
degree of the instances that make up a class, 
which belong to a single cluster. But purity and 
entropy only consider one factor and discard 
another. So we use FScore measure to assess a 
clustering solution. 
For the sake of completeness, we also employ 
the V-Measure to assess different clustering 
solutions. V-Measure assesses a cluster solution 
by considering its homogeneity and its 
completeness (Rosenberg and Hirschberg, 2007). 
Homogeneity measures the degree that each 
cluster contains data points which belong to a 
single Gold Standard class. And completeness 
measures the degree that each Gold Standard 
class contains data points assigned to a single 
cluster (Rosenberg and Hirschberg, 2007). In 
general, the larger the V-Measure, the better the 
clustering performance. More details can be 
referred to (Rosenberg and Hirschberg, 2007). 
4 Results 
In this section we describe the participant 
systems and present their results. 
Since the size of test data may not be large 
enough to distinguish word senses, participants 
were provided the total number of the target 
word?s senses. And participants were also 
allowed to use extra resources without 
hand-annotated. 
4.1 Participant teams and systems 
There were 17 teams registered for the WSI task 
and 12 teams submitted their results. Totally 19 
participant system results were submitted (One 
was submitted after the deadline). 10 teams 
submitted their technical reports. Table 2 
demonstrates the statistics of the participant 
information.  
The methods used by the participated systems 
were described as follows: 
FDU: This system first extracted the triplets 
for target word in each instance and got the 
intersection of all related words of these triplets 
using Baidu web search engine. Then the triplets 
and their corresponding intersections were used 
to construct feature vectors of the target word?s 
instances. After that, sequential Information 
Bottleneck algorithm was used to group 
instances into clusters. 
BUPT: Three clustering algorithms- the 
k-means algorithm, the Expectation- 
maximization algorithm and the Locally 
Adaptive Clustering algorithm were employed to 
cluster instances, where all instances were 
represented using some combined features. In 
the end the Group-average agglomerative 
clustering was used to cluster the consensus 
matrix M, which was obtained from the  
 
 
Name of Participant Team Result Report
Natural Language Processing Laboratory at Northeastern University (NEU) ? ? 
Beijing University of Posts and Telecommunications (BUPT) ? ? 
Beijing Institute of Technology (BIT) ?  
Shanghai Jiao Tong University (SJTU)   
Laboratory of Intelligent Information Processing and Application 
Institutional at Leshan Teachers? College (LSTC) 
? ? 
 Natural Language Processing Laboratory at Soochow University (SCU) ? ? 
Fudan University (FDU) ? ? 
Institute of Computational Linguistics at Peking University 1 (PKU1) ? ? 
Beijing University of Information Science and Technology (BUIST) ?  
Tsinghua University Research Institute of Information Technology, 
Speech and Language Technologies R&D Center (THU) 
  
Information Retrieval Laboratory at Dalian University of Technology 
(DLUT) 
? ? 
Institute of Computational Linguistics at Peking University 2 (PKU2) ? ? 
City University of HK (CTU)   
Institute of Software Chinese Academy of Sciences (ISCAS) ? ? 
Cognitive Science Department at Xiamen University (XMU) ? ? 
Harbin Institute of Technology Shenzhen Graduate School (HITSZGS)   
National Taipei University of Technology (NTUT)   
Table 2: The registered teams. ??? means that the team submitted the result or the report. 
 
adjacency matrices of the individual clusters 
generated by the three single clustering 
algorithms mentioned above. 
LSTC: This team extracted the five neighbor 
words and their POSs around the target word as 
features. Then the k-means algorithm was used 
to cluster the instances of each target word. 
NEU: The ?Global collocation? and the 
?local collocation? were extracted as features. A 
constraint hierarchical clustering algorithm was 
used to cluster the instances of each target 
word. 
XMU: The neighbor words of the target 
word were extracted as features and TongYiCi 
CiLin1 was employed to measure the similarity 
between instances. The word instances are 
???????????????????????????????????????? ?????????????????????
1? http://www.ir?lab.org/?
clustered using the improved hierarchical 
clustering algorithm based on parts of speech. 
DLUT: This team used the information gain 
to determine the size of the feature window. 
TongYiCi CiLin was used to solve the data 
sparseness problem.  The word instances are 
clustered using an improvement k-means 
algorithm where k-initial centers were selected 
based on maximum distance. 
ISCAS: This team employed k-means 
clustering algorithm to cluster the second order 
co-occurrence vectors of contextual words. 
TongYiCi CiLin and singular value 
decomposition method were used to solve the 
problem of data sparseness. Please note that this 
system was submitted by the organizers. The 
organizers have taken great care in order to  
 
guaranty all participants are under the same 
conditions. 
PKU2: This team used local tokens, local 
bigram feature and topical feature to represent 
words as vectors. Spectral clustering method 
was used to cluster the instances of each target 
word. 
PKU1: This team extracted three types of 
features to represent instances as feature vectors. 
Then the clustering was done by using k-means 
algorithm. 
SCU: All words except stop words in 
instances were extracted to produce the feature 
vectors, based on which the similarity matrix 
were generated. After that, the spectral 
clustering algorithm was applied to group 
instances into clusters. 
4.2 Official Results 
In this section we present the official results of 
the participant systems (ISCAS* was submitted 
by organizers; BUIST** was submitted after the 
deadline). We also provide the result of a 
baseline -- 1c1w, which group all instances of a 
target word into a single cluster. 
Table 3 shows the FScore of the main 
systems submitted by participant teams on the 
test dataset. Table 4 shows the FScore and 
V-Measure of all participant systems. Systems 
were ranked according to their FScore. 
 
Systems Rank FScore 
BUPT_mainsys 1 0.7933 
PKU1_main_system 2 0.7812 
FDU 3 0.7788 
DLUT_main_system 4 0.7729 
PKU2 5 0.7598 
ISCAS* 6 0.7209 
SCU 7 0.7108 
NEU_WSI_1 8 0.6715 
XMU 9 0.6534 
BIT 10 0.6366 
1c1w 11 0.6147 
BUIST** 12 0.5972 
LSTC 13 0.5789 
Table 3: FScore of main systems on the test 
dataset including one baseline -1c1w. 
 
 
 
 
Systems Rank FScore V- 
Measure
BUPT_mainsys 1 0.7933 0.4628 
BUPT_LAC 2 0.7895 0.4538 
BUPT_EM 3 0.7855 0.4356 
BUPT_kmeans 4 0.7849 0.4472 
PKU1_main_system 5 0.7812 0.4300 
FDU 6 0.7788 0.4196 
DLUT_main_system 7 0.7729 0.5032 
PKU1_agglo 8 0.7651 0.4096 
PKU2 9 0.7598 0.4078 
ISCAS* 10 0.7209 0.3174 
SCU 11 0.7108 0.3131 
NEU_WSI_1 12 0.6715 0.2331 
XMU 13 0.6534 0.1954 
NEU_WSI_0 14 0.6520 0.1947 
BIT 15 0.6366 0.1713 
1c1w 16 0.6147 0.0 
DLUT_RUN2 17 0.6067 0.1192 
BUIST** 18 0.5972 0.1014 
DLUT_RUN3 19 0.5882 0.0906 
LSTC 20 0.5789 0.0535 
Table 4: FScore and V-Measure of all systems, 
including one baseline. 
 
From the results shown in Table 3 and 4, we 
can see that: 
1)  As described in section 4.1, most 
systems use traditional clustering 
methods. For example, the teams using 
the k-means algorithm contain BUPT, 
LSTC, PKU1, DLUT and ISCAS. The 
teams using the spectral clustering 
algorithm contain SCU and PKU2. The 
team XMU and NEU use hierarchical 
clustering algorithm. The results shows 
that if provided with the number of 
target word senses, traditional methods 
can achieve a good performance. But we 
also notice that even the same method 
can have a different performance. This 
seems to indicate that features which are 
predictive of word senses are important 
to the task of CWSI. 
2)  Most systems outperform the 1c1w 
baseline, which indicates these systems 
are able to induce correct senses of 
target words to some extent.   
3)  The rank of FScore is much the same as 
that of V-Measure but with little 
difference. This may be because that the 
two evaluation measures both assess 
quality of a clustering solution by 
considering two different aspects, where 
precision corresponds to homogeneity 
and recall corresponds to completeness. 
But when assessing the quality of a 
clustering solution, the FScore only 
considers the contributions from the 
classes which are most similar to the 
clusters while the V-Measure considers 
the contributions from all classes. 
 
Systems Characters Words 
BUPT_mainsys 0.6307 0.8392 
BUPT_LAC 0.6298 0.8346 
BUPT_EM 0.6191 0.8324 
BUPT_kmeans 0.6104 0.8341 
PKU1_main_system 0.6291 0.8240 
FDU 0.6964 0.8020 
DLUT_main_system 0.5178 0.8448 
PKU1_agglo 0.5946 0.8132 
PKU2 0.6157 0.8004 
ISCAS* 0.5639 0.7651 
SCU 0.5715 0.7501 
NEU_WSI_1 0.5786 0.6977 
XMU 0.5290 0.6885 
NEU_WSI_0 0.5439 0.6825 
BIT 0.5328 0.6659 
DLUT_RUN2 0.5196 0.6313 
BUIST** 0.5022 0.6240 
DLUT_RUN3 0.5066 0.6113 
LSTC 0.4648 0.6110 
1c1w 0.4611 0.6581 
Table 5: FScore of all systems on the dataset 
only containing either single characters or 
words respectively. 
 
A Chinese word can be constituted by single 
or multiple Chinese characters. Senses of 
Chinese characters are usually determined by 
the words containing the character. In order to 
compare the WSI performance on different 
granularity of words, we add 22 Chinese 
characters into the test corpus. Table 5 shows 
the results of the participant systems 
correspondingly on the corpus which only 
contains the 22 Chinese characters and the 
corpus which only contains the 78 Chinese 
words. 
From Table 5, we can see that: 
1) The FScore of systems on the corpus 
only containing single characters is 
significantly lower than that on the 
corpus only containing words. We 
believe this is because: 1) The Single 
Chinese characters usually contains 
more senses than Chinese words; 2) 
Their senses are not determined directly 
by their contexts but by the words 
containing them. Compared to the 
number of instances, the number of 
words containing the single character is 
large. So it is difficult to distinguish 
different senses of single characters 
because of the data sparseness.  
2) We noticed that all systems outperform 
the 1c1w baseline on the corpus only 
containing single characters but there 
are some systems? FScore are lower 
than the baseline on the corpus only 
containing words. It may be because the 
large number of characters? senses and 
the FScore favored the words which 
have small number of senses.  
5 Conclusions 
In this paper we describe the design and the 
results of CLP2010 back-off task 4-Chinese 
word sense induction task. 17 teams registered 
to this task and 12 teams submitted their results. 
In total there were 19 participant systems (One 
of them was submitted after the deadline). And 
10 teams submitted their technical reports. All 
systems are evaluated on a corpus containing 
100 target words and 5000 instances using 
FScore measure and V-Measure. Participants 
are also provided with the number of senses and 
allowed to use resources without 
hand-annotated. 
The evaluation results have shown that most 
of the participant systems achieve a better 
performance than the 1c1w baseline. We also 
notice that it is more difficult to distinguish 
senses of Chinese characters than words. For 
future work, in order to test the performances of 
Chinese word sense induction systems under 
different conditions, corpus from different 
fields will be constructed and the number of 
target word senses will not be provided and will 
leave as an open task to the participant systems. 
Acknowledgments 
This work has been partially funded by National 
Natural Science Foundation of China under 
grant #60773027, #60736044 and #90920010 
and by ?863? Key Projects #2006AA010108, 
?863? Projects #2008AA01Z145. We would 
like to thank Dr. Han Xianpei and Zhang Weiru 
for their detailed comments. We also want to 
thank the annotators for their hard work on 
preparing the trial and test dataset. 
References 
Andrew Rosenberg and Julia Hirschberg. 2007. 
V-Measure: A conditional entropy-based external 
cluster evaluation measure. In Proceedings of the 
2007 Joint Conference on Empirical Methods in 
Natural Language Processing and Computational 
Natural Language Learning (EMNLP-CoNLL), 
pages 410?420. 
Eneko Agirre, David Mart??nez, Oier L?opez de 
Lacalle,and Aitor Soroa. 2006. Two graph-based 
algorithms for state-of-the-art WSD. In 
Proceedings of the 2006 Conference on Empirical 
Methods in Natural Language Processing, pages 
585?593, Sydney, Australia. 
Eneko Agirre and Aitor Soroa. 2007. Semeval-2007 
task2: Evaluating word sense induction and 
discrimination systems. In Proceedings of 
SemEval-2007. Association for Computational 
Llinguistics, pages 7-12, Prague. 
Ioannis P. Klapaftis and Suresh Manandhar, 2008. 
Word Sense Induction Using Graphs of 
Collocations. In Proceeding of the 2008 
conference on 18th European Conference on 
Artificial Intelligence, Pages: 298-302. 
Jean. V?eronis. 2004. Hyperlex: lexical cartography 
for information retrieval. Computer Speech & 
Language,18(3):223.252. 
Samuel Brody and Mirella Lapata, 2009. Bayesian 
word sense induction. In Proceedings of the 12th 
Conference of the European Chapter of the 
Association for Computational Linguistics, pages 
103-111, Athens, Greece. 
Ying Zhao and George Karypis. 2005. Hierarchical 
clustering algorithms for document datasets. Data 
Mining and Knowledge Discovery,10(2):141.168. 
Zhendong  Dong, 
http://www.keenage.com/zhiwang/e_zhiwang.html 
