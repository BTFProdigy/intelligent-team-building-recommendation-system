TIPS: A Translingual Information Processing System
Y. Al-Onaizan, R. Florian, M. Franz, H. Hassan, Y. S. Lee, S. McCarley, K.
Papineni, S. Roukos, J. Sorensen, C. Tillmann, T. Ward, F. Xia
IBM T. J. Watson Research Center
Yorktown Heights
Abstract
Searching online information is
increasingly a daily activity for many
people. The multilinguality of online
content is also increasing (e.g. the
proportion of English web users, which
has been decreasing as a fraction the
increasing population of web users, dipped
below 50% in the summer of 2001). To
improve the ability of an English speaker
to search mutlilingual content, we built a
system that supports cross-lingual search
of an Arabic newswire collection and
provides on demand translation of Arabic
web pages into English. The cross-lingual
search engine supports a fast search
capability (sub-second response for typical
queries) and achieves state-of-the-art
performance in the high precision region
of the result list. The on demand statistical
machine translation uses the Direct
Translation model along with a novel
statistical Arabic Morphological Analyzer
to yield state-of-the-art translation quality.
The on demand SMT uses an efficient
dynamic programming decoder that
achieves reasonable speed for translating
web documents.
Overview
Morphologically rich languages like Arabic
(Beesley, K. 1996) present significant challenges
to many natural language processing applications
as the one described above because a word often
conveys complex meanings decomposable into
several morphemes (i.e. prefix, stem, suffix). By
segmenting words into morphemes, we can
improve the performance of natural language
systems including machine translation (Brown et
al. 1993) and information retrieval (Franz, M.
and McCarley, S. 2002). In this paper, we
present a cross-lingual English-Arabic search
engine combined with an on demand Arabic-
English statistical machine translation system
that relies on source language analysis for both
improved search and translation. We developed
novel statistical learning algorithms for
performing Arabic word segmentation (Lee, Y.
et al2003) into morphemes and morphological
source language (Arabic) analysis (Lee, Y. et al
2003b). These components improve both mono-
lingual (Arabic) search and cross-lingual
(English-Arabic) search and machine
translation. In addition, the system supports
either document translation or convolutional
models for cross-lingual search (Franz, M. and
McCarley, S. 2002).
The overall demonstration has the following
major components:
1. Mono-lingual search: uses Arabic word
segmentation and an okapi-like search
engine for document ranking.
2. Cross-lingual search: uses Arabic word
segmentation and morphological
analysis along with a statistical
morpheme translation matrix in a
convolutional model for document
ranking. The search can also use
document translation into English to
rank the Arabic documents. Both
approaches achieve similar precision in
the high precision region of retrieval.
The English query is also
morphologically analyzed to improve
performance.
3. OnDemand statistical machine
translation: this component uses both
analysis components along with a direct
channel translation model with a fast
dynamic programming decoder
(Tillmann, C. 2003). This system
                                                               Edmonton, May-June 2003
                                                              Demonstrations , pp. 1-2
                                                         Proceedings of HLT-NAACL 2003
achieves state-of-the-art Arabic-English
translation quality.
4. Arabic named entity detection and
translation: we have 31 categories of
Named Entities (Person, Organization,
etc.) that we detect and highlight in
Arabic text and provide the translation
of these entities into English. The
highlighted named entities help the user
to quickly assess the relevance of a
document.
All of the above functionality is available
through a web browser. We indexed the Arabic
AFP corpus about 330k documents for the
demonstration. The resulting search engine
supports sub-second query response. We also
provide an html detagging capability that allows
the translation of Arabic web pages while trying
to preserve the original layout as much as
possible in the on demand SMT component. The
Arabic Name Entity Tagger is currently run as an
offline process but we expect to have it online by
the demonstration time. We aslo include two
screen shots of the demonstration system.
Acknowledgments
This work was partially supported by the
Defense Advanced Research Projects Agency
and monitored by SPAWAR under contract No.
N66001-99-2-8916. The views and findings
contained in this material are those of the authors
and do not necessarily reflect the position of
policy of the Government and no official
endorsement should be inferred.
References
Beesley, K. 1996. Arabic Finite-State
Morphological Analysis and Generation.
Proceedings of COLING-96, pages 89? 94.
Brown, P., Della Pietra, S., Della Pietra, V., and
Mercer, R. 1993. The mathematics of statistical
machine translation: Parameter Estimation.
Computational Linguistics, 19(2): 263?311.
Franz, M. and McCarley, S. 2002. Arabic
Information Retrieval at IBM. Proceedings
of TREC 2002, pages 402?405.
Lee, Y., Papineni, K., Roukos, S.,
Emam, O., and Hassan, H. 2003. Language
Model Based Arabic Word Segmentation.
Submitted for publication.
Lee, Y., Papineni, K., Roukos, S., Emam,
O., and Hassan, H. 2003b. Automatic
Induction of Morphological Analysis for
Statistical Machine Translation. Manuscript in
preparation.
Tillmann, C., 2003. Word Reordering and a
DP Beam Search Algorithm for Statistical
Machine Translation. Computational
Linguistics, 29(1): 97-133.
Morphological Analysis for Statistical Machine Translation 
 
Young-Suk Lee 
IBM T. J. Watson Research Center, Yorktown Heights, NY 10598 
Email: ysuklee@us.ibm.com 
 
Abstract 
 
We present a novel morphological 
analysis technique which induces a 
morphological and syntactic   symmetry 
between two languages with highly 
asymmetrical morphological structures to 
improve statistical machine translation 
qualities.  The technique pre-supposes 
fine-grained segmentation of a word in 
the morphologically rich language into  
the sequence of prefix(es)-stem-suffix(es) 
and  part-of-speech tagging of the parallel 
corpus.  The algorithm identifies 
morphemes to be merged or deleted in the 
morphologically rich language to induce 
the desired morphological and syntactic 
symmetry. The technique improves 
Arabic-to-English translation qualities 
significantly  when applied to IBM Model 
1 and Phrase Translation Models trained  
on the training corpus size ranging from 
3,500 to 3.3 million sentence pairs. 
 
1. Introduction 
 
Translation of two languages with  highly 
different morphological structures as exemplified 
by Arabic and English poses a challenge to 
successful implementation of statistical machine 
translation models (Brown et al 1993).  Rarely 
occurring inflected forms of a stem in Arabic 
often do not accurately translate due to the 
frequency imbalance with the corresponding 
translation word in English.  So called a word 
(separated by a white space) in Arabic often 
corresponds to more than one independent word 
in English, posing a technical problem to the 
source channel models.  In the English-Arabic 
sentence alignment shown in Figure 1, Arabic 
word AlAHmr (written in Buckwalter 
transliteration) is aligned to two English words 
?the red?, and llmEArDp to three English words 
?of the opposition.?  In this paper, we present a 
technique to induce a morphological and 
syntactic symmetry between two languages with 
different morphological structures for statistical 
translation quality improvement. 
The technique is implemented as a two-step 
morphological processing for word-based 
translation models.  We first apply word 
segmentation to Arabic, segmenting a word into 
prefix(es)-stem-suffix(es). Arabic-English 
sentence alignment after Arabic word 
segmentation is illustrated in Figure 2, where one 
Arabic morpheme is aligned to one or zero 
English word.  We then apply the proposed 
technique to the word segmented  Arabic corpus 
to identify prefixes/suffixes to be merged into 
their stems or deleted to induce a symmetrical 
morphological structure.  Arabic-English 
sentence alignment after Arabic morphological 
analysis is shown in Figure 3, where the suffix p 
is merged into their stems mwAjh and mEArd. 
For phrase translation models, we apply 
additional morphological analysis induced from 
noun phrase parsing of Arabic to accomplish a 
syntactic as well as morphological symmetry 
between the two languages. 
 
2. Word Segmentation 
 
We pre-suppose segmentation of a word into 
prefix(es)-stem-suffix(es), as described in (Lee et 
al. 2003)  The category prefix and suffix 
encompasses function words such as conjunction 
markers, prepositions, pronouns, determiners and 
all inflectional morphemes of the language. If a 
word token contains more than one prefix and/or 
suffix, we posit multiple prefixes/suffixes per 
stem.  A sample word segmented Arabic text is 
given below, where prefixes are marked with #, 
and suffixes with +.  
 
w# s# y# Hl sA}q Al# tjArb fy jAgwAr Al# 
brAzyly lwsyAnw bwrty mkAn AyrfAyn fy Al# 
sbAq gdA Al# AHd Al*y s# y# kwn Awly xTw 
+At +h fy EAlm sbAq +At AlfwrmwlA 
 
3.  Morphological  Analysis 
 
Morphological analysis identifies functional 
morphemes to be merged into meaning-bearing 
stems or to be deleted. In Arabic, functional 
morphemes typically belong to prefixes or 
suffixes. 
 
         Sudan  :    alert    in       the     red     sea   to  face       build-up    of      the  oppositions       in     Eritrea 
 
 
 
   AlswdAn         :    AstnfAr    fy  AlbHr  AlAHmr   lmwAjhp    H$wd   llmEArDp     dAxl      ArytryA 
       Figure 1. Word alignment between Arabic and English without Arabic morphological processing 
        Sudan    :   alert   in    the      red  sea  to    face        build-up  of   the    opposition      in     Eritrea 
 
 
 
      Al     swdAn  :  AstnfAr   fy  Al  bHr  Al  AHmr  l  mwAjh  p      H$wd  l  Al  mEArd  p dAxl    ArytryA 
            Figure 2. Alignment between word-segmented Arabic and English 
          Sudan   :   alert   in       the  red      sea   to  face   build-up        of   the   opposition       in        Eritrea 
        
 
 
         swdAn  :  AstnfAr  fy   Al  bHr    AHmr  l    mwAjhp  H$wd    l     Al     mEArdp  dAxl       ArytryA 
      Figure 3. Alignment between morphologically analyzed Arabic and English 
 
Sample Arabic texts before and after   
morphological analysis is shown below. 
Mwskw 51-7 ( Af b ) - Elm An Al# qSf Al# 
mdfEy Al*y Ady Aly ASAb +p jndy +yn 
rwsy +yn Avn +yn b# jrwH Tfyf +p q*A}f 
Al# jmE +p fy mTAr xAn qlE +p ? 
Mwskw 51-7 ( Af b ) - Elm An Al# qSf Al# 
mdfEy Al*y Ady Aly ASAbp jndyyn rwsyyn 
Avnyn b# jrwH Tfyfp msA' Al# jmEp fy 
mTAr xAn qlEp ? 
 
In the morphologically analyzed Arabic (bottom), 
the feminine singular suffix +p and the 
masculine plural suffix +yn are merged into the 
preceding stems analogous to singular/plural 
noun distinction in English, e.g. girl vs. girls.  
 
3.1 Method 
 
We apply part-speech tagging to a symbol 
tokenized and word segmented Arabic and 
symbol-tokenized English parallel corpus.  We 
then viterbi-align the part-of-speech tagged 
parallel corpus, using translation parameters 
obtained via Model 1 training of word 
segmented Arabic and symbol-tokenized English, 
to derive the conditional probability of an 
English part-of-speech tag given the combination 
of an Arabic prefix and its part-of-speech or an 
Arabic suffix and its part-of-speech.1 
                                                 
1 We have used an Arabic part-of-speech tagger with 
around 120 tags, and an English part-of-speech tagger 
with around 55 tags. 
 
3.2  Algorithm 
 
The algorithm utilizes two sets of translation 
probabilities to determine merge/deletion 
analysis of a morpheme. We obtain tag-to-tag 
translation probabilities according to (1), which 
identifies the most probable part-of-speech 
correspondences between Arabic (tagA) and 
English (tagE).  
 
(1) Pr(tagE | tagA) 
 
We also obtain translation probabilities of an 
English part-of-speech tag given each Arabic 
prefix/suffix and its part-of-speech according to 
(2) and (3):  
 
(2)  Pr(tagE | stemtagA, suffixj_tagjk) 
 
(2) computes the translation probability of an 
Arabic suffix and its part-of-speech into an 
English part-of-speech in the Arabic stem tag 
context, stemtagA. StemtagA is one of the major 
stem parts-of-speech with which the specified 
prefix or suffix co-occurs, i.e. ADV, ADJ, NOUN, 
NOUN_PROP, VERB_IMPERFECT, VERB_PERFECT. 2  
J in suffixj ranges from 1 to M, M = number of 
distinct suffixes co-occurring with stemtagA.  
tagjk in suffixj_tagjk is the part-of-speech of suffixj, 
where k ranges from 1 to L, L = number of 
                                                 
2  All Arabic part-of-speech tags are adopted from 
LDC-distributed Arabic Treebank and English tags are 
adopted from Penn Treebank. 
distinct tags assigned to the suffixj in the training 
corpus.  
 
(3) Pr(tagE | prefixi_tagik, stemtagA) 
 
(3) computes the translation probability of an 
Arabic prefix and its part-of-speech into an 
English part-of-speech in the Arabic stem tag 
context, stemtagA.  Prefixi and tagik in 
prefixi_tagik may be interpreted in a manner 
analogous to suffixj and tagjk of suffixj_tagjk in (2).  
 
3.2.1  IBM Model 1 
 
The algorithm for  word-based translation model, 
e.g. IBM Model 1, implements the idea that if a 
morpheme in one language is robustly  translated 
into a distinct part-of-speech in the other 
language, the morpheme is very likely to have its 
independent counterpart in the other language.  
Therefore, a robust overlap of tagE given tagA 
between Pr(tagE|tagA) and Pr(tagE|stemtagA, 
suffixj_tagjk) for a suffix  and Pr(tagE|tagA) and 
Pr(tagE|prefixi_tagik, stemtagA) for a prefix is a 
positive indicator that the Arabic prefix/suffix 
has an independent counterpart in English.  If the 
overlap is weak or doesn?t exist, the prefix/suffix 
is unlikely to have an independent counterpart 
and is subject to merge/deletion analysis.3  
 
Step 1: For each tagA, select the top 3 most 
probable tagE from Pr(tagE|tagA).   
Step 2: Partition all prefixi_tagik and suffixj_tagjk 
into two groups in each  stemtagA context. 
Group I: At least one of  ?tagE|tagik? or 
?tagE|tagjk? occurs as one of the top 3 most 
probable translation pairs in Pr(tagE|tagA).  
Prefixes and suffixes in this group are likely to 
have their independent counterparts in English. 
Group II: None of  ?tagE|tagik? or ?tagE|tagjk? 
occurs as one of the top 3 most probable 
translation pairs in Pr(tagE|tagA).  Prefixes and 
suffixes in this group are unlikely to have their 
independent counterparts in English. 
Step 3:  Determine the merge/deletion analysis 
of  the prefixes/suffixes in Group II as follows: If 
prefixi_tagik/suffixj_tagjk occurs in more than one 
stemtagA context, and its translation probability 
into NULL tag is the highest, delete the 
prefixi_tagik/suffixj_tagjk in the stemtagA context. 
If prefixi_tagik/suffixj_tagjk occurs in more than 
one stemtagA context, and its translation 
                                                 
3  We assume that only one tag is assigned to one 
morpheme or word, i.e. no combination tag of the 
form DET+NOUN, etc. 
probability into NULL tag is not the highest, 
merge the prefixi_tagik/suffixj_tagjk into its stem 
in the  stemtagA context.   
Merge/deletion analysis is applied to all 
prefixi_tagik/suffixj_tagjk occurring in the 
appropriate stem tag contexts in the training 
corpus (for translation model training) and a new 
input text (for decoding). 
 
3.2.2 Phrase Translation Model 
 
For phrase translation models (Och and Ney 
2002),  we induce  additional merge/deletion 
analysis on the basis of base noun phrase parsing 
of Arabic. One major  asymmetry between 
Arabic and English is caused by more frequent 
use of the determiner Al# in Arabic compared 
with its counterpart the in English.  We apply 
Al#-deletion to Arabic noun phrases so that only 
the first occurrence of Al#  in a noun phrase is 
retained. All instances of Al# occurring before a 
proper noun ? as in Al# qds, whose literal 
translation is the Jerusalem ? are also deleted. 
Unlike the automatic induction of morphological 
analysis described in 3.2.1,  Al#-deletion analysis 
is manually induced.  
 
4. Performance Evaluations 
 
System performances are evaluated on LDC-
distributed Multiple Translation Arabic Part I  
consisting of 1,043 segments derived from AFP 
and Xinhua newswires. Translation qualities are 
measured by uncased BLEU (Papineni et al 
2002) with 4 reference translations, sysids: ahb, 
ahc, ahd, ahe.  
Systems are developed from 4 different sizes 
of training corpora, 3.5K, 35K, 350K and 3.3M 
sentence pairs, as in Table 1. The number in each 
cell indicates the number of sentence pairs in 
each genre (newswires, ummah, UN corpus).4 
Genre    3.5K    35K    350K     3.3M 
News   1,000   1,000     9,238      12,002 
Ummah      500   1,000   13,027      13,027 
UN   2,000 33,000 327,735 3,270,200 
      Table 1. Training Corpora Specifications 
 
4.1 IBM Model 1 
 
Impact of morphological analysis on IBM Model 
1 is shown in Table 2. 
                                                 
4  We have used the same language model for all 
evaluations.  
 
corpus  size   baseline   morph analysis 
       3.5K      0.10           0.25 
        35K      0.14           0.29 
      350K      0.18           0.31 
      3.3M      0.18           0.32 
Table 2. Impact of morphological analysis on 
IBM Model 1 
Baseline performances are obtained by 
Model 1 training and decoding without any 
segmentation or morphological analysis on 
Arabic. BLEU scores under ?morph analysis? is 
obtained by Model 1 training on Arabic 
morphologically analyzed and English symbol-
tokenized parallel corpus and Model 1 decoding 
on the Arabic morphologically analyzed input 
text.5 
  
4.2  Phrase Translation Model 
 
Impact of Arabic morphological analysis on a 
phrase translation model with monotone 
decoding (Tillmann 2003), is shown in Table 3. 
  corpus size   baseline  morph analysis 
       3.5K      0.17           0.24 
        35K      0.24           0.29 
      350K      0.32           0.36 
       3.3M      0.36           0.39 
Table 3. Impact of morphological analysis on 
Phrase Translation Model 
BLEU scores under baseline and morph 
analysis are obtained in a manner analogous to 
Model 1 except that the morphological analysis 
for the phrase translation model is a combination 
of the automatically induced analysis for Model 
1 plus the manually induced Al#-deletion in 3.2.2. 
The scores with only automatically induced 
morphological analysis are 0.21, 0.25, 0.33 and 
0.36 for 3.5K, 35K, 350K and 3.3M sentence 
pair training corpora, respectively. 
 
5. Related  Work 
 
Automatic induction of the desired linguistic 
knowledge from a word/morpheme-aligned 
parallel corpus is analogous to (Yarowsky et al 
2001). Word segmentation and merge/deletion 
analysis in morphology is similar to parsing and   
insertion operation in syntax by (Yamada and 
Knight 2001). Symmetrization of linguistic 
structures can also be found in (Niessen and Ney 
2000).  
                                                 
5  Our experiments indicate that addition of Al#-
deletion, cf. Phrase Translation Model, does not affect 
the performance of IBM Model 1.  
Acknowledgements 
 
This work was partially supported by the 
Defense Advanced Research Projects Agency 
and monitored by SPAWAR under contract No. 
N66001-99-2-8916. The views and findings 
contained in this material are those of the authors 
and do not necessarily reflect the position of 
policy of the Government and no official 
endorsement should be inferred. We would like 
to acknowledge Salim Roukos and Kishore 
Papineni for technical discussions. 
 
6. References 
 
Brown, P., Della Pietra, S., Della Pietra, V., 
and Mercer, R. 1993. The mathematics of 
statistical machine translation: Parameter 
Estimation. Computational Linguistics, 19(2): 
263?311. 
Lee, Y-S., Papineni, K., Roukos, S., Emam, 
O., Hassan, H. 2003. Language Model Based 
Arabic Word Segmentation. In Proceedings of 
the 41st Annual Meeting of the ACL. Pages 399?
406. Sapporo, Japan. 
Niessen, S., Ney, H. 2000. Improving SMT 
quality with morpho-syntactic analysis. In 
Proceedings of 20th International Conference on 
Computational Linguistics. Saarbrucken, 
Germany. 
Och, F. J., Ney. H. 2002. Discriminative 
training and maximum entropy models for 
statistical machine translation. In Proceedings of 
the 40th Annual Meeting of the ACL. Pages 
295?302. Philadelphia. PA. 
Papineni, K., Roukos, S., Ward, R., Zhu W. 
2002. Bleu: a Method for Automatic Evaluation 
of Machine Translation. Proceedings of the 40th 
Annual Meeting of the ACL.  Pages 311?318. 
Philadelphia, PA. 
Tillmann, Christoph 2003. A Projection 
Extension Algorithm for Statistical Machine 
Translation. In Proceedings of the 2003 
Conference on Empirical Methods in Natural 
Language Processing.  Pages 1?8. Sapporo, 
Japan. 
Yamada, K. and Knight, K. 2001. A Syntax-
Based Statistical Translation Model. In 
Proceedings of the 39th Conference of the ACL. 
Pages 523?530. Toulouse, France. 
Yarowsky, D., G. Ngai and R. Wicentowski 
2001.  Inducing Multilingual Text Analysis 
Tools via Robust Projection across Aligned 
Corpora. In Proceedings of HLT 2001 (ISBN: 1-
55860-786-2). 
 
  
Language Model Based Arabic Word Segmentation 
 
Young-Suk Lee     Kishore Papineni      Salim Roukos 
IBM T. J. Watson Research Center 
Yorktown Heights, NY 10598 
 
Ossama Emam    Hany Hassan 
IBM Cairo Technology Development Center 
P.O.Box 166, El-Ahram, Giza, Egypt
  
Abstract 
 
We approximate Arabic?s rich 
morphology by a model that a word 
consists of a sequence of morphemes in 
the pattern prefix*-stem-suffix* (* 
denotes zero or more occurrences of a 
morpheme). Our method is seeded by a 
small manually segmented Arabic corpus 
and uses it to bootstrap an unsupervised 
algorithm to build the Arabic word 
segmenter from a large unsegmented 
Arabic corpus. The algorithm uses a 
trigram language model to determine the 
most probable morpheme sequence for a 
given input. The language model is 
initially estimated from a small manually 
segmented corpus of about 110,000 
words. To improve the segmentation 
accuracy, we use an unsupervised 
algorithm for automatically acquiring 
new stems from a 155 million word 
unsegmented corpus, and re-estimate the 
model parameters with the expanded 
vocabulary and training corpus. The 
resulting Arabic word segmentation 
system achieves around 97% exact match 
accuracy on a test corpus containing 
28,449 word tokens. We believe this is a 
state-of-the-art performance and the 
algorithm can be used for many highly 
inflected languages provided that one can 
create a small manually segmented 
corpus of the language of interest.  
 
 
 
1   Introduction 
 
Morphologically rich languages like       
Arabic present significant challenges to many 
natural language processing applications 
because a word often conveys complex 
meanings decomposable into several 
morphemes (i.e. prefix, stem, suffix).   By 
segmenting words into morphemes, we can 
improve the performance of natural language 
systems including machine translation (Brown 
et al 1993) and information retrieval (Franz, 
M. and McCarley, S. 2002). In this paper, we 
present a general word segmentation algorithm 
for handling inflectional morphology capable 
of segmenting a word into a prefix*-stem-
suffix* sequence, using a small manually 
segmented corpus and a table of 
prefixes/suffixes of the language. We do not 
address Arabic infix morphology where many 
stems correspond to the same root with various 
infix variations; we treat all the stems of a 
common root as separate atomic units. The use 
of a stem as a morpheme (unit of meaning) is 
better suited than the use of a root for the 
applications we are considering in information 
retrieval and machine translation (e.g. different 
stems of the same root translate into different 
English words.) Examples of Arabic words and 
their segmentation into prefix*-stem-suffix* are 
given in Table 1, where '#' indicates a 
morpheme being a prefix, and '+' a suffix.1 As  
                                                          
1 Arabic is presented in both native and Buckwalter 
transliterated Arabic whenever possible. All native 
Arabic is to be read from right-to-left, and transliterated 
Arabic is to be read from left-to-right. The convention of 
shown in Table 1, a word may include multiple 
prefixes, as in   ???? (l: for, Al: the),  or multiple 
suffixes, as in   ????? (t: feminine singular, h: his).  
A word may also consist only of a stem, as in 
 ?????  (AlY, to/towards). 
  The algorithm implementation involves (i) 
language model training on a morpheme-
segmented corpus, (ii) segmentation of input 
text into a sequence of morphemes using the 
language model parameters, and (iii) 
unsupervised acquisition of new stems from a 
large unsegmented corpus. The only linguistic 
resources required include  a small manually 
segmented corpus ranging from 20,000 words 
to 100,000 words, a table of prefixes and 
suffixes of the language and  a large 
unsegmented corpus.   
  In Section 2, we discuss related work. In 
Section 3, we describe the segmentation 
algorithm.  In Section 4, we discuss the  
unsupervised algorithm for new stem 
acquisition. In Section 5, we present 
experimental results. In Section 6, we 
summarize the paper. 
 
2   Related Work 
 
Our work adopts major components of the 
algorithm from (Luo & Roukos 1996): 
language model (LM) parameter estimation 
from a segmented corpus and input 
segmentation on the basis of LM probabilities.  
However, our work diverges from their work 
in two crucial respects: (i) new technique of 
computing all possible segmentations of a 
word into prefix*-stem-suffix* for decoding, 
and  (ii) unsupervised algorithm for new stem 
acquisition based on a stem candidate's 
similarity to stems occurring in the training 
corpus. 
  (Darwish 2002) presents a  supervised 
technique which identifies the root of an 
Arabic word by stripping away the prefix and 
the suffix of the word on the basis of manually 
acquired dictionary of word-root pairs and the 
likelihood that a prefix and a suffix would 
occur with the template from which the root is 
derived. He reports 92.7% segmentation 
accuracy on a 9,606 word evaluation corpus.  
His technique pre-supposes at most one prefix 
and one suffix per stem regardless of the actual 
number and meanings of prefixes/suffixes 
associated with the stem.  (Beesley 1996)  
presents a finite-state morphological analyzer 
for Arabic, which displays the root, pattern, 
and prefixes/suffixes. The analyses are based 
on manually acquired lexicons and rules.  
Although his analyzer is comprehensive in the 
types of knowledge it presents, it has been 
criticized for their extensive development time 
and lack of robustness, cf. (Darwish 2002). 
                                                                                    
marking a prefix with '#" and a suffix with '+' will be 
adopted throughout the paper. 
  (Yarowsky and Wicentowsky 2000) 
presents a minimally supervised morphological 
analysis with a  performance of over 99.2% 
accuracy for the 3,888 past-tense test cases in 
English. The core algorithm lies in the 
estimation of a probabilistic alignment 
between inflected forms and root forms. The 
probability estimation is based on the lemma 
alignment by frequency ratio similarity among 
different inflectional forms derived from the 
same lemma, given a table of inflectional 
parts-of-speech, a list of the canonical suffixes 
for each part of speech, and a list of the 
candidate noun, verb and adjective roots of the 
language.  Their algorithm does not handle 
multiple affixes per word. 
  (Goldsmith 2000) presents an unsupervised 
technique based on the expectation-
maximization algorithm and minimum 
description length to segment exactly one 
suffix per word, resulting in an F-score of 81.8 
for suffix identification in English according to 
(Schone and Jurafsky 2001). (Schone and 
Jurafsky 2001) proposes an unsupervised 
algorithm capable of automatically inducing 
the morphology of inflectional languages using 
only text corpora. Their algorithm combines 
cues from orthography, semantics, and 
contextual information to induce 
morphological relationships in German, Dutch, 
and English, among others. They report F-
scores between 85 and 93 for suffix analyses 
and between 78 and 85 for circumfix analyses 
in these languages. Although their algorithm 
captures prefix-suffix combinations or 
circumfixes, it does not handle the multiple 
affixes per word we observe in Arabic.
 2
                Words            Prefixes                 Stems             Suffixes 
    Arabic    Translit.   Arabic  Translit.    Arabic    Translit.   Arabic   Translit. 
 ????????????? ?   AlwlAyAt  #??    Al#       ????       wlAy      ?? +    +At 
      ???????????    HyAth           ??????     HyA  ?  +? +    +t +h 
 ?????????????    llHSwl  #?#  ??     l# Al#    ??????     HSwl   
         ?????        AlY           ?????      AlY   
 Table 1  Segmentation of Arabic Words into Prefix*-Stem-Suffix* 
 
3  Morpheme Segmentation 
 
3.1 Trigram Language Model 
 
Given an Arabic sentence, we use a trigram 
language model on morphemes to segment it 
into a sequence of morphemes {m1, m2, ?,mn}. 
The input to the morpheme segmenter is a 
sequence of Arabic tokens ? we use a 
tokenizer that looks only at white space and 
other punctuation, e.g. quotation marks, 
parentheses, period, comma, etc.  A sample of 
a manually segmented corpus is given below2. 
Here multiple occurrences of prefixes and 
suffixes per word are marked with an 
underline. 
 
???? # ??? ??????? ???? ?? ?? ??# ?
??? # ???? ?? # ? ??+??? ?? ???? # ??
? ?????? ??? ?+???? ??? ???? # ?? #
 ??? ???+? +? ???? +???? ?? ???  #
??? #?# ??? # ????? ?# ?????? ?? ?? 
?? ??+???? # ? ??????# ??? ???? ? #
 ? ??? ?? ???? ???? ?????? +????? .
????? ?? ?????? #  ?? ???? ??#?# ?# ?
??????? ??????? ????? ???? # ??
??? # ???? ??? ??# ??????? ?? ??
 ?? ?+?? + ??? ???? ??? #? # ????? 
 ?? ?????????+???? ???? 
 
w# kAn AyrfAyn Al*y Hl fy Al# mrkz Al# 
Awl fy jA}z +p Al# nmsA Al# EAm Al# 
mADy Ely syAr +p fyrAry $Er b# AlAm fy 
bTn +h ADTr +t +h Aly Al# AnsHAb mn Al#  
tjArb w# hw s# y# Ewd Aly lndn l# AjrA' Al# 
fHwS +At Al# Drwry +p Hsb mA A$Ar fryq  
 
                                                          
2 A manually segmented Arabic corpus containing about 
140K word tokens has been provided by LDC 
(http://www.ldc.upenn.edu). We divided this corpus into 
training and the development test sets as described in 
Section 5. 
 
 
jAgwAr. w# s# y# Hl sA}q Al# tjArb fy 
jAgwAr Al# brAzyly lwsyAnw bwrty mkAn 
AyrfAyn fy Al# sbAq gdA Al# AHd Al*y s# 
y# kwn Awly xTw +At +h fy EAlm sbAq +At 
AlfwrmwlA 
 
Many instances of prefixes and suffixes in 
Arabic are meaning bearing and correspond to 
a word in English such as pronouns and 
prepositions.  Therefore, we choose a 
segmentation into multiple prefixes and 
suffixes. Segmentation into one prefix  and one 
suffix per word, cf. (Darwish 2002), is not very 
useful for applications like statistical machine 
translation, (Brown et al 1993), for which an 
accurate word-to-word alignment between the 
source and the target languages is critical for 
high quality translations. 
  The trigram language model probabilities 
of morpheme sequences, p(mi|mi-1, mi-2), are 
estimated from the morpheme-segmented 
corpus. At token boundaries, the morphemes 
from previous tokens constitute the histories of 
the current morpheme in the trigram language 
model.  The trigram model is smoothed using 
deleted interpolation with the bigram and 
unigram models, (Jelinek 1997), as in (1): 
 
(1) p(m3 | m1 ,m2) =  ?3 p(m3 |m1 ,m2) + ?2 
p(m3 |m2) + ?3 p(m3), where ?1+?2 +?3 = 1. 
 
  A small morpheme-segmented corpus 
results in a relatively high out of vocabulary 
rate for the stems. We describe below an 
unsupervised acquisition of new stems from a 
large unsegmented Arabic corpus.  However, 
we first describe the segmentation algorithm.   
 
3.2  Decoder for Morpheme Segmentation 
 
 3
We take the unit of decoding to be a sentence 
that has been tokenized using white space and 
punctuation.  The task of a decoder is to find 
the morpheme sequence which maximizes the 
trigram probability of the input sentence, as in 
(2): 
 
(2)  SEGMENTATIONbest = Argmax IIi=1, N 
p(mi|mi-1mi-2), N = number of morphemes in 
the input. 
 
Search algorithm for (2) is informally 
described for each word token as follows: 
 
Step 1: Compute all possible segmentations of 
the token  (to be elaborated in 3.2.1). 
Step 2: Compute the trigram language model 
score of each segmentation.  For some 
segmentations of a token, the stem may be an 
out of vocabulary item. In that case, we use an 
?UNKNOWN? class in the trigram language 
model with the model probability given by 
p(UNKNOWN|mi-1, mi-2) * UNK_Fraction, where 
UNK_Fraction is 1e-9 determined on empirical 
grounds. This allows us to segment new words 
with a high accuracy even with a relatively 
high number of unknown stems in the 
language model vocabulary, cf. experimental 
results in Tables 5 & 6. 
Step 3: Keep the top N highest scored 
segmentations. 
 
3.2.1  Possible Segmentations of  a Word 
 
Possible segmentations of a word token are 
restricted to those derivable from a table of 
prefixes and suffixes of the language for 
decoder speed-up and improved accuracy.   
  Table 2 shows examples of atomic (e.g. ??, 
??) and multi-component (e.g.  ??????     ,???????) 
prefixes and suffixes, along with their 
component morphemes in native Arabic.3 
 
                                                          
3 We have acquired the prefix/suffix table from a 110K 
word manually segmented LDC corpus (51 prefixes & 72 
suffixes) and from IBM-Egypt (additional 14 prefixes & 
122 suffixes). The performance improvement by the 
additional prefix/suffix list ranges from 0.07% to 0.54% 
according to the manually segmented training corpus 
size. The smaller the manually segmented corpus size is, 
the bigger the performance improvement by adding 
additional prefix/suffix list is. 
         Prefixes          Suffixes 
      ??          ??       ??# ??+ 
    ??????        ?#  ??# ?????+   ???     ??+ 
 ???????     ?#  ?#   ??# ?????+?? + ??  
          Table 2  Prefix/Suffix Table 
 
Each token is assumed to have the structure 
prefix*-stem-suffix*, and is compared against 
the prefix/suffix table for segmentation. Given 
a word token, (i) identify all of the matching 
prefixes and suffixes from the table, (ii) further 
segment each matching prefix/suffix at each 
character position, and (iii) enumerate all 
prefix*-stem-suffix* sequences derivable from 
(i) and (ii).  
  Table 3 shows all of its possible 
segmentations of the token ???????  
(wAkrrhA; 'and I repeat it'),4 where ? indicates 
the null prefix/suffix and the Seg Score is the 
language model probabilities of each 
segmentation S1 ... S12. For this token, there 
are two matching prefixes #?(w#) and 
#??(wA#) from the prefix table, and two 
matching suffixes ?+(+A) and ??+(+hA)  
from the suffix table. S1, S2, & S3 are the 
segmentations given the null prefix ? and 
suffixes ?, +A, +hA. S4, S5, & S6 are the 
segmentations given the prefix w# and suffixes 
?, +A, +hA. S7, S8, & S9 are the 
segmentations given the prefix wA# and 
suffixes ?, +A, +hA. S10, S11, & S12 are the 
segmentations given the prefix sequence w# 
A# derived from the prefix wA# and  suffixes 
?, +A, +hA. As illustrated by S12, derivation 
of sub-segmentations of the matching 
prefixes/suffixes enables the system to identify 
possible segmentations which would have been 
missed otherwise. In this case, segmentation 
including the derived prefix sequence               
??+??? # ?# ? (w# A# krr +hA) happens to 
be the correct one.  
 
3.2.2. Prefix-Suffix Filter 
 
While the number of possible segmentations is 
maximized by sub-segmenting matching 
                                                          
4 A sentence in which the token occurs is as follows:  ?????
??????? ???????? ???? ?? ????? ????? ????? ?? ???????? ??????? 
(qlthA wAkrrhA fAlm$klp lyst fy AlfnT AlxAm wAnmA fy 
Alm$tqAt AlnfTyp.) 
 4
prefixes and suffixes, some of illegitimate sub-
segmentations are filtered out on the basis of 
the knowledge specific to the manually 
segmented corpus. For instance, sub-
segmentation of the suffix hA into +h +A is 
ruled out because there is no suffix sequence 
+h +A in the training corpus. Likewise, sub-
segmentation of the prefix Al into A# l# is 
filtered out. Filtering out improbable 
prefix/suffix sequences improves the 
segmentation accuracy, as shown in Table 5. 
 
 Prefix Stem Suffix Seg Scores 
S1 ? wAkrrhA ? 2.6071e-05 
S2 ? wAkrrh +A 1.36561e-06 
S3 ? wAkrr +hA 9.45933e-07 
S4 w# AkrrhA ? 2.72648e-06 
S5 w# Akrrh +A 5.64843e-07 
S6 w# Akrr +hA 4.52229e-05 
S7 wA# krrhA ? 7.58256e-10 
S8 wA# krrh +A 5.09988e-11 
S9 wA# krr +hA 1.91774e-08 
S10 w# A# krrhA ? 7.69038e-07 
S11 w# A# krrh +A 1.82663e-07 
S12 w# A# krr +hA 0.000944511 
Table 3 Possible Segmentations of  
??????? (wAkrrhA) 
 
4  Unsupervised Acquisition  of  New  
Stems 
 
Once the seed segmenter is developed on the 
basis of a manually segmented corpus,  the 
performance may be improved by iteratively 
expanding the stem vocabulary  and retraining 
the language model on a large automatically 
segmented Arabic corpus.  
  Given a small manually segmented corpus 
and a large unsegmented corpus, segmenter 
development proceeds as follows. 
 
Initialization: Develop the seed segmenter 
Segmenter0 trained on the manually segmented 
corpus Corpus0, using the language model 
vocabulary, Vocab0, acquired from Corpus0.  
Iteration: For i = 1 to N, N = the number of 
partitions of the unsegmented corpus 
 i. Use Segmenteri-1 to segment Corpusi. 
 ii.  Acquire new stems from the newly 
segmented Corpusi. Add the new stems to 
Vocabi-1, creating an expanded vocabulary 
Vocabi.  
 iii. Develop Segmenteri trained on Corpus0 
through Corpusi with Vocabi.   
Optimal Performance Identification:  
Identify the Corpusi and Vocabi, which result 
in the best performance, i.e. system training 
with Corpusi+1 and Vocabi+1 does not improve 
the performance any more. 
  Unsupervised acquisition of new stems 
from an automatically segmented new corpus 
is a three-step process: (i)  select new stem 
candidates on the basis of a frequency 
threshold, (ii) filter out new stem candidates  
containing a sub-string with a high likelihood 
of being a prefix, suffix, or prefix-suffix. The 
likelihood of a sub-string being a prefix, suffix, 
and prefix-suffix of a token is computed as in  
(5) to (7), (iii) further filter out new stem 
candidates on the basis of contextual 
information, as in (8). 
 
(5)  Pscore = number of tokens with prefix P / 
number of tokens starting with sub-string P 
(6)  Sscore = number of tokens with suffix S / 
number of tokens ending with sub-string S 
(7)  PSscore = number of tokens with prefix P 
and suffix S / number of tokens starting with 
sub-string P and ending with  sub-string S 
 
Stem candidates containing a sub-string with a 
high prefix, suffix, or prefix-suffix likelihood 
are filtered out. Example sub-strings with the 
prefix, suffix, prefix-suffix likelihood 0.85 or 
higher in a 110K word manually segmented 
corpus are given in Table 4. If a token starts 
with the sub-string ???  (sn), and end with  ???  
(hA), the sub-string's likelihood of being the 
prefix-suffix of the token is 1.  If a token starts 
with the sub-string  ????  (ll), the sub-string's 
likelihood of being the prefix of the token is 
0.945, etc. 
 
        Arabic Transliteration      Score 
 ??? +  stem # ???     sn# stem+hA      1.0 
     ?+ stem # ?????  Al# stem+p      0.984        
         stem # ????   ll# stem      0.945 
  ??+  stem         stem+At      0.889 
    Table 4 Prefix/Suffix Likelihood Score 
 
 5
(8) Contextual Filter: (i) Filter out stems co-
occurring with prefixes/suffixes not present in 
the training corpus. (ii) Filter out stems whose 
prefix/suffix distributions are highly 
disproportionate to those seen in the training 
corpus.  
   According to (8), if a stem is followed by 
a potential suffix +m, not present in the 
training corpus, then it is filtered out as an 
illegitimate stem. In addition, if a stem is 
preceded by a prefix and/or followed by a 
suffix with a significantly higher proportion 
than that observed in the training corpus, it is 
filtered out. For instance, the probability for 
the suffix +A to follow a stem is less than 50% 
in the training corpus regardless of the stem 
properties, and therefore, if a candidate stem is 
followed by +A with the probability of over 
70%, e.g. mAnyl +A, then it is filtered out as 
an illegitimate stem. 
 
5  Performance Evaluations 
 
We present experimental results illustrating the 
impact of three factors on segmentation error 
rate: (i) the base algorithm, i.e. language model 
training and decoding, (ii) language model 
vocabulary and training corpus size, and (iii) 
manually segmented training corpus size.  
Segmentation error rate is defined in (9). 
 
(9)  (number of incorrectly segmented tokens /  
       total number of tokens)  x  100 
 
  Evaluations have been performed on a 
development test corpus containing 28,449 
word tokens.  The test set is extracted from 
20001115_AFP_ARB.0060.xml.txt through 
20001115_AFP_ARB.0236.xml.txt of the 
LDC Arabic Treebank: Part 1 v 2.0 Corpus. 
Impact of the core algorithm and the 
unsupervised stem acquisition has been 
measured on segmenters developed from 4 
different sizes of manually segmented seed 
corpora: 10K, 20K, 40K, and 110K words.    
  The experimental results are shown in 
Table 5. The baseline performances are 
obtained by assigning each token the most 
frequently occurring segmentation in the 
manually segmented training corpus. The 
column headed by '3-gram LM' indicates the 
impact of the segmenter using only trigram 
language model probabilities for decoding. 
Regardless of the manually segmented training 
corpus size, use of  trigram language model 
probabilities reduces the word error rate of the 
corresponding baseline by approximately 50%. 
The column headed by '3-gram LM + PS 
Filter' indicates the impact of the core 
algorithm plus Prefix-Suffix Filter discussed in 
Section 3.2.2. Prefix-Suffix Filter reduces the 
word error rate ranging from 7.4% for the 
smallest (10K word) manually segmented 
corpus to 21.8% for the largest (110K word) 
manually segmented corpus ?- around 1% 
absolute reduction for all segmenters. The 
column headed by '3-gram LM + PS Filter + 
New Stems' shows the impact of unsupervised 
stem acquisition from a 155 million word 
Arabic corpus.  Word error rate reduction due 
to the unsupervised stem acquisition is 38% for 
the segmenter developed from the 10K word 
manually segmented corpus and 32% for the 
segmenter developed from 110K word 
manually segmented corpus. 
  Language model vocabulary size (LM VOC 
Size) and the unknown stem ratio (OOV ratio) 
of various segmenters is given in Table 6. For 
unsupervised stem acquisition, we have set the 
frequency threshold at 10 for every 10-15 
million word corpus, i.e. any new morphemes 
occurring more than 10 times in a 10-15 
million word corpus are considered to be new 
stem candidates. Prefix, suffix, prefix-suffix 
likelihood score to further filter out illegitimate 
stem candidates was set at 0.5 for the 
segmenters developed from 10K, 20K, and 
40K manually segmented corpora, whereas it 
was set at 0.85 for the segmenters developed 
from a 110K manually segmented corpus.  
Both the frequency threshold and the optimal 
prefix, suffix, prefix-suffix likelihood scores 
were determined on empirical grounds. 
Contextual Filter stated in (8) has been applied 
only to the segmenter developed from 110K 
manually segmented training corpus.5 
Comparison of Tables 5 and 6 indicates a high 
correlation between the segmentation error rate 
and the unknown stem ratio.  
                                                          
5 Without the Contextual Filter, the  error rate of the 
same segmenter is 3.1%. 
 6
   
 
Manually Segmented 
Training Corpus Size 
      Baseline  3-gram LM  3-gram LM +  
PS Filter 
3-gram LM + PS 
Filter + New Stems 
        10K Words    26.0%        14.7%            13.6%          8.5% 
        20K Words       19.7%        9.1%            8.0%          5.9% 
        40K Words        14.3%        7.6%            6.5%          5.1% 
      110K Words        11.0%        5.5%            4.3%           2.9% 
Table 5 Impact of Core Algorithm and LM Vocabulary Size on Segmentation Error Rate 
 
                       3-gram LM  3-gram LM + PS Filter + New Stems Manually Segmented 
Training Corpus Size     LM VOC Size      OOV Ratio    LM VOC Size      OOV Ratio 
         10K Words           2,496          20.4%          22,964           7.8% 
         20K Words           4,111          11.4%          25,237           5.3% 
         40K Words           5,531            9.0%          21,156           4.7% 
       110K Words           8,196            5.8%          25,306           1.9% 
             Table 6 Language Model Vocabulary Size and Out of Vocabulary Ratio 
  
                                  3-gram LM + PS Filter + New Stems Manually Segmented 
Training Corpus Size   Unknown Stem          Alywm     Other Errors  Total # of Errors 
         10 K Words    1,844  (76.9%)        98 (4.1%)     455 (19.0%)          2,397 
         20 K Words    1,174  (71.1%)        82 (5.0%)     395 (23.9%)          1,651 
         40 K Words    1,005  (69.9%)        81 (5.6%)     351 (24.4%)          1,437 
       110 K Words       333  (39.6%)        82 (9.8%)     426 (50.7%)             841 
Table 7 Segmentation Error Analyses
  
Table 7 gives the error analyses of four 
segmenters according to three factors: (i) 
errors due to unknown stems, (ii) errors 
involving  ?????????? (Alywm), and (iii) errors due to 
other factors. Interestingly, the segmenter 
developed from a 110K manually segmented 
corpus has the lowest percentage of ?unknown 
stem? errors at 39.6% indicating that our 
unsupervised acquisition of new stems is 
working well, as well as suggesting to use a 
larger unsegmented corpus for unsupervised 
stem acquisition.  
    ?????????? (Alywm) should be segmented 
differently depending on its part-of-speech to 
capture the semantic ambiguities. If it is an 
adverb or a proper noun, it is segmented as 
 ?????????? 'today/Al-Youm', whereas if it is a noun, 
it is segmented as ?? # ??????   'the day.'  Proper 
segmentation of   ?????????? primarily requires its 
part-of-speech information, and cannot be 
easily handled by morpheme trigram models 
alone. 
  Other errors include over-segmentation of  
foreign words such as  ???????????????  (bwtyn) as  ?# 
 ??????????  and  ?????????????  (lytr)  'litre' as ? # ?# ????? .  
These errors are attributed to the segmentation 
ambiguities of these tokens:  ??????????????? is 
ambiguous between ' ??????????????? (Putin)' and '?# 
 ?????????? (by aorta)'.   ?????????????  is ambiguous 
between ' ????????????? (litre)' and ' ? # ?# ?????  (for him 
to harm)'. These errors may also be corrected 
by incorporating part-of-speech information 
for disambiguation. 
  To address the segmentation ambiguity 
problem, as illustrated by ' ??????????????? (Putin)' vs. 
' ? # ??????????  (by aorta)', we have developed a 
joint model for segmentation and part-of-
speech tagging for which the best 
segmentation of an input sentence is obtained 
according to the formula (10), where ti is the 
part-of-speech of morpheme mi, and N is the 
number of morphemes in the input sentence. 
 
(10) SEGMENTATIONbest = Argmax ?i=1,N  
p(mi|mi-1 mi-2) p(ti|ti-1 ti-2) p(mi|ti) 
 
By using the joint model, the segmentation 
word error rate of the best performing 
segmenter has been reduced by about 10% 
 7
from 2.9% (cf. the last column of Table 5) to 
2.6%. 
   
5  Summary and Future Work 
 
We have presented a robust word segmentation 
algorithm which segments a word into a 
prefix*-stem-suffix* sequence, along with 
experimental results. Our Arabic word 
segmentation system implementing the 
algorithm achieves around 97% segmentation 
accuracy on a development test corpus 
containing 28,449 word tokens. Since the 
algorithm can identify any number of prefixes 
and suffixes of a given token, it is generally 
applicable to various language families 
including agglutinative languages (Korean, 
Turkish, Finnish), highly inflected languages 
(Russian, Czech) as well as semitic languages 
(Arabic, Hebrew). 
   Our future work includes (i) application 
of the current technique to other highly 
inflected languages, (ii) application of the 
unsupervised stem acquisition technique on 
about 1 billion word unsegmented Arabic 
corpus, and (iii) adoption of a novel 
morphological analysis technique to handle 
irregular morphology, as realized in Arabic 
broken plurals  ????????? (ktAb) 'book' vs.  ???????? 
(ktb) 'books'. 
 
Acknowledgment 
 
This work was partially supported by the 
Defense Advanced Research Projects Agency 
and monitored by SPAWAR under contract No. 
N66001-99-2-8916. The views and findings 
contained in this material are those of the 
authors and do not necessarily reflect the 
position of policy of the Government and no 
official endorsement should be inferred. We 
would like to thank Martin Franz for discussions 
on language model building, and his help with 
the use of ViaVoice language model toolkit. 
 
References 
 
Beesley, K. 1996. Arabic Finite-State 
 Morphological Analysis and Generation. 
 Proceedings of COLING-96, pages 89?  94. 
Brown, P., Della Pietra, S., Della Pietra, V., 
 and Mercer, R. 1993. The mathematics  of 
 statistical machine translation:  Parameter 
 Estimation. Computational  Linguistics, 
 19(2): 263?311. 
Darwish, K. 2002. Building a Shallow  Arabic 
 Morphological Analyzer in  One  Day. 
 Proceedings of the  Workshop on 
 Computational  Approaches to Semitic 
 Languages,  pages 47?54.  
Franz, M. and McCarley, S. 2002. Arabic 
 Information Retrieval at IBM.  Proceedings 
 of TREC 2002, pages 402? 405. 
Goldsmith, J. 2000. Unsupervised  learning 
 of  the morphology of a natural  language.   
 Computational Linguistics, 27(1). 
Jelinek, F. 1997. Statistical Methods for 
 Speech Recognition. The MIT Press. 
Luo, X. and Roukos, S. 1996. An Iterative 
 Algorithm to Build Chinese Language 
 Models. Proceedings of ACL-96, pages 
 139?143. 
Schone, P. and Jurafsky, D. 2001. 
 Knowledge-Free Induction of  Inflectional 
 Morphologies. Proceedings  of  North 
 American Chapter of  Association for 
 Computational  Linguistics. 
Yarowsky, D. and Wicentowski, R. 2000. 
 Minimally supervised morphological 
 analysis by multimodal alignment. 
 Proceedings of ACL-2000, pages 207? 216. 
Yarowsky, D, Ngai G. and Wicentowski, R. 
 2001. Inducting Multilingual Text  Analysis 
 Tools via Robust Projection  across Aligned 
 Corpora. Proceedings of  HLT 2001, pages 
 161?168. 
 
 
 
 8
Interlingua-Based Broad-Coverage Korean-to-English 
Translation in CCLINC 
       Young-Suk Lee               Wu Sok Yi            Stephanie Seneff        Clifford J. Weinstein 
     MIT Lincoln Laboratory     MIT Lincoln Laboratory                 MIT/LCS                     MIT Lincoln Laboratory 
         244 Wood Street               244 Wood Street               77 Mass Avenue                     244 Wood Street 
     Lexington, MA 02420         Lexington, MA 02420      Cambridge, MA 02673             Lexington, MA 02420 
                U.S.A                                   U.S.A                                U.S.A                                       U.S.A 
         1-781-981-2703                 1-781-981-4609                1-617-254-0456             1-781-981-7621 
       YSL@LL.MIT.EDU           WUYI@LL.MIT.EDU     SENEFF@LCS.MIT.EDU          CJW@LL.MIT.EDU  
                    
  
ABSTRACT 
 
At MIT Lincoln Laboratory, we have been developing a Korean-
to-English machine translation system CCLINC (Common 
Coalition Language System at Lincoln Laboratory). The CCLINC 
Korean-to-English translation system  consists of two core 
modules, language understanding and generation modules 
mediated by a language neutral meaning representation called a 
semantic frame. The key features of the system include: (i) Robust 
efficient parsing of Korean (a verb final language with overt case 
markers, relatively free word order, and frequent omissions of 
arguments). (ii) High quality translation via word sense 
disambiguation and accurate word order generation of  the target 
language. (iii) Rapid system development and porting to new 
domains via knowledge-based automated acquisition of 
grammars. Having been trained on Korean newspaper articles on 
?missiles? and ?chemical biological warfare,? the system produces 
the translation output sufficient for content understanding of the 
original document. 
 
1. SYSTEM OVERVIEW 
 The CCLINC  The CCLINC Korean-to-English translation 
system is a component of the CCLINC Translingual Information 
System, the focus languages of which are English and Korean, 
[11,17]. Translingual Information System Structure is given in 
Figure 1.  
Given the input text or speech, the language understanding system 
parses the input, and transforms the parsing output into a language 
neutral meaning representation called a semantic frame, [16,17]. 
The semantic frame ? the key properties of which will be 
discussed in Section 2.3 ? becomes the input to the generation 
system. The generation system produces the target to the 
generation system, the semantic frame can be utilized for other 
applications such as translingual information extraction and 
 
 
 
 
  
language translation output after word order arrangement, 
vocabulary replacement, and the appropriate surface form 
realization in the target language, [6]. Besides serving as the input 
question-answering, [12].?  In this paper, we focus on the Korean-
to-English text  translation component of CCLINC.1 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1. CCLINC Translingual Information System 
Structure 
 
2. ROBUST PARSING, MEANING 
REPRESENTATION, AND AUTOMATED 
GRAMMAR ACQUISITION 
                                                                
? This work was sponsored by the Defense Advanced Research 
Project Agency under the contract number F19628-00-C-0002. 
Opinions, interpretations, conclusions, and recommendations 
are those of the authors and are not necessarily endorsed by the 
United States Air Force. 
1 For other approaches to Korean-to-English translation, the 
readers are referred to Korean-to-English translation by Egedi, 
Palmer, Park and Joshi 1994, a transfer-based approach using 
synchronous tree adjoining grammar, [5], and Dorr 1997, a 
small-scale interlingua-based approach, using Jackendoff?s 
lexical conceptual structure as the interlingua, [4]. 
  
OTHER LANGUAGES
SEMANTIC FRAMES
(COMMON
COALITION
LANGUAGE)
SEMANTIC FRAMES
(COMMON
COALITION
LANGUAGE)
UNDERSTANDINGUNDERSTANDING UNDERSTANDINGUNDERSTANDING
GENERATIONGENERATION GENERATIONGENERATION
C4I
INFORMATION
ACCESS
C4I
INFORMATION
ACCESS
ENGLISH
TEXT OR
SPEECH
KOREAN
TEXT OR
SPEECH
1.1 Robust Parsing 
The CCLINC parsing module, TINA [16], implements the top-
down chart parsing and the best-first search techniques, driven by 
context free grammars rules compiled into a recursive transition 
network augmented by features, [8]. The following properties of 
Korean induce a great degree of ambiguity in the grammar: (i) 
relatively free word order for arguments --- given a sentence with 
three arguments, subject, object, indirect object, all 6 logical word 
order permutations are possible in reality, (ii) frequent omissions 
of subjects and objects, and (iii) the strict verb finality, [10]. Due 
to the free word order and argument omissions, the first word of 
an input sentence can be many way ambiguous  --- it can be a part 
of a subject, an object, and any other post-positional phrases.2  
The ambiguity introduced by the first input word grows rapidly as 
the parser processes subsequent input words. Verbs,  which 
usually play a crucial role in reducing the ambiguity in English by 
the subcategorization frame information, are not available until 
the end, [1,3,11]. 
Our solution to the ambiguity problem lies in a novel grammar 
writing technique, which reduces the ambiguity of the first input 
word. We hypothesize that (i) the initial symbol in the grammar 
(i.e. Sentence) always starts with the single category generic_np, 
the grammatical function (subject, object) of which is 
undetermined. This ensures that the ambiguity of the first input 
word is reduced to the number of different ways the category 
generic_np can be rewritten. (ii) The grammatical function of the 
generic_np is determined after the parser processes the following 
case marker via a trace mechanism.3   
Figure 2 illustrates a set of sample context free grammar rules, and 
Figure 3 (on the next page) is a sample parse tree for the input 
sentence ?URi Ga EoRyeoUn MunJe Reul PulEox Da (We solved 
a difficult problem).?4 
 
(i)           sentence ? generic_np clause sentence_marker 
(ii) clause ? subject generic_np object verbs 
(iii) subject ? subj_marker np_trace 
Figure 2. Sample context free grammar rules for  Korean 
 
                                                                
2 Post-positional phrases in Korean correspond to pre-positional 
phrases in English. We use the term post-positional phrase to 
indicate that the function words at issue are located after the 
head noun. 
3 The hypothesis that all sentences start with a single category 
generic_np is clearly over simplified. We can easily find a 
sentence starting with other elements such as coordination 
markers which do not fall under generic_np.  For the sentences 
which do not start with the category generic_np, we discard 
these elements for parsing purposes. And this method has 
proven to be quite effective in the overall design of the 
translation system, especially due to the fact that most of  non 
generic_np sentence initial elements (e.g. coordination markers, 
adverbs, etc.) do not contribute to the core meaning of the input 
sentence.  
4 Throughout this paper, ?subj_marker? stands for ?subject 
marker?, and ?obj_marker?, ?object marker?. 
The generic_np dominated by the initial symbol sentence in (i) of 
Figure 2 is parsed as an element moved from the position 
occupied by np_trace in (iii), and therefore corresponds to the 
category np_trace dominated by subject in Figure 3 (placed on 
the next page for space reasons).  All of the subsequent 
generic_np?s, which are a part of a direct object, an indirect 
object, a post-positional phrase, etc. are unitarily handled by the 
same trace mechanism. By hypothesizing that all sentences start 
with generic_np, the system can parse Korean robustly and 
efficiently.  The trace mechanism determines the grammatical 
function of generic_np by repositioning it after the appropriate 
case marker. 
Utilization of overt case markers to improve the parsing efficiency 
precisely captures  the commonly shared intuition for parsing 
relatively free word order languages with overt case markers such 
as Korean and Japanese, compared with parsing relatively strict 
word order languages with no overt case markers such as English:  
In languages like English, the verb of a sentence plays the crucial 
role in reducing the ambiguity via the verb subcategorization 
frame information on the co-occuring noun phrases, [1,3,11].   In 
languages like Korean, however, it is typically the case marker 
which identifies the grammatical function of the co-occuring noun 
phrase, assuming the role similar to that of verbs in English.  The 
current proposal is the first explicit implementation of this 
intuition, instantiated by the novel idea that all noun phrases are 
moved out of  the case marked phrases immediately following 
them. 
 
2.2 Meaning Representation and Generation 
The CCLINC Korean-to-English translation system achieves high 
quality translation by (i) robust mapping of the parsing output into 
the semantic frame, and  (ii) word sense disambiguation on the 
basis of the selection preference between two grammatical 
relations (verb-object, subject-verb, head-modifier) easily 
identifiable from the semantic frame, [13].  The former facilitates 
the accurate word order generation of various target language 
sentences, and the latter, the accurate choice of the target language 
word given multiple translation candidates for the same source 
language word. Given the parsing output in Figure 3, the system 
produces the semantic frame in Figure 4:5 
 
                                                                
5 Strictly speaking, the meaning representation in Figure 4 is not 
truly language neutral in that the terminal vocabularies are 
represented in Korean rather than in interlingua vocabulary. It is 
fairly straightforward to adapt our system to produce the meaning 
representation with the terminal vocabularies specified by an 
interlingua.  However, we have made a deliberate decision to 
leave the Korean vocabularies in the representation largely (1) to 
retain the system efficiency for mapping parsing output into 
meaning representation, and (2) for unified execution of 
automation algorithms for both Korean-to-English and English-
to-Korean translation. And we would like to point out that this 
minor compromise in meaning representation still ensures the 
major benefit of interlingua approach to machine translation, 
namely, 2 x N sets of grammar rules for N language pairs, as 
opposed to 2N. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
          {c statement 
                        :topic {q  pronoun 
                 :name ?URi? } 
               :pred {p pul_v 
                              :topic {q problem 
               :name ?MunJe?  
                              :pred {p EoRyeoUn } } } 
 
Figure 4. Semantic Frame  for the input sentence ?URi Ga 
EoRyeoUn MunJe Reul PulEox Da.? 
The semantic frame captures the core predicate-argument 
structure of the input sentence in a hierarchical manner, [9,10] 
(i.e. the internal argument, typically object, is embedded under the 
verb, and the external argument, typically subject, is at the same 
hierarchy as the main predicate, i.e. verb phrase in syntactic 
terms). The predicate and the arguments along with their 
representation categories are bold-faced in Figure 4. With the 
semantic frame as input, the generation system generates the 
English translation using the grammar rules in (1), and the Korean 
paraphrase using the grammar rules in (2). 
The semantic frame captures the core predicate-argument 
structure of the input sentence in a hierarchical manner, [9,10] 
(i.e. the internal argument, typically object, is embedded under the 
verb, and the external argument, typically subject, is at the same 
hierarchy as the main predicate, i.e. verb phrase in syntactic 
terms). The predicate and the arguments along with their 
representation categories are bold-faced in Figure 4. With the 
semantic frame as input, the generation system generates the 
English translation using the grammar rules in (1), and the Korean 
paraphrase using the grammar rules in (2). 
(1)  a. statement :topic :predicate               
       b. pul_v  :predicate :topic 
(2) a. statement :topic :predicate 
      b. pul_v  :topic :predicate 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
(1b) and (2b) state that the topic category for the object follows 
the verb predicate in English, whereas it precedes the verb 
predicate in Korean. 
The predicate-argument structure also provides a means for word 
sense disambiguation, [13,15]. The verb pul_v is at least two-way 
ambiguous between  solve and  untie. Word sense disambiguation 
is performed by applying the rules, as in (3). 
 (3) a .pul_v   b .pul_v 
                   problem pul+solve_v     thread  pul+untie_v 
 
(3a) states that if the verb pul_v occurs with an object of type 
problem, it is disambiguated as pul+solve_v. (3b) states that the  
verb occurring with an object of type thread is disambiguated as 
pul+untie_v. The disambiguated verbs are translated into solve 
and untie, respectively, in the Korean-to-English translation 
lexicon. 
 
1.2 Knowledge-Based Automated Acquisition 
of Grammars 
To overcome the knowledge bottleneck for robust translation and 
efficient system porting in an interlingua-based system [7], we 
have developed a technique for automated acquisition of grammar 
rules which leads to a simultaneous acquisition of  rules for (i) the 
parser, (ii) the mapper between the parser and the semantic frame, 
and (iii) the generator. 
The technique utilizes a list of words and their corresponding 
parts-of-speech in the corpus as the knowledge source, 
presupposes a set of knowledge-based rules to be derived from a 
word and its part-of-speech pair, and gets executed according to 
the procedure given in Figure 5. The rationale behind the 
technique is that (i) given a word and its part-of-speech, most of 
the syntactic rules associated with the word can be automatically 
derived according to the projection principle (the syntactic 
subj_marker 
sentence 
clause sentence_marker 
subject object verbs 
np_trace obj_marker modifier np_trace 
noun adj noun verb 
statement 
Ga URi Reul EoRyeoUn MunJe PulEox Da 
Figure 1. Parse Tree for the Sentence URi Ga   EoRyeoUn MunJe    Reul PulEox 
representation must observe the subcategorization properties of 
each lexical item) and the X-bar schema (major syntactic 
categories such as N, V, Adj, Adv project to the same syntactic 
structures)  in linguistic theories, [2], and (ii) the mapping from 
the syntactic structure to the semantic frame representation is 
algorithmic. The specific rules to be acquired for a language 
largely depend on the grammar of the language  for parsing.  
Some example rules acquired for the verb BaiChiHa (arrange) in 
Korean ? consistent with the parsing technique discussed in 
Section 2.1 ?  are given in (4) through (7). 
 
Initialization: Create the list of words and their parts-of-speech in 
the corpus. 
Grammar Update: For each word and its associated part-of-
speech, check to see whether or not the word and the rules 
associated with the corresponding part-of-speech occur in each 
lexicon and grammar.  
 If they already occur, do nothing. 
 If not:  
(i) Create the appropriate rules and vocabulary items 
for  each entry. 
(ii) Insert the newly created rules and vocabulary items 
into the appropriate positions of the 
grammar/lexicon files for the parser, the grammar 
file for the mapper between the parser and  the 
semantic frame, and the grammar/lexicon files for 
the generator . 
 
Figure 5.  Automated Gammar Acquistion Procedure 
 
(4) Rules for the parser6 
.verbs 
[negation] vBaiChiHa [negation] [aspect] [tense] [auxiliary] 
[negation] [aspect] [tense] [and_verbs] [or_verbs] 
 
.vBaiChiHa 
#BaiChiHa 
 
(5) Rules for the mapper from the parser to the semantic frame 
.bachiha_v 
vBaiChiHa 
                                                                
6 The rules for the parser for the verb tell in English are given 
below, to illustrate the dependency of the rules acquired  to the 
specific implementation of the grammar of the language for 
parsing: 
   .vp_tell 
     vtell [adverb_phrase] dir_object [v_pp]  
 vtell [adverb_phrase] indir_object dir_object  
 vtell [adverb_phrase] dir_object v_to_pp [v_pp] 
 vtell [adverb_phrase] dir_object that_clause 
 vtell [and_verb] [or_verb] [adverb_phrase] dir_object wh_clause 
 
   The contrast in  complexity of verb rules in (4) for Korean, and (i) 
for English, reflects the relative importance of the role played by 
verbs for parsing in each language. That is, verbs play the minimal 
role in Korean, and the major role in English for ambiguity 
reduction and efficiency improvement. 
 
(6) Lexicon for the generation vocabulary 
baichiha_v V2 ?arrang? 
V2    V ?e? ING ?ing? PP ?ed? THIRD ?es? ROOT ?e? 
PAST ?ed? PASSIVE ?ed? 
 
(7) Rules for the generation grammar 
baichiha_v        :predicate :conj :topic :sub_clause 
np-baichiha_v   :noun_phrase :predicate :conj :topic :sub_clause 
 
The system presupposes the flat phrase structure for a sentence in 
Korean, as shown in Figure 3, and therefore the rules for the verbs 
do not require the verb subcategorization information, as in (4). 
The optional elements such as [negation], [tense], etc. are possible 
prefixes and suffixes to be attached to the verb stem, illustrating a 
fairly complex verb morphology in this language. The rules for 
the generation grammar in (7) are the subcategorization frames for 
the verb arrange in English, which is the translation of the 
Korean verb baichiha_v, as given in (6).   
The current technique is quite effective in expanding the system?s 
capability when there is no large syntatically annotated corpus 
available from which we can derive and train the grammar rules,  
[14], and applicable across languages in so far as the notion of 
part-of-speech, the projection principle and the X-bar schema is 
language independent.  With this technique, manual acquisition of 
the knowledge database for the overall translation system is 
reduced to the acquisition of  (i) the bilingual lexicon, and (ii) the 
corpus specific top-level grammar rules which constitute less than 
20% of the total grammar rules in our system. And this has 
enabled us to produce a fairly large-scale interlingua-based 
translation system within a short period of time.  One apparent 
limitation of  the technique, however, is that it still requires the 
manual acquisition of corpus-specific rules  (i.e. the patterns 
which do not fall under the linguistic generalization).  And we are 
currently developing a technique for automatically deriving 
grammar rules and obtaining the rule production probabilities 
from a syntactically annotated corpus. 
 
3. EVALUATION AND RESEARCH 
ISSUES 
We have trained the system with about 1,600 Korean newspaper 
articles on ?missiles? and ?chemical biological warfare?, as in 
Table 1. 
Table 1. Korean-to-English translation training data statistics 
# of 
articles 
# of  
sents/article 
# of 
words/sent 
# of distinct 
      words 
1,631           24 17 15,220 
 
For quality evaluation, we have adopted a 5-point scale evaluation 
score, defined as follows.  Score 4: Translation is both accurate 
and natural. Score 3: Translation is accurate with minor 
grammatical errors which do not affect the intended meaning of 
the input, e.g. morphological errors such as ?swam vs. swimmed.? 
Score 2: Translation is partially accurate, and sufficient for 
content understanding. Most errors are due to inaccurate word 
choice, inaccurate word order, and partial translation. Score 1: 
Translation is word-for-word, and partial content understanding is 
possible. Score 0: There is no translation output, or no content 
understanding is possible.  
We have performed the quality evaluation on 410 clauses from the 
training data, and 80 clauses from the test data. We have 
conducted the evaluation in 3 phases. Eval 1: Baseline evaluation 
after grammar and lexicon acquisition. Eval 2: Evaluation after 
augmenting word sense disambiguation rules. Eval 3: Evaluation 
after augmenting word sense disambiguation rules and accurate 
word order generation rules. The purpose of the 3-phase 
evaluation was to examine the contribution of parsing, word sense 
disambiguation and accurate word order generation to the overall 
translation quality. Once the score had been assigned to each 
clause, the translation score was obtained by the formula:  (Sum 
of  the scores for each clause *  25) / Number of clauses 
evaluated. 
Evaluation results are shown in Table 2 and Table 3 in terms of 
parsing coverage (P) and the translation score (T).7 
Table 2. Translation Quality Evaluation on Training Data 
            Eval 1             Eval 2             Eval 3 
       P         T        P        T         P        T 
      92      58        94       69       94      74 
 
Table 3. Translation Quality Evaluation on Test Data 
            Eval 1             Eval 2             Eval 3 
        P       T         P        T         P       T 
      79      55       89       63       89      65 
 
For both training and test data, the baseline translation quality 
score is over 50, sufficient for content understanding of the 
documents. Word sense disambiguation (Eval 1 vs. Eval 2) 
increases the translation score by about 10%, indicating that 
effective word sense disambiguation has a great potential for 
improving the translation quality.    
We would like to point out  that the evaluations reported in this 
paper are performed on clauses rather than sentences (which often 
consist of more than one clause).  In a very recent evaluation, we 
have found out that evaluations on sentences decrease the overall 
translation score about by 15.  Nevertheless, the translation 
quality is still good enough for content understanding with some 
effort.  The primary cause for the lower translation scores when 
the evaluation unit is a sentence as opposed to a clause is due to 
either an incorrect clause boundary identification, or some 
information (e.g. missing arguments in embedded clauses) which 
cannot be easily recovered after a sentence  is fragmented into 
clauses. This has led to the ability to handle complex sentences as 
                                                                
7 We would like to note that the evaluation reported here was a 
self-evaluation of the system by a system developer, primarily to 
identify the key research issues in system development. We will 
report evaluation results by non system developers who have no 
knowledge of  Korean in the future.  A system evaluation by  a 
non-bilingual speaker will avoid the issue of implicitly utilizing 
the knowledge  the  evaluator has about the source language in 
the evaluation process. 
the primary research issue, and we are working out the solution of 
utilizing syntactically annotated corpus for both grammar and 
probability acquisition, as discussed in Section 2.3. 
 
4. SUMMARY AND ONGOING WORK 
We have described the key features of the CCLINC interlingua-
based Korean-to-English translation system which is capable of 
translating a large quantity of Korean newspaper articles on 
missiles and chemical biological warfare in real time. Translation 
quality evaluations on the training and test data indicate that the 
current system produces translation sufficient for content 
understanding of a document in the training domains.  The key 
research issues identified from the evaluations include (i) parsing 
complex sentences, (ii) automated acquisition of word sense 
disambiguation rules from the training corpus,  and (iii) 
development of discourse module to identify the referents of 
missing arguments.  Our solution to the key technical challenges 
crucially draws upon the utilization of annotated corpora: For 
complex sentence parsing, we acquire both rules and rule 
production probabilities from syntactically annotated corpus. For 
automated word sense disambiguation, we utilize a sense-tagged 
corpus to identify various senses of a word, and obtain 
probabilities for word senses in various contexts.  For discourse 
understanding, we are developing an algorithm for our 2-way 
speech translation work, [12], and plan to expand the module for 
document translations. 
 
5. ACKNOWLEDGMENTS  
We would like to acknowledge Dr. Jun-Tae Yoon, who provided 
us with a high-quality robust Korean morphological analyzer 
called morany during his stay at the Institute for Research in 
Cognitive Science, University of Pennsylvania as a postdoctoral 
fellow. Morany has served as a pre-processor of the understanding 
module in the CCLINC Korean-to-English translation system. 
 
6. REFERENCES 
[1] Srinivas Bangalore and Aravind Joshi. ?Some Novel 
Applications of Explnation-Based Learning for Parsing 
Lexicalized Tree-Adjoining Grammars,? Proceedings of  33rd 
Association for Computational Linguistics.  pp. 268?275. 1995.  
[2] Noam Chomsky. Barriers.  Linguistic Inquiry Monograph 13. 
MIT Press, Cambridge, MA. 1986. 
[3] Michael Collins. Three Generative, Lexicalized Models for 
Statistical Parsing. Procceedings of the 35th Annual Meeting of 
ACL. pp. 16?23. Madrid, Spain. July. 1997. 
[4] Bonnie Dorr. ?LCS-based Korean Parsing and Translation,? 
Ms. Institute for Advanced Computer Studies and Department of 
Computer Science, University of Maryland. 1997. 
[5] Diana Egedi, Martha Palmer, H-S. Park, Aravind Joshi. 
?Korean to English Translation Using Synchronous TAGs,? 
Proceedings of  the First Conference of the Association for 
Machine Translation in the Americas. pp. 48?55. Columbia, 
Maryland. October 1994. 
[6] James Glass, Joe Polifroni and Stephanie Seneff. 
?Multilingual Language Generation across Multiple Domains,? 
Proceedings of International Conference on Spoken Language 
Processing, pp. 983?986. Yokohama, Japan. September, 1994. 
[7] W.J. Hutchins and H.L. Somers. An Introduction to Machine 
Translation. Academic Press. London. 1992. 
[8] James Allen. Natural Language Understanding, 2nd Edition. 
Benjamin-Cummings Publisher. 1995 
[9] Ken Hale. ?Preliminary Remarks on Configurationality,? 
Proceedings of NELS 12,  pp. 86?96. 1982. 
[10] Young-Suk Lee. Scrambling as Case-Driven Obligatory 
Movement. PhD Thesis (IRCS Report No.: 93-06 ). University of  
Pennsylvania. 1993. 
[11] Young-Suk Lee, Clifford Weinstein, Stephanie Seneff, 
Dinesh Tummala, ?Ambiguity Resolution for Machine 
Translation of  Telegraphic Messages,? Proceedings of  the 35th 
Annual Meeting of ACL. pp. 120?127. Madrid, Spain. July 1997. 
[12] Young-Suk Lee and Clifford Weinstein. ?An Integrated 
Approach to English-Korean Translation and Translingual 
Information Access,? Proceedings of CSTAR Workshop.  
Schwetzingen, Germany.  September, 1999. 
[13] Young-Suk Lee, Clifford Weinstein, Stephanie Seneff, 
Dinesh Tummala. ?Word Sense Disambiguation for Machine 
Translation in Limited Domains,? Manuscript. Information 
Systems Technology Group. MIT Lincoln Laboraotry. January 
1999. 
[14]  Mitch Marcus, Beatrice Santorini, and Mary Ann 
Marcinkiewicz. ?Building a large annotated corpus of English: the 
Penn Treebank,? Computational Linguistics 19 (2). pp. 313?
330. 1993. 
[15] Philip Resnik. ?Semantic Similarity in a Taxonomy: An 
Information-Based Measure and Its Application to Problems of 
Ambiguity in Natural Language,? Journal of Artificial 
Intelligence Research (JAIR) 11. pp. 95?130. 1999. 
[16] Stephanie Seneff. ?TINA: A Natural Language System for 
Spoken Language Applications,? Computational Linguistics 18 
(1). pp. 61?92. 1992. 
[17] Clifford Weinstein, Young-Suk Lee, Stephanie Seneff, 
Dinesh Tummala, Beth Carlson, John T. Lynch, Jung-Taik 
Hwang, Linda Kukolich. ?Automated English-Korean Translation 
for Enhanced Coalition Communications,? The Lincoln 
Laboratory Journal 10 (1).  pp. 35?60. 1997. 
 
 
 
 
 
 
Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 626?634,
Beijing, August 2010
Constituent Reordering and Syntax Models for English-to-
Japanese Statistical Machine Translation
Young-Suk Lee
IBM Research
ysuklee@us.ibm.com
Bing Zhao
IBM Research
zhaob@us.ibm.com
Xiaoqiang Luo
IBM Research
xiaoluo@us.ibm.com
Abstract
We present a constituent parsing-based
reordering technique that improves the
performance of the state-of-the-art Eng-
lish-to-Japanese phrase translation sys-
tem that includes distortion models by
4.76 BLEU points. The phrase transla-
tion model with reordering applied at the
pre-processing stage outperforms a syn-
tax-based translation system that incor-
porates a phrase translation model, a hi-
erarchical phrase-based translation
model and a tree-to-string grammar. We
also show that combining constituent re-
ordering and  the syntax model improves
the translation quality by additional  0.84
BLEU points.
1 Introduction
Since the seminal work by (Wu, 1997) and (Ya-
mada and Knight, 2001), there have been great
advances in syntax-based statistical machine
translation to accurately model the word order
distortion between the source and the target lan-
guages.
Compared with the IBM source-channel mod-
els (Brown et al, 1994) and the phrase transla-
tion models (Koehn et al, 2003), (Och and Ney,
2004) which are good at capturing local reorder-
ing within empirical phrases, syntax-based mod-
els have been effective in  capturing the long-
range reordering between language pairs with
very different word orders like Japanese-English
(Yamada and Knight, 2001), Chinese-English
(Chiang, 2005) and Urdu-English (Zollmann et
al. 2008), (Callison-Burch et al 2010).
 However, (Xu et al, 2009) show that apply-
ing dependency parsing-based reordering as pre-
processing (pre-ordering hereafter) to phrase
translation models produces translation qualities
significantly better than a hierarchical phrase-
based  translation model (Hiero hereafter) im-
plemented in (Zollman and Venugopal, 2006)
for English-to-Japanese translation. They also
report that the two models result in comparable
translation qualities for English-to-
Korean/Hindi/Turkish/Urdu, underpinning the
limitations of syntax-based models for handling
long-range reordering exhibited by the strictly
head-final Subject-Object-Verb (SOV) order
languages like Japanese and the largely head-
initial Subject-Verb-Object (SVO) order lan-
guages like English.
In this paper,  we present a novel constituent
parsing-based reordering technique that uses
manually written context free (CFG hereafter)
and context sensitive grammar (CSG hereafter)
rules. The technique improves the performance
of the state-of-the-art English-to-Japanese
phrase translation system that includes distortion
models by 4.76 BLEU points. The phrase trans-
lation model with constituent pre-ordering con-
sistently outperforms a syntax-based translation
system that integrates features from a phrase
translation model, Hiero and a tree-to-string
grammar. We also achieve an additional 0.84
BLEU point improvement by  applying an ex-
tended set of  reordering rules that incorporate
new rules learned from the syntax model for
decoding.
The rest of the paper is organized as follows.
In Section 2, we summarize  previous work re-
lated to this paper. In Section 3, we give an
overview of the syntax model with which we
compare the performance of a phrase translation
626
model with pre-ordering. We also discuss a
chart-based decoder used in all of our experi-
ments. In Section 4, we describe the constituent
parsing-based reordering rules. We show the
impact of pre-ordering on a phrase translation
model and compare its performance with the
syntax model. In Section 5, we discuss experi-
mental results from the combination of syntax
model and pre-ordering.  Finally in Section 6,
we discuss future work.
2 Related Work
Along the traditions of unsupervised learning by
(Wu, 1997), (Chiang, 2005) presents a model
that uses hierarchical phrases, Hiero.   The
model is a synchronous context free grammar
learned from a parallel corpus without any lin-
guistic annotations and is applied to Chinese-to-
English translation. (Galley and Manning, 2008)
propose a hierarchical phrase reordering model
that uses shift-reduce parsing.
In line with the syntax-based model of (Ya-
mada and Knight, 2001) that transforms a source
language parse tree into a target language string
for Japanese-English translation, linguistically
motivated syntactic features have been directly
incorporated into both modeling and decoding.
(Liu, et. al. 2006), (Zhao and Al-Onaizan, 2008)
propose a  source tree to target string grammar
(tree-to-string grammar hereafter) in order to
utilize the source language parsing information
for translation. (Liu, et. al. 2007) propose
packed forest to allow ambiguities in the source
structure for the tree-to-string grammar.  (Ding
and Palmer, 2005) and (Zhang et. al., 2006) pro-
pose a tree-to-tree grammar, which generates the
target tree structure from the high-precision
source syntax.  (Shen, et. al., 2008) propose a
string to dependency tree grammar to use the
target syntax when the target is English for
which parsing is more accurate than other lan-
guages.  (Marcu et al, 2006) introduce a syntax
model that uses syntactified target language
phrases. (Chang and Toutanova, 2007) propose a
global discriminative statistical word order
model that combines syntactic and surface
movement information, which improves  the
translation quality by 2.4 BLEU points in Eng-
lish-to-Japanese translation. (Zollmann, et. al.,
2008) compare various translation models and
report that the syntax augmented model works
better for Chinese-to-English and Urdu-to-
English, but not for Arabic-to-English transla-
tion. (Carreras and Collins, 2009) propose a
highly flexible reordering operations during tree
adjoining grammar parsing for German-English
translation. (Callison-Burch et al, 2010) report a
dramatic impact of syntactic translation models
on Urdu-to-English translation.
Besides the approaches which integrate  the
syntactic features into translation models, there
are approaches showing improvements via pre-
ordering for model training and decoding. (Xia
and McCord, 2004), (Collins et al, 2005) and
(Wang, et. al. 2007) apply pre-ordering to the
training data according to language-pair specific
reordering rules to improve the translation quali-
ties of French-English, German-English and
Chinese-English, respectively. (Habash, 2007)
uses syntactic preprocessing for Arabic-to-
English translation. (Xu et al, 2009) use a de-
pendency parsing-based pre-ordering to improve
translation qualities of English to five SOV lan-
guages including Japanese.
The current work is related to (Xu et al,
2009) in terms of the language pair and transla-
tion models explored. However, we use con-
stituent parsing with hierarchical rules, while
(Xu et al, 2009) use dependency parsing with
precedence rules. The two approaches have dif-
ferent rule coverage and result in different word
orders especially for phrases headed by verbs
and prepositions. We also present techniques for
combining the syntax model with tree-to-string
grammar and pre-ordering for additional per-
formance improvement. The total  improvement
by the current techniques over the state-of-the-
art phrase translation model is  5.6 BLEU points,
which is an improvement gap not attested else-
where with reordering approaches.
3 Syntax Model and Chart-Based De-
coder
In this section, we give an overview of  the syn-
tax model incorporating a tree-to-string gram-
mar.  We will compare  the syntax model per-
formance with  a phrase translation model that
uses the pre-ordering technique we propose in
Section 4. We also describe the chart-based de-
coder that we use in all of the experiments re-
ported in this paper.
627
3.1 Tree-to-String Grammar
Tree-to-string grammar utilizes the source lan-
guage parse to model reordering probabilities
from a source tree to the target string (Liu et. al.,
2006), (Liu et. al., 2007), (Zhao and Al-
Onaizan, 2008) so that long distance word reor-
dering becomes local in the parse tree.
Reordering patterns of the source language
syntax and their probabilities are automatically
learned from the word-aligned source-parsed
parallel data and incorporated as a tree-to-string
grammar for decoding.  Source side parsing and
the resulting reordering patterns bound the
search space. Parsing also assigns linguistic la-
bels to the chunk, e.g. NP-SBJ, and allows sta-
tistics to be clustered reasonably.   Each syn-
chronous context free grammar (SCFG) rewrit-
ing rule rewrites a source treelet into a target
string, with both sides containing hiero-style
variables.  For instance, the rule [X, VP] [X,
VB] [X,NP] ? [X, NP] [X, VB] rewrites a VP
with two constituents VB and NP  into an NP
VB order in the target, shown below.
The tree-to-string grammar introduces possible
search space to generate an accurate word order,
which is refined on the basis of supports from
other models. However, if the correct word or-
der cannot be generated by the tree-to-string
grammar, the system can resort to rules from
Hiero or a phrase translation model for extended
rule coverage.
3.2 Chart-based Decoder
We use a  chart-based decoder ? a template de-
coder that generalizes over various decoding
schemes in terms of the dot-product in Earley-
style parsing (Earley, 1970) ? to support various
decoding schemes such as phrase, Hiero
(Chiang, 2005), Tree-to-String, and the mixture
of all of the above.
This framework allows one to strictly com-
pare different decoding schemes using the same
feature and parameter setups. For the experi-
mental results in Sections 4 & 5, we applied (1)
phrase decoding for the baseline phrase transla-
tion system that includes distortion models, (2)
Hiero decoding for the Hiero system that incor-
porates a phrase translation model, and (3)
Tree-to-string decoding for the syntax-based
systems that incorporate features  from phrase
translation, Hiero and tree-to-string grammar
models.
The decoder seeks the best hypothesis *e  ac-
cording to the Bayesian decision rule (1):
)1()()(minarg*
},{
dee
Dde
?? ??
?
d is one derivation path, rewriting the source
tree into the target string via the probabilistic
synchronous context free tree-to-string grammar
(PSCFG). )(e? is the cost functions computed
from general n-gram language models. In this
work, we use two sets of interpolated 5-gram
language models. )(d? is a vector of cost func-
tions defined on the derivation sequence. We
have integrated  18 cost functions ranging  from
the basic relative frequencies and IBM model-1
scores to counters for different types of rules
including blocks, glue, Hiero, and tree-to-string
grammar rules.  Additional cost functions are
also integrated into the decoder, including meas-
uring the function/content-word mismatch be-
tween source and target, similar to (Chiang et.
al., 2009) and length distribution for non-
terminals in (Shen et. al., 2009).
4 Parsing and Reordering Rules
We apply a set of manually acquired reordering
rules to the parsing output from a constituent
parser to pre-order the data for model training
and decoding.
4.1 Parsing with Functional Tags
We use a maximum entropy English parser (Rat-
naparkhi, 1999) trained on OntoNotes (Hovy,
2006) data. OntoNotes data include most of the
Wall Street Journal data in Penn Treebank
(Marcus et al, 1993) and additional data from
broadcast conversation, broadcast news and web
log.
S
NP-SBJ
X1
X2
VP
VB
X3
NP
X1 X3 X2
Src treelet
Tgt string
628
Figure 1. Parse Tree and Word Alignment before Reordering
Figure 2. Parse Tree and Word Alignment after Reordering
The parser is trained with all of the functional
and part-of-speech (POS)  tags in the original
distribution: total 59 POS tags and 364 phrase
labels.
We use functional tags since reordering de-
cisions for machine translation are highly in-
fluenced by the function of a phrase, as will be
shown later in this section. An example parse
tree with functional tags is given at the top half
of  Figure 1. NP-SBJ indicates a subject noun
phrase, SBAR-ADV, an adverbial clause.
4.2 Structural Divergence between Eng-
lish and Japanese
Japanese is a strictly head-final language, i.e.
the head is located at the end of  a phrase.
This leads to  a high degree of distortions with
English, which is largely head initial.
SBAR-ADV
S
VP
VBN
IN
NP-SBJ
PRP
VP
VP
NP VB
NP VP
DT NNS VBN
PP
NP
DT NN
IN
MD
NN
NP-SBJ
PRP
VP
MD VP
VB NP
NP VP
DT NNS VBN PP
S
IN NP
DT NN
SBAR-ADV
IN S
VP
VBN
you           must       undo   the        changes     made      by        that     installation         if        needed
??? ??? , ?? ?????? ? ?? ?? ? ?? ?? ??? ?? ??
needed if you sbj  the changes that  installation by  made undo     must
S
??? ??? , ?? ?????? ? ?? ?? ? ?? ?? ??? ?? ??
629
The word order contrast between the two
languages is illustrated by the human word
alignment at the bottom half of Figure 1. All
instances of word alignments are non-
monotonic except for the sequence that installa-
tion, which is monotonically aligned to the
Japanese morpheme sequence ??
??????.  Note that there are no word
boundaries in Japanese written text, and we ap-
ply Japanese morpheme segmentation to obtain
morpheme sequences in the figure. All of the
Japanese examples in this paper are presented
with morpheme segmentation.
The manual reordering rules are written by a
person who is proficient with English and Japa-
nese/Korean grammars, mostly on the basis of
perusing parsed English texts.
4.3 CFG Reordering Rules
Our reordering rules are mostly CFG rules and
divided into head and modifier  rules.
Head reordering rules in Table 1 move verbs
and prepositions from the phrase initial to the
phrase final positions (Rules 1-11). Reordering
of the head phrase in an adverbial clause also
belongs to this group (Rules 12-14). The label
sequences in Before RO and After RO are the
immediate children of the Parent Node before
and after reordering. VBX stands for VB, VBZ,
VBP, VBD, VBN and VBG. XP+ stands for one
or more POS and/or phrase labels such as MD,
VBX, NP, PP, VP, etc.  In 2 & 4, RB is  the tag
for negation not. In 5, RP is the tag for a verb
particle.
Modifier reordering rules in Table 2 move
modified phrases from the phrase initial to the
phrase final positions within an NP (Rules 1-3).
They also include placement of NP, PP, ADVP
within a VP (Rules 4 & 5).  The subscripts in a
rule, e.g. PP1 and PP2 in Rule 3, indicate the
distinctness of each phrase sharing the same
label.
4.4 CSG Reordering Rules
Some reordering rules cannot be captured by
CFG rules, and we resort to CSG rules.1
1 These CSG rules apply to trees of depth two or more, and
the applications are dependent on surrounding contexts.
Therefore,  they are different from CFG rules which apply
only to trees of depth one, and TSG (tree substitution
grammar) rules for which variables are independently
substituted by substitution. The readers are referred to
Parent Node Before RO After RO
1 VP MD VP VP MD
2 VP MD RB VP VP MD RB
3 VP VBX XP+ XP+ VBX
4 VP VBX RB XP+ XP+ VBX RB
5 VP VBX RP XP+ XP+ VBX RP
6 ADJP-PRD JJ XP+ XP+ JJ
7 PP IN NP NP IN
8 PP IN S S IN
9 SBAR-TMP IN S S IN
10 SBAR-ADV IN S S IN
11 SBAR-PRP IN S S IN
12 SBAR-TMP WHADVP S S WHADVP
13 SBAR-ADV WHADVP S S WHADVP
14 SBAR-PRP WHADVP S S WHADVP
Table 1. Head Reordering Rules
Parent
Node
Before RO After RO
1 NP NP SBAR SBAR NP
2 NP NP PP PP NP
3 NP NP PP1 PP2 PP1 PP2 NP
4 VP VBX NP PP PP NP VBX
5 VP VBX NP ADVP-
TMP PP
PP NP ADVP-
TMP VBX
Table 2. Modifier Reordering Rules
For instance, in the parse tree and word
alignment in Figure 1,  the last two English
words if needed under SBAR-ADV is aligned to
the first  two Japanese words ??? ???.
In order to change the English order to the cor-
responding Japanese order, SBAR-ADV domi-
nated by the VP should move across the VP to
sentence initial position, as shown in the top
half of Figure 2,  requiring a CSG rule.
The adverbial clause reordering in Figure 2 is
denoted as Rule 1 in Table 3, which lists two
other CSG rules, Rule 2 & 3.2  The subscripts in
Table 3 are interpreted in the same way as those
in Table 2.
(Joshi and Schabes, 1997) for formal definitions of various
grammar formalisms.
2
 Rule 3 is applied after all CFG rules, see Section 4.6.
Therefore, VBX?s are located at the end of each corre-
sponding VP.
630
Before  RO ? After RO
1 (S XP1+ (VP XP2+ SBAR-ADV ))? (S SBAR-ADV XP1 + (VP XP2+ ))
2 (S XP1+ (VP (XP2+ SBAR-ADV )))? (S XP1+ SBAR-ADV (VP (XP2 + )))
3 (VP1 ADVP-MNR (VP2 XP+ VBX2 ) VBX1)?(VP1 (VP2 XP+ ADVP-MNR VBX2) VBX1)
Table 3. CSG Reordering Rules
ADVP-MNR stands for a manner adverbial
phrase such as explicitly in the following: The
software version has been explicitly verified as
working. Rule 3 in Table 3 indicates that a
ADVP-MNR has to immediately precede a verb
in Japanese, resulting in the substring ?...as
working explicitly verified...? after reordering.
Note that functional tags allow us to write re-
ordering rules specific to  semantic phrases. For
instance, in Rule 1, SBAR-ADV under VP
moves to the sentence initial position under S,
but an SBAR without any functional tags do
not. It typically stays within a VP as the com-
plement of the verb.
4.5 Subject Marker Insertion
Japanese extensively uses case particles that
denote the role of the preceding noun phrase,
for example,  as subject, object, etc.  We insert
sbj, denoting the subject marker, at the end of a
subject noun phrase NP-SBJ. The inserted sub-
ject marker sbj mostly gets translated into the
subject particle? or? in Japanese.3
4.6 Reordering Rule Application
The rules are applied categorically, sequentially
and recursively. CSG Rules 1 and 2 in Table 3
are applied before all of the CFG rules. Among
CFG rules, the modifier rules in Table 2 are
applied before the head rules in Table 1. CSG
Rule 3 in Table 3 is applied last,  followed by
the subject marker insertion operation.
CFG head and modifier rules are applied re-
cursively.  The top half of Figure 2 is the parse
tree obtained by applying reordering rules to the
parse tree in Figure 1. After reordering, the
word alignment becomes mostly monotonic, as
shown at the bottom half of Figure 2.
3 The subject marker insertion is analogous to the insertion
operation  in (Yamada and Knight, 2001), which covers a
wide range of insertion of case particles and verb inflec-
tions in general.
4.7 Experimental Results
All systems are trained on a parallel corpus,
primarily from the Information Technology (IT)
domain and evaluated on the data from the same
domain. The training data statistics is in Table 4
and the evaluation data statistics is in Table 5.
Japanese tokens are morphemes and English
tokens are punctuation tokenized words.
Corpus Stats English Japanese
sentence count 3,358,635 3,358,635
token count 57,231,649 68,725,865
vocabulary size 242,712 348,221
    Table 4. Training Corpus Statistics
Data Sets Sentence Count Token Count
Tuning 600 11,761
DevTest 437 8,158
Eval 600 11,463
Table 5. Evaluation Data Statistics
We measure the translation quality with IBM
BLEU (Papineni et al, 2002) up to 4 grams,
using 2 reference translations, BLEUr2n4. For
BLEU score computation, we character-
segment Kanji and Kana sequences in the refer-
ence and the machine translation output.   Vari-
ous system performances are shown in Table 6.
Models Tuning DevTest Eval
Phrase (BL) 0.5102 0.5330 0.5486
Hiero 0.5385 0.5574 0.5724
Syntax 0.5561 0.5777 0.5863
Phrase+RO1 0.5681 0.5793 0.5962
Table 6. Model Performances (BLEUr2n4)
Phrase (BL) is the baseline phrase translation
system that  incorporates lexical distortion
models (Al-Onaizan and Papineni, 2006).
Hiero is the hierarchical phrase-based system
(Chiang, 2006) that incorporates the phrase
translation model. Syntax is the syntax model
described in Section 3, which incorporates the
phrase translation, Hiero and tree-to-string
grammar models. Phrase+RO1 is the phrase
translation model with pre-ordering  for system
training and decoding,  using the rules described
in this section. Phrase+RO1 improves the trans-
lation quality of the baseline model by 4.76
BLEU points and outperforms the syntax model
by over 0.9 BLEU points.
631
5 Constituent Reordering and Syntax
Model Combined
Translation qualities of systems that combine
the syntax model and pre-ordering are shown in
Table 7. Syntax+RO1 indicates the  syntax
model with pre-ordering discussed in Section 4.
Syntax+RO2 indicates the syntax model with a
more extensive pre-ordering for decoding dis-
cussed below .
Models Tuning DevTest Eval
Phrase+RO1 0.5681 0.5793 0.5962
Syntax+RO1 0.5742 0.5802 0.6003
Syntax+RO2 0.5769 0.5880 0.6046
Table 7. Syntax Model with Pre-ordering
Analyses of the syntax model in Table 6 re-
vealed that automatically learned rules by the
tree-to-string grammar include new rules not
covered by the manually written rules,  some of
which are shown in Table 8.
Parent  Node Before  RO After RO
ADJP-PRD RB JJ PP PP RB JJ
ADVP-TMP RB PP PP RB
ADVP ADVP PP PP ADVP
NP NP VP VP NP
Table 8. New CFG rules automatically learned
by Tree-to-String grammar
We augment the manual rules with the new
automatically learned  rules. We call this ex-
tended set of reordering rules RO2. We use the
manual reordering rules RO1 for model train-
ing, but use the extended rules RO2 for decod-
ing. And we obtain the translation output Syn-
tax+RO2 in Table 7.  Syntax+RO2 outperforms
Phrase+RO1 by 0.84 BLEU points, and Syn-
tax+RO1 by 0.43 BLEU points.
In Table 9, we show the ratio of each rule
type preserved in the derivation of one-best
translation output of the following two models:
Syntax  and Syntax+RO2.  In the table,
?Blocks? indicate phrases from the phrase trans-
lation model and ?Glue Rules? denote the de-
fault grammar rule for monotone decoding.
The syntax model without pre-ordering (Syn-
tax) heavily utilizes the Hiero and tree-to-string
grammar rules, whereas the syntax model with
pre-ordering (Syntax+RO2) mostly depends on
monotone decoding with blocks and glue rules.
Rule Type Syntax Syntax+RO2
Blocks 46.3% 51.2%
Glue Rules  6.0% 37.3%
Hiero Rules 18.3%   1.3%
Tree-to-String 29.4% 10.2%
Table 9. Ratio of each rule type preserved in the
translation derivation of Syntax and Syn-
tax+RO2
6 Summary and Future Research
We have proposed a constituent pre-ordering
technique for English-to-Japanese translation.
The technique improves the performance of the
state-of-the-art phrase translation models by
4.76 BLEU points and outperforms a syntax-
based translation system that incorporates a
phrase translation model, Hiero and a tree-to-
string grammar. We have also shown that com-
bining constituent pre-ordering and  the syntax
model improves the translation quality by addi-
tional  0.84 BLEU points.
While achieving solid performance im-
provement over the existing translation models
for English-to-Japanese translation, our work
has revealed some limitations of syntax models
both in terms of grammar representations and
modeling.  Whereas many syntax models are
based on CFG rules for probability acquisition,
the current research shows that there are various
types of reordering that require the generative
capacity beyond CFG.  While most of the reor-
dering rules for changing the English order to
the Japanese order (and vice versa) should ap-
ply categorically,4 often the probabilities of
tree-to-string grammar rules are not high
enough to survive in the translation derivations.
As for the reordering rules that require the
generative capacity beyond CFG, we may
model mildly context sensitive grammars such
as tree adjoining grammars (Joshi and Schabes,
1997), as in (Carreras and Collins, 2009). The
4 Assuming that the parses are correct, the head reordering
rules in Table 1 have to apply categorically to change the
English order into the Japanese order because English is
head initial and Japanese is head final without any excep-
tions. Similarly, most of the modifier reordering rules in
Table 2 have to apply categorically because most modifi-
ers follow the modified head phrase in English, e.g. a rela-
tive clause modifier follows the head noun phrase, a
prepositional phrase modifier follows the head noun
phrase, etc., whereas modifier phrases precede the modi-
fied head phrases in Japanese.
632
extended domain of locality of  tree adjoining
grammars should suffice to capture non-CFG
reordering rules for many language pairs. Alter-
natively, we can adopt enriched feature repre-
sentations so that  a tree of depth one can actu-
ally convey information on a tree of several
depths, such as parent annotation of (Klein and
Manning, 2003).
Regarding the issue of modeling, we can in-
troduce a rich set of features, as in (Ittycheriah
and Roukos, 2007), the weights of which are
trained to ensure that the tree-to-string grammar
rules generating the accurate target orders are
assigned probabilities high enough not to get
pruned out  in the translation derivation.
Acknowledgement
We would like to acknowledge IBM RTTS
(Realtime Translation Systems) team for tech-
nical discussions on the topic and the provision
of linguistic resources. We also would like to
thank IBM SMT (Statistical Machine Transla-
tion) team for various software tools and the
anonymous reviewers for their helpful com-
ments .
References
Y. Al-Onaizan and K. Papineni. 2006.  Distortion
models for statistical machine translation. Pro-
ceedings of ACL-COLING. Pages 529-536.
C. Baker, S. Bethard, M. Bloodgood, R. Brown, C.
Callison-Burch, G. Coppersmith, B. Dorr, W. Fi-
lardo, K. Giles, A. Irvine, M. Kayser, L. Levin, J.
Martineau, J. Mayfield, S. Miller, A. Phillips, A.
Philpot, C. Piatko, L. Schwartz, D. Zajic. 2010.
Semantically Informed Machine Translation
(SIMT). Final Report of the 2009 Summer Camp
for Applied Language Exploration.
P. Brown, V. Della Pietra, S. Della Pietra, and R.
Mercer. 1993. The mathematics of statistical ma-
chine translation: parameter estimation, Computa-
tional Linguistics, 19(2):263?311.
X. Carreras and M. Collins. 2009. Non-projective
parsing for statistical machine translation. Pro-
ceedings of the 2009 EMNLP. Pages 200-209.
P. Chang and C. Toutanova. 2007.  A Discriminative
Syntactic Word Order Model for Machine Trans-
lation. Proceedings of ACL. Pages 9-16.
D. Chiang. 2005. A Hierarchical Phrase-Based
Model for Statistical Machine Translation. Pro-
ceedings of ACL. Pages 263-270.
D. Chiang, W. Wang and  Kevin Knight. 2009.
11,001 new features for statistical machine trans-
lation. Proceedings of HLT-NAACL. Pages 218-
226.
M. Collins, P. Koehn, I. Kucerova. 2005. Clause
Restructuring for Statistical Machine Translation.
Proceedings of  ACL. Pages 531-540.
Y. Ding and M. Palmer. 2005. Machine translation
using probabilistic synchronous dependency in-
sertion grammars. Proceedings of ACL. Pages
541-548.
J. Earley. 1970. An efficient context-free parsing
algorithm. Communications of the ACM. Vol. 13.
Pages 94?102.
M. Galley and C. Manning. 2008. A Simple and Ef-
fective Hierarchical Phrase Reordering Model.
Proceedings of EMNLP.
N. Habash. 2007. Syntactic Preprocessing for Statis-
tical Machine Translation. Proceedings of the
Machine Translation Summit.
E. Hovy, M. Marcus, M. Palmer, L. Ramshaw and
R. Weischedel. 2006. OntoNotes: The 90% Solu-
tion. Proceedings of HLT. Pages 57-60.
A. Ittycheriah and S. Roukos. 2007. Direct Transla-
tion Model 2. Proceedings of HLT-NAACL.
A. Joshi and Y. Schabes. 1997.  Tree-adjoining
grammars. In G. Rozenberg and K. Salomaa, edi-
tors, Handbook of Formal Languages, volume 3.
Springer.
D. Klein and C. Manning. 2003.  Accurate Unlexi-
calized Parsing. Proceedings of 41st ACL.
P. Koehn, F. J. Och, and D. Marcu. 2003. Statistical
phrase-based translation, Proceedings of
HLT?NAACL. Pages 48?54.
Y. Liu, Q. Liu and S. Lin. 2006. Tree-to-string
alignment template for statistical machine transla-
tion. Proceedings of ACL-COLING.
Y. Liu, Y. Huang, Q. Liu, and S. Lin. 2007. Forest-
to-string statistical translation rules. Proceedings
of the 45th ACL.
D. Marcu, W. Wang, A. Echihabi and K. Knight.
2006. SPMT: Statistical Machine Translation with
Syntactified Target Language Phrases. Proceed-
ings of EMNLP. Pages 44-52.
M. Marcus, B. Santorini and M.  Marcinkiewicz.
1993. Building a Large Annotated Corpus of Eng-
633
lish: the Penn Treebank. Computational Linguis-
tics,  19(2):  313-330.
F. J. Och and H. Ney. 2004. The alignment template
approach to statistical machine translation. Com-
putational Linguistics: Vol. 30.  Pages 417? 449.
K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002.
Bleu: a method for automatic evaluation of ma-
chine translation. Proceddings  of ACL. Pages
311?318.
A. Ratnaparkhi. 1999. Learning to Parse Natural
Language with Maximum Entropy Models. Ma-
chine Learning: Vol. 34. Pages 151-178.
L. Shen, J. Xu and R. Weischedel. 2008. A new
string-to-dependency machine translation algo-
rithm with a target dependency language model.
Proceedings of ACL.
L. Shen, J. Xu, B. Zhang, S. Matsoukas and Ralph
Weischedel. 2009. Effective Use of Linguistic
and Contextual Information for Statistical Ma-
chine Translation. Proceedings of EMNLP.
C. Wang, M. Collins, P. Koehn. 2007. Chinese Syn-
tactic Reordering for Statistical Machine Transla-
tion. Proceedings of EMNLP-CoNLL.
D. Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel cor-
pora. Computational Linguistics, 23(3): 377-404.
F. Xia and M. McCord. 2004. Improving a Statistical
MT System with Automatically Learned Rewrite
Patterns. Proceedings of COLING.
P. Xu, J. Kang, M. Ringgaard, F. Och. 2009. Using a
dependency parser to improve SMT for subject-
verb-object languages. Proceedings of HLT-
NAACL.
K. Yamada and K. Knight.  2001. A Syntax-based
Statistical Translation Model. Proceedings of the
39th ACL. Pages 523-530.
H. Zhang, L. Huang, D. Gildea and K. Knight.
2006.  Synchronous binarization for machine
translation. Proceedings of the HLT-NAACL.
Pages 256-263.
B. Zhao and Y. Al-onaizan. 2008. Generalizing Lo-
cal and Non-Local Word-Reordering Patterns for
Syntax-Based Machine Translation. Proceedings
of EMNLP. Pages 572-581.
A. Zollmann and A. Venugopal. 2006. Syntax aug-
mented machine translation via chart parsing.
Proceedings of NAACL 2006 -Workshop on sta-
tistical machine  translation.
A. Zollmann, A. Venugopal, F. Och and J. Ponte.
2008. A Systematic Comparison of Phrase-Based,
Hierarchical and Syntax-Augmented MT. Pro-
ceedings of COLING.
634
Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 433?443, Dublin, Ireland, August 23-29 2014.
Confusion Network for Arabic Name Disambiguation and Translitera-
tion in Statistical Machine Translation
Young-Suk Lee
IBM T. J. Watson Research Center
1101 Kitchawan Road
Yorktown Heights, NY 10598, USA
ysuklee@us.ibm.com
Abstract
Arabic words are often ambiguous between name and non-name interpretations, frequently
leading to incorrect name translations. We present a technique to disambiguate and transliter-
ate names even if name interpretations do not exist or have relatively low probability distribu-
tions in the parallel training corpus. The key idea comprises named entity classing at the pre-
processing step, decoding of a simple confusion network created from the name class label and
the input word at the statistical machine translation step, and transliteration of names at the
post-processing step. Human evaluations indicate that the proposed technique leads to a statis-
tically significant translation quality improvement of highly ambiguous evaluation data sets
without degrading the translation quality of a data set with very few names.
1 Introduction
Arabic person and location names are often ambiguous between name and non-name interpretations,
as noted in (Hermjakob et al., 2008; Zayed et al., 2013).  (1) and (2) illustrate such ambiguities for
Iraqi Arabic, where the ambiguous names and their translations are in bold-face and the Buckwalter
transliteration of  Arabic is provided in parentheses:1
(1) a. ???????? ???? ???? ?? ??????? ?
(Any sAkn b$qp ym Almdrsp bxDrA')
I live in an apartment near the school in Khadraa
b. ????? ??????
(mSbwgp xDrA')
It is painted green
(2) a.  ???? ????????????
($yqdr SbAH yqwl Alk)
What can Sabah tell you?
b. ????? ??? ???? ???? ????????
(SbAH Alxyr Ant Akyd nqyb HsAm)
Good morning you must be captain Hosam
In this paper, we propose a technique for disambiguating and transliterating Arabic names in an
end-to-end statistical machine translation system. The key idea lies in name classing at the pre-
processing step, decoding of a simple confusion network created from the class label $name, and the
input word at the machine translation step, and transliteration of names by a character-based phrase
transliteration model at the post-processing step.
While Bertoldi et al. (2007) propose confusion network decoding to handle multiple speech recog-
nition outputs for phrase translation and Dyer et al. (2008) generalize lattice decoding algorithm to
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
1Arabic should be read from right to left, and the Buckwalter transliteration should be read from left to right.
433
tackle word segmentation ambiguities for hierarchical phrase-based translation, the current proposal is
the first to deploy a confusion network for name disambiguation and translation. The character-based
phrase transliteration model captures the asymmetry between Arabic and English vowel systems by
treating English vowels as spontaneous words attachable to the neighboring target phrases for phrase
(a sequence of characters) acquisition.
Confusion network decoding enables the system to choose between name and other translations of
the source word on the basis of the decoding cost computed from all of the decoder feature functions
which incorporate name tag scores into translation model scores. Probabilistic choice between name
versus non-name interpretations makes the technique robust to name classing errors, without stipulat-
ing the frequency threshold of the names to be transliterated in order to avoid translation quality deg-
radation (Hermjakob et al., 2008; Li et al., 2013). A tight integration of named entity detection and
classing into the machine translation system, coupled with a generative approach to name translitera-
tion, enables the system to produce reliable name translations even when name interpretations do not
exist or have relatively low distributions in the parallel corpus, distinguishing the current proposal
from Hermjakob et al. (2008).
In Section 2, we give an overview of the translation system. In Section 3, we discuss the model
training and confusion network decoding. In Section 4, we detail name transliteration model. We pre-
sent the experimental results in Section 5. We discuss related work in Section 6 and conclude the pa-
per in Section 7.
2 End-to-end Translation System Overview
Arabic name disambiguation and transliteration techniques are incorporated into an end-to-end phrase
translation system (Och and Ney, 2002; Koehn et al., 2003; Koehn et al., 2007). Our phrase translation
system builds on Tillmann (2003) for translation model training and an in-house implementation of
Ney and Tillmann (2003) for beam search phrase decoding.
Iraqi Arabic to English end-to-end phrase translation systems are trained on DARPA TransTac data
(Hewavitharana et al., 2013), comprising 766,410 sentence pairs (~6.8 million morpheme tokens in
Arabic, ~7.3 million word tokens in English; ~55k unique vocabulary in Arabic and ~35k unique vo-
cabulary in English).  The data consist of sub-corpora of several domains including military combined
operations, medical, humanitarian aid, disaster relief, etc., and have been created primarily for speech-
to-speech translations. The process flow of Arabic to English translation incorporating the proposed
technique is shown in Figure 1. The components relevant to name disambiguation and transliteration
are in bold face.
Given the input sentence (3), the spelling normalizer normalizes ???  to ???.
(3) ??? ???? ???? ?? ??????? ??????
(|ny sAkn b$qp ym Almdrsp bxDrA')
The morpheme segmenter segments a word into morphemes (Lee et al., 2003; Lee, 2004; Habash and
Sadat, 2006) as in (4), where # indicates that the morpheme is a prefix.
(4) ?????# ????? ?# ??? ?? ??# ??? ???? ?
(Any sAkn b# $qp ym Al# mdrsp b# xDrA')
Part-of-speech tagging is applied to the morphemes, identifying a name with the tag NOUN_PROP. The
input word tagged as NOUN_PROP is classified as name, denoted by the label $name in (5).
(5) $name_(?????) ????? ?# ??? ?? ??# ??? ???? ?#
(Any sAkn b# $qp ym Al# mdrsp b# $name_(xDrA'))
The token $name_(?????) is decomposed into the class label $name and the source word ??????,
creating a simple confusion network for decoding. The beam search phrase decoder computes the
translation costs for all possible input phrases including the phrase pair ?$name  | $name?,2 using all of
2 The source phrase $name translates to the target phrase $name.
434
the decoder feature functions. Assuming that the translation cost for $name being translated into
$name is the lowest, the decoder produces the translation (6), where the name classed source word
????? retains its Arabic spelling .
(6) I live in an apartment near the school in ?????
The Arabic word ????? in (6) is transliterated into khadraa by the NAME/OOV transliteration module.
And the system produces the final translation output (7).
(7) I live in an apartment near the school in khadraa
Figure 1. Process Flow of Arabic to English Phrase Translation Decoding
We use an in-house implementation of the maximum entropy part-of-speech tagger described in
Adwait (1996) for name classing.  The part-of-speech tagger is trained on the combination of LDC-
released Arabic Treebank data containing about 3 million morpheme tokens from MSA (modern stan-
dard Arabic) and in-house annotated TransTac Iraqi Arabic data containing about 63k morpheme to-
kens.
F-score of the tagger on proper noun tags, NOUN_PROP, is about 93% on 2,044 MSA name tokens
derived from Arabic Treebank: Part 3 v 3.2 (LDC2010T08), and about 81.4% on 2,631 Iraqi Arabic
name tokens derived from the DARPA TransTac corpus.
Spelling normalization
Morpheme Segmentation
Part-of-Speech Tagging
Name Classing
Confusion Network
Phrase Decoding
NAME/OOV Transliteration
De-tokenization
English Output
Pre-processing
SMT Decoding
Post-processing
Arabic Input
435
3 Model Training and Confusion Network Decoding
We train translation and language models with name classing to obtain proper translation  and language
model probabilities of the class label $name. We extend the baseline phrase beam search decoder to han-
dle a relatively simple confusion network (CN hereafter) and incorporate the name part-of-speech tagging
scores into the decoder feature functions.
3.1 Translation Model
For any name classed input word, $name_(?? ? ?) in (5), we  would like to have the name translation,
$name ? $name, always available in addition to other translations of the input word obtainable from the
parallel training corpus.
In order to estimate $name distributions without obfuscating the distributions of other training vocabu-
lary, we apply name classing only to words that occur less than 3 times in the training corpus and part-of-
speech tagged with NOUN_PROP. The reasons are three-fold: 1) we need to keep all non-name translations
of the training vocabulary, 2) typical low frequency words include names and typos, 3) even with $name
classing on low frequency words only, the overall $name count is high enough for a robust probability
estimation.
After name classing of words occurring less than 3 times, $name occurs 6,944 times (122th most fre-
quent token) in Arabic and 9,707 times (108th most frequent token) in English. We train both phrase trans-
lation and distortion models on the name classed parallel corpus. Note that the frequency restriction ap-
plies only to model training. During decoding, any word labeled with $name may be name transliterated
regardless of its frequency in the training corpus, differentiating the current technique from (Li et al.,
2013).
3.2 Language Models
To properly capture the name and non-name ambiguities, we interpolate two types language models: 1) 5-
gram language model trained on the English side of the parallel corpus without name classing (LM1), 2)
5-gram language model trained on the English side of the parallel corpus and additional monolingual cor-
pora with name classing (LM2).
Each language model is smoothed with modified Kneser-Ney (Chen and Goodman, 1998). The two
sets of language models are interpolated, as in (8), where ? is set to 0.1. We find the optimal interpolation
weight on the basis of BLEU scores of the development test data set containing about 30k word tokens in
Arabic and about 43k word tokens in English.
(8) ? ? LM1 + (1??) ? LM2
3.3 Confusion Network Decoding
The confusion network containing the class label $name and the source word is handled by an extension
of the  baseline phrase decoder. The baseline decoder utilizes 11 feature functions including those in (9)3
through (14), where f denotes the source phrase and e , the target phrase, and s, the source sentence, t,
the target sentence and a, a word alignment. We use the in-house implementation of the simplex algo-
rithm in Zhao et al. (2009) for decoder parameter optimization.
(9) Direct phrase translation model for )|( fepr
(10) Distortion models(Al-Onaizan and Papineni, 2006)
(11)  Mixture language models
3 We do not use )|( efpr
436
(12)  Lexical weights ),|(&),|( afepaefp ww , cf. (Koehn et al., 2003)
(13) Lexical weights pw (t|s,a) & pw (s|t,a)(14) Word and phrase penalties (Zens and Ney, 2004)
Lexical weight ),|( afepw in (12) is computed according to (15), where j = 1, ?, n source word positions
and i = 1,?, m target word positions within a phrase, N = source phrase length, w(e|f) = the lexical prob-
ability distribution:4
(15) Nfewafep ji
n
j aij
w /))|((),|(
1 ),max(
?
? ?
?
Lexical weight pw(t|s,a) in (13) is computed according to (16), where K = number of  phrases in the input
sentence, k = kth phrase, and ),|(_ afepr kw  = ),|(_ afep kw without normalization by the source phrase
length N.
(16) pw(t|s,a) = ),|(
1
_ afepr
K
k
kw?
?
We augment the baseline decoder in two ways: First, we incorporate the maximum entropy part-of-
speech tagging scores of names into the translation scores in (9), (12) and (13). We simply add the name
part-of-speech tag cost, i.e. ?log probability, to the translation model costs. Second, the decoder can acti-
vate more than one edge from one source word position to another, as shown in Figure 2.5 The name
classed input is split into two tokens $name and xDrA?, leading to two separate decoding paths.  The
choice between the two paths depends on the overall decoding cost of each path, computed from all of the
decoder feature functions.
Since the decoding path to $name is always available when the input word is classed as $name at the
pre-processing step, the technique can discover the name interpretation of an input word even if the name
interpretation is absent in the parallel training corpus. Even when the input word occurs as a name in the
training corpus but has a lower name translation probability than non-name translations in the baseline
phrase table, it can be correctly translated into a name as long as the word is labeled as $name and the
decoder feature functions support the $name path in the given context. When a non-name token is mistak-
enly labeled as $name, the confusion network decoder can recover from the mistake if the non-name path
receives a lower decoding cost than  the $name path.6  If the input token is name classed and the correct
name translation also exists in the baseline phrase table with a high probability, either path will lead to the
correct translation, and the decoder chooses the path with the lower translation cost.
Figure 2. Confusion Network Decoding Paths for Name Classed Input
4 Estimated in the manner described in Koehn et al. (2003).
5 Arabic is represented by Buckwalter transliteration scheme.
6 The decoding scores are computed as cost on the basis of ?log likelihood of various component models. And therefore, a
smaller decoding cost indicates a higher translation quality.
START
Any
b#
$qp
ym
Al#
mdrsp
b# $name
xDrA?
END
sAkn
437
4 Character-Based Phrase Transliteration Models
All instances of un-translated input words, which include names and OOVs, are transliterated in the post-
processing step. Character-based phrase transliteration models are trained on 9,737 unique name pairs.
965 name pairs are obtained from a name lexicon and the remaining 8,772 name pairs are automatically
derived from the parallel training corpus as follows: 1) Take each side of the parallel corpus, i.e. Iraqi
Arabic or English. 2) Mark names manually or automatically. 3) Apply word alignment to the name-
marked parallel corpus in both directions. 4) Extract name pairs aligned in both directions. For name
marking, we used the manual mark-up that was provided in the original data.
5-gram character language models are trained on about 120k entries of names in English. In addition to
about 9.7k names from the English side of the parallel names, about 110k entries are collected from wiki
pages, English Gigaword 5th Edition (LDC2011T07), and various name lexicons.
4.1 Phrase Extraction with English Vowels as Spontaneous Words
Short vowels are optional in written Arabic, whereas all vowels have to be obligatorily specified in Eng-
lish for a word to be valid (Stalls and Knight, 1998; Al-Onaizan and Knight, 2002b). We model the
asymmetrical nature of vowels between the two languages by treating all instances of unaligned English
vowels ? a, e, i, o, u ? as spontaneous words which can be attached to the left or to the right of an aligned
English character for phrase extractions. An example GIZA++ (Och and Ney, 2003) character alignment is
shown in Figure 3. Arabic name is written left to right to illustrate the monotonicity of the alignments.
Figure 3. Automatic Character Alignment between Arabic and English names
In Figure 3, solid lines indicate the automatic machine alignments. English vowels in rectangular boxes
indicate null alignments by the aligner. The dotted lines indicate the potential attachment sites of the un-
aligned vowels for phrase extractions. The first instance of unaligned a (denoted by a1) may be a part ofthe phrases containing the preceding consonant sequence g h, or the following consonant d. The second
instance of unaligned a (denoted by a2) may be a part of the phrases containing the preceding consonant dor the following consonant r.7
4.2 Experiments
We use exact match accuracy8 to evaluate transliteration qualities. Systems are tested on 500 unique name
pairs including 52 names unseen in the training corpus. Experimental results are shown in Table 1.9 Note
that using English vowels as spontaneous words dramatically improves the accuracy from 21.6% to
89.2%.
Decoding is carried out by the baseline phrase decoder discussed in Section 3.3, using the same de-
coder feature functions except for the distortion models. Using only phrase translation and language
model probabilities for decoding results in 74.4% accuracy on SYSTEM4, much lower than 90% accuracy
with all decoder feature functions. The same language model is used for all experiments. For the end-to-
7 Attachment of unaligned English vowels takes place after phrase extractions and should be distinguished from a heuristic
alignment of unaligned English vowels to Arabic characters before phrase extractions.
8 A transliteration is correct if and only if it exactly matches the truth, i.e. gold standard.
9 GIZA++ word aligner is trained with 5 iterations of IBM MODEL 1, 5 iterations of HMM, 5 iterations of IBM MODEL 3 and 5 iterations
of IBM MODEL 4. HMM word aligner (Vogel et al., 1996) is trained with 15 iterations of IBM MODEL 1 and 6 iterations of HMM.
 ?  ? ? ?  ? ?  ? ?
g h a1 d a2 r a n a w i
438
end translation quality evaluations in Section 5, we use SYSTEM4. Exact match accuracy of SYSTEM4 on
the 52 unseen name pairs is 46%.
Systems Character Alignments Symmetrization10 Target spontaneous words Accuracy
SYSTEM1 GIZA++ Union None 21.6%
SYSTEM2 HMM Refined None 86.8%
SYSTEM3 GIZA++ Union All English vowels: a, e, i, o, u 89.2%
SYSTEM4 GIZA++ & HMM Union All English vowels: a, e, i, o, u 90.0%
Table 1. Name transliteration accuracy on 500 names according to various phrase extraction techniques
5 End-to-end Translation System Experimental Results
End-to-end translation quality experiments are carried out on 3 evaluation data sets shown in Table 2.
TransTac.eval  has a low out-of-vocabulary (OOV) and a low name ratios, and has been used as the test
data for system development among DARPA BOLT?C11 program partners. TransTac.oov has a high OOV
and a high name ratios, and has been created in-house for OOV detection system developement. Tran-
sTac.name has a low OOV and a high name ratios, and was used for the TransTac 2008 name translation
evaluations.
Evaluation Data Sets TransTac.eval TransTac.oov TransTac.name
sentence count 3,138 344 79
token count 36,895 3,053 514
OOV ratio 0.4% 4.7% 0.6%
name ratio ~0.5% ~11.3% ~15.4%
Table 2. Translation Quality Evaluation Data Statistics
5.1 Systems, Metrics and Results
End-to-end translation system evaluation results are shown in Table 3. Bold-faced and italicized scores
indicate that the system?s translation quality is statistically significantly better than all other systems with
over 95% confidence, i.e. two-tailed P value < 0.05 in paired t-tests.
Metrics EvalSetsSystems TransTac.eval TransTac.oov TransTac.name TransTac.name_spnorm
baseline 33.35 30.72 35.03 37.39
OOVTranslit 33.35 31.93 35.03 37.54
name_t 32.94 31.81 32.97 40.15
Uncased
BLEU
(4-gram
& 1 ref) CN 33.35 32.60 32.19 40.97
baseline 3.16 1.45 3.19 3.19
OOVTranslit 3.22 2.88 3.36 3.36
name_t 2.16 2.79 3.58 3.58
HUMAN
(6-point
scale)
CN 3.20 3.09 3.86 3.86
Table 3. Translation Quality Evaluation Result
The system baseline is trained without name classing and decoded by the baseline decoder without
name classing. The system OOVTranslit is trained and decoded the same way as the baseline except that
all instances of un-translated OOVs are transliterated at the post-processing step. The system name_t is
10 Bi-directional word alignment symmetrization methods, as defined in Och and Ney (2003), include union, intersection and
refined.
11 BOLT stands for Broad Operational Language Translation and BOLT-C focuses on speech-to-speech translation with dialog man-
agement.
439
trained without name classing and decoded by the baseline decoder with name classing.12 The system CN
is trained with name classing and decoded by the CN decoder with name classing.13
We evaluate the systems, using automatic BLEU (Papineni et al., 2002), and 6-point scale human
evaluations. Lowercased BLEU scores are computed with 1 reference translation up to 4-grams. Scoring
criteria for human evaluations are as follows. 0: exceptionally poor; 1: poor; 2: not good enough; 3:
good enough; 4: very good; 5: excellent. Human evaluations are conducted on a subset of the automatic
evaluation data containing names.14 We exclude the input sentences for which all systems produce the
same translation output.  This leaves 201 sentences from TransTac.eval, 197 sentences from Tran-
sTac.oov, 64 sentences from TransTac.name.
5.2 Result Analysis
We observe that human evaluation scores are relatively consistent with BLEU scores on two data sets,
TransTac.eval and TransTac.oov. TransTac.eval contains very few names. Therefore, incorrect name
classing at the pre-processing step hurts the translation quality for the system name_t. The CN decoder can
improve the translation quality by recovering from a name classing error by choosing the non-name path.
Transliteration of OOVs (OOVTranslit) can improve the translation quality if any of the OOVs are names.
Human evaluations capture the behaviors of the CN decoder and OOVTranslit by giving a slightly higher
(statistically insignificant) score to OOVTranslit, 3.22, and the CN decoder, 3.20, than to the baseline, 3.16.
All three systems, baseline, OOVTranslit and CN, however, received the same BLEU scores, 33.35. This
seems to reflect the fact humans can easily capture the spelling variation of names whereas the automatic
evaluation with 1 reference cannot.
Transtac.oov has a high OOV and a high name ratios and all OOVs are names. Therefore, name classing
improves the translation quality as long as the correctly classed names out-number the incorrectly classed
ones, explaining the higher translation quality of name_t  than the baseline. OOVTranslit improves the
translation quality over the baseline because all OOVs are names. The CN decoder out-performs all three
other systems by correctly disambiguating non-OOV names and transliterating name OOVs. BLEU scores
and human evaluation scores show the same pattern.
For TransTac.name with a high name and a low OOV ratios, however, human evaluation and BLEU
scores show the opposite pattern, although none of the BLEU scores are statistically significantly better
than others (note the small evaluation data size of 79 segments and 514 tokens). Since most names in this
data set are known to the translation vocabulary and is highly ambiguous, we expect the CN decoder to
out-perform all other systems. This expectation is borne out in the human evaluations, but not in BLEU
scores. Our analysis indicates that the apparent inconsistency between BLEU and human evaluation scores
is primarily due to spelling variations of a name, which are not captured by BLEU with just one reference,
cf. (Li et al., 2013). Out of the human evaluated 64 names in TransTac.name, the baseline system pro-
duced the same spelling as the reference 34 times (53.13%), which contrasts with 28 times (43.75%) by
the CN decoder. Overall, the CN decoder produced 62 correct name translations, about 20% more than 49
correct translations by the baseline system. Table 4 shows the names for which the reference spelling
agrees with the baseline system, but disagrees with the CN decoding followed by transliteration.
Reference CN output Reference CN output Reference CN output
tikrit tikreet mariam maryam mousa moussa
ajlan al-`ajlan jaafar gaafar basra al-basra
Table 4. Name Spelling Variations
12 We ensure that any name classed input word $name is translated into $name by adding $name to the translation vocabulary,
and the input word for $name is transliterated in the post-processing stage.
13 We also evaluated another system, called name_st, which is trained with name classing and decoded with name classing using
the baseline decoder. BLEU scores on TransTac.eval and TransTac.oov indicated that model training and decoding with name
classing (name_st) is only slightly better than model training without name classing and decoding with name classing (name_t).
14 For TransTac.eval data, we selected the sentences containing words tagged as name, i.e. NOUN_PROP, by the automatic part-of-
speech tagger. The name ratio around 0.5% in Table 2 is computed on the basis of human annotations on the reference translation.
440
To verify that the inconsistency between BLEU and human evaluation scores is due to name spelling
variations which humans capture but automatic metrics does not, we recomputed BLEU scores after nor-
malizing spellings of the system outputs to be consistent with the reference translation spelling. The re-
computed BLEU scores are denoted by TransTac.name_spnorm in Table 3, which shows that the recom-
puted BLEU scores are indeed consistent with the human evaluation scores.15 Also note that the translation
quality improvement by transliterating OOV names is well captured in human evaluation scores, 3.19 in
the baseline vs. 3.36 in the system OOVTranslit, but not in BLEU scores, 35.03 in both baseline and OOV-
Translit.
We point out that the same name is often spelled differently in  various parts of our training corpus and
even in the same reference translation, e.g. al-aswad vs. aswad, jassim vs. jasim, risha vs. rasha, mahadi
vs. mehdi vs. mahdi, etc., as had been noted in Al-Onaizan and Knight (2002b), Huang et al. (2008).
6 Related Work
Al-Onaizan and Knight (2002a) propose an Arabic named entity translation algorithm that performs at
near human translation accuracy when evaluated as an independent name translation module. Hassan et al.
(2007) propose to improve named entity translation by exploiting comparable and parallel corpora.
Hermjakob et al. (2008) present a method to learn when to transliterate Arabic names. They search for
name translation candidates in large lists of English words/phrases. Therefore, they cannot accurately
translate a name if the correct English name is missing in the word lists.  Their restriction of named entity
transliteration to rare words cannot capture name interpretations of frequent words, e.g. ???? (Sa-
bah/morning), if the name interpretations are absent in the parallel corpus. Li et al. (2013) propose a
Name-aware machine translation approach which tightly integrates high accuracy name processing into a
Chinese-English MT model. Similar to Hermjakob et al. (2008), they restrict the use of name translation to
names occurring less than 5 times in the training data. They train the translation model by merging the
name-replaced parallel data with the original parallel data to prevent the quality degradation of high fre-
quency names.
Onish et al. (2010) present a lattice decoding for paraphrase translations, which can handle OOV
phrases as long as their paraphrases are found in the training corpus. They build the paraphrase lattices of
the input sentence, which are given to the Moses lattice decoder. They deploy the source-side language
model of paraphrases as a decoding feature.
Stalls and Knight (1998) propose a back-transliteration technique to recover original spelling in Roman
script given a foreign name or a loanword in Arabic text, which consist of three models: a  model to con-
vert an Arabic string to English phone sequences, a model to convert English phone sequences to English
phrases, a language model to rescore the English phrases. They use weighted finite state transducers for
decoding. Al-Onaizan and Knight (2002b) propose a spelling-based source-channel model for translitera-
tion (Brown et al., 1993), which directly maps English letter sequences into Arabic letter sequences, and
therefore overcomes Stalls and Knight?s major drawback that needs a manual lexicon of English pronun-
ciations. Sherif and Kondrak (2007) propose a substring-based transliteration technique inspired by
phrase based translation models and show that substring (i.e. phrase) models out-perform letter (i.e. word)
models of Al-Onaizan and Knight (2002b). Their approach is most similar to the current approach in that
we both adopt phrase-based translation models for transliteration. The current approach and Sherif and
Kondrak (2007), however, diverge in most technical details including word alignments, phrase extraction
heuristics and decoding, although it is not clear how they estimate transliteration probabilities. Crucially,
we use the same set of decoder feature functions (excluding distortion models) as the end-to-end phrase
translation system including lexical weights for phrases and a sentence in both directions and word/phrase
penalties, whereas Sherif and Kondrak (2007) use only transliteration and language models for substring
15 The spellings of the CN decoder output are normalized as follows:  38 instances of names, 2 instances of ?s to is, 2 instances of
the city of arar to arar city and 1 instance of talk with to speak to. Only name spelling normalizations were necessary for other
system outputs.
441
transducer. We noted in Section 4 that inclusion of all decoder feature functions improves the accuracy
by 15.6% absolute, compared with using just translation and language models for decoding.
7 Conclusion
We proposed a confusion network decoding to disambiguate Arabic names between name and non-
name interpretations of an input word and character-based phrase transliteration models for NAME/OOV
transliteration.
Name classing at the pre-processing step, coupled with name transliteration at the post-processing
step, enables the system to accurately translate OOV names. Robust TM/LM probability estimations of
names on the class label $name enable the system to correctly translate names even when the name
interpretation of an in-vocabulary word is absent from the training data.  Confusion network decoding
can recover from name classing errors by choosing an alternative decoding path supported by decoder
feature functions, obviating the need for stipulating a count threshold of an input token for name trans-
lation. The character-based phrase transliteration system achieves 90% exact match accuracy on 500
unique name pairs, utilizing all of the phrase decoder feature functions except for distortion models.
We capture the asymmetries of English and Arabic vowel systems by treating any instance of an un-
aligned English vowel as a spontaneous word that can be attached to the preceding or following target
phrases for phrase acquisition.
Although we proposed the confusion network decoding and character-based phrase transliteration
models in the contexts of Arabic name disambiguation and transliteration tasks, the techniques are
language independent and may be applied to any languages.
Acknowledgements
This work has been funded by the Defense Advanced Research Projects Agency BOLT program, Con-
tract No. HR0011-12-C-0015. Any opinions, findings, conclusions or recommendations expressed in
this paper are those of the authors and do not necessarily reflect the view of DARPA. We would like
to thank Lazkin Tahir for his tireless effort on human evaluations. We also thank anonymous review-
ers for their helpful comments and suggestions.
References
Y. Al-Onaizan and K. Knight. 2002. Translating Named Entities Using Monolingual and Bilingual Resources.
In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 400?408.
Y. Al-Onaizan and K. Knight. 2002. Machine Transliteration of Names in Arabic Text. In Proceedings of the
Association for Computational Linguistics Workshop on Computational Approaches to Semitic Languages.
Y. Al-Onaizan and K. Papineni. 2006. Distortion models for Statistical Machine Translation. In Proceedings of
the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Associa-
tion for Computational Linguistics, pages 529?536.
N. Bertoldi, R. Zens, and M. Federico.2007. Speech translation by confusion network decoding. In Proceedings
of the International Conference on Acoustics, Speech, and Signal Processing (ICASSP), pages 1297?1300.
P. Brown, S. Della Pietra, V. Della Pietra and R. Mercer. 1993. The mathematics of statistical machine transla-
tion: Parameter estimation. In Computational Linguistics, 19(2), pages 263?311.
S. Chen and J. Goodman. 1998. An Empirical Study of Smoothing Techniques for Language Modeling.  TR-10-
98. Computer Science Group. Harvard University.
C. Dyer, S. Muresan, and P. Resnik. 2008. Generalizing Word Lattice Translation. In Proceeding of the 46th An-
nual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 1012?
1020.
N. Habash and F. Sadat. 2006. Arabic Preprocessing Schemes for Statistical Machine Translation, In Proceed-
ings of the North American Chapter of the Association for Computational Linguistics (NAACL), pages 49?52.
A. Hassan, H. Fahmy, and H. Hassan. 2007. Improving Named Entity Translation by Exploiting Comparable and
Parallel Corpora. In Proceeding RANLP?07, pages 1?6.
442
U. Hermjakob, K. Knight, and H. Daume III. 2008. Name Translation in Statistical Machine Transla-
tion:Learning When to Transliterate. In Proceedings of the 46th Annual Meeting of the Association for Compu-
tational Linguistics, pages 389?397.
S. Hewavitharana, D. Mehay, S. Ananthakrishnan, and P. Natarajan. 2013. Incremental Topic-Based Translation
Model Adaptation for Conversational Spoken Language Translation. In Proceedings of the 51st Annual Meet-
ing of the Association for Computational Linguistics, pages 697-701.
F. Huang, A. Emami, and I. Zitouni. 2008. When Harry Met Harri,  and : Cross-lingual Name Spell-
ing Normalization. In Proceedings of the Empirical Methods in Natural Language Processing, pages 391?399.
P. Koehn, F. Josef Och, and D. Marcu. 2003. Statistical Phrase-Based Translation. In Proceedings of the 2003
Conference of the North American Chapter of the Association for Computational Linguistics on Human Lan-
guage Technology ? Volume 1, pages 127?133.
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch, M. Federico, N. Bertoldi, B. Cowan, W. Shen, C. Moran, R.
Zens, C. Dyer, O. Bojar, A. Constantin, and E. Herbst. 2007. Moses: Open source toolkit for statistical ma-
chine translation. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics
on Interactive Poster and Demonstration Sessions, pages 177?180.
Y. Lee, K. Papineni, S. Roukos, O. Emam and H. Hassan. 2003. In Proceedings of the 41st Annual Meeting of
Association for Computational Linguistics ? Volume 1,  pages 399?406.
Y. Lee. 2004. Morphological Analysis for Statistical Machine Translation. In Proceedings of Human Language
Technology Conference/North American Chapter of the Association for Computational Linguistics: Short Pa-
pers, pages 57?60.
H. Li, J. Zheng, H. Ji, Q. Li and W. Wang. 2013. Name-aware Machine Translation. In Proceedings of the 51st
Annual Meeting of the Association for Computational Linguistics, pages 604?614.
F. Och and H. Ney. 2003. A Systematic Comparison of Various Statistical Alignment Models. In Computational
Linguistics 29(1), pages 19?51. MIT Press.
T. Onish, M. Utiyama and E. Sumita. 2010. Paraphrase Lattice for Statistical Machine Translation. In Proceed-
ings of the 48th Annual Meeting of the Association for Computational Linguistics Short Papers, pages 1?5.
K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002. BLEU: a Method for Automatic Evaluation of Machine
Translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,
pages 311?318.
A. Ratnaparkhi. 1996. A Maximum Entropy Model for Part-Of-Speech Tagging. In Proceedings of the Empiri-
cal Methods in Natural Language Processing, pages 133?142.
T. Sherif and G. Kondrak. 2007. Substring-Based Transliteration. In Proceedings of the 45th Annual Meeting of
the Association for Computational Linguistics, pages 944?951.
B. G. Stalls and K. Knight. 1998. Translating Names and Technical Terms in Arabic Text. In Proceedings of the
COLING/ACL Workshop on Computational Approaches to Semitic Languages.
C. Tillmann. 2003. A Projection Extension Algorithm for Statistical Machine Translation. In Proceedings of the
Empirical Methods in Natural Language Processing, pages 1?8.
C. Tillmann and H. Ney. 2003. Word Reordering and a Dynamic Programming Beam-Search Algorithm for Sta-
tistical MT. Computational Linguistics 29(1), pages 97?133.  MIT Press.
S. Vogel, H. Ney and C. Tillmann. 1996. HMM-based word alignment in statistical machine translation. In Pro-
ceedings of the 16th International Conference on Computational Linguistics, Volume 2, pages 836?841.
O. Zayed, S. El-Beltagy, O. Haggag. An Approach for Extracting and Disambiguating Arabic Person?s Names
Using Clustered Dictionaries and Scored Patterns. In Natural Language Processing and Information Systems
Lecture Notes in Computer Science. Vol. 7934, 2013, pages 201?212.
B. Zhao and S. Chen. 2009. A Simplex Armijo Downhill Algorithm for Optimizing Statistical Machine Transla-
tion Decoding. In Proceedings of Human Language Technology Conference/North American Chapter of the
Association for Computational Linguistics Short Papers, pages 21?24.
R. Zen and H. Ney. 2004. Improvements in phrase-based statistical machine translation. In Proceedings of Hu-
man Language Technology Conference/North American Chapter of the Association for Computational Lin-
guistics, pages 257?264.
443
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 846?855,
Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational Linguistics
Learning to Transform and Select Elementary Trees for Improved
Syntax-based Machine Translations
Bing Zhao?, and Young-Suk Lee?, and Xiaoqiang Luo?, and Liu Li?
IBM T.J. Watson Research? and Carnegie Mellon University?
{zhaob, ysuklee, xiaoluo}@us.ibm.com and liul@andrew.cmu.edu
Abstract
We propose a novel technique of learning how to
transform the source parse trees to improve the trans-
lation qualities of syntax-based translation mod-
els using synchronous context-free grammars. We
transform the source tree phrasal structure into a
set of simpler structures, expose such decisions to
the decoding process, and find the least expensive
transformation operation to better model word re-
ordering. In particular, we integrate synchronous bi-
narizations, verb regrouping, removal of redundant
parse nodes, and incorporate a few important fea-
tures such as translation boundaries. We learn the
structural preferences from the data in a generative
framework. The syntax-based translation system in-
tegrating the proposed techniques outperforms the
best Arabic-English unconstrained system in NIST-
08 evaluations by 1.3 absolute BLEU, which is sta-
tistically significant.
1 Introduction
Most syntax-based machine translation models with syn-
chronous context free grammar (SCFG) have been re-
lying on the off-the-shelf monolingual parse structures
to learn the translation equivalences for string-to-tree,
tree-to-string or tree-to-tree grammars. However, state-
of-the-art monolingual parsers are not necessarily well
suited for machine translation in terms of both labels
and chunks/brackets. For instance, in Arabic-to-English
translation, we find only 45.5% of Arabic NP-SBJ struc-
tures are mapped to the English NP-SBJ with machine
alignment and parse trees, and only 60.1% of NP-SBJs
are mapped with human alignment and parse trees as in
? 2. The chunking is of more concern; at best only 57.4%
source chunking decisions are translated contiguously on
the target side. To translate the rest of the chunks one
has to frequently break the original structures. The main
issue lies in the strong assumption behind SCFG-style
nonterminals ? each nonterminal (or variable) assumes a
source chunk should be rewritten into a contiguous chunk
in the target. Without integrating techniques to mod-
ify the parse structures, the SCFGs are not to be effec-
tive even for translating NP-SBJ in linguistically distant
language-pairs such as Arabic-English.
Such problems have been noted in previous literature.
Zollmann and Venugopal (2006) and Marcu et al (2006)
used broken syntactic fragments to augment their gram-
mars to increase the rule coverage; while we learn opti-
mal tree fragments transformed from the original ones via
a generative framework, they enumerate the fragments
available from the original trees without learning pro-
cess. Mi and Huang (2008) introduced parse forests to
blur the chunking decisions to a certain degree, to ex-
pand search space and reduce parsing errors from 1-best
trees (Mi et al, 2008); others tried to use the parse trees
as soft constraints on top of unlabeled grammar such as
Hiero (Marton and Resnik, 2008; Chiang, 2010; Huang
et al, 2010; Shen et al, 2010) without sufficiently lever-
aging rich tree context. Recent works tried more com-
plex approaches to integrate both parsing and decoding
in one single search space as in (Liu and Liu, 2010), at
the cost of huge search space. In (Zhang et al, 2009),
combinations of tree forest and tree-sequence (Zhang et
al., 2008) based approaches were carried out by adding
pseudo nodes and hyper edges into the forest. Overall,
the forest-based translation can reduce the risks from up-
stream parsing errors and expand the search space, but
it cannot sufficiently address the syntactic divergences
between various language-pairs. The tree sequence ap-
proach adds pseudo nodes and hyper edges to the forest,
which makes the forest even denser and harder for nav-
igation and search. As trees thrive in the search space,
especially with the pseudo nodes and edges being added
to the already dense forest, it is becoming harder to wade
through the deep forest for the best derivation path out.
We propose to simplify suitable subtrees to a reason-
able level, at which the correct reordering can be easily
identified. The transformed structure should be frequent
enough to have rich statistics for learning a model. In-
stead of creating pseudo nodes and edges and make the
forest dense, we transform a tree with a few simple oper-
ators; only meaningful frontier nodes, context nodes and
edges are kept to induce the correct reordering; such oper-
ations also enable the model to share the statistics among
all similar subtrees.
On the basis of our study on investigating the language
divergence between Arabic-English with human aligned
and parsed data, we integrate several simple statistical op-
erations, to transform parse trees adaptively to serve the
846
translation purpose better. For each source span in the
given sentence, a subgraph, corresponding to an elemen-
tary tree (in Eqn. 1), is proposed for PSCFG translation;
we apply a few operators to transform the subgraph into
some frequent subgraphs seen in the whole training data,
and thus introduce alternative similar translational equiv-
alences to explain the same source span with enriched
statistics and features. For instance, if we regroup two
adjacent nodes IV and NP-SBJ in the tree, we can ob-
tain the correct reordering pattern for verb-subject order,
which is not easily available otherwise. By finding a set
of similar elementary trees derived from the original ele-
mentary trees, statistics can be shared for robust learning.
We also investigate the features using the context be-
yond the phrasal subtree. This is to further disambiguate
the transformed subgraphs so that informative neighbor-
ing nodes and edges can influence the reordering prefer-
ences for each of the transformed trees. For instance, at
the beginning and end of a sentence, we do not expect
dramatic long distance reordering to happen; or under
SBAR context, the clause may prefer monotonic reorder-
ing for verb and subject. Such boundary features were
treated as hard constraints in previous literature in terms
of re-labeling (Huang and Knight, 2006) or re-structuring
(Wang et al, 2010). The boundary cases were not ad-
dressed in the previous literature for trees, and here we
include them in our feature sets for learning a MaxEnt
model to predict the transformations. We integrate the
neighboring context of the subgraph in our transforma-
tion preference predictions, and this improve translation
qualities further.
The rest of the paper is organized as follows: in sec-
tion 2, we analyze the projectable structures using hu-
man aligned and parsed data, to identify the problems for
SCFG in general; in section 3, our proposed approach
is explained in detail, including the statistical operators
using a MaxEnt model; in section 4, we illustrate the in-
tegration of the proposed approach in our decoder; in sec-
tion 5, we present experimental results; in section 6, we
conclude with discussions and future work.
2 The Projectable Structures
A context-free style nonterminal in PSCFG rules means
the source span governed by the nonterminal should be
translated into a contiguous target chunk. A ?projectable?
phrase-structure means that it is translated into a con-
tiguous span on the target side, and thus can be gener-
alized into a nonterminal in our PSCFG rule. We carried
out a controlled study on the projectable structures using
human annotated parse trees and word alignment for 5k
Arabic-English sentence-pairs.
In Table 1, the unlabeled F-measures with machine
alignment and parse trees show that, for only 48.71% of
the time, the boundaries introduced by the source parses
Alignment Parse Labels Accuracy
H H
NP-SBJ 0.6011
PP 0.3436
NP 0.4832
unlabel 0.5739
M H
NP-SBJ 0.5356
PP 0.2765
NP 0.3959
unlabel 0.5305
M M
NP-SBJ 0.4555
PP 0.1935
NP 0.3556
unlabel 0.4871
Table 1: The labeled and unlabeled F-measures for projecting
the source nodes onto the target side via alignments and parse
trees; unlabeled F-measures show the bracketing accuracies for
translating a source span contiguously. H: human, M: machine.
are real translation boundaries that can be explained by a
nonterminal in PSCFG rule. Even for human parse and
alignment, the unlabeled F-measures are still as low as
57.39%. Such statistics show that we should not blindly
learn tree-to-string grammar; additional transformations
to manipulate the bracketing boundaries and labels ac-
cordingly have to be implemented to guarantee the reli-
ability of source-tree based syntax translation grammars.
The transformations could be as simple as merging two
adjacent nonterminals into one bracket to accommodate
non-contiguity on the target side, or lexicalizing those
words which have fork-style, many-to-many alignment,
or unaligned content words to enable the rest of the span
to be generalized into nonterminals. We illustrate several
cases using the tree in Figure 1.
NP?SBJ
the millde east crisisupthat make
mn
PREP PRON
+hA Azmp
NOUN
Al$rq
ADJ
AlAwsT
PRON IV
Alty ttAlf
NOUN
WHNP VP PP?CLR
SBAR
S
NP
Figure 1: Non-projectable structures in an SBAR tree with
human parses and alignment; there are non-projectable struc-
tures: the deleted nonterminals PRON (+hA), the many-to-
many alignment for IV(ttAlf) PREP(mn), fork-style alignment
for NOUN (Azmp).
In Figure 1, several non-projectable nodes were illus-
847
trated: the deleted nonterminals PRON (+hA), the many-
to-many alignment for IV(ttAlf) PREP(mn), fork-style
alignment for NOUN (Azmp). Intuitively, it would be
good to glue the nodes NOUN(Al$rq) ADJ(AlAwsT) un-
der the node of NP, because it is more frequent for moving
ADJ before NOUN in our training data. It should be eas-
ier to model the swapping of (NOUN ADJ) using the tree
(NP NOUN, ADJ) instead of the original bigger tree of
(NP-SBJ Azmp, NOUN, ADJ) with one lexicalized node.
Approaches in tree-sequence based grammar (Zhang et
al., 2009) tried to address the bracketing problem by us-
ing arbitrary pseudo nodes to weave a new ?tree? back
into the forest for further grammar extractions. Such ap-
proach may improve grammar coverage, but the pseudo
node labels would be arguably a worse choice to split
the already sparse data. Some of the interior nodes con-
necting the frontier nodes might be very informative for
modeling reordering. Also, due to the introduced pseudo
nodes, it would need exponentially many nonterminals to
keep track of the matching tree-structures for translations.
The created pseudo node could easily block the informa-
tive neighbor nodes associated with the subgraph which
could change the reordering nature. For instance, IV and
NP-SBJ tends to swap at the beginning of a sentence, but
it may prefer monotone if they share a common parent of
SBAR for a subclause. In this case, it is unnecessary to
create a pseudo node ?IV+SBJ? to block useful factors.
We propose to navigate through the forest, via simpli-
fying trees by grouping the nodes, cutting the branches,
and attaching connected neighboring informative nodes
to further disambiguate the derivation path. We apply ex-
plicit translation motivated operators, on a given mono-
lingual elementary tree, to transform it into similar but
simpler trees, and expose such statistical preferences to
the decoding process to select the best rewriting rule
from the enriched grammar rule sets, for generating tar-
get strings.
3 Elementary Trees to String Grammar
We propose to use variations of an elementary tree, which
is a connected subgraph fitted in the original monolingual
parse tree. The subgraph is connected so that the frontiers
(two or more) are connected by their immediate common
parent. Let ? be a source elementary tree:
? =< `; vf , vi, E >, (1)
where vf is a set of frontier nodes which contain nonter-
minals or words; vi are the interior nodes with source la-
bels/symbols; E is the set of edges connecting the nodes
v = vf+vi into a connected subgraph fitted in the source
parse tree; ` is the immediate common parent of the fron-
tier nodes vf . Our proposed grammar rule is formulated
as follows:
< ?;?;?; m?; t? >, (2)
where ? is the target string, containing the terminals
and/or nonterminals in a target language; ? is the one-
to-one alignment of the nonterminals between ? and ?; t?
contains possible sequence of transform operations (to be
explained later in this section) associated with each rule;
m? is a function of enumerating the neighborhood of the
source elementary tree ?, and certain tree context (nodes
and edges) can be used to further disambiguate the re-
ordering or the given lexical choices. The interior nodes
of ?.vi, however, are not necessarily informative for the
reordering decisions, like the unary nodes WHNP,VP, and
PP-CLR in Figure 1; while the frontier nodes ?.vf are the
ones directly executing the reordering decisions. We can
selectively cut off the interior nodes, which have no or
only weak causal relations to the reordering decisions.
This will enable the frequency or derived probabilities
for executing the reordering to be more focused. We call
such transformation operators t?. We specified a few op-
erators for transforming an elementary tree ?, including
flattening tree operators such as removing interior nodes
in vi, or grouping the children via binarizations.
Let?s use the trigram ?Alty ttAlf mn? in Figure 1 as
an example, the immediate common parent for the span
is SBAR: ?.` = SBAR; the interior nodes are ?.vi =
{WHNP VP S PP-CLR}; the frontier nodes are ?.vf =
(x:PRON x:IV x:PREP). The edges ?.E (as highlighted
in Figure 1) connect ?.vi and ?.vf into a subgraph for the
given source ngram.
For any source span, we look up one elementary tree ?
covering the span, then we select an operator t? ? T , to
explore a set of similar elementary trees t?(?, m?) = {??}
as simplified alternatives for translating that source tree
(span) ? into an optimal target string ?? accordingly. Our
generative model is summarized in Eqn. 3:
?? = argmax
t??T ;???t?(?,m?)
pa(??|??)?
pb(??|t?, ?, m?)?
pc(t?|?, m?). (3)
In our generative scheme, for a given elementary tree
?, we sample an operator (or a combination of operations)
t? with the probability of pc(t?|?); with operation t?, we
transform ? into a set of simplified versions ?? ? t?(?, m?)
with the probability of pb(??|t?, ?); finally we select the
transformed version ?? to generate the target string ??
with a probability of pa(??|??). Note here, ?? and ? share
the same immediate common parent `, but not necessar-
ily the frontier, or interior, or even neighbors. The frontier
nodes can be merged, lexicalized, or even deleted in the
tree-to-string rule associated with ??, as long as the align-
ment for the nonterminals are book-kept in the deriva-
tions. To simplify the model, one can choose the operator
t? to be only one level, and the model using a single oper-
ator t? is to be deterministic. Thus, the final set of models
848
to learn are pa(??|??) for rule alignment, and the pref-
erence model pb(??|t?, ?, m?), and the operator proposal
model pc(t?|?, m?), which in our case is a maximum en-
tropy model? the key model in our proposed approach
in this paper for transforming the original elementary tree
into similar trees for evaluating the reordering probabili-
ties.
Eqn. 3 significantly enriches reordering powers for
syntax-based machine translation. This is because it uses
all similar set of elementary trees to generate the best tar-
get strings. In the next section, we?ll first define the op-
erators conceptually, and then explain how we learn each
of the models.
3.1 Model pa(??|??)
A log linear model is applied here to approximate
pa(??|??) ? exp(?? ?ff) via weighted combination (??) of
feature functions ff(??, ??), including relative frequen-
cies in both directions, and IBM Model-1 scores in both
directions as ?? and ?? have lexical items within them.
We also employed a few binary features listed in the fol-
lowing table.
?? is observed less than 2 times
(??, ??) deletes a src content word
(??, ??) deletes a src function word
(??, ??) over generates a tgt content word
(??, ??) over generates a tgt function word
Table 2: Additional 5 Binary Features for pa(??|??)
3.2 Model pb(??|t?, ?, m?)
pb(??|t?, ?, m?) is our preference model. For instance us-
ing the operator t? of cutting an unary interior node in
?.vi, if ?.vi has more than one unary interior node, like
the SBAR tree in Figure 1, having three unary interior
node: WHNP, VP and PP-CLR, pb(??|t?, ?, m?) specifies
which one should have more probabilities to be cut. In
our case, to make model simple, we simply choose his-
togram/frequency for modeling the choices.
3.3 Model pc(t?|?, m?)
pc(t?|?, m?) is our operator proposal model. It ranks
the operators which are valid to be applied for the
given source tree ? together with its neighborhood m?.
Here, in our approach, we applied a Maximum Entropy
model, which is also employed to train our Arabic parser:
pc(t?|?, m?) ? exp ?? ? ff(t?, ?, m?). The feature sets we
use here are almost the same set we used to train our Ara-
bic parser; the only difference is the future space here is
operator categories, and we check bag-of-nodes for inte-
rior nodes and frontier nodes. The key feature categories
we used are listed as in the Table 3. The headtable used
in our training is manually built for Arabic.
bag-of-nodes ?.vi
bag-of-nodes and ngram of ?.vf
chunk-level features: left-child, right-child, etc.
lexical features: unigram and bigram
pos features: unigram and bigram
contextual features: surrounding words
Table 3: Feature Features for learning pc(t?|?, m?)
3.4 t?: Tree Transformation Function
Obvious systematic linguistic divergences between
language-pairs could be handled by some simple oper-
ators such as using binarization to re-group contiguously
aligned children. Here, we start from the human aligned
and parsed data as used in section 2 to explore potential
useful operators.
3.4.1 Binarizations
One of the simplest way for transforming a tree is via bi-
narization. Monolingual binarization chooses to re-group
children into smaller subtree with a suitable label for the
newly created root. We choose a function mapping to se-
lect the top-frequent label as the root for the grouped chil-
dren; if such label is not found we simply use the label of
the immediate common parent for ?. In decoding time,
we need to select trees from all possible binarizations,
while in the training time, we restrict the choices allowed
with the alignment constraint, that every grouped chil-
dren should be aligned contiguously on the target side.
Our goal is to simulate the synchronous binarization as
much as we can. In this paper, we applied the four ba-
sic operators for binarizing a tree: left-most, right-most
and additionally head-out left and head-out right for more
than three children. Two examples are given in Table 4,
in which we used LDC style representation for the trees.
With the proper binarization, the structure becomes
rich in sub-structures which allow certain reordering to
happen more likely than others. For instance for the sub-
tree (VP PV NP-SBJ), one would apply stronger statistics
from training data to support the swap of NP-SBJ and PV
for translation.
3.4.2 Regrouping verbs
Verbs are keys for reordering especially for Araic-English
with VSO translated into SVO. However, if the verb and
its relevant arguments for reordering are at different lev-
els in the tree, the reordering is difficult to model as more
interior nodes combinations will distract the distributions
and make the model less focused. We provide the fol-
lowing two operations specific for verb in VP trees as in
Table 5.
3.4.3 Removing interior nodes and edges
For reordering patterns, keeping the deep tree structure
might not be the best choice. Sometimes it is not even
849
Binarization Operations Examples
right-most (NP Xnoun Xadj1 Xadj2) 7? (NP Xnoun (ADJP Xadj1 Xadj2))left-most (VP Xpv XNP-SBJ XSBAR) 7? (VP (VP Xpv XNP-SBJ) XSBAR)
Table 4: Operators for binarizing the trees
Operators for regroup verbs Examples
regroup verb (V P1 Xv (V P2 Y )) 7? (V P1 (V P2 Xv Y ))
regroup verb and remove the top level VP (R (V P1 Xv (R2 Y ))) 7? (R (R2 XvY ))
Table 5: Operators for manipulating the trees
possible due to the many-to-many alignment, insertions
and deletions of terminals. So, we introduce the oper-
ators to remove the interior nodes ?.vi selectively; this
way, we can flatten the tree, remove irrelevant nodes and
edges, and can use more frequent observations of simpli-
fied structures to capture the reordering patterns. We use
two operators as shown in Table 6.
The second operator deletes all the interior nodes, la-
bels and edges; thus reordering will become a Hiero-alike
(Chiang, 2007) unlabeled rule, and additionally a spe-
cial glue rule: X1X2 ? X1X2. This operator is neces-
sary, we need a scheme to automatically back off to the
meaningful glue or Hiero-alike rules, which may lead to a
cheaper derivation path for constructing a partial hypoth-
esis, at the decoding time.
NP*
PREP
to ignite the situation
AlAwDAE
DET+NOUN
AlAnfjAr
DET+NOUN
dfE
NOUN
NP
NP
PP*
NP
Aly
Figure 2: A NP tree with an ?inside-out? alignment. The nodes
?NP*? and ?PP*? are not suitable for generalizing into NTs
used in PSCFG rules.
As shown in Table 1, NP brackets has only 35.56% of
time to be translated contiguously as an NP in machine
aligned & parsed data. The NP tree in Figure 2 happens to
be an ?inside-out? style alignment, and context free gram-
mar such as ITG (Wu, 1997) can not explain this structure
well without necessary lexicalization. Actually, the Ara-
bic tokens of ?dfE Aly AlAnfjAr? form a combination
and is turned into English word ?ignite? in an idiomatic
way. With lexicalization, a Hiero style rule ?dfE X Aly
AlAnfjAr 7? to ignite X? is potentially a better alterna-
tive for translating the NP tree. Our operators allow us
to back off to such Hiero-style rules to construct deriva-
tions, which share the immediate common parent NP, as
defined for the elementary tree, for the given source span.
3.5 m?: Neighboring Function
For a given elementary tree, we use function m? to check
the context beyond the subgraph. This includes looking
the nodes and edges connected to the subgraph. Similar
to the features used in (Dyer et al, 2009), we check the
following three cases.
3.5.1 Sentence boundaries
When the tree ? frontier sets contain the left-most token,
right-most token, or both sides, we will add to the neigh-
boring nodes the corresponding decoration tags L (left),
R (right), and B (both), respectively. These decorations
are important especially when the reordering patterns for
the same trees are depending on the context. For instance,
at the beginning or end of a sentence, we do not expect
dramatic reordering ? moving a token too far away in the
middle of the sentences.
3.5.2 SBAR/IP/PP/FRAG boundaries
We check siblings of the root for ? for a few special la-
bels, including SBAR, IP, PP, and FRAG. These labels
indicate a partial sentence or clause, and the reordering
patterns may get different distributions due to the posi-
tion relative to these nodes. For instance, the PV and SBJ
nodes under SBAR tends to have more monotone prefer-
ence for word reordering (Carpuat et al, 2010). We mark
the boundaries with position markers such as L-PP, to in-
dicate having a left sibling PP, R-IP for having a right
sibling IP, and C-SBAR to indicate the elementary tree is
a child of SBAR. These labels are selected mainly based
on our linguistic intuitions and errors in our translation
system. A data-driven approach might be more promis-
ing for identifying useful markups w.r.t specific reorder-
ing patterns.
3.5.3 Translation boundaries
In the Figure 2, there are two special nodes under NP:
NP* and PP*. These two nodes are aligned in a ?inside-
out? fashion, and none of them can be generalized into
a nonterminal to be rewritten in a PSCFG rule. In other
words, the phrasal brackets induced from NP* and PP*
850
operators for removing nodes/edges Examples
remove unary nodes (R Xt1(R1 (R2 Xt2))) 7? (R Xt1(R2 Xt2)))
remove all labels (R (R1 Xt1(R2 Xt2))) 7? (R Xt2Xt1)
Table 6: Operators for simplifying the trees
are not translation boundaries, and to avoid translation
errors we should identify them by applying a PSCFG
rule on top of them. During training, we label nodes
with translation boundaries, as one additional function
tag; during decoding, we employ the MaxEnt model to
predict the translation boundary label probability for each
span associated with a subgraph ?, and discourage deriva-
tions accordingly for using nonterminals over the non-
translation boundary span. The translation boundaries
over elementary trees have much richer representation
power. The previous works as in Xiong et al (2010),
defined translation boundaries on phrase-decoder style
derivation trees due to the nature of their shift-reduce al-
gorithm, which is a special case in our model.
4 Decoding
Decoding using the proposed elementary tree to string
grammar naturally resembles bottom up chart parsing al-
gorithms. The key difference is at the grammar querying
step. Given a grammar G, and the input source parse tree
pi from a monolingual parser, we first construct the ele-
mentary tree for a source span, and then retrieve all the
relevant subgraphs seen in the given grammar through
the proposed operators. This step is called populating,
using the proposed operators to find all relevant elemen-
tary trees ? which may have contributed to explain the
source span, and put them in the corresponding cells in
the chart. There would have been exponential number of
relevant elementary trees to search if we do not have any
restrictions in the populating step; we restrict the maxi-
mum number of interior nodes |?.vi| to be 3, and the size
of frontier nodes |?.vf | to be less than 6; additional prun-
ing for less frequent elementary trees is carried out.
After populating the elementary trees, we construct
the partial hypotheses bottom up, by rewriting the fron-
tier nodes of each elementary tree with the probabili-
ties(costs) for ? ? ?? as in Eqn. 3. Our decoder (Zhao
and Al-Onaizan, 2008) is a template-based chart decoder
in C++. It generalizes over the dotted-product operator in
Earley style parser, to allow us to leverage many opera-
tors t? ? T as above-mentioned, such as binarizations, at
different levels for constructing partial hypothesis.
5 Experiments
In our experiments, we built our system using most of the
parallel training data available to us: 250M Arabic run-
ning tokens, corresponding to the ?unconstrained? condi-
tion in NIST-MT08. We chose the testsets of newswire
and weblog genres from MT08 and DEV101. In partic-
ular, we choose MT08 to enable the comparison of our
results to the reported results in NIST evaluations. Our
training and test data is summarized in Table 5. For test-
ings, we have 129,908 tokens in our testsets. For lan-
guage models (LM), we used 6-gram LM trained with
10.3 billion English tokens, and also a shrinkage-based
LM (Chen, 2009) ? ?ModelM? (Chen and Chu, 2010;
Emami et al, 2010) with 150 word-clusters learnt from
2.1 million tokens.
From the parallel data, we extract phrase pairs(blocks)
and elementary trees to string grammar in various con-
figurations: basic tree-to-string rules (Tr2str), elementary
tree-to-string rules with boundaries t?(elm2str+m?), and
with both t? and m? (elm2str+t? + m?). This is to evalu-
ate the operators? effects at different levels for decoding.
To learn our MaxEnt models defined in ? 3.3, we collect
the events during extracting elm2str grammar in training
time, and learn the model using improved iterative scal-
ing. We use the same training data as that used in training
our Arabic parser. There are 16 thousand human parse
trees with human alignment; additional 1 thousand hu-
man parse and aligned sent-pairs are used as unseen test
set to verify our MaxEnt models and parsers. For our
Arabic parser, we have a labeled F-measure of 78.4%,
and POS tag accuracy 94.9%. In particular, we?ll evaluate
model pc(t?|?, m?) in Eqn. 3 for predicting the translation
boundaries in ? 3.5.3 for projectable spans as detailed in
? 5.1.
Our decoder (Zhao and Al-Onaizan, 2008) supports
grammars including monotone, ITG, Hiero, tree-to-
string, string-to-tree, and several mixtures of them (Lee
et al, 2010). We used 19 feature functions, mainly from
those used in phrase-based decoder like Moses (Koehn
et al, 2007), including two language models (one for a
6-gram LM, one for ModelM, one brevity penalty, IBM
Model-1 (Brown et al, 1993) style alignment probabil-
ities in both directions, relative frequency in both direc-
tions, word/rule counts, content/function word mismatch,
together with features on tr2str rule probabilities. We
use BLEU (Papineni et al, 2002) and TER (Snover et
al., 2006) to evaluate translation qualities. Our base-
line used basic elementary tree to string grammar without
any manipulations and boundary markers in the model,
1DEV10 are unseen testsets used in our GALE project. It was se-
lected from recently released LDC data LDC2010E43.v3.
851
Data Train MT08-NW MT08-WB Dev10-NW Dev10-WB
# Sents 8,032,837 813 547 1089 1059
# Tokens 349M(ar)/230M(en) 25,926 19,654 41,240 43,088
Table 7: Training and test data; using all training parallel training data for 4 test sets
and we achieved a BLEUr4n4 55.01 for MT08-NW, or
a cased BLEU of 53.31, which is close to the best offi-
cially reported result 53.85 for unconstrained systems.2
We expose the statistical decisions in Eqn. 3 as the rule
probability as one of the 19 dimensions, and use Sim-
plex Downhill algorithm with Armijo line search (Zhao
and Chen, 2009) to optimize the weight vector for de-
coding. The algorithm moves all dimensions at the same
time, and empirically achieved more stable results than
MER(Och, 2003) in many of our experiments.
5.1 Predicting Projectable Structures
The projectable structure is important for our proposed
elementary tree to string grammar (elm2str). When a
span is predicted not to be a translation boundary, we
want the decoder to prefer alternative derivations out-
side of the immediate elementary tree, or more aggres-
sive manipulation of the trees, such as deleting inte-
rior nodes, to explore unlabeled grammar such as Hi-
ero style rules, with proper costs. We test separately
on predicting the projectable structures, like predicting
function tags in ? 3.5.3, for each node in syntactic parse
tree. We use one thousand test sentences with two con-
ditions: human parses and machine parses. There are
totally 40,674 nodes excluding the sentence-level node.
The results are shown in Table 8. It showed our Max-
Ent model is very accurate using human trees: 94.5% of
accuracy, and about 84.7% of accuracy for using the ma-
chine parsed trees. Our accuracies are higher compared
with the 71+% accuracies reported in (Xiong et al, 2010)
for their phrasal decoder.
Setups Accuracy
Human Parses 94.5%
Machine Parses 84.7%
Table 8: Accuracies of predicting projectable structures
We zoom in the translation boundaries for MT08-NW,
in which we studied a few important frequent labels in-
cluding VP and NP-SBJ as in Table 9. According to our
MaxEnt model, 20% of times we should discourage a VP
tree to be translated contiguously; such VP trees have an
average span length of 16.9 tokens in MT08-NW. Simi-
lar statistics are 15.9% for S-tree with an average span of
13.8 tokens.
2See link: http://www.itl.nist.gov/iad/mig/tests/mt/2008/doc/mt08
official results v0.html
Labels total NonProj Percent Avg.len
VP* 4479 920 20.5% 16.9
NP* 14164 825 5.8% 8.12
S* 3123 495 15.9% 13.8
NP-SBJ* 1284 53 4.12% 11.9
Table 9: The predicted projectable structures in MT08-NW
Using the predicted projectable structures for elm2str
grammar, together with the probability defined in Eqn. 3
as additional cost, the translation results in Table 11 show
it helps BLEU by 0.29 BLEU points (56.13 v.s. 55.84).
The boundary decisions penalize the derivation paths us-
ing nonterminals for non-projectable spans for partial hy-
pothesis construction.
Setups TER BLEUr4n4
Baseline 39.87 55.01
right-binz (rbz) 39.10 55.19
left-binz (lbz) 39.67 55.31
Head-out-left (hlbz) 39.56 55.50
Head-out-right (hrbz) 39.52 55.53
+all binzation (abz) 39.42 55.60
+regroup-verb 39.29 55.72
+deleting interior nodes ?.vi 38.98 55.84
Table 10: TER and BLEU for MT08-NW, using only t?(?)
5.2 Integrating t? and m?
We carried out a series of experiments to explore the im-
pacts using t? and m? for elm2str grammar. We start from
transforming the trees via simple operator t?(?), and then
expand the function with more tree context to include the
neighboring functions: t?(?, m?).
Setups TER BLEUr4n4
Baseline w/ t? 38.98 55.84
+ TM Boundaries 38.89 56.13
+ SENT Bound 38.63 56.46
all t?(?, m?) 38.61 56.87
Table 11: TER and BLEU for MT08-NW, using t?(?, m?).
Experiments in Table 10 focus on testing operators es-
pecially binarizations for transforming the trees. In Ta-
ble 10, the four possible binarization methods all improve
852
Data MT08-NW MT08-WB Dev10-NW Dev10-WB
Tr2Str 55.01 39.19 37.33 41.77
elm2str+t? 55.84 39.43 38.02 42.70
elm2str+m? 55.57 39.60 37.67 42.54
elm2str+t?(?, m?) 56.87 39.82 38.62 42.75
Table 12: BLEU scores on various test sets; comparing elementary tree-to-string grammar (tr2str), transformation of the trees
(elm2str+t?), using the neighboring function for boundaries ( elm2str+m?), and combination of all together ( elm2str+t?(?, m?)).
MT08-NW and MT08-WB have four references; Dev10-WB has three references, and Dev10-NW has one reference. BLEUn4
were reported.
over the baseline from +0.18 (via right-most binarization)
to +0.52 (via head-out-right) BLEU points. When we
combine all binarizations (abz), we did not see additive
gains over the best individual case ? hrbz. Because during
our decoding time, we do not frequently see large number
of children (maximum at 6), and for smaller trees (with
three or four children), these operators will largely gen-
erate same transformed trees, and that explains the differ-
ences from these individual binarization are small. For
other languages, these binarization choices might give
larger differences. Additionally, regrouping the verbs is
marginally helpful for BLEU and TER. Upon close ex-
aminations, we found it is usually beneficial to group
verb (PV or IV) with its neighboring nodes for expressing
phrases like ?have to do? and ?will not only?. Deleting
the interior nodes helps on shrinking the trees, so that we
can translate it with more statistics and confidences. It
helps more on TER than BLEU for MT08-NW.
Table 11 extends Table 10 with neighboring function
to further disambiguate the reordering rule using the tree
context. Besides the translation boundary, the reorder-
ing decisions should be different with regard to the posi-
tions of the elementary tree relative to the sentence. At
the sentence-beginning one might expect more for mono-
tone decoding, while in the middle of the sentence, one
might expect more reorderings. Table 11 shows when we
add such boundary markups in our rules, an improvement
of 0.33 BLEU points were obtained (56.46 v.s. 56.13)
on top of the already improved setups. A close check
up showed that the sentence-begin/end markups signifi-
cantly reduced the leading ?and? (from Arabic word w#)
in the decoding output. Also, the verb subject order un-
der SBAR seems to be more like monotone with a lead-
ing pronoun, rather than the general strong reordering of
moving verb after subject. Overall, our results showed
that such boundary conditions are helpful for executing
the correct reorderings. We conclude the investigation
with full function t?(?, m?), which leads to a BLEUr4n4 of
56.87 (cased BLEUr4n4c 55.16), a significant improve-
ment of 1.77 BLEU point over a already strong baseline.
We apply the setups for several other NW and WEB
datasets to further verify the improvement. Shown in Ta-
ble 12, we apply separately the operators for t? and m? first,
then combine them as the final results. Varied improve-
ments were observed for different genres. On DEV10-
NW, we observed 1.29 BLEU points improvement, and
about 0.63 and 0.98 improved BLEU points for MT08-
WB and DEV10-WB, respectively. The improvements
for newwire are statistically significant. The improve-
ments for weblog are, however, only marginally better.
One possible reason is the parser quality for web genre is
reliable, as our training data is all in newswire. Regarding
to the individual operators proposed in this paper, we ob-
served consistent improvements of applying them across
all the datasets. The generative model in Eqn. 3 leverages
the operators further by selecting the best transformed
tree form for executing the reorderings.
5.3 A Translation Example
To illustrate the advantages of the proposed grammar, we
use a testing case with long distance word reordering and
the source side parse trees. We compare the translation
from a strong phrasal decoder (DTM2) (Ittycheriah and
Roukos, 2007), which is one of the top systems in NIST-
08 evaluation for Arabic-English. The translations from
both decoders with the same training data (LM+TM) are
in Table 13. The highlighted parts in Figure 3 show that,
the rules on partial trees are effectively selected and ap-
plied for capturing long-distance word reordering, which
is otherwise rather difficult to get correct in a phrasal sys-
tem even with a MaxEnt reordering model.
6 Discussions and Conclusions
We proposed a framework to learn models to predict
how to transform an elementary tree into its simplified
forms for better executing the word reorderings. Two
types of operators were explored, including (a) trans-
forming the trees via binarizations, grouping or deleting
interior nodes to change the structures; and (b) neighbor-
ing boundary context to further disambiguate the reorder-
ing decisions. Significant improvements were observed
on top of a strong baseline system, and consistent im-
provements were observed across genres; we achieved a
cased BLEU of 55.16 for MT08-NW, which is signifi-
cantly better than the officially reported results in NIST
MT08 Arabic-English evaluations.
853
Src Sent qAl AlAmyr EbdAlrHmn bn EbdAlEzyz nA}b wzyr AldfAE AlsEwdy AlsAbq fy tSryH SHAfy An +hmtfA}l b# qdrp Almmlkp Ely AyjAd Hl l# Alm$klp .
Phrasal Decoder prince abdul rahman bin abdul aziz , deputy minister of defense former saudi said in a press statementthat he was optimistic about the kingdom ?s ability to find a solution to the problem .
Elm2Str+t?(?, m?) former saudi deputy defense minister prince abdul rahman bin abdul aziz said in a press statementthat he was optimistic of the kingdom ?s ability to find a solution to the problem .
Table 13: A translation example, comparing with phrasal decoder.
Figure 3: A testing case: illustrating the derivations from chart decoder. The left panel is source parse tree for the Arabic sentence
? the input to our decoder; the right panel is the English translation together with the simplified derivation tree and alignment
from our decoder output. Each ?X? is a nonterminal in the grammar rule; a ?Block? means a phrase pair is applied to rewrite a
nonterminal; ?Glue? and ?Hiero? means the unlabeled rules were chosen to explain the span as explained in ? 3.4.3 ; ?Tree? means
a labeled rule is applied for the span. For instance, for the source span [1,10], a rule is applied on a partial tree with PV and NP-SBJ;
for the span [18,23], a rule is backed off to an unlabeled rule (Hiero-alike); for the span [21,22], it is another partial tree of NPs.
Within the proposed framework, we also presented
several special cases including the translation boundaries
for nonterminals in SCFG for translation. We achieved
a high accuracy of 84.7% for predicting such bound-
aries using MaxEnt model on machine parse trees. Fu-
ture works aim at transforming such non-projectable trees
into projectable form (Eisner, 2003), driven by translation
rules from aligned data(Burkett et al, 2010), and infor-
mative features form both the source 3 and the target sides
(Shen et al, 2008) to enable the system to leverage more
3The BLEU score on MT08-NW has been improved to 57.55 since
the acceptance of this paper, using the proposed technique but with our
GALE P5 data pipeline and setups.
isomorphic trees, and avoid potential detour errors. We
are exploring the incremental decoding framework, like
(Huang and Mi, 2010), to improve pruning and speed.
Acknowledgments
This work was partially supported by the Defense Ad-
vanced Research Projects Agency under contract No.
HR0011-08-C-0110. The views and findings contained in
this material are those of the authors and do not necessar-
ily reflect the position or policy of the U.S. government
and no official endorsement should be inferred.
We are also very grateful to the three anonymous re-
viewers for their suggestions and comments.
854
References
Peter F. Brown, Stephen A. Della Pietra, Vincent. J.
Della Pietra, and Robert L. Mercer. 1993. The mathematics
of statistical machine translation: Parameter estimation. In
Computational Linguistics, volume 19(2), pages 263?331.
David Burkett, John Blitzer, and Dan Klein. 2010. Joint pars-
ing and alignment with weakly synchronized grammars. In
Proceedings of HLT-NAACL, pages 127?135, Los Angeles,
California, June. Association for Computational Linguistics.
Marine Carpuat, Yuval Marton, and Nizar Habash. 2010.
Reordering matrix post-verbal subjects for arabic-to-english
smt. In 17th Confrence sur le Traitement Automatique des
Langues Naturelles, Montral, Canada, July.
Stanley F. Chen and Stephen M. Chu. 2010. Enhanced word
classing for model m. In Proceedings of Interspeech.
Stanley F. Chen. 2009. Shrinking exponential language mod-
els. In Proceedings of NAACL HLT,, pages 468?476.
David Chiang. 2007. Hierarchical phrase-based translation. In
Computational Linguistics, volume 33(2), pages 201?228.
David Chiang. 2010. Learning to translate with source and
target syntax. In Proc. ACL, pages 1443?1452.
Chris Dyer, Hendra Setiawan, Yuval Marton, and Philip Resnik.
2009. The University of Maryland statistical machine trans-
lation system for the Fourth Workshop on Machine Trans-
lation. In Proceedings of the Fourth Workshop on Statisti-
cal Machine Translation, pages 145?149, Athens, Greece,
March.
Jason Eisner. 2003. Learning Non-Isomorphic tree mappings
for Machine Translation. In Proc. ACL-2003, pages 205?
208.
Ahmad Emami, Stanley F. Chen, Abe Ittycheriah, Hagen
Soltau, and Bing Zhao. 2010. Decoding with shrinkage-
based language models. In Proceedings of Interspeech.
Bryant Huang and Kevin Knight. 2006. Relabeling syntax
trees to improve syntax-based machine translation quality. In
Proc. NAACL-HLT, pages 240?247.
Liang Huang and Haitao Mi. 2010. Efficient incremental
decoding for tree-to-string translation. In Proceedings of
EMNLP, pages 273?283, Cambridge, MA, October. Asso-
ciation for Computational Linguistics.
Zhongqiang Huang, Martin Cmejrek, and Bowen Zhou. 2010.
Soft syntactic constraints for hierarchical phrase-based trans-
lation using latent syntactic distributions. In Proceedings of
the 2010 EMNLP, pages 138?147.
Abraham Ittycheriah and Salim Roukos. 2007. Direct transla-
tion model 2. In Proc of HLT-07, pages 57?64.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-
Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan,
Wade Shen, Christine Moran, Richard Zens, Chris Dyer, On-
drej Bojar, Alexandra Constantin, and Evan Herbst. 2007.
Moses: Open source toolkit for statistical machine transla-
tion. In ACL, pages 177?180.
Young-Suk Lee, Bing Zhao, and Xiaoqian Luo. 2010. Con-
stituent reordering and syntax models for english-to-japanese
statistical machine translation. In Proceedings of Coling-
2010, pages 626?634, Beijing, China, August.
Yang Liu and Qun Liu. 2010. Joint parsing and translation.
In Proceedings of COLING 2010,, pages 707?715, Beijing,
China, August.
Daniel Marcu, Wei Wang, Abdessamad Echihabi, and Kevin
Knight. 2006. Spmt: Statistical machine translation with
syntactified target language phraases. In Proceedings of
EMNLP-2006, pages 44?52.
Yuval Marton and Philip Resnik. 2008. Soft syntactic con-
straints for hierarchical phrased-based translation. In Pro-
ceedings of ACL-08: HLT, pages 1003?1011.
Haitao Mi and Liang Huang. 2008. Forest-based translation
rule extraction. In Proceedings of EMNLP 2008, pages 206?
214.
Haitao Mi, Liang Huang, and Qun Liu. 2008. Forest-based
translation. In In Proceedings of ACL-HLT, pages 192?199.
Franz Josef Och. 2003. Minimum error rate training in Statis-
tical Machine Translation. In ACL-2003, pages 160?167.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing
Zhu. 2002. Bleu: a method for automatic evaluation of ma-
chine translation. In Proc. of the ACL-02), pages 311?318,
Philadelphia, PA, July.
Libin Shen, Jinxi Xu, and Ralph Weischedel. 2008. A new
string-to-dependency machine translation algorithm with a
target dependency language model. In Proceedings of ACL-
08: HLT, pages 577?585, Columbus, Ohio, June. Associa-
tion for Computational Linguistics.
Libin Shen, Bing Zhang, Spyros Matsoukas, Jinxi Xu, and
Ralph Weischedel. 2010. Statistical machine translation
with a factorized grammar. In Proceedings of the 2010
EMNLP, pages 616?625, Cambridge, MA, October. Asso-
ciation for Computational Linguistics.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Mic-
ciulla, and John Makhoul. 2006. A study of translation edit
rate with targeted human annotation. In AMTA.
W. Wang, J. May, K. Knight, and D. Marcu. 2010. Re-
structuring, re-labeling, and re-aligning for syntax-based sta-
tistical machine translation. In Computational Linguistics,
volume 36(2), pages 247?277.
Dekai Wu. 1997. Stochastic inversion transduction grammars
and bilingual parsing of parallel corpora. In Computational
Linguistics, volume 23(3), pages 377?403.
Deyi Xiong, Min Zhang, and Haizhou Li. 2010. Learn-
ing translation boundaries for phrase-based decoding. In
NAACL-HLT 2010, pages 136?144.
Min Zhang, Hongfei Jiang, Aiti Aw, Haizhou Li, Chew Lim
Tan, and Sheng Li. 2008. A tree sequence alignment-based
tree-to-tree translation model. In ACL-HLT, pages 559?567.
Hui Zhang, Min Zhang, Haizhou Li, Aiti Aw, and Chew Lim
Tan. 2009. Forest-based tree sequence to string translation
model. In Proc. of ACL 2009, pages 172?180.
Bing Zhao and Yaser Al-Onaizan. 2008. Generalizing local
and non-local word-reordering patterns for syntax-based ma-
chine translation. In Proceedings of EMNLP, pages 572?
581, Honolulu, Hawaii, October.
Bing Zhao and Shengyuan Chen. 2009. A simplex armijo
downhill algorithm for optimizing statistical machine trans-
lation decoding parameters. In Proceedings of HLT-NAACL,
pages 21?24, Boulder, Colorado, June. Association for Com-
putational Linguistics.
Andreas Zollmann and Ashish Venugopal. 2006. Syntax aug-
mented machine translation via chart parsing. In Proc. of
NAACL 2006 - Workshop on SMT, pages 138?141.
855
