Proceedings of the 8th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities (LaTeCH) @ EACL 2014, pages 22?31,
Gothenburg, Sweden, April 26 2014.
c
?2014 Association for Computational Linguistics
New Technologies for Old Germanic. Resources and Research on Parallel
Bibles in Older Continental Western Germanic
Christian Chiarcos, Maria Sukhareva, Roland Mittmann,
Timothy Price, Jens Chobotsky, and Gaye Detmold
Goethe University Frankfurt, Germany
{lastname}@em.uni-frankfurt.de
Abstract
We provide an overview of on-going ef-
forts to facilitate the study of older Ger-
manic languages currently pursued at the
Goethe-University Frankfurt, Germany.
We describe created resources, such as a
parallel corpus of Germanic Bibles and a
morphosyntactically annotated corpus of
Old High German (OHG) and Old Saxon,
a lexicon of OHG in XML and a multi-
lingual etymological database. We discuss
NLP algorithms operating on this data,
and their relevance for research in the Hu-
manities.
RDF and Linked Data represent new and
promising aspects in our research, cur-
rently applied to establish cross-references
between etymological dictionaries, infer
new information from their symmetric clo-
sure and to formalize linguistic annota-
tions in a corpus and grammatical cate-
gories in a lexicon in an interoperable way.
1 Background
We describe on-going efforts at the Goethe Uni-
versity Frankfurt on the study of older Continen-
tal Western Germanic languages, in particular, Old
High German (OHG, ancestor of German), Old
Saxon (OS, ancestor of Low German) and (to a
lesser extent) Old Low Franconian (OLF, ancestor
of Dutch) and their relation to Old English (OE),
Gothic, German and other Germanic languages as
well as the relation of OHG and OS religious texts
to their Latin sources. This line of research is con-
ducted in the context of two larger efforts, the Old
German Reference Corpus and the LOEWE clus-
ter ?Digital Humanities?, in collaboration with the
Applied Computational Linguistics group at the
Goethe-Universitt Frankfurt.
The Old German Reference Corpus is a DFG-
funded project that emerged from the Deutsch Di-
achron Digital (DDD) initiative, conducted in co-
operation between HU Berlin, U Frankfurt and
U Jena, and aims to provide a morphosyntacti-
cally annotated, exhaustive reference corpus of
Old High German and Old Saxon. The LOEWE
cluster ?Digital Humanities?,
1
funded through a
programm of the State of Hessen, is a collabo-
ration between U Frankfurt, TU Darmstadt and
Freies Deutsches Hochstift Frankfurt aiming to
develop methodologies and infrastructures to fa-
cilitate information-technological support of re-
search in the humanities.
The collaboration between the humanities and
NLP described here is guided by different, though
converging interests: For the humanities, the lan-
guage resources, annotations, alignment and tools
created in collaboration with NLP researchers
represent novel instruments complementing tradi-
tional philological approaches, e.g., to investigate
emergence and decay of syntactic patterns.
From an NLP perspective, the Germanic lan-
guages provide a test-bed to develop strategies
for novel algorithms for alignment and annotation
projection. In particular, the abundance of parallel
(Bible) texts for all major language stages of most
Germanic languages, the excellent NLP support
for modern Germanic languages, and the availabil-
ity of a considerable body of annotated historical
texts allow us to study the impact of the factor
of diachronic relatedness when building resources
for low-resource languages.
2 Corpus Data
Along with annotated corpora provided by third
parties (Tab. 1), two important data sets have been
constructed in the course of our research. These
include a massive, verse-aligned Bibles corpus
1
http://www.digital-humanities-hessen.de
22
covering all Germanic languages, and the Old Ger-
man Reference Corpus. In additional, a thematical
alignment of quasi-parallel text within and across
biblical texts was extrapolated from the literature.
2.1 Germanic parallel Bible corpus
Bible data represents the majority of parallel data
available for historical Germanic languages, and
for the case of OS and OHG, gospel harmonies
represent even the majority of data currently
known. Hence, we began compiling a corpus of
Bible texts, excerpts and fragments for all Ger-
manic languages marked up with IDs for verses (if
possible), chapters and books. For data represen-
tation, we employed an XML version of the CES-
scheme developed by (Resnik et al., 1997). Hav-
ing outgrown the scale of Resnik?s earlier project
by far, we are currently in transition to TEI P5
XML format. At the moment, 271 texts with about
38.4M tokens have already been processed (Tab.
2). Copyright prevents redistributing most of this
data under a free or an academic license, but we
plan to share the extraction and conversion scripts
we used. . Except for automatically parsed Bibles
in modern English, German and Swedish, the texts
in this collection are not annotated. Where anno-
tations are available from other corpora (Tab. 1),
however, these were aligned with our Bibles.
2.2 Old German Reference Corpus
The Old German Reference Corpus (Referenzkor-
pus Altdeutsch) (Mittmann, 2013) is a joint project
in cooperation between HU Berlin, U Frankfurt
and U Jena, conducted in the wider context of the
Deutsch Diachron Digital (DDD) initiative. The
DDD initiative aims to provide deeply-annotated
reference corpora of different historical stages of
German. The Old German Reference Corpus com-
prises all preserved texts from the oldest stages of
continental Western Germanic (OHG and OS) dat-
ing from ca. 750 to 1050 CE, 650,000 tokens in
total. Among the largest coherent subcorpora are
Tatian (OHG), Otfrid of Weissenburg (OHG) and
the Heliand (OS). From these, only Tatian can be
verse-aligned with the gospels (and is included in
Tab. 1 and 2), while the Heliand and Otfrid are free
renderings of the gospels. For these, the literature
provides a section-level alignment only.
The DDD builds on the earlier efforts of the
TITUS project (Thesaurus of Indo-European Text
and Language Materials, Thesaurus Indogerman-
ischer Text- und Sprachmaterialien) that pro-
vided digitized editions of texts in old Germanic
languages as well as other Indo-European and
selected non-Indo-European languages (Gippert,
2011).
2
The annotations are mostly derived from the lit-
erature and existing glossaries that provide gram-
matical information for all known OHG and OS
words, together with their exact source. These
have been digitized, automatically applied to the
text, manually refined using the annotation soft-
ware ELAN,
3
augmented with metadata, and fi-
nally published via the ANNIS database (Linde
and Mittmann, 2013).
The annotated corpus is published under a CC-
BY-SA license over http://www.laudatio.
org, where ELAN and relANNIS files are pro-
vided. So far, the OHG Tatian is available, further
data sets are currently in preparation.
2.3 Thematical alignment within and across
biblical texts
Translations of religious texts are well-suited for
language comparison as well as NLP experiments
exploiting parallel data as they are not only faith-
fully translated, but also, they come with a verse-
level alignment which can serve as a basis for sta-
tistical word-level alignment, using, e.g., GIZA++
(Och and Ney, 2003). Where such a verse-level is
not explicitly given, it can be automatically iden-
tified for actual translations. However, for inde-
pendent compositions such as gospel harmonies,
alignment is harder to identify and can only be es-
tablished at the level of sections. In addition, sim-
ilar links also exist between different parts of the
Bible, e.g., parallel passages in different gospels.
For these, an index providing a coarse-grained
thematical alignment at the level of sections was
extrapolated from the literature. This index can
be exploited to increase the coverage of the align-
ment: where no exact translation is available (his-
torical language data is often fragmentary), a the-
matically matching section is retrieved. Further-
more, consulting the verse under consideration to-
gether with renderings of quasiparallel parts of the
same text allows historical linguists to grasp the
degree of grammatical variability for the phenom-
ena they are interested in. Language comparison
can thus be particularly well accomodated if mul-
2
http://titus.uni-frankfurt.de/texte/
texte2.htm#ahd and #asachs
3
http://www.lat-mpi.eu/tools/elan
23
language period syntax tok. corpus
English
Modern 19th CS 21K (Kroch et al., 2010)
British 18th CS 32K (Kroch et al., 2010)
Early 17th CS 22K (Kroch et al., 2004)
Modern 16th CS 21K (Kroch et al., 2004)
Middle 14th CS 66K (Kroch and Taylor, 2000)
Old 10th CS 78K (Taylor et al., 2003b)
DS 7K (Haug and J?hndal, 2008)
Icelandic Middle 16th CS 40K (R?ognvaldsson et al., 2012)
High Early Mod.16th CS 27K (Light, 2013)
German Old 9th CH 41K Sect. 2.2
Gothic 4th DS 56K (Haug and J?hndal, 2008)
Table 1: Verse-aligned older Germanic Bible texts
from various corpora with manual annotations for
morphosyntax and syntax (CH chunks, CS con-
stituents, DS dependencies)
after 1800- 1600- 1400- 1100- before
1900 1900 1800 1600 1400 1100
Insular West Germanic
English 2 2 2 6 3 (+2) 1
Pidgin/Creol 2
Scots (6) (1)
Frisian 2 (+8) (12) Continental West Germanic
Dutch 4 1 5 (1)
L. Franconian (47) 21
Afrikaans 3
German 3 1 (19) 1 (+4) 1 (+1) 1
dialects 3 (+2)
Yiddish 1
Low German 3 (+18) (66) (2) 1
Plautdietsch 2
Danish 1 North & East Germanic
Swedish 3 (3) (1)
Bokm?al 2
Nynorsk 2
Icelandic 1 1
Faroese 1
Norn (2)
Gothic 1
tokens 21.8M 3.2M 2.7M 9.2M 1.2M 0.2M
Table 2: Verse-aligned texts in the Germanic par-
allel Bible corpus (parentheses indicate marginal
fragments with less than 50,000 tokens)
tiple versions of the same passage in the same lan-
guage can be provided.
To exploit redundancy and to enlarge the num-
ber of parallel and quasi-parallel passages for a
given phenomenon searched in the corpus, cross-
references within the Bible and between the Bible
and derived texts have been identified. For ex-
ample, coarse-grained thematical alignment be-
tween different gospels is provided by the Euse-
bian Canon Tables and their subordinate Ammo-
nian sections and are extendable to the Latin Ta-
tian. For OS Heliand, a free adaptation of gospels,
we have only a section-level thematical alignment
with Tatian provided by Sievers (1872).
Information on these cross-references has been
digitized and employed to create an interlinked in-
dex of thematically similar sections in the gospels
and the OS and OHG gospel harmonies. Our Bible
West Germanic other reconstr.
lexicon OE OHG OS OLF OFr ON Got PGmc PIE
entries (XML, in K)
25 24 9 2 13 12 5 9 7
triples (RDF, in M)
1.2 1.6 .6 .2 .6 .7 .4 .2 .2
lemon:Words & links (in K)
OE 25 1
OHG 2 26 7 2 3 1
OS 1 4 9 1 2 1
ON 1 1 14
Got 1 1 1 1 6
PGmc 5 3 3 1 2 4 2 8
PIE 2 1 1 1 1 1 1 8
German 16 23 8 4 10 12 7 6 3
English 10 4 2 5 9 2
symmetric closure of etym. links (triples per lang. in K)
+11 +14 +11 +5 +9 +8 +5 +21 +9
links to (L)LOD data sets (triples per data set in K)
OLiA 24 22 8 2 12 11 5 8 7
lexvo 132 186 82 21 68 82 49 14 15
Glottolog 15 11 8 3 7 11 6 9 13
Table 3: Statistics on the etymological dictio-
naries, including Old Low Franconian (OLF),
Old Frisian (OFr), Old Norse (ON), Gothic
(Got), Proto-Germanic (PGmc) and Proto-Indo-
European (PIE)
data is thus accompanied with an index that links
disparate texts from different time periods and in
distinctive styles and variant languages on the ba-
sis of thematical similarity as identified in the liter-
ature. For gospels and gospel harmonies, we iden-
tified 4560 inter-text groups made up of the related
chunks between all the originals and languages in-
volved that represents the basis for a more fine-
grained level of alignment (Price, 2012).
3 Linked Lexicon Data
A large lexical database of etymologically linked
dictionaries of old Germanic languages (OS,
OHG, OE, Gothic, Old Norse, Old Frisian, Old
Low Franconian, Proto-Germanic; also Proto-
Indo-European) has been developed in the con-
text of the LOEWE cluster ?Digital Humanities?
at the U Frankfurt. Building on the etymologi-
cal and translational dictionaries of Old Germanic
languages by Gerhard K?obler,
4
the project ?Histor-
ical Linguistic Database? developed user-friendly
means of comparing etymologically related forms
between historical dialects and their daughter lan-
guages (Price, 2012). The original PDF data
were converted into an XML representation, cross-
references have been resolved and the results are
4
http://www.koeblergerhard.de/
ahdwbhin.html
24
imported into an XML database. A web interface
has been developed, that transforms user queries
into XQuery and visualizes the results in a conve-
nient way using XSLT.
To provide a machine-readable representation
of the etymological dictionaries, an RDF version
has been compiled. Applying the Linked Data
paradigm (Bizer et al., 2009) to etymological lex-
icons is particularly promising as they are char-
acterized by a heavy linkage across different lan-
guages, so that etymological lexicons for differ-
ent languages are very likely to complement each
other. RDF provides the means to represent the
cross-language linking using a uniform formalism,
and subsequently, to facilitate information aggre-
gation over multiple etymological lexicons as well
as language-specific lexical resources.
We converted the K?obler lexicons to RDF in
conformance to the Lemon model (McCrae et
al., 2011), an LMF-based vocabulary to repre-
sent machine-readable lexicons by using Semantic
Web standards. This conversion followed the three
main objectives:
(i) linkability: XML-based query languages
such as XQuery and XPath, used to create the user
interface to the lexicons, limit our lexicon to a
tree-structure representation. However, as our lex-
icons complement each other, it would be desir-
able to provide explicit cross-references between
these entries, and to allow them to be queried
jointly. Within the RDF data model, the relations
within and beyond a single lexicon can be repre-
sented and queried with equal ease, surmounting
constraint imposed by XML.
(ii) interoperability: Instead of resource-
specific abbreviations for languages and gram-
matical categories, we represent linguistic
information and meta data by reference to
community-maintained vocabularies publicly
available as part of the (Linguistic) Linked Open
Data cloud, namely lexvo (de Melo, to appear,
ISO 639-3 language codes), Glottolog (Nordhoff
and Hammarstr?om, 2011, language families) and
OLiA (Chiarcos, 2008, linguistic categories).
Reusing vocabularies shared among many parties
over the Web of Data has the advantage that
resources dealing with related phenomena in
the same language can be easily identified and
their information integrated without additional
conversion steps.
(iii) inference: The original lexicons were dis-
tributed in individual PDF files, and the XML rep-
resentation was created as a faithful representation
of their content, augmented with markup for rele-
vant linguistic features. These files, however, pro-
vided complementary information, so that, say, a
lexicon entry in the OS dictionary provided a ref-
erence to an etymological corresponding OHG en-
try, but this reference was not found in the OHG
dictionary. Such gaps can be easily detected (and
filled) through symmetric closure in the RDF data
model.
The results of this conversion are summarized in
Tab. 3. In the original XML (first row), every en-
try corresponds to a lemma of the language under
consideration, with different etymologies (and/or
senses) being associated with it. In RDF (second
row), each of these homographs (together with its
definition number) is defined as a lemon:Word
with a homography relation with the homograph
set (represented by a lemon:Word without defi-
nition number). The number of lemon:Words
is thus slightly higher than the number of en-
tries in the original dictionaries. Differently from
the XML, however, information from different
data sets can be easily aggregated, and triples
originating from one document can be comple-
mented with triples from another, shown here for
the symmetric closure of etymological relations
(third row) that can be easily generated using a
simple SPARQL pattern like CONSTRUCT { ?o
?p ?s } WHERE {?s ?p ?o}. The last row
shows links to other data sets from the (Linguis-
tic) Linked Open Data cloud. Most original en-
tries were complemented with grammatical infor-
mation using different (and not fully consistent)
abbreviations. For the most frequent abbrevia-
tions used, a link to the corresponding OLiA con-
cept was generated. These definitions are thus
interoperable beyond these lexicons and can be
compared, e.g., with those of lexical-semantic re-
sources for Modern German and English as com-
piled in (Eckle-Kohler et al., to appear). Similarly,
language abbreviations were mapped to ISO 639-
3 codes (in lexvo), or, where these were not avail-
able, to Glottolog. Even though the number of data
in historical languages is constantly increasing and
there is a demand for fine-grained language codes
for them, neither of the aforementioned resources
provide such codes. So we had to use a link to the
corresponding language family instead.
25
language period scheme corpus reference
English
Modern PTB (Taylor et al., 2003a; Kroch et al., 2010)
Early Mod. PPCEME (Kroch et al., 2004)
Middle PPME2 (Kroch and Taylor, 2000)
Old
YCOE (Taylor et al., 2003b)
PROIEL (Taylor et al., 2003b)
High German
Modern STTS (Schiller et al., 1999)
Early Mod. PCENHG (Light, 2013)
Old
Sect. 2.2
T-CODEX (Petrova et al., 2009)
Dutch Modern Alpino (Bouma et al., 2001)
Old Norse Menota (Haugen et al., 2008)
Danish Modern EAGLES (Leech and Wilson, 1996)
Swedish Modern Mamba (Nivre et al., 2006)
Icelandic IcePaHC (R?ognvaldsson et al., 2012)
Gothic PROIEL (Haug and J?hndal, 2008)
(a) Morphosyntactic annotations
language period scheme corpus reference
English
Modern
PTB (Taylor et al., 2003a; Kroch et al., 2010)
Stanford deps (De Marneffe and Manning, 2008)
Penn2Malt deps (Johansson and Nugues, 2007)
Early Mod. PPCEME (Kroch et al., 2004)
Middle PPME2 (Kroch and Taylor, 2000)
Old
YCOE (Taylor et al., 2003b)
PROIEL (Taylor et al., 2003b)
High German
Modern
TIGER (Brants et al., 2004)
T?uba-D/Z (Telljohann et al., 2003)
NEGRA (Skut et al., 1997)
Early Mod. PCENHG (Light, 2013)
Dutch Modern Alpino (Bouma et al., 2001)
Swedish Modern Mamba (Nivre et al., 2006)
Icelandic IcePaHC (R?ognvaldsson et al., 2012)
Gothic PROIEL (Haug and J?hndal, 2008)
(b) Syntactic annotations
Table 4: List of annotation schemes represented as OWL2/DL ontologies and relevant Germanic corpora
4 NLP methods applied
We sketch selected NLP applications developed on
the data described before, the automated phrase-
level alignment of quasi-parallel text, and two
experiments on annotation projection on parallel
text. All of these experiments are still in a rela-
tively early stage.
4.1 Automated phrase-level alignment of
quasi-parallel text
The needs of historical lingustics demand a more
fine-grained alignment than the currently avail-
able thematical alignment of Heliand with Ta-
tian and the gospels. We thus investigate parallel
phrase detection between Heliand (OS) and Tatian
(OHG), resp., Heliand and the West Saxon gospels
(OE).
To identify cognate phrases, we explore 6 types
of similarity metrics ?(w
OS
, w
OHG
) for every OS
word w
OS
and its potential OHG cognate w
OHG
.
1. geometry ?
g
= difference between the relative
positions of w
OS
and w
OHG
.
2. identity ?
i
(w
OS
, w
OHG
) = 1 iff w
OHG
=
w
OS
(0 otherwise)
3. lexicon ?
lex
(w
OS
, w
OHG
) = 1 iff w
OHG
?
W (0 otherwise) where W is a set of possible
OHG translations for w
OS
suggested by a lexicon,
i.e., either
direct etymological link in (the symmetric
closure of) the etymological dictionaries, or
indirect shared German gloss in the etymo-
logical dictionaries
4. orthography similarity measure based on
character replacement likelihood:
relative Levenshtein similarity
?
lev
(w
OS
, w
OHG
) = 1 ?
ld
|w
OS
|+|w
OHG
|
where ld is the standard Levenstein distance
and |w
OS
| and |w
OHG
| are the number of
characters in each word.
statistical character replacement probability
as approximated by a character-based statisti-
cal machine translation system (Neubig et al.,
2012)
5. normalization ?
norm
(w
OS
, w
OHG
) =
?
i
(w
?
OS
, w
OHG
) , with w
?
OS
being the OHG ?nor-
malization? of the original w
OS
. Here, normaliza-
tion uses a weighted Levenshtein distance and a
fixed list of OHG target words (Bollmann et al.,
2011).
6. cooccurrences ?
p
(w
OS
, w
OHG
) =
P (w
OS
|w
OHG
)P (w
OHG
|w
OS
), calculated
on thematically aligned sections from both texts.
For any two thematically aligned OS and OHG
word vectors, we thus span up a similarity ma-
trix between both word vectors on the basis of
these metrics. On the matrices, different opera-
tions can be applied to calculate similarity derived
metrics, including point-wise multiplication or ad-
dition, thresholds and a smoothing operator, that
aligns words due to the similarity of its neighbors.
The resulting matrix is then decoded by a greedy
algorithm that aligns the words with the highest
score, and then iterates for the remaining words.
At the moment, we provide a graphical interface
over a webpage that allows a philologist to dynam-
26
ically define an alignment function and that pro-
vides a graphical visualization of the result. Dur-
ing a partial qualitative evaluation a historical lin-
guist was asked to compare the results of align-
ment based on various metrics applied to a small
text passage. He took into consideration the over-
all match of the topic of the aligned passages as
well as the number of parallel passages that the
metrics failed to align. Eventually, it was indi-
cated that the best results can be achieved by com-
bining multiple metrics. A combination of either
direct lexicon-based or normalization-based align-
ment and geometrical alignment appears to be par-
ticularly promising. Yet, systematic experiments
to automatically explore this feature space are still
being prepared and depend on the availability of a
gold alignment for selected verses.
4.2 Projecting dependency relations
As shown in Tab. 1, we only possess shallow syn-
tactic annotations of OHG (and OS) text. We are
thus particularly interested in establishing richer
syntactic annotations. A challenging aspect in this
respect is the limited availability of parallel train-
ing data for historical language stages. However,
due to diachronic relatedness, we may expect that
syntactic patterns of Old Germanic languages are
preserved in their modern descendants. Such an
approach requires a consistent hyperlemmatiza-
tion, e.g., against a modern language
We tested this idea on Bible texts from four cor-
pora with closely related annotation schemes for
syntax (Tab. 1, corpora with CS-syntax): Icelandic
(IS), Early Modern High German (DE), Mid-
dle English (ME) and Old English (OE). These
schemes originate in the Penn Treebank scheme
(Taylor et al., 2003a), and we thus parsed a mod-
ern English Bible with a parser trained on the Penn
Treebank. As older Germanic languages are char-
acterized by a higher degree of word order flexi-
bility than Modern English, we converted histor-
ical and modern annotations to dependency rela-
tions using standard tools for this task (Johans-
son and Nugues, 2007). Word-alignment was ob-
tained with GIZA++ and 1:1 alignment was en-
forced using the translation table. Then, we pro-
jected dependency relations and the English words
as hyperlemmas for the historical texts. The his-
torical texts had comparable POS annotation that
was only slightly normalized across the corpora as
it preserved more morphological information than
Modern English POS tags.
On these projections, a fragment-aware parser
was trained using the English (hyper)lemmas and
the original POS tags (Spreyer and Kuhn, 2009).
We limited the amount of parallel data available to
a training set of 437 sentences per language and a
test set of 174 per language. Our hypothesis was
that in this setting, (projected) training data from
related languages can be used in place of train-
ing data for the language under consideration, if
the amount of data is sufficient and the languages
are sufficiently closely related. Furthermore, we
assumed that with an increasing number of lan-
guages considered (and thus training set size), the
quality of the projected annotations would contin-
uously improve as long as the languages are suffi-
ciently closely related.
For evaluation, we employed the unlabeled at-
tachment score (UAS) (Collins et al., 1999) on
the test data and compared with the (dependency
version of) the original annotation in these cor-
pora. Tab. 5 compares the performance of a
parser trained on target language data with parsers
trained on (hyperlemmatized) related languages.
The scores in the second column are the baseline
UAS where the parser was applied to the same
language as it was trained on. The third column
shows the difference with the parser applied to a
language but trained on projections into another
language. The fourth and the fifth column pro-
vides the results of the parser trained on one or
two additional related languages respectively.
The results showed that, among the West Ger-
manic languages (but not IS), a parser trained
on two or more related languages can reach the
same performance or even outperforms a parser
trained on the target language. Furthermore, a
parser trained on (projected) annotations from two
or more related languages is likely to outperform
a parser trained on a single related language. Ac-
cordingly, in absence of parallel texts for the target
language, the parser can be successfully trained on
annotation projections from two or more related
languages. It should be noted, however, that the
overall performance of the parser was relatively
poor. This may be, however, an artifact of the great
grammatical divergency between Modern English
(and, to a limited degree, ME: reduced morphol-
ogy, strict word order) and older Germanic lan-
guages (rich morphology, flexible word order).
Subsequent experiments will thus address the
27
inclusion of richer morphological features, projec-
tions from other languages and evaluation against
another set of dependency (DS) annotations for
Gothic and Old English (Tab. 1), for which related
annotation schemes for Latin, Greek and Czech
are available ? all of these languages are charac-
terized by rich morphology and flexible syntax.
on on related languages
Tgt Tgt Best monoling. Best biling. Triling.
lang. model ?UAS model ?UAS model ?UAS
DE .41 IS +.02
n.s.
+ME +.05
?
+OE +.04
??
IS .32 ME ?.06
???
+DE ?.03
n.s.
+OE ?.04
?
ME .60 IS ?.04
???
+OE ?.01
n.s.
+DE ?.02
n.s.
OE .30 ME .00
n.s.
+IS .00
n.s.
+DE .00
n.s.
Table 5: Performance of parsing models (UAS dif-
ference vs. 2nd col. with ?
2
:
?
p < .05,
??
p < .01,
???
p < .005)
4.3 Harmonization of grammatical features
Another line of studies addresses the projection of
grammatical features as represented in POS tags
and dependency labels. Unfortunately, modern
and historical language stages are annotated ac-
cording to a great variety of annotation schemes
which can not be trivially mapped to a general-
ization without substantial loss of information (as,
e.g., in the approach by Petrov et al., 2012). For
processing of multilingual corpora the problem of
heteroginity of linguistic annotations is very acute.
Above, we described an experiment that used PTB
style annotations only. This limitation was im-
posed by the annotation schema of the target cor-
pora that had PTB style syntactic annotations.
We thus follow Chiarcos (2008) and represent
the most relevant Germanic annotation schemes
as OWL2/DL ontologies, and link these to an
overarching Reference Model. Unlike a tagset,
whose string-based annotations require disjoint
categories at a fixed level of granularity, this
ontology-based approach allows to decompose the
semantics of annotations and consider all aspects
independently. For example, a tagger may cor-
rectly identify plural agreement but incorrectly as-
sume that it pertains a noun, as in the Penn Tree-
bank tag NNS. In the original tagset, a correspond-
ing tag for, say, adjectives, does not exist, but us-
ing the ontology, a plural adjective could neverthe-
less be represented in the form of different RDF
triples. With lexicon data being available in RDF
and linked to the OLiA Reference Model, as well
(Sect. 3), the incorrect word class can be spot-
ted, and corrected, but the agreement information
could remain unaffected.
These annotations have also been successfully
employed in ensemble combination architectures,
where information from different sources (say,
NLP tools) was integrated on the basis of the
Reference Model and disambiguated using onto-
logical axioms (Chiarcos, 2010; Pareja-Lora and
Aguado de Cea, 2010). In an annotation pro-
jection scenario, these sources could be projec-
tions from different languages annotated accord-
ing to different schemes, e.g., German, English,
Swedish or Latin. These experiments are currently
being conducted, but Annotation Models for sev-
eral schemes are already available (Tab. 4).
5 Digital Humanities
Our ultimate goal is to facilitate studies of histori-
cal and empirical linguists and philologists.
One research question under consideration is
whether the Heliand influenced Luther (Price,
2012), who, apparently, possessed one copy.
Based on a thorough comparison of thematically
aligned passages, evidence for or against this hy-
pothesis may be gathered, and this investigation
can be simplified by limiting the search to parallel
phrases automatically identified (Sect. 4.1).
Another research question pertains to divergen-
cies between, e.g., OHG texts and their Latin
source. As most OHG material is translated in a
literal fashion, and the word order was relatively
flexible, the OHG syntax may have been adjusted
to mirror the Latin original. Research of OHG
syntax thus concentrates on passages where OHG
syntax differs from the Latin source (Hinterh?olzl
and Petrova, 2009).
Different types of divergencies have been iden-
tified by qualitative research. Early translations
unlike modern ones tend to be very literal, of-
ten not being only word by word translation but
also preserving the syntax of the original. Nev-
ertheless, due to strong grammatical differences
between two languages, various divergencies on
(morpho)syntactic and lexical levels were un-
avoidable. Such, the transition from the Latin syn-
thetic to OHG analytic wordforms in case of the
deponent verbs is systematically observed. Also
the changes of the word position as well as miss-
ing a word in translation or adding a word that is
not present in the Latin original can be frequently
found. Such divergencies can be often explained
28
by stylistic or pragmatic reasons as well as by per-
sonal preferences of the translator.
This line of research is currently supported
through automated word-level alignment between
the OHG and Latin versions of Tatian. We built
a parallel corpus using GIZA++ and used the
TreeAligner (Lundborg et al., 2007) for search and
evaluation. On this basis, a philological compari-
son of OHG Tatian and its Latin source is being
conducted. More helpful, however, would be a
comparison of different syntactic patterns in OHG
and Latin which motivates our experiments in an-
notation projection (Sect. 4.2).
Finally, our experiments in the ontology-based
harmonization of different annotation schemes
(Sect. 4.3) will facilitate subsequent typological
and linguistic comparison across corpora with
manual annotations for syntax and/or morphology
according to different schemes.
6 Summary
We sketched major research directions on the de-
velopment of resources, NLP tools and algorithms
to facilitate the study Old Germanic languages
currently pursued at the Goethe-University Frank-
furt in the context of two related research initia-
tives, the LOEWE cluster ?Digital Humanities?
and the project ?Old German Reference corpus?.
Our efforts resulted in the creation of the fol-
lowing resources:
? a massive parallel corpus of TEI-
conformant Bibles including all con-
temporary Germanic languages as well as
early stages of Germanic languages (Sect.
2.1).
? an exhaustive, morphosyntactically anno-
tated corpus of OHG and OS with mor-
phosyntactic annotations. Annotations were
automatically derived from glossaries and
manually refined (Sect. 2.2).
? an index providing a thematical alignment
of the four gospels with each other as well as
with OHG and OS gospel harmonies (Sect.
2.3). This high quality alignment provides a
solid basis for further more fine-grained au-
tomatic alignment (Sect. 4.1).
? XML versions of lexical resources, includ-
ing etymological dictionaries of Old Ger-
manic languages (Sect. 3)
? an RDF-based linked etymological
database of Old Germanic languages
compiled from the latter (Sect. 3)
? a Linked Data representation of annotation
schemes for corpora, NLP tools and gram-
matical features in the linked lexicon data
(Sect. 3, 4.3)
The resources created provide an excellent test-
bed for various NLP algorithms, particularly for
experiments on alignment and annotation projec-
tion techniques: We developed different metrics
for quasi-parallel alignment applied to the cor-
pus of gospel harmonies (Sect. 4.1). For subse-
quent analysis, evaluation and refinement by his-
torical linguists, we provide a graphical visualiza-
tion and user interface in a form of a webpage.
This is an on-going project and further research
will aim at refining metrics and their combination.
Our massive parallel corpus is a perfect prereq-
uisite for annotation projection (Sect. 4.2). Our
experiments on annotation projections and cross-
lingual parser adaptation showed that it is possible
to use (hyperlemmatized) training data from mul-
tiple closely related languages in place of training
data for the language under consideration, and on
small sets of parallel training data available, this
did not lead to a significant loss of performance.
The only exception in the experiment (IS) is also
most remote from the other languages considered.
A severe limitation of this experiment was that
it required operating on (variants of) the same an-
notation scheme. Another line of our research is
focused on researching of ways to surmount such
restrictions. We thus adopt a modular approach
with annotation schemes linked to the OLiA Ref-
erence Model to harmonize annotations and gram-
matical features from lexicons (Sect. 4.3).
Finally, applications of these algorithms and re-
sources in research questions in philology, histor-
ical linguistics and comparative linguistics were
sketched in Sect. 5.
While most resources described in this pa-
per have been developed for several years at the
Goethe-University Frankfurt, the increased focus
on NLP and Linked Data represent novel develop-
ments pursued by the newly established Applied
Computational Linguistics Lab at the Goethe Uni-
versity Frankfurt. Different aspects of research
sketched in this paper thus describe on-going ac-
tivities at different degrees of completion.
29
Acknowledgements
The research of Christian Chiarcos, Maria
Sukhareva, Tim Price, Gaye Detmold, and Jens
Chobotsky described in this paper was supported
by the research cluster ?Digital Humanities? at the
Goethe-University Frankfurt, funded through the
LOEWE programme of the federal state of Hes-
sia. The research of Roland Mittmann was con-
ducted in the project ?Old German Reference cor-
pus?, funded by the Deutsche Forschungsgemein-
schaft (DFG).
References
Christian Bizer, Tom Heath, and Tim Berners-Lee.
2009. Linked Data ? The story so far. International
Journal on Semantic Web and Information Systems
(IJSWIS), 5(3):1?22.
Marcel Bollmann, Florian Petran, and Stefanie Dip-
per. 2011. Rule-based normalization of historical
texts. In Proceedings of the Workshop on Language
Technologies for Digital Humanities and Cultural
Heritage (LaTeCH-2011), pages 34?42, Hissar, Bul-
garia, September.
Gosse Bouma, Gertjan Van Noord, and Robert Malouf.
2001. Alpino: Wide-coverage computational analy-
sis of Dutch. Language and Computers, 37(1):45?
59.
Sabine Brants, Stefanie Dipper, Peter Eisenberg, Sil-
via Hansen-Schirra, Esther K?onig, Wolfgang Lezius,
Christian Rohrer, George Smith, and Hans Uszkor-
eit. 2004. Tiger: Linguistic interpretation of a ger-
man corpus. Research on Language and Computa-
tion, 2(4):597?620.
Christian Chiarcos. 2008. An ontology of linguistic
annotations. LDV Forum, 23(1):1?16.
Christian Chiarcos. 2010. Towards robust multi-tool
tagging. An OWL/DL-based approach. In Proc. of
the 48th Annual Meeting of the Association for Com-
putational Linguistics (ACL-2010), pages 659?670,
Uppsala, Sweden.
Michael Collins, Lance Ramshaw, Jan Haji?c, and
Christoph Tillmann. 1999. A statistical parser for
Czech. In Proc. of the 37th Annual Meeting of the
Association for Computational Linguistics (ACL-
1999), pages 505?512, Maryland, June.
Marie-Catherine De Marneffe and Christopher D Man-
ning. 2008. The Stanford typed dependencies rep-
resentation. In Proceedings of the COLING-2008
Workshop on Cross-Framework and Cross-Domain
Parser Evaluation, pages 1?8.
Gerard de Melo. to appear. Lexvo.org: Language-
related information for the linguistic linked data
cloud. Semantic Web Journal, pages 1?7.
Judith Eckle-Kohler, John McCrae, and Christian
Chiarcos. to appear. lemonUby ? A large, in-
terlinked, syntactically-rich resource for ontologies.
Semantic Web Journal: Multilingual Linked Open
Data.
Jost Gippert. 2011. The TITUS Project. 25 years
of corpus building in ancient languages. In Per-
spektiven einer corpusbasierten historischen Lin-
guistik und Philologie. Internationale Tagung des
Akademienvorhabens ?Alt?agyptisches W?orterbuch?
an der Berlin-Brandenburgischen Akademie der
Wissenschaften, pages 169?192, Berlin, December.
Dag TT Haug and Marius J?hndal. 2008. Creat-
ing a parallel treebank of the old Indo-European
bible translations. In Proceedings of the Language
Technology for Cultural Heritage Data Workshop
(LaTeCH 2008), pages 27?34, Marrakech, Morocco,
June.
Odd Einar Haugen, Tone Merete Bruvik, Matthew
Driscoll, Karl G Johansson, Rune Kyrkjeb?, and
Tarrin Wills. 2008. The Menota handbook: Guide-
lines for the electronic encoding of Medieval Nordic
primary sources.
Roland Hinterh?olzl and Svetlana Petrova. 2009. In-
formation Structure and Language Change: New
Approaches to Word Order Variation in Germanic.
Mouton de Gruyter.
Richard Johansson and Pierre Nugues. 2007. Ex-
tended constituent-to-dependency conversion for
English. In Proceedings of the 16th Nordic Con-
ference on Computational Linguistics (NoDaLiDa-
2007), pages 105?112, Tartu, Estonia, May.
Anthony Kroch and Ann Taylor. 2000. The
Penn-Helsinki Parsed Corpus of Middle English
(PPCME2). Department of Linguistics, University
of Pennsylvania. CD-ROM.
Anthony Kroch, Beatrice Santorini, and Lauren Delfs.
2004. The Penn-Helsinki Parsed Corpus of Early
Modern English (PPCEME). Department of Lin-
guistics, University of Pennsylvania. CD-ROM.
Anthony Kroch, Beatrice Santorini, and Ariel Diertani.
2010. The Penn-Helsinki Parsed Corpus of Modern
British English (PPCMBE). Department of Linguis-
tics, University of Pennsylvania. CD-ROM.
Geoffrey Leech and Andrew Wilson. 1996. EAGLES
guidelines: Recommendations for the morphosyn-
tactic annotation of corpora.
Caitlin Light. 2013. Parsed Corpus of Early
New High German (PCENHG), v. 0.5. Uni-
versity of Pennsylvania, http://enhgcorpus.
wikispaces.com/.
Sonja Linde and Roland Mittmann. 2013. Old German
Reference Corpus. Digitizing the knowledge of the
19th century. In Paul Bennett, Martin Durrell, Silke
30
Scheible, and Richard J. Whitt, editors, New Meth-
ods in Historical Corpus Linguistics = Korpuslin-
guistik und interdiziplinre Perspektiven auf Sprache
? Corpus linguistics and Interdisciplinary perspec-
tives on language (CLIP), volume 3 of Korpuslin-
guistik und interdiziplinre Perspektiven auf Sprache
? Corpus linguistics and Interdisciplinary perspec-
tives on language (CLIP), T?ubingen. Narr.
Joakim Lundborg, Torsten Marek, Ma?el Mettler, and
Martin Volk. 2007. Using the Stockholm
TreeAligner. In Proceedings of the 6th Workshop
on Treebanks and Linguistic Theories (TLT-2007),
pages 73?78.
John McCrae, Dennis Spohr, and Philipp Cimiano.
2011. Linking lexical resources and ontologies on
the semantic web with lemon. In The Semantic
Web: Research and Applications, pages 245?259.
Springer.
Roland Mittmann. 2013. Digitalisierung historischer
Glossare zur automatisierten Vorannotation von
Textkorpora am Beispiel des Altdeutschen. Journal
for Language Technology and Computational Lin-
guistics (JLCL), 27(2):39?52.
Graham Neubig, Taro Watanabe, Shinsuke Mori, and
Tatsuya Kawahara. 2012. Machine translation with-
out words through substring alignment. In Proc. of
the 50th Annual Meeting of the Association for Com-
putational Linguistics (ACL-2012), pages 165?174,
Jeju Island, Korea, July.
Joakim Nivre, Jens Nilsson, and Johan Hall. 2006. Tal-
banken05: A Swedish treebank with phrase struc-
ture and dependency annotation. In Proc. of the 5th
International Conference on Language Resources
and Evaluation (LREC-2006), pages 1392?1395.
Sebastian Nordhoff and Harald Hammarstr?om. 2011.
Glottolog/langdoc: Defining dialects, languages,
and language families as collections of resources. In
Proceedings of the First International Workshop on
Linked Science 2011 (LISC-2011).
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29(1):19?51.
Antonio Pareja-Lora and Guadalupe Aguado de Cea.
2010. Ontology-based interoperation of linguistic
tools for an improved lemma annotation in Span-
ish. In Proc. of the 6th International Conference on
Language Resources and Evaluation (LREC-2010),
Valetta, Malta, May.
Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012.
A universal part-of-speech tagset. In Proc. of the 8th
International Conference on Language Resources
and Evaluation (LREC-2012), pages 2089?2096, Is-
tanbul, Turkey.
Svetlana Petrova, Michael Solf, Julia Ritz, Christian
Chiarcos, and Amir Zeldes. 2009. Building and
using a richly annotated interlinear diachronic cor-
pus: The case of Old High German Tatian. TAL,
50(2):47?71.
Timothy Blaine Price. 2012. Multi-faceted alignment:
Toward automatic detection of textual similarity in
gospel-derived texts. In Proceedings of Historical
Corpora 2012, Frankfurt, Germany.
Philip Resnik, Mari Broman Olsen, and Mona Diab.
1997. Creating a parallel corpus from the book of
2000 tongues. In Proc. of the Text Encoding Initia-
tive 10th Anniversary User Conference (TEI-10).
Eir??kur R?ognvaldsson, Anton Karl Ingason, Einar Freyr
Sigurdsson, and Joel Wallenberg. 2012. The Ice-
landic Parsed Historical Corpus (IcePaHC). In Proc.
of the 8th International Conference on Language
Resources and Evaluation (LREC-2012), Istanbul,
Turkey, May.
Anne Schiller, Simone Teufel, Christine St?ockert, and
Christine Thielen. 1999. Guidelines f?ur das Tagging
deutscher Textcorpora mit STTS. Technical report,
Universit?aten Stuttgart und T?ubingen.
Wojciech Skut, Brigitte Krenn, Thorsten Brants, and
Hans Uszkoreit. 1997. An annotation scheme for
free word order languages. In Proc. of the 5th Con-
ference on Applied Natural Language Processing,
pages 88?95.
Kathrin Spreyer and Jonas Kuhn. 2009. Data-driven
dependency parsing of new languages using incom-
plete and noisy training data. In Proc. of the
13th Conference on Computational Natural Lan-
guage Learning (CoNLL-2009), pages 12?20, Boul-
der, CO, June.
Ann Taylor, Mitchell Marcus, and Beatrice Santorini.
2003a. The Penn Treebank: An overview. In Anne
Abeill, editor, Treebanks, pages 5?22. Springer,
Dordrecht.
Ann Taylor, Anthony Warner, Susan Pintzuk, and
Frank Beths. 2003b. The York-Toronto-Helsinki
parsed corpus of Old English prose.
Heike Telljohann, Erhard W Hinrichs, Sandra K?ubler,
Heike Zinsmeister, and Kathrin Beck. 2003. Style-
book for the T?ubingen treebank of written German
(T?uBa-D/Z). Technical report, Seminar f?ur Sprach-
wissenschaft, Universit?at T?ubingen, Germany.
31
Proceedings of the First Workshop on Applying NLP Tools to Similar Languages, Varieties and Dialects, pages 11?20,
Dublin, Ireland, August 23 2014.
Diachronic proximity vs. data sparsity in cross-lingual parser projection.
A case study on Germanic
Maria Sukhareva
Goethe University Frankfurt
sukharev@em.uni-frankfurt.de
Christian Chiarcos
Goethe University Frankfurt
chiarcos@em.uni-frankfurt.de
Abstract
For the study of historical language varieties, the sparsity of training data imposes immense prob-
lems on syntactic annotation and the development of NLP tools that automatize the process. In
this paper, we explore strategies to compensate the lack of training data by including data from
related varieties in a series of annotation projection experiments from English to four old Ger-
manic languages: On dependency syntax projected from English to one or multiple language(s),
we train a fragment-aware parser trained and apply it to the target language. For parser training,
we consider small datasets from the target language as a baseline, and compare it with models
trained on larger datasets from multiple varieties with different degrees of relatedness, thereby
balancing sparsity and diachronic proximity.
Our experiments show
(a) that including related language data to training data in the target language can improve
parsing performance,
(b) that a parser trained on data from two related languages (and none from the target language)
can reach a performance that is statistically not significantly worse than that of a parser
trained on the projections to the target language, and
(c) that both conclusions holds only among the three most closely related languages under
consideration, but not necessarily the fourth.
The experiments motivate the compilation of a larger parallel corpus of historical Germanic va-
rieties as a basis for subsequent studies.
1 Background and motivation
We describe an experiment on annotation projection (Yarowski and Ngai, 2001) between different Ger-
manic languages, resp., their historical varieties, with the goal to assess to what extent sparsity of parallel
data can be compensated by material from varieties related to the target variety, and studying the impact
of diachronic proximity onto such applications.
Statistical NLP of historical language data involves general issues typical for low-resource languages
(the lack of annotated corpora, data sparsity, etc.), but also very specific challenges such as lack of stan-
dardized orthography, unsystematized punctuation, and a considerable degree of morphological varia-
tion. At the same time, historical languages can be viewed as variants of their modern descendants rather
than entirely independent languages, a situation comparable to low-resource languages for which a di-
achronically related major language exists. Technologies for the cross-lingual adaptation of NLP tools or
training of NLP tools on multiple dialects or language stages are thus of practical relevance to not only
historical linguistics, but also to modern low-resource languages.
The final paper will be published under a Creative Commons Attribution 4.0 International Licence (CC-BY), http:
//creativecommons.org/licenses/by/4.0/.
11
in this context, historical language allows to study the impact of the parameter of diachronic related-
ness, as it can be adjusted relatively freely, e.g., by choosing dialects which common ancestor existed
just a few generations before rather than languages separated for centuries. A focused study of the im-
pact of diachronic relatedness on projected annotations requires sufficient amounts of parallel texts for
major language stages, and comparable annotations as a gold standard for evaluation. In this regard, the
Germanic languages provide us with a especially promising sandbox to develop such algorithms due to
the abundance of annotated corpora and NLP tools of the modern Germanic languages, most noteably
Modern English.
We employ annotation projection from EN to Middle English (ME), Old English (OE) and the less
closely related Early Modern High German (DE) and Middle Icelandic (IS) for which we possess com-
parable annotations, and test the following hypotheses:
(H1) Adding data from related varieties compensates the sparsity of target language training data.
(H2) Data from related languages compensates the lack of target language training data.
(H3) The greater the diachronic proximity, the better the performance of (H1) and (H2).
We test these hypotheses in the following setup: (1) Hyperlemmatization: Different historical variants
are normalized to a consistent standard, e.g., represented by a modern language (Bollmann et al., 2011).
We emulate hyperlemmatization by English glosses automatically obtained through SMT. (2) Projection:
We create training data for a fragment-aware dependency parser (Spreyer et al., 2010) using annotation
projection from modern English. (3) Combination and evaluation: Parser modules are trained on differ-
ent training data sets, and evaluated against existing gold annotations.
In our setting, we enforce data sparsity by using deliberately small training data sets. This is because
we emulate the situation of less-documented languages that will be in the focus of subsequent experi-
ments, namely, Old High German and Old Saxon, which are relatively poorly documented. We do hope,
however, that scalable NLP solutions can be developed if we add background information from their de-
scendants (Middle/Early Modern High German, Middle/Modern Low German), or closely related, and
better documented varieties (Old English, Middle Dutch).
Hence, the goal of our experiment is not to develop state-of-the-art parsers, but to detect statistically
significant differences in parsing performance. If these can be confirmed, this motivates creating a larger
corpus of parallel texts in Germanic languages as a basis for subsequent studies and more advanced,
projection-based technologies for older and under-resourced Germanic languages.
2 Languages and corpus data
We use parallel biblical texts in Old English (OE), Middle English (ME), Middle Icelandic (IS) and Early
Modern High German (DE). This selection is determined by the availability of syntactically annotated
corpora with closely related annotation schemes. As these schemes are derived from the Penn TreeBank
(PTB) bracketing guidelines (Taylor et al., 2003a), we decided to use Modern English (EN) as a source
for the projections.
The Germanic languages derive from Proto-Germanic as a common ancestor. OE and Old High
German separated in the 5th c. The antecessor of IS separated from this branch about 500 years earlier.
Among Germanic languages, great differences emerged, but most languages developed similarly towards
a loss of morphology and a more rigid syntax, a tendency particularly prevalent in EN.
As compared to this, OE had a relatively free OV word order, with grammatical roles conveyed through
morphological markers. The OE case marking system distinguished four cases, but eventually collapsed
during ME, resulting in a strict strict VO word order in EN (Trips, 2002; van Kemenade and Los, 2009;
Cummings, 2010).
Unlike EN, DE preserved four cases, and a relatively free word order (Ebert, 1976). A characteristic
of German are separable verb prefixes, leading to 1 : n mappings in the statistical alignment with EN.
12
Figure 1: Workflow
Unlike EN and DE, IS is a North Germanic language. It is assumed to be conservative, with relatively
free word order with both OV and VO patterns and a rich morphology that leads to many 1 : n alignments
with EN, e.g., for suffixed definite articles; we thus expect special challenges for annotation projection
under conditions with limited training data.
Different from the old languages, EN developed a rigid word order and a largely reduced morphol-
ogy. A direct adaptation of an existing English parser to (hyperlemmatized) OE, IS or DE is thus not
promising. Therefore, we employ an approach based on annotation projection.
The corpus data we used consists of parsed bible fragments from manually annotated corpora, mostly
the gospels of Matthew (Mt), Mark (Mr), John (J) and Luke (L), from which we drew a test set of 147
sentences and a training set of 437 sentences for every language.
ME and OE The Penn-Helsinki Parsed Corpus of Middle English (PPCME2)
1
and the York-Toronto-
Helsinki Parsed Corpus of Old English Prose (Taylor et al., 2003b, YCOE) use a variant of the PTB
annotation schema (Taylor et al., 2003a). YCOE contains the full West Saxon Gospel, but PPCME2
contains only a small fragment of a Wycliffite gospel of John, the ME data is thus complemented
with parts of Genesis (G) and Numbers (N).
IS The Icelandic Parsed Historical Corpus (R?ognvaldsson et al., 2012, IcePaHC) is annotated follow-
ing YCOE with slight modifications for specifics of IS. We use the gospel of John from Oddur
Gottsk?alksson?s New Testament, a direct translation from Luther.
DE The Parsed Corpus of Early New High German
2
contains three gospels from Luther?s Septembertes-
tament (1522). As an IcePaHC side-project, it adapts the IS annotation scheme.
EN For EN, we use the ESV Bible.
3
Due to a moderate number of archaisms, it is particularly well-
suited for automated annotation.
3 Experimental setup
We study the projection of dependency syntax, as it is considered particularly suitable for free word-order
languages like IS, OE and DE. The existing constituent annotations were thus converted with standard
tools for PTB conversion. Figure 1 summarizes the experimental setup.
For annotating EN, we created dependency versions of WSJ and Brown sections of the PTB with
the LTH Converter (Johansson and Nugues, 2007). We trained Malt 1.7.2 (Nivre, 2003), optimized its
features with MaltOptimizer (Ballesteros and Nivre, 2012), and parsed the EN bible using the resulting
feature model.
1
http://www.ling.upenn.edu/hist-corpora/PPCME2-RELEASE-3/index.html
2
http://enhgcorpus.wikispaces.com
3
http://esv.org
13
The ME, OE, DE and IS datasets were word aligned with EN using GIZA++ (Och and Ney, 2003).
1 : n alignments were resolved to the most probable 1 : 1 mapping. During annotation projection,
we assume that the aligned words represent the respective heads for the remaining n ? 1 words. These
dependent words are assigned the dependency relation FRAG to the word that got the highest score in
the translation table. This solution solves, among others, the problem of separable verb prefixes in DE,
for example, DE ruffen with prefix an would be aligned to English word call: As P (?call?|?an?) <
P (?call?|?ruffen?), the syntactic information of ?call? will be projected to ?ruffen? and ?an? will be
its dependent labeled with ?FRAG?. The projected dependency trees were checked on well-formedness,
sentences with cycles were dismissed from the data set.
We formed training sets containing 437 sentences for ME, OE, DE, IS. Monolingual data sets were
combined into bi-, tri- or quadrilingual training data sets with a simple concatenation, thereby creating
less sparse, but more heterogeneous training data sets. For every language, test data was taken from J,
174 sentences per language.
We used the projected dependencies to train fMalt (Spreyer et al., 2010), a fragment-aware dependency
parser, in order to maximize the gain of information from incomplete projections.
In our setting, fMalt used two features, POS and hyperlemmas.
POS The tagsets of the historical corpora originate in PTB, but show incompatible adaptations to the
native morphosyntax. Tagset extensions on grammatical case in OE, IS and DE were removed and
language-specific extensions for auxiliaries and modal verbs were leveled, in favor of a common,
but underspecified tagset for all four languages. As these generalized tags preserve information not
found in EN, they were fed into the parser.
(hyper-)lemma Lexicalization is utterly important for the dependency parsing (Kawahara and Uchi-
moto, 2007), but to generalize over specifics of historical language varieties, hyperlemmatization
needs to be performed. Similar to Zeman and Resnik (2008), we use projected English words as
hyperlemmas and feed them into the parser. Hyperlemmatization against a closely related languages
is acceptable as we can expect that the syntactic properties of words are likely to be similar.
The projected annotations were then evaluated against dependency annotations created analoguously to
the EN annotations from manual PTB-style constituency syntax. As LTH works exclusively on PTB
data, the historical corpora were converted with its antecessor Penn2Malt
4
using user-defined head-rules
(Yamada and Matsumoto, 2003).
4 Evaluation results
baseline ?UAS worst model ?UAS best model ?UAS
UAS +1 +2 +1 +2 +3
ME .60 +DE +.00
n.s.
+DE+IS -.01
n.s.
+OE +.01
n.s.
+OE+IS +.01
n.s.
-.00
n.s.
OE .31 +IS -.00
n.s.
+DE+IS -.02
n.s.
+DE +.02
n.s.
+ME+DE +.00
n.s.
+.02
n.s.
DE .41 +OE +.02
n.s.
+OE+IS +.03
?
+ME +.04
???
+ME+IS +.03
?
+.04
??
IS .32 +IS -.02
n.s.
+DE+OE -.02
n.s.
+ME +.00
n.s.
+ME+DE -.01
n.s.
-.04
??
(a) trained on target and related language(s)
baseline ?UAS worst model ?UAS best model ?UAS
UAS 1 2 1 2 3
ME .60 OE -.09
???
DE-IS -.01
n.s
IS -.05
???
IS+OE -.02
n.s.
-.02
n.s.
OE .31 DE -.03
?
ME-DE -.01
n.s.
ME -.02
n.s.
ME+IS -.01
n.s.
-.00
n.s.
DE .41 OE -.01
n.s.
OE-IS +.02
n.s.
IS +.02
n.s.
IS+ME +.05
???
+.04
??
IS .32 OE -.07
???
DE-OE -.02
n.s.
ME -.06
???
ME+DE -.02
n.s.
-.04
??
(b) trained on related language(s) alone
Table 1: Performance of best- and worst-performing parsing models (UAS diff. vs. baseline with ?
2
:
?
p < .05,
??
p < .01,
???
p < .005)
We evaluate the unlabeled attachment score (Collins et al., 1999, UAS), i.e., the proportion of tokens in
a sentence (without punctuation) that are assigned the correct head, on test sets of 174 sentences in each
language.
4
http://stp.lingfil.uu.se/ nivre/research/Penn2Malt.html
14
As a baseline for the evaluation we take the performance of the parser trained solely on the target
language data. As shown in Tab. 1 (second col.), the UAS scores mirror both the diachronic relatedness
(ME>DE>IS), as well as the relative loss of morphology (ME>DE>IS/OE), indicating that diachronic
relatedness may not be the only factor licensing the applicability of the annotation projection scenario
(H3). It is also important, though, to keep in mind that the OE and IS translations of the Bible had
considerable influence of Latin syntax, whereas DE and ME translations aimed for a language easy to
understand.
Table 1a gives the best and worst results for the unlabeled attachment score for the parser trained on
target and related language(s) (H1). With the exception of DE, we observed no significant differences in
UAS scores relative to the baseline. DE may benefit from ME because of its more flexible syntax (thus
closer to ME [and OE] than to Modern English), and from IS because of Luther?s direct influence on the
IS bible. That ME did not mutually benefit from German may be due to the good quality of ME annota-
tion projections (resulting from its proximity to EN). Parsers trained on trilingual and quadrilingual sets
exhibited no improvement over the bilingual sets. Taken together, we found no positive effect of using
additional training data from language stages diachronically separated for more than 500 years (e.g.,
OE/ME), but also, we did not find a negative effect among the West Germanic languages. If additional
training material is carefully chosen among particularly closely related varieties, however, the DE effect
can be replicated, and then, including related language data to training data in the target language can
improve parsing performance.
While in our setting, training data from related languages may (but does not have to) improve a parser
training if training data for the target language is available, it may very well be employed fruitfully if
no training data for the target language is available (H2): Table 1b shows that, unsurprisingly, parsers
trained only on one related language had the lowest performance in the experiment, so using multiple
train languages seems to compensate language-specific idiosyncrasies. The best-performing parsing
models trained on two or more related languages achieved a performance not significantly worse (if not
better) than models being trained on target language data. This effect extends to all languages except
for IS and indicates that a careful choice of additional training data from related varieties may facilitate
annotation projection. Equally important (and valid across all languages) is that none of the models
trained on one language outperformed any of the model trained on two languages. Using training data
from two related languages doesn?t seem to hurt performance in our setting. Adding a third language
did not yield systematic improvements, the scores for trilingual models are in the range of the bilingual
models.
Again, DE is exceptionally good, benefitting from being a direct source of the IS translation as well as
structurally comparable to ME. In both settings, the worst-performing language is IS, with a significant
drop in annotation projection quality with Western Germanic material added, indicating that diachronic
distance between Northern and Western Germanic languages limits the applicability of (H2), thereby
supporting (H3).
Taken together, our results indicate
1. a significant positive effect for the Western Germanic languages (ME, OE, DE) for (H2), and
2. a significant negative effect for Western and Northern Germanic languages (IS) for (H2)
As a tentative hypothesis, one may speculate that languages separated for 1000 years (OE-IS) or more
are too remote from each other to provide helpful background information, but that languages separated
within the last 750 years (ME-DE) or less are still sufficiently close. This novel assumption may provide
a guideline for future efforts to project annotations among related languages, and is thus of immense
practical relevance for developing future NLP tools for historical and less-resourced language varieties.
Ultimately, one may formulate rules of best practice like the following:
? If no syntactic annotations for a target language are available, annotation projection among closely
related languages may be a solution. Even with limited amounts of parallel data, diachronic dis-
tances of more than 500 years can be successfully bridged (EN/ME, baseline).
15
? If no syntactic annotations for a target language are available, a parser trained on hyperlemmatized
corpora in two languages may yield a performance comparable to a parser trained on small amounts
of target data. A parser trained on hyperlemmatized monolingual data may be significantly worse
(H2).
? The sparsity of parallel text to conduct annotation projection and train a (hyperlemmatized) parser
can only be compensated by adding parallel data from one related language if these are closely
diachronically related (with a separation being less than, say, 500 years ago) and at a similar de-
velopmental stage (DE/ME, H1). Adding data from multiple, equally remote languages does not
necessarily improve the results further.
At the current state, such recommendations would be premature, they require deeper investigation, but
with the confirmation of (H2) and (H3), we can now motivate larger-scale efforts to compile a massive
parallel corpus of historical Germanic language varieties as a basis for subsequent studies. Initial steps
towards this goal are described in the following section.
5 Towards a massive parallel corpus of historical Germanic languages
With the long-term goal to systematically assess the impact of the factor of diachronic proximity, we
focus on annotation projection among the Germanic languages as test field. The Germanic languages
represent a particularly well-resourced, well-documented and well-studied language family which devel-
opment during the last 1800 years is not only well-explored, but also documented with great amounts
of (parallel) data, ranging from the 4th century Gothic bible over a wealth of Bible translations since
the middle ages to the modern age of communication with its abundance of textual resources for even
marginal varieties. Motivated from our experiment, we thus began to compile a parallel corpus of his-
torical and dialectal Germanic language varieties. Primary source data for a massive parallel corpus of
historical varieties of any European language is mostly to be drawn from the Bible and related literature.
The Bible is the single most translated book in the world and available in a vast majority of world lan-
guages. It is also often the case that there are several biblical translation existing for a language. Bible
data also represents the majority of parallel data available for historical Germanic languages, and for the
case of OS and OHG, gospel harmonies represent even the majority of data currently known. Beyond
this, the corpus includes Bible excerpts and paraphrases from all Germanic languages and their major
historical stages.
Tab. 2 gives an overview over the current status of the Parallel Bible Corpus. At the moment, 271 texts
with about 38.4M tokens have been processed, converted from their original format and verse-aligned
according to their original markup or with a lexicon-supported geometric sentence aligner (T?oth et al.,
2008). In the table, ?text? means any document ranging from a small excerpt such as the Lord?s Prayer
(despite their marginal size valuable to develop algorithms for normalization/[hyper]lemmatization) over
gospel harmonies and paraphrases to the entire bible that has been successfully aligned with Bible verses.
The compiled corpus, excerpts and fragments for all Germanic languages marked up with IDs for verses,
chapters and books. For data representation, we employed an XML version of the CES-scheme de-
veloped by Resnik et al. (1997). Having outgrown the scale of Resnik?s earlier project by far, we are
currently in transition to TEI P5.
As it is compiled from different sources, the corpus cannot be released under a free or an academic
license. It contains material without explicit copyright statement, with proprietary content (e.g., from
existing corpora), or available for personal use only. Instead, we plan to share the extraction and con-
version scripts we used. For the experiments we aim to prepare, we focus on primary data, the texts in
this collection are not annotated. Where annotations are available from other corpora or can be produced
with existing tools, however, these annotated versions will be aligned with the Bibles and included in
subsequent experiments.
16
after 1800- 1600- 1400- 1100- before
1900 1900 1800 1600 1400 1100
West Germanic
English 2 2 2 6 3 (+2) 1
Pidgin/Creol 2
Scots (6) (1)
Frisian 2 (+8) (12)
Dutch 4 1 5 (1)
L. Franconian (47) (21)
Afrikaans 3
German 3 1 (19) 1 (+4) 1 (+1) 1
dialects 3 (+2)
Yiddish 1
Low German 3 (+18) (66) (2) 1
Plautdietsch 2
Danish 1 North & East Germanic
Swedish 3 (3) (1)
Bokm?al 2
Nynorsk 2
Icelandic 1 1
Faroese 1
Norn (2)
Gothic 1
tokens 21.8M 3.2M 2.7M 9.2M 1.2M 0.2M
Table 2: Verse-aligned texts in the Germanic parallel Bible corpus (parentheses indicate marginal frag-
ments with less than 50,000 tokens)
6 Summary and outlook
This paper describes a motivational experiment on annotation projection, or more precisely, strategies
to compensate data sparsity (the lack of parallel data) with material from related, but heterogeneous
varieties to facilitate cross-language parser adaptation for low-resource historical languages. We used a
fragment-aware dependency parser trained on annotation projections from ESV Bible to four historical
languages.
Our results indicate a lexicalized fragment-aware parser trained on a small amount of annotation pro-
jections can yield good results on closely related languages. In a situation of the absence of training
data for the target language (or, for example, in the situation where there is no parallel corpora for the
target language), a hyperlemmatized parser trained on (projected) annotations from two or more related
languages is likely to outperform a parser trained on a single related language.
We achieved statistically significant differences in parser performance trained on (a) target language
data, and (b) target language and data from related varieties, resp. (c) data from related varieties only.
These indicate that closely related languages (say, with a common ancestor about 750 years ago, such as
DE and ME) have some potential to compensate sparsity of parallel data in the target variety, wheres this
potential does not seem to exist for more remotely related languages (say, with a common ancestor more
than 1000 years ago such as OE and IS).
The experimental results revealed that the parser performance can, indeed, be improved by means of
including a related language to the training data, but we had a significant effect for only one language
under consideration, indicating that the diachronic proximity of the languages considered was possibly
too large, and thereby motivating subsequent experiments, and in particular, the creation of a larger
parallel corpus of historical Germanic language varieties. We described initial steps in the compilation
of this corpus.
Our experiment raises a number of open issues that are to be pursued in subsequent studies:
1. Our setup has a clear bias towards English (in the annotation schemes used and the source annota-
tions), and parser performance was strongly affected by the syntactic difference between the target
language and Modern English from which the syntactic dependencies were projected, indicating the
relevance of diachronic relatedness as well as the developmental state of a related language. Sub-
sequent experiments will hence address the inclusion of richer morphological features, projection
from other languages and evaluation against syntactic annotations according to other schemes not
derived from the Penn Treebank, as currently available, for example, for Old High German, Old
Norse, and Gothic.
17
2. The hyperlemmatization in our approach was achieved through alignment/SMT, and a similar
lexically-oriented approach has been suggested by (Zeman and Resnik, 2008). Alternative strate-
gies more suitable for scenarios with limited amounts of training data may include the use of ortho-
graphical normalization techniques (Bollmann et al., 2011) or substring-based machine translation
(Neubig et al., 2012) and are also subject to on-going research. We assume that SMT-based hyper-
lemmatization introduces more noise than these strategies, so that it is harder to achieve statistically
significant results. Our findings are thus likely to remain valid regardless of the hyperlemmatization
strategy. This hypothesis is, however, yet to be confirmed in subsequent studies.
3. Our experiment mostly deals with data translated from (or at least informed by) the Latin Vulgate.
Our data may be biased by translation strategies which evolved over time, from very literal trans-
lations (actually, glossings) of Latin texts in the early middle ages to Reformation-time translations
aiming to grasp the intended meaning rather than to preserve the original formulation. A focus on
classical languages is, however, inherent to the parallel material in our domain. A representative
investigation of annotation projection techniques thus requires the consideration of quasi-parallel
data along with parallel data. This can be found in the great wealth of medieval religious literature,
with Bible paraphrases, gospel harmonies, sermons and homilies as well as poetic and prose adap-
tations of biblical motives. The parallel corpus of Germanic languages thus needs to be extended
accordingly.
4. One may wonder how the annotation projection approach performs in comparison to direct applica-
tions of modern language NLP tools to normalized historical data language (Scheible et al., 2011).
While it is unlikely that such an approach could scale beyond closely related varieties, success-
ful experiments on the annotation of normalized historical language have been reported, although
mostly focused on token-level annotations (POS, lemma, morphology) of language stages which
syntax does not greatly deviate from modern rules (Rayson et al., 2007; Pennacchiotti and Zan-
zotto, 2008; Kestemont et al., 2010; Bollmann, 2013). For the annotation of more remotely related
varieties with more drastic differences in word order rigidity or morphology as considered here,
however, projection techniques are more promising as they have been successfully applied to un-
related languages, as well, but still benefit from diachronic proximity, cf. Meyer (2011) for the
projection-based morphological analysis of Modern and Old Russian.
The goal of our experiment was not to achieve state-of-the-art performance, but to show whether back-
ground material from related languages with different degrees of diachronic distance can help to com-
pensate data sparsity, in this case with an experiment on annotation projection. This hypothesis could be
confirmed and we found effects that ? even on the minimal amounts of data considered for this study ?
indicated statistically significant improvements.
It is thus to be expected that even greater improvements can be achieved by considering more closely
related pairs of languages, with greater amounts of data. The further exploration of this hypothesis is
the driving force behind our efforts to compile a massive corpus of parallel and quasi-parallel texts for
all major varieties of synchronic and historical Germanic languages. Algorithms successfully tested in
this context can be expected to be applicable to other scenarios in which, e.g., well-researched modern
languages may be employed to facilitate the creation of NLP tools for less-ressourced, related languages.
Our efforts are thus not specific to historical languages.
As the diachronic development and the diversification of the Germanic languages is well-documented
in this body of data, and the linguistic processes involved are well-researched, this data set represents an
extraordinarily valuable resource for philological and comparitve studies as well as Natural Language
Processing. In particular, we are interested in developing algorithms that explore and exploit the variable
degree of diachronic relatedness found between the languages in our sample. At the same time, we
cooperate with researchers from philology, historical and comparative linguistics, which research on
intertextuality, diachronic lexicology, phonology, morphology and syntax we aim to support with NLP
tools developed on the basis of this body of parallel text.
18
References
Miguel Ballesteros and Joakim Nivre. 2012. Maltoptimizer: A system for maltparser optimization. In Nicoletta
Calzolari (Conference Chair), Khalid Choukri, Thierry Declerck, Mehmet Uur Doan, Bente Maegaard, Joseph
Mariani, Asuncion Moreno, Jan Odijk, and Stelios Piperidis, editors, Proceedings of the Eight International
Conference on Language Resources and Evaluation (LREC?12), Istanbul, Turkey, may. European Language
Resources Association (ELRA).
Marcel Bollmann, Florian Petran, and Stefanie Dipper. 2011. Rule-based normalization of historical texts. In Pro-
ceedings of the Workshop on Language Technologies for Digital Humanities and Cultural Heritage (LaTeCH-
2011), pages 34?42, Hissar, Bulgaria, September.
Marcel Bollmann. 2013. POS tagging for historical texts with sparse training data. In Proceedings of the 7th
Linguistic Annotation Workshop and Interoperability with Discourse, pages 11?18, Sofia, Bulgaria, August.
Association for Computational Linguistics.
Michael Collins, Lance Ramshaw, Jan Haji?c, and Christoph Tillmann. 1999. A statistical parser for czech. In
Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational
Linguistics, pages 505?512. Association for Computational Linguistics.
Michael Cummings. 2010. An Introduction to the Grammar of Old English: A Systemic Functional Approach.
Functional Linguistics. Equinox Publishing Limited.
Robert P. Ebert. 1976. Infinitival complement constructions in Early New High German. Linguistische Arbeiten.
De Gruyter.
Richard Johansson and Pierre Nugues. 2007. Extended constituent-to-dependency conversion for English. In
Proceedings of NODALIDA 2007, pages 105?112, Tartu, Estonia, May 25-26.
Daisuke Kawahara and Kiyotaka Uchimoto. 2007. Minimally lexicalized dependency parsing. In Proceedings
of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, pages 205?208.
Association for Computational Linguistics.
Mike Kestemont, Walter Daelemans, and Guy De Pauw. 2010. Weigh your words: Memory-based lemma-retrieval
for Middle Dutch literary texts. In CLIN 2010. Computational linguistics in the Netherlands 20, Utrecht, The
Netherlands, May.
Roland Meyer. 2011. New wine in old wineskins? Tagging Old Russian via annotation projection from modern
translations. Russian linguistics, 35(2):267?281.
Graham Neubig, Taro Watanabe, Shinsuke Mori, and Tatsuya Kawahara. 2012. Machine translation without words
through substring alignment. In Proceedings of the 50th Annual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers), pages 165?174, Jeju Island, Korea, July. Association for Computational
Linguistics.
Joakim Nivre. 2003. An efficient algorithm for projective dependency parsing. In Proceedings of the 8th Interna-
tional Workshop on Parsing Technologies (IWPT).
Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models.
Computational linguistics, 29(1):19?51.
Marco Pennacchiotti and Fabio Massimo Zanzotto. 2008. Natural language processing across time: An empirical
investigation on italian. In Advances in Natural Language Processing, pages 371?382. Springer.
Paul Rayson, Dawn Archer, Alistair Baron, Jonathan Culpeper, and Nicholas Smith. 2007. Tagging the Bard:
Evaluating the accuracy of a modern POS tagger on Early Modern English corpora. In Proceedings of the 4th
Corpus Linguistics Conference (CL-2007), Birmingham, UK.
Philip Resnik, Mari Broman Olsen, and Mona Diab. 1997. Creating a parallel corpus from the book of 2000
tongues. In Proc. of the Text Encoding Initiative 10th Anniversary User Conference (TEI-10).
Eir??kur R?ognvaldsson, Anton Karl Ingason, Einar Freyr Sigurdhsson, and Joel Wallenberg. 2012. The Icelandic
Parsed Historical Corpus (IcePaHC). In LREC, pages 1977?1984.
Silke Scheible, Richard J. Whitt, Martin Durrell, and Paul Bennett. 2011. Evaluating an ?off-the-shelf? POS-
tagger on Early Modern German text. In Proceedings of the 5th ACL-HLT Workshop on Language Technology
for Cultural Heritage, Social Sciences, and Humanities (LaTeCH-2011), pages 19?23, Portland, OR, USA,
June.
19
Kathrin Spreyer, Lilja Ovrelid, and Jonas Kuhn. 2010. Training parsers on partial trees: A cross-language com-
parison. In Proc. of the 7th International Conference on Language Resources and Evaluation (LREC-2010),
Valletta, Malta, May.
Ann Taylor, Mitchell Marcus, and Beatrice Santorini. 2003a. The Penn treebank: an overview. In Treebanks,
pages 5?22. Springer.
Ann Taylor, Anthony Warner, Susan Pintzuk, and Frank Beths. 2003b. The york-toronto-helsinki parsed corpus
of old english prose. University of York.
Krisztina T?oth, Rich?ard Farkas, and Andr?as Kocsor. 2008. Sentence alignment of hungarian-english parallel
corpora using a hybrid algorithm. Acta Cybern., 18(3):463?478, January.
C. Trips. 2002. From OV to VO in Early Middle English. Linguistics today. John Benjamins Pub.
A. van Kemenade and B. Los. 2009. The Handbook of the History of English. Blackwell Handbooks in Linguis-
tics. John Wiley & Sons.
Hiroyasu Yamada and Yuji Matsumoto. 2003. Statistical dependency analysis with support vector machines. In
Proceedings of IWPT. Vol. 3. 2003.
David Yarowski and Grace Ngai. 2001. Inducing multilingual POS taggers and NP bracketers via robust projection
across aligned corpora. In Proceedings of NAACL 2001, pages 200?207.
Daniel Zeman and Philip Resnik. 2008. Cross-language parser adaptation between related languages. In IJCNLP-
08 Workshop on NLP for Less Privileged Languages, pages 35?41, Hyderabad, India, Jan.
20
