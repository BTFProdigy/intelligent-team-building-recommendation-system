Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 37?46,
The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational Linguistics
Probabilistic Ontology Trees for Belief Tracking in Dialog Systems
Neville Mehta
Oregon State University
mehtane@eecs.oregonstate.edu
Rakesh Gupta
Honda Research Institute
rgupta@hra.com
Antoine Raux
Honda Research Institute
araux@hra.com
Deepak Ramachandran
Honda Research Institute
dramachandran@hra.com
Stefan Krawczyk
Stanford University
stefank@cs.stanford.edu
Abstract
We introduce a novel approach for robust
belief tracking of user intention within
a spoken dialog system. The space of
user intentions is modeled by a proba-
bilistic extension of the underlying do-
main ontology called a probabilistic on-
tology tree (POT). POTs embody a prin-
cipled approach to leverage the dependen-
cies among domain concepts and incorpo-
rate corroborating or conflicting dialog ob-
servations in the form of interpreted user
utterances across dialog turns. We tailor
standard inference algorithms to the POT
framework to efficiently compute the user
intentions in terms of m-best most proba-
ble explanations. We empirically validate
the efficacy of our POT and compare it to
a hierarchical frame-based approach in ex-
periments with users of a tourism informa-
tion system.
1 Introduction
A central function of a spoken dialog system
(SDS) is to estimate the user?s intention based on
the utterances. The information gathered across
multiple turns needs to be combined and under-
stood in context after automatic speech recogni-
tion (ASR). Traditionally, this has been addressed
by dialog models and data structures such as forms
(Goddeau et al, 1996) and hierarchical task de-
composition (Rich and Sidner, 1998). To formal-
ize knowledge representation within the SDS and
enable the development of reusable software and
resources, researchers have investigated the or-
ganization of domain concepts using IS-A/HAS-A
ontologies (van Zanten, 1998; Noh et al, 2003).
Because the SDS only has access to noisy ob-
servations of what the user really uttered due to
speech recognition and understanding errors, be-
lief tracking in speech understanding has received
particular attention from proponents of probabilis-
tic approaches to dialog management (Bohus and
Rudnicky, 2006; Williams, 2006). The mecha-
nism for belief tracking often employs a Bayesian
network (BN) that represents the joint probabil-
ity space of concepts while leveraging conditional
independences among them (Paek and Horvitz,
2000). Designing a domain-specific BN requires
significant effort and expert knowledge that is not
always readily available. Additionally, real-world
systems typically yield large networks on which
inference is intractable without major assumptions
and approximations. A common workaround to
mitigate the intensive computation of the joint dis-
tribution over user intentions is to assume full con-
ditional independence between concepts which vi-
olates the ground truth in most domains (Bohus
and Rudnicky, 2006; Williams, 2006).
We propose a novel approach to belief track-
ing for an SDS that solves both the design and
tractability issues while making more realistic
conditional independence assumptions. We repre-
sent the space of user intentions via a probabilistic
ontology tree (POT) which is a tree-structured BN
whose structure is directly derived from the hier-
archical concept structure of the domain specified
via an IS-A/HAS-A ontology. The specialization
(IS-A) and composition (HAS-A) relationships be-
tween the domain concepts are intuitive and pro-
vide a systematic way of representing ontological
knowledge for a wide range of domains.
The remainder of the paper is structured as fol-
lows. We begin by describing the construction of
the POT given a domain ontology. We show how
a POT employs null semantics to represent con-
sistent user intentions based on the specialization
and composition constraints of the domain. We
then show how standard inference algorithms can
be tailored to exploit the characteristics of the POT
to efficiently infer the m-best list of probable ex-
planations of user intentions given the observa-
37
tions. The POT and the associated inference al-
gorithm empower a dialog manager (DM) to ac-
count for uncertainty while avoiding the design
complexity, intractability issues, and other restric-
tive assumptions that characterize state-of-the-art
systems. The section on empirical evaluation de-
scribes experiments in a tourist information do-
main that compare the performance of the POT
system to a frame-based baseline system. The pa-
per concludes with a discussion of related work.
2 Problem Formulation
Let {X1, X2, . . . , XN} be a set of N concepts.
Every conceptXi takes its value from its finite dis-
crete domain D(Xi) which includes a special null
element for the cases where Xi is irrelevant. The
user intention space is defined as U = D(X1) ?
D(X2) ? ? ? ? ? D(XN ). At each dialog turn t,
the system makes a noisy observation ot about
the true user intention u ? U . ot consists of
a set of slots. A slot is a tuple ?v, d, c? where
v ? {X1, . . . , XN}, d ? D(v) is a value of v,
and c ? R is the confidence score assigned to that
concept-value combination by the speech under-
standing (SU) system.
The goal of belief tracking is to maintain
Pr(X1, . . . , XN |o1, . . . , ot), a distribution over
the N -dimensional space U conditioned on all the
observations made up to turn t. At each turn, the
belief is updated based on the new observations to
estimate the true, unobserved, user intention.
3 Probabilistic Ontology Trees
We model the space of the user intentions via a
POT. A POT is a tree-structured BN that extends
a domain ontology by specifying probability dis-
tributions over its possible instantiations based on
specializations and compositions.
3.1 Domain Ontology
To ensure that the corresponding POTs are tree-
structured, we consider a restricted class of do-
main ontologies over concepts.
Definition 1. A domain ontology is a labeled di-
rected acyclic graph. The set of vertices (corre-
sponding to the domain concepts) is partitioned
into {V0}, VS , and VC , where V0 is the only root
node, VS is the set of specialization nodes (re-
lated via IS-A to their parents), and VC is the set
of composition nodes (related via HAS-A to their
parents). The set of edges satisfy the constraints
A
B
D
C
E
H
F
I
G
J
K
I
J
K
Figure 1: The ontology for a sample domain where
B IS-A A, C IS-A A, D IS-A A, E IS-A B, F IS-A B,
C HAS-A G (essential), D HAS-A G (nonessential),
H IS-A D, E HAS-A I (essential), J IS-A G, and
K IS-A G. Specialization nodes are drawn single-
lined, composition nodes are drawn double-lined,
and the root node is drawn triple-lined. Special-
ization subtrees are marked by dashed ovals.
that a specialization node has exactly one parent
and a composition node may only have more than
one parent if they are all specialization nodes with
a common parent.
Specialization nodes represent refinements of
their parent concepts. Specializations of a con-
cept are disjoint, that is, for any particular instance
of the parent exactly one specialization is applica-
ble and the rest are inapplicable. For example, if
Dog IS-A Animal and Cat IS-A Animal, then Cat
is inapplicable when Dog is applicable, and vice
versa. Composition nodes represent attributes of
their parents and may be essential or nonessential,
e.g., Dog HAS-A Color (essential), Dog HAS-A
Tail (nonessential). These definitions correspond
with the standard semantics in the knowledge rep-
resentation community (Noh et al, 2003). An ex-
ample ontology is shown in Figure 1.
Definition 2. A specialization subtree (spec-tree)
in the ontology is a subtree consisting of a node
with its specialization children (if any).
3.2 POT Construction
We now describe how a POT may be constructed
from a domain ontology. The purpose of the POT
is to maintain a distribution of possible instanti-
ations of the ontology such that the ontological
structure is respected.
38
Given an ontology G, the corresponding POT is
a tree-structured BN defined as follows:
Variables. Let T be a spec-tree in G with root
R. Unless R is a (non-root) specialization node
with no specialization children, T is represented
in the POT by a variable X with the domain
D(X) =
?
??
??
{exists, null}, if ChildrenT (R) = ?
ChildrenT (R), if R = V0
ChildrenT (R) ? {null}, otherwise.
Edges. Let POT variables X and Y correspond
to distinct spec-trees TX and TY in G. There is a
directed edge from X to Y if and only if either
? A leaf of TX is the root of TY .
? There is an edge from a leaf in TX to the non-
specialization root of TY .
? There is an edge from the non-specialization
root of TX to that of TY .
Conditional Probability Tables (CPTs). If X
(corresponding to spec-tree TX ) is the parent of Y
(corresponding to spec-tree TY ) in the POT, then
Y ?s CPT is conditioned as follows:
? If TY is rooted at one of the leaves of TX ,
then
Pr(Y = null|X = Y) = 0
Pr(Y = null|X 6= Y) = 1
where Y is the domain value of X corre-
sponding to child Y .
? If R is the root of TX , and TY has a compo-
sition root node that is attached only to nodes
in S ? ChildrenTX (R), then
Pr(Y = null|X = V) = 1
for any domain value V of X corresponding
to a node V ? ChildrenTX (R)? S.
? If the root of TY is an essential composition
node attached to a leaf V of TX , then
Pr(Y = null|X = V) = 0
where V is the domain value of X corre-
sponding to the leaf V .
We label a POT variable with that of the root of
the corresponding spec-tree for convenience. The
domain of a POT variable representing a spec-tree
comprises the specialization children (node names
in sanserif font) and the special value null; the null
A
B
C
D
0.4
0.3
50
.25
B
D
E
F
nu
ll
B
0.6
0.4
0
C
0
0
1
D
0
0
1
H
nu
ll
B
0
1
C
0
1
D
1
0
ex
ist
sn
ull
E
1
0
F
0
1
nu
ll
0
1
J
K
nu
ll
B
0
0
1
C
0.8
0.2
0
D
0.7
0.1
0.2
I
G
Figure 2: The POT for the example domain. If a
node represents a spec-tree in the ontology, then it
is labeled by the root of the spec-tree; otherwise,
it is labeled with the name of the corresponding
ontology node. D(A) = {B, C, D}, D(B) = {E, F,
null}, D(D) = {H, null}, and Pr(A), Pr(B|A) and
Pr(D|A) represent some distributions over the re-
spective specializations. D(I) = {exists, null} and
D(G) = {J, K, null}. Note that a composition node
(G) can be shared between multiple specializa-
tions (C and D) in the ontology while the resulting
POT remains tree-structured.
value allows us to render any node (except the
root) inapplicable. Spec-trees comprising single
nodes have the domain value exists to switch be-
tween being applicable and inapplicable. The CPT
entries determine the joint probabilities over pos-
sible valid instantiations of the ontology and could
be based on expert knowledge or learned from
data. The conditions we impose on them (null se-
mantics) ensure that inconsistent instantiations of
the ontology have probability 0 in the POT. While
the ontology might have undirected cycles involv-
ing the children of spec-trees, the corresponding
POT is a tree because spec-trees in the ontology
collapse into single POT nodes. The POT for the
example domain is shown in Figure 2.
3.3 Tourist Information POT
For the empirical analysis, we designed a POT for
a tourist information system that informs the user
about places to shop, eat, get service, and displays
relevant information such as the distance to an in-
tended location. The user can also provide con-
versational commands such as stop, reset, undo,
etc. The full ontology for the tourist information
domain is shown in Figure 3 and the POT is in
Figure 4. In the POT, Action is the root node, with
D(Action) = {Venue, Command}, and D(Venue)
39
Ac
tio
n
Ve
nue
Co
mm
and
Sta
rt
Ca
nce
l
Re
sta
ura
nt
Sto
re
Ser
vic
e
Ar
ea
Dis
pla
y
Mi
les
Am
bie
nce
Cu
isin
e
Ho
urs
Ser
vic
eT
ype
Str
eet
Ra
tin
g
Sto
reT
ype
Pri
ceR
ang
e
Figure 3: The ontology for the tourist information domain. All the composition nodes have specializa-
tions of their own (such as Japanese and Greek for Cuisine), but have not been shown for the sake of
compactness.
= {Restaurant, Store, Service, null}. All the com-
position (or attribute) nodes such as Hours and
Rating are made children of Venue by construc-
tion. Since a Command is inapplicable when the
Action is a Venue, we have Pr(Command = null
| Action = Venue) = 1. The composition nodes
(Cuisine, Street, etc.) have specializations of their
own ({Japanese, Greek, . . . }, {Castro, Elm, . . . },
etc.), but are not shown for the sake of clarity.
Since Cuisine is an essential attribute of Restau-
rant, Pr(Cuisine = null | Venue = Restaurant) = 0;
moreover, Pr(Cuisine = null | Venue = Service) =
1 because Cuisine is not relevant for Service.
4 Inferring User Intention
We have seen how the POT provides the proba-
bilistic machinery to represent domain knowledge.
We now discuss how the POT structure can be
leveraged to infer user intention based on the slots
provided by the SU.
4.1 Soft Evidence
Every slot retrieved from the SU needs to be incor-
porated as observed evidence in the POT. We can
set the associated node within the POT directly to
its domain value as hard evidence when we know
these values with certainty. Instead, we employ
probabilistic observations to soften the evidence
entered into the POT. We assume that the confi-
dence score c ? [0, 100] of a slot corresponds to
the degree of certainty in the observation. For an
observed slot variableX , we create an observation
node X? on the fly with the same domain as X and
make it a child of X . If x is the observed value for
slot X , then the CPT of X? is constructed from the
slot?s confidence score as follows:
Pr(X?|X = x) =
{
c(|D(X)|?1)/100+1
|D(X)| , X? = x
1?c/100
|D(X)| , X? 6= x
The probability values are generated by lin-
early interpolating between the uniform probabil-
ity value and 1 based on the confidence score. For
the remaining values,
Pr(X?|X 6= x) =
{
1? ?(|D(X)| ? 1), X? = X
?, X? 6= X
where ? > 0.1 Since the confidence score gives an
indication of the probability for the observed value
of a slot but says nothing about the remaining val-
ues, the diagonal elements for the remaining val-
ues are near 1. We cannot make them exactly 1
because the observation node needs to coexist with
possibly conflicting observations in the POT.
If the user confirms the current POT hypothesis,
then observations corresponding to the current hy-
pothesis (with CPTs proportional to the score of
the confirmation) are added to the POT to enforce
the belief. If the user denies the current hypothe-
sis, then all observations corresponding to the cur-
rent hypothesis are removed from the POT.
1In our experiments, we use ? = 10?10.
40
Ac
tio
n
Ve
nue
Co
mm
and
Am
bie
nce
Cu
isin
e
Dis
pla
y
Ho
urs
Ser
vic
eT
ype
Mi
les
Ra
tin
g
Sto
reT
ype
Ar
ea
Str
eet
Pri
ceR
ang
e
Cu
isin
e
Str
eet
Cas
tro
Elm
nul
l
Cas
tro
0.8
0.1
0.1
Jap
ane
se
Gre
ek
nul
l
Jap
ane
se
0.6
0.2
0.2
Cu
isin
e
Str
eet
Elm
?
1?2
?
?
nul
l
?
?
1?2
?
p Gre
ek
?
1?2
?
?
nul
l
?
?
1?2
?
Figure 4: The POT for the tourist information domain. Assuming that D(Cuisine) = {Japanese, Greek,
null} and D(Street) = {Castro, Elm, null}, the shaded observation nodes represent the soft evidence for
input slots ?Cuisine, Japanese, 40? and ?Street, Castro, 70?.
The POT for the tourist information domain af-
ter getting two slots as input is shown in Figure 4.
The attached nodes are set to the observed slot val-
ues and the evidence propagates through the POT
as explained in the next section.
4.2 POT Inference
A probable explanation (PE) or hypothesis is an
assignment of values to the variables in the POT,
and the most probable explanation (MPE) within
the POT is the explanation that maximizes the
joint probability conditioned on the observed vari-
ables. The top m estimates of the user?s intentions
correspond to them-best MPEs. The design of the
POT ensures that the m-best MPEs are all con-
sistent across specializations, that is, exactly one
specialization is applicable per node in any PE; all
inconsistent explanations have a probability of 0.
The m-best MPEs could be found naively us-
ing the Join-Tree algorithm to compute the joint
distribution over all variables and then use that to
find the top m explanations. The space required to
store the joint distribution alone is O(nN ), where
N is the number of nodes and n the number of
values per node. Because the run time complex-
ity is at least as much as this, it is impractical for
any reasonably sized tree. However, we can get
a significant speedup for a fixed m by using the
properties of the POT.
Algorithm 1 uses a message-passing protocol,
similar to many in the graphical models litera-
ture (Koller and Friedman, 2009), to simulate a
Algorithm 1 COMPUTE-PE
Input: POT T with rootX0, number of MPEsm, evidence E
Output: m MPEs for T
1: for X ? T in reverse topological order do
2: Collect messages ?Yi from all children Yi of X
3: ?X = COMPUTE-MPE-MESSAGE(X,m, {?Yi})
4: end for
5: return top m elements of Pr(X0|E)?X0(?) without E
Algorithm 2 COMPUTE-MPE-MESSAGE
Input: POT node X , number of MPEs m, messages from
children ?Yi
Output: Message ?X(?)
1: if X is a leaf node then
2: ?X(x)? 1,?x ? D(X)
3: return ?X
4: end if
5: for x ? D(X) do
6: for ~z = ((y1, ~z1), . . . , (yk, ~zk)) ? {D(?Y1)? . . .?
D(?Yk ) : Pr (Yi = null|X = x,E) < 1} do
7: ??X(x, ~z)?
?
i
[
Pr(Yi = yi|X = x,E)?Yi (yi, ~zi)
]
8: end for
9: ?X(x)? top m elements of ??X(x).
10: end for
11: return ?X
dynamic programming procedure across the lev-
els of the tree (see Figure 5). In Algorithm 2, an
MPE message is computed at each node X using
messages from the children, and sent to the par-
ent. The message from X is the function (or ta-
ble) ?X(x,~z) that represents the probabilities of
the top m explanations, ~z, of the subtree rooted at
X for a particular value of X = x. At the root
node X0 we try all values of x0 to find the top m
MPEs for the entire tree. Note that in step 7, we
41
A
? D
? B B
D
? D
? B
?
? G
I
G
? I
(a)
A =
 B
? D
? B B
D
? D
? B
?
? G
I
G
? I
(b)
A =
 C
? D
? B B
D
? D
? B
?
? G
I
G
? I
(c)
A =
 D
? D
? B B
D
?
? G
? D
? B I
G
? I
(d)
Figure 5: COMPUTE-MPE applied to the exam-
ple POT. (a) Inference starts with the messages be-
ing passed up from the leaves to the root A. Every
message ?X is an m ? n table that contains the
probabilities for the m-best MPEs of the subtree
rooted at X for all the n domain values of X . (b)
At the root, A is set to its first element B, and its
marginal Pr(A = B) is combined with the mes-
sage ?B . The semantics of the POT ensures that
the other messages can be safely ignored because
those subtrees are known to be null with probabil-
ity 1. (c) A is set to C and only the essential at-
tribute G is non-null. (d) A is set to its final el-
ement D, and consequently both the node D and
the nonessential attribute G are non-null and their
messages are mutually independent.
need the marginal P (Y |X,E) which can be ef-
ficiently computed by a parallel message-passing
method. Evidence nodes can only appear as leaves
because of our soft evidence representation, and
are encompassed by the base case. The algorithm
leverages the fact that the joint of any entire sub-
tree rooted at a node that is null with probability 1
can be safely assumed to be null with probability
1. The validity of Algorithm 1 is proven in Ap-
pendix A.
4.3 Complexity Analysis
At a POT node with at most n values and branch-
ing factor k, we do nmaximizations over the prod-
uct space of k nm-sized lists. Thus, the time
complexity of Algorithm 1 on a POT with N
nodes is O(N(nm)k) and the space complexity is
O(Nnmk). (Insertion sort maintains a sorted list
truncated at m elements to keep track of the top
m elements at any time.) However, the algorithm
is significantly faster on specialization nodes be-
cause only one child is applicable and needs to be
considered in the maximization (step 7). In the ex-
treme case of a specialization-only POT, the time
and space complexities both drop to O(Nmn).
A similar algorithm for incrementally finding
m-best MPEs in a general BN is given in Srinivas
and Nayak (1996). However, our approach has the
ability to leverage the null semantics in POTs re-
sulting in significant speedup as described above.
This is crucial because the run-time complexity of
enumerating MPEs is known to be PPP -Complete
for a general BN (Kwisthout, 2008).
5 Empirical Evaluation
To test the effectiveness of our POT approach, we
compare it to a frame-based baseline system for
inferring user intentions.
The baseline system uses a hierarchical frame-
based approach. Each frame maps to a par-
ticular user intention, and the frames are filled
concurrently from the dialog observations. The
slots from a turn overwrite matching slots re-
ceived in previous turns. The baseline system uses
the same ontology as the POT to insure that it
only produces consistent hypotheses, e.g., it never
produces ?Venue=Service, Cuisine=Japanese? be-
cause Service does not have a Cuisine attribute.
When several hypotheses compete, the system se-
lects the one with the maximum allocated slots.
We implemented the POT engine based on the
Probabilistic Network Library (Intel, 2005). It
takes a POT specification as input, receives the
ASR slots, and returns its m-best MPEs.
Using a tourism information spoken dialog sys-
tem, we collected a corpus of 375 dialogs from
15 users with a total of 720 turns (details in
Appendix B). Evaluation is performed by run-
ning these collected dialogs in batch and pro-
viding the ASR slots of each turn to both the
baseline and POT belief-tracking systems.2 Af-
ter each turn, both systems return their best hy-
pothesis of the overall user intention in the form
of a set of concept-value pairs. These hypothe-
2Speech recognition and understanding was performed
using the Nuance Speech Recognition System v8.5 running
manual and statistical grammars with robust interpretation.
42
System Precision Recall F1
Top hypothesis 0.84 0.81 0.83
Top 2 hypotheses 0.87 0.84 0.85
POT Top 3 hypotheses 0.89 0.85 0.87
Top 4 hypotheses 0.91 0.86 0.89
Top 5 hypotheses 0.92 0.86 0.89
Baseline 0.84 0.79 0.81
Table 1: Precision/recall results comparing the
baseline system against the POT-based system on
the 25-scenario experiment. Results are averaged
over all 15 users.
?1 ?0.8 ?0.6 ?0.4 ?0.2 00.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Log?likelihood of top POT hypothesis 
F1
Figure 6: F1 score as a function of the log-
likelihood of the top hypothesis for the user?s goal.
ses are compared to the true user intention ex-
pressed so far in the dialog (e.g., if the user wants
a cheap restaurant but has not mentioned it yet,
PriceRange=Cheap is not considered part of the
ground truth). This offline approach allows us to
compare both versions on the same input.
Table 1 shows the precision/recall results for the
experiment based on comparing the set of true user
intention concepts to the inferred hypotheses of
the POT and baseline systems. The average word
error rate for all users is 29.6%. The POT sys-
tem shows a 2% improvement in recall and F1
over the baseline. Additionally, leveraging the m-
best hypotheses beyond just the top one could help
enhance performance or guide useful clarification
questions as shown by the improved performance
when using the top 2?5 hypotheses; we assume
an oracle for selecting the hypothesis with highest
F1 among the top m hypotheses. All of the CPTs
in the POT (besides the structural constraints) are
uniformly distributed. Thus, the performance of
the POT could be further improved by training the
CPTs on real data.
To assess the quality of likelihood returned by
the POT as a belief confidence measure, we binned
dialog turns according to the log-likelihood of the
top hypothesis and then computed the F1 score of
each bin. Figure 6 shows that belief log-likelihood
is indeed a good predictor of the F1 score. This
information could be very useful to a dialog man-
ager to trigger confirmation or clarification ques-
tions for example.
6 Discussion
The definition and construction of POTs provide a
principled and systematic way to construct proba-
bilistic models for an SDS. While any BN can be
used to model the space of user intentions, design-
ing an effective network is not an easy task for sys-
tem designers not well versed in graphical mod-
els. In previous belief tracking work, researchers
describe their networks with little indication on
how they arrived at the specific structure (Paek and
Horvitz, 2000; Thomson and Young, 2009). Prior
work on ontologies for SDSs (van Zanten, 1998;
Noh et al, 2003) as well as the prominence of
concept hierarchies in other areas such as object-
oriented programming and knowledge engineer-
ing make them a natural and intuitive way of repre-
senting SDS domains. The development of POTs
builds on past research on constructing BNs based
on ontological knowledge (Helsper and van der
Gaag, 2002; Pfeffer et al, 1999).
While most approaches to belief tracking in the
dialog systems community make a strict indepen-
dence assumption between concepts (Bohus and
Rudnicky, 2006; Williams, 2006), POTs model
the dependencies between concepts connected by
specialization and composition relationships while
remaining significantly more tractable than gen-
eral BNs and being very straightforward to de-
sign. The null semantics allow a POT to capture
disjoint values and the applicability of attributes
which are common aspects of concept ontologies.
Obviously, a POT cannot capture all types of con-
cept relationships since each concept can have
only one parent. However, this restriction allows
us to perform efficient exact computation of the
m-best MPEs which is a significant advantage.
Statistical Relational Learning approaches such as
Markov Logic Networks (Richardson and Domin-
gos, 2006) have been developed for more general
relational models than strict ontologies, but they
lack the parsimony and efficiency of POTs.
43
Thomson and Young (2009) describe an ap-
proach to dialog management based on a partially
observable Markov decision process (POMDP)
whose policy depends only on individual con-
cepts? marginal distributions rather than on the
overall user intention. Because their system per-
forms belief tracking with a dynamic Bayesian
network (DBN) rather than a static BN, the ex-
act marginal computation is intractable and the au-
thors use loopy belief propagation to compute the
marginals. Even then, they indicate that the depen-
dencies of the subgoals must be limited to enable
tractability. In practice, all concepts are made in-
dependent except for the binary validity nodes that
deterministically govern the dependence between
nodes (similar to the null semantics of a POT).
Williams (2007) also represents the user goal as
a DBN for a POMDP-based DM. They perform
belief updating using particle filtering and approx-
imate the joint probability over the user intention
with the product of the concept marginals. This
could lead to inaccurate estimation for condition-
ally dependent concepts.
Among authors who have used m-best lists of
dialog states for dialog management, Higashinaka
et al (2003) have shown empirically that main-
taining multiple state hypotheses facilitates shorter
dialogs. Their system scores each dialog state
using a linear combination of linguistic and dis-
course features, and this score is used by a hand-
crafted dialog policy. While illustrating the advan-
tages of m-best lists, this scoring approach lacks
theoretical justification and ability to include prior
knowledge that POTs inherit from BNs.
7 Conclusion
We have presented the POT framework for belief
tracking in an SDS. We have shown how a POT
can be constructed from the domain ontology and
provided an exact algorithm to infer the user?s in-
tention in real-time. POTs strike a balance be-
tween representing rich concept dependencies and
facilitating efficient tracking of them-best user in-
tentions based on exact joint probabilities rather
than approximations such as concept marginals.
References
D. Bohus and A. Rudnicky. 2006. A K Hypotheses
+ Other Belief Updating Model. In AAAI Workshop
on Statistical and Empirical Approaches to Spoken
Dialogue Systems.
D. Goddeau, H. Meng, J. Polifroni, S. Seneff, and
S. Busayapongchai. 1996. A Form-Based Dialogue
Manager for Spoken Language Applications. In IC-
SLP.
E. Helsper and L. van der Gaag. 2002. Building
Bayesian Networks through Ontologies. In Euro-
pean Conference on Artificial Intelligence.
R. Higashinaka, M. Nakano, and K. Aikawa. 2003.
Corpus based Discourse Understanding on Spoken
Dialog Systems. In Annual Meeting on Association
for Computational Linguistics.
Intel. 2005. Probabilistic Network Library. http://
sourceforge.net/projects/openpnl/.
D. Koller and N. Friedman. 2009. Probabilistic
Graphical Models: Principles and Techniques. MIT
Press.
J. Kwisthout. 2008. Complexity Results for Enumerat-
ing MPE and Partial MAP. In European Workshop
on Probabilistic Graphical Models.
H. Noh, C. Lee, and G. Lee. 2003. Ontology-based
Inference for Information-seeking in Natural Lan-
guage Dialog Systems. In IEEE International Con-
ference on Industrial Informatics.
T. Paek and E. Horvitz. 2000. Conversation as Ac-
tion under Uncertainty. In Uncertainty in Artificial
Intelligence.
A. Pfeffer, D. Koller, B. Milch, and K. T. Takusagawa.
1999. Spook: A system for probabilistic object-
oriented knowledge representation. In Uncertainty
in Artifical Intelligence.
C. Rich and C. Sidner. 1998. COLLAGEN: a Col-
laboration Manager for Software Interface Agents.
An International Journal: User Modeling and User
Adapted Interaction, 8.
M. Richardson and P. Domingos. 2006. Markov Logic
Networks. Machine Learning, 62:107?136.
S. Srinivas and P. Nayak. 1996. Efficient Enumeration
of Instantiations in Bayesian Networks. In UAI.
B. Thomson and S. Young. 2009. Bayesian Update
of Dialogue State: A POMDP Framework for Spo-
ken Dialogue Systems. Computer Speech and Lan-
guage.
G. van Zanten. 1998. Adaptive Mixed-Initiative Dia-
logue Management. In IEEE Workshop on Interac-
tive Voice Technology for Telecommunications Ap-
plications.
J. Williams. 2006. Partially Observable Markov Deci-
sion Processes for Dialog Management.
J. Williams. 2007. Using Particle Filters to Track
Dialogue State. In IEEE Workshop on Automatic
Speech Recognition & Understanding.
44
A Analysis of the Inference Algorithm
Theorem 1. Algorithm 1 returns the top m MPEs
of the POT along with their joint probabilities.
Proof. We first prove this for the special case of
m = 1 to simplify notation. For the base case
of a node with no children, Algorithm 2 sim-
ply returns a message with all probabilities at
1 for all values of that node. Now, consider a
node X with children Y1, . . . , Yk. Let Desc(Y )
be the descendants of node Y . Since Algo-
rithm 2 given node X returns exactly one expla-
nation, z for each x ? D(X), we will define
?X(x) = ?X(x, z). Now, to show that ?X(x) =
maxDesc(X) Pr(Desc(X)|X = x,E), that is, Al-
gorithm 2 returns the top explanation of the entire
subtree rooted at X for every value in D(X), we
use structural induction on the tree.
max
Desc(X)
Pr(Desc(X)|X = x,E)
= max
Y1:k,Desc(Y1:k)
Pr(Y1:k,Desc(Y1:k)|X = x,E)
= max
Y1:k,Desc(Y1:k)
?
i
Pr(Yi|X = x,E) Pr(Desc(Yi)|Yi, E)
=
?
i
max
Yi,Desc(Yi)
[
Pr(Yi|X = x,E) Pr(Desc(Yi)|Yi, E)
]
=
?
i
max
Yi
[
Pr(Yi|X = x,E) max
Desc(Yi)
Pr(Desc(Yi)|Yi, E)
]
=
?
i
max
Yi
[
Pr(Yi|X = x,E)?Yi(yi)
]
{Inductive step}
= ?X(x).
The proof for m > 1, where every maximization
returns a list of the top m elements, is similar.
B Dialogs in the Tourist Information
Domain
Each user conducted 25 dialogs according to pre-
scribed scenarios for the tourist information do-
main. The order of scenarios was randomized for
each user. Sample scenarios:
1. Find a good and cheap Mexican restaurant in
Mountain View.
2. There is a medical emergency and you need
to get to the hospital. Find a route.
3. You need to find your favorite coffee fran-
chise. You have 10 minutes to get coffee.
4. Find a place to buy some fruits and vegeta-
bles.
5. Find a Chinese restaurant in Santa Clara with
good ambiance, and display travel distance.
6. Find an ATM on Castro Street in Mountain
View.
Figure 7 shows a typical interaction with the
system for the first scenario along with a possi-
ble hypothesis inferred by the system at every turn
of the dialog. Figure 8 shows an example where
the POT system is able to discard an incorrect ob-
servation about a restaurant based on the accumu-
lated belief about bookstores over multiple turns.
Figure 9 shows how the POT is able to leverage the
ontological structure to pick out higher-level con-
cepts with lower confidence scores over spurious
low-level concepts with higher confidence scores.
45
User Find a Mexican restaurant in Mountain View.
Hypothesis [venue restaurant] [area mountain view] [cuisine italian]
{Note: Mexican is misrecognized as Italian.}
User No, Mexican.
Hypothesis [venue restaurant] [area mountain view] [cuisine mexican]
User Show me ones with at least four star rating.
Hypothesis [venue restaurant] [area mountain view] [cuisine mexican] [rating four star]
User I want a cheap place.
Hypothesis [venue restaurant] [area mountain view] [cuisine mexican] [rating four star] [price cheap]
User Is there anything on Castro?
Hypothesis [venue restaurant] [area mountain view] [street castro] [cuisine mexican] [rating four star] [price cheap]
Figure 7: A sample dialog in the tourism information domain showing the inferred hypothesis of the
user?s intention at every turn. The information response from the system?s back-end is based on its
current hypothesis.
User utterance Where is the bookstore?
ASR where is the bookstore
True hypothesis [action venue] [venue store] [sell book]
Baseline hypothesis [action venue] [venue store] [sell book]
POT hypothesis [action venue] [venue store] [sell book]
User utterance Store on Market Street.
ASR store on market street
True hypothesis [action venue] [venue store] [sell book] [street market]
Baseline hypothesis [action venue] [venue store] [sell book] [street market]
POT hypothesis [action venue] [venue store] [sell book] [street market]
User utterance In downtown.
ASR dennys
True hypothesis [action venue] [venue store] [sell book] [street market] [area downtown]
Baseline hypothesis [action venue] [venue restaurant] [brand dennys]
POT hypothesis [action venue] [venue store] [sell book] [street market]
Figure 8: A dialog showing the ASR input for the user?s utterance, and the corresponding true, baseline,
and POT hypotheses. The POT is able to correctly discard the inconsistent observation in the third turn
with the observations in previous turns.
User utterance Where should I go to buy Lego for my kid?
SU slots ?Venue Store 38? ?ServiceType GolfCourse 60?
True hypothesis [action venue] [venue store] [storetype toy]
Baseline hypothesis [action venue] [venue service] [servicetype golf course]
POT hypothesis [action venue] [venue store]
Figure 9: A single dialog turn showing the SU slots for the user?s utterance, and the corresponding
baseline, POT, and true hypotheses. Any system that looks at the individual confidence scores will base
its hypothesis on the ?ServiceType GolfCourse 60? slot. Instead, the POT hypothesis is influenced by
?Venue Store 38? because its score in combination with the concept?s location in the POT makes it more
likely than the other slot.
46
Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 169?178,
Seoul, South Korea, 5-6 July 2012. c?2012 Association for Computational Linguistics
Landmark-based Location Belief Tracking in a Spoken Dialog System
Yi Ma
The Ohio State University
Columbus, OH 43210
may@cse.ohio-state.edu
Antoine Raux, Deepak Ramachandran, Rakesh Gupta
Honda Research Institute, USA
425 National Ave, Mountain View, CA 94043
{araux,dramachandran,
rgupta}@hra.com
Abstract
Many modern spoken dialog systems use
probabilistic graphical models to update their
belief over the concepts under discussion, in-
creasing robustness in the face of noisy input.
However, such models are ill-suited to prob-
abilistic reasoning about spatial relationships
between entities. In particular, a car naviga-
tion system that infers users? intended desti-
nation using nearby landmarks as descriptions
must be able to use distance measures as a fac-
tor in inference. In this paper, we describe
a belief tracking system for a location iden-
tification task that combines a semantic belief
tracker for categorical concepts based on the
DPOT framework (Raux and Ma, 2011) with
a kernel density estimator that incorporates
landmark evidence from multiple turns and
landmark hypotheses, into a posterior proba-
bility over candidate locations. We evaluate
our approach on a corpus of destination set-
ting dialogs and show that it significantly out-
performs a deterministic baseline.
1 Introduction
Mobile devices such as smart phones and in-car in-
fotainment systems have generated demand for a
new generation of location-based services such as
local business search, turn-by-turn navigation, and
social event recommendation. Accessing such ser-
vices in a timely manner through speech is a crucial
requirement, particularly on the go when the user is
unable to resort to other modalities e.g. where safety
regulations prohibit drivers from using buttons or a
touchscreeen while driving.
In such systems, a Point of Interest (POI)
or a destination such as a restaurant, store or a
public place is often specified. For example, a
car navigation system needs the user to input the
destination before giving directions. Similarly, a
photo tagging application must allow its users to
designate the location where a picture was taken.
While postal addresses can be used to unambigously
identify locations, they are often either unknown
or hard for users to remember. A more natural
(though potentially ambiguous) means of speci-
fying locations is to use landmarks such as ?the
Italian restaurant near Red Rock
cafe on Castro Street? or ?the bakery
near that mall with a Subway and
a 7 Eleven?. A location-based dialog system
that understands referring expressions using land-
marks could lead to more succinct dialogs, higher
recognition accuracy and a greater appearance of
intelligence to the user.
We present a system that performs belief track-
ing over multiple turns of user speech input to infer
the most probable target location. The user inter-
acts with the system through speech in order to spec-
ify a target location, and may include references to
one or more landmarks. Such a system must han-
dle two sources of uncertainty. First, ASR is notori-
ously error-prone and modern ASR engines provide
ranked lists of possible interpretations of speech in-
put rather than single hypotheses. Second, the suit-
ability of a particular landmark or its likelihood of
usage by the speaker depends on a number of factors
such as distance, size and prominence of the land-
mark, familiarity of the user and his expectation of
169
common ground for understanding. These factors,
or at least the resulting variability, must be taken into
account when making inferences about target loca-
tions from landmark-based expressions.
The first source of ambiguity (speech understand-
ing) has been the target of research on belief tracking
(Mehta et al, 2010; Raux and Ma, 2011; Thomson
and Young, 2010). In previous work, the concepts
of interest are entities that are ontologically related
(i.e. with is-a or has-a relations), thus discrete prob-
abilistic graphical models such as DBNs have gen-
erally sufficed as representations. But these mod-
els are ill-suited for dense continuous spatial rela-
tions like the distance between any two locations on
a map. In this paper, we introduce a kernel-based
belief tracker as a probabilistic model for inferring
target locations from (uncertain) landmarks. The
kernel-based representation allows a natural way to
weigh the suitability of a landmark and the speech
understanding confidence. The output of this tracker
is combined with that of a Dynamic Probabilistic
Ontology Tree (DPOT) (Raux and Ma, 2011), which
performs ontological reasoning over other features
of the target location, to give a posterior distribu-
tion over the intended location. We evaluate our ap-
proach on a new corpus of location setting dialogs
specially collected for this work and find it to signif-
icantly outperform a deterministic baseline.
2 Related Work
In the context of a location-based dialog system,
Seltzer et al (2007) describes a speech understand-
ing system designed to recognize street intersec-
tions and map them to a database of valid intersec-
tions using information retrieval techniques. Ro-
bustness is achieved by exploiting both words and
phonetic information at retrieval time, allowing a
soft-matching of the ASR result to the canonical in-
tersection name. Their approach is specifically tar-
geted at intersections, to the exclusion of other types
of landmarks. While intersections are frequently
used as landmarks in North America (where their
study was conducted), this is not always the case
in other cultures, such as Japan (Suzuki and Wak-
abayashi, 2005), where points of interests such as
train stations are more commonly used. Also, their
approach, which is framed as speech understanding,
does not exploit information from previous dialog
turns to infer user intention.
Landmarks have been integrated in route direc-
tions (Pierre-emmanuel Michon, 2001; Tversky and
Lee, 1999) with significant use at origin, destination
and decision points. Further, landmarks have been
found to work better than street signs in wayfind-
ing (Tom and Denis, 2003). The multimodal system
described in (Gruenstein and Seneff, 2007) supports
the use of landmarks from a limited set that the user
specifies by pointing at the map and typing landmark
names. While this allows the landmarks (and their
designations) to be of any kind, the burden of defin-
ing them is on the user.
Spatial language, including landmarks, has also
been the focus of research within the context of
human-robot interaction. (Huang et al, 2010;
MacMahon et al, 2006) describe systems that trans-
late natural language directions into motion paths or
physical actions. These works focus on understand-
ing the structure of (potentially complex) spatial lan-
guage and mapping it into a representation of the
environment. Issues such as imperfect spoken lan-
guage understanding have not been investigated in
this context. Similarly, this vein of spatial language
research has traditionally been conducted on small
artificial worlds with a few dozen objects and places
at most, whereas real-world location-based services
deal with thousands or millions of entities.
3 Hybrid Semantic / Location Belief
Tracking
Our belief tracking system consists of two trackers
running in parallel: a DPOT belief tracker (Raux and
Ma, 2011) and a novel kernel-based location tracker.
The final inference of user intentions is produced by
combining information from the two trackers. The
general idea is to rerank the user goals given spatial
information provided by the location tracker.
3.1 Semantic Belief Tracker
We perform belief tracking over non-landmark con-
cepts such as business name and street using a Dy-
namic Probabilistic Ontology Tree (DPOT) (Raux
and Ma, 2011). A DPOT is a Bayesian Network
composed of a tree-shaped subnetwork representing
the (static) user goal (Goal Network), connected to
170
Figure 1: Top view heat map of spatial distribution with landmarks Subway and 7 Eleven over potential target
places in Mountain View, CA
a series of subnetworks representing the evidence
gathered from each successive dialog turn (Evidence
Networks). Details of the model and an efficient in-
ference method for posterior probability computa-
tions can be found in (Raux and Ma, 2011).
In the context of this paper, the purpose of the
semantic tracker is to update a list of the most
likely target locations using attributes of that
location provided by the user (see Figure 2). In
a local business database, such attributes include
Business Name, Street, Category (e.g.
Japanese restaurant or convenience store), etc.
The structure and parameters of the Goal Network
encode probabilistic ontological relations between
the attributes (e.g. a Mcdonalds would be described
as a fast-food restaurant with high probability)
that can be exploited during inference. These can
be derived from expert knowledge, learned from
data, or as is the case in our experimental system,
populated from a database of local businesses (see
section 4). After each user utterance, the DPOT
outputs a ranked list of user goal hypotheses (an ex-
ample goal hypothesis is [Category=italian
restaurant,Street=castro street]).
Each hypothesis is converted into a query to the
backend database, and the posterior probability of
the hypothesis is split equally among all matching
entries. This results in a ranked list of database
entries corresponding to the system?s belief over
potential target locations, with potentially many
entries having the same probability.
3.2 Kernel-based Location Tracker
Landmark concepts extracted by the Natural Lan-
guage Understanding module (NLU) are passed to
the location tracker, which maintains a distribution
over coordinates of potential target locations. Each
such landmark concept is treated as evidence of spa-
tial proximity of the target to the landmark and the
distribution is accordingly updated. Any location in
the database can serve as a landmark observation,
including major POIs such as train stations or pub-
lic facilities. If the name of a generic chain store
with multiple locations such as Subway is used for
the landmark, then an observation corresponding to
each individual location is added to the tracker.
For each observed landmark `, the location
tracker constructs a 2-dimensional Gaussian kernel
with mean equal to the longitude and latitude of the
landmark (?` = (long`, lat`)) and a fixed covari-
171
Figure 2: Overview of the hybrid semantic / location belief tracking approach; the database entry in shade is the
underlying true target place to which the provided landmark is close
ance matrix ?` for each landmark:
 `(t) =
1
2?|?|1/2 exp( 
1
2(t  ?`)
T? 1` (t  ?`))
This kernel density determines the conditional prob-
ability that the target is at coordinates t =
(longt, latt) given the fixed landmark `. The covari-
ance matrix ?` and hence the shape of the kernel
can be adjusted for different landmarks depending
on considerations such as the familiarity, size and
prominence of the landmark (a large historic monu-
ment is likely to be used as a landmark for locations
much further away than a small corner grocery store)
etc.
The probability density of the location t being the
target is then given by a weighted mixture model:
Pr(t|L) =
X
`2L
w` `(t) (1)
where L is the set of candidate landmarks returned
by the NLU (see Section 4.1) up to the current turn
and w` is set to the confidence score of ` from the
NLU. Thus candidate landmarks that have higher
confidence in the NLU will contribute more strongly
to the total likelihood. Since Pr(t|L) is a den-
sity function, it is unnormalized. In Figure 1, we
show the kernel tracker distribution for a dialog state
where Subway and 7 Eleven are provided as
landmarks.
The kernel density estimator is a simple approach
to probabilistic spatial reasoning. It is easy to imple-
ment and requires only a moderate amount of tuning.
It naturally models evidence from multiple speech
hypotheses and multiple provided landmarks, and
it benefits from accumulated evidence across dia-
log turns. It can also potentially be used to model
more general kinds of spatial expressions by using
appropriate kernel functions. For example, ?Along
Castro street? can be modeled by a Gaussian
with an asymmetric covariance matrix such that the
shape of the resulting distribution is elongated and
concentrated on the street. While ?Two blocks
away from ...? could be modeled by adding
an extra ?negative? density kernel that extends from
172
Figure 3: Overview of the Destination Setting System
the center of the landmark to a distance two blocks
away.
3.3 Combining the Two Trackers
At each turn, the updated results from the Seman-
tic and Location tracker are combined to give a
single ranked list of likely target locations. In
Figure 2, this process is illustrated for a dia-
log turn where two possible concepts are identi-
fied   a category attribute [Category:italian
restaurant] and a landmark [Landmark:red
rock coffee company]. These are passed to
the DPOT tracker and the location tracker respec-
tively. The output of the DPOT is used to retrieve
and score matching database entries. The score for
each entry is reweighted by the kernel density esti-
mator measured at the coordinates of the location 1:
Pr(eij) = (
pi
Ni
)? ? Pr(eij |L) (2)
where Ni is the number of matching database en-
tries retrieved from ith goal hypothesis (having joint
probability pi) and eij is the jth such entry (j 2
[1..Ni]). The exponent ? for the posterior term is
introduced to account for scale difference between
the semantic score and the kernel density.
The set of candidate entries can then be reranked
according to Eq 2 and returned as the output of the
combined belief tracker.
Figure 4: Structure of the Goal Network for the experi-
mental system.
4 Evaluation
4.1 Experimental System
The architecture of our experimental system is
shown in Figure 3. The web client, shown in Figure
5, runs in the participant?s web browser and displays
the target location of the current scenario using the
Google Map API. The user?s goal is to convey this
target location to the system through speech only.
The system backend consists of a database of
2902 businesses located in Mountain View, Cali-
fornia with their name, street, street number, busi-
ness category, latitude and longitude provided. The
grammar rules for the NLU and the probability ta-
bles in the DPOT are populated from this database.
The web client captures the user speech and sends
it to our server with a push-to-talk interface based
on the WAMI toolkit (Gruenstein et al, 2008). The
server uses a commercial cloud-based ASR service
with generic acoustic and language models, which
were not adapted to our task. The n-best list of hy-
potheses from the ASR is sent to our robust natural
1The scores are renormalized to between 0 and1.
173
language understanding module for parsing.
Our NLU uses a hybrid approach combining
a weighted finite-state transducer (WFST) with
string matching based rescoring of the output. The
WFST incorporates out-of-grammar word loops
that allow skipping input words at certain points
in the parse2. This parser robustly maps free form
utterances (e.g. ?Okay let?s go to that
Italian place near, uh..., Red
Rock Cafe, on Castro?) to semantic frames
(e.g. [Category=italian restaurant,
Street=castro street, Landmark=red
rock coffee company]).
The NLU confidence score is computed based on
the number of words skipped while parsing, and
how close the important concept words match the
canonical phrases found in the database. For in-
stance, ?Red Rock Cafe? matches the canoni-
cal name ?Red Rock Coffee Company? with
high confidence because rare words (Red, Rock)
are identical, and differing but common words
(Cafe, Coffee, Company) have a low weight
in the score. The string matching score is based
on the term-frequency/inverse document frequency
(TF-IDF) metric commonly used in information re-
trieval. In our case, the weight of different terms
(IDF) is estimated based on their frequency of occur-
rence in different database entries (i.e. how uniquely
they describe a matching entry). We use the sec-
ondstring open-source library (Cohen et al, 2003)
for string matching. For any ASR hypothesis, the
NLU is likely to generate several parses which are
all merged in a global list of candidate parses.
For each candidate parse, the system generates
a set of dialog acts (one per concept in the parse)
which are input to the belief tracker with their confi-
dence score. Following the approach described in
section 3, dialog acts corresponding to the Land-
mark concept are sent to the kernel-based location
belief tracker, while all other concepts are sent to a
Dynamic Probabilistic Ontology Trees (DPOT) se-
mantic belief tracker, whose structure is shown in
Figure 4. We use a two-level tree. The value of
the root node (Id) is never directly observed and
represents the database entry targeted by the user.
2This module is implemented using the OpenFST library
(Allauzen et al, 2007)
The leaf nodes correspond to the relevant attributes
Name, Category, and Street. For any database
entry e, attribute a and value of that attribute va, the
conditional probability P (a = va|Id = e) is set to 1
if the value of a is va for entry e in the database, and
to 0 otherwise. For attributes such as Category,
which allow several possible values for each entry,
the probability is split equally among valid values.
After each user utterance, the network is augmented
with a new Evidence Network capturing the possi-
ble interpretations and their likelihood, as computed
by the NLU. The posterior probability distribution
over user goals is computed and rescored using the
kernel-based location tracker.
Finally, the Response Generator takes the highest
scoring target location from the belief tracker and
sends it back to the web client which displays it on
the map and also indicates what are the values of
the Name, Category, and Street concepts for
the top belief (see Figure 5). If the top belief lo-
cation does not match the goal of the scenario, the
user can speak again to refine or correct the system
belief. After the user has spoken 5 utterances, they
also get the choice of moving on to the next scenario
(in which case the dialog is considered a failure).
4.2 Data collection
To evaluate our approach, we ran a data collection
experiment using the Amazon Mechanical Turk on-
line marketplace. We defined 20 scenarios grouped
into 4 Human Intelligence Tasks (HITs). Figure 5
shows a screen shot of the web interface to the sys-
tem. In each scenario, the worker is given a target
location to describe by referring to nearby landmark
information. The target locations were chosen so as
to cover a variety of business categories and nearby
landmarks. The compensation for completing each
set of 5 scenarios is 1 US dollar. Before their first
scenario, workers are shown a video explaining the
goal of the task and how to use the interface, in
which they are specifically encouraged to use land-
marks in their descriptions.
At the beginning of each scenario, the target
location is displayed on the map with a call-
out containing a short description using either a
generic category (e.g. Italian restaurant,
Convenience store) or the name of a chain
store (e.g. Subway, Mcdonalds). The worker
174
Figure 5: Screen capture of the data collection web interface where the target location is an Italian restaurant (in
green, underlying target place is [Ristorante Don Giovanni]) and after the first turn user input ?Italian
restaurant? with a system belief [Frankie, Johnnie & Luigi, Too] in blue returned without any land-
mark information provided so far
then interacts with the system described in section
4.1 until either the system?s top belief matches the
target location, or they decide to skip the scenario.
4.3 Data Statistics
Overall, 99 workers participated in the data col-
lection, providing 948 dialogs (2,869 utterances, 3
turns per scenario on average), which two of the
authors manually transcribed and annotated for di-
alog acts. 76% of the dialogs (46% of utterances)
contained a reference to a landmark. Other strate-
gies commonly used by workers to uniquely identify
a location include using a category or chain name
and a street, as well as explicitly mentioning the tar-
get business name (although workers were explicitly
discouraged form doing so). Figure 7 in appendix
provides one example dialog from the corpus.
Overall, the workers provided 203 unique land-
marks, of which 143 (70%) are in the database.
Workers were able to set the target destination
within 5 turns in 60.1% of the dialogs, which we
hereafter refer to as task successes. However, based
on the manual transcripts, 19.0% of the dialogs
could not have succeeded with the current system
because the workers used landmark or attributes that
do not appear in the database. Since the focus of this
study is robustness rather than coverage, we base our
evaluation on the remaining 768 dialogs, which we
split between a development set of 74 dialogs and
a test set of 694 dialogs. On this test set, the live
system has a task success rate of 70.6%. By inspect-
ing the log files, we noticed that runtime issues such
as timeouts prevented the system from getting any
belief from the belief tracker in 6.3% of the dialogs.
The mean Word Error Rate (WER) per worker on
the test set is 27.5%. There was significant variabil-
ity across workers, with a standard deviation 20.7%.
Besides the usual factors such as acoustic noise and
non-native accents, many of the errors came from
the misrecognition of business names, due to the fact
that ASR uses an open-ended language model that is
tuned neither to Mountain View, nor to businesses,
nor to the kind of utterances that our set up tends
to yield, which is a realistic situation for large scale
practical applications.
Concept precision of the top scoring NLU hypoth-
esis is 73.0% and recall is 57.7%. However, when
considering the full list of NLU hypotheses and us-
ing an oracle to select the best one for each turn,
precision increases to 89.3% and recall to 66.2%,
underscoring the potential of using multiple input
hypotheses in the belief tracker.
175
42% 
50% 
69% 
83% 
0% 
10% 
20% 
30% 
40% 
50% 
60% 
70% 
80% 
90% 
W/o landmarks 
baseline 
W/o landmarks BT W/ landmarks 
baseline 
W/ landmarks BT 
Tas
k S
ucc
ess
 Ra
te 
Figure 6: Batch evaluation of the proposed (BT) and baseline approaches with and without landmark information.
4.4 Batch Results
To further analyze the performance of our approach,
we conducted a series of batch experiments on the
data collected with the runtime system. We first
tuned the parameters of the belief tracker ? and ?l
(see section 3) on the development set (? = 3 and
?l corresponds to a circular Gaussian with standard
deviation 500 meters).
We compare the tuned proposed belief tracking
system (labeled BT) with three other versions. First,
we define a deterministic baseline system which, at
each turn, updates its belief by overwriting each con-
cept?s value with the value found in the top NLU
hypothesis. Based on this (single) user goal hy-
pothesis, we query the database to retrieve match-
ing entries. If the current goal hypothesis con-
tains a Landmark concept, the baseline system se-
lects the matching entry that is closest to any loca-
tion matching the landmark name, by computing the
pairwise distance between candidate target locations
and landmarks.
We also compute the performance of both the
baseline and our proposed approach without us-
ing landmark information at all. In these versions,
the belief over the attributes (Name, Street, and
Category) is updated according to either the top
NLU hypothesis (baseline) or the DPOT model (BT)
and the first matching database entry is returned, ig-
noring any landmark information.
Figure 6 shows the task success of each of the four
versions on the test set. First, it is clear that land-
mark information is critical to complete the tasks in
this corpus since both systems ignoring landmarks
perform significantly worse than their counterparts.
Second, the belief tracking approach significantly
outperforms the deterministic baseline (83.0% vs
69.3%, p < 0.001 using sign test for matched pairs).
To further analyze the performance of the sys-
tem in different input conditions, we split the di-
alogs based on their measured concept accuracy (ex-
pressed in terms of concept F-measure). All dialogs
with an F-measure higher than the median (70.0%)
are labeled as high-accuracy, while the other half of
the data is labeled as low-accuracy. While both the
proposed approach and the baseline perform simi-
larly well for high-accuracy dialogs (task success of
resp. 96.0% and 92.8%, difference is not statisti-
cally significant), the difference is much larger for
low-accuracy dialogs (70.0% vs 45.8%, p < 0.001)
confirming the robustness of the landmark-based be-
lief tracking approach when confronted with poor
input conditions.
5 Conclusion
In this paper, we have explored the possibilities of
incorporating spatial information into belief tracking
in spoken dialog systems. We proposed a landmark-
based location tracker which can be combined with
a semantic belief tracker to output inferred joint user
goal. Based on the results obtained from our batch
experiments, we conclude that integrating spatial in-
formation into a location-based dialog system could
improve the overall accuracy of belief tracking sig-
nificantly.
176
References
Cyril Allauzen, Michael Riley, Johan Schalkwyk, Woj-
ciech Skut, and Mehryar Mohri. 2007. Openfst: A
general and efficient weighted finite-state transducer
library. In Proceedings of the Ninth International
Conference on Implementation and Application of Au-
tomata (CIAA) Lecture Notes in Computer Science,
volume 4783, pages 11?23. Springer.
W.W. Cohen, P. Ravikumar, and S.E. Fienberg. 2003.
A comparison of string distance metrics for name-
matching tasks. In Proceedings of the IJCAI-2003
Workshop on Information Integration on the Web
(IIWeb-03), pages 73?78.
Alexander Gruenstein and Stephanie Seneff. 2007. Re-
leasing a multimodal dialogue system into the wild:
User support mechanisms. In In Proceedings of the
8th SIGdial Workshop on Discourse and Dialogue,
pages 111?119, September.
A. Gruenstein, I. McGraw, and I. Badr. 2008. The wami
toolkit for developing, deploying, and evaluating web-
accessible multimodal interfaces. In Proceedings of
the 10th international conference on Multimodal in-
terfaces, pages 141?148. ACM.
Albert Huang, Stefanie Tellex, Abe Bachrach, Thomas
Kollar, Deb Roy, and Nick Roy. 2010. Natural lan-
guage command of an autonomous micro-air vehicle.
In International Conference on Intelligent Robots and
Systems (IROS).
M. MacMahon, B. Stankiewicz, and B. Kuipers. 2006.
Walk the talk: Connecting language, knowledge, and
action in route instructions. In Proceedings of the
National Conference on Artificial Intelligence, vol-
ume 21, page 1475. Menlo Park, CA; Cambridge, MA;
London; AAAI Press; MIT Press; 1999.
N. Mehta, R. Gupta, A. Raux, D. Ramachandran, and
S. Krawczyk. 2010. Probabilistic ontology trees for
belief tracking in dialog systems. In Proceedings of
the 11th Annual Meeting of the Special Interest Group
on Discourse and Dialogue, pages 37?46. Association
for Computational Linguistics.
Michel Denis Pierre-emmanuel Michon. 2001. When
and why are visual landmarks used in giving direc-
tions? In D. R. Montello, editor, Spatial Information
Theory, Volume 2205 of Lecture Notes in Computer
Science, pages 292?305. Springer, Berlin.
A. Raux and Y. Ma. 2011. Efficient probabilistic track-
ing of user goal and dialog history for spoken dialog
systems. In Proceedings of Interspeech 2011.
Michael L. Seltzer, Yun-Cheng Ju, Ivan Tashev, and Alex
Acero. 2007. Robust location understanding in spo-
ken dialog systems using intersections. In Proceed-
ings of Interspeech 2007, pages 2813?2816.
K. Suzuki and Y. Wakabayashi. 2005. Cultural dif-
ferences of spatial descriptions in tourist guidebooks.
Spatial Cognition IV. Reasoning, Action, and Interac-
tion, 3343:147?164.
B. Thomson and S. Young. 2010. Bayesian update of di-
alogue state: A pomdp framework for spoken dialogue
systems. Computer Speech & Language, 24(4):562?
588.
Ariane Tom and Michel Denis. 2003. Referring to land-
mark or street information in route directions: What
difference does it make? Spatial Information The-
ory. Foundations of Geoghraphic Information Science,
Lecture Notes in Computer Science, 2825/2003:362?
374.
Barbara Tversky and Paul U. Lee. 1999. Pictorial and
verbal tools for conveying routes. In Proceedings of
the International Conference on Spatial Information
Theory: Cognitive and Computational Foundations
of Geographic Information Science(COSIT). Springer-
Verlag London.
177
User: &Italian&restaurant&near&
ASR: %italian%restaurant%near%
NLU: %Category=Italian%Restaurant%
Category %Italian'Restaurant'
Target !Dominos!Pizza!
Category %Italian'Restaurant'
Target !Dominos!Pizza!
User: &Italian&restaurant&near&Kappo&Nami&Nami&
ASR: %italian%restaurant%near%camp%to%numa%numa%
NLU: %Category=Italian%Restaurant,%Street=Camp%Avenue%
%Category=Italian%Restaurant,%Landmark=Jefunira%Camp%
Category %Italian'Restaurant%%
Street %Camp'Avenue'
Target &No!match!
Category %Italian'Restaurant'
Landmark %Jefunira'Camp'
Target ! !Maldonado?s%
User: &Italian&restaurant&near&Tempta5ons&
ASR: %italian%restaurant%near%temptaAons%
NLU: %Category=Italian%Restaurant,%Landmark=TemptaAons%
Category %Italian'Restaurant'
Street %Camp'Avenue'
Landmark %Tempta5ons'
Target &No!match!
Category %Italian'Restaurant'
Landmark %Jefunira'Camp,'Tempta5ons'
Target &Don!Giovanni!
Baseline' DPOT+Kernels'
Example&Dialog
Figure 7: Comparison between baseline and proposed method on an example dialog whose underlying true target is
an Italian restaurant called Don Giovanni.
178
Proceedings of the SIGDIAL 2013 Conference, pages 404?413,
Metz, France, 22-24 August 2013. c?2013 Association for Computational Linguistics
The Dialog State Tracking Challenge
Jason Williams1, Antoine Raux2?, Deepak Ramachandran3?, and Alan Black4
1Microsoft Research, Redmond, WA, USA 2Lenovo Corporation, Santa Clara, CA, USA
3Nuance Communications, Mountain View, CA, USA 4Carnegie Mellon University, Pittsburgh, PA, USA
jason.williams@microsoft.com araux@lenovo.com deepak.ramachandran@nuance.com awb@cmu.edu
Abstract
In a spoken dialog system, dialog state
tracking deduces information about the
user?s goal as the dialog progresses, syn-
thesizing evidence such as dialog acts over
multiple turns with external data sources.
Recent approaches have been shown to
overcome ASR and SLU errors in some
applications. However, there are currently
no common testbeds or evaluation mea-
sures for this task, hampering progress.
The dialog state tracking challenge seeks
to address this by providing a heteroge-
neous corpus of 15K human-computer di-
alogs in a standard format, along with a
suite of 11 evaluation metrics. The chal-
lenge received a total of 27 entries from 9
research groups. The results show that the
suite of performance metrics cluster into 4
natural groups. Moreover, the dialog sys-
tems that benefit most from dialog state
tracking are those with less discriminative
speech recognition confidence scores. Fi-
nally, generalization is a key problem: in
2 of the 4 test sets, fewer than half of the
entries out-performed simple baselines.
1 Overview and motivation
Spoken dialog systems interact with users via nat-
ural language to help them achieve a goal. As the
interaction progresses, the dialog manager main-
tains a representation of the state of the dialog
in a process called dialog state tracking (DST).
For example, in a bus schedule information sys-
tem, the dialog state might indicate the user?s de-
sired bus route, origin, and destination. Dialog
state tracking is difficult because automatic speech
?Most of the work for the challenge was performed when
the second and third authors were with Honda Research In-
stitute, Mountain View, CA, USA
recognition (ASR) and spoken language under-
standing (SLU) errors are common, and can cause
the system to misunderstand the user?s needs. At
the same time, state tracking is crucial because
the system relies on the estimated dialog state to
choose actions ? for example, which bus schedule
information to present to the user.
Most commercial systems use hand-crafted
heuristics for state tracking, selecting the SLU re-
sult with the highest confidence score, and dis-
carding alternatives. In contrast, statistical ap-
proaches compute scores for many hypotheses for
the dialog state (Figure 1). By exploiting correla-
tions between turns and information from external
data sources ? such as maps, bus timetables, or
models of past dialogs ? statistical approaches can
overcome some SLU errors.
Numerous techniques for dialog state tracking
have been proposed, including heuristic scores
(Higashinaka et al, 2003), Bayesian networks
(Paek and Horvitz, 2000; Williams and Young,
2007), kernel density estimators (Ma et al, 2012),
and discriminative models (Bohus and Rudnicky,
2006). Techniques have been fielded which scale
to realistically sized dialog problems and operate
in real time (Young et al, 2010; Thomson and
Young, 2010; Williams, 2010; Mehta et al, 2010).
In end-to-end dialog systems, dialog state tracking
has been shown to improve overall system perfor-
mance (Young et al, 2010; Thomson and Young,
2010).
Despite this progress, direct comparisons be-
tween methods have not been possible because
past studies use different domains and system
components, for speech recognition, spoken lan-
guage understanding, dialog control, etc. More-
over, there is little agreement on how to evaluate
dialog state tracking. Together these issues limit
progress in this research area.
The Dialog State Tracking Challenge (DSTC)
provides a first common testbed and evaluation
404
Figure 1: Overview of dialog state tracking. In this example, the dialog state contains the user?s desired
bus route. At each turn t, the system produces a spoken output. The user?s spoken response is processed
to extract a set of spoken language understanding (SLU) results, each with a local confidence score. A
set of Nt dialog state hypotheses is formed by considering all SLU results observed so far, including the
current turn and all previous turns. Here, N1 = 3 and N2 = 5. The dialog state tracker uses features of
the dialog context to produce a distribution over all Nt hypotheses and the meta-hypothesis that none of
them are correct.
suite for dialog state tracking. The DSTC orga-
nizers made available a public, heterogeneous cor-
pus of over 15K transcribed and labeled human-
computer dialogs. Nine teams entered the chal-
lenge, anonymously submitting a total of 27 dialog
state trackers.
This paper serves two roles. First, sections 2
and 3 provide an overview of the challenge, data,
and evaluation metrics, all of which will remain
publicly available to the community (DST, 2013).
Second, this paper summarizes the results of the
challenge, with an emphasis on gaining new in-
sights into the dialog state tracking problem, in
Section 4. Section 5 briefly concludes.
2 Challenge overview
2.1 Problem statement
First, we define the dialog state tracking problem.
A dialog state tracker takes as input all of the ob-
servable elements up to time t in a dialog, includ-
ing all of the results from the automatic speech
recognition (ASR) and spoken language under-
standing (SLU) components, and external knowl-
edge sources such as bus timetable databases and
models of past dialogs. It also takes as input a
set of Nt possible dialog state hypotheses, where
a hypothesis is an assignment of values to slots in
the system. The tracker outputs a probability dis-
tribution over the set of Nt hypotheses, and the
meta-hypothesis REST which indicates that none
of them are correct. The goal is to assign probabil-
ity 1.0 to the correct state, and 0.0 to other states.
Note that the set of dialog states is given. Also
note that Nt varies with t ? typically as the dia-
log progresses and more concepts are discussed,
the number of candidate hypotheses increases. An
example is given in Figure 1.
In this challenge, dialog states are generated in
the usual way, by enumerating all slots values that
have appeared in the SLU N-best lists or system
output up until the current turn. While this ap-
proach precludes a tracker assigning a score to an
405
SLU value that has not been observed, the cardi-
nality of the slots is generally large, so the likeli-
hood of a tracker correctly guessing a slot value
which hasn?t been observed anywhere in the input
or output is vanishingly small.
2.2 Challenge design
The dialog state tracking challenge studies this
problem as a corpus-based task ? i.e., dialog state
trackers are trained and tested on a static corpus
of dialogs, recorded from systems using a variety
of state tracking models and dialog managers. The
challenge task is to re-run state tracking on these
dialogs ? i.e., to take as input the runtime system
logs including the SLU results and system output,
and to output scores for dialog states formed from
the runtime SLU results. This corpus-based de-
sign was chosen because it allows different track-
ers to be evaluated on the same data, and because a
corpus-based task has a much lower barrier to en-
try for research groups than building an end-to-end
dialog system.
In practice of course, a state tracker will be used
in an end-to-end dialog system, and will drive ac-
tion selection, thereby affecting the distribution of
the dialog data the tracker experiences. In other
words, it is known in advance that the distribu-
tion in the training data and live data will be mis-
matched, although the nature and extent of the
mis-match are not known. Hence, unlike much
of supervised learning research, drawing train and
test data from the same distribution in offline ex-
periments may overstate performance. So in the
DSTC, train/test mis-match was explicitly created
by choosing test data to be from different dialog
systems.
2.3 Source data and challenge corpora
The DSTC uses data from the public deployment
of several systems in the Spoken Dialog Challenge
(SDC) (Black et al, 2010), provided by the Dialog
Research Center at Carnegie Mellon University. In
the SDC, telephone calls from real passengers of
the Port Authority of Allegheny County, who runs
city buses in Pittsburgh, were forwarded to dialog
systems built by different research groups. The
goal was to provide bus riders with bus timetable
information. For example, a caller might want
to find out the time of the next bus leaving from
Downtown to the airport.
The SDC received dialog systems from three
different research groups, here called Groups A,
B, and C. Each group used its own ASR, SLU,
and dialog manager. The dialog strategies across
groups varied considerably: for example, Groups
A and C used a mixed-initiative design, where the
system could recognize any concept at any turn,
but Group B used a directed design, where the
system asked for concepts sequentially and could
only recognize the concept being queried. Groups
trialled different system variants over a period of
almost 3 years. These variants differed in acoustic
and language models, confidence scoring model,
state tracking method and parameters, number of
supported bus routes, user population, and pres-
ence of minor bugs. Example dialogs from each
group are shown in the Appendix.
The dialog data was partitioned into 5 train-
ing corpora and 4 testing corpora (Table 1).
The partioning was intended to explore different
types of mis-match between the training and test
data. Specifically, the dialog system in TRAIN1A,
TRAIN1B, TRAIN1C, TRAIN2, and TEST1 are all
very similar, so TEST1 tests the case where there
is a large amount of similar data. TEST2 uses the
same ASR and SLU but a different dialog con-
troller, so tests the case where there is a large
amount of somewhat similar data. TEST3 is very
similar to TRAIN3 and tests the case where there
is a small amount of similar data. TEST4 uses a
completely different dialog system to any of the
training data.
2.4 Data preparation
The dialog system log data from all three groups
was converted to a common format, which
described SLU results and system output using
a uniform set of dialog acts. For example, the
system speech East Pittsburgh Bus Schedules.
Say a bus route, like 28X, or say I?m not sure.
was represented as hello(), request(route), exam-
ple(route=28x), example(route=dontknow). The
user ASR hypothesis the next 61c from oakland to
mckeesport transportation center was represented
as inform(time.rel=next), inform(route=61c),
inform(from.neighborhood=oakland), in-
form(to.desc=?mckeesport transportation
center?). In this domain there were a total
of 9 slots: the bus route, date, time, and three
components each for the origin and destination,
corresponding to streets, neighborhoods, and
points-of-interest like universities. For complete
details see (Williams et al, 2012).
406
TRAIN TEST
1A 1B 1C 2 3 1 2 3 4
Group A A A A B A A B C
Year(s) 2009 2009 2009 2010 2010 2011 2012 2011-2 2010
Dialogs 1013 1117 9502 643 688 715 750 1020 438
Turns/Dialog 14.7 13.3 14.5 14.5 12.6 14.1 14.5 13.0 10.9
Sys acts/turn 4.0 3.8 3.8 4.0 8.4 2.8 3.2 8.2 4.6
Av N-best len 21.7 22.3 21.9 22.4 2.9 21.2 20.5 5.0 3.2
Acts/N-best hyp 2.2 2.2 2.2 2.3 1.0 2.1 2.0 1.0 1.6
Slots/turn 44.0 46.5 45.6 49.0 2.1 41.4 36.9 4.3 3.5
Transcribed? yes yes yes yes yes yes yes yes yes
Labelled? yes no no yes yes yes yes yes yes
1-best WER 42.9% 41.1% 42.1% 58.2% 40.5% 57.9% 62.1% 48.1% 55.6%
1-best SLU Prec. 0.356 - - 0.303 0.560 0.252 0.275 0.470 0.334
1-best SLU Recall 0.522 - - 0.388 0.650 0.362 0.393 0.515 0.376
N-best SLU Recall 0.577 - - 0.485 0.738 0.456 0.492 0.634 0.413
Table 1: Summary of the datasets. One turn includes a system output and a user response. Slots are
named entity types such as bus route, origin neighborhood, date, time, etc. N-best SLU Recall indicates
the fraction of concepts which appear anywhere on the SLU N-best list.
Group B and C systems produced N-best lists
of ASR and SLU output, which were included in
the log files. Group A systems produced only 1-
best lists, so for Group A systems, recognition was
re-run with the Pocketsphinx speech recognizer
(Huggins-Daines et al, 2006) with N-best output
enabled, and the results were included in the log
files.
Some information in the raw system logs was
specific to a group. For example, Group B?s logs
included information about word confusion net-
works, but other groups did not. All of this infor-
mation was included in a ?system specific? sec-
tion of the log files. Group A logs contained about
40 system-specific name/value pairs per turn, and
Group B about 600 system-specific name/value
pairs per turn. Group C logs contained no system
specific data.
3 Labeling and evaluation design
The output of a dialog state tracker is a proba-
bility distribution over a set of given dialog state
hypotheses, plus the REST meta-hypothesis. To
evaluate this output, a label is needed for each di-
alog state hypothesis indicating its correctness.
In this task-oriented domain, we note that the
user enters the call with a specific goal in mind.
Further, when goal changes do occur, they are
usually explicitly marked: since all of the sys-
tems first collect slot values, and then provide bus
timetables, if the user wishes to change their goal,
they need to start over from the beginning. These
?start over? transitions are obvious in the logs.
This structure allows the correctness of each di-
alog state to be equated to the correctness of the
SLU items it contains. As a result, in the DSTC
we labeled the correctness of SLU hypotheses in
each turn, and then assumed these labels remain
valid until either the call ends, or until a ?start
over? event. Thus to produce the labels, the la-
beling task followed was to assign a correctness
value to every SLU hypothesis on the N-best list,
given a transcript of the words actually spoken in
the dialog up to the current turn.
To accomplish this, first all user speech was
transcribed. The TRAIN1 datasets had been tran-
scribed using crowd-sourcing in a prior project
(Parent and Eskenazi, 2010); the remainder were
transcribed by professionals. Then each SLU hy-
pothesis was labled as correct or incorrect. When a
transcription exactly and unambiguously matched
a recognized slot value, such as the bus route
?sixty one c?, labels were assigned automati-
cally. The remainder were assigned using crowd-
sourcing, where three workers were shown the true
words spoken and the recognized concept, and
asked to indicate if the recognized concept was
correct ? even if it did not match the recognized
words exactly. Workers were also shown dialog
407
history, which helps decipher the user?s meaning
when their speech was ambiguous. If the 3 work-
ers were not unanimous in their labels (about 4%
of all turns), the item was labeled manually by the
organizers. The REST meta-hypothesis was not
explicitly labeled; rather, it was deemed to be cor-
rect if none of the prior SLU results were labeled
as correct.
In this challenge, state tracking performance
was measured on each of the 9 slots separately,
and also on a joint dialog state consisting of all the
slots. So at each turn in the dialog, a tracker output
10 scored lists: one for each slot, plus a 10th list
where each dialog state contains values from all
slots. Scores were constrained to be in the range
[0, 1] and to sum to 1.
To evaluate tracker output, at each turn, each hy-
pothesis (including REST) on each of the 10 lists
was labeled as correct or incorrect by looking up
its corresponding SLU label(s). The scores and la-
bels over all of the dialogs were then compiled to
compute 11 metrics. Accuracy measures the per-
cent of turns where the top-ranked hypothesis is
correct. This indicates the correctness of the item
with the maximum score. L2 measures the L2 dis-
tance between the vector of scores, and a vector of
zeros with 1 in the position of the correct hypoth-
esis. This indicates the quality of all scores, when
the scores as viewed as probabilities.
AvgP measures the mean score of the first cor-
rect hypothesis. This indicates the quality of the
score assigned to the correct hypothesis, ignoring
the distribution of scores to incorrect hypotheses.
MRR measures the mean reciprocal rank of the
first correct hypothesis. This indicates the quality
of the ordering the scores produces (without nec-
essarily treating the scores as probabilities).
The remaining measures relate to receiver-
operating characteristic (ROC) curves, which
measure the discrimination of the score for the
highest-ranked state hypothesis. Two versions
of ROC are computed ? V1 and V2. V1 com-
putes correct-accepts (CA), false-accepts (FA),
and false-rejects (FR) as fractions of all utter-
ances, so for example
CA.V 1(s) = #CA(s)N (1)
where #CA(s) indicates the number of correctly
accepted states when only those states with score
? s are accepted, and N is the total number
of states in the sample. The V1 metrics are a
20%
30%
40%
50%
60%
70%
80%
90%
100%
sche
dule
2 ac
cura
cy fo
r all
 slot
s
Trackers Oracle Baseline0 Baseline1
train293% test175% test289% test348%train382% test438%
Figure 2: Schedule2 accuracy averaged over slots
for every tracker on every dataset. Percentages un-
der the datasets indicate the percent of the track-
ers which exceeded the performance of both base-
lines.
useful indication of overall performance because
they combine discrimination and overall accuracy
? i.e., the maximum CA.V 1(s) value is equal to
accuracy computed above.
V2 considers fractions of correctly classified ut-
terances, so for example
CA.V 2(s) = #CA(s)#CA(0) . (2)
The V2 metrics are useful because they measure
the discrimination of the scoring independently of
accuracy ? i.e., the maximum value of CA.V 2(s)
is always 1, regardless of accuracy.
From these ROC statistics, several met-
rics are computed. ROC.V1.EER computes
FA.V 1(s) where FA.V 1(s) = FR.V 1(s).
The metrics ROC.V1.CA05, ROC.V1.CA10,
and ROC.V1.CA20 compute CA.V 1(s) when
FA.V 1(s) = 0.05, 0.10, and 0.20 respec-
tively. ROC.V2.CA05, ROC.V2.CA10, and
ROC.V2.CA20 do the same using the V2 ver-
sions.
Apart from what to measure, there is currently
no standard that specifies when to measure ? i.e.,
which turns to include when computing each met-
ric. So for this challenge, a set of 3 schedules were
used. schedule1 includes every turn. schedule2
include turns where the target slot is either present
on the SLU N-best list, or where the target slot
is included in a system confirmation action ? i.e.,
where there is some observable new information
408
0%
10%
20%
30%
40%
50%
60%
70%
80%
90%
100%
0% 20% 40% 60% 80% 100%
True 
posit
ive ra
te
 
False positive rate  
test4test3test2test1
Figure 3: Receiver operating characteristc (ROC)
curve for SLU confidence scores of the 1-best hy-
pothesis in the test datasets. The SLU confidence
score in TEST3 is most discriminative; TEST1 and
TEST2 are the least discriminative.
about the target slot. schedule3 includes only the
last turn of a dialog.
In sum, for each tracker, one measurement is re-
ported for each test set (4), schedule (3), and met-
ric (11) for each of the 9 slots, the ?joint? slot, and
a weighted average of the individual slots (11), for
a total of 4 ? 3 ? 11 ? 11 = 1452 measurements per
tracker. In addition, each tracker reported average
latency per turn ? this ranged from 10ms to 1s.
3.1 Baseline trackers
For comparisons, two simple baselines were im-
plemented. The first (Baseline0) is a majority
class baseline that always guesses REST with
score 1. The second (Baseline1) follows simple
rules which are commonly used in spoken dialog
systems. It maintains a single hypothesis for each
slot. Its value is the SLU 1-best with the highest
confidence score observed so far, with score equal
to that SLU item?s confidence score.
4 Results and discussion
Logistically, the training data and labels, bus
timetable database, scoring scripts, and baseline
system were publicly released in late December
2012. The test data (without labels) was released
on 22 March 2013, and teams were given a week to
run their trackers and send results back to the orga-
nizers for evaluation. After the evaluation, the test
labels were published. Each team could enter up
to 5 trackers. For the evaluation, teams were asked
to process the test dialogs online ? i.e., to make a
1
3
5
7
9
11
13
15
17
19
accuracy l2 roc.v1_eer roc.v2_ca05
Average
 rank
 in tes
t datase
ts
Metric - schedule2 - weighted average over all slots
T3.E2T5.E1T5.E2T5.E5T6.E2T6.E3T6.E4T6.E5T9.E1
Figure 4: Average rank of top-performing trackers
for the four metrics identified in Figure 6. Rank-
ing was done using the given metric, schedule2,
and the weighted average of all slots. Tn.Em in-
dicates team n, entry m.
single pass over the data, as if the tracker were be-
ing run in deployment. Participation was open to
researchers at any institution, including the orga-
nizers and advisory board. To encourage partici-
pation, the organizers agreed not to identify par-
ticipants in publications, and there was no require-
ment to disclose how trackers were implemented.
9 teams entered the DSTC, submitting a total of
27 trackers. The raw output and all 1452 measure-
ments for each tracker (and the 2 baselines) are
available from the DSTC homepage (DST, 2013).
4.1 Analysis of trackers and datasets
We begin by looking at one illustrative metric,
schedule2 accuracy averaged over slots, which
measures the accuracy of the top dialog hypothe-
sis for every slot when it either appears on the SLU
N-best list or is confirmed by the system.1 Results
in Figure 2 show two key trends. First, relative
to the baselines, performance on the test data is
markedly lower than the training data. Comparing
TRAIN2 to TEST1/TEST2 and TRAIN3 to TEST3,
the relative gain over the baselines is much lower
on test data. Moreover, only 38% of trackers per-
formed better than a simple majority-class base-
line on TEST4, for which there was no matched
training data. These findings suggests that gen-
eralization is an important open issues for dialog
state trackers.
Second, Figure 2 indicates that the gains made
1Results using the joint dialog state are broadly similar,
and are omitted for space.
409
20%
30%
40%
50%
60%
70%
80%
90%
0% 5% 10% 15% 20% 25% 30% 35% 40%
sche
dule2
 accu
racy 
for a
ll slo
ts
% of turns where top dialog hypothesis was not top SLU result
Trackers Baseline0 Baseline1
(a) TEST1
20%
30%
40%
50%
60%
70%
80%
90%
0% 5% 10% 15% 20% 25% 30% 35% 40%
sche
dule2
 accu
racy 
for a
ll slo
ts
% of turns where top dialog hypothesis was not top SLU result
(b) TEST2
20%
30%
40%
50%
60%
70%
80%
90%
0% 5% 10% 15% 20% 25% 30% 35% 40%
sche
dule2
 accu
racy 
for a
ll slo
ts
% of turns where top dialog hypothesis was not top SLU result
(c) TEST3
20%
30%
40%
50%
60%
70%
80%
90%
0% 5% 10% 15% 20% 25% 30% 35% 40%
sche
dule2
 accu
racy 
for a
ll slo
ts
% of turns where top dialog hypothesis was not top SLU result
(d) TEST4
Figure 5: Percent of highest-scored dialog state hypotheses which did not appear in the top-ranked SLU
position vs. schedule2 accuracy over all slots. Trackers ? including those with the highest accuracy ?
for TEST1 and TEST2 rarely assigned the highest score to an SLU hypothesis other than the top. All
trackers for TEST3 and TEST4 assigned the highest score to an SLU hypothesis other than the top in a
non-trivial percent of turns.
by the trackers over the baselines are larger
for Group A systems (TEST1 and TEST2) than
for Group B (TEST3) and C (TEST4) systems.
Whereas the baselines consider only the top SLU
hypothesis, statistical trackers can make use of
the entire N-best list, increasing recall ? compare
the 1-best and N-best SLU recall rates in Table 1.
However, Group A trackers almost never assigned
the highest score to an item below the top position
in the SLU N-best list. Rather, the larger gains for
Group A systems seem due to the relatively poor
discrimination of Group A?s SLU confidence score
(Figure 3): whereas the trackers use a multitude
of features to assign scores, the baselines rely en-
tirely on the SLU confidence for their scores, so
undiscriminative SLU confidence measures ham-
per baseline performance.
4.2 Analysis of metrics
This challenge makes it possible to study the em-
pirical differences among the evaluation metrics.
Intuitively, if the purpose of a metric is to order
a set of trackers from best to worst, then 2 met-
rics are similar if they yield a similar ordering over
trackers. Specifically, for every metricm, we have
a value x(m, d, s, t) where d is the dataset, and
s is the evaluation schedule, and t is the tracker.
We define r(m, d, s, t) as the rank of tracker t
when ordered using metric m, dataset d and eval-
uation schedule s. Using these ranks, we compute
Kendall?s Tau for every d, s, and pair of metrics
m1 and m2 (Kendall, 1938). We then compute the
average Kendall?s Tau for m1 and m2 by averag-
ing over all d and s.2
Results are in Figure 6. Here we see 4 natu-
ral clusters emerge: a cluster for correctness with
Accuracy, MRR, and the ROC.V1.CA measures; a
cluster for probability quality with L2 and Aver-
age score; and two clusters for score discrimina-
tion ? one with ROC.V1.EER and the other with
the three ROC.V2 metrics. This finding suggest
2A similar analysis over schedules showed that the differ-
ences in ranking for different schedules were smaller than for
metrics.
410
accuracy
mrr
roc_v1.ca05
roc_v1.ca10
roc_v1.ca20
roc.v1_eer
avgp
l2
roc.v2_ca05
roc.v2_ca05
roc.v2_ca05
Figure 6: Average divergence between rank orderings produced by different metrics. The size of a circle
at (x, y) is given by 1?? , where ? is the average Kendall?s Tau computed on the rank orderings produced
by methods x and y. Larger circles indicate dissimilar rankings; smaller circles indicate similar rankings;
missing circles indicate identical rankings. The red boxes indicate groups of metrics that yield similar
rankings.
that measuring one metric from each cluster will
contain nearly the same information as all 9 met-
rics. For example, one might report only Accu-
racy, L2, ROC.V1.EER, and ROC.V2.CA5.
Using these 4 metrics, we rank-ordered each
tracker, using schedule2 and a weighted average
of all slots. We then computed the average rank
across the 4 test sets. Finally we selected the set
of trackers with the top three average ranks for
each metric. Results in Figure 4 emphasize that
different trackers are tuned for different perfor-
mance measures, and the optimal tracking algo-
rithm depends crucially on the target performance
measure.
5 Conclusion
The dialog state tracking challenge has provided
the first common testbed for this task. The data,
evaluation tools, and baselines will continue to be
freely available to the research community (DST,
2013). The details of the trackers themselves will
be published at SIGDIAL 2013.
The results of the challenge show that the
suite of performance metrics cluster into 4 natural
groups. We also find that larger gains over conven-
tional rule-based baselines are present in dialog
systems where the speech recognition confidence
score has poor discrimination. Finally, we observe
substantial limitations on generalization: in mis-
matched conditions, around half of the trackers en-
tered did not exceed the performance of two sim-
ple baselines.
In future work, it should be verified that im-
provements in dialog state tracking lead to im-
provements in end-to-end dialog performance
(e.g., task completion, user satisfaction, etc.). In
addition, it would be interesting to study dialogs
where goal changes are more common.
Acknowledgements
The organizers thank the advisory board for their
valuable input on the design of the challenge:
Daniel Boies, Paul Crook, Maxine Eskenazi, Mil-
ica Gasic, Dilek Hakkani-Tur, Helen Hastie, Kee-
Eung Kim, Ian Lane, Sungjin Lee, Teruhisa Misu,
Olivier Pietquin, Joelle Pineau, Blaise Thomson,
David Traum, and Luke Zettlemoyer. The orga-
nizers also thank Ian Lane for his support for tran-
scription, and Microsoft and Honda Research In-
stitute USA for funding the challenge. Finally,
we thank the participants for making the challenge
successful.
411
References
AW Black, S Burger, B Langner, G Parent, and M Es-
kenazi. 2010. Spoken dialog challenge 2010. In
Proc SLT, Berkeley.
D Bohus and AI Rudnicky. 2006. A ?K hypotheses +
other? belief updating model. In Proc AAAI Work-
shop on Statistical and Empirical Approaches for
Spoken Dialogue Systems, Boston.
2013. Dialog State Tracking Challenge Home-
page. http://research.microsoft.com/
events/dstc/.
H Higashinaka, M Nakano, and K Aikawa. 2003.
Corpus-based discourse understanding in spoken di-
alogue systems. In Proc ACL, Sapporo.
D Huggins-Daines, M Kumar, A Chan, A W Black,
M Ravishankar, and A I Rudnicky. 2006. Pock-
etSphinx: A Free, Real-Time Continuous Speech
Recognition System for Hand-Held Devices. In
Proc ICASSP, Toulouse.
M Kendall. 1938. A new measure of rank correlation.
Biometrika, 30(1-2):81?89.
Y Ma, A Raux, D Ramachandran, and R Gupta. 2012.
Landmark-based location belief tracking in a spoken
dialog system. In Proc SigDial, Seoul.
N Mehta, R Gupta, A Raux, D Ramachandran, and
S Krawczyk. 2010. Probabilistic ontology trees for
belief tracking in dialog systems. In Proc SigDial,
Tokyo.
T Paek and E Horvitz. 2000. Conversation as ac-
tion under uncertainty. In Proc UAI, Stanford, pages
455?464.
G Parent and M Eskenazi. 2010. Toward Bet-
ter Crowdsourced Transcription: Transcription of a
Year of the Let?s Go Bus Information System Data.
In Proc SLT, Berkeley.
B Thomson and SJ Young. 2010. Bayesian update
of dialogue state: A POMDP framework for spoken
dialogue systems. Computer Speech and Language,
24(4):562?588.
JD Williams and SJ Young. 2007. Partially observable
Markov decision processes for spoken dialog sys-
tems. Computer Speech and Language, 21(2):393?
422.
JD Williams, A Raux, D Ramachandran, and
AW Black. 2012. Dialog state tracking challenge
handbook. Technical report, Microsoft Research.
JD Williams. 2010. Incremental partition recombina-
tion for efficient tracking of multiple dialogue states.
In Proc. of ICASSP.
SJ Young, M Gas?ic?, S Keizer, F Mairesse, J Schatz-
mann, B Thomson, and K Yu. 2010. The hid-
den information state model: a practical framework
for POMDP-based spoken dialogue management.
Computer Speech and Language, 24(2):150?174.
Appendix 1: Sample dialog excerpts
Below are transcripts of calls in the DSTC corpus.
The user?s side shows utterances as transcribed by
human annotators.
Group A
SYS: Welcome to the CMU Let?s Go bus informa-
tion system. To get help at any time, just say Help
or press zero. What can I do for you?
USR: 61c evening hours
SYS: For example, you can say, when is the next
28X from DOWNTOWN to THE AIRPORT? or
I?d like to go from MCKEESPORT to HOME-
STEAD tomorrow at 10 a.m.
USR: i?d like to go [noise]
SYS: Where are you leaving from?
USR: from Kennywood tomorrow at 6:30 PM
SYS: Leaving from MCKEE. Is this correct?
USR: yes
SYS: Okay What is your destination?
USR: downtown
SYS: Going to DOWNTOWN. Is this correct?
USR: yes
SYS: Right When do you want to travel?
USR: 6:30 PM
SYS: Leaving at 6 30 p.m.. Is this correct?
USR: [noise] yes
SYS: Alright Hold on. I?ll look that up. There is
a 71D leaving FIFTH AVENUE AT DARRAGH
MCKEE at 6 40 p.m.. It will arrive at FIFTH AV-
ENUE AT MARKET at 6 58 p.m.. To get more
information about buses related to this trip, you
can say, when is the next bus, or, when is the pre-
vious bus. To ask about a different trip, you can
say, start a new query. If you are finished, you can
say goodbye.
USR: start a new query
SYS: Okay, let?s start from the beginning.
USR: ...
Group B
SYS: East Pittsburgh Bus Schedules. Say a bus
route, like 28X, or say I?m not sure.
USR: 61A
SYS: Okay, 61A. To change, say go back. Where
are you leaving from?
USR: Downtown
SYS: Okay, downtown. You can always say go
back. And where are you going to?
USR: East Pittsburgh East Pittsburgh
SYS: Pittsburgh. Is that right?
412
USR: No
SYS: Oh, sorry, where are you going to?
USR: East Pittsburgh
SYS: Okay, East Pittsburgh. Do you want times
for the next few buses? Say yes or no.
USR: Yes
SYS: Ok, the next few buses. To change, say go
back. At 7:45 PM today, there is a 61 A, from
Fifth Avenue And Market Street, Downtown, ar-
riving Dynamo Alley And Beech Avenue, In East
Pittsburgh, at 8:42 PM. Say repeat, next, previous,
or start over.
Group C
SYS: Welcome to the Lets Go! bus information
system for Pittsburgh. Where would you like to
leave from?
USR: [noise]
SYS: Where do you wanna leave from?
USR: [noise] um I?m leaving from Forbes avenue
and Murray avenue
SYS: I?m sorry but I do not know any stops in the
moon neighborhood. The routes I currently cover
are the following: 28X, 54C, 56U, 61A, 61B, 61C,
61D and 64.
USR: um I need the scheduling information for the
61D
SYS: Where would you like to leave from?
USR: Forbes and Murray
SYS: Where do you wanna go?
USR: Greenfield
SYS: When are you going to take that bus?
USR: 61D
SYS: When are you going to take that bus?
USR: 61D
SYS: When would you like to travel? Say next bus
for the the next bus .
USR: next bus
SYS: The next bus from forbes avenue at murray
to greenfield is the 61D, leaving at 8 43 p.m. . It
arrives at murray avenue at loretta at 8 52 p.m. .
You may now say. next bus, previous bus, restart,
or goodbye.
USR: [noise] good-bye
SYS: Thank you goodbye
Appendix 2: Example log fragment
Following is a log from a call in TRAIN3. Someelements have been omitted for space. Logs areformatted in JavaScript Object Notation (JSON).
{
"session-id": "dt-201007221854-4808D",
"turns": [ {
"input": {
"asr-hyps": [
{ "asr-hyp": "sixty one b",
"score": 0.834314,
},
...
],
"slu-hyps": [
{ "slu-hyp": [
{"act": "inform",
"slots": [["route", "61b"]]},
],
"score": 0.834314,
},
...
],
"audio-file": "002.raw",
"start-time": 7.504
},
"output": {
"start-time": 0.078,
"transcript": "East Pittsburgh Bus
Schedules. Say a bus route, like
28X, or say I?m not sure.",
"dialog-acts": [
{ "act": "hello",
"slots": [] },
{ "act": "request",
"slots": [["route",null]] },
{ "act": "example",
"slots": [["route","28x"]] },
{ "act": "example",
"slots": [["route","dontknow"]] }
],
}
"system-specific": {
"wcn": {
"best_path_score": 0.9965,
"best_path": {
"word": ["sixty","one","b"],
"prob": [ 1.0,1.0,0.9965 ],
}
"network": [ ... ]
},
"nbest": [
{
"normSpeechLhood": -152.654,
"lastSpeechFrame": 266,
"numFrames": 354,
"udelta": -3.0280,
"speechLikelihood": -15876.0,
},
...
],
...
},
},
...
]
}
413
