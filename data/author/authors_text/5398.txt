Bootstrapping Morphological Analyzers 
by Combining Human Elicitation and 
Machine Learning 
Kemal Oflazer* 
Sabancl University 
Marjorie McShane* 
New Mexico State University 
Sergei Nirenburg* 
New Mexico State University 
This paper presents a semiautomatic technique for developing broad-coverage finite-state mor- 
phological analyzers for use in natural language processing applications. It consists of three 
components--elicitation f linguistic information from humans, a machine learning bootstrap- 
ping scheme, and a testing environment. The three components are applied iteratively until a 
threshold of output quality is attained. The initial application of this technique is for the mor- 
phology of low-density languages in the context of the Expedition project at NMS U Computing 
Research Laboratory. This elicit-build-test technique compiles lexical and inflectional information 
elicited from a human into a finite-state transducer lexicon and combines this with a sequence 
of morphographemic rewrite rules that is induced using transformation-based l arning from 
the elicited examples. The resulting morphological nalyzer is then tested against a test set, 
and any corrections are fed back into the learning procedure, which then builds an improved 
analyzer. 
1. Introduction 
The Expedition project at NMSU Computing Research Laboratory is devoted to the 
fast "ramp-up" of machine translation systems from less studied, so-called low-density 
languages, into English. One of the components hat must be acquired and built dur- 
ing this process is a morphological nalyzer for the source language. Since language 
informants are not expected or required to be well-versed in computational linguistics 
in general, or in recent approaches tobuilding morphological nalyzers (e.g., Kosken- 
niemi 1983; Antworth 1990; Karttunen, Kaplan, and Zaenen 1992; Karttunen 1994) and 
the operation of state-of-the-art finite-state tools (e.g., Karttunen 1993; Karttunen and 
Beesley 1992; Karttunen et al 1996; Mohri, Pereira, and Riley 1998; van Noord 1999; 
van Noord and Gerdemann 1999) in particular, the generation of the morphological 
analyzer component has to be accomplished semiautomatically. The informant will 
be guided through a knowledge licitation procedure using the elicitation component 
of Expedition, the Boas system. As this task is not easy, we expect hat the develop- 
ment of the morphological nalyzer will be an iterative process, whereby the human 
informant will revise and/or refine the information previously elicited based on the 
feedback from test runs of the nascent analyzer. 
* Faculty of Engineering and Natural Sciences, Orhanh, 81474 Tuzla, Istanbul, TURKEY 
t Computing Research Laboratory, Las Cruces, NM 88003 
Computational Linguistics Volume 27, Number 1 
The work reported in this paper describes the process of building and refining mor- 
phological analyzers using data elicited from human informants and machine learning. 
The main use of machine learning in our current approach is in the automatic learning 
of formal rewrite or replace rules for morphographemic changes derived from the ex- 
amples provided by the informant. The subtask of accounting for morphographemic 
changes is perhaps one of the more complicated aspects of building an analyzer; by 
automating it, we expect o improve productivity. 
After a review of related work, we very briefly describe the Boas project, of which 
the current work is a part. Subsequent sections describe the details of the approach, 
the architecture of the morphological analyzer, the elicited descriptive data, and the 
computational processes performed on this data, including segmentation and the in- 
duction of morphographemic rules. We then provide a detailed example of applying 
this approach to developing a morphological nalyzer for Polish. Finally, we provide 
some conclusions and ideas for future work. 
2. Related Work 
Machine learning techniques are widely employed in many aspects of language pro- 
cessing. The availability of large, annotated corpora has fueled a significant amount of 
work in the application of machine learning techniques to language processing prob- 
lems, such as part-of-speech tagging, grammar induction, and sense disambiguation, 
as witnessed by recent workshops and journal issues dedicated to this topic. 1 The cur- 
rent work attempts to contribute to this literature by describing a human-supervised 
machine learning approach to the induction of morphological analyzers--a problem 
that, surprisingly, has received little attention. 
There have been a number of studies on inducing morphographemic rules from a 
list of inflected words and a root word list. Johnson (1984) presents a scheme for in- 
ducing phonological rules from surface data, mainly in the context of studying certain 
aspects of language acquisition. The premise is that languages have a finite number of 
alternations to be handled by morphographemic rules and a fixed number of contexts 
in which they appear; so if there is enough data, phonological rewrite rules can be 
generated to account for the data. Rules are ordered by some notion of "surfaciness", 
and at each stage the most surfacy rule--the rule with the most transparent context-- 
is selected. Golding and Thompson (1985) describe an approach for inducing rules of 
English word formation from a corpus of root forms and the corresponding inflected 
forms. The procedure described there generates a sequence of transformation rules, 2 
each specifying how to perform a particular inflection. 
More recently, Theron and Cloete (1997) have presented a scheme for obtaining 
two-level morphology rules from a set of aligned segmented and surface pairs. They 
use the notion of string edit sequences, assuming that only insertions and deletions 
are applied to a root form to get the inflected form. They determine the root form 
associated with an inflected form (and consequently the suffixes and prefixes) by ex- 
haustively matching the inflected form against all root words. The motivation is that 
"real" suffixes will appear frequently in the corpus of inflected forms. Once common 
suffixes and prefixes are identified, the segmentation for an inflected word can be 
determined by choosing the segmentation with the most frequently occurring affix 
segments; the remainder is then considered the root. While this procedure seems to 
1 For instance, the CoNLL (Computational Natural Language Learning) Workshops, recent special issues 
of Machine Learning Journal (Vol. 34 Issue 1/3, Feb. 1999) and AIMagazine (Vol. 18, No. 4, 1997). 
2 Not in the sense in which it is used in transformation-based learning (Brill 1995). 
60 
Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzers 
be reasonable for a small root word list, the potential for "noisy" or incorrect align- 
ments is quite high when the corpus of inflected forms is large and the procedure 
is not given any prior knowledge of possible segmentations. As a result, automati- 
cally selecting the "correct" segmentation becomes nontrivial. An additional compli- 
cation is that allomorphs how up as distinct affixes and their counts in segmentations 
are not accumulated, which might lead to actual segmentations being missed due to 
fragmentation. The rules are not induced via a learning scheme: aligned pairs are 
compressed into a special data structure and traversals over this data structure gener- 
ate morphographemic rules. Theron and Cloete have experimented with pluralization 
in Afrikaans, and the resulting system has shown about 94% accuracy on unseen 
words. 
Goldsmith (1998) has used an unsupervised learning method based on the mini- 
mum description length principle to learn the "morphology" of a number of languages. 
What is learned is a set of root words and affixes, and common inflectional-pattern 
classes. The system requires just a corpus of words in a language. In the absence of 
any root word list to use as a scaffolding, the shortest forms that appear frequently 
are assumed to be roots, and observed surface forms are then either generated by the 
concatenative affixation of suffixes or by rewrite rules. 3 Since the system has no notion 
of what the roots and their part-of-speech values really are, and what morphological 
information is encoded by the affixes, this information eeds to be retrofitted manually 
by a human, who has to weed through a large number of noisy rules. We feel that this 
approach, while quite novel, can be used to build real-world morphological nalyzers 
only after substantial modifications are made. 
3. The BOAS Project 
Boas (Nirenburg 1998; Nirenburg and Raskin 1998) is a semiautomatic knowledge 
elicitation system that guides a team of two people (a language informant and a 
programmer) through the process of developing the static knowledge sources required 
to produce a moderate-quality, broad-coverage MT system from any "low-density" 
language into English. Boas contains knowledge about human language phenomena 
and various realizations of these phenomena in a number of specific languages, as 
well as extensive pedagogical support, making the system a kind of "linguist in a 
box," intended to help nonprofessional users with the task. In the spirit of the goal- 
driven, "demand-side" approach to computational pplications of language processing 
(Nirenburg and Raskin 1999), the process of acquiring this knowledge has been split 
into two steps: (i) acquiring the descriptive, declarative knowledge about a language 
and (ii) deriving operational knowledge (content for the processing engines) from this 
descriptive knowledge. 
An important goal that we strive to achieve regarding these descriptive and op- 
erational pieces of information, be they elicited from human informants or acquired 
via machine learning, is that they be transparent, human-readable, and, where neces- 
sary, human-maintainable and human-extendable, contrary to the opaque and unin- 
terpretable representations acquired by various statistical learning paradigms. 
Before proceeding any further, we would also like to make explicit the aims and 
limitations of our approach. Our main goal is to significantly expedite the develop- 
ment of a morphological nalyzer. It is clear that for inflectional languages where each 
3 Some of these rules may not make sense, but they are necessary to account for the data: for instance, a 
rule like insert a word f inal y after the root " eas " is used to generate easy. 
61 
Computational Linguistics Volume 27, Number 1 
root word can be associated with a finite number of word forms, one can, with a lot of 
work, generate a list of word forms with associated morphological features encoded, 
then use this as a lookup table to analyze word forms in input texts. Since this pro- 
cess is time consuming, expensive, and error-prone, it is something we would like to 
avoid. We prefer to capture general morphophonological and morphographemic phe- 
nomena using sample paradigms as the basis of lexical abstractions. This reduces the 
acquisition process to assigning citation forms to one of the established paradigms; 
the automatic generation process described below does the rest of the work. 4 This 
process is still imperfect, as we expect human informants to err in making their 
paradigm abstractions and to overlook details and exceptions. So, the whole pro- 
cess is an iterative one, with convergence to a wide-coverage analyzer coming slowly 
at the beginning (where morphological phenomena nd lexicon abstractions are be- 
ing defined and tested), but significantly speeding up once wholesale lexical acqui- 
sition starts. Since the generation of the operational content (data files to be used 
by the morphological analyzer engine) from the elicited descriptions i  expected to 
take only a few minutes, feedback on operational performance can be provided very 
quickly. 
Human languages have many diverse morphological phenomena nd it is not 
our intent at this point to have a universal architecture that can accommodate any 
and all phenomena. Rather, we propose an extensible approach that can accommo- 
date additional functionality in future incarnations of Boas. We also intend to limit 
morphological processing to single tokens and to deal with multitoken phenomena, 
such as partial or full word reduplications, with additional machinery that we do not 
discuss here. 
4. The Elicit-Build-Test Loop 
In this paper we concentrate on operational content in the context of building a mor- 
phological analyzer. To determine this content, we integrate the information provided 
by the informant with automatically derived information. The whole process is an 
iterative one, as illustrated in Figure 1: the elicited information is transformed into 
the operational data required by the generic morphological analyzer engine and the 
resulting analyzer is then tested on a test corpus, s'6 Any discrepancies between the 
output of the analyzer and the test corpus are then analyzed and potential sources 
of errors are given as feedback to the elicitation process. Currently, this feedback is 
limited to identifying problems in handling morphographemic processes (such as for 
instance the change of word-final -y to -i when the suffix -est is added). 
The box in Figure 1 labeled Morphological Analyzer Generation is the main com- 
ponent, which takes in the elicited information and generates a series of regular ex- 
pressions for describing the morphological lexicon and morphographemic rules. The 
morphographemic rules describing changes in spelling as a result of affixation opera- 
tions are induced from the examples provided by using transformation-based l arning 
(Brill 1995; Satta and Henderson 1997). The result is an ordered set of contextual re- 
place or rewrite rules, much like those used in phonology. 
4 We use the term citation form to refer to the word form that is used to look up a given inflected form 
in a dictionary. It may  be the root or stem form that affixation is applied to, or it may  have additional 
morphological markers to indicate its citation form status. 
5 We currently use XRCE finite-state tools as our target environment (Karttunen et al 1996). 
6 The test corpus is either elicited from the human informant or compiled from on-line resources for the 
language in question. 
62 
Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzers 
Corpus  1 
~ompilatiol~ 
Start 
I Human Elicitation 1~ 
Process 
I Description f Morphology 
(paradigms~ examples~ exceptions~ etc.) 
i Test I Err?rs, I Corpus Omissions 
Figure 1 
I Morphological Analyzer 1 
Generation 
\[ Content for Morphological Analyzer Engine \] 
(lexicons~ morphographemic rules) 
\[" Comparison ~ ~l 
~'| with Test Corpus \[ 
\[,(MA Engine, Test Engine)J "\[ 
The elicit-build-test paradigm for bootstrapping a morphological nalyzer. 
4.1 Morphological Analyzer Architecture 
We adopt the general approach advocated by Karttunen (1994) and build the morpho- 
logical analyzer as the combination of several finite-state transducers, ome of which 
are constructed irectly from the elicited information, and others of which are con- 
structed from the output of the machine learning stage. Since the combination of the 
transducers i computed at compile-time, there are no run-time overheads. The ba- 
sic architecture of the morphological analyzer is depicted in Figure 2. The analyzer 
consists of the union of transducers, each of which implements the morphological 
analysis process for one paradigm. Each transducer is the composition of a number of 
components. These components (from bottom to top) are described below: 
. 
. 
The bottom component is an ordered sequence of morphographemic 
rules that are learned via transformation-based l arning from the sample 
inflectional paradigms provided by the human informant. These rules are 
then composed into one finite-state transducer (Kaplan and Kay 1994). 
The citation form and affix lexicon contains the citation forms and the 
affixes. We currently assume that all affixation is concatenative and that 
the lexicon is described by a regular expression of the sort 
\[ Pref ixes  \]* \[ Citat ionForms \] \[ Suf f ixes \].7 
7 We currently assume that we have at most one prefix and at most one suffix, but this is not a 
fundamental limitation. The elicitation of morphotactics foran agglutinating language like Turkish or 
Finnish requires a significantly more sophisticated licitation machinery. 
63 
Computational Linguistics Volume 27, Number 1 
Lemma+Morphological Features (e.g., happy+Adj+Super) 
. - - - ~ ZZ-_Z,Z,Z-,--22-7.--7.2--ZZZZZZZZZ--Z'2~ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  7~2-=2=2-=2- :22: :2=:=:==-==:==:=:2=:=: :~- - .  
i J Feature Constraints Feature Constraints o ', 
I Surfacy-to-Feature 
Mapping 1 
O 
I Lexical & Surfacy Constraints I 
U 000 U 
O 
Surfacy-to-FeatureMapping ) 
,, 0 
? 1' Lexical & Surfacy Constraints 
O 
I Morpheme-to-Surf icy-Feature 1 r Morpheme-to-Surfacy-Feature 
Mapping J Mapping J 
O o 
nl 1 Citation Form and Affix Lexico itation Form and Affix Lexicon 
O O 
\[,I Morphographemic Rules lJ !\[ Morphographemic Rules 11 
Paradigm 1 Paradigm n 
" ' '4  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  I " *  
Surface Form (e.g., happiest) 
Figure 2 
General architecture of the morphological nalyzer. 
. 
. 
. 
The morpheme to surfacy feature mapping essentially maps 
morphemes to feature names but retains some encoding of the surface 
morpheme. Thus, al lomorphs that encode the same feature would be 
mapped to different surfacy features. 
The lexical and surfacy constraints pecify any conditions to constrain 
the possibly overgenerating morphotactics of the citation form and 
morpheme lexicons. These constraints can be encoded using the citation 
forms and the surfacy features generated by the previous mapping. The 
use of surfacy features also enables reference to zero morphemes, which 
otherwise could not be used. For instance, if in some paradigm a certain 
prefix does not co-occur with a certain suffix, or always occurs with 
some other suffix, or if a certain citation form in that paradigm has 
exceptional behavior with respect o one or more of the affixes, or if the 
affixal aUomorph that goes with a certain citation form depends on the 
properties of the citation form, these are encoded at this level as 
finite-state constraints. 
The surfacy feature to feature mapping module maps the surfacy 
representation f the affixes to symbolic feature names; as a result, no 
surface information remains except for the citation form. Thus, for 
instance, al lomorphs that encode the same feature and map to different 
surfacy features now map to the same feature symbol. 
64 
Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzers 
. The feature constraints specify constraints among the symbolic features. 
They are different means of constraining morphotactics than the one 
provided by lexical and surfacy constraints. At this level, one refers to 
and constrains symbolic morphosyntactic features as opposed to surfacy 
features. This may provide a more natural or convenient abstraction, 
especially for languages with long-distance morphotactic constraints. 
These six finite-state transducers are composed to yield a transducer for the paradigm. 
The union of the transducers for all paradigms produces one (possibly large) trans- 
ducer for morphological nalysis, where surface strings applied at the lower end pro- 
duce all possible analyses at the upper end. 
4.2 Information Elicited from Human Informants 
The Boas environment guides the language informant through a series of questions 
leading up to paradigm delineation. The informant indicates the parameters for which 
a given part of speech inflects (e.g., Case, Number), the relevant values for those pa- 
rameters (e.g., Nominative, Accusative; Singular, Plural), and the licit combinations 
of parameter values (e.g., Nominative Singular, Nominative Plural). The informant 
then posits any number of paradigms, whose members are expected to show sim- 
ilar patterns of inflection. It is assumed that all citation forms that belong to the 
same paradigm take essentially the same set of inflectional affixes (perhaps ubject 
to morphophonological v riations). It is expected that the citation forms and/or the 
affixes may undergo systematic or idiosyncratic morphographemic changes. It is also 
assumed that certain citation forms in a given paradigm may behave in some excep- 
tional way (for instance, contrary to all other citation forms, a given citation form 
may not have one of the inflected forms.) A paradigm description provides the full 
inflectional pattern for one characteristic or distinguished citation form and additional 
examples for any other citation forms whose inflectional forms undergo nonstandard 
morphographemic changes. If necessary, any lexical and feature constraints can be 
encoded. Currently the provisions we have for such constraints are limited to writing 
regular expressions (albeit at a much higher level than standard regular expressions); 
however, capturing such constraints using a more natural language (e.g., Ranta 1998) 
can be incorporated into future versions. 
4.3 Elicited Descriptive Data 
Figure 3 presents the encoding of the information elicited for one paradigm of a Polish 
morphological nalyzer, which will be covered in detail ater, s
The data elicited using the user interface component of Boas is converted into 
a description text file with various components delineated by SGML-like tags. The 
components in the description are as follows: 
? The <LANGUAGE-DESCRIPTION... >component lists information about he 
language and specifies its vowels and consonants, and other orthographic 
symbols that do not fall into those two groups. 
? A paradigm description starts with the tag <PARADIGM NAME=... >, which 
lists the name of the paradigm, its part-of-speech ategory, and any 
8 Our actual system works using unicode character representation. But unicode input and output are not 
yet supported in the XRCE xfst tool, hence we employ an ASCII external representation f r the unicode 
characters during off-line testing. Inthe following examples, however, we have opted to represent the 
actual characters a they should appear on screen. 
65 
Computational Linguistics Volume 27, Number 1 
<LANGUAGE-DESCRIPTION TYPE = "morphology" 
NAME = "Polish" 
ALPHABET = "a~bcdde~fghijklhnnfio6pqrs~tuvwxyz~z" 
VOWELS = "age@io6uy" 
CONSONANTS= "bcddfghjkl~mnfipqrs~tvwxz~z" 
OTHER = ""> 
<PARADIGM NAME="MasclnUStart"  POS = "Noun" FEATURES="Mascul ine"> 
<PRIMARY-EXAMPLE> 
<INF-GROUP> 
<PRIMARY-CIT-FORM FORM = "telefon"> 
<INF-FORM FORM = "telefon" FEATURE = "Nom. Sg."> 
<INF-FORM FORM = "tslefon" FEATURE ="Acc .  Sg."> 
<INF-FORM FORM = "telefonach" FEATURE = "Loc.Pl ."> 
<INF-FORM FORM = "telefonami" FEATURE = "Instr .P l ."> 
</ INF-GROUP> 
</PRIMARY-EXAMPLE > 
<EXAMPLE> 
<INF-GROUP> 
</INF-GROUP> 
</EXAMPLE> 
<LEXICON> 
</LEXICON> 
</PARADIGM> 
<CIT-FORM FORM = "akcent"> 
<INF-FORM FORM = "akcent" FEATURE = "Nom. Sg."> 
<INF-FORM FORM = "akcencie" FEATURE = "Loc.Sg."> 
<CIT-FORM FORM = "stron"> 
<CIT-FORM FORM = "klub"> 
<CIT-FORM FORM = "sklep"> 
</LANGUAGE-DESCRIPTION> 
Figure 3 
Sample paradigm description generated by Boas elicitation. 
additional morphosyntactic features that are common to all citation 
forms in this paradigm. In the example in Figure 3, the paradigm is for 
masculine nouns. Everything up to the </PARADIGM> tag is part of the 
descriptive data for the paradigm. This descriptive data consists of a 
primary example, a series of zero or more additional examples, and the 
lexicon. 
The primary example is given between the <PRIMARY-EXAMPLE> and 
</PRIMARY-EXAMPLE> tags. The description is given as a sequence of one 
or more inflection groups between <INF-GROUP> and </INF-GROUP> tags. 
In some instances, a given lexical item can use different citation forms in 
different inflectional forms. For example, one citation form might be 
used in the present tense and another in the past tense; or one might be 
66 
Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzers 
used with multisyllable affixes and another with single-syllable affixes. 
Thus, a given lexical item can have multiple citation forms, each of 
which gets associated with a mutually exclusive subset of inflectional 
forms. All the citation forms for a given lexical item, plus all its 
inflectional forms, are represented in an inflection group. If the 
association of citation forms with inflectional forms is predictable (as 
indicated by the language informant), the subsets of inflectional forms 
are processed separately; if not, we assume that all citation forms can be 
used in all inflectional forms and hence overgenerate. Manual constraints 
can later be added, if necessary, to constrain this overgeneration. 
Additional examples are provided between <EXAMPLE> and </EXAMPLE> 
tags. Examples contain ew citation forms plus any inflectional forms 
that are not predictable based on the primary example. Each example is 
considered an inflectional group and is enclosed within the 
corresponding tags. 
The citation forms given in the primary example and any additional 
examples are considered to be a part of the citation form lexicon of the 
paradigm definition. Any additional citation forms in this paradigm are 
listed between the <LEXICON> and </LEXICON> tags. 
5. Generating the Morphological Analyzer 
The morphological nalyzer is a finite-state transducer that is actually the union of 
the transducers for each paradigm definition in the description provided. Thus, the 
elicited data is processed one paradigm at a time. For each paradigm we proceed as 
follows: 
. 
. 
. 
The elicited primary citation form and associated inflected forms are 
processed to find the "best" segmentation f the forms into stem and 
affixes. 9Although we allow for inflectional forms to have both a prefix 
and a suffix (one of each), we expect only suffixation to be employed by 
the inflecting languages with which we are dealing (Sproat 1992). 
Once the affixes are determined, we segment the inflected forms for the 
primary example and any additional examples provided, and pair them 
with the corresponding surface forms. The segmented forms are now 
based on the citation form plus the affixes (not the stem). The reason is 
that we expect he morphological nalyzer to generate the citation form 
for further access to lexical databases to be used in the applications. The 
resulting segmented form-surface form pairs make up the example base 
of the paradigm. 
The citation forms given in the primary example, in additional examples, 
and explicitly in the lexicon definition of the elicited data, along with the 
mapping from suffix strings to the corresponding morphosyntactic 
features, are compiled (by our morphological nalyzer generating 
system) into suitable regular expressions (expressed using the regular 
9 The stern is considered to be that part of the citation form onto which affixes are attached, and in our 
context i has no function except for determining the affix strings. 
67 
Computational Linguistics Volume 27, Number 1 
. 
. 
expression language of the XRCE finite-state tools \[Karttunen tal. 
1996\]). l? 
The example base of the paradigm generated in step 2 is then used by a 
learning algorithm to generate a sequence of morphographemic rules 
(Kaplan and Kay 1994) that handle the morphographemic phenomena. 
The regular expressions for the lexicon in step 3 and the regular 
expressions for the morphographemic rules induced in step 4 are then 
compiled into finite-state transducers and combined by composition to 
generate the finite-state morphological nalyzer for the paradigm. 
The resulting finite-state transducers for each paradigm are then unioned to give 
the transducer for the complete set of paradigms. 
5.1 Determining Segmentation and Affixes 
The suffixes and prefixes in a paradigm are determined by segmenting the inflected 
forms provided for the primary example. This process is complicated by the fact that 
the citation form may not correspond to the stem--it may contain a morphological in- 
dication that it is the citation form. Furthermore, since the language informant provides 
only a small number of examples, tatistically motivated approaches like the one sug- 
gested by Theron and Cleoete (1997) are not applicable. We have experimented with a 
number of approaches and have found that the following approach works quite well. 
Using the notion of description length (Rissanen 1989), we try to find a stem and 
a set of affixes that account for all the inflected forms of the primary example. Let 
C = (cl, c2 . . . . .  ccl be the character string for the citation form in the primary example 
(ci are symbols in the alphabet of the language). Let Sk = (cl, c2 . . . . .  Ckl, 1 < k <_ c 
be a (string) prefix of C length k. We assume that the stem onto which morphological 
affixes are attached is Sk for some k. 11 The set of inflectional forms given in the primary 
J J ,fill (f//are alphabet example are {F1, F2,..., El}, with each Fj = ~f~,f~ . . . .  symbols in the 
of the language and lj is the length of the jth form). The function ed(v,w) (ed for 
edit distance), where v and w are strings, measures the minimum number of symbol 
insertions and deletions (but not substitutions) that can be applied to v to obtain w 
(Damerau 1964). 12 We define 
j=f 
d(Sk) = k + ~_~ ed(Sk, Fj) 
j=l  
as a measure of the information eeded to account for all the inflected forms. The first 
term above, k, is the length of the stem. The second term, the summation, measures 
how many symbols must be inserted and deleted to obtain the inflected form. The 
Sk with the minimum d(Sk) is then chosen as the stem S. Creating segmentations 
based on stem S proceeds as follows: To determine the affixes in each inflected form 
Fj = ~f~,f~ . . . . .  f/i/, we compute the projection of the stem Pj = ~f~ . . . .  ,f/el in Fj, as that 
10 Note that other finite state tools could also be used (e.g., Mohri, Pereira and Riley 1998; van Noord 
1999). 
11 The stem can also be an arbitrary substring of C, not just some initial prefix. Our approach can 
certainly extend to that. 
12 The function ed(...) assumes that vowels only align with other vowels or are elided, and consonants 
only align with consonants or are elided. 
68 
Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzers 
substring of Fj whose alignment with S provides the minimum edit distance, that is, 
P j = argmin ed ( S, ~f~ . . . . . .  /d,>) 
(f~ ..... ,fd,>,l<_b'<e'<lj 
Then we select he substring ~f~ . . . . .  f~-l> of Fj (if it exists) as the prefix and ... ,J~} q~+l" 
(if it exists) as the suffix. If there are multiple substrings of Fj that give the same 
(minimum) edit distance when aligned with S, we prefer the longer substring. We 
then create 
f~_l + C + 9<~+1 . . . . .  . . . . .  
as an aligned segmented form-surface form pair and add it to the example base that 
we will use in the learning stage. Note that we now use the citation form C, and not 
the stem S, as a part of the segmented form. 
Thus, at the end of the process we generate pairs of inflected forms and their 
corresponding segmented forms to be used in the derivation of the morphographemic 
rules. These pairs come from both the inflected forms given in the primary example 
and from any additional examples given. 
For example, suppose we have the following primary example: 
<PRIMARY-EXAMPLE> 
<INF-GROUP> 
<PRIMARY-C IT -FORM FORM = "strona"> 
<INF-FORM FORM = "strona" FEATURE = "Nom. Sg."> 
<INF-FORM FORM = "strong" FEATURE = "Acc. Sg."> 
<INF-FORM FORM = "strony" FEATURE = "Gen. Sg."> 
<INF-FORM FORM = "stronie" FEATURE = "Dat .Sg."> 
<INF-FORM FORM = "stronie" FEATURE ="Loc .  Sg."> 
<INF-FORM FORM = "strong" FEATURE =" Ins t r .  Sg."> 
<INF-FORM FORM = "strony" FEATURE = "Nom. P l . "> 
<INF-FORM FORM = "strony" FEATURE = "Acc .P I . "> 
<INF-FORM FORM = "stron" FEATURE = "Gen. P l . "> 
<INF-FORM FORM = "stronom" FEATURE = "Dat. P l . "> 
<INF-FORM FORM = "stronach" FEATURE = "Loc.P l . "> 
<INF-FORM FORM = "stronami"  FEATURE = " Inst r .P l . "> 
</ INF-GROUP> 
</PR IMARY-EXAMPLE> 
For this example, stems Sk: s, st, str, stro, stron, strona, are considered. Table 1 
tabulates d(Sk) considering all the unique inflected forms above. It can be seen that 
the value of d(Ss) is minimum for $5 = S = stron. We then determine suffixes based 
on this stem selection. The suffixes are given in this table under k = 5, where the stem 
S = stron perfectly aligns with the initial substring stron in each inflected form Fj, with 
0 edit distance. 
The segmented form-surface form pairs in Table 2 are then generated from the 
alignment of the stem with each surface form. 
5.2 Learning Segmentation and Morphographemic Rules 
The citation form and the affix information elicited and extracted by the process de- 
scribed above are used to construct regular expressions for the lexicon component 
69 
Computational Linguistics Volume 27, Number 1 
Table 1 
Stems Sk and the corresponding d(Sk). 
k=l  k=2 
Stems Considered, Sk 
k=3 k=4 k=5 k=6 
Form Fj s st str stro stron 
strona 5 4 3 2 1 
stron~ 5 4 3 2 1 
strony 5 4 3 2 1 
stronie 6 5 4 3 2 
stron G 5 4 3 2 1 
stron 4 3 2 1 0 
stronom 6 5 4 3 2 
stronach 7 6 5 4 3 
stronami 7 6 5 4 3 
Suffix 
-a 
-? 
-y 
-ie 
-om 
-ach 
-ami 
strona 
0 
2 
2 
3 
2 
1 
3 
2 
2 
d(Sk) 51 43 35 27 19 
Table 2 
The segmented and surface pair examples obtained. 
Segmented Surface 
strona+a strona 
strona+~ stron~ 
strona+y strony 
strona+ie stronie 
strona+ G stron G 
strona+ stron 
strona+om stronom 
strona+ach stronach 
strona+ami stronami 
of each paradigm. 13The example segmentations are fed into the learning module to 
induce morphographemic rules. 
5.2.1 Generat ing Candidate Rules f rom Examples. The preprocessing stage yields 
a list of pairs of segmented lexical forms and surface forms. The segmented forms 
contain the citation forms and affixes; the affix boundaries are marked by the + symbol. 
This list is then processed by a transformation-based l arning paradigm (Brill 1995; 
Satta and Henderson 1997), as illustrated in Figure 4. The basic idea is that we consider 
the list of segmented words as our input and find transformation rules (expressed as 
contextual rewrite rules) to incrementally transform this list into the list of surface 
forms. The transformation we choose at every iteration is the one that makes the list 
of segmented forms closest o the list of surface forms. 
The first step in the learning process is an initial alignment of pairs using a stan- 
dard dynamic programming scheme. The only constraints in the alignment are: (i) a + 
in the segmented lexical form is always aligned with an empty string on the surface 
side, notated by 0; (ii) a consonant on one side is always aligned with a consonant or 
0 on the other side, and likewise for vowels; (iii) the alignment must correspond to 
13 The result of this process i a script for the XRCE finite-state ool xfst. Large-scale l xicons can be more 
efficiently compiled by the XRCE tool lexc. We currently do not generate l xc scripts, but it is trivial to 
do so. 
70 
Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzers 
Segmented 
Forms 
I 
Figure 4 
l 
(incrementally) 
transformed 
segmented 
forms 
Learner 
Surface forms 
(Truth) 
Transformation-based learning of morphographemic rules. 
the minimum edit distance between the original lexical and surface forms. 14 From this 
point on, we will use a simple example from English to clarify our points. 
Assume that we have the pairs (un+happy+est, unhappiest)  and (shop+ed, 
shopped) in our example base. We align these and determine the total number of 
"errors" in the segmented forms that we have to fix to make all segmented forms 
match the corresponding surface forms. The initial alignment produces the aligned 
pairs: 
un + happy + est shopO+ ed 
un 0 happi 0 est shopp 0 ed 
with a total of five errors. From each segmented pair we generate rewrite rules of the 
sort is 
u -> i \[\] Le f tContext ,  RightContext ; 
where u(pper) is a symbol in the segmented form, l(ower) is a symbol in the surface 
form. Rules are generated only from those aligned symbol pairs that are different. 
Lef tContext  and RightContext are simple regular expressions describing contexts 
in the segmented side (up to some small length), also taking into account he word 
boundaries. For instance, from the first aligned-pair example, this procedure would 
generate rules such as the following (depending on the amount of left and right context 
allowed): 
y -> i 
y -> i 
y -> i 
+ -> 0 
+ -> 0 
+ -> 0 
+ -> 0 
p_  y->i  
p_+es  y -> i  
p_  + e s t # y -> i 
# U n 
e s t 
est# . .  
est# Ppy  - 
+ -> 0 
p_+e 
p_+est  
p p_+e 
#un _ hap  
14 We arbitrarily choose one if there are multiple legitimate alignments. 
15 We use the XRCE finite-state ools regular expression syntax (Karttunen et al 1996). For the sake of 
readability, we will ignore the escape symbol (%) that should precede any special characters (e.g., ?) 
used in these rules. 
71 
Computational Linguistics Volume 27, Number 1 
The # symbol denotes a word boundary and is intended to capture any word-initial 
and word-final phenomena. The segmentation rules (+ -> 0) require at least some 
minimal eft or right context (usually longer than the minimal context for other rules 
in order to produce more accurate segmentation decisions). We disallow contexts that 
consist only of a morpheme boundary, as such contexts are usually not informative. 
It should be noted that these rules transform a segmented form into a surface form 
(contrary to what may be expected for analysis). This lets us capture situations where 
multiple segmented forms map to the same surface form, which occurs when the 
language has morphological mbiguity. Thus, in a reverse lookup, a given surface 
form may be interpreted in multiple ways, if applicable. 
Since we have many examples of aligned pairs in our example base, it is likely that 
a given rule will be generated from many pairs. For instance, if the pairs (stop+ed, 
stopped) and (tr ip+ed, tr ipped) were also in the list, the gemination rule 0 -> p 
I I p - + e d (along with certain others) will also be generated from these examples. 
We count how many times a rule is generated and associate this number with the rule 
as its promise, meaning that it promises to fix this many "errors" if it is selected to 
apply to the current list of segmented forms. 
5.2.2 Genera l i z ing  Ru les .  The candidate rules generated by the processes described 
above refer to specific strings of symbols as left and right contexts. It is, however, 
possible to obtain more generalized rules by classifying the symbols in the alphabet 
into phonologically relevant groups, like vowels and consonants. The benefit of this 
approach is that the number of rules thus induced is typically smaller, and more 
unseen cases can be covered. 
For instance, in addition to a rule like 0 -> p I I p - + e,  the rules 
0 -> p 
0 -> p 
CONSONANTS _ 
p _ + VOWELS 
+ e 
0 -> p CONSONANTS _ + VOWELS 
can be generated, where symbols such as CONSONANTS and VOWELS stand for regu- 
lar expressions denoting the union of relevant symbols in the alphabet. The promise 
scores of the generalized rules are found by adding the promise scores of the origi- 
nal rules generating them. Generalization substantially increases the number of can- 
didate rules to be considered during each iteration, but this is not a very serious 
issue, as the number of examples per paradigm is expected to be quite small. The 
rules thus learned would be the most general set of rules that do not conflict with 
the evidence in the examples. It is possible to use a more refined set of classes that 
correspond to subclasses of vowels (e.g., high vowels) and consonants (e.g., frica- 
tives) but these will substantially increase the number of candidate rules at every 
iteration and will have an impact on the iteration time unless examples are chosen 
carefully. 
5.2.3 Selecting Rules. At each iteration, all the rules along with their promise scores 
are generated from the current state of the example pairs. The rules generated are then 
ranked based on their promise scores, with the top rule having the highest promise. 
Among rules with the same promise score, we rank more general rules higher, with 
generality being based on context subsumption (i.e., preference goes to rules using 
shorter contexts and/or referring to classes of symbols, like vowels or consonants). 
All segmentation rules go to the bottom of the list, though within this group, rules 
are still ranked based on decreasing promise and context generality. The reasoning 
72 
Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzers 
for treating the segmentation rules separately and later in the process is that affixa- 
tion boundaries constitute contexts for all morphographemic  changes; therefore they 
should not be eliminated if there are any (more) morphographemic  phenomena to 
process. 
Starting with the top-ranked rule, we test each rule on the segmented compo- 
nent of the pairs. A finite-state ngine emulates the replace rules to see how much 
the segmented forms are "fixed." The first rule that fixes as many "errors" as it 
promises to fix, and does not generate an interim example base with generation 
ambiguity, is selected. 16 The issue of generation ambiguity refers to cases where the 
same segmented forms are paired with distinct surface forms. 17 In such cases, find- 
ing a rule that fixes both pairs is not possible, so in choosing rules, we avoid any 
rules whose tentative application generates an interim example base with such am- 
biguities. In this way, we can account for all the discrepancies between the sur- 
face and segmented forms without falling into a local minima. Although we do not 
have formal proof that this simple heuristic avoids such local minima situations, in 
our experimentation with a large number  of cases we have never seen such an in- 
stance. 
The complete procedure for rule learning can now be given as follows: 
- Align surface and segmented forms in the example base; 
- Compute total Error; 
- while(Error > O) { 
-Generate all possible rewrite rules subject to context size limits; 
-Rank Rules ; 
-whi le  ( there  are more ru les  and a ru le  has not yet  been se lec ted)  { 
- Tentatively apply the next rule to all the segmented forms; 
- Re-align the resulting segmented forms with the 
corresponding surface forms to see how many 
''errors'' have been fixed; 
- If the number of errors fixed is equal to what the rule 
promised to fix AND the result does not have generation 
ambiguity, select this rule; 
} 
-Commit the changes performed by the rule on the segmented forms 
to the example base; 
-Reduce Error by the promise score of the selected rule; 
This procedure ventually generates an ordered sequence of two ordered groups 
of rewrite rules. The first group of rules is for any morphographemic  phenomena 
in the given set of examples, and the second group of rules handles segmentation. 
All these rules are composed in the order in which they are generated to construct 
the Morphographemic Rules transducer at the bottom of each parad igm (see Fig- 
ure 2). 
16 Note that a rule may actually introduce unintended errors in other pairs, since context checking is 
done only on the segmented form side; therefore what a rule delivers may be different than what it 
promises, as promise scores also depend on the surface side. 
17 Consider a state of the example base where some segmented lexical form L is paired with different 
surface forms $1 and $2, that is, we have pairs (L, $1) and (L, $2) in our example base. Any rule that 
will bring L closer to $1 will also change L of the second pair and potentially make it impossible to 
bring it closer to $2. 
73 
Computational Linguistics Volume 27, Number 1 
5.3 Identifying Errors and Providing Feedback 
Once the Morphographemic Rules transducers are compiled and composed with the 
lexicon transducer that is generated automatically from the elicited information, we 
obtain an analyzer for the paradigm. The analyzer for the paradigm can be tested by 
using the xfst environment of the XRCE finite-state tools. This environment provides 
machinery for testing the output of the analyzer by generating all forms involving 
a specific citation form, a specific morphosyntactic feature, or the like. This kind of 
testing has proved quite sufficient for our purposes. 
When the full analyzer is generated by unioning all the analyzers for each para- 
digm, one can do a more comprehensive t st against a test corpus to see what surface 
forms in the test corpus are not recognized by the generated analyzer. Apart from 
revealing obvious deficiencies in coverage (e.g., missing citation forms in the lexicon), 
such testing provides feedback about minor human errors--the failure to cover cer- 
tain morphographemic phenomena, or the incorrect assignment of citation forms to 
paradigms, for example. 
Our approach is as follows: we use the resulting morphological analyzer with an 
error-tolerant finite-state recognizer engine (Oflazer 1996). Using this engine, we try to 
find words recognized by the analyzer that are (very) close to a rejected (correct) word 
in the test corpus, essentially performing a reverse spelling correction. If the rejection 
is due to a small number of errors (1 or 2), the erroneous words recognized by the 
recognizer are aligned with the corresponding correct words from the test corpus. 
These aligned pairs can then be analyzed to see what the problems may be. 
5.4 Applicability to Infixing, Circumfixing, and Agglutinating Languages 
The machine learning procedure for inducing rewrite rules is not language dependent. 
It is applicable to any language whose lexical representation is a concatenation of
free and bound morphemes (or portions thereof). All this stage requires is a set of 
pairs of lexical and surface representations of the examples compiled for the example 
base. 
We have tested the rule learning component above on several other languages in- 
cluding Turkish, an agglutinating language, using an example base with lexical forms 
produced by a variant of the two-level morphology-based finite-state morphological 
analyzer described in Oflazer (1994). The lexical representation for Turkish also in- 
volved meta symbols (such as H for high vowels, D for dentals, etc.), which would 
be resolved with the appropriate surface symbol by the rules learned. For instance, 
vowel harmony rules would learn to resolve H as one of ~, i ,  u, ii in the appropriate 
context. 
Furthermore, the version of the rule learning (sub)system used for Turkish also 
made use of context-bound morphophonological distinctions that are not elicited in 
Boas, such as high vowels, low unrounded vowels, dentals, etc. The rules generated 
were the most general set of rules that did not conflict with the example base. There 
were many examples in the example base that involved multiple suffixes, not just 
one, as in the inflecting languages we address in this paper. It was quite satisfying 
to observe that the system could learn rules for dealing with vowel harmony, de- 
voicing, and so on. A caveat is that if there were too many examples and too many 
morphophonological classes, the number of candidate rules to be tried increased ex- 
ponentially. This could be alleviated to a certain extent by a careful selection of the 
example base. 
Thus, the rule-learning component is applicable to agglutinative, and also to in- 
fixing and circumfixing languages, provided there is a proper representation of the 
lexical and surface forms. However, for infixing languages it could be very problem- 
74 
Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzers 
atic to have a linear representation f the infixation, with the lexical root being split 
in two and the morphotactics picking up the first part, the infix, and the second part. 
To prevent overgeneration, the infix lexicon might have to be replicated for each root, 
to enforce the fact that the two parts of the stem go together. 18The case for circumfix- 
ation is simpler since the number of such morphemes i  assumed to be much smaller 
than the number of stems, so the circumfixing morphemes can be split up into two 
lexicons and treated as a prefix-suffix combination. The co-occurrence r strictions for 
the respective pairs can then be manually enforced with finite-state constraints that 
can be added to the lexical and surfacy constraints section of the analyzer (see Fig- 
ure 2). 
Thus, in all three cases, learning the rules is not a problem provided the example 
base is in the requisite linear representation. On the other hand, this approach as such 
is inapplicable to languages like Arabic, which have radically different word formation 
processes (for which a number of other finite-state approaches have been proposed; 
(see, for example, Beesley \[1996\] and Kiraz \[2000\]). 
On the other hand, in contrast o acquiring the rewrite rules, eliciting the mor- 
photactics and the affix lexicons for an agglutinating language (semi)automatically 
is a very different process and is yet to be addressed. There are three parts to this 
problem: 
. 
2. 
3. 
Determining the boundaries of free and bound morphemes, accounting 
for any morphographemic variations; 
Determining the order of morphemes; 
Determining the "semantics" of the morphemes, that is, the features they 
encode. 
These are complicated by a number of additional issues uch as zero morphemes, local 
and long-distance o-occurrence r strictions (e.g., for allomorph selection), exceptions, 
productive derivations, circular derivations, and morphemes with the same surface 
forms but a totally different morphotactic position and function. Also, in languages 
that have a phenomenon like vowel harmony, such as Turkish, even if all harmonic 
allomorphs of a certain suffix are somehow automatically grouped into a lexicon with- 
out any further abstraction, severe overgeneration would result, unless the all root and 
suffix lexicons were split or replicated along vowel lines. In such cases, a human in- 
formant (who possesses a certain familiarity with morphographemics and issues of 
overgeneration) may have to resort o manual abstraction of the morpheme represen- 
tations. Then the process of acquiring the features for inflectional and derivational 
morphemes could proceed. 
6. Bootstrapping a Polish Analyzer 
This section presents a quite extensive xample of bootstrapping a morphological n- 
alyzer for Polish by iteratively providing examples and testing the morphological n- 
alyzer systematically. The idea of this exercise was to have a relatively limited number 
of paradigms that bunched words showing slight inflectional variations. 19For reasons 
18 This is much like what one encounters when dealing with reduplication in the FS framework. Also 
note that his is a lexicon issue and not a rule issue. 
19 Nonexpert language informants u ing Boas will be encouraged to split, rather than bunch, paradigms, 
for the sake of simplicity. 
75 
Computational Linguistics Volume 27, Number 1 
of space, the exposition is limited to developing four paradigms, of which one will be 
covered in detail. The paradigms here cover only a subset of masculine norms, and 
do not treat feminine or neuter nouns at all; however, they cover all the problems that 
would be found in words of those genders. 
For purposes of testing the learner off-line (i.e., outside the Boas environment), we 
tried to keep to a minimum the number of inflected forms given for each additional 
citation form. This was a learner-oriented task and intended to determine how robust 
the learner could become with a minimum of input. When using the Boas interface, the 
language informant will not have the option of selectively providing inflected forms. 
The interface works as follows: the informant gives all forms of the primary example 
and lists other citation forms that he or she thinks belong to the given paradigm. Hav- 
ing learned rules from the primary example, the learner generates all the inflectional 
forms for each citation form provided. The informant hen corrects all mistakes and 
the learner elearns the rules. So, the informant never has the opportunity to say "Well, 
I know the learner can't predict the locative singular for this word, so I will supply 
it overtly from the outset." The informant will just have to wait for the learner to get 
the given forms wrong and then correct hem. Any other approach would make for 
a complex interface and would require a sophisticated language informant--not what 
we are expecting. 
Polish is a highly inflectional West Slavic language that is written using extended 
Latin characters (six consonants and three vowels have diacritics). Certain phonemes 
are written using combinations of letters: e.g., sz, cz, and szcz represent phonetic ~, 
G and ~,  respectively. R? Polish nominals inflect for seven cases: Nominative (Nom.), 
Accusative (Acc.), Genitive (Gen.), Dative (Dat.), Locative (Loc.), Instrumental (Instr.), 
and Vocative (Voc.); and two numbers: Singular (Sg.) and Plural (P1.). 21 The complex- 
ity of Polish declension derives from four sources: (i) certain stem-final consonants 
mutate during inflection; these are called "alternating" consonants, and are contrasted 
with so-called "nonalternating" consonants (alternating/nonalternating is a crucial 
diagnostic for paradigm delineation in Polish); (ii) certain letters are spelled differ- 
ently depending on whether they are word-final or word-internal (e.g., word-final 
-d is written -si when followed by a vocalic ending); (iii) final-syllable vowels are 
added/deleted in some (not entirely predictable) words; and (iv) declension is not 
entirely phonologically driven--semantics and idiosyncrasy affect inflectional end- 
ings. 
The following practical simplifications have been made for testing purposes: 
Words that are normally capitalized (like names) are not capitalized here. 
Some inflectional form(s) that might not be semantically valid (e.g., 
plurals for collectives) were disregarded. Thus a bit of overgeneration 
still remains but can be removed with some additional effort. 
6.1 Paradigm 1 
The process starts with the description of Paradigm 1, which describes alternating 
inanimate masculine nouns with genitive singular in -u and no vowel shifts. The 
20 We actually treat hese as single symbols during learning. Such symbols are indicated in the 
description file in a special section that we have omitted in Figure 3. 
21 The Vocative case was not included in these tests because it is not expected tooccur widely in the 
journalistic prose for which the system is being built. 
76 
Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzers 
following pr imary example for the 
Case 
Nom.  
Acc. 
Gen. 
Dat. 
Loc. 
Instr. 
citation form telefon is given in full: 
Number 
Singular Plural 
telefon telefony 
telefon telefony 
telefonu telefon6w 
telefonowi telefonom 
telefonie telefonach 
telefonem telefonami 
All inflectional forms in this paradigm are trivial except: 
? The Loc.Sg. depends on the final consonant and induces orthographic 
alternations for some alternating consonants: 22
Final Consonant(s) 
b, p, f, w, m, n, s, z 
t, d, st, zm 
Lr, st 
g, k, ch 
Loc.Sg. Ending 
-ie 
- ie 
-e 
-u 
Consonant Alternations 
t-,c, d--,dz, st--+gc, zm--*;~m 
f~l, r--*rz, sl--*gl 
? Instr.Sg. and Nom.P1. depend on the final consonant; two velars have an 
idiosyncratic ending: 
Final Consonant(s) 
b, p, f, w, m, n, s, z 
t, d, st zm, L r, st, ch 
g,k 
Instr.Sg. 
Ending 
-em 
- iem 
Nom.P1. 
Ending 
-y 
-i 
The following examples were provided in addition to the inflectional forms of the 
pr imary example in order to show Loc.Sg. endings and accompanying consonant al- 
ternations that could not be predicted based on the pr imary example: 
1. t~c: akcent (Nom.Sg.), akcencie (Loc.Sg.) 
2. d --* dz: wyktad (Nom.Sg.), wyktadzie (Loc.Sg.) 
3. st ---~dc: most (Nom.Sg.), modcie (Loc.Sg.) 
4. zm---~m: komunizm (Nom.Sg.), komuni~mie (Loc.Sg.) 
5. t-*l: artykut (Nom.Sg.), artykule (Loc.Sg.) 
6. r--*rz: teatr (Nom.Sg.), teatrze (Loc.Sg.) 
7. st~sl: pomyst (Nom.Sg.), pomydle (Loc.Sg.) 
The following additional examples were provided to show velar pecularities: 
8. g: pociqg (Nom.Sg.), pociqgu (Loc.Sg.), pociqgiem (Instr.Sg.), pociqgi (Nom.Pl.) 
22 Strictly speaking, the consonants b,p,f, w, m, n, s, and z alternate as well in the Loc.Sg., since 
alternating/nonalternating is a phonological distinction, ot a graphotactic one. The softening of these 
consonants i  indicated by the -i that precedes the canonical Loc.Sg. ending -e. However, for our 
purposes it is more straightforward toconsider the Loc.Sg. ending for these consonants -ie with no 
accompanying graphotactic alternation. 
77 
Computational Linguistics Volume 27, Number 1 
Table 3 
Summary of runs for Paradigm 1. 
Citation Additional Run 1 Additional Run 2 Additional Run 3 
Key Forms Examples Results Examples Results Examples Results 
0 telefon, stron, x/ 
paragraf, 
~piew, sklep, 
ttum, adres, 
obraz 
1 akcent, bilet Nom.Sg. mutates all Nom.P1. mutates Instr.Sg. x/ 
Loc.Sg. oblique forms lnstr.Sg. 
2 wyklad, sad Nom.Sg. mutates all Nom.P1. mutates Instr.Sg. x/ 
Loc.Sg. oblique forms Instr.Sg. 
3 most, list Nom.Sg. mutates all Nom.P1. mutates Instr.Sg. V' 
Loc.Sg. oblique forms Instr.Sg. 
4 komunizm, Nom.Sg. mutates all Nom.P1. mutates Instr.Sg. ~/ 
socjalizm Loc.Sg. oblique forms Instr.Sg. 
5 artykut, Nom.Sg. mutates all Nora.P1. mutates Instr.Sg. x/ 
kawat Loc.Sg. oblique forms Instr.Sg. 
6 teatr, numer Nom.Sg. mutates all Nom.P1. mutates Instr.Sg. x/ 
Loc.Sg. oblique forms Instr.Sg. 
7 pomysl, Nom.Sg. mutates all Nom.P1. mutates Instr.Sg. x/ 
zmyst Loc.Sg. oblique forms Instr.Sg. 
8 poci~g, brzeg Nom.Sg. x/ 
Loc.Sg. 
Instr.Sg. 
Nora.P1. 
9 bank, krok Nom.Sg. missed velar- Loc.Sg. of v / 
krok; 
Loc.Sg. specific Loc.Sg.; Add btysk to 
Instr.Sg. gave *krokie lexicon for 
Nom.P1. not kroku testing 
10 dach, wirch Nom.Sg. missed velar- Loc.Sg. of wrong add v / 
wirch; 
specific Loc.Sg.; Add ~miech Instr.Sg. Instr.Sg. 
gave *wirchie to lexicon for wirch, of 
not wirchu for testing ~miech wirch 
Loc.Sg. 
. 
10. 
k: bank (Nom.Sg.), banku (Loc.Sg.), bankiem (Instr.Sg.), banki (Nom.Pl.) 
ch: dach (Nom.Sg.), dachu (Loc.Sg.) 
Table 3 summarizes the first three runs for this paradigm, which were sufficient o 
create a relatively robust set of morphological rules that required only slight amend- 
ment and further testing in two additional runs. For this and subsequent such tables 
we use the following conventions: Key 0 shows the primary citation form and addi- 
tional citation forms whose inflectional patterns hould be fully covered by the rules 
generated for the primary example. The other key numbers correspond to the addi- 
tional examples given above. Boldface citation forms under the lexicon column are 
those for which some additional inflectional examples were given. The citation forms 
given in plain text are for testing purposes. Oblique cases refer to the Genitive, Dative, 
Locative, and Instrumental cases. 
The original assumption for Paradigm 1 was that it would be sufficient o pro- 
vide one unmutated form (the Nom.Sg.) plus the mutated form (the Loc.Sg.) for words 
ending in mutating consonants. This led to overgeneralization of the alternation; there- 
78 
Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzers 
fore, another unmutated form had to be added as a "control." Adding the Nom.P1. 
forms fixed most oblique forms for all the words, but it left the Instr.Sg. mutated. 
This appears to be because the inflectional ending for the Loc.Sg. (which mutates) and 
the Instr.Sg. (which does not) both begin in -e for the words in question. Adding the 
Instr.Sg. overtly counters overgeneralization of the alternation. The source of the velar 
errors is not immediately evident. 
Supplementary testing was carried out after the above-mentioned words were all 
correct. Correct forms were produced for all new words showing consonant mutations 
and velar peculiarities: amolot, przyklad, pretekst, podziaL kolor, dtug, lek, gmach. One error 
for a nonmutating word (in Key 0) occurred. This word, herb, ends in a different 
consonant than the primary example and produced the wrong Loc.Sg. form. This was 
later added overtly and more words with other nonmutating consonants (postcp, puf, 
gniew, film, opis, raz) were tested; all were covered correctly. 
6.2 Paradigm 2 
The paradigm implemented next was Paradigm 2: alternating inanimate masculine 
nouns with genitive singular in -u and vowel shifts. The following primary example 
for the citation form gr6b was given in full: 
Case 
Nom. 
Acc. 
Gen. 
Dat. 
Loc. 
Instr. 
Number 
Singular Plural 
gr6b groby 
gr6b groby 
grobu grob6w 
grobowi grobom 
grobie grobach 
grobem grobami 
This paradigm is just like Paradigm 1, except hat there are vowel shifts that are 
not entirely graphotactically predictable; therefore, words showing these shifts must be 
classed separately. The vowel shifts occur in all inflectional forms except he Nom.Sg. 
and the Acc.Sg., which are identical. The following vowel shifts occurred in the cases 
we considered (~b indicates vowel deletion). 
Vowel in Vowel in 
Nom.Sg./Acc.Sg. Other Forms 
6 o 
e 
ie ~b 
a e ~ 
This shift only occurs in Loc.Sg. 
The following consonant alternations are also observed in this paradigm: 
Consonant in 
Most Forms 
d 
dz 
t 
r 
Consonant in 
Loc.Sg. 
dz  
~dz 
1 
r z  
Based on the experience of Paradigm 1, the Instr.Sg. forms for all words with 
consonant alternation were provided as examples at the outset o avoid the overgen- 
eralization of the alternation. The velar pecularities are still in effect and must be dealt 
with explicitly. 
79 
Computational Linguistics Volume 27, Number 1 
The following examples were given to exemplify vowel shifts with an unmutating 
consonant: 
1. e --* q~ shift with n: sen(Nom.Sg.), snie (Loc.Sg.) 
The following examples were employed to show vowel shifts in combination with 
various consonant alternations in the Loc.Sg. forms: 
. 
. 
, 
5. 
6. 
d ~ o and d --* dz: samoch6d (Nom.Sg.), samochodzie (Loc.Sg.), samochodem 
(Instr.Sg.) 
a --~ e and zd ~ ~dz: dojazd (Nom.Sg.), doje~dzie (Loc.Sg.), dojazdem 
(Instr.Sg.) 
d --+ o and t --* h st6t (Nom.Sg.), stole (Loc.Sg.), stotem (Instr.Sg.) 
e -* ~ and r --~ rz: puder (Nom.Sg.), pudrze (Loc.Sg.), pudrem (Instr.Sg.) 
ie --~ ~ and r ~ rz: cukier (Nom.Sg.), cukrze (Loc.Sg.), cukrem (Instr.Sg.) 
Finally, the following examples were given to show velar peculiarities: 
. 
. 
e --, ~ with k: budynek (Nom.Sg.), budynku (Loc.Sg.), budynkiem (Instr.Sg.), 
budynki (Nom.P1.) 
d --* 0 with g: r6g (Nom.Sg.), rogu (Loc.Sg.), rogiem (Instr.Sg.), rogi 
(Nom.P1.) 
At the end of first run for this paradigm only one of the eight groups above 
was covered completely. All vowel shifts for all groups came out right. However, the 
Nom.P1. and Acc.P1. endings were incorrectly generalized as -i instead of -y, probably 
because two "exceptional" velar examples (in -i) were provided in contrast o one 
"regular" nonvelar example (in -y). Adding the Nom.P1. forms of three nonvelar words 
fixed this error. The results for velars were perfect except for the loss of z in 10 of 12 
forms of obowiqzek. Adding the Nom.P1. form obowi~zki f xed this. For st6t and d6t, the 
consonant alternation was incorrectly extended to Gen.Sg. Adding the Gen.Sg. form 
of st6t fixed this error for both words. At the end of the second run, all groups were 
correctly learned. 
Supplementary testing after the above-mentioned words were correct included the 
words naw6z, doch6d, poz6r, rozbi6r, gr6d, rozch6d, nar6d, wtorek, kierunek; all forms were 
correct. 
6.3 Parad igm 3 
Paradigm 3 contains alternating "man" nouns--that is, masculine nouns referring to 
human men. The following primary example for the citation form pasierb was given 
in full: 
Case 
Nom. 
acc. 
Gen. 
Dat. 
Loc. 
InstE 
Number 
Singular 
pasierb 
pasierba 
pasierba 
pasierbowi 
pasierbie 
pasierbem 
Plural 
pasierbowie 
pasierbi 
pasierb6w 
pasierb6w 
pasierbom 
pasierbach 
pasierbami 
80 
Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzers 
In this paradigm, all of the consonant alternations encountered above are still in 
effect and some word-final consonants undergo additional alternations in the Nom.P1. 
The velar peculiarities remain in effect. One additional complication i this paradigm 
is that there may be multiple Nom.P1. forms for a given citation form (e.g., pasierbowie 
and pasierbi are both acceptable Nora.P1. forms for pasierb). Furthermore, -i/-y are allo- 
morphs in complementary distribution (i.e., the second Nom.P1. form in this paradigm 
is realized with -y for certain word-final consonants). 
Stem-Final 
Consonant 
b, f, w, m, n, z, t 
p, ch 
d,t  
r,k,g 
Nom.P1. 
Ending 
-owie or -i or both 
-i only 
-owie only 
-owie or -y or both 
Since the analyzer needs only to analyze (and not generate) forms, there is no need 
to split this paradigm into five different ones to account for each Nom.P1. possibility: 
-owie,-owie/-i,-i, -owie/-y, -y. We simply permit overgeneration, allowing each word to 
have two Nom.P1. forms: the correct one of the -i/-y allomorphs and -owie. Further, 
since the analyzer has no way to predict which of the -i/-y allomorphs i used with a 
given word-final consonant, explicit examples of each word-final consonant must be 
provided. 
These considerations lead to splitting the citation forms for this paradigm into 
14 groups, which represent the primary example plus 13 inflectional groups added 
as supplementary examples. The Nom.Sg., Loc.Sg., and both (or applicable) Nom.P1. 
forms were provided for all groups apart from the primary example. After the first 
run, 13 of 14 groups were correctly covered. The remaining roup was handled cor- 
rectly in two additional runs: two more inflectional forms of the example in word-final 
r had to be provided to counter overgeneralization of the r --* rz alternation. 
Supplementary testing after the above-mentioned words were correct included 
the citation forms drab, piastun, kasztelan, faraon, w6jt, mnich, biedak, norweg, wtoch. The 
following errors were encountered: 
norweg got the Acc.Sg./Gen.Sg. form *norweda instead of norwega. 
Adding the correct Acc.Sg. form fixed this problem. 
wtoch got the Nom.P1. form *wtoci instead of wtosi. This form was added 
overtly. 
mnich got the Nom.P1. form *mnici instead of mnisi. This form was added 
overtly. 
After these final additions, wtoch and mnich ended up with the Acc.Sg./Gen.Sg. 
forms *wtosa and *mnisa instead of wtocha and mnicha (i.e., the alternation was overgen- 
eralized again). Overtly adding the correct Acc.Sg. form wtocha solved this problem 
for both words and all forms were now correct. 
6.4 Paradigm 4 
Paradigm 4 was for nonalternating inanimate masculine nouns with genitive singular 
in -a and no vowel shifts. The following declension for bicz was provided as the 
81 
Computational Linguistics Volume 27, Number 1 
primary example: 
Case 
Nom. 
Acc. 
Gen. 
Dat. 
Loc. 
Instr. 
Number 
Singular Plural 
bicz bicze 
bicz bicze 
bicza biczy 
biczowi biczom 
biczu biczach 
biczem biczami 
A spelling rule of Polish comes into play in this paradigm: letters that take a 
diacritic word-finally or when followed by a consonant are spelled with no diacritic 
plus an -i when followed by a vowel. For instance: ~+u --* niu, ~+owi --* niowi, d+u --* 
ciu, d+owi --+ ciowi. Some, but not all, word-final letters in this paradigm have diacritics. 
In addition, in this paradigm, Gen.Sg. endings depend on the final consonant: they 
can be -6w (for j, ch, szcz), -i (for L ~, ~) or -y (for cz, sz, rz, ~). In many instances, more 
than one form is possible, but this test covers only the most common form for each 
stem-final consonant. 
The citation forms in this paradigm broke down into 10 groups based on the final 
consonant. The Nom.Sg., Gen.Pl., and Instr.P1. forms were provided for the 9 groups 
(the tenth is the primary example, for which all forms were provided). Eight of the 
10 groups were handled correctly after the first run. The spelling-rule related to -i 
required some extra forms to be learned correctly. Otherwise, everything came out as 
predicted. Supplementary testing included the citation forms klawisz, b~bel, strumie~, 
tach, cyrkularz; all inflectional forms were produced correctly. 
7. Performance Issues 
Generating a morphological nalyzer once the descriptive data is given can be carried 
out very fast. Each paradigm can be processed within tens of seconds on a fast work- 
station, including the few tens of iterations of rule learning from the examples. A new 
version of the analyzer can be generated within minutes and tested rapidly on any test 
data. Thus, none of the processes described in this paper constitutes a bottleneck in the 
elicitation process. Figure 5 provides ome relevant information from the runs of the 
first paradigm in Polish described above. The top graph shows, for different runs, the 
number of distinct rules generated from the aligned segmented form--surface-form 
pairs generated from the examples provided, using a rule format with at most five 
symbols in each of the left and right contexts. The bottom graph shows, for differ- 
ent runs, the total number of rules generated and generalized--again, with the same 
context size as above. 
There are a few interesting things about these graphs. As expected, when more 
examples are added, the number of rules and the number of iterations needed for 
convergence usually increases. All curves have a steeper initial segment and a steeper 
final segment. The steep initial segments result from the initial selection of rules that 
fix the largest number of "errors" between the segmented and surface forms. Once 
those rules are found, the curves flatten as a number of morphographemic rules are 
selected, each dealing with a very small number of errors. Finally, when all the mor- 
phographemic changes are accounted for, the segmentation rules kick in and each such 
rule fixes a large number of segmentation "errors," so that a few general rules deal 
with all such cases. 
82 
Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzers 
Rules generated in each i te ra t ion  o f  the learner i n  sequent ia l  runs 
- - - ? - - -Run  1 
- - - I I - - -Run  2 
& Run 3 
1000 ? 
900  ? 
800  ? 
700  
600 
500 ? 
= 
-5 
400  ? 
300  ? 
200  
100 
0 
\ 
? \ 
? , L 
" ' ? ,  " I L  
" ? - - . ? ,  l i -  ~ ~ll- ~. iB.  i .  
~-- -e* - .~? . . ?  " i t -  ~ ~il-- ~ . i .  ~ . i -  
;'.-,, . 
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  23  
Learning i teration 
Rules general ized in each i te ra t ion  o f  the learner i n  sequent ia l  runs  
- - -e - - -Run  1 
- - -m- - -Run  2 
A Run 3 
20000,  
18000,  
16000,  
14000,  
~ 12000,  
m 
lO000,  
8000,  
6000,  
4000,  
2000,  
0 
~ #1-. - +an- :--+HI- --+l+.,.. - ~ _ . .  0 
~ -i-. ~ -il~,.~, L
" '~- - - t - .  ~-ap .  
" ' t - . .e .  ~'i l- ~ L 
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  21 22 23  
Learning Iteration 
Figure 5 
Rule statistics for processing Paradigm 1. 
8. Summary  and Conc lus ions  
We have presented the highlights of our approach for automatically generating finite- 
state morphological nalyzers from information elicited from human informants. Our 
approach uses transformation-based learning to induce morphographemic rules from 
examples and combines these rules with the lexicon information elicited to compile 
the morphological nalyzer. There are other opportunities for using machine learning 
in this process. For instance, one of the important issues in wholesale acquisition of 
83 
Computational Linguistics Volume 27, Number 1 
open-class items is that of determining which paradigm a given citation form belongs 
to. From the examples given during the acquisition phase, it is possible to induce a 
classifier that can perform this selection to aid the language informant. 
We believe that we have presented a viable approach to the automatic generation 
of a natural language processor. Since this approach involves a human informant 
working in an elicit-generate-test loop, the noise and opaqueness of other induction 
schemes can be avoided. 
We also feel that the task of analyzing a set of incorrectly generated forms and 
automatically offering a diagnosis of what may have gone wrong and what additional 
examples can be supplied as remedies is, in itself, an important aspect of this work. 
Although we have only scratched the surface of this topic here, we consider it a fruitful 
extension of the work described in this paper. 
Acknowledgments 
This research was supported in part by 
Contract MDA904-97-C-3976 from the U.S. 
Department of Defense. We also thank 
XRCE for providing the finite-state tools. 
Most of this work was done while the first 
author was visiting NMSU Computing 
Research Laboratory during the 1998-1999 
academic year, on leave from Bilkent 
University, Ankara, Turkey. 
References 
Antworth, Evan L. 1990. PC-KIMMO: A 
two-level processor for Morphological Analysis. 
Occasional Publications in Academic 
Computing, Number 16. Summer 
Institute of Linguistics, Dallas, TX. 
Beesley, Kenneth R. 1996. Arabic finite-state 
morphological nalysis and generation. In
Proceedings ofthe 16th International 
Conference on Computational Linguistics 
(COLING'96), pages 89-94, Copenhagen, 
Denmark. 
Brill, Eric. 1995. Transformation-based 
error-driven learning and natural 
language processing: A case study in 
part-of-speech tagging. Computational 
Linguistics, 21(4):543-566, December. 
Damerau, F. J. 1964. A technique for 
computer detection and correction of 
spelling errors. Communications of the 
Association for Computing Machinery, 
7(3):171-176. 
Golding, Andrew and Henry S. Thompson. 
1985. A morphology component for 
language programs. Linguistics, 
23:263-284. 
Goldsmith, John. 1998. Unsupervised 
learning of the morphology of a natural 
language. Unpublished manuscript, 
available at http:/ /humanit ies.  
uchicago, edu/f aculty/goldsmith/ 
index, html. 
Johnson, Mark. 1984. A discovery procedure 
for certain phonological rules. In 
Proceedings ofl Oth International Conference 
on Computational Linguistics (COLING'84), 
pages 344-347, Stanford, CA, USA. 
Kaplan, Ronald M. and Martin Kay. 1994. 
Regular models of phonological rule 
systems. Computational Linguistics, 
20(3):331-378, September. 
Karttunen, Lauri. 1993. Finite-state l xicon 
compiler. Technical Report, XEROX, Palo 
Alto Research Center, April. 
Karttunen, Lauri. 1994. Constructing lexical 
transducers. In Proceedings ofthe 15th 
International Conference on Computational 
Linguistics (COLING '94), volume 1, 
pages 406-411, Kyoto, Japan. 
Karttunen, Lauri and Kenneth R. Beesley. 
1992. Two-level rule compiler. Technical 
Report, XEROX Palo Alto Research 
Center. 
Karttunen, Lauri, Jean-Pierre Chanod, 
Gregory Grefenstette, and Anne Schiller. 
1996. Regular expressions for language 
engineering. Natural Language Engineering, 
2(4):305-328. 
Karttunen, Lauri, Ronald M. Kaplan, and 
Annie Zaenen. 1992. Two-level 
morphology with composition. In 
Proceedings ofthe 14th International 
Conference on Computational Linguistics, 
volume 1, pages 141-148, Nantes, France. 
Kiraz, George Anton. 2000. Multitiered 
nonlinear morphology using multitape 
finite automata: A case study on Syriac 
and Arabic. Computational Linguistics, 
26(1):77-105. 
Koskenniemi, Kimmo. 1983. Two-level 
morphology: A general computational 
model for word form recognition and 
production. Publication No. 11, 
Department of General Linguistics, 
University of Helsinki. 
Mohri, Mehryar, Fernando Pereira, and 
Michael Riley. 1998. A rational design for 
a weighted finite-state transducer library. 
84 
Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzers 
In Lecture Notes in Computer Science, 1436. 
Springer Verlag. 
Nirenburg, Sergei. 1998. Universal grammar 
and lexis for quick ramp-up of MT 
systems. In Proceedings ofthe First 
International Conference on Language 
Resources and Evaluation, pages 739-746, 
Spain. 
Nirenburg, Sergei and Victor Raskin. 1998. 
Project Boas: "A Linguist in a Box" as a 
multi-purpose language resource. In 
COLING-ACL "98: 36th Annual Meeting of 
the Association for Computational Linguistics 
and 17th International Conference on 
Computational Linguistics, pages 975-979, 
Montreal, Quebec Canada. 
Nirenburg, Sergei and Victor Raskin. 1999. 
Supply-side and demand-side l xical 
semantics. In Evelyne Viegas, editor, 
Depth and Breadth of Semantic Lexicons. Text, 
Speech, and Language Technology Series. 
Kluwer, Dordrecht and Boston. 
Oflazer, Kemal. 1994. Two-level description 
of Turkish morphology. Literary and 
Linguistic Computing, 9(2):137-148. 
Oflazer, Kemal. 1996. Error-tolerant 
finite-state recognition with applications 
to morphological nalysis and spelling 
correction. Computational Linguistics, 
22(1):73-90, March. 
Ranta, Aarne. 1998. A multilingual natural 
language interface to regular expressions. 
In Lauri Karttunen and Kemal Oflazer, 
editors, Proceedings ofthe International 
Workshop on Finite State Methods in Natural 
Language Processing, FSMNLP'98, 
pages 79-90. 
Rissanen, Jorma. 1989. Stochastic Complexity 
in Statistical Inquiry. World Scientific 
Publishing. 
Satta, Giorgio and John C. Henderson. 1997. 
String transformation learning. In 
Proceedings ofACL/EACL'97. 
Sproat, Richard. 1992. Morphology and 
Computation. M1T Press. 
Theron, Pieter and Ian Cloete. 1997. 
Automatic acquisition of two-level 
morphological rules. In Proceedings ofthe 
5th Conference on Applied Natural Language 
Processing. 
van Noord, Gertjan. 1999. FSA6: Finite state 
automata utilities (version 6) manual. 
Available at http://odur.let.rug.nl/van- 
noord/Fsa/Manual/. 
van Noord, Gertjan and Dale Gerdemann. 
1999. An extendible regular expression 
compiler for finite-state approaches in
natural anguage processing. In 
Proceedings ofWIA 99. 
85 

43
44
45
46
47
48
49
50
51
52
 
Sergei Nirenburg Marjorie McShane Stephen Beale  
 
Institute for Language Information Technologies 
University of Maryland, Baltimore County 
{sergei,marge,sbeale}@umbc.edu 
 
 
Abstract 
 
In this paper, we briefly and informally illus-
trate, using a few annotated examples, the 
static and dynamic knowledge resources of on-
tological semantics. We then present the main 
motivations and desiderata of our approach 
and then discuss issues related to making onto-
logical-semantic applications feasible through 
the judicious stepwise enhancement of static 
and dynamic knowledge sources while at all 
times maintaining a working system.  
 
1.  Introduction 
 
This paper discusses selected issues in ontological se-
mantics (OS), an implemented computational-semantic 
theory that deals with the extraction, representation and 
use of meaning in natural language texts. Unlike practi-
cally all other work in computational semantics, OS 
makes itself responsible for all the necessary compo-
nents and stages in automatic text meaning analysis: it 
addresses lexical and compositional meaning as well as 
pragmatics and discourse issues. Its processing heuris-
tics are derived from syntax, morphology and other 
?preprocessing,? non-semantic analysis stages that are 
still incorporated in the system, as well as from detailed 
underlying world models that include specifications not 
only of basic events, objects and properties but also of 
complex events, or scripts.  
The goal of OS is the extraction, representation and 
manipulation of meaning in natural language texts with 
a view toward supporting applications such as MT or 
question answering. Text meaning is represented in text 
meaning representations (TMRs) that are derived com-
positionally, primarily from meanings of words and 
phrases in the text. Word and phrase meaning is en-
coded in the ontological-semantic lexicon. The underly-
ing ontology is the main metalanguage of lexical mean-
ing specification.1 As a result, TMRs largely consist of 
                                                 
1 Some lexical elements carry grammatical, pragmatic or dis-
course-related meanings that are reflected in TMRs but not in 
terms of ontological concepts. 
instances of ontological concepts. Some of these in-
stances are remembered (as ?facts?) and stored in the 
fact repository, FR, a knowledge base of remembered 
ontological instances. Some facts in the fact repository 
are referred to by proper names in texts?personal 
names, toponyms, names of organizations, specific arti-
facts (?the statue of Liberty?), etc. These proper names 
are stored in the onomasticon, the semantic zones of 
whose entries contain a pointer to a corresponding FR 
element.2  
The following example illustrates our ontological-
semantic knowledge resources (for a more detailed de-
scription see Nirenburg and Raskin 2003, Chapters 6-
7). The example is much simpler than the sentences 
from real texts with which the ontological-semantic 
analyzer typically works and is used here for pedagogi-
cal reasons and to save space. Consider the input sen-
tence Alex Patrick makes tools. Morphological and syn-
tactic analysis of this input will yield the following 
structure (throughout this paper we use a presentation 
notation that is simplified for readability): 
 
root     make 
 cat   verb 
 tense  present 
 subject     
  root   ?Alex Patrick? 
  cat   noun-proper 
 direct-object   
  root      tool 
  cat   noun 
  number  plural 
 
The relevant zones of the ontological-semantic entry for 
the appropriate (first verbal) sense of make are as fol-
lows: 
 
make-v1 
syn-struc 
 root make 
                                                 
2 State-of-the-art techniques for recognizing named entities 
not in the onomasticon are incorporated in the analyzer; for 
example, lists of personal names from various languages are 
included in the lexicon. Note also the special reference resolu-
tion issues that maintenance of the FR raises.  
Operative Strategies in Ontological Semantics  
 cat  verb 
 subject  
             root $var1  
   cat   noun 
 direct-object  
        root $var2  
  cat   noun 
 sem-struc 
  CREATE-ARTIFACT 
   AGENT ^$var1 
   THEME ^$var2 
 
In the above entry, the variables are used for link-
ing; the caret means ?the meaning of?; CREATE-
ARTIFACT is an ontological concept (ontological con-
cepts are in SMALL-CAPS); AGENT and THEME are 
among its case roles and are used in this lexicon entry 
to specify selectional restrictions on this sense of make. 
As it happens, the selectional restrictions listed in the 
ontological definition of the concept CREATE-ARTIFACT 
are sufficient for this case of make, so that no further 
specialization or generalization of these restrictions in 
the lexicon is required. 
 
CREATE-ARTIFACT 
       ... 
 AGENT sem HUMAN 
 THEME sem ARTIFACT 
? 
 
In general, constraints in lexicon entries can modify and 
supplant those listed in the ontology; this is a means of 
controlling the proliferation of ontological concepts in 
the system. Lexicon entries for the appropriate senses 
of the other elements of the input sentence are as fol-
lows (we assume that the FR does not include an Alex 
Patrick, so that regular lexicon entries will have to be 
used): 
 
alex-n1 
 syn-struc 
  root alex 
  cat  noun-proper 
 sem-struc 
  HUMAN 
   FIRST-NAME value alex 
   GENDER sem male  
 
In the above, the filler of the property GENDER is intro-
duced through the sem facet since it is defeasible (the 
lexicon acquirer judged it plausible that there may be 
females called Alex). 
 
patrick-n2  ;this is the last name sense 
 syn-struc 
  root patrick 
  cat  noun-proper 
 sem-struc 
  HUMAN 
   LAST-NAME value patrick  
 
tool-n1 
 syn-struc 
  root tool 
  cat  noun 
 sem-struc 
   TOOL 
 
In the entry for tool-n1, the semantics is simply a uni-
vocal mapping to an ontological concept.  
On the basis of the knowledge from the ontology, 
the lexicon and syntactic analysis, the ontological-
semantic analyzer will produce the following semantic 
dependency that will serve as the basis of the TMR 
(numbers appended to ontological concept names mark 
them as instances of these concepts): 
 
CREATE-ARTIFACT-73 
 AGENT human-209 
 FIRST-NAME  alex 
 LAST-NAME  patrick  
      THEME set-46 
    element-type tool 
    cardinality  > 1 
 
1.1  Disambiguation 
 
A number of important representational and processing 
issues have been omitted in this presentation, notably, a 
discussion of disambiguation heuristics. The first-line 
mechanism of ambiguity resolution in OS is matching 
selectional restrictions. In our example, selectional re-
strictions on the theme of the proposition head matched 
successfully: indeed, tools are artifacts. As to the re-
strictions on the agent, they have been found to be too 
weak to resolve the ambiguity completely: both the last-
name and the first-name (not shown) sense of Patrick fit 
the selectional restrictions on the proposition head (in-
deed, Alex Patrick may be also be a double first name). 
Additional disambiguation means are required in this 
case.  
We have developed two general methods for addi-
tional sense disambiguation: dynamic tightening of se-
lectional restrictions (Mahesh et al, 1997) and deter-
mining weighted distances among ontological concepts 
activated in the input (using the Ontosearch procedure, 
e.g., Onyshkevych, 1997). None of these methods will, 
incidentally, help in our example, so that additional 
heuristic procedures will have to be built for this type of 
ambiguity. Incidentally, such heuristic procedures could 
include evidence from a wide variety of sources, in-
cluding text corpora. Supporting semantic analysis in 
this way should become an important direction of work 
in corpus-oriented computational linguistics (see further 
discussion below).  
Residual ambiguity is one of several possible initial 
outcomes of the analysis process. Figure 1 illustrates 
the entire set of possible outcomes of the analyzer op-
eration. Note that, in principle, the single-candidate 
outcome may prove to be less than ideal?it might sim-
ply reflect errors and omissions in static knowledge re-
sources. Still, at this time deriving a single output 
serves as the halting condition of the analysis process.  
 
 
 
Figure 1. Eventualities in semantic analysis. 
 
If Alex Patrick were the name of a company (cf. 
Merrill Lynch) and were not listed in the FR and there 
were no textual clues (e.g., Inc.) to recognize it as such, 
the system would fail to produce the correct analysis 
(that is, we would end up with zero candidate out-
comes). Currently, the only way to rectify this state of 
affairs is to (manually) add to the fact repository an in-
stance of CORPORATION with the name Alex Patrick and 
all its known property values. However, we are working 
on coercion rules that in the above example would fa-
vor the corporation reading if the event in question had 
the selectional restriction CORPORATION in the appro-
priate case role.  
 
1.2  Multivalued Selectional Restrictions 
 
Returning to our original example, if Alex Patrick is a 
corporation, then the selectional restrictions on CREATE-
ARTIFACT will be violated (a company is not a human). 
As a result, the corporation sense will always lose to the 
human sense because in the latter case selectional re-
strictions do match! We have, naturally, noted that or-
ganizations are often used in texts in positions that are 
?officially? occupied by people; indeed, this is one of 
the most widespread types of metonymy. We therefore 
decided to relax the selectional restrictions in such 
cases by introducing a relaxable-to facet for property 
fillers, in addition to the rigid value and abductively 
overridable sem facets. This amounted to the introduc-
tion of multivalued selectional restrictions. Matches on 
fillers of sem facets are preferred but matches on fillers 
of relaxable-to facets are not discarded as wrong. If, as 
in our example, ambiguity results, additional means of 
its resolution are used.  
 Multivalued selectional restrictions are also used to 
treat metonymy: e.g., the THEME of PLAY-MUSICAL-
INSTRUMENT is constrained to MUSIC-PIECE but the 
standard metonymy of composer name will be also 
noted in the same lexicon entry, together with its ex-
pansion to MUSIC-PIECE with the property AUTHORED-
BY filled by the metonym. 
 Processing unexpected input (including lexically 
unaccounted for metonymies) can be done dynamically 
using Ontosearch. To treat metonymies, Ontosearch 
calculates whether the ontological distance between the 
metonym and the selectional restriction that it must 
match is below a preset threshold (in which case dy-
namic relaxation is allowed and the case is declared 
true metonymy). 
 
1.3  More Expressive Means in OS 
  
The Alex Patrick example illustrated some of the issues 
involved in building a basic semantic dependency. On-
tological semantics, however, goes beyond that limit 
and into what is traditionally covered in pragmatics and 
discourse ? on the assumption that, since these types of 
meanings are expressed in language they ought to be 
represented and manipulated. The following example 
illustrates both the treatment of additional types of 
meaning and additional expressive means in OS.  
The English verb prevent has two senses in the on-
tological-semantic lexicon. The first sense is used, for 
example, in The union organizer prevented a strike. 
The basic meaning of prevent-v1 can be roughly 
glossed as ?the union organizer carried out an unnamed 
action or actions as a result of which a strike that was 
looming did not materialize.?  
In the sem-struc zone of prevent-v1, the meaning of 
the syntactic subject (^$var1) has selectional restric-
tions on two facets (sem and relaxable-to). The precon-
dition for the preventive event is the potential of the 
thing that is being prevented. The effect is that the thing 
that was prevented did not materialize. This is encoded 
using value ranges of certain modalities of the event. 
Modalities in OS are means of expressing speaker atti-
tudes toward various elements of meaning (or even en-
tire TMRs). Potential modality reflects the probability 
of a certain event or state of affairs taking place; epis-
temic modality measures the degree of factivity of the 
elements in its scope. Modalities are attributed to spe-
cific sources and take their values from abstract value 
ranges between 0 and 1. Epistemic modality 0 means 
that the event did not take place.3  
                                                 
3 Ontological semantics recognizes modalities other than epis-
temic and potential. The inventory of modalities continues to 
grow and develop ? witness the differences between the ac-
counts in Nirenburg and Raskin 2003, Section 8.5.3. and in 
Nirenburg et al (in preparation).  
 
prevent-v1 
    syn-struc 
 root  $var0 
    cat  verb 
    subject  
        root  $var1 
        cat  noun 
  direct-object 
  root  $var2 
  cat  noun  
    sem-struc 
       EVENT 
     AGENT       ^$var1  
   sem           HUMAN 
   relaxable-to  ORGANIZATION 
     
 PRECONDITION    ^$var2 
            sem EVENT 
             modality potential  > .5 
          epistemic < 1 
      
 EFFECT      ^$var2 
    sem EVENT 
            modality epistemic 0   
 
The second sense of prevent is the one used, for exam-
ple, in Negotiations prevented a strike. Here the mean-
ing is expressed as a CHANGE-EVENT: the event that is 
the meaning of the subject (^$var1) caused this change 
event; there was a potential for ^$var2 to take place; as 
a result of this change, ^$var2 has not taken place (its 
epistemic modality is 0). There is no need for overt 
specification of time dependencies, as causality deter-
mines temporal ordering. (Note that the syntactic ana-
lyzer currently used in OS recognizes certain ?ing 
forms, e.g., striking, as nouns.) 
 
prevent-v2 
    syn-struc 
 root  $var0 
    cat  verb 
    subject  
        root  $var1 
        cat  noun 
  direct-object 
  root  $var2 
  cat  noun 
    sem-struc 
        CHANGE-EVENT 
    PRECONDITION    ^$var2 
           sem     EVENT 
                   modality  potential  > .5 
              epistemic < 1 
      
    EFFECT        ^$var2 
    sem      EVENT 
                   modality  epistemic 0   
 
                 CAUSED-BY        
                   ^$var1 
      sem   EVENT 
 
 The above entries are simplified. For instance, we 
did not show the treatment of generic, timeless state-
ments like Being well prepared prevents unpleasant 
surprises, whose meaning specification does not in-
volve creating a specific instance of either of the two 
events but rather a so-called generic ontological in-
stance representing any element of the class (e.g., tigers 
in tigers are ferocious). A special heuristic rule will be 
used in this case to determine whether generic ontologi-
cal instances are appropriate. One clue that casts a vote 
for the generic reading is the present simple form of the 
verb, which is often associated with timelessness. An-
other is the indefiniteness of the direct object. However, 
these clues do not always guarantee that the statement 
is indeed generalized. One way to ascertain this fact is 
to call a special procedure to check whether ^$var2 co-
refers with a specific concept instance either in the 
TMR or in the fact repository.  
 Procedures such as the above are called meaning 
procedures. For example, the meaning of intensifiers 
(e.g., very) is best expressed in terms of a meaning pro-
cedure ? take the meaning of the adjective modified by 
very; it will be expressed as a range on some scale, e.g., 
the meaning of dim will be the range (<> 0.1 0.4) on 
the scale of BRIGHTNESS.  Relative values of such prop-
erties are expressed as ranges on abstract scales be-
tween 0 and 1. The expected absolute boundaries for 
such properties will be defined in the corresponding on-
tological concepts. Thus, while the HEIGHT property of 
HUMAN-ADULT may be marked as the range between 
145 and 200 cm (these values are, in fact, overridable), 
the corresponding values for PROFESSIONAL-
BASKETBALL-PLAYER may be between 180 and 230 cm. 
Values on relative scales can, thus, be resolved to 
ranges on absolute scales. The meaning of very roughly 
amounts to narrowing the range toward its extreme. 
 The presence of meaning procedures demonstrates 
that OS combines declarative and procedural semantics:  
on the one hand, knowledge in OS is separated from the 
processing engines; on the other hand, meaning is cal-
culated dynamically.  
 
2.  Some Distinguishing Features of OS 
 
The above, we hope, has presented an informative 
glimpse into the representational, descriptive and proc-
essing concerns of OS. Space restrictions prevent us 
from describing the many remaining elements of and 
decisions taken in OS. At this point, we?ll attempt to 
summarize important preferences and tenets of our ?op-
erational philosophy? that distinguish our work from 
other work and generally characterize OS.  
 The overall emphasis in the development of OS is 
given to: 
 
? maintaining and improving a comprehensive mean-
ing extraction and representation system; 
? gradual enhancement of both the breadth and the 
depth of description (which stand in a trade-off re-
lation relative to a given amount of resources) 
through a large-scale descriptive effort; 
? formulation of heuristics for extracting intended 
meanings and supporting task-oriented processing; 
? attaining adequate descriptive coverage of the mass 
of ?uninteresting? linguistic phenomena that ac-
count for a huge majority of occurrences in texts. 
 
Relatively lower (though not zero) priorities are ac-
corded to the study of: 
 
? capabilities of the representation medium; 
? computational complexity of the processes; 
? consistency of the knowledge base; 
? individual ?interesting? linguistic cases that are dif-
ficult for people to describe and judge (e.g., com-
plex issues in quantification). 
 
Ontological semantics is a comprehensive approach that 
does not relinquish responsibility for attaining its goal 
to other areas of study or rely on prerequisites that are 
either beyond the reach of the current state of the art or 
are expected as a result of large amounts of research by 
others. It is for this reason that OS includes in its pur-
view all the preprocessing stages in text analysis: to-
kenization, morphology and syntax. Moreover, its pur-
view is broader than that of traditional formal or lexical 
semantics: for example, it does not see a need to sepa-
rate pragmatics and discourse into separate disciplines 
(allowing, for example, formal semanticists to bypass 
many kinds of meaning description on account of their 
being outside the purview of their theories).  
 Ontological semantics seeks to incorporate all the 
relevant topics often studied in relative isolation. These 
topics include language- and knowledge-related issues 
such as aspect, modality, time, causality, quantification, 
text-level relations, non-literal meaning, style, deduc-
tive and abductive presuppositions and entailments, 
nominal compounds, prepositional phrase attachment, 
the meaning of adjectives that do not semantically mod-
ify their syntactic governors, etc. They also include ar-
chitecture and control issues connected with optimizing 
the search for the best semantic analysis in the poten-
tially very large candidate space. We strive to develop 
our own accounts (we call them ?microtheories?) for 
each such topic exploiting the research findings of oth-
ers and modifying and expanding them in accordance 
with the practical goals and needs of OS. Unfortunately, 
no feasible solutions have been proposed in the litera-
ture for most microtheories that we need: much of the 
reported work is devoted to rather narrow topics (for 
example, meanings of single words at a grain size be-
yond the capabilities ? and often the needs ? of the ana-
lyzer) and still other proposals invent very complex 
formal notations without any emphasis on heuristics for 
the assignment of values to language phenomena. (In-
deed, one of the knowledge acquisition rules of thumb 
in OS is not to include in the descriptions everything 
that can be said, only those parts that are actually use-
ful.) 
The purpose of all the microtheories is to help de-
rive text meaning. Some microtheories are driven by 
the needs of the meaning representation (its content, not 
format). For example, all TMRs must at least attempt to 
resolve the deictic indices (speaker, hearer, place, time) 
and, more broadly, all references. Other microtheories 
are forward-chaining ? they are triggered not by the 
needs of the output but by the occurrences of certain 
lexical and syntactic configurations in the input ? for 
example, nominal compounds. Developing microtheo-
ries means acquiring heuristic rules for the treatment of 
specific phenomena. In OS, the strategy is to use any 
and all potentially useful kinds of knowledge in the left-
hand sides of such rules. Some of this knowledge is en-
coded in the static knowledge sources of the system. 
Other sources of heuristics include syntactic or morpho-
logical information in the input and general properties 
of the input document right down to its formatting 
properties. Finally, the heuristic rules can use evidence 
from various co-occurrence measures for subsets of in-
put in a corpus. We believe that supporting heuristic 
processing in a computational-semantic system is one 
of the more useful applications of corpus linguistics.  
 
3.  Balancing Desiderata and Practical Con-
straints 
 
Ontological-semantic descriptive work is guided by the 
desiderata of breadth and depth of coverage. Constrain-
ing these, however, are the twin limitations of human 
resource availability and the computability of knowl-
edge. In this section we present a number of resource 
acquisition choices, each of which is driven by practical 
needs and represents a whole class of phenomena 
whose continued development occupies the day-to-day 
work in OS. We fully understand that it is inappropriate 
to talk about a particular ontology or even a particular 
lexicon as ?the correct one.? While some constraints on 
ontology construction may be considered universal, 
there are many other equally acceptable choices in 
specifying the world model to be used both as the meta-
language for text meaning description and as a major 
source for knowledge to support reasoning. 
 Grain size of static knowledge specification. High 
precision in semantic description always incurs in-
creased acquisition time and often increased processing 
challenges as well. For this reason, OS explicitly pre-
fers well selected simplifications, defined as those not 
expected to noticeably impoverish the usefulness of the 
resulting TMR. For example, about in the meaning 
travel about Europe is mapped to the spatial relation 
INSIDE-OF rather than a) forcing the inclusion of a new 
concept with precisely this meaning or b) adding to the 
lexicon entry complex inferences or effects ? e.g., see-
ing numerous different places. Similarly, the meaning 
along as in trees grew along the road is mapped to BE-
SIDE, despite the loss of the precondition that the trees 
cover some unspecified stretch of the road interpreted 
by the speaker as significant. 
 Such conscious simplifications ? which, we must 
emphasize, are always open to finer representation 
given the needs of an application and the resulting deci-
sion to thus deploy resources ? apply to all aspects of 
knowledge acquisition. For example, due to the quag-
mire of semantic and pragmatic issues involved in in-
terpreting conjunctions like and and but when they 
serve to  link clauses, we level their semantics, creating 
a separate TMR for each clause linked by the functional 
binder ?conjoined?. Contrast this with our treatment of 
since, because, so that, etc., which are less ambiguous, 
more important for reasoning, and are thus rendered by 
the concepts CAUSED-BY, EFFECT, and ENABLEMENT, as 
applicable.  
 Another example of methodical simplification con-
cerns the expression of time. Temporal properties of 
TMR elements are expressed using a very ?lean? set of 
parameters: the ontological relations BEFORE (<) and 
LONG-BEFORE (<<) and their inverses AFTER (>) and 
LONG-AFTER (>>), the concepts START-TIME, END-TIME, 
SPEAKER-TIME, DURATION, and time measurement units. 
We also define two meaning procedures ? find-anchor-
time and combine-time. find-anchor-time attempts to 
determine the deictic index, or anchor, relative to which 
other times are defined in the text. It uses a variety of 
heuristics, including times of events mentioned in the 
text as well as the dateline of the text, if available. find-
anchor-time may fail to determine the anchor, in which 
case, at present, the time statements in TMRs are made 
relative to an unknown time of speech, t0. combine-time 
takes as input an anchor time and an expression denot-
ing a time period, one of whose ends is the anchor, and 
returns the (actual or relative) time of the combination.  
 As an illustration, below are abbreviated meaning 
representations of some time-related word and phrase 
senses:  
 
after-p4 (as in ?ten hours after the operation?) 
  time (combine-time ^$var2.time ^$var3 after) 
 
for-p5 (as in ?dribbling for thirty seconds?)  
  time (duration $var2 (sem TEMPORAL-UNIT)) 
 
for-p6 (as in ?for the time being?)   
  time (find-anchor-time) 
 
Always open to reconsideration, these and other such 
decisions in favor of a coarse grain size, at a minimum, 
help to drive forward the work of supporting our broad-
coverage text processing system.  
 Economy of expressive means. One tenet of OS is to 
avoid a proliferation of ontological concepts, in line 
with the recommendation by Hayes (1979) that the ratio 
of knowledge elements used to describe a set of ele-
ments of the world to the number of these latter ele-
ments must be kept as low as possible. The factors in-
volved in deciding when and when not to introduce a 
new concept constitute something of a cognitive art too 
subtle to capture in a thumbnail sketch of a short article; 
however, a contrastive example might provide some 
insight. 
 Consider spatial after, as in the first house after the 
stop sign. Previous examples showed cases in which an 
ontologically available spatial relation was deemed 
close enough to describe given lexical entities. In this 
case, though, there is no such relation: NEXT-TO, the 
best candidate, is inappropriate since the house could be 
miles after the stop sign. One option would be to de-
scribe the semantics as a script: the first house one sees 
after passing the stop sign during a motion event ? but 
this was judged too complex. Instead, we went ahead 
and added a new spatial relation, AFTER-SPATIAL, to ac-
commodate this and synonymous lexical items from all 
the languages that express such a relation (we must em-
phasize that the ontology is language independent). One 
reason we did not expend the effort to more fully de-
scribe the semantics of after is that we have not yet de-
veloped a sophisticated microtheory of spatial relations. 
Therefore, we are not currently poised to make complex 
inferences about spatial relations in texts. However, 
when we do ultimately embark upon a microtheory of 
spatial relations ? either stimulated by the demands of 
an application or through the natural overall progres-
sion of ontological-semantic research ? we may recon-
sider whether a descriptive rather than an ontological 
representation of after would be most beneficial.  
 The opposite decision was taken in the case of 
about and its synonyms when they convey approxima-
tion. Approximation is too important for reasoning for 
us to make an ontological concept and consider all ap-
proximated entities thus resolved. Instead, we need 
meaning procedures to fix ranges on scales. Preliminary 
analysis suggested that a 7% expansion either way 
around a magnitude works reasonably well in most 
cases: e.g., about 5 gallons is 4.65 to 5.35 gallons; 
about 150 lbs. is 139.5 to 160.5 pounds. However the 
7% rule produces bad results in some instances: e.g., 
resolving about 6 feet tall to 5?7??-6?5?? is bad. What 
we need, instead, is 7% of the amount by which peo-
ple?s heights can vary, which is about 2 feet. The 7% 
rule applied to 2 feet yields 5?10.5?? to 6?1.5?? ? a much 
better reflection of reality. Another failure of the 
straightforward 7% rule involves clock time. For prag-
matic reasons, saying around 10  or around 5:30 im-
plies 10 minutes in either direction, whereas around 
5:15 permits a smaller range and around 7:07 a smaller 
range still. This example of clock time ? work on which 
is still under way ? shows that some issues considered 
to be of crucial import to TMRs and the reasoning they 
support are immediate priorities in OS despite the over-
head of research and implementation they impose.  
 Including results of abductive reasoning in TMRs. 
To offset any impression that the current state of devel-
opment of OS always opts for shallower analysis, we 
offer an example relating to our evolving treatment of 
verbs that that have a relatively general meaning despite 
the fact that, in a given context, speakers understand 
them to carry more meaning.  
 Consider once again, for example, make in the sense 
of create an artifact (i.e., a man-made physical object). 
This sense of make, which is only one of many, can 
contextually imply different specific types of events 
including but not limited to baking (make a cake), 
sculpting (make a sculpture), recording (make a CD), 
filming (make a film) and knitting (make a sweater). 
The verbal sense of make that covers all of these exam-
ples says that make is a CREATE-ARTIFACT event whose 
subject is HUMAN and whose object is an ARTIFACT.  
 Representing this meaning of make as CREATE-
ARTIFACT captures all the meaning that is explicitly 
conveyed by this lexical item. In that sense, our analy-
sis should be considered complete. However, we as us-
ers of language know much more precisely what activ-
ity is actually carried out in making a cake: by default, 
it?s baking. When we set about to reflect this knowl-
edge in the ontological-semantic knowledge resources, 
we list CAKE as a default THEME of BAKE. Whereas in-
heritance in the ontology allows the match of CAKE 
with CREATE-ARTIFACT, a more exact, constrained 
match obtains between CAKE and BAKE.  (Note that 
CAKE matches CREATE-ARTIFACT because the THEME of 
CREATE-ARTIFACT includes a union of the fillers of 
THEME of all its descendants, which include, among 
many others, BUILD, PREPARE-FOOD, MAKE-LAW, AU-
THOR-EVENT, FILM-EVENT, RECORD-SOUND, RECORD-
TEXT, CREATE-FABRIC-MATERIAL-ARTIFACT, etc., as 
well as their descendants.) 
An important question at this point is whether we 
should act upon the extra knowledge that cakes are usu-
ally baked or simply allow the correct, though more 
vague direct TMR of the input text to stand. The answer 
depends on the circumstances of an application. For ex-
ample, in machine translation, all other things being 
equal, if the direct TMR can be used as the input to 
successful target text generation, there is no need for 
any specialization procedure. There are, however, many 
cases in which such a procedure would improve the 
performance of various analysis tasks. For example, 
such a procedure helps to resolve certain ambiguities, 
e.g., by preferring the oven to the stove sense of range 
in John prepared the cake using the range?see a de-
tailed description in Mahesh et al, 1997.  It also helps 
in the selection and resolution of referring expressions. 
For example, in John made a good cake though the 
oven was not hot enough, the definite referring expres-
sion the oven is legitimately used for a discourse-initial 
reference?and, therefore, no co-reference resolution 
procedure should be called?because the ontology lists 
OVEN as the default instrument of BAKE. This type of 
inference is ultimately made possible by the availability 
of ontological scripts. 
In principle, if we decide to carry out proactive ab-
ductive meaning specialization whenever we come 
across constructions whose verbs have rather general 
meanings (note, incidentally, that many such verbs have 
meanings that are even vaguer and less specific than 
that of make?consider, for example, such verbs as use, 
do, have or get), we can call the meaning procedure 
seek-specification in each such case. However, the ana-
lyzer currently triggers specialization exclusively on an 
as-needed basis, not proactively because proactive evo-
cation of seek-specification will result in conclusions 
that might never be used.  
 Ontological semantics defines many types of mean-
ing procedures, and their application results in both 
more precise and more fine-grain specification of text 
meaning. In fact, when all meaning procedures are ap-
plied, the resulting TMR will contain information that 
was both overtly present in the original text and infor-
mation abductively inferred form the background 
knowledge of the system. We call the former type of 
TMR basic and the latter, extended.  
 
4.  Summary, Status and Future Work 
 
In this paper, we first briefly and informally illustrated, 
using a few annotated examples, the static and dynamic 
knowledge resources of OS. We then presented the 
main motivations and desiderata of our approach and 
discussed issues relating to how to make ontological-
semantic applications feasible through judicious step-
wise enhancement of static and dynamic knowledge 
sources while at all times maintaining a working sys-
tem.  
 The latest implementation of OS uses an ontology 
of about 6,500 concepts each of which is a named col-
lection of property-value pairs (on average, every con-
cept in the current ontology has 16 properties defined 
for it), with the ?meta-metalanguage? of properties 
numbering at the time of this writing about 350 rela-
tions and attributes. The current English lexicon is 
about 35,000 entries and growing. There are also Span-
ish and Chinese lexicons, and lexicons for other lan-
guages are under construction. We have also developed 
a collection of ever growing onomasticons. The English 
onomasticon at present contains over half a million en-
tries. In addition to the lexicons and the ontology, the 
static knowledge sources in OS also include morpho-
logical and syntactic grammars to support text analysis 
and generation, as well as a growing fact repository. 
 We are actively developing a variety of ontologi-
cal-semantic microtheories including microtheories of 
time, quantification, approximateness, issues relating to 
sets and ordered lists, several different aspects of refer-
ence, modality, discourse cohesion, script-based abduc-
tive reasoning. We are also developing pedagogical mi-
crotheories devoted to ontology, lexicon and script ac-
quisition. Additional microtheories are planned for de-
velopment as soon as the current ones reach minimum 
utility levels. We continue to augment the basic knowl-
edge resources and are investigating methods of using 
current knowledge resources to speed up acquisition of 
knowledge resources for languages other than those al-
ready in the system.  
 We are also developing a system for the automatic 
extraction of fact repository elements from TMRs. With 
the help of this system, we plan to acquire a large fact 
repository that will be used as the search space in the 
ontological-semantic approach to information extrac-
tion and question answering. 
 Many difficulties still remain in the path toward 
high-quality, broad-coverage extraction and manipula-
tion of meaning from texts. Still, we believe that the 
ontological-semantic approach is on the right path to-
ward this goal ? mainly because it is predicated on de-
tailed and flexible descriptive work on language and 
world knowledge, does not rely on unattainable or un-
computable prerequisites and is driven by the require-
ments of specific high-end computational-linguistic ap-
plications.  
  
References 
 
Hayes, P. 1979. The Naive Physics Manifesto. In: Mitchie, D 
(ed.), Expert Systems in the Microelectronic Age. Edin-
burgh: Edinburgh University Press. 
 
Mahesh, K., S. Nirenburg, and S. Beale 1997. If You Have It, 
Flaunt It: Using Full Ontological Knowledge for Word 
Sense Disambiguation. Proceedings of TMI-97, Santa Fe, 
NM, 1-9. 
 
Nirenburg, S., M. McShane and S. Beale (in preparation). Be-
yond Basic Semantic Dependencies I: The Microtheory of 
Modality in Ontological Semantics. 
 
Nirenburg, S. and V. Raskin. 2003. Ontological Semantics. 
MIT Press (forthcoming). 
 
Onyshkevych, B. 1997. An Ontological-Semantic Framework 
for Text Analysis. Unpublished Ph.D. thesis, Center for 
Machine Translation, Carnegie Mellon University, Pitts-
burgh, PA. 
 
 
 
 
 
 
OntoSem and SIMPLE: Two Multi-Lingual World Views 
Marjorie MCSHANE, Margalit ZABLUDOWSKI, Sergei NIRENBURG and Stephen BEALE 
Institute for Language and Information Technologies (ILIT) 
University of Maryland Baltimore County 
1000 Hilltop Circle 
Baltimore, MD  21250  USA   
marge@umbc.edu, margalit@rcn.com, sergei@umbc.edu, sbeale@umbc.edu 
 
Abstract 
In this paper we compare programs of work 
that aim to develop broad coverage cross-
linguistic resources for NLP: Ontological 
Semantics (OntoSem) and SIMPLE. The 
approaches taken in these projects differ in 
three notable respects: the use of an 
ontology versus a word net as the semantic 
substrate; the development of knowledge 
resources inside of as opposed to outside of 
a processing environment; and the 
development of lexicons for multiple 
languages based on a single core lexicon or 
without such a core (i.e., in parallel 
fashion). In large part, these differences 
derive from project-driven, real-world 
requirements and available resources ? a 
reflection of their being practical rather 
than theoretical projects. However, that 
being said, we will suggest certain 
preferences  regarding the content and 
development of NLP resources with a view 
toward both short- and long-term, high-
level language processing goals. 
1 Introduction 
Ontological Semantics (OntoSem) is a multi-
lingual text processing environment that takes as 
input unrestricted text and, using a suite of static 
resources and processors, automatically creates 
text-meaning representations (TMRs) which can 
then be used as the basis for any NLP application, 
including MT, question answering, summarization, 
etc. OntoSem knowledge resources are developed 
in coordination with each other and with the 
processors they serve. Some of the resources are 
fully language independent while others are readily 
parameterizable, wherein lies the cross-linguistic 
portability of the system. Although in  this paper, 
we focus on OntoSem lexicons, a crucial point is 
that they are not built in isolation but, rather, in an 
integrated environment where their utility can be 
tested and evaluated in a variety of practical 
applications.  
The SIMPLE project takes a different approach 
to achieving the dual goals of multilinguality and 
resource utility across applications. It aims to 
develop compatible (they use the term 
?harmonised?) lexicons for 12 European 
languages, attempting to foresee what will be most 
useful for applications but without referring to any 
particular processors that will use the information 
and without building any other knowledge 
resources to share the burden of semantic 
specification. As we will show, these different 
points of departure lead to quite different 
realizations of cross-lingual lexicons for NLP.  
2 Overview of SIMPLE 
The SIMPLE project is developing 10K-sense 
?harmonised? semantic lexicons for 12 European 
Union languages (Catalan, Danish, Dutch, English, 
Finnish, French, German, Greek, Italian, 
Portuguese, Spanish, Swedish), continuing the 
earlier PAROLE project, which developed 20K-
sense morphological and syntactic lexicons for 
these languages. The lexicons are monolingual and 
are developed independently, with the word stock 
based on corpus evidence for each language. To 
ensure some overlap of lexical senses, certain Base 
Concepts of EuroWordNet must be covered in 
each language (462 nominal, 187 verbal and 185 
adjectival Base Concepts that were culled and 
cleaned from EuroWordNet). This overlap will 
permit direct interlinking among languages; 
interlinking of the rest of the lexical stock is slated 
as future work. Pustejovsky?s four Qualia (which 
are, essentially, properties expressing formal, 
agentive, constitutive and telic meanings; see 
Pustejovsky 1995) are used to specify certain 
aspects of word meaning, and a common library of 
140 template types is used to guide acquisition in 
all languages (Lenci et al2000a, 2000b).  
Lenci et al 2000b (p. 5) summarize the 
information that can be represented in a SIMPLE 
lexicon entry: ?i) semantic type, corresponding to 
the template the SemU (semantic unit) instantiates; 
ii) domain information; iii) lexicographic gloss; iv) 
argument structure for predicative SemUs; v) 
selectional restrictions on the arguments; vi) event 
type, to characterise the aspectual properties of 
verbal predicates; vii) link of the arguments to the 
syntactic subcategorization frames, as represented 
in the PAROLE lexicons; viii) Qualia Structure; 
ix) information about regular polysemous 
alternation in which a word sense may enter; x) 
cross-part-of-speech relations (e.g. intelligent - 
intelligence; writer - to write); xi) synonymy.? 
 Below  is the SemU for a sense of lancet, 
instantiating the template Instrument (from 
Palmer et al 2000). 
 
Instrument 
Usem:     Lancet 
BC number: 
Template_Type:  [Instrument] 
Unification_path:  [Concrete_entity|ArtifactAgentive |  
      Telic] 
Domain:    Medicine 
Semantic Class:  Instrument 
Gloss: a surgical knife with a pointed double-edged 
blade; used for punctures and small incisions 
Pred_Rep.:    <Nil> 
Selectional Restr.:  <Nil> 
Derivation:    <Nil> 
Formal:    isa (<lancet>, <knife>: [Instrument]) 
Agentive:    created_by (<lancet>, <make>: 
      [Creation]) 
Constitutive:   made_of (<lancet>, <metal>:  
      [Substance]) 
      has_as_part (<lancet>, <edge>: 
      [Part]) 
Telic:     used_for(<lancet>, <cut>: [Constitu
      tive_change]) 
      used_by (<lancet>, <doctor>) 
Synonymy:    <Nil> 
Collocates:    Collocates (<SemU1>,?,<SemUn>) 
Complex:    <Nil> 
 
While the SIMPLE project is certainly 
producing useful resources, we would suggest that 
the lexical information and structure are being 
overly constrained by the frameworks selected, 
which we will comment on briefly in preparation 
for an extended comparison between OntoSem and 
SIMPLE in section 4. 
EuroWordNet is being used as the anchor for 
semantic description in SIMPLE. However, like 
the original English WordNet, it is not a property-
rich ontology but, rather, a hierarchical net of 
lexical items whose use in NLP has the same 
pitfalls  as any non-ontological word net (e.g., lack 
of disambiguating power and lack of sufficient 
relations between entities; see Nirenburg 2004c for 
a discussion of the insufficiency of WordNet for 
NLP). In order to make up for the sparsity of 
information in the semantic substrate, the SIMPLE 
lexicons contain what would, we believe, be more 
efficiently recorded in a single, sufficient ontology. 
For example, when the lexicon acquirers for each 
language use the Instrument template to describe 
lancet, they must rerecord in the lexicon of each L 
all of the language-independent property values for 
this lexical item, like the values for the four Qualia 
(formal, agentive, constitutive, telic), the domain, 
the unification path, etc. This is significant 
redundancy and, moreover, there is no guarantee 
that acquirers will arrive at the same decisions, 
either through  error, oversight or competing 
analyses of the phenomena in question. 
Another, in our view, insufficiently explained 
aspect of SIMPLE is the priority given to Qualia as 
descriptors of lexical  items. The original inventory 
of Qualia (from Pustejovsky 1995) consists of only 
four properties of the hundreds that can usefully be 
used to link concepts for purposes of NLP. Lenci et 
al. (2000b) address this issue as follows: 
?Although they [the four Qualia] clearly do not 
exhaust the semantic content of lexical items, 
Pustejovsky (1995) has convincingly shown that 
these four Qualia dimensions play a particularly 
prominent role in determining the linguistic 
behavior of word senses, as well as in the 
explanation of the generative mechanisms at the 
basis of lexical creativity. Qualia-based 
information can be specified for all the parts of 
speech, although prima facie it seems to be more 
directly suitable for the characterization of certain 
types of nominals?. However, there is large gap 
between theoretical interest and practical 
application: in fact, because of this, the SIMPLE 
project has moved toward an Extended Qualia 
Structure with more fine-grained subtypes of given 
Qualia.1  
In conclusion, we believe that SIMPLE is 
pursuing useful goals that could be pursued in even 
more useful ways by shifting the focus from 
lexicon-only work to integrated work within an 
environment in which ontological and lexical 
resources are developed together and where extant 
types of processors can be used to test the value of 
resources as they are developed.   
3 Overview of OntoSem 
The OntoSem approach to lexicon and ontology 
acquisition differs from that used in SIMPLE 
                                                     
1 As an aside, we see a parallel between focusing on 
Qualia in lexical description and, for example, focusing 
on classes of verbs with respect to their alternations, as 
is done, for example, in Levin 1995. While the 
descriptions that derive from theoretically-driven 
research such as this can certainly be useful, when it 
comes to writing ?well-rounded? semantic descriptions 
of words for large-scale systems, there is no distinction 
between a Quale and other properties. Similarly, the fact 
that a verb belongs to some group with respect to 
alternations is no more or less important than its other 
potential group membership along other parameters. See 
Nirenburg and Raskin 2004 for further discussion of 
these and related issues. 
because OntoSem is an integrated text processing 
environment, meaning that knowledge resources 
are crafted hand-in-hand with each other and with 
processors such that responsibility for various 
analysis tasks can be distributed in an ideal (to the 
degree of our understanding) way.  
 OntoSem takes as input unrestricted raw text 
and carries out preprocessing, morphological 
analysis, syntactic analysis and semantic analysis, 
with the results of semantic analysis represented as 
formal text-meaning representations (TMRs) that 
can then be used as the basis for a wide variety of 
NLP applications. Text analysis relies on:  
 
? The OntoSem language-independent ontology, 
which is written using a metalanguage of 
description and currently contains around 5,500 
concepts, each of which is described by an 
average of 16 properties. In all, the ontology 
contains hundreds of properties (which cover the 
same territory as the Qualia plus much more). 
Fillers for properties can be other ontological 
concepts or literals. 
? An OntoSem lexicon for each language 
processed, which contains syntactic and semantic 
zones (linked using variables) as well as calls to 
?meaning procedures? (i.e., programs that carry 
out procedural semantics, see McShane et al 
2004a) when applicable. The semantic zone most 
frequently refers to ontological concepts, either 
directly or with property-based modifications, 
but can also describe word meaning extra-
ontologically, for example, in terms of modality, 
aspect, time, etc. The current English lexicon 
contains approximately 12K senses, including all 
closed-class items and the most frequent verbs, 
as indicated by corpus analysis. This English 
lexicon  took less than 1 person year to build and 
can (as described below) be ported to other 
languages. 
? An onomasticon, or lexicon of proper names, 
which contains approximately 350,000 entries 
and is growing daily using semi-automated 
extraction techniques.  
? A fact repository, which contains real-world 
facts represented as numbered ?remembered 
instances? of ontological concepts (e.g., SPEECH-
ACT-3366 is the 3366th instantiation of the 
concept SPEECH-ACT in the world model 
constructed during the given run of the analyzer). 
? The OntoSem text analyzers, which cover 
preprocessing, syntactic analysis, semantic 
analysis, and creation of TMRs. They are largely 
parameterizable and thus can be ported to other 
languages. 
? The TMR language, which is the metalanguage 
for representing text meaning. A very simple 
example of a TMR (simple because most of the 
sentences we process are much longer), which 
reflects the meaning of the sentence He asked the 
UN to authorize the war, is as follows:  
 
REQUEST-ACTION-69  
    AGENT      HUMAN-72  
    THEME        ACCEPT-70  
    BENEFICIARY     ORGANIZATION-71  
    SOURCE-ROOT-WORD  ask  
    TIME       (< (FIND-ANCHOR-TIME))  
ACCEPT-70  
   THEME      WAR-73  
   THEME-OF     REQUEST-ACTION-69  
   SOURCE-ROOT-WORD   authorize 
ORGANIZATION-71  
   HAS-NAME     UNITED-NATIONS 
   BENEFICIARY-OF   REQUEST-ACTION-69  
   SOURCE-ROOT-WORD  UN 
HUMAN-72  
   HAS-NAME    COLIN POWELL 
   AGENT-OF     REQUEST-ACTION-69  
   SOURCE-ROOT-WORD  he ; ref. resolution done 
WAR-73  
   THEME-OF                ACCEPT-70  
    SOURCE-ROOT-WORD  war  
Details of this approach to text processing can be 
found, e.g., in Nirenburg et al 2004a,b. The 
ontology itself, a brief ontology tutorial, and an 
extensive lexicon tutorial can be viewed at 
http://ilit.umbc.edu. 
 OntoSem has been used with languages 
including English, Spanish, Chinese, Arabic and 
Persian, to varying degrees of lexical coverage 
(e.g., earlier, less fine-grained English and Spanish 
lexicons contained 40K entries and were used for 
MT in the Mikrokosmos project). What makes 
OntoSem amenable to efficient cross-linguistic 
usage is that many of the resources are either fully 
language independent (the ontology, the fact 
repository, the TMR metalanguage) or 
parameterizable in well understood ways. Here we 
focus on exploiting cross-linguistic similarity for 
lexical acquisition, but a similar analysis could be 
applied to the OntoSem analyzers. 
 
3. 1  OntoSem Lexicons 
A basic verbal lexicon entry in OntoSem looks as 
follows (in presentation format): 
 
watch  
watch-v1 
    synonyms ?observe? 
    anno 
         definition  ?to observe, look at? 
         example ?He?s watching the competition.? 
syn-struc 
       subject    $var1   cat n 
        v                $var0   cat v 
       directobject   $var2   cat n  
sem-struc 
     VOLUNTARY-VISUAL-EVENT 
            agent   ^$var1 
          theme   ^$var2 
 
The syntactic structure (syn-struc) says that this is 
a transitive sense of watch and the semantic 
structure (sem-struc) says that a VOLUNTARY-
VISUAL-EVENT ? which is a concept in our 
ontology ? must be instantiated in the TMR. The 
variables are used for linking, so, for example, the 
syntactic subject is linked to the meaning of the 
AGENT of the VOLUNTARY-VISUAL-EVENT (^ is 
read ?the meaning of?).  
 Apart from mapping directly to an ontological 
concept, there are many other ? and more complex 
? ways to express meaning in OntoSem. For 
example, one can map to an ontological concept 
with modified property values: e.g.,  
 
? Zionist is described as a POLITICAL-ROLE  that 
is the AGENT-OF a SUPPORT event whose THEME 
is Israel.  
? asphalt (v.) is described as a COVER event 
whose INSTRUMENT is ASPHALT.  
? recall (v. as in they recalled the high chairs) is 
described as a RETURN-OBJECT event that is 
CAUSED-BY a FOR-PROFIT-CORPORATION and 
whose THEME is ARTIFACT, INGESTIBLE or 
MATERIAL. 
 
There are also a number of fully or partially 
non-ontological ways of describing meaning, like 
the use of parametric values of mood or aspect. For 
example, the auxiliary might as in He might come 
over is described using the modality ?epistemic?, 
which deals with the truth value of a statement:    
 syn-struc 
      subject    $var1   cat n 
      v                $var0   cat v 
      inf-cl    $var2   cat v    
 sem-struc 
       ^$var2  
   epistemic  .5 
   agent   ^$var1 
 meaning-procedure 
   fix-case-role (value ^$var1) (value ^$var2) 2 
                                                     
                                                                                   2 This meaning procedure reassigns a case-role if the 
listed AGENT case-role is inappropriate considering the 
meaning of $var1 and/or $var2: e.g., in the truck might 
come, truck is a THEME of a MOTION-EVENT, not an 
 
Another set of extra-ontological semantic 
descriptors is used for time expressions, as shown 
by the example of yesterday below. 
 
syn-struc 
     root   $var1   cat v 
     mods   root $var0 cat adv   
     type    pre-verb-post-clause 
sem-struc 
    ^$var1  
        time  
      combine-time  
     (find-anchor-time) (day 1) before 
 
As already shown in the examples of might and 
yesterday, calls to procedural semantic routines 
(which may or may not be listed in the meaning-
procedure zone of the lexicon entry) are used 
widely in OntoSem lexical description. This 
reflects the fact that many aspects of meaning 
cannot be statically described but, rather, must be 
computed. An advantage of developing lexical 
resources within a processing environment is being 
able to assign responsibility for portions of 
semantic composition to resources best suited for 
them. 
In addition to the means of lexical expression 
described above, OntoSem lexicon entries can 
include entities of any degree of complexity, 
including phrasals of any profile, as reported in 
McShane et al 2004b.  
 
3.2  Porting OntoSem Lexicon Entries Across 
Languages 
As is clear from the examples above, OntoSem 
provides significant expressive power semantically 
(not to mention syntactically, which we do not 
pursue here). Expressive means include mapping 
to the ontology (which itself is rich in property-
value descriptors), mapping to the ontology with 
lexical supplementation of properties, or referring 
to extra-ontological microtheories like those that 
treat time, reference resolution, comparison, 
ellipsis resolution, modality, aspect, etc. What 
must be emphasized, however, is how language 
neutral ? and therefore portable across languages ? 
the semantic descriptions are. Whereas it is typical 
to assume that lexicons are language-specific 
whereas ontologies are language-independent, 
most aspects of OntoSem sem-strucs are language-
independent, apart from the linking of specific 
variables to their counterparts in the syn-struc. 
AGENT, and in I might get sick, I am an EXPERIENCER of 
a DISEASE  event, not an AGENT of it.  
 
Stated differently, if we consider sem-strucs ? no 
matter what lexicon they originate from ? to be 
building blocks of the representation of word 
meaning (as opposed to concept meaning, as is 
done in the ontology), then the job of writing a 
lexicon for L2 based on the lexicon for L1 is in 
large part limited to a) providing an L2 translation 
for the head word(s), b) making any necessary syn-
struc adjustments and c) checking/modifying the 
linking among variables in the syn- and sem-strucs. 
This conception of cross-linguistic lexicon 
development derives in large part from the 
Principle of Practical Effability (Nirenburg and 
Raskin 2004), which states that what can be 
expressed in one language can somehow be 
expressed in all other languages, be it by a word, a 
phrase, etc.  
Apart from this theoretical justification for 
conceptualizing the sem-strucs as building blocks 
for lexical representation, there are two practical 
rationales: supporting consistency of meaning 
representation across languages and using acquirer 
time most efficiently in large-scale lexical 
acquisition.  
 As regards consistency, the potential for 
paraphrase must be considered when building 
multi-lingual resources. For instance, ?weapons of 
mass destruction? can be described as the union of 
CHEMICAL-WEAPON and BIOLOGICAL-WEAPON, or 
it can be described as WEAPON with the ability to 
KILL > 10,000 HUMANs (the actual number 
recorded will be treated by the analyzer in a fuzzy 
fashion; however, it would be less than ideal for a 
lexicon for L2 to record 10,000 while a lexicon for 
L3 recorded 25,000). While both representations 
are valid, it is desirable to use the same one in all 
languages covered. In addition, the decision of 
how to describe a notion ? whether by ontologizing 
it, describing it using extra-ontological means, 
describing it using an existing concept with 
additional properties and values defined ? is often 
a judgment call. It would not be desirable for the 
acquirer of German to map the word Schimmel 
?white horse? to the concept HORSE with the lexical 
restriction COLOR: WHITE, while the acquirer of 
some other language that also has a word for 
?white horse? introduced an ontological concept 
specifically for this entity. Again, while both 
representations are valid and, in this case, 
semantically equivalent, the general tendency 
should be to strive toward uniformity where 
possible. 
As concerns acquirer time, composing sem-
strucs is, by far, the most time- and effort-intensive 
aspect of writing OntoSem lexicon entries. This 
derives from the wealth of expressive means; the 
fact that microtheories of time, reference, etc., are 
naturally built during lexicon development (recall 
that our environment is fully integrated with 
processors); and the fact that ontology 
development occurs hand-in-hand with lexicon 
development. Therefore, work on the first lexicon 
entry that describes a word sense ? regardless of 
the language of origin ? takes much more time 
than editing a word sense for a new language. 
Moreover, although in the worst case some editing 
of entries is necessary for L2, L3, etc., in most 
cases no such editing is needed. Although one 
might hypothesize this state of affairs based on 
cross-linguistic principles, we have tested it in the 
lexicon-porting experiment described below. 
 
3.3  An English to Polish Lexicon Porting 
Experiment 
For the experiment, a bilingual English/Polish 
computational linguist took the English OntoSem 
lexicon as a seed and experimented with various 
porting methods into Polish.  
The primary insight was that while manually 
porting individual lexical senses is quite 
straightforward and will save time over acquisition 
from scratch, porting lexicons wholesale is rather 
more complex. That is, manually providing 
translations for the senses in L1 is a conceptually 
relatively simple task, complicated only by the 
need for the occasional remapping of variables, 
editing of syntactic structures, omission of given 
senses due to language lacunae (e.g., a phrasal 
encoded in L1 might not occur in L2 in a fixed 
form), etc. However, if one attempts either to 
(semi-)automate the acquisition process and/or use 
L1 as a seed lexicon for more ?creative? 
acquisition of L2, the space of options becomes 
quite broad and must be constrained 
programmatically in order to actually benefit from 
the reuse of semantic descriptions.  
 For example, if a well-trained acquirer of L2 is 
using L1 as a seed, questions that arise include: 
Should the base lexicon be left as is (considering 
that it is known to have incomplete coverage) or 
should one attempt to improve its quality and 
coverage while building L2? Should L2 acquisition 
be driven by correspondences in head words or 
simply by the content of sem-struc zones (e.g., all 
English senses of table will be in one head entry, 
and typically will be acquired at once; should all 
senses of all L2 translations of table be handled at 
once during L2 acquisition or should the L2 
acquirer wait until he comes upon sem-strucs that 
represent the given other meanings of the L2 
words)? To what extent should the regular 
acquisition process ? including ontology 
supplementation ? be carried out on L2? The 
answers to all of these, and more such, questions 
depend entirely upon available resources and 
should be informed by (a) experiments to 
determine what works best for a given acquirer, 
and (b) the goals of a given project.  
 As regards automation, the experiment found 
that automatically mapping L2 words to L1 
OntoSem entries works very well (at well over 
90%) when the machine-tractable L1-L2 resource 
used to support this process has one sense of the 
given word in the given part of speech and the 
OntoSem lexicon also has one sense for the given 
part of speech. The extraction and matching of 
such senses represents a well-defined, extremely 
time-efficient task, especially for specialized 
terminology that tends to have only one sense in 
any language. When the mapping between senses 
in the L1-L2 lexicon and the OntoSem lexicon is 
more than one to one, manual linking of senses 
(which do not always correspond among the 
languages) has proved necessary, with the potential 
benefits of a time-saving interface becoming 
immediately clear.3 
4 Pudding in SIMPLE and OntoSem 
Now we return to the comparison between 
SIMPLE and OntoSem. We use the example of 
pudding, which is cited in numerous documents 
related to SIMPLE. The Qualia (in italics) and 
their values (in boldface) for this word are: formal 
? substance; constitutive ? ingredients; telic ? 
eat; agentive ? make. The stated rationale for 
encoding these qualia values in SIMPLE lexicon 
entries is that they are needed to understand the 
semantics of the sentences like the following (from 
Lenci et al 2000b):  
 
a) John refused the pudding (= refused to eat: telic);  
b) That?s an easy pudding (= easy to make: agentive);  
c) There is pudding on the floor (= substance: formal);  
d) The pudding came out well (= has been made well: 
agentive);  
e) That was a nice bread pudding (= made of/ingredient: 
constitutive)   
 
 We would suggest, as before, that the lexicon is 
not the best place for this information and, further, 
that this information is incomplete. For 
comparison, we present our approach to describing 
and processing pudding in the OntoSem 
environment. Since OntoSem uses a full ontology 
(not a word net), the ontological specification of 
the concept PUDDING contains much of the needed 
                                                     
3 Some automation of the mapping between L1-L2 
multi-sense words is possible as demonstrated by 
Pianta, et al 2002, but the results still require intensive 
manual work by an acquirer. 
 
information for processing all the above sentences 
containing pudding. Moreover, since the OntoSem 
ontology, lexicons and processors are developed 
together, their known mutual contributions drive 
resource acquisition. Obviously, one cannot expect 
the same approaches to be used in a lexicon-only 
project like SIMPLE. However, a non-trivial 
question, considering the expense of manual 
resource acquisition, is to what extent should we 
be developing resources separately from 
processors that can use them, especially when the 
nature of processors crucially affects what is 
needed of knowledge resources? 
Below is a subset (for reasons of space) of the 
properties and values for the concept PUDDING in 
the OntoSem ontology; the first 4 are locally 
specified while the others are inherited. 
 
PUDDING 
   IS-A            
 DESSERT 
     HAS-OBJECT-AS-PART  MILK, SUGAR, EGG 
     FATTINESS     > .6 
     THICKNESS     > .8 
 Inherited from DESSERT 
     BITTERNESS     0 
     SALTINESS     0 
  SWEETNESS     > .7 
  SPICINESS     0 
 Inherited from PREPARED-FOOD 
  THEME-OF    PREPARE-FOOD, BUY 
  PRODUCT-TYPE-OF   FOOD-SERVICE-  
         ORGANIZATION 
 Inherited from FOOD 
  THEME-OF    INGEST 
 Inherited from ARTIFACT 
  CREATION-RELATION HUMAN 
  COST      > 0 
(Inheritance continues, from INANIMATE, 
 PHYSICAL-OBJECT, OBJECT, ALL.) 
   
Since all of the necessary information about 
PUDDING is encoded in the ontology, the OntoSem 
lexicon entry for pudding need only contain a 
direct link to the concept.  
 The analysis of sentences (a)-(e) in OntoSem is 
carried out as follows. For (a), there is a lexical 
sense of refuse that expects an OBJECT (not an 
EVENT, as in the main sense) as its direct object. 
This sense expects the semantic ellipsis of a verb 
and, as such, is supplemented with a meaning 
procedure called ?seek-specification?, which 
searches for the elided event. There are two 
sources it searches: previous TMRs, for a recent 
semantically viable event, and the ontology itself, 
for an EVENT (or EVENTs) whose default AGENT is 
HUMAN and default THEME is PUDDING. This 
search procedure in some cases returns more than 
one candidate event to reconstruct the semantic 
ellipsis. While this is not always ideal, it does 
reflect precisely the type of lexical ambiguity that 
can be resolved only by contextual clues. For 
example, the sentence John refused the pudding 
could be used in a supermarket context to describe 
a situation where John refused to take/accept a free 
box of pudding that was being pushed upon him by 
a promoter. The desire to be able to treat this 
second reading of the sentence is the reason for 
treating constraints in OntoSem abductively. As far 
as one can tell, the constraints in SIMPLE are 
rigid: ?telic = eat? for pudding is a hard constraint. 
In fact, the example John refused the pudding is 
representative of a much broader class of 
phenomena known as semantic ellipsis, the 
treatment of which must be carried out by 
procedural semantic routines (see McShane et al 
2004a for details).  
 Example (b) is another case that OntoSem 
handles through lexical and procedural semantics 
working in tandem. The NP easy pudding is 
actually a construction {a value on the scale 
DIFFICULTY + ARTIFACT} that is known to involve 
semantic ellipsis. Thus, we prepare for it in the 
OntoSem lexicon by associating this construction 
with the seek-specification meaning procedure, 
described above, which handles with equal 
efficacy easy pudding (PREPARE-FOOD), easy song 
(PERFORM-MUSIC), etc.  
 Example (c) is handled trivially based on the 
fact that PUDDING is a PHYSICAL-OBJECT and, like 
all PHYSICAL-OBJECTs, is ontologically defined for 
LOCATION.  
 Example (d) is analyzed using the information 
that PUDDING is a PREPARED-FOOD and, as such, is 
the THEME-OF PREPARE-FOOD, which in turn is a 
child of CREATE-ARTIFACT. The lexicalized phrasal 
{ARTIFACT + come out + a value of evaluative 
modality} is mapped to CREATE-ARTIFACT, with 
the THEME being the given ARTIFACT and the 
evaluative modality being concretized based on the 
evaluative value of the lexical item (e.g., ?well?, as 
in ?the pudding came out well? is mapped to 
?evaluative .7?). This phrasal, of course, works for 
any ARTIFACT and any value of evaluative 
modality, so lexicalizing it once is a real savings in 
time and effort. 
 Example (e) has two possible treatments in 
OntoSem: on the one hand, the lexical item ?bread 
pudding? could (and, ultimately, should ? though it 
is not in the OntoSem lexicon at the moment)  be 
listed as a phrasal in the lexicon, described as 
PUDDING: HAS-OBJECT-AS-PART BREAD. However, 
if it is not listed, it is treated by our productive 
rules for treating noun-noun compounds. One of 
the N-N compound rules is that the pattern 
MATERIAL + N is analyzed as N:HAS-OBJECT-AS-
PART:MATERIAL.  
 
5 Conclusions 
Although space does not permit us to fully describe 
the resources, programs and resulting TMRs for 
sentences (a)-(e), this snapshot of their processing 
underscores the point that developing resources 
within an environment where they are tightly 
coupled with processing has clear advantages over 
developing resources in the abstract. Of course, in 
the absence of a full environment, projects like 
SIMPLE make sense. However, the challenges of 
resource development outside of an environment 
are keenly felt by developers: as Calzolari 
(1999:42) reports: ?A dichotomy at stake here is 
the one between generality of a LR [lexical 
resource] vs. usefulness for applications. In 
principle, only when we know the actual specific 
use we intend to do [sic] of a LR can we build the 
?very best? LR for that use, but this has proved to 
be too expensive and not realistic. In practice, 
however, there exists a large core of information 
that can be shared by many applicative uses, and 
this leads to the concept of ?generic? LR, which is 
at the basis for the EAGLES initiative and of the 
PAROLE/SIMPLE projects, to be then enhanced 
and tuned with other means?. The only aspect of 
this statement that we would dispute is the 
unrealistic nature of building resources for 
particular systems. If a system, like OntoSem, 
creates text-meaning representations that can be 
used equally effectively for many applications, 
then there is no reason why they cannot be built 
specifically for the given environment. In other 
words, when the result of semantic analysis is a 
metalanguage-formulated TMR, programs of any 
profile can exploit this representation. Stated 
differently, there need not be a direct link between 
end applications and the input text elements or 
their lexical representations.  
References 
Lenci, Alessandro, Federica Busa, Nilda Ruimy, 
Elisabetta Gola, Monica Monachini, Nicoletta 
Calzolari, Antonio Zampolli et al 2000a. 
SIMPLE Work Package 2, Linguistic 
Specifications, Deliverable D2.1, March 2000. 
Lenci, Alessandro, Nuria Bel, Federica Busa, 
Nicoletta Calzolari, Elisabetta Gola, Monica 
Monachini, Antoine Ogonowski, Ivonne Peters, 
Wim Peters, Nilda Ruimy, Marta Villegas, 
Antonio Zampolli. 2000b. SIMPLE: A General 
Framework for the Development of Multilingual 
Lexicons. Proceedings of LREC 2000. 
Levin, Beth. 1995. English Verb Classes and 
Alternations. Chicago: University of Chicago 
Press. 
McShane, Marjorie, Stephen Beale and Sergei 
Nirenburg. 2004a (forthcoming).  Some 
meaning procedures of Ontological Semantics. 
Proceedings of LREC 2004, Lisbon, Portugal.   
McShane, Marjorie, Sergei Nirenburg and Stephen 
Beale. 2004b (ms.). The description and 
processing of multi-word expressions in 
OntoSem. Available at 
http://ilit.umbc.edu/RecentPubl.htm. 
Nirenburg, Sergei and Victor Raskin. 2004a 
(forthcoming). Ontological Semantics, the MIT 
Press, Cambridge, Mass.  
Nirenburg, Sergei, Stephen Beale and Marjorie 
McShane. 2004b (forthcoming). Evaluating the 
performance of the OntoSem semantic analyzer. 
ACL 2004 Workshop on Text Meaning and 
Interpretation.. 
Nirenburg, Sergei, McShane, Marjorie, Stephen 
Beale.  Forthcoming. 2004c (forthcoming). The 
rationale for building resources expressly for 
NLP. Proceedings of LREC 2004, Lisbon, 
Portugal.   
Palmer, Martha, Ralph Grishman Nicoletta 
Calzolari, Antonio Zampolli. 2000. 
Standardizing multilingual lexicons. Paper 
presented at the workshop on Web-Based 
Language Documentation and Description 12-15 
December 2000, Philadelphia, USA. 
Pederson, Bolette Sandford and Britt Keson. 
SIMPLE - Semantic information for 
multifunctional plurilingual lexica: Some 
examples of Danish concrete nouns. SIGLEX99: 
Standardizing Lexical Resources Workshop, 
ACL99. 
Pianta, Emanuele, Luisa Bentivogli and Christian 
Girardi. 2002. MultiWordNet: Developing an 
aligned multilingual database. Proceedings of the 
First International Conference on Global 
WordNet, Mysore, India, January 21-25, 2002. 
Pustejovsky, J. 1995. The Generative Lexicon. 
Cam, 28(1):11-21. 
Evaluating the Performance of the OntoSem Semantic Analyzer 
Sergei NIRENBURG, Stephen BEALE and Marjorie MCSHANE  
Institute for Language and Information Technologies (ILIT) 
University of Maryland Baltimore County 
1000 Hilltop Circle 
Baltimore, MD  21250  USA   
sergei@umbc.edu, sbeale@umbc.edu, marge@umbc.edu  
 
Abstract 
This paper describes an innovative 
evaluation regimen developed for the text 
meaning representations (TMRs) produced 
by the Ontological Semantic (OntoSem) 
general purpose syntactic-semantic 
analyzer. The goal of evaluation is not only 
to determine the quality of TMRs for given 
texts, but also to assign blame for various 
classes of errors, thus suggesting directions 
for continued work on both knowledge 
resources and processors. The paper 
includes descriptions of the OntoSem 
processing environment, the evaluation 
regime itself and results from ur first 
evaluation effort.  
F
e
O
1 Introduction 
In this paper we describe the 
evaluation regimen for a 
general-purpose syntactic-
semantic analyzer, OntoSem, 
under continuous development 
at the Institute for Language 
and Information Technologies 
(ILIT) of the University of 
Maryland Baltimore County. 
Its top-level architecture is 
illustrated in Figure 1. The 
knowledge in the fact 
repository and the ontology 
serves not only OntoSem itself 
but also provides a knowledge 
substrate to be used in a 
variety of reasoning 
applications. At present, the 
acquisition of the ontology and 
the semantic lexicon is carried 
out by human acquirers using 
interactive tools. The 
acquisition of the fact 
repository is mixed, with some 
of it carried out manually and 
The approach to semantic analysis in OntoSem is
described in some detail in, e.g., Nirenburg and
Raskin 2004, Nire
some of it resulting from the ope
fact extractor on the results of seman
 
 
nburg et al 2003, Beale et al
 of pre-semantic text processing modules. 
he preprocessor module deals with mark-up in 
2003. Our description here will be necessarily 
brief.  
 
Text analysis in OntoSem relies on the results of a 
battery
T
the input text, finds boundaries of sentences and 
words, and recognizes dates, numbers, named 
entities and acronyms. Morphological analysis 
accepts a string of word forms as input and for 
each word form outputs a record containing its 
citation form in the lexicon and a set of 
morphological features and their values that corre-
spond to the word form from the text. Once the  o 
igure 1. The overall architecture of the OntoSem semantic analyzer. The 
valuation regimen described in this paper evaluates the production of basic TMRs. 
ther processing will be evaluated in follow-up work. 
ration of the 
tic analysis. 
morphological analyzer has generated the citation 
forms for word forms in a text, the system can 
activate the relevant lexical entries in its lexicons, 
including the onomasticon (a lexicon of proper 
names). The task of syntactic analysis in 
ontological semantics is, essentially, to determine 
clause-level dependency structures for an input 
text and assign grammatical categories to clause 
constituents (that is, establish subjects, direct 
objects, obliques and adjuncts).  
 
Semantic analysis proper uses the information 
(mutual constraints) in the active lexicon entries, 
the ontology and the results of earlier processing to 
i
 
A
a 
nguage as well as for the specification of 
lso supports morphological and 
sy tactic analysis. Semantically, it specifies what 
carry out, at the first stage, word sense 
disambiguation and establish basic semantic 
dependencies in the text. The results are recorded  
 
 
 
 
 
 
 
 
 
 
 
v
s
e
d
a
s
F
a
p
(
a
t
a
 
The OntoSem ontology provides a metalanguage 
for describing the meaning of the lexical units in 
la
meaning encoded in TMRs. The ontology contains 
specifications of concepts corresponding to classes 
of things and events in the world. It is a collection 
of frames, or named collections of property-value 
pairs, organized into a hierarchy with multiple 
inheritance. The expressive power of the ontology 
and the TMR is enhanced by multivalued fillers for 
properties, implemented using the value ?facets? 
DEFAULT, SEM, VALUE, and RELAXABLE-TO, 
among others. At the time of this writing, the 
ontology contains about 5,500 concepts (events, 
objects and properties), with, on average, 16 
properties each. 
 
The OntoSem lexicon contains not only semantic 
information, it a
n
concept, concepts, property or properties of 
concepts defined in the ontology must be 
instantiated in the TMR to account for the meaning 
of a given lexical unit of input. At the time of 
writing, the latest version of the English semantic 
lexicon includes over 12,000 handcrafted entries. 
These entries cover some of the most complex 
lexical material in the language ? ?closed-class? 
grammatical lexemes such as conjunctions, 
prepositions, pronouns, auxiliary and modal verbs,  
g
Figure 2. Creation of basic TMRs. The basic 
semantic analyzer relies largely on matchin  
selectional restrictions. This can lead to incongruity 
when the listed constraints are too strong, or to 
residual ambiguity if they are too weak to filter out all 
but one candidate. To resolve these problems, 
OntoSem uses both static knowledge (multivalued 
selectional restrictions and lateral constraints among 
co-arguments of a predicate) and context-generated 
heuristics, including information in the nascent TMR 
and measuring distances among any two concepts in 
the ontological search space.
 basic text meaning representations  (TMRs). n
t the next stage, the analyzer determines the 
e, 
eech acts, speaker attitudes etc., to produce 
to the 
danger" 
 
1 at n 
4 at n opt + 
 
r3 cat n 
e str
  
N 
ENT) 
  
 
In the lexicon, variables (e.g., $var2) support 
sy ? 
alues of the various modalities, aspect, tim
p
xtended TMRs. At both stages, the analyzer has to 
eal with ambiguity, incongruity between the input 
nd expectations recorded in the static knowledge 
ources, unknown words, and non-literal language. 
igure 2 summarizes the types of heuristics that the 
nalyzer uses at the first stage. While all of 
rocedures using them have been implemented 
see Nirenburg et al 2003), the version of the 
nalyzer we evaluated involved only a subset of 
hem. We plan to evaluate the analyzer with all the 
vailable recovery procedures in the near future.  
etc., as well as about 3,000 of the most frequent 
verbs. We illustrate the structure of the lexicon 
entry on the example of the first verbal sense of 
alert (presented in a simplified format): 
 
alert-v1       
 example "He alerted us 
  morph    regular  
 syn-struc 
  root    root $var0 cat v 
   subject root $var c
root $var c   object  
   pp-adjunct  
     root $var2  
   cat prep root to opt +
ect      obj
      root $va
c  s m- u
cept   WARN        ;an ontological con
  agen     t value ^$var1 sem HUMA
value ^$var3     theme  
    beneficiary value ^$var4 
    instrument value ^$var1 
         sem (or 
     ARTIFACT EV
   ^$var2  null-sem +    
ntax-semantics dependency linking; the caret ?^
is read ?the meaning of.? In this ex ple, am if ^$var1 
  or a descendant of , it occupies 
tological concepts by 
rize the 
ar from a recently processed text about Colin 
      ACCEPT-70  
NEFICIARY     ORGANIZATION-71  
 ask  
HOR-TIME))  
ST-ACTION-69  
-
ON-71  
ATIONS 
f. resolution done 
-ACTION 
A -72 (Colin Powell), 
whose BENEFICIARY is ORGANIZATION-71 (United 
bered instances of ontological concepts. As 
 does not play a significant role in the evaluation 
e
an-aided version of the 
 all three 
nalysis ? 
put by hand in a text 
file. Preprocessor output is relatively simple to 
it 
3. 
4. eveloped visual 
 
5. 
6.  analysis.  
We plan to integrate this capability with our 
to 
produce a full-function text processing system. The 
is HUMAN HUMAN
the semantic role of AGENT (he alerted us...), 
whereas if it is ARTIFACT or EVENT (or a 
descendant of any of those concepts) it is 
INSTRUMENT (the bell alerted us..., his behavior 
alerted us...). For lack of space, we will not be able 
to discuss all the representational and descriptive 
devices used in the lexicon or the variety of the 
ways in which semantic information in the lexicon 
and the ontology can interact. See Nirenburg and 
Raskin 2004 for discussion. 
 
The English Onomasticon (lexicon of proper 
names) currently contains over 350,000 entries that 
are semantically linked to on
way of the fact repository. Onomasticon entries are 
indexed by name (e.g., New York), while the 
entries in the fact repository are identified by 
appending a unique number to the name of the 
ontological concept of which they are instances 
(e.g., Detroit might be listed as CITY-213). 
 
The TMR (automatically generated but shown 
here in a simplified presentation format) for the 
hort sentence He asked the UN to authos
w
Powell is presented below. The numbers associated 
with the ontological concepts indicate instances of 
those concepts: e.g., REQUEST-ACTION-69 means 
the 69th time that the concept REQUEST-ACTION has 
been instantiated in the world model used for, and 
extended during, the processing of this text or 
corpus.  
 
REQUEST-ACTION-69  
    AGENT      HUMAN-72  
    THEME  
    BE
    SOURCE-ROOT-WORD 
    TIME       (< (FIND-ANC
ACCEPT-70  
   THEME      WAR-73  
   THEME-OF     REQUE
   SOURCE ROOT-WORD   authorize 
ORGANIZATI
   HAS-NAME     UNITED-N
   BENEFICIARY-OF   REQUEST-ACTION-69  
   SOURCE-ROOT-WORD  UN 
HUMAN-72  
   HAS-NAME    COLIN POWELL 
   AGENT-OF     REQUEST-ACTION-69  
   SOURCE-ROOT-WORD  he ; re
WAR-73  
   THEME-OF                ACCEPT-70  
    SOURCE-ROOT-WORD  war  
 
The above says that there is a REQUEST
event whose AGENT is HUM N
Nations) and whose THEME is ACCEPT. The 
ACCEPT event, in turn, has a THEME of WAR-73. 
Note that the concept ACCEPT is not the same as 
the English word accept: its human-oriented 
definition in the ontology is ?To agree to carry out 
an action, fulfill a request, etc?, which fits well 
here.  
 
The Fact Repository contains a list of 
remem
it
regim n reported in this paper, we will provide no 
further description here.   
2 Generating Gold Standard TMRs 
We have developed a hum
OntoSem analyzer in which the results of
major stages of ontological semantic a
preprocessor output, syntax output and semantic 
output ? can be inspected and corrected by a 
human. For purposes of evaluation, we have used it 
to produce gold standard (GS) outputs for each of 
the three stages. The production of gold standard 
outputs proceeds as follows: 
 
1. Run the OntoSem analyzer on an input text. 
2. Correct preprocessor out
read in text format, and we have found 
quickest to simply correct it by hand. It takes 
on average 1 minute to correct an average-
length (> 25 words) sentence.  
Input the corrected preprocessor results into 
the analyzer and produce a syntactic analysis.  
If necessary, use a specially d
editing interface to add or delete edges on the 
chart that presents the results of syntactic
analysis, to remove spurious parses, to correct 
phrase and clause boundaries, and to add any 
missing phrase or clause parses. 
Feed the correct syntax back into the analyzer 
and obtain a semantic analysis. 
If necessary, correct the semantic
 
knowledge acquisition interfaces in order 
side effects of this process will include the creation 
of a bank of gold standard TMRs as well as, 
possibly, less importantly, gold standard results of 
preprocessing and syntactic analysis. Such 
resources are clearly valuable as training data for 
statistical NLP, and a number of projects are 
devoted to entirely or in a large measure to their 
creation. The process of producing gold standard 
TMRs, unlike most of the resource acquisition 
approaches, is, to a significant degree, automated ? 
which reduces the incidence of interannotator 
disagreement and generally makes the process 
faster and cheaper.  
 
In the OntoSem research paradigm, knowledge 
acquisition (enhancement of the ontology, the 
xicon and other basic static knowledge sources) 
ms that do not involve knowledge acquisition 
f the kind OntoSem uses. However, the set of 
the only one we consider 
ractical.  It is not possible for a human to produce 
luate the results of fully 
utomatic analysis (see below); as training data for 
auto put  we evaluate several 
? baseline 1: same as above, except we force the 
 first senses in our lexicon entries are 
? 
d 
? 
 analyzer;   
put to the 
 
For
prep syntax results; semantics 
results and evaluation results The evaluation is 
dard outputs and include a) the 
ord/phrase count; b) the number of input words 
le
is an ongoing process. The process of creating gold 
standard TMRs provides an empirical impetus for 
knowledge acquisition. This process will not at all 
interfere with our evaluation regimen because our 
approach does not rely on having a standard test 
corpus. We will simply run the entire evaluation 
procedure (starting with the production of the gold 
standard TMRs) on a new corpus, analyze the 
results and move on to yet another corpus, and so 
on.  
 
This approach cannot be directly exported to those 
syste
o
gold standard TMRs produced through our 
evaluation process will be made freely available 
and can serve as the test corpus for any other 
semantic analyzer (word sense disambiguator 
and/or semantic dependency extractor). This will 
be our direct contribution to the resource set in the 
field. Of course, using this resource will involve 
resolving the differences in the notation and 
semantics between the TMR structures and any 
other metalanguage. 
 
This methodology for producing gold standard 
semantic outputs is 
p
gold standard semantic outputs by hand because of 
the complexity of the knowledge, as well as the 
high probability of annotator disagreement due to 
valid semantic paraphrasing (e.g., one annotator 
might describe the meaning of weapons of mass 
destruction as the union of BIOLOGICAL-WEAPON 
and CHEMICAL-WEAPON, whereas another might 
describe it as WEAPON that has the potential to kill 
more than 10,000 people). 
 
In sum, gold standard  outputs are used for a 
number of purposes: to eva
a
machine learning, with the goal of improving the 
system?s static knowledge sources; to trigger 
manual acquisition of knowledge for lacunae; or to 
derive high-confidence TMRs for use in mining 
information for a fact repository. Last but not least, 
the gold standard TMRs produced according to our 
methodology can also be directly used in a variety 
of applications ? from human-assisted knowledge-
based MT to knowledge acquisition for general-
purpose reasoning systems.  
3 Automated Evaluation of Ontological 
Semantic Analyses 
Once the gold standard TMRs are produced, the 
evaluation of OntoSem proceeds fully 
matically. For each in
?runs? as follows: 
 
? as is: we simply input the text and evaluate the 
outputs; 
analyzer to use the first lexical sense of each 
word; the
typically the most central and frequent ones; 
baseline 2: same as baseline 1, except we use 
the first sense that has the correct part of 
speech (as specified in the gold standar
preprocessor results); 
correct preprocessor output: we use the gold 
standard preprocessor output as input to the 
syntactic and semantic
? corrected syntax output: we use the gold 
standard syntax (and gold standard 
preprocessor output) as the in
semantic analyzer. 
 each run, we produce four output files: 
rocessor results; 
performed by automatically comparing the actual 
preprocessor, syntax or semantic results to the 
corresponding gold standard outputs. The 
evaluation produces statistics and/or measurements 
as follows.  
 
General text-level statistics are collected from the 
golden stan
w
that are not in the OntoSem lexicon; c) the 
syntactic ambiguity count, which is the number of 
phrases and clauses in the syntactic output; d) the 
semantic ambiguity count, which is the product of 
the number of senses of each word, which provides 
an estimate of the overall theoretical complexity of 
semantic analysis; and e) the word sense ambiguity 
count, which is the number of semantic 
combinations the analyzer actually needed to 
examine to produce the result; this number 
provides an estimate for the actual complexity of 
semantic analysis: syntactic clues often help prune 
many spurious analyses and the efficient semantic 
analysis algorithm (Beale, et. al. 1995) reduces the 
total number of combinations that have to be 
examined while maintaining accuracy.  
For this evaluation, the lexicon provided almost 
complete lexical coverage of the input texts (in fact 
only one word was missing). We will use the 
are 
ollected for each evaluation run. 
ches between an 
ctual run and the gold standard, n is the number of 
 of 
hrases, and phrase attachment.   
turned for each 
phrase, with 1.0 reflecting a perfect match. 
 
1
 
gstart is the gold standard word number 
 
ber at the start of the phrase being 
 
b)
ach phrase in the 
gold standard syntax, it is determined if there 
exists a phrase with the same part of speech 
 
c) 
ure looks for a phrase that 
overlaps with it that has the same part of 
 
A s
as 
Ana ll Score is then the average score of 
, b and c. 
 (SD) determination. For WSD, three 
measures are computed.  
on is marked with the 
word number from the input text from which it 
 
B) 
en 0.0 and 1.0 is returned. 
A mismatch of a word with more senses is 
 
C) 
is 
ontologically ?close? to the correct sense is 
results of this first evaluation as a baseline for 
future evaluation of the degradation of the results 
due to incompleteness of the static knowledge. 
 
Results from the operation of the preprocessor, 
syntactic analysis and semantic analysis 
c
 
The preprocessor statistics are recorded as 
follows (m is the number of mat
a
mismatches): a) abbreviations, time, date and 
number recognition (m/n); b) named entity 
recognition (m/n); c) part of speech tagging (m/n). 
The overall score of the preprocessor is calculated 
as the average of m/m+n for all three measures. 
 
Syntactic analysis statistics measure the quality 
of the determination of phrase boundaries, heads
p
 
a) For phrase boundaries, an overall score 
between 0.0 and 1.0 is re
Each phrase in the gold standard syntax output 
is compared to its closest match in the output 
under consideration.The output phrase that has 
the same label (NP, CL, etc.), the same head 
word, and the closest matching starting and 
ending points is used for the comparison. Each 
phrase is given the score:  
 - (|gstart - start| + |gend - end|)/(gend - gstart) 
where 
at the start of the phrase and start is the word
num
evaluated. Thus, if the gold standard phrase 
began at word 10 and ended at word 16, and the 
closest matching phrase in the output being 
evaluated began at word 9 and ended at word 
17, then the score for this phrase would be 1 -  
(|10 - 9| + |16 - 17|) / (16 - 10) = (1 - (2 / 6)) = 
2/3. If no matching phrase could be found (i.e. 
no overlapping phrase could be found with the 
same phrase label and head word), then a score 
of 0.0 is assigned. The score for the whole 
sentence under evaluation is the average of the 
scores for each of the phrases. 
 For phrase head determination, the standard 
(m/n) measure is used. For e
and head word that overlaps with the gold 
standard phrase.  
Attachment is also measured as (m/n). For 
each phrase in the gold standard syntax, the 
evaluation proced
speech, the same head word and the same 
constituents. For example, if the gold standard 
output has a PP attached to a NP, it will be 
shown to be a constituent of that NP. If the 
output being evaluated attaches the PP at a 
different constituent, then a mismatch will be 
identified. 
core between 0.0 and 1.0 is assigned for b and c 
follows: Score = m/(m+n). The Syntactic 
lysis Overa
a
 
Semantic analysis statistics measure the quality 
of word sense disambiguation (WSD) and semantic 
dependency
 
A) First, the standard match/mismatch (m/n) is 
used. Each TMR element in the gold standard 
semantic representati
arose. The TMR element in the semantic 
representation being evaluated that 
corresponds to that same word number is then 
compared with it.  
Second, the evaluation system produces a 
weighted score for WSD complexity. An 
overall score betwe
penalized less than a mismatch of a word with 
fewer senses. The score for each mismatch is 1 
- (2 / number-of-senses), if the word has more 
than 2 senses, and 0.0 if it has less than or 
equal to 2 senses. An exact match is given a 
score of 1.0. The overall score for the sentence 
is the average score for each TMR element.  
The system also computes a weighted score for 
WSD ?distance.? An overall score between 0.0 
and 1.0 is returned. A mismatch that 
penalized less than a mismatch that is 
ontologically ?far? from the correct semantics. 
The ontological distance is computed using the 
Ontosearch algorithm (Onyshkevych 1997)  
that returns a score between 0.0 and 1.0 
reflecting how close the two concepts are in 
the ontology, with a score of 1.0 indicating a 
Example Semantic Evaluation  perfect match. The overall score for the 
sentence is the average score of each TMR 
element. 
The quality of semantic dependency 
determination is computed using the standard 
(m/n) measur
 
We will now exemplify the evaluation of the 
semantic analysis of the sample sentence in 1:  
D) 
e. Each TMR element in the gold 
standard is compared to the corresponding 
 
1. Hall is scheduled to embark on the 12 hour 
overland trip to the Iraqi capital, Baghdad. 
 
 
Figure 4. Gold Standard Syntactic Analysis for a sample sentence. 
 
TMR element in the semantics being 
evaluated. Each property modifying the gold 
standard TMR element that is also in the 
evaluation TMR element increments the m 
count, each property in the gold standard TMR 
element that is not in the evaluation TMR 
element increments the n count.  The fillers of 
matching properties are also compared. If the 
filler of the gold standard property is another 
TMR element (as opposed to being a literal), 
then the filler is also matched against the 
corresponding filler in the semantic 
representation being evaluated, incrementing 
the m and n counters as appropriate. The 
relations between TMR elements is one of the 
central aspects of Ontological Semantics which 
goes beyond simple word sense 
disambiguation. This score reflects how well 
the dependency determination was performed. 
The analyzer produces the syntactic analysis 
shown in Figure 3. This analysis contains many 
spurious parses (along with the correct ones). The 
gold standard parse of this sentence is shown in 
Figure 4. The illustrations are difficult to read but 
the number of edges can be visually compared. 
 
In order to make an interesting evaluation example, 
we forced the semantic analyzer to misinterpret 
capital. The analyzer actually chose the correct 
sense, CAPITAL-CITY, but here we will force it to 
select the monetary sense, CAPITAL.  
 
We will now demonstrate the calculation and 
significance of the semantic evaluation parameters. 
 
A) Match/mismatch of TMR elements. In this 
example, there will be six matches and one 
mismatch ? the CAPITAL concept that should 
be CAPITAL-CITY. A score of 6/7 = 0.86 is also 
calculated for use in the overall semantic 
score. 
 
 
B) Weighted score for WSD complexity. The 
word capital has three senses in our English 
lexicon, corresponding to the CAPITAL-CITY, 
CAPITAL (i.e. monetary) and CAPITAL-
EQUIPMENT meanings. It will receive a score 
of 1 - 2/number-of-senses = 1 - 2/3 = 0.33. If 
there were two or less senses, it would have 
received a score of 0.0. If there were many 
senses of capital, its score would have been 
higher, reflecting the fact that there was a more 
complex disambiguation problem. The other 
six TMR elements receive a score of 1.0.  The 
total score for the sentence is therefore 6.33/7 
=0.90. 
         Figure 3: Syntactic Analysis of Sample Text  
 
A normalized score between 0.0 and 1.0 is 
calculated for a and d as follows: Score = 
m/(m+n).   
 
 
 
 
C) Weighted score for WSD distance. We 
determine the distance between the chosen 
eaning, 
-CITY, by submitting the concept pair 
 
(ontosearch capital capital-city) ? 0.525 
CT   
EED  
DEED   IS-A   DOCUMENT 
d to 
onnect the two concepts reflects this. So the score 
lysis of capital. In other cases, mismatched 
dependencies can arise by incorrect linking 
A score 
Our first evaluation run returned the results 
summarized in Tables 1 and 2. The motivation for 
was given in 
future evaluations, for 
stance, by using the corresponding components 
of the Stanford Lexicalized Parser (accessible from 
http://nl u/). 
 
 
meaning, CAPITAL, and the correct m
CAPITAL
to Ontosearch: 
PATH: 
CAPITAL   IS-A   FINANCIAL-OBJE
FINANCIAL-OBJECT   SUBCLASSES   D
DOCUMENT   PRODUCED-BY   NATION 
NATION   LOCATION-OF   CITY 
CITY   SUBCLASSES   CAPITAL-CITY 
 
Ontosearch returns a score between 0.0 and 1.0 
reflecting the closeness of the two concepts. An 
exact match would return a score of 1.0. 
Ontosearch also returns the path traversed to link 
the two concepts. In this case, the score returned is 
relatively low, and the ?strange? path neede
c
for this TMR element is 0.52. The other TMR 
elements in the sentence all receive a score of 1.0, 
so the score for the sentences is 6.52/7 = 0.93. 
 
D. Semantic dependency determination. In the 
example input, there are six links between TMR 
elements. Thus, the instance of SCHEDULE-EVENT 
has as its THEME the instance of TRAVEL-EVENT, 
which has an instance of CAPITAL as its 
DESTINATION, an instance of HUMAN as its AGENT 
and an instance of HOUR as its DURATION. CAPITAL 
is linked to NATION and CITY. Each link is checked 
against the gold standard. In this case, all six links 
match. This increments the dependecy match 
counter by  six. The fillers of the link, i.e. the TMR 
element that it points to, are also checked. For this 
example, the DESTINATION of the TRAVEL- EVENT 
should be CAPITAL-CITY, but it is CAPITAL. This 
increments the mismatch counter by one. The other 
five fillers match with the gold standard, thus the 
match counter is incremented by 5. For the whole 
sentence, the dependency matches will be 11 and 
the mismatches will be 1. In this case, the 
mismatched dependency was caused by the 
misana
between syntactic and semantic structures. 
of 11/12 = 0.92 is calculated for use in the overall 
score. 
4 Results of the First Evaluation Run 
the different statistics and runs 
Section 3.  
5 Discussion and Future Work 
The kind of evaluation that we have undertaken so 
far reflects our desire to understand the causes of  
less-than-maximum results, that is, to assign blame 
to the various components of the analyzer. The 
results clearly show that the preprocessor we have 
so far been using in the OntoSem system does not 
perform sufficiently well, and we will change the 
preprocessor for the 
in
p.stanford.ed
word count 204
sense count 604
syntactic  ambiguity 192
semantic  ambiguity   1.9 x 1017 
word sense ambiguity   4 .8 8  x 10
 
rmine their relative 
tility and contributions to the quality of semantic 
rates on selectional 
Table 1. The general statistics for the 
first evaluation run of OntoSem 
 
Our WSD evaluation environment differs from 
many WSD approaches in that it allows the ?none 
of the above? outcome for the cases when the 
lexicon entries do not fit the expectations in the 
text even after a measure of constraint relaxation. 
The count of incorrectly determined word senses 
includes the above eventuality but also the case 
when the current system has to select an answer 
from a set of candidates none of which can be 
preferred on the basis of available heuristics. For 
future evaluations, we plan to use the version of 
the analyzer with additional available means of 
ambiguity resolution incorporated (see Figure 2 for 
a brief listing). In fact, we will use different 
combinations of the procedures for residual 
ambiguity resolution and recovery from 
?unexpected? input to dete
u
analysis (not only WSD but also semantic 
dependency determination).  
 
The evaluation of semantic dependency 
determination is different from that suggested by 
Gildea and Jurafsky (2002) who designed a system 
to automatically learn the semantic roles of 
unknown predicates. First, that system does not  
actually do WSD; second, it makes assumptions 
that our work does not: it does not use any 
language-independent metalanguage to record 
meaning and concent
restrictions, a far more limited inventory than the 
set of all possible relations between concepts 
provided in our ontology. 
The evaluation environment we have developed 
reduces the amount of time necessary to produce a 
sense that it is a very important enabling element 
for larger-scale evaluation work that from this 
point on will become standard proc
gold standard output for each of the three stages of 
our analysis process quite dramatically. It is in this 
edure in our 
work on building semantic analyzers 
 
  Baseline 
A 
Baseline 
B As Is 
Correct  
Preprocessor 
Correct 
Syntax 
Abbreviations, numbers, etc. 3/2 3/2 3/2 5/0 5/0 
Named entities 14/10 14/10 14/10 24/0 24/0 
Parts of Speech 121/83 121/83 121/83 204/0 204/0 
Preprocessor Total 0.59 0.59 0.59 1.0 1.0 
Phrase boundary score 0.81 0.8 0.91 0.97 1.0 
Phrase heads 129/48 127/50 159/25 180/12 182/0 
Attachments 86/38 87/37 100/53 166/15 `81/0 
Syntax Total 0.74 0.77 0.81 0.94 1.0 
WSD 57/54 59/52 63/48 86/25 98/15 
WSD complexity 0.61 0.62 0.64 0.85 0.96 
WSD distance 0.79 0.80 0.83 0.92 0.96 
Semantic dependencies 104/182 113/173 136/150 198/88 229/43 
 
Table 2. Results of the initial evaluation of the OntoSem semantic analyzer. 
References  
ephen Beale, Sergei Nirenburg and Marjorie 
McShane. 2003. Just-in-time grammar. 
Proceedings of the 2003 Internation
St
al 
Gi y. 2002. Automated 
Se
ings of HLT-NAACL-03 
Se ictor Raskin. 2004 
On
r knowledge-based 
text processing. Unpublished PhD Dissertation. 
Carnegie Mellon University. 
 
Multiconference in Computer Science and 
Computer Engineering, Las Vegas, Nevada.  
ldea, Dan and Dan Jurafsk
labeling of semantic roles. Computational 
Linguistics 28(3): 245-288 
rgei Nirenburg, Marjorie McShane and Stephen 
Beale. 2003. Operative strategies in Ontological 
Semantics. Proceed
Workshop on Text Meaning, Edmonton, Alberta, 
Canada, June 2003. 
rgei Nirenburg and V
(forthcoming). Ontological Semantics, the MIT 
Press, Cambridge, Mass.  
yshkevych, Boyan 1997. Ontosearch: Using an 
ontology as a search space fo
Question Answering Using Ontological Semantics 
Stephen BEALE, Benoit LAVOIE, Marjorie MCSHANE, Sergei NIRENBURG,Tanya KORELSKY 
 
Institute for Language and Information 
Technologies (ILIT-UMBC) 
1000 Hilltop Circle 
Baltimore, MD, USA 21250 
{sbeale,marge,sergei}@umbc.edu 
CoGenTex, Inc. 
840 Hanshaw Rd, Suite 1 
Ithaca, NY, USA, 14850 
{benoit,tanya}@cogentext.com 
 
Abstract 
This paper describes the initial results of an 
experiment in integrating knowledge-based 
text processing with real-world reasoning in a 
question answering system. Our MOQA 
?meaning-oriented question answering? 
system seeks answers to questions not in open 
text but rather in a structured fact repository 
whose elements are instances of ontological 
concepts extracted from the text meaning 
representations (TMRs) produced by the 
OntoSem text analyzer. The query 
interpretation and answer content formulation 
modules of MOQA use the same knowledge 
representation substrate and the same static 
knowledge resources as the ontological 
semantic (OntoSem) semantic text analyzer. 
The same analyzer is used for deriving the 
meaning of questions and of texts from which 
the fact repository content is extracted. 
Inference processes in question answering rely 
on ontological scripts (complex events) that 
also support reasoning for purely NLP-related 
purposes, such as ambiguity resolution in its 
many guises. 
1 The Task 
People would have no problem answering 
questions like Has Tony Hall met with Umid 
Medhat Mubarak? ? provided they know who 
these two people are and have witnessed such a 
meeting or read about it. Even in the absence of 
overt evidence about such a meeting, people might 
conclude ? based on additional knowledge they 
might have about the protagonists ? that such a 
meeting could or might have taken place. Some 
current automatic question-answering (QA) 
systems might be able to answer such a question if 
they found a sentence like Tony Hall met with 
(saw, talked with) Umid Medhat Mubarak on July 
3, 2003 in Baghdad  in some text. But what if the 
text data was more typical, like, for instance, the 
following two excerpts: 
  
April 18, 2000  Associated Press. Representative 
Tony Hall, a Democrat from Ohio, arrived in 
Baghdad on a four-day visit to investigate the 
plight of Iraqi people under sanctions aimed at 
forcing the government of Iraq to give up its 
weapons of mass destruction? 
 
Umid Medhat Mubarak returned to Baghdad on 
April 17, 2000 after a visit to Jordan and plans to 
meet with a visiting US politician. 
 
To the best of our knowledge, no current system 
can input the above texts and return a reasoned 
response about the likelihood of a meeting between 
Tony Hall and Mubarak. But in a realistic 
environment there are even further complications. 
What if the first text was in English and the second 
in Arabic? Will the system be able to make even a 
tentative connection between Tony Hall (in the 
first text) and US politician (in the second)? What 
if the reference to US politician was omitted; i.e. if 
the second text contained only the information that 
Umid Medhat Mubarak was in Baghdad on April 
17, 2000? The system would have to infer the 
possibility of a meeting on the basis of knowledge 
about (at least) the social and professional 
background of the protagonists and the times 
involved. 
This paper describes a system that is able to 
make connections and inferences such as the 
above. Its most important properties are question 
answering against structured data stored in a fact 
repository (FR) and the fact that it uses the same 
processing machinery and knowledge resources a) 
to process texts for conversion into facts, b) to 
understand questions and c) to find answers to 
questions. We describe the underlying technology 
that supports such a capability, including the 
production of text meaning representations 
(TMRs), reference and date resolution, fact 
extraction and retrieval, and event scripts that 
allow us to infer (with some degree of probability) 
certain events or states not directly stated in any 
text. 
2 The Environment for QA 
Our question answering system consists of four 
main and one auxiliary processing modules (see 
Figure 1). The question analysis module takes as 
input the text of a user?s question and produces its 
text meaning representation (TMR, see below 
for an illustration) that contains representations of 
instances of ontological concepts to which the 
input refers plus speaker-attitude and 
communicative information. The TMR is input to 
the question interpretation module that interprets 
the question in terms of its type and transforms it 
into a formal query against the fact repository or 
the ontology (see below). (Note that the format of 
the database query is the same as that of the 
question TMR. In general, all internal 
representations of knowledge in our system, both 
elements of knowledge support and results of 
actual processing, are compatible with the content 
and format of the ontology and fact repository.)  
a
p
c
t
m
t
f
a
k
t
c
w
i
C
s
W
m
g
a
p
q
i
implementation simply returns fragments of facts 
(and fact reasoning chains) that answer the initial 
question. In the future, natural language generation 
will be employed to produce textual responses. 
In order to answer complex questions in context, 
a system must extract, manipulate and generate the 
meaning of natural language texts. Question 
answering against a structured knowledge base, 
especially when the latter contains interpretable 
knowledge elements (e.g., instances of events and 
objects defined in an ontology, not uninterpreted 
text strings), can attain better results than QA that 
works by manipulating templates filled with 
snippets of actual texts ? at the least because of the 
added benefit of disambiguation and reference 
resolution. The prerequisite for such a system is 
the existence of a structured knowledge base used 
as a source of answers to questions. In a real 
application, the knowledge must be ample and 
dynamic, so that the knowledge resources must be 
constantly and promptly augmented. This is not 
practical if knowledge is acquired entirely by 
people. Automating structured knowledge 
acquisition from open text is, therefore, a 
necessary condition for the success of an advanced 
QA application. The CSK module of our system is Figure 1. The top-level architecture of the 
system. 
Thus, text meaning representation in our 
pproach ?doubles? as the basis for reasoning 
rocesses. The query serves as input to answer 
ontent determination. This latter module uses 
he knowledge resources of the system to infer the 
ost preferred answer, once again, formulated in 
he TMR metalanguage. If an answer cannot be 
ound, the system has the option to call the 
uxiliary module for creating structured 
nowledge, CSK. The CSK module works also in 
he background mode, using text sources to 
ontinuously update the fact repository (in the 
ork reported here there has been some human 
nvolvement in the process of TMR production for 
SK; we plan to study the degradation of the 
ystem when used in a fully automatic mode). 
hen called by the answer content determination 
odule, the CSK module analyzes texts and 
enerates entries in the fact repository that help to 
nswer the original question. The text analysis 
rocess in this module is the same as that used in 
uestion analysis. The final module in the system 
s answer formulation. The current 
a step toward this functionality, albeit not yet in a 
fully automatic way. At this point, we rely on 
TMRs that are obtained automatically but 
improved through human interaction (see 
Nirenburg et al 2004 for details). Note that fully 
automatic methods for creating structured 
knowledge of a quality even remotely approaching 
that needed to support realistic QA do not at this 
point exist. Few of the numerous current and 
recent machine learning and statistical processing 
experiments in NLP deal with the analysis of 
meaning at all; and those that do address partial 
tasks (e.g., determining case role fillers in terms of 
undisambiguated text elements in Gildea and 
Jurafsky 2002) in a rather ?knowledge-lean? 
manner. The results are very far away indeed from 
either good quality or good coverage, either in 
terms of phenomena and text. We believe that our 
approach, using as it does statistical as well as 
recorded-knowledge evidence for extracting, 
representing and manipulating meaning is the most 
practical and holds the most promise for the future. 
Indeed, it is not even as expensive as many people 
believe. 
3 The Knowledge Support Infrastructure 
The process of deriving TMRs from text is 
implemented in our Ontosem text analyzer. 
Semantic analysis in OntoSem is described in 
some detail in Nirenburg and Raskin 2004; 
Nirenburg et al, 2004; Beale et al 1995, 1996, 
2003; Mahesh et al 1997. Our description here 
will be necessarily brief.  Also note that the 
analysis process is described here as if it were a 
strict pipeline architecture; in reality, semantic 
analysis is used to inform and disambiguate 
syntactic analysis, for example, in cases of 
prepositional phrase attachment.  
Text analysis in OntoSem relies on the results of 
a battery of pre-semantic text processing modules. 
The preprocessor module deals with mark-up in 
the input text, finds boundaries of sentences and 
words, recognizes dates, numbers, named entities 
a l 
a
g
t
e
l
s
o
c
a
c
o
(
t
c
d
d
i
a
m
a
produced in OntoSem using a variety of 
?microtheories,? to produce extended TMRs. At 
both steps, the analyzer has to deal with ambiguity, 
incongruity between the input and the expectations 
recorded in the static knowledge sources (SKSs), 
unknown words, and non-literal language. In a 
recent evaluation, the basic analyzer was shown to 
carry out word sense disambiguation at over 90% 
and semantic dependency determination at 87% on 
the basis of correct syntactic analysis and on 
sentences of an average length of over 25 words 
with 1.33 unknown words on average per input 
sentence (see Nirenburg et al, 2004). While not nd acronyms and performs morphologicanalysis. Once the morphological analyzer has 
enerated the citation forms for word forms in a 
ext, the system can activate the relevant lexical 
ntries in its lexicons, including the onomasticon (a 
exicon of proper names). Figure 2 presents a 
ample of preprocessor output.  
Figure 2: Sample preprocessor output 
Figure 3: Sample parser output, in graphical
The task of syntactic analysis (see Figure 3) in 
ntological semantics is, essentially, to determine 
lause-level dependency structures for an input text 
nd assign grammatical categories to clause 
onstituents (that is, establish subjects, direct 
bjects, oblique objects and adjuncts). 
 
Semantic analysis proper uses the information 
mutual constraints) in the active lexicon entries, 
he ontology and the results of earlier processing to 
arry out, at the first step, word sense 
isambiguation and establish basic semantic 
ependencies in the text. The results are recorded 
n basic TMRs (see below). At the next step, the 
nalyzer determines the values of the various 
odalities, aspect, time, speech acts, speaker 
ttitudes and other knowledge elements that are 
perfect, these results show promise as training data 
for machine learning work.  
The OntoSem ontology provides a 
metalanguage for describing the meaning of the 
lexical units in a language as well as for the 
specification of meaning encoded in TMRs. The 
ontology contains specifications of 
concepts corresponding to classes of 
things and events in the world. It is a 
collection of frames, or named sets of 
property-value pairs, organized into a 
hierarchy with multiple inheritance. The 
expressive power of the ontology and the TMR is 
enhanced by multivalued fillers for properties, 
implemented using the ?facets? DEFAULT, SEM, 
VALUE, and RELAXABLE-TO, among others. At the 
time of this writing, the ontology contains about 
6,000 concepts (events, objects and properties), 
with, on average, 16 properties each. Temporally 
and causally related events are encoded as values 
of a complex event?s HAS-EVENT-AS-PART 
property. These are essentially scripts that provide 
information that is very useful in general reasoning 
as well as reasoning for NLP (e.g., Schank and 
Abelson 1977, Lin and Hovy 2000, Clark and 
Porter 2000). We use scripts in the answer content 
determination module of the question answering 
system. Figure 4 illustrates a rather simple script 
that supports reasoning for our example question 
answering session.  
     The OntoSem lexicon contains not only 
semantic information, it also supports 
morphological and syntactic analysis. 
Semantically, it specifies what concept, concepts, 
property or properties of concepts defined in the 
ontology must be instantiated in the TMR to 
account for the meaning of a given lexical unit of 
input. At the time of writing, the latest version of 
the English semantic lexicon includes over 12,000 
handcrafted entries. These entries cover some of 
the most complex lexical material in the language 
? ?closed-class? grammatical lexemes such as 
conjunctions, prepositions, pronouns, auxiliary and 
modal verbs, etc. as well as about 3,000 of the 
For lack of space, we will not be able to discuss 
all the representational and descriptive devices 
used in the lexicon or the variety of ways in which 
semantic information in the lexicon and the 
ontology can interact. See Nirenburg and Raskin 
(2004, Chapters 7 and 8) for a discussion.  
MEET-WITH     
  (AGENT (VALUE $VAR1))     
  (THEME (VALUE $VAR2))     
  (LOCATION (VALUE $VAR3))     
  (TIME(VALUE $VAR4))     
 
 PRECONDITIONS     
  (AND         
  (LOCATION           
    (DOMAIN (VALUE $VAR1))           
    (RANGE (VALUE $VAR3))           
    (TIME (VALUE $VAR4)))        
  (LOCATION          
    (DOMAIN (VALUE $VAR2))         
    (RANGE (VALUE $VAR3))          
    (TIME (VALUE $VAR4))))     
 
 EFFECTS      
 (SPEECH-ACT        
   (AGENT (VALUE $VAR1))          
   (BENEFICIARY (VALUE $VAR2)))       
 (SPEECH-ACT        
   (AGENT (VALUE $VAR2))       
   (BENEFICIARY (VALUE $VAR1))) 
 
 
COME   
  (AGENT (VALUE $VAR1))   
  (DESTINATION (VALUE $VAR2))     
 
 EFFECTS     
 (LOCATION     
    (DOMAIN (VALUE $VAR1))      
   (RANGE (VALUE $VAR2))) 
 
 
LOCATION  
  (DOMAIN (VALUE $VAR1))  
  (RANGE (VALUE $VAR2))    
 
 EFFECT-OF     
 (COME       
   (AGENT (VALUE $VAR1))       
   (DESTINATION (VALUE $VAR2))) 
 
Figure 4: A sample script,  
presented in a simplified  
presentation format. 
The English onomasticon (lexicon of proper 
names) currently contains over 350,000 entries 
semantically linked to ontological concepts; it is 
increasing in size daily by means of semi-
automated knowledge-extraction methods. 
The TMR (automatically generated but shown 
here in a simplified presentation format) for a short 
sentence (He asked the UN to authorize the 
war) from a recently processed text about Colin 
Powell is presented below. The numbers associated 
with the ontological concepts indicate instances of 
those concepts: e.g., REQUEST-ACTION-69 means 
the 69th time that the concept REQUEST-ACTION has 
been instantiated in the world model used for, and 
extended during, the processing of this text or 
corpus.  
 
REQUEST-ACTION-69  
    AGENT   HUMAN-72  
    THEME   ACCEPT-70  
    BENEFICIARY   ORGANIZATION-71  
    SOURCE-ROOT-WORD  ask  
    TIME     (< (FIND-ANCHOR-TIME))  
ACCEPT-70  
   THEME   WAR-73  
   THEME-OF   REQUEST-ACTION-69  
   SOURCE-ROOT-WORD   authorize 
ORGANIZATION-71  
   HAS-NAME   UNITED-NATIONS 
   BENEFICIARY-OF     REQUEST-ACTION-69  
   SOURCE-ROOT-WORD  UN 
HUMAN-72  
   HAS-NAME  COLIN-POWELL 
   AGENT-OF   REQUEST-ACTION-69  
   SOURCE-ROOT-WORD   he ; ref. resolution done 
WAR-73  
   THEME-OF     ACCEPT-70  
    SOURCE-ROOT-WORD  war  
most frequent main verbs. We illustrate the 
structure of the lexicon entry on the example of the 
first verbal sense of alert: 
 
alert-v1      
  cat    v   
  morph  regular     
  ex     "He alerted us to the danger" The above says that there is a REQUEST-ACTION 
event whose agent is HUMAN-72 (Colin Powell), 
whose beneficiary is ORGANIZATION-71 (United 
Nations) and whose THEME is an ACCEPT event. 
That ACCEPT event, in turn, has the THEME WAR-
73. Note that the concept ACCEPT is not the same 
as the English word accept: its human-oriented 
definition in the ontology as ?To agree to carry out 
an action, fulfill a request, etc?, which fits well 
here.  
  syn-struc 
    subject   $var1          
 root    "alert" 
     indirectobject  $var2  
     pp   (opt +) 
    root  "to"  
  object $var3          
  sem-struc 
     WARN      
    agent   ^$var1   
      beneficiary  ^$var2 
      theme   ^$var3 
The Fact Repository contains a list of 
remembered instances of ontological concepts. For 
 
ex the 
co ies 
for
on
rep
dif
ins
ea
typ
are
un
en
4 
de
mo
Int
Fig
ex
qu
an
an
The TMR of the question, the result of the 
Question Analysis module, is displayed in the ample, whereas the ontology contains 
ncept CITY, the fact repository contains entr
 London, Paris and Rome; and whereas the 
tology contains the concept WAR, the fact 
ository contains the entry WWII. The main 
ference between an ontological concept and its 
tance is the nature of the fillers of properties for 
ch. In the former, the fillers of properties are, 
ically, overridable constraints; in the latter, they 
 actual values (when known), or they are left 
filled when not known. A simple fact repository 
try is illustrated below: 
 
HUMAN-33599 
 NAME George W. Bush  
 ALIAS  
 George Bush,  
Figure 5: Querying about a known person.
  President Bush,  
 George W,  
 the president of the United States,  
 the US president 
 SOCIAL-ROLE  PRESIDENT 
 GENDER        male 
 NATIONALITY        NATION-213 ;(USA)  
 DATE-OF-BIRTH July 6, 1946 
 spouse  human-33966 ;Laura Bush 
The Question Answering Modules 
Referring back to Figure 1, we now will briefly 
scribe the three central question answering 
dules of Question Analysis, Question 
erpretation and Answer Content Determination.  
ure 5 shows a question answering session that 
emplifies these three stages. The user enters a 
estion in the ?Natural Language Query? text box 
d clicks on the ?Submit? button. The OntoSem 
alyzer is then invoked to analyze the question. 
Query Analysis Details box. Obviously, not many 
of the details can be seen in these figures, but in 
the interface, the user can scroll through the TMR 
output. We will, in fact, be integrating our existing 
TMR and Fact graphical browsers into this 
interface in the near future. The results of the next 
module, Question Interpretation, are then displayed 
in the Query Paraphrase box. From there, the fact 
repository is queried, an answer is returned 
(perhaps utilizing the inference techniques to be 
described), and the supporting fact (or fact 
reasoning chain) is displayed in the Answer Details 
box. Below we present three example sessions, the 
third of which will be the basis for the more 
detailed description of the three modules. 
For this discussion, we concentrate on the 
following three sentences that have been processed 
by the CSK module and the facts that were derived 
from them and stored in the fact repository (the 
facts are represented using instances of ontological 
concepts, of course): 
 
1. Tony Hall Met with Umid Medhat Mubarak. 
2. Tony Hall arrived in Baghdad (on Thursday). 
3. Ali Atwa was in Baghdad (on April 18 and 
later). 
 
In Figure 5, the question is ?Who is Tony Hall?? 
In its current state, the system simply finds and 
responds with the stored fact about Tony Hall, 
which includes the information about his arrival 
(the COME-1003 event derived from sentence 2) 
and the MEET-WITH-1001 event (derived from 
sentence 1). Figure 6 shows the results of the 
query, ?Did Tony Hall meet with Umid Medhat 
Mubarak?? A matching 
fact was found in the FR 
(derived from sentence 
1) and is displayed in the 
Answer Details. Figure 7 
presents a more complex 
case. The query is ?Did 
Tony Hall meet with Ali 
Atwa?? The FR contains 
no fact that can directly 
answer this question. 
The system uses facts 
from sentences 2 and 3 
to return the possible 
inference MEET-WITH-
??? (the tentative nature 
of the inference is 
marked by the -??? 
appended as the instance 
number; and in the 
Figure 6: Querying about a known event. 
future, we will also generate a numerical value 
reflecting the confidence level of the inferences 
and sub-inferences). The supporting reasoning 
chain is also displayed. We will now use this 
example to discuss the three main question 
answering modules. 
The Question Analysis module takes the input 
text question and produces the TMR using the 
resources described in section 3 above. Figure 8 
illustrates the resulting TMR in a graphical 
browser. (One can inspect the content of the 
various concept instances ? e.g., OBJECT-56 ? by 
clicking on graphical objects representing them). 
The main thing to point out is that the TMR 
instantiates a MEET-WITH event which is the basis 
for querying the FR, itself comprised of facts 
represented by ontological concept instances. 
The Question Interpretation module then 
derives the canonical form of an 
input question TMR (determining 
question type and reformulating 
the content of an actual question 
in a standard format), and applies 
reference resolution. The answer 
displayed in Figure 7 involves 
reformulating the query Did $X 
meet with $Y? to Find meetings 
involving $X and $Y or more 
particularly, Find meetings where 
a person named $X is AGENT and 
a person named $Y is 
BENEFICIARY, and meetings 
where a person named $Y is 
AGENT and a person named $X is 
BENEFICIARY. Such a query can 
be specified as a standard DBMS 
query for the actual search. The knowledge that we 
are dealing with people and knowledge of their 
names is used to help resolve the references 
between the instances Tony Hall 
and Ali Atwa appearing in the 
query and the references to Tony 
Hall and Ali Atwa that may be 
stored in the fact repository. We 
will report on the actual methods 
of question interpretation and 
reference resolution we use 
separately.  
    The Answer Content 
Determination module is 
invoked next. The possible 
queries constructed in the 
previous module are processed. 
First, direct queries are attempted. 
If an answer is found, it is returned directly. In this 
example, no fact directly states that Tony Hall met 
Ali Atwa. Scripts are then activated which allow us 
to reason about the question. In the script of Figure 
4, the preconditions of a MEET-WITH event include 
both participants having to be in the same place at 
the same time. This will invoke a series of queries 
that will determine if Tony Hall and Ali Atwa were 
indeed in the same location at the same time. In 
general, if the preconditions of an event are 
satisfied, we infer that the event itself possibly 
took place. In this case, the fact that Ali Atwa was 
in Baghdad is present in the FR by virtue of 
sentence 3 above. Using this knowledge, the 
system seeks to prove that Tony Hall was also in 
Baghdad at the same time. Once again, there is no 
direct fact that states this. However, the facts about 
Tony Hall include information that he arrived in 
Baghdad at a certain time (at the present time, we 
do not attempt to match the times of the facts, 
although this will be a focus of our ongoing work). 
Figure 7: Querying about an unknown 
event. 
Matching times ofThis information is represented 
by the COME-1003 fact. We can look up COME in 
the script of Figure 4 and see that one effect of a 
COME event is that the agent?s location becomes 
the destination of the COME event. In general, we 
can use known facts to infer additional facts about 
their effects. In this case, we can infer that Tony 
Hall was, in fact, in Baghdad, which, in turn, 
allows us to make the top level inference that he 
might have met with Ali Atwa, who we previously 
determined was also in Baghdad. We are aware 
that the conjecture about the possible meeting 
should involve additional knowledge of the 
background and histories of the participants (e.g., 
if a cobbler and a head of state are in the same 
p a 
p g 
o e 
o
r
i
T
i
?
?
?
e
p
e
direct the inference process ? even we are fully 
aware of the abductive, defeasible nature of this 
knowledge.  
The inference steps described above were 
directed by the information in the MEET-WITH and 
COME scripts. Also, known facts about one of the 
participants, Tony Hall, were used to direct queries 
to support a possible inference. Obviously, much 
work remains to be done. We must populate a large 
fact repository that should include a large 
collection of facts about individuals as well as 
places, organizations and event instances. At this 
time, we are starting to use our TMR production 
environment for extracting facts. We hope to be 
able to report on the progress of this work at the 
workshop.  
5 Conclusion 
We have presented the first experiment with a 
knowledge-based QA system in which text 
processing is integrated with reasoning on the basis 
of shared knowledge and processing 
infrastructures. Indeed, the same processing and 
knowledge resources in the system carry out 
reasoning for the purposes of QA and reasoning 
that is necessary to create a high-quality 
unambiguous text meaning representation itself. 
While this is just a small experiment, we have 
specific and, we believe, realistic plans for scaling 
this system up ? through automatic population of 
the fact repository, semi-automatic enlargement of 
the lexicons and the ontology and expansion of the 
inventory of scripts.  
Figure 8. Sample output viewed through the 
TMR browser 
We believe that integrating a comprehensive 
throughput system for an advanced application, 
even one in which some of the modules are still on 
a relatively small scale, is a very important kind of 
work in our field. It tackles real problems head on, lace at the same time, that does not imply 
otential meeting between them). We are workin
n enhancing the knowledge (centered on th
ntological MEET-WITH script) to improve such 
eckoning.  
In a separate article in preparation, we will go 
nto much more detail about the reasoning process. 
here are obviously many additional issues, 
ncluding: 
 events. Our time resolution meaning 
procedures enable this; 
 Assigning probabilities to inferences. For 
example, if two people were in the same room, 
the possibility of their meeting is much higher 
than if they were in the same country; 
 Controlling the inference process. 
 
With regard to this last issue, the OntoSem 
nvironment provides a useful mechanism. In 
articular, the scripts that we are developing 
ncode expectations and are meant to constrain and 
without resorting to a rather defeatist ? though 
quite common in today?s NLP ? claim that certain 
goals are infeasible.  
References  
S. Beale, S. Nirenburg and K. Mahesh. 1995. 
Semantic analysis in the Mikrokosmos machine 
translation project. In Proceedings of the 2nd 
Symposium on Natural Language Processing, 
Kaset Sart University, Bangkok, Thailand.   
S. Beale, S. Nirenburg and K. Mahesh. 1996. 
Hunter-Gatherer: Three search techniques 
integrated for natural language semantics. In 
Proceedings of the 13th National Conference on 
Artificial Intelligence. Portland, OR.  
S. Beale, S. Nirenburg and M. McShane. 
2003. Just-in-time grammar. In Proceedings 
HLT-NAACL-2003, Edmonton, Canada. 
P. Clark and B. Porter. 2000. $RESTAURANT Ren-
visited: A KM implementation of a compositional 
approach. Technical Report, AI Lab, University 
of Texas at Austin.  
D. Gildea and D. Jurafsky. 2002. Automatic 
labeling of semantic roles. Computational 
Linguistics 28(3). 245-288.  
C. Lin and E. H. Hovy. 2000. The automated 
acquisition of topic signatures for text 
summarization. In Proceedings of the COLING 
Workshop on Text Summarization. Strasbourg, 
France. 
K. Mahesh, S. Nirenburg and S. Beale. 1997. If 
you have it, flaunt it: Using full ontological 
knowledge for word sense disambiguation. In 
Proceedings of Theoretical and Methodological 
Issues in Machine Translation (TMI-97). Santa 
Fe, NM. 
S. Nirenburg and V. Raskin. 2004. Ontological 
Semantics.  MIT Press. 
S. Nirenburg, M. McShane and S. Beale.  2004.  
Evaluating the performance of OntoSem.  In 
Proceedings ACL Workshop on Text Meaning 
and Interpretation, Barcelona. 
R. Schank and R. Abelson. 1977. Scripts, plans, 
goals, and understanding. Hillsdale, NJ: 
Erlbaum. 
 
OntoSem Methods for Processing Semantic Ellipsis  
Marjorie McShane, Stephen Beale and Sergei Nirenburg 
 
Institute for Language and Information Technologies 
University of Maryland Baltimore County 
{marge,sbeale,sergei}@umbc.edu 
 
 
Abstract 
This paper describes various types of semantic 
ellipsis and underspecification in natural lan-
guage, and the ways in which the meaning of 
semantically elided elements is reconstructed 
in the Ontological Semantics (OntoSem) text 
processing environment. The description cov-
ers phenomena whose treatment in OntoSem 
has reached various levels of advancement: 
fully implemented, partially implemented, and 
described algorithmically outside of imple-
mentation. We present these research results 
at this point ? prior to full implementation and 
extensive evaluation ? for two reasons: first, 
new descriptive material is being reported; 
second, some subclasses of the phenomena in 
question will require a truly long-term effort 
whose results are best reported in installments.  
1 
                                                          
Introduction 
Syntactic ellipsis ? the non-expression of syntactically 
obligatory elements ? has been widely studied in com-
putational (not to mention other branches of) linguistics, 
largely because accounting for missing syntactic ele-
ments is a crucial aspect of achieving a full parse, and 
parsing is required for many approaches to NLP.1 Much 
less attention has been devoted to what we will call se-
mantic ellipsis, or the non-expression of elements that, 
while not syntactically obligatory, are required for a full 
semantic interpretation of a text.2 Naturally, semantic 
ellipsis is important only in truly knowledge-rich ap-
1 Examples of NLP efforts to resolve syntactic ellipsis in-
clude Hobbs and Kehler 1997; Kehler and Shieber 1997; 
and Lappin 1992, among many others. 
2 Some of the types of semantic underspecification treated 
here are described in the literature (e.g., Pustejovsky 1995) 
in theoretical terms, not as heuristic algorithms. This is due, 
in large part, to a lack of knowledge sources for semantic 
reasoning in those contributions. 
proaches to NLP, which few current non-toy systems 
pursue. 
 All definitions of ellipsis derive from a stated or 
implied notion of completeness. Taking, again, the ex-
ample of syntactic ellipsis, this means that obligatory 
verbal arguments must be overt, auxiliary verbs must 
have complements, etc. ? all of which is defined in 
lexico-grammatical terms. But even if a text is devoid of 
syntactic gaps, much remains below the surface, easily 
interpretable by people but not directly observable.  
 Typical examples of semantically underspecified 
elements are pronouns and indexicals (e.g., here, now, 
yesterday), whose real-world anchors must be clarified 
in a fully developed semantic representation (i.e., yes-
terday has a concrete meaning only if one knows when 
today is). Pronouns and indexicals, though often diffi-
cult to resolve, have one advantage over the cases to be 
discussed here: the trigger that further semantic specifi-
cation need be carried out is the word itself, and the 
inventory of such words is well known.  
 By contrast, the semantically underspecified cases in 
the following examples are more subtle:  
 
(1) After boosting employment the past few years, 
Aluminum Co. of America won't be doing any 
hiring this fall beyond replacing those who leave. 
 
(2) Mitchell said he planned to work late tonight to 
complete the legislation. 
 
(3) Civilians invited into the prison by the admini-
stration to help keep the peace were unable to 
stanch the bloodshed. 
 
The categories of semantic ellipsis illustrated by these 
examples can be described as follows. (1) shows refer-
ence resolution that relies on the reconstruction of a 
semantically elided category: i.e., to understand who 
those refers to, one must understand that the implicit 
object of hire is ?employees?, and that the elided head of 
the NP with those as its determiner also refers to em-
ployees (albeit a different real-world set of employees). 
(2) illustrates semantic event ellipsis in configurations 
containing modal/aspectual + OBJECT: i.e., the meaning 
of complete the legislation is actually complete writing 
the legislation. (3) illustrates lexical patterns with pre-
dictable event ellipsis: e.g., invite <person> to  <loca-
tion> means ?invite someone to come/go to the 
location.? These examples, which illustrate the types of 
semantic ellipsis to be discussed below, require special 
treatment in our ontological semantic (OntoSem) text 
processing system, since its goal is to automatically 
produce fully specified semantic representations of un-
restricted text that can then be used in a wide variety of 
applications. 
2 
3 
A Snapshot of the OntoSem Environ-
ment 
OntoSem is a text-processing environment that takes  as 
input unrestricted raw text and carries out preprocess-
ing, morphological analysis, syntactic analysis, and se-
mantic analysis, with the results of semantic analysis 
represented as formal text-meaning representations 
(TMRs) that can then be used as the basis for many ap-
plications. Text analysis relies on:  
 
? The OntoSem language-independent ontology, which 
is written using a metalanguage of description and 
currently contains around 5,500 concepts, each of 
which is described by an average of 16 properties.  
? An OntoSem lexicon for each language processed, 
which contains syntactic and semantic zones (linked 
using variables) as well as calls to ?meaning proce-
dures? (i.e., programs that carry out procedural se-
mantics, see McShane et al forthcoming) when 
applicable. The semantic zone most frequently refers 
to ontological concepts, either directly or with prop-
erty-based modifications, but can also describe word 
meaning extra-ontologically, for example, in terms of 
modality, aspect, time, etc. The current English lexi-
con contains approximately 12K senses, including all 
closed-class items and the most frequent verbs, as in-
dicated by corpus analysis. 
? An onomasticon, or lexicon of proper names, which 
contains approximately 350,000 entries and is grow-
ing daily using automated extraction techniques.  
? A fact repository, which contains real-world facts 
represented as numbered ?remembered instances? of 
ontological concepts (e.g., SPEECH-ACT-3366 is the 
3366th instantiation of the concept SPEECH-ACT in the 
world model constructed during the processing of 
some given text(s)). 
? The OntoSem text analyzers, which cover preprocess-
ing, syntactic analysis, semantic analysis, and creation 
of TMRs. 
? The TMR language, which is the metalanguage for 
representing text meaning.  
 
 A very simple example of a TMR, reflecting the 
meaning of the sentence The US won the war, is as fol-
lows: 
WIN-3 
 AGENT  NATION-213 
 THEME  WAR-ACTIVITY-7 
  
This TMR is headed by a WIN event ? in fact, it is the 3rd 
instantiation of the concept WIN (WIN-3) in the world 
?snapshot? being built during the processing of the 
given text(s). Its agent is NATION-213, which refers to 
the United States of America in our fact repository. The 
theme of the event is the 7th instantiation of WAR-
ACTIVITY in this text. Details of this approach to text 
processing can be found, e.g., in Nirenburg and Raskin 
2004, Beale et al2003, Nirenburg et al2003a,b. The 
ontology itself, a brief ontology tutorial, and an exten-
sive lexicon tutorial can be viewed at 
http://ilit.umbc.edu. 
 Since OntoSem text processing attempts to do it all 
? meaning that any phenomenon in any language we are 
processing is within the purview of our approach ? work 
on any given problem is carried out in spiral fashion: 
first at a rough grain size, then at a finer grain size with 
each iterative improvement of the system. In order both 
to drive and to organize work, we develop a ?microthe-
ory? for each aspect of text processing we treat: e.g., we 
have microtheories of mood, time, reference resolution, 
and many more. One of the benefits of conceiving work 
on a given topic in terms of a microtheory is that con-
ceptual, algorithmic progress can occur separately from 
its realization in a specific application. This does not 
imply a disconnect between algorithms and implementa-
tions ? quite the opposite: all algorithms are devised for 
the OntoSem environment, relying on the types of 
knowledge and processing it can currently provide or 
realistically promises to provide. Within this frame-
work, a ?big picture? of long-term work on a given 
topic is often clarified before all details of implementa-
tion, or complete knowledge support, become available.  
 In this paper we present initial results of our work on 
the microtheory of semantic ellipsis and underspecifica-
tion, some of whose contributing phenomena can cur-
rently be well-handled in OntoSem and others of which 
will require long-term research and development efforts.  
Reference Resolution that Relies on the 
Reconstruction of a Semantically Elided 
Antecedent  
The reference resolution task in NLP has widely come 
to be understood in very narrow terms ? as linking pro-
nouns to their overt textual antecedents (a focus fueled 
by MUC and other similar competitions; see Sundheim 
1995). However, the scope of reference-related prob-
lems is actually much broader (see, e.g., McShane and 
Nirenburg 2002 and McShane forthcoming). In this sec-
tion we describe a number of cases in which reference 
resolution requires knowledge of semantically elided 
categories. That is, we are not talking simply about re-
covering a semantically elided category in its own right, 
we are talking about recovering it in order to support the 
correct analysis of another category in the text.  
 Consider the challenge of resolving the reference of 
those in example (1): After boosting employment the 
past few years, Aluminum Co. of America won't be do-
ing any hiring this fall beyond replacing those who 
leave. ?Those? refers to an unspecified set of employees. 
The ellipsis of the head noun employees (or any syno-
nym of it) is licensed by the fact that the notion of ?em-
ployees? is implicitly introduced into the discourse by 
the use of the word hire in the preceding clause (in the 
way described below). The real-world set of employees 
instantiated by the verb hire is not the same as the real-
world set of employees referred to by the ?those? NP. 
However, as this corpus-derived example shows, 
coreference at the level of concepts rather than instances 
can, in fact, license ellipsis.3 
 Most reference resolution programs  rely on shallow, 
stochastic methods and limit potential antecedents to 
overt textual elements; such programs would fail to re-
solve this case of reference. The OntoSem reference 
resolution programs, by contrast, include ontological 
knowledge in the search space of antecedents and, ac-
cordingly, can resolve such references. To make clear 
how this is done, a few more words about ontological 
specification and TMRs are necessary.  
 Fillers of properties in the OntoSem ontology can be 
concepts, literals, numbers or ranges of numbers. A 
small excerpt from the ontological specification of HIRE 
is as follows. 
 
HIRE 
     AGENT    sem    SOCIAL-ROLE  
      default   BUSINESS-ROLE 
        relaxable-to   CORPORATION 
     THEME  sem   SOCIAL-ROLE  
     LOCATION   sem   PLACE 
    default   BUILDING 
   
The fillers for ontological properties can be specified on 
various facets, including: sem, which indicates typical 
selectional restrictions; default, which indicates the de-
                                                          
3 It is noteworthy that many elliptical phenomena permit 
matching at the conceptual rather than instance-based level. 
For example, in Russian one can say the equivalent of They 
were selling stocks at a good rate so I bought, in which case 
the direct object of ?bought? is elided and understood to rep-
resent some subset of the original set of stocks being sold 
(see McShane forthcoming for details). 
fault filler(s), if any (i.e., this is more tightly constrained 
than sem); and relaxable-to, which shows acceptable 
relaxation of typical selectional restrictions. So, whereas 
the most typical AGENT of hiring is somebody in a busi-
ness role (children of BUSINESS-ROLE include MANAGER, 
CHAIRMAN, VP-CORPORATION and others) it is perfectly 
normal for any person in a social role to hire someone 
(e.g., I, as a homeowner, can hire a gardener), and even 
corporations can be metonymically said to hire people. 
As concerns the THEME of hiring, it is always a person 
in a social role, and no defaults or extensions to that 
specification are required. (Note that SOCIAL-ROLE is a 
child of HUMAN in the ontology.) 
 When a concept is instantiated in a TMR, its entire 
description becomes part of the TMR, and any property 
fillers actually provided by the text are indicated using 
the value facet. Fillers on the value facet are appended 
with an instance number, just like the main concept be-
ing instantiated. So an excerpt from the instantiation of 
HIRE (minus over a dozen properties that are not as-
signed specific values from the text) in the TMR for 
sentence (1) is as follows, with information explicit in 
the text shown in boldface: 
 
HIRE-47 
     AGENT sem    SOCIAL-ROLE  
    default   BUSINESS-ROLE 
       relaxable-to   CORPORATION 
   value   CORPORATION-4165 
     THEME sem   SOCIAL-ROLE  
  
In other words, the fact that certain properties of a con-
cept are not overtly mentioned in a text does not mean 
that the properties themselves or information about their 
typical fillers is stricken from the TMR: this information 
is available in the TMR, just as it is available to a per-
son when he is interpreting a text.  
 The OntoSem algorithm for resolving the reference 
of those can be briefly outlined as follows: 
 
1.  From the list of candidate antecedents that is gener-
ated during the processing of each sentence, ex-
clude those with incompatible grammatical features 
(in this case, those in the singular). 
2 Compare potential antecedents using (a) weighted 
heuristics of the same type as are used in most sto-
chastic reference resolution programs, based on fea-
tures such as text distance, grammatical function, 
etc, and (b) comparison of the semantic similarity 
between those (as suggested by the selectional re-
strictions imposed by its selecting verb) and each 
antecedent.  
 
The two key differences between our approach and sto-
chastic ones are that, for us, semantic comparison is a 
heavily weighted heuristic, and implicit properties of 
TMR-instantiated concepts are accessible in the search 
space. In example (1), this means that the THEME of 
HIRE, which is semantically specified as SOCIAL-ROLE, is 
a potential source of the semantics of those. Since there 
are no other viable candidates to supply the elided se-
mantic content, SOCIAL-ROLE will be understood as the 
conceptual head of the NP whose determiner is those. 
 Continuing with the example of HIRE, consider ex-
ample (4) which, like all examples cited in this paper, 
was drawn from a news corpus. 
 
(4) Although early placement statistics show that hiring 
by Wall Street has declined dramatically, students 
are not exactly flocking to the factory floor. For ex-
ample, preliminary statistics show that hiring by in-
vestment banks has been cut in half, from 22% of 
graduates in 1987 to 11% this year.  
 
The practical need for resolving the semantic ellipsis of 
the theme of hire in this passage becomes clear when 
one seeks to interpret the phrase from 22% of graduates 
in 1987 to 11% this year. Syntactically speaking, this 
phrase is difficult to parse, as it is appended to the main 
clause in a rather ?telegraphic? way: i.e., it is doubtful 
that most parsers have a rule to specifically target this 
sentence structure (ours does not). Interpreting this 
phrase relies primarily on semantics, i.e., an understand-
ing that the graduates are coreferential with the semanti-
cally elided object of hire.  
 In OntoSem, difficult cases of parsing are handled 
using what we call ?recovery? procedures. If a perfect 
parse cannot be arrived at in the initial run of the parser 
? where the most typical syntactic dependency struc-
tures are sought ? the parser can invoke several levels of 
recovery rules, as needed (see Beale et al 2003 for de-
tails). Among these recovery rules is the option to apply 
the semantics of a constituent to the nascent TMR with-
out recourse to its syntactic function. This type of re-
covery reflects our general desire to leverage semantic 
knowledge more and rely on syntax less.  
 An excerpt from the core of the TMR for the second 
sentence in (4) will look as follows (with COMMERCIAL-
BANK-8 representing the string investment banks):  
 
HIRE-50 
     AGENT  sem    SOCIAL-ROLE  
    default   BUSINESS-ROLE 
       relaxable-to   CORPORATION 
   value   COMMERCIAL-BANK-8 
     THEME sem   SOCIAL-ROLE  
 
And the TMR for the syntactically unattached compo-
nent, from 22% of graduates in 1987 to 11% this year, 
will look as follows (from and to have lexical senses 
that indicate the start-value and end-value of a range 
when their complement is a number): 
 
START-VALUE     
 DOMAIN  SOCIAL-ROLE-977 
      AGENT-OF  GRADUATE-COLLEGE 
 RANGE   .22 
 YEAR   1987 
 
END-VALUE 
 DOMAIN  SOCIAL-ROLE-978 
      AGENT-OF GRADUATE-COLLEGE 
 RANGE   .11 
 YEAR   find-anchor-year ; a call to a proce- 
        dural semantics program 
 
In short, the head of the core TMR expects a  SOCIAL-
ROLE as the THEME of HIRE, and the domain of the syn-
tactically unattached segment of the sentence is namely 
a SOCIAL-ROLE. The direct, and correct, hypothesis is to 
link the unattached TMR fragment namely to the filler 
of the THEME of HIRE, which is exactly what our seman-
tic analyzer does.  
 Cases in which semantically elided elements are 
crucial to the interpretation of other sentence elements 
are not rare. Another example taken from the same do-
main of hiring (we remain in this domain only for sim-
plicity of exposition) is shown in (5). 
 
(5) For one thing, in 20 states and the District of Co-
lumbia, it's illegal to discriminate in hiring or pro-
motions on the basis of marital status.  
 
In order to interpret the connection of marital status to 
the rest of the proposition, one must corefer the HUMAN 
in the DOMAIN of the concept MARITAL-STATUS to the 
implicit THEME of HIRE and PROMOTE.  
 
LEGALITY-ATTRIBUTE-4 
 DOMAIN sem   SOCIAL-EVENT 
    value  DISCRIMINATE-23 
 RANGE sem  YES, NO 
    value  NO 
 
DISCRIMINATE-23 
 AGENT  sem    HUMAN 
    relaxable-to  CORPORATION 
         ORGANIZATION 
 THEME sem    MENTAL-OBJECT 
    value    HIRE-65 
         PROMOTE-53 
 BENEFICIARY sem   HUMAN 
    relaxable-to  CORPORATION 
         ORGANIZATION 
 CAUSED-BY sem   EVENT 
     VALUE  MARITAL-STATUS-1 
 
 
MARITAL-STATUS-1 
 DOMAIN HUMAN 
 RANGE  SINGLE, MARRIED, WIDOWED, DIVORCED 
 
 As these examples show, there is a concrete, corpus-
attested need to resolve many instances of semantic 
ellipsis, namely, the need to use implicit information as 
the antecedent for coreferring categories. 
4 
                                                          
Semantic Event Ellipsis in Configura-
tions Containing a Modal/Aspectual + 
OBJECT  
In English and many other languages, modals and as-
pectuals can take nominal complements. Those com-
plements can, semantically, be of two types: OBJECTs 
and EVENTs. If the syntactic object semantically repre-
sents an EVENT, then there is no semantic ellipsis, as in 
The delegates began the conversation at noon, whose 
simplified TMR is as follows:  
 
SPEECH-ACT-35333 
 PHASE  begin 
 AGENT  DELEGATE-2223 
 TIME  12.00 
 
In other words, since conversation is mapped to the 
event SPEECH-ACT, it naturally has a PHASE and an 
AGENT and a TIME and there is no semantic ellipsis. Ex-
amples of this type are frequent in texts, as shown by 
examples (5)-(7): 
 
(5) Dataproducts has since started a restructuring that 
started the still-raging bidding wars  
 
(6) Nomura started a credit-card venture with Ameri-
can Express Co. 
 
(7) The spokesman said Maxicare hopes to complete 
the reorganization by early 1990 
 
 If the syntactic object semantically represents an 
OBJECT, then the semantics of the implied verb must be 
recovered. For OntoSem text processing, two subtypes 
of such cases are important: those in which the object 
refers to an institution, program, etc., and the elided 
verb predictably means ?initiate, found?, and those in 
which the object refers to something else and the verbal 
semantics must be inferred based on the meaning of the 
overt categories. Examples of the first subtype include 
the following:   
 
(8) She'll be the first one to leave it and start a fourth 
party. 
 
(9) Brazil started an ethanol program about 15 years 
ago. 
 
(10) Quebecor started the Philadelphia Journal. 
 
The OntoSem lexicon contains a number of lexical 
senses of start, finish, etc. that cover such cases: e.g., 
one sense specifies the THEME to be an ORGANIZATION, 
and heads the semantic description with the concept 
FOUND-ORGANIZATION; another specifies the THEME to 
be a MENTAL-OBJECT and heads the semantic description 
with INVENT (as in ?He started a new semantic theory?). 
This type of semantic ellipsis is discussed more fully in 
Section 5. 
 The second subtype requires procedural semantic 
analysis to recover the meaning of the implied event. 
Examples of such contexts include the following: 
 
(11) Mitchell said he planned to work late tonight to 
complete the legislation [elided WRITE]. 
  
(12) He conscripted 700,000 slaves to finish the Great 
Wall [elided BUILD]. 
 
(13) Most service businesses can complete their books 
within three weeks after a period has ended 
[elided BOOKKEEPING]. 
  
(14) Next Inc.... has finished the first version of its 
operating-system software [elided DESIGN-
SOFTWARE].  
 
(15) Manufacturers Hanover this week started a new 
series of ads that push "Power Savings" [elided 
BROADCAST].  
 
The OntoSem lexical sense that covers these contexts  
includes a procedural attachment called seek-event-
specification, which attempts to dynamically recover the 
meaning of the semantically elided events. That is, it 
seeks concepts for which the meaning of the subject and 
direct object provided in the text are most specifically 
constrained. For example, in (11), the program will seek 
an EVENT for which the default AGENT is SENATOR 
(Mitchell was a senator at the time4) and the default 
THEME is BILL-LEGISLATIVE; and in (12), the program 
4 We can expect that earlier in the text he was referred to us-
ing a more complete appellation which either overtly de-
scribed him as a senator or provided sufficient information 
for our reference-resolution program to link him to his fact-
repository entry, where his SOCIAL-ROLE of SENATOR is 
listed. Reference resolution using fact-repository informa-
tion has been implemented but not widely tested yet. The 
problem of identifying him as the same person that has just 
been elected Chairman of Disney is outside of the purview 
of this paper.  
will seek an EVENT for which AGENT is SLAVE and the 
default THEME is WALL (the basic ontological mapping 
of Great Wall, though a number of properties are de-
fined in its fact repository entry, like LOCATION: China, 
LENGTH: 5000 km). If more than one match is found, all 
options are retained in the TMR for possible later dis-
ambiguation based on further context. If no matches are 
found using the default facet, matches using the sem 
facet are sought. In the worst case (the maximal level of 
semantic relaxation), the only thing the semantic ana-
lyzer can say about the elided EVENT is that there is, 
indeed, an unspecified EVENT that has the text-specified 
AGENT and THEME. 
 Two points must be emphasized: a) the OntoSem 
lexicon records our expectations that dynamic semantic-
ellipsis resolution will be necessary in certain types of 
contexts, which can be specified based on reference to 
ontological types of OBJECTS; and b) the resolution of 
semantic event ellipsis is supported by the property-
defined relationships between ontological OBJECTs and 
EVENTs.  
5 Lexical Patterns with Predictable Event 
Ellipsis 
Ontological semantics has practical aims, which means, 
among other things, that extending the lexicon to in-
clude complex entities and thus bypass the need for 
their runtime compositional semantic treatment is a 
valid methodological option. A good case in point is the 
lexicalization of common cases of semantic ellipsis. 
Like any lexicalization, this does not offer full cover-
age; however, like all lexicalization, it does provide 
concrete information about concrete phenomena that 
can be immediately exploited. Here we present just a 
few examples of the lexicalized treatment of semantic 
ellipsis as an illustration of our omnivorous approach to 
improving the overall quality of text processing.  
 The verb invite, when followed by a prepositional 
phrase or adverb indicating location (or destination) 
directly or metonymically, actually means ?invite to 
come/go to that place?; the verb of motion is semanti-
cally elided. Examples include (16)-(19): 
  
(16) Civilians invited into the prison by the admini-
stration to help keep the peace were unable to 
stanch the bloodshed. 
 
(17) ?If they invited us back tomorrow to govern the 
mainland, frankly we would hesitate," Vice For-
eign Minister John H. Chang told a U.S. gover-
nor's delegation. 
 
(18) All 13 OPEC oil ministers were invited to the 
meeting. 
 
(19) He often is one of a handful of top aides invited 
into the Oval Office for the informal sessions at 
which President Bush likes to make sensitive for-
eign-policy decisions.  
 
The lexicon sense that covers this use of invite in (16) 
and (18) is as follows, in presentation format (the lexi-
con sense that covers (17) has an adverb of loca-
tion/destination instead of a PP): 
 
invite-v2 
  def  ?+ pp of destination, implies ?invite to come?? 
  ex ?She invited him to Paris? 
   
  syn-struc 
    subject      root $var1  cat n 
    v               root $var0 
    directobject   root $var2    cat n 
    pp-adjunct    root $var3    cat prep    
     root (or to onto into on) 
     obj     root $var4   cat n 
 
  sem-struc 
      INVITE  
   AGENT    value ^$var1 
  THEME    MOTION-EVENT 
      DESTINATION   value ^$var4 
      AGENT   value ^$var2 
 ^$var3  null-sem + 
 
The syntactic structure (syn-struc) says that this sense of 
like requires a subject, direct object and PP, and that the 
PP must be headed by the word to, onto, into or on. The 
semantic structure (sem-struc) is headed by an INVITE 
event, whose AGENT is the subject of the clause (note 
the linked variables) and whose theme is a MOTION-
EVENT. The AGENT and DESTINATION of the MOTION-
EVENT are the meanings of the direct object and preposi-
tional object, respectively, of the input clause. (We 
gloss over formal aspects of the entry that are tangential 
to the current discussion.) Note that there is no verb of 
motion in the input text: MOTION-EVENT is lexically 
specified since it is a predictable semantically elided 
aspect of meaning in the given configuration.  
 Another lexical item for which we can predict a par-
ticular type of semantic ellipsis is forget. When the di-
rect object of forget semantically represents a 
PHYSICAL-OBJECT, there is an elided TAKE event, as 
shown in (20). 
 
(20) ?This is the slowest day I've seen this year,? said 
Peter Canelo, a market strategist at Bear Stearns 
Cos. ?I've only had one call all day from a real 
investor and he just forgot his umbrella.? 
 
Thus, the OntoSem lexicon has a special sense for for-
get + PHYSICAL-OBJECT  that is selected by the semantic 
analyzer in contexts like (20). 
 Obviously, a lexicon that anticipates instances of 
semantic ellipsis must be quite detailed and, as a result, 
relatively expensive to build. The OntoSem lexicon falls 
into both of these categories. However, expensive does 
not mean prohibitive, and we believe that the ultimate 
utility of such a knowledge resource will fully justify its 
compilation. The rate of acquisition for open-class 
words and phrases in OntoSem depends primarily on the 
type of entity being acquired, be it argument-taking or 
not. A conservative estimate for lexical acquisition for 
OntoSem, based on a recent acquisition drive, is as fol-
lows: 
 
? acquisition of argument-taking word and phrase 
senses: 6 words/hr * 6 hrs./day * 5 days/week * 
50 weeks/yr = 9,000 senses/year 
? acquisition of non-argument-taking word and 
phrase senses (about 5 times as fast): 9000 * 5 = 
45,000 senses/year 
 
According to these estimates, and considering that many 
more words are non-argument-taking than are argu-
ment-taking, we might realistically expect to increase 
the size of the lexicon by around 100,000 senses per 
year if given 3 full-time acquirers supported by one full-
time ontology developer. In short, large volumes of 
high-quality knowledge can be achieved in real time.    
6 
7 
Evaluation 
In response to the current evaluation standards in NLP 
(which are more suited to and informative for stochas-
tic-based systems than knowledge-based ones), we have 
recently developed a novel evaluation methodology that 
assigns scores as well as blame for errors to various 
aspects of the TMRs generated during OntoSem text 
processing. While percentage scores for correct vs. in-
correct results can provide a general evaluation of sys-
tem function, it is blame assignment that drives 
development. Blame assignment is determined by proc-
essing each sentence multiple times: first without man-
ual intervention, then with the correction of 
preprocessor errors, then with the correction of syntax 
errors. The rationale behind these loops of correction 
and reevaluation is that ?low level? mistakes like pre-
processor errors or lack of coverage of some syntactic 
construction require different development action than 
more weighty (from our point of view) errors in seman-
tic interpretation that might result from gaps in knowl-
edge, insufficient reasoning engines, etc.  
 The first experiment with our new evaluation regime 
produced the following results (reported on in detail in 
Nirenburg et al 2004): the analyzer was shown to carry 
out word sense disambiguation at over 90% and seman-
tic dependency determination at 87% on the basis of 
correct syntactic analysis and on sentences of an aver-
age length of over 25 words with 1.33 unknown words 
on average per input sentence. Outstanding errors in 
semantic analysis were due, in most cases, to non-literal 
use of language (which is one of our topics of ongoing 
investigation). Although this first formal experiment 
was limited to WSD and semantic dependencies, testing 
of other modules ? like those for reference resolution 
and ellipsis ? will soon be added to the formal evalua-
tion regime. At this stage, evaluation work is slow, but 
we are well into the development of an evaluation and 
correction environment that promises to significantly 
speed up both evaluation and system enhancement. 
Closing Thoughts 
The type of work presented in this paper might be 
termed a practical, progressive long-term effort.  
 The work is practical because it is being carried out 
within a working system that: (a) uses non-toy, real text-
oriented knowledge resources ? lexical and ontological 
? that are being built not in the hope that someday some 
system might be able to use them, but because they are 
useful right now in the system under construction; (b) 
has processors that cover all levels of text analysis, from 
preprocessing raw input text to creating semantic text-
meaning representations of it; (c) has been and contin-
ues to be used in applications as diverse as machine 
translation, information extraction, summarization and 
question answering. In short, the work that we carry out 
on any given aspect of text processing answers a need 
encountered in real applications, and does so in a con-
crete, implemented and further implementable way.  
 The work is progressive in the sense that the loop of 
algorithm development and integration in each new ver-
sion of the working system is continuous. We find it 
important, tactically, to view issues in natural language 
from a broad perspective first, with development of 
practical ?microtheories? for their treatment progressing 
as need demands and resources permit. What we try not 
to do is artificially exclude from our purview those as-
pects of phenomena that are not easily treated at the 
present state of the art. Instead, we include such aspects 
in our algorithms to the degree possible and make sure 
that they are modified as soon as an advance is made in 
resource acquisition or algorithm fusion (e.g., incorpo-
rating stochastic methods if and when knowledge-based 
ones fail to produce a single, unambiguous semantic 
representation, as in the case of weighted heuristics for 
reference resolution). 
 The work is long term because we know that high-
quality text processing cannot be achieved in the short 
term. If a phenomenon exists in a language we are proc-
essing, it is, by definition, within our purview. Our ul-
timate aim: an intelligent agent able to communicate no 
less fluently than you or I and in possession of human-
level background knowledge about the world and lan-
guage. Of course, this goal will not be realized in our 
lifetimes, unless adequate resources are allocated to this 
task and its subtasks. However, a solid foundation that 
in principle can accommodate any and all later needs of 
language processing is what we are attempting to de-
velop while at the same time developing working appli-
cations. 
References 
 
Stephen Beale, Sergei Nirenburg and Marjorie 
McShane. 2003. Just-in-time grammar. Proceedings 
of the 2003 International Multiconference in Com-
puter Science and Computer Engineering, Las Ve-
gas, Nevada.  
Jerry R. Hobbs and Andrew Kehler. 1997. A theory of 
parallelism and the case of VP ellipsis. Proceedings 
of the 35th  Annual Meeting of the Association for 
Computational Linguistics, Madrid, Spain. 
Andrew Kehler and Stuart Shieber. 1997. Anaphoric 
dependencies in ellipsis. Computational Linguistics, 
23(3): 457-466. 
Shalom Lappin. 1992. The syntactic basis of ellipsis 
resolution. Proceedings of the Stuttgart Ellipsis 
Workshop, 1-47. 
Marjorie McShane. Forthcoming. A Theory of Ellipsis. 
Oxford University Press. 
Marjorie McShane, Stephen Beale and Sergei Niren-
burg.  Forthcoming.  Some meaning procedures of 
Ontological Semantics.  Proceedings of LREC 2004, 
Lisbon, Portugal.   
Marjorie McShane and Sergei Nirenburg. 2002. Refer-
ence and ellipsis in Ontological Semantics. Memo-
randa in Computer and Cognitive Science, MCCS-
02-329. The Computing Research Laboratory, New 
Mexico State University.   
Sergei Nirenburg, Marjorie McShane and Stephen 
Beale. 2003a. Enhancing recall in information ex-
traction through Ontological Semantics. Proceedings 
of the Workshop on Ontologies and Information Ex-
traction, Bucharest, Romania, August 2003. 
Sergei Nirenburg, Marjorie McShane and Stephen 
Beale. 2003b. Operative strategies in Ontological 
Semantics. Proceedings of HLT-NAACL-03 Work-
shop on Text Meaning, Edmonton, Alberta, Canada, 
June 2003. 
Sergei Nirenburg and Victor Raskin. 2004 (forthcom-
ing). Ontological Semantics, the MIT Press, Cam-
bridge, Mass.  
Sergei Nirenburg, Stephen Beale and Marjorie 
McShane. 2004. Evaluating the Performance of the 
OntoSem Semantic Analyzer. Submitted to ACL-
04. 
James Pustejovsky. The Generative Lexicon. The MIT 
Press, Cambridge, Mass. 
Roger Schank and Robert Abelson. 1977. Scripts, 
Plans, Goals, and Understanding: An Inquiry into 
Human Knowledge Structures. L. Erlbaum Associ-
ates, New York. 
Beth Sundheim. 1995. The MUC coreference task defi-
nition v. 3.0. Proceedings of the 6th Message Under-
standing Conference. 
Proceedings of the Workshop on Frontiers in Corpus Annotation II: Pie in the Sky, pages 68?75,
Ann Arbor, June 2005. c?2005 Association for Computational Linguistics
Semantically Rich Human-Aided Machine Annotation 
 
Marjorie McShane, Sergei Nirenburg, Stephen Beale, Thomas O?Hara 
Department of Computer Science and Electrical Engineering 
University of Maryland Baltimore County 
1000 Hilltop Circle, Baltimore, Maryland, 21250   USA 
{marge, sergei, sbeale, tomohara}@umbc.edu 
 
Abstract 
This paper describes a semantically rich, 
human-aided machine annotation system 
created within the Ontological Semantics 
(OntoSem) environment using the 
DEKADE toolset. In contrast to main-
stream annotation efforts, this method of 
annotation provides more information at a 
lower cost and, for the most part, shifts 
the maintenance of consistency to the sys-
tem itself. In addition, each tagging effort 
not only produces knowledge resources 
for that corpus, but also leads to im-
provements in the knowledge environ-
ment that will better support subsequent 
tagging efforts.  
1 Introduction 
Corpus tagging is a prerequisite for many machine 
learning methods in NLP but has the drawbacks of 
high cost, inter-annotator inconsistency and the 
insufficient treatment of meaning. A tagging ap-
proach that strives to ameliorate all of these draw-
backs is semantically rich, human-aided machine 
annotation (HAMA), implemented in the OntoSem 
(Ontological Semantics) environment using a tool-
set called DEKADE: the Development, Evaluation, 
Knowledge Acquisition and Demonstration Envi-
ronment of OntoSem. 
In brief, the OntoSem text analyzer takes as in-
put open text and outputs a text-meaning represen-
tation (TMR) that represents its meaning using an 
ontologically grounded, language-independent 
metalanguage (see Nirenburg and Raskin 2004). 
Since the processing leading up to the production 
of TMR includes, in addition to semantic analysis 
proper, preprocessing (roughly, segmentation, 
treatment of named entities and morphology) and 
syntactic analysis, the overall annotation of text in 
this approach includes tags relating to all of the 
above levels. Since the typical input for analysis in 
our practice is genuine sentences, which are on 
average 25 words long and contain all manner of 
complex phenomena, it is not uncommon for the 
automatically generated TMRs to contain errors. 
These errors?which can occur at the level of pre-
processing, syntactic analysis or semantic analy-
sis?can be corrected manually using the 
DEKADE environment, yielding ?gold standard? 
output. Making a human the final arbiter in the 
process means that such long-term complexities as 
treatment of metaphor, metonymy, PP-attachment, 
difficult cases of reference resolution and others 
can be resolved locally while we work on funda-
mental, implementable automatic solutions.  
In this paper we describe the Onto-
Sem/DEKADE environment for the creation of 
gold standard TMRs, which supports the first ever 
annotation effort that:  
 
? produces structures that can be used as input 
for both text generators and general reason-
ing systems: semantically rich representa-
tions of the meaning of text written in a 
language-independent metalanguage; these 
representations cover entities, propositions, 
relations, attributes, speaker attitudes, mo-
dalities, polarity, discourse relations, time, 
reference relations, and more; 
? produces semantic tagging of text largely 
automatically, thus making more realistic 
and affordable the tagging of large amounts 
of text in finite time; 
? almost fully circumvents the pitfalls of man-
ual tagging, including human tagger errors 
and inconsistencies;  
? produces richer semantic annotations than 
manual tagging realistically could, since ma-
nipulating large and complex static knowl-
68
edge sources would be impossible for hu-
mans if starting from scratch (i.e., our meth-
odology effectively turns an essay question 
into a multiple choice one, with most of the 
correct answers already provided); 
? incorporates humans as final arbiters for out-
put of three stages of text analysis (preproc-
essing, syntactic analysis and semantic 
analysis), thus maximally leveraging the 
automated capacity of the system but not re-
quiring of it blanket coverage at this point in 
its development; 
? promises to reduce, over time, the depend-
ence on human input because an important 
side effect of the operation of the human-
assisted machine annotation approach is en-
hancement of the static knowledge resources 
? the lexicon and the ontology ? underlying 
the OntoSem analyzer, so that the quality of 
automatic text analysis will grow as the 
HAMA system operates, leading to an ever 
improving quality of raw, unedited TMRs; 
? (as a corollary to the previous point) be-
comes more cost-efficient over time; and 
? can be cost-effectively extended to other 
languages (including less commonly taught 
languages), with much less work than was 
required for the first language since many of 
the necessary resources are language-
independent. 
 
Our approach to text analysis is a hybrid of 
knowledge-based and corpus-based, stochastic 
methods.   
In the remainder of the paper we will briefly de-
scribe the lay of the land in text annotation (Sec-
tion 2), the OntoSem environment (Section 3), the 
DEKADE environment for creating gold-standard 
TMRs from automatically generated ones (Section 
4), the portability of OntoSem to other languages 
(Section 5), and the broader implications of this 
R&D effort (Section 6).   
2 The Lay of the Land in Annotation 
In addition to the well-known bottlenecks of cost 
and inconsistency, it is widely assumed that low-
level (only syntactic or ?light semantic?) tagging is 
either sufficient or inevitable due to the complexity 
of semantic tagging. Past and ongoing tagging ef-
forts share this point of departure. 
Numerous projects have striven to achieve text 
annotation via a simpler task, like translation, 
sometimes assuming that one language has already 
been tagged (e.g., Pianta and Bentivogli 2003, and 
references therein). But results of such efforts are 
either of low quality, light semantic depth, or re-
main to be reported. Of significant interest is the 
porting of annotations across languages: for exam-
ple, Yarowsky et al 2001 present a method for 
automatic tagging of English and the projection of 
the tags to other languages; however, these tags do 
not include semantics. 
Post-editing of automatic annotation has been 
pursued in various projects (e.g., Brants 2000, and 
Marcus et al 1993). The latter group did an ex-
periment early on in which they found that ?man-
ual tagging took about twice as long as correcting 
[automated tagging], with about twice the inter-
annotator disagreement rate and an error rate that 
was about 50% higher? (Marcus et al 1993). This 
conclusion supports the pursuit of automated tag-
ging methods. The difference between our work 
and the work in the above projects, however, is 
that syntax for us is only a step in the progression 
toward semantics. 
 Interesting time- and cost-related observations 
are provided in Brants 2000 with respect to the 
manual correction of automated POS and syntactic 
tagging of a German corpus (semantics is not ad-
dressed). Although these tasks took approximately 
50 seconds per sentence, with sentences averaging 
17.5 tokens, the actual cost in time and money puts 
each sentence at 10 minutes, by the time two tag-
gers carry out the task, their results are compared, 
difficult issues are resolved, and taggers are trained 
in the first place. Notably, however, this effort 
used students as taggers, not professionals. We, by 
contrast, use professionals to check and correct 
TMRs and thus reduce to practically zero the train-
ing time, the need for multiple annotators (pro-
vided the size of a typical annotation task is 
commensurate with those in current projects), and 
costly correction of errors.  
Among past projects that have addressed se-
mantic annotation are the following: 
 1. Gildea and Jurafsky (2002) created a stochas-
tic system that labels case roles of predicates with 
either abstract (e.g., AGENT, THEME) or domain-
specific (e.g., MESSAGE, TOPIC) roles. The system 
69
trained on 50,000 words of hand-annotated text 
(produced by the FrameNet project). When tasked 
to segment constituents and identify their semantic 
roles (with fillers being undisambiguated textual 
strings) the system scored in the 60?s in precision 
and recall. Limitations of the system include its 
reliance on hand-annotated data, and its reliance on 
prior knowledge of the predicate frame type (i.e., it 
lacks the capacity to disambiguate productively). 
Semantics in this project is limited to case-roles.  
 2. The goal of the ?Interlingual Annotation of 
Multilingual Text Corpora? project 
(http://aitc.aitcnet.org/nsf/iamtc/) is to create a syn-
tactic and semantic annotation representation 
methodology and test it out on six languages (Eng-
lish, Spanish, French, Arabic, Japanese, Korean, 
and Hindi). The semantic representation, however, 
is restricted to those aspects of syntax and seman-
tics that developers believe can be consistently 
handled well by hand annotators for many lan-
guages. The current stage of development includes 
only syntax and light semantics ? essentially, the-
matic roles. 
 3. In the ACE project 
(http://www.ldc.upenn.edu/Projects/ACE/intro.htm
l), annotators carry out manual semantic annotation 
of texts in English, Chinese and Arabic to create 
training and test data for research task evaluations. 
The downside of this effort is that the inventory of 
semantic entities, relations and events is very small 
and therefore the resulting semantic representa-
tions are coarse-grained: e.g., there are only five 
event types. The project description promises more 
fine-grained descriptors and relations among 
events in the future.  
 4. Another response to the insufficiency of syn-
tax-only tagging is offered by the developers of 
PropBank, the Penn Treebank semantic extension. 
Kingsbury et al 2002 report: ?It was agreed that 
the highest priority, and the most feasible type of 
semantic annotation, is coreference and predicate 
argument structure for verbs, participial modifiers 
and nominalizations?, and this is what is included 
in PropBank.  
 To summarize, previous tagging efforts that 
have addressed semantics at all have covered only 
a relatively small subset of semantic phenomena. 
OntoSem, by contrast, produces a far richer anno-
tation, carried out largely automatically, within an 
environment that will improve over time and with 
use.  
3 A Snapshot of OntoSem 
OntoSem is a text-processing environment that 
takes as input unrestricted raw text and carries out 
preprocessing, morphological analysis, syntactic 
analysis, and semantic analysis, with the results of 
semantic analysis represented as formal text-
meaning representations (TMRs) that can then be 
used as the basis for many applications (for details, 
see, e.g., Nirenburg and Raskin 2004, Beale et al 
2003). Text analysis relies on:  
 
? The OntoSem language-independent ontology, 
which is written using a metalanguage of de-
scription and currently contains around 6,000 
concepts, each of which is described by an aver-
age of 16 properties.  
? An OntoSem lexicon for each language proc-
essed, which contains syntactic and semantic 
zones (linked using variables) as well as calls for 
procedural semantic routines when necessary. 
The semantic zone most frequently refers to on-
tological concepts, either directly or with prop-
erty-based modifications, but can also describe 
word meaning extra-ontologically, for example, 
in terms of modality, aspect, time, etc. The cur-
rent English lexicon contains approximately 
25,000 senses, including most closed-class items 
and many of the most frequent and polysemous  
verbs, as targeted by corpus analysis. (An exten-
sive description of the lexicon, formatted as a tu-
torial, can be found at http://ilit.umbc.edu.) 
? An onomasticon, or lexicon of proper names, 
which contains approximately 350,000 entries.  
? A fact repository, which contains real-world 
facts represented as numbered ?remembered in-
stances? of ontological concepts (e.g., SPEECH-
ACT-3366 is the 3366th instantiation of the con-
cept SPEECH-ACT in the world model constructed 
during the processing of some given text(s)). 
? The OntoSem syntactic-semantic analyzer, 
which covers preprocessing, syntactic analysis, 
semantic analysis, and the creation of TMRs. In-
stead of using a large, monolithic grammar of a 
language, which leads to ambiguity and ineffi-
ciency, we use a special lexicalized grammar 
created on the fly for each input sentence (Beale, 
et. al. 2003).  Syntactic rules are generated from 
the lexicon entries of each of the words in the 
sentence, and are supplemented by a small in-
ventory of generalized rules. We augment this 
70
basic grammar with transformations triggered by 
words or features present in the input sentence.  
? The TMR language, which is the metalanguage 
for representing text meaning.  
 
 Creating gold standard TMRs involves running 
text through the OntoSem processors and check-
ing/correcting the output after three stages of 
analysis: preprocessing, syntactic analysis, and 
semantic analysis. These outputs can 
be viewed and edited as text or as vis-
ual representations through the 
DEKADE interface. Although the gold 
standard TMR itself does not reflect 
the results of preprocessing or syntactic 
analysis, the gold standard results of 
those stages of processing are stored in 
the system and can be converted into a 
more traditional annotation format. 
4 TMRs in DEKADE 
TMRs represent propositions con-
nected by discourse relations (since 
space permits only the briefest of descriptions, in-
terested readers are directed to Nirenburg and 
Raskin 2004, Chapter 6 for details). Propositions 
are headed by instances of ontological concepts, 
parameterized for modality, aspect, proposition 
time, overall TMR time, and style. Each proposi-
tion is related to other instantiated concepts using 
ontologically defined relations (which include case 
roles and many others) and attributes. Coreference 
links form an additional layer of linking between 
instantiated concepts. OntoSem microtheories de-
voted to modality, aspect, time, style, reference, 
etc., undergo iterative extensions and improve-
ments in response to system needs as diagnosed 
during the processing of actual texts.    
 We use the following sentence to walk through 
the processes of automatically generating TMRs 
and viewing/editing those TMRs to create a gold-
standard annotated corpus.   
 
The Iraqi government has agreed to let 
U.S. Representative Tony Hall visit the 
country to assess the humanitarian crisis.  
 
Preprocessor. The preprocessor identifies the 
root word, part of speech and morphological fea-
tures of each word; recognizes sentence bounda-
ries, named entities, dates, times and numbers; and 
for named entities, determines the ontological type 
(i.e. HUMAN, PLACE, ORGANIZATION, etc.) of the 
entity as well as its subparts (e.g., the first, last, 
and middle names of a person). For the semi-
automatic creation of gold standard TMRs, much 
ambiguity can be removed at small cost by allow-
ing people to correct spurious part-of-speech tags, 
number and date boundaries, etc., through the 
DEKADE environment at the preprocessor stage 
(see Figure 1). Clicking on w+ permits a new POS 
tag/analysis, and clicking on w-, the more common 
action, removes spurious analyses. Preprocessor 
correction is a conceptually simple and logistically 
fast task that can be carried out by less trained, and 
therefore less expensive, annotators.  
Figure 1. Preprocesor Output Editor. 
Syntax. Syntax output can be viewed and ed-
ited in text or graphic form. The graphic 
viewer/editor presents the sentence using the tradi-
tional metaphor of color-coded labeled arcs. 
Mouse clicks show the components of arcs, permit 
arcs to be deleted along with the orphans they 
would leave, allow for the edges of arcs to be 
moved, etc. (no graphic of the syntax or semantics 
browsers/editors are provided due to space con-
straints).   
One common error in syntax output is spurious 
parses due to contextually incorrect POS or feature 
analysis. As shown above, this can be fixed from 
the outset by correcting the preprocessor. How-
ever, since the preprocessor will always contain 
spurious analyses that can usually be removed 
automatically by the syntactic analyzer, it is not 
necessarily most time efficient to always start with 
preprocessor editing. A more difficult, long-term 
research issue is genuine ambiguity caused, for 
example, by PP-attachments. While such issues are 
71
not likely to be solved computationally in the short 
term, they can be easily resolved when humans are 
used as the final arbiters in the creation of gold 
standard TMRs.  
 When the correct parse is not included in the 
syntactic output, either the necessary lexical 
knowledge is lacking (i.e. there is an unknown 
word or word sense), or an unknown grammatical 
construction has been used. While the syntax-
editing interface permits spot-correction of the 
problem by the addition of the necessary arc(s), a 
more fundamental knowledge-building approach is 
generally preferred ? except when the input is non-
standard, in which case systemic modifications are 
avoided.   
 Semantics. Within the OntoSem environment, 
there are two stages of text-meaning representa-
tions (TMRs): basic and extended. The basic TMR 
shows the basic ontological mappings and depend-
ency structure, whereas the extended TMR shows 
the results of procedural semantics, including ref-
erence resolution, reasoning about time relations, 
etc. The basic and extended stages of TMR crea-
tion can be viewed and edited separately within 
DEKADE.   
TMRs can be viewed and edited in text format 
or graphically. In the latter, concepts are shown as 
nodes and properties are shown as lines connecting 
them. A pretty-printed view of the textual extended 
TMR for our sample sentence, repeated for con-
venience, is as follows (concept names are in small 
caps; instance numbers are appended to them).  
 
The Iraqi government has agreed to let U.S.  
Representative Tony Hall visit the country to  
assess the humanitarian crisis. 
 
AGREE-268 
 textpointer agree 
THEME   MODALITY-200 
 AGENT   GOVERNMENTAL-ORGANIZATION-41 
 TIME   (< FIND-ANCHOR-TIME) 
GOVERNMENTAL-ORGANIZATION-41 
 textpointer government 
 RELATION  NATION-56      
 AGENT-OF  AGREE-268 
NATION-56 
 textpointer Iraq 
 RELATION  GOVERNMENTAL-ORGANIZATION-41 
MODALITY-200 
 textpointer let 
      TYPE    permissive 
SCOPE   TRAVEL-EVENT-272 
      VALUE       1 
TRAVEL-EVENT-272 
 textpointer visit 
 AGENT   SENATOR-4471  
 DESTINATION NATION-57 
 PURPOSE  EVALUATE-69 
 SCOPE-OF  MODALITY-200 
SENATOR-447 
 textpointer Representative Tony Hall2 
 REPRESENTATIVE-OF NATION-40 
NATION-40 
 textpointer U.S. 
 REPRESENTED-BY SENATOR-447 
NATION-57 
 textpointer country    
 COREFER  NATION-56 
EVALUATE-69 
 AGENT   SENATOR-447 
 THEME   DISASTER-EVENT-2 
DISASTER-EVENT-2 
 BENEFICIARY SET-23 
 THEME-OF  EVALUATE-69 
SET-23 
 MEMBER-TYPE HUMAN-1342 
 BENEFICIARY-OF DISASTER-EVENT-2 
 
Within the graphical browser, clicking on concept 
names or properties permits them to be deleted, 
edited, or permits new ones to be added. It also 
shows the expansion of any concept in text format. 
 Evaluating and editing the semantic output is 
the most challenging aspect of creating gold stan-
dard TMRs, since creating formal semantic repre-
sentations is arguably one of the most difficult 
tasks in all of NLP. If a knowledge engineer de-
termines that some aspect of the semantic repre-
sentation is incorrect, the problems can be 
corrected locally or by editing the knowledge re-
sources and rerunning the analyzer. Local correc-
tions are used, for example, in cases of metaphor 
and metonymy, which we do not record in our 
knowledge resources (we are working on a mi-
crotheory of tropes but it is not yet implemented).  
In all other cases, resource supplementation is pre-
ferred; it can be carried out either immediately or 
the problem can be fixed locally, in which case a 
request will be sent to a knowledge acquirer to 
carry out the necessary resource enhancements.  
                                                          
1 The concept SENATOR is defined as a member of a legislative 
assembly. 
2 Collocations of SOCIAL-ROLE + personal name are handled by 
the preprocessor. 
72
 Striking the balance between short-term goals 
(a gold standard TMR for the given text) and long-
term goals (better analysis of any text in the future) 
is always a challenge. For example, if a text con-
tained the word grass in the sense of ?marijuana?, 
and if the lexicon lacked the word ?grass? alto-
gether, we would want to acquire the meaning 
?green lawn cover? as well; however, doing this 
without constraint could mean getting bogged 
down by knowledge acquisition (as with the doz-
ens of idiomatic uses of ?have?) at the expense of 
actually producing gold-standard TMRs. There are 
also cases in which a local solution to semantic 
representation is very easy whereas a fundamental, 
machine-reproducible solution is very difficult. 
Consider the case of relative expressions, like re-
spective and respectively, as used in Smith and 
Matthews pleaded innocent and guilty, respec-
tively. Manually editing a TMR such that the ap-
propriate properties are linked to their heads is 
quite simple, whereas writing a program for this 
non-trivial case of reference resolution is not. 
Thus, in some cases we push through gold standard 
TMR production while keeping track of ? and de-
veloping as time permits ? the more difficult as-
pects of text processing that will enhance TMR 
output in the future.    
The gold standard TMR for the sentence dis-
cussed at length here was produced with only a 
few manual corrections: changing two part of 
speech tags and selecting the correct sense for one 
word. Work took less than the 10 minutes reported 
by Brants 2000 for their non-semantic tagging. 
5 Porting to Other Languages 
Recently the need for tagged corpora for less 
commonly taught languages has received much 
attention. While our group is not currently pursu-
ing such languages, it has in the past: TMRs have 
been automatically generated for languages such as 
Chinese, Georgian, Arabic and Persian. We take a 
short tangent to explain how OntoSem/DEKADE 
can be extended, at relatively low cost, to the anno-
tation of other languages ? showing yet another 
way in which this approach to annotation reaches 
beyond the results for any given text or corpus.  
Whereas it is typical to assume that lexicons are 
language-specific whereas ontologies are lan-
guage-independent, most aspects of the semantic 
structures (sem-strucs) of OntoSem lexicon entries 
are actually language-independent, apart from the 
linking of specific variables to their counterparts in 
the syntactic structure. Stated differently, if we 
consider sem-strucs ? no matter what lexicon they 
originate from ? to be building blocks of the repre-
sentation of word meaning (as opposed to concept 
meaning, as is done in the ontology), then we un-
derstand why building a large OntoSem lexicon for 
English holds excellent promise for future porting 
to other languages: most of the work is already 
done. This conception of cross-linguistic lexicon 
development derives in large part from the Princi-
ple of Practical Effability (Nirenburg and Raskin 
2004), which states that what can be expressed in 
one language can somehow be expressed in all 
other languages, be it by a word, a phrase, etc. (Of 
course, it is not necessary that every nuanced 
meaning be represented in the lexicon of every 
language and, as such, there will be some differ-
ences in the lexical stock of each language: e.g., 
whereas German has a word for white horse which 
will be listed in its lexicon, English will not have 
such a lexical entry, the collocation white horse 
being treated compositionally.) We do not intend 
to trivialize the fact that creating a new lexicon is a 
lot of work. It is, however, compelling to consider 
that a new lexicon of the same quality of our On-
toSem English one could be created with little 
more work than would be required to build a typi-
cal translation dictionary. In fact, we recently car-
ried out an experiment on porting the English 
lexicon to Polish and found that a) much of it could 
be done semi-automatically and b) the manual 
work for a second language is considerably less 
than for the first language (for further discussion, 
see McShane et al 2004).  
To sum up, the OntoSem ontology and the 
DEKADE environment are equally suited to any 
language, and the OntoSem English lexicon and 
analyzer can be configured to new languages with 
much less work required than for their initial de-
velopment. In short, semantic-rich tagging through 
TMR creation could be a realistic option for lan-
guages other than English.  
6 Discussion 
Lack of interannotator agreement presents a sig-
nificant problem in annotation efforts (see, e.g., 
Marcus et al 1993). With the OntoSem semi-
automated approach, there is far less possibility of 
73
interannotator disagreement since people only cor-
rect the output of the analyzer, which is responsi-
ble for consistent and correct deployment of the 
large and complex static resources:  if the knowl-
edge bases are held constant, the analyzer will pro-
duce the same output every time, ensuring 
reproducibility of the annotation.  
Evaluation of annotation has largely centered 
upon the demonstration of interannotator agree-
ment, which is at best a partial standard for evalua-
tion. On the one hand, agreement among 
annotators does not imply the correctness of the 
annotations: all annotators could be mistaken, par-
ticularly as students are most typically recruited for 
the job. On the other hand, there are cases of genu-
ine ambiguity, in which more than one annotation 
is equally correct. Such ambiguity is particularly 
common with certain classes of referring expres-
sions, like this and that, which can refer to chunks 
of text ranging from a noun phrase to many para-
graphs. Genuine ambiguity in the context of corpus 
tagging has been investigated by Poesio and Art-
stein (ms.), among others, who conclude, reasona-
bly, that a system of tags must permit multiple 
possible correct coreference relations and that it is 
useful to evaluate coreference based on corefer-
ence chains rather than individual entities. 
The abovementioned evidence suggests the need 
for ever more complex evaluation metrics which 
are costly to develop and deploy. In fact, evalua-
tion of a complex tagging effort will be almost as 
complex as the core work itself. In our case, TMRs 
need to be evaluated not only for their correctness 
with respect to a given state of knowledge re-
sources but also in the abstract. Speed of gold 
standard TMR creation must also be evaluated, as 
well as the number of mistakes at each stage of 
analysis, and the effect that the correction of output 
at one stage has on the next stage. No methods or 
standards for such evaluation are readily available 
since no work of this type has ever been carried 
out.  
In the face of the usual pressures of time and 
manpower, we have made the programmatic deci-
sion not to focus on all types of evaluation but, 
rather, to concentrate our evaluation metrics on the 
correctness of the automated output of the system, 
the extent to which manual correction is needed, 
and the depth and robustness of  our knowledge 
resources (see Nirenburg et al 2004 for our first 
evaluation effort). We do not deny the ultimate 
desirability of additional aspects of evaluation in 
the future. 
The main source of variation among knowledge 
engineers within our approach lies not in review-
ing/editing annotations as such, but in building the 
knowledge sources that give rise to them. To take 
an actual example we encountered: one member of 
our group described the phrase weapon of mass 
destruction in the lexicon as BIOLOGICAL-WEAPON 
or CHEMICAL-WEAPON, while another described it 
as a WEAPON with the potential to kill a very large 
number of people/animals. While both of these are 
correct, they focus on different salient aspects of 
the collocation. Another example of potential dif-
ferences at the knowledge level has to do with 
grain size: whereas one knowledge engineer re-
viewing a TMR might consider the current lexical 
mapping of neurosurgeon to SURGEON perfectly 
acceptable,  another might consider that this grain 
size is too rough and that, instead, we need a new 
concept NEUROSURGEON, whose special properties 
are ontologically defined. Such cases are to be ex-
pected especially as we work on new specialized 
domains which put greater demands on the depth 
of knowledge encoded about relevant concepts.  
There has been some concern that manual edit-
ing of automated annotation can introduce bias. 
Unfortunately, completely circumventing bias in 
semantic annotation is and will remain impossible 
since the process involves semantic interpretation, 
which often differs among individuals from the 
outset. As such, even agreements among annota-
tors can be questioned by a third (fourth, etc.) 
party.  
At the present stage of development, the TMR 
together with the static (ontology, lexicons) and 
dynamic (analyzer) knowledge sources that are 
used in generating and manipulating it, already 
provide substantial coverage for a broad variety of 
semantic phenomena and represent in a compact 
way practically attainable solutions for most issues 
that have concerned the computational linguistics 
and NLP community for over fifty years. Our 
TMRs have been used as the substrate for ques-
tion-answering, MT, knowledge extraction, and 
were also used as the basis for reasoning in the 
question-answering system AQUA, where they 
supplied knowledge to enable the operation of the  
JTP (Fikes et al, 2003) reasoning module. 
We are creating a database of TMRs paired 
with their corresponding sentences that we believe 
74
will be a boon to machine learning research. Re-
peatedly within the ML community, the creation of 
a high quality dataset (or datasets) for a particular 
domain has sparked development of applications, 
such as  learning semantic parsers, learning lexical 
items, learning about the structure of the underly-
ing domain of discourse, and so on. Moreover, as 
the quality of the raw TMRs increases due to gen-
eral improvements to the static resources (in part, 
as side effects of the operation of the HAMA proc-
ess) and processors (a long-term goal), the net 
benefit of this approach will only increase, as the 
production rate of gold-standard TMRs will in-
crease thus lowering the costs.  
TMRs are a useful medium for semantic repre-
sentation in part because they can capture any con-
tent in any language, and even content not 
expressed in natural language. They can, for ex-
ample, be used for recording the interim and final 
results of reasoning by intelligent agents. We fully 
expect that, as the actual coverage in the ontology 
and the lexicons and the quality of semantic analy-
sis grows, the TMR format will be extended to ac-
commodate these improvements. Such an 
extension, we believe, will largely involve move-
ment toward a finer grain size of semantic descrip-
tion, which the existing formalism should readily 
allow. The metalanguage of TMRs is quite trans-
parent, so that the task of converting them into a 
different representation language (e.g., OWL) 
should not be daunting.   
References  
Stephen Beale, Sergei Nirenburg and Marjorie 
McShane. 2003. Just-in-time grammar. Proceedings 
of the 2003 International Multiconference in Com-
puter Science and Computer Engineering. Las Ve-
gas, Nevada. 
Thorsten Brants. 2000. Inter-annotator agreement for a 
German newspaper corpus. LREC-2000. Athens, 
Greece. 
Richard Fikes, Jessica Jenkins and Gleb Frank. 2003. 
JTP: A system architecture and component library for 
hybrid reasoning. Proceedings of the Seventh World 
Multiconference on Systemics, Cybernetics, and In-
formatics. Orlando, Florida, USA. 
Daniel Gildea and Daniel Jurafsky. 2002. Automatic 
labeling of semantic roles. Computational Linguistics 
28:3, 245-288. 
Paul Kingsbury, Martha Palmer and Mitch Marcus. 
2002. Adding semantic annotation to the Penn Tree-
Bank. (http://www.cis.upenn.edu/~ace/ 
    HLT2002-propbank.pdf.) 
Marcus, Mitchell P., Beatrice Santorini and Mary Ann 
Marcinkiewicz. 1993. Building a large annotated 
corpus of English: the Penn Treebank. Computa-
tional Linguistics 19. 
Marjorie McShane, Margalit Zabludowski, Sergei Ni-
renburg and Stephen Beale. 2004. OntoSem and 
SIMPLE: Two multi-lingual world views. Proceed-
ings of ACL-2004 Workshop on Text Meaning and 
Interpretation. Barcelona, Spain. 
Sergei Nirenburg, Stephen Beale and Marjorie 
McShane. 2004. Evaluating the performance of the 
OntoSem semantic analyzer. Proceedings of the ACL 
Workshop on Text Meaning Representation. Barce-
lona, Spain. 
Sergei Nirenburg and Victor Raskin. 2004. Ontological 
Semantics. The MIT Press.  
Emanuele Pianta and Luisa Bentivogli. 2003. Transla-
tion as annotation. Proceedings of the AI*IA 2003 
Workshop "Topics and Perspectives of Natural Lan-
guage Processing in Italy." Pisa, Italy. 
Massimo Poesio and Ron Artstein. 2005. The reliability 
of anaphoric annotation, reconsidered: Taking ambi-
guity into account. Proceedings of the ACL 2005 
Workshop ?Frontiers in Corpus Annotation II, Pie in 
the Sky?. 
David Yarowsky, Grace Ngai and Richard Wicen-
towski. 2001. Inducing multilingual text analysis 
tools via robust projection across aligned corpora. 
Proceedings of HLT 2001, First International Con-
ference on Human Language Technology Research, 
San Diego, California, USA. 
75
Coling 2008: Proceedings of the workshop on Speech Processing for Safety Critical Translation and Pervasive Applications, pages 36?39
Manchester, August 2008
Language Understanding in Maryland Virtual Patient  
Sergei Nirenburg Stephen Beale Marjorie McShane University of Maryland Baltimore County {sergei, sbeale, marge}@umbc.edu 
Bruce Jarrell George Fantry University of Maryland School of Medicine BJarrell@som.umaryland.edu GFantry@medicine.umaryland.edu 
 Abstract This paper discusses language under-standing in the Maryland Virtual Patient environment. Language understanding is just one of many cognitive functions of the virtual patients in MVP, others in-cluding decision making about healthcare and lifestyle, and the experiencing and remembering of interoceptive events.  1 Introduction Maryland Virtual Patient2 (MVP) is an agent-oriented environment for automating certain fac-ets of medical training. The environment con-tains a network of human and software agents, at whose core is a virtual patient  ? a knowledge-based model of a person with a disease.  This model is implemented in a computer simulation. The virtual patient is a ?double agent? that dis-plays both physiological and cognitive function. Physiologically, it undergoes both normal and pathological processes in response to internal and external stimuli. Cognitively, it experiences symptoms, has lifestyle preferences, has memory (many of whose details fade with time), and communicates with the human user about its per-sonal history and symptoms. Other software agents in the MVP environment include consult-ing physicians, lab technicians and a virtual men-tor (tutor).  What makes virtual patient modeling feasible ? considering that comprehensively modeling human physiology would be a boundless en-deavor ? is our task-oriented approach: we are                                                 ? 2008. Licensed under the Creative Commons Attri-bution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. 2 Patent pending. 
not trying to recreate the human organism in all its details, we are modeling it to the extent neces-sary to support its realistic autonomous function-ing in applications aimed at training the diagnos-tic and treatment skills of medical personnel.  Trainees can use MVP to interview a virtual patient; order lab tests; receive the results of lab tests from technician agents; receive interpreta-tions of lab tests from consulting physician agents; posit hypotheses, clinical diagnoses and definitive diagnoses; prescribe treatments; fol-low-up after those treatments to judge their effi-cacy; follow a patient?s condition over an ex-tended period of time, with the trainee having control over the speed of simulation (i.e., the clock); and, if desired, receive mentoring from the automatic mentor.  The virtual patient (VP) simulation is grounded in an ontologically-defined model of human anatomy and physiology. Instances of virtual patients with particular diseases and par-ticular physiological peculiarities are generated from core ontological knowledge about human physiology and anatomy by grafting a disease process onto a generic instance of a human. Dis-ease processes themselves are described as com-plex events in the underlying ontology. 2 Reasoning by the Cognitive Agent The cognitive side of the VP carries out reason-ing in response to two types of input: interocep-tion (the experiencing of physical stimuli, like symptoms) and language input. Specifically its functioning includes: 1. experiencing, interpreting and remember-ing symptoms 2. deciding to go see a doctor, initially and during treatment 3. understanding the doctor?s language input as well as its intent 
36
4. deciding whether to ask knowledge-seeking questions about a test or interven-tion suggested by the doctor  5. deciding whether to agree to a test or inter-vention suggested by the doctor. 6. deciding on what specifically to say in re-sponse to the doctor?s questions, recommendations, etc.  In this paper we concentrate on point 3. We point readers to other works about MVP (e.g., McShane et al 2007) for a discussion of other aspects of MVP.  Five types of subdialogs are supported in MVP.  1. Requests for information and responses. These include (a) the physician asking the patient questions about symptoms and life-style, and (b) the patient asking questions about features of suggested interventions as well as other options. 2. Requests for action and responses ? pri-marily the physician suggesting that the patient agree to have an intervention. 3. Domain descriptions provided by the user, the key points of which must be under-stood and remembered  (?learned?) by the VP. 4. Scheduling follow-up appointments.  5. General dialog topics, like greetings, ex-pressions of gratitude and other means for making the dialog more realistic in the user?s eyes.  Our approach to treating dialog is unlike most other approaches in that all language-oriented reasoning is carried out on the basis of formal interpretations of text meaning. We call these interpretations text meaning representations or TMRs. Note that TMRs are written using the same ontologically grounded metalanguage as is used to represent interoception. In short, all knowledge and reasoning in our environment employs the same metalanguage, so whether a patient experiences new symptoms or learns in-formation about its disease from the user, the new information will be stored the same way in the patient?s memory.  There are several advantages to orienting an agent?s language processing around TMRs rather than text strings. First, TMRs are unambiguous, since linguistic ambiguity is resolved as the TMRs are being produced. Second, TMRs re-duce to a single representation many types of linguistic paraphrase, be it lexical (esophagus ~ 
food pipe), syntactic (I will administer it to you ~ It will be administered to you by me) or even se-mantic  (Does the food get stuck when you swal-low? ~ Do you have difficulty swallowing?).  Third, TMRs facilitate the detection of which aspects of meaning are central and which are of secondary importance. For example, the analyzer can determine which portions of input utterances merely convey politeness. To take an extreme example for illustration, the question ?Do you have difficultly swallowing?? could be rendered by an overly polite physician as: ?If you don?t mind, I would really appreciate it if you would tell me whether you have any difficulty swallow-ing.? When the VP receives language input, it uses its lexicon, ontology and a reasoning-enabled  analyzer to create a TMR corresponding to the input. Next, it determines the intent of that input ? e.g., through the recognition of indirect speech acts. After that it plans its response then gener-ates its response. Here we talk about the first two stages of text processing: understanding the dia-log turn and understanding its intent.  3 Understanding a Dialog Turn The input to understanding a dialog turn is text input by the user. Background knowledge that must be leveraged is the knowledge stored in the lexicon, ontology and the patient?s long-term memory of assertions, also called its fact reposi-tory. The output is a TMR. TMR production ac-tually comprises two stages: the first stage, pro-duction of the basic TMR, involves disambigua-tion and the determination of semantic depend-encies; the second stage, production of the ex-tended TMR, adds the results of procedural se-mantic routines, like the resolution of reference.  For example, the following questions are all synonyms at the level of extended TMR, at least at the grain-size of description needed for our current application: Have you been coughing? Do you find yourself coughing? Do you experi-ence any coughing? Do you ever experience coughing? Do you have a cough? Any coughing? Coughing? etc. All of these questions ask whether or not the patient has the symptom onto-logically described as the event called COUGH. The extended TMR for this set of questions is:  (REQUEST-INFO-1  (THEME  MODALITY-1.VALUE)) (MODALITY-1  (TYPE  EPISTEMIC)   (SCOPE  ASPECT-1)) 
37
(ASPECT-1  (ITERATION  MULTIPLE)  (SCOPE  COUGH-1)) (COUGH-1  (EXPERIENCER HUMAN-1)     (TIME         (FIND-INTERVAL (FIND-ANCHOR-TIME)         (FIND-INTERVAL-LENGTH) BEFORE)))  This TMR is read as follows. The input creates an instance of REQUEST-INFO. The instance is numbered, like all TMR instances, to distinguish it from other instances of that concept. The THEME of REQUEST-INFO-1 ? i.e., what is being asked about ? is whether or not COUGH-1 has occurred repetitively; this is shown in the AS-PECT-1 frame. The COUGH event itself has the VP, HUMAN-1, as the EXPERIENCER. The time of the COUGH event is calculated using a procedural semantic routine that seeks a certain time interval in the past (we leave out details of which period of time in order to avoid a lengthy tangent). Al-though this example is a bit complex ? involving both aspect and modality ? it provides some in-sight into the format and content of TMRs in our environment.  The text analyzer can automatically create this same TMR for all of the different inputs in large part thanks to the lexicon. Syntactic knowledge in lexicon entries in OntoSem is formulated us-ing an extended form of Lexical Functional Grammar, with variables used to link entities in the syntactic structure (syn-struc) zone of an en-try with those in the semantic structure (sem-struc) zone. Lexicon entries can also contain calls to procedural semantic routines (meaning-procedures). The caret means ?the meaning of? a given variable. $var0 is the head entry. Have you been coughing? is a syntactic trans-formation of Do you cough?, which is under-stood directly by the analyzer as a question about cough (v.), which is mapped to the concept COUGH in the respective lexicon entry.   (cough-v1   (syn-struc      ((subject ((root $var1) (cat n)))       (root $var0) (cat v)))   (sem-struc      (COUGH (EXPERIENCER (value ^$var1)))))  For the other paraphrases, ?superfluous? words must be attributed null semantics. For example, to find oneself verb-ing is semantically same as to verb, the only real difference being stylistic. There is a lexical sense of find that attributes null 
semantics to find oneself in the collocation find oneself doing X.  Examples in which question processing is folded into the lexicon entry are Any + EVENT ? (Any coughing?) and EVENT? (Coughing?). The lexicon entry that covers these is keyed on the question mark, since it is the only element that is always available in these turns of phrase (since ?any?  is optional). The sem-struc is headed by the concept REQUEST-INFO, whose THEME is the value of epistemic modality scoping over the event in question.  This brief overview is intended only to give a taste of the process of language understanding by virtual patients in MVP. This process is exactly the same as language understanding in other ap-plications of our text processor, called OntoSem (see Nirenburg and Raskin 2004). The eventualities of text understanding by the cognitive agent of the VP are: (a) successful un-derstanding, (b) the VP?s belief that it under-stood, only to be corrected by the user, or (c) the failure of understanding, in which case the VP asks for clarification by the user.   4 Understanding the Intent of a Dialog Turn  The extended TMR is our most complete model of the meaning of an utterance, but it does not include what is called indirect speech act proc-essing ? i.e., understanding intentions of the speaker when they are not overtly mentioned in the utterance. Well-known examples of the di-chotomy between expressed meaning and in-tended meaning include It?s cold in here (which might be a statement/complaint or might be an indirect request for the interlocutor to do some-thing about it, like close the window) and Can you pass the salt? (which might be a question about physical ability or an indirect request).  Our work on indirect speech acts includes long-term, fundamental theory building as well as short-term, immediately implementable solu-tions. At a fundamental level, speech act process-ing requires the speaker and the interlocutor to keep a full inventory of their beliefs about the other?s knowledge, their understanding of their own and the other?s plans and goals, both long-term and immediate, their understanding of what is and what is not within each person?s or agent?s power to do, and so on. More immediately, we have implemented a means of detecting indirect speech acts in the dialogs between VPs and us-
38
ers. Our approach, like all of our approaches to automatic reasoning, is grounded in TMRs.  There are three utterance types that the VP ex-pects of the user, which correspond to three user plans: asking questions to learn information that will aid in diagnosis and treatment, explaining things to educate the VP, and giving advice to the VP about what it should do. At any point in the dialog when the user stops typing and expects a response from the VP, the VP must decide which of the plans the user is pursuing. Surface-level heuristics are not always definitive: e.g., Would you agree to have a Heller myotomy? is both a question and advice, and I think that hav-ing a Heller myotomy is the best option is both information and advice.  We prepare the VP to interpret indirect speech acts by creating TMR correspondences between the direct and the indirect meaning of certain types of utterances. Let us take as an example the doctor?s offering advice on what to do. There are many ways the doctor can present advice, includ-ing the following, provided below with their re-spective TMRs. In all of these TMRs, HUMAN-1 is the doctor and HUMAN-2 is the patient (these TMRs are simplified for purposes of exposition; also note that all reference resolution has been carried out). INTERVENTION stands for any event that is ontologically an intervention ? that is, a test or a medical procedure. Note that the lexicon directly supports the automatic generation of these TMRs.  1. I (would) advise/suggest/recommend (having) INTERVENTION  (ADVISE-1       (THEME  INTERVENTION-1)     (AGENT  HUMAN-1)    (INTERVENTION-1     (EXPERIENCER  HUMAN-2))    2. I think you should have INTERVENTION (MODALITY-1     (TYPE BELIEF)     (VALUE (> .7))     (SCOPE MODALITY-2)     (ATTRIBUTED-TO HUMAN-1)) (MODALITY-2     (TYPE OBLIGATIVE)      (VALUE .8)      (SCOPE INTERVENTION-1)     (ATTRIBUTED-TO HUMAN-1)) (INTERVENTION-1   (EXPERIENCER HUMAN-2)))  
3. I'd like to schedule you for <set you up for, set you up to have> INTERVENTION   (MODALITY-1      (TYPE VOLITIVE)      (SCOPE EVENT-1)      (VALUE .8)      (ATTRIBUTED-TO HUMAN-1))  (SCHEDULE-EVENT-1      (AGENT HUMAN-1)     (THEME INTERVENTION-1)      (BENEFICIARY HUMAN-2)) (INTERVENTION-1      (EXPERIENCER HUMAN-2))   The ?core? meaning that the VP must glean from any of these TMRs is the meaning shown in (1): that the doctor is advising that the patient have the intervention. The correlations between the TMRs in (2) and (3) and this core TMR are established using a TMR-to-TMR translation function. The efficacy of this translation process depends on (a) preparing for the full inventory of possible types of input TMRs that correspond to the given meaning, and (b) being able to extract from more complex TMRs these basic kernels of meaning. We have already implemented part (a) in our current system. Part (b) requires more long-term effort, the problem essentially being that one needs to teach the system to zero in on what is important and ignore what is unimpor-tant. For example, negation is very important: I advise you to have INTERVENTION is very differ-ent from I do not advise you to have INTERVEN-TION. However, I think I would choose to advise you to have INTERVENTION  includes aspects of meaning (?think?, ?would choose?) that are really not important and should be simplified to the main meaning of the proposition. We consider research on this aspect of agent reasoning to be a long-term endeavor   References McShane, Marjorie, Sergei Nirenburg, Stephen Beale, Bruce Jarrell and George Fantry. 2007. Knowl-edge-based modeling and simulation of diseases with highly differentiated clinical manifestations. 11th Conference on Artificial Intelligence in Medi-cine (AIME 07), Amsterdam, The Netherlands, July 7-11, 2007. Nirenburg, Sergei and Victor Raskin. 2004. Ontologi-cal Semantics. MIT Press.   
39
The Idiom?Reference
Connection
Marjorie McShane
Sergei Nirenburg
University of Maryland Baltimore County (USA)
email: marge@umbc.edu
Abstract
Idiom processing and reference resolution are two complex aspects of text
processing that are commonly treated in isolation. However, closer study
of the reference needs of some idioms suggests that these two phenom-
ena will need to be treated together to support high-endNLP applications.
Using evidence from Russian and English, this article describes a num-
ber of classes of idioms according to their reference needs and suggests a
method of lexical encoding which, supplemented by procedural semantic
routines, can adequately support the full semantic and referential inter-
pretation of these idioms.
165
166 McShane and Nirenburg
1 Introduction
Reference resolution and idiom processing have received much attention in natural
language processing (NLP), but these phenomena are commonly treated in isolation
of each other, andmost treatments address only a single aspect of the respective overall
problems. For example, much of the work on practical reference resolution has con-
centrated on establishing textual coreference relations for a subset of pronouns (e.g.
Mitkov et al, 2002), and the most widely pursued aspect of idiom processing has been
the automatic extraction of multi-word expressions (of which idioms are a subtype)
from corpora (e.g. Baldwin and Villavicencio, 2002). Of course, some contributions in
both of these subfields have ventured much wider;1 however, we have found few prac-
tical approaches that explore the interaction of idiomaticity and reference resolution
and its implications for NLP.
One might ask, why treat these phenomena together? Perhaps the best reason is to
highlight the indispensability for real progress in NLP of semantic analysis that goes
beyond what the most researchers are currently pursuing in practical system building.
Another reason to integrate the study of reference and idioms is to address the diffi-
culties that automatic text analyzers will encounter in detecting and processing idioms
when some of their components are elided. Ellipsis, a means of expressing reference,
thus, becomes an important component of this study. The approach suggested here
should, we believe, alleviate some of the inherent difficulties of these complex tasks.
Note that similar kinds of problems are discussed in Pulman (1993), which suggests
the need for ?contextual reasoning? applied to idioms, which is ?the process of tak-
ing the information that can be derived linguistically from a sentence and fleshing it
out with information supplied by the local context or general background knowledge?
(Pulman, 1993, p. 251).
The proposed analysis delineates several categories of idioms according to their ref-
erence needs and shows how the encoding of idioms in a semantically oriented lexicon
can support both basic semantic analysis and reference resolution. Although the anal-
ysis is theory- and system-neutral, the exposition follows a specific, implemented the-
ory of natural language processing. This theory, called Ontological Semantics (Niren-
burg and Raskin, 2004), colors our understanding of the nature of meaning-oriented
NLP, including our treatment of reference and idioms.
Ontological Semantics seeks to achieve full semantic and pragmatic analysis of
texts such that interpreted structures, rather than textual strings, serve as the input to
automatic reasoners. Ontological Semantics relies on knowledge obtained through
many layers of processing: preprocessing followed by morphological, syntactic, se-
mantic and discourse analysis. The static knowledge resources, which are intercon-
nected and all use the same metalanguage of description, are a lexicon and onomas-
ticon for each language processed, a language-independent ontology (a knowledge
base of concept types), and a language-independent fact repository (a knowledge base
of concept instances). Static resources are compiled manually, using sophisticated
editing environments, to ensure high quality, though we are experimenting with ma-
chine learning to speed the acquisition process. Text analysis involves the automatic
1See, for example, the contributions to recent workshops (e.g., ACL 2004 ?Reference Resolution and its
Applications? and ?Multi-word Expression: Integrating Processing?; EACL 2006 ?Multi-word Expressions
in a Multilingual Context?) and Stanford?s Multi-Word Expression Project (http://mwe.stanford.edu/).
The Idiom?Reference Connection 167
evaluation of semantic preferences recorded in the lexicon and ontology, as well as
preferences based on stochastically trained measures of semantic distance among on-
tological concepts.
Within this semantically-oriented, knowledge-based environment we define refer-
ence resolution rather differently than in most NLP applications, where resolving ref-
erence is understood as linking coreferring text strings. In fact, our conceptualization
of reference resolution strongly influences how we approach resolving reference in
idioms and therefore must be clarified from the outset.
2 What is Reference Resolution?
We define reference resolution as the anchoring of referring expressions in the episodic
memory of an intelligent text processing agent. This knowledge base of stored mem-
ories, called the fact repository, differs from the ontology in that it contains indexed
instances of ontological concepts and their property-based interconnections. Anchor-
ing entities in the fact repository is the culmination of semantic analysis and reference
resolution.
When presented with a new text, the system must first semantically analyze every
sentence, creating an unambiguous text meaning representation (TMR); reference is
then resolved for the correct meaning of each string. The TMR contains the crucial
clues for determining which entities are referring expressions: numbered instances
of ontological concepts are referring expressions whereas properties, literal property
fillers, and so on, are not. As an example, consider the following context which,
although contrived, illustrates many relevant phenomena at one go.
(1) At 4:48 it became clear that the programmers couldn?t finish debugging the
system before the 5:00 deadline. All hell broke loose, the boss was fit to be
tied ? almost strangled his project manager!
Let us concentrate on the second sentence. In the tables below, each string or
idiomatic group of strings from that sentence (top row) is associated with its corre-
sponding semantic structure (bottom row). The concept instances set in italics must
be resolved. The important thing to notice is that the system must orient around se-
mantic structures rather than strings in order to create the correct inventory of referring
expressions.
all broke his project
hell loose the boss was fit to be tied almost strangled manager
CHAOS-1 MANAGER-1 ANGER (RANGE 1) HUMAN-1 (MODALITY-2
(TYPE EPISTEMIC)
(VALUE .9)
(SCOPE STRANGLE-1))
STRANGLE-1 ASSISTANT-1
Highlights of the analysis are as follows:
? Whereas all hell and broke loose could individually be referring expressions in
some other context, when the are used in this idiom they together represent a
single meaning, CHAOS, this instance of which is called CHAOS-1 ? the first
instance of the concept CHAOS encountered while processing the given text or
corpus. This event, like all instances of OBJECTs and EVENTs in TMRs, re-
quires reference resolution: it must be determined whether this is a new event to
168 McShane and Nirenburg
be added to the fact repository or a reference to an event that is already recorded
there. In this case, it is a new event, since the algorithm used to detect event
coreference requires either (a) that there be an ample overlap of properties as-
sociated with a candidate fact repository ?anchor? or (b) that the new event be
referred to using a definite description (e.g., the strike), with the definite de-
scription triggering the search for a coreferent in the context or fact repository.
? Whereas the boss and his project manager can either be descriptors (as in This
man is a boss and that man is a project manager) or referring expressions, here
they are referring expressions and must be resolved.
? Whereas fit and tied can be referring expressions in isolation, in this idiom they
are not referring expressions, nor is the idiom on the whole a referring expres-
sion: it indicates the highest value of the property ANGER.
? Although the second half of the sentence has no overt subject, he is the under-
stood subject. The reference resolver must detect this missing entity and create
a coreference link between it and MANAGER-1.
? Almost is never a referring expression: it indicates a value of less than 1 for
epistemic modality scoping over the given event (here, STRANGLE-1). How-
ever, some other adverbs are referring expressions (e.g., here, yesterday) and
must be resolved.
? STRANGLE-1, like all EVENTs, must undergo reference resolution.
Once all referring expressions have been detected, the system must resolve them
against the fact repository. There are several possible scenarios: (a) the entity has a
textual antecedent, in which case the new entity is linked to the same fact repository
anchor as that antecedent; (b) the entity does not have a textual antecedent but is
already a known entity (like the earth or Plato) and is linked to the existing anchor
in the fact repository; (c) the entity is determined to be new and a new anchor is
established for it in the fact repository. This, in a nutshell, is how reference is resolved
in our semantic analysis environment, OntoSem.
Our reference resolver for English is implemented and covers all the eventualities
posed by this sentence. It has not yet undergone formal evaluation. We will now
describe how idioms are encoded to support this process.
The examples used for illustration are not from English, they are from Russian,
a language that is not currently supported in OntoSem. The reason for using Rus-
sian examples even though the implemented system does not yet cover Russian is
that Russian presents a superset of challenges for reference resolution ? namely, a
much wider use of ellipsis, or the null referring expression; therefore, showing that
the scope of phenomena presented by Russian can be handled a fortiori shows that
the same phenomena can be handled in English. Indeed, the OntoSem environment
supports multilingual text processing, using a language-independent ontology and fact
repository, and using the same types of lexicon entries regardless of the language pro-
cessed (see McShane et al, 2005).
The Idiom?Reference Connection 169
3 Encoding Idioms to Support their Full Analysis
A cornerstone of theoretical, descriptive, computational and psycholinguistc work on
idioms is the attempt to understand to what extent idioms are fixed and to what extent
they are flexible (see, e.g., Cacciari and Tabossi (1993), whose component articles
include extensive overviews of the literature). The competing classifications can de-
rive from both theoretical considerations, like psycholinguistic evidence, and practical
considerations, like whether an NLP system attempts to analyze only those idioms that
are recorded or whether it attempts to analyze new coinages as well. The scope of the
current analysis is idioms that are recorded as well as certain types of free modifi-
cations of them. Completely new idioms will need to be processed as ?unexpected
input?, in a similar way as the system attempts to process metaphor and metonymy.
Like Stock et al (1993) (in Cacciari and Tabossi (1993)), we integrate idioms into
the lexicon as ?more information about particular words? (Stock et al, 1993, p. 238)
rather than treat them using special lists and idiosyncratic procedures. In the discus-
sion below, we look at some examples of idioms that highlight noteworthy reference
resolution needs and show how our all-purpose lexical encoding mechanisms and ref-
erence resolution routines cover idiomatic input as readily as compositional input. A
more detailed description of how we encode idioms and other multi-word expressions,
as well as many additional examples, can be found in McShane et al (2008).
3.1 Productive Syntactic Processes in Idioms
Each of the examples below contains an idiom in the second half, and each of those
idioms shows at least one productive use of ellipsis. In the examples, the elided cat-
egory, [e], and its antecedent, if syntactically available, are in boldface. Grammatical
information is provided sparingly for reasons of space.2
(2) Nado
it-is-necessary
zashchishchat?
to-defend
svoix
self?sACC.PL
sotrudnikov
coworkersACC.PL
a
and
ne
not
prinosit?
deliverINFIN
[e]
[e]ACC
v
as
zhertvu
sacrificeACC.SG.FEM
.
.
You should defend your coworkers, not sacrifice them.
(3) Ja
I
ne
don?t
xochu
want
preduprezhdat?
to-forewarn
ego,
himACC
[e]
[e]1.SG
xochu
want1.SG.
zastat?[e]
to-catch[e]3.SG.ACC.MASC
vrasplox
unawares
.
.
I don?t want to forewarn him, I want to catch him unawares.
These examples represent configurations in which ellipsis is highly promoted in non-
idiomatic and idiomatic contexts.3 Example (2) shows VP conjunction with the latter
of two coreferential direct objects elided. Example (3) shows subject and direct object
2Most of the Russian examples here are from Lubensky (1995), which is a bilingual learner?s dictionary
of Russian idioms that provides grammatical descriptions but no special treatment of ellipsis.
3See McShane (2005) for discussion and extensive examples of ellipsis-promoting configurations using
non-idiomatic examples. Idiomatic examples of many of the phenomena have also been found but are not
presented here for reasons of space.
170 McShane and Nirenburg
ellipsis in an ?assertion + elaboration? strategy (see McShane (2005)), in which the
topic of discourse is asserted then either restated or elaborated upon subsequently.
The above idioms are idiomatic VPs that are recorded in the OntoSem lexicon in a
similar way as typical verbs, with just a few special features. Let us take the example
of v grob vgonjat? ?to kill? (literally: to drive to the grave) as an example.
(vgonjat?-v1
(def "idiom: v grob vgonjat? - to kill (drive to the grave)")
(ex "Ja v grob vgonju tebja! I?ll kill you!")
(syn-struc
((subject ((root $var1) (cat n)))
(root $var0) (cat v)
(directobject ((root $var2) (cat n)))
(pp ((root $var3) (cat prep) (root v)
(obj ((root $var4) (cat n) (root grob)))))
(sem-struc
(KILL
(AGENT (value ^$var1))
(THEME (value ^$var2)))
(^$var3 (null-sem +)) (^$var4 (null-sem +))))
This lexical sense is headed by the verb, vgonjat? ?drive?. The syntactic zone (syn-
struc) says that the verb takes a subject, direct object and prepositional phrase with
no unusual syntactic constraints, meaning that the structure is open to the same sorts
of variability ? like different verbal tenses and aspects, free word order, syntactic
transformations and ellipsis? as is typical of non-idiomaticRussian. The only special
syntactic feature is that the roots of the lexical components of the prepositional phrase
are explicitly listed: v (into) and grob (grave). The semantic zone (sem-struc) records
the semantic interpretation: it is headed by a KILL event whose AGENT and THEME
are productively analyzed as the meaning of the subject and direct object, respectively.
The meanings of v (into) and grob (grave), which are ? under this analysis ? non-
compositional, are attributed null semantics.
Two aspects of semantic interpretation require comment. First, in most contexts
this idiom is not used to threaten actual killing; however, the same can be said for
the lexeme kill used in the threat I?ll kill you!; this aspect of interpretation is clearly
extra-lexical. Second, although it is likely that a person who did not know this idiom
would be able to interpret its meaning using the meanings of the component elements,
most NLP systems would struggle. Once we decide to record a phrase as idiomatic to
ease processing, the level of transparency of the components becomes unimportant.
Analysis of a clause that uses vgonjat? v grob ?kill? will generate three referring
expressions that must be resolved: the AGENT of the killing, the THEME of the killing
(we will not quibble here about which case role to choose for the person killed), and
the act of killing. These referring expressions might be realized, for example, as
HUMAN-23, HUMAN-24 and KILL-4 in a given text meaning representation. Once the
system has arrived at these analyses, reference resolution proceeds as it would for any
referring expressions, whether or not they were part of an idiom: textual coreferents
? recorded as semantic entities in TMR ? are sought and, whether or not they are
found, the referring expression is anchored in the fact repository. If we look at what is
The Idiom?Reference Connection 171
special about processing the reference in idioms, then, there are only two aspects: (1)
ensuring that productive syntactic processes are permitted only if applicable, and (2)
ensuring that the correct inventory of referring expressions ? understood as semantic
structures ? is generated.
Let us compare this treatment of idioms to the one proposed by Villavicencio et al
(2004). They treat the potential variability of idioms using the notion of semantic
decomposition. If an idiom can be paraphrased in a syntactically parallel way, it is de-
composable (spill the beans ? reveal a secret), even though non-standard meanings
need to be assigned to each component. The fundamental differences between their
approach and ours relate to semantic encoding and reference resolution. For Villavi-
cencio et al, the semantics of idioms is conveyed by paraphrases with other linguistic
elements (spill ? reveal, beans ? secret). For us, semantics is formulated using the
ontologically grounded metalanguage of OntoSem. As regards the initial syntactic
parse, both approaches seem to offer the same coverage of syntactic variability, and
resources could be shared with seeminglyminimal work devoted to format conversion.
3.2 Essentially Frozen Idioms
We have just shown how syntactic processes ? specifically, various types of ellipsis
? can apply to idioms in a language, and how the lexical encoding of such idioms al-
lows for syntactic variability. Other idioms, by contrast, are syntactically frozen. Such
idioms are commonly treated as strings with spaces, but this only works if absolutely
no modifiers or other entities (e.g., ?ahem?) can intervene. If intervening material
is possible, it is preferable to encode the idiom using separate syntactic constituents.
However, if one records the components individually, the analysis system must under-
stand that diathesis transformations, ellipsis, pronominalization, etc., are not applica-
ble. In OntoSem we label frozen syntactic constituents using immediate constituents,
like NP, rather than grammatical function labels, like subject. Since transformations
apply only to grammatical functions, they become automatically inapplicable if imme-
diate constituents are used. However, since all constituents are still listed individually,
intervening material and free modification are permitted in the usual way, as in He
kicked the bloody bucket!
Of course, treating free modifications of non-compositional parts of an idiom or
other multi-word expression (MWE) is not trivial, as described in some depth in Mc-
Shane et al (2008). To summarize that discussion, our basic approach to treating mod-
ifiers within MWEs is to analyze the MWE as indicated in the sem-struc, then attempt
to attach the meaning of ?orphan? modifiers to the meaning of the entire structure
using generalized processes for meaning composition. In the case of He kicked the
bloody bucket, the basic meaning will be rendered in the text meaning representation
as (DIE-1 (EXPERIENCER HUMAN-1)). The modifier bloody has two senses in our
lexicon, semantically described as (RELATION BLOOD) and (EMPHASIS .7). We have
a rule that prefers the stylistic interpretation in the case of non-compositional idioms.
So the final text meaning representation will be (DIE-1 (EXPERIENCER HUMAN-1)
(EMPHASIS .7)). ((emphasis .7) indicates a high value for the property EMPHASIS on
the abstract scale {0,1}.)
Such meaning composition is not specific to multi-word expressions: our semantic
analyzer carries out the same process in all cases when meaning must be recovered
172 McShane and Nirenburg
from an incomplete parse. The latter may be due to insufficient coverage of the syn-
tactic parser, lexical lacunae that confound the parser, or unexpected (ungrammatical,
highly elliptical, etc.) input.
Returning to our main point about how to encode essentially frozen idioms, en-
coding their components as separate entities provides the best of both worlds: frozen
components, fixed word order, and the possibility of intervening strings that typically
act as modifiers. One Russian idiom that fits this description is shown below.
(4) Ishchi-svishchi
Look-for-whistle-forIMPER
vetra
wind
v
in
pole
field
.
.
?You?ll never find him/her/it/etc.?
(ishchi-svishchi?-v1
(def "idiom: ishchi-svishchi vetra v pole
?you will never find him/her/it/etc.?")
(syn-struc
((root $var0) (cat v) (form imperative)
(np ((root $var1) (cat np) (root vetra)))
(pp ((root $var2) (cat prep) (root v)
(np ((root $var3) (cat np) (root pole)))))
(sem-struc
(modality
((type potential)
(value 0)
(attributed-to (sem HUMAN))
(scope (value refsem1))))
(refsem1
(FIND
(AGENT (sem human))
(THEME (sem all))
(time (> (find-anchor-time))))
(^$var1 (null-sem +))
(^$var2 (null-sem +))
(^$var3 (null-sem )))
(meaning-procedure
(seek-specification
((value find.modality.attributed-to)
(resolve-1st-sing)))
(seek-specification
((value find.agent) (resolve-2nd-sing)))
(seek-specification
((value find.theme) (resolve-3rd))))
The syntactic description should be self-evident based on the examples and description
above, but the semantic structure requires commentary.
The variables $var1, $var2 and $var3 are attributed null semantics because they do
not contribute to compositional meaning ? that is, this idiom (?look for whistle for
wind in the field?) is completely semantically opaque.
The sem-struc is headed by a modality statement: it is impossible introducesmodal-
ity of the type ?potential? with a value of 0. This modality is attributed, by default, to
The Idiom?Reference Connection 173
the speaker. It scopes over a proposition headed by FIND, and the latter is ontologically
defined as taking an AGENT and a THEME case role.
The semantic representation includes four referring expressions that must be re-
solved: (1) the speaker, to whom the modality is attributed; (2) the FIND event itself,
which will be a new anchor in the fact repository; (3) the AGENT of finding, which is
the interlocutor; and (4) the THEME of finding, which must be contextually computed.
The OntoSem analyzer would resolve the reference of the instance of FIND in the
usual way; this requires no further comment. What does require further comment,
however, is the way in which we guide the analyzer?s efforts to resolve the under-
specified instances of HUMAN, HUMAN and ALL that represent the speaker, the inter-
locutor and the object of the FIND event, respectively. We provide this guidance in
the meaning-procedures zone of the lexicon entry, which contains calls to procedural
semantic routines that are launched at run time. For example, we need to know who
the speaker is so that the modality can be attributed to the correct real-world person.
This is done using the ?seek-specification? meaning procedure. The first argument of
this procedure is what we are seeking the specification of (i.e., to whom the modality
is attributed), and the second argument is the function that will let us determine this ?
i.e., ?resolve-1st-sing?, which is, incidentally, the same routine used to seek the refer-
ent of the pronoun I. The latter meaning procedure includes ordered routines testing
for many cases including:
? the pronoun I being used in a context in which another pronoun I (which itself
should have been resolved earlier) can serve as an antecedent: I like chocolate
ice cream and always choose it if I have the option.
? the pronoun I being used within a quotation, and that quotation being the THEME
of a SPEECH-ACT of which the coreferent of I is the AGENT: I/Mary said, ?But
I don?t want strawberry ice cream!?
? the pronoun I being used outside of a quotation and the writer of the text
being available in metadata: <title>Understanding Your Finances</title>
<author>Mary Smith</author> . . . I believe that the only way to understand
your finances is to consult a financial advisor.
In short, using the combination of the information in the sem-struc and meaning-
procedures zones we arm the analyzer with the types of the information a person
would use to both understand the idiom and to resolve all implied references. (For
a more detailed description of meaning procedures in OntoSem, see McShane et al
(2004).)
3.3 Subjectless Constructions
We conclude our example-based discussion with one category of phenomena in which
idiom processing is actually much simpler than the processing of structurally similar
compositional language since it permits preemptive disambiguation. The disambigua-
tion in question regards subjects, which in Russian can be overt, elided or completely
missing. Completely missing (uninsertable) subjects occur in the following construc-
tions:
174 McShane and Nirenburg
? In the indefinite personal construction a 3rd person plural verb form is used
without a subject to indicate an unspecified person or people. It is used in
contexts like the Russian equivalent of They say it will rain today.
? In the non-agentive impersonal construction a 3rd person singular verb is used
without a subject to show that the event is non-agentive. It is used in contexts
like the Russian equivalent of He?s attracted to girls like that, whose structure-
preserving paraphrasewould be ?[some unnamed force] attracts him to girls like
that.?
The difficulty in processing productive subjectless sentences is determining whether
the verb has a specific subject that has been elided and must be recovered, or does
not have a specific subject, in which case the generalized personal or non-agentive
interpretation should be used. However, when it comes to idioms that employ these
constructions, the syntax can be encoded to explicitly block a subject, and the seman-
tics can explicitly indicate the interpretation added by the missing subject.
An idiom that employs the indefinite personal construction is shown in (5), along
with the lexical sense of bit? ?hit? that records it.
(5) Lezhachego
Lying-down-personACC.SG.MASC.
ne
not
b?jut
beat3.PL.PRES.
.
.
[L-45]
You don?t/shouldn?t kick a man/person/guy when he?s down.
(bit?-v10
(def "phrasal: Lezhachego ne b?jut - you shouldn?t do
something bad to someone who is in a bad position already")
(ex "You don?t/shouldn?t kick a guy when he?s down")
(syn-struc
((np ((root $var1) (cat n) (root lezhachij)
(case acc) (gender masc) (number sing)))
(verb-neg ((root $var2) (cat verb-neg)))
(root $var0) (cat v) (tense present) (person third) (number pl))))
(sem-struc
(modality ; ??should??
(type obligative)
(scope (value refsem1))
(value 1)
(attributed-to *speaker*))
(refsem1
(modality ; ??not??
(type epistemic)
(scope (value refsem2))
(value 0)
(attributed-to *speaker*)))
(refsem2
(ABUSE
(AGENT (value refsem3))
The Idiom?Reference Connection 175
(THEME (value refsem4))))
(refsem3
(set
(member-type human)
(cardinality 1)
(complete yes)))
(refsem4 (HUMAN (EXPERIENCER-OF MISFORTUNE)))
(^$var1 (null-sem +)) (^$var2 (null-sem +))
(output-syntax (cl)))
The syn-struc should be clear based on previous examples; the only new element is
verb-neg, which indicates a negating particle.
The sem-struc looks more complex than it actually is because many of the slot
fillers require reified structures, each of which must be pointed to using numbered
variables called refsems.The sem-struc is headed by obligativemodality, which scopes
over an epistemicmodality, which scopes over an ABUSE event. The obligativemodal-
ity has the value 1 (absolute obligation), whereas the epistemic modality has the value
0 (negation). Put plainly, ?it is necessary not to abuse?. The AGENT of the ABUSE
event is the set of all people, described just as we describe the word everyone. The
THEME of the ABUSE event is a HUMAN who is the EXPERIENCER-OF a MISFOR-
TUNE. One might ask, why not record this idiom as a fully fixed entity with white
spaces in between, rather than as a multi-part syntactic structure? For the same rea-
son as discussed earlier: there is an outside chance of modification, so the component
elements must be kept separate.
Example (6) shows an idiomatic example of the second type of obligatorily sub-
jectless sentence: the non-agentive impersonal construction.
(6) Kakim
whatINSTR.SG.MASC.
vetrom
windINSTR.SG.MASC.
vas
youACC.PL/POLITE
zaneslo
brought3.SG.NEUT.PFV
sjuda
hereDIRECTIONAL
?
?
What brings you here?/What are you doing here?
This idiom will be recorded under the headword zanesti ?bring?. The core meaning
of the idiom ? COME ? heads the sem-struc. There are two variables in this multi-
word expression: the direct object, mapped to the AGENT of COME, and the spatial
adverbial, mapped to the DESTINATION of COME. These are productively analyzed at
run-time. The meaning of ?what wind? is, of course, attributed null semantics.
To summarize this section: recording obligatorily subjectless idioms not only pro-
vides for their semantic interpretation, it also removes ambiguity in analysis, since the
?elided subject? reading is explicitly blocked.
4 Final Thoughts
This paper has presented an analysis of phenomena that extends past what any given
system currently uses or requires. However, the utility of this analysis reaches well
beyond the traditional goals of descriptive and theoretical linguistics. Ideally, system
building in NLP should centrally involve the objective of incrementally overcoming
176 McShane and Nirenburg
successively more difficult challenges and thus lead to more sophisticated systems in
the future. Looking forward to the next stage can help us to develop methodolog-
ical, architectural and knowledge infrastructures to facilitate progress toward future
goals. The OntoSem environment does not currently work on Russian, though it has
been applied, at least partially, to several languages apart from English in the past ?
including such different languages as Turkish, Spanish, Korean and Georgian. The
reason for exploring the idiom-reference connection in Russian was to judge how well
our approach, which is implemented for and works well in English, holds up cross-
linguistically. Having worked the examples presented in this paper and many others,
we are convinced that when the time comes, a Russian OntoSem will be configurable
without the need to expand the theory and methodology that support our treatment of
idioms, ellipsis and reference overall.
A reasonable question would be, why not evaluate the approach on English, since
an English system already exists? The reason is purely practical: it is far more diffi-
cult and expensive to run evaluations of knowledge-based systems that treat complex
phenomena than it is to run evaluations of systems that treat less complex phenomena.
That being said, we are just completing a new version of our DEKADE knowledge
acquisition and evaluation environment which will make it much easier than before to
evaluate the results of text analysis. We expect regular evaluations to become part of
our development work in the near future.
References
Baldwin, T. and A. Villavicencio (2002). A case study on verb-particles. In Pro-
ceedings of the Sixth Conference on Computational Natural Language Learning
(CoNLL 2002), pp. 98?104.
Cacciari, C. and P. Tabossi (1993). Idioms: Processing, Structure and Interpretation.
Lawrence Erlbaum and Associates, Inc.
Lubensky, S. (1995). Russian-English Dictionary of Idioms. Random House.
McShane, M. (2005). A Theory of Ellipsis. Oxford University Press.
McShane, M., S. Beale, and S. Nirenburg (2004). Some meaning procedures of On-
tological Semantics. In Proceedings of LREC-2004.
McShane, M., S. Nirenburg, and S. Beale (2005). An NLP lexicon as a largely lan-
guage independent resource. Machine Translation 19(2), 139?173.
McShane, M., S. Nirenburg, and S. Beale (2008). Achieving adequacy of description
of multiword entities in semantically-oriented computational lexicons. Submitted.
Mitkov, R., R. Evans, and C. Orasan (2002). A new, fully automatic version of
mitkov?s knowledge-poor pronoun resolution method. In Proceedings of CICLing-
2000.
Nirenburg, S. and V. Raskin (2004). Ontological Semantics. MIT Press.
The Idiom?Reference Connection 177
Pulman, S. (1993). The recognition and interpretation of idioms. In C. Cacciari and
P. Tabossi (Eds.), Idioms: Processing, Structure and Interpretation, pp. 249?270.
Lawrence Erlbaum and Associates, Inc.
Stock, O., J. Slack, and A. Ortony (1993). Building castles in the air: Some com-
putational and theoretical issues in idiom comprehension. In C. Cacciari (Ed.),
Idioms: Processing, Structure and Interpretation, pp. 229?248. Lawrence Erlbaum
and Associates, Inc.
Villavicencio, A., A. Copestake, B. Waldron, and F. Lambeau (2004). The lexical
encoding of MWEs. In Proceedings of the ACL 2004 Workshop on Multiword
Expressions: Integrating processing.
Resolving Paraphrases to
Support Modeling Language
Perception in an
Intelligent Agent
Sergei Nirenburg
Marjorie McShane
Stephen Beale
Universtity of Maryland Baltimore County (USA)
email: sergei@umbc.edu
Abstract
When interacting with humans, intelligent agents must be able not only
to understand natural language inputs but also to remember them and link
their content with the contents of their memory of event and object in-
stances. As inputs can come in a variety of forms, linking to memory
can be successful only when paraphrasing relations are established be-
tween the meaning of new input and the content of the agent?s memory.
This paper discusses a variety of types of paraphrases relevant to this task
and describes the way we implement this capability in a virtual patient
application.
179
180 Nirenburg, McShane, and Beale
1 Overview of and Rationale for Studying Paraphrase
Paraphrase, under any of its many definitions, is ubiquitous in language use. It could
be likened to reference, both in function and in the complexity of its detection and
resolution. Indeed, there are many ways to express a given idea in language: one
can use a canonical word/phrase (dog), a synonymous terse locution (mutt, pooch,
canine, man?s best friend), or an explanatory description that can be of any length and
include one or more specific salient features (a pet that barks; one of the two most
common four-legged domesticated mammals in the USA that is not a cat). Although
these locutions are not semantically identical, they are functionally equivalent in many
contexts, meaning that they can permit a person or intelligent agent to carry out the
same types of reasoning.
No matter which of the above locutions is used to express the idea of dog, a person
or an artificial intelligent agent should be able resolve it to the concept DOG in his/its
world model. Such resolution, or ?anchoring?, permits other knowledge about the
entity to be leveraged for reasoning: for example, the sentence Our pooch has a long
tail should be construed as perfectly normal, whereas Our pooch wrote a grocery list
should be understood as impossible in its direct sense since dogs cannot be agents of
writing. Such incongruence should, in turn, suggest either a non-real world or the use
of pooch as a nickname for some person or intelligent agent, like an automatic grocery
list writing system.
1.1 Work by Others
Paraphrase is a difficult problem: at its deepest, it centrally involves semantics, which,
due to its inherent complexity, can be addressed only in limited ways in current NLP
work. As a result, most contributions devoted to paraphrase can be described as syn-
tactic or ?light semantic.? In some contributions, processing semantics is constrained
to finding synonyms, hyponyms, etc., in a manually constructed word net, like Word-
Net or any of its progeny. Some others do not rely on a manually constructed knowl-
edge resource but, rather, aim to determine distributional clustering of similar words
in corpora (see, e.g. Pereira et al (1993) or Lin (2001)). A few approaches to dealing
with paraphrase actually go beyond the detection and use of synonyms. For exam-
ple, Lapata (2001) seeks to interpret the meanings of contextually elastic adjectives
(such as fast, which means different things in fast highway and fast eater) by semi-
automatically constructing paraphrases for phrases that include such adjectives. These
paraphrases use the original noun and the adjective (or any of its synonyms, taken from
a hand-constructed list) in its adverbial form and add a corpus-derived candidate verb
intended to explain the meaning of the adjective. Results are evaluated by human
judgments of whether a paraphrase (e.g., highway travel quickly) is appropriate as an
explanation of the meaning of fast in fast highway.
Ibrahim et al (2003) pursue the more immediate goal of supporting a question-
answering system. Creating paraphrases for questions helps to expand the queries
to the textual resources that are mined for answers. In an early version of this sys-
tem, such paraphrase rules ? which included a combination of lexical and syntactic
transformations ? were created by hand (Katz and Levin, 1988). The new approach
follows the methodology of Lin and Pantel (2001) for dynamically determining para-
phrases in a corpus bymeasuring the similarity of paths between nodes in syntactic de-
Resolving Paraphrases to Support Modeling Language Perception 181
pendency trees. This method was applied to pairs of sentences from different English
translations of the same text. (The idea of using a monolingual ?sentence-aligned?
corpus is due to Barzilay and McKeown (2001).) Ibrahim et al (2003) then suggest
a set of heuristics for the subsentential-level matching of nouns and pronouns which
leads to the specification of paraphrases in terms of rules such as X became a state
in Y ? X was admitted to the Union in Y. The reported precision of the process is
about 41%, while the upper bound is given at about 65%.1 Ibrahim et al state that
?question answering should be performed at the level of ?key relations? in addition
to keywords.? We believe that it is even better to use key word senses rather than
key words, and to include key relations of a semantic and pragmatic nature ? though
syntactic information should be retained as a valuable source of heuristics for spec-
ifying semantic relations. We believe that we have developed enabling technologies
and resources that allow us, at this time, to process paraphrase by relying on meaning
representations rather than just syntactic dependencies and text-level relations.
One system that has an application area similar to ours is the one developed by
Boonthum (2004). Boonthum is developing an automatic tutoring application that
will be enhanced by paraphrase recognition. To process paraphrase, she automatically
converts natural language sentences into Conceptual Graphs (Sowa, 1983) and com-
pares the graphs of two candidate paraphrases using various metrics. This system,
unlike ours, works at the level of strings (not concepts), does not automatically carry
out disambiguation, and cannot handle complex sentences or long spans of text.
Since paraphrase recognition, when viewed broadly, is a very challenging task,
some developers choose to focus on a narrow application area. One such system,
reported in Brun and Hag?ge (2003), detects paraphrases in texts about toxic prod-
ucts. Developers hand create rules using lexical and structural information, and sys-
tem output is logical structures like PHYS_FORM(acetone,liquid), which means that
the physical form of acetone is liquid. The approach taken in this work seems very
appropriate for this narrow domain of interest.
1.2 Our research methodology
The research methodology we adopt has the following features, which will serve to
orient it in the landscape of work by others. This methodology:
? addresses paraphrase within an application;
? takes into account the needs of question answering and ? more broadly speak-
ing ? dialog processing;
? integrates paraphrasing due to different types of agent perception: the percep-
tion of language and the perception of non-linguistic inputs, like interoception
(sensitivity to stimuli originating in the body, e.g., symptoms of a disease);
? uses an agent?s memories as both the source of paraphrase detection and as the
target to which new memories are linked; and
1We believe that the low upper bound is due to the way the problem was framed. In cases where
the semantic differences among candidate paraphrases are important (not ?benign?), the inter-respondent
agreement, we believe, will be higher.
182 Nirenburg, McShane, and Beale
? has provisions for including conceptual paraphrases, which are different ways
of describing the same object or event that must be interpreted using the onto-
logical knowledge available to specific agents.
The initial experimentation that we are reporting covers a relatively narrow domain
but we hypothesize that the same methodology can be used in other domains, with
certain modifications related to ontological and lexical coverage.
1.3 Maryland Virtual Patient (MVP)
The application that drives our current research is Maryland Virtual Patient (MVP),
which is an agent-oriented simulation and tutoring system. In MVP, a human user
plays the role of a physician in training who must diagnose and treat open-ended sim-
ulations of patients, with or without the help of a virtual mentor agent (e.g. McShane
et al, 2007). The virtual patient is, itself, a ?double? agent, comprised of: (a) a physio-
logical agent that lives over time and responds in realistic ways to disease progression
and interventions, and (b) a cognitive agent that experiences symptoms, decides when
to consult a physician, makes decisions about its lifestyle, treatment options, etc., and
communicates with a human user using natural language. The system currently covers
six diseases of the esophagus, so many of our examples will come from this subdo-
main of medicine.
As should be clear even from this brief overview, MVP is a reasoning-intensive
application. Both physiological simulation and NLP are supported by hand-crafted,
ontologically grounded knowledge that includes:
1. a general purpose ontology with broad and deep coverage of medical concepts,
including ontological scripts describing disease progression and treatment, the
plans and goals of patients and physicians, clinical best practices, medical in-
terviews and dialog in general
2. a lexiconwhose entries include a syntactic structure, a semantic structure (linked
to the ontology), and calls to procedural semantic routines (e.g., to provide for
the reference resolution of pronouns and other deictics)
3. a fact repository, which is a memory of assertions, as contrasted with the ontol-
ogy, which covers knowledge of types.
All knowledge in the MVP environment is recorded using the metalanguage of
description of Ontological Semantics (Nirenburg and Raskin, 2004). The MVP ap-
plication will serve as a concrete example for the discussion of paraphrase processing
in applications that include intelligent agents. However, the analysis is readily gen-
eralizable and could be applied to any system that would benefit from paraphrase
understanding.
This paper will not discuss all types of paraphrase and how OntoSem (the imple-
mentation of the theory of Ontological Semantics) handles them, even though one
of the core contributions of OntoSem is the robust handling of lexical and syntactic
paraphrase by automatically deriving identical meaning representations for inputs that
contain such paraphrases (for discussion see Nirenburg and Raskin, 2004, Chapter 8).
Here we focus on just a few of the more ?compositional-semantic? types of paraphrase
and our theoretical and implementation-oriented solutions to treating them.
Resolving Paraphrases to Support Modeling Language Perception 183
2 Paraphrase-Oriented Eventualities
Each agent in MVP is supplied with its own ontology, lexicon and fact repository
(i.e., memory), which can be enriched on the fly in various ways based on the agent?s
activities ? be they linguistic, interoceptive, or other. In order for the language-
endowed agents (on whom we focus here) to operate intelligently ? as when answer-
ing questions posed by the human user or learning new facts he presents to them ?
they must be able to interpret language input, remember the content of that input,
and attempt to match/link that content with memories already stored in their fact
repository. Linking new information to old memories is a standing goal of all intel-
ligent agents, and in MVP it is triggered automatically for each new input. A core
capability enabling such linking is the recognition and resolution of paraphrase.
We will show how various types of paraphrase are handled as part of agent memory
management in the OntoSem environment. More specifically, we focus on creating
and linking new knowledge from linguistic input, not on the use of this knowledge for
reasoning. Memory management (e.g., modeling forgetting and generalizing) is also
a key enabling technology, but one whose description lies outside of the scope of this
paper.
Having generated a meaning representation (MR) for a textual input, the intelligent
agent must consider the following eventualities in deciding on how to remember the
content of this input. The eventualities in boldface (numbers 5, 6 and 7) are those that
we will be discussing in some detail below.
1. The newly input MR is identical to a stored memory
2. The newly input MR is identical to a stored memory except for metadata values:
the identity of the speaker, the time stamp, etc. This can be viewed as type
coreference. For example, in the MVP environment, if the agent coughs every
day, is every cough a new instance or is it better remembered as a generalized
action with a given periodicity? The answer here depends in a large part on
the event generalization capabilities of an agent (a component of its memory
management capabilities): indeed, even in real life one cannot be immune from
the failure to realize that a certain sequence of events is actually better viewed
as a single periodic event.
3. The newly input MR contains a subset or a superset of properties of a stored
memory. For example, the new input can describe only the location of a symp-
tom but not its severity, whereas remembered instances of this same symptom
may overtly list its severity and various other properties. Note that the informa-
tion about which properties are applicable to a particular concept is stored in the
ontology; the memory (fact repository) contains information about those of the
properties that were overtly perceived by the agent.
4. The new input is similar to a stored memory but one or more properties has
a different value. For example, an input could specify one level of symptom
severity while stored instances of the symptom may specify different values of
this property.
184 Nirenburg, McShane, and Beale
5. The newly input MR (or a component of it) is related to a stored memory
via ontological subsumption, meronymy or location.
6. The newly input MR is related to a stored memory as the latter?s precondi-
tion or effect.
7. The newly input MR is related to a stored memory via ?ontological para-
phrase.?
8. The new input is not related to any stored memory because different concepts
are used, there are conflicting property values, etc. For example, a symptom
experienced by somebody other than the given agent may be known to the agent,
but the agent will certainly not interpret it as coreferential with knowledge about
its own symptoms.
For case 1, the new information is interpreted as confirmation of the existing mem-
ory, it is not stored as a separate memory. For case 2, the choice of storing instances
individually or grouping them into a recurring event is determined by the agent?s mem-
ory management activities. For cases 3-8 reasoning must be carried out to determine
if there is a match or not. In our current implementation, if a stored MR unifies with
the newly input MR, the two MRs are judged to be paraphrases. With respect to case
4, this is a simplification because significant differences in values of properties in the
two MRs under comparison should be used as heuristics voting against declaring the
two MRs paraphrases. However, this level of analysis requires the establishment of
a scale of relevancy on all the properties of a given concept, a task that we defer to
future system releases. For case 8, the new information should be stored as a new
memory. Let us consider eventualities 5-7 in more detail.
2.1 The newly input MR (or a component of it) is related to a stored memory
via ontological subsumption, meronymy or location
There is much variability in the use of language, which can result from lack of knowl-
edge of more precise terminology or from a person?s understanding that certain kinds
of underspecificity are entirely acceptable. For example, one can say Let?s eat at your
place rather than specifying whether we mean a house, a condominium or a studio
apartment; and one can say Does your arm hurt? rather than asking Does the broken
bone in your arm hurt or, even more specifically, Does your ulna hurt?
When attempting to match new textual input with a stored memory, the question is,
how close do the compared MRs have to be in order to be considered a match? An
important consideration when making this judgment is the application. In the dialog
application we are developing, the notion of sincerity conditions plays an important
role. That is, the VP expects the physician to ask it questions that it can answer; there-
fore, it should try hard? and search broadly, if necessary? to come up with the clos-
est memories that will permit it to generate a response. In McShane et al (2008) we
suggest an algorithm that determines when two closely related MRs are close enough
to be considered identical. The algorithm involves following three types of ontological
links ? subsumption, meronymy and location; if a match is found within the ?lower?
(i.e., domain-specific) ontology, then the related elements are considered a paraphrase.
Let us show how this paraphrase processing works using a concrete example.
Resolving Paraphrases to Support Modeling Language Perception 185
The physician asks the virtual patient, Do you have any discomfort in your esoph-
agus? The MR for that question is as follows.
(REQUEST-INFO-1
(THEME MODALITY-1.VALUE))
(MODALITY-1
(TYPE EPISTEMIC)
(SCOPE DISCOMFORT-1))
(DISCOMFORT-1
(EXPERIENCER HUMAN-1)
(LOCATION ESOPHAGUS-1))
(ESOPHAGUS-1
(PART-OF-OBJECT HUMAN-1))
The interrogativemood gives rise to the instance of request-info, whose theme is the
value of epistemic modality that scopes over the proposition headed by DISCOMFORT-
1. (If the event actually happened, then the value of epistemic modality is 1; if it did
not happen, then the value is 0).
The event DISCOMFORT is experienced by HUMAN-1, which will be linked to a
specific human (the interlocutor) via reference resolution (reference resolution is car-
ried out on every referring expression in OntoSem). The LOCATION of the DISCOM-
FORT is the ESOPHAGUS of that HUMAN.
If we extract the core meaning of this question, abstracting away from the interrog-
ative elements, we have:
(DISCOMFORT-1
(EXPERIENCER HUMAN-1)
(LOCATION ESOPHAGUS-1))
(ESOPHAGUS-1
(PART-OF-OBJECT HUMAN-1))
Let us assume that the patient has stored memories about its discomfort in a differ-
ent way, as an undifferentiated symptom in its chest:
(SYMPTOM-1
(EXPERIENCER HUMAN-1)
(LOCATION CHEST-1))
(CHEST-1
(PART-OF-OBJECT HUMAN-1))
Note that the patient stores memories of interoception directly, translating the out-
put of its physiological agent into a memory that is in keeping with its own ontology.
This translation is necessary because the agent?s own ontology is a ?lay? ontology ?
one lacking highly specified medical subtrees. The ontology available to the phys-
iological agent, by contrast, is an ?expert? ontology that is rich enough in medical
knowledge to support disease simulation and treatment (see McShane et al, 2008).
186 Nirenburg, McShane, and Beale
The MR components in boldface are the ones that must be matched. DISCOMFORT
is a child of SYMPTOM, forming a subsumption link of only one jump. ESOPHAGUS
has a LOCATION of CHEST, and they are both PART-OF-OBJECT the human in ques-
tion. Therefore, according to our matching algorithm ? in conjunction with the fact
that the VP assumes sincerity conditions in its conversations with the physician ? the
VP?s memory of this event sufficiently matches the physician?s question and the VP
can respond affirmatively to the question: i.e., the VP has a memory of the symptom
the physician is asking about.
In discussing the next two paraphrase-oriented phenomena we will shift to a dif-
ferent application area not because the medical domain lacks examples, but because
understanding them would require too much background knowledge. The application
area we will posit is an agent that is a personal companion, with the agent?s job being
to uphold its end of an open-ended conversation.
2.2 The newly input MR is related to a stored memory as the latter?s
precondition or effect
Consider the following dialog snippet between an elderly woman, Anne, and an intel-
ligent agent that serves as her ?conversational companion?:
Anne: You know, my husband and I went to Rome for our honeymoon.
Agent: Is that so?
Anne: Yes. We ate such great artichokes in Trastevere!
As the agent participates in this conversation, it creates and stores memories of the
meaning of Anne?s utterances. In analyzing Anne?s final utterance, the agent should
create a link between Anne and her husband being in Trastevere, and Anne and her
husband traveling to Rome.
OntoSem produces the following core meaning representation for the statement
about traveling to Rome:
(TRAVEL-EVENT-1
(AGENT SET-1)
(DESTINATION ROME)
(TIME (< find-anchor-time)))
(SET-1
(MEMBERS HUMAN-1 HUMAN-2))
Some details are omitted in the above structure, as they are not relevant to our
exposition here. Find-anchor-time is a meaning procedure that triggers a search in
the metadata or in the text itself for the time of the event, which is before the time of
speech. The above meaning representation will be stored by the agent in its memory.
The meaning representation (again, omitting some details) for the statement about
eating in Trastevere will be:
(INGEST
(AGENT SET-1) ; coreferential with SET-1 above
(THEME ARTICHOKE-1)
(LOCATION TRASTEVERE)
Resolving Paraphrases to Support Modeling Language Perception 187
(TIME (< find-anchor-time)))
(MODALITY-1
(TYPE EVALUATIVE)
(SCOPE ARTICHOKE-1)
(VALUE 1)
(ATTRIBUTED-TO HUMAN-1))
At this point the agent must check whether the above MR should be linked in the
agent?s memory to the memory of the travel event processed earlier. In this case, a
match is found ? that is, the agent can establish that a precondition of the second
event is among the effects of the first one. Specifically, the linking occurs because:
1. the agent?s ontology contains the description of a complex event (a script)
TRAVEL-EVENT, where it is listed that an ef fect of traveling to X is being in X;
2. the agent?s ontology contains the knowledge that a precondition for an INGEST
event taking place at LOCATION Y with AGENT X is that X is at LOCATION Y;
3. the agent?s fact repository contains the knowledge that Trastevere is a neighbor-
hood in Rome.
2.3 The newly input MR is related to a stored memory via ontological
paraphrase
The third source of paraphrase we will discuss is what we call ontological paraphrase.
This occurs when more than one metalanguage representation means the same thing.
In an environment with only artificial agents, where communication can be carried out
without resorting to natural language, such paraphrase should be excluded to the extent
possible. However, in environments (like MVP) where meaning representations can
be generated from natural language, this eventuality is more difficult to avoid. This is
because a) basic meaning representations are produced on the basis of lexicon entries
for words and phrases appearing in the sentence; and b) a word or phrase can be used
in a particular sentence to render a narrower or broader meaning than it has in general.
Now, in creating basic meaning representations, OntoSem uses concepts that are listed
in the lexicon entries for the appropriate senses of the input words (in this paper we
do not describe OntoSem?s approach to word sense disambiguation and determination
of semantic dependencies), and these concepts cannot reflect broadening or narrowing
usages of the word. A good example of this phenomenon is the following: One can
say (a) go to London by plane or (b) fly to London, and these inputs will generate
different MRs:
(a) (MOTION-EVENT-7 (DESTINATION London) (INSTRUMENT AIRPLANE))
(b) (AERIAL-MOTION-EVENT-19 (DESTINATION London)).
This is because the semantics of the appropriate sense of go is explained using the
concept MOTION-EVENT, while the semantics of the appropriate sense of fly uses
AERIAL-MOTION-EVENT. In the former structure, the head event instance is more
general than in the latter. In fact, the corresponding ontological concepts stand in a
188 Nirenburg, McShane, and Beale
direct subsumption relation. If one chooses to use a concept that is higher in the onto-
logical hierarchy, one may have to add further overt constraints to the meaning repre-
sentation (like the one about the INSTRUMENT of the MOTION-EVENT above). If one
chooses the lower-level, narrower ontological concept to start with, such constraints
may be inherent in its definition (as is the case with AERIAL-MOTION-EVENT). This
preference is the inverse of the lexical choice in text generation off of text meaning
representations (for details see Nirenburg and Nirenburg, 1988).
OntoSem can yield either of the above basic text meaning representations. In many
applications ? for example, in interlingua-based machine translation ? this would
be quite benign. However, it is possible to create extended meaning representations
such that the above variability is eliminated. The method we use for this purpose relies
on the dynamic tightening or relaxation of selectional restrictions and is described in
detail in Mahesh et al (1997). Note that different paraphrases will still be produced
for inputs that, while referring to the same event instance, describe it with a different
degree of vagueness or underspecificity (see Section 2.1 above).
The fact that the two meaning representations above are paraphrases of one an-
other can be automatically detected using a fairly simple heuristic: the ontological
description of AERIAL-MOTION-EVENT includes the following property-value pairs:
AERIAL-MOTION-EVENT
IS-A MOTION-EVENT
INSTRUMENT AIRPLANE HELICOPTER BALLOON
Since the head of one of the MRs is an ancestor of the other, and the property-value
pairs in the ancestor-based MR unify with the ontological definition of the descendant
(the head of the other MR), these two structures are deemed to be paraphrases.
As we see from this example, world knowledge stored in the ontology is leveraged
to carry out the reasoning needed to detect that the abovementioned formal structures
are paraphrases. Such situations are somewhat similar to ?bridging references? in the
literature devoted to reference resolution (e.g. Poesio et al, 2004) because a knowl-
edge bridge is needed to aid in the reference resolution of the entity.
A common source of this type of paraphrase derives from decisions about how to
build the ontology. Ontology building is a complex task with ?the lesser of the evils?
decisions to be made at every turn. Two ontologies can be equally valid and yet look
quite different. One of the most difficult aspects of ontology building is deciding when
a new concept is needed. Let us continue with the example of taking a trip. A small
excerpt from the MOTION-EVENT subtree of our ontology is as follows:
MOTION-EVENT
AERIAL-MOTION
LIQUID-CONTACT-MOTION
SURFACE-CONTACT-MOTION
TRAVEL-EVENT
. . .
As we can see, rather than having a single MOTION-EVENT lexically supplemented
by property-value pairs that distinguish between types of motion, we have various
Resolving Paraphrases to Support Modeling Language Perception 189
types of motion being represented as different ontological concepts. This means that
when different kinds of motion are referred to ? even if they describe the same real-
world event ? they will instantiate different concepts in MR and we will be faced
with the problem of matching at the level of MR. Whereas this matching problem
can be seen as a vote for constraining the number of ontological concepts, there are
practical reasons for not wanting to overdo this: for example, MRs are much harder to
read and evaluate when lexical senses are described using property-value pairs rather
than simply pointing to an iconic ontological concept that holds the description. Of
course, the use of iconic concepts results in lower expressive power of an ontology,
which affects the reasoning capabilities of agents in memory management, goal- and
plan-based reasoning and the more complex cases of language understanding.
2.4 Theoretical Notes
This work derives from the theoretical assumption that in order for agents to show truly
intelligent behavior their memory must be well managed. What is actually stored as a
memory, however, is a complex question. For example, if someone were to describe a
trip to New York and never referred to it as ?trip to NY? but rather said that he ?was
in NY? (and the interlocutor knows that he doesn?t live there), the interlocutor might
still save the memory as
(TRAVEL-EVENT-1
(AGENT HUMAN-1)
(DESTINATION New York)).
So the ?grain size? of memories is a compelling and complex problem. However,
we must deflect a deep study of the question What is memory, agreeing with Minsky
(2006) that lingering over definitions that might never be truly precise does not support
practical progress.
Describing this work in broad terms risks conveying the impression that it is trivial,
either conceptually or in terms of implementation. In fact, both of these facets of the
work are quite complex, involving extensive theoretical and practical decision-making
at every step ? one of the reasons, perhaps, why it is not being broadly pursued.
The standard counterargument that resource development for such an approach is too
expensive does not hold up when one considers the cost of semantically annotating
corpora and then building machine learning engines to exploit such corpora. Another
criticism of knowledge-based approaches is that they are too narrow in coverage. In-
deed, one cannot cover broad corpora at a deep level all at once; however, the insights
gained in carrying out this kind of work, and its potential to significantly enhance the
current state of the art in NLP, are really quite exciting. And, of course, there are no
a priori preferences for starting with breadth and striving for depth over the opposite
strategy of starting with depth and striving for breadth.
One final point must be mentioned. The OntoSem environment that forms the
substrate for the work described here is used for applications that are much broader
than MVP. Recent applications include question-answering and information extrac-
tion. Thus, the ongoing development of the ontology, lexicon, fact repository and
semantic analyzer benefits a range of application areas.
190 Nirenburg, McShane, and Beale
3 State of Development
We have developed a complete simulated physiological agent that covers diseases of
the esophagus and is capable of realistic physiological responses to even unexpected
interventions. We have developed a tool for the fast creation of large libraries of
physiological agents that feature different diseases, different genetic and behavioral
predispositions and different realistic disease progressions. We have implemented a
cognitive agent capable of interoception, perception through language, goal- and plan-
based reasoning (within the domain of doctor-patient interaction), memory manage-
ment, (simulated) physical action and (real) verbal action. With respect to interocep-
tion, we have developed a simulation of how the cognitive agent (the cognitive side of
the ?double? agent) perceives signals (symptoms) from its physiological agent coun-
terpart. Even though a single knowledge representation substrate is used for modeling
both agents, the interoception simulation process involves paraphrase.
We have developed a set of knowledge resources covering relevant knowledge
about the world (the ontology), past events remembered by the agent (the fact reposi-
tory) and knowledge about language (represented, largely, in the agent?s lexicon).
The operational OntoSem semantic analyzer is used as the basic tool for creating
meaning representations from language inputs. The latter already reflect results of the
resolution of many kinds of paraphrase as a matter of course.
Content specification for the agent?s dialog turns is addressed in the implemented
goal- and plan-based reasoning module of the cognitive agent. Surface generation of
agent dialog turns has, at this point, been implemented in a limited fashion, on the
basis of prefabricated open textual patterns linked to types of text meaning represen-
tations that are output by the content specification module. In the next release of MVP
we intend to incorporate a text realizer such as YAG (McRoy et al, 2003).
Upcoming evaluations will continue to help to debug the system and the underlying
knowledge; and, more importantly for the topic of this paper, data will be collected
for an evaluation of the dialog component of the system.
The quality of the system?s treatment of paraphrase will be judged at two levels.
First, the appropriateness of the agent?s dialog responses will provide a practical,
application-based measure of the quality of paraphrase processing, though blame as-
signment for anymiscues will pose a complication. Second, we will be able to directly
inspect the agent?s memory for traces of the resolution of paraphrase against remem-
bered concept instances and judge the appropriateness of these results against human
decisions. To facilitate this, we will provide textual glosses to meaning representa-
tions comprising the agent?s memory. The above regimen is the most economical way
to evaluate our approach because an important prerequisite for evaluating the perfor-
mance of paraphrase resolution algorithms in our environment is the creation of the
fact repository (i.e., the agent?s memory), against which the comparisons and linking
occur. In the proposed testing regimen, this memory will be augmented and man-
aged as a result of the operation of the system itself, so that there will be no need for
creating it just for the purposes of evaluation.
Resolving Paraphrases to Support Modeling Language Perception 191
References
Barzilay, R. and K. McKeown (2001). Extracting paraphrases from a parallel corpus.
In Proceedings of the 39th Annual Meeting of the Association for Computational
Linguistics (ACL-2001).
Boonthum, C. (2004). iSTART: Paraphrase recognition. In Proceedings of the Student
Research Workshop at ACL 2004, pp. 31?36.
Brun, C. and C. Hag?ge (2003). Normalization and paraphrasing using symbolic
methods. In Proceedings of the Second International Workshop on Paraphrasing
(IWP 2003).
Ibrahim, A., B. Katz, and J. Lin (2003). Extracting structural paraphrases from aligned
monolingual corpora. In Proceedings of the Second International Workshop on
Paraphrasing (IWP 2003).
Katz, B. and B. Levin (1988). Exploiting lexical regularities in designing natural
language systems. In Proceedings of the 12th International Conference on Com-
putational Linguistics (COLING-1988).
Lapata, M. (2001). A corpus-based account of regular polysemy: The case of context-
sensitive adjectives. In Proceedings of the Second Meeting of the North American
Chapter of the Association for Computational Linguistics (NAACL-2001).
Lin, D. (2001). Extracting collocations from text corpora. In Proceedings of the First
Workshop on Computational Terminology.
Lin, D. and P. Pantel (2001). DIRT - discovery of inference rules from text. In Pro-
ceedings of the ACM SIGKDD Conference Conference on Knowledge Discovery
and Data Mining.
Mahesh, K., S. Nirenburg, and S. Beale (1997). If you have it, flaunt it: Using full
ontological knowledge for word sense disambiguation. In Proceedings of TMI-97.
McRoy, S. W., S. Channarukul, and S. S. Ali (2003). An augmented template-based
approach to text realization. Natural Language Engineering 9(4), 381?420.
McShane, M., S. Nirenburg, and S. Beale (2008). Two kinds of paraphrase in model-
ing embodied cognitive agents. In Proceedings of the Naturally-Inspired Artificial
Intelligence AAAI Fall Symposium.
McShane, M., S. Nirenburg, S. Beale, B. Jarrell, and G. Fantry (2007). Knowledge-
based modeling and simulation of diseases with highly differentiated clinical man-
ifestations. In Proceedings of the 11th Conference on Artificial Intelligence in
Medicine (AIME 07).
Minsky, M. L. (2006). The Emotion Machine. Simon & Schuster.
Nirenburg, S. and I. Nirenburg (1988). A framework for lexical selection in natural
language generation. In Proceedings of COLING-88.
192 Nirenburg, McShane, and Beale
Nirenburg, S. and V. Raskin (2004). Ontological Semantics. MIT Press.
Pereira, F., N. Tishby, and L. Lee (1993). Distributional clustering of English words.
In Proceedings of the 30th Annual Meeting of the Association for Computational
Linguistics (ACL-1991).
Poesio, M., R. Mehta, A. Maroudas, and J. Hitzeman (2004). Learning to resolve
bridging references. In Proceedings of the 42nd Annual Meeting on Association
for Computational Linguistics.
Sowa, J. F. (1983). Conceptual Structures: Information Processing in Mind and Ma-
chine. Addison-Wesley.
Baseline Evaluation of WSD
and Semantic Dependency in
OntoSem
Sergei Nirenburg
Stephen Beale
Marjorie McShane
University of Maryland Baltimore County (USA)
email: sergei@umbc.edu
Abstract
This paper presents the evaluation of a subset of the capabilities of the On-
toSem semantic analyzer conducted in the framework of the Shared Task
for the STEP 2008 workshop. We very briefly describe OntoSem?s com-
ponents and knowledge resources, describe the work preparatory to the
evaluation (the creation of gold standard basic text meaning representa-
tions) and present OntoSem?s performance on word sense disambiguation
and determination of semantic dependencies. The paper also contains el-
ements of a methodological discussion.
315
316 Nirenburg, Beale, and McShane
1 Overview of OntoSem
OntoSem, which is the implementation of the theory of Ontological Semantics (Niren-
burg and Raskin, 2004), is a text-processing environment that takes as input unre-
stricted raw text and carries out preprocessing followed by morphological, syntactic,
semantic, and discourse analysis, with the results of analysis represented as a formal
text-meaning representation (TMR) that can then be used as the basis for various ap-
plications. Text analysis relies on several knowledge resources, briefly described in
the subsections below.
1.1 The OntoSem Ontology
The OntoSem ontology is a formal, language-independent, unambiguous model of
the world that provides a metalanguage for describing meaning. It is a multiple-
inheritance hierarchical collection of frames that contains richly interconnected de-
scriptions of types of OBJECTs, EVENTs and PROPERTies. It is a general purposes
ontology, containing about 9,000 concepts, that has a number of especially well de-
veloped domains that reflect past and ongoing application-specific knowledge acqui-
sition. Each OBJECT and EVENT is described by several dozen properties, some prop-
erty values being locally specified and others, inherited from ancestors.
Selectional restrictions in the ontology are multivalued, with fillers being intro-
duced by a facet. The value facet is rigid and is used less in the ontology than in its
sister knowledge base of real-world assertions, the fact repository (see Section 1.3).
The facets default (for strongly preferred constraints) and sem (for basic semantic
constraints) are abductively overridable. The relaxable-to facet indicates possible but
atypical restrictions, and not blocks the given type of filler.
Event-oriented scripts encode typical sequences of EVENTs and the OBJECTs that
fill their case-roles. Scripts are used to reason about both language and the world and,
in addition to supporting text processing, can support simulation, as in our ongoing
Maryland Virtual Patient project (see, e.g. McShane et al, 2007).
The number of concepts in the ontology is far fewer than the number of words or
phrases in any language due to the existence of synonyms in language; the possibility
of describing lexical items using a combination of ontological and extra-ontological
(e.g., temporal) descriptors; the use of a single concept for each scalar attribute that
describes all words on that scale (e.g., gorgeous, pretty, ugly); and the decision not to
include language-specific concepts in the ontology.
As an example of the description of an ontological concept, consider an excerpt
from the description of the concept ESOPHAGUS:
ESOPHAGUS
IS-A value ANIMAL-ORGAN
LOCATION sem TRUNK-OF-BODY
DISTAL-TO sem PHARYNX
PROXIMAL-TO sem STOMACH
LENGTH sem 24
default-measure CENTIMETER
INSTRUMENT-OF sem SWALLOW
THEME-OF sem ESOPHAGEAL-CANCER
ACHALASIA ...
Baseline Evaluation of WSD and Semantic Dependency in OntoSem 317
It is the richness of the property-based descriptions that permit the OntoSem ontology
to be used for high-end applications like medical simulation and tutoring.
1.2 The OntoSem Lexicon
Even though we refer to the OntoSem lexicon as a semantic lexicon, it contains more
than just semantic information: it also supports morphological and syntactic analysis
and generation. Semantically, it specifies what concept, concepts, property or proper-
ties of concepts defined in the ontology must be instantiated in the TMR to account
for the meaning of a given lexical unit of input.
Lexical entries are written in an extended Lexical-Functional Grammar formalism
using LISP-compatible format. The lexical entry ? in OntoSem, it is actually called
a superentry ? can contain descriptions of several lexical senses; we call the latter
entries. As an example, consider the 2nd sense of take:
(take-v2
(cat v)
(def "to begin to grasp physically")
(ex "He took her hand as she got out of the car.")
(syn-struc
((subject ((root $var1) (cat n)))
(root $var0) (cat v)
(directobject ((root $var2) (cat n)))))
(sem-struc
(HOLD
(phase begin)
(AGENT (value ? $var1))
(THEME (value ? $var2)))))
The sem-struc says that the meaning of this word sense is the inceptive aspect (?phase
begin?) of the ontological event HOLD. The AGENT of HOLD is assigned the meaning
of $var1 (the caret indicates ?the meaning of?) in the input text, and the THEME of
HOLD is assigned the meaning of $var2. The OntoSem lexicon currently contains
approximately 35,000 senses. For further information about the lexicon, see, e.g.,
McShane et al (2005b).
A sister resource to the lexicon is the onomasticon, a lexicon of proper names
linked to their respective ontological concepts: e.g., IBM is semantically described as
CORPORATION.
1.3 The Fact Repository
The fact repository contains numbered remembered instances of concepts, with the
numbers being used for disambiguation: e.g., HUMAN-FR88 is the 88th human stored
in the fact repository ? e.g., President Clinton. Some aspects of ?general world
knowledge? are part of the seed fact repository used for all applications: e.g., France
is recorded as NATION-FR47, and this information is available to all intelligent agents
in our environment. This seed fact repository is then dynamically augmented as a
given corpus is being processed. The fact repository also supports text processing, as
for reference resolution: e.g., President Clinton in any text will be coreferential with
HUMAN-FR88.
318 Nirenburg, Beale, and McShane
2 Text Meaning Representations (TMRs)
Section 3 includes an example of a TMR taken from the competition texts as well
as a description of it. Here we will give a brief overview of the status of TMRs in
OntoSem.
TMRs represent propositions connected by discourse relations (see Nirenburg and
Raskin (2004), Chapter 6 for details). Propositions are headed by instances of on-
tological concepts, parameterized for modality, aspect, proposition time and overall
TMR time.Each proposition is related to other instantiated concepts using ontologi-
cally defined relations. Coreference links form an additional layer of linking between
instantiated concepts in the TMR as well as stored concept instances in the fact repos-
itory.
3 The STEP 2008 Shared Task
This section describes the evaluation of OntoSem results for the shared task at the
STEP 2008 Workshop. Individual groups were allowed to make their own decisions
with respect to a number of important parameters of the task, including, among others:
1. the nature of the metalanguage of semantic description (e.g., whether it relies
on uninterpreted clusters of word senses, defined either within a language or
cross-linguistically; whether it is based on a language-independent ?interlin-
gual? vocabulary; whether the latter is interpreted by assigning properties to
vocabulary elements and constraints on the values of these properties, etc.);
2. the breadth of the coverage of phenomena (e.g., whether to include word sense
disambiguation, semantic dependency determination, reference resolution, cov-
erage of modality, aspect, time, quantification, etc.);
3. the depth of coverage of phenomena (e.g., the grain size of the description of
word senses, the size of the inventory of semantic roles and other descriptive
properties);
4. whether the analyzer is tuned to produce a complete result for any input; to
produce partial results for all or some inputs; to produce output only for inputs
it knows it can process;
5. whether (and how) the analyzer takes into account benign ambiguities, vague-
ness and underspecification;
6. whether the analyzer creates a semantic and pragmatic context for the input
texts, thus modeling human ability to activate relevant knowledge not expressly
mentioned in the text;
7. the practical end application(s) that a particular semantic analyzer aims to sup-
port.
In working on the shared task, our group has elected to test our system?s perfor-
mance on word sense disambiguation (WSD) and semantic dependency determina-
tion. (For an early small-scale evaluation, see Nirenburg et al (2004).) A prerequisite
Baseline Evaluation of WSD and Semantic Dependency in OntoSem 319
for our chosen evaluation experiment was filling the lacunae in lexical coverage. Two
points are important to make here: a) we acquired what we consider a complete set of
senses for each input word absent from our lexicon, not just the sense that was needed
for the text ? in other words, this was general-purpose acquisition; b) this was a part
of routine ongoing work on resource acquisition and improvement in OntoSem. The
only difference that these input texts made was with respect to the schedule of what
to acquire first. Here are some basic statistics about our lexicon work. The input
texts contained 270 lemmata, of which 36 (13%) were not originally in the OntoSem
lexicon. 44 senses were added to the lexicon for the 36 words (these words were pre-
dominantly very specific, single-sense ones). In 12 cases, a sense was added to an
existing lexicon entry (bringing the average number of senses for these 12 lemmata to
10.5). Finally, 5 word senses were added not because of any lacunae in the lexicon but
just to make the life of the analyzer more difficult. In the end, the lexicon contained
1,168 senses for the 270 lemmata (an average of 4.33 senses per word).
Note that OntoSem processes more phenomena than WSD and dependency ? as-
pect, time, speaker attitudes (called modalities in OntoSem), reference resolution and
semantic ellipsis, discourse relations, unexpected input, metonymy, etc. In broad
terms, the overall objective of the OntoSem analyzer, when viewed outside of the
needs of this evaluation experiment, is to generate a significant amount of machine-
tractable knowledge from the text, knowledge that includes not just a minimum of
information gleaned from the text but also preference information obtained from the
ontological and fact-repository substrate to be used in disambiguation heuristics and
applications relying on the human ability to reconstruct meanings not overtly men-
tioned in the text for the purposes of reasoning and applications like question answer-
ing. For an overview of how TMRs produced by OntoSem can be used in lieu of
traditional annotation schemes, see McShane et al (2005a).
A standard example of using world knowledge activated in the process of text anal-
ysis is being able to infer (abductively) that once ?virus? has been resolved to be the
organism rather than the computer program, then if the word ?operation? appears fur-
ther on in the text, it is more probable that it means surgery rather than a computer
operation or a military operation. The meaning extraction process also has a strong
filtering ability to reject most of the senses of the words in the input as inappropriate
for the particular text. This ability is not error-proof but the filtering capacity is quite
strong even in the current state of the OntoSem analyzer; also note that the ratio of
selected senses to those filtered away is a good measure of how much the static re-
sources were tuned to a particular text or domain ? the greater the number of senses
per word, the less tuning occurred.
OntoSem distinguishes two stages of meaning representation producing, respec-
tively, what is called basic and extended TMRs. The former covers the parts of the
semantic representation that can be derived from the syntactic and lexical-semantic
information and contains triggers (called ?meaning procedures?) for a variety of mi-
crotheories that require additional heuristics (and usually, as in the case of reference
resolution, use general world knowledge from the ontology and fact repository as well
as a window of text that is wider than a single sentence; for more on meaning proce-
dures see McShane et al (2004)). In this evaluation we constrained ourselves to the
level of basic TMRs.
320 Nirenburg, Beale, and McShane
We will use the following relatively simple example sentence to demonstrate the
scope of work of OntoSem.
Researchers have been looking for other cancers that may be caused by
viruses.
The basic TMR for this sentence is as follows:
SEARCH-103
AGENT RESEARCHER-102
THEME CANCER-104
textpointer look
word-num 3
from-sense look-v2
RESEARCHER-102
AGENT-OF SEARCH-103
multiple +
textpointer researcher
word-num 0
from-sense researcher-n1
CANCER-104
THEME-OF SEARCH-103
CAUSED-BY VIRUS-DISEASE-108
multiple +
textpointer cancer
word-num 6
from-sense cancer-n1
MODALITY-105
TYPE EPISTEMIC
SCOPE CAUSED-BY-109
VALUE 0.5
textpointer may
word-num 8
from-sense may-aux1
CAUSED-BY-109
DOMAIN CANCER-104
RANGE VIRUS-DISEASE-108
SCOPE-OF MODALITY-105
textpointer caused by
word-num 10
from-sense cause-v1
VIRUS-DISEASE-108
EFFECT CANCER-104
multiple +
textpointer virus
word-num 12
from-sense virus-n1
We will describe select aspects of this TMR that apply to all frames. The head of the
TMR is a SEARCH event with the instance number 103. Its AGENT is RESEARCHER-
102 and its THEME is CANCER-104. Both of these case-role fillers also have their own
frames that show inverse relations as well as other properties: e.g., RESEARCHER-102
has the property ?multiple +?, which indicates a set with cardinality > 1. A textpointer
is the word in the text that gives rise to the given concept; its word number is shown,
as is the appropriate lexical sense. The textpointer is included for the benefit of the
Baseline Evaluation of WSD and Semantic Dependency in OntoSem 321
human users, as an aid in debugging. It does not have any bearing on the meaning
representation, as used by an application. Ontological concepts are unambiguous,
as can be seen by the mapping of virus to the concept VIRUS-DISEASE rather than
COMPUTER-VIRUS. Modalities are defined for type, scope and value, with values
being on the abstract scale {0,1}. They are also defined for their attribution, which
defaults to the speaker if no person is indicated explicitly in the text.
In this TMR, it so happens, there are no overt triggers for further processing ?
even though reference resolution is routinely triggered on all objects and events with
the exception of those that are known not to require it (e.g., NPs with an indefinite
article or universally known single entities, such as the sun).
The English gloss of the above TMR is as follows. There is one main event in
the sentence ? the searching event (represented by the word look). The agent of this
event is a set of researchers and the theme of this event is a set of cancers, understood
as diseases. This latter set is further qualified to include only those cancers that are
caused by viruses, understood as organisms. The researchers are not sure at the mo-
ment of speech whether particular cancers are indeed caused ? fully or partially ?
by viruses. It is known to the researchers and the author of the text that some cancer
or cancers may, in fact, be caused by viruses (this is a contribution of the word other
to the meaning of the sentence; another contribution of that word is posting a meaning
procedure for blocking coreference of the cancer or cancers mentioned in this sentence
with those mentioned in previous text). The search started before the time of speech
and is still ongoing at the time of speech.
4 Creating Gold Standard TMRs
Gold standard TMRs form the basis for evaluating the results of automatic semantic
analysis. To serve as useful measures, these TMRs must be created on the basis of the
available static knowledge resources (in the case of OntoSem, mainly the lexicon and
the ontology) and reflect the maximum of what a system could in principle do with
the given resources.
Creating gold standard TMRs is similar to manually annotating texts using the met-
alanguage of OntoSem. Text annotation is a difficult and time-consuming (and, there-
fore, expensive) task. The deeper the level of annotation, the less reliable the results
are. Even syntactic annotation poses problems and does not yield acceptable kappa
scores measuring agreement among annotators (and, of course, agreement among an-
notators is not a fool-proof measure of the quality of an annotation). The annotation
necessary for evaluating OntoSem TMRs is quite deep. Our experience showed that
building gold standard TMRs entirely by hand is a very costly task ? it requires
highly skilled personnel and involves many searches in the knowledge resources for
selecting appropriate TMR components.
In view of the above, we decided on semi-automatic production of gold standard
TMRs as the most economical way of producing high-quality annotations. The pro-
cess is, briefly, as follows. OntoSem operation is modularized into stages. Given
an input, OntoSem runs the first stage and presents its results to the human valida-
tor/editor. The latter corrects any mistakes and submits the resulting structure to the
next stage of OntoSem. The process repeats until OntoSem?s final stage results are
corrected and approved by the human validator, thus yielding a gold standard TMR.
322 Nirenburg, Beale, and McShane
Although ?raw? TMRs can be cumbersome to read, the presentation format shown
below ? which is automatically generated from raw TMRs ? reads rather easily as
non-natural languages go. This demonstrates how our representation is actually quite
NL-like, its role being not unlike the English ?possibilistic? sentences of Schubert
(2002). As concerns writing TMRs, people practically never do it ? the most they do
is check and, sometimes, correct the output of the automatic analysis system.
Figure 1: The preprocessor editor of DEKADE
The user interfaces supporting the production of gold standard TMRs are incor-
porated in DEKADE, OntoSem?s Development, Evaluation, Knowledge Acquisition
and Demonstration Environment. The editor for preprocessor results is illustrated in
Figure 1.
The process of gold standard TMR creation has undergone modifications since the
first version of DEKADE was deployed. In particular, experience showed that people
find it difficult to edit the results of syntactic analysis, since it produces a densely pop-
ulated chart of various options. So, instead of the syntax editor, we introduced a link-
ing editor (see Figure 2) that helps to establish the correct linking between syntactic
arguments and adjuncts on the one hand and semantic case roles and other ontologi-
cal properties on the other. We will return to editing syntactic dependency structures
once we devise or import an ergonomically appropriate method for this task. Figure 3
illustrates the editor of basic TMRs.
The semi-automatic methodology of creating gold standard TMRs has proved ad-
equate. It takes a well-trained person on average less than a minute to correct pre-
processing results for an average sentence of 25 words. Establishing correct linking
between syntactic arguments and semantic case roles can take much longer. Together
with the task of validating word sense selection (because of the peculiarities of the
DEKADE editors), this task takes on average about 30 minutes per 25-word sentence.
The time for final editing of the basic gold standard TMRs varies depending on how
much material is present that does not relate to the ?who did what to whom? compo-
nent of meaning. However, the overall net time needed to create a gold standard TMR
Baseline Evaluation of WSD and Semantic Dependency in OntoSem 323
Figure 2: The linking editor of DEKADE
Figure 3: The TMR editor of DEKADE
324 Nirenburg, Beale, and McShane
for a 25-word sentence is on the order of about 40 minutes.
Our methodology of semi-automatic creation of gold standard TMRs differs from
the established rules of the game in the annotation-based evaluation business. We se-
lected this approach because it a) significantly cuts the time needed for TMR produc-
tion (we believe that the task would be simply impractical if attempted fully manually
? the amount of annotation required being too extensive); b) simplifies the evaluation
because it produces the TMR for the one paraphrase that OntoSem will (attempt to)
produce automatically. The main efficiency gain in this semi-automatic production of
gold standard TMRs is in using the OntoSem analyzer as a means of quickly retrieving
and easily inspecting and selecting the lexical senses for the words in the input.
5 Results
Depending on a particular setting, OntoSem can seek one result for WSD or depen-
dency determination, n-best results or both for each case of ambiguity. We chose to
create both types of output. At the level of basic TMR there can in principle be one
or more correct results, the latter case may signify a situation of underspecification or
vagueness, to be resolved in OntoSem by special microtheories leading to the produc-
tion of an extended TMR. In producing gold standard TMRs we always selected the
single correct word sense, irrespective of whether we had to consult other parts of the
input text or general world knowledge.
The results of OntoSem?s performance on word sense disambiguation were evalu-
ated against the gold standard TMRs and involved four different scores. In the case of
each of the scores, performance on individual instances of word sense disambiguation
was averaged over each sentence and text.
Score1 is 1 if the disambiguation was correct and 0 if it was not.
Score2 is 1 if the correct result is in the set of best results returned by OntoSem for
a particular disambiguation instance such that the quality score generated for them by
OntoSem is within 0.03 of the single best score (on the scale from 0 to 1). This score
is 0 if the correct result is not within the above set. This measure was used because
the significance of a preference at this fine-grain level is minimal.
Score3 takes into account the complexity of the disambiguation task by involving
the number of senses from which the choice is made. Indeed, selecting out of 13
candidates is more difficult than out of, say, just 2. Thus, returning an incorrect result
when there are 2 candidates earns a 0 but if there are more than 2 candidates, instead
of 0 (as in Score1), we list the score of 1? (2/n), where n is the number of senses.
A correct result is given a score of 1. As usual, cumulative scores were computed as
simple averages over the input words.
Score4 was calculated using partially corrected results of the preprocessing and
syntactic stages of the analysis process. This score did not take into account the
complexity of the disambiguation task, as did Score3. It was, in fact, Score2 computed
over partially corrected preprocessing results. The purpose of using it is to attempt to
assign blame across the various components of the rather complex OntoSem system.
Semantic dependency results are scored as 1 when they are correct and 0 when
they are incorrect. If an element of TMR is not a part of the semantic dependency
structure but should be then we count that as an error. The results of the evaluation are
summarized in the table below:
Baseline Evaluation of WSD and Semantic Dependency in OntoSem 325
Text WSD Score1 WSD Score2 WSD Score3 WSD Score4 Dependencies
1 42/55 .78 43/55 .87 49.707/55 .90 48/55 .87 20/34 .59
2 30/40 .75 31/40 .78 37.030/40 .93 36/40 .90 15/20 .75
3 22/29 .76 23/29 .79 26.348/29 .91 24/29 .83 18/22 .82
4 75/114 .66 77/114 .68 96.966/114 .85 87/114 .76 44/84 .52
5 67/105 .64 67/105 .64 88.440/105 .84 85/105 .81 36/62 .58
6 82/129 .64 84/129 .65 104.807/129 .79 92/129 .71 45/99 .45
7 95/133 .71 95/133 .71 114.260/133 .86 101/133 .76 47/88 .53
Total 413/605 .68 420/605 .69 517.550/605 .86 474/605 .78 225/410 .55
6 Discussion
Our goal was not to get the best results for this particular task but rather to test some
of the capabilities of the ?raw? OntoSem analyzer. We have always advocated hy-
bridization of methods, a direct consequence of our group?s belief in task- rather than
method-oriented approaches to system building. We fully expect to take that route
when we are putting together the next end application. However, from the scientific
point of view, it is important to assess the quality and promise of a particular method,
even if it is known beforehand that it will be used in practical applications together
with other methods.
Some practical limitations influenced our results. This is why we included the
word ?baseline? in the title of this paper. We intend to eliminate these limitations
over time. The syntactic support for the system has been recently fully revamped
to incorporate the Stanford parser. The work on deriving full syntactic dependency
structures compatible with the requirements and coverage of the OntoSem syntax-to-
semantics linking module from the results provided by the Stanford parser was not
completed by the time of the evaluation. This means, among other things, that not all
the diathesis transformations needed have been included.
In the current version of DEKADE, the automatic validator of lexicon acquisition
does not yet indicate to acquirers when a new lexical sense has the same or very
similar syntactic and semantic constraints. As a result, some of the word senses cannot
currently be disambiguated using the standard selectional restriction-based method.
In addition to the above general limitations, there were some challenges specific to
the particular input corpus. For example, the microtheory of measure has not yet been
fully implemented in OntoSem.
We have not yet done enough to determine the contribution of preprocessing, syntax
and the various semantic microtheories to the final result. We intend to pay more
attention to this blame assignment task.
We restricted ourselves to evaluating just WSD and dependency determination be-
cause of time and resource limitations. It is clear that the quality of OntoSem?s output
for the other microtheories mentioned in Section 3 above, among others, must also be
evaluated.
In addition to the above, we also plan to run an evaluation of OntoSem?s perfor-
mance on treating unexpected input, using the version of the lexicon existing before
the shared task started.
We will also work on modifying the relative importance of heuristics from different
326 Nirenburg, Beale, and McShane
sources. In particular, we will work toward reducing the influence of syntactic clues
and thereby moving the center of gravity of the analysis process toward semantics
proper.
The process of evaluating TMRs has benefits beyond assessing our progress. It
facilitates debugging and enhancing the knowledge resources and processing modules
of the system. Finally, we believe that the gold standard TMRs required for evaluation
can also be used as an annotated training corpus for machine learning experiments
in semantic analysis. We believe that the annotation task is quite feasible. If we
estimate the time to create a gold standard basic TMR for a 25-word sentence takes
one person-hour, counting the estimated time for acquiring the missing lexicon and
ontology information, then it should be possible to create a 100,000-word corpus of
gold standard basic TMRs in about two person-years.
References
McShane, M., S. Beale, and S. Nirenburg (2004). Some meaning procedures of onto-
logical semantics. In Proceedings of LREC-2004.
McShane, M., S. Nirenburg, and S. Beale (2005a). An NLP lexicon as a largely
language independent resource. Machine Translation 19(2), 139?173.
McShane, M., S. Nirenburg, and S. Beale (2005b). Text-meaning representations as
repositories of structured knowledge. In Proceedings of the Fourth Workshop on
Treebanks and Linguistic Theories (TLT 2005).
McShane, M., S. Nirenburg, S. Beale, B. Jarrell, and G. Fantry (2007). Knowledge-
based modeling and simulation of diseases with highly differentiated clinical man-
ifestations. In Proceedings of the 11th Conference on Artificial Intelligence in
Medicine (AIME 07).
Nirenburg, S., S. Beale, and M. McShane (2004). Evaluating the performance of the
OntoSem semantic analyzer. In Proceedings of the ACLWorkshop on Text Meaning
Representation.
Nirenburg, S. and V. Raskin (2004). Ontological Semantics. MIT Press.
Schubert, L. (2002). Can we derive general world knowledge from texts? In Pro-
ceedings of the HLT Conference.
