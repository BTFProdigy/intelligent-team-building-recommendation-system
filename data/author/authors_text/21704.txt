Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 59?66,
Portland, Oregon, June 17-18, 2011. c?2011 Association for Computational Linguistics
Spoken Dialogue System based on Information Extraction
using Similarity of Predicate Argument Structures
Koichiro Yoshino, Shinsuke Mori and Tatsuya Kawahara
School of Informatics, Kyoto University
Sakyo-ku, Kyoto, 606-8501, Japan
Abstract
We present a novel scheme of spoken dialogue
systems which uses the up-to-date informa-
tion on the web. The scheme is based on in-
formation extraction which is defined by the
predicate-argument (P-A) structure and real-
ized by semantic parsing. Based on the in-
formation structure, the dialogue system can
perform question answering and also proac-
tive information presentation. Feasibility of
this scheme is demonstrated with experiments
using a domain of baseball news. In order to
automatically select useful domain-dependent
P-A templates, statistical measures are intro-
duced, resulting to a completely unsupervised
learning of the information structure given a
corpus. Similarity measures of P-A structures
are also introduced to select relevant infor-
mation. An experimental evaluation shows
that the proposed system can make more rel-
evant responses compared with the conven-
tional ?bag-of-words? scheme.
1 Introduction
Recently, a huge amount of information is accumu-
lated and distributed on the web day by day. As a
result, many people get information via web rather
than the conventional mass media. On the other
hand, the amount of information on the web is so
huge that we often encounter the difficulty in finding
information we want. Keyword search is the most
widely-used means for the web information access.
However, this style is not necessarily the best for
information demands of all users who do not have
definite goals or just want to know what would be
interesting. To cope with user?s vague information
demands is an important mission for interactive spo-
ken dialogue systems. Moreover, supporting user?s
information collection in a small-talk style is one of
the new directions of spoken dialogue systems.
Existing spoken dialogue systems can be clas-
sified into two types (T.Kawahara, 2009): those
using relational databases (RDB) such as the Air-
line Travel Information System (ATIS) (D.A.Dahl,
1994), and those using information retrieval tech-
niques based on statistical document matching
(T.Misu and T.Kawahara, 2010). The first scheme
can achieve a well-defined task by using a struc-
tural database, but this scheme cannot be applied to
the web information in which the structure and task
are not well defined. The second scheme has been
studied to handle large-scale texts such as web, but
most of the conventional systems adopt a ?bag-of-
words? model, and naive statistical matching often
generates irrelevant responses which have nothing
to do with the user?s requests. Our proposed scheme
solves this problem by using information extraction
based on semantic parsing from web texts, with-
out constructing an RDB. We adopt the predicate-
argument (P-A) structure generated by a parser as
a baseline, but every P-A structure is not useful for
information extraction and retrieval(Y.Kiyota et al,
2002; M.O.Dzikovska et al, 2003; S.Harabagiu et
al., 2005). In fact, the useful information structure
is dependent on domains. Conventionally, the tem-
plates for information extraction were hand-crafted
(R.Grishman, 2003), but this heuristic process is so
costly that it cannot be applied to a variety of do-
mains on the web. In this paper, therefore, we pro-
59
	

 	 
Proceedings of the SIGDIAL 2014 Conference, pages 32?40,
Philadelphia, U.S.A., 18-20 June 2014.
c?2014 Association for Computational Linguistics
Information Navigation System Based on POMDP that Tracks User Focus
Koichiro Yoshino Tatsuya Kawahara
School of Informatics, Kyoto University
Sakyo-ku, Kyoto, 606-8501, Japan
yoshino@ar.media.kyoto-u.ac.jp
Abstract
We present a spoken dialogue system for
navigating information (such as news ar-
ticles), and which can engage in small
talk. At the core is a partially observ-
able Markov decision process (POMDP),
which tracks user?s state and focus of at-
tention. The input to the POMDP is pro-
vided by a spoken language understanding
(SLU) component implemented with lo-
gistic regression (LR) and conditional ran-
dom fields (CRFs). The POMDP selects
one of six action classes; each action class
is implemented with its own module.
1 Introduction
A large number of spoken dialogue systems have
been investigated and many systems are deployed
in the real world. Spoken dialogue applications
that interact with a diversity of users are avail-
able on smart-phones. However, current appli-
cations are based on simple question answering
and the system requires a clear query or a def-
inite task goal. Therefore, next-generation dia-
logue systems should engage in casual interactions
with users who do not have a clear intention or a
task goal. Such systems include a sightseeing nav-
igation system that uses tour guide books or doc-
uments in Wikipedia (Misu and Kawahara, 2010),
and a news navigation system that introduces news
articles updated day-by-day (Yoshino et al., 2011;
Pan et al., 2012). In this paper, we develop an in-
formation navigation system that provides infor-
mation even if the user request is not necessarily
clear and there is not a matching document in the
knowledge base. The user and the system converse
on the current topic and the system provides po-
tentially useful information for the user.
Dialogue management of this kind of systems
was usually made in a heuristic manner and based
on simple rules (Dahl et al., 1994; Bohus and Rud-
nicky, 2003). There is not a clear principle nor
established methodology to design and implement
casual conversation systems. In the past years, ma-
chine learning, particularly reinforcement learn-
ing, have been investigated for dialogue manage-
ment. MDPs and POMDPs are now widely used
to model and train dialogue managers (Levin et
al., 2000; Williams and Young, 2007; Young et
al., 2010; Yoshino et al., 2013b). However, the
conventional scheme assumes that the task and di-
alogue goal can be clearly stated and readily en-
coded in the RL reward function. This is not true
in casual conversation or when browsing informa-
tion.
Some previous work has tackled with this prob-
lem. In a conversational chatting system (Shibata
et al., 2014), users were asked to make evalua-
tion at the end of each dialogue session, to define
rewards for reinforcement learning. In a listen-
ing dialogue system (Meguro et al., 2010), levels
of satisfaction were annotated in logs of dialogue
sessions to train a discriminative model. These
approaches require costly input from users or de-
velopers, who provide labels and evaluative judg-
ments.
In this work, we present a framework in which
reward is defined for the quality of system actions
and also for encouraging long interactions, in con-
trast to the conventional framework. Moreover,
user focus is tracked to make appropriate actions,
which are more rewarded.
2 Conversational Information
Navigation System
In natural human-human conversation, partici-
pants have topics they plan to talk about, and they
progress through the dialogue in accordance with
the topics (Schegloff and Sacks, 1973). We call
this dialogue style ?information navigation.? An
example is shown in Figure 1. First, the speaker
32
Dialogue states
Speaker (system) Listener (user)
Offer a topic Be interested in the topicPresent the detail Make a questionAnswer the question Be silentOffer a new topic (topic 2) Not be interested in
Offer a new topic (topic 3)
???
Make a questionTopic 3
Topic 2
???
Topic 1
Figure 1: An example of information navigation.
Story Telling(ST)System-initiative
Modules of related topics
Question Answering(QA)User-initiative
Proactive 
initiative
Presentation(PP)System-
Draw new topic
Related topics
Topic
Topic
Topic
Topic
Topic
Topic Topic
???
???
???
Selected topic
Modules of current topic
Topic Presentation (TP)
Topic N
Topic 3
Topic 2
???
Topic 1
Other modules
Greeting(GR) Keep silence(KS)
Figure 2: Overview of the information navigation
system.
offers a new topic and probes the interest of the
listener. If the listener shows interest, the speaker
describes details of the topic. If the listener asks
a specific question, the speaker answers the ques-
tion. On the other hand, if the listener is not inter-
ested in the topic, the speaker avoids the details of
that topic, and changes the topic. Topics are often
taken from current news.
In our past work, we have developed a news
navigation system (Yoshino et al., 2011) based on
this dialogue structure. The system provides top-
ics collected from Web news texts, and the user
gets information according to his interests and
queries.
2.1 System overview
An overview of the proposed system is depicted
in Figure 2. The system has six modules, each of
which implements a class of actions. Each module
takes as input a recognized user utterance, an an-
alyzed predicate-argument (P-A) structure and the
detected user focus.
The system begins dialogues by selecting the
?topic presentation (TP)? module, which presents
a new topic selected from a news article. The sys-
tem chooses the next module based on the user?s
response. In our task, the system assumes that
each news article corresponds to a single topic,
and the system presents a headline of news in the
TP module. If the user shows interest (positive
response) in the topic without any specific ques-
tions, the system selects the ?story telling (ST)?
module to give details of the news. In the STmod-
ule, the system provides a summary of the news
article by using lead sentences. The system can
also provide related topics with the ?proactive pre-
sentation (PP)? module. This module is invoked
by system initiative; this module is not invoked by
any user request. If the user makes a specific ques-
tion regarding the topic, the system switches to the
?question answering (QA)? module to answer the
question. This module answers questions on the
presented topic and related topics.
The modules of PP and QA are based on a di-
alogue framework which uses the similarity of P-
A structures (Yoshino et al., 2011). This frame-
work defines the similarity of P-A structures be-
tween user queries and news articles, and retrieves
or recommends the appropriate sentence from the
news articles. This method searches for appropri-
ate information from automatically parsed docu-
ments by referring to domain knowledge that is
automatically extracted from domain corpus.
Transitions between the modules are allowed as
shown in Figure 2. The modules ?greeting (GR)?
and ?keep silence (KS)? are also implemented.
GR module generates fixed greeting patterns by
using regular expression matching. In terms of
dialogue flow, these modules can be used at any
time.
2.2 User focus in information navigation
?Focus? in discourse is ?attentional state (that)
contains information about the objects, properties,
relations, and discourse intentions that are most
salient at any given point.? (Grosz and Sidner,
1986). The user has specific attention to an ob-
ject if the user utterance contains the focus. In
this work, we define the user focus as ?the main
piece of information of interest to the user.? It
makes a central component when making a reply
or selecting relevant topics at the current dialogue
state. For example, given ?Did Ichiro perform bril-
33
SYS, tp, ?Matsui, a part-time coach for the Giants, demonstrated 5 homeruns. The Giants president
told him "Come back as a player!?
USR, st, 0, ? Give me the detail??, ?Give:me/0 the:detail/0?
SYS, st, ?Matsui joined the extra batting training in the Giants' camp, and demonstrated his batting
to young players.?
USR, qa, 1, ?Will Matsui become the Giants' manager in the future??, ?Matsui/0 will:become/0
the Giants' manager/1 in the future/0?
SYS, qa, ?The director of Giants told him "Come back as a player!??
USR, tp, 0, ?Next news, please.?, ?Next:news/0 please/0?
SYS, tp, ? To be a ace pitcher, has Fujinami improved from the rookie year?
?
Figure 3: An example of annotation for collected dialogue. System utterances have a tuple of three
elements separated by a comma: speaker, called module and utterance. User utterances have a tuple of
four elements: speaker, the module the user request falls in, binary information of user focus, utterance
and user focus annotation on each phrase or P-A element. (This example is translated from Japanese)
liantly?,? user focus is ?Ichiro? because the sys-
tem reply should include information on Ichiro.
This information is annotated on content words or
named entities in a user utterance. In the POMDP,
decisions are made based on whether any user fo-
cus was detected in the user?s utterance.
3 Spoken Language Understanding
(SLU)
In this section, we present the spoken language un-
derstanding components of our system. It detects
the user?s focus and intention and provides these
to the dialogue manager. These spoken language
understanding modules are formulated with a sta-
tistical model to give likelihoods which are used
in POMDP.
3.1 Dialogue data
We collected 606 utterances (from 10 users) with a
rule-based dialogue system (Yoshino et al., 2011).
We annotated two kinds of tags: user intention (6
tags defined in Section 3.3), and focus information
defined in Section 2.2. An example of annotation
is shown in Figure 3. We highlighted annotation
points in the bold font.
To prepare the training data, each utterance was
labeled with one of the six modules, indicating the
best module to respond. In addition, each phrase
or P-A elements is labeled to indicated whether it
is the user?s focus or not. The user focus is deter-
mined by the attributes (=specifications of words
in the domain) and preference order of phrases to
identify the most appropriate information that the
user wants to know. For example, in the second
user utterance in Figure 3, the user?s focus is the
phrase ?the Giants? manager?. These tags are an-
notated by one person.
3.2 User focus detection based on CRF
To detect the user focus, we use a conditional
random field (CRF)
1
. The problem is defined as
a sequential labeling of the focus labels to a se-
quence of the phrases of the user utterance. Fea-
tures used are shown in the Table 1. ORDER fea-
tures are the order of the phrase in the sequence
and in the P-A structure. We incorporate these
features because the user focus often appears in
the first phrase of the user utterance. POS fea-
tures are part-of-speech (POS) tags and their pairs
in the phrase. P-A features are semantic role of the
P-A structure. We also incorporate the domain-
dependent predicate-argument (P-A) scores that
are defined with an unsupervised method (Yoshino
et al., 2011). The score is discretized to 0.01, 0.02,
0.05, 0.1, 0.2, 0.5.
Table 2 shows the accuracy of user focus de-
tection, which was conducted via five-fold cross-
validation. ?Phrase? is phrase-base accuracy and
?sentence? indicates whether the presence of any
user focus phrase was correctly detected (or not),
regardless of whether the correct phrase was iden-
tified. This table indicates that WORD features
are effective for detecting the user focus, but they
are not essential for in the sentence-level accuracy.
In this paper, we aim for portability across do-
mains; therefore the dialogue manager only uses
the sentence-level feature, so in our system we do
not user the WORD features.
3.3 User intention analysis based on LR
The module classifies the user intention from the
user utterance. We define six intentions as below.
? TP: request to the TP module.
1
CRFsuite (Okazaki, 2007).
34
Table 1: Features of user focus detection.
feature type feature
ORDER Rank in a sequence of phrases
Rank in a sequence of elements of P-A
POS POS tags in the phrase
POS tag sequence
POSORDER Pair of POS tag and its order in the
phrase
P-A Which semantic role the phrase has
Which semantic roles exist on the
utterance
P-AORDER Pair of semantic role and its order in
the utterance
P-A score P-A templates score
WORD Words in the phrase
Pair of words in the phrase
Pair of word and its order in the phrase
Table 2: Accuracy of user focus detection.
Accuracy
phrase 86.7%
phrase + (WORD) 90.3%
sentence (focus exist or not) 99.8%
sentence (focus exist or not) + (WORD) 99.8%
? ST: request to the ST module.
? QA: request to the QA module.
? GR: greeting to the GR module.
? NR: silence longer than a threshold.
? II: irrelevant input due to ASR errors or noise.
We adopt logistic regression (LR)-based dia-
logue act tagging approach (Tur et al., 2006). The
probability of user intention o given an ASR result
of the user utterance h is defined as,
P (o|h) =
exp(? ? ?(h, o))
?
o
exp(? ? ?(h, o))
. (1)
Here, ? is a vector of feature weights and ?(h, o)
is a feature vector. We use POS, P-A and P-A tem-
plates score as a feature set. In addition, we add a
typical expression feature (TYPICAL) to classify
TP, ST or GR tags. For example, typical expres-
sions in conversation are ?Hello? or ?Go on,? and
those in information navigation are ?News of the
day? or ?Tell me in detail.? Features for the clas-
sifier are shown in the Table 3.
The accuracy of the classification in five-fold
cross-validation is shown in Table 4. The TYP-
Table 3: Features of user intention analysis.
feature type feature
POS Bag of POS tags
Bag of POS bi-gram
P-A Bag of semantic role labels
Bag of semantic role labels bi-gram
Pair of semantic role label and its rank
P-A score P-A templates score
TYPICAL Occurrence of typical expressions
Table 4: Accuracy of user intention analysis.
All features without TYPICAL
TP 100% 100%
ST 75.3% 64.2%
QA 94.1% 93.5%
GR 100% 100%
II 16.7% 16.7%
All 92.1% 90.2%
ICAL feature improves the classification accuracy
while keeping the domain portability.
3.4 SLU for ASR output
ASR and intention analysis involves errors. Here,
s is a true user intention and o is an observed in-
tention. The observation model P (o|s) is given
by the likelihood of ASR result P (h|u) (Komatani
and Kawahara, 2000) and the likelihood of the in-
tention analysis P (o|h),
P (o|s) =
?
h
P (o, h|s) (2)
?
?
h
P (o|h)P (h|u). (3)
Here, u is an utterance of the user. We combine
the N-best (N = 5) hypotheses of the ASR result
h.
4 Dialogue Management for Information
Navigation
The conventional dialogue management for task-
oriented dialogue systems is designed to reach a
task goal as soon as possible (Williams and Young,
2007). In contrast, information navigation does
not always have a clear goal, and the aim of infor-
mation navigation is to provide as much relevant
information as the user is interested in. Therefore,
our dialogue manager refers user involvement or
engagement (=level of interest) and the user focus
35
(=object of interest). This section describes the
general dialogue management based on POMDP,
and then gives an explanation of the proposed dia-
logue management using the user focus.
4.1 Dialogue management based on POMDP
The POMDP-based statistical dialogue manage-
ment is formulated as below. The random vari-
ables involved at a dialogue turn t are as follows:
? s ? I
s
: user state
User intention.
? a ? K: system action
Module that the system selects.
? o ? I
s
: observation
Observed user state, including ASR and in-
tention analysis errors.
? b
s
i
= P (s
i
|o
1:t
): belief
Stochastic variable of the user state.
? pi: policy function
This function determines a system action a
given a belief of user b. pi
?
is the optimal pol-
icy function that is acquired by the training.
? r: reward function
This function gives a reward to a pair of the
user state s and the system action a.
The aim of the statistical dialogue management is
to output an optimal system action a?
t
given a se-
quence of observation o
1:t
from 1 to t time-steps.
Next, we give the belief update that includes the
observation and state transition function. The be-
lief update of user state s
i
in time-step t is defined
as,
b
t+1
s
?
j
? P (o
t+1
|s
?
j
)
? ?? ?
Obs.
?
s
i
P (s
?
j
|s
i
, a?
k
)
? ?? ?
Trans.
b
t
s
i
. (4)
Obs. is an observation function which is defined
in Equation (3) and Trans. is a state transition
probability of the user state. Once the system es-
timates the belief b
t
s
i
, the policy function outputs
the optimal action a? as follows:
a? = pi
?
(b
t
). (5)
4.2 Training of POMDP
We applied Q-learning (Monahan, 1982; Watkins
and Dayan, 1992) to acquire the optimal policy
pi
?
. Q-learning relies on the estimation of a Q-
function, which maximizes the discounted sum of
future rewards of the system action a
t
at a dialogue
turn t given the current belief b
t
. Q-learning is
performed by iterative updates on the training dia-
logue data:
Q(b
t
, a
t
) ? (1? ?)Q(b
t
, a
t
)
+ ?[R(s
t
, a
t
) + ? max
a
t+1
Q(b
t+1
, a
t+1
)], (6)
where ? is a learning rate, ? is a discount factor of
a future reward. We experimentally decided ? =
0.01 and ? = 0.9. The optimal policy given by the
Q-function is determined as,
pi
?
(b
t
) = argmax
a
t
Q(b
t
, a
t
). (7)
However, it is impossible to calculate the Q-
function for all possible real values of belief b.
Thus, we train a limited Q-function given by a
Grid-based Value Iteration (Bonet, 2002). The be-
lief is given by a function,
b
s
i
=
{
? if s = i
1??
|I
s
|
if s ?= i
. (8)
Here, ? is a likelihood of s = i that is output
of the intention analyzer, and we selected 11 dis-
crete points from 0.0 to 1.0 by 0.1. We also added
the case of uniform distribution. The observation
function of the belief update is also given in a sim-
ilar manner.
4.3 Dialogue management using user focus
Our POMDP-based dialogue management
chooses actions based on its belief in: the user
intention s and the user focus f (0 or 1 ? J
f
).
The observation o is controlled by hidden states
f and s that are decided by the state transition
probabilities,
P (f
t+1
|f
t
, s
t
, a
t
), (9)
P (s
t+1
|f
t+1
, f
t
, s
t
, a
t
). (10)
We constructed a user simulator by using the an-
notated data described in Section 3.1.
Equation (10) is also used for the state transition
probability of the belief update. The equation of
the belief update (4) is extended by introducing the
previous user focus f
l
and current user focus f
?
m
information,
b
t+1
s
?
j
= P (o
t+1
|s
?
j
)
? ?? ?
Obs.
?
?
i
P (s
?
j
|f
?
m
, f
l
, s
i
, a?
k
)
? ?? ?
Trans.
b
t
s
i
,f
l
. (11)
36
Table 5: Rewards in each turn.
state focus action a
s f TP ST QA PP GR KS
TP
0
+10 -10 -10 -10 -10 -10
1
ST
0
-10 +10 -10 0 -10 -10
1
QA
0
-10
+10 +10 -10
-10 -10
1 -10 +30 +10
GR
0
-10 -10 -10 -10 +10 -10
1
NR
0 +10
-10 -10
-10
-10 0
1 -10 +10
II
0
-10 -10 -10 -10 -10 +10
1
The resultant optimal policy is,
a? = pi
?
(b
t
, f
l
). (12)
4.4 Definition of rewards
Table 5 defines a reward list at the end of a each
turn. The reward of +10 is given to appropriate
actions, 0 to acceptable actions, and -10 to inap-
propriate actions.
In Table 5, pairs of a state and its apparently
corresponding action, TP and TP, ST and ST, QA
and QA, GR and GR, and II and KS, have posi-
tive rewards. Rewards in bold fonts (+10) are de-
fined for the following reasons. If the user asks a
question (QA) without a focus (e.g. ?What hap-
pened on the game??), the system can continue by
story telling (ST). But when the question has a fo-
cus, the system should answer the question (QA),
which is highly rewarded (+30). If the system can-
not find an answer, it can present relevant informa-
tion (PP). When the user says nothing (NR), the
system action should be decided by considering
the user focus; present a new topic if the user is
not interested in the current topic (f=0) or present
an article related to the dialogue history (f=1).
Reward of +200 is given if 20 turns are passed,
to reward a long continued dialogue. The user sim-
ulator terminates the dialogue if the system selects
an inappropriate action (action of r = ?10) five
times, and a large penalty -200 is given to the sys-
tem.
5 Evaluations of Dialogue
We evaluated the proposed system with two exper-
iments; dialogue state tracking with real users and
average reward with a user simulator. For the eval-
uation, we collected an additional 312 utterances
Average of rewards
Noise
-250
-200
-150
-100
-50
0
50
100
150
200
250
300
350
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
w. focus w.o. focus
Figure 4: Effect of introduction of the user focus
in simulation.
(8 users, 24 dialogues) with the proposed dialogue
system.
5.1 Evaluation of dialogue manager with
user simulator
First, we evaluated the dialogue manager with
user simulation that is constructed from the train-
ing corpus (Section 3.1). In this evaluation, the
system calculated average reward of 100,000 di-
alogue sessions between the system and the user
simulator given a fixed noise rate. Figure 4 shows
the effect of the user focus. By introducing the
user focus, the system receives higher rewards
than the model without the user focus. Especially,
the proposed model is more robust with a noise
level of 10?30% that spoken dialogue systems of-
ten encounter (Yoshino et al., 2013a).
5.2 Evaluation of dialogue state tracking
with real users
Dialogue state tracking (DST) is a task of track-
ing the correct user state with a noisy input (e.g.
ASR and NLU errors) (Williams et al., 2013).
It tries to maximize the probability of the belief
of the correct states, but we evaluated the accu-
racy of the 1-best result of the belief update. We
also evaluated the average reward of each dia-
logue. The baseline system is a rule-based dia-
logue manager which we previously implemented.
The baseline system is operated by a score of
the question-answering module using predicate-
argument structures (Yoshino et al., 2011) and reg-
ular expressions for TP and GR modules.
The DST accuracy and average reward are
shown in Table 6. This result shows that the pro-
posed method tracks the dialogue state of the user
with a high accuracy. Our statistical framework
37
Sys: Hello.
Usr: Hello. Tell me today's news.
Sys: Tanaka showed a crazy split. His colleague 
Sabathia was stunned.
Usr: What is the crazy split?
Sys: His split comes just like a four-seam, but it 
drops quickly in front of the home plate.
Usr: Where was he training?
Sys: Tanaka practiced at the bullpen in the New 
York Yankees' camp on Feb. 20th.
Usr: (pause)
Sys: By the way, he also practiced a drop 
two-seam on Feb. 18.
Usr: Does his two-seam drop?
Sys: The catcher said "Tanaka's two-seam not
only slides, but also drops."
Usr: OK, any other news?
Sys: Yankees' Ichiro is training strenuously!
Usr: Tell me more.
Sys: Ichiro came to the field an hour earlier than 
usual and trained strenuously.
?
=TP,    =0.8, (=TP)=0.800, =0
=TP, (=TP =0)=0.8
=QA,    =0.4, (=QA)=0.934, =1
=QA, (=QA, =1)=0.9
=QA,    =0.8, (=QA)=0.973, =1
=QA, (=QA, =1)=1.0
=NR,    =1.0, (=NR)=1.00, =1
=PP, (=NR, =1)=1.0
=QA,    =0.6, (=QA)=0.867, =1
=QA, (=QA, =1)=0.9
=TP,    =0.8, (=TP)=0.984, =0
=TP, (=TP, =0)=1.0
=ST,    =0.9, (=ST)=0.871, =0
=ST, (=ST, =0)=0.9
Dialogue 1
Sys: Hello.
Usr: Hello. Tell me today's news?
Sys: Matsui, a part-time coach for the Giants, 
demonstrated 5 homeruns. The Giants
president told him "Come back as a player!"
Usr: What happened?
Sys: The godzilla cannon came back to the Giants?
spring camp in Miyazaki.
Usr: What is the Godzilla cannon?
Sys: The Godzilla coach demonstrated his 
home-run batting to young players.
Usr: Next please.
Sys: To be a ace pitcher, has Fujinami improved 
from the rookie year?
?
=TP,    =0.8, (=TP)=0.800, =0
=TP, (=TP =0)=0.8
=QA,    =0.8, (=QA)=0.532, =0
=ST, (=QA, =0)=0.5
=QA,    =0.8, (=QA)=0.806, =1
=QA, (=QA, =1)=0.8
=TP,    =0.8, (=TP)=0.986, =0
=TP, (=TP, =0)=1.0
Dialogue 2
Figure 5: A dialogue example. (This example is translated from Japanese)
Table 6: Accuracy of dialogue state tracking.
rule focus POMDP
Accuracy of tracking 0.561 0.869
(1-best) (=175/312) (=271/312)
Average reward -22.9 188.6
improved SLU accuracy and robustness against
ASR errors, especially reducing confusions be-
tween question answering (QA) and topic presen-
tation (TP). Moreover, belief update can detect the
TP state even if the SLU incorrectly predicts QA
or ST.
5.3 Discussion of trained policy
An example dialogue is shown in Figure 5. In
the example, the system selects appropriate ac-
tions even if the observation likelihood is low. At
the 4th turn of Dialogue 1 in this example, the sys-
tem with the user focus responds with an action of
proactive presentation a=PP, but the system with-
out the user focus responds with an action of topic
presentation a=TP. At the 2nd turn of Dialogue 2,
the user asks a question without a focus. The con-
fidence of s=QA is lowered by the belief update,
and the system selects the story telling module
a=ST. These examples show that the training re-
sult (=learned policy) reflects our design described
in Section 4.4: It is better to make a proactive pre-
sentation when the user is interested in the topic.
6 Conclusions
We constructed a spoken dialogue system for in-
formation navigation ofWeb news articles updated
day-by-day. The system presents relevant infor-
38
mation according to the user?s interest, by track-
ing the user focus. We introduce the user focus
detection model, and developed a POMDP frame-
work which tracks user focus to select the appro-
priate action class (module) of the dialogue sys-
tem. In experimental evaluations, the proposed di-
alogue management approach determines the state
of the user more accurately than the existing sys-
tem based on rules. An evaluation with a user sim-
ulator shows that including user focus in the dia-
logue manager?s belief state improves robustness
to ASR/SLU errors.
In future work, we plan to evaluate the system
with a large number of real users on a variety of
domains, and optimize the reward function for the
information navigation task.
Acknowledgments
We thank Dr. Jason Williams for his valuable and
detailed advice to improve this paper on SIGDIAL
mentoring program. This work was supported by
Grant-in-Aid for JSPS Fellows 25-4537.
References
Dan Bohus and Alexander I. Rudnicky. 2003. Raven-
claw: Dialog management using hierarchical task
decomposition and an expectation agenda. In Pro-
ceedings of the 8th European Conference on Speech
Communication and Technology, pages 597?600.
Blai Bonet. 2002. An e-optimal grid-based algorithm
for partially observable Markov decision processes.
In Proceedings of International Conference on Ma-
chine Learning, pages 51?58.
Deborah A. Dahl, Madeleine Bates, Michael Brown,
William Fisher, Kate Hunicke-Smith, David Pallett,
Christine Pao, Alexander Rudnicky, and Elizabeth
Shriberg. 1994. Expanding the scope of the ATIS
task: the ATIS-3 corpus. In Proceedings of the
workshop on Human Language Technology, pages
43?48.
Barbara J. Grosz and Candace L. Sidner. 1986. Atten-
tion, intentions, and the structure of discourse. Com-
putational Linguistics, 12(3):175?204.
Ryuichiro Higashinaka, Katsuhito Sudoh, and Mikio
Nakano. 2006. Incorporating discourse features
into confidence scoring of intention recognition re-
sults in spoken dialogue systems. Speech Communi-
cation, 48(3):417?436.
Tatsuya Kawahara. 2009. New perspectives on spoken
language understanding: Does machine need to fully
understand speech? In Proceedings of IEEE work-
shop on Automatic Speech Recognition and Under-
standing, pages 46?50.
Kazunori Komatani and Tatsuya Kawahara. 2000.
Flexible mixed-initiative dialogue management us-
ing concept-level confidence measures of speech
recognizer output. In Proceedings of the 18th con-
ference on Computational linguistics, pages 467?
473.
Esther Levin, Roberto Pieraccini, and Wieland Eckert.
2000. A stochastic model of human-machine inter-
action for learning dialog strategies. IEEE Transac-
tions on Speech and Audio Processing, 8(1):11?23.
Toyomi Meguro, Ryuichiro Higashinaka, Yasuhiro Mi-
nami, and Kohji Dohsaka. 2010. Controlling
listening-oriented dialogue using partially observ-
able markov decision processes. In Proceedings
of the 23rd International Conference on Computa-
tional Linguistics, pages 761?769.
Teruhisa Misu and Tatsuya Kawahara. 2010. Bayes
risk-based dialogue management for document re-
trieval system with speech interface. Speech Com-
munication, 52(1):61?71.
George E. Monahan. 1982. State of the art? a survey
of partially observable Markov decision processes:
Theory, models, and algorithms. Management Sci-
ence, 28(1):1?16.
Naoaki Okazaki. 2007. CRFsuite: a fast implementa-
tion of Conditional Random Fields (CRFs).
Yi-Cheng Pan, Hung yi Lee, and Lin shan Lee. 2012.
Interactive spoken document retrieval with sug-
gested key terms ranked by a markov decision pro-
cess. IEEE Transactions on Audio, Speech, and
Language Processing, 20(2):632?645.
Emanuel A. Schegloff and Harvey Sacks. 1973. Open-
ing up closings. Semiotica, 8(4):289?327.
Tomohide Shibata, Yusuke Egashira, and Sadao Kuro-
hashi. 2014. Chat-like conversational system based
on selection of reply generating module with rein-
forcement learning. In Proceedings of the 5th In-
ternational Workshop Series on Spoken Dialog Sys-
tems.
Gokhan Tur, Umit Guz, and Dilek Hakkani-Tur. 2006.
Model adaptation for dialog act tagging. In Pro-
ceedings of IEEE workshop on Spoken Language
Technology, pages 94?97. IEEE.
Christopher JCH Watkins and Peter Dayan. 1992. Q-
learning. Machine learning, 8(3):279?292.
Jason D. Williams and Steve Young. 2007. Par-
tially observable Markov decision processes for spo-
ken dialog systems. Computer Speech & Language,
21(2):393?422.
Jason D. Williams, Antoine Raux, Deepak Ramachan-
dran, and Alan Black. 2013. The dialog state track-
ing challenge. In Proceedings of the 14th Annual
Meeting of the Special Interest Group on Discourse
and Dialogue, pages 404?413.
39
Koichiro Yoshino, Shinsuke Mori, and Tatsuya Kawa-
hara. 2011. Spoken dialogue system based on infor-
mation extraction using similarity of predicate argu-
ment structures. In Proceedings of the 12th Annual
Meeting of the Special Interest Group on Discourse
and Dialogue, pages 59?66.
Koichiro Yoshino, Shinsuke Mori, and Tatsuya Kawa-
hara. 2013a. Incorporating semantic information to
selection of web texts for language model of spoken
dialogue system. In Proceedings of IEEE Interna-
tional Conference on Acoustic, Speech and Signal
Processing, pages 8252?8256.
Koichiro Yoshino, Shinji Watanabe, Jonathan Le Roux,
and John R. Hershey. 2013b. Statistical dialogue
management using intention dependency graph. In
Proceedings of the 6th International Joint Confer-
ence on Natural Language Processing, pages 962?
966.
Steve Young, Milica Ga?si?c, Simon Keizer, Franc?ois
Mairesse, Jost Schatzmann, Blaise Thomson, and
Kai Yu. 2010. The hidden information state model:
A practical framework for POMDP-based spoken
dialogue management. Computer Speech & Lan-
guage, 24(2):150?174.
40
Proceedings of the 8th International Natural Language Generation Conference, pages 118?122,
Philadelphia, Pennsylvania, 19-21 June 2014. c?2014 Association for Computational Linguistics
FlowGraph2Text: Automatic Sentence Skeleton Compilation
for Procedural Text Generation
?1Shinsuke Mori ?2Hirokuni Maeta 1Tetsuro Sasada 2Koichiro Yoshino
3Atsushi Hashimoto 1Takuya Funatomi 2Yoko Yamakata
1Academic Center for Computing and Media Studies, Kyoto University
2Graduate School of Informatics, Kyoto University
3Graduate School of Law, Kyoto University
Yoshida Honmachi, Sakyo-ku, Kyoto, Japan
?forest@i.kyoto-u.ac.jp
Abstract
In this paper we describe a method for
generating a procedural text given its
flow graph representation. Our main
idea is to automatically collect sen-
tence skeletons from real texts by re-
placing the important word sequences
with their type labels to form a skeleton
pool. The experimental results showed
that our method is feasible and has a
potential to generate natural sentences.
1 Introduction
Along with computers penetrating in our daily
life, the needs for the natural language gener-
ation (NLG) technology are increasing more
and more. If computers understand both the
meaning of a procedural text and the progres-
sion status, they can suggest us what to do
next. In such situation they can show sen-
tences describing the next instruction on a dis-
play or speak it.
On this background we propose a method
for generating instruction texts from a flow
graph representation for a series of procedures.
Among various genres of procedural texts, we
choose cooking recipes, because they are one of
the most familiar procedural texts for the pub-
lic. In addition, a computerized help system
proposed by Hashimoto et al. (2008) called
smart kitchen is becoming more and more re-
alistic. Thus we try to generate cooking pro-
cedural texts from a formal representation for
a series of preparation instructions of a dish.
As the formal representation, we adopt the
flow graph representation (Hamada et al.,
2000; Mori et al., 2014), in which the vertices
and the arcs correspond to important objects
?His current affiliation is Cybozu Inc., Koraku 1-4-
14, Bunkyo, Tokyo, Japan.
or actions in cooking and relationships among
them, respectively. We use the flow graphs as
the input and the text parts as the references
for evaluation.
Our generation method first automatically
compiles a set of templates, which we call the
skeleton pool, from a huge number of real pro-
cedural sentences. Then it decomposes the in-
put flow graph into a sequence of subtrees that
are suitable for a sentence. Finally it converts
subtrees into natural language sentences.
2 Recipe Flow Graph Corpus
The input of our LNG system is the mean-
ing representation (Mori et al., 2014) for cook-
ing instructions in a recipe. A recipe con-
sists of three parts: a title, an ingredient list,
and sentences describing cooking instructions
(see Figure 1). The meaning of the instruc-
tion sentences is represented by a directed
acyclic graph (DAG) with a root (the final
dish) as shown in Figure 2. Its vertices have
a pair of an important word sequence in the
recipe and its type called a recipe named en-
tity (NE)1. And its arcs denote relationships
between them. The arcs are also classified into
some types. In this paper, however, we do
not use arc types for text generation, because
we want our system to be capable of generat-
ing sentences from flow graphs output by an
automatic video recognition system2 or those
drawn by internet users.
Each vertex of a flow graph has an NE com-
posed of a word sequence in the text and its
type such as food, tool, action, etc. Table 3
1Although the label set contains verb phrases, they
are called named entities.
2By computer vision techniques such as (Regneri et
al., 2013) we may be able to figure out what action
a person takes on what objects. But it is difficult to
distinguish the direct object and the indirect object,
for example.
118
1. ??????????
(In a Dutch oven, heat oil.)
?????????????????
(Add celery, green onions, and garlic.)
????????
(Cook for about 1 minute.)
2. ?????????????????
???????????????
(Add broth, water, macaroni, and pepper,
and simmer until the pasta is tender.)
3. ???????????
(Sprinkle the snipped sage.)
Figure 1: A recipe example. The sentences are
one of the ideal outputs of our problem. They
are also used as the reference in evaluation.
lists all of the type labels along with the aver-
age numbers of occurrences in a recipe text
and examples. The word sequences of ver-
bal NEs do not include their inflectional end-
ings. From the definition we can say that the
content words are included in the flow graph
representation. Thus an NLG system has to
decide their order and generate the function
words (including inflectional endings for verbs)
to connect them to form a sentence.
3 Recipe Text Generation
The problem in this paper is generating a pro-
cedural text for cooking (ex. Figure 1) from a
recipe flow graph (ex. Figure 2).
Our method is decomposed into two mod-
ules. In this section, we explain them in detail.
3.1 Skeleton Pool Compilation
Before the run time, we first prepare a skele-
ton pool. A skeleton pool is a collection of
skeleton sentences, or skeletons for short, and
a skeleton is a sentence in which NEs have
been replaced with NE tags. The skeletons
are similar to the so-called templates and the
main difference is that the skeletons are auto-
matically converted from real sentences. The
following is the process to prepare a skeleton
pool.
1. Crawl cooking procedural sentences from
recipe sites.
2. Segment sentences into words by a word
segmenter KyTea (Neubig et al., 2011).
Then recognize recipe NEs by an NE rec-
ognizer PWNER (Mori et al., 2012).
3. Replace the NE instances in the sentences
with NE tags.
Figure 2: The flow graph of the example
recipe.
Table 3: Named entity tags with average fre-
quence per recipe.
NE tag Meaning Freq.
F Food 11.87
T Tool 3.83
D Duration 0.67
Q Quantity 0.79
Ac Action by the chef 13.83
Af Action by foods 2.04
Sf State of foods 3.02
St State of tools 0.30
We store skeletons with a key which is the se-
quence of the NE tags in the order of their
occurrence.
3.2 Sentence Planning
Our sentence planner produces a sequence of
subtrees each of which corresponds to a sen-
tence. There are two conditions.
Cond. 1 Each subtree has an Ac as its root.
Cond. 2 Every vertex is included in at least
one subtree.
As a strategy for enumerating subtrees given a
flow graph, we choose the following algorithm.
1. search for an Ac vertex by the depth first
search (DFS),
2. each time it finds an Ac, return the largest
subtree which has an Ac as its root and
contains only unvisited vertices.
3. set the visited-mark to the vertices con-
tained in the returned subtree,
4. go back to 1 unless all the vertices are
marked as visited.
In DFS, we choose a child vertex randomly
because a recipe flow graph is unordered.
119
Table 1: Corpus specifications.
Usage #Recipes #Sent. #NEs #Words #Char.
Test 40 245 1,352 4,005 7,509
NER training 360 2,813 12,101 51,847 97,911
Skeleton pool 100,000 713,524 ?3,919,964 ?11,988,344 22,826,496
The numbers with asterisc are estimated values on the NLP result.
Table 2: Statistical results of various skeleton pool sizes.
No. of sentences used for 2,769 11,077 44,308 177,235 708,940
skeleton pool compilation (1/256) (1/64) (1/16) (1/4) (1/1)
No. of uncovered subtrees 52 27 17 9 4
Average no. of skeletons 37.4 124.3 450.2 1598.1 5483.3
BLEU 11.19 11.25 12.86 13.12 13.76
3.3 Sentence Generation
Given a subtree sequence, our text realizer
generates a sentence by the following steps.
1. Collect skeletons from the pool whose NE
key matches the NE tag sequence speci-
fied by the subtree3.
2. Select the skeleton that maximize a scor-
ing function among collected ones. As the
first trial we use the frequency of skeletons
in the pool as the scoring function.
3. Replace each NE in the skeleton with the
word sequence of the corresponding NE in
the subtree.
4 Evaluation
We conducted experiments generating texts
from flow graphs. In this section, we report
the coverage and the sentence quality.
4.1 Experimental Settings
The recipe flow graph corpus (Mori et al.,
2014) contains 200 recipes. We randomly se-
lected 40 flow graphs as the test data from
which we generate texts. The other 160 recipes
were used to train the NE recognizer PWNER
(Mori et al., 2012) with 200 more recipes that
we annotated with NE tags. To compile the
skeleton pool we crawled 100,000 recipes con-
taining 713,524 sentences (see Table 1).
4.2 Skeleton Pool Coverage
First we counted the numbers of the skeletons
that matches with a subtree (Step 1 in Subsec-
tion 3.3) for all the subtrees in the test set by
3This part is language dependent. Since Japanese is
SOV language, the instance of Ac is placed at the last
of the sentence to be generated. Languages of other
types like English may need some rules to change the
NE tag order specified by the subtree into the proper
sentence element order.
changing the number of the recipe sentences
used for the skeleton pool compilation.
Table 2 shows the numbers of subtrees that
do not have any matching skeleton in the pool
(uncovered subtrees) and the average number
of skeletons in the pool for a subtree. From
the results shown in the table we can say that
when we use 100,000 recipes for the skeleton
compilation, our method can generate a sen-
tence for 98.4% subtrees. And the table says
that we can halve the number of uncovered
subtrees by using about four times more sen-
tences. The average number of the skeletons
says that we have enough skeletons in average
to try more sophisticated scoring functions.
4.3 Text Quality
To measure the quality of generated texts, we
first calculated the BLEU (N = 4) (Papineni
et al., 2002) with taking the original recipe
texts as the references. The unit in our case
is a sequence of sentences for a dish. Table 2
shows the average BLEU for all the test set.
The result says that the more sentences we use
for the skeleton pool compilation, the better
the generated sentences become.
The absolute BLEU score, however, does
not tell much about the quality of generated
texts. As it is well known, we can sometimes
change the instruction order in dish prepa-
ration. Therefore we conducted a subjective
evaluation in addition. We asked four evalu-
ators to read 10 texts generated from 10 flow
graphs and answer the following questions.
Q1. How many ungrammatical two-word se-
quences does the text contain?
Q2. How many ambiguous wordings do you
find in the text?
Then we show the evaluators the original
recipe text and asked the following question.
120
Table 4: Result of text quality survey on 10 recipe texts.
Evaluator 1 Evaluator 2 Evaluator 3 Evaluator 4
BLEU Q1 Q2 Q3 Q1 Q2 Q3 Q1 Q2 Q3 Q1 Q2 Q3
6.50 13 2 4 11 0 3 12 0 2 7 1 2
7.99 7 2 2 5 2 2 7 1 1 4 2 2
10.09 18 2 4 15 2 1 17 4 1 11 4 2
11.60 24 1 4 13 2 4 18 2 4 13 1 2
13.35 6 1 4 6 0 4 7 1 5 4 1 2
14.70 16 1 4 12 2 4 12 0 3 6 2 2
16.76 9 2 3 6 1 3 7 1 3 5 3 2
19.65 8 2 5 6 1 1 4 1 4 4 2 4
22.85 18 1 4 15 2 5 12 2 2 7 3 2
31.35 5 1 5 5 0 4 5 1 3 5 1 4
Ave. 12.4 1.5 3.9 9.4 1.2 3.1 10.1 1.3 2.8 6.6 2.0 2.4
PCC ?0.30 ?0.46 +0.57 ?0.24 ?0.24 +0.36 ?0.46 ?0.04 +0.26 ?0.29 ?0.04 +0.70
PPC stands for Pearson correlation coefficient.
Q3. Will the dish be the same as the origi-
nal recipe when you cook according to the
generated text? Choose the one among 5:
completely, 4: almost, 3: partly, 2: differ-
ent, or 1: unexecutable.
Table 4 shows the result. The generated texts
contain 14.5 sentences in average. The an-
swers to Q1 tell that there are many grammat-
ical errors. We need some mechanism that se-
lects more appropriate skeletons. The number
of ambiguous wordings, however, is very low.
The reason is that the important words are
given along with the subtrees. The average of
the answer to Q3 is 3.05. This result says that
the dish will be partly the same as the original
recipe. There is a room for improvement.
Finally, let us take a look at the correlation
of the result of three Qs with BLEU. The num-
bers of grammatical errors, i.e. the answers
to Q1, has a stronger correlation with BLEU
than those of Q2 asking the semantic quality.
These are consistent with the intuition. The
answer to Q3, asking overall text quality, has
the strongest correlation with BLEU on aver-
age among all the questions. Therefore we can
say that for the time being the objective eval-
uation by BLEU is sufficient to measure the
performance of various improvements.
5 Related Work
Our method can be seen a member of
template-based text generation systems (Re-
iter, 1995). Contrary to the ordinary
template-based approach, our method first au-
tomatically compiles a set of templates, which
we call skeleton pool, by running an NE tagger
on the real texts. This allows us to cope with
the coverage problem with keeping the advan-
tage of the template-based approach, ability
to prevent from generating incomprehensible
sentence structures. The main contribution of
this paper is to use an accurate NE tagger to
convert sentences into skeletons, to show the
coverages of the skeleton pool, and to evaluate
the method in a realistic situation.
Among many applications of our method, a
concrete one is the smart kitchen (Hashimoto
et al., 2008), a computerized cooking help sys-
tem which watches over the chef by the com-
puter vision (CV) technologies etc. and sug-
gests the chef the next action to be taken or
a good way of doing it in a casual manner. In
this application, the text generation module
make a sentence from a subtree specified by
the process supervision module.
There are some other interesting applica-
tions: a help system for internet users to write
good sentences, machine translation of a recipe
in a different language represented as a flow
graph, or automatic recipe generation from
a cooking video based on CV and NLP re-
searches such as (Regneri et al., 2013; Ya-
makata et al., 2013; Yu and Siskind, 2013).
6 Conclusion
In this paper, we explained and evaluated our
method for generating a procedural text from
a flow graph representation. The experimental
results showed that our method is feasible es-
pecially when we have huge number of real sen-
tences and that some more sophistications are
possible to generate more natural sentences.
121
Acknowledgments
This work was supported by JSPS Grants-
in-Aid for Scientific Research Grant Numbers
26280084, 24240030, and 26280039.
References
Reiko Hamada, Ichiro Ide, Shuichi Sakai, and Hide-
hiko Tanaka. 2000. Structural analysis of cook-
ing preparation steps in japanese. In Proceedings
of the fifth international workshop on Informa-
tion retrieval with Asian languages, number 8 in
IRAL ?00, pages 157?164.
Atsushi Hashimoto, Naoyuki Mori, Takuya Fu-
natomi, Yoko Yamakata, Koh Kakusho, and
Michihiko Minoh. 2008. Smart kitchen: A user
centric cooking support system. In Proceedings
of the 12th Information Processing and Manage-
ment of Uncertainty in Knowledge-Based Sys-
tems, pages 848?854.
Shinsuke Mori, Tetsuro Sasada, Yoko Yamakata,
and Koichiro Yoshino. 2012. A machine learn-
ing approach to recipe text processing. In Pro-
ceedings of Cooking with Computer workshop.
Shinsuke Mori, Hirokuni Maeta, Yoko Yamakata,
and Tetsuro Sasada. 2014. Flow graph cor-
pus from recipe texts. In Proceedings of the
Nineth International Conference on Language
Resources and Evaluation.
Graham Neubig, Yosuke Nakata, and Shinsuke
Mori. 2011. Pointwise prediction for robust,
adaptable japanese morphological analysis. In
Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics.
Kishore Papineni, Salim Roukos, Todd Ward, and
Wei-Jing Zhu. 2002. Bleu: a method for auto-
matic evaluation of machine translation. In Pro-
ceedings of the 40th Annual Meeting of the As-
sociation for Computational Linguistics, pages
311?318.
Michaela Regneri, Marcus Rohrbach, Dominikus
Wetzel, Stefan Thater, Bernt Schiele, and Man-
fred Pinkal. 2013. Grounding action descrip-
tions in videos. Transactions of the Association
for Computational Linguistics, 1(Mar):25?36.
Ehud Reiter. 1995. Nlg vs. templates. In Pro-
ceedings of the the Fifth European Workshop on
Natural Language Generation, pages 147?151.
Yoko Yamakata, Shinji Imahori, Yuichi Sugiyama,
Shinsuke Mori, and Katsumi Tanaka. 2013.
Feature extraction and summarization of recipes
using flow graph. In Proceedings of the 5th In-
ternational Conference on Social Informatics,
LNCS 8238, pages 241?254.
Haonan Yu and Jeffrey Mark Siskind. 2013.
Grounded language learning from video de-
scribed with sentences. In Proceedings of the
51st Annual Meeting of the Association for
Computational Linguistics.
122
