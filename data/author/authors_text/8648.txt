Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 917?926,
Honolulu, October 2008. c?2008 Association for Computational Linguistics
A graph-theoretic model of lexical syntactic acquisition
Hinrich Schu?tze and Michael Walsh
Institute for Natural Language Processing
University of Stuttgart, Germany
{hs999,walsh}@ifnlp.org
Abstract
This paper presents a graph-theoretic model of
the acquisition of lexical syntactic representa-
tions. The representations the model learns
are non-categorical or graded. We propose a
new evaluation methodology of syntactic ac-
quisition in the framework of exemplar theory.
When applied to the CHILDES corpus, the
evaluation shows that the model?s graded syn-
tactic representations perform better than pre-
viously proposed categorical representations.
1 Introduction
In recent years, exemplar theory has had great ex-
planatory success in phonetics. Exemplar theory
posits that linguistic production and perception are
not mediated via abstract categories, but that instead
each production and perception of a linguistic unit
is stored and retained. Linguistic inference then di-
rectly operates on these stored exemplars. In this pa-
per, we propose a new approach to lexical syntactic
acquisition in the framework of exemplar theory.
Our approach uses an evaluation measure that
is different from previous work. Lexical syntac-
tic acquisition is most often evaluated with respect
to standard syntactic categories like verb and noun.
Our first contribution in this paper is that we instead
evaluate learned representations in the context of a
syntactic task. This task is the determination of an
aspect of grammaticality that we call local syntactic
coherence.
Our second contribution is a graph-theoretic
model of the acquisition of lexical syntactic rep-
resentations that is more rigorous than previous
heuristic proposals. The graph-theoretic model
can learn both categorical and non-categorical (or
graded) representations. The model is also a unified
framework for syntagmatic and paradigmatic rela-
tions (as will be discussed below), and for lower-
order syntactic relations (those that can be directly
observed from the input) and higher-order syntac-
tic relations (those that require some generalization
from what is directly observable).
Redington et al (1998) give an influential account
of the acquisition of lexical syntactic representations
in which a standard syntactic category like verb or
noun is assigned to each word. Our third contribu-
tion is to show that, in the context of acquisition,
graded representations are superior to standard cat-
egorical representations in supporting judgments of
local syntactic coherence. A graded representation
formalism is one that, for any two words, can rep-
resent a third word whose syntactic properties are
intermediate between the two words (Manning and
Schu?tze, 1999).
Clearly exemplar theory is not the only frame-
work in which lexical acquisition has been explored.
Gleitman (1990) for example argues for syntactic
bootstrapping to infer lexical semantics, work not at
odds with our own (see discussion on the role of se-
mantics below). Our argument for the importance
of distributional evidence does not call into question
the large body of work in child language acquisition
that demonstrates that ?part of the capacity to learn
languages must be ?innate? ? (Gleitman and New-
port, 1995). Tabula rasa learning is not possible. Our
goal is not to show that language acquisition pro-
ceeds with a minimum of inductive bias. Rather, we
attempt to formalize one aspect of language acquisi-
tion, the use of distributional information.
The paper is organized as follows. Section 2 moti-
vates the exemplar-theoretic approach by reviewing
its success in phonetics. Section 3 defines local syn-
tactic coherence, which is the basis for a new evalu-
ation methodology for the acquisition of lexical rep-
resentations. Section 4 develops the graph-theoretic
model. Section 5 compares graded and categorical
representations for the task of inferring local syn-
917
tactic coherence. Section 6 presents our evaluation.
Sections 7 and 8 discuss related and future work, and
present our conclusions.
2 Exemplar theory
The general idea of research into exemplars in
speech production and perception is that encoun-
tered items (segments, words, sentences etc.) are
stored in great detail in memory along with rich
linguistic and extra-linguistic context information.
These exemplars are organized into clouds of mem-
ory traces with similar traces lying close to each
other while dissimilar traces are more distant. A
number of such models have had great success in
accounting for production and perception phenom-
ena in phonetics. E.g., Johnson (1997) offers an
exemplar model which challenges the notion that
speech is perceived through a process of normal-
ization whereby a speaker-specific representation is
mapped or normalized into a speaker-neutral cate-
gorical abstraction. Johnson?s model successfully
treats aspects of vowel perception, sex identifica-
tion, and speaker variability. Crucially, no normal-
ization of percepts into categorical representations
takes place. The correct identification of phonemes
and words in his model is a function of direct com-
parison to richly detailed exemplars stored in mem-
ory. Other examples of exemplar-theoretic phonetic
accounts include (Goldinger, 1997), (Pierrehumbert,
2001), and our own work (Schu?tze et al, 2007). Ex-
emplar theory?s success in phonetics motivates us to
investigate its use as a model for local syntactic phe-
nomena.
3 Local syntactic coherence
In the context sequence model for exemplar-
theoretic phonetics (Wade et al, 2008), we represent
speech using amplitude envelopes derived from the
acoustic signal and then compute similarity as the
integral over the correlation of the two acoustic sig-
nals.
For the syntactic level, we need a representa-
tion that has two key properties of the represen-
tation we use in phonetics in order to support an
exemplar-theoretic account. First, the representa-
tion must be directly derivable from the perceived
input. In particular, it cannot rely on the results of
any disambiguation that would occur either as part
of exemplar-theoretic perception or in further down-
stream processing. Second, it must support similar-
ity computations. Accordingly, we first motivate the
representation we use and then introduce a similarity
measure on these representations.
Representation. There are two main sources1 of
directly observable information about the syntactic
properties of words: semantic cues (e.g., things are
often referred to with nouns) and the neighbors of
a word in sentences that it is used in. In this pa-
per, we only consider the second source of informa-
tion for acquisition, lexical neighbors.2 We further
limit ourselves to the immediate left and right lexical
neighbors (see discussion in Section 7).
When using lexical neighbors as the basis of rep-
resentation, we have to make a basic choice as to
whether we look at left and right neighbors sepa-
rately or whether we only look at the ?correlated?
neighborhood information of left and right neigh-
bors jointly. Our approach is based on the first alter-
native: we separate the processing of left and right
neighbors. We do this for two reasons. First, gener-
alization improves and model complexity decreases
if left-neighbor information and right-neighbor in-
formation are looked at separately. E.g., the right
neighbors of to, might and not are similar because
all three words can be followed by base verbs like
dance: to dance, might dance, (might) not dance.
But their left neighbors are very different.
Second, exemplar-theoretic similarity is best de-
fined at the smallest possible scale in order to allow
optimal matching between parts of the stimulus and
parts of memory. In phonetics, we use a time scale
of 10s of milliseconds or even less. Conceivably,
one could also use segments (e.g., consonants and
vowels) as the smallest unit; however, this would
presume a segmented signal. And segmentation is
part of the perception task we want to explain in the
first place.
Separating left and right neighbors ? which
amounts to looking at left and right local contexts
of each word separately ? is the smallest scale we
can operate at when doing syntactic matching. We
1A comprehensive account of acquisition must also include
morphology. See Christiansen et al (2004).
2Psycholinguistic evidence for the importance of neighbor
information for learning categories includes (Mintz, 2002).
918
choose this small scale for the same reasons as we
choose a small scale in phonetics: to ensure maxi-
mum flexibility when matching parts of the stimulus
with exemplars in memory. Using words, bigrams or
larger units would reduce the flexibility in matching
and require a larger amount of experience (or train-
ing data) to learn a particular generalization.
We refer to the representations of left and right
contexts of a given word as half-words. In other
words, we split a word into two entities, a left half-
word that characterizes its behavior to the left and
a right half-word that characterizes its behavior to
the right. Thus left-context and right-context com-
ponents of the representation of a given focus word
are defined, where a left (right) half-word consists
of a probability distribution over all words that oc-
cur to the left (right) of the focus word and the
dimensionality of the vector for each word is de-
pendent on the number of distinct neighbors (left
and right). For example, having experienced take
doll twice and drop doll once, then the left con-
text distribution, or left half-word of doll, dolll, is
P (take) = 2/3, P (drop) = 1/3. By extension, the
phrase take the doll is represented as the following
six half-words: takel, taker , thel, ther , dolll , and
dollr .
Distance measure. The basic intuition behind lo-
cal syntactic coherence is that an important compo-
nent of syntactic wellformedness ? and a compo-
nent that is of particular importance in acquisition
? is whether a similar sequence has already been
stored as grammatical in memory. The same way
that a phonetic signal that is well-formed in a partic-
ular language has many similar exemplars in mem-
ory, a syntactic sequence should also be licensed by
similar, previously perceived sequences in memory.
To operationalize this notion, we need to be able to
compute the similarity or distance between an in-
put stimulus and exemplars in memory. We do this
by first defining a distance measure for sequences of
fixed length.
The distance ? between two sequences of half-
words < g1, . . . , gn > and < h1, . . . , hn > is de-
fined to be the sum of the distances of their half-
words:
?(<g1, . . . , gn>,<h1, . . . , hn>) =
?n
i=1 ?(gi, hi)
This definition presupposes a definition of the dis-
tance of two half-words which will be given below.
We then call a sequence of n half-words
g1, . . . , gn locally coherent if there is a sequence
h1, . . . , hn in memory with ?(< g1, . . . , gn >,<
h1, . . . , hn >) < ? where ? is a parameter.
Finally, we define a sentence to be locally n-
coherent if all of its subsequences of length n are
locally coherent.
The graph-theoretic model that is introduced in
the next section will be evaluated with respect to
how well it captures local syntactic coherence. This
enables us to evaluate the model with respect to a
task as opposed to its ability to reproduce a particu-
lar linguistic representation of syntactic categories.3
Obviously, the notion of local syntactic coherence
only captures some aspects of syntax ? e.g., it does
not capture long-distance dependencies. However,
it is a plausible component of syntactic competence
and a plausible intermediate step in the acquisition
of syntax.
4 Graph-theoretic model
We briefly review the structuralist notions of syntag-
matic and paradigmatic relationships that have been
frequently used in prior work in NLP (e.g., (Church
et al, 1994)). De Saussure defined a syntagmatic
relationship between two words as their contigu-
ous occurrence in a sentence and a paradigmatic re-
lationship as mutual substitutability (de Saussure,
1962) (although he used the term rapport associ-
atif instead of paradigmatic). E.g., brown and dog
stand in a syntagmatic relationship with each other
in the phrase brown dog; brown and black stand in a
paradigmatic relationship with each other with re-
spect to the position between the and dog in the
phrase the X dog. De Saussure?s conceptualization
of syntactic relationships captures the fact that both
admissible neighbors and admissible substitutes in
language are an important part of the characteriza-
tion of the syntactic properties of a word.
We formalize the two relations as distribu-
tions over words, where we assume a vocabulary
{w1, . . . , wV } and V is the number of words in the
vocabulary.
We denote the left syntagmatic distribution of wi
3Freudenthal et al (2004) have much the same motivation
in introducing an evaluation measure of syntactic acquisition
based on chunking.
919
by pi,s,l,m where i is the vocabulary index of wi, s
stands for syntagmatic, l for left and m is the order
of the distribution as discussed below. Intuitively,
pi,s,l,m(wj) is the probability that word wj occurs to
the left of wi. Similarly, for the left paradigmatic
distribution of wi, pi,p,l,m(wj) is the probability that
wj can be substituted for wi without changing local
syntactic coherence as far as the context to the left
is concerned. Note that we distinguish between left
and right paradigmatic distributions. A word wj can
be a perfect substitute for wi as far as the context to
the left is concerned, but a very unlikely substitute as
far as the context to the right is concerned. E.g., in
the phrase She loves her job, the word him is a good
left-context substitute for her, but a terrible right-
context substitute for her.
We will now show how the syntag-
matic/paradigmatic (henceforth: syn/para) dis-
tributions are defined iteratively, based on the
bigram distribution pww, and grounded by defining
pi,p,l,1 and pi,p,r,1.
pww(wiwj) is the probability that the bigram
wiwj occurs, that is, that wi and wj occur next to
each other (and in that order). We define the V ? V
joint probability matrix J by Jij = pww(wiwj).
Denote by N the diagonal V ?V matrix that con-
tains in Nii the reciprocal of pw(wi) where pw is the
marginal distribution of pww:
V
?
j=1
pww(wiwj) =
V
?
j=1
pww(wjwi) = pw(wi) =
1
Nii
The conditional probability pleft of the fol-
lowing word and the conditional probability
pright of the preceding word can be computed
by multiplying (the transpose of) J and N :
pleft(wi|wj) = pww(wiwj)/pw(wj) = (JN)ij ; and
pright(wi|wj) = (JTN)ij .
The ?grounding? paradigmatic distributions of or-
der 1 are defined as follows.
pi,p,l,1(wj) = pi,p,r,1(wj) =
{
0 if wi 6= wj
1 if wi = wj
In other words, each word has only one perfect left
/ right substitute and that perfect substitute is itself.
We define the syn/para distributions of higher order
recursively:
pi,s,l,m = JNpi,p,l,m (1)
pi,p,r,m pi,s,r,m
woman
girl
boy
man
ran
sang
laughed
cried
Figure 1: The distribution of typical right neighbors (the
right syntagmatic distribution pi,s,r,m) is computed from
the distribution of typical ?right substitutes? (the right
paradigmatic distribution pi,p,r,m).
pi,p,l,m = JTNpi,s,l,m?1 (2)
pi,s,r,m = JTNpi,p,r,m (3)
pi,p,r,m = JNpi,s,r,m?1 (4)
Basic matrix arithmetic shows that pi,s,l,1 is sim-
ply pleft(.|wi) and pi,s,r,1 is pright(.|wi).
For higher orders, the principle underlying Eq.s
1?4 is that when moving from left to right, we use
pright (that is, JTN ), the conditional distribution that
characterizes right neighbors; when moving from
right to left, we use pleft (that is, JN ), the condi-
tional distribution that characterizes left neighbors.
This is graphically shown in Fig. 1.
As illustrated by Fig. 1, the underlying graph for
pi,s,r,m and pi,p,r,m is a weighted bipartite directed
graph that connects the vocabulary on the left with
the vocabulary on the right. A directed edge from
wi on the left to wj on the right is weighted with
pww(wiwj)/pw(wi). A directed edge from wj on
the right to wi on the left (not shown) is weighted
with pww(wiwj)/pw(wj).
Eq.s 1?4 define four Markov chains:
pi,s,l,m = (JNJTN)pi,s,l,m?1 (5)
pi,p,l,m = (JTNJN)pi,p,l,m?1 (6)
pi,s,r,m = (JTNJN)pi,s,r,m?1 (7)
pi,p,r,m = (JNJTN)pi,p,r,m?1 (8)
It is easy to see that pw is a stationary distribution
for Eq. 1?4. Writing ~x for pw, we have:
(JN~x)i =
V
?
j=1
pww(wiwj)
pw(wj)
pw(wj) = pw(wi) = xi
(JTN~x)i =
V
?
j=1
pww(wjwi)
pw(wj)
pw(wj) = pw(wi) = xi
920
Hence, pw is a solution for Eq.s (5)?(8).
The series converge if JNJTN and JTNJN
are ergodic, i.e., if the chain is aperiodic and irre-
ducible (Kemeny and Snell, 1976). Observe that
for many simple probabilistic context-free gram-
mars (PCFGs) the series in Eq. 1?4 will not con-
verge. For simple PCFGs, the alternation between
syntagmatic and paradigmatic distributions is peri-
odic. E.g., if inflected verb forms only occur after
nouns and nouns only before inflected verb forms,
then the right syntagmatic distributions of nouns will
have non-zero activation only for verbs and the right
paradigmatic distributions of nouns will have non-
zero activation only for nouns, thus preventing con-
vergence.4
The key difference between a simple PCFG and
natural language is ambiguity and noise. Because
of ambiguity and noise, JNJTN and JTNJN are
likely to be ergodic ? there is always a small non-
zero probability that two words can occur next to
each other. Ambiguity and noise have the same ef-
fect as teleportation for PageRank (Brin and Page,
1998) in the sense that we can jump from each word
to each other word with non-zero probability.
Assuming that the Markov chains are ergodic, all
four converge to pw: pi,p,r,? = pi,p,l,? = pi,s,r,? =
pi,s,l,? = pw, for 1 ? i ? V .
Thus, in this formalization, given enough itera-
tions, syntagmatic and paradigmatic distributions of
words eventually all become identical with the prior
distribution pw. This is surprising because linguisti-
cally and computationally syntagmatic and paradig-
matic relations are fundamentally different.
However, on closer inspection, we observe that
limiting the number of iterations is often beneficial
when computing solutions to a problem iteratively.
E.g., the expectation-maximization algorithm is of-
ten stopped early because results close to conver-
gence are worse than results obtained after a small
number of iterations. From the point of view of
modeling human language acquisition, early stop-
ping is perhaps also more realistic since humans are
unlikely to perform a large number of iterations.
4However, non-ergodicity of JN does not imply non-
ergodicity of JNJT N and JT NJN , so Eq. (5)?(8) can con-
verge even for non-ergodic JN .
g
g
g
g
g
g
g g g g g g g g g
2 4 6 8 10 12 14
0.
0
0.
1
0.
2
0.
3
0.
4
0.
5
0.
6
0.
7
iteration m
JS
 d
ive
rg
en
ce
 o
f r
ig
ht
 s
yn
t. 
di
st
rib
ut
io
ns
t t t t t t t t t t t t t t t
g
t
elephant?giraffe
elephant?the
Figure 2: The distance between elephant and giraffe
(measured by the Jensen-Shannon divergence) is accu-
rately represented after a number of iterations. The words
elephant and the retain their large distance.
Example 1. For the following matrix J
?
?
?
?
w1 w2 w3
w1 82/1002 77/1002 112/1002
w2 90/1002 18/1002 107/1002
w3 99/1002 120/1002 297/1002
?
?
?
?
we get p1,s,r,1 = (0.31, 0.28, 0.41) by comput-
ing the product JTNp1,p,r,1. E.g., p1,s,r,1(w2) =
pww(w1w2)/pw(w1) ? 1.0 = 77/(82 + 77 + 112) ?
0.28.
By iteration m = 4, the series pi,s,r,m (Eq. (7))
and pi,p,r,m (Eq. (8)) have converged to:
pi,s,r,m = pi,p,r,m = (0.2704, 0.2145, 0.5149)
for all three words wi. One can easily verify that
this is pw. E.g., pw(w1) = (82 + 90 + 99)/1002 =
(82 + 77 + 112)/1002 ? 0.27045.
Example 2. We computed 15 iterations of
syn/para distributions for the corpus: The giraffe
ran. An elephant fell. The man ran. An aunt fell. The
man slept. The aunt slept. Fig. 2 shows that the dis-
tance between the right syntagmatic distributions of
elephant and giraffe is large for m = 1. The reason
is that the two words have no right neighbors in com-
mon. The right neighbors of the two words are ran
and fell. Although ran and fell have no left neighbors
in common, their left neighbors have a right neigh-
bor in common: the word slept. This indirect simi-
larity information is exploited to deduce by iteration
921
15 that the two words are very similar with respect to
their right syntactic context. In contrast, no such in-
ference, even a very indirect one, is possible for the
right contexts of elephant and the. Consequently, the
distance between the two distributions remains high
and unchanged with higher iterations.
In this case, the Markov chain is not ergodic and
the syntagmatic and paradigmatic series (Eq.s (5)?
(8)) do not converge to pw.
5 Experimental evaluation
Recall from Section 3 that our evaluation task is to
discriminate sentences that exhibit local coherence
from those that do not; that sentences are repre-
sented as sequences of half-words; that syntactic co-
herence of a sentence is defined as all subsequences
of a given length n exhibiting local coherence; and
that a subsequence is locally coherent if its distance
from a sequence in memory is less than ?.
These definitions can be applied to the graph
model as follows. A left half-word is a left syntag-
matic (or paradigmatic) distribution and a right half-
word is a right syntagmatic (or paradigmatic) distri-
bution. We compute the distance of two half-words
either as the Jensen-Shannon (JS) divergence (Lin,
1991) or as (1? cos(?)). JS divergence is more ap-
propriate for the comparison of probability distribu-
tions. But the cosine is more efficient when a sparse
vector is compared to a dense vector.5 We therefore
employ the cosine for the compute-intensive experi-
ments in Section 6.
The baseline representation is the categorical rep-
resentation proposed by Redington et al (1998). A
difficulty in replicating their experiments is that they
use hierarchical agglomerative clustering (HAC),
which eventually agglomerates all words in a sin-
gle category. To circumvent the need for a stop-
ping criterion, we represent each word as the tem-
poral sequence of clusters it occurred in during ag-
glomeration and define the distance of two words as
the agglomeration step in which the two words are
joined in a cluster. E.g., given the agglomeration se-
quences {1}, {1, 2}, {1, 2, 4}, {1, 2, 3, 4} for w1 and
{4}, {4}, {1, 2, 4}, {1, 2, 3, 4} for w4, the distance
5This is so because, when computing the cosine, we can ig-
nore all dimensions where one of the two vectors has a zero
value.
between w1 and w4 is 3 since they are joined in step
3 when cluster {1, 2, 4} is created.
For both graded (graph-theoretic) and categorical
(cluster-based) representations, we need to set the
parameter ? that is the boundary between locally co-
herent and locally incoherent sentences. This pa-
rameter gives rise to a precision-recall tradeoff. A
small ? will impose strict requirements on which se-
quences in memory match, resulting in false nega-
tive decisions for local grammaticality. A large ?
will incorrectly judge many locally incoherent se-
quences to be grammatical.
We will pick the optimal ? in both cases. For
categorical representations, this amounts to select-
ing the HAC dendrogram with optimal performance.
The experiment below evaluates whether grammati-
cal and ungrammatical sentences are well separated
by the proposed measure.6
Experiment on CHILDES. We used the well-
known CHILDES database (MacWhinney, 2000), a
corpus of conversations between young children and
their playmates, siblings, and caretakers. In order to
avoid mixing varieties of English (e.g., British En-
glish vs. American English), we selected the largest
homogeneous subcorpus of CHILDES, the Manch-
ester corpus. It contains roughly 350,000 sentences
and 1.5 million words. This is a conservative esti-
mate of the amount of child-directed speech a child
would receive annually (Redington et al, 1998). All
names in the corpus (i.e., all capitalized words) were
replaced with a special word ? n ?. A boundary
symbol ? b ? was introduced to separate sentences.
The representation of the corpus is then a concate-
nation of all its sentences. The vocabulary consists
of V = 8601 words.
Construction of the evaluation set. We tested
the ability of the two models to distinguish locally
coherent vs. incoherent sentences by selecting 100
unattested sentences from the corpus, which were
not used to train the model. We only selected unat-
tested sentences that were not a substring of a sen-
tence in the training corpus since, presumably, any
substring of a sentence in the training corpus is lo-
cally coherent. A further constraint was that the
6This evaluation of ?separation? is not directly an evaluation
of classification performance, but more similar to an evaluation
of ranking using AUC or an evaluation of clustering using a
measure like purity.
922
unattested sentence was not allowed to contain a
word that did not occur in the training corpus, the
rationale being that we want to address the prob-
lem of local coherence for known words only since
unknown words present special challenges. Finally,
we ensured that each unattested sentence contained
a word that occurred in only one sentence type in
the training corpus. In early experiments, we found
that local grammatical inference for frequent words
is easy as there is redundant evidence available that
characterizes legal syntactic environments for fre-
quent words. Since rare words are a key challenge in
syntactic acquisition, we only selected sentences as
unattested sentences that contained at least one rare
word (where a rare word is defined as a word that
occurs once in the training set).
100 ungrammatical sentences were generated by
randomly selecting and concatenating words from
the vocabulary. Ungrammatical sentences were
matched in length to unattested sentences, so that
both sets contained the same number of sentences
of a given length. As with unattested sentences, un-
grammatical sentences that were substrings of sen-
tences in the training corpus were eliminated. As
there are many more infrequent words than frequent
words in the vocabulary, the construction ensured
that, as with unattested sentences, infrequent words
were overrepresented in ungrammatical sentences.
To summarize, our setup consists of 348,463
training sentences, 100 unattested grammatical sen-
tences and 100 ungrammatical sentences.
The task of discriminating the 100 unattested
from the 100 ungrammatical sentences cannot be
solved perfectly as CHILDES contains ungrammat-
ical sentences, a few of which were randomly se-
lected as unattested sentences (e.g., yes pleas, which
is missing the final letter). Similarly, one or two
of the automatically generated ungrammatical sen-
tences were actually grammatical.
Since the test set does not consist of a random
sample of sentences, performance on the test set is
not a direct indicator of the percentage of sentences
that the model can correctly discriminate in a child?s
typical input. A large proportion of sentences in
child input are simple 1-word, 2-word, and 3-word
sentences that even simplistic models can evaluate
with high accuracy. However, the test set is appro-
priate for a comparative evaluation of graded and
x
x
x
x
x
x
x x
x x
2 4 6 8 10
0.
5
0.
6
0.
7
0.
8
0.
9
1.
0
number of half words
a
cc
u
ra
cy
 o
f d
isc
rim
in
at
io
n
c
c c c
c
c
c
c
c c
x
c
graded
categorical
Figure 3: Accuracy of discrimination between grammati-
cal and ungrammatical sentences for graded and categor-
ical representations.
categorical syntactic representations in language ac-
quisition, which is one of the goals of the paper. Dif-
ficult sentences (those with rare words and greater
length) are overrepresented in the test set as the dis-
crimination of short sentences containing only fre-
quent words can easily be done by simplistic mod-
els. Thus, a test set of ?easy? sentences would not
distinguish good models from bad models.
Discrimination experiment. In order to train the
graph model, the entries of matrix J were estimated
using maximum likelihood based on the training
corpus. pi,s,l,1 and pi,s,r,1 were then computed for
all 8601 words. Replicating (Redington et al, 1998),
the most frequent 1000 words were clustered (using
single-link HAC, Manning and Schu?tze (1999)). For
each remaining word w, the closest neighbor w? in
the 1000 most frequent words was determined and
w was then assigned to the cluster of w?.
Fig. 3 shows the performance of graded and cat-
egorical representations for different subsequence
sizes n. To compute the accuracy for each n, the ?
with optimal discrimination performance was cho-
sen (for both graded and categorical).
For a subsequence of size n = 1, the performance
is 0.5 in both cases since the 200-sentence test set
does not contain unknown words. So for every half-
word, there is a sequence of one half-word in the
training corpus with distance 0. Thus, all sentences
923
get the same local coherence scores, both for graded
and categorical representations.
This argument does not apply to n = 2 since we
earlier defined a sentence to be locally coherent if
all of its subsequences are coherent. While subse-
quences of 2 half-words that are part of the same
word have local coherence score 0, this is not true of
subsequences of 2 half-words that are part of differ-
ent words, e.g., the subsequence <blackr,dogl> in
black dog. If black dog does not occur in the train-
ing set, then its local coherence score is > 0.
The main result of the experiment is that except
for n=1 (p = 1) and n=2 (p = 0.39) the differences
between categorical and graded representations are
significant (?2 test, p < 0.05 for 3 ? n ? 10). This
is evidence that graded representations are more ac-
curate when determining local syntactic coherence
and grammaticality than categorical representations.
The experimental results demonstrate that, for
syntagmatic distributions of order 1, graded repre-
sentations discriminate locally coherent vs. incoher-
ent sentences better than categorical representations.
We attribute this to the ability of exemplar theory to
incorporate rich context information into discrimi-
nation decisions. This is of particular importance
for ambiguous words. Categorical representations of
ambiguous words are problematic because they are
either too similar or not similar enough to the two
alternatives. E.g., if a word with a verb/noun ambi-
guity is represented as one of the alternatives, say,
as a verb, then subsequences containing its noun use
will no longer be similar to other subsequences with
nouns. If a special conflation category noun/verb is
introduced, then we are faced with the same prob-
lem: subsequences containing the noun/verb cate-
gory are not similar to subsequences containing ei-
ther non-ambiguous verbs or non-ambiguous nouns.
6 Higher-order distributions
The main motivation for higher-order distributions
is that syntagmatic vectors of order 1 do not per-
form well for some infrequent words. In the ele-
phant/giraffe example above, the distance between
the two words is close to maximum for order 1 repre-
sentations because each occurs only once, in entirely
different contexts. As we showed in Fig. 2, higher-
order representations address this problem because
s
s
s
s
s
s
s
s
s
2 4 6 8 10
0.
70
0.
75
0.
80
0.
85
0.
90
0.
95
number of half words
a
cc
u
ra
cy
 o
f d
isc
rim
in
at
io
n
p p
p
p
p
p
p p
p
t
t
t
t
t
t t
t
t
q
q q
q
q
q q
q
q
s
p
t
q
synt?1
para?2
synt?2
para?3
Figure 4: Accuracy of discrimination between grammat-
ical and ungrammatical sentences of the exemplar-based
method for different orders. Key: synt = syntagmatic,
para = paradigmatic; s is of order 1; p and t are of order
2; q is of order 3.
they exploit indirect evidence about the syntactic
properties of words.
To evaluate higher-order representations on
CHILDES, we used the same setup as before, but
computed several additional iterations. We also lim-
ited the experiments to a subset consisting of 60,000
words of the Manchester corpus. It contains only
V=1666 different words, which reduces the storage
requirements for the syn/para distributions (which is
2 ?V 2 for each order) and the cost of the matrix mul-
tiplications. We also used (1? cos(?)) instead of JS
divergence as distance measure.
The results of the experiment are shown in Fig. 4.
Higher-order representations are clearly superior for
short subsequences, especially for n = 2 and n = 3
(and up to 5 half-words when comparing synt-1 and
para-2). However, for long subsequences, there is no
consistent difference between the syntagmatic distri-
bution of order 1 (synt-1) and higher order distribu-
tions. Apparently, the generalized information avail-
able in higher orders is not helpful in local grammat-
ical inference if long contexts are considered.
We were surprised that the best-performing dis-
tribution for short sequences is para-2 (paradigmatic
distribution of order 2), not a higher order distri-
bution. E.g., para-3 performs worse than para-2.
924
We would expect the performance to decrease with
higher order eventually since the distributions con-
verge towards pw. The fact that this happens so early
in this experiment merits further investigation.
7 Related work
Data-oriented parsing (Bod et al, 2003) shares
basic assumptions about linguistic inference with
exemplar-based theory, but it does not model or use
the similarity between input and stored exemplars.
Previous work on exemplar theory in syntax (Abbot-
Smith and Tomasello, 2006; Bybee, 2006; Hay and
Bresnan, 2006) has not been computational or for-
mal. Previous work on non-categorical representa-
tions of words has viewed these representations as
an intermediate step for arriving at categorical parts
of speech (Redington et al, 1998; Schu?tze, 1995;
Clark, 2003). Consequently, all of these papers eval-
uate their results by comparing induced categories to
gold-standard parts of speech.
Redington et al (1998) did not find a difference in
categorization accuracy between simple syntagmatic
representation and those using non-adjacent words.
The BEAGLE model (Jones and Mewhort, 2007),
and related work (Sahlgren et al, 2008), merges co-
occurrence information and word order information
into a single composite vector through a process of
vector convolution. Our model differs in that it ex-
plicitly captures the recursive relationship between
the orders in a unified framework.
Previous graph-theoretic work (Biemann, 2006)
uses order 1 representations. Several papers have
looked at higher-order representations, but have not
examined the equivalence of syn/para distributions
when formalized as Markov chains (Schu?tze and
Pedersen, 1993; Lund and Burgess, 1996; Edmonds,
1997; Rapp, 2002; Biemann et al, 2004; Lemaire
and Denhie`re, 2006). Toutanova et al (2004) found
that their graph model of predicate argument struc-
ture deteriorated after a small number of iterations
of the random walk, similar to our findings.
8 Conclusions and Future Work
In this paper, we have presented a graph-theoretic
model of the acquisition of lexical syntactic rep-
resentations and a new exemplar-based evaluation
of lexical syntactic acquisition. When applied to
the CHILDES corpus, the evaluation shows that
the graded syntactic representations learned by the
model perform significantly better than previously
proposed categorical representations. An initial
evaluation of high-order representations showed lit-
tle improvement over low-order representations.
In future work, we intend to investigate the in-
fluence of noise and ambiguity on the quality of
the representations in order to characterize when
higher order representations improve generalization
and exemplar-theoretic inference. We also want
to address that the model as it currently stands is
trained under the false assumption that the train-
ing input is grammatical. Ungrammatical test input
which matches a learned ungrammatical sequence
will be deemed grammatical. Future work will ex-
amine how to best treat this challenge, e.g., by using
an estimation of density instead of the simplistic ?1
nearest neighbor? distance used here.
The most important future work concerns class-
based language models. The cognitive-linguistic
tradition we have mainly addressed in this paper
has focused on the task of learning traditional parts
of speech and has usually not discussed the rele-
vance of language models to acquisition. If, as we
have argued, instead of learning traditional parts of
speech the focus should be on performance in par-
ticular language processing tasks (like grammatical-
ity judgments), then language models are the nat-
ural competing account that we must compare our
work to. Of particular relevance are class-based lan-
guage models (e.g., (Saul and Pereira, 1997; Brown
et al, 1992)). In ongoing work, we are attempting
to show that the exemplar-theoretic model performs
better on grammaticality judgments than class-based
language models.
Acknowledgements. This research was funded by
the German Research Council (DFG, Grant SFB
732). We thank K. Rothenha?usler, H. Schmid and
the reviewers for their valuable comments.
References
Abbot-Smith, Kirsten and Michael Tomasello. 2006.
Exemplar-learning and schematization in a usage-
based account of syntactic acquisition. The Linguistic
Review, 23:275?290.
925
Biemann, Chris, Stefan Bordag, and Uwe Quasthoff.
2004. Automatic acquisition of paradigmatic relations
using iterated co-occurrences. In LREC.
Biemann, Chris. 2006. Unsupervised part-of-speech tag-
ging employing efficient graph clustering. In ACL.
Bod, Rens, Remko Scha, and Khalil Sima?an. 2003.
Data-Oriented Parsing. CSLI Publications.
Brin, Sergey and Lawrence Page. 1998. The anatomy
of a large-scale hypertextual web search engine. In
WWW, pages 107?117.
Brown, Peter F., Peter V. deSouza, Robert L. Mercer, Vin-
cent J. Della Pietra, and Jenifer C. Lai. 1992. Class-
based n-gram models of natural language. Comput.
Linguist., 18(4):467?479.
Bybee, Joan L. 2006. From usage to grammar: The
mind?s response to repetition. Language, 82:711?733.
Christiansen, Morten, Luca Onnis, Padraic Monaghan,
and Nick Chater. 2004. Happy endings in language
acquisition. In AMLaP.
Church, Kenneth, Patrick Hanks, Donald Hindle,
William Gale, and Rosamund Moon. 1994. Lexical
substitutability. In Atkins, B.T.S. and A. Zampolli, ed-
itors, Computational Approaches to the Lexicon. OUP.
Clark, Alexander. 2003. Combining distributional and
morphological information for part of speech induc-
tion. In EACL, pages 59?66.
de Saussure, Ferdinand. 1962. Cours de linguistique
ge?ne?rale. Payot, Paris. Originally published in 1916.
Edmonds, Philip. 1997. Choosing the word most typical
in context using a lexical co-occurrence network. In
ACL, pages 507?509.
Freudenthal, Daniel, Julian Pine, and Fernand Gobet.
2004. Resolving ambiguities in the extraction of syn-
tactic categories through chunking. In ICCM.
Gleitman, Lila and Elissa Newport. 1995. The invention
of language by children: Environmental and biologi-
cal influences on the acquisition of language. In Gleit-
man, Lila and Mark Liberman, editors, Language: An
invitation to cognitive science. MIT Press, 2nd edition.
Gleitman, Lila. 1990. The structural sources of verb
meanings. Language Acquisition, 1:3?55.
Goldinger, Stephen D. 1997. Words and voices?
perception and production in an episodic lexicon. In
(Johnson and Mullennix, 1997).
Hay, Jennifer and Joan Bresnan. 2006. Spoken syntax:
The phonetics of giving a hand in New Zealand En-
glish. The Linguistic Review, 23.
Johnson, Keith and John W. Mullennix, editors. 1997.
Talker Variability in Speech Processing. Academic
Press.
Johnson, Keith. 1997. Speech perception without
speaker normalization. In (Johnson and Mullennix,
1997).
Jones, Michael N. and Douglas J.K. Mewhort. 2007.
Representing word meaning and order information in
a composite holographic lexicon. Psychological Re-
view, 114:1?37.
Kemeny, John G. and J. Laurie Snell. 1976. Finite
Markov Chains. Springer, New York.
Lemaire, Benoit and Guy Denhie`re. 2006. Effects of
high-order co-occurrences on word semantic similar-
ity. Behaviour, Brain & Cognition, 18(1).
Lin, Jianhua. 1991. Divergence measures based on the
Shannon entropy. IEEE Trans. Inf. Theory, 37(1):145?
151.
Lund, Kevin and Curt Burgess. 1996. Producing
high-dimensional semantic spaces from lexical co-
occurrence. Behavior Research Methods, Instrumen-
tation, and Computers, 28:203?208.
MacWhinney, Brian. 2000. The CHILDES project:
Tools for analyzing talk. Lawrence Erlbaum.
Manning, Christopher D. and Hinrich Schu?tze. 1999.
Foundations of Statistical Natural Language Process-
ing. MIT Press, Boston, MA.
Mintz, Toben H. 2002. Category induction from dis-
tributional cues in an artificial language. Memory &
Cognition, 30:678?686.
Pierrehumbert, Janet. 2001. Exemplar dynamics: Word
frequency, lenition and contrast. In Bybee, Joan and
Paul Hopper, editors, Frequency and the Emergence of
Linguistic Structure, pages 137?157. Benjamins.
Rapp, Reinhard. 2002. The computation of word as-
sociations: comparing syntagmatic and paradigmatic
approaches. In Coling.
Redington, Martin, Nick Chater, and Steven Finch.
1998. Distributional information: A powerful cue
for acquiring syntactic categories. Cognitive Science,
22(4):425?469.
Sahlgren, Magnus, Anders Holst, and Jussi Karlgren.
2008. Permutations as a means to encode order in
word space. In CogSci.
Saul, Lawrence and Fernando Pereira. 1997. Aggre-
gate and mixed-order markov models for statistical
language processing. In EMNLP, pages 81?89.
Schu?tze, Hinrich and Jan Pedersen. 1993. A vector
model for syntagmatic and paradigmatic relatedness.
In UW Centre for the New OED and Text Research.
Schu?tze, Hinrich, Michael Walsh, Travis Wade, and
Bernd Mo?bius. 2007. Towards a unified exemplar-
theoretic model of phonetic and syntactic phenomena.
In CogSci, Poster Session.
Schu?tze, Hinrich. 1995. Distributional part-of-speech
tagging. In EACL, pages 141?148.
Toutanova, Kristina, Christopher D. Manning, and An-
drew Y. Ng. 2004. Learning random walk models for
inducing word dependency distributions. In ICML.
Wade, Travis, Grzegorz Dogil, Hinrich Schu?tze, Michael
Walsh, and Bernd Mo?bius. 2008. Syllable fre-
quency effects in a context-sensitive segment produc-
tion model. Submitted.
926
Proceedings of the 12th Conference of the European Chapter of the ACL, pages 728?736,
Athens, Greece, 30 March ? 3 April 2009. c?2009 Association for Computational Linguistics
Frequency Matters: Pitch Accents and Information Status
Katrin Schweitzer, Michael Walsh, Bernd Mo?bius,
Arndt Riester, Antje Schweitzer, Hinrich Schu?tze
University of Stuttgart
Stuttgart, Germany
<firstname>.<surname>@ims.uni-stuttgart.de
Abstract
This paper presents the results of a series
of experiments which examine the impact
of two information status categories (given
and new) and frequency of occurrence on
pitch accent realisations. More specifi-
cally the experiments explore within-type
similarity of pitch accent productions and
the effect information status and frequency
of occurrence have on these productions.
The results indicate a significant influence
of both pitch accent type and information
status category on the degree of within-
type variability, in line with exemplar-
theoretic expectations.
1 Introduction
It seems both intuitive and likely that prosody
should have a significant role to play in marking
information status in speech. While there are well
established expectations concerning typical asso-
ciations between categories of information status
and categories of pitch accent, e.g. rising L?H
accents are often a marker for givenness, there
is nevertheless some variability here (Baumann,
2006). Furthermore, little research has focused on
how pitch accent tokens of the same type are re-
alised nor have the effects of information status
and frequency of occurrence been considered.
From the perspective of speech technology, the
tasks of automatically inferring and assigning in-
formation status clearly have significant impor-
tance for speech synthesis and speech understand-
ing systems.
The research presented in this paper examines a
number of questions concerning the relationship
between two information status categories (new
and given), and how tokens of associated pitch ac-
cent types are realised. Furthermore the effect of
frequency of occurrence is also examined from an
exemplar-theoretic perspective.
The questions directly addressed in this paper
are as follows:
1. How are different tokens of a pitch accent
type realised?
Does frequency of occurrence of the pitch ac-
cent type play a role?
2. What effect does information status have on
realisations of a pitch accent type?
Does frequency of occurrence of the informa-
tion status category play a role?
3. Does frequency of occurrence in pitch ac-
cents and in information status play a role,
i.e. is there a combined effect?
In examining the realisation of pitch accent to-
kens, their degree of similarity is the characteristic
under investigation. Similarity is calculated by de-
termining the cosine of the angle between pairs of
pitch accent vector representations (see section 6).
The results in this study are examined from
an exemplar-theoretic perspective (see section 3).
The expectations within that framework are based
upon two different aspects. Firstly, it is expected
that, since all exemplars are stored, exemplars of
a type that occur often, offer the speaker a wider
selection of exemplars to choose from during pro-
duction (Schweitzer and Mo?bius, 2004), i.e. the
realisations are expected to be more variable than
those of a rare type. However, another aspect of
Exemplar Theory has to be considered, namely en-
trenchment (Pierrehumbert, 2001; Bybee, 2006).
The central idea here is that frequently occurring
behaviours undergo processes of entrenchment,
they become in some sense routine. Therefore re-
alisations of a very frequent type are expected to
be realised similar to each other. Thus, similarity
and variability are expressions of the same charac-
teristic: the higher the degree of similarity of pitch
accent tokens, the lower their realisation variabil-
ity.
728
The structure of this paper is as follows: Sec-
tion 2 briefly examines previous work on the in-
teraction of information status categories and pitch
accents. Section 3 provides a short introduction to
Exemplar Theory. In this study similarity of pitch
accent realisations on syllables, annotated with the
information status categories of the words they be-
long to, is examined using the parametric intona-
tion model (Mo?hler, 1998) which is outlined in
Section 4. Section 5 discusses the corpus em-
ployed. Section 6 introduces a general methodol-
ogy which is used in the experiments in Sections 7,
8 and 9. Section 10 then presents some discussion,
conclusions and opportunities for future research.
2 Information Status and Intonation
It is commonly assumed that pitch accents are the
main correlate of information status1 in speech
(Halliday, 1967). Generally, accenting is said
to signal novelty while deaccenting signals given
information (Brown, 1983), although there is
counter evidence: various studies note given in-
formation being accented (Yule, 1980; Bard and
Aylett, 1999). Terken and Hirschberg (1994) point
out that new information can also be deaccented.
As for the question of which pitch accent type
(in terms of ToBI categories (Silverman et al,
1992)) is typically assigned to different degrees of
givenness, Pierrehumbert and Hirschberg (1990)
find H? to be the standard novelty accent for En-
glish, a finding which has also been confirmed by
Baumann (2006) and Schweitzer et al (2008) for
German. Given information on the other hand, if
accented at all, is found to carry L? accent in En-
glish (Pierrehumbert and Hirschberg, 1990). Bau-
mann (2006) finds deaccentuation to be the most
preferred realisation for givenness in his experi-
mental phonetics studies on German. However,
Baumann (2006) points out that H+L? has also
been found as a marker of givenness in a German
corpus study. Previous findings on the corpus used
in the present study found L?H being the typical
marker for givenness (Schweitzer et al, 2008).
Leaving the phonological level and examining
correlates of information status in acoustic detail,
Kohler (1991) reports that in a falling accent, an
early peak indicates established facts, while a me-
dial peak is used to mark novelty. In a recent
1The term information status is used in (Prince, 1992) for
the first time. Before that the terms givenness, novelty or in-
formation structure were used for these concepts.
study Ku?gler and Fe?ry (2008) found givenness to
lower the high tones of prenuclear pitch accents
and to cancel them out postnuclearly. These find-
ings among others (Ku?gler and Fe?ry, 2008) moti-
vate an examination of the acoustic detail of pitch
accent shape across different information status
categories.
The experiments presented here go one step fur-
ther, however, in that they also investigate poten-
tial exemplar-theoretic effects.
3 Exemplar Theory
Exemplar Theory is concerned with the idea that
the acquisition of language is significantly facil-
itated by repeated exposure to concrete language
input, and it has successfully accounted for a num-
ber of language phenomena, including diachronic
language change and frequency of occurrence ef-
fects (Bybee, 2006), the emergence of gram-
matical knowledge (Abbot-Smith and Tomasello,
2006), syllable duration variability (Schweitzer
and Mo?bius, 2004; Walsh et al, 2007), entrench-
ment and lenition (Pierrehumbert, 2001), among
others. Central to Exemplar Theory are the notions
of exemplar storage, frequency of occurrence, re-
cency of occurrence, and similarity. There is an
increasing body of evidence which indicates that
significant storage of language input exemplars,
rich in detail, takes place in memory (Johnson,
1997; Croot and Rastle, 2004; Whiteside and Var-
ley, 1998). These stored exemplars are then em-
ployed in the categorisation of new input percepts.
Similarly, production is facilitated by accessing
these stored exemplars. Computational models of
the exemplar memory also argue that it is in a con-
stant state of flux with new inputs updating it and
old unused exemplars gradually fading away (Pier-
rehumbert, 2001).
Up to now, virtually no exemplar-theoretic re-
search has examined pitch accent prosody (but
see Marsi et al (2003) for memory-based predic-
tion of pitch accents and prosodic boundaries, and
Walsh et al (2008)(discussed below)) and to the
authors? knowledge this paper represents the first
attempt to examine the relationship between pitch
accent prosody and information status from an
exemplar-theoretic perspective. Given the consid-
erable weight of evidence for the influence of fre-
quency of occurrence effects in a variety of other
linguistic domains it seems reasonable to explore
such effects on pitch accent and information sta-
729
tus realisations. For example, what effect might
givenness have on a frequently/infrequently occur-
ring pitch accent? Does novelty produce a similar
result?
The search for possible frequency of occur-
rence effects takes place with respect to pitch ac-
cent shapes captured by the parametric intonation
model discussed next.
4 The Parametric Representation of
Intonation Events - PaIntE
The model approximates stretches of F0 by em-
ploying a phonetically motivated model function
(Mo?hler, 1998). This function consists of the sum
of two sigmoids (rising and falling) with a fixed
time delay which is selected so that the peak does
not fall below 96% of the function?s range. The re-
sulting function has six parameters which describe
the contour and were employed in the analysis: pa-
rameters a1 and a2 express the gradient of the ac-
cent?s rise and fall, parameter b describes the ac-
cent?s temporal alignment (which has been shown
to be crucial in the description of an accent?s shape
(van Santen and Mo?bius, 2000)), c1 and c2 model
the ranges of the rising and falling amplitude of
the accent?s contour, respectively, and parameter d
expresses the peak height of the accent.2 These six
parameters are thus appropriate to describe differ-
ent pitch accent shapes.
For the annotation of intonation the GToBI(S)
annotation scheme (Mayer, 1995) was used. In
earlier versions of PaIntE, the approximation of
the F0-contour for H?L and H? was carried out on
the accented and post?accented syllables. How-
ever, for these accents the beginning of the rise is
likely to start at the preaccented syllable. In the
current version of PaIntE the window used for the
approximation of the F0-contour for H?L and H?
accents has been extended to the preaccented syl-
lable, so that the parameters are calculated over
the span of the accented syllables and its immedi-
ate neighbours (unless it is followed by a boundary
tone which causes the window to end at the end of
the accented syllable).
5 Corpus
The experiments that follow (sections 7, 9 and 8),
were carried out on German pitch accents from the
2Further information and illustrations concerning the me-
chanics of the PaIntE model can be found in Mo?hler and
Conkie (1998).
IMS Radio News Corpus (Rapp, 1998). This cor-
pus was automatically segmented and manually la-
belled according to GToBI(S) (Mayer, 1995). In
the corpus, 1233 syllables are associated with an
L?H accent, 704 with an H?L accent and 162 with
an H? accent.
The corpus contains data from three speakers,
two female and a male one, but the majority of the
data is produced by the male speaker (888 L?H
accents, 527 H?L accents and 152 H? accents). In
order to maximise the number of tokens, all three
speakers were combined. Of the analysed data,
77.92% come from the male speaker. However,
it is not necessarily the case that the same percent-
age of the variability also comes from this speaker:
Both, PaIntE and z-scoring (cf. section 6) nor-
malise across speakers, so the contribution from
each individual speaker is unclear.
The textual transcription of the corpus was an-
notated with respect to information status using
the annotation scheme proposed by Riester (2008).
In this taxonomy information status categories re-
flect the default contexts in which presuppositions
are resolved, which include e. g. discourse context,
environment context or encyclopaedic context.
The annotations are based solely on the written
text and follow strict semantic criteria. Given that
textual information alone (i.e. without prosodic
or speech related information) is not necessarily
sufficient to unambiguously determine the infor-
mation status associated with a particular word,
there are therefore cases where words have mul-
tiple annotations, reflecting underspecification of
information status. However, it is important to
note that in all the experiments reported here, only
unambiguous cases are considered.
The rich annotation scheme employed in the
corpus makes establishing inter-annotator agree-
ment a time-consuming task which is currently un-
derway. Nevertheless, the annotation process was
set up in a way to ensure a maximal smoothing of
uncertainties. Texts were independently labelled
by two annotators. Subsequently, a third, more ex-
perienced annotator compared the two results and,
in the case of discrepancies, took a final decision.
In the present study the categories given and
new are examined. These categories do not rep-
resent a binary distinction but are two extremes
from a set of clearly distinguished categories. For
the most part they correspond to the categories tex-
tually given and brand-new that are used in Bau-
730
mann (2006), but their scope is more tightly con-
strained. The information status annotations are
mapped to the phonetically transcribed speech sig-
nals, from which individual syllable tokens bear-
ing information status are derived.
Syllables for which one of the PaIntE-
parameters was identified as an outlier, were re-
moved. Outliers were defined such that the upper
2.5 percentile as well as the lower 2.5 percentile
of the data were excluded. This led to a reduced
number of pitch accent tokens: 1021 L?H accents,
571H?L accents and 134H? accents. Thus, there
is a continuum of frequency of occurrence, high to
low, from L?H to H?.
With respect to information status, 102 L?H ac-
cents, 87H?L accents and 21H? accents were un-
ambiguously labelled as new. For givenness the
number of tokens is: 114 L?H accents, 44H?L ac-
cents and 10H? accents.
6 General Methodology
In the experiments the general methodology for
calculation of similarity detailed in this section
was employed.
For tokens of the pitch accent types L?H, H?L
and H?, each token was modelled using the full
set of PaIntE parameters. Thus, each token was
represented in terms of a 6-dimensional vector.
For each of the pitch accent types the following
steps were carried out:
? For each 6-dimensional pitch accent category
token calculate the z-score value for each di-
mension. The z-score value represents the
number of standard deviations the value is
away from the mean value for that dimension
and allows comparison of values from differ-
ent normal distributions. The z-score is given
by:
z ? scoredim =
valuedim ?meandim
sdevdim
(1)
Hence, at this point each pitch accent is repre-
sented by a 6-dimensional vector where each
dimension value is a z-score.
? For each token z-scored vector calculate how
similar it is to every other z-scored vector
within the same pitch accent category, and,
in Experiment 2 and 3, with the same infor-
mation status value (e.g. new), using the co-
sine of the angle between the vectors. This is
given by:
cos(~i,~j) =
~i ?~j
?~i ?? ~j ?
(2)
where i and j are vectors of the same pitch ac-
cent category and ? represents the dot prod-
uct.
Each comparison between vectors yields a
similarity score in the range [-1,1], where -1
represents high dissimilarity and 1 represents
high similarity.
The experiments that follow examine distribu-
tions of token similarity. In order to establish
whether distributions differ significantly two dif-
ferent levels of significance were employed, de-
pending on the number of pairwise comparisons
performed.
When comparing two distributions (i.e. per-
forming one test), the significance level was set to
? = 0.05. In those cases where multiple tests were
carried out (Experiment 1 and Experiment 3), the
level of significance was adjusted (Bonferroni cor-
rection) according to the following formula:
? = 1? (1? ?1)
1
n (3)
where ?1 represents the target significance level
(set to 0.05) and n represents the number of tests
being performed. The Bonferroni correction is of-
ten discussed controversially. The main criticism
concerns the increased likelihood of type II errors
that lead to non-significance of actually significant
findings (Pernegger, 1998). Although this conser-
vative adjustment was applied, the statistical tests
in this study resulted in significant p-values indi-
cating the robustness of the findings.
7 Experiment 1: Examining frequency of
occurrence effects in pitch accents
In accordance with the general methodology set
out in section 6, the PaIntE vectors of pitch ac-
cent tokens of types L?H, H?L, and H? were all
z-scored and, within each type, every token was
compared for similarity against every other token
of the same type, using the cosine of the angle be-
tween their vectors. In essence, this experiment
illustrates how similarly pitch accents of the same
type are realised.
Figure 1 depicts the results of the analysis. It
shows the density plot for each distribution of
cosine-similarity comparison values, whereby the
731
?1.0 ?0.5 0.0 0.5 1.0
0.0
0.2
0.4
0.6
0.8
Frequency of Occurrence Effects in Pitch Accents
Cosine?Similarity Comparison Values
Den
sity
H*LL*HH*
Figure 1: Density plots for similarity within pitch ac-
cent types. All distributions differ significantly from each
other. There is a trend towards greater similarity from high-
frequency L?H to low-frequency H?.
distributions can be compared directly ? irrespec-
tive of the different number of data points.
An initial observation is that L?H tokens tend
to be realised fairly variably, the main portion
of the distribution is centred around zero. To-
kens of H?L tend to be produced more simi-
larly (i.e. the distribution is centred around a
higher similarity value), and tokens of H? more
similarly again. These three distributions were
tested against each other for significance using the
Kolmogorov-Smirnov test (? = 0.017), yielding
p-values of p  0.001. Thus there are significant
differences between these distributions.
What is particularly noteworthy is that a de-
crease in frequency of occurrence across pitch ac-
cent types co-occurs significantly with an increase
in within-type token similarity.
While the differences between the graphed dis-
tributions do not appear to be highly marked
the frequency of occurrence effect is nevertheless
in keeping with exemplar-theoretic expectations
as posited by Bybee (2006) and Schweitzer and
Mo?bius (2004), that is, the high frequency of oc-
currence entails a large number of stored exem-
plars, giving the speaker the choice from among
a large number of production targets. This wider
choice leads to a broader range of chosen targets
for different productions and thus to more variable
realisations of tokens of the same type.
?1.0 ?0.5 0.0 0.5 1.0
0.0
0.2
0.4
0.6
0.8
1.0
H*L: Frequency of Occurrence Effects 
  in Information Status Categories
Cosine?Similarity Comparison Values
Den
sity
givennew
Figure 2: Density plots for similarity of H?L tokens. To-
kens of the low-frequency information status category given
display greater similarity to each other than those of the high-
frequency information status category new.
Walsh et al (2008) also reported significant
differences between these distributions, however,
there did not appear to be a clear frequency of oc-
currence effect. The results in the present study
differ from their results because the distributions
centre around different ranges of the similarity
scale clearly indicating that each accent type be-
haves differently in terms of similarity/variability
between the tokens of the respective type. The dif-
ferences between the two findings can be ascribed
to the augmented PaIntE model (section 4).
Given the results from this experiment, the next
experiment seeks to establish what relationship, if
any, exists between information status and pitch
accent production variability.
8 Experiment 2: Examining frequency of
occurrence effects in information
status categories
This experiment was carried out in the same man-
ner as Experiment 1 above with the exception that
in this experiment a subset of the corpus was em-
ployed: only syllables that were unambiguously
labelled with either the information status cate-
gory new or the category given were included in
the analyses. The experiment aims to investigate
the effect of information status on the similar-
ity/variability of tokens of different pitch accent
types. For each pitch accent type, tokens that were
labelled with the information status category new
732
?1.0 ?0.5 0.0 0.5 1.0
0.0
0.2
0.4
0.6
0.8
L*H: Frequency of Occurrence Effects 
  in Information Status Categories
Cosine?Similarity Comparison Values
Den
sity
givennew
Figure 3: Density plots for similarity of L?H tokens. The
curves differ significantly, a trend towards greater similarity
is not observable. The number of tokens for both information
status categories is comparable.
were compared to tokens labelled as given. Again,
a pairwise Kolmogorov-Smirnov test was applied
for each comparison (? = 0.05). Figure 2 depicts
the results for H?L accents. The K-S test yielded a
highly significant difference between the two dis-
tributions (p  0.001), reflecting the clearly visi-
ble difference between the two curves. It is note-
worthy here that for H?L the information status
category new is more frequent than the category
given. Indeed, approximately twice as many are
labelled as new than those labelled given. Figure 2
illustrates that new H?L accents are realised more
variably than given ones. That is, again, an in-
crease in frequency of occurrence co-occurs with
an increase in similarity, this time at the level of
information status.
Figure 3 depicts the difference in similar-
ity/variability for L?H between new tokens and
given tokens. It is clearly visible that the two
curves do not differ as much as those under the
H?L condition. Both curves centre around zero re-
flecting the fact that for both types the tokens are
variable. Although the Kolmogorov-Smirnov test
indicates significance (? = 0.05, p = 0.044), the
nature of the impact that information status has in
this case is unclear.
Here again an effect of frequency of occurrence
might be the reason for this result. The high fre-
quency of L?H accents in general results in a rel-
ative high frequency of given L?H tokens. So the
?1.0 ?0.5 0.0 0.5 1.0
0.0
0.2
0.4
0.6
0.8
Effect of Information Status Category "new" 
 across Pitch Accent Types
Cosine?Similarity Comparison Values
Den
sity
H*LL*HH*
Figure 4: Density plots for similarity of new tokens across
three pitch accent types. In comparison to fig. 1 the trend
towards greater similarity from high-frequency L?H to low-
frequency H? is even more pronounced.
token number for both types is similar (102 new
L?H tokens vs. 114 given L?H tokens), there is
high frequency in both cases, hence variability.
These results, particularly in the case of H?L
(fig. 2) indicate that information status affects
pitch accent realisation. The next experiment
compares the effect across different pitch accent
types.
9 Experiment 3: Examining the effect of
information status across pitch accent
types
This experiment was carried out in the same man-
ner as Experiments 1 and 2 above. For each pitch
accent type, figure 4 depicts within-type pitch ac-
cent similarity for tokens unambiguously labelled
as new.
As with Experiments 1 and 2, frequency of
occurrence once more appears to play a signifi-
cant role. Again, all Kolmogorov-Smirnov tests
yielded significant results (p < 0.017 in all cases).
Indeed, the difference between the distributions
of L?H, H?L, and H? similarity plots appears to
be considerably more prominent than in Experi-
ment 1 (see fig. 1). This indicates that under the
condition of novelty the frequency of occurrence
effect is more pronounced. In other words, there is
a considerably more noticeable difference across
the distributions of L?H, H?L and H?, when nov-
733
?1.0 ?0.5 0.0 0.5 1.0
0.0
0.2
0.4
0.6
0.8
1.0
1.2
Effect of Information Status Category "given" 
 across Pitch Accent Types
Cosine?Similarity Comparison Values
Den
sity
H*LL*HH*
Figure 5: Density plots for similarity of given tokens across
three pitch accent types. Mid-frequency H?L displays greater
similarity than high-frequency L?H. For lowest frequency H?
(only 10 tokens) the trend cannot be observed.
elty is considered: novelty compounds the fre-
quency of occurrence effect.
Figure 5 illustrates results of the same analysis
methodology but applied to tokens of pitch accents
unambiguously labelled as given. Once again
there is a considerable difference between the dis-
tributions of L?H and H?L tokens (p < 0.017).
And again, this difference reflects a more pro-
nounced frequency of occurrence effect for given
tokens than for all accents pooled (as described
in Experiment 1): the information status category
given compounds the frequency of occurrence ef-
fect for L?H and H?L.
For H? the result is not as clear as for the two
more frequent accents. The comparison between
H? and L?H results in a significant difference
(p < 0.017) whereas the comparison between H?
and H?L is slightly above the conservative signif-
icance level (p = 0.0186). Moreover, the dis-
tribution is centred between the distributions for
L?H and H?L and it is thus not clear how to inter-
pret this result with respect to a possible frequency
of occurrence effect. However, having only ten
instances of given H?, the explanatory power of
these comparisons is questionable.
10 Discussion
The experiments discussed above yield a num-
ber of interesting results with implications for re-
search in prosody, information status, the interac-
tion between the two domains, and for exemplar
theory.
Returning to the first question posed at the out-
set in section 1, it is quite clear from Experiment 1
that a certain amount of variability exists when
different tokens of the same pitch accent type are
produced. It is also clear, from the same experi-
ment, that the frequency of occurrence of the pitch
accent type does indeed play a role: with an in-
crease in frequency comes an increase in vari-
ability. This result is in line with the exemplar-
theoretic view that since all exemplars are stored,
exemplars of a type that occur often are more vari-
able because they offer the speaker a wider se-
lection of exemplars to choose from during pro-
duction (Schweitzer and Mo?bius, 2004). How-
ever, with respect to entrenchment (Pierrehum-
bert, 2001; Bybee, 2006), i.e. the idea that fre-
quently occurring behaviours undergo processes
of entrenchment, in Experiment 1 one might ex-
pect to see greater similarity in the realisations of
L?H. However, it is important to note that while
tokens of L?H are not particularly similar to each
other (the bulk of the distribution is around zero
(see figure 1)), they are not too dissimilar either.
That is, they rest at the midpoint of the similar-
ity continuum produced by cosine calculation, in
quite a normal looking distribution. This is not
at odds with the idea of entrenchment. As pro-
ductions of a pitch accent type become more fre-
quent, the distribution of similarity spreads from
the right side of the graph (where infrequent and
highly similar H? tokens lie) leftwards (through
H?L) to the point where the L?H distribution is
found. Beyond this point tokens are excessively
different.
The second question posed in section 1, and ad-
dressed in Experiment 2, sought to ascertain the
impact, if any, information status has on pitch ac-
cent realisation. Distributions of given and new
H?L similarity scores differed significantly, as
did distributions of given and new L?H similar-
ity scores, indicating that information status af-
fects realisation. In other words, for both pitch
accent types, given and new tokens behave dif-
ferently. Concerning the frequency of occurrence
of the information status categories, certainly in
the case of H?L the higher frequency new tokens
exhibited more variability. In the case of L?H
similar numbers of new and given tokens, possi-
bly due to the high frequency of L?H in general,
734
?1.0 ?0.5 0.0 0.5 1.0
0.0
0.2
0.4
0.6
0.8
1.0
Combined Frequency of Occurrence Effect 
 on L*H and H*L
Cosine?Similarity Comparison Values
Den
sity
given L*H new L*Hnew H*Lgiven H*L
Figure 6: Density plots for similarity of combinations of
information status categories given and new with pitch ac-
cent types L?H and H?L. The distributions show a clear
trend towards greater similarity form high-frequency ?given
L?H? and ?new L?H? to mid-frequency ?new H?L? and
low-frequency ?given H?L?.
led to visually similar yet significantly different
distributions. Once again sensitivity to frequency
of occurrence seems to be present, in line with
exemplar-theoretic predictions.
The final question concerns the possibility of a
combined effect of pitch accent frequency of oc-
currence and information status frequency of oc-
currence. Figures 4 and 5 depict a clear com-
pounding effect of both information status cate-
gories across the different pitch accent types (and
their inherent frequencies) when compared to fig-
ure 1. Interestingly, the less frequently occurring
given appears to have a greater impact, particularly
on high frequency L?H.
Figure 6 displays all possible combinations of
L?H, H?L, given and new. H? is omitted in this
graph because of the small number of tokens (10
given, 21 new) and the resulting lack of explana-
tory power. It is evident that an overall frequency
of occurrence effect can be observed: ?given L?H?
and ?new L?H?, which have a similar number of
instances (114 vs. 102 tokens) both centre around
zero and are thus the most leftward skewed curves
in the graph. The distribution of ?new H?L? (87
tokens) shows a trend towards the right hand side
of the graph and thus represents greater similarity
of the tokens. The distribution of similarity values
for the least frequent combination of pitch accent
and information status, ?given H?L? (44 tokens),
centres between 0.5 and 1.0 and is thus the most
rightward curve in the graph, reflecting the high-
est similarity between the tokens.
These results highlight an intricate relationship
between pitch accent production and information
status. The information status of the word influ-
ences not only the type and shape of the pitch ac-
cent (Pierrehumbert and Hirschberg, 1990; Bau-
mann, 2006; Ku?gler and Fe?ry, 2008; Schweitzer et
al., 2008) but also the similarity of tokens within a
pitch accent type. Moreover, this effect is well ex-
plainable within the framework of Exemplar The-
ory as it is subject to frequency of occurrence:
tokens of rare types are produced more similar to
each other than tokens of frequent types.
In the context of speech technology, unfortu-
nately the high variability in highly frequent pitch
accents has a negative consequence, as the correla-
tion between a certain pitch accent or a certain in-
formation status category and the F0 contour is not
a one-to-one relationship. However, forewarned
is forearmed and perhaps a finer grained contex-
tual analysis might yield more context specific so-
lutions.
11 Future Work
The methodology outlined in section 6 gives a lu-
cid insight into the levels of similarity found in
pitch accent realisations. Further insights, how-
ever, could be gleaned from a fine-grained exam-
ination of the PaIntE parameters. For example,
which parameters differ and under what conditions
when examining highly variable tokens? Informa-
tion status evidently plays a role in pitch accent
production but the contexts in which this takes
place have yet to be examined. In addition, the
role of information structure (focus-background,
contrast) also needs to be investigated. A further
line of research worth pursuing concerns the im-
pact of information status on the temporal struc-
ture of spoken utterances and possible compound-
ing with frequency of occurrence effects.
References
Kirsten Abbot-Smith and Michael Tomasello. 2006.
Exemplar-learning and schematization in a usage-
based account of syntactic acquisition. The Linguis-
tic Review, 23(3):275?290.
Ellen G. Bard and M. P. Aylett. 1999. The dissocia-
tion of deaccenting, givenness, and syntactic role in
735
spontaneous speech. In Proceedings of ICPhS (San
Francisco), volume 3, pages 1753?1756.
Stefan Baumann. 2006. The Intonation of Givenness
? Evidence from German., volume 508 of Linguis-
tische Arbeiten. Niemeyer, Tu?bingen. Ph.D. thesis,
Saarland University.
Gillian Brown. 1983. Prosodic structure and the
given/new distinction. In Anne Cutler and D. Robert
Ladd, editors, Prosody: Models and Measurements,
pages 67?77. Springer, New York.
Joan Bybee. 2006. From usage to grammar: The
mind?s response to repetition. Language, 84:529?
551.
Karen Croot and Kathleen Rastle. 2004. Is there
a syllabary containing stored articulatory plans for
speech production in English? In Proceedings of the
10th Australian International Conference on Speech
Science and Technology (Sydney), pages 376?381.
Michael A. K. Halliday. 1967. Intonation and Gram-
mar in British English. Mouton, The Hague.
Keith Johnson. 1997. Speech perception without
speaker normalization: An exemplar model. In
K. Johnson and J. W. Mullennix, editors, Talker
Variability in Speech Processing, pages 145?165.
Academic Press, San Diego.
Klaus J. Kohler. 1991. Studies in german intonation.
AIPUK (Univ. Kiel), 25.
Frank Ku?gler and Caroline Fe?ry. 2008. Pitch accent
scaling on given, new and focused constituents in
german. Journal of Phonetics.
Erwin Marsi, Martin Reynaert, Antal van den Bosch,
Walter Daelemans, and Ve?ronique Hoste. 2003.
Learning to predict pitch accents and prosodic
boundaries in dutch. In Proceedings of the ACL-
2003 Conference (Sapporo, Japan), pages 489?496.
Jo?rg Mayer. 1995. Transcribing German In-
tonation ? The Stuttgart System. Technical
report, Universita?t Stuttgart. http://www.ims.uni-
stuttgart.de/phonetik/joerg/labman/STGTsystem.html.
Gregor Mo?hler and Alistair Conkie. 1998. Paramet-
ric modeling of intonation using vector quantization.
In Third Intern. Workshop on Speech Synth (Jenolan
Caves), pages 311?316.
Gregor Mo?hler. 1998. Describing intonation with a
parametric model. In Proceedings ICSLP, volume 7,
pages 2851?2854.
T. V. Pernegger. 1998. What?s wrong with Bonferroni
adjustment. British Medical Journal, 316:1236?
1238.
Janet Pierrehumbert and Julia Hirschberg. 1990. The
meaning of intonational contours in the interpreta-
tion of discourse. In P. R. Cohen, J. Morgan, and
M. E. Pollack, editors, Intentions in Communication,
pages 271?311. MIT Press, Cambridge.
Janet Pierrehumbert. 2001. Exemplar dynamics: Word
frequency, lenition and contrast. In Joan Bybee and
Paul Hopper, editors, Frequency and the Emergence
of Linguistic Structure, pages 137?157. Amsterdam.
Ellen F. Prince. 1992. The ZPG Letter: Subjects, Def-
initeness and Information Status. In W. C. Mann
and S. A. Thompson, editors, Discourse Descrip-
tion: Diverse Linguistic Analyses of a Fund-Raising
Text, pages 295?325. Amsterdam.
Stefan Rapp. 1998. Automatisierte Erstellung von Ko-
rpora fu?r die Prosodieforschung. Ph.D. thesis, IMS,
Universita?t Stuttgart. AIMS 4 (1).
Arndt Riester. 2008. A Semantic Explication of In-
formation Status and the Underspecification of the
Recipients? Knowledge. In Atle Gr?nn, editor, Pro-
ceedings of Sinn und Bedeutung 12, Oslo.
Antje Schweitzer and Bernd Mo?bius. 2004. Exemplar-
based production of prosody: Evidence from seg-
ment and syllable durations. In Speech Prosody
2004 (Nara, Japan), pages 459?462.
Katrin Schweitzer, Arndt Riester, Hans Kamp, and
Grzegorz Dogil. 2008. Phonological and acoustic
specification of information status - a semantic and
phonetic analysis. Poster at ?Experimental and The-
oretical Advances in Prosody?, Cornell University.
Kim Silverman, Mary Backman, John Pitrelli, Mari
Ostendorf, Colin Wightman, Patti Price, Janet Pier-
rehumbert, and Julia Hirschberg. 1992. Tobi: A
standard for Labeling English Prosody. In Proceed-
ings of ICSLP (Banff, Kanada), volume 2, pages
867?870, Banff, Canada.
Jacques Terken and Julia Hirschberg. 1994. Deaccen-
tuation of words representing ?given? information:
effects of persistence of grammatical function and
surface position. Language and Speech, 37:125?
145.
Jan P. H. van Santen and BerndMo?bius. 2000. A quan-
titative model of F0 generation and alignment. In
A. Botinis, editor, Intonation?Analysis, Modelling
and Technology, pages 269?288. Kluwer.
Michael Walsh, Hinrich Schu?tze, Bernd Mo?bius, and
Antje Schweitzer. 2007. An exemplar-theoretic ac-
count of syllable frequency effects. In Proceedings
of ICPhS (Saarbru?cken), pages 481?484.
Michael Walsh, Katrin Schweitzer, Bernd Mo?bius, and
Hinrich Schu?tze. 2008. Examining pitch-accent
variability from an exemplar-theoretic perspective.
In Proceedings of Interspeech 2008 (Brisbane).
Sandra P. Whiteside and Rosemary A. Varley. 1998.
Dual-route phonetic encoding: Some acoustic evi-
dence. In Proceedings of ICSLP (Sydney), volume 7,
pages 3155?3158.
George Yule. 1980. Intonation and Givenness in Spo-
ken Discourse. Studies in Language, pages 271?
286.
736
XiSTS ? XML in Speech Technology Systems 
 
Michael Walsh Stephen Wilson Julie Carson-Berndsen 
Department of Computer Science 
University College Dublin 
Ireland 
{michael.j.walsh, stephen.m.wilson, julie.berndsen}@ucd.ie 
 
Abstract: This paper describes the use of XML in three generic interacting speech technology 
systems.  The first, a phonological syllable recognition system, generates feature-based finite-state 
automaton representations of phonotactic constraints in XML. It employs axioms of event logic to 
interpret multilinear representations of speech utterances and outputs candidate syllables to the second 
system, an XML syllable lexicon. This system enables users to generate their own lexicons and its default 
lexicon is used to accept or reject the candidate syllables output by the speech recognition system. 
Furthermore its XML representation facilitates its use by the third system which generates additional 
lexicons, based on different feature sets, by means of a transduction process. The applicability of these 
alternative feature sets in the generation of synthetic speech can then be tested using these new lexicons. 
 
 
1. Introduction 
 
The flexibility and portability provided by 
XML, and its related technologies, result in 
them being well suited to the development 
of robust, generic, Natural Language 
Processing applications. In this paper we 
describe the use of XML within the context 
of speech technology software, with a 
particular focus on speech recognition. We 
present a framework, based on the model of 
Time Map Phonology (Carson-Berndsen, 
1998), for the development  and testing of 
phonological well- formedness constraints 
for generic speech technology applications. 
Furthermore, we illustrate how the use of a 
syllable lexicon, specified in terms of 
phonological features, and marked-up in 
XML, contributes to both speech recognition 
and synthesis. In the following sections 
three inter-connected systems are discussed. 
The first, the Language Independent 
Phonotactic System, LIPS, a syllable 
recognition application based on Time Map 
Phonology and a significant departure from 
current ASR technology, is described. The 
second system, Realising Enforced Feature-
based Lexical Entries in XML, REFLEX, is 
outlined and finally, the third system, 
Transducing Recognised Entities via XML, 
T-REX, is discussed. All three systems build 
on earlier work on generic speech tools 
(Carson-Berndsen, 1999; Carson-Berndsen 
& Walsh, 2000a). 
 
2. The Time Map Model  
 
This paper focuses on representing speech 
utterances in terms of non-segmental 
phonology, such as autosegmental 
phonology (Goldsmith, 1990), where 
utterances are represented in terms of tiers 
of autonomous features (autosegments) 
which can spread across a number of 
sounds. The advantage of this approach is 
that coarticulation can be modelled by 
allowing features to overlap. The Time Map 
model (Carson-Berndsen, 1998, 2000) 
builds on this autosegmental approach by 
allowing multilinear representations of 
autonomous features to be interpreted by an 
event-based computational linguistic model 
  
of phonology. The Time Map model 
employs a phonotactic automaton (finite-
state representation of the permissible 
combinations of sounds in a language), and 
axioms of event logic, to interpret 
multilinear feature representations. Indeed, 
much recent research (e.g. Ali et al, 1999; 
Chang, Greenberg & Wester, 2001) has 
focused on extracting  similar features to 
those used in our model. Figure 1 below, 
illustrates a mulitlinear feature-based 
representation of the syllable [So:n] 1. 
 
Figure 1. Multilinear representation of [So:n] 
 
Two temporal domains are distinguished by 
the Time Map model. The first, absolute 
(signal) time, considers features as events 
with temporal endpoints. The second, 
relative time, considers only the temporal 
relations of overlap and precedence as 
salient. Input to the model is in absolute 
time. Parsing, however, is performed in the 
relative time domain using only the overlap 
and precedence relations, and is guided by 
the phonotactic automaton which imposes 
top-down constraints on the relations that 
can occur in a particular language. The 
construction of the phonotactic automaton 
and the actual parsing process is carried out 
by LIPS. 
 
3. LIPS 
 
LIPS is the generic framework for the Time 
Map model. It incorporates finite-state 
                                                 
1All phonemes are specified in  SAMPA notation. 
methodology which enables users to 
construct their own phonotactic automata for 
any language by means of a graphical user 
interface. Furthermore, LIPS employs an 
event logic, enabling it to map from absolute 
time to relative time, and in a novel 
approach to ASR, carry out parsing on the 
phonological feature level. The system is 
comprised of two principal components, the 
network generator and the parser, outlined in 
the following subsections. 
 
3.1. The Network Generator 
 
The network generator interface allows 
users to build their own phonotactic 
automata. Users input node values and select 
from a list of feature overlap relations those 
that a given arc is to represent. These 
relations can be selected from a default list 
of IPA-like features or the user can specify 
their own set. In this way LIPS is feature-set 
independent. The network generator 
constructs feature-based networks and 
parsing takes place at the feature level. Once 
the user has completed the network 
specification, the system generates an XML 
representation of the phonotactic automaton. 
An automaton representing a small 
subsection of the phonotactics of English is 
illustrated in Figure 2. It is clear from this 
automaton that English permits an [S] 
followed by a [r] in syllable-initial position, 
but not the other way around. 
  
 
Figure 2. Phonotactic automaton  
  
 
 
Figure 3. XML representation of subsection of phonotactic automaton for English. 
 
Figure 3 illustrates a subsection of the XML 
representation of the English phonotactics 
output by the network generator. A single 
arc with a single phoneme, [S], and its 
overlap constraints, is shown.  
The motivation for generating an XML 
representation for our phonotactic  automata 
is that XML enables us to specify a well-
defined, easy to interpret, portable template, 
without compromising the generic nature of 
the network generator. That is to say the 
user can still specify a phonotactic 
automaton independent of any language or 
feature-set. The generated phonotactic 
automaton is then used to guide the second 
principal component of the system, the 
parser. 
3.2 The Parser 
 
LIPS employs a top-down and breadth-first 
parsing strategy and is best explained 
through exemplification. 
 
Purely for the purposes of describing how 
the parsing procedure takes place, we return 
to the phonotactic automaton of Figure 2, 
which of course represents only a very small 
subsection of English. This automaton will 
recognise such syllables as shum, shim, 
shem, shown, shrun, shran etc., some being 
actual lexicalised syllables of English and 
others being phonotactically well- formed, 
potential, syllables of English. For our 
example we take the multilinear 
  
representation of the utterance [So:n] as 
depicted in Figure 4 as our input to the 
parser. 
 
 
 
Figure 4. Interaction between the input and the 
automaton. 
 
At the beginning of the parsing process the 
phonotactic automaton is anticipating a [S] 
sound, that is it requires three temporal 
overlap constraints to be satisfied, the 
feature voiceless must overlap the feature 
fricative,  the feature palato  must overlap 
the feature voiceless, and the feature 
fricative must overlap the feature palato. A 
variable window is applied over the input 
utterance and the features within the window 
are examined to see if they satisfy the 
overlap constraints. As can be seen from 
Figure 4 the three features are indeed 
present and all overlap in time. Thus the [S] 
is recognised and the two arcs bearing the 
[S] symbol are traversed and the window 
moves on. At this point then the automaton 
is anticipating either an [r] or a vowel sound. 
In a similar fashion the contents of the new 
window are examined and in the case of our 
example the vowel [o:] is recognised (the [r]  
is rejected). The vowel transition is 
traversed, the window moves on, and the 
automaton is expecting an [n] or an [m]. For 
full details of the parsing process see 
Carson-Berndsen & Walsh (2000b). Output 
from LIPS is then fed through the REFLEX 
system to determine if actual or potential 
syllables have been found. 
 
4. REFLEX 
 
REFLEX is a generic, language independent 
application, which allows for the rapid 
design and construction of syllable lexicons, 
for any language. One of the main focuses 
of other research working on broadening the 
scope of the lexicon across languages, has  
been in the development of multilingual 
lexicons. One such project, PolyLex (Cahill 
& Gazdar, 1999), captures commonalities 
across related languages using hierarchical 
inheritance mechanisms. One of the main 
concerns of the work presented here 
however, is to provide generic, reusable, 
tools which facilitate the development and 
testing of phonological systems, rather than 
the creation of such multilingual lexicons. 
 
Work on phonological features and lexical 
description has either been within this 
multilingual context (Tiberius & Evans, 
2000) or has concentrated on using a 
feature-based lexicon for comparison with 
features extracted from a sound signal 
(Reetz, 2000). By removing reference to 
specific languages and concentrating on 
providing mechanisms for lexical 
generation, REFLEX can generate a syllable 
lexicon for any language that can be 
adequately represented in a phonetic 
notation. 
 
Furthermore, the decision to use XML to 
represent the output data means that it is 
readily available for use and manipulation 
by other outside systems with minimal 
effort. All background processing is 
completely hidden; one deals only with the 
marked-up output, from which idiosyncratic 
user-required structures can be rapidly 
generated.  
  
The REFLEX system outputs a feature-
based syllable lexicon. This lexicon is a 
valid XML document, meaning that it 
conforms to the given REFLEX Document 
Type Definition (DTD). The DTD stipulates 
the structure, order and number of XML 
element tags and attributes, modelling all 
potential syllable structures (e.g. V, CV, 
CVC etc). 
 
An example of a typical lexical entry, in this 
case corresponding to the multilinear 
representation specified in Figure 5, [So:n] 
is given below. 
 
 
Figure 5. Typical lexical entry in XML 
 
The syllable element shown has four 
children, described as follows: 
 
1) A text child, in this case So:n, the 
SAMPA representation of the entire 
syllable. 2) An <onset> element whose 
attribute list denotes its position within the 
syllable, i.e.<onset type=?first?>, <onset 
type=?second?> etc. 3) Nucleus and 4) 
coda elements are similarly defined. 
 
 Each of the syllable?s elements, <onset>, 
<nucleus> and <coda>, may have only one 
child element, <segment>, which tags the 
given phoneme. Its attribute list describes 
the phonemes specification in terms of 
phonological features.  It also has a duration 
attribute, which is derived from corpus 
analysis. 
 
<segment phonation=?voiced? 
   manner=?nasal? place=?apical?  
  duration=?null?>n</segment> 
 
REFLEX provides two methods by which  
syllables can be added to the lexicon. The 
first, requires users to specify an input file of 
monosyllables represented in a phonetic 
notation, in this case SAMPA.  The second, 
enables the user to specify syllables, in 
terms of phonemes, position, and if desired, 
a typical duration, by means of a GUI 
illustrated below in Figure 6. 
  
 
 
 
Figure 6. REFLEX lexicographer interface 
 
Regardless of the input option chosen, new 
entries are added to the lexicon via a 
background process.  REFLEX makes use of 
DATR, a non-monotonic inheritance based 
lexical representation language (Evans & 
Gazdar, 1996) to carry out this process. 
DATR is used to quickly and 
comprehensively define the phonological 
feature descriptions for a given language. 
For a greater understanding of how this can 
be achieved see Cahill, Carson-Berndsen & 
Gazdar (2000). Using DATR?s inference 
mechanisms, REFLEX manipulates the 
output into a valid XML document, creating 
a sophisticated phonological feature-based 
lexicon, shown in Figure 5. 
  
All syllable elements are enclosed within the 
root <lexicon> tag, whose sole attribute 
specifies the lexicon?s language. 
 
        <lexicon language=?English?> 
                  <syllable>?</syllable> 
                        :  
                   <syllable>?</syllable> 
        </lexicon>                    
 
The REFLEX lexicon is a versatile tool that 
has a number of potential applications 
within the domain of speech technology 
systems. The following sub-sections 
illustrate how this syllable lexicon, by virtue 
of its being marked up in XML, can 
contribute to both speech recognition and 
synthesis. 
 
4.1 LIPS and REFLEX 
 
By allowing feature overlap constraints to be 
relaxed in the case of underspecified input, 
LIPS can produce a number of candidate 
syllables.  In Figure 4 above, at the final 
transition, the automaton is expecting either 
an [m] or an [n]. The input, however, is  
underspecified, no feature distinguishing 
between [m] or [n], or indeed any voiced 
nasal, is present. By allowing the overlap 
constraints for the [m]  and the [n] to be 
relaxed, LIPS can consider both [So:n] and 
[So:m] to be candidate syllables for the 
utterance. Both candidate syllables are well-
formed, adhering to the phonotactics of 
English, however only one, [So:n], is an 
actual syllable of English. Thus at this point 
a lexicon providing good coverage of the 
language should reject [So:m] and accept 
[So:n]. In order to achieve this, REFLEX 
makes use of the XPath specification (a 
means for locating nodes in an XML 
document) and formulates a query before 
applying it to the syllable lexicon. 2 In the 
                                                 
2 The full W3C XPath specification can be found at 
http://www.w3c.org/TR/xpath 
example given, REFLEX searches the 
document, checking the value of the text 
child of each syllable element, against each 
candidate syllable output by LIPS. Any 
successful matches returned are therefore 
not only well- formed, but are deemed to be 
actual syllables. Thus at this point, the 
lexicon is searched and the syllable [So:n] is 
recognised. The granularity of the REFLEX 
search capability is such, that it can be 
extended to the feature level. Users can 
search the lexicon for syllables that contain 
a number of specific features in certain 
positions, e.g. search for syllables that 
contain a voiced, labial, plosive in the first 
onset. Again, REFLEX forms an XPath 
expression and queries the lexicon, returning 
all matches.  REFLEX also functions as a 
knowledge source for the T-REX system. 
This system is responsible for mapping 
output from the lexicon into syllable 
representations using different feature sets, 
e.g. features from other phonologies, and is 
discussed below in the context of speech 
synthesis.  
 
5. T-REX 
 
The role of this module is to enable 
lexicographers and speech scientists etc. to 
generate, via a transduction process,  
syllable lexicons based on different  
phonological feature sets. The default 
feature set employed by REFLEX is based 
on IPA-like features. However, T-REX 
provides a GUI that permits lexicographers 
to define phoneme to feature attribute 
mappings. Given this functionality T-REX 
operates as a testbed for investigating the 
merits of different feature sets in the context 
of speech synthesis. Different lexicons are 
generated by associating new feature sets 
with the same phonetic alphabet (SAMPA) 
via a GUI. The new lexicon is then 
transduced by T-REX which maps all 
syllable entries from the default lexicon 
(with IPA-like features) to the new lexicon,  
  
applying the features input by the user, to 
their associated phonemes. In order to 
exemplify this we return to our sample 
syllable, [So:n]. Figure 2 above shows the 
lexical representation, using IPA-like 
features, for [So:n]. Figure 7 below shows 
new features being associated with the 
phoneme [S].  
 
 
 
Figure 7. GUI for T-REX 
 
Similarly, new features are associated with 
the remaining phonemes, [o:]  and [n], and 
indeed the rest of the SAMPA alphabet. On 
completion the user initiates the transduction 
process and a new lexicon is produced. The 
XML representation of the phoneme [S], in 
the new lexicon, is depicted in Figure 8. 
Note how the feature attributes differ from 
those in the default lexicon.  
 
 
 
Figure 8. Phoneme with transduced features 
 
The advantages of this transduction 
capability are that numerous lexicons can be 
rapidly developed and used to investigate 
the appropriateness of specific formal 
models of phonological representation for 
the purposes of speech synthesis. 
Furthermore, the same computational 
phonological model, i.e. the Time Map 
model, can be employed. Bohan et al(2001) 
describe how the phonotactic automaton is 
used to generate a multilinear event 
representation of overlap and precedence 
constraints for an utterance, which is then  
mapped to control parameters of the HLsyn 
(Sensimetrics Corporation) synthesis engine. 
Different feature sets can be evaluated by 
assessing how they influence the various 
control parameters of the HLsyn engine and 
the quality of the synthesised speech. 
 
6. Conclusion 
 
This paper has described how the use of 
XML together with a computational 
phonological model can contribute 
significantly to the tasks of speech 
recognition, speech synthesis and lexicon 
development. Phonotactic automata and 
multilinear representations were introduced 
and the interpretation of these 
representations was discussed. Three robust, 
well-defined systems, LIPS, REFLEX, and 
T-REX, were outlined. These systems offer 
generic structures coupled with the 
portability of XML. In doing so, they enable 
users to recognise speech, synthesise speech, 
and develop lexicons for different languages 
using different feature sets while 
maintaining a common interface.  The 
generic and portable nature of these systems 
means that languages with significantly 
different phonologies are supported. In 
addition, languages which, to date, have 
received little attention with respect to 
speech technology are equally provided for.  
 
Ongoing projects include work on Irish, 
which has a notably different phonology 
from English and on developing phonotactic 
automata and phonological lexicons for 
other languages. Furthermore, the models 
are being extended to include phoneme-
  
grapheme mappings based on the contexts 
defined by the phonotactic automata.  
 
7. Bibliography 
 
Ali, A.M..A.; J. Van der Spiegel; P. Mueller; G. 
Haentjaens & J. Berman (1999): An 
Acoustic-Phonetic Feature-Based System for 
Automatic Phoneme Recognition in 
Continuous Speech. In: IEEE International 
Symposium on Circuits and Systems (ISCAS-
99), III-118-III-121, 1999. 
Bohan, A.; E. Creedon, , J. Carson-Berndsen & 
F. Cummins (2001): Application of a 
Computational Model of Phonology to 
Speech Synthesis. In: Proceedings of 
AICS2001, Maynooth, September 2001. 
Cahill, L. & G. Gazdar (1999). The PolyLex 
architecture: multilingual lexicons for 
related languages. Traitement Automatique 
des Langues, 40(2), 5-23. 
Cahill, L.; J. Carson-Berndsen & G. Gazdar 
(2000), Phonology-based Lexical 
Knowledge Representation. In: F. van Eynde 
& D. Gibbon (eds.) Lexicon Development 
for Speech and Language Processing, 
Kluwer Academic Publishers, Dordrecht. 
Carson-Berndsen, J. (1998): Time Map 
Phonology: Finite State Models and Event 
Logics in Speech Recognition. Kluwer 
Academic Publishers, Dordrecht. 
Carson-Berndsen, J. (1999): A Generic Lexicon 
Tool for Word Model Definition in 
Multimodal Applications. Proceedings of 
EUROSPEECH 99, 6th European 
Conference on Speech Communication and 
Technology, Budapest, September 1999. 
 
 
 
Carson-Berndsen, J. (2000): Finite State Models, 
Event Logics and Statistics in Speech 
Recognition, In: Gazdar, G.; K. Sparck 
Jones & R. Needham (eds.): Computers, 
Language and Speech: Integrating formal 
theories and statistical data. Philosophical 
Transactions of the Royal Society, Series A, 
358(1770), 1255-1266. 
Carson-Berndsen, J. & M. Walsh (2000a): 
Generic techniques for multilingual speech 
technology applications, Proceedings of the 
7th Conference on Automatic Natural 
Language Processing, Lausanne, 
Switzerland, 61-70. 
Carson-Berndsen, J. & M. Walsh (2000b): 
Interpreting Multilinear Representations in 
Speech. In: Proceedings of the Eight 
International Conference on Speech Science 
and Technology, Canberra, December 2000. 
Chang, S.; S. Greenberg & M. Wester (2001): 
An Elitist Approach to Articulatory-
Acoustic Feature Classification. In: 
Proceedings of Eurospeech 2001, Aalborg. 
Evans, R & G. Gazdar (1996), DATR: A 
language for lexical knowledge 
representation. In: Computational 
Linguistics 22, 2, pp. 167-216. 
Goldsmith, J. (1990): Autosegmental and 
Metrical Phonology. Basil Blackwell, 
Cambridge, MA. 
Reetz, H. (2000) Underspecified 
Phonological Features for Lexical 
Access. In: PHONUS 5, pp. 161-173. 
Saarbr?cken: Institute of Phonetics, 
University of the Saarland. 
Tiberius, C. & R. Evans, 2000 
"Phonological feature based Multilingual 
Lexical Description," Proceedings of 
TALN 2000, Geneva, Switzerland. 
 
 
