Proceedings of the 4th ACL-SIGSEM Workshop on Prepositions, pages 31?37,
Prague, Czech Republic, June 2007. c?2007 Association for Computational Linguistics
Measuring the Productivity of Determinerless PPs
Florian Do?mges, Tibor Kiss, Antje Mu?ller, Claudia Roch
Sprachwissenschaftliches Institut
Ruhr-Universita?t Bochum
florian.doemges@rub.de
tibor@linguistics.rub.de
antje.mueller@rub.de
claudia.roch@rub.de
Abstract
We determine the productivity of determin-
erless PPs in German quantitatively, restrict-
ing ourselves to the preposition unter. The
study is based on two German newspa-
per corpora, comprising some 210 million
words. The problematic construction, i.e.
unter followed by a determinerless singular
noun occurs some 16.000 times in the cor-
pus. To clarify the empirical productivity
of the construction, we apply a productivity
measure developed by Baayen (2001) to the
syntactic domain by making use of statisti-
cal models suggested in Evert (2004). We
compare two different models and suggest a
gradient descent search for parameter esti-
mation. Our results show that the combina-
tion of unter+noun must in fact be character-
ized as productive, and hence that a syntactic
treatment is required.
Kiss (2006),Kiss (2007),Li (1992), Zipf (1949)
1 Introduction
The combination of a preposition with a singular
count noun, illustrated in (1) with the preposition
unter, is a frequent construction in written and spo-
ken German. From a theoretical perspective, con-
structions like (1) are interesting since they seem
to violate the near universal rule that determiners
should accompany singular count nouns if the lan-
guage in question shows determiners at all (cf. Him-
melmann (1998)).
unter Vorbehalt (with reservation),
(1)unter Androhung (on pain),
unter Lizenz (under licence),
unter Vorwand (pretending)
Baldwin et al (2006) follow a tradition of En-
glish grammar and call constructions like (1) deter-
minerless PPs (D-PP), defined as PPs whose NP-
complement consists of a singular count noun with-
out an accompanying determiner (as e.g. English
by bus, in mind ). It has been claimed that D-PPs
are mostly idiomatic and not productive. Hence,
computational grammars often include D-PPs only
as stock phrases or listed multiword expressions and
do not offer a grammatical treatment. However, both
claims have to be doubted seriously. Kiss (2006,
2007) shows that the class of D-PPs does not con-
tain more idiomatic phrases than a typical phrasal
category should and also argues against a ?light P
hypothesis? which allows a pseudo-compositional
treatment of D-PPs by ignoring the semantics of the
preposition altogether. Trawinski (2003), Baldwin
et al (2006), as well as Trawinski et al (2006) offer
grammatical treatments of D-PPs, or at least of some
subclasses of D-PPs. Interestingly, (Baldwin et al
(2006), 175f.) take the productivity of a subclass
of D-PPs for granted and propose a lexical entry for
prepositions which select determinerless N?s as their
complement. While we are sympathetic to a syn-
tactic treatment of D-PPs in a computational gram-
mar, we think that the productivity of such construc-
tions must be considered more closely. The analysis
of Baldwin et al (2006) allows the unlimited com-
bination of prepositions meeting their lexical spec-
ification with a determinerless N projection. This
31
assumption is not in line with speaker?s intuitions
with regard to producing or judging such construc-
tions. As has been pointed out by Kiss (2006, 2007),
speakers of German can neither freely produce se-
quences consisting of unter and determinerless N
projections (typically a noun) nor can they judge
such constructions in isolation. In addition, not even
very similar nouns can be interchanged in a D-PP,
as can be witnessed by comparing near-synonyms
Voraussetzung and Pra?misse which both translate as
prerequisite, or as provided in the examples in (2).
The examples in (2) illustrate that Voraussetzung
cannot be replaced by Pra?misse in a D-PP (2a, b),
while it can be replaced as a head noun in a full
PP (2c, d). While the contrast in (2) casts doubt on
a productive analysis on the basis of the speakers
knowledge of language, the present paper will show
that unter+noun has to be classified as productive
from an empirical perspective.
a. Auch Philippe Egli besteht auf einer
(2)
eigenen Handschrift - unter
Voraussetzung des Einversta?ndnisses
des Ensembles.
b. * Auch Philippe Egli besteht auf einer
eigenen Handschrift - unter Pra?misse
des Einversta?ndnisses des Ensembles.
c. Auch Philippe Egli besteht auf einer
eigenen Handschrift - unter der
Voraussetzung des Einversta?ndnisses
des Ensembles.
d. Auch Philippe Egli besteht auf einer
eigenen Handschrift - unter der
Pra?misse des Einversta?ndnisses des
Ensembles.
?Philippe Egli insists on his individual way
of dealing with the issue, provided the
ensemble agrees.?
Our investigation is based of a corpus analysis of
D-PPs, consisting of the preposition unter and a fol-
lowing noun, and employs a quantitative measure
of productivity, first developed by Harald Baayen
to analyze morphological productivity. The pre-
liminary conclusion to be drawn from this result
will be that empirical and intuitive productivity of
unter+noun sequences do not match.
In applying Baayen?s productivity measure to
syntactic sequences, however, we are faced with
a serious problem. Baayen?s productivity measure
P (N) is based on the expectation of the hapax
legomena ? E[V1] ? occurring in a vocabulary of
size N, i.e. P (N) = E[V1]N .
 1
 10
 100
 1  10  100  1000
Cardinalities of the frequency classes
Figure 1: Cardinalities of the frequency classes. The
frequency of each type was counted, then the types
were grouped into classes of equal frequency. The
number of types in each class was counted. The fre-
quency values m are assigned to the x-axis, the size
of the class Vm to the y-axis. Both are scaled loga-
rithmically.
Since we cannot derive the expectation of the ha-
pax legomena directly from the corpus, we have to
approximate it by use of regression models. To sim-
plify matters somewhat, Baayen?s models can only
be applied to unigrams, while we have to consider
bigrams ? the preposition and the adjacent noun. To
circumvent this problem, Kiss (2006,2007) calcu-
lated P (N) on the basis of the empirical distribu-
tion of V1 as N gets larger. Evert (2004) offers re-
gression models to determine E[V1] for n-grams and
suggests two different models, the Zipf-Mandelbrot
32
model (ZM) and the finite Zipf-Mandelbrot model
(fZM). The difference between these two models
is that fZM assumes a finite vocabulary. In the
present paper, we apply Evert?s models to sequences
of unter+noun. We differ from Evert?s proposal in
estimating the free parameter ? in both models on
the basis of the gradient descent algorithm. Contrary
to Evert?s assumptions, we will show that the results
of the ZM model are much closer to the empirical
observations than the results of the fZM model.
The paper is structured as follows. Section 2 de-
scribes the empirical basis of the experiment, a cor-
pus study of unter+textnounsg sequences. Section
3 introduces the models suggested by Evert (2004).
Section 3.1 introduces the models, section 3.2 shows
how the free parameter is estimated by making use
of the gradient descent algorithm. The results are
compared in section 3.3.
2 Corpus Study
The present study is based on two German corpora,
with a total of 213 million words: the NZZ-corpus
1995-1998 (Neue Zu?rcher Zeitung) and the FRR-
corpus 1997-1999 (Frankfurter Rundschau). Mak-
ing use of the orthographic convention that nouns
are capitalized in German, we have automatically
extracted 12.993 types, amouting to some 71.000
tokens of unter and a following noun. From these
12.993 types, we have removed all candidates where
the noun is a proper noun, or realized as a plural,
or as member of a support verb construction. Also,
we have excluded typical stock phrases and all mass
nouns. The extraction process was done both man-
ually (proper nouns, mass nouns, support verb con-
structions) and automatically (plurals, mass nouns).
As a result of the extraction process, a total num-
ber of 1.103 types remained, amounting to 16.444
tokens. The frequency of every type was determined
and types with the same frequency were grouped
into classes. 65 equivalence classes were established
according to their frequency m (cf. Figure 1). The
number of elements in every class was counted and
the various count results were associated with the
variables Vm = V1, V2, . . . , V2134.
3 LNRE Model Regression
Baayen (2001) uses the term LNRE models (large
number of rare events) to describe a class of mod-
els that allow the determination of the expectation
with a small set of parameters. Evert (2004) pro-
poses two LNRE models with are based on Zipf?s
Law (Zipf(1949), Li (1992)) to identify the expec-
tations E[V1], . . . , E[Vmax]. Both models are based
on the Zipf-Mandelbrot law.
Zipf?s Law (Zipf(1949), Li (1992)) posits that the
frequency of the r-most frequent type is proportional
to 1r . The distribution of random texts displays a
strong similarity to the results expected according to
Zipf?s Law (cp. Li (1992)). Mandelbrot (1962) et
al. explain this phenomenon by Zipf?s Principle of
Least Effort.
Rouault (1978) shows that the probability of types
with a low frequency asymptotically behaves as
posited by the Zipf-Mandelbrot Law
?i =
C
(i + b)a
with a > 1 and b > 0.
The models are introduced in section 3.1. Both
require a parameter ?, whose value was determined
by employing a gradient descent algorithm imple-
mented in Perl. The optimal value for the free pa-
rameter was found by constructing an error function
to minimise ?. The calculation was carried out for
both models, but better results are produced if the
assumption is given up that the vocabulary is finite.
3.1 Finite and general Zipf-Mandelbrot models
Evert (2004) proposes the finite Zipf-Mandelbrot
model (fZM) and the general Zipf-Mandelbrot
model (ZM) for modelling the expectations of the
frequency classes Vm, i.e. E[V1], . . . , E[Vmax] and
the expected vocabulary size, i.e. the expectation
of the different types E[V ]. The two models make
different assumptions about the probability distribu-
tions of the frequency classes. The fZM assumes
that there is a minimal probability A ? defined as
?A : ?i : A ? ?i. This amounts to the assumption
that the vocabulary size itself is finite. Hence, it can
be expected according to the fZM model that the set
of observed types does not increase once N ? 1A is
reached. In the general ZM model, there is no such
minimal probability.
Assuming a fZM model, Evert (2004) proposes
the following results to estimate the expectation of
33
the frequency classes E[Vm] and the expected vo-
cabulary size E[V ]. In the following equations,
B stands for the maximum probability, defined as
?i : B ? ?i.
E[Vm] =
1 ? ?
(B1?? ?A1??) ?m! ?
N? ? ?(m? ?,N ? A) (3)
E[V ] = 1 ? ?(B1?? ?A1??) ?N
? ? ?(1 ? ?,N ?A)? +
1 ? ?
(B1?? ?A1??) ? ? ? A? ? (1 ? e
?N ?A) (4)
As can be witnessed from the formulae given, N ,
A, and B are already known or directly derivable
from our observations, leaving us with the determi-
nation of the free parameter ?.
Using the general Zipf-Mandelbrot model, we end
with the following estimations, again suggested by
Evert (2004):
E[Vm] =
1 ? ?
B1?? ?m! ?N
? ? ?(m? ?) (5)
E[V ] = 1 ? ?B1?? ?N
? ? ?(1 ? ?)? (6)
As there is no minimal probability, we are left
with the maximal probability B, the token size N,
and again a free parameter ?.
3.2 Parameter estimation through gradient
descent
Since the expectation of the frequency classes in (3)
and (5) depend on the free parameter ?, this pa-
rameter must be estimated in a way that minimises
the deviation of expected and observed values. We
measure the deviation with a function that takes into
account all observed frequencies and their expected
values. A function satisfying these criteria can be
found by treating observed frequency classes and ex-
pectations as real-valued vectors in a vector space.
OT = (V, V1, V2, . . . , V2134) ? R66 (7)
ET (?) =
(E(V )(?), E(V1)(?), . . . , E(V2134)(?)) ? R66 (8)
 1
 10
 100
 1  10  100  1000
Cardinalities of the frequency classes
Figure 2: The application of the fZM LNRE Model
combined with Rouault?s estimation method leads to
a strong deviation from the observed data. The ob-
served data is depicted as a solid line, the data from
the model as a dotted line. The frequency values m
are assigned to the x-axis, the size of the class Vm
respectively the expected size E(Vm) to the y-axis.
Both are scaled logarithmically.
A natural choice for a measure of error is the
quadratic norm of the difference vector between ob-
servation and expectation. As we have no infor-
34
mation about the relationship between different fre-
quencies we assume that the covariance matrix is the
unit matrix.
These thoughts result in the following error func-
tion:
g(?) = (E(V )(?) ? V )2+
?
m=1,...,2134
(E(Vm)(?) ? Vm)2 (9)
The minimal ? is equal to the root of the deriva-
tive of the error function with respect to ?. The
derivative of the error function is:
?g
?? = 2
?E(V )
?? (E(V )(?) ? V )+
2
?
m=1,...,2134
?E(Vm)
?? (E(Vm)(?) ? Vm) (10)
One way to find the minimum ?? =
argmin? g(?) would be to derive the expected
values with respect to ? and solve g?(??) = 0 for
?. As there is no way known to the authors to
accomplish this in a symbolic way, the use of a
numeric method to calculate ?? is advised.
We chose to find ?? by employing a gradient de-
scent method and approximating ?g?? by evaluating
g(?) in small steps ??(i) and calculating ?g(k)??(k) =
g(?0+
Pk
j=1 ??(j))?g(?0+
Pk?1
j=1 ??(j))
??(k) , where k is num-
ber of the iteration.
In the vicinity of a minimum ?g??(?) decreases un-
til it vanishes at ??.
After every iteration the new ??(k) is chosen by
taking under consideration the change of ?g(k)??(k) and
the sign of ??(k? 1). If ?g(k)??(k) increased, the sign of
??(k ? 1) is inverted: ??(k) = ???(k ? 1).
To prevent the algorithm from oscillat-
ing around the minimum the last two values
g(?0 +
?k?2
j=1 ??(j)) and g(?0 +
?k?1
j=1 ??(j)) are
saved.
When a step would result in returning to a previ-
ous value g(?0 +
?k?1
j=1 ??(j) + ??(k)) = g(?0 +
?k?2
j=1 ??(j)), the step size is multiplied by a con-
stant 0 < ? ? 1: ??(k) = ???(k ? 1). The al-
gorithm is stopped when the absolute value of the
step size drops under a predetermined threshold:
|??(k)| < ?threshold.
3.3 Results
Interestingly, ? as determined by gradient descent
on the basis of a fZM leads to a value of 0.666,
which does not match well with our observations,
as can be witnessed in Figure 2.
 1
 10
 100
 1  10  100  1000
Cardinalities of the frequency classes
Figure 3: The ZM LNRE Model leads to a far better
result with less deviation from the observation. The
observed data is depicted as a solid line, the data
from the model as a dotted line. The frequency val-
ues m are assigned to the x-axis, the size of the class
Vm respectively the expected size E(Vm) to the y-
axis. Both are scaled logarithmically.
A gradient descent search on the basis of the ZM
model delivered a value of ? = 0.515, a much better
approximation (with a ?2-Value of 4.514), as can be
35
witnessed from Figure 3. The value thus reached
also converges with the estimation procedure for ?
suggested by Rouault (1978), and taken up by Evert
(2004), i.e. ? = V1V . Consequently, we assume a
ZM model for estimating of expected frequencies.
 0
 0.05
 0.1
 0.15
 0.2
 0  0.2  0.4  0.6  0.8  1
Estimated Productivity
Observed Productivity
Figure 4: The parts of the corpus were appended
to each other and after every step the productivity
P (N) was calculated directly from the data as well
as from the fitted ZM model. The percentage of
the corpus is assigned to the x-axis, the productiv-
ity P (N) is assigned to the y-axis. The productivity
values that were deduced directly from data are plot-
ted as a dotted line, the productivity values from the
ZM model are plotted as a solid line.
To chart the productivity of sequences of the form
unter+noun, we have divided our corpus into six
smaller parts and sampled V , N , and V1 at these
parts. The distribution of the observations thus
gained can be found in Figure 4, together with the
expectations derived from the ZM model. We ob-
serve that both distributions are strikingly similar
and converge at the values for the full corpus.
N V1 E[V1] P (N)
542 74 96.66 0.182
1068 104 123.47 0.118
2151 169 166.41 0.079
4262 282 249.93 0.059
6222 384 332.19 0.054
8365 469 400.43 0.048
16444 746 748.81 0.022
Table 1: Overview of the observed and expected
numbers of hapax legomena and the associated pro-
ductivity value at different corpus sizes.
In a broader perspective, Figure 4 shows that the
combination of unter+noun is a productive process,
when its empirical distribution is considered. As
was already pointed out in section 1, this finding
is at odds with speaker?s intuitions about combina-
tions of unter+noun. Assuming that this result can
be extended to other subclasses of D-PPs, we would
suggest restricting lexical specifications for preposi-
tions to subclasses of nouns, depending on the perti-
nent preposition. Future research will have to show
whether such clear-cut subclasses can be identified
by looking more closely at the empirical findings,
other whether we are confronted with a continuum,
which would require alternative rule types.
References
Harald Baayen. 2001. Word Frequency Distributions.
Kluwer, Dordrecht.
Timothy Baldwin, John Beavers, Leonoor van der Beek,
Francis Bond, Dan Flickinger, and Ivan A. Sag. 2006.
In Search of a Systematic Treatment of Determinerless
PPs. In Patrick Saint-Dizier, editor, Syntax and Se-
mantics of Prepositions, pages 163?179. Springer.
Stefan Evert. 2004. A Simple LNRE Model for Ran-
dom Character Sequences. In Proceedings of the
7mes Journees Internationales d?Analyse Statistique
des Donnees Textuelles, pages 411?422.
Nikolaus Himmelmann. 1998. Regularity in Irregular-
ity: Article Use in Adpositional Phrases. Linguistic
Typology, 2:315?353.
Tibor Kiss. 2006. Do we need a grammar of irregular
sequences? In Miriam Butt, editor, Proceedings of
KONVENS, pages 64?70, Konstanz.
36
Tibor Kiss. 2007. Produktivita?t und Idiomatizita?t
von Pra?position-Substantiv-Sequenzen. forthcoming
in Zeitschrift fu?r Sprachwissenschaft.
W. Li. 1992. Random texts exhibit zipf?s-law-like word
frequency distribution. IEEE Transactions on Infor-
mation Theory.
B. Mandelbrot. 1962. On the theory of word frequencies
and on related Markovian models of discourse. Amer-
ican Mathematical Society.
A. Rouault. 1978. Lois de Zipf et sources markoviennes.
Annales de l?Institut H. Poincare.
Beata Trawinski, Manfred Sailer, and Jan-Philipp Soehn.
2006. Combinatorial Aspects of Collocational Prepo-
sitional Phrases. In Patrick Saint-Dizier, editor, Syn-
tax and Semantics of Prepositions, pages 181?196.
Springer.
Beata Trawinski. 2003. The Syntax of Complex Preposi-
tions in German: An HPSG Approach. In Proceedings
of GLIP, volume 5, pages 155?166.
G. K. Zipf. 1949. Human Behavior and the Principle of
Least Effort. Addison-Wesley, Campridge.
37
Coling 2010: Poster Volume, pages 561?569,
Beijing, August 2010
A Logistic Regression Model of Determiner Omission in PPs 
Tibor Kiss Katja Ke?elmeier Antje M?ller Claudia Roch Tobias Stadtfeld Jan Strunk Sprachwissenschaftliches Institut,  Ruhr-Universit?t Bochum {tibor, kesselmeier, mueller, roch, stadtfeld, strunk}@linguistics.rub.de  Abstract The realization of singular count nouns without an accompanying determiner in-side a PP (determinerless PP, bare PP, Preposition-Noun Combination) has re-cently attracted some interest in computa-tional linguistics. Yet, the relevant factors for determiner omission remain unclear, and conditions for determiner omission vary from language to language. We pre-sent a logistic regression model of deter-miner omission in German based on data obtained by applying annotation mining to a large, automatically and manually annotated corpus.  1 The problem and how to deal with it Preposition-Noun Combinations (PNCs, some-times called determinerless PPs or bare PPs) minimally consist of a preposition and a count noun in the singular that ? despite requirements formulated elsewhere in the grammar of the re-spective language ? appears without a deter-miner. The noun in a PNC can be extended through prenominal modification (1) and post-nominal complementation (2). Still, a determiner is missing. The following examples are given from German. (1) auf parlamentarische Anfrage (?after being asked in parliament?), mit beladenem Ruck-sack (?with loaded backpack?), unter sanfter Androhung (?under gentle threat?)  (2) Er wehrt sich gegen die Forderung nach  he defies REFL against the demand for  Stilllegung einer Verbrennungsanlage. closedown an  incineration plant ?He defies the demand for closing an inciner-ation plant.? 
PNCs occur in a wide range of languages (Himmelmann, 1998); the conditions for deter-miner omission, however, have not been detected yet, and conditions applying to one language do not carry over to other languages. In addition, speakers only reluctantly judge the acceptability of newly coined PNCs, so that reliance to intro-spective judgments cannot be assumed. For English, Stvan (1998) and Baldwin et al (2006) have claimed that either the semantics of the preposition or of the noun play a major role in determining whether a singular count noun may appear without a determiner in a PNC. Stvan (1998) assumes that nouns determine the well-formedness of PNCs (3) if the denotation of the noun occurs in a particular semantic field, while Baldwin et al (2006) assume that certain prepositions impose selection restrictions on their nominal complements that allow for deter-miner omission (4).  (3) from school, at school, in jail, from jail, ? (4) by train, by plane, by bus, by pogo stick, by hydro-foil ? Interestingly, Le Bruyn et al (2009) have ob-served that basic assumptions of Stvan?s analysis do not apply to Dutch, French, or Norwegian. With regard to German, we observe that neither the pattern in (3) nor in (4) is productive. Con-structions like (4) cannot be realized as PNCs in German, but require full PPs. In the following, we propose an analysis of PNCs that combines corpus annotation, annota-tion mining (Chiarcos et al, 2008), and logistic regression modeling (Harrell, 2001). Annotation mining assumes that linguistically relevant gen-eralizations can be derived in a bottom-up fash-ion from a suitably annotated corpus. Relevant hits in the corpus are mapped into a feature vec-tor that serves as input for logistic regression classification. In the present case, the input con-
561
sists of sentences containing either PNCs or PPs. Binary logistic regression suggests itself as a classification method since the problem of PNCs can be rephrased as the following question: Un-der which conditions can an otherwise obligatory determiner be omitted? The majority of required annotations can be derived automatically, but there are no available systems for the automatic determination of preposition senses in German, so preposition sense annotation has to be carried out manually and requires a language-specific tagset for prepo-sition senses. While our initial analysis is based on German data, the general methodology can be applied to other languages, provided that corpora receive proper annotation.     2 Corpus annotation 2.1 General characteristics  The present analysis is based on a newspaper corpus of the Swiss-German newspaper Neue Z?rcher Zeitung from 1993 to 1999, comprising approx. 230 million words. The annotation is based on an XML-stand-off format. MMAX2 (M?ller and Strube, 2006) is used for manual annotation. Annotations are carried out both for PNCs and for full-fledged PPs. For each prepo-sition, the following data is considered: PNCs, where N is a count noun; corresponding PPs with the same count noun; and PPs containing count nouns not appearing inside PNCs. The following annotations are provided for each dataset in the corpus: Lexical level: part-of-speech, inflectional morphology, derivational morphology of nouns, count/mass distinction of nouns, interpretation of nouns, interpretation of prepositions, noun com-pounding. Syntactic level: mode of embedding of the phrase (adjunct or complement), syntactic de-pendents of the noun, modification of the noun. Global level: Is the phrase contained in a headline, title, or quotation? Is the phrase idio-matic? Headlines, titles, and quotations are par-ticularly prone to text truncation and PNCs oc-curring here might not be the result of syntactic operations. Similarly, idiomatic PNCs and PPs might follow combination rules that differ from the general modes of combination. Hence, the 
annotations may serve to exclude these cases from general classification.  2.2 Automatic annotation  The following tools are employed for automatic annotation: Regression Forest Tagger (Schmid and Laws, 2008) for POS tagging and morpho-logical analysis (the tagger contains the SMOR component for morphological analysis, cf. Schmid, 2004), and Tree Tagger (Schmid, 1995) for chunk parsing.  To determine noun meanings, we make use of two resources. The first resource is GermaNet (Kunze and Lemnitzer, 2002), the German ver-sion of WordNet. We employ 23 top-level cate-gories, and each noun is annotated with every top-level category it belongs to.1 Secondly, we use the computer lexicon HaGenLex (Hartrumpf et al, 2003), which offers specific sortal infor-mation derived from a formal ontology for each noun. Finally, we employ a classifier for the count/mass distinction. The classifier combines lexical statistics, expressed in terms of a decision tree classifier, with contextual information, which is handled by Na?ve Bayes classification (cf. Stadtfeld 2010). The classification is based on the fine-grained distinctions first introduced in Allan (1980), but we employ a reduced set of five instead of eight classes. The classifier is type-based as it makes use of the relation be-tween singular and plural realizations of noun lemmas, but takes the immediate context of the lemma into account.   Nouns are only assigned to a particular class if both classifiers come to the same result w.r.t.  this class assignment. While this leads to some nouns being excluded from the count/mass dis-tinction, the resulting classes show a high degree of precision.   2.3 Manual annotation of preposition senses Prepositions are highly polysemous. What is more, the relation between a preposition and its senses has to be determined in a language-                                                1 Nouns that are assigned to more than one top-level cate-gory are presumably homonymous or polysemous. We do not disambiguate the nouns. The reason is that individual features will be evaluated for their effect in a logistic model, and an ambiguous noun will receive a value in each feature. Hence, we can be sure that a significant semantic feature will be included in the classification.  
562
specific manner. While the Preposition Project forms a basis for preposition sense annotation in English (cf. Litkowski and Hargraves 2005, 2007), little attention has been paid to specialized annotation schemata for preposition senses in German, which form the first prerequisite for a classification of preposition senses.   Based on four usage-based grammars and dic-tionaries of German (Duden 2002, Helbig and Buscha 2001, Durrell and Br?e 1993, Schr?der 1986), we have developed an annotation schema with a hierarchical structure, allowing for sub-trees of preposition senses that require a fine-grained classification (such as TEMPORAL, SPA-TIAL, CAUSAL, and PRESENCE). For temporal and spatial interpretations, the annotation is further facilitated by the use of decision trees.2  Altogether, the annotation schema includes the following list of top-level categories: MODAL, CAUSAL, PRESENCE, SPATIAL, TEMPORAL, STATE, COMITATIVE, AGENT, REDUCTION/EXTENSION, PARTICIPATION, SUBORDINATION, RECIPIENT, AFFILIATION, CORRELATION/INTERACTION, TRANSGRESSION, ORDER, THEME, SUBSTITUTE, EXCHANGE, COMPARISON, RESTRICTIVE, COPU-LATIVE, ADVERSATIVE, DISTRIBUTIVE, STATE-MENT/OPINION, CENTRE OF REFERENCE, and RE-ALISATION.  Based on an extension of the weighted kappa statistic we have reached an overall kappa value (?w) of 0.657 and values between 0.551 and 0.860 for individual features (cf. M?ller et al 2010a). Two properties of the annotation schema prohibit the application of a standard kappa sta-tistic: First, the schema allows subsorts, and sec-ondly, a preposition may receive more than one annotation if its sense cannot be fully disambigu-ated. The values reported in M?ller et al (2010) for maximal subtypes such as SPATIAL (?w = 0.709) and TEMPORAL (?w = 0.860) can be equated to aggregate values in standard kappa statistics.   In the models presented below, we employ top-level categories only and have aggregated more specific sense annotations.  
                                                2 The schema does not directly distinguish between local and directional senses, but makes use of cross-classification to deal with the distinction. Cf. M?ller et al (2010b).   
3 Preparing logistic regression models for ohne (?without?) and unter (?un-der?, ?below?) The problem of PNCs, i.e. why a determiner is omitted in a construction which otherwise re-quires the realization of the determiner, can be rephrased as a problem for binary logistic regres-sion and classification.  While binary logistic regression does not pro-hibit monocausal explanations, typical models for binary logistic regression employ more than one factor, and the value of the coefficients mod-els the relative influence of the individual fac-tors. Logistic regression thus does not only help to identify factors for determiner omission, but also reveals the interplay of multiple licensing conditions ? thus possibly accounting for the relative difficulty to distinguish acceptable from inacceptable PNCs. We are aiming at a description of PNCs in German for the 22 prepositions listed in (5). (5) an, auf, bei, dank, durch, f?r, gegen, gem??, hinter, in, mit, mittels, nach, neben, ohne, seit, ?ber, um, unter, vor, w?hrend, wegen These prepositions have been chosen on the basis of the following two assumptions: a) they appear in PNCs and PPs, and b) their ?typical? object is an NP.   We present logistic regression models of de-terminer realization for two prepositions: ohne (?without?) and unter (?under?, ?below?). The first preposition, ohne, is the only preposition that appears more often in PNCs than in PPs. The second preposition, unter, belongs to the class of highly polysemous prepositions. In fact, it is the preposition with the second largest number of senses (10 senses), only surpassed by mit (?with?) (11 senses), which however appears much more often than unter in the corpus and thus requires further annotation. The following table summa-rizes the distribution of PNCs and PPs for both prepositions, after tokens that had been annotated as belonging to headlines, quotations, telegram style sentences, or as being idiomatic were ex-cluded from the data. With regard to the first group (headlines etc.), the elimination mostly applies to PNCs, but among the PPs we found many idiomatic expressions and fixed phrases, which have also been excluded from modeling.  
563
Preposition ? PP PNC ohne 3,750    591  3,159 unter 5,181 4,334     857  Table 1. Data Distribution of PNCs and PPs   The analysis has been carried out in R (R De-velopment Core Team, 2010) and makes exten-sive use of Harrell?s DESIGN package (Harrell, 2001). The feature vector consists of the dependent variable ? the factor DET with its levels no and yes ? and of relevant classificatory features rep-resenting the interpretation of the preposition (in terms of the features presented in section 2), the internal syntactic structure of the nominal projec-tion (prenominal modification of N, syntactic arguments of N, internal structure of N as a com-pound, derivational status of N), the external syntactic embedding of the PNC or PP, and the interpretation of the noun.  Features starting with DEP signify syntactic arguments of the noun (DEP-S a sentential com-plement, DEP-NP an NP complement, etc.); the feature ADJA signifies the presence of one or more modifying adjectives; the feature COM-POUND indicates whether the noun in question is a compound. The feature GOVERNED indicates whether a noun or a verb governs the phrase. The feature NOMINALIZATION provides information about the derivational structure of the noun, in particular it indicates whether a noun is derived from a verb by use of the suffix ?ung. Features starting with GN are GermaNet top-level categories, features starting with HL are HaGenLex ontological sorts; both describe the interpretation of the noun.  The statistical modeling started with the as-sumption that each feature is relevant, so that an initial feature set of 92 features was considered. Feature elimination took place through fast backwards elimination (Lawless and Singhal, 1978) and manual inspection. The results of fast backwards elimination were not followed blindly. Following Harrell?s (2001:56) suggestion, we have kept factors despite their low significance levels. In most cases, however, manual inspec-tion and fast backwards elimination suggested the same results. The resulting models were sub-jected to bootstrap validation to identify possible overfitting (cf. section 5.1).   
The value DET = no is taken to be the default value in the following models. As a consequence, negative values for coefficients indicate rising probability for an omission of a determiner, while positive coefficients shift odds in favor of a realization of the determiner.  4 Logistic models for the omission of a determiner with ohne and unter The logistic regression models developed for the prepositions ohne and unter make use of 13 and 22 features, respectively. In each case, we have started with a full model fit (Harrell, 2001:58f.), evaluated the full model and eliminated factors through manual inspection and fast backwards elimination. The coefficients for the models for ohne and unter are reported in tables 2 and 3.    Coef. S.E. Wald Z p INTERCEPT  -2.4024 0.1109  -21.66 0.000 NOMINAL.  -1.3579 0.1870  -7.26 0.000 ADJA   1.1360     0.1188  9.57  0.000 CAUSAL   1.2063  0.1302     9.26  0.000 COMITAT.   2.2821  0.5201     4.39  0.000 PARTICIP.   3.4027  0.4895     6.95  0.000 PRESENCE  -0.7780  0.1463     -5.32 0.000 DEP-S  5.0797  1.0542     4.82  0.000 DEP-NP  2.9752  0.1718    17.32  0.000 DEP-PP  2.1978  0.1487    14.78  0.000 GN-RELAT.  -1.0292  0.4072    -2.53  0.011 GN-ATTR.  -1.3528  0.3038    -4.45  0.000 GN-EVENT  -0.8431  0.1431    -5.89  0.000 GN-ARTE.  -0.4117  0.1564    -2.63  0.008 Table 2. Coefficients for a logistic regression model of determiner omission with ohne.3                                                              3 In the following tables, S.E. stands for standard error Wald Z reports the Z-score of the Wald statistic, which is deter-mined by divided the value of the coefficient through its standard error. The squared Wald Z statistic is ?2-distributed and thus indicates the goodness of fit for the coefficients of the model. 
564
 Coef. S.E. Wald Z p INTERCEPT  -0.4379  0.1657    -2.64  0.008 NOMINAL.  -0.8346  0.2259   -3.70 0.000 ADJA  -1.0177  0.1432   -7.11 0.000 COMPOUND   2.1719  0.2538    8.56 0.000 GOVERNED  1.9894  0.3017    6.59 0.000 SPATIAL   2.3237  0.2044   11.37 0.000 CAUSAL  1.3047  0.2272    5.74 0.000 SUBORD.  3.0529  0.2559   11.93 0.000 ORDER  3.4228  0.1861   18.40 0.000 TRANSGR.  4.4186  0.3677   12.02 0.000 DEP-S  8.4717  4.0734    2.08   0.037 DEP-NP  0.8551  0.1436    5.95 0.000 DEP-PP  0.3043  0.2170    1.40   0.161 GN-GROUP  0.5241  0.2563    2.04   0.041 GN-COMM.  -0.9149  0.1443   -6.34 0.000 GN-LOC.  2.2704  0.6208    3.66 0.000 GN-REL.  -2.1161  0.6022   -3.51 0.000 GN-POSS.  -0.8482  0.3665   -2.31   0.021 GN-ATTR.  -2.2847  0.2741   -8.33 0.000 GN-ARTE.  0.4169  0.1601    2.60   0.009 GN-HUM.  1.8870  0.4999    3.77 0.000 HL-AD  -1.0253  0.1888   -5.43 0.000 HL-AS  -1.4214  0.3804   -3.74 0.000 Table 3. Coefficients for a logistic model of de-terminer omission with unter.  General measures of the two models are reported in table 4. Somers? Dxy describes the proportion of observations, for which the model provides an appropriate class probability. Dxy can be derived from C, the corresponding receiver operating characteristic curve area, since Dxy = 2 ? (C?0.5). Model L.R. (likelihood ratio) indicates the im-provement reached by including the predictors. Degrees of freedom (d.f.) have been omitted from table 4, as they correspond to the number of predictors, i.e. 12 in the case of ohne and 23 in the case of unter. The high figures for Somers? Dxy are reassuring.    Model L.R. p C Dxy ohne 1,063.5 0 0.876  0.753 unter 2,245.6 0 0.937 0.874 Table 4. Model Quality. 4.1 The model for ohne Starting with the model in table 2, we can iden-tify several groups of factors:  
The first group comprises the interpretation of the preposition. The group discriminates between determiner omission and realization. The seman-tic features CAUSAL, COMITATIVE, and PARTICI-PATION show positive coefficients, suggesting that prepositions receiving the aforementioned interpretations tend to favor an ?ordinary? NP including a determiner. The interpretation PRES-ENCE, on the other hand, shows a negative coef-ficient and thus suggests the omission of a de-terminer. There are further senses of ohne, which do not have a significant effect on determiner omission/realization.   Turning to the representation of syntactic ar-gument structure of the noun, we find that the coefficients of DEP-S, DEP-NP, and DEP-PP re-ceive positive values throughout. The presence of syntactic complements thus shifts odds in fa-vor of determiner realization. There is a strong preference against determiner omission with DEP-S, and somewhat weaker values for Dep-NP and Dep-PP, respectively. A comparison of in-terpretation and complement realization offers a general assessment of PNCs. As ohne and unter share only a few senses, we do not necessarily expect that the discerning senses relevant for a realization of a PNC with ohne carry over to un-ter; but we do expect that features pertaining to the syntactic structure of the nominal comple-ment play a role not only for ohne, but for unter (or for prepositions admitting PNCs in general) as well. And this prediction is actually borne out in the model for unter. The model thus already offers interesting insights not only w.r.t. the re-alization conditions of PNCs and PPs headed by ohne, but for broader analyses of PNCs as well.  We will return to the role and value of the fea-tures ADJA and NOMINALIZATION in section 4.3. The last group comprises the semantic charac-teristics of nouns derived from GermaNet. If a noun is classified as belonging to the relevant GermaNet top-level categories, determiner omi-ssion is favored.  4.2 The model for unter A first glance at the model for unter shows that it requires a larger set of predictors than the model for ohne. In part, this is due to the higher degree of polysemy of unter: with more senses, we ex-pect more semantic predictors to enter the dis-crimination. In addition, a wider range of senses 
565
also allows for a wider range of selection restric-tions, and hence for a larger number of different sortal specifications for selected nouns.  The higher complexity of the model, however, should not conceal a peculiarity of this model that casts serious doubt on the idea that PNCs are mono-causally licensed by particular senses of a prepo-sition: the model selects five senses from the ten top level interpretations of unter, but the coeffi-cients are unsigned. Thus, the model indicates that the senses SPATIAL, CAUSAL, SUBORDINA-TION, ORDER, and TRANSGRESSION block the omission of a determiner. What we do not find are senses that favor the omission of a deter-miner.  The features DEP-S, DEP-NP, and DEP-PP again favor the realization of a determiner. A comparison of the coefficient of DEP-S to the coefficients of DEP-NP and DEP-PP shows, how-ever, that the presence of a sentential comple-ment has a strong influence on determiner reali-zation, while NP- and PP-complements may still occur in PNCs, as their coefficients are relatively low (also in comparison to the coefficients of these values for ohne).4  In more general terms, we suspect a general mechanism relating sentential complementation to the realization of the determiner, a topic to be addressed in future research.   It should also be noted that the external syn-tactic realization of the phrase plays a role for unter. The feature GOVERNED did not play a role for ohne, but suggests the realization of a deter-miner for unter. The reason might be that few verbs or nouns govern the preposition ohne. Prepositional objects headed by unter, however, are more common. Prepositional objects headed by ohne make up only 1.2 % of the occurrences of ohne in the present corpus, while the share of prepositional objects headed by unter is three times larger: 3.6 %.  Finally, we note that a variety of sortal classi-fications for nouns suggest either an omission or realization of the determiner, supporting the as-                                                4 One could argue against the inclusion of the coefficient for DEP-PP altogether, as it does not seem to be significant (p > 0.05) in the first place. However, we have followed Har-rell?s (2001) advice that blind exclusion of seemingly insig-nificant factors may not lead to model improvement. In fact, models for unter including Dep-PP outperform models ex-cluding this feature. 
sumption that in addition to the preposition?s meaning, the meaning of the noun plays a role. GermaNet top-level categories were already dis-criminating in the model for ohne; but the model for unter also makes use of HaGenLex sortal categories (HL-AD and HL-AS). The predictors stand for dynamic and static concepts that both receive an abstract interpretation. Their inclusion is particularly interesting, as it is sometimes claimed (e.g. Bale and Barner, 2009) that ?ab-stract? nouns are never to be classified as count nouns. 4.3 General assessment of the models  Both models show that the realization of syntac-tic complements, of sentential complements in particular, seems to impede determiner omission. That syntactic complexity does not seem to play a role per se, can be deduced from the coeffi-cients for the factor ADJA: While ADJA favors determiner realization with ohne, it prohibits de-terminer realization with unter.  The role of morphological derivation through ?ung, as represented by the factor NOMINALIZA-TION, is the same in both models: derived nomi-nals shift odds in favor of determiner omission. While the derivational structure might be consid-ered a formal property of the construction, it might also reflect an underlying denotational dis-tinction between events and objects, which has to be clarified in future work.  It is a striking feature of the model for unter that we do not find interpretational features of the preposition unter that favor determiner omis-sion. Taken together with the other factors in the two models presented, the analysis suggests a picture rather different from the (more or less) monocausal analyses of Stvan (1998) and Baldwin et al (2006). With regard to unter a model in the sense of Baldwin et al (2006) could only provide negative rules of the form ?if P does not mean this, its nominal complement may be realized without a determiner?, but such a model would lead to less precision than the mul-ticausal model presented here. 5 Validation of the models 5.1 Bootstrap validation Logistic regression models may suffer from overfitting the data. We have thus carried out a 
566
bootstrap validation of both models and applied penalized maximum likelihood estimation (Har-rell, 2001) to the models. The results of the ini-tial (non-penalized) models are reported in Table 5 and Table 6, where we report values for Dxy and the average maximal error of the model. Bootstrap validation makes use of sampling with replacement. The training samples for evaluation thus may contain certain instances many times, but some original data will never be sampled and can thus be used for testing the models. Boot-strap validation is carried out 200 times, the re-sults being averaged. The overfitting of the mod-els is determined by the optimism derived from the bootstrap evaluation.      Dxy Emax Original Index 0.7525 0.0000 Training 0.7578 0.0000 Test 0.7497 0.0123 Optimism 0.0080 0.0123 Corrected Index 0.7445 0.0123 Table 5. Bootstrap validation of model for ohne.5     Dxy Emax Original Index 0.8737 0.0000 Training 0.8741 0.0000 Test 0.8690 0.0072 Optimism 0.0051 0.0072 Corrected Index 0.8685 0.0072 Table 6. Bootstrap validation of model for unter.   Penalized maximum likelihood estimation (Har-rell, 2001:207) for both models resulted in penal-ties of 0.3 and 0.8, respectively, based on Akaike?s AIC. The updated models have again been bootstrap validated, resulting in the im-proved values presented in table 7 and table 8.        Dxy Emax Original Index 0.7526 0.0000 Training 0.7570 0.0000 Test 0.7500 0.0096 Optimism 0.0070 0.0096 Corrected Index 0.7456 0.0096 
                                                5 Emax is the maximal error determined in average over the bootstrap runs. 
Table 7. Bootstrap validation of penalized model for ohne.    Dxy Emax Original Index 0.8736 0.0000 Training 0.8744 0.0000 Test 0.8692 0.0055 Optimism 0.0052 0.0055 Corrected Index 0.8684 0.0055 Table 8. Bootstrap validation of penalized model for unter. 5.2 Representing the influence of factors in a nomogram The respective influence of individual factors can be read of a nomogram (Banks, 1985) derived from the models presented above (we make use of a tabular presentation for reasons of legibil-ity). The nomogram for ohne consists of the ta-bles 9 and 10. Table 9 lists the individual scores for the factors in the model for ohne, were 0 in-dicates that the pertinent property is not present and 1 indicates that the property is present. Table 10 maps the sum to probability of determiner omission.   Predictor 0 1 NOMINALIZATION  27  0 ADJA  0  22 CAUSAL  0  24 COMITATIVE  0  45 PARTICIPATION  0  67 PRESENCE  15  0 DEP-S  0  100 DEP-NP  0  59 DEP-PP  0  43 GN-RELATION  20  0 GN-ATTRIBUTE  27  0 GN-EVENT  17  0 GN-ARTEFACT  8  0 Table 9. Nomogram: individual scores of predic-tors for ohne.  Total Points Pr(?Omission of Det?) 118 0.9 134 0.8 144 0.7 153 0.6 
567
161 0.5 169 0.4 178 0.3 188 0.2 204 0.1 Table 10. Nomogram: mapping from total points to probability of determiner omission.  As an illustration, consider pairs of ohne and a noun with the values in (6) and (7). (6) NOMINALIZATION = 1, ADJA = 1, COMITA-TIVE = 1, all other senses including PRESENCE = 0, all GN features = 0, DEP features = 0. (7) NOMINALIZATION = 0, ADJA = 1, PRESENCE = 1, all other senses = 0, GN-ATTRIBUTE = 1, all other GN features = 0, DEP features = 0. Given the individual scores for the factors in table 9, the total number of points for the combi-nation in (6) is 144, leading to a probability of 0.7 that a determiner will be omitted in the con-struction. In other words, a determiner omission is likely with the feature set given in (6). In (7), we reach a total of 92 only, so that the likelihood of determiner omission rises above 0.9. 6 Summary and prospects The models presented support the general as-sumption that the realization or omission of a determiner in a prepositional phrase should be analyzed as a multicausal phenomenon. The lo-gistic regression analysis presents evidence for the assumption that the senses of the preposition and the interpretation of the noun (possibly gov-erned by selection restrictions of the preposition) as well as the syntactic complexity of the em-bedded nominal projection are major factors in determining whether an article can be dropped or not.  With regard to the complexity of the nominal projection, the two models presented here indi-cate that it is not complexity per se, but that the realization of a complement of the noun, in par-ticular of a sentential complement, clearly raises the probability of article realization. While this is a speculation, based on the models presented here, it might very well be that this dependency reflects a deeper referential requirement.  In developing further models for prepositions, we expect that the realization of a complement of the noun will establish itself as a common factor, 
but this has to await further research and model development.  Acknowledgement We gratefully acknowledge the funding of our research by the Deutsche Forschungsgemein-schaft (DFG) under project grant KI 759/5-1.  References Allan, Keith. 1980. Nouns and countability. Language 56(3):541-567. Baldwin, Timothy, John Beavers, Leonoor van der Beek, Francis Bond, Dan Flickinger, and Ivan Sag. 2006. In search of a systematic treatment of deter-minerless PPs. In Patrick Saint-Dizier (eds.), Syn-tax and Semantics of Prepositions. Springer, Dordrecht, 163-179. Bale, Alan, and David Barner. 2009. The interpreta-tion of functional heads: Using comparatives to ex-plore the mass/count distinction. Journal of Seman-tics 26, 217-252. Banks, J. 1985. Nomograms. In S. Kotz and N.L. Johnson (eds.), Encyclopedia of Statistical Sci-ences, Vol. 6. Wiley, New York. Chiarcos, Christian, Stefanie Dipper, Michael G?tze, Ulf Leser, Anke L?deling, Julia Ritz, and Manfred Stede. 2008. A flexible framework for integrating annotations from different tools and tagsets. Traitement Automatique des Langues. Special Is-sue Platforms for Natural Language Processing. ATALA, 49 (2). Duden. 2002. Duden. Deutsch als Fremdsprache. Bi-bliographisches Institut and F.A. Brockhaus AG, Mannheim. Durell, Martin and David Br?e. 1993. German tempo-ral prepositions from an English perspective. In Cornelia Zelinsky-Wibbelt (ed.), The Semantics of Prepositions. From Mental Processing to ?atural Language Processing. De Gruyter, Berlin/New York, 295-325. Harrell, Frank E. 2001. Regression modeling strate-gies: with applications to linear models, logistic regression, and survival analysis. Springer: New York. Hartrumpf, Sven, Hermann Helbig, and Rainer Oss-wald. 2003. The Semantically Based Computer Lexicon HaGenLex - Structure and Technological Environment. Traitement automatique des langues 44(2):81-105. 
568
Helbig, Gerhard and Joachim Buscha. 2001. Deutsche Grammatik. Ein Handbuch f?r den Ausl?nderunter-richt. Leipzig, Langenscheidt. Himmelmann, Nikolaus. 1998. Regularity in irregu-larity: Article use in adpositional phrases. Linguis-tic Typology, 2:315?353.  Kunze, Claudia, and Lothar Lemnitzer. 2002. Ger-maNet - representation, visualization, application. Proc. LREC 2002, main conference, Vol V., 1485-1491. Lawless, J. and K. Singhal. 1978. Efficient screening on nonnormal regression models. Biometrics 34:318-327. Le Bruyn, Bert, Henri?tte de Swart, and Joost Zwarts. 2009. Bare PPs across languages. Presented at the Workshop on Bare nouns, Paris. M?ller, Antje, Olaf H?lscher, Claudia Roch, Katja Ke?elmeier, Tobias Stadtfeld, Jan Strunk, and Ti-bor Kiss. 2010. An Annotation Schema for Prepo-sition Senses in German. Proceedings of ACL-LAW IV, Uppsala, Sweden. M?ller, Antje, Katja Ke?elmeier, Claudia Roch, Jan Strunk, Tobias Stadtfeld and Tibor Kiss. 2010. Creating a Feature Space for the Annotation of Preposition Senses in German. Linguistic Evi-dence,T?bingen 2010. M?ller, Christoph, and Michael Strube. 2006. Multi-level annotation of linguistic data with MMAX2. In Sabine Braun, Kurt Kohn, Joybrato Mukherjee, (eds.), Corpus Technology and Language Peda-gogy: New Resources, New Tools, New Methods. Peter Lang, Frankfurt a.M., 197-214. Nivre, Joakim. 2006. Inductive Dependency Parsing (Text, Speech, and Language Technology). New York: Springer. R Development Core Team. 2010. R: A language and environment for statistical computing. Foundation for Statistical Computing, Vienna, Austria. http://www.rproject.org. Stadtfeld, Tobias. 2010. Determining the Countability of English and German Nouns. Ms. Ruhr-University Bochum. Schmid, Helmut. 1995. Improvements in part-of-speech tagging with an application to German. In Proceedings of the EACL SIGDAT Workshop, Dublin, Ireland, March. Schmid, Helmut, Arne Fitschen, and Ulrich Heid. 2004. SMOR: A German computational morphol-ogy covering derivation, composition, and inflec-
tion. In Proceedings of LREC 2004, 1263-1266, Lisbon, Portugal. Schmid, Helmut, and Florian Laws. 2008. Estimation of conditional probabilities with decision trees and an application to fine-grained POS tagging. In Pro-ceedings of COLING 2008, Manchester, UK. Schr?der, Jochen. 1986. Lexikon deutscher Pr?posi-tionen. Leipzig, VEB Verlag Enzyklop?die. Stvan, Laurel S. 1998. The Semantics and Pragmatics of Bare Singular Noun Phrases. Ph.D. thesis, Northwestern University, Evanston/ Chicago, IL.   
569
Proceedings of the Fourth Linguistic Annotation Workshop, ACL 2010, pages 177?181,
Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational Linguistics
An Annotation Schema for Preposition Senses in German  
 
 
Antje 
M?ller 
Olaf 
H?lscher 
Claudia 
Roch 
Katja Ke-
?elmeier 
Tobias 
Stadtfeld 
Jan  
Strunk 
Tibor 
Kiss 
Sprachwissenschaftliches Institut, Ruhr-Universit?t Bochum 
D-44801 Bochum, Germany 
{mueller, roch, kesselmeier, stadtfeld, strunk, tibor} 
@linguistics.rub.de, olaf.huelscher@rub.de 
 
 
Abstract 
Prepositions are highly polysemous. Yet, little 
effort has been spent to develop language-
specific annotation schemata for preposition 
senses to systematically represent and analyze 
the polysemy of prepositions in large corpora. 
In this paper, we present an annotation schema 
for preposition senses in German. The annota-
tion schema includes a hierarchical taxonomy 
and also allows multiple annotations for indi-
vidual tokens. It is based on an analysis of 
usage-based dictionaries and grammars and 
has been evaluated in an inter-annotator-
agreement study.  
1 Annotation Schemata for Preposition 
Senses: A Problem to be Tackled 
It is common linguistic wisdom that preposi-
tions are highly polysemous. It is thus somewhat 
surprising that little attention has been paid to the 
development of specialized annotation schemata 
for preposition senses.1 In the present paper, we 
present a tagset for the annotation of German 
prepositions. The need for an annotation schema 
emerged in an analysis of so-called Preposition-
Noun Combinations (PNCs), sometimes called 
determinerless PPs or bare PPs. PNCs minimally 
consist of a preposition and a count noun in the 
singular that appear without a determiner. In (1), 
examples are given from German. 
(1) auf parlamentarische Anfrage (after being 
asked in parliament), bei absolut klarer Ziel-
setzung (given a clearly present aim), unter 
sanfter Androhung (under gentle threat)  
The preposition-sense annotation forms part of a 
larger annotation task of the corpus, where all 
                                                           
1  The Preposition Project is a notable exception (cf. 
www.clres.com/prepositions.html). 
relevant properties of PPs and PNCs receive either 
automated or manual annotations. In developing 
an annotation schema for preposition senses, we 
pursue two general goals:   
I. An annotation schema for preposition senses 
should provide a basis for manual annotation 
of a corpus to determine whether the interpre-
tation of prepositions is a grammatical factor. 
II. The preposition sense annotations together 
with the other annotations of the corpus 
should serve as a reference for the automatic 
classification of preposition senses.  
With regard to the goals formulated, the present 
paper is an intermediate report. The annotation 
schema has been developed and the manual anno-
tation of the corpus is well under way. The next 
logical steps will be to apply the annotations to a 
wider range of prepositions and eventually to use 
the annotated corpus for an automated classifica-
tion system for preposition senses.   
As PNCs form the basic rationale for the current 
investigation, we are only considering prepositions 
that occur in PPs and PNCs in German. We thus 
systematically exclude prepositions that do not 
take an NP complement, postpositions, and com-
plex prepositions. Thus, the sense annotation for 
prepositions currently comprises the following 22 
simple prepositions in German: 
(2) an, auf, bei, dank, durch, f?r, gegen, gem??, 
hinter, in, mit, mittels, nach, neben, ohne, seit, 
?ber, um, unter, vor, w?hrend, wegen  
As empirical base of the analysis, we use a Swiss 
German newspaper corpus, which contains about 
230 million tokens (Neue Z?rcher Zeitung 1993-
1999).  
The remaining paper is structured as follows:  
Section 2 is devoted to the characteristics of the 
annotation schema. In section 3, we present an 
analysis of the schema in terms of inter-annotator 
177
agreement. It takes into account that the annotation 
schema is hierarchically ordered and allows for 
multiple annotations. Section 4 illustrates the ap-
plication of the schema to the preposition ohne 
(?without?) in German.  
2 Properties of the Annotation Schema 
There are no standardized features for an anno-
tation of preposition senses in German. Our work 
is thus based on several reference works, which we 
analyzed and combined to develop the schema, 
namely Duden Deutsch als Fremdsprache (Duden, 
2002) (a dictionary of German for foreign learn-
ers), Deutsche Grammatik from Helbig and 
Buscha (2001) (a grammar of German for foreign 
learners) (both usage-based), the Lexikon 
Deutscher Pr?positionen (Schr?der, 1986) (a dic-
tionary of German prepositions) and an analysis of 
prepositions with a temporal meaning (Durell and 
Br?e, 1993). Prima facie, the dictionary of German 
prepositions appears to be the most promising 
starting point because it includes a fine-grained 
feature-based analysis of preposition senses. How-
ever, it turns out that it is too complex for manual 
annotation, making use of more than 200 binary 
features to classify preposition meanings. 
The annotation schema shows a hierarchically 
organized, tree-like structure. Beginning with a 
root node, types of preposition meanings branch to 
subtrees for different classes (e.g. local, temporal 
or causal) with differing depths or to individual, 
non-splitting branches (see Figure 1). For temporal 
and spatial interpretations, we use decision trees 
that help to guide the annotator through the anno-
tation process.  
Altogether the annotation schema includes the 
following list of top-level categories: SPATIAL, 
TEMPORAL, MODAL, CAUSAL, STATE, COMMUNAL-
ITY/COMMUTATIVE, TRANSGRESSION, AGENT, 
REDUCTION/EXTENSION, PARTICIPATION, SUBOR-
DINATION, RECIPIENT, AFFILIATION, CORRELA-
TION/INTERACTION, ORDER, THEME, SUBSTITUTE, 
EXCHANGE, COMPARISON, RESTRICTIVE, COPULA-
TIVE, ADVERSATIVE, DISTRIBUTIVE, STATE-
MENT/OPINION, EXISTENCE/PRESENCE, CENTRE OF 
REFERENCE, and REALIZATION. 
 
The schema allows cross-classification at every 
level. This is of particular importance for the clas-
sification of directional meanings. Directionality is 
introduced through cross-classification and not 
through copying the hierarchical structure of the 
local subtree.2  
Another important property of the annotation 
schema is the possibility of multiple annotations 
for one preposition in context. For instance, a final 
distinction between a temporal and a causal inter-
pretation cannot be drawn in example (3). 
                                                           
2 During annotation, local and directional interpretations can 
be distinguished by case assignment in the majority of cases. 
 (3) Feuer nach [temporal/causal] Blitzschlag 
 ?Fire after/because of lightning stroke? 
In addition to the semantic categories, we use a 
feature ?governed? to label a preposition as gov-
erned by a lexical head whenever appropriate. 
Governed prepositions usually are assumed to be 
semantically empty but in some cases there is a 
discernible meaning for the preposition despite its 
being governed.  
The preposition sense annotation is only one 
part of a bigger annotation project. Annotations on 
lexical (POS, morphology, countability, preposi-
tion meaning, noun meaning), syntactic (chunks), 
relational (internal and external dependencies), and 
Figure 1: Hierarchical Annotation Schema 
178
??
global (e.g. marking as a headline or part of a TV 
program in a newspaper, idiomaticity, telegraphic 
style) levels will serve as a basis for annotation 
mining to detect licensing conditions of PNCs. 
3 An Analysis of Inter-Annotator 
Agreement  in a Hierarchical Annota-
tion Schema 
A weighted kappa statistic (?) forms a standard 
for assessing the feasibility of annotation sche-
mata. Based on Cohen?s seminal work (Cohen, 
1968), Artstein and Poesio (2008) suggest the 
measure in (4), where ? is calculated as the 
weighted difference between observed and ex-
pected disagreement. 
(4)      = 1 ?  
Two aspects of the present annotation schema 
prohibit a direct application of this statistic. First, 
the annotation schema makes use of a hierarchy 
with subtypes, which leads to overlapping annota-
tion categories. As an illustration, assume that one 
annotator has annotated a given preposition with 
the sense PRESENCE, while a second annotator 
makes use of the annotation ANALYTIC, the latter 
being a subtype of the first. Secondly, the annota-
tion schema allows more than one annotation for 
the same token, to cover cases where an ambigu-
ous interpretation cannot be maximally reduced, as 
in (4). 
To deal with the first problem, the hierarchical 
structure of the annotation schema is included in 
the calculation of the weight coefficients for ?. 
Basically, two annotations are more closely related 
if either both annotations are dominated by the 
same set of nodes in the hierarchy, or one annota-
tion is a direct subtype of the other one (as usual, 
we assume domination to be reflexive). Accord-
ingly, the weight coefficient for a given disagree-
ment is reduced in relation to the depth of embed-
ding of the subcategories, based on the cardinality 
of the set of nodes that dominate both categories. 
As an illustration consider two senses A and B 
in the following configurations: a) A and B are 
directly dominated by C, a subtype of ROOT; b) A 
dominates B, A being a subtype of ROOT, and c) 
ROOT directly dominates A and C, and B is a sub-
type of C. Intuitively, c) is a case of clear dis-
agreement, while in b) we find that one annotation 
is more specific than the other one, and in a), the 
annotators have at least agreed in a common super-
type of the categories. 
Consequently, the weight coefficient for dis-
agreement should be highest in case c), but should 
be similar in cases a) and b).  
(5)  
a) b) c) 
   
The weight coefficient is determined by the fol-
lowing formula, where 	

 designates the depth 
of the lowest common dominating node of the two 
senses (and hence the cardinality of the set of 
dominating nodes minus 1). 
(6)     

 = 

 ,    ?  0,   =  