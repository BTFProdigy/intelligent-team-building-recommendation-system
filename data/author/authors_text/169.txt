Event-based Information Extraction for the biomedical domain: the Caderige project 
 
Erick Alphonse**, Sophie Aubin*, Philippe Bessi?res**, Gilles Bisson****, Thierry Hamon*, 
Sandrine Lagarrigue***, Adeline Nazarenko*, Alain-Pierre Manine**, Claire N?dellec**, 
Mohamed Ould Abdel Vetah**, Thierry Poibeau*, Davy Weissenbacher* 
 
*Laboratoire d?Informatique de Paris-Nord  
CNRS UMR 7030 
Av. J.B. Cl?ment 93430 F-Villetaneuse 
{firstname.lastname}@lipn.univ-paris13.fr 
**Laboratoire Math?matique, Informatique et G?nome (MIG), 
INRA,  
Domaine de Vilvert, 78352 F-Jouy-en-Josas 
{firstname.lastname}@jouy.inra.fr 
***Laboratoire de G?n?tique Animale,  
INRA-ENSAR 
Route de Saint Brieuc, 35042 Rennes Cedex 
lagarrig@roazhon.inra.fr 
****Laboratoire Leibniz ? UMR CNRS 5522  
46 Avenue F?lix Viallet - 38031 F-Grenoble Cedex 
Gilles.Bisson@imag.fr 
 
 Abstract  
This paper gives an overview of the 
Caderige project. This project involves 
teams from different areas (biology, 
machine learning, natural language 
processing) in order to develop high-
level analysis tools for extracting 
structured information from biological 
bibliographical databases, especially 
Medline. The paper gives an overview 
of the approach and compares it to the 
state of the art.  
1 Introduction 
Developments in biology and biomedicine are 
reported in large bibliographical databases 
either focused on a specific species (e.g. 
Flybase, specialized on Drosophilia 
Menogaster) or not (e.g. Medline). This type 
of  information sources is crucial for biologists 
but there is a lack of tools to explore them and 
extract relevant information. While recent 
named entity recognition tools have gained a 
certain success on these domains, event-based 
Information Extraction (IE) is still a challenge.  
The Caderige project aims at designing and 
integrating Natural Language Processing 
(NLP) and Machine Learning (ML) techniques 
to explore, analyze and extract targeted 
information in biological textual databases. We 
promote a corpus-based approach focusing on 
text pre-analysis and normalization: it is 
intended to drain out the linguistic variation 
dimension, as most as possible. Actually, the 
MUC (1995) conferences have demonstrated 
that extraction is more efficient when 
performed on normalized texts. The extraction 
patterns are thus easier to acquire or learn, 
more abstract and easier to maintain 
Beyond extraction patterns, it is also possible 
to acquire from the corpus, via ML methods, a 
part of the knowledge necessary for text 
normalization as shown here.  
This paper gives an overview of current 
research activities and achievements of the 
Caderige project. The paper first presents our 
approach and compares it with the one 
developed in the framework of a similar 
project called Genia (Collier et al 1999). We 
then propose an account of Caderige 
techniques on various filtering and 
normalization tasks, namely, sentence filtering, 
resolution of named entity synonymy, 
syntactic parsing, and ontology learning. 
Finally, we show how extraction patterns can 
be learned from normalized and annotated 
documents, all applied to biological texts.  
2 Description of our approach 
In this section, we give some details about the 
motivations and choices of implementation. 
We then briefly compare our approach with the 
one of the Genia project. 
43
2.1 Project organization 
The Caderige project is a multi disciplinary 
French research project on the automatic 
mining of textual data from the biomedical 
domain and is mainly exploratory orientated. It 
involved biology teams (INRA), computer 
science teams (LIPN, INRA and Leibniz-
IMAG) and NLP teams (LIPN) as major 
partners, plus LRI and INRIA from 2000 to 
2003. 
2.2 Project motivations 
Biologists can search bibliographic databases 
via the Internet, using keyword queries that 
retrieve a large superset of relevant papers. 
Alternatively, they can navigate through 
hyperlinks between genome databanks and 
referenced papers. To extract the requisite 
knowledge from the retrieved papers, they 
must identify the relevant abstracts or 
paragraphs. Such manual processing is time 
consuming and repetitive, because of the 
bibliography size, the relevant data sparseness, 
and the database continuous updating. From 
the Medline database, the focused query 
?Bacillus subtilis and transcription? which 
returned 2,209 abstracts in 2002, retrieves 
2,693 of them today. We chose this example 
because Bacillus subtilis is a model bacterium 
and transcription is a central phenomenon in 
functional genomics involved in genic 
interaction, a popular IE problem. 
GerE stimulates cotD transcription and 
inhibits cotA transcription in vitro by 
sigma K RNA polymerase, as expected from 
in vivo studies, and, unexpectedly, 
profoundly inhibits in vitro 
transcription of the gene (sigK) that 
encode sigma K. 
Figure 1: A sentence describing a genic interaction 
Once relevant abstracts have been retrieved, 
templates should be filled by hand since there 
is no available IE tool operational in genomics  
Type: positive 
Agent: GerE 
 
Interaction 
Target: transcription of the 
gene sigK 
Figure 2: A template describing a genic 
interaction. 
Still, applying IE ? la MUC to genomics and 
more generally to biology is not an easy task 
because IE systems require deep analysis 
methods to locate relevant fragments. As 
shown in the example in Figures 1 and 2, 
retrieving that GerE is the agent of the 
inhibition of the transcription of the gene sigK 
requires at least syntactic dependency analysis 
and coordination processing. In most of the 
genomics IE tasks (function, localization, 
homology) the methods should then combine 
the semantic-conceptual analysis of text 
understanding methods with IE through pattern 
matching. 
2.3 Comparison with the Genia project 
Our approach is very close to the one of the 
Genia project (Collier et al, 1999). Both 
projects rely on precise high-level linguistic 
analysis to be able to perform IE. The kind of 
information being searched is similar, 
concerning mainly gene and protein interaction 
as most of the research in this domain. The 
Genia corpus (Ohtae et al 2001) is not 
specialized on a specific species whereas ours 
is based on Bacillus Subtilis.  
Both projects develop annotation tools and 
Document Type Definition (DTD), which are, 
for the most part, compatible. The aim here is 
to build training corpus to which various 
techniques of NLP and ML are applied in 
order to acquire efficient event-based 
extraction patterns. The choice of ML and 
NLP methods differs but their aim is similar to 
our: normalizing text with predicate-arguments 
structures for learning better patterns. For 
example, Genia uses a combination of parsers 
to finally perform an HPSG-like analysis. The 
Caderige syntactic analysis is based on the 
specialization of the Link Parser (Sleator and 
Temperley, 1993 see section 4) to the 
biological domain.  
 In the following two sections, we detail our 
text filtering and normalization methods. 
Filtering aims at pruning the irrelevant part of 
the corpus while normalization aims at 
building an abstract representation of the 
relevant text. Section 4 is devoted to the 
acquisition of extraction patterns from the 
filtered and normalized text. 
3 Text filtering 
IR and text filtering are a prerequisite step to 
IE, as IE methods (including normalization and 
learning) cannot be applied to large and 
irrelevant corpora (they are not robust enough 
and they are computationally expensive). IR 
here is done through Medline interface by 
keyword queries for filtering the appropriate 
44
document subset. Then, text filtering, reduces 
the variability of textual data with the 
following assumptions: 
? desired information is local to sentences ; 
? relevant sentences contain at least two gene 
names. 
These hypotheses may lead to miss some genic 
interactions, but we assume that information 
redundancy is such that at least one instance of 
each interaction is contained into a single 
sentence in the corpus. The documents 
retrieved are thus segmented into sentences 
and the sentences with at least two gene names 
are selected. 
To identify the only relevant sentences among 
thoses,  classical supervised ML methods have 
been applied to a Bacillus Subtilis corpus in 
which relevant and irrelevant sentences had 
been annotated by a biological expert. Among 
SVMs, Na?ve Bayes (NB) methods, Neural 
Networks, decision trees (Marcotte et al, 
2001;  Nedellec et al, 2001), (Nedellec et al 
2001) demonstrates that  simple NB methods 
coupled with feature selection seem to perform 
well by yielding around 85 % precision and 
recall. Moreover, our first experiments show 
that the linguistic-based representation changes 
such as the use of lemmatization, terminology 
and named entities, do not lead to significant 
improvements. The relevant sentences filtered 
at this step are then used as input of the next 
tasks, normalization and IE. 
4 Normalization 
This section briefly presents three text 
normalization tasks: normalization of entity 
names, normalization of relations between text 
elements through syntactic dependency parsing 
and semantic labeling. The normalization 
process, by providing an abstract 
representation of the sentences, allows the 
identification of regularities that simplify the 
acquisition or learning of pattern rules. 
4.1 Entity names normalization 
Named Entity recognition is a critical point in 
biological text analysis, and a lot of work was 
previously done to detect gene names in text 
(Proux and al., 1998), (Fukuda and al., 1998). 
So, in Caderige, we do not develop any 
original NE extraction tool. We focus on a less 
studied problem that is synonyms recognition.  
Beyond typographical variations and 
abbreviations, biological entities often have 
several different names. Synonymy of gene 
names is a well-known problem, partly due to 
the huge amount of data manipulated (43.238 
references registered in Flybase for 
Drosophilia Melanogaster for example). Genes 
are often given a temporary name by a 
biologist. This name is then changed according 
to information on the concerned gene: for 
example SYGP-ORF50 is a gene name 
temporarily attributed by a sequencing project 
to the PMD1 yeast gene. We have shown that, 
in addition to available data in genomic 
database (GenBank, SwissProt,?), it is 
possible to acquire many synonymy relations 
with good precision through text analysis. By 
focusing on synonymy trigger phrases such as 
"also called" or "formerly", we can extract text 
fragments of that type :  gene trigger gene. 
However, the triggers themselves are subject to 
variation and the arguments of the synonymy 
relation must be precisely identified. We have 
shown that it is possible to define patterns to 
recognize synonymy expressions. These 
patterns have been trained on a representative 
set of sentences from Medline and then tested 
on a new corpus made of 106 sentences 
containing the keyword formerly. Results on 
the test corpus are the following: 97.5% 
precision, 75% recall. We chose to have a high 
precision since the acquired information must 
be valid for further acquisition steps 
(Weissenbacher, 2004).  
The approach that has been developed is very 
modular since abstract patterns like gene 
trigger gene (the trigger being a linguistic 
marker or a simple punctuation) can be 
instantiated by various linguistic items. A 
score can be computed for each instantiation of 
the pattern, during a learning phase on a large 
representative corpus. The use of a reduced 
tagged corpus and of a large untagged corpus 
justify the use of semi-supervised learning 
techniques.  
4.2  Sentence parsing 
The extraction of structured information from 
texts requires precise sentence parsing tools 
that exhibit relevant relation between domain 
entities. Contrary to (Akane et al 2001), we 
chose a partial parsing approach: the analysis 
is focused on relevant parts of texts and, from 
these chunks, on specific relations. Several 
reasons motivate this choice: among others, the 
fact that relevant information generally appears 
in predefined syntactic patterns and, moreover, 
45
the fact that we want to learn domain 
knowledge ontologies from specific syntactic 
relations (Faure and Nedellec, 2000 ; Bisson et 
al. 2000). 
First experiments have been done on several 
shallow parsers. It appeared that constituent 
based parsers are efficient to segment the text 
in syntactic phrases but fail to extract relevant 
functional relationships betweens phrases. 
Dependency grammars are more adequate 
since they try to establish links between heads 
of syntactic phrases. In addition, as described 
in Schneider (1998), dependency grammars are 
looser on word order, which is an advantage 
when working on  a domain specific language.  
Two dependency-based syntactic parsers have 
been tested (Aubin 2003): a hybrid commercial 
parser (henceforth HCP) that combines 
constituent and dependency analysis, and a 
pure dependency analyzer: the Link Parser.   
Prasad and Sarkar (2000) promote a twofold 
evaluation for parsers: on the one hand the use 
of a representative corpus and, on the other 
hand, the use of specific manually elaborated 
sentences. The idea is to evaluate analyzers on 
real data (corpus evaluation) and then to check 
the performance on specific syntactic 
phenomena. In this experiment, we chose to 
have only one corpus, made of sentences 
selected from the Medline corpus depending 
on their syntactic particularity. This strategy 
ensures representative results on real data. 
A set of syntactic relations was then selected 
and manually evaluated. This led to the results 
presented for major relations only in table 1. 
For each analyzer and relation, we compute a 
recall and precision score (recall = # relevant 
found relations / # relations to be found; 
precision = # relevant found relations / # 
relations found by the system).  
The Link Parser generally obtains better results 
than HCP. One reason is that a major 
particularity of our corpus (Medline abstracts) 
is that sentences are often (very) long (27 
words on average) and contain several clauses. 
The dependency analyzer is more accurate to 
identify relevant relationships between 
headwords whereas the constituent parser is 
lost in the sentence complexity. We finally 
opted for the Link Parser. Another advantage 
of the Link Parser is the possibility to modify 
its set of rules (see next subsection). The Link 
parser is currently used in INRA to extract 
syntactic relationships from texts in order to 
learn domain ontologies on the basis of a 
distributional analysis (Harris 1951, Faure and 
N?dellec, 1999).  
4.3 Recycling a general parser for biology 
During the evaluation tests, we noticed that 
some changes had to be applied either to the 
parser or to the text itself to improve the 
syntactic analysis of our biomedical corpus. 
The corpus needs to be preprocessed: sentence 
segmentation, named entities and terms 
recognition are thus performed using generic 
modules tuned for the biology domain
1
. Term 
recognition allows the removing of numerous 
structure ambiguities, which clearly benefits 
the parsing quality and execution time.  
                                                     
1
 A term analyser is currently being built at LIPN 
using existing term resources like Gene Ontology 
(see Hamon and Aubin, 2004). 
  Link Parser HCP 
Rel nbRel relOK R. RelTot P. RelOK R RelTot P. 
Subject 
18 13 0.72 19 0.68 14 0.78 20 0.65 
Object 
18 16 0.89 17 0.94 9 0.5 13 0.69 
Prep 
48 25 0.52 55 0.45 20 0.42 49 0.41 
V-GP1 
14 13 0.93 15 0.87 9 0.64 23 0.39 
O-GP 
16 7 0.43 12 0.58 12 0.75 28 0.43 
NofN 
16 13 0.81 15 0.87 14 0.87 26 0.54 
VtoV 
10 9 0.9 9 1 7 0.7 7 1 
VcooV 
10 8 0.8 9 0.89 6 0.6 6 1 
NcooN 
10 8 0.7 10 0.8 4 0.4 6 0.67 
nV-Adj 
10 8 0.8 9 0.89 0 0 0 1 
PaSim 
18 17 0.94 18 0.94 17 0.94 22 0.77 
PaRel 
12 11 0.92 11 1 8 0.67 11 0.73 
Table 1: Evaluation of two parsers on various syntactic relations 
Relations meaning: subject = subject-verb, Object = verb-object, Prep = prepositional phrase, V-GP = verb-prep. 
phrase, O-GP = Object- prep. phrase, NofN = Noun of noun, VtoV = Verb to Verb, VcooV = Verb coord. Verb, 
NcooN = Noun coord. Noun, nV-Adj = not + Verb or adjective, PaSim = passive form, PaRel = passive relative 
46
Concerning the Link Parser, we have manually 
introduced new rules and lexicon to allow the 
parsing of syntactic structures specific to the 
domain. For instance, the Latin-derived Noun 
Adjective phrase "Bacillus subtilis" has a 
structure inverse to the canonical English noun 
phrase (Adjective Noun). Another major task 
was to loosen the rules constraints because 
Medline abstracts are written by biologists 
who express themselves in sometimes broken 
English. A typical error is the omission of the 
determinant before some nouns that require 
one. We finally added words unknown to the 
original parser. 
4.4 Semantic labelling 
Asium software is used to semi-automatically 
acquire relevant semantic categories by 
distributional semantic analysis of parsed 
corpus. These categories contribute to text 
normalization at two levels, disambiguating 
syntactic parsing and typing entities and 
actions for IE. Asium is based on an original 
ascendant hierarchical clustering method that 
builds a hierarchy of semantic classes from the 
syntactic dependencies parsed in the training 
corpus. Manual validation is required in order 
to distinguish between different meanings 
expressed by identical syntactic structures. 
5 Extraction pattern learning 
Extraction pattern learning requires a training 
corpus from which the relevant and 
discriminant regularities can be automatically 
identified. This relies on two processes: text 
normalization that is domain-oriented but not 
task-oriented (as described in previous 
sections), and task-oriented annotation by the 
expert of the task.  
5.1 Annotation procedure 
The Caderige annotation language is based on 
XML and a specific DTD (Document Type 
Definition that can be used to annotate both 
prokaryote and eukaryote organisms by 50 
tags with up to 8 attributes. Such a precision is 
required for learning feasibility and extraction 
efficiency. Practically, each annotation aims at 
highlighting the set of words in the sentence 
describing: 
? Agents (A): the entities activating or 
controlling the interaction 
? Targets (T): the entities that are produced 
or controlled 
? Interaction (I): the kind of control 
performed during the interaction 
? Confidence (C): the confidence level in this 
interaction. 
The annotation of ?A low level of GerE 
activated transcription of CotD by GerE RNA 
polymerase in vitro ...? is given below. The 
attributes associated to the tag <GENIC-
INTERACTION> express the fact that the 
interaction is a transcriptional activation and 
that it is certain. The other tags (<IF>, 
<AF1>, ?) mark  the agent (AF1 and AF2), the 
target (TF1) and the interaction (IF). 
 
<GENIC-INTERACTION 
 id=?1?  
 type=?transcriptional?  
 assertion=?exist?  
 regulation=?activate?  
 uncertainty=?certain?  
 self-contained=?yes?  
 text-clarity=?good?> 
  <IF>A<I> low level </I>of</IF>     
  <AF1><A1  
     type=protein  
        role=modulate  
        direct=yes> GerE 
  </A1></AF1>,  
  <IF><I>activated</I> transcription  
      of</IF>    
     <TF1><T1 type=protein> CotD </T1>           
         </TF1> by   
     <AF2><A2  
           type=protein  
         role=required> 
       GerE RNA polymerase 
   </A2></AF2>,  
   <CF>but<C>in vitro</C></CF> 
</GENIC-INTERACTION> 
5.2 The annotation editor2 
Annotations cannot be processed in text form 
by biologists. The annotation framework 
developed by Caderige provide a general XML 
editor with a graphic interface for creating, 
checking and revising annotated documents. 
For instance, it displays the text with graphic 
attributes as defined in the editor XML style 
sheet, it allows to add the tags without strong 
constraint on the insertion order and it 
automatically performs some checking. 
The editor interface is composed of four main 
parts (see Figure 3). The editable text zone for 
annotation, the list of XML tags that can be 
used at a given time, the attributes zone to edit 
the values of the selected tag, and the XML 
                                                     
2
 Contact one of the authors if you are interested to 
use this annotation tool in a research project 
47
code currently generated. In the text zone, the 
above sentence is displayed as follows: 
A low level of GerE activated 
transcription of CotD by GerE RNA 
polymerase but in vitro 
This editor is currently used by some of the 
Caderige project partners and at SIB (Swiss 
Institute of BioInformatics) with another DTD, 
in the framework of the European BioMint 
project. Several corpora on various species 
have been annotated using this tool, mainly by 
biologists from INRA.  
5.3 Learning 
The vast majority of approaches relies on 
hand-written pattern rules that are based on 
shallow representations of the sentences (e.g. 
Ono et al, 2001). In Caderige, the deep 
analysis methods increase the complexity of 
the sentence representation, and thus of the IE 
patterns. ML techniques appear therefore very 
appealing to automate the process of rule 
acquisition (Freitag, 1998; Califf et al, 1998; 
Craven et al, 1999).  
Learning IE rules is seen as a discrimination  
task, where the concept to learn is a n-ary 
relation between arguments which correspond 
to the template fields. For example, the 
template in figure 2 can be filled by learning a 
ternary relation genic-interaction(X,Y,Z), 
where X,Y and Z are the type, the agent and 
the target of the interaction. The learning 
algorithm is provided with a set of positive and 
negative examples built from the sentences 
annotated and normalized. We use the 
relational learning algorithm, Propal (Alphonse 
et al, 2000). The appeal of using a relational 
method for this task is that it can naturally 
represent the relational structure of the 
syntactic dependencies in the normalized 
sentences and the background knowledge if 
needed, such as for instance semantic relations.  
For instance, the IE rules learned by Propal 
extract, from the following sentence :"In this 
mutant, expression of the spoIIG gene, whose 
transcription depends on both sigA and the 
phosphorylated Spo0A protein, Spo0AP, a 
major transcription factor during early stages 
of sporulation, was greatly reduced at 43 
degrees C.", successfully extract the two 
relations genic-interaction(positive, sigA, 
spoIIG) and genic-interaction(positive, 
Spo0AP, spoIIG). As preliminary experiments, 
we selected a subset of sentences as learning 
dataset, similar to this one. The performance of 
the learner evaluated by ten-fold cross-
validation is 69?6.5% of recall and 86?3.2% 
of precision. This result is encouraging, 
showing that the normalization process 
provides a good representation for learning IE 
rules with both high recall and high precision. 
6 Conclusion 
We have presented in this paper some results 
from the Caderige project. Two major issues 
are the development of a specific annotation 
editor for domain specialists and a set of 
machine learning and linguistic processing 
tools tuned for the biomedical domain.  
Current developments focus on the use of 
learning methods in the extraction process. 
These methods are introduced at different 
levels in the system architecture. A first use is 
Figure 3: the Caderige annotation editor 
48
the acquisition of domain knowledge to 
enhance the extraction phase. A second use 
concerns a dynamic adaptation of existing 
modules during the analysis according to 
specific features in a text or to specific text 
genres.  
7 References 
E. Agichtein and H. Yu (2003). Extracting 
synonymous gene and protein terms from 
biological literature. Bioinformatics, vol. 19 
Suppl.1, Oxford Press. 
E. Alphonse and C. Rouveirol (2000). Lazy 
propositionalisation for Relational  
Learning. In 14th European Conference on 
Artificial Intelligence (ECAI?00, W. Horn ed.), 
Berlin, pp. 256-260.  
S. Aubin (2003). ?valuation comparative de deux 
analyseurs produisant des relations syntaxiques. 
In workshop TALN and multilinguism. Batz-sur-
Mer. 
Y. Akane, Y. Tateisi, Y. Miyao and J. Tsujii. 
(2001). Event extraction from biomedical papers 
using a full parser. In Proceedings of the sixth 
Pacific Symposium on Biocomputing (PSB 2001). 
Hawaii, U.S.A.. pp. 408-419.  
G. Bisson, C. Nedellec, L. Ca?amero 2000. 
Designing clustering methods for ontology 
building: The Mo?K workbench. In Proceedings 
of Ontology Learning workshop (ECAI 2000), 
Berlin, 22 ao?t 2000.  
M. E. Califf, 1998. Relational Learning Techniques 
for Natural Language Extraction. Ph.D. 
Disseration, Computer Science Department, 
University of Texas, Austin, TX. AI Technical 
Report 98-276. 
N. Collier, Hyun Seok Park, Norihiro Ogata, Yuka 
Tateisi, Chikashi Nobata, Takeshi Sekimizu, 
Hisao Imai and Jun'ichi Tsujii. (1999). The 
GENIA project: corpus-based knowledge 
acquisition and information extraction from 
genome research papers. In Proceedings of the 
European Association for Computational 
Linguistics (EACL 1999). 
M. Craven et al, 1999. Constructing Biological 
Knowledge Bases by Extracting Information 
from Text Sources. ISMB 1999: 77-86 
D. Faure and C. Nedellec (1999). Knowledge 
acquisition of predicate argument structures from 
technical texts using Machine Learning: the 
system ASIUM. In EKAW'99, pp. 329-334, 
Springer-Verlag.  
D. Freitag, 1998, Multistrategy learning for 
information extraction. In Proceedings of the 
Fifteenth International Conference on Machine 
Learning, 161-169. Madison, WI: Morgan 
Kaufmann 
T. Hamon and S. Aubin (2004). Evaluating 
terminological resource coverage for relevant 
sentence selection and semantic class building. 
LIPN internal report. 
K. Fukuda, T. Tsunoda, A. Tamura, T. Takagi 
(1998). Toward information extraction : 
identifying protein names from biological papers. 
Proceedings of the Pacific Symposium of 
Biocomputing, pp. 707-718. 
Z. Harris (1951). Methods in Structural Linguistics. 
Chicago. University of Chicago Press.  
E.M. Marcotte, I. Xenarios I., and D. Eisenberg 
(2001). Mining litterature for protein-protein 
interactions. In Bioinformatics, vo. 17 n? 4, 
pp. 359-363. 
MUC (1995) Proceeding of the 6
th
 Message 
understanding Conference. Morgan Kaufmann. 
Palo Alto.  
C. N?dellec, M. Ould Abdel Vetah and P. Bessi?res 
(2001). Sentence Filtering for Information 
Extraction in Genomics: A Classification 
Problem. In Proceedings of the International 
Conference on Practical Knowledge Discovery in 
Databases (PKDD?2001), pp. 326?338. Springer 
Verlag, LNAI 2167, Freiburg. 
T. Ohta, Yuka Tateisi, Jin-Dong Kim, Hideki Mima 
and Jun'ichi Tsujii. (2001). Ontology Based 
Corpus Annotation and Tools. In Proceedings of 
the 12th Genome Informatics 2001. pp. 469--470. 
T. Ono, H. Hishigaki, A. Tanigami and T. Takagi 
(2001). Automated extraction of information on 
protein-protein interactions from the biological  
literature. Bioinformatics. vol 17, n? 2, pp. 155-
161, Oxford Press. 
B. Prasad and A. Sarkar (2000) Comparing Test-
suite based evaluation and Corpus-based 
evaluation of a wide-coverage grammar for 
English. In Using Evaluation within Human 
Language Technology. LREC. Athens.  
D. Proux, F. Rechenmann, L. Julliard, V. Pillet, B. 
Jacq (1998). Detecting gene symbols and names 
in biological texts : a first step toward pertinent 
information extraction. In Genome Informatics, 
vol. 9, pp. 72-80. 
G. Schneider (1998). A Linguistic Comparison of 
Constituency, Dependency and Link Grammar. 
PhD thesis, Institut f?r Informatik der Universit?t 
Z?rich, Switzerland. 
D. Sleator and D. Temperley (1993). Parsing 
English with a Link Grammar. In Third 
International Workshop on Parsing 
Technologies. Tilburg. Netherlands. 
D. Weissenbacher (2004). La relation de 
synonymie en g?nomique. In Recital conference. 
Fes. 
49
Proceedings of BioNLP Shared Task 2011 Workshop, pages 65?73,
Portland, Oregon, USA, 24 June, 2011. c?2011 Association for Computational Linguistics
BioNLP Shared Task 2011 ? Bacteria Gene Interactions and Renaming
Julien Jourde1, Alain-Pierre Manine2, Philippe Veber1, Kare?n Fort3, Robert Bossy1,
Erick Alphonse2, Philippe Bessie`res1
1Mathe?matique, Informatique et 2PredictiveDB 3LIPN ? Universite? Paris-Nord/
Ge?nome ? Institut National de la 16, rue Alexandre Parodi CNRS UMR7030 and
Recherche Agronomique F75010 Paris, France INIST CNRS UPS76 ? F54514
MIG INRA UR1077 {apmanine,alphonse} Vand?uvre-le`s-Nancy, France
F78352 Jouy-en-Josas, France @predictivedb.com karen.fort@inist.fr
forename.lastname@jouy.inra.fr
Abstract
We present two related tasks of the BioNLP
Shared Tasks 2011: Bacteria Gene Renam-
ing (Rename) and Bacteria Gene Interactions
(GI). We detail the objectives, the corpus spec-
ification, the evaluation metrics, and we sum-
marize the participants? results. Both issued
from PubMed scientific literature abstracts,
the Rename task aims at extracting gene name
synonyms, and the GI task aims at extracting
genic interaction events, mainly about gene
transcriptional regulations in bacteria.
1 Introduction
The extraction of biological events from scientific
literature is the most popular task in Information Ex-
traction (IE) challenges applied to molecular biol-
ogy, such as in LLL (Ne?dellec, 2005), BioCreative
Protein-Protein Interaction Task (Krallinger et al,
2008), or BioNLP (Demner-Fushman et al, 2008).
Since the BioNLP 2009 shared task (Kim et al,
2009), this field has evolved from the extraction of a
unique binary interaction relation between proteins
and/or genes towards a broader acceptation of bio-
logical events including localization and transforma-
tion (Kim et al, 2008). In the same way, the tasks
Bacteria Gene Interactions and Bacteria Gene Re-
naming deal with the extraction of various molecu-
lar events capturing the mechanisms relevant to gene
regulation in prokaryotes. The study of bacteria has
numerous applications for health, food and indus-
try, and overall, they are considered as organisms
of choice for the recent integrative approaches in
systems biology, because of their relative simplicity.
Compared to eukaryotes, they allow easier and more
in-depth analysis of biological functions and of their
related molecular mechanisms.
Processing literature on bacteria raises linguis-
tic and semantic specificities that impact text anal-
ysis. First of all, gene renaming is a frequent phe-
nomenon, especially for model bacteria. Hence, the
abundance of gene synonyms that are not morpho-
logical variants is high compared to eukaryotes. The
history of bacterial gene naming has led to drastic
amounts of homonyms and synonyms which are of-
ten missing (or worse, erroneous) in gene databases.
In particular, they often omit old gene names that
are no longer used in new publications, but that are
critical for exhaustive bibliography search. Poly-
semy makes the situation even worse, as old names
frequently happen to be reused to denote different
genes. A correct and complete gene synonym table
is crucial to biology studies, for instance when inte-
grating large scale experimental data using distinct
nomenclatures. Indeed this information can save a
lot of bibliographic research time. The Rename Task
is a new task in text-mining for biology that aims at
extracting explicit mentions of renaming relations.
It is a critical step in gene name normalization that
is needed for further extraction of biological events
such as genic interactions.
Regarding stylistics, gene and protein interactions
are not formulated in the same way for eukary-
otes and prokaryotes. Descriptions of interactions
and regulations in bacteria include more knowledge
about their molecular actors and mechanisms, com-
pared to the literature on eukaryotes. Typically in
bacteria literature, the genic regulations are more
65
likely expressed by direct binding of the protein,
while in eukaryote literature, non-genic agents re-
lated to environmental conditions are much more
frequent. The bacteria GI Task is based on (Manine
et al, 2010) which is a semantic re-annotation of the
LLL challenge corpus (Ne?dellec, 2005), where the
description of the GI events in a fine-grained rep-
resentation includes the distinction between expres-
sion, transcription and other action events, as well as
different transcription controls (e.g. regulon mem-
bership, promoter binding). The entities are not only
protein agent and gene target but extend to families,
complexes and DNA sites (binding sites, promoters)
in order to better capture the complexity of the reg-
ulation at a molecular level. The task consists in re-
lating the entities with the relevant relations.
2 Rename Task Description
The goal of the Rename task is illustrated by Figure
1. It consists in predicting renaming relations be-
tween text-bound gene names given as input. The
only type of event is Renaming where both argu-
ments are of type Gene. The event is directed, the
former and the new names are distinguished. Genes
and proteins were not distinguished because of the
high frequency of metonymy in renaming events.
The relation to predict between genes is a Renam-
ing of a former gene name into a new one. In the
example of Figure 1, YtaA, YvdP and YnzH are the
former names of three proteins renamed CotI, CotQ
and CotU, respectively.
Figure 1: Examples of relations to be extracted.
2.1 Rename Task corpus
The Rename Task corpus is a set of 1,836 PubMed
references of bacterial genetic and genomic studies,
including title and abstract. A first set of 23,000 doc-
uments was retrieved, identifying the presence of the
bacterium Bacillus subtilis in the text and/or in the
MeSH terms. B. subtilis documents are particularly
rich in renaming mentions. Many genes were re-
named in the middle of the nineties, so that the new
names matched those of the Escherichia coli homo-
logues. The 1,843 documents the most susceptible
to mention renaming were automatically filtered ac-
cording to two non exclusive criteria:
1. Either the document mentions at least two gene
synonyms as recorded in the fusion of seven B.
subtilis gene nomenclatures. This led to a set
of 703 documents.
2. Or the document contains a renaming expres-
sion from a list that we manually designed and
tested (e.g. rename, also known as). It is an ex-
tension of a previous work by (Weissenbacher,
2004). A total of 1,140 new documents not in-
cluded in the first set match this criteria.
About 70% of the documents (1,146) were kept in
the training data set. The rest was split into the de-
velopment and test sets, containing 246 and 252 doc-
uments respectively. Table 1 gives the distribution
of genes and renaming relations per corpus. Gene
names were automatically annotated in the docu-
ments with the nomenclature of B. subtilis. Gene
names involved in renaming acts were manually cu-
rated. Among the 21,878 gene mentions in the three
corpus, 680 unique names are involved in renaming
relations which represents 891 occurrences of genes.
Training + Dev. Test
Documents (1,146 + 246) 1,392 252 (15%)
Gene names 18,503 3,375 (15%)
Renamings 373 88 (24%)
Table 1: Rename Task corpus content.
2.2 Rename Task annotation and guidelines
Annotation procedure The corpus was annotated
in a joint effort of MIG/INRA and INIST/CNRS.
The reference annotation of the Rename Task cor-
pus was done in two steps, a first annotation step
by science information professionals of INIST with
MIG initial specifications, a second checking step by
people at MIG. Two annotators and a project man-
ager were in charge of the task at INIST. The docu-
ments were annotated using the Cadixe editor1. We
1http://caderige.imag.fr/Articles/
CADIXEXML-Annotation.pdf
66
provided to them detailed annotation guidelines that
were largely modified in the process. A subset of
100 documents from the first set of 703 was anno-
tated as a training session. This step was used to re-
fine the guidelines according to the methodology de-
scribed in (Bonneau-Maynard et al, 2005). Several
inter-annotator agreements coefficients were com-
puted to measure the discrepancy between annota-
tors (Fort et al, 2009). With a kappa and pi scores
(for more details on those, see (Artstein and Poesio,
2008)), the results can be considered satisfactory.
The manual analysis of the 18 discrepancies led to
enrich the annotation guidelines. The first hundreds
of documents of the second set did not mention any
renaming, leading to concentrate the annotation ef-
forts on the first set. These documents actually con-
tained renamings, but nearly exclusively concerning
other kinds of biological entities (protein domains,
molecules, cellular ultrastructures, etc.).
Guidelines In order to simplify the task, only
short names of gene/protein/groups in B. subtilis
were considered. Naming conventions set short
names of four letters long with an upper case let-
ter at the end for all genes (e.g. gerE) and the same
names with the upper case of the initial letter (e.g.
GerE) and long names for the proteins (e.g. Spore
germination protein gerE). But many irregular gene
names exist (e.g. tuf), which are considered as well.
It also happens that gene or protein name lists are
abbreviated by factorization to form a sequence. For
instance queCDEF is the abbreviation of the list of
gene names queC, queD, queE and queF. Such ag-
gregations are acceptable gene names as well. In any
case, these details were not needed by the task par-
ticipants since the corpus was provided with tagged
gene names.
Most renaming relations involve couples of the
same type, genes, proteins or aggregations. Only
18 relations link mixed couples of genes and pro-
teins. In case of ambiguity, annotators would consult
international gene databases and an internal INRA
database to help them determine whether a given
couple of names were actually synonyms.
Multiple occurrences of the same renaming rela-
tion were annotated independently, and had to be
predicted. The renaming pairs are directed, the for-
mer and the new forms have to be distinguished.
When the renaming order was not explicit in the
document, the rule was to annotate by default the
first member of the couple as the new form, and the
second one as the former form. Figure 2 presents the
most common forms of renaming.
Figure 2: Common types of relations to be extracted.
Revised annotations INIST annotations were
systematically checked by two experts in Bioinfor-
matics from INRA. Mainly, encoding relations (e.g.
the gene encoding sigma K (sigK)) that are not re-
naming cases were purged. Given the number of
ambiguous annotations, we designed a detailed ty-
pology in order to justify acceptance or rejection
decisions in seven different sub-cases hereafter pre-
sented. Three positive relations figure in Table 2,
where the underlined names are the former names
and the framed names are the new ones. Explicit re-
naming relations occur in 261 sentences, synonymy-
like relations in 349 sentences, biological proof-
based relations in 76 sentences.
Explicit renaming relation is the easiest positive
case to identify. In the example, the aggregation of
gene names ykvJKLM is clearly renamed by the au-
thors as queCDEF. Although the four genes are con-
Explicit renaming
PMID 15767583 : Genetic analysis of ykvJKLM mu-
tants in Acinetobacter confirmed that each was essen-
tial for queuosine biosynthesis, and the genes were re-
named queCDEF .
Implicit renaming
PMID 8002615 : Analysis of a suppressor mutation
ssb ( kinC ) of sur0B20 (spo0A) mutation in Bacil-
lus subtilis reveals that kinC encodes a histidine pro-
tein kinase.
Biological proof
PMID 1744050 : DNA sequencing established that
spoIIIF and spoVB are a single monocistronic locus
encoding a 518-amino-acid polypeptide with features
of an integral membrane protein.
Table 2: Positive examples of the Rename Task.
67
catenated, there is no evidence mentioned of them
acting as an operon. Furthermore, despite the con-
text involving mutants of Acinetobacter, the aggre-
gation belongs correctly to B. subtilis.
Implicit renaming is an asymmetric relation
since one of the synonyms is intended to replace the
other one in future uses. The example presents two
renaming relations between former names ssb and
spo0A, and new names kinC and sur0B20, respec-
tively. The renaming relation between ssb and kinC
has a different orientation due to additional informa-
tion in the reference. Like in the preceding example,
the renaming is a consequence of a genetic mutation
experiment. Mutation names represent an important
transversal issue that is discussed below.
Biological proof is a renaming relation induced
by an explicit scientific conclusion while the renam-
ing is not, as in the example where experiments re-
veal that two loci spoIIIF and spoVB are in fact the
same one and then become synonyms. Terms such
as ?allelic to? or ?identical to? usually qualify such
conclusions. Predicting biological proof-based rela-
tions requires some biological modeling.
The next three cases are negative (Table 3). Un-
derlined gene and protein names are involved in a
relation which is not a renaming relation.
Protein encoding relation occurs between a gene
and the protein it codes for. Some mentions may
look like renaming relations. The example presents
the gene yeaC coding for MoxR. No member of the
couple is expected to replace the other one.
Homology measures the similarity between gene
or protein sequences. Most of the homology men-
tions involve genes or proteins from different species
Protein encoding
PMID 8969499: The putative products of ORFs yeaB
(Czd protein), yeaC (MoxR), yebA (CNG-channel and
cGMP-channel proteins from eukaryotes),
Genetic homology
PMID 10619015 : Dynamic movement of the ParA-
like Soj protein of B. subtilis and its dual role in nu-
cleoid organization and developmental regulation.
Operon | Regulon | Family
PMID 3127379 : Three promoters direct transcription
of the sigA (rpoD) operon in Bacillus subtilis.
Table 3: Negative examples of the Rename Task.
(orthologues). The others compare known gene or
protein sequences of the same species (paralogues).
This may be misleading since the similarity men-
tion may look like biological proof-based relations,
as between ParA and Soj in Table 3.
Operon, regulon or family renaming involves
objects that may look like genes, proteins or sim-
ple aggregations of gene or protein names but that
are perceptibly different. The objects represent more
than one gene or protein and the renaming does not
necessarily affect all of them. More problematic,
their name may be the same as one of the genes or
proteins they contain, as in the example where sigA
and rpoD are operons but are also known as gene
names. Here, sigA (and so rpoD) represents at least
two different genes. For the sake of clarity, oper-
ons, regulons and families are rejected, even if all
the genes are clearly named, as in an aggregation.
The last point concerns mutation which are fre-
quent in Microbiology for revealing gene pheno-
types. They carry information about the original
gene names (e.g., rvtA11 is a mutant name created
by adding 11 to rvtA). But partial names cannot be
partially annotated, that is to say, the original part
(rvtA) should not be annotated in the mutation name
(rvtA11). Most of these names are local names, and
should not be annotated because of their restricted
scope. It may happen so that the mutation name
is registered as a synonym in several international
databases. To avoid inconsistencies, all renamings
involving a mutation referenced in a database were
accepted, and only biological proof-based and ex-
plicit renamings involving a strict non-null unrefer-
enced mutation (a null mutation corresponds to a to-
tal suppression of a gene) were accepted.
2.3 Rename Task evaluation procedure
The evaluation of the Rename task is given in terms
of recall, precision and F-score of renaming rela-
tions. Two set of scores are given: the first set is
computed by enforcing strict direction of renaming
relations, the second set is computed with relaxed
direction. Since the relaxed score takes into ac-
count renaming relations even if the arguments are
inverted, it will necessarily be greater or equal than
the strict score. The participant score is the relaxed
score, the strict score is given for information. Re-
laxed scores are informative with respect to the ap-
68
plication goal. The motivation of the Rename task
is to keep bacteria gene synonyms tables up to date.
The choice of the canonical name among synonyms
for denoting a gene is done by the bacteriology com-
munity, and it may be independent of the anteriority
or novelty of the name. The annotation of the ref-
erence corpus showed that the direction was not al-
ways decidable, even for a human reader. Thus, it
would have been unfair to evaluate systems on the
basis of unsure information.
2.4 Results of the Rename Task participants
Final submissions were received from three teams,
the University of Turku (Uturku), the University of
Concordia (Concordia) and the Bibliome team from
MIG/INRA. Their results are summarized in Table
4. The ranking order is given by the overall F-score
for relations with relaxed argument order.
Team Prec. Recall F-score
Univ. of Turku 95.9 79.6 87.0
Concordia Univ. 74.4 65.9 69.9
INRA 57.0 73.9 64.4
Table 4: Participant scores at the Rename Task.
Uturku achieved the best F-score with a very high
precision and a high recall. Concordia achieved the
second F-score with balanced precisions and recalls.
Bibliome is five points behind with a better recall
but much lower precision. Both UTurku and Con-
cordia predictions rely on dependencies (Charniak-
Johnson and Stanford respectively, using McClosky
model), whereas Bibliome predictions rely on bag of
words. This demonstrates the high value of depen-
dency parsing for this task, in particular for the pre-
cision of predictions. We notice that UTurku system
uses machine learning (SVM) and Concordia uses
rules based on trigger words. The good results of
UTurku confirms the hypothesis that gene renam-
ing citations are highly regular in scientific litera-
ture. The most frequently missed renamings belong
to the Biological Proof category (see Table 2). This
is expected because the renaming is formulated as a
reasoning where the conclusion is only implicit.
2.5 Discussion
The very high score of Uturku method leads us to
conclude that the task can be considered as solved
by a linguistic-based approach. Whereas Bib-
liome used an extensive nomenclature considered
as exhaustive and sentence filtering using a SVM,
Uturku used only two nomenclatures in synergy but
with more sophisticated linguistic-based methods,
in particular syntactic analyses. Bibliome methods
showed that a too high dependence to nomenclatures
may decrease scores if they contain compromised
data. However, the use of an extensive nomencla-
ture as done by Bibliome may complement Uturku
approach and improve recall. It is also interesting
that both systems do not manage renamings cross-
ing sentence boundaries.
The good results of the renaming task will be ex-
ploited to keep synonym gene lists up to date with
extensive bibliography mining. In particular this
will contribute to enriching SubtiWiki, a collabora-
tive annotation effort on B. subtilis (Flo?rez et al,
2009; Lammers et al, 2010).
3 Gene Interactions Task description
The goal of the Bacteria GI Task is illustrated by
Figure 3. The genes cotB and cotC are related to
their two promoters, not named here, by the rela-
tion PromoterOf. The protein GerE is related to
these promoters by the relation BindTo. As a con-
sequence, GerE is related to cotB and cotC by an In-
teraction relation. According to (Kim et al, 2008),
the need to define specialized relations replacing one
unique and general interaction relation was raised in
(Manine et al, 2009) for extracting genic interac-
tions from text. An ontology describes relations and
entities (Manine et al, 2008) catching a model of
gene transcription to which biologists implicitly re-
fer in their publications. Therefore, the ontology is
mainly oriented towards the description of a struc-
tural model of genes, with molecular mechanisms
of their transcription and associated regulations.
The corpus roughly contains three kinds of genic
Figure 3: Examples of relations to be extracted.
69
interaction mentions, namely regulations, regulon
membership and binding. The first case corresponds
to interactions the mechanism of which is not explic-
itly given in the text. The mention only tells that the
transcription of a given gene is influenced by a given
protein, either positively (activation), negatively (in-
hibition) or in an unspecified way. The second kind
of genic interaction mention (regulon membership)
basically conveys the same information, using the
regulon term/concept. The regulon of a gene is the
set of genes that it controls. In that case, the interac-
tion is expressed by saying that a gene is a member
of some regulon. The third and last kind of mention
provides with more mechanistic details on a regula-
tion, since it describes the binding of a protein near
the promoter of a target gene. This motivates the in-
troduction of Promoter and Site entities, which cor-
respond to DNA regions. It is thus possible to extract
the architecture of a regulatory DNA region, linking
a protein agent to its gene target (see Figure 3).
The set of entity types is divided into two main
groups, namely 10 genic entities and 3 kinds of ac-
tion (Table 5). Genic entities represent biological
objects like a gene, a group of genes or a gene prod-
uct. In particular, a GeneComplex annotation corre-
sponds to an operon, which is a group of genes that
are contiguous in the genome and under the control
of the same promoter. The annotation GeneFamily
is used to denote either genes involved in the same
biological function or genes with sequence homolo-
gies. More importantly, PolymeraseComplex anno-
tations correspond to the protein complex that is re-
sponsible for the transcription of genes. This com-
plex includes several subunits (components), com-
bined with a sigma factor, that recognizes specific
promoters on the DNA sequence.
The second group of entities are phrases express-
ing either molecular processes (e.g. sequestration,
dephosphorylation, etc.) or the molecular state of
the bacteria (e.g. presence, activity or level of a pro-
tein). They represent some kind of action that can
be performed on a genic entity. Note that transcrip-
tion and expression events were tagged as specific
actions, because they play a specific part in certain
relations (see below).
The annotation of entities and actions was pro-
vided to the participants, and the task consisted in
extracting the relations listed in Table 6.
Name Example
Gene cotA
GeneComplex sigX-ypuN
GeneFamily class III heat shock genes
GeneProduct yvyD gene product
Protein CotA
PolymeraseComplex SigK RNA polymerase
ProteinFamily DNA-binding protein
Site upstream site
Promoter promoter regions
Regulon regulon
Action activity | level | presence
Expression expression
Transcription transcription
Table 5: List of molecular entities and actions in GI.
Name Example
ActionTarget expression of yvyD
Interaction ComK negatively regulates
degR expression
RegulonDependence sigmaB regulon
RegulonMember yvyD is member of sigmaB
regulon
BindTo GerE adheres to the pro-
moter
SiteOf -35 sequence of the pro-
moter
PromoterOf the araE promoter
PromoterDependence GerE-controlled promoter
TranscriptionFrom transcription from the up-
stream site
TranscriptionBy transcription of cotD by
sigmaK RNA polymerase
Table 6: List of relations in GI.
The relations are binary and directed, and rely the
entities defined above. The three kinds of interac-
tions are represented with an Interaction annotation,
linking an agent to its target. The other relations
provide additional details on the regulation, like ele-
mentary components involved in the reaction (sites,
promoters) and contextual information (mainly pro-
vided by the ActionTarget relations). A formal def-
inition of relations and relation argument types can
be found on the Bacteria GI Task Web page.
3.1 Bacteria Gene Interactions corpus
The source of the Bacteria GI Task corpus is a set
of PubMed abstracts mainly dealing with the tran-
70
scription of genes in Bacillus subtilis. The semantic
annotation, derived from the ontology of (Manine et
al., 2008), contains 10 molecular entities, 3 different
actions, and 10 specialized relations. This is applied
to 162 sentences from the LLL set (Ne?dellec, 2005),
which are provided with manually checked linguis-
tic annotations (segmentation, lemmatization, syn-
tactic dependencies). The corpus was split into 105
sentences for training, 15 for development and 42
for test. Table 7 gives the distribution of the entities
and actions per corpus and Table 8 gives the distri-
bution of the relations per corpus.
3.2 Annotation procedures and guidelines
The semantic annotation scheme was developed by
two annotators through a series of independent an-
notations of the corpus, followed by reconciliation
steps, which could involve concerted modifications
(Manine et al, 2010). As a third and final stage, the
Entity or action Train. + Dev. Test
Documents (105+15) 120 42
Protein 219 85
Gene 173 56
Transcription 53 21
Promoter 49 10
Action 45 22
PolymeraseComplex 43 14
Expression 29 6
Site 22 8
GeneComplex 19 4
ProteinFamily 12 3
Regulon 11 2
GeneProduct 10 3
GeneFamily 6 5
Table 7: Distribution of entities and actions in GI.
Relation Train. + Dev. Test
Interaction 208 64
ActionTarget 173 47
PromoterOf 44 8
BindTo 39 4
PromoterDependence 36 4
TranscriptionBy 36 8
SiteOf 23 6
RegulonMember 17 2
TranscriptionFrom 14 2
RegulonDependence 12 1
Table 8: Distribution of relations in GI.
corpus was reviewed and the annotation simplified
to make it more appropriate to the contest. The final
annotation contains 748 relations distributed in nine
categories, 146 of them belonging to the test set.
The annotation scheme was generally well suited
to accurately represent the meaning of the sentences
in the corpus, with one notable exception. In the cor-
pus, there is a common phrasing telling that a pro-
tein P regulates the transcription of a gene G by a
given sigma factor S. In that case, the only anno-
tated interactions are between the couples (P, G) and
(S, G). This representation is not completely satis-
factory, and a ternary relation involving P, S and G
would have been more adequate.
Additional specific rules were needed to cope
with linguistic issues. First, when the argument of a
relation had coreferences, the relation was repeated
for each maximally precise coreference of the argu-
ment. Second, in case of a conjunction like ?sig-
maA and sigmaX holoenzymes?, there should ide-
ally be two entities (namely ?sigmaA holoenzyme?
and ?sigmaX holoenzyme?); however, this is not
easy to represent using the BioNLP format. In this
situation, we grouped the two entities into a single
one. These cases were rare and unlikely affected the
feasibility of the task, since entities were provided
in the test set.
3.3 Gene Interactions evaluation procedure
The training and development corpora with the ref-
erence annotations were made available to partici-
pants by December, 1st on the BioNLP shared Task
pages together with evaluation software. The test
corpus with the entity annotations has been made
available by March, 1st. The participants sent the
predicted annotations to the BioNLP shared Task
organizers by March, 10th. The evaluation results
were computed and provided to the participants and
on the Web site the same day. The participants are
evaluated and ranked according to two scores: F-
score for all event types together, and F-score for
the Interaction event type. In order for a predicted
event to count as a hit, both arguments must be the
same as in the reference in the right order and the
event type must be the same as in the reference.
71
3.4 Results of GI Task participants
There was only one participant, whose results are
shown in Tables 9 and 10. Some relations were
not significantly represented in the test set and thus
the corresponding results should be considered with
caution. This is the case for RegulonMember and
TranscriptionFrom, only represented two times each
in the test. The lowest recall, 17%, obtained for the
SiteOf relation is explained by its low representa-
tion in the corpus: most of the test errors come from
a difficult sentence with coreferences.
The recall of 56% for the Interaction relation cer-
tainly illustrates the heterogeneity of this category,
gathering mentions of interactions at large, as well
as precise descriptions of gene regulations. For in-
stance, Figure 4 shows a complex instance where all
of the interactions were missed. Surprisingly, we
also found false negatives in rather trivial examples
(?ykuD was transcribed by SigK RNA polymerase
from T4 of sporulation.?). Uturku used an SVM-
based approach for extraction, and it is thus delicate
to account for the false negatives in a simple and
concise way.
Event U. Turku scores
Global Precision 85
Global Recall 71
Global F-score 77
Interaction Precision 75
Interaction Recall 56
Interaction F-score 64
Table 9: University of Turku global scores.
Event Prec. Rec. F-score
Global 85 71 77
ActionTarget 94 92 93
BindTo 75 75 75
Interaction 75 56 64
PromoterDependence 100 100 100
PromoterOf 100 100 100
RegulonDependence 100 100 100
RegulonMember 100 50 67
SiteOf 100 17 29
TranscriptionBy 67 50 57
TranscriptionFrom 100 100 100
Table 10: University of Turku scores for each relation.
Figure 4: Examples of three missed interactions.
3.5 Discussion
The GI corpus was previously used in a relation
extraction work (Manine et al 2009) based on In-
ductive Logic Programming (Muggleton and Raedt,
1994). However a direct comparison of the results
is not appropriate here since the annotations were
partially revised, and the evaluation setting was dif-
ferent (leave-one-out in Manine?s work, test set in
the challenge).
Nevertheless, we note similar tendencies if we
compare relative results between relations. In partic-
ular, it was also found in Manine?s paper that SiteOf,
TranscriptionBy and Interaction are the most diffi-
cult relations to extract. It is also worth to mention
that both approaches rely on syntactic dependencies,
and use the curated dependencies provided in the
corpus. Interestingly, the approach by the University
of Turku reports a slightly lower F-measure with de-
pendencies calculated by the Charniak parser (about
1%, personal communication). This information is
especially important in order to consider a produc-
tion setting.
4 Conclusion
The quality of results for both challenges suggests
that current methods are mature enough to be used
in semi-automatic strategies for genome annotation,
where they could efficiently assist biological experts
involved in collaborative annotation efforts (Lam-
mers et al, 2010). However, the false positive rate,
notably for the Interaction relation, is still too high
for the extraction results to be used as a reliable
source of information without a curation step.
Acknowlegments
We thank Franc?oise Tisserand and Bernard Talercio
(INIST) for their work on the Rename corpus, and
the QUAERO Programme funded by OSEO (French
agency for innovation) for its support.
72
References
Artstein R., Poesio M. (2008). Inter-coder agreement
for Computational Linguistics. Computational Lin-
guistics, 34(4):555-96.
Bjo?rne J., Heimonen J., Ginter F., Airola A., Pahikkala
T., Salakoski T. (2009). Extracting complex biological
events with rich graph-based feature sets. BioNLP?09
Proc. Workshop Current Trends in Biomedical Natural
Language Processing: Shared Task, pp. 10-18.
Bonneau-Maynard H., Rosset S., Ayache C., Kuhn A.,
Mostefa D. (2005). Semantic annotation of the French
Media Dialog Corpus. Interspeech-2005, pp. 3457-60.
Demner-Fushman D., Ananiadou S., Cohen K.B., Pestian
J., Tsujii J., Webber B. (2008). Themes in biomedical
natural language processing: BioNLP08. BMC Bioin-
formatics, 9(Suppl. 11):S1.
Flo?rez L.A., Roppel S.F., Schmeisky A.G., Lammers
C.R., Stu?lke J. (2009). A community-curated con-
sensual annotation that is continuously updated: The
Bacillus subtilis centred wiki SubtiWiki. Database,
2009:bap012.
Fort K., Franc?ois C., Ghribi M. (2010). ?Evaluer des an-
notations manuelles disperse?es : les coefficients sont-
ils suffisants pour estimer l?accord inter-annotateurs ?
17e Conf. Traitement Automatique des Langues Na-
turelles (TALN 2010).
Kim J.D., Ohta T., Tsujii J. (2008) Corpus annotation for
mining biomedical events from literature. BMC Bioin-
formatics, 9:10.
Kim J.D., Ohta T., Pyysalo S., Kano Y., Tsujii J. (2009).
Overview of BioNLP?09 shared task on event ex-
traction. BioNLP?09 Proc. Workshop Current Trends
in Biomedical Natural Language Processing: Shared
Task, pp. 1-9.
Krallinger M., Leitner F., Rodriguez-Penagos C., Va-
lencia A. (2008). Overview of the protein-protein in-
teraction annotation extraction task of BioCreative II.
Genome Biology, 9(Suppl. 2):S4.
Lammers C.R., Flo?rez L.A., Schmeisky A.G., Roppel
S.F., Ma?der U., Hamoen L., Stu?lke J. (2010). Con-
necting parts with processes: SubtiWiki and Subti-
Pathways integrate gene and pathway annotation for
Bacillus subtilis. Microbiology, 156(3):849-59.
Manine A.P., Alphonse E., Bessie`res P. (2008). Informa-
tion extraction as an ontology population task and its
application to genic interactions. 20th IEEE Int. Conf.
Tools with Artificial Intelligence (ICTAI?08), pp. 74-
81.
Manine A.P., Alphonse E., Bessie`res P. (2009). Learn-
ing ontological rules to extract multiple relations of
genic interactions from text. Int. J. Medical Informat-
ics, 78(12):e31-8.
Manine A.P., Alphonse E., Bessie`res P. (2010). Extrac-
tion of genic interactions with the recursive logical the-
ory of an ontology. Lecture Notes in Computer Sci-
ences, 6008:549-63.
Muggleton S., Raedt L.D. (1994) Inductive Logic Pro-
gramming: Theory and methods. J. Logic Program-
ming, 19-20:629-79.
Ne?dellec C. (2005). Learning Language in Logic ? Genic
Interaction Extraction Challenge. Proc. 4th Learning
Language in Logic Workshop (LLL?05), pp. 31-7.
Weissenbacher, D. (2004). La relation de synonymie en
Ge?nomique. RECITAL 2004 Conference.
73
