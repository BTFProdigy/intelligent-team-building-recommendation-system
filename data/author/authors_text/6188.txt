Proceedings of the Third Workshop on Statistical Machine Translation, pages 171?174,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
MATREX: the DCU MT System for WMT 2008
John Tinsley, Yanjun Ma, Sylwia Ozdowska, Andy Way
National Centre for Language Technology
Dublin City University
Dublin 9, Ireland
{jtinsley, yma, sozdowska, away}@computing.dcu.ie
Abstract
In this paper, we give a description of the ma-
chine translation system developed at DCU
that was used for our participation in the eval-
uation campaign of the Third Workshop on
Statistical Machine Translation at ACL 2008.
We describe the modular design of our data-
driven MT system with particular focus on
the components used in this participation. We
also describe some of the significant modules
which were unused in this task.
We participated in the EuroParl task for the
following translation directions: Spanish?
English and French?English, in which we em-
ployed our hybrid EBMT-SMT architecture to
translate. We also participated in the Czech?
English News and News Commentary tasks
which represented a previously untested lan-
guage pair for our system. We report results
on the provided development and test sets.
1 Introduction
In this paper, we present the Data-Driven MT sys-
tems developed at DCU, MATREX (Machine Trans-
lation using Examples). This system is a hybrid sys-
tem which exploits EBMT and SMT techniques to
build a combined translation model.
We participated in both the French?English and
Spanish?English EuroParl tasks. In these two tasks,
we monolingually chunk both source and target
sides of the dataset using a marker-based chunker
(Gough and Way, 2004). We then align these chunks
using a dynamic programming, edit-distance-style
algorithm and combine them with phrase-based
SMT-style chunks into a single translation model.
We also participated in the Czech?English News
Commentary and News tasks. This language pair
represents a new challenge for our system and pro-
vides a good test of its flexibility.
The remainder of this paper is organised as fol-
lows: Section 2 details the various components of
our system, in particular the chunking and chunk
alignment strategies used for the shared task. In Sec-
tion 3, we outline the complete system setup for the
shared task, and in Section 4 we give some results
and discussion thereof.
2 The MATREX System
The MATREX system is a modular hybrid data-
driven MT system, built following established De-
sign Patterns, which exploits aspects of both the
EBMT and SMT paradigms. It consists of a num-
ber of extendible and re-implementable modules, the
most significant of which are:
? Word Alignment Module: outputs a set of word
alignments given a parallel corpus,
? Chunking Module: outputs a set of chunks
given an input corpus,
? Chunk Alignment Module: outputs aligned
chunk pairs given source and target chunks ex-
tracted from comparable corpora,
? Decoder: returns optimal translation given a
set of aligned sentence, chunk/phrase and word
pairs.
In some cases, these modules may comprise
wrappers around pre-existing software. For exam-
ple, our system configuration for the shared task
incorporates a wrapper around GIZA++ (Och and
Ney, 2003) for word alignment and a wrapper
around Moses (Koehn et al, 2007) for decoding. It
171
should be noted, however, that the complete system
is not limited to using only these specific module
choices. The following subsections describe those
modules unique to our system.
2.1 Marker-Based Chunking
The chunking module used for the shared task is
based on the Marker Hypothesis, a psycholinguistic
constraint which posits that all languages are marked
for surface syntax by a specific closed set of lex-
emes or morphemes which signify context. Using a
set of closed-class (or ?marker?) words for a particu-
lar language, such as determiners, prepositions, con-
junctions and pronouns, sentences are segmented
into chunks. A chunk is created at each new occur-
rence of a marker word with the restriction that each
chunk must contain at least one content (or non-
marker) word. An example of this chunking strategy
for English and Spanish is given in Figure 1.
2.2 Chunk Alignment
In order to align the chunks obtained by the chunk-
ing procedures described in Section 2.1, we make
use of an ?edit-distance-style? dynamic program-
ming alignment algorithm.
In the following, a denotes an alignment between
a target sequence e consisting of I chunks and a
source sequence f consisting of J chunks. Given
these sequences of chunks, we are looking for the
most likely alignment a?:
a? = argmax
a
P(a|e, f) = argmax
a
P(a, e|f).
We first consider alignments such as those ob-
tained by an edit-distance algorithm, i.e.
a = (t1, s1)(t2, s2) . . . (tn, sn),
with ?k ? J1, nK, tk ? J0, IK and sk ? J0, JK, and
?k < k?:
tk ? tk? or tk? = 0,
sk ? sk? or sk? = 0,
where tk = 0 (resp. sk = 0) denotes a non-aligned
target (resp. source) chunk.
We then assume the following model:
P(a, e|f) = ?kP(tk, sk, e|f) = ?kP(etk |fsk),
where P(e0|fj) (resp. P(ei|f0)) denotes an ?inser-
tion? (resp. ?deletion?) probability.
Assuming that the parameters P(etk |fsk) are
known, the most likely alignment is computed by
a simple dynamic-programming algorithm.1
Instead of using an Expectation-Maximization al-
gorithm to estimate these parameters, as commonly
done when performing word alignment (Brown
et al, 1993; Och and Ney, 2003), we directly com-
pute these parameters by relying on the information
contained within the chunks. The conditional prob-
ability P(etk |fsk) can be computed in several ways.
In our experiments, we have considered three main
sources of knowledge: (i) word-to-word translation
probabilities, (ii) word-to-word cognates, and (iii)
chunk labels. These sources of knowledge are com-
bined in a log-linear framework. The weights of
the log-linear model are not optimised; we experi-
mented with different sets of parameters and did not
find any significant difference as long as the weights
stay in the interval [0.5 ? 1.5]. Outside this inter-
val, the quality of the model decreases. More details
about the combination of knowledge sources can be
found in (Stroppa and Way, 2006).
2.3 Unused Modules
There are numerous other features available in our
system which, due to time constraints, were not ex-
ploited for the purposes of the shared task. They
include:
? Word packing (Ma et al, 2007): a bilingually
motivated packing of words that changes the
basic unit of the alignment process in order to
simplify word alignment.
? Supertagging (Hassan et al, 2007b): incorpo-
rating lexical syntactic descriptions, in the form
of supertags, to the language model and target
side of the translation model in order to better
inform decoding.
? Source-context features (Stroppa et al, 2007):
use memory-based classification to incorporate
context-informed features on the source side of
the translation model.
? Treebank-based phrase extraction (Tinsley
et al, 2007): extract word and phrase align-
ments based on linguistically informed sub-
sentential alignment of the parallel data.
1This algorithm is actually a classical edit-distance al-
gorithm in which distances are replaced by opposite-log-
conditional probabilities.
172
English: [I voted] [in favour] [of the strategy presented] [by the council] [concerning relations] [with
Mediterranean countries]
Spanish: [He votado] [a favor] [de la estrategia presentada] [por el consejo] [relativa las relaciones]
[con los pa??ses mediterrane?os]
Figure 1: English and Spanish Marker-Based chunking
Filter criteria es?en fr?en cz?en
Initial Total 1258778 1288074 1096941
Blank Lines 5632 4200 2
Length 6794 8361 2922
Fertility 120 82 1672
Final Total 1246234 1275432 1092345
Table 1: Summary of pre-processing on training data.
3 Shared Task Setup
The following section describes the system setup
using the Spanish?English and French?English Eu-
roParl, and Czech?English CzEng training data.
3.1 Pre-processing
For all tasks we initially tokenised the data (Czech
data was already tokenised) and removed blank
lines. We then filtered out sentence pairs based on
length (>100 words) and fertility (9:1 word ratio).
Finally we lowercased the data. Details of this pre-
processing are given in Table 1.
3.2 System Configuration
As mentioned in Section 2, our word alignment
module employs a wrapper around GIZA++.
We built a 5-gram language model based the tar-
get side of the training data. This was done using
the SRI Language Modelling toolkit (Stolcke, 2002)
employing linear interpolation and modified Kneser-
Ney discounting (Chen and Goodman, 1996).
Our phrase-table comprised a combination of
marker-based chunk pairs2, extracted as described
in Sections 2.1 and 2.2, and word-alignment-based
phrase pairs extracted using the ?grow-diag-final?
method of Koehn et al (2003), with a maximum
phrase length of 7 words. Phrase translation proba-
bilities were estimated by relative frequency over all
phrase pairs and were combined with other features,
2This module was omitted from the Czech?English system
as we have yet to verify whether marker-based chunking is ap-
propriate for Czech.
System BLEU (-EBMT) BLEU (+EBMT)
es?en 0.3283 0.3287
fr?en 0.2768 0.2770
cz?en 0.2235 -
Table 2: Summary of results on developments sets de-
vtest2006 for EuroParl tasks and nc-test2007 for cz?en
tasks.
System BLEU (-EBMT) BLEU (+EBMT)
es?en 0.3274 0.3285
fr?en 0.3163 0.3174
cz?en (news) 0.1458 -
cz?en (nc) 0.2217 -
Table 3: Summary of results on 2008 test data.
such as a reordering model, in a log-linear combina-
tion of functions.
We tuned our system on the development set de-
vtest2006 for the EuroParl tasks and on nc-test2007
for Czech?English, using minimum error-rate train-
ing (Och, 2003) to optimise BLEU score.
Finally, we carried out decoding using a wrapper
around the Moses decoder.
3.3 Post-processing
Case restoration was carried out by training the sys-
tem outlined above - without the EBMT chunk ex-
traction - to translate from the lowercased version
of the applicable target language training data to the
truecased version. We have previously shown this
approach to be very effective for both case and punc-
tuation restoration (Hassan et al, 2007a). The trans-
lations were then detokenised.
4 Results
The system output is evaluated with respect to
BLEU score. Results on the development sets and
test sets for each task are given in Tables 2 and 3
respectively, where ?-EBMT? indicates that EBMT
chunk modules were not used, and ?+EBMT? indi-
cates that they were used.
173
4.1 Discussion
Those configurations which incorporated the EBMT
chunks improved slightly over those which did not.
Groves (2007) has shown previously that combin-
ing EBMT and SMT translation models can lead to
considerable improvement over the baseline systems
from which they are derived. The results achieved
here lead us to believe that on such a large scale
there may be a more effective way to incorporate the
EBMT chunks.
Previous work has shown the EBMT chunks to
have higher precision than their SMT counterparts,
but they lack sufficient recall when used in isola-
tion (Groves, 2007). We believe that increasing their
influence in the translation model may lead to im-
proved translation accuracy. One experiment to this
effect would be to add the EBMT chunks as a sep-
arate phrase table in the log-linear model and allow
the decoder to chose when to use them.
Finally, we intend to exploit the unused modules
of the system in future experiments to investigate
their effects on the tasks presented here.
Acknowledgments
This work is supported by Science Foundation Ireland
(grant nos. 05/RF/CMS064 and OS/IN/1732). Thanks
also to the reviewers for their insightful comments and
suggestions.
References
Brown, P. F., Pietra, S. A. D., Pietra, V. J. D., and Mercer,
R. L. (1993). The mathematics of statistical machine
translation: Parameter estimation. Computational Lin-
guistics, 19(2):263?311.
Chen, S. F. and Goodman, J. (1996). An Empirical Study
of Smoothing Techniques for Language Modeling. In
Proceedings of the Thirty-Fourth Annual Meeting of
the Association for Computational Linguistics, pages
310?318, San Francisco, CA.
Gough, N. and Way, A. (2004). Robust Large-Scale
EBMT with Marker-Based Segmentation. In Proceed-
ings of the 10th International Conference on Theoreti-
cal and Methodological Issues in Machine Translation
(TMI-04), pages 95?104, Baltimore, MD.
Groves, D. (2007). Hybrid Data-Driven Models of Ma-
chine Translation. PhD thesis, Dublin City University,
Dublin, Ireland.
Hassan, H., Ma, Y., and Way, A. (2007a). MATREX: the
DCU Machine Translation System for IWSLT 2007. In
Proceedings of the International Workshop on Spoken
Language Translation, pages 69?75, Trento, Italy.
Hassan, H., Sima?an, K., and Way, A. (2007b). Su-
pertagged Phrase-based Statistical Machine Transla-
tion. In Proceedings of the 45th Annual Meeting of the
Association for Computational Linguistics (ACL?07),
pages 288?295, Prague, Czech Republic.
Koehn, P., Hoang, H., Birch, A., Callison-Burch, C., Fed-
erico, M., Bertoldi, N., Cowan, B., Shen, W., Moran,
C., Zens, R., Dyer, C., Bojar, O., Constantin, A., and
Herbst, E. (2007). Moses: Open Source Toolkit for
Statistical Machine Translation. In Annual Meeting of
the Association for Computational Linguistics (ACL),
demonstration session, pages 177?180, Prague, Czech
Republic.
Koehn, P., Och, F. J., and Marcu, D. (2003). Statisti-
cal Phrase-Based Translation. In Proceedings of the
2003 Conference of the North American Chapter of the
Association for Computational Linguistics on Human
Language Technology (NAACL ?03), pages 48?54, Ed-
monton, Canada.
Ma, Y., Stroppa, N., and Way, A. (2007). Boostrap-
ping Word Alignment via Word Packing. In Proceed-
ings of the 45th Annual Meeting of the Association for
Computational Linguistics (ACL?07), pages 304?311,
Prague, Czech Republic.
Och, F. (2003). Minimum error rate training in statistical
machine translation. In Proceedings of the 41st Annual
Meeting of the Association for Computational Linguis-
tics (ACL), pages 160?167, Sapporo, Japan., Sapporo,
Japan.
Och, F. J. and Ney, H. (2003). A Systematic Comparison
of Various Statistical Alignment Models. Computa-
tional Linguistics, 29(1):19?51.
Stolcke, A. (2002). SRILM - An Extensible Language
Modeling Toolkit. In Proceedings of the Interna-
tional Conference Spoken Language Processing, Den-
ver, CO.
Stroppa, N., van den Bosch, A., and Way, A. (2007).
Exploiting Source Similarity for SMT using Context-
Informed Features. In Proceedings of the 11th Interna-
tional Conference on Theoretical and Methodological
Issues in Machine Translation (TMI-07), pages 231?
240, Sko?vde, Sweden.
Stroppa, N. and Way, A. (2006). MaTrEx: the DCU ma-
chine translation system for IWSLT 2006. In Proceed-
ings of the International Workshop on Spoken Lan-
guage Translation, pages 31?36, Kyoto, Japan.
Tinsley, J., Hearne, M., and Way, A. (2007). Exploiting
Parallel Treebanks to Improve Phrase-Based Statisti-
cal Machine Translation. In Proceedings of the Sixth
International Workshop on Treebanks and Linguistic
Theories (TLT-07), pages 175?187, Bergen, Norway.
174
Proceedings of the Second ACL Workshop on Syntax and Structure in Statistical Translation (SSST-2), pages 69?77,
ACL-08: HLT, Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
Improving Word Alignment Using Syntactic Dependencies
Yanjun Ma1 Sylwia Ozdowska1 Yanli Sun2 Andy Way1
1 School of Computing, Dublin City University, Dublin, Ireland
{yma,sozdowska,away}@computing.dcu.ie
2 School of Applied Language and Intercultural Studies,
Dublin City University, Dublin, Ireland
yanli.sun2@mail.dcu.ie
Abstract
We introduce a word alignment framework
that facilitates the incorporation of syntax en-
coded in bilingual dependency tree pairs. Our
model consists of two sub-models: an anchor
word alignment model which aims to find a set
of high-precision anchor links and a syntax-
enhanced word alignment model which fo-
cuses on aligning the remaining words relying
on dependency information invoked by the ac-
quired anchor links. We show that our syntax-
enhanced word alignment approach leads to a
10.32% and 5.57% relative decrease in align-
ment error rate compared to a generative word
alignment model and a syntax-proof discrim-
inative word alignment model respectively.
Furthermore, our approach is evaluated ex-
trinsically using a phrase-based statistical ma-
chine translation system. The results show
that SMT systems based on our word align-
ment approach tend to generate shorter out-
puts. Without length penalty, using our word
alignments yields statistically significant im-
provement in Chinese?English machine trans-
lation in comparison with the baseline word
alignment.
1 Introduction
Automatic word alignment can be defined as the
problem of determining translational correspon-
dences at word level given a parallel corpus of
aligned sentences. Bilingual word alignment is a
fundamental component of most approaches to sta-
tistical machine translation (SMT). Dominant ap-
proaches to word alignment can be classified into
two main schools: generative and discriminative
word alignment models.
Generative word alignment models, initially de-
veloped at IBM (Brown et al, 1993), and then
augmented by an HMM-based model (Vogel et al,
1996), have provided powerful modeling capability
for word alignment. However, it is very difficult to
incorporate new features into these models. Dis-
criminative word alignment models, based on dis-
criminative training of a set of features (Liu et al,
2005; Moore, 2005), on the other hand, are more
flexible to incorporate new features, and feature se-
lection is essential to the performance of the system.
Syntactic annotation of bilingual corpora, which
can be obtained more efficiently and accurately with
the advances in monolingual language processing,
is a potential information source for word align-
ment tasks. For example, Part-of-Speech (POS) tags
of source and target words can be used to tackle
the data sparseness problem in discriminative word
alignment (Liu et al, 2005; Blunsom and Cohn,
2006). Shallow parsing has also been used to pro-
vide relevant information for alignment (Ren et al,
2007; Sun et al, 2000). Deeper syntax, e.g. phrase
or dependency structures, has been shown useful in
generative models (Wang and Zhou, 2004; Lopez
and Resnik, 2005), heuristic-based models (Ayan et
al., 2004; Ozdowska, 2004) and even for syntac-
tically motivated models such as ITG (Wu, 1997;
Cherry and Lin, 2006).
In this paper, we introduce an approach to im-
prove word alignment by incorporating syntactic de-
pendencies. Our approach is motivated by the fact
that words tend to be dependent on each other. If
69
we can first obtain a set of reliable anchor links, we
could take advantage of the syntactic dependencies
relating unaligned words to aligned anchor words to
expand the alignment. Figure 1 gives an illustrating
example. Note that the link (2, 4) can be easily iden-
tified, but the link involving the fourth Chinese word
(a function word denoting ?time?) (4, 4) is hard. In
such cases, we can make use of the dependency re-
lationship (?tclause?) between c2 and c4 to help the
alignment process. Given such an observation, our
model is composed of two related alignment models.
The first one is an anchor alignment model which is
used to find a set of anchor links; the other one is a
syntax-enhanced alignment model aiming to process
the words left unaligned after anchoring.
Figure 1: How syntactic dependencies can help word
alignment: an example
The remainder of this paper is organized as fol-
lows. In Section 2, we introduce our syntax-
enhanced discriminative word alignment approach.
The feature functions used are described in Sec-
tion 3. Experimental setting and results are pre-
sented in Section 4 and 5 respectively. In Section 6,
we compare our approach with other related word
alignment approaches. Section 7 concludes the pa-
per and gives avenues for future work.
2 Word Alignment Model
2.1 Notation
While in this paper we focus on Chinese?English,
the method proposed is applicable to any language
pair. The notation will assume Chinese?English
word alignment and Chinese?English MT. Here we
adopt a notation similar to (Brown et al, 1993).
Given a Chinese sentence cJ1 consisting of J words
{c1, ..., cJ} and an English sentence eI1 consisting of
I words e1, ..., eI , we define the alignment A be-
tween cJ1 and eI1 as a subset of the Cartesian product
of the word positions:
A ? {(j, i) : j = 1, ..., J ; i = 1, ..., I}
Our alignment representation is restricted so that
each source word can only be aligned to one tar-
get word. The alignment A consists of associations
j ? i = aj from a source position j to a target po-
sition i = aj . The ?null? alignment aj = 0 with the
?empty? word e0 is used to account for source words
that are not aligned to any target word.
We use A? to denote a subset of A. The indices of
the K source words involved in A? are represented
as ?K1 and the corresponding target indices for ?k
are represented as a?k . The unaligned source words
are represented as ??.
2.2 General Model
Given a source sentence cJ1 and target sentence eI1,
we seek to find the optimum alignment A? such that:
A? = argmax
A
P (A|cJ1 , eI1) (1)
We use a model (2) that directly models the link-
age between source and target words similarly to (It-
tycheriah and Roukos, 2005). We decompose this
model into an anchor alignment model (3) and a
syntax-enhanced model (4) by distinguishing the an-
chor alignment from the non-anchor alignment.
p(A|cJ1 , eI1) =
J
?
j=0
p(aj |cJ1 , eI1, aj?11 ) (2)
= 1Z ? p?(A?|c
J
1 , eI1) ? (3)
?
j???
p(aj|cJ1 , eI1, aj?11 , A?) (4)
2.3 Anchor Alignment Model
The anchor alignment model p?(A?) aims to find a
set of high precision links. Various approaches can
be used for this purpose. In this paper we adopted
the following two approaches.
2.3.1 Heuristics-based Approach
The problem of word alignment is regarded as a
process of word linkage disambiguation, i.e. choos-
ing the correct links between words from all com-
peting hypothesis (Melamed, 2000; Deng and Gao,
2007).
70
We constrain the link probabilities in such a way
that:
?i? ? {1, ..., I}, i? 6= i : p((j, i))p((j, i?)) > ?1 (5)
?j? ? {1, ..., J}, j? 6= j : p((j, i))p((j?, i)) > ?2 (6)
Condition (5) implies that for the source word cj ,
the link with the target word ei is more probable
(with reliability threshold ?1) than the link with any
other target word. Condition (6) guarantees that for
the target word ei, cj is the only most probable (with
threshold ?2) source word to be linked to.
2.3.2 Intersected Generative Word Alignment
Models
We can use the asymmetric IBM models for bidi-
rectional word alignment and get the intersection.
2.4 Syntax-Enhanced Word Alignment Model
The syntax-enhanced model is used to model the
alignment of the words left unaligned after anchor-
ing. We directly model the linkage between source
and target words using a discriminative word align-
ment framework where various features can be in-
corporated. Given a source word cj and the target
sentence eI1, we search for the alignment aj such
that:
a?j = argmax
aj
{p?M1 (aj |c
J
1 , eI1, a
j?1
1 , A?)} (7)
= argmax
aj
{?Mm=1 ?mhm(cJ1 , eI1, a
j
1, A?, Tc, Te)}
In this decision rule, we assume that a set of highly
reliable anchor alignments A? has been obtained,
and Tc (resp. Te) is used to denote the dependency
structure for source (resp. target) language. In such
a framework, various machine learning techniques
can be used for parameter estimation.
3 Feature Function for Syntax-Enhanced
Model
The various features used in our syntax-enhanced
model can be classified into three groups: statistics-
based features, syntactic features and relative distor-
tion features.
3.1 Statistics-based Features
3.1.1 IBM model 1 score
IBM model 1 is a position-independent word
alignment model which is often used to boot-
strap parameters for more complex models. Model
1 models the conditional distribution and uses a
uniform distribution for the dependencies between
source word positions and target word positions.
Pr(cJ1 , aJ1 |eI1) =
p(J |I)
(I + 1)J
J
?
j=1
p(cj |eaj ) (8)
3.1.2 Log-likelihood ratio
The log-likelihood ratio statistic has been found to
be accurate for modeling the associations between
rare events (Dunning, 1993). It has also been suc-
cessfully used to measure the associations between
word pairs (Melamed, 2000; Moore, 2005). Given
the following contingency table:
cj ?cj
ei a b
?ei c d
the log-likelihood ratio can be defined as:
G2(cj , ei) = ?2log
B(a|a + b, p1)B(c|c + d, p2)
B(a|a+ b, p)B(c|c + d, p)
where B(k|n, p) = (nk )pk(1 ? p)n?k are binomial
probabilities. The probability parameters can be ob-
tained using maximum likelihood estimates:
p1 =
a
a+ b , p2 =
c
c+ d (9)
p = a+ ca + b+ c+ d (10)
3.1.3 POS translation probability
The POS tags can provide effective information
for addressing the data sparseness problem using the
lexical features (Liu et al, 2005; Blunsom and Cohn,
2006). The POS translation probability can be easily
obtained using maximum likelihood estimation from
an annotated corpus:
Pr(Tc|Te) =
COL(Tc, Te)
COF (Te)
(11)
71
where Tc is a Chinese word?s POS tag and Te is an
English word?s POS tag. COL(Tc, Te) is the count
of Tc and Te being linked to each other in the corpus,
and COF (Te) is the frequency of Te in the corpus.
3.2 Syntactic Features
The dependency relation Re (resp. Rc) between two
English (resp. Chinese) words ei and ei? (resp. cj
and cj?) in the dependency tree of the English sen-
tence eI1 (resp. Chinese sentence cJ1 ) can be repre-
sented as a triple <ei, Re, ei?>(resp. <cj , Rc, ej?>).
Given cJ1 , eI1 and their syntactic dependency trees
TcJ1 , TeI1 , if ei is aligned to cj and ei? aligned to
cj? , according to the dependency correspondence as-
sumption (Hwa et al, 2002), there exists a triple
<cj , Rc, cj?>.
While we are not aiming to justify the feasibil-
ity of the dependency correspondence assumption
by proving to what extent Re = Rc under the con-
dition described above, we do believe that cj and cj?
are likely to be dependent on each other. Given the
anchor alignment A?, a candidate link (j, i) and the
dependency trees, we can design four classes of fea-
ture functions.
3.2.1 Agreement features
The agreement features can be further classi-
fied into dependency agreement features and depen-
dency label agreement features. Given a candidate
link (j, i) and the anchor alignment A?, the depen-
dency agreement (DA) feature function is defined as
follows:
hDA?1 =
?
?
?
?
?
1 if ? <cj, Rc, cj?>, <ei, Re, ei?>
and (j?, i?) ? A?,
0 otherwise.
(12)
By changing the dependency direction between the
words cj and cj? , we can derive another dependency
agreement feature:
hDA?2 =
?
?
?
?
?
1 if ? <cj? , Rc, cj>, <ei? , Re, ei>
and (j?, i?) ? A?,
0 otherwise.
(13)
We can define the dependency label agreement fea-
ture1 as follows:
hDLA?1 =
?
?
?
?
?
1 if ? <cj , Rc, cj?>, <ei, Re, ei?>
and (j?, i?) ? A?,Rc = Re,
0 otherwise.
(14)
Similarly we can obtain hDLA?2 by changing the
dependency direction.
3.2.2 Source word dependency features
Given a candidate link (j, i) and anchor alignment
A?, source language dependency features are used
to capture the dependency label between a source
word cj and a source anchor word ck ? ?. For
example, a feature function relating to dependency
type ?PRD? can be defined as:
hsrc?1?PRD =
?
?
?
?
?
1 if ? <cj, Rc, cj?>
and Rc =?PRD?,
0 otherwise.
(15)
By changing the direction we can obtain
hsrc?2?PRD.
3.2.3 Target word dependency features
Target word dependency features can be defined
in a similar way as source word dependency fea-
tures.
3.2.4 Target anchor feature
The target anchor feature defines whether the tar-
get word ei is an anchor word.
hsrc?1?PRD =
{
1 if i ? a?,
0 otherwise.
(16)
3.3 Relative distortion feature
We can design features encoding the relative dis-
tortion information which can be used to evaluate
a candidate link by computing its relative position
change with respect to the anchor alignment. The
relative position change of a candidate link l = (j, i)
is formally defined as follows:
1Note that we used the same dependency parser for source
and target language parsing.
72
D(l) = min(|dL|, |dR|) (17)
dL = (j ? jL) ? (i? iL) (18)
dR = (j ? jR)? (i? iR) (19)
where (iL, jL) is the leftmost anchor link of l,
(iR, jR) is the rightmost anchor link of l. The less
the relative position changes, the more likely the
candidate link is. With a set of anchor alignments,
we can obtain the distribution of the relative posi-
tion changes from an annotated corpus using maxi-
mum likelihood estimation. In our experiments, we
used the following four probabilities: p(D = 0),
p(D = 1, 2), p(D = 3, 4) and p(D > 4).
4 Experimental Setting
4.1 Data
The experiments were carried out using the
Chinese?English datasets provided within the
IWSLT 2007 evaluation campaign (Fordyce, 2007),
extracted from the Basic Travel Expression Corpus
(BTEC) (Takezawa et al, 2002). This multilingual
speech corpus contains sentences similar to those
that are usually found in phrase-books for tourists
going abroad.
We tagged all the sentences in the training and de-
vset3 using a maximum entropy-based POS tagger?
MXPOST (Ratnaparkhi, 1996), trained on the Penn
English and Chinese Treebanks. Both Chinese and
English sentences are parsed using the Malt depen-
dency parser (Nivre et al, 2007), which achieved
84% and 88% labelled attachment scores for Chi-
nese and English respectively.
4.1.1 Word Alignment
We manually annotated word alignments on de-
vset3. Since manual word alignment is an ambigu-
ous task, we also explicitly allow for ambiguous
alignments, i.e. the links are marked as sure (S) or
possible (P) (Och and Ney, 2003). IWSLT devset3
consists of 502 sentence pairs after cleaning. We
used the first 300 sentence pairs for training, the fol-
lowing 50 sentence pairs as validation set and the
last 152 sentence pairs for testing.
4.1.2 Machine Translation
Training was performed using the default training
set (39,952 sentence pairs), to which we added the
set devset1 (506 sentence pairs).2 We used devset2
(506 sentence pairs, 16 references) to tune various
parameters in the MT system and IWSLT 2007 test
set (489 sentence pairs, 6 references) for testing.
4.2 Alignment Training and Search
In our experiments, we treated anchor alignment and
syntax-enhanced alignment as separate processes in
a pipeline. The anchor alignments are kept fixed so
that the parameters in the syntax-enhanced model
can be optimized.3 We used the support vector ma-
chine (SVM) toolkit?SVM light4 to optimize the
parameters in (7). Our model is constrained in such
a way that each source word can only be aligned to
one target word. Therefore, in training, we trans-
form each possible link involving the words left un-
aligned after anchoring into an event. In testing, the
source words are consumed in sequence and the tar-
get words serve as states. The SVM dual variable
was used to measure the reliability of each candidate
link and the alignment link for each word is made
independently, which makes the alignment search
much easier. A threshold t was set as the minimal
reliability score for each link. t is optimized accord-
ing to alignment error rate (21) on the validation set.
4.3 Baselines
4.3.1 Word Alignment
We used the GIZA++ implementation of IBM
word alignment model 4 (Brown et al, 1993; Och
and Ney, 2003) for word alignment, and the heuris-
tics described in (Och and Ney, 2003) to derive the
intersection and refined alignment.
4.3.2 Machine Translation
We use a standard log-linear phrase-based SMT
(PB-SMT) model as a baseline: GIZA++ implemen-
tation of IBM word alignment model 4,5 the refine-
2More specifically, we chose the first English reference from
the 16 references and the Chinese sentence to construct new
sentence pairs.
3Note our anchor alignment does not achieve 100% preci-
sion. Since we performed precision-oriented alignment for the
anchor alignment model, the errors in anchor alignment will not
bring much noise into the syntax-enhanced model.
4http://svmlight.joachims.org/
5More specifically, we performed 5 iterations of Model 1, 5
iterations of HMM, 3 iterations of Model 3, and 3 iterations of
Model 4.
73
ment and phrase-extraction heuristics described in
(Koehn et al, 2003), minimum-error-rate training
(Och, 2003), a trigram language model with Kneser-
Ney smoothing trained with SRILM (Stolcke, 2002)
on the English side of the training data, and Moses
(Koehn et al, 2007) to decode.
4.4 Evaluation
We evaluate the intrinsic quality of predicted align-
ment A with precision, recall and alignment error
rate (AER). Slightly differently from (Och and Ney,
2003), we use possible alignments in computing re-
call.
recall = |A ? P ||P | , precision =
|A ? P |
|A| (20)
AER(S,P ;A) = 1? |A ? S|+ |A ? P ||A| + |S| (21)
We also extrinsically measure the word alignment
quality via a Chinese?English translation task. The
translation output is measured using BLEU (Pap-
ineni et al, 2002).
5 Experimental Results
5.1 Word Alignment
We performed word alignment bidirectionally using
our approach to obtain the union and compared our
results with two strong baselines based on generative
word alignment models. The results are shown in
Table 1. We can see that both the syntax-enhanced
model based on HMM intersection anchors (Syntax-
HMM) and on IBM model 4 anchors (Syntax-Model
4) are better than the pure generative word alignment
models. Our approach is superior in precision with
a disadvantage in recall. The best result achieved
10.32% relative decrease in AER compared to the
baseline when we use IBM model 4 intersection to
obtain the set of anchor alignments.
model precision recall f-score AER
HMM refined 0.8043 0.7592 0.7811 0.2059
Syntax-HMM 0.8744 0.7304 0.7959 0.1845
Model 4 refined 0.7941 0.7987 0.7964 0.1929
Syntax-Model 4 0.8566 0.7685 0.8102 0.1730
Table 1: Comparing syntax-enhanced approach with gen-
erative word alignment
5.1.1 The Influence of Anchor Alignment
Quality
As we can see in Table 2, our precision-oriented
approach to acquire anchor alignments was accom-
plished quite well. All four different anchor align-
ment models achieved high precision. However, the
recall differs dramatically, with model 4 achieving
the highest recall and the heuristics-based approach
receiving the lowest. To investigate the influence
anchor model precision recall f-measure AER
Heuristics 0.9774 0.4047 0.5724 0.3947
Model 1 0.9509 0.5011 0.6563 0.3157
HMM 0.9802 0.5327 0.6903 0.2809
Model 4 0.9777 0.5677 0.7179 0.2533
Table 2: Performance of anchor alignment
of the anchor alignment model, we first obtained
the intersection of the words left unaligned after an-
choring using each of the anchor alignment models.
We evaluate the alignment of these words against
the gold-standard alignments involving these words.
The influence of anchor alignment on the perfor-
mance of the syntax-enhanced model can be seen
in Table 3. The performance of the syntax-enhanced
model is closely related to that of the anchor align-
ment method. As can be seen from Table 2 and
3, HMM anchoring achieves the best precision and
so does the syntax-enhanced alignment; IBM model
4 achieves the best recall and so does the syntax-
enhanced alignment. Finally, the best alignment per-
formances are obtained with IBM model 4 anchor-
ing, with the difference in recall between HMM and
IBM model 4 anchoring being more significant than
the difference in precision.
anchor model precision recall f-score AER
Heuristics 0.4505 0.3270 0.3790 0.6210
Model 1 0.5538 0.3894 0.4573 0.5427
HMM 0.5932 0.3611 0.4489 0.5511
Model 4 0.5660 0.4216 0.4832 0.5168
Table 3: Influence of anchor alignment in syntax-
enhanced model
5.1.2 The Influence of Syntactic Dependencies
on Word Alignment
The influence of incorporating syntactic depen-
dencies into the word alignment process is shown
74
in Table 4. Syntax plays a positive role in all differ-
ent anchor alignment configurations. The influence
grows proportionally to the strength of the anchor
alignment model. With the Model 4 intersection
used as the set of anchor alignments, adding syn-
tactic dependency features into the syntax-enhanced
alignment model yields a 5.57% relative decrease in
AER.
model precision recall f-score AER
Heuristics
no syntax 0.8362 0.6751 0.7470 0.2302
w. syntax 0.8376 0.6894 0.7563 0.2240
Model 1
no syntax 0.8759 0.6902 0.7720 0.2045
w. syntax 0.8542 0.7160 0.7790 0.2011
HMM
no syntax 0.8655 0.7168 0.7841 0.1952
w. syntax 0.8744 0.7304 0.7959 0.1845
Model 4
no syntax 0.8697 0.7340 0.7961 0.1832
w. syntax 0.8566 0.7685 0.8102 0.1730
Table 4: Influence of syntactic dependencies on word
alignment
5.1.3 Contribution of Different Feature Classes
We interpret the contribution of each feature in
terms of feature weights in SVM model training.
The weights for the most discriminative features in
each feature class in Chinese?English word align-
ment (using HMM intersection as anchor align-
ment) are shown in Table 5. As we can see, all
statistics-based features are informative. Two target
dependency features are informative: ?PRD? denot-
ing ?predicative? dependency, and ?AMOD? denot-
ing ?adjective/adverb modifier? dependency.
weight
Model 1 Score 0.1416
POS 0.0540
Log-likelihood Ratio 0.0856
relative distortion 0.0606
DA-1 0.0227
DLA-2 0.0927
tgt-1-PRD 0.0961
tgt-2-AMOD 0.0621
Table 5: Weights of some informative features
5.2 Machine Translation
Research has shown that an increase in AER does
not necessarily imply an improvement in translation
quality (Liang et al, 2006) and vice-versa (Vilar et
al., 2006). Hereafter, we used a Chinese?English
MT task to extrinsically evaluate the quality of our
word alignment.
Table 6 shows the influence of our word align-
ment approach on MT quality.6 On development set,
we achieved statistically significant improvement
using both our syntax-enhanced models?Syntax-
HMM (p<0.002) and Syntax-Model 4 (p<0.008).
On the test set, we observed that the MT output
based on our alignment model tends to be shorter
than the reference translations and the BLEU score
is considerably penalized. If we ignore the length
penalty (?BP? in Table 6) in significance testing, the
improvement on test set is also statistically signif-
icant: p<0.04 for both Syntax-HMM and Syntax-
Model 4. However, an indepth manual analysis
needs to be carried out in order to determine the ex-
act nature of the shorter sentences derived.
dev. set test set
Baseline 0.5412 0.3510 (BP=0.96)
Syntax-HMM 0.6015 0.3409 (BP=0.86)
Syntax-Model 4 0.5834 0.3585 (BP=0.91)
Table 6: The Influence of Word Alignment on MT
6 Comparison with Previous Work
Our syntax-enhanced model is a discriminative word
alignment model. Certain generative word align-
ment models (e.g. HMM or IBM 4) also take
the first-order dependencies into account. How-
ever, long distance dependencies between words are
hard to incorporate into these models because of
the explosive number of parameters. On the other
hand, like existing discriminative models, our ap-
proach uses a set of informative features based on
co-occurrence statistics, e.g. log-likelihood ratio
and DICE score. The advantage of our approach is
the mechanism by which syntactic features may be
incorporated.
6Note that the only difference between our MT system and
the baseline PB-SMT system is the word alignment component.
75
Some previous research also tried to make use
of syntax in word alignment. (Wang and Zhou,
2004) investigated the benefit of monolingual pars-
ing for alignment. They learned a generalized word
association measure (crosslingual word similarities)
based on monolingual dependency structures and
improved alignment performances over IBM model
2 and certain heuristic-based models. (Cherry and
Lin, 2006) used dependency structures as soft con-
straints to improve word alignment in an ITG frame-
work. Compared to these models, our approach di-
rectly takes advantage of dependency relations as
they are transformed into feature functions incorpo-
rated into a discriminative word alignment frame-
work.
7 Conclusion and Future Work
In this paper, we proposed a model that can facili-
tate the incorporation of syntax into word alignment
and measured the combination of a set of syntactic
features. Experimental results have shown that syn-
tax is useful in word alignment and especially effec-
tive in improving the recall. We have also observed
that in our word alignment framework, the two sub-
models are closely related and the quality of the an-
chor alignment model plays an important role in the
system performance.
The promising results will lead us to improve our
model in the following aspects. First, the two sub-
models in our approach are two separate processes
performed in pipeline. We plan to jointly optimize
the two models in one go. Second, some of our
experiments used complex IBM models, e.g. IBM
Model 4, to obtain anchor alignment. We plan to
boostrap the alignment using simple heuristics with-
out relying on complex IBM models. Third, the
alignment searching process assumed the alignment
link for each word is made independently. A feasible
markovian assumption will be tested for searching.
Fourth, a comparison with traditional discriminative
word alignment models is also necessary to justify
the merits of our approach. Finally, we also plan to
adapt our approach to larger data sets and more lan-
guage pairs.
Acknowledgments
This work is supported by Science Foundation Ire-
land (grant number OS/IN/1732). Prof. Rebecca
Hwa from University of Pittsburgh and Dr. Yang
Liu from the Institute of Computing Technology,
Chinese Academy of Sciences, are kindly acknowl-
edged for providing us with their word alignment
guidelines. We would also like to thank the anony-
mous reviewers for their insightful comments.
References
Necip Fazil Ayan, Bonnie Dorr, and Nizar Habash.
2004. Multi-align: Combining linguistic and statis-
tical techniques to improve alignments for adaptable
mt. In Proceedings of the 6th Conference of the AMTA
(AMTA-2004), pages 17?26, Washington DC.
Phil Blunsom and Trevor Cohn. 2006. Discrimina-
tive word alignment with conditional random fields.
In Proceedings of the 21st International Conference
on Computational Linguistics and 44th Annual Meet-
ing of the Association for Computational Linguistics,
pages 65?72, Sydney, Australia.
Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della
Pietra, and Robert L. Mercer. 1993. The mathematics
of statistical machine translation: Parameter estima-
tion. Computational Linguistics, 19(2):263?311.
Colin Cherry and Dekang Lin. 2006. Soft syntactic
constraints for word alignment through discriminative
training. In Proceedings of the 21st International Con-
ference on Computational Linguistics and 44th Annual
Meeting of the Association for Computational Linguis-
tics, pages 105?112, Sydney, Australia.
Yonggang Deng and Yuqing Gao. 2007. Guiding sta-
tistical word alignment models with prior knowledge.
In Proceedings of the 45th Annual Meeting of the
Association of Computational Linguistics, pages 1?8,
Prague, Czech Republic.
Ted Dunning. 1993. Accurate methods for the statistics
of surprise and coincidence. Computational Linguis-
tics, 19(1):61?74.
Cameron Shaw Fordyce. 2007. Overview of the IWSLT
2007 Evaluation Campaign. In Proceedings of the In-
ternational Workshop on Spoken Language Transla-
tion, pages 1?12, Trento, Italy.
Rebecca Hwa, Philip Resnik, Amy Weinberg, and Okan
Kolak. 2002. Evaluating translational correspondence
using annotation projection. In Proceedings of the
40th Annual Meeting of the Association for Compu-
tational Linguistics, pages 392?399, Philadelphia, PA.
Abraham Ittycheriah and Salim Roukos. 2005. A max-
imum entropy word aligner for Arabic-English ma-
chine translation. In Proceedings of Human Language
76
Technology Conference and Conference on Empirical
Methods in Natural Language Processing, pages 89?
96, Vancouver, British Columbia, Canada.
Philipp Koehn, Franz Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In Proceedings of
Human Language Technology Conference and Confer-
ence on Empirical Methods in Natural Language Pro-
cessing, pages 48?54, Edmonton, Canada.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondrej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: Open source
toolkit for statistical machine translation. In Proceed-
ings of the 45th Annual Meeting of the Association for
Computational Linguistics Companion Volume Pro-
ceedings of the Demo and Poster Sessions, pages 177?
180, Prague, Czech Republic.
Percy Liang, Ben Taskar, and Dan Klein. 2006. Align-
ment by agreement. In Proceedings of Human Lan-
guage Technology Conference and Conference on
Empirical Methods in Natural Language Processing,
pages 104?111, New York, NY.
Yang Liu, Qun Liu, and Shouxun Lin. 2005. Log-linear
models for word alignment. In Proceedings of the
43rd Annual Meeting of the Association for Compu-
tational Linguistics, pages 459?466, Ann Arbor, MI.
Adam Lopez and Philip Resnik. 2005. Improved HMM
alignment models for languages with scarce resources.
In Proceedings of the ACL Workshop on Building and
Using Parallel Texts, pages 83?86, Ann Arbor, Michi-
gan, June.
I. Dan Melamed. 2000. Models of translational equiv-
alence among words. Computational Linguistics,
26(2):221?249.
Robert C. Moore. 2005. A discriminative framework for
bilingual word alignment. In Proceedings of Human
Language Technology Conference and Conference on
Empirical Methods in Natural Language Processing,
pages 81?88, Vancouver, British Columbia, Canada.
Joakim Nivre, Johan Hall, Jens Nilsson, Atanas Chanev,
Gu?lsen Eryigit, Sandra Ku?bler, Svetoslav Marinov,
and Ervin Marsi. 2007. MaltParser: A language-
independent system for data-driven dependency pars-
ing. Natural Language Engineering, 13(2):95?135.
Franz Och and Hermann Ney. 2003. A systematic com-
parison of various statistical alignment models. Com-
putational Linguistics, 29(1):19?51.
Franz Och. 2003. Minimum error rate training in statis-
tical machine translation. In Proceedings of the 41st
Annual Meeting of the Association for Computational
Linguistics, pages 160?167, Sapporo, Japan.
Sylwia Ozdowska. 2004. Identifying correspondences
between words: an approach based on a bilingual syn-
tactic analysis of French/English parallel corpora. In
Proceedings of the COLING?04 Workshop on Multi-
lingual Linguistic Resources, pages 49?56, Geneva,
Switzerland.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic eval-
uation of machine translation. In Proceedings of the
40th Annual Meeting of the Association for Computa-
tional Linguistics, pages 311?318, Philadelphia, PA.
Adwait Ratnaparkhi. 1996. A maximum entropy model
for part-of-speech tagging. In Eric Brill and Ken-
neth Church, editors, Proceedings of the Conference
on Empirical Methods in Natural Language Process-
ing, pages 133?142, Somerset, NJ.
Dengjun Ren, Hua Wu, and Haifeng Wang. 2007. Im-
proving statistical word alignment with various clues.
In Machine Translation Summit XI, pages 391?397,
Copenhagen, Denmark.
Andrea Stolcke. 2002. SRILM ? An extensible lan-
guage modeling toolkit. In Proceedings of the Inter-
national Conference on Spoken Language Processing,
pages 901?904, Denver, CO.
Le Sun, Youbing Jin, Lin Du, and Yufang Sun. 2000.
Word alignment of English-Chinese bilingual corpus
based on chunks. In Proceedings of the 2000 Joint
SIGDAT conference on Empirical Methods in Natural
Language Processing and very large corpora, pages
110?116.
Toshiyuki Takezawa, Eiichiro Sumita, Fumiaki Sugaya,
Hirofumi Yamamoto, and Seiichi Yamamoto. 2002.
Toward a broad-coverage bilingual corpus for speech
translation of travel conversations in the real world.
In Proceedings of Third International Conference on
Language Resources and Evaluation 2002, pages 147?
152, Las Palmas, Spain.
David Vilar, Maja Popovic, and Hermann Ney. 2006.
AER: Do we need to ?improve? our alignments? In
Proceedings of the International Workshop on Spoken
Language Translation, pages 205?212, Kyoto, Japan.
Stefan Vogel, Hermann Ney, and Christoph Tillmann.
1996. HMM-based word alignment in statistical trans-
lation. In Proceedings of the 16th International Con-
ference on Computational Linguistics, pages 836?841,
Copenhagen, Denmark.
Wei Wang and Ming Zhou. 2004. Improving word align-
ment models using structured monolingual corpora.
In Dekang Lin and Dekai Wu, editors, Proceedings
of Conference on Empirical Methods in Natural Lan-
guage Processing, pages 198?205, Barcelona, Spain.
Dekai Wu. 1997. Stochastic Inversion Transduction
Grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3):377?403.
77
Proceedings of the ACL Student Research Workshop, pages 127?132,
Ann Arbor, Michigan, June 2005. c?2005 Association for Computational Linguistics
Using bilingual dependencies to align words in 
Enlish/French parallel corpora 
 
 
Sylwia Ozdowska 
ERSS - CNRS & Universit? de Toulouse le Mirail 
5 all?es Antonio Machado 
31058 Toulouse Cedex France 
ozdowska@univ-tlse2.fr 
 
 
 
Abstract 
This paper describes a word and phrase 
alignment approach based on a depend-
ency analysis of French/English parallel 
corpora, referred to as alignment by ?syn-
tax-based propagation.? Both corpora are 
analysed with a deep and robust depend-
ency parser. Starting with an anchor pair 
consisting of two words that are transla-
tions of one another within aligned sen-
tences, the alignment link is propagated to 
syntactically connected words. 
1 Introduction 
It is now an acknowledged fact that alignment of 
parallel corpora at the word and phrase level plays 
a major role in bilingual linguistic resource extrac-
tion and machine translation. There are basically 
two kinds of systems working at these segmenta-
tion levels: the most widespread rely on statistical 
models, in particular the IBM ones (Brown et al, 
1993); others combine simpler association meas-
ures with different kinds of linguistic information 
(Arhenberg et al, 2000; Barbu, 2004). Mainly 
dedicated to machine translation, purely statistical 
systems have gradually been enriched with syntac-
tic knowledge (Wu, 2000; Yamada & Knight, 
2001; Ding et al, 2003; Lin & Cherry, 2003). As 
pointed out in these studies, the introduction of 
linguistic knowledge leads to a significant im-
provement in alignment quality. 
In the method described hereafter, syntactic infor-
mation is the kernel of the alignment process. In-
deed, syntactic dependencies identified on both 
sides of English/French bitexts with a parser are 
used to discover correspondences between words. 
This approach has been chosen in order to capture 
frequent alignments as well as sparse and/or cor-
pus-specific ones. Moreover, as stressed in previ-
ous research, using syntactic dependencies seems 
to be particularly well suited to coping with the 
problem of linguistic variation across languages 
(Hwa et al, 2002). The implemented procedure is 
referred to as ?syntax-based propagation?. 
2 Starting hypothesis 
The idea is to make use of dependency relations to 
align words (Debili & Zribi, 1996). The reasoning 
is as follows (Figure 1): if there is a pair of anchor 
words, i.e. if two words w1i (community in the ex-
ample) and w2m (communaut?) are aligned at the 
sentence level, and if there is a dependency rela-
tion between w1i (community) and w1j (ban) on the 
one hand, and between w2m (communaut?) and w2n 
(interdire) on the other hand, then the alignment 
link is propagated from the anchor pair (commu-
nity, communaut?) to the syntactically connected 
words (ban, interdire). 
 
 subj
 
The Community banned imports of ivory. 
 
La Communaut? a interdit l?importation d?ivoire. 
 subj
 
Figure 1. Syntax-based propagation 
 
 
127
We describe hereafter the overall design of the 
syntax-based propagation process. We present the 
results of applying it to three parsed Eng-
lish/French bitexts and compare them to the base-
line obtained with the giza++ package (Och & 
Ney, 2000). 
3 Corpora and parsers 
The syntax-based alignment was tested on three 
parallel corpora aligned at the sentence level: 
INRA, JOC and HLT. The first corpus was com-
piled at the National Institute for Agricultural Re-
search (INRA)1 to enrich a bilingual terminology 
database used by translators. It comprises 6815 
aligned sentences2 and mainly consists of research 
papers and popular-science texts. 
The JOC corpus was made available in the frame-
work of the ARCADE project, which focused on 
the evaluation of parallel text alignment systems 
(Veronis & Langlais, 2000). It contains written 
questions on a wide variety of topics addressed by 
members of the European Parliament to the Euro-
pean Commission, as well as the corresponding 
answers. It is made up of 8765 aligned sentences. 
The HLT corpus was used in the evaluation of 
word alignment systems described in (Mihalcea & 
Pederson, 2003). It contains 447 aligned sentences 
from the Canadian Hansards (Och & Ney, 2000). 
The corpus processing was carried out by a 
French/English parser, SYNTEX (Fabre & Bouri-
gault, 2001). SYNTEX is a dependency parser 
whose input is a POS tagged3 corpus ? meaning 
each word in the corpus is assigned a lemma and 
grammatical tag. The parser identifies dependen-
cies in the sentences of a given corpus, for instance 
subjects and direct and indirect objects of verbs. 
The parsing is performed independently in each 
language, yet the outputs are quite homogeneous 
since the syntactic dependencies are identified and 
represented in the same way in both languages. 
In addition to parsed English/French bitexts, the 
syntax-based alignment requires pairs of anchor 
words be identified prior to propagation. 
4 Identification of anchor pairs 
                                                          
1 We are grateful to A. Lacombe who allowed us to use this corpus for research 
purposes. 
2 The sentence-level alignment was performed using Japa 
(http://www.rali.iro.umontreal.ca). 
3 The French and English versions of Treetagger (http://www.ims.uni-
stuttgart.de) are used.
To derive a set of words that are likely to be useful 
for initiating the propagation process, we imple-
mented a widely used method of co-occurrence 
counts described notably in (Gale & Church, 1991; 
Ahrenberg et al, 2000). For each source (w1) and 
target (w2) word, the Jaccard association score is 
computed as follows:  
j(w1, w2) = f(w1, w2)/f(w1) + f(w2) ? f(w1, w2) 
 
The Jaccard is computed provided the number of 
overall occurrences of w1 and w2 is higher than 4, 
since statistical techniques have proved to be par-
ticularly efficient when aligning frequent units. 
The alignments are filtered according to the j(w1, 
w2) value, and retained if this value was 0.2 or 
higher. Moreover, two further tests based on cog-
nate recognition and mutual correspondence condi-
tion are applied. 
The identification of anchor pairs, consisting of 
words that are translation equivalents within 
aligned sentences, combines both the projection of 
the initial lexicon and the recognition of cognates 
for words that have not been taken into account in 
the lexicon. These pairs are used as the starting 
point of the propagation process4. 
Table 1 gives some characteristics of the corpora. 
 
 INRA JOC HLT 
aligned sentences 6815 8765 477 
anchor pairs 4376 60762 996 
w1/source sentence 21 25 15 
w2/target sentence 24 30 16 
anchor pairs/sentence 6.38 6.93 2.22 
Table 1. Identification of anchor pairs 
5 Syntax-based propagation 
5.1 Two types of propagation 
The syntax-based propagation may be performed 
in two different directions, as a given word is 
likely to be both governor and dependent with re-
spect to other words. The first direction starts with 
dependent anchor words and propagates the align-
ment link to the governors (Dep-to-Gov propaga-
tion). The Dep-to-Gov propagation is a priori not 
ambiguous since one dependent is governed at 
                                                          
4 The process is not iterative up to date so the number of words it allows to align 
depends on the initial number of anchor words per sentence. 
128
most by one word. Thus, there is just one relation 
on which the propagation can be based. The sec-
ond direction goes the opposite way: starting with 
governor anchor words, the alignment link is 
propagated to their dependents (Gov-to-Dep 
propagation). In this case, several relations that 
may be used to achieve the propagation are avail-
able, as it is possible for a governor to have more 
than one dependent. So the propagation is poten-
tially ambiguous. The ambiguity is particularly 
widespread when propagating from head nouns to 
their nominal and adjectival dependents. In Figure 
2, there is one occurrence of the relation pcomp in 
English and two in French. Thus, it is not possible 
to determine a priori whether to propagate using 
the relations mod/pcomp2, on the one hand, and 
pcomp1/pcomp2?, on the other hand, or 
mod/pcomp2? and pcomp1/pcomp2. Moreover, 
even if there is just one occurrence of the same 
relation in each language, it does not mean that the 
propagation is of necessity performed through the 
same relation, as shown in Figure 3. 
 
 
pcomp2? 
mod 
 
 
 
 
 
 
 
Figure 2. Ambiguous propagation from head nouns 
 
 
 
 
 
 
 
 
 
 
 
Figure 3. Ambiguous propagation from head nouns 
 
In the following sections, we describe the two 
types of propagation. The propagation patterns we 
rely on are given in the form CDep-rel-CGov, 
where CDep is the POS of the dependent, rel is the 
dependency relation and CGov, the POS of the 
governor. The anchor element is underlined and 
the one aligned by propagation is in bold. 
5.2 Alignment of verbs 
Verbs are aligned according to eight propagation 
patterns. 
DEP-TO-GOV PROPAGATION TO ALIGN GOVERNOR 
VERBS. The patterns are: Adv-mod-V (1), N-subj-
V (2), N-obj-V (3), N-pcomp-V (4) and V-pcomp-
V (5). 
(1) The net is then hauled to the shore. 
Le filet est ensuite hal? ? terre. 
(2) The fish are generally caught when they mi-
grate from their feeding areas. 
G?n?ralement les poissons sont captur?s quand ils 
migrent de leur zone d?engraissement. 
(3) Most of the young shad reach the sea. 
La plupart des alosons gagne la mer. 
(4) The eggs are very small and fall to the bottom. 
Les oeufs de tr?s petite taille tombent sur le fond. 
(5) X is a model which was designed to stimulate? 
X est un mod?le qui a ?t? con?u pour stimuler? 
GOV-TO-DEP PROPAGATION TO ALIGN DEPENDENT 
VERBS. The alignment links are propagated from 
the dependents to the verbs using three propagation 
patterns: V-pcomp-V (1), V-pcomp-N (2) and V-
pcomp-Adj (3). 
     mod       pcomp1 
(1) Ploughing tends to destroy the soil microag-
gregated structure. 
outdoor use  of water 
utilisation  en ext?rieur de l?eau 
Le labour tend ? rompre leur structure microagr?-
g?e. 
pcomp2 
(2) The capacity to colonize the digestive mu-
cosa? 
L?aptitude ? coloniser le tube digestif? 
(3) An established infection is impossible to con-
trol. 
     mod          pcomp1 
Toute infection en cours est impossible ? ma?triser. 
reference product on the market 
produit 5.3 Alignment of adjectives and nouns  commercial de r?f?rence 
The two types of propagation described in section 
5.2 for use with verbs are also used to align adjec-
tives and nouns. However, these latter categories 
cannot be treated in a fully independent way when 
propagating from head noun anchor words in order 
to align the dependents. The syntactic structure of 
noun phrases may be different in English and 
French, since they rely on a different type of com-
position to produce compounds and on the same 
one to produce free noun phrases. Thus, the poten-
tial ambiguity arising from the Gov-to-Dep propa-
gation from head nouns mentioned in section 5.1 
pcomp2 
129
may be accompanied by variation phenomena af-
fecting the category of the dependents. For in-
stance, a noun may be rendered by an adjective, or 
vice versa: tax treatment profits is translated by 
traitement fiscal des b?n?fices, so the noun tax is in 
correspondence with the adjective fiscal. The syn-
tactic relations used to propagate the alignment 
links are thus different. 
In order to cope with the variation problem, the 
propagation is performed regardless of whether the 
syntactic relations are identical in both languages, 
and regardless of whether the POS of the words to 
be aligned are the same. To sum up, adjectives and 
nouns are aligned separately of each other by 
means of Dep-to-Gov propagation or Gov-to-Dep 
propagation provided that the governor is not a 
noun. They are not treated separately when align-
ing by means of Gov-to-Dep propagation from 
head noun anchor pairs. 
DEP-TO-GOV PROPAGATION TO ALIGN 
ADJECTIVES. The propagation patterns involved 
are: Adv-mod-Adj (1), N-pcomp-Adj (2) and V-
pcomp-Adj (3). 
(1) The white cedar exhibits a very common physi-
cal defect. 
Le Poirier-pays pr?sente un d?faut de forme tr?s 
fr?quent. 
(2) The area presently devoted to agriculture 
represents? 
La surface actuellement consacr?e ? l?agriculture 
repr?senterait? 
(3) Only four plots were liable to receive this input. 
Seulement quatre parcelles sont susceptibles de 
recevoir ces apports. 
DEP-TO-GOV PROPAGATION TO ALIGN NOUNS. 
Nouns are aligned according to the following 
propagation patterns: Adj-mod-N (1), N-mod-N/N-
pcomp-N (2), N-pcomp-N (3) and V-pcomp-N (4). 
(1) Allis shad remain on the continental shelf. 
La grande alose reste sur le plateau continental. 
(2) Nature of micropollutant carriers. 
La nature des transporteurs des micropolluants. 
(3) The bodies of shad are generally fusiform. 
Le corps des aloses est g?n?ralement fusiforme. 
(4) Ability to react to light. 
Capacit? ? r?agir ? la lumi?re. 
UNAMBIGUOUS GOV-TO-DEP PROPAGATION TO 
ALIGN NOUNS. The propagation is not ambiguous 
when dependent nouns are not governed by a noun. 
This is the case when considering the following 
three propagation patterns: N-subj|obj-V (1), N-
pcomp-V (2) and N-pcomp-Adj (3). 
(1) The caterpillars can inoculate the fungus. 
Les chenilles peuvent inoculer le champignon. 
(2) The roots are placed in tanks. 
Les racines sont plac?es en bacs. 
(3) ...a fungus responsible for rot. 
... un champignon responsable de la pourriture. 
POTENTIALLY AMBIGUOUS GOV-TO-DEP 
PROPAGATION TO ALIGN NOUNS AND ADJECTIVES. 
Considering the potential ambiguity described in 
section 5.1, the algorithm which supports Gov-to-
Dep propagation from head noun anchor words 
(n1, n2) takes into account three situations which 
are likely to occur. 
First, each of n1 and n2 has only one dependent, 
respectively dep1 and dep2, involving one of the 
mod or pcomp relation; dep1 and dep2 are aligned. 
the drained whey 
le lactos?rum d??gouttage 
? (drained, ?gouttage) 
Second, n1 has one dependent dep1 and n2 several 
{dep21, dep22, ?, dep2n}, or vice versa. For each 
dep2i, check if one of the possible alignments has 
already been performed, either by propagation or 
anchor word spotting. If such an alignment exists, 
remove the others (dep1, dep2k) such that k ? i, or 
vice versa. Otherwise, retain all the alignments 
(dep1, dep2i), or vice versa, without resolving the 
ambiguity. 
stimulant substances which are absent from? 
substances solubles stimulantes absentes de? 
(stimulant, {soluble, stimulant, absent}) 
already_aligned(stimulant, stimulant) = 1 
? (stimulant, stimulant) 
Third, both n1 and n2 have several dependents, 
{dep11, dep12, ?, dep1m} and {dep21, dep22, ?, 
dep2n} respectively. For each dep1i and each dep2j, 
check if one/several alignments have already been 
performed. If such alignments exist, remove all the 
alignments (dep1k, dep2l) such that k ? i or l ? j. 
Otherwise, retain all the alignments (dep1i, dep2j) 
without resolving the ambiguity. 
unfair trading practices
pratiques commerciales d?loyales 
(unfair, {commercial, d?loyal}) 
(trading, {commercial, d?loyal}) 
already_aligned(unfair, d?loyal) = 1 
130
? (unfair, d?loyal) 
? (trading, commercial) 
a big rectangular net, which is lowered? 
un vaste filet rectangulaire immerg?? 
(big, {vaste, rectangulaire, immerg?}) 
(rectangular, {vaste, rectangulaire, immerg?}) 
already_aligned(rectangular, rectangulaire) = 1 
? (rectangular, rectangulaire) 
? (big, {vaste, immerg?}) 
The implemented propagation algorithm has two 
major advantages: it permits the resolution of some 
alignment ambiguities, taking advantage of align-
ments that have been previously performed. This 
algorithm also allows the system to cope with the 
problem of non-correspondence between English 
and French syntactic structures and makes it possi-
ble to align words using various syntactic relations 
in both languages, even though the category of the 
words under consideration is different. 
5.4 Comparative evaluation 
The results achieved using the syntax-based align-
ment (sba) are compared to those obtained with the 
baseline provided by the IBM models implemented 
in the giza++ package (Och & Ney, 2000) (Table 2 
and Table 3). More precisely, we used the intersec-
tion of IBM-4 Viterbi alignments for both transla-
tion directions. Table 2 shows the precision 
assessed against a reference set of 1000 alignments 
manually annotated in the INRA and the JOC cor-
pus respectively. It can be observed that the syn-
tax-based alignment offers good accuracy, similar 
to that of the baseline. 
 
 INRA JOC 
 sba giza++ sba giza++ 
Precision 0.93 0.96 0.95 0.94 
Table 2. sba ~ giza++: INRA & JOC 
 
More complete results (precision, recall and f-
measure) are presented in Table 3. They have been 
obtained using reference data from an evaluation 
of word alignment systems (Mihalcea & Pederson, 
2003). It should be noted that the figures concern-
ing the syntax-based alignment were assessed in 
respect to the annotations that do not involve 
empty words, since up to now we focused only on 
content words. Whereas the baseline precision5 for 
the HLT corpus is comparable to the one reported 
in Table 2, the syntax-based alignment score de-
creases. Moreover, the difference between the two 
approaches is considerable with regard to the re-
call. This may be due to the fact that our syntax-
based alignment approach basically relies on iso-
morphic syntactic structures, i.e. in which the two 
following conditions are met: i) the relation under 
consideration is identical in both languages and ii) 
the words involved in the syntactic propagation 
have the same POS. Most of the cases of non-
isomorphism, apart from the ones presented sec-
tion 5.1, are not taken into account. 
 
 HLT 
 sba giza++ 
Precision 0.83 0.95 
Recall 0.58 0.85 
F-measure 0.68 0.89 
Table 3. sba ~ giza++: HLT 
6 Discussion 
The results achieved by the syntax-based propaga-
tion method are quite encouraging. They show a 
high global precision rate ? 93% for the INRA 
corpus and 95% for the JOC ? comparable to that 
reported for the giza++ baseline system. The fig-
ures vary more from the HLT reference set. One 
possible explanation is the fact that the gold stan-
dard has been established according to specific 
annotation criteria. Indeed, the HLT project con-
cerned above all statistical alignment systems aim-
ing at language modelling for machine translation. 
In approaches such as Lin and Cherry?s (2003), 
linguistic knowledge is considered secondary to 
statistical information even if it improves the 
alignment quality. The syntax-based alignment 
approach was designed to capture both frequent 
alignments and those involving sparse or corpus-
specific words as well as to cope with the problem 
of non-correspondance across languages. That is 
why we chose the linguistic knowledge as the main 
information source. 
 
 
                                                          
5 Precision, recall and f-measure reported by Och and Ney (2003) for  the inter-
section of IBM-4 Viterbi alignments from both translation directions. 
131
7 Conclusion 
We have presented an efficient method for aligning 
words in English/French parallel corpora. It makes 
the most of dependency relations to produce highly 
accurate alignments when the same propagation 
pattern is used in both languages, i.e. when the 
syntactic structures are identical, as well as in 
cases of noun/adjective transpositions, even if the 
category of the words to be aligned varies (Oz-
dowska, 2004). We are currently pursuing the 
study of non-correspondence between syntactic 
structures in English and French. The aim is to de-
termine whether there are some regularities in the 
rendering of specific English structures into given 
French ones. If variation across languages is sub-
ject to such regularities, as assumed in (Dorr, 1994; 
Fox, 2002; Ozdowska & Bourigault, 2004), the 
syntax-based propagation could then be extended 
to cases of non-correspondence in order to improve 
recall. 
References  
Ahrenberg L., Andersson M. & Merkel M. 2000. A 
knowledge-lite approach to word alignment. In 
V?ronis J. (Ed.), Parallel Text Processing: Alignment 
and Use of Translation Corpora, Dordrecht: Kluwer 
Academic Publishers, pp. 97-138. 
Barbu A. M. 2004. Simple linguistic methods for im-
proving a word alignment algorithm. In Actes de la 
Conf?rence JADT. 
Brown P., Della Pietra S. & Mercer R. 1993. The 
mathematics of statistical machine translation: pa-
rameter estimation. In Computational Linguistics, 
19(2), pp. 263-311.  
Debili F. & Zribi A. 1996. Les d?pendances syntaxiques 
au service de l?appariement des mots. In Actes du 
10?me Congr?s RFIA. 
Ding Y., Gildea D. & Palmer M. 2003. An Algorithm 
for Word-Level Alignment of Parallel Dependency 
Trees. In Proceedings of the 9th MT Summit of Inter-
national Association of Machine Translation. 
Dorr B. 1994. Machine translation divergences: a for-
mal description and proposed solution. In Computa-
tional Linguistics, 20(4), pp. 597-633. 
Fabre C. & Bourigault D. 2001. Linguistic clues for 
corpus-based acquisition of lexical dependencies. In 
Proceedings of the Corpus Linguistic Conference. 
Fox H. J. 2002. Phrasal Cohesion and Statistical Ma-
chine Translation. In Proceedings of EMNLP-02, pp. 
304-311. 
Gale W. A. & Church K. W. 1991. Identifying Word 
Correspondences in Parallel Text. In Proceedings of 
the DARPA Workshop on Speech and Natural Lan-
guage. 
Hwa R., Resnik P., Weinberg A. & Kolak O. 2002. 
Evaluating Translational Correspondence Using An-
notation Projection. In Proceedings of the 40th An-
nual Conference of the Association for 
Computational Linguistics. 
Lin D. & Cherry C. 2003. ProAlign: Shared Task Sys-
tem Description. In HLT-NAACL 2003 Workshop on 
Building and Using Parallel Texts: Data Driven Ma-
chine Translation and Beyond. 
Mihalcea R. & Pedersen T. 2003. An Evaluation Exer-
cise for Word Alignment. In HLT-NAACL 2003 
Workshop on Building and Using Parallel Texts: 
Data Driven Machine Translation and Beyond. 
Och F. Z. & Ney H., 2003. A Systematic Comparison of 
Various Statistical Alignment Models. In Computa-
tional Linguistics, 29(1), pp. 19-51. 
Ozdowska S. 2004. Identifying correspondences be-
tween words: an approach based on a bilingual syn-
tactic analysis of French/English parallel corpora. In 
COLING 04 Workshop on Multilingual Linguistic 
Resources. 
Ozdowska S. & Bourigault D. 2004. D?tection de rela-
tions d?appariement bilingue entre termes ? partir 
d?une analyse syntaxique de corpus. In Actes des 
14?me Congr?s RFIA. 
V?ronis J. & Langlais P. 2000. Evaluation of parallel 
text alignment systems. The ARCADE project. In 
V?ronis J. (ed.), Parallel Text Processing: Alignment 
and Use of Translation Corpora, Dordrecht: Kluwer 
Academic Publishers, pp. 371-388 
Wu D. 2000. Bracketing and aligning words and con-
stituents in parallel text using Stochastic Inversion 
Transduction Grammars. In V?ronis, J. (Ed.), Paral-
lel Text Processing: Alignment and Use of Transla-
tion Corpora, Dordrecht: Kluwer Academic 
Publishers, pp. 139-167. 
Yamada K. & Knight K. 2001. A syntax-based statisti-
cal translation model. In Proceedings of the 39th An-
nual Conference of the Association for 
Computational Linguistics. 
132
Identifying correspondences between words: an approach based on a bilingual 
syntactic analysis of French/English parallel corpora 
Sylwia OZDOWSKA 
Equipe de Recherche en Syntaxe et S?mantique  
Universit? Toulouse le Mirail 
5 all?es Antonio Machado 
31058 Toulouse Cedex 1 France 
ozdowska@univ-tlse2.fr 
 
Abstract 
We present a word alignment procedure based 
on a syntactic dependency analysis of 
French/English parallel corpora called 
?alignment by syntactic propagation?. Both 
corpora are analysed with a deep and robust 
parser. Starting with an anchor pair consisting 
of two words which are potential translations 
of one another within aligned sentences, the 
alignment link is propagated to the 
syntactically connected words. The method 
was tested on two corpora and achieved a 
precision of 94.3 and 93.1% as well as a recall 
of 58 and 56%, respectively for each corpus. 
1 Introduction 
It is now an aknowledged fact that parallel 
corpora, i.e. corpora made of texts in one language 
and their translation in another language, are well 
suited in particular to cope with the problem of the 
construction of bilingual resources such as 
bilingual lexicons or terminologies. Several works 
have focused on the alignment of units which are 
smaller than a sentence, for instance words or 
phrases, as to produce bilingual word, phrase or 
term associations. A common assumption is that 
the alignment of words or phrases raises a real 
challenge, since it is ?neither one-to-one, nor 
sequential, nor compact?, and thus ?the 
correspondences are fuzzy and contextual? (Debili, 
1997). Indeed, it is even often diffult for a human 
to determine which source unit correspond to 
which target unit within aligned sentences (Och 
and Ney, 2003). 
Most alignment systems working on parallel 
corpora rely on statistical models, in particular the 
EM ones (Brown, Della Pietra and Mercer, 1993). 
Quite recently attempts have been made in order to 
incorporate different types of linguistic 
information sources into word and phrase 
alignment systems. The idea is to take into account 
the specific problems arising from the alignment at 
the word or phrase level mentioned in particular by 
Debili (1997). Different types of linguistic 
knowledge are exploited: morphological, lexical 
and syntactic ones. In the method described in this 
article, the syntactic information is the kernel of 
the alignment process. Indeed, syntactic relations 
identified on both sides of the French/English 
parallel corpus with a deep and robust parser are 
used to find out new correspondences between 
words or to confirm existing ones in order to 
achieve a high accuracy alignment. We call this 
procedure ?alignment by syntactic propagation?. 
2 State of the art 
2.1 Term alignment 
Two kinds of methods have been basically 
proposed in order to address the problem of 
bilingual lexicon extraction. On the one hand, 
terms are recognized in both source and target 
language and then they are mapped to each other 
(Daille, Gaussier and Lang?, 1994). On the other 
hand, only source terms are extracted and the 
target ones are discovered through the alignment 
process (Gaussier, 1998; Hull, 2001). The 
alignment between terms is obtained either by 
computing association probabilities (Gaussier, 
1998 ; Daille, Gaussier and Lang?, 1994) or by 
identifying, for a given source term, a sequence of 
words in the target language which is likely to 
contain or to correspond to its translation (Hull, 
2001). In so far as the precision rate may be 
affected by the number of alignments obtained 
(Daille, Gaussier and Lang?, 1994; Gaussier, 
1998), the results achieved basically range between 
80% and 90%, for the first 500 alignments. As for 
the method described in (Hull, 2001), the precison 
reported is 56%. 
It should be noticed that the use of linguistic 
knowledge is most of the time restricted to the 
term recognition stage. This kind of knowledge is 
quite rarely taken into account within the very 
alignment process, except for the approach 
implemented by Daille, Gaussier and Lang? 
(1994), which try to take advantage of 
correspondences between the syntactic patterns 
defined for each language. 
2.2 Word alignment 
Quite recently attempts have been made in order 
to incorporate different types of linguistic 
information sources into word alignment systems 
and to combine them with statistical knowledge. 
Various and more or less complex sources of 
linguistic knowledge are exploited: morphological, 
lexical (Arhenberg, Andersson and Merkel, 2000) 
and syntactic knowledge (Wu, 2000; Lin and 
Cherry, 2003). The contribution of these 
information sources to the alignment process with 
respect to the statistical data varies according to the 
considered system. However, as pointed out by 
Arhenberg, Andersson and Merkel (2000) as well 
as Lin and Cherry (2003), the introduction of 
linguistic knowledge leads to a significant 
improvement in alignment quality. In the first case, 
the accuracy goes from 91% for a baseline 
configuration up to 96.7% for a linguistic 
knowledge based one. In the second, the precision 
rate is increased from 82.7% up to 89.2% and the 
improvement noticed have been confirmed within 
the framework of an evaluation task (Mihalcea and 
Pedersen, 20003). 
For our part, we propose a method in which the 
syntactic information plays a major role in the 
alignment process, since syntactic relations are 
used to find out new correspondences between 
words or to confirm the existent ones. We chose 
this approach in order to achieve a high accuracy 
alignment both at word and phrase level. Indeed, 
we aim at capturing frequent alignments between 
words and phrases as well as those involving 
sparse or corpus specific ones. Moreover, as 
stressed in previous works, using syntactic 
dependencies seems to be particularly well suited 
to solve n-to-1 or n-to-m alignments (Fluhr, Bisson 
and Elkateb, 2000) and to cope with the problem of 
linguistic variation and non correspondence across 
languages, for instance when aligning terms 
(Gaussier, 2001).  
3 Starting hypothesis 
We take as a starting point the hypothesis 
formulated by Debili and Zribi (1996) according to 
which ?paradigmatic connections can help to 
determine syntagmatic relations, and conversely?1. 
More precisely, the idea is that one can make use 
of syntactic relations to validate or invalidate the 
existence of alignment links, on the one hand, and 
to create new ones, on the other hand. The 
reasoning is as follows : if there is a pair of anchor 
words, i.e. if two words w1i (community in the 
example) and w2m (communaut?) are aligned at the 
sentence level, and if there is a syntactic relation 
standing between w1i (community) and w1j (ban) 
on the one hand, and between w2m (communaut?) 
and w2n (interdire) on the other hand, then the 
alignment link is propagated from the anchor pair 
(community, communaut?) to the words (ban, 
interdire). We call this procedure ?alignment by 
syntactic propagation?. 
 
 
                                                     
                                                     1Our translation of the French version ? les liaisons 
paradigmatiques peuvent aider ? d?terminer les 
relations syntagmatiques, et inversement ?. 
 
 
The Community banned imports of ivory. 
SUBJECT 
 
La Communaut? a interdit l?importation d?ivoire. 
 
SUBJECT  
 
 
In the rest of this article, we describe the overall 
design and implementation of the syntactic 
propagation process and the results of applying it 
to two parsed French/English parallel corpora: 
INRA and JOC. 
4 Corpus processing 
The alignment by syntactic propagation was 
tested on two different parallel corpora aligned at 
the sentence level: INRA and JOC. The first 
corpus was constituted at the National Institute for 
Agricultural Research (INRA)2 to enrich a 
bilingual terminology database exploited by 
translators. It comprises about 300,000 words and 
mainly consists of research and popular-science 
papers, press releases. 
The JOC corpus was provided by the ARCADE 
project, a campaign devoted to the evaluation of 
parallel text alignment systems (Veronis and 
Langlais, 2000). It contains written questions on a 
wide variety of topics addressed by members of the 
European Parliament to the European Commission 
and corresponding answers published by the 
Official Journal of the European Community in 
nine official languages. A portion of about 400,000 
words of the French and English parts were used in 
the framework of the ARCADE evaluation task. 
The corpus processing was carried out by a 
French/English parser: SYNTEX (Bourigault and 
Fabre, 2000; Fr?rot, Fabre and Bourigault, 2003). 
SYNTEX is a dependency parser whose input is a 
2 We are grateful to A. Lacombe who allowed us to use 
this corpus for research purposes. 
POS tagged3 corpus?meaning each word in the 
corpus is assigned a lemma and grammatical tag. 
The parser identifies syntactic dependencies in the 
sentences of a given corpus, for instance subjects, 
direct and indirect objects of verbs. Once all 
syntactic dependencies have been identified, a set 
of words and phrases is extracted out of the corpus. 
The association score is computed provided the 
number of overall occurrences of u1 and u2 is 
higher than 4 since statistical techniques have 
proved to be particularly efficient when aligning 
frequent units. Moreover, the alignments are 
filtered according to the j(u1, u2) value, provided 
the latter is higher than 0.2. Then, two tests, based 
on cognate recognition and mutual correspondence 
condition (Altenberg, 1999), are applied as to filter 
spurious associations out of the initial lexicon. 
Both versions of the parser?the French one and 
the English one?are being developed according to 
the same procedures and architecture. The parsing 
is performed independently in each language, yet 
the outputs are quite homogeneous since the 
syntactic dependencies are identified and 
represented in the same way in both languages. In 
this respect, the alignment method proposed is 
different from the ones developed by Wu (2000) as 
well as Lin and Cherry (2003): the former is based 
on synchronous parsing while the letter uses a 
dependency tree generated only in the source 
language. 
The identification of anchor pairs, consisting of 
words which are translation equivalents within 
aligned sentences, combines both the projection of 
the initial lexicon and the recognition of cognates 
for words which have not been taken into account 
in the lexicon. These pairs are used as the starting 
point of the propagation process. 
Table 1
Table 1: The identification of anchor pairs 
 gives some characteristics of the two 
corpora as for the number of aligned sentences, the 
overall number of anchor pairs identified, the 
average number of anchor pairs per sentence pair 
as well as the precision rate4 of the anchor pairs. It 
can be seen that a high number of anchor pairs has 
been identified per sentence for both corpora with 
a high accuracy. 
In addition to parsed French/English corpus 
aligned at the sentence level, the syntactic 
alignment requires pairs of anchor words be 
identified prior to propagation as to start the 
process. In this study, we chose to extract a lexicon 
out of the corpus, the anchor pairs being located 
both by projecting the lexicon at the level of 
aligned sentences and processing the identical and 
fuzzy cognates. 
 
 INRA JOC 
aligned sentences 7056 8774 
anchor pairs 42570 58771 
words/source sentence 21 25 
words/target sentence 24 30 
anchor pairs/sentence 6.38 6.77 
precision (%) 98 99.3 
5 Identification of anchor pairs 
To derive a list of words which are likely to be 
used to initiate the syntactic propagation process 
out of the corpus, we implemented a widely used 
method described notably in (Gale and Church, 
1991; Ahrenberg, Andersson and Merkel, 2000) 
which is based on the assumption that the words 
which appear frequently in aligned text segments 
are potential translation equivalents. For each 
source (English) and target (French) unit, 
respectively u1 and u2, extracted by SYNTEX, the 
translation equivalents are searched for by 
counting co-occurrences of (u1, u2) in aligned 
sentences in comparison with their overall 
occurrences in the corpus and then an association 
score is computed. In this study, we chose the 
Jaccard association score which is calculated as 
follows: 
6 Syntactic propagation 
6.1 Two types of propagation 
The syntactic propagation may be performed 
according to two different directions. Indeed, a 
given word is likely to be both governor and 
dependent with respect to other words. The first 
direction consists in starting with dependent anchor 
words and propagating the alignment link to the 
governors (DepGov propagation). The DepGov 
propagation is a priori not ambiguous since one 
dependent is governed at most by one word. Thus, 
there is just one syntactic relation on which the 
propagation can be based. The syntactic structures 
are said to be parallel in English and French 
provided the two following conditions are met: i) 
the relation under consideration is identical in both 
languages and ii) the words involved in the 
 
f(u1, u2) 
j(u1, u2) =  
f(u1) + f(u2) ? f(u1, u2) 
 
 
                                                     
                                                     3 We use both the French and English versions of the 
Treetagger. (http://www.ims.uni-stuttgart.de) 4 The precision was evaluated manually 
6.2 Alignment of verbs syntactic propagation have the same POS. The 
second direction goes the opposite way: starting 
with governor anchor words, the alignment link is 
propagated to the dependents (GovDep 
propagation). In this case, several relations which 
may be used to achieve the propagation are 
available, as it is possible for a governor to have 
more than one dependent, and so the propagation is 
potentially ambiguous. The ambiguity is 
particularly widespread when performing the 
GovDep propagation from head nouns to their 
nominal and adjectival dependents. Let us consider 
the example (1). There is one occurrence of the 
relation PREP in English and two in French. Thus, 
it is not possible to determine a priori whether to 
propagate using the relations NN/PREP2, on the one 
hand, and PREP1/PREP2?, on the other hand, or 
NN/PREP2? and PREP1/PREP2. Moreover, even if 
there is just one occurrence of the same relation in 
each language, it does not mean that the 
propagation is of necessity performed through the 
same relation, as shown in example (2). 
Verbs are aligned according to eight propagation 
patterns, that is to say five for the DepGov 
propagation and three for the GovDep one. 
DEPGOV PROPAGATION TO ALIGN GOVERNOR 
VERBS. Five propagation patterns are used to align 
verbs: Adv-MOD-V (1), N-SUJ-V (2), N-OBJ-V 
(3), N-PREP-V (4) and V-PREP-V (5). 
 
(1) The net is then hauled to the shore. 
Le filet est ensuite hal? ? terre. 
(2) The fish are generally caught when they 
migrate from their feeding areas. 
G?n?ralement les poissons sont captur?s quand ils 
migrent de leur zone d?engraissement. 
(3) Most of the young shad reach the sea. 
La plupart des alosons gagne la mer. 
(4) The eggs are very small and fall to the bottom. 
Les oeufs de tr?s petite taille tombent sur le fond. 
(5) X is a model which was designated to 
stimulate? 
X est un mod?le qui a ?t? con?u pour stimuler?    GOVDEP PROPAGATION TO ALIGN DEPENDENT 
VERBS. The alignment links are propagated from 
the dependents to the verbs using three propagation 
patterns: V-PREP-V (1), V-PREP-N (2) and V-
PREP-Adj (3). 
 NN       PREP1 
(1)  
 outdoor use  of water 
utilisation  en ext?rieur de l?eau 
PREP2 
 
   (1) Ploughing tends to destroy the soil 
microaggregated structure.  PREP2?  Le labour tend ? rompre leur structure 
microagr?g?e.  (2)  (2) The capacity to colonize the digestive 
mucosa? 
NN             PREP1 
 
 L?aptitude ? coloniser le tube digestif? 
ADJ 
reference product on the market 
produit commercial de r?f?rence 
 (3) An established infection is impossible to 
control.   Toute infection en cours est impossible ? ma?triser.    PREP2  DepGov 
propagation 
GovDep 
propagation
INRA 
precision (%) 94.1 96.7 
JOC 
precision (%) 92.7 97.5 
 
 
In the following sections, we describe precisely 
the implementation of the two types of propagation 
defined above in order to align verbs (section  6.2), 
on the one hand, and nouns and adjectives, on the 
other hand (section  6.3). To this, we rely on 
different propagation patterns. Propagation 
patterns are given in the form CDep-REL-CGov, 
where CDep is the POS of the dependent, REL is 
the syntactic relation and CGov, the POS of the 
governor. The anchor element is underlined and 
the one aligned by propagation is bolded. For 
instance, the pattern N-SUJ-V corresponds to the 
propagation going from a noun anchor pair to the 
verbs through the subject relation. 
Table 2: Alignment of verbs by means of the 
DepGov and GovDep propagation 
6.3 Alignment of adjectives and nouns 
As for verbs, the two types of propagation 
described in section  6.1 are used to align adjectives 
and nouns. However, as far as these categories of 
words are concerned, they can?t be treated in a 
fully independent way when propagating from 
head noun anchor words in order to align the 
dependents. Indeed, the syntactic structure of noun 
phrases may be different in English and French, 
since they rely on a different type of composition 
to produce compounds and on the same one to 
produce free noun phrases (Chuquet and Paillard, 
1989). Then the potential ambiguity arising from 
the GovDep propagation from head nouns evoked 
in section  6.1 may be accompanied by variation 
phenomena affecting the category of the 
dependents, called transposition (Vinay and 
Darbelnet, 1958; Chuquet and Paillard, 1989). For 
instance, a noun may be rendered by an adjective, 
or vice versa: tax treatment profits is translated by 
traitement fiscal des b?n?fices, so the noun tax is in 
correspondence with the adjective fiscal. The 
syntactic relations used to propagate the alignment 
links are thus different. 
In order to cope with the variation problem, the 
propagation is performed whether the syntactic 
relations are identical in both languages or not, and 
if they are not, whether the categories of the words 
to be aligned are the same or not. To sum up, 
adjectives and nouns are aligned separately of each 
other by means of DepGov propagation or GovDep 
propagation provided that the governor is not a 
noun. They are not treated separately when 
aligning by means of GovDep propagation from 
head noun anchor pairs. 
 
DEPGOV PROPAGATION TO ALIGN ADJECTIVES. 
The propagation patterns involved are: Adv-MOD-
Adj (1), N-PREP-Adj (2) and V-PREP-Adj (3). 
 
(1) The white cedar exhibits a very common 
physical defect. 
Le Poirier-pays pr?sente un d?faut de forme tr?s 
fr?quent. 
(2) The area presently devoted to agriculture 
represents? 
La surface actuellement consacr?e ? l?agriculture 
repr?senterait? 
(3) Only fours plots were liable to receive this 
input. 
Seulement quatre parcelles sont susceptibles de 
recevoir ces apports. 
 
DEPGOV PROPAGATION TO ALIGN NOUNS. Nouns 
are aligned according to the following propagation 
patterns: Adj-ADJ-N (1), N-NN-N/N-PREP-N (2), 
N-PREP-N (3) and V-PREP-N (4). 
 
(1) Allis shad remain on the continental shelf. 
La grande alose reste sur le plateau continental. 
(2) Nature of micropolluant carriers. 
La nature des transporteurs des micropolluants. 
(3) The bodies of shad are generally fusiform. 
Le corps des aloses est g?n?ralement fusiforme. 
(4) Ability to react to light. 
Capacit? ? r?agir ? la lumi?re. 
 
DepGov propagation  
Adjectives Nouns 
INRA 
precision (%) 98.7 94.2 
JOC 
precision (%) 97.2 93.7 
Table 3: Alignment of adjectives and nouns by 
means of the DepGov propagation 
 
UNAMBIUOUS GOVDEP PROPAGATION TO ALIGN 
NOUNS. The propagation is not ambiguous when 
dependent nouns are not governed by a noun. This 
is the case when considering the following three 
propagation patterns: N-SUJ|OBJ-V (1), N-PREP-V 
(2) and N-PREP-Adj (3). 
 
(1) The caterpillars can inoculate the fungus. 
Les chenilles peuvent inoculer le champignon. 
(2) The roots are placed in tanks. 
Les racines sont plac?es en bacs. 
(3) Botrysis, a fungus responsible for grey rot. 
Botrysis, champignon responsable de la pourriture 
grise. 
 
POTENTIALLY AMBIGUOUS GOVDEP 
PROPAGATION TO ALIGN NOUNS AND ADJECTIVES. 
As we already explained in section  6.1, the 
propagation is potentially ambiguous when starting 
with head noun anchor words and trying to align 
the noun(s) and/or adjective(s) they govern. 
Considering this potential ambiguity, the algorithm 
which supports GovDep propagation form head 
noun anchor words (n1, n2) takes into account 
three situations which are likely to occur : 
 
1. if each of n1 and n2 have only one 
dependent, respectively reg1 and reg2, 
involving one of the following relations 
NN, ADJ or PREP; reg1 and reg2 are 
aligned; 
the drained whey 
le lactos?rum d??gouttage 
? (drained, ?gouttage) 
 
2. n1 has one dependent reg1 and n2 several 
ones {reg21, reg22, ?, reg2n}, or vice 
versa. For each reg2i, check if one of the 
possible alignments has already been 
performed, either by propagation or anchor 
word spotting. If such an alignment exists, 
remove the others (reg1, reg2k) such as k ? 
i, or vice versa. Otherwise, retain all the 
alignments (reg1, reg2i), or vice versa, 
without solving the ambiguity; 
stimulant substances which are absent 
from? 
substances solubles stimulantes absentes 
de? 
(stimulant, {soluble, stimulant, absent}) 
already_aligned(stimulant, stimulant) = 1 
? stimulant, stimulant) 
 
3. both n1 and n2 have several dependents, 
{reg11, reg12, ?, reg1m} and {reg21, 
reg22, ?, reg2n} respectively. For each 
reg1i and each reg2j, check if one/several 
alignments have already been performed. 
If such alignments exist, remove all the 
alignments (reg1k, reg2l) such as k ? i or 
l ? j. Otherwise, retain all the alignments 
(reg1i, reg2j) without solving the 
ambiguity. 
unfair trading practices 
pratiques commerciales d?loyales 
(unfair, {commercial, d?loyal}) 
(trading, {commercial, d?loyal}) 
already_aligned(unfair, d?loyal) = 1 
? (unfair, d?loyal) 
? (trading, commercial) 
a big rectangular net, which is lowered? 
un vaste filet rectangulaire immerg?? 
(big, {vaste, rectangulaire, immerg?}) 
(rectangular, {vaste, rectangulaire, immerg?}) 
already_aligned(rectangular, rectangulaire) = 1 
? (rectangular, rectangulaire) 
? (big, {vaste, immerg?}) 
 
The implemented propagation algorithm has two 
major advantages: it allows to solve some 
alignment ambiguities taking advantage of 
alignments which have been performed previously. 
This algorithm allows also to cope with the 
problem of non correspondence between English 
and French syntactic structures and makes it 
possible to align words using different syntactic 
relations in both languages, even though the 
category of the words under consideration is 
different. 
 
 
GovDep propagation  
Gov?Noun Gov=Noun 
INRA 
precision (%) 95.4 97.7 
JOC 
precision (%) 95 95.4 
Table 4: Alignment of adjectives and nouns by 
means of the GovDep propagation 
6.4 Overall results 
Table 5 gives a summary of the results obtained 
by applying all propagation patterns according to 
each corpus. It can be seen that the highest 
accuracy is achieved for the alignments 
corresponding to anchor pairs validated by the 
syntactic propagation (AP and PP): 99.7 and 
99.8% precision, respectively for INRA and JOC. 
The rates tend to decrease ? respectively 88.5 and 
86.1% ? as regards alignments established only by 
means of propagation, referred to as propagated 
pairs (PP), and is even lower ? 76.3% ? for the 
anchor pairs which have not been confirmed by the 
propagation (AP). Furthermore, the new 
alignments produced account for less than 20% of 
overall alignments to approximately 50% for the 
confirmed ones. Finally, since the method aims at 
aligning content words, the recall is assessed in 
relation to their overall occurrences in the corpora. 
 
 Total AP AP and PP PP 
INRA 
alignments 
50438 
(100%) 
23646 
(47%) 
18923 
(37%)
7868 
(16%)
precision (%) 94.3 76.3 99.7 88.5 
recall (%) 58 
JOC 
alignments 
71814 
(100%) 
37118 
(52%) 
21625 
(30%)
13073 
(18%)
precision (%) 93.1 94 99.8 86.1 
recall (%) 56 
Table 5: overall results of word alignment 
7 Discussion 
The results achieved by the syntactic 
propagation method are quite encouraging. They 
show a high global precision rate ? 94.3% for the 
INRA corpus and 93.1% for the JOC ? assessed 
respectively against a reference list of 
approximately 8000 and 4600 alignments. 
Various reasons make it difficult to compare the 
results of this experiment with those reported in the 
literature and presented in section 2. Indeed, each 
approach has been tested on a different corpus and 
the results achieved could depend on the type of 
texts used for evaluation purposes. Moreover, the 
reference alignment lists, i.e. the gold standards, 
have probably been established according to 
different annotation criteria, which could also 
influence the quality of the results. Finally, each 
system has been designed, or at least used, to 
perform a specific task and evaluated in this 
respect. Daille, Gaussier and Lang? (1994), as well 
as Gaussier (1998) and Hull (2001), were 
interested in bilingual terminology extraction so 
that word alignment could not be considered as an 
end in itself but rather as a basis for term 
alignment. The system proposed by Wu (2000) 
aims at bilingual language modelling, word and 
phrase alignment is incorporated as a subtask. 
Finally, Arhenberg, Andersson and Merkel (2000) 
as well as Lin and Cherry (2003) addressed the 
problem of full word alignment without restricting 
themselves to content words. Both noticed that the 
integration of linguistic knowledge, morphological 
and lexical for the former, syntactic for the latter, 
improves the alignment quality. However, 
concerning the approach proposed by Lin and 
Cherry (2003), it should be pointed out that 
linguistic knowledge is considered secondary to 
statistical information. As regards the alignment by 
syntactic propagation, linguistic knowledge is the 
kernel of the approach rather than an additional 
information. 
The propagation of alignments links using 
syntactic relations has proved very efficient when 
the same propagation pattern is used in both 
languages, i.e. when the syntactic structures are 
identical. A high level of precision is also achieved 
in the case of noun/adjective transpositions, even if 
the category of the words to be aligned varies. We 
are actually pursuing the study of non-
correspondence between syntactic structures in 
English and French outlined in (Ozdowska and 
Bourigault, 2004). The aim is to determine whether 
there are some regularities in rendering certain 
English structures into certain French ones or not. 
If variation across languages is subjected to such 
regularities, the syntactic propagation could then 
be extended to the cases of non correspondence. 
References  
Ahrenberg L., Andersson M. and Merkel M. 2000. 
A knowledge-lite approach to word alignment, 
V?ronis J. (Ed.), Parallel Text Processing : 
Alignment and Use of Translation Corpora, 
Dordrecht: Kluwer Academic Publishers, pp. 97-
138. 
Altenberg B. 1999. Adverbial connectors in 
English and Swedish: Semantic and lexical 
correspondences, Hasselgard and Oksefjell (eds), 
pp. 249-268. 
Bourigault D. and Fabre C. 2000. Approche 
linguistique pour l?analyse syntaxique de corpus, 
Cahiers de Grammaire, 25, pp. 131-151, 
Universit? Toulouse le Mirail. 
Brown P., Della Pietra S. and Mercer R. 1993. The 
mathematics of statistical machine translation : 
parameter estimation, Computational 
Linguistics, 19(2), pp. 263-311.  
Chuquet H. and Paillard M. 1989. Approche 
linguistique des probl?mes de traduction 
anglais/fran?ais, Ophrys.  
Daille B., Gaussier E. and Lang? J.-M. 1994. 
Towards Automatic Extraction of Monolingual 
and Bilingual Terminology, Proceedings of the 
International Conference on Computational 
Linguistics (COLING?94) , pp. 515-521.  
Debili F. 1997. L?appariement :quels probl?mes ?, 
Actes des 1?res JST 1997 FRANCIL de 
l?AUPELF-UREF, pp. 199-206. 
Debili F. and Zribi A. 1996. Les d?pendances 
syntaxiques au service de l?appariement des 
mots, Actes du 10?me Congr?s Reconnaissance 
des Formes et Intelligence Artificielle 
(RFIA?96). 
Fluhr C., Bisson B. and Elkateb F. 2000. Parallel 
Text Alignment Using Crosslingual Information 
Retrieval Techniques, V?ronis, J. (Ed.), Parallel 
Text Processing : Alignment and Use of 
Translation Corpora, Dordrecht: Kluwer 
Academic Publishers. 
Fox H. J. 2002. Phrasal Cohesion and Statistical 
Machine Translation, Proceedings of EMNLP-
02, pp. 304-311. 
Fr?rot C., Bourigault D. and Fabre C. 2003. Marier 
apprentissage endog?ne et ressources exog?nes 
dans un analyseur syntaxique de corpus. Le cas 
du rattachement verbal ? distance de la 
pr?position ? de ?,  in Traitement Automatique 
des Langues, 44-3. 
Fr?rot C., Rigou G. and Lacombe A. 2001. 
Approche phras?ologique d?une extraction 
automatique de terminologie dans un corpus 
scientifique bilingue align?, Actes des 4?mes 
rencontres Terminologie et Intelligence 
Artificielle, Nancy, pp 180-188. 
Gale W. A. and Church K. W. 1991. Identifying 
Word Correspondences in Parallel Text, 
Proceedings of the DARPA Workshop on Speech 
and Natural Language.  
Gaussier E. 1998. Flow Network Models for Word 
Alignment and Terminology Extraction from 
Bilingual Corpora, Proceedings of the joint 17th 
International Conference on Computational 
Linguistics and 36th Annual Meeting of the 
Association for Computational Linguistics 
(COLING/ACL?98) , pp. 444-450.  
Gaussier E. 2001. General considerations on 
bilingual terminology extraction, D. Bourigault, 
Ch. Jacquemin, M.?C. L?Homme (Eds.), Recent 
Advances in Computational Terminology, John 
Benjamins, pp. 167-183.  
Harris B. 1988. Bi-text, A New Concept in 
Translation Theory, Language Monthly, 54, 
pp.8-10.  
Hull D. 2001. Software tools to support the 
construction of bilingual terminology lexicons, 
Bourigault, D., Jacquemin, Ch. and L?Homme, 
M.-C. (Eds.), Recent Advances in Computational 
Terminology, John Benjamins, pp. 225-244.  
Lin D. and Cherry C. 2003a. Linguistic Heuristics 
in Word Alignment, Proceedings of PACLing 
2003. 
Lin D. and Cherry C. 2003b. ProAlign: Shared 
Task System Description, Workshop 
Proceedings on Building and Using Parallel 
Texts: Data Driven Machine Translation and 
Beyond (HLT-NAACL 2003). 
Mihalcea R. and Pedersen T. 2003. An Evaluation 
Exercise for Word Alignment, Workshop 
Proceedings on Building and Using Parallel 
Texts: Data Driven Machine Translation and 
Beyond (HLT-NAACL 2003), pp. 1-10 
Och F. Z. and Ney H., 2003. A Systematic 
Comparison of Various Statistical Alignment 
Models, Computational Linguistics, 29(1), pp. 
19-51. 
Ozdowska S. and Bourigault D. 2004. D?tection de 
relations d?appariement bilingue entre termes ? 
partir d?une analyse syntaxique de corpus, Actes 
du 14?me Congr?s Francophone AFRIF-AFIA de 
Reconnaissance des Formes et Intelligence 
artificielle 
V?ronis J. (Ed). 2000. Parallel Text Processing : 
Alignment and Use of Parallel Corpora, 
Dordrecht : Kluwer Academic Publishers.  
V?ronis J. and Langlais P. 2000. Evaluation of 
parallel text alignment systems. The ARCADE 
project, V?ronis J. (ed.), Parallel Text 
Processing : Alignment and Use of Translation 
Corpora, Dordrecht: Kluwer Academic 
Publishers, pp. 371-388 
Vinay J-P. and Darbelnet J. 1958. Stylistique 
compar?e du fran?ais et de l?anglais , Paris, 
Didier.  
Wu D. 2000. Bracketing and aligning words and 
constituents in parallel text using Stochastic 
Inversion Transduction Grammars, V?ronis, J. 
(Ed.), Parallel Text Processing : Alignment and 
Use of Translation Corpora, Dordrecht: Kluwer 
Academic Publishers, pp. 139-167. 
 
Projecting POS tags and syntactic dependencies from English and French
to Polish in aligned corpora
Sylwia Ozdowska
ERSS - CNRS & Universit? Toulouse-le Mirail
Maison de la Recherche
5 all?es Antonio Machado
F-31058 Toulouse Cedex 9
ozdowska@univ-tlse2.fr
Abstract
This paper presents the first step to project
POS tags and dependencies from English
and French to Polish in aligned corpora.
Both the English and French parts of the
corpus are analysed with a POS tagger
and a robust parser. The English/Polish
bi-text and the French/Polish bi-text are
then aligned at the word level with the
GIZA++ package. The intersection of
IBM-4 Viterbi alignments for both trans-
lation directions is used to project the an-
notations from English and French to Pol-
ish. The results show that the precision
of direct projection vary according to the
type of induced annotations as well as the
source language. Moreover, the perfor-
mances are likely to be improved by defin-
ing regular conversion rules among POS
tags and dependencies.
1 Introduction
A clear imbalance may be observed between lan-
guages, such as English or French, for which a
number of NLP tools as well as different linguistic
resources exist (Leech, 1997) and those for which
they are sparse or even absent, such as Polish.
One possible option to enrich resource-poor lan-
guages consists in taking advantage of resource-
rich/resource-poor language aligned corpora to in-
duce linguistic information for the resource-poor
side from the resource-rich side (Yarowski et al,
2001; Borin, 2002; Hwa et al, 2002). For Pol-
ish, this has been made possible on account of its
accessing to the European Union (EU) which has
resulted in the construction of a large multilingual
corpus of EU legislative texts and a growing inter-
est for new Member States languages.
This paper presents a direct projection of vari-
ous morpho-syntactic informations from English
and French to Polish. First, a short survey of re-
lated works is made in order to motivate the is-
sues addressed in this study. Then, the principle of
annotation projection is explained and the frame-
work of the experiment is decribed (corpus, POS
tagging and parsing, word alignment). The re-
sults of applying the annotation projection princi-
ple from two different source languages are finally
presented and discussed.
2 Background
Yarowski, Ngai and Wicentowski (2001) have
used annotation projection from English in order
to induce statistical NLP tools for instance for Chi-
nese, Czech, Spanish and French. Different kinds
of analysis were produced: POS tagging, noun
phrase bracketing, named entity tagging and in-
flectional morphological analysis, and relied on to
train statistical tools for each task. The authors re-
port that training allows to overcome the problem
of erroneous and incomplete word alignment thus
improving the accuracy as compared to direct pro-
jection: 96% for core POS tags in French.
The study proposed by Hwa, Resnik, Weinberg
and Kolak (2002) aims at quantifying the degree to
which syntactic dependencies are preserved in En-
glish/Chinese aligned corpora. Syntactic relation-
ships are projected to Chinese either directly or us-
ing elementary transformation rules which leads to
68% precision and about 66% recall.
Finally, Borin (2002) has tested the projection
of major POS tags and associated grammatical
informations (number, case, person, etc.) from
53
Swedish to German. 95% precision has been
obtained for major POS tags1 whereas associ-
ated grammatical informations have turned out
not to be applicable across the studied languages.
A rough comparison has been made between
Swedish, German and additional languages (Pol-
ish, English and Finnish). It tends to show that
it should be possible to derive indirect yet regular
POS correspondences, at least across fairly similar
languages.
The projection from French and English to Pol-
ish presented in this paper is basically a direct
one. It concerns different linguistic informations:
POS tags and associated grammatical information
as well as syntactic dependencies. Regarding the
works mentioned above, uneven results are ex-
pected depending on the type of annotations in-
duced. This is the first point this study considers.
The second one is to identify regularity in render-
ing some French or English POS tags or depen-
dencies with some Polish ones. Finally, the idea is
to test if the results vary significantly with respect
to the source language used for the induction.
3 Projecting morpho-syntactic
annotations
We take as the starting point of annotation projec-
tion the direct correspondence assumption as for-
mulated in (Hwa et al, 2002): ?for two sentences
in parallel translation, the syntactic relationships
in one language directly map the syntactic rela-
tionships in the other?, and extend it to POS tags
as well. The general principle of annotation pro-
jection in aligned corpora may be explained as fol-
lows:
if two words w1 and w2 are translation equiv-
alents within aligned sentences, the morpho-
syntactic informations associated to w1 are
assigned to w2
In this study, the projected annotations are POS
tags, with gender and number subcategories for
nouns and adjectives, on one hand, and syntactic
dependencies on the other hand.
Let us take the example of Commission and
Komisja, respectively w1i and w2m, two aligned
words (figure 1). In accordance with the annota-
tion projection principle, Komisja is first assigned
the POS N (noun) as well as the information on
its number, sg (singular), and gender f (feminine).
1Assessed on correct alignments.
Furthermore, the dependencies connecting w1i to
other words w1j are examined. Foreach w1j , if
there is an alignment linking w1j and w2n, the de-
pendency identified between w1i and w2j is pro-
jected to w2m and w2n. For example, the noun
Commission (w1i) is syntactically connected to
the verb adopte (w1j) through the subject relation
and adopte is aligned to przyjmuje (w2n). There-
fore, it is possible to induce a dependency relation,
namely a subject one, between Komisja (w2m) and
przyjmuje (w2n)2.
Nfsg
Nfsg
subj
Komisja przyjmuje roczny program
La Commission adopte un programme  annuel
V
V
NmsgDET ADJmsg
ADJmsg Nmsg
DET
subj
Figure 1: Projection of POS tags and dependen-
cies from French to Polish
The induced dependencies are given the same la-
bel as the source dependencies that is to say that
the noun Komisja and the verb przyjmuje are con-
nected through the subject relation. Moreover, in
this preliminary study, the projection is basically
limited to cases where there is exactly one relation
going from w1i and w1j on the one hand, and from
w2m and w2n on the other hand. Thus, as shown
in figure 2, the relation connecting Komisja and
przyjmuje could not be induced from English since
Commission and adapt are not linked directly but
by means of the modal shall.
AUX ADJ
ADJ N
DET DET
auxsubj
N
N V
V
Komisja przyjmuje roczny program
N
The Commission shall adopt an annual program
Figure 2: Projection of POS tags and dependen-
cies from English to Polish
2The POS and the additional grammatical informations
available are also projected from the verb adopte to przyj-
muje.
54
The only exception concerns the complement and
prepositional complement relations. Indeed, Pol-
ish is a highly inflected language which means
that: 1) word order is less constrained than in
French and English 2) syntactic relations between
words are indicated by the case. This is the reason
why, going back to figure 1, the projection from
the nouns programme and travail, linked by the
preposition de, results in the induction of a rela-
tion between the nouns program and pracy.
4 Experimental framework
4.1 Bi-texts
The countries wishing to join the EU have first to
approve the Acquis Communautaire. The Acquis
communautaire encompasses the core EU law, its
resolutions and declarations as well as the com-
mon aims pursued since its creation in the 1950s.
It comprises about 8,000 documents that have
been translated and published by official institu-
tions3 thus ensuring a high quality of translation.
Each language version of the Acquis is considered
semantically equivalent to the others and legally
binding. This collection of documents is made
available on Europe?s website4.
The AC corpus is made of a part of the Acquis texts
in 20 languages5, and in particular the languages
of the new Member States6. It has been collected
and aligned at the sentence level by the Language
Technology team at the Joint Research Centre
working for the European Commision7 (Erjavec
et al, 2005; Pouliquen and Steinberger, 2005).
It is one of the largest parallel corpus regarding
its size8 and the number of different languages it
covers. A portion of the English, French and Pol-
ish parts form the multilingual parallel corpus se-
lected for this study. Table 1 gives the main fea-
tures of each part of the corpus.
3Only European Community legislation printed in the pa-
per edition of the Official Journal of the European Union is
deemed authentic.
4http://europa.eu.int/eur-lex/lex
5German, English, Danish, Spanish, Estonian, Finish,
French, Greek, Hungarian, Italian, Latvian, Lithuanian, Mal-
tese, Deutch, Polish, Portugese, Slovak, Slovene, Swedish
and Czech.
6In 2004, the EU welcomed ten new Member States:
Cyprus, Estonia, Hungary, Latvia, Lithuania, Malta, Poland,
Czech Republic, Slovakia, Slovenia.
7http://www.jrc.cec.eu.int/langtech/index.html
8The number of word forms goes from 6 up to 13 million
according to the language. The parts corresponding to the
languages of the new Member States range from 6 up to 10
million word forms as compared to 10 up to 13 million for
English French Polish
word forms 562,458 809,036 764,684
sentences 52,432
Table 1: AC ? the English/French/Polish parallel
corpus
4.2 Bi-text processing
4.2.1 POS tagging
Both the English and French parts of the corpus
have been POS tagged and parsed. The POS tag-
ging has been performed using the TreeTagger
(Schmidt, 1994). Among the morpho-syntactic in-
formations provided by the TreeTagger?s tagset,
only the main distinctions are kept for further anal-
ysis: noun, verb, present participle, adjective, past
participle, adverb, pronoun and conjunction (co-
ordination and subordination). Nouns, adjectives
and past participles are assigned data related to
their number and gender and verbs are assigned
information on voice, gender and form (infinitive
or not), if available (table 2). The TreeTagger?s
output is given as input to the parser after a post-
processing stage which modifies the tokenization.
Some multi-word units are conflated (for exam-
ple complex prepositions such as in accordance
with, as well as for English, conform?ment ?, sous
forme de for French, adverbs like in particular, at
least, en particulier, au moins, or even verbs pren-
dre en consid?ration, avoir recours).
4.2.2 Parsing
Each post-processed POS-tagged corpus is anal-
ysed with a deep and robust dependency parser:
SYNTEX (Fabre and Bourigault, 2001; Bourigault
et al, fothcoming). For each sentence, SYN-
TEX identifies syntactic relations between words
such as subject (SUBJ), object (OBJ), preposi-
tional modifier (PMOD), prepositional comple-
ment (PCOMP), modifier (MOD), etc. Both ver-
sions of the parser are being developed accord-
ing to the same procedure and architecture. The
outputs are quite homogeneous in both languages
since the dependencies are identified and repre-
sented in the same way, thus allowing the compar-
ision of annotations induced from either French or
English. Table 2 gives some examples of the basic
relations taken into account as well as the tags as-
signed to the syntactically connected words. The
the languages of the ?pre-enlargement? EU.
55
parts of speech are in upper case (N represents a
noun, V a verb, etc.) and the grammatical informa-
tion (number, gender) is in lower case (sg reprents
the singular, pl the plural, f the feminine and m the
masculine).
(the) Regulation_Nsg SUBJ?? establishes_Vsg
(le) r?glement_Nmsg SUBJ?? d?termine_Vsg
covering_PPR OBJ?? placing_PPR PMOD?? on_PREP
PCOMP
?? (the) market_Nsg
(qui) r?gissent_Vpl OBJ?? (la) mise_Nfsg PMOD?? sur_PREP
PCOMP
?? (le) march?_Nmsg
further_ADJ MOD?? calls_Npl
appels_Nmpl MOD?? suppl?mentaires_ADJpl
(the) Member_Nsg MOD?? States_Npl
(les) ?tats_Nmpl MOD?? Membres_Nmpl
(the debates) clearly_ADV MOD?? illustrate_Vpl
(les d?bats) montrent_Vpl MOD?? clairement_ADV
(placing on) the_DET DET?? market_Nsg
la_DET DET?? mise (sur) le_DET DET?? march?_Nmsg
Table 2: Syntactic dependencies identified with
SYNTEX
4.2.3 Word alignment
The English/Polish parts of the corpus on the one
hand, and the French/Polish parts on the other
hand, have been aligned at the word level using the
GIZA++ package9 (Och and Ney, 2003). GIZA++
consists of a set of statistical translation mod-
els of different complexity, namely the IBM ones
(Brown et al, 1993). For both corpora, the tok-
enization resulting from the post-processing stage
prior to parsing was used in the alignment pro-
cess for the English and Polish parts in order to
keep the same segmentation especially to facilitate
manual annotation for evaluation purposes. More-
over, each word being assigned a lemma at the
POS tagging stage, the sentences given as input to
GIZA++ were lemmatized, as lemmatization has
proven to boost statistical word alignment perfor-
mances. On the Polish side, a rough tokeniza-
tion using blanks and punctuation was realised; no
lemmatization was performed. The IBM-4 model
has been trained on each bi-text in both trans-
lation directions and the intersection of Viterbi
9GIZA++ is available at
http://www.jfoch.com/GIZA++.html.
alignments obtained has been used to project the
morpho-syntactic annotations. In other words, our
first goal was to test the extent to which the di-
rect projection across English or French and Polish
was accurate. Therefore, we relied only on one-
to-one alignments, thus favouring precision to the
detriment of recall for this preliminary study. Fig-
ure 3 shows an example of word alignment output.
The intersection in both directions is represented
with plain arrows; the dotted ones represent uni-
directional alignments. It shows that the intersec-
tion results in an incomplete alignment which may
differ depending on the pair of languages consid-
ered and the segmentation performed in each lan-
guage10.
Les sanctions sont r?gl?es dans la convention de subvention
Sankcje sa uregulowane w porozumiewaniach o dotacji
Sanctions are_regulated in grant agreements
Figure 3: Intersection of IMB-4 model Viterbi
alignments in both translation directions
5 Evaluation
5.1 Method
In order to evaluate the annotation projection,
an a posteriori reference was constructed, which
means that a sample of the output was selected
randomly and annotated manually. There are some
advantages to work with this kind of reference.
First, it is less time-consuming than an a apri-
ori reference built independently from the output
obtained. Second, it allows to skip the cases for
which it is difficult to decide whether they are cor-
rect or not: syntactic analysis may be ambiguous
and translation often makes it difficult to deter-
mine which source unit corresponds to which tar-
get one (Och and Ney, 2003). A better level of
confidence may thus be ensured with an a poste-
riori reference in comparison with a human anno-
tation task where a choice is to be made for each
case. Finally, whatever strategy is adopted, there
is always a part of subjectivity in human annota-
tion. Thus, the results may vary from one person
to another. The major drawback of an a posteriori
reference is that it allows to assess only precision
10The underscore indicates token conflation .
56
and not recall since it precisely only contains data
provided as output of the algorihtm subjected to
evaluation.
5.2 Parameters
The sample used in order to constitute the a pos-
teriori reference is made of 50 French/Polish sen-
tences and 50 English/Polish sentences. The same
sentences in each language version were selected.
Indeed, one of the goals of this study is to deter-
mine if the choice of the source language has an
influence on annotation projection results. These
50 sentences correspond to 800 evaluated tags and
400 evaluated dependencies in the French/Polish
bi-text, and 782 evaluated POS tags and 391 de-
pendencies in the English/Polish bi-text.
Several parameters have been taken into account
for each type of annotation projection by answer-
ing yes or no to the points listed below.
For POS tags:
1a. the projected POS is the correct one;
2a. the gender and number of nouns, adjectives
and past participles are correct.
The gender parameter has been evaluated only for
the projection from French to Polish as this infor-
mation was not available in English.
For dependencies:
1b. there is a dependency relation between two
given Polish words regardless of its label;
2b. the label of the dependency is correct.
Each time the answer to points 2a and 2b was no,
the information about the correct annotation was
added.
6 Results
6.1 Performances
Table 3 presents the number of projected POS tags
and dependencies with respect to each source lan-
guage. It gives the precision for each parameter,
POS tag (1a), number and gender (2a), unlabeled
dependencies (1b) and labeled dependencies (2b)
assessed against the a posteriori reference.
It shows that the number of projected POS tags as
well as syntactic relations is slightly lower when
English is used as source language. A lower num-
ber of identified alignment links or dependencies
may explain this difference. It also should be
Fr/Pl En/Pl
projected POS tags 800 782
1a POS tags .87 .88
2a number .88 .91
2a gender .59 ?
projected dependencies 400 391
1b unlabeled dependencies .83 .82
2b labeled dependencies .62 .67
Table 3: Precision according to each evaluated pa-
rameter
noted that the evaluated projections are not nec-
essarily the same in both corpora. As mentioned
in section 5.1, the same sentences were chosen for
evaluation. Nevertheless, since word alignment
depends on the pair of languages involved, it has
an impact on the projections obtained and the a
posteriori reference built on their basis.
The precision rates vary according to the type of
informations induced. No significant difference is
observed whether the source language is French
or English. The number subcategory achieves
the highest score: 0.88 and 0.91 respectively for
French/Polish and English/Polish. Dependencies
rank second?0.83 and 0.82?but an important
decrease in accuracy?about 20%?is observed
when their labels are taken into account. Finally,
for French, the gender category achieves the low-
est score: 0.59. The main reasons for which an-
notation projection fails are investigated hereafter.
The projection of the number and gender subcate-
gories are not taken into account.
6.2 Result analysis
There are various reasons for the failure of the
POS tags and dependencies? projection: a) word
alignment, b) lexical density, c) tokenization, d)
POS tagging/parsing errors and e) insertion (for
dependencies). In following examples, the word
alignments are bold faced and in order to avoid
confusion, the POS tags on the Polish side are the
intended POS tags and not the induced POS tags.
a) The noun countries is aligned to trzecich11
which is actually an adjective. On the other
hand, participation and udzia? being aligned, the
projected dependency is also erroneous.
Participation_N
1
of third countries_N
2
Udzia?_N
1
pan?stw trzecich_ADJ
2
11The correct alignment is pan?stw.
57
b)Under is translated by the prepositionnal phrase
na podstawie but is aligned only to podstawie
which is a noun. Thus, the projected tag cannot be
assigned just to podstawie, which is also the case
with the PMOD dependency between zawarte and
podstawie.
concluded_PPA
1
under_PREP
2
the general
framework
zawarte_PPA
1
na podstawie_N
2
og?lnych ram
c) This case is similar to the previous but
the difference in lexical density is partly caused
by the conflation of in accordance with, which
corresponds to the prepositionnal phrase zgodnie
z, at the post-processing stage of the POS tagging.
They must be constituted
in_accordance_with_PREP
1
the law_N
2
Musza? byc? ustanowione zgodnie_ADV
1
z
prawem_N
2
d) The following example shows an error in
PCOMP attachement resulting in an error in
dependency projection: with is linked to pursue
instead of activities and the same relation is
assigned to o and zajmowac?.
They must pursue_V
1
activities with_PREP
2
a
European dimension
Musza? zajmowac?_V
1
sie? dzia?alnos?cia? o_PREP
2
europejskim wymiarze
e) On the Polish side, the inserted noun
postanowien? governs traktatu. Thus, the PCOMP
dependency does not link dla and traktatu but dla
and postanowien?.
Without prejudice for_PREP
1
the Treaty_N
2
Bez uszczerbku dla_PREP
1
postanowien?
Traktatu_N
2
Considering the precision figures, in partic-
ular those accounting for the projection of
dependencies which decrease significantly when
labels are considered, we tried to determine if
there are indirect yet regular French/Polish and
English/Polish correspondences. By indirect
correspondence we mean that a given source
POS tag or dependency is usually rendered by
a given Polish POS tag or dependency. The
correspondences are calculated provided there
is no error prior to projection (word alignment,
tagging or parsing).
Table 4 shows the direct and indirect correspon-
dences among the POS tags which occur in the
reference set. We can see that there is a direct
correspondence among POS tags in 92% and 93%
of the cases respectively for French/Polish and
English/Polish projection. Moreover, the indirect
correspondences, for example noun/adjective or
verb/noun, are similar for both source languages.
The following examples show occurrences of
noun/adjective and verb/noun correspondences.
the exercice of implementing_N powers
l?exercice des comp?tences d?ex?cution_N
wykonywania uprawnien? wykonawczych_ADJ
measures planned to ensure_V dissemina-
tion
mesures pr?vues pour assurer_V la diffu-
sion s?rodki zaplanowane dla zapewnienia_N
rozpowszechnienia
Some indirect correspondences are more probable
than others that seem unexpected. Most of the
time the latter come from the differences in
tokenization mentioned above.
Fr POS Pl POS c
N_359 N_349; ADJ_6; PPA_3; V_1 .97
ADJ_74 ADJ_69; N_3; V_1; DET_1 .93
V_68 V_55; N_13 .80
PPA_67 PPA_59; V_6; ADJ_1; N_1 .88
PREP_35 PREP_24; N_7; DET_2; V_1;
PPR_1
.68
others_61 same_56 .91
664 612 .92
En POS Pl POS c
N_374 N_364; ADJ_9; PPA_1 .97
PREP_64 PREP_53; N_7; DET_4 .83
V_51 V_35; PPA_10; N_6 .69
ADJ_46 ADJ_42; N_2; V_1; DET_1 .91
DET_36 DET_33; N_2 .91
others_73 same_70 .95
644 597 .93
Table 4: French/Polish and English/Polish POS
tag correspondences
Table 5 summarizes direct and indirect correspon-
dences among syntactic dependency relations.
It can be seen that direct correspondence rates
for dependencies are lower than direct corre-
spondences for POS tags: 78% when the source
language is French source and 82% when it is
58
English. Moreover, the difference according to
the source language?5% in favour of English?is
more important than for POS tags?1% in favour
of English. It is mainly due to the PMOD and
PCOMP relations: the first connects a preposition
to its governor and the second connects the
dependent to a preposition. Since Polish is an
inflected language, the connections between
words are indicated through cases. In particular,
it results in a noun not being necessarily linked
to another noun by a preposition. This is also
the case for English, as far as compounds are
concerned, while in French a preposition is almost
always required to form noun phrases. This is
one of the reasons why the direct correspondence
rate between English and Polish is higher than
between French and Polish. The following
example shows a direct MOD/MOD correspon-
dence for the English/Polish pair and an indirect
PMOD_PCOMP/MOD correspondence for the
French/Polish one.
purity MOD?? criteria_N substances_N listed
les crit?res_N PMOD_de_PCOMP?? puret? des
substances ?num?r?s
kryteria_N MOD?? czysztos?ci_N dla substancji
wymienionych
Fr DEP Pl DEP c
PMOD_111 PMOD_56; MOD_51; OBJ_4 .50
MOD_106 MOD_106 1
PCOMP_35 PCOMP_25; MOD_7; OBJ_2;
PMOD_1;
.71
OBJ_23 OBJ_16; MOD_5; PMOD_2 .69
SUJ_19 SUJ_18; OBJ_1 .94
others_38 same_38 1
332 259 .78
En DEP Pl DEP c
MOD_95 MOD_90; PMOD_5 .94
PMOD_93 PMOD_59; MOD_26; PCOMP_4;
OBJ_3; SUBJ_1
.63
PCOMP_64 PCOMP_49; MOD_8; PMOD_7 .76
DET_29 DET_29 1
OBJ_23 OBJ_22; PMOD_1 .95
others_18 same_18 1
322 267 .83
Table 5: French/Polish and English/Polish syntac-
tic correspondences
7 Discussion
The results of the projection of POS tags and de-
pendencies concur with those reported in the re-
lated works presented in section 2. First, concern-
ing the number and gender subcategories, Borin
(2002) has found that the former is applicable
across languages whereas the latter is less relevant,
at least for the German/Swedish language pair. As
seen in section 3, the projection of the number
subcategory offers the highest score and the pro-
jection of the gender the lowest?0.59. It was to
be expected that gender would perform the worst
considering its arbitrary nature at least in French
and Polish. Indeed, there are three genders in Pol-
ish, masculine, feminine and neutral, as well as
in English, and two in French. Thus, not only the
number of genders across French and Polish is dif-
ferent but they are not distributed in the same way
in both languages. The information on gender was
not available for English, gender being assigned
according to the human/non-human feature.
Considering POS tags, the level of direct corre-
spondence is the highest one when compared to
the number and gender subcategories as well as to
dependencies. The precision performed is how-
ever lower with respect to the figures obtained by
Borin (2002) on the one hand, and Yarowski et
al.?s (2001) on the other hand. In Borin?s study,
precision was assessed provided the word align-
ments used to project POS tags were correct. In
this study, precision has been evaluated regardless
of possible errors prior to projection. When these
errors are discarded, the precision rates are simi-
lar. In Yarowski et al?s work (2001), the evalua-
tion did not concern annotation projection but an
induced tagger trained on 500K occurrences of au-
tomatically derived POS tag projections. Indeed,
the authors claim that direct annotation projection
is quite noisy. This study shows that such a simple
approach can perform fairly well as far as preci-
sion is concerned. The results are likely to be im-
proved by implementing basic POS tag conversion
rules as suggested in (Borin, 2002).
For the projection of dependencies, defining such
conversion rules seems necessary as suggested by
the significant difference in precision when the
projection of unlabeled and labeled dependencies
are compared. Polish does not proceed in the
same way to encode syntactic functions as com-
pared to English or French. Nevertheless, some
of the syntactic divergences observed seem regu-
59
lar enough to be used to derive indirect correspon-
dences. Hwa et al (2002) have noticed that ap-
plying elementary linguistic transformations con-
siderably increases precision and recall when pro-
jecting syntactic relations, at least for the En-
glish/Chinese language pair. The present study
suggests that this kind of approach is promising
for the English/Polish and French/Polish pairs as
well.
The exceptionnal status of the corpus certainly in-
fluences the quality of the results. Legislative texts
of the EU in their different language versions are
legally binding. Thus, they have to be as close
as possible semantically and this constraint may
favour the direct correspondences observed.
8 Conclusion
We have presented a simple yet promising method
based on aligned corpora to induce linguistic an-
notations in Polish texts. POS tags and depen-
dencies are directly projected to the Polish part of
the corpus from the automatically annotated En-
glish or French part. As far as precision is con-
cerned, the direct projection is fairly efficient for
POS tags but appears to be too restrictive for de-
pendencies. Nevetheless, the results are encour-
aging since they are likely to be improved by ap-
plying indirect correspondence rules. They vali-
date the idea of the existence of direct or indirect
yet regular correspondences on the English/Polish
and French/Polish language pairs which has al-
ready been tested with some syntax-based align-
ment techniques (Ozdowska, 2004; Ozdowska and
Claveau, 2005). The next step will consist in ex-
ploiting the indirect correspondences and the mul-
tiple sources of information provided by two dif-
ferent source languages. Moreover, using IBM-4
word alignments in one direction instead of the in-
tersection will be considered.
This work mainly focusses on precision thus lack-
ing information on recall. Larger scale evalua-
tions would be necessary to validate the approach,
particularly evaluations that could measure recall,
since the amount of evaluation data used is this
study could be considered too limited.
References
Lars Borin. 2002. Alignment and tagging. In Lars
Borin, editor, Parallel corpora, parallel worlds: se-
lected papers from a symposium on parallel and
comparable corpora at Uppsala University, pages
207?217. Rodopi, Amsterdam/New York.
Didier Bourigault, C?cile Fabre, C?cile Fr?rot, Marie-
Paule Jacques, and Sylwia Ozdowska. fothcoming.
Acquisition et ?valuation sur corpus de propri?t?s de
sous-cat?gorisation syntaxique. T.A.L (Traitement
Automatique des Langues).
Peter F. Brown, Stephen. A. Della Pietra, Vincent
J. Della Pietra, and Robert L. Mercer. 1993.
The mathematics of statistical machine translation:
parameter estimation. Computational Linguistics,
19(2):263?311.
Toma? Erjavec, Camelia Ignat, Bruno Pouliquen, and
Ralf Steinberger. 2005. Massive multilingual cor-
pus compilation: Acquis communautaire and TO-
TALE. In 2nd Language and Technology Confer-
ence.
C?cile Fabre and Didier Bourigault. 2001. Linguistic
clues for corpus-based acquisition of lexical depen-
dencies. In Corpus Linguisitc Conference.
Rebecca Hwa, Philip Resnik, Amy Weinberg, and
Okan Kolak. 2002. Evaluating translational cor-
respondence using annotation projection. In 40th
Annual Conference of the Association for Compu-
tational Linguistics.
Geoffrey Leech. 1997. Introducting corpus annotation.
In Roger Garside, Geoffrey Leech, and Anthony
McEnery, editors, Corpus Annotation. Linguistic In-
formation from Computer Text corpora, pages 1?18.
Longman, London/New York.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statisical alignment mod-
els. Computational Linguistics, 1(29):19?51.
Sylwia Ozdowska and Vincent Claveau. 2005. Aligne-
ment de mots par apprentissage de r?gles de prop-
agation syntaxique en corpus de taille restreinte.
In Conf?rence sur le Traitement Automatique des
Langues Naturelles, pages 243?252.
Sylwia Ozdowska. 2004. Identifying correspondences
between words: an approach based on a bilingual
syntactic analysis of French/English parallel cor-
pora. In Multilingual Linguistic Resources Work-
shop of COLING?04.
Bruno Pouliquen and Ralf Steinberger. 2005. The ac-
quis communautaire corpus. In JRC Enlargement
and Integration Workshop.
Helmut Schmidt. 1994. Probabilistic part-of-speech
tagging using decision trees. In 1st International
Conference on New Methods in Natural Language
Processing.
David Yarowski, Grace Ngai, and Richard Wicen-
towski. 2001. Inducing multilingual text analysis
tools via robust projection across aligned corpora.
In 1st Human Language Technology Conference.
60
