c? 2002 Association for Computational Linguistics
Incremental Construction and
Maintenance of Minimal Finite-State
Automata
Rafael C. Carrasco? Mikel L. Forcada?
Universitat d?Alacant Universitat d?Alacant
Daciuk et al [Computational Linguistics 26(1):3?16 (2000)] describe a method for constructing
incrementally minimal, deterministic, acyclic finite-state automata (dictionaries) from sets of
strings. But acyclic finite-state automata have limitations: For instance, if one wants a linguistic
application to accept all possible integer numbers or Internet addresses, the corresponding finite-
state automaton has to be cyclic. In this article, we describe a simple and equally efficient method
for modifying any minimal finite-state automaton (be it acyclic or not) so that a string is added
to or removed from the language it accepts; both operations are very important when dictionary
maintenance is performed and solve the dictionary construction problem addressed by Daciuk
et al as a special case. The algorithms proposed here may be straightforwardly derived from
the customary textbook constructions for the intersection and the complementation of finite-
state automata; the algorithms exploit the special properties of the automata resulting from the
intersection operation when one of the finite-state automata accepts a single string.
1. Introduction
In a recent paper in this journal, Daciuk et al (2000) describe two methods for con-
structing incrementally minimal, deterministic, acyclic finite-state automata (dictio-
naries) from sets of strings: The first method adds strings in dictionary order, and the
second one is for unsorted data. Adding an entry is an important dictionary mainte-
nance operation, but so is removing an entry from the dictionary, for example, if it
is found to be incorrect. Since ordering cannot obviously be expected in the removal
case, we will focus on the second, more general problem (a solution for which has
already been sketched by Revuz [2000]).
But dictionaries or acyclic finite automata have limitations: For instance, if one
wants an application to accept all possible integer numbers or Internet addresses, the
corresponding finite-state automaton has to be cyclic. In this article, we show a simple
and equally efficient method for modifying any minimal finite-state automaton (be it
acyclic or not) so that a string is added to or removed from the language it accepts. The
algorithm may be straightforwardly derived from customary textbook constructions
for the intersection and the complementation of finite-state automata; the resulting
algorithm solves the dictionary construction problem addressed by Daciuk et al?s
(2000) second algorithm as a special case.
? Departament de Llenguatges i Sistemes Informa`tics, Universitat d?Alacant, E-03071 Alacant, Spain.
E-mail: carrasco@dlsi.ua.es
? Departament de Llenguatges i Sistemes Informa`tics, Universitat d?Alacant, E-03071 Alacant, Spain.
E-mail: mlf@dlsi.ua.es.
208
Computational Linguistics Volume 28, Number 2
This article has the following parts. In Section 2, we give some necessary math-
ematical preliminaries. The minimal automata resulting from adding or removing a
string are described in detail in Section 3; the algorithms are described in Section 4.
In Section 5, one addition and one removal example are explained in detail, and some
closing remarks are given in Section 6.
2. Mathematical Preliminaries
2.1 Finite-State Automata and Languages
As in Daciuk et al (2000), we will define a deterministic finite-state automaton as
M = (Q,?, ?, q0, F), where Q is a finite set of states, q0 ? Q is the start state, F ? Q is
a set of accepting states, ? is a finite set of symbols called the alphabet, and ?: Q ?
? ? Q is the next-state mapping. In this article, we will define ? as a total mapping;
the corresponding finite-state automaton will be called complete (Revuz 2000). This
involves no loss of generality, as any finite-state automaton may be made complete
by adding a new absorption state ? to Q, so that all undefined transitions point to it
and ?(?, a) =? for all a ? ?. Using complete finite-state automata is convenient for
the theoretical discussion presented in this article; real implementations of automata
and the corresponding algorithms need not contain an explicit representation of the
absorption state and its incoming and outgoing transitions.
For complete finite-state automata, the extended mapping ??: Q ? ?? ? Q (the
extension of ? for strings) is defined simply as
??(q, ) = q
??(q, ax ) = ??(?(q, a), x) (1)
for all a ? ? and x ? ??, with  the empty or null string. The language accepted by
automaton M
L(M) = {w ? ??: ??(q0, w) ? F} (2)
and the right language of state q
L(q) = {x ? ??: ??(q, x) ? F} (3)
are defined as in Daciuk et al (2000).
2.2 Single-String Automaton
We also find it convenient to define the (complete) single-string automaton for string
w, denoted Mw = (Qw,?, ?w, q0w, Fw), such that L(Mw) = {w}. This automaton has
Qw = Pr(w)?{?w}, where Pr(w) is the set of all prefixes of w and ?w is the absorption
state, Fw = {w}, and q0w =  (note that nonabsorption states in Qw will be named after
the corresponding prefix of w). The next-state function is defined as follows
?(x, a) =
{
xa if x , xa ? Pr(w)
?w otherwise
(4)
Note that the single-string automaton for a string w has |Qw| = |w|+ 2 states.
2.3 Operations with Finite-State Automata
2.3.1 Intersection Automaton. Given two finite-state automata M1 and M2, it is easy
to build an automaton M so that L(M) = L(M1) ? L(M2). This construction is found
209
Carrasco and Forcada Incremental Construction of Minimal FSA
in formal language theory textbooks (Hopcroft and Ullman 1979, page 59) and is
referred to as standard in papers (Karakostas, Viglas, and Lipton 2000). The (complete)
intersection automaton has Q = Q1?Q2, q0 = (q01, q02), F = F1?F2, and ?((q1, q2), a) =
(?1(q1, a), ?2(q2, a)) for all a ? ?, q1 ? Q1 and q2 ? Q2.
2.3.2 Complementary Automaton. Given a complete finite-state automaton M, it is
easy to build its complementary automaton M? so that L(M?) = ?? ? L(M); the only
change is the set of final states: F? = Q ? F (Hopcroft and Ullman 1979, page 59). In
particular, the complementary single-string automaton M?w accepting ?? ? {w} is
identical to Mw except that F?w = Q ? {w}.
2.3.3 Union Automaton. The above constructions may be combined easily to obtain a
construction to build, from two complete automata M1 and M2, the (complete) union
automaton M such that L(M) = L(M1) ? L(M2). It suffices to consider that, for any
two languages on ??, L1 ? L2 = ?? ? (?? ? L1) ? (?? ? L2). The resulting automaton
M is identical to the intersection automaton defined above except that F = (F1 ?Q2)?
(Q1 ? F2).
3. Adding and Removing a String
3.1 Adding a String
Given a (possibly cyclic) minimal complete finite-state automaton M, it is easy to
build a new complete automaton M? accepting L(M?) = L(M) ? {w} by applying the
union construct defined above to M and the single-string automaton Mw. The resulting
automaton M? = (Q?,?, ??, q?0, F
?), which may be minimized very easily (see below), has
four kinds of states in Q?:
? States of the form (q,?w) with q ? Q ? {?}, equivalent to those
nonabsorption states of M that are not reached by any prefix of w; they
will be called intact states, because they have the same transition
structure as their counterparts in M (that is, if ?(q, a) = q?, then
??((q,?w), a) = (q?,?w)) and belong to F? if q ? F. As a result, they have
exactly the same right languages, L((q,?w)) = L(q), because all of their
outgoing transitions go to other intact states. Furthermore, each state
(q,?w) has a different right language; therefore, no two intact states will
ever be merged into one by minimization (intact states may, however, be
eliminated, if they become unreachable, as we will describe below). For
large automata (dictionaries) M, these are the great majority of states (the
number of intact states ranges between |Q| ? |w| ? 1 and |Q|); therefore, it
will be convenient in practice to consider M? as a modified version of M,
and it will be treated as such in the algorithms found in this article.
? States of the form (q, x) with q ? Q ? {?} and x ? Pr(w), such that
??(q0, x) = q; they will be called cloned states, inspired by the
terminology in Daciuk et al (2000); the remaining states in
(Q ? {?})? Pr(w)?the great majority of states in Q ? Qw?may safely
be discarded because they are unreachable from the new start state
q?0 = (q0, ), which itself is a cloned state. Cloned states are modified
versions of the original states q ? Q ? {?}: All of their outgoing
transitions point to the corresponding intact states in Q?, that is,
(?(q, a),?w), except for the transition with symbol a : xa ? Pr(w), which
210
Computational Linguistics Volume 28, Number 2
now points to the corresponding cloned state (?(q, a), xa), that is,
??((q, x), a) =
{
(?(q, a), xa) if xa ? Pr(w)
(?(q, a),?w) otherwise
(5)
Cloned states are in F? if the corresponding original states are in F; in
addition, if there is a cloned state of the form (q, w), then it is in F?. There
are at most |w|+ 1 cloned states.
? States of the form (?, x), with x ? Pr(w). These states will be called
queue states; states of this form appear when the string w is not in L(M)
(the pertinent case, because we are adding it) and only if in the original
automaton ??(q0, x) =? for some x ? Pr(w). Only the final queue state
(?, w)?if it exists?is in F?. There are at most |w| queue states.
? The new absorption state ??= (?,?w) /? F.
This automaton has to be minimized; because of the nature of the construction algo-
rithm, however, minimization may be accomplished in a small number of operations.
It is not difficult to show that minimization may be performed by initializing a list R
called the register (Daciuk et al 2000) with all of the intact states and then testing,
one by one, queue and cloned states (starting with the last queue state (?, w) or, if it
does not exist, the last clone state (q, w), and descending in Pr(w)) against states in
the register and adding them to the register if they are not found to be equivalent to
a state in R. (Performing this check backwards avoids having to test the equivalence
of states by visiting their descendants recursively: see the end of Section 4.1.) Mini-
mization (including the elimination of unreachable states in M?) appears in Section 4
as part of the string addition and removal algorithms.
3.2 Removing a String
Again, given a (possibly cyclic) minimal complete finite-state automaton M, it is easy
to build a new complete automaton M? accepting L(M?) = L(M) ? {w} = L(M) ?
(?? ? {w}) by applying the intersection construct defined above to M and M?w. The
resulting automaton has the same sets of reachable states in Q? as in the case of adding
string w and therefore the same close-to-minimality properties; since w is supposed
to be in L(M), however, no queue states will be formed. (Note that, if w /? L(M),
a nonaccepting queue with all states eventually equivalent to ??= (?,?w) may be
formed.) The accepting states in F? are intact states (q,?w) and cloned states (q, x)
with q ? F, except for state (q, w). Minimization may be performed analogously to the
string addition case.
4. Algorithms
4.1 Adding a String
Figure 1 shows the algorithm that may be used to add a string to an existing automa-
ton, which follows the construction in Section 3.1. The resulting automaton is viewed
as a modification of the original one: Therefore, intact states are not created; instead,
unreachable intact states are eliminated later. The register R of states not needing
minimization is initialized with Q. The algorithm has three parts:
? First, the cloned and queue states are built and added to Q by using
function clone() for all prefixes of w. The function returns a cloned state
211
Carrasco and Forcada Incremental Construction of Minimal FSA
(with all transitions created), if the argument is a nonabsorption state in
Q ? {?}, or a queue state, if it operates on the absorption state ?? Q.
? Second, those intact states that have become unreachable as a result of
designating the cloned state q?0 as the new start state are removed from Q
and R, and the start state is replaced by its clone. Unreachable states are
simply those having no incoming transitions as constructed by the
algorithm or as a consequence of the removal of other unreachable
states; therefore, function unreachable() simply has to check for the
absence of incoming transitions. Note that only intact states (q,?w)
corresponding to q such that ??(q0, x) = q for some x ? Pr(w) may
become unreachable as a result of having been cloned.
? Third, the queue and cloned states are checked (starting with the last
state) against the register using function replace or register(), which is
essentially the same as the nonrecursive version in the second algorithm
in Daciuk et al (2000) and is shown in Figure 2. If argument state q is
found to be equivalent to a state p in the register R, function merge(p, q)
is called to redirect into p those transitions coming into q; if not,
argument state q is simply added to the register. Equivalence is checked
by function equiv(), shown in Figure 3, which checks for the equivalence
of states by comparing (1) whether both states are accepting or not, and
(2) whether the corresponding outgoing transitions lead to the same state
in R. Note that outgoing transitions cannot lead to equivalent states, as
there are no pairs of different equivalent states in the register
(?p, q ? R, equiv(p, q) ? p = q) and backwards minimization guarantees
that the state has no transitions to unregister states.
Finally, the new (minimal) automaton is returned. In real implementations, absorption
states are not explicitly stored; this results in small differences in the implementations
of the functions clone() and equiv().
4.2 Removing a String
The algorithm for removing a string from the language accepted by an automaton M?
differs from the previous algorithm only in that the line
F ? F ? {qlast}
has to be added after the first end for. Since the string removal algorithm will usually
be asked to remove a string that was in L(M), function clone() will usually generate
only cloned states and no queue states (see Section 3.2 for the special case w /? L(M)).
5. Examples
5.1 Adding a String
Assume that we want to add the string bra to the automaton in Figure 4, which accepts
the set of strings (ba)+?{bar} (for clarity, in all automata, the absorption state and all
transitions leading to it will not be drawn). The single-string automaton for string bra
is shown in Figure 5. Application of the first stages of the string addition algorithm
leads to the (unminimized) automaton in Figure 6. The automaton has, in addition to
the set of intact states {(0,?w), . . . , (5,?w)}, two cloned states ((0, ) and (1, b)) and two
queue states ((?, br) and (?, bra)). As a consequence of the designation of (0, ) as the
212
Computational Linguistics Volume 28, Number 2
algorithm addstring
Input: M = (Q,?, ?, q0, F) (minimal, complete), w ? ??
Output: M?=(Q?,?, ??, q?0, F
?) minimal, complete, and such that L(M?)=L(M)?{w}
R ? Q [initialize register]
q?0 ? clone(q0) [clone start state]
qlast ? q?0
for i = 1 to |w|
q ? clone(??(q0, w1 ? ? ?wi)) [create cloned and queue states;
add clones of accepting states to F]
?(qlast, wi) ? q
qlast ? q
end for
i ? 1
qcurrent ? q0
while(i ? |w| and unreachable(qcurrent))
qnext ? ?(qcurrent, wi)
Q ? Q ? {qcurrent} [remove unreachable state from Q
and update transitions in ?]
R ? R ? {qcurrent} [remove also from register]
qcurrent ? qnext
i ? i + 1
end while
if unreachable(qcurrent)
Q ? Q ? {qcurrent}
R ? R ? {qcurrent}
end if
q0 ? q?0 [replace start state]
for i = |w| downto 1
replace or register(??(q0, w1 ? ? ?wi)) [check queue and cloned states one by one]
end for
return M = (Q,?, ?, q0, F)
end algorithm
Figure 1
Algorithm to add a string w to the language accepted by a finite-state automaton while
keeping it minimal.
function replace or register(q)
if ?p ? R : equiv(p, q) then
merge(p, q)
else
R ? R ? {q}
end if
end function
Figure 2
The function replace or register().
213
Carrasco and Forcada Incremental Construction of Minimal FSA
function equiv(p, q)
if (p ? F ? q /? F) ? (p /? F ? q ? F) return false
for all symbols a ? ?
if ?(p, a) = ?(q, a) return false
end for
return true
end function
Figure 3
The function equiv(p, q).
Figure 4
Minimal automaton accepting the set of strings (ba)+ ? {bar}.
Figure 5
Single-string automaton accepting string bra.
0,?w 1,?w 2,?w
3,?w
4,?w 5,?w
0,? 1,b
?,br ?,bra
b a
r
b a
bb
a
r
a
Figure 6
Unminimized automaton accepting the set (ba)+ ? {bar} ? {bra}. Shadowed states (0,?w)
and (1,?w) have become unreachable (have no incoming transitions) and are eliminated in
precisely that order.
214
Computational Linguistics Volume 28, Number 2
Figure 7
Minimal automaton accepting the set (ba)+ ? {bar} ? {bra}.
? b ba bab babab a b a
Figure 8
Single-string automaton accepting the string baba.
0,?w 1,?w
2,?w
3,?w
4,?w
5,?w
6,?w
0,? 1,b 2,ba 4,bab 6,baba
b
a
r
b
r
a
a
b
b
r
a
r
b a
b
Figure 9
Unminimized automaton accepting the set (ba)+ ? {bar} ? {bra} ? {baba}. Shadowed states
(0,?w), (1,?w), and (2,?w) have become unreachable (have no incoming transitions) and are
eliminated in precisely that order.
new start state, shadowed states (0,?w) and (1,?w) become unreachable (have no in-
coming transitions) and are eliminated in precisely that order in the second stage of the
algorithm. The final stage of the algorithm puts intact states into the register and tests
queue and cloned states for equivalence with states in the register. The first state tested
is (?, bra), which is found to be equivalent to (3,?w); therefore, transitions coming
into (?, bra) are made to point to (3,?w). Then, states (?, br), (1, b) and (0, ) are tested
in order, found to have no equivalent in the register, and added to it. The resulting
minimal automaton, after a convenient renumbering of states, is shown in Figure 7.
5.2 Removing a String
Now let us consider the case in which we want to remove string baba from the
language accepted by the automaton in Figure 7 (the single-string automaton for baba
is shown in Figure 8). The automaton resulting from the application of the initial
(construction) stages of the automaton is shown in Figure 9. Note that state (6, baba) is
marked as nonaccepting, because we are removing a string. Again, as a consequence
of the designation of (0, ) as the new start state, shadowed states (0,?w), (1,?w),
215
Carrasco and Forcada Incremental Construction of Minimal FSA
0 1
2
3
4
5 6
7 8
b
r
a
a
r
b a
b
a
b
Figure 10
Minimal automaton accepting the set (ba)+ ? {bar} ? {bra} ? {baba}.
and (2,?w) become unreachable (have no incoming transitions) and are eliminated in
precisely that order in the second stage of the algorithm. The last stage of the algorithm
puts all intact states into the register, checks cloned states (6, baba), (4, bab), (2, ba),
(1, b) and (0, ) (no queue states, since baba is accepted by the automaton in Figure 7),
and finds none of them to be equivalent to those in the register, to which they are
added. The resulting minimal automaton is shown in Figure 10.
6. Concluding Remarks
We have derived, from basic results of language and automata theory, a simple method
for modifying a minimal (possibly cyclic) finite-state automaton so that it recognizes
one string more or one string less while keeping the finite-state automaton minimal.
These two operations may be applied to dictionary construction and maintenance
and generalize the result in Daciuk et al?s (2000) second algorithm (incremental con-
struction of acyclic finite-state automata from unsorted strings) in two respects, with
interesting practical implications:
? The method described here allows for the addition of strings to the
languages of cyclic automata (in practice, it may be convenient to have
cycles in dictionaries if we want them to accept, for example, all possible
integer numbers or Internet addresses). In this respect, the algorithm
presented also generalizes the string removal method sketched by Revuz
(2000) for acyclic automata.
? Removal of strings is as easy as addition. This means that, for example,
the detection of an erroneous entry in the dictionary does not imply
having to rebuild the dictionary completely.
The asymptotic time complexity of the algorithms is in the same class (O(|Q||w|)) as
that in Daciuk et al (2000), because the slowest part of the algorithm (the last one)
checks all queue and cloned states (O(|w|)) against all states of the register (O(|Q|)). As
suggested by one of the reviewers of this article, an improvement in efficiency may be
obtained by realizing that, in many cases, cloned states corresponding to the shortest
prefixes of string w are not affected by minimization, because their intact equivalents
have become unreachable and therefore have been removed from the register; the
solution lies in identifying these states and not cloning them (for example, Daciuk et
al.?s [2000] and Revuz?s [2000] algorithms do not clone them).
As for the future, we are working on an adaptation of this algorithm for the main-
tenance of morphological analyzers and generators using finite-state nondeterministic
letter transducers (Roche and Schabes 1997; Garrido et al 1999).
216
Computational Linguistics Volume 28, Number 2
Acknowledgments
The work reported in this article has been
funded by the Spanish Comisio?n
Interministerial de Ciencia y Tecnolog??a
through grant TIC2000-1599. We thank the
two reviewers for their suggestions and
Colin de la Higuera for his comments on
the manuscript.
References
Daciuk, Jan, Stoyan Mihov, Bruce W.
Watson, and Richard E. Watson. 2000.
Incremental construction of minimal
acyclic finite-state automata.
Computational Linguistics, 26(1):3?16.
Garrido, Alicia, Amaia Iturraspe, Sandra
Montserrat, Herm??nia Pastor, and
Mikel L. Forcada. 1999. A compiler for
morphological analysers and generators
based on finite-state transducers.
Procesamiento del Lenguaje Natural,
25:93?98.
Hopcroft, John E. and Jeffrey D. Ullman.
1979. Introduction to Automata Theory,
Languages, and Computation.
Addison-Wesley, Reading, MA.
Karakostas, George, Anastasios Viglas, and
Richard J. Lipton. 2000. On the
complexity of intersecting finite state
automata. In Proceedings of the 15th Annual
IEEE Conference on Computational
Complexity (CoCo?00), pages 229?234.
Revuz, Dominique. 2000. Dynamic acyclic
minimal automaton. In Preproceedings of
CIAA 2000: Fifth International Conference on
Implementation and Application of Automata,
pages 226?232, London, Ontario, July
24?25.
Roche, Emmanuel and Yves Schabes. 1997.
Introduction. In Emmanuel Roche and
Yves Schabes, editors, Finite-State Language
Processing. MIT Press, pages 1?65.
Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 111?114,
Ann Arbor, June 2005. c?Association for Computational Linguistics, 2005
LIHLA: Shared task system description
Helena M. Caseli, Maria G. V. Nunes
NILC ? ICMC ? Univ. Sa?o Paulo
CP 668P, 13560-970 Sa?o Carlos?SP, Brazil
{helename,gracan}@icmc.usp.br
Mikel L. Forcada
Transducens ? DLSI ? Univ. d?Alacant
E-03071 Alacant, Spain
mlf@dlsi.ua.es
Abstract
In this paper we describe LIHLA, a lexical
aligner which uses bilingual probabilis-
tic lexicons generated by a freely availa-
ble set of tools (NATools) and language-
independent heuristics to find links be-
tween single words and multiword units
in sentence-aligned parallel texts. The
method has achieved an alignment error
rate of 22.72% and 44.49% on English?
Inuktitut and Romanian?English parallel
sentences, respectively.
1 Introduction
Alignment of words and multiword units plays an
important role in many natural language processing
(NLP) applications, such as example-based machine
translation (EBMT) (Somers, 1999) and statistical
machine translation (SMT) (Ayan et al, 2004; Och
and Ney, 2000), transfer rule learning (Carl, 2001;
Menezes and Richardson, 2001), bilingual lexi-
cography (Go?mez Guinovart and Sacau Fontenla,
2004), and word sense disambiguation (Gale et al,
1992), among others.
Aligning two (or more) texts means finding
correspondences (translation equivalences) between
segments (paragraphs, sentences, words, etc.) of the
source text and segments of its translation (the tar-
get text). Following the same idea of many recently
proposed approaches on lexical alignment (e.g., Wu
and Wang (2004) and Ayan et al (2004)), the
method described in this paper, LIHLA (Language-
Independent Heuristics Lexical Aligner) starts from
statistical alignments between single words (de-
fined in bilingual lexicons) and applies language-
independent heuristics to them, aiming at finding the
best alignments between words or multiword units.
Although the most frequent alignment category is
1 : 1 (in which one source word is translated exactly
as one target word), other categories such as omis-
sions (1 : 0 or 0 : 1) or those involving multiword
units (n : m, with n and/or m ? 1) are also possible.
This paper is organized as follows: section 2 ex-
plains how LIHLA works; section 3 describes some
experiments carried out with LIHLA together with
their results and, in section 4, some concluding re-
marks are presented.
2 How LIHLA works
As the first step, LIHLA uses alignments between
single words defined in two bilingual lexicons
(source?target and target?source) generated from
sentence-aligned parallel texts using NATools.1
Given two sentence-aligned corpus files, the NA-
Tools word aligner ?based on the Twenty-One sys-
tem (Hiemstra, 1998)? counts the co-occurrences
of words in all aligned sentence pairs and builds a
sparse matrix of word-to-word probabilities (Model
A) using an iterative expectation-maximization al-
gorithm (5 iterations by default). Finally, the ele-
ments with higher values in the matrix are cho-
sen to compose two probabilistic bilingual lexi-
cons (source?target and target?source) (Simo?es and
Almeida, 2003). For each word in the corpus, each
1NATools is a set of tools developed to work with parallel
corpora, which is freely available in http://natura.di.
uminho.pt/natura/natura/.
111
bilingual lexicon gives: the number of occurrences
of that word in the corpus (its absolute frequency)
and its most likely translations together with their
probabilities.
The construction of the bilingual lexicons is an
independent prior step for the alignment performed
by LIHLA and the same bilingual lexicons can be
used several times to align parallel sentences.
So, using the two bilingual lexicons generated
by NATools and some language-independent heuris-
tics, LIHLA tries to find the best alignment between
source and target tokens (words, numbers, special
characters, etc.) in a pair of parallel sentences. For
each source token sj in source sentence S, LIHLA
will look for the best token ti in the target parallel
sentence T applying these heuristics in sequence:
1. Exact match
LIHLA creates a 1 : 1 alignment between sj
and ti if they are identical. This heuristic stays
for exact matches, for instance, between proper
names and numbers.
2. Best candidate according to the bilingual
lexicon
LIHLA looks for possible translations of sj in
the source?target bilingual lexicon (BS) and
makes an intersection between them and the
words in T . In this intersection, if no candi-
date word identical to those in BS is found,
then LIHLA tries to look for cognates for
those words using the longest common subse-
quence ratio (LCSR).2 By doing this, LIHLA
can deal with small changes in possible trans-
lations such as different forms of the same verb,
changes in gender and/or number of nouns,
adjectives, and so on.
Then, LIHLA selects the best target candidate
word ti for sj ?the best candidate word accor-
ding to BS among those in a position which
is favorably situated in relation to sj? and
looks for multiword units involving sj and ti
?those words that occur immediately before
and/or after sj (for source multiword units) or
2The LCSR of two words is computed by dividing the length
of their longest common subsequence by the length of the
longer word. For example, the LCSR of Portuguese word alin-
hamento and Spanish word alineamiento is 1012 ' 0.83 as their
longest common subsequence is a-l-i-n-a-m-e-n-t-o.
ti (for target multiword units) and are not pos-
sible translations for other words in T and S,
respectively. According to the multiword units
that have (or not) been found, a 1 : 1, 1 : n,
m : 1 or m : n alignment is established. An
omission alignment for sj (1 : 0) can also be
established if no target candidate word ti that
satisfies this heuristic is available.
3. Cognates
If no possible translation for sj is found in the
bilingual lexicon and the target sentence (T ) at
the same time, LIHLA uses the LCSR to look
for cognates for sj in T and sets a 1 : 1 align-
ment between sj and its best cognate or a 1 : 0
alignment if there is no cognate available.
These heuristics are applied while alignments can
still be produced and a maximum number of itera-
tions is not reached (see section 3 for the number
of iterations performed in the experiments described
in this paper). Furthermore, at the first iteration,
all words with a frequency higher than a set thres-
hold are ignored to avoid erroneous alignments since
all subsequent alignments are based on the previous
ones.
In its last step (which is optional and has not
been performed in the experiments described in
this paper), LIHLA aligns the remaining unaligned
source and target tokens between two pairs of al-
ready aligned tokens establishing several 1 : 1 align-
ments when there are the same number of source
and target tokens, or just one alignment involving
all source and target tokens if they exist in different
quantities. The decision of creating n 1 : 1 align-
ments in spite of just one n : n alignment when there
is the same number of source and target tokens is due
to the fact that a 1 : 1 alignment is more likely to be
found than a n : n one.
3 Experiments
In this section we present the experiments carried
out with LIHLA for the ?Shared task on word align-
ment? in the Workshop on Building and Using Pa-
rallel Texts during ACL2005. Systems participa-
ting in this shared task were provided with training
data (consisting of sentence-aligned parallel texts)
for three pairs of languages: English?Inuktitut,
112
Romanian?English and English?Hindi. Further-
more, the systems would choose to participate in one
or both subtasks of ?limited resources? (where sys-
tems were allowed to use only the resources pro-
vided) and ?unlimited resources? (where systems
were allowed to use any resources in addition to
those provided). The system described in this pa-
per, LIHLA, participated in the subtask of limited re-
sources aligning English?Inuktitut and Romanian?
English test sets.
The training sets ?composed of 338,343
English?Inuktitut aligned sentences (omission cases
were excluded from the whole set of 340,526 pairs)
and 48,478 Romanian?English aligned ones? were
used to build the bilingual lexicons. Then,
without changing any default parameter (threshold
for LCSR, maximum number of iterations, etc.),
LIHLA aligned the 75 English?Inuktitut and the 203
Romanian?English parallel sentences on test sets.
The whole alignment process (bilingual lexicon ge-
neration and alignment itself) did not take more than
17 minutes for English?Inuktitut (3 iterations per
sentence, on average) and 7 minutes for Romanian?
English (4 iterations per sentence, on average).
The evaluation was run with respect to precision,
recall, F -measure, and alignment error rate (AER)
considering sure and probable alignments but not
NULL ones (Mihalcea and Pedersen, 2003). Tables
1 and 2 present metric values for English?Inuktitut
and Romanian?English alignments, respectively, as
provided by the organization of the shared task.
Metric Sure Probable
Precision 46.55% 79.53%
Recall 73.72% 18.71%
F -measure 57.07% 30.30%
AER 22.72%
Table 1: LIHLA results for English?Inuktitut
Metric Sure Probable
Precision 57.68% 57.68%
Recall 53.51% 53.51%
F -measure 55.51% 55.51%
AER 44.49%
Table 2: LIHLA results for Romanian?English
The results obtained in these experiments were
not so good as those achieved by LIHLA on the
language pairs for which it was developed, that
is, 92.48% of precision and 88.32% of recall on
Portuguese?Spanish parallel texts and 84.35% of
precision and 76.39% of recall on Portuguese?
English ones.3
The poor performance in the English?Inuktikut
task may be partly due to the fact that Inuktikut is
a polysynthetic language, that is, one in which, un-
like in English, words are formed by long strings of
concatenated morphemes. This makes it difficult for
NATools to build reasonable dictionaries and lead
to a predominance of n : 1 alignments, which are
harder to determine ?this fact can be confirmed by
the better precision of LIHLA when probable align-
ments were considered (see table 1). The perfor-
mance in the English?Romanian task, not very far
from the English?Portuguese task used to tune up
the parameters of the algorithm, is harder to explain
without further analysis.
The difference in precision and recall between
the two language pairs is due to the fact that on
the English?Inuktitut reference corpus in addition to
sure alignments the probable ones were also anno-
tated while in Romanian?English only sure align-
ments are found. This indicates that evaluating
alignment systems is not a simple task since their
performance depends not only on the language pairs
and the quality of parallel corpora (constant criteria
in this shared task) but also the way the reference
corpus is built.
So, at this moment, it would be unfair to blame
the worse performance of LIHLA on its alignment
methodology since it has been applied to the new
language pairs without changing any of its default
parameters. Maybe a simple optimization of para-
meters for each pair of languages could bring better
results and also the impact of size and quality of
training and reference corpora used in these experi-
ments should be investigated. Then, the only conclu-
sion that can be taken at this moment is that LIHLA,
with its heuristics and/or default parameters, can not
be indistinctly applied to any pair of languages.
Despite of its performance, LIHLA has some
3For more details of these experiments see (Caseli et al, ac-
cepted paper).
113
advantages when compared to other lexical align-
ment methods found in the literature, such as: it
does not need to be trained for a new pair of lan-
guages (as in Och and Ney (2000)) and neither does
it require pre-processing steps to handle texts (as
in Go?mez Guinovart and Sacau Fontenla (2004)).
Furthermore, the whole alignment process (bilingual
lexical generation and alignment itself) has proved
to be very fast as mentioned previously.
4 Concluding remarks
This paper has presented a lexical alignment
method, LIHLA, which aligns words and multi-
word units based on initial statistical word-to-word
correspondences and language-independent heuris-
tics.
In the experiments carried out at the ?Shared
task on word alignment? which took place at the
Workshop on Building and Using Parallel Texts
during ACL2005, LIHLA has been evaluated on
English?Inuktitut and Romanian?English parallel
texts achieving an AER of 22.72% and 44.49%,
respectively.
As future work, we aim at investigating the impact
of using additional linguistic information (such as
part-of-speech tags) on LIHLA?s performance. Also,
as a long-term goal, LIHLA will be part of a system
implemented to learn transfer rules from sequences
of aligned words.
Acknowledgments
We thank FAPESP, CAPES, CNPq and the
Spanish Ministry of Science & Technology (Project
TIC2003-08681-C02-01) for financial support.
References
Necip F. Ayan, Bonnie J. Dorr, and Nizar Habash. 2004.
Multi-Align: Combining linguistic and statistical tech-
niques to improve alignments for adaptable MT. In
R. E. Frederking and K. B. Taylor, editors, Proceed-
ings of the 6th Conference of the AMTA (AMTA-2004),
number 3265 in Lecture Notes in Artificial Inteligence
(LNAI), pages 17?26. Springer-Verlag Berlin Heidel-
berg.
Michael Carl. 2001. Inducing probabilistic invertible
translation grammars from aligned texts. In Pro-
ceedings of CoNLL-2001, pages 145?151, Toulouse,
France.
Helena M. Caseli, Maria das Grac?as V. Nunes, and
Mikel L. Forcada. (accepted paper). LIHLA: A
lexical aligner based on language-independent heuris-
tics. In Proceedings of the V Encontro Nacional de
Intelige?ncia Artificial (ENIA05), Sa?o Leopoldo, RS,
Brazil.
William A. Gale, Kenneth W. Church, and David
Yarowsky. 1992. Using bilingual materials to develop
word sense disambiguation methods. In Proceedings
of the 4th International Conference on Theoretical and
Methodological Issues in Machine Translation (TMI
1992), pages 101?112, Montreal, Canada, June.
Xavier Go?mez Guinovart and Elena Sacau Fontenla.
2004. Me?todos de optimizacio?n de la extraccio?n de
le?xico bilingu?e a partir de corpus paralelos. Proce-
samiento del Lenguaje Natural, 33:133?140.
Djoerd Hiemstra. 1998. Multilingual domain modeling
in Twenty-One: automatic creation of a bi-directional
translation lexicon from a parallel corpus. In Pe-
ter Arno Coppen, Hans van Halteren, and Lisanne Te-
unissen, editors, Proceedings of the 8th CLIN meeting,
pages 41?58.
Arul Menezes and Stephen D. Richardson. 2001. A best-
first alignment algorithm for automatic extraction of
transfer mappings from bilingual corpora. In Proceed-
ings of the Workshop on Data-driven Machine Trans-
lation at 39th Annual Meeting of the ACL (ACL-2001),
pages 39?46, Toulouse, France.
Rada Mihalcea and Ted Pedersen. 2003. An evaluation
exercise for word alignment. In HLT-NAACL 2003
Workshop: Building and Using Parallel Texts Data
Driven Machine Translation and Beyond, pages 1?10,
Edmonton, May?June.
Franz J. Och and Hermann Ney. 2000. Improved sta-
tistical alignment models. In Proceedings of the 38th
Annual Meeting of the ACL (ACL-2000), pages 440?
447, Hong Kong, China, October.
Alberto M. Simo?es and Jose? J. Almeida. 2003. NA-
Tools ? A statistical word aligner workbench. Pro-
cessamiento del Lenguaje Natural, 31:217?224.
Harold Somers. 1999. Review article: Example-based
machine translation. Machine Translation, 14(2):113?
157.
Hua Wu and Haifeng Wang. 2004. Improving domain-
specific word alignment with a general bilingual cor-
pus. In R. E. Frederking and K. B. Taylor, editors, Pro-
ceedings of the 6th Conference of the AMTA (AMTA-
2004), number 3265 in Lecture Notes in Artificial
Inteligence (LNAI), pages 262?271. Springer-Verlag
Berlin Heidelberg.
114
First Joint Conference on Lexical and Computational Semantics (*SEM), pages 472?476,
Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational Linguistics
UAlacant: Using Online Machine Translation for
Cross-Lingual Textual Entailment
Miquel Espla`-Gomis and Felipe Sa?nchez-Mart??nez and Mikel L. Forcada
Departament de Llenguatges i Sistemes Informa`tics
Universitat d?Alacant, E-03071 Alacant, Spain
{mespla,fsanchez,mlf}@dlsi.ua.es
Abstract
This paper describes a new method for cross-
lingual textual entailment (CLTE) detection
based on machine translation (MT). We use
sub-segment translations from different MT
systems available online as a source of cross-
lingual knowledge. In this work we describe
and evaluate different features derived from
these sub-segment translations, which are used
by a support vector machine classifier to detect
CLTEs. We presented this system to the Se-
mEval 2012 task 8 obtaining an accuracy up to
59.8% on the English?Spanish test set, the sec-
ond best performing approach in the contest.
1 Introduction
Cross-lingual textual entailment (CLTE) detec-
tion (Mehdad et al, 2010) is an extension of the
textual entailment (TE) detection (Dagan et al, 2006)
problem. TE detection consists of finding out, for
two text fragments T and H in the same language,
whether T entails H from a semantic point of view
or not. CLTE presents a similar problem, but with T
and H written in different languages.
During the last years, many authors have focused
on resolving TE detection, as solutions to this prob-
lem have proved to be useful in many natural lan-
guage processing tasks, such as question answer-
ing (Harabagiu and Hickl, 2006) or machine trans-
lation (MT) (Mirkin et al, 2009; Pado? et al, 2009).
Therefore, CLTE may also be useful for related tasks
in which more than one language is involved, such
as cross-lingual question answering or cross-lingual
information retrieval. Although CLTE detection is
a relatively new problem, it has already been tack-
led. Mehdad et al (2010) propose to use machine
translation (MT) to translate H from LH , the lan-
guage of H , into LT , the language of T , and then use
any of the state-of-the-art TE approaches. In a later
work (Mehdad et al, 2011), the authors use MT, but
in a more elaborate way. They train a phrase-based
statistical MT (PBSMT) system (Koehn et al, 2003)
translating from LH to LT , and use the translation
table obtained as a by-product of the training process
to extract a set of features which are processed by a
support vector machine classifier (Theodoridis and
Koutroumbas, 2009, Sect. 3.7) to decide whether T
entails H or not. Castillo (2011) discusses another
machine learning approach in which the features are
obtained from semantic similarity measures based on
WordNet (Miller, 1995).
In this work we present a new approach to tackle
the problem of CLTE detection using a machine learn-
ing approach, partly inspired by that of Mehdad et
al. (2011). Our method uses MT as a source of infor-
mation to detect semantic relationships between T
and H . To do so, we firstly split both T and H into
all the possible sub-segments with lengths between 1
and L, the maximum length, measured in words. We
then translate the set of sub-segments from T into
LH , and vice versa, and collect all the sub-segment
pairs in a single set. We claim that when T -side
sub-segments match T and their corresponding H-
side sub-segments match H , this reveals a semantic
relationship between them, which can be used to de-
termine whether T entails H or not. Note that MT
is used as a black box, i.e. sub-segment translations
may be collected from any MT system, and that our
approach could even use any other sources of bilin-
gual sub-sentential information. It is even possible
to combine different MT systems as we do in our
experiments. This is a key point of our work, since
472
it uses MT in a more elaborate way than Mehdad et
al. (2010), and it does not depend on a specific MT
approach. Another important difference between this
work and that of Mehdad et al (2011) is the set of
features used for classification.
The paper is organized as follows: Section 2 de-
scribes the method used to collect the MT informa-
tion and obtain the features; Section 3 explains the
experimental framework; Section 4 shows the results
obtained for the different features combination pro-
posed; the paper ends with concluding remarks.
2 Features from machine translation
Our approach uses MT as a black box to detect par-
allelisms between the text fragments T and H by
following these steps:
1. T is segmented in all possible sub-segments
tm+p?1m of length p with 1 ? p ? L and 1 ?
m ? |T | ? p + 1, where L is the maximum
sub-segment length allowed. Analogously, H is
segmented to get al the possible sub-segments
hn+q?1n of length q, with 1 ? q ? L and 1 ?
n ? |T | ? q + 1.
2. The sub-segments obtained from T are trans-
lated using all the available MT systems into
LH . Analogously, the sub-segments from H
are translated into LT , to generate a set of sub-
segment pairs (t, h).
3. Those pairs of sub-segments (t, h) such that t is
a sub-string of T and h is a sub-string of H are
annotated as sub-segment links.
Note that it could be possible to use statistical MT to
translate both T and H and then use word alignments
to obtain the sub-segment links. However, we use this
methodology to ensure that any kind of MT system
can be used by our approach. As a result of this
process, a sub-segment in T may be linked to more
than one sub-segment in H , and vice versa. Based
on these sub-segment links we have designed a set of
features which may be used by a classifier for CLTE.
2.1 Basic features [Bas]
We used a set of basic features to represent the infor-
mation from the sub-segment links between T and H ,
which are computed as the fraction of words in each
of them covered by linked sub-segments of length
l ? [1, L]. We define the feature function Fl(S),
applied on a text fragment S (either T or H) as:
Fl(S) = Cov(S, l)/|S|
where Cov(S, l) is a function which obtains the num-
ber of words in S covered by at least one sub-segment
of length l which is part of a sub-segment link. An
additional feature is computed to represent the total
proportion of words in each text fragment:
Ftotal(S) = Cov(S, ?)/|S|
where Cov(S, ?) is the same as Cov(S, l) but using
sub-segments of any length up to L. Ftotal(S) pro-
vide information about overlapping that Fl(S) can-
not grasp. For instance, if we have F1(T ) = 0.5 and
F2(T ) = 0.5, we cannot know if the sub-segments
of l = 1 and l = 2 are covering the same or different
words, so Ftotal(S) represents the actual proportion
of words covered in a text fragment S. These fea-
ture functions are applied both on T and H , thus
obtaining a set of 2 ? L+ 2 features, henceforth Bas.
2.2 Extensions to the basic features
Some extensions can be made to the basic features
defined above by using additional external resources.
In this section we propose two extensions.
Separate analysis of function words and content
words [Spl]. In this case, features represent, sepa-
rately, function words, with poor lexical information,
and content words, with richer lexical and seman-
tic information. In this way, Fl(S) is divided into
FFl(S) and CFl(S) defined as:
FFl(S) = CovF(S, l)/|FW(S)|
and
CFl(S) = CovC(S, l)/|CW(S)|
where FW(S) is a function that returns the func-
tion words in text fragment S and CW(S) per-
forms the same task for content words. Analogously,
CovF(S, l) and CovC(S, l) are versions of Cov(S, l)
which only consider function and content words, re-
spectively. This extension can be also be applied to
Ftotal(T ) and Ftotal(H). The set of 4L+ 4 features
obtained in this way (henceforth Spl) allows the clas-
sifier to use the information from the most relevant
words in T and H to detect entailment.
473
Stemming [Stm and SplStm]. Stemming can also
be used when detecting the sub-segment links. Both
the table of sub-segment pairs and the text fragment
pair (T ,H) are stemmed before matching. In this
way, conflicts of number or gender disagreement in
the translations can be overcome in order to detect
more sub-segment links. This new extension can
be applied both to Bas, obtaining the set of features
Stm, and to Spl, obtaining the set of features SplStm.
Although lemmatization could have been used, stem-
ming was preferred because it does not require the
part-of-speech ambiguity to be solved, which may
be difficult to solve when dealing with very short
sub-segments.
2.3 Additional features
Two additional features were defined unrelated with
the basic features proposed. The first one, called here
R, is the length ratio |T |/|H|. Intuitively we can
guess that if H is much longer than T it is unlikely
that T entails H .
The second additional set of features is the one
defined by Mehdad et al (2011), so we will refer to
it as M . The corresponding feature function com-
putes, for the total number of sub-segments of a given
length l ? [1, L] obtained from a text fragment S, the
fraction of them which appear in a sub-segment link.
It is applied both to H and T and is defined as:
F ?l (S) = Linkedl(S)/(|S| ? l + 1)
where Linkedl is the number of sub-segments from
S with length l which appear in a sub-segment link.
3 Experimental settings
The experiments designed for this task are aimed
at evaluating the features proposed in Section 2.
We evaluate our CLTE approach using the English?
Spanish data sets provided in the task 8 of SemEval
2012 (Negri et al, 2012).
Datasets. Two datasets were provided by the or-
ganization of SemEval 2012 (Negri et al, 2011): a
training set and a test set, both composed by a set
of 500 pairs of sentences. CLTE detection is evalu-
ated in both directions, so instances belong to one of
these four classes: forward (the sentence in Spanish
entails the one in English); backward (the sentence
in English entails the one in Spanish); bidirectional
(both sentences entail each other); and no entailment
(neither of the sentences entails each other).
For the whole data set, both sentences in each in-
stance were tokenized using the scripts1 included in
the Moses MT system (Koehn et al, 2007). Each sen-
tence was segmented to get al possible sub-segments
which were then translated into the other language.
External resources. We used three different MT
systems to translate the sub-segments from English
to Spanish, and vice versa:
? Apertium:2 a free/open-source platform for the
development of rule-based MT systems (For-
cada et al, 2011). We used the English?Spanish
MT system from the project?s repository3 (revi-
sion 34706).
? Google Translate:4 an online MT system by
Google Inc.
? Microsoft Translator:5 an online MT system by
Microsoft.
External resources were also used for the extended
features described in Section 2.2. We used the stem-
mer6 and the stopwords list provided by the SnowBall
project for Spanish7 and English.8
Classifier. We used the implementation of support
vector machine included in the WEKA v.3.6.6 data
mining software package (Hall et al, 2009) for multi-
class classification, and a polynomial kernel.
4 Results and discussion
We tried the different features proposed in Section 2
in isolation, and also different combinations of them.
Table 1 reports the accuracy for the different fea-
tures described in Section 2 on the test set using
sub-segments with lengths up to L = 6.9
1http://bit.ly/H4LNux
2http://www.apertium.org
3http://bit.ly/HCbn8a
4http://translate.google.com
5http://www.microsofttranslator.com
6http://bit.ly/H2HU97
7http://bit.ly/JMybmL
8http://bit.ly/Iwg9Vm
9All the results in this section are computed with L = 6,
which proved to be the value providing the best accuracy for the
dataset available after trying different values of L.
474
Bas ? Spl ? Stm ? SplStm ?M ?R Bas ? Spl ?M ?R
Apertium Ap.+Go.+Mi. Apertium Ap.+Go.+Mi.
P R P R P R P R
Backward 64.3% 64.8% 64.5% 72.8% 59.1% 64.8% 57.3% 60.0%
Forward 65.5% 57.6% 68.9 % 56.8% 59.8% 56.0% 58.7% 59.2%
Bidirectional 57.7% 56.8% 56.6% 55.2% 43.7% 41.6% 42.5% 40.8%
No-entailment 47.5% 53.6% 50.7% 54.4% 42.5% 43.2% 44.7% 44.0%
Accuracy 58.2% 59.8% 51.4% 51.0%
Table 2: Precision (P) and recall (R) obtained by our approach for each of the four entailment classes and total accuracy
on the English?Spanish test set using different feature combinations and different MT systems: Apertium, and a
combination of Apertium, Google Translate, and Microsoft Translator (Ap.+Go.+Mi.).
Feature set Nf Accuracy
Bas 14 50.0%
Spl 28 56.0%
Stm 14 49.6%
SplStm 28 56.8%
R 1 45.8%
M 12 47.0%
Bas ? Spl 42 56.6%
Bas ? Stm 28 51.0%
Bas ? Spl ? Stm ? SplStm 84 57.4%
Bas ? Spl ?M ?R 41 58.2%
Bas ? Spl ? Stm ?
? SplStm ?M ?R
97 59.8%
Table 1: Accuracy obtained by the system using the dif-
ferent feature sets proposed in Section 2 for the test set.
Nf is the number of features.
As can be seen, the features providing the best
results on accuracy are the SplStm features. In ad-
dition, results show that all versions of the basic
features (Bas, Spl, Stm, and SplStm) provide better
results than the M feature alone. Some combinations
of features are also reported in Table 1. Although
many combinations were tried, we only report the
results of the combinations of features performing
best because of lack of space.
As can be seen, both feature combinations Bas ?
Spl and Bas ? Stm obtain higher accuracy than the
separated features. Combining all these features
Bas ? Spl ? Stm ? SplStm provide even better re-
sults, thus confirming some degree of orthogonality
between them. Combination Bas ? Spl ?M ? R
obtains one of the best results, since it produces
an improvement of almost 1% over combination
Bas ? Spl ? Stm ? SplStm but using less than a
half of features. Combining all the features provides
the best accuracy as expected, so this seems to be the
best combination for the task.
Table 2 reports the results sent for the SemEval
2012 task 8. We chose feature combinations Bas ?
Spl?M ?R and Bas?Spl?Stm?SplStm?M ?
R since they are the best performing combinations.
We sent two runs of our method using all three MT
systems described in Section 3 and two more runs
using only sub-segment translations from Apertium.
From the ten teams presenting systems for the con-
test, only one overcomes our best result. Even the
results obtained using Apertium as the only MT sys-
tem overcome seven of the ten approaches presented.
This result confirms that state-of-the-art MT is a rich
source of information for CLTE detection.
5 Concluding remarks
In this paper we have described a new method for
CLTE detection which uses MT as a black-box source
of bilingual information. We experimented with dif-
ferent features which were evaluated with the datasets
for task 8 of SemEval 2012. We obtained up to 59.8%
of accuracy on the Spanish?English test set provided,
becoming the second best performing approach of
the contest. As future works, we are now preparing
experiments for other pairs of languages and we plan
to use weights to promote those translations coming
from more-reliable MT systems.
Acknowledgements: Work supported by the Span-
ish government through project TIN2009-14009-
C02-01 and by Universitat d?Alacant through project
GRE11-20. Google Translate service provided by the
University Research Program for Google Translate.
We thank M. Negri, Y. Mehdad, and M. Federico for
encouraging us to participate in SemEval 2012.
475
References
Julio J. Castillo. 2011. A WordNet-based semantic ap-
proach to textual entailment and cross-lingual textual
entailment. International Journal of Machine Learning
and Cybernetics, 2(3):177?189.
Ido Dagan, Oren Glickman, and Bernardo Magnini. 2006.
The PASCAL recognising textual entailment chal-
lenge. In Machine Learning Challenges. Evaluating
Predictive Uncertainty, Visual Object Classification,
and Recognising Tectual Entailment, volume 3944 of
Lecture Notes in Computer Science, pages 177?190.
Springer Berlin / Heidelberg.
Mikel Forcada, Mireia Ginest??-Rosell, Jacob Nordfalk,
Jim O?Regan, Sergio Ortiz-Rojas, Juan Pe?rez-Ortiz,
Felipe Sa?nchez-Mart??nez, Gema Ram??rez-Sa?nchez, and
Francis Tyers. 2011. Apertium: a free/open-source
platform for rule-based machine translation. Machine
Translation, 25(2):127?144.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten. 2009.
The WEKA data mining software: an update. SIGKDD
Explorations Newsletter, 11(1):10?18.
Sanda Harabagiu and Andrew Hickl. 2006. Methods
for using textual entailment in open-domain question
answering. In Proceedings of the 21st International
Conference on Computational Linguistics and the 44th
Annual Meeting of the Association for Computational
Linguistics, pages 905?912, Sydney, Australia.
Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In Proceedings of
the 2003 Conference of the North American Chapter
of the Association for Computational Linguistics on
Human Language Technology, pages 48?54, Edmonton,
Canada.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondr?ej Bojar, Alexandra Constantin,
and Evan Herbst. 2007. Moses: open source toolkit
for statistical machine translation. In Proceedings of
the 45th Annual Meeting of the ACL, pages 177?180,
Prague, Czech Republic.
Yashar Mehdad, Matteo Negri, and Marcello Federico.
2010. Towards cross-lingual textual entailment. In
Human Language Technologies: The 11th Annual Con-
ference of the North American Chapter of the Associ-
ation for Computational Linguistics, pages 321?324,
Los Angeles, USA.
Yashar Mehdad, Matteo Negri, and Marcello Federico.
2011. Using bilingual parallel corpora for cross-lingual
textual entailment. In Proceedings of the 49th Annual
Meeting of the Association for Computational Linguis-
tics: Human Language Technologies, pages 1336?1345,
Portland, Oregon.
George A. Miller. 1995. WordNet: a lexical database for
english. Communications of the ACM, 38(11):39?41.
Shachar Mirkin, Lucia Specia, Nicola Cancedda, Ido
Dagan, Marc Dymetman, and Idan Szpektor. 2009.
Source-language entailment modeling for translating
unknown terms. In Proceedings of the Joint Confer-
ence of the 47th Annual Meeting of the ACL and the 4th
International Joint Conference on Natural Language
Processing of the Asian Federation of Natural Lan-
guage Processing, pages 791?799, Suntec, Singapore.
Matteo Negri, Luisa Bentivogli, Yashar Mehdad, Danilo
Giampiccolo, and Alessandro Marchetti. 2011. Di-
vide and conquer: crowdsourcing the creation of cross-
lingual textual entailment corpora. In Proceedings of
the Conference on Empirical Methods in Natural Lan-
guage Processing, pages 670?679, Edinburgh, United
Kingdom.
Matteo Negri, Alessandro Marchetti, Yashar Mehdad,
Luisa Bentivogli, and D. Giampiccolo. 2012. Semeval-
2012 Task 8: Cross-lingual Textual Entailment for Con-
tent Synchronization. In Proceedings of the 6th Inter-
national Workshop on Semantic Evaluation (SemEval
2012).
Sebastian Pado?, Michel Galley, Dan Jurafsky, and Chris
Manning. 2009. Robust machine translation evalua-
tion with entailment features. In Proceedings of the
Joint Conference of the 47th Annual Meeting of the
ACL and the 4th International Joint Conference on Nat-
ural Language Processing of the Asian Federation of
Natural Language Processing, pages 297?305, Suntec,
Singapore.
Sergios Theodoridis and Konstantinos Koutroumbas.
2009. Pattern Recognition. Elsevier, 4th edition.
476
Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 143?148,
Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational Linguistics
MATREX: The DCU MT System for WMT 2010
Sergio Penkale, Rejwanul Haque, Sandipan Dandapat, Pratyush Banerjee, Ankit K. Srivastava,
Jinhua Du, Pavel Pecina, Sudip Kumar Naskar, Mikel L. Forcada, Andy Way
CNGL, School of Computing
Dublin City University, Dublin 9, Ireland
{ spenkale, rhaque, sdandapat, pbanerjee, asrivastava, jdu, ppecina, snaskar, mforcada, away }@computing.dcu.ie
Abstract
This paper describes the DCU machine
translation system in the evaluation cam-
paign of the Joint Fifth Workshop on Sta-
tistical Machine Translation and Metrics
in ACL-2010. We describe the modular
design of our multi-engine machine trans-
lation (MT) system with particular focus
on the components used in this partici-
pation. We participated in the English?
Spanish and English?Czech translation
tasks, in which we employed our multi-
engine architecture to translate. We also
participated in the system combination
task which was carried out by the MBR
decoder and confusion network decoder.
1 Introduction
In this paper, we present the DCU multi-engine
MT system MATREX (Machine Translation using
Examples). This system exploits example-based
MT, statistical MT (SMT), and system combina-
tion techniques.
We participated in the English?Spanish (en?
es) and English?Czech (en?cs) translation
tasks. For these two tasks, we employ several
individual MT systems: 1) Baseline: phrase-
based SMT (Koehn et al, 2007); 2) EBMT:
Monolingually chunking both source and target
sides of the dataset using a marker-based chunker
(Gough and Way, 2004); 3) Factored translation
model (Koehn and Hoang, 2007); 4) Source-side
context-informed (SSCI) systems (Stroppa et al,
2007); 5) the moses-chart (a Moses imple-
mentation of the hierarchical phrase-based (HPB)
approach of Chiang (2007)) and 6) Apertium (For-
cada et al, 2009) rule-based machine translation
(RBMT). Finally, we use a word-level combina-
tion framework (Rosti et al, 2007) to combine the
multiple translation hypotheses and employ a new
rescoring model to generate the final translation.
For the system combination task, we first use
the minimum Bayes-risk (MBR) (Kumar and
Byrne, 2004) decoder to select the best hypoth-
esis as the alignment reference for the confusion
network (CN) (Mangu et al, 2000). We then build
the CN using the TER metric (Snover et al, 2006),
and finally search for the best translation.
The remainder of this paper is organised as fol-
lows: Section 2 details the various components of
our system, in particular the multi-engine strate-
gies used for the shared task. In Section 3, we
outline the complete system setup for the shared
task and provide evaluation results on the test set.
Section 4 concludes the paper.
2 The MATREX System
2.1 System Architecture
The MATREX system is a combination-based
multi-engine architecture, which exploits as-
pects of both the EBMT and SMT paradigms.
The architecture includes various individual sys-
tems: phrase-based, example-based, hierarchical
phrase-based and tree-based MT.
The combination structure uses the MBR and
CN decoders, and is based on a word-level com-
bination strategy (Du et al, 2009). In the final
stage, we use a new rescoring module to process
the N -best list generated by the combination mod-
ule. Figure 1 illustrates the architecture.
2.2 Example-Based Machine Translation
The EBMT system uses a language-specific, re-
duced set of closed-class marker morphemes or
lexemes (Gough and Way, 2004) to define a way
to segment sentences into chunks, which are then
aligned using an edit-distance-style algorithm, in
which edit costs depend on word-to-word transla-143
Figure 1: System Framework.
tion probabilities and the amount of word-to-word
cognates (Stroppa and Way, 2006).
Once these phrase pairs were obtained they
were merged with the phrase pairs extracted by
the baseline system adding word alignment infor-
mation.
2.3 Apertium RBMT
Apertium1 is a free/open-source platform for
RBMT. The current version of the en?es system
in Apertium was used for the system combination
task (section 2.7), and its morphological analysers
and part-of-speech taggers were used to build a
factored Moses model.
2.4 Factored Translation Model
We also used a factored model for the en?es
translation task. Factored models (Koehn and
Hoang, 2007) facilitate the translation by break-
ing it down into several factors which are further
combined using a log-linear model (Och and Ney,
2002).
We used three factors in our factored translation
model, which are used in two different decoding
paths: a surface form (SF) to SF translation factor,
a lemma to lemma translation factor, and a part-of-
speech (PoS) to PoS translation factor.
Finally, we used two decoding paths based on
1http://www.apertium.org
the above three translation factors: an SF to SF
decoding path and a path which maps lemma to
lemma, PoS to PoS, and an SF generated using
the TL lemma and PoS. The lemmas and PoS for
en and es were obtained using Apertium (sec-
tion 2.3).
2.5 Source-Side Context-informed PB-SMT
One natural way to express a context-informed
feature (h?MBL) is to view it as the conditional
probability of the target phrases (e?k) given the
source phrase (f?k) and its source-side context in-
formation (CI):
h?MBL = logP (e?k|f?k,CI(f?k)) (1)
We use a memory-based machine learning
(MBL) classifier (TRIBL:2 Daelemans and
van den Bosch (2005)) that is able to estimate
P (e?k|f?k,CI(f?k)) by similarity-based reasoning
over memorized nearest-neighbour examples of
source?target phrase translations. In equation (1),
SSCI may include any feature (lexical, syntactic,
etc.), which can provide useful information to
disambiguate a given source phrase. In addition
to using local words and PoS-tags as features,
as in (Stroppa et al, 2007), we incorporate
grammatical dependency relations (Haque et al,
2009a) and supertags (Haque et al, 2009b) as
syntactic source context features in the log-linear
PB-SMT model.
In addition to the above feature, we derived a
simple binary feature h?best, defined in (2):
h?best =
{
1 if e?k maximizes P (e?k|f?k,CI(f?k))
0 otherwise
(2)
We performed experiments by integrating these
two features, h?MBL and h?best, directly into the
log-linear framework of Moses.
2.6 Hierarchical PB-SMT model
For the en?cs translation task, we built
a weighted synchronous context-free grammar
model (Chiang, 2007) of translation that uses
the bilingual phrase pairs of PB-SMT as a start-
ing point to learn hierarchical rules. We used
the open-source Tree-Based translation system
moses-chart3 to perform this experiment.
2An implementation of TRIBL is freely available as part
of the TiMBL software package, which can be downloaded
from http://ilk.uvt.nl/timbl
3http://www.statmt.org/moses/?n=Moses.SyntaxTutorial144
2.7 System Combination
For multiple system combination, we used an
MBR-CN framework (Du et al, 2009, 2010) as
shown in Figure 1. Due to the varying word or-
der in the MT hypotheses, it is essential to define
the backbone which determines the general word
order of the CN. Instead of using a single system
output as the skeleton, we employ an MBR de-
coder to select the best single system output Er
from the merged N -best list by minimizing the
BLEU (Papineni et al, 2002) loss, as in (3):
r = argmin
i
Ns?
j=1
(1? BLEU(Ej , Ei)) (3)
where Ns indicates the number of translations in
the merged N -best list, and {Ei}Nsi=1 are the trans-
lations themselves. In our task, we only merge the
1-best output of each individual system.
The CN is built by aligning other hypotheses
against the backbone, based on the TER metric.
Null words are allowed in the alignment. Ei-
ther votes or different confidence measures are as-
signed to each word in the network. Each arc in
the CN represents an alternative word at that po-
sition in the sentence and the number of votes for
each word is counted when constructing the net-
work. The features we used are as follows:
? word posterior probability (Fiscus, 1997);
? 3, 4-gram target language model;
? word length penalty;
? Null word length penalty;
We use MERT (Och, 2003) to tune the weights
of the CN.
2.8 Rescoring
Rescoring is a very important part in post-
processing which can select a better hypothesis
from the N -best list. We augmented our previ-
ous rescoring model (Du et al, 2009) with more
large-scale data. The features we used include:
? Direct and inverse IBM model;
? 3, 4-gram target language model;
? 3, 4, 5-gram PoS language model (Schmid,
1994; Ratnaparkhi, 1996);
? Sentence length posterior probability (Zens
and Ney, 2006);
? N -gram posterior probabilities within the N -
Best list (Zens and Ney, 2006);
? Minimum Bayes Risk probability;
? Length ratio between source and target sen-
tence;
The weights are optimized via MERT.
3 Experimental Setup
This section describes our experimental setup for
the en?cs and en?es translation tasks.
3.1 Data
Bilingual data: In the experiments we used data
sets provided by the workshop organizers. For the
en?cs translation table extraction we employed
both parallel corpora (News-Commentary10 and
CzEng 0.9), and for the en?es experiments, we
used the Europarl(Koehn, 2005), News Commen-
tary and United Nations parallel data. We used a
maximum sentence length of 80 for en?es and
40 for en?cs. Detailed statistics are shown in Ta-
ble 1.
Corpus Langs. Sent. Source
tokens
Target
tokens
Europarl en?es 1.6M 43M 45M
News-comm en?es 97k 2.4M 2.7M
UN en?es 5.9M 160M 190M
News-Comm en?cs 85k 1.8M 1.6M
CzEng en?cs 7.8M 80M 69M
Table 1: Statistics of en?cs and en?es parallel data.
Monolingual data: For language modeling pur-
poses, in addition to the target parts of the bilin-
gual data, we used the monolingual News corpus
for cs; and the Gigaword corpus for es. For both
languages, we used the SRILM toolkit (Stolcke,
2002) to train a 5-gram language model using all
monolingual data provided. However, for en?es
we used the IRSTLM toolkit (Federico and Cet-
tolo, 2007) to train a 5-gram language model using
the es Gigaword corpus. Both language models
use modified Kneser-Ney smoothing (Chen and
Goodman, 1996). Statistics for the monolingual
corpora are given in Table 2.
Corpus Language Sentences Tokens
E/N/NC/UN es 9,6M 290M
Gigaword es 40M 1,2G
News cs 13M 210M
Table 2: Statistics of Monolingual Data. E/N/NC/UN
refers to Europarl/News/News Commentary/United Nations
corpora.
For all the systems except Apertium, we first
lowercase and tokenize all the monolingual and
bilingual data using the tools provided by the
WMT10 organizers. After translation, system
combination output is detokenised and true-cased.145
3.2 English?Czech (en?cs) Experiments
The CzEng corpus (Bojar and Z?abokrtsky?, 2009)
is a collection of parallel texts from sources of dif-
ferent quality and as such it contains some noise.
As the first step, we discarded those sentence pairs
having more than 10% of non-Latin characters.
The CzEng corpus is quite large (8M sen-
tence pairs). Although we were able to build
a vanilla SMT system on all parallel data avail-
able (News-Commentary + CzEng), we also at-
tempted to build additional systems using News-
Commentary data (which we considered in-
domain) and various in-domain subsets of CzEng
hoping to achieve better results on domain-
specific data.
For our first system, we selected 128,218 sen-
tence pairs from CzEng labeled as news. For the
other two systems, we selected subsets of 2M and
4M sentence pairs identified as most similar to
the development sets (as a sample of in-domain
data) based on cosine similarity of their represen-
tation in a TF-IDF weighted vector space model
(cf. Byrne et al (2003)). We also applied the
pseudo-relevavance-feedback technique for query
expansion (Manning et al, 2008) to select another
subset with 2M sentence pairs.
We used the output of 15 systems for sys-
tem combination for the en?cs translation task.
Among these, 5 systems were built using Moses
and varying the size of the training data (DCU-
All, DCU-Ex2M, DCU-4M, DCU-2M and DCU-
News); 9 context-informed PB-SMT systems
(DCU-SSCI-*) using (combinations of) various
context features (word, PoS, supertags and depen-
dency relations) trained only on the News Com-
mentary data (marked with ? in Table 4); and one
system using the moses-chart decoder, also
trained on the news commentary data.
3.3 English?Spanish (en?es) Experiments
Three baseline systems using Moses were built,
where we varied the amount of training data used:
? epn: This system uses all of the Europarl and
News-Commentary parallel data.
? UN-half: This system uses the data suplied
to ?epn?, plus an additional 2.1M sentences
pairs randomly selected from the United Na-
tions corpus.
? all: This system uses all of the available par-
allel data.
For en?es we also obtained output from the
factored model (trained only on the news com-
mentary corpus) and the Apertium RBMT sys-
tem. We also derived phrase alignments using the
MaTrEx EBMT system (Stroppa and Way, 2006),
and added those phrase translations in the Moses
phrase table. The systems marked with ? use a
language model built using the Spanish Gigaword
corpus, in addition to the one built using the pro-
vided monolingual data. These 6 sets of system
outputs are then used for system combination.
3.4 Experimental Results
The evaluation results for en?es and en?cs ex-
periments are shown in Table 3 and Table 4 re-
spectively. The output of the systems marked ?
were submitted in the shared tasks.
System BLEU NIST METEOR TER
DCU-half ?? 29.77% 7.68 59.86% 59.55%
DCU-all ?? 29.63% 7.66 59.82% 59.74%
DCU-epn ?? 29.45% 7.66 59.71% 59.64%
DCU-ebmt ?? 29.38% 7.62 59.59% 60.11%
DCU-factor 22.58% 6.56 54.94% 67.65%
DCU-apertium 19.22% 6.37 49.68% 67.68%
DCU-system-
combination ? 30.42% 7.78 60.56% 58.71%
Table 3: en?es experimental results.
System BLEU NIST METEOR TER
DCU-All 10.91% 4.60 39.18% 81.76%
DCU-Ex2M 10.63% 4.56 39.12% 81.96%
DCU-4M 10.61% 4.56 39.26% 82.04%
DCU-2M 10.48% 4.58 39.35% 81.56%
DCU-Chart 9.34% 4.25 37.04% 83.87%
DCU-News 8.64% 4.16 36.27% 84.96%
DCU-SSCI-ccg? 8.26% 4.02 34.76% 85.58%
DCU-SSCI-
supertag-pair? 8.11% 3.95 34.93% 86.63%
DCU-SSCI-
ccg-ltag? 8.09% 3.96 34.90% 86.62%
DCU-SSCI-PR? 8.06% 4.00 34.89% 85.99%
DCU-SSCI-base? 8.05% 3.97 34.61% 86.02%
DCU-SSCI-PRIR? 8.03% 3.99 34.81% 85.98%
DCU-SSCI-ltag? 8.00% 3.95 34.57% 86.41%
DCU-SSCI-PoS? 7.91% 3.94 34.57% 86.51%
DCU-SSCI-word? 7.57% 3.88 34.16% 87.14%
DCU-system-
combination ? 13.22% 4.98 40.39% 78.59%
Table 4: en?cs experimental results.
4 Conclusion
This paper presents the Dublin City University
MT system in WMT2010 shared task campaign.
This was DCU?s first attempt to translate from en
to es and cs in any shared task. We developed a
multi-engine framework which combined the out-
puts of several individual MT systems and gener-
ated a new N -best list after CN decoding. Then by146
using some global features, the rescoring model
generated the final translation output. The experi-
mental results demonstrated that the combination
module and rescoring module are effective in our
framework for both language pairs, and produce
statistically significant improvements as measured
by bootstrap resampling methods (Koehn, 2004)
on BLEU over the single best system.
Acknowledgements: This work is supported
by Science Foundation Ireland (Grant No.
07/CE/I1142) and by PANACEA, a 7th Frame-
work Research Programme of the European
Union, contract number 7FP-ITC-248064. M.L.
Forcada?s sabbatical stay at Dublin City Univer-
sity is supported by Science Foundation Ireland
through ETS Walton Award 07/W.1/I1802 and by
the Universitat d?Alacant (Spain).
References
Bojar, O. and Z?abokrtsky?, Z. (2009). CzEng0.9:
Large Parallel Treebank with Rich Annotation.
Prague Bulletin of Mathematical Linguistics,
92:63?83.
Byrne, W., Khudanpur, S., Kim, W., Kumar, S.,
Pecina, P., Virga, P., Xu, P., and Yarowsky, D.
(2003). The Johns Hopkins University 2003
Chinese?English machine translation system.
In Proceedings of MT Summit IX, pages 447?
450, New Orleans, LA.
Chen, S. F. and Goodman, J. (1996). An Empir-
ical Study of Smoothing Techniques for Lan-
guage Modeling. In Proc. 34th Ann. Meeting of
the Association for Computational Linguistics,
pages 310?318, San Francisco, CA.
Chiang, D. (2007). Hierarchical phrase-
based translation. Computational Linguistics,
33(2):201?228.
Daelemans, W. and van den Bosch, A. (2005).
Memory-Based Language Processing (Studies
in Natural Language Processing). Cambridge
University Press, New York, NY.
Du, J., He, Y., Penkale, S., and Way, A. (2009).
MaTrEx: The DCU MT System for WMT2009.
In Proc. 3rd Workshop on Statistical Machine
Translation, EACL 2009, pages 95?99, Athens,
Greece.
Du, J., Pecina, P., and Way, A. (2010). An
Augmented Three-Pass System Combination
Framework: DCU Combination System for
WMT 2010. In Proc. ACL 2010 Joint Workshop
in Statistical Machine Translation and Metrics
Matr, Uppsala, Greece.
Federico, M. and Cettolo, M. (2007). Efficient
Handling of N-gram Language Models for Sta-
tistical Machine Translation. In Proceedings
of the Second Workshop on Statistical Machine
Translation, pages 88?95, Prague, Czech Re-
public.
Fiscus, J. G. (1997). A post-processing sys-
tem to yield reduced word error rates: Recog-
nizer output voting error reduction (ROVER).
In Proceedings 1997 IEEE Workshop on Auto-
matic Speech Recognition and Understanding
(ASRU), pages 347?352, Santa Barbara, CA.
Forcada, M. L., Tyers, F. M., and Ram??rez-
Sa?nchez, G. (2009). The free/open-source ma-
chine translation platform Apertium: Five years
on. In Proceedings of the First International
Workshop on Free/Open-Source Rule-Based
Machine Translation FreeRBMT?09, pages 3?
10.
Gough, N. and Way, A. (2004). Robust Large-
Scale EBMT with Marker-Based Segmenta-
tion. In Proceedings of the 10th International
Conference on Theoretical and Methodological
Issues in Machine Translation (TMI-04), pages
95?104, Baltimore, MD.
Haque, R., Naskar, S. K., Bosch, A. v. d., and
Way, A. (2009a). Dependency relations as
source context in phrase-based smt. In Proc.
23rd Pacific Asia Conference on Language, In-
formation and Computation, pages 170?179,
Hong Kong, China.
Haque, R., Naskar, S. K., Ma, Y., and Way, A.
(2009b). Using supertags as source language
context in SMT. In EAMT-2009: Proceed-
ings of the 13th Annual Conference of the Eu-
ropean Association for Machine Translation,
pages 234?241, Barcelona, Spain.
Koehn, P. (2004). Statistical significance tests for
machine translation evaluation. In Proceedings
of EMNLP, volume 4, pages 388?395.
Koehn, P. (2005). Europarl: A Parallel Corpus
for Statistical Machine Translation. In Machine
Translation Summit X, pages 79?86, Phuket,
Thailand.
Koehn, P. and Hoang, H. (2007). Factored Trans-
lation Models. In Proceedings of the Joint Con-
ference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural147
Language Learning (EMNLP-CoNLL), pages
868?876, Prague, Czech Republic.
Koehn, P., Hoang, H., Birch, A., Callison-Burch,
C., Federico, M., Bertoldi, N., Cowan, B.,
Shen, W., Moran, C., Zens, R., Dyer, C., Bo-
jar, O., Constantin, A., and Herbst, E. (2007).
Moses: Open Source Toolkit for Statistical Ma-
chine Translation. In Annual Meeting of the As-
sociation for Computational Linguistics (ACL),
demonstration session, pages 177?180, Prague,
Czech Republic.
Kumar, S. and Byrne, W. (2004). Minimum
Bayes-Risk Decoding for Statistical Machine
Translation. In Proceedings of the Joint Meet-
ing of the Human Language Technology Con-
ference and the North American Chapter of
the Association for Computational Linguistics
(HLT-NAACL 2004), pages 169?176, Boston,
MA.
Mangu, L., Brill, E., and Stolcke, A. (2000). Find-
ing consensus in speech recognition: Word er-
ror minimization and other applications of con-
fusion networks. Computer Speech and Lan-
guage, 14(4):373?400.
Manning, C. D., Raghavan, P., and Schu?tze, H.
(2008). Introduction to Information Retrieval.
Cambridge University Press.
Och, F. (2003). Minimum error rate training
in statistical machine translation. In Proceed-
ings of the 41st Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL),
pages 160?167, Sapporo, Japan.
Och, F. and Ney, H. (2002). Discriminative train-
ing and maximum entropy models for statistical
machine translation. In Proceedings of ACL,
volume 2, pages 295?302.
Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J.
(2002). BLEU: a Method for Automatic Eval-
uation of Machine Translation. In Proceedings
of the 40th Annual Meeting of the Association
for Computational Linguistics (ACL-02), pages
311?318, Philadelphia, PA.
Ratnaparkhi, A. (1996). A Maximum Entropy
Model for Part-Of-Speech Tagging. In Pro-
ceedings of the Empirical Methods in Natural
Language Processing Conference (EMNLP),
pages 133?142, Philadelphia, PA.
Rosti, A.-V. I., Xiang, B., Matsoukas, S.,
Schwartz, R., Ayan, N. F., and Dorr, B. J.
(2007). Combining outputs from multiple ma-
chine translation systems. In Proceedings of the
Joint Meeting of the Human Language Technol-
ogy Conference and the North American Chap-
ter of the Association for Computational Lin-
guistics (HLT-NAACL 2007), pages 228?235,
Rochester, NY.
Schmid, H. (1994). Probabilistic Part-of-Speech
Tagging Using Decision Trees. In Proceedings
of International Conference on New Methods
in Language Processing, pages 44?49, Manch-
ester, UK.
Snover, M., Dorr, B., Schwartz, R., Micciula, L.,
and Makhoul, J. (2006). A study of transla-
tion edit rate with targeted human annotation.
In Proceedings of the 7th Conference of the As-
sociation for Machine Translation in the Amer-
icas (AMTA 2006), pages 223?231, Cambridge,
MA.
Stolcke, A. (2002). SRILM - An Extensible Lan-
guage Modeling Toolkit. In Proceedings of
the International Conference Spoken Language
Processing, pages 901?904, Denver, CO.
Stroppa, N., van den Bosch, A., and Way, A.
(2007). Exploiting Source Similarity for SMT
using Context-Informed Features. In Proceed-
ings of the 11th International Conference on
Theoretical and Methodological Issues in Ma-
chine Translation (TMI-07), pages 231?240,
Sko?vde, Sweden.
Stroppa, N. and Way, A. (2006). MaTrEx: the
DCU machine translation system for IWSLT
2006. In Proceedings of the International Work-
shop on Spoken Language Translation, pages
31?36, Kyoto, Japan.
Zens, R. and Ney, H. (2006). N-gram Poste-
rior Probabilities for Statistical Machine Trans-
lation. In Proceedings of the Joint Meeting of
the Human Language Technology Conference
and the North American Chapter of the As-
sociation for Computational Linguistics (HLT-
NAACL 2006), pages 72?77, New York, NY.
148
Workshop on Humans and Computer-assisted Translation, pages 57?65,
Gothenburg, Sweden, 26 April 2014.
c?2014 Association for Computational Linguistics
Black-box integration of heterogeneous bilingual resources into an
interactive translation system
Juan Antonio P
?
erez-Ortiz
japerez@dlsi.ua.es
Daniel Torregrosa
dtr5@alu.ua.es
Departament de Llenguatges i Sistemes Inform`atics
Universitat d?Alacant, Spain
Mikel L. Forcada
mlf@dlsi.ua.es
Abstract
The objective of interactive translation
prediction (ITP) is to assist human trans-
lators in the translation of texts by making
context-based computer-generated sug-
gestions as they type. Most of the ITP
systems in literature are strongly coupled
with a statistical machine translation sys-
tem that is conveniently adapted to provide
the suggestions. In this paper, however,
we propose a resource-agnostic approach
in which the suggestions are obtained from
any bilingual resource (a machine transla-
tion system, a translation memory, a bilin-
gual dictionary, etc.) that provides target-
language equivalents for source-language
segments. These bilingual resources are
considered to be black boxes and do not
need to be adapted to the peculiarities of
the ITP system. Our evaluation shows
that savings of up to 85% can be theoreti-
cally achieved in the number of keystrokes
when using our novel approach. Prelim-
inary user trials indicate that these bene-
fits can be partly transferred to real-world
computer-assisted translation interfaces.
1 Introduction
Translation technologies are frequently used to
assist human translators. Common approaches
consider machine translation (MT) (Hutchins and
Somers, 1992) or translation memories (Somers,
2003) to be systems that produce a first (and usu-
ally incorrect) prototype of the translation which
is then edited by the human translator in order
to produce a target-language text that is adequate
for publishing. In both situations, the suggestion
may be considered as a source of inspiration by
the human translators, who will assemble the final
translation by on some occasions accepting and re-
arranging parts of the proposal, or on others in-
troducing their own words when an appropriate
equivalent is not included or is not found in the
suggestion. The whole process may be viewed as a
negotiation between the wordings that form in the
translator?s mind and wordings that already appear
in the suggestion. In both approaches the sugges-
tion is generated once, usually before starting to
manually translate every new sentence.
The approach introduced in this paper, however,
follows a different path, which is strongly con-
nected to the field of interactive translation pre-
diction
1
(ITP), a research field which explores a
kind of computer-assisted translation framework
whose aim is to interactively provide users with
suggestions at every step during the translation
process.
2
Most works in the field of ITP have fo-
cused on statistical MT systems as the only source
of translations considered to obtain the sugges-
tions, but our study aims to determine how bilin-
gual resources of any kind can be accommodated
into an interoperable ITP. To obtain the sugges-
tions, the source-language sentence to be trans-
lated is split up into many different (and possi-
bly overlapping) word segments of up to a given
length, and a translation for each segment is ob-
tained by using a bilingual resource which is able
to deliver one or more target-language equivalents
for a particular source-language segment. These
equivalents will be the source of the proposals
which will be offered to the human translator dur-
ing the translation process. In principle, the nature
of these bilingual resources is not restricted: in
1
The name interactive translation prediction has recently
been proposed (Alabau et al., 2013) for this research field,
which has historically been referred to as target-text medi-
ated interactive MT (Foster et al., 1997) or simply interactive
MT (Barrachina et al., 2009). Despite the traditional term, we
consider the recent one to be more suitable for our approach
since it is not exclusively based on MT.
2
The interaction can be compared to that of word comple-
tion mechanisms in input text boxes and word processors.
57
this paper we shall explore the use of an MT sys-
tem, but they may also consist of translation mem-
ories, dictionaries, catalogues of bilingual phrases,
or a combination of heterogeneous resources. As
stated above, MT or translation memories cannot
usually deliver appropriate translations at the sen-
tence level, but their proposals usually contain ac-
ceptable segments that do not cover the whole sen-
tence but which can be accepted by the user to as-
semble a good translation, thus saving keystrokes,
mouse actions
3
and, possibly, time.
The remainder of the paper is organised as fol-
lows. After reviewing the state-of-the-art in ITP
in Section 2, we outline the main differences be-
tween our proposal and those found in literature in
Section 3. Our method for generating translation
suggestions from bilingual resources is formally
presented in Section 4. We then introduce in Sec-
tion 5 our experimental set-up and show the results
of two evaluations: one that is fully automatic and
another consisting of a user trial involving human
evaluators. Finally, we discuss the results and pro-
pose future lines of research in Section 6.
2 Related work
The systems which have most significantly con-
tributed to the field of ITP are those built in the
pioneering TransType project (Foster et al., 1997;
Langlais et al., 2000), and its continuation, the
TransType2 project (Macklovitch, 2006). These
systems observe the current partial translation al-
ready typed by the user and, by exploiting an
embedded statistical MT engine, propose one or
more completions that are compatible with the
sentence prefix entered by the user. Various mod-
els were considered for the underlying MT system,
including alignment templates, phrase-based mod-
els, and stochastic finite-state transducers (Bar-
rachina et al., 2009). The proposals offered may
range from one or several words, to a comple-
tion of the remainder of the target sentence. An
automatic best-scenario evaluation with training
and evaluation corpora belonging to the same do-
main (Barrachina et al., 2009) showed that it might
theoretically be possible to use only 20?25% of
the keystrokes in comparison with the unassisted
translation for English?Spanish translation (both
directions) and around 45% for English?French
and English?German. The results of the user tri-
3
In the case of touch devices, other means of interaction
(such as gestures) may exist.
als (Macklovitch, 2006) showed gains in produc-
tivity (measured in number of words translated per
hour) of around 15?20%, but despite this, the hu-
man translators were not satisfied with the system,
principally because they had to correct the same
errors in the proposals over and over again (the
models in the underlying statistical MT system re-
mained unchanged during the translation process).
A number of projects continued the research
where TransType2 had left off. Caitra (Koehn,
2009) is an ITP tool which uses both the phrase
table and the decoder of a statistical MT sys-
tem to generate suggestions; although individ-
ual results vary, translators are generally fastest
with post-editing and obtain the highest trans-
lation performance when combining post-editing
and ITP in the same interface (Koehn and Haddow,
2009). Researchers at the Universitat Polit`ecnica
de Val`encia have also made significant improve-
ments to the TransType2 system such as online
learning techniques with which to adaptively gen-
erate better proposals from user feedback (Ortiz-
Mart??nez et al., 2011), phrase-table smoothing to
cope with segments in the partially typed transla-
tion which cannot be generated with the phrases
collected during training (Ortiz-Mart??nez, 2011),
or multimodal interfaces (Alabau et al., 2010).
The objective of the CASMACAT project (Alabau
et al., 2013), which is under active development,
is to develop new types of assistance along all
these lines. Finally, commercial translation mem-
ory systems have also recently started to introduce
ITP as one of their basic features (see, for exam-
ple, SDL Trados AutoSuggest
4
).
3 Innovative nature of our proposal
Common to most of the approaches discussed
above is the fact that the underlying translation en-
gine needs to be a glass-box resource, that is, a
resource whose behaviour is modified to meet the
ITP system needs. The approaches rely on a statis-
tical MT (Koehn, 2010) system which is adapted
to provide the list of n-best completions for the
remainder of the sentence, given the current sen-
tence prefix already introduced by the user; in or-
der to meet the resulting time constraints, the de-
coder of the statistical MT system cannot be exe-
cuted after each keystroke and techniques to com-
pute the search graph once and then reuse it have
been proposed (Bender et al., 2005). However, it
4
http://www.translationzone.com/
58
Figure 1: Screenshot of the web interface of our
ITP tool showing a translation in progress with
some suggestions being offered. The top text box
contains the source sentence, whereas users type
the translation into the bottom box.
may occur that an ITP system has access to bilin-
gual resources which cannot produce a comple-
tion for the rest of the target-language sentence
from a given sentence prefix, but are able to sup-
ply the translation of a particular source-language
segment. This may be owing to either intrinsic
reasons inherent to the type of resource being used
(for example, a bilingual dictionary can only trans-
late single words or short multi-word units) or ex-
trinsic reasons (for example, an MT system avail-
able through a third-party web service cannot be
instructed to continue a partial translation).
We propose a black-box treatment of the bilin-
gual resources in contrast to the glass-box ap-
proaches found in literature. Unlike them, ac-
cess to the inner details of the translation system
is not necessary; this maintains coupling between
the ITP tool and the underlying system to a mini-
mum and provides the opportunity to incorporate
additional sources of bilingual information beyond
purposely-designed statistical MT systems. More-
over, suggestions are computed once at the start
and not after each keystroke, which results in a
more effective interaction with the user in execu-
tion environments with limited resources.
In this paper, we shall focus on a black-box MT
system (Forcada et al., 2011), but we have also be-
gun to explore the integration of other bilingual re-
sources (such as translation memories, dictionar-
ies, catalogues of bilingual phrases, or even a com-
bination of heterogeneous resources). Our system
has a web interface similar to that in the projects
discussed in Section 2: users freely type the trans-
lation of the source sentence, and are offered sug-
gestions on the fly in a drop-down list with items
based on the current prefix, although this prefix
will correspond to the first characters of the word
currently being typed and not to the part of the
target sentence already entered; users may accept
these suggestions (using cursor keys, the mouse
or specific hot keys) or ignore them and continue
typing. A screenshot of the interface is shown in
Figure 1. Despite the cognitive load inherent to
any predictive interface, the interface is easy and
intuitive to use, even for inexperienced users.
4 Method
Our method starts by splitting the source-language
sentence S up into all the (possibly overlapping)
segments of length l ? [1, L], where L is the max-
imum source segment length measured in words.
The resulting segments are then translated by
means of a bilingual resource (or combinations
thereof). The set of potential proposals P
S
for
sentence S is made up of pairs comprising the
translation of each segment and the position in the
input sentence of the first word of the correspond-
ing source-language segment. See Table 1 for an
example of the set P
S
obtained in an English to
Spanish translation task when using L = 3. We
shall represent the i-th suggestion as p
i
, its target-
language segment as t(p
i
) and its corresponding
source-language word position as ?(p
i
). Suitable
values for L will depend on the bilingual resource:
on the one hand, we expect higher values of L
to be useful for high-quality MT systems, such
as those translating between closely related lan-
guages, since adequate translations may stretch to
a relatively large number of words; on the other
hand, L should be kept small for resources such
as dictionaries or low-quality MT systems whose
translations quickly deteriorate as the length of the
input segment increases.
Let P
S
C
(w?, j) be the subset of P
S
including the
compatible suggestions which can be offered to
the user after typing w? as the prefix of the j-th
word in the translated sentence T . The elements
of P
S
C
(w?, j) are determined by considering only
those suggestions in P
S
that have the already-
typed word prefix as their own prefix:
P
S
C
(w?, j) = {p
i
? P
S
: w? ? Prefix(t(p
i
))}
For example, in the case of the translation of the
English sentence in Table 1, if the user types an
M, the set of compatible suggestions P
S
C
(?M?, 1)
59
Start position Source segment Suggestion
1 My (Mi,1)
1 My tailor (Mi sastre,1)
1 My tailor is (Mi sastre es,1)
2 tailor (sastre,2)
2 tailor is (sastre es,2)
2 tailor is healthy (sastre est?a sano,2)
3 is (es,3)
3 is healthy (est?a sano,3)
4 healthy (sano,4)
Table 1: Source-language segments and potential
suggestions P
S
when translating the sentence S =
?My tailor is healthy? into Spanish with L = 3.
will contain the suggestions with target-language
segments Mi, Mi sastre and Mi sastre es, since
they are the only proposals in P
S
starting with
an M. The size of P
S
C
is dependent on the value
of L, but compatible proposals may also origi-
nate from translations of source segments start-
ing at different positions in the input sentence (for
example, the set P
S
C
after the user types an s in
the same translation will contain proposals starting
with sastre and sano). More elaborated strategies
are consequently necessary to further reduce the
number of proposals, since we do not expect users
to tolerate lists with more than a few suggestions.
In 4.1 we propose the use of a ranking strategy to
sort the elements of P
S
C
in such a way that it is pos-
sible to predict which of them are most suitable to
be offered to the user. However, we first elaborate
on the issue of compatible suggestions originating
from different source positions.
The number of source positions that generate
compatible suggestions also depends on the spe-
cific word prefix; for example, when users type
the letter d when translating a long sentence into
Spanish, they will probably obtain a significant
number of suggestions starting with de
5
originat-
ing from segments located in different source po-
sitions. We measured the number of different po-
sitions that provide compatible suggestions when
the first characters of the current word are typed
during an automatic evaluation of our system (see
Section 5); for instance, when translating from En-
glish to Spanish, the average is 1.46 after typing b,
whereas it is 4.73 after typing d. Figure 2 shows
the average number of different positions for all
the letters as users type longer prefixes. Obviously,
only suggestions originating from the part of the
source sentence currently being translated may be
5
The preposition de is notably frequent in Spanish texts.
 1
 1.5
 2
 2.5
 3
 3.5
 4
 1  2  3  4  5  6  7  8  9  10
Ave
rag
e n
um
ber
 of 
diff
ere
nt 
so
urc
e p
osi
tion
s
Word prefix length
ca?es
en?es
Figure 2: Average number, for all the letters in
the alphabet, of different source positions in the
source sentence providing compatible suggestions
versus length in characters of the typed prefix of
the current target word. A system with L = 4,
M = ? and no deletion of selected suggestions
(see Section 4) was used to obtain the points in
this graph. Data is shown for the English?Spanish
(en-es) and Catalan?Spanish (es-ca) corpora used
in the automatic experiments (see Section 5).
useful, but this position is difficult to determine
unambiguously. The degree of success that can be
achieved in this task will be explored in greater
depth in future work (see Section 6); a simple ap-
proximation is presented in the following section.
4.1 Ranking suggestions
In the absence of a strategy with which to rank
the suggestions in P
S
C
(w?, j) which we are cur-
rently working on, in this paper we explore a na??ve
distance-based approach which is based solely on
the position j: suggestions p
i
whose source posi-
tion ?(p
i
) is closer
6
to j are prioritised. For ex-
ample, in the case of the translation in Table 1, if
the user types Mi s, suggestions starting with sas-
tre will be ranked before those starting with sano.
This linearity assumption can be seen as a rough
attempt to determine the part of the input sentence
that is currently being translated; more sophisti-
cated approaches will be considered in future work
(see Section 6). However, notice that according to
Figure 2, the average number of different source
positions of the compatible segments quickly be-
comes closer to 1 when the length of the word
prefix is greater than 2; it is therefore expected
that the role played by the distance-based ranker
will soon decrease as the user continues typing the
6
Ties are broken at random.
60
 0
 5
 10
 15
 20
 25
0 1 2 3-4 5-7 8-10 11-20    21-300
Pe
rce
nta
ge 
of s
ugg
est
ion
s
Source-target distance
Figure 3: Distribution of the absolute differences
(measured in words) between source position of
accepted suggestions versus position in the target
sentence in which they were selected for the case
of Spanish?English translation. L = 4, M = ?
and no deletion of selected suggestions (see Sec-
tion 4) was used to obtain this graph.
current word (although the position of a valid sug-
gestion is far from j, it will probably be the only
compatible proposal, and will consequently be se-
lected to be offered).
Translation between closely related languages
is often monotonic and most reorderings are local;
our distance-based ranking is therefore expected
to produce good results for this kind of language
pairs. Nevertheless, we cannot in principle ex-
pect this ranker to work reasonably well on un-
related languages with different overall grammat-
ical structures (e.g., when translating a language
with a verb?subject?object order into another one
with a subject?verb?object typology). The graph
in Figure 3 represents the distribution of the dis-
tances between the source positions of all the
accepted suggestions in our automatic Spanish?
English evaluation (see Section 5) versus the po-
sition in the target sentence of the word for which
they were selected. The Pearson correlation coef-
ficient between both positions is very high (0.93),
which supports the idea that our na??ve distance-
based ranking may work reasonably well for the
languages used in our experiments.
7
Let M be the maximum number of sugges-
tions that will eventually be offered to the human
translator; the ordered list of suggestions offered
to the user P
S
O
(w?, j) is made up of a subset of
the elements in P
S
C
(w?, j) and restricted so that
7
Although not shown here, similar results are obtained for
the Catalan?Spanish pair.
|P
S
O
(w?, j)| ? M . Note that for the interface to
be friendly, the value of M should be kept small
and, as a result of this, it could easily occur that all
the suggestions offered are obtained starting at the
same source position (that closest to the current
target position) although better suggestions from
different positions exist. In order to mitigate the
impact of this, in this paper we propose to restrict
the number of proposals originating from a par-
ticular source position to two (the longest and the
shortest, in this order, which are compatible with
the typed word prefix) as long as different compat-
ible suggestions originating from a different posi-
tion exist. The longest is offered in the hope that
it will be correct and will contribute towards sav-
ing a lot of keystrokes; however, since the qual-
ity of machine translations usually degrades with
the length of the input segment (see Figure 4), the
shortest is also offered. This must, however, be
researched in more depth.
4.2 Deleting dispensable suggestions
Suggestions that have been accepted by the user
should not be proposed again. In this work, a
selected suggestion p
i
will be removed from P
S
if no other suggestion p
j
with the same target-
language text t(p
i
) and different source position
?(p
j
) exists in P
S
. In this case, those suggestions
obtained from the source position ?(p
i
) are also
removed from P
S
. Deleting dispensable sugges-
tions allows other useful suggestions to be selected
by the ranker in order to be offered.
5 Experimental setup and results
A fully automatic evaluation and a user trial in-
volving human evaluators were conducted. As
previously stated in Section 3, the only bilingual
resource considered in this paper is an MT system;
in particular, the Spanish to Catalan and English to
Spanish rule-based MT systems in the free/open-
source platform Apertium
8
(Forcada et al., 2011).
5.1 Evaluation metrics
The performance of our system has been measured
by using two metrics: keystroke ratio (KSR) and
acceptable suggestion ratio (ASR). On the one
hand, the KSR is the ratio between the number
of keystrokes and the length of the translated sen-
8
Revision 44632 of the Apertium repository at http://svn.
code.sf.net/p/apertium/svn/trunk/ was used for the engine and
linguistic data in these experiments.
61
tence (Langlais et al., 2000). A lower KSR repre-
sents a greater saving in keystrokes. In our exper-
iments, selecting a suggestion has the same cost
as pressing one key. On the other hand, the ASR
measures the percentage of times that at least one
of the suggestions in a non-empty P
S
O
is selected.
If users frequently receive suggestion lists contain-
ing no acceptable proposals, they will stop con-
sulting the list and translate without assistance; it
is therefore important to measure the number of
times the user is needlessly bothered.
5.2 Automatic evaluation
In order to determine optimal values for the dif-
ferent parameters of our system and to obtain an
idea of the best results attainable, a number of au-
tomatic tests were conducted. The approach fol-
lowed is identical to that described by Langlais et
al. (2000), in which a parallel corpus with pairs
of sentences was used, each pair consisting of a
sentence S in the source language and a reference
translation T in the target language. In the context
of our automatic evaluation, S is used as the input
sentence to be translated and T is considered as the
target output sentence a user is supposed to have in
mind and stick to while typing. The longest sug-
gestion in P
S
O
which concatenated to the already
typed text results in a new prefix of T is always
used. If P
S
O
contains no suggestions at a particular
point, then the system continues typing according
to T . As the algorithm proceeds in a left-to-right
longest-match greedy fashion, there is no guaran-
tee that the best possible results will be obtained,
but they will be a good approximation.
9
For exam-
ple, for T = Mi coche est?a averiado, partial output
translation Mi c, and P
S
O
(?c?, 2) = {coche, coche
es, coche est?a roto}, our automatic evaluation sys-
tem will proceed as follows: it will first discard
coche est?a roto, because Mi coche est?a roto is not
a prefix of T ; it will then discard coche es, be-
cause although Mi coche es is a prefix of T , it is
not a prefix when a blank is added after it; finally,
it will select coche, because Mi coche followed by
a blank is a prefix of T and no longer suggestion
that also satisfies these conditions exists.
Two different corpora were used for the au-
tomatic evaluation: for English?Spanish (en-es),
a combination of sentences from all the editions
of DGT-TM (Steinberger et al., 2012) released
9
Note that real users could also decide to select sugges-
tions with small errors and fix them, but neither this nor other
behaviours are considered in our automatic evaluation.
 0
 0.2
 0.4
 0.6
 0.8
 1
 1  2  3  4  5  6  7
KS
R/A
SR
l
ca-es KSR
en-es KSR
ca-es ASR
en-es ASR
Figure 4: Automatically evaluated KSR versus
exact length of the segments l. Longer sugges-
tions are much more useful for Spanish?Catalan
(closely related languages) than for English?
Spanish: the KSR for l = 7 is still a little better
than that for l = 1 for Catalan?Spanish, but no-
ticeably worse for English?Spanish. ASR quickly
degrades as l increases.
in 2004?2011 (15 250 sentences; 163 196 words
in English; 190 448 in Spanish) was used; for
Catalan?Spanish (ca-es), a collection of news
items from El Peri?odico de Catalunya
10
(15 000
sentences; 307 095 words in Catalan; 294 488 in
Spanish) was used.
5.3 Results of the automatic evaluation
The objective of the automatic evaluation was to
estimate the influence of the language pair and the
parameters L and M .
11
Maximum length of segments. We first tested
to what extent each different segment length l con-
tributes separately to the KSR. Note that l cor-
responds in this case to the exact length of the
source segments and not to the longest one (as rep-
resented by L). M = ? is used in all the ex-
periments in this section. Figure 4 shows that the
KSR becomes worse for greater values of l, which
can be explained by the fact that longer machine
translations often contain more errors than shorter
ones. In the case of Catalan?Spanish, the worst
KSR value is for l = 1 since adequate suggestions
will usually consist of few characters and selecting
them will barely contribute to keystroke reduction.
10
http://www.elperiodico.cat/ca/
11
95% confidence intervals of the average values presented
in this section were calculated using the Student?s t-test. The
size of the evaluation corpora signifies that the resulting con-
fidence intervals are so small that they would have been im-
perceptible on the graphs and have therefore been omitted.
62
 0
 0.2
 0.4
 0.6
 0.8
 1
 1  2  3  4  5  6  7
KS
R/A
SR
L
ca-es KSR
en-es KSR
ca-es ASR
en-es ASR
Figure 5: Automatically evaluated KSR/ASR ver-
sus maximum length of the segments L. As L in-
creases, the KSR improves, but the ASR is nega-
tively affected.
Combining different segment lengths up to length
L provides better values of KSR than using only
a fixed value l = L (compare Figures 4 and 5).
Figure 5 shows an estimation of the best results
our method could attain if all the compatible sug-
gestions in P
S
C
were included in P
S
O
: values be-
tween 0.3 and 0.4 for the Catalan?Spanish KSR
and between 0.7 and 0.8 for the English?Spanish
KSR. The notable difference may be explained
by the fact that Apertium performance is much
better (Forcada et al., 2011) for Catalan?Spanish
(word error rates of around 15%) than for English?
Spanish (word error rates of around 70%).
Maximum number of suggestions offered. We
evaluated the influence of the maximum size M
of the list of suggestions offered to the user and,
hence, the impact of the distance-based ranker.
L = 4 was used, as this value provides good re-
sults for both language pairs (see Figure 5). As
expected (see Figure 6), the distance-based rank-
ing strategy works remarkably well (values for
KSR and ASR from M = 4 are similar to those
obtained with M = ?) for closely related lan-
guages (Catalan?Spanish), in which translations
are usually monotonic and reorderings seldom oc-
cur. However, the empirical results also show (see
again Figure 6) that it also works well for language
pairs (English?Spanish) in which long-distance re-
orderings exist, at least when compared to the re-
sults without ranking (M =?).
5.4 Human evaluation
A preliminary evaluation of a real use of our sys-
tem involving 8 human non-professional trans-
 0
 0.2
 0.4
 0.6
 0.8
 1
? 1  2  3  4  5
KS
R/A
SR
M
ca-es KSR
en-es KSR
ca-es ASR
en-es ASR
Figure 6: Automatically evaluated KSR/ASR ver-
sus maximum number M of suggestions offered.
Although the results with M = 1 (only one sug-
gestion offered) are considerably worse, for higher
values of M they quickly approach the results ob-
tained when no ranker was used and all the com-
patible suggestions were offered (M =?).
lators (volunteer computer science students) was
also conducted. All the users were Spanish na-
tive speakers who understood Catalan, but with no
experience with ITP systems. As the results of the
automatic evaluation show that the performance of
the Apertium English?Spanish MT system nega-
tively affects our ITP system (see Section 5), we
decided to focus on the Catalan?Spanish scenario.
A set of 10 sentences in Catalan were randomly
extracted from the same corpus used in the auto-
matic evaluation. The test was designed to take
around 20 minutes. The evaluators were allowed
to practise with a couple of sentences before start-
ing the trial. After completing the test, they were
surveyed about the usefulness of the system. Our
ITP system was used with L = M = 4.
5.5 Results of the human evaluation
The users were divided into two groups: users
1?4 translated sentences 1?5 assisted by our ITP
tool and sentences 6?10 with no assistance, while
users 5?8 translated sentences 1?5 with no assis-
tance and sentences 6?10 assisted by the tool. The
KSR and translation times for each user are shown
in Table 2. This table also includes KSR
?
, which
is the value of KSR obtained by running our au-
tomatic evaluator (see Section 5.2) using the sen-
tences entered by each user as the reference trans-
lations T ; this can be considered as an approxi-
mation to the best result achievable with the ITP
tool. All users attained KSRs that were notice-
63
User Sentences 1?5 Sentences 6?10
KSR Time KSR
?
KSR Time KSR
?
#1 0.49 136 0.22 1.11 137 0.23
#2 0.64 144 0.15 1.21 86 0.22
#3 0.63 209 0.22 1.09 112 0.21
#4 0.37 189 0.22 1.22 199 0.18
#5 1.10 145 0.28 0.37 102 0.15
#6 1.24 150 0.27 0.51 154 0.17
#7 1.15 178 0.30 0.64 147 0.17
#8 1.18 118 0.39 0.58 93 0.15
Table 2: KSR, translation times (seconds) and
KSR
?
(see main text) for each of the users in the
evaluation. Values in bold correspond to the trans-
lations with assistance from our ITP system.
ably lower than 1 for the assisted translations and
slightly higher than 1 when translating without the
ITP system; the former, however, are often worse
than the KSR values obtained in the automatic
evaluation which are around 0.4 for L = M = 4
(see Figure 6). Moreover, the values for KSR
?
show that even better values for KSR could the-
oretically be attained for these sentences; note,
however, that the reference translations in this case
were precisely generated by accepting suggestions
generated by Apertium.
The users were surveyed to evaluate the follow-
ing statements in the range from 1 (complete dis-
agreement) to 5 (complete agreement): the inter-
face is easy to use; I would use a tool like this in
future translations; I have found the suggestions
useful; and the tool has allowed me to translate
faster. The median of the responses to the first two
questions was 5, whereas the median for the two
last questions was 4.5. It was evident that the eval-
uators perceived that the ITP system had helped
them to translate faster, although the time values
in Table 2 seem to suggest the opposite. Finally,
note that this was a small-scale human evaluation
and that sounder results will have to be collected
under different conditions by increasing the num-
ber of users, sentences and languages in the test.
6 Discussion and future work
The automatic evaluation of our ITP system has
provided an estimation of its potential for human
translators. Note, however, that this evaluation
strategy is based on a greedy algorithm which may
not adequately reproduce the way in which a hu-
man translator might usually perform the task. Ac-
cording to the best results of our automatic exper-
iments, when a maximum of M = 4 suggestions
are offered and the system selects the longest one
that matches the reference translation, 25?65%
keystrokes could be saved depending on the lan-
guage pair. Moreover, 30?55% of the times that
a list of suggestions is offered, at least one of the
suggestions matches the target sentence.
Our preliminary human tests can be used to dis-
cern how well our system could perform, but a
more extensive evaluation is needed to explore the
influence of parameters, different kinds of users,
heterogeneous bilingual resources, new language
pairs, particular domains, different interfaces, etc.
in greater depth. A comparison with similar tools
in literature will also be carried out.
We plan to improve the ranking strategy shown
in Section 4.1 by automatically detecting the part
of the input sentence being translated at each mo-
ment so that segments that originate in those posi-
tions are prioritised. We intend to achieve this by
combining word alignment and distortion models.
The former will be used to determine the align-
ments between the last words introduced by the
user and the words in the input sentence;
12
the lat-
ter will predict which source words will be trans-
lated next, partly by using information from the
alignment model.
The ITP system presented in this paper is im-
plemented in Java, except for the web interface,
which is written in HTML and JavaScript. The
Java code, however, has been designed in such a
way that it can be compiled into JavaScript with
the help of the Google Web Toolkit framework;
13
and the same code can therefore be executed either
on the browser in JavaScript when human transla-
tors interact with the tool, or locally in Java when
performing the automatic evaluation. The entire
code of the application is available
14
under a free
software license (GNU Affero General Public Li-
cense, version 3); this ensures the reproducibility
of the experiments and allows our ITP system to
be integrated into professional translation tools.
Acknowledgments. This work has been partly
funded by the Spanish Ministerio de Econom??a y
Competitividad through project TIN 2012-32615.
12
On-the-fly, light alignment models have been proposed
which do not require parallel corpora and are based on the
translation of all the possible segments of the sentence with
the help of black-box bilingual resources (Espl`a-Gomis et al.,
2012); these models would fit nicely into our ITP method.
13
http://www.gwtproject.org/
14
https://github.com/jaspock/forecat
64
References
Vicent Alabau, Daniel Ortiz-Mart??nez, Alberto San-
chis, and Francisco Casacuberta. 2010. Multimodal
interactive machine translation. In ICMI-MLMI ?10:
Proceedings of the 2010 International Conference
on Multimodal Interfaces.
Vicent Alabau, Ragnar Bonk, Christian Buck, Michael
Carl, Francisco Casacuberta, Mercedes Garc??a-
Mart??nez, Jes?us Gonz?alez-Rubio, Philipp Koehn,
Luis A. Leiva, Bartolom?e Mesa-Lao, Daniel Or-
tiz, Herve Saint-Amand, Germ?an Sanchis-Trilles,
and Chara Tsoukala. 2013. CASMACAT: An
open source workbench for advanced computer
aided translation. Prague Bull. Math. Linguistics,
100:101?112.
Sergio Barrachina, Oliver Bender, Francisco Casacu-
berta, Jorge Civera, Elsa Cubel, Shahram Khadivi,
Antonio Lagarda, Hermann Ney, Jes?us Tom?as, En-
rique Vidal, and Juan-Miguel Vilar. 2009. Sta-
tistical approaches to computer-assisted translation.
Computational Linguistics, 35(1):3?28.
Oliver Bender, David Vilar, Richard Zens, and Her-
mann Ney. 2005. Comparison of generation strate-
gies for interactive machine translation. In Pro-
ceedings of EAMT 2005 (10th Annual Conference of
the European Association for Machine Translation,
pages 30?40.
Miquel Espl`a-Gomis, Felipe S?anchez-Mart??nez, and
Mikel L. Forcada. 2012. Using external sources of
bilingual information for on-the-fly word alignment.
Technical report, Departament de Llenguatges i Sis-
temes Inform`atics, Universitat d?Alacant.
Mikel L Forcada, Mireia Ginest??-Rosell, Jacob Nord-
falk, Jim O?Regan, Sergio Ortiz-Rojas, Juan An-
tonio P?erez-Ortiz, Felipe S?anchez-Mart??nez, Gema
Ram??rez-S?anchez, and Francis M Tyers. 2011.
Apertium: a free/open-source platform for rule-
based machine translation. Machine Translation,
25(2):127?144.
George F. Foster, Pierre Isabelle, and Pierre Plam-
ondon. 1997. Target-text mediated interactive
machine translation. Machine Translation, 12(1-
2):175?194.
W. John Hutchins and Harold L. Somers. 1992. An in-
troduction to machine translation. Academic Press.
Philipp Koehn and Barry Haddow. 2009. Interactive
assistance to human translators using statistical ma-
chine translation methods. MT Summit XII.
Philipp Koehn. 2009. A web-based interactive com-
puter aided translation tool. In Proceedings of the
ACL-IJCNLP 2009 Software Demonstrations, pages
17?20.
Philipp Koehn. 2010. Statistical Machine Translation.
Cambridge University Press.
Philippe Langlais, S?ebastien Sauv?e, George Foster, El-
liott Macklovitch, and Guy Lapalme. 2000. Eval-
uation of TransType, a computer-aided translation
typing system: a comparison of a theoretical-and a
user-oriented evaluation procedures. In Conference
on Language Resources and Evaluation (LREC),
page 8.
Elliott Macklovitch. 2006. TransType2: The last
word. In Proceedings of the 5th International Con-
ference on Languages Resources and Evaluation
(LREC 06), pages 167?172.
Daniel Ortiz-Mart??nez, Luis A. Leiva, Vicent Alabau,
Ismael Garc??a-Varea, and Francisco Casacuberta.
2011. An interactive machine translation system
with online learning. In Proceedings of the ACL-
HLT 2011 System Demonstrations, pages 68?73.
Daniel Ortiz-Mart??nez. 2011. Advances in Fully-
Automatic and Interactive Phrase-Based Statisti-
cal Machine Translation. Ph.D. thesis, Universitat
Polit`ecnica de Val`encia.
Harold L. Somers. 2003. Computers and Translation:
A Translator?s Guide. Benjamins translation library.
John Benjamins Publishing Company.
Ralf Steinberger, Andreas Eisele, Szymon Klocek,
Spyridon Pilos, and Patrick Schl?uter. 2012. DGT-
TM: a freely available Translation Memory in 22
languages. In Language Resources and Evaluation
Conference, pages 454?459.
65
