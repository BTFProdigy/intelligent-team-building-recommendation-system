Proceedings of the Second Workshop on Statistical Machine Translation, pages 197?202,
Prague, June 2007. c?2007 Association for Computational Linguistics
The ISL Phrase-Based MT System for the 2007 ACL Workshop on
Statistical Machine Translation
M. Paulik1,2, K. Rottmann2, J. Niehues2, S. Hildebrand 1,2 and S. Vogel1
1Interactive Systems Laboratories, Carnegie Mellon University, Pittsburgh, PA, USA
2Institut fu?r Theoretische Informatik, Universita?t Karlsruhe (TH), Karlsruhe, Germany
{paulik|silja|vogel}@cs.cmu.edu ; {jniehues|rottmann}@ira.uka.de
Abstract
In this paper we describe the Interactive Sys-
tems Laboratories (ISL) phrase-based ma-
chine translation system used in the shared
task ?Machine Translation for European
Languages? of the ACL 2007 Workshop on
Statistical Machine Translation. We present
results for a system combination of the
ISL syntax-augmented MT system and the
ISL phrase-based system by combining and
rescoring the n-best lists of the two systems.
We also investigate the combination of two
of our phrase-based systems translating from
different source languages, namely Spanish
and German, into their common target lan-
guage, English.
1 Introduction
The shared task of the ACL 2007 Workshop on Sta-
tistical Machine Translation focuses on the auto-
matic translation of European language pairs. The
workshop provides common training sets for trans-
lation model training and language model training
to allow for easy comparison of results between the
participants.
Interactive Systems Laboratories participated in the
English ? Spanish Europarl and News Commen-
tary task as well as in the English ? German Eu-
roparl task. This paper describes the phrase-based
machine translation (MT) system that was applied
to these tasks. We also investigate the feasibility
of combining the ISL syntax-augmented MT system
(Zollmann et al, 2007) with our phrase-based sys-
tem by combining and rescoring the n-best lists pro-
duced by both systems for the Spanish ? English
Europarl task. Furthermore, we apply the same com-
bination technique to combine two of our phrase-
based systems that operate on different source lan-
guages (Spanish and German), but share the same
target language (English).
The paper is organized as follows. In section 2 we
give a general description of our phrase-based sta-
tistical machine translation system. Section 3 gives
an overview of the data and of the final systems
used for the English ? Spanish Europarl and News
Commentary tasks, along with corresponding per-
formance numbers. Section 4 shows the data, final
systems and results for the English ? German Eu-
roparl task. In Section 5, we present our experiments
involving a combination of the syntax-augmented
MT system with the phrase-based MT system and a
combination of the Spanish ? English and German
? English phrase-based systems.
2 The ISL Phrase-Based MT System
2.1 Word and Phrase Alignment
Phrase-to-phrase translation pairs are extracted by
training IBM Model-4 word alignments in both di-
rections, using the GIZA++ toolkit (Och and Ney,
2000), and then extracting phrase pair candidates
which are consistent with these alignments, start-
ing from the intersection of both alignments. This
is done with the help of phrase model training
code provided by University of Edinburgh during
the NAACL 2006 Workshop on Statistical Machine
Translation (Koehn and Monz, 2006). The raw rel-
197
ative frequency estimates found in the phrase trans-
lation tables are then smoothed by applying modi-
fied Kneser-Ney discounting as explained in (Foster
et al, 2006). The resulting phrase translation tables
are pruned by using the combined translation model
score as determined by Minimum Error Rate (MER)
optimization on the development set.
2.2 Word Reordering
We apply a part-of-speech (POS) based reordering
scheme (J. M. Crego et al, 2006) to the POS-tagged
source sentences before decoding. For this, we use
the GIZA++ alignments and the POS-tagged source
side of the training corpus to learn reordering rules
that achieve a (locally) monotone alignment. Fig-
ure 1 shows an example in which three reordering
rules are extracted from the POS tags of an En-
glish source sentence and its corresponding Span-
ish GIZA++ alignment. Before translation, we con-
struct lattices for every source sentence. The lattices
include the original source sentence along with all
the reorderings that are consistent with the learned
rules. All incoming edges of the lattice are anno-
tated with distortion model scores. Figure 2 gives an
example of such a lattice. In the subsequent lattice
decoding step, we apply either monotone decoding
or decoding with a reduced local reordering window,
typically of size 2.
2.3 Decoder and MER Training
The ISL beam search decoder (Vogel, 2003) com-
bines all the different model scores to find the best
translation. Here, the following models were used:
? The translation model, i.e. the phrase-to-
phrase translations extracted from the bilingual
corpus, annoted with four translation model
scores. These four scores are the smoothed for-
ward and backward phrase translation proba-
bilities and the forward and backward lexical
weights.
? A 4-gram language model. The SRI language
model toolkit was used to train the language
model and we applied modified Kneser-Ney
smoothing.
? An internal word reordering model in addition
to the already described POS-based reordering.
  
We all agree on thatPRP DT VB IN DTEn {4} esto {5} estamos {1} todos {2} de {} acuerdo {3}
? PRP DT VB IN DT :   4 ? 5 ? 1 ? 2 ? 3? PRP DT VB:   2 ? 3 ? 1 ? PRP DT VB IN:   3 ? 4 ? 1 ? 2
Figure 1: Rule extraction for the POS-based reorder-
ing scheme.
This internal reordering model assigns higher
costs to longer distance reordering.
? Simple word and phrase count models. The
former is essentially used to compensate for
the tendency of the language model to prefer
shorter translations, while the latter can give
preference to longer phrases, potentially im-
proving fluency.
The ISL SMT decoder is capable of loading
several language models (LMs) at the same time,
namely n-gram SRI language models with n up to
4 and suffix array language models (Zhang and Vo-
gel, 2006) of arbitrary length. While we typically
see gains in performance for using suffix array LMs
with longer histories, we restricted ourselves here to
one 4-gram SRI LM only, due to a limited amount
of available LM training data. The decoding process
itself is organized in two stages. First, all available
word and phrase translations are found and inserted
into a so-called translation lattice. Then the best
combination of these partial translations is found
by doing a best path search through the translation
lattice, where we also allow for word reorderings
within a predefined local reordering window.
To optimize the system towards a maximal BLEU
or NIST score, we use Minimum Error Rate (MER)
Training as described in (Och, 2003). For each
model weight, MER applies a multi-linear search
on the development set n-best list produced by the
system. Due to the limited numbers of translations
in the n-best list, these new model weights are sub-
optimal. To compensate for this, a new full trans-
lation is done. The resulting new n-best list is then
merged with the old n-best list and the optimization
process is repeated. Typically, the translation quality
converges after three iterations.
198
1
20 3
honourable1.0000
Members1.0000 honourable0.3299
Members0.6701 6
75 8
we1.0000
have1.0000
have0.9175
a0.08254,1.0000 a1.0000
?
?Honourable Members, we have a challenging agenda?
Figure 2: Example for a source sentence lattice from
the POS-based reordering scheme.
English Spanish
sentence pairs 1259914
unique sent. pairs 1240151
sentence length 25.3 26.3
words 31.84 M 33.16 M
vocabulary 266.9 K 346.3 K
Table 1: Corpus statistics for the English/Spanish
Europarl corpus.
3 Spanish? English Europarl and News
Commentary Task
3.1 Data and Translation Tasks
The systems for the English ? Spanish translation
tasks were trained on the sentence-aligned Europarl
corpus (Koehn, 2005). Detailed corpus statistics can
be found in Table 1. The available parallel News
Commentary training data of approximately 1 mil-
lion running words for both languages was only
used as additional language model training data, to
adapt our in-domain (Europarl) system to the out-of-
domain (News Commentary) task.
The development sets consist of 2000 Europarl
sentences (dev-EU) and 1057 News Commentary
sentences (dev-NC). The available development-
test data consists of 2 x 2000 Europarl sentences
(devtest-EU and test06-EU) and 1064 News Com-
mentary sentences (test06-NC). All development
and development-test sets have only one reference
translation per sentence.
3.2 Data Normalization
The ACL shared task is very close in form and con-
tent to the Final Text Editions (FTE) task of the TC-
STAR (TC-STAR, 2004) evaluation. For this rea-
son, we decided to apply a similar normalization
scheme to the training data as was applied in our TC-
STAR verbatim SMT system. Although trained on
?verbatimized? data that did not contain any num-
bers, but rather had all numbers and dates spelled
out, it yielded consistently better results than our
TC-STAR FTE SMT system. When translating FTE
content, the verbatim system treated all numbers as
unknown words, i.e. they were left unchanged dur-
ing translation. To compensate for this, we applied
extended postprocessing to the translations that con-
ducts the necessary conversions between Spanish
and English numbers, e.g. the conversion of deci-
mal comma in Spanish to decimal point in English.
Other key points which we adopted from this nor-
malization scheme were the tokenization of punc-
tuation marks, the true-casing of the first word of
each sentence, as well as extended cleaning of the
training data. The latter mainly consisted of the re-
moval of sections with a highly unbalanced source
to target words ratio and the removal of unusual
string combinations and document references, like
for example ?B5-0918/2000?, ?(COM(2000) 335 -
C5-0386/2000 - 2000/0143(CNS))?, etc.
Based on this normalization scheme, we trained and
optimized a baseline in-domain system on accord-
ingly normalized source and reference sentences.
For optimization, we combined the available de-
velopment sets for the Europarl task and the News
Commentary task. In order to further improve
the applied normalization scheme, we experimented
with replacing all numbers with the string ?NMBR?,
rather than spelling them out and by replacing all
document identifiers with the string ?DCMNT?,
rather than deleting them. This was first done for
the language model training data only, and then for
all data, i.e. for the bilingual training data and for
the development set source and reference sentences.
In the latter case, the respective tags were again re-
placed by the correct numbers and document identi-
fiers during postprocessing. Table 2 shows the case
sensitive BLEU scores for the three normalization
approaches on the English ? Spanish Europarl and
News Commentary development sets. These scores
were computed with the official NIST scoring script
against the original (not normalized) references.
3.3 In-domain System
As mentioned above, we combined the Europarl and
News Commentary development sets when optimiz-
ing the in-domain system. This resulted in only one
199
Task baseline LM only all data
Europarl 30.94 31.20 31.26
News Com. 31.28 31.39 31.73
Table 2: Case sensitive BLEU scores on the in-
domain and out-of-domain development sets for the
three different normalization schemes.
Task Eng ? Spa Spa ? Eng
dev-EU 31.29 31.77
dev-NC 31.81 31.12
devtest-EU 31.01 31.40
test06-EU 31.87 31.76
test06-NC 30.23 29.22
Table 3: Case sensitive BLEU scores for the final
English ? Spanish in-domain systems.
set of scaling factors, i.e. the in-domain system
applies the same scaling factors for translating in-
domain data as for translating out-of-domain data.
Our baseline system applied only monotone lattice
decoding. For our final in-domain system, we used a
local reordering window of length 2, which accounts
for the slightly higher scores when compared to the
baseline system. The BLEU scores for both trans-
lation directions on the different development and
development-test sets can be found in Table 3.
3.4 Out-of-domain System
In order to adapt our in-domain system towards the
out-of-domain News Commentary task, we consid-
ered two approaches based on language model adap-
tation. First, we interpolated the in-domain LM
with an out-of-domain LM computed on the avail-
able News Commentary training data. The inter-
polation weights were chosen such as to achieve a
minimal LM perplexity on the out-of-domain de-
velopment set. For both languages, the interpo-
lation weights were approximately 0.5. Our sec-
ond approach was to simply load the out-of-domain
LM as an additional LM into our decoder. In both
cases, we optimized the translation system on the
out-of-domain development data only. For the sec-
ond approach, MER optimization assigned three to
four times higher scaling factors to the consider-
ably smaller out-domain LM than to the original in-
domain LM. Table 4 shows the results in BLEU on
the out-of-domain development and development-
test sets for both translation directions. While load-
Eng ? Spa Spa ? Eng
Task interp 2 LMs interp 2 LMs
dev-NC 33.31 33.28 32.61 32.70
test06-NC 32.55 32.15 30.73 30.55
Table 4: Case sensitive BLEU scores for the final
English ? Spanish out-of-domain systems.
ing a second LM gives similar or slightly better re-
sults on the development set during MER optimiza-
tion, we see consistently worse results on the unseen
development-test set. This, in the context of the rela-
tively small amount of development data, can be ex-
plained by stronger overfitting during optimization.
4 English? German Europarl Task
The systems for the English ? German translation
tasks were trained on the sentence-aligned Europarl
corpus only. The complete corpus consists of ap-
proximately 32 million English and 30 million Ger-
man words.
We applied a similar normalization scheme to the
training data as for the English ? Spanish system.
The main difference was that we did not replace
numbers and that we removed all document refer-
ences. In the translation process, the document ref-
erences were treated as unknown words and there-
fore left unchanged. As above, we trained and op-
timized a first baseline system on the normalized
source and reference sentences. However, we used
only the Europarl task development set during opti-
mization. To achieve further improvements on the
German ? English task, we applied a compound
splitting technique. The compound splitting was
based on (Koehn and Knight, 2003) and was applied
on the lowercased source sentences. The words gen-
erated by the compound splitting were afterwards
true-cased. Instead of replacing a compound by
its separate parts, we added a parallel path into the
source sentence lattices used for translation. The
source sentence lattices were augmented with scores
on their edges indicating whether each edge repre-
sents a word of the original text or if it was gener-
ated during compound splitting.
Table 5 shows the case-sensitive BLEU scores for
the final German ? English systems. In contrast
to the English ? Spanish systems, we used only
monotonous decoding on the lattices containing the
200
task Eng ? Ger Ger ? Eng
dev-EU 18.58 23.85
devtest-EU 18.50 23.87
test06-EU 18.39 23.88
Table 5: Case sensitive BLEU scores for the final
English ? German in-domain systems.
syntactical reorderings.
5 System Combination via n-best List
Combination and Rescoring
5.1 N-best List Rescoring
For n-best list rescoring we used unique 500-best
lists, which may have less than 500 entries for
some sentences. In this evaluation, we used sev-
eral features computed from different information
sources such as features from the translation sys-
tem, additional language models, IBM-1 word lex-
ica and the n-best list itself. We calculated 4 fea-
tures from the IBM-1 word lexica: the word proba-
bility sum as well as the maximum word probabil-
ity in both language directions. From the n-best list
itself, we calculated three different sets of scores.
A position-dependent word agreement score as de-
scribed in (Ueffing and Ney, 2005) with a position
window instead of the Levenshtein alignment, the
n-best list n-gram probability as described in (Zens
and Ney, 2006) and a position-independent n-gram
agreement, which is a variation on the first two. To
tune the feature combination weights, we used MER
optimization.
Rescoring the n-best lists from our individual sys-
tems did not give significant improvements on the
available unseen development-test data. For this rea-
son, we did not apply n-best list rescoring to the indi-
vidual systems. However, we investigated the feasi-
bility of combining two different systems by rescor-
ing the joint n-best lists of both systems. The corre-
sponding results are described in the following sec-
tions.
5.2 Combining Syntax-Augmented MT and
Phrase-Based MT
On the Spanish ? English in-domain task, we par-
ticipated not only with the ISL phrase-based SMT
system as described in this paper, but also with
the ISL syntax-augmented system. The syntax-
task PHRA SYNT COMB
dev-EU 31.77 32.48 32.77
test06-EU 31.76 32.15 32.27
Table 6: Results for combining the syntax-
augmented system (SYNT) with the phrase-based
system (PHRA).
augmented system was trained on the same normal-
ized data as the phrase-based system. However, it
was optimized on the in-domain development set
only. More details on the syntax-augmented system
can be found in (Zollmann et al, 2007). Table 6
lists the respective BLEU scores of both systems as
well as the BLEU score achieved by combining and
rescoring the individual 500-best lists.
5.3 Combining MT Systems with Different
Source Languages
(Och and Ney, 2001) describes methods for trans-
lating text given in multiple source languages into a
single target language. The ultimate goal is to im-
prove the translation quality when translating from
one source language, for example English into mul-
tiple target languages, such as Spanish and German.
This can be done by first translating the English doc-
ument into German and then using the translation as
an additional source, when translating to Spanish.
Another scenario where a multi-source translation
becomes desirable was described in (Paulik et al,
2005). The goal was to improve the quality of au-
tomatic speech recognition (ASR) systems by em-
ploying human-provided simultaneous translations.
By using automatic speech translation systems to
translate the speech of the human interpreters back
into the source language, it is possible to bias the
source language ASR system with the additional
knowledge. Having these two frameworks in mind,
we investigated the possibility of combining our in-
domain German ? English and Spanish ? English
translation systems using n-best list rescoring. Ta-
ble 7 shows the corresponding results. Even though
the German ? English translation performance was
approximately 8 BLEU below the translation perfor-
mance of the Spanish ? English system, we were
able to improve the final translation performance by
up to 1 BLEU.
201
task Spa ? Eng Ger ? Eng Comb.
dev-EU 31.77 23.85 32.76
devtest-EU 31.40 23.87 32.41
test06-EU 31.76 23.88 32.51
Table 7: Results for combining the Spanish ? En-
glish and German ? English phrase-based systems
on the in-domain tasks.
6 Conclusion
We described the ISL phrase-based statistical ma-
chine translation systems that were used for the 2007
ACL Workshop on Statistical Machine Translation.
Using the available out-of-domain News Commen-
tary task training data for language model adapta-
tion, we were able to significantly increase the per-
formance on the out-of-domain task by 2.3 BLEU
for English ? Spanish and by 1.3 BLEU for Span-
ish ? English. We also showed the feasibility of
combining different MT systems by combining and
rescoring their resprective n-best lists. In particular,
we focused on the combination of our phrase-based
and syntax-augmented systems and the combination
of two phrase-based systems operating on different
source languages. While we saw only a minimal im-
provement of 0.1 BLEU for the phrase-based and
syntax-augmented combination, we gained up to 1
BLEU, in case of the multi-source translation.
References
G. Foster, R. Kuhn, and H. Johnson. 2006. Phrasetable
Smoothing for Statistical Machine Translation. In
Proc. of Empirical Methods in Natural Language Pro-
cessing, Sydney, Australia.
J. M. Crego et al 2006. N-gram-based SMT System
Enhanced with Reordering Patterns. In Proc. of the
Workshop on Statistical Machine Translation, pages
162?165, New York, USA.
P. Koehn and K. Knight. 2003. Empirical Methods for
Compound Splitting. In Proc. of the tenth conference
on European chapter of the Association for Computa-
tional Linguistics, pages 187?193, Budapest, Hungary.
P. Koehn and C. Monz. 2006. Manual and Automatic
Evaluation of Machine Translation between European
Langauges. In Proc. of the Workshop on Statisti-
cal Machine Translation, pages 102?121, New York,
USA.
P. Koehn. 2005. Europarl: A Parallel Corpus for Statis-
tical Machine Translation. In Proc. of Machine Trans-
lation Summit.
F.J. Och and H. Ney. 2000. Improved Statistical Align-
ment Models. In Proc. of the 38th Annual Meet-
ing of the Association for Computational Linguistics,
Hongkong, China.
F. J. Och and H. Ney. 2001. Statistical Multi-Source
Translation. In Proc. of Machine Translation Summit,
pages 253?258, Santiago de Compostela, Spain.
F. J. Och. 2003. Minimum Error Rate Training in Statis-
tical Machine Translation. In Proc. of the 41st Annual
Meeting of the Association for Computational Linguis-
tics, pages 160 ? 167, Sapporo, Japan.
M. Paulik, S. Stueker, C. Fuegen, T. Schultz, T. Schaaf,
and A. Waibel. 2005. Speech Translation Enhanced
Automatic Speech Recognition. In Proc. of the Work-
shop on Automatic Speech Recognition and Under-
standing, San Juan, Puerto Rico.
TC-STAR. 2004. Technology and Corpora for Speech to
Speech Translation. http://www.tc-star.org.
N. Ueffing and H. Ney. 2005. Word-Level Con-
fidence Estimation for Machine Translation using
Phrase-Based Translation Models. In Proc. of HLT
and EMNLP, pages 763?770, Vancouver, British
Columbia, Canada.
S. Vogel. 2003. SMT Decoder Dissected: Word Re-
ordering. In Proc. of Int. Conf. on Natural Lan-
guage Processing and Knowledge Engineering, Bei-
jing, China.
R. Zens and H. Ney. 2006. N-gram Posterior Proba-
bilities for Statistical Machine Translation. In Proc.
of the Workshop on Statistical Machine Translation,
pages 72?77, New York, USA.
Y. Zhang and S. Vogel. 2006. Suffix Array and its Ap-
plications in Empirical Natural Language Processing.
In the Technical Report CMU-LTI-06-010, Pittsburgh,
USA.
A. Zollmann, A. Venugopal, M. Paulik, and S. Vogel.
2007. The Syntax Augmented MT (SAMT) system
at the Shared Task for the 2007 ACL Workshop on
Statistical Machine Translation. In Proc. of ACL 2007
Workshop on Statistical MachineTranslation, Prague,
Czech Republic.
202
Proceedings of the Third Workshop on Statistical Machine Translation, pages 18?25,
Columbus, Ohio, USA, June 2008. c?2008 Association for Computational Linguistics
Discriminative Word Alignment via Alignment Matrix Modeling
Jan Niehues
Institut fu?r Theoretische Informatik
Universita?t Karlsruhe (TH)
Karlsruhe, Germany
jniehues@ira.uka.de
Stephan Vogel
Language Technologies Institute
Carnegie Mellon University
Pittsburgh, PA, 15213, USA
stephan.vogel@cs.cmu.edu
Abstract
In this paper a new discriminative word align-
ment method is presented. This approach
models directly the alignment matrix by a con-
ditional random field (CRF) and so no restric-
tions to the alignments have to be made. Fur-
thermore, it is easy to add features and so all
available information can be used. Since the
structure of the CRFs can get complex, the in-
ference can only be done approximately and
the standard algorithms had to be adapted. In
addition, different methods to train the model
have been developed. Using this approach the
alignment quality could be improved by up
to 23 percent for 3 different language pairs
compared to a combination of both IBM4-
alignments. Furthermore the word alignment
was used to generate new phrase tables. These
could improve the translation quality signifi-
cantly.
1 Introduction
In machine translation parallel corpora are one very
important knowledge source. These corpora are of-
ten aligned at the sentence level, but to use them
in the systems in most cases a word alignment is
needed. Therefore, for a given source sentence fJ1
and a given target sentence eI1 a set of links (j, i) has
to be found, which describes which source word fj
is translated into which target word ei.
Most SMT systems use the freely available
GIZA++-Toolkit to generate the word alignment.
This toolkit implements the IBM- and HMM-
models introduced in (Brown et al, 1993; Vogel et
al., 1996). They have the advantage that they are
trained unsupervised and are well suited for a noisy-
channel approach. But it is difficult to include addi-
tional features into these models.
In recent years several authors (Moore et al,
2006; Lacoste-Julien et al, 2006; Blunsom and
Cohn, 2006) proposed discriminative word align-
ment frameworks and showed that this leads to im-
proved alignment quality. In contrast to generative
models, these models need a small amount of hand-
aligned data. But it is easy to add features to these
models, so all available knowledge sources can be
used to find the best alignment.
The discriminative model presented in this pa-
per uses a conditional random field (CRF) to model
the alignment matrix. By modeling the matrix no
restrictions to the alignment are required and even
n:m alignments can be generated. Furthermore, this
makes the model symmetric, so the model will pro-
duce the same alignment no matter which language
is selected as source and which as target language.
In contrast, in generative models the alignment is a
function where a source word aligns to at most one
target word. So the alignment is asymmetric.
The training of this discriminative model has to be
done on hand-aligned data. Different methods were
tested. First, the common maximum-likelihood ap-
proach was used. In addition to this, a method to
optimize the weights directly towards a word align-
ment metric was developed.
The paper is structured as follows: Section 2 and
3 present the model and the training. In Section 4
the model is evaluated in the word alignment task as
well as in the translation task. The related work and
the conclusion are given in Sections 5 and 6.
18
Figure 1: Alignment Example
2 The Model
In the approach presented here the word alignment
matrix is modeled by a conditional random field
(CRF). A CRF is an unidirectional graphical model.
It models the conditional distribution over random
variables. In most applications like (Tseng et al,
2005; Sha and Pereira, 2003), a sequential model is
used. But to model the alignment matrix the graphi-
cal structure of the model is more complex.
The alignment matrix is described by a random
variable yji for every source and target word pair
(fj , ei). These variables can have two values, 0
and 1, indicating whether these words are transla-
tions of each other or not. An example is shown
in Figure 1. Gray circles represent variables with
value 1, white circles stand for variables with value
0. Consequently, a word with zero fertility is indi-
rectly modeled by setting all associated random vari-
ables to a value of 0.
The structure of the CRF is described by a fac-
tored graph like it was done, for example, in (Lan
et al, 2006). In this bipartite graph there are two
different types of nodes. First, there are hidden
nodes, which correspond to the random variables.
The second type of nodes are the factored nodes c
. These are not drawn in Figure 1 to keep the pic-
ture clear, but they are shown in Figure 2. They
define a potential ?c on the random variables Vc
they are connected to. This potential is used to
describe the probability of an alignment based on
the information encoded in the features. This po-
tential is a log-linear combination of some features
Fc(Vc) = (f1(Vc), . . . , fn(Vc)) and it can be written
as:
?c(Vc) = exp(? ? Fc(Vc)) = exp(
?
k
?k ? fk(Vc))
(1)
with the weights ?. Then the probability of an
assignment of the random variables, which corre-
sponds to a word alignment, can be expressed as:
p?(y|e, f) =
1
Z(e, f)
?
c?VFN
?c(Vc) (2)
with VFN the set of all factored nodes in the graph,
and the normalization factor Z(e, f) defined as:
Z(e, f) =
?
Y
?
c?VFN
?c(Vc) (3)
where Y is the set of all possible alignments.
In the presented model there are four different
types of factored nodes corresponding to four groups
of features.
2.1 Features
One main advantage of the discriminative frame-
work is the ability to use all available knowledge
sources by introducing additional features. Differ-
ent features have been developed to capture different
aspects of the word-alignment.
The first group of features are those that depend
only on the source and target words and may there-
fore be called local features. Consequently, the
factored node corresponding to such a feature is
connected to one random variable only (see Figure
2(a)). The lexical features, which represent the lexi-
cal translation probability of the words belong to this
group. In our experiments the IBM4-lexica in both
directions were used. Furthermore, there are source
and target normalized lexical features for every lexi-
con. The source normalized feature, for example, is
normalized in a way, that all translation probabilities
of one source word to target words in the sentences
sum up to one as shown in equation 4.
psourceN (fj , ei) =
plex(fj , ei)
?
1?j?J plex(fj , ei)
(4)
ptargetN (fj , ei) =
plex(fj , ei)
?
1?i?I plex(fj , ei)
(5)
19
Figure 2: Different features
(a) Local features (b) Fertility features (c) First order features
They compare the possible translations in one sen-
tence similar to the rank feature used in the approach
presented by Moore (2006). In addition, the follow-
ing local features are used: The relative distance of
the sentence positions of both words. This should
help to aligned words that occur several times in the
sentence. The relative edit distance between source
and target word was used to improve the align-
ment of cognates. Furthermore a feature indicating
if source and target words are identical was added
to the system. This helps to align dates, numbers
and names, which are quite difficult to align using
only lexical features since they occur quite rarely.
In some of our experiments the links of the IBM4-
alignments are used as an additional local feature.
In the experiments this leads to 22 features. Lastly,
there are indicator features for every possible com-
bination of Parts-of-Speech(POS)-tags and for Nw
high frequency words. In the experiments the 50
most frequent words were used, which lead to 2500
features and around 1440 POS-based features were
used. The POS-feature can help to align words, for
which the lexical features are weak.
The next group of features are the fertility fea-
tures. They model the probability that a word trans-
lates into one, two, three or more words, or does not
have any translation at all. The corresponding fac-
tored node for a source word is connected to all I
random variables representing the links to the target
words, and the node for a target word is connected
to all the J nodes for the links to source words (s.
Figure 2(b)). In this group of features there are two
different types. First, there are indicator features for
the different fertilities. To reduce the complexity of
the calculation this is only done up to a given max-
imal fertility Nf and there is an additional indicator
feature for all fertilities larger than Nf . This is an
extension of the empty word indicator feature used
in other discriminative word alignment models. Fur-
thermore, there is a real-valued feature, which can
use the GIZA++ probabilities for the different fer-
tilities. This has the advantage compared to the in-
dicator feature that the fertility probabilities are not
the same for all words. But here again, all fertilities
larger than a givenNf are not considered separately.
In the evaluation Nf = 3 was selected. So 12 fertil-
ity features were used in the experiments.
The first-order features model the first-order de-
pendencies between the different links. They are
grouped into different directions. The factored node
for the direction (s, t) is connected to the variable
nodes yji and y(j+s)(i+t). For example, the most
common direction is (1, 1), which describes the sit-
uation that if the words at positions j and i are
aligned, also the immediate successor words in both
sentences are aligned as shown in Figure 2(c). In
the default configuration the directions (1, 1), (2, 1),
(1, 2) and (1,?1) are used. So this feature is able to
explicitly model short jumps in the alignment, like
in the directions (2, 1) and (1, 2) as well as crossing
links like in the directions (1,?1). Furthermore, it
can be used to improve the fertility modeling. If a
word has got a fertility of two, it is often aligned to
two consecutive words. Therefore, for example in
the Chinese-English system the directions (1, 0) and
(0, 1) were used in addition. This does not mean,
that other directions in the alignment are not possi-
ble, but other jumps in the alignment do not improve
the probability of the alignment. For every direction,
an indicator feature that both links are active and an
additional one, which also depends on the POS-pair
of the first word pair is used. For a configuration
with 4 directions this leads to 4 indicator features
and, for example, 5760 POS-based features.
20
The last group of features are phrase features,
which are introduced to model context dependen-
cies. First a training corpus is aligned. Then, groups
of source and target words are extracted. Words
build a group, if all source words in the group are
aligned to all target words. The relative frequency
of this alignment is used as the feature and indicator
features for 1 : 1, 1 : n, n : 1 and n : m alignments.
The corresponding factored node is connected to all
links that are important for this group.
2.2 Alignment
The structure of the described CRF is quite complex
and there are many loops in the graphical structure,
so the inference cannot be done exactly. For exam-
ple, the random variables y(1,1) and y(1,2) as well as
y(2,1) and y(2,2) are connected by the source fertil-
ity nodes of the words f1 and f2. Furthermore the
variables y(1,1) and y(2,1) as well as y(1,2) and y(2,2)
are connected by the target fertility nodes. So these
nodes build a loop as shown in Figure 2(b). The first
order feature nodes generate loops as well. Conse-
quently an approximation algorithm has to be used.
We use the belief propagation algorithm introduced
in (Pearl, 1966). In this algorithm messages consist-
ing of a pair of two values are passed along the edges
between the factored and hidden nodes for several it-
erations. In each iterations first messages from the
hidden nodes to the connected factored nodes are
sent. These messages describe the belief about the
value of the hidden node calculated from the incom-
ing messages of the other connected factored nodes.
Afterwards the messages from the factored nodes
to the connected hidden nodes are send. They are
calculated from the potential and the other incom-
ing messages. This algorithm is not exact in loopy
graphs and it is not even possible to prove that it con-
verges, but in (Yedidia et al, 2003) it was shown,
that this algorithm leads to good results.
The algorithm cannot be used directly, since the
calculation of the message sent from a factored node
to a random variable has an exponential runtime
in the number of connected random variables. Al-
though we limit the number of considered fertili-
ties, the number of connected random variables can
still be quite large for the fertility features and the
phrase features, especially in long sentences. To re-
duce this complexity, we leverage the fact that the
potential can only have a small number of different
values. This will be shown for the fertility feature
node. For a more detailed description we refer to
(Niehues, 2007). The message sent from a factored
node to a random variable is defined in the algorithm
as:
mc?(j,i)(v) =
?
Vc/v
?c(Vc) (6)
?
(j,i)??N(c)/(j,i)
n(j,i)??c(v
?)
where Vc is the set of random variables connected
to the factored node and
?
Vc/v is the sum over all
possible values of Vc where the random variable yji
has the the value v. So the value for the message is
calculated by looking at every possible combination
of the other incoming messages. Then the belief for
this combination is multiplied with the potential of
this combination. This can be rewritten, since the
potential only depends on how many links are active,
not on which ones are active.
mc?(j,i)(v) =
Nf?
n=0
?c(n+ v) ? ?(n) (7)
+ ?c(Nf + 1) ? ?(Nf + 1)
with ?(n) the belief for a fertility of n of the other
connected nodes and ?(Nf+1) the belief for a fertil-
ity bigger than Nf with ?c(Nf + 1) the correspond-
ing potential. The belief for a configuration of some
random variables is calculated by the product over
all out-going messages. So ?(n) is calculated by the
sum over all possible configurations that lead to a
fertility of n over these products.
?(n) =
?
Vc/v:|Vc|=n
?
(j,i)??Vc/(j,i)
n(j,i)??c(v
?)
?(Nf + 1) =
?
Vc/v:|Vc|>Nf
?
(j,i)??Vc/(j,i)
n(j,i)??c(v
?)
The values of the sums can be calculated in linear
time using dynamic programming.
3 Training
The weights of the CRFs are trained using a gradient
descent for a fixed number of iterations, since this
approach leads already to quite good results. In the
21
experiments 200 iterations turned out to be a good
number.
The default criteria to train CRFs is to maximize
the log-likelihood of the correct solution, which is
given by a manually created gold standard align-
ment. Therefore, the feature values of the gold stan-
dard alignment and the expectation values have to be
calculated for every factored node. This can be done
using again the belief propagation algorithm.
Often, this hand-aligned data is annotated with
sure and possible links and it would be nice, if the
training method could use this additional informa-
tion. So we developed a method to optimize the
CRFs towards the alignment error rate (AER) or the
F-score with sure and possible links as introduced
in (Fraser and Marcu, 2007). The advantage of the
F-score is, that there is an additional parameter ?,
which allows to bias the metric more towards pre-
cision or more towards recall. To be able to use
a gradient descent method to optimize the weights,
the derivation of the word alignment metric with re-
spect to these weights must be computed. This can-
not be done for the mentioned metrics since they are
not smooth functions. We follow (Gao et al, 2006;
Suzuki et al, 2006) and approximate the metrics us-
ing the sigmoid function. The sigmoid function uses
the probabilities for every link calculated by the be-
lief propagation algorithm.
In our experiments we compared the maximum
likelihood method and the optimization towards the
AER. We also tested combinations of both. The best
results were obtained when the weights were first
trained using the ML method and the resulting fac-
tors were used as initial values for the AER opti-
mization. Another problem is that the POS-based
features and high frequency word features have a
lot more parameters than all other features and with
these two types of features overfitting seems to be a
bigger problem. Therefore, these features are only
used in a third optimization step, in which they are
optimized towards the AER, keeping all other fea-
ture weights constant. Initial results using a Gaus-
sian prior showed no improvement.
4 Evaluation
The word alignment quality of this approach was
tested on three different language pairs. On the
Spanish-English task the hand-aligned data provided
by the TALP Research Center (Lambert et al, 2005)
was used. As proposed, 100 sentences were used as
development data and 400 as test data. The so called
?Final Text Edition of the European Parliament Pro-
ceedings? consisting of 1.4 million sentences and
this hand-aligned data was used as training corpus.
The POS-tags were generated by the Brill-Tagger
(Brill, 1995) and the FreeLing-Tagger (Asterias et
al., 2006) for the English and the Spanish text re-
spectively. To limit the number of different tags for
Spanish we grouped them according to the first 2
characters in the tag names.
A second group of experiments was done on
an English-French text. The data from the 2003
NAACL shared task (Mihalcea and Pedersen, 2003)
was used. This data consists of 1.1 million sen-
tences, a validation set of 37 sentences and a test
set of 447 sentences, which have been hand-aligned
(Och and Ney, 2003). For the English POS-tags
again the Brill Tagger was used. For the French side,
the TreeTagger (Schmid, 1994) was used.
Finally, to test our alignment approach with lan-
guages that differ more in structure a Chinese-
English task was selected. As hand-aligned data
3160 sentences aligned only with sure links were
used (LDC2006E93). This was split up into 2000
sentences of test data and 1160 sentences of devel-
opment data. In some experiments only the first
200 sentences of the development data were used to
speed up the training process. The FBIS-corpus was
used as training corpus and all Chinese sentences
were word segmented with the Stanford Segmenter
(Tseng et al, 2005). The POS-tags for both sides
were generated with the Stanford Parser (Klein and
Manning, 2003).
4.1 Word alignment quality
The GIZA++-toolkit was used to train a baseline
system. The models and alignment information
were then used as additional knowledge source for
the discriminative word alignment. For the first two
tasks, all heuristics of the Pharaoh-Toolkit (Koehn
et al, 2003) as well as the refined heuristic (Och and
Ney, 2003) to combine both IBM4-alignments were
tested and the best ones are shown in the tables. For
the Chinese task only the grow-diag-final heuristic
was used.
22
Table 1: AER-Results on EN-ES task
Name Dev Test
IBM4 Source-Target 21.49
IBM4 Target-Source 19.23
IBM4 grow-diag 16.48
DWA IBM1 15.26 20.82
+ IBM4 14.23 18.67
+ GIZA-fert. 13.28 18.02
+ Link feature 12.26 15.97
+ POS 9.21 15.36
+ Phrase feature 8.84 14.77
Table 2: AER-Results on EN-FR task
Name Dev Test
IBM4 Source-Target 8.6
IBM4 Target-Source 9.86
IBM4 intersection 5.38
DWA IBM1 5.54 6.37
+ HFRQ/POS 3.67 5.57
+ Link Feature 3.13 4.80
+ IBM4 3.60 4.60
+ Phrase feature 3.32 4.30
The results measured in AER of the discrimina-
tive word alignment for the English-Spanish task are
shown in Table 1. In the experiments systems using
different knowledge sources were evaluated. The
first system used only the IBM1-lexica of both di-
rections as well as the high frequent word features.
Then the IBM4-lexica were used instead and in
the next system the GIZA++-fertilities were added.
As next knowledge source the links of both IBM4-
alignments were added. Furthermore, the system
could be improved by using also the POS-tags. For
the last system, the whole EPPS-corpus was aligned
with the previous system and the phrases were ex-
tracted. Using them as additional features, the best
AER of 14.77 could be reached. This is an improve-
ment of 1.71 AER points or 10% relative to the best
baseline system.
Similar experiments have also been done for the
English-French task. The results measured in AER
are shown in Table 2. The IBM4 system uses
the IBM4 lexica and links instead of the IBM1s
Table 3: AER-Results on CH-EN task
Name Test
IBM4 Source-target 44.94
IBM4 Target-source 37.43
IBM4 Grow-diag-final 35.04
DWA IBM4 30.97
- similarity 30.24
+ Add. directions 27.96
+ Big dev 27.26
+ Phrase feature 27.00
+ Phrase feature(high P.) 26.90
and adds the GIZA++-fertilities. For the ?phrase
feature?-system the corpus was aligned with the
?IBM4?-system and the phrases were extracted.
This led to the best result with an AER of 4.30. This
is 1.08 points or 20% relative improvement over the
best generative system. One reason, why less knowl-
edge sources are needed to be as good as the base-
line system, may be that there are many possible
links in the reference alignment and the discrimina-
tive framework can better adapt to this style. So a
system using only features generated by the IBM1-
model could already reach an AER of 4.80.
In Table 3 results for the Chinese-English align-
ment task are shown1. The first system was only
trained on the smaller development set and used the
same knowledge source than the ?IBM4?-systems
in the last experiment. The system could be im-
proved a little bit by removing the similarity fea-
ture and adding the directions (0, 1) and (1, 0) to
the model. Then the same system was trained on
the bigger development set. Again the parallel cor-
pus was aligned with the discriminative word align-
ment system, once trained towards AER and once
more towards precision, and phrases were extracted.
Overall, an improvement by 8.14 points or 23% over
the baseline system could be achieved.
These experiments show, that every knowledge
source that is available should be used. For all lan-
guages pairs additional knowledge sources lead to
an improvement in the word alignment quality. A
problem of the discriminative framework is, that
hand-aligned data is needed for training. So the
1For this task no results on the development task are given
since different development sets were used
23
Table 4: Translation results for EN-ES
Name Dev Test
Baseline 40.04 47.73
DWA 41.62 48.13
Table 5: Translation results for CH-EN
Name Dev Test
Baseline 27.13 22.56
AER 27.63 23.85?
F0.3 26.34 22.35
F0.7 26.40 23.52?
Phrase feature AER 25.84 23.42?
Phrase feature F0.7 26.41 23.92?
French-English dev set may be too small, since the
best system on the development set does not cor-
respond to the best system on the test set. And as
shown in the Chinese-English task additional data
can improve the alignment quality.
4.2 Translation quality
Since the main application of the word alignment is
statistical machine translation, the aim was not only
to generate better alignments measured in AER, but
also to generate better translations. Therefore, the
word alignment was used to extract phrases and use
them then in the translation system. In all translation
experiments the beam decoder as described in (Vo-
gel, 2003) was used together with a 3-gram language
model and the results are reported in the BLUE met-
ric. For test set translations the statistical signifi-
cance of the results was tested using the bootstrap
technique as described in (Zhang and Vogel, 2004).
The baseline system used the phrases build with the
Pharaoh-Toolkit.
The new word alignment was tested on the
English-Spanish translation task using the TC-Star
07 development and test data. The discriminative
word alignment (DWA) used the configuration de-
noted by +POS system in Table 1. With this con-
figuration it took around 4 hours to align 100K sen-
tences. But, of course, generating the alignment can
be parallelized to speed up the process. As shown
in Table 4 the new word alignment could generate
better translations as measured in BLEU scores.
For the Chinese-English task some experiments
were made to study the effect of different training
schemes. Results are shown in Table 5. The sys-
tems used the MT?03 eval set as development data
and the NIST part of the MT?06 eval set was used as
test set. Scores significantly better than the baseline
system are mark by a ?. The first three systems used
a discriminative word alignment generated with the
configuration as the one described as ?+ big dev?-
system in Table 3. The first one was optimized to-
wards AER, the other two were trained towards the
F-score with an ?-value of 0.3 (recall-biased) and
0.7 (precision-biased) respectively. A higher pre-
cision word alignment generates fewer alignment
links, but a larger phrase table. For this task, the
precision seems to be more important. So the sys-
tem trained towards the AER and the F-score with
an ?-value of 0.7 performed better than the other
systems. The phrase features gave improved perfor-
mance only when optimized towards the F-score, but
not when optimized towards the AER.
5 Comparison to other work
Several discriminative word alignment approaches
have been presented in recent years. The one most
similar to ours is the one presented by Blunsom
and Cohn (2006). They also used CRFs, but they
used two linear-chain CRFs, one for every direc-
tions. Consequently, they could find the optimal so-
lution for each individual CRF, but they still needed
the heuristics to combine both alignments. They
reached an AER of 5.29 using the IBM4-alignment
on the English-French task (compared to 4.30 of our
approach).
Lacoste-Julien et al (2006) enriched the bipartite
matching problem to model also larger fertilities and
first-or der dependencies. They could reach an AER
of 3.8 on the same task, but only if they also included
the posteriors of the model of Liang et al (2006).
Using only the IBM4-alignment they generated an
alignment with an AER of 4.5. But they did not use
any POS-based features in their experiments.
Finally, Moore et al (2006) used a log-linear
model for the features and performed a beam search.
They could reach an AER as low as 3.7 with both
types of alignment information. But they presented
no results using only the IBM4-alignment features.
24
6 Conclusion
In this paper a new discriminative word alignment
model was presented. It uses a conditional random
field to model directly the alignment matrix. There-
fore, the algorithms used in the CRFs had to be
adapted to be able to model dependencies between
many random variables. Different methods to train
the model have been developed. Optimizing the F-
score allows to generate alignments focusing more
on precision or on recall. For the model a multitude
of features using the different knowledge sources
have been developed. The experiments showed that
the performance could be improved by using these
additional knowledge sources. Furthermore, the use
of a general machine learning framework like the
CRFs enables this alignment approach to benefit
from future improvements in CRFs in other areas.
Experiments on 3 different language pairs have
shown that word alignment quality as well as trans-
lation quality could be improved. In the translation
experiments it was shown that the improvement is
significant at a significance level of 5%.
References
Atserias, J., B. Casas, E. Comelles, M. Gonza?lez, L.
Padro? and M. Padro?. 2006. FreeLing 1.3: Syntactic
and semantic services in an open-source NLP library.
In LREC?06. Genoa, Italy.
P. Blunsom and T. Cohn. 2006. Discriminative word
alignment with conditional random fields. In ACL?06,
pp. 65-72. Sydney, Australia.
E. Brill. 1995. Transformation-based error-driven learn-
ing and natural language processing: A case study in
part of speech tagging. Computational Linguistics,
21(4):543-565.
P.F. Brown, S. Della Pietra, V. J. Della Pietra, R. L. Mer-
cer. 1993. The Mathematic of Statistical Machine
Translation: Parameter Estimation. Computational
Linguistics, 19(2):263-311.
A. Fraser, D. Marcu. 2007. Measuring Word Alignment
Quality for Statistical Machine Translation Computa-
tional Linguistics, 33(3):293-303.
S. Gao, W. Wu, C. Lee, T. Chua. 2006. A maximal
figure-of-merit (MFoM)-learning approach to robust
classifier design for text categorization. ACM Trans.
Inf. Syst., 24(2):190-218.
D. Klein and C.D. Manning. 2003. Fast Exact Inference
with a Factored Model for Natural Language Parsing.
Advances in Neural Information Processing Systems
15 (NIPS 2002), pp. 3-10.
P. Koehn, F. J. Och, D. Marcu. 2003. Statistical
phrase-based translation. In HTL-NAACL?03, pp. 48-
54. Morristown, New Jersey, USA.
S. Lacoste-Julien, B. Taskar, D. Klein, M. I. Jordan.
2006. Word alignment via quadratic assignment. In
HTL-NAACL?06. New York, USA.
P. Lambert, A. de Gispert, R. Banchs and J. b. Marino.
2005. Guidelines for Word Alignment Evaluation and
Manual Alignment. Language Resources and Evalua-
tion, pp. 267-285, Springer.
X. Lan and S. Roth, D. P. Huttenlocher, M. J. Black.
2006. Efficient Belief Propagation with Learned
Higher-Order Markov Random Fields. ECCV (2),
Lecture Notes in Computer Science, pp. 269-282.
P. Liang, B. Taskar, D. Klein. 2006. Alignment by agree-
ment. In HTL-NAACL?06, pp. 104-110. New York,
USA.
R. Mihalcea, T. Pedersen. 2003. An Evaluation Exer-
cise for Word Alignment. In HLT-NAACL 2003 Work-
shop, Building and Using Parallel Texts: Data Driven
Machine Translation and Beyond, pp. 1-6. Edmon-
ton,Canada.
R. C. Moore, W. Yih, A. Bode. 2006. Improved dis-
criminative bilingual word alignment. In ACL?06, pp.
513-520. Sydney, Australia.
J. Niehues. 2007. Discriminative Word Alignment Mod-
els. Diplomarbeit at Universita?t Karlsruhe(TH).
F. J. Och and H. Ney. 2003. A Systematic Comparison of
Various Statistical Alignment Models. Computational
Linguist,29(1):19-51.
J. Pearl. 1988. Probabilistic Reasoning in Intelligent
Systems: Networks of Plausible Inference.
H. Schmid. 1994. Probabilistic Part-of-Speech Tagging
Using Decision Trees. In NEMLAP?94. Manchester,
UK.
F. Sha and F. Pereira. 2003. Shallow parsing with condi-
tional random fields. In HLT-NAACL?03, pp. 134?141.
Edmonton, Canada.
J. Suzuki, E. McDermott, H. Isozaki. 2006. Training
conditional random fields with multivariate evaluation
measures In ACL?06, pp 217-224. Sydney, Australia.
H. Tseng, P. Chang, G. Andrew, D. Jurafsky and C. Man-
ning. 2005. A Conditional Random Field Word Seg-
menter. In SIGHAN-4. Jeju, Korea.
S. Vogel, H. Ney, C. Tillmann. 1996. HMM-based word
alignment in statistical translation. In COLING?96,
pp. 836-841. Copenhagen, Denmark.
S. Vogel. 2003. SMT Decoder Dissected: Word Reorder-
ing. In NLP-KE?03. Bejing, China.
J. S. Yedidia, W. T. Freeman, Y. Weiss. 2003. Un-
derstanding belief propagation and its generalizations.
Exploring artificial intelligence in the new millennium.
Y. Zhang and S. Vogel. 2004. Measuring Confidence
Intervals for MT Evaluation Metrics. In TMI 2004.
Baltimore, MD, USA.
25
Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 80?84,
Athens, Greece, 30 March ? 31 March 2009. c?2009 Association for Computational Linguistics
The Universita?t Karlsruhe Translation System for the EACL-WMT 2009
Jan Niehues, Teresa Herrmann, Muntsin Kolss and Alex Waibel
Universita?t Karlsruhe (TH)
Karlsruhe, Germany
{jniehues,therrman,kolss,waibel}@ira.uka.de
Abstract
In this paper we describe the statistical
machine translation system of the Univer-
sita?t Karlsruhe developed for the transla-
tion task of the Fourth Workshop on Sta-
tistical Machine Translation. The state-of-
the-art phrase-based SMT system is aug-
mented with alternative word reordering
and alignment mechanisms as well as op-
tional phrase table modifications. We par-
ticipate in the constrained condition of
German-English and English-German as
well as in the constrained condition of
French-English and English-French.
1 Introduction
This paper describes the statistical MT system
used for our participation in the WMT?09 Shared
Translation Task and the particular language-pair-
dependent variations of the system. We use stan-
dard alignment and training tools and a phrase-
based SMT decoder for creating state-of-the-art
MT systems for our contribution in the transla-
tion directions English-German, German-English,
English-French and French-English.
Depending on the language pair, the baseline
system is augmented with part-of-speech (POS)-
based short-range and long-range word reordering
models, discriminative word alignment (DWA)
and several modifications of the phrase table. Ex-
periments with different system variants were con-
ducted including some of those additional system
components. Significantly better translation re-
sults could be achieved compared to the baseline
results.
An overview of the system will follow in Sec-
tion 2, which describes the baseline architecture,
followed by descriptions of the additional system
components. Translation results for the different
languages and system variants are presented in
Section 5.
2 Baseline System
The core of our system is the STTK decoder (Vo-
gel, 2003), a phrase-based SMT decoder with a
local reordering window of 2 words. The de-
coder generates a translation for the input text
or word lattice by searching translation model
and language model for the hypothesis that max-
imizes phrase translation probabilities and target
language probabilities. The translation model, i.e.
the SMT phrase table is created during the training
phase by a modified version of the Moses Toolkit
(Koehn et al, 2007) applying GIZA++ for word
alignment. Language models are built using the
SRILM Toolkit. The POS-tags for the reorder-
ing models were generated with the TreeTagger
(Schmid, 1994) for all languages.
2.1 Training, Development and Test Data
We submitted translations for the English-
German, German-English, English-French and
French-English tasks. All systems were trained
on the Europarl and News Commentary corpora
using the Moses Toolkit and apply 4-gram lan-
guage models created from the respective mono-
lingual News corpora. All feature weights are au-
tomatically determined and optimized with respect
to BLEU via MERT (Venugopal et al, 2005).
For development and testing we used data pro-
vided by the WMT?09, news-dev2009a and news-
dev2009b, consisting of 1026 sentences each.
3 Word Reordering Model
One part of our system that differs from the base-
line system is the reordering model. To account
for the different word orders in the languages, we
used the POS-based reordering model presented in
Rottmann and Vogel (2007). This model learns
rules from a parallel text to reorder the source side.
The aim is to generate a reordered source side that
can be translated in a more monotone way.
80
In this framework, first, reordering rules are
extracted from an aligned parallel corpus and
POS information is added to the source side.
These rules are of the form VVIMP VMFIN PPER
? PPER VMFIN VVIMP and describe how the
source side has to be reordered to match the tar-
get side. Then the rules are scored according to
their relative frequencies.
In a preprocessing step to the actual decoding
different reorderings of the source sentences are
encoded in a word lattice. Therefore, for all re-
ordering rules that can be applied to a sentence the
resulting reorderings are added to the lattice if the
score is better than a given threshold. The decod-
ing is then performed on the resulting word lattice.
This approach does model the reordering well
if only short-range reorderings occur. But espe-
cially when translating from and to German, there
are also long-range reorderings that require the
verb to be shifted nearly across the whole sen-
tence. During this shift of the verb, the rest of
the sentence remains mainly unchanged. It does
not matter which words are in between, since they
are moved as a whole. Furthermore, rules in-
cluding an explicit sequence of POS-tags spanning
the whole sentence would be too specific. A lot
more rules would be needed to cover long-range
reorderings with each rule being applicable only
very sparsely. Therefore, we model long-range re-
ordering by generalizing over the unaffected se-
quences and introduce rules with gaps. (For more
details see Niehues and Kolss (2009)). These are
learned in a way similar to the other type of re-
ordering rules described above, but contain a gap
representing one or several arbitrary words. It is,
for example, possible to have the following rule
VAFIN * VVPP ? VAFIN VVPP *, which puts
both parts of the German verb next to each other.
4 Translation Model
The translation models of all systems we submit-
ted differ in some parts from the baseline system.
The main changes done will be described in this
section.
4.1 Word Alignment
The baseline method for creating the word align-
ment is to create the GIZA++ alignments in both
directions and then to combine both alignments
using a heuristic, e.g. grow-diag-final-and heuris-
tic, as provided by the Moses Toolkit. In some
of the submitted systems we used a discrimina-
tive word alignment model (DWA) to generate
the alignments as described in Niehues and Vogel
(2008) instead. This model is trained on a small
amount of hand-aligned data and uses the lexical
probability as well as the fertilities generated by
the GIZA++ Toolkit and POS information. We
used all local features, the GIZA and indicator fer-
tility features as well as first order features for 6
directions. The model was trained in three steps,
first using the maximum likelihood optimization
and afterwards it was optimized towards the align-
ment error rate. For more details see Niehues and
Vogel (2008).
4.2 Phrase Table Smoothing
The relative frequencies of the phrase pairs are a
very important feature of the translation model,
but they often overestimate rare phrase pairs.
Therefore, the raw relative frequency estimates
found in the phrase translation tables are smoothed
by applying modified Kneser-Ney discounting as
described in Foster et al (2006).
4.3 Lattice Phrase Extraction
For the test sentences the POS-based reordering
allows us to change the word order in the source
sentence, so that the sentence can be translated
more easily. But this approach does not reorder
the training sentences. This may cause problems
for phrase extraction, especially for long-range re-
orderings. For example, if the English verb is
aligned to both parts of the German verb, this
phrase can not be extracted, since it is not contin-
uous on the German side. In the case of German
as source language, the phrase could be extracted
if we also reorder the training corpus.
Therefore, we build lattices that encode the
different reorderings for every training sentence.
Then we can not only extract phrase pairs from the
monotone source path, but also from the reordered
paths. So it would be possible to extract the ex-
ample mentioned before, if both parts of the verb
were put together by a reordering rule. To limit
the number of extracted phrase pairs, we extract
a source phrase only once per sentence even if it
may be found on different paths. Furthermore, we
do not use the weights in the lattice.
If we use the same rules as for the test sets,
the lattice would be so big that the number of ex-
tracted phrase pairs would be still too high. As
mentioned before, the word reordering is mainly
81
a problem at the phrase extraction stage if one
word is aligned to two words which are far away
from each other in the sentence. Therefore, the
short-range reordering rules do not help much in
this case. So, only the long-range reordering rules
were used to generate the lattice for the training
corpus. This already leads to an increase of the
number of source phrases in the filtered phrase ta-
ble from 724K to 971K. The number of phrase
pairs grows from 5.1M to 6.7M.
4.4 Phrase Table Adaption
For most of the different tasks there was a huge
amount of parallel out-of-domain training data
available, but only a much smaller amount of in-
domain training data. Therefore, we tried to adapt
our system to the in-domain data. We want to
make use of the big out-of-domain data, but do
not want to lose the information encoded in the in-
domain data.
To achieve this, we built an additional phrase
table trained only on the in-domain data. Since
the word alignment does not depend heavily on the
domain we used the same word alignment. Then
we combined both phrase tables in the following
way. A phrase pair with features ? from the first
phrase table is added to the combined one with
features < ?, 1 >, where 1 is a vector of ones with
length equal to the number of features in the other
phrase table. The phrase pairs of the other phrase
table were added with the features < 1, ? >.
5 Results
We submitted system translations for the English-
German, German-English, English-French and
French-English task. Their performance is mea-
sured applying the BLEU metric. All BLEU
scores are computed on the lower-cased transla-
tions.
5.1 English-German
The system translating from English to German
was trained on the data described in Section 2.1.
The first system already uses the POS-based re-
ordering model for short-range reorderings. The
results of the different systems are shown in Ta-
ble 1.
We could improve the translation quality on the
test set by using the smoothed relative frequen-
cies in the phrase table as described before and
by adapting the phrase table. Then we used the
discriminative word alignment to generate a new
word alignment. For the training of the model
we used 500 hand-aligned sentences from the Eu-
roparl corpus. By training a translation model
based on this word alignment we could improve
the translation quality further. At last we added
the model for long-range reorderings, which per-
forms best on the test set.
The improvement achieved by smoothing is sig-
nificant at a level of 5%, the remaining changes are
not significant on their own. In all language pairs,
the problem occurs that some features do not lead
to an improvement on the development set, but on
the test set. One reason for this may be that the
development set is quite small.
Table 1: Translation results for English-German
(BLEU Score)
System Dev Test
Short-range 13.96 14.99
+ Smoothing 14.36 15.38
+ Adaptation 13.96 15.44
+ Discrim. WA 14.45 15.61
+ Long-range reordering 14.58 15.70
5.2 German-English
The German-English system was trained on the
same data as the English-German except that we
perform compound splitting as an additional pre-
processing step. The compound splitting was
done with the frequency-based method described
in Koehn et al (2003). For this language di-
rection, the initial system already uses phrase ta-
ble smoothing, adaptation and discriminative word
alignment, in addition to the techniques of the
English-German baseline system. The results are
shown in Table 2.
For this language pair, we could improve the
translation quality, first, by adding the long-range
reordering model. Further improvements could be
achieved by using lattice phrase extraction as de-
scribed before.
5.3 English-French
For creating the English-French translations, first,
the baseline system as described in Section 2
was used. This baseline was then augmented
with phrase table smoothing, short-range word re-
ordering and phrase table adaptation as described
above. In addition, the adapted phrase table was
82
Table 2: Translation results for German-English
(BLEU Score)
System Dev Test
Initial System 20.52 22.01
+ Long-range reordering 21.04 22.36
+ Lattice phrase extraction 20.69 22.64
postprocessed such that phrase table entries in-
clude the same amount of punctuation marks, es-
pecially quotation marks, in both source and tar-
get phrase. In contrast to the English?German
language pairs, the word reordering required
in English?French translations are restricted to
rather local word shifts which can be covered by
the short-range reordering feature. Applying addi-
tional long-range reordering is scarcely expected
to yield further improvements for these language
pairs and was not applied specifically in this task.
Table 3 shows the results of the system variants.
Table 3: Translation results for English-French
(BLEU Score)
System Dev Test
Baseline 20.97 20.87
+ Smoothing 21.42 21.32
+ Short-range reordering 20.79 22.26
+ Adaptation 21.05 21.97
+ cleanPT 21.50 21.98
Both on development and test set, smoothing
the probabilities in the phrase table resulted in an
increase of nearly 0.5 BLEU points. Applying
short-range word reordering did not lead to an im-
provement on the development set. However, the
increase in BLEU on the test set is substantial. The
opposite is the case when adapting the phrase ta-
ble: While phrase table adaptation improves the
translation quality on the development set, adapta-
tion leads to lower scores on the test set.
Thus, the system configuration that performed
best on the test set applies phrase table smoothing
and short-range word reordering. For creating the
translations for our submission, this configuration
was used.
5.4 French-English
For the French-English task, similar experiments
have been conducted. With respect to the base-
line system, improvements in translation quality
could be measured when applying phrase table
smoothing. An increase of 0.43 BLEU points was
achieved using short-range word reordering. Ad-
ditional experiments with adapting the phrase ta-
ble to the domain of the test set led to further im-
provement. Submissions for the shared task were
created using the system including all mentioned
features.
Table 4: Translation results for French-English
(BLEU Score)
System Dev Test
Baseline 21.29 22.41
+ Smoothing 21.55 22.59
+ Short-range reordering 22.55 23.02
+ Adaptation 21.72 23.20
+ cleanPT 22.60 23.21
6 Conclusions
We have presented our system for the WMT?09
Shared Translation Task. The submissions for the
language pairs English-German, German-English,
English-French and French-English have been
created by the STTK decoder applying different
additional methods for each individual language
pair to enhance translation quality.
Word reordering models covering short-
range reordering for the English?French and
English?German and long-range reordering for
English?German respectively proved to result in
better translations.
Smoothing the phrase probabilities in the phrase
table also increased the scores in all cases, while
adapting the phrase table to the test domain only
showed a positive influence on translation quality
in some of our experiments. Further tuning of the
adaptation procedure could help to clarify the ben-
efit of this method.
Using discriminative word alignment as an
alternative to performing word alignment with
GIZA++ did also improve the systems translating
between English and German. Future experiments
will be conducted applying discriminative word
alignment also in the English?French systems.
Acknowledgments
This work was partly supported by Quaero Pro-
gramme, funded by OSEO, French State agency
for innovation.
83
References
George Foster, Roland Kuhn, and Howard Johnson.
2006. Phrasetable Smoothing for Statistical Ma-
chine Translation. In Proc. of Empirical Methods in
Natural Language Processing. Sydney, Australia.
Philipp Koehn, Franz Josef Och and Daniel Marcu.
2003. Statistical Phrase-Based Translation. In
HLT/NAACL 2003. Edmonton, Canada.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin and Evan Herbst. 2007. Moses: Open
Source Toolkit for Statistical Machine Translation.
In Proc. of Second ACL Workshop on Statistical Ma-
chine Translation. Prague, Czech Republic.
Jan Niehues and Stephan Vogel. 2008. Discriminative
Word Alignment via Alignment Matrix Modeling.
In Proc. of Third ACL Workshop on Statistical Ma-
chine Translation. Columbus, OH, USA.
Jan Niehues and Muntsin Kolss. 2009. A POS-Based
Model for Long-Range Reorderings in SMT. In
Proc. of Forth ACL Workshop on Statistical Machine
Translation. Athens, Greece.
Kay Rottmann and Stephan Vogel. 2007. Word Re-
ordering in Statistical Machine Translation with a
POS-Based Distortion Model. In TMI. Sko?vde,
Sweden.
Helmut Schmid. 1994. Probabilistic Part-of-Speech
Tagging Using Decision Trees. In International
Conference on New Methods in Language Process-
ing. Manchester, UK.
Ashish Venugopal, Andreas Zollman and Alex Waibel.
2005. Training and Evaluation Error Minimiza-
tion Rules for Statistical Machine Translation. In
Proc. of ACL 2005, Workshop on Data-drive Ma-
chine Translation and Beyond (WPT-05). Ann Ar-
bor, MI.
Stephan Vogel. 2003. SMT Decoder Dissected: Word
Reordering. In NLP-KE?03. Beijing, China.
84
Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 206?214,
Athens, Greece, 30 March ? 31 March 2009. c?2009 Association for Computational Linguistics
A POS-Based Model for Long-Range Reorderings in SMT
Jan Niehues and Muntsin Kolss
Universita?t Karlsruhe
Karlsruhe, Germany
{jniehues,kolss}@ira.uka.de
Abstract
In this paper we describe a new approach
to model long-range word reorderings in
statistical machine translation (SMT). Un-
til now, most SMT approaches are only
able to model local reorderings. But even
the word order of related languages like
German and English can be very different.
In recent years approaches that reorder the
source sentence in a preprocessing step
to better match target sentences according
to POS(Part-of-Speech)-based rules have
been applied successfully. We enhance
this approach to model long-range reorder-
ings by introducing discontinuous rules.
We tested this new approach on a German-
English translation task and could signifi-
cantly improve the translation quality, by
up to 0.8 BLEU points, compared to a sys-
tem which already uses continuous POS-
based rules to model short-range reorder-
ings.
1 Introduction
Statistical machine translation (SMT) is currently
the most promising approach to machine transla-
tion of large vocabulary tasks. The approach was
first presented by Brown et al (1993) and has since
been used in many translation systems (Wang and
Waibel, 1998), (Och and Ney, 2000), (Yamada
and Knight, 2000), (Vogel et al, 2003). State-
of-the-art SMT systems often use translation mod-
els based on phrases to describe translation corre-
spondences and word reordering between two lan-
guages. The reordering of words is one of the main
difficulties in machine translation.
Phrase-based translation models by themselves
have only limited capability to model different
word orders in the source and target language, by
capturing local reorderings within phrase pairs. In
addition, the decoder can reorder phrases, subject
to constraints such as confining reorderings to a
relatively small window. In combination with a
distance-based distortion model, some short-range
reorderings can be handled. But for many lan-
guage pairs this is not sufficient, and several au-
thors have proposed additional reordering mod-
els as described in Section 2. In this work we
present a new method that explicitly handles long-
range word reorderings by applying discontinu-
ous, POS-based reordering rules.
The paper is structured as follows: In the next
section we present related work that was carried
out in this area. Afterwards, we describe the prob-
lem of long-range reordering. In Section 4 the
existing framework for reordering will be intro-
duced. Section 5 describes the extraction of rules
modeling long-range reorderings, and in the fol-
lowing section the integration into the framework
will be explained. Finally, the model will be eval-
uated in Section 7, and a conclusion is given in
Section 8.
2 Related Work
Several approaches have been proposed to ad-
dress the problem of word reordering in SMT. Wu
(1996) and Berger et al (1996), for example, re-
strict the possible reorderings either during decod-
ing time or during the alignment, but do not use
any additional linguistic knowledge. A compari-
son of both methods can be found in Zens and Ney
(2003).
Furthermore, techniques to use additional lin-
guistic knowledge to improve the word order have
been developed. Shen et al (2004) and Och et al
(2004) presented approaches to re-rank the output
of the decoder using syntactic information. Fur-
thermore, lexical block-oriented reordering mod-
els have been developed in Tillmann and Zhang
(2005) and Koehn et al (2005). These models de-
cide during decoding time for a given phrase, if
206
the next phrase should be aligned to the left or to
the right.
In recent years several approaches using re-
ordering rules on the source side have been applied
successfully in different systems. These rules can
be used in rescoring as in Chen et al (2006) or can
be used in a preprocessing step. The aim of this
step is to monotonize the source and target sen-
tence. In Collins et al (2005) and Popovic? and
Ney (2006) hand-made rules were used to reorder
the source side depending on information from a
syntax tree or based on POS information. These
rules had to be created manually, but only a few
rules were needed and they were able to model
long-range reorderings. Consequently, for every
language pair these rules have to be created anew.
In contrast, other authors propose data-driven
methods. In Costa-jussa` and Fonollosa (2006)
the source sentence is first translated into an aux-
iliary sentence, whose word order is similar to
the one of the target sentences. Thereby statisti-
cal word classes were used. Rottmann and Vogel
(2007),Zhang et al (2007) and Crego and Habash
(2008) used rules to reorder the source side and
store different possible reorderings in a word lat-
tice. They use POS tags and in the latter two cases
also chunk tags to generalize the rules. The dif-
ferent reorderings are assigned weights depending
on their relative frequencies (Rottmann and Vo-
gel, 2007) or depending on a source side language
model (Zhang et al, 2007).
In the presented work we will use discontinuous
rules in addition to the rules used in Rottmann and
Vogel (2007). This enables us to model long-range
reorderings although we only need POS informa-
tion and no chunk tags.
3 Long-Range Reorderings
One of the main problems when translating from
German to English is the different word order
in both languages. Although both languages are
closely related, the word order is very different
in some cases. Especially when translating the
verb long-range reorderings have to be performed,
since the position of the German verb is differ-
ent from the one in the English sentence in many
cases.
The finite verbs in the English language are al-
ways located at the second position, in the main
clauses as well as in subordinate clauses. In Ger-
man this is only true for the main clause. In con-
trast to that, in German subordinate clauses the
verb (glauben) is at the final position as shown in
Example 1.
Example 1: ..., die an den Markt und an die
Gleichbehandlung aller glauben.
... who believe in markets and equal treatment
for all.
Example 2: Das wird mit derart unter-
schiedlichen Mitgliedern unmo?glich sein .
That will be impossible with such disparate
members.
A second difference in both languages is the po-
sition of the infinitive verb (sein/be) as shown in
Example 2. In contrast to the English language,
where it directly follows the finite verb, it is at the
final position of the sentence in the German lan-
guage.
The two examples show that in order to be able
to handle the reorderings between German and
English, the model has to allow some words to
be shifted across the whole sentence. If this is
not handled correctly, phrase-based systems some-
times generate translations that omit words, as will
be shown in Section 7. This is especially problem-
atic in the German-English case because the verb
may be omitted, which carries the most important
information of the sentence.
4 POS-Based Reordering
We will first briefly introduce the framework pre-
sented in Rottmann and Vogel (2007) since we ex-
tended it to also use discontinuous rules.
In this framework, the first step is to extract re-
ordering rules. Therefore, an aligned parallel cor-
pus and the POS tags of the source side are needed.
For every sequence of source words where the tar-
get words are in a different order, a rule is ex-
tracted that describes how the source side has to be
reordered to match the target side. A rule may for
example look like this: VVIMP VMFIN PPER ?
PPER VMFIN VVIMP. The framework can handle
rules that only depend on POS tags as well as rules
that depend on POS tags and words. We will refer
to these rules as short-range reordering rules.
The next step is to calculate the relative frequen-
cies which are used as a score in the word lattice.
The relative frequencies are calculated as the num-
ber of times the source side is reordered this way
divided by the number of times the source side oc-
curred in the corpus.
In a preprocessing step to the actual decoding,
207
different reorderings of the source sentences are
encoded in a word lattice. For all reordering rules
that can be applied to the sentence, the resulting
edge is added to the lattice if the score is better
than a given threshold. If a reordering is generated
by different rules, only the path of the reordering
with the highest score is added to the lattice. Then,
decoding is performed on the resulting word lat-
tice.
5 Rule Extraction
To be able to handle long-range reorderings, we
extract discontinuous reordering rules in addition
to the continuous ones. The extracted rules should
look, for example, like this: VAFIN * VVPP ?
VAFIN VVPP *, where the placeholder ?*? repre-
sents one or more arbitrary POS tags.
Compared to the continuous, short-range re-
ordering rules described in the previous section,
extracting such discontinuous rules presents an ad-
ditional difficulty. Not only do we need to find
reorderings and extract the corresponding rules,
but we also have to decide which parts of the rule
should be replaced by the placeholder. Since it
is not always clear what is the best part to be re-
placed, we extract four different types of discon-
tinuous rules. Then we decide during decoding
which type of rules to use.
In a first step the reordering rule has to be found.
Since this is done in a different way than for the
continuous one, we will first describe it in detail.
Like the continuous rules, the discontinuous ones
are extracted from a word aligned corpus, whose
source side is annotated with POS tags. Then the
source side is scanned for reorderings. This is
done by comparing the alignment points ai and
ai+1 of two consecutive words. We found a re-
ordering if the target words aligned to fi and fi+1
are in a different order than the source words. In
our case the target word eai+1 has to precede the
target word eai . More formally said, we check the
following condition:
ai > ai+1 (1)
In Figure 1 an example with an automatically
generated alignment is given. There, for example,
a reordering can be found at the position of the
word ?Kenntnis?.
Since we only check the links of consecutive
words, we may miss some reorderings where there
is an unaligned word between the words with a
Figure 1: Example training sentence used to ex-
tract reordering rules
crossing link. However, in this case it is not clear
where to place the unaligned word, so we do not
extract rules from such a reordering.
So now we have found a reordering and also
the border between the left and right part of the
reordering. To be able to extract a rule for this
reordering we need to find the beginning of the
left and the end of the right part. This is done
by searching for the last word before and the first
word after the reordering. In the given example,
the left part is ?ihre Bereitschaft zur Kenntnis? and
the right part would be ?genommen?. As shown in
the figure, the words of the first part have to be
aligned to target words that follow the target word
aligned to the first word of the right part. Oth-
erwise, they would not be part of the reordering.
Consequently, to find the first word that is not part
of the reordering, we search for the first word be-
fore the word fi+1 that is aligned to the word eai+1
or to a target word before this word. More for-
mally, we search for the word fj that satisfies the
following condition:
j = argmaxl<i al ? ai+1 (2)
The first word after the reordering is found in the
same way. Formally, we search for the word fk
satisfying the condition:
k = argmaxl>i+1 al ? ai (3)
In our example, we now can extract the fol-
lowing reordering rule: ihre Bereitschaft zur
Kenntnis genommen ? genommen ihre Bere-
itschaft zur Kenntnis. In general, we will
extract the rule: fj+1 . . . fifi+1 . . . fk?1 ?
fi+1 . . . fk?1fj+1 . . . fi
208
An additional problem are unaligned words af-
ter fj and before fk. For these words it is not clear
if they are part of the reordering or not. There-
fore, we will include or exclude them depending
on the type of rule we extract. To be able to write
the rules in a easier way let fj? be the first word
following fj that is aligned and fk? the last word
before fk.
After extracting the reordering rule, we need to
replace some parts of the rule by a placeholder to
obtain more general rules. As described before, it
is not directly clear which part of the rule should
be replaced and therefore, we extract four different
types of rules.
In the reordering, there is always a left part, in
our example ihre Bereitschaft zur Kenntnis, and
a right part (genommen). So we can either re-
place the left or the right part of the reordering by
a placeholder. One could argue that always the
longer sequence should be replaced, since that is
more intuitive, but to lose no information we just
extract both types of rules. Later we will see that
depending on the language pair, one or the other
type will generalize better. In the evaluation part
the different types will be referred to as Left and
Right rules.
Furthermore, not the whole part has to be re-
placed. It can be argued that the first or last word
of the part is important to characterize the reorder-
ing and should therefore not be replaced. For each
of the types described before, we extract two dif-
ferent sub-types of rules, which leads altogether to
four different types of rules.
Let us first have a look at the types where we
replace the left part. If we replace the whole part,
in the example we would get the following rule: *
VVPP ? VVPP *. This would lead to problems
during rule application. Since the rule begins with
a placeholder, it is not clear where the matching
should start. Therefore, we also include the last
word before the reordering into the rule and can
now extract the following rule from the sentence:
VAFIN * VVPP ? VAFIN VVPP *. In general, we
extract the following rule to which we will refer as
Left All:
fj ? fi+1 . . . fk? ? fjfi+1 . . . fk??
As mentioned in the beginning, we extracted a
second sub-type of rule. This time, the first word
of the left part is not replaced. The reason can be
seen by looking at the reordered sequence. There,
the second part of the reordering is moved between
the last word before the reordering (fj) and the
first word of the first part (fj+1). In our example
this results in the following rule: VAFIN PPOSAT
* VVPP ? VAFIN VVPP PPOSAT * and in gen-
eral, we extract the rule (Left Part):
fjfj+1 ? fi+1 . . . fk? ? fjfi+1 . . . fk?fj+1 ?
If we replace the right part by a star, we sim-
ilarly get the following rule (Right All): PPOSAT
NN APPART NN * ? * PPOSAT NN APPART NN.
The other rule (Right Part) can not be extracted
from this example, since the right part has length
one. But in general we get the two rules:
fj? . . . fi ? fk?1fk ? ?fk?1fj+1 . . . fifk
fj? . . . fi ? fk ? ?fj? . . . fifk
Here we already see that the rules where the
first part is replaced result in typical reordering be-
tween the German and English language. The sec-
ond part of the verb is at the end of the sentence
in German, but in an English sentence it directly
follows the first part.
6 Rule Application
During the training of the system all reordering
rules are extracted from the parallel corpus in the
way described in the last section. The rules are
only used if they occur more often than a given
threshold value. In the experiments a threshold of
5 is used.
The rules are scored in the same way as the con-
tinuous rules were. The relative frequencies are
calculated as the number of times the rule was ex-
tracted divided by the number of times both parts
occur in one sentence.
Then, in the preprocessing step, continuous
rules as described in Section 4 and discontinuous
rules are applied to the source sentence. As in the
framework presented before, the rules are applied
only to the source sentence and not to the lattice.
Thus the rules cannot be applied recursively. For
the discontinuous rules the ?*? could match any
sequence of POS tags, but it has to consist of at
least one tag. If more than one rule can be ap-
plied to a sequence of POS tags and they generate
different output, all edges are added to the lattice.
If they generate the same sequence, only the rule
with the highest probability is applied.
209
In initial experiments we observed that some
rules can be applied very often to a sentence and
therefore the lattice gets quite big. Therefore, we
first check how often a rule can be applied to a
sentence. If this exceeds a given threshold, we do
not use this rule for this sentence. In these cases,
the rule will most likely not find a good reorder-
ing, but randomly shuffle the words. In the experi-
ments we use 5 as threshold, since this reduces the
lattices to a decent size.
These restrictions limit the number of reorder-
ings that have to be tested during decoding. But
if all reorderings that can be generated by the re-
maining rules would be inserted into the lattice,
the size of the lattice would still be too big to
be able to do efficient decoding. Therefore, only
rules with a probability greater than a given thresh-
old are used to reorder the source sentence. Since
the probabilities of the long-range reorderings are
quite small compared to those of the short-range
reorderings, we used two different thresholds.
7 Evaluation
We performed the experiments on the translation
task of the WMT?08 evaluation. Most of the ex-
periments were done on the German-English task,
but in the end also some results on German-French
and English-German are shown. The systems
were trained on the European Parliament Proceed-
ings (EPPS) and the News Commentary corpus.
For the German-French task we used the inter-
section of the parallel corpora from the German-
English and English-French task. The data was
preprocessed and we applied compound splitting
to the German corpus for the tasks translating from
German. Afterwards, the word alignment was
generated with the GIZA++-Toolkit and the align-
ments of the two directions were combined us-
ing the grow-diag-final-and heuristic. Then the
phrase tables were created where we performed
additional smoothing of the relative frequencies
(Foster et al, 2006). Furthermore, the phrase ta-
ble applied in the news task was adapted to this
domain. In addition, a 4-gram language model
was trained on both corpora. The rules were ex-
tracted using the POS tags generated by the Tree-
Tagger (Schmid, 1994). In the end a beam-search
decoder as described in Vogel (2003) was used
to optimize the weights using the MER-training
on the development sets provided for the different
task by the workshop. The systems were tested
Table 1: Evaluation of different Lattice sizes
generated by changing the short-range threshold
?short and long-range threshold ?long
?short ?long #Edges Dev Test
0.2 1 112K 24.57 27.25
0.1 1 203K 24.71 27.48
0.2 0.2 113K 24.70 27.51
0.2 0.1 121K 24.97 27.56
0.2 0.05 152K 25.28 27.80
0.1 0.1 212K 24.97 27.49
0.1 0.05 243K 25.12 27.81
on the test2007 set for the EPPS task and on the
nc-test2007 testset for the news task. For test set
translations the statistical significance of the re-
sults was tested using the bootstrap technique as
described in Zhang and Vogel (2004).
7.1 Lattice Creation
In a first group of experiments we analyzed the in-
fluence of the two thresholds that determine the
minimal probability of a rule that is used to insert
the reordering into the lattice. The experiments
were performed on the news task and used only the
long-range rules generated by the Part All rules.
The results are shown in Table 1 where ?short
is the threshold for the short-range reorderings
and ?long for the long-range reorderings. Con-
sequently, only paths were added that are gener-
ated by a short-range reordering rule that has a
probability greater than ?short or paths generated
by a long-range reordering rule with a minimum
probability of ?long. We used different thresholds
for both groups of rules since the probabilities of
long-range reorderings are in general lower.
The first two systems use no long-range reorder-
ings. Adding the long-range reorderings does im-
prove the translation quality and it makes sense to
add even all edges generated by rules with a prob-
ability of at least 0.05. Using this system, less
short-range reorderings are needed. The system
using the thresholds of 0.2 and 0.05 has a perfor-
mance nearly as good as the one using the thresh-
olds 0.1 and 0.05, but it needs fewer edges. If
long-range reordering is applied, fewer edges are
needed than in the case of using only short-range
reordering even though the translation quality is
better. Therefore, we used the thresholds 0.2 and
0.05 in the following experiments.
210
Figure 2: Most common long-range reordering rules of type Left Part
NN ADV * VAFIN ? NN VAFIN ADV *
VAFIN ART * VVPP ? VAFIN VVPP ART *
? ADV * PPER ? ? PPER ADV *
$, ART * VVINF PTKZU ? $, VVINF PTKZU ART *
PRELS ART * VVFIN ? PRELS VVFIN ART *
Figure 3: Most common long-range reordering rules of type Left All
PRELS * VAFIN ? PRELS VAFIN *
PRELS * VAFIN VVPP ? PRELS VAFIN VVPP *
PPER * VMFIN ? PPER VMFIN *
PRELS * VMFIN ? PRELS VMFIN *
VMFIN * VAINF ? VMFIN VAINF *
Table 2: Number of long-range reordering rules of
different types used to create the lattices
Type Left Right
Part 8079 1127
All 2470 509
Both 9223 1405
7.2 Rule Usage
We analyzed which long-range reordering rules
were used to build the lattices. First, we compared
the usage of the different types of rules. There-
fore, we counted the number of rules that were ap-
plied to the development set of 2000 sentences if
the thresholds 0.2 and 0.05 were used. The result-
ing numbers are shown in Table 2.
As it can be seen, the Left rules are more of-
ten used than the Right ones. This is what we
expected, since when translating from German to
English, the most important rules move the verb
to the left. And these rules should be more gen-
eral and therefore have a higher probability than
the rules that move the words preceding the verb
to the end of the sentence.
Next we analyzed which rules of the Left Part
ones are used most frequently. The five most fre-
quent rules are shown in Figure 2. The first, fourth
and fifth rule moves the verb more to the front,
as is often needed in English subordinate clauses.
The second one moves both parts of the verb to-
gether.
The third most frequent rule moves personal pro-
nouns to the front. In the English language the
Table 3: Translation results for the German-
English task using different rule types (BLEU)
Type EPPS NEWS
Dev Test Dev Test
Left Part 26.99 29.16 25.12 27.88
Right Part 26.69 28.73 24.76 27.28
Right/Left Part 26.99 28.96 25.06 27.69
Left All 26.77 28.76 24.37 26.56
Left Part/All 26.99 29.32 25.38 27.86
All 27.02 29.14 25.20 27.63
subject has to be always at the front. In contrast,
in German the word order is not that strict and the
subject can appear later.
We have done the same for the Left All rules.
The rules are shown in Figure 3. In this type of
rule the five most frequent rules all try to move the
verb more to the front of the sentence. In the last
case both parts of the verb are put together.
7.3 Rule Types
In a next group of experiments we evaluated the
performance of the different rule types. In Table 3
the translation performance of systems using dif-
ferent rule types is shown. The experiments were
carried out on the EPPS task as well as on the
NEWS task.
First it can be seen that the Left rules perform
better than the Right rules. This is not surpris-
ing, since they better describe how to reorder from
German to English and because they are more of-
ten used in the lattice. If both types are used this
211
Table 4: Summary of translation results for the
German-English tasks (BLEU)
System EPPS NEWS
Dev Test Dev Test
Baseline 25.47 27.24 23.40 25.90
Short 26.77 28.54 24.73 27.48
Long 26.99 29.32 25.38 27.86
lowers the performance a little. So if it is clear
which type explains the reordering better, only this
type should be used, but if that is not possible us-
ing both types can still help.
If both types of rules are compared, it can be
seen that Part rules seem to have a more positive
influence than All ones. The reason for this may be
that the Part rules can also be applied more often
than the rules of the other type. Using the com-
bination of both types of rules, the performance is
better on one task and equally good on the other
task. Consequently, we used the combination of
both types in the remaining experiments.
7.4 German-English
The results on the German-English task are sum-
marized in Table 4. The long-range reorderings
could improve the performance by 0.8 and 0.4
BLEU points on the different tasks compared to
a system applying only short-range reorderings.
These improvements are significant at a level of
5%.
We also analyzed the influence of tagging er-
rors. Therefore, we tagged every word of the test
sentence with the tag that this word is mostly as-
signed to in the training corpus. If the word does
not occur in the training corpus, it was tagged as a
noun. This results in different tags for 5% of the
words and a BLEU score of 27.68 on the NEWS
test set using long-range reorderings. So the trans-
lation quality drops by about 0.2 BLEU points, but
it is still better than the system using only short-
range reorderings.
In Figure 4 example translations of the baseline
system, the system modeling only short-range re-
orderings and the system using also long-range re-
orderings rules are shown. The part of the sen-
tences that needs long-range reorderings is always
underlined.
In the first two examples the verbal phrase con-
sists of two parts and the German one is splitted.
In these cases, it was impossible for the short-
Table 5: Translation results for the German-
French translation task (BLEU)
System EPPS NEWS
Dev Test Dev Test
Baseline 25.86 27.05 17.90 18.52
Short 27.02 28.06 18.59 19.99
Long 27.27 28.61 19.10 20.11
range reordering model to move the second part of
the verb to the front so that it could be translated
correctly. In one case this leads to a selection of a
phrase pair that removes the verb from the transla-
tion. Thus it is hard to understand the meaning of
the sentence.
In the other two examples the verb of the subor-
dinate clause has to be moved from the last posi-
tion in the German sentence to the second position
in the English one. This is again only possible us-
ing the long-range reordering rules. Furthermore,
if these rules are not used, it is possible that the
verb will be not translated at all as in the last ex-
ample.
7.5 German-French
We also performed similar experiments on the
German-French task. Since the type of reordering
needed for this language pair is similar to the one
used in the German-English task, we used also the
Left rules in the long-range reorderings. As it can
be seen in Table 5, the long-range reordering rules
could also help to improve the translation perfor-
mance for this language pair. The improvement on
the EPPS task is significant at a level of 5%.
7.6 English-German
In a last group of experiments we applied the same
approach also to the English-German translation
task. In this case the verb has to be moved to
the right, so that we used the Right rules for the
long-range reorderings. Looking at the rule us-
age of the different type of rules, the picture was
quite promising. This time the Right rules could
be applied more often and the Left ones only a few
times. But if we look at the results as shown in Ta-
ble 6, the long-range reorderings do not improve
the performance. We will investigate the reasons
for this in future work.
212
Figure 4: Example translation from German to English using different type of rules
Source: Diese Ma?nahmen werden als eine Art Wiedergutmachung fu?r fru?her begangenes
Unrecht angesehen .
Baseline: these measures will as a kind of compensation for once injustice done .
Short: these measures will as a kind of compensation for once injustice done .
Long: these measures will be seen as a kind of compensation for once injustice done .
Source: Das wird mit derart unterschiedlichen Mitgliedern unmo?glich sein .
Baseline: this will with such different impossible .
Short: this will with such different impossible .
Long: this will be impossible to such different members .
Source: Er braucht die Unterstu?tzung derer , die an den Markt und an die Gleichbehandlung
aller glauben .
Baseline: he needs the support of those who market and the equal treatment of all believe .
Short: it needs the support of those who in the market and the equal treatment of all believe .
Long: it needs the support of those who believe in the market and the equal treatment of all .
Source: .., da? sie das Einwanderungsproblem als politischen Hebel benutzen .
Baseline: .. that they the immigration problem as a political lever .
Short: .. that the problem of immigration as a political lever .
Long: .. that they use the immigration problem as a political lever .
Table 6: Translation results for the English-
German translation task (BLEU)
System EPPS NEWS
Dev Test Dev Test
Baseline 18.93 2072 16.31 17.91
Short 19.49 21.56 17.13 18.31
Long 19.56 21.33 16.93 18.15
8 Conclusion
We have presented a new method to model long-
range reorderings in statistical machine transla-
tion. This method extends a framework based
on extracting POS-based reordering rules from an
aligned parallel corpus by adding discontinuous
reordering rules. Allowing rules with gaps cap-
tures very long-range reorderings while avoiding
the data sparseness problem of very long continu-
ous reordering rules.
The extracted rules are used to generate a word
lattice with different possible reorderings of the
source sentence in a preprocessing step prior to de-
coding. Placing various restrictions on the appli-
cation of the rules keeps the lattice small enough
for efficient decoding. Compared to a baseline
system that only uses continuous reordering rules,
applying additional discontinuous rules improved
the translation performance on a German-English
translation task significantly by up to 0.8 BLEU
points.
In contrast to approaches like Collins et al
(2005) and Popovic? and Ney (2006), the rules are
created in a data-driven way and not manually. It
was therefore easily possible to transfer this ap-
proach to the German-French translation task, and
we showed that we could improve the translation
quality for this language pair as well. Further-
more, this approach needs only the POS informa-
tion and no syntax tree. Thus, if we use the ap-
proximation for the tags as described before, the
approach could also easily be integrated into a
real-time translation system.
An unsolved problem is still why this ap-
proach does not improve the results of the English-
German translation task. An explanation might be
that here the reordering problem is even more dif-
ficult, since the German word order is very free.
Acknowledgments
This work was partly supported by Quaero Pro-
gramme, funded by OSEO, French State agency
for innovation.
References
Adam L. Berger, Vincent J. Della Pietra, and Stephen
A. Della Pietra. 1996. A Maximum Entropy Ap-
213
proach to Natural Language Processing. Compua-
tional Linguistics, 22(1):39?71.
Peter F. Brown, Stephen A. Della Pietra, Vincent
J. Della Pietra, and Robert L. Mercer. 1993. The
Mathematics of Statistical Machine Translation: Pa-
rameter Estimation. Computational Linguistics,
19(2):263?311.
Boxing Chen, Mauro Cettolo, and Marcello Federico.
2006. Reordering Rules for Phrase-based Statisti-
cal Machine Translation. In International Workshop
on Spoken Language Translation (IWSLT 2006), Ky-
oto, Japan.
Michael Collins, Philipp Koehn, and Ivona Kuc?erova?.
2005. Clause Restructuring for Statistical Machine
Translation. In Proc. of the 43rd Annual Meeting on
Association for Computational Linguistics (ACL),
pages 531?540.
Marta R. Costa-jussa` and Jose? A. R. Fonollosa. 2006.
Statistical Machine Reordering. In Conference on
Empirical Methods on Natural Language Process-
ing (EMNLP 2006), Sydney, Australia.
Nizar Crego and Nizar Habash. 2008. Using Shal-
low Syntax Information to Improve Word Align-
ment and Reordering for SMT. In 46th Annual
Meeting of the Association for Computational Lin-
guistics: Human Language Technologies (ACL-08:
HLT), Columbus, Ohio, USA.
George Foster, Roland Kuhn, and Howard Johnson.
2006. Phrasetable Smoothing for Statistical Ma-
chine Translation. In Conference on Empirical
Methods in Natural Language Processing (EMNLP
2006), Sydney, Australia.
Philipp Koehn, Amittai Axelrod, Alexandra B. Mayne,
Chris Callison-Burch, Miles Osborne, and David
Talbot. 2005. Edinburgh System Description for
the 2005 IWSLT Speech Translation Evaluation. In
IWSLT, Pittsburgh, PA, USA.
Franz Josef Och and Herman Ney. 2000. Improved
Statistical Alignment Models. In 38th Annual Meet-
ing of the Association for Computational Linguistics
(ACL 2000), Hong Kong.
Franz J. Och, Daniel Gildea, Sanjeev P. Khudan-
pur, Anoop Sarkar, Kenji Yamada, Alexander
Fraser, Shankar Kumar, Libin Shen, David A.
Smith, Katherine Eng, Viren Jain, Zhen Jin, and
Dragomir R. Radev. 2004. A Smorgasboard of Fea-
tures for Statistical Machine Translation. In Human
Language Technology Conference and the 5th Meet-
ing of the North American Association for Com-
putational Linguistics (HLT-NAACL 2004), Boston,
USA.
Maja Popovic? and Hermann Ney. 2006. POS-based
Word Reorderings for Statistical Machine Transla-
tion. In International Conference on Language Re-
sources and Evaluation (LREC 2006), Genoa, Italy.
Kay Rottmann and Stephan Vogel. 2007. Word Re-
ordering in Statistical Machine Translation with a
POS-Based Distortion Model. In TMI, Sko?vde,
Sweden.
Helmut Schmid. 1994. Probabilistic Part-of-Speech
Tagging Using Decision Trees. In International
Conference on New Methods in Language Process-
ing, Manchester, UK.
Libin Shen, Anoop Sarkar, and Franz Och. 2004.
Discriminative Reranking for Machine Translation.
In Human Language Technology Conference and
the 5th Meeting of the North American Association
for Computational Linguistics (HLT-NAACL 2004),
Boston, USA.
Christoph Tillmann and Tong Zhang. 2005. A Local-
ized Prediction Model for Statistical Machine Trans-
lation. In 43rd Annual Meeting of the Association
for Computational Linguistics (ACL 2005), Ann Ar-
bor, Michigan, USA.
Stephan Vogel, Ying Zhang, Fei Huang, Alicia Tribble,
Ashish Venogupal, Bing Zhao, and Alex Waibel.
2003. The CMU Statistical Translation System. In
MT Summit IX, New Orleans, LA, USA.
Stephan Vogel. 2003. SMT Decoder Dissected: Word
Reordering. In Int. Conf. on Natural Language
Processing and Knowledge Engineering, Beijing,
China.
Yeyi Wang and Alex Waibel. 1998. Fast Decoding
for Statistical Machine Translation. In ICSLP?98,
Sydney, Australia.
Dekai Wu. 1996. A Polynomial-time Algorithm for
Statistical Machine Translation. In ACL-96: 34th
Annual Meeting of the Assoc. for Computational
Linguistics, Santa Cruz, CA, USA, June.
Kenji Yamada and Kevin Knight. 2000. A Syntax-
based Statistical Translation Model. In 38th Annual
Meeting of the Association for Computational Lin-
guistics (ACL 2000), Hong Kong.
Richard Zens and Hermann Ney. 2003. A Compar-
ative Study on Reordering Constraints in Statistical
Machine Translation. In 41st Annual Meeting of the
Association for Computational Linguistics (ACL),
pages 192?202, Sapporo, Japan.
Ying Zhang and Stephan Vogel. 2004. Measuring
Confidence Intervals for mt Evaluation Metrics. In
TMI 2004, Baltimore, MD, USA.
Yuqi Zhang, Richard Zens, and Hermann Ney. 2007.
Chunk-Level Reordering of Source Language Sen-
tences with Automatically Learned Rules for Sta-
tistical Machine Translation. In HLT-NAACL Work-
shop on Syntax and Structure in Statistical Transla-
tion, Rochester, NY, USA.
214
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 43?47,
Gothenburg, Sweden, April 26-30 2014.
c?2014 Association for Computational Linguistics
Tight Integration of Speech Disfluency Removal into SMT
Eunah Cho Jan Niehues
Interactive Systems Lab
Institute of Anthropomatics
Karlsruhe Institute of Technology, Germany
{eunah.cho,jan.niehues,alex.waibel}@kit.edu
Alex Waibel
Abstract
Speech disfluencies are one of the main
challenges of spoken language processing.
Conventional disfluency detection systems
deploy a hard decision, which can have
a negative influence on subsequent appli-
cations such as machine translation. In
this paper we suggest a novel approach
in which disfluency detection is integrated
into the translation process.
We train a CRF model to obtain a disflu-
ency probability for each word. The SMT
decoder will then skip the potentially dis-
fluent word based on its disfluency prob-
ability. Using the suggested scheme, the
translation score of both the manual tran-
script and ASR output is improved by
around 0.35 BLEU points compared to the
CRF hard decision system.
1 Introduction
Disfluencies arise due to the spontaneous nature
of speech. There has been a great deal of effort to
detect disfluent words, remove them (Johnson and
Charniak, 2004; Fitzgerald et al., 2009) and use
the cleaned text for subsequent applications such
as machine translation (MT) (Wang et al., 2010;
Cho et al., 2013).
One potential drawback of conventional ap-
proaches is that the decision whether a token is
a disfluency or not is a hard decision. For an
MT system, this can pose a severe problem if the
removed token was not in fact a disfluency and
should have been kept for the correct translation.
Therefore, we pass the decision whether a word is
part of a disfluency or not on to the translation sys-
tem, so that we can use the additional knowledge
available in the translation system to make a more
reliable decision. In order to limit the complexity,
the search space is pruned prior to decoding and
represented in a word lattice.
2 Related Work
Disfluencies in spontaneous speech have been
studied from various points of view. In the noisy
channel model (Honal and Schultz, 2003), it is
assumed that clean text without any disfluencies
has passed through a noisy channel. The clean
string is retrieved based on language model (LM)
scores and five additional models. Another noisy
channel approach involves a phrase-level statisti-
cal MT system, where noisy tokens are translated
into clean tokens (Maskey et al., 2006). A tree ad-
joining grammar is combined with this noisy chan-
nel model in (Johnson and Charniak, 2004), using
a syntactic parser to build an LM.
Fitzgerald et al. (2009) present a method to de-
tect speech disfluencies using a conditional ran-
dom field (CRF) with lexical, LM, and parser
information features. While previous work has
been limited to the postprocessing step of the au-
tomatic speech recogition (ASR) system, further
approaches (Wang et al., 2010; Cho et al., 2013)
use extended CRF features or additional models
to clean manual speech transcripts and use them
as input for an MT system.
While ASR systems use lattices to encode hy-
potheses, lattices have been used for MT systems
with various purposes. Herrmann et al. (2013)
use lattices to encode different reordering variants.
Lattices have also been used as a segmentation tac-
tic for compound words (Dyer, 2009), where the
segmentation is encoded as input in the lattice.
One of the differences between our work and
previous work is that we integrate the disfluency
removal into an MT system. Our work is not lim-
ited to the preprocessing step of MT, instead we
use the translation model to detect and remove dis-
fluencies. Contrary to other systems where detec-
tion is limited on manual transcripts only, our sys-
43
tem shows translation performance improvements
on the ASR output as well.
3 Tight Integration using Lattices
In this chapter, we explain how the disfluency re-
moval is integrated into the MT process.
3.1 Model
The conventional translation of texts from sponta-
neous speech can be formulated as
e? = argmax
e
p(e| argmax
f
c
p(f
c
|f)) (1)
with
p(f
c
|f) =
I
?
i=1
p(c
i
|f
i
) (2)
where f
c
denotes the clean string
f
c
= {f
1
, . . . , f
I
| c
i
= clean} (3)
for the disfluency decision class c of each token.
c ?
{
clean
disfluent
(4)
Thus, using the conventional models, disfluency
removal is applied to the original, potentially noisy
string in order to obtain the cleaned string first.
This clean string is then translated.
The potential drawback of a conventional
speech translation system is caused by the rough
estimation in Equation 1, as disfluency removal
does not depend on maximizing the translation
quality itself. For example, we can consider the
sentence Use what you build, build what you use.
Due to its repetitive pattern in words and structure,
the first clause is often detected as a disfluency us-
ing automatic means. To avoid this, we can change
the scheme how the clean string is chosen as fol-
lows:
e? = argmax
e,f
c
(p(e|f
c
) ? p(f
c
|f)) (5)
This way a clean string which maximizes the
translation quality is chosen. Thus, no instant de-
cision is made whether a token is a disfluency or
not. Instead, the disfluency probability of the to-
ken will be passed on to the MT process, using
the log linear combination of the probabilities as
shown in Equation 5.
In this work, we use a CRF (Lafferty et al.,
2001) model to obtain the disfluency probability
of each token.
Since there are two possible classes for each to-
ken, the number of possible clean sentences is ex-
ponential with regard to the sentence length. Thus,
we restrict the search space by representing only
the most probable clean source sentences in a word
lattice.
3.2 CRF Model Training
In order to build the CRF model, we used the
open source toolkit CRF++ (Kudoh, 2007). As
unigram features, we use lexical and LM features
adopted from Fitzgerald et al. (2009), and addi-
tional semantics-based features discussed in (Cho
et al., 2013). In addition to the unigram features,
we also use a bigram feature to model first-order
dependencies between labels.
We train the CRF with four classes; FL for filler
words, RC for (rough) copy, NC for non-copy and
0 for clean tokens. The class FL includes obvious
filler words (e.g. uh, uhm) as well as other dis-
course markers (e.g. you know, well in English).
The RC class covers identical or roughly simi-
lar repetitions as well as lexically different words
with the same meaning. The NC class represents
the case where the speaker changes what to speak
about or reformulates the sentence and restarts the
speech fragments. The disfluency probability P
d
of each token is calculated as the sum of probabil-
ities of each class.
3.3 Lattice Implementation
We construct a word lattice which encodes long-
range reordering variants (Rottmann and Vogel,
2007; Niehues and Kolss, 2009). For translation
we extend this so that potentially disfluent words
can be skipped. A reordering lattice of the ex-
ample sentence Das sind die Vorteile, die sie uh
die sie haben. (En.gls: These are the advantages,
that you uh that you have.) is shown in Figure 1,
where words representing a disfluency are marked
in bold letters. In this sentence, the part die sie
uh was manually annotated as a disfluency, due to
repetition and usage of a filler word.
Table 1 shows the P
d
obtained from the CRF
model for each token. As expected, the words die
sie uh obtain a high P
d
from the CRF model.
In order to provide an option to avoid translating
a disfluent word, a new edge which skips the word
is introduced into the lattice when the word has a
higher P
d
than a threshold ?. During decoding the
importance of this newly introduced edge is opti-
mized by weights based on the disfluency proba-
44
0 1 das 2 sie 3 sie 4 sind 5 das 6 das 7 die 8 sind 9 sind 10 Vorteile 11 die 12 die 13 , 14 Vorteile 15 Vorteile 16 die 17 , 18 , 19 sie 20
 haben  die 21 die 22 uh 23
 sie 
24 sie 25 die 26
 uh 
27 uh 28 sie 29 haben 30
 die  die 31 haben  sie  sie 32 . 
Figure 1: Reordering lattice before adding alternative clean paths for an exemplary sentence
0 1 das 2 sie 3 sie 5 das 4
 sind  das 6 das 7
 die 
8 sind 9 sind 
10 Vorteile 
11 die 12 die 
13 , 
14 Vorteile 15 Vorteile 
16 die 19 haben 26 die 17 , 18 , 
 haben 20 sie  die  die  die 21 die 30 die 
22 sie 28 die 23 uh  die 
24 sie  die 
25 uh  die  die 
27 uh  die 
 die 
29 haben  sie  die 
31
 sie  sie  haben 32 . 
Figure 2: Extended lattice with alternative clean paths for an exemplary sentence
das 0.000732 sie 0.953126
sind 0.004445 uh 0.999579
die 0.013451 die 0.029010
Vorteile 0.008183 sie 0.001426
, 0.035408 haben 0.000108
die 0.651642 . 0.000033
Table 1: Disfluency probability of each word
bility and transition probability. The extended lat-
tice for the given sentence with ? = 0.5 is shown
in Figure 2, with alternative paths marked by a
dotted line. The optimal value of ? was manually
tuned on the development set.
4 System Description
The training data for our MT system consists of
1.76 million sentences of German-English paral-
lel data. Parallel TED talks
1
are used as in-domain
data and our translation models are adapted to the
domain. Before training, we apply preprocess-
ing such as text normalization, tokenization, and
smartcasing. Additionally, German compound
words are split.
To build the phrase table we use the Moses
package (Koehn et al., 2007). An LM is trained
on 462 million words in English using the SRILM
Toolkit (Stolcke, 2002). In order to extend source
word context, we use a bilingual LM (Niehues et
al., 2011). We use an in-house decoder (Vogel,
2003) with minimum error rate training (Venu-
gopal et al., 2005) for optimization.
For training and testing the CRF model, we use
61k annotated words of manual transcripts of uni-
1
http://www.ted.com
versity lectures in German. For tuning and testing
the MT system, the same data is used along with
its English reference translation. In order to make
the best use of the data, we split it into three parts
and perform three-fold cross validation. There-
fore, the train/development data consists of around
40k words, or 2k sentences, while the test data
consists of around 20k words, or 1k sentences.
5 Experiments
In order to compare the effect of the tight inte-
gration with other disfluency removal strategies,
we conduct different experiments on manual tran-
scripts as well as on the ASR output.
5.1 Manual Transcripts
As a baseline for manual transcripts, we use
the whole uncleaned data for development and
test. For ?No uh?, we remove the obvious filler
words uh and uhm manually. In the CRF-hard
experiment, the token is removed if the label
output of the CRF model is a disfluency class.
The fourth experiment uses the tight integration
scheme, where new source paths which jump over
the potentially noisy words are inserted based on
the disfluency probabilities assigned by the CRF
model. In the next experiments, this method is
combined with other aforementioned approaches.
First, we apply the tight integration scheme after
we remove all obvious filler words. In the next
experiment, we first remove all words whose P
d
is higher than 0.9 as early pruning and then apply
the tight integration scheme. In a final experiment,
we conduct an oracle experiment, where all words
annotated as a disfluency are removed.
45
5.2 ASR Output
The same experiments are applied to the ASR out-
put. Since the ASR output does not contain re-
liable punctuation marks, there is a mismatch be-
tween the training data of the CRF model, which is
manual transcripts with all punctuation marks, and
the test data. Thus, we insert punctuation marks
and augment sentence boundaries in the ASR out-
put using the monolingual translation system (Cho
et al., 2012). As the sentence boundaries differ
from the reference translation, we use the Leven-
shtein minimum edit distance algorithm (Matusov
et al., 2005) to align hypothesis for evaluation.
No optimization is conducted, but the scaling fac-
tors obtained when using the correponding setup
of manual transcripts are used for testing.
5.3 Results
Table 2 shows the results of our experiments. The
scores are reported in case-sensitive BLEU (Pap-
ineni et al., 2002).
System Dev Text ASR
Baseline 23.45 22.70 14.50
No uh 25.09 24.04 15.10
CRF-hard 25.32 24.50 15.15
Tight int. 25.30 24.59 15.19
No uh + Tight int. 25.41 24.68 15.33
Pruning + Tight int. 25.38 24.84 15.51
Oracle 25.57 24.87 -
Table 2: Translation results for the investigated
disfluency removal strategies
Compared to the baseline where all disfluen-
cies are kept, the translation quality is improved
by 1.34 BLEU points for manual transcripts by
simply removing all obvious filler words. When
we take the output of the CRF as a hard deci-
sion, the performance is further improved by 0.46
BLEU points. When using the tight integration
scheme, we improve the translation quality around
0.1 BLEU points compared to the CRF-hard deci-
sion. The performance is further improved by re-
moving uh and uhm before applying the tight inte-
gration scheme. Finally the best score is achieved
by using the early pruning coupled with the tight
integration scheme. The translation score is 0.34
BLEU points higher than the CRF-hard decision.
This score is only 0.03 BLEU points less than the
oracle case, without all disfluencies.
Experiments on the ASR output also showed a
considerable improvement despite word errors and
consequently decreased accuracy of the CRF de-
tection. Compared to using only the CRF-hard de-
cision, using the coupled approach improved the
performance by 0.36 BLEU points, which is 1.0
BLEU point higher than the baseline.
System Precision Recall
CRF-hard 0.898 0.544
Pruning + Tight int. 0.937 0.521
Table 3: Detection performance comparison
Table 3 shows a comparison of the disfluency
detection performance on word tokens. While re-
call is slightly worse for the coupled approach,
precision is improved by 4% over the hard deci-
sion, indicating that the tight integration scheme
decides more accurately. Since deletions made by
a hard decision can not be recovered and losing a
meaningful word on the source side can be very
critical, we believe that precision is more impor-
tant for this task. Consequently we retain more
words on the source side with the tight integration
scheme, but the numbers of word tokens on the
translated target side are similar. The translation
model is able to leave out unnecessary words dur-
ing translation.
6 Conclusion
We presented a novel scheme to integrate disflu-
ency removal into the MT process. Using this
scheme, it is possible to consider disfluency prob-
abilities during decoding and therefore to choose
words which can lead to better translation perfor-
mance. The disfluency probability of each token
is obtained from a CRF model, and is encoded in
the word lattice. Additional edges are added in the
word lattice, to bypass the words potentially rep-
resenting speech disfluencies.
We achieve the best performance using the tight
integration method coupled with early pruning.
This method yields an improvement of 2.1 BLEU
points for manual transcripts and 1.0 BLEU point
improvement over the baseline for ASR output.
Although the translation of ASR output is im-
proved using the suggested scheme, there is still
room to improve. In future work, we would like to
improve performance of disfluency detection for
ASR output by including acoustic features in the
model.
46
Acknowledgements
The research leading to these results has received
funding from the European Union Seventh Frame-
work Programme (FP7/2007-2013) under grant
agreement n
?
287658.
References
Eunah Cho, Jan Niehues, and Alex Waibel. 2012.
Segmentation and Punctuation Prediction in Speech
Language Translation using a Monolingual Trans-
lation System. In Proceedings of the Interna-
tional Workshop for Spoken Language Translation
(IWSLT), Hong Kong, China.
Eunah Cho, Thanh-Le Ha, and Alex Waibel. 2013.
CRF-based Disfluency Detection using Seman-
tic Features for German to English Spoken Lan-
guage Translation. In Proceedings of the Interna-
tional Workshop for Spoken Language Translation
(IWSLT), Heidelberg, Germany.
Chris Dyer. 2009. Using a Maximum Entropy Model
to Build Segmentation Lattices for MT. In Proceed-
ings of Human Language Technologies: The 2009
Annual Conference of the North American Chap-
ter of the Association for Computational Linguis-
tics, Boulder, Colorado, USA, June. Association for
Computational Linguistics.
Erin Fitzgerald, Kieth Hall, and Frederick Jelinek.
2009. Reconstructing False Start Errors in Sponta-
neous Speech Text. In Proceedings of the European
Association for Computational Linguistics (EACL),
Athens, Greece.
Teresa Herrmann, Jan Niehues, and Alex Waibel.
2013. Combining Word Reordering Methods on
different Linguistic Abstraction Levels for Statisti-
cal Machine Translation. In Proceedings of the Sev-
enth Workshop on Syntax, Semantics and Structure
in Statistical Translation, Altanta, Georgia, USA,
June. Association for Computational Linguistics.
Matthias Honal and Tanja Schultz. 2003. Correction of
Disfluencies in Spontaneous Speech using a Noisy-
Channel Approach. In Eurospeech, Geneva.
Mark Johnson and Eugene Charniak. 2004. A TAG-
based Noisy Channel Model of Speech Repairs. In
Proceedings of the Association for Computational
Linguistics (ACL).
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
Source Toolkit for Statistical Machine Translation.
In Proceedings of the Association for Computational
Linguistics (ACL), Demonstration Session, Prague,
Czech Republic, June.
Taku Kudoh. 2007. CRF++: Yet Another CRF
Toolkit.
John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. Conditional Random Fields: Prob-
abilitic Models for Segmenting and Labeling Se-
quence Data. In ICML, Massachusetts, USA.
Sameer Maskey, Bowen Zhou, and Yuqing Gao. 2006.
A Phrase-Level Machine Translation Approach for
Disfluency Detection using Weighted Finite State
Tranducers. In Interspeech, Pittsburgh, PA.
Evgeny Matusov, Gregor Leusch, Oliver Bender, and
Herrmann Ney. 2005. Evaluating Machine Trans-
lation Output with Automatic Sentence Segmenta-
tion. In Proceedings of the International Workshop
on Spoken Language Translation (IWSLT), Boulder,
Colorado, USA, October.
Jan Niehues and Muntsin Kolss. 2009. A POS-Based
Model for Long-Range Reorderings in SMT. In
Proceedings of the 4th Workshop on Statistical Ma-
chine Translation, Athens, Greece.
Jan Niehues, Teresa Herrmann, Stephan Vogel, and
Alex Waibel. 2011. Wider Context by Using Bilin-
gual Language Models in Machine Translation. In
Proceedings of the 6th Workshop on Statistical Ma-
chine Translation, Edinburgh, UK.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic
Evaluation of Machine Translation. Technical Re-
port RC22176 (W0109-022), IBM Research Divi-
sion, T. J. Watson Research Center.
Kay Rottmann and Stephan Vogel. 2007. Word Re-
ordering in Statistical Machine Translation with a
POS-Based Distortion Model. In TMI, Sk?ovde,
Sweden.
Andreas Stolcke. 2002. SRILM ? An Extensible Lan-
guage Modeling Toolkit. Denver, Colorado, USA.
Ashish Venugopal, Andreas Zollman, and Alex Waibel.
2005. Training and Evaluation Error Minimization
Rules for Statistical Machine Translation. In WPT-
05, Ann Arbor, MI.
Stephan Vogel. 2003. SMT Decoder Dissected: Word
Reordering. In Int. Conf. on Natural Language
Processing and Knowledge Engineering, Beijing,
China.
Wen Wang, Gokhan Tur, Jing Zheng, and Necip Fazil
Ayan. 2010. Automatic Disfluency Removal for Im-
proving Spoken Language Translation. In Interna-
tional Conference on Acoustics, Speech, and Signal
Processing (ICASSP).
47
Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 138?142,
Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational Linguistics
The Karlsruhe Institute for Technology Translation System for the
ACL-WMT 2010
Jan Niehues, Teresa Herrmann, Mohammed Mediani and Alex Waibel
Karlsruhe Instiute of Technolgy
Karlsruhe, Germany
firstname.lastname@kit.edu
Abstract
This paper describes our phrase-based Sta-
tistical Machine Translation (SMT) sys-
tem for the WMT10 Translation Task. We
submitted translations for the German to
English and English to German transla-
tion tasks. Compared to state-of-the-art
phrase-based systems we preformed addi-
tional preprocessing and used a discrim-
inative word alignment approach. The
word reordering was modeled using POS
information and we extended the transla-
tion model with additional features.
1 Introduction
In this paper we describe the systems that we
built for our participation in the Shared Trans-
lation Task of the ACL 2010 Joint Fifth Work-
shop on Statistical Machine Translation and Met-
ricsMATR. Our translations are generated using
a state-of-the-art phrase-based translation system
and applying different extensions and modifica-
tions including Discriminative Word Alignment,
a POS-based reordering model and bilingual lan-
guage models using POS and stem information.
Depending on the source and target languages,
the proposed models differ in their benefit for the
translation task and also expose different correl-
ative effects. The Sections 2 to 4 introduce the
characteristics of the baseline system and the sup-
plementary models. In Section 5 we present the
performance of the system variants applying the
different models and chose the systems used for
creating the submissions for the English-German
and German-English translation task. Section 6
draws conclusions and suggests directions for fu-
ture work.
2 Baseline System
The baseline systems for the translation directions
German-English and English-German are both de-
veloped using Discriminative Word Alignment
(Niehues and Vogel, 2008) and the Moses Toolkit
(Koehn et al, 2007) for extracting phrase pairs
and generating the phrase table from the discrimi-
native word alignments. The difficult reordering
between German and English was modeled us-
ing POS-based reordering rules. These rules were
learned using a word-aligned parallel corpus. The
POS tags for the reordering models are generated
using the TreeTagger (Schmid, 1994) for all lan-
guages.
Translation is performed by the STTK Decoder
(Vogel, 2003) and all systems are optimized to-
wards BLEU using Minimum Error Rate Training
as proposed in Venugopal et al (2005).
2.1 Training, Development and Test Data
We used the data provided for the WMT for train-
ing, optimizing and testing our systems: Our
training corpus consists of Europarl and News
Commentary data, for optimization we use new-
stest2008 as development set and newstest2009 as
test set.
The baseline language models are trained on
the target language part of the Europarl and News
Commentary corpora. Additional, bigger lan-
guage models were trained on monolingual cor-
pora. For both systems the News corpus was used
while an English language model was also trained
on the even bigger Gigaword corpus.
2.2 Preprocessing
The training data was preprocessed before used for
training. In this step different normalizations were
done like mapping different types of quotes. In
the end the first word of every sentence was smart-
cased.
138
For the German text, additional preprocessing
steps were applied. First, the older German data
uses the old German orthography whereas the
newer parts of the corpus use the new German
orthography. We tried to normalize the text by
converting the whole text to the new German or-
thography. In a first step, we search for words that
are only correct according to the old writing rules.
Therefore, we selected all words in the corpus, that
are correct according to the hunspell lexicon1 us-
ing the old rules, but not correct according to the
hunspell lexicon using the new rules. In a second
step we tried to find the correct spelling according
to the new rules. We first applied rules describing
how words changed from one spelling system to
the other, for example replacing ??? by ?ss?. If the
new word is a correct word according to the hun-
spell lexicon using the new spelling rules, we map
the words.
When translating from German to English, we
apply compound splitting as described in Koehn
and Knight (2003) to the German corpus.
As a last preprocessing step we remove sen-
tences that are too long and empty lines to obtain
the final training corpus.
3 Word Reordering Model
Reordering was applied on the source side prior
to decoding through the generation of lattices en-
coding possible reorderings of each source sen-
tence that better match the word sequence in the
target language. These possible reorderings were
learned based on the POS of the source language
words in the training corpus and the information
about alignments between source and target lan-
guage words in the corpus. For short-range re-
orderings, continuous reordering rules were ap-
plied to the test sentences (Rottmann and Vogel,
2007). To model the long-range reorderings be-
tween German and English, different types of non-
continuous reordering rules were applied depend-
ing on the translation direction. (Niehues and
Kolss, 2009). When translating from English to
German, most of the changes in word order con-
sist in a shift to the right while typical word shifts
in German to English translations take place in the
reverse direction.
1http://hunspell.sourceforge.net/
4 Translation Model
The translation model was trained on the parallel
corpus and the word alignment was generated by
a discriminative word alignment model, which is
described below. The phrase table was trained us-
ing the Moses training scripts, but for the German
to English system we used a different phrase ex-
traction method described in detail in Section 4.2.
In addition, we applied phrase table smoothing as
described in Foster et al (2006). Furthermore, we
extended the translation model by additional fea-
tures for unaligned words and introduced bilingual
language models.
4.1 Word Alignment
In most phrase-based SMT systems the heuristic
grow-diag-final-and is used to combine the align-
ments generated by GIZA++ from both direc-
tions. Then these alignments are used to extract
the phrase pairs.
We used a discriminative word alignment model
(DWA) to generate the alignments as described in
Niehues and Vogel (2008) instead. This model is
trained on a small amount of hand-aligned data
and uses the lexical probability as well as the fer-
tilities generated by the PGIZA++2 Toolkit and
POS information. We used all local features, the
GIZA and indicator fertility features as well as
first order features for 6 directions. The model was
trained in three steps, first using maximum likeli-
hood optimization and afterwards it was optimized
towards the alignment error rate. For more details
see Niehues and Vogel (2008).
4.2 Lattice Phrase Extraction
In translations from German to English, we often
have the case that the English verb is aligned to
both parts of the German verb. Since this phrase
pair is not continuous on the German side, it can-
not be extracted. The phrase could be extracted, if
we also reorder the training corpus.
For the test sentences the POS-based reordering
allows us to change the word order in the source
sentence so that the sentence can be translated
more easily. If we apply this also to the train-
ing sentences, we would be able to extract the
phrase pairs for originally discontinuous phrases
and could apply them during translation of the re-
ordered test sentences.
2http://www.cs.cmu.edu/?qing/
139
Therefore, we build lattices that encode the dif-
ferent reorderings for every training sentence, as
described in Niehues et al (2009). Then we can
not only extract phrase pairs from the monotone
source path, but also from the reordered paths. So
it would be possible to extract the example men-
tioned before, if both parts of the verb were put
together by a reordering rule. To limit the num-
ber of extracted phrase pairs, we extract a source
phrase only once per sentence even if it may be
found on different paths. Furthermore, we do not
use the weights in the lattice.
If we used the same rules as for reordering the
test sets, the lattice would be so big that the num-
ber of extracted phrase pairs would be still too
high. As mentioned before, the word reordering
is mainly a problem at the phrase extraction stage
if one word is aligned to two words which are
far away from each other in the sentence. There-
fore, the short-range reordering rules do not help
much in this case. So, only the long-range reorder-
ing rules were used to generate the lattices for the
training corpus.
4.3 Unaligned Word Feature
Guzman et al (2009) analyzed the role of the word
alignment in the phrase extraction process. To bet-
ter model the relation between word alignment and
the phrase extraction process, they introduced two
new features into the log-linear model. One fea-
ture counts the number of unaligned words on the
source side and the other one does the same for the
target side. Using these additional features they
showed improvements on the Chinese to English
translation task. In order to investigate the impact
on closer related languages like English and Ger-
man, we incorporated those two features into our
systems.
4.4 Bilingual Word language model
Motivated by the improvements in translation
quality that could be achieved by using the n-gram
based approach to statistical machine translation,
for example by Allauzen et al (2009), we tried
to integrate a bilingual language model into our
phrase-based translation system.
To be able to integrate the approach easily into a
standard phrase-based SMT system, a token in the
bilingual language model is defined to consist of
a target word and all source words it is aligned to.
The tokens are ordered according to the target lan-
guage word order. Then the additional tokens can
be introduced into the decoder as an additional tar-
get factor. Consequently, no additional implemen-
tation work is needed to integrate this feature.
If we have the German sentence Ich bin nach
Hause gegangen with the English translation I
went home, the resulting bilingual text would look
like this: I Ich went bin gegangen home Hause.
As shown in the example, one problem with this
approach is that unaligned source words are ig-
nored in the model. One solution could be to have
a second bilingual text ordered according to the
source side. But since the target sentence and not
the source sentence is generated from left to right
during decoding, the integration of a source side
language model is more complex. Therefore, as
a first approach we only used a language model
based on the target word order.
4.5 Bilingual POS language model
The main advantage of POS-based information
is that there are less data sparsity problems and
therefore a longer context can be considered. Con-
sequently, if we want to use this information in the
translation model of a phrase-based SMT system,
the POS-based phrase pairs should be longer than
the word-based ones. But this is not possible in
many decoders or it leads to additional computa-
tion overhead.
If we instead use a bilingual POS-based lan-
guage model, the context length of the language
model is independent from the other models. Con-
sequently, a longer context can be considered for
the POS-based language model than for the word-
based bilingual language model or the phrase
pairs.
Instead of using POS-based information, this
approach can also be applied with other additional
linguistic word-level information like word stems.
5 Results
We submitted translations for English-German
and German-English for the Shared Translation
Task. In the following we present the experiments
we conducted for both translation directions ap-
plying the aforementioned models and extensions
to the baseline systems. The performance of each
individual system configuration was measured ap-
plying the BLEU metric. All BLEU scores are cal-
culated on the lower-cased translation hypotheses.
The individual systems that were used to create the
submission are indicated in bold.
140
5.1 English-German
The baseline system for English-German applies
short-range reordering rules and discriminative
word alignment. The language model is trained
on the News corpus. By expanding the coverage
of the rules to enable long-range reordering, the
score on the test set could be slightly improved.
We then combined the target language part of the
Europarl and News Commentary corpora with the
News corpus to build a bigger language model
which resulted in an increase of 0.11 BLEU points
on the development set and an increase of 0.25
points on the test set. Applying the bilingual lan-
guage model as described above led to 0.04 points
improvement on the test set.
Table 1: Translation results for English-German
(BLEU Score)
System Dev Test
Baseline 15.30 15.40
+ Long-range Reordering 15.25 15.44
+ EPNC LM 15.36 15.69
+ bilingual Word LM 15.37 15.73
+ bilingual POS LM 15.42 15.67
+ unaligned Word Feature 15.65 15.66
+ bilingual Stem LM 15.57 15.74
This system was used to create the submis-
sion to the Shared Translation Task of the WMT
2010. After submission we performed additional
experiments which only led to inconclusive re-
sults. Adding the bilingual POS language model
and introducing the unaligned word feature to the
phrase table only improved on the development
set, while the scores on the test set decreased. A
third bilingual language model based on stem in-
formation again only showed noteworthy effects
on the development set.
5.2 German-English
For the German to English translation system,
the baseline system already uses short-range re-
ordering rules and the discriminative word align-
ment. This system applies only the language
model trained on the News corpus. By adding the
possibility to model long-range reorderings with
POS-based rules, we could improve the system by
0.6 BLEU points. Adding the big language model
using also the English Gigaword corpus we could
improve by 0.3 BLEU points. We got an addi-
tional improvement by 0.1 BLEU points by adding
lattice phrase extraction.
Both the word-based and POS-based bilingual
language model could improve the translation
quality measured in BLEU. Together they im-
proved the system performance by 0.2 BLEU
points.
The best results could be achieved by using also
the unaligned word feature for source and target
words leading to the best performance on the test
set (22.09).
Table 2: Translation results for German-English
(BLEU Score)
System Dev Test
Baseline 20.94 20.83
+ Long-range Reordering 21.52 21.43
+ Gigaword LM 21.90 21.71
+ Lattice Phrase Extraction 21.94 21.81
+ bilingual Word LM 21.94 21.87
+ bilingual POS LM 22.02 22.05
+ unaligned Word Feature 22.09 22.09
6 Conclusions
For our participation in the WMT 2010 we built
translation systems for German to English and En-
glish to German. We addressed to the difficult
word reordering when translating from or to Ger-
man by using POS-based reordering rules during
decoding and by using lattice-based phrase extrac-
tion during training. By applying those methods
we achieved substantially better results for both
translation directions.
Furthermore, we tried to improve the translation
quality by introducing additional features to the
translation model. On the one hand we included
bilingual language models based on different word
factors into the log-linear model. This led to very
slight improvements which differed also with re-
spect to language and data set. We will investigate
in the future whether further improvements are
achievable with this approach. On the other hand
we included the unaligned word feature which has
been applied successfully for other language pairs.
The improvements we could gain with this method
are not as big as the ones reported for other lan-
guages, but still the performance of our systems
could be improved using this feature.
141
Acknowledgments
This work was realized as part of the Quaero Pro-
gramme, funded by OSEO, French State agency
for innovation.
References
Alexandre Allauzen, Josep Crego, Aure?lien Max, and
Franc?ois Yvon. 2009. LIMSI?s statistical trans-
lation system for WMT?09. In Fourth Workshop
on Statistical Machine Translation (WMT 2009),
Athens, Greece.
George Foster, Roland Kuhn, and Howard Johnson.
2006. Phrasetable Smoothing for Statistical Ma-
chine Translation. In Conference on Empirical
Methods in Natural Language Processing (EMNLP
2006), Sydney, Australia.
Francisco Guzman, Qin Gao, and Stephan Vogel.
2009. Reassessment of the Role of Phrase Extrac-
tion in PBSMT. In MT Summit XII, Ottawa, Ontario,
Canada.
Philipp Koehn and Kevin Knight. 2003. Empirical
Methods for Compound Splitting. In EACL, Bu-
dapest, Hungary.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexan-
dra Constantin, and Evan Herbst. 2007. Moses:
Open Source Toolkit for Statistical Machine Trans-
lation. In ACL 2007, Demonstration Session,
Prague, Czech Republic, June 23.
Jan Niehues and Muntsin Kolss. 2009. A POS-Based
Model for Long-Range Reorderings in SMT. In
Fourth Workshop on Statistical Machine Translation
(WMT 2009), Athens, Greece.
Jan Niehues and Stephan Vogel. 2008. Discriminative
Word Alignment via Alignment Matrix Modeling.
In Proc. of Third ACL Workshop on Statistical Ma-
chine Translation, Columbus, USA.
Jan Niehues, Teresa Herrmann, Muntsin Kolss, and
Alex Waibel. 2009. The Universita?t Karlsruhe
Translation System for the EACL-WMT 2009. In
Fourth Workshop on Statistical Machine Translation
(WMT 2009), Athens, Greece.
Kay Rottmann and Stephan Vogel. 2007. Word Re-
ordering in Statistical Machine Translation with a
POS-Based Distortion Model. In TMI, Sko?vde,
Sweden.
Helmut Schmid. 1994. Probabilistic Part-of-Speech
Tagging Using Decision Trees. In International
Conference on New Methods in Language Process-
ing, Manchester, UK.
Ashish Venugopal, Andreas Zollman, and Alex Waibel.
2005. Training and Evaluation Error Minimization
Rules for Statistical Machine Translation. In Work-
shop on Data-drive Machine Translation and Be-
yond (WPT-05), Ann Arbor, MI.
Stephan Vogel. 2003. SMT Decoder Dissected: Word
Reordering. In Int. Conf. on Natural Language
Processing and Knowledge Engineering, Beijing,
China.
142
Proceedings of the 6th Workshop on Statistical Machine Translation, pages 198?206,
Edinburgh, Scotland, UK, July 30?31, 2011. c?2011 Association for Computational Linguistics
Wider Context by Using Bilingual Language Models in Machine Translation
Jan Niehues1, Teresa Herrmann1, Stephan Vogel2 and Alex Waibel1,2
1Institute for Anthropomatics, KIT - Karlsruhe Institute of Technology, Germany
2 Language Techonolgies Institute, Carnegie Mellon University, USA
1firstname.lastname@kit.edu 2lastname@cs.cmu.edu
Abstract
In past Evaluations for Machine Translation of
European Languages, it could be shown that
the translation performance of SMT systems
can be increased by integrating a bilingual lan-
guage model into a phrase-based SMT system.
In the bilingual language model, target words
with their aligned source words build the to-
kens of an n-gram based language model. We
analyzed the effect of bilingual language mod-
els and show where they could help to bet-
ter model the translation process. We could
show improvements of translation quality on
German-to-English and Arabic-to-English. In
addition, for the Arabic-to-English task, train-
ing an extra bilingual language model on the
POS tags instead of the surface word forms
led to further improvements.
1 Introduction
In many state-of-the art SMT systems, the phrase-
based (Koehn et al, 2003) approach is used. In
this approach, instead of building the translation by
translating word by word, sequences of source and
target words, so-called phrase pairs, are used as the
basic translation unit. A table of correspondences
between source and target phrases forms the transla-
tion model in this approach. Target language fluency
is modeled by a language model storing monolin-
gual n-gram occurrences. A log-linear combination
of these main models as well as additional features
is used to score the different translation hypotheses.
Then the decoder searches for the translation with
the highest score.
A different approach to SMT is to use a stochas-
tic finite state transducer based on bilingual n-
grams (Casacuberta and Vidal, 2004). This ap-
proach was for example successfully applied by Al-
lauzen et al (2010) on the French-English trans-
lation task. In this so-called n-gram approach the
translation model is trained by using an n-gram lan-
guage model of pairs of source and target words,
called tuples. While the phrase-based approach cap-
tures only bilingual context within the phrase pairs,
in the n-gram approach the n-gram model trained on
the tuples is used to capture bilingual context be-
tween the tuples. As in the phrase-based approach,
the translation model can also be combined with ad-
ditional models like, for example, language models
using log-linear combination.
Inspired by the n-gram-based approach, we in-
troduce a bilingual language model that extends
the translation model of the phrase-based SMT ap-
proach by providing bilingual word context. In ad-
dition to the bilingual word context, this approach
enables us also to integrate a bilingual context based
on part of speech (POS) into the translation model.
When using phrase pairs it is complicated to use
different kinds of bilingual contexts, since the con-
text of the POS-based phrase pairs should be bigger
than the word-based ones to make the most use of
them. But there is no straightforward way to inte-
grate phrase pairs of different lengths into the trans-
lation model in the phrase-based approach, while it
is quite easy to use n-gram models with different
context lengths on the tuples. We show how we can
use bilingual POS-based language models to capture
longer bilingual context in phrase-based translation
198
systems.
This paper is structured in the following way: In
the next section, we will present some related work.
Afterwards, in Section 3, a motivation for using the
bilingual language model will be given. In the fol-
lowing section the bilingual language model is de-
scribed in detail. In Section 5, the results and an
analysis of the translation results is given, followed
by a conclusion.
2 Related Work
The n-gram approach presented in Mari?o et al
(2006) has been derived from the work of Casacu-
berta and Vidal (2004), which used finite state trans-
ducers for statistical machine translation. In this ap-
proach, units of source and target words are used as
basic translation units. Then the translation model is
implemented as an n-gram model over the tuples. As
it is also done in phrase-based translations, the dif-
ferent translations are scored by a log-linear combi-
nation of the translation model and additional mod-
els.
Crego and Yvon (2010) extended the approach to
be able to handle different word factors. They used
factored language models introduced by Bilmes and
Kirchhoff (2003) to integrate different word factors
into the translation process. In contrast, we use a
log-linear combination of language models on dif-
ferent factors in our approach.
A first approach of integrating the idea presented
in the n-gram approach into phrase-based machine
translation was described in Matusov et al (2006).
In contrast to our work, they used the bilingual units
as defined in the original approach and they did not
use additional word factors.
Hasan et al (2008) used lexicalized triplets to in-
troduce bilingual context into the translation pro-
cess. These triplets include source words from out-
side the phrase and form and additional probability
p(f |e, e?) that modifies the conventional word prob-
ability of f given e depending on trigger words e? in
the sentence enabling a context-based translation of
ambiguous phrases.
Other approaches address this problem by inte-
grating word sense disambiguation engines into a
phrase-based SMT system. In Chan and Ng (2007)
a classifier exploits information such as local col-
locations, parts-of-speech or surrounding words to
determine the lexical choice of target words, while
Carpuat and Wu (2007) use rich context features
based on position, syntax and local collocations to
dynamically adapt the lexicons for each sentence
and facilitate the choice of longer phrases.
In this work we present a method to extend the
locally limited context of phrase pairs and n-grams
by using bilingual language models. We keep the
phrase-based approach as the main SMT framework
and introduce an n-gram language model trained in a
similar way as the one used in the finite state trans-
ducer approach as an additional feature in the log-
linear model.
3 Motivation
To motivate the introduction of the bilingual lan-
guage model, we will analyze the bilingual context
that is used when selecting the target words. In a
phrase-based system, this context is limited by the
phrase boundaries. No bilingual information outside
the phrase pair is used for selecting the target word.
The effect can be shown in the following example
sentence:
Ein gemeinsames Merkmal aller extremen
Rechten in Europa ist ihr Rassismus
und die Tatsache, dass sie das Einwan-
derungsproblem als politischen Hebel be-
nutzen.
Using our phrase-based SMT system, we get the
following segmentation into phrases on the source
side: ein gemeinsames, Merkmal, aller, extremen
Rechten. That means, that the translation of Merk-
mal is not influenced by the source words gemein-
sames or aller.
However, apart from this segmentation, other
phrases could have been conceivable for building a
translation:
ein, ein gemeinsames, ein gemeinsames Merk-
mal, gemeinsames, gemeinsames Merkmal, Merk-
mal aller, aller, extremen, extremen Rechten and
Rechten.
As shown in Figure 1 the translation for the
first three words ein gemeinsames Merkmal into a
common feature can be created by segmenting it
into ein gemeinsames and Merkmal as done by the
199
Figure 1: Alternative Segmentations
phrase-based system or by segmenting it into ein and
gemeinsames Merkmal. In the phrase-based system,
the decoder cannot make use of the fact that both
segmentation variants lead to the same translation,
but has to select one and use only this information
for scoring the hypothesis.
Consequently, if the first segmentation is cho-
sen, the fact that gemeinsames is translated to com-
mon does effect the translation of Merkmal only by
means of the language model, but no bilingual con-
text can be carried over the segmentation bound-
aries.
To overcome this drawback of the phrase-based
approach, we introduce a bilingual language model
into the phrase-based SMT system. Table 1 shows
the source and target words and demonstrates how
the bilingual phrases are constructed and how the
source context stays available over segment bound-
aries in the calculation of the language model score
for the sentence. For example, when calculating the
language model score for the word feature P ( fea-
ture_Merkmal | common_gemeinsames) we can see
that through the bilingual tokens not only the previ-
ous target word but also the previous source word is
known and can influence the translation even though
it is in a different segment.
4 Bilingual Language Model
The bilingual language model is a standard n-gram-
based language model trained on bilingual tokens in-
stead of simple words. These bilingual tokens are
motivated by the tuples used in n-gram approaches
to machine translation. We use different basic units
for the n-gram model compared to the n-gram ap-
proach, in order to be able to integrate them into a
phrase-based translation system.
In this context, a bilingual token consists of a tar-
get word and all source words that it is aligned to.
More formally, given a sentence pair eI1 = e1...eI
and fJ1 = f1...fJ and the corresponding word align-
ment A = {(i, j)} the following tokens are created:
tj = {fj} ? {ei|(i, j) ? A} (1)
Therefore, the number of bilingual tokens in a
sentence equals the number of target words. If a
source word is aligned to two target words like the
word aller in the example sentence, two bilingual to-
kens are created: all_aller and the_aller. If, in con-
trast, a target word is aligned to two source words,
only one bilingual token is created consisting of the
target word and both source words.
The existence of unaligned words is handled in
the following way. If a target word is not aligned
to any source word, the corresponding bilingual to-
ken consists only of the target word. In contrast, if a
source word is not aligned to any word in the target
language sentence, this word is ignored in the bilin-
gual language model.
Using this definition of bilingual tokens the trans-
lation probability of source and target sentence and
the word alignment is then defined by:
p(eI1, f
J
1 , A) =
J?
j=1
P (tj |tj?1...tj?n) (2)
This probability is then used in the log-linear com-
bination of a phrase-based translation system as an
additional feature. It is worth mentioning that al-
though it is modeled like a conventional language
model, the bilingual language model is an extension
to the translation model, since the translation for the
source words is modeled and not the fluency of the
target text.
To train the model a corpus of bilingual tokens can
be created in a straightforward way. In the genera-
tion of this corpus the order of the target words de-
fines the order of the bilingual tokens. Then we can
use the common language modeling tools to train
the bilingual language model. As it was done for
the normal language model, we used Kneser-Ney
smoothing.
4.1 Comparison to Tuples
While the bilingual tokens are motivated by the tu-
ples in the n-gram approach, there are quite some
differences. They are mainly due to the fact that the
200
Source Target Bi-word LM Prob
ein a a_ein P(a_ein | <s>)
gemeinsames common common_gemeinsames P(common_gemeinsames | a_ein, <s>)
Merkmal feature feature_Merkmal P(feature_Merkmal | common_gemeinsames)
of of_ P(of_ | feature_Merkmal)
aller all all_aller P(all_aller | of_)
aller the the_aller P(the_aller | all_aller, of_)
extremen extreme extreme_extremen P(extreme_extremen)
Rechten right right_Rechten P(right_Rechten | extreme_extremen)
Table 1: Example Sentence: Segmentation and Bilingual Tokens
tuples are also used to guide the search in the n-gram
approach, while the search in the phrase-based ap-
proach is guided by the phrase pairs and the bilin-
gual tokens are only used as an additional feature in
scoring.
While no word inside a tuple can be aligned to
a word outside the tuple, the bilingual tokens are
created based on the target words. Consequently,
source words of one bilingual token can also be
aligned to target words inside another bilingual to-
ken. Therefore, we do not have the problems of em-
bedded words, where there is no independent trans-
lation probability.
Since we do not create a a monotonic segmenta-
tion of the bilingual sentence, but only use the seg-
mentation according to the target word order, it is
not clear where to put source words, which have no
correspondence on the target side. As mentioned be-
fore, they are ignored in the model.
But an advantage of this approach is that we have
no problem handling unaligned target words. We
just create bilingual tokens with an empty source
side. Here, the placing order of the unaligned tar-
get words is guided by the segmentation into phrase
pairs.
Furthermore, we need no additional pruning of
the vocabulary due to computation cost, since this is
already done by the pruning of the phrase pairs. In
our phrase-based system, we allow only for twenty
translations of one source phrase.
4.2 Comparison to Phrase Pairs
Using the definition of the bilingual language model,
we can again have a look at the introductory example
sentence. We saw that when translating the phrase
ein gemeinsames Merkmal using a phrase-based sys-
tem, the translation of gemeinsames into common
can only be influenced by either the preceeding ein
# a or by the succeeding Merkmal # feature, but
not by both of them at the same time, since either
the phrase ein gemeinsames or the phrase gemein-
sames Merkmal has to be chosen when segmenting
the source sentence for translation. If we now look
at the context that can be used when translating this
segment applying the bilingual language model, we
see that the translation of gemeinsames into com-
mon is on the one hand influenced by the translation
of the token ein # a within the bilingual language
model probability P (common_gemeinsames | a_ein,
<s>).
On the other hand, it is also influenced by the
translation of the word Merkmal into feature en-
coded into the probability P (feature_Merkmal |
common_gemeinsames). In contrast to the phrase-
based translation model, this additional model is ca-
pable of using context information from both sides
to score the translation hypothesis. In this way,
when building the target sentence, the information
of aligned source words can be considered even be-
yond phrase boundaries.
4.3 POS-based Bilingual Language Models
When translating with the phrase-based approach,
the decoder evaluates different hypotheses with dif-
ferent segmentations of the source sentence into
phrases. The segmentation depends on available
phrase pair combinations but for one hypothesis
translation the segmentation into phrases is fixed.
This leads to problems, when integrating parallel
POS-based information. Since the amount of differ-
201
ent POS tags in a language is very small compared to
the number of words in a language, we could man-
age much longer phrase pairs based on POS tags
compared to the possible length of phrase pairs on
the word level.
In a phrase-based translation system the average
phrase length is often around two words. For POS
sequences, in contrast, sequences of 4 tokens can
often be matched. Consequently, this information
can only help, if a different segmentation could be
chosen for POS-based phrases and for word-based
phrases. Unfortunately, there is no straightforward
way to integrate this into the decoder.
If we now look at how the bilingual language
model is applied, it is much easier to integrate the
POS-based information. In addition to the bilin-
gual token for every target word we can generate a
bilingual token based on the POS information of the
source and target words. Using this bilingual POS
token, we can train an additional bilingual POS-
based language model and apply it during transla-
tion. In this case it is no longer problematic if the
context of the POS-based bilingual language model
is longer than the one based on the word informa-
tion, because word and POS sequences are scored
separately by two different language models which
cover different n-gram lengths.
The training of the bilingual POS language model
is straightforward. We can build the corpus of bilin-
gual POS tokens based on the parallel corpus of
POS tags generated by running a POS tagger over
both source and target side of the initial parallel cor-
pus and the alignment information for the respective
words in the text corpora.
During decoding, we then also need to know the
POS tag for every source and target word. Since
we build the sentence incrementally, we cannot use
the tagger directly. Instead, we store also the POS
source and target sequences during the phrase ex-
traction. When creating the bilingual phrase pair
with POS information, there might be different pos-
sibilities of POS sequences for the source and target
phrases. But we keep only the most probable one for
each phrase pair. For the Arabic-to-English trans-
lation task, we compared the generated target tags
with the tags created by the tagger on the automatic
translations. They are different on less than 5% of
the words.
Using the alignment information as well as the
source and target POS sequences we can then create
the POS-based bilingual tokens for every phrase pair
and store it in addition to the normal phrase pairs.
At decoding time, the most frequent POS tags in the
bilingual phrases are used as tags for the input sen-
tence and the translation is done based on the bilin-
gual POS tokens built from these tags together with
their alignment information.
5 Results
We evaluated and analyzed the influence of the bilin-
gual language model on different languages. On
the one hand, we measured the performance of the
bilingual language model on German-to-English on
the News translation task. On the other hand, we
evaluated the approach on the Arabic-to-English di-
rection on News and Web data. Additionally, we
present the impact of the bilingual language model
on the English-to-German, German-to-English and
French-to-English systems with which we partici-
pated in the WMT 2011.
5.1 System Description
The German-to-English translation system was
trained on the European Parliament corpus, News
Commentary corpus and small amounts of addi-
tional Web data. The data was preprocessed and
compound splitting was applied. Afterwards the dis-
criminative word alignment approach as described
in (Niehues and Vogel, 2008) was applied to gener-
ate the alignments between source and target words.
The phrase table was built using the scripts from the
Moses package (Koehn et al, 2007). The language
model was trained on the target side of the paral-
lel data as well as on additional monolingual News
data. The translation model as well as the language
model was adapted towards the target domain in a
log-linear way.
The Arabic-to-English system was trained us-
ing GALE Arabic data, which contains 6.1M sen-
tences. The word alignment is generated using
EMDC, which is a combination of a discriminative
approach and the IBM Models as described in Gao
et al (2010). The phrase table is generated using
Chaski as described in Gao and Vogel (2010). The
language model data we trained on the GIGAWord
202
V3 data plus BBN English data. After splitting the
corpus according to sources, individual models were
trained. Then the individual models were interpo-
lated to minimize the perplexity on the MT03/MT04
data.
For both tasks the reordering was performed as a
preprocessing step using POS information from the
TreeTagger (Schmid, 1994) for German and using
the Amira Tagger (Diab, 2009) for Arabic. For Ara-
bic the approach described in Rottmann and Vogel
(2007) was used covering short-range reorderings.
For the German-to-English translation task the ex-
tended approach described in Niehues et al (2009)
was used to cover also the long-range reorderings
typical when translating between German and En-
glish.
For both directions an in-house phrase-based de-
coder (Vogel, 2003) was used to generate the transla-
tion hypotheses and the optimization was performed
using MER training. The performance on the test-
sets were measured in case-insensitive BLEU and
TER scores.
5.2 German to English
We evaluated the approach on two different test sets
from the News Commentary domain. The first con-
sists of 2000 sentences with one reference. It will
be referred to as Test 1. The second test set consists
of 1000 sentences with two references and will be
called Test 2.
5.2.1 Translation Quality
In Tables 2 and 3 the results for translation per-
formance on the German-to-English translation task
are summarized.
As it can been seen, the improvements of transla-
tion quality vary considerably between the two dif-
ferent test sets. While using the bilingual language
model improves the translation by only 0.15 BLEU
and 0.21 TER points on Test 1, the improvement on
Test 2 is nearly 1 BLEU point and 0.5 TER points.
5.2.2 Context Length
One intention of using the bilingual language
model is its capability to capture the bilingual con-
texts in a different way. To see, whether additional
bilingual context is used during decoding, we ana-
lyzed the context used by the phrase pairs and by
the n-gram bilingual language model.
However, a comparison of the different context
lengths is not straightforward. The context of an n-
gram language model is normally described by the
average length of applied n-grams. For phrase pairs,
normally the average target phrase pair length (avg.
Target PL) is used as an indicator for the size of the
context. And these two numbers cannot be com-
pared directly.
To be able to compare the context used by the
phrase pairs to the context used in the n-gram lan-
guage model, we calculated the average left context
that is used for every target word where the word
itself is included, i.e. the context of a single word
is 1. In case of the bilingual language model the
score for the average left context is exactly the aver-
age length of applied n-grams in a given translation.
For phrase pairs the average left context can be cal-
culated in the following way: A phrase pair of length
1 gets a left context score of 1. In a phrase pair of
length 2, the first word has a left context score of 1,
since it is not influenced by any target word to the
left. The second word in that phrase pair gets a left
context count of 2, because it is influenced by the
first word in the phrase. Correspondingly, the left
context score of a phrase pair of length 3 is 6 (com-
posed of the score 1 for the first word, score 2 for
the second word and score 3 for the third word). To
get the average left context for the whole translation,
the context scores of all phrases are summed up and
divided by the number of words in the translation.
The scores for the average left contexts for the two
test sets are shown in Tables 2 and 3. They are called
avg. PP Left Context. As it can be seen, the con-
text used by the bilingual n-gram language model is
longer than the one by the phrase pairs. The average
n-gram length increases from 1.58 and 1.57, respec-
tively to 2.21 and 2.18 for the two given test sets.
If we compare the average n-gram length of the
bilingual language model to the one of the target
language model, the n-gram length of the first is of
course smaller, since the number of possible bilin-
gual tokens is higher than the number of possible
monolingual words. This can also be seen when
looking at the perplexities of the two language mod-
els on the generated translations. While the perplex-
ity of the target language model is 99 and 101 on
Test 1 and 2, respectively, the perplexity of the bilin-
203
gual language model is 512 and 538.
Metric No BiLM BiLM
BLEU 30.37 30.52
TER 50.27 50.06
avg. Target PL 1.66 1.66
avg. PP Left Context 1.57 1.58
avg. Target LM N-Gram 3.28 3.27
avg. BiLM N-Gram 2.21
Table 2: German-to-English results (Test 1)
Metric No BiLM BiLM
BLEU 44.16 45.09
TER 41.02 40.52
avg. Target PL 1.65 1.65
avg. PP Left Context 1.56 1.57
avg. Target LM N-Gram 3.25 3.23
avg. BiLM N-Gram 2.18
Table 3: German-to-English results (Test 2)
5.2.3 Overlapping Context
An additional advantage of the n-gram-based ap-
proach is the possibility to have overlapping con-
text. If we would always use phrase pairs of length
2 only half of the adjacent words would influence
each other in the translation. The others are only
influenced by the other target words through the lan-
guage model. If we in contrast would have a bilin-
gual language model which uses an n-gram length
of 2, this means that every choice of word influences
the previous and the following word.
To analyze this influence, we counted how many
borders of phrase pairs are covered by a bilingual
n-gram. For Test 1, 16783 of the 27785 borders
between phrase pairs are covered by a bilingual n-
gram. For Test 2, 9995 of 16735 borders are cov-
ered. Consequently, in both cases at around 60 per-
cent of the borders additional information can be
used by the bilingual n-gram language model.
5.2.4 Bilingual N-Gram Length
For the German-to-English translation task we
performed an additional experiment comparing dif-
ferent n-gram lengths of the bilingual language
BiLM Length aNGL BLEU TER
No 30.37 50.27
1 1 29.67 49.73
2 1.78 30.36 50.05
3 2.11 30.47 50.08
4 2.21 30.52 50.06
5 2.23 30.52 50.07
6 2.24 30.52 50.07
Table 4: Different N-Gram Lengths (Test 1)
BiLM Length aNGL BLEU TER
No 44.16 41.02
1 1 44.22 40.53
2 1.78 45.11 40.38
3 2.09 45.18 40.51
4 2.18 45.09 40.52
5 2.21 45.10 40.52
6 2.21 45.10 40.52
Table 5: Different N-Gram Lengths (Test 2)
model. To ensure comparability between the exper-
iments and avoid additional noise due to different
optimization results, we did not perform separate
optimization runs for for each of the system vari-
ants with different n-gram length, but used the same
scaling factors for all of them. Of course, the sys-
tem using no bilingual language model was trained
independently. In Tables 4 and 5 we can see that the
length of the actually applied n-grams as well as the
BLEU score increased until the bilingual language
model reaches an order of 4. For higher order bilin-
gual language models, nearly no additional n-grams
can be found in the language models. Also the trans-
lation quality does not increase further when using
longer n-grams.
5.3 Arabic to English
The Arabic-to-English system was optimized on the
MT06 data. As test set the Rosetta in-house test set
DEV07-nw (News) and wb (Web Data) was used.
The results for the Arabic-to-English translation
task are summarized in Tables 6 and 7. The perfor-
mance was tested on two different domains, transla-
tion of News and Web documents. On both tasks,
the translation could be improved by more than 1
204
BLEU point. Measuring the performance in TER
also shows an improvement by 0.7 and 0.5 points.
By adding a POS-based bilingual language
model, the performance could be improved further.
An additional gain of 0.2 BLEU points and decrease
of 0.3 points in TER could be reached. Conse-
quently, an overall improvement of up to 1.7 BLEU
points could be achieved by integrating two bilin-
gual language models, one based on surface word
forms and one based on parts-of-speech.
System
Dev Test
BLEU TER BLEU
NoBiLM 48.42 40.77 52.05
+ BiLM 49.29 40.04 53.51
+ POS BiLM 49.56 39.85 53.71
Table 6: Results on Arabic to English: Translation of
News
System
Dev Test
BLEU TER BLEU
NoBiLM 48.42 47.14 41.90
+ BiLM 49.29 46.66 43.12
+ POS BiLM 49.56 46.40 43.28
Table 7: Results on Arabic to English: Translation of
Web documents
As it was done for the German-to-English system,
we also compared the context used by the different
models for this translation direction. The results are
summarized in Table 8 for the News test set and in
Table 9 for the translation of Web data. It can be seen
like it was for the other language pair that the context
used in the bilingual language model is bigger than
the one used by the phrase-based translation model.
Furthermore, it is worth mentioning that shorter
phrase pairs are used, when using the POS-based
bilingual language model. Both bilingual language
models seem to model the context quite good, so that
less long phrase pairs are needed to build the trans-
lation. Instead, the more frequent short phrases can
be used to generate the translation.
5.4 Shared Translation Task @ WMT2011
The bilingual language model was included in 3
systems built for the WMT2011 Shared Translation
Metric No BiLM POS BiLM
BLEU 52.05 53.51 53.71
avg. Target PL 2.12 2.03 1.79
avg. PP Left Context 1.92 1.85 1.69
avg. BiLM N-Gram 2.66 2.65
avg. POS BiLM 4.91
Table 8: Bilingual Context in Arabic-to-English results
(News)
Metric No BiLM POS BiLM
BLEU 41.90 43.12 43.28
avg. Target PL 1.82 1.80 1.57
avg. PP Left Context 1.72 1.69 1.53
avg. BiLM N-Gram 2.33 2.31
avg. POS BiLM 4.49
Table 9: Bilingual Context in Arabic-to-English results
(Web data)
Task evaluation. A phrase-based system similar to
the one described before for the German-to-English
results was used. A detailed system description can
be found in Herrmann et al (2011). The results are
summarized in Table 10. The performance of com-
petitive systems could be improved in all three lan-
guages by up to 0.4 BLEU points.
Language Pair No BiLM BiLM
German-English 24.12 24.52
English-German 16.89 17.01
French-English 28.17 28.34
Table 10: Preformance of Bilingual language model at
WMT2011
6 Conclusion
In this work we showed how a feature of the n-gram-
based approach can be integrated into a phrase-
based statistical translation system. We performed
a detailed analysis on how this influences the scor-
ing of the translation system. We could show im-
provements on a variety of translation tasks cover-
ing different languages and domains. Furthermore,
we could show that additional bilingual context in-
formation is used.
Furthermore, the additional feature can easily be
205
extended to additional word factors such as part-of-
speech, which showed improvements for the Arabic-
to-English translation task.
Acknowledgments
This work was realized as part of the Quaero Pro-
gramme, funded by OSEO, French State agency for
innovation.
References
Alexandre Allauzen, Josep M. Crego, I?lknur Durgar El-
Kahlout, and Fran?ois Yvon. 2010. LIMSI?s Statisti-
cal Translation Systems for WMT?10. In Fifth Work-
shop on Statistical Machine Translation (WMT 2010),
Uppsala, Sweden.
Jeff A. Bilmes and Katrin Kirchhoff. 2003. Fac-
tored language models and generalized parallel back-
off. In Proceedings of the 2003 Conference of the
North American Chapter of the Association for Com-
putational Linguistics on Human Language Technol-
ogy, pages 4?6, Stroudsburg, PA, USA.
Marine Carpuat and Dekai Wu. 2007. Improving Statis-
tical Machine Translation using Word Sense Disam-
biguation. In In The 2007 Joint Conference on Em-
pirical Methods in Natural Language Processing and
Computational Natural Language Learning.
Francisco Casacuberta and Enrique Vidal. 2004. Ma-
chine Translation with Inferred Stochastic Finite-State
Transducers. Comput. Linguist., 30:205?225, June.
Yee Seng Chan and Hwee Tou Ng. 2007. Word Sense
Disambiguation improves Statistical Machine Trans-
lation. In In 45th Annual Meeting of the Association
for Computational Linguistics (ACL-07, pages 33?40.
Josep M. Crego and Fran?ois Yvon. 2010. Factored
bilingual n-gram language models for statistical ma-
chine translation. Machine Translation, 24, June.
Mona Diab. 2009. Second Generation Tools (AMIRA
2.0): Fast and Robust Tokenization, POS tagging, and
Base Phrase Chunking. In Proc. of the Second Interna-
tional Conference on Arabic Language Resources and
Tools, Cairo, Egypt, April.
Qin Gao and Stephan Vogel. 2010. Training Phrase-
Based Machine Translation Models on the Cloud:
Open Source Machine Translation Toolkit Chaski. In
The Prague Bulletin of Mathematical Linguistics No.
93.
Qin Gao, Francisco Guzman, and Stephan Vogel.
2010. EMDC: A Semi-supervised Approach for Word
Alignment. In Proc. of the 23rd International Confer-
ence on Computational Linguistics, Beijing, China.
Sa?a Hasan, Juri Ganitkevitch, Hermann Ney, and Jes?s
Andr?s-Ferrer. 2008. Triplet Lexicon Models for Sta-
tistical Machine Translation. In Proc. of Conference
on Empirical Methods in NLP, Honolulu, USA.
Teresa Herrmann, Mohammed Mediani, Jan Niehues,
and Alex Waibel. 2011. The Karlsruhe Institute of
Technology Translation Systems for the WMT 2011.
In Sixth Workshop on Statistical Machine Translation
(WMT 2011), Edinbugh, U.K.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical Phrase-Based Translation. In Pro-
ceedings of the 2003 Conference of the North Ameri-
can Chapter of the Association for Computational Lin-
guistics on Human Language Technology, pages 48?
54, Edmonton, Canada.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondrej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: Open Source
Toolkit for Statistical Machine Translation. In ACL
2007, Demonstration Session, Prague, Czech Repub-
lic, June 23.
Jos? B. Mari?o, Rafael E. Banchs, Josep M. Crego, Adri?
de Gispert, Patrik Lambert, Jos? A. R. Fonollosa, and
Marta R. Costa-juss?. 2006. N-gram-based machine
translation. Comput. Linguist., 32, December.
Evgeny Matusov, Richard Zens, David Vilar, Arne
Mauser, Maja Popovic?, Sa?a Hasan, and Hermann
Ney. 2006. The rwth machine translation system. In
TC-STAR Workshop on Speech-to-Speech Translation,
pages 31?36, Barcelona, Spain, June.
Jan Niehues and Stephan Vogel. 2008. Discriminative
Word Alignment via Alignment Matrix Modeling. In
Proc. of Third ACL Workshop on Statistical Machine
Translation, Columbus, USA.
Jan Niehues, Teresa Herrmann, Muntsin Kolss, and Alex
Waibel. 2009. The Universit?t Karlsruhe Translation
System for the EACL-WMT 2009. In Fourth Work-
shop on Statistical Machine Translation (WMT 2009),
Athens, Greece.
Kay Rottmann and Stephan Vogel. 2007. Word Reorder-
ing in Statistical Machine Translation with a POS-
Based Distortion Model. In TMI, Sk?vde, Sweden.
Helmut Schmid. 1994. Probabilistic Part-of-Speech Tag-
ging Using Decision Trees. In International Con-
ference on New Methods in Language Processing,
Manchester, UK.
Stephan Vogel. 2003. SMT Decoder Dissected: Word
Reordering. In Int. Conf. on Natural Language Pro-
cessing and Knowledge Engineering, Beijing, China.
206
Proceedings of the 6th Workshop on Statistical Machine Translation, pages 358?364,
Edinburgh, Scotland, UK, July 30?31, 2011. c?2011 Association for Computational Linguistics
Joint WMT Submission of the QUAERO Project
?Markus Freitag, ?Gregor Leusch, ?Joern Wuebker, ?Stephan Peitz, ?Hermann Ney,
?Teresa Herrmann, ?Jan Niehues, ?Alex Waibel,
?Alexandre Allauzen, ?Gilles Adda,?Josep Maria Crego,
?Bianka Buschbeck, ?Tonio Wandmacher, ?Jean Senellart
?RWTH Aachen University, Aachen, Germany
?Karlsruhe Institute of Technology, Karlsruhe, Germany
?LIMSI-CNRS, Orsay, France
?SYSTRAN Software, Inc.
?surname@cs.rwth-aachen.de
?firstname.surname@kit.edu
?firstname.lastname@limsi.fr ?surname@systran.fr
Abstract
This paper describes the joint QUAERO sub-
mission to the WMT 2011 machine transla-
tion evaluation. Four groups (RWTH Aachen
University, Karlsruhe Institute of Technol-
ogy, LIMSI-CNRS, and SYSTRAN) of the
QUAERO project submitted a joint translation
for the WMT German?English task. Each
group translated the data sets with their own
systems. Then RWTH system combination
combines these translations to a better one. In
this paper, we describe the single systems of
each group. Before we present the results of
the system combination, we give a short de-
scription of the RWTH Aachen system com-
bination approach.
1 Overview
QUAERO is a European research and develop-
ment program with the goal of developing multi-
media and multilingual indexing and management
tools for professional and general public applica-
tions (http://www.quaero.org). Research in machine
translation is mainly assigned to the four groups
participating in this joint submission. The aim of
this WMT submission was to show the quality of a
joint translation by combining the knowledge of the
four project partners. Each group develop and main-
tain their own different machine translation system.
These single systems differ not only in their general
approach, but also in the preprocessing of training
and test data. To take the advantage of these dif-
ferences of each translation system, we combined
all hypotheses of the different systems, using the
RWTH system combination approach.
1.1 Data Sets
For WMT 2011 each QUAERO partner trained their
systems on the parallel Europarl and News Com-
mentary corpora. All single systems were tuned on
the newstest2009 dev set. The newstest2008 dev set
was used to train the system combination parame-
ters. Finally the newstest2010 dev set was used to
compare the results of the different system combi-
nation approaches and settings.
2 Translation Systems
2.1 RWTH Aachen Single Systems
For the WMT 2011 evaluation the RWTH utilized
RWTH?s state-of-the-art phrase-based and hierar-
chical translation systems. GIZA++ (Och and Ney,
2003) was employed to train word alignments, lan-
guage models have been created with the SRILM
toolkit (Stolcke, 2002).
2.1.1 Phrase-Based System
The phrase-based translation (PBT) system is
similar to the one described in Zens and Ney (2008).
After phrase pair extraction from the word-aligned
bilingual corpus, the translation probabilities are es-
timated by relative frequencies. The standard feature
set alo includes an n-gram language model, phrase-
level IBM-1 and word-, phrase- and distortion-
penalties, which are combined in log-linear fash-
ion. Parameters are optimized with the Downhill-
Simplex algorithm (Nelder and Mead, 1965) on the
word graph.
358
2.1.2 Hierarchical System
For the hierarchical setups described in this pa-
per, the open source Jane toolkit (Vilar et al, 2010)
is employed. Jane has been developed at RWTH
and implements the hierarchical approach as intro-
duced by Chiang (2007) with some state-of-the-art
extensions. In hierarchical phrase-based translation,
a weighted synchronous context-free grammar is in-
duced from parallel text. In addition to contiguous
lexical phrases, hierarchical phrases with up to two
gaps are extracted. The search is typically carried
out using the cube pruning algorithm (Huang and
Chiang, 2007). The model weights are optimized
with standard MERT (Och, 2003) on 100-best lists.
2.1.3 Phrase Model Training
For some PBT systems a forced alignment pro-
cedure was applied to train the phrase translation
model as described in Wuebker et al (2010). A
modified version of the translation decoder is used
to produce a phrase alignment on the bilingual train-
ing data. The phrase translation probabilities are es-
timated from their relative frequencies in the phrase-
aligned training data. In addition to providing a sta-
tistically well-founded phrase model, this has the
benefit of producing smaller phrase tables and thus
allowing more rapid and less memory consuming
experiments with a better translation quality.
2.1.4 Final Systems
For the German?English task, RWTH conducted
experiments comparing the standard phrase extrac-
tion with the phrase training technique described in
Section 2.1.3. Further experiments included the use
of additional language model training data, rerank-
ing of n-best lists generated by the phrase-based sys-
tem, and different optimization criteria.
A considerable increase in translation quality can
be achieved by application of German compound
splitting (Koehn and Knight, 2003). In comparison
to standard heuristic phrase extraction techniques,
performing force alignment phrase training (FA)
gives an improvement in BLEU on newstest2008
and newstest2009, but a degradation in TER. The
addition of LDC Gigaword corpora (+GW) to the
language model training data shows improvements
in both BLEU and TER. Reranking was done on
1000-best lists generated by the the best available
system (PBT (FA)+GW). Following models were
applied: n-gram posteriors (Zens and Ney, 2006),
sentence length model, a 6-gram LM and IBM-1 lex-
icon models in both normal and inverse direction.
These models are combined in a log-linear fashion
and the scaling factors are tuned in the same man-
ner as the baseline system (using TER?4BLEU on
newstest2009).
The final table includes two identical Jane sys-
tems which are optimized on different criteria. The
one optimized on TER?BLEU yields a much lower
TER.
2.2 Karlsruhe Institute of Technology Single
System
2.2.1 Preprocessing
We preprocess the training data prior to training
the system, first by normalizing symbols such as
quotes, dashes and apostrophes. Then smart-casing
of the first words of each sentence is performed. For
the German part of the training corpus we use the
hunspell1 lexicon to learn a mapping from old Ger-
man spelling to new German spelling to obtain a cor-
pus with homogeneous spelling. In addition, we per-
form compound splitting as described in (Koehn and
Knight, 2003). Finally, we remove very long sen-
tences, empty lines, and sentences that probably are
not parallel due to length mismatch.
2.2.2 System Overview
The KIT system uses an in-house phrase-based
decoder (Vogel, 2003) to perform translation. Op-
timization with regard to the BLEU score is done
using Minimum Error Rate Training as described
by Venugopal et al (2005). The translation model
is trained on the Europarl and News Commentary
Corpus and the phrase table is based on a GIZA++
Word Alignment. We use two 4-gram SRI language
models, one trained on the News Shuffle corpus and
one trained on the Gigaword corpus. Reordering is
performed based on continuous and non-continuous
POS rules to cover short and long-range reorder-
ings. The long-range reordering rules were also ap-
plied to the training corpus and phrase extraction
was performed on the resulting reordering lattices.
Part-of-speech tags are obtained using the TreeTag-
1http://hunspell.sourceforge.net/
359
ger (Schmid, 1994). In addition, the system applies
a bilingual language model to extend the context of
source language words available for translation. The
individual models are described briefly in the fol-
lowing.
2.2.3 POS-based Reordering Model
We use a reordering model that is based on parts-
of-speech (POS) and learn probabilistic rules from
the POS tags of the words in the training corpus and
the alignment information. In addition to continu-
ous reordering rules that model short-range reorder-
ing (Rottmann and Vogel, 2007), we apply non-
continuous rules to address long-range reorderings
as typical for German-English translation (Niehues
and Kolss, 2009). The reordering rules are applied
to the source sentences and the reordered sentence
variants as well as the original sequence are encoded
in a word lattice which is used as input to the de-
coder.
2.2.4 Lattice Phrase Extraction
For the test sentences, the POS-based reordering
allows us to change the word order in the source sen-
tence so that the sentence can be translated more eas-
ily. If we apply this also to the training sentences, we
would be able to extract also phrase pairs for origi-
nally discontinuous phrases and could apply them
during translation of reordered test sentences.
Therefore, we build reordering lattices for all
training sentences and then extract phrase pairs from
the monotone source path as well as from the re-
ordered paths. To limit the number of extracted
phrase pairs, we extract a source phrase only once
per sentence, even if it is found in different paths and
we only use long-range reordering rules to generate
the lattices for the training corpus.
2.2.5 Bilingual Language Model
In phrase-based systems the source sentence is
segmented by the decoder during the search pro-
cess. This segmentation into phrases leads to the
loss of context information at the phrase boundaries.
The language model can make use of more target
side context. To make also source language context
available we use a bilingual language model, an ad-
ditional language model in the phrase-based system
in which each token consist of a target word and all
source words it is aligned to. The bilingual tokens
enter the translation process as an additional target
factor.
2.3 LIMSI-CNRS Single System
2.3.1 System overview
The LIMSI system is built with n-code2, an open
source statistical machine translation system based
on bilingual n-grams.
2.3.2 n-code Overview
In a nutshell, the translation model is im-
plemented as a stochastic finite-state transducer
trained using a n-gram model of (source,target)
pairs (Casacuberta and Vidal, 2004). Training this
model requires to reorder source sentences so as to
match the target word order. This is performed by a
stochastic finite-state reordering model, which uses
part-of-speech information3 to generalize reordering
patterns beyond lexical regularities.
In addition to the translation model, eleven fea-
ture functions are combined: a target-language
model; four lexicon models; two lexicalized reorder-
ing models (Tillmann, 2004) aiming at predicting
the orientation of the next translation unit; a weak
distance-based distortion model; and finally a word-
bonus model and a tuple-bonus model which com-
pensate for the system preference for short transla-
tions. The four lexicon models are similar to the ones
use in a standard phrase based system: two scores
correspond to the relative frequencies of the tuples
and two lexical weights estimated from the automat-
ically generated word alignments. The weights asso-
ciated to feature functions are optimally combined
using a discriminative training framework (Och,
2003), using the newstest2009 data as development
set.
The overall search is based on a beam-search
strategy on top of a dynamic programming algo-
rithm. Reordering hypotheses are computed in a
preprocessing step, making use of reordering rules
built from the word reorderings introduced in the tu-
ple extraction process. The resulting reordering hy-
potheses are passed to the decoder in the form of
word lattices (Crego and Marin?o, 2007).
2http://www.limsi.fr/Individu/jmcrego/n-code
3Part-of-speech information for English and German is com-
puted using the TreeTagger.
360
2.3.3 Data Preprocessing
Based on previous experiments which have
demonstrated that better normalization tools provide
better BLEU scores (K. Papineni and Zhu, 2002),
all the English texts are tokenized and detokenized
with in-house text processing tools (De?chelotte et
al., 2008). For German, the standard tokenizer sup-
plied by evaluation organizers is used.
2.3.4 Target n-gram Language Models
The English language model is trained assuming
that the test set consists in a selection of news texts
dating from the end of 2010 to the beginning of
2011. This assumption is based on what was done
for the 2010 evaluation. Thus, a development cor-
pus is built in order to create a vocabulary and to
optimize the target language model.
Development Set and Vocabulary In order to
cover different period, two development sets are
used. The first one is newstest2008. However, this
corpus is two years older than the targeted time pe-
riod. Thus a second development corpus is gath-
ered by randomly sampling bunches of 5 consecu-
tive sentences from the provided news data of 2010
and 2011.
To estimate a LM, the English vocabulary is first
defined by including all tokens observed in the Eu-
roparl and news-commentary corpora. This vocabu-
lary is then expanded with all words that occur more
that 5 times in the French-English giga-corpus, and
with the most frequent proper names taken from the
monolingual news data of 2010 and 2011. This pro-
cedure results in a vocabulary around 500k words.
Language Model Training All the training data
allowed in the constrained task are divided into 9
sets based on dates on genres. On each set, a
standard 4-gram LM is estimated from the 500k
word vocabulary with in-house tools using abso-
lute discounting interpolated with lower order mod-
els (Kneser and Ney, 1995; Chen and Goodman,
1998).
All LMs except the one trained on the news cor-
pora from 2010-2011 are first linearly interpolated.
The associated coefficients are estimated so as to
minimize the perplexity evaluated on the dev2010-
2011. The resulting LM and the 2010-2011 LM are
finally interpolated with newstest2008 as develop-
ment data. This two steps interpolation aims to avoid
an overestimate of the weight associated to the 2010-
2011 LM.
2.4 SYSTRAN Software, Inc. Single System
The data submitted by SYSTRAN were obtained by
the SYSTRAN baseline system in combination with
a statistical post editing (SPE) component.
The SYSTRAN system is traditionally classi-
fied as a rule-based system. However, over the
decades, its development has always been driven by
pragmatic considerations, progressively integrating
many of the most efficient MT approaches and tech-
niques. Nowadays, the baseline engine can be con-
sidered as a linguistic-oriented system making use of
dependency analysis, general transfer rules as well
as of large manually encoded dictionaries (100k ?
800k entries per language pair).
The basic setup of the SPE component is identi-
cal to the one described in (L. Dugast and Koehn,
2007). A statistical translation model is trained on
the rule-based translation of the source and the tar-
get side of the parallel corpus. This is done sepa-
rately for each parallel corpus. Language models are
trained on each target half of the parallel corpora and
also on additional in-domain corpora. Moreover, the
following measures ? limiting unwanted statistical
effects ? were applied:
? Named entities are replaced by special tokens
on both sides. This usually improves word
alignment, since the vocabulary size is signif-
icantly reduced. In addition, entity translation
is handled more reliably by the rule-based en-
gine.
? The intersection of both vocabularies (i.e. vo-
cabularies of the rule-based output and the ref-
erence translation) is used to produce an addi-
tional parallel corpus (whose target is identical
to the source). This was added to the parallel
text in order to improve word alignment.
? Singleton phrase pairs are deleted from the
phrase table to avoid overfitting.
? Phrase pairs not containing the same number
of entities on the source and the target side are
also discarded.
361
? Phrase pairs appearing less than 2 times were
pruned.
The SPE language model was trained 15M
phrases from the news/europarl corpora, provided
as training data for WMT 2011. Weights for these
separate models were tuned by the MERT algorithm
provided in the Moses toolkit (P. Koehn et al, 2007),
using the provided news development set.
3 RWTH Aachen System Combination
System combination is used to produce consensus
translations from multiple hypotheses produced with
different translation engines that are better in terms
of translation quality than any of the individual hy-
potheses. The basic concept of RWTH?s approach
to machine translation system combination has been
described by Matusov et al (2006; 2008). This ap-
proach includes an enhanced alignment and reorder-
ing framework. A lattice is built from the input hy-
potheses. The translation with the best score within
the lattice according to a couple of statistical mod-
els is selected as consensus translation. A deeper
description will be also given in the WMT11 sys-
tem combination paper of RWTH Aachen Univer-
sity. For this task only the A2L framework has been
used.
4 Experiments
We tried different system combinations with differ-
ent sets of single systems and different optimiza-
tion criteria. As RWTH has two different transla-
tion systems, we put the output of both systems into
system combination. Although both systems have
the same preprocessing, their hypotheses differ. Fi-
nally, we added for both RWTH systems two addi-
tional hypotheses to the system combination. The
two hypotheses of Jane were optimized on differ-
ent criteria. The first hypothesis was optimized on
BLEU and the second one on TER?BLEU. The first
RWTH phrase-based hypothesis was generated with
force alignment, the second RWTH phrase-based
hypothesis is a reranked version of the first one as
described in 2.1.4. Compared to the other systems,
the system by SYSTRAN has a completely different
approach (see section 2.4). It is mainly based on a
rule-based system. For the German?English pair,
SYSTRAN achieves a lower BLEU score in each
test set compared to the other groups. But since the
SYSTRAN system is very different to the others, we
still obtain an improvement when we add it also to
system combination.
We obtain the best result from system combina-
tion of all seven systems, optimizing the parameters
on BLEU. This system was the system we submitted
to the WMT 2011 evaluation.
For each dev set we obtain an improvement com-
pared to the best single systems. For newstest2008
and newstest2009 we get an improvement of 0.5
points in BLEU and 1.8 points in TER compared to
the best single system of Karlsruhe Institute of Tech-
nology. For newstest2010 we get an improvement
of 1.8 points in BLEU and 2.7 points in TER com-
pared to the best single system of RWTH. The sys-
tem combination weights optimized for the best run
are listed in Table 2. We see that although the single
system of SYSTRAN has the lowest BLEU scores,
it gets the second highest system weight. This high
value shows the influence of a completely different
system. On the other hand, all RWTH systems are
very similar, because of their same preprocessing
and their small variations. Therefor the system com-
bination parameter of all four systems by themselves
are relatively small. The summarized ?RWTH ap-
proach? system weight, though, is again on par with
the other systems.
5 Conclusion
The four statistical machine translation systems of
Karlsruhe Institute of Technology, RWTH Aachen
and LIMSI and the very structural approach of SYS-
TRAN produce hypotheses with a huge variability
compared to the others. Finally the RWTH Aachen
system combination combined all single system hy-
potheses to one hypothesis with a higher BLEU
compared to each single system. If the system
combination implementation can handle enough sin-
gle systems we would recommend to add all single
systems to the system combination. Although the
single system of SYSTRAN has the lowest BLEU
scores and the RWTH single systems are similar we
achieved the best result in using all single systems.
362
newstest2008 newstest2009 newstest2010 description
BLEU TER BLEU TER BLEU TER
22.73 60.73 22.50 59.82 25.26 57.37 sc (all systems) BLEU opt
22.61 60.60 22.28 59.39 25.07 56.95 sc (all systems - (1)) TER?BLEU opt
22.50 60.41 22.52 59.61 25.23 57.40 sc (all systems) TER?BLEU opt
22.19 60.09 22.05 59.31 24.74 56.89 sc (all systems - (4)) TER?BLEU opt
22.21 60.71 21.89 59.95 24.72 57.58 sc (all systems - (4,7)) TER?BLEU opt
22.22 60.45 21.79 59.72 24.32 57.59 sc (all systems - (3,4)) TER?BLEU opt
22.27 60.60 21.75 59.92 24.35 57.64 sc (all systems - (3,4)) BLEU opt
22.10 62.59 22.01 61.64 23.34 60.35 (1) Karlsruhe Institute of Technology
21.41 62.77 21.12 61.91 23.44 60.06 (2) RWTH PBT (FA) rerank +GW
21.11 62.96 21.06 62.16 23.29 60.26 (3) RWTH PBT (FA)
21.47 63.89 21.00 63.33 22.93 61.71 (4) RWTH jane + GW BLEU opt
20.89 61.05 20.36 60.47 23.42 58.31 (5) RWTH jane + GW TER?BLEU opt
20.33 64.50 19.79 64.91 21.97 61.44 (6) Limsi-CNRS
17.06 69.48 17.52 67.34 18.68 66.37 (7) SYSTRAN Software
Table 1: All systems for the WMT 2011 German?English translation task (truecase). BLEU and TER results are in
percentage. FA denotes systems with phrase training, +GW the use of LDC data for the language model. sc denotes
system combination.
system weight
Karlsruhe Institute of Technology 0.350
RWTH PBT (FA) rerank +GW 0.001
RWTH PBT (FA) 0.046
RWTH jane + GW BLEU opt 0.023
RWTH jane + GW TER?BLEU opt 0.034
Limsi-CNRS 0.219
SYSTRAN Software 0.328
Table 2: Optimized systems weights for each system of the best system combination result.
Acknowledgments
This work was achieved as part of the QUAERO
Programme, funded by OSEO, French State agency
for innovation.
References
F. Casacuberta and E. Vidal. 2004. Machine translation
with inferred stochastic finite-state transducers. Com-
putational Linguistics, 30(3):205?225.
S.F. Chen and J.T. Goodman. 1998. An empirical
study of smoothing techniques for language modeling.
Technical Report TR-10-98, Computer Science Group,
Harvard University.
D. Chiang. 2007. Hierarchical Phrase-Based Transla-
tion. Computational Linguistics, 33(2):201?228.
J.M. Crego and J.B. Marin?o. 2007. Improving statistical
MT by coupling reordering and decoding. Machine
Translation, 20(3):199?215.
D. De?chelotte, O. Galibert G. Adda, A. Allauzen, J. Gau-
vain, H. Meynard, and F. Yvon. 2008. LIMSI?s statis-
tical translation systems for WMT?08. In Proc. of the
NAACL-HTL Statistical Machine Translation Work-
shop, Columbus, Ohio.
L. Huang and D. Chiang. 2007. Forest Rescoring: Faster
Decoding with Integrated Language Models. In Proc.
Annual Meeting of the Association for Computational
Linguistics, pages 144?151, Prague, Czech Republic,
June.
T. Ward K. Papineni, S. Roukos and W. Zhu. 2002. Bleu:
363
a method for automatic evaluation of machine transla-
tion. In ACL ?02: Proc. of the 40th Annual Meeting
on Association for Computational Linguistics, pages
311?318. Association for Computational Linguistics.
R. Kneser and H. Ney. 1995. Improved backing-off for
m-gram language modeling. In Proceedings of the In-
ternational Conference on Acoustics, Speech, and Sig-
nal Processing, ICASSP?95, pages 181?184, Detroit,
MI.
P. Koehn and K. Knight. 2003. Empirical Methods
for Compound Splitting. In Proceedings of European
Chapter of the ACL (EACL 2009), pages 187?194.
J. Senellart L. Dugast and P. Koehn. 2007. Statistical
post-editing on systran?s rule-based translation system.
In Proceedings of the Second Workshop on Statisti-
cal Machine Translation, StatMT ?07, pages 220?223,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
E. Matusov, N. Ueffing, and H. Ney. 2006. Computing
Consensus Translation from Multiple Machine Trans-
lation Systems Using Enhanced Hypotheses Align-
ment. In Conference of the European Chapter of the
Association for Computational Linguistics (EACL),
pages 33?40.
E. Matusov, G. Leusch, R.E. Banchs, N. Bertoldi,
D. Dechelotte, M. Federico, M. Kolss, Y.-S. Lee,
J.B. Mari no, M. Paulik, S. Roukos, H. Schwenk, and
H. Ney. 2008. System Combination for Machine
Translation of Spoken and Written Language. IEEE
Transactions on Audio, Speech and Language Pro-
cessing, 16(7):1222?1237.
J.A. Nelder and R. Mead. 1965. The Downhill Simplex
Method. Computer Journal, 7:308.
J. Niehues and M. Kolss. 2009. A POS-Based Model for
Long-Range Reorderings in SMT. In Fourth Work-
shop on Statistical Machine Translation (WMT 2009),
Athens, Greece.
F.J. Och and H. Ney. 2003. A Systematic Comparison of
Various Statistical Alignment Models. Computational
Linguistics, 29(1):19?51.
F.J. Och. 2003. Minimum Error Rate Training for Statis-
tical Machine Translation. In Proc. Annual Meeting of
the Association for Computational Linguistics, pages
160?167, Sapporo, Japan, July.
A. Birch P. Koehn, H. Hoang, C. Callison-Burch, M. Fed-
erico, N. Bertoldi, B. Cowan, W. Shen, C. Moran,
R. Zens, C. Dyer, O. Bojar, A. Constantin, and
E. Herbst. 2007. Moses: open source toolkit for
statistical machine translation. In Proceedings of the
45th Annual Meeting of the ACL on Interactive Poster
and Demonstration Sessions, ACL ?07, pages 177?
180, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
K. Rottmann and S. Vogel. 2007. Word Reordering in
Statistical Machine Translation with a POS-Based Dis-
tortion Model. In TMI, Sko?vde, Sweden.
H. Schmid. 1994. Probabilistic Part-of-Speech Tagging
Using Decision Trees. In International Conference
on NewMethods in Language Processing, Manchester,
UK.
A. Stolcke. 2002. SRILM - an extensible language mod-
eling toolkit. In Proc. Int. Conf. on Spoken Language
Processing, volume 2, pages 901?904, Denver, Col-
orado, USA, September.
C. Tillmann. 2004. A unigram orientation model for sta-
tistical machine translation. In Proceedings of HLT-
NAACL 2004, pages 101?104. Association for Com-
putational Linguistics.
A. Venugopal, A. Zollman, and A. Waibel. 2005. Train-
ing and Evaluation Error Minimization Rules for Sta-
tistical Machine Translation. In Workshop on Data-
drive Machine Translation and Beyond (WPT-05), Ann
Arbor, MI.
D. Vilar, S. Stein, M. Huck, and H. Ney. 2010. Jane:
Open Source Hierarchical Translation, Extended with
Reordering and Lexicon Models. In ACL 2010 Joint
Fifth Workshop on Statistical Machine Translation and
Metrics MATR, pages 262?270, Uppsala, Sweden,
July.
S. Vogel. 2003. SMT Decoder Dissected: Word Re-
ordering. In Int. Conf. on Natural Language Process-
ing and Knowledge Engineering, Beijing, China.
J. Wuebker, A. Mauser, and H. Ney. 2010. Training
Phrase Translation Models with Leaving-One-Out. In
Proceedings of the 48th Annual Meeting of the Assoc.
for Computational Linguistics, pages 475?484, Upp-
sala, Sweden, July.
R. Zens and H. Ney. 2006. N-gram Posterior Proba-
bilities for Statistical Machine Translation. In Human
Language Technology Conf. / North American Chap-
ter of the Assoc. for Computational Linguistics Annual
Meeting (HLT-NAACL), Workshop on Statistical Ma-
chine Translation, pages 72?77, New York City, June.
R. Zens and H. Ney. 2008. Improvements in Dynamic
Programming Beam Search for Phrase-based Statisti-
cal Machine Translation. In Proc. of the Int. Workshop
on Spoken Language Translation (IWSLT), Honolulu,
Hawaii, October.
364
Proceedings of the 6th Workshop on Statistical Machine Translation, pages 379?385,
Edinburgh, Scotland, UK, July 30?31, 2011. c?2011 Association for Computational Linguistics
The Karlsruhe Institute of Technology Translation Systems
for the WMT 2011
Teresa Herrmann, Mohammed Mediani, Jan Niehues and Alex Waibel
Karlsruhe Institute of Technology
Karlsruhe, Germany
firstname.lastname@kit.edu
Abstract
This paper describes the phrase-based SMT
systems developed for our participation
in the WMT11 Shared Translation Task.
Translations for English?German and
English?French were generated using a
phrase-based translation system which is
extended by additional models such as
bilingual and fine-grained POS language
models, POS-based reordering, lattice phrase
extraction and discriminative word alignment.
Furthermore, we present a special filtering
method for the English-French Giga corpus
and the phrase scoring step in the training is
parallelized.
1 Introduction
In this paper we describe our systems for the
EMNLP 2011 Sixth Workshop on Statistical Ma-
chine Translation. We participated in the Shared
Translation Task and submitted translations for
English?German and English?French. We use a
phrase-based decoder that can use lattices as input
and developed several models that extend the stan-
dard log-linear model combination of phrase-based
MT. These include advanced reordering models and
corresponding adaptations to the phrase extraction
process as well as extension to the translation and
language model in form of discriminative word
alignment and a bilingual language model to ex-
tend source word context. For English-German, lan-
guage models based on fine-grained part-of-speech
tags were used to address the difficult target lan-
guage generation due to the rich morphology of Ger-
man.
We also present a filtering method directly ad-
dressing the problems of web-crawled corpora,
which enabled us to make use of the French-English
Giga corpus. Another novelty in our systems this
year is the parallel phrase scoring method that re-
duces the time needed for training which is espe-
cially convenient for such big corpora as the Giga
corpus.
2 System Description
The baseline systems for all languages use a trans-
lation model that is trained on EPPS and the News
Commentary corpus and the phrase table is based
on a GIZA++ word alignment. The language model
was trained on the monolingual parts of the same
corpora by the SRILM Toolkit (Stolcke, 2002). It
is a 4-gram SRI language model using Kneser-Ney
smoothing.
The problem of word reordering is addressed us-
ing the POS-based reordering model as described
in Section 2.4. The part-of-speech tags for the re-
ordering model are obtained using the TreeTagger
(Schmid, 1994).
An in-house phrase-based decoder (Vogel, 2003)
is used to perform translation and optimization with
regard to the BLEU score is done using Minimum
Error Rate Training as described in Venugopal et al
(2005). During decoding only the top 20 translation
options for every source phrase were considered.
2.1 Data
We trained all systems using the parallel EPPS and
News Commentary corpora. In addition, the UN
corpus and the Giga corpus were used for training
379
the French-English systems.
Optimization was done for most languages using
the news-test2008 data set and news-test2010 was
used as test set. The only exception is German-
English, where news-test2009 was used for opti-
mization due to system combination arrangements.
The language models for the baseline systems were
trained on the monolingual versions of the training
corpora. Later on, we used the News Shuffle and the
Gigaword corpus to train bigger language models.
For training a discriminative word alignment model,
a small amount of hand-aligned data was used.
2.2 Preprocessing
The training data is preprocessed prior to training
the system. This includes normalizing special sym-
bols, smart-casing the first words of each sentence
and removing long sentences and sentences with
length mismatch.
For the German parts of the training corpus
we use the hunspell1 lexicon to map words writ-
ten according to old German spelling to new Ger-
man spelling, to obtain a corpus with homogenous
spelling.
Compound splitting as described in Koehn and
Knight (2003) is applied to the German part of the
corpus for the German-to-English system to reduce
the out-of-vocabulary problem for German com-
pound words.
2.3 Special filtering of the Giga parallel Corpus
The Giga corpus incorporates non-neglegible
amounts of noise even after our usual preprocess-
ing. This noise may be due to different causes.
For instance: non-standard HTML characters,
meaningless parts composed of only hypertext
codes, sentences which are only partial translation
of the source, or eventually not a correct translation
at all.
Such noisy pairs potentially degrade the transla-
tion model quality, therefore it seemed more conve-
nient to eliminate them.
Given the size of the corpus, this task could not be
performed manually. Consequently, we used an au-
tomatic classifier inspired by the work of Munteanu
and Marcu (2005) on comparable corpora. This clas-
1http://hunspell.sourceforge.net/
sifier should be able to filter out the pairs which
likely are not beneficial for the translation model.
In order to reliably decide about the classifier to
use, we evaluated several techniques. The training
and test sets for this evaluation were built respec-
tively from nc-dev2007 and nc-devtest2007. In each
set, about 30% randomly selected source sentences
switch positions with the immediate following so
that they form negative examples. We also used lex-
ical dictionaries in both directions based on EPPS
and UN corpora.
We relied on seven features in our classifiers:
IBM1 score in both directions, number of unaligned
source words, the difference in number of words be-
tween source and target, the maximum source word
fertility, number of unaligned target words, and the
maximum target word fertility. It is noteworthy
that all the features requiring alignment information
(such as the unaligned source words) were computed
on the basis of the Viterbi path of the IBM1 align-
ment. The following classifiers were used:
Regression Choose either class based on a
weighted linear combination of the features
and a fixed threshold of 0.5.
Logistic regression The probability of the class is
expressed as a sigmoid of a linear combination
of the different features. Then the class with
the highest probability is picked.
Maximum entropy classifier We used the same set
of features to train a maximum entropy classi-
fier using the Megam package2.
Support vector machines classifier An SVM clas-
sifier was trained using the SVM-light pack-
age3.
Results of these experiments are summarized in
Table 1.
The regression weights were estimated so that to
minimize the squared error. This gave us a pretty
poor F-measure score of 90.42%. Given that the lo-
gistic regression is more suited for binary classifica-
tion in our case than the normal regression, it led to
significant increase in the performance. The training
2http://www.cs.utah.edu/?hal/megam/
3http://svmlight.joachims.org/
380
Approach Precision Recall F-measure
Regression 93.81 87.27 90.42
LogReg 93.43 94.84 94.13
MaxEnt 93.69 94.54 94.11
SVM 98.20 96.87 97.53
Table 1: Results of the filtering experiments
was held by maximizing the likelihood to the data
with L2 regularization (with ? = 0.1). This gave an
F-measure score of 94.78%.
The maximum entropy classifier performed better
than the logistic regression in terms of precision but
however it had worse F-measure.
Significant improvements could be noticed us-
ing the SVM classifier in both precision and recall:
98.20% precision, 96.87% recall, and thus 97.53%
F-measure.
As a result, we used the SVM classifier to filter
the Giga parallel corpus. The corpus contained orig-
inally around 22.52 million pairs. After preprocess-
ing and filtering it was reduced to 16.7 million pairs.
Thus throwing around 6 million pairs.
2.4 Word Reordering
In contrast to modeling the reordering by a distance-
based reordering model and/or a lexicalized distor-
tion model, we use a different approach that relies
on part-of-speech (POS) sequences. By abstracting
from surface words to parts-of-speech, we expect to
model the reordering more accurately.
2.4.1 POS-based Reordering Model
To model reordering we first learn probabilistic
rules from the POS tags of the words in the train-
ing corpus and the alignment information. Contin-
uous reordering rules are extracted as described in
Rottmann and Vogel (2007) to model short-range re-
orderings. When translating between German and
English, we apply a modified reordering model with
non-continuous rules to cover also long-range re-
orderings (Niehues and Kolss, 2009). The reorder-
ing rules are applied to the source text and the orig-
inal order of words and the reordered sentence vari-
ants generated by the rules are encoded in a word
lattice which is used as input to the decoder.
2.4.2 Lattice Phrase Extraction
For the test sentences, the POS-based reordering
allows us to change the word order in the source sen-
tence so that the sentence can be translated more eas-
ily. If we apply this also to the training sentences, we
would be able to extract the phrase pairs for orig-
inally discontinuous phrases and could apply them
during translation of reordered test sentences.
Therefore, we build reordering lattices for all
training sentences and then extract phrase pairs from
the monotone source path as well as from the re-
ordered paths.
To limit the number of extracted phrase pairs, we
extract a source phrase only once per sentence even
if it is found in different paths.
2.5 Translation and Language Models
In addition to the models used in the baseline sys-
tem described above we conducted experiments in-
cluding additional models that enhance translation
quality by introducing alternative or additional in-
formation into the translation or language modelling
process.
2.5.1 Discriminative Word Alignment
In most of our systems we use the PGIZA++
Toolkit4 to generate alignments between words in
the training corpora. The word alignments are gen-
erated in both directions and the grow-diag-final-and
heuristic is used to combine them. The phrase ex-
traction is then done based on this word alignment.
In the English-German system we applied the
Discriminative Word Alignment approach as de-
scribed in Niehues and Vogel (2008) instead. This
alignment model is trained on a small corpus of
hand-aligned data and uses the lexical probability
as well as the fertilities generated by the PGIZA++
Toolkit and POS information.
2.5.2 Bilingual Language Model
In phrase-based systems the source sentence is
segmented by the decoder according to the best com-
bination of phrases that maximize the translation
and language model scores. This segmentation into
phrases leads to the loss of context information at
the phrase boundaries. Although more target side
context is available to the language model, source
4http://www.cs.cmu.edu/?qing/
381
side context would also be valuable for the decoder
when searching for the best translation hypothesis.
To make also source language context available we
use a bilingual language model, an additional lan-
guage model in the phrase-based system in which
each token consist of a target word and all source
words it is aligned to. The bilingual tokens enter
the translation process as an additional target factor
and the bilingual language model is applied to the
additional factor like a normal language model. For
more details see (Niehues et al, 2011).
2.5.3 Parallel phrase scoring
The process of phrase scoring is held in two runs.
The objective of the first run is to compute the nec-
essary counts and to estimate the scores, all based
on the source phrases; while the second run is sim-
ilarly held based on the target phrases. Thus, the
extracted phrases have to be sorted twice: once by
source phrase and once by target phrase. These two
sorting operations are almost always done on an ex-
ternal storage device and hence consume most of the
time spent in this step.
The phrase scoring step was reimplemented in or-
der to exploit the available computation resources
more efficiently and therefore reduce the process-
ing time. It uses optimized sorting algorithms for
large data volumes which cannot fit into memory
(Vitter, 2008). In its core, our implementation re-
lies on STXXL: an extension of the STL library for
external memory (Kettner, 2005) and on OpenMP
for shared memory parallelization (Chapman et al,
2007).
Table 2 shows a comparison between Moses and
our phrase scoring tools. The comparison was held
using sixteen-core 64-bit machines with 128 Gb
RAM, where the files are accessed through NFS on
a RAID disk. The experiments show that the gain
grows linearly with the size of input with an average
of 40% of speed up.
2.5.4 POS Language Models
In addition to surface word language models, we
did experiments with language models based on
part-of-speech for English-German. We expect that
having additional information in form of probabil-
ities of part-of-speech sequences should help espe-
cially in case of the rich morphology of German and
#pairs(G) Moses ?103(s) KIT ?103(s)
0.203 25.99 17.58
1.444 184.19 103.41
1.693 230.97 132.79
Table 2: Comparison of Moses and KIT phrase extraction
systems
therefore the more difficult target language genera-
tion.
The part-of-speeches were generated using the
TreeTagger and the RFTagger (Schmid and Laws,
2008), which produces more fine-grained tags that
include also person, gender and case information.
While the TreeTagger assigns 54 different POS tags
to the 357K German words in the corpus, the RF-
Tagger produces 756 different fine-grained tags on
the same corpus.
We tried n-gram lengths of 4 and 7. While no im-
provement in translation quality could be achieved
using the POS language models based on the normal
POS tags, the 4-gram POS language model based
on fine-grained tags could improve the translation
system by 0.2 BLEU points as shown in Table 3.
Surprisingly, increasing the n-gram length to 7 de-
creased the translation quality again.
To investigate the impact of context length, we
performed an analysis on the outputs of two different
systems, one without a POS language model and one
with the 4-gram fine-grained POS language model.
For each of the translations we calculated the aver-
age length of the n-grams in the translation when
applying one of the two language models using 4-
grams of surface words or parts-of-speech. The re-
sults are also shown in Table 3.
The average n-gram length of surface words on
the translation generated by the system without POS
language model and the one using the 4-gram POS
language model stays practically the same. When
measuring the n-gram length using the 4-gram POS
language model, the context increases to 3.4. This
increase of context is not surprising, since with
the more general POS tags longer contexts can be
matched. Comparing the POS context length for
the two translations, we can see that the context in-
creases from 3.18 to 3.40 due to longer matching
POS sequences. This means that the system using
382
the POS language model actually generates trans-
lations with more probable POS sequences so that
longer matches are possible. Also the perplexity
drops by half since the POS language model helps
constructing sentences that have a better structure.
System BLEU avg. ngram length PPL
Word POS POS
no POS LM 16.64 2.77 3.18 66.78
POS LM 16.88 2.81 3.40 33.36
Table 3: Analysis of context length
3 Results
Using the models described above we performed
several experiments leading finally to the systems
used for generating the translations submitted to the
workshop. The following sections describe the ex-
periments for the individual language pairs and show
the translation results. The results are reported as
case-sensitive BLEU scores (Papineni et al, 2002)
on one reference translation.
3.1 German-English
The German-to-English baseline system applies
short-range reordering rules and uses a language
model trained on the EPPS and News Commen-
tary. By exchanging the baseline language model
by one trained on the News Shuffle corpus we im-
prove the translation quality considerably, by more
than 3 BLEU points. When we expand the cov-
erage of the reordering rules to enable long-range
reordering we can improve even further by 0.4 and
adding a second language model trained on the En-
glish Gigaword corpus we gain another 0.3 BLEU
points. To ensure that the phrase table also includes
reordered phrases, we use lattice phrase extraction
and can achieve a small improvement. Finally, a
bilingual language model is added to extend the con-
text of source language words available for transla-
tion, reaching the best score of 23.35 BLEU points.
This system was used for generating the translation
submitted to the German-English Translation Task.
3.2 English-German
The English-to-German baseline system also in-
cludes short-range reordering and uses translation
System Dev Test
Baseline 18.49 19.10
+ NewsShuffle LM 20.63 22.24
+ LongRange Reordering 21.00 22.68
+ Additional Giga LM 21.80 22.92
+ Lattice Phrase Extraction 21.87 22.96
+ Bilingual LM 22.05 23.35
Table 4: Translation results for German-English
and language model based on EPPS and News Com-
mentary. Exchanging the language model by the
News Shuffle language model again yields a big im-
provement by 2.3 BLEU points. Adding long-range
reordering improves a lot on the development set
while the score on the test set remains practically
the same. Replacing the GIZA++ alignments by
alignments generated using the Discriminative Word
Alignment Model again only leads to a small im-
provement. By using the bilingual language model
to increase context we can gain 0.1 BLEU points
and by adding the part-of-speech language model
with rich parts-of-speech including case, number
and gender information for German we achieve the
best score of 16.88. This system was used to gener-
ate the translation used for submission.
System Dev Test
Baseline 13.55 14.19
+ NewsShuffle LM 15.10 16.46
+ LongRange Reordering 15.79 16.46
+ DWA 15.81 16.52
+ Bilingual LM 15.85 16.64
+ POS LM 15.88 16.88
Table 5: Translation results for English-German
3.3 English-French
Table 6 summarizes how our system for English-
French evolved. The baseline system for this direc-
tion was trained on the EPPS and News Commen-
tary corpora, while the language model was trained
on the French part of the EPPS, News Commen-
tary and UN parallel corpora. Some improvement
could be already seen by introducing the short-range
reorderings trained on the baseline parallel corpus.
383
Apparently, the UN data brought only slight im-
provement to the overall performance. On the other
hand, adding bigger language models trained on the
monolingual French version of EPPS, News Com-
mentary and the News Shuffle together with the
French Gigaword corpus introduces an improvement
of 3.7 on test. Using a system trained only on the
Giga corpus data with the same last configuration
shows a significant gain. It showed an improvement
of around 1.0. We were able to obtain some further
improvements by merging the translation models of
the last two systems. i.e. the one system based on
EPPS, UN, and News Commentary and the other on
the Giga corpus. This merging increased our score
by 0.2. Finally, our submitted system for this direc-
tion was obtained by using a single language model
trained on the union of all the French corpora in-
stead of using multiple models. This resulted in an
improvement of 0.1 leading to our best score: 28.28.
System Dev Test
Baseline 20.62 22.36
+ Reordering 21.29 23.11
+ UN 21.27 23.24
+ Big LMs 23.77 26.90
Giga data 24.53 27.94
Merge 24.74 28.14
+ Merged LMs 25.07 28.28
Table 6: Translation results for English-French
3.4 French-English
The development of our system for the French-
English direction is summarized in Table 7. Our sys-
tem for this direction evolved quite similarly to the
opposite direction. The largest improvement accom-
panied the integration of the bigger language mod-
els (trained on the English version of EPPS, News
Commentary, News Shuffle and the Gigaword cor-
pus): 3.3 BLEU points, whereas smaller improve-
ments could be gained by applying the short reorder-
ing rules and almost no change by including the UN
data. Further gains were obtained by training the
system on the Giga corpus added to the previous
parallel data. This increased our performance by
0.6. The submitted system was obtained by aug-
menting the last system with a bilingual language
model adding around 0.2 to the previous score and
thus giving 28.34 as final score.
System Dev Test
Baseline 20.76 23.78
+ Reordering 21.42 24.28
+ UN 21.55 24.21
+ Big LMs 24.16 27.55
+ Giga data 24.86 28.17
+ BiLM 25.01 28.34
Table 7: Translation results for French-English
4 Conclusions
We have presented the systems for our participation
in the WMT 2011 Evaluation for English?German
and English?French. For English?French, a spe-
cial filtering method for web-crawled data was de-
veloped. In addition, a parallel phrase scoring tech-
nique was implemented that could speed up the MT
training process tremendously. Using these two fea-
tures, we were able to integrate the huge amounts of
data available in the Giga corpus into our systems
translating between English and French.
We applied POS-based reordering to improve our
translations in all directions, using short-range re-
ordering for English?French and long-range re-
ordering for English?German. For German-
English, reordering also the training corpus lead to
further improvements of the translation quality.
A Discriminative Word Alignment Model led to
an increase in BLEU for English-German. For this
direction we also tried fine-grained POS language
models of different n-gram lengths. The best trans-
lations could be obtained by using 4-grams.
For nearly all experiments, a bilingual language
model was applied that expands the context of
source words that can be considered during decod-
ing. The improvements range from 0.1 to 0.4 in
BLEU score.
Acknowledgments
This work was realized as part of the Quaero Pro-
gramme, funded by OSEO, French State agency for
innovation.
384
References
Barbara Chapman, Gabriele Jost, and Ruud van der Pas.
2007. Using OpenMP: Portable Shared Memory Par-
allel Programming (Scientific and Engineering Com-
putation). The MIT Press.
Roman Dementiev Lutz Kettner. 2005. Stxxl: Stan-
dard template library for xxl data sets. In Proceedings
of ESA 2005. Volume 3669 of LNCS, pages 640?651.
Springer.
Philipp Koehn and Kevin Knight. 2003. Empirical Meth-
ods for Compound Splitting. In EACL, Budapest,
Hungary.
Dragos Stefan Munteanu and Daniel Marcu. 2005. Im-
proving machine translation performance by exploit-
ing non-parallel corpora. Computational Linguistics,
31:477?504.
Jan Niehues and Muntsin Kolss. 2009. A POS-Based
Model for Long-Range Reorderings in SMT. In
Fourth Workshop on Statistical Machine Translation
(WMT 2009), Athens, Greece.
Jan Niehues and Stephan Vogel. 2008. Discriminative
Word Alignment via Alignment Matrix Modeling. In
Proc. of Third ACL Workshop on Statistical Machine
Translation, Columbus, USA.
Jan Niehues, Teresa Herrmann, Stephan Vogel, and Alex
Waibel. 2011. Wider Context by Using Bilingual Lan-
guage Models in Machine Translation. In Sixth Work-
shop on Statistical Machine Translation (WMT 2011),
Edinburgh, UK.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic
Evaluation of Machine Translation. Technical Report
RC22176 (W0109-022), IBM Research Division, T. J.
Watson Research Center.
Kay Rottmann and Stephan Vogel. 2007. Word Reorder-
ing in Statistical Machine Translation with a POS-
Based Distortion Model. In TMI, Sko?vde, Sweden.
Helmut Schmid and Florian Laws. 2008. Estimation of
Conditional Probabilities with Decision Trees and an
Application to Fine-Grained POS Tagging. In COL-
ING 2008, Manchester, Great Britain.
Helmut Schmid. 1994. Probabilistic Part-of-Speech Tag-
ging Using Decision Trees. In International Con-
ference on New Methods in Language Processing,
Manchester, UK.
Andreas Stolcke. 2002. SRILM ? An Extensible Lan-
guage Modeling Toolkit. In Proc. of ICSLP, Denver,
Colorado, USA.
Ashish Venugopal, Andreas Zollman, and Alex Waibel.
2005. Training and Evaluation Error Minimization
Rules for Statistical Machine Translation. In Work-
shop on Data-drive Machine Translation and Beyond
(WPT-05), Ann Arbor, MI.
Jeffrey Scott Vitter. 2008. Algorithms and Data Struc-
tures for External Memory. now Publishers Inc.
Stephan Vogel. 2003. SMT Decoder Dissected: Word
Reordering. In Int. Conf. on Natural Language Pro-
cessing and Knowledge Engineering, Beijing, China.
385
Proceedings of the 7th Workshop on Statistical Machine Translation, pages 322?329,
Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational Linguistics
Joint WMT 2012 Submission of the QUAERO Project
?Markus Freitag, ?Stephan Peitz, ?Matthias Huck, ?Hermann Ney,
?Jan Niehues, ?Teresa Herrmann, ?Alex Waibel,
?Le Hai-son, ?Thomas Lavergne, ?Alexandre Allauzen,
?Bianka Buschbeck, ?Josep Maria Crego, ?Jean Senellart
?RWTH Aachen University, Aachen, Germany
?Karlsruhe Institute of Technology, Karlsruhe, Germany
?LIMSI-CNRS, Orsay, France
?SYSTRAN Software, Inc.
?surname@cs.rwth-aachen.de
?firstname.surname@kit.edu
?firstname.lastname@limsi.fr ?surname@systran.fr
Abstract
This paper describes the joint QUAERO sub-
mission to the WMT 2012 machine transla-
tion evaluation. Four groups (RWTH Aachen
University, Karlsruhe Institute of Technol-
ogy, LIMSI-CNRS, and SYSTRAN) of the
QUAERO project submitted a joint translation
for the WMT German?English task. Each
group translated the data sets with their own
systems and finally the RWTH system combi-
nation combined these translations in our final
submission. Experimental results show im-
provements of up to 1.7 points in BLEU and
3.4 points in TER compared to the best single
system.
1 Introduction
QUAERO is a European research and develop-
ment program with the goal of developing multi-
media and multilingual indexing and management
tools for professional and general public applica-
tions (http://www.quaero.org). Research in machine
translation is mainly assigned to the four groups
participating in this joint submission. The aim of
this WMT submission was to show the quality of a
joint translation by combining the knowledge of the
four project partners. Each group develop and main-
tain their own different machine translation system.
These single systems differ not only in their general
approach, but also in the preprocessing of training
and test data. To take the advantage of these dif-
ferences of each translation system, we combined
all hypotheses of the different systems, using the
RWTH system combination approach.
This paper is structured as follows. In Section
2, the different engines of all four groups are in-
troduced. In Section 3, the RWTH Aachen system
combination approach is presented. Experiments
with different system selections for system combi-
nation are described in Section 4. Finally in Section
5, we discuss the results.
2 Translation Systems
For WMT 2012 each QUAERO partner trained their
systems on the parallel Europarl and News Com-
mentary corpora. All single systems were tuned
on the newstest2009 or newstest2010 development
set. The newstest2011 dev set was used to train
the system combination parameters. Finally, the
newstest2008-newstest2010 dev sets were used to
compare the results of the different system combina-
tion settings. In this Section all four different system
engines are presented.
2.1 RWTH Aachen Single Systems
For the WMT 2012 evaluation the RWTH utilized
RWTH?s state-of-the-art phrase-based and hierar-
chical translation systems. GIZA++ (Och and Ney,
2003) was employed to train word alignments, lan-
guage models have been created with the SRILM
toolkit (Stolcke, 2002).
2.1.1 Phrase-Based System
The phrase-based translation (PBT) system is
similar to the one described in Zens and Ney (2008).
After phrase pair extraction from the word-aligned
parallel corpus, the translation probabilities are esti-
mated by relative frequencies. The standard feature
322
set alo includes an n-gram language model, phrase-
level IBM-1 and word-, phrase- and distortion-
penalties, which are combined in log-linear fash-
ion. The model weights are optimized with standard
Mert (Och, 2003) on 200-best lists. The optimiza-
tion criterium is BLEU.
2.1.2 Hierarchical System
For the hierarchical setups (HPBT) described in
this paper, the open source Jane toolkit (Vilar et
al., 2010) is employed. Jane has been developed at
RWTH and implements the hierarchical approach as
introduced by Chiang (2007) with some state-of-the-
art extensions. In hierarchical phrase-based transla-
tion, a weighted synchronous context-free grammar
is induced from parallel text. In addition to contigu-
ous lexical phrases, hierarchical phrases with up to
two gaps are extracted. The search is typically car-
ried out using the cube pruning algorithm (Huang
and Chiang, 2007). The model weights are opti-
mized with standard Mert (Och, 2003) on 100-best
lists. The optimization criterium is 4BLEU ?TER.
2.1.3 Preprocessing
In order to reduce the source vocabulary size
translation, the German text was preprocessed
by splitting German compound words with the
frequency-based method described in (Koehn and
Knight, 2003a). To further reduce translation com-
plexity for the phrase-based approach, we performed
the long-range part-of-speech based reordering rules
proposed by (Popovic? et al, 2006).
2.1.4 Language Model
For both decoders a 4-gram language model is ap-
plied. The language model is trained on the par-
allel data as well as the provided News crawl, the
109 French-English, UN and LDC Gigaword Fourth
Edition corpora. For the 109 French-English, UN
and LDC Gigaword corpora RWTH applied the data
selection technique described in (Moore and Lewis,
2010).
2.2 Karlsruhe Institute of Technology Single
System
2.2.1 Preprocessing
We preprocess the training data prior to training
the system, first by normalizing symbols such as
quotes, dashes and apostrophes. Then smart-casing
of the first words of each sentence is performed. For
the German part of the training corpus we use the
hunspell1 lexicon to learn a mapping from old Ger-
man spelling to new German spelling to obtain a cor-
pus with homogenous spelling. In addition, we per-
form compound splitting as described in (Koehn and
Knight, 2003b). Finally, we remove very long sen-
tences, empty lines, and sentences that probably are
not parallel due to length mismatch.
2.2.2 System Overview
The KIT system uses an in-house phrase-based
decoder (Vogel, 2003) to perform translation and op-
timization with regard to the BLEU score is done us-
ing Minimum Error Rate Training as described in
Venugopal et al (2005).
2.2.3 Translation Models
The translation model is trained on the Europarl
and News Commentary Corpus and the phrase ta-
ble is based on a discriminative word alignment
(Niehues and Vogel, 2008).
In addition, the system applies a bilingual lan-
guage model (Niehues et al, 2011) to extend the
context of source language words available for trans-
lation.
Furthermore, we use a discriminative word lexi-
con as introduced in (Mauser et al, 2009). The lex-
icon was trained and integrated into our system as
described in (Mediani et al, 2011).
At last, we tried to find translations for
out-of-vocabulary (OOV) words by using quasi-
morphological operations as described in Niehues
and Waibel (2011). For each OOV word, we try to
find a related word that we can translate. We modify
the ending letters of the OOV word and learn quasi-
morphological operations to be performed on the
known translation of the related word to synthesize
a translation for the OOV word. By this approach
we were for example able to translate Kaminen into
chimneys using the known translation Kamin # chim-
ney.
2.2.4 Language Models
We use two 4-gram SRI language models, one
trained on the News Shuffle corpus and one trained
1http://hunspell.sourceforge.net/
323
on the Gigaword corpus. Furthermore, we use a 5-
gram cluster-based language model trained on the
News Shuffle corpus. The word clusters were cre-
ated using the MKCLS algorithm. We used 100
word clusters.
2.2.5 Reordering Model
Reordering is performed based on part-of-speech
tags obtained using the TreeTagger (Schmid, 1994).
Based on these tags we learn probabilistic continu-
ous (Rottmann and Vogel, 2007) and discontinuous
(Niehues and Kolss, 2009) rules to cover short and
long-range reorderings. The rules are learned from
the training corpus and the alignment. In addition,
we learned tree-based reordering rules. Therefore,
the training corpus was parsed by the Stanford parser
(Rafferty and Manning, 2008). The tree-based rules
consist of the head node of a subtree and all its
children as well as the new order and a probability.
These rules were applied recursively. The reordering
rules are applied to the source sentences and the re-
ordered sentence variants as well as the original se-
quence are encoded in a word lattice which is used
as input to the decoder. For the test sentences, the
reordering based on parts-of-speech and trees allows
us to change the word order in the source sentence
so that the sentence can be translated more easily.
In addition, we build reordering lattices for all train-
ing sentences and then extract phrase pairs from the
monotone source path as well as from the reordered
paths.
2.3 LIMSI-CNRS Single System
LIMSI?s system is built with n-code (Crego et al,
2011), an open source statistical machine translation
system based on bilingual n-gram2. In this approach,
the translation model relies on a specific decomposi-
tion of the joint probability of a sentence pair P(s, t)
using the n-gram assumption: a sentence pair is de-
composed into a sequence of bilingual units called
tuples, defining a joint segmentation of the source
and target. In the approach of (Marin?o et al, 2006),
this segmentation is a by-product of source reorder-
ing which ultimately derives from initial word and
phrase alignments.
2http://ncode.limsi.fr/
2.3.1 An Overview of n-code
The baseline translation model is implemented as
a stochastic finite-state transducer trained using a
n-gram model of (source,target) pairs (Casacuberta
and Vidal, 2004). Training this model requires to
reorder source sentences so as to match the target
word order. This is performed by a stochastic finite-
state reordering model, which uses part-of-speech
information3 to generalize reordering patterns be-
yond lexical regularities.
In addition to the translation model, eleven fea-
ture functions are combined: a target-language
model; four lexicon models; two lexicalized reorder-
ing models (Tillmann, 2004) aiming at predicting
the orientation of the next translation unit; a ?weak?
distance-based distortion model; and finally a word-
bonus model and a tuple-bonus model which com-
pensate for the system preference for short transla-
tions. The four lexicon models are similar to the ones
used in a standard phrase based system: two scores
correspond to the relative frequencies of the tuples
and two lexical weights estimated from the automat-
ically generated word alignments. The weights asso-
ciated to feature functions are optimally combined
using a discriminative training framework (Och,
2003), using the newstest2009 development set.
The overall search is based on a beam-search
strategy on top of a dynamic programming algo-
rithm. Reordering hypotheses are computed in a
preprocessing step, making use of reordering rules
built from the word reorderings introduced in the tu-
ple extraction process. The resulting reordering hy-
potheses are passed to the decoder in the form of
word lattices (Crego and Marin?o, 2007).
2.3.2 Continuous Space Translation Models
One critical issue with standard n-gram transla-
tion models is that the elementary units are bilingual
pairs, which means that the underlying vocabulary
can be quite large. Unfortunately, the parallel data
available to train these models are typically smaller
than the corresponding monolingual corpora used to
train target language models. It is very likely then,
that such models should face severe estimation prob-
lems. In such setting, using neural network language
3Part-of-speech labels for English and German are com-
puted using the TreeTagger (Schmid, 1995).
324
model techniques seem all the more appropriate. For
this study, we follow the recommendations of Le et
al. (2012), who propose to factor the joint proba-
bility of a sentence pair by decomposing tuples in
two (source and target) parts, and further each part
in words. This yields a word factored translation
model that can be estimated in a continuous space
using the SOUL architecture (Le et al, 2011).
The design and integration of a SOUL model for
large SMT tasks is far from easy, given the computa-
tional cost of computing n-gram probabilities. The
solution used here was to resort to a two pass ap-
proach: the first pass uses a conventional back-off
n-gram model to produce a k-best list; in the second
pass, the k-best list is reordered using the probabil-
ities of m-gram SOUL translation models. In the
following experiments, we used a fixed context size
for SOUL of m = 10, and used k = 300.
2.3.3 Corpora and Data Preprocessing
The parallel data is word-aligned using
MGIZA++4 with default settings. For the En-
glish monolingual training data, we used the same
setup as last year5 and thus the same target language
model as detailed in (Allauzen et al, 2011).
For English, we took advantage of our in-house
text processing tools for tokenization and detok-
enization steps (De?chelotte et al, 2008) and our sys-
tem was built in ?true-case?. As German is mor-
phologically more complex than English, the default
policy which consists in treating each word form
independently is plagued with data sparsity, which
is detrimental both at training and decoding time.
Thus, the German side was normalized using a spe-
cific pre-processing scheme (Allauzen et al, 2010;
Durgar El-Kahlout and Yvon, 2010), which notably
aims at reducing the lexical redundancy by (i) nor-
malizing the orthography, (ii) neutralizing most in-
flections and (iii) splitting complex compounds.
2.4 SYSTRAN Software, Inc. Single System
The data submitted by SYSTRAN were obtained by
a system composed of the standard SYSTRAN MT
engine in combination with a statistical post editing
(SPE) component.
4http://geek.kyloo.net/software
5The fifth edition of the English Gigaword (LDC2011T07)
was not used.
The SYSTRAN system is traditionally classi-
fied as a rule-based system. However, over the
decades, its development has always been driven by
pragmatic considerations, progressively integrating
many of the most efficient MT approaches and tech-
niques. Nowadays, the baseline engine can be con-
sidered as a linguistic-oriented system making use of
dependency analysis, general transfer rules as well
as of large manually encoded dictionaries (100k -
800k entries per language pair).
The SYSTRAN phrase-based SPE component
views the output of the rule-based system as the
source language, and the (human) reference trans-
lation as the target language, see (L. Dugast and
Koehn, 2007). It performs corrections and adaptions
learned from the 5-gram language model trained on
the parallel target-to-target corpus. Moreover, the
following measures - limiting unwanted statistical
effects - were applied:
? Named entities, time and numeric expressions
are replaced by special tokens on both sides.
This usually improves word alignment, since
the vocabulary size is significantly reduced. In
addition, entity translation is handled more re-
liably by the rule-based engine.
? The intersection of both vocabularies (i.e. vo-
cabularies of the rule-based output and the ref-
erence translation) is used to produce an addi-
tional parallel corpus to help to improve word
alignment.
? Singleton phrase pairs are deleted from the
phrase table to avoid overfitting.
? Phrase pairs not containing the same number
of entities on the source and the target side are
also discarded.
The SPE language model was trained on 2M bilin-
gual phrases from the news/Europarl corpora, pro-
vided as training data for WMT 2012. An addi-
tional language model built from 15M phrases of
the English LDC Gigaword corpus using Kneser-
Ney (Kneser and Ney, 1995) smoothing was added.
Weights for these separate models were tuned by
the Mert algorithm provided in the Moses toolkit
(P. Koehn et al, 2007), using the provided news de-
velopment set.
325
3 RWTH Aachen System Combination
System combination is used to produce consensus
translations from multiple hypotheses produced with
different translation engines that are better in terms
of translation quality than any of the individual hy-
potheses. The basic concept of RWTH?s approach
to machine translation system combination has been
described by Matusov et al (2006; 2008). This ap-
proach includes an enhanced alignment and reorder-
ing framework. A lattice is built from the input hy-
potheses. The translation with the best score within
the lattice according to a couple of statistical models
is selected as consensus translation.
4 Experiments
This year, we tried different sets of single systems
for system combination. As RWTH has two dif-
ferent translation systems, we put the output of
both systems into system combination. Although
both systems have the same preprocessing and lan-
guage model, their hypotheses differ because of
their different decoding approach. Compared to
the other systems, the system by SYSTRAN has a
completely different approach (see section 2.4). It
is mainly based on a rule-based system. For the
German?English pair, SYSTRAN achieves a lower
BLEU score in each test set compared to the other
groups. However, since the SYSTRAN system is
very different to the others, we still obtain an im-
provement when we add it also to system combina-
tion.
We did experiments with different optimization
criteria for the system combination optimization.
All results are listed in Table 1 (unoptimized), Table
2 (optimized on BLEU) and Table 3 (optimized on
TER-BLEU). Further, we investigated, whether we
will loose performance, if a single system is dropped
from the system combination. The results show that
for each optimization criteria we need all systems to
achieve the best results.
For the BLEU optimized system combination, we
obtain an improvement compared to the best sin-
gle systems for all dev sets. For newstest2008, we
get an improvement of 1.5 points in BLEU and 1.5
points in TER compared to the best single system of
Karlsruhe Institute of Technology. For newstest2009
we get an improvement of 1.9 points in BLEU and
1.5 points in TER compared to the best single sys-
tem. The system combination of all systems outper-
forms the best single system with 1.9 points in BLEU
and 1.9 points in TER for newstest2010. For new-
stest2011 the improvement is 1.3 points in BLEU
and 2.9 points in TER.
For the TER-BLEU optimized system combina-
tion, we achieved more improvement in TER com-
pared to the BLEU optimized system combination.
For newstest2008, we get an improvement of 0.8
points in BLEU and 3.0 points in TER compared to
the best single system of Karlsruhe Institute of Tech-
nology. The system combinations performs better
on newstest2009 with 1.3 points in BLEU and 2.7
points in TER. For newstest2010, we get an im-
provement of 1.7 points in BLEU and 3.4 points in
TER and for newstest2011 we get an improvement
of 0.7 points in BLEU and 2.5 points in TER.
5 Conclusion
The four statistical machine translation systems of
Karlsruhe Institute of Technology, RWTH Aachen
and LIMSI and the very structural approach of SYS-
TRAN produce hypotheses with a huge variability
compared to the others. Finally, the RWTH Aachen
system combination combined all single system hy-
potheses to one hypothesis with a higher BLEU and
a lower TER score compared to each single sys-
tem. For each optimization criteria the system com-
binations using all single systems outperforms the
system combinations using one less single system.
Although the single system of SYSTRAN has the
worst error scores and the RWTH single systems are
similar, we achieved the best result in using all single
systems. For the WMT 12 evaluation, we submitted
the system combination of all systems optimized on
BLEU.
Acknowledgments
This work was achieved as part of the Quaero Pro-
gramme, funded by OSEO, French State agency for
innovation.
References
Alexandre Allauzen, Josep M. Crego, I?lknur Durgar El-
Kahlout, and Francois Yvon. 2010. LIMSI?s statis-
tical translation systems for WMT?10. In Proc. of the
326
Table 1: All systems for the WMT 2012 German?English translation task (truecase). BLEU and TER results are in
percentage. sc denotes system combination. All system combinations are unoptimized.
system newstest2008 newstest2009 newstest2010 newstest2011
BLEU TER BLEU TER BLEU TER BLEU TER TER-BLEU
KIT 22.2 61.8 21.3 61.0 24.1 59.0 22.4 60.2 37.9
RWTH.PBT 21.4 62.0 21.3 61.1 23.9 59.1 21.4 61.2 39.7
Limsi 22.2 63.0 22.0 61.8 23.9 59.9 21.8 62.0 40.2
RWTH.HPBT 21.5 62.6 21.5 61.6 23.6 60.2 21.5 61.8 40.4
SYSTRAN 18.3 64.6 17.9 63.4 21.1 60.5 18.3 63.1 44.8
sc-withAllSystems 23.4 59.7 22.9 59.0 26.2 56.5 23.3 58.8 35.5
sc-without-RWTH.PBT 23.2 59.8 22.8 59.0 25.9 56.6 23.1 58.7 35.6
sc-without-RWTH.HPBT 23.2 59.6 22.7 58.9 26.1 56.2 23.1 58.7 35.6
sc-without-Limsi 22.7 60.1 22.4 59.2 25.5 56.7 22.8 58.8 36.0
sc-without-SYSTRAN 23.0 60.3 22.5 59.5 25.7 57.2 23.1 59.2 36.1
sc-without-KIT 23.0 59.9 22.5 59.1 25.9 56.6 22.9 59.1 36.3
Table 2: All systems for the WMT 2012 German?English translation task (truecase). BLEU and TER results are in
percentage. sc denotes system combination. All system combinations are optimized on BLEU .
system newstest2008 newstest2009 newstest2010 newstest2011
BLEU TER BLEU TER BLEU TER BLEU TER TER-BLEU
sc-withAllSystems 23.7 60.3 23.2 59.5 26.0 57.1 23.7 59.2 35.6
sc-without-RWTH.PBT 23.4 61.1 23.1 59.8 25.5 57.6 23.5 59.5 36.1
sc-without-SYSTRAN 23.3 61.1 22.6 60.5 25.3 58.1 23.5 60.0 36.5
sc-without-Limsi 23.1 60.7 22.6 59.7 25.4 57.5 23.3 59.4 36.2
sc-without-KIT 23.4 60.7 23.0 59.7 25.6 57.7 23.3 59.8 36.5
sc-without-RWTH.HPBT 23.3 59.4 22.8 58.6 26.1 56.0 23.1 58.4 35.2
Table 3: All systems for the WMT 2012 German?English translation task (truecase). BLEU and TER results are in
percentage. sc denotes system combination. All system combinations are optimized on TER-BLEU .
system newstest2008 newstest2009 newstest2010 newstest2011
BLEU TER BLEU TER BLEU TER BLEU TER TER-BLEU
sc-withAllSystems 23.0 58.8 22.4 58.3 25.8 55.6 23.1 57.7 34.6
sc-without-RWTH.PBT 23.0 59.3 22.5 58.5 25.6 56.0 23.1 58.0 34.9
sc-without-RWTH.HPBT 23.1 59.0 22.6 58.3 25.8 55.6 23.0 58.0 35.0
sc-without-SYSTRAN 22.9 59.7 22.4 59.1 25.6 56.7 23.2 58.5 35.3
sc-without-Limsi 22.7 59.4 22.2 58.7 25.3 56.1 22.7 58.1 35.5
sc-without-KIT 22.9 59.3 22.4 58.5 25.7 55.8 22.7 58.1 35.4
327
Joint Workshop on Statistical Machine Translation and
MetricsMATR, pages 54?59, Uppsala, Sweden.
Alexandre Allauzen, Gilles Adda, He?le`ne Bonneau-
Maynard, Josep M. Crego, Hai-Son Le, Aure?lien Max,
Adrien Lardilleux, Thomas Lavergne, Artem Sokolov,
Guillaume Wisniewski, and Franc?ois Yvon. 2011.
LIMSI @ WMT11. In Proceedings of the Sixth Work-
shop on Statistical Machine Translation, pages 309?
315, Edinburgh, Scotland, July. Association for Com-
putational Linguistics.
F. Casacuberta and E. Vidal. 2004. Machine translation
with inferred stochastic finite-state transducers. Com-
putational Linguistics, 30(3):205?225.
D. Chiang. 2007. Hierarchical Phrase-Based Transla-
tion. Computational Linguistics, 33(2):201?228.
J.M. Crego and J.B. Marin?o. 2007. Improving statistical
MT by coupling reordering and decoding. Machine
Translation, 20(3):199?215.
Josep M. Crego, Franois Yvon, and Jos B. Mario.
2011. N-code: an open-source Bilingual N-gram SMT
Toolkit. Prague Bulletin of Mathematical Linguistics,
96:49?58.
D. De?chelotte, O. Galibert G. Adda, A. Allauzen, J. Gau-
vain, H. Meynard, and F. Yvon. 2008. LIMSI?s statis-
tical translation systems for WMT?08. In Proc. of the
NAACL-HTL Statistical Machine Translation Work-
shop, Columbus, Ohio.
Ilknur Durgar El-Kahlout and Franois Yvon. 2010. The
pay-offs of preprocessing for German-English Statis-
tical Machine Translation. In Marcello Federico, Ian
Lane, Michael Paul, and Franois Yvon, editors, Pro-
ceedings of the seventh International Workshop on
Spoken Language Translation (IWSLT), pages 251?
258.
L. Huang and D. Chiang. 2007. Forest Rescoring: Faster
Decoding with Integrated Language Models. In Proc.
Annual Meeting of the Association for Computational
Linguistics, pages 144?151, Prague, Czech Republic,
June.
R. Kneser and H. Ney. 1995. Improved backing-off for
m-gram language modeling. In Proceedings of the In-
ternational Conference on Acoustics, Speech, and Sig-
nal Processing, ICASSP?95, pages 181?184, Detroit,
MI.
P. Koehn and K. Knight. 2003a. Empirical Methods for
Compound Splitting. In EACL, Budapest, Hungary.
P. Koehn and K. Knight. 2003b. Empirical Methods
for Compound Splitting. In Proceedings of European
Chapter of the ACL (EACL 2009), pages 187?194.
J. Senellart L. Dugast and P. Koehn. 2007. Statistical
post-editing on systran?s rule-based translation system.
In Proceedings of the Second Workshop on Statisti-
cal Machine Translation, StatMT ?07, pages 220?223,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Hai-Son Le, Ilya Oparin, Alexandre Allauzen, Jean-Luc
Gauvain, and Franc?ois Yvon. 2011. Structured output
layer neural network language model. In Proceedings
of ICASSP?11, pages 5524?5527.
Hai-Son Le, Alexandre Allauzen, and Franc?ois Yvon.
2012. Continuous space translation models with neu-
ral networks. In NAACL ?12: Proceedings of the
2012 Conference of the North American Chapter of the
Association for Computational Linguistics on Human
Language Technology.
Jose? B. Marin?o, R. Banchs, J.M. Crego, A. de Gispert,
P. Lambert, J.A.R. Fonollosa, and M.R. Costa-jussa`.
2006. N-gram-based machine translation. Computa-
tional Linguistics, 32(4).
E. Matusov, N. Ueffing, and H. Ney. 2006. Computing
Consensus Translation from Multiple Machine Trans-
lation Systems Using Enhanced Hypotheses Align-
ment. In Conference of the European Chapter of the
Association for Computational Linguistics (EACL),
pages 33?40.
E. Matusov, G. Leusch, R.E. Banchs, N. Bertoldi,
D. Dechelotte, M. Federico, M. Kolss, Y.-S. Lee,
J.B. Mari no, M. Paulik, S. Roukos, H. Schwenk, and
H. Ney. 2008. System Combination for Machine
Translation of Spoken and Written Language. IEEE
Transactions on Audio, Speech and Language Pro-
cessing, 16(7):1222?1237.
Arne Mauser, Sas?a Hasan, and Hermann Ney. 2009. Ex-
tending Statistical Machine Translation with Discrim-
inative and Trigger-based Lexicon Models. In Pro-
ceedings of the 2009 Conference on Empirical Meth-
ods in Natural Language Processing: Volume 1 - Vol-
ume 1, EMNLP ?09, Singapore.
Mohammed Mediani, Eunah Cho, Jan Niehues, Teresa
Herrmann, and Alex Waibel. 2011. The KIT English-
French Translation Systems for IWSLT 2011. In Pro-
ceedings of the Eighth International Workshop on Spo-
ken Language Translation (IWSLT).
R.C. Moore and W. Lewis. 2010. Intelligent Selection
of Language Model Training Data. In ACL (Short Pa-
pers), pages 220?224, Uppsala, Sweden, July.
J. Niehues and M. Kolss. 2009. A POS-Based Model for
Long-Range Reorderings in SMT. In Fourth Work-
shop on Statistical Machine Translation (WMT 2009),
Athens, Greece.
J. Niehues and S. Vogel. 2008. Discriminative Word
Alignment via Alignment Matrix Modeling. In Proc.
of Third ACL Workshop on Statistical Machine Trans-
lation, Columbus, USA.
Jan Niehues and Alex Waibel. 2011. Using Wikipedia
to Translate Domain-specific Terms in SMT. In Pro-
328
ceedings of the Eighth International Workshop on Spo-
ken Language Translation (IWSLT), San Francisco,
CA.
Jan Niehues, Teresa Herrmann, Stephan Vogel, and Alex
Waibel. 2011. Wider Context by Using Bilingual Lan-
guage Models in Machine Translation. In Sixth Work-
shop on Statistical Machine Translation (WMT 2011),
Edinburgh, UK.
F.J. Och and H. Ney. 2003. A Systematic Comparison of
Various Statistical Alignment Models. Computational
Linguistics, 29(1):19?51.
F.J. Och. 2003. Minimum Error Rate Training for Statis-
tical Machine Translation. In Proc. Annual Meeting of
the Association for Computational Linguistics, pages
160?167, Sapporo, Japan, July.
A. Birch P. Koehn, H. Hoang, C. Callison-Burch, M. Fed-
erico, N. Bertoldi, B. Cowan, W. Shen, C. Moran,
R. Zens, C. Dyer, O. Bojar, A. Constantin, and
E. Herbst. 2007. Moses: open source toolkit for
statistical machine translation. In Proceedings of the
45th Annual Meeting of the ACL on Interactive Poster
and Demonstration Sessions, ACL ?07, pages 177?
180, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
M. Popovic?, D. Stein, and H. Ney. 2006. Statistical
Machine Translation of German Compound Words.
In FinTAL - 5th International Conference on Natural
Language Processing, Springer Verlag, LNCS, pages
616?624.
Anna N. Rafferty and Christopher D. Manning. 2008.
Parsing three German treebanks: lexicalized and un-
lexicalized baselines. In Proceedings of the Workshop
on Parsing German.
K. Rottmann and S. Vogel. 2007. Word Reordering in
Statistical Machine Translation with a POS-Based Dis-
tortion Model. In TMI, Sko?vde, Sweden.
H. Schmid. 1994. Probabilistic Part-of-Speech Tagging
Using Decision Trees. In International Conference
on NewMethods in Language Processing, Manchester,
UK.
Helmut Schmid. 1995. Improvements in part-of-speech
tagging with an application to German. In Evelyne
Tzoukermann and SusanEditors Armstrong, editors,
Proceedings of the ACL SIGDATWorkshop, pages 47?
50. Kluwer Academic Publishers.
A. Stolcke. 2002. SRILM - an extensible language mod-
eling toolkit. In Proc. Int. Conf. on Spoken Language
Processing, volume 2, pages 901?904, Denver, Col-
orado, USA, September.
C. Tillmann. 2004. A unigram orientation model for sta-
tistical machine translation. In Proceedings of HLT-
NAACL 2004, pages 101?104. Association for Com-
putational Linguistics.
A. Venugopal, A. Zollman, and A. Waibel. 2005. Train-
ing and Evaluation Error Minimization Rules for Sta-
tistical Machine Translation. In Workshop on Data-
drive Machine Translation and Beyond (WPT-05), Ann
Arbor, MI.
D. Vilar, S. Stein, M. Huck, and H. Ney. 2010. Jane:
Open Source Hierarchical Translation, Extended with
Reordering and Lexicon Models. In ACL 2010 Joint
Fifth Workshop on Statistical Machine Translation and
Metrics MATR, pages 262?270, Uppsala, Sweden,
July.
S. Vogel. 2003. SMT Decoder Dissected: Word Re-
ordering. In Int. Conf. on Natural Language Process-
ing and Knowledge Engineering, Beijing, China.
R. Zens and H. Ney. 2008. Improvements in Dynamic
Programming Beam Search for Phrase-based Statisti-
cal Machine Translation. In Proc. of the Int. Workshop
on Spoken Language Translation (IWSLT), Honolulu,
Hawaii, October.
329
Proceedings of the 7th Workshop on Statistical Machine Translation, pages 349?355,
Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational Linguistics
The Karlsruhe Institute of Technology Translation Systems
for the WMT 2012
Jan Niehues, Yuqi Zhang, Mohammed Mediani, Teresa Herrmann, Eunah Cho and Alex Waibel
Karlsruhe Institute of Technology
Karlsruhe, Germany
firstname.lastname@kit.edu
Abstract
This paper describes the phrase-based SMT
systems developed for our participation
in the WMT12 Shared Translation Task.
Translations for English?German and
English?French were generated using a
phrase-based translation system which is
extended by additional models such as
bilingual, fine-grained part-of-speech (POS)
and automatic cluster language models and
discriminative word lexica. In addition, we
explicitly handle out-of-vocabulary (OOV)
words in German, if we have translations for
other morphological forms of the same stem.
Furthermore, we extended the POS-based
reordering approach to also use information
from syntactic trees.
1 Introduction
In this paper, we describe our systems for the
NAACL 2012 Seventh Workshop on Statistical Ma-
chine Translation. We participated in the Shared
Translation Task and submitted translations for
English?German and English?French. We use a
phrase-based decoder that can use lattices as input
and developed several models that extend the stan-
dard log-linear model combination of phrase-based
MT. In addition to the POS-based reordering model
used in past years, for German-English we extended
it to also use rules learned using syntax trees.
The translation model was extended by the bilin-
gual language model and a discriminative word lex-
icon using a maximum entropy classifier. For the
French-English and English-French translation sys-
tems, we also used phrase table adaptation to avoid
overestimation of the probabilities of the huge, but
noisy Giga corpus. In the German-English system,
we tried to learn translations for OOV words by ex-
ploring different morphological forms of the OOVs
with the same lemma.
Furthermore, we combined different language
models in the log-linear model. We used word-
based language models trained on different parts of
the training corpus as well as POS-based language
models using fine-grained POS information and lan-
guage models trained on automatic word clusters.
The paper is organized as follows: The next sec-
tion gives a detailed description of our systems in-
cluding all the models. The translation results for
all directions are presented afterwards and we close
with a conclusion.
2 System Description
For the French?English systems the phrase table
is based on a GIZA++ word alignment, while the
systems for German?English use a discriminative
word alignment as described in Niehues and Vogel
(2008). The language models are 4-gram SRI lan-
guage models using Kneser-Ney smoothing trained
by the SRILM Toolkit (Stolcke, 2002).
The problem of word reordering is addressed with
POS-based and tree-based reordering models as de-
scribed in Section 2.3. The POS tags used in the
reordering model are obtained using the TreeTagger
(Schmid, 1994). The syntactic parse trees are gen-
erated using the Stanford Parser (Rafferty and Man-
ning, 2008).
An in-house phrase-based decoder (Vogel, 2003)
is used to perform translation. Optimization with
349
regard to the BLEU score is done using Minimum
Error Rate Training as described in Venugopal et al
(2005). During decoding only the top 10 translation
options for every source phrase are considered.
2.1 Data
Our translation models were trained on the EPPS
and News Commentary (NC) corpora. Furthermore,
the additional available data for French and English
(i.e. UN and Giga corpora) were exploited in the
corresponding systems.
The systems were tuned with the news-test2011
data, while news-test2011 was used for testing in all
our systems. We trained language models for each
language on the monolingual part of the training cor-
pora as well as the News Shuffle and the Gigaword
(version 4) corpora. The discriminative word align-
ment model was trained on 500 hand-aligned sen-
tences selected from the EPPS corpus.
2.2 Preprocessing
The training data is preprocessed prior to training
the system. This includes normalizing special sym-
bols, smart-casing the first word of each sentence
and removing long sentences and sentences with
length mismatch.
For the German parts of the training corpus, in
order to obtain a homogenous spelling, we use the
hunspell1 lexicon to map words written according to
old German spelling rules to new German spelling
rules.
In order to reduce the OOV problem of German
compound words, Compound splitting as described
in Koehn and Knight (2003) is applied to the Ger-
man part of the corpus for the German-to-English
system.
The Giga corpus received a special preprocessing
by removing noisy pairs using an SVM classifier as
described in Mediani et al (2011). The SVM clas-
sifier training and test sets consist of randomly se-
lected sentence pairs from the corpora of EPPS, NC,
tuning, and test sets. Giving at the end around 16
million sentence pairs.
2.3 Word Reordering
In contrast to modeling the reordering by a distance-
based reordering model and/or a lexicalized distor-
1http://hunspell.sourceforge.net/
tion model, we use a different approach that relies on
POS sequences. By abstracting from surface words
to POS, we expect to model the reordering more ac-
curately. For German-to-English, we additionally
apply reordering rules learned from syntactic parse
trees.
2.3.1 POS-based Reordering Model
In order to build the POS-based reordering model,
we first learn probabilistic rules from the POS tags
of the training corpus and the alignment. Contin-
uous reordering rules are extracted as described in
Rottmann and Vogel (2007) to model short-range re-
orderings. When translating between German and
English, we apply a modified reordering model with
non-continuous rules to cover also long-range re-
orderings (Niehues and Kolss, 2009).
2.3.2 Tree-based Reordering Model
Word order is quite different between German and
English. And during translation especially verbs or
verb particles need to be shifted over a long dis-
tance in a sentence. Using discontinuous POS rules
already improves the translation tremendously. In
addition, we apply a tree-based reordering model
for the German-English translation. Syntactic parse
trees provide information about the words in a sen-
tence that form constituents and should therefore be
treated as inseparable units by the reordering model.
For the tree-based reordering model, syntactic parse
trees are generated for the whole training corpus.
Then the word alignment between the source and
target language part of the corpus is used to learn
rules on how to reorder the constituents in a Ger-
man source sentence to make it matches the English
target sentence word order better. In order to apply
the rules to the source text, POS tags and a parse
tree are generated for each sentence. Then the POS-
based and tree-based reordering rules are applied.
The original order of words as well as the reordered
sentence variants generated by the rules are encoded
in a word lattice. The lattice is then used as input to
the decoder.
For the test sentences, the reordering based on
POS and trees allows us to change the word order
in the source sentence so that the sentence can be
translated more easily. In addition, we build reorder-
ing lattices for all training sentences and then extract
350
phrase pairs from the monotone source path as well
as from the reordered paths.
2.4 Translation Models
In addition to the models used in the baseline system
described above, we conducted experiments includ-
ing additional models that enhance translation qual-
ity by introducing alternative or additional informa-
tion into the translation modeling process.
2.4.1 Phrase table adaptation
Since the Giga corpus is huge, but noisy, it is
advantageous to also use the translation probabil-
ities of the phrase pair extracted only from the
more reliable EPPS and News commentary cor-
pus. Therefore, we build two phrase tables for the
French?English system. One trained on all data
and the other only trained on the EPPS and News
commentary corpus. The two models are then com-
bined using a log-linear combination to achieve the
adaptation towards the cleaner corpora as described
in (Niehues et al, 2010). The newly created trans-
lation model uses the four scores from the general
model as well as the two smoothed relative frequen-
cies of both directions from the smaller, but cleaner
model. If a phrase pair does not occur in the in-
domain part, a default score is used instead of a rela-
tive frequency. In our case, we used the lowest prob-
ability.
2.4.2 Bilingual Language Model
In phrase-based systems the source sentence is
segmented by the decoder according to the best com-
bination of phrases that maximize the translation
and language model scores. This segmentation into
phrases leads to the loss of context information at
the phrase boundaries. Although more target side
context is available to the language model, source
side context would also be valuable for the decoder
when searching for the best translation hypothesis.
To make also source language context available we
use a bilingual language model, in which each token
consists of a target word and all source words it is
aligned to. The bilingual tokens enter the translation
process as an additional target factor and the bilin-
gual language model is applied to the additional fac-
tor like a normal language model. For more details
see Niehues et al (2011).
2.4.3 Discriminative Word Lexica
Mauser et al (2009) have shown that the use
of discriminative word lexica (DWL) can improve
the translation quality. For every target word, they
trained a maximum entropy model to determine
whether this target word should be in the translated
sentence or not using one feature per one source
word.
When applying DWL in our experiments, we
would like to have the same conditions for the train-
ing and test case. For this we would need to change
the score of the feature only if a new word is added
to the hypothesis. If a word is added the second time,
we do not want to change the feature value. In order
to keep track of this, additional bookkeeping would
be required. Also the other models in our translation
system will prevent us from using a word too often.
Therefore, we ignore this problem and can calcu-
late the score for every phrase pair before starting
with the translation. This leads to the following def-
inition of the model:
p(e|f) =
J?
j=1
p(ej |f) (1)
In this definition, p(ej |f) is calculated using a max-
imum likelihood classifier.
Each classifier is trained independently on the
parallel training data. All sentences pairs where the
target word e occurs in the target sentence are used
as positive examples. We could now use all other
sentences as negative examples. But in many of
these sentences, we would anyway not generate the
target word, since there is no phrase pair that trans-
lates any of the source words into the target word.
Therefore, we build a target vocabulary for every
training sentence. This vocabulary consists of all
target side words of phrase pairs matching a source
phrase in the source part of the training sentence.
Then we use all sentence pairs where e is in the tar-
get vocabulary but not in the target sentences as neg-
ative examples. This has shown to have a postive
influence on the translation quality (Mediani et al,
2011) and also reduces training time.
2.4.4 Quasi-Morphological Operations for
OOV words
Since German is a highly inflected language, there
will be always some word forms of a given Ger-
351
Figure 1: Quasi-morphological operations
man lemma that did not occur in the training data.
In order to be able to also translate unseen word
forms, we try to learn quasi-morphological opera-
tions that change the lexical entry of a known word
form to the unknown word form. These have shown
to be beneficial in Niehues and Waibel (2011) using
Wikipedia2 titles. The idea is illustrated in Figure 1.
If we look at the data, our system is able to trans-
late a German word Kamin (engl. chimney), but not
the dative plural form Kaminen. To address this
problem, we try to automatically learn rules how
words can be modified. If we look at the example,
we would like the system to learn the following rule.
If an ?en? is appended to a German word, as it is
done when creating the dative plural form of Kami-
nen, we need to add an ?s? to the end of the English
word in order to perform the same morphological
word transformation. We use only rules where the
ending of the word has at most 3 letters.
Depending on the POS, number, gender or case of
the involved words, the same operation on the source
side does not necessarily correspond to the same op-
eration on the target side.
To account for this ambiguity, we rank the differ-
ent target operation using the following four features
and use the best ranked one. Firstly, we should not
generate target words that do not exist. Here, we
have an advantage that we can use monolingual data
to determine whether the word exists. In addition,
a target operation that often coincides with a given
source operation should be better than one that is
rarely used together with the source operation. We
therefore look at pairs of entries in the lexicon and
count in how many of them the source operation can
be applied to the source side and the target operation
can be applied to the target side. We then use only
operations that occur at least ten times. Furthermore,
2http://www.wikipedia.org/
we use the ending of the source and target word to
determine which pair of operations should be used.
Integration We only use the proposed method for
OOVs and do not try to improve translations of
words that the baseline system already covers. We
look for phrase pairs, for which a source operation
ops exists that changes one of the source words f1
into the OOV word f2. Since we need to apply a
target operation to one word on the target side of the
phrase pair, we only consider phrase pairs where f1
is aligned to one of the target words of the phrase
containing e1. If a target operation exists given f1
and ops, we select the one with the highest rank.
Then we generate a new phrase pair by applying
ops to f1 and opt to e1 keeping the original scores
from the phrase pairs, since the original and syn-
thesized phrase pair are not directly competing any-
way. We do not add several phrase pairs generated
by different operations, since we would then need to
add the features used for ranking the operations into
the MERT. This is problematic, since the operations
were only used for very few words and therefore a
good estimation of the weights is not possible.
2.5 Language Models
The 4-gram language models generated by the
SRILM toolkit are used as the main language mod-
els for all of our systems. For English-French and
French-English systems, we use a good quality cor-
pus as in-domain data to train in-domain language
models. Additionally, we apply the POS and clus-
ter language models in different systems. All lan-
guage models are integrated into the translation sys-
tem by a log-linear combination and received opti-
mal weights during tuning by the MERT.
2.5.1 POS Language Models
The POS language model is trained on the POS
sequences of the target language. In this evalua-
tion, the POS language model is applied for the
English-German system. We expect that having ad-
ditional information in form of probabilities of POS
sequences should help especially in case of the rich
morphology of German. The POS tags are gener-
ated with the RFTagger (Schmid and Laws, 2008)
for German, which produces fine-grained tags that
include person, gender and case information. We
352
use a 9-gram language model on the News Shuf-
fle corpus and the German side of all parallel cor-
pora. More details and discussions about the POS
language model can be found in Herrmann et al
(2011).
2.5.2 Cluster Language Models
The cluster language model follows a similar idea
as the POS language model. Since there is a data
sparsity problem when we substitute words with the
word classes, it is possible to make use of larger
context information. In the POS language model,
POS tags are the word classes. Here, we generated
word classes in a different way. First, we cluster
the words in the corpus using the MKCLS algorithm
(Och, 1999) given a number of classes. Second, we
replace the words in the corpus by their cluster IDs.
Finally, we train an n-gram language model on this
corpus consisting of cluster IDs. Generally, all clus-
ter language models used in our systems are 5-gram.
3 Results
Using the models described above we performed
several experiments leading finally to the systems
used for generating the translations submitted to the
workshop. The following sections describe the ex-
periments for the individual language pairs and show
the translation results. The results are reported as
case-sensitive BLEU scores (Papineni et al, 2002)
on one reference translation.
3.1 German-English
The experiments for the German-English translation
system are summarized in Table 1. The Baseline
system uses POS-based reordering, discriminative
word alignment and a language model trained on the
News Shuffle corpus. By adding lattice phrase ex-
traction small improvements of the translation qual-
ity could be gained.
Further improvements could be gained by adding
a language model trained on the Gigaword corpus
and adding a bilingual and cluster-based language
model. We used 50 word classes and trained a 5-
gram language model. Afterwards, the translation
quality was improved by also using a discriminative
word lexicon. Finally, the best system was achieved
by using Tree-based reordering and using special
treatment for the OOVs. This system generates a
BLEU score of 22.31 on the test data. For the last
two systems, we did not perform new optimization
runs.
System Dev Test
Baseline 23.64 21.32
+ Lattice Phrase Extraction 23.76 21.36
+ Gigaward Language Model 24.01 21.73
+ Bilingual LM 24.19 21.91
+ Cluster LM 24.16 22.09
+ DWL 24.19 22.19
+ Tree-based Reordering - 22.26
+ OOV - 22.31
Table 1: Translation results for German-English
3.2 English-German
The English-German baseline system uses also
POS-based reordering, discriminative word align-
ment and a language model based on EPPS, NC and
News Shuffle. A small gain could be achieved by the
POS-based language model and the bilingual lan-
guage model. Further gain was achieved by using
also a cluster-based language model. For this lan-
guage model, we use 100 word classes and trained
a 5-gram language model. Finally, the best system
uses the discriminative word lexicon.
System Dev Test
Baseline 17.06 15.57
+ POSLM 17.27 15.63
+ Bilingual LM 17.40 15.78
+ Cluster LM 17.77 16.06
+ DWL 17.75 16.28
Table 2: Translation results for English-German
3.3 English-French
Table 3 summarizes how our English-French sys-
tem evolved. The baseline system here was trained
on the EPPS, NC, and UN corpora, while the lan-
guage model was trained on all the French part of
the parallel corpora (including the Giga corpus). It
also uses short-range reordering trained on EPPS
and NC. This system had a BLEU score of around
26.7. The Giga parallel data turned out to be quite
353
beneficial for this task. It improves the scores by
more than 1 BLEU point. More importantly, addi-
tional language models boosted the system quality:
around 1.8 points. In fact, three language models
were log-linearly combined: In addition to the afore-
mentioned, two additional language models were
trained on the monolingual sets (one for News and
one for Gigaword). We could get an improvement
of around 0.2 by retraining the reordering rules on
EPPS and NC only, but using Giza alignment from
the whole data. Adapting the translation model by
using EPPS and NC as in-domain data improves the
BLEU score by only 0.1. This small improvement
might be due to the fact that the news domain is
very broad and that the Giga corpus has already been
carefully cleaned and filtered. Furthermore, using a
bilingual language model enhances the BLEU score
by almost 0.3. Finally, incorporating a cluster lan-
guage model adds an additional 0.1 to the score.
This leads to a system with 30.58.
System Dev Test
Baseline 24.96 26.67
+ GigParData 26.12 28.16
+ Big LMs 29.22 29.92
+ All Reo 29.14 30.10
+ PT Adaptation 29.15 30.22
+ Bilingual LM 29.17 30.49
+ Cluster LM 29.08 30.58
Table 3: Translation results for English-French
3.4 French-English
The development of our system for the French-
English direction is summarized in Table 4. The
baseline system for this direction was trained on the
EPPS, NC, UN and Giga parallel corpora, while the
language model was trained on the French part of the
parallel training corpora. The baseline system in-
cludes the POS-based reordering model with short-
range rules. The largest improvement of 1.7 BLEU
score was achieved by the integration of the bigger
language models which are trained on the English
version of News Shuffle and the Gigaword corpus
(v4). We did not add the language models from the
monolingual English version of EPPS and NC data,
since the experiments have shown that they did not
provide improvement in our system. The second
largest improvement came from the domain adap-
tation that includes an in-domain language model
and adaptations to the phrase extraction. The BLEU
score has improved about 1 BLEU in total. The in-
domain data we used here are parallel EPPS and NC
corpus. Further gains were obtained by augmenting
the system with a bilingual language model adding
around 0.2 BLEU to the previous score. The sub-
mitted system was obtained by adding the cluster
5-gram language model trained on the News Shuf-
fle corpus with 100 clusters and thus giving 30.25 as
the final score.
System Dev Test
Baseline 25.81 27.15
+ Indomain LM 26.17 27.91
+ PT Adaptation 26.33 28.11
+ Big LMs 28.90 29.82
+ Bilingual LM 29.14 30.09
+ Cluster LM 29.31 30.25
Table 4: Translation results for French-English
4 Conclusions
We have presented the systems for our participation
in the WMT 2012 Evaluation for English?German
and English?French. In all systems we could im-
prove by using a class-based language model. Fur-
thermore, the translation quality could be improved
by using a discriminative word lexicon. Therefore,
we trained a maximum entropy classifier for ev-
ery target word. For English?French, adapting the
phrase table helps to avoid using wrong parts of the
noisy Giga corpus. For the German-to-English sys-
tem, we could improve the translation quality addi-
tionally by using a tree-based reordering model and
by special handling of OOV words. For the inverse
direction we could improve the translation quality
by using a 9-gram language model trained on the
fine-grained POS tags.
Acknowledgments
This work was realized as part of the Quaero Pro-
gramme, funded by OSEO, French State agency for
innovation.
354
References
Teresa Herrmann, Mohammed Mediani, Jan Niehues,
and Alex Waibel. 2011. The karlsruhe institute of
technology translation systems for the wmt 2011. In
Proceedings of the Sixth Workshop on Statistical Ma-
chine Translation, pages 379?385, Edinburgh, Scot-
land, July. Association for Computational Linguistics.
Philipp Koehn and Kevin Knight. 2003. Empirical Meth-
ods for Compound Splitting. In EACL, Budapest,
Hungary.
Arne Mauser, Sas?a Hasan, and Hermann Ney. 2009. Ex-
tending Statistical Machine Translation with Discrim-
inative and Trigger-based Lexicon Models. In Pro-
ceedings of the 2009 Conference on Empirical Meth-
ods in Natural Language Processing: Volume 1 - Vol-
ume 1, EMNLP ?09, Singapore.
Mohammed Mediani, Eunah Cho, Jan Niehues, Teresa
Herrmann, and Alex Waibel. 2011. The kit english-
french translation systems for iwslt 2011. In Proceed-
ings of the eight International Workshop on Spoken
Language Translation (IWSLT).
Jan Niehues and Muntsin Kolss. 2009. A POS-Based
Model for Long-Range Reorderings in SMT. In
Fourth Workshop on Statistical Machine Translation
(WMT 2009), Athens, Greece.
Jan Niehues and Stephan Vogel. 2008. Discriminative
Word Alignment via Alignment Matrix Modeling. In
Proc. of Third ACL Workshop on Statistical Machine
Translation, Columbus, USA.
Jan Niehues and Alex Waibel. 2011. Using wikipedia to
translate domain-specific terms in smt. In Proceedings
of the eight International Workshop on Spoken Lan-
guage Translation (IWSLT).
Jan Niehues, Mohammed Mediani, Teresa Herrmann,
Michael Heck, Christian Herff, and Alex Waibel.
2010. The KIT Translation system for IWSLT 2010.
In Marcello Federico, Ian Lane, Michael Paul, and
Franc?ois Yvon, editors, Proceedings of the seventh In-
ternational Workshop on Spoken Language Transla-
tion (IWSLT), pages 93?98.
Jan Niehues, Teresa Herrmann, Stephan Vogel, and Alex
Waibel. 2011. Wider Context by Using Bilingual Lan-
guage Models in Machine Translation. In Sixth Work-
shop on Statistical Machine Translation (WMT 2011),
Edinburgh, UK.
Franz Josef Och. 1999. An efficient method for deter-
mining bilingual word classes. In Proceedings of the
ninth conference on European chapter of the Associa-
tion for Computational Linguistics, EACL ?99, pages
71?76, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic
Evaluation of Machine Translation. Technical Report
RC22176 (W0109-022), IBM Research Division, T. J.
Watson Research Center.
Anna N. Rafferty and Christopher D. Manning. 2008.
Parsing three german treebanks: lexicalized and un-
lexicalized baselines. In Proceedings of the Workshop
on Parsing German.
Kay Rottmann and Stephan Vogel. 2007. Word Reorder-
ing in Statistical Machine Translation with a POS-
Based Distortion Model. In TMI, Sko?vde, Sweden.
Helmut Schmid and Florian Laws. 2008. Estimation of
Conditional Probabilities with Decision Trees and an
Application to Fine-Grained POS Tagging. In COL-
ING 2008, Manchester, Great Britain.
Helmut Schmid. 1994. Probabilistic Part-of-Speech Tag-
ging Using Decision Trees. In International Con-
ference on New Methods in Language Processing,
Manchester, UK.
Andreas Stolcke. 2002. SRILM ? An Extensible Lan-
guage Modeling Toolkit. In Proc. of ICSLP, Denver,
Colorado, USA.
Ashish Venugopal, Andreas Zollman, and Alex Waibel.
2005. Training and Evaluation Error Minimization
Rules for Statistical Machine Translation. In Work-
shop on Data-drive Machine Translation and Beyond
(WPT-05), Ann Arbor, MI.
Stephan Vogel. 2003. SMT Decoder Dissected: Word
Reordering. In Int. Conf. on Natural Language Pro-
cessing and Knowledge Engineering, Beijing, China.
355
Proceedings of the 7th Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 39?47,
Atlanta, Georgia, 13 June 2013. c?2013 Association for Computational Linguistics
Combining Word Reordering Methods on different Linguistic Abstraction
Levels for Statistical Machine Translation
Teresa Herrmann, Jan Niehues, Alex Waibel
Institute for Anthropomatics
Karlsruhe Institute of Technology
Karlsruhe, Germany
{teresa.herrmann,jan.niehues,alexander.waibel}@kit.edu
Abstract
We describe a novel approach to combin-
ing lexicalized, POS-based and syntactic tree-
based word reordering in a phrase-based ma-
chine translation system. Our results show
that each of the presented reordering meth-
ods leads to improved translation quality on its
own. The strengths however can be combined
to achieve further improvements. We present
experiments on German-English and German-
French translation. We report improvements
of 0.7 BLEU points by adding tree-based and
lexicalized reordering. Up to 1.1 BLEU points
can be gained by POS and tree-based reorder-
ing over a baseline with lexicalized reorder-
ing. A human analysis, comparing subjec-
tive translation quality as well as a detailed er-
ror analysis show the impact of our presented
tree-based rules in terms of improved sentence
quality and reduction of errors related to miss-
ing verbs and verb positions.
1 Introduction
One of the main difficulties in statistical machine
translation (SMT) is presented by the different word
orders between languages. Most state-of-the-art
phrase-based SMT systems handle it within phrase
pairs or during decoding by allowing words to be
swapped while translation hypotheses are generated.
An additional reordering model might be included in
the log-linear model of translation. However, these
methods can cover reorderings only over a very lim-
ited distance. Recently, reordering as preprocessing
has drawn much attention. The idea is to detach the
reordering problem from the decoding process and
to apply a reordering model prior to translation in
order to facilitate a monotone translation.
Encouraged by the improvements that can be
achieved with part-of-speech (POS) reordering rules
(Niehues and Kolss, 2009; Rottmann and Vogel,
2007), we apply such rules on a different linguis-
tic level. We abstract from the words in the sentence
and learn reordering rules based on syntactic con-
stituents in the source language sentence. Syntac-
tic parse trees represent the sentence structure and
show the relations between constituents in the sen-
tence. Relying on syntactic constituents instead of
POS tags should help to model the reordering task
more reliably, since sentence constituents are moved
as whole blocks of words, thus keeping the sentence
structure intact.
In addition, we combine the POS-based and syn-
tactic tree-based reordering models and also add a
lexicalized reordering model, which is used in many
state-of-the-art phrase-based SMT systems nowa-
days.
2 Related Work
The problem of word reordering has been addressed
by several approaches over the last years.
In a phrase-based SMT system reordering can
be achieved during decoding by allowing swaps of
words within a defined window. Lexicalized re-
ordering models (Koehn et al, 2005; Tillmann,
2004) include information about the orientation of
adjacent phrases that is learned during phrase extrac-
tion. This reordering method, which affects the scor-
ing of translation hypotheses but does not generate
new reorderings, is used e.g. in the open source ma-
39
chine translation system Moses (Koehn et al, 2007).
Syntax-based (Yamada and Knight, 2001) or
syntax-augmented (Zollmann and Venugopal, 2006)
MT systems address the reordering problem by em-
bedding syntactic analysis in the decoding process.
Hierarchical MT systems (Chiang, 2005) construct
a syntactic hierarchy during decoding, which is in-
dependent of linguistic categories.
To our best knowledge Xia and McCord (2004)
were the first to model the word reordering problem
as a preprocessing step. They automatically learn
reordering rules for English-French translation from
source and target language dependency trees. After-
wards, many followed these footsteps. Earlier ap-
proaches craft reordering rules manually based on
syntactic or dependency parse trees or POS tags de-
signed for particular languages (Collins et al, 2005;
Popovic? and Ney, 2006; Habash, 2007; Wang et al,
2007). Later there were more and more approaches
using data-driven methods. Costa-jussa` and Fonol-
losa (2006) frame the word reordering problem as
a translation task and use word class information
to translate the original source sentence into a re-
ordered source sentence that can be translated more
easily. A very popular approach is to automatically
learn reordering rules based on POS tags or syn-
tactic chunks (Popovic? and Ney, 2006; Rottmann
and Vogel, 2007; Zhang et al, 2007; Crego and
Habash, 2008). Khalilov et al (2009) present re-
ordering rules learned from source and target side
syntax trees. More recently, Genzel (2010) proposed
to automatically learn reordering rules from IBM1
alignments and source side dependency trees. In
DeNero and Uszkoreit (2011) no parser is needed,
but the sentence structure used for learning the re-
ordering model is induced automatically from a par-
allel corpus. Among these approaches most are able
to cover short-range reorderings and some store re-
ordering variants in a word lattice leaving the selec-
tion of the path to the decoder. Long-range reorder-
ings are addressed by manual rules (Collins et al,
2005) or using automatically learned rules (Niehues
and Kolss, 2009).
Motivated by the POS-based reordering models
in Niehues and Kolss (2009) and Rottmann and Vo-
gel (2007), we present a reordering model based on
the syntactic structure of the source sentence. We
intend to cover both short-range and long-range re-
ordering more reliably by abstracting to constituents
extracted from syntactic parse trees instead of work-
ing only with morphosyntactic information on the
word level. Furthermore, we combine POS-based
and tree-based models and additionally include a
lexicalized reordering model. Altogether we apply
word reordering on three different levels: lexical-
ized reordering model on the word level, POS-based
reordering on the morphosyntactic level and syntax
tree-based reordering on the constituent level. In
contrast to previous work we use original syntactic
parse trees instead of binarized parse trees or depen-
dency trees. Furthermore, our goal is to address es-
pecially long-range reorderings involving verb con-
structions.
3 Motivation
When translating from German to English different
word order is the most prominent problem. Espe-
cially the verb needs to be shifted over long dis-
tances in the sentence, since the position of the verb
differs in German and English sentences. The finite
verbs in the English language are generally located
at the second position in the sentence. In German
this is only the case in a main clause. In German
subordinate clauses the verb is at the final position
as shown in Example 1.
Example 1:
Source: ..., nachdem ich eine Weile im Inter-
net gesucht habe.
Gloss: ... after I a while in-the internet
searched have.
POS Reord.: ..., nachdem ich habe eine Weile im
Internet gesucht.
POS Transl.: ... as I have for some time on the
Internet.
The example shows first the source sentence and
an English gloss. POS Reord presents the reordered
source sentence as produced by POS rules. This
should be the source sentence according to target
language word order. POS Transl shows the trans-
lation of the reordered sequence. We can see that
some cases remain unresolved. The POS rules suc-
ceed in putting the auxiliary habe/have to the right
position in the sentence. But the participle, carry-
ing the main meaning of the sentence, is not shifted
together with the auxiliary. During translation it is
40
dropped from the sentence, rendering it unintelligi-
ble.
A reason why the POS rules do not shift both
parts of the verb might be that the rules operate on
the word level only and treat every POS tag inde-
pendently of the others. A reordering model based
on syntactic constituents can help with this. Addi-
tional information about the syntactic structure of
the sentence allows to identify which words belong
together and should not be separated, but shifted as
a whole block. Abstracting from the word level to
the constituent level also provides the advantage that
even though reorderings are performed over long
sentence spans, the rules consist of less reordering
units (constituents which themselves consist of con-
stituents or words) and can be learned more reliably.
4 Tree-based Reordering
In order to encourage linguistically meaningful re-
orderings we learn rules based on syntactic tree con-
stituents. While the POS-based rules are flat and
perform the reordering on a sequence of words, the
tree-based rules operate on subtrees in the parse tree
as shown in Figure 1.
VP
VVPPNPPTNEG
?
VP
NPVVPPPTNEG
Figure 1: Example reordering rule based on subtrees
A syntactic parse tree contains both the word-
level categories, i.e. parts-of-speech and higher or-
der categories, i.e. constituents. In this way it pro-
vides information about the building blocks of a sen-
tence that belong together and should not be taken
apart by reordering. Consequently, the tree-based
reordering operates both on the word level and on
the constituent level to make use of all available in-
formation in the parse tree. It is able to handle long-
range reorderings as well as short-range reorder-
ings, depending on how many words the reordered
constituents cover. The tree-based reordering rules
should also be more stable and introduce less ran-
dom word shuffling than the POS-based rules.
The reordering model consists of two stages. First
the rule extraction, where the rules are learned by
searching the training corpus for crossing align-
ments which indicate a reordering between source
and target language. The second is the application
of the learned reordering rules to the input text prior
to translation.
4.1 Rule Extraction
As shown in Figure 4 we learn rules like this:
VP PTNEG NP VVPP? VP PTNEG VVPP NP
where the first item in the rule is the head node of
the subtree and the rest represent the children. In
the second part of the rule the children are indexed
so that children of the same category cannot be con-
fused. Figure 2 shows an example for rule extrac-
tion: a sentence in its syntactic parse tree representa-
tion, the sentence in the target language and an auto-
matically generated alignment. A reordering occurs
between the constituents VVPP and NP.
S
1-n
CS
...
VP
2-5
VVPP
3-3
gewa?hlt
NP
4-5
NN
5-5
Szenarien
ADJA
4-4
ku?nstliche
PTNEG
2-2
nicht
VAFIN
2-2
haben
PPER
1-1
Wir
1
We
2
didn?t
3
choose
4
artificial
5
scenarios
Figure 2: Example training sentence used to extract re-
ordering rules
In a first step the reordering rule has to be found.
We extract the rules from a word aligned corpus
where a syntactic parse tree is provided for each
source side sentence. We traverse the tree top down
and scan each subtree for reorderings, i.e. cross-
ings of alignment links between source and target
sentence. If there is a reordering, we extract a
rule that rearranges the source side constituents ac-
cording to the order of the corresponding words on
41
the target side. Each constituent in a subtree com-
prises one or more words. We determine the lowest
(min) and highest (max) alignment point for each
constituent ck and thus determine the range of the
constituent on the target side. This can be formal-
ized as min(ck) = min{j|fi ? ck; ai = j} and
max(ck) = max{j|fi ? ck; ai = j}. To illustrate
the process, we have annotated the parse tree in Fig-
ure 2 with the alignment points (min-max) for each
constituent.
After defining the range, we check for the follow-
ing conditions in order to determine whether to ex-
tract a reordering rule.
1. all constituents have a non-empty range
2. source and target word order differ
First, for each subtree at least one word in each con-
stituent needs to be aligned. Otherwise it is not pos-
sible to determine a conclusive order. Second, we
check whether there is actually a reordering, i.e. the
target language words are not in the same order as
the constituents in the source language: min(ck) >
min(ck+1) and max(ck) > max(ck+1).
Once we find a reordering rule to extract, we cal-
culate the probability of this rule as the relative fre-
quency with which such a reordering occurred in all
subtrees of the training corpus divided by the num-
ber of total occurrences of this subtree in the corpus.
We only store rules for reorderings that occur more
than 5 times in the corpus.
4.1.1 Partial Rules
The syntactic parse trees of German sentences are
quite flat, i.e. a subtree usually has many children.
When a rule is extracted, it always consists of the
head of the subtree and all its children. The ap-
plication requires that the applicable rule matches
the complete subtree: the head and all its children.
However, most of the time only some of the chil-
dren are actually involved in a reordering. There
are also many different subtree variants that are quite
similar. In verb phrases or noun phrases, for exam-
ple, modifiers such as prepositional phrases or ad-
verbial phrases can be added nearly arbitrarily. In
order to generalize the tree-based reordering rules,
we extend the rule extraction. We do not only extract
the rules from the complete child sequence, but also
from any continuous child sequence in a constituent.
This way, we extract generalized rules which can
be applied more often. Formally, for each subtree
h ? cn1 = c1c2...cn that matches the constraints
presented in Section 4.1, we modify the basic rule
extraction to: ?i, j1 ? i < j ? n : h ? cji . It
could be argued that the partial rules might be not
as reliable as the specific rules. In Section 6 we will
show that such generalizations are meaningful and
can have a positive effect on the translation quality.
4.2 Rule Application
During the training of the system all reordering rules
are extracted from the parallel corpus. Prior to trans-
lation the rules are applied to the original source text.
Each rule is applied independently producing a re-
ordering variant of that sentence. The original sen-
tence and all reordering variants are stored in a word
lattice which is later used as input to the decoder.
The rules may be applied recursively to already re-
ordered paths. If more than one rule can be applied,
all paths are added to the lattice unless the rules gen-
erate the same output. In this case only the rule with
the highest probability is applied.
The edges in a word lattice for one sentence are
assigned transition probabilities as follows. In the
monotone path with original word order all transi-
tion probabilities are initially set to 1. In a reordered
path the first branching transition is assigned the
probability of the rule that generated the path. All
other transition probabilities in this path are set to 1.
Whenever a reordered path branches from the mono-
tone path, the probability of the branching edge is
substracted from the probability of the monotone
edge. However, a minimum probability of 0.05 is
reserved for the monotone edge. The score of the
complete path is computed as the product of the tran-
sition probabilities. During decoding the best path
is searched for by including the score for the cur-
rent path weighted by the weight for the reordering
model in the log-linear model. In order to enable
efficient decoding we limit the lattice size by only
applying rules with a probability higher than a pre-
defined threshold.
4.2.1 Recursive Rule Application
As mentioned above, the tree-based rules may be
applied recursively. That means, after one rule is
applied to the source sentence, a reordered path may
42
SS
aus anderen Bundesla?ndern
PP
VAFIN
habe
VP
VVPP
bekommen
viele Anfragen
NP
ADV
schon
PPER
ich
KOUS
dass
Ich kann Ihnen nur sagen,
...
I may just tell you that I got already lots of requests from other federal states
Figure 3: Example parse tree with separated verb particles
be reordered again. The reason is the structure of
the syntactic parse trees. Verbs and their particles
are typically not located within the same subtree.
Hence, they cannot be covered by one reordering
rule. A separate rule is extracted for each subtree.
Figure 3 demonstrates this in an example. The two
parts that belong to the verb in this German sentence,
namely bekommen and habe, are not located within
the same constituent. The finite verb habe forms a
constituent of its own and the participle bekommen
forms part of the VP constituent. In English the fi-
nite verb and the participle need to be placed next to
each other. In order to rearrange the source language
words according to the target language word order,
the following two reordering movements need to be
performed: the finite verb habe needs to be placed
before the VP constituent and the participle bekom-
men needs to be moved within the VP constituent to
the first position. Only if both movements are per-
formed, the right word order can be generated.
However, the reordering model only considers
one subtree at a time when extracting reordering
rules. In this case two rules are learned, but if they
are applied to the source sentence separately, they
will end up in separate paths in the word lattice. The
decoder then has to choose which path to translate:
the one where the finite verb is placed before the VP
constituent or the path where the participle is at the
first position in the VP constituent.
To counter this drawback the rules may be applied
recursively to the new paths created by our reorder-
ing rules. We use the same rules, but newly created
paths are fed back into the queue of sentences to be
reordered. However, we only apply the rules to parts
of the reordered sentence that are still in the original
word order and restrict the recursion depth.
5 Combining reordering methods
In order to get a deeper insight into their individ-
ual strengths we compare the reordering methods on
different linguistic levels and also combine them to
investigate whether gains can be increased. We ad-
dress the word level using the lexicalized reordering,
the morphosyntactic level by POS-based reordering
and the constituent level by tree-based reordering.
5.1 POS-based and tree-based rules
The training of the POS-based reordering is per-
formed as described in (Rottmann and Vogel,
2007) for short-range reordering rules, such as
VVIMP VMFIN PPER ? PPER VMFIN VVIMP.
Long-range reordering rules trained according
to (Niehues and Kolss, 2009) include gaps match-
ing longer spans of arbitrary POS sequences
(VAFIN * VVPP ? VAFIN VVPP *). The POS-
based reordering used in our experiments always in-
cludes both short and long-range rules.
The tree-based rules are trained separately as de-
scribed above. First the POS-based rules are applied
to the monotone path of the source sentence and then
43
the tree-based rules are applied independently, pro-
ducing separate paths.
5.2 Rule-based and lexicalized reordering
As described in Section 4.2 we create word lattices
that encode the reordering variants. The lexical-
ized reordering model stores for each phrase pair
the probabilities for possible reordering orientations
at the incoming and outgoing phrase boundaries:
monotone, swap and discontinuous. In order to ap-
ply the lexicalized reordering model on lattices the
original position of each word is stored in the lat-
tice. While the translation hypothesis is generated,
the reordering orientation with respect to the origi-
nal position of the words is checked at each phrase
boundary. The probability for the respective orien-
tation is included as an additional score.
6 Results
The tree-based models are applied for German-
English and German-French translation. Results are
measured in case-sensitive BLEU (Papineni et al,
2002).
6.1 General System Description
First we describe the general system architecture
which underlies all the systems used later on. We
use a phrase-based decoder (Vogel, 2003) that takes
word lattices as input. Optimization is performed
using MERT with respect to BLEU. All POS-based
or tree-based systems apply monotone translation
only. Baseline systems without reordering rules use
a distance-based reordering model. In addition, a
lexicalized reordering model as described in (Koehn
et al, 2005) is applied where indicated. POS tags
and parse trees are generated using the Tree Tag-
ger (Schmid, 1994) and the Stanford Parser (Raf-
ferty and Manning, 2008).
6.1.1 Data
The German-English system is trained on the pro-
vided data of the WMT 2012. news-test2010 and
news-test2011 are used for development and test-
ing. The type of data used for training, development
and testing the German-French system is similar to
WMT data, except that 2 references are available.
The training corpus for the reordering models con-
sist of the word-aligned Europarl and News Com-
mentary corpora where POS tags and parse trees are
generated for the source side.
6.2 German-English
We built systems using POS-based and tree-based
reordering and show the impact of the individual
models as well as their combination on the transla-
tion quality. The results are presented in Table 1.
For each system, two different setups were evalu-
ated. First, with a distance-based reordering model
only (noLexRM) and with an additional lexicalized
reordering model (LexRM). The baseline system
which uses no reordering rules at all allows a re-
ordering window of 5 in the decoder for both setups.
For all systems where reordering rules are applied,
monotone translation is performed. Since the rules
take over the main reordering job, only monotone
translation is necessary from the reordered word lat-
tice input. In this experiment, we compare the tree-
based rules with and without recursion, and the par-
tial rules.
Rule Type
System noLexRM LexRM
Dev Test Dev Test
Baseline (no Rules) 22.82 21.06 23.54 21.61
POS 24.33 21.98 24.42 22.15
Tree 24.01 21.92 24.24 22.01
Tree rec. 24.37 21.97 24.53 22.19
Tree rec.+ par. 24.31 22.21 24.65 22.27
POS + Tree 24.57 22.21 24.91 22.47
POS + Tree rec. 24.61 22.39 24.81 22.45
POS + Tree rec.+ par. 24.80 22.45 24.78 22.70
Table 1: German-English
Compared to the baseline system using distance-
based reordering only, 1.4 BLEU points can be
gained by applying combined POS and tree-based
reordering. The tree rules including partial rules and
recursive application alone achieve already a bet-
ter performance than the POS rules, but using them
all in combination leads to an improvement of 0.4
BLEU points over the POS-based reordering alone.
When lexicalized reordering is added, the relative
improvements are similar: 1.1 BLEU points com-
pared to the Baseline and 0.55 BLEU points over the
POS-based reordering. We can therefore argue that
the individual rule types as well as the lexicalized re-
ordering model seem to address complementary re-
ordering issues and can be combined successfully to
44
obtain an even better translation quality.
We applied only tree rules with a probability of
0.1 and higher. Partial rules require a threshold of
0.4 to be applied, since they are less reliable. In or-
der to prevent the lattices from growing too large,
the recursive rule application is restricted to a max-
imum recursion depth of 3. These values were set
according to the results of preliminary experiments
investigating the impact of the rule probabilities on
the translation quality. Normal rules and partial rules
are not mixed during recursive application.
With the best system we performed a final exper-
iment on the official testset of the WMT 2012 and
achieved a score of 23.73 which is 0.4 BLEU points
better than the best constrained submission.
6.3 Translation Examples
Example 2 shows how the translation of the sen-
tence presented above is improved by adding the
tree-based rules. We can see that using tree con-
stituents in the reordering model indeed addresses
the problem of verb particles and especially missing
verb parts in German.
Example 2:
Src: ..., nachdem ich eine Weile im Internet
gesucht habe.
Gloss: ..., after I a while in-the Internet search-
ed have.
POS: ... as I have for some time on the Inter-
net.
+Tree: ... after I have looked for a while on the
Internet.
Example 3 shows another aspect of how the tree-
based rules work. With the help of the tree-based re-
ordering rules, it is possible to relocate the separated
prefix of German verbs and find the correct transla-
tion. The verb vorschlagen consist of the main verb
(MV) schlagen (here conjugated as schla?gt) and the
prefix (PX) vor. Depending on the verb form and
sentence type, the prefix must be separated from the
main verb and is located in a different part of the
sentence. The two parts of the verb can also have
individual meanings. Although the translation of
the verb stem were correct if it were the full verb,
not recognizing the separated prefix and ignoring it
in translation, corrupts the meaning of the sentence.
With the help of the tree-based rules, the dependency
between the main verb and its prefix is resolved and
the correct translation can be chosen.
6.4 German-French
The same experiments were tested on German-
French translation. For this language pair, similar
improvements could be achieved by combining POS
and tree-based reordering rules and applying a lexi-
calized reordering model in addition. Table 2 shows
the results. Up to 0.7 BLEU points could be gained
by adding tree rules and another 0.1 by lexicalized
reordering.
Rule Type
System noLexRM LexRM
Dev Test Dev Test
POS 41.29 38.07 42.04 38.55
POS + Tree 41.94 38.47 42.44 38.57
POS + Tree rec. 42.35 38.66 42.80 38.71
POS + Tree rec.+ par. 42.48 38.79 42.87 38.88
Table 2: German-French
6.5 Binarized Syntactic Trees
Even though related work using syntactic parse trees
in SMT for reordering purposes (Jiang et al, 2010)
have reported an advantage of binarized parse trees
over standard parse trees, our model did not bene-
fit from binarized parse trees. It seems that the flat
hierarchical structure of standard parse trees enables
our reordering model to learn the order of the con-
stituents most efficiently.
7 Human Evaluation
7.1 Sentence-based comparison
In order to have an additional perspective of the
impact of our tree-based reordering, we also pro-
vide a human evaluation of the translation output
of the German-English system without the lexical-
ized reordering model. 250 translation hypotheses
were selected to be annotated. For each input sen-
tence two translations generated by different sys-
tems were presented, one applying POS-based re-
ordering only and the other one applying both POS-
based and tree-based reordering rules. The hypothe-
ses were anonymized and presented in random order.
Table 3 shows the BLEU scores of the analyzed
systems and the manual judgement of comparative,
subjective translation quality. In 50.8% of the sen-
45
Example 3:
Src: Die RPG Byty schla?gt ihnen in den Schreiben eine Mieterho?hung von ca. 15 bis 38 Prozent vor.
Gloss: The RPG Byty proposes-MV them in the letters a rent increase of ca. 15 to 38 percent proposes-PX
POS: The RPG Byty beats them in the letter, a rental increase of around 15 to 38 percent.
+Tree: The RPG Byty proposes them in the letters a rental increase of around 15 to 38 percent.
System BLEU wins %
POS Rules 21.98 58 23.2
POS + Tree Rules rec. par. 22.45 127 50.8
Table 3: Human Evaluation of Translation quality
tences, the translation generated by the system us-
ing tree-based rules was judged to be better, whereas
in 23.2% of the cases the system without tree-based
rules was rated better. For 26% of the sentences the
translation quality was very similar. Consequently,
in 76.8% of the cases the tree-based system pro-
duced a translation that is either better or of the same
quality as the system using POS rules only.
7.2 Analysis of verbs
Since the verbs in German-to-English translation
were one of the issues that the tree-based reorder-
ing model should address, a more detailed analysis
was performed on the first 165 sentences. We espe-
cially investigated the changes regarding the verbs
between the translations stemming from the system
using the POS-based reordering only and the one us-
ing both the POS and the tree-based model. We ex-
amined three aspects of the verbs in the two trans-
lations. Each change introduced by the tree-based
reordering model was first classified either as an im-
provement or a degradation of the translation qual-
ity. Secondly, it was assigned to one of the following
categories: exist, position or form. In case of an im-
provement, exist means a verb existed in the trans-
lation due to the tree-based model, which did not
exist before. A degradation in this category means
that a verb was removed from the translation when
including the tree-based reordering model. An im-
provement or degradation in the category position
or form means that the verb position or verb form
was improved or degraded, respectively.
Table 4 shows the results of this analysis. In total,
48 of the verb changes were identified as improve-
ments, while only 16 were regarded as degradations
of translation quality. Improvements mainly concern
Type all exist position form
Improvements 48 22 21 5
Degradations 16 2 11 3
Table 4: Manual Analysis of verbs
improved verb position in the sentence and verbs
that could be translated with the help of the tree-
based rules that were not there before. Even though
also degradations were introduced by the tree-based
reordering model, the improvements outweigh them.
8 Conclusion
We have presented a reordering method based on
syntactic tree constituents to model long-range re-
orderings in SMT more reliably. Furthermore, we
combined the reordering methods addressing dif-
ferent linguistic abstraction levels. Experiments
on German-English and German-French translation
showed that the best translation quality could be
achieved by combining POS-based and tree-based
rules. Adding a lexicalized reordering model in-
creased the translation quality even further. In total
we could reach up to 0.7 BLEU points of improve-
ment by adding tree-based and lexicalized reorder-
ing compared to only POS-based rules. Up to 1.1
BLEU points were gained over to a baseline system
using a lexicalized reordering model.
A human evaluation showed a preference of the
POS+Tree-based reordering method in most cases.
A detailed analysis of the verbs in the transla-
tion outputs revealed that the tree-based reordering
model indeed addresses verb constructions and im-
proves the translation of German verbs.
Acknowledgments
This work was partly achieved as part of the Quaero
Programme, funded by OSEO, French State agency
for innovation. The research leading to these results
has received funding from the European Union Sev-
enth Framework Programme (FP7/2007-2013) un-
der grant agreement n? 287658.
46
References
David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In Proceedings of
the 43rd Annual Meeting on Association for Computa-
tional Linguistics, ACL ?05, pages 263?270, Strouds-
burg, PA, USA.
Michael Collins, Philipp Koehn, and Ivona Kuc?erova?.
2005. Clause Restructuring for Statistical Machine
Translation. In Proceedings of ACL 2005, Ann Arbor,
Michigan.
Marta R. Costa-jussa` and Jose? A. R. Fonollosa. 2006.
Statistical Machine Reordering. In Conference on
Empirical Methods on Natural Language Processing
(EMNLP 2006), Sydney, Australia.
Josep M. Crego and Nizar Habash. 2008. Using Shallow
Syntax Information to Improve Word Alignment and
Reordering for SMT. In ACL-HLT 2008, Columbus,
Ohio, USA.
John DeNero and Jakob Uszkoreit. 2011. Inducing sen-
tence structure from parallel corpora for reordering. In
Proceedings of EMNLP 2011, pages 193?203, Edin-
burgh, Scotland, UK.
Dmitriy Genzel. 2010. Automatically learning source-
side reordering rules for large scale machine transla-
tion. In Proceedings of COLING 2010, Beijing, China.
Nizar Habash. 2007. Syntactic preprocessing for statis-
tical machine translation. Proceedings of the 11th MT
Summit.
Jie Jiang, Jinhua Du, and Andy Way. 2010. Improved
phrase-based smt with syntactic reordering patterns
learned from lattice scoring. In Proceedings of AMTA
2010, Denver, CO, USA.
M. Khalilov, J.A.R. Fonollosa, and M. Dras. 2009.
A new subtree-transfer approach to syntax-based re-
ordering for statistical machine translation. In Proc.
of the 13th Annual Conference of the European As-
sociation for Machine Translation (EAMT?09), pages
198?204, Barcelona, Spain.
Philipp Koehn, Amittai Axelrod, Alexandra Birch
Mayne, Chris Callison-Burch, Miles Osborne, and
David Talbot. 2005. Edinburgh system description for
the 2005 iwslt speech translation evaluation. In Inter-
national Workshop on Spoken Language Translation.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, et al 2007. Moses: Open source toolkit for
statistical machine translation. In Annual meeting-
association for computational linguistics, volume 45,
page 2.
Jan Niehues and Muntsin Kolss. 2009. A POS-Based
Model for Long-Range Reorderings in SMT. In
Fourth Workshop on Statistical Machine Translation
(WMT 2009), Athens, Greece.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic
Evaluation of Machine Translation. Technical Report
RC22176 (W0109-022), IBM Research Division, T. J.
Watson Research Center.
Maja Popovic? and Hermann Ney. 2006. POS-based
Word Reorderings for Statistical Machine Translation.
In International Conference on Language Resources
and Evaluation (LREC 2006), Genoa, Italy.
Anna N. Rafferty and Christopher D. Manning. 2008.
Parsing three German treebanks: lexicalized and un-
lexicalized baselines. In Proceedings of the Workshop
on Parsing German, Columbus, Ohio.
Kay Rottmann and Stephan Vogel. 2007. Word Reorder-
ing in Statistical Machine Translation with a POS-
Based Distortion Model. In TMI, Sko?vde, Sweden.
Helmut Schmid. 1994. Probabilistic Part-of-Speech Tag-
ging Using Decision Trees. In International Con-
ference on New Methods in Language Processing,
Manchester, UK.
Christoph Tillmann. 2004. A unigram orientation model
for statistical machine translation. In Proceedings of
HLT-NAACL 2004: Short Papers, pages 101?104.
Stephan Vogel. 2003. SMT Decoder Dissected: Word
Reordering. In Int. Conf. on Natural Language Pro-
cessing and Knowledge Engineering, Beijing, China.
Chao Wang, Michael Collins, and Philipp Koehn. 2007.
Chinese syntactic reordering for statistical machine
translation. In Proceedings of the 2007 Joint Confer-
ence on Empirical Methods in Natural Language Pro-
cessing and Computational Natural Language Learn-
ing (EMNLP-CoNLL), pages 737?745.
Fei Xia and Michael McCord. 2004. Improving a sta-
tistical mt system with automatically learned rewrite
patterns. In Proceedings of COLING 2004, Geneva,
Switzerland.
Kenji Yamada and Kevin Knight. 2001. A syntax-
based statistical translation model. In Proceedings of
the 39th Annual Meeting on Association for Computa-
tional Linguistics, ACL ?01, pages 523?530, Strouds-
burg, PA, USA.
Yuqi Zhang, Richard Zens, and Hermann Ney. 2007.
Chunk-Level Reordering of Source Language Sen-
tences with Automatically Learned Rules for Statis-
tical Machine Translation. In HLT-NAACL Work-
shop on Syntax and Structure in Statistical Transla-
tion, Rochester, NY, USA.
Andreas Zollmann and Ashish Venugopal. 2006. Syntax
augmented machine translation via chart parsing. In
Proceedings of the Workshop on Statistical Machine
Translation, StatMT ?06, pages 138?141, Stroudsburg,
PA, USA.
47
Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 104?108,
Sofia, Bulgaria, August 8-9, 2013 c?2013 Association for Computational Linguistics
The Karlsruhe Institute of Technology Translation Systems
for the WMT 2013
Eunah Cho, Thanh-Le Ha, Mohammed Mediani, Jan Niehues,
Teresa Herrmann, Isabel Slawik and Alex Waibel
Karlsruhe Institute of Technology
Karlsruhe, Germany
firstname.lastname@kit.edu
Abstract
This paper describes the phrase-based
SMT systems developed for our partici-
pation in the WMT13 Shared Translation
Task. Translations for English?German
and English?French were generated us-
ing a phrase-based translation system
which is extended by additional models
such as bilingual, fine-grained part-of-
speech (POS) and automatic cluster lan-
guage models and discriminative word
lexica (DWL). In addition, we combined
reordering models on different sentence
abstraction levels.
1 Introduction
In this paper, we describe our systems for the
ACL 2013 Eighth Workshop on Statistical Ma-
chine Translation. We participated in the Shared
Translation Task and submitted translations for
English?German and English?French using a
phrase-based decoder with lattice input.
The paper is organized as follows: the next sec-
tion gives a detailed description of our systems
including all the models. The translation results
for all directions are presented afterwards and we
close with a conclusion.
2 System Description
The phrase table is based on a GIZA++ word
alignment for the French?English systems. For
the German?English systems we use a Discrim-
inative Word Alignment (DWA) as described in
Niehues and Vogel (2008). For every source
phrase only the top 10 translation options are con-
sidered during decoding. The SRILM Toolkit
(Stolcke, 2002) is used for training SRI language
models using Kneser-Ney smoothing.
For the word reordering between languages, we
used POS-based reordering models as described in
Section 4. In addition to it, tree-based reordering
model and lexicalized reordering were added for
German?English systems.
An in-house phrase-based decoder (Vogel,
2003) is used to perform translation. The trans-
lation was optimized using Minimum Error Rate
Training (MERT) as described in Venugopal et
al. (2005) towards better BLEU (Papineni et al,
2002) scores.
2.1 Data
The Europarl corpus (EPPS) and News Commen-
tary (NC) corpus were used for training our trans-
lation models. We trained language models for
each language on the monolingual part of the
training corpora as well as the News Shuffle and
the Gigaword corpora. The additional data such as
web-crawled corpus, UN and Giga corpora were
used after filtering. The filtering work for this data
is discussed in Section 3.
For the German?English systems we use the
news-test2010 set for tuning, while the news-
test2011 set is used for the French?English sys-
tems. For testing, news-test2012 set was used for
all systems.
2.2 Preprocessing
The training data is preprocessed prior to train-
ing the system. This includes normalizing special
symbols, smart-casing the first word of each sen-
tence and removing long sentences and sentence
pairs with length mismatch.
Compound splitting is applied to the German
part of the corpus of the German?English system
as described in Koehn and Knight (2003).
3 Filtering of Noisy Pairs
The filtering was applied on the corpora which
are found to be noisy. Namely, the Giga English-
French parallel corpus and the all the new web-
crawled data . The operation was performed using
104
an SVM classifier as in our past systems (Medi-
ani et al, 2011). For each pair, the required lexica
were extracted from Giza alignment of the corre-
sponding EPPS and NC corpora. Furthermore, for
the web-crawled data, higher precision classifiers
were trained by providing a larger number of neg-
ative examples to the classifier.
After filtering, we could still find English sen-
tences in the other part of the corpus. Therefore,
we performed a language identification (LID)-
based filtering afterwards (performed only on the
French-English corpora, in this participation).
4 Word Reordering
Word reordering was modeled based on POS se-
quences. For the German?English system, re-
ordering rules learned from syntactic parse trees
were used in addition.
4.1 POS-based Reordering Model
In order to train the POS-based reordering model,
probabilistic rules were learned based on the POS
tags from the TreeTagger (Schmid and Laws,
2008) of the training corpus and the alignment. As
described in Rottmann and Vogel (2007), continu-
ous reordering rules are extracted. This modeling
of short-range reorderings was extended so that it
can cover also long-range reorderings with non-
continuous rules (Niehues and Kolss, 2009), for
German?English systems.
4.2 Tree-based Reordering Model
In addition to the POS-based reordering, we
apply a tree-based reordering model for the
German?English translation to better address the
differences in word order between German and
English. We use the Stanford Parser (Rafferty and
Manning, 2008) to generate syntactic parse trees
for the source side of the training corpus. Then
we use the word alignment between source and
target language to learn rules on how to reorder
the constituents in a German source sentence to
make it match the English target sentence word or-
der better (Herrmann et al, 2013). The POS-based
and tree-based reordering rules are applied to each
input sentence. The resulting reordered sentence
variants as well as the original sentence order are
encoded in a word lattice. The lattice is then used
as input to the decoder.
4.3 Lexicalized Reordering
The lexicalized reordering model stores the re-
ordering probabilities for each phrase pair. Pos-
sible reordering orientations at the incoming and
outgoing phrase boundaries are monotone, swap
or discontinuous. With the POS- and tree-based
reordering word lattices encode different reorder-
ing variants. In order to apply the lexicalized re-
ordering model, we store the original position of
each word in the lattice. At each phrase boundary
at the end, the reordering orientation with respect
to the original position of the words is checked.
The probability for the respective orientation is in-
cluded as an additional score.
5 Translation Models
In addition to the models used in the baseline sys-
tem described above, we conducted experiments
including additional models that enhance trans-
lation quality by introducing alternative or addi-
tional information into the translation modeling
process.
5.1 Bilingual Language Model
During the decoding the source sentence is seg-
mented so that the best combination of phrases
which maximizes the scores is available. How-
ever, this causes some loss of context information
at the phrase boundaries. In order to make bilin-
gual context available, we use a bilingual language
model (Niehues et al, 2011). In the bilingual lan-
guage model, each token consists of a target word
and all source words it is aligned to.
5.2 Discriminative Word Lexicon
Mauser et al (2009) introduced the Discriminative
Word Lexicon (DWL) into phrase-based machine
translation. In this approach, a maximum entropy
model is used to determine the probability of using
a target word in the translation.
In this evaluation, we used two extensions to
this work as shown in (Niehues and Waibel, 2013).
First, we added additional features to model the
order of the source words better. Instead of rep-
resenting the source sentence as a bag-of-words,
we used a bag-of-n-grams. We used n-grams up to
the order of three and applied count filtering to the
features for higher order n-grams.
Furthermore, we created the training examples
differently in order to focus on addressing errors
of the other models of the phrase-based translation
105
system. We first translated the whole corpus with a
baseline system. Then we only used the words that
occur in the N-Best List and not in the reference as
negative examples instead of using all words that
do not occur in the reference.
5.3 Quasi-Morphological Operations
Because of the inflected characteristic of the
German language, we try to learn quasi-
morphological operations that change the lexi-
cal entry of a known word form to the out-of-
vocabulary (OOV) word form as described in
Niehues and Waibel (2012).
5.4 Phrase Table Adaptation
For the French?English systems, we built two
phrase tables; one trained with all data and the
other trained only with the EPPS and NC cor-
pora. This is due to the fact that Giga corpus is big
but noisy and EPPS and NC corpus are more reli-
able. The two models are combined log-linearly to
achieve the adaptation towards the cleaner corpora
as described in Niehues et al (2010).
6 Language Models
The 4-gram language models generated by the
SRILM toolkit are used as the main language
models for all of our systems. For the
English?French systems, we use a good quality
corpus as in-domain data to train in-domain lan-
guage models. Additionally, we apply the POS
and cluster language models in different systems.
For the German?English system, we build sepa-
rate language models using each corpus and com-
bine them linearly before the decoding by mini-
mizing the perplexity. Language models are inte-
grated into the translation system by a log-linear
combination and receive optimal weights during
tuning by the MERT.
6.1 POS Language Models
For the English?German system, we use the POS
language model, which is trained on the POS se-
quence of the target language. The POS tags are
generated using the RFTagger (Schmid and Laws,
2008) for German. The RFTagger generates fine-
grained tags which include person, gender, and
case information. The language model is trained
with up to 9-gram information, using the German
side of the parallel EPPS and NC corpus, as well
as the News Shuffle corpus.
6.2 Cluster Language Models
In order to use larger context information, we use
a cluster language model for all our systems. The
cluster language model is based on the idea shown
in Och (1999). Using the MKCLS algorithm, we
cluster the words in the corpus, given a number
of classes. Then words in the corpus are replaced
with their cluster IDs. Using these cluster IDs,
we train n-gram language models as well as a
phrase table with this additional factor of cluster
ID. Our submitted systems have diversed range of
the number of clusters as well as n-gram.
7 Results
Using the models described above we performed
several experiments leading finally to the systems
used for generating the translations submitted to
the workshop. The results are reported as case-
sensitive BLEU scores on one reference transla-
tion.
7.1 German?English
The experiments for the German to English trans-
lation system are summarized in Table 1. The
baseline system uses POS-based reordering, DWA
with lattice phrase extraction and language models
trained on the News Shuffle corpus and Giga cor-
pus separately. Then we added a 5-gram cluster
LM trained with 1,000 word classes. By adding a
language model using the filtered crawled data we
gained 0.3 BLEU on the test set. For this we com-
bined all language models linearly. The filtered
crawled data was also used to generate a phrase
table, which brought another improvement of 0.85
BLEU. Applying tree-based reordering improved
the BLEU score, and the performance had more
gain by adding the extended DWL, namely us-
ing both bag-of-ngrams and n-best lists. While
lexicalized reordering gave us a slight gain, we
added morphological operation and gained more
improvements.
7.2 English?German
The English to German baseline system uses POS-
based reordering and language models using par-
allel data (EPPS and NC) as shown in Table 2.
Gradual gains were achieved by changing align-
ment from GIZA++ to DWA, adding a bilingual
language model as well as a language model based
on the POS tokens. A 9-gram cluster-based lan-
guage model with 100 word classes gave us a
106
System Dev Test
Baseline 24.15 22.79
+ Cluster LM 24.18 22.84
+ Crawled Data LM (Comb.) 24.53 23.14
+ Crawled Data PT 25.38 23.99
+ Tree Rules 25.80 24.16
+ Extended DWL 25.59 24.54
+ Lexicalized Reordering 26.04 24.55
+ Morphological Operation - 24.62
Table 1: Translation results for German?English
small gain. Improving the reordering using lexi-
alized reordering gave us gain on the optimization
set. Using DWL let us have more improvements
on our test set. By using the filtered crawled data,
we gained a big improvement of 0.46 BLEU on
the test set. Then we extended the DWL with bag
of n-grams and n-best lists to achieve additional
improvements. Finally, the best system includes
lattices generated using tree rules.
System Dev Test
Baseline 17.00 16.24
+ DWA 17.27 16.53
+ Bilingual LM 17.27 16.59
+ POS LM 17.46 16.66
+ Cluster LM 17.49 16.68
+ Lexicalized Reordering 17.57 16.68
+ DWL 17.58 16.77
+ Crawled Data 18.43 17.23
+ Extended DWL 18.66 17.57
+ Tree Rules 18.63 17.70
Table 2: Translation results for English?German
7.3 French?English
Table 3 reports some remarkable improvements
as we combined several techniques on the
French?English direction. The baseline system
was trained on parallel corpora such as EPPS, NC
and Giga, while the language model was trained
on the English part of those corpora plus News
Shuffle. The newly presented web-crawled data
helps to achieve almost 0.6 BLEU points more
on test set. Adding bilingual language model and
cluster language model does not show a significant
impact. Further gains were achieved by the adap-
tation of in-domain data into general-theme phrase
table, bringing 0.15 BLEU better on the test set.
When we added the DWL feature, it notably im-
proves the system by 0.25 BLEU points, resulting
in our best system.
System Dev Test
Baseline 30.33 29.35
+ Crawled Data 30.59 29.93
+ Bilingual and Cluster LMs 30.67 30.01
+ In-Domain PT Adaptation 31.17 30.16
+ DWL 31.07 30.40
Table 3: Translation results for French?English
7.4 English?French
In the baseline system, EPPS, NC, Giga and News
Shuffle corpora are used for language modeling.
The big phrase tables tailored EPPC, NC and Giga
data. The system also uses short-range reordering
trained on EPPS and NC. Adding parallel and fil-
tered crawl data improves the system. It was fur-
ther enhanced by the integration of a 4-gram bilin-
gual language model. Moreover, the best config-
uration of 9-gram language model trained on 500
clusters of French texts gains 0.25 BLEU points
improvement. We also conducted phrase-table
adaptation from the general one into the domain
covered by EPPS and NC data and it helps as well.
The initial try-out with lexicalized reordering fea-
ture showed an improvement of 0.23 points on the
development set, but a surprising reduction on the
test set, thus we decided to take the system after
adaptation as our best English?French system.
System Dev Test
Baseline 30.50 27.77
+ Crawled Data 31.05 27.87
+ Bilingual LM 31.23 28.50
+ Cluster LM 31.58 28.75
+ In-Domain PT Adaptation 31.88 29.12
+ Lexicalized Reordering 32.11 28.98
Table 4: Translation results for English?French
8 Conclusions
We have presented the systems for our par-
ticipation in the WMT 2013 Evaluation for
English?German and English?French. All sys-
tems use a class-based language model as well
as a bilingual language model. Using a DWL
with source context improved the translation qual-
ity of English?German systems. Also for these
systems, we could improve even more with a
tree-based reordering model. Special handling
107
of OOV words improved German?English sys-
tem, while for the inverse direction the language
model with fine-grained POS tags was helpful. For
English?French, phrase table adaptation helps to
avoid using wrong parts of the noisy Giga corpus.
9 Acknowledgements
This work was partly achieved as part of the
Quaero Programme, funded by OSEO, French
State agency for innovation. The research lead-
ing to these results has received funding from
the European Union Seventh Framework Pro-
gramme (FP7/2007-2013) under grant agreement
n? 287658.
References
Teresa Herrmann, Jan Niehues, and Alex Waibel.
2013. Combining Word Reordering Methods on
different Linguistic Abstraction Levels for Statisti-
cal Machine Translation. In Proceedings of the Sev-
enth Workshop on Syntax, Semantics and Structure
in Statistical Translation, Altanta, Georgia, USA,
June. Association for Computational Linguistics.
Philipp Koehn and Kevin Knight. 2003. Empirical
Methods for Compound Splitting. In EACL, Bu-
dapest, Hungary.
Arne Mauser, Sas?a Hasan, and Hermann Ney. 2009.
Extending Statistical Machine Translation with Dis-
criminative and Trigger-based Lexicon Models. In
Proceedings of the 2009 Conference on Empirical
Methods in Natural Language Processing: Volume
1 - Volume 1, EMNLP ?09, Singapore.
Mohammed Mediani, Eunah Cho, Jan Niehues, Teresa
Herrmann, and Alex Waibel. 2011. The kit english-
french translation systems for iwslt 2011. In Pro-
ceedings of the eight International Workshop on
Spoken Language Translation (IWSLT).
Jan Niehues and Muntsin Kolss. 2009. A POS-Based
Model for Long-Range Reorderings in SMT. In
Fourth Workshop on Statistical Machine Translation
(WMT 2009), Athens, Greece.
Jan Niehues and Stephan Vogel. 2008. Discriminative
Word Alignment via Alignment Matrix Modeling.
In Proc. of Third ACL Workshop on Statistical Ma-
chine Translation, Columbus, USA.
Jan Niehues and Alex Waibel. 2012. Detailed Analysis
of different Strategies for Phrase Table Adaptation
in SMT. In Proceedings of the American Machine
Translation Association (AMTA), San Diego, Cali-
fornia, October.
Jan Niehues and Alex Waibel. 2013. An MT Error-
driven Discriminative Word Lexicon using Sentence
Structure Features. In Eighth Workshop on Statisti-
cal Machine Translation (WMT 2013), Sofia, Bul-
garia.
Jan Niehues, Mohammed Mediani, Teresa Herrmann,
Michael Heck, Christian Herff, and Alex Waibel.
2010. The KIT Translation system for IWSLT 2010.
In Marcello Federico, Ian Lane, Michael Paul, and
Franc?ois Yvon, editors, Proceedings of the seventh
International Workshop on Spoken Language Trans-
lation (IWSLT), pages 93?98.
Jan Niehues, Teresa Herrmann, Stephan Vogel, and
Alex Waibel. 2011. Wider Context by Using Bilin-
gual Language Models in Machine Translation. In
Sixth Workshop on Statistical Machine Translation
(WMT 2011), Edinburgh, UK.
Franz Josef Och. 1999. An efficient method for de-
termining bilingual word classes. In Proceedings of
the ninth conference on European chapter of the As-
sociation for Computational Linguistics, EACL ?99,
pages 71?76, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic
Evaluation of Machine Translation. Technical Re-
port RC22176 (W0109-022), IBM Research Divi-
sion, T. J. Watson Research Center.
Anna N. Rafferty and Christopher D. Manning. 2008.
Parsing three German treebanks: lexicalized and un-
lexicalized baselines. In Proceedings of the Work-
shop on Parsing German, Columbus, Ohio.
Kay Rottmann and Stephan Vogel. 2007. Word Re-
ordering in Statistical Machine Translation with a
POS-Based Distortion Model. In TMI, Sko?vde,
Sweden.
Helmut Schmid and Florian Laws. 2008. Estimation
of Conditional Probabilities with Decision Trees and
an Application to Fine-Grained POS Tagging. In
COLING 2008, Manchester, Great Britain.
Andreas Stolcke. 2002. SRILM ? An Extensible Lan-
guage Modeling Toolkit. In Proc. of ICSLP, Denver,
Colorado, USA.
Ashish Venugopal, Andreas Zollman, and Alex Waibel.
2005. Training and Evaluation Error Minimization
Rules for Statistical Machine Translation. In Work-
shop on Data-drive Machine Translation and Be-
yond (WPT-05), Ann Arbor, MI.
Stephan Vogel. 2003. SMT Decoder Dissected: Word
Reordering. In Int. Conf. on Natural Language
Processing and Knowledge Engineering, Beijing,
China.
108
Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 185?192,
Sofia, Bulgaria, August 8-9, 2013 c?2013 Association for Computational Linguistics
Joint WMT 2013 Submission of the QUAERO Project
?Stephan Peitz, ?Saab Mansour, ?Matthias Huck, ?Markus Freitag, ?Hermann Ney,
?Eunah Cho, ?Teresa Herrmann, ?Mohammed Mediani, ?Jan Niehues, ?Alex Waibel,
?Alexandre Allauzen, ?Quoc Khanh Do,
?Bianka Buschbeck, ?Tonio Wandmacher
?RWTH Aachen University, Aachen, Germany
?Karlsruhe Institute of Technology, Karlsruhe, Germany
?LIMSI-CNRS, Orsay, France
?SYSTRAN Software, Inc.
?surname@cs.rwth-aachen.de
?firstname.surname@kit.edu
?firstname.lastname@limsi.fr ?surname@systran.fr
Abstract
This paper describes the joint submis-
sion of the QUAERO project for the
German?English translation task of the
ACL 2013 Eighth Workshop on Statisti-
cal Machine Translation (WMT 2013).
The submission was a system combina-
tion of the output of four different transla-
tion systems provided by RWTH Aachen
University, Karlsruhe Institute of Technol-
ogy (KIT), LIMSI-CNRS and SYSTRAN
Software, Inc. The translations were
joined using the RWTH?s system com-
bination approach. Experimental results
show improvements of up to 1.2 points in
BLEU and 1.2 points in TER compared to
the best single translation.
1 Introduction
QUAERO is a European research and develop-
ment program with the goal of developing multi-
media and multilingual indexing and management
tools for professional and general public applica-
tions (http://www.quaero.org). Research in ma-
chine translation is mainly assigned to the four
groups participating in this joint submission. The
aim of this submission was to show the quality of
a joint translation by combining the knowledge of
the four project partners. Each group develop and
maintain their own different machine translation
system. These single systems differ not only in
their general approach, but also in the preprocess-
ing of training and test data. To take advantage
of these differences of each translation system, we
combined all hypotheses of the different systems,
using the RWTH system combination approach.
This paper is structured as follows. First, the
different engines of all four groups are introduced.
In Section 3, the RWTH Aachen system combina-
tion approach is presented. Experiments with dif-
ferent system selections for system combination
are described in Section 4. This paper is concluded
in Section 5.
2 Translation Systems
For WMT 2013, each QUAERO partner trained
their systems on the parallel Europarl (EPPS),
News Commentary (NC) corpora and the web-
crawled corpus. All single systems were tuned on
the newstest2009 and newstest2010 development
set. The newstest2011 development set was used
to tune the system combination parameters. Fi-
nally, on newstest2012 the results of the different
system combination settings are compared. In this
Section, all four different translation engines are
presented.
2.1 RWTH Aachen Single System
For the WMT 2013 evaluation, RWTH utilized a
phrase-based decoder based on (Wuebker et al,
2012) which is part of RWTH?s open-source SMT
toolkit Jane 2.1 1. GIZA++ (Och and Ney, 2003)
was employed to train a word alignment, language
models have been created with the SRILM toolkit
(Stolcke, 2002).
After phrase pair extraction from the word-
aligned parallel corpus, the translation probabil-
ities are estimated by relative frequencies. The
standard feature set alo includes an n-gram lan-
guage model, phrase-level IBM-1 and word-,
phrase- and distortion-penalties, which are com-
bined in log-linear fashion. Furthermore, we used
an additional reordering model as described in
(Galley and Manning, 2008). By this model six
1http://www-i6.informatik.rwth-aachen.
de/jane/
185
additional feature are added to the log-linear com-
bination. The model weights are optimized with
standard Mert (Och, 2003a) on 200-best lists. The
optimization criterion is BLEU.
2.1.1 Preprocessing
In order to reduce the source vocabulary size trans-
lation, the German text was preprocessed by split-
ting German compound words with the frequency-
based method described in (Koehn and Knight,
2003). To further reduce translation complexity
for the phrase-based approach, we performed the
long-range part-of-speech based reordering rules
proposed by (Popovic? et al, 2006).
2.1.2 Translation Model
We applied filtering and weighting for domain-
adaptation similarly to (Mansour et al, 2011) and
(Mansour and Ney, 2012). For filtering the bilin-
gual data, a combination of LM and IBM Model
1 scores was used. In addition, we performed
weighted phrase extraction by using a combined
LM and IBM Model 1 weight.
2.1.3 Language Model
During decoding a 4-gram language model is ap-
plied. The language model is trained on the par-
allel data as well as the provided News crawl,
the 109 French-English, UN and LDC Gigaword
Fourth Edition corpora.
2.2 Karlsruhe Institute of Technology Single
System
2.2.1 Preprocessing
The training data was preprocessed prior to the
training. Symbols such as quotes, dashes and
apostrophes are normalized. Then the first words
of each sentence are smart-cased. For the Ger-
man part of the training corpus, the hunspell2 lex-
icon was used, in order to learn a mapping from
old German spelling to new German writing rules.
Compound-splitting was also performed as de-
scribed in Koehn and Knight (2003). We also re-
moved very long sentences, empty lines, and sen-
tences which show big mismatch on the length.
2.2.2 Filtering
The web-crawled corpus was filtered using an
SVM classifier as described in (Mediani et al,
2011). The lexica used in this filtering task were
obtained from Giza alignments trained on the
2http://hunspell.sourceforge.net/
cleaner corpora, EPPS and NC. Assuming that this
corpus is very noisy, we biased our classifier more
towards precision than recall. This was realized
by giving higher number of false examples (80%
of the training data).
This filtering technique ruled out more than
38% of the corpus (the unfiltered corpus contains
around 2.4M pairs, 0.9M of which were rejected
in the filtering task).
2.2.3 System Overview
The in-house phrase-based decoder (Vogel, 2003)
is used to perform decoding. Optimization with
regard to the BLEU score is done using Minimum
Error Rate Training (MERT) as described in Venu-
gopal et al (2005).
2.2.4 Reordering Model
We applied part-of-speech (POS) based reordering
using probabilistic continuous (Rottmann and Vo-
gel, 2007) and discontinuous (Niehues and Kolss,
2009) rules. This was learned using POS tags gen-
erated by the TreeTagger (Schmid, 1994) for short
and long range reorderings respectively.
In addition to this POS-based reordering, we
also used tree-based reordering rules. Syntactic
parse trees of the whole training corpus and the
word alignment between source and target lan-
guage are used to learn rules on how to reorder the
constituents in a German source sentence to make
it match the English target sentence word order
better (Herrmann et al, 2013). The training corpus
was parsed by the Stanford parser (Rafferty and
Manning, 2008). The reordering rules are applied
to the source sentences and the reordered sentence
variants as well as the original sequence are en-
coded in a word lattice which is used as input to
the decoder.
Moreover, our reordering model was extended
so that it could include the features of lexicalized
reordering model. The reordering probabilities for
each phrase pair are stored as well as the origi-
nal position of each word in the lattice. During
the decoding, the reordering origin of the words
is checked along with its probability added as an
additional score.
2.2.5 Translation Models
The translation model uses the parallel data of
EPPS, NC, and the filtered web-crawled data. As
word alignment, we used the Discriminative Word
Alignment (DWA) as shown in (Niehues and Vo-
186
gel, 2008). The phrase pairs were extracted using
different source word order suggested by the POS-
based reordering models presented previously as
described in (Niehues et al, 2009).
In order to extend the context of source lan-
guage words, we applied a bilingual language
model (Niehues et al, 2011). A Discriminative
Word Lexicon (DWL) introduced in (Mauser et
al., 2009) was extended so that it could take the
source context also into the account. For this,
we used a bag-of-ngrams instead of representing
the source sentence as a bag-of-words. Filtering
based on counts was then applied to the features
for higher order n-grams. In addition to this, the
training examples were created differently so that
we only used the words that occur in the n-best list
but not in the reference as negative example.
2.2.6 Language Models
We build separate language models and combined
them prior to decoding. As word-token based
language models, one language model is built on
EPPS, NC, and giga corpus, while another one is
built using crawled data. We combined the LMs
linearly by minimizing the perplexity on the de-
velopment data. As a bilingual language model we
used the EPPS, NC, and the web-crawled data and
combined them. Furthermore, we use a 5-gram
cluster-based language model with 1,000 word
clusters, which was trained on the EPPS and NC
corpus. The word clusters were created using the
MKCLS algorithm.
2.3 LIMSI-CNRS Single System
2.3.1 System overview
LIMSI?s system is built with n-code (Crego et al,
2011), an open source statistical machine transla-
tion system based on bilingual n-gram3. In this
approach, the translation model relies on a spe-
cific decomposition of the joint probability of a
sentence pair using the n-gram assumption: a sen-
tence pair is decomposed into a sequence of bilin-
gual units called tuples, defining a joint segmen-
tation of the source and target. In the approach of
(Marin?o et al, 2006), this segmentation is a by-
product of source reordering which ultimately de-
rives from initial word and phrase alignments.
2.3.2 An overview of n-code
The baseline translation model is implemented as
a stochastic finite-state transducer trained using
3http://ncode.limsi.fr/
a n-gram model of (source,target) pairs (Casacu-
berta and Vidal, 2004). Training this model re-
quires to reorder source sentences so as to match
the target word order. This is performed by
a stochastic finite-state reordering model, which
uses part-of-speech information4 to generalize re-
ordering patterns beyond lexical regularities.
In addition to the translation model, eleven fea-
ture functions are combined: a target-language
model; four lexicon models; two lexicalized re-
ordering models (Tillmann, 2004) aiming at pre-
dicting the orientation of the next translation unit;
a ?weak? distance-based distortion model; and
finally a word-bonus model and a tuple-bonus
model which compensate for the system prefer-
ence for short translations. The four lexicon mod-
els are similar to the ones use in a standard phrase
based system: two scores correspond to the rel-
ative frequencies of the tuples and two lexical
weights estimated from the automatically gener-
ated word alignments. The weights associated to
feature functions are optimally combined using a
discriminative training framework (Och, 2003b).
The overall search is based on a beam-search
strategy on top of a dynamic programming algo-
rithm. Reordering hypotheses are computed in a
preprocessing step, making use of reordering rules
built from the word reorderings introduced in the
tuple extraction process. The resulting reordering
hypotheses are passed to the decoder in the form
of word lattices (Crego and Mario, 2006).
2.3.3 Continuous space translation models
One critical issue with standard n-gram translation
models is that the elementary units are bilingual
pairs, which means that the underlying vocabu-
lary can be quite large, even for small translation
tasks. Unfortunately, the parallel data available to
train these models are typically order of magni-
tudes smaller than the corresponding monolingual
corpora used to train target language models. It is
very likely then, that such models should face se-
vere estimation problems. In such setting, using
neural network language model techniques seem
all the more appropriate. For this study, we fol-
low the recommendations of Le et al (2012), who
propose to factor the joint probability of a sen-
tence pair by decomposing tuples in two (source
and target) parts, and further each part in words.
This yields a word factored translation model that
4Part-of-speech labels for English and German are com-
puted using the TreeTagger (Schmid, 1995).
187
can be estimated in a continuous space using the
SOUL architecture (Le et al, 2011).
The design and integration of a SOUL model for
large SMT tasks is far from easy, given the com-
putational cost of computing n-gram probabilities.
The solution used here was to resort to a two pass
approach: the first pass uses a conventional back-
off n-gram model to produce a k-best list; in the
second pass, the k-best list is reordered using the
probabilities of m-gram SOUL translation models.
In the following experiments, we used a fixed con-
text size for SOUL of m= 10, and used k = 300.
2.3.4 Corpora and data pre-processing
All the parallel data allowed in the constrained
task are pooled together to create a single par-
allel corpus. This corpus is word-aligned using
MGIZA++5 with default settings. For the English
monolingual training data, we used the same setup
as last year6 and thus the same target language
model as detailed in (Allauzen et al, 2011).
For English, we also took advantage of our in-
house text processing tools for the tokenization
and detokenization steps (Dchelotte et al, 2008)
and our system is built in ?true-case?. As Ger-
man is morphologically more complex than En-
glish, the default policy which consists in treat-
ing each word form independently is plagued with
data sparsity, which is detrimental both at training
and decoding time. Thus, the German side was
normalized using a specific pre-processing scheme
(described in (Allauzen et al, 2010; Durgar El-
Kahlout and Yvon, 2010)), which notably aims at
reducing the lexical redundancy by (i) normalizing
the orthography, (ii) neutralizing most inflections
and (iii) splitting complex compounds.
2.4 SYSTRAN Software, Inc. Single System
In the past few years, SYSTRAN has been focus-
ing on the introduction of statistical approaches
to its rule-based backbone, leading to Hybrid Ma-
chine Translation.
The technique of Statistical Post-Editing
(Dugast et al, 2007) is used to automatically edit
the output of the rule-based system. A Statistical
Post-Editing (SPE) module is generated from a
bilingual corpus. It is basically a translation mod-
ule by itself, however it is trained on rule-based
5http://geek.kyloo.net/software
6The fifth edition of the English Gigaword
(LDC2011T07) was not used.
translations and reference data. It applies correc-
tions and adaptations learned from a phrase-based
5-gram language model. Using this two-step
process will implicitly keep long distance re-
lations and other constraints determined by the
rule-based system while significantly improving
phrasal fluency. It has the advantage that quality
improvements can be achieved with very little
but targeted bilingual data, thus significantly
reducing training time and increasing translation
performance.
The basic setup of the SPE component is identi-
cal to the one described in (Dugast et al, 2007).
A statistical translation model is trained on the
rule-based translation of the source and the target
side of the parallel corpus. Language models are
trained on each target half of the parallel corpora
and also on additional in-domain corpora. More-
over, the following measures - limiting unwanted
statistical effects - were applied:
? Named entities are replaced by special tokens
on both sides. This usually improves word
alignment, since the vocabulary size is sig-
nificantly reduced. In addition, entity trans-
lation is handled more reliably by the rule-
based engine.
? The intersection of both vocabularies (i.e. vo-
cabularies of the rule-based output and the
reference translation) is used to produce an
additional parallel corpus (whose target is
identical to the source). This was added to the
parallel text in order to improve word align-
ment.
? Singleton phrase pairs are deleted from the
phrase table to avoid overfitting.
? Phrase pairs not containing the same number
of entities on the source and the target side
are also discarded.
? Phrase pairs appearing less than 2 times were
pruned.
The SPE language model was trained on 2M
phrases from the news/europarl and Common-
Crawl corpora, provided as training data for WMT
2013. Weights for these separate models were
tuned by the Mert algorithm provided in the Moses
toolkit (Koehn et al, 2007), using the provided
news development set.
188
0
1
5:
th
at
/1
7:
th
is/
3
2
3:
is/
3
8:
w
as
/1
3
0:
*E
PS
*/
3
4:
it/
1
4
0:
*E
PS
*/
3
2:
in
/1
5
0:
*E
PS
*/
3
6:
th
e/
1
6
0:
*E
PS
*/
1
1:
fu
tu
re
/3
Figure 1: Confusion network of four different hypotheses.
3 RWTH Aachen System Combination
System combination is used to produce consen-
sus translations from multiple hypotheses gener-
ated with different translation engines. First, a
word to word alignment for the given single sys-
tem hypotheses is produced. In a second step a
confusion network is constructed. Then, the hy-
pothesis with the highest probability is extracted
from this confusion network. For the alignment
procedure, each of the given single systems gen-
erates one confusion network with its own as pri-
mary system. To this primary system all other hy-
potheses are aligned using the METEOR (Lavie
and Agarwal, 2007) alignment and thus the pri-
mary system defines the word order. Once the
alignment is given, the corresponding confusion
network is constructed. An example is given in
Figure 1. The final network for one source sen-
tence is the union of all confusion networks gen-
erated from the different primary systems. That
allows the system combination to select the word
order from different system outputs.
Before performing system combination, each
translation output was normalized by tokenization
and lowercasing. The output of the combination
was then truecased based on the original truecased
output.
The model weights of the system combination
are optimized with standard Mert (Och, 2003a)
on 100-best lists. We add one voting feature for
each single system to the log-linear framework of
the system combination. The voting feature fires
for each word the single system agrees on. More-
over, a word penalty, a language model trained on
the input hypotheses, a binary feature which pe-
nalizes word deletions in the confusion network
and a primary feature which marks the system
which provides the word order are combined in
this log-linear model. The optimization criterion
is 4BLEU-TER.
4 Experimental Results
In this year?s experiments, we tried to improve the
result of the system combination further by com-
bining single systems tuned on different develop-
Table 1: Comparison of single systems tuned on
newstest2009 and newstest2010. The results are
reported on newstest2012.
single systems tuned on newstest2012
newstest BLEU TER
KIT 2009 24.6 58.4
2010 24.6 58.6
LIMSI 2009 22.5 61.5
2010 22.6 59.8
SYSTRAN 2009 20.9 63.3
2010 21.2 62.2
RWTH 2009 23.7 60.8
2010 24.4 58.8
ment sets. The idea is to achieve a more stable
performance in terms of translation quality, if the
single systems are not optimized on the same data
set. In Table 1, the results of each provided single
system tuned on newstest2009 and newstest2010
are shown. For RWTH, LIMSI and SYSTRAN,
it seems that the performance of the single system
depends on the chosen tuning set. However, the
translation quality of the single systems provided
by KIT is stable.
As initial approach and for the final submis-
sion, we grouped single systems with dissimilar
approaches. Thus, KIT (phrase-based SMT) and
SYSTRAN (rule-based MT) tuned their system on
newstest2010, while RWTH (phrase-based SMT)
and LIMSI (n-gram) optimized on newstest2009.
To compare the impact of this approach, all pos-
sible combinations were checked (Table 2). How-
ever, it seems that the translation quality can not be
improved by this approach. For the test set (new-
stest2012), BLEU is steady around 25.6 points.
Even if the single system with lowest BLEU are
combined (KIT 2010, LIMSI 2009, SYSTRAN
2010, RWTH 2009), the translation quality in
terms of BLEU is comparable with the combina-
tion of the best single systems (KIT 2009, LIMSI
2010, SYSTRAN 2010, RWTH 2010). However,
we could gain 1.0 point in TER.
Due to the fact, that for the final submission the
initial grouping was available only, we kept this
189
Table 2: Comparison of different system combination settings. For each possible combination of systems
tuned on different tuning sets, a system combination was set up, re-tuned on newstest2011 and evaluated
on newstest2012. The setting used for further experiments is set in boldface.
single systems system combinations
KIT LIMSI SYSTRAN RWTH newstest2011 newstest2012
tuned on newstest BLEU TER BLEU TER
2009 2009 2009 2009 24.6 58.0 25.6 56.8
2010 2010 2010 2010 24.2 58.1 25.6 57.7
2010 2009 2009 2009 24.5 57.9 25.7 57.4
2009 2010 2009 2009 24.4 58.3 25.7 57.0
2009 2009 2010 2009 24.5 57.9 25.6 57.0
2009 2009 2009 2010 24.5 58.0 25.6 56.8
2009 2010 2010 2010 24.1 57.5 25.4 56.4
2010 2009 2010 2010 24.3 57.6 25.6 56.9
2010 2010 2009 2010 24.2 58.0 25.6 57.3
2010 2010 2010 2009 24.3 57.9 25.5 57.6
2010 2010 2009 2009 24.4 58.1 25.6 57.5
2009 2009 2010 2010 24.4 57.8 25.5 56.6
2009 2010 2010 2009 24.4 58.2 25.5 57.0
2009 2010 2009 2010 24.2 57.8 25.5 56.8
2010 2009 2009 2010 24.4 57.9 25.6 57.4
2010 2009 2010 2009 24.4 57.7 25.6 57.4
Table 3: Results of the final submission (bold-
face) compared with best single system on new-
stest2012.
newstest2011 newstest2012
BLEU TER BLEU TER
best single 23.2 60.9 24.6 58.4
system comb. 24.4 57.7 25.6 57.4
+ IBM-1 24.6 58.1 25.6 57.6
+ bigLM 24.6 57.9 25.8 57.2
combination. To improve this baseline further, two
additional models were added. We applied lexi-
cal smoothing (IBM-1) and an additional language
model (bigLM) trained on the English side of the
parallel data and the News shuffle corpus. The re-
sults are presented in Table 3.
The baseline was slightly improved by 0.2
points in BLEU and TER. Note, this system com-
bination was the final submission.
5 Conclusion
For the participation in the WMT 2013 shared
translation task, the partners of the QUAERO
project (Karlsruhe Institute of Technology, RWTH
Aachen University, LIMSI-CNRS and SYSTRAN
Software, Inc.) provided a joint submission. By
joining the output of four different translation sys-
tems with RWTH?s system combination, we re-
ported an improvement of up to 1.2 points in
BLEU and TER.
Combining systems optimized on different tun-
ing sets does not seem to improve the translation
quality. However, by adding additional model, the
baseline was slightly improved.
All in all, we conclude that the variability in
terms of BLEU does not influence the final result.
It seems that using different approaches of MT in
a system combination is more important (Freitag
et al, 2012).
Acknowledgments
This work was achieved as part of the Quaero Pro-
gramme, funded by OSEO, French State agency
for innovation.
References
Alexandre Allauzen, Josep M. Crego, I?lknur Durgar El-
Kahlout, and Franc?ois Yvon. 2010. LIMSI?s statis-
tical translation systems for WMT?10. In Proc. of
190
the Joint Workshop on Statistical Machine Transla-
tion and MetricsMATR, pages 54?59, Uppsala, Swe-
den.
Alexandre Allauzen, Gilles Adda, He?le`ne Bonneau-
Maynard, Josep M. Crego, Hai-Son Le, Aure?lien
Max, Adrien Lardilleux, Thomas Lavergne, Artem
Sokolov, Guillaume Wisniewski, and Franc?ois
Yvon. 2011. LIMSI @ WMT11. In Proceedings of
the Sixth Workshop on Statistical Machine Transla-
tion, pages 309?315, Edinburgh, Scotland, July. As-
sociation for Computational Linguistics.
Francesco Casacuberta and Enrique Vidal. 2004. Ma-
chine translation with inferred stochastic finite-state
transducers. Computational Linguistics, 30(3):205?
225.
Josep M. Crego and Jose? B. Mario. 2006. Improving
statistical MT by coupling reordering and decoding.
Machine Translation, 20(3):199?215.
Josep M. Crego, Franois Yvon, and Jos B. Mario.
2011. N-code: an open-source Bilingual N-gram
SMT Toolkit. Prague Bulletin of Mathematical Lin-
guistics, 96:49?58.
Lo??c Dugast, Jean Senellart, and Philipp Koehn. 2007.
Statistical post-editing on systran?s rule-based trans-
lation system. In Proceedings of the Second Work-
shop on Statistical Machine Translation, StatMT
?07, pages 220?223, Stroudsburg, PA, USA. Asso-
ciation for Computational Linguistics.
Ilknur Durgar El-Kahlout and Franois Yvon. 2010.
The pay-offs of preprocessing for German-English
Statistical Machine Translation. In Marcello Fed-
erico, Ian Lane, Michael Paul, and Franois Yvon, ed-
itors, Proceedings of the seventh International Work-
shop on Spoken Language Translation (IWSLT),
pages 251?258.
Daniel Dchelotte, Gilles Adda, Alexandre Allauzen,
Olivier Galibert, Jean-Luc Gauvain, Hlne Maynard,
and Franois Yvon. 2008. LIMSI?s statistical
translation systems for WMT?08. In Proc. of the
NAACL-HTL Statistical Machine Translation Work-
shop, Columbus, Ohio.
Markus Freitag, Stephan Peitz, Matthias Huck, Her-
mann Ney, Teresa Herrmann, Jan Niehues, Alex
Waibel, Alexandre Allauzen, Gilles Adda, Bianka
Buschbeck, Josep Maria Crego, and Jean Senellart.
2012. Joint wmt 2012 submission of the quaero
project. In NAACL 2012 Seventh Workshop on Sta-
tistical Machine Translation, pages 322?329, Mon-
treal, Canada, June.
Michel Galley and Christopher D. Manning. 2008. A
simple and effective hierarchical phrase reordering
model. In Proceedings of the 2008 Conference on
Empirical Methods in Natural Language Process-
ing, pages 847?855, Honolulu, Hawaii, October. As-
sociation for Computational Linguistics.
Teresa Herrmann, Jan Niehues, and Alex Waibel.
2013. Combining Word Reordering Methods on
different Linguistic Abstraction Levels for Statisti-
cal Machine Translation. In Proceedings of the Sev-
enth Workshop on Syntax, Semantics and Structure
in Statistical Translation, Altanta, Georgia, USA,
June. Association for Computational Linguistics.
Philipp Koehn and Kevin Knight. 2003. Empirical
Methods for Compound Splitting. In EACL, Bu-
dapest, Hungary.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondr?ej Bojar, Alexandra
Constantine, and Evan Herbst. 2007. Moses: Open
Source Toolkit for Statistical Machine Translation.
pages 177?180, Prague, Czech Republic, June.
Alon Lavie and Abhaya Agarwal. 2007. ME-
TEOR: An Automatic Metric for MT Evaluation
with High Levels of Correlation with Human Judg-
ments. pages 228?231, Prague, Czech Republic,
June.
Hai-Son Le, Ilya Oparin, Alexandre Allauzen, Jean-
Luc Gauvain, and Franc?ois Yvon. 2011. Structured
output layer neural network language model. In Pro-
ceedings of ICASSP?11, pages 5524?5527.
Hai-Son Le, Alexandre Allauzen, and Franc?ois Yvon.
2012. Continuous space translation models with
neural networks. In NAACL ?12: Proceedings of
the 2012 Conference of the North American Chap-
ter of the Association for Computational Linguistics
on Human Language Technology.
Saab Mansour and Hermann Ney. 2012. A sim-
ple and effective weighted phrase extraction for ma-
chine translation adaptation. In International Work-
shop on Spoken Language Translation, pages 193?
200, Hong Kong, December.
Sab Mansour, Joern Wuebker, and Hermann Ney.
2011. Combining Translation and Language Model
Scoring for Domain-Specific Data Filtering. In Pro-
ceedings of the International Workshop on Spoken
Language Translation (IWSLT), San Francisco, CA,
December.
Jose? B. Marin?o, Rafael E. Banchs, Josep M. Crego,
Adria` de Gispert, Patrick Lambert, Jose? A.R. Fonol-
losa, and Marta R. Costa-Jussa`. 2006. N-gram-
based machine translation. Computational Linguis-
tics, 32(4):527?549.
Arne Mauser, Sas?a Hasan, and Hermann Ney. 2009.
Extending Statistical Machine Translation with Dis-
criminative and Trigger-based Lexicon Models. In
Proceedings of the 2009 Conference on Empirical
Methods in Natural Language Processing: Volume
1 - Volume 1, EMNLP ?09, Singapore.
191
Mohammed Mediani, Eunah Cho, Jan Niehues, Teresa
Herrmann, and Alex Waibel. 2011. The KIT
English-French Translation Systems for IWSLT
2011. In Proceedings of the Eighth Interna-
tional Workshop on Spoken Language Translation
(IWSLT).
Jan Niehues and Muntsin Kolss. 2009. A POS-Based
Model for Long-Range Reorderings in SMT. In
Fourth Workshop on Statistical Machine Translation
(WMT 2009), Athens, Greece.
Jan Niehues and Stephan Vogel. 2008. Discriminative
Word Alignment via Alignment Matrix Modeling.
In Proc. of Third ACL Workshop on Statistical Ma-
chine Translation, Columbus, USA.
Jan Niehues, Teresa Herrmann, Muntsin Kolss, and
Alex Waibel. 2009. The Universita?t Karlsruhe
Translation System for the EACL-WMT 2009. In
Fourth Workshop on Statistical Machine Translation
(WMT 2009), Athens, Greece.
Jan Niehues, Teresa Herrmann, Stephan Vogel, and
Alex Waibel. 2011. Wider Context by Using Bilin-
gual Language Models in Machine Translation. In
Sixth Workshop on Statistical Machine Translation
(WMT 2011), Edinburgh, UK.
Franz Josef Och and Hermann Ney. 2003. A System-
atic Comparison of Various Statistical Alignment
Models. Computational Linguistics, 29(1):19?51,
March.
Franz Josef Och. 2003a. Minimum Error Rate Train-
ing in Statistical Machine Translation. In Proc. of
the 41th Annual Meeting of the Association for Com-
putational Linguistics (ACL), pages 160?167, Sap-
poro, Japan, July.
Franz Josef Och. 2003b. Minimum error rate training
in statistical machine translation. In ACL ?03: Proc.
of the 41st Annual Meeting on Association for Com-
putational Linguistics, pages 160?167.
M. Popovic?, D. Stein, and H. Ney. 2006. Statistical
Machine Translation of German Compound Words.
In FinTAL - 5th International Conference on Nat-
ural Language Processing, Springer Verlag, LNCS,
pages 616?624.
Anna N. Rafferty and Christopher D. Manning. 2008.
Parsing three German treebanks: lexicalized and un-
lexicalized baselines. In Proceedings of the Work-
shop on Parsing German.
Kay Rottmann and Stephan Vogel. 2007. Word Re-
ordering in Statistical Machine Translation with a
POS-Based Distortion Model. In TMI, Sko?vde,
Sweden.
Helmut Schmid. 1994. Probabilistic Part-of-Speech
Tagging Using Decision Trees. In International
Conference on New Methods in Language Process-
ing, Manchester, UK.
Helmut Schmid. 1995. Improvements in part-of-
speech tagging with an application to German.
In Evelyne Tzoukermann and SusanEditors Arm-
strong, editors, Proceedings of the ACL SIGDAT-
Workshop, pages 47?50. Kluwer Academic Publish-
ers.
Andreas Stolcke. 2002. SRILM ? An Extensible Lan-
guage Modeling Toolkit. In Proc. Int. Conf. on Spo-
ken Language Processing, volume 2, pages 901?
904, Denver, Colorado, USA.
Christoph Tillmann. 2004. A unigram orientation
model for statistical machine translation. In Pro-
ceedings of HLT-NAACL 2004, pages 101?104. As-
sociation for Computational Linguistics.
Ashish Venugopal, Andreas Zollman, and Alex Waibel.
2005. Training and Evaluation Error Minimization
Rules for Statistical Machine Translation. In Work-
shop on Data-drive Machine Translation and Be-
yond (WPT-05), Ann Arbor, MI.
Stephan Vogel. 2003. SMT Decoder Dissected: Word
Reordering. In Int. Conf. on Natural Language
Processing and Knowledge Engineering, Beijing,
China.
Joern Wuebker, Matthias Huck, Stephan Peitz, Malte
Nuhn, Markus Freitag, Jan-Thorsten Peter, Saab
Mansour, and Hermann Ney. 2012. Jane 2: Open
source phrase-based and hierarchical statistical ma-
chine translation. In International Conference on
Computational Linguistics, pages 483?491, Mum-
bai, India, December.
192
Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 512?520,
Sofia, Bulgaria, August 8-9, 2013 c?2013 Association for Computational Linguistics
An MT Error-driven Discriminative Word Lexicon
using Sentence Structure Features
Jan Niehues and Alex Waibel
Institute for Anthropomatics
Karlsruhe Institute of Technology, Germany
firstname.secondname@kit.edu
Abstract
The Discriminative Word Lexicon (DWL)
is a maximum-entropy model that pre-
dicts the target word probability given the
source sentence words. We present two
ways to extend a DWL to improve its abil-
ity to model the word translation probabil-
ity in a phrase-based machine translation
(PBMT) system. While DWLs are able to
model the global source information, they
ignore the structure of the source and tar-
get sentence. We propose to include this
structure by modeling the source sentence
as a bag-of-n-grams and features depend-
ing on the surrounding target words. Fur-
thermore, as the standard DWL does not
get any feedback from the MT system, we
change the DWL training process to ex-
plicitly focus on addressing MT errors.
By using these methods we are able to im-
prove the translation performance by up
to 0.8 BLEU points compared to a system
that uses a standard DWL.
1 Introduction
In many state-of-the-art SMT systems, the phrase-
based (Koehn et al, 2003) approach is used. In
this approach, instead of building the translation
by translating word by word, sequences of source
and target words, so-called phrase pairs, are used
as the basic translation unit. A table of correspon-
dences between source and target phrases forms
the translation model. Target language fluency is
modeled by a language model storing monolingual
n-gram occurrences. A log-linear combination of
these main models as well as additional features is
used to score the different translation hypotheses.
Then the decoder searches for the translation with
the highest score.
One problem of this approach is that bilingual
context is only modeled within the phrase pairs.
Therefore, different approaches to increase the
context available during decoding have been pre-
sented (Haque et al, 2011; Niehues et al, 2011;
Mauser et al, 2009). One promising approach is
the Discriminative Word Lexicon (DWL). In this
approach, a discriminative model is used to predict
the probability of a target word given the words in
the source sentence.
In contrast to other models in the phrase-based
system, this approach is capable of modeling the
translation probability using information from the
whole sentence. Thus it is possible to model
long-distance dependencies. But the model is not
able to use the structure of the sentence, since
the source sentence is modeled only as a bag-
of-words. Furthermore, the DWL is trained to
discriminate between all translation options with-
out knowledge about the other models used in a
phrase-based machine translation system such as
the translation model, language model etc. In
contrast, we try to feedback information about
possible errors of the MT system into the DWL.
Thereby, the DWLs are able to focus on improving
the errors of the other models of an MT system.
We will introduce features that encode infor-
mation about the source sentence structure. Fur-
thermore, the surrounding target words will also
be used in the model to encode information about
the target sentence structure. Finally, we incor-
porate information from the other models into the
creation of the training examples. We create the
negative training examples using possible errors of
the other models.
2 Related Work
Bangalore et al (2007) presented an approach to
machine translation using discriminative lexical
selection. Motivated by their results, Mauser et
al. (2009) integrated the DWL into the PBMT ap-
512
proach. Thereby, they are able to use global source
information.
This was extended by Huck et al (2010) by a
feature selection strategy in order to reduce the
number of weights. In Mediani et al (2011) a first
approach to use information about MT errors in
the training of DWLs was presented. They select
the training examples by using phrase table infor-
mation also.
The DWLs are related to work that was done
in the area of word sense disambiguation (WSD).
Carpuat and Wu (2007) presented an approach to
disambiguate between different phrases instead of
performing the disambiguation at word level.
A different lexical model that uses target side
information was presented in Jeong et al (2010).
The focus of this work was to model complex mor-
phology on the target language.
3 Discriminative Word Lexicon
The DWL is a maximum entropy model used to
determine the probability of using a target word
in the translation. Therefore, we train individ-
ual models for every target word. Each model is
trained to return the probability of this word given
the input sentence.
The input of the model is the source sentence.
Therefore, we need to represent the input sentence
by features. In this approach this is done by using
binary features. We use an indicator feature for
every input word. Therefore, the sentence is mod-
eled as a bag-of-words and the order of the words
is ignored. More formally, a given source sen-
tence F = f1 . . . fI is represented by the features
I(F ) = {if (F ) : f ? SourceV ocabulary}:
if (F ) =
{
1 : f ? F
0 : f /? F (1)
The models are trained on examples generated
by the parallel training data. The labels for train-
ing the classifier of target word e are defined as
follows:
labele(F,E) =
{
1 : e ? E
0 : e /? E (2)
We used the MegaM Toolkit1 to train the maxi-
mum entropy models. This model approximates
the probability p(ej |F ) of a target word ej given
the source sentence F .
1http://www.umiacs.umd.edu/ hal/megam/index.html
When we have the probability for every word ej
given the source sentence F , we need to combine
these probabilities into a probability of the whole
target sentence E = e1 . . . eJ given F . Making an
assumption of independence on the target side as
well, the models can be combined to the probabil-
ity of E given F :
p(E|F ) =
?
ej?e
p(ej |F ) (3)
In this equation we multiply the probability of
one word only once even if the word occurs sev-
eral times in the sentence. Since we build the tar-
get sentence from left to right during decoding,
we would need to change the score for this fea-
ture only if a new word is added to the hypothesis.
If a word is added second time we do not want
to change the feature value. In order to keep track
of this, additional bookkeeping would be required.
But the other models in our translation system will
prevent us from using a word too often in any case.
Therefore, we approximate the probability of the
sentence differently as defined in Equation 4.
p(E|F ) =
J?
j=1
p(ej |F ) (4)
In this case we multiply the probabilities of all
word occurrences in the target sentence. There-
fore, we can calculate the score for every phrase
pair before starting with the translation.
4 Modeling Sentence Structure
As mentioned before one main drawback of DWLs
is that they do not encode any structural informa-
tion about the source or target sentence. We in-
corporated this information with two types of fea-
tures. First, we tried to encode the information
from the source sentence better by using a bag-of-
n-grams approach. Secondly, we introduced new
features to be able to encode information about the
neighboring target words also.
4.1 Source Sentence Structure
In the default approach the sentence is represented
as a bag-of-words. This has the advantage that
the model can use a quite large context of the
whole sentence. In contrast to the IBM models,
where the translation probability only depends on
the aligned source word, here the translation prob-
ability can be influenced by all words in the sen-
tence.
513
On the other hand, the local context is ignored
by the bag-of-words approach. Information about
the word order get lost. No information about the
previous and next word is available. The problem
is illustrated in the example in Figure 1.
Figure 1: Example for source structural informa-
tion
Source: Die Lehrer wussten nicht, ...
Reference: The teachers didn?t know ...
The German word Lehrer (engl. teacher) is the
same word for singular or plural. It is only pos-
sible to distinguish whether singular or plural is
meant through the context. This can be determined
by the plural article die. If only one teacher would
be meant, the corresponding article would be der.
In order be able to use the DWL to distinguish
between these two translations, we need to im-
prove the representation of the input sentence. As
shown in the example, it would be helpful to know
the order of the words. If we know that the word
die precedes Lehrer, it would be more probable
that the word is translated into teachers rather than
teacher.
Therefore, we propose to use a bag-of-n-grams
instead of a bag-of-words to represent the input
sentence. In this case we will use an indicator fea-
ture for every n-gram occurring in the input sen-
tence and not only for every word. This way we
are also able to encode the sequence of the words.
For the example, we would have the input feature
die Lehrer, which would increase the probability
of using teachers in the translation compared to
teacher.
By increasing the order of the n-grams, we will
also increase the number of features and run into
data sparseness problems. Therefore, we used
count filtering on the features for higher order n-
grams. Furthermore, we combine n-grams of dif-
ferent orders to better handle the data sparseness
problem.
4.2 Target Sentence Structure
In the standard DWL approach, the probability of
the target word depends only on the source words
in the input sentence. But this is a quite rough ap-
proximation. In reality, the probability of a target
word occurring in the sentence also depends on the
other target words in the sentence.
If we look at the word langsam (engl. slow or
slowly) in the example sentence in Figure 2, we
can only determine the correct translation by using
the target context. The word can be translated as
slow or slowly depending on how it is used in the
English sentence.
In order to model the translation probability bet-
ter we need structural information of the target
side. For example, if the preceding word on the
target side is be, the translation will be more prob-
ably slow than slowly.
We encoded the target context of the word by
features indicating the preceding or next word.
Furthermore, we extend the context to up to three
words before and after the word. Therefore the
following target features are added to the set of
features for the classifier of word e:
iTC e? k(E) =
{
1 : ?j : ej = e ? ej+k = e?
0 : else
(5)
where k ? {?1, 1} for a context of one word
before and after.
5 Training
Apart from the missing sentence structure the
DWL is not able to make use of feedback from
the other models in the MT system. We try to in-
corporate information about possible errors intro-
duced by the other models into the training of the
DWL.
The DWL is trained on the paral-
lel data that is available for the task
T = (F1, E1), . . . , (FM , EM ). In order to
train it, we need to create positive and negative
examples from this data. We will present different
approaches to generate the training examples,
which differ in the information used for creating
the negative examples.
In the original approach, one training example
is created for every sentence of the parallel data
and for every DWL classifier. If the target word
occurs in the sentence, we create a positive ex-
ample and if not the source sentence is used as a
negative example as described in Equation 2. For
most words, this results in a very unbalanced set of
training examples. Most words will only occur in
quite few sentences and therefore, we have mostly
negative examples.
Mediani et al (2011) presented an approach
to create the training examples that is driven by
looking at possible errors due to the different
514
Figure 2: Example for target structural information
Source: Die Anerkennung wird langsam sein in den Vereinigten Staaten ...
Reference: The recognition is going to be slow in the United States, ...
translations in the phrase table (Phrase pair ap-
proach). Since a translation is generated always
using phrase pairs (f? , e?) with matching source
side, wrong words can only be generated in the
translation if the word occurs in the target side
words of those matching phrase pairs. There-
fore, we can define the possible target vocabulary
TV (F ) of a source sentence:
TV (F ) = {e|?(f? , e?) : f? ? F ? e ? e?} (6)
As a consequence, we generate a negative train-
ing example for one target word only from those
training sentences where the word is in the target
vocabulary but not in the reference.
labele(F,E) =
{
1 : e ? E
0 : e /? E ? e ? TV (F )
(7)
All training sentences for which the label is not
defined are not used in the training of the model
for word e. Thereby, not only can we focus the
classifiers on improving possible errors made by
the phrase table, but also reduce the amount of
training examples and therefore the time needed
for training dramatically.
In the phrase pair approach we only use in-
formation about possible errors of the translation
model for generating the negative training exam-
ples. But it would be preferable to consider possi-
ble errors of the whole MT system instead of only
using the phrase table. Some of the errors of the
phrase table might already be corrected by the lan-
guage model. The possible errors of the whole
system can be approximated by using the N -Best
list.
We first need to translate the whole cor-
pus and save the N -Best list for all sentences
NBEST (F ) = {E?1 . . . E?N}. Then we can
approximate the possible errors of the MT sys-
tem with the errors that occur in the N -Best list.
Therefore, we create a negative example for a tar-
get word only if it occurs in the N -Best list and
not in the reference. Compared to the phrase pair
approach, the only difference is the definition of
the target vocabulary:
TV (F ) = {e|e ? NBEST (F )} (8)
The disadvantage of the N-Best approach is, of
course, that we need to translate the whole cor-
pus. This is quite time consuming, but it can be
parallelized.
5.1 Training Examples for Target Features
If we use target features, the creation of the train-
ing examples gets more difficult. When using only
source features, we can create one example from
every training sentence. Even if the word occurs
in several phrase pairs or in several entries of the
N -Best list, all of them will create the same train-
ing example, since the features only depend on the
source sentence.
When we use target features, the features of the
training example depend also on the target words
that occur around the word. Therefore, we can
only use the N -Best list approach to create the tar-
get features since previous approaches mentioned
in the last part do not have the target context in-
formation. Furthermore, we can create different
examples from the same sentence. If we have, for
example, the N -Best list entries I think ... and I be-
lieve .., we can use the context think or the context
believe for the model of I.
In the approach using all target features (All
TF), we created one training example for every
sentence where the word occurs. If we see the
word in different target contexts, we create all the
features for these contexts and use them in the
training example.
I(F,E) = max( I(F ); I(E); (9)
I(E?)|E? ? NBEST (F ))
The maximum is defined component-wise. So
all features, which have in I(F ),I(E) or I(E?) the
value one, also have the value one in I(F,E). If
we use the context that was given by the reference,
this might not exist in the phrase-based MT sys-
tem. Therefore, in the next approach (N-Best TF),
we only used target features from the N -Best list.
I(F,E) = max(I(F ); I(E?)|E? ? NBEST (F ))
(10)
In both examples, we still have the problem that
we can use different contexts in one training ex-
515
ample. This condition can not happen when ap-
plying the DWL model. Therefore, we changed
the set of training examples in the separate target
features approach (Separate TF). We no longer
create one training example for every training sen-
tence (F,E), but one for every training sentence
N -Best list translation (F,E,E?). We only con-
sidered the examples for the classifier of target
word e, where e occurs in the N -Best list entry E?.
If the word does not occur in any N -Best list en-
try of a training sentence, but in the reference, we
created an additional example (F,E, ??). The fea-
tures of this examples can then be created straight
forward as:
I((F,E,E?)) = max(I(F ); I(E?)) (11)
If we have seen the word only in the reference,
we create an training example without target fea-
tures. Therefore, we have again a training exam-
ple which can not happen when using the DWL
model. Therefore, we removed these examples in
the last method (Restricted TF).
6 Experiments
After presenting the different approaches to per-
form feature and example selection, we will now
evaluate them. First, we will give a short overview
of the MT system. Then we will give a detailed
evaluation on the task of translating German lec-
tures into English and analyze the influence of the
presented approaches. Afterwards, we will present
overview experiments on the German-to-English
and English-to-German translation task of WMT
13 Shared Translation Task.
6.1 System Description
The translation system was trained on the EPPS
corpus, NC corpus, the BTEC corpus and TED
talks.2 The data was preprocessed and compound
splitting (Koehn and Knight, 2003) was applied
for German. Afterwards the discriminative word
alignment approach as described in Niehues and
Vogel (2008) was applied to generate the align-
ments between source and target words. The
phrase table was built using the scripts from the
Moses package (Koehn et al, 2007). A 4-gram
language model was trained on the target side of
the parallel data using the SRILM toolkit (Stolcke,
2002). In addition we used a bilingual language
model as described in Niehues et al (2011).
2http://www.ted.com
Reordering was performed as a preprocessing
step using part-of-speech information generated
by the TreeTagger (Schmid, 1994). We used
the reordering approach described in Rottmann
and Vogel (2007) and the extensions presented in
Niehues and Kolss (2009) to cover long-range re-
orderings, which are typical when translating be-
tween German and English.
An in-house phrase-based decoder was used to
generate the translation hypotheses and the opti-
mization was performed using MERT (Venugopal
et al, 2005).
We optimized the weights of the log-linear
model on a separate set of TED talks and also
used TED talks for testing. The development set
consists of 1.7k segments containing 16k words.
As test set we used 3.5k segments containing 31k
words. We will refer to this system as System 1.
In order to show the influence of the approaches
better, we evaluated them also in a second system.
In addition to the models used in the first system
we performed a log-linear language model and
phrase table adaptation as described in Niehues
and Waibel (2012). To this system we refer as Sys-
tem 2 in the following experiments.
6.2 German - English TED Experiments
6.2.1 Source Features
In a first set of experiments, we analyzed the dif-
ferent types of source structure features described
in Section 4.1. In all the experiments, we generate
the negative training examples using the candidate
translations generated by the phrase pairs. The re-
sults can be found in Table 1.
First, we added the unigram DWL to the base-
line system. The higher improvements for the Sys-
tem 1 is due to the fact that the DWL is only
trained on the TED corpus and therefore also per-
forms some level of domain adaptation. This is
more important for the System 1, since System 2
is already adapted to the TED domain.
If we use features based on bigrams instead of
unigrams, the number of features increases by a
factor of eight. Furthermore, in both cases the
translation quality drops. Especially for System
1, we have a significant drop in the BLEU score
of the test set by 0.6 BLEU points. One prob-
lem might be that most of the bigrams occur quite
rarely and therefore, we have a problem of data
sparseness and generalization.
If we combine the features of unigram and bi-
516
Table 1: Experiments using different source features
System FeatureSize System 1 System 2
Dev Test Dev Test
Baseline 0 26.32 24.24 28.40 25.89
Unigram 40k 27.46 25.56 28.58 26.15
Bigram 319k 27.34 24.92 28.53 25.82
Uni+bigram 359k 27.69 25.55 28.66 26.51
+ Count filter 2 122k 27.75 25.71 28.75 26.74
+ Count filter 5 63k 27.81 25.67 28.72 26.81
+ Trigram 77k 27.76 25.76 28.82 26.94
gram features, for System 1, we get an improve-
ment of 0.2 BLEU points on the development data
and the same translation quality on the test data
as the baseline DWL system using only unigrams.
For System 2, we can improve by 0.1 on the devel-
opment data and 0.4 on the test data. So we can get
a first improvement using these additional source
features, but the number of features increased by a
factor of nine.
In order to decrease the number of features
again, we applied count filtering to the bigram
features. In a first experiment we only used the
bigram features that occur at least twice. This
reduced the number of features dramatically by
a factor of three. Furthermore, this even im-
proved the translation quality. In both systems we
could improve the translation quality by 0.2 BLEU
points. So it seems to be quite important to add
only the relevant bigram features.
If we use a minimum occurrence of five for the
bigram features, we can even decrease the num-
ber of features further by a factor of two without
losing any translation performance.
Finally, we added the trigram features. For
these features we applied count filtering of five.
For System 1, the translation quality stays the
same, but for System 2 we can improve the trans-
lation quality by additional 0.2 BLEU points.
In summary, we could improve the translation
quality by 0.2 for the System 1 and 0.8 BLEU
points for the System 2 on the test set. Due to the
count filtering, this is achieved by only using less
than twice as many features.
6.3 Training Examples
In a next step we analyzed the different exam-
ple selection approaches. The results are summa-
rized in Table 2. In these experiments we used the
source features using unigrams, bigrams and tri-
grams with count filtering in all experiments.
In the first experiment, we used the original ap-
proach to create the training examples. In this
case, all sentences where the word does not occur
in the reference generate negative examples. In
our setup, we needed 8,461 DWL models to trans-
late the development and test data. These are all
target words that occur in phrase pairs that can be
used to translate the development or test set.
In each of approaches we have 0.75M posi-
tive examples for these models. In the origi-
nal approach, we have 428M negative examples.
So in this case the number of positive and nega-
tive examples is very unbalanced. This training
data leads to models with a total of 659M feature
weights.
If we use the target side of the phrase pairs to
generate our training examples, we dramatically
reduce the number of negative training examples.
In this case only 5M negative training examples
are generated. The size of the models is reduced
dramatically to 38M weights. Furthermore, we
could improve the translation quality by 0.3 BLEU
points on both System 1 and System 2.
If we use the 300-Best lists produced by Sys-
tem 1 to generate the training examples, we can
reduce the model size further. This approach leads
to models only half the size of the phrase pairs ap-
proach using only 1.59M negative examples. Fur-
thermore, for System 1 the translation quality can
be improved further to 25.87 BLEU points. For
System 2 the BLEU score on the development data
increases, but the score on the test sets drops by 0.4
BLEU points.
In the next experiment we used the N -Best lists
generated by System 2. The results are shown in
the line N -Best list 2. In this case, the model size
is slightly reduced further. And on the adapted
system a similar performance is achieved. But for
517
Table 2: Experiments using different methods to create training examples
System #weight #neg. Examples System 1 System 2
Dev Test Dev Test
Original Approach 659 M 428 M 27.39 25.44 28.64 26.63
Phrase pairs 38 M 5.26 M 27.76 25.76 28.82 26.94
N -Best list 1 16 M 1.59 M 27.93 25.87 29.07 26.57
N -Best list 2 11 M 1.22 M 27.46 25.37 28.79 26.59
N -Best list 1 nonUnique 16 M 1.41M 27.99 25.97 29.07 26.65
System 1 the performance of this approach drops.
Consequently, it seems to be fine to use an N -
Best list of a more general system to generate the
negative examples. But the N -Best list should not
stem from an adapted system.
Finally, the phrase table was trained on the same
corpus as the one that was used to generate the N -
Best lists for DWL training. Since we have seen
the data before, longer phrases can be used than
in a real test scenario. To compensate partly for
that, we removed all phrase pairs that occur only
once in the phrase table. The results are shown in
the last line. This approach could slightly improve
the translation quality leading to a BLEU score of
25.97 for System 1 and 26.65 for the System 2.
6.4 Target Features
After evaluating the different approaches to gen-
erate the negative examples, we also evaluated the
different approaches for the target features. The
results are summarized in Table 3. In all these ex-
periments we use the training examples generated
by the N -Best list of System 1 using the phrase
table without unique phrase pairs.
First, we tested the four different methods using
a context of one word before and one word after
the word.
In the experiments the first two methods, All
TF and N-Best TF , perform worse than the last
two approaches, Separate TF and Restricted TF.
So it seems to be important to have realistic exam-
ples and not to mix different target contexts in one
example. The Separate and Restricted approach
perform similarly well. In both cases the perfor-
mance can be improved slightly by using a context
of three words before and after instead of using
only one word.
If we look at the model size, the number of
weights increases from 16M to 17M, when using
a context of one word and to 21M using a context
of three words.
If we compare the results to the systems using
no target features in the first row, no or only slight
improvements can be achieved. One reason might
be that the morphology of English is not very com-
plex and therefore, the target context is not as im-
portant to determine the correct translation.
6.4.1 Overview
In Table 4, we give an overview of the results us-
ing the different extensions to DWLs given in this
paper. The baseline system does not use any DWL
at all. If we use a DWL using only bag-of-words
features and the training examples from the phrase
pairs, we can improve by 1.3 BLEU points on Sys-
tem 1 and 0.3 BLEU points on System 2.
By adding the source-context features, the first
system can be improved by 0.2 BLEU points and
the second one by 0.8 BLEU points. If we use the
training examples from the N -Best list instead of
using the ones from the phrase table, we improve
by 0.2 on System 1, but perform 0.3 worse on Sys-
tem 2. Adding the target context features does not
improve System 1, but System 2 can be improved
by 0.3 BLEU points. This system results in the
best average performance. Compared to the base-
line system with DWLs, we can improve by 0.4
and 0.8 BLEU points, respectively.
Table 4: Overview of results for TED lectures
System System 1 System 2
Dev Test Dev Test
Baseline 26.32 24.24 28.40 25.89
DWL 27.46 25.56 28.58 26.15
sourceContext 27.76 25.76 28.82 26.94
N -Best 27.99 25.97 29.07 26.65
TargetContext 28.15 25.91 29.12 26.90
6.5 German - English WMT 13 Experiments
In addition to the experiments on the TED data,
we also tested the models in the systems for the
518
Table 3: Experiments using different target features
System Context System 1 System 2
Dev Test Dev Test
No Target Features 0-0 27.99 25.97 29.07 26.65
All TF 1-1 27.80 25.48 28.80 26.38
N-Best TF 1-1 27.99 25.74 28.86 26.37
Separate TF 1-1 28.06 25.81 28.98 26.80
Restricted TF 1-1 28.13 25.84 28.94 26.68
Separate TF 3-3 27.87 25.90 28.99 26.75
Restricted TF 3-3 28.15 25.91 29.12 26.90
WMT 2013. The systems are similar to the one
used before, but were trained on all available train-
ing data and use additional models. The systems
were tested on newstest2012. The results for Ger-
man to English are summarized in Table 5. In this
case the DWLs were trained on the EPPS and the
NC corpus. Since the corpora are bigger, we per-
form an additional weight filtering on the models.
The baseline system uses already a DWL
trained with the bag-of-words features and the
training examples were created using the phrase
table. If we add the bag-of-n-grams features up
to a n-gram length of 3, we cannot improve the
translation quality on this task. But by addition-
ally generating the negative training examples us-
ing the 300-Best list, we can improve this system
by 0.2 BLEU points.
Table 5: Experiments on German to English WMT
2013
System Dev Test
Unigram DWL 25.79 24.36
+ Bag-of-n-gram 25.85 24.33
+ N -Best 25.84 24.52
6.6 English - German WMT 13 Experiments
We also tested the approach also on the reverse
direction. Since the German morphology is much
more complex than the English one, we hope that
in this case the target features can help more. The
results for this task are shown in Table 6. Here, the
baseline system again already uses DWLs. If we
add the bag-of-n-grams features and generate the
training examples from the 300-Best list, we can
again slightly improve the translation quality. In
this case we can improve the translation quality by
additional 0.1 BLEU points by adding the target
features. This leads to an overall improvement by
nearly 0.2 BLEU points.
Table 6: Experiments on English to German WMT
2013
System Dev Test
unigram DWL 16.97 17.41
+ Bag-of-n-gram 16.89 17.45
+ N -Best 17.10 17.47
+ Target Features 17.08 17.58
7 Conclusion
Discriminative Word Lexica have been recently
used in several translation systems and have shown
to improve the translation quality. In this work, we
extended the approach to improve its modeling of
the translation process.
First, we added features which represent the
structure of the sentence better. By using bag-of-
n-grams features instead of bag-of-words features,
we are able to encode the order of the source sen-
tence. Furthermore, we use features for the sur-
rounding target words to also model the target con-
text of the word. In addition, we tried to train the
DWLs in a way that they help to address possi-
ble errors of the MT system by feeding informa-
tion from the MT system back into the generation
of the negative training examples. Thereby, we
could reduce the size of the models and improve
the translation quality. Overall, we were able to
improve the translation quality on three different
tasks in two different translation directions. Im-
provements of up to 0.8 BLEU points could be
achieved.
519
8 Acknowledgements
This work was partly achieved as part of the
Quaero Programme, funded by OSEO, French
State agency for innovation. The research lead-
ing to these results has received funding from
the European Union Seventh Framework Pro-
gramme (FP7/2007-2013) under grant agreement
n? 287658.
References
S. Bangalore, P. Haffner, and S. Kanthak. 2007. Sta-
tistical Machine Translation through Global Lexical
Selection and Sentence Reconstruction. In Annual
Meeting-Association for Computational Linguistics,
volume 45, page 152.
M. Carpuat and D. Wu. 2007. Improving Statis-
tical Machine Translation using Word Sense Dis-
ambiguation. In In The 2007 Joint Conference on
Empirical Methods in Natural Language Processing
and Computational Natural Language Learning.
R. Haque, S.K. Naskar, A. Bosch, and A. Way.
2011. Integrating source-language context into
phrase-based statistical machine translation. Ma-
chine Translation, 25(3):239?285.
M. Huck, M. Ratajczak, P. Lehnen, and H. Ney. 2010.
A Comparison of Various Types of Extended Lexi-
con Models for Statistical Machine Translation. In
Proc. of the Conf. of the Assoc. for Machine Trans-
lation in the Americas (AMTA).
M. Jeong, K. Toutanova, H. Suzuki, and C. Quirk.
2010. A Discriminative Lexicon Model for Com-
plex Morphology. In Proceedings of the Ninth Con-
ference of the Association for Machine Translation
in the Americas (AMTA 2010).
P. Koehn and K. Knight. 2003. Empirical Methods for
Compound Splitting. In EACL, Budapest, Hungary.
P. Koehn, F.J. Och, and D. Marcu. 2003. Statis-
tical Phrase-Based Translation. In Proceedings of
the 2003 Conference of the North American Chap-
ter of the Association for Computational Linguistics
on Human Language Technology, pages 48?54, Ed-
monton, Canada.
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,
and E. Herbst. 2007. Moses: Open Source Toolkit
for Statistical Machine Translation. In ACL 2007,
Demonstration Session, Prague, Czech Republic.
A. Mauser, S. Hasan, and H. Ney. 2009. Extending
Statistical Machine Translation with Discriminative
and Trigger-based Lexicon Models. In Proceedings
of the 2009 Conference on Empirical Methods in
Natural Language Processing: Volume 1 ? Volume
1, Emnlp?09, Singapore.
M. Mediani, E. Cho, J. Niehues, T. Herrmann, and
A. Waibel. 2011. The KIT English-French Trans-
lation Systems for IWSLT 2011. Proceedings of the
eight International Workshop on Spoken Language
Translation (IWSLT).
Jan Niehues and Mutsin Kolss. 2009. A POS-Based
Model for Long-Range Reorderings in SMT. Fourth
Workshop on Statistical Machine Translation (WMT
2009), Athens, Greece.
J. Niehues and S. Vogel. 2008. Discriminative Word
Alignment via Alignment Matrix Modeling. Pro-
ceedings of the Third Workshop on Statistical Ma-
chine Translation, pages 18?25.
J. Niehues and A. Waibel. 2012. Detailed Analysis of
different Strategies for Phrase Table Adaptation in
SMT. In Proceedings of the Tenth Conference of the
Association for Machine Translation in the Ameri-
cas (AMTA).
J. Niehues, T. Herrmann, S. Vogel, and A. Waibel.
2011. Wider Context by Using Bilingual Language
Models in Machine Translation. Sixth Workshop on
Statistical Machine Translation (WMT 2011), Edin-
burgh, UK.
K. Rottmann and S. Vogel. 2007. Word Reordering in
Statistical Machine Translation with a POS-Based
Distortion Model. In TMI, Sko?vde, Sweden.
H. Schmid. 1994. Probabilistic Part-of-Speech Tag-
ging Using Decision Trees. In International Con-
ference on New Methods in Language Processing,
Manchester, UK.
A. Stolcke. 2002. SRILM ? An Extensible Language
Modeling Toolkit. In Icslp, Denver, Colorado, USA.
A. Venugopal, A. Zollman, and A. Waibel. 2005.
Training and Evaluation Error Minimization Rules
for Statistical Machine Translation. In Workshop on
Data-drive Machine Translation and Beyond (WPT-
05), Ann Arbor, MI.
520
Proceedings of the Workshop on Continuous Vector Space Models and their Compositionality, pages 30?39,
Sofia, Bulgaria, August 9 2013. c?2013 Association for Computational Linguistics
Letter N-Gram-based Input Encoding for Continuous Space Language
Models
Henning Sperr?, Jan Niehues? and Alexander Waibel?
Institute of Anthropomatics
KIT - Karlsruhe Institute of Technology
Karlsruhe, Germany
? firstname.lastname@kit.edu
? henning.sperr@student.kit.edu
Abstract
We present a letter-based encoding for
words in continuous space language mod-
els. We represent the words completely by
letter n-grams instead of using the word
index. This way, similar words will au-
tomatically have a similar representation.
With this we hope to better generalize
to unknown or rare words and to also
capture morphological information. We
show their influence in the task of machine
translation using continuous space lan-
guage models based on restricted Boltz-
mann machines. We evaluate the trans-
lation quality as well as the training time
on a German-to-English translation task of
TED and university lectures as well as on
the news translation task translating from
English to German. Using our new ap-
proach a gain in BLEU score by up to 0.4
points can be achieved.
1 Introduction
Language models play an important role in natural
language processing. The most commonly used
approach is n-gram-based language models (Chen
and Goodman, 1999).
In recent years Continuous Space Language
Models (CSLMs) have gained a lot of atten-
tion. Compared to standard n-gram-based lan-
guage models they promise better generalization
to unknown histories or n-grams with only few
occurrences. Since the words are projected into
a continuous space, true interpolation can be per-
formed when an unseen sample appears. The stan-
dard input layer for CSLMs is a so called 1-of-
n coding where a word is represented as a vector
with a single neuron turned on and the rest turned
off. In the standard approach it is problematic to
infer probabilities for words that are not inside the
vocabulary. Sometimes an extra unknown neu-
ron is used in the input layer to represent these
words (Niehues and Waibel, 2012). Since all un-
seen words get mapped to the same neuron, no real
discrimination between those words can be done.
Furthermore, rare words are also hard to model,
since there is too few training data available to es-
timate their associated parameters.
We try to overcome these shortcomings by
using subword features to cluster similar words
closer together and generalize better over unseen
words. We hope that words containing similar let-
ter n-grams will yield a good indicator for words
that have the same function inside the sentence.
Introducing a method for subword units also has
the advantage that the input layer can be smaller,
while still representing nearly the same vocabulary
with unique feature vectors. By using a smaller in-
put layer, less weights need to be trained and the
training is faster. In this work we present the letter
n-gram approach to represent words in an CSLM,
and compare it to the word-based CSLM presented
in Niehues and Waibel (2012).
The rest of this paper is structured as follows:
First we will give an overview of related work.
After that we give a brief overview of restricted
Boltzmann machines which are the basis of the
letter-based CSLM presented in Section 4. Then
we will present the results of the experiments and
conclude our work.
2 Related Work
First research on neural networks to predict word
categories has been done in Nakamura et al
(1990) where neural networks were used to pre-
dict word categories. Xu and Rudnicky (2000)
proposed a language model that has an input con-
sisting of one word and no hidden units. This
network was limited to infer unigram and bigram
statistics. There has been research on feed for-
ward neural network language models where they
30
achieved a decrease in perplexity compared to
standard n-gram language models (Bengio et al,
2003). In Schwenk and Gauvain (2005) and later
in Schwenk (2007) research was performed on
training large scale neural network language mod-
els on millions of words resulting in a decrease of
the word error rate for continuous speech recog-
nition. In Schwenk et al (2006) they use the
CSLM framework to rescore n-best lists of a ma-
chine translation system during tuning and testing
steps. Usually these networks use short lists to
reduce the size of the output layer and to make
calculation feasible. There have been approaches
to optimize the output layer of such a network,
so that vocabularies of arbitrary size can be used
and there is no need to back off to a smaller n-
gram model (Le et al, 2011). In this Structured
Output Layer (SOUL) neural network language
model a hierarchical output layer was chosen. Re-
current Neural Networks have also been used to
try and improve language model perplexities in
Mikolov et al (2010), concluding that Recurrent
Neural Networks potentially improve over classi-
cal n-gram language models with increasing data
and a big enough hidden unit size of the model.
In the work of Mnih and Hinton (2007) and Mnih
(2010) training factored restricted Boltzmann ma-
chines yielded no gain compared to Kneser-Ney
smoothed n-gram models. But it has been shown
in Niehues and Waibel (2012), that using a re-
stricted Boltzmann machine with a different layout
during decoding can yield an increase in BLEU
score. There has also been a lot of research in
the field of using subword units for language mod-
eling. In Shaik et al (2011) linguistically moti-
vated sub-lexical units were proposed to improve
open vocabulary speech recognition for German.
Research on morphology-based and subword lan-
guage models on a Turkish speech recognition task
has been done by Sak et al (2010). The idea
of Factored Language models in machine transla-
tion has been introduced by Kirchhoff and Yang
(2005). Similar approaches to develop joint lan-
guage models for morphologically rich languages
in machine translation have been presented by
Sarikaya and Deng (2007). In Emami et al (2008)
a factored neural network language model for Ara-
bic was built. They used different features such as
segmentation, part-of-speech and diacritics to en-
rich the information for each word.
3 Restricted Boltzmann Machine-based
Language Model
In this section we will briefly review the con-
tinuous space language models using restricted
Boltzmann machines (RBM). We will focus on
the parts that are important for the implementa-
tion of the input layers described in the next sec-
tion. A restricted Boltzmann machine is a gener-
ative stochastic neural network which consists of
a visible and a hidden layer of neurons that have
unidirectional connections between the layers but
no inner layer connections as shown in Figure 1.
Visible
Hidden
Figure 1: Restricted Boltzmann Machine.
The activation of the visible neurons will be de-
termined by the input data. The standard input
layer for neural network language models uses a
1-of-n coding to insert a word from the vocabulary
into the network. This is a vector, where only the
index of the word in the vocabulary is set to one
and the rest to zero. Sometimes this is also referred
to as a softmax layer of binary units. The activa-
tion of the hidden units is usually binary and will
be inferred from the visible units by using sam-
pling techniques. In Niehues and Waibel (2012)
an n-gram Boltzmann machine language model is
proposed using such a softmax layer for each con-
text. In this work, we want to explore different
ways of encoding the word observations in the in-
put layer. Figure 2 is an example of the original
model with three hidden units, two contexts and
a vocabulary of two words. In this example the
bigram my house is modeled.
To calculate the probability of a visible config-
uration v we will use the definition of the free en-
ergy in a restricted Boltzmann machine with bi-
nary stochastic hidden units, which is
F (v) = ?
?
i
viai ?
?
j
log(1 + exj ) (1)
where ai is the bias of the ith visible neuron vi and
31
Visible
<s> </s> my house <s> </s> my house
Hidden
Figure 2: RBMLM with three hidden units and a
vocabulary size of two words and two word con-
texts, where activated units are marked as black.
xj is the activation of the jth hidden neuron. The
activation xj is defined as
xj = bj +
?
i
viwij (2)
where bj is the bias of the jth hidden neuron and
wij is the weight between visible unit vi and hid-
den unit xj . Using these definitions, the probabil-
ity of our visible configuration v is
p(v) =
1
Z
e?F (v) (3)
with the partition function Z =
?
v e
?F (v) being
the normalization constant. Usually this normal-
ization constant is not easy to compute since it is
a sum over an exponential amount of values. We
know that the free energy will be proportional to
the true probability of our visible vector, this is
the reason for using the free energy as a feature
in our log-linear model instead of the true prob-
ability. In order to use it as a feature inside the
decoder we actually need to be able to compute
the probability for a whole sentence. As shown in
Niehues and Waibel (2012) we can do this by sum-
ming over the free energy of all n-grams contained
in the sentence.
3.1 Training
For training the restricted Boltzmann machine lan-
guage model (RBMLM) we used the Contrastive
Divergence (CD) algorithm as proposed in Hinton
(2010). In order to do this, we need to calculate the
derivation of the probability of the example given
the weights
? log p(v)
?wij
= <vihj>data ?<vihj>model (4)
where <vihj>model is the expected value of vihj
given the distribution of the model. In other
words we calculate the expectation of how often
vi and hj are activated together, given the dis-
tribution of the data, minus the expectation of
them being activated together given the distribu-
tion of the model, which will be calculated us-
ing Gibbs-Sampling techniques. Usually many
steps of Gibbs-Sampling are necessary to get an
unbiased sample from the distribution, but in the
Contrastive Divergence algorithm only one step of
sampling is performed (Hinton, 2002).
4 Letter-based Word Encoding
In this section we will describe the proposed in-
put layers for the RBMLM. Compared to the word
index-based representation explained above, we
try to improve the capability to handle unknown
words and morphology by splitting the word into
subunits.
4.1 Motivation
In the example mentioned above, the word index
model might be able to predict my house but it
will fail on my houses if the word houses is not in
the training vocabulary. In this case, a neuron that
classifies all unknown tokens or some other tech-
niques to handle such a case have to be utilized.
In contrast, a human will look at the single let-
ters and see that these words are quite similar. He
will most probably recognize that the appended s
is used to mark the plural form, but both words re-
fer to the same thing. So he will be able to infer
the meaning although he has never seen it before.
Another example in English are be the words
happy and unhappy. A human speaker who does
not know the word unhappy will be able to know
from the context what unhappy means and he can
guess that both of the words are adjectives, that
have to do with happiness, and that they can be
used in the same way.
In other languages with a richer morphology,
like German, this problem is even more important.
The German word scho?n (engl. beautiful) can have
16 different word forms, depending on case, num-
ber and gender.
Humans are able to share information about
words that are different only in some morphemes
like house and houses. With our letter-based input
encoding we want to generalize over the common
word index model to capture morphological infor-
32
mation about the words to make better predictions
for unknown words.
4.2 Features
In order to model the aforementioned morpholog-
ical word forms, we need to create features for
every word that represent which letters are used
in the word. If we look at the example of house,
we need to model that the first letter is an h, the
second is an o and so on.
If we want to encode a word this way, we have
the problem that we do not have a fixed size of
features, but the feature size depends on the length
of the word. This is not possible in the framework
of continuous space language models. Therefore,
a different way to represent the word is needed.
An approach for having a fixed size of features
is to just model which letters occur in the word.
In this case, every input word is represented by a
vector of dimension n, where n is the size of the
alphabet in the text. Every symbol, that is used
in the word is set to one and all the other features
are zero. By using a sparse representation, which
shows only the features that are activated, the word
house would be represented by
w1 = e h o s u
The main problem of this representation is that
we lose all information about the order of the let-
ters. It is no longer possible to see how the word
ends and how the word starts. Furthermore, many
words will be represented by the same feature vec-
tor. For example, in our case the words house and
houses would be identical. In the case of houses
and house this might not be bad, but the words
shortest and others or follow and wolf will also
map to the same input vector. These words have
no real connection as they are different in mean-
ing and part of speech.
Therefore, we need to improve this approach
to find a better model for input words. N-grams
of words or letters have been successfully used to
model sequences of words or letters in language
models. We extend our approach to model not
only the letters that occur in the in the word, but
the letter n-grams that occur in the word. This
will of course increase the dimension of the fea-
ture space, but then we are able to model the order
of the letters. In the example of my house the fea-
ture vector will look like
w1 = my <w>m y</w>
w2 = ho ou se us <w>h e</w>
We added markers for the beginning and end of
the word because this additional information is im-
portant to distinguish words. Using the example
of the word houses, modeling directly that the last
letter is an s could serve as an indication of a plural
form.
If we use higher order n-grams, this will in-
crease the information about the order of the let-
ters. But these letter n-grams will also occur more
rarely and therefore, the weights of these features
in the RBM can no longer be estimated as reliably.
To overcome this, we did not only use the n-grams
of order n, but all n-grams of order n and smaller.
In the last example, we will not only use the bi-
grams, but also the unigrams.
This means my house is actually represented as
w1 = m y my <w>m y</w>
w2 = e h o s u ho ou se us <w>h e</w>
With this we hope to capture many morpholog-
ical variants of the word house. Now the represen-
tations of the words house and houses differ only
in the ending and in an additional bigram.
houses = ... es s</w>
house = ... se e</w>
The beginning letters of the two words will con-
tribute to the same free energy only leaving the
ending letter n-grams to contribute to the different
usages of houses and house.
The actual layout of the model can be seen in
Figure 3. For the sake of clarity we left out the
unigram letters. In this representation we now do
not use a softmax input layer, but a logistic input
layer defined as
p(vi = on) =
1
1 + e?xi
(5)
where vi is the ith visible neuron and xi is the in-
put from the hidden units for the ith neuron de-
fined as
xi = ai +
?
j
hjwij (6)
with ai being the bias of the visible neuron vi and
wij being the weight between the hidden unit hj
and vi.
33
Visible
<i>>e/
myho ou myhH dssemyho ou umnyh semyhH
?
ds umnyh
?
Figure 3: A bigram letter index RBMLM with
three hidden units and two word contexts, where
activated units are marked as black.
4.3 Additional Information
The letter index approach can be extended by
several features to include additional information
about the words. This could for example be part-
of-speech tags or other morphological informa-
tion. In this work we tried to include a neuron
to capture capital letter information. To do this we
included a neuron that will be turned on if the first
letter was capitalized and another neuron that will
be turned on if the word was written in all capital
letters. The word itself will be lowercased after we
extracted this information.
Using the example of European Union, the new
input vector will look like this
w1 =a e n o p r u an ea eu op pe ro ur
<w>e n</w><CAPS>
w2 =u i n o un io ni on
<w>u n</w><CAPS>
This will lead to a smaller letter n-gram vocab-
ulary since all the letter n-grams get lowercased.
This also means there is more data for each of the
letter n-gram neurons that were treated differently
before. We also introduced an all caps feature
which is turned on if the whole word was written
in capital letters. We hope that this can help detect
abbreviations which are usually written in all cap-
ital letters. For example EU will be represented
as
w1 = e u eu <w>e u</w><ALLCAPS>
5 Evaluation
We evaluated the RBM-based language model
on different statistical machine translation (SMT)
tasks. We will first analyze the letter-based word
representation. Then we will give a brief descrip-
tion of our SMT system. Afterwards, we de-
scribe in detail our experiments on the German-
to-English translation task. We will end with addi-
tional experiments on the task of translating Eng-
lish news documents into German.
5.1 Word Representation
In first experiments we analyzed whether the
letter-based representation is able to distinguish
between different words. In a vocabulary of
27,748 words, we compared for different letter n-
gram sizes how many words are mapped to the
same input feature vector.
Table 1 shows the different models, their input
dimensions and the total number of unique clus-
ters as well as the amount of input vectors con-
taining one, two, three or four or more words that
get mapped to this input vector. In the word index
representation every word has its own feature vec-
tor. In this case the dimension of the input vector
is 27,748 and each word has its own unique input
vector.
If we use only letters, as done in the unigram
model, only 62% of the words have a unique repre-
sentation. Furthermore, there are 606 feature vec-
tors representing 4 or more words. This type of
encoding of the words is not sufficient for the task.
When using a bigram letter context nearly each
of the 27,748 words has a unique input represen-
tation, although the input dimension is only 7%
compared to the word index. With the three let-
ter vocabulary context and higher there is no input
vector that represents more than three words from
the vocabulary. This is good since we want similar
words to be close together but not have exactly the
same input vector. The words that are still clus-
tered to the same input are mostly numbers or typ-
ing mistakes like ?YouTube? and ?Youtube?.
5.2 Translation System Description
The translation system for the German-to-English
task was trained on the European Parliament cor-
pus, News Commentary corpus, the BTEC cor-
pus and TED talks1. The data was preprocessed
and compound splitting was applied for German.
Afterwards the discriminative word alignment ap-
proach as described in Niehues and Vogel (2008)
was applied to generate the alignments between
source and target words. The phrase table was
1http://www.ted.com
34
#Vectors mapping to
Model Caps VocSize TotalVectors 1 Word 2 Words 3 Words 4+ Words
WordIndex - 27,748 27,748 27,748 0 0 0
Letter 1-gram No 107 21,216 17,319 2,559 732 606
Letter 2-gram No 1,879 27,671 27,620 33 10 8
Letter 3-gram No 12,139 27,720 27,701 10 9 0
Letter 3-gram Yes 8,675 27,710 27,681 20 9 0
Letter 4-gram No 43,903 27,737 27,727 9 1 0
Letter 4-gram Yes 25,942 27,728 27,709 18 1 0
Table 1: Comparison of the vocabulary size and the possibility to have a unique representation of each
word in the training corpus.
built using the scripts from the Moses package de-
scribed in Koehn et al (2007). A 4-gram language
model was trained on the target side of the parallel
data using the SRILM toolkit from Stolcke (2002).
In addition, we used a bilingual language model as
described in Niehues et al (2011). Reordering was
performed as a preprocessing step using part-of-
speech (POS) information generated by the Tree-
Tagger (Schmid, 1994). We used the reorder-
ing approach described in Rottmann and Vogel
(2007) and the extensions presented in Niehues et
al. (2009) to cover long-range reorderings, which
are typical when translating between German and
English. An in-house phrase-based decoder was
used to generate the translation hypotheses and
the optimization was performed using the MERT
implementation as presented in Venugopal et al
(2005). All our evaluation scores are measured us-
ing the BLEU metric.
We trained the RBMLM models on 50K sen-
tences from TED talks and optimized the weights
of the log-linear model on a separate set of TED
talks. For all experiments the RBMLMs have been
trained with a context of four words. The devel-
opment set consists of 1.7K segments containing
16K words. We used two different test sets to
evaluate our models. The first test set contains
TED talks with 3.5K segments containing 31K
words. The second task was from an in-house
computer science lecture corpus containing 2.1K
segments and 47K words. For both tasks we used
the weights optimized on TED.
For the task of translating English news texts
into German we used a system developed for the
Workshop on Machine Translation (WMT) eval-
uation. The continuous space language models
were trained on a random subsample of 100K sen-
tences from the monolingual training data used for
this task. The out-of-vocabulary rates for the TED
task are 1.06% while the computer science lec-
tures have 2.73% and nearly 1% on WMT.
5.3 German-to-English TED Task
The results for the translation of German TED lec-
tures into English are shown in Table 2. The base-
line system uses a 4-gram Kneser-Ney smoothed
language model trained on the target side parallel
data. We then added a RBMLM, which was only
trained on the English side of the TED corpus.
If the word index RBMLM trained for one iter-
ation using 32 hidden units is added, an improve-
ment of about 1 BLEU can be achieved. The let-
ter bigram model performs about 0.4 BLEU points
better than no additional model, but significantly
worse then the word index model or the other let-
ter n-gram models. The letter 3- to 5-gram-based
models obtain similar BLEU scores, varying only
by 0.1 BLEU point. They also achieve a 0.8 to
0.9 BLEU points improvement against the base-
line system and a 0.2 to 0.1 BLEU points decrease
than the word index-based encoding.
System Dev Test
Baseline 26.31 23.02
+WordIndex 27.27 24.04
+Letter 2-gram 26.67 23.44
+Letter 3-gram 26.80 23.84
+Letter 4-gram 26.79 23.93
+Letter 5-gram 26.64 23.82
Table 2: Results for German-to-English TED
translation task
Using the word index model with the first base-
line system increases the BLEU score nearly as
much as adding a n-gram-based language model
trained on the TED corpus as done in the base-
35
line of the systems presented in Table 3. In these
experiments all letter-based models outperformed
the baseline system. The bigram-based language
model performs worst and the 3- and 4-gram-
based models perform only slightly worse than the
word index-based model.
System Dev Test
Baseline+ngram 27.45 24.06
+WordIndex 27.70 24.34
+Letter 2-gram 27.45 24.15
+Letter 3-gram 27.52 24.25
+Letter 4-gram 27.60 24.30
Table 3: Results of German-to-English TED trans-
lations using an additional in-domain language
model.
A third experiment is presented in Table 4. Here
we also applied phrase table adaptation as de-
scribed in Niehues et al (2010). In this experiment
the word index model improves the system by 0.4
BLEU points. In this case all letter-based models
perform very similar. They are again performing
slightly worse than the word index-based system,
but better than the baseline system.
To summarize the results, we could always im-
prove the performance of the system by adding
the letter n-gram-based language model. Further-
more, in most cases, the bigram model performs
worse than the higher order models. It seems to be
important for this task to have more context infor-
mation. The 3- and 4-gram-based models perform
almost equal, but slightly worse than the word
index-based model.
System Dev Test
BL+ngram+adaptpt 28.40 24.57
+WordIndex 28.55 24.96
+Letter 2-gram 28.31 24.80
+Letter 3-gram 28.31 24.71
+Letter 4-gram 28.46 24.65
Table 4: Results of German-to-English TED trans-
lations with additional in-domain language model
and adapted phrase table.
5.3.1 Caps Feature
In addition, we evaluated the proposed caps fea-
ture compared to the non-caps letter n-gram model
and the baseline systems. As we can see in Ta-
ble 5, caps sometimes improves and sometimes
decreases the BLEU score by about ?0.2 BLEU
points. One reason for that might be that most
English words are written lowercased, therefore
we do not gain much information.
System Dev Test
Baseline 26.31 23.02
+Letter 3-gram 26.80 23.84
+Letter 3-gram+caps 26.67 23.85
Baseline+ngram 27.45 24.06
+Letter 3-gram 27.52 24.25
+Letter 3-gram+caps 27.60 24.47
BL+ngram+adaptpt 28.40 24.57
+Letter 3-gram 28.31 24.71
+Letter 3-gram+caps 28.43 24.66
Table 5: Difference between caps and non-caps
letter n-gram models.
5.4 German-to-English CSL Task
After that, we evaluated the computer science lec-
ture (CSL) test set. We used the same system as
for the TED translation task. We did not perform
a new optimization, since we wanted so see how
well the models performed on a different task.
The results are summarized in Table 6. In this
case the baseline is outperformed by the word in-
dex approach by approximately 1.1 BLEU points.
Except for the 4-gram model the results are similar
to the result for the TED task. All systems could
again outperform the baseline.
System Test
Baseline 23.60
+WordIndex 24.76
+Letter 2-gram 24.17
+Letter 3-gram 24.36
+Letter 4-gram 23.82
Table 6: Results the baseline of the German-to-
English CSL task.
The system with the additional in-domain lan-
guage model in Table 7 shows that both letter
n-gram language models perform better than the
baseline and the word index model, improving the
baseline by about 0.8 to 1 BLEU. Whereas the
word index model only achieved an improvement
of 0.6 BLEU points.
The results of the system with the additional
phrase table adaption can be seen in Table 8. The
36
System Test
Baseline+ngram 23.81
+WordIndex 24.41
+Letter 2-gram 24.37
+Letter 3-gram 24.66
+Letter 4-gram 24.85
Table 7: Results on German-to-English CSL cor-
pus with additional in-domain language model.
word index model improves the baseline by 0.25
BLEU points. The letter n-gram models improve
the baseline by about 0.3 to 0.4 BLEU points also
improving over the word index model. The letter
bigram model in this case performs worse than the
baseline.
System Test
BL+ngram+adaptpt 25.00
+WordIndex 25.25
+Letter 2-gram 24.68
+Letter 3-gram 25.43
+Letter 4-gram 25.33
Table 8: Results on German-to-English CSL with
additional in-domain language model and adapted
phrase table.
In summary, again the 3- and 4-gram letter mod-
els perform mostly better than the bigram version.
They both perform mostly equal. In contrast to the
TED task, they were even able to outperform the
word index model in some configurations by up to
0.4 BLEU points.
5.5 English-to-German News Task
When translating English-to-German news we
could not improve the performance of the base-
line by using a word index model. In contrast, the
performance dropped by 0.1 BLEU points. If we
use a letter bigram model, we could improve the
translation quality by 0.1 BLEU points over the
baseline system.
System Dev Test
Baseline 16.90 17.36
+WordIndex 16.79 17.29
+Letter 2-gram 16.91 17.48
Table 9: Results for WMT2013 task English-to-
German.
5.6 Model Size and Training Times
In general the letter n-gram models perform al-
most as good as the word index model on English
language tasks. The advantage of the models up to
the letter 3-gram context model is that the training
time is lower compared to the word index model.
All the models were trained using 10 cores and
a batch size of 10 samples per contrastive diver-
gence update. As can be seen in Table 10 the letter
3-gram model needs less than 50% of the weights
and takes around 75% of the training time of the
word index model. The four letter n-gram model
takes longer to train due to more parameters.
Model #Weights Time
WordIndex 3.55 M 20 h 10 min
Letter 2-gram 0.24 M 1h 24 min
Letter 3-gram 1.55 M 15 h 12 min
Letter 4-gram 5.62 M 38 h 59 min
Table 10: Training time and number of parameters
of the RBMLM models.
6 Conclusions
In this work we presented the letter n-gram-based
input layer for continuous space language models.
The proposed input layer enables us to encode the
similarity of unknown words directly in the input
layer as well as to directly model some morpho-
logical word forms.
We evaluated the encoding on different trans-
lation tasks. The RBMLM using this encod-
ing could always improve the translation qual-
ity and perform similar to a RBMLM based on
word indices. Especially in the second configu-
ration which had a higher OOV rate, the letter n-
gram model performed better than the word index
model. Moreover, the model based on letter 3-
grams uses only half the parameters of the word
index model. This reduced the training time of the
continuous space language model by a quarter.
Acknowledgments
This work was partly achieved as part of the
Quaero Programme, funded by OSEO, French
State agency for innovation. The research lead-
ing to these results has received funding from
the European Union Seventh Framework Pro-
gramme (FP7/2007-2013) under grant agreement
n? 287658.
37
References
Yoshua Bengio, Re?jean Ducharme, Pascal Vincent, and
Christian Jauvin. 2003. A Neural Probabilistic Lan-
guage Model. Journal of Machine Learning Re-
search, 3:1137?1155.
Stanley F. Chen and Joshua Goodman. 1999. An
empirical study of smoothing techniques for lan-
guage modeling. Computer Speech & Language,
13(4):359?393.
Ahmad Emami, Imed Zitouni, and Lidia Mangu. 2008.
Rich morphology based n-gram language models for
arabic. In INTERSPEECH, pages 829?832. ISCA.
Geoffrey E. Hinton. 2002. Training products of ex-
perts by minimizing contrastive divergence. Neural
Comput., 14(8):1771?1800, August.
Geoffrey Hinton. 2010. A Practical Guide to Training
Restricted Boltzmann Machines. Technical report,
University of Toronto.
Katrin Kirchhoff and Mei Yang. 2005. Improved Lan-
guage Modeling for Statistical Machine Translation.
In Proceedings of the ACL Workshop on Building
and Using Parallel Texts, pages 125?128, Ann Ar-
bor, Michigan, USA.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexan-
dra Constantin, and Evan Herbst. 2007. Moses:
Open Source Toolkit for Statistical Machine Trans-
lation. In ACL 2007, Demonstration Session,
Prague, Czech Republic.
Hai Son Le, Ilya Oparin, Abdelkhalek Messaoudi,
Alexandre Allauzen, Jean-Luc Gauvain, and
Franc?ois Yvon. 2011. Large vocabulary soul neural
network language models. In INTERSPEECH 2011,
12th Annual Conference of the International Speech
Communication Association, Florence, Italy.
Tomas Mikolov, Martin Karafia?t, Lukas Burget, Jan
Cernocky?, and Sanjeev Khudanpur. 2010. Recur-
rent neural network based language model. In IN-
TERSPEECH 2010, 11th Annual Conference of the
International Speech Communication Association,
Makuhari, Chiba, Japan.
Andriy Mnih and Geoffrey Hinton. 2007. Three new
graphical models for statistical language modelling.
In Proceedings of the 24th international conference
on Machine Learning, ICML ?07, pages 641?648,
New York, NY, USA. ACM.
Andriy Mnih. 2010. Learning distributed representa-
tions for statistical language modelling and collabo-
rative filtering. Ph.D. thesis, University of Toronto,
Toronto, Ont., Canada. AAINR73159.
Masami Nakamura, Katsuteru Maruyama, Takeshi
Kawabata, and Kiyohiro Shikano. 1990. Neural
network approach to word category prediction for
english texts. In Proceedings of the 13th conference
on Computational linguistics - Volume 3, COLING
?90, pages 213?218, Stroudsburg, PA, USA.
Jan Niehues and Muntsin Kolss. 2009. A POS-Based
Model for Long-Range Reorderings in SMT. In
Fourth Workshop on Statistical Machine Translation
(WMT 2009), Athens, Greece.
Jan Niehues and Stephan Vogel. 2008. Discriminative
Word Alignment via Alignment Matrix Modeling.
In Proceedings of the Third Workshop on Statisti-
cal Machine Translation, StatMT ?08, pages 18?25,
Stroudsburg, PA, USA.
Jan Niehues and Alex Waibel. 2012. Continuous
Space Language Models using Restricted Boltz-
mann Machines. In Proceedings of the International
Workshop for Spoken Language Translation (IWSLT
2012), Hong Kong.
Jan Niehues, Mohammed Mediani, Teresa Herrmann,
Michael Heck, Christian Herff, and Alex Waibel.
2010. The KIT Translation system for IWSLT 2010.
In Proceedings of the Seventh International Work-
shop on Spoken Language Translation (IWSLT),
Paris, France.
Jan Niehues, Teresa Herrmann, Stephan Vogel, and
Alex Waibel. 2011. Wider Context by Using Bilin-
gual Language Models in Machine Translation. In
Sixth Workshop on Statistical Machine Translation
(WMT 2011), Edinburgh, UK.
Kay Rottmann and Stephan Vogel. 2007. Word Re-
ordering in Statistical Machine Translation with a
POS-Based Distortion Model. In TMI, Sko?vde,
Sweden.
Hasim Sak, Murat Saraclar, and Tunga Gungor. 2010.
Morphology-based and sub-word language model-
ing for Turkish speech recognition. In 2010 IEEE
International Conference on Acoustics Speech and
Signal Processing (ICASSP), pages 5402?5405.
Ruhi Sarikaya and Yonggang Deng. 2007. Joint
Morphological-Lexical Language Modeling for Ma-
chine Translation. In Human Language Technolo-
gies 2007: The Conference of the North American
Chapter of the Association for Computational Lin-
guistics; Companion Volume, Short Papers, pages
145?148, Rochester, New York, USA.
Helmut Schmid. 1994. Probabilistic Part-of-Speech
Tagging Using Decision Trees. In International
Conference on New Methods in Language Process-
ing, Manchester, UK.
Holger Schwenk and Jean-Luc Gauvain. 2005. Train-
ing neural network language models on very large
corpora. In Proceedings of the conference on Hu-
man Language Technology and Empirical Methods
in Natural Language Processing, HLT ?05, pages
201?208, Stroudsburg, PA, USA.
38
Holger Schwenk, Daniel Dchelotte, and Jean-Luc Gau-
vain. 2006. Continuous Space Language mModels
for Statistical Machine T ranslation. In Proceedings
of the COLING/ACL on Main conference poster ses-
sions, COLING-ACL ?06, pages 723?730, Strouds-
burg, PA, USA.
Holger Schwenk. 2007. Continuous Space Language
Models. Comput. Speech Lang., 21(3):492?518,
July.
M. Ali Basha Shaik, Amr El-Desoky Mousa, Ralf
Schlu?ter, and Hermann Ney. 2011. Hybrid language
models using mixed types of sub-lexical units for
open vocabulary german lvcsr. In INTERSPEECH
2011, 12th Annual Conference of the International
Speech Communication Association, Florence, Italy.
Andreas Stolcke. 2002. SRILM - an extensible
language modeling toolkit. In 7th International
Conference on Spoken Language Processing, IC-
SLP2002/INTERSPEECH 2002, Denver, Colorado,
USA.
Ashish Venugopal, Andreas Zollman, and Alex Waibel.
2005. Training and Evaluation Error Minimization
Rules for Statistical Machine Translation. In Work-
shop on Data-driven Machine Translation and Be-
yond (WPT-05), Ann Arbor, MI, USA.
Wei Xu and Alex Rudnicky. 2000. Can artificial neural
networks learn language models? In Sixth Interna-
tional Conference on Spoken Language Processing,
ICSLP 2000 / INTERSPEECH 2000, Beijing, China,
pages 202?205. ISCA.
39
Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 84?89,
Baltimore, Maryland USA, June 26?27, 2014.
c?2014 Association for Computational Linguistics
The KIT-LIMSI Translation System for WMT 2014
?
Quoc Khanh Do,
?
Teresa Herrmann,
??
Jan Niehues,
?
Alexandre Allauzen,
?
Franc?ois Yvon and
?
Alex Waibel
?
LIMSI-CNRS, Orsay, France
?
Karlsruhe Institute of Technology, Karlsruhe, Germany
?
surname@limsi.fr
?
firstname.surname@kit.edu
Abstract
This paper describes the joined submis-
sion of LIMSI and KIT to the Shared
Translation Task for the German-to-
English direction. The system consists
of a phrase-based translation system us-
ing a pre-reordering approach. The base-
line system already includes several mod-
els like conventional language models on
different word factors and a discriminative
word lexicon. This system is used to gen-
erate a k-best list. In a second step, the
list is reranked using SOUL language and
translation models (Le et al., 2011).
Originally, SOUL translation models were
applied to n-gram-based translation sys-
tems that use tuples as translation units
instead of phrase pairs. In this article,
we describe their integration into the KIT
phrase-based system. Experimental re-
sults show that their use can yield sig-
nificant improvements in terms of BLEU
score.
1 Introduction
This paper describes the KIT-LIMSI system for
the Shared Task of the ACL 2014 Ninth Work-
shop on Statistical Machine Translation. The sys-
tem participates in the German-to-English trans-
lation task. It consists of two main components.
First, a k-best list is generated using a phrase-
based machine translation system. This system
will be described in Section 2. Afterwards, the k-
best list is reranked using SOUL (Structured OUt-
put Layer) models. Thereby, a neural network lan-
guage model (Le et al., 2011), as well as several
translation models (Le et al., 2012a) are used. A
detailed description of these models can be found
in Section 3. While the translation system uses
phrase pairs, the SOUL translation model uses tu-
ples as described in the n-gram approach (Mari?no
et al., 2006). We describe the integration of the
SOUL models into the translation system in Sec-
tion 3.2. Section 4 summarizes the experimen-
tal results and compares two different tuning al-
gorithms: Minimum Error Rate Training (Och,
2003) and k-best Batch Margin Infused Relaxed
Algorithm (Cherry and Foster, 2012).
2 Baseline system
The KIT translation system is an in-house imple-
mentation of the phrase-based approach and in-
cludes a pre-ordering step. This system is fully
described in Vogel (2003).
To train translation models, the provided Eu-
roparl, NC and Common Crawl parallel corpora
are used. The target side of those parallel corpora,
the News Shuffle corpus and the GigaWord cor-
pus are used as monolingual training data for the
different language models. Optimization is done
with Minimum Error Rate Training as described
in Venugopal et al. (2005), using newstest2012
and newstest2013 as development and test data,
respectively.
Compound splitting (Koehn and Knight, 2003)
is performed on the source side (German) of the
corpus before training. Since the web-crawled
Common Crawl corpus is noisy, this corpus is
first filtered using an SVM classifier as described
in Mediani et al. (2011).
The word alignment is generated using the
GIZA++ Toolkit (Och and Ney, 2003). Phrase
extraction and scoring is done using the Moses
toolkit (Koehn et al., 2007). Phrase pair proba-
bilities are computed using modified Kneser-Ney
smoothing (Foster et al., 2006).
We apply short-range reorderings (Rottmann
and Vogel, 2007) and long-range reorder-
ings (Niehues and Kolss, 2009) based on part-of-
speech tags. The POS tags are generated using
the TreeTagger (Schmid, 1994). Rewriting rules
84
based on POS sequences are learnt automatically
to perform source sentence reordering according
to the target language word order. The long-range
reordering rules are further applied to the training
corpus to create reordering lattices to extract the
phrases for the translation model. In addition,
a tree-based reordering model (Herrmann et al.,
2013) trained on syntactic parse trees (Rafferty
and Manning, 2008; Klein and Manning, 2003)
is applied to the source sentence. In addition
to these pre-reordering models, a lexicalized
reordering model (Koehn et al., 2005) is applied
during decoding.
Language models are trained with the SRILM
toolkit (Stolcke, 2002) using modified Kneser-Ney
smoothing (Chen and Goodman, 1996). The sys-
tem uses a 4-gram word-based language model
trained on all monolingual data and an additional
language model trained on automatically selected
data (Moore and Lewis, 2010). The system fur-
ther applies a language model based on 1000 auto-
matically learned word classes using the MKCLS
algorithm (Och, 1999). In addition, a bilingual
language model (Niehues et al., 2011) is used as
well as a discriminative word lexicon (DWL) us-
ing source context to guide the word choices in the
target sentence.
3 SOUL models for statistical machine
translation
Neural networks, working on top of conventional
n-gram back-off language models (BOLMs), have
been introduced in (Bengio et al., 2003; Schwenk,
2007) as a potential means to improve discrete
language models. The SOUL model (Le et al.,
2011) is a specific neural network architecture that
allows us to estimate n-gram models using large
vocabularies, thereby making the training of large
neural network models feasible both for target lan-
guage models and translation models (Le et al.,
2012a).
3.1 SOUL translation models
While the integration of SOUL target language
models is straightforward, SOUL translation mod-
els rely on a specific decomposition of the joint
probability P (s, t) of a sentence pair, where s is a
sequence of I reordered source words (s
1
, ..., s
I
)
1
1
In the context of the n-gram translation model, (s, t) thus
denotes an aligned sentence pair, where the source words are
reordered.
and t contains J target words (t
1
, ..., t
J
). In the
n-gram approach (Mari?no et al., 2006; Crego et
al., 2011), this segmentation is a by-product of
source reordering, and ultimately derives from ini-
tial word and phrase alignments. In this frame-
work, the basic translation units are tuples, which
are analogous to phrase pairs, and represent a
matching u = (s, t) between a source phrase s
and a target phrase t.
Using the n-gram assumption, the joint proba-
bility of a segmented sentence pair using L tupels
decomposes as:
P (s, t) =
L
?
i=1
P (u
i
|u
i?1
, ..., u
i?n+1
) (1)
A first issue with this decomposition is that the
elementary units are bilingual pairs. Therefore,
the underlying vocabulary and hence the number
of parameters can be quite large, even for small
translation tasks. Due to data sparsity issues, such
models are bound to face severe estimation prob-
lems. Another problem with Equation (1) is that
the source and target sides play symmetric roles,
whereas the source side is known, and the tar-
get side must be predicted. To overcome some
of these issues, the n-gram probability in Equa-
tion (1) can be factored by first decomposing tu-
ples in two (source and target) parts, and then de-
composing the source and target parts at the word
level.
Let s
k
i
denote the k
th
word of source part of the
tuple s
i
. Let us consider the example of Figure 1,
s
1
11
corresponds to the source word nobel, s
4
11
to
the source word paix, and similarly t
2
11
is the tar-
get word peace. We finally define h
n?1
(t
k
i
) as the
sequence of the n?1 words preceding t
k
i
in the tar-
get sentence, and h
n?1
(s
k
i
) as the n?1 words pre-
ceding s
k
i
in the reordered source sentence: in Fig-
ure 1, h
3
(t
2
11
) thus refers to the three word context
receive the nobel associated with the target word
peace. Using these notations, Equation 1 can be
rewritten as:
P (s, t) =
L
?
i=1
[
|t
i
|
?
k=1
P
(
t
k
i
|h
n?1
(t
k
i
), h
n?1
(s
1
i+1
)
)
?
|s
i
|
?
k=1
P
(
s
k
i
|h
n?1
(t
1
i
), h
n?1
(s
k
i
)
)
]
(2)
This decomposition relies on the n-gram assump-
tion, this time at the word level. Therefore, this
85
 s?
8
: ? 
 t
?
8
: to 
 s?
9
: recevoir 
 t
?
9
: receive 
 s?
10
: le 
 t
?
10
: the 
 s?
11
: nobel de la paix 
 t
?
11
: nobel peace 
 s?
12
: prix 
 t
?
12
: prize 
 u
8
  u
9
  u
10
  u
11
  u
12
 
s :   .... 
t :   .... 
? recevoir le prix nobel de la paixorg :   ....
....
....
Figure 1: Extract of a French-English sentence pair segmented into bilingual units. The original (org)
French sentence appears at the top of the figure, just above the reordered source s and the target t. The
pair (s, t) decomposes into a sequence of L bilingual units (tuples) u
1
, ..., u
L
. Each tuple u
i
contains a
source and a target phrase: s
i
and t
i
.
model estimates the joint probability of a sentence
pair using two sliding windows of length n, one
for each language; however, the moves of these
windows remain synchronized by the tuple seg-
mentation. Moreover, the context is not limited
to the current phrase, and continues to include
words in adjacent phrases. Equation (2) involves
two terms that will be further denoted as TrgSrc
and Src, respectively P
(
t
k
i
|h
n?1
(t
k
i
), h
n?1
(s
1
i+1
)
)
and P
(
s
k
i
|h
n?1
(t
1
i
), h
n?1
(s
k
i
)
)
. It is worth notic-
ing that the joint probability of a sentence pair
can also be decomposed by considering the fol-
lowing two terms: P
(
s
k
i
|h
n?1
(s
k
i
), h
n?1
(t
1
i+1
)
)
and P
(
t
k
i
|h
n?1
(s
1
i
), h
n?1
(t
k
i
)
)
. These two terms
will be further denoted by SrcTrg and Trg. There-
fore, adding SOUL translation models means that
4 scores are added to the phrase-based systems.
3.2 Integration
During the training step, the SOUL translation
models are trained as described in (Le et al.,
2012a). The main changes concern the inference
step. Given the computational cost of computing
n-gram probabilities with neural network models,
a solution is to resort to a two-pass approach: the
first pass uses a conventional system to produce
a k-best list (the k most likely hypotheses); in
the second pass, probabilities are computed by the
SOUL models for each hypothesis and added as
new features. Then the k-best list is reordered ac-
cording to a combination of all features including
these new features. In the following experiments,
we use 10-gram SOUL models to rescore 300-
best lists. Since the phrase-based system described
in Section 2 uses source reordering, the decoder
was modified in order to generate k-best lists that
contain necessary word alignment information be-
tween the reordered source sentence and its asso-
ciated target hypothesis. The goal is to recover
the information that is illustrated in Figure 1 and
to apply the n-gram decomposition of a sentence
pair.
These (target and bilingual) neural network
models produce scores for each hypothesis in the
k-best list; these new features, along with the fea-
tures from the baseline system, are then provided
to a new phase which runs the traditional Mini-
mum Error Rate Training (MERT ) (Och, 2003), or
a recently proposed k-best Batch Margin Infused
Relaxed Algorithm (KBMIRA ) (Cherry and Fos-
ter, 2012) for tuning purpose. The SOUL mod-
els used for this year?s evaluation are similar to
those described in Allauzen et al. (2013) and Le
et al. (2012b). However, since compared to these
evaluations less parallel data is available for the
German-to-English task, we use smaller vocabu-
laries of about 100K words.
4 Results
We evaluated the SOUL models on the German-
to-English translation task using two systems to
generate the k-best lists. The first system used
all models of the baseline system except the DWL
model and the other one used all models.
Table 1 summarizes experimental results in
terms of BLEU scores when the tuning is per-
formed using KBMIRA. As described in Section
3, the probability of a phrase pair can be decom-
posed into products of words? probabilities in 2
different ways: we can first estimate the probabil-
ity of words in the source phrase given the context,
and then the probability of the target phrase given
its associated source phrase and context words
(see Equation (2)); or inversely we can generate
the target side before the source side. The for-
mer proceeds by adding Src and TrgSrc scores as
86
No DWL DWL
Soul models Dev Test Dev Test
No 26.02 27.02 26.27 27.46
Target 26.30 27.42 26.43 27.85
Translation st 26.46 27.70 26.66 28.04
Translation ts 26.48 27.41 26.61 28.00
All Translation 26.50 27.86 26.70 28.08
All SOUL models 26.62 27.84 26.75 28.10
Table 1: Results using KBMIRA
No DWL DWL
Soul models Dev Test Dev Test
No 26.02 27.02 26.27 27.46
Target 26.18 27.09 26.44 27.54
Translation st 26.36 27.59 26.66 27.80
Translation ts 26.44 27.69 26.63 27.94
All Translation 26.53 27.65 26.69 27.99
All SOUL models 26.47 27.68 26.66 28.01
Table 2: Results using MERT. Results in bold correpond to the submitted system.
2 new features into the k-best list, and the latter by
adding Trg and SrcTrg scores. These 2 methods
correspond respectively to the Translation ts and
Translation st lines in the Table 1. The 4 trans-
lation models may also be added simultaneously
(All Translations). The first line gives baseline
results without SOUL models, while the Target
line shows results in adding only SOUL language
model. The last line (All SOUL models) shows
the results for adding all neural network models
into the baseline systems.
As evident in Table 1, using the SOUL trans-
lation models yields generally better results than
using the SOUL target language model, yielding
about 0.2 BLEU point differences on dev and test
sets. We can therefore assume that the SOUL
translation models provide richer information that,
to some extent, covers that contained in the neural
network language model. Indeed, these 4 trans-
lation models take into account not only lexi-
cal probabilities of translating target words given
source words (or in the inverse order), but also the
probabilities of generating words in the target side
(Trg model) as does a language model, with the
same context length over both source and target
sides. It is therefore not surprising that adding the
SOUL language model along with all translation
models (the last line in the table) does not give sig-
nificant improvement compared to the other con-
figurations. The different ways of using the SOUL
translation models perform very similarly.
Table 2 summarizes the results using MERT in-
stead of KBMIRA. We can observe that using KB-
MIRA results in 0.1 to 0.2 BLEU point improve-
ments compared to MERT. Moreover, this impact
becomes more important when more features are
considered (the last line when all 5 neural net-
work models are added into the baseline systems).
In short, the use of neural network models yields
up to 0.6 BLEU improvement on the DWL sys-
tem, and a 0.8 BLEU gain on the system without
DWL. Unfortunately, the experiments with KB-
MIRA were carried out after the the submission
date. Therefore the submitted system corresponds
to the last line of table 2 indicated in bold.
5 Conclusion
We presented a system with two main features: a
phrase-based translation system which uses pre-
reordering and the integration of SOUL target lan-
guage and translation models. Although the trans-
lation performance of the baseline system is al-
ready very competitive, the rescoring by SOUL
models improve the performance significantly. In
the rescoring step, we used a continuous language
model as well as four continuous translation mod-
87
els. When combining the different SOUL models,
the translation models are observed to be more im-
portant in increasing the translation performance
than the language model. Moreover, we observe a
slight benefit to use KBMIRA instead of the stan-
dard MERT tuning algorithm. It is worth noticing
that using KBMIRA improves the performance
but also reduces the variance of the final results.
As future work, the integration of the SOUL
translation models could be improved in differ-
ent ways. For SOUL translation models, there
is a mismatch between translation units used dur-
ing the training step and those used by the de-
coder. The former are derived using the n-gram-
based approach, while the latter use the conven-
tional phrase extraction heuristic. We assume that
reducing this mismatch could improve the overall
performance. This can be achieved for instance
using forced decoding to infer a segmentation of
the training data into translation units. Then the
SOUL translation models can be trained using
this segmentation. For the SOUL target language
model, in these experiments we only used the En-
glish part of the parallel data for training. Results
may be improved by including all the monolingual
data.
Acknowledgments
The research leading to these results has received
funding from the European Union Seventh Frame-
work Programme (FP7/2007-2013) under grant
agreement n
?
287658 as well as the French Ar-
maments Procurement Agency (DGA) under the
RAPID Rapmat project.
References
Alexandre Allauzen, Nicolas P?echeux, Quoc Khanh
Do, Marco Dinarelli, Thomas Lavergne, Aur?elien
Max, Hai-Son Le, and Franc?ois Yvon. 2013.
Limsi@ wmt13. In Proceedings of the Eighth Work-
shop on Statistical Machine Translation, pages 60?
67.
Yoshua Bengio, R?ejean Ducharme, Pascal Vincent, and
Christian Janvin. 2003. A neural probabilistic lan-
guage model. Journal of Machine Learning Re-
search, 3:1137?1155.
S.F. Chen and J. Goodman. 1996. An empirical study
of smoothing techniques for language modeling. In
Proceedings of the 34th Annual Meeting on Associa-
tion for Computational Linguistics (ACL ?96), pages
310?318, Santa Cruz, California, USA.
Colin Cherry and George Foster. 2012. Batch tun-
ing strategies for statistical machine translation. In
Proceedings of the 2012 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 427?436. Association for Computational Lin-
guistics.
Josep M. Crego, Franois Yvon, and Jos B. Mari?no.
2011. N-code: an open-source Bilingual N-gram
SMT Toolkit. Prague Bulletin of Mathematical Lin-
guistics, 96:49?58.
George F. Foster, Roland Kuhn, and Howard Johnson.
2006. Phrasetable smoothing for statistical machine
translation. In EMNLP, pages 53?61.
Teresa Herrmann, Jan Niehues, and Alex Waibel.
2013. Combining Word Reordering Methods on
different Linguistic Abstraction Levels for Statisti-
cal Machine Translation. In Proceedings of the Sev-
enth Workshop on Syntax, Semantics and Structure
in Statistical Translation, Altanta, Georgia, USA,
June. Association for Computational Linguistics.
Dan Klein and Christopher D. Manning. 2003. Accu-
rate Unlexicalized Parsing. In Proceedings of ACL
2003.
Philipp Koehn and Kevin Knight. 2003. Empirical
Methods for Compound Splitting. In EACL, Bu-
dapest, Hungary.
Philipp Koehn, Amittai Axelrod, Alexandra B. Mayne,
Chris Callison-Burch, Miles Osborne, and David
Talbot. 2005. Edinburgh System Description for
the 2005 IWSLT Speech Translation Evaluation. In
Proceedings of the International Workshop on Spo-
ken Language Translation (IWSLT), Pittsburgh, PA,
USA.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
Source Toolkit for Statistical Machine Translation.
In Proceedings of ACL 2007, Demonstration Ses-
sion, Prague, Czech Republic.
Hai-Son Le, Ilya Oparin, Alexandre Allauzen, Jean-
Luc Gauvain, and Franc?ois Yvon. 2011. Structured
output layer neural network language model. In Pro-
ceedings of ICASSP, pages 5524?5527.
Hai-Son Le, Alexandre Allauzen, and Franc?ois Yvon.
2012a. Continuous space translation models with
neural networks. pages 39?48, Montr?eal, Canada,
June. Association for Computational Linguistics.
Hai-Son Le, Thomas Lavergne, Alexandre Al-
lauzen, Marianna Apidianaki, Li Gong, Aur?elien
Max, Artem Sokolov, Guillaume Wisniewski, and
Franc?ois Yvon. 2012b. Limsi@ wmt?12. In Pro-
ceedings of the Seventh Workshop on Statistical Ma-
chine Translation, pages 330?337. Association for
Computational Linguistics.
88
Jos?e B. Mari?no, Rafael E. Banchs, Josep M. Crego,
Adri`a de Gispert, Patrick Lambert, Jos?e A.R. Fonol-
losa, and Marta R. Costa-Juss`a. 2006. N-gram-
based machine translation. Computational Linguis-
tics, 32(4):527?549.
Mohammed Mediani, Eunah Cho, Jan Niehues, Teresa
Herrmann, and Alex Waibel. 2011. The KIT
English-French Translation systems for IWSLT
2011. In Proceedings of the Eight Interna-
tional Workshop on Spoken Language Translation
(IWSLT).
R.C. Moore and W. Lewis. 2010. Intelligent selection
of language model training data. In Proceedings of
the ACL 2010 Conference Short Papers, pages 220?
224, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
Jan Niehues and Muntsin Kolss. 2009. A POS-Based
Model for Long-Range Reorderings in SMT. In
Fourth Workshop on Statistical Machine Translation
(WMT 2009), Athens, Greece.
Jan Niehues, Teresa Herrmann, Stephan Vogel, and
Alex Waibel. 2011. Wider Context by Using Bilin-
gual Language Models in Machine Translation. In
Sixth Workshop on Statistical Machine Translation
(WMT 2011), Edinburgh, UK.
Franz Josef Och and Hermann Ney. 2003. A System-
atic Comparison of Various Statistical Alignment
Models. Computational Linguistics, 29(1):19?51.
Franz Josef Och. 1999. An Efficient Method for De-
termining Bilingual Word Classes. In EACL?99.
Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In Proceedings of
the 41st Annual Meeting on Association for Compu-
tational Linguistics-Volume 1, pages 160?167. As-
sociation for Computational Linguistics.
Anna N. Rafferty and Christopher D. Manning. 2008.
Parsing Three German Treebanks: Lexicalized and
Unlexicalized Baselines. In Proceedings of the
Workshop on Parsing German.
Kay Rottmann and Stephan Vogel. 2007. Word Re-
ordering in Statistical Machine Translation with a
POS-Based Distortion Model. In Proceedings of
the 11th International Conference on Theoretical
and Methodological Issues in Machine Translation
(TMI), Sk?ovde, Sweden.
Helmut Schmid. 1994. Probabilistic Part-of-Speech
Tagging Using Decision Trees. In International
Conference on New Methods in Language Process-
ing, Manchester, United Kingdom.
Holger Schwenk. 2007. Continuous space lan-
guage models. Computer Speech and Language,
21(3):492?518, July.
Andreas Stolcke. 2002. SRILM ? An Extensible Lan-
guage Modeling Toolkit. In International Confer-
ence on Spoken Language Processing, Denver, Col-
orado, USA.
Ashish Venugopal, Andreas Zollman, and Alex Waibel.
2005. Training and Evaluating Error Minimization
Rules for Statistical Machine Translation. In Work-
shop on Data-drive Machine Translation and Be-
yond (WPT-05), Ann Arbor, Michigan, USA.
Stephan Vogel. 2003. SMT Decoder Dissected: Word
Reordering. In International Conference on Natural
Language Processing and Knowledge Engineering,
Beijing, China.
89
Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 130?135,
Baltimore, Maryland USA, June 26?27, 2014.
c?2014 Association for Computational Linguistics
The Karlsruhe Institute of Technology Translation Systems
for the WMT 2014
Teresa Herrmann, Mohammed Mediani, Eunah Cho, Thanh-Le Ha,
Jan Niehues, Isabel Slawik, Yuqi Zhang and Alex Waibel
Institute for Anthropomatics and Robotics
KIT - Karlsruhe Institute of Technology
firstname.lastname@kit.edu
Abstract
In this paper, we present the KIT
systems participating in the Shared
Translation Task translating between
English?German and English?French.
All translations are generated using
phrase-based translation systems, using
different kinds of word-based, part-of-
speech-based and cluster-based language
models trained on the provided data.
Additional models include bilingual lan-
guage models, reordering models based
on part-of-speech tags and syntactic parse
trees, as well as a lexicalized reordering
model. In order to make use of noisy
web-crawled data, we apply filtering
and data selection methods for language
modeling. A discriminative word lexicon
using source context information proved
beneficial for all translation directions.
1 Introduction
We describe the KIT systems for the Shared Trans-
lation Task of the ACL 2014 Ninth Workshop on
Statistical Machine Translation. We participated
in the English?German and English?French
translation directions, using a phrase-based de-
coder with lattice input.
The paper is organized as follows: the next sec-
tion describes the data used for each translation
direction. Section 3 gives a detailed description of
our systems including all the models. The trans-
lation results for all directions are presented after-
wards and we close with a conclusion.
2 Data
We utilize the provided EPPS, NC and Common
Crawl parallel corpora for English?German and
German?English, plus Giga for English?French
and French?English. The monolingual part
of those parallel corpora, the News Shuffle
corpus for all four directions and additionally
the Gigaword corpus for English?French and
German?English are used as monolingual train-
ing data for the different language models. For
optimizing the system parameters, newstest2012
and newstest2013 are used as development and
test data respectively.
3 System Description
Before training we perform a common preprocess-
ing of the raw data, which includes removing long
sentences and sentences with a length mismatch
exceeding a certain threshold. Afterwards, we nor-
malize special symbols, dates, and numbers. Then
we perform smart-casing of the first letter of every
sentence. Compound splitting (Koehn and Knight,
2003) is performed on the source side of the cor-
pus for German?English translation. In order to
improve the quality of the web-crawled Common
Crawl corpus, we filter out noisy sentence pairs us-
ing an SVM classifier for all four translation tasks
as described in Mediani et al. (2011).
Unless stated otherwise, we use 4-gram lan-
guage models (LM) with modified Kneser-Ney
smoothing, trained with the SRILM toolkit (Stol-
cke, 2002). All translations are generated by
an in-house phrase-based translation system (Vo-
gel, 2003), and we use Minimum Error Rate
Training (MERT) as described in Venugopal et
al. (2005) for optimization. The word align-
ment of the parallel corpora is generated using
the GIZA++ Toolkit (Och and Ney, 2003) for
both directions. Afterwards, the alignments are
combined using the grow-diag-final-and heuris-
tic. For English?German, we use discrimi-
native word alignment trained on hand-aligned
data as described in Niehues and Vogel (2008).
The phrase table (PT) is built using the Moses
toolkit (Koehn et al., 2007). The phrase scoring
for the small data sets (German?English) is also
130
done by the Moses toolkit, whereas the bigger sets
(French?English) are scored by our in-house par-
allel phrase scorer (Mediani et al., 2012a). The
phrase pair probabilities are computed using mod-
ified Kneser-Ney smoothing as described in Foster
et al. (2006).
Since German is a highly inflected language,
we try to alleviate the out-of-vocabulary prob-
lem through quasi-morphological operations that
change the lexical entry of a known word form to
an unknown word form as described in Niehues
and Waibel (2011).
3.1 Word Reordering Models
We apply automatically learned reordering rules
based on part-of-speech (POS) sequences and syn-
tactic parse tree constituents to perform source
sentence reordering according to the target lan-
guage word order. The rules are learned
from a parallel corpus with POS tags (Schmid,
1994) for the source side and a word align-
ment to learn reordering rules that cover short
range (Rottmann and Vogel, 2007) and long
range reorderings (Niehues and Kolss, 2009).
In addition, we apply a tree-based reordering
model (Herrmann et al., 2013) to better address
the differences in word order between German and
English. Here, a word alignment and syntactic
parse trees (Rafferty and Manning, 2008; Klein
and Manning, 2003) for the source side of the
training corpus are required to learn rules on how
to reorder the constituents in the source sentence.
The POS-based and tree-based reordering rules
are applied to each input sentence before transla-
tion. The resulting reordered sentence variants as
well as the original sentence are encoded in a re-
ordering lattice. The lattice, which also includes
the original position of each word, is used as input
to the decoder.
In order to acquire phrase pairs matching the
reordered sentence variants, we perform lattice
phrase extraction (LPE) on the training corpus
where phrase are extracted from the reordered
word lattices instead of the original sentences.
In addition, we use a lexicalized reordering
model (Koehn et al., 2005) which stores reorder-
ing probabilities for each phrase pair. During
decoding the lexicalized reordering model deter-
mines the reordering orientation of each phrase
pair at the phrase boundaries. The probability for
the respective orientation with respect to the orig-
inal position of the words is included as an addi-
tional score in the log-linear model of the transla-
tion system.
3.2 Adaptation
In the French?English and English?French sys-
tems, we perform adaptation for translation mod-
els as well as for language models. The EPPS and
NC corpora are used as in-domain data for the di-
rection English?French, while NC corpus is the
in-domain data for French?English.
Two phrase tables are built: one is the out-
of-domain phrase table, which is trained on all
corpora; the other is the in-domain phrase table,
which is trained on in-domain data. We adapt the
translation model by using the scores from the two
phrase tables with the backoff approach described
in Niehues and Waibel (2012). This results in a
phrase table with six scores, the four scores from
the general phrase table as well as the two condi-
tional probabilities from the in-domain phrase ta-
ble. In addition, we take the union of the candidate
phrase pairs collected from both phrase tables A
detailed description of the union method can be
found in Mediani et al. (2012b).
The language model is adapted by log-linearly
combining the general language model and an in-
domain language model. We train a separate lan-
guage model using only the in-domain data. Then
it is used as an additional language model during
decoding. Optimal weights are set during tuning
by MERT.
3.3 Special Language Models
In addition to word-based language models, we
use different types of non-word language models
for each of the systems. With the help of a bilin-
gual language model (Niehues et al., 2011) we
are able to increase the bilingual context between
source and target words beyond phrase bound-
aries. This language model is trained on bilin-
gual tokens created from a target word and all its
aligned source words. The tokens are ordered ac-
cording to the target language word order.
Furthermore, we use language models based
on fine-grained part-of-speech tags (Schmid and
Laws, 2008) as well as word classes to allevi-
ate the sparsity problem for surface words. The
word classes are automatically learned by clus-
tering the words of the corpus using the MKCLS
algorithm (Och, 1999). These n-gram language
models are trained on the target language corpus,
131
where the words have been replaced either by their
corresponding POS tag or cluster ID. During de-
coding, these language models are used as addi-
tional models in the log-linear combination.
The data selection language model is trained
on data automatically selected using cross-entropy
differences between development sets from pre-
vious WMT workshops and the noisy crawled
data (Moore and Lewis, 2010). We selected the
top 10M sentences to train this language model.
3.4 Discriminative Word Lexicon
A discriminative word lexicon (DWL) models the
probability of a target word appearing in the trans-
lation given the words of the source sentence.
DWLs were first introduced by Mauser et al.
(2009). For every target word, they train a maxi-
mum entropy model to determine whether this tar-
get word should be in the translated sentence or
not using one feature per source word.
We use two simplifications of this model that
have shown beneficial to translation quality and
training time in the past (Mediani et al., 2011).
Firstly, we calculate the score for every phrase pair
before translating. Secondly, we restrict the nega-
tive training examples to words that occur within
matching phrase pairs.
In this evaluation, we extended the DWL
with n-gram source context features proposed
by Niehues and Waibel (2013). Instead of rep-
resenting the source sentence as a bag-of-words,
we model it as a bag-of-n-grams. This allows us
to include information about source word order in
the model. We used one feature per n-gram up to
the order of three and applied count filtering for
bigrams and trigrams.
4 Results
This section presents the participating systems
used for the submissions in the four translation
directions of the evaluation. We describe the in-
dividual components that form part of each of
the systems and report the translation qualities
achieved during system development. The scores
are reported in case-sensitive BLEU (Papineni et
al., 2002).
4.1 English-French
The development of our English?French system
is shown in Table 1.
It is noteworthy that, for this direction, we chose
to tune on a subset of 1,000 pairs from news-
test2012, due to the long time the whole set takes
to be decoded. In a preliminary set of experiments
(not reported here), we found no significant differ-
ences between tuning on the small or the big devel-
opment sets. The translation model of the baseline
system is trained on the whole parallel data after
filtering (EPPS, NC, Common Crawl, Giga). The
same data was also used for language modeling.
We also use POS-based reordering.
The biggest improvement was due to using two
additional language models. One consists of a log-
linear interpolation of individual language models
trained on the target side of the parallel data, the
News shuffle, Gigaword and NC corpora. In ad-
dition, an in-domain language model trained only
on NC data is used. This improves the score by
more than 1.4 points. Adaptation of the translation
model towards a smaller model trained on EPPS
and NC brings an additional 0.3 points.
Another 0.3 BLEU points could be gained by
using other special language models: a bilingual
language model together with a 4-gram cluster
language model (trained on all monolingual data
using the MKCLS tool and 500 clusters). Incor-
porating a lexicalized reordering model into the
system had a very noticeable effect on test namely
more than half a BLEU point.
Finally, using a discriminative word lexicon
with source context has a very small positive ef-
fect on the test score, however more than 0.3 on
dev. This final configuration was the basis of our
submitted official translation.
System Dev Test
Baseline 15.63 27.61
+ Big LMs 16.56 29.02
+ PT Adaptation 16.77 29.32
+ Bilingual + Cluster LM 16.87 29.64
+ Lexicalized Reordering 16.92 30.17
+ Source DWL 17.28 30.19
Table 1: Experiments for English?French
4.2 French-English
Several experiments were conducted for the
French?English translation system. They are
summarized in Table 2.
The baseline system is essentially a phrase-
based translation system with some preprocess-
132
ing steps on the source side and utilizing the
short-range POS-based reordering on all parallel
data and fine-grained monolingual corpora such as
EPPS and NC.
Adapting the translation model using a small in-
domain phrase table trained on NC data only helps
us gain more than 0.4 BLEU points.
Using non-word language models including a
bilingual language model and a 4-gram 50-cluster
language model trained on the whole parallel data
attains 0.24 BLEU points on the test set.
Lexicalized reordering improves our system on
the development set by 0.3 BLEU points but has
less effect on the test set with a minor improve-
ment of around 0.1 BLEU points.
We achieve our best system, which is used for
the evaluation, by adding a DWL with source con-
text yielding 31.54 BLEU points on the test set.
System Dev Test
Baseline 30.16 30.70
+ LM Adaptation 30.58 30.94
+ PT Adaptation 30.69 31.14
+ Bilingual + Cluster LM 30.85 31.38
+ Lexicalized Reordering 31.14 31.46
+ Source DWL 31.19 31.54
Table 2: Experiments for French?English
4.3 English-German
Table 3 presents how the English-German transla-
tion system is improved step by step.
In the baseline system, we used parallel data
which consists of the EPPS and NC corpora. The
phrase table is built using discriminative word
alignment. For word reordering, we use word lat-
tices with long range reordering rules. Five lan-
guage models are used in the baseline system; two
word-based language models, a bilingual language
model, and two 9-gram POS-based language mod-
els. The two word-based language models use 4-
gram context and are trained on the parallel data
and the filtered Common Crawl data separately,
while the bilingual language model is built only
on the Common Crawl corpus. The two POS-
based language models are also based on the paral-
lel data and the filtered crawled data, respectively.
When using a 9-gram cluster language model,
we get a slight improvement. The cluster is trained
with 1,000 classes using EPPS, NC, and Common
Crawl data.
We use the filtered crawled data in addition to
the parallel data in order to build the phrase table;
this gave us 1 BLEU point of improvement.
The system is improved by 0.1 BLEU points
when we use lattice phrase extraction along with
lexicalized reordering rules.
Tree-based reordering rules improved the sys-
tem performance further by another 0.1 BLEU
points.
By reducing the context of the two POS-based
language models from 9-grams to 5-grams and
shortening the context of the language model
trained on word classes to 4-grams, the score on
the development set hardly changes but we can see
a slightly improvement for the test case.
Finally, we use the DWL with source context
and build a big bilingual language model using
both the crawled and parallel data. By doing so,
we improved the translation performance by an-
other 0.3 BLEU points. This system was used for
the translation of the official test set.
System Dev Test
Baseline 16.64 18.60
+ Cluster LM 16.76 18.66
+ Common Crawl Data 17.27 19.66
+ LPE + Lexicalized Reordering 17.45 19.75
+ Tree Rules 17.53 19.85
+ Shorter n-grams 17.55 19.92
+ Source DWL + Big BiLM 17.82 20.21
Table 3: Experiments for English?German
4.4 German-English
Table 4 shows the development steps of the
German-English translation system.
For the baseline system, the training data of the
translation model consists of EPPS, NC and the
filtered parallel crawled data. The phrase table
is built using GIZA++ word alignment and lattice
phrase extraction. All language models are trained
with SRILM and scored in the decoding process
with KenLM (Heafield, 2011). We use word lat-
tices generated by short and long range reordering
rules as input to the decoder. In addition, a bilin-
gual language model and a target language model
trained on word clusters with 1,000 classes are in-
cluded in the system.
Enhancing the word reordering with tree-based
reordering rules and a lexicalized reordering
133
model improved the system performance by 0.6
BLEU points.
Adding a language model trained on selected
data from the monolingual corpora gave another
small improvement.
The DWL with source context increased the
score on the test set by another 0.5 BLEU points
and applying morphological operations to un-
known words reduced the out-of-vocabulary rate,
even though no improvement in BLEU can be ob-
served. This system was used to generate the
translation submitted to the evaluation.
System Dev Test
Baseline 24.40 26.34
+ Tree Rules 24.71 26.86
+ Lexicalized Reordering 24.89 26.93
+ LM Data Selection 24.96 27.03
+ Source DWL 25.32 27.53
+ Morphological Operations - 27.53
Table 4: Experiments for German?English
5 Conclusion
In this paper, we have described the systems
developed for our participation in the Shared
Translation Task of the WMT 2014 evaluation
for English?German and English?French. All
translations were generated using a phrase-based
translation system which was extended by addi-
tional models such as bilingual and fine-grained
part-of-speech language models. Discriminative
word lexica with source context proved beneficial
in all four language directions.
For English-French translation using a smaller
development set performed reasonably well and
reduced development time. The most noticeable
gain comes from log-linear interpolation of multi-
ple language models.
Due to the large amounts and diversity of
the data available for French-English, adapta-
tion methods and non-word language models con-
tribute the major improvements to the system.
For English-German translation, the crawled
data and a DWL using source context to guide
word choice brought most of the improvements.
Enhanced word reordering models, namely
tree-based reordering rules and a lexicalized re-
ordering model as well as the source-side fea-
tures for the discriminative word lexicon helped
improve the system performance for German-
English translation.
In average we achieved an improvement of over
1.5 BLEU over the respective baselines for all our
systems.
Acknowledgments
The research leading to these results has received
funding from the European Union Seventh Frame-
work Programme (FP7/2007-2013) under grant
agreement n
?
287658.
References
George F. Foster, Roland Kuhn, and Howard Johnson.
2006. Phrasetable Smoothing for Statistical Ma-
chine Translation. In Proceedings of the 2006 Con-
ference on Empirical Methods on Natural Language
Processing (EMNLP), Sydney, Australia.
Kenneth Heafield. 2011. KenLM: Faster and Smaller
Language Model Queries. In Proceedings of the
Sixth Workshop on Statistical Machine Translation,
Edinburgh, Scotland, United Kingdom.
Teresa Herrmann, Jan Niehues, and Alex Waibel.
2013. Combining Word Reordering Methods on
different Linguistic Abstraction Levels for Statisti-
cal Machine Translation. In Proceedings of the Sev-
enth Workshop on Syntax, Semantics and Structure
in Statistical Translation, Altanta, Georgia, USA.
Dan Klein and Christopher D. Manning. 2003. Ac-
curate Unlexicalized Parsing. In Proceedings of the
41st Annual Meeting on Association for Computa-
tional Linguistics (ACL 2003), Sapporo, Japan.
Philipp Koehn and Kevin Knight. 2003. Empirical
Methods for Compound Splitting. In Proceedings
of the Eleventh Conference of the European Chap-
ter of the Association for Computational Linguistics
(EACL 2003), Budapest, Hungary.
Philipp Koehn, Amittai Axelrod, Alexandra B. Mayne,
Chris Callison-Burch, Miles Osborne, and David
Talbot. 2005. Edinburgh System Description for
the 2005 IWSLT Speech Translation Evaluation. In
Proceedings of the Second International Workshop
on Spoken Language Translation (IWSLT 2005),
Pittsburgh, PA, USA.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexan-
dra Constantin, and Evan Herbst. 2007. Moses:
Open Source Toolkit for Statistical Machine Trans-
lation. In Proceedings of the 45th Annual Meeting of
the Association for Computational Linguistics (ACL
2007), Demonstration Session, Prague, Czech Re-
public.
134
Arne Mauser, Sa?sa Hasan, and Hermann Ney. 2009.
Extending Statistical Machine Translation with Dis-
criminative and Trigger-based Lexicon Models.
In Proceedings of the 2009 Conference on Em-
pirical Methods in Natural Language Processing
(EMNLP), Suntec, Singapore.
Mohammed Mediani, Eunah Cho, Jan Niehues, Teresa
Herrmann, and Alex Waibel. 2011. The KIT
English-French Translation systems for IWSLT
2011. In Proceedings of the Eight International
Workshop on Spoken Language Translation (IWSLT
2011), San Francisco, CA, USA.
Mohammed Mediani, Jan Niehues, and Alex Waibel.
2012a. Parallel Phrase Scoring for Extra-large Cor-
pora. In The Prague Bulletin of Mathematical Lin-
guistics, number 98.
Mohammed Mediani, Yuqi Zhang, Thanh-Le Ha, Jan
Niehues, Eunach Cho, Teresa Herrmann, Rainer
K?argel, and Alexander Waibel. 2012b. The KIT
Translation Systems for IWSLT 2012. In Proceed-
ings of the Ninth International Workshop on Spoken
Language Translation (IWSLT 2012), Hong Kong,
HK.
R.C. Moore and W. Lewis. 2010. Intelligent Selection
of Language Model Training Data. In Proceedings
of the ACL 2010 Conference Short Papers, Uppsala,
Sweden.
Jan Niehues and Muntsin Kolss. 2009. A POS-Based
Model for Long-Range Reorderings in SMT. In
Proceedings of the Fourth Workshop on Statistical
Machine Translation (WMT 2009), Athens, Greece.
Jan Niehues and Stephan Vogel. 2008. Discriminative
Word Alignment via Alignment Matrix Modeling.
In Proceedings of the Third Workshop on Statistical
Machine Translation (WMT 2008), Columbus, OH,
USA.
Jan Niehues and Alex Waibel. 2011. Using Wikipedia
to Translate Domain-specific Terms in SMT. In
Proceedings of the Eight International Workshop on
Spoken Language Translation (IWSLT 2008), San
Francisco, CA, USA.
J. Niehues and A. Waibel. 2012. Detailed Analysis of
Different Strategies for Phrase Table Adaptation in
SMT. In Proceedings of the Tenth Conference of the
Association for Machine Translation in the Ameri-
cas (AMTA 2012), San Diego, CA, USA.
J. Niehues and A. Waibel. 2013. An MT Error-Driven
Discriminative Word Lexicon using Sentence Struc-
ture Features. In Proceedings of the Eighth Work-
shop on Statistical Machine Translation, Sofia, Bul-
garia.
Jan Niehues, Teresa Herrmann, Stephan Vogel, and
Alex Waibel. 2011. Wider Context by Using Bilin-
gual Language Models in Machine Translation. In
Sixth Workshop on Statistical Machine Translation
(WMT 2011), Edinburgh, Scotland, United King-
dom.
Franz Josef Och and Hermann Ney. 2003. A System-
atic Comparison of Various Statistical Alignment
Models. Computational Linguistics, 29(1):19?51.
Franz Josef Och. 1999. An Efficient Method for Deter-
mining Bilingual Word Classes. In Proceedings of
the Ninth Conference of the European Chapter of the
Association for Computational Linguistics (EACL
1999), Bergen, Norway.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic
Evaluation of Machine Translation. Technical Re-
port RC22176 (W0109-022), IBM Research Divi-
sion, T. J. Watson Research Center.
Anna N. Rafferty and Christopher D. Manning. 2008.
Parsing Three German Treebanks: Lexicalized and
Unlexicalized Baselines. In Proceedings of the
Workshop on Parsing German, Columbus, OH,
USA.
Kay Rottmann and Stephan Vogel. 2007. Word Re-
ordering in Statistical Machine Translation with a
POS-Based Distortion Model. In Proceedings of the
11th International Conference on Theoretical and
Methodological Issues in Machine Translation (TMI
2007), Sk?ovde, Sweden.
Helmut Schmid and Florian Laws. 2008. Estimation
of Conditional Probabilities with Decision Trees and
an Application to Fine-Grained POS Tagging. In In-
ternational Conference on Computational Linguis-
tics (COLING 2008), Manchester, Great Britain.
Helmut Schmid. 1994. Probabilistic Part-of-Speech
Tagging Using Decision Trees. In International
Conference on New Methods in Language Process-
ing, Manchester, United Kingdom.
Andreas Stolcke. 2002. SRILM ? An Extensible Lan-
guage Modeling Toolkit. In International Confer-
ence on Spoken Language Processing, Denver, Col-
orado, USA.
Ashish Venugopal, Andreas Zollman, and Alex Waibel.
2005. Training and Evaluation Error Minimization
Rules for Statistical Machine Translation. In Pro-
ceedings of the ACL Workshop on Building and Us-
ing Parallel Texts, Ann Arbor, Michigan, USA.
Stephan Vogel. 2003. SMT Decoder Dissected: Word
Reordering. In International Conference on Natural
Language Processing and Knowledge Engineering,
Beijing, China.
135
Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 246?253,
Baltimore, Maryland USA, June 26?27, 2014.
c?2014 Association for Computational Linguistics
LIMSI @ WMT?14 Medical Translation Task
Nicolas P
?
echeux
1,2
, Li Gong
1,2
, Quoc Khanh Do
1,2
, Benjamin Marie
2,3
,
Yulia Ivanishcheva
2,4
, Alexandre Allauzen
1,2
, Thomas Lavergne
1,2
,
Jan Niehues
2
, Aur
?
elien Max
1,2
, Franc?ois Yvon
2
Univ. Paris-Sud
1
, LIMSI-CNRS
2
B.P. 133, 91403 Orsay, France
Lingua et Machina
3
, Centre Cochrane franc?ais
4
{firstname.lastname}@limsi.fr
Abstract
This paper describes LIMSI?s submission
to the first medical translation task at
WMT?14. We report results for English-
French on the subtask of sentence trans-
lation from summaries of medical ar-
ticles. Our main submission uses a
combination of NCODE (n-gram-based)
and MOSES (phrase-based) output and
continuous-space language models used in
a post-processing step for each system.
Other characteristics of our submission in-
clude: the use of sampling for building
MOSES? phrase table; the implementation
of the vector space model proposed by
Chen et al. (2013); adaptation of the POS-
tagger used by NCODE to the medical do-
main; and a report of error analysis based
on the typology of Vilar et al. (2006).
1 Introduction
This paper describes LIMSI?s submission to the
first medical translation task at WMT?14. This
task is characterized by high-quality input text
and the availability of large amounts of training
data from the same domain, yielding unusually
high translation performance. This prompted us
to experiment with two systems exploring differ-
ent translation spaces, the n-gram-based NCODE
(?2.1) and an on-the-fly variant of the phrase-
based MOSES (?2.2), and to later combine their
output. Further attempts at improving translation
quality were made by resorting to continuous lan-
guage model rescoring (?2.4), vector space sub-
corpus adaptation (?2.3), and POS-tagging adap-
tation to the medical domain (?3.3). We also per-
formed a small-scale error analysis of the outputs
of some of our systems (?5).
2 System Overview
2.1 NCODE
NCODE implements the bilingual n-gram ap-
proach to SMT (Casacuberta and Vidal, 2004;
Mari?no et al., 2006; Crego and Mari?no, 2006) that
is closely related to the standard phrase-based ap-
proach (Zens et al., 2002). In this framework, the
translation is divided into two steps. To translate
a source sentence f into a target sentence e, the
source sentence is first reordered according to a
set of rewriting rules so as to reproduce the tar-
get word order. This generates a word lattice con-
taining the most promising source permutations,
which is then translated. Since the translation step
is monotonic, the peculiarity of this approach is to
rely on the n-gram assumption to decompose the
joint probability of a sentence pair in a sequence
of bilingual units called tuples.
The best translation is selected by maximizing
a linear combination of feature functions using the
following inference rule:
e
?
= argmax
e,a
K
?
k=1
?
k
f
k
(f , e,a) (1)
where K feature functions (f
k
) are weighted by
a set of coefficients (?
k
) and a denotes the set of
hidden variables corresponding to the reordering
and segmentation of the source sentence. Along
with the n-gram translation models and target n-
gram language models, 13 conventional features
are combined: 4 lexicon models similar to the ones
used in standard phrase-based systems; 6 lexical-
ized reordering models (Tillmann, 2004; Crego et
al., 2011) aimed at predicting the orientation of
the next translation unit; a ?weak? distance-based
distortion model; and finally a word-bonus model
and a tuple-bonus model which compensate for the
system preference for short translations. Features
are estimated during the training phase. Training
source sentences are first reordered so as to match
246
the target word order by unfolding the word align-
ments (Crego and Mari?no, 2006). Tuples are then
extracted in such a way that a unique segmenta-
tion of the bilingual corpus is achieved (Mari?no et
al., 2006) and n-gram translation models are then
estimated over the training corpus composed of tu-
ple sequences made of surface forms or POS tags.
Reordering rules are automatically learned during
the unfolding procedure and are built using part-
of-speech (POS), rather than surface word forms,
to increase their generalization power (Crego and
Mari?no, 2006).
2.2 On-the-fly System (OTF)
We develop an alternative approach implement-
ing an on-the-fly estimation of the parameter of
a standard phrase-based model as in (Le et al.,
2012b), also adding an inverse translation model.
Given an input source file, it is possible to compute
only those statistics which are required to trans-
late the phrases it contains. As in previous works
on on-the-fly model estimation for SMT (Callison-
Burch et al., 2005; Lopez, 2008), we first build
a suffix array for the source corpus. Only a lim-
ited number of translation examples, selected by
deterministic random sampling, are then used by
traversing the suffix array appropriately. A coher-
ent translation probability (Lopez, 2008) (which
also takes into account examples where translation
extraction failed) is then estimated. As we cannot
compute exactly an inverse translation probability
(because sampling is performed independently for
each source phrase), we resort to the following ap-
proximation:
p(
?
f |e?) = min
(
1.0,
p(e?|
?
f)? freq(
?
f)
freq(e?)
)
(2)
where the freq(?) is the number of occurrences of
the given phrase in the whole corpus, and the nu-
merator p(e?|
?
f)?freq(
?
f) represents the predicted
joint count of
?
f and e?. The other models in this
system are the same as in the default configuration
of MOSES.
2.3 Vector Space Model (VSM)
We used the vector space model (VSM) of Chen
et al. (2013) to perform domain adaptation. In
this approach, each phrase pair (
?
f, e?) present in
the phrase table is represented by a C-dimensional
vector of TF-IDF scores, one for each sub-corpus,
where C represents the number of sub-corpora
(see Table 1). Each component w
c
(
?
f, e?) is a stan-
dard TF-IDF weight of each phrase pair for the
c
th
sub-corpus. TF(
?
f, e?) is the raw joint count of
(
?
f, e?) in the sub-corpus; the IDF(
?
f, e?) is the in-
verse document frequency across all sub-corpora.
A similar C-dimensional representation of the
development set is computed as follows: we first
perform word alignment and phrase pairs extrac-
tion. For each extracted phrase pair, we compute
its TF-IDF vector and finally combine all vectors
to obtain the vector for the develompent set:
w
dev
c
=
J
?
j=0
K
?
k=0
count
dev
(
?
f
j
, e?
k
)w
c
(
?
f
j
, e?
k
) (3)
where J and K are the total numbers of source
and target phrases extracted from the development
data, respectively, and count
dev
(
?
f
j
, e?
k
) is the joint
count of phrase pairs (
?
f
j
, e?
k
) found in the devel-
opment set. The similarity score between each
phrase pair?s vector and the development set vec-
tor is added into the phrase table as a VSM fea-
ture. We also replace the joint count with the
marginal count of the source/target phrase to com-
pute an alternative average representation for the
development set, thus adding two VSM additional
features.
2.4 SOUL
Neural networks, working on top of conventional
n-gram back-off language models, have been in-
troduced in (Bengio et al., 2003; Schwenk et al.,
2006) as a potential means to improve discrete
language models. As for our submitted transla-
tion systems to WMT?12 and WMT?13 (Le et al.,
2012b; Allauzen et al., 2013), we take advantage
of the recent proposal of (Le et al., 2011). Using
a specific neural network architecture, the Struc-
tured OUtput Layer (SOUL), it becomes possible
to estimate n-gram models that use large vocab-
ulary, thereby making the training of large neural
network language models feasible both for target
language models and translation models (Le et al.,
2012a). Moreover, the peculiar parameterization
of continuous models allows us to consider longer
dependencies than the one used by conventional
n-gram models (e.g. n = 10 instead of n = 4).
Additionally, continuous models can also be
easily and efficiently adapted as in (Lavergne et
al., 2011). Starting from a previously trained
SOUL model, only a few more training epochs are
247
Corpus Sentences Tokens (en-fr) Description wrd-lm pos-lm
in-domain
COPPA 454 246 10-12M -3 -15
EMEA 324 189 6-7M 26 -1
PATTR-ABSTRACTS 634 616 20-24M 22 21
PATTR-CLAIMS 888 725 32-36M 6 2
PATTR-TITLES 385 829 3-4M 4 -17
UMLS 2 166 612 8-8M term dictionary -7 -22
WIKIPEDIA 8 421 17-18k short titles -5 -13
out-of-domain
NEWSCOMMENTARY 171 277 4-5M 6 16
EUROPARL 1 982 937 54-60M -7 -33
GIGA 9 625 480 260-319M 27 52
all parallel all 17M 397-475M concatenation 33 69
target-lm
medical-data -146M 69 -
wmt13-data -2 536M 49 -
devel/test
DEVEL 500 10-12k khresmoi-summary
LMTEST 3 000 61-69k see Section 3.4
NEWSTEST12 3 003 73-82k from WMT?12
TEST 1 000 21-26k khresmoi-summary
Table 1: Parallel corpora used in this work, along with the number of sentences and the number of English
and French tokens, respectively. Weights (?
k
) from our best NCODE configuration are indicated for each
sub-corpora?s bilingual word language model (wrd-lm) and POS factor language model (pos-lm).
needed on a new corpus in order to adapt the pa-
rameters to the new domain.
3 Data and Systems Preparation
3.1 Corpora
We use all the available (constrained) medical data
extracted using the scripts provided by the orga-
nizers. This resulted in 7 sub-corpora from the
medical domain with distinctive features. As out-
of-domain data, we reuse the data processed for
WMT?13 (Allauzen et al., 2013).
For pre-processing of medical data, we closely
followed (Allauzen et al., 2013) so as to be able to
directly integrate existing translation and language
models, using in-house text processing tools for
tokenization and detokenization steps (D?echelotte
et al., 2008). All systems are built using a
?true case? scheme, but sentences fully capital-
ized (plentiful especially in PATTR-TITLES) are
previously lowercased. Duplicate sentence pairs
are removed, yielding a sentence reduction up to
70% for EMEA. Table 1 summarizes the data used
along with some statistics after the cleaning and
pre-processing steps.
3.2 Language Models
A medical-domain 4-gram language model is built
by concatenating the target side of the paral-
lel data and all the available monolingual data
1
,
with modified Kneser-Ney smoothing (Kneser and
Ney, 1995; Chen and Goodman, 1996), using the
SRILM (Stolcke, 2002) and KENLM (Heafield,
2011) toolkits. Although more similar to term-to-
term dictionaries, UMLS and WIKIPEDIA proved
better to be included in the language model.
The large out-of-domain language model used for
WMT?13 (Allauzen et al., 2013) is additionaly
used (see Table 1).
3.3 Part-of-Speech Tagging
Medical data exhibit many peculiarities, includ-
ing different syntactic constructions and a specific
vocabulary. As standard POS-taggers are known
not to perform very well for this type of texts, we
use a specific model trained on the Penn Treebank
and on medical data from the MedPost project
(Smith et al., 2004). We use Wapiti (Lavergne
et al., 2010), a state-of-the-art CRF implementa-
tion, with a standard feature set. Adaptation is per-
formed as in (Chelba and Acero, 2004) using the
out-of-domain model as a prior when training the
in-domain model on medical data. On a medical
test set, this adaptation leads to a 8 point reduc-
tion of the error rate. A standard model is used for
WMT?13 data. For the French side, due to the lack
of annotaded data for the medical domain, corpora
are tagged using the TreeTagger (Schmid, 1994).
1
Attempting include one language model per sub-corpora
yielded a significant drop in performance.
248
3.4 Proxy Test Set
For this first edition of a Medical Translation Task,
only a very small development set was made avail-
able (DEVEL in Table 1). This made both system
design and tuning challenging. In fact, with such a
small development set, conventional tuning meth-
ods are known to be very unstable and prone to
overfitting, and it would be suboptimal to select
a configuration based on results on the develop-
ment set only.
2
To circumvent this, we artificially
created our own internal test set by randomly se-
lecting 3 000 sentences out from the 30 000 sen-
tences from PATTR-ABSTRACTS having the low-
est perplexity according to 3-gram language mod-
els trained on both sides of the DEVEL set. This
test set, denoted by LMTEST, is however highly
biaised, especially because of the high redundancy
in PATTR-ABSTRACTS, and should be used with
great care when tuning or comparing systems.
3.5 Systems
NCODE We use NCODE with default settings, 3-
gram bilingual translation models on words and 4-
gram bilingual translation factor models on POS,
for each included corpora (see Table 1) and for the
concatenation of them all.
OTF When using our OTF system, all in-
domain and out-of-domain data are concatenated,
respectively. For both corpora, we use a maxi-
mum random sampling size of 1 000 examples and
a maximum phrase length of 15. However, all
sub-corpora but GIGA
3
are used to compute the
vectors for VSM features. Decoding is done with
MOSES
4
(Koehn et al., 2007).
SOUL Given the computational cost of com-
puting n-gram probabilities with neural network
models, we resort to a reranking approach. In
the following experiments, we use 10-gram SOUL
models to rescore 1 000-best lists. SOUL models
provide five new features: a target language model
score and four translation scores (Le et al., 2012a).
We reused the SOUL models trained for our par-
ticipation to WMT?12 (Le et al., 2012b). More-
over, target language models are adapted by run-
ning 6 more epochs on the new medical data.
2
This issue is traditionally solved in Machine Learning by
folded cross-validation, an approach that would be too pro-
hibitive to use here.
3
The GIGA corpus is actually very varied in content.
4
http://www.statmt.org/moses/
System Combination As NCODE and OTF dif-
fer in many aspects and make different errors, we
use system combination techniques to take advan-
tage of their complementarity. This is done by
reranking the concatenation of the 1 000-best lists
of both systems. For each hypothesis within this
list, we use two global features, corresponding
either to the score computed by the correspond-
ing system or 0 otherwise. We then learn rerank-
ing weights using Minimum Error Rate Training
(MERT) (Och, 2003) on the development set for
this combined list, using only these two features
(SysComb-2). In an alternative configuration, we
use the two systems without the SOUL rescoring,
and add instead the five SOUL scores as features in
the system combination reranking (SysComb-7).
Evaluation Metrics All BLEU scores (Pap-
ineni et al., 2002) are computed using cased
multi-bleu with our internal tokenization. Re-
ported results correspond to the average and stan-
dard deviation across 3 optimization runs to bet-
ter account for the optimizer variance (Clark et al.,
2011).
4 Experiments
4.1 Tuning Optimization Method
MERT is usually used to optimize Equation 1.
However, with up to 42 features when using
SOUL, this method is known to become very sen-
sitive to local minima. Table 2 compares MERT,
a batch variant of the Margin Infused Relaxation
Algorithm (MIRA) (Cherry and Foster, 2012) and
PRO (Hopkins and May, 2011) when tuning an
NCODE system. MIRA slightly outperforms PRO
on DEVEL, but seems prone to overfitting. How-
ever this was not possible to detect before the re-
lease of the test set (TEST), and so we use MIRA
in all our experiments.
DEVEL TEST
MERT 47.0? 0.4 44.1? 0.8
MIRA 47.9? 0.0 44.8? 0.1
PRO 47.1? 0.1 45.1? 0.1
Table 2: Impact of the optimization method during
the tuning process on BLEU score, for a baseline
NCODE system.
249
4.2 Importance of the Data Sources
Table 3 shows that using the out-of-domain data
from WMT?13 yields better scores than only using
the provided medical data only. Moreover, com-
bining both data sources drastically boosts perfor-
mance. Table 1 displays the weights (?
k
) given by
NCODE to the different sub-corpora bilingual lan-
guage models. Three corpora seems particulary
useful: EMEA, PATTR-ABSTRACTS and GIGA.
Note that several models are given a negative
weight, but removing them from the model sur-
prisingly results in a drop of performance.
DEVEL TEST
medical 42.2? 0.1 39.6? 0.1
WMT?13 43.0? 0.1 41.0? 0.0
both 48.3? 0.1 45.4? 0.0
Table 3: BLEU scores obtained by NCODE trained
on medical data only, WMT?13 data only, or both.
4.3 Part-of-Speech Tagging
Using the specialized POS-tagging models for
medical data described in Section 3.3 instead of a
standart POS-tagger, a 0.5 BLEU points increase
is observed. Table 4 suggests that a better POS
tagging quality is mainly beneficial to the reorder-
ing mechanism in NCODE, in contrast with the
POS-POS factor models included as features.
Reordering Factor model DEVEL TEST
std std 47.9? 0.0 44.8? 0.1
std spec 47.9? 0.1 45.0? 0.1
spec std 48.4? 0.1 45.3? 0.1
spec spec 48.3? 0.1 45.4? 0.0
Table 4: BLEU results when using a standard POS
tagging (std) or our medical adapted specialized
method (spec), either for the reordering rule mech-
anism (Reordering) or for the POS-POS bilingual
language models features (Factor model).
4.4 Development and Proxy Test Sets
In Table 5, we assess the importance of domain
adaptation via tuning on the development set used
and investigate the benefits of our internal test set.
Best scores are obtained when using the pro-
vided development set in the tuning process. Us-
DEVEL LMTEST NEWSTEST12 TEST
48.3? 0.1 46.8? 0.1 26.2? 0.1 45.4? 0.0
41.8? 0.2 48.9? 0.1 18.5? 0.1 40.1? 0.1
39.8? 0.1 37.4? 0.2 29.0? 0.1 39.0? 0.3
Table 5: Influence of the choice of the develop-
ment set when using our baseline NCODE system.
Each row corresponds to the choice of a develop-
ment set used in the tuning process, indicated by a
surrounded BLEU score.
Table 6: Contrast of our two main systems and
their combination, when adding SOUL language
(LM) and translation (TM) models. Stars indicate
an adapted LM. BLEU results for the best run on
the development set are reported.
DEVEL TEST
NCODE 48.5 45.2
+ SOUL LM 49.4 45.7
+ SOUL LM
?
49.8 45.9
+ SOUL LM + TM 50.1 47.0
+ SOUL LM
?
+ TM 50.1 47.0
OTF 46.6 42.5
+ VSM 46.9 42.8
+ SOUL LM 48.6 44.0
+ SOUL LM
?
48.4 44.2
+ SOUL LM + TM 49.6 44.8
+ SOUL LM
?
+ TM 49.7 44.9
SysComb-2 50.5 46.6
SysComb-7 50.7 46.5
ing NEWSTEST12 as development set unsurpris-
ingly leads to poor results, as no domain adapta-
tion is carried out. However, using LMTEST does
not result in much better TEST score. We also note
a positive correlation between DEVEL and TEST.
From the first three columns, we decided to use the
DEVEL data set as development set for our sub-
mission, which is a posteriori the right choice.
4.5 NCODE vs. OTF
Table 6 contrasts our different approaches. Prelim-
inary experiments suggest that OTF is a compara-
ble but cheaper alternative to a full MOSES sys-
tem.
5
We find a large difference in performance,
5
A control experiment for a full MOSES system (using a
single phrase table) yielded a BLEU score of 45.9 on DEVEL
and 43.2 on TEST, and took 3 more days to complete.
250
extra missing incorrect unknown
word content filler disamb. form style term order word term all
syscomb 4 13 20 47 62 8 18 21 1 11 205
OTF+VSM+SOUL 4 4 31 44 82 6 20 42 3 12 248
Table 7: Results for manual error analysis following (Vilar et al., 2006) for the first 100 test sentences.
NCODE outperforming OTF by 2.8 BLEU points
on the TEST set. VSM does not yield any signifi-
cant improvement, contrarily to the work of Chen
et al. (2013); it may be the case all individual sub-
corpus are equally good (or bad) at approximating
the stylistic preferences of the TEST set.
4.6 Integrating SOUL
Table 6 shows the substantial impact of adding
SOUL models for both baseline systems. With
only the SOUL LM, improvements on the test set
range from 0.5 BLEU points for NCODE system
to 1.2 points for the OTF system. The adaptation
of SOUL LM with the medical data brings an ad-
ditional improvement of about 0.2 BLEU points.
Adding all SOUL translation models yield an
improvement of 1.8 BLEU points for NCODE and
of 2.4 BLEU points with the OTF system using
VSM models. However, the SOUL adaptation step
has then only a modest impact. In future work, we
plan to also adapt the translation models in order
to increase the benefit of using in-domain data.
4.7 System Combination
Table 6 shows that performing the system combi-
nation allows a gain up to 0.6 BLEU points on the
DEVEL set. However this gain does not transfer to
the TEST set, where instead a drop of 0.5 BLEU
is observed. The system combination using SOUL
scores showed the best result over all of our other
systems on the DEVEL set, so we chose this (a
posteriori sub-obtimal) configuration as our main
system submission.
Our system combination strategy chose for DE-
VEL about 50% hypotheses among those produced
by NCODE and 25% hypotheses from OTF, the
remainder been common to both systems. As ex-
pected, the system combination prefers hypothe-
ses coming from the best system. We can observe
nearly the same distribution for TEST.
5 Error Analysis
The high level of scores for automatic metrics
encouraged us to perform a detailed, small-scale
analysis of our system output, using the error types
proposed by Vilar et al. (2006). A single annota-
tor analyzed the output of our main submission, as
well as our OTF variant. Results are in Table 7.
Looking at the most important types of errors,
assuming the translation hypotheses were to be
used for rapid assimilation of the text content, we
find a moderate number of unknown terms and in-
correctly translated terms. The most frequent er-
ror types include missing fillers, incorrect disam-
biguation, form and order, which all have some
significant impact on automatic metrics. Compar-
ing more specifically the two systems used in this
small-scale study, we find that our combination
(which reused more than 70% of hypotheses from
NCODE) mostly improves over the OTF variant on
the choice of correct word form and word order.
We may attribute this in part to a more efficient
reordering strategy that better exploits POS tags.
6 Conclusion
In this paper, we have demonstrated a successful
approach that makes use of two flexible transla-
tion systems, an n-gram system and an on-the-fly
phrase-based model, in a new medical translation
task, through various approaches to perform do-
main adaptation. When combined with continu-
ous language models, which yield additional gains
of up to 2 BLEU points, moderate to high-quality
translations are obtained, as confirmed by a fine-
grained error analysis. The most challenging part
of the task was undoubtedly the lack on an internal
test to guide system development. Another inter-
esting negative result lies in the absence of success
for our configuration of the vector space model
of Chen et al. (2013) for adaptation. Lastly, a more
careful integration of medical terminology, as pro-
vided by the UMLS, proved necessary.
7 Acknowledgements
We would like to thank Guillaume Wisniewski and
the anonymous reviewers for their helpful com-
ments and suggestions.
251
References
Alexandre Allauzen, Nicolas P?echeux, Quoc Khanh
Do, Marco Dinarelli, Thomas Lavergne, Aur?elien
Max, Hai-son Le, and Franc?ois Yvon. 2013. LIMSI
@ WMT13. In Proceedings of the Workshkop on
Statistical Machine Translation, pages 62?69, Sofia,
Bulgaria.
Yoshua Bengio, R?ejean Ducharme, Pascal Vincent, and
Christian Jauvin. 2003. A neural probabilistic lan-
guage model. Journal of Machine Learning Re-
search, 3(6):1137?1155.
Chris Callison-Burch, Colin Bannard, and Josh
Schroeder. 2005. Scaling phrase-based statisti-
cal machine translation to larger corpora and longer
phrases. In Proceedings of ACL, Ann Arbor, USA.
Francesco Casacuberta and Enrique Vidal. 2004. Ma-
chine translation with inferred stochastic finite-state
transducers. Computational Linguistics, 30(3):205?
225.
Ciprian Chelba and Alex Acero. 2004. Adaptation
of maximum entropy classifier: Little data can help
a lot. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing
(EMNLP), Barcelona, Spain.
Stanley F. Chen and Joshua T. Goodman. 1996. An
empirical study of smoothing techniques for lan-
guage modeling. In Proceedings of the 34th Annual
Meeting of the Association for Computational Lin-
guistics (ACL), pages 310?318, Santa Cruz, NM.
Boxing Chen, Roland Kuhn, and George Foster. 2013.
Vector space model for adaptation in statistical ma-
chine translation. In Proceedings of ACL, Sofia,
Bulgaria.
Colin Cherry and George Foster. 2012. Batch tun-
ing strategies for statistical machine translation. In
Proceedings of the 2012 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 427?436. Association for Computational Lin-
guistics.
Jonathan H Clark, Chris Dyer, Alon Lavie, and Noah A
Smith. 2011. Better Hypothesis Testing for Statisti-
cal Machine Translation : Controlling for Optimizer
Instability. In Better Hypothesis Testing for Statisti-
cal Machine Translation : Controlling for Optimizer
Instability, pages 176?181, Portland, Oregon.
Josep M. Crego and Jos?e B. Mari?no. 2006. Improving
statistical MT by coupling reordering and decoding.
Machine Translation, 20(3):199?215.
Josep M. Crego, Franc?ois Yvon, and Jos?e B. Mari?no.
2011. N-code: an open-source bilingual N-gram
SMT toolkit. Prague Bulletin of Mathematical Lin-
guistics, 96:49?58.
Daniel D?echelotte, Gilles Adda, Alexandre Allauzen,
Olivier Galibert, Jean-Luc Gauvain, H?el`ene May-
nard, and Franc?ois Yvon. 2008. LIMSI?s statisti-
cal translation systems for WMT?08. In Proc. of the
NAACL-HTL Statistical Machine Translation Work-
shop, Columbus, Ohio.
Kenneth Heafield. 2011. KenLM: Faster and Smaller
Language Model Queries. In Proceedings of the
Sixth Workshop on Statistical Machine Translation,
pages 187?197, Edinburgh, Scotland, July. Associa-
tion for Computational Linguistics.
Mark Hopkins and Jonathan May. 2011. Tuning as
ranking. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing,
EMNLP ?11, pages 1352?1362, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Reinhard Kneser and Herman Ney. 1995. Improved
backing-off for m-gram language modeling. In Pro-
ceedings of the International Conference on Acous-
tics, Speech, and Signal Processing, ICASSP?95,
pages 181?184, Detroit, MI.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexan-
dra Constantin, and Evan Herbst. 2007. Moses:
Open source toolkit for statistical machine transla-
tion. In Proceedings of the 45th Annual Meeting of
the Association for Computational Linguistics Com-
panion Volume Proceedings of the Demo and Poster
Sessions, pages 177?180, Prague, Czech Republic,
June. Association for Computational Linguistics.
Thomas Lavergne, Olivier Capp?e, and Franc?ois Yvon.
2010. Practical very large scale CRFs. In Proceed-
ings the 48th Annual Meeting of the Association for
Computational Linguistics (ACL), pages 504?513.
Association for Computational Linguistics, July.
Thomas Lavergne, Hai-Son Le, Alexandre Allauzen,
and Franc?ois Yvon. 2011. LIMSI?s experiments
in domain adaptation for IWSLT11. In Mei-Yuh
Hwang and Sebastian St?uker, editors, Proceedings
of the heigth International Workshop on Spoken
Language Translation (IWSLT), San Francisco, CA.
Hai-Son Le, Ilya Oparin, Alexandre Allauzen, Jean-
Luc Gauvain, and Franc?ois Yvon. 2011. Structured
output layer neural network language model. In Pro-
ceedings of ICASSP, pages 5524?5527.
Hai-Son Le, Alexandre Allauzen, and Franc?ois Yvon.
2012a. Continuous space translation models with
neural networks. In Proceedings of the 2012 confer-
ence of the north american chapter of the associa-
tion for computational linguistics: Human language
technologies, pages 39?48, Montr?eal, Canada, June.
Association for Computational Linguistics.
Hai-Son Le, Thomas Lavergne, Alexandre Al-
lauzen, Marianna Apidianaki, Li Gong, Aur?elien
252
Max, Artem Sokolov, Guillaume Wisniewski, and
Franc?ois Yvon. 2012b. LIMSI @ WMT12. In
Proceedings of the Seventh Workshop on Statisti-
cal Machine Translation, pages 330?337, Montr?eal,
Canada.
Adam Lopez. 2008. Tera-Scale Translation Models
via Pattern Matching. In Proceedings of COLING,
Manchester, UK.
Jos?e B. Mari?no, Rafael E. Banchs, Josep M. Crego,
Adri`a de Gispert, Patrick Lambert, Jos?e A.R. Fonol-
losa, and Marta R. Costa-Juss`a. 2006. N-gram-
based machine translation. Computational Linguis-
tics, 32(4):527?549.
Franz Josef Och. 2003. Minimum error rate training in
statistical machine translation. In Proceedings of the
41st Annual Meeting on Association for Computa-
tional Linguistics, pages 160?167, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic
Evaluation of Machine Translation. In Proceedings
of 40th Annual Meeting of the Association for Com-
putational Linguistics, pages 311?318, Philadelphia,
USA, July. Association for Computational Linguis-
tics.
Helmut Schmid. 1994. Probabilistic part-of-speech
tagging using decision trees. In Proceedings of
International Conference on New Methods in Lan-
guage Processing, September.
Holger Schwenk, Daniel Dchelotte, and Jean-Luc Gau-
vain. 2006. Continuous space language models for
statistical machine translation. In Proceedings of the
COLING/ACL on Main conference poster sessions,
pages 723?730, Morristown, NJ, USA. Association
for Computational Linguistics.
L. Smith, T. Rindflesch, and W. J. Wilbur. 2004. Med-
post: a part of speech tagger for biomedical text.
Bioinformatics, 20(14):2320?2321.
A. Stolcke. 2002. SRILM - an extensible lan-
guage modeling toolkit. In Proceedings of the In-
ternational Conference on Spoken Language Pro-
cessing (ICSLP), pages 901?904, Denver, Colorado,
September.
Christoph Tillmann. 2004. A unigram orientation
model for statistical machine translation. In Pro-
ceedings of HLT-NAACL, pages 101?104.
David Vilar, Jia Xu, Luis Fernando D?Haro, and Her-
mann Ney. 2006. Error Analysis of Statistical Ma-
chine Translation Output. In LREC, Genoa, Italy.
Richard Zens, Franz Joseph Och, and Herman Ney.
2002. Phrase-based statistical machine translation.
In M. Jarke, J. Koehler, and G. Lakemeyer, editors,
KI-2002: Advances in artificial intelligence, volume
2479 of LNAI, pages 18?32. Springer Verlag.
253
