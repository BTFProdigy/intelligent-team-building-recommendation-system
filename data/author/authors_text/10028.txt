Proceedings of the ACL-08: HLT Student Research Workshop (Companion Volume), pages 37?42,
Columbus, June 2008. c?2008 Association for Computational Linguistics
Arabic Language Modeling with Finite State Transducers
Ilana Heintz
Department of Linguistics
The Ohio State University
Columbus, OH
heintz.38@osu.edu?
Abstract
In morphologically rich languages such as
Arabic, the abundance of word forms result-
ing from increased morpheme combinations is
significantly greater than for languages with
fewer inflected forms (Kirchhoff et al, 2006).
This exacerbates the out-of-vocabulary (OOV)
problem. Test set words are more likely to
be unknown, limiting the effectiveness of the
model. The goal of this study is to use the
regularities of Arabic inflectional morphology
to reduce the OOV problem in that language.
We hope that success in this task will result in
a decrease in word error rate in Arabic auto-
matic speech recognition.
1 Introduction
The task of language modeling is to predict the next
word in a sequence of words (Jelinek et al, 1991).
Predicting words that have not yet been seen is the
main obstacle (Gale and Sampson, 1995), and is
called the Out of Vocabulary (OOV) problem. In
morphologically rich languages, the OOV problem
is worsened by the increased number of morpheme
combinations.
Berton et al (1996) and Geutner (1995) ap-
proached this problem in German, finding that lan-
guage models built on decomposed words reduce the
OOV rate of a test set. In Carki et al (2000), Turk-
ish words are split into syllables for language model-
ing, also reducing the OOV rate (but not improving
?This work was supported by a student-faculty fellowship
from the AFRL/Dayton Area Graduate Studies Insititute, and
worked on in partnership with Ray Slyh and Tim Anderson of
the Air Force Research Labs.
WER). Morphological decomposition is also used to
boost language modeling scores in Korean (Kwon,
2000) and Finnish (Hirsima?ki et al, 2006).
We approach the processing of Arabic morphol-
ogy, both inflectional and derivational, with finite
state machines (FSMs). We use a technique that pro-
duces many morphological analyses for each word,
retaining information about possible stems, affixes,
root letters, and templates. We build our language
models on the morphemes generated by the anal-
yses. The FSMs generate spurious analyses. That
is, although a word out of context may have several
morphological analyses, in context only one such
analysis is correct. We retain all analyses. We ex-
pect that any incorrect morphemes that are generated
will not affect the predictions of the model, because
they will be rare, and the language model introduces
bias towards frequent morphemes. Although many
words in a test set may not have occurred in a train-
ing set, the morphemes that make up that word likely
will have occurred. Using many decompositions to
describe each word sets apart this study from other
similar studies, including those byWang and Vergyri
(2006) and Xiang et al (2006).
This study differs from previous research on Ara-
bic language modeling and Arabic automatic speech
recognition in two other ways. To promote cross-
dialectal use of the techniques, we use properties of
Arabic morphology that we assume to be common to
many dialects. Also, we treat morphological analy-
sis and vowel prediction with a single solution.
An overview of Arabic morphology is given in
Section 2. A description of the finite state machine
process used to decompose the Arabic words into
37
morphemes follows in Section 3. The experimental
language model training procedure and the proce-
dures for training two baseline language models are
discussed in Section 4. We evaluate all three models
using average negative log probability and coverage
statistics, discussed in Section 5.
2 Arabic Morphology
This section describes the morphological processes
responsible for the proliferation of word forms in
Arabic. The discussion is based on information from
grammar textbooks such as that by Haywood and
Nahmad (1965), as well as descriptions in various
Arabic NLP articles, including that by Kirchhoff et
al. (2006).
Word formation in Arabic takes place on two
levels. Arabic is a root-and-pattern language in
which many vocalic and consonantal patterns com-
bine with semantic roots to create surface forms. A
root, usually composed of three letters, may encode
more than one meaning. Only by combining a root
with a pattern does one create a meaningful and spe-
cific term. The combination of a root with a pattern
is a stem. In some cases, a stem is a complete surface
form; in other cases, affixes are added.
The second level of word formation is inflec-
tional, and is usually a concatenative process. In-
flectional affixes are used to encode person, number,
gender, tense, and mood information on verbs, and
gender, number, and case information on nouns. Af-
fixes are a closed class of morphemes, and they en-
code predictable information. In addition to inflec-
tion, cliticization is common in Arabic text. Prepo-
sitions, conjunctions, and possessive pronouns are
expressed as clitics.
This combination of templatic derivational mor-
phology and concatenative inflectional morphology,
together with cliticization, results in a rich variation
in word forms. This richness is in contrast with the
slower growth in number of English word forms. As
shown in Table 1, the Arabic stem /drs/, meaning to
study, combines with the present tense verb pattern
?CCuCu?, where the ?C? represents a root letter, to
form the present tense stem drusu. This stem can be
combined with 11 different combinations of inflec-
tional affixes, creating as many unique word forms.
Table 1 can be expanded with stems from the
Transliteration Translation Affixes
adrusu I study a-
nadrusu we study na-
tadrusu you (ms) study ta-
tadrusina you (fs) study ta- ,-ina
tadrusAn you (dual) study ta-, -An
tadrusun you (mp) study ya-, -n
tadrusna you (fp) study ta-, -na
yadrusu he studies ya-
tadrusu she studies ta-
yadrusan they (dual) study ya-, -An
yadrusun they (mp) study ya-, -n
yadrusna they (fp) study ya-, -na
Table 1: An Example of Arabic Inflectional Morphology
same root representing different tenses. For in-
stance, the stem daras means studied. Or, we can
combine the root with a different pattern to obtain
different meanings, for instance, to teach or to learn.
Each of these stems can combine with the same or
different affixes to create additional word forms.
Adding a single clitic to the words in Table 1 will
double the number of forms. For instance, the word
adrusu, meaning I study, can take the enclitic ?ha?,
to express I study it. Some clitics can be combined,
increasing again the number of possible word forms.
Stems differ in some ways that do not surface in
the Arabic orthography. For instance, the pattern
?CCiCu? differs from ?CCuCu? only in one short
vowel, which is encoded orthographically as a fre-
quently omitted diacritic. Thus, adrisu and adrusu
are homographs, but not homophones. This prop-
erty helps decrease the number of word forms, but
it causes ambiguity in morphological analyses. Re-
covering the quality of short vowels is a significant
challenge in Arabic natural language processing.
This abundance of unique word forms in Modern
Standard Arabic is problematic for natural language
processing (NLP). NLP tasks usually require that
some analysis be provided for each word (or other
linguistic unit) in a given data set. For instance,
in spoken word recognition, the decoding process
makes use of a language model to predict the words
that best fit the acoustic signal. Only words that have
been seen in the language model?s training data will
be proposed. Because of the immense number of
possible word forms in Arabic, it is highly proba-
38
0
1m
2m t d A s r
3A s r m t d
4m t d A s r
0
1m t d A s r
2s r m t d A
3A
4m t d A s r
Figure 1: Two templates, mCCC andCCAC as finite state
recognizers, with a small sample alphabet of letters A, d,
m, r, s, and t.
0m:mt:td:dA:As:sr:r
1
m:[m
2A:A s:s r:r m:m t:t d:d
3
m:m t:t d:d A:A s:s r:r
4
m:m] t:t] d:d] A:A] s:s] r:r]m:
mt:td:dA:As:sr:r
Figure 2: The first template above, now a transducer, with
affixes accepted, and the stem separated by brackets in the
output.
ble that the words in an acoustic signal will not have
been present in the language model?s training text,
and incorrect words will be predicted. We use in-
formation about the morphology of Arabic to create
a more flexible language model. This model should
encounter fewer unseen forms, as the units we use to
model the language are the more frequent and pre-
dictable morphemes, as opposed to full word forms.
As a result, the word error rate is expected to de-
crease.
3 FSM Analyses
This section describes howwe derive, for each word,
a lattice that describes all possible morphological
decompositions for that word. We start with a group
of templates that define the root consonant positions,
long vowels, and consonants for all Arabic regular
and augmented stems. For instance, where C repre-
sents a root consonant, three possible templates are
0
2
m
1
[mdrA]
3
[drAs] s
Figure 3: Two analyses of the word ?mdrAs?, as pro-
duced by composing a word FSM with the template
FSMs above.
CCC, mCCC, and CACC. We build a finite state rec-
ognizer for each of the templates, and in each case,
the C arcs are expanded, so that every possible root
consonant in the vocabulary has an arc at that posi-
tion. The two examples in Figure 1 show the patterns
mCCC and CCAC and a short sample alphabet.
At the start and end node of each template recog-
nizer, we add arcs with self-loops. This allows any
sequence of consonants as an affix. To track stem
boundaries, we add an open bracket to the first stem
arc, and a close bracket to the final stem arc. The
templates are compiled into finite state transducers.
Figure 2 shows the result of these additions.
For each word in the vocabulary, we define a sim-
ple, one-arc-per-letter finite state recognizer. We
compose this with each of the templates. Some num-
ber of analyses result from each composition. That
is, a single template may not compose with the word,
may compose with it in a unique way, or may com-
pose with the word in several ways. Each of the suc-
cessful compositions produces a finite state recog-
nizer with brackets surrounding the stem. We use a
script to collapse the arcs within the stem to a single
arc. The result is shown in Figure 3, where the word
?mdrAs? has two analyses corresponding to the two
templates shown. We store a lattice as in Figure 3
for each word.
The patterns that we use to constrain the stem
forms are drawn from Haywood and Nahmad
(1965). These patterns also specify the short vowel
patterns that are used with words derived from each
pattern. An option is to simply add these short
vowels to the output symbols in the template FSTs.
However, because several short vowel options may
exist for each template, this would greatly increase
the size of the resulting lattices. We postpone this ef-
fort. In this work, we focus solely on the usefulness
of the unvoweled morphological decompositions.
We do not assess or need to assess the accuracy of
39
the morphological decompositions. Our hypothesis
is that by having many possible decompositions per
word, the frequencies of various affixes and stems
across all words will lead the model to the strongest
predictions. Even if the final predictions are not pre-
scriptively correct, they may be the most useful de-
compositions for the purpose of speech decoding.
4 Procedure
We compare a language model built on multiple seg-
mentations as determined by the FSMs described
above to two baseline models. We call our exper-
imental model FSM-LM; the baseline models use
word-based n-grams (WORD), and pre-defined affix
segmentations (AFFIX). Our data set in this study
is the TDT4 Arabic broadcast news transcriptions
(Kong and Graff, 2005). Because of time and mem-
ory constraints, we built and evaluated all models on
only a subsection of the training data, 100 files of
TDT4, balanced across the years of collection, and
containing files from each of the 4 news sources. We
use 90 files for training, comprising about 6.3 mil-
lion unvoweled word tokens, and 10 files for testing,
comprising about 700K word tokens, and around 5K
sentences. The size of the vocabulary is 104757. We
use ten-fold cross-validation in our evaluations.
4.1 Experimental Model
We extract the vocabulary of the training data, and
compile the word lattices as described in Section 3.
The union of all decompositions (a lattice) for each
individual word is stored separately.
For each sentence of training data, we concate-
nate the lattices representing each word in that sen-
tence. We use SRILM (Stolcke, 2002) to calculate
the posterior expected n-gram count for morpheme
sequences up to 4-grams in the sentence-long lattice.
The estimated frequency of an n-gram N is calcu-
lated as the number of occurrences of that n-gram
in the lattice, divided by the number of paths in the
lattice. This is true so long as the paths are equally
weighted; at this point in our study, this is the case.
We merge the n-gram counts over all sentences
in all of the training files. Next, we estimate a lan-
guage model based on the n-gram counts, using only
the 64000 most frequent morphemes, since we ex-
pect this vocabulary size may be a limitation of our
ASR system. Also, by limiting the vocabulary size
of all of our models (including the baseline models
described below), we can make a fairer comparison
among the models. We use Good-Turing smoothing
to account for unseen morphemes, all of which are
replaced with a single ?unknown? symbol.
In later work, we will apply our LM statistics to
the lattices, and recalculate the path weights and
estimated counts. In this study, the paths remain
equally weighted.
We evaluate this model, which we call FSM-LM,
with respect to two baseline models.
4.2 Baseline Models
For the WORD model, we do no manipulation to the
training or test sets beyond the normalization that
occurs as a preprocessing step (hamza normaliza-
tion, replacement of problematic characters). We
build a word-based 4-gram language model using
the 64000 most frequent words and Good-Turing
smoothing.
For the AFFIX model, we first define the charac-
ter strings that are considered affixes. We use the
same list of affixes as in Xiang et al (2006), which
includes 12 prefixes and 34 suffixes. We add to the
lists all combinations of two prefixes and two suf-
fixes. We extract the vocabulary from the training
data, and for each word, propose a single segmenta-
tion, based on the following constraints:
1. If the word has an acceptable prefix-stem-suffix
decomposition, such that the stem is at least 3
characters long, choose it as the correct decom-
position.
2. If only one affix is found, make sure the re-
mainder is at least 3 characters long, and is not
also a possible affix.
3. If the word has prefix-stem and stem-suffix de-
compositions, use the longest affix.
4. If the longest prefix and longest suffix are equal
length, choose the prefix-stem decomposition.
We build a dictionary that relates each word to a
single segmentation (or no segmentation). We seg-
ment the training and test texts by replacing each
word with its segmentation. Morphemes are sepa-
rated by whitespace. The language model is built by
counting 4-grams over the training data, then using
only the most frequent 64000 morphemes in estimat-
ing a language model with Good-Turing smoothing.
40
WORD AFFIX FSM-LM
Avg Neg
Log Prob
4.65 5.30 4.56
Coverage (%):
Unigram 96.03 99.30 98.89
Bigram 17.81 53.13 69.56
Trigram 1.52 11.89 27.25
Four-gram .37 3.42 9.62
Table 2: Average negative log probability and coverage
results for one experimental language model (FSM-LM)
and two baseline language models. Results are averages
over 10 folds.
5 Evaluation
For each model, the test set undergoes the same ma-
nipulation as the train set; words are left alone for
the WORD model, split into a single segmentation
each for the AFFIX model, or their FSM decompo-
sitions are concatenated.
Language models are often compared using the
perplexity statistic:
PP (x1 . . . xn) = 2
? 1n
?n
xi=4
logP (xi|x
i?3
i?1) (1)
Perplexity represents the average branching factor of
a model; that is, at each point in the test set, we cal-
culate the entropy of the model. Therefore, a lower
perplexity is desired.
In the AFFIX and FSM-LM models, each word is
split into several parts. Therefore, the value 1n would
be approximately three times smaller for these mod-
els, giving them an advantage. To make a more even
comparison, we calculate the geometric mean of the
n-gram transition probabilities, dividing by the num-
ber of words in the test set, not morphemes, as in
Kirchhoff et al (2006). The log of this equation is:
AvgNegLogProb(x1 . . . xn) =
?
1
N
n?
i=4
logP (xi|x
i?3
i?1) (2)
where n is the number of morphemes or words in the
test set, depending on the model, and N is the num-
ber of words in the test set, and log P (xi|x
i?3
i?1) is the
log probability of the item xi given the 3-item his-
tory (calculated in base 10, as this is how the SRILM
Toolkit is implemented). Again, we are looking for
a low score.
In the FSM-LM, each test sentence is represented
by a lattice of paths. To determine the negative log
probability of the sentence, we score all paths of
the sentence according to the equations above, and
record the maximum probability. This reflects the
likely procedure we would use in implementing this
model within an ASR task.
We see in Table 2 that the average negative log
probability of the FSM-LM is lower than that of
either the WORD or AFFIX model. The average
across 10 folds reflects the pattern of scores for each
fold. We conclude from this that the FSM model
of predicting morphemes is more effective than -
or more conservatively, at least as effective as - a
static decomposition, as in the AFFIX model. Fur-
thermore, we have successfully reproduced the re-
sults of Xiang et al (2006) and Kirchhoff et al
(2006), among others, that modeling Arabic with
morphemes is more effective than modeling with
whole word forms.
We also calculate the coverage of each model: the
percentage of units in the test set that are given prob-
abilities in the language model. For the FSM model,
only the morphemes in the best path are counted.
The coverage results are reported in Table 2 as the
average coverage over the 10 folds. Both the AF-
FIX and FSM-LM models showed improved cover-
age as compared to the WORD model, as expected.
This means that we reduce the OOV problem by us-
ing morphemes instead of whole words. The AF-
FIX model has the best coverage of unigrams be-
cause only new stems, not new affixes, are proposed
in the test set. That is, the same fixed set of affixes
are used to decompose the test set as the train set,
however, unseem stems may appear. In the FSM-
LM, there are no restrictions on the affixes, there-
fore, unseen affixes may appear in the test set, as
well as new stems, lowering the unigram coverage of
the test set. For larger n-grams, however, the FSM-
LM model has the best coverage. This is due to
keeping all decompositions until test time, then al-
lowing the language model to define the most likely
sequences, rather than specifying a single decompo-
sition for each word.
A 4-gram of words will tend to cover more con-
text than a 4-gram of morphemes; therefore, the
word 4-grams will exhibit more sparsity than the
morpheme 4-grams. We compare, for a single train-
41
WORD AFFIX FSM-LM
unigrams 4.97 5.84 5.60
bigrams 4.95 5.70 4.61
trigrams 4.95 5.69 4.56
four-grams 4.95 5.69 4.57
Table 3: Comparison of n-gram orders across language
model types.
test fold, how lower order n-grams compare among
the models. The results are shown in Table 3. We
find that for lower-order n-grams, the word model
performs best. As the n-grams get larger, the spar-
sity problem favors the FSM-LM, which has the best
overall score of all models shown. Apparently, the
frequencies of 3- and 4-grams are not big enough
to make a big difference in the evaluation. This is
likely due to the small size of our corpus, and we
expect the result would change if we were to use all
of the TDT4 corpus, rather than a 100 file portion of
the corpus.
6 Conclusion & Future Work
It has been shown that reduced perplexity scores do
not necessarily correlate with reduced word error
rates in an ASR task (Berton et al, 1996). This is be-
cause the perplexity (or in this case, average negative
log probability) statistic does not take into account
the acoustic confusability of the items being consid-
ered. However, the average negative log probability
score is a useful tool as a proof-of-concept, giving
us reason to believe that we may be successful in
implementing this model within an ASR task.
The real test of this model is its ability to predict
short vowels. The average negative log probability
scores may lead us to believe that the FSM-LM is
only marginally better than the WORD or AFFIX
model, and the differences may not be apparent in
an ASR application. However, only the FSM-LM
model allows for the opportunity to predict short
vowels, by arranging the FSMs as finite state trans-
ducers with short vowel information encoded as part
of the stem patterns.
We will continue to tune the language model by
applying the language model weights to the decom-
position paths and re-estimating the language model.
Also, we will expand the language model to include
more training data. We will implement the model
within an Arabic ASR system, with and without
short vowel hypotheses. Furthermore, we are inter-
ested to see how well the application of these tem-
plates and this framework will apply to other Arabic
dialects.
References
A Berton, P Fetter, and P Regel-Brietzmann. 1996.
Compound words in large vocabulary German speech
recognition system. In Proceedings of ICSLP 96,
pages 1165?1168.
K. Carki, P. Geutner, and T. Schultz. 2000. Turkish
lvcsr: Towards better speech recognition for aggluti-
native languages. In ICASSP 2000, pages 134?137.
William A. Gale and Geoffrey Sampson. 1995. Good-
Turing frequency estimation without tears. Journal of
Quantitative Linguistics, 22:217?37.
P Geutner. 1995. Using morphology towards better
large-vocabulary speech recognition systems. In Pro-
ceedings of ICASSP-95, volume 1, pages 445?448.
J.A. Haywood and H.M. Nahmad. 1965. A New Arabic
Grammar of the Written Language. Lund Humphries,
Burlington, VT.
Teemu Hirsima?ki, Mathias Creutz, Vesa Siivola, Mikko
Kurimo, Sami Virpioja, and Janne Pylkko?nen. 2006.
Unlimited vocabulary speech recognition with morph
language models applied to Finnish. Computer Speech
and Language, 20:515?541.
F. Jelinek, B. Merialdo, S. Roukos, and M. Strauss. 1991.
A dynamic language model for speech recognition. In
Proc. Wkshp on Speech and Natural Language, pages
293?295, Pacific Grove, California. ACL.
Katrin Kirchhoff, Dimitra Vergyri, Kevin Duh, Jeff
Bilmes, and Andreas Stolcke. 2006. Morphology-
based language modeling for conversational Arabic
speech recognition. Computer Speech and Language,
20(4):589?608.
Junbo Kong and David Graff. 2005. TDT4 multilingual
broadcast news speech corpus.
Oh-Wook Kwon. 2000. Performance of LVCSR with
morpheme-based and syllable-based recognition units.
In Proceedings of ICASSP ?00, volume 3, pages 1567?
1570.
Andreas Stolcke. 2002. SRILM - an extensible lan-
guage modeling toolkit. In Proc. Intl. Conf. Spoken
Language Processing, Denver, Colorado.
Wen Wang and Dimitra Vergyri. 2006. The use of word
n-grams and parts of speech for hierarchical cluster
language modeling. In Proceedings of ICASSP 2006,
pages 1057?1060.
Bing Xiang, Kham Nguyen, Long Nguyen, Richard
Schwartz, and John Makhoul. 2006. Morphological
decomposition for Arabic broadcast news transcrip-
tion. In Proc. ICASSP 2006, pages 1089?1092.
42
Proceedings of the First Workshop on Metaphor in NLP, pages 58?66,
Atlanta, Georgia, 13 June 2013. c?2013 Association for Computational Linguistics
Automatic Extraction of Linguistic Metaphor with LDA Topic Modeling 
Ilana Heintz*, Ryan Gabbard*, Mahesh Srinivasan+, *, David Barner+, Donald S. Black*, 
 Marjorie Freedman*, Ralph Weischedel*  
 
* Raytheon BBN Technologies 
10 Moulton St,  
Cambridge MA 02139 
 
{iheintz, rgabbard,  
mfreedman, dblack, 
rweischedel}@bbn.com 
+University of California, San Diego 
5336 McGill Hall,  
9500 Gilman Drive 
La Jolla, CA 92093-0109 
 
 barner@ucsd.edu,  
mahesh.srinivasan@gmail.com  
Abstract 
We aim to investigate cross-cultural patterns 
of thought through cross-linguistic investiga-
tion of the use of metaphor.  As a first step, 
we produce a system for locating instances of 
metaphor in English and Spanish text.  In con-
trast to previous work which relies on re-
sources like syntactic parsing and WordNet, 
our system is based on LDA topic modeling, 
enabling its application even to low-resource 
languages, and requires no labeled data.  We 
achieve an F-score of 59% for English. 
1 Introduction 
Patterns in the use of metaphors can provide a 
great deal of insight into a culture. Cultural differ-
ences expressed linguistically as metaphor can play 
a role in matters as complex and important as dip-
lomatic relations.  For instance, Thornborrow 
(1993) discusses the different metaphors that are 
used in the context of security in French and Brit-
ish coverage of two major post-cold-war summit 
meetings.  Example metaphors such as ?the corner-
stone of the new security structure,? ?structures for 
defence and security cooperation,? and ?the emerg-
ing shape of Europe,? exemplify the English use of 
the source concept structure in describing the tar-
get concept of security.  In contrast, the metaphors 
?des r?gles de s?curit? nouvelles (new rules of se-
curity)?, ?une r?vision fondamentale des disposi-
tions de s?curit? (a fundamental revision of 
security provisions)?, and ?un syst?me de s?curit? 
europ?en (a system of European security)? exem-
plify the French use of the more abstract source 
concept system to describe the same target concept.  
As Thornborrow notes, the implied British concep-
tion of security as ?concrete, fixed, and immobile? 
contrasts deeply with the French conception of se-
curity as ?a system as a series of processes.? 
Our ultimate goal is to use metaphor to further 
our knowledge of how different cultures under-
stand complex topics.  Our immediate goal in this 
paper is to create an automated system to find in-
stances of metaphor in English and Spanish text. 
Most existing work on metaphor identification 
(Fass, 1991; Martin, 1994; Peters and Peters, 2000; 
Mason, 2004; Birke and Sarkar, 2006; Gegigan et 
al., 2006; Krishnakumaran and Zhu, 2007; Shutova 
et  al., 2010; Shutova et al, 2012)1 has relied 
on some or all of handwritten rules, syntactic pars-
ing, and semantic databases like WordNet (Fell-
baum, 1998) and FrameNet (Baker et al, 1998).  
This limits the approaches to languages with rich 
linguistic resources.  As our ultimate goal is broad, 
cross-linguistic application of our system, we can-
not rely on resources which would be unavailable 
in resource-poor languages.  Instead, we apply 
LDA topic modeling (Blei et al, 2003b) which 
requires only an adequate amount of raw text in the 
target language.  This work is similar to Bethard et 
al. (2009), in which an SVM model is trained with 
LDA-based features to recognize metaphorical 
text. There the work is framed as a classification 
task, and supervised methods are used to label 
metaphorical and literal text.  Here, the task is one 
of recognition, and we use heuristic-based, unsu-
                                                          
1 See Shutova (2010) for a survey of existing approaches 
58
pervised methods to identify the presence of meta-
phor in unlabeled text. We hope to eliminate the 
need for labeled data which, as discussed in 
Bethard et al (2009) and elsewhere, is very diffi-
cult to produce for metaphor recognition. 
2 Terminology 
We will refer to a particular instance of metaphori-
cal language in text as a linguistic metaphor.  
Each such metaphor talks about a target concept 
in terms of a source concept.  For example, in 
?Dems, like rats, will attack when cornered? the 
source concept is animals and the target concept is 
politicians2, or at a higher level, governance.  The 
abstract mapping between a source concept and a 
target concept will be referred to as a conceptual 
metaphor which is grounded by a collection of 
linguistic metaphors. 
In this work, we restrict our attention to a single 
target concept, governance.  Our definition of gov-
ernance is broad, including views of the governed 
and those who govern, institutions of government, 
laws, and political discourse.  We used a large col-
lection (see Table 1) of potential source concepts.  
Beginning with the source concepts of primary 
metaphors, which are hypothesized to be univer-
sal (Grady, 1998), we expanded our set to include 
source concepts commonly found in the scientific 
literature about metaphor, as well as those found 
by human annotators manually collecting instances 
of governance-related metaphors. 
 
Animals Fishing Plants 
Baseball Flight Race 
Body Football Religion 
Botany Gambling Sick 
Boundary Grasp Size 
Chess Health Sound 
Color Height Sports 
Combustion Light Taste 
Cooking Liquid Temperature 
Courtship Machine Texture 
Cut Maritime Theater 
Directional force Money Time of day 
Dogs Motion Toxicity 
Drug use Mythology Vehicle 
Electricity Natural disasters War 
Energy source Nuclear Weaponry 
Entry Odor Weather 
                                                          
2 ?Dems?' refers to the Democratic Party, an American politi-
cal party 
Family Pathways Weight 
Farming Physical structure Wild west 
Fight Planning  
Table 1: English Source Concepts 
3 High-level system overview 
 
Figure 1: System Overview 
 
Our main hypothesis is that metaphors are likely to 
be found in sentences that exhibit evidence of both 
a source and a target concept.  The core idea of our 
system is to use LDA topics as proxies for seman-
tic concepts which may serve as the source or tar-
get for a metaphor.  For a given language, we build 
an LDA model from Wikipedia and then align its 
topics to potential source and target concepts, 
which are defined by small human-created lists of 
seed words. 
At runtime, the system first does LDA infer-
ence on our input corpus to get topic probabilities 
for each document and sentence.  The system then 
selects those sentences linked by LDA to both a 
source-aligned topic and a target-aligned topic.3 
For example, a sentence containing ??virtud so-
                                                          
3 This is a distant, automatic relative of the ?directed-search? 
technique of Martin (1994). 
59
cial para construir la democracia??4 will be se-
lected because LDA strongly associates it with 
both the topic [elecciones, ministro, sucesor, ?]5, 
aligned to the target concept governance, and the 
topic [edificio, arquitectura, torre,?] 6, aligned to 
the source concept physical structure.  
Next, the system identifies the words in each 
selected sentence that are strongly associated with 
each concept. In the sentence above, it marks vir-
tud and democracia as target-associated and con-
struir as source-associated. 
Next it applies two filters. First, we exclude any 
sentence with too few words that are not LDA 
stopwords, because the model's predictions may be 
very inaccurate in these cases.  Second, if the topic 
associated with the source model for a sentence is 
also a top-ranked topic for the document as a 
whole, the sentence is excluded.  The reason for 
this is that if the source concept is present through-
out the document, it is probably being used literal-
ly (see Figure 2). 
Finally, it uses previously-computed infor-
mation to determine a final score.  All linguistic 
metaphors scoring above a certain threshold are 
returned.  By varying this threshold, the user can 
vary the precision-recall tradeoff as needed. A dia-
gram of the system can be found in Figure 1. 
 
Figure 2: Even though the last sentence is relevant to the 
source concept pathways and the target concept govern-
ance, it will be correctly rejected because pathways-
aligned topics are present throughout the document. 
4 Implementation Details: Training 
Our runtime system requires as input an LDA 
model, a list of seed words for each concept, and 
an alignment between concepts and LDA topics. 
4.1 LDA Topic Model 
The topics defined by LDA topic modeling serve 
as stand-ins for the more abstractly-defined source 
and target concepts underlying the metaphors.  The 
input to training our LDA model is the full text of 
                                                          
4 social virtue to build democracy 
5 elections, minister, successor 
6 building, architecture, tower 
Wikipedia articles in the target language.  Wikipe-
dia is available in numerous languages and serves 
as a corpus of general knowledge, providing us 
with topics corresponding to a broad range of con-
cepts.  Our LDA model is trained using MALLET 
(McCallum, 2002) for 1000 iterations with 100 
topics, optimizing hyperparameters every 10 itera-
tions after a 100 iteration burn-in period. The 500 
most common tokens in the training corpus were 
used as stopwords. The result of LDA is 100 top-
ics, where each topic is a probability distribution 
over the training corpus vocabulary.  Representa-
tive words for example English topics are shown in 
Figure 3. 
 
Figure 3: Sample LDA topics with representative terms 
4.2 Concept Seed Word Lists 
For each concept  , we have a label and a small set 
of seed words representing that concept, referred to 
as     .  These lists were created by hand in Eng-
lish and then translated into Spanish by native 
speakers. The translation was not intended to be 
exact; we instructed the annotators to create the 
lists in a way that was appropriate for their lan-
guage and culture.  For instance, the football topic 
for English describes American football, but in 
Spanish, the same topic describes soccer. 
4.3 Concept-Topic Alignment 
The final input to our system is an alignment be-
tween concepts and topics, with every topic being 
mapped to at most one concept.  In addition to the 
seed lists and LDA model, this alignment process 
takes a score threshold        and a maximum 
number of alignments per source and target con-
cept   and  .  
The alignment algorithm is as follows. We 
align each topic   to the concept   with the maxi-
mum score       , which measures the concept 
terms? summed probability in the LDA topic: 
                      .  We remove all align-
ments where                . Finally, for each 
concept, only the   highest scoring alignments 
are kept, where   may be different for source and 
Our county has many roads in bad shape.  
Thousands of our bridges are structurally 
deficient.  Congress needs to pass a new 
highway bill. 
theater stage musical miss actreess 
theory philosophy pp study scientific 
knowledge 
nfl bowl yards coach players card yard 
governor republican senate election congress 
60
target. We refer to the aligned topics for a concept 
  as     . 
Label Seed List 
Words 
Aligned Topics 
Vehicle vehicle, 
wheels, gas, 
bus 
0.035: engine, car, 
model 
0.29: railway, 
trains, train 
0.022: energy, 
gas, linear 
Animals animal, beast, 
cattle 
0.066: animals, 
animal, species 
Courtship courtship, ro-
mance, court 
None 
Governance aristocrat, bi-
partisan, citi-
zen, duke 
0.25: Election, 
elected, parliament 
0.22: Governor, 
republican, Senate 
0.14: sir, lord,  
henry 
0.13: kingdom, 
emperor, empire 
0.12: rights, legal, 
laws 
Table 2: Sample concepts, manually-created seed lists, 
and aligned topics 
A last condition on the topic-concept alignment 
is the assignment of topics to trump concepts. Our 
only trump concept in this study is war. If an LDA 
topic is aligned with both the war concept and the 
governance concept, it is removed from alignment 
with the governance concept. We do this because 
war is so tightly associated with governments that 
the alignment algorithm invariably aligns it to the 
governance topic.  However, war is also a very 
important source concept for governance meta-
phors; our choice is to suffer on recall by missing 
some governance-relevant sentences, but increase 
recall on metaphors for which the source concept is 
war. Sample topic-concept alignments are shown 
inTable 2. By inspecting the resulting alignments 
by hand, we chose the following parameter values 
for both languages:       =0.01,  =3,  =5.   
The process of defining concepts is simple and 
fast and the alignment method is inexpensive.  
Therefore, while we have not captured all possible 
source concepts in our initial list, expanding this 
list is not difficult.  We can define new source con-
cepts iteratively as we analyze metaphors that our 
extraction system misses, and we can add target 
concepts as our interests broaden. 
5 Implementation Details: Runtime 
The system receives as input a corpus of docu-
ments, their LDA decodings, the LDA decodings 
of each sentence treated as a separate document, 
and the topic-concept alignments. Each four-tuple 
          is processed independently, where   is 
the language,   is the source concept,   is the tar-
get concept, and   is the sentence. 
 
Determining Concept Relevance: Recall our 
basic intuition that a sentence relevant both to an 
LDA topic in      (termed source-relevant) and 
one in      (termed target-relevant) is potentially 
metaphorical.  The system judges a sentence   to 
be  -relevant if the probability of  -aligned topics 
in that sentence is above a threshold:       
                      , where        is an ad-
justable parameter tuned by hand.         is 0.06 in 
English and 0.05 in Spanish.        is 0.1 in both 
languages. On the source side, the system removes 
all topics in      from        and renormalizes 
before determining relevance in order to avoid pe-
nalizing sentences for having very strong evidence 
of relevance to governance in addition to providing 
evidence of relevance to a source concept.  For 
reference below, let                    (a 
measure of how strongly the sentence is associated 
with its topics) and let 
                            (the most proba-
ble  -aligned topic in the sentence). 
If   is not both source- and target-relevant, the 
system stops and the sentence is not selected. 
 
Finding Concept-Associated Words: The system 
next creates sets    of the words in   associated 
with the concept  .  Let                   .  
Then let   
  {                   , where 
      is a hand tuned parameter set to 0.1 for both 
languages. That is, any word whose probability in 
the topic is higher than a theshold is included as a 
concept-associated word in that sentence.  Let 
               and vice-versa. Note that words 
which could potentially be associated with either 
concept are associated with neither.  For reference 
below, let                      (the most 
strongly concept-associated words in the sentence) 
61
and                    (the combined 
strength of those associations).  
If   lacks words strongly associated with the 
source and target concepts (that is,    or    is 
empty), the system stops and the sentence is not 
selected. 
Filters: The system applies two filters. First,   
must have at least four words which are not LDA 
stopwords; otherwise, the LDA predictions which 
drive the system's concept-relevance judgements 
tend to be unreliable.  Second, the most likely 
source topic       must not be one of the top 10 
topics for the document as a whole, for reasons 
described above.  If either of these requirements 
fail, the system stops and the sentence is not se-
lected. 
Final Scoring: Finally, the system determines 
if  
  (  (     )  (     )            )         
where        is a hand-tuned threshold set to -10.0 
for English and -13.0 for Spanish.  This takes into 
account the strength of association between topics 
and the sentence, between the annotated words and 
the topics, and between the topics and their aligned 
concepts.  Any sentence passing this threshold is 
selected as a linguistic metaphor. 
6 Example Output 
We provide examples of both true and false posi-
tives extracted by our system.  The annotations of 
source and target-associated words in each sen-
tence are those defined as    and    above.  The 
source concept animals is used for all examples. 
1. ModeratesT we all hear are an endangeredS 
speciesS, Sen. Richard 
2. DemsT like ratsS sometimes attack when cor-
nered 
3. ObamaT 's world historical political ambitions 
crossbredS with his 
4. At least DemocraticT representativesT are 
snakeheadS fish 
5. Another whopperS from Cleveland, GOPT 
lawyer backs him up 
6. Previous post: Illinois GOPT lawmakerT ar-
rested in animalS feed bag related incident 
7. Next post: National Enquirer catfighting 
Michelle ObamaT has clawsS out for that nice 
Ann Romney 
8. Sen. Lisa MurkowskiT R AK independent 
from Alaska - thank you silly Repubs, teaS 
party her out ha  
Examples 1 through 4 are correct metaphors ex-
tracted by our system.  In each, some words related 
to the target concept governance are described us-
ing terms related to the source concept animals.  
Example 1 best represents the desired output of our 
system, such that it contains a governance- and 
animals-relevant metaphor and the terms associat-
ed with the metaphor are properly annotated. Some 
issues do arise in these true positive examples. Ex-
ample 2, while often termed a simile, is counted as 
a metaphor for our purposes.  In example 3, the 
source term is correctly annotated, but the target 
terms should be political ambitions rather than  
Obama.  It is unclear why the term snakehead but 
not the term fish in example 4 is associated with 
the source concept.  
Examples 5 through 8 represent system errors.  
In example 5, the fact that the word whopper oc-
curs frequently to describe a large animal (espe-
cially a fish) causes the sentence to be mistakenly 
identified as relevant to the source concept animal.  
The source term animal in example 6 is clearly 
relevant to the source concept, but it is being used 
literally.  The document-level source concept fil-
tering does not entirely eliminate this error class.  
While example 7 contains a metaphor and has 
some relationship to American politics, it would be 
counted as an error in our evaluations because the 
metaphor itself is not related to governance. In ex-
ample 8, we have two errors. First, tea is strongly 
present in the topic aligned to the animal concept, 
causing the sentence to be incorrectly marked as 
source-relevant. Second, because our topic model 
operates at the level of individual words, it was 
unable to recognize that tea here is part of the 
fixed, governance-related phrase tea party. 7 
7 Evaluation 
7.1 Collecting Evaluation Data 
We collected a domain-specific corpus in each 
language.  We curated a set of news websites and 
governance-relevant blogs in English and Spanish 
and then collected data from these websites over 
the course of several months. For each language, 
we ran our system over this corpus (all steps in 
                                                          
7 an American political movement 
62
Section 5), produced a set of linguistic metaphors 
for each topic-aligned source concept (the target 
concept was always governance), and ranked them 
by the final score (Section 4.4). Below, we will 
refer to the set of all linguistic metaphors sharing 
the same source and target concept as a conceptual 
metaphor. 
7.2 Simple Evaluation 
For this evaluation, we selected the top five exam-
ples for each conceptual metaphor.  If the same 
sentence was selected by multiple conceptual met-
aphors, it was kept for only the highest scoring 
one.  We then added enough of the highest-ranked 
unselected metaphors to create a full set of 300. 
We then added random sentences from the corpus 
that were not selected as metaphorical by the sys-
tem to bring the total to 600.  Our Spanish annota-
tors were unavailable at the time this evaluation 
took place, so we are only able to report results for 
English in this case. 
For each of these instances, two annotators 
were asked the question, ?Is there a metaphor 
about governance in this example?? These annota-
tors had previous experience in identifying meta-
phors for this study, both by searching manually in 
online texts and evaluating previous versions of 
our system.  Over time we have given them feed-
back on what does and does not constitute a meta-
phor.  In this case, the annotators were given 
neither the system's concept-word association an-
notations nor the source concept associated with 
the instance.  In one way, the evaluation was gen-
erous, because any metaphor in the extracted sen-
tence would benefit precision even if it was not the 
metaphor found by our system. On the other hand, 
the same is true for the random sentences; while 
the system will only extract metaphors with source 
concepts in our list, the annotators had no such 
restriction. This causes the recall score to suffer.  
The annotation task was difficult, with a  -score of 
0.48.  The resulting scores are given in Table 3.   
The examples given in Section 5 illustrate the error 
classes found among the false positives identified 
by the human annotators. There are many cases 
where the source-concept associated terms are used 
literally rather than metaphorically, and many cas-
es where the system-found metaphor is not about 
governance.  Some text processing issues, such as 
a bug in our sentence breaking script, as well as the 
noisy nature of blog and blog comment input, 
caused some of the examples to be difficult to in-
terpret or evaluate.  
 
Annotator Precision ?Recall? F Kappa 
1 
2 
65 
43 
67 
60 
66 
50 
0.48 
Mean 54 64 59  
Table 3: Simple English Evaluation 
7.3 Stricter Evaluation 
Common Experimental Setup 
We did a second evaluation of both English and 
Spanish using a different paradigm.  For each lan-
guage, we selected the 250 highest-ranked linguis-
tic metaphor instances in the corpus.  Subjects on 
Amazon Mechanical Turk were shown instances 
with the system-predicted concept-associated 
words highlighted and asked if the highlighted 
words were being used metaphorically (options 
were yes and no).  Each subject was randomly 
asked about roughly a quarter of the data. 
 
We paid the subjects $10 per hour.  We added 
catch trial sentences which asked the subject to 
simply answer yes or no as a way of excluding 
those not actually reading the sentences.  Subjects 
answering these questions incorrectly were exclud-
ed (17 in English, 25 in Spanish).  
We defined the metaphoricity of an instance to 
be the fraction of subjects who answered yes for 
that instance. We define the metaphoricity of a 
conceptual metaphor as the average metaphoricity 
of its groundings among the instances in this eval-
uation set.  
 
  
63
English Results 
We restricted our subjects to those claiming to 
be native English speakers who had IP addresses 
within the U.S. and had 115 participants.  The ex-
amples were grouped into 66 conceptual meta-
phors. The mean metaphoricity of instances was 
0.41 (standard deviation=0.33).  The mean meta-
phoricity of the conceptual metaphors (Figure 4), 
was 0.39 (SD=0.26).  Although there was wide 
variance in metaphoricity across conceptual meta-
phors, it appears likely that most of the conceptual 
metaphors discovered by the system are correct: 
65% of the conceptual metaphors had metaphorici-
ty greater than 0.25, and 73% greater than 0.2. 
Given that many metaphors are conventional and 
difficult to detect in natural language (Lakoff and 
Johnson, 1980), it is possible that even in cases in 
which only a minority of subjects detected a meta-
phor, a metaphor nonetheless exists 
Spanish Results 
We restricted our subjects to those claiming to be 
native speakers of Mexican Spanish with IP ad-
dresses in the US (57) or Mexico (29).  The in-
stances were grouped into 52 conceptual meta-
phors.  The mean metaphoricity of instances was 
0.33 (SD=0.23) and for conceptual metaphors 
(Figure 4), 0.31 (SD=0.16). 60% of conceptual 
metaphors had metaphoricity greater than 0.25, and 
73% greater than 0.2.  That performance was only 
slightly lower than English is a positive indication 
of our method?s cross-linguistic potential. 
8 Discussion and Future Work 
We observed a number of problems with our ap-
proach which provide avenues for future research. 
8.1 Topics as Proxies of Primary Metaphor 
Concepts 
Many of the metaphors missed by our system were 
instances of primary metaphor, especially those 
involving movement and spatial position.  Our 
LDA approach is poorly suited to these because the 
source concepts are not well-characterized by word 
co-occurrence: words describing movement and 
spatial position do not have a strong tendency to 
co-occur with other such words, at least in Wik-
ipedia.  Augmenting our system with a separate 
 
 
 
 
Figure 4: Metaphoricity of Conceptual Metaphors for English (top) and Spanish (bottom) 
64
approach to primary metaphor would boost its per-
formance significantly. 
8.2 Topics as Proxies of Non-Primary Meta-
phor Concepts 
We found that most of our potential source con-
cepts did not correspond to any LDA topic. How-
ever, many of these, such as wild west, have fairly 
strong word co-occurrence patterns, so they plau-
sibly could be found by a different topic modeling 
algorithm.  There are two promising approaches 
here which could potentially be combined.  The 
first is to use a hierarchical LDA algorithm (Blei et 
al, 2003b) to allow concepts to align to topics with 
varying degrees of granularity, from the very gen-
eral (e.g. war) to the very specific (e.g. wild west).  
The second is to use constrained LDA approaches 
(Andrzejewski and Zhu, 2009; Hu et al, 2010) to 
attempt to force at least one topic to correspond to 
each of our seed concept lists.   
A different approach would leave behind seed 
lists entirely.  In our current approach, only about 
one third of the topics modeled by LDA are suc-
cessfully aligned with a source concept from our 
hand-made list.  However, some non-aligned LDA 
topics have properties similar to those that were 
chosen to represent source concepts.  For instance, 
the topic whose highest ranked terms are [institute, 
professor, engineering, degree] is comprised of a 
set of semantically coherent and concrete terms, 
and could be assigned a reasonably accurate label 
such as higher education.  If we were to choose 
LDA topics based on the terms? coherence and 
concreteness (and perhaps other relevant, measura-
ble properties), then assign a label using a method 
such as that in Mei et al (2007), we would be able 
to leverage more of the concepts in the LDA mod-
el. This would increase the recall of our system, 
and also reduce some of the confusion associated 
with incorrect labeling of concepts in linguistic and 
conceptual metaphors.  Applying Labeled LDA, as 
in Ramage et al (2009), would be a similar ap-
proach. 
8.3 Confusion of Literal and Metaphorical 
Usage of Source Concepts 
Another major problem was the confusion between 
literal and metaphorical usage of source terms.  
This is partly addressed by our document topics 
filter, but more sophisticated use of document con-
text for this purpose would be helpful.  A similar 
filter based on contexts across the test corpus 
might be useful. 
8.4 Fixed Expressions 
Some of our errors were due to frequent fixed 
phrases which included a word strongly associated 
with a source topic, like Tea Party.  Minimum de-
scription length (MDL) phrase-finding or similar 
techniques could be used to filter these out.  Initial 
experiments performed after the evaluations dis-
cussed above show promise in this regard. Using 
the MDL algorithm (Rissanen, 1978), we devel-
oped a list of likely multi-word expressions in the 
Wikipedia corpus.  We then concatenated these 
phrases in the Wikipedia corpus before LDA mod-
eling and in the test corpus before metaphor pre-
diction.  Though we did not have time to formally 
evaluate the results, a subjective analysis showed 
fewer of these fixed phrases appearing as indica-
tors of metaphor (as words in    or   ). 
8.5 Difficulty of Annotation 
A different method of presentation of metaphors to 
the subjects, for instance with annotations marking 
where in the sentence we believed metaphor to 
exist or with a suggestion of the source concept, 
may have improved agreement and perhaps the 
system?s evaluation score. 
8.6 Summary 
We have presented a technique for linguistic and 
conceptual metaphor discovery that is cross-
linguistically applicable and requires minimal lin-
guistic resources.  Our approach of looking for 
overlapping semantic concepts allows us to find 
metaphors of any syntactic structure.  The frame-
work of our metaphor discovery technique is flexi-
ble in its ability to incorporate a wide variety of 
source and target concepts. The only linguistic re-
sources the system requires are a corpus of gen-
eral-knowledge text adequate for topic modeling 
and a small set of seed word lists. We could im-
prove our system by applying new research in au-
tomatic topic modeling, by creating new filters and 
scoring mechanisms to discriminate between literal 
and figurative word usages, and by creating train-
ing data to allow us to automatically set certain 
system parameters.   
 
65
Acknowledgements 
Supported by the Intelligence Advanced Research Pro-
jects Activity (IARPA) via Department of Defense US 
Army Research Laboratory contract number W911NF-
12-C0-0023. The U.S. Government is authorized to 
reproduce and distribute reprints for Governmental pur-
poses notwithstanding any copyright annotation there-
on.  Disclaimer: The views and conclusions contained 
herein are those of the authors and should not be inter-
preted as necessarily representing the official policies or 
endorsements, either expressed or implied, of IARPA, 
DoD/ARL, or the U.S. Government.? 
References 
David Andrzejewski and Xiaojin Zhu. 2009. Latent Di-
richlet Allocation with Topic-in-Set Knowledge. In 
Proceedings of NAACL Workshop on Semi-
Supervised Learning for NLP. 
Collin Baker, Charles Fillmore, and John Lowe. 1998. 
The Berkeley FrameNet project. In Proceedings of 
COLING-ACL. 
Stephen Bethard, Vicky Tzuyin Lai and James H. Mar-
tin.  2009. Topic Model Analysis of Metaphor Fre-
quency for Psycholinguistic Stimuli.  .  In Proc. Of 
NAACL-HLT Workshop on Computational Ap-
proaches to Linguistic Creativity. 
Julia Birke and Anoop Sarkar. 2006. A Clustering Ap-
proach for the Nearly Unsupervised Recognition of 
Nonliteral Language. In Proceedings of EACL. 
David Blei, Thomas Griffiths, Michael Jordan, and 
Joshua Tenenbaum. 2003a. Hierarchical topic models 
and the nested Chinese restaurant process. In Pro-
ceedings of NIPS. 
David Blei, Andrew Ng, and Michael Jordan. 2003b. 
Latent Dirichlet Allocation. Journal of Machine 
Learning Research, 2003(3):993?1022. 
Dan Fass. 1991. met*: A Method for Discriminating 
Metonymy and Metaphor by Computer. Computa-
tional Linguistics, 17(1):49?90. 
Christine Fellbaum. 1998. WordNet: An Electronic Lex-
ical Database. MIT Press, Cambridge, MA. 
Matt Gegigan, John Bryant, Srini Narayanan, and 
Branimir Ciric. 2006. Catching Metaphors. In Pro-
ceedings of the 3rd Workshop on Scalable Natural 
Language Understanding. 
Joseph E. Grady. 1998. Foundations of meaning: Prima-
ry metaphors and primary scenes. UMI. 
Yuenin Hu, Jordan Boyd-Graber, and Brianna Satinoff. 
2010. Interactive Topic Modeling. In Proceedings of 
ACL. 
Saisuresh Krishnakumaran and Xiaojin Zhu. 2007. 
Hunting Elusive Metaphors Using Lexical Re-
sources. In Proceedings of the Workshop on Compu-
tational Approaches to Figurative Language. 
George Lakoff and Mark Johnson. 1980. Metaphors We 
Live By. University of Chicago. 
James H. Martin. 1994. MetaBank: A knowledge-base 
of metaphoric language convention. Computational 
Intelligence, 10(2):134?149. 
Zachary Mason. 2004. CorMet: A Computational, Cor-
pus-Based Conventional Metaphor Extraction Sys-
tem. Computational Linguistics, 30(1):23?44. 
Andrew Kachites McCallum. 2002. MALLET: A Ma-
chine Learning for Language Toolkit. 
http://mallet.cs.umass.edu. 
Qiaozhu Mei, Xuehua Shen, and Chengxiang Zhai.  
Automatic Labeling of Multinomial Topic Models.  
In Proceedings of KDD ?07.  2007. 
Wim Peters and Ivonne Peters. 2000. Lexicalised Sys-
tematic Polysemy in WordNet. In Proceedings of 
LREC. 
Daniel Ramage, David Hall, Ramesh Nallapati and 
Christopher D. Manning. 2009. Labeled LDA: A su-
pervised topic model for credit attribution in multi-
labeled corpora.  In Proceedings of EMNLP. 
Jorma Rissanen.  Modeling by shortest data description. 
Automatica 14:465-471. 
Ekaterina Shutova, Lin Sun, and Anna Korhonen. 2010. 
Metaphor Identification Using Noun and Verb Clus-
tering. In Proceedings of COLING. 
Ekaterina Shutova, Simone Teufel, and Anna Korhonen. 
2012. Statistical Metaphor Processing. Computation-
al Linguistics. Uncorrected proof. 
Ekaterina Shutova. 2010. Models of metaphor in NLP. 
In Proceedings of ACL. 
Joanna Thornborrow. 1993. Metaphors of security: a 
comparison of representation in defence discourse in 
post-cold-war France and Britain. Discource & Soci-
ety, 4(1):99?119 
 
 
66
