Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,
pages 1567?1578, Dublin, Ireland, August 23-29 2014.
The Wisdom of Minority: Unsupervised Slot Filling Validation based on
Multi-dimensional Truth-Finding
Dian Yu
1
, Hongzhao Huang
1
, Taylor Cassidy
2,3
, Heng Ji
1
Chi Wang
4
, Shi Zhi
4
, Jiawei Han
4
, Clare Voss
2
, Malik Magdon-Ismail
1
1
Computer Science Department, Rensselaer Polytechnic Institute
2
U.S. Army Research Lab
3
IBM T. J. Watson Research Center
4
Computer Science Department, Univerisity of Illinois at Urbana-Champaign
1
{yud2,huangh9,jih,magdon}@rpi.edu,
2,3
{taylor.cassidy.ctr,clare.r.voss.civ}@mail.mil
4
{chiwang1,shizhi2,hanj}@illinois.edu
Abstract
Information Extraction using multiple information sources and systems is beneficial due to multi-
source/system consolidation and challenging due to the resulting inconsistency and redundancy.
We integrate IE and truth-finding research and present a novel unsupervised multi-dimensional
truth finding framework which incorporates signals from multiple sources, multiple systems and
multiple pieces of evidence by knowledge graph construction through multi-layer deep linguistic
analysis. Experiments on the case study of Slot Filling Validation demonstrate that our approach
can find truths accurately (9.4% higher F-score than supervised methods) and efficiently (finding
90% truths with only one half the cost of a baseline without credibility estimation).
1 Introduction
Traditional Information Extraction (IE) techniques assess the ability to extract information from
individual documents in isolation. However, similar, complementary or conflicting information may
exist in multiple heterogeneous sources. We take the Slot Filling Validation (SFV) task of the NIST Text
Analysis Conference Knowledge Base Population (TAC-KBP) track (Ji et al., 2011) as a case study. The
Slot Filling (SF) task aims at collecting from a large-scale multi-source corpus the values (?slot fillers?)
for certain attributes (?slot types?) of a query entity, which is a person or some type of organization. KBP
2013 has defined 25 slot types for persons (per) (e.g., age, spouse, employing organization) and 16 slot
types for organizations (org) (e.g., founder, headquarters-location, and subsidiaries). Some slot types
take only a single slot filler (e.g., per:birthplace), whereas others take multiple slot fillers (e.g., org:top
employees).
We call a combination of query entity, slot type, and slot filler a claim. Along with each claim, each
system must provide the ID of a source document and one or more detailed context sentences as evidence
which supports the claim. A response (i.e., a claim, evidence pair) is correct if and only if the claim is
true and the evidence supports it.
Given the responses produced by multiple systems from multiple sources in the SF task, the goal of
the SFV task is to determine whether each response is true or false. Though it?s a promising line of
research, it raises two complications: (1) different information sources may generate claims that vary
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
1567
in trustability; and (2) a large-scale number of SF systems using different resources and algorithms may
generate erroneous, conflicting, redundant, complementary, ambiguously worded, or inter-dependent
claims from the same set of documents. Table 1 presents responses from four SF systems for the query
entity Ronnie James Dio and the slot type per:city of death. Systems A, B and D return Los Angeles
with different pieces of evidence
1
extracted from different information sources, though the evidence of
System D does not decisively support the claim. System C returns Atlantic City, which is neither true
nor supported by the corresponding evidence.
Such complications call for ?truth finding?: determining the veracity of multiple conflicting claims
from various sources and systems. We propose a novel unsupervised multi-dimensional truth finding
framework to study credibility perceptions in rich and wide contexts. It incorporates signals from
multiple sources and systems, using linguistic indicators derived from knowledge graphs constructed
from multiple evidences using multi-layer deep linguistic analysis. Experiments demonstrate that our
approach can find truths accurately (9.4% higher F-score than supervised methods) and efficiently (find
90% truths with only one half cost of a baseline without credibility estimation).
System Source Slot Filler Evidence
A Agence France-
Presse, News
Los Angeles The statement was confirmed by publicist Maureen O?Connor, who said Dio
died in Los Angeles.
B New York
Times, News
Los Angeles Ronnie James Dio, a singer with the heavy-metal bands Rainbow, Black
Sabbath and Dio, whose semioperatic vocal style and attachment to demonic
imagery made him a mainstay of the genre, died on Sunday in Los Angeles.
C Discussion Fo-
rum
Atlantic City Dio revealed last summer that he was suffering from stomach cancer shortly
after wrapping up a tour in Atlantic City.
D Associated
Press
Worldstream,
News
Los Angeles LOS ANGELES 2010-05-16 20:31:18 UTC Ronnie James Dio, the metal god
who replaced Ozzy Osbourne in Black Sabbath and later piloted the bands
Heaven, Hell and Dio, has died, according to his wife and manager.
Table 1: Conflicting responses across different SF systems and different sources (query entity = Ronnie
James Dio, slot type = per:city of death).
2 Related Work & Our Novel Contributions
Most previous SFV work (e.g., (Tamang and Ji, 2011; Li and Grishman, 2013)) focused on filtering
incorrect claims from multiple systems by simple heuristic rules, weighted voting, or costly supervised
learning to rank algorithms. We are the first to introduce the truth finding concept to this task.
The ?truth finding? problem has been studied in the data mining and database communities (e.g., (Yin
et al., 2008; Dong et al., 2009a; Dong et al., 2009b; Galland et al., 2010; Blanco et al., 2010; Pasternack
and Roth, 2010; Yin and Tan, 2011; Pasternack and Roth, 2011; Vydiswaran et al., 2011; Ge et al.,
2012; Zhao et al., 2012; Wang et al., 2012; Pasternack and Roth, 2013)). Compared with the previous
work, our truth finding problem is defined under a unique setting: each response consists of a claim and
supporting evidence, automatically generated from unstructured natural language texts by a SF system.
The judgement of a response concerns both the truth of the claim and whether the evidence supports
the claim. This has never been modeled before. We mine and exploit rich linguistic knowledge from
multiple lexical, syntactic and semantic levels from evidence sentences for truth finding. In addition,
previous truth finding work assumed most claims are likely to be true. However, most SF systems have
hit a performance ceiling of 35% F-measure, and false responses constitute the majority class (72.02%)
due to the imperfect algorithms as well as the inconsistencies of information sources. Furthermore,
certain truths might only be discovered by a minority of good systems or from a few good sources. For
example, 62% of the true responses are produced only by 1 or 2 of the 18 SF systems.
1
Hereafter, we refer to ?pieces of evidence? with the shorthand ?evidences?. Note that SF systems may include multiple
sentences as ?evidence? within their responses.
1568
r1 
      Response 
<Claim, Evidence> 
t1 
t2 
System 
s1 
r2 
r3 
s2 
Source 
t3 
r4 t4 
s3 
r5 
Figure 1: Heterogeneous networks for MTM.
3 MTM: A Multi-dimensional Truth-Finding Model
MTM Construction
A response is trustworthy if its claim is true and its evidence supports the claim. A trusted
source always supports true claims by giving convincing evidence, and a good system tends to extract
trustworthy responses from trusted sources. We propose a multi-dimensional truth-finding model (MTM)
to incorporate and compute multi-dimensional credibility scores.
Consider a set of responses R = {r
1
, . . . , r
m
} extracted from a set of sources S = {s
1
, . . . , s
n
} and
provided by a set of systems T = {t
1
, . . . , t
l
}. A heterogeneous network is constructed as shown in
Fig. 1. Let weight matrices be W
rs
m?n
= {w
rs
ij
} and W
rt
m?l
= {w
rt
ik
}. A link w
rs
ij
= 1 is generated
between r
i
and s
j
when response r
i
is extracted from source s
j
, and a link w
rt
ik
= 1 is generated between
r
i
and t
k
when response r
i
is provided by system t
k
.
Credibility Initialization
Each source is represented as a combination of publication venue and genre. The credibility scores
of sources S are initialized uniformly as
1
n
, where n is the number of sources. Given the set of systems
T = {t
1
, . . . , t
l
}, we initialize their credibility scores c
0
(t) based on their interactions on the predicted
responses. Suppose each system t
i
generates a set of responses R
t
i
. The similarity between two systems
t
i
and t
j
is defined as similarity(t
i
, t
j
) =
|R
t
i
?R
t
j
|
log (|R
t
i
|)+log (|R
t
j
|)
(Mihalcea, 2004). Then we construct a
weighted undirected graph G = ?T,E?, where T (G) = {t
1
, . . . , t
l
} and E(G) = {?t
i
, t
j
?}, ?t
i
, t
j
? =
similarity(t
i
, t
j
), and apply the TextRank algorithm (Mihalcea, 2004) on G to obtain c
0
(t).
We got negative results by initializing system credibility scores uniformly. We also got negative results
by initializing system credibility scores using system metadata, such as the algorithms and resources the
system used at each step, its previous performance in benchmark tests, and the confidence values it
produced for its responses. We found the quality of an SF system depends on many different resources
instead of any dominant one. For example, an SF system using a better dependency parser does not
necessarily produce more truths. In addition, many systems are actively being improved, rendering
previous benchmark results unreliable. Furthermore, most SF systems still lack reliable confidence
estimation.
The initialization of the credibility scores for responses relies on deep linguistic analysis of the
evidence sentences and the exploitation of semantic clues, which will be described in Section 4.
Credibility Propagation
1569
We explore the following heuristics in MTM.
HEURISTIC 1: A response is more likely to be true if derived from many trustworthy sources. A source
is more likely to be trustworthy if many responses derived from it are true.
HEURISTIC 2: A response is more likely to be true if it is extracted by many trustworthy systems. A
system is more likely to be trustworthy if many responses generated by it are true.
Based on these two heuristics we design the following credibility propagation approach to mutually
reinforce the trustworthiness of linked objects in MTM.
By extension of Co-HITS (Deng et al., 2009), designed for bipartite graphs, we develop a propagation
method to handle heterogeneous networks with three types of objects: source, response and system. Let
the weight matrices beW
rs
(between responses and sources) andW
rt
(between responses and systems),
and their transposes beW
sr
andW
tr
. We can obtain the transition probability that vertex s
i
in S reaches
vertex r
j
in R at the next iteration, which can be formally defined as a normalized weight p
sr
ij
=
w
sr
ij?
k
w
sr
ik
such that
?
r
j
?R
p
sr
ij
= 1. We compute the transition probabilities p
rs
ji
, p
rt
jk
and p
tr
kj
in an analogous
fashion.
Given the initial credibility scores c
0
(r), c
0
(s) and c
0
(t), we aim to obtain the refined credibility scores
c(r), c(s) and c(t) for responses, sources, and systems, respectively. Starting with sources, the update
process considers both the initial score c
0
(s) and the propagation from connected responses, which we
formulated as:
c(s
i
) = (1? ?
rs
)c
0
(s
i
) + ?
rs
?
r
j
?R
p
rs
ji
c(r
j
) (1)
Similarly, the propagation from responses to systems is formulated as:
c(t
k
) = (1? ?
rt
)c
0
(t
k
) + ?
rt
?
r
j
?R
p
rt
jk
c(r
j
) (2)
Each response?s score c(r
j
) is influenced by both linked sources and systems:
c(r
j
) = (1? ?
sr
? ?
tr
)c
0
(r
j
) + ?
sr
?
s
i
?S
p
sr
ij
c(s
i
) + ?
tr
?
t
k
?T
p
tr
kj
c(t
k
) (3)
where ?
rs
, ?
rt
, ?
sr
and ?
tr
? [0, 1]. These parameters control the preference for the propagated over
initial score for every type of random walk link. The larger they are, the more we rely on link structure
2
.
The propagation algorithm converges (10 iterations in our experimental settings) and a similar theoretical
proof to HITS (Peserico and Pretto, 2009) can be constructed. Algorithm 1 summarizes MTM.
4 Response Credibility Initialization
Each evidence along with a claim is expressed as a few natural language sentences that include the query
entity and the slot filler, along with semantic content to support the claim. We analyze the evidence of
each response in order to initialize that response?s credibility score. This is done using heuristic rules
defined in terms of the binary outputs of various linguistic indicators (Section 4.1).
4.1 Linguistic Indicators
We encode linguistic indicators based on deep linguistic knowledge acquisition and use them to
determine whether responses provide supporting clues or carry negative indications (Section 4.3). These
indicators make use of linguistic features on varying levels - surface form, sentential syntax, semantics,
and pragmatics - and are defined in terms of knowledge graphs (Section 4.2). We define a heuristic rule
for each slot type in terms of the binary-valued linguistic indicator outputs to yield a single binary value
(1 or 0) for each response. If a response?s linguistic indicator value is 1, the credibility score of a response
is initialized at 1.0, and 0.5 otherwise.
2
We set ?
rs
= 0.9, ?
sr
= 0.1, ?
rt
= 0.3 and ?
tr
= 0.2, optimized from a development set. See Section 5.1.
1570
Input: A set of responses (R), sources (S) and systems (T ).
Output: Credibility scores (c(r)) for R.
1: Initialize the credibility scores c
0
(s) for S as c
0
(s
i
) =
1
|S|
;
2: Use TextRank to compute initial credibility scores c
0
(t) for T ;
3: Initialize the credibility scores c
0
(r) using linguistic indicators (Section 4);
4: Construct heterogeneous networks across R, S and T ;
5: k ? 0, diff? 10e6;
6: while k < MaxIteration and diff > MinThreshold do
7: Use Eq. (1) to compute c
k+1
(s);
8: Use Eq. (2) to compute c
k+1
(t);
9: Use Eq. (3) to compute c
k+1
(r);
10: Normalize c
k+1
(s), c
k+1
(t), and c
k+1
(r);
11: diff?
?
(|c
k+1
(r)? c
k
(r)|);
12: k ? k + 1
13: end while
Algorithm 1:Multi-dimensional Truth-Finding.
4.2 Knowledge Graph Construction
A semantically rich knowledge graph is constructed that links a query entity, all of its relevant slot
filler nodes, and nodes for other intermediate elements excerpted from evidence sentences. There is one
knowledge graph per sentence.
Fig. 2 shows a subregion of the knowledge graph built from the sentence: ?Mays, 50, died in his sleep
at his Tampa home the morning of June 28.?. It supports 3 claims: [Mays, per: city of death, Tampa],
[Mays, per: date of death, 06/28/2009] and [Mays, per: age, 50].
Formally, a knowledge graph is an annotated graph of entity mentions, phrases and their links. It must
contain one query entity node and one or more slot filler nodes. The annotation of a node includes its
entity type, subtype, mention type, referent entities, and semantic category (though not every node has
each type of annotation). The annotation of a link includes a dependency label and/or a semantic relation
between the two linked nodes.
The knowledge graph is constructed using the following procedure. First, we annotate the evidence
text using dependency parsing (Marneffe et al., 2006) and Information Extraction (entity, relation and
event) (Li et al., 2013; Li and Ji, 2014). Two nodes are linked if they are deemed related by one of the
annotation methods (e.g., [Mays, 50] is labeled with the dependency type amod, and [home, Tampa] is
labeled with the semantic relation located in). The annotation output is often in terms of syntactic heads.
Thus, we extend the boundaries of entity, time, and value mentions (e.g., people?s titles) to include an
entire phrase where possible. We then enrich each node with annotation for entity type, subtype and
mention type. Entity type and subtype refer to the role played by the entity in the world, the latter being
more fine-grained, whereas mention type is syntactic in nature (it may be pronoun, nominal, or proper
name). For example, ?Tampa? in Fig. 2 is annotated as a Geopolitical (entity type) Population-Center
(subtype) Name (mention type) mention. Every time expression node is annotated with its normalized
reference date (e.g., ?June, 28? in Fig. 2 is normalized as ?06/28/2009?).
Second, we perform co-reference resolution, which introduces implicit links between nodes that refer
to the same entity. Thus, an entity mention that is a nominal or pronoun will often be co-referentially
linked to a mention of a proper name. This is important because many queries and slot fillers are
expressed only as nominal mentions or pronouns in evidence sentences, their canonical form appearing
elsewhere in the document.
Finally, we address the fact that a given relation type may be expressed in a variety of ways. For
example, ?the face of ? indicates the membership relation in the following sentence: ?Jennifer Dunn was
the face of the Washington state Republican Party for more than two decades.? We mined a large
1571
Mays 
had 
died 
sleep 
his 
home 
Tampa 
50 
June,28 
amod 
nsubj 
aux 
prep_in 
poss 
prep_at 
prep_of 
nn 
poss 
  located_in 
{PER.Individual, NAM, Billy Mays} 
?Query? 
{NUM } 
?Per:age? 
{Death-Trigger} 
{PER.Individual.PRO, Mays} 
{GPE.Population-Center.NAM, FL-USA} 
? Per:place_of_death? 
{FAC.Building-Grounds.NOM} 
{06/28/2009, TIME-WITHIN}  
? per:date_of_death? 
Figure 2: Knowledge Graph Example.
number of trigger phrases for each slot type by mapping various knowledge bases, including Wikipedia
Infoboxes, Freebase (Bollacker et al., 2008), DBPedia (Auer et al., 2007) and YAGO (Suchanek et
al., 2007), into the Gigaword corpus
3
and Wikipedia articles via distant supervision (Mintz et al.,
2009)
4
. Each intermediate node in the knowledge graph that matches a trigger phrase is then assigned a
corresponding semantic category. For example, ?died? in Fig. 2 is labeled a Death-Trigger.
4.3 Knowledge Graph-Based Verification
We design linguistic indicators in terms of the properties of nodes and paths that are likely to be bear on
the response?s veracity. Formally, a path consists of the list of nodes and links that must be traversed
along a route from a query node to a slot filler node.
Node indicators contribute information about a query entity or slot filler node in isolation, that
may bear on the trustworthiness of the containing evidence sentence. For instance, a slot filler for the
per:date of birth slot type must be a time expression.
Node Indicators
1. Surface: Whether the slot filler includes stop words; whether it is lower cased but appears in news.
These serve as negative indicators.
2. Entity type, subtype and mention type: For example, the slot fillers for ?org:top employees? must be
person names; and fillers for ?org:website? must match the url format. Besides the entity extraction
system, we also exploited the entity attributes mined by the NELL system (Carlson et al., 2010)
from the KBP source corpus.
Each path contains syntactic and/or semantic relational information that may shed light on the manner
in which the query entity and slot filler are related, based on dependency parser output, IE output,
and trigger phrase labeling. Path indicators are used to define properties of the context in which
which query-entity and slot-filler are related in an evidence sentence. For example, whether the path
3
http://catalog.ldc.upenn.edu/LDC2011T07
4
Under the distant supervision assumption, sentences that appear to mention both entities in a binary relation contained in
the knowledge base were assumed to express that relation.
1572
associated with a claim about an organization?s top employee includes a title commonly associated with
decision-making power can be roughly represented using the trigger phrases indicator.
Path Indicators
1. Trigger phrases: Whether the path includes any trigger phrases as described in Section 4.2.
2. Relations and events: Whether the path includes semantic relations or events indicative of the slot
type. For example, a ?Start-Position? event indicates a person becomes a ?member? or ?employee?
of an organization.
3. Path length: Usually the length of the dependency path connecting a query node and a slot filler
node is within a certain range for a given slot type. For example, the path for ?per:title? is usually
no longer than 1. A long dependency path between the query entity and slot filler indicates a lack
of a relationship. In the following evidence sentence, which does not entail the ?per:religion?
relation between ?His? and the religion ?Muslim?, there is a long path (?his-poss-moment-nsubj-
came-advcl-seized-militant-acmod-Muslim?): ?His most noticeable moment in the public eye came
in 1979, when Muslim militants in Iran seized the U.S. Embassy and took the Americans stationed
there hostage.?.
Detecting and making use of interdependencies among various claims is another unique challenge in
SFV. After initial response credibility scores are calculated by combining linguistic indicator values, we
identify responses that have potentially conflicting or potentially supporting slot-filler candidates. For
such responses, their credibility scores are changed in accordance with the binary values returned by the
following indicators.
Interdependent Claims Indicators
1. Conflicting slot fillers: When fillers for two claims with the same query entity and slot type appear
in the same evidence sentence, we apply an additional heuristic rule designed for the slot type in
question. For example, the following evidence sentence indicates that compared to ?Cathleen P.
Black?, ?Susan K. Reed? is more likely to be in a ?org:top employees/members? relation with ?The
Oprah Magazine? due to the latter pair?s shorter dependency path: ?Hearst Magazine?s President
Cathleen P. Black has appointed Susan K. Reed as editor-in-chief of the U.S. edition of The
Oprah Magazine.?. The credibility scores are accordingly changed (or kept at) 0.5 for responses
associated with the former claim, and 1.0 for those associated with the latter.
2. Inter-dependent slot types: Many slot types are inter-dependent, such as ?per:title? and
?per:employee of ?, and various family slots. After determining initial credibility scores for each
response, we check whether evidence exists for any implied claims. For example, given initial
credibility scores of 1.0 for two responses supporting the claims that (1)?David? is ?per:children?
of ?Carolyn Goodman? and (2)?Andrew? is ?per:sibling? of ?David?, we check for any responses
supporting the claim that (3)?Andrew? is ?per:children? of ?Carolyn Goodman?, and set their
credibility scores to 1.0. For example, a response supporting this claim included the evidence
sentence, ?Dr. Carolyn Goodman, her husband, Robert, and their son, David, said goodbye to
David?s brother, Andrew.?.
5 Experimental Results
This section presents the experiment results and analysis of our approach.
5.1 Data
The data set we use is from the TAC-KBP2013 Slot Filling Validation (SFV) task, which consists of the
merged responses returned by 52 runs (regarded as systems in MTM) from 18 teams submitted to the Slot
1573
Methods Precision Recall F-measure Accuracy Mean Average Precision
1.Random 28.64% 50.48% 36.54% 50.54% 34%
2.Voting 42.16% 70.18% 52.68% 62.54% 62%
3.Linguistic Indicators 50.24% 70.69% 58.73% 72.29% 60%
4.SVM (3 + System + Source) 56.59% 48.72% 52.36% 75.86% 56%
5.MTM (3 + System + Source) 53.94% 72.11% 61.72% 81.57% 70%
Table 2: Overall Performance Comparison.
Filling (SF) task. The source collection has 1,000,257 newswire documents, 999,999 web documents
and 99,063 discussion forum posts, which results in 10 different sources (combinations of publication
venues and genres) in our experiment. There are 100 queries: 50 person and 50 organization entities.
After removing redundant responses within each single system run, we use 45,950 unique responses as
the input to truth-finding. Linguistic Data Consortium (LDC) human annotators manually assessed all
of these responses and produced 12,844 unique responses as ground truth. In order to compare with
state-of-the-art supervised learning methods for SFV (Tamang and Ji, 2011; Li and Grishman, 2013), we
trained a SVMs classifier
5
as a counterpart, incorporating the same set of linguistic indicators, sources
and systems as features. We picked 10% (every 10th line) to compose the development set for MTM and
the training set for the SVMs. The rest is used for blind test.
5.2 Overall Performance
Table 2 shows the overall performance of various truth finding methods on judging each response as true
or false. MTM achieves promising results and even outperforms supervised learning approach. Table 3
presents some examples ranked at the top and the bottom based on the credibility scores produced by
MTM.
We can see that majority voting across systems performs much better than random assessment, but its
accuracy is still low. For example, the true claim T5 was extracted by only one system because most
systems mistakenly identified ?Briton Stuart Rose? as a person name. In comparison, MTM obtained
much better accuracy by also incorporating multiple dimensions of source and evidence information.
Method 3 using linguistic indicators alone, already achieved promising results. For example, many
claims are judged as truths through trigger phrases (T1 and T5), event extraction (T2), coreference (T4),
and node type indicators (T3). On the other hand, many claims are correctly judged as false because
their evidence sentences did not include the slot filler (F1, F4, F5) or valid knowledge paths to connect
the query entity and the slot filler (F2, F3). The performance gain (2.99% F-score) from Method 3 to
Method 5 shows the need for incorporating system and source dimensions. For example, most truths are
from news while many false claims are from newsgroups and discussion forum posts (F1, F2, F5).
The SVMs model got very low recall because of the following two reasons: (1) It ignored the inter-
dependency between multiple dimensions; (2) the negative instances are dominant in the training data,
so the model is biased towards labeling responses as false.
5.3 Truth Finding Efficiency
Table 3 shows that some truths (T1) are produced from low-ranked systems whereas some false responses
from high-ranked systems (F1, F2). Note that systems are ranked by their performance in KBP SF task.
In order to find all the truths, human assessors need to go through all the responses returned by multiple
systems. This process was proven very tedious and costly (Ji et al., 2010; Tamang and Ji, 2011).
Our MTM approach can expedite this process by ranking responses based on their credibility scores
and asking human to assess the responses with high credibility first. Traditionally, when human assess
responses, they follow an alphabetical order or system IDs in a ?passive learning? style. This is set as
our baseline. For comparison, we also present the results using only linguistic indicators, using voting
in which the responses which get more votes across systems are assessed first, and the oracle method
assessing all correct responses first. Table 2 shows our model can successfully rank trustworthy responses
at high positions compared with other approaches.
5
We used the LIBSVM toolkit (Chang and Lin, 2011) with Gaussian radial basis function kernel.
1574
Response Ranked by MTM
Source
System
Rank
Claim
Evidence
Query Entity Slot Type Slot Filler
Top
Truths
T1 China
Banking
Regulatory
Commission
org:top
member-
s/employees
Liu
Mingkang
Liu Mingkang, the chairman of
the China Banking Regulatory
Commission
Central
News
Agency
of Taiwan
News
News 15
T2 Galleon
Group
org:founded
by
Raj
Rajaratnam
Galleon Group, founded by bil-
lionaire Raj Rajaratnam
New York
Times
News 9
T3 Mike Penner per:age 52 L.A. Times Sportswriter Mike
Penner, 52, Dies
New York
Times
News 1
T4 China
Banking
Regulatory
Commission
org:alternate
names
CBRC ...China Banking Regulatory Com-
mission said in the notice. The five
banks ... according to CBRC.
Xinhua,
News
News 5
T5 Stuart Rose per:origin Briton Bolland, 50, will replace Briton
Stuart Rose at the start of 2010.
Agence
France-
Presse
News 3
Bottom
False
Claims
F1 American
Association
for the Ad-
vancement of
Science
org:top
members
employees
Freedman erica.html &gt; American Library
Association, President: Maurice
Freedman &lt; http://www.aft.org
&gt; American Federation of
Teachers ...
Google Newsgroup4
F2 Jade Goody per:origin Britain because Jade Goody?s the only
person to ever I love Britain
Discussion Forum 3
F3 Don Hewitt per:spouse Swap ...whether ?Wife Swap? on ABC
or ?Jon &amp; Kate? on TLC
New York
Times
News 7
F4 Council of
Mortgage
Lenders
org:website www.cml.org.ukme purchases in the U.K. jumped
by 16 percent in April, suggesting
the property market slump may
have bottomed out
Associated
Press
World-
stream
News 18
F5 Don Hewitt per:alternate
names
Hewitt M-
chen
US DoMIna THOMPson LACtaTe
haVeD [3866 words]
Google Newsgroup13
Table 3: Top and Bottom Response Examples Ranked by MTM.
Fig. 3 summarizes the results from the above 6 approaches. The common end point of all curves
represents the cost and benefit of assessing all system responses. We can see that the baseline is very
inefficient at finding the truths. If we employ linguistic indicators, the process can be dramatically
expedited. MTM provides further significant gains, with performance close to the Oracle. With only half
the cost of the baseline, MTM can already find 90% truths.
5.4 Enhance Individual SF Systems
Finally, as a by-product, our MTM approach can also be exploited to validate the responses from each
individual SF system based on their credibility scores. For fair comparison with the official KBP
evaluation, we use the same ground-truth in KBP2013 and standard precision, recall and F-measure
metrics as defined in (Ji et al., 2011). To increase the chance of including truths which may be particularly
difficult for a system to find, LDC prepared a manual key which was assessed and included in the final
ground truth. According to the SF evaluation setting, F-measure is computed based on the number of
unique true claims. After removing redundancy across multiple systems, there are 1,468 unique true
claims. The cutoff criteria for determining whether a response is true or not was optimized from the
development set.
Fig. 4 presents the F-measure scores of the best run from each individual SF system. We can see that
our MTM approach consistently improves the performance of almost all SF systems, in an absolute gain
range of [-1.22%, 5.70%]. It promotes state-of-the-art SF performance from 33.51% to 35.70%. Our
MTM approach provides more gains to SF systems which mainly rely on lexical or syntactic patterns
than other systems using distant supervision or logic rules.
1575
1 
0 10000 20000 30000 40000
0
2000
4000
6000
8000
10000
12000
14000
13 2
4
5
#tr
uth
s
 6 Oracle 
 5 MTM
 4 SVM
 3 Linguistic Indicator
 2 Voting
 1 Baseline
#total responses
6
Figure 3: Truth Finding Efficiency.
0 2 4 6 8 10 12 14 16 18 20
0
5
10
15
20
25
30
35
F-m
es
au
re 
(%
)
System
 Before
 After
Figure 4: Impact on Individual SF Systems.
1576
6 Conclusions and Future Work
Truth finding has received attention from both Natural Language Processing (NLP) and Data Mining
communities. NLP work has mostly explored linguistic analysis of the content, while Data Mining
work proposed advanced models in resolving conflict information from multiple sources. They have
relative strengths and weaknesses. In this paper we leverage the strengths of these two distinct,
but complementary research paradigms and propose a novel unsupervised multi-dimensional truth-
finding framework incorporating signals both from multiple sources, multiple systems and multiple
evidences based on knowledge graph construction with multi-layer linguistic analysis. Experiments on
a challenging SFV task demonstrated that this framework can find high-quality truths efficiently. In the
future we will focus on exploring more inter-dependencies among responses such as temporal and causal
relations.
Acknowledgments
This work was supported by the U.S. Army Research Laboratory under Cooperative Agreement
No. W911NF-09-2-0053 (NS-CTA), the U.S. Army Research Office under Cooperative Agreement
No. W911NF-13-1-0193, U.S. National Science Foundation grants IIS-0953149, CNS-0931975,
IIS-1017362, IIS-1320617, IIS-1354329, U.S. DARPA Award No. FA8750-13-2-0041 in the Deep
Exploration and Filtering of Text (DEFT) Program, IBM Faculty Award, Google Research Award,
DTRA, DHS and RPI faculty start-up grant. The views and conclusions contained in this document are
those of the authors and should not be interpreted as representing the official policies, either expressed
or implied, of the U.S. Government. The U.S. Government is authorized to reproduce and distribute
reprints for Government purposes notwithstanding any copyright notation here on.
References
S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, and Z. Ives. 2007. Dbpedia: A nucleus for a web of open data. In
Proc. the 6th International Semantic Web Conference.
L. Blanco, V. Crescenzi, P. Merialdo, and P. Papotti. 2010. Probabilistic models to reconcile complex data
from inaccurate data sources. In Proc. Int. Conf. on Advanced Information Systems Engineering (CAiSE?10),
Hammamet, Tunisia, June.
K. Bollacker, R. Cook, and P. Tufts. 2008. Freebase: A shared database of structured general human knowledge.
In Proc. National Conference on Artificial Intelligence.
A. Carlson, J. Betteridge, B. Kisiel, B. Settles, Estevam R Hruschka Jr, and Tom M Mitchell. 2010. Toward an
architecture for never-ending language learning. In AAAI.
C. Chang and C. Lin. 2011. Libsvm: a library for support vector machines. ACM Transactions on Intelligent
Systems and Technology (TIST), 2(3):27.
H. Deng, M. R. Lyu, and I. King. 2009. A generalized co-hits algorithm and its application to bipartite graphs. In
Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,
KDD ?09, pages 239?248, New York, NY, USA. ACM.
X. L. Dong, L. Berti-Equille, and D. Srivastavas. 2009a. Integrating conflicting data: The role of source
dependence. In Proc. 2009 Int. Conf. Very Large Data Bases (VLDB?09), Lyon, France, Aug.
X. L. Dong, L. Berti-Equille, and D. Srivastavas. 2009b. Truth discovery and copying detection in a dynamic
world. In Proc. 2009 Int. Conf. Very Large Data Bases (VLDB?09), Lyon, France, Aug.
A. Galland, S. Abiteboul, A. Marian, and P. Senellart. 2010. Corroborating information from disagreeing views.
In Proc. ACM Int. Conf. on Web Search and Data Mining (WSDM?10), New York, NY, Feb.
L. Ge, J. Gao, X. Yu, W. Fan, and A. Zhang. 2012. Estimating local information trustworthiness via multi-
source joint matrix factorization. In Data Mining (ICDM), 2012 IEEE 12th International Conference on, pages
876?881. IEEE.
1577
H. Ji, R. Grishman, H. T. Dang, K. Griffitt, and J. Ellis. 2010. An overview of the tac2010 knowledge base
population track. In Proc. Text Analytics Conf. (TAC?10), Gaithersburg, Maryland, Nov.
H. Ji, R. Grishman, and H.T. Dang. 2011. Overview of the tac 2011 knowledge base population track. In Text
Analysis Conf. (TAC) 2011.
X. Li and R. Grishman. 2013. Confidence estimation for knowledge base population. In Proc. Recent Advances
in Natural Language Processing (RANLP).
Q. Li and H. Ji. 2014. Incremental joint extraction of entity mentions and relations.
Q. Li, H. Ji, and L. Huang. 2013. Joint event extraction via structured prediction with global features.
M. D. Marneffe, B. Maccartney, and C. D. Manning. 2006. Generating typed dependency parses from phrase
structure parses. In LREC, pages 449,454.
R. Mihalcea. 2004. Graph-based ranking algorithms for sentence extraction, applied to text summarization. In
Proc. ACL2004.
M. Mintz, S. Bills, R. Snow, and D. Jurafsky. 2009. Distant supervision for relation extraction without labeled
data. In Proc. ACL2009.
J. Pasternack and D. Roth. 2010. Knowing what to believe (when you already know something). In
Proceedings of the 23rd International Conference on Computational Linguistics, pages 877?885. Association
for Computational Linguistics.
J. Pasternack and D. Roth. 2011. Making better informed trust decisions with generalized fact-finding. In Proc.
2011 Int. Joint Conf. on Artificial Intelligence (IJCAI?11), Barcelona, Spain, July.
J. Pasternack and D. Roth. 2013. Latent credibility analysis. In Proc. WWW 2013.
E. Peserico and L. Pretto. 2009. Score and rank convergence of hits. In Proceedings of the 32nd international
ACM SIGIR conference on Research and development in information retrieval, pages 770?771. ACM.
Fabian M. Suchanek, Gjergji Kasneci, and Gerhard Weikum. 2007. Yago: A Core of Semantic Knowledge. In
16th international World Wide Web conference (WWW 2007), New York, NY, USA. ACM Press.
S. Tamang and H. Ji. 2011. Adding smarter systems instead of human annotators: Re-ranking for slot filling
system combination. In Proc. CIKM2011 Workshop on Search & Mining Entity-Relationship data, Glasgow,
Scotland, UK, Oct.
VG Vydiswaran, C.X. Zhai, and D. Roth. 2011. Content-driven trust propagation framework. In Proceedings
of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 974?982.
ACM.
D. Wang, L. Kaplan, H. Le, and T. Abdelzaher. 2012. On truth discovery in social sensing: A maximum likelihood
estimation approach. In Proc. ACM/IEEE Int. Conf. on Information Processing in Sensor Networks (IPSN?12),
pages 233?244, Beijing, China, April.
X. Yin and W. Tan. 2011. Semi-supervised truth discovery. In Proc. 2011 Int. World Wide Web Conf. (WWW?11),
Hyderabad, India, March.
X. Yin, J. Han, and P. S. Yu. 2008. Truth discovery with multiple conflicting information providers on the Web.
IEEE Trans. Knowledge and Data Engineering, 20:796?808.
B. Zhao, B. I. P. Rubinstein, J. Gemmell, and J. Han. 2012. A Bayesian approach to discovering truth from
conflicting sources for data integration. In Proc. 2012 Int. Conf. Very Large Data Bases (VLDB?12), Istanbul,
Turkey, Aug.
1578
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1083?1093,
Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational Linguistics
Resolving Entity Morphs in Censored Data
Hongzhao Huang1, Zhen Wen2, Dian Yu1, Heng Ji1,
Yizhou Sun3, Jiawei Han4, He Li5
1Computer Science Department and Linguistics Department,
Queens College and Graduate Center, City University of New York, New York, NY, USA
2IBM T. J. Watson Research Center, Hawthorne, NY, USA
3College of Computer and Information Science, Northeastern University, Boston, MA, USA
4Computer Science Department, Univerisity of Illinois at Urbana-Champaign, Urbana, IL, USA
5Admaster Inc., China
{hongzhaohuang1,yudiandoris1,hengjicuny1, liheact5}@gmail.com,
zhenwen@us.ibm.com2, yzsun@ccs.neu.edu3, hanj@illinois.edu4
Abstract
In some societies, internet users have to
create information morphs (e.g. ?Peace
West King? to refer to ?Bo Xilai?) to avoid
active censorship or achieve other com-
munication goals. In this paper we aim
to solve a new problem of resolving en-
tity morphs to their real targets. We ex-
ploit temporal constraints to collect cross-
source comparable corpora relevant to any
given morph query and identify target can-
didates. Then we propose various novel
similarity measurements including surface
features, meta-path based semantic fea-
tures and social correlation features and
combine them in a learning-to-rank frame-
work. Experimental results on Chinese
Sina Weibo data demonstrate that our ap-
proach is promising and significantly out-
performs baseline methods1.
1 Introduction
Language constantly evolves to maximize com-
municative success and expressive power in daily
social interactions. The proliferation of online so-
cial media significantly expedites this evolution,
as new phrases triggered by social events may be
disseminated rapidly in social media. To automati-
cally analyze such fast evolving language in social
media, new computational models are demanded.
In this paper, we focus on one particular lan-
guage evolution that creates new ways to commu-
nicate sensitive subjects because of the existence
of internet information censorship. We call this
1Some of the resources and open source programs devel-
oped in this work are made freely available for research pur-
pose at http://nlp.cs.qc.cuny.edu/Morphing.tar.gz
phenomenon information morph. For example,
when Chinese online users talk about the former
politician ?Bo Xilai?, they use a morph ?Peace
West King? instead, a historical figure four hun-
dreds years ago who governed the same region
as Bo. Morph can be considered as a special
case of alias used for hiding true entities in ma-
licious environment (Hsiung et al, 2005; Pantel,
2006). However, social network plays an impor-
tant role in generating morphs. Usually morphs
are generated by harvesting the collective wisdom
of the crowd to achieve certain communication
goals. Aside from the purpose of avoiding cen-
sorship, other motivations for using morph include
expressing sarcasm/irony, positive/negative senti-
ment or making descriptions more vivid toward
some entities or events. Table 1 presents the wide
range of cases that are used to create the morphs.
We can see that a morph can be either a regular
term with new meaning or a newly created term.
Morph Target Motivation
Peace West King Bo Xilai Sensitive
Blind Man Chen Guangcheng Sensitive
Miracle Brother Wang Yongping Irony
Kim Fat Kim Joing-il Negative
Kimchi Country South Korea Vivid
Table 1: Morph Examples and Motivations.
We believe that successful resolution of morphs
is a crucial step for automated understanding of
the fast evolving social media language, which
is important for social media marketing (Bar-
wise and Meehan, 2010). Another application
is to help common users without enough back-
ground/cultural knowledge to understand internet
language for their daily use. Furthermore, our ap-
proaches can also be applied for satire or other im-
plicit meaning recognition, as well as information
extraction (Bollegala et al, 2011).
1083
However, morph resolution in social media is
challenging due to the following reasons. First,
the sensitive real targets that exist in the same
data source under active censorship are often au-
tomatically filtered. Table 2 presents the distribu-
tions of some examples of morphs and their tar-
gets in English Twitter and Chinese Sina Weibo.
For example, the target ?Chen Guangcheng? only
appears once in Weibo. Thus, the co-occurrence
of a morph and its target is quite low in the vast
amount of information in social media. Second,
most morphs were not created based on pronunci-
ations, spellings or other encryptions of their origi-
nal targets. Instead, they were created according to
semantically related entities in historical and cul-
tural narratives (e.g. ?Peace West King? as morph
of ?Bo Xilai?) and thus very difficult to capture
based on typical lexical features. Third, tweets
from Twitter/Chinese Weibo are short (only up to
140 characters) and noisy, resulting in difficult ex-
traction of rich and accurate evidences due to the
lack of enough contexts.
 Frequency in  Twitter Frequency in  Weibo Morph Target Morph Target Morph Target Hu Ji Hu Jintao 1 3,864 2,611 71 Blind  Man Chen  Guangcheng 18 2,743 20,941 1 Baby Wen Jiabao 2238 2021 26,279 8  
Table 2: Distributions of Morph Examples
To the best of our knowledge, this is the first
work to use NLP and social network analysis tech-
niques to automatically resolve morphed informa-
tion. To address the above challenges, our paper
offers the following novel contributions.
? We detect target candidates by exploiting the
dynamics of the social media to extract tem-
poral distribution of entities, based on the as-
sumption that the popularity of an individ-
ual is correlated between censored and un-
censored text within a certain time window.
? Our approach builds and analyzes heteroge-
neous information networks from multiple
sources, such as Twitter, Sina Weibo and web
documents in formal genre (e.g. news) be-
cause a morph and its target tend to appear in
similar contexts.
? We propose two new similarity measures, as
well as integrating temporal information into
the similarity measures to generate global se-
mantic features.
? We model social user behaviors and use so-
cial correlation to assist in measuring seman-
tic similarities because the users who posted
a morph and its corresponding target tend to
share similar interests and opinions.
Our experiments demonstrate that the pro-
posed approach significantly outperforms tradi-
tional alias detection methods (Hsiung et al,
2005).
2 Approach Overview   Morph Query   Comparable Data Acquisition   
Target Candidate Ranking 
Target
Learning to Rank 
Semantic Features
Semantic Annotation and  Target Candidate Identification
Surface Features Social Features
Censored Data Uncensored Data
Figure 1: Overview of Morph Resolution
Given a morph query m, the goal of morph res-
olution is to find its real target. Figure 1 depicts
the general procedure of our approach. It consists
of two main sub-tasks:
? Target Candidate Identification: For each
m, discover a list of target candidates E =
{e1, e2, ..., eN}. First, relevant comparable
data sets that include m are retrieved. In
this paper we collect comparable censored
data from Weibo and uncensored data from
Twitter and Web documents such as news ar-
ticles. We then apply various annotations
such as word segmentation, part-of-speech
tagging, noun phrase chunking, name tagging
and event extraction to these data sets.
? Target Candidate Ranking: Rank the target
candidates in E. We explore various features
including surface, semantic and social fea-
tures, and incorporate them into a learning to
1084
rank framework. Finally, the top ranked can-
didate is produced as the resolved target.
3 Target Candidate Identification
The general goal of the first step is to identify a list
of target candidates for each morph query from the
comparable corpora including Sina Weibo, Chi-
nese News websites and English Twitter. How-
ever, obviously we cannot consider all of the
named entities in these sources as target candi-
dates due to the sheer volume of information. In
addition, morphs are not limited to named entity
forms. In order to narrow down the scope of tar-
get candidates, we propose a Temporal Distribu-
tion Assumption as follows. The intuition is that
a morph m and its real target e should have sim-
ilar temporal distributions in terms of their occur-
rences. Suppose the data sets are separated into Z
temporal slots (e.g. by day), the assumption can
be stated as:
Let Tm = {tm1, tm2, ..., tmZm} be the set of
temporal slots each morph m occurs, and Te =
{te1, te2, ..., teZe} be the set of slots a target can-
didate e occurs. Then e is considered as a target
candidate of m if and only if, for each tmi ? Tm
(i = 1, 2, ..., Zm), there exist a j ? {1, 2, ..., Ze}
such that tmi ? tej ? ?, where ? is a threshold
value (in this paper we set the threshold to 7 days,
which is optimized from a development set). For
comparison we also attempted topic modeling ap-
proach to detect target candidates, as shown in sec-
tion 5.3.
4 Target Candidate Ranking
Next, we propose a learning-to-rank framework to
rank target candidates based on various levels of
novel features based on surface, semantic and so-
cial analysis.
4.1 Surface Features
We first extract surface features between the
morph and the candidate based on measuring or-
thographic similarity measures which were com-
monly used in entity coreference resolution (e.g.
(Ng, 2010; Hsiung et al, 2005)). The measures
we use include ?string edit distance?, ?normalized
string edit distance? (Wagner and Fischer, 1974)
and ?longest common subsequence? (Hirschberg,
1977).
4.2 Semantic Features
4.2.1 Motivations
Fortunately, although a morph and its target may
have very different orthographic forms, they tend
to be embedded in similar semantic contexts
which involve similar topics and events. Figure 2
presents some example messages under censor-
ship (Weibo) and not under censorship (Twitter
and Chinese Daily). We can see that they include
similar topics, events (e.g., ?fell from power?,
?gang crackdown?, ?sing red songs?), and se-
mantic relations (e.g., family relations with ?Bo
Guagua?). Therefore if we can automatically ex-
tract and exploit these indicative semantic con-
texts, we can narrow down the real targets effec-
tively.
?Pe
ace W
est K
ingfr
om C
hong
qing
fell fr
om p
ower
, still
 nee
d to 
sing 
red s
ongs
?
?T
here
 is no
 diffe
renc
e be
twee
n tha
t 
guy?s
 plag
iarism
 and
 Buh
ou?s
gang
 
crack
down
.
?R
eme
mbe
r tha
t Buh
ousa
id tha
t his 
famil
y wa
s not
 rich 
at th
e pre
ss 
confe
renc
e a f
ew d
ays b
efore
 he 
fell fr
om p
ower
. His 
sonB
o 
Guag
uais 
supp
orted
 by h
is 
scho
larsh
ip.
?B
o Xila
i: ten
 thou
sand
 lette
rs of
 
accu
satio
n ha
ve be
en re
ceive
d du
ring 
Chon
gqing
gang
 crac
kdow
n.
?T
he w
ebpa
ge o
f ?Tia
nzeE
cono
mic 
Stud
y Ins
titute
?own
ed b
y the
 liber
al 
party
 has 
been
 clos
ed. T
his is
 the 
first 
affec
ted w
ebsit
e of 
the li
bera
l par
ty 
after
 Bo X
ilaife
ll from
 pow
er.
?B
o Xila
igave
 an e
xplan
ation
 abo
ut th
e 
sour
ce of
 hiss
on, B
o Gu
agua
?s 
tuitio
n.
?B
o Xila
iled C
hong
qing 
city l
eade
rs 
and 
40 d
istric
t and
 coun
ty pa
rty a
nd 
gove
rnme
nt lea
ders
 to si
ng re
d son
gs.
Weib
o(ce
nsore
d)
Twitt
er an
d Ch
inese
 New
s (un
cens
ored)
Figure 2: Cross-source Comparable Data Example
(each morph and target pair is shown in the same
color)
4.2.2 Information Network Construction
We define an information network as a directed
graph G = (V, E) with an object type mapping
function ? : V ? A and a link type mapping func-
tion ? : E ? R, where each object v ? V belongs
to one particular object type ?(v) ? A, each link
e ? E belongs to a particular relation ?(e) ? R.
If two links belong to the same relation type, then
they share the same starting object type as well as
the same ending object type. An information net-
work is homogeneous if and only if there is only
one type for both objects and links, and an infor-
mation network is heterogeneous when the objects
are from multiple distinct types or there exist more
than one type of links.
In order to construct the information networks
for morphs, we apply the Standford Chinese word
1085
segmenter with Chinese Penn Treebank segmen-
tation standard (Chang et al, 2008) and Stan-
ford part-of-speech tagger (Toutanova et al, 2003)
to process each sentence in the comparable data
sets. Then we apply a hierarchical Hidden Markov
Model (HMM) based Chinese lexical analyzer
ICTCLAS (Zhang et al, 2003) to extract named
entities, noun phrases and events.
We have also attempted using the results from
Dependency Parsing, Relation Extraction and
Event Extraction tools (Ji and Grishman, 2008)
to enrich the link types. Unfortunately the state-
of-the-art techniques for these tasks still perform
poorly on social media in terms of both accuracy
and coverage of important information, these so-
phisticated semantic links all produced negative
impact on the target ranking performance. There-
fore we limited the types of vertices into: Morph
(M), Entity(E), which includes target candidates,
Event (EV), and Non-Entity Noun Phrases (NP);
and used co-occurrence as the edge type. We ex-
tract entities, events, and non-entity noun phrases
that occur in more than one tweet as neighbors.
And for two vertices xi and xj , the weight wij
of their edge is the frequency they co-occur to-
gether within the tweets. A network schema of
such networks is shown in Figure 3. Figure 4
M
E NP
EV
Figure 3: Network Schema of Morph-Related Het-
erogeneous Information Network
presents an example of a heterogeneous informa-
tion network from the motivation examples fol-
lowing the above network schema, which connects
the morphs ?Peace West King?, ?Buhou? and their
corresponding target ?Bo Xilai?.
4.2.3 Meta-Path-Based Semantic Similarity
Measurements
Given the constructed network, a straightforward
solution for finding the target for a morph is to use
link-based similarity search. However, now ob-
jects are linked to different types of neighbors, if
all neighbors are treated as the same, it may cause
information loss problems. For example, the en-
tity ??? (Chongqing)? is a very important aspect
characterizing the politician ????(Bo Xilai)?
Ga
ng 
Cra
ckd
ow
n 
Fel
l Fr
om
 
Pow
er
Ch
ong
qin
g
Sin
g R
ed 
Son
gs
Bu
hou
Pea
ce 
We
st 
Kin
g
Bo
 Xil
ai
Bo
 Gu
agu
a
Ent
ity
Ent
ity
Ent
ity
Eve
nt
Eve
nt
Eve
nt
Mo
rph
Mo
rph
Figure 4: Example of Morph-Related Heteroge-
neous Information Network
since he governed it, and if a morph m which is
also highly correlated with ??? (Chongqing)?, it
is very likely that ?Bo Xilai? is the real target ofm.
Therefore, the semantic features generated from
neighbors such as the entity ??? (Chongqing)?
should be treated differently from other types of
neighbors such as ???(talented people)? .
In this work, we propose to measure the simi-
larity of two nodes over heterogeneous networks
as shown in Figure 3, by distinguishing neighbors
into three types according to the network schema
(i.e. entities, events, non-entity noun phrases). We
then adopt meta-path-based similarity measures
(Sun et al, 2011a; Sun et al, 2011b), which are
defined over heterogeneous networks to extract se-
mantic features. A meta-path is a path defined over
a network, and composed of a sequence of rela-
tions between different object types. For example,
as shown in Figure 3, a morph and its target can-
didate can be connected by three meta-paths, in-
cluding ?M - E - E?, ?M - EV - E?, and ?M - NP
- E?. Intuitively, each meta-path provides a unique
angle to measure how similar two objects are.
For the determined meta-paths, we extract se-
mantic features using the similarity measures pro-
posed in (Sun et al, 2011a; Hsiung et al, 2005).
We denote the neighbor sets of certain type for a
morph m and a target candidate e as ?(m) and
?(e), and a meta-path as P . We now list several
meta-path-based similarity measures below.
Common neighbors (CN). It measures the num-
ber of common neighbors that m and e share as
|?(m) ? ?(e)|.
Path count (PC). It measures the number of path
instances betweenm and e following meta-pathP .
Pairwise random walk (PRW). For a meta-
path P that can be decomposed into two shorter
1086
meta-paths with the same length P = (P1P2),
pairwise random walk measures the probabil-
ity of the pairwise random walk starting from
both m and e and reaching the same mid-
dle object. More formally, it is computed as?
(p1p2)?(P1P2) prob(p1)prob(p?12 ), where p?12 isthe inverse of p2.
Kullback-Leibler distance (KLD). For m and
e, the pairwise random walk probability of their
neighbors can be represented as two probability
vectors, then Kullback-Leibler distance (Hsiung
et al, 2005) can be used to compute sim(m, e).
Beyond the above similarity measures, we also
propose to use cosine-similarity-style normaliza-
tion method to modify common neighbor and pair-
wise random walk measures so that we can ensure
the morph node and the target candidate node are
strongly connected and also have similar popular-
ity. The modified algorithms penalize features in-
volved with the highly popular objects, since they
are more likely to have accidental interactions with
each other.
Normalized common neighbors (NCN). Nor-
malized common neighbors can be measured as
sim(m, e) = |?(m)??(e)|?
|?(m)|
?
|?(e)|
. It refines the simple
counting of common neighbors by avoiding bias
to highly visible or concentrated objects.
Pairwise random walk/cosine (PRW/cosine).
Pairwise random walk measures linkage weights
disproportionately with their visibility to their
neighbors, which may be too strong. Instead, we
propose to use a tamer normalization method as?
(p1p2)?(P1P2) f(p1)f(p?12 ), where.
f(p1) = count(m,x)??
x?? count(m,x)
,
f(p2) = count(e, x)??
x?? count(e, x)
,
and ? is the set of middle objects connecting the
decomposed meta-paths p1 and p?12 , count(y, x)
is the total number of paths between y and the mid-
dle object x, y could be m or e.
The above similarity measures can also be ap-
plied to homogeneous networks that do not differ-
entiate the neighbor types.
4.2.4 Global Semantic Feafure Generation
A morph tends to have higher temporal correlation
with its real target, and share more similar topics
compared to other irrelevant targets. Therefore,
we propose to incorporate temporal information
into similarity measures to generate global seman-
tic features.
Let T = t1 ? t2 ? ... ? tN be a set of temporal
slots (i.e. by day),E be the set of target candidates
for each morphm. Then for each ti ? T , and each
e ? E, the local semantic features simti(m, e)
is extracted based only on the information posted
within ti using one of the similarity measures in-
troduced in Section 4.2.3. Then we propose two
approaches to generate global semantic features.
The first approach is adding the similarity score
between m and e in each temporal slot to attain
the first set of global features:
simglobal sum(m, e) =
?
ti?T
simti(m, e).
The second method first normalizes the similarity
score in each temporal slot ti, them sum the nor-
malized scores to generate the second set of global
features, which can be calculated as
simglobal norm(m, e) =
?
ti?T
normti(m, e).
where normti(m, e) = simti (m,e)?e?E simti (m,e) .
4.2.5 Integrate Cross Source/Cross Genre
Information
Due to internet information censorship or surveil-
lance, users may need to use morphs to post sensi-
tive information. For example, the Chinese Weibo
message ?????,??????? (Already
put in prison, still need to serve Buhou?? include
a morph ?? (Buhou). In contrast, users are less
restricted in some other uncensored social media
such as Twitter. For example, the tweet from Twit-
ter ?...?????????????????...
(...call Bo Xilai?peace west king? or ?buhou?...)?
contains both the morph and the real target ??
? (Bo Xilai). Therefore, we propose to integrate
information from another source (e.g. Twitter) to
help resolution of sensitive morphs in Weibo.
Another difficulty from morph resolution in
micro-blogging is that tweets are only allowed to
contain maximum 140 characters with a lot of
noise and diverse topics. The shortness and di-
versity of tweets may limit the power of content
analysis for semantic feature extraction. However,
formal genres such as web documents are cleaner
and contain richer contexts, thus can provide more
topically related information. In this work, we also
exploit the background web documents from the
1087
embedded URLs in tweets to enrich information
network construction. After applying the same an-
notation techniques as tweets for uncensored data
sets, sentence-level co-occurrence relations are ex-
tracted and integrated into the network as shown in
Figure 3.
4.3 Social Features
It has been shown that there exist correlation be-
tween neighbors in social networks (Anagnos-
topoulos et al, 2008; Wen and Lin, 2010). Be-
cause of such social correlation, close social
neighbors in social media such as Twitter and
Weibo may post similar information, or share sim-
ilar opinion. Therefore, we can utilize social cor-
relation to assist in resolving morphs.
As social correlation can be defined as a func-
tion of social distance between a pair of users, we
use social distance as a proxy to social correla-
tion in our approach. The social distance between
user i and j is defined by considering the degree
of separation in their interaction (e.g. retweet-
ing and mentioning) and the amount of the in-
teraction. Similar definition has been shown ef-
fective in characterizing social distance in social
networks extracted from communication data (Lin
et al, 2012; Wen and Lin, 2010). Specifically,
it is dist(i, j) = ?K?1k=1 1strength(vk,vk+1) , where
v1, ..., vk are the nodes on the shortest path from
user i to user j, and strength(vk, vk+1) measures
the strength of interactions between vk and vk+1
as: strength(i, j) = log(Xij)maxj log(Xij) , where Xij isthe total interactions between user i and j, includ-
ing both retweeting and mentioning (If Xij < 10,
we set strength(i, j) = 0).
We integrate social correlation and temporal in-
formation to define our social features. The in-
tuition is that when a morph is used by an user,
the real target may also in the posts by the user or
his/her close friends within a certain time period.
Let T be the set of temporal slots a morph m oc-
curs, Ut be the set of users whose posts include m
in slot t where t ? T , and Uc be the set of close
friends (i.e., social distance < 0.5) for Ut. The
social features are defined as
s(m, e) =
?
t?T f(e, t, Ut, Uc)
|T | .
where f(e, t, Ut, Uc) is a indicator function which
return 1 if one of the users in Ut or Uc posts tweets
include the target candidate e within 7 days before
t.
4.4 Learning-to-Rank
Similar to (Hsiung et al, 2005; Sun et al, 2011a),
we then model the probability of linkage predic-
tion between a morph m and its target candidate
e as a function incorporating the surface, semantic
and social features. Given a training pair ?m, e?,
we choose the standard logistic regression model
to learn weights for the features defined above.
The learnt model is used to predict the probabil-
ity of linking an unseen morph and its target can-
didate. Based on the descending ranking order of
the probability, we select top k candidates as the
final answers based on the answer size k.
5 Experiments
Next, we present the experiment under various set-
tings shown in Table 3, and the impacts of cross
source and cross genre information.
5.1 Data and Evaluation Metric
We collected 1, 553, 347 tweets from Chinese Sina
Weibo from May 1 to June 30 to construct the
censored data set, and retrieved 66, 559 web doc-
uments from the embedded URLs in tweets as the
initial uncensored data set. Retweets and redun-
dant web documents are filtered to ensure more
reliable frequency counting of co-occurrence rela-
tions. We asked two native Chinese annotators to
analyze the data, and construct a test set consisted
of 107 morph entities (81 persons and 26 loca-
tions) and their real targets as our references. We
verified the references by Web resources includ-
ing the summary of popular morphs in Wikipedia
2. In addition, we used 23 sensitive morphs and
the entities that appear in the tweets as queries and
retrieved 25, 128 Chinese tweets from 10% Twit-
ter feeds within the same time period, as well as
7, 473 web documents from the embedded URLs
and added them into the uncensored data set.
To evaluate the system performance, we use
leave-one-out cross validation by computing ac-
curacy as Acc@k = CkQ , where Ck is the to-tal number of correctly resolved morphs at top
k ranked answers, and Q is the total number of
morph queries. We consider a morph as correctly
resolved at the top k answers if the top k answer
set contains the real target of the morph.
2http://zh.wikipedia.org/wiki/??????????
1088
Feature sets Descriptions
Surf Surface features
HomB Semantic features extracted from homogeneous CN, PC, PRW, and KLD
HomE HomB + semantic features extracted from homogeneous NCN and PRW/cosine
HetB Semantic features extracted from heterogeneous CN, PC, PRW and KLD
HetE HetB + Semantic features extracted from heterogeneous NCN and PRW/cosine
Glob? Global semantic features
Social Social network features
Table 3: Description of feature sets. ? Glob only uses the same set of similarity measures when combined
with other semantic features.
5.2 Resolution Performance
5.2.1 Single Genre Information
We first study the contributions of each set of sur-
face and semantic features, as shown in the first
five rows in Table 4. The poor performance based
on surface features shows that morph resolution
task is very challenging since 70% of morphs are
not orthographically similar to their real targets.
Thus, capturing a morph?s semantic meaning is
crucial. Overall, the results demonstrate the ef-
fectiveness of our proposed methods. Specifi-
cally, comparing ?HomB? and ?HetB?, ?HomE?
and ?HetE?, we can see that the semantic fea-
tures based on heterogeneous networks have ad-
vantages over those based on homogeneous net-
works. This corroborates that different neighbor
sets contribute differently, and such discrepancies
should be captured. And comparisions of ?HomB?
and ?HomE?, ?HetB? and ?HetE?demonstrate the
effectiveness of our two new proposed measures.
To evaluate the importance of each similarity mea-
sures, we delete the semantic features obtained
from each measure in ?HetE? and re-evaluate the
system. We find that NCN is the most effective
measure, while KLD is the least important one.
Further adding the global semantic features signif-
icantly improves the performance. This indicates
that capturing both temporal correlations and se-
mantics of morphing simultaneously are important
for morph resolution.
Table 5 shows that combination of surface and
semantic features further improves the perfor-
mance, showing that they are complementary. For
example, using only surface features, the real tar-
get ?????Steve Jobs?? of the morph ???
? (Qiao Boss)? is not top ranked since some other
candidates such as ??? (George)? are more or-
thographically similar. However, ?Steve Jobs? is
ranked top when combined with semantic features.
Features Surf HomB HomE HetB HetE
Acc@1 0.028 0.201 0.192 0.224 0.252
Acc@5 0.159 0.313 0.369 0.393 0.421
Acc@10 0.243 0.346 0.407 0.439 0.467
Acc@20 0.313 0.411 0.467 0.50 0.523
Features + Glob + Glob + Glob + Glob
Acc@1 0.230 0.285 0.257 0.285
Acc@5 0.402 0.407 0.449 0.458
Acc@10 0.435 0.458 0.50 0.495
Acc@20 0.486 0.523 0.565 0.542
Table 4: The System Performance Based on Each
Single Feature Set.
Features Surf +
HomB
Surf +
HomE
Surf +
HetB
Surf +
HetE
Acc@1 0.234 0.238 0.262 0.276
Acc@5 0.416 0.444 0.481 0.519
Acc@10 0.477 0.505 0.533 0.570
Acc@20 0.519 0.561 0.565 0.598
Features + Glob + Glob + Glob + Glob
Acc@1 0.290 0.341 0.322 0.346
Acc@5 0.505 0.495 0.528 0.533
Acc@10 0.551 0.551 0.579 0.584
Acc@20 0.594 0.603 0.636 0.631
Table 5: The System Performance Based on Com-
binations of Surface and Semantic Features.
5.2.2 Cross Source and Cross Genre
Information
We integrate the cross source information from
Twitter, and the cross genre information from web
documents into Weibo tweets for information net-
work construction, and extract a new set of se-
mantic features. Table 6 shows that further gains
can be achieved. Notice that integrating tweets
from Twitter mainly improves the ranking for top
k where k > 1. This is because Weibo dominates
our dataset, and in Weibo many of these sensi-
tive morphs are mostly used with their traditional
meanings instead of the morph senses. Further
performance improvement is achieved by integrat-
ing information from background formal web doc-
uments which can provide richer context and rela-
tions.
1089
Features Surf +
HomB +
Glob
Surf +
HomE +
Glob
Surf +
HetB +
Glob
Surf +
HetE +
Glob
Acc@1 0.290 0.341 0.322 0.346
Acc@5 0.505 0.495 0.528 0.533
Acc@10 0.551 0.551 0.579 0.584
Acc@20 0.594 0.603 0.636 0.631
Features + Twit-
ter
+ Twit-
ter
+ Twit-
ter
+ Twit-
ter
Acc@1 0.308 0.336 0.336 0.346
Acc@5 0.514 0.519 0.547 0.565
Acc@10 0.579 0.594 0.594 0.636
Acc@20 0.631 0.640 0.668 0.668
Features + Web + Web + Web + Web
Acc@1 0.327 0.360 0.341 0.379
Acc@5 0.528 0.519 0.565 0.575
Acc@10 0.594 0.589 0.622 0.645
Acc@20 0.631 0.650 0.678 0.678
Table 6: The System Performance of Integrating
Cross Source and Cross Genre Information.
5.2.3 Effects of Social Features
Table 7 shows that adding social features can im-
prove the best performance achieved so far. This is
because a group of people with close relationships
may share similar opinion. As an example, two
tweets ?...of course the reputation of Buhou is a
little too high! //@User1: //@User2: Chongqing
event tells us...)? and ?...do not follow Bo Xi-
lai...@User1...) are from two users in the same
social group.One includes a morph ?Buhou? and
the other includes its target ?Bo Xilai?.
Features Surf +
HomB +
Glob +
Twitter
+ Web
Surf +
HomE +
Glob +
Twitter
+ Web
Surf +
HetB +
Glob +
Twitter
+ Web
Surf +
HetE +
Glob +
Twitter
+ Web
Acc@1 0.327 0.360 0.341 0.379
Acc@5 0.528 0.519 0.565 0.575
Acc@10 0.594 0.589 0.622 0.645
Acc@20 0.631 0.650 0.678 0.678
Features + Social + Social + Social + Social
Acc@1 0.336 0.369 0.365 0.379
Acc@5 0.537 0.547 0.589 0.594
Acc@10 0.594 0.601 0.645 0.659
Acc@20 0.645 0.664 0.701 0.701
Table 7: The Effects of Social Features.
5.3 Effects of Candidate Detection
The performance with and without candidate de-
tection step (using all features) is shown in Ta-
ble 8. The gain is small since the combination
of all features in the learning to rank framework
can already well capture the relationship between
a morph and a target candidate. Nevertheless, the
temporal distribution assumption is effective. It
helps to filter out 80% of unrelated targets and
speed up the system 5 times, while retain 98.5%
of the morph candidates that can be detected.
System Acc@1 Acc@5 Acc@10 Acc@20
Without 0.365 0.579 0.645 0.696
With 0.379 0.594 0.659 0.701
Table 8: The Effects of Temporal Constraint
We also attempted using topic modeling ap-
proach to detect target candidates. Due to the large
amount of data, we first split the data set on a daily
basis, then applied Probabilistic Latent Semantic
Analysis (PLSA) (Hofmann, 1999). Named enti-
ties which co-occur at least ? times with a morph
query in the same topic are selected as its target
candidates. As shown in Table9 (K is the num-
ber of predefined topics), PLSA is not quite effec-
tive mainly because traditional topic modeling ap-
proaches do not perform well on short texts from
social media. Therefore, in this paper we choose
a simple method based on temporal distribution to
detect target candidates.
Method All Temporal PLSA( PLSA(
K = 5 K = 5
? = 1) ? = 2)
Acc 0.935 0.921 0.935 0.925
No. 8, 111 1, 964 6, 380 4, 776
Method PLSA( PLSA( PLSA( PLSA(
K = 10 K = 10 K = 20 K = 20
? = 1) ? = 2) ? = 1) ? = 2)
Acc 0.935 0.907 0.888 0.757
No. 5, 117 3, 138 3, 702 1, 664
Table 9: Accuracy of Target Candidate Detection
5.4 Discussions
Compared with the standard alias detection
(?Surf+HomB?) approach (Hsiung et al, 2005),
our proposed approach achieves significantly bet-
ter performance (99.9% confidence level by the
Wilcoxon Matched-Pairs Signed-Ranks Test for
Acc@1). We further explore two types of factors
which may affect the system performance as fol-
lows.
One important aspect affecting the resolution
performance is the morph & non-morph ambigu-
ity. We categorize a morph query as ?Unique? if
the string is mainly used as a morph when it oc-
curs, such as ??? (Bodu)? which is used to re-
fer to ?Bo Xilai?; otherwise as ?Common? (e.g.
??? (Baby)? ,??? (President)? ). Table 10
presents the separate scores for these two cate-
gories. We can see that the morphs in ?Unique?
1090
category have much better resolution performance
than those in ?Common? category.
Category Number Acc@1 Acc@5 Acc@10 Acc@20
Unique 72 0.479 0.715 0.771 0.819
Common 35 0.171 0.343 0.40 0.429
Table 10: Performance of Two Categories
We also investigate the effects of popularity of
morphs on the resolution performance. We split
the queries into 5 bins with equal size based on the
non-descending frequency, and evaluate Acc@1
separately. As shown in Table11, we can see that
the popularity is not highly correlated with the per-
formance.
Rank 0 ?
20%
20% ?
40%
40% ?
60%
60% ?
80%
80% ?
100%
All 0.333 0.476 0.341 0.429 0.318
Unique 0.321 0.679 0.379 0.571 0.483
Common 0.214 0.214 0.071 0.071 0.286
Table 11: Effects of Popularity of Morphs
6 Related Work
To analyze social media behavior under active
censorship, (Bamman et al, 2012) automatically
discovered politically sensitive terms from Chi-
nese tweets based on message deletion analysis.
In contrast, our work goes beyond target idendi-
fication by resolving implicit morphs to their real
targets.
Our work is closely related to alias detec-
tion (Hsiung et al, 2005; Pantel, 2006; Bollegala
et al, 2011; Holzer et al, 2005). We demon-
strated that state-of-the-art alias detection meth-
ods did not perform well on morph resolution. In
this paper we exploit cross-genre information and
social correlation to measure semantic similarity.
(Yang et al, 2011; Huang et al, 2012) also showed
the effectiveness of exploiting information from
formal web documents to enhance tweet summa-
rization and tweet ranking.
Other similar research lines are the TAC-KBP
Entity Linking (EL) (Ji et al, 2010; Ji et al, 2011),
which links a named entity in news and web docu-
ments to an appropriate knowledge base (KB) en-
try, the task of mining name translation pairs from
comparable corpora (Udupa et al, 2009; Ji, 2009;
Fung and Yee, 1998; Rapp, 1999; Shao and Ng,
2004; Hassan et al, 2007) and the link predic-
tion problem (Adamic and Adar, 2001; Liben-
Nowell and Kleinberg, 2003; Sun et al, 2011b;
Hasan et al, 2006; Wang et al, 2007; Sun et al,
2011a). Most of the work focused on unstruc-
tured or structured data with clean and rich re-
lations (e.g. DBLP). In contrast, our work con-
structs heterogeneous information networks from
unstructured, noisy multi-genre text without ex-
plicit entity attributes.
7 Conclusion and Future Work
To the best of our knowledge, this is the first work
of resolving implicit information morphs from the
data under active censorship. Our promising re-
sults can well serve as a benchmark for this new
problem. Both of the Meta-path based and so-
cial correlation based semantic similarity mea-
surements are proven powerful and complemen-
tary.
In this paper we have focused on entity morphs.
In the future we will extend our method to dis-
cover other types of information morphs, such as
events and nominal mentions. In addition, auto-
matic identification of candidate morphs is another
challenging task, especially when the mentions are
ambiguous and can also refer to other real enti-
ties. Our ongoing work includes identifying can-
didate morphs from scratch, as well as discovering
morphs for a given target based on anomaly anal-
ysis and textual coherence modeling.
Acknowledgments
Thanks to the three anonymous reviewers for their
insightful comments. This work was supported
by the U.S. Army Research Laboratory under Co-
operative Agreement No. W911NF- 09-2-0053
(NS-CTA), the U.S. NSF CAREER Award under
Grant IIS-0953149, the U.S. NSF EAGER Award
under Grant No. IIS-1144111, the U.S. DARPA
FA8750-13-2-0041 - Deep Exploration and Filter-
ing of Text (DEFT) Program, the U.S. DARPA un-
der Agreement No. W911NF-12-C-0028, CUNY
Junior Faculty Award, NSF IIS-0905215, CNS-
0931975, CCF-0905014, and MIAS, a DHS-IDS
Center for Multimodal Information Access and
Synthesis at UIUC. The views and conclusions
contained in this document are those of the au-
thors and should not be interpreted as representing
the official policies, either expressed or implied,
of the U.S. Government. The U.S. Government is
authorized to reproduce and distribute reprints for
Government purposes notwithstanding any copy-
right notation here on.
1091
References
Lada A. Adamic and Eytan Adar. 2001. Friends
and neighbors on the web. SOCIAL NETWORKS,
25:211?230.
Aris Anagnostopoulos, Ravi Kumar, and Mohammad
Mahdian. 2008. Influence and correlation in social
networks. In KDD, pages 7?15.
David Bamman, Brendan O?Connor, and Noah A.
Smith. 2012. Censorship and deletion practices in
chinese social media. First Monday, 17(3).
Patrick Barwise and Sea?n Meehan. 2010. The one
thing you must get right when building a brand.
Harvard Business Review, 88(12):80?84.
D. Bollegala, Y. Matsuo, and M. Ishizuka. 2011. Au-
tomatic discovery of personal name aliases from
the web. Knowledge and Data Engineering, IEEE
Transactions on, 23(6):831?844.
Pi-Chuan Chang, Michel Galley, and Christopher D.
Manning. 2008. Optimizing chinese word segmen-
tation for machine translation performance. In Pro-
ceedings of the Third Workshop on Statistical Ma-
chine Translation, StatMT ?08, pages 224?232.
Pascale Fung and Lo Yuen Yee. 1998. An ir approach
for translating new words from nonparallel, com-
parable texts. In Proceedings of the 36th Annual
Meeting of the Association for Computational Lin-
guistics and 17th International Conference on Com-
putational Linguistics - Volume 1, ACL ?98, pages
414?420.
Mohammad Al Hasan, Vineet Chaoji, Saeed Salem,
and Mohammed Zaki. 2006. Link prediction using
supervised learning. In In Proc. of SDM 06 work-
shop on Link Analysis, Counterterrorism and Secu-
rity.
Ahmed Hassan, Haytham Fahmy, and Hany Has-
san. 2007. Improving named entity translation
by exploiting comparable and parallel corpora. In
RANLP.
Daniel S. Hirschberg. 1977. Algorithms for the
longest common subsequence problem. J. ACM,
24(4):664?675.
Thomas Hofmann. 1999. Probabilistic latent semantic
indexing. In Proceedings of the 22nd annual inter-
national ACM SIGIR conference on Research and
development in information retrieval, SIGIR ?99,
pages 50?57.
Ralf Holzer, Bradley Malin, and Latanya Sweeney.
2005. Email alias detection using social network
analysis. In Conference on Knowledge Discovery
in Data: Proceedings of the 3 rd international work-
shop on Link discovery, volume 21, pages 52?57.
Paul Hsiung, Andrew Moore, Daniel Neill, and Jeff
Schneider. 2005. Alias detection in link data sets.
In Proceedings of the International Conference on
Intelligence Analysis, May.
Hongzhao Huang, Arkaitz Zubiaga, Heng Ji, Hongbo
Deng, Dong Wang, Hieu Khac Le, Tarek F. Ab-
delzaher, Jiawei Han, Alice Leung, John Hancock,
and Clare R. Voss. 2012. Tweet ranking based on
heterogeneous networks. In COLING, pages 1239?
1256.
Heng Ji and Ralph Grishman. 2008. Refining event ex-
traction through cross-document inference. In Pro-
ceedings of ACL, pages 254?262.
H. Ji, R. Grishman, H.T. Dang, K. Griffitt, and J. El-
lis. 2010. Overview of the tac 2010 knowledge base
population track. In Text Analysis Conference (TAC)
2010.
H. Ji, R. Grishman, and H.T. Dang. 2011. Overview
of the tac 2011 knowledge base population track. In
Text Analysis Conference (TAC) 2011.
Heng Ji. 2009. Mining name translations from com-
parable corpora by creating bilingual information
networks. In Proceedings of the 2nd Workshop
on Building and Using Comparable Corpora: from
Parallel to Non-parallel Corpora, BUCC ?09, pages
34?37.
David Liben-Nowell and Jon Kleinberg. 2003. The
link prediction problem for social networks. In
Proceedings of the twelfth international conference
on Information and knowledge management, CIKM
?03, pages 556?559.
Ching-Yung Lin, Lynn Wu, Zhen Wen, Hanghang
Tong, Vicky Griffiths-Fisher, Lei Shi, and David
Lubensky. 2012. Social network analysis in enter-
prise. Proceedings of the IEEE, 100(9):2759?2776.
Vincent Ng. 2010. Supervised noun phrase corefer-
ence research: the first fifteen years. In Proceedings
of the 48th Annual Meeting of the Association for
Computational Linguistics, ACL ?10, pages 1396?
1411.
Patrick Pantel. 2006. Alias detection in malicious en-
vironments. In AAAI Fall Symposium on Capturing
and Using Patterns for Evidence Detection, pages
14?20.
Reinhard Rapp. 1999. Automatic identification of
word translations from unrelated english and german
corpora. In Proceedings of the 37th annual meet-
ing of the Association for Computational Linguistics
on Computational Linguistics, ACL ?99, pages 519?
526.
Li Shao and Hwee Tou Ng. 2004. Mining new word
translations from comparable corpora. In Proceed-
ings of the 20th international conference on Compu-
tational Linguistics, COLING ?04.
Yizhou Sun, Rick Barber, Manish Gupta, Charu C. Ag-
garwal, and Han Jiawei. 2011a. Co-author relation-
ship prediction in heterogeneous bibliographic net-
works. In Proceedings of the 2011 International
Conference on Advances in Social Networks Anal-
ysis and Mining, ASONAM ?11, pages 121?128.
1092
Yizhou Sun, Jiawei Han, Xifeng Yan, Philip S. Yu, and
Tianyi Wu. 2011b. Pathsim: Meta path-based top-k
similarity search in heterogeneous information net-
works. PVLDB, 4(11):992?1003.
Kristina Toutanova, Dan Klein, Christopher D. Man-
ning, and Yoram Singer. 2003. Feature-rich part-of-
speech tagging with a cyclic dependency network.
In Proceedings of the 2003 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics on Human Language Technology
- Volume 1, NAACL ?03, pages 173?180.
Raghavendra Udupa, K. Saravanan, A. Kumaran, and
Jagadeesh Jagarlamudi. 2009. Mint: a method
for effective and scalable mining of named entity
transliterations from large comparable corpora. In
Proceedings of the 12th Conference of the European
Chapter of the Association for Computational Lin-
guistics, EACL ?09, pages 799?807.
Robert A. Wagner and Michael J. Fischer. 1974.
The string-to-string correction problem. J. ACM,
21(1):168?173.
Chao Wang, Venu Satuluri, and Srinivasan
Parthasarathy. 2007. Local probabilistic mod-
els for link prediction. In Proceedings of the 2007
Seventh IEEE International Conference on Data
Mining, ICDM ?07, pages 322?331.
Zhen Wen and Ching-Yung Lin. 2010. On the qual-
ity of inferring interests from social neighbors. In
KDD, pages 373?382.
Zi Yang, Keke Cai, Jie Tang, Li Zhang, Zhong Su, and
Juanzi Li. 2011. Social context summarization. In
Proceedings of the 34th international ACM SIGIR
conference on Research and development in Infor-
mation Retrieval, SIGIR ?11, pages 255?264.
Hua-Ping Zhang, Hong-Kui Yu, De-Yi Xiong, and Qun
Liu. 2003. Hhmm-based chinese lexical analyzer
ictclas. In Proceedings of the second SIGHAN work-
shop on Chinese language processing - Volume 17,
SIGHAN ?03, pages 184?187.
1093
