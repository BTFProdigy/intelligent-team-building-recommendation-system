Mining Linguistically Interpreted Texts  
Cassiana Fagundes da Silva, Renata Vieira, 
Fernando Santos Os?rio 
PIPCA - Unisinos  
Av. Unisinos, 950  - S?o Leopoldo, RS 
Brasil ? 93.022-000  
{cassiana, renata, osorio}@exatas.unisinos.br 
Paulo Quaresma 
Departamento de Inform?tica, 
Universidade de ?vora, 7000  
?vora - Portugal 
 {pq}@di.uevora.pt 
 
Abstract 
This paper proposes and evaluates the use of 
linguistic information in the pre-processing 
phase of text mining tasks. We present several 
experiments comparing our proposal for 
selection of terms based on linguistic 
knowledge with usual techniques applied in 
the field. The results show that part of speech 
information is useful for the pre-processing 
phase of text categorization and clustering, as 
an alternative for stop words and stemming.  
1 Introduction 
Natural language texts can be viewed as 
resources containing uniform data in such a way 
that methods similar to those used in Data Base 
Knowledge Extraction can be applied to them. The 
adaptation of these methods to texts is known as 
Text Mining (Tan, 1999). Machine learning 
techniques are applied to document collections 
aiming at extracting patterns that may be useful to 
organize or recover information from the 
collections. Tasks related to this area are text 
categorization, clustering, summarization, and 
information extraction.  One of the first steps in 
text mining tasks is the pre-processing of the 
documents, as they need to be represented in a 
more structured way.  
Our work proposes a new technique to the pre-
processing phase of documents and we compare it 
with usual pre-processing methods. We focus on 
two text mining tasks, namely text categorization 
and clustering. In the categorization task we 
associate each document to a class from a pre-
defined set, in the clustering task the challenge is 
to identify groups of similar documents without 
being aware of pre-defined classes. Usually, the 
pre-processing phase in these tasks are based on 
the approach called bag-of-words, in which just 
simple techniques are used to eliminate 
uninteresting words and to reduce various 
semantically related terms to the same root (stop-
words and stemming, respectively). As an 
alternative, we propose the use of linguistic 
information in the pre-processing phase, by 
selecting words according to their category (nouns, 
adjectives, proper names, verbs) and using its 
canonical form. We ran a series of experiments to 
evaluate this proposal over Brazilian Portuguese 
texts.  
This paper is organized as follows. Section 2 
presents an overview of text mining. Section 3 
presents the methods used for collecting the 
linguistic knowledge used in the experiments. The 
experiments themselves are described in Section 4. 
Section 5 presents an analysis of the results and the 
paper is concluded in Section 6. 
 
2 Text Mining 
Text mining processes are usually divided in five 
major phases: A) Document collection: consists of 
the definition of the set of the documents from 
which knowledge must be extracted. B) Pre-
processing: consists of a set of actions that 
transform the set of documents in natural language 
into a list of useful terms. C) Preparation and 
selection of the data: consists in the identification 
and selection of relevant terms form the pre-
processed ones. D) Knowledge Extraction: consists 
of the application of machine learning techniques 
to identify patterns that can classify or cluster the 
documents in the collection. E) Evaluation and 
interpretation of the results: consists of the 
analysis of the results.  
The pre-processing phase in text mining is 
essential and usually very expensive and time 
consuming. As texts are originally non-structured a 
series of steps are required to represent them in a 
format compatible with knowledge extraction 
methods and tools. The usual techniques employed 
in phase B are the use of a list of stop-words, 
which are discarded from the original documents 
and the use of stemming which reduces the words 
to their root.  
Having the proper tools to process Portuguese 
texts, we investigate whether linguistic information 
can have an impact on the results of the whole 
process. In the next section we describe the tools 
we used for acquiring the linguistic knowledge in 
which we base our experiments. 
3 Tools for acquiring linguistic knowledge 
The linguistic knowledge we use in the 
experiments is based on the syntactic analysis 
performed by the PALAVRAS parser (Bick, 
2000). This Portuguese parser is robust enough to 
always give an output even for incomplete or 
incorrect sentences (which might be the case for 
the type of documents used in text mining tasks). It 
has a comparatively low percentage of errors (less 
than 1% for word class and 3-4% for surface 
syntax) (Bick, 2003). We also used another tool 
that makes easier the extraction of features from 
the analyzed texts: the Palavras Xtractor (Gasperin 
et. al. 2003).  This tool converts the parser output 
into three XML files, containing: a) the list of all 
words from the text and their identifier; b) morpho-
syntactic information for each word; c) the 
sentence?s syntactic structures. Using XSL 
(eXtensible Stylesheet Language)1 we can extract 
specified terms from the texts, according to their 
linguistic value. The resulting lists of terms 
according to each combination are then passed to 
phases C, D and E. The experiments are described 
in detail in the next section. 
4 Experiments 
4.1 Corpus 
The corpus used in the experiments is composed 
by a subset of the NILC corpus (N?cleo 
Interdisciplinar de Ling??stica Computacional2) 
containing 855 documents corresponding to 
newspaper articles of Folha de S?o Paulo from 
1994. These documents are related to five 
newspaper sections: informatics, property, sports, 
politics and tourism.  
4.2 Pre-processing techniques 
We prepared three different versions of the 
corpus (V1, V2 and V3) for 3-fold cross validation. 
Each version is partitioned in different training and 
testing parts, containing 2/3 and 1/3 of the 
documents respectively. 
For the experiments with the usual methods, 
irrelevant terms (stop-words) were eliminated from 
the documents, on the basis of a list of stop-words, 
containing 476 terms (mainly articles, prepositions, 
auxiliary verbs, pronouns, etc). The remaining 
terms were stemmed according to Martin Porter?s 
algorithm (Porter, 1980). Based on these 
                                                     
1
 Available in http://www.w3.org/Style/XSL/ 
2
 Available in http://nilc.icmc.sc.usp.br/nilc/   
techniques we generated a collection of pre-
processed documents called PD1. 
To test our proposal we then pre-processed the 
855 documents in a different way: we parsed all 
texts of our corpus, generating the corresponding 
XML files and extracted terms according to their 
grammatical categories, using XSL. Based on these 
techniques we generated a collection of pre-
processed documents called PD2. 
4.2.1 Other mining phases 
All other text mining phases were equally 
applied to both PD1 and PD2. We used relative 
frequency for the selection of relevant terms. The 
representation of the documents was according to 
the vector space model. For the categorization task, 
vectors corresponding to each class were built, 
where the more frequent terms were selected. After 
that, a global vector was composed. We also tested 
with different numbers of terms in the global 
vector (30, 60, 90, 120, 150). For the clustering 
task we measured the similarity of the documents 
using cosine. After calculating similarity of the 
documents, the data was codified according to 
format required by the machine learning tool Weka 
(Witten, 2000). Weka is a collection of machine 
learning algorithms for data mining tasks that 
contains tools for data pre-processing, 
classification, regression, clustering, association 
rules, and visualization.  
In this work the adopted machine learning 
techniques are Decision Tree for the categorization 
process and K-means for text clustering.  
Decision Tree is a supervised learning algorithm 
based on the recursive division of the training 
examples in representative subsets, using the 
metric of information gain. After the induction of a 
classifying tree, it can be applied to new examples, 
described with the same attributes of the training 
examples. 
K-means divides a group of objects in k groups 
in a way that the resulting intracluster similarity is 
high, but the intercluster similarity is low. The 
similarity of groups is measured in respect to the 
medium value of the objects in a group, which can 
be seen as the center of gravity (centroid) of the 
group. The parameters used to run k-means are the 
default ones as suggested by the tool, seed 10 and 
5 groups.  
The evaluation of the results for the 
categorization task is based on the classification 
error, which was used to compare the results for 
PD1 and PD2. For the clustering task the 
evaluation of the results is given by recall and 
precision, based on the generated confusion 
matrices. 
5 Results 
5.1 Text Categorization 
Table 1 shows the results for text categorization 
of PD1, given by the average error rates 
considering the three versions the corpus (V1, V2 
and V3). We had around 20% of error for the 
categorization task. We can see minor variations in 
the results according to the size of the vectors. Best 
results were obtained for 150 terms.  
 
Terms 30 60 90 120 150 
Errors 21,64 21,99 20,47 20,35 19,77 
Table 1: Average Classification Error for PD1% 
Table 2 shows the results for different 
grammatical combinations in PD2, while Figure 1 
summarizes the lowest error rates found for PD1 
and all groups of PD2. The group nouns and 
adjectives presents the lower error rates of all 
experiments (18,01). However, due to the small 
size of the corpus, the improvement reported 
between usual methods (18,01) and nouns-
adjectives (20,47), when considering the same 
number of terms (90), are at 75-80% confidence 
level only (t-test). 
In general, the results show that the presence of 
nouns is crucial, the worst classification errors are 
based on groups that do not contain the category 
nouns, and here the confidence level for the 
differences reported reaches 95%. The groups 
containing nouns present results comparable to 
those found in the experiments based on usual 
methods of pre-processing. The use of verbs, either 
alone or with other grammatical groups is not an 
interesting option. 
 
Terms 30 60 90 120 150 
Nouns 24,91 21,75 23,98 23,51 22,69 
Nouns-adjec. 23,15 20,35 18,01 19,18 18,71 
Nouns-adjec.-
proper names 20,82 22,92 20,94 21,05 21,17 
Nouns-proper 
names 
24,09 24,56 22,80 22,45 22,80 
Adjec.-proper 
names 
47,01 46,34 32,51 33,21 32,86 
Verbs 63,73 62,33 57,75 58,45 55,64 
Nouns-verbs 40 27,72 25,61 24,21 26,32 
Nouns-verbs-
adjectives 35,09 27,02 27,72 24,21 23,51 
Table 2: Average Classification Error for PD2  
It can be observed that usually the best results 
are obtained when the documents are represented 
by a larger number of terms (90, 120 and 150), for 
the group nouns, however, the best results were 
obtained for vectors containing just 60 terms.  
Figure 1: Lower error rates for PD1 and PD2 
We looked at the terms resulting from different 
selection methods and categories to check the 
overlap among the groups. From PD1 to PD2 
based on nouns and adjectives (the one with the 
best results) we could see that we had around 50% 
of different terms. That means that 50% of terms in 
PD1 are terms included in the categories nouns and 
adjectives and 50% of the terms selected on the 
basis of stop-words and stemming are from other 
grammatical categories. As adjectives added to 
nouns improved the results, we checked adjectives 
to figure out their significance. We found terms 
such as Brazilian, electoral, multimedia, political. 
Intuitively, these terms seem to be relevant for the 
classes we had. Analysing the groups containing 
verbs, we observed that the verbs are usually very 
common or auxiliary verbs (such as to be, to have, 
to say), therefore not relevant for classification. 
5.2 Text Clustering 
We tested our hypothesis through clustering 
experiments for PD1 and variations of PD2. For 
the experiments on clustering we used vectors 
containing 150 features from V2 and we set k to 5 
groups. The resulting confusion matrix for PD1 is 
presented in Table 3.  
 
 Cl.0 Cl.1 Cl.2 Cl.3 Cl.4 
Sp. 1  31 2 0 23 
Prop. 2 0 4 0 51 
Inf. 0 0 1 0 55 
Pol. 0 0 2 39 16 
Tour. 5 0 17 0 33 
Table 3: Confusion Matrix PD1 (150 terms) 
Considering the larger group in each row and 
column (highlighted in the table) as the intended 
cluster for each class, the   corresponding precision 
is of 50,52%. 
We repeated the same set of experiments for 
PD2. We tested several grammatical groups, the 
best result was related to nouns and proper names. 
The results are shown in Tables 4. The 
corresponding precision is 63,15%. 
 
 Cl.0 Cl.1 Cl.2 Cl.3  Cl.4 
Sp. 0 38 19 0 0 
Prop. 11 0 44 1 1 
Inf. 0 0 19 0 38 
Pol. 0 1 20 36 0 
Tour. 0 0 57 0 0 
Table 4:  Confusion Matrix PD2 (nouns + proper 
names, 150 terms) 
6 Conclusions 
This paper presented a series of experiments 
aiming at comparing our proposal of pre-
processing techniques based on linguistic 
information with usual methods adopted for pre-
processing in text mining.  
We find in the literature other alternative 
proposals for the pre-processing phase of text 
mining. (Gon?alves and Quaresma, 2003) use the 
canonical form of the word instead stemming, for 
European Portuguese. (Feldman et al 1998) 
proposes the use of compound terms as opposed to 
single terms for text mining. Similarly, (Aizawa, 
2001) uses morphological analysis to aid the 
extraction of compound terms. Our approach 
differs from those since we propose single terms 
selection based on different part of speech 
information. 
The results show that a selection made solely on 
the basis of category information produces results 
at least as good as those produced by usual 
methods (when the selection considers nouns and 
adjectives or nouns and proper nouns) both in 
categorization and clustering tasks. In the 
categorization experiments we obtained the lowest 
error rate for PD2 when the pre-processing phase 
was based on the selection of nouns and adjectives, 
18,01%. However, the second best score in the 
case of categorization was achieved by the 
traditional methods, 19,77%. Due to the small 
corpus, further experiments are needed to verify 
the statistical significance of  the reported gains. 
The results of the clustering experiments show a 
difference in precision from  50,52% to 63,15%. 
As we are planning to test our techniques with a 
larger number of documents and consequently a 
larger number of terms, we are considering 
applying other machine-learning techniques such 
as Support Vector Machines that are robust enough 
to deal with a large number of terms. We are also 
planning to apply more sophisticated linguistic 
knowledge than just grammatical categories, as, for 
instance, the use of noun phrases for terms 
selection, since this information is provided by the 
parser PALAVRAS. Other front for future work is 
further tests for other languages. 
References  
Aizawa A., 2001. Linguistic Techniques to 
Improve the Performance of Automatic Text 
Categorization. Proc. of the Sixth Natural 
Language Processing Pacific Rim Symposium, 
pages 307-314. 
Bick, E. 2000. The Parsing System PALAVRAS: 
Automatic Gramatical Analysis of Porutugese in 
a Constraint Grammar Framework. ?rhus 
University. ?rhus: ?rhus University Press. 
Bick, E. 2003. A Constraint Grammar Based 
Question Answering System for Portuguese. 
Proceedings of the 11? Portuguese Conference 
on Artificial Intelligence, pages 414-418. LNAI 
Springer Verlag. 
Feldman R., et al 1998. Text Mining at the Term 
Level. Proc. of the Second European Symposium 
on Principles of Data Mining and Knowledge 
Discovery, pages 65-73. LNCS Springer. 
Gasperin, C.; Vieira, R.; Goulart, R. and 
Quaresma, P. 2003. Extracting XML Syntactic 
Chunks from Portuguese Corpora. Proc. of the 
TALN Workshop on Natural Language 
Processing of Minority Languages and Small 
Languages, pages 223-232. Batz-sur-Mer  
France. 
Gon?alves, T. and Quaresma, P. 2003. A prelimary 
approach classification problem of Portuguese 
juridical documents. Proceedings of the 11? 
Portuguese Conference on Artificial Intelligence, 
pages 435-444. LNAI Springer Verlag. 
Porter, M. F. 1980. An Algorithm for Suffix 
Stripping. Program, 14 no. 3, pages 130-137. 
Tan, Ah-Hwee. 1999. Text mining: the state of the 
art and the challenges. Proc. of the Pacific-Asia  
Workshop on Knowledge Discovery from 
Advanced Databases, pages 65-70, Beijing. 
Witten, I. H. 2000. Data mining: Pratical Machine 
Learning tools and techniques with Java 
implementations. Academic Press. 
 
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 375?379,
Dublin, Ireland, August 23-24, 2014.
JU-Evora: A Graph Based Cross-Level Semantic Similarity Analysis 
using Discourse Information 
 
 
Swarnendu Ghosh 
Dept. of Computer 
Science and Engi-
neering  
Jadavpur University, 
Kolkata, India 
swarbir@gmail.
com 
Nibaran Das 
Dept. of Computer 
Science and Engi-
neering 
Jadavpur University, 
Kolkata, India 
ni-
baran@ieee.org 
Teresa Gon?alves 
Dept. of Inform?tica 
University of ?vora, 
?vora, Portugal 
tcg@evora.pt 
Paulo Quaresma 
Dept. of Inform?tica 
University of ?vora, 
?vora, Portugal  
pq@evora.pt 
 
Abstract 
Text Analytics using semantic information is 
the latest trend of research due to its potential 
to represent better the texts content compared 
with the bag-of-words approaches. On the 
contrary, representation of semantics through 
graphs has several advantages over the tradi-
tional representation of feature vector. There-
fore, error tolerant graph matching techniques 
can be used for text comparison. Neverthe-
less, not many methodologies exist in the lit-
erature which expresses semantic representa-
tions through graphs. The present system is 
designed to deal with cross level semantic 
similarity analysis as proposed in the 
SemEval-2014 : Semantic Evaluation, Inter-
national Workshop on Semantic Evaluation, 
Dublin, Ireland.  
1 Introduction 
Text Analytics has been the focus of much re-
search work in the last years. State of the art ap-
proaches typically represent documents as vec-
tors (bag-of-words) and use a machine learning 
algorithm, such as k-NN or SVM, to create a 
model and to compare and classify new docu-
ments. However, and in spite of being able to 
obtain good results, these approaches fail to rep-
resent the semantic content of the documents, 
losing much information and limiting the tasks 
that can be implemented over the document rep-
resentation structures. To overcome these short-
comings some research has been done aiming to 
use and evaluate more complex knowledge rep-
resentation structures. In this paper, a new ap-
proach which integrates a deep linguistic analysis 
of the documents with graph-based classification 
algorithms and metrics has been proposed.  
2 Overview of the Task 
This task provides an evaluation for semantic 
similarity across different sizes of text, which we 
refer to as lexical levels. Specifically, this task 
encompasses four semantic similarity compari-
sons: 
? paragraph to sentence(P2S), 
? sentence to phrase(S2Ph), 
? phrase to word(Ph2W), and 
? word to sense(W2S). 
Task participants were provided with pairs of 
each comparison type and asked to rate the pair 
according to the semantic similarity of the small-
er item to the larger item. As an example, given a 
sentence and a paragraph, a system would assess 
how similar is the meaning of the sentence to the 
meaning of the paragraph. Ideally, a high-
similarity sentence would reflect overall meaning 
of the paragraph. The participants were expected 
to assign a score between [0,4] to each pairs of 
sentences, where 0 shows no similarity in con-
cept while 4 shows complete similarity in con-
cept. 
3 Theoretical Concepts 
3.1 Discourse Representation Structures 
Extraction and representation of the information 
conveyed by texts can be performed through 
several approaches, starting from statistical anal-
ysis to deep linguistic techniques. In this paper 
This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and 
proceedings footer are added by the organisers. Licence 
details: http://creativecommons.org/licenses/by/4.0/ 
375
we will use a deep linguistic processing se-
quence: lexical, syntactic, and semantic analysis. 
One of the most prominent research work on 
semantic analysis is the Discourse Representa-
tion Theory (DRT)(Kamp & Reyle, 1993). In 
DRT, we aim to associate sentences with expres-
sions in a logical language, which indicate their 
meaning. In DRT, each sentence is viewed as an 
update of an existing context, having as result a 
new context. 
DRT provides a very powerful platform for 
the representation of semantic structures of doc-
uments including complex relations like implica-
tions, propositions and negations. It is also able 
to separately analyse almost all kinds of events 
and find out their agent and patient. 
The main component of DRT is the Discourse 
Representation Structure (DRS These expres-
sions have two main parts: a) a set of referents, 
which refer to entities present in the context and 
b) a set of conditions, which are the relations that 
exist between the entities. An example of a DRS 
representation for the sentence "He throws a 
ball." is shown below. 
[ 
x1, x2, x3: 
male(x1), 
ball(x2), 
throw(x3), 
event(x3), 
agent(x3,x1), 
patient(x3, x2) 
] 
3.2 GML Structure 
Graph Modelling Language (GML)(Himsolt & 
Passau, 1996) is a simple and efficient way to 
represent weighted directed graphs. A GML file 
is basically a 7-bit ASCII file, and, as such, can 
be easily read, parsed, and written. Several open 
source applications 1  are available that enable 
viewing and editing GML files. 
Graphs are represented by the keys viz. graph, 
node and edge. The basic structure is modelled 
with the node's id and the edge's source and tar-
get at-tributes. The id attributes assign numbers 
to nodes, which are then referenced by source 
and target. Weights can be represented by the 
label attribute. 
                                                 
1http://en.wikipedia.org/wiki/Graph_Modelling_Lang
uage 
3.3 Similarity Metrics for Graphs 
It has already been mentioned that the objective 
of the present work is to generate similarity 
scores among documents of different lexical lev-
els using an approach which integrates a deep 
linguistic analysis of the documents with graph-
based classification algorithms and metrics. 
Here, five different distance metrics taken from 
(Bunke, 2010) are utilized for this purpose. They 
are popularly used in object recognition task, but 
for text similarity measure they have not yet been 
used.  
For two graphs    and   , if  (     ) is the 
dissimilarity/similarity measure, then this meas-
ure would be a distance if   has the following 
properties: 
1.  (     )   , iff         
2.  (     )   (     ) 
3.  (     )   (     )   (     ) 
 
The measures used in the present work follow 
the above rules and the corresponding equations 
are 
    (     )       
|   (     )|
   (|  | |  |)
                  ( ) 
    (     )      
|   (     )|
|  |  |  |  |   (     )|
  
?(2) 
    (     )   |  |  |  |    |   (     )|  
?(3) 
     (     )  |   (     )|  |   (     )| 
?(4) 
      (     )     
|   (     )|
|   (     )|
                 ( ) 
In the equations    (     )  and 
   (     ) denote maximal common subgraph 
and minimum common super graphs of two 
graphs    and   . Theoretically    (     )  is 
the largest graph in terms of edges that is iso-
morphic to a subgraph of     and   . The 
   (     ) has been formally defined in a work 
of Horst Bunke (Bunke, Foggia, Guidobaldi, 
Sansone, & Vento, 2002).  As stated earlier, it is 
a NP complete problem and actually, the method 
of finding the    ()  is a brute force method 
which finds all the subgraphs of both the graphs 
and select the maximum graph which is common 
to both. To make the program computationally 
faster, the program is modified  to an approxi-
376
mate version of   (     ) on the fact that  the 
vertices which exhibit greater similarity in their 
local structures among the two graphs have a 
greater probability of inclusion in the   ()  The 
two pass approach used in the present work to 
form the approximate   (     ) is as follows: 
? All the node pairs (one from each graph) 
are ranked according the number of 
matching self-loops. 
? The mcs is built by including each node 
pair (starting with the one with the highest 
number of matching self-loops) and con-
sidering it as a common node; and then in-
clude the rest of the edges (i.e. non-self-
loop edges) which occur in the same fash-
ion in both the graphs. 
In this way it ensures that the approximation 
version exhibits most of the properties of a mcs, 
while keeping the complexity in a polynomial 
time. 
The minimum common supergraph 
(   )(Angelova & Weikum, 2006) is formed 
using the union of two graphs, i.e. 
   (     )       . 
The distance metrics of Equations 1-3 were 
used directly without any modifications; the ones 
of Equations 3-4 were divided by (|  |  |  |) 
and |   (     )     (     )|   respectively 
to make them normalized, keeping the value of 
distance metrics within the range [   ]  
It is worthy to note that label matching that is 
performed during the above mentioned step may 
not necessarily be exact matching. Rather in this 
case we have used the WordNet to find an ap-
proximate conceptual similarity between two 
labels. For our experiment we have used the Wu 
and  Palmer?s conceptual similarity (Wu & 
Palmer, 1994).  
        (     ) , where   and    are a pair 
of concepts corresponding to   two words and 
   (     ) means the lowest super ordinate then, 
     (     )
 
       ( )
   (    )     (    )         ( )
 
3.4 Tools Used 
In order to process texts C&C/Boxer (Bos, 2008; 
Curran, Clark, & Bos, 2007) a well-known open 
source  tool available as a plugin to Natural Lan-
guage Toolkit (NLTK) is used. The tool consists 
of a combinatory categorical grammar (CCG) 
(Curran et al., 2007) parser and outputs the se-
mantic representations using discourse represen-
tation structures (DRS) of Discourse Representa-
tion Theory (DRT) (Kamp & Reyle, 1993). 
4  System Description 
The method described in the present work, is 
mainly divided into three major components. The 
first is the creation of the DRS of the semantic 
interpretation of the text. The second is the con-
struction of graphs in GML from the obtained 
DRS using some predefined rules. The third one 
is the classification phase where the different 
graph distances are assessed using a k-NN classi-
fier (Zhang, Li, Sun, & Nadee, 2013).  
The algorithm semantic evaluation of text con-
tent may be described as follows. 
? NLTK Module : For each pair of text, to 
Figure 1: Graphical overview of  mcs and MCS:  (a), (b) graph representation of sentences 
meaning ?Mary drinks water? and ?David drinks water ? respectively, (c)  maximum com-
mon subgraph,  (d) minimum common supergraph. 377
compare their similarity measure we need 
to find their DRS using the C&C/Boxer 
toolkit. The toolkit first uses the C&C Par-
ser to find the combinatorial categorical 
grammar(CCG) of the text. Next the Boxer 
Module uses the CCG to find the discourse 
representation structures. 
? Graph building module : In general Box-
er represents a sentence through some dis-
course referents and conditions based on 
the semantic interpretation of the sentence. 
In the graph, the referent is represented by 
vertex after resolving the equity among 
different referents of the DRS; and a con-
dition is represented by an edge value be-
tween two referents. The condition of a 
single referent is represented as a self-loop 
of the referent (source and destination ref-
erents are same). Special relationships 
such as proposition, implication etc. are 
treated as edge values between two refer-
ents; Agent and patient are also treated as 
conditions of discourse, hence represented 
by the edge values of two referents. 
? Calculating Similarity Index : It has al-
ready been mentioned that the different 
distance metrics (see Equations 1-5) calcu-
lated based on the mcs() and MCS(). The 
values of  mcs() and MCS() are represent-
ed by the number of similar edges. Thus, 
ten different distances are calculated based 
on Equations 1-5. 
? Learning : We obtained 5 similarity 
scores for each pair of texts. Our task re-
quires us to assign a score between 0-4 for 
each pair of text. Hence using the gold 
standard a K-NN Classifier have been 
trained to find the output score for a test 
sample. The value of K has been empiri-
cally adjusted using the cross validation 
technique to find the optimal value. 
Our method works smoothly for the first two 
lexical levels. But for the last two levels i.e. 
phrase to word and word to sense it is not possi-
ble to find out DRS for a single word. Hence we 
have used the WordNet(Fellbaum, 1998) to ex-
tract the definition of the word in question and 
calculate its DRS and proceed with the method. 
When a word has multiple definitions, all the 
definitions are fused to a single sentence after 
conjugating them with the conjunction ?or?. 
5 Results and Discussions 
The JU-Evora system performed fairly in the 
SemEval Competition 2014. All the correlation 
scores are not as good as the Baseline(LCS) 
scores, however it provides a better  Pearson cor-
relation score in case of Paragraph to Sentence. 
The other scores, though not higher, are in the 
vicinity of the baseline. All the scores are shown 
below in Table 1. 
 
 
Table 1: Performance of JU-Evora system with 
respect to Baseline. 
6 Conclusion 
In this paper a new approach has been proposed 
to the text comparison task which integrates a 
deep linguistic analysis of the documents with a 
graph-based comparison algorithm. In the lin-
guistic analysis, discourse representation struc-
tures (DRS) are used to represent text semantic 
content and, afterwards, these structures are 
transformed into graphs. We have evaluated ex-
istent graph distance metrics and proposed some 
modifications, more adequate to calculate graph 
distances between graph-drs structures. Finally, 
we integrated graph-drs structures and the pro-
posed graph distance metrics into a k-NN classi-
fier for calculating the similarity between two 
documents. Future works in this area would  be 
concentrated on the use of external knowledge 
sources to make the system more robust. 
References 
Angelova, Ralitsa, & Weikum,Gerhard. (2006). 
Graph-based Text Classification: Learn from Your 
Neighbors. In Proceedings of the 29th Annual 
International ACM SIGIR Conference on 
Research and Development in Information 
Retrieval (pp. 485?492). New York, NY, USA: 
ACM. 
Bos, Johan (2008). Wide-Coverage Semantic 
Analysis with Boxer. In J. Bos & R. Delmonte 
PEARSON?S CORRELATION 
 P2S S2Ph Ph2W W2S 
JU-Evora 0.536 0.442 0.090 0.091 
Baseline (LCS) 0.527 0.562 0.165 0.109 
SPEARMAN CORRELATION 
JU-Evora 0.533 0.440 0.096 0.075 
Baseline (LCS) 0.613 0.626 0.162 0.130 
378
(Eds.), Semantics in Text Processing. STEP 2008 
Conference Proceedings (pp. 277?286). College 
Publications. 
Bunke, Horst (2010). Graph Classification and 
Clustering Based on Vector Space Embedding 
(Vol. Volume 77, pp. 15?34). WORLD 
SCIENTIFIC. 
doi:doi:10.1142/9789814304726_0002 
Bunke, Horst, Foggia, Pasquale, Guidobaldi, Corrado, 
Sansone, Carlo, & Vento, Mario (2002). A 
Comparison of Algorithms for Maximum 
Common Subgraph on Randomly Connected 
Graphs. In T. Caelli, A. Amin, R. W. Duin, D. 
Ridder, & M. Kamel (Eds.), Structural, Syntactic, 
and Statistical Pattern Recognition SE  - 12 (Vol. 
2396, pp. 123?132). Springer Berlin Heidelberg.  
Curran, James, Clark, Stephen, & Bos, Johan (2007). 
Linguistically Motivated Large-Scale NLP with 
C&C and Boxer. In Proceedings of the 45th 
Annual Meeting of the Association for 
Computational Linguistics Companion Volume 
Proceedings of the Demo and Poster Sessions (pp. 
33?36). Prague, Czech Republic: Association for 
Computational Linguistics. 
Fellbaum, Christiane (1998). WordNet: An Electronic 
Lexical Database. British Journal Of Hospital 
Medicine London England 2005 (Vol. 71, p. 423).  
Himsolt, Michael, & Passau, Universit?t (1996). 
GML?: A portable Graph File Format. Syntax, 1?
11.  
Kamp, Hans, & Reyle, Uwe (1993). From discourse 
to logic: Introduction to model theoretic semantics 
of natural language, formal logic and discourse 
representation theory.  
Wu, Zhibiao, & Palmer, Martha (1994). Verb 
semantics and lexical selection. In 32nd Annual 
Meeting of the Association for Computational 
Linguistics,, 32, 133?138.  
Zhang, Libiao, Li, Yuefeng, Sun, Chao, & Nadee, 
Winai (2013). Rough Set Based Approach to Text 
Classification. Web Intelligence (WI) and 
Intelligent Agent Technologies (IAT), 2013 
IEEE/WIC/ACM International Joint Conferences 
on.  
 
379
