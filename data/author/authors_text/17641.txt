Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 219?224,
Sofia, Bulgaria, August 8-9, 2013 c?2013 Association for Computational Linguistics
QCRI-MES Submission at WMT13: Using Transliteration Mining to
Improve Statistical Machine Translation
Hassan Sajjad1, Svetlana Smekalova2, Nadir Durrani3,
Alexander Fraser4, Helmut Schmid4
1Qatar Computing Research Institute ? hsajjad@qf.org.qa
2University of Stuttgart ? smekalsa@ims.uni-stuttgart.de
3University of Edinburgh ? dnadir@inf.ed.ac.uk
4Ludwig-Maximilians University Munich ? (fraser|schmid)@cis.uni-muenchen.de
Abstract
This paper describes QCRI-MES?s sub-
mission on the English-Russian dataset to
the Eighth Workshop on Statistical Ma-
chine Translation. We generate improved
word alignment of the training data by
incorporating an unsupervised translitera-
tion mining module to GIZA++ and build
a phrase-based machine translation sys-
tem. For tuning, we use a variation of PRO
which provides better weights by optimiz-
ing BLEU+1 at corpus-level. We translit-
erate out-of-vocabulary words in a post-
processing step by using a transliteration
system built on the transliteration pairs
extracted using an unsupervised translit-
eration mining system. For the Russian
to English translation direction, we apply
linguistically motivated pre-processing on
the Russian side of the data.
1 Introduction
We describe the QCRI-Munich-Edinburgh-
Stuttgart (QCRI-MES) English to Russian and
Russian to English systems submitted to the
Eighth Workshop on Statistical Machine Trans-
lation. We experimented using the standard
Phrase-based Statistical Machine Translation
System (PSMT) as implemented in the Moses
toolkit (Koehn et al, 2007). The typical pipeline
for translation involves word alignment using
GIZA++ (Och and Ney, 2003), phrase extraction,
tuning and phrase-based decoding. Our system is
different from standard PSMT in three ways:
? We integrate an unsupervised transliteration
mining system (Sajjad et al, 2012) into the
GIZA++ word aligner (Sajjad et al, 2011).
So, the selection of a word pair as a correct
alignment is decided using both translation
probabilities and transliteration probabilities.
? The MT system fails when translating out-of-
vocabulary (OOV) words. We build a statis-
tical transliteration system on the translitera-
tion pairs mined by the unsupervised translit-
eration mining system and transliterate them
in a post-processing step.
? We use a variation of Pairwise Ranking Op-
timization (PRO) for tuning. It optimizes
BLEU at corpus-level and provides better
feature weights that leads to an improvement
in translation quality (Nakov et al, 2012).
We participate in English to Russian and Rus-
sian to English translation tasks. For the Rus-
sian/English system, we present experiments with
two variations of the parallel corpus. One set of
experiments are conducted using the standard par-
allel corpus provided by the workshop. In the sec-
ond set of experiments, we morphologically re-
duce Russian words based on their fine-grained
POS tags and map them to their root form. We
do this on the Russian side of the parallel corpus,
tuning set, development set and test set. This im-
proves word alignment and learns better transla-
tion probabilities by reducing the vocabulary size.
The paper is organized as follows. Section
2 talks about unsupervised transliteration mining
and its incorporation to the GIZA++ word aligner.
In Section 3, we describe the transliteration sys-
tem. Section 4 describes the extension of PRO
that optimizes BLEU+1 at corpus level. Section
5 and Section 6 present English/Russian and Rus-
sian/English machine translation experiments re-
spectively. Section 7 concludes.
219
2 Transliteration Mining
Consider a list of word pairs that consists of either
transliteration pairs or non-transliteration pairs.
A non-transliteration pair is defined as a word
pair where words are not transliteration of each
other. They can be translation, misalignment,
etc. Transliteration mining extracts transliteration
pairs from the list of word pairs. Sajjad et al
(2012) presented an unsupervised transliteration
mining system that trains on the list of word pairs
and filters transliteration pairs from that. It models
the training data as the combination of a translit-
eration sub-model and a non-transliteration sub-
model. The transliteration model is a joint source
channel model. The non-transliteration model as-
sumes no correlation between source and target
word characters, and independently generates a
source and a target word using two fixed uni-
gram character models. The transliteration mining
model is defined as an interpolation of the translit-
eration model and the non-transliteration model.
We apply transliteration mining to the list of
word pairs extracted from English/Russian paral-
lel corpus and mine transliteration pairs. We use
the mined pairs for the training of the translitera-
tion system.
2.1 Transliteration Augmented-GIZA++
GIZA++ aligns parallel sentences at word level. It
applies the IBM models (Brown et al, 1993) and
the HMM model (Vogel et al, 1996) in both direc-
tions i.e. source to target and target to source. It
generates a list of translation pairs with translation
probabilities, which is called the t-table. Sajjad
et al (2011) used a heuristic-based transliteration
mining system and integrated it into the GIZA++
word aligner. We follow a similar procedure but
use the unsupervised transliteration mining system
of Sajjad et al (2012).
We define a transliteration sub-model and train
it on the transliteration pairs mined by the unsuper-
vised transliteration mining system. We integrate
it into the GIZA++ word aligner. The probabil-
ity of a word pair is calculated as an interpolation
of the transliteration probability and the transla-
tion probability stored in the t-table of the differ-
ent alignment models used by the GIZA++ aligner.
This interpolation is done for all iterations of all
alignment models.
2.1.1 Estimating Transliteration Probabilities
We use the algorithm for the estimation of translit-
eration probabilities of Sajjad et al (2011). We
modify it to improve efficiency. In step 6 of Al-
gorithm 1 instead of taking all f that coocur with
e, we take only those that have a word length ra-
tio in range of 0.8-1.2.1 This reduces cooc(e) by
more than half and speeds up step 9 of Algorithm
1. The word pairs that are filtered out from cooc(e)
won?t have transliteration probability pti(f |e). We
do not interpolate in these cases and use the trans-
lation probability as it is.
Algorithm 1 Estimation of transliteration proba-
bilities, e-to-f direction
1: unfiltered data? list of word pairs
2: filtered data?transliteration pairs extracted using unsu-
pervised transliteration mining system
3: Train a transliteration system on the filtered data
4: for all e do
5: nbestTI(e) ? 10 best transliterations for e accord-
ing to the transliteration system
6: cooc(e)? set of all f that cooccur with e in a parallel
sentence with a word length in ratio of 0.8-1.2
7: candidateTI(e)? cooc(e) ? nbestTI(e)
8: for all f do
9: pmoses(f, e) ? joint transliteration probability of e
and f according to the transliterator
10: Calculate conditional transliteration probability
pti(f |e)? pmoses(f,e)?
f??CandidateTI(e) pmoses(f ?,e)
2.1.2 Modified EM Training
Sajjad et al (2011) modified the EM training of
the word alignment models. They combined the
translation probabilities of the IBM models and
the HMM model with the transliteration proba-
bilities. Consider pta(f |e) = fta(f, e)/fta(e) is
the translation probability of the word alignment
models. The interpolated probability is calcu-
lated by adding the smoothed alignment frequency
fta(f, e) to the transliteration probability weight
by the factor ?. The modified translation probabil-
ities is given by:
p?(f |e) = fta(f, e) + ?pti(f |e)fta(e) + ?
(1)
where fta(f, e) = pta(f |e)fta(e). pta(f |e) is ob-
tained from the original t-table of the alignment
model. fta(e) is the total corpus frequency of e.
? is the transliteration weight which is defined as
the number of counts the transliteration model gets
versus the translation model. The model is not
1We assume that the words with very different character
counts are less likely to be transliterations.
220
very sensitive to the value of ?. We use ? = 50
for our experiments. The procedure we described
of estimation of transliteration probabilities and
modification of EM is also followed in the oppo-
site direction f-to-e.
3 Transliteration System
The unsupervised transliteration mining system
(as described in Section 2) outputs a list of translit-
eration pairs. We consider transliteration word
pairs as parallel sentences by putting a space af-
ter every character of the words and train a PSMT
system for transliteration. We apply the transliter-
ation system to OOVs in a post-processing step on
the output of the machine translation system.
Russian is a morphologically rich language.
Different cases of a word are generally represented
by adding suffixes to the root form. For OOVs
that are named entities, transliterating the inflected
forms generates wrong English transliterations as
inflectional suffixes get transliterated too. To han-
dle this, first we need to identify OOV named en-
tities (as there can be other OOVs that are not
named entities) and then transliterate them cor-
rectly. We tackle the first issue as follows: If
an OOV word is starting with an upper case let-
ter, we identify it as a named entity. To correctly
transliterate it to English, we stem the named en-
tity based on a list of suffixes ( , , , , , )
and transliterate the stemmed form. For morpho-
logically reduced Russian (see Section 6.1), we
follow the same procedure as OOVs are unknown
to the POS tagger too and are (incorrectly) not re-
duced to their root forms. For OOVs that are not
identified as named entities, we transliterate them
without any pre-processing.
4 PRO: Corpus-level BLEU
Pairwise Ranking Optimization (PRO) (Hopkins
and May, 2011) is an extension of MERT (Och,
2003) that can scale to thousands of parameters.
It optimizes sentence-level BLEU+1 which is an
add-one smoothed version of BLEU (Lin and Och,
2004). The sentence-level BLEU+1 has a bias
towards producing short translations as add-one
smoothing improves precision but does not change
the brevity penalty. Nakov et al (2012) fixed this
by using several heuristics on brevity penalty, ref-
erence length and grounding the precision length.
In our experiments, we use the improved version
of PRO as provided by Nakov et al (2012). We
call it PROv1 later on.
5 English/Russian Experiments
5.1 Dataset
The amount of bitext used for the estimation of the
translation model is ? 2M parallel sentences. We
use newstest2012a for tuning and newstest2012b
(tst2012) as development set.
The language model is estimated using large
monolingual corpus of Russian ? 21.7M sen-
tences. We follow the approach of Schwenk and
Koehn (2008) by training domain-specific lan-
guage models separately and then linearly inter-
polate them using SRILM with weights optimized
on the held-out development set. We divide the
tuning set newstest2012a into two halves and use
the first half for tuning and second for test in or-
der to obtain stable weights (Koehn and Haddow,
2012).
5.2 Baseline Settings
We word-aligned the parallel corpus using
GIZA++ (Och and Ney, 2003) with 5 iterations
of Model1, 4 iterations of HMM and 4 iterations
of Model4, and symmetrized the alignments us-
ing the grow-diag-final-and heuristic (Koehn et al,
2003). We built a phrase-based machine transla-
tion system using the Moses toolkit. Minimum er-
ror rate training (MERT), margin infused relaxed
algorithm (MIRA) and PRO are used to optimize
the parameters.
5.3 Main System Settings
Our main system involves a pre-processing step
? unsupervised transliteration mining, and a post-
processing step ? transliteration of OOVs. For the
training of the unsupervised transliteration min-
ing system, we take the word alignments from
our baseline settings and extract all word pairs
which occur as 1-to-1 alignments (like Sajjad et
al. (2011)) and later refer to them as a list of
word pairs. The unsupervised transliteration min-
ing system trains on the list of word pairs and
mines transliteration pairs. We use the mined pairs
to build a transliteration system using the Moses
toolkit. The transliteration system is used in Algo-
rithm 1 to generate transliteration probabilities of
candidate word pairs and is also used in the post-
processing step to transliterate OOVs.
We run GIZA++ with identical settings as de-
scribed in Section 5.2. We interpolate for ev-
221
GIZA++ TA-GIZA++ OOV-TI
MERT 23.41 23.51 23.60
MIRA 23.60 23.73 23.85
PRO 23.57 23.68 23.70
PROv1 23.65 23.76 23.87
Table 1: BLEU scores of English to Russian ma-
chine translation system evaluated on tst2012 us-
ing baseline GIZA++ alignment and translitera-
tion augmented-GIZA++. OOV-TI presents the
score of the system trained using TA-GIZA++ af-
ter transliterating OOVs
ery iteration of the IBM Model1 and the HMM
model. We had problem in applying smoothing
for Model4 and did not interpolate transliteration
probabilities for Model4. The alignments are re-
fined using the grow-diag-final-and heuristic. We
build a phrase-based system on the aligned pairs
and tune the parameters using PROv1. OOVs are
transliterated in the post-processing step.
5.4 Results
Table 1 summarizes English/Russian results on
tst2012. Improved word alignment gives up to
0.13 BLEU points improvement. PROv1 improves
translation quality and shows 0.08 BLEU point
increase in BLEU in comparison to the parame-
ters tuned using PRO. The transliteration of OOVs
consistently improve translation quality by at least
0.1 BLEU point for all systems.2 This adds to a
cumulative gain of up to 0.2 BLEU points.
We summarize results of our systems trained on
GIZA++ and transliteration augmented-GIZA++
(TA-GIZA++) and tested on tst2012 and tst2013
in Table 2. Both systems use PROv1 for tuning
and transliteration of OOVs in the post-processing
step. The system trained on TA-GIZA++ per-
formed better than the system trained on the base-
line aligner GIZA++.
6 Russian/English Experiments
In this section, we present translation experiments
in Russian to English direction. We morphologi-
cally reduce the Russian side of the parallel data in
a pre-processing step and train the translation sys-
tem on that. We compare its result with the Rus-
sian to English system trained on the un-processed
parallel data.
2We see similar gain in BLEU when using operation se-
quence model (Durrani et al, 2011) for decoding and translit-
erating OOVs in a post-processing step (Durrani et al, 2013).
SYS tst2012 tst2013
GIZA++ 23.76 18.4
TA-GIZA++ 23.87 18.5*
Table 2: BLEU scores of English to Russian ma-
chine translation system evaluated on tst2012 and
tst2013 using baseline GIZA++ alignment and
transliteration augmented-GIZA++ alignment and
post-processed the output by transliterating OOVs.
Human evaluation in WMT13 is performed on
TA-GIZA++ tested on tst2013 (marked with *)
6.1 Morphological Processing
The linguistic processing of Russian involves POS
tagging and morphological reduction. We first tag
the Russian data using a fine grained tagset. The
tagger identifies lemmas and the set of morpholog-
ical attributes attached to each word. We reduce
the number of these attributes by deleting some
of them, that are not relevant for English (for ex-
ample, gender agreement of verbs). This gener-
ates a morphologically reduced Russian which is
used in parallel with English for the training of
the machine translation system. Further details on
the morphological processing of Russian are de-
scribed in Weller et al (2013).
6.1.1 POS Tagging
We use RFTagger (Schmid and Laws, 2008) for
POS tagging. Despite the good quality of tagging
provided by RFTagger, some errors seem to be un-
avoidable due to the ambiguity of certain gram-
matical forms in Russian. A good example of
this is neuter nouns that have the same form in
all cases, or feminine nouns, which have identi-
cal forms in singular genitive and plural nomina-
tive (Sharoff et al, 2008). Since Russian sentences
have free word order, and the case of nouns can-
not be determined on that basis, this imperfection
can not be corrected during tagging or by post-
processing the tagger output.
6.1.2 Morphological Reduction
English in comparison to Slavic group of lan-
guages is morphologically poor. For example, En-
glish has no morphological attributes for nouns
and adjectives to express gender or case; verbs in
English have no gender either. Russian, on the
contrary, has rich morphology. It suffices to say
that the Russian has 6 cases and 3 grammatical
genders, which manifest themselves in different
222
suffixes for nouns, pronouns, adjectives and some
verb forms.
When translating from Russian into English, a
lot of these attributes become meaningless and ex-
cessive. It makes sense to reduce the number of
morphological attributes before the text is sup-
plied for the training of the MT system. We ap-
ply morphological reduction to nouns, pronouns,
verbs, adjectives, prepositions and conjunctions.
The rest of the POS (adverbs, particles, interjec-
tions and abbreviations) have no morphological at-
tributes and are left unchanged.
We apply morphological reduction to train,
tune, development and test data. We refer to this
data set as morph-reduced later on.
6.2 Dataset
We use two variations of the parallel corpus to
build and test the Russian to English system. One
system is built on the data provided by the work-
shop. For the second system, we preprocess the
Russian side of the data as described in Section
6.1. Both the provided parallel corpus and the
morph-reduced parallel corpus consist of 2M par-
allel sentences each. We use them for the estima-
tion of the translation model. We use large train-
ing data for the estimation of monolingual lan-
guage model ? en? 287.3M sentences. We follow
the identical procedure of interpolated language
model as described in Section 5.1. We use new-
stest2012a for tuning and newstest2012b (tst2012)
for development.
6.3 System Settings
We use identical system settings to those described
in Section 5.3. We trained the systems sepa-
rately on GIZA++ and transliteration augmented-
GIZA++ to compare their results. All systems are
tuned using PROv1. The translation output is post-
processed to transliterate OOVs.
6.4 Results
Table 3 summarizes results of Russian to English
machine translation systems trained on the orig-
inal parallel corpus and on the morph-reduced
corpus and using GIZA++ and transliteration
augmented-GIZA++ for word alignment. The sys-
tem using TA-GIZA++ for alignment shows the
best results for both tst2012 and tst2013. The im-
proved alignment gives a BLEU improvement of
up to 0.4 points.
Original corpus
SYS tst2012 tst2013
GIZA++ 32.51 25.5
TA-GIZA++ 33.40 25.9*
Morph-reduced
SYS tst2012 tst2013
GIZA++ 31.22 24.30
TA-GIZA++ 31.40 24.45
Table 3: Russian to English machine translation
system evaluated on tst2012 and tst2013. Human
evaluation in WMT13 is performed on the system
trained using the original corpus with TA-GIZA++
for alignment (marked with *)
The system built on the morph-reduced data
shows degradation in results by 1.29 BLEU points.
However, the percentage of OOVs reduces for
both test sets when using the morph-reduced data
set compared to the original parallel corpus. We
analyze the output of the system and find that the
morph-reduced system makes mistakes in choos-
ing the right tense of the verb. This might be one
reason for poor performance. This implies that the
morphological reduction is slightly damaging the
data, perhaps for specific parts of speech. In the
future, we would like to investigate this issue in
detail.
7 Conclusion
In this paper, we described the QCRI-Munich-
Edinburgh-Stuttgart machine translation systems
submitted to the Eighth Workshop on Statistical
Machine Translation. We aligned the parallel cor-
pus using transliteration augmented-GIZA++ to
improve the word alignments. We built a phrase-
based system using the Moses toolkit. For tun-
ing the feature weights, we used an improvement
of PRO that optimizes for corpus-level BLEU. We
post-processed the output of the machine transla-
tion system to transliterate OOV words.
For the Russian to English system, we mor-
phologically reduced the Russian data in a pre-
processing step. This reduced the vocabulary size
and helped to generate better word alignments.
However, the performance of the SMT system
dropped by 1.29 BLEU points in decoding. We
will investigate this issue further in the future.
223
Acknowledgments
We would like to thank the anonymous reviewers
for their helpful feedback and suggestions. We
would like to thank Philipp Koehn and Barry Had-
dow for providing data and alignments. Nadir
Durrani was funded by the European Union Sev-
enth Framework Programme (FP7/2007-2013) un-
der grant agreement n ? 287658. Alexander Fraser
was funded by Deutsche Forschungsgemeinschaft
grant Models of Morphosyntax for Statistical Ma-
chine Translation. Helmut Schmid was supported
by Deutsche Forschungsgemeinschaft grant SFB
732. This publication only reflects the authors
views.
References
Peter F. Brown, Stephen A. Della Pietra, Vincent J.
Della Pietra, and R. L. Mercer. 1993. The mathe-
matics of statistical machine translation: parameter
estimation. Computational Linguistics, 19(2).
Nadir Durrani, Helmut Schmid, and Alexander Fraser.
2011. A joint sequence translation model with in-
tegrated reordering. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies, Port-
land, USA.
Nadir Durrani, Helmut Schmid, Alexander Fraser, Has-
san Sajjad, and Richa?rd Farkas. 2013. Munich-
Edinburgh-Stuttgart submissions of OSM systems at
WMT13. In Proceedings of the Eighth Workshop on
Statistical Machine Translation, Sofia, Bulgaria.
Mark Hopkins and Jonathan May. 2011. Tuning as
ranking. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing,
Edinburgh, United Kingdom.
Philipp Koehn and Barry Haddow. 2012. Towards
effective use of training data in statistical machine
translation. In Proceedings of the Seventh Work-
shop on Statistical Machine Translation, Montre?al,
Canada.
Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In Proceed-
ings of the Human Language Technology and North
American Association for Computational Linguis-
tics Conference, Edmonton, Canada.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
source toolkit for statistical machine translation. In
Proceedings of the 45th Annual Meeting of the Asso-
ciation for Computational Linguistics, Demonstra-
tion Program, Prague, Czech Republic.
Chin-Yew Lin and Franz Josef Och. 2004. OR-
ANGE: a method for evaluating automatic evalua-
tion metrics for machine translation. In Proceed-
ings of the 20th international conference on Compu-
tational Linguistics, Geneva, Switzerland.
Preslav Nakov, Francisco Guzma?n, and Stephan Vo-
gel. 2012. Optimizing for sentence-level BLEU+1
yields short translations. In Proceedings of the
24th International Conference on Computational
Linguistics, Mumbai, India.
Franz J. Och and Hermann Ney. 2003. A systematic
comparison of various statistical alignment models.
Computational Linguistics, 29(1).
Franz J. Och. 2003. Minimum error rate training in
statistical machine translation. In Proceedings of the
41st Annual Meeting of the Association for Compu-
tational Linguistics, Sapporo, Japan.
Hassan Sajjad, Alexander Fraser, and Helmut Schmid.
2011. An algorithm for unsupervised translitera-
tion mining with an application to word alignment.
In Proceedings of the 49th Annual Conference of
the Association for Computational Linguistics, Port-
land, USA.
Hassan Sajjad, Alexander Fraser, and Helmut Schmid.
2012. A statistical model for unsupervised and
semi-supervised transliteration mining. In Proceed-
ings of the 50th Annual Conference of the Associa-
tion for Computational Linguistics, Jeju, Korea.
Helmut Schmid and Florian Laws. 2008. Estimation
of conditional probabilities with decision trees and
an application to fine-grained pos tagging. In Pro-
ceedings of the 22nd International Conference on
Computational Linguistics - Volume 1, Manchester,
United Kingdom.
Holger Schwenk and Philipp Koehn. 2008. Large and
Diverse Language Models for Statistical Machine
Translation. In International Joint Conference on
Natural Language Processing, Hyderabad, India.
Serge Sharoff, Mikhail Kopotev, Tomaz Erjavec, Anna
Feldman, and Dagmar Divjak. 2008. Designing
and evaluating a russian tagset. In Proceedings of
the Sixth International Conference on Language Re-
sources and Evaluation.
Stephan Vogel, Hermann Ney, and Christoph Tillmann.
1996. HMM-based word alignment in statistical
translation. In 16th International Conference on
Computational Linguistics, Copenhagen, Denmark.
Marion Weller, Max Kisselew, Svetlana Smekalova,
Alexander Fraser, Helmut Schmid, Nadir Durrani,
Hassan Sajjad, and Richa?rd Farkas. 2013. Munich-
Edinburgh-Stuttgart submissions at WMT13: Mor-
phological and syntactic processing for SMT. In
Proceedings of the Eighth Workshop on Statistical
Machine Translation, Sofia, Bulgaria.
224
Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 232?239,
Sofia, Bulgaria, August 8-9, 2013 c?2013 Association for Computational Linguistics
Munich-Edinburgh-Stuttgart Submissions at WMT13:
Morphological and Syntactic Processing for SMT
Marion Weller1, Max Kisselew1, Svetlana Smekalova1, Alexander Fraser2,
Helmut Schmid2, Nadir Durrani3, Hassan Sajjad4, Richa?rd Farkas5
1University of Stuttgart ? (wellermn|kisselmx|smekalsa)@ims.uni-stuttgart.de
2Ludwig-Maximilian University of Munich ? (schmid|fraser)@cis.uni-muenchen.de
3University of Edinburgh ? dnadir@inf.ed.ac.uk
4Qatar Computing Research Institute ? hsajjad@qf.org.qa
5University of Szeged ? rfarkas@inf.u-szeged.hu
Abstract
We present 5 systems of the Munich-
Edinburgh-Stuttgart1 joint submissions to
the 2013 SMT Shared Task: FR-EN, EN-
FR, RU-EN, DE-EN and EN-DE. The
first three systems employ inflectional gen-
eralization, while the latter two employ
parser-based reordering, and DE-EN per-
forms compound splitting. For our ex-
periments, we use standard phrase-based
Moses systems and operation sequence
models (OSM).
1 Introduction
Morphologically complex languages often lead to
data sparsity problems in statistical machine trans-
lation. For translation pairs with morphologically
rich source languages and English as target lan-
guage, we focus on simplifying the input language
in order to reduce the complexity of the translation
model. The pre-processing of the source-language
is language-specific, requiring morphological anal-
ysis (FR, RU) as well as sentence reordering (DE)
and dealing with compounds (DE). Due to time
constraints we did not deal with inflection for DE-
EN and EN-DE.
The morphological simplification process con-
sists in lemmatizing inflected word forms and deal-
ing with word formation (splitting portmanteau
prepositions or compounds). This needs to take
into account translation-relevant features (e.g. num-
ber) which vary across the different language pairs:
while French only has the features number and
gender, a wider array of features needs to be con-
sidered when modelling Russian (cf. table 6). In
addition to morphological reduction, we also apply
transliteration models learned from automatically
1The language pairs DE-EN and RU-EN were developed
in collaboration with the Qatar Computing Research Institute
and the University of Szeged.
mined transliterations to handle out-of-vocabulary
words (OOVs) when translating from Russian.
Replacing inflected word forms with simpler
variants (lemmas or the components of split com-
pounds) aims not only at reducing the general com-
plexity of the translation model, but also at decreas-
ing the amount of out-of-vocabulary words in the
input data. This is particularly the case with Ger-
man compounds, which are very productive and
thus often lack coverage in the parallel training
data, whereas the individual components can be
translated. Similarly, inflected word forms (e.g. ad-
jectives) benefit from the reduction to lemmas if
the full inflection paradigm does not occur in the
parallel training data.
For EN-FR, a translation pair with a morpho-
logically complex target language, we describe a
two-step translation system built on non-inflected
word stems with a post-processing component for
predicting morphological features and the genera-
tion of inflected forms. In addition to the advantage
of a more general translation model, this method
also allows the generation of inflected word forms
which do not occur in the training data.
2 Experimental setup
The translation experiments in this paper are car-
ried out with either a standard phrase-based Moses
system (DE-EN, EN-DE, EN-FR and FR-EN) or
with an operation sequence model (RU-EN, DE-
EN), cf. Durrani et al (2013b) for more details.
An operation sequence model (OSM) is a state-
of-the-art SMT-system that learns translation and
reordering patterns by representing a sentence pair
and its word alignment as a unique sequence of
operations (see e.g. Durrani et al (2011), Durrani
et al (2013a) for more details). For the Moses sys-
tems we used the old train-model perl scripts rather
than the EMS, so we did not perform Good-Turing
smoothing; parameter tuning was carried out with
batch-mira (Cherry and Foster, 2012).
232
1 Removal of empty lines
2 Conversion of HTML special characters like
&quot; to the corresponding characters
3 Unification of words that were written both
with an ? or with an oe to only one spelling
4 Punctuation normalization and tokenization
5 Putting together clitics and apostrophes like
l ? or d ? to l? and d?
Table 1: Text normalization for FR-EN.
Definite determiners la / l? / les ? le
Indefinite determiners un / une ? un
Adjectives Infl. form ? lemma
Portmanteaus e. g. au ? a` le
Verb participles Reduced to
inflected for gender non-inflected
and number verb participle form
ending in e?e/e?s/e?es ending in e?
Clitics and apostroph- d? ? de,
ized words are converted qu? ? que,
to their lemmas n? ? ne, ...
Table 2: Rules for morphological simplification.
The development data consists of the concate-
nated news-data sets from the years 2008-2011.
Unless otherwise stated, we use all constrained data
(parallel and monolingual). For the target-side lan-
guage models, we follow the approach of Schwenk
and Koehn (2008) and train a separate language
model for each corpus and then interpolate them
using weights optimized on development data.
3 French to English
French has a much richer morphology than English;
for example, adjectives in French are inflected with
respect to gender and number whereas adjectives
in English are not inflected at all. This causes data
sparsity in coverage of French inflected forms. We
try to overcome this problem by simplifying French
inflected forms in a pre-processing step in order to
adapt the French input better to the English output.
Processing of the training and test data The
pre-processing of the French input consists of two
steps: (1) normalizing not well-formed data (cf.
table 1) and (2) morphological simplification.
In the second step, the normalized training data
is annotated with Part-of-Speech tags (PoS-tags)
and word lemmas using RFTagger (Schmid and
Laws, 2008) which was trained on the French tree-
bank (Abeille? et al, 2003). French forms are then
simplified according to the rules given in table 2.
Data and experiments We trained a French to
English Moses system on the preprocessed and
System BLEU (cs) BLEU (ci)
Baseline 29.90 31.02
Simplified French* 29.70 30.83
Table 3: Results of the French to English system
(WMT-2012). The marked system (*) corresponds
to the system submitted for manual evaluation. (cs:
case-sensitive, ci: case-insensitive)
simplified constrained parallel data.
Due to tractability problems with word align-
ment, the 109 French-English corpus and the UN
corpus were filtered to a more manageable size.
The filtering criteria are sentence length (between
15 and 25 words), as well as strings indicating that
a sentence is neither French nor English, or other-
wise not well-formed, aiming to obtain a subset of
good-quality sentences. In total, we use 9M par-
allel sentences. For the English language model
we use large training data with 287.3M true-cased
sentences (including the LDC Giga-word data).
We compare two systems: a baseline with reg-
ular French text, and a system with the described
morphological simplifications. Results for the
WMT-2012 test set are shown in table 3. Even
though the baseline is better than the simplified
system in terms of BLEU, we assume that the trans-
lation model of the simplified system benefits from
the overall generalization ? thus, human annotators
might prefer the output of the simplified system.
For the WMT-2013 set, we obtain BLEU scores
of 29,97 (cs) and 31,05 (ci) with the system built
on simplified French (mes-simplifiedfrench).
4 English to French
Translating into a morphologically rich language
faces two problems: that of asymmetry of mor-
phological information contained in the source and
target language and that of data sparsity.
In this section we describe a two-step system de-
signed to overcome these types of problems: first,
the French data is reduced to non-inflected forms
(stems) with translation-relevant morphological fea-
tures, which is used to built the translation model.
The second step consists of predicting all neces-
sary morphological features for the translation out-
put, which are then used to generate fully inflected
forms. This two-step setup decreases the complex-
ity of the translation task by removing language-
specific features from the translation model. Fur-
thermore, generating inflected forms based on word
stems and morphological features allows to gener-
233
ate forms which do not occur in the parallel training
data ? this is not possible in a standard SMT setup.
The idea of separating the translation into two
steps to deal with complex morphology was in-
troduced by Toutanova et al (2008). Fraser et
al. (2012) applied this method to the language
pair English-German with an additional special
focus on word formation issues such as the split-
ting and merging of portmanteau prepositions and
compounds. The presented inflection prediction
systems focuses on nominal inflection; verbal in-
flection is not addressed.
Morphological analysis and resources The
morphological analysis of the French training data
is obtained using RFTagger, which is designed
for annotating fine-grained morphological tags
(Schmid and Laws, 2008). For generating inflected
forms based on stems and morphological features,
we use an extended version of the finite-state mor-
phology FRMOR (Zhou, 2007). Additionally, we
use a manually compiled list of abbreviations and
named entities (names of countries) and their re-
spective grammatical gender.
Stemming For building the SMT system, the
French data (parallel and monolingual) is trans-
formed into a stemmed representation. Nouns,
i.e. the heads of NPs or PPs, are marked with
inflection-relevant features: gender is considered
as part of the stem, whereas number is determined
by the source-side input: for example, we expect
source-language words in plural to be translated by
translated by stems with plural markup. This stem-
markup is necessary in order to guarantee that the
number information is not lost during translation.
For a better generalization, portmanteaus are split
into separate parts: au? a`+le (meaning, ?to the?).
Predicting morphological features For predict-
ing the morphological features of the SMT output
(number and gender), we use a linear chain CRF
(Lavergne et al, 2010) trained on data annotated
with these features using n-grams of stems and part-
of-speech tags within a window of 4 positions to
each side of the current word. Through the CRF,
the values specified in the stem-markup (number
and gender on nouns) are propagated over the rest
of the linguistic phrase, as shown in column 2 of
table 4. Based on the stems and the morphological
features, inflected forms can be generated using
FRMOR (column 3).
Post-processing As the French data has been
normalized, a post-processing step is needed in or-
der to generate correct French surface forms: split
portmanteaus are merged into their regular forms
based on a simple rule set. Furthermore, apostro-
phes are reintroduced for words like le, la, ne, ... if
they are followed by a vowel. Column 4 in table 4
shows post-processing including portmanteau for-
mation. Since we work on lowercased data, an
additional recasing step is required.
Experiments and evaluation We use the same
set of reduced parallel data as the FR-EN system;
the language model is built on 32M French sen-
tences. Results for the WMT-2012 test set are given
in table 5. Variant 1 shows the results for a small
system trained only on a part of the training data
(Europarl+News Commentary), whereas variant 2
corresponds to the submitted system. A small-scale
analysis indicated that the inflection prediction sys-
tem tends to have problems with subject-verb agree-
ment. We trained a factored system using addi-
tional PoS-tags with number information which
lead to a small improvement on both variants.
While the small model is significantly better than
the baseline2 as it benefits more from the general-
ization, the result for the full system is worse than
the baseline3. Here, given the large amount of
data, the generalization effect has less influence.
However, we assume that the more general model
from the inflection prediction system produces bet-
ter translations than a regular model containing a
large amount of irrelevant inflectional information,
particularly when considering that it can produce
well-formed inflected sequences that are inaccessi-
ble to the baseline. Even though this is not reflected
in terms of BLEU, humans might prefer the inflec-
tion prediction system.
For the WMT-2013 set, we obtain BLEU scores
of 29.6 (ci) and 28.30 (cs) with the inflection pre-
diction system mes-inflection (marked in table 5).
5 Russian-English
The preparation of the Russian data includes the
following stages: (1) tokenization and tagging and
(2) morphological reduction.
Tagging and tagging errors For tagging, we use
a version of RFTagger (Schmid and Laws, 2008)
2Pairwise bootstrap resampling with 1000 samples.
3However, the large inflection-prediction system has a
slightly better NIST score than the baseline (7.63 vs. 7.61).
234
SMT-output predicted generated after post- gloss
with stem-markup in bold print features forms processing
avertissement<Masc><Pl>[N] Masc.Pl avertissements avertissements warnings
sinistre[ADJ] Masc.Pl sinistres sinistres dire
de[P] ? de du from
le[ART] Masc.Sg le the
pentagone<Masc><Sg>[N] Masc.Sg pentagone pentagone pentagon
sur[P] ? sur sur over
de[P] ? de d? of
e?ventuel[ADJ] Fem.Pl e?ventuelles e?ventuelles potential
re?duction<Fem><Pl>[N] Fem.Pl re?ductions re?ductions reductions
de[P] ? de du of
le[ART] Masc.Sg le the
budget<Masc><Sg>[N] Masc.Sg budget budget budget
de[P] ? de de of
le[ART] Fem.Sg la la the
de?fense<Fem><Sg>[N] Fem.Sg de?fense de?fense de?fense
Table 4: Processing steps for the input sentence dire warnings from pentagon over potential defence cuts.
that has been developed based on data tagged with
TreeTagger (Schmid, 1994) using a model from
Sharoff et al (2008). The data processed by Tree-
Tagger contained errors such as wrong definition
of PoS for adverbs, wrong selection of gender for
adjectives in plural and missing features for pro-
nouns and adverbs. In order to train RFTagger, the
output of TreeTagger was corrected with a set of
empirical rules. In particular, the morphological
features of nominal phrases were made consistent
to train RFTagger: in contrast to TreeTagger, where
morphological features are regarded as part of the
PoS-tag, RFTagger allows for a separate handling
of morphological features and POS tags.
Despite a generally good tagging quality, some
errors seem to be unavoidable due to the ambiguity
of certain grammatical forms in Russian. A good
example of this are neuter nouns that have the same
form in all cases, or feminine nouns, which have
identical forms in singular genitive and plural nom-
inative (Sharoff et al, 2008). Since Russian has no
binding word order, and the case of nouns cannot
be determined on that basis, such errors cannot be
corrected with empirical rules implemented as post-
System BLEU (ci) BLEU (cs)
1 Baseline 24.91 23.40
InflPred 25.31 23.81
InflPred-factored 25.53 24.04
2 Baseline 29.32 27.65
InflPred* 29.07 27.40
InflPred-factored 29.17 27.46
Table 5: Results for French inflection prediction
on the WMT-2012 test set. The marked system (*)
corresponds to the system submitted for manual
evaluation.
processing. Similar errors occur when specifying
the case of adjectives, since the suffixes of adjec-
tives are even less varied as compared to the nouns.
In our application, we hope that this type of error
does not affect the result due to the following sup-
pression of a number of morphological attributes
including the case of adjectives.
Morphological reduction In comparison to
Slavic languages, English is morphologically poor.
For example, English has no morphological at-
tributes for nouns and adjectives to express gender
or case; verbs have no gender either. In contrast,
Russian is morphologically very rich ? there are
e.g. 6 cases and 3 grammatical genders, which
manifest themselves in different suffixes for nouns,
pronouns, adjectives and some verb forms. When
translating from Russian into English, many of
these attributes are (hopefully) redundant and are
therefore deleted from the training data. The mor-
phological reduction in our system was applied to
nouns, pronouns, verbs, adjectives, prepositions
and conjunctions. The rest of the POS (adverbs,
particles, interjections and abbreviations) have no
morphological attributes. The list of the original
and the reduced attributes is given in Table 6.
Transliteration mining to handle OOVs The
machine translation system fails to translate out-of-
vocabulary words (OOVs) as they are unknown to
the training data. Most of the OOVs are named en-
tities and transliterating them to the target language
script could solve this problem. The transliteration
system requires a list of transliteration pairs for
training. As we do not have such a list, we use
the unsupervised transliteration mining system of
Sajjad et al (2012) that takes a list of word pairs for
235
Part of Attributes Reduced
Speech RFTagger attributes
Noun Type Type
Gender Gender
Number Number
Case Case
nom,gen,dat,acc,instr,prep gen,notgen
Animate
Case 2
Pronoun Person Person
Gender Gender
Number Number
Case Case
nom,gen,dat,acc,instr,prep nom,notnom
Syntactic type
Animated
Verb Type Type
VForm VForm
Tense Tense
Person Person
Number Number
Gender
Voice Voice
Definiteness
Aspect Aspect
Case
Adjec- Type Type
tive Degree Degree
Gender
Number
Case
Definiteness
Prep- Type
osition Formation
Case
Conjunc- Type Type
tion Formation Formation
Table 6: Rules for simplifying the morphological
complexity for RU.
training and extracts transliteration pairs that can
be used for the training of the transliteration system.
The procedure of mining transliteration pairs and
transliterating OOVs is described as follows: We
word-align the parallel corpus using GIZA++ and
symmetrize the alignments using the grow-diag-
final-and heuristic. We extract all word pairs which
occur as 1-to-1 alignments (Sajjad et al, 2011) and
later refer to them as a list of word pairs. We train
the unsupervised transliteration mining system on
the list of word pairs and extract transliteration
pairs. We use these mined pairs to build a transliter-
ation system using the Moses toolkit. The translit-
eration system is applied as a post-processing step
to transliterate OOVs.
The morphological reduction of Russian (cf. sec-
tion 5) does not process most of the OOVs as they
are also unknown to the POS tagger. So OOVs that
we get are in their original form. When translit-
Original corpus
SYS WMT-2012 WMT-2013
GIZA++ 32.51 25.5
TA-GIZA++ 33.40 25.9*
Morph-reduced
SYS WMT-2012 WMT-2013
GIZA++ 31.22 24.3
TA-GIZA++ 31.40 24.45
Table 7: Russian to English machine translation
system evaluated on WMT-2012 and WMT-2013.
Human evaluation in WMT13 is performed on the
system trained using the original corpus with TA-
GIZA++ for alignment (marked with *).
erating them, the inflected forms generate wrong
English transliterations as inflectional suffixes get
transliterated too, specially OOV named entities.
We solved this problem by stemming the OOVs
based on a list of suffixes ( , , , , , ) and
transliterating the stemmed forms.
Experiments and results We trained the sys-
tems separately on GIZA++ and transliteration
augmented-GIZA++ (TA-GIZA++) to compare
their results; for more details see Sajjad et al
(2013). All systems are tuned using PROv1 (Nakov
et al, 2012). The translation output is post-
processed to transliterate OOVs.
Table 7 summarizes the results of RU-EN trans-
lation systems trained on the original corpus and
on the morph-reduced corpus. Using TA-GIZA++
alignment gives the best results for both WMT-
2012 and WMT-2013, leading to an improvement
of 0.4 BLEU points.
The system built on the morph-reduced data
leads to decreased BLEU results. However, the per-
centage of OOVs is reduced for both test sets when
using the morph-reduced data set compared to the
original data. An analysis of the output showed
that the morph-reduced system makes mistakes in
choosing the right tense of the verb, which might
be one reason for this outcome. In the future, we
would like to investigate this issue in detail.
6 German to English and English to
German
We submitted systems for DE-EN and EN-DE
which used constituent parses for pre-reordering.
For DE-EN we also deal with word formation is-
sues such as compound splitting. We did not per-
form inflectional normalization or generation for
German due to time constraints, instead focusing
236
our efforts on these issues for French and Russian
as previously described.
German to English German has a wider diver-
sity of clausal orderings than English, all of which
need to be mapped to the English SVO order. This
is a difficult problem to solve during inference, as
shown for hierarchical SMT by Fabienne Braune
and Fraser (2012) and for phrase-based SMT by
Bisazza and Federico (2012).
We syntactically parsed all of the source side
sentences of the parallel German to English data
available, and the tuning, test and blindtest sets.
We then applied reordering rules to these parses.
We use the rules for reordering German constituent
parses of Collins et al (2005) together with the
additional rules described by Fraser (2009). These
are applied as a preprocess to all German data.
For parsing the German sentences, we used the
generative phrase-structure parser BitPar with opti-
mizations of the grammar, as described by Fraser
et al (2013). The parser was trained on the Tiger
Treebank (Brants et al, 2002) along with utilizing
the Europarl corpus as unlabeled data. At the train-
ing of Bitpar, we followed the targeted self-training
approach (Katz-Brown et al, 2011) as follows. We
parsed the whole Europarl corpus using a grammar
trained on the Tiger corpus and extracted the 100-
best parse trees for each sentence. We selected the
parse tree among the 100 candidates which got the
highest usefulness scores for the reordering task.
Then we trained a new grammar on the concatena-
tion of the Tiger corpus and the automatic parses
from Europarl.
The usefulness score estimates the value of a
parse tree for the reordering task. We calculated
this score as the similarity between the word order
achieved by applying the parse tree-based reorder-
ing rules of Fraser (2009) and the word order indi-
cated by the automatic word alignment between
the German and English sentences in Europarl.
We used the Kendall?s Tau Distance as the simi-
larity metric of two word orderings (as suggested
by Birch and Osborne (2010)).
Following this, we performed linguistically-
informed compound splitting, using the system of
Fritzinger and Fraser (2010), which disambiguates
competing analyses from the high-recall Stuttgart
Morphological Analyzer SMOR (Schmid et al,
2004) using corpus statistics. We also split German
portmanteaus like zum? zu dem (meaning to the).
system BLEU BLEU system name
(ci) (cs)
DE-EN (OSM) 27.60 26.12 MES
DE-EN (OSM) 27.48 25.99 not submitted
BitPar not self-trained
DE-EN (Moses) 27.14 25.65 MES-Szeged-
reorder-split
DE-EN (Moses) 26.82 25.36 not submitted
BitPar not self-trained
EN-DE (Moses) 19.68 18.97 MES-reorder
Table 8: Results on WMT-2013 (blindtest)
English to German The task of mapping En-
glish SVO order to the different clausal orders in
German is difficult. For our English to German
systems, we solved this by parsing the English and
applying the system of Gojun and Fraser (2012) to
reorder English into the correct German clausal or-
der (depending on the clause type which is detected
using the English parse, see (Gojun and Fraser,
2012) for further details).
We primarily used the Charniak-Johnson gener-
ative parser (Charniak and Johnson, 2005) to parse
the English Europarl data and the test data. How-
ever, due to time constraints we additionally used
Berkeley parses of about 400K Europarl sentences
and the other English parallel training data. We
also left a small amount of the English parallel
training data unparsed, which means that it was
not reordered. For tune, test and blindtest (WMT-
2013), we used the Charniak-Johnson generative
parser.
Experiments and results We used all available
training data for constrained systems; results for
the WMT-2013 set are given in table 8. For the
contrastive BitPar results, we reparsed WMT-2013.
7 Conclusion
We presented 5 systems dealing with complex mor-
phology. For two language pairs with a morpho-
logically rich source language (FR and RU), the
input was reduced to a simplified representation
containing only translation-relevant morphologi-
cal information (e.g. number on nouns). We also
used reordering techniques for DE-EN and EN-DE.
For translating into a language with rich morphol-
ogy (EN-FR), we applied a two-step method that
first translates into a stemmed representation of
the target language and then generates inflected
forms based on morphological features predicted
on monolingual data.
237
Acknowledgments
We would like to thank the anonymous reviewers
for their helpful feedback and suggestions, Daniel
Quernheim for providing Berkeley parses of some
of the English data, Stefan Ru?d for help with the
manual evalution, and Philipp Koehn and Barry
Haddow for providing data and alignments.
Nadir Durrani was funded by the European
Union Seventh Framework Programme (FP7/2007-
2013) under grant agreement n. 287658. Alexan-
der Fraser was funded by Deutsche Forschungs-
gemeinschaft grant Models of Morphosyntax for
Statistical Machine Translation and from the Eu-
ropean Community?s Seventh Framework Pro-
gramme (FP7/2007-2013) under Grant Agreement
n. 248005. Marion Weller was funded from the
European Community?s Seventh Framework Pro-
gramme (FP7/2007-2013) under Grant Agreement
n. 248005. Svetlana Smekalova was funded by
Deutsche Forschungsgemeinschaft grant Models
of Morphosyntax for Statistical Machine Trans-
lation. Helmut Schmid and Max Kisselew were
supported by Deutsche Forschungsgemeinschaft
grant SFB 732. Richa?rd Farkas was supported by
the European Union and the European Social Fund
through project FuturICT.hu (grant n. TA?MOP-
4.2.2.C-11/1/KONV-2012-0013). This publication
only reflects the authors? views.
References
A. Abeille?, L. Cle?ment, and F. Toussenel. 2003. Build-
ing a treebank for french. In A. Abeille?, editor, Tree-
banks. Kluwer, Dordrecht.
Alexandra Birch and Miles Osborne. 2010. Lrscore for
evaluating lexical and reordering quality in mt. In
Proceedings of ACL WMT and MetricsMATR, Upp-
sala, Sweden.
Arianna Bisazza and Marcello Federico. 2012. Mod-
ified distortion matrices for phrase-based statistical
machine translation. In ACL, pages 478?487.
Sabine Brants, Stefanie Dipper, Silvia Hansen, Wolf-
gang Lezius, and George Smith. 2002. The TIGER
treebank. In Proceedings of the Workshop on Tree-
banks and Linguistic Theories.
Eugene Charniak and Mark Johnson. 2005. Coarse-
to-fine n-best parsing and MaxEnt discriminative
reranking. In ACL, pages 173?180, Ann Arbor, MI,
June. Association for Computational Linguistics.
Colin Cherry and George Foster. 2012. Batch tuning
strategies for statistical machine translation. In Pro-
ceedings of the North American Chapter of the Asso-
ciation for Computational Linguistics (NAACL).
Michael Collins, Philipp Koehn, and Ivona Kuc?erova?.
2005. Clause restructuring for statistical machine
translation. In Porceedings of ACL 2005.
Nadir Durrani, Helmut Schmid, and Alexander Fraser.
2011. A Joint Sequence Translation Model with In-
tegrated Reordering. In Proceedings of ACL-HLT
2011, Portland, Oregon, USA.
Nadir Durrani, Alexander Fraser, and Helmut Schmid.
2013a. Model With Minimal Translation Units, But
Decode With Phrases. In Proceedings of NAACL
2013, Atlanta, Georgia, USA.
Nadir Durrani, Helmut Schmid, Alexander Fraser, Has-
san Sajjad, and Richa?rd Farkas. 2013b. Munich-
Edinburgh-Stuttgart Submissions of OSM Systems
at WMT13. In Proceedings of the Eighth Workshop
on Statistical Machine Translation, Sofia, Bulgaria.
Anita Gojun Fabienne Braune and Alexander Fraser.
2012. Long-distance reordering during search for
hierarchical phrase-based SMT. In Proceedings of
EAMT 2012.
Alexander Fraser, Marion Weller, Aoife Cahill, and Fa-
bienne Cap. 2012. Modeling Inflection and Word-
Formation in SMT. In Proceedings of EACL 2012,
Avignon, France.
Alexander Fraser, Helmut Schmid, Richa?rd Farkas,
Renjing Wang, and Hinrich Schu?tze. 2013. Knowl-
edge sources for constituent parsing of German, a
morphologically rich and less-configurational lan-
guage. Computational Linguistics - to appear.
Alexander Fraser. 2009. Experiments in morphosyn-
tactic processing for translating to and from German.
In EACL WMT.
Fabienne Fritzinger and Alexander Fraser. 2010. How
to avoid burning ducks: Combining linguistic analy-
sis and corpus statistics for German compound pro-
cessing. In ACL WMT and Metrics MATR.
Anita Gojun and Alexander Fraser. 2012. Determin-
ing the placement of German verbs in English-to-
German SMT. In Proceedings of EACL 2012.
Jason Katz-Brown, Slav Petrov, Ryan McDon-
ald, Franz Och, David Talbot, Hiroshi Ichikawa,
Masakazu Seno, and Hideto Kazawa. 2011. Train-
ing a parser for machine translation reordering. In
Proceedings of EMNLP 2011, Edinburgh, Scotland.
Thomas Lavergne, Olivier Cappe?, and Franc?ois Yvon.
2010. Practical very large scale CRFs. In Proceed-
ings of ACL 2010, pages 504?513.
Preslav Nakov, Francisco Guzma?n, and Stephan Vo-
gel. 2012. Optimizing for sentence-level BLEU+1
yields short translations. Mumbai, India.
238
Hassan Sajjad, Alexander Fraser, and Helmut Schmid.
2011. An algorithm for unsupervised transliteration
mining with an application to word alignment. In
Proceedings of ACL 2011, Portland, USA.
Hassan Sajjad, Alexander Fraser, and Helmut Schmid.
2012. A statistical model for unsupervised and semi-
supervised transliteration mining. In Proceedings of
ACL 2012, Jeju, Korea.
Hassan Sajjad, Svetlana Smekalova, Nadir Durrani,
Alexander Fraser, and Helmut Schmid. 2013.
QCRI-MES Submission at WMT13: Using Translit-
eration Mining to Improve Statistical Machine
Translation. In Proceedings of the Eighth Workshop
on Statistical Machine Translation, Sofia, Bulgaria.
Helmut Schmid and Florian Laws. 2008. Estimation
of conditional probabilities with decision trees and
an application to fine-grained pos tagging. In Pro-
ceedings of COLING 2008, Stroudsburg, PA, USA.
Helmut Schmid, Arne Fitschen, and Ulrich Heid. 2004.
SMOR: a German Computational Morphology Cov-
ering Derivation, Composition, and Inflection. In
Proceedings of LREC 2004.
Helmut Schmid. 1994. Probabilistic part-of-speech
tagging using decision trees. In Proceedings of the
International Conference on New Methods in Lan-
guage Processing.
Holger Schwenk and Philipp Koehn. 2008. Large
and diverse language models for statistical machine
translation. In Proceedings of IJCNLP 2008.
Serge Sharoff, Mikhail Kopotev, Tomaz Erjavec, Anna
Feldman, and Dagmar Divjak. 2008. Designing and
evaluating russian tagsets. In Proceedings of LREC
2008.
Kristina Toutanova, Hisami Suzuki, and Achim Ruopp.
2008. Applying Morphology Generation Models to
Machine Translation. In Proceedings of ACL-HLT
2008.
Zhenxia Zhou. 2007. Entwicklung einer franzo?sischen
Finite-State-Morphologie. Diploma Thesis, Insti-
tute for Natural Language Processing, University of
Stuttgart.
239
