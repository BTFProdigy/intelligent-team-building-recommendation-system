Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 13?18,
Baltimore, Maryland USA, June 23-24, 2014.
c?2014 Association for Computational Linguistics
Open-Source Tools for Morphology, Lemmatization, POS Tagging
and Named Entity Recognition
Jana Strakov
?
a and Milan Straka and Jan Haji
?
c
Charles University in Prague
Faculty of Mathematics and Physics
Institute of Formal and Applied Linguistics
{strakova,straka,hajic}@ufal.mff.cuni.cz
Abstract
We present two recently released open-
source taggers: NameTag is a free soft-
ware for named entity recognition (NER)
which achieves state-of-the-art perfor-
mance on Czech; MorphoDiTa (Morpho-
logical Dictionary and Tagger) performs
morphological analysis (with lemmatiza-
tion), morphological generation, tagging
and tokenization with state-of-the-art re-
sults for Czech and a throughput around
10-200K words per second. The taggers
can be trained for any language for which
annotated data exist, but they are specifi-
cally designed to be efficient for inflective
languages, Both tools are free software
under LGPL license and are distributed
along with trained linguistic models which
are free for non-commercial use under the
CC BY-NC-SA license. The releases in-
clude standalone tools, C++ libraries with
Java, Python and Perl bindings and web
services.
1 Introduction
Morphological analysis, part-of-speech tagging
and named entity recognition are one of the most
important components of computational linguistic
applications. They usually represent initial steps
of language processing. It is no wonder then that
they have received a great deal of attention in the
computational linguistics community and in some
respect, these tasks can even be considered very
close to being ?solved?.
However, despite the fact that there is a consid-
erable number of POS taggers available for En-
glish and other languages with a large number of
active users, we lacked a POS tagger and NE rec-
ognizer which would
? be well suited and trainable for languages
with very rich morphology and thus a large
tagset of possibly several thousand plausible
combinations of morphologically related at-
tribute values,
? provide excellent, preferably state-of-the-art
results for Czech,
? be distributed along with trained linguistic
models for Czech,
? allow the user to train custom models for any
language,
? be extremely efficient in terms of RAM and
disc usage to be used commercially,
? offer a full end-to-end solution for users with
little computational linguistics background,
? be distributed as a library without additional
dependencies,
? offer API in many programming languages,
? be open-source, free software.
Following these requirements, we have devel-
oped a morphological dictionary and tagger soft-
ware, which is described and evaluated in Sec-
tion 3; and a named entity recognizer, which is de-
scribed and evaluated in Section 4. The software
performance and resource usage are described in
Section 5 and the release and licensing condition
information is given in Section 6. We conclude the
paper in Section 7.
2 Related Work
2.1 POS Tagging
In English, the task of POS tagging has been in
the center of computational linguists? attention for
decades (Kucera and Francis, 1967), with renewed
interest after significant improvements achieved
by (Collins, 2002). The recent state-of-the-art for
English POS supervised tagging without external
data for training is by (Shen et al., 2007) and there
are many available taggers, such as well-known
Brill tagger (Brill, 1992), TnT tagger (Brants,
2000) and many others.
13
In Czech, the POS tagging research has been
carried out mostly by Czech speaking linguistic
community and the current state-of-the-art was re-
ported by (Spoustov?a et al., 2009) in Mor?ce re-
search project
1
. Based on this project, two taggers
were released: Mor?ce tagger (released as part of
COMPOST
2
containing morphological analyzer,
tagger and trained models, available to registered
users only) and Featurama
3
(source code only, no
trained models publicly available).
2.2 Named Entity Recognition
For English, many NE datasets and shared tasks
exist, e.g. CoNLL-2003 (Tjong Kim Sang and
De Meulder, 2003), MUC7 (Chinchor, 1998).
These shared tasks and the associated freely avail-
able NE annotated corpora allowed wide and suc-
cessful research in NE recognition in English. For
example, the systems which published high scores
on the CoNLL-2003 task include (Suzuki and
Isozaki, 2008), (Ando and Zhang, 2005) and to our
knowledge, the best currently known results on
this dataset were published by (Ratinov and Roth,
2009). One should also mention a well-known and
widely used Stanford parser (Finkel et al., 2005).
In Czech, the referential corpus for NE recog-
nition is called the Czech Named Entity Corpus
4
(
?
Sev?c??kov?a et al., 2007) and we describe its? prop-
erties further in Section 4.2. The development of
the Czech NE recognition research is easy to fol-
low: started by a pilot project by (
?
Sev?c??kov?a et al.,
2007), the results were improved by (Kravalov?a
and
?
Zabokrtsk?y, 2009), (Konkol and Konop??k,
2011) and (Konkol and Konop??k, 2013). The cur-
rent state-of-the-art results for CNEC are reported
by (Strakov?a et al., 2013). So far, there was no
freely available Czech NE recognizer.
3 MorphoDiTa: Morphological
Dictionary and Tagger
3.1 Morphological Dictionary Methodology
The morphological dictionary is specially de-
signed for inflective languages with large number
of suffixes (endings) and we propose an effective
method for handling rich morphology.
In inflective languages,
5
words take endings
1
http://ufal.mff.cuni.cz/morce/index.php
2
http://ufal.mff.cuni.cz/compost/
3
http://sourceforge.net/projects/featurama/
4
http://ufal.mff.cuni.cz/cnec/
5
In the following, we describe features of a core group
of inflective languages, such as Slavic languages of all types.
(suffixes) to mark linguistic cases, grammatical
number, gender etc. Therefore, many forms may
be related to one lemma. For example, the lemma
?zelen?y? (?green? in Czech) can appear as ?ze-
len?y?, ?zelen?ej?s???, ?zelen?emu? etc. ? there are
several tens of forms for this type of adjective.
Corpus-wise, there are 168K unique forms and
72K lemmas in a corpus of 2M words (Prague De-
pendency Treebank 2.5 (Bej?cek et al., 2012)) in
Czech. It is therefore crucial to handle the end-
ings effectively and to reduce the processing costs
where regularities are found.
Given a resource with forms, lemmas and tags,
6
MorphoDiTa estimates regular patterns based on
common form endings and automatically clusters
them into morphological ?templates? without
linguistic knowledge about the language. We now
describe the method for template set creation.
During template set creation, MorphoDiTa
takes lemmas one by one. For each lemma, it
collects all corresponding forms and builds a trie
(De La Briandais, 1959; Knuth, 1997). Trie is a
tree structure in which one character corresponds
to a node and all descendants of a node share the
same prefix. The procedure then finds a suitable
common ancestor in the trie (common prefix or
stem). The heuristics is ?such a node whose sub-
tree has depth at most N and at the same time has
the maximal number of ancestors with one child?.
Intuitively, this means we want to select a long
prefix (stem) ? hence ?maximal number of ances-
tors? but at the same time, the linguistic endings
are not too long (at most N ). Having selected a
common prefix, all the endings (including their
corresponding tags) in its subtree define a tem-
plate. A rich trie with many subtrees may be split
into multiple templates. For example, a simple trie
for noun ?hrad? (?castle? in Czech) with one tem-
plate, and also two lemmas sharing two templates
are shown in Fig. 1. When processing the next
lemma and its corresponding forms, either new
template is created, or the templates are reused if
the set of endings is the same. Larger N leads to
longer endings and larger number of classes, and
smaller N leads to short endings and less classes.
7
Sometimes, the word ?inflective? is used also for agglutina-
tive languages such as Turkish, Hungarian or Finnish; we be-
lieve our tools are suitable for these, too, but we have not
tested them on this group yet.
6
In Czech, the resource used was Morfflex CZ by Jan
Haji?c: http://ufal.mff.cuni.cz/morfflex.
7
Our morphological dictionary representation cannot be
replaced with a minimized finite state automaton with marked
14
The number of templates determines the effi-
ciency of dictionary encoding. When too few tem-
plates are used, many are needed to represent a
lemma. When too many are used, the representa-
tion of the templates themselves is large.
The morphological dictionary is then saved in
binary form and the software offers a higher level
access: given a form, morphological analysis lists
all possible lemma-tag pairs; given a lemma-tag
pair, MorphoDiTa generates the respective form.
The analysis function is then used in tagging,
which we describe in the next section.
The heuristics described above does not require
linguistic knowledge about the language and han-
dles linguistic regularities very well. The major
advantage is a significant data compression lead-
ing to efficient resource usage: in our setting, the
original morphology dictionary, the Czech Morf-
flex, contains 120M form-tag pairs derived from
1M unique lemmas, using 3 922 different tags, of
total size 6.7GB.
8
Using the proposed heuristics
with N = 8, there are 7 080 templates created,
such that the whole dictionary is encoded using
3M template instances. The resulting binary form
of the dictionary uses 2MB, which is 3 000 times
smaller than the original dictionary.
In order to look up a word form in the dictio-
nary, we split it into a prefix and an ending for
all ending lengths from 1 to N . We then find
templates associated with both the prefix and the
ending. For each such template, we return the
lemma corresponding to the prefix and the tag cor-
responding to the ending. The result is a set of
lemma-tag pairs found during this procedure. This
algorithm can be implemented efficiently ? our
implementation performs 500k word form lookups
per second in the Czech morphological dictionary.
3.2 POS Tagger Methodology
The POS tagger is an offspring of Mor?ce and Fea-
turama research projects based on (Spoustov?a et
al., 2009). For each form in the text, the mor-
phological dictionary suggests all possible lemma-
tag candidates and these lemma-tag pairs are dis-
ambiguated by the tagger. The tagger is imple-
mented as supervised, rich feature averaged per-
ceptron (Collins, 2002) and the classification fea-
tures are adopted from (Spoustov?a et al., 2009).
lemmas, because the process of minimization cannot capture
templates containing word forms (or their prefixes) of multi-
ple lemmas.
8
Which compresses to 454MB using gzip -9.
h
r
a
d
a e ? u ? y
m
a
c m
h
m m
 
b
r
a?
nn
 
l
i?
pp
a ? ? o u y
m
ai
cm
h
u
a ? o
m
i
c m
h
u
Figure 1: A simple trie for noun ?hrad? (castle in
Czech), and two lemmas sharing templates.
Czech language was trained on the training part
of the Prague Dependency Treebank 2.5 (Bej?cek
et al., 2012). The English language was trained
on the standard training portion (Sections 0-18) of
the Wall Street Journal part of the Penn Treebank
(Marcus et al., 1993). In both cases, the system
was tuned on the development set (Sections 19-21
in PTB/WSJ in English) and tested on the testing
section (Sections 22-24 in PTB/WSJ in English).
3.3 POS Tagger Evaluation
An evaluation of POS taggers, which do not use
external data, is shown in Table 1 for Czech and in
Table 2 for English. MorphoDiTa reaches state-of-
the-art results for Czech and nearly state-of-the-
art results for English. The results are very simi-
lar for the three Czech systems, Mor?ce, Featurama
and MorphoDiTa, because in all three cases, they
are implementations of (Spoustov?a et al., 2009).
However, MorphoDiTa is the first end-to-end ap-
plication released under a free license.
Due to rich morphosyntactic complexity of the
Czech language and the positional tagging scheme
proposed by (Haji?c, 2004), there are 3 922 plausi-
ble tags in Czech (although only 1 571 unique tags
actually appear in training data).
However, in many applications, only the first
two tagging positions, which correspond to POS
and sub-POS,
9
are actually needed for further pro-
cessing, which greatly reduces the complexity of
the task, leaving only 67 possible tags (64 in train-
ing data), although some morphological informa-
tion, such as case, is lost.
9
Sub-POS is detailed set of POS labels, which includes
basic properties such as the type of pronouns, conjunctions,
adjectives, also some tense and active/passive/mood informa-
tion for verbs, etc.
15
Tagger Task Accuracy
Mor?ce tag 95.67%
Featurama tag 95.66%
MorphoDiTa tag 95.75%
MorphoDiTa lemma 97.80%
MorphoDiTa lemma+tag 95.03%
MorphoDiTa tag-first two pos. 99.18%
Table 1: Evaluation of Czech POS taggers.
Tagger Accuracy
Mor?ce (Spoustov?a et al., 2009) 97.23%
(Shen et al., 2007) 97.33%
MorphoDiTa 97.27%
Table 2: Evaluation of the English taggers.
An example of a full 15-position tag and the re-
stricted 2-position tag for an adjective ?zelen?y? is
?AAIS1----1A----? and ?AA?, respectively.
The first two positions are in fact quite similar
to what the Penn-style tags encode (for English).
MorphoDiTa therefore also offers models trained
on such a restricted tagging scheme. The tag-
ger evaluation for the 2-position, restricted tags is
given in the last row of Table 1.
4 NameTag: Named Entity Recognizer
4.1 NER Methodology
The NE recognizer is an implementation of a re-
search project by (Strakov?a et al., 2013). The rec-
ognizer is based on a Maximum Entropy Markov
Model. First, maximum entropy model predicts,
for each word in a sentence, the full probabil-
ity distribution of its classes and positions with
respect to an entity. Consequently, a global op-
timization via dynamic programming determines
the optimal combination of classes and named en-
tities chunks (lengths). The classification features
utilize morphological analysis, two-stage predic-
tion, word clustering and gazetteers and are de-
scribed in (Strakov?a et al., 2013).
The recognizer is available either as a run-time
implementation with trained linguistic models for
Czech, or as a package which allows custom mod-
els to be trained using any NE-annotated data.
4.2 Czech Named Entity Corpus
For training the recognizer, Czech Named Entity
Corpus(
?
Sev?c??kov?a et al., 2007) was used. In this
corpus, Czech entities are classified into a two-
level hierarchy classification: a fine-grained set
of 42 classes or a more coarse classification of 7
System
F-measure F-measure
(42 classes) (7 classes)
(
?
Sev?c??kov?a et al., 2007) 62.00 68.00
(Kravalov?a et al., 2009) 68.00 71.00
(Konkol and Konop??k, 2013) NA 79.00
(Strakov?a et al., 2013) 79.23 82.82
NameTag CNEC 1.1 77.88 81.01
NameTag CNEC 2.0 77.22 80.30
Table 3: Evaluation of the Czech NE recognizers.
Corpus Words / sec RAM Model size
CNEC 1.1 40K 54MB 3MB
CNEC 2.0 45K 65MB 4MB
Table 4: Evaluation of the NE recognizer tagger
throughput, RAM and model size.
super-classes. Like other authors, we report the
evaluation on both hierarchy levels.
Czech Named Entity Corpus annotation allows
ambiguous labels, that is, one entity can be labeled
with two classes; however, NameTag predicts ex-
actly one label per named entity, just like the pre-
vious work does (Strakov?a et al., 2013).
Furthermore, CNEC also allows embedded
entities, which is also somewhat problematic.
NameTag always predicts only the outer-most en-
tity (the embedding entity), although it is penal-
ized by the evaluation score which includes cor-
rect prediction of the nested entities.
4.3 NER Evaluation
For comparison with previous work, we report re-
sults for the first version of the Czech Named En-
tity Corpus (CNEC 1.1). The linguistic models
released with NameTag are trained on the most
current version of the Czech Named Entity Cor-
pus (CNEC 2.0), which has been recently released.
We report our results for both CNEC 1.1 and
CNEC 2.0 in Table 3.
5 Software Performance
We designed MorphoDiTa and NameTag as light-
weight, efficient software with low resource usage.
Depending on the morphosyntactic complexity
of the language and the selected tagging scheme,
the MorphoDiTa tagger has a throughput around
10-200K words per second on 2.9GHz Pentium
computer with 4GB RAM. Table 4 shows the sys-
tem word throughput, allocated RAM and model
size on such a machine for NameTag and Table 5
shows these parameters for MorphoDiTa.
16
Task System Words / sec RAM Model size
Czech tag Mor?ce (Spoustov?a et al., 2009) 1K 902MB 178MB
Czech tag Featurama 2K 747MB 210MB
Czech tag MorphoDiTa 10K 52MB 16MB
Czech tag?first two pos. MorphoDiTa 200K 15MB 2MB
English Penn style Mor?ce (Spoustov?a et al., 2009) 3K 268MB 42MB
English Penn style Featurama 10K 195MB 49MB
English Penn style MorphoDiTa 50K 30MB 6MB
Table 5: Evaluation of the POS tagger throughput, RAM and model size.
MorphoDiTa NameTag
Binaries and source code https://github.com/ufal/morphodita https://github.com/ufal/nametag
Project website http://ufal.mff.cuni.cz/morphodita http://ufal.mff.cuni.cz/nametag
Demo http://lindat.mff.cuni.cz/services/morphodita/ http://lindat.mff.cuni.cz/services/nametag/
Web services http://lindat.mff.cuni.cz/services
Language models http://lindat.mff.cuni.cz
Table 6: Web links to MorphoDiTa and NameTag downloads.
6 Release
Both MorphoDiTa and NameTag are free software
under LGPL and their respective linguistic models
are free for non-commercial use and distributed
under CC BY-NC-SA license, although for some
models the original data used to create the model
may impose additional licensing conditions. Both
MorphoDiTa and NameTag can be used as:
? a standalone tool,
? C++ library with Java, Python, Perl bindings,
? a web service, which does not require any in-
stallation at the user?s machine whatsoever,
? an on-line demo.
MorphoDiTa and NameTag are platform inde-
pendent and do not require any additional libraries.
Web services and demo for the Czech and English
languages are also available.
Table 6 lists the web links to all resources. The
pre-compiled binaries and source code are avail-
able on GitHub, the language models are avail-
able from the LINDAT/CLARIN infrastructure
and the documentation can be found at the respec-
tive project websites.
7 Conclusion
We released two efficient, light-weight POS- and
NE taggers (especially efficient for inflective lan-
guages), which are available to a wide audience
as an open-source, free software with rich API
and also as an end-to-end application. The tag-
gers reach state-of-the-art results for Czech and
are distributed with the models. We are currently
working on more language releases (Slovak, Pol-
ish and Arabic). We are also aware that the cre-
ation of the dictionary relies on the existence of a
resource annotated with forms, lemmas and tags,
which may not be readily available. Therefore,
our future work includes developing a guesser for
analyzing previously unseen but valid word forms
in inflective languages, using only data annotated
with disambiguated POS tags. We hope the release
for Czech will prove useful for broad audience, for
example for shared tasks which include Czech lan-
guage data.
Acknowledgments
This work has been partially supported and has
been using language resources developed and/or
stored and/or distributed by the LINDAT/CLARIN
project of the Ministry of Education of the Czech
Republic (project LM2010013). This research was
also partially supported by SVV project number
260 104. We are grateful to the reviewers for com-
ments which helped us to improve the paper.
References
Rie Kubota Ando and Tong Zhang. 2005. A high-
performance semi-supervised learning method for
text chunking. In Proceedings of the 43rd Annual
Meeting on Association for Computational Linguis-
tics, ACL ?05, pages 1?9. Association for Computa-
tional Linguistics.
Eduard Bej?cek, Jarmila Panevov?a, Jan Popelka, Pavel
Stra?n?ak, Magda
?
Sev?c??kov?a, Jan
?
St?ep?anek, and
Zden?ek
?
Zabokrtsk?y. 2012. Prague Dependency
Treebank 2.5 ? a revisited version of PDT 2.0. In
17
Martin Kay and Christian Boitet, editors, Proceed-
ings of the 24th International Conference on Com-
putational Linguistics (Coling 2012), pages 231?
246, Mumbai, India. IIT Bombay, Coling 2012 Or-
ganizing Committee.
Thorsten Brants. 2000. TnT: A Statistical Part-of-
speech Tagger. In Proceedings of the Sixth Con-
ference on Applied Natural Language Processing,
ANLC ?00, pages 224?231, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Eric Brill. 1992. A Simple Rule-based Part of Speech
Tagger. In Proceedings of the Third Conference on
Applied Natural Language Processing, ANLC ?92,
pages 152?155, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Nancy A. Chinchor. 1998. Proceedings of the Sev-
enth Message Understanding Conference (MUC-
7) Named Entity Task Definition. In Proceedings
of the Seventh Message Understanding Conference
(MUC-7), page 21 pages, April.
Michael Collins. 2002. Discriminative Training Meth-
ods for Hidden Markov Models: Theory and Ex-
periments with Perceptron Algorithms. In Proceed-
ings of the 2002 Conference on Empirical Methods
in Natural Language Processing, pages 1?8. Asso-
ciation for Computational Linguistics, July.
Rene De La Briandais. 1959. File Searching Using
Variable Length Keys. In Papers Presented at the
the March 3-5, 1959, Western Joint Computer Con-
ference, IRE-AIEE-ACM ?59 (Western), pages 295?
298, New York, NY, USA. ACM.
Jenny Rose Finkel, Trond Grenager, and Christopher
Manning. 2005. Incorporating non-local informa-
tion into information extraction systems by Gibbs
sampling. In Proceedings of the 43rd Annual Meet-
ing on Association for Computational Linguistics,
ACL ?05, pages 363?370. Association for Compu-
tational Linguistics.
J. Haji?c. 2004. Disambiguation of Rich Inflection:
Computational Morphology of Czech. Karolinum
Press.
Donald Knuth, 1997. The Art of Computer Program-
ming, Volume 3: Sorting and Searching, Third Edi-
tion, chapter Section 6.3: Digital Searching, pages
492?512. Addison-Wesley.
Michal Konkol and Miloslav Konop??k. 2011. Maxi-
mum Entropy Named Entity Recognition for Czech
Language. In Text, Speech and Dialogue, volume
6836 of Lecture Notes in Computer Science, pages
203?210. Springer Berlin Heidelberg.
Michal Konkol and Miloslav Konop??k. 2013. CRF-
Based Czech Named Entity Recognizer and Consol-
idation of Czech NER Research. In Ivan Haber-
nal and Vclav Matouek, editors, Text, Speech, and
Dialogue, volume 8082 of Lecture Notes in Com-
puter Science, pages 153?160. Springer Berlin Hei-
delberg.
Jana Kravalov?a and Zden?ek
?
Zabokrtsk?y. 2009. Czech
named entity corpus and SVM-based recognizer. In
Proceedings of the 2009 Named Entities Workshop:
Shared Task on Transliteration, NEWS ?09, pages
194?201. Association for Computational Linguis-
tics.
H. Kucera and W. N. Francis. 1967. Computational
analysis of present-day American English. Brown
University Press, Providence, RI.
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a Large Annotated
Corpus of English: The Penn Treebank. COMPU-
TATIONAL LINGUISTICS, 19(2):313?330.
Lev Ratinov and Dan Roth. 2009. Design challenges
and misconceptions in named entity recognition. In
CoNLL ?09: Proceedings of the Thirteenth Confer-
ence on Computational Natural Language Learning,
pages 147?155. Association for Computational Lin-
guistics.
Libin Shen, Giorgio Satta, and Aravind Joshi. 2007.
Guided Learning for Bidirectional Sequence Classi-
fication. In Proceedings of the 45th Annual Meet-
ing of the Association of Computational Linguistics,
pages 760?767, Prague, Czech Republic, June. As-
sociation for Computational Linguistics.
Drahom??ra ?johanka? Spoustov?a, Jan Haji?c, Jan Raab,
and Miroslav Spousta. 2009. Semi-Supervised
Training for the Averaged Perceptron POS Tagger.
In Proceedings of the 12th Conference of the Euro-
pean Chapter of the ACL (EACL 2009), pages 763?
771, Athens, Greece, March. Association for Com-
putational Linguistics.
Jana Strakov?a, Milan Straka, and Jan Haji?c. 2013. A
New State-of-The-Art Czech Named Entity Recog-
nizer. In Ivan Habernal and V?aclav Matou?sek, edi-
tors, Text, Speech and Dialogue: 16th International
Conference, TSD 2013. Proceedings, volume 8082
of Lecture Notes in Computer Science, pages 68?75,
Berlin / Heidelberg. Z?apado?cesk?a univerzita v Plzni,
Springer Verlag.
Jun Suzuki and Hideki Isozaki. 2008. Semi-
Supervised Sequential Labeling and Segmentation
using Giga-word Scale Unlabeled Data. Computa-
tional Linguistics, (June):665?673.
Erik F. Tjong Kim Sang and Fien De Meulder.
2003. Introduction to the CoNLL-2003 Shared
Task: Language-Independent Named Entity Recog-
nition. In Proceedings of CoNLL-2003, pages 142?
147. Edmonton, Canada.
Magda
?
Sev?c??kov?a, Zden?ek
?
Zabokrtsk?y, and Old?rich
Kr?uza. 2007. Named entities in Czech: annotat-
ing data and developing NE tagger. In Proceedings
of the 10th international conference on Text, speech
and dialogue, TSD?07, pages 188?195. Springer-
Verlag.
18
Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 221?228,
Baltimore, Maryland USA, June 26?27, 2014.
c
?2014 Association for Computational Linguistics
Machine Translation of Medical Texts in the Khresmoi Project
Ond
?
rej Du
?
sek, Jan Haji
?
c, Jaroslava Hlav
?
a
?
cov
?
a, Michal Nov
?
ak,
Pavel Pecina, Rudolf Rosa, Ale
?
s Tamchyna, Zde
?
nka Ure
?
sov
?
a, Daniel Zeman
Charles University in Prague, Faculty of Mathematics and Physics
Institute of Formal and Applied Linguistics
Malostransk?e n?am?est?? 25, 11800 Prague, Czech Republic
{odusek,hajic,hlavacova,mnovak,pecina,rosa,tamchyna,uresova,zeman}@ufal.mff.cuni.cz
Abstract
This paper presents the participation of
the Charles University team in the WMT
2014 Medical Translation Task. Our sys-
tems are developed within the Khresmoi
project, a large integrated project aim-
ing to deliver a multi-lingual multi-modal
search and access system for biomedical
information and documents. Being in-
volved in the organization of the Medi-
cal Translation Task, our primary goal is
to set up a baseline for both its subtasks
(summary translation and query transla-
tion) and for all translation directions.
Our systems are based on the phrase-
based Moses system and standard meth-
ods for domain adaptation. The con-
strained/unconstrained systems differ in
the training data only.
1 Introduction
The WMT 2014 Medical Translation Task poses
an interesting challenge for Machine Translation
(MT). In the ?standard? translation task, the end
application is the translation itself. In the Medi-
cal Translation Task, the MT system is considered
a part of a larger system for Cross-Lingual Infor-
mation Retrieval (CLIR) and is used to solve two
different problems: (i) translation of user search
queries, and (ii) translation of summaries of re-
trieved documents.
In query translation, the end user does not even
necessarily see the MT output as their queries are
translated and search is performed on documents
in the target language. In summary translation, the
sentences to be translated come from document
summaries (snippets) displayed to provide infor-
mation on each of the documents retrieved by the
search. Therefore, translation quality may not be
the most important measure in this task ? the per-
formance of the CLIR system as a whole is the
final criterion. Another fundamental difference
from the standard task is the nature of the trans-
lated texts. While we can consider document sum-
maries to be ordinary texts (despite their higher in-
formation density in terms of terminology from a
narrow domain), search queries in the medical do-
main are an extremely specific type of data, and
traditional techniques for system development and
domain adaptation are truly put to a test here.
This work is a part of the of the large integrated
EU-funded Khresmoi project.
1
Among other
goals, such as joint text and image retrieval of ra-
diodiagnostic records, Khresmoi aims to develop
technology for transparent cross-lingual search of
medical sources for both professionals and laypeo-
ple, with the emphasis primarily on publicly avail-
able web sources.
In this paper, we describe the Khresmoi sys-
tems submitted to the WMT 2014 Medical Trans-
lation Task. We participate in both subtasks (sum-
mary translation and query translation) for all
language pairs (Czech?English, German?English,
and French?English) in both directions (to English
and from English). Our systems are based on the
Moses phrase-based translation toolkit and stan-
dard methods for domain adaptation. We submit
one constrained and one unconstrained system for
each subtask and translation direction. The con-
strained and unconstrained systems differ in train-
ing data only: The former use all allowed training
data, the latter take advantage of additional web-
crawled data.
We first summarize previous works in MT do-
main adaptation in Section 2, then describe the
data we used for our systems in Section 3. Sec-
1
http://www.khresmoi.eu/
221
tion 4 contains an account of the submitted sys-
tems and their performance in translation of search
queries and document summaries. Section 5 con-
cludes the paper.
2 Related work
To put our work in the context of other approaches,
we first describe previous work on domain adap-
tation in Statistical Machine Translation (SMT),
then focus specifically on SMT in the medical do-
main.
2.1 Domain adaptation of Statistical machine
translation
Many works on domain adaptation examine the
usage of available in-domain data to directly im-
prove in-domain performance of SMT. Some au-
thors attempt to combine the predictions of two
separate (in-domain and general-domain) transla-
tion models (Langlais, 2002; Sanchis-Trilles and
Casacuberta, 2010; Bisazza et al., 2011; Nakov,
2008) or language models (Koehn and Schroeder,
2007). Wu and Wang (2004) use in-domain data
to improve word alignment in the training phase.
Carpuat et al. (2012) explore the possibility of us-
ing word sense disambiguation to discriminate be-
tween domains.
Other approaches concentrate on the acquisition
of larger in-domain corpora. Some of them ex-
ploit existing general-domain corpora by select-
ing data that resemble the properties of in-domain
data (e.g., using cross-entropy), thus building a
larger pseudo-in-domain training corpus. This
technique is used to adapt language models (Eck
et al., 2004b; Moore and Lewis, 2010) as well as
translation models (Hildebrand et al., 2005; Axel-
rod et al., 2011) or their combination (Mansour et
al., 2011). Similar approaches to domain adapta-
tion are also applied in other tasks, e.g., automatic
speech recognition (Byrne et al., 2004).
2.2 Statistical machine translation in the
medical domain
Eck et al. (2004a) employ an SMT system for the
translation of dialogues between doctors and pa-
tients and show that according to automatic met-
rics, a dictionary extracted from the Unified Medi-
cal Language System (UMLS) Metathesaurus and
its semantic type classification (U.S. National Li-
brary of Medicine, 2009) significantly improves
translation quality from Spanish to English when
applied to generalize the training data.
Wu et al. (2011) analyze the quality of MT on
PubMed
2
titles and whether it is sufficient for pa-
tients. The conclusions are very positive espe-
cially for languages with large training resources
(English, Spanish, German) ? the average fluency
and content scores (based on human evaluation)
are above four on a five-point scale. In automatic
evaluation, their systems substantially outperform
Google Translate. However, the SMT systems are
specifically trained, tuned, and tested on the do-
main of PubMed titles, and it is not evident how
they would perform on other medical texts.
Costa-juss`a et al. (2012) are less optimistic re-
garding SMT quality in the medical domain. They
analyze and evaluate the quality of public web-
based MT systems (such as Google Translate) and
conclude that in both automatic and manual eval-
uation (on 7 language pairs), the performance of
these systems is still not good enough to be used
in daily routines of medical doctors in hospitals.
Jimeno Yepes et al. (2013) propose a method
for obtaining in-domain parallel corpora from ti-
tles and abstracts of publications in the MED-
LINE
3
database. The acquired corpora contain
from 30,000 to 130,000 sentence pairs (depending
on the language pair) and are reported to improve
translation quality when used for SMT training,
compared to a baseline trained on out-of-domain
data. However, the authors use only one source
of in-domain parallel data to adapt the translation
model, and do not use any in-domain monolingual
data to adapt the language model.
In this work, we investigate methods combining
the different kinds of data ? general-domain, in-
domain, and pseudo-in-domain ? to find the opti-
mal approach to this problem.
3 Data description
This section includes an overview of the parallel
and monolingual data sources used to train our
systems. Following the task specification, they
are split into constrained and unconstrained sec-
tions. The constrained section includes medical-
domain data provided for this task (extracted by
the provided scripts), and general-domain texts
provided as constrained data for the standard task
(?general domain? here is used to denote data
2
http://www.ncbi.nlm.nih.gov/pubmed/
3
http://www.nlm.nih.gov/pubs/
factsheets/medline.html
222
Czech?English German?English French?English
dom set pairs source target pairs source target pairs source target
med con 2,498 18,126 19,964 4,998 123,686 130,598 6,139 202,245 171,928
gen con 15,788 226,711 260,505 4,520 112,818 119,404 40,842 1,470,016 1,211,516
gen unc ? ? ? 9,320 525,782 574,373 13,809 961,991 808,222
Table 1: Number of sentence pairs and tokens (source/target) in parallel training data (in thousands).
dom set English Czech German French
med con 172,991 1,848 63,499 63,022
gen con 6,132,107 627,493 1,728,065 1,837,457
med unc 3,275,272 36,348 361,881 908,911
gen unc 618,084 ? 339,595 204,025
Table 2: Number of tokens in monolingual training data (in thousands).
which comes from a mixture of various different
domains, mostly news, parliament proceedings,
web-crawls, etc.). The unconstrained section con-
tains automatically crawled data from medical and
health websites and non-medical data from patent
collections.
3.1 Parallel data
The parallel data summary is presented in Table 1.
The main sources of the medical-domain data
for all the language pairs include the EMEA cor-
pus (Tiedemann, 2009), the UMLS metathesaurus
of health and biomedical vocabularies and stan-
dards (U.S. National Library of Medicine, 2009),
and bilingual titles of Wikipedia articles belonging
to the categories identified to be medical domain.
Additional medical-domain data comes from the
MAREC patent collection: PatTR (W?aschle and
Riezler, 2012) available for DE?EN and FR?EN,
and COPPA (Pouliquen and Mazenc, 2011) for
FR?EN (only patents from the medical categories
A61, C12N, and C12P are allowed in the con-
strained systems).
The constrained general-domain data include
three parallel corpora for all the language pairs:
CommonCrawl (Smith et al., 2013), Europarl ver-
sion 6 (Koehn, 2005), the News Commentary cor-
pus (Callison-Burch et al., 2012). Further, the con-
strained data include CzEng (Bojar et al., 2012)
for CS?EN and the UN corpus for FR?EN.
For our unconstrained experiments, we also em-
ploy parallel data from the non-medical patents
from the PatTR and COPPA collections (other cat-
egories than A61, C12N, and C12P).
3.2 Monolingual data
The monolingual data is summarized in Table 2.
The main sources of the medical-domain mono-
lingual data for all languages involve Wikipedia
pages, UMLS concept descriptions, and non-
parallel texts extracted from the medical patents
of the PatTR collections. For English, the main
source is the AACT collection of texts from Clin-
icalTrials.gov. Smaller resources include: Drug-
Bank (Knox et al., 2011), GENIA (Kim et al.,
2003), FMA (Rosse and Mejino Jr., 2008), GREC
(Thompson et al., 2009), and PIL (Bouayad-Agha
et al., 2000).
In the unconstrained systems, we use additional
monolingual data from web pages crawled within
the Khresmoi project: a collection of about one
million HON-certified
4
webpages in English re-
leased as the test collection for the CLEF 2013
eHealth Task 3 evaluation campaign,
5
additional
web-crawled HON-certified pages (not publicly
available), and other webcrawled medical-domain
related webpages.
The constrained general-domain resources in-
clude: the News corpus for CS, DE, EN, and FR
collected for the purpose of the WMT 2014 Stan-
dard Task, monolingual parts of the Europarl and
News-Commentary corpora, and the Gigaword for
EN and FR.
For the FR?EN and DE?EN unconstrained sys-
tems, the additional general domain monolingual
data is taken from monolingual texts of non-
medical patents in the PatTR collection.
4
https://www.hon.ch/
5
https://sites.google.com/site/
shareclefehealth/
223
medical general
c
o
n
s
t
r
a
i
n
e
d
?15
?10
?5
0
5
10
15
?15
?10
?5
0
5
10
15
u
n
c
o
n
s
t
r
a
i
n
e
d
?15
?10
?5
0
5
10
15
Figure 1: Distribution of the domain-specificity
scores in the English?French parallel data sets.
3.3 Data preprocessing
The data consisting of crawled web pages, namely
CLEF, HON, and non-HON, needed to be cleaned
and transformed into a set of sentences. The
Boilerpipe (Kohlsch?utter et al., 2010) and Justext
(Pomik?alek, 2011) tools were used to remove boil-
erplate texts and extract just the main content from
the web pages. The YALI language detection tool
(Majli?s, 2012) trained on both in-domain and gen-
eral domain data then filtered out those cleaned
pages which were not identified as written in one
of the concerned languages.
The rest of the preprocessing procedure was ap-
plied to all the datasets mentioned above, both
parallel and monolingual. The data were tok-
enized and normalized by converting or omit-
ting some (mostly punctuation) characters. A
set of language-dependent heuristics was applied
in an attempt to restore and normalize the open-
ing/closing quotation marks, i.e. convert "quoted"
to ?quoted? (Zeman, 2012). The motivation here
is twofold: First, we hope that paired quota-
tion marks could occasionally work as brackets
and better denote parallel phrases for Moses; sec-
ond, if Moses learns to output directed quotation
marks, the subsequent detokenization will be eas-
ier. For all systems which translate from German,
decompounding is employed to reduce source-side
data sparsity. We used BananaSplit for this task
(M?uller and Gurevych, 2006).
We perform all training and internal evaluation
on lowercased data; we trained recasers to post-
process the final submissions.
medical general
c
o
n
s
t
r
a
i
n
e
d
?15
?10
?5
0
5
10
15
?15
?10
?5
0
5
10
15
u
n
c
o
n
s
t
r
a
i
n
e
d
?15
?10
?5
0
5
10
15
?15
?10
?5
0
5
10
15
Figure 2: Distribution of the domain-specificity
scores in the French monolingual data sets.
4 Submitted systems
We first describe our technique of psedo-in-
domain data selection in Section 4.1, then com-
pare two methods of combining the selected data
in Section 4.2. This, along with using constrained
and unconstrained data sets to train the systems
(see Section 3), amounts to a total of four system
variants submitted for each task. A description of
the system settings used is given in Section 4.3.
4.1 Data selection
We follow an approach originally proposed for
selection of monolingual sentences for language
modeling (Moore and Lewis, 2010) and its modi-
fication applied to selection of parallel sentences
(Axelrod et al., 2011). This technique assumes
two language models for sentence scoring, one
trained on (true) in-domain text and one trained
on (any) general-domain text in the same lan-
guage (e.g., English). For both data domains
(general and medical), we score each sentence
by the difference of its cross-perplexity given the
in-domain language model and cross-perplexity
given the general-domain language model (in this
order). We only keep sentences with a negative
score in our data, assuming that these are the
most ?medical-like?. Visualisation of the domain-
specificity scores (cross-perplexity difference) in
the FR?EN parallel data and FR monolingual data
is illustrated in Figures 1 and 2, respectively.
6
The
scores (Y axis) are presented for each sentence in
increasing order from left to right (X axis).
6
For the medical domain, constrained and unconstrained
parallel data are identical.
224
cs?en de?en en?cs en?de en?fr fr?en
con concat 33.64?1.14 32.84?1.24 18.10?0.94 18.29?0.92 33.39?1.11 36.71?1.17
con interpol 32.94?1.11 32.31?1.20 18.96?0.93 18.41?0.93 34.06?1.11 37.42?1.21
unc concat 34.10?1.11 34.52?1.20 21.12?1.03 19.76?0.92 36.23?1.03 38.15?1.16
unc interpol 34.48?1.16 34.92?1.17 22.15?1.06 20.81?0.95 36.26?1.13 37.91?1.13
Table 3: BLEU scores of summary translations.
cs?en de?en en?cs en?de en?fr fr?en
con concat 30.87?4.70 33.21?5.03 23.25?4.85 17.72?4.75 28.64?3.77 35.56?4.94
con interpol 32.46?5.05 33.74?4.97 21.56?4.80 16.90?4.39 29.34?3.73 35.28?5.26
unc concat 34.88?5.04 31.24?5.59 22.61?4.91 19.13?5.66 33.08?3.80 36.73?4.88
unc interpol 33.82?5.16 34.19?5.27 23.93?5.16 15.87?11.31 31.19?3.73 40.25?5.14
Table 4: BLEU scores of query translations.
The two language models for sentence scoring
are trained with a restricted vocabulary extracted
from the in-domain training data as words occur-
ring at least twice (singletons and other words are
treated as out-of-vocabulary). In our experiments,
we apply this technique to select both monolin-
gual data for language models and parallel data
for translation models. Selection of parallel data
is based on the English side only. The in-domain
models are trained on the monolingual data in the
target language (constrained or unconstrained, de-
pending on the setting). The general-domain mod-
els are trained on the WMT News data.
Compared to the approach of Moore and Lewis
(2010) and Axelrod et al. (2011), we prune the
model vocabulary more aggressively ? we discard
not only the singletons, but also all words with
non-Latin characters, which helps clean the mod-
els from noise introduced by the automatic process
of data acquisition by web crawling.
4.2 Data combination
For both parallel and monolingual data, we obtain
two data sets after applying the data selection:
? ?medical-like? data from the medical domain
? ?medical-like? data from the general domain.
For each language pair and for each system
type (constrained/unconstrained), we submitted
two system variants which differ in how the se-
lected data are combined. The first variant uses
a simple concatenation of the two datasets both
for parallel data and for language model data. In
the second variant, we train separate models for
each section and use linear interpolation to com-
bine them into a single model. For language mod-
els, we use the SRILM linear interpolation feature
(Stolcke, 2002). We interpolate phrase tables us-
ing Tmcombine (Sennrich, 2012). In both cases,
the held-out set for minimizing the perplexity is
the system development set.
4.3 System details
We compute word alignment on lowercase 4-cha-
racter stems using fast align (Dyer et al., 2013).
We create phrase tables using the Moses toolkit
(Koehn et al., 2007) with standard settings. We
train 5-gram language models on the target-side
lowercase forms using SRILM. We use MERT
(Och, 2003) to tune model weights in our systems
on the development data provided for the task.
The only difference between the system variants
for query and summary translation is the tuning
set. In both cases, we use the respective sets pro-
vided offcially for the shared task.
4.4 Results
Tables 3 and 4 show case-insensitive BLEU scores
of our systems.
7
As expected, the unconstrained
systems outperform the constrained ones. Linear
interpolation outperforms data concatenation quite
reliably across language pairs for summary trans-
lation. While the picture for query translation is
similar, there is more variance in the results, so
we cannot state that interpolation definitely works
7
As we use the same recasers for both summary and query
translation, our systems are heavily penalized for wrong let-
ter case in query translation. However, letter case is not taken
into account in most CLIR systems. All BLEU scores re-
ported in this paper will be case-insensitive for this reason.
225
better in this case. This is due to the sizes of the
development and test sets and most importantly
due to sentence lengths ? queries are very short,
making BLEU unreliable, MERT unstable, and
bootstrap resampling intervals wide.
If we compare our score to the other competi-
tors, we are clearly worse than the best systems for
summary translation. From this perspective, our
data filtering seems overly eager (i.e., discarding
all sentence pairs with a positive perplexity differ-
ence). An experiment which we leave for future
work is doing one more round of interpolation to
combine a model trained on the data with negative
perplexity with models trained on the remainder.
5 Conclusions
We described the Charles University MT system
used in the Shared Medical Translation Task of
WMT 2014. Our primary goal was to set up a
baseline for both the subtasks and all translation
directions. The systems are based on the Moses
toolkit, pseudo-in-domain data selection based on
perplexity difference and two different methods of
in-domain and out-of-domain data combination:
simple data concatenation and linear model inter-
polation.
We report results of constrained and uncon-
strained systems which differ in the training data
only. In most experiments, using additional data
improved the results compared to the constrained
systems and using linear model interpolation out-
performed data concatenation. While our systems
are on par with best results for case-insensitive
BLEU score in query translation, our overly ea-
ger data selection techniques caused lower scores
in summary translation. In future work, we plan
to include a special out-of-domain model in our
setup to compensate for this problem.
Acknowledgments
This work was supported by the EU FP7 project
Khresmoi (contract no. 257528), the Czech Sci-
ence Foundation (grant no. P103/12/G084), and
SVV project number 260 104. This work has
been using language resources developed, stored,
and distributed by the LINDAT/CLARIN project
of the Ministry of Education, Youth and Sports of
the Czech Republic (project LM2010013).
References
A. Axelrod, X. He, and J. Gao. 2011. Domain adap-
tation via pseudo in-domain data selection. In Pro-
ceedings of the 2011 Conference on Empirical Meth-
ods in Natural Language Processing, pages 355?
362, Edinburgh, United Kingdom. ACL.
A. Bisazza, N. Ruiz, and M. Federico. 2011. Fill-
up versus interpolation methods for phrase-based
SMT adaptation. In Proceedings of the Interna-
tional Workshop on Spoken Language Translation,
pages 136?143, San Francisco, CA, USA. Interna-
tional Speech Communication Association.
O. Bojar, Z.
?
Zabokrtsk?y, O. Du?sek, P. Galu?s?c?akov?a,
M. Majli?s, D. Mare?cek, J. Mar?s??k, M. Nov?ak,
M. Popel, and A. Tamchyna. 2012. The joy of
parallelism with CzEng 1.0. In Proceedings of the
Eighth International Conference on Language Re-
sources and Evaluation, pages 3921?3928, Istanbul,
Turkey. European Language Resources Association.
N. Bouayad-Agha, D. R. Scott, and R. Power. 2000.
Integrating content and style in documents: A case
study of patient information leaflets. Information
Design Journal, 9(2?3):161?176.
W. Byrne, D. S. Doermann, M. Franz, S. Gustman,
J. Haji?c, D. W. Oard, et al. 2004. Automatic recog-
nition of spontaneous speech for access to multilin-
gual oral history archives. Speech and Audio Pro-
cessing, IEEE Transactions on, 12(4):420?435.
C. Callison-Burch, P. Koehn, C. Monz, M. Post,
R. Soricut, and L. Specia. 2012. Findings of the
2012 Workshop on Statistical Machine Translation.
In Proceedings of the Seventh Workshop on Statis-
tical Machine Translation, pages 10?51, Montr?eal,
Canada. ACL.
M. Carpuat, H. Daum?e III, A. Fraser, C. Quirk,
F. Braune, A. Clifton, et al. 2012. Domain adap-
tation in machine translation: Final report. In
2012 Johns Hopkins Summer Workshop Final Re-
port, pages 61?72. Johns Hopkins University.
M. R. Costa-juss`a, M. Farr?us, and J. Serrano Pons.
2012. Machine translation in medicine. A qual-
ity analysis of statistical machine translation in the
medical domain. In Proceedings of the 1st Virtual
International Conference on Advanced Research in
Scientific Areas, pages 1995?1998,
?
Zilina, Slovakia.
?
Zilinsk?a univerzita.
C. Dyer, V. Chahuneau, and N. A. Smith. 2013. A sim-
ple, fast, and effective reparameterization of IBM
model 2. In Proceedings of NAACL-HLT, pages
644?648.
M. Eck, S. Vogel, and A. Waibel. 2004a. Improv-
ing statistical machine translation in the medical do-
main using the Unified Medical Language System.
In COLING 2004: Proceedings of the 20th Inter-
national Conference on Computational Linguistics,
pages 792?798, Geneva, Switzerland. ACL.
226
M. Eck, S. Vogel, and A. Waibel. 2004b. Language
model adaptation for statistical machine translation
based on information retrieval. In Maria Teresa
Lino, Maria Francisca Xavier, F?atima Ferreira, Rute
Costa, and Raquel Silva, editors, Proceedings of the
International Conference on Language Resources
and Evaluation, pages 327?330, Lisbon, Portugal.
European Language Resources Association.
A. S. Hildebrand, M. Eck, S. Vogel, and A. Waibel.
2005. Adaptation of the translation model for statis-
tical machine translation based on information re-
trieval. In Proceedings of the 10th Annual Con-
ference of the European Association for Machine
Translation, pages 133?142, Budapest, Hungary.
European Association for Machine Translation.
A. Jimeno Yepes,
?
E. Prieur-Gaston, and A. N?ev?eol.
2013. Combining MEDLINE and publisher data to
create parallel corpora for the automatic translation
of biomedical text. BMC Bioinformatics, 14(1):1?
10.
J.-D Kim, T. Ohta, Y. Tateisi, and J. Tsujii. 2003. GE-
NIA corpus ? a semantically annotated corpus for
bio-textmining. Bioinformatics, 19(suppl 1):i180?
i182.
C. Knox, V. Law, T. Jewison, P. Liu, Son Ly, A. Frolkis,
A. Pon, K. Banco, C. Mak, V. Neveu, Y. Djoum-
bou, R. Eisner, A. C. Guo, and D. S. Wishart.
2011. DrugBank 3.0: a comprehensive resource for
?Omics? research on drugs. Nucleic acids research,
39(suppl 1):D1035?D1041.
P. Koehn and J. Schroeder. 2007. Experiments in do-
main adaptation for statistical machine translation.
In Proceedings of the Second Workshop on Statis-
tical Machine Translation, pages 224?227, Prague,
Czech Republic. ACL.
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,
and E. Herbst. 2007. Moses: Open Source Toolkit
for Statistical Machine Translation. In Proceedings
of the 45th Annual Meeting of the Association for
Computational Linguistics Companion Volume Pro-
ceedings of the Demo and Poster Sessions, pages
177?180, Praha, Czechia, June. ACL.
P. Koehn. 2005. Europarl: a parallel corpus for sta-
tistical machine translation. In Conference Proceed-
ings: the tenth Machine Translation Summit, pages
79?86, Phuket, Thailand. Asia-Pacific Association
for Machine Translation.
C. Kohlsch?utter, P. Fankhauser, and W. Nejdl. 2010.
Boilerplate detection using shallow text features. In
Proceedings of the Third ACM International Confer-
ence on Web Search and Data Mining, WSDM ?10,
pages 441?450, New York, NY, USA. ACM.
P. Langlais. 2002. Improving a general-purpose statis-
tical translation engine by terminological lexicons.
In COLING-02 on COMPUTERM 2002: second
international workshop on computational terminol-
ogy, volume 14, pages 1?7, Taipei, Taiwan. ACL.
M. Majli?s. 2012. Yet another language identifier. In
Proceedings of the Student Research Workshop at
the 13th Conference of the European Chapter of the
Association for Computational Linguistics, pages
46?54, Avignon, France. ACL.
S. Mansour, J. Wuebker, and H. Ney. 2011. Com-
bining translation and language model scoring for
domain-specific data filtering. In International
Workshop on Spoken Language Translation, pages
222?229, San Francisco, CA, USA. ISCA.
R. C. Moore and W. Lewis. 2010. Intelligent selection
of language model training data. In Proceedings of
the ACL 2010 Conference Short Papers, pages 220?
224, Uppsala, Sweden. ACL.
C. M?uller and I. Gurevych. 2006. Exploring the po-
tential of semantic relatedness in information re-
trieval. In LWA 2006 Lernen ? Wissensentdeck-
ung ? Adaptivit?at, 9.-11.10.2006, Hildesheimer In-
formatikberichte, pages 126?131, Hildesheim, Ger-
many. Universit?at Hildesheim.
P. Nakov. 2008. Improving English?Spanish statistical
machine translation: Experiments in domain adapta-
tion, sentence paraphrasing, tokenization, and recas-
ing. In Proceedings of the Third Workshop on Statis-
tical Machine Translation, pages 147?150, Colum-
bus, OH, USA. ACL.
F. J. Och. 2003. Minimum error rate training in statis-
tical machine translation. In ACL ?03: Proceedings
of the 41st Annual Meeting on Association for Com-
putational Linguistics, pages 160?167, Morristown,
NJ, USA. ACL.
J. Pomik?alek. 2011. Removing Boilerplate and Du-
plicate Content from Web Corpora. PhD thesis,
Masaryk University, Faculty of Informatics, Brno.
B. Pouliquen and C. Mazenc. 2011. COPPA, CLIR
and TAPTA: three tools to assist in overcoming the
patent barrier at WIPO. In Proceedings of the Thir-
teenth Machine Translation Summit, pages 24?30,
Xiamen, China. Asia-Pacific Association for Ma-
chine Translation.
C. Rosse and Jos?e L. V. Mejino Jr. 2008. The foun-
dational model of anatomy ontology. In A. Burger,
D. Davidson, and R. Baldock, editors, Anatomy On-
tologies for Bioinformatics, volume 6 of Computa-
tional Biology, pages 59?117. Springer London.
G. Sanchis-Trilles and F. Casacuberta. 2010. Log-
linear weight optimisation via Bayesian adaptation
in statistical machine translation. In Proceedings
of the 23rd International Conference on Computa-
tional Linguistics: Posters, pages 1077?1085, Bei-
jing, China. ACL.
227
R. Sennrich. 2012. Perplexity minimization for trans-
lation model domain adaptation in statistical ma-
chine translation. In Proceedings of the 13th Confer-
ence of the European Chapter of the Association for
Computational Linguistics, pages 539?549. ACL.
J. R. Smith, H. Saint-Amand, M. Plamada, P. Koehn,
C. Callison-Burch, and A. Lopez. 2013. Dirt cheap
web-scale parallel text from the common crawl. In
Proceedings of the 51st Annual Meeting of the As-
sociation for Computational Linguistics (Volume 1:
Long Papers), pages 1374?1383, Sofia, Bulgaria.
ACL.
A. Stolcke. 2002. SRILM ? an extensible language
modeling toolkit. In Proceedings of International
Conference on Spoken Language Processing, Den-
ver, Colorado, USA.
P. Thompson, S. Iqbal, J. McNaught, and Sophia Ana-
niadou. 2009. Construction of an annotated corpus
to support biomedical information extraction. BMC
bioinformatics, 10(1):349.
J. Tiedemann. 2009. News from OPUS ? a collection
of multilingual parallel corpora with tools and in-
terfaces. In Recent Advances in Natural Language
Processing, volume 5, pages 237?248, Borovets,
Bulgaria. John Benjamins.
U.S. National Library of Medicine. 2009. UMLS
reference manual. Metathesaurus. Bethesda, MD,
USA.
K. W?aschle and S. Riezler. 2012. Analyzing paral-
lelism and domain similarities in the MAREC patent
corpus. In M. Salampasis and B. Larsen, edi-
tors, Multidisciplinary Information Retrieval, vol-
ume 7356 of Lecture Notes in Computer Science,
pages 12?27. Springer Berlin Heidelberg.
H. Wu and H. Wang. 2004. Improving domain-specific
word alignment with a general bilingual corpus. In
Robert E. Frederking and Kathryn B. Taylor, editors,
Machine Translation: From Real Users to Research,
volume 3265 of Lecture Notes in Computer Science,
pages 262?271. Springer Berlin Heidelberg.
C. Wu, F. Xia, L. Deleger, and I. Solti. 2011. Statistical
machine translation for biomedical text: are we there
yet? AMIA Annual Symposium proceedings, pages
1290?1299.
D. Zeman. 2012. Data issues of the multilingual trans-
lation matrix. In Proceedings of the Seventh Work-
shop on Statistical Machine Translation, pages 395?
400, Montr?eal, Canada. ACL.
228
