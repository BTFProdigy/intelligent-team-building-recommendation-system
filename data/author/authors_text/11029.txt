BUPT Systems in the SIGHAN Bakeoff 2007 
Ying Qin   Caixia Yuan   Jiashen Sun   Xiaojie Wang 
Center of Intelligent Science and Technology Research 
Beijing University of Posts and Telecommunications 
Beijing, 100876, China 
qinyingmail@163.com, yuancx@gmail.com, 
b.bigart911@gmail.com, xjwang@bupt.edu.cn 
 
 
Abstract 
Chinese Word Segmentation(WS), Name 
Entity Recognition(NER) and Part-Of-
Speech(POS) are three important Chinese 
Corpus annotation tasks. With the great 
improvement in these annotations on some 
corpus, now, the robustness, a capability of 
keeping good performances for a system by 
automatically fitting the different corpus 
and standards, become a focal problem. 
This paper introduces the work on 
robustness of WS and POS annotation 
systems from Beijing University of Posts 
and Telecommunications(BUPT), and two 
NER systems. The WS system combines a 
basic WS tagger with an adaptor used to fit 
a specific standard given. POS taggers are 
built for different standards under a two 
step frame, both steps use ME but with 
incremental features. A multiple 
knowledge source system and a less 
knowledge Conditional Random Field 
(CRF) based systems are used for NER. 
Experiments show that our WS and POS 
systems are robust. 
1 Introduction 
In the last SIGHAN bakeoff, there is no single 
system consistently outperforms the others on 
different test standards of Chinese WS and NER 
standards(Sproat and Emerson, 2003). 
Performances of some systems varied significantly 
on different corpus and different standards, this 
kind of systems can not satisfy demands in 
practical applications. The robustness, a capability 
of keeping good performances for a system by 
automatically fitting the different corpus and 
standard, thus become a focal problem in WS and 
NER, it is the same for Chinese Part-of-
Speech(POS) task which is new in the SIGHAN 
bakeoff 2007.  
It is worthy to distinguish two kinds of different 
robustness, one is for different corpus (from 
different sources or different domain and so on) 
under a same standard, we call it corpus robustness, 
and another is for different standards (for different 
application goals or demands and so on) for a same 
corpus. We call it standard robustness. The 
SIGHAN bakeoff series seems to focus more on 
later. We think corpus robustness should be 
received more attentions in the near future. 
We participant all simplified Chinese track on 
WS, NER and POS task in the SIGHAN bakeoff 
2007. There are more than two tracks for WS and 
POS. This gives us a chance to test the robustness 
of our systems. This paper reports our WS, NER 
and POS systems in the SIGHAN Bakeoff 2007, 
especially on the work of achieving robustness of 
WS and POS systems.  
This paper is arranged as follows, we introduce 
our WS, NER and POS system separately in 
section 2, section 3 and section 4, experiments and 
results are listed in section 5, finally we draw some 
conclusions. 
2 Word Segmentation 
WS system includes three sequent steps, which are 
basic segmentation, disambiguation and out-of 
vocabulary (OOV) recognition. In each step, we 
construct a basic work unit first, and then have an 
adaptor to tune the basic unit to fit different 
standards. 
94
Sixth SIGHAN Workshop on Chinese Language Processing
2.1 Basic Segmentation 
For constructing a basic work unit for WS, a 
common wordlist containing words ratified by four 
different segmentation standards (from SXU, NCC, 
PKU and CTB separately) are built. We finally get 
64,000 words including about 1500 known entity 
words as the common wordlist. A forward-
backward maximum matching algorithm with the 
common wordlist is employed as the common unit 
of our basic segmentor.  
To cater for different characteristics in different 
segmentation standards, we construct another 
wordlist containing words for each specification.  
A wordlist based adaptor is built to implement the 
tuning task after basic segmentation.  
2.2 Disambiguation 
Disambiguation of overlapping Ambiguity (OA) is 
a major task in this step.  
Strings with OA are also detected during basic 
forward-backward maximum matching in basic 
WS step. These strings are common OA strings for 
different standards. Class-based bigram model is 
applied to resolve the ambiguities. In class-based 
bigram, all named entities, all punctuation and 
factoids is one class respectively and each word is 
one class. We train the bigram transition 
probability based on the corpus of Chinese 
People?s Daily 2000 newswire.  
For corpus from different standards, overlapping 
ambiguity strings with less than 3 overlapping 
chain are extracted from each train corpus. We do 
not work on all of them but on some strings with a 
frequency that is bigger than a given value. A 
disambiguation adaptor using the highest 
probability segmentations is built for OA strings 
from each different standard.  
2.3 OOV Recognition 
In OOV recognition, we have a similar model 
which consists of a common part based on 
common characteristics and an individual part 
automatically constructed for each standard. 
We divide OOV into factoid which contains 
non-Chinese characters like date, time, ordinal 
number, cardinal number, phone number, email 
address and non-factoid.  
Factoid is recognized by an automaton. To 
compatible to different standards, we also built 
core automata and several adaptors. 
Non-factoid is tackled by a unified character-
based segmentation model based on CRF. We first 
transform the WS training dataset into character-
based two columns format as the training dataset in 
NER task. The right column is a boundary tag of 
each character. The boundary tags are B I and S, 
which B is the tag of the first character of a word 
which contains more than two characters, I is the 
other non-initial characters in a word, S is for the 
single character word. Then the transformed 
training data is used to train the CRF model. 
Features in the model are current character and 
other three characters within the context and 
bigrams.  
The trigger of non-factoid recognition is 
continual single character string excluding all the 
punctuations in a line after basic word matching, 
disambiguation and factoid incorporation. The 
model will tell whether these consecutive 
characters can form multi-character words in a 
given context. 
At last, several rules are used to recognize some 
proper names separated by coordinate characters 
like ???, ???, ??? and symbol ??? in foreign 
person names.  
3 Named Entity Recognition 
We built two NER systems separately. One is a 
unified named entity model based on CRF. It used 
only a little knowledge include a small scale of 
entity dictionary, a few linguistic rules to process 
some special cases such as coordinate relation in 
corpus and some special symbols like dot among a 
transliteration foreign person name.  
Another one is an individual model for each 
kind of entity based on Maximum Entropy where 
more rules found from corpus are used on entity 
boundary detection. Some details on this model 
can be found in Suxiang Zhang et al2006. 
4 POS Tagging 
In POS, we construct POS taggers for different 
standards under a two steps frame, both steps use 
ME but with incremental features. First, we use 
normal features based Maximum Entropy (ME) to 
train a basic model, and then join some 
probabilistic features acquired from error analysis 
to training a finer model.  
95
Sixth SIGHAN Workshop on Chinese Language Processing
4.1 Normal Features for ME 
In the first step of feature selection for ME 
tagger, we select contextual syntactic features for 
all words basing on a series of incremental 
experiments. 
For shrinking the search space, the model only 
assigns each word a label occurred in the training 
data. That is, the model builds a subset of all POS 
tags for each token and restricts all possible labels 
of a word within a small candidate set, which 
greatly saves computing cost. 
We enlarged PKU training corpus by using one 
month of Peking University's China Daily corpus 
(June in 2003) and CTB training corpus by using 
CTB 2.0 data which includes 325 passages. 
To adapt with the given training corpus, the 
samples whose labels are not included in the 
standard training data were omitted firstly. After 
preprocessing, we get two sets of training samples 
for PKU and CTB with 1178 thousands tokens and 
206 thousands tokens respectively. But the NCC 
test remains its original data due to we have no 
corpus with this standard. 
4.2 Probabilistic feature for ME 
By detecting the label errors when training and 
testing using syntactic features such as words 
around the current tokens and tags of previous 
tokens, words with multiple possible tags are 
obviously error-prone. We thus define some 
probabilistic features especially for multi-tag 
words.  
We find labels of these tokens are most closely 
related to POS tag of word immediately previous 
to them. For instance, in corpus of Peking 
University, word ?Report? has three different tags 
of ?n(noun), v(verb), vn(noun verb)?. But when we 
taken into account its immediately previous words, 
we can find that when previous word's label is 
?q(quantifier)?, ?Report? is labeled as ?n? with a 
frequency of 91.67%, ?v? with a frequency of 
8.33% and ?vn? with a frequency of 0.0%. We can 
assume that ?Report? is labeled as ?n? with the 
91.67% probability when previous word's label is 
?q?, and so on. 
 Such probability is calculated from the whole 
training data and is viewed as discriminating 
probabilistic feature when choosing among the 
multiple tags for each word.  But for words with 
only one possible tag, no matter what the label of 
previous word is, the label for them is always the 
tag occurred in the training data.  
5 Experiments 
We participant all simplified Chinese tracks on WS, 
NER and POS task in the SIGHAN bakeoff 2007. 
Our systems only deal with Chinese in GBK code. 
There are some mistakes in some results submitted 
to bakeoff organizer due to coding transform from 
GBK to UTF-16. We then use WS evaluation 
program in the SIGHAN bakeoff 2006 to re-
evaluate WS system using same corpus, as for POS, 
since there is no POS evaluation in the SIGHAN 
bakeoff 2006, we implement a evaluation using 
ourselves? program using same corpus.  
Table 1 shows evaluation results of WS using 
evaluation programs from both the SIGHAN 
bakeoff 2007 and the SIGHAN bakeoff 2006. 
Table 2 lists evaluation results of NER using 
evaluation program from the SIGHAN bakeoff 
2007. Table 3 gives evaluation results of POS 
using evaluation programs from both the SIGHAN 
bakeoff 2007 and ourselves(BUPT).  
 
 
Track UTF-16 
(SIGHAN4) 
GBK 
(SIGHAN 3) 
CTB 0.9256 0.950 
SXU 0.8741 0.969 
NCC 0.9592 0.972 
Table 1. WS results (F-measure) 
 
 
SIGHAN 4 R P F 
System-1 0.8452 0.872 0.8584 
System-2 0.8675 0.9163 0.8912 
Table 2. NER results (F-measure) 
 
 
Track UTF-16 
(SIGHAN 4) 
GBK 
(BUPT) 
CTB 0.9689 0.9689 
NCC 0.9096 0.9096 
PKU 0.6649 0.9462 
Table 3. POS Results (F-measure) 
 
From the table 1 and Table 3, we can find our 
system is robust enough. WS system keeps at a 
relatively steady performance. Difference in POS 
96
Sixth SIGHAN Workshop on Chinese Language Processing
between NCC and other two tracks is mainly due 
to the difference of the training corpus.  
6 Conclusion 
Recently, the robustness, a capability of keeping 
good performances for a system by automatically 
fitting the different corpus and standards, become a 
focal problem. This paper introduces our WS, NER 
and POS systems, especially on how they can get a 
robust performance. 
The SIGHAN bakeoff series seems to focus 
more on standard robustness. We think corpus 
robustness should be received more attentions in 
the near future. 
 
Acknowledgement 
Thanks to Zhang Yan, Zhang Bichuan, Zhang 
Taozheng, Liu Haipeng and Jiang Huixing for all 
the work they done to make the WS, NER and 
POS systems go on wheels in a very short time.  
References 
Berger, A., Della Pietra, S. and Della Pietra, V.: A 
Maximum Entropy Approach to Natural 
Language Processing. Computational 
Linguistics. 22(1): pp 39-71, 1996. 
Thomas Emerson. 2005. The Second International 
Chinese Word Segmentation Bakeoff. In 
Proceedings of the Fourth SIGHAN Workshop 
on Chinese Language Processing, Jeju Island, 
Republic of Korea. 
NanYuan Liang. 1987 A Written Chinese 
Segmentation system? CDWS.  Journal of 
Chinese Information Processing, Vol.2: 44-52 
YaJuan Lv, Tie-jun Zhao, et al 2001. Leveled 
unknown Chinese Words resolution by dynamic 
programming. Journal Information Processing, 
15(1): 28-33.  
Yintang Yan, XiaoQiang Zhou. 2000. Study of 
Segmentation Strategy on Ambiguous Phrases 
of Overlapping Type  Journal of The China 
Society For Scientific and Technical Information  
Vol. 19 , ?6  
Richard Sproat and Thomas Emerson. 2003. The 
First International Chinese Word Segmentation 
Bakeoff. In Proceedings of the Second SIGHAN 
Workshop on Chinese Language Processing, 
Sapporo, Japan. 
Caixia Yuan, Xiaojie Wang, Yixin Zhong. Some 
Improvements on Maximum Entropy Based 
Chinese POS Tagging. The Journal of China 
Universities of Posts and Telecommunications, 
Vol. 13, pp 99-103, 2006. 
Suxiang Zhang, Xiaojie Wang, Juan Wen, Ying 
Qin, Yixin Zhong. A Probabilistic Feature 
Based Maximum Entropy Model for Chinese 
Named Entity Recognition, in proceedings of 
21st International Conference on the Computer 
Processing of Oriental Languages,December 
17-19, 2006, Singapore.  
 
 
97
Sixth SIGHAN Workshop on Chinese Language Processing
Person Name Disambiguation based on Topic Model
Jiashen Sun, Tianmin Wang and Li Li
Center of Intelligence Science and Technology
Beijing University of Posts and Telecommunications
b.bigart911@gmail.com,
tianmin180@sina.com, wbg111@126.com
Xing Wu
School of Computer
Beijing University of Posts and 
Telecommunications
wuxing-6@163.com
Abstract
In this paper we describe our 
participation in the SIGHAN 2010 Task-
3 (Person Name Disambiguation) and 
detail our approaches. Person Name 
Disambiguation is typically viewed as an 
unsupervised clustering problem where 
the aim is to partition a name?s contexts 
into different clusters, each representing 
a real world people. The key point of 
Clustering is the similarity measure of 
context, which depends upon the features 
selection and representation. Two 
clustering algorithms, HAC and 
DBSCAN, are investigated in our system. 
The experiments show that the topic 
features learned by LDA outperforms
token features and more robust.
1 Introduction
Most current web searches relate to person
names. A study of the query log of the 
AllTheWeb and Altavista search sites gives an 
idea of the relevance of the people search task: 
11-17% of the queries were composed of a 
person name with additional terms and 4% were 
identified simply as person names (Spink et al,
2004).
However, there is a high level of ambiguity 
where multiple individuals share the same name 
and thus the harvesting and the retrieval of 
relevant information becomes more difficult. 
This ambiguity has recently become an active 
research topic and, simultaneously, a relevant 
application domain for Web search services. 
Zoominfo.com, Spock.com and 123people.com 
are examples of sites which perform web people 
search, although with limited disambiguation 
capabilities (Artiles et al, 2009).
This issue directed current researchers 
towards the definition of a new task called Web 
People Search (WePS) or Personal Name 
Disambiguation (PND). The key assumption 
underlying the task is that the context 
surrounding an ambiguous person name is 
indicative of its ascription. The goal of the 
clustering task was to group web pages
containing the target person's name, so that 
pages referring to the same individual are 
assigned to the same cluster. For this purpose a 
large dataset was collected and manually 
annotated.
Moreover, because of the ambiguity in word 
segmentation in Chinese, person name detection
is necessary, which is subtask of Named Entity 
Recognition (NER). NER is one of difficulties 
of the study of natural language processing, of 
which the main task is to identify person names, 
place names, organization names, number, time 
words, money and other entities. The main 
difficulties of Chinese person name entity 
recognition are embodied in the following points: 
1) the diversity of names form; 2) the Chinese 
character within names form words with each; 3) 
names and their context form words; 4) 
translation of foreign names require special 
considerations. 
In this paper we describe our system and
approach in the SIGHAN 2010 task-3 (Person 
Name Disambiguation). A novel Bayesian 
approach is adopt in our system, which
formalizes the disambiguation problem in a 
generative model. For each ambiguous name we 
first draw a distribution over person, and then 
generate context words according to this 
distribution. It is thus assumed that different 
persons will correspond to distinct lexical 
distributions. In this framework, Person Name 
Disambiguation postulates that the observed data 
(contexts) are explicitly intended to 
communicate a latent topic distribution 
corresponding to real world people.
The remainder of this paper is structured as 
follows. We first present an overview of related 
work (Section 2) and then describe our system 
which consists of NER and clustering in more 
details (Sections 3 and 4). Section 5 describes 
the resources and evaluation results in our 
experiments. We discuss our results and 
conclude our work in Section 6.
2 Related Work
The most commonly used feature is the bag of 
words in local or global context of the 
ambiguous name (Ikeda et al, 2009; Romano et 
al., 2009). Because the given corpus is often not 
large enough to learn the realistic probabilities 
or weights for those features, traditional 
algorithm such as vector-based techniques used 
in large-scale text will lead to data sparseness.
In recent years, more and more important 
studies have attempted to overcome the problem
to get a better (semantic) similarity measures. A
lot of features such as syntactic chunks, named 
entities, dependency parses, semantic role labels,
etc., were employed. However, these features 
need many NLP preprocessing (Chen, 2009). 
Many studies show that they can achieve state-
of-the-art performances only with lightweight 
features. Pedersen et al (2005) present
SenseClusters which represents the instances to 
be clustered using second order co?occurrence 
vectors. Kozareva (2008) focuses on the 
resolution of the web people search problem 
through the integration of domain information,
which can represent relationship between 
contexts and is learned from WordNet. PoBOC 
clustering (Cleuziou et al, 2004) is used which 
builds a weighted graph with weights being the
similarity among the objects.
Another way is to utilize universal data
repositories as external knowledge sources (Rao 
et al, 2007; Kalmar and Blume, 2007; Pedersen 
and Kulkarni; 2007) in order to give more
realistic frequency for a proper name or measure 
whether a bigram is a collocation.
Phan et al (2008) presents a general 
framework for building classifiers that deal with 
short and sparse text and Web segments by
making the most of hidden topics discovered 
from large-scale data collections. Samuel Brody 
et al (2009) adopt a novel Bayesian approach 
and formalize the word sense induction problem 
in a generative model.
Previous work using the WePS1 (Artiles et al,
2007) or WePS2 data set (Artiles et al, 2009) 
shows that standard document clustering 
methods can deliver excellent performance if 
similarity measure is enough good to represent 
relationship of context.
The study in Chinese PND is still in its 
infancy. Person Name detection is often 
necessary in Chinese. At present, the main 
technology of person name recognition is used 
statistical models, and the hybrid approach. Liu
et al (2000) designed a Chinese person name 
recognition system based on statistical methods, 
using samples of names from the text corpus and 
the real amount of statistical data to improve the 
system performance, while the shortcoming is 
that samples of name database are too small, 
resulting in low recall. Li et al (2006) use the 
combination of the boundary templates and local 
statistics to recognize Chinese person name, the 
recognition process is to use the boundary with 
the frequency of template to identify potential 
names, and to recognize the results spread to the 
entire article in order to recall missing names 
caused by sparse data.
3 Person Name Recognition
In this section, we focus on Conditional Random 
Fields (CRFs) algorithm to establish the 
appropriate language model. Given of the input 
text, we may detect the potential person names 
in the text fragments, and then take various 
features into account to recognize of Chinese 
person names.
Conditional Random Fields as a sequence 
learning method has been successfully applied in 
many NLP tasks. More details of the its 
principle can be referred in (Lafferty, McCallum, 
and Pereira, 2001; Wallach, 2004). We here will 
focus on how to apply CRFs in our person name 
recognition task.
3.1 CRFs-based name recognition
CRFs is used to get potential names as the first 
stage name recognition outcome. To avoid the 
interference that caused by word segmentation 
errors, we use single Chinese character 
information rather than word as discriminative 
features for CRFs learning model. 
We use BIEO label strategy to transfer the name 
recognition as a sequence learning task. The 
label set includes: B-Nr (Begin, the initial 
character of name), I-Nr (In, the middle 
character of name), E-Nr(End, the end character 
of name) and O (Other, other characters that 
aren?t name).
3.2 Rule-based Correction
After labeling the potential names by CRFs 
model, we apply a set of rules to boost 
recognition result, which has been proved to be 
the key to improve Chinese name recognition.
The error of the potential names outcome by 
CRFs model is mainly divided into the following 
categories: the initial character of name is not 
recognized, the middle character of name is not 
recognized, the end character of name is not 
recognized, and their combinations of those 
three errors. The other two extreme errors, 
including non-name recognition for the anchor 
name, and the name is not recognized as 
potential names.
In the stage of rule-based correction, we first 
conduct word segmentation for the text. The 
segmentation process is also realized with the 
method of CRFs, without using dictionaries and 
other external knowledge. The detailed 
description is beyond this paper, which can be 
accessible in the paper (Lafferty, McCallum, and 
Pereira, 2001). The only thing we should note is 
that part of the error in such segmentation result 
obtained in this way can be corrected through 
the introduction of an external dictionary.
For each potential name, and we examine it 
from the following two aspects:
1) It is reasonable to use the word in a person 
name, including checking the surname and the 
character used in names;
2) The left and right borders are correct. 
Check the left and right sides of the cutting unit 
can be added to the names, including the words
used before names, the words used behind 
names and the surname and character used in 
names.
4 Clustering
4.1 Features
The clustering features we used can be divided 
into two types, one is token features, including 
word (after stop-word removal), uni-character
and bi-character, the other is topic features, 
which is topic-based distribution of global or 
window context learned by LDA (Latent 
Dirichlet Allocation) model.
4.1.1 Token-based Features
Simple token-based features are used in almost 
every disambiguation system. Here, we extract 
three kinds of tokens: words, uni-char and bi-
char occurring in a given document.
Then, each token in each feature vector is 
weighed by using a tf-idf weighting and entropy 
weighting schemes defined as follows.
tf-idf weighting:
log( )ik ik
i
N
a f
n
 <
entropy weighting:
1
1
log( 1.0) 1 log( )
log( )
N
ij ij
ik ik
j i i
f f
a f
N n n 
? ?? ?
  ? ?? ?? ?? ?? ?
?<
where is the frequency of term i in 
document k, N is the number of document in 
corpus, is the frequency of term i in corpus. 
So,
1
1
log( )
log( )
N
ij ij
j i i
f f
N n n 
? ?
? ?
? ?
?
is the average uncertainty or entropy of term i.
Entropy weighting is based on information 
theoretic ideas and is the most sophisticated
weighting scheme.
4.1.2 Features Selection
In this Section, we give a brief introduction on 
two effective unsupervised feature selection 
methods, DF and global tf-idf.
DF (Document frequency) is the number of 
documents in which a term occurs in a dataset. It 
is the simplest criterion for term selection and 
easily scales to a large dataset with linear
computation complexity. It is a simple but 
effective feature selection method for text 
categorization (Yang & Pedersen, 1997).
We introduce a new feature selection method 
called ?global tf-idf? that takes the term weight 
into account. Because DF assumes that each 
term is of same importance in different 
documents, it is easily biased by those common 
terms which have high document frequency but 
uniform distribution over different classes.
Global tf-idf is proposed to deal with this 
problem:
1
N
i ik
k
g tfidf
 
 ?
4.1.3 Latent Dirichlet Allocation (LDA)
Our work is related to Latent Dirichlet 
Allocation (LDA, Blei et al 2003), a 
probabilistic generative model of text generation. 
LDA models each document using a mixture 
over K topics, which are in turn characterized as 
distributions over words. The main motivation is 
that the task, fail to achieve high accuracy due to 
the data sparseness.
LDA is a generative graphical model as 
shown in Figure 1. It can be used to model and 
discover underlying topic structures of any kind 
of discrete data in which text is a typical 
example. LDA was developed based on an 
assumption of document generation process 
depicted in both Figure 1 and Table 1.
Figure 1 Generation Process for LDA
4.1.4 LDA Estimation with Gibbs Sampling
Estimating parameters for LDA by directly and 
exactly maximizing the likelihood of the whole 
data collection is intractable. The solution to this 
is to use approximate estimation methods like 
Gibbs Sampling (Griffiths and Steyvers, 2004).
Here, we only show the most important 
formula that is used for topic sampling for words.
$IWHUILQLVKLQJ*LEEV6DPSOLQJWZRPDWULFHV?
DQG?DUH computed as follows.
where ? is the latent topic distribution 
corresponding to real world people.
4.1.5 Topic-based Features
Through the observation for the given corpus, 
many key information, like occupation,
affiliation, mentor, location, and so on, in many 
cases, around the target name. So, both local and 
global context are choose to doing topic analysis.
Finally, the latent topic distributions are topic-
based representation of context.
4.2 Clustering
Our system trusts the result of Person Name
detection absolutely, so contexts need to do 
clustering only if they refer to persons with the 
same name. We experimented with two different 
classical clustering methods: HAC and 
DBSCAN.
4.2.1 HAC
At the heart of hierarchical clustering lies the 
definition of similarity between clusters, which 
based on similarity between individual 
documents. In my system, a linear combination 
of similarity based on both local and global 
context is employed:
(1 )global localsim sim simD D ?  
where, the general similarity between two 
features-vector of documents di and dj is 
defined as the cosine similarity:
( , ) i ji j
i j
d d
sim d d
d d
 
<
We will now refine this algorithm for the 
different similarity measures of single-link,
complete-link, group-average and centroid 
clustering when clustering two smaller clusters 
together. In our approach we used an overall
similarity stopping threshold.
4.2.2 DBSCAN
In this section, we present the algorithm 
DBSCAN (Density Based Spatial Clustering of 
Applications with Noise) (Ester et al, 1996) 
(Table 2) which is designed to discover the 
clusters and the noise in a spatial database.
Table 2 Algorithm of DBSCAN
Arbitrary select a point p
Retrieve all points density-reachable from p wrt
Eps and MinPts.
If p is a core point, a cluster is formed.
If p is a border point, no points are density-
reachable from p and DBSCAN visits the 
next point of the database.
Continue the process until all of the points
5 Experiments and Results Analysis
We run all experiments on SIGHAN 2010 
training and test corpus. 
5.1 Preprocessing and Person Name 
Recognition
Firstly, a word segmentation tool based on CRF 
is used in each document. Then, person name 
recognition is processing. The training data for
word segmentation and PNR is People's Daily in 
January, 1998 and the whole 2000, respectively.
5.2 Feature Space
Our experiments used five types of feature (uni-
char, bi-char, word and topic in local and global), 
two feature weighting methods (tf-idf and 
entropy) and two feature selection methods (DF 
and global tf-idf).
5.3 Model Selection in LDA
Our model is conditioned on the Dirichlet 
hyperparameters D andE , the number of topic
K and iterations. The value for the D was set to 
0.2, which was optimized in tuning experiment 
used training datasets. The E was set to 0.1,
which is often considered optimal in LDA-
related models (Griffiths and Steyvers, 2004). 
The K was set to 200. The Gibbs sampler was 
run for 1,000 iterations.
5.4 Clustering Results and Analysis
Since the parameter setting for the clustering 
system is very important, we focus only on the 
B-cubed scoring (Artiles et al, 2009), and 
acquire an overall optimal fixed stop-threshold 
from the training data, and then use it in test data. 
In this section, we report our results evaluated 
by the clustering scoring provided by SIGNAN 
2010 evaluation, which includes both the B-
cubed scoring and the purity-based scoring.
Table 3 and 4 demonstrate the performance (F 
scores) of our system in different features 
representation and clustering for the training 
data of the SIGNAN 2010. In Table 3, the 
numbers in parentheses are MinPts and Eps 
respectively, and stop-threshold in Table 4. As 
shown in Table 3, DBSCAN isn?t suitable for 
this task, and the results are very sensitive to
parameters. So we didn?t submit DBSCAN-
based results.
Table 4 shows that the best averaged F-scores
for PND are based on topic model, which meet 
our initial assumptions, and result based on 
merging local and global information is a bit 
better than both local and global information
independently. Also, the results based on topic 
model are the most robust because the F-score of 
variation is slightly with stop-threshold changing.
Conversely, the results based on token are not 
like this. As the performance of segmentation is 
not very satisfactory, results based on word are 
worst, even worse than uni-char-based. In 
addition, it is found that global tf-idf is better 
than DF, which is the simplest unsupervised 
feature selection method. Entropy weighting is
more effective than tf-idf weighting.
Table 5 shows that the evaluation results in 
test data on SIGHAN 2010, and the last two 
lines are results in diagnosis test. We are in fifth 
place. The evaluation results (F-score) of Person 
Name Recognition in training data is 0.965.
Features FS Weighting B-Cubed P-IP
precision recall F P IP F
word (0.19)
DF
tf-idf
79.05 79.68 76.49 83.25 85.84 82.72
word (0.2) 80.99 75.72 75.54 84.67 83.08 82.2
word (0.3) entropy 78.8 80.71 77.42 83.13 86.62 83.58
word (0.25)
global tf-idf tf-idf
80.79 83.1 80.53 84.88 88.32 85.79
word (0.23) 79.45 84.49 79.66 83.76 89.25 85.08
uni-char (0.43)
DF tf-idf
76.47 85.46 78.77 81.7 90.05 84.45
uni-char (0.5) 82.34 75.97 77 86.11 83.54 83.78
uni-char (0.48) 80.42 79.44 78.01 84.53 86.17 84.26
bi-char (0.35) 88.3 67.75 75.34 89.96 77.38 82.44
bi-char (0.315) 81.84 81.58 80.54 85.72 87.17 85.8
local topic (0.6) 78.76 86.8 80.63 83.27 91.16 85.88
global topic (0.4) 77.92 88.72 81.04 82.67 92.64 86.26
global topic (0.7) 80.54 88.43 83.55 84.76 92.55 88.02
merged topic (0.63) 81.39 87.82 83.88 85.42 91.94 88.21
Table 3    Performance of HAC
B-Cubed P-IP
MinPts 
and Eps
precision recall F P IP F
2  0.9 64.15 95.84 74.19 71.95 97.36 80.97
2  0.4 71.34 62.25 63.95 76.56 71.94 72.59
3  0.9 64.15 95.88 74.2 71.95 97.37 80.97
6  0.95 64.12 96.55 74.44 71.92 97.79 81.12
B-Cubed P-IP
precision recall F P IP F
80.33 94.52 85.79 85.1 96.46 89.77
80.56 92.56 85.29 85.34 95.19 89.5
80.43 95.41 86.18 85.07 97.06 89.96
80.82 93.41 85.77 85.62 95.76 89.91
Table 5   Evaluation Results in test data
Table 4    Performance of DBSCAN
6 Discussion and Future Work
In this paper, we present implementation of our 
systems for SIGHAN-2010 PND bekeoff,.The 
experiments show that the topic features learned 
by LDA outperform token features and exhibit 
good robustness.
However, in our system, only given data is 
exploited. We are going to collect a very large 
external data as universal dataset to train topic 
model, and then do clustering on both a small set 
of training data and a rich set of hidden topics 
discovered from universal dataset. The universal 
dataset can be snippets returned by search 
engine or Wikipedia queried by target name and 
some keywords, and so on.
We built our PDN system on the result of 
person name recognition. However, it is not 
appropriate to toally trust the result of Person 
Name detection. So an algorithm that can correct 
NER mistakes should be investigated in future 
work..
Moreover, Cluster Ensemble system can 
ensure the result to be more robust and accurate 
accordingly, which is another direction of future 
work..
Acknowledgments
This research has been partially supported by the 
National Science Foundation of China (NO. 
NSFC90920006). We also thank Xiaojie Wang,
Caixia Yuan and Huixing Jiang for useful 
discussion of this work.
References
Spink, B. Jansen, and J. Pedersen. 2004.
Searching for people on web search engines. 
Journal of Documentation, 60:266 -278.
Javier Artiles, Julio Gonzalo, and Satoshi Sekine. 
2009. Weps 2 evaluation campaign: overview 
of the web people search clustering task. In 
WePS 2 Evaluation Workshop. WWW 
Conference.
Javier Artiles, Julio Gonzalo, and Satoshi Sekine. 
2007. The semeval-2007 weps evaluation: 
Establishing a benchmark for the web people 
search task. In Proceedings of the Fourth 
International Workshop on Semantic 
Evaluations (SemEval-2007).ACL.
M. Ikeda, S. Ono, I. Sato, M. Yoshida, and H. 
Nakagawa. 2009. Person name 
disambiguation on the web by twostage 
clustering. In 2nd Web People Search 
Evaluation Workshop (WePS 2009), 18th 
WWW Conference.
L. Romano, K. Buza, C. Giuliano, and L. 
Schmidt-Thieme. 2009. Person name 
disambiguation on the web by twostage 
clustering. In 2nd Web People Search 
Evaluation Workshop (WePS 2009), 18th 
WWW Conference.
Y. Chen, S. Y. M. Lee, and C.-R. Huang. 2009.
Polyuhk: A robust information extraction 
system for web personal names. In 2nd Web 
People Search Evaluation Workshop (WePS 
2009), 18th WWW Conference.
Z. Kozareva, R. Moraliyski, and G. Dias. 2008.
Web people search with domain ranking. In 
TSD '08: Proceedings of the 11th 
international conference on Text, Speech and
Dialogue, 133-140, Berlin, Heidelberg.
Pedersen, Ted, Amruta Purandare, and Anagha 
Kulkarni. 2005. Name Discrimination by 
Clustering Similar Contexts. In Proceedings 
of the Sixth International Conference on
Intelligent Text Processing and 
Computational Linguistics, Mexico City, 
Mexico.
G. Cleuziou, L. Martin, and C. Vrain. 2004.
Poboc: an overlapping clustering algorithm.
application to rule-based classification and 
textual data, 440-444.
Kalmar, Paul and Matthias Blume. 2007. FICO: 
Web Person Disambiguation Via Weighted 
Similarity of Entity Contexts. In Proceedings 
of the Fourth International Workshop on 
Semantic Evaluations (SemEval-2007).ACL.
Rao, Delip, Nikesh Garera and David Yarowsky. 
2007. JHU1 : An Unsupervised Approach to 
Person Name Disambiguation using Web 
Snippets. In Proceedings of the Fourth 
International Workshop on Semantic 
Evaluations (SemEval-2007).ACL.
Pedersen, Ted and Anagha Kulkarni. 2007.
Unsupervised Discrimination of Person 
Names in Web Contexts. In Proceedings of 
the Eighth International Conference on
Intelligent Text Processing and 
Computational Linguistics, Mexico City, 
Mexico.
Phan, X., Nguyen, L. and Horiguchi. 2008.
Learning to Classify Short and Sparse Test & 
Web with Hidden Topics from large-scale 
Data collection. In Proceedings of 17th
International World Wide Web Conference. 
(Beijing, China, April 21-25, 2008). ACM 
Press, New York, NY, 91-100.
Samuel Brody and Mirella Lapata. 2009.
Bayesian word sense induction In 
Proceedings of the 12th Conference of the 
European Chapter of the Association for 
Computational Linguistics, 103-111.
Sun et al 1995. Identifying Chinese Names in 
Unrestricted Texts (in Chinese). In Journal of 
Chinese Information Processing, 9(2):16-27.
Liu et al 2000. Statistical Chinese Person 
Names Identification (in Chinese). In Journal 
of Chinese Information Processing, 14(3):16-
24.
Huang et al 2001. Identification of Chinese 
Names Based on Statistics (in Chinese). In
Journal of Chinese Information Processing,
15(2):31-37.
Li et al 2006. Chinese Name Recognition Based 
on Boundary Templates and Local Frequency
(in Chinese). In Journal of Chinese 
Information Processing, 20(5):44-50.
Mao et al 2007. Recognizing Chinese Person 
Names Based on Hybrid Models (in Chinese).
In Journal of Chinese Information Processing,
21(2):22-27.
J. Lafferty, A. McCallum, and F. Pereira. 2001. 
Conditional random fields: Probabilistic 
models for segmenting and labeling sequence
data. In Proc. ICML-01, 282-289, 2001.
Wallach, Hanna. 2004. Conditional random 
fields: An introduction. Technical report,
University of Pennsylvania, Department of 
Computer and Information Science.
Yang, Y. and Pedersen, J. O. 1997. A 
comparative study on feature selection in text
categorization. In Proceedings of ICML-97, 
14th International Conference on Machine
Learning (Nashville, US, 1997), 412?420.
Martin Ester, Hans-Peter Kriegel, J?rg Sander, 
Xiaowei Xu. 1996. A density-based algorithm 
for discovering clusters in large spatial 
databases with noise. In Proceedings of the 
Second International Conference on 
Knowledge Discovery and Data Mining 
(KDD-96). AAAI Press. 226-231.
Blei, David M., Andrew Y. Ng, and Michael I. 
Jordan. 2003. Latent dirichlet alocation. In J. 
Machine Learn. Res. 3, 993-1022.
T. Griffiths and M. Steyvers. 2004. Finding 
scientific topics. In The National Academy of 
Sciences, 101:5228-5235.
Word Sense Induction using Cluster Ensemble 
 
  Bichuan  Zhang, Jiashen Sun 
 
Lingjia Deng, Yun Huang, Jianri Li, 
Zhongwan Liu, Pujun Zuo 
 
Center of Intelligence Science and 
Technology 
School of Computer 
Beijing University of Posts and Telecommunications, Beijing, 100876 China   
 
 
Abstract 
In this paper, we describe the implementation 
of an unsupervised learning method for 
Chinese word sense induction in 
CIPS-SIGHAN-2010 bakeoff. We present 
three individual clustering algorithms and the 
ensemble of them, and discuss in particular 
different approaches to represent text and 
select features. Our main system based on 
cluster ensemble achieves 79.33% in F-score, 
the best result of this WSI task. Our 
experiments also demonstrate the versatility 
and effectiveness of the proposed model on 
data sparseness problems.  
 
1 Introduction 
Word Sense Induction (WSI) is a particular task 
of computational linguistics which consists in 
automatically discovering the correct sense for 
each instance of a given ambiguous word  
(Pinto , 2007). This problem is closely related to 
Word Sense Disambiguation (WSD), however, 
in WSD the aim is to tag each ambiguous word 
in a text with one of the senses known as prior, 
whereas in WSI the aim is to induce the different 
senses of that word. 
The object of the sense induction task of 
CIPS-SIGHAN-2010 was to cluster 5,000 
instances of 100 different words into senses or 
classes. The task data consisted of the 
combination of the test and training data (minus 
the sense tags) from the Chinese lexical sample 
task. Each instance is a context of several 
sentences which contains an occurrence of a 
given word that serves as the target of sense 
induction.  
The accuracy of the corpus-based algorithms 
for WSD is usually proportional to the amount of 
hand-tagged data available, but the construction 
of that kind of training data is often difficult for 
real applications. WSI overcomes this drawback 
by using clustering algorithms which do not need 
training data in order to determine the possible 
sense for a given ambiguous word.  
This paper describes an ensemble-based 
unsupervised system for induction and 
classification. Given a set of data to be classified, 
the system clusters the data by individual clusters, 
then operates cluster ensemble to ensure the 
result to be robust and accurate accordingly.  
The paper is organized as follows. Section 2 
gives an description of the general framework of 
our system. Sections 3 and 4 present in more 
detail the implementation of feature set and 
cluster algorithms used for the task, respectively. 
Section 5 presents the results obtained, and 
Section 6 draws conclusions and some 
interesting future work. 
 
2 Methodology in Sense Induction Task 
Sense induction is typically treated as an 
unsupervised clustering problem. The input to 
the clustering algorithm are instances of the 
ambiguous word with their accompanying 
contexts (represented by co-occurrence vectors) 
and the output is a grouping of these instances 
into classes corresponding to the induced senses. 
In other words, contexts that are grouped 
together in the same class represent a specific 
word sense. 
In this task, an instance to be clustered is 
represented as a bag of tokens or characters that 
co?occur with the target word. To exploit the 
diversity of features, besides the co?occurrence 
matrix, we invoke the n-gram such as bi-grams 
that occur in the contexts. For assigning a weight 
for each term in each instance, a number of 
alternatives to tf-idf and entropy have been 
investigated.  
This representation raises one severe 
problem: the high dimensionality of the feature 
space and the inherent data sparseness. 
Obviously, a single document has a sparse vector 
over the set of all terms. The performance of 
clustering algorithms will decline dramatically 
due to the problems of high dimensionality and 
data sparseness. Therefore it is highly desirable 
to reduce the feature space dimensionality. We 
used two techniques to deal with this problem: 
feature selection and feature combination.  
Feature selection is a process that chooses a 
subset from the original feature set according to 
some criterion. The selected feature retains 
original physical meaning and provides a better 
understanding for the data and learning process. 
Depending on whether the class label 
information is required, feature selection can be 
either unsupervised or supervised. For WSI 
should be an unsupervised fashion, the 
correlation of each feature with the class label is 
computed by distance, information dependence, 
or consistency measures.  
Feature combination is a process that 
combines multiple complementary features based 
on different aspects extracted at the selection 
step, and forms a new set of features. 
The methods mentioned above are not 
directly targeted to clustering instances; in this 
paper we introduce three cluster algorithms: (a) 
EM algorithms (Dempster et al, 1977; 
McLachlan and Krishnan, 1997), (b) K-means 
(MacQueen, 1967), and (c) LAC (Locally 
Adaptive Clustering) (Domeniconi et al, 2004), 
and one cluster ensemble method to incorporate 
three results together to represent the target 
patterns and conduct sense clustering. 
We conduct multiple experiments to assess 
different methods for feature selection and 
feature combination on real unsupervised WSI 
problems, and make analysis through three facets: 
(a) to what extent feature selection can improve 
the clustering quality, (b) how much width of the 
smallest window that contains all the 
co?occurrence context can be reduced without 
losing useful information in text clustering, and 
(c) what index weighting methods should be 
applied to sense clustering. Besides the feature 
exploitation, we studied in more detail the 
performance of cluster ensemble method. 
 
3 Feature Extraction  
3.1 Preprocessing 
Each training or test instance for WSI task 
contains up to a few sentences as the surrounding 
context of the target word w, and the number of 
the sense of w is provided. We assume that the 
surrounding context of a target w is informative 
to determine the sense of it. Therefore a stream 
of induction methods can be designed by 
exploiting the context features for WSI.  
In our experiment, we consider both tokens 
(after word segmentation) and characters 
(without word segmentation) in the surrounding 
context of target word w as discriminative 
features, and these tokens or characters can be in 
different sentences from instances of w. Tokens 
in the list of stop words and tokens with only one 
character (such as punctuation symbols) are 
removed from the feature sets. All remaining 
terms are gathered to constitute the feature space 
of w. 
Since the long dependency property, the word 
sense could be relying on the context far away 
from it. From this point, it seems that more 
features will bring more accurate induction, and 
all linguistic cues should be incorporated into the 
model. However, more features are involved, 
more serious sparseness happens. Therefore, it is 
important to find a sound trade-off between the 
scale and the representativeness of features. We 
use the sample data provided by the 
CIPS-SIGHAN as a development data to find a 
genetic parameter to confine the context scale. 
Let ? be the width of the smallest window in an 
instance d that contains terms near the target 
word, measured in the number of words in the 
window. In cases where the terms in the window 
do not contain all of the informative terms, we 
can set ? to be some enormous number (? < the 
length of sentence). Such proximity-weighted 
scoring functions are a departure from pure 
cosine similarity and closer to the ?soft 
conjunctive? semantics.  
Token or character is the most straightforward 
basic term to be used to represent an instance. 
For WSI, in many cases a term is a meaningful 
unit with little ambiguity even without 
considering context. In this case the bag-of-terms 
representation is in fact a bag-of-words, therefore 
N-gram model can be used to exploit such 
meaningful units. An n-gram is a sequence of n 
consecutive characters (or tokens) in an instance. 
The advantages of n-grams are: they are 
language independent, robust against errors in 
instance, and they capture information about 
phrases. We performed experiments to show that 
for WSI, n-gram features perform significantly 
better than the flat features. 
There exists many approaches to weight 
features in text computing (Aas and Eikvil, 1999). 
A simple approach is TF (term frequency) using 
the frequency of the word in the document. The 
schemes take into account the frequency of the 
word throughout all documents in the collection. 
A well known variant of TF measure is TF-IDF 
weighting which assigns the weight to word i in 
document k in proportion to the number of 
occurrences of the word in the document, and in 
inverse proportion to the number of documents 
in the collection for which the word occurs at 
least once. 
*log( )ik ik
i
N
a f
n
=  
Another approach is Entropy weighting, 
Entropy weighting is based on information 
theoretic ideas and is the most sophisticated 
weighting scheme. It has been proved more 
effective than word frequency weighting in text 
representing. In the entropy weighting scheme, 
the weight for word  in document  is given 
by a
i k
ik. 
1
1
log( 1.0)* 1 log( )
log( )
N
ij ij
ik ik
j i i
f f
a f
N n n=
? ?= + +? ?? ?? ?
?? ?? ?? ?
 Re-parameterization is the process of 
constructing new features as combinations or 
transformations of the original features. We 
investigated Latent Semantic Indexing (LSI) 
method in our research and produce a 
term-document matrix for each target word. LSI 
is based on the assumption that there is some 
underlying or latent structure in the pattern of 
word usage across documents, and that statistical 
techniques can be used to estimate this structure. 
However, it is against the primitive goal of the 
LSI weighting that LSI performs slightly poorer 
compared with the TF, TF-IDF and entropy. The 
most likely reason may is that the feature space 
we construct is far from high-dimension, while 
feature the LSI omitted may be of help for 
specific sense induction.  
3.2 Feature Selection 
A simple features election method used here is 
frequency thresholding. Instance frequency is the 
number of instance to be clustered in which a 
term occurs. We compute the instance frequency 
for each unique term in the training corpus and 
remove from the feature space those terms whose 
instance frequency was less than some 
predetermined threshold (in our experiment, the 
threshold is 5). The basic assumption is that rare 
terms are either non-informative for category 
prediction, or not influential in global 
performance. The assumption of instance 
frequency threshold is more straightforward that 
of LSI, and in either case, removal of rare terms 
reduces the dimensionality of the feature space. 
Improvement in cluster accuracy is also possible 
if rare terms happen to be noise terms. 
Frequency threshold is the simplest technique 
for feature space reduction. It easily scales to 
sparse data, with a computational complexity 
approximately linear in the number of training 
documents. However, it is usually considered an 
ad hoc approach to improve efficiency, not a 
principled criterion for selecting predictive 
features. Also, frequency threshold is typically 
not used for aggressive term removal because of 
a widely received assumption in information 
retrieval. That is, low instance frequency terms 
are assumed to be relatively informative and 
therefore should not be removed aggressively. 
We will re-examine this assumption with respect 
to WSI tasks in experiments. 
Information gain (IG) is another feature 
felection can be easily applied to clustering and 
frequently employed as a term-goodness 
criterion in the field of machine learning. It 
measures the number of bits of information 
obtained for cluster prediction by knowing the 
presence or absence of a term in an instance.  
Since WSI should be conducted in an 
unsupervised fashion, that is, the labels are not 
provided, the IG method can not be directly used 
for WSI task. But IG can be used to find which 
kind of features we consider in Section 3.1 are 
most informative feature among all the feature 
set. We take the training samples as the 
development data to seek for the cues of most 
informative feature. For each unique term we 
compute the information gain and selecte from 
the feature space those terms whose information 
gain is more than some predetermined threshold. 
The computation includes the estimation of the 
conditional probabilities of a cluster given a term 
and the entropy computations in the definition.  
m
i 1
IG(t) = - ( ) log ( )i ip c p c=?  
       
m
i 1
( ) ( | t) log ( | t)i ip t p c p c=+ ?  
       
m
i 1
( ) ( | ) log ( | )i ip t p c t p c t=+ ?  
where t is the token under consideration, ci is 
the corresponding cluster.This definition is more 
general than the one employed in binary 
classification models. We use the more general 
form because WSI task have a feature sparse 
problem, and we need to measure the goodness 
of a feature selection method globally with 
respect to all clusters on average. 
3.3 Feature combination 
Combining all features selected by different 
feature set can improve the performance of a 
WSI system. In the selection step, we find the 
feature that best distinguishes the sense classes, 
and iteratively search additional features which 
in combination with other chosen features 
improve word sense class discrimination. This 
process stops once the maximal evaluation 
criterion is achieved. 
We are trying to disply an empirical 
comparison of representative feature 
combination methods. We hold that particular 
cluster support specific datasets; a test with such 
combination of cluster algorithm and feature set 
may wrongly show a high accuracy rate unless a 
variety of clusterers are chosen and many 
statistically different feature sets are used. Also, 
as different feature selection methods have a 
different bias in selecting features, similar to that 
of different clusterers, it is not fair to use certain 
combinations of methods and clusterers, and try 
to generalize from the results that some feature 
selection methods are better than others without 
considering the clusterer. 
This problem is challenging because the 
instances belonging to the same sense class 
usually have high intraclass variability. To 
overcome the problem of variability, one strategy 
is to design feature combination method which 
are highly invariant to the variations present 
within the sense classes. Invariance is an 
improvement, but it is clear that none of the 
feature combination method will have the same 
discriminative power for all clusterers. 
For example, features based on global window 
might perform well when instances are shot, 
whereas a feature weighting method for this task 
should be invariant to the all the WSI corpus. 
Therefore it is widely accepted that, instead of 
using a single feature type for all target words it 
is better to adaptively combine a set of diverse 
and complementary features. In our experiment, 
we use several combination of features in 
multiple views, that is, uni-gram/bi-gram, 
global/window, and tfidf/entropy ? in order to 
discriminate each combination best from all 
other clusters.  
4 Cluster  
There are two main issues in designing cluster 
ensembles: (a) the design of the individual 
?clusterers? so that they form potentially an 
accurate ensemble, and (b) the way the outputs 
of the clusterers are combined to obtain the final 
partition, called the consensus function. In some 
ensemble design methods the two issues are 
merged into a single design procedure, e.g., 
when one clusterer is added at a time and the 
overall partition is updated accordingly (called 
the direct or greedy approach).  
In this task we consider the two tasks 
separately, and investigate three powerful cluster 
methods and corresponding consensus functions. 
4.1 EM algorithm 
Expectation-maximization algorithm, or EM 
algorithm (Dempster et al, 1977; McLachlan and 
Krishnan, 1997) is an elegant and powerful 
method for finding maximum likelihood 
solutions for models with latent variables.  
Given a joint distribution  (X, Z | )p ?  over 
observed variables X and latent variables Z, 
governed by parameters ? , the goal is to 
maximize the likelihood function (X | )p ?  
with respect to? . 
1. Choose an initial setting for the 
parameters
old? ; 
2. E step Evaluate ; (Z | X, )oldp ?
3. M step Evaluate new?  given by 
 ; = argmax ( , )new old
?
? ? ? ?
where ( , ) (Z|X, ) ln (X,Z| )old old
z
p p? ? ? ? ?=?  
4. Check for convergence of either the log 
likelihood or the parameter values. If the 
convergence criterion is not satisfied, then let 
old new? ??  
and return to step 2. 
4.2  K-means  
K-means clustering (MacQueen, 1967) is a 
method commonly used to automatically 
partition a data set into k groups. It proceeds by 
selecting k initial cluster centers and then 
iteratively refining them as follows:  
1. Each instance d is assigned to its closest 
cluster center. 
i 
2. Each cluster center C is updated to be the 
mean of its constituent instances. 
j 
The algorithm converges when there is no 
further change in assignment of instances to 
clusters. In this work, we initialize the clusters 
using instances chosen at random from the data 
set. The data sets we used are composed of 
numeric feature, for numeric features, we use a 
Euclidean distance metric.  
4.3  LAC 
Domeniconi et al(2004) proposed an Locally 
Adaptive Clustering algorithm (LAC), which 
discovers clusters in subspaces spanned by 
different combinations of dimensions via local 
weightings of features. Dimensions along which 
data are loosely correlated receive a small weight, 
which has the effect of elongating distances 
along that dimension. Features along which data 
are strongly correlated receive a large weight, 
which has the effect of constricting distances 
along that dimension. Thus the learned weights 
perform a directional local reshaping of distances 
which allows a better separation of clusters, and 
therefore the discovery of different patterns in 
different subspaces of the original input space.  
The clustering result of LAC depends on 
two input parameters. The first one is common to 
all clustering algorithms: the number of clusters 
k to be discovered in the data. The second one 
(called h) controls the strength of the incentive to 
cluster on more features. The setting of h is 
particularly difficult, since no domain knowledge 
for its tuning is likely to be available. Thus, it 
would be convenient if the clustering process 
automatically determined the relevant subspaces.  
 
4.4 Cluster Ensemble 
Cluster ensembles offer a solution to challenges 
inherent to clustering arising from its ill-posed 
nature. Cluster ensembles can provide robust and 
stable solutions by leveraging the consensus 
across multiple clustering results, while 
averaging out emergent spurious structures that 
arise due to the various biases to which each 
participating algorithm is tuned. 
Kuncheva et al (2006) has shown Cluster 
ensembles to be a robust and accurate alternative 
to single clustering runs. In the work of 
Kuncheva et al (2006), 24 methods for 
designing cluster ensembles are compared using 
24 data sets, both artificial and real. Both 
diversity within the ensemble and accuracy of 
the individual clusterers are important factors, 
although not straightforwardly related to the 
ensemble accuracy. 
The consensus function aggregates the outputs 
of the Individual clusterers into a single partition. 
Many consensus functions use the consensus 
matrix obtained from the adjacency matrices of 
the individual clusterers. Let N be the number of 
objects in the data set. The adjacency matrix for 
clusterer  is an N by N matrix with entry k
( , ) 1i j =  if objects i  and j  are placed in the 
same cluster by clusterer , and ( ,k ) 0i j = , 
otherwise. The overall consensus matrix, M, is 
the average of the adjacency matrices of the 
clusterers. Its entry gives the proportion of 
clusterers which put and
( , )i j
i j  in the same cluster. 
Here the overall consensus matrix, M, can be 
interpreted as similarity between the objects or 
the ?data?. It appears that the clear winner in the 
consensus function ?competition? is using the 
consensus matrix as data. Therefore, the 
consensus functions used in the WSI task invoke 
the approach whereby the consensus matrix M is 
used as data (features). Each object is 
represented by N features, i.e., the j -the feature 
for object  is the ( ,  entry of M. i )i j
Then we use Group-average agglomerative 
clustering (GAAC) to be the consensus functions 
clustering the M matrix. 
5 Analysis 
First, we conducte an ideal case experiment on 
the training samples provided by CIPS-SIGHAN 
2010, to see whether good terms can help sense 
clustering. Specifically, we applied supervised 
feature selection methods to choose the best 
feature combinations driven by performance 
improving on the training features. Then, we 
executed the word sense induction task using 
features under the prefered feature combinations 
and compare the various clustering results output 
by three individual cluster. 
We then designe cluster ensemble method 
with results on three clusters, distributed as M 
data consensus matrix.  
5.1 Soundex for Feature 
We apply feature selection and feature 
combination to instances in the preprocessing of 
K-means, EM and LAC. The effectiveness of a 
combination method is evaluated using the 
performance of the cluster algorithm on the 
preprocessed WSI. We use the standard 
definition of recall and precision as F-score 
(Zhao and Karypis, 2005) to evaluate the 
clustering result. 
As described in Section 3, selection methods 
are included in this study, each of which uses a 
term-goodness criterion threshold to achieve a 
desired degree from the full feature set of WSI 
corpus. 
Table 2 shows The F-score figures for the 
different combinations of knowledge sources and 
learning algorithms for the training data set. The 
feature columns correspond to: 
(i) tfidf: tf-idf weighting 
(ii) entro: Entropy weighting 
(iii) bi: bi-gram representation 
(iv) uni: uni-gram representation 
(v) global: using all the terms in the 
instance 
(vi) winXX: using only terms in the 
surrounding context, and the width of 
the window is the figure followed by. 
As shown in Table 2, the best averaged 
F-score for WSI (without combination) is 
obtained by global_entro by maintaining a very 
consistent result for three cluster algorithm. That 
is, the feature weighting method will dominate  
 
Feature k-means LAC EM average 
combine_uni_bi_entro_8:2 0.817375775 0.819315654 0.811188742 0.81596 
combine_uni_bi_entro_9:1 0.812858111 0.817265352 0.81510355 0.815075 
combine_uni_bi_entro_7:3 0.805319576 0.817909374 0.819887132 0.814372 
combine_uni_bi_entro_1:1 0.810324177 0.81397143 0.812962625 0.812419 
combine_uni_bi_entro_6:4 0.806647971 0.815069965 0.810440791 0.811945 
combine_uni_bi_entro_1:9 0.810576944 0.811287122 0.813785918 0.811883 
combine_uni_bi_entro_4:6 0.810475113 0.810512846 0.811584054 0.810857 
combine_uni_bi_entro_3:7 0.809265111 0.811142052 0.811340668 0.810582 
combine_uni_bi_entro_2:8 0.811090379 0.804433939 0.813767918 0.809764 
uni_global_entro 0.765063808 0.75954835 0.746212504 0.756942 
uni_global_tfidf 0.765011785 0.757537564 0.745006996 0.755852 
uni_win30_tfidf 0.764949578 0.757424304 0.744497086 0.755624 
uni_win40_tfidf 0.764772672 0.755702292 0.744319609 0.754932 
uni_win30_entro 0.764286757 0.755514592 0.742825875 0.754209 
uni_win40_tfidf 0.763994795 0.75954835 0.742747114 0.75543 
bi_global_entro 0.740026161 0.731310077 0.71651859 0.729285 
bi_global_tfidf 0.739555095 0.731264758 0.716031966 0.728951 
bi_win30_entro 0.737209909 0.729711844 0.714498518 0.72714 
bi_win40_entro 0.715230191 0.713987571 0.699644178 0.709621 
bi_win40_tfidf 0.714031488 0.710282928 0.697201196 0.707172 
bi_win30_ tfidf 0.740026161 0.731310077 0.71651859 0.729285 
 
Table 1: Feature selection for our system. 
 
                  
the F-score. On the other hand, we should 
combine uni_global_entro and bi_global_entro to 
improve the cluster performance: 
(vii) combine: combining all two feature 
(uni and bi) with the at the rate of  
the ratio followed by. 
From these figures, we found the following 
points. First, feature selection can improve the 
clustering performance when a certain terms are 
combined. For example, any feature combination 
methods can achieve about 5% improvement. 
Second, as can be seen from Table 1, the best 
performances yielded at the combination ratio of 
8:2. As can be seen, when more bi-gram terms 
are added, the performances of combination 
methods drop obviously. In order to find out the 
reason, we compared the terms selected at 
different ratio. After analysis, we found that 
Chinese word senses have their own 
characteristics, unigram language model is 
suitable for WSI in Chinese; also, in WSI task,  
informative term may be in the entire instance 
but not appear closest to the target word, the 
language model and the width of window is 
much more important than the feature weighting 
for feature selection. Since entropy weighting 
perform better than tf-idf weighting, tf-idf 
weighting can be removed with an improvement 
in clustering performance on the training dataset. 
Hence, it is obvious that combination methods 
are much better than single feature set when 
processing WSI, and we chose 
combine_uni_bi_entro_8:2, i.e., the top 80% 
uni-gram features and top 20% features as the 
final clustering features. 
5.2 The cluster ensembles 
As described in Section 5.1, we use two language 
models (uni-gram and bi-gram), 4 types of the 
context window (20, 30, 40 and global) and 2 
feature weighting methods (tf-idf and entropy), 
also, 10 combined feature set and 3 cluster 
algorithm is introduced; in the other word, we 
have at least 78 result, that is 78 consensus 
matrix interpreted as ?data? to be aggregated. 
Thus we can evaluate the statistical significance 
of the difference among any ensemble methods 
on any cluster result set.  
To compare all ensemble methods, we group 
the result sets (out of 78) into different feature 
representation scheme. Significant difference for 
a given feature representation methods, the 
ensemble result is observed to check weather 
cluster ensembles can be more accurate than 
single feature set and to find out which method 
appears to be the best choice for the WSI task. 
Table 2 shows the ensembles examined in our 
experiment. The feature columns correspond to 
different group of result set, for example, bi_tfidf 
indicates bi-gram model and tf-idf feature 
weighting methods are selected, all the 3 cluster 
results on win20, win30, win 40 and global 
feature sets (12 consensus matrix) are aggregated; 
complex_entro indicates that all the feature 
representation methods selecting entropy 
weighting are chosen. 
Results show that the best performance is the 
group in which all the outputs of all the 
clusterers are combined (the top row in Table 2). 
 
Feature F1-score Scale 
complex 0.827566232 78 
complex_entro 0.823006644 24 
complex_nocomb 0.822970703 48 
complex_global 0.821960768 12 
uni_complex 0.821931155 24 
uni_ entro 0.821931155 15 
uni_global 0.821817211 6 
complex_combine 0.819456935 30 
uni_ tfidf 0.811631894 12 
complex_tfidf 0.806807226 24 
complex_entro 0.806063712 24 
bi_complex 0.801211134 24 
bi_entro 0.794939656 12 
bi_global 0.788673134 6 
bi_tfidf 0.788170215 12 
Table 2: Ensemble designs sorted by the total 
index of performance 
5.3 CIPS-SIGHAN WSI Performance 
The goal of this task is to promote the exchange 
of ideas among participants and improve the 
performance of Chinese WSI systems. The input 
consists of 100 target words, each target word 
having a set of contexts where the word appears. 
The goal is to automatically induce the senses 
each word has, and cluster the contexts 
accordingly. The evaluation measures provided 
is F-Score measure. In order to improve the 
overall performance, we used two techniques: 
feature combination and Cluster Ensemble. 
We chose combinomg global size of window, 
entropy weighting, uni-garm and bi-gram at the 
ratio of 8:2 as the final feature extraction method. 
Three powerful cluster algorithms, EM, K-means 
and LAC recieve these features as input, and in 
our main system all the outputs of all the 
clusterers are combined to process cluster 
ensemble. In Table 3 we show four results 
obtained by three individual clusters and one 
ensemble of them. 
Our main system has outperformed the other 
systems achieving 79.33%. Performance for 
LAC is 78.95%, 0.4% lower the best system. For 
EM our F-sore is 78.55%, which is around 0.8% 
lower than the best system, the similar result ia 
also observed for K-means. The results of our 
system are ranked in the top 4 place and 
obviously better the other systems. 
 
Name F1-score Rank 
BUPT_mainsys 0.7933 1 
BUPT_LAC 0.7895 2 
BUPT_EM  0.7855 3 
BUPT_kmeans 0.7849 4 
Table 3: Evaluation (F-score performance) 
6 Conclusions  
In this paper, we described the implementation of 
our systems that participated in word sense 
induction task at CIPS-SIGHAN-2010 bakeoff. 
Our ensemble model achieved 79.33% in F-score, 
78.95% for LAC, 78.55% for EM and 78.49% 
for K-means. The result proved that our system 
had the ability to fully exploit the informative 
feature in senses and the ensemble clusters 
enhance this advantage. 
One direction of future work is to exploit more 
semantic cues for word sense distribution. 
Furthermore, in order to represent the short 
context of the target word, we should investigate 
more powerful model and external knowledge to 
expand its linguistic environments. 
Acknowledgement 
 
This research has been partially supported by the 
National Science Foundation of China (NO. 
NSFC90920006). We also thank Xiaojie Wang, 
Caixia Yuan and Huixing Jiang for useful 
discussion of this work.  
References  
D. Pinto, P. Rosso, and H. Jim?enez-Salazar. UPV-SI: 
Word sense induction using self term expansion. In 
Proc. of the 4th International Workshop on 
Semantic Evaluations - SemEval 2007. Association 
for Computational Linguistics, 2007. pp. 430-433. 
Yiming Yang and Jan O. Pedersen. A Comparative 
Study on Feature Selection in Text Categorization. 
In Proceedings of the 14th International 
Conference on Machine Learning (ICML), 1997. 
pp. 412-420. 
Salton, Gerard, and Chris Buckley. 1987. Term 
weighting approaches in automatic text retrieval. 
Technical report, Cornell University, Ithaca, NY, 
USA. 
S. Dumais, Improving the retrieval of information 
from external sources, Behavior Research Methods, 
Instruments, & Computers, 1991, 23:229-236. 
M. W. Berry, S. T. Dumais, and G. W. O'Brien, Using 
linear algebra for intelligent information retrieval, 
SIAM Rev., 1995, 37:573-595 
MacQueen, J. B. (1967). Some methods for 
classification and analysis of multivariate  
observations. Proceedings of the Fifth Symposium 
on Math, Statistics, and Probability, Berkeley, CA: 
University of California Press. pp. 281-297. 
Dempster,A.P., Laird,N.M and Rubin,D.B. (1977) 
Maximum likelihood from incomplete data via the 
EM algorithm. J. Roy. Statist. Soc. B, 39, 1-38. 
MCLACHLAN, G., AND KRISHNAN, T. 1997. The 
EM algorithm and extensions. Wiley series in 
probability and statistics. JohnWiley & Sons. 
Y. Zhao and G. Karypis. 2002. Evaluation of 
hierarchical clustering algorithms for document 
datasets. In Proceedings of the 11th Conference of 
Information and Knowledge Management (CIKM), 
pp. 515-524. 
K. Aas and L. Eikvil. Text categorisation: A survey. 
Technical Report 941, Norwegian Computing 
Center, June 1999. 
C. Domeniconi, D. Papadopoulos, D. Gunopulos, and 
S. Ma. Subspace clustering of high dimensional 
data. SIAM International Conference on Data 
Mining, 2004. 
Kuncheva, L.I., Hadjitodorov, S.T., and Todorova, 
L.P. Experimental Comparison of Cluster 
Ensemble Methods, The 9th International 
Conference on Information Fusion, 2006. 
